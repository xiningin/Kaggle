{"cell_type":{"26479316":"code","9b3aa8c1":"code","12d4a207":"code","8e347d0b":"code","6b8b56c4":"code","b68e28c9":"code","8e152fac":"code","6ea3516a":"code","c48e381c":"code","5c94f36b":"code","32496e06":"code","9cef894d":"code","421667ab":"code","6fba9454":"code","81991123":"code","28e87275":"code","0e8fd5c6":"code","818a3234":"code","d63c3791":"code","ad90a43a":"code","119eac3b":"code","d62f2d23":"code","db6f361c":"code","10303bc1":"code","3c62e093":"code","d4c465ca":"code","8596aa56":"code","f48e77e4":"code","1f69e971":"markdown","7fcfc004":"markdown","f1e15663":"markdown","214d1064":"markdown","7f5fcbf6":"markdown","2031d878":"markdown","4c5793fa":"markdown","17944be1":"markdown","ceab202a":"markdown","1bf3d4c9":"markdown","f7a3c339":"markdown","d52d013c":"markdown","3109562d":"markdown","a65e1be2":"markdown","2c0a4a18":"markdown","4058c650":"markdown","1b1f4680":"markdown","dc6165a1":"markdown","753db88b":"markdown","41e5a498":"markdown","fb790d1b":"markdown","62a5819f":"markdown","bcebb16a":"markdown","e4d05a42":"markdown","0575c671":"markdown","e9727baa":"markdown","6944c626":"markdown","0a4cec20":"markdown","f0700dc0":"markdown","227b6892":"markdown","3074c257":"markdown","15c1dabf":"markdown","deaf869e":"markdown","1a7f23dd":"markdown","31728e1f":"markdown","da2a78ff":"markdown","029d677d":"markdown","e8b161ac":"markdown","6294c637":"markdown","28e3016b":"markdown","238bef4b":"markdown","792c332e":"markdown","5f79a267":"markdown","b65542f7":"markdown"},"source":{"26479316":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport folium\nfrom folium.plugins import FastMarkerCluster, Fullscreen, MiniMap, HeatMap, HeatMapWithTime\nimport geopandas as gpd\nfrom branca.colormap import LinearColormap\nimport os\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport re\nfrom wordcloud import WordCloud, STOPWORDS","9b3aa8c1":"def style_function(feature):\n    \"\"\"\n    Customize maps\n    \"\"\"\n    return {\n        'fillColor': '#ffaf00',\n        'color': 'grey',\n        'weight': 1.5,\n        'dashArray': '5, 5'\n    }\n\ndef highlight_function(feature):\n    \"\"\"\n    Customize maps\n    \"\"\"\n    return {\n        'fillColor': '#ffaf00',\n        'color': 'black',\n        'weight': 2,\n        'dashArray': '5, 5'\n    }\n\ndef format_spines(ax, right_border=True):\n    \"\"\"\n    This function sets up borders from an axis and personalize colors\n    \n    Input:\n        Axis and a flag for deciding or not to plot the right border\n    Returns:\n        Plot configuration\n    \"\"\"    \n    # Setting up colors\n    ax.spines['bottom'].set_color('#CCCCCC')\n    ax.spines['left'].set_color('#CCCCCC')\n    ax.spines['top'].set_visible(False)\n    if right_border:\n        ax.spines['right'].set_color('#CCCCCC')\n    else:\n        ax.spines['right'].set_color('#FFFFFF')\n    ax.patch.set_facecolor('#FFFFFF')\n    \ndef count_plot(feature, df, colors='Blues_d', hue=False, ax=None, title=''):\n    \"\"\"\n    This function plots data setting up frequency and percentage in a count plot;\n    This also sets up borders and personalization.\n    \n    Input:\n        The feature to be counted and the dataframe. Other args are optional.\n    Returns:\n        Count plot.\n    \"\"\"    \n    # Preparing variables\n    ncount = len(df)\n    if hue != False:\n        ax = sns.countplot(x=feature, data=df, palette=colors, hue=hue, ax=ax, \n                           order=df[feature].value_counts().index)\n    else:\n        ax = sns.countplot(x=feature, data=df, palette=colors, ax=ax,\n                           order=df[feature].value_counts().index)\n\n    # Make twin axis\n    ax2=ax.twinx()\n\n    # Switch so count axis is on right, frequency on left\n    ax2.yaxis.tick_left()\n    ax.yaxis.tick_right()\n\n    # Also switch the labels over\n    ax.yaxis.set_label_position('right')\n    ax2.yaxis.set_label_position('left')\n    ax2.set_ylabel('Frequency [%]')\n    frame1 = plt.gca()\n    frame1.axes.get_yaxis().set_ticks([])\n\n    # Setting up borders\n    format_spines(ax)\n    format_spines(ax2)\n\n    # Setting percentage\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax.annotate('{:.1f}%'.format(100.*y\/ncount), (x.mean(), y), \n                ha='center', va='bottom') # set the alignment of the text\n    \n    # Final configuration\n    if not hue:\n        ax.set_title(df[feature].describe().name + ' Counting plot', size=13, pad=15)\n    else:\n        ax.set_title(df[feature].describe().name + ' Counting plot by ' + hue, size=13, pad=15)  \n    if title != '':\n        ax.set_title(title)       \n    plt.tight_layout()\n    \ndef country_analysis(country_name, data, palette, colors_plot2, color_lineplot):\n    \"\"\"\n    This function creates a dashboard with informations of terrorism in a certain country.\n    Input:\n        The function receives the name of the country, the dataset and color configuration\n    Output:\n        It returns a 4 plot dashboard.\n    \"\"\"\n    # Preparing\n    country = data.query('country_txt == @country_name')\n    if len(country) == 0:\n        print('Country did not exists in dataset')\n        return \n    country_cities = country.groupby(by='city', as_index=False).count().sort_values('eventid', \n                                                                                   ascending=False).iloc[:5, :2]\n    suicide_size = country['suicide'].sum() \/ len(country)\n    labels = ['Suicide', 'Not Suicide']\n    colors = colors_plot2\n    \n    country_year = country.groupby(by='iyear', as_index=False).sum().loc[:, ['iyear', 'nkill']]\n    country_weapon = country.groupby(by='weaptype1_txt', as_index=False).count().sort_values(by='eventid',\n                                                                                             ascending=False).iloc[:, \n                                                                                                                   :2]\n    # Dashboard\n    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n    \n    # Plot 1 - Top 5 terrorism cities\n    sns.barplot(x='eventid', y='city', data=country_cities, ci=None, palette=palette, ax=axs[0, 0])\n    format_spines(axs[0, 0], right_border=False)\n    axs[0, 0].set_title(f'Top 5 {country_name} Cities With Most Terrorism Occurences')\n    \"\"\"for p in axs[0, 0].patches:\n        width = p.get_width()\n        axs[0, 0].text(width-290, p.get_y() + p.get_height() \/ 2. + 0.10, '{}'.format(int(width)), \n                ha=\"center\", color='white')\"\"\"\n    axs[0, 0].set_ylabel('City')\n    axs[0, 0].set_xlabel('Victims')\n    \n    # Plot 2 - Suicide Rate\n    center_circle = plt.Circle((0,0), 0.75, color='white')\n    axs[0, 1].pie((suicide_size, 1-suicide_size), labels=labels, colors=colors_plot2, autopct='%1.1f%%')\n    axs[0, 1].add_artist(center_circle)\n    format_spines(axs[0, 1], right_border=False)\n    axs[0, 1].set_title(f'{country_name} Terrorism Suicide Rate')\n    axs[0, 0].set_ylabel('Victims')\n    \n    # Plot 3 - Victims through the years\n    sns.lineplot(x='iyear', y='nkill', data=country_year, ax=axs[1, 0], color=color_lineplot)\n    format_spines(axs[1, 0], right_border=False)\n    axs[1, 0].set_xlim([1970, 2017])\n    axs[1, 0].set_title(f'{country_name} Number of Victims Over Time')\n    axs[1, 0].set_ylabel('Victims')\n    \n    # Plot 4 - Terrorism Weapons\n    sns.barplot(x='weaptype1_txt', y='eventid', data=country_weapon, ci=None, palette=palette, ax=axs[1, 1])\n    axs[1, 1].set_xticklabels(axs[1, 1].get_xticklabels(), rotation=90)\n    axs[1, 1].set_xlabel('')\n    axs[1, 1].set_ylabel('Count')\n    format_spines(axs[1, 1], right_border=False)\n    axs[1, 1].set_title(f'{country_name} Weapons Used in Attacks')\n    \n    plt.suptitle(f'Terrorism Analysis in {country_name} between 1970 and 2017', size=16)    \n    plt.tight_layout()\n    plt.subplots_adjust(top=0.90)\n    plt.show()","12d4a207":"terr = pd.read_csv('..\/input\/globalterrorismdb_0718dist.csv', encoding='ISO-8859-1')\nattribs = ['eventid', 'iyear', 'imonth', 'iday', 'extended', 'country_txt', 'region_txt', 'city', \n                        'latitude', 'longitude', 'specificity', 'summary', 'success', 'suicide', 'attacktype1_txt', \n                        'targtype1_txt', 'copr1', 'target1', 'natlty1_txt', 'gname', 'motive', 'nperps', \n                        'weaptype1_txt', 'nkill', 'nkillter', 'nwound', 'nwoundte', 'ishostkid', 'nhostkid']\nterr_data = terr.loc[:, attribs]\nterr_data.head()","8e347d0b":"terr_data['country_txt'] = terr_data['country_txt'].apply(lambda x: x.replace('United States', \n                                                                              'United States of America'))\nterr_data['weaptype1_txt'] = terr_data['weaptype1_txt'].apply(lambda x: x.split()[0] if 'Vehicle' in x.split() else x)","6b8b56c4":"url = 'https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data'\nworld_geo = f'{url}\/world-countries.json'\njson_data = gpd.read_file(f'{url}\/world-countries.json')","b68e28c9":"country_data = terr_data.groupby(by=['country_txt'], \n                                 as_index=False).count().sort_values(by='eventid', ascending=False).iloc[:, :2]\nnkill_data = terr_data.groupby(by=['country_txt'], \n                                 as_index=False).sum().sort_values(by='eventid', \n                                                                   ascending=False).loc[:, ['country_txt', 'nkill']]\ntemp_global = json_data.merge(country_data, left_on='name', right_on='country_txt', how='left').fillna(0)\nglobal_data = temp_global.merge(nkill_data, left_on='name', right_on='country_txt', how='left').fillna(0)\n\nm = folium.Map(\n    location=[0, 0], \n    zoom_start=1.50,\n    tiles='openstreetmap'\n)\n\nfolium.Choropleth(\n    geo_data=json_data,\n    name='Ataques Terroristas',\n    data=country_data,\n    columns=['country_txt', 'eventid'],\n    key_on='feature.properties.name',\n    fill_color='OrRd',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    nan_fill_color='white',\n    nan_fill_opacity=0.9,\n    legend_name='Terrorism Recorded 1970 - 2017',\n    popup_function='Teste'\n).add_to(m)\n\nFullscreen(\n    position='topright',\n    title='Expand me',\n    title_cancel='Exit me',\n    force_separate_button=True\n).add_to(m)\n\nfolium.GeoJson(\n    global_data,\n    style_function=style_function,\n    highlight_function=highlight_function,\n    tooltip=folium.GeoJsonTooltip(fields=['name', 'eventid', 'nkill'],\n                                  aliases=['Country:', 'Incidents:', 'Victims'],\n                                  labels=True,\n                                  sticky=True)\n).add_to(m)\n\nm.save('terrorism_incidents.html')\nm","8e152fac":"heat_data = terr_data.groupby(by=['latitude', 'longitude'], \n                                 as_index=False).count().sort_values(by='eventid', ascending=False).iloc[:, :3]\n\nm = folium.Map(\n    location=[33.312805, 44.361488], \n    zoom_start=2.5, \n    tiles='Stamen Toner'\n)\n\nHeatMap(\n    name='Mapa de Calor',\n    data=heat_data,\n    radius=10,\n    max_zoom=13\n).add_to(m)\n\nFullscreen(\n    position='topright',\n    title='Expand me',\n    title_cancel='Exit me',\n    force_separate_button=True\n).add_to(m)\n\nm.save('terrorism_density.html')\nm","6ea3516a":"year_list = []\nfor year in terr_data['iyear'].sort_values().unique():\n    data = terr_data.query('iyear == @year')\n    data = data.groupby(by=['latitude', 'longitude'], \n                        as_index=False).count().sort_values(by='eventid', ascending=False).iloc[:, :3]\n    year_list.append(data.values.tolist())\n\nm = folium.Map(\n    location=[0, 0], \n    zoom_start=2.0, \n    tiles='Stamen Toner'\n)\n\nHeatMapWithTime(\n    name='Terrorism Heatmap',\n    data=year_list,\n    radius=9,\n    index=list(terr_data['iyear'].sort_values().unique())\n).add_to(m)\n\nm","c48e381c":"month_index = [\n    'jan\/2017',\n    'feb\/2017',\n    'mar\/2017',\n    'apr\/2017',\n    'may\/2017',\n    'jun\/2017',\n    'jul\/2017',\n    'aug\/2017',\n    'sep\/2017',\n    'oct\/2017',\n    'nov\/2017',\n    'dec\/2017'\n]\n\nmonth_list = []\nfor month in terr_data.query('iyear==2017')['imonth'].sort_values().unique():\n    data = terr_data.query('imonth == @month')\n    data = data.groupby(by=['latitude', 'longitude'], \n                        as_index=False).sum().sort_values(by='imonth', \n                                                          ascending=True).loc[:, ['latitude', \n                                                                                   'longitude', \n                                                                                   'nkill']]\n    month_list.append(data.values.tolist())\n\nm = folium.Map(\n    location=[0, 0], \n    zoom_start=1.5, \n    tiles='Stamen Toner'\n)\n\nHeatMapWithTime(\n    name='Mapa de Calor',\n    data=month_list,\n    radius=4,\n    index=month_index\n).add_to(m)\n\nm","5c94f36b":"fig, ax = plt.subplots(figsize=(12, 6))\ncount_plot('region_txt', terr_data, ax=ax, colors='autumn')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nax.set_title('Distribution of Attacks per Region (1970-2017)', size=15)\nplt.show()","32496e06":"country_victims = terr_data.groupby(by='country_txt', as_index=False).sum().sort_values(by='nkill', \n                                                                      ascending=False).loc[:, ['country_txt', \n                                                                                               'nkill']]\ncountry_victims = country_victims.iloc[:10, :]\n\nterr_data_2017 = terr_data.query('iyear == 2017')\ncountry_victims_2017 = terr_data_2017.groupby(by='country_txt', as_index=False).sum().sort_values(by='nkill', \n                                                                      ascending=False).loc[:, ['country_txt', \n                                                                                               'nkill']]\ncountry_victims_2017 = country_victims_2017.iloc[:10, :]\ncountry_victims_2017['country_txt'][16] = 'Central African Rep.'\ncountry_victims_2017['country_txt'][22] = 'Dem. Rep. Congo'\n\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n\nsns.barplot(x='nkill', y='country_txt', data=country_victims, ci=None,\n                 palette='autumn', ax=axs[0])\nsns.barplot(x='nkill', y='country_txt', data=country_victims_2017, ci=None,\n                 palette='autumn', ax=axs[1])\n\nformat_spines(axs[0], right_border=False)\nformat_spines(axs[1], right_border=False)\naxs[0].set_title('Top 10 - Total Victims by Country (1970-2017)')\naxs[1].set_title('Top 10 - Total Victims by Country (2017)')\naxs[0].set_ylabel('')\naxs[1].set_ylabel('')\n\nfor p in axs[0].patches:\n    width = p.get_width()\n    axs[0].text(width-4000, p.get_y() + p.get_height() \/ 2. + 0.10, '{}'.format(int(width)), \n            ha=\"center\", color='white')\n\nfor p in axs[1].patches:\n    width = p.get_width()\n    axs[1].text(width-300, p.get_y() + p.get_height() \/ 2. + 0.10, '{}'.format(int(width)), \n            ha=\"center\", color='white')\n\nplt.show()","9cef894d":"country_analysis(country_name='Iraq', data=terr_data, palette='summer', \n                 colors_plot2=['crimson', 'green'], color_lineplot='crimson')","421667ab":"country_analysis(country_name='United States of America', data=terr_data, palette='plasma', \n                 colors_plot2=['crimson', 'navy'], color_lineplot='navy')","6fba9454":"country_analysis(country_name='Nigeria', data=terr_data, palette='summer', \n                 colors_plot2=['crimson', 'green'], color_lineplot='green')","81991123":"country_analysis(country_name='Colombia', data=terr_data, palette='hot', \n                 colors_plot2=['crimson', 'gold'], color_lineplot='crimson')","28e87275":"country_analysis(country_name='Egypt', data=terr_data, palette='copper', \n                 colors_plot2=['crimson', 'brown'], color_lineplot='brown')","0e8fd5c6":"terr_data['summary'][:10]","818a3234":"temp_corpus = terr_data['summary'].dropna()\ncorpus = temp_corpus.apply(lambda x: x.split(': ')[-1]).values\nprint(f'We have {len(corpus)} elements on the corpus\\n\\n')\nprint(f'Example 1: \\n{corpus[1]}\\n')\nprint(f'Example 2: \\n{corpus[-1]}')","d63c3791":"for c in corpus:\n    urls = re.findall('(http|ftp|https):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?', c)\n    if len(urls) == 0:\n        pass\n    else:\n        print(f'Description: {list(corpus).index(c)} - Links: {urls}')","ad90a43a":"# Example\ncorpus[6977]","119eac3b":"# Replacing sites and hiperlinks\ncorpus_wo_hiperlinks = []\nfor c in corpus:\n    c = re.sub(r'(http|ftp|https):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?', 'link', c)\n    corpus_wo_hiperlinks.append(c)\ncorpus_wo_hiperlinks[6977]","d62f2d23":"# Example of description with number\ncorpus_wo_hiperlinks[399]","db6f361c":"# Replacing numbers\ncorpus_wo_numbers = []\nfor c in corpus_wo_hiperlinks:\n    c = re.sub('\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'number', c)\n    corpus_wo_numbers.append(c)\ncorpus_wo_numbers[399]","10303bc1":"# Example with special characteres\ncorpus_wo_numbers[1113]","3c62e093":"# Replacing special characteres with whitespace\ncorpus_text = []\nfor c in corpus_wo_numbers:\n    c = re.sub(r'\\W', ' ', c)\n    corpus_text.append(c)\ncorpus_text[1113]","d4c465ca":"# Removing additional whitespaces\ncorpus_after_regex = []\nfor c in corpus_text:\n    c = re.sub(r'\\s+', ' ', c)\n    corpus_after_regex.append(c)\n    \ncorpus_after_regex[1113]","8596aa56":"cleaned_corpus = pd.Series(corpus_after_regex).apply(lambda x: x.lower())\ncleaned_corpus = list(cleaned_corpus.values)\ncleaned_corpus[990]","f48e77e4":"# Genereating wordcloud\ntext = ' '.join(cleaned_corpus)\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", collocations=False).generate(text)\n\nplt.figure(figsize=(15, 15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","1f69e971":"# Libraries","7fcfc004":"### Special Characteres","f1e15663":"## WordCloud","214d1064":"Good! I think we are done here with RegEx","7f5fcbf6":"Now we have a selection bar in the bottom of the map where we can select the terrorist records from a specific year between 1970 and 2017. It is important to cross this information with historical facts, wars and incidents. It's kind of interesting to see how the concentration of incidents starts at North America in the 70s and move to Europe and Middle East region as long as the time goes by.","2031d878":"As we have already seen in our first geographical plot, the highest concentration of incidentes recorded are from Middle East & North Africa. The region represents 27.8% of all records between 1970 and 2017. \n\nIn the next plot, we will make a comparison of this historical data with 2017 data, but this time looking at the top 10 countries if highest nuber of terrorist incidents.","4c5793fa":"I hope you really enjoy this storytelling. Please upvote this kernel to keep me motivated to do even more!","17944be1":"Good! Keep going.","ceab202a":"As we applied Regular Expressions (like this one on session 6.1.3), we generated some additional whitespaces. We can threat it with RegEx as well.","1bf3d4c9":"# Reading the Data","f7a3c339":"The next step we must on Natural Language Processing is putting all the tokens in lower case. We can do that with the method `apply` of Pandas DataFrame.","d52d013c":"Well, it seems that only one attack summary have hiperlinks on it. Let's print it just to confirm.","3109562d":"In this session, we will generate a WordCloud for all descriptions.","a65e1be2":"* This kernel is a continuation of the kernel [Global Terrorism - Data Understanding](https:\/\/www.kaggle.com\/thiagopanini\/global-terrorism-data-understanding), where an extremely important process of understanding the data was carried out in order to go deep into the context and make useful data transformations for further analysis.\n\nThis second approach intends to tell a story about Terrorism around the world taking the data provided as a basis. Here, we will apply an exploratory data analysis, look for patterns and explanations related to the context and present the conclusions in a dynamic and visual ways. If you like this kernel, **please upvote**! This always keep me motivated to do things even better! English is not my mother language... so sorry for any mistake!\n\nWe will use libs like **Folium**, **Seaborn**, **Matplotlib** and other usefull tools to try to see:","2c0a4a18":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Libraries<\/a><\/span><\/li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Functions<\/a><\/span><\/li><li><span><a href=\"#Data-Prep\" data-toc-modified-id=\"Data-Prep-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Data Prep<\/a><\/span><\/li><li><span><a href=\"#Terrorism-Around-the-World\" data-toc-modified-id=\"Terrorism-Around-the-World-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Terrorism Around the World<\/a><\/span><\/li><li><span><a href=\"#Countries-and-Terrorism\" data-toc-modified-id=\"Countries-and-Terrorism-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Countries and Terrorism<\/a><\/span><\/li><li><span><a href=\"#NLP-on-Incident-Summary\" data-toc-modified-id=\"NLP-on-Incident-Summary-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>NLP on Incident Summary<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Regular-Expressions\" data-toc-modified-id=\"Regular-Expressions-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>Regular Expressions<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Sites-and-Hiperlinks\" data-toc-modified-id=\"Sites-and-Hiperlinks-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;<\/span>Sites and Hiperlinks<\/a><\/span><\/li><li><span><a href=\"#Numbers\" data-toc-modified-id=\"Numbers-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;<\/span>Numbers<\/a><\/span><\/li><li><span><a href=\"#Special-Characteres\" data-toc-modified-id=\"Special-Characteres-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;<\/span>Special Characteres<\/a><\/span><\/li><li><span><a href=\"#Additional-Whitespaces\" data-toc-modified-id=\"Additional-Whitespaces-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;<\/span>Additional Whitespaces<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Lower-Case\" data-toc-modified-id=\"Lower-Case-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>Lower Case<\/a><\/span><\/li><li><span><a href=\"#WordCloud\" data-toc-modified-id=\"WordCloud-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>WordCloud<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#References\" data-toc-modified-id=\"References-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>References<\/a><\/span><\/li><\/ul><\/div>","4058c650":"# Countries and Terrorism","1b1f4680":"With this Heatmap, we can see places with greater concentration of terrorism incidents from 1970 to 2017. To get more insights, let's see the\"evolution\" of terrorism year by year.","dc6165a1":"Well, in this session our goal is to apply some Natural Language Processing techniques to take a look at the words as a tool for understanding the Terrorism around the World. First of all, let's see some elements from the column _summary_","753db88b":"### Numbers","41e5a498":"As we could see on some examples above, there are incidents descriptions with numbers. Here we will search for those text descriptions and replace the numbers with the token `number`.","fb790d1b":"For this task, we will iterate all over the corpus applying the method `findall` using a specific Regular Expression created for searching sites and hiperlinks. Let's see what we can tell about it.","62a5819f":"* A big picture of terrorism around the world and its evolution over the years;\n* Countries with most incidents recorded;\n* Countries with highest number of victims;\n* A dashboard for terrorism analysis in some countries;\n* Incidents that lasted more than 24h (extended = 1);\n* Major radical groups responsible for terrorist attacks (gname);\n* Attacks with the highest number of terrorists (nperps);\n* A WordCloud for attributes like summary corp1, target1 and motive;","bcebb16a":"The most recent data we have is from 2017. Let's plot a global heatmap to see incidents among the months of 2017. Using the selection bar in the bottom, we can see the concentration of terrorism from january to december of 2017.","e4d05a42":"### Sites and Hiperlinks","0575c671":"Before we get started, we need to ensure the charts will be plotted the way we expect. First, we have to set the name of United States country to same string that we have in the json file used as map (United States of America). Second, let's just change the large string describing the \"Vehicle\" in `weaptype1_txt` attribute.","e9727baa":"Now that we have already transformed the corpus on an array structure, let's apply some Regular Expressions to deal with non-desired elements. The analysis we will do in the following topics will cover:\n\n* Search for Sites and Hiperlinks\n* Search for Numbers\n* Search for Special Characteres\n* Search for Additional Whitespaces","6944c626":"Let's change the scenery and see the effects of terrorism in specific countries. First of all, let's take a look at the main countries affected by terrorism.","0a4cec20":"This is not the final version. There is much more to do:\n\n* Create a WordCloud for attributes like corp1, target1 and motive;\n* Look for more Exploratory Data Analysis like:\n    * Incidents that lasted more than 24h (extended = 1);\n    * Major radical groups responsible for terrorist attacks (gname);\n    * Attacks with the highest number of terrorists (nperps);","f0700dc0":"Again, as long as we are looking at incidents descriptions, we faced some special characteres that need to be replaced for further analysis. For this, let's apply another Regular Expresion to replace special characters with whitespace.","227b6892":"# NLP on Incident Summary","3074c257":"In previous versions, I separated the analysis into \"Data Preparation\" and \"Storytelling\" just to keep in mind that some transformations in data would be necessary to reach the goals. But, as long as the storytelling part took the center stage and grew on large scale, I decided to make the transformations on data only where applicable.\n\nIn other words, all the steps required for the analysis will be performed on their respective topic. For now, let's just read the data, filter attributes and go through visualizations!","15c1dabf":"## Lower Case","deaf869e":"# References","1a7f23dd":"# Terrorism Around the World","31728e1f":"https:\/\/nbviewer.jupyter.org\/gist\/jtbaker\/57a37a14b90feeab7c67a687c398142c?flush_cache=true\n\nhttps:\/\/github.com\/python-visualization\/folium\/issues\/904\n\nhttps:\/\/towardsdatascience.com\/data-101s-spatial-visualizations-and-analysis-in-python-with-folium-39730da2adf\n\nhttps:\/\/www.kaggle.com\/rachan\/how-to-folium-for-maps-heatmaps-time-analysis\n\nhttps:\/\/python-visualization.github.io\/folium\/plugins.html","da2a78ff":"Ok, our method worked. So we will replace the links with the token \"link\".","029d677d":"We are one step closer to the goal.","e8b161ac":"# Functions","6294c637":"If you want to see details of a full process of global terrorism data preparation, please go through the [Global Terrorism - Data Understanding](https:\/\/www.kaggle.com\/thiagopanini\/global-terrorism-data-understanding).","28e3016b":"We can see two points by now:\n\n* It is necessary to handle null data on this\n* Also, we have to eliminate the date information at the beginning of each instance","238bef4b":"## Regular Expressions","792c332e":"With the grap above we can see that Iraq and Afghanistan are the countries with most terrorism occurences in 2017 (and also in all period). Colombia, Peru and El Salvador appear in historica data but don't appear in 2017 data maybe because of past conflicts. Let's make a more specific analysis in some countries to see more details.\n\nNow I present you the dashboard for country-terrorism relationship analysis. We will see details from Iraq, United States, Nigeria, Colombia and Egypt.","5f79a267":"### Additional Whitespaces","b65542f7":"Well, here we can see clearly that Iraq is the country with the highest number of incidents recorded. The map also shows tooltips with the name of the country, number of incidents and total of victims recorded. Another thing that can be said looking at the map is that the Middle East and South Asia are the regions with the highes number of recorded attacks between 1970 and 2017."}}