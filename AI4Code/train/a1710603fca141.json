{"cell_type":{"0e8eca11":"code","c10bd49d":"code","351e0e43":"code","45699060":"code","2bff9ea9":"code","6fa4b256":"code","c581a979":"code","cdd6f919":"code","fa93d1b9":"code","76591bb5":"code","a92ac509":"code","4b5805c8":"code","e22869c5":"code","2a95e29c":"code","e5602d51":"code","34f9de2f":"code","2f5d91ef":"code","7c39f20f":"markdown","5abd6254":"markdown","321d5a0f":"markdown"},"source":{"0e8eca11":"import os\nimport glob\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nTEST_SIZE=0.1\nSEED=1\nBATCH_SIZE=64\n\ntf.random.set_seed(SEED)\n","c10bd49d":"labels_df = pd.read_csv('..\/input\/traffic-sign-dataset-classification\/labels.csv')\nprint(labels_df.sample(10))\n\n#Create a label map\nlabel_map = dict(labels_df.values)","351e0e43":"image_list = list(Path('..\/input\/traffic-sign-dataset-classification\/traffic_Data\/DATA').glob(r'**\/*.png'))\nlabels = list(map(lambda path: os.path.split(os.path.split(path)[0])[1], image_list))\n\n#Create dataframe with path of images and labels\nimage_series = pd.Series(image_list).astype(str)\nlabels_series = pd.Series(labels).astype(str)\nframe = {'image':image_series, 'label':labels_series}\nimage_df = pd.DataFrame(frame)\nimage_df.info()\nprint(image_df.sample(5))","45699060":"count_labels = image_df.groupby(['label']).size()\nplt.figure(figsize=(17,5))\nplt.ylabel('count images')\nsns.barplot(x=count_labels.index, y=count_labels, palette=\"rocket\")","2bff9ea9":"SPLIT_MINIMUM_COUNT = 10","6fa4b256":"def split_dataset(df, rate=SPLIT_MINIMUM_COUNT):\n  \"\"\"\n  Allocate a  dataset that has at least SPLIT_MINIMUM_COUNT_IMAGES of images\n  \n  split_df: dataframe for train\n  train1_df: dataframe for drop\n  \"\"\"\n\n  count_labels = df.groupby(['label']).size()\n  count_labels_df = count_labels.to_frame(name='count_images').reset_index()\n\n  drop_label_list = list(\n      count_labels_df['label'].\\\n      loc[count_labels_df['count_images']<SPLIT_MINIMUM_COUNT]\n  )\n\n  drop_df = df.copy()\n  split_df = df.copy()\n\n  for index, row in df.iterrows():\n    if str(row.label) in drop_label_list:\n      split_df = split_df.drop(index)\n    else:\n      drop_df = drop_df.drop(index)\n\n  return split_df, drop_df\n\ndef custom_train_test_split(df):\n    \"\"\"\n      Train test split where test_df has minimum 1 image in all labels\n    in random split. This need to work model.fit and model.evaluate\n    \"\"\"\n  \n    labels = df.label.unique()\n    test_df = pd.DataFrame()\n\n    for label in labels:\n      label_samples = df.loc[df.label==label]\n      test_df = test_df.append(label_samples.sample(len(label_samples)\/\/10+1,\n                               random_state=SEED))\n    \n    train_df = df.drop(list(test_df.index), axis=0)\n    test_df = test_df.sample(frac=1, random_state=SEED)\n    train_df = train_df.sample(frac=1, random_state=SEED)\n\n    return train_df, test_df\n","c581a979":"split_df, _ = split_dataset(image_df)\ntrain_df, test_df = custom_train_test_split(split_df)\ntrain, val = custom_train_test_split(train_df)\n","cdd6f919":"train_labels = train_df.groupby(['label']).size()\nNUM_CLASSES = len(train_labels)","fa93d1b9":"#plot images\nfig, axes = plt.subplots(2,4, figsize=(16, 7))\nfor idx, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(train_df.image.iloc[idx]))\n    ax.set_title(train_df.label.iloc[idx])\nplt.tight_layout()\nplt.show()","76591bb5":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    rotation_range = 10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    fill_mode='constant',\n    shear_range=0.1,\n    zoom_range=0.2,\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n)","a92ac509":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='image',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(128, 128),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED,\n)\n\nval_images = test_generator.flow_from_dataframe(\n    dataframe=val,\n    x_col='image',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(128, 128),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED,\n)\n\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='image',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(128, 128),\n    batch_size=BATCH_SIZE,\n)\n","4b5805c8":"#create model\ndef create_model(input_shape=(128,128,3)):\n  \"\"\"\n  load EfficientNet without last layer and \n  add Dense and ouput Dense with NUM_CLASSES units\n\n  \"\"\"\n  inputs = tf.keras.layers.Input(input_shape)\n\n  base_model = tf.keras.applications.EfficientNetB0(\n      include_top=False,\n      weights='imagenet',\n      pooling='avg'\n  )\n  base_model.trainable = False\n  \n  x = base_model(inputs)\n  x = tf.keras.layers.BatchNormalization()(x)\n  x = tf.keras.layers.Dense(512, activation='relu')(x)\n  #x = tf.keras.layers.Dropout(0.2)(x)\n  #x = tf.keras.layers.Dense(256, activation='relu')(x)\n  outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n\n  return tf.keras.models.Model(inputs, outputs)","e22869c5":"model = create_model()","2a95e29c":"model.compile(\n    optimizer='Adam',\n    loss='categorical_crossentropy',\n    metrics=['acc'],\n)","e5602d51":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    train_images,\n    epochs=40,\n    validation_data=val_images,\n    callbacks=[callback]\n)","34f9de2f":"plt.figure(figsize=(12,5))\nplt.plot(history.history['acc'], label='train_acc')\nplt.plot(history.history['val_acc'], label='val_acc')\nplt.title('Accuracy plot')\nplt.xlabel('epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","2f5d91ef":"score, accuracy = model.evaluate(test_images)\nprint(f'Test score: {round(score,4)}, Test accuracy: {round(accuracy,4)}')","7c39f20f":"Some labels contain very few image instances. If you apply random partitioning to training and validation, there is a chance that the training set will not reflect the entire general population. Let's split into training and validation only for the part where the number of image instances is higher than SPLIT_MINIMUM_COUNT","5abd6254":"These are my first steps in computer vision, any comments would be welcome","321d5a0f":"Parth 2. Train model"}}