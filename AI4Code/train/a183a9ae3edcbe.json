{"cell_type":{"e67a1150":"code","b9adaa94":"code","85a64a4c":"code","56ead644":"code","8a558626":"code","40baba03":"code","a6cfbf2c":"code","9be24381":"code","cb8b9763":"code","6914244e":"code","d58bfedb":"code","4b4d499f":"code","15cb2edf":"code","0b43924a":"code","a18b25f0":"code","1ad899fe":"code","3ab0da29":"code","91893c4e":"code","86db462b":"markdown","52074062":"markdown","7dd5eced":"markdown","43de423d":"markdown"},"source":{"e67a1150":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import CIFAR10 as tcifar10\nfrom torchvision import transforms,utils\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nfrom torch.utils.data.dataset import Subset\nimport tensorflow.image as timage\nimport sklearn.preprocessing as skp\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","b9adaa94":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","85a64a4c":"def display_examples(data_loader,img_size):\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(11,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i])\\\n                      .reshape(img_size,img_size,3))\n        break\ndef show_image(img):\n    npimg=img.numpy()\/2.+.5; tr=(1,2,0)\n    pl.figure(figsize=(10,2))\n    pl.imshow(np.transpose(npimg,tr))\n    pl.xticks([]); pl.show()\ndef show_examples(train_loader,classes,num_examples):\n    dataiter=iter(train_loader)\n    images,labels=dataiter.next()\n    show_image(utils.make_grid(images[0:num_examples]))\n    print('^'.join('%9s'%classes[labels[j]] \n                   for j in range(num_examples)),end='^')","56ead644":"def model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()\/num_examples*100\n@register_line_magic\ndef print_acc(n):\n    if int(n)==1:\n        data_loader=\\\n        [train_loader,valid_loader,test_loader]\n    if int(n)==2:\n        data_loader=\\\n        [train_loader2,valid_loader2,test_loader2]\n    print('Train accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[0])))\n    print('Valid accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[1])))\n    print('Test accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[2])))","8a558626":"img_size=32\nrandom_seed=1; batch_size=128\ntrain_ids=torch.arange(0,44000)\nvalid_ids=torch.arange(44000,50000)\ntr0=(.5,.5,.5); tr1=(.48,.48,.48)\ntrain_transform=transforms\\\n.Compose([transforms.ToTensor(),\n          transforms.Normalize(tr0,tr0)])\ntest_transform=transforms\\\n.Compose([transforms.ToTensor(),\n          transforms.Normalize(tr0,tr0)])\ntrain_valid=tcifar10(root='data',train=True,\n                     download=True,\n                     transform=train_transform)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tcifar10(root='data',train=False, \n              transform=test_transform)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\nvalid_loader=tdl(dataset=valid,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","40baba03":"classes=('plane','car','bird','cat','deer',\n         'dog','frog','horse','ship','truck')\nshow_examples(valid_loader,classes,7)","a6cfbf2c":"fpath='..\/input\/classification-of-handwritten-letters\/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\/255\nprint(x.mean(),x.std())\n#x=skp.MinMaxScaler((.05,.95))\\\n#.fit_transform(x.reshape(-1,img_size*img_size*3))\nx=x.reshape(-1,3,img_size,img_size)\n#print(x.mean(),x.std())\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]","9be24381":"random_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,shuffle=True,\n                  batch_size=batch_size2)\nvalid_loader2=tdl(dataset=valid2,shuffle=True,\n                  batch_size=batch_size2)\ntest_loader2=tdl(dataset=test2,shuffle=False,\n                 batch_size=batch_size2)","cb8b9763":"display_examples(valid_loader2,img_size)","6914244e":"def convrelu(x,y,k,s,p):\n    return tnn.Sequential(\n        tnn.Conv2d(x,y,kernel_size=k,\n                   stride=s,padding=p),\\\n        tnn.ReLU(inplace=True))\nclass NNinNN(tnn.Module):\n    def __init__(self,num_classes):\n        super(NNinNN,self).__init__()\n        self.num_classes=num_classes\n        self.classifier=tnn.Sequential(\n            convrelu(3,192,5,1,2),\n            convrelu(192,160,1,1,0),\n            convrelu(160,96,1,1,0),\n            tnn.MaxPool2d(kernel_size=3,\n                          stride=2,padding=1),\n            tnn.Dropout(.5),\n            convrelu(96,192,5,1,2),\n            convrelu(192,192,1,1,0),\n            convrelu(192,192,1,1,0),\n            tnn.AvgPool2d(kernel_size=3,\n                          stride=2,padding=1),\n            tnn.Dropout(.5),\n            convrelu(192,192,3,1,1),\n            convrelu(192,192,1,1,0),\n            convrelu(192,self.num_classes,1,1,0),\n            tnn.AvgPool2d(kernel_size=8,\n                          stride=1,padding=0))\n    def forward(self,x):\n        x=self.classifier(x)\n        logits=x.view(x.size(0),self.num_classes)\n        probs=torch.softmax(logits,dim=1)\n        return logits,probs","d58bfedb":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)\/\/batch_size,cost))\n        model.eval()\n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader),\n                   model_acc(model,valid_loader)))","4b4d499f":"torch.manual_seed(random_seed)\nnum_classes=10; learning_rate=.0001\nmodel=NNinNN(num_classes); model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","15cb2edf":"%train_run 200","0b43924a":"%print_acc 1","a18b25f0":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets.long())\n            optimizer2.zero_grad(); cost.backward()\n            optimizer2.step()\n            if not batch_ids%50:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)\/\/batch_size2,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader2),\n                   model_acc(model,valid_loader2)))","1ad899fe":"torch.manual_seed(random_seed)\nnum_classes=33; learning_rate=.0001\nmodel=NNinNN(num_classes)\nmodel.to(dev)\noptimizer2=torch.optim.Adam(model.parameters(),\n                            lr=learning_rate)","3ab0da29":"%train_run2 300","91893c4e":"%print_acc 2","86db462b":"## Data","52074062":"## NNinNN","7dd5eced":"Reading classics [Deep Learning Models](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/cnn\/nin-cifar10.ipynb)\n\n## Code Modules, Classes, & Functions\n\n[GoogleColaboratory Variant](https:\/\/colab.research.google.com\/drive\/1V9fDIPwPPi0gMkyDxOcMEu7-VHI1CjTm)","43de423d":"## Training"}}