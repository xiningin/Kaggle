{"cell_type":{"76f35ee2":"code","b4117f7b":"code","02411d89":"code","cdb810a9":"code","7f3f788a":"code","00f8f1a6":"code","47fb227e":"code","f94b7ac2":"code","4529a48a":"code","201b4861":"code","1904dfb4":"code","2749d5e4":"code","5df2beec":"code","e2511813":"code","5b63eb3e":"code","91da39bf":"code","a0acf5c9":"code","af909bb4":"code","fc748024":"code","ef9ce57d":"code","43c18bad":"code","4083bcde":"code","1037b863":"code","26c3bb34":"code","ae97a768":"code","255fa165":"code","14edc11e":"markdown","b319b8af":"markdown","5d34ed7d":"markdown","785203c4":"markdown","e3beb07b":"markdown","f0618397":"markdown","e47ad651":"markdown","16b33ea4":"markdown","a27b886b":"markdown","baf8b19f":"markdown","4285c7b2":"markdown","712d1eb8":"markdown","61dbd262":"markdown","f221e72d":"markdown","110edc7e":"markdown","d896ecfd":"markdown","e835da8c":"markdown","863d5f7f":"markdown","b90da33f":"markdown"},"source":{"76f35ee2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom re import sub\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n#import lifelines\n\nimport scipy\nimport scipy.stats\n\nfrom scipy.special import gammaln\nfrom scipy.special import psi\nfrom scipy.special import factorial\nfrom scipy.optimize import fmin_l_bfgs_b as optim\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","b4117f7b":"cov_mod = pd.read_csv('..\/input\/Coverage modifications per group.csv', delimiter=',')\npay15 = pd.read_csv('..\/input\/Payments 2015.csv', delimiter=',')\npay16 = pd.read_csv('..\/input\/Payments 2016.csv', delimiter=',')\npay17 = pd.read_csv('..\/input\/Payments 2017.csv', delimiter=',')\npay18 = pd.read_csv('..\/input\/Payments 2018.csv', delimiter=',')\ndiseases = pd.read_csv('..\/input\/Diseases per person.csv', delimiter=',')\n","02411d89":"# Arreglando los tipos de datos en cov_mod\ndeductible = []\ncoinsurance = []\npol_lim = []\nfor d,l,c in zip(cov_mod['Deductible'],cov_mod['Policy limit'],cov_mod['Coinsurance']):\n    deductible.append(float(sub(r'[^\\d.]', '', d)))\n    coinsurance.append(float(sub('%', '', c))\/100)\n    if pd.notna(l):\n        pol_lim.append(float(sub(r'[^\\d.]', '', l)))\n    elif pd.isna(l):\n        pol_lim.append(None)\n\ncov_mod['Deductible'] = deductible\ncov_mod['Coinsurance'] = coinsurance\ncov_mod['Policy limit'] = pol_lim","cdb810a9":"# Arreglando los tipos de datos en la siniestralidad de los \u00faltimos 4 a\u00f1os\npagos15 = []\nfor p in pay15['Pago']:\n    pagos15.append(float(sub(r'[^\\d.]', '', p)))\npagos16 = []\nfor p in pay16['Pago']:\n    pagos16.append(float(sub(r'[^\\d.]', '', p)))\npagos17 = []\nfor p in pay17['Pago']:\n    pagos17.append(float(sub(r'[^\\d.]', '', p)))\npagos18 = []\nfor p in pay18['Pago']:\n    pagos18.append(float(sub(r'[^\\d.]', '', p)))\n\npay15['Pago'] = pagos15\npay16['Pago'] = pagos16\npay17['Pago'] = pagos17\npay18['Pago'] = pagos18","7f3f788a":"cov_mod","00f8f1a6":"def montos(pagos,coverturas):\n    xi = []\n    di = []\n    ui = []\n    for g,p in zip(pagos['Grupo'],pagos['Pago']):\n        i = (coverturas['Group']==g).idxmax()\n        c = coverturas['Coinsurance'].iloc[i]\n        d = coverturas['Deductible'].iloc[i]\n        l = coverturas['Policy limit'].iloc[i]\n        if(p==l):\n            ui.append(p)\n            xi.append(None)\n        else:\n            xi.append((p\/(1-c))+d)\n            ui.append(None)\n        di.append(d)\n    \n    pagos['xi'] = xi\n    pagos['ui'] = ui\n    pagos['di'] = di\n    return pagos","47fb227e":"# Obteniendo los montos de los siniestros para cada a\u00f1o:\n\npay15 = montos(pay15,cov_mod)\npay16 = montos(pay16,cov_mod)\npay17 = montos(pay17,cov_mod)\npay18 = montos(pay18,cov_mod)\n\npay15.head()","f94b7ac2":"# Trayendo a valor presente con tasas de inflaci\u00f3n:\ninf = [0.0213,0.0336,0.0677,0.0483,0.036]\npay15['xi'] = pay15.xi*(1+inf[0])*(1+inf[1])*(1+inf[2])*(1+inf[3])*(1+inf[4])\npay16['xi'] = pay16.xi*(1+inf[1])*(1+inf[2])*(1+inf[3])*(1+inf[4])\npay17['xi'] = pay17.xi*(1+inf[2])*(1+inf[3])*(1+inf[4])\npay18['xi'] = pay18.xi*(1+inf[3])*(1+inf[4])","4529a48a":"def KaplanMeier(pagos):\n    si =[]\n    pagos = pagos.sort_values(\"xi\")\n    for x in pagos.xi:\n        i = 0\n        for xj in pagos.xi:\n            if(x==xj):\n                i += 1\n        si.append(i)\n    pagos['si'] = si\n    #print(sum(pagos['si']>1))\n    pagos_ui = pagos[pd.notna(pagos.ui)]\n    pagos_xi = pagos[pd.notna(pagos.xi)].drop_duplicates(\"xi\")\n    pagos = pd.concat([pagos_xi,pagos_ui])\n    \n    # Calculando el conjunto en riesgo\n    ri = []\n    for y in pagos.xi:\n        r = sum((pagos.xi >= y)*pagos.si) + sum(pagos.ui >= y) - sum(pagos.di >= y)\n        ri.append(r)\n    pagos['ri'] = ri\n    \n    # Haciendo la funci\u00f3n de supervivencia\n    pagos['indx'] = range(0,len(pagos))\n    pagos2 = pagos.set_index('indx')\n    pagos2.index.name = None\n    pagos = pagos2\n    \n    p = 1\n    S = {(0,pagos.xi[0]):p}\n    for i in range(1,sum(pd.notna(pagos.xi))):\n        p = p * ((pagos.ri[i-1]-pagos.si[i-1])\/pagos.ri[i-1])\n        S[(pagos.xi[i-1],pagos.xi[i])] = p\n    xmax = max(pagos_xi.xi)\n    umax = max(pagos_ui.ui)\n    w = max(xmax,umax)\n    S[(pagos.xi[i],w)] = p\n    \n    return S","201b4861":"def plotKM(S,titulo=\"\"):\n    x = []\n    for xj in list(S.keys()):\n        x.append(xj[0])\n        x.append(xj[1]-.05)\n    y = []\n    for yj in list(S.values()):\n        y.append(yj)\n        y.append(yj)\n    plt.plot(x,y)\n    plt.title(titulo)\n    plt.show()\n    \ndef esperanzaKM(S):\n    suma = 0\n    for xj, yj in list(S.items()):\n        suma += (xj[1]-xj[0])*yj\n    return suma\n    ","1904dfb4":"# Gr\u00e1ficas de supervivencia Kaplan-Meier\nS_15 = KaplanMeier(pay15)\nplotKM(S_15,\"Funci\u00f3n de supervivencia Kaplan Meier Pagos-2015\")\n\nS_16 = KaplanMeier(pay16)\nplotKM(S_16,\"Funci\u00f3n de supervivencia Kaplan Meier Pagos-2016\")\n\nS_17 = KaplanMeier(pay17)\nplotKM(S_17,\"Funci\u00f3n de supervivencia Kaplan Meier Pagos-2017\")\n\nS_18 = KaplanMeier(pay18)\nplotKM(S_18,\"Funci\u00f3n de supervivencia Kaplan Meier Pagos-2018\")\n","2749d5e4":"# Esperanzas de la severidad 2015, 2016, 2017, 2018\nsev15 = esperanzaKM(S_15)\nsev16 = esperanzaKM(S_16)\nsev17 = esperanzaKM(S_17)\nsev18 = esperanzaKM(S_18)\nprint(\"Esperanza de la severidad 2015 = {:.2f}\".format(sev15))\nprint(\"Esperanza de la severidad 2016 = {:.2f}\".format(sev16))\nprint(\"Esperanza de la severidad 2017 = {:.2f}\".format(sev17))\nprint(\"Esperanza de la severidad 2018 = {:.2f}\".format(sev18))","5df2beec":"# Tomando un promedio de la severidad:\nsev_prom = (sev15+sev16+sev17+sev18)\/4\nsev_prom","e2511813":"diseases.head()","5b63eb3e":"plt.hist(diseases['Number of claims'])\nplt.title(\"Histograma de n\u00famero de reclamaciones\")","91da39bf":"diseases['Number of claims'].describe()","a0acf5c9":"# Haciendo un fit para la distribucion de las reclamaciones\nfreq = np.array(diseases['Number of claims'])","af909bb4":"def fit_nbinom(X, initial_params=None):\n    infinitesimal = np.finfo(np.float).eps\n\n    def log_likelihood(params, *args):\n        r, p = params\n        X = args[0]\n        N = X.size\n\n        #EMV basado en la f\u00f3rmula de Wikipedia:\n        # http:\/\/en.wikipedia.org\/wiki\/Negative_binomial_distribution#Maximum_likelihood_estimation\n        result = np.sum(gammaln(X + r)) \\\n            - np.sum(np.log(factorial(X))) \\\n            - N*(gammaln(r)) \\\n            + N*r*np.log(p) \\\n            + np.sum(X*np.log(1-(p if p < 1 else 1-infinitesimal)))\n\n        return -result\n\n    def log_likelihood_deriv(params, *args):\n        r, p = params\n        X = args[0]\n        N = X.size\n\n        pderiv = (N*r)\/p - np.sum(X)\/(1-(p if p < 1 else 1-infinitesimal))\n        rderiv = np.sum(psi(X + r)) \\\n            - N*psi(r) \\\n            + N*np.log(p)\n\n        return np.array([-rderiv, -pderiv])\n\n    if initial_params is None:\n        #reasonable initial values (from fitdistr function in R)\n        m = np.mean(X)\n        v = np.var(X)\n        size = (m**2)\/(v-m) if v > m else 10\n\n        #convert mu\/size parameterization to prob\/size\n        p0 = size \/ ((size+m) if size+m != 0 else 1)\n        r0 = size\n        initial_params = np.array([r0, p0])\n\n    bounds = [(infinitesimal, None), (infinitesimal, 1)]\n    optimres = optim(log_likelihood,\n                     x0=initial_params,\n                     #fprime=log_likelihood_deriv,\n                     args=(X,),\n                     approx_grad=1,\n                     bounds=bounds)\n\n    params = optimres[0]\n    return {'size': params[0], 'prob': params[1]}\n","fc748024":"# Utilizando la funci\u00f3n anterior para estimar por m\u00e1xima verosimilitud los par\u00e1metros de la distribuci\u00f3n\nparam = fit_nbinom(freq)\nr = param['size']\np = param['prob']\nparam","ef9ce57d":"# Probando los par\u00e1metros\n#fig, ax = plt.subplots(1, 2)\nbins = np.linspace(0, 10, 15)\nbn = scipy.stats.nbinom.rvs(r,p,size=1000)\nplt.subplot(1,2,1)\nplt.hist(bn,bins,color=\"skyblue\")\nplt.title(\"Estimaci\u00f3n\")\nplt.subplot(1,2,2)\nplt.hist(freq,bins,color =\"red\")\nplt.title(\"Datos\")","43c18bad":"# La esperanza de la frecuencia ser\u00eda:\nesp_freq = r*p\n# Como tenemos 6610 empleados, con dependientes econ\u00f3micos que se distribuyen Poisson(1.2), vamos a tener que\nEN = esp_freq*6610*(1+1.2)\n\n# Por lo tanto la prima (E[S]) de estos asegurados ser\u00eda de:\nES = EN*sev_prom\nprint(\"La prima nos da ${:.2f}\".format(ES))","4083bcde":"from IPython.display import display\nCNSF={'A\u00f1o':[2015,2016,2017,2018],\n    'Inflacion':[0.02,0.03,0.07,0.05],\n    'Prima Emitida':[5373112471, 6204393260, 5198319344,0],\n    'Siniestros Pagados':[1118812328, 1168284188, 1083611405,0],\n    'Numero Asegurados': [43711576, 70465702, 55260012, 54859790],\n    'Numero Siniestros': [254127, 283994, 244987, 210732],\n    'Suma Asegurada':[43356000000000, 92587000000000, 89157510000000, 89335825020000]}\ndf = pd.DataFrame(CNSF)\ndf","1037b863":"df[\"Prima Actual\"]=[df[\"Prima Emitida\"][0]*(1+df[\"Inflacion\"][0])*(1+df[\"Inflacion\"][1])*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]), \n                    df[\"Prima Emitida\"][1]*(1+df[\"Inflacion\"][1])*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]),\n                    df[\"Prima Emitida\"][2]*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]),\n                    df[\"Prima Emitida\"][3]*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3])*(1.002)]\ndf[\"Siniestros Actual\"]=[df[\"Siniestros Pagados\"][0]*(1+df[\"Inflacion\"][0])*(1+df[\"Inflacion\"][1])*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]), \n                    df[\"Siniestros Pagados\"][1]*(1+df[\"Inflacion\"][1])*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]),\n                    df[\"Siniestros Pagados\"][2]*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]),\n                    df[\"Siniestros Pagados\"][3]*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3])*(1.002)]\ndf[\"Suma Asegurada Actual\"]=[df[\"Suma Asegurada\"][0]*(1+df[\"Inflacion\"][0])*(1+df[\"Inflacion\"][1])*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]), \n                    df[\"Suma Asegurada\"][1]*(1+df[\"Inflacion\"][1])*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]),\n                    df[\"Suma Asegurada\"][2]*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3]),\n                    df[\"Suma Asegurada\"][3]*(1+df[\"Inflacion\"][2])*(1+df[\"Inflacion\"][3])*(1.002)]\ndf[\"Prima Asegurado\"]=[df[\"Prima Actual\"][0]\/df[\"Numero Asegurados\"][0],\n                    df[\"Prima Actual\"][1]\/df[\"Numero Asegurados\"][1],\n                    df[\"Prima Actual\"][2]\/df[\"Numero Asegurados\"][2],\n                    df[\"Prima Actual\"][3]\/df[\"Numero Asegurados\"][3]]\ndf[\"Siniestros Asegurado\"]=[df[\"Siniestros Actual\"][0]\/df[\"Numero Asegurados\"][0],\n                    df[\"Siniestros Actual\"][1]\/df[\"Numero Asegurados\"][1],\n                    df[\"Siniestros Actual\"][2]\/df[\"Numero Asegurados\"][2],\n                    df[\"Siniestros Actual\"][3]\/df[\"Numero Asegurados\"][3]]\n#df.drop(labels=\"Prima Promedio\",axis=1)\ndf[\"Suma Asegurada por Asegurado\"]=[df[\"Suma Asegurada Actual\"][0]\/df[\"Numero Asegurados\"][0],\n                    df[\"Suma Asegurada Actual\"][1]\/df[\"Numero Asegurados\"][1],\n                    df[\"Suma Asegurada Actual\"][2]\/df[\"Numero Asegurados\"][2],\n                    df[\"Suma Asegurada Actual\"][3]\/df[\"Numero Asegurados\"][3]]\n\nPrima_Prom_Aseg=sum(df[\"Prima Asegurado\"])\/4\nprint(\"${:.2f}\".format(Prima_Prom_Aseg))","26c3bb34":"Siniestros_Prom_Aseg=sum(df[\"Siniestros Asegurado\"])\/4\nprint(\"{:.0f}\".format(Siniestros_Prom_Aseg))","ae97a768":"PRIMA_SEG=6000*Prima_Prom_Aseg\nprint(\"${:.2f}\".format(PRIMA_SEG))\n","255fa165":"SA_Prom_Aseg=sum(df[\"Suma Asegurada por Asegurado\"])\/4\nprint(\"${:.2f}\".format(SA_Prom_Aseg))","14edc11e":"E[X] = 80,449.35 \n\nA continuacion calculamos E[N] (frecuencia) para as\u00ed obtener E[S].","b319b8af":"## Estimaci\u00f3n de la frecuencia","5d34ed7d":"Despues de obtener esperanza de la severidad para cada a\u00f1o, todo actualizado con inflacion, obtenemos la esperanza de severidad E[X]","785203c4":"# Health Insurance","e3beb07b":"Despu\u00e9s de obtener la funci\u00f3n de supervivencia por a\u00f1o, graficamos cada una. Esto nos facilita integrar las funciones y as\u00ed obtener el valor esperado de la severidad del 2015 al 2018.","f0618397":"## Estimaci\u00f3n de la severidad","e47ad651":"## Proposals","16b33ea4":"Para agregar valor, proponemos un seguro de accidentes personales enfocado a la incapacidad para los grupos mas vulnerables (1 y 2). De esta manera apoyaremos a los empleados. A continuacion describimos la cobertura y sus implicaciones en precio. ","a27b886b":"La cual asegura a 6000 personas por un SA por empleado de\n","baf8b19f":"Ahora vamos aproximar nuestra distribuci\u00f3n de las reclamaciones con una conocida para su facil manejo.","4285c7b2":"Al tener datos emp\u00edricos con informaci\u00f3n incompleta, decidimos utilizar el estimador de Kaplan-Meier. Este estimador nos permite \u00a8tumbar\u00a8 la cola de manera exponencial para as\u00ed obtener momentos y evitar que omega se vaya a infinito.\n\nA continuaci\u00f3n definimos el procedimiento Kaplan-Meier, calculamos el conjunto en riesgo y obtenemos la funci\u00f3n de Superviviencia.","712d1eb8":"Estamos interesados en conocer el monto del siniestro, por lo mismo, reincorporamos el deducible y el coaseguro al monto pagado por la aseguradora. As\u00ed, recuperamos el deducible, coaseguro y monto pagado, el cual esta topado a la suma asegurada seg\u00fan la categor\u00f1ia a la que pertenece el empleado.","61dbd262":"Tenemos los pagos realizados durante los \u00faltimos 4 a\u00f1os (2015,2016,2017,2018) por una aseguradora, para un grupo de 6610 trabajadores. La empresa clasifica a los trabajadores en 5 categor\u00edas, cada una con diferentes condiciones. A continuci\u00f3n arreglamos los datos proporcionados para evitar problemas al realizar el c\u00f3digo.","f221e72d":"Ahora podemos decir que el n\u00famero de reclamaciones se distribuye Binomial Negativa con par\u00e1metros (0.5665, 0.5904).\n\nHacemos un histograma con la distribuci\u00f3n de la severidad y de la distribuci\u00f3n estimada para hacer visible la similitud.","110edc7e":"### Por Luis Fernando Acosta , Nicolas Mora, Fernanda Valerio, y Alejandro Rivera","d896ecfd":"Los datos de la tabla anterior estan en pesos corrientes. Por lo mismo, actualizamos las cifras con inflaci\u00f3n para que los datos sean comparables. Los datos de inflaci\u00f3n general utilizados fueron los reportados por el Banco de M\u00e9xico.","e835da8c":"Mostramos un histograma con el n\u00famero de reclamaciones para checar poder darnos una idea en c\u00f3mo se \ndistribuye la frecuencia. \nAdem\u00e1s, se anexa un summary donde nos muestra los datos relevantes de la distribuci\u00f3n.","863d5f7f":"Para los grupos I y II tenemos en total 6000 personas, entonces la prima ser\u00eda por","b90da33f":"As\u00ed, obenemos la Esperanaz de la Frecuencia E[N]\n\nContinuamos calculando la Esperanza de la p\u00e9rdida agregada E[S] como E[X]E[N], obteniendo una prima de $391,335,218.53"}}