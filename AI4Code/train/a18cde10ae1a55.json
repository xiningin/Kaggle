{"cell_type":{"1cf23a2c":"code","4e13c3cd":"code","35fe3d3f":"code","7c06fa52":"code","84a0f2a7":"code","0cb179b1":"code","4837e05c":"code","2abe5db0":"code","a01bbe33":"code","1360dbc6":"code","ed908e30":"code","f6cfc3f3":"code","177d92e6":"code","b45d9ab9":"code","fa1b6075":"code","b4698324":"code","ab62ad6d":"code","7a1e3819":"code","dd773060":"code","9500142d":"code","e2977fad":"markdown","bc1cbd57":"markdown","9a0bdd79":"markdown","4f952ce3":"markdown","9188bef7":"markdown","6886413a":"markdown","cbc589e4":"markdown","16a2decc":"markdown","a63444f7":"markdown","74ab9e4a":"markdown","3ca7132c":"markdown","3deb4e65":"markdown","8bc0ad30":"markdown","444c8d79":"markdown","33b003c0":"markdown","55223c1a":"markdown","15b8f4c1":"markdown"},"source":{"1cf23a2c":"#data work\nimport pandas as pd\nimport numpy as np\n\n# visuals\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go","4e13c3cd":"# Load 2017 data\ndata_2017 = pd.read_csv(\"..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv\",encoding='ISO-8859-1', low_memory=False)\n\n# Load 2018 data\ndata_2018 = pd.read_csv(\"..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\", low_memory=False)\n\n# Load 2019 data\ndata_2019 = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\", low_memory=False)\n\n# Load 2020 data\ndata_2020 = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\", low_memory=False)","35fe3d3f":"#function to consolidate countries across all years as they're in different formats\ndef consolidate_country_2017_to_2020(x):\n    if ((x == 'United States') | (x== 'United States of America')):\n        return 'USA'\n    elif ((x == 'United Kingdom of Great Britain and Northern Ireland') | (x == 'United Kingdom')):\n        return 'UK'\n    elif ((x == \"People 's Republic of China\")):\n        return 'China' \n    elif ((x == 'Iran, Islamic Republic of...')):\n        return 'Iran' \n    else: \n        return x    ","7c06fa52":"#function to consolidate salaries across all years as they're in different formats  \ndef consolidate_salary_2017(x):\n    try:\n        x = int(x.replace(',', ''))\n        if x < 30000:\n            return '0-30k'\n        if x < 50000:\n            return '30-50k'\n        elif x <100000:\n            return '50-100k'\n        elif x < 150000:\n            return '100-150k'\n        elif x < 200000:\n            return '150-200k'\n        elif x < 250000:\n            return '200-250k'\n        elif x < 500000:\n            return '250-500k'\n        else: \n            return '$500k+'\n    except:\n        return 'No compensation disclosed'\n\n    \ndef consolidate_salary_2018(x):\n    if ((x == '0-10,000') | (x== '10-20,000') | (x == '20-30,000')):\n        return '0-30k'\n    elif ((x == '30-40,000') | (x == '40-50,000')):\n        return '30-50k'\n    elif ((x == '50-60,000') | (x == '60-70,000') | (x == '70-80,000') | (x == '80-90,000') | (x == '90-100,000')):\n        return '50-100k' \n    elif ((x == '100-125,000') | (x == '125-150,000')):\n        return '100-150k'\n    elif ((x == '150-200,000')):\n        return '150-200k'\n    elif ((x == '200-250,000')):\n        return '200-250k'\n    elif ((x == '250-300,000') | (x == '300-400,000') | (x == '400-500,000')):\n        return '250-500k'\n    elif ((x == '500,000+')):\n        return '$500k+'  \n    else: \n        return 'No compensation disclosed'    \n\ndef consolidate_salary_2019_2020(x):\n    if ((x == '$0-999') | (x== '1,000-1,999') | (x == '2,000-2,999') | (x == '3,000-3,999') | (x == '4,000-4,999')  \n        | (x == '5,000-7,499') | (x == '7,500-9,999')| (x == '10,000-14,999')  | (x == '15,000-19,999') | (x == '20,000-24,999') | (x == '25,000-29,999')):\n        return '0-30k'\n    elif ((x == '30,000-39,999') | (x == '40,000-49,999')):\n        return '30-50k'\n    elif ((x == '50,000-59,999  ') | (x == '60,000-69,999') | (x == '70,000-79,999') | (x == '80,000-89,999') | (x == '90,000-99,999')):\n        return '50-100k' \n    elif ((x == '100,000-124,999') | (x == '125,000-149,999')):\n        return '100-150k'\n    elif ((x == '150,000-199,999')):\n        return '150-200k'\n    elif ((x == '200,000-249,999')):\n        return '200-250k'\n    elif ((x == '250,000-299,999') | (x == '300,000-500,000')):\n        return '250-500k'\n    elif ((x == '> $500,000')):\n        return '$500k+'\n    else: \n        return 'No compensation disclosed'\n    \n","84a0f2a7":"#function to consolidate sex across all years as they're in different formats \ndef consolidate_sex_2017_to_2020(x):\n    if ((x == 'Prefer not to say ') | (x== 'Prefer to self-describe') | (x== 'Nonbinary') | (x== 'A different identity') | (x== 'Prefer not to say') | (x== 'Non-binary, genderqueer, or gender non-conforming')):\n        return 'Other'\n    elif ((x == \"Man\")):\n        return 'Male' \n    elif ((x == 'Woman')):\n        return 'Female' \n    else: \n        return x   ","0cb179b1":"#function to consolidate job titles across all years as they're in different formats\ndef consolidate_job_titles_2017_to_2020(x):\n    if ((x == 'Data Scientist') | (x == 'Machine Learning Engineer') | (x == 'Predictive Modeler')):\n        return 'Data science\/ML engineers'\n    \n    elif ((x == 'Software Engineer') | (x == 'Software Developer\/Software Engineer') | (x == 'Programmer') | (x == 'Developer Advocate') | (x == 'Computer Scientist')):\n        return 'Software developers'\n    \n    elif ((x == 'Data Analyst') | (x == 'Business Analyst') | (x == 'Data Miner') | (x == 'Marketing Analyst') | (x == 'Data Journalist')):\n        return 'Data\/business analysts'\n    \n    elif ((x == 'DBA\/Database Engineer') | (x == 'Data Engineer') | (x == 'Data Miner') | (x == 'Marketing Analyst') | (x == 'Data Journalist')):\n        return 'Data engineers'\n    \n    elif ((x == 'Student') | (x== 'Researcher')):\n        return 'Students'\n    else: \n        return 'Other job fields'    ","4837e05c":"#function to consolidate respondents' age across all years as they're in different formats\ndef consolidate_age_2017(x):\n    if x < 25:\n        return 'Under 25'\n    elif x < 35:\n        return '25-35'  \n    elif x < 45:\n        return '35-45'\n    elif x < 60:\n        return '45-60'\n    elif x < 70:\n        return '60-69'\n    else:\n        return '70+'\n    \n\ndef consolidate_age_2018_to_2020(x):\n    if ((x == '18-21') | (x == '22-24')):\n        return 'Under 25'\n    elif ((x == '25-29') | (x == '30-34')):\n        return '25-35'\n    elif ((x == '35-39') | (x == '40-44')):\n        return '35-45'\n    elif ((x == '45-49') | (x == '50-54') | (x == '55-59')):\n        return '45-60'\n    else: \n        return x    ","2abe5db0":"#function to consolidate visual modules across all years as they're in different formats\ndef consolidate_vizmodules_2018_to_2020(x):\n    if (x == 'MatplotlibSeaborn'):\n        return 'Matplotlib & Seaborn'\n    elif ((x == 'Plotly \/ Plotly Express') | (x == 'Plotly')):\n        return 'Plotly Alone'\n    elif ((x == 'MatplotlibPlotly \/ Plotly Express') | (x == 'MatplotlibPlotly')):\n        return 'Matplotlib & Plotly'\n    elif ((x == 'MatplotlibSeabornPlotly \/ Plotly ExpressBokeh') | (x == 'MatplotlibPlotly \/ Plotly ExpressBokehSeaborn') | (x == 'MatplotlibPlotlyBokehSeaborn')):\n        return 'All 4 modules'\n    elif (x == 'Bokeh'):\n        return 'Bokeh Alone'\n    elif ((x == 'MatplotlibBokeh')):\n        return 'Matplotlib & Bokeh'\n    elif ((x == 'Seaborn')):\n        return 'Seaborn Alone'\n    elif (x == 'Matplotlib'):\n        return 'Matplotlib Alone' \n    elif ((x == 'Shiny')):\n        return 'Shiny Alone'\n    elif ((x == 'Ggplot \/ ggplot2') | (x == 'ggplot2')):\n        return 'Ggplot Alone' \n    elif ((x == 'Ggplot \/ ggplot2Shiny') | (x == 'ggplot2Shiny')):\n        return 'Both Modules'\n    else: \n        return x    ","a01bbe33":"#function to consolidate ML modules across all years as they're in different formats\ndef consolidate_mlmodules_2018_to_2020(x):\n    if ((x == 'Scikit-learn') | (x == 'Scikit-Learn') | (x == 'Scikit-LearnrandomForest') | (x == 'Scikit-learnRandomForest') | (x == 'Scikit-learnCaret') | (x == 'randomForest') | (x == 'Caret')\n       | (x == 'Scikit-learnRandomForestCaret') | (x == 'CaretrandomForest') | (x == 'RandomForest') | (x == 'Scikit-LearnCaret') | (x == 'RandomForestCaret') | (x == 'Scikit-LearnCaretrandomForest')):\n        return 'Classic ML modules'\n    \n    elif ((x == 'TensorFlow') | (x == 'TensorFlowKeras') | (x == 'PyTorch') | (x == 'TensorFlowKerasPyTorch')\n         | (x == 'Keras') | (x == 'TensorFlowPyTorch') | (x == 'KerasPyTorch') | (x == 'TensorFlowKerasPyTorchFast.ai') | (x == 'TensorFlowKerasPyTorchFastai')\n         | (x == 'PyTorchFast.ai') | (x == 'TensorFlowKerasFastai') | (x == 'Fast.ai') | (x == 'TensorFlowKerasFast.ai') | (x == 'KerasPyTorchFast.ai')\n         | (x == 'TensorFlowPyTorchFast.ai') | (x == 'Fastai') | (x == 'PyTorchFastai') | (x == 'KerasFast.ai') | (x == 'TensorFlowPyTorchFastai')\n         | (x == 'TensorFlowFast.ai ') | (x == 'KerasPyTorchFastai') | (x == 'TensorFlowFastai') | (x == 'KerasFastai') | (x == 'TensorFlowFast.ai')\n         | (x == 'Xgboost') | (x == 'XgboostLightGBM') | (x == 'Xgboostlightgbm') | (x == 'Xgboostlightgbmcatboost') | (x == 'XgboostLightGBMCatBoost') | (x == 'LightGBM')\n         | (x == 'Xgboostcatboost') | (x == 'XgboostCatBoost') | (x == 'lightgbm') | (x == 'CatBoost') | (x == 'catboost') | (x == 'LightGBMCatBoost') | (x == 'lightgbmcatboost')\n         | (x == 'TensorFlowKerasXgboost') | (x == 'TensorFlowKerasPyTorchXgboost') | (x == 'TensorFlowKerasXgboostLightGBM') | (x == 'TensorFlowXgboost') | (x == 'KerasXgboost') | (x == 'TensorFlowKerasPyTorchXgboostLightGBM') | (x == 'TensorFlowKerasXgboostlightgbm')\n         | (x == 'PyTorchXgboost') | (x == 'TensorFlowKerasXgboostlightgbmcatboost') | (x == 'KerasXgboostLightGBM') | (x == 'KerasPyTorchXgboost') | (x == 'KerasPyTorchXgboostLightGBM') | (x == 'PyTorchLightGBM') | (x == 'TensorFlowKerasPyTorchFast.aiXgboostLightGBM ')\n         \n         | (x == 'TensorFlowKerasPyTorchXgboostLightGBMCatBoost') | (x == 'PyTorchXgboostLightGBM') | (x == 'TensorFlowKerasXgboostLightGBMCatBoost') | (x == 'TensorFlowKerasPyTorchXgboostlightgbm') | (x == 'TensorFlowPyTorchXgboost') | (x == 'TensorFlowKerasPyTorchXgboostlightgbmcatboost')):\n        return 'Deep Learning & Boosting modules'\n    \n    else: \n        return x","1360dbc6":"# Merge all survey data from all years into one dataframe and unify responses as much as possible\nconsolidated_data =  pd.DataFrame()\nyear_2017 =  pd.DataFrame()\nyear_2018 =  pd.DataFrame()\nyear_2019 =  pd.DataFrame()\nyear_2020 =  pd.DataFrame()\n\n#'17\nyear_2017['Salary'] = data_2017.CompensationAmount.apply(lambda x: consolidate_salary_2017(x))\nyear_2017['Country'] = data_2017.Country.apply(lambda x: consolidate_country_2017_to_2020(x))\nyear_2017['Age'] = data_2017.Age.drop(0).apply(lambda x: consolidate_age_2017(x))\nyear_2017['Job_field'] = data_2017.CurrentJobTitleSelect.drop(0).apply(lambda x: consolidate_job_titles_2017_to_2020(x))\nyear_2017['Sex'] = data_2017.GenderSelect.drop(0).apply(lambda x: consolidate_sex_2017_to_2020(x))\nyear_2017['Year'] = 2017\n\n#'18\nyear_2018['Salary'] = data_2018.Q9.apply(lambda x: consolidate_salary_2018(x))\nyear_2018['Country'] = data_2018.Q3.drop(0).apply(lambda x: consolidate_country_2017_to_2020(x))\nyear_2018['Age'] = data_2018.Q2.drop(0).replace({'70-79' : '70+', '80+' : '70+'})\nyear_2018['Age'] = year_2018.Age.apply(lambda x: consolidate_age_2018_to_2020(x))\nyear_2018['Job_field'] = data_2018.Q6.drop(0).apply(lambda x: consolidate_job_titles_2017_to_2020(x))\nyear_2018['Sex'] = data_2018.Q1.drop(0).apply(lambda x: consolidate_sex_2017_to_2020(x))\nyear_2018['Visual_modules'] = (data_2018['Q21_Part_1'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_2'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_3'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_4'].fillna('').drop(0).str.strip(' ') \n                                  + data_2018['Q21_Part_5'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_6'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_7'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_8'].fillna('').drop(0).str.strip(' ') \n                                  + data_2018['Q21_Part_9'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_10'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_11'].fillna('').drop(0).str.strip(' ') + data_2018['Q21_Part_12'].fillna('').drop(0).str.strip(' ') \n                                  + data_2018['Q21_Part_9'].fillna('').drop(0).str.strip(' '))\nyear_2018['Visual_modules'] = year_2018.Visual_modules.apply(lambda x: consolidate_vizmodules_2018_to_2020(x))\nyear_2018['ML_modules'] = (data_2018['Q19_Part_1'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_2'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_3'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_4'].fillna('').drop(0).str.strip(' ')\n                                 + data_2018['Q19_Part_5'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_6'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_7'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_8'].fillna('').drop(0).str.strip(' ')\n                                 + data_2018['Q19_Part_9'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_10'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_11'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_12'].fillna('').drop(0).str.strip(' ')\n                                 + data_2018['Q19_Part_13'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_14'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_15'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_16'].fillna('').drop(0).str.strip(' ')\n                                 + data_2018['Q19_Part_17'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_18'].fillna('').drop(0).str.strip(' ') + data_2018['Q19_Part_19'].fillna('').drop(0).str.strip(' '))\nyear_2018['ML_modules'] = year_2018.ML_modules.apply(lambda x: consolidate_mlmodules_2018_to_2020(x))\nyear_2018['Year'] = 2018 \n\n#'19\nyear_2019['Salary'] = data_2019.Q10.apply(lambda x: consolidate_salary_2019_2020(x))\nyear_2019['Country'] = data_2019.Q3.drop(0).apply(lambda x: consolidate_country_2017_to_2020(x))\nyear_2019['Age'] = data_2019.Q1.drop(0)\nyear_2019['Age'] = year_2019.Age.apply(lambda x: consolidate_age_2018_to_2020(x))\nyear_2019['Job_field'] = data_2019.Q5.drop(0).apply(lambda x: consolidate_job_titles_2017_to_2020(x))\nyear_2019['Sex'] = data_2019.Q2.drop(0).apply(lambda x: consolidate_sex_2017_to_2020(x))\nyear_2019['Visual_modules'] = (data_2019['Q20_Part_1'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_2'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_3'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_4'].fillna('').drop(0).str.strip(' ') \n                                  + data_2019['Q20_Part_5'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_6'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_7'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_8'].fillna('').drop(0).str.strip(' ') \n                                  + data_2019['Q20_Part_9'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_10'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_11'].fillna('').drop(0).str.strip(' ') + data_2019['Q20_Part_12'].fillna('').drop(0).str.strip(' '))\nyear_2019['Visual_modules'] = year_2019.Visual_modules.apply(lambda x: consolidate_vizmodules_2018_to_2020(x))\nyear_2019['ML_modules'] = (data_2019['Q28_Part_1'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_2'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_3'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_4'].fillna('').drop(0).str.strip(' ')\n                                 + data_2019['Q28_Part_5'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_6'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_7'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_8'].fillna('').drop(0).str.strip(' ')\n                                 + data_2019['Q28_Part_9'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_10'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_11'].fillna('').drop(0).str.strip(' ') + data_2019['Q28_Part_12'].fillna('').drop(0).str.strip(' '))\nyear_2019['ML_modules'] = year_2019.ML_modules.apply(lambda x: consolidate_mlmodules_2018_to_2020(x))\nyear_2019['Year'] = 2019 \n\n#'20 \nyear_2020['Salary'] = data_2020.Q24.apply(lambda x: consolidate_salary_2019_2020(x))\nyear_2020['Country'] = data_2020.Q3.drop(0).apply(lambda x: consolidate_country_2017_to_2020(x))\nyear_2020['Age'] = data_2020.Q1.drop(0)\nyear_2020['Age'] = year_2020.Age.apply(lambda x: consolidate_age_2018_to_2020(x))\nyear_2020['Job_field'] = data_2020.Q5.drop(0).apply(lambda x: consolidate_job_titles_2017_to_2020(x))\nyear_2020['Sex'] = data_2020.Q2.drop(0).apply(lambda x: consolidate_sex_2017_to_2020(x))\nyear_2020['Visual_modules'] = (data_2020['Q14_Part_1'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_2'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_3'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_4'].fillna('').drop(0).str.strip(' ')\n                              + data_2020['Q14_Part_5'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_6'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_7'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_8'].fillna('').drop(0).str.strip(' ')\n                              + data_2020['Q14_Part_9'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_10'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_Part_11'].fillna('').drop(0).str.strip(' ') + data_2020['Q14_OTHER'].fillna('').drop(0).str.strip(' '))\nyear_2020['Visual_modules'] = year_2020.Visual_modules.apply(lambda x: consolidate_vizmodules_2018_to_2020(x))\nyear_2020['ML_modules'] = (data_2020['Q16_Part_1'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_2'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_3'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_4'].fillna('').drop(0).str.strip(' ')\n                                 + data_2020['Q16_Part_5'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_6'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_7'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_8'].fillna('').drop(0).str.strip(' ') \n                                 + data_2020['Q16_Part_9'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_10'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_11'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_12'].fillna('').drop(0).str.strip(' ') \n                                 + data_2020['Q16_Part_13'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_14'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_Part_15'].fillna('').drop(0).str.strip(' ') + data_2020['Q16_OTHER'].fillna('').drop(0).str.strip(' '))\nyear_2020['ML_modules'] = year_2020.ML_modules.apply(lambda x: consolidate_mlmodules_2018_to_2020(x))\nyear_2020['Year'] = 2020\n\n\n#consolidating the dataframe\nconsolidated_data = year_2017\nconsolidated_data = consolidated_data.append(year_2018)\nconsolidated_data = consolidated_data.append(year_2019)\nconsolidated_data = consolidated_data.append(year_2020)\n\nconsolidated_data = consolidated_data.reset_index(drop=True)","ed908e30":"#making subplots for top 10 countries on total number of respondents\n\nsub_2017 = year_2017['Country'].value_counts().sort_values(ascending = False).head(10).reset_index().round(1)\nsub_2018 = year_2018['Country'].value_counts().sort_values(ascending = False).head(10).reset_index().round(1)\nsub_2019 = year_2019['Country'].value_counts().sort_values(ascending = False).head(10).reset_index().round(1)\nsub_2020 = year_2020['Country'].value_counts().sort_values(ascending = False).head(10).reset_index().round(1)\n\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=(\"2017\", \"2018\", \"2019\", \"2020\"))\n\nfig.add_trace(go.Bar(x=sub_2017['index'], y=sub_2017['Country']),\n              row=1, col=1)\n              \nfig.add_trace(go.Bar(x=sub_2018['index'], y=sub_2018['Country']),\n              row=1, col=2)\n\nfig.add_trace(go.Bar(x=sub_2019['index'], y=sub_2019['Country']),\n              row=2, col=1)\n\nfig.add_trace(go.Bar(x=sub_2020['index'], y=sub_2020['Country']),\n              row=2, col=2)\n\nfig.update_layout(\n                  title_text=\"Top 10 countries 2017-20 (total number of respondents)\", title_x=0.5)\n\nfig.update_layout(showlegend=False)\nfig.show()","f6cfc3f3":"#making a dataframe for animation \nanimate_countries = consolidated_data.groupby(['Year', 'Country']).size().reset_index()\nanimate_countries['Percentage'] = consolidated_data.groupby(['Year', 'Country']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_countries.columns = ['Year', 'Country', 'Counts', 'Percentage']\nanimate_countries = animate_countries.loc[(animate_countries['Country'] == 'USA') | (animate_countries['Country'] == 'India')]\n\n#plotting animated bars for USA vs India change over the years\nfig = px.bar(\n        animate_countries, x=\"Country\", y = 'Percentage', color=\"Country\",\n        animation_frame=\"Year\", range_y=[0,50], text=animate_countries['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)))\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text='India vs USA (2017-2020)', title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1.2, opacity=1)\nfig.update_layout(showlegend=False)\n\nfig.show()","177d92e6":"#making a dataframe for animation \nanimate_countries = consolidated_data.groupby(['Year', 'Country']).size().reset_index()\nanimate_countries['Percentage'] = consolidated_data.groupby(['Year', 'Country']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_countries.columns = ['Year', 'Country', 'Counts', 'Percentage']\nanimate_countries = animate_countries.loc[(animate_countries['Country'] == 'Germany') | (animate_countries['Country'] == 'Brazil') | (animate_countries['Country'] == 'Russia') | (animate_countries['Country'] == 'UK') | (animate_countries['Country'] == 'China')]\nanimate_countries = animate_countries.sort_values(by=['Percentage'], ascending = False)\n\n#plotting animated bars for other countries change over the years\nfig = px.bar(\n        animate_countries, x=\"Country\", y = 'Percentage', color=\"Country\",\n        animation_frame=\"Year\", range_y=[0,10], text=animate_countries['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), \n    category_orders={'Year': [2017, 2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text='Rise  Brazil & China (2017-2020)', title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(61, 57, 55)', marker_line_width=1, opacity=1)\nfig.update_layout(showlegend=False)\nfig.show()","b45d9ab9":"#making a dataframe for animation \nconsolidated_data_0 = consolidated_data[consolidated_data.Salary != 'No compensation disclosed']\nanimate_salaries = consolidated_data_0.groupby(['Year', 'Salary']).size().reset_index()\nanimate_salaries['Percentage'] = consolidated_data_0.groupby(['Year', 'Salary']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_salaries.columns = ['Year', 'Salary', 'Counts', 'Percentage']\nanimate_salaries = animate_salaries.sort_values(by=['Percentage'], ascending = False)\n\n\n#plotting animated bars for salary change over years\nfig = px.bar(\n        animate_salaries, x=\"Salary\", y = 'Percentage', color=\"Salary\", \n        animation_frame=\"Year\", range_y=[0,100], text=animate_salaries['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), \n    category_orders={'Year': [2017, 2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text=\"Respondents' salaries change (2017-2020)\", title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\nfig.update_layout(showlegend=False)\n\nfig.show()","fa1b6075":"#making a dataframe for animation \nanimate_sex = consolidated_data.groupby(['Year', 'Sex']).size().reset_index()\nanimate_sex['Percentage'] = consolidated_data.groupby(['Year', 'Sex']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_sex.columns = ['Year', 'Sex', 'Counts', 'Percentage']\nanimate_sex = animate_sex.sort_values(by=['Percentage'], ascending = False)\n\n\n#plotting animated bars for sex change over years\nfig = px.bar(\n        animate_sex, x=\"Sex\", y = 'Percentage', color=\"Sex\", \n        animation_frame=\"Year\", range_y=[0,100], text=animate_sex['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), category_orders={'Year': [2017, 2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text=\"Respondents' sex (2017-2020)\", title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\nfig.update_layout(showlegend=False)\n\nfig.show()","b4698324":"#making a dataframe for animation \nanimate_job_field = consolidated_data.groupby(['Year', 'Job_field']).size().reset_index()\nanimate_job_field['Percentage'] = consolidated_data.groupby(['Year', 'Job_field']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_job_field.columns = ['Year', 'Job_field', 'Counts', 'Percentage']\nanimate_job_field = animate_job_field.sort_values(by=['Percentage'], ascending = False)\n\n\n#plotting animated bars for salary change over years\nfig = px.bar(\n        animate_job_field, x=\"Job_field\", y = 'Percentage', color=\"Job_field\", \n        animation_frame=\"Year\", range_y=[0,70], text=animate_job_field['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), category_orders={'Year': [2017, 2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text='Job field change (2017-2020)', title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\nfig.update_layout(showlegend=False)\n\nfig.show()","ab62ad6d":"#making a dataframe for animation \nanimate_age = consolidated_data.groupby(['Year', 'Age']).size().reset_index()\nanimate_age['Percentage'] = consolidated_data.groupby(['Year', 'Age']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_age.columns = ['Year', 'Age', 'Counts', 'Percentage']\nanimate_age = animate_age.sort_values(by=['Percentage'], ascending = False)\n\n\n#plotting animated bars for age change over years\nfig = px.bar(\n        animate_age, x=\"Age\", y = 'Percentage', color=\"Age\", \n        animation_frame=\"Year\", range_y=[0,50], text=animate_age['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), category_orders={'Year': [2017, 2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text=\"Respondents' age change (2017-2020)\", title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\nfig.update_layout(showlegend=False)\n\nfig.show()","7a1e3819":"#making a dataframe for animation \nexclude_2017 = consolidated_data[consolidated_data.Visual_modules != '']\nanimate_visuals = exclude_2017.groupby(['Year', 'Visual_modules']).size().reset_index()\nanimate_visuals['Percentage'] = exclude_2017.groupby(['Year', 'Visual_modules']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_visuals.columns = ['Year', 'Visual_modules', 'Counts', 'Percentage']\nanimate_visuals = animate_visuals.loc[(animate_visuals['Visual_modules'] == 'Matplotlib Alone') | (animate_visuals['Visual_modules'] == 'Seaborn Alone') \n                  | (animate_visuals['Visual_modules'] == 'Plotly Alone') | (animate_visuals['Visual_modules'] == 'Bokeh Alone') | (animate_visuals['Visual_modules'] == 'Matplotlib & Bokeh')\n                  | (animate_visuals['Visual_modules'] == 'Matplotlib & Seaborn') | (animate_visuals['Visual_modules'] == 'Matplotlib & Plotly') | (animate_visuals['Visual_modules'] == 'All 4 modules')]\nanimate_visuals = animate_visuals.sort_values(by=['Percentage'], ascending = False)\n\n#plotting animated bars for visual modules change over years\nfig = px.bar(\n        animate_visuals, x=\"Visual_modules\", y = 'Percentage', color=\"Visual_modules\", \n        animation_frame=\"Year\", range_y=[0,25], text=animate_visuals['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), \n    category_orders={'Year': [2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text='Most popular Python visualisation modules use (2018-2020)', title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\n\nfig.update_layout(showlegend=False)\n\nfig.show()","dd773060":"#making a dataframe for animation \nexclude_2017 = consolidated_data[consolidated_data.Visual_modules != '']\nanimate_visuals = exclude_2017.groupby(['Year', 'Visual_modules']).size().reset_index()\nanimate_visuals['Percentage'] = exclude_2017.groupby(['Year', 'Visual_modules']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_visuals.columns = ['Year', 'Visual_modules', 'Counts', 'Percentage']\nanimate_visuals = animate_visuals.loc[(animate_visuals['Visual_modules'] == 'Ggplot Alone') | (animate_visuals['Visual_modules'] == 'Shiny Alone') | (animate_visuals['Visual_modules'] == 'Both Modules')]\nanimate_visuals = animate_visuals.sort_values(by=['Percentage'], ascending = False)\n\n#plotting animated bars for visual modules change over years\nfig = px.bar(\n        animate_visuals, x=\"Visual_modules\", y = 'Percentage', color=\"Visual_modules\", \n        animation_frame=\"Year\", range_y=[0,10], text=animate_visuals['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), \n    category_orders={'Year': [2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text='R visualisation modules use (2018-2020)', title_x=0.5)\nfig.update_yaxes(title=\"Portion of Respondents (%)\")\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\n\nfig.update_layout(showlegend=False)\n\nfig.show()","9500142d":"#making a dataframe for animation \nexclude_2017 = consolidated_data[consolidated_data.ML_modules != '']\nanimate_mlmods = exclude_2017.groupby(['Year', 'ML_modules']).size().reset_index()\nanimate_mlmods['Percentage'] = exclude_2017.groupby(['Year', 'ML_modules']).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values.round(2)\nanimate_mlmods.columns = ['Year', 'ML_modules', 'Counts', 'Percentage']\nanimate_mlmods = animate_mlmods.sort_values(by=['Percentage'], ascending = False)\nanimate_mlmods = animate_mlmods.loc[(animate_mlmods['ML_modules'] == 'Classic ML modules') | (animate_mlmods['ML_modules'] == 'Deep Learning & Boosting modules')]\n\n#plotting animated bars for ML modules change over years\nfig = px.bar(\n        animate_mlmods, x=\"ML_modules\", y = 'Percentage', color=\"ML_modules\", \n        animation_frame=\"Year\", range_y=[0,20], text=animate_mlmods['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)), \n    category_orders={'Year': [2018, 2019, 2020]})\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2200\nfig.update_layout(title_text='ML frameworks change over time (2018-2020)', title_x=0.5)\nfig.update_yaxes(title='Portion of Respondents (%)')\nfig.update_xaxes(title='')\nfig.update_traces(marker_line_color='rgb(31, 27, 25)', marker_line_width=1, opacity=1)\n\nfig.update_layout(showlegend=False)\n\nfig.show()","e2977fad":"![](https:\/\/d2f99xq7vri1nk.cloudfront.net\/DinoSequentialSmaller.gif)","bc1cbd57":"All we can say is that Kaggle is definitely getting younger and younger... No country for old men here...\n\n\n<a id=\"section-six\"><\/a>\n### Visualisation modules over time\n\n#### Python: Matplotlib vs Seaborn, Plotly & Bokeh","9a0bdd79":"Plotting the animated graphs isn't super difficult, but the Kaggle Survey data is quite changeling as it mostly contains categorical data that has different formats across all years. So some data wrangling and consolidation need to be done here.\u00a0","4f952ce3":"Now let's see how Brazil and China slightly took over other countries in the last 4 years","9188bef7":"## Kaggle surveys and the animated graphs (Plotly)\n\nData visuals do not have to be always static! The animated graphs with Plotly are amazing tools that are relatively easy to implement and bring data to life. \n\nIn this notebook, I want to use a couple of basic animated graphs in order to explore what trends are in the Data Science Kaggle surveys from 2017 to 2020. Let's try to animate the following:\n\n* [Countries - India vs USA and others](#section-one)\n\n* [Respondents' salaries change over time](#section-two)\n\n* [Respondents' sex change over time](#section-three)\n\n* [Respondents' job field change over time](#section-four) \n\n* [Respondents' age change over time](#section-five) \n\n* [Visualisation modules over time](#section-six) \n\n* [ML modules\/frameworks over time](#section-seven)\n\n* [Conclusion](#section-eight)\n\nLet's first import the required python modules and the datasets. ","6886413a":"<a id=\"section-one\"><\/a>\n### Countries - India vs USA and others \n\nHow the portion of respondents from different countries has changed during the years? Let's first plot the static bar charts to see it","cbc589e4":"As seen the classic ML modules still dominating, but the use of deep learning & boosting models rising closer to 2020 and probably will continue doing so.\u00a0\n\n<a id=\"section-eight\"><\/a>\n### Conclusion\n\nSo as it's seen, the animated plots are quite easy to implement and they can sometimes be quite helpful. Specifically, in this notebook, graphs have shown that:\n\n\n* [India took over the USA in the last 2 years](#section-one)\n\n* [Reported salaries of respondents became lower and mostly are in the range of USD 0-30k](#section-two)\n\n* [Kaggle is still dominated by males, but there is \"A New Hope\" in 2020](#section-three)\n\n* [Actually, only around 20% of Kaggle survey respondents work in the direct DS\/ML field, but there is a surge in the learning field](#section-four) \n\n* [Kaggle is becoming younger and younger. That's probably good](#section-five) \n\n* [Matplotlib and Seaborn along with Classic ML modules are still 'go-to' modules](#section-six) \n\n\nMore info on the animated plots for Python can be found [here](https:\/\/plotly.com\/python\/animations\/) and [here](https:\/\/plotly.com\/r\/animations\/) for R\n","16a2decc":"As seen in 2017 the largest number of respondents were reporting their salary in the range of USD 50-100k (27 percent). However, with time the range of $0-30k started reporting by the majority of respondents. \n\nAt least this can probably be because of the fact that respondents are actually more honest or potentially more respondents with lower salaries took part in the survey (junior positions, people from regions with lower cost of living etc)","a63444f7":"Well, there wasn't much change in the respondents' sex, and Kaggle is still dominated by males to large extent. However, there was a surge in the portion of female respondents in 2020 and hopefully, this trend is going to remain in the future.\u00a0\n\n<a id=\"section-four\"><\/a>\n### Respondents' job field change over time\n\nLet's see how respondents' job titles were changing across the years.","74ab9e4a":"As seen the US was dominating the place until 2019 and then India started ruling the game. So instead of looking into these boring subplots, let's animate them. Just press \"Play\" button below","3ca7132c":"<a id=\"section-three\"><\/a>\n### Respondents' sex change over time\n\nLet's see how respondents' sex was changing over the years.","3deb4e65":"As seen there was an increase in the number of students since 2017 and that is likely because there was no specific question on students in the 2017 survey. Also, it is interesting that direct DS\/ML job titles been only within approx. 20 percent of respondents while there is much more people studying or in other job fields like software dev. \n\n<a id=\"section-five\"><\/a>\n### Respondents' age change over time\n\nLet's see how respondents' age was changing across the years:","8bc0ad30":"In 2018 Matplotlib alone was a dominating visualisation module, but then a combination with Seaborn became a number 1 choice in 2020. ","444c8d79":"<a id=\"section-two\"><\/a>\n### Respondents' salaries change over time\n\nGood idea to see how reported by the survey respondents' salaries changed from 2017 to 2020. Again just press the play button to see it in action","33b003c0":"#### R: Ggplot vs Shiny","55223c1a":"So the most dominating visualisation modules are Seaborn with Matplotlib and Ggplot for Python and R respectively. Plotly isn't getting much of attention, but hopefully that will change at some time.\n\n<a id=\"section-seven\"><\/a>\n### ML modules\/frameworks over time\n\nI decided to generalize and compare the use of classic ML modules with deep learning and boosting modeling ones. The comparison are the combinations of modules as follows:\n\n- Classic ML = Scikit-learn (Python) + Caret (R)\n- Deep Learning = TensorFlow + Keras + Pytorch + Fast.ai (Python)\n- Boosting models = Catboost + Lightgbm + Xgboost","15b8f4c1":"As seen in the USA Kagglers dominated the Survey in 2017, and then India took the lead in 2019 and 2020. The number of Chinese respondents increased dramatically in 2018 and then went back in 2019 & 2020, while Brazil steadily was taking the 4th place."}}