{"cell_type":{"a9d58784":"code","0807f6ea":"code","33e25313":"code","05bbd432":"code","ea112295":"code","fce2fc2d":"code","ff5142e3":"code","d499e574":"code","e72be5dd":"code","c70f3a74":"code","fad34b49":"code","03bc012a":"code","2ee02b77":"code","42efea51":"code","d068f51e":"code","d67ca6d0":"code","9961a6fa":"code","06542f01":"code","f460be70":"code","6cac7c02":"code","8a7cb312":"code","c90a86eb":"code","494682cc":"code","14e81399":"code","c83ebc1d":"code","4394b709":"code","a3c6d857":"code","d0121822":"code","797b6396":"code","88ca6b46":"code","1161869c":"code","00969b63":"code","2aa2fcef":"code","59297dd1":"code","437acfd9":"code","3df8d9bf":"code","c96e7a76":"code","367b52d1":"code","f3cee7a1":"code","520a0b11":"code","b7779bd5":"code","9929777a":"code","ea3ae35f":"code","fa85a229":"code","8875f2dc":"code","77e2e6d2":"code","11cd02de":"code","d9f17a56":"code","aff0258a":"code","274581fc":"code","399722bc":"code","a94b3e1b":"code","9e9a1674":"code","8472dbc4":"code","5ecf0f6b":"code","9751132f":"code","f82e6f36":"code","181bc6ac":"code","f00016f1":"code","9b3ab179":"code","3f9cc53e":"markdown","8c1ecdba":"markdown","17805942":"markdown","abe670b7":"markdown","6636648a":"markdown","781d77fa":"markdown","5803def8":"markdown","94ff6bf3":"markdown","6a9e72c5":"markdown","c3464ce8":"markdown","56213583":"markdown","e67c27af":"markdown","5dc6ac57":"markdown","84016708":"markdown","9b1b839a":"markdown","d6a9ffe2":"markdown","0b594a77":"markdown","49eb86e4":"markdown","db194f6b":"markdown","5984f2d9":"markdown","8622b697":"markdown","e81c08ab":"markdown","b38f2ee8":"markdown","a2f4d88e":"markdown","d9b741a5":"markdown","6940183d":"markdown","40c5a50e":"markdown","7af302a8":"markdown","25df9f9f":"markdown","bfd11f2f":"markdown","29c86f94":"markdown","2813ea8e":"markdown","ccabad66":"markdown","273a71aa":"markdown","2bf3f62c":"markdown","5c0ddb00":"markdown","321d5cab":"markdown"},"source":{"a9d58784":"# Random Movie Picture function.\nimport requests\nimport bs4\nimport re\n\nfrom IPython.display import Image, HTML, display\n\ndef get_movie_image(row):\n    \"\"\"\n    Get Movie Image\n    \n    Description\n    -----------\n    The dataset already provides us with the poster url, but I thought it would be fun to extend this idea and\n    get images from the movie gallery itself.\n    \n    Parameters\n    ----------\n    row: One row from the TMDB movie dataset. Needs an IMDB movie id to fetch an image correctly.\n    \n    \"\"\"\n    assert len(row) == 1, \"Select one row from the dataset.\"\n    \n    title, release_date, revenue, ids = (\n        \"<center><h3>Title: \" + row.title.values[0] + \"<\/h3><\/center>\",\n        \"<center><h3>Release Date: \" + row.release_date.values[0] + \"<\/h3><\/center>\",\n        \"<center><h3>Revenue: \" + '${:,}'.format(row.revenue.values[0]) + \"<\/h3><\/center>\",\n        row.imdb_id.values[0]\n    )\n    res = requests.get(\"https:\/\/www.imdb.com\/title\/%s\/mediaviewer\" % (str(ids)))\n    display(HTML(title)), display(HTML(revenue)), display(Image(re.findall(\"https:\/\/m.media.amazon.com\/\\w+\/.+?\\.jpg\", str(res.content))[0]))","0807f6ea":"# Data\nimport numpy as np\nimport pandas as pd\n\n# Plotting\nfrom matplotlib import pyplot as plt\n%matplotlib inline","33e25313":"# Load the data.\ntrain, test = pd.read_csv(\"..\/input\/train.csv\"), pd.read_csv(\"..\/input\/test.csv\")","05bbd432":"train.head(3)","ea112295":"train.columns.values","fce2fc2d":"get_movie_image(train.sample(1, random_state=24))","ff5142e3":"get_movie_image(train.sample(1, random_state=11233))","d499e574":"fig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\naxes.vlines(ymin=0, ymax=2500, x=train.revenue.mean() \/ 1000000)\naxes.hist(train.revenue \/ 1000000, bins=25)\naxes.set(title=\"Distribution of Revenue\")\naxes.set(xlabel=\"Amount (Millions)\")\nplt.show()","e72be5dd":"# Scaled mean by millions.\ntrain.revenue.mean() \/ 1000000","c70f3a74":"fig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\naxes.vlines(ymin=0, ymax=2500, x=np.log1p(train.revenue.mean()))\naxes.hist(np.log1p(train.revenue), bins=25)\naxes.set(title=\"Distribution of Revenue\")\naxes.set(xlabel=\"Amount (Log)\")\nplt.show()","fad34b49":"train.sort_values(\"revenue\", ascending=True).head(5)[[\"title\", \"revenue\", \"budget\", \"popularity\", \"release_date\", \"runtime\"]]","03bc012a":"train.sort_values(\"revenue\", ascending=False).head(5)[[\"title\", \"revenue\", \"budget\", \"popularity\", \"release_date\", \"runtime\"]]","2ee02b77":"get_movie_image(train.sample(1, random_state=9087))","42efea51":"fig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\naxes.vlines(ymin=0, ymax=2500, x=train.popularity.mean())\naxes.hist(train.popularity, bins=25)\naxes.set(title=\"Movie Popularity\")\naxes.set(xlabel=\"Popularity\")\nplt.show()","d068f51e":"fig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\naxes.vlines(ymin=0, ymax=2500, x=np.log(train.popularity.mean()))\naxes.hist(np.log1p(train.popularity), bins=25)\naxes.set(title=\"Movie Popularity\")\naxes.set(xlabel=\"Popularity\")\nplt.show()","d67ca6d0":"train.popularity.describe()","9961a6fa":"get_movie_image(train.sample(1, random_state=71515))","06542f01":"fig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\naxes.vlines(ymin=0, ymax=2500, x=train.budget.mean() \/ 1000000)\naxes.hist(train.budget \/ 1000000, bins=25)\naxes.set(title=\"Movie Budget\")\naxes.set(xlabel=\"Budget (Millions)\")\nplt.show()","f460be70":"train.sort_values(\"budget\", ascending=True).head(5)[[\"title\", \"revenue\", \"budget\", \"popularity\", \"release_date\", \"runtime\", \"status\"]]","6cac7c02":"train.sort_values(\"budget\", ascending=False).head(5)[[\"title\", \"revenue\", \"budget\", \"popularity\", \"release_date\", \"runtime\", \"status\"]]","8a7cb312":"fig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\nmovie_profit = (train.revenue - train.budget) \/ 1000000\navg_profit = (train.revenue.mean() - train.budget.mean()) \/ 1000000\n\naxes.vlines(ymin=0, ymax=2500, x=avg_profit)\naxes.hist(movie_profit[movie_profit > 0], color=\"blue\", bins = 20)\naxes.hist(movie_profit[movie_profit <= 0], color = \"red\", bins = 20)\naxes.set(title=\"Movies Make an Average Profit of ${:,.0f}\".format(avg_profit))\naxes.set(xlabel=\"Budget (Millions)\")\n\nplt.show()\n\n# Add profit to our training data.\ntrain[\"profit\"] = (train.revenue - train.budget)","c90a86eb":"print(\"Movies that made a profit: {}\".format(sum((movie_profit >= 0))))\n\nprint(\"Movies that tanked: {}\".format(sum((movie_profit < 0))))","494682cc":"get_movie_image(train.sample(1, random_state=1960))","14e81399":"def parse_date(x):\n    x = tuple(str(x).split(\"\/\"))\n    if len(x) == 3:\n        month, day, year = tuple(x)\n    else:\n        return None\n    \n    # Ths works assuming there aren't any release dates lower than 1920.\n    if int(year) > 19:\n        year = \"19\" + str(year)\n    else:\n        year = \"20\" + str(year)\n    \n    return pd.Timestamp(year=int(year), month=int(month), day=int(day))","c83ebc1d":"# Parse the release date.\ntrain[\"release_date_parsed\"] = train.release_date.apply(parse_date)","4394b709":"# Our groupby variable.\nby_year = train.loc[train.status == \"Released\", \"release_date_parsed\"].apply(lambda x: pd.Period(x, \"Y\"))\n\n# Add the year to our training data.\ntrain[\"year\"] = train[\"release_date_parsed\"].apply(lambda x: x.year)\n\nfig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\n# Group by year and plot with pandas.\ntrain \\\n    .loc[train.status == \"Released\", \"title\"] \\\n    .groupby(by_year) \\\n    .count() \\\n    .plot(kind=\"bar\")\n\n\naxes.set(title = \"Movies Released by Year\")\naxes.set(xlabel = \"\")\n\n# Get the default location.\nloc, label = plt.xticks()\n\n# Select every 4th label and loc. Add the right ticks.\nind = np.arange(0, len(loc), 4)\nloc, label = loc[ind], np.array(list(label))[ind]\nplt.xticks(loc, label, rotation=45)\n\nplt.show()","a3c6d857":"# Result is .51.\n# \"{:.2f} of our movies were made after 2003.\".format(sum(by_year > 2003) \/ len(train))","d0121822":"# Our groupby variable.\nby_month = train.loc[train.status == \"Released\", \"release_date_parsed\"].apply(lambda x: pd.Period(x, \"M\").month)\n\n\n# Add month to our dataset.\ntrain[\"month\"] = train[\"release_date_parsed\"].apply(lambda x: x.month)\n\n# Four are missing month values, we'll assign them a 9.\n\nfig, axes = plt.figure(figsize=(12, 6)), plt.axes()\n\n# Group by year and plot with pandas.\ntrain \\\n    .loc[train.status == \"Released\", \"title\"] \\\n    .groupby(by_month) \\\n    .count() \\\n    .plot(kind=\"bar\")\n\n\naxes.set(title = \"Movies Released by Month\")\naxes.set(xlabel = \"\")\n\n# Get the default location.\nloc, label = plt.xticks()\n\n# Select every 4th label and loc. Add the right ticks.\nind = np.arange(0, len(loc), 1)\nloc, label = loc, [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\nplt.xticks(loc, label, rotation=45)\n\nplt.show()","797b6396":"get_movie_image(train.sample(1, random_state=198568))","88ca6b46":"features = [\"revenue\", \"budget\", \"popularity\", \"profit\", \"runtime\", \"year\", \"month\", \"id\"]\n\n# Display the table.\ndisplay(train[features].corr())\n\n# Corr Plot.\nfig = plt.figure(figsize=(10, 5))\nplt.imshow(train[features].corr())\nplt.title(\"Correlate Continuous Features\")\nplt.yticks(range(0, len(features)), features)\nplt.xticks(range(0, len(features)), features, rotation=45)\nplt.show()","1161869c":"features = [\"revenue\", \"budget\", \"popularity\", \"runtime\", \"year\", \"month\", \"id\"]\n\nto_scale = [\"revenue\", \"budget\", \"popularity\", \"runtime\"]\n\ntrain_scaled = train.copy()\nfor col in to_scale:\n    train_scaled[col] = np.log1p(train_scaled[col])\n\n# Display the table.\ndisplay(train_scaled[features].corr())\n\n# Corr Plot.\nfig = plt.figure(figsize=(10, 5))\nplt.imshow(train_scaled[features].corr())\nplt.title(\"Correlate Continuous Features\")\nplt.yticks(range(0, len(features)), features)\nplt.xticks(range(0, len(features)), features, rotation=45)\nplt.show()","00969b63":"get_movie_image(train.sample(1, random_state=1957))","2aa2fcef":"train.select_dtypes(\"object\").head(3)","59297dd1":"def parse_content(x, key):\n    \"\"\"\n    Parse Content\n    \n    Provide a string with a 'key': 'value' pair and the output will be a string value.\n    \"\"\"\n    return re.findall(pattern=f\"'{str(key)}': (.+?')\", string=str(x))\n\ndef vectorize_list(x, unique_list):\n    \"\"\"\n    Vectorize a list of values\n    \n    Returns a numpy nd-array. Similar to the output pd.get_dummies would give.\n    \"\"\"\n    x = np.array([item in row_list for row_list in x for item in unique_list]).reshape(len(x), len(unique_list))\n    x = pd.DataFrame(x)\n    return unique_list, x\n\ndef make_column_names(prefix, x):\n    return [\"{}_{}\".format(prefix, i) for i in range(0, len(x))]","437acfd9":"# Get the name if a movie belongs in a collection.\nbelongs_to_collection = train.belongs_to_collection.apply(parse_content, key=\"name\")\n\n# How many belong to a series?\nprint(belongs_to_collection.apply(lambda x: x != []).sum())\n\n# Add as an indicator.\ntrain[\"movie_in_series\"] = belongs_to_collection.apply(lambda x: x != [])","3df8d9bf":"get_movie_image(train.sample(1, random_state=9761))","c96e7a76":"def plot_top_n_count(key, identity, n, plot_title):\n    top_count = list(zip(key, identity.sum()))\n    top_count.sort(key=lambda x: x[1], reverse=True)\n\n    # Plot the top number of companies.\n    top_count = np.array(top_count[:n])\n\n    fig, ax = plt.figure(figsize=(12, 6)), plt.axes()\n\n    # Note the float conversion. Otherwise the plot looked a weird.\n    ax.bar(height=list(map(float, top_count[:, 1])), x=top_count[:, 0], align=\"center\")\n    plt.title(plot_title)\n    plt.xticks(rotation=45)\n    plt.show()","367b52d1":"# Get the names of production companies.\nproduction_companies = train.production_companies.apply(parse_content, key=\"name\")\n\n# Create an identity matrix.\nunique_companies = set([item for item in production_companies for item in item])\ncompany_key, company_identity = vectorize_list(production_companies, unique_companies)\n\n# Plot.\nplot_top_n_count(company_key, company_identity, 20, \"What Companies Create the Most Movies?\")","f3cee7a1":"# Get Countries.\nproduction_countries = train.production_countries.apply(parse_content, key=\"name\")\n\n# Create an identity matrix.\nunique_countries = set([item for item in production_countries for item in item])\ncountry_key, country_identity = vectorize_list(production_countries, unique_countries)\n\n# Plot.\nplot_top_n_count(country_key, country_identity, 20, \"Where are Movies Made?\")","520a0b11":"cast_name = train.cast.apply(parse_content, key=\"name\")\n\nunique_cast = set([item for item in cast_name for item in item])\ncast_key, cast_identity = vectorize_list(cast_name, unique_cast)\n\nplot_top_n_count(cast_key, cast_identity, 20, \"What Actors Participate in the Most Movies?\")","b7779bd5":"keywords = train.Keywords.apply(parse_content, key=\"name\")\n\nunique_keyword = set([item for item in keywords for item in item])\nkeyword_key, keyword_identity = vectorize_list(keywords, unique_keyword)\n\nplot_top_n_count(keyword_key, keyword_identity, 20, \"What top Keywords are used to describe a Movie?\")","9929777a":"crew_name = train.crew.apply(parse_content, key=\"name\")\nunique_crew = set([item for item in crew_name for item in item])\ncrew_key, crew_identity = vectorize_list(crew_name, unique_crew)\nplot_top_n_count(crew_key, crew_identity, 20, \"What Crewmember has Worked on the Most Movies?\")","ea3ae35f":"genre_name = train.genres.apply(parse_content, key=\"name\")\nunique_genre = set([item for item in genre_name for item in item])\ngenre_key, genre_identity = vectorize_list(genre_name, unique_genre)\nplot_top_n_count(genre_key, genre_identity, 20, \"What are the Top Movie Genres?\")","fa85a229":"# Rename Company\ncompany_identity = company_identity.rename({i: \"company_{}\".format(i) for i in range(0, len(company_key))}, axis=1)\n\n# Rename Country\ncountry_identity = country_identity.rename({i: \"country_{}\".format(i) for i in range(0, len(country_key))}, axis=1)\n\n# Rename Crew\ncrew_identity = crew_identity.rename({i: \"crew_{}\".format(i) for i in range(0, len(crew_key))}, axis=1)\n\n# Rename Actor\ncast_identity = cast_identity.rename({i: \"cast_{}\".format(i) for i in range(0, len(cast_key))}, axis=1)\n\n# Rename Genre\ngenre_identity = genre_identity.rename({i: \"genre_{}\".format(i) for i in range(0, len(genre_key))}, axis=1)\n\n# Create a categorical for train.\ntrain_categorical = pd.concat([company_identity, country_identity, crew_identity, cast_identity, genre_identity], axis=1)","8875f2dc":"# Production Companies\nproduction_companies = test.production_companies.apply(parse_content, key=\"name\")\ncompany_key, company_identity = vectorize_list(production_companies, unique_companies)\ncompany_identity = company_identity.rename({i: \"company_{}\".format(i) for i in range(0, len(company_key))}, axis=1)\n\n# Production Countries\nproduction_countries = test.production_countries.apply(parse_content, key=\"name\")\ncountry_key, country_identity = vectorize_list(production_countries, unique_countries)\ncountry_identity = country_identity.rename({i: \"country_{}\".format(i) for i in range(0, len(country_key))}, axis=1)\n\n# Cast\ncast_name = test.cast.apply(parse_content, key=\"name\")\ncast_key, cast_identity = vectorize_list(cast_name, unique_cast)\ncast_identity = cast_identity.rename({i: \"cast_{}\".format(i) for i in range(0, len(cast_key))}, axis=1)\n\n# Keywords\nkeywords = test.Keywords.apply(parse_content, key=\"name\")\nkeyword_key, keyword_identity = vectorize_list(keywords, unique_keyword)\nkeyword_identity = keyword_identity.rename({i: \"cast_{}\".format(i) for i in range(0, len(keyword_key))}, axis=1)\n\n# Crew\ncrew_name = test.crew.apply(parse_content, key=\"name\")\ncrew_key, crew_identity = vectorize_list(crew_name, unique_crew)\ncrew_identity = crew_identity.rename({i: \"crew_{}\".format(i) for i in range(0, len(crew_key))}, axis=1)\n\n# Genre\ngenre_name = test.genres.apply(parse_content, key=\"name\")\ngenre_key, genre_identity = vectorize_list(genre_name, unique_genre)\ngenre_identity = genre_identity.rename({i: \"genre_{}\".format(i) for i in range(0, len(genre_key))}, axis=1)\n\ntest_categorical = pd.concat([company_identity, country_identity, crew_identity, cast_identity, genre_identity], axis=1)","77e2e6d2":"train = pd.concat([train, train_categorical], axis=1)\ntest = pd.concat([test, train_categorical], axis=1)","11cd02de":"fig, ax = plt.figure(figsize=(10, 6)), plt.axes()\n\n# Data\ntrain[\"original_language\"] \\\n    .groupby(train[\"original_language\"]) \\\n    .count() \\\n    .sort_values(ascending=False) \\\n    .transform(lambda x: x \/ len(train)) \\\n    .plot(kind=\"bar\", color=\"salmon\")\n\nplt.title(\"Movies by Original Language\")\nplt.show()","d9f17a56":"from sklearn import linear_model, metrics, model_selection, impute","aff0258a":"get_movie_image(train.sample(1, random_state= 1256))","274581fc":"# Parse the release date.\ntest[\"release_date_parsed\"] = test.release_date.apply(parse_date)\n\n# Add Year\ntest[\"year\"] = test.release_date_parsed.apply(lambda x: x.year)\n\n# Add Month\ntest[\"month\"] = test.release_date_parsed.apply(lambda x: x.month)","399722bc":"features = [\"budget\", \"popularity\", \"runtime\", \"year\", \"month\", \"id\"]\n\n# Simple impute uses the mean\nimp = impute.SimpleImputer()\n\ntrain[features] = imp.fit_transform(train[features])","a94b3e1b":"test[features].isna().sum()","9e9a1674":"test[features] = imp.fit_transform(test[features])","8472dbc4":"# Small featureset for a linear model.\ntarget, features = \"revenue\", [\"budget\", \"popularity\", \"runtime\", \"year\"]\n\n# Do a train\/test split.\nX_train, X_test, y_train, y_test = model_selection.train_test_split(train[features], train[target], test_size=0.3, random_state=42)\n\n# Init the estimator.\nlm = linear_model.LinearRegression()\n\n# KFold Cross validation.\ncv = model_selection.KFold(n_splits=5)\n\n# Fit a normal model.\nlm.fit(X_train, y_train)\n\ny_pred = lm.predict(X_train)\n\n# Perform cross validation.\nprint(\"Cross Validation: \", model_selection.cross_val_score(estimator=lm, X=X_train, y=y_train, cv=cv, scoring=\"neg_mean_squared_error\"))\n\nprint(\"Training Sample Performance: \", metrics.mean_squared_error(y_train, y_pred))\n\nplt.figure(figsize=(10, 5))\nplt.scatter(y_pred, y_train)\nplt.show()","5ecf0f6b":"import sklearn","9751132f":"# Small featureset for a linear model.\ntarget, features = \"revenue\", [\"budget\", \"popularity\", \"runtime\"]\n\n# Do a train\/test split.\nX_train, X_test, y_train, y_test = model_selection.train_test_split(train[features], train[target], test_size=0.3, random_state=42)\n\n# Feature scaling.\ny_train = np.log1p(y_train)\n\nX_train[features] = X_train[features].transform(np.log1p)\n\n# Init the estimator.\nlm = linear_model.LinearRegression()\n\n# KFold Cross validation.\ncv = model_selection.KFold(n_splits=5)\n\n# Fit a normal model.\nlm.fit(X_train, y_train)\n\ny_pred = lm.predict(X_train)\n\n# Use an exponential to back-transform our predictions, targets.\ny_train, y_pred = np.expm1(y_train), np.expm1(y_pred)\n\n\nplt.figure(figsize=(10, 5))\nplt.scatter(y_pred, y_train)\nplt.xlim(0, 1e8)\nplt.ylim(0, 1e8)\nplt.show()","f82e6f36":"get_movie_image(train.sample(1, random_state=8615))","181bc6ac":"from sklearn import ensemble","f00016f1":"company_cols = list(company_identity.columns.values)\ncast_cols = list(cast_identity.columns.values)\n\ntarget, features = \"revenue\", [\"budget\", \"popularity\", \"runtime\", \"year\"] + company_cols + cast_cols\n\n# Do a train\/test split.\nX_train, X_test, y_train, y_test = model_selection.train_test_split(train[features], train[target], test_size=0.3, random_state=42)\n\n# Init the estimator.\nlm = ensemble.RandomForestRegressor()\n\n# KFold Cross validation.\ncv = model_selection.KFold(n_splits=5)\n\n# Fit a normal model.\nlm.fit(X_train, y_train)\n\ny_pred = lm.predict(X_train)\n\n# Perform cross validation.\nprint(\"Cross Validation: \", model_selection.cross_val_score(estimator=lm, X=X_train, y=y_train, cv=cv, scoring=\"neg_mean_squared_error\"))\n\nprint(\"Training Sample Performance: \", metrics.mean_squared_error(y_train, y_pred))\n\nplt.figure(figsize=(10, 5))\nplt.scatter(y_pred, y_train)\nplt.show()","9b3ab179":"get_movie_image(train.sample(1, random_state=865241))","3f9cc53e":"Now we'll scale some of our features and see if that improves the correlation.","8c1ecdba":"#### Other features","17805942":"There's a lot we can do to clean and engineer features, but first we'll look at some of our continuous variables.\n\nContinuous Features\n-------------------\n\n### First Look At Revenue","abe670b7":"### Random Forest Model\n\nNow that we've looked at just the continuous features. We'll expand into categorical features while using an ensemble model to help with feature selection.","6636648a":"Using the function we have just created, let's create some plots.","781d77fa":"### Linear Model with Continuous Features","5803def8":"#### Add Features to Train Data","94ff6bf3":"### Release Date","6a9e72c5":"### Linear Model with Scaled Continuous Features","c3464ce8":"A fair number of the movies in our dataset made profit, but 650 movies out of 3000 that didn't make enough money to cover their budget seems pretty significant.","56213583":"### Correlate our Continuous Features","e67c27af":"The original language for the vast majority of movies are English. Followed by French and Russian.","5dc6ac57":"Our results are pretty un-intelligible. So, we'll want to stick with the unscaled target and\/or use a better model.","84016708":"#### Combine Train and Test Categorical","9b1b839a":"We'll start with a simple model using the continuous features that we've already examined. Later we'll try some different models.","d6a9ffe2":"I don't quite understand what this rating is yet. Seems to be a score from 0 to 100, but it's not intuitive what makes a movie popular.","0b594a77":"### Budget","49eb86e4":"A quick view of our columns that can be used as categorical features.","db194f6b":"<br>\n<br>\n![](https:\/\/m.media-amazon.com\/images\/M\/MV5BNTMwZGU3MGUtZWE0Ni00YzExLWIyY2MtMmNmMDlmYTdmNzFkXkEyXkFqcGdeQXVyNjExODE1MDc@._V1_.jpg)\n\nIt's worth doing a little online research for some of these, but it's hard to believe that a movie like this with a decent revenue cost nothing to make.\n\nWhile we're looking at budgets and revenues, let's try looking at the average profit a movie makes.","5984f2d9":"That's looking a little better, but the distribution is still not as uniform as I would like. This might be good enough for predictive purposes, but we'll confirm that when we model our data.","8622b697":"These dates are a little weird. I could spend some time looking through date parsing formats, but I'm going to convert these into something more recognizable and then parse with pd.Timestamp. Normally using apply is pretty slow, so I'd look for a better solution, but this dataset is small enough that this is no problem.","e81c08ab":"This is looking much better, but there are a few more features that we haven't used yet! In a future version of this notebook, I'd like to include some of the features that I missed and explore what the Random Forest thinks is important.","b38f2ee8":"Setup\n-----\n\nFirst, we'll load the packages and data to start doing some basic exploration.","a2f4d88e":"We've added year and month features to our training set. Let's do the same to our test.","d9b741a5":"Models\n------","6940183d":"### Popularity","40c5a50e":"The first function looks for key and value pairs based on a regular expression. It's pretty simple, but will open up a lot of possibilities for engineering features.","7af302a8":"#### Add Features to Test Data","25df9f9f":"Some of the values for revenue seem very small. These could be potential outliers.\n\n![](https:\/\/image.tmdb.org\/t\/p\/w300\/nsOM52BsDeHzc0yI27bah2OWems.jpg)\n\n... but after some investigation, that might not be the case. Definitely wouldn't want to miss this one!\n\nBased on this small sample of data, it looks like popularity, release date, and budget will be helpful in determining overall revenue. So, we can look at those next.","bfd11f2f":"Which movies have the highest budgets?","29c86f94":"Now fix missing variables.","2813ea8e":"Exploring Categorical Features\n------------------------------","ccabad66":"The correlations don't improve like I would expect them to. Cross validation and our loss function will tell us for sure.","273a71aa":"#### Original Language","2bf3f62c":"This looks about what you would expect with most movies making under 200 million. If we start off with a linear model, we might need do a transformation.","5c0ddb00":"Since there are so many combinations, this will fill up our feature space pretty quickly. An ensemble algorithm like the random forest may help us sort through which of these features are important. I won't do this right away, but I suspect we will remove the sparse companies with few movies produced.","321d5cab":"Many of these columns will require a couple steps in order to be parsed. First, we'll create a couple of function that can help us to extract data in this format."}}