{"cell_type":{"4b6980d8":"code","c2984413":"code","6c2ec4cb":"code","b68fbdb5":"code","4c911e0c":"code","c9fd599f":"code","201b562b":"code","f5b4c036":"code","da116fbd":"code","8f729e27":"code","e511846c":"code","6a86d5ac":"code","fdf78e55":"code","9d9f59bb":"code","18cfa4bb":"code","a9442d98":"code","8ea8d1f8":"code","ce59c473":"code","89edc58a":"code","b76a8bc1":"code","91041cd5":"code","6af0d900":"code","262673b4":"code","4391b9d6":"code","1095b20e":"code","d7ff7eef":"code","0afbddd4":"code","22918010":"code","ce2516a8":"code","8d212dc9":"code","67d3b25d":"code","46976188":"code","46247a36":"code","e116b57a":"code","36fda44a":"code","bf70998c":"code","966bc7ac":"code","8530b8a4":"code","4a2f9c38":"code","e6d60b3b":"code","dcf3ef87":"code","03a90570":"code","43a4cb30":"code","61e7fc82":"markdown","398638b7":"markdown","033cff78":"markdown","9b2492f4":"markdown","7d021bed":"markdown","159155c8":"markdown","b75e1cdc":"markdown","b4b4e6f9":"markdown","a14bb9e6":"markdown","d209550e":"markdown"},"source":{"4b6980d8":"%matplotlib inline\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nsns.set_style('darkgrid')","c2984413":"import warnings\nfrom matplotlib import rcParams\nrcParams[\"xtick.labelsize\"] = 15\nrcParams[\"ytick.labelsize\"] = 15\nrcParams[\"legend.fontsize\"] = \"small\"\npd.set_option(\"precision\", 2)\nwarnings.filterwarnings(\"ignore\")","6c2ec4cb":"Jun = pd.read_csv('..\/input\/silverminidataset\/30Jun2021.csv',parse_dates=[\"Date\"],index_col=\"Date\")\nJun = Jun [['Open','High','Low','Close','Previous Close']]","b68fbdb5":"Aug= pd.read_csv('..\/input\/silverminidataset\/31AUG2021.csv',parse_dates=[\"Date\"],index_col=\"Date\")\nAug = Aug [['Open','High','Low','Close','Previous Close']]","4c911e0c":"print(Jun.head())\nprint(Jun.tail())","c9fd599f":"print(Aug.head())\nprint(Aug.tail())","201b562b":"Jun = Jun[~Jun.Open.isnull()]\nJun.tail()","f5b4c036":"Aug[~Aug.Open.isnull()]","da116fbd":"#I just need the data from 30th June till date\n#The slicing starts reverse, because my dates are reversed\nAug = Aug.loc[\"2021-08\":\"2021-07\"]","8f729e27":"#Creating Data from Nov'20 to Jul'21, that is 9 months\nqtr = Aug.append(Jun)","e511846c":"print(qtr.shape)\nqtr.head()","6a86d5ac":"qtr['mon'] = qtr.index.month_name()","fdf78e55":"qtr['day'] = qtr.index.day_name()","9d9f59bb":"#qtr['Open'].asfreq('M').tail(5) is not workin\nqtr.tail()","18cfa4bb":"#Learning to impute\nimputer = pd.read_csv('..\/input\/silverminidataset\/30Jun2021.csv',parse_dates=[\"Date\"],index_col=\"Date\")","a9442d98":"imputer = imputer[['Open','High','Low','Close','Previous Close']]","8ea8d1f8":"imputer[imputer.Open.isna()].Open = imputer[imputer.Open.isna()].Close","ce59c473":"for id in imputer[imputer.Open.isna()].index:\n    imputer.loc[id,'Open'] = imputer.loc[id,'Close']","89edc58a":"for id in imputer[imputer.High.isna()].index:\n    imputer.loc[id,'High'] = imputer.loc[id,'Close']","b76a8bc1":"for id in imputer[imputer.Low.isna()].index:\n    imputer.loc[id,'Low'] = imputer.loc[id,'Close']","91041cd5":"imputer.tail()","6af0d900":"#Creating Data from Nov'20 to Jul'21, that is 9 months\nnew_qtr = Aug.append(imputer)","262673b4":"print(qtr.shape)\nprint(new_qtr.shape)\n#If not imputed, then approx 60 days closing price will be lost","4391b9d6":"new_qtr['day']=new_qtr.index.day_name()\nnew_qtr['month']=new_qtr.index.month_name()\nnew_qtr.head()","1095b20e":"#Adding additional information\nnew_qtr['intra'] = new_qtr.Open - new_qtr.Close\nnew_qtr['gap'] = new_qtr.Open - new_qtr['Previous Close']\nnew_qtr.tail()","d7ff7eef":"#Which days of the week there has been high intra day jump?\n\nsns.catplot(y ='intra', x = 'day',data=new_qtr, kind='boxen',col='month',col_wrap=3)","0afbddd4":"#Which days of the week there has been high intra day jump?\nsns.catplot(y ='gap', x = 'day',data=new_qtr, kind='box',col='month',col_wrap=3)","22918010":"sns.jointplot(x='intra',y='gap',data=new_qtr[:'2021-03'],hue='month')","ce2516a8":"sns.jointplot(x='intra',y='gap',data=new_qtr['2021-02':],hue='month')","8d212dc9":"vol = pd.read_csv('..\/input\/silverminidataset\/30Jun2021.csv',parse_dates=[\"Date\"],index_col=\"Date\")\nvol = vol[['Volume(Lots)','Close']]","67d3b25d":"vol['day'] = vol.index.day_name()\nvol['month'] = vol.index.month_name()","46976188":"vol.head()","46247a36":"sns.catplot(x='Volume(Lots)',y='month',data=vol[:'2021-04'],kind='box')","e116b57a":"sns.catplot(x='Volume(Lots)',y='month',data=vol['2021-01':],kind='box')","36fda44a":"new_qtr['lognat'] = new_qtr['Close'].apply(lambda x: np.log(x))\n\nfig, ax = plt.subplots(3,1,figsize=(14,14))\n\nnew_qtr.Close.plot(ax=ax[0])\n\nnew_qtr.lognat.plot(ax=ax[1])\n\nnew_qtr['lag'] = new_qtr.Close - new_qtr.Close.shift()\nnew_qtr.lag.plot(ax=ax[2])","bf70998c":"from statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\n\n#Here we are subtracting the close of earlier date with later date\nlag_correlations = acf(new_qtr['lag'].iloc[1:])\nlag_partial_correlations = pacf(new_qtr['lag'].iloc[1:])","966bc7ac":"fig, ax = plt.subplots(figsize=(16,12))\n\nax.plot(lag_correlations, marker='o', linestyle='--',color='b')\nax.plot(lag_partial_correlations, marker='x', linestyle='-',color='r')","8530b8a4":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(new_qtr['lag'].iloc[1:], model='additive', freq=30)\nfig = plt.figure(figsize=(20,10))\nfig = decomposition.plot()","4a2f9c38":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(new_qtr['lognat'], model='additive', freq=30)\nfig = plt.figure()\nfig = decomposition.plot()","e6d60b3b":"model = sm.tsa.ARIMA(new_qtr.lognat, order=(1, 0, 0))\nresults = model.fit(disp=-1)\nnew_qtr['Forecast'] = results.fittedvalues\nnew_qtr[['lognat', 'Forecast']].plot(figsize=(16, 12))","dcf3ef87":"new_qtr['diff_lognat'] = new_qtr.lognat - new_qtr.lognat.shift()","03a90570":"model = sm.tsa.ARIMA(new_qtr.diff_lognat.iloc[1:], order=(1, 0, 0))\nresults = model.fit(disp=-1)\nnew_qtr['diff_Forecast'] = results.fittedvalues\nnew_qtr[['diff_lognat', 'diff_Forecast']].plot(figsize=(16, 12))","43a4cb30":"model = sm.tsa.ARIMA(new_qtr.diff_lognat.iloc[1:], order=(0, 0, 1))\nresults = model.fit(disp=-1)\nnew_qtr['diff_Forecast'] = results.fittedvalues\nnew_qtr[['diff_lognat', 'diff_Forecast']].plot(figsize=(16, 12))","61e7fc82":"## Thanks for Joining me in this journey....","398638b7":"It has performed much better with the natural log values, how it will do on natural log with a lag?","033cff78":"The above plots show many insights\n1) In the beginning there is not much Intraday action, since Open and Close are the same, even though, the close might be at different values\n\n2)Most of the intraday action happens on the Friday, as the week closes.\n\n3)Major moves or corrections happen on the Thursdays, and on Tuesdays in most of the months. Mondays and Fridays are active only in 2 or less months.\n\n4)Intraday has seen some good positive moves, upto 6000 INR. When it comes to negative side, it has gone upto -2500 INR in a day\n","9b2492f4":"The graph above shows that there is no significant correlation between the \"lagged\" series and the next 40 such lags. So essentially the series is a Random Walk. ","7d021bed":"1) One can see from the Opening Gap, how liquid the market is for traders\n\n2) Overnight impact on the pricing slowly fades away as the future starts getting traded by more people\n\n* By looking at the volumes traded till date, and dividing it into each month the details can be seen visually\n\n* More people entering the market there is significant liquidity to abosorb any price shocks\n\n3) How significant the impact of opening gap  on the intraday movement? \n\n* Take a look at one of the joint plot between the opening gap and the intraday moves, there is no correlation\n\n* Higher Opening Gaps have occured during the initial months when the liquidity was less\n\n* After splitting the data with help of the months column, the significance of the liquidity can be observed\n\nQuestions:\n1) Where the price of the instrument comes in the begining of the instrument?\n    \n    - Usually, it is calculated and registered by the script creator on the market\n    \n    - The market makers open the script and close at the same price for accounting purposes\n    \n    - Even in this data in the beginning you will see the \"Close\" prices copied onto the \"Open\",\"High\",\"Low\", for the days \n    where this information was missing. Imputing in the statistical way was not done. \n    \n2) How can these insights be used for understanding the price movements?\n\n    - Price moves because there is supply and demand change of the underlying, in this it was silver. The instrument, Silver   Micro future\n    \n    - Once the analysis is through, and you find that using the price movement of this instrument is useless, then you search for another instrument that is correlating with this instrument. We have one such underlying, it is Gold.\n    \n    - Using the probability of the price movements can be very useful in controlling your anxiety during the wild swings in the market. The below plots on the \"Close\" will show what happens in market in statistical point.","159155c8":"There is surprising monthly cycles on the closing prices. What can explain this seasonality?\n\nHow can this seasonality be leveraged for forecasting? b","b75e1cdc":"Objective of this notebook is not just to check how the prediction is being done on a time series, but to understand the series and then use the knowledge to predict in other more predictable series.","b4b4e6f9":"#To begin with \n\nLet us directly try to find out whether there is any correlation between the lagged prices. This is called as autocorrelation.\nThere are partial ACF and ACF functions that can help find out such a correlations in the series.\n\nIf there is no correlation, then the series is effectively a Random Walk. Lets begin","a14bb9e6":"Now it's pretty obvious that the forecast is way off.  We're predicting tiny little variations relative to what is actually happening day-to-day.  Again, this is more of less expected with a simple moving average model of a random walk time series.  There's not enough information from the previous days to accurately forcast what's going to happen the next day.\n\nA moving average model doesn't appear to do so well.  What about an exponential smoothing model?  Exponential smoothing spreads out the impact of previous values using an exponential weighting, so things that happened more recently are more impactful than things that happened a long time ago.  Maybe this \"smarter\" form of averaging will be more accurate?","d209550e":"## Timeseries Analysis of Silver Microfutures\n\n* Understand the timeseries data\n\n* Post process the data for analysis\n\n* Basic plotting and Exploratory Data Analysis\n\n* ACF\/ PACF analysis\n\n* Fitting using ARIMA model"}}