{"cell_type":{"eb438b3f":"code","452db46f":"code","9f1046dd":"code","ad6c5df2":"code","9f3e8329":"code","397d3ea4":"code","91ab44b0":"code","8b97f613":"code","a48ebb9f":"code","48ed050a":"code","f3ecdad8":"code","33305930":"code","bf49a899":"code","e2fa7fbf":"code","d191accf":"code","85635c09":"code","e8ebf6ca":"code","9164b2b1":"code","e0bc3e02":"code","14894741":"code","09af1616":"code","18ca3e29":"code","a4b62837":"code","4995522e":"code","58e4472e":"code","85d04503":"code","e7212184":"code","c4de27d9":"code","e9770222":"code","8b92a3d0":"code","deabf4f7":"code","e8fe7b54":"code","073195a6":"code","ececf464":"code","46e1e3f0":"code","e6400d03":"code","b819fc30":"code","9149c191":"code","e5c33db7":"code","dddec9f5":"code","6aea20c1":"code","b42ca111":"code","9c13bf62":"code","b420a486":"code","b989c7a5":"code","dcef701a":"markdown","96e15ed2":"markdown","9451ac11":"markdown","ad47a31d":"markdown","f73cb0c2":"markdown","7172d56b":"markdown","4e88f8f1":"markdown","82c39f1f":"markdown","6e7e06e3":"markdown"},"source":{"eb438b3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","452db46f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport pandas as pd\nimport seaborn as sns\nimport shap\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# sklearn libs compatilhadas\nimport sklearn\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\nfrom sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, train_test_split, RandomizedSearchCV\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n## Tratando dados desbalanceados\nfrom imblearn.over_sampling import SMOTE\n\n\n\n\n### Clusteniza\u00e7\u00e3o 1\nfrom sklearn.cluster import KMeans \nfrom sklearn import metrics \nfrom scipy.spatial.distance import cdist \n\n\n\n## Classificacao 1\nfrom sklearn.linear_model import LogisticRegression\n\n## Classifica\u00e7\u00e3o 2\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nfrom lightgbm import LGBMClassifier\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\n","9f1046dd":"shap.initjs()","ad6c5df2":"\ndef plot_confusion_matrix(y_test, y_pred):\n    cm = confusion_matrix(y_test, y_pred, normalize=\"true\")\n    df = pd.DataFrame(cm, index=[\"no\", \"yes\"], columns=[\"no\", \"yes\"])\n    ax = sns.heatmap(df, annot=True)\n    ax.set_xlabel(\"Predicted label\")\n    ax.set_ylabel(\"True label\")\n    return ax\n\ndef plot_roc(y_true, y_score, figsize=(8, 8)):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure(figsize=figsize)\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=2, label=f'ROC curve (AUC = {100*roc_auc:.2f}%)')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    \n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    return roc_auc\n\n\ndef plot_precision_recall(precisions, recalls, thresholds):\n    fig, ax = plt.subplots(figsize=(12,8))\n    ax.plot(thresholds, precisions[:-1], \"r--\", label=\"Precisions\")\n    ax.plot(thresholds, recalls[:-1], \"#424242\", label=\"Recalls\")\n    ax.set_title(\"Precision and Recall \\n Tradeoff\", fontsize=18)\n    ax.set_ylabel(\"Level of Precision and Recall\", fontsize=16)\n    ax.set_xlabel(\"Thresholds\", fontsize=16)\n    ax.legend(loc=\"best\", fontsize=14)\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    return ax\n\ndef plot_confusion_matrix2(y_test, y_pred, figsize=(16,16),names=False):\n    fig, ax = plt.subplots(figsize = figsize)\n    cm = confusion_matrix(y_test, y_pred, normalize=\"true\")\n    if names:\n        df = pd.DataFrame(cm, index=names, columns=names)\n    else:\n        df = pd.DataFrame(cm)#, index=[\"no\", \"yes\"], columns=[\"no\", \"yes\"])    \n    ax = sns.heatmap(df, annot=True,ax=ax)\n    ax.set_xlabel(\"Predicted label\")\n    ax.set_ylabel(\"True label\")\n    return ax","9f3e8329":"df = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')","397d3ea4":"df.columns = ['Patient ID',\n 'Patient_age_quantile',\n 'SARS-Cov-2_result',\n 'Patient_addmited_regular_ward_care_bool',\n 'Patient_addmited_semi-intensive_care_bool',\n 'Patient_addmited_intensive_care_bool',\n 'Hematocrit',\n 'Hemoglobin',\n 'Platelets',\n 'Mean_platelet_volume',\n 'Red_blood_Cells',\n 'Lymphocytes',\n 'MCHC',\n 'Leukocytes',\n 'Basophils',\n 'MCH',\n 'Eosinophils',\n 'MCV',\n 'Monocytes',\n 'RDW',\n 'Serum Glucose',\n 'Respiratory_Syncytial Virus',\n 'Influenza_A',\n 'Influenza_B',\n 'Parainfluenza_1',\n 'CoronavirusNL63',\n 'Rhinovirus_Enterovirus',\n 'Mycoplasma_pneumoniae',\n 'Coronavirus_HKU1',\n 'Parainfluenza_3',\n 'Chlamydophila_pneumoniae',\n 'Adenovirus',\n 'Parainfluenza 4',\n 'Coronavirus229E',\n 'CoronavirusOC43',\n 'Inf_A_H1N1_2009',\n 'Bordetella_ertussis',\n 'Metapneumovirus',\n 'Parainfluenza_2',\n 'Neutrophils',\n 'Urea',\n 'Proteina_C',\n 'Creatinine',\n 'Potassium',\n 'Sodium',\n 'Influenza_B_test',\n 'Influenza_A_test',\n 'Alanine_ransaminase',\n 'Aspartate_transaminase',\n 'Gamma-glutamyltransferase',\n 'Total_Bilirubin',\n 'Direct_Bilirubin',\n 'Indirect_Bilirubin',\n 'Alkaline_phosphatase',\n 'Ionized_calcium',\n 'Strepto_A',\n 'Magnesium_',\n 'pCO2_',\n 'Hb_saturation_',\n 'Bas_excess_',\n 'pO2_',\n 'Fio2_',\n 'Total_CO2_',\n 'pH_',\n 'HCO3_venon',\n 'Rods',\n 'Segmented',\n 'Promyelocytes',\n 'Metamyelocytes',\n 'Myelocytes',\n 'Myeloblasts',\n 'Urine_Esterase',\n 'Urine_Aspect',\n 'Urine_pH',\n 'Urine_Hemoglobin',\n 'Urine_Bile pigments',\n 'Urine_Ketone Bodies',\n 'Urine_Nitrite',\n 'Urine_Density',\n 'Urine_Urobilinogen',\n 'Urine_Protein',\n 'Urine_Sugar',\n 'Urine_Leukocytes',\n 'Urine_Crystals',\n 'Urine_Red blood cells',\n 'Urine_Hyaline cylinders',\n 'Urine_Granular cylinders',\n 'Urine_Yeasts',\n 'Urine_Color',\n 'Partial_thromboplastin_time',\n 'Relationship',\n 'INR',\n 'Lactic_Dehydrogenase',\n 'Prothrombin_time (PT)',\n 'Vitamin_B12',\n 'Creatine_phosphokinase',\n 'Ferritin',\n 'Lactic_Acid',\n 'Lipase_dosage',\n 'D-Dimer',\n 'Albumin',\n 'Hb_saturation',\n 'pCO2',\n 'Base_excess',\n 'pH',\n 'Total_CO2',\n 'HCO3_artery',\n 'pO2',\n 'Arteiral_Fio2',\n 'Phosphor',\n 'ctO2']","91ab44b0":"# sorted([[df.shape[0]-j,i] for i,j in df.isna().sum().items() if j > 0])\n\n\n# [0, 'D-Dimer'],\n#  [0, 'Mycoplasma_pneumoniae'],\n#  [0, 'Partial_thromboplastin_time'],\n#  [0, 'Prothrombin_time (PT)'],\n#  [0, 'Urine_Sugar'],\n#  [1, 'Fio2_'],\n#  [1, 'Urine_Nitrite'],\n#  [3, 'Vitamin_B12'],\n#  [8, 'Lipase_dosage'],","8b97f613":"## \ndf.drop(['Prothrombin_time (PT)', 'D-Dimer', 'Mycoplasma_pneumoniae', 'Urine_Sugar', 'Partial_thromboplastin_time', 'Fio2_', 'Urine_Nitrite', 'Vitamin_B12'], axis = 1, inplace = True)","a48ebb9f":"## Preenchendo as colunas  dos testes que n\u00e3o foram feitos.\ncolumns_to_fill = pd.DataFrame(df.isna().sum()\/df.shape[0], columns=['Missing'])\ncolumns_to_fill = columns_to_fill[(columns_to_fill.Missing < 0.87)].index\n\nfor col in columns_to_fill:\n    df[col] = df[col].fillna('not_done')","48ed050a":"## Map CATEGORICO\nfullMapper={'negative': 0, 'positive': 1,\n           'not_detected': 0, 'detected': 1,\n            'not_done': -1, 'absent': -1,\n            'N\u00e3o Realizado': -1,\n               ## Urine Aspects\n              'clear': 0,\n              'cloudy': 1,\n              'lightly_cloudy': 2,\n              'altered_coloring': 3,\n               #Urine_Leukocytes\n               '<1000': 1000,\n                #Urine_urobilinogen\n                'normal':0,\n            #'Urine_Crystals': {\n              'Ausentes': 0,\n              'Urato Amorfo --+': 1,\n              'Urato Amorfo +++': 2,\n              'Oxalato de C\u00e1lcio +++': 3,\n              'Oxalato de C\u00e1lcio -++': 4,\n            # Urine_Color\n              'yellow': 0,\n              'light_yellow': 1,\n              'orange': 2,\n              'citrus_yellow': 3,\n            # Urine_Hemoglobin\n            'present': 1,\n               }\n\ndf.replace(fullMapper, inplace=True)","f3ecdad8":"## Preenchendo os exames de sangue com base na m\u00e9dia por idade\ncolumns_to_fill = pd.DataFrame(df.isna().sum()\/df.shape[0], columns=['Missing'])\ncolumns_to_fill = columns_to_fill[columns_to_fill.Missing > 0.87].index\n\n#Prenche quando tiver o dado da idade\nfor value in df.Patient_age_quantile.unique():\n    df_aux = df[df.Patient_age_quantile == value].copy()\n    \n    for col in columns_to_fill:\n        df_aux[col] = df_aux[col].fillna(df_aux[col].median())\n        \n    df.loc[df_aux.index] = df_aux\n\n#Preenche com a media geral\nfor col in columns_to_fill:\n    df[col] = df[col].fillna(df[col].median())","33305930":"df[['Urine_Aspect', 'Urine_Color', 'Urine_Crystals']]  = df[['Urine_Aspect', 'Urine_Color', 'Urine_Crystals']].astype('category')","bf49a899":"df.isna().sum().sum()","e2fa7fbf":"X = df.drop(['Patient ID','SARS-Cov-2_result', 'Patient_addmited_regular_ward_care_bool',\n       'Patient_addmited_semi-intensive_care_bool',\n       'Patient_addmited_intensive_care_bool'], axis=1)\ny = df['SARS-Cov-2_result']\nX_scaled = StandardScaler().fit_transform(X)","d191accf":"os = SMOTE(random_state=0)\nX_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_scaled, y, test_size=0.3, random_state=0)\ncolumns = X.columns\n\nos_data_X, os_data_y = os.fit_sample(X_train_all, y_train_all)\nos_data_X = pd.DataFrame(data=os_data_X,columns=columns)\nos_data_y = pd.DataFrame(data=os_data_y)\n\nX_train_all = os_data_X\ny_train_all = os_data_y['SARS-Cov-2_result']","85635c09":"print(f\"\"\"\ntamanho do dataset de treino:\nX_train:{X_train_all.shape}\ny_train:{y_train_all.shape}\n~~~~~~~\ntamanho do dataset de teste:\nX_test:{X_test_all.shape}\ny_test:{y_test_all.shape}\n\"\"\")","e8ebf6ca":"X_train = X_train_all.copy()\ny_train = y_train_all.copy()\nX_test= X_test_all.copy()\ny_test=y_test_all.copy()\n\n# params = dict(\n#     n_estimators=[150,500,1000],\n#     max_depth=[3, 5, 10],\n#     min_samples_split=[2,50],\n#     min_samples_leaf=[1,5,10],\n# )\n# model = RandomForestClassifier(n_jobs=-1, random_state=42)\n# grid = GridSearchCV(model, param_grid = params,verbose=True, n_jobs=-1, return_train_score= True)\n# grid.fit(X_train, y_train)\n","9164b2b1":"best_params = {'max_depth': 10,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'n_estimators': 500}\n\nmodel = RandomForestClassifier(**best_params,n_jobs=-1,verbose=0, random_state=42).fit(X_train, y_train)\ny_pred = model.predict_proba(X_test)","e0bc3e02":"pred_train = model.predict(X_train)\nscores = sklearn.metrics.accuracy_score(y_train, pred_train)\nprint('Accuracy on training data: {:.2f}%'.format(scores))   \n \npred_test = model.predict(X_test)\nscores2 = sklearn.metrics.accuracy_score(y_test, pred_test)\nprint('Accuracy on test data: {:.2f}%'.format(scores2))    ","14894741":"_ =plot_roc(y_test, y_pred[:,1])","09af1616":"precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred[:,1])\n_ =plot_precision_recall(precisions, recalls, thresholds)","18ca3e29":"threshold = 0.6\n\ny_pred_ = y_pred[:,1] > threshold\n\n_ =plot_confusion_matrix(y_test, y_pred_)\nconfusion_matrix(y_test, y_pred_)","a4b62837":"X_train = X_train_all.copy()\ny_train = y_train_all.copy()\nX_test= X_test_all.copy()\ny_test_=y_test_all.copy()\n","4995522e":"# one hot encode outputs\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test_)\n\ncount_classes = y_test.shape[1]\nprint(count_classes)","58e4472e":"\n# build the model\nmodel = Sequential()\nmodel.add(Dense(250, activation='relu', input_dim=(X_train.shape[1])))\nmodel.add(Dropout(.2))\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(200, activation='tanh'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dropout(.3))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#Fitting The Mdoel\nmodel.fit(X_train, y_train, epochs=300, verbose = True)","85d04503":"pred_train = model.predict(X_train)\nscores = model.evaluate(X_train, y_train, verbose=0)\nprint('Accuracy on training data: {:.2f}% \\n Error on training data: {:.2f}'.format(scores[1], 1 - scores[1]))   \n \npred_test = model.predict(X_test)\nscores2 = model.evaluate(X_test, y_test, verbose=0)\nprint('Accuracy on test data: {:.2f}% \\n Error on test data: {:.2f}'.format(scores2[1], 1 - scores2[1]))    ","e7212184":"y_pred =  model.predict(X_test)","c4de27d9":"y_pred[:,1]\ny_test_","e9770222":"_ =plot_roc(y_test_, y_pred[:,1])","8b92a3d0":"precisions, recalls, thresholds = precision_recall_curve(y_test_, y_pred[:,1])\n_ =plot_precision_recall(precisions, recalls, thresholds)","deabf4f7":"threshold = 0.57\n\ny_pred_ = y_pred[:,1] > threshold\n\n_ =plot_confusion_matrix(y_test_, y_pred_)\nconfusion_matrix(y_test_, y_pred_)","e8fe7b54":"## Pessoas sem covid\ndf['grau_doenca'] = 0\n\n\n## Pessoas sem covid mas em leitos hospitalares\nind = (df[df['SARS-Cov-2_result'] == 0][['Patient_addmited_regular_ward_care_bool',\n       'Patient_addmited_semi-intensive_care_bool',\n       'Patient_addmited_intensive_care_bool']].sum(axis=1) == 1)\nind = [ind for ind, boolean in ind.items() if boolean == 1]\ndf.loc[ind, 'grau_doenca'] = 1\n\n\n\n# ## Pessoas com covid mas fora de leito\nind = (df[df['SARS-Cov-2_result'] == 1][['Patient_addmited_regular_ward_care_bool',\n       'Patient_addmited_semi-intensive_care_bool',\n       'Patient_addmited_intensive_care_bool']].sum(axis=1) == 0)\n\nind = [ind for ind, boolean in ind.items() if boolean == 1]\ndf.loc[ind, 'grau_doenca'] = 2\n\n\n\n\n# ## Pessoas com covid em leito\nind = (df[df['SARS-Cov-2_result'] == 1][['Patient_addmited_regular_ward_care_bool',\n       'Patient_addmited_semi-intensive_care_bool',\n       'Patient_addmited_intensive_care_bool']].sum(axis=1) != 0)\n\nind = [ind for ind, boolean in ind.items() if boolean == True]\ndf.loc[ind, 'grau_doenca'] = 3\n\ndic={0: 'sem doen\u00e7a',\n2: 'com covid leve',\n1: 'internado sem covid',\n3: 'covid internado'}\n\n{dic[i]:j for i,j in  df['grau_doenca'].value_counts().items()}","073195a6":"X = df.drop(['Patient ID','SARS-Cov-2_result', 'Patient_addmited_regular_ward_care_bool',\n       'Patient_addmited_semi-intensive_care_bool',\n       'Patient_addmited_intensive_care_bool', 'grau_doenca'], axis=1)\ny = df['grau_doenca']\nX_scaled = StandardScaler().fit_transform(X)","ececf464":"from imblearn.over_sampling import SMOTE\nos = SMOTE(random_state=0)\nX_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_scaled, y, test_size=0.3, random_state=30)\ncolumns = X.columns\n\nos_data_X, os_data_y = os.fit_sample(X_train_all, y_train_all)\nos_data_X = pd.DataFrame(data=os_data_X,columns=columns)\nos_data_y = pd.DataFrame(data=os_data_y)\n\nX_train_all = os_data_X\ny_train_all = os_data_y['grau_doenca']\n\n\nprint('items no dataset de teste')\n{dic[i]:j for i,j in  y_test_all.value_counts().items()}","46e1e3f0":"X_train = X_train_all.copy()\ny_train_ = y_train_all.copy()\nX_test= X_test_all.copy()\ny_test_= y_test_all.copy()\n\n# one hot encode outputs\ny_train = to_categorical(y_train_)\ny_test = to_categorical(y_test_)\ny_test_=y_test_.values\ncount_classes = y_test.shape[1]\nprint(count_classes)","e6400d03":"# build the model\nmodel = Sequential()\nmodel.add(Dense(250, activation='tanh', input_dim=(X_train.shape[1])))\nmodel.add(Dropout(.2))\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dropout(.3))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(count_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n\n#Fitting The Mdoel\nhistory = model.fit(X_train, y_train, epochs=150, verbose = True)","b819fc30":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['loss'])\nplt.title('model metrics')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['accuracy', 'loss'], loc='upper left')\nplt.show()","9149c191":"pred_train = model.predict(X_train)\nscores = sklearn.metrics.accuracy_score(y_train_, pred_train.argmax(axis=1))\nprint('Accuracy on training data: {:.2f}%'.format(scores))   \n \npred_test = model.predict(X_test)\nscores2 = sklearn.metrics.accuracy_score(y_test_, pred_test.argmax(axis=1))\nprint('Accuracy on test data: {:.2f}%'.format(scores2))","e5c33db7":"names=['sem doen\u00e7a',\n'covid leve',\n'internado sem covid',\n'covid grave']\nplot_confusion_matrix2(y_test_, pred_test.argmax(axis=1), figsize= (12,12),names=names)","dddec9f5":"explainer = shap.KernelExplainer(model.predict, X_train[:150])","6aea20c1":"shap_values = explainer.shap_values(X_test[:150], nsamples=150)","b42ca111":"shap.summary_plot(shap_values[0], X_test[:150])\n","9c13bf62":"shap.summary_plot(shap_values[1], X_test[:150])\n","b420a486":"shap.summary_plot(shap_values[2], X_test[:150])\n","b989c7a5":"shap.summary_plot(shap_values[3], X_test[:150])","dcef701a":"# Tratando Nulls","96e15ed2":"## MODELO 01 - Random Forest","9451ac11":"## Modelo DeepLearning","ad47a31d":"# Modelos","f73cb0c2":"# Feature importance with SHAP","7172d56b":"# Imports","4e88f8f1":"# Libs","82c39f1f":"# Deep Learning to predict admission to general ward, semi-intensive unit or intensive care unit","6e7e06e3":"# Funcs"}}