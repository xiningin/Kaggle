{"cell_type":{"752a4fd2":"code","6655f87b":"code","b128446d":"code","82116e60":"code","568aa0fe":"code","bfe2922f":"code","fe8cccaf":"code","17a719eb":"code","4a972cbc":"code","f2f3f1bf":"code","54321818":"code","cc3ab92e":"code","25aacb1b":"code","eb55d73c":"code","cfa3c56f":"code","68aa5ad7":"code","5a12d965":"code","5c35f98b":"code","87e00b0f":"code","1eff535a":"code","284eacaa":"code","6cc4f3b7":"code","868d73de":"code","8966344c":"code","15b4ba8b":"code","b90565e6":"code","677d3332":"code","4e766d56":"code","df6da190":"code","9842d4ba":"code","8d3b3110":"code","ccd80567":"code","961ca640":"code","24c72992":"code","e8777fef":"code","660ccb01":"code","8e3fea46":"markdown"},"source":{"752a4fd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6655f87b":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","b128446d":"sub = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","82116e60":"test_data.isna().sum()","568aa0fe":"train_data.head()","bfe2922f":"# Identifying missing value\ntrain_data.isna().sum()\/len(train_data)","fe8cccaf":"# As cabin has almost 77% missing data , we better remove it \ntrain_data = train_data.drop(\"Cabin\",axis=1)\ntest_data = test_data.drop(\"Cabin\",axis=1)","17a719eb":"# Remove passenger id \ntrain_data = train_data.drop(\"PassengerId\",axis=1)","4a972cbc":"train_data.Embarked.isna().sum() # Has only 2 missing so dropping these rows will cause no harm","f2f3f1bf":"train_data = train_data[train_data.Embarked.notna()]","54321818":"# Getting description of train data\ntrain_data.describe()","cc3ab92e":"#set(train_data.Name.str.split(\",\").apply(lambda x:x[1].split()[0]))\n#train_data[\"Title\"] = train_data.Name.str.split(\",\").apply(lambda x:x[0].strip())","25aacb1b":"median = train_data.groupby([\"Sex\",\"Pclass\"]).median()[\"Age\"].reset_index()\nmedian_test = test_data.groupby([\"Sex\",\"Pclass\"]).median()[\"Age\"].reset_index()","eb55d73c":"# The median of the group will be replaced with the median of group of Sex and Pclass\nmissing_train_data = train_data[train_data.Age.isna()]\nmissing_train_data_cp = missing_train_data.drop(columns = [\"Age\"])[[\"Sex\",\"Pclass\"]]\nnon_missing_train_data = train_data[~train_data.Age.isna()]\nmissing_train_data[\"Age\"] = missing_train_data_cp.merge(median,on=[\"Sex\",\"Pclass\"]).Age\ntrain_data = pd.concat([missing_train_data,non_missing_train_data])\nprint(train_data.head(3))\n\n\n# The median of the group will be replaced with the median of group of Sex and Pclass\nmissing_test_data = test_data[test_data.Age.isna()]\nmissing_test_data_cp = missing_test_data.drop(columns = [\"Age\"])[[\"Sex\",\"Pclass\"]]\nnon_missing_test_data = test_data[~test_data.Age.isna()]\nmissing_test_data[\"Age\"] = missing_test_data_cp.merge(median,on=[\"Sex\",\"Pclass\"]).Age\ntest_data = pd.concat([missing_test_data,non_missing_test_data])\nprint(\"Test Data-> \\n\",test_data.head())","cfa3c56f":"# Impute rest of the missing data by median\ntrain_data.Age.fillna(median.Age.median(),inplace=True)\nprint(\"Tain data impute\",train_data.isna().sum())\n\n# Impute rest of the missing data by median\ntest_data.Age.fillna(median_test.Age.median(),inplace=True)\nprint(\"Test Data Impute\",test_data.isna().sum())","68aa5ad7":"# Replacing Fare with the median value of fares of that class\npclass_ = int(test_data[test_data.Fare.isna()].Pclass.values)\ntest_data.Fare.fillna(test_data[test_data.Pclass == pclass_].Fare.median(),inplace=True)","5a12d965":"test_data.isna().sum()","5c35f98b":"# Plotting correlation matrix\ntrain_data.corr()","87e00b0f":"# Dropping Name and ticket column as they have high number of unique values\ntrain_data = train_data.drop(columns=[\"Ticket\",\"Name\"])\ntest_data = test_data.drop(columns=[\"Ticket\",\"Name\"])","1eff535a":"for col in train_data:\n    print(\"% of unique values in \"+col+\" -> \",len(set(train_data[col]))\/len(train_data))\n    print(\"Class frequency in each column-> \\n\",train_data[col].value_counts().head(5))","284eacaa":"# converting Categourical data to one hot encoding\ntrain_data[\"Sex\"] = train_data[\"Sex\"].map({\"male\":1,\"female\":0})\ntest_data[\"Sex\"] = test_data[\"Sex\"].map({\"male\":1,\"female\":0})","6cc4f3b7":"train_data =pd.concat([train_data,pd.get_dummies(train_data.Embarked,prefix=\"Emb\",drop_first=True)],axis=1)\ntest_data =pd.concat([test_data,pd.get_dummies(test_data.Embarked,prefix=\"Emb\",drop_first=True)],axis=1)","868d73de":"train_data = train_data.drop(columns = [\"Embarked\"])\ntest_data = test_data.drop(columns = [\"Embarked\"])","8966344c":"# Data for Random forest and decision tree models \nX_train_tree = train_data.drop(columns=['Survived'])\ny_train_tree = train_data.Survived\n\nX_test_tree = test_data.drop(\"PassengerId\",axis=1)","15b4ba8b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold,KFold","b90565e6":"rf = RandomForestClassifier(n_estimators=800,min_samples_split=10,min_samples_leaf=1)\nsf = StratifiedKFold(n_splits=5,shuffle=True)","677d3332":"X_train_tree1 = X_train_tree.reset_index(drop=True)\ny_train_tree1 = y_train_tree.reset_index(drop=True)\n\nfor train,test in sf.split(X_train_tree1,y_train_tree1):\n    x_train = X_train_tree1.iloc[train]\n    y_train = y_train_tree1.iloc[train]\n    x_test = X_train_tree1.iloc[test]\n    y_test = y_train_tree1.iloc[test]\n    rf.fit(x_train,y_train)\n    print(rf.score(x_test,y_test))","4e766d56":"#rf.fit(X_train_tree,y_train_tree)\ny_tran_pred_tree = rf.predict(X_train_tree)","df6da190":"rf.score(X_train_tree,y_train_tree)","9842d4ba":"cm = confusion_matrix(y_train_tree,y_tran_pred_tree)\nConfusionMatrixDisplay(cm).plot()","8d3b3110":"# True positive rate \ncm[1][1]\/(cm[1][1]+cm[1][0])","ccd80567":"# False positive rate\ncm[1][1]\/(cm[1][1]+cm[0][1])","961ca640":"# Predicting the score \ny_pred = rf.predict(X_test_tree)","24c72992":"# Submission of results\nresult = test_data[[\"PassengerId\"]]\nresult[\"Survived\"] = y_pred","e8777fef":"result.to_csv(\"\/kaggle\/working\/titanic_submission.csv\",index=False)","660ccb01":"result.to_csv(\"submission.csv\",index=False)","8e3fea46":"Now we have 2 columns with missing value in which one is embarked and one is Age"}}