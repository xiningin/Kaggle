{"cell_type":{"12cb2e9d":"code","bb8e4a64":"code","9c42c795":"code","87fe2cdd":"code","2c0d9ae7":"code","c0c9d246":"code","1d6634c1":"code","7398ca75":"code","42d82369":"code","0d9ec5e1":"code","5742a1b6":"code","32b36a57":"code","55ce5833":"code","65598423":"code","357de3be":"markdown","0be49286":"markdown","356d2918":"markdown","6dee3e34":"markdown","136e3a02":"markdown","2cc209fb":"markdown","5d96d47b":"markdown","b2520e28":"markdown","45d0d5a5":"markdown","fe7b04b0":"markdown","abb5d74a":"markdown","fd4de381":"markdown","8d9133c1":"markdown","f997a934":"markdown","fff3f199":"markdown"},"source":{"12cb2e9d":"# Import relevant modules\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nsns.set(style ='white', palette = 'colorblind')","bb8e4a64":"# Load the Data\ndf = pd.read_csv(\"..\/input\/fish-market\/Fish.csv\")\ndf.head(10)","9c42c795":"print(\"The species were {}.\".format(list(set(df.Species))))\nprint('There are {} observations in our dataframe.'.format(len(df)))","87fe2cdd":"# Plotting Distributions of Columns\nplt.rcParams['xtick.labelsize'] = 16\nplt.rcParams['ytick.labelsize'] = 16\nfig, ax = plt.subplots(2, 3, sharey = True, figsize = [16, 10])\nfig.suptitle('Distribution of Fish Measurements', fontsize = 26)\nfig.subplots_adjust(hspace = 0.2)\ni = 0\nj = 0\nfor col in df.iloc[:, 1:]:\n    ax[i, j].hist(df[col], bins = 20, histtype = 'bar')\n    ax[i, j].set_title(col, fontsize = 20)\n    ax[i, j].text(0.65, 0.9, r\"$\\mu$ = {: .1f}\".format(df[col].mean()), transform = ax[i, j].transAxes, fontsize = 16)\n    ax[i, j].text(0.65, 0.8, r\"$\\sigma$ = {: .1f}\".format(df[col].std()), transform = ax[i, j].transAxes, fontsize = 16)\n    if j < 2:\n        j += 1\n    else:\n        i += 1\n        j -= 2","2c0d9ae7":"df.describe().round(2)","c0c9d246":"# Replace Zeroes with Median Weight of all fish\nmedian_weight = df['Weight'][df['Weight']!=0].median()\ndf['Weight'] = df['Weight'].mask(df['Weight'] == 0, median_weight)","1d6634c1":"df['Weight'].describe().round(2)","7398ca75":"# Correlation Matrix of Features\ncorrs = df.corr().round(2)\nplt.figure(figsize = (10, 8))\nsns.heatmap(corrs, cmap = 'Greys')","42d82369":"df = df.drop(['Length1', 'Length2'], axis = 1)","0d9ec5e1":"df['wid_for_height'] = df['Width'] \/ df['Height'] \ndf['weight_for_height'] = df['Weight'] \/ df['Height']","5742a1b6":"x = df.iloc[:, 1:]\ny = df.iloc[:, 0]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle = True, random_state = 123)","32b36a57":"#Multinomial Logit\nlog = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial', max_iter = 20000)\nlog.fit(x_train, y_train)\npreds = log.predict(x_test)\nspecies_list = log.classes_.tolist()\nconf_mx = confusion_matrix(y_test, preds, species_list)\nprint(\"\\t\\t Model Metrics\")\nprint(\"Precision: \\t\", precision_score(y_test, preds, average = 'weighted').round(2))\nprint(\"Recall: \\t\", recall_score(y_test, preds, average = 'weighted').round(2))\nprint(\"F1 Score: \\t\", f1_score(y_test, preds, average = 'weighted').round(2))","55ce5833":"randompreds = np.random.choice(list(set(df['Species'])), size = len(y_test))\nall_perch = np.full(len(y_test), fill_value = 'Perch')\n\nprint(\"If I randomly guessed, the precision score would be {}.\".format(precision_score(y_test, randompreds, average = 'weighted')))\nprint(\"If I guessed all fish were perch, it would be {}.\".format(precision_score(y_test, all_perch, average = 'weighted')))","65598423":"# Matrix of errors\nrow_sums = conf_mx.sum(axis = 1, keepdims = True)\nnorm_conf_mx = conf_mx \/ row_sums\nnp.fill_diagonal(norm_conf_mx, 0)\n\nfig = plt.figure(figsize = (10, 8))\nfig.tight_layout()\nax = fig.add_subplot(111)\ncax = ax.matshow(norm_conf_mx, cmap = 'gist_heat_r')\nplt.title('Proportion of Incorrect Predictions\\nfor Fish Classifier', fontsize = 16)\nfig.colorbar(cax)\nplt.gca().xaxis.tick_bottom()\nax.set_xticklabels([''] + species_list, rotation = 30)\nax.set_yticklabels([''] + species_list)\nplt.xlabel('Predicted Class', fontsize = 16)\nplt.ylabel('Actual Class', fontsize = 16)","357de3be":"# Introduction\nThe goal of this notebook is to train a multi-class classifier to identify fish based on their body measurements. This was just a fun way to practice multi-class classification.\n\n![](https:\/\/i.pinimg.com\/originals\/db\/6a\/94\/db6a94f49205d32b2404cbb6cf562721.jpg)","0be49286":"# Training the Model\n\nNow I will split the data into training and testing sets, using an 80-20 split.","356d2918":"Here we see that the minimum weight in the sample is 0.00, which is obviously impossible. One of the fish had an incorrect weight entered. I am going to replace the zero value with the median weight for all of the fish.","6dee3e34":"# Some Feature Engineering\n\nLet's take a look at how correlated our features are with each other. Because we have several columns in the dataframe with different measurements of length, these may all be highly collinear, and it therefore might not be necessary to keep them all in our model. Since our dataframe only has 159 observations in it, it wouldn't hurt to reduce the number of features we include in our classifier, if possible.","136e3a02":"It is clear that there are two fish that the model is struggling to identify. 100% of whitefish were misclassified as perch, but this is not too surprising because there were only 6 whitefish in the entire sample and only 1 in the test data.    \n\nBut the model also struggled alot to correctly classify Roach, which was the third largest group of fish in the dataset.  Here, the model incorrectly classified roaches as perch for about 60% of the cases in which the fish was actually a roach.","2cc209fb":"Now we can check again to make sure it is all in order:","5d96d47b":"As I suspected, the three length metrics are highly correlated with one another. I therefore chose to only keep `Length3`, which is the diagonal length of the fish.","b2520e28":"I tried out a few different classification models, including K-Nearest Neighbors, KMeans, and multinomial logistic regression. The multinomial logit was easily the most successful, so I will only present those results here.","45d0d5a5":"I then chose to construct a couple of other features to that may make the model a bit more discriminant for classifying between the seven types of fish. The new features are width-for-height (the width divided by the height) and the weight-for-height (the weight divided by the height). I tried other combinations but these were the most successful.","fe7b04b0":"# Conclusion\n\nBased on pretty basic data, the model was reasonably strong at classifying the fish into their proper categories. It was pretty bad at classifying roaches or whitefish though. So, if this model was needed for that purpose, it would require more fine-tuning before it would be ready to be used for prediction. Thanks for joining me in this little multi-classification problem and I hope you enjoyed it!","abb5d74a":"The distribution for weight is a bit skewed, which isn't inherently a problem, but I will take a closer look at the summary statistics.","fd4de381":"These data have six different body measurements for seven fish species.","8d9133c1":"So at least we know the classifier is doing a lot better than naive guessing! But it is also important to know if there are specific classes that the model is struggling to predict.","f997a934":"In the end, 89% of my predictions were of the correct class, and 88% of the true classes were correctly identified. Not too bad for a model with very basic information!    \n\nAs a frame of reference, let's do two little experiments to gauge how well this model is doing. First, how do these compare to just randomly guessing one of the seven fish? And second, what if I only guessed that every fish was a Perch, which was the most common fish in the sample?","fff3f199":"Since there aren't many features in this dataset, I will first take a look at their distributions."}}