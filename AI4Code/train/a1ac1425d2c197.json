{"cell_type":{"4d44e15a":"code","35e444a1":"code","c40625a6":"code","b4dcd1fb":"code","2e2a7611":"code","a4d2fc85":"code","3c5afd88":"code","d0043d3b":"code","874cde4a":"code","2b71ba16":"code","8b326599":"code","287347d2":"code","fe63632e":"code","dd07dfbf":"code","acaef02f":"code","81fe3545":"code","9e4b8bb5":"code","17e9240d":"code","3ada7f7e":"code","936bbdcd":"code","667e539d":"code","073999a5":"code","cabba747":"code","da680bf6":"code","639988d5":"code","8444c11e":"code","ddbadb6b":"code","fc96dd56":"code","44021121":"code","799b3f3e":"code","43482a4a":"code","dc385731":"code","929f364d":"code","0b19da26":"markdown","3badabaa":"markdown","cf2a0e1c":"markdown","e55ee0c3":"markdown","b92b762b":"markdown","f159c56b":"markdown","027c8969":"markdown","bcc526eb":"markdown","aba71697":"markdown","79f169cd":"markdown","b9404221":"markdown","f4faac09":"markdown","c227803a":"markdown","ff47ffdf":"markdown","50680ca2":"markdown","09cda656":"markdown","659aba60":"markdown","2ce4873a":"markdown","fcc58bf3":"markdown","110fa18d":"markdown","bd63479b":"markdown","700605ca":"markdown","9a4e5207":"markdown","d3a4f09c":"markdown","f7e94fde":"markdown","66a21d38":"markdown"},"source":{"4d44e15a":"import pandas as pd\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, GlobalAvgPool1D, Dropout, Embedding,Bidirectional, Flatten, CuDNNLSTM, Conv1D, MaxPooling1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nimport random\nimport matplotlib.pyplot as plt","35e444a1":"training_set = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")","c40625a6":"training_set = training_set.drop(['id'], axis=1)","b4dcd1fb":"print(\"Number of training records :\",len(training_set))\nprint(\"Columns :\")\nfor i in training_set:\n    print(\"\\t\"+i)","2e2a7611":"#plot 2\ncolumns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']  \ncount_ones = []\nfor i in columns:\n    count_ones.append(training_set[training_set[i]==1][i].count())\ny_pos = np.arange(len(columns))\nplt.bar(y_pos, count_ones, align=\"center\", alpha=0.5)\nplt.xticks(y_pos, columns)\nplt.ylabel(\"Number of Ones\")\nplt.title(\"Number of Ones\")\nplt.show()\n\n#plot 1\ncount_zeros = []\nfor i in columns:\n    count_zeros.append(training_set[training_set[i]==0][i].count())\ny_pos = np.arange(len(columns))\nplt.bar(y_pos, count_zeros, align=\"center\", alpha=0.5)\nplt.xticks(y_pos, columns)\nplt.ylabel(\"Number of Zeros\")\nplt.title(\"Number of Zeros\")\nplt.show()","a4d2fc85":"for i in range(1):\n    j = random.randint(0, 10000)\n    print(training_set.values[j])\n    ","3c5afd88":"f = open(\"..\/input\/glove-embeddings\/glove.6B.300d.txt\")","d0043d3b":"embedding_matrix = {}\nfor line in tqdm(f):\n    temp = line.split(\" \")\n    word = temp[0]\n    embeds = np.array(temp[1:], dtype='float32')\n    embedding_matrix[word] = embeds","874cde4a":"x = training_set['comment_text']\ny = training_set[columns]","2b71ba16":"token = Tokenizer(num_words=20000)\ntoken.fit_on_texts(x)\nseq = token.texts_to_sequences(x)","8b326599":"padded_seq = pad_sequences(seq, maxlen=40)","287347d2":"vocab_size = len(token.word_index)+1\nprint(vocab_size)","fe63632e":"embeddings = np.zeros((vocab_size, 300))\nfor word, i in tqdm(token.word_index.items(), position=0):\n    embeds = embedding_matrix.get(word)\n    if embeds is not None:\n        embeddings[i] = embeds","dd07dfbf":"model1 = Sequential()\nmodel1.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel1.add(Conv1D(128, 5, activation='relu'))\nmodel1.add(MaxPooling1D(5))\nmodel1.add(Conv1D(128, 5, activation='relu'))\nmodel1.add(MaxPooling1D(3))\nmodel1.add(Flatten())\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(Dense(1, activation='sigmoid'))\n\nmodel1.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel1.summary()","acaef02f":"model1.fit(padded_seq, training_set['toxic'], epochs=3, batch_size=32, validation_split=0.2)","81fe3545":"model2 = Sequential()\nmodel2.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel2.add(Conv1D(128, 5, activation='relu'))\nmodel2.add(MaxPooling1D(5))\nmodel2.add(Conv1D(128, 5, activation='relu'))\nmodel2.add(MaxPooling1D(3))\nmodel2.add(Flatten())\nmodel2.add(Dense(128, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))\n\nmodel2.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel2.summary()","9e4b8bb5":"model2.fit(padded_seq, training_set['severe_toxic'], epochs=2, batch_size=32, validation_split=0.2)","17e9240d":"model3 = Sequential()\nmodel3.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel3.add(Conv1D(128, 5, activation='relu'))\nmodel3.add(MaxPooling1D(5))\nmodel3.add(Conv1D(128, 5, activation='relu'))\nmodel3.add(MaxPooling1D(3))\nmodel3.add(Flatten())\nmodel3.add(Dense(128, activation='relu'))\nmodel3.add(Dense(1, activation='sigmoid'))\n\nmodel3.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel3.summary()","3ada7f7e":"model3.fit(padded_seq, training_set['obscene'], epochs=2, batch_size=32, validation_split=0.2)","936bbdcd":"model4 = Sequential()\nmodel4.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel4.add(Conv1D(128, 5, activation='relu'))\nmodel4.add(MaxPooling1D(5))\nmodel4.add(Conv1D(128, 5, activation='relu'))\nmodel4.add(MaxPooling1D(3))\nmodel4.add(Flatten())\nmodel4.add(Dense(128, activation='relu'))\nmodel4.add(Dense(1, activation='sigmoid'))\n\nmodel4.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel4.summary()","667e539d":"model4.fit(padded_seq, training_set['threat'], epochs=1, batch_size=32, validation_split=0.2)","073999a5":"model5 = Sequential()\nmodel5.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel5.add(Conv1D(128, 5, activation='relu'))\nmodel5.add(MaxPooling1D(5))\nmodel5.add(Conv1D(128, 5, activation='relu'))\nmodel5.add(MaxPooling1D(3))\nmodel5.add(Flatten())\nmodel5.add(Dense(128, activation='relu'))\nmodel5.add(Dense(1, activation='sigmoid'))\n\nmodel5.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel5.summary()","cabba747":"model5.fit(padded_seq, training_set['insult'], epochs=2, batch_size=32, validation_split=0.2)","da680bf6":"model6 = Sequential()\nmodel6.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel6.add(Conv1D(128, 5, activation='relu'))\nmodel6.add(MaxPooling1D(5))\nmodel6.add(Conv1D(128, 5, activation='relu'))\nmodel6.add(MaxPooling1D(3))\nmodel6.add(Flatten())\nmodel6.add(Dense(128, activation='relu'))\nmodel6.add(Dense(1, activation='sigmoid'))\n\nmodel6.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel6.summary()","639988d5":"model6.fit(padded_seq, training_set['identity_hate'], epochs=1, batch_size=32, validation_split=0.2)","8444c11e":"test_set = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv')","ddbadb6b":"x_test = test_set['comment_text']\ntoken = Tokenizer(num_words=20000)\ntoken.fit_on_texts(x_test)\nseq = token.texts_to_sequences(x_test)","fc96dd56":"test_padded_seq = pad_sequences(seq, maxlen=40)","44021121":"toxic = model1.predict(test_padded_seq)\nsevere_toxic = model2.predict(test_padded_seq)\nobscene = model3.predict(test_padded_seq)\nthreat = model4.predict(test_padded_seq)\ninsult = model5.predict(test_padded_seq)\nidentity_hate = model6.predict(test_padded_seq)","799b3f3e":"toxic = [1 if i>=0.5 else 0 for i in toxic]\nsevere_toxic = [1 if i>=0.5 else 0 for i in severe_toxic]\nobscene = [1 if i>=0.5 else 0 for i in obscene]\nthreat = [1 if i>=0.5 else 0 for i in threat]\ninsult = [1 if i>=0.5 else 0 for i in insult]\nidentity_hate = [1 if i>=0.5 else 0 for i in identity_hate]","43482a4a":"id = test_set['id']","dc385731":"df = pd.DataFrame({'id':id,\n                   'toxic':toxic,\n                   'severe_toxic':severe_toxic,\n                   'obscene':obscene,\n                   'threat':threat,\n                   'insult':insult,\n                   'identity_hate':identity_hate})","929f364d":"df.to_csv(\"submission.csv\", index=False)","0b19da26":"**Model for TOXIC **","3badabaa":"# Toxic Comments Classification","cf2a0e1c":"**Now, let's take a look at how many examples of training data do we have satifying our labels.**","e55ee0c3":"We will need to pad our sequences. This is useful for making all the sentences of the same size.","b92b762b":"**Model for INSULT**","f159c56b":"For the words which may not be present in glove word embeddings, we will be using zero vectos.","027c8969":"**Model for THREAT**","bcc526eb":"We will now create word embeddings for words in our dictionary.","aba71697":"**Model for SEVERE_TOXIC**","79f169cd":"**Let's have a look at some of the data examples.**","b9404221":"Since, we have text data and the semantics of text are very important to correctly classify them as being toxic, severe_toxic, and so on, we will be using pre-trained word embeddings as inputs.","f4faac09":"**Okay, so enough of analyzing the data. Now, let's preprocess our data for training.**","c227803a":"## Getting Word Embeddings","ff47ffdf":"**Model fot IDENTITY_HATE**","50680ca2":"## Getting the dataset","09cda656":"**Model for OBSCENE**","659aba60":"In this program, we are going to classify a comment in 6 different labels such as *toxic, severe_toxic, obsene*, etc.","2ce4873a":"The training set consists of 159571 records and 8 columns. The columns are very much self explanatory.<br>\n<br>\n>The **id** contains the id of our training records and is quite irrelevant for the training purpose, so we will eventually end up dropping this column.<br>\n>Then we have **comment_text**, which consists of the text of comment text.<br>\n>Rest other columns have values 0\/1 based on whether the comment text qualifies for that label.\n<br>\n","fcc58bf3":"From the above plots, we can see that our training set has more records which are negative(or have '0' value). We have around 15000 records which have are positively classified as toxic and around 140000 which are classified as negative. The worst case is with the threat class, here we have aroung 500-700 positive records only, while having 160000 negative records. So, our data is could be highly biased towards predicting a comment as negative toxicity for most of the classes.","110fa18d":"Since we have to make predictions for six classes, let's have a separate classifier for each of them.","bd63479b":"**Let's now create x and y datasets where 'x' will be the values we will use for making predictions and 'y', the values to predict.**","700605ca":"## Defining our models","9a4e5207":"## Let's make some predictions now","d3a4f09c":"## Analyzing the dataset","f7e94fde":"Now, we will tokenize our texts and convert them to sequences.","66a21d38":"## Importing libraries"}}