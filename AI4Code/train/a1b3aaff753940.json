{"cell_type":{"c30ae431":"code","a35fb714":"code","0b0079f3":"code","b0e78162":"code","119f3f32":"code","68bfefa1":"code","ef1f926a":"code","5bf5158c":"code","24492496":"code","ebcd5373":"code","1f2998c3":"code","27641b06":"code","d13a7914":"markdown","afb9922d":"markdown","0a291c0c":"markdown"},"source":{"c30ae431":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a35fb714":"import pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier","0b0079f3":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ntrain.head()","b0e78162":"#\u0443\u0434\u0430\u043b\u0438\u043c \u043d\u0435 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u044b \u0438 \u043d\u0435 \u0432\u0430\u0436\u043d\u044b\u0439 \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 PassengerId\nX = train.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\ny = train.Survived\nX.head()","119f3f32":"#\u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0443\u043b\u0435\u0432\u044b\u0445 \u044f\u0447\u0435\u0435\u043a \u0432 \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u0445\ntrain.isnull().sum()","68bfefa1":"#\u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430 \u043c\u0435\u0434\u0438\u0430\u043d\u043d\u044b\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c\nX = X.fillna({'Age': X.Age.median()})\n\n#\u043f\u0435\u0440\u0435\u0432\u043e\u0434 \u043e\u0441\u0442\u0430\u0432\u0448\u0438\u0445\u0441\u044f \u0432\u0430\u0436\u043d\u044b\u0445 \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0432 \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439 \u0444\u043e\u0440\u043c\u0430\u0442\nX = pd.get_dummies(X)\nX.head()","ef1f926a":"#\u043f\u0440\u043e\u0434\u0435\u043b\u0430\u0435\u043c \u0442\u0435 \u0436\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u043c\u0438\ntest.head()","5bf5158c":"test.isnull().sum()","24492496":"#\u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c ID \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nID = test.PassengerId\ntest = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\ntest = test.fillna({'Age': test.Age.median(), 'Fare': test.Fare.median()})\ntest = pd.get_dummies(test)","ebcd5373":"dt = RandomForestClassifier(criterion='entropy')\nparametres = {'n_estimators':range(40,51,2),'max_depth':range(1,13,2),'min_samples_leaf':range(1,8),'min_samples_split':range(2,10,2)}\nsearch = GridSearchCV(dt, parametres, cv=5, n_jobs=-1)\nsearch.fit(X, y)","1f2998c3":"#\u043e\u0431\u0443\u0447\u0438\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u043d\u043e\u043c \u043b\u0443\u0447\u0448\u0435\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0435\nbest_clf = search.best_estimator_\nbest_clf.fit(X, y)\npred = best_clf.predict(test)\npred","27641b06":"#\u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043f\u043e\u043b\u0443\u0447\u0438\u0432\u0448\u0435\u0435\u0441\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0432 \u0444\u0430\u0439\u043b\npd.DataFrame({\"PassengerId\": ID, \"Survived\": pred}).to_csv('submission.csv', index=False, header=True)","d13a7914":"<h2> \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 <\/h2>\n<h3> \u0414\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0431\u0440\u0430\u043d RandomForestClassifier. \u041f\u043e\u0434\u0431\u043e\u0440 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e GridSearchCV, \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u044b \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u0435 parametres.","afb9922d":"<h2> \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a","0a291c0c":"<h2> \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445"}}