{"cell_type":{"57e8c4c8":"code","eb0c8095":"code","79e8ba45":"code","d36e783d":"code","32b6febb":"code","ba7a7c2f":"code","1442b82b":"code","c342c739":"code","ce80fedd":"code","4711169a":"code","135219a0":"code","44120ac8":"code","c4b56ad4":"code","982ba500":"code","2cfac171":"code","78e01408":"code","21f90ea0":"code","9e99e708":"code","9619dc0f":"code","0501183a":"code","dd1efdaf":"code","f2f051a5":"code","8cd59945":"code","babdcb92":"code","6c0a37d0":"code","b1533485":"code","282f15b3":"code","243fbdff":"code","4a9fb174":"code","16398e1f":"code","eb12fd90":"code","b34f4f5d":"code","a9ed7fff":"code","70dad418":"code","419f9b47":"code","0c34bbcb":"code","3aa6313a":"code","5fbd6f56":"code","a0eb0086":"code","eafa4518":"code","915d28cb":"code","f502bf57":"code","befe6059":"code","8a33b77e":"code","27c2b6cf":"code","be821625":"code","01f07001":"code","a0ff04cd":"code","37521db4":"markdown","78a5e1c9":"markdown","ba230593":"markdown","1923f741":"markdown","e097e3bb":"markdown","c3fe9a08":"markdown","224ab7cc":"markdown","5106b428":"markdown","589f7757":"markdown","1a452493":"markdown","eb7c6934":"markdown","eb0d597f":"markdown","4982065d":"markdown","9a4d45b1":"markdown","a2cec888":"markdown","b2786eb9":"markdown","6d197a4b":"markdown"},"source":{"57e8c4c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","eb0c8095":"#importing the genome_scores dataset to get the tag scores\nscores=pd.read_csv('..\/input\/genome_scores.csv')\nscores.columns","79e8ba45":"#importing the link dataset to get the tag scores\nlink=pd.read_csv('..\/input\/link.csv')\nlink.columns","d36e783d":"# we need all the columns\nscores.head()","32b6febb":"# import movie data set and look at columns\nmovie = pd.read_csv(\"..\/input\/movie.csv\")\nmovie.columns","ba7a7c2f":"# what we need is that movie id and title\nmovie = movie.loc[:,[\"movieId\",\"title\"]]\nmovie.head(10)","1442b82b":"#importing rating data set\nrating = pd.read_csv(\"..\/input\/rating.csv\")\nrating.columns","c342c739":"# what we need is that user id, movie id and rating\nrating = rating.loc[:,[\"userId\",\"movieId\",\"rating\"]]\nrating.head(10)","ce80fedd":"# then merge movie and rating data\ndata = pd.merge(movie,rating,on='movieId')","4711169a":"# now lets look at our data \ndata.head()","135219a0":"data.shape","44120ac8":"#getting the no. of times each user rated\n\na=data['userId'].value_counts().reset_index()\na.rename(columns={'userId':'count','index':'userId'},inplace = True)\na","c4b56ad4":"a.shape","982ba500":"#we will consider only those users who have rated for more than 300 times\n\na = a[a['count']>300]\na.shape","2cfac171":"#we will consider only those selected users only in our analysis\n\ndata = data[data['userId'].isin(a['userId'])]\ndata.shape","78e01408":"# lets make a pivot table in order to recommend easily\nptable = data.pivot_table(index = [\"movieId\"],columns = [\"userId\"],values = \"rating\")\nptable.head()","21f90ea0":"ptable=ptable.fillna(0)","9e99e708":"ptable.head()","9619dc0f":"#importing the necessary package\n\nfrom sklearn.neighbors import NearestNeighbors","0501183a":"model=NearestNeighbors(algorithm='brute')","dd1efdaf":"model.fit(ptable)","f2f051a5":"def recommends(movie_id):\n    distances,suggestions=model.kneighbors(ptable.loc[movie_id,:].values.reshape(1,-1),n_neighbors=16)\n    return ptable.iloc[suggestions[0]].index","8cd59945":"l=movie[movie['movieId'].isin(ptable.index)]","babdcb92":"l[l['title'].str.contains('avengers',case=False)]","6c0a37d0":"recommendation=recommends(89745)","b1533485":"#getting the recommend movie's Id\n\nrecommendation","282f15b3":"#getting the movie names from it's Id\n\nfor movie_id  in recommendation[1:]:\n    print(movie[movie['movieId']==movie_id]['title'].values[0])","243fbdff":"l[l['title'].str.contains('harry potter',case=False)]","4a9fb174":"recommendation=recommends(4896)\n\n#getting the movie names from it's Id\n\nfor movie_id  in recommendation[1:]:\n    print(movie[movie['movieId']==movie_id]['title'].values[0])","16398e1f":"scores.head()","eb12fd90":"scores.shape","b34f4f5d":"movie_tag_pivot=pd.pivot_table(columns='tagId',index='movieId',values='relevance',data=scores)","a9ed7fff":"movie_tag_pivot","70dad418":"movie_tag_pivot.fillna(0,inplace=True)","419f9b47":"model1=NearestNeighbors(algorithm='brute')","0c34bbcb":"model1.fit(movie_tag_pivot)","3aa6313a":"def recommend(movie_id):\n    distances,suggestions=model1.kneighbors(movie_tag_pivot.loc[movie_id,:].values.reshape(1,-1),n_neighbors=16)\n    return movie_tag_pivot.iloc[suggestions[0]].index","5fbd6f56":"#we will merge the link and scores dataset now\n\nmovie = pd.merge(movie,link,on='movieId')","a0eb0086":"scores_movie=movie[movie['movieId'].isin(movie_tag_pivot.index)]","eafa4518":"scores_movie[scores_movie['title'].str.contains('avengers',case=False)]","915d28cb":"recommendations=recommend(89745)","f502bf57":"recommendations","befe6059":"for movie_id  in recommendations[1:]:\n    print(movie[movie['movieId']==movie_id]['title'].values[0])","8a33b77e":"scores_movie[scores_movie['title'].str.contains('harry potter',case=False)]","27c2b6cf":"recommendation=recommend(4896)\n\nfor movie_id  in recommendation[1:]:\n    print(movie[movie['movieId']==movie_id]['title'].values[0])","be821625":"import pickle as pkl","01f07001":"#for tag-user recommendation\n\npkl.dump(model1,open('engine_tu.pkl','wb'))\npkl.dump(movie_tag_pivot,open('movie_tag_pivot_table_tu.pkl','wb'))\npkl.dump(scores_movie,open('movie_names_tu.pkl','wb'))","a0ff04cd":"#one problem will persist while dumping the rating vs user pivot table. that is we have seen that the data is huge in that table and we might face space problem in this IDE.\n\n#thus we will consider the dump file of tag-user only.","37521db4":"**Getting inside my algorithm**","78a5e1c9":"Function to recommend movies","ba230593":"Checking for the movie 'Avengers'","1923f741":"Doing the same procedures in this case again.","e097e3bb":"Our data is finally reduced.\n\nNow we will go on with our predictions.","c3fe9a08":"Model Dumping","224ab7cc":"* As it can be seen from table above, rows are movie Id, columns are user Id and values are ratings","5106b428":"# We see both the models are predicting more or less the same type of things.\n\n(Anyway from an user perspective, our recommendation is working good.)","589f7757":"# Introduction\nRecommender Systems:\n1. Rating-user Based Recommender Systems\n2. Tag-user Based Recommender Systems\n\n**The purpose of recommender systems is recommending new things that are not seen before from people.**\n\nWe will use Collaborative Filtering while recommending\n\n**Collaborative filtering means to recommend according to the combination of your experience and experiences of other people.**","1a452493":"We will check for Harry Potter now","eb7c6934":"We see a huge amount data. All of these data will take a lot of time to work with. So we will consider only those data which will help us to recommend and will not take un-neccessary space.\n\nHere we have a lot of user-id. We will consider only those users that has rated for more than 300 movies.\n\n**Reason -** A person with good movie knowledge has definitely seen and rated more movies, and we will consider only those users.\n\n\n*This process will automatically reduce my data without making problem to my analysis and prediction.*","eb0d597f":"**Will feel all the NaN values with 0**","4982065d":"Predictions for the movie avengers","9a4d45b1":"2.Starting with tag-user recommendation system","a2cec888":"getting the movie code and will recommend using the code itself","b2786eb9":"Importing the necessary data-set","6d197a4b":"*1.Starting with* **rating-user recommendation system.**"}}