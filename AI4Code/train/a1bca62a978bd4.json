{"cell_type":{"c4609460":"code","9c8380ce":"code","d1b9edf2":"code","af87d848":"code","284def31":"code","82447532":"code","6ef1c684":"code","5d7af60f":"code","b7d39a29":"code","d4ad7091":"code","9086d1c0":"code","944b0edb":"code","fac24ac2":"code","92a11c6f":"code","0c463b4b":"code","31015eb5":"code","5c8f3914":"code","36957729":"code","680f67ef":"code","3117294f":"code","7d58a62e":"code","f6330d8d":"code","9ee3370f":"code","7d93218d":"markdown","84528702":"markdown","301cb13c":"markdown","638f6f57":"markdown","967a34cf":"markdown","4685fced":"markdown","6c43c6fd":"markdown","4a06ba6b":"markdown","ee910ec9":"markdown","dc08534e":"markdown"},"source":{"c4609460":"BASE_PATH = \"..\/input\/chaii-hindi-and-tamil-question-answering\/\"\n!ls -l $BASE_PATH","9c8380ce":"import pandas as pd\ndf_train = pd.read_csv(BASE_PATH + \"train.csv\")\ndf_test = pd.read_csv(BASE_PATH + \"test.csv\")\ndf_sub = pd.read_csv(BASE_PATH + \"sample_submission.csv\")\n\n# How many training and test samples have been provided?\nprint(f\"Training shape  : {df_train.shape}\")\nprint(f\"Test shape      : {df_test.shape}\")\nprint(f\"Submission shape: {df_sub.shape}\")","d1b9edf2":"df_train.head()","af87d848":"# This is the full df_test, not only the head\ndf_test","284def31":"# Same here\ndf_sub","82447532":"df_train.head()","6ef1c684":"for _, row in df_train.iterrows():\n    assert row.answer_text in row.context","5d7af60f":"display(df_train['language'].value_counts())\nprint()\ndf_train['language'].value_counts(normalize=True).round(2)","b7d39a29":"df_train['language'].value_counts(normalize=True).round(2).plot.bar(alpha=0.5, rot=0, color=['red', 'green'], figsize=(10, 5));","d4ad7091":"df_train['question'].str.split().str.len().hist(figsize=(10, 5), alpha=0.5)\npd.DataFrame(df_train['question'].str.split().str.len().describe().round(2)).T","9086d1c0":"df_train['answer_text'].str.split().str.len().hist(figsize=(10, 5), alpha=0.5)\npd.DataFrame(df_train['answer_text'].str.split().str.len().describe().round(2)).T","944b0edb":"df_train['context'].str.split().str.len().hist(figsize=(10, 5), alpha=0.5)\npd.DataFrame(df_train['context'].str.split().str.len().describe().round(2)).T","fac24ac2":"# You can uncomment this line to see the size of the largest context:\n# df_train.loc[df_train['context'].str.split().str.len() == 10259, 'context'].iloc[0]","92a11c6f":"import string\n\ndef transliterate_hindi(st):\n    HINDI_MAP = { '\u0950' : 'o\u1e41', '\u0900' : '\u1e41', '\u0901' : '\u1e43', '\u0902' : '\u1e43', '\u0903' : '\u1e25', '\u0905' : 'a', '\u0906' : '\u0101', '\u0907' : 'i', '\u0908' : '\u012b', '\u0909' : 'u', '\u090a' : '\u016b', '\u090b' : 'r\u0325', '\u0960' : ' r\u0325\u0304', '\u090c' : 'l\u0325', '\u0961' : ' l\u0325\u0304', '\u090d' : '\u00ea', '\u090e' : 'e', '\u090f' : 'e', '\u0910' : 'ai', '\u0911' : '\u00f4', '\u0912' : 'o', '\u0913' : 'o', '\u0914' : 'au', '\u093e' : '\u0101', '\u093f' : 'i', '\u0940' : '\u012b', '\u0941' : 'u', '\u0942' : '\u016b', '\u0943' : 'r\u0325', '\u0944' : ' r\u0325\u0304', '\u0962' : 'l\u0325', '\u0963' : ' l\u0325\u0304', '\u0945' : '\u00ea', '\u0947' : 'e', '\u0948' : 'ai', '\u0949' : '\u00f4', '\u094b' : 'o', '\u094c' : 'au', '\u0915\u093c' : 'q', '\u0915' : 'k', '\u0916\u093c' : 'x', '\u0916' : 'kh', '\u0917\u093c' : '\u0121', '\u0917' : 'g', '\u097b' : 'g', '\u0918' : 'gh', '\u0919' : '\u1e45', '\u091a' : 'c', '\u091b' : 'ch', '\u091c\u093c' : 'z', '\u091c' : 'j', '\u097c' : 'j', '\u091d' : 'jh', '\u091e' : '\u00f1', '\u091f' : '\u1e6d', '\u0920' : '\u1e6dh', '\u0921\u093c' : '\u1e5b', '\u0921' : '\u1e0d', '\u0978' : '\u1e0d', '\u097e' : 'd', '\u0922\u093c' : '\u1e5bh', '\u0922' : '\u1e0dh', '\u0923' : '\u1e47', '\u0924' : 't', '\u0925' : 'th', '\u0926' : 'd', '\u0927' : 'dh', '\u0928' : 'n', '\u092a' : 'p', '\u092b\u093c' : 'f', '\u092b' : 'ph', '\u092c' : 'b', '\u097f' : 'b', '\u092d' : 'bh', '\u092e' : 'm', '\u092f' : 'y', '\u0930' : 'r', '\u0932' : 'l', '\u0933' : '\u1e37', '\u0935' : 'v', '\u0936' : '\u015b', '\u0937' : '\u1e63', '\u0938' : 's', '\u0939' : 'h', '\u093d' : '\\'', '\u094d' : '', '\u093c' : '', '\u0966' : '0', '\u0967' : '1', '\u0968' : '2', '\u0969' : '3', '\u096a' : '4', '\u096b' : '5', '\u096c' : '6', '\u096d' : '7', '\u096e' : '8', '\u096f' : '9', '\ua8f3' : '\u1e41', '\u0964' : '.', '\u0965' : '..', ' ' : ' '}\n    return ''.join(HINDI_MAP.get(c, c)  for c in st)\n\ndef transliterate_tamil(st):\n    text = \"\"\"\u0b85 a \u0b8e e \u0b86 \u0101 \u0b8f \u0113 \u0b87 i \u0b90 ai \u0b88 \u012b \u0b92 o \u0b89 u \u0b93 \u014d \u0b8a \u016b \u0b94 au \u0b83 ka \u0bae ma \u0b95 ka \u0baf ya \u0b99 \u1e45a \u0bb0 ra \u0b9a ca \u0bb2 la \u0b9e \u00f1a \u0bb5 va \u0b9f \u1e6da \u0bb4 la \u0ba3 \u1e47a \u0bb3 \u1e37a \u0ba4 ta \u0bb1 ra\u0ba8 na \u0ba9 na \u0baa pa \u0b9c ja \u0bb8 sa \u0bb6 \u015ba \u0bb9 ha \u0bb7 \u1e63a\"\"\".split()\n    TAMIL_MAP = dict(zip(text[0::2], text[1::2]))\n    TAMIL_MAP.update({t: t for t in ' ?.1234567890'+string.ascii_lowercase})\n    return ''.join(TAMIL_MAP.get(c.lower(), '') for c in st)\n\ndef transliterate(df_in, columns=['question', 'context', 'answer_text']):\n    df = df_in.copy()\n    for c in columns:\n        df.loc[df['language'] == 'hindi', c] = df.loc[df['language'] == 'hindi', c].apply(transliterate_hindi)\n        df.loc[df['language'] == 'tamil', c] = df.loc[df['language'] == 'tamil', c].apply(transliterate_tamil)        \n    return df","0c463b4b":"df_trans = transliterate(df_train)","31015eb5":"df_train.head(5)","5c8f3914":"df_trans.head(5)","36957729":"df_train[df_train['language'] == 'hindi'].head(5)","680f67ef":"df_trans[df_trans['language'] == 'hindi'].head(5)","3117294f":"# This is a name. Adolph Meyr or something\ndf_trans[df_trans['language'] == 'hindi']['answer_text'].iloc[0]","7d58a62e":"df_train[df_train['language'] == 'hindi']['answer_text'].iloc[0]","f6330d8d":"df_train.iloc[1112]['answer_text']","9ee3370f":"df_trans.iloc[1112]['answer_text']","7d93218d":"It increases a little the readability. See for example:","84528702":"# Length of text columns (number of words)\n\n| Field | Average | Min | Max |\n| -- | -- | -- | -- |\n| question|  7 | 3 | 22| \n| answer|  7 | 1 | 51| \n| context|  1694 | 24 | 10259| \n\nThe context is huge! I don't know how good models work on this sequence length regime. We will see...","301cb13c":"# Let's take a look at `df_train`\n\nIt has a `question` and a `context` (the inputs) and an `answer_text` (the output) plus the `answer_start` position indicator, which is a common practice as we mentioned in the [first notebook](https:\/\/www.kaggle.com\/julian3833\/1-the-competition-qa-for-qa-noobs#Question-Answering).\n\nNote that the submission only requires the `PredictionString` and not the position of it.","638f6f57":"And this is a date (October 27, 1605):","967a34cf":"<img src=\"https:\/\/i.imgur.com\/RFR6UZX.jpg\" width=\"100%\"\/>\n\n# 2. The Dataset\n### [chaii - Hindi and Tamil Question Answering](https:\/\/www.kaggle.com\/c\/chaii-hindi-and-tamil-question-answering) - A quick overview for QA noobs\n\nHi and welcome! This is the second kernel of the series `chaii - Hindi and Tamil Question Answering - A quick overview for QA noobs`.\n\n**In this short kernel, we will go over the competition dataset very briefly and provide a transliteration table .**\n\n\n---\n\nThe entire series consists of the following notebooks:\n1. [The competition](https:\/\/www.kaggle.com\/julian3833\/1-the-competition-qa-for-qa-noobs)\n2. _[The dataset](https:\/\/www.kaggle.com\/julian3833\/2-the-dataset-qa-for-qa-noobs) (This notebook)_\n3. [The metric (Jaccard)](https:\/\/www.kaggle.com\/julian3833\/3-the-metric-jaccard-qa-for-qa-noobs) \n4. [Exploring Public Models](https:\/\/www.kaggle.com\/julian3833\/4-exploring-public-models-qa-for-qa-noobs\/)\n5. [\ud83e\udd47 XLM-Roberta + Torch's extra data [LB: 0.749]](https:\/\/www.kaggle.com\/julian3833\/5-xlm-roberta-torch-s-extra-data-lb-0-749)\n6. [\ud83e\udd17 Pre & post processing](https:\/\/www.kaggle.com\/julian3833\/6-pre-post-processing-qa-for-qa-noobs\/)\n\nThis is an ongoing project, so expect more notebooks to be added to the series soon. Actually, we are currently working on the following ones:\n* Exploring Public Models Revisited\n* Reviewing `squad2`, `mlqa` and others\n* About `xlm-roberta-large-squad2`\n* Own improvements\n\n---","4685fced":"As we explained in the first notebook, the answer is always a substring of the context:","6c43c6fd":"# Small-data regime\n\nThe training dataset is tiny! It looks like the addition of datasets might be an important aspect of this competition as it goes by.\n\nRegarding the size of the test and submission: these are just placeholders, as explained in [this section](https:\/\/www.kaggle.com\/julian3833\/1-the-competition-qa-for-qa-noobs#Code-requirements) of the [first notebook](https:\/\/www.kaggle.com\/julian3833\/1-the-competition-qa-for-qa-noobs). It is a common practice in `Kernel-only` competitions like this one.","4a06ba6b":"## Language percentages\n`67% hindi`, \n`33% tamil`","ee910ec9":"I created a short notebook with the transliteration code so it's easy to copy-and-paste the code: [Quick and Dirty Transliteration Tables](https:\/\/www.kaggle.com\/julian3833\/quick-and-dirty-transliteration-tables).\n\n## What's next?\n\nEnough of the data! Let's check the `Jaccard metric` in the [next notebook](https:\/\/www.kaggle.com\/julian3833\/3-the-metric-jaccard-qa-for-qa-noobs) so we can move to the Public Models.\n\nIf you want to see more EDA, there are some incredible notebooks around. These are the ones I liked the most, but there are many more!\n* [EDA Chaii Gogogo \ud83d\ude05](https:\/\/www.kaggle.com\/vaby667\/eda-chaii-gogogo)\n* [chaii-explore_the_data](https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data)\n* [ChAii: The Beginning: EDA, Wordclouds](https:\/\/www.kaggle.com\/hoshi7\/chaii-the-beginning-eda-wordclouds)\n\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n## Remember to upvote the notebook if you found it useful! \ud83e\udd17\n","dc08534e":"# Some quick and dirty transliterations\n\nI saw some beautiful EDAs with [wordclouds](https:\/\/www.kaggle.com\/hoshi7\/chaii-the-beginning-eda-wordclouds) in `Hindi` and `Tamil` and thought immediately: a transliteration could be something good to do.\n\n\n# What is transliteration?  `\u0905\u0915\u094d\u0924\u0942\u092c\u0930` -> `akt\u016bbr` (October)\n\nTransliteration is phonetically replacing one alphabet with another. It allows or improves phonetic readability and, sometimes, interpretability too.\n\nSee this example:\n\nThis is how you write `police` in Russian: `\u043f\u043e\u043b\u0438\u0446\u0438\u044f`.\n\nAnd this is how it looks when you transliterate Cyrillic to Latin: `politsiya`\n\nIt's still Russian, but much more familiar, isn't it?\nThe transliteration is a simple phonetic mapping from one alphabet to another. Here, the mapping was:\n```python\n{'\u043f': 'p', '\u043e': 'o', '\u043b': 'l', '\u0438': 't', '\u0446': 's', '\u0438': 'i', '\u044f': 'ya'}\n```\n\n\n# Origin of the tables\n\nI couldn't find well-established python packaged for that, at least fast. But I did find the following tables:\n\nFor Hindi:\n* https:\/\/pandey.github.io\/posts\/transliterate-devanagari-to-latin.html\n\nFor Tamil:\n* https:\/\/www.loc.gov\/catdir\/cpso\/romanization\/tamil.pdf\n\n\nNote that few characters are dropped (this is actually quick and dirty)\n\n\n# Usage\n\nThe usage is quite straightforward. See examples below for some good surprises!\n```python\ndf_trans = transliterate(df_train)\n```"}}