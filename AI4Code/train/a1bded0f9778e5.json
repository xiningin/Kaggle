{"cell_type":{"9f899834":"code","8cd21394":"code","fe975bf4":"code","8fdc2e79":"code","83f15428":"code","ea82ec2f":"code","23053d88":"code","13d0db5f":"code","475505e4":"code","f47b2087":"code","536a6739":"code","36428dc8":"code","f2952a64":"code","11ed7474":"code","94c30580":"code","d9abe6d9":"code","d9c8a6fb":"code","7b7feed1":"code","c00a0848":"code","e09b6c19":"code","2783e135":"code","2231886f":"code","29b19a4c":"code","b71d0c9f":"code","7275831a":"code","9c39b3cc":"code","86d828ec":"code","84afe0ff":"code","724b4ddc":"code","16c98603":"code","8beb7ca1":"code","3a92d479":"code","9707c17c":"code","3713cf1c":"code","ef59ab96":"code","9b147bd0":"code","7809132a":"code","165ca3da":"code","52448e3c":"code","6d69254a":"code","8a241f67":"code","364b592c":"code","5ba782f2":"code","4de62183":"code","2bd1000b":"code","fc06ce5b":"code","0b48f870":"code","92fe24de":"code","64e75716":"code","8329f6bf":"code","d66fe8bf":"code","b880ea1b":"code","26f6f431":"code","a1ebf7ce":"code","04653494":"code","d9628a4f":"code","55edd65b":"code","fe2ebfd8":"code","c4741498":"code","d4ebde95":"code","5bf07943":"code","a973bba6":"code","342df903":"code","f5b8ef55":"markdown","6b0dda41":"markdown","3c51ff9e":"markdown","239d6395":"markdown","cf93100b":"markdown","a426a910":"markdown","60cf35fc":"markdown","05a3cdf1":"markdown","26916acf":"markdown","b7141741":"markdown","81410845":"markdown","cf9d716b":"markdown"},"source":{"9f899834":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","8cd21394":"df=pd.read_csv('..\/input\/blood-pressure-dataset\/Blood_Pressure_data.csv')","fe975bf4":"print(df.shape)\nprint(df.dtypes)","8fdc2e79":"df.info()","83f15428":"df.head(10).T","ea82ec2f":"df.tail(10).T","23053d88":"print(\"Majority of the population is Caucasians followed by African American:\")\ndf['cast'].value_counts().plot(kind='bar',color = list('ygbkrmc'))","13d0db5f":"print(\"Gender data comprises of 55% male whereas 45% are female: \")\ndf['gender'].value_counts().plot(kind='bar',color = list('bgrkymc'))","475505e4":"print(\"Details of age data are as follows:\")\ndf['age group'].value_counts().plot(kind='bar',color = list('ygbkrmc'))","f47b2087":"print(\"Majority of weight data was missing so we had to drop that column:\")\ndf['weight'].value_counts().plot(kind='bar',color = list('ygbkrmc'))","536a6739":"print(\"Max Glu Serum:\")\ndf['max_glu_serum'].value_counts().plot(kind='bar',color = list('ygbkrmc'))","36428dc8":"print(\"A1C Result:\")\ndf['A1Cresult'].value_counts().plot(kind='bar',color = list('gybcrkm'))","f2952a64":"print(\"There is change in medicines for almost 40\u201345% of the patients:\")\ndf['change'].value_counts().plot(kind='bar',color = list('gybcrkm'))\n","11ed7474":"print(\"It seems that almost 75% of the patients were taking the medicines:\")\ndf['Med'].value_counts().plot(kind='bar',color = list('ybgcrkm'))","94c30580":"print(\"Time spent in  hospital:\")\ndf['time_in_hospital'].value_counts().plot(kind='line',color = 'y')","d9abe6d9":"print(\"We can see from the following scatter plot that how random is the data of diagnosis columns:\")\nplt.figure(figsize=(30, 15))\ndiag1=df['diag_1']\ndiag2=df['diag_2']\nplt.scatter(diag1,diag2)\nplt.show()","d9c8a6fb":"print(\"Insulin dosage:\")\nplt.figure(figsize=(15, 7))\nplt.xlabel(\"Insulin\")\ndf['insulin'].value_counts().plot(kind='pie',autopct=\"%0.2f%%\")","7b7feed1":"print(df['label'].value_counts())","c00a0848":"df=df.drop(['id','patient_no','weight','payer_code','medical_specialty'],1)","e09b6c19":"df.head(10).T","2783e135":"df['gender'].value_counts()","2231886f":"df=df[df['gender']!='Unknown\/Invalid']","29b19a4c":"df['gender'].value_counts()","b71d0c9f":"df['age group'].value_counts()","7275831a":"df['age group'] = df['age group'].str[1:].str.split('-',expand=True)[0]\ndf['age group'] = df['age group'].astype(int)","9c39b3cc":"df['age group'].value_counts()","86d828ec":"df.head(20).T","84afe0ff":"df = df.drop(['citoglipton','examide'],1)","724b4ddc":"df.head().T","16c98603":"for col in df.columns:\n    if df[col].dtype == 'int64':\n         print(col,df[col][df[col] == '?'].count())","8beb7ca1":"for col in df.columns:\n    if df[col].dtype == object:\n         print(col,df[col][df[col] == '?'].count())","3a92d479":"df=df.fillna(0)\ndf=df.replace(['?'],0)","9707c17c":"df.head(10).T","3713cf1c":"df['label'] = df['label'].replace('>5', 1)\ndf['label'] = df['label'].replace('<30', 1)\ndf['label'] = df['label'].replace('NO', 0)","ef59ab96":"diag_cols = ['diag_1','diag_2','diag_3']\nfor col in diag_cols:\n    df[col] = df[col].str.replace('E','-')\n    df[col] = df[col].str.replace('V','-')","9b147bd0":"a={'None':0,'Norm':100,'>200':200,'>300':300}\ndf[\"max_glu_serum\"]=df[\"max_glu_serum\"].map(a)","7809132a":"b={'None':0,'Norm':5,'>7':7,'>8':8}\ndf[\"A1Cresult\"]=df[\"A1Cresult\"].map(b)","165ca3da":"c={'No':-1,'Ch':1}\ndf[\"change\"]=df[\"change\"].map(c)","52448e3c":"d={'No':-1,'Yes':1}\ndf[\"Med\"]=df[\"Med\"].map(d)","6d69254a":"tests_cols = ['metformin','repaglinide','nateglinide','chlorpropamide','glimepiride','acetohexamide','glipizide','glyburide',\n 'tolbutamide','pioglitazone','rosiglitazone','acarbose','miglitol','troglitazone','tolazamide','insulin','glyburide-metformin',\n'glipizide-metformin','glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone']\nreplace_words={'Up':10,'Down':-10,'Steady':0,'No':-20}\nfor col in tests_cols:\n    df[col] = df[col].replace(replace_words)","8a241f67":"e={'Male':0,'Female':1}\ndf[\"gender\"]=df[\"gender\"].map(e)","364b592c":"f={'Caucasian':0,'AfricanAmerican':1,'Hispanic':2,'Other':2,'Asian':2}\ndf[\"cast\"]=df[\"cast\"].map(f)","5ba782f2":"df.dropna(inplace=True)","4de62183":"df['cast'].value_counts()","2bd1000b":"df['gender'].value_counts()","fc06ce5b":"df.head(10).T","0b48f870":"df['cast'] = df['cast'].astype('Int64')","92fe24de":"df","64e75716":"X=df.drop(\"label\",1)\nX.dtypes","8329f6bf":"X=pd.get_dummies(X)\nX","d66fe8bf":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print (X.head(10).T)","b880ea1b":"y=df['label']\ny","26f6f431":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Lasso,LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\nlogit = LogisticRegression(C=1, penalty='l1', solver='liblinear')\nlogit.fit(X_train, y_train)","a1ebf7ce":"print('Shape of X_train = ', X_train.shape)\nprint('Shape of y_train = ', y_train.shape)\nprint('Shape of X_test = ', X_test.shape)\nprint('Shape of y_test = ', y_test.shape)","04653494":"logit_pred = logit.predict(X_test)\n\npd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(logit_pred, name = 'Predict'), margins = True)","d9628a4f":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report \nprint (\"Accuracy : \" , accuracy_score(y_test,logit_pred)*100)                                                          \nprint(\"Report : \\n\", classification_report(y_test, logit_pred))\nprint(\"F1 Score : \",f1_score(y_test, logit_pred, average='macro')*100)\n\nAccuracy_lg=(accuracy_score(y_test,logit_pred)*100)\nF1_Score_lg=(f1_score(y_test, logit_pred, average='macro')*100)","55edd65b":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=1000)\ndtree.fit(X_train, y_train)","fe2ebfd8":"dtree_pred = dtree.predict(X_test)\npd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(dtree_pred, name = 'Predict'), margins = True)","c4741498":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report \nprint (\"Accuracy : \" , accuracy_score(y_test,dtree_pred)*100)  \nprint(\"Report : \\n\", classification_report(y_test, dtree_pred))\nprint(\"F1 Score : \",f1_score(y_test, dtree_pred, average='macro')*100)\n\nAccuracy_dt=(accuracy_score(y_test,dtree_pred)*100)\nF1_Score_dt=(f1_score(y_test, dtree_pred, average='macro')*100)","d4ebde95":"from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nclf1=RandomForestClassifier()\nclf1.fit(X_train,y_train)\npred=clf1.predict(X_test)\nclf1.score(X_test,y_test)","5bf07943":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report \nprint (\"Accuracy : \" , accuracy_score(y_test,pred)*100)  \nprint(\"Report : \\n\", classification_report(y_test, pred))\nprint(\"F1 Score : \",f1_score(y_test, pred, average='macro')*100)\n\nAccuracy_rf=(accuracy_score(y_test,pred)*100)\nF1_Score_rf=(f1_score(y_test, pred, average='macro')*100)","a973bba6":"plt.figure(figsize=(15, 8))\nax = plt.subplot(111)\n\nmodels = ['Logistic Regression', 'Decision Tree', 'Random Forests']\nvalues = [Accuracy_lg, Accuracy_dt, Accuracy_rf]\nmodel = np.arange(len(models))\n\nplt.bar(model, values, align='center', width = 0.17, alpha=0.7, color = 'yellow', label= 'accuracy')\nplt.xticks(model, models)\n           \n\n           \nax = plt.subplot(111)\n\nmodels = ['Logistic Regression', 'Decision Tree', 'Random Forests']\nvalues = [F1_Score_lg, F1_Score_dt, F1_Score_rf]\nmodel = np.arange(len(models))\n\nplt.bar(model+0.15, values, align='center', width = 0.17, alpha=0.7, color = 'blue', label = 'F1 Score')\nplt.xticks(model, models)\n\nplt.ylabel('Machine Learning Models')\nplt.title('Model Comparison')\n    \n# removing the axis on the top and right of the plot window\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.legend()\n\nplt.show()","342df903":"predictions = pd.DataFrame(columns=['LogisticRegression',\n                                    'DecisionTree',\n                                    'RandomForest'])\npredictions['LogisticRegression'] = logit_pred\npredictions['DecisionTree'] = dtree_pred\npredictions['RandomForest'] = pred\n\n# Lets take a look at the end of the dataframe\npredictions.head(20).T","f5b8ef55":"# Data Preprocessing Part 2","6b0dda41":"# Logistic Regression","3c51ff9e":"# Random Forest","239d6395":"# Exploratory Data Analysis","cf93100b":"**You have to perform a classification on provided dataset of Heart Attack prediction.\nFor that prediction, first of all you have to preprocess dataset and convert it into appropriate numeric form. Then you have to perform any Machine Learning model for the prediction of Label. Here are some outcomes of the project that I expect from that I expect from you.**\n1. Preprocessing\n2. Applying more than 3 Machine Learning algorithms for the prediction and apply majority voting concept for the final output. Majority voting means to take Predicted labels from all applied classifiers and assign final label according to majority vote.\n3. Exploratory Data Analysis: Lot of graphs to understand the Data insights.\n4. Accuracy, F Score more than 65 percent. The more the F-score, more marks will be awarded.\n\n**You can use Numpy, Pandas, Sklearn, Matplotlib library for that.**","a426a910":"## Random Forest","60cf35fc":"## Decision Tree ","05a3cdf1":"# Data Preprocessing Part 1","26916acf":"## Logistic Regression","b7141741":"# Modelling","81410845":"* Upvote my work and follow me fore more notebooks like this one.\n* Drop your queries in the comment section.","cf9d716b":"# Decision Tree"}}