{"cell_type":{"2dd6c8c2":"code","3bc85f0a":"code","0d03c45b":"code","357d8b28":"code","31818fc4":"code","d803d809":"code","6d1fdcca":"code","78eeec6b":"code","3bf821cf":"code","e5670095":"code","2711baeb":"code","d986a0cb":"code","557457b0":"code","a517861b":"code","f34013f5":"code","f4fe9d14":"code","275c6e0b":"code","23a125bf":"code","7ab9c073":"code","83fef8b6":"code","e7e2e924":"code","81eb75f9":"code","db96b658":"code","91c6597e":"code","06297961":"code","9ecc40bd":"code","822d38c8":"code","ea30598c":"code","e4f7674c":"code","eaac6262":"code","f842e1d7":"code","3b2c0911":"code","7bc9696a":"code","db544e41":"code","660bb2f2":"code","30340d9d":"code","ba97595d":"code","54d2fdc0":"code","8d067b9d":"markdown","0a765946":"markdown","982c98ab":"markdown","e1c2eba6":"markdown","eabfd41f":"markdown","66b4f617":"markdown","0530eade":"markdown","544070a2":"markdown","e9c028cb":"markdown","2a83dd93":"markdown","c3392897":"markdown","adbbd6fb":"markdown"},"source":{"2dd6c8c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3bc85f0a":"import numpy as np\nimport pandas as pd\nfrom random import randint\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom time import time","0d03c45b":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","357d8b28":"df","31818fc4":"target = df['target']","d803d809":"df.head()","6d1fdcca":"df.isna().sum()","78eeec6b":"df.groupby('thal').count()","3bf821cf":"for i in range(0, 303):\n  if df['sex'][i] == 1:\n   df['sex'][i] = 'Yes'\n  else:\n   df['sex'][i] = 'No'\nfor i in range(0, 303):\n  if df['cp'][i] == 0:\n   df['cp'][i] = 'Zero CP'\n  elif df['cp'][i] == 1:\n   df['cp'][i] = 'First CP'\n  elif df['cp'][i] == 2:\n   df['cp'][i] = 'Second CP'\n  else:\n   df['cp'][i] = 'Third CP'\nfor i in range(0, 303):\n  if df['fbs'][i] == 1:\n   df['fbs'][i] = 'Yes FBS'\n  else:\n   df['fbs'][i] = 'No FBS'\nfor i in range(0, 303):\n  if df['restecg'][i] == 1:\n   df['restecg'][i] = 'Yes ECG'\n  else:\n   df['restecg'][i] = 'No ECG'\nfor i in range(0, 303):\n  if df['exang'][i] == 1:\n   df['exang'][i] = 'Yes EXANG'\n  else:\n   df['exang'][i] = 'No EXANG'\nfor i in range(0, 303):\n  if df['slope'][i] == 0:\n   df['slope'][i] = 'Zero SLOPE'\n  elif df['slope'][i] == 1:\n   df['slope'][i] = 'First SLOPE'\n  else:\n   df['slope'][i] = 'Second SLOPE'\nfor i in range(0, 303):\n  if df['thal'][i] == 0:\n   df['thal'][i] = 'Zero THAL'\n  elif df['thal'][i] == 1:\n   df['thal'][i] = 'First THAL'\n  elif df['thal'][i] == 2:\n   df['thal'][i] = 'Second THAL'\n  else:\n   df['thal'][i] = 'Third THAL'","e5670095":"df","2711baeb":"df = pd.get_dummies(df, columns=[\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\"], drop_first=True)","d986a0cb":"df.head()","557457b0":"df_target = df.drop('target', axis = 1)","a517861b":"df_target['target'] = target","f34013f5":"df_final = df_target","f4fe9d14":"df_final.head()","275c6e0b":"X = df_final.iloc[:, :-1].values\ny = df_final.iloc[:, -1].values","23a125bf":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","7ab9c073":"X_train_sep = X_train[:, 0:5]\nX_test_sep = X_test[:, 0:5]","83fef8b6":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sep = sc.fit_transform(X_train_sep)\nX_test_sep = sc.transform(X_test_sep)","e7e2e924":"X_train = X_train[:, 5:]\nX_test = X_test[:, 5:]","81eb75f9":"X_train = np.append(X_train, X_train_sep, axis=1)\nX_test = np.append(X_test, X_test_sep, axis=1)","db96b658":"model = Sequential([Dense(units=2,input_shape=(18,),activation='relu'),\n                    Dense(units=5,activation='relu'),\n                    keras.layers.Dropout(0.5),\n                    Dense(units=10,activation='relu'),\n                    keras.layers.Dropout(0.5),\n                    Dense(units=2,activation='sigmoid')])","91c6597e":"model.summary()","06297961":"tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)","9ecc40bd":"model.compile(optimizer=Adam(learning_rate=0.01),loss='sparse_categorical_crossentropy',metrics=['accuracy', 'mse'])","822d38c8":"model.fit(\n      x=X_train\n    , y=y_train\n    , batch_size=20\n    , epochs=1000\n    , shuffle=True\n    , verbose=0\n)","ea30598c":"predictions = model.predict(\n      x=X_test\n    , batch_size=20\n    , verbose=0\n)","e4f7674c":"rounded_predictions = np.argmax(predictions, axis=-1)","eaac6262":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, rounded_predictions)\nprint(cm)\nprint('Test Accuracy: {}%'.format(round(accuracy_score(y_test, rounded_predictions), 4)*100))","f842e1d7":"#Function for plotting Confusion Matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n%matplotlib inline\n\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","3b2c0911":"cm = confusion_matrix(y_true=y_test, y_pred=rounded_predictions)","7bc9696a":"cm_plot_labels = ['No Heart Disease','Heart Disease']","db544e41":"plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","660bb2f2":"#Calculating Senstivity (Basically, this is the metric that is really important for medical diagnosis)\n#Sensitivity is a measure of the proportion of actual positive cases that got predicted as positive (or true positive).\n#Senstivity = True Positives \/ (True Positives + False Negatives)\n\nsenstivity = cm[1][1]\/(cm[1][1]+cm[1][0])\nprint('Senstivity: {}%'.format(round(senstivity, 3)*100))","30340d9d":"#Calculating Specificity\n#Specificity is defined as the proportion of actual negatives, which got predicted as the negative (or true negative).\n#Specificity = True Negatives \/ (True Negatives + False Positives)\n\nspecificity = cm[0][0]\/(cm[0][0]+cm[0][1])\nprint('Specificity: {}%'.format(round(specificity, 3)*100))","ba97595d":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_test, rounded_predictions)\n\nfig, ax = plt.subplots()\nax.plot(fpr, tpr)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Heart Disease Predictor')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","54d2fdc0":"auc(fpr, tpr) #Our model got a decent area under curve value","8d067b9d":"# Setting Model Parameters","0a765946":"# Working on Categorical Variable Columns","982c98ab":"# Splitting the dataset into Train and Test Sets","e1c2eba6":"# Data Scaling","eabfd41f":"# Creating the ANN Model","66b4f617":"# Checking for Missing Values","0530eade":"# Taking the dataset as input","544070a2":"![](https:\/\/media.istockphoto.com\/photos\/illustration-of-heart-medical-concept-picture-id530199842?b=1&k=20&m=530199842&s=170667a&w=0&h=yZdSVVcbin1aQvpMUXzqsyqrRRrQGwkAUeBuR5BOF5A=)","e9c028cb":"# Importing Necessary Libraries","2a83dd93":"# Getting some insights about how the Model actually is!","c3392897":"# Making Predictions on the Test Set","adbbd6fb":"# Training the Model"}}