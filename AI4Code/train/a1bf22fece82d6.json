{"cell_type":{"518e947c":"code","4e2dcd54":"code","56d31d43":"code","adf35245":"code","cb36dddb":"code","5e64cc30":"code","214963d0":"code","e52c91cb":"code","7e28a782":"code","ee7e2dc4":"code","38a8bf9f":"code","24210014":"code","38b64e2b":"code","2f2431ff":"code","d94ab2f2":"code","ebd28cc9":"code","d826d48d":"code","b799ae19":"code","58288980":"code","9b0dcdc9":"code","9db31204":"code","a1ef27e6":"code","b0277c0d":"markdown","ce09fa97":"markdown","e74d4015":"markdown","7f56f24c":"markdown","9bf975fe":"markdown","c95c5cfe":"markdown","f19b010c":"markdown","d610025c":"markdown","e01d7d96":"markdown"},"source":{"518e947c":"#! conda install -c conda-forge gdcm -y","4e2dcd54":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pydicom #as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport ast\nimport seaborn as sns\n\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","56d31d43":"path = '\/kaggle\/input\/siim-covid19-detection\/'\nos.listdir(path)","adf35245":"train_image = pd.read_csv(path+'train_image_level.csv')\ntrain_study = pd.read_csv(path+'train_study_level.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","cb36dddb":"txt = \"The shape of image samples, study samples and sample submissions is: {}, {}, {}\"\nprint(txt.format(train_image.shape, train_study.shape, samp_subm.shape))","5e64cc30":"train_image['StudyInstanceUID'].nunique()","214963d0":"train_study['id'].nunique()","e52c91cb":"studyGroups = train_image.groupby(['StudyInstanceUID']).size().sort_values(ascending=False)\n#groupsDist = studyGroups","7e28a782":"ImsPerStudy = studyGroups.value_counts().sort_values(ascending=False)\nlist(range(11, 17))\nprint(ImsPerStudy)","ee7e2dc4":"fig, ax = plt.subplots(1, 1, figsize=(8, 4))\naxes = ImsPerStudy.plot.bar(rot=0, subplots=True)","38a8bf9f":"train_image.head()","24210014":"train_study.head()","38b64e2b":"samp_subm.head()","2f2431ff":"ts_cols = train_study.columns\n\n# counting the training labels\nm = []\nn = []\nfor i in range(1,5):\n    m.append(train_study[ts_cols[i]].sum())\n    n.append(ts_cols[i])\nprint(m)\nprint(n)","d94ab2f2":"fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n\nax.bar(n, m)\nax.set_xticklabels(n, rotation=30)\nax.set_title('Distribution pneumonia and COVID types')\nplt.grid()\nplt.show()","ebd28cc9":"train_image.columns","d826d48d":"train_image['id'][0]","b799ae19":"print(train_image['label'][0])","58288980":"print(train_image['boxes'][0])","9b0dcdc9":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n    \n# thanks to https:\/\/www.kaggle.com\/tanlikesmath\/siim-covid-19-detection-a-simple-eda","9db31204":"dicom_paths = get_dicom_files(path+'train')\nprint(dicom_paths[:4])","a1ef27e6":"imgs = [dicom2array(path) for path in dicom_paths[:4]]\nplot_imgs(imgs)","b0277c0d":"## Thanks for reading! More to follow!","ce09fa97":"Welcome to the [SIIM-FISABIO-RSNA COVID-19 Detection](http:\/\/www.kaggle.com\/c\/siim-covid19-detection) competition to identify and localize COVID-19 abnormalities on chest radiographs.\n\nThis notebook is a work in progress EDA notebook. \n\n","e74d4015":"## Images","7f56f24c":"There are 6054 unique imaging studies. The majority of these contain one image. train_image contains 6334 samples. 280 more samples than train_study","9bf975fe":"--- If this was useful, please upvote! :)","c95c5cfe":"## Libraries","f19b010c":"## Overview","d610025c":"## Load","e01d7d96":"So we have:\n\n* `train_study_level.csv` - the train study-level metadata, with one row for each study, including correct labels.\n* `train_image_level.csv` - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\n* `sample_submission.csv` - a sample submission file containing all image- and study-level IDs.\n* `train` folder - comprises 6,334 chest scans in DICOM format, stored in paths with the form `study`\/`series`\/`image`\n* `test` folder - The hidden test dataset is of roughly the same scale as the training dataset.\n"}}