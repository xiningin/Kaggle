{"cell_type":{"db30f239":"code","f5740321":"code","053d96bd":"code","718d4bd0":"code","315da678":"code","2b27e8b4":"code","52bc2338":"markdown","20fdba3a":"markdown","e54376b2":"markdown","14e0cc9e":"markdown","36d25cb8":"markdown","ef34166b":"markdown","878ec7f7":"markdown","dcca27e4":"markdown","486490d0":"markdown","1fc2feb4":"markdown","b5e44bdb":"markdown","18fc9132":"markdown","4ee6d366":"markdown","ae9267a6":"markdown","e672e11f":"markdown","8211681d":"markdown"},"source":{"db30f239":"# Importing required libraries\n\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f5740321":"# Read JSON file containing tweets data and removce tweets not in English\n\nraw_tweets = pd.read_json(r'..\/input\/farmers-protest-tweets-dataset-raw-json\/farmers-protest-tweets-2021-2-4.json', lines=True)\nraw_tweets = raw_tweets[raw_tweets['lang']=='en']\nprint(\"Shape: \", raw_tweets.shape)\nraw_tweets.head(5)","053d96bd":"# Normalize 'user' field\n\nusers = json_normalize(raw_tweets['user'])\nusers.drop(['description', 'linkTcourl'], axis=1, inplace=True)\nusers.rename(columns={'id':'userId', 'url':'profileUrl'}, inplace=True)\nusers.head(5)","718d4bd0":"# Create DataFrame and remove duplicates\n\nusers = pd.DataFrame(users)\nusers.drop_duplicates(subset=['userId'], inplace=True)\nprint(\"Shape: \", users.shape)\nusers.head(5)","315da678":"# Transform 'raw_tweets' DataFrame\n\n# Add column for 'userId'\nuser_id = []\nfor user in raw_tweets['user']:\n    uid = user['id']\n    user_id.append(uid)\nraw_tweets['userId'] = user_id\n\n# Remove less important columns\ncols = ['url', 'date', 'renderedContent', 'id', 'userId', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount', 'source', 'media', 'retweetedTweet', 'quotedTweet', 'mentionedUsers']\ntweets = raw_tweets[cols]\ntweets.rename(columns={'id':'tweetId', 'url':'tweetUrl'}, inplace=True)\ntweets.head(5)","2b27e8b4":"# Convert to DataFrame, remove duplicates and keep only English tweets\n\ntweets = pd.DataFrame(tweets)\ntweets.drop_duplicates(subset=['tweetId'], inplace=True)\nprint(\"Shape: \", tweets.shape)\ntweets.head(5)","52bc2338":"Next, let's create the final DataFrame for Twitter users who tweeted using the hashtag \"#FarmersProtest\". I have also dropped duplicate records from the DataFrame based on the field 'userID' as each user must have a unique user ID.\n\nLet's take a look at the shape and first 5 records for the final DataFrame for the Twitter users.","20fdba3a":"# Cleaning raw JSON tweets data scraped using snscrape library","e54376b2":"## Read raw JSON tweets data","14e0cc9e":"Hence, in this notebook we have seen how to perform some transformations to convert the raw JSON data about tweets scraped using snscrape into a more usable falt table form. The single JSON file containing data about tweets is now converted into 2 easier to use DataFrames, 'tweets' and 'users', which contain data about tweets and the users who posted those tweets separately. The 2 DFs can be joined on the 'userId' field.\n\nFrom here, we can save the 'tweets' and 'users' DataFrames as CSV files or continue the analysis using the DFs.","36d25cb8":"In this notebook, I will be discussing how to clean and pre-process raw JSON data about tweets scraped using the Python library snscrape. The JSON data is finally converted to CSV files to make it easier for analysis.\n\nAs an example, I have scraped tweets that contain the hashtag \"#FarmersProtest\" using snscrape which gives a JSON file about the relevant tweets.\n\nsnscrape is a Python library that allows you to scrape tweets easily through the Twitter API without any request limits. I will not be focussing on how to scrape tweets and get the raw JSON tweets data. For an easy-to-follow tutorial on how to use snscrape to scrape tweets through the Twitter API, check out [this Medium blog by Martin Beck](https:\/\/betterprogramming.pub\/how-to-scrape-tweets-with-snscrape-90124ed006af).","ef34166b":"Next, we load the raw JSON tweets data using the function read_json() available in pandas library. Since we are interested in performing analysis using techniques such as NLP, I have only retained tweets that are in the English language. Next, let's take a look at the first 5 records for the raw JSON data.","878ec7f7":"## Introduction","dcca27e4":"## Importing required libraries","486490d0":"Let's start by importing the required libraries. We will be needing Pandas to load and work with JSON data as well as the json_normalize() function in the pandas.io.json package to perform some transformation functions on JSON data.","1fc2feb4":"## Normalize 'user' field in raw_tweets","b5e44bdb":"## Create tweets DF","18fc9132":"We see that 'raw_tweets' has a nested JSON field named 'user'. This field can be normalized for better analysis using the json_normalize() function in the pandas.io.json library. Essentially, semi-structured JSON data is \"normalized\" into a flat table.\n\nFor more info on how to use json_normalize(), check out [the documentation page for pandas.io.json.json_normalize()](https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.17.0\/generated\/pandas.io.json.json_normalize.html).\n\nI have also renamed the fields 'id' to 'userId' and 'url' to 'profileUrl' for it to make more sense and avoid confusion. The fields 'description' and 'linkTcourl' are not important and hence, have been dropped.\n\nLet's take a look at the first 5 records.","4ee6d366":"## Create users DF","ae9267a6":"Finally, I have created the final DataFrame for tweets that contain the hashtag \"#FarmersProtest\". Duplicate records are dropped from the DF based on the unique ID for each tweet (the field 'tweetId').\n\nLet's take a look at the shape and first 5 records of the final tweets DataFrame.","e672e11f":"Next, we will transform the 'raw_tweets' DataFrame to obtain a DataFrame for tweets that contain the hashtag \"#FarmersProtest\". A new field, 'userId' is added which corresponds to the unique ID of the user who posted the particular tweet.\n\nNext, I have retained only the important fields and renamed the fields 'id' to 'tweetId' and 'url' to 'tweetUrl' for it to make more sense and avoid confusion.\n\nLet's take a look at the first 5 records of this DataFrame.","8211681d":"# Conclusion"}}