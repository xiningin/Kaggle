{"cell_type":{"883deaaa":"code","4fae54f5":"code","80d302ab":"code","3627fc72":"code","657febc4":"code","50255a09":"code","15c432c9":"code","ee840803":"code","c3a44760":"code","e600eaf6":"code","f297e572":"code","ac7a6073":"code","508b00ae":"markdown","5b7e62f2":"markdown","77966dba":"markdown","137d2e47":"markdown","9eb11dcd":"markdown","3fd77b06":"markdown","f1cb7664":"markdown"},"source":{"883deaaa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4fae54f5":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","80d302ab":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","3627fc72":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","657febc4":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","50255a09":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_testt = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_testt)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","15c432c9":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","ee840803":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","c3a44760":"lr = LinearRegression()\ndtc = DecisionTreeClassifier()\nsgd = SGDClassifier()\nknn = KNeighborsClassifier(n_neighbors=20, p=2, weights='uniform', algorithm='auto')\n\n#splitting training data set\ntrain, test = train_test_split(train_data, test_size = 418)\n\ny_train = train[\"Survived\"]\ny_test = test[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX_train = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nX_trainlr = pd.get_dummies(train[\"Sex\"])\nX_testlr = pd.get_dummies(test[\"Sex\"])\nlr.fit(X_trainlr, y_train)\n\ndtc.fit(X_train, y_train)\ndtcpred = dtc.predict(X_test)\n\nsgd.fit(X_train, y_train)\nsgdpred = sgd.predict(X_test)\n\nknn.fit(X_train, y_train)\nknnpred = knn.predict(X_test)\n\n#fixing lr predicted values to 1's and 0's\nlrpred = lr.predict(X_testlr)\nlrpredInt = [0]*len(lrpred)\nfor x in range(len(lrpred)):\n    if lrpred[x] > 0.5:\n        lrpredInt[x] = 1\n    else: \n        lrpredInt[x] = 0","e600eaf6":"# Accuracy\nacc = [accuracy_score(y_test, lrpredInt), accuracy_score(y_test, knnpred),\n         accuracy_score(y_test, dtcpred), accuracy_score(y_test, sgdpred)]\nprint(acc)\nmini_value = max(acc)\nmini_index = acc.index(mini_value)\nprint(mini_index)","f297e572":"submit = pd.get_dummies(test_data[features])\ndtcpred = dtc.predict(submit)\nsgdpred = sgd.predict(submit)\nknnpred = knn.predict(submit)\n\nsubmitlr = pd.get_dummies(test_data['Sex'])\nlrpred = lr.predict(submitlr)\nlrpredInt = [0]*len(lrpred)\nfor x in range(len(lrpred)):\n    if lrpred[x] > 0.5:\n        lrpredInt[x] = 1\n    else: \n        lrpredInt[x] = 0","ac7a6073":"if mini_index == 0:\n    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': lrpredInt})\nelif mini_index == 1:\n    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': knnpred})\nelif mini_index == 1:\n    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': dtcpred})\nelse:\n    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': sgdpred})\n\noutput.to_csv('submission.csv', index=False)","508b00ae":"# Tutorial","5b7e62f2":"# Submitting the Best Model","77966dba":"# Creating the models","137d2e47":"# Predicting Test Data","9eb11dcd":"# Imports","3fd77b06":"# Exploratory Data Analysis","f1cb7664":"# Data being loaded"}}