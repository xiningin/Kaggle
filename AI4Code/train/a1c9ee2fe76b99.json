{"cell_type":{"b1041991":"code","9024c001":"code","989b3f3e":"code","de92331b":"code","b8f869cc":"code","5fb3f1a1":"code","30c00287":"code","1454e1c1":"code","d3d123eb":"code","05801665":"markdown","f1b10004":"markdown","8deb77f8":"markdown","e1f25594":"markdown"},"source":{"b1041991":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing","9024c001":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","989b3f3e":"learning_rate = 0.00003\ntraining_epochs = 200\nbatch_size =20\ndrop_prob = 0.3\nScaler = preprocessing.StandardScaler()","de92331b":"train_data=pd.read_csv('train_AI_project.csv').dropna()\n\ntest_data=pd.read_csv('test_AI_porject.csv').dropna()\ntrain_data['Year']=train_data['Year']%10000\/100\nx_train_data=train_data.loc[:,[i for i in train_data.keys()[:-1]]]\ny_train_data=train_data[train_data.keys()[-1]]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\nx_train_data = Scaler.fit_transform(x_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.FloatTensor(y_train_data)\n\ntrain_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)\n\ndata_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)","b8f869cc":"linear1 = torch.nn.Linear(7,256,bias=True)\nlinear2 = torch.nn.Linear(256,256,bias=True)\nlinear3 = torch.nn.Linear(256,1,bias=True)\n\nrelu = torch.nn.ReLU()\ndropout = torch.nn.Dropout(p=drop_prob)\n\ntorch.nn.init.kaiming_normal_(linear1.weight)\ntorch.nn.init.kaiming_normal_(linear2.weight)\ntorch.nn.init.kaiming_normal_(linear3.weight)","5fb3f1a1":"model = torch.nn.Sequential(linear1,relu,dropout,\n                            linear2,relu,dropout,linear3).to(device)","30c00287":"# \uc190\uc2e4\ud568\uc218\uc640 \ucd5c\uc801\ud654 \ud568\uc218\nloss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","1454e1c1":"total_batch = len(data_loader)\nmodel.train()\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        X = X.to(device)\n        Y = Y.to(device)\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning finished')","d3d123eb":"with torch.no_grad():\n\n  test_data['Year']=test_data['Year']%10000\/100\n  x_test_data=test_data.loc[:,[i for i in test_data.keys()[:]]]\n  x_test_data=np.array(x_test_data)\n  x_test_data = Scaler.transform(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n  prediction = model(x_test_data)\n    \ncorrect_prediction = prediction.cpu().numpy().reshape(-1,1)\n\nsubmit=pd.read_csv('submit_sample_AI_project.csv')\n\nfor i in range(len(correct_prediction)):\n  submit['Expected'][i]=correct_prediction[i].item()","05801665":"\uc5ec\uae30 \ubd80\ud130\ub294 \ub3d9\uc77c ","f1b10004":"baseline\uacfc \ucc28\uc774\uc810 :\n\nsequntial \ud560 \ub54c dropout \ud3ec\ud568","8deb77f8":"baseline\uacfc \ucc28\uc774\uc810 :\n\n\ubaa8\ub378 \uc7ac\uc124\uacc4 \n\nlayer 10 --> layer 3\n\nxavier\ucd08\uae30\ud654 --> kaiming\ucd08\uae30\ud654","e1f25594":"https:\/\/youtu.be\/0G0PCn9TaeU\n\nbaseline\uacfc \ucc28\uc774\uc810 :\n\n10\uacc4\uce35 NN ---> 3\uacc4\uce35 NN\n\nmodel squential\ud560 \ub54c dropout\uc740 \ud3ec\ud568\uc2dc\ud0a4\uc9c0 \uc54a\uc74c --> dropout\uae4c\uc9c0 \ud3ec\ud568 \uc2dc\ud0b4 \n\nex) model = torch.nn.Sequential(linear1,relu,dropout,linear2,relu,dropout,linear3).to(device)\n\nXavier\ucd08\uae30\ud654 --> kaiming\ucd08\uae30\ud654"}}