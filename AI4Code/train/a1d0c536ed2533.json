{"cell_type":{"71fd543f":"code","7217df08":"code","62c1ac1c":"code","6b1242a4":"code","47d5e38a":"code","321a706b":"code","3d758720":"code","4659d92f":"code","39d91827":"code","f4d0024e":"code","470a335f":"code","31a372ee":"code","a03e2a67":"code","bcd72bf7":"code","76391ba1":"code","2d68eedb":"code","0ed2e7a7":"code","a2f83299":"code","9ecd6d63":"code","8690d484":"code","3ce22881":"code","1ec113d5":"code","b1d83c26":"code","dddcb3ac":"code","259c2646":"code","78a5ec8d":"code","070025d9":"code","abbc2eee":"code","f8c6d10f":"markdown","82d47440":"markdown","cd0934a9":"markdown","354e9f50":"markdown","acfed6ce":"markdown","18d6e0ad":"markdown","12a37ee6":"markdown"},"source":{"71fd543f":"# bibliotecas\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport plotly.graph_objects as go\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nprint(tf.__version__)","7217df08":"df = pd.read_csv('https:\/\/raw.githubusercontent.com\/italomarcelogit\/keras-regressor\/main\/dados.csv', sep=';')\ndf.head()","62c1ac1c":"# fun\u00e7\u00e3o para gerar gr\u00e1fico scatter, utilizando plotly\ndef scatter(data, x, y, txt_titulo='', txt_xaxis='', txt_yaxis=''):\n  # fig = go.Figure(data=go.Scatter(x=df[x], y=df[y], mode='lines'))\n  fig = go.Figure()\n  for f in x:\n    for l in y:\n      fig.add_trace(go.Scatter(x=data[f], y=data[l],\n                      mode='lines+markers',\n                      name=l))\n  fig.update_layout(title=txt_titulo,\n                    xaxis_title=txt_xaxis,\n                    yaxis_title=txt_yaxis,\n                    template='plotly_white',\n                    xaxis = dict(tickangle=80)\n                    )\n  fig.show()\n\n# exibir valores das vendas realizadas\nscatter(df, x=['ds'], y=['y'], txt_titulo='Vendas Realizadas - Hist\u00f3ria',\n        txt_xaxis='Per\u00edodo', txt_yaxis='Total de Vendas')","6b1242a4":"df2 = df[['ds', 'y']].copy()\ndf2.head()","47d5e38a":"df2.info()","321a706b":"df2['diaAno'] = df.ds.apply(lambda x: pd.to_datetime([x]).dayofyear[0])\ndf2['ano'] = df.ds.apply(lambda x: pd.to_datetime([x]).year[0])\ndf2.head()","3d758720":"qtdna = df2.isna().sum().sum()\nif qtdna:\n  print(f'Existem {qtdna} valores nulos. Excluindo valores NA')\n  df2 = df2.dropna()\n  print(df2.isna().sum().sum())\nelse:\n  print(f'Existem {qtdna} valores nulos')","4659d92f":"# utilizar somente valores com o ano menor de 2021\n# dataset = df2[df2.ano < 2021][['diaAno', 'ano', 'y']].copy()\ndataset = df2[['diaAno', 'ano', 'y']].copy()","39d91827":"dataset.head()","f4d0024e":"# FEATURES: dados de treino e teste\n# dftreino = dataset.sample(frac=0.8, random_state=0)\n# dfteste = dataset.drop(dftreino.index)\ndftreino = dataset[dataset.ano<2021]\ndfteste = dataset[dataset.ano>2020]\ndataset.shape, dftreino.shape, dfteste.shape","470a335f":"# FEATURES: vis\u00e3o estat\u00edstica\ndfstats = dftreino.describe()\ndfstats.pop('y')\ndfstats = dfstats.transpose()\ndfstats","31a372ee":"# LABELS: \nlabels_treino = dftreino.pop('y')\nlabels_teste = dfteste.pop('y')\nlabels_treino.shape, labels_teste.shape","a03e2a67":"# NORMALIZAR OS DADOS, para diminuir a escala de valores entre as features\ndftreino.head(2)","bcd72bf7":"def normaliza(dataframe):\n  return (dataframe - dfstats['mean']) \/ dfstats['std']","76391ba1":"dftreino_normalizado = normaliza(dftreino)\ndftreino_normalizado.head(2)","2d68eedb":"# precisamos fazer a mesma coisa nos dados de teste\ndfteste_normalizado = normaliza(dfteste)","0ed2e7a7":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\ndef criarModelo():\n  model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=[len(dftreino.keys())]),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.01)\n  # outras op\u00e7\u00f5es\n  # optimizer = tf.keras.optimizers.Adam(0.2)\n  # optimizer = tf.keras.optimizers.Adamax(0.1)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model","a2f83299":"# criar modelo\nmodelo = criarModelo()","9ecd6d63":"# examinar modelo\nmodelo.summary()","8690d484":"# classe para callback\nclass pontoEpoch(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print(f'')\n    print('.', end='')\n\nparada = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)","3ce22881":"EPOCHS = 1000\nprint('Treinamento iniciado')\ntreinamento = modelo.fit(dftreino_normalizado, labels_treino, epochs=EPOCHS,\n                         validation_split = 0.2, verbose=0, \n                         callbacks=[parada, pontoEpoch()])\nprint('\\nTreinamento finalizado')","1ec113d5":"historico = pd.DataFrame(treinamento.history)","b1d83c26":"hist = pd.DataFrame()\nhist['epoch'] = historico.index.to_list()\nhist['epoch'] = hist['epoch'].apply(lambda x: x+1)\nhist['mae'] = historico['mae']\nhist['val_mae'] = historico['val_mae']\nscatter(hist, x=['epoch'], y=['mae', 'val_mae'], txt_titulo='An\u00e1lise de erros',\n        txt_xaxis='Epochs', txt_yaxis='MAE')","dddcb3ac":"loss, mae, mse = modelo.evaluate(dfteste_normalizado, labels_teste, verbose=2)\nprint(\"Erro m\u00e9dio absoluto - dataset de teste: {:5.2f} y\".format(mae))","259c2646":"label_previsao = modelo.predict(dfteste_normalizado).flatten()","78a5ec8d":"vdc = []\nfor x in dfteste.index:\n  a = dfteste.loc[x]['ano']\n  da = dfteste.loc[x]['diaAno']\n  dc = datetime.strptime(f'{a}' + \"-\" + f'{da}', \"%Y-%j\").strftime(\"%d-%m-%Y\")\n  vdc.append(dc)","070025d9":"dfprev = pd.DataFrame()\ndfprev['Realizado'] = labels_teste.to_list()\ndfprev['Previs\u00e3o'] = label_previsao.tolist()\ndfprev['Per\u00edodo'] = vdc","abbc2eee":"scatter(dfprev, ['Per\u00edodo'], ['Realizado', 'Previs\u00e3o'], \n        txt_titulo='An\u00e1lise de Compara\u00e7\u00e3o - Realizado x Previs\u00e3o',\n        txt_xaxis='Per\u00edodo', txt_yaxis='Total de Vendas')","f8c6d10f":"# **Modelo keras**","82d47440":"**Criar e examinar o modelo**","cd0934a9":"# **TENSORFLOW - keras**\nExemplo de previs\u00e3o de vendas utilizando features de tempo e valor total de vendas agrupados mensalmente","354e9f50":"# **Dataset**","acfed6ce":"**Treinar o modelo**","18d6e0ad":"**Prever valores**","12a37ee6":"# **PR\u00e9-PROCESSAMENTO**"}}