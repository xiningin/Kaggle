{"cell_type":{"6e38a319":"code","40fecb91":"code","4d467310":"code","0c38ff7e":"code","d487203c":"code","af8b3b17":"code","85db0e8b":"code","eaf22107":"code","db71337c":"code","78acddac":"code","c4c70fdd":"code","8641a8f0":"code","5c6cdc23":"code","656cee5c":"code","69dbd3aa":"code","31751f61":"code","e02611d4":"code","2c5514c7":"code","3260ab69":"code","61c7d865":"code","0d1438ee":"code","20108525":"code","d2edf325":"code","ba2fd08b":"code","13279576":"code","81927420":"code","280461ac":"code","b4568b28":"code","83d636de":"code","d5807b2d":"code","d51334f8":"code","40efe43c":"code","62730687":"code","bccb0bcf":"code","ffc552ee":"markdown","dd7b8668":"markdown","f401189b":"markdown","9372b363":"markdown","4dbdd6b8":"markdown","372a68b4":"markdown","ff6086fc":"markdown","806f47f2":"markdown","debbbfcc":"markdown","6f2d1fde":"markdown","2d8094c4":"markdown","05adaa9d":"markdown"},"source":{"6e38a319":"import numpy as np\nimport pandas as pd \nfrom tqdm import tqdm\nimport pyarrow.parquet as pq\nfrom scipy.sparse import coo_matrix, csr_matrix, hstack\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import pairwise_distances\nfrom joblib import parallel_backend\nfrom joblib import Parallel, delayed","40fecb91":"train_dir = '..\/input\/dada-for-hack-sber\/train.parquet'\nsub_dir = '..\/input\/dada-for-hack-sber\/test_ids.csv'\n\n# Validation version\n# train_dir = '..\/input\/sber-hack-valid-data\/train_val.parquet'\n# sub_dir = '..\/input\/sber-hack-valid-data\/submission_val.csv'\n\ntrain = pq.read_table(train_dir, use_threads=False, columns=['id', 'cluster_id', 'store_id'])#, 'completed_at', 'order_id', 'city_id'])\ntrain = train.to_pandas()\n\nsubmission = pd.read_csv(sub_dir, index_col='id')\nsubmission.index.nunique()","4d467310":"# \u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c 1 \u0438\u0437 3-\u0445 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0439 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f\n\nmatrix_of_sum = train.groupby(['id', 'cluster_id']).nunique().reset_index()  # bool \u043c\u0430\u0442\u0440\u0438\u0446\u0430\nmatrix_of_sum['order_id'] = 1\n\n# matrix_of_sum = train.groupby(['id', 'cluster_id'])['order_id'].nunique().reset_index()  # \u043f\u043e\u043b\u043d\u044b\u0439 count (max 160)\n\n# train['order_id'] = train.completed_at.dt.month  # count \u0434\u043e 4-\u0445 (\u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0443\u043f\u043a\u0438 \u0440\u0430\u0437 \u0432 \u043c\u0435\u0441\u044f\u0446)\n# del train['completed_at']\n# train = train.drop_duplicates()\n# matrix_of_sum = train.groupby(['id', 'cluster_id'])['order_id'].nunique().reset_index()","0c38ff7e":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 sparse matrix\n# \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u0425 \u0432\u0441\u0435 \u0442\u043e\u0432\u0430\u0440\u044b X \u043a\u043e\u043b-\u0432\u043e \u043f\u043e\u043a\u0443\u043f\u043e\u043a \u043f\u043e \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0438\nuser_id_mapping = {id: i for i, id in enumerate(matrix_of_sum['id'].unique())}\ncluster_id_mapping = {id: i for i, id in enumerate(matrix_of_sum['cluster_id'].unique())}\nunmap_cluster_id = {y: x for x, y in cluster_id_mapping.items()}\n\nmatrix_of_sum['id'] = matrix_of_sum['id'].map(user_id_mapping)\nmatrix_of_sum['cluster_id'] = matrix_of_sum['cluster_id'].map(cluster_id_mapping)\n\nshape = (len(user_id_mapping), len(cluster_id_mapping))\nmatrix_of_sum_csr = csr_matrix((matrix_of_sum['order_id'], (matrix_of_sum['id'], matrix_of_sum['cluster_id'])), shape=shape) \nmatrix_of_sum_csr","d487203c":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c id \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430 - \u0432\u0435\u0441\ncluster_weights = pq.read_table('..\/input\/dada-for-hack-sber\/cluster_weights.parquet', use_threads=False)\ncluster_weights = cluster_weights.to_pandas().set_index('cluster_id')\n\ncluster_w_mapping = {cluster_id_mapping[key]: value for key, value in cluster_weights.to_dict()['w'].items()}","af8b3b17":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0421\u0435\u0440\u0438\u0438:\n# \u041c\u0430\u0433\u0430\u0437\u0438\u043d - \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0443\u043f\u0430\u0442\u0435\u043b\u0438\nstore_user = train.groupby(['store_id']).id.apply(set)\nstore_user = store_user.apply(lambda x: set(user_id_mapping[i] for i in x))\n\n# \u042e\u0437\u0435\u0440 - \u043c\u0430\u0433\u0430\u0437\u0438\u043d, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u043d \u0441\u0434\u0435\u043b\u0430\u043b \u0437\u0430\u043a\u0430\u0437\nuser_store = train[train.id.isin(submission.index)].groupby(['id']).store_id.apply(set)\n\n# \u041c\u0430\u0433\u0430\u0437\u0438\u043d - \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u044b\nstore_cluster = train.groupby(['store_id']).cluster_id.apply(set)\nstore_cluster = store_cluster.apply(lambda x: set(cluster_id_mapping[i] for i in x))\n\ndel train","85db0e8b":"columns_arange = np.arange(matrix_of_sum_csr.shape[1])\ncluster_w = np.array([cluster_w_mapping[i] for i in columns_arange])","eaf22107":"# \u041a\u043e\u043b\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u0438\u0432\u043d\u0430\u044f \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u044f \u0441 \u043a\u043e\u0441\u0438\u043d\u0443\u0441\u043d\u043e\u0439 \u043c\u0435\u0440\u043e\u0439 \u0438 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u043c\u0438\ndef get_pred(us, list_of_us, cl_f):\n    batch = matrix_of_sum_csr[list_of_us]\n    similarity = cosine_similarity(matrix_of_sum_csr[us], batch).reshape(-1, 1)\n\n    rates = csr_matrix.multiply(batch, similarity**3)\n    cluster_rates = np.array(np.sum(rates, axis=0))[0]\n    \n    # F1  \u0444\u0438\u043b\u044c\u0442\u0440\u0443\u0435\u0442 \u0442\u043e\u0432\u0430\u0440\u044b \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u044e\u0437\u0435\u0440 \u0443\u0436\u0435 \u0434\u0435\u043b\u0430\u043b\n    cluster_rates *= np.where(matrix_of_sum_csr[us].toarray()[0], 0, 1)\n    \n    # F2  \u0444\u0438\u043b\u044c\u0442\u0440\u0443\u0435\u043c \u0442\u043e\u0432\u0430\u0440\u044b \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u043f\u0440\u043e\u0434\u0430\u044e\u0442\u0441\u044f \u0432 \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u0430\u0445, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043f\u043e\u043a\u0443\u043f\u0430\u043b \u044e\u0437\u0435\u0440\n    cluster_rates *= np.bincount(cl_f)\n    \n    # \u0412\u0437\u0432\u0435\u0448\u0438\u0432\u0430\u0435\u043c \u0442\u043e\u0432\u0430\u0440\u044b\n    cluster_rates *= cluster_w\n\n    top_k_cluster = columns_arange[np.argsort(cluster_rates)[::-1][:45]]\n    unmapped_top_k_clusters = [unmap_cluster_id[cluster_id] for cluster_id in top_k_cluster]\n\n    return ';'.join(map(str, unmapped_top_k_clusters))","db71337c":"%%time\npredict = dict()\nlimit = -1 # 1000  # \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u0431\u0430\u0442\u0447 \u0434\u043e \u044d\u0442\u043e\u0433\u043e \u0443\u0440\u043e\u0432\u043d\u044f \u0440\u0430\u043d\u0434\u043e\u043c\u043d\u044b\u043c\u0438 \u044e\u0437\u0435\u0440\u0430\u043c\u0438\n\n\ndef f(user):\n    tmp = set()\n    clust_f = set([7188]) # for validation set([6949])\n    for st in user_store.loc[user]:\n        tmp.update(store_user[st])\n        clust_f.update(store_cluster[st])\n\n    diff = limit - len(tmp)\n    if diff > 0:\n        tmp.update(np.random.choice(np.arange(len(user_id_mapping)), diff, replace=False))\n    predict[user] = get_pred(user_id_mapping[user], list(tmp), list(clust_f))\n\n\nwith parallel_backend('threading', n_jobs=-1):\n    Parallel()(delayed(f)(user) for user in tqdm(user_store.index[:1000]))  # [:1000] for test","78acddac":"df = pd.DataFrame.from_dict(predict, orient='index', columns=['target'])\ndf.index.rename('id', inplace=True)","c4c70fdd":"df.to_csv('submission_test_w_store_bool_f2_pow3.csv')","8641a8f0":"# \u0422\u043e\u0432\u0430\u0440\u044b \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u043f\u043e\u043a\u0443\u043f\u0430\u0435\u0442 \u0435\u0436\u0435\u043c\u0435\u0441\u044f\u0447\u043d\u043e \u0445\u043e\u0442\u044f \u0431\u044b 1 \u0440\u0430\u0437 (\u043c\u043e\u0436\u0435\u0442 \u0438 \u043d\u0435 \u0431\u044b\u0442\u044c!) \"\u0420\u0435\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0437\u0430\u043a\u0430\u0437\u044b\"\nparam = 2  # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437 \u0438\u0437 4-\u0445 \u043c\u0435\u0441\u044f\u0446\u0435\u0432 \u043f\u043e\u043a\u0443\u043f\u0430\u043b\u0441\u044f \u0442\u043e\u0432\u0430\u0440\nf1 = pq.read_table('..\/input\/dada-for-hack-sber\/train.parquet', use_threads=False, columns=['id', 'cluster_id', 'completed_at'])\nf1 = f1.to_pandas()\nf1 = f1[f1.id.isin(submission.index.unique())] # for valid\n\nusers = list(submission.index)\nf1 = f1.loc[f1.id.isin(users), :]\nf1['month'] = f1.completed_at.dt.month\ndel f1['completed_at']\nf1 = f1.drop_duplicates()\n\ntmp = f1.groupby(['cluster_id', 'id']).count().reset_index()\ntmp = tmp[tmp.month >= param]\ndel tmp['month']\ndel f1\n\nres_top_3m = tmp.groupby('id').agg({'cluster_id': lambda x: ';'.join(map(str, x))})\nres_top_3m","5c6cdc23":"# \u0422\u043e\u043f \u0442\u043e\u0432\u0430\u0440\u044b \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u0437\u0430\u043a\u0430\u0437\u044b\u0432\u0430\u043b (\u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c < 20) \"\u0427\u0430\u0441\u0442\u043e\u0442\u043d\u044b\u0435 \u0437\u0430\u043a\u0430\u0437\u044b\"\na = 5  # \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u0437\u0438\u0446\u0438\u0439 \u0432\u0437\u044f\u0442\u044c \u0438\u0437 \u0441\u0430\u043c\u044b\u0445 \u0447\u0430\u0441\u0442\u044b\u0445 \u0437\u0430\u043a\u0430\u0437\u043e\u0432\nb = 1  # \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437 \u043c\u0438\u043d\u0438\u043c\u0443\u043c \u043f\u043e\u0437\u0438\u0446\u0438\u044f \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c \u0437\u0430\u043a\u0430\u0437\u0430\u043d\u0430, \u0447\u0442\u043e \u0431\u044b \u043f\u043e\u043f\u0430\u0441\u0442\u044c \u043b\u0438\u0441\u0442\nf1 = pq.read_table(train_dir, use_threads=False, columns=['id', 'cluster_id'])\nf1 = f1.to_pandas()\n\nf1 = f1.loc[f1.id.isin(users), :].set_index('id')\nres_top = f1.groupby('id').agg({'cluster_id': lambda x: ';'.join(map(str, x.value_counts()[x.value_counts() > b].index[:a]))})\ndel f1","656cee5c":"# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043e\u0442\u043e\u0431\u0440\u0430\u043d\u043d\u044b\u0435 \u0432\u044b\u0448\u0435 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u044b \u0432 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043e\u0442 \u043a\u043e\u043b\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u0438\u0432\u043d\u043e\u0439 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u0438\ntmp = pd.merge(df.reset_index(), res_top.reset_index(), left_on='id', right_on='id', how='left').set_index('id')\ntmp.fillna('', inplace=True)\n\ndef f(x):\n    return [i for i in x if i]\n\na = 20  # \u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u0442\u0435\u043b\u044c \u0434\u043b\u044f \"\u0427\u0430\u0441\u0442\u043e\u0442\u043d\u044b\u0445 \u0437\u0430\u043a\u0430\u0437\u043e\u0432\" (\u041f\u0440\u0438 \u0438\u0445 \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0435 \u0435\u0441\u0442\u044c \u0441\u0432\u043e\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b!)\ntmp['target1'] = tmp.apply(lambda x: (';'.join(list(dict.fromkeys(f(x.cluster_id.split(';')[:a]) + x.target.split(';')))[:20]).strip(';')), axis=1)\nsub_top4_store = tmp.copy()\n\nsub_top4_store = sub_top4_store[['target1']]\nsub_top4_store = sub_top4_store.rename(columns={'target1': 'target'})\n\ntmp = pd.merge(sub_top4_store.reset_index(), res_top_3m.reset_index(), left_on='id', right_on='id', how='left').set_index('id')\ntmp.fillna('', inplace=True)\n\ndef f(x):\n    return [i for i in x if i]\n\na = 20  # \u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u0442\u0435\u043b\u044c \u0434\u043b\u044f \"\u0420\u0435\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u0437\u0430\u043a\u0430\u0437\u043e\u0432\" (\u041f\u0440\u0438 \u0438\u0445 \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0435 \u0435\u0441\u0442\u044c \u0441\u0432\u043e\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b!)\ntmp['target1'] = tmp.apply(lambda x: (';'.join(list(dict.fromkeys(f(x.cluster_id.split(';')[:a]) + x.target.split(';')))[:20]).strip(';')), axis=1)\n\nsub_fin = tmp[['target1']]\nsub_fin = sub_fin.rename(columns={'target1': 'target'})","69dbd3aa":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0440\u0435\u0448\u0435\u043d\u0438\u0435\nsub_fin.to_csv('submission_val_store_bool_f1_f2_pow3_m3_top5.csv')","31751f61":"f1 = pq.read_table('..\/input\/dada-for-hack-sber\/train.parquet', use_threads=False, columns=['id', 'cluster_id', 'completed_at'])\nf1 = f1.to_pandas()\n\nf1['month'] = f1.completed_at.dt.month\ndel f1['completed_at']\n\ntest = f1[f1.month == 9]\ntrain = f1[f1.month != 9]\ndel f1","e02611d4":"test_id = set(test.id.unique())\ntrain_id = set(train.id.unique())\n\nset_id = (test_id & train_id)\nlen(set_id)","2c5514c7":"test = test[test.id.isin(set_id)]\ntrain = train[train.id.isin(set_id)]\n\ndel test['month']\ndel train['month']\n\ntest.shape, train.shape","3260ab69":"test_ids = pd.read_csv('..\/input\/dada-for-hack-sber\/test_ids.csv', index_col='id')\ntest = test[test.id.isin(test_ids.index)]\n\ntest_grop = test.groupby('id').cluster_id.apply(list)","61c7d865":"%%time\ndef f(x):\n    df = pd.Series(x).value_counts()\n    return ';'.join(map(str, list(df.index[:20])))\n\n\nres = test_grop.apply(lambda x: f(x))\nres.to_frame().to_csv('submission_val.csv')\npd.read_csv('.\/submission_val.csv', index_col='id')\n\ntmp = res.apply(lambda x: len(x.split(';')))\ntmp.mean()","0d1438ee":"f1 = pq.read_table('..\/input\/dada-for-hack-sber\/train.parquet', use_threads=False, columns=['id', 'cluster_id', 'completed_at', 'store_id', 'city_id'])\nf1 = f1.to_pandas()\n\nf1 = f1[f1.id.isin(set_id)]\nf1.id.nunique(), len(set_id)","20108525":"f1['month'] = f1.completed_at.dt.month\n\ntrain = f1[f1.month != 9]\ndel train['month']\ndel f1\n\ntrain.id.nunique(), len(set_id)","d2edf325":"train.to_parquet('train_val.parquet')","ba2fd08b":"submission_val = pd.read_csv('.\/submission_val.csv')\nsubmission_val.rename(columns={'cluster_id': 'target'}, inplace=True)","13279576":"cluster_weights = pq.read_table('..\/input\/dada-for-hack-sber\/cluster_weights.parquet', use_threads=False)\ncluster_weights = cluster_weights.to_pandas().set_index('cluster_id')\nmax_w = cluster_weights['w'].max()\ncluster_weights = cluster_weights['w'].to_dict()","81927420":"train = pq.read_table('..\/input\/sber-hack-valid-data\/train_val.parquet', use_threads=False, columns=['id', 'cluster_id', 'store_id'])\ntrain = train.to_pandas()\nhistory = train.groupby('id')['cluster_id'].apply(set).to_dict()","280461ac":"def competition_metric_low_memory(\n    submission: pd.DataFrame,\n    test: pd.DataFrame,\n    k: int = 20\n) -> float:\n\n    \n    if len(set(submission[\"id\"].unique()) ^ set(test[\"id\"].unique())) > 0:\n        raise SubmissionError(\"Length of disjunctive union of sets of submission and test ids greater than zero\")\n    \n    submission = submission.set_index('id')['target'].to_dict()\n    test = test.set_index('id')['target'].to_dict()\n    \n    n = len(submission)\n    \n    recall_score = 0\n    serendipity_score = 0\n\n    for _id in submission:\n        \n        actual = test.get(_id, -1)\n        if actual == -1:\n            raise SubmissionError(f\"id={_id} not in test set\")\n\n        hist = history.get(_id, -1)\n        if hist == -1:\n            raise SubmissionError(f\"id={_id} not in history set\")\n        \n        recs = [int(item) for item in submission[_id].split(';')]\n        if len(recs) != len(set(recs)):\n            raise SubmissionError(\"Duplicate ids in submission\")\n        \n        if len(recs) > k:\n            raise SubmissionError(f\"Length of the recommendation list must be less than or equal to {k}\")\n        \n        actual = set([int(item) for item in actual.split(';')])\n        \n        recall_score += sum(\n            [\n                cluster_weights.get(item, max_w)\n                for item in recs \n                if item in actual\n            ]\n        ) \/ min(k, len(actual))\n        serendipity_score += sum(\n            [\n                cluster_weights.get(item, max_w)\n                for item in recs \n                if item in actual\n                and item not in hist\n            ]\n        ) \/ min(k, len(actual))\n\n    return 0.25 * recall_score \/ n + 0.75 * serendipity_score \/ n\n\ncompetition_metric_low_memory(submission_val, submission_val)","b4568b28":"# \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c basiline \u0438 \u0445\u0443\u0434\u0448\u0438\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\nclusters = list(train['cluster_id'].value_counts().index)\ngood = clusters[:20]\nbad = clusters[-20:]\n\nsub_good = submission_val.copy()\nsub_bad = submission_val.copy()\nsub_good.target = ';'.join(map(str, good))\nsub_bad.target = ';'.join(map(str, bad))","83d636de":"competition_metric_low_memory(sub_good, submission_val)","d5807b2d":"competition_metric_low_memory(sub_bad, submission_val)","d51334f8":"# \u0418\u043c\u0435\u044f \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0439 \u043e\u0446\u0435\u043d\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0438, \u043f\u043e\u0434\u0431\u0438\u0440\u0435\u043c \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\nf1 = pq.read_table('.\/train_val.parquet', use_threads=False, columns=['id', 'cluster_id', 'completed_at'])\nf1 = f1.to_pandas()\n\nusers = list(submission_val.id.values)\nf1 = f1[f1.id.isin(users)]\n\nf1 = f1.drop_duplicates().set_index('id')","40efe43c":"%%time\nb0 = 2\nb1 = 7\nb2 = 18\nb3 = 20\n\ndef f(x):\n    tmp = x.value_counts()\n    res = list(tmp[tmp > 3].index[:b3])\n    res += [i for i in tmp[tmp > 2].index[:b2] if i not in res]\n    res += [i for i in tmp[tmp > 1].index[:b1] if i not in res]\n    res += [i for i in tmp[tmp > 0].index[:b0] if i not in res]\n    return ';'.join(map(str, res[:20]))\n\nsub_prep = f1.groupby('id').agg({'cluster_id': lambda x: f(x)})","62730687":"sub_prep.rename(columns={'cluster_id': 'target'}, inplace=True)","bccb0bcf":"tmp = pd.merge(sub_good, sub_prep, left_on='id', right_on='id', how='left').set_index('id')\ntmp.fillna('', inplace=True)\n\ndef f(x):\n    return [i for i in x if i]\n\na = 20  # \u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u0442\u0435\u043b\u044c \u0434\u043b\u044f \"\u0427\u0430\u0441\u0442\u043e\u0442\u043d\u044b\u0445 \u0437\u0430\u043a\u0430\u0437\u043e\u0432\" (\u041f\u0440\u0438 \u0438\u0445 \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0435 \u0435\u0441\u0442\u044c \u0441\u0432\u043e\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b!)\ntmp['target'] = tmp.apply(lambda x: (';'.join(list(dict.fromkeys(f(x.target_y.split(';')[:a]) + x.target_x.split(';')))[:20]).strip(';')), axis=1)\nsub_top4_store = tmp.copy()\ncompetition_metric_low_memory(sub_top4_store[['target']].reset_index(), submission_val)","ffc552ee":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c train","dd7b8668":"\u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f - \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c \u043a\u043e\u043b\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u0438\u0432\u043d\u0443\u044e \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u044e \u0441\u0440\u0435\u0434\u0438 \u044e\u0437\u0435\u0440\u043e\u0432 \u0441\u043e\u0432\u0435\u0440\u0448\u0438\u0432\u0448\u0448\u0438\u0445 \u0437\u0430\u043a\u0430\u0437\u044b \u0432 \u0442\u0435\u0445 \u0436\u0435 \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u0430\u0445,  \n\u0447\u0442\u043e \u0438 \u044e\u0437\u0435\u0440 \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0441\u0442\u0440\u043e\u0438\u043c \u043f\u0440\u043e\u0433\u043d\u043e\u0437","f401189b":"\u0421\u043e\u0433\u043b\u0430\u0441\u043d\u043e \u043f\u0435\u0440\u0432\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 \u043d\u0430\u0448\u0435\u0439 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 (0.25 Recall@k) \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u044b \u0442\u043e\u0432\u0430\u0440\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435  \n\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0438 \u0443\u0436\u0435 \u0437\u0430\u043a\u0430\u0437\u044b\u0432\u0430\u043b\u0438","9372b363":"\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u0447\u0438:  \n\n\u041f\u0440\u0435\u0434\u0441\u0442\u043e\u0438\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043a\u0430\u043a\u0438\u0435 \u043f\u043e\u043a\u0443\u043f\u043a\u0438 \u0441\u043e\u0432\u0435\u0440\u0448\u0438\u0442 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u0432 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u043c \u043c\u0435\u0441\u044f\u0446\u0435.  \n\u0412 \u0421\u0431\u0435\u0440\u041c\u0430\u0440\u043a\u0435\u0442\u0435 \u0431\u043e\u043b\u0435\u0435 2 \u043c\u0438\u043b\u043b\u0438\u043e\u043d\u043e\u0432 \u0442\u043e\u0432\u0430\u0440\u043d\u044b\u0445 \u043f\u043e\u0437\u0438\u0446\u0438\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043c\u044b \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u043b\u0438 \u0442\u043e\u0432\u0430\u0440\u044b \u0432 \u00ab\u043a\u043b\u0430\u0441\u0442\u0435\u0440\u044b\u00bb.  \n\u041a\u0430\u0436\u0434\u044b\u0439 \u043a\u043b\u0430\u0441\u0442\u0435\u0440 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u0442 \u043f\u043e\u0445\u043e\u0436\u0438\u0435 \u0442\u043e\u0432\u0430\u0440\u044b \u043f\u043e \u0438\u0445 \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u044e. \u041a\u043b\u0430\u0441\u0442\u0435\u0440\u044b \u0431\u044b\u043b\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u044b \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e ML, \u0447\u0435\u0440\u0435\u0437 \u044d\u043c\u0431\u0435\u0434\u0434\u0438\u043d\u0433\u0438 \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u043e\u0432.  \n\u0427\u0442\u043e\u0431\u044b \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0438\u0437\u0443\u0447\u0438\u0442\u044c \u0432\u0437\u0430\u0438\u043c\u043e\u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u044f \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u043e\u0432, \u043c\u044b \u0434\u0430\u0434\u0438\u043c \u0432\u0430\u043c \u0438\u0445 \u00ab\u0446\u0435\u043d\u0442\u0440\u044b\u00bb \u0438 \u0431\u0430\u0437\u043e\u0432\u044b\u0435 \u0441\u0442\u0430\u0442. \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438.  \n\u0412 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b \u0443\u0432\u0438\u0434\u0438\u0442\u0435 id \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u043e\u0432 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c \u0431\u0443\u0434\u0435\u0442\u0435 \u0438\u043c\u0435\u043d\u043d\u043e \u0438\u0445.  ","4dbdd6b8":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c submission \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f","372a68b4":"## \u0412\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f","ff6086fc":"\u0414\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043d\u0430\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0439 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 \u043f\u043e\u0434 \u043c\u0435\u0442\u0440\u0438\u043a\u0443 \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 train \u0438 test.  \n\u0412\u043e\u0437\u044c\u043c\u0435\u043c \u0432 train \u043c\u0435\u0441\u044f\u0446\u0430 \u0441 \u0438\u044e\u043d\u044f \u043f\u043e \u0430\u0432\u0433\u0443\u0441\u0442, \u0432 test \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044c.","806f47f2":"\u041c\u0435\u0442\u0440\u0438\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430  \n\n\u041c\u0435\u0442\u0440\u0438\u043a\u043e\u0439 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432\u0437\u0432\u0435\u0448\u0435\u043d\u043d\u0430\u044f \u0441\u0443\u043c\u043c\u0430 Recall@k \u0438 Serendipity@k (K = 20):  \nscore = 0.25Recall@k + 0.75Serendipity@k  \n\nRecall@k - \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442\u0441\u044f \u043a\u0430\u043a \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0440\u0435\u043b\u0435\u0432\u0430\u043d\u0442\u043d\u044b\u0445 (\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445) \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0432 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445 \u0441  \n\u043d\u0430\u0438\u0432\u044b\u0441\u0448\u0438\u043c \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u043e\u043c k \u043a \u043e\u0431\u0449\u0435\u043c\u0443 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0443 \u0440\u0435\u043b\u0435\u0432\u0430\u043d\u0442\u043d\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0434\u043b\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0432\u044b\u0434\u0430\u0447\u0438.\n\nSerendipity@k - \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0430\u044f, \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0440\u0435\u043b\u0435\u0432\u0430\u043d\u0442\u043d\u044b\u0445 (\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445) \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432,  \n\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u043b\u0438\u0441\u044c \u0432 \u0438\u0441\u0442\u043e\u0440\u0438\u0438 \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f, \u0432 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445 \u0441 \u043d\u0430\u0438\u0432\u044b\u0441\u0448\u0438\u043c \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u043e\u043c k  \n\u043a \u043e\u0431\u0449\u0435\u043c\u0443 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0443 \u0440\u0435\u043b\u0435\u0432\u0430\u043d\u0442\u043d\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0434\u043b\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0432\u044b\u0434\u0430\u0447\u0438.","debbbfcc":"\u041a\u0430\u043a \u0432\u0438\u0434\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0432\u044b\u0440\u043e\u0441\u043b\u043e (\u0431\u044b\u043b\u043e 0.016062681655974236)  \n\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0430 train 0.03133","6f2d1fde":"\u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","2d8094c4":"\u0414\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f:\n - train.parquet - \u0438\u0441\u0442\u043e\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043e \u043f\u043e\u043a\u0443\u043f\u043a\u0430\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439\n - clusters.parquet - \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430\u0445\n - centroids.parquet - \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u043e \u0446\u0435\u043d\u0442\u0440\u0430\u0445 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u043e\u0432","05adaa9d":"# Sbermarket competition: Predict Next Purchases Clusters"}}