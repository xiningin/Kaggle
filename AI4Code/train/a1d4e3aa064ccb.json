{"cell_type":{"d1627919":"code","8cb03719":"code","27abe5e6":"code","4a3b587f":"code","9dfc6521":"code","9c72bd71":"code","4d2247ef":"code","d5552f20":"code","d5af1ad9":"code","9b1f59e2":"code","323c2a4d":"code","4dd6ac30":"code","f4bcc8e7":"code","e1ce494c":"code","57da60b6":"code","d47df065":"code","e4bb506a":"code","81399d3d":"code","573101e0":"code","ab8c8204":"code","8dc522c0":"code","7f0e4299":"code","140083db":"code","2f27303a":"code","1f532082":"code","2d8e08ea":"code","fd240fa3":"code","d545a792":"code","c880811b":"code","69c94fa9":"code","4172415c":"code","40bdb9df":"code","a44905a8":"code","f5ec092a":"code","8555dddc":"code","ae440ad7":"code","cf882769":"code","45de9041":"code","cd0ea7da":"code","6b2a8606":"code","45c2f8e1":"code","ac5cf9e2":"code","48879129":"code","996e7399":"code","2781a960":"code","3a1c6e83":"code","db788a98":"code","34eda88d":"code","f5a271e5":"code","44a6b1d4":"code","1b9076be":"code","b26fbe3d":"code","05f5e86a":"code","d1cfbb17":"code","6589e595":"code","1973cb54":"code","cdf44b65":"markdown","acbf41fa":"markdown","8e35f3db":"markdown","801a5e62":"markdown","4dd0a362":"markdown","c501cc7f":"markdown","265c5064":"markdown","176adb7b":"markdown","faa47c9a":"markdown","f4a8e816":"markdown","097ee261":"markdown","9066b44b":"markdown","860b327b":"markdown","d7c4f376":"markdown","2c954127":"markdown","1f654833":"markdown","2dc4302e":"markdown","a7b85d37":"markdown","1671d780":"markdown"},"source":{"d1627919":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sympy import binomial\nfrom scipy.stats import binom, beta, norm\n#from scipy.stats import stats\nimport scipy.integrate as integrate\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = 20, 15\n#plt.rcParams['figure.titlesize'] = 100","8cb03719":"dice = [i for i in range(1,7)]\nnp.random.choice(dice)","27abe5e6":"def two_dice7(trials=10_000):\n    dice = [i for i in range(1,7)]\n    counter = 0\n    for i in range(trials):\n        a, b = np.random.choice(dice), np.random.choice(dice)\n        if a + b >= 7:\n            counter += 1\n    return counter\/trials\ntwo_dice7()","4a3b587f":"def three_dice7(trials=10_000):\n    dice = [i for i in range(1,7)]\n    counter = 0\n    for i in range(trials):\n        a, b, c = np.random.choice(dice), np.random.choice(dice), np.random.choice(dice)\n        if a + b + c >= 7:\n            counter += 1\n    return counter\/trials\nthree_dice7()","9dfc6521":"dice = [i for i in range(1,7)]\n# We get the count of 7 as two sum\ncounter = 0\nfor i in dice:\n    for j in dice:\n        if i + j > 6:\n            counter += 1\nf'Counts, Actual Prob and the simmulated probs are : {counter, counter\/36.0, two_dice7()}'","9c72bd71":"dice = [i for i in range(1,7)]\n# We get the count of 7 as three sum\ncounter = 0\nfor i in dice:\n    for j in dice:\n        for k in dice:\n            if i + j + k > 6:\n                counter += 1\nf'Counts, Actual Prob and the simmulated probs are : {counter, counter\/(6*36.0), three_dice7()}'","4d2247ef":"'''The Yankees are playing the Red Sox. You\u2019re a diehard Sox fan and bet your friend\nthey\u2019ll win the game. You\u2019ll pay your friend $30 if the Sox lose and your friend will have to\npay you only $5 if the Sox win. What is the probability you have intuitively assigned to the\nbelief that the Red Sox will win?'''\n\nodds = 30\/5.\nprob = odds \/ (odds + 1)\n\nf'The probability of Sox win is {prob}'","d5552f20":"# What is the probability of rolling a 20 three times in a row on a 20-sided die?\n(1\/20)**3","d5af1ad9":"'''The weather report says there\u2019s a 10 percent chance of rain tomorrow, and you forget\nyour umbrella half the time you go out. What is the probability that you\u2019ll be caught in the\nrain without an umbrella tomorrow?'''\n\np_rain_2moro = .1\np_forget_umbrella = .5\n\np_rain_no_umbrella = p_rain_2moro *  p_forget_umbrella\np_rain_no_umbrella","9b1f59e2":"'''Raw eggs have a 1\/20,000 probability of having salmonella. If you eat two raw eggs,\nwhat is the probability you ate a raw egg with salmonella?'''\n\n1\/20000 + 1\/20000 - (1\/20000)**2","323c2a4d":"'''What is the probability of either flipping two heads in two coin tosses or rolling three\n6s in three six-sided dice rolls?'''\ntwo_h = 1\/4\nsixes = 1\/(6**3)\n\ntwo_h + sixes - two_h * sixes","4dd6ac30":"# setting the values\n# of n and p\nn = 10\np = .5\n# defining the list of r values\nk_values = list(range(n + 1))\n# obtaining the mean and variance \nmean, var = binom.stats(n, p)\n# list of pmf values\ndist = [binom.pmf(k, n, p) for k in k_values]\n# printing the table\nprint(\"k\\tB(k,n,p)\")\nfor i in range(n + 1):\n    print(str(k_values[i]) + \"\\t\" + str(dist[i]))\n# printing mean and variance\nprint(f'Mean and variace of binom dist are {mean, var}')","f4bcc8e7":"plt.bar(k_values, dist)\nplt.xlabel('k Values')\nplt.ylabel('B(k,n,p)')\nplt.title('B(k,n,p) vs k')","e1ce494c":"# The probability of getting a 6 when rolling a six-sided die 10 times\n# setting the values\n# of n and p\nn = 10\np = 1\/6.\n# defining the list of r values\nk_values = list(range(n + 1))\n# obtaining the mean and variance \nmean, var = binom.stats(n, p)\n# list of pmf values\ndist = [binom.pmf(k, n, p) for k in k_values]\n# printing the table\nprint(\"k\\tB(k,n,p)\")\nfor i in range(n + 1):\n    print(str(k_values[i]) + \"\\t\" + str(dist[i]))\n# printing mean and variance\nprint(f'Mean and variace of binom dist are {mean, var}')\nplt.bar(k_values, dist)","57da60b6":"'''You have a new mobile game, Bayesian Battlers. The current set of cards you\ncan pull from is called a banner. The banner contains some average cards and some featured cards\nthat are more valuable. As you may suspect, all of the cards in Bayesian Battlers are famous\nprobabilists and statisticians. The top cards in this banner are as follows, each with its respective\nprobability of being pulled:\n- Thomas Bayes: 0.721%\n- E. T. Jaynes: 0.720%\n- Harold Jeffreys: 0.718%\n- Andrew Gelman: 0.718%\n- John Kruschke: 0.714%\n\nYou really want the E. T. Jaynes card to complete your elite Bayesian team. Unfortunately, you have\nto purchase the in-game currency, Bayes Bucks, in order to pull cards. It costs one Bayes Buck to\npull one card, but there\u2019s a special on right now allowing you to purchase 100 Bayes Bucks for only\n$10. That\u2019s the maximum you are willing to spend on this game, and only if you have at least an\neven chance of pulling the card you want. This means you\u2019ll buy the Bayes Bucks only if the\nprobability of getting that awesome E. T. Jaynes card is greater than or equal to 0.5.\n\n'''\nn = 100\np = .0072\n# defining the list of r values\nk_values = list(range(n + 1))\n# obtaining the mean and variance \nmean, var = binom.stats(n, p)\n# list of pmf values\ndist = [binom.pmf(k, n, p) for k in k_values]\n\n# printing mean and variance\nprint(f'Mean and variace of binom dist are {mean, var}')\nplt.bar(k_values, dist)\nprob_jayce = sum(dist[1:])\nprint()\nprint(f'Probability of getting that awesome E. T. Jaynes card is {prob_jayce}')\nprint('\\nHence we are going to spend Bayes Bucks!!! Cheers:)\\n')","d47df065":"'''What are the parameters of the binomial distribution for the probability of rolling\neither a 1 or a 20 on a 20-sided die, if we roll the die 12 times?'''\ndef bino_dist(n, p):\n    \n    # defining the list of k values\n    k_values = list(range(n + 1))\n    # obtaining the mean and variance \n    mean, var = binom.stats(n, p)\n    # list of pmf values\n    dist = [binom.pmf(k, n, p) for k in k_values]\n\n    # printing mean and variance\n    print(f'\\nMean and variance of binom dist are {mean, var}\\n')\n    plt.bar(k_values, dist)\n    return dist, mean, var\n\ndist, mean, var = bino_dist(12, 2\/20.)\n\nprint(f'Probability of rolling either a 1 or a 20 on a 20-sided die, if we roll the die 12 times is : {dist[1]}\\n')","e4bb506a":"'''There are four aces in a deck of 52 cards. If you pull a card, return the card, then\nreshuffle and pull a card again, how many ways can you pull just one ace in five pulls?'''\ndist, _, _ = bino_dist(5, 4\/52.)\nn = 4 * binomial(5,1) * (48 ** 4)\nprint(f'No of ways of ways you pull just one ace in five pulls is {n}') # dividing n by 52**4 we get the dist[1]\nprint(f'Prob of pulling just one ace in five pulls is {dist[1]}\\n')","81399d3d":"# probability of pulling five aces in 10 pulls\n\ndist, _, _ = bino_dist(10, 4\/52.)\n\nprint(f'Probability of pulling five aces in 10 pulls is {dist[5]}\\n')","573101e0":"'''When you\u2019re searching for a new job, it\u2019s always helpful to have more than one offer\non the table so you can use it in negotiations. If you have a 1\/5 probability of receiving a job\noffer when you interview, and you interview with seven companies in a month, what is the\nprobability you\u2019ll have at least two competing offers by the end of that month?'''\n\ndist, _, _ = bino_dist(7, 1\/5.)\nseven = sum(dist[2:])\nprint(f'Probability you\u2019ll have at least two competing offers by the end of that month is if we go for 7 interviews {seven}\\n')","ab8c8204":"'''You get a bunch of recruiter emails and find out you have 25 inter-\nviews lined up in the next month. Unfortunately, you know this will leave\nyou exhausted, and the probability of getting an offer will drop to 1\/10\nif you\u2019re tired. You really don\u2019t want to go on this many interviews unless\nyou are at least twice as likely to get at least two competing offers. Are you\nmore likely to get at least two offers if you go for 25 interviews, or stick to\njust 7?'''\n\ndist, _, _ = bino_dist(25, 1\/10.)\ntwenty_five = sum(dist[2:])\nprint(f'Probability you\u2019ll have at least two competing offers by the end of that month is if we go for 25 interviews {twenty_five}\\n')\nprint(f'So going to 25 is {twenty_five\/seven} times better than going to 7. Hence worth trying 25, though it is tiring.\\n')","8dc522c0":"'''The shopkeeper informs you that he\u2019s just as curious as you are and will gladly donate a roll of\nquarters\u2014containing $10 worth of quarters, or 40 quarters\u2014provided you return any winnings to\nhim. You put a quarter in, and happily, two more quarters pop out! Now we have two pieces of data:\nthe mystical box does in fact pay out sometimes, and sometimes it eats the coin.\nGiven our two observations, one where you lose the quarter and another where you win, you might\nguess naively that P(two quarters) = 1\/2. Since our data is so limited, however, there is still a range\nof probabilities we might consider for the true rate at which this mysterious box returns two coins.\nTo gather more data, you\u2019ll use the rest of the quarters in the roll. In the end, including your first\nquarter, you get:\n14 wins\n27 losses\n\nWithout doing any further analysis, you might intuitively want to update your guess that P(two\nquarters) = 1\/2 (H1) to P(two quarters) = 14\/41 (H2). But what about your original guess\u2014does your new\ndata mean it\u2019s impossible that 1\/2 is the real probability?'''\n\ndist1, _, _ = bino_dist(41, 1\/2.) # H1\n\n\nprint(f'If H1 were true and the probability of getting two coins was 1\/2, then the probability of observing 14 occasions \\\nwhere we get two coins out of 41 trials would be about {dist1[14]}\\n')\n","7f0e4299":"dist2, _, _ = bino_dist(41, 14\/41.) #H2\nprint(f'If H2 were true and the probability of getting two coins was 14\/41, then the probability of observing 14 occasions \\\nwhere we get two coins out of 41 trials would be about {dist2[14]}\\n')","140083db":"hypotheses = []\nx = []\nfor i in range(100):\n    x.append((i+1)\/100)\n    hypotheses.append(binom.pmf(14, 41, x[-1]))\nplt.scatter(x, hypotheses)\nplt.axhline(.1)\n","2f27303a":"'''If you looked at the graph closely, you may have noticed a larger problem here: there are at\nleast 10 dots above 0.1 right now, and we have an infinite number of points to add. This means that\nour probabilities don\u2019t sum to 1! From the rules of probability, we know that the probabilities of all\nour possible hypotheses must sum to 1. If they don\u2019t, it means that some hypotheses are not\ncovered. If they add up to more than 1, we would be violating the rule that probabilities must be\nbetween 0 and 1. Even though there are infinitely many possibilities here, we still need them all to\nsum to 1. This is where the beta distribution comes in.'''\n# No of point with prob at least .1\nsum(np.where(np.array(hypotheses) > .1, 1, 0))","1f532082":"rv = beta(14, 27)\nx = np.linspace(0, 1, 200)\nplt.plot(x, rv.pdf(x), 'k-', lw=2, label='Beta(14, 27)')\nplt.legend()\nplt.xlabel('p - Probability of success') # prob of success\nplt.ylabel('Density (Chance of successiding with probability p given data)') # Probability of successiding with probability p given data\nplt.title('Give me quarter I give you 2 quarter box!')\nplt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), 0, .5)\nprint(f'\\nThis tells us the probability that the rate of pulling 2 quarter form a box with probability <= 0.5, given\\\nthe evidence we have observed, is only {res[0]} with error of {res[1]}\\n')","2d8e08ea":"rv = beta(5, 1195)\nx = np.linspace(0, .1, 2000)\nplt.plot(x, rv.pdf(x), 'k-', lw=2, label='beta(5, 1195)')\nplt.legend()\nplt.title('Pull Bradley Efron card')\n#plt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), .005, 1)\nprint(f'\\nThis tells us the probability that the rate of pulling a Bradley Efron card is 0.005 or greater, given\\\nthe evidence we have observed, is only {res[0]} with error of {res[1]}\\n')","fd240fa3":"'''You want to use the beta distribution to determine whether or not a coin you have is\na fair coin\u2014meaning that the coin gives you heads and tails equally. You flip the coin 10\ntimes and get 4 heads and 6 tails. Using the beta distribution, what is the probability that the\ncoin will land on heads more than 60 percent of the time?'''\nrv = beta(4, 6)\nx = np.linspace(0, 1, 200)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Flip the coin 10 times and get 4 heads and 6 tails.')\nplt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), 0.6, 1)\nprint(f'\\nThe probability that the\\\ncoin will land on heads more than 60 percent of the time is {res[0]} with error of {res[1]}\\n')","d545a792":"'''You flip the coin 10 more times and now have 9 heads and 11 tails total. What is the\nprobability that the coin is fair, using our definition of fair, give or take 5 percent?'''\nrv = beta(9, 11)\nx = np.linspace(0, 1, 200)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Flip the coin 20 times and get 9 heads and 11 tails.')\nplt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), 0.45, .55)\nprint(f'\\nThe probability that the\\\ncoin will land on heads from 45 to 55 % of the time is {res[0]} with error of {res[1]}\\n')","c880811b":"'''Data is the best way to become more confident in your assertions. You flip the coin\n200 more times and end up with 109 heads and 111 tails. Now what is the probability that\nthe coin is fair, give or take 5 percent?'''\nrv = beta(109, 111)\nx = np.linspace(0, 1, 200)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Flip the coin \\\n200 more times and end up with 109 heads and 111 tails.')\nplt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), 0.45, .55)\nprint(f'\\nThe probability that the\\\ncoin will land on heads from 45 to 55 % of the time is {res[0]} with error of {res[1]}\\n')","69c94fa9":"# Distribution of c3-POs likelihood of surviving\nrv = beta(2, 7440)\nx = np.linspace(0, .005, 500)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Distribution of c3-POs likelihood of surviving')\n#plt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), 0, .001)\nprint(f'\\nThe probability of having survival probability at most .001 is {res[0]} with error of {res[1]}\\n')","4172415c":"# Distribution of out prior belief of Han Solo surviving\nrv = beta(20_000, 1)\nx = np.linspace(0.999, 1, 500)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Distribution of out prior belief of Han Solo surviving')\n#plt.axvline(.5)\nres = integrate.quad(lambda x: rv.pdf(x), .8, 1)\nprint(f'\\nThe probability of Han Solo surviving with at least 80% chance is {res[0]} with error of {res[1]}\\n')","40bdb9df":"'''Combining our two beta distributions\u2014one representing C-3PO\u2019s data (the likelihood) and\nthe other our prior belief in Han\u2019s ability to survive anything (our prior)\u2014in this way is remarkably\neasy:'''\nalpha_likelihood, alpha_prior, beta_likelihood, beta_prior = 2, 20000, 7440, 1\n\nrv = beta(alpha_likelihood + alpha_prior, beta_likelihood + beta_prior)\nx = np.linspace(0.69, 1, 1000)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Distribution of out prior belief of Han Solo surviving')\nplt.axvline(.72, c='r')\nres = integrate.quad(lambda x: rv.pdf(x), .72, 1)\nprint(f'\\nThe probability of Han Solo surviving with at least 72% chance is {res[0]} with error of {res[1]}\\n')","a44905a8":"'''A friend finds a coin on the ground, flips it, and gets six heads in a row and then one\ntails. Give the beta distribution that describes this. Use integration to determine the\nprobability that the true rate of flipping heads is between 0.4 and 0.6, reflecting that the coin\nis reasonably fair.'''\n\nrv = beta(6,1)\nx = np.linspace(0, 1, 1000)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Distribution of our prior belief of getting heads')\n#plt.axvline(.72, c='r')\nres = integrate.quad(lambda x: rv.pdf(x), .4, .6)\nprint(f'\\nThe probability that the true rate of flipping heads is between 0.4 and 0.6 is {res[0]} with error of {res[1]}.\\nSo the \\\ncoin does not seem to be fair. With about a 4 percent chance this coin is fair, based on likelihood \\\nalone, we would consider it unfair.\\n')","f5ec092a":"'''Come up with a prior probability that the coin is fair. Use a beta\ndistribution such that there is at least a 95 percent chance that the true\nrate of flipping heads is between 0.4 and 0.6.'''\nalpha_prior, beta_prior = 54, 54\nrv = beta(6 + alpha_prior, 1 + beta_prior)\nx = np.linspace(0, 1, 1000)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Distribution of our prior belief of getting heads')\n#plt.axvline(.72, c='r')\nres = integrate.quad(lambda x: rv.pdf(x), .4, .6)\nprint(f'\\nThe probability that the true rate of flipping heads is between 0.4 and 0.6 is {res[0]} with error of {res[1]}.\\n\\\nWith about a 95 percent chance this coin is fair, based on likelihood and prior\\\n, we would consider it fair.\\n')","8555dddc":"'''Now see how many more heads (with no more tails) it would take to\nconvince you that there is a reasonable chance that the coin is not fair. In\nthis case, let\u2019s say that this means that our belief in the rate of the coin\nbeing between 0.4 and 0.6 drops below 0.5.'''\nmoreheads = 22\nrv = beta(6 + alpha_prior + moreheads, 1 + beta_prior)\nx = np.linspace(0, 1, 1000)\nplt.plot(x, rv.pdf(x), lw=2)\n\nplt.title('Distribution of our prior belief of getting heads')\n#plt.axvline(.72, c='r')\nres = integrate.quad(lambda x: rv.pdf(x), .4, .6)\nprint(f'\\nThe probability that the true rate of flipping heads is between 0.4 and 0.6 is {res[0]} with error of {res[1]}.\\n\\\nWith about a 50 percent chance this coin is fair, based on likelihood and prior and more heads\\\n, we would consider it 50% fair.\\n')","ae440ad7":"'''Imagine a mustachioed cartoon villain wants to set off a bomb to blow a hole in a bank vault.\nUnfortunately, he has only one bomb, and it\u2019s rather large. He knows that if he gets 200 feet away\nfrom the bomb, he can escape to safety. It takes him 18 seconds to make it that far. If he\u2019s any closer\nto the bomb, he risks death.\nAlthough the villain has only one bomb, he has six fuses of equal size, so he decides to test out five\nof the six fuses, saving the last one for the bomb. The fuses are all the same size and should take the\nsame amount of time to burn through. He sets off each fuse and measures how long it takes to burn\nthrough to make sure he has the 18 seconds he needs to get away. Of course, being in a rush leads\nto some inconsistent measurements. Here are the times he recorded (in seconds) for each fuse to\nburn through: 19, 22, 20, 19, 23.\nSo far so good: none of the fuses takes less than 18 seconds to burn. Calculating the mean gives us \u03bc\n= 20.6, and calculating the standard deviation gives us \u03c3 = 1.62.'''\nl = [19, 22, 20, 19, 23]\nmu, sigma, var = np.mean(l), np.std(l), np.var(l)","cf882769":"np.sqrt(np.var(l))","45de9041":"rv = norm(mu, sigma)\nx = np.linspace(5, 35, 1000)\nplt.plot(x, rv.pdf(x), lw=2)\na = np.linspace(5, 18, 1000)\nplt.fill_between(a, rv.pdf(a), step='pre', alpha=.4)\n\nplt.title(f'Normal Distribution with given mu, sigma = {mu, sigma}')\nplt.axvline(mu, c='r')\nres = integrate.quad(lambda x: rv.pdf(x), 5, 18)\nprint(f'\\nWe can see that P(fuse time < 18) = {res[0]} with error {res[1]}, telling us there is a 5 percent chance \\\nthat the fuse will last 18 seconds or less. Even villains value their own lives, and in this case our \\\nvillain will attempt the bank robbery only if he is 99.9 percent sure that he can safely escape the \\\nblast. For today then, the bank is safe!\\n')\n","cd0ea7da":"''''The Probability of the data withing 1, 2, 3 -STD of MEAN is 68, 95, 99.7 % resp. So to get this info one does not need to integrate\nand one get this info for free'''\n\nfor i in range(1,4):\n    res = integrate.quad(lambda x: rv.pdf(x), mu - i*sigma, mu + i*sigma)\n    print(f'The Probability of the data withing {i}-STD of MEAN is {res[0]} with error of {res[1]}')\n    \nprint('\\n\\nThe probability that the \\\nvillain\u2019s bomb fuse will last longer than 21 seconds, we don\u2019t want to have to integrate from 21 to \\\ninfinity. What can we use for our upper bound? We can integrate from 21 to 25.46 (which is 20.6 + \\\n3 \u00d7 1.62), which is 3 standard deviations from our mean. Being three standard deviations from the \\\nmean will account for 99.7 percent of our total probability.')","6b2a8606":"# Normal vs Beta Distribution \nx = [1,1,1,0,0,0,0]\n\nb = beta(3, 4)\nmu, sigma = np.mean(x), np.std(x)\nnormal = norm(mu, sigma)\n\nx = np.linspace(0, 1, 1000)\nplt.plot(x, b.pdf(x), label='Beta Dist')\nplt.plot(x, normal.pdf(x), label='Normal Dist')\nplt.axvline(mu, c='r', label='Mean')\nplt.legend()","45c2f8e1":"'''What is the probability of observing a value five sigma greater than\nthe mean or more?'''\nres = integrate.quad(lambda x: normal.pdf(x), mu + 5*sigma, 100)\nprint(f'The Probability of the data beyond 5-STD of MEAN is {res[0]} with error of {res[1]}')\n    ","ac5cf9e2":"'''A fever is any temperature greater than 100.4 degrees Fahrenheit.\nGiven the following measurements, what is the probability that the patient\nhas a fever?\n100.0, 99.8, 101.0, 100.5, 99.7'''\n\nx = [100.0, 99.8, 101.0, 100.5, 99.7]\n\nmu, sigma = np.mean(x), np.std(x)\n\nnormal = norm(mu, sigma)\n\nd = np.linspace(95, 105, 1000)\nplt.plot(d, normal.pdf(d))\nplt.axvline(100.4)\n\nres = integrate.quad(lambda x: normal.pdf(x), 100.4, 105)\nprint(f'The Probability of the of having fever is {res[0]} with error of {res[1]}.\\nGiven these measurements,\\\nthere\u2019s about a 34 percent chance of fever.\\n')\n    \n","48879129":"np.sqrt(1000\/9.8)","996e7399":"'''Suppose in Chapter 11 we tried to measure the depth of a well by\ntiming coin drops and got the following values:\n2.5, 3, 3.5, 4, 2\nThe distance an object falls can be calculated (in meters) with the\nfollowing formula:\ndistance = 1\/2 \u00d7 G \u00d7 time^2\nwhere G is 9.8 m\/s^2. What is the probability that the well is over 500\nmeters deep?'''\n\nx = [2.5, 3, 3.5, 4, 2]\nmu, sigma = np.mean(x), np.std(x)\n\nnormal = norm(mu, sigma)\n\nd = np.linspace(-1, 7, 1000)\nplt.plot(d, normal.pdf(d))\nplt.axvline(mu)\n\n#time needed for reaching 500 meter deep\nt = np.sqrt(1000\/9.8)\nres = integrate.quad(lambda x: normal.pdf(x), t, t + 10)\nprint(f'The coin takes {t} seconds to reach 500m deep. \\nThe Probability of well 500m deep is {res[0]} with error of {res[1]}.\\nGiven these measurements,\\\nthere\u2019s about a {res[0]*100} percent chance of 500m deep. That is almost surely it is not 500m deep.\\n')","2781a960":"'''What is the probability there is no well (i.e., the well is really 0 meters\ndeep)? You\u2019ll notice that probability is higher than you might expect, given\nyour observation that there is a well. There are two good explanations for\nthis probability being higher than it should. The first is that the normal \ndistribution is a poor model for our measurements; the second is that,\nwhen making up numbers for an example, I chose values that you likely\nwouldn\u2019t see in real life. Which is more likely to you?'''\n\nres = integrate.quad(lambda x: normal.pdf(x), -1, 0)\nprint(f'\\nThe probability that there is no well (i.e., the well is really 0 meters \\\ndeep) is {res[0]} with error of {res[1]}. It\u2019s small, but the probability that there is no well is greater than 1 \\\nin 100,000.')","3a1c6e83":"'''ESTIMATING THE CONVERSION RATE FOR AN EMAIL SIGNUP\nLIST\nSay you run a blog and want to know the probability that a visitor to your blog will subscribe to\nyour email list. In marketing terms, getting a user to perform a desired event is referred to as\nthe conversion event, or simply a conversion, and the probability that a user will subscribe is\nthe conversion rate.\nAs discussed in Chapter 5, we would use the beta distribution to estimate p, the probability of\nsubscribing, when we know k, the number of people subscribed, and n, the total number of visitors.\nThe two parameters needed for the beta distribution are \u03b1, which in this case represents the total\nsubscribed (k), and \u03b2, representing the total not subscribed (n \u2013 k).\nWhen the beta distribution was introduced, you learned only the basics of what it looked like and\nhow it behaved. Now you\u2019ll see how to use it as the foundation for parameter estimation. We want\nto not only make a single estimate for our conversion rate, but also come up with a range of\npossible values within which we can be very confident the real conversion rate lies.'''\n\nb = beta(300, 39700)\nx = np.linspace(0, .02, 500)\nplt.plot(x, b.pdf(x), lw=2)\n\nplt.title('Email subscription density distribution')\n#plt.axvline(.5)\nmost_65 = integrate.quad(lambda x: b.pdf(x), 0, .0065)\natleast_85 = integrate.quad(lambda x: b.pdf(x), .0085, 1)\nprint(f'\\nThe probability that the \\\nconversion rate is <= .0065 is {most_65[0]} with error of {most_65[1]}. \\nAnd the probability that the \\\nconversion rate is >= .0085 is {atleast_85[0]} with error of {atleast_85[1]}.\\n\\nThis means that if we had to make a \\\ndecision with the limited data we have, we could still calculate how much likelier one extreme is \\\nthan the other: \\n\\nIn fact, there is {100*(-1+(atleast_85[0]\/most_65[0]))} percent more likely that our true conversion rate is greater than 0.0085 than that it\u2019s \\\nlower than 0.0065.\\n')","db788a98":"# CDF\nb = beta(300, 39700)\nx = np.linspace(0, .1, 500)\nplt.plot(x, b.cdf(x), lw=2, label='CDF')\n\nplt.title('Email subscription CDF')\nplt.axvline(.0065, c='r',label='.0065')\nplt.axvline(.0085, c='g', label='.0085')\nplt.legend()","34eda88d":"x = np.linspace(0, .02, 50000)\na = b.cdf(x)\nmedian_index = np.where((a <= .5005) & (.49999 <= a))\na[median_index], x[median_index]\nplt.plot(x, b.cdf(x), lw=2, label='CDF')\n\nplt.title('Email subscription CDF')\nplt.axvline(.0065, c='r',label='.0065')\nplt.axvline(.0085, c='g', label='.0085')\nplt.axvline(x[median_index], label=f'Median is {x[median_index][0]}')\nplt.axhline(a[median_index], label=f'{a[median_index][0]}')\n\nplt.legend()","f5a271e5":"x = np.linspace(0, .02, 50000)\na = b.cdf(x)\nmedian_index = np.where((a <= .5005) & (.49999 <= a))\na[median_index], x[median_index]\nplt.plot(x, b.cdf(x), lw=2, label='CDF')\n\nplt.title('Email subscription CDF')\nplt.axvline(x[median_index], c='r',label=f'{x[median_index]}')\nplt.axvline(.0085, c='g', label='.0085')\nplt.axhline(a[median_index], label=f'Median is {x[median_index][0]}')\nplt.axhline(b.cdf(.0085), label=f'CDF at .0085 probability')\n\nplt.legend()\nprint(f'\\nTo estimate the probability that the conversion rate is between 0.0075 and 0.0085, we can trace \\\nlines from the x-axis at these points, then see where they meet up with the y-axis. The distance \\\nbetween the two points is the approximate integral. We can see that on the y-axis these values range from roughly 0.5 to 0.99, \\\nmeaning that there is approximately a {(b.cdf(.0085)-a[median_index])*100} percent chance that our true conversion rate lies \\\nsomewhere between these two values.\\n\\n')","44a6b1d4":"x = np.linspace(0, .02, 50000)\na = b.cdf(x)\nepsilon = .0001\nlower_index = np.where((a <= .1 + epsilon) & (.1 - epsilon <= a))\nupper_index = np.where((a <= .9 + epsilon) & (.9 - epsilon <= a))\n#print(lower_index, upper_index)\na[median_index], x[median_index]\nplt.plot(x, b.cdf(x), lw=2, label='CDF')\n\nplt.title('Email subscription CDF')\nplt.axvline(x[lower_index], c='r',label=f'LOWER')\nplt.axvline(x[upper_index], c='g', label='UPPER')\nplt.axhline(a[lower_index], label=f'About .1 density')\nplt.axhline(a[upper_index], label=f'About .9 density')\n\nplt.legend()\nprint(f'\\nSo about 80% chance that our true conversion rate falls somewhere between {x[lower_index][0],x[upper_index][0]}\\n\\n')","1b9076be":"# PPF is inverse of cdf in Python : \n# https:\/\/stackoverflow.com\/questions\/20626994\/how-to-calculate-the-inverse-of-the-normal-cumulative-distribution-function-in-p\n\nb = beta(300, 39700)\npercentile = b.ppf(.999)\nprint(f'The result is {percentile}, meaning we can be 99.9 percent certain that the true conversion rate for our \\\nemails is less than {percentile}')\n\n'''We can then use the quantile function to quickly calculate exact values\nfor confidence intervals for our estimates. To find the 95 percent confidence interval, we can find\nthe values greater than the 2.5 percent lower quantile and the values lower than the 97.5 percent upper \nquantile, and the interval between them is the 95 percent confidence interval (the\nunaccounted region totals 5 percent of the probability density at both extremes).'''\n\nl, u = b.ppf(.025), b.ppf(1-.025)\n\nprint(f'\\nNow we can confidently say that we are 95 percent certain that the real conversion rate for blog \\\nvisitors is somewhere between {l*100} percent and {u*100} percent.\\n\\nWe can, of course, increase or decrease these thresholds \\\ndepending on how certain we want to be. \\\nNow that we have all of the tools of parameter estimation, we can easily pin down an exact range \\\nfor the conversion rate. The great news is that we can also use this to predict ranges of values for \\\nfuture events. Suppose an article on your blog goes viral and gets 100,000 visitors. Based on our calculations, we \\\nknow that we should expect between {l*100000} and {u*100000} new email subscribers with 95% confidence')","b26fbe3d":"# Checking ppf is inverse of cdf\nx = np.linspace(0,1,10000)\nfor i in range(10):\n    if round(b.cdf(b.ppf(x[i])) - x[i],3) != 0:\n        print(i, 'CDF - PPF')\n    if round(b.ppf(b.cdf(x[i])) - x[i],3) != 0:\n        print(i, round(b.ppf(b.cdf(x[i])) - x[i],10), 'PPF - CDF')","05f5e86a":"'''Plot the CDF and quantile functions for beta(300, 39700)'''\nb = beta(300, 39700)\nx = np.linspace(.005, .01, 1000)\n\nplt.plot(x, b.cdf(x))\nplt.xlabel('\"Probability of subscription\"')\nplt.ylabel(\"Cumulative probability\")\nplt.title('CDF Beta(300,39700)')\nplt.legend()","d1cfbb17":"x = np.linspace(.001, .99, 1000)\n\nplt.plot(x, b.ppf(x))\nplt.xlabel('Quantile')\nplt.ylabel(\"Probability of subscription\")\nplt.title(\"Quantile of Beta(300,39700)\")","6589e595":"'''Returning to the task of measuring snowfall from Chapter 10, say you\nhave the following measurements (in inches) of snowfall:\n7.8, 9.4, 10.0, 7.9, 9.4, 7.0, 7.0, 7.1, 8.9, 7.4\nWhat is your 99.9 percent confidence interval for the true value of\nsnowfall?'''\nsnow = [7.8, 9.4, 10.0, 7.9, 9.4, 7.0, 7.0, 7.1, 8.9, 7.4]\n\nmu, sigma = np.mean(snow), np.std(snow)\n\nnormal = norm(mu, sigma)\n# to calculate the 99.9 percent confidence interval upper and lower bounds.\nl, u = normal.ppf(.0005), normal.ppf(1-.0005)\n\nprint(f'\\nThis means that we\u2019re very confident that there\u2019s no less than {l} \\\ninches of snowfall and no more than {u}.\\n')","1973cb54":"'''A child is going door to door selling candy bars. So far she has visited\n30 houses and sold 10 candy bars. She will visit 40 more houses today.\nWhat is the 95 percent confidence interval for how many candy bars she\nwill sell the rest of the day?'''\n\nb = beta(10, 20)\n\nl, u = b.ppf(.025), b.ppf(1-.025)\n\nprint(f\"The 95 percent confidence interval for candy sell is {l*40, u * 40}\")","cdf44b65":"# Normal Distribution","acbf41fa":"This nb is based on a wonderful book by Will Kurt. Thanks very much for writing such a nice book :)\nCheck out https:\/\/nostarch.com\/learnbayes\n\n# Imports","8e35f3db":"Our friend will pull for this card only if the probability\nis around 0.7 or greater, so based on the evidence from our data collection, our friend should not try\nhis luck.","801a5e62":"If you really want to be particular, we could actually calculate the\nquantile for the binomial distribution at each extreme of her selling\nrates.\n\nTo be continued at https:\/\/www.kaggle.com\/bhavinmoriya\/bayesian-statistics-the-fun-way-by-will-kurt-1","4dd0a362":"Now we find that there\u2019s a 86 percent chance that our coin is fair,\ngiven the new data we have.","c501cc7f":"# THE PDF, CDF, AND QUANTILE FUNCTION","265c5064":"# THE QUANTILE FUNCTION\nYou might have noticed that the median and confidence intervals we took visually with the CDF are\nnot easy to do mathematically. With the visualizations, we simply drew lines from the y-axis and\nused those to find a point on the x-axis.\nMathematically, the CDF is like any other function in that it takes an x value, often representing the\nvalue we\u2019re trying to estimate, and gives us a y value, which represents the cumulative probability.\nBut there is no obvious way to do this in reverse; that is, we can\u2019t give the same function a y to get\nan x. As an example, imagine we have a function that squares values. We know that square(3) = 9,\nbut we need an entirely new function\u2014the square root function\u2014to know that the square root of 9\nis 3.\n\nHowever, reversing the function is exactly what we did in the previous section to estimate the\nmedian: we looked at the y-axis for 0.5, then traced it back to the x-axis. What we\u2019ve done visually is\ncompute the inverse of the CDF.\n\nWhile computing the inverse of the CDF visually is easy for estimates, we need a separate\nmathematical function to compute it for exact values. The inverse of the CDF is an incredibly\ncommon and useful tool called the quantile function. To compute an exact value for our median and\nconfidence interval, we need to use the quantile function for the beta distribution. Just like the CDF,\nthe quantile function is often very tricky to derive and use mathematically, so instead we rely on\nsoftware to do the hard work for us.","176adb7b":"# Beta Distribution","faa47c9a":"Now, we cross check the probabilities with the actual probabilities calculations.","f4a8e816":"It\u2019s clear that these distributions are quite different. We can see that for both distributions the\ncenter of mass appears in roughly the same place, but the bounds for the normal distribution\nextend way beyond the limits of our graph. This demonstrates a key point: only when you know\nnothing about the data other than its mean and variance is it safe to assume a normal distribution.\nFor the beta distribution, we know that the value we\u2019re looking for must lie in the range 0 to 1. The\nnormal distribution is defined from \u2013\u221e to \u221e, which often includes values that cannot possibly exist.\nHowever, in most cases this is not practically important because measurements out that far are essentially impossible in probabilistic terms. But for our example of measuring the probability of an\nevent happening, this missing information is important for modeling our problem.\nSo, while the normal distribution is a very powerful tool, it is no substitute for having more\ninformation about a problem.","097ee261":"# Binomial Distribution","9066b44b":"So coin does not seem to be fair. Now we find that there\u2019s a 30 percent chance that our coin is fair,\ngiven the new data we have.","860b327b":"But you can see a well! It\u2019s right in front of you! So, even\nif the probability is small, it\u2019s not really that close to zero. Now should\nwe question the model, or should we question the data? ***As a Bayesian,\ngenerally you should favor questioning the model over the data.*** For\nexample, movement in stock prices will typically have very high \u03c3 events\nduring financial crises. This means that the normal distribution is a\nbad model for stock movements.\n\nOne of the greatest virtues in statistical analysis is skepticism. In\npractice I have been given bad data to work with on a few occasions.\n***Even though models are always imperfect, it\u2019s very important to make\nsure that you can trust your data as well.*** See if the assumptions you\nhave about the world hold up and, if they don\u2019t, see if you can be convinced \nthat you still trust your model and your data.","d7c4f376":"# Basics","2c954127":"Note that with the beliefs of just Han Solo we were getting 80% chance of servival with probabiltity almost 1. But using the information of C3-PO together with the Han Solo JackAss skills we got 72% chance of servival with probabiltity almost 1, so Han is not the same JackAss anymore :)\n\nWe learned how important background information is to analyzing the data in front\nof you. C-3PO\u2019s data provided us with a likelihood function that didn\u2019t match up with our prior\nunderstanding of Han\u2019s abilities. Rather than simply dismissing C-3PO, as Han famously does, we\ncombine C-3PO\u2019s likelihood with our prior to come up with an adjusted belief about the possibility\nof Han\u2019s success. In Star Wars: The Empire Strikes Back, this uncertainty is vital for the tension the\nscene creates. If we completely believe C-3PO\u2019s data or our own prior, we would either be nearly\ncertain that Han would die or be nearly certain that he would survive without trouble.","1f654833":"# Calculating Median in continuous distribution\n\nThe median is the point in the data at which half the values fall on one side and half on the other\u2014it\nis the exact middle value of our data. In other words, the probability of a value being greater than\nthe median and the probability of it being less than the median are both 0.5. The median is\nparticularly useful for summarizing the data in cases where it contains extreme values.\nUnlike the mean, computing the median can actually be pretty tricky. For small, discrete cases, it\u2019s\nas simple as putting your observations in order and selecting the value in the middle. But for\ncontinuous distributions like our beta distribution, it\u2019s a little more complicated.\n\nThankfully, we can easily spot the median on a visualization of the CDF. We can simply draw a line\nfrom the point where the cumulative probability is 0.5, meaning 50 percent of the values are below\nthis point and 50 percent are above. As Figure 3-5 illustrates, the point where this line intersects\nthe x-axis gives us our median!","2dc4302e":"**In fact, if you ever observe data that is five standard deviations from the mean, it\u2019s likely a good sign\nthat your normal distribution is not modeling the underlying data accurately.**","a7b85d37":"# Estimating Confidence Intervals\n\nLooking at the probability of ranges of values leads us to a very important concept in probability:\nthe confidence interval. A confidence interval is a lower and upper bound of values, typically\ncentered on the mean, describing a range of high probability, usually 95, 99, or 99.9 percent. When\nwe say something like \u201cThe 95 percent confidence interval is from 12 to 20,\u201d what we mean is that\nthere is a 95 percent probability that our true measurement is somewhere between 12 and 20.\nConfidence intervals provide a good method of describing the range of possibilities when we\u2019re\ndealing with uncertain information.\n\n***NOTE*** : In Bayesian statistics what we are calling a \u201cconfidence interval\u201d can go by a few other names, such as\n\u201ccritical region\u201d or \u201ccritical interval.\u201d In some more traditional schools of statistics, \u201cconfidence\ninterval\u201d has a slightly different meaning, which is beyond the scope of this book.\nWe can estimate confidence intervals using the CDF. Say we wanted to know the range that covers\n80 percent of the possible values for the true conversion rate. We solve this problem by combining our previous approaches: we draw lines at the y-axis from 0.1 and 0.9 to cover 80 percent, and then\nsimply see where on the x-axis these intersect with our CDF. As you can see, the x-axis is intersected at roughly 0.007 and 0.008, which means that there\u2019s an 80\npercent chance that our true conversion rate falls somewhere between these two values.","1671d780":"# Gacha Games"}}