{"cell_type":{"92709aa1":"code","fa91c9df":"code","40cbcb6d":"code","a23912ea":"code","bcb85933":"code","bbbb19c3":"code","bccc730e":"code","34948e61":"code","bbd3f1be":"code","a2cd1683":"code","cecb7959":"code","e5f6e1f5":"code","49beaee9":"code","07147fcf":"markdown","57830aa5":"markdown","68823fd2":"markdown","fe1345ac":"markdown","54b79286":"markdown","4e9e808d":"markdown","f9398dd5":"markdown"},"source":{"92709aa1":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport cv2\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nimport itertools\n\n\nsns.set(style='white', context='notebook', palette='deep')\n","fa91c9df":"n = 128\ni=0\nX=np.zeros((741,n,n))\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        im= cv2.imread((os.path.join(dirname, filename)))\n        resized_image = cv2.resize(im, (n,n))\n        X[i,:,:]=np.sum(resized_image,axis=2)\n        i+=1","40cbcb6d":"X\/=255*3 # normalising \nX = X.reshape(-1,n,n,1) #reshaping as tensor becuase keras accpets only tensor inputs\nX.shape","a23912ea":"train_label = np.zeros(741)\nlabel=np.array([82,59,299,301])\na=0\nfor i in range(4):\n    for j in range(label[i]):\n        train_label[j+a]=i\n    a+=j+1\nlabels=train_label%2","bcb85933":"labels","bbbb19c3":"X_train, X_test, Y_train, Y_test = train_test_split(X, labels, test_size = 0.2, random_state=50)","bccc730e":"model = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu', input_shape = (128,128,1)))\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.01))\n\n\nmodel.add(Conv2D(filters = 8, kernel_size = (1,1),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 8, kernel_size = (1,1),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.01))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(16, activation = \"relu\"))\nmodel.add(Dropout(0.01))\nmodel.add(Dense(1, activation = \"sigmoid\"))","34948e61":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","bbd3f1be":"epochs = 50\nbatch_size = 50","a2cd1683":"history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n           verbose = 1)","cecb7959":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n#ax[0].plot(history.history['test_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='r', label=\"Training accuracy\")\n#ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n","e5f6e1f5":"# Predict the values from the validation dataset\nY_pred = model.predict(X_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred) \n# Convert validation observations to one hot vectors\nyl=len(Y_pred)\nY_test=Y_test.reshape(yl,1)\nfor j in range(yl):\n    if Y_pred[j]>0.25:\n        Y_pred[j]=1\n    else:\n        Y_pred[j]=0        \nconfusion_matrix(Y_test, Y_pred)\n","49beaee9":"score=model.evaluate(X_test,Y_test)\nprint(f'loss value is {score[0]})')\nprint(f'accuracy of the model is {score[1]*100}%')","07147fcf":"# Creating the CNN model","57830aa5":"# Loading the Data","68823fd2":"# Creating Labels ","fe1345ac":"# Splitting the Data into test and train","54b79286":"# Evaluating the Model","4e9e808d":"# Compiling and fitting the model","f9398dd5":"# Importing the libraries for data handling and representing the Data"}}