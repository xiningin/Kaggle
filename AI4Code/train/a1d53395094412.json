{"cell_type":{"2a1f9ce7":"code","18dc7be2":"code","35ba879e":"code","a7acbf78":"code","931b8937":"code","78777d39":"code","91280102":"code","f43936c3":"code","091240ec":"code","be5be58b":"code","be4512a8":"code","709a83c8":"code","0b81ed13":"code","78920012":"code","7e2ebc22":"code","4eef68b9":"code","1156acd5":"code","b8176be6":"markdown","ef3bbeec":"markdown","474bc23c":"markdown","bcd0cba3":"markdown","3202ce40":"markdown","bd2a6dbc":"markdown","05613d76":"markdown","5dbafda1":"markdown","f7356b3c":"markdown","639ffee1":"markdown","8c4c2799":"markdown","f03dbd36":"markdown"},"source":{"2a1f9ce7":"import os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport tensorflow as tf\nfrom tensorflow import keras \nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n%matplotlib inline","18dc7be2":"for file in os.listdir('\/kaggle\/input\/intel-image-classification'):\n    print(file)","35ba879e":"path='\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/forest'\npath=path+'\/'+os.listdir(path)[0]\nimg=cv.imread(path)\nplt.imshow(img)","a7acbf78":"train_path='\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_path='\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test'\npredict_path='\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred'","931b8937":"len(os.listdir(train_path+'\/forest'))","78777d39":"from keras.preprocessing.image import ImageDataGenerator\ntrain_data_gen=ImageDataGenerator(rescale=1\/255,\n                                  rotation_range=20,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  shear_range=0.2,\n                                  height_shift_range=0.2,\n                                  width_shift_range=0.2,\n                                  fill_mode='nearest'\n                                 )\ntrain_gen=train_data_gen.flow_from_directory(\n    train_path,\n    target_size=(150,150),\n    batch_size=30,\n    class_mode='categorical'\n)\ntest_data_gen=ImageDataGenerator(rescale=1\/255)\ntest_gen=test_data_gen.flow_from_directory(\n    test_path,\n    target_size=(150,150),\n    batch_size=30,\n    class_mode='categorical'\n)","91280102":"model=keras.Sequential([Conv2D(256,(3,3),input_shape=(150,150,3),padding='same',activation='relu'),\n                        MaxPooling2D(2,2),\n                        Conv2D(128,(3,3),padding='same',activation='relu'),\n                        Conv2D(128,(3,3),padding='same',activation='relu'),\n                        Conv2D(64,(3,3),padding='same',activation='relu'),\n                        MaxPooling2D(2,2),\n                        Dropout(0.25),\n                        Conv2D(64,(3,3),padding='same',activation='relu'),\n                        MaxPooling2D(2,2),\n                        Dropout(0.25),\n                        Conv2D(64,(3,3),padding='same',activation='relu'),\n                        MaxPooling2D(2,2),\n                        Dropout(0.25),\n                        Conv2D(32,(3,3),padding='same',activation='relu'),\n                        MaxPooling2D(2,2),\n                        Dropout(0.5),\n                        Flatten(),\n                        Dense(256,activation='relu'),\n                        Dropout(0.25),\n                        Dense(1024,activation='relu'),\n                        Dense(6,activation='softmax')\n                       ])","f43936c3":"model.summary()","091240ec":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']\n             )","be5be58b":"history=model.fit_generator(train_gen,validation_data=test_gen,steps_per_epoch=14034\/\/30,epochs=50)","be4512a8":"from keras.models import load_model\nmodel.save(\"model.h5\")\nmodel = load_model('model.h5')","709a83c8":"train_loss=history.history['loss']\ntrain_accuracy=history.history['accuracy']\nvalid_loss=history.history['val_loss']\nvalid_accuracy=history.history['val_accuracy']","0b81ed13":"plt.figure()\nepochs=range(len(valid_accuracy))\n\nplt.plot(epochs,train_accuracy,'r',label='Training accuracy')\nplt.plot(epochs,valid_accuracy,'b',label='Testing accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epochs,train_loss,'r',label='Training loss')\nplt.plot(epochs,valid_loss,'b',label='Testing loss')\nplt.legend()","78920012":"from keras.preprocessing import image\nY_pred=[]\n\nfor file in os.listdir(predict_path):\n    img = image.load_img(path= predict_path+'\/'+file,target_size=(150,150,3))\n    img = image.img_to_array(img)\n    test_img = img.reshape((1,150,150,3))\n    img_class = model.predict_classes(test_img)\n    prediction = img_class[0]\n    Y_pred.append(prediction)","7e2ebc22":"classes={0:'buildings',\n 1:'forest',\n 2:'glacier',\n 3:'mountain',\n 4:'sea',\n 5:'street'}","4eef68b9":"yhat = [classes[idx] for idx in Y_pred] ","1156acd5":"i=1\nplt.figure(figsize=(18,18))\nfor file in os.listdir(predict_path)[:16]:\n    img=cv.imread(predict_path+'\/'+file)\n    plt.subplot(4,4,i)\n    plt.imshow(img)\n    plt.title(yhat[i-1])\n    i+=1","b8176be6":"<b><h3>We will use Image Augmentation on the images provided using Image Data Generator<\/h3>\n\n<h4>For those who don't know about Image Augmentation it's just like a process of applying different filters. For ex. rotation_range is used to rotate the image within given angle and then train the model on the image produced after its rotated by some random angle and orignal one helping the model train on more diverse images hence improving it's accuracy even when the training data is small.<\/h4>\n\n<h4>If you want to learn about how to implement different filters and their use vist the link -><a href='https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator'>Image Augmentation<\/a><\/h4><\/b>","ef3bbeec":"<h4>Note as we have multi classes in the dataset we will set the class_mode to 'categorical'<\/h4>","474bc23c":"# Now Let's plot the graph between loss and accuracy on Training and Validation data","bcd0cba3":"# Now Let's predict on the unseen data","3202ce40":"<b>Let's print first image from Forest directory <\/b>","bd2a6dbc":"<h3 style='color:red;font-size:20px;font-family:cursive'><b>Please comment below if you have any doubt regarding the notebook also please do upvote my notebook if you like it<\/b><\/h3>","05613d76":"<h1><center style='color:blue'>Don't Forget to upvote the Notebook if you find it useful &#128522;<\/center><\/h1>","5dbafda1":"<h3><b>Let's see the class predicted by our model on some examples which are new for model<\/b><\/h3>","f7356b3c":"# Importing Liabraries","639ffee1":"<h3>Now we will create the model using different features of keras<\/h3>","8c4c2799":"Let's first import the liabraries we will need during classification\n","f03dbd36":"<b>The task in this dataset is to identify the images using deep learning. The 6 different classes in the dataset are :\n<ul>\n    <li>Buildings<\/li>\n    <li>Forest<\/li>\n    <li>Glacier<\/li>\n    <li>Mountain<\/li>\n    <li>Sea<\/li>\n    <li>Street<\/li>\n<\/ul>\n<i>Note: In this notebook we will use Tensorflow and keras for classifying the images<\/i>\n<\/b>"}}