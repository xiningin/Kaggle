{"cell_type":{"8631816a":"code","c17d6af3":"code","3494ff99":"code","3edc5732":"code","fb8e8a39":"code","fd3ee965":"code","80132a2a":"code","13044e4c":"code","5d71b7d7":"code","c519abad":"code","60dbb79d":"code","5bece8fe":"code","81b54dc6":"code","dbc20ae6":"code","271e5331":"code","f82dfdea":"markdown","44901d4b":"markdown","e9bacfb9":"markdown","61e65c17":"markdown","59db6823":"markdown","499e91e5":"markdown","b38c3ca9":"markdown","fc88b84e":"markdown","db409563":"markdown","4f62680b":"markdown","b213a35d":"markdown","47714d3e":"markdown","71eb8dcd":"markdown","22d410f5":"markdown"},"source":{"8631816a":"!nvidia-smi","c17d6af3":"from google.colab import drive\ndrive.mount(\"\/content\/gdrive\", force_remount=True)","3494ff99":"!unzip \".\/gdrive\/My Drive\/shopee-product-detection-dataset.zip\"","3edc5732":"# See how the folders are named for each category\n!ls \".\/train\/train\"","fb8e8a39":"%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os\nfrom torch.utils.data.dataset import Dataset\nimport numpy as np\nimport pandas as pd\nimport torchvision.models as models\nimport torch.nn as nn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nfrom PIL import Image,ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom tqdm.notebook import tqdm","fd3ee965":"path=\".\/train\/train\/\"                                       # where the training images are\nclasses = [\"%.2d\" % i for i in range(len(os.listdir(path)))]    # ['00','01',...,'41'] i.e. the folders for the images of each corresponding category\nfor i in classes:\n    ls = sorted(os.listdir(path+i))\n    print(\"Number of images for Class {}:\".format(i),len(ls))\n    img=mpimg.imread(path+'{}\/{}'.format(i,ls[1]))          # load images\n    imgplot = plt.imshow(img)                               # display images\n    plt.show()","80132a2a":"class ShopeeDataset(Dataset):\n    def __init__(self,directory,transform,train=True):\n        self.transform = transform                      # function that turns an image into a tensor that can be passed to the pytorch model\n        self.img_ls = list()                            # where the path to each training image file is stored\n\n        classes = [\"%.2d\" % i for i in range(len(os.listdir(directory)))]           # ['00','01',...,'41'] i.e. the folders for the images of each corresponding category\n        for clas in classes:\n            path = os.path.join(directory,clas)\n            ls = sorted(os.listdir(path))               # obtain list of image file names in a class folder\n            if train:\n                for img_name in ls[:-50]:                                           # take all images except the last 50 images for each category. This will be used as training data\n                    self.img_ls.append((os.path.join(path,img_name),int(clas)))     # adds to img_ls in a tuple format (path,category)\n            else:\n                for img_name in ls[-50:]:                                           # last 50 images of each category for validation set, for monitoring of current performance\n                    self.img_ls.append((os.path.join(path,img_name),int(clas)))\n        \n    def __getitem__(self, idx):                         # this function will be called by pytorch dataloader class.\n        name, label = self.img_ls[idx]\n        img = Image.open(name).convert('RGB')           # load image\n        img.load()\n        img = self.transform(img)                       # apply transformation to turn image into torch tensor\n        return {\"image\": img, \"label\": label}\n    \n    def __len__(self):                                  # allows usage of len(<name of dataset>) to obtain size of entire dataset\n        return len(self.img_ls)","13044e4c":"def train_epoch(model,  trainloader,  criterion, device, optimizer):\n\n\n    model.train()\n    losses = list()\n    ct=0\n    for batch_idx, data in enumerate(tqdm(trainloader)):       #iterate through dataset. tqdm is the loading bar, allows you to track progress\n        ct+=1\n        inputs=data['image'].to(device)                 # images\n        labels=data['label'].to(device)                 # labels\n        optimizer.zero_grad()\n        outputs = model(inputs)                         # prediction\n        loss = criterion(outputs, labels)               # loss function, tells you how \"wrong\" your predictions are based on the training dataset.\n        loss.backward()                                 # backpropogation\n        optimizer.step()                                # gradient descent\n        losses.append(loss.item())\n\n    return sum(losses)\/ct","5d71b7d7":"def evaluate(model, dataloader, device):\n\n    model.eval()                                                    # set model to evaluation mode\n    total=0                                                         # store total number of validation samples\n    correct = 0                                                     # store total number of correct prediction samples\n    with torch.no_grad():\n      for ctr, data in enumerate(dataloader):\n          inputs = data['image'].to(device)                         # obtain validation images\n          outputs = model(inputs)                                   # pass images to model\n          labels = data['label']                                    # actual labels for validation images. Also known as ground truth\n          labels = labels.float()\n          cpuout= outputs.to('cpu')\n          total += len(labels)                                      # total number of samples\n\n          pred = cpuout.argmax(dim=1, keepdim=True)                 # for each sample, the model gives a score for each category. Choose the category that contains the highest score as the prediction\n          correct += pred.eq(labels.view_as(pred)).sum().item()     # number of correct predictions\n\n      accuracy = correct \/ total                                    # accuracy = total correct \/ total number of samples\n\n    return accuracy","c519abad":"def train_modelcv(dataloader_cvtrain, dataloader_cvtest ,  model ,  criterion, optimizer, scheduler, num_epochs, device):\n\n  for epoch in range(num_epochs):                                                           # iterates through specified number of epochs\n    print('-' * 10)\n    print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n\n    model.train(True)                                                                           \n    train_loss=train_epoch(model,  dataloader_cvtrain,  criterion,  device , optimizer )    # train model\n\n    model.train(False)\n    measure = evaluate(model, dataloader_cvtest, device)                                    # evaluate model\n\n    print('Top 1 Accuracy:', measure, \"\\n\")                                                 # print accuracy for current epoch\n  return None","60dbb79d":"batchsize=64                                                            # number of images being passed to the model at any one time. If you face cuda memory error, reduce batchsize.\nlr = 0.01                                                               # how \"fast\" you want your model to learn. Very important to play around with different values.\n\n\ndata_transform = transforms.Compose([transforms.Resize((224,224)),      # images are of different size, reshape them to same size. Up to you to decide what size to use.\n                                     transforms.ToTensor(),             # convert image to torch tensor\n                                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])   # normalizing images helps improve convergence\n\npath = \".\/train\/train\"                                                  # where your training images are\ndataset_train = ShopeeDataset(path, data_transform,train=True)          # training dataset\ndataset_valid = ShopeeDataset(path, data_transform,train=False)         # validation dataset to measure current model performance. (rough gauge)\n\nloadertr=torch.utils.data.DataLoader(dataset_train,batch_size=batchsize,shuffle=True)       # dataloader for training set\nloaderval=torch.utils.data.DataLoader(dataset_valid,batch_size=batchsize,shuffle=True)      # dataloader for validation set\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # which device to use. If GPU is detected, use GPU, else, use CPU\ncriterion = nn.CrossEntropyLoss()                                       # Loss function\n\nmodel = models.resnet18(pretrained=True)                                # transfer learning, Pytorch has a pretrained model trained on ImageNet. Turn this off if you want to, it may or may not help in the end. Helps achieve higher accuracy with less epochs though\nmodel.fc = nn.Linear(512, 42)                                           # as we only have 42 classes, change the last layer to predict on 42 classes.\nmodel.to(device)                                                        # send model to device, and hopefully your device is GPU\n\noptimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\nmaxnumepochs=2                                                          # number of epochs to train on. Should most definitely increase this to train more.\ntrain_modelcv(dataloader_cvtrain = loadertr,                            # lets start training\n              dataloader_cvtest = loaderval,  \n              model = model,  \n              criterion = criterion, \n              optimizer = optimizer,\n              scheduler = None,\n              num_epochs = maxnumepochs,\n              device = device)","5bece8fe":"class ShopeeTestDataset(Dataset):\n    def __init__(self,directory,transform):\n        self.transform = transform\n        self.img_ls = list()\n\n        ls = sorted(os.listdir(directory))\n        for img_name in ls:\n            self.img_ls.append((os.path.join(directory,img_name)))\n        \n    def __getitem__(self, idx):\n        name = self.img_ls[idx]\n        img = Image.open(name).convert('RGB')\n        img.load()\n        img = self.transform(img)\n        return img,name[12:]\n    \n    def __len__(self):\n        return len(self.img_ls)","81b54dc6":"def inference(model, dataloader, device):\n    # df = pd.DataFrame()\n    path_ls = list()\n    pred_ls = list()\n    model.eval()\n    with torch.no_grad():\n      for ctr, data in enumerate(dataloader):\n          inputs,path = data\n          inputs = inputs.to(device)\n          outputs = model(inputs)\n          cpuout= outputs.to('cpu')\n          pred = cpuout.argmax(dim=1).numpy()\n          path_ls += list(path)\n          pred_ls += list(pred)\n    df = pd.DataFrame({'filename':path_ls,'category':pred_ls})\n\n    return df","dbc20ae6":"test_dataset = ShopeeTestDataset(\".\/test\/test\", data_transform)\nloaderte=torch.utils.data.DataLoader(test_dataset,batch_size=256,shuffle=False)\ndf = inference(model,loaderte,device)                               # predictions are stored in this dataframe\ndf.to_csv(\".\/gdrive\/My Drive\/test_prediction.csv\",index=False)      # export dataframe as csv. It will export to your Google drive home folder","271e5331":"df.head()","f82dfdea":"Create Dataset class to load testing images","44901d4b":"**Create dataset class to pass images into model**. This class stores a list of the path to each training image file. It only loads an item when its called(from the \\_getitem_ function). This is done like this because it will require a lot of memory to load all 100k images at once. This way, an image is only loaded when it is needed.","e9bacfb9":"Quick peek at the dataframe","61e65c17":"This section will unzip the shopee code league file to this instance. This should work if you put the zip file directly in your Google Drive folder. Otherwise, adjust your path correspondingly. This will take roughly 2-3mins\n\n","59db6823":"This function tests the performance of your current model on the validation images. Recall we saved the last 50 images of each category as validation images. ","499e91e5":"This function trains the model for 1 epoch (meaning it iterates through the entire training dataset once). ","b38c3ca9":"**Displaying example images.** Prints a sample image for each category.","fc88b84e":"Let's start predicting on the test images","db409563":"This command tells you what GPU you have been assigned. If you get P100, you should be very happy, it is an excellent card. Otherwise, K80 or P4 are not as powerful but its free, and its sufficient to help you train.","4f62680b":"This function collates the predictions for test images and returns a pandas dataframe in the format specified by Shopee","b213a35d":"Libraries to import. I am most familiar with PyTorch, hence the library I use is PyTorch.","47714d3e":"This function is simply to organize the whole training procedure. It iterates through all the epochs, and evaluates the model after each epoch, so you can see the training progress.","71eb8dcd":"Let's start training","22d410f5":"Connect Google Drive to this instance. You can access your google drive files under \/content\/gdrive\/"}}