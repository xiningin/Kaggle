{"cell_type":{"4a59a0e8":"code","dabbbe4d":"code","947f1022":"code","368916bb":"code","c16dc737":"code","073f37a9":"code","589075e1":"code","5254b813":"code","e91c6a3a":"code","7237388a":"code","7ce4c187":"code","7665d707":"code","f7d70d14":"code","6d29ca4a":"code","7392b7d7":"code","e2738f69":"code","33817f93":"code","35d7a709":"code","4b1f86e3":"code","3823adef":"code","2a49000c":"code","735f56e8":"code","da7c9f34":"code","42fb3eed":"code","a41cc92e":"code","90eb1d63":"code","68ca0e1c":"code","a8de29be":"code","c577e31d":"code","ca3b0c45":"code","1a93e062":"code","90a02559":"code","cabe2ca9":"code","6a7c8969":"code","07dac74e":"code","6a38376f":"code","3251d8fb":"code","cd999d06":"code","43e17217":"code","591f8592":"code","523fcda4":"code","d5a10f12":"code","b03f5751":"code","2fb90bfe":"code","36269243":"code","83efbeb8":"code","c873fee1":"code","65a0f4f5":"code","fd0cff75":"code","e3983fb8":"code","9872929c":"code","7465913b":"code","af9982f1":"code","ca662cb6":"code","eb897cf3":"code","8f0e0e79":"code","7c0106fe":"code","3acc4467":"code","8752ae3d":"code","13140515":"code","d546951a":"code","8fd47db6":"code","a13ecfa5":"code","04ac4d99":"code","53ccddc1":"code","8809f40b":"code","a4c0d4f0":"code","5362fad8":"markdown","22475874":"markdown"},"source":{"4a59a0e8":"import numpy as np\nimport pandas as pd","dabbbe4d":"train_data= pd.read_csv('..\/input\/titanic\/train.csv' )\ntrain_data.head()","947f1022":"train_data.info()","368916bb":"## Drop columns - Passenger Id, Name ,Ticket.\ntrain_data.drop(['PassengerId'], axis=1, inplace=True)\ntrain_data.drop(['Name'], axis=1, inplace=True)\ntrain_data.drop(['Ticket'], axis=1, inplace=True)","c16dc737":"train_data.head()","073f37a9":"## Train Data has missing values in columns - Age,Cabin,Embarked\n\n# Handle missing data in Embarked Column\nMode = train_data['Embarked'].mode().values[0]\ntrain_data['Embarked'].fillna(Mode ,inplace=True)\ntrain_data.info()           ","589075e1":"train_data.Embarked.value_counts()","5254b813":"## 0= not allocated cabin , 1= allocated cabin\ntrain_data['Allocated_Cabin'] =np.where(train_data['Cabin'].isna(),0,1)\ntrain_data.drop(columns=['Cabin'], axis=1, inplace = True)\ntrain_data.head()","e91c6a3a":"## Parch and SibSp Columns can be merged to form a new Feature\n\ntrain_data['Family_Size'] = train_data['SibSp'] + train_data['Parch']\ntrain_data.head()","7237388a":"## After Calculating Family Size, now Parch and Sibsp can be dropped safely\ntrain_data.drop(['SibSp'], axis=1,inplace=True)\ntrain_data.drop(['Parch'], axis=1, inplace=True)\ntrain_data.head()","7ce4c187":"features= train_data.iloc[:,1:8].values\nlabel =train_data.iloc[:,[0]].values\n#label","7665d707":"print(features.shape)\nfeatures","f7d70d14":"from sklearn.preprocessing import Imputer","6d29ca4a":"##Using Imputer to fill missing values in Age column. \nAgeimputer = Imputer(missing_values='NaN', strategy='mean', axis=0)","7392b7d7":"features[:,[2]] = Ageimputer.fit_transform(features[:,[2]])","e2738f69":"pd.DataFrame(features).head()","33817f93":"from sklearn.preprocessing import LabelEncoder\n\nencode = LabelEncoder()\nfeatures[:,4] = encode.fit_transform(features[:,4])\nfeatures[:,1] = encode.fit_transform(features[:,1])","35d7a709":"pd.DataFrame(features).head()","4b1f86e3":"features.shape","3823adef":"encode.classes_","2a49000c":"## One hot encoding for Embarked Column values\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nhotencode= OneHotEncoder(categorical_features=[4])\nfeatures= hotencode.fit_transform(features).toarray()","735f56e8":"hotencode.get_feature_names()","da7c9f34":"pd.DataFrame(features).head()","42fb3eed":"features.shape","a41cc92e":"##One hot encoding for Sex Column Values\n\nhotencode2= OneHotEncoder(categorical_features=[1])\nfeatures= hotencode2.fit_transform(features).toarray()","90eb1d63":"hotencode2.get_feature_names()","68ca0e1c":"features.shape","a8de29be":"final_data = pd.DataFrame(features)\nfinal_data.head()","c577e31d":"train_data.corr()","ca3b0c45":"pd.DataFrame(features).corr()","1a93e062":"## Vizualize correlation Matrix\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","90a02559":"plt.figure(figsize=(10,10))   \nsns.heatmap(train_data.corr(),annot=True,fmt=\".0%\")\nplt.show()","cabe2ca9":"plt.figure(figsize=(10,10))         ##HeatMap of Features Data\nsns.heatmap(pd.DataFrame(features).corr(),annot=True,fmt=\".0%\")\nplt.show()","6a7c8969":"plot= sns.kdeplot(features[:,6][(label[:,0] == 0)], color=\"Red\", shade = True)\nplot =sns.kdeplot(features[:,6][(label[:,0] == 1)],color =\"Blue\" ,shade=True)\n\nplot.set_xlabel(\"Age\")\nplot.set_ylabel(\"Frequency\")\nplot = plot.legend([\"Not Survived\",\"Survived\"])","07dac74e":"labelValue = train_data.Survived.value_counts()    ## No.of values Label- 0 & 1 does not match that means it is unbalanced dataset\nlabelValue","6a38376f":"sns.countplot(train_data.Survived ,label='count')","3251d8fb":"## Validation DataSet\nval_data= pd.read_csv(\"..\/input\/titanic\/test.csv\")\nPassengerId = val_data['PassengerId']\nval_data.head()\n#PassengerId","cd999d06":"val_data.info()","43e17217":"## Validation Data has missing values in columns - Age,Fare,Cabin\n\nval_data.describe()","591f8592":"## Handle Missing Data - Age,Fare,Cabin\n\nval_data['Age'].fillna(int(val_data.Age.mean()) , inplace = True)\nval_data.info()","523fcda4":"val_data['Fare'].fillna(int(val_data.Fare.median()) ,inplace=True)\nval_data.info()","d5a10f12":"## 0= not allocated cabin , 1= allocated cabin\nval_data['Allocated_Cabin'] =np.where(val_data['Cabin'].isna(),0,1)\nval_data.drop(columns=['Cabin'], axis=1, inplace = True)\nval_data.head()","b03f5751":"val_data['Family_Size'] = val_data['SibSp']+val_data['Parch']\nval_data.head()","2fb90bfe":"val_data.drop(['PassengerId','Name','Ticket','SibSp','Parch'], axis=1, inplace=True)\nval_data.head()","36269243":"Val_Features= val_data.iloc[:,:].values\nVal_Features","83efbeb8":"from sklearn.preprocessing import LabelEncoder\n\nencodeVal = LabelEncoder()\nVal_Features[:,4] = encodeVal.fit_transform(Val_Features[:,4])\nVal_Features[:,1] = encodeVal.fit_transform(Val_Features[:,1])","c873fee1":"Val_Features.shape","65a0f4f5":"encodeVal.classes_","fd0cff75":"from sklearn.preprocessing import OneHotEncoder\n\nVal_hotencode= OneHotEncoder(categorical_features=[4])\nVal_Features= Val_hotencode.fit_transform(Val_Features).toarray()","e3983fb8":"Val_Features.shape","9872929c":"Val_hotencode= OneHotEncoder(categorical_features=[1])\nVal_Features= Val_hotencode.fit_transform(Val_Features).toarray()","7465913b":"Val_Features.shape","af9982f1":"Val_Features","ca662cb6":"## Feature Scaling Of Test DataSet\nfrom sklearn.preprocessing import StandardScaler\n\nsc= StandardScaler()\nScale_Val_Features = sc.fit_transform(Val_Features)","eb897cf3":"Scale_Val_Features","8f0e0e79":"# Train Test Split\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(features,label,test_size=0.2,\n                                              random_state=10)","7c0106fe":"## Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nsc= StandardScaler()\nX_train= sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","3acc4467":"def models(X_train,y_train):\n    ## Logistic Regression Model\n        from sklearn.linear_model import LogisticRegression\n        logis= LogisticRegression(C=50)\n        logis.fit(X_train, y_train)\n        train_score1 =logis.score(X_train,y_train)\n        test_score1 =logis.score(X_test,y_test)\n\n        ## Random Forest Model\n        from sklearn.ensemble import RandomForestClassifier\n        rf = RandomForestClassifier(n_estimators=10,criterion=\"entropy\",random_state=5)\n        rf.fit(X_train,y_train)\n        train_score2 =rf.score(X_train,y_train)\n        test_score2 =rf.score(X_test,y_test)\n\n        ## KNN\n        from sklearn.neighbors import KNeighborsClassifier\n        knc = KNeighborsClassifier(n_neighbors=11)\n        knc.fit(X_train,y_train)\n        train_score3 =knc.score(X_train,y_train)\n        test_score3 =knc.score(X_test,y_test)\n\n        ## SVC\n        from sklearn.svm import SVC\n        sv = SVC()\n        sv.fit(X_train, y_train)\n        train_score4 =sv.score(X_train,y_train)\n        test_score4 =sv.score(X_test,y_test)\n\n        ## XgBoost\n        from xgboost import XGBClassifier\n        boost= XGBClassifier(learning_rate=0.01)\n        boost.fit(X_train,y_train)\n        train_score5 =boost.score(X_train,y_train)\n        test_score5 =boost.score(X_test,y_test)\n\n        ## Print Accuracy\n        print(\"Logistic train score: \", train_score1, \"Test score : \",test_score1)\n        print(\"Random Forest train score: \", train_score2, \"Test score : \",test_score2)\n        print(\"KNN train score: \", train_score3, \"Test score : \",test_score3)\n        print(\"SVC train score: \", train_score4, \"Test score : \",test_score4)\n        print(\"Xgboost train score: \", train_score5, \"Test score : \",test_score5)\n        \n        return logis,rf,knc,sv,boost","8752ae3d":"model=models(X_train,y_train)","13140515":"model","d546951a":"from sklearn.metrics import confusion_matrix","8fd47db6":"for i in range(len(model)):\n    print(\"Model \", i)\n    cm= confusion_matrix(y_test,model[i].predict(X_test))\n    TP=cm[0][0]\n    TN=cm[1][1]\n    FN=cm[1][0]\n    FP=cm[0][1]\n    print(cm)","a13ecfa5":"from sklearn.metrics import classification_report","04ac4d99":"for i in range(len(model)):\n    print(\"Model \", i)\n    Report = classification_report(y_test,model[i].predict(X_test))\n    print(Report)","53ccddc1":"pred=model[3].predict(Scale_Val_Features)  ##SVC so far best model\npred","8809f40b":"Final_Result = pd.DataFrame({ 'PassengerId': PassengerId,\n                               'Survived': pred})","a4c0d4f0":"Final_Result.to_csv(r'ResultSubmission.csv',index=False)","5362fad8":"# Test Data","22475874":"# Model"}}