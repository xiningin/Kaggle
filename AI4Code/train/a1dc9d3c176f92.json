{"cell_type":{"85e33a05":"code","aea3b27c":"code","c06e9027":"code","0b03de52":"code","7cc5fabc":"code","db9878f7":"code","409b043c":"code","71646b6e":"code","8360c268":"code","8d055e29":"code","dde2947c":"code","3025be98":"code","d31f487a":"code","40149ee1":"markdown","28870fba":"markdown","f8c4c545":"markdown","d141af0e":"markdown","27b0fe0f":"markdown","74618c99":"markdown","66ddac09":"markdown","3747a908":"markdown","6ac5aa68":"markdown","7c2b689f":"markdown","fd7c06da":"markdown","eb80d7ed":"markdown","e7fd7ddf":"markdown","6f3224fe":"markdown"},"source":{"85e33a05":"\n\nimport warnings\nwarnings.filterwarnings('ignore')","aea3b27c":"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport scipy.stats as st\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.mlab as mlab\n\n#Importing the dataset and dropping the unwanted columns \nheart_df=pd.read_csv(\"..\/input\/framingham.csv\")\nheart_df.drop(['education'],axis=1,inplace=True)\nheart_df.head()\n","c06e9027":"#Renaming the column name\nheart_df.rename(columns={'male':'Sex_male'},inplace=True)\n\nheart_df.head()","0b03de52":"# Checking the missing values \nheart_df.isnull().sum()","7cc5fabc":"#Counting the missing values and dropping them\ncount=0\nfor i in heart_df.isnull().sum(axis=1):\n    if i>0:\n        count=count+1\nprint('Total number of rows with missing values is ', count)\nprint('since it is only',round((count\/len(heart_df.index))*100), 'percent of the entire dataset the rows with missing values are excluded.')\n\nheart_df.dropna(axis=0,inplace=True)\n\nheart_df.describe()","db9878f7":"heart_df.isnull().sum()","409b043c":"#Adding a constant\nfrom statsmodels.tools import add_constant as add_constant\nheart_df_constant = add_constant(heart_df)\nheart_df_constant.head()\n","71646b6e":"\n\nst.chisqprob = lambda chisq, df: st.chi2.sf(chisq, df)\ncols=heart_df_constant.columns[:-1]\nmodel=sm.Logit(heart_df.TenYearCHD,heart_df_constant[cols])\nresult=model.fit()\nresult.summary()\n","8360c268":"\ndef back_feature_elem (data_frame,dep_var,col_list):\n    while len(col_list)>0 :\n        model=sm.Logit(dep_var,data_frame[col_list])\n        result=model.fit(disp=0)\n        largest_pvalue=round(result.pvalues,3).nlargest(1)\n        if largest_pvalue[0]<(0.05):\n            return result\n            break\n        else:\n            col_list=col_list.drop(largest_pvalue.index)\n\nresult=back_feature_elem(heart_df_constant,heart_df.TenYearCHD,cols)\n","8d055e29":"#Interpreting the results: Odds Ratio, Confidence Intervals and Pvalues\n\nparams = np.exp(result.params)\nconf = np.exp(result.conf_int())\nconf['OR'] = params\npvalue=round(result.pvalues,3)\nconf['pvalue']=pvalue\nconf.columns = ['CI 95%(2.5%)', 'CI 95%(97.5%)', 'Odds Ratio','pvalue']\nprint ((conf))\n","dde2947c":"\nimport sklearn\nnew_features=heart_df[['age','Sex_male','cigsPerDay','totChol','sysBP','glucose','TenYearCHD']]\nx=new_features.iloc[:,:-1]\ny=new_features.iloc[:,-1]\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred=logreg.predict(x_test)\n","3025be98":"\nfrom sklearn import metrics\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nprint(confusion_matrix)","d31f487a":"\nsklearn.metrics.accuracy_score(y_test,y_pred)\n","40149ee1":" **Introduction**\n \nWorld Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant\/risk factors of heart disease as well as predict the overall risk using logistic regression.","28870fba":"Logistic regression equation\nP=e(\u03b20+\u03b21X1\/1+e\u03b20+\u03b21X1)\n \nWhen all features plugged in:\n\nlogit(p)=log(p\/(1\u2212p))=\u03b20+\u03b21\u2217Sexmale+\u03b22\u2217age+\u03b23\u2217cigsPerDay+\u03b24\u2217totChol+\u03b25\u2217sysBP+\u03b26\u2217glucose\n","f8c4c545":"**#Splitting data to train and test split**","d141af0e":"** # Supress Warnings**","27b0fe0f":"**  LOGISTIC REGRESSION TO  PREDICT HEART DISEASE.**","74618c99":"Data Preparation\nSource:\nThe dataset is publically available on the Kaggle website, and it is from an ongoing ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).The dataset provides the patients\u2019 information. It includes over 4,000 records and 15 attributes","66ddac09":"**again checking null values**","3747a908":"Missing values","6ac5aa68":"**#Confusion matrix**","7c2b689f":"**Logistic Regression**\n\nLogistic regression is a type of regression analysis in statistics used for prediction of outcome of a categorical dependent variable from a set of predictor or independent variables. In logistic regression the dependent variable is always binary. Logistic regression is mainly used to for prediction and also calculating the probability of success.\n\n**Chi-square Test**\n\n\u25cf A Chi-square Test (also written \ud835\udf122) is used to determine the probability of an observed frequency of events given an expected frequency\n\n**Chi-square Test**\n\n\u25cf The chi-square formula considers the sum of square distances between observed values O and expected values E, divided by each expected value:\n\ud835\udf122 = ((\ud835\udc42 \u2212 \ud835\udc38)e2)\/E","fd7c06da":"**#Feature Selection: Backward elemination (P-value approach)\n#Takes in the dataframe, the dependent variable and a list of column names, \n#runs the regression repeatedly eleminating feature with the highest\n#P-value above alpha one at a time and returns the regression summary \n#with all p-values below alpha\n**","eb80d7ed":"Exploratory Analysis","e7fd7ddf":"**#Model accuracy**","6f3224fe":"**import libraries**"}}