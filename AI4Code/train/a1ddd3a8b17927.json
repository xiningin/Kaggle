{"cell_type":{"3c2517f0":"code","f3247e4f":"code","056cc3f9":"code","a181f6ed":"code","2d2ae891":"code","dee3ac41":"code","f2bef69d":"code","9b6a0e95":"code","149fed15":"code","64b29657":"code","ea42698f":"code","2f6cc8fd":"code","b3cc3176":"code","cc750538":"code","8ff63fa8":"code","ad20162f":"code","1de29105":"code","0642a855":"code","3521f742":"code","273b7c57":"code","84840adc":"code","43df1d0b":"code","d9994f12":"code","0263875d":"code","1b4dbe05":"code","76a7dae5":"code","4375dea5":"code","f5cafa45":"code","ec053500":"code","984af3f8":"code","d16a42dc":"code","6c5f7ac8":"code","642defdf":"code","9288198c":"code","38338ba5":"code","5cb8bbe6":"code","80ac5641":"code","d1776b5b":"code","c61842f6":"code","5394076e":"code","c25bd965":"markdown","26aa44b3":"markdown","23927ac8":"markdown","20627143":"markdown","5fc507a0":"markdown","34dcab00":"markdown","fb6119f7":"markdown","9d1cfb9e":"markdown","ffebaa33":"markdown","d3871e17":"markdown","ac1fe46f":"markdown","59cba1fc":"markdown","e7a2d8d9":"markdown","3ab21fad":"markdown","78e8b4d7":"markdown","925d3e7d":"markdown","3e6b1505":"markdown","0214bc6e":"markdown","c863d118":"markdown","24a63041":"markdown","22c1ab6f":"markdown","33c3318b":"markdown","031daabb":"markdown","47facb6f":"markdown","f2cb8993":"markdown","d3f74b0e":"markdown","e6f98cf7":"markdown","5de19041":"markdown","5eec4b5e":"markdown","eb10158a":"markdown"},"source":{"3c2517f0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","f3247e4f":"df = pd.read_csv('..\/input\/social-ads\/social-network-ads.csv')\ndf.head(10)","056cc3f9":"X = df.iloc[:, :-1].values\nX","a181f6ed":"y = df.iloc[:, -1].values\ny","2d2ae891":"# first we need to split the data\nfrom sklearn.model_selection import train_test_split","dee3ac41":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","f2bef69d":"# now we do scaling to the X values using StandardScaler model\nfrom sklearn.preprocessing import StandardScaler","9b6a0e95":"sc = StandardScaler()","149fed15":"X_train = sc.fit_transform(X_train)\nX_train","64b29657":"X_test = sc.transform(X_test)\nX_test","ea42698f":"from sklearn.svm import SVC","2f6cc8fd":"classifier = SVC(kernel='linear', random_state= 0)","b3cc3176":"classifier.fit(X_train, y_train)","cc750538":"# check if the everything going well :)\nprint(classifier.predict(sc.transform([[40, 75000]])))","8ff63fa8":"y_pred = classifier.predict(X_test)\ny_pred","ad20162f":"y_test","1de29105":"# if needed to check every prediction versus the original input \nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","0642a855":"from sklearn.metrics import accuracy_score, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","3521f742":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_train), y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('SVM (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","273b7c57":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_test), y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('SVM (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","84840adc":"from sklearn.svm import SVC","43df1d0b":"classifier = SVC(kernel = 'rbf', random_state = 0)","d9994f12":"classifier.fit(X_train, y_train)","0263875d":"print(classifier.predict(sc.transform([[40, 75000]])))","1b4dbe05":"y_pred = classifier.predict(X_test)\ny_pred","76a7dae5":"y_test","4375dea5":"print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","f5cafa45":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred) ","ec053500":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_train), y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Kernel SVM (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","984af3f8":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_test), y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Kernel SVM (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","d16a42dc":"# model training\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\nclassifier.fit(X_train, y_train)","6c5f7ac8":"# model prediction\nprint(classifier.predict(sc.transform([[47, 80000]])))","642defdf":"y_pred1 = classifier.predict(X_test)\ny_pred1","9288198c":"y_test","38338ba5":"# model evaluation\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred1) * 100","5cb8bbe6":"# model training\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators= 10, criterion= 'entropy', random_state=0)\nclassifier.fit(X_train, y_train)","80ac5641":"# model prediction\nprint(classifier.predict(sc.transform([[45,97000]])))","d1776b5b":"y_pred2 = classifier.predict(X_test)\ny_pred2","c61842f6":"y_test","5394076e":"# model evaluation\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred2)\nprint(cm)\naccuracy_score(y_test, y_pred2) * 100","c25bd965":"### Data Splitting & Preprocessing","26aa44b3":"### Model Training & Predicting","23927ac8":"![](https:\/\/www.threegirlsmedia.com\/wp-content\/uploads\/2020\/11\/3G.SocialMediaAds.1.21.2019.png)","20627143":"#### Now that the problem is solved we can build the model","5fc507a0":"#### Is better than the linear kernel so i will accept this accourcy score","34dcab00":"#### There is a problem with the X values needing to be scaled so I need to do some data preprocessing to fix the problem","fb6119f7":"## Please leave an upvote and comment to helps me continue my data science journy and improves my work. Thanks","9d1cfb9e":"## Now let's try using Dicision Trees & Random forests model","ffebaa33":"##### Visualising the Test set results","d3871e17":"## Using RBF Kernel","ac1fe46f":"## Using Linear Kernel","59cba1fc":"##### Visualising the Training set results","e7a2d8d9":"### Model Evaluation","3ab21fad":"### Model Training & Predicting","78e8b4d7":"### Importing Libraries","925d3e7d":"##### Visualising the Training set results","3e6b1505":"Good score!! now let's try Random Forrests algorithm","0214bc6e":"##### Visualising the Test set results","c863d118":"The score are 90% are very good but i need more than that in this time so i will try another kernel ","24a63041":"#### Notice: In my previous notebook, I used KNN algorithms to predict who would make a purchase based on salary compared to age, now I'm going to use SVM algorithm to try to get higher accuracy and separate the points in the scatter","22c1ab6f":"#### The best results is the KBF Kernel model with 93% accuracy","33c3318b":"#### 2- Using Random Forrests classifier","031daabb":"# Social Media ADs analysis & prediction ","47facb6f":"### Visualising Results","f2cb8993":"### Importing Dataset & Extracting Features","d3f74b0e":"## The purpose of the case study:\n\n### The main purpose of the study is to predict whether customers will buy again based on age and income","e6f98cf7":"### Visualizing Results","5de19041":"### Model Evaluation","5eec4b5e":"### 1- Using Decision Trees classifier","eb10158a":"#### Now let's evaluate the model"}}