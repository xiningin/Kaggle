{"cell_type":{"abb08459":"code","7decbf83":"code","2ba7c152":"code","68e57711":"code","03909cbe":"code","976255ac":"code","e0beff80":"code","e2291585":"code","d84414af":"code","656b825a":"code","9f065d57":"code","bfc85d2d":"code","3c0d74c8":"code","53453980":"code","a1fe385f":"code","3b35923d":"code","a07ff923":"code","f20a4f72":"code","30968811":"code","679a791b":"code","ce419809":"code","e9d88467":"code","55485474":"code","d794f510":"code","5c57609f":"code","54d3ef97":"code","b60e5b5a":"code","74380a7f":"code","8c2891cf":"code","f09ab427":"code","7440146d":"code","b867aeca":"code","74bfa93c":"code","6211778f":"code","888b7e80":"code","0e842bb7":"code","bd429e44":"code","ed6fcff6":"code","a89a7477":"code","2aefa56d":"code","82dbb669":"code","2cc17aa8":"code","1fc8ea1d":"code","afbc1656":"code","00907ec1":"code","82fb37a7":"code","4ed2c11e":"code","d6e56671":"code","675940e1":"code","c124597a":"code","ea5d6984":"code","2bfdf9a3":"code","aee7be07":"code","40a65666":"code","0bc0ba41":"code","b8bd2ade":"code","5b6a45ad":"code","4a2e3dab":"code","55b7b994":"code","be7f05a6":"code","1424fb2d":"code","e12504b5":"code","120ba86f":"code","13164912":"code","fe04f0b7":"code","fbb44598":"code","3f4bfe0d":"code","4e13bc13":"code","a7483345":"code","11a77d1c":"code","d2a233e9":"code","22780c4c":"code","ac4c9eaf":"code","fb9bb4e6":"code","f5eb17c5":"code","48e67177":"code","7f3a3ee5":"code","4303dd5f":"code","e53d5c80":"code","55ee2b6a":"code","9aae2e70":"code","2e775ad8":"code","bf478564":"code","6f995db2":"code","c7a05d81":"code","657b32bf":"code","8f1d781a":"code","10a4972f":"code","2fd341e5":"code","d1a3a8c7":"code","a4c4f5da":"code","9eaef6cd":"code","7de911dd":"code","78966c38":"code","6419d795":"code","1d13a71a":"code","91cf62d2":"code","7fa38e52":"code","6c4606d4":"code","90719908":"markdown","6942e682":"markdown","0967a6ba":"markdown","bf41159b":"markdown","4c863db2":"markdown","19f256ce":"markdown","37896556":"markdown","7b2acbf0":"markdown","565a6aae":"markdown","cfe0644e":"markdown","42178092":"markdown","dfa79a6f":"markdown","46a9d71a":"markdown","c9260a1d":"markdown","7c52b378":"markdown","eba6bddb":"markdown","363ce8ba":"markdown","56088ac3":"markdown","4bf67ccd":"markdown","c04356cc":"markdown","08f2f491":"markdown","fa3abadb":"markdown","2db9b482":"markdown","72ad7590":"markdown"},"source":{"abb08459":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7decbf83":"!pip install pyspark","2ba7c152":"import pyspark\nimport warnings\nimport pandas as pd\nimport seaborn as sns\nfrom pyspark.ml.classification import GBTClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, StandardScaler\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.sql import SparkSession\n\nimport pyspark\nfrom pyspark import SparkContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.conf import SparkConf\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","68e57711":"spark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"pyspark_giris\") \\\n    .getOrCreate()\n    \nsc = spark.sparkContext","03909cbe":"sc","976255ac":"spark_df = spark.read.csv(\"..\/input\/churn\/churn.csv\", header = True, inferSchema = True)","e0beff80":"spark_df.head()","e2291585":"type(spark_df)","d84414af":"dff = pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ntype(dff)","656b825a":"dff.head()","9f065d57":"spark_df.head()","bfc85d2d":"dff.dtypes","3c0d74c8":"spark_df.dtypes","53453980":"dff.ndim","a1fe385f":"# Won't work, every command won't work with spark like dataframe\n\n# spark_df.ndim\n# spark_df.shape","3b35923d":" # Spark cheatshit needs to be used for all commands","a07ff923":"spark_df.count()","f20a4f72":"# Number of observations and variables\n\nspark_df.count(), len(spark_df.columns)","30968811":"print(\"Shape: \", (spark_df.count(), len(spark_df.columns)))","679a791b":"# types of variables\n\nspark_df.printSchema()","ce419809":"spark_df.dtypes","e9d88467":"spark_df.Age","55485474":"spark_df.select('age')","d794f510":"spark_df.select('age').show(5)","5c57609f":"# head\n\nspark_df.head()","54d3ef97":"# take\n\nspark_df.take(5)","b60e5b5a":"spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])","74380a7f":"dff.describe().T","8c2891cf":"spark_df.describe().show()","f09ab427":"spark_df.describe(['age', 'churn']).show()","7440146d":"# Categorical variable class statistics\n\n# value_counts()\n\ndff['cut'].value_counts()","b867aeca":"spark_df.groupby(\"churn\").count().show()","74bfa93c":"# unique\n\ndff['cut'].unique()","6211778f":"spark_df.select(\"churn\").distinct().show()","888b7e80":"dff.head()","0e842bb7":"len(dff['cut'])","bd429e44":"spark_df.filter(spark_df.age > 55).count()","ed6fcff6":"spark_df.select('age').count()","a89a7477":"spark_df.show(5)","2aefa56d":"num_cols = [i for i in dff.columns if dff[i].dtypes != 'O']\nnum_cols","82dbb669":"spark_df.columns","2cc17aa8":"spark_df.dtypes","1fc8ea1d":"num_cols = [i for i in spark_df.columns if spark_df.select(i).dtypes != 'string']\nnum_cols","afbc1656":"# OR\n\nnum_cols = [col[0] for col in spark_df.dtypes if col[1] != 'string']\nnum_cols","00907ec1":"cat_cols = [i for i in spark_df.columns if spark_df.select(i).dtypes == 'string']\ncat_cols","82fb37a7":"# value_counts() doesn't work with spark\n# Converting to pandas\n\na = spark_df.select('age').toPandas()\na.head()","4ed2c11e":"a.value_counts().head()","d6e56671":"# len() doesn't work with spark\n# Converting to pandas\n\nb = spark_df.select('churn').toPandas()\nb.head()","675940e1":"len(b)","c124597a":"dff[dff['carat'] > 4]","ea5d6984":"spark_df.filter(spark_df.age > 55).show()","2bfdf9a3":"for col in num_cols:\n    spark_df.select(col).distinct().show()","aee7be07":"spark_df.groupby('churn').agg({'age':'mean'}).show()","40a65666":"dff.isnull().sum()","0bc0ba41":"from pyspark.sql.functions import when, count, col","b8bd2ade":"spark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns]).show()","5b6a45ad":"c = spark_df.toPandas()\nc.head()","4a2e3dab":"c.isnull().sum()","55b7b994":"spark_df.dropna().show(5)","be7f05a6":"spark_df.fillna(50).show(5)","1424fb2d":"spark_df.show(5)","e12504b5":"# If you want to make changes to the variables, use 'withColumn'\n\nspark_df = spark_df.withColumn('age_total_purchase', spark_df.age \/ spark_df.total_purchase)\nspark_df.show(5)","120ba86f":"from pyspark.ml.feature import Bucketizer","13164912":"# In pandas world, this can do with qcut, etc.\n# numeric variables to categorical variables\n\nbucketizer = Bucketizer(splits = [0, 30, 45, 65], inputCol = 'age', outputCol = 'age_cat')\nspark_df = bucketizer.setHandleInvalid('keep').transform(spark_df)\nspark_df.show(15)","fe04f0b7":"spark_df = spark_df.withColumn('age_cat', spark_df.age_cat + 1)\nspark_df.show(5)","fbb44598":"spark_df = spark_df.withColumn('segment', when(spark_df['years'] < 5, \"segment_b\").otherwise(\"segment_a\"))\nspark_df.show(5)","3f4bfe0d":"spark_df.withColumn('age_cat_2',\n                    when(spark_df['age'] < 36, \"young\").\n                    when((35 < spark_df['age']) & (spark_df['age'] < 46), \"mature\").\n                    otherwise(\"senior\")).show(8)\n","4e13bc13":"spark_df = spark_df.withColumn(\"age_cat\", spark_df[\"age_cat\"].cast(\"integer\"))","a7483345":"spark_df.show(5)","11a77d1c":"indexer = StringIndexer(inputCol=\"segment\", outputCol=\"segment_label\")\ntemp_sdf = indexer.fit(spark_df).transform(spark_df)\nspark_df = temp_sdf.withColumn(\"segment_label\", temp_sdf[\"segment_label\"].cast(\"integer\"))","d2a233e9":"spark_df = spark_df.drop('segment')\nspark_df.show(15)","22780c4c":"encoder = OneHotEncoder(inputCols = ['age_cat'], outputCols = ['age_cat_ohe'])\nspark_df = encoder.fit(spark_df).transform(spark_df)\nspark_df.show(5)","ac4c9eaf":"stringIndexer = StringIndexer(inputCol = 'churn', outputCol = 'label')\ntemp_sdf = stringIndexer.fit(spark_df).transform(spark_df)\nspark_df = temp_sdf.withColumn(\"label\", temp_sdf[\"label\"].cast(\"integer\"))","fb9bb4e6":"cols = ['age', 'total_purchase', 'account_manager', 'years',\n        'num_sites', 'age_total_purchase', 'segment_label', 'age_cat_ohe']","f5eb17c5":"va = VectorAssembler(inputCols=cols, outputCol=\"features\")final_df = va_df.select(\"features\", \"label\")\n","48e67177":"va_df = va.transform(spark_df)\nva_df.show()","7f3a3ee5":"final_df = va_df.select(\"features\", \"label\")\nfinal_df.show(10)","4303dd5f":"train_df, test_df = final_df.randomSplit([0.7, 0.3], seed=17)\ntrain_df.show(10)","e53d5c80":"test_df.show(10)","55ee2b6a":"print(\"Training Dataset Count: \" + str(train_df.count())), print(\"Test Dataset Count: \" + str(test_df.count()))","9aae2e70":"log_model = LogisticRegression(featuresCol='features', labelCol='label').fit(train_df)\ny_pred = log_model.transform(test_df)\ny_pred.show()","2e775ad8":"y_pred.select('label', 'prediction').show()","bf478564":"evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')","6f995db2":"evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")","c7a05d81":"roc_auc = evaluator.evaluate(y_pred)\nprecision = evaluatorMulti.evaluate(y_pred, {evaluatorMulti.metricName: \"precisionByLabel\"})\nrecall = evaluatorMulti.evaluate(y_pred, {evaluatorMulti.metricName: \"recallByLabel\"})\nf1 = evaluatorMulti.evaluate(y_pred, {evaluatorMulti.metricName: \"f1\"})","657b32bf":"print(\"accuracy: %f, precision: %f, recall: %f, f1: %f, roc_auc: %f\" % (acc, precision, recall, f1, roc_auc))","8f1d781a":"gbm = GBTClassifier(maxIter=100, featuresCol=\"features\", labelCol=\"label\")\ngbm_model = gbm.fit(train_df)\ny_pred = gbm_model.transform(test_df)\n\ny_pred.show(5)","10a4972f":"evaluator = BinaryClassificationEvaluator()\n\ngbm_params = (ParamGridBuilder()\n              .addGrid(gbm.maxDepth, [2, 4, 6])\n              .addGrid(gbm.maxBins, [20, 30])\n              .addGrid(gbm.maxIter, [10, 20])\n              .build())\n\ncv = CrossValidator(estimator=gbm,\n                    estimatorParamMaps=gbm_params,\n                    evaluator=evaluator,\n                    numFolds=5)\n\ncv_model = cv.fit(train_df)","2fd341e5":"\ny_pred = cv_model.transform(test_df)\nac = y_pred.select(\"label\", \"prediction\")","d1a3a8c7":"names = pd.Series([\"John\", \"jimmy\", \"Daman\", \"Quasis\", \"Uho\"])\nage = pd.Series([18, 43, 34, 50, 40])\ntotal_purchase = pd.Series([5000, 10000, 6000, 30000, 100000])\naccount_manager = pd.Series([1, 0, 0, 1, 1])\nyears = pd.Series([20, 10, 3, 8, 30])\nnum_sites = pd.Series([2, 8, 8, 6, 50])\nage_total_purchase = age \/ total_purchase\nsegment_label = pd.Series([1, 1, 0, 1, 1])\nage_cat_ohe = pd.Series([1, 1, 0, 2, 1])\n\nnew_customers = pd.DataFrame({\n    'names': names,\n    'age': age,\n    'total_purchase': total_purchase,\n    'account_manager': account_manager,\n    'years': years,\n    'num_sites': num_sites,\n    \"age_total_purchase\": age_total_purchase,\n    \"segment_label\": segment_label,\n    \"age_cat_ohe\": age_cat_ohe})\n","a4c4f5da":"new_sdf = spark.createDataFrame(new_customers)\nnew_customers = va.transform(new_sdf)\nnew_customers.show(3)","9eaef6cd":"results = cv_model.transform(new_customers)\nresults.select(\"names\", \"prediction\").show()","7de911dd":"from pyspark.sql.types import IntegerType, StringType, FloatType\nfrom pyspark.sql.functions import udf","78966c38":"def age_converter(age):\n    if age < 35:\n        return 1\n    elif age < 45:\n        return 2\n    elif age <= 65:\n        return 3","6419d795":"func_udf = udf(age_converter, IntegerType())","1d13a71a":"spark_df = spark_df.withColumn('age_cat2', func_udf(spark_df['age']))\nspark_df.show(5)","91cf62d2":"def segment(years):\n    if years < 5:\n        return \"segment_b\"\n    else:\n        return \"segment_a\"\n\n\nfunc_udf = udf(segment, StringType())\nspark_df = spark_df.withColumn('segment', func_udf(spark_df['years']))\nspark_df.show(5)","7fa38e52":"from pyspark.sql.functions import pandas_udf","6c4606d4":"@pandas_udf(FloatType())\ndef pandas_log(col):\n    import numpy as np\n    return np.log(col)\n\nspark_df.withColumn('age_log', pandas_log(spark_df.age)).show(5)","90719908":"# Bucketization \/ Bining \/ Num to Cat\n","6942e682":"spark_df = spark_df.withColumn(\"age_cat\", spark_df[\"age_cat\"].cast(\"double\"))\nspark_df.show(5)","0967a6ba":"# Exploratory Data Analysis","bf41159b":"# Filtering","4c863db2":"# Data Pre-processing & Feature Engineering","19f256ce":"# Label Encoding\n\n### Spark like to see dependent variables as feature,\n### Independent variables as label","37896556":"# len() = .count()","7b2acbf0":"# Feature Interaction","565a6aae":"# TARGET","cfe0644e":"# One Hot Encoding","42178092":"# Pandas UDFs","dfa79a6f":"# User Defined Functions (UDFs)","46a9d71a":"# cast (double, integer)","c9260a1d":"# Logistic Regression","7c52b378":"# New Prediction\n\n### What about new customers come ?","eba6bddb":"# MODELING","363ce8ba":"# Missing Values","56088ac3":"# Pandas df vs Spark df","4bf67ccd":"# Features","c04356cc":"# groupby","08f2f491":"# GBM","fa3abadb":"# Creating a variable with when, (segment)","2db9b482":"# Numeric and categorical variables","72ad7590":"# toPandas()"}}