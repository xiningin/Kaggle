{"cell_type":{"7a703036":"code","6a47ea7e":"code","b54b482b":"code","907acfea":"code","52f8f246":"code","0e4bb9a9":"code","8b9d49db":"code","9102f0a7":"code","f3a226be":"code","0f6ea065":"code","40552171":"code","c152176d":"code","e1293283":"code","5aac4478":"code","80f88b54":"code","da0c42d5":"code","c61ce2dd":"code","fd00dc8c":"code","a80e33d9":"code","a9159361":"code","9c616126":"code","d696f6c5":"code","4bd3ebee":"code","881d94b6":"markdown"},"source":{"7a703036":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a47ea7e":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras","b54b482b":"data = pd.read_csv(\"..\/input\/plant-pathology-2021-fgvc8\/train.csv\")","907acfea":"data.head()","52f8f246":"base_image_dir_path = \"..\/input\/plant-pathology-2021-fgvc8\/train_images\/\"","0e4bb9a9":"data[\"image_path\"] = [f\"{base_image_dir_path}{image_id}\" for image_id in data[\"image\"].values]","8b9d49db":"data.head()","9102f0a7":"# Counting the unique values for label and double crossing\ndata[\"image\"].loc[0], data[\"image_path\"].loc[0]","f3a226be":"target_dir = {value : key for key,value in enumerate(list(data[\"labels\"].unique()))}","0f6ea065":"target_dir","40552171":"data[\"labels\"] = data[\"labels\"].map(target_dir)","c152176d":"data.head()","e1293283":"(*IMAGE_SIZE,3)","5aac4478":"# image resolution for eff net model\n\"\"\"\nBase model\tresolution\nEfficientNetB0\t224\nEfficientNetB1\t240\nEfficientNetB2\t260\nEfficientNetB3\t300\nEfficientNetB4\t380\nEfficientNetB5\t456\nEfficientNetB6\t528\nEfficientNetB7\t600\n\n\"\"\"\n\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nIMAGE_SIZE = [260, 260]\nEPOCHS = 40\nSEED = 24\nBATCH_SIZE = 32 \n\n\ndef prepare_images(image, label):\n    img = tf.io.read_file(image)\n    # Decode Jpeg files\n    img = tf.image.decode_jpeg(img, channels = 3)\n    img = tf.image.resize(img, size = IMAGE_SIZE, method = \"bicubic\")\n    \n    return img,label\n\ndef augment_image(image,label):\n    img = tf.image.random_flip_up_down(image, seed = SEED)\n    img = tf.image.rot90(img)\n    img = tf.image.flip_left_right(img)\n\n    \n    return img, label\n\n\ndef decode_tensor_to_image(tensor):\n    if len(tensor.shape) >= 4:\n        if tensor.shape[0] == 1:\n            tensor = tf.squeeze(tensor, axis = 0)\n        else:\n            tensor = tensor[0]\n    img = tf.keras.preprocessing.image.array_to_img(tensor)\n    \n    return img\n\ndef process_function(image,label):\n    img = tf.keras.applications.efficientnet.preprocess_input(image)\n    return img, label","80f88b54":"from sklearn.model_selection import train_test_split","da0c42d5":"train_files , valid_files = train_test_split(data, test_size = 0.1)","c61ce2dd":"def get_dataset(files, batch_size):\n    image_dataset = tf.data.Dataset.from_tensor_slices(files[\"image_path\"].values)\n    labels_dataset = tf.data.Dataset.from_tensor_slices(files[\"labels\"].values)\n    final_dataset = tf.data.Dataset.zip((image_dataset, labels_dataset))\n    final_dataset = final_dataset.shuffle(1000)\n    final_dataset = final_dataset.map(prepare_images, num_parallel_calls = AUTO)\n    final_dataset = final_dataset.map(augment_image, num_parallel_calls = AUTO)\n    final_dataset = final_dataset.map(process_function, num_parallel_calls = AUTO)\n    final_dataset = final_dataset.batch(batch_size, drop_remainder = False)\n    final_dataset = final_dataset.prefetch(4)\n    \n    return final_dataset","fd00dc8c":"train_dataset = get_dataset(train_files, batch_size = 32)\nvalid_dataset = get_dataset(valid_files, batch_size = 24)","a80e33d9":"img, label = next(iter(valid_dataset))\nimage = decode_tensor_to_image(img)\nimage","a9159361":"model = keras.applications.EfficientNetB2(include_top = True,weights = None, input_shape = (*IMAGE_SIZE,3) , classes = 12, classifier_activation = \"softmax\")\nmodel.summary()","9c616126":"model.compile(optimizer = \"adam\", loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [\"accuracy\"])","d696f6c5":"model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = \".\/model\",monitor = \"val_accuracy\", mode = \"max\",save_best_only = True)","4bd3ebee":"model.fit(train_dataset, epochs = EPOCHS, callbacks = model_checkpoint, validation_data = valid_dataset)","881d94b6":"# Model Building"}}