{"cell_type":{"dae18e5c":"code","f2df1588":"code","16235bc5":"code","a16d1cfd":"code","58054f01":"code","14962f23":"code","4701fc99":"code","e0d252ee":"code","f3c41770":"code","b1795782":"code","0bc8da66":"code","da055eba":"code","b79bc513":"code","eebddcbf":"code","38becf4d":"code","491e609c":"code","ef8d77db":"code","3f814ad9":"code","03a86924":"markdown","73d8e3f2":"markdown","2aaa7e7d":"markdown","ba0db517":"markdown","71df04fd":"markdown","6a048c8a":"markdown","86e3d0e5":"markdown","eaa53ec3":"markdown","5b91bafd":"markdown"},"source":{"dae18e5c":"# Carga de la librer\u00eda pandas\nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/amazon-fine-food-reviews\/Reviews.csv') # se carga el conjunto de datos en un dataframe\n\ndf.head() # sse muestran los primeros registros","f2df1588":"# Primero vamos a borrar unos atributos para mejorar la vista del dataframe\n\ndf = df.drop(['UserId'], axis=1)\ndf = df.drop(['ProfileName'], axis=1)\ndf = df.drop(['HelpfulnessNumerator'], axis=1)\ndf = df.drop(['HelpfulnessDenominator'], axis=1)\n\ndf","16235bc5":"# Se procede a analizar la variable \u201cScore\u201d para revisar como son mayor\u00eda de las calificaciones\n\n#importamos m\u00e1s librerias\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.express as px\n%matplotlib inline\n\ncolor = sns.color_palette()\npy.init_notebook_mode(connected=True)\n\n# Se grafica la distribuci\u00f3n de las calificaciones de los productos en el conjunto de datos\n\nfig = px.histogram(df, x = \"Score\") # histograma del atributo score\nfig.update_layout(title_text = \"Calificaci\u00f3n del Producto\")\nfig.show()\n","a16d1cfd":"import nltk\nfrom nltk.corpus import stopwords\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS\n\n# Se crea la lista de palabras\n\nstopwords = set(STOPWORDS)\nstopwords.update([\"br\", \"href\"])\ntext = \" \".join(review for review in df.Text)\n\n# Se crea una nube de palabras a partir de los comentarios de campo \"text\" en las rese\u00f1as\n\nwordcloud = WordCloud(stopwords=stopwords).generate(text) \n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()","58054f01":"df = df[df['Score']!=3] # se extraen los registros con score no iguala tres\n\n# se crea un atributo \"sentiment\" y se carga su valor seg\u00fan Score\ndf['sentiment'] = df['Score'].apply(lambda rating: +1 if rating > 3 else -1) \n","14962f23":"positive = df[df['sentiment'] == 1]\nnegative = df[df['sentiment'] == -1]\n\n# Nube de palabras para positivos\n\nstopwords = set(STOPWORDS) \nstopwords.update([\"br\", \"href\",\"good\",\"great\"]) \n\npos = \" \".join(review for review in positive.Summary)\nwordcloud2 = WordCloud(stopwords=stopwords).generate(pos)\n\nplt.imshow(wordcloud2, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","4701fc99":"# Nube de palabras de negativos\n\nneg = \" \".join(str(review) for review in negative.Summary)\nwordcloud3 = WordCloud(stopwords=stopwords).generate(neg)\n\nplt.imshow(wordcloud3, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","e0d252ee":"# Distribuci\u00f3n de las rese\u00f1as a traves del dataset\n\ndf['sentimentt'] = df['sentiment'].replace({-1 : 'negative'})\ndf['sentimentt'] = df['sentimentt'].replace({1 : 'positive'})\n\nfig = px.histogram(df, x=\"sentimentt\")\nfig.update_traces(marker_color=\"indianred\",marker_line_color='rgb(8,48,107)',marker_line_width=1.5)\nfig.update_layout(title_text='Product Sentiment')\nfig.show()","f3c41770":"# Limpieza de datos\n# Se usan los datos de la columna \u201csummary\u201d para determinar las predicciones. \n# Primero se remueven todas las puntaciones\n\ndef remove_punctuation(text):\n    final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\", \"!\",'\"'))\n    return final\n\ndf['Text'] = df['Text'].apply(remove_punctuation)\ndf = df.dropna(subset=['Summary'])\ndf['Summary'] = df['Summary'].apply(remove_punctuation)\n\ndf","b1795782":"# El buevo dataframe (dfNew) solo deber\u00eda contar con dos columnas \u201cSummary (rese\u00f1a)\u201d y \u201csentiment (target)\u201d\n\ndfNew = df[['Summary','sentiment']]\ndfNew.head()","0bc8da66":"# Se divide al azar el dataframe para entrenamiento y para test. \n\nimport numpy as np\n\nindex = df.index\ndf['random_number'] = np.random.randn(len(index))\n\ntrain = df[df['random_number'] <= 0.8]\ntest = df[df['random_number'] > 0.8]\n","da055eba":"# Creaci\u00f3n de una bolsa de palabras\n\n# Se usaremos \u201ccount vectorize\u201d de la librer\u00eda Scikit-learn. Esto transforma el texto del dataframe en una bolsa \n# modelo de palabras, la cual contendr\u00e1 una matriz dispersa de numero enteros. Se contar\u00e1 e imprimir\u00e1 el numero de \n# ocurrencias de cada palabra. Esto se hace debido a que el algoritmo de regresi\u00f3n log\u00edstica no puede entender texto.\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\ntrain_matrix = vectorizer.fit_transform(train['Summary'])\ntest_matrix = vectorizer.transform(test['Summary'])\n","b79bc513":"# Se realiza la regresi\u00f3n l\u00f3gistica\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver='liblinear')","eebddcbf":"# Se dividen las variables independientes del objetivo\n\nX_train = train_matrix\nX_test = test_matrix\ny_train = train['sentiment']\ny_test = test['sentiment']","38becf4d":"# Se ajusta el modelo\n\nlr.fit(X_train,y_train)\n","491e609c":"# Se hacen predicciones\n\npredictions = lr.predict(X_test)","ef8d77db":"# Se prueba el modelo (accuracy, precision, recall)\n\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nnew = np.asarray(y_test)\nconfusion_matrix(predictions,y_test)","3f814ad9":"# Se complementa con el siguiente importe\n\nprint(classification_report(predictions, y_test))","03a86924":"Ya se clasificaron los registtros en positivos y negativos. Se procede a crear una nube de palabras para ambos casos. Para ello nos valdremos de dos dataframes, uno para las rese\u00f1as positivas y otro para las rese\u00f1as negativas.","73d8e3f2":"Nota: Las palabras \u201cgood\u201d y \u201cgreat\u201d inicialmente aparec\u00edan en la nube de sentimientos negativos, a pesar de ser palabras positivas. Esto se debe probablemente que estas palabras se usaron en un contexto negativo como, \u201cnot good\u201d, \u201cnot great\u201d. Por este motivo es que fueron removidas de la nube de palabras.","2aaa7e7d":"Se observa que la mayor\u00eda de las calificaciones de los clientes son positivas. Lo cual sugiere que la mayor\u00eda de las rese\u00f1as ser\u00e1n tambi\u00e9n positivas.\n\nSe procede a crear una **nube de palabras**","ba0db517":"# Experiencia, conjunto de datos \"Amazon Fine Food Reviews\"\n\nOriginal: https:\/\/neuraldojo.org\/proyectos\/analisis-de-sentimiento\/guia-basica-de-analisis-de-sentimiento-en-python\/\n\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\nContents: Reviews.csv \n\nData includes:\n* Reviews from Oct 1999 - Oct 2012\n* 568,454 reviews\n* 256,059 users\n* 74,258 products\n* 260 users with > 50 reviews\n\nhttps:\/\/www.kaggle.com\/snap\/amazon-fine-food-reviews?select=Reviews.csv","71df04fd":"Se observa que la mayor\u00eda de las calificaciones de los clientes son positivas. Lo cual sugiere que la mayor\u00eda de las rese\u00f1as ser\u00e1n tambi\u00e9n positivas.\n\nLas palabras populares son \u201cTaste\u201d, \u201cLove\u201d, \u201cProduct\u201d, \u201cAmazon\u201d, \u201cOne\u201d,  en su mayor\u00eda son positivas.\n\n**Clasificaci\u00f3n de rese\u00f1as**\n\nRese\u00f1as positivas se clasifican +1, y rese\u00f1as negativas ser\u00e1n clasificadas como -1.\n\nClasificaremos todas las rese\u00f1as con \u201cScore\u201d>3 como +1, \u201cScore\u201d<3 como -1. Se eliminar\u00e1n las rese\u00f1as con \u201cScore\u201d=3 porque son  neutrales. ","6a048c8a":"La matrix de confusi\u00f3n anterior ayuda a comprender el desempe\u00f1o del modelo\n","86e3d0e5":"Se observa que la precisi\u00f3n general del modelo en los datos de prueba es del 93%","eaa53ec3":"Se observa dataframe contiene productos, usuarios e informaci\u00f3n de la rese\u00f1a.\n\nLos datos que m\u00e1s vamos a utilizar para el an\u00e1lisis ser\u00e1 \u201cSummary\u201d, \u201cText\u201d y \u201cScore\u201d.\n\n* Text \u2013 Es la variable que contiene la rese\u00f1a completa.\n* Summary \u2013 Es el resumen de la rese\u00f1a.\n* Score \u2013 Es la calificaci\u00f3n del producto provista por el cliente.\n\n**Paso 2: An\u00e1lisis de Datos**","5b91bafd":"**Construcci\u00f3n del modelo**\n\nObjetivo: Tomar las rese\u00f1as como entrada y luego proporcionar una predicci\u00f3n si la rese\u00f1a es positiva o negativa.\n\nEs una tarea clasificaci\u00f3n, se enternar\u00e1 al modelo bajo una regresi\u00f3n log\u00edstica.\n"}}