{"cell_type":{"607af7d4":"code","3ea92ede":"code","a6e23ab6":"code","878af38a":"code","03fc05e2":"code","8553d152":"code","c21d0b74":"code","ee4f5540":"code","da7e7648":"code","8dac8b71":"markdown","336aaa89":"markdown","74a14ff6":"markdown","c397032d":"markdown","ef980f51":"markdown","6de01efe":"markdown","a75b2641":"markdown","294bbca9":"markdown","be8185b3":"markdown","095d9da6":"markdown"},"source":{"607af7d4":"# importing modules and data \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 70)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom mlxtend.classifier import StackingCVClassifier\nfrom sklearn.model_selection import KFold\nimport warnings\nwarnings.simplefilter(action='ignore')\n\ntrain = pd.read_csv('..\/input\/learn-together\/train.csv')\ntest = pd.read_csv('..\/input\/learn-together\/test.csv')\n\n","3ea92ede":"cover_type = {1:'Spruce\/Fir', 2:'Lodgepole Pine',3:'Ponderosa Pine',4:'Cottonwood\/Willow',5:'Aspen',6:'Douglas-fir',7:'Krummholz'}\ntrain['Cover_type_description'] = train['Cover_Type'].map(cover_type)\n\n# I put together train and test to work simultaneously on both of them\n\ncombined_data = [train, test]\n\ndef distance(a,b):\n    return np.sqrt(np.power(a,2)+np.power(b,2))\n\nextremely_stony = [1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1]\nstony = [0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\nrubbly = [0,0,1,1,1,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\nother = [0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,1,1,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]\n\nfor data in combined_data:\n\n    data['mean_Hillshade'] = (data['Hillshade_9am']+ data['Hillshade_Noon']+data['Hillshade_3pm'])\/3\n    data['Distance_to_hidrology'] = distance(data['Horizontal_Distance_To_Hydrology'],data['Vertical_Distance_To_Hydrology'])\n    data['Distance_hydrology_roads'] =distance(data['Vertical_Distance_To_Hydrology'], data['Horizontal_Distance_To_Roadways'])\n    data['Distance_hydrology_fire'] = distance(data['Vertical_Distance_To_Hydrology'], data['Horizontal_Distance_To_Fire_Points'])\n    \n    # there are 40 differents type of soil in Roosvelt National Forest but there are some common features between them\n    # we can try to group soils according to some common features like stony \n    \n    data['extremely_stony_level'] = data[[col for col in data.columns if col.startswith(\"Soil\")]]@extremely_stony\n    data['stony'] = data[[col for col in data.columns if col.startswith(\"Soil\")]]@stony\n    data['rubbly'] = data[[col for col in data.columns if col.startswith(\"Soil\")]]@rubbly\n    data['other'] = data[[col for col in data.columns if col.startswith(\"Soil\")]]@other\n   \n    data['Hillshade_noon_3pm'] = data['Hillshade_Noon']- data['Hillshade_3pm']\n    data['Hillshade_3pm_9am'] = data['Hillshade_3pm']- data['Hillshade_9am']\n    data['Hillshade_9am_noon'] = data['Hillshade_9am']- data['Hillshade_Noon']\n    \n    data['Up_the_water'] = data['Vertical_Distance_To_Hydrology'] > 0\n    data['Horizontal_plus_vertical_distance_to_hydrology'] = data['Horizontal_Distance_To_Hydrology'] + data['Vertical_Distance_To_Hydrology']\n    data['Total_horizontal_distance'] = data['Horizontal_Distance_To_Hydrology']+ data['Horizontal_Distance_To_Roadways']+ data['Horizontal_Distance_To_Fire_Points']\n    data['Elevation_of_hydrology'] = data['Elevation']+ data['Vertical_Distance_To_Hydrology']\n    data['Elevation_of_hydrology2'] = data['Elevation']- data['Vertical_Distance_To_Hydrology']\n    data['Distance_to_firepoints plus Distance_to_roads'] = data['Horizontal_Distance_To_Fire_Points']+ data['Horizontal_Distance_To_Roadways']\n    data['Distance_to_roads plus distance_to_hydrology'] = data['Horizontal_Distance_To_Roadways'] + data['Horizontal_Distance_To_Hydrology']\n    data['Distance_to_firepoints minus Distance_to_roads'] = data['Horizontal_Distance_To_Fire_Points']- data['Horizontal_Distance_To_Roadways']\n    data['Distance_to_roads minus distance_to_hydrology'] = data['Horizontal_Distance_To_Roadways'] - data['Horizontal_Distance_To_Hydrology']\n    data['Elevation_plus_slope'] = data['Elevation']+ data['Slope']\n    data['Elevation_plus_aspect'] =data['Elevation']+ data['Aspect']\n    data['Elevation_Aspect_Slope'] = data['Elevation']+ data['Aspect']+ data['Slope']\n    data['Slope_plus_aspect'] = data['Slope']+ data['Aspect']\n    data['Hillshade9_plus_hillshadenoon_plus_hillshade3'] = data['Hillshade_9am'] + data['Hillshade_Noon']+ data['Hillshade_3pm']\n    data['Aspen'] = data['Soil_Type11']+data['Soil_Type13']+data['Soil_Type18']+data['Soil_Type19']+data['Soil_Type26']+data['Soil_Type30']\n    data['Cottonwood\/Willow'] = data['Soil_Type1']+data['Soil_Type3']+data['Soil_Type14']+data['Soil_Type17']\n    data['Douglas-fir'] = data['Soil_Type5']+data['Soil_Type10']+data['Soil_Type16']\n    data['Krummholz'] = data['Soil_Type35']+data['Soil_Type36']+data['Soil_Type37']+data['Soil_Type38']+data['Soil_Type39']+data['Soil_Type40']\n    data['Lodgepole Pine'] = data['Soil_Type8']+data['Soil_Type9']+data['Soil_Type12']+data['Soil_Type20']+data['Soil_Type25']+data['Soil_Type28']+data['Soil_Type29']+data['Soil_Type32']+data['Soil_Type33']+data['Soil_Type34']\n    data['Ponderosa Pine'] = data['Soil_Type2']+data['Soil_Type4']+data['Soil_Type6']\n    data['Spruce\/Fir'] = data['Soil_Type21']+data['Soil_Type22']+data['Soil_Type23']+data['Soil_Type24']+data['Soil_Type27']+data['Soil_Type31']\n    data['Spruce\/Fir2'] = data['Soil_Type19']+data['Soil_Type21']+data['Soil_Type22']+data['Soil_Type23']+data['Soil_Type24']+data['Soil_Type27']+data['Soil_Type31']+data['Soil_Type35']+data['Soil_Type38']+data['Soil_Type39']+data['Soil_Type40']\n    data['Lodgepole Pine2'] = data['Soil_Type2']+data['Soil_Type3']+data['Soil_Type4']+data['Soil_Type6']+data['Soil_Type8']+data['Soil_Type9']+data['Soil_Type10']+data['Soil_Type11']+data['Soil_Type12']+data['Soil_Type13']+data['Soil_Type14']+data['Soil_Type16']+data['Soil_Type17']+data['Soil_Type18']+data['Soil_Type20']+data['Soil_Type25']+data['Soil_Type26']+data['Soil_Type28']+data['Soil_Type29']+data['Soil_Type30']+data['Soil_Type32']+data['Soil_Type33']+data['Soil_Type34']+data['Soil_Type36']\n    data['Aspen_elev'] = data['Aspen'] * data['Elevation']\n    data['Cottonwood\/Willow_elev'] = data['Cottonwood\/Willow'] * data['Elevation']\n    data['Douglas-fir_elev'] = data['Douglas-fir'] * data['Elevation']\n    data['Krummholz_elev'] = data['Krummholz'] * data['Elevation']\n    data['Lodgepole Pine_elev'] = data['Lodgepole Pine'] * data['Elevation']\n    data['Ponderosa Pine_elev'] =data['Ponderosa Pine'] * data['Elevation']\n    data['Spruce\/Fir_elev'] = data['Spruce\/Fir'] * data['Elevation']\n    data['Aspen_elev2'] = data['Aspen'] * data['Elevation_of_hydrology2']\n    data['Cottonwood\/Willow_elev2'] = data['Cottonwood\/Willow'] * data['Elevation_of_hydrology2']\n    data['Douglas-fir_elev2'] = data['Douglas-fir'] * data['Elevation_of_hydrology2']\n    data['Krummholz_elev2'] = data['Krummholz'] * data['Elevation_of_hydrology2']\n    data['Lodgepole Pine_elev2'] = data['Lodgepole Pine'] * data['Elevation_of_hydrology2']\n    data['Ponderosa Pine_elev2'] =data['Ponderosa Pine'] * data['Elevation_of_hydrology2']\n    data['Spruce\/Fir_elev2'] = data['Spruce\/Fir'] * data['Elevation_of_hydrology2']\n\n\nsoil_columns = [col for col in train.columns if col.startswith('Soil')]\n\n# we can drop soil columns because we have group each soil according to their stoyness\n\nfor data in combined_data:\n    data.drop(columns = soil_columns, inplace=True)\n    \n# for categorical value (up the water) we can encode them into dummy values  \ncolumns_to_encode = ['Up_the_water']\n        \ntrain = pd.get_dummies(train,columns = columns_to_encode)\ntest = pd.get_dummies(test,columns = columns_to_encode)\n\n# once we have encoded the columns we can drop them from both training and testing dataset\n\nfor data in combined_data:\n    data.drop(columns= columns_to_encode, inplace=True)\n\ntarget = 'Cover_Type'\nfeatures = [ col for col in train.columns if col not in ['Id','Cover_Type','Cover_type_description']]\n\n\nX = train[features]\ny = train[target]\n    ","a6e23ab6":"\n\nX_train, X_test,y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n\n#Random Forest\n\n\nrandom_forest = RandomForestClassifier()\nparams_random_forest = {'n_estimators':[150,200],'criterion' : ['entropy','gini'], 'max_depth': [30,35,40]}\ngrid_search_random_forest = GridSearchCV(random_forest, param_grid= params_random_forest, cv=5, n_jobs=-1)\ngrid_search_random_forest.fit(X_train,y_train)\n\nforest = RandomForestClassifier(n_estimators=grid_search_random_forest.best_params_['n_estimators'],criterion=grid_search_random_forest.best_params_['criterion'],max_depth=grid_search_random_forest.best_params_['max_depth'] )\nforest.fit(X_train, y_train)\n","878af38a":"y_pred = forest.predict(X_test)\n\nprint(\"Accuracy random forest :\", accuracy_score(y_test, y_pred))","03fc05e2":"gradient_boosting = GradientBoostingClassifier()\nparams_gradient_boosting = {'n_estimators':[150,200], 'max_depth': [30,35,40]}\ngrid_search_gradient_boosting = GridSearchCV(gradient_boosting, param_grid= params_gradient_boosting, cv=5, n_jobs=-1)\ngrid_search_gradient_boosting.fit(X_train,y_train)\n\nboosting = GradientBoostingClassifier(n_estimators=grid_search_random_forest.best_params_['n_estimators'],max_depth=grid_search_random_forest.best_params_['max_depth'] )\nboosting.fit(X_train, y_train)\n\ny_pred = boosting.predict(X_test)\n\nprint(\"Accuracy gradient_classifier :\", accuracy_score(y_test, y_pred))","8553d152":"extra_tree = ExtraTreesClassifier()\nparams_extra_tree = {'n_estimators':[150,200], 'max_depth': [30,35,40]}\ngrid_search_extra_tree = GridSearchCV(extra_tree, param_grid=params_extra_tree , cv=5, n_jobs=-1)\ngrid_search_extra_tree.fit(X_train,y_train)\n\nextra_tree = ExtraTreesClassifier(n_estimators=grid_search_extra_tree.best_params_['n_estimators'],criterion='entropy',max_depth=grid_search_extra_tree.best_params_['max_depth'] ,  bootstrap=True)\nextra_tree.fit(X_train,y_train)\n\ny_pred = extra_tree.predict(X_test)\n\nprint(\"Accuracy extra_tree classifier :\", accuracy_score(y_test, y_pred))\n","c21d0b74":"#Kfold cross validation for stacking clssifiers\nkf = KFold(n_splits=10, shuffle = True)\n\nclassifiers = [forest,boosting,extra_tree]\n\nstacking_clf = StackingCVClassifier(classifiers=classifiers,use_probas=True,meta_classifier=forest,cv=kf, use_features_in_secondary=True, random_state=1)\n\nstacking_clf.fit(X_train, y_train)\n\ny_pred = extra_tree.predict(X_test)\n\nprint(\"Accuracy stacking classifier :\", accuracy_score(y_test, y_pred))\n\n","ee4f5540":"cover_type = ['Spruce\/Fir', 'Lodgepole Pine','Ponderosa Pine','Cottonwood\/Willow','Aspen','Douglas-fir','Krummholz']\ncm = pd.DataFrame(confusion_matrix(y_test, y_pred), index = cover_type, columns= cover_type)\n\nprint(cm)","da7e7648":"#Submitting\nX_sub = test[features]\ny_pred_sub = stacking_clf.predict(X_sub)\n\n    \nsub = pd.DataFrame({'Id': test.Id, 'Cover_Type': y_pred_sub})\nsub.to_csv('submission.csv', index = False)","8dac8b71":"## Stacking Classifiers","336aaa89":"# Stacking classifiers for Roosevelt National Forest \n\nKernel is divided in this way:\n\n1 - Features engineering\n\n2- Models building \n\n3 - Stacking models\n\n4 - Confusion Matrix","74a14ff6":"### Gradientboosting Classifier","c397032d":"### Random Forest ","ef980f51":"As you can see from confusion matrix most of the errors are focused on misclassification between Spruce\/Fir and Lodgepole\/Pine. This is something the needs to be investigated to improve the model.  Finding the right features to differentiate between Spruce\/Fir and Lodgepole\/Pine could be the key point to improve the model","6de01efe":"## 3 - Confusion Matrix","a75b2641":"If you find this kernel useful or it has given some insights to improve yours, please upvote!","294bbca9":"### ExtraTree Classifier ","be8185b3":"## 2 - Models Building","095d9da6":"## 1 - Features engineering"}}