{"cell_type":{"36659996":"code","6d2e1f1f":"code","0f524113":"code","3cd20177":"code","4fe4367b":"code","6b373f0d":"code","6c782ca1":"code","2a52cba1":"code","359971f5":"code","2f87b487":"code","a809bf66":"code","ba05be83":"code","2ee6f02d":"code","1b3ac0e4":"code","7ec9a145":"code","9e7e2d4b":"code","b4a31e04":"code","9e45ca4a":"markdown","fc88fbb6":"markdown","9f3d0922":"markdown","be48ed5a":"markdown","78b1916c":"markdown"},"source":{"36659996":"import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nimport cv2","6d2e1f1f":"image_string = tf.io.read_file(\"..\/input\/mnistasjpg\/testSet\/testSet\/img_10.jpg\")\nimage=tf.image.decode_jpeg(image_string,channels=3)","0f524113":"image.shape, image.numpy().max()","3cd20177":"fig = plt.figure()\nplt.subplot(1,2,1)\nplt.title('Original image')\nplt.imshow(image)","4fe4367b":"batch_size = 200\nimg_height = 28\nimg_width = 28\nepochs = 10\ntrain_dir = \"..\/input\/mnistasjpg\/trainingSet\/trainingSet\/\"\ntest_dir = \"..\/input\/mnistasjpg\/trainingSample\/trainingSample\/\"","6b373f0d":"# data_dir = tf.keras.utils.get_file(origin=\"..\/input\/mnistasjpg\/null\", \n#                                    fname='flower_photos', \n#                                    untar=True)\n\n# _URL\n# path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n# PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')","6c782ca1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_image_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.3) # Generator for our training data\n","2a52cba1":"train_ds =  train_image_generator.flow_from_directory(batch_size=batch_size,\n                                                           directory=train_dir,\n                                                           shuffle=True,\n                                                           target_size=(img_height, img_width),\n                                                           class_mode='categorical',\n                                                            subset='training')\n\n\ntest_ds =  train_image_generator.flow_from_directory(batch_size=batch_size,\n                                                           directory=train_dir,\n                                                           shuffle=True,\n                                                           target_size=(img_height, img_width),\n                                                           class_mode='categorical',\n                                                            subset='validation')","359971f5":"# Seed value\nseed_value= 0\n\nimport os\nos.environ['PYTHONHASHSEED']=str(seed_value)\n\nimport random\nrandom.seed(seed_value)\n\nimport numpy as np\nnp.random.seed(seed_value)\n\nimport tensorflow as tf\ntf.random.set_seed(seed_value)","2f87b487":"import math\ndef scheduler(epoch):\n  epoch_limit = 3\n\n  if epoch < epoch_limit:\n    return 0.01\n  else:\n    return  max(0.001 * math.exp(0.001 * (epoch_limit - epoch)) , 0.0001)\n\n\n\nlrcallback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\nimport os, datetime\n\nlogdir = os.path.join(\"logs3\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\n\n# {epoch:02d}-{val_loss:.2f}\ncheckpoint_filepath = '.\/{epoch:02d}-{val_accuracy:.2f}.checkpoint2.hdf5'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n                              filepath=checkpoint_filepath,\n                              monitor='val_accuracy',\n                              mode='max',\n                              save_best_only=True)\n\n\n\n# The patience parameter is the amount of epochs to check for improvement\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n","a809bf66":"#\n# Multi models\n#","ba05be83":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","2ee6f02d":"inputs = keras.Input(shape=(28, 28, 3),name=\"img\")\nx1 = layers.Conv2D(4, 5, activation=\"relu\")(inputs)\nx2 = layers.Conv2D(8, 5, activation=\"relu\")(x1)\nx3 = layers.MaxPooling2D(3)(x2)\n\n\nx4 = layers.Conv2D(16, 5, activation=\"relu\", padding='same')(x3)\nx5 = layers.Conv2D(32, 5, activation=\"relu\", padding='same')(x4)\nx6 = layers.MaxPooling2D(3)(x5)\n\n\nflatten = layers.Flatten()\n\nblock_3_output = layers.Concatenate()([flatten(inputs), flatten(x3), flatten(x6)])\n\nx = layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(block_3_output)\nx = layers.Dropout(0.05)(x)\noutputs = layers.Dense(10, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs, outputs, name=\"mnist\")\nmodel.summary()","1b3ac0e4":"ls","7ec9a145":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])","9e7e2d4b":"# keras.backend.set_value(model.optimizer.learning_rate, 0.0001)","b4a31e04":"history = model.fit(\n    train_ds,\n    steps_per_epoch=len(train_ds.filepaths) \/\/ batch_size,\n    epochs=epochs,\n    verbose=1,\n    validation_data=test_ds,\n    validation_steps=len(test_ds.filepaths) \/\/ batch_size\n)","9e45ca4a":"# Train & Validation Split","fc88fbb6":"# Network topology","9f3d0922":"\n# **Tunning parameters**\n","be48ed5a":"# Seed Initial random weights","78b1916c":"# Non-linear connectivity topology"}}