{"cell_type":{"1e055230":"code","ed7ca7b5":"code","41ffcef6":"code","a7bce98a":"code","0013c2a1":"code","e355d4a3":"code","62ceebf0":"code","2674a5b6":"code","8e2d0ddd":"code","f136fe59":"code","84ee8800":"code","91abd29f":"code","62f953d3":"code","187e180e":"code","bbff4e81":"code","c1b2c5d9":"code","195fa116":"code","3c3c250a":"code","c99d79e2":"markdown","74021e18":"markdown","3aeebdd2":"markdown","56fdc8d7":"markdown","6ebbf43d":"markdown","3f082cdf":"markdown"},"source":{"1e055230":"import pandas as pd\nimport numpy as np\n\n## Plotting Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n## ML Libraries\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale, MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","ed7ca7b5":"# Reading only the training set for now\ndf = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")","41ffcef6":"## To display max column and row\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","a7bce98a":"df.head()","0013c2a1":"## looking at the shape of the dataframe to see number of rows and columns\ndf.shape","e355d4a3":"## Checking count of target variables to see if the data is skewed or not\ndf['target'].value_counts()","62ceebf0":"corr = df.corr()\n# high_corr = corr[corr <= 0.3]\nplt.figure(figsize=(35, 30))\nsns.heatmap(corr, cmap=\"Greens\")","2674a5b6":"corr_target = df.corrwith(df[\"target\"])","8e2d0ddd":"## Top positively correlated columns with target variables\ncorr_target[corr_target > 0].sort_values(ascending = False)","f136fe59":"## Top negatively correlated columns with target variables\ncorr_target[corr_target < 0].sort_values()","84ee8800":"c = df.corr().abs()\nc = c.drop([\"id\"], axis = 1)\nc = c.drop([\"id\"], axis = 0)\ns = c.unstack()\nso = s.sort_values(kind=\"quicksort\")\n\n## Top 20 positively correlated columns \nso[:20]","91abd29f":"## Everything after 102 are column coorelating with each other so looking at ~last 40 columns\nso[-150:-102]","62f953d3":"train, validation = train_test_split(df, test_size = 0.2)\ntrain, test = train_test_split(train, test_size = 0.2)","187e180e":"## Preparing the data to be used in training the dataset\ntrain_df = train.drop([\"id\",\"target\"], axis = 1)\ntrain_df_y = train[\"target\"]\n\ntest_df = test.drop([\"id\", \"target\"], axis = 1)\n# train_df_y = train[\"target\"]\n\nvalid_df = validation.drop([\"id\", \"target\"], axis = 1)\nvalid_df_y = validation[\"target\"]","bbff4e81":"## Scaling the data\nscaler = MinMaxScaler()\nscaler.fit(train_df)\ntrain_df = pd.DataFrame(scaler.transform(train_df))\nvalid_df = pd.DataFrame(scaler.transform(valid_df))\ntest_df = pd.DataFrame(scaler.transform(test_df))","c1b2c5d9":"## Building XGboost classifier\nXGB = xgb.XGBClassifier(max_depth = 10,\n                       learning_rate = 0.01,\n                       objective = 'binary: logistic',\n                       gamma = 0.6,\n                       min_child_weight = 8) ","195fa116":"train_df.head()","3c3c250a":"## training and evaluating the model\nXGB_ = XGB.fit(train_df, train_df_y)\n#               eval_set = [(valid_df.values, valid_df_y)],\n#               eval_metric = 'auc',\n#               early_stopping_rounds = 15,\n#               verbose = True)","c99d79e2":"# Work still in progress. Please visit again to check for updates\n\n#### If you liked the work so far, support it with upvote and if you have any suggestions\/feedbacks please leave a comment and I will work on it. ","74021e18":"### Feature Importance and Feature Selection With XGBoost","3aeebdd2":"##### finding correlation of all columns to target column","56fdc8d7":"#### Finding Correlation","6ebbf43d":"##### Finding highly correlated columns","3f082cdf":"Note: None of the columns are highly correlated with each other so we cant drop any columns but we can build a model using top 20 columns that are highly correlated with target variable. "}}