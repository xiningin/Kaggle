{"cell_type":{"afb527f4":"code","4c5cd498":"code","aad22e0d":"code","18eac4cd":"code","ddc558b2":"code","3fc9f964":"code","599ec230":"code","79434b39":"code","e0a51476":"code","56a99617":"code","904fa4a0":"code","c1535944":"code","e0e015c5":"code","5edbfa2c":"code","936987c2":"code","687c93ab":"markdown","3afefc15":"markdown","8e65659e":"markdown","2cfe50b5":"markdown","ef006276":"markdown","c774468e":"markdown","da8d3ced":"markdown","2a31f450":"markdown","fc60cfef":"markdown","6ad3d31c":"markdown","ce203331":"markdown","85da4886":"markdown"},"source":{"afb527f4":"!pip install pycaret\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pycaret.classification import *\n\nfrom sklearn.metrics import *\nimport scikitplot as skplt\n\ndf = pd.read_csv(\"..\/input\/parkinsons-disease-data-set\/parkinsons.data\")","4c5cd498":"df.head()","aad22e0d":"df.info()","18eac4cd":"df.describe()","ddc558b2":"ax = sns.countplot(x=\"status\", data=df)","3fc9f964":"test_df = df.sample(frac=0.1)\ntrain_df = df.drop(test_df.index).reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ntest_df['set'] = 'test'\ntrain_df['set'] = 'train'\n\nax = sns.catplot(x=\"status\", col=\"set\", data=pd.concat([train_df, test_df]), kind=\"count\", height=3)\nplt.show()\n\nprint('Training dataset           :', len(train_df))\nprint('Unseen data for validation :', len(test_df))","599ec230":"clf1 = setup(data = train_df, target = 'status',ignore_features = ['name'],fix_imbalance=True, session_id=123, silent = True)","79434b39":"compare_models()","e0a51476":"xgboost  = create_model('xgboost')","56a99617":"tuned_xgboost = tune_model(xgboost)","904fa4a0":"plot_model(tuned_xgboost, plot = 'auc')","c1535944":"plot_model(tuned_xgboost, plot='feature')","e0e015c5":"plot_model(tuned_xgboost, plot = 'confusion_matrix')","5edbfa2c":"final_xgboost = finalize_model(tuned_xgboost)","936987c2":"unseen_predictions = predict_model(final_xgboost, data=test_df)\nclass_names=['parkinson', 'normal']\nprint(classification_report(unseen_predictions['status'].values, unseen_predictions['Label'].values, target_names=class_names,zero_division=0))\ncm = skplt.metrics.plot_confusion_matrix(unseen_predictions['status'].values, unseen_predictions['Label'].values, figsize=(8, 8), normalize=False)","687c93ab":"### Tuned Model","3afefc15":"### Model selection","8e65659e":"## Parkinson's Data Set\nThe dataset was created by Max Little of the University of Oxford, in collaboration with the National Centre for Voice and Speech, Denver, Colorado, who recorded the speech signals. The original study published the feature extraction methods for general voice disorders. This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds to one of 195 voice recordings from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to the \"status\" column which is set to 0 for healthy and 1 for PD.\n\nThe data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column. \n\n### Attribute Information\n* **name** - ASCII subject name and recording number\n* **MDVP:Fo(Hz)** - Average vocal fundamental frequency\n* **MDVP:Fhi(Hz)** - Maximum vocal fundamental frequency\n* **MDVP:Flo(Hz)** - Minimum vocal fundamental frequency\n* **MDVP:Jitter(%), MDVP:Jitter(Abs), MDVP:RAP, MDVP:PPQ, Jitter:DDP** - Several measures of variation in fundamental frequency\n* **MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA** - Several measures of variation in amplitude\n* **NHR, HNR** - Two measures of the ratio of noise to tonal components in the voice\n* **status** - The health status of the subject (one) - Parkinson's, (zero) - healthy\n* **RPDE, D2** - Two nonlinear dynamical complexity measures\n* **DFA - Signal** fractal scaling exponent\n* **spread1,spread2,PPE** - Three nonlinear measures of fundamental frequency variation","2cfe50b5":"### Evaluate training performance","ef006276":"### Split training & test dataset","c774468e":"## Work in Progress","da8d3ced":"# Parkinson's Disease Detection From Vocal Biomarker\nby Nasrul Hakim\n\n## Introduction\nParkinson\u2019s Disease (PD) is a degenerative neurological disorder marked by decreased dopamine levels in the brain. It manifests itself through a deterioration of movement, including the presence of tremors and stiffness. There is commonly a marked effect on speech, including dysarthria (difficulty articulating sounds), hypophonia (lowered volume), and monotone (reduced pitch range). Additionally, cognitive impairments and changes in mood can occur, and risk of dementia is increased.\n\n![https:\/\/www.parkinson.org\/sites\/default\/files\/neurons%20.jpg](https:\/\/www.parkinson.org\/sites\/default\/files\/neurons%20.jpg)\n\nTraditional diagnosis of Parkinson\u2019s Disease involves a clinician taking a neurological history of the patient and observing motor skills in various situations. Since there is no definitive laboratory test to diagnose PD, diagnosis is often difficult, particularly in the early stages when motor effects are not yet severe. Monitoring progression of the disease over time requires repeated clinic visits by the patient. An effective screening process, particularly one that doesn\u2019t require a clinic visit, would be beneficial. Since PD patients exhibit characteristic vocal features, voice recordings are a useful and non-invasive tool for diagnosis.\n\nThe advancement of artificial intelligence (AI), technologies, and computer sciences has paved the way for new opportunities in the field of digital health, the ultimate goal of which is to improve the lives of people and healthcare professionals through the use of technology. If machine learning algorithms could be applied to a voice recording dataset to accurately diagnosis PD, this would be an effective screening step prior to an appointment with a clinician.\n\n### Parkinson's Desease\nVocal biomarkers have been studied primarily in the field of neurodegenerative disorders, particularly Parkinson's disease, where voice disorders are prevalent (up to 89%). Voice changes are expected to be used as an early diagnostic biomarker or marker of disease progression, eventually supplementing the state-of-the-art manual examination to assess symphony. \n\nThese vocal problems are mostly associated with phonation and articulation, and include pitch changes, diminished energy in the upper harmonic regions, and imprecise vowel and consonant articulation, which results in impaired intelligibility. While alterations in voice are frequently disregarded by both patients and physicians during the early stages of the disease, objective assessments indicate that up to 78% of people with early stage Parkinson's disease have changes in voice features.\n\n### Vocal biomarkers\nThe human voice is a rich medium that is used extensively in interpersonal communication. It is one of the most natural and energy-efficient modes of communication. The voice, as complex arrays of sound emanating from our vocal chords, has a plethora of data and is essential for social interaction because it enables us to communicate insights about our emotions, anxieties, sentiments, and stimulation through modulation of its tone or pitch.\n\nA biomarker is a factor that can be objectively measured and evaluated to represent a biological or pathogenic process, or a pharmacological response to a therapeutic intervention, and can be used as a surrogate marker of a clinical endpoint. A vocal biomarker is a signature, feature, or combination of features from the audio signal of the voice that is associated with a clinical outcome and can be used to monitor patients, diagnose a condition, or grade the severity or stages of a disease, or for drug development.\n\n### Extracting Audio Feature\nPrior to data analysis, it is necessary to convert the audio signal to \"features,\" which are the signal's most prominent and discriminating qualities that will subsequently be used to train machine learning algorithms. Numerous approaches for deriving acoustic features from temporal, frequency, cepstral, wavelet, and time-frequency domains have been proposed in many literatures. \n* **Prosodic** - pitch, formants, energy, jitter, and shimmer\n* **Spectral characteristics** - spectral flux, slope, centroid, entropy, roll-off, and flatness \n* **Voice quality** - zero-crossing rate, harmonic-to-noise ratio, noise-to-harmonic ratio\n* **Phonation** - fundamental frequency, pitch period entropy) parameters can all be extracted and analysed\n\nThe appropriate selection of attributes is highly dependent on the type of voice issue, condition, and recording method. For instance, while acoustic features extracted from sustained vowel phonations or diadochokinetic recordings are frequently used to detect Parkinson's disease, linguistic features extracted from spontaneous or semi-spontaneous speech may be a better choice for estimating Alzheimer's disease or mental health disorders.","2a31f450":"---\n### Import Libraries","fc60cfef":"### Evaluate on unseen data","6ad3d31c":"### Exploratory Data Analysis","ce203331":"### Setup environment","85da4886":"### Create XGBoost Model"}}