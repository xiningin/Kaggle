{"cell_type":{"9b0cde04":"code","0f3b70c6":"code","10db84ef":"code","fff7fa61":"code","b25d6438":"code","146ad9fe":"code","8e709993":"code","c27719bd":"code","a46f768b":"code","c9f38928":"code","997eb5f8":"code","1725d024":"code","8619a214":"code","02d27414":"code","65d49203":"code","377fcdb8":"code","7657ab29":"code","05fd306b":"code","aa92b1a2":"code","d33248fe":"code","6967cbe1":"code","05b3b5c4":"code","240a27e9":"code","136d1622":"code","37f3fae7":"code","7e30e223":"code","06b4c136":"code","c88b3257":"code","562d67c2":"code","e63da820":"code","9ae44149":"code","16b0921b":"code","f20ed9fe":"code","29a6d0ac":"code","f743a393":"code","3c8efdd6":"code","75124769":"code","dfb2439a":"code","4e949631":"code","017ee09c":"code","8ca1de7b":"code","94fffe7d":"code","847f3c49":"markdown","be0942ce":"markdown","2ea552f6":"markdown","79ae5dce":"markdown","e6d15c5b":"markdown","93a5514f":"markdown","6559a796":"markdown","597f7e67":"markdown","6304e65a":"markdown","cc4d3526":"markdown","7214d783":"markdown","85c71b6f":"markdown","a28a4b0a":"markdown","0a11ad5d":"markdown","dfc7dc56":"markdown","6a7452b2":"markdown"},"source":{"9b0cde04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f3b70c6":"!pip install jovian --upgrade --quiet","10db84ef":"#import necessory libraries\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline","fff7fa61":"#project name\nproject_name = 'natural-scene-classification'","b25d6438":"data_dir = \"..\/input\/intel-image-classification\/seg_train\/seg_train\/\"\ntest_data_dir = \"..\/input\/intel-image-classification\/seg_test\/seg_test\"","146ad9fe":"\nbuilding_files = os.listdir(data_dir + '\/buildings')\nprint(f\"Number of Buildings : {len(building_files)}\")\nprint(building_files[:5])","8e709993":"dataset = ImageFolder(data_dir,transform = transforms.Compose([\n    transforms.Resize((150,150)),transforms.ToTensor()\n]))\ntest_dataset = ImageFolder(test_data_dir,transforms.Compose([\n    transforms.Resize((150,150)),transforms.ToTensor()\n]))","c27719bd":"img, label = dataset[0]\nprint(img.shape,label)","a46f768b":"print(f\"Images in tarining data : {len(dataset)}\")\nprint(f\"Images in test data : {len(test_dataset)}\")","c9f38928":"print(\"Follwing classes are there : \\n\",dataset.classes)","997eb5f8":"def display_img(img,label):\n    print(f\"Label : {dataset.classes[label]}\")\n    plt.imshow(img.permute(1,2,0))","1725d024":"display_img(*dataset[0])","8619a214":"display_img(*dataset[5000])","02d27414":"display_img(*dataset[8000])","65d49203":"random_seed = 2021\ntorch.manual_seed(random_seed)","377fcdb8":"val_size = 2000\ntrain_size = len(dataset) - val_size \n\ntrain_data,val_data = random_split(dataset,[train_size,val_size])\nprint(f\"Length of Train Data : {len(train_data)}\")\nprint(f\"Length of Validation Data : {len(val_data)}\")","7657ab29":"batch_size = 128","05fd306b":"train_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\nval_dl = DataLoader(val_data, batch_size*2, num_workers = 4, pin_memory = True)","aa92b1a2":"from torchvision.utils import make_grid\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig,ax = plt.subplots(figsize = (16,12))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n        break","d33248fe":"show_batch(train_dl)","6967cbe1":"class ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","05b3b5c4":"class NaturalSceneClassification(ImageClassificationBase):\n    \n    def __init__(self):\n        \n        super().__init__()\n        self.network = nn.Sequential(\n            \n            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n            nn.ReLU(),\n            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n        \n            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            \n            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            \n            nn.Flatten(),\n            nn.Linear(82944,1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512,6)\n        )\n    \n    def forward(self, xb):\n        return self.network(xb)","240a27e9":"model = NaturalSceneClassification()\nmodel","136d1622":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","37f3fae7":"def get_default_device():\n    \"\"\" Set Device to GPU or CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \n\ndef to_device(data, device):\n    \"Move data to the device\"\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device,non_blocking = True)\n\nclass DeviceDataLoader():\n    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n    \n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    \n    def __iter__(self):\n        \"\"\" Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b,self.device)\n            \n    def __len__(self):\n        \"\"\" Number of batches \"\"\"\n        return len(self.dl)","7e30e223":"device = get_default_device()\ndevice","06b4c136":"# load the into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device)","c88b3257":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n    \n    history = []\n    optimizer = opt_func(model.parameters(),lr)\n    for epoch in range(epochs):\n        \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    \n    return history","562d67c2":"#load the model to the device\nmodel = to_device(NaturalSceneClassification(),device)","e63da820":"#initial evaluation of the model\nevaluate(model,val_dl)","9ae44149":"#set the no. of epochs, optimizer funtion and learning rate\nnum_epochs = 30\nopt_func = torch.optim.Adam\nlr = 0.001","16b0921b":"#fitting the model on training data and record the result after each epoch\nhistory = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","f20ed9fe":"def plot_accuracies(history):\n    \"\"\" Plot the history of accuracies\"\"\"\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n    \n\nplot_accuracies(history)","29a6d0ac":"def plot_losses(history):\n    \"\"\" Plot the losses in each epoch\"\"\"\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","f743a393":"# Apply the model on test dataset and Get the results\ntest_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\nresult = evaluate(model, test_loader)\nresult","3c8efdd6":"#save the model\ntorch.save(model.state_dict(), 'natural-scene-classification.pth')","75124769":"def predict_img_class(img,model):\n    \"\"\" Predict the class of image and Return Predicted Class\"\"\"\n    img = to_device(img.unsqueeze(0), device)\n    prediction =  model(img)\n    _, preds = torch.max(prediction, dim = 1)\n    return dataset.classes[preds[0].item()]","dfb2439a":"from PIL import Image\n\n#open image file\nimg = Image.open(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10004.jpg\")\n\n#convert image to tensor\nimg = transforms.ToTensor()(img)\n\n#print image\nplt.imshow(img.permute(1,2,0))\n\n#prdict image label\nprint(f\"Predicted Class : {predict_img_class(img,model)}\")","4e949631":"#open image file\nimg = Image.open(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10100.jpg\")\n\n#convert image to tensor\nimg = transforms.ToTensor()(img)\n\n#print image\nplt.imshow(img.permute(1,2,0))\n\n#prdict image label\nprint(f\"Predicted Class : {predict_img_class(img,model)}\")","017ee09c":"#open image file\nimg = Image.open(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10241.jpg\")\n\n#convert image to tensor\nimg = transforms.ToTensor()(img)\n\n#print image\nplt.imshow(img.permute(1,2,0))\n\n#prdict image label\nprint(f\"Predicted Class : {predict_img_class(img,model)}\")","8ca1de7b":"img.shape","94fffe7d":"import jovian\n\njovian.log_dataset(dataset_url = data_dir, val_size = val_size, random_seed = random_seed)\n\n#save the hyperparameters to jovian plateform \n#jovian.reset()\njovian.log_hyperparams({\n    'num_epochs': num_epochs,\n    'opt_func': opt_func.__name__,\n    'batch_size': batch_size,\n    'lr': lr,\n})\n\njovian.log_metrics(test_loss=result['val_loss'], test_acc=result['val_acc'])\n\njovian.commit(project=project_name)","847f3c49":"> # **Model Fitting**","be0942ce":"# Netural Scene Classfication Model:","2ea552f6":" **Note:** Igonre or comment jovian lines if you are running this notebook.","79ae5dce":"> ## Predicting for invisual images:","e6d15c5b":"We have 14034 images in training data and 3000 images in test dataset.","93a5514f":"> # **Exploring the Dataset**","6559a796":"Save the parmeters to jovian plateform","597f7e67":"The images are rgb and have 150*150 pixel in each image","6304e65a":"> # Graphs for Model Accuracy and Losses :","cc4d3526":"> # Base Model for Image Classification:","7214d783":"> # Evaluate Test Data :","85c71b6f":"> # Training and Validation Datasets : ","a28a4b0a":"> # **Grid Of Train Data Images :**","0a11ad5d":"> # Visualising some images :","dfc7dc56":"> # Load the dataset into batches:","6a7452b2":"Helper Function or classes to Load Data into GPU"}}