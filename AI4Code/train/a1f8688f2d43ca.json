{"cell_type":{"c1f7469e":"code","d5ba00d9":"code","43142ad3":"code","84dd0940":"code","ed3790ee":"code","996b6fb9":"code","4ab0520b":"code","8b816942":"code","d6d45f36":"code","b6eb22b0":"code","133f2e38":"code","f06fb0b7":"code","85d6f677":"markdown","c558b284":"markdown","8b17c8b0":"markdown","ad3e6299":"markdown","5030d3bf":"markdown","825461aa":"markdown","1754aa79":"markdown","ab0386ce":"markdown"},"source":{"c1f7469e":"#-----------------\u8f09\u5165\u5957\u4ef6-------------------------\nimport pandas as pd\nimport numpy as np\nimport scipy\n\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom sklearn.linear_model import Ridge\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom scipy.optimize import minimize\n\nimport matplotlib.pyplot as plt\n\nimport gc\n","d5ba00d9":"#-------------------\u8cc7\u6599\u6e96\u5099-----------------------\nprint(\"Reading in Data\")\ndf_train = pd.read_csv('..\/input\/train.tsv', sep='\\t')\ndf_test = pd.read_csv('..\/input\/test_stg2.tsv', sep='\\t')\n\nnrow_train=df_train.shape[0]\nnrow_test=df_test.shape[0]\nY_train=np.log1p(df_train[\"price\"])\n\nprint('Size of train set',nrow_train)\nprint('Size of test set',nrow_test)\n\ndf=pd.concat([df_train,df_test],axis=0,sort=True)\ndf_test=pd.DataFrame(df_test[\"test_id\"])\n\n\n#----------------\u8655\u7406\u7f3a\u5931\u503c--------------------\nNUM_BRAND=2500\ndf[\"category_name\"]=df[\"category_name\"].fillna(\"Other\").astype(\"category\")\n\ndf[\"brand_name\"]=df[\"brand_name\"].fillna(\"Unknown\")\npop_brands=df[\"brand_name\"].value_counts().index[1:NUM_BRAND+1]\ndf.loc[~df[\"brand_name\"].isin(pop_brands),\"brand_name\"]=\"Other\"\ndf[\"brand_name\"]=df[\"brand_name\"].astype(\"category\")\n\ndf[\"item_description\"]=df[\"item_description\"].fillna(\"None\")\n\ndf[\"item_condition_id\"]=df[\"item_condition_id\"].astype(\"category\")\ndf_train.head()","43142ad3":"del df_train\ngc.collect","84dd0940":"#--------------------encode------------------------\nNAME_MIN_DF=10\nMAX_FEAT_DESCP=50000\nprint(\"Encodings\")\n\nprint(\"Condition Encoders\")\nvect_condition=LabelBinarizer(sparse_output=True)\nX_Condition=vect_condition.fit_transform(df[\"item_condition_id\"])\n\nprint(\"Shipping Encoders\")\nvect_shipping=LabelBinarizer(sparse_output=True)\nX_Shipping=vect_shipping.fit_transform(df[\"shipping\"])\n\nprint(\"Name Encoders\")\ncount_name=CountVectorizer(min_df=NAME_MIN_DF)\nX_name=count_name.fit_transform(df[\"name\"])\n\nprint(\"Category Encoders\")\ncount_category=CountVectorizer()\nX_category=count_category.fit_transform(df[\"category_name\"])\n\nprint(\"Brand Encoders\")\ncount_brand=CountVectorizer()\nX_brand=count_brand.fit_transform(df[\"brand_name\"])\n\n\nprint(\"Descp Encoders\")\ncount_descp=TfidfVectorizer(max_features=MAX_FEAT_DESCP,\n                            ngram_range=(1,3),\n                            stop_words=\"english\")\nX_descp=count_descp.fit_transform(df[\"item_description\"])\n\n","ed3790ee":"del df\ngc.collect\n","996b6fb9":"X=scipy.sparse.hstack([X_Shipping,X_Condition,X_brand,\n                       X_category,X_descp,X_name]).tocsr()\n","4ab0520b":"del X_descp\ndel X_brand\ndel X_category\ndel X_name\ndel X_Shipping\ndel X_Condition\ngc.collect\n","8b816942":"X_train=X[:nrow_train]\nX_test=X[nrow_train:]\ndtest=xgb.DMatrix(X_test)","d6d45f36":"del X\ngc.collect","b6eb22b0":"#--------------------Cross-Validation------------------------\nprint(\"Cross-Validation\")\nxgb_pred_val_index = np.zeros(X_train.shape[0])\nridge_pred_val_index = np.zeros(X_train.shape[0])\nlgb_pred_val_index = np.zeros(X_train.shape[0])\nxgb_pred_all_sum=[]\nridge_pred_all_sum=[]\nlgb_pred_all_sum=[]\nxgb_cv_RMSLE_sum=0\nridge_cv_RMSLE_sum=0\nlgb_cv_RMSLE_sum=0\n\n\nfolds=3\nkf = KFold(n_splits=folds, random_state=1001)\nfor i, (train_index, val_index) in enumerate(kf.split(X_train, Y_train)):\n    x_train, x_val = X_train[train_index], X_train[val_index]\n    y_train, y_val = Y_train[train_index], Y_train[val_index]\n\n    dtrain=xgb.DMatrix(x_train,y_train)\n    dval=xgb.DMatrix(x_val)\n    deval=xgb.DMatrix(x_val,y_val)\n    \n    \n    params = {\n    'booster': 'gblinear',\n    'objective': 'reg:linear', \n    'gamma': 0,                \n    'max_depth': 10,           \n    'lambda': 0,                   \n    'subsample': 0.85,             \n    'colsample_bytree': 0.9,      \n    'min_child_weight': 17,\n    'silent': 1,                  \n    'eta': 0.4,                 \n    'seed': 1001,\n    'nthread': 4,                 \n    'eval_metric':'rmse'\n    }\n    \n    plst = params.items()\n    evallist = [(deval, 'eval'), (dtrain, 'train')]\n    num_round=300\n    \n    model=xgb.train(plst,dtrain,num_round,evallist, verbose_eval=100,early_stopping_rounds=100)\n    xgb_pred_val=model.predict(dval)\n    xgb_RMSLE=np.sqrt(mean_squared_error(xgb_pred_val,y_val))\n    print('\\n Fold %02d XGBoost RMSLE: %.6f' % ((i + 1), xgb_RMSLE))\n    xgb_pred_all=model.predict(dtest)\n    \n    del dtrain\n    del dval\n    del deval\n    gc.collect()\n    \n    params = {\n        'boosting': 'gbdt',\n        'max_depth': 7,\n        'min_data_in_leaf': 80,\n        'num_leaves': 30,\n        'learning_rate': 0.4,\n        'objective': 'regression',\n        'metric': 'rmse',\n        'nthread': 4,\n        'bagging_freq': 1,\n        'subsample': 0.9,\n        'colsample_bytree': 0.7,\n        'min_child_weight': 17,\n        'is_unbalance': False,\n        'verbose': -1,\n        'seed': 1001,\n        'max_bin':511,\n        'num_threads':4\n    }\n    \n    dtrain = lgb.Dataset(x_train, label=y_train)\n    deval = lgb.Dataset(x_val, label=y_val)\n    watchlist = [dtrain, deval]\n    watchlist_names = ['train', 'val']\n\n    model = lgb.train(params,\n    train_set=dtrain,\n    num_boost_round=3000,\n    valid_sets=watchlist,\n    valid_names=watchlist_names,\n    early_stopping_rounds=100,\n    verbose_eval=300)\n    lgb_pred_val = model.predict(x_val)\n    lgb_RMSLE = np.sqrt(mean_squared_error(lgb_pred_val,y_val))\n    print(' Fold %02d LightGBM RMSLE: %.6f' % ((i + 1), lgb_RMSLE))\n    lgb_pred_all = model.predict(X_test)\n    \n    del dtrain\n    del deval\n    gc.collect()\n    \n    \n    \n    model=Ridge(solver='sag',alpha=4.75)\n    model.fit(x_train,y_train)\n    ridge_pred_val=model.predict(x_val)\n    ridge_RMSLE=np.sqrt(mean_squared_error(ridge_pred_val,y_val))\n    print('\\n Fold %02d Ridge RMSLE: %.6f' % ((i + 1), ridge_RMSLE))\n    ridge_pred_all=model.predict(X_test)\n    \n    del x_train\n    del y_train\n    del x_val\n    del y_val\n    gc.collect()\n    \n    xgb_pred_val_index[val_index] = xgb_pred_val\n    ridge_pred_val_index[val_index] = ridge_pred_val\n    lgb_pred_val_index[val_index] = lgb_pred_val\n    \n    if i > 0:\n        xgb_pred_all_sum = xgb_pred_all_sum + xgb_pred_all\n        ridge_pred_all_sum = ridge_pred_all_sum + ridge_pred_all\n        lgb_pred_all_sum = lgb_pred_all_sum + lgb_pred_all\n    else:\n        xgb_pred_all_sum = xgb_pred_all\n        ridge_pred_all_sum = ridge_pred_all\n        lgb_pred_all_sum = lgb_pred_all\n    \n    xgb_cv_RMSLE_sum = xgb_cv_RMSLE_sum + xgb_RMSLE\n    ridge_cv_RMSLE_sum = ridge_cv_RMSLE_sum + ridge_RMSLE\n    lgb_cv_RMSLE_sum = lgb_cv_RMSLE_sum + lgb_RMSLE\n\nxgb_cv_avg_score=xgb_cv_RMSLE_sum\/folds\nridge_cv_avg_score=ridge_cv_RMSLE_sum\/folds\nlgb_cv_avg_score=lgb_cv_RMSLE_sum\/folds\n\nxgb_val_real_RMSLE=np.sqrt(mean_squared_error(xgb_pred_val_index,Y_train))\nridge_val_real_RMSLE=np.sqrt(mean_squared_error(ridge_pred_val_index,Y_train))\nlgb_val_real_RMSLE=np.sqrt(mean_squared_error(lgb_pred_val_index,Y_train))\n\nprint('\\n Average XGBoost RMSLE(cv):\\t%.6f' % xgb_cv_avg_score)\nprint(' Out-of-fold XGBoost RMSLE:\\t%.6f' % xgb_val_real_RMSLE)\nprint('\\n Average LightGBM RMSLE(cv):\\t%.6f' % lgb_cv_avg_score)\nprint(' Out-of-fold LightGBM RMSLE:\\t%.6f' % lgb_val_real_RMSLE)\nprint('\\n Average Ridge RMSLE(cv):\\t%.6f' % ridge_cv_avg_score)\nprint(' Out-of-fold Ridge RMSLE:\\t%.6f' % ridge_val_real_RMSLE)\n\nxgb_pred_all_avg=xgb_pred_all_sum\/folds\nridge_pred_all_avg=ridge_pred_all_sum\/folds\nlgb_pred_all_avg=lgb_pred_all_sum\/folds\n","133f2e38":"#------------blend-------------------\ndef rmse_min_func(weights):\n    final_prediction=0\n    for weight,prediction in zip(weights,blend_train):\n        final_prediction+=weight*prediction\n    return np.sqrt(mean_squared_error(Y_train,final_prediction))\n\nblend_train = []\nblend_test = []\n\nblend_train.append(xgb_pred_val_index) \nblend_train.append(lgb_pred_val_index)\nblend_train.append(ridge_pred_val_index)\nblend_train=np.array(blend_train)\n\nblend_test.append(xgb_pred_all_avg)\nblend_test.append(lgb_pred_all_avg)\nblend_test.append(ridge_pred_all_avg)\nblend_test=np.array(blend_test)\n\nprint('\\n Finding Blending Weights ...')\n\nres_list=[]\nweight_list=[]\n\nfor k in range(20):\n    starting_value=np.random.uniform(-1,1,len(blend_train))\n    bounds=[(-1,1)]*len(blend_train)\n    \n    res=minimize(\n        rmse_min_func,\n        starting_value,\n        method='L-BFGS-B',\n        bounds=bounds,\n        options={'disp':False,\n        'maxiter':100000})\n    \n    res_list.append(res['fun'])\n    weight_list.append(res['x'])\n    print('{iter}\\tScore: {score}\\tWeights: {weights}'.format(\n        iter=(k+1),\n        score=round(res['fun'],6),\n        weights='\\t'.join([str(round(item,10)) for item in res['x']])))\n\nbestSC=np.min(res_list)\nbestweight=weight_list[np.argmin(res_list)]\n\nprint('\\n Ensemble Score:{best_score}'.format(best_score=bestSC))\nprint('\\n Best Weights:{weight}'.format(weight=bestweight))\n\n\ntest_price=np.zeros(len(blend_test[0]))\ntrain_price =np.zeros(len(blend_train[0]))\n\nprint('\\n Your final model:')\nfor k in range(len(blend_test)):\n    print('%.6f * model-%d'%(bestweight[k],(k+1)))\n    test_price+=blend_test[k]*bestweight[k]\n    train_price+= blend_train[k] * bestweight[k]\n\ndf_test[\"price\"]=np.expm1(test_price)\nprint(\"Generatig File\")\ndf_test[[\"test_id\",\"price\"]].to_csv(\"submission.csv\",index=False)","f06fb0b7":"#------------------\u6a21\u578b\u6aa2\u8996---------------------------\nprint('\\n Making scatter plots of actual vs. predicted prices ...')\nx_true = np.expm1(Y_train)\nx_pred = np.expm1(xgb_pred_val_index)\ncm = plt.cm.get_cmap('RdYlBu')\n# Normalized prediction error clipped so the color-coding covers -75% to 75% range\nx_diff = np.clip(100 * ((x_pred - x_true) \/ x_true), -75, 75)\nplt.figure(1, figsize=(12, 10))\nplt.title('Actual vs. Predicted Prices - XGBoost')\nplt.scatter(x_true, x_pred, c=x_diff, s=10, cmap=cm)\nplt.colorbar()\nplt.plot([x_true.min() - 50, x_true.max() + 50],\n         [x_true.min() - 50, x_true.max() + 50],\n         'k--',lw=1)\nplt.xlabel('Prices')\nplt.ylabel('Predicted Prices')\nplt.xlim(-50, 2050)\nplt.ylim(-50, 2050)\nplt.tight_layout()\nplt.show()\n\n\nx_pred = np.expm1(lgb_pred_val_index)\n# Normalized prediction error clipped so the color-coding covers -75% to 75% range\nx_diff = np.clip(100 * ((x_pred - x_true) \/ x_true), -75, 75)\nplt.figure(1, figsize=(12, 10))\nplt.title('Actual vs. Predicted Prices - LightGBM')\nplt.scatter(x_true, x_pred, c=x_diff, s=10, cmap=cm)\nplt.colorbar()\nplt.plot([x_true.min() - 50, x_true.max() + 50],\n         [x_true.min() - 50, x_true.max() + 50],\n         'k--',lw=1)\nplt.xlabel('Prices')\nplt.ylabel('Predicted Prices')\nplt.xlim(-50, 2050)\nplt.ylim(-50, 2050)\nplt.tight_layout()\nplt.show()\n\n\nx_pred = np.expm1(ridge_pred_val_index)\n# Normalized prediction error clipped so the color-coding covers -75% to 75% range\nx_diff = np.clip(100 * ((x_pred - x_true) \/ x_true), -75, 75)\nplt.figure(1, figsize=(12, 10))\nplt.title('Actual vs. Predicted Prices - Ridge Regression')\nplt.scatter(x_true, x_pred, c=x_diff, s=10, cmap=cm)\nplt.colorbar()\nplt.plot([x_true.min() - 50, x_true.max() + 50],\n         [x_true.min() - 50, x_true.max() + 50],\n         'k--',lw=1)\nplt.xlabel('Prices')\nplt.ylabel('Predicted Prices')\nplt.xlim(-50, 2050)\nplt.ylim(-50, 2050)\nplt.tight_layout()\nplt.show()\n\n\nx_pred = np.expm1(train_price)\n# Normalized prediction error clipped so the color-coding covers -75% to 75% range\nx_diff = np.clip(100 * ((x_pred - x_true) \/ x_true), -75, 75)\nplt.figure(4, figsize=(12, 10))\nplt.title('Actual vs. Predicted Prices - Blend')\nplt.scatter(x_true, x_pred, c=x_diff, s=10, cmap=cm)\nplt.colorbar()\nplt.plot([x_true.min() - 50, x_true.max() + 50],\n         [x_true.min() - 50, x_true.max() + 50],\n         'k--',lw=1)\nplt.xlabel('Prices')\nplt.ylabel('Predicted Prices')\nplt.xlim(-50, 2050)\nplt.ylim(-50, 2050)\nplt.tight_layout()\nplt.show()","85d6f677":"**<font size=6>\u5f8c\u8a18<\/font>**\n\n\u5728\u7279\u5fb5\u8655\u7406\u65b9\u9762\uff0c\u6211\u9084\u8a66\u904e\u5c07\u5546\u54c1\u63cf\u8ff0\u505a**\u8a5e\u5e79\u63d0\u53d6(Stemming)**\uff0c\u66f4\u7cbe\u6e96\u7684\u63d0\u53d6\u63cf\u8ff0\u91cd\u9ede\uff0c\u4f46\u662f\u9019\u9ebc\u505a\u4f7f\u5f97\u5167\u5b58\u7121\u6cd5\u8ca0\u8377\u4e14\u6642\u9593\u904e\u9577\uff0c\u56e0\u6b64\u5c31\u653e\u68c4\u4e86\u9019\u500b\u505a\u6cd5\u3002\n\n\u9019\u6b21\u6bd4\u8cfd\u7684\u505a\u6cd5\u4ecd\u6709\u5f88\u591a\u53ef\u4fee\u6b63\u7684\u65b9\u5f0f\uff0c\u4f8b\u5982**\u7814\u7a76\u4e0d\u540c\u6f14\u7b97\u6cd5\u4e4b\u9593\u7684\u914d\u9069\u7a0b\u5ea6\u3001\u4ee5\u66f4\u8907\u96dc\u7684\u65b9\u5f0f\u6df7\u5408\u6a21\u578b**\uff0c\u627e\u51fa\u66f4\u597d\u7684\u6f14\u7b97\u6cd5\u7d44\u5408\uff0c\u4f46\u5c0d\u65bc\u6211\u76ee\u524d\u7684\u80fd\u529b\u9084\u6c92\u8fa6\u6cd5\u5b8c\u6210\uff0c\u6240\u4ee5\u5c31\u7576\u4f5c\u7d66\u5927\u5bb6\u512a\u5316\u7684\u53c3\u8003\uff0c**\u672c\u6b21\u89e3\u7b54\u6700\u5f8c\u5f97\u52300.44327\u5206\uff0c\u6392\u540d\u7d04\u70ba288\u540d**(\u6bd4\u8cfd\u7d50\u675f\u5f8c\u5b8c\u6210\uff0c\u7121\u660e\u78ba\u540d\u6b21)\uff0c\u7b2c\u4e00\u540d\u5206\u6578\u70ba0.37758\uff0c\u53c3\u52a0\u968a\u4f0d\u70ba2384\u7d44\u3002\n![](https:\/\/i.imgur.com\/s2qtX6w.jpg)\n\n<font size=1>\u6bd4\u8cfd\u7db2\u5740:https:\/\/www.kaggle.com\/c\/mercari-price-suggestion-challenge<\/font>","c558b284":"**<font size=9>Mercari Price Suggestion Challenge<\/font>**\nTING-LE,LIN    ,SCU FEAM\n\n**<font size=6>\u524d\u8a00<\/font>**\n\n\u4e0d\u77e5\u9053\u5927\u5bb6\u6709\u6c92\u6709\u66fe\u7d93\u5728\u62cd\u8ce3\u5e73\u53f0\u4e2d\u8ca9\u552e\u7269\u54c1\u7684\u7d93\u9a57\uff0c\u8ca9\u552e\u7269\u54c1\u6642\u6700\u56f0\u96e3\u7684\u6c7a\u7b56\u83ab\u904e\u65bc\u5546\u54c1\u552e\u50f9\uff0c**\u82e5\u8ce3\u5f97\u592a\u8cb4\uff0c\u6703\u4f7f\u5f97\u5546\u54c1\u4e4f\u4eba\u554f\u6d25\uff0c\u82e5\u8ce3\u592a\u4fbf\u5b9c\uff0c\u53c8\u6703\u4e0d\u5c0f\u5fc3\u548c\u8ca1\u5bcc\u64e6\u80a9\u800c\u904e**\u3002\u5927\u90e8\u5206\u7684\u4eba\u5728\u5b9a\u50f9\u6642\u6703\u901a\u5e38\u505a\u7684\u4e8b\u60c5\u662f\uff0c\u53c3\u8003\u540c\u54c1\u9805\u7684\u50f9\u683c\u3001\u5546\u54c1\u539f\u50f9\u3001\u65b0\u820a\u7a0b\u5ea6\u7b49\u7b49\uff0c**\u4f46\u9019\u4e9b\u6b65\u9a5f\u986f\u5f97\u76f8\u7576\u7e41\u7463\u6c92\u6709\u6548\u7387\uff0c\u4e5f\u6709\u53ef\u80fd\u82b1\u4e86\u5927\u91cf\u6642\u9593\u5230\u6700\u5f8c\u537b\u9084\u662f\u7121\u6cd5\u8a02\u51fa\u5408\u9069\u50f9\u683c\u3002**\n\n\u4eca\u5929\u6211\u5c31\u8981\u8ddf\u5927\u5bb6\u8ac7\u8ac7\u9019\u500b\u554f\u984c\u7684\u5be6\u73fe\uff0c\u9019\u662f\u7531Mercari\u5728Kaggle\u6240\u8209\u8fa6\u7684\u4e00\u5834\u6bd4\u8cfd\uff0c\u6bd4\u8cfd\u76ee\u7684\u5728\u65bc\uff0c**\u70ba\u62cd\u8ce3\u5e73\u53f0\u4e2d\u7684\u4f7f\u7528\u8005\u63d0\u4f9b\u53c3\u8003\u552e\u50f9**\uff0c\u5728\u6bd4\u8cfd\u4e2d\uff0c\u6211\u5011\u6703\u5f97\u5230\u7684\u8cc7\u8a0a\u6709**\u5546\u54c1\u540d\u7a31\u3001\u904b\u8cbb\u6b78\u5c6c\u3001\u5546\u54c1\u5206\u985e\u3001\u5546\u54c1\u54c1\u724c\u3001\u5546\u54c1\u72c0\u6cc1\u3001\u5546\u54c1\u63cf\u8ff0**\uff0c\u6211\u5011\u88ab\u8981\u6c42\u4ee5\u9019\u4e9b\u8cc7\u8a0a\u4f86\u9810\u6e2c\u5546\u54c1\u7684\u552e\u50f9\uff0c\u9019\u4e9b\u8cc7\u6599\u5168\u90fd\u662f\u7531**\u6587\u5b57**\u7d44\u6210\uff0c\u56e0\u6b64\u5728\u9810\u6e2c\u6642\u76f8\u5c0d\u8f03\u8907\u96dc\u3002\u8a55\u5206\u65b9\u5f0f\u4ee5**RMSLE**\u8a08\u7b97\uff0c\u8f03\u4f4e\u8005\u52dd\u3002\n        \n**<font size=6>\u89e3\u6c7a\u65b9\u6848<\/font>**\n\n**<font size=3>1. \u8cc7\u6599\u8f09\u5165\u53ca\u524d\u7f6e\u8655\u7406<\/font>**\n\n\u8a13\u7df4\u8cc7\u6599\u67091482353\u7b46\uff0c\u6e2c\u8a66\u8cc7\u6599\u67093460725\u7b46(stage 2)\u3002\u70ba\u4e86\u5f8c\u9762cross-validation\u8a55\u5206\u65b9\u4fbf\uff0c\u5148\u5c07\u8a13\u7df4\u8cc7\u6599\u7684\u552e\u50f9\u505alog(price+1)\u8655\u7406\u3002\n\n\u9019\u500b\u90e8\u5206\u9664\u4e86\u8655\u7406\u8cc7\u6599\u7f3a\u5931\u503c\u5916\uff0c\u7531\u65bc\u5546\u54c1\u54c1\u724c\u6578\u91cf\u904e\u591a\uff0c\u5728\u7a0b\u5f0f\u904b\u884c\u6642\u6703\u4f54\u64da\u904e\u591a\u5167\u5b58\uff0c\u5c0e\u81f4\u7a0b\u5f0f\u7121\u6cd5\u904b\u884c\uff0c**\u56e0\u6b64\u53ea\u4fdd\u7559\u524d2500\u5927**\uff0c\u800c2500\u500b\u5546\u54c1\u54c1\u724c\u5df2\u7d93\u5305\u542b\u4e8670%\u4ee5\u4e0a\u7684\u5546\u54c1\u6578\u91cf\u3002\n        \n        \n        ","8b17c8b0":"**<font size=3>5. \u6a21\u578b\u6aa2\u8996<\/font>**\n\n\u5f9e\u5716\u5f62\u4f86\u770b\uff0c**LightGBM\u8207Ridge Regression\u5c0d\u5546\u54c1\u50f9\u683c\u9ad8\u4f30\u7684\u60c5\u6cc1\u8f03\u591a\uff0c\u800cXGBoost\u5247\u662f\u9ad8\u4f30\u7684\u6bd4\u4f8b\u8f03\u9ad8**\uff0c\u7531\u6b64\u53ef\u4ee5\u89e3\u91cb\u6700\u5f8c\u7684\u6a21\u578b\u6bd4\u4f8b\uff0c\u7531**LightGBM\u8ddfXGBoost\u4f86\u505a\u4e92\u88dc**\uff0c\u800c\u6e96\u78ba\u7387\u8f03\u9ad8LightGBM\u5360\u6700\u591a\u6bd4\u4f8b\u3002\u6700\u7d42\u7684\u6a21\u578b\u4e0a\u5728\u4f4e\u4f30\u72c0\u6cc1\u6539\u5584\u8a31\u591a\u3002","ad3e6299":"\u6700\u7d42\u6a21\u578b\u7d04\u70ba\uff0c**XGBoost 30%\u3001LightGBM 60%\u3001 Ridge Regression 10%**\uff0c\u8207Cross-Validation\u4e2d\u7684\u9a57\u8b49\u8aa4\u5dee\u4e26\u6c92\u6709\u76f4\u63a5\u76f8\u95dc\uff0c\u4f46LightGBM\u6a21\u578b\u78ba\u5be6\u5360\u4e86\u6700\u5927\u7684\u6bd4\u4f8b\u3002","5030d3bf":"**<font size=3>3. \u4ea4\u53c9\u9a57\u8b49\u53ca\u9810\u6e2c<\/font>**\n\n\u5728\u6642\u9593\u8a31\u53ef\u4e0b\uff0c\u6211\u4f7f\u7528**KFold\u4f86\u505aCross-Validation**\uff0c\u5c07\u8a13\u7df4\u8cc7\u6599\u5206\u6210\u4e09\u500bFold\uff0c\u88fd\u4f5c\u51fa\u4e09\u500b\u6a21\u578b\uff0c**\u5c07\u4e09\u6b21Validation\u7684\u6578\u503c\u5132\u5b58\uff0c\u7d50\u5408\u6210\u5b8c\u6574\u9810\u6e2c\u8cc7\u6599**\uff0c\u4e26\u5c07\u5176RMSLE\u5206\u6578\u8a08\u7b97\u51fa\u4f86\uff0c\u4f5c\u70ba\u4e0b\u500b\u6b65\u9a5f\u7684\u6750\u6599\uff0c\u540c\u6642\u5206\u5225**\u4f7f\u7528\u4e09\u500b\u6a21\u578b\u5c0d\u6e2c\u8a66\u8cc7\u6599\u505a\u9810\u6e2c\u4e26\u53d6\u5e73\u5747**\u3002\u5728\u4e0a\u8ff0\u7684\u904e\u7a0b\u4e2d\uff0c\u6211\u5011\u6703\u4ee5\u4e09\u500b\u4e0d\u540c\u7684\u6f14\u7b97\u6cd5\uff0c**Ridge Regression\u3001LightGBM\u3001XGBoost**\u4f86\u57f7\u884c\uff0c\u81f3\u65bc\u539f\u56e0\u5247\u6703\u5728\u4e0b\u500b\u6b65\u9a5f\u505a\u89e3\u91cb\u3002\n\n![](https:\/\/i.imgur.com\/8svMOQl.jpg)","825461aa":"Cross-Validation\u4e2d\u53ef\u4ee5\u767c\u73fe\uff0cLightGBM\u7684\u6210\u7e3e\u662f\u6700\u512a\u79c0\u7684\uff0c\u5176\u6b21\u662fRidge Regression\uff0c\u6700\u5f8c\u624d\u662fXGBoost\u3002LightGBM\u5efa\u6a21\u4ecd\u6709\u66f4\u512a\u5316\u7684\u53ef\u80fd\uff0c\u4f46\u7531\u65bc\u6642\u9593\u95dc\u4fc2\u758a\u4ee3\u6b21\u6578\u8a2d\u70ba3000\u6b21\uff0cXGBoost\u5efa\u6a21\u904e\u7a0b\u96d6\u7136\u8a13\u7df4\u8aa4\u5dee\u6301\u7e8c\u4e0b\u964d\uff0c\u4f46\u9a57\u8b49\u8aa4\u5dee\u537b\u4e0d\u65b7\u4e0a\u5347\uff0c\u56e0\u6b64\u4e0d\u5f97\u5df2\u6368\u68c4\u66f4\u9ad8\u7684\u758a\u4ee3\u6b21\u6578\u3002","1754aa79":"**<font size=3>2. \u7279\u5fb5\u8655\u7406<\/font>**\n\n\u8a66\u60f3\u5728\u7db2\u8def\u5546\u8ca9\u552e\u7269\u54c1\u6642\uff0c\u586b\u5beb\u54ea\u500b\u5546\u54c1\u7279\u5fb5\u6b04\u4f4d\u6703\u8b93\u4f60\u4e0b\u6700\u591a\u8457\u58a8\u5462? \u6211\u60f3\u5927\u90e8\u5206\u7684\u4eba\u90fd\u6703\u56de\u7b54\u5546\u54c1\u63cf\u8ff0\u5427\uff0c\u672c\u6b21\u7279\u5fb5\u7684\u8655\u7406\u5c31\u662f\u4ee5\u9019\u500b\u60f3\u6cd5\u51fa\u767c\uff0c\u900f\u904e\u5c0d**\u5927\u90e8\u5206\u7684\u9805\u76ee\u7528CountVectorizer\u4f86\u505a\u7279\u5fb5\u63d0\u53d6**\uff0c**\u904b\u8cbb\u6b78\u5c6c\u53ca\u5546\u54c1\u72c0\u6cc1\u4f7f\u7528LabelBinarizer\u52a0\u8a3b\u6a19\u7c64**\uff0c\u6700\u5f8c\uff0c\u672c\u6b21\u6700\u91cd\u8981\u7684\u9805\u76ee\u8655\u7406\u65b9\u5f0f\u70ba\uff0c**TF-IDF\u5c0d\u5546\u54c1\u63cf\u8ff0\u7684\u52a0\u6b0a\u7279\u5fb5\u63d0\u53d6**(TfidfVectorizer)\uff0c\u5be6\u8e10\u5c0d\u9019\u6b21\u7279\u5fb5\u60f3\u6cd5\uff0c\u6700\u5f8c\u518d\u5c07\u7279\u5fb5\u7d50\u5408\u4e26\u8f49\u63db\u6210\u7a00\u758f\u77e9\u6b63\u3002","ab0386ce":"**<font size=3>4. \u6a21\u578b\u6df7\u5408\u8207\u6700\u7d42\u9810\u6e2c<\/font>**\n\n\u5b8c\u6210\u6b65\u9a5f\u4e09\u4e4b\u5f8c\uff0c\u6703\u6709Ridge\u3001XGBoost\u3001LightGBM\u5c0d\u8a13\u7df4\u8cc7\u6599\u505a\u51fa\u7684\u9810\u6e2c\uff0c\u7528**\u7dda\u6027\u7d44\u5408\u5c07\u4e09\u7d44\u8cc7\u6599\u7684\u9810\u6e2c\u505a\u6df7\u5408\uff0c\u7b97\u51fa\u5176\u932f\u8aa4\u7387\uff0c\u627e\u51fa\u6700\u4f73\u7684\u6a21\u578b\u6bd4\u4f8b\uff0c\u6700\u5f8c\u4f9d\u6bd4\u4f8b\u505a\u51fa\u6e2c\u8a66\u8cc7\u6599\u7684\u6700\u7d42\u7b54\u6848**\u3002\n\n![](https:\/\/i.imgur.com\/HzuS1XH.jpg)"}}