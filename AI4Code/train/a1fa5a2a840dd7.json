{"cell_type":{"9371ee77":"code","7e750dec":"code","8e4eec81":"code","f2dc3223":"code","6e34ff56":"code","6be558a8":"code","d3483577":"code","d5b47060":"code","f2531967":"code","24398772":"code","06df0a5a":"code","e95acf3c":"code","346ab4b4":"code","7aefad82":"code","14ce1649":"markdown","45eacb11":"markdown","1d5eaf2e":"markdown","d331d9fc":"markdown","9d9d6d4f":"markdown","7357c24a":"markdown","c45e79d3":"markdown","12ba5697":"markdown","134bd90c":"markdown","149a61a1":"markdown","4a033971":"markdown","6d7d3b58":"markdown","77c6ab40":"markdown","525b31f2":"markdown","d36ac0e1":"markdown","61adfcf8":"markdown","f59d2ec4":"markdown","ee5f6647":"markdown","cb388470":"markdown","a9669cfc":"markdown","8e341a37":"markdown","531008b3":"markdown","162db118":"markdown","f18fe0f6":"markdown","96c45cfd":"markdown","c044b3b6":"markdown","0862dfe0":"markdown"},"source":{"9371ee77":"import pandas as pd\nimport pandas_profiling\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import svm\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score","7e750dec":"# setting up dataframes\ndata = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-02\/train.csv')\nval = pd.read_csv('..\/input\/cap-4611-2021-fall-assignment-02\/eval.csv')\n\nprint (data.esrb_rating.unique())","8e4eec81":"data.head()","f2dc3223":"print(data.isnull().sum())\n\nprint('\\n')\n\nprint(data.isna().sum())","6e34ff56":"pandas_profiling.ProfileReport(data)","6be558a8":"X_train, X_test, y_train, y_test = train_test_split(data.drop(['id', 'title','esrb_rating'], axis=1),data['esrb_rating'].astype('category').cat.codes, test_size=0.2, random_state=0)","d3483577":"logistic = LogisticRegression()\npd.DataFrame(cross_val_score(logistic, X_train, y_train, cv=10),columns = [\"Accuracy\"]).describe()","d5b47060":"svmachine = svm.SVC()\npd.DataFrame(cross_val_score(svmachine, X_train, y_train, cv=10),columns = [\"Accuracy\"]).describe()","f2531967":"decisiontree = DecisionTreeClassifier()\npd.DataFrame(cross_val_score(decisiontree, X_train, y_train, cv=10),columns = [\"Accuracy\"]).describe()","24398772":"randomforest = RandomForestClassifier(n_estimators=1, random_state=69)\npd.DataFrame(cross_val_score(randomforest, X_train, y_train, cv=10),columns = [\"Accuracy\"]).describe()","06df0a5a":"kneighbors = KNeighborsClassifier()\npd.DataFrame(cross_val_score(kneighbors, X_train, y_train, cv=10),columns = [\"Accuracy\"]).describe()","e95acf3c":"dct = {0:'E', 1:'ET', 2:'M', 3:'T'}\nprint('Accuracy Score:', metrics.accuracy_score(y_pred, y_test))","346ab4b4":"randomforest.fit(X_train, y_train)\n\nanswers = randomforest.predict(val.drop(['id'], axis=1))\nanswers = np.array([dct[val] for val in answers])\nanswers","7aefad82":"submission = pd.DataFrame({'id':val['id'], 'esrb_rating':answers})\ndisplay(submission)\nsubmission.to_csv('.\/submission.csv', index = False)","14ce1649":"### Decision Tree Classifier with describe() in bottom cell.","45eacb11":"*Along with loading in the data, I sought the insight needed to find out what I'm looking for. In other words, what ratings exist and how I should be sorting out the games. So, I discovered that there are 4 ratings: E, ET, T, and M. My next step is to look at what feature combination results in which rating.*","1d5eaf2e":"### Random Forest Classifier with describe() in bottom cell.","d331d9fc":"# Exploratory Data Analysis\n\n*To better understand the dataset, I decided to go with Pandas Profiling. Pandas gave me insight on the dataset, better understanding the correlation of features with the ESRB Rating. I noticed from the 52 warnings that arose, that the features that included violence, blood, gore, and strong language had a heavy influence on ESRB Rating. In other words: they were strongly correlated. On the other hand, nudety, drugs and alcohol has lower correlation with ESRB rating. I also came to the conclusion that outliers in this dataset do not exist, since the dataset is generated for a rating score so all the games must fall into a rating category. So, no actions were taken in regards to outlier handling.*","9d9d6d4f":"# Models","7357c24a":"**5. [2 point] You must build and train a Logistic Regression model on the training data and evaluate its performance on a set of validation data**\n* **You must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)**","c45e79d3":"**6. [2 point] You must build and train an Support Vector Machine on the training data and evaluate its performance on a set of validation data**\n* **You must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)**","12ba5697":"*Before I dive into creating any additional features, I checked for missing values and found out that there isn't any, so no action was taken regarding missing values.*","134bd90c":"*Below is the training dataframe displaying the long list of features that includes alcohol_reference, animated_blood, etc. These features contain binary values that denote whether or not they exist int the came. The feature list also includes a console column that denotes whether or not the same is PS exclusive or not (Xbox & PS).*","149a61a1":"# Imports\n","4a033971":"**9. [2 point] You must build and train an K Nearest Neighors on the training data and evaluate its performance on a set of validation data**\n* **You must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)**","6d7d3b58":"# Submission File","77c6ab40":"**1. [2 point] You must load the data from the provided CSV files.**","525b31f2":"*Using train_test_split, the data was split. Unnecessary columns were dropped.*","d36ac0e1":"# Loading Data","61adfcf8":"**10. [2 points] You must select the best model that you have generated and use that model to predict the target vector for the test data.**\n* **You must save this this target vector to your submission.csv file and print the contents of your submission.csv file within the notebook**\n","f59d2ec4":"# Preparing Data\n\n","ee5f6647":"### SVM Classifier with describe() in bottom cell.","cb388470":"*Below is the code that determines the accuracy score.*","a9669cfc":"### K Neighbors Classifier with describe() in bottom cell.","8e341a37":"# Assignment 2: ESRB Game Rating\n\n# Data Description\n\n* This data contains the name for ***1895 games*** with ***34 of ESRB rating content with the name and console*** as features for each game.\n\n* A single data point is represented as a binary value ***0-1*** for ***Console*** and a ***binary vector*** for the ***features of ESRB content***.\n \n* RP, EC, A, rating is not provided in the current version of the data, it might be included in the next updates","531008b3":"**2. [2 point] You must check for missing values within the training data and, if required, describe and implement an approach to handle those missing values.**","162db118":"**4. [2 point] You must describe any data transformations or feature engineering that are required and provide an explanation as to \"why\" each is being done.**","f18fe0f6":"# Missing Values","96c45cfd":"**7. [2 point] You must build and train an Decision Tree model on the training data and evaluate its performance on a set of validation data**\n* **You must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)**","c044b3b6":"**3. [2 point] You must check for outliers within the training data and, if required, describe and implement an approach to handle those outliers.**","0862dfe0":"**8. [2 point] You must build and train an Random Forest model on the training data and evaluate its performance on a set of validation data**\n* **You must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)**"}}