{"cell_type":{"1a83dab9":"code","1a9fe286":"code","377512ae":"code","3edb84b2":"code","477f411c":"code","26e36805":"code","08160035":"code","55db6143":"code","fc44f4fe":"code","d5b74124":"code","e4d15f3c":"code","f12497d3":"code","72af13f5":"code","e6e22ea2":"code","c79114f5":"code","e07c4f30":"code","39e4d70f":"code","654a9407":"code","e5faf2cf":"code","23cd6032":"code","414d99b4":"code","e159b973":"code","2c662716":"code","cd0040e7":"code","a98037f7":"code","2eeb6fc4":"code","ec40644e":"code","65db9c43":"code","3ef00b0c":"code","f4d86c7f":"code","c8036dd6":"code","fbd56b11":"code","13816961":"code","aa8cbcbf":"code","bb3965a0":"code","b046fadd":"code","02648ce4":"code","880b25e1":"code","e94ac4af":"code","6f09b98a":"code","c0a46f5e":"code","4eed4048":"code","d719db90":"code","7f94b763":"code","497f7dfa":"code","5c391bac":"code","cfc272a5":"code","498667e0":"code","b21179b7":"code","1e1145fd":"code","a25f510b":"code","be7fd5a5":"code","bca225cb":"code","ebc158a6":"code","f14415c0":"code","6e3564dd":"code","aa6e780c":"code","9f21422f":"code","f1b33e7d":"code","0176aaaa":"code","1e630609":"code","f48b0fe8":"code","c3cd6439":"code","51a0ab8e":"code","bbdd3f7d":"code","9a91bbc9":"code","0e0c0f67":"code","c87bf4f2":"code","656a2683":"code","5d61eca1":"code","d0929fe0":"code","2c057bd0":"code","ec5d887a":"code","83d9bb54":"code","354d8e47":"code","1e5de9a8":"code","8850cdda":"code","6bf71264":"code","4be090e0":"code","49b74e3b":"code","1594186a":"code","943e4821":"code","b3aef338":"code","8dee8fd5":"code","01736b08":"code","172839c9":"code","f179948e":"code","eb676c7a":"code","163d88d2":"code","ebbb05fd":"code","764d9118":"code","2fcde89b":"code","9ff6ac3a":"code","236786c5":"markdown","915f9e65":"markdown","f3954358":"markdown","e1fe74cf":"markdown","ba1579cf":"markdown","2ba06aa3":"markdown","be304b5c":"markdown"},"source":{"1a83dab9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a9fe286":"#importing other libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","377512ae":"#loading train data\ndata_train=pd.read_csv('..\/input\/train-data\/train_SJC.csv')\ndata_test=pd.read_csv('..\/input\/machine-learning-24-hrs-hackathon\/Test_SJC.csv')","3edb84b2":"data_train.info()","477f411c":"data_train.head()","26e36805":"data_train.shape","08160035":"data_train.columns","55db6143":"#Finding the missing values \ndata_train.isnull().sum()","fc44f4fe":"#Missing value imputation using statistical methods","d5b74124":"data_train['WeeklyWages'].fillna(data_train['WeeklyWages'].mean(),inplace=True)","e4d15f3c":"data_train['HoursWorkedPerWeek'].fillna(data_train['HoursWorkedPerWeek'].mean(),inplace=True)","f12497d3":"#Here we can assign 'unknown ' to the missing values\ndata_train['MaritalStatus'].fillna(\"U\",inplace=True)","72af13f5":"data_train['MaritalStatus'].value_counts()","e6e22ea2":"data_train.isnull().sum()","c79114f5":"#Converting dates to ages","e07c4f30":"data_train['DateTOA']= pd.to_datetime(data_train['DateTimeOfAccident'])\ndata_train['DateTOA']= pd.to_datetime(data_train.DateTOA).dt.tz_localize(None)\ndata_train['Age_Accid']= (pd.to_datetime('now')-data_train['DateTOA']).astype('<m8[Y]')","39e4d70f":"data_train['DateREP']= pd.to_datetime(data_train['DateReported'])\ndata_train['DateREP']= pd.to_datetime(data_train.DateTOA).dt.tz_localize(None)\ndata_train['Age_Rep']= (pd.to_datetime('now')-data_train['DateREP']).astype('<m8[Y]')","654a9407":"data_train.info()","e5faf2cf":"# Dropping unnecessary columns\ndata_train.drop(['ClaimNumber','DateTimeOfAccident','DateReported','ClaimDescription','DateTOA','DateREP'], axis='columns', inplace=True)","23cd6032":"#Handling duplicate records\nduplicated =data_train.duplicated()\nduplicated.sum()","414d99b4":"data_train.shape","e159b973":"data_train['Gender'].value_counts()","2c662716":"#Changing the only one 'U' value to the mode value of 'Gender'\ndata_train['Gender'] = data_train['Gender'].replace(['U'],'M')","cd0040e7":"data_train['Gender'].value_counts()","a98037f7":"#Processing Test Data\ndata_test.shape","2eeb6fc4":"#Finding the missing values \ndata_test.isnull().sum()","ec40644e":"#Missing value imputation\ndata_test['MaritalStatus'].fillna(\"U\",inplace=True)\ndata_test['MaritalStatus'].value_counts()","65db9c43":"data_test.info()","3ef00b0c":"#Converting dates to ages\ndata_test['DateTOA']= pd.to_datetime(data_test['DateTimeOfAccident'])\ndata_test['DateTOA']= pd.to_datetime(data_test.DateTOA).dt.tz_localize(None)\ndata_test['Age_Accid']= (pd.to_datetime('now')-data_test['DateTOA']).astype('<m8[Y]')","f4d86c7f":"data_test['DateREP']= pd.to_datetime(data_test['DateReported'])\ndata_test['DateREP']= pd.to_datetime(data_test.DateTOA).dt.tz_localize(None)\ndata_test['Age_Rep']= (pd.to_datetime('now')-data_test['DateREP']).astype('<m8[Y]')","c8036dd6":"# Dropping unnecessary columns\ndata_test.drop(['ClaimNumber','DateTimeOfAccident','DateReported','ClaimDescription','DateTOA','DateREP','Age_Rep'], axis='columns', inplace=True)","fbd56b11":"data_test['Gender'].value_counts()","13816961":"#Changing the only one 'U' value to the mode value of 'Gender'\ndata_test['Gender'] = data_test['Gender'].replace(['U'],'M')","aa8cbcbf":"#Categorical and Numerical Features\ncat=data_test.select_dtypes(exclude=[float,int])\nnum=data_test.select_dtypes(include=[float,int])","bb3965a0":"cat.describe()","b046fadd":"#Encoding of categorical variables\nimport sklearn.preprocessing as pre\nle=pre.LabelEncoder()\nfor x in cat:\n    data_test[x]=le.fit_transform(data_test[x])","02648ce4":"#Numerical features\ndata_test['Age'].describe()","880b25e1":"d2=data_test","e94ac4af":"data_train.describe()","6f09b98a":"print(data_train[\"MaritalStatus\"].value_counts())\ndata_train[\"MaritalStatus\"].value_counts().plot.bar(color='pink')\nplt.title(\"Workers'Marital status\")","c0a46f5e":"print(data_train[\"PartTimeFullTime\"].value_counts())\ndata_train[\"PartTimeFullTime\"].value_counts().plot.bar(color='g')\nplt.title(\"Work Type Status\")","4eed4048":"data_train['Age'].value_counts().plot.bar()","d719db90":"data_train['Age_Accid'].value_counts().plot.bar()","7f94b763":"data_train['Age_Rep'].value_counts().plot.bar()\n#We can conclude, both 'Year of accident' and 'year of reporting them' are almost the same","497f7dfa":"data=data_train ","5c391bac":"data_train.columns","cfc272a5":"data.plot.box(figsize=(20,2))","498667e0":"plt.scatter('Age_Accid','UltimateIncurredClaimCost',data=data)","b21179b7":"sns.pairplot(data,x_vars='InitialIncurredCalimsCost', y_vars='UltimateIncurredClaimCost', kind='scatter')","1e1145fd":"data_train['Gender'].value_counts().plot.bar(color='k')","a25f510b":"sns.pairplot(data,hue='Gender',x_vars='InitialIncurredCalimsCost', y_vars='UltimateIncurredClaimCost', kind='reg')\n#There is difference in the ultimate claim cost ,with gender ","be7fd5a5":"sns.catplot(data=data,x='UltimateIncurredClaimCost',col='Gender',kind='violin')\n#Females are more likely to get high claim cost","bca225cb":"sns.pairplot(data,x_vars='Age', y_vars='UltimateIncurredClaimCost', kind='scatter')","ebc158a6":"sns.catplot(data=data,x='UltimateIncurredClaimCost', col='PartTimeFullTime',kind='box')\n#full time workers are getting more advantages than part timers","f14415c0":"sns.catplot(data=data,x='UltimateIncurredClaimCost', col='MaritalStatus',kind='box')","6e3564dd":"plt.scatter('WeeklyWages','UltimateIncurredClaimCost',data=data)","aa6e780c":"sns.catplot(data=data,x='WeeklyWages',col='Gender',kind='violin')","9f21422f":"plt.scatter('HoursWorkedPerWeek','UltimateIncurredClaimCost',data=data)","f1b33e7d":"sns.catplot(data=data,x='UltimateIncurredClaimCost', col='DaysWorkedPerWeek',kind='box')","0176aaaa":"sns.catplot(data=data,x='UltimateIncurredClaimCost',col='DependentsOther',kind='violin')","1e630609":"plt.scatter('InitialIncurredCalimsCost','UltimateIncurredClaimCost',data=data)","f48b0fe8":"sns.pairplot(data,x_vars='DependentChildren', y_vars='UltimateIncurredClaimCost', kind='hist')","c3cd6439":"sns.pairplot(data,x_vars='Age_Accid', y_vars='UltimateIncurredClaimCost', kind='scatter')","51a0ab8e":"sns.countplot(data=data,x='Gender',hue='MaritalStatus')","bbdd3f7d":"corr = data.drop(columns=['UltimateIncurredClaimCost']).corr()\nsns.heatmap(corr)\n#clearly Age_Accid and Age_Rep are highly correlated.So we can drop \"Age_Rep\" ","9a91bbc9":"data_train.drop(['Age_Rep'], axis='columns', inplace=True)","0e0c0f67":"#Categorical and Numerical Features","c87bf4f2":"cat_data=data_train.select_dtypes(exclude=[float,int])","656a2683":"num_data=data_train.select_dtypes(include=[float, int])","5d61eca1":"cat_data.describe()","d0929fe0":"cat_data.tail()","2c057bd0":"#Encoding of categorical variables\nimport sklearn.preprocessing as pre\nle=pre.LabelEncoder()\nfor x in cat_data:\n    data_train[x]=le.fit_transform(data_train[x])","ec5d887a":"data_train.info()","83d9bb54":"data_train['Gender'].value_counts()","354d8e47":"#Numerical features","1e5de9a8":"data_train.dtypes","8850cdda":"#checking for outliers\nsns.boxplot(data=data_train,x='Age',)","6bf71264":"data_train.columns","4be090e0":"d1=data_train","49b74e3b":"data_train.nunique()","1594186a":"import sklearn.model_selection as ms","943e4821":"#Minmax scaling\nX_scale=pre.minmax_scale(data_train.drop('UltimateIncurredClaimCost',axis=1))","b3aef338":"Y=data_train['UltimateIncurredClaimCost']","8dee8fd5":"Y_scale=pre.minmax_scale(data_train['UltimateIncurredClaimCost'])","01736b08":"x_train,x_test,y_train,y_test=ms.train_test_split(X_scale,Y,test_size=0.3,random_state=123)\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","172839c9":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","f179948e":"regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nregressor.fit(x_train, y_train)\n\n# Predicting new result\ny_pred = regressor.predict(x_test)\nregressor.score(x_train,y_train)","eb676c7a":"mse=mean_squared_error(y_test,y_pred)\nrmse=np.sqrt(mse)\nrmse","163d88d2":"#For test data\ndata_scale1=pre.minmax_scale(data_test)\ny_pred = regressor.predict(data_scale1)\ny_pred","ebbb05fd":"#saving the array as a csv file\ncsv = pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")\ncsv[\"UltimateIncurredClaimCost\"]=y_pred\ncsv.to_csv(\"Sample Submission.csv\", index = False)","764d9118":"#Checking accuracy with another model\nimport sklearn.linear_model as lm\nglm=lm.LinearRegression()\nglm.fit(x_train,y_train)\nglm.score(x_test,y_test)","2fcde89b":"glm.score(x_train,y_train)","9ff6ac3a":"l=glm.predict(data_scale1)\ncsv = pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")\ncsv[\"UltimateIncurredClaimCost\"]=l\ncsv.to_csv(\"Sample Submission12.csv\", index = False)","236786c5":"I selected Random forest regressor to do the work as it could give more accurate result than other regression algorithms.\nIt is better than others, because being a bagging model, it will show less overfitting.I can take a number of trees that could vote for the right value of the dependent variable.Thus giving a more accurate prediction.\nIn the above code ,I have also used generalized linear model to show its lower accuracy.","915f9e65":"****DATA PROCESSING****","f3954358":"**EDA**","e1fe74cf":"****Reason to select the algorithm and how it's better than other models****","ba1579cf":"**DATA LOADING**","2ba06aa3":"**Feature Engineering**","be304b5c":"****ML MODEL****"}}