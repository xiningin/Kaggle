{"cell_type":{"252b0cf0":"code","2628f79a":"code","a66fcb3b":"code","06cae82f":"code","64e7baef":"code","bb25c2dd":"code","853ec53a":"code","e2654dd7":"code","182e530f":"code","c36bf37b":"code","1350be80":"code","c08a5e44":"code","96264b81":"code","e99a4d87":"code","47819e40":"code","98800400":"code","5e14f241":"code","2a97675e":"code","bea011d4":"code","2f758312":"code","c6b522db":"code","1446dc1c":"code","75c7dd87":"code","5a80e982":"code","c7747d7b":"code","e6cc7dd3":"code","d7459b7f":"code","171cadfe":"code","120b83ef":"markdown","57db1a36":"markdown","cc1ca071":"markdown","05eac054":"markdown","2d3ed9d2":"markdown","04a0145c":"markdown","59e01db2":"markdown","1a718d21":"markdown","ea3fbc48":"markdown","d7189684":"markdown"},"source":{"252b0cf0":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom google.cloud import bigquery\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n\n\nprint(f'numpy = {np.__version__}')\nprint(f'pandas = {pd.__version__}')\nprint(f'tensorflow = {tf.__version__}')\nprint(f'bigquery = {bigquery.__version__}')","2628f79a":"X_START = '20161001'\nX_END = '20161231'\nY_START = '20170101'\nY_END = '20170131'\nCLIENT = bigquery.Client()","a66fcb3b":"def evaluate_pred(y_train, y_pred_train, y_test, y_pred_test):\n    fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_train)\n    fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_test)\n    plt.figure()\n    lw = 2\n    plt.plot(fpr_train, tpr_train, color='darkorange', lw=lw, label='Train ROC (area = %0.2f)' % roc_auc_score(y_train, y_pred_train))\n    plt.plot(fpr_test, tpr_test, color='lightblue', lw=lw, label='Test ROC (area = %0.2f)' % roc_auc_score(y_test, y_pred_test))\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()    ","06cae82f":"query = f''' \n    select distinct a.*\n    , case when substring(a.fullVisitorId, length(a.fullVisitorId), length(a.fullVisitorId)) in ('0', '1', '2') then 1 else 0 end as testset\n    , case when b.fullVisitorId is not null then 1 else 0 end as revisited\n    from (\n        select distinct fullVisitorId\n        , count(1) as n_events\n        , count(distinct date) as n_days\n        , count(1) \/ count(distinct date) as avg_events_per_day\n        , sum(totals.bounces) as bounces\n        , sum(totals.bounces) \/ count(distinct date) as avg_bounces_per_day\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n        where _TABLE_SUFFIX between '{X_START}' and '{X_END}'\n        group by fullVisitorId\n    ) a\n    left join ( \n        select distinct fullVisitorId\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n        where _TABLE_SUFFIX between '{Y_START}' and '{Y_END}'\n    ) b on a.fullVisitorId = b.fullVisitorId\n    order by fullVisitorId\n'''\ndata = CLIENT.query(query).result().to_dataframe().set_index('fullVisitorId')\ndata.head()","64e7baef":"X_train = data[data['testset']==0].drop(columns=['revisited', 'testset']).fillna(0.0)\ny_train = data[data['testset']==0]['revisited']\nX_test = data[data['testset']==1].drop(columns=['revisited', 'testset']).fillna(0.0)\ny_test = data[data['testset']==1]['revisited']\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\nprint(f'revisits in train = {sum(y_train)}, test = {sum(y_test)}')\n\nmodel1 = GradientBoostingClassifier()\nmodel1.fit(X_train, y_train)\nevaluate_pred(y_train, model1.predict_proba(X_train)[:, 1], y_test, model1.predict_proba(X_test)[:, 1])","bb25c2dd":"pd.DataFrame({'feature': X_train.columns, 'impt': model1.feature_importances_}).set_index('feature').sort_values('impt', ascending=False)","853ec53a":"query = f''' \n    select distinct a.*\n    , case when substring(a.fullVisitorId, length(a.fullVisitorId), length(a.fullVisitorId)) in ('0', '1', '2') then 1 else 0 end as testset\n    , case when b.fullVisitorId is not null then 1 else 0 end as revisited\n    from (\n        select distinct fullVisitorId\n        , count(1) as n_events\n        , string_agg(h.page.pagePath, \" \" order by visitStartTime desc) as pagePathSeq\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*`  , unnest(hits) h\n        where _TABLE_SUFFIX between '{X_START}' and '{X_END}'\n        group by fullVisitorId\n    ) a\n    left join ( \n        select distinct fullVisitorId\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n        where _TABLE_SUFFIX between '{Y_START}' and '{Y_END}'\n    ) b on a.fullVisitorId = b.fullVisitorId\n    order by fullVisitorId\n'''\ndata = CLIENT.query(query).result().to_dataframe().set_index('fullVisitorId')\ndata.head()","e2654dd7":"X_train = data[data['testset']==0].drop(columns=['revisited', 'testset']).fillna(0.0)\ny_train = data[data['testset']==0]['revisited']\nX_test = data[data['testset']==1].drop(columns=['revisited', 'testset']).fillna(0.0)\ny_test = data[data['testset']==1]['revisited']\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","182e530f":"# limit to 100 \nmax_events = X_train.n_events.max()\nn_events = 10\nprint(f'max_events = {max_events}, n_events = {n_events}')","c36bf37b":"# https:\/\/www.tensorflow.org\/guide\/keras\/rnn\n\npage_tokenizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_sequence_length=n_events)\npage_tokenizer.adapt(np.array(X_train['pagePathSeq']))\npage_vocab = page_tokenizer.get_vocabulary()\nprint(f'{len(page_vocab)} tokens parsed: {page_vocab[:10]}')\n\nmodel2 = tf.keras.Sequential(name = 'approach_2', layers = [\n    tf.keras.Input(shape=(1,), dtype=tf.string),\n    page_tokenizer,\n    tf.keras.layers.Embedding(input_dim=len(page_vocab), output_dim=10),\n    tf.keras.layers.GRU(units=n_events, return_sequences=False),\n    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n])\nmodel2.compile(optimizer='rmsprop', loss='binary_crossentropy')\nmodel2.summary()\ntf.keras.utils.plot_model(model2, show_shapes=True)","1350be80":"model2.fit(X_train[\"pagePathSeq\"], y_train, epochs=10, batch_size=256)","c08a5e44":"y_pred_train = model2.predict(X_train[\"pagePathSeq\"])\ny_pred_test = model2.predict(X_test[\"pagePathSeq\"])\nevaluate_pred(y_train, y_pred_train, y_test, y_pred_test)","96264b81":"query = f''' \n    with transformed as (\n        select distinct fullVisitorId\n        -- , date_diff(parse_date(\"%Y%m%d\", '{X_END}'), parse_date(\"%Y%m%d\", date), day) as days_since\n        , visitStartTime\n        -- , device.browser\n        -- , device.operatingSystem\n        -- , device.isMobile\n        -- , geoNetwork.continent\n        -- , geoNetwork.subContinent\n        , geoNetwork.country\n        -- , case when totals.bounces is null then 0 else totals.bounces end as bounces\n        , trafficSource.source as source\n        , h.page.pagePath as pagePath\n        -- , h.page.hostname as hostname\n        -- , h.hitNumber\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*`  , unnest(hits) h\n        where _TABLE_SUFFIX between '{X_START}' and '{X_END}'\n    )\n    select distinct a.*\n    , case when substring(a.fullVisitorId, length(a.fullVisitorId), length(a.fullVisitorId)) in ('0', '1', '2') then 1 else 0 end as testset\n    , case when b.fullVisitorId is not null then 1 else 0 end as revisited\n    from (\n        select distinct fullVisitorId\n        , count(1) as n_events\n        , string_agg(pagePath, \" \" order by visitStartTime desc) as pagePathSeq\n        , string_agg(source, \" \" order by visitStartTime desc) as sourceSeq\n        , string_agg(country, \" \" order by visitStartTime desc) as countrySeq\n        from transformed\n        group by fullVisitorId\n    ) a\n    left join ( \n        select distinct fullVisitorId\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n        where _TABLE_SUFFIX between '{Y_START}' and '{Y_END}'\n    ) b on a.fullVisitorId = b.fullVisitorId\n    order by fullVisitorId\n'''\ndata = CLIENT.query(query).result().to_dataframe().set_index('fullVisitorId')\ndata.head()","e99a4d87":"X_train = data[data['testset']==0].drop(columns=['revisited', 'testset']).fillna(0.0)\ny_train = data[data['testset']==0]['revisited']\nX_test = data[data['testset']==1].drop(columns=['revisited', 'testset']).fillna(0.0)\ny_test = data[data['testset']==1]['revisited']\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","47819e40":"max_events = X_train.n_events.max()\nn_events = 10\nprint(f'max_events = {max_events}, n_events = {n_events}')","98800400":"# https:\/\/towardsdatascience.com\/building-a-one-hot-encoding-layer-with-tensorflow-f907d686bf39\n\nsource_tokenizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_sequence_length=n_events, max_tokens=10)\nsource_tokenizer.adapt(np.array(X_train[\"sourceSeq\"]))\nsource_vocab = source_tokenizer.get_vocabulary()\nsource_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\nsource_feat = tf.keras.layers.Embedding(input_dim=len(source_vocab), output_dim=10)(source_tokenizer(source_input))\nprint(f'{len(source_vocab)} tokens parsed: {source_vocab[:10]}')\n\npage_tokenizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_sequence_length=n_events, max_tokens=10)\npage_tokenizer.adapt(np.array(X_train[\"pagePathSeq\"]))\npage_vocab = page_tokenizer.get_vocabulary()\npage_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\npage_feat = tf.keras.layers.Embedding(input_dim=len(source_vocab), output_dim=10)(page_tokenizer(page_input))\nprint(f'{len(page_vocab)} tokens parsed: {page_vocab[:10]}')\n\ncountry_tokenizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_sequence_length=n_events, max_tokens=10)\ncountry_tokenizer.adapt(np.array(X_train[\"countrySeq\"]))\ncountry_vocab = country_tokenizer.get_vocabulary()\ncountry_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\ncountry_feat = tf.keras.layers.Embedding(input_dim=len(source_vocab), output_dim=10)(country_tokenizer(country_input))\nprint(f'{len(country_vocab)} tokens parsed: {country_vocab[:10]}')\n\nall_feat = tf.keras.layers.Concatenate()([source_feat, page_feat, country_feat])\ngru_layer = tf.keras.layers.GRU(units=n_events, return_sequences=False)(all_feat)\ndense_layer = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(gru_layer)\n\nmodel3 = tf.keras.Model(name='approach_3', inputs=[source_input, page_input, country_input], outputs=[dense_layer])\nmodel3.compile(optimizer='rmsprop',loss='binary_crossentropy')\nmodel3.summary()\ntf.keras.utils.plot_model(model3, show_shapes=True)","5e14f241":"model3.fit([X_train[\"sourceSeq\"], X_train[\"pagePathSeq\"], X_train[\"countrySeq\"]], y_train, epochs=10, batch_size=256)","2a97675e":"y_pred_train = model3.predict([X_train[\"sourceSeq\"], X_train[\"pagePathSeq\"], X_train[\"countrySeq\"]])\ny_pred_test = model3.predict([X_test[\"sourceSeq\"], X_test[\"pagePathSeq\"], X_test[\"countrySeq\"]])\nevaluate_pred(y_train, y_pred_train, y_test, y_pred_test)","bea011d4":"query = '''\n    SELECT distinct column_name, data_type\n    FROM `bigquery-public-data.google_analytics_sample.INFORMATION_SCHEMA.COLUMNS`\n    WHERE table_name like 'ga_sessions_%'\n    ORDER BY 1\n'''\ndata = CLIENT.query(query).result().to_dataframe()\ndata","2f758312":"query = f''' select fullVisitorId, d.* from `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest(customDimensions) d where _TABLE_SUFFIX between '20170701' and '20170701' LIMIT 5 '''\ndata = CLIENT.query(query).result().to_dataframe()\ndata","c6b522db":"query = f''' select fullVisitorId, device.* from `bigquery-public-data.google_analytics_sample.ga_sessions_*` where _TABLE_SUFFIX between '20170701' and '20170701' LIMIT 5 '''\ndata = CLIENT.query(query).result().to_dataframe()\ndata","1446dc1c":"query = f''' select fullVisitorId, geoNetwork.* from `bigquery-public-data.google_analytics_sample.ga_sessions_*` where _TABLE_SUFFIX between '20170701' and '20170701' LIMIT 5 '''\ndata = CLIENT.query(query).result().to_dataframe()\ndata","75c7dd87":"query = f'''\n   select fullVisitorId, h.*\n   from `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest(hits) h\n   where _TABLE_SUFFIX between '20170701' and '20170701'\n   LIMIT 5\n'''\ndata = CLIENT.query(query).result().to_dataframe()\ndata.shape","5a80e982":"data.iloc[:, :17]","c7747d7b":"data.iloc[:, 17:]","e6cc7dd3":"query = f''' select fullVisitorId, totals.* from `bigquery-public-data.google_analytics_sample.ga_sessions_*` where _TABLE_SUFFIX between '20170701' and '20170701' LIMIT 5 '''\ndata = CLIENT.query(query).result().to_dataframe()\ndata","d7459b7f":"query = f''' select fullVisitorId, trafficSource.* from `bigquery-public-data.google_analytics_sample.ga_sessions_*` where _TABLE_SUFFIX between '20170701' and '20170701' LIMIT 5 '''\ndata = CLIENT.query(query).result().to_dataframe()\ndata","171cadfe":"query = f''' \n    select distinct visits, count(1) as records \n    from (\n        select distinct fullVisitorId, count(distinct visitStartTime) as visits\n        from `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n        where _TABLE_SUFFIX between '{X_START}' and '{X_END}'\n        group by fullVisitorId\n    )\n    group by visits\n    order by visits \n'''\ndf = CLIENT.query(query).result().to_dataframe().set_index('visits')\ndf.plot()\ndf","120b83ef":"# Appendix (Data Exploration)","57db1a36":"# Approach #1: Standard ML Approach","cc1ca071":"# Import Packages","05eac054":"# Approach #3: Incorporating Event Properties","2d3ed9d2":"# Purpose\n\n- Want to compare standard ML approach using sklearn vs deep learning approach using tensorflow\n- Will be using google's public website traffic dataset (https:\/\/www.kaggle.com\/bigquery\/google-analytics-sample)\n- Propose to predict whether a visitor is likely to revisit the website in future\n- Propose to use AUC to determine which approach is better since this is a standard binary classification problem","04a0145c":"# Approach #2: Treating Events Like Text Tokens","59e01db2":"# TL;DR\n- Approach #2 (AUC=0.78) performs slightly better than approach #1 (AUC=0.77), suggesting that basic sequence model may not outperform traditional ML approach by much\n- Approach #3 (AUC=0.85) performs much better than approach #2 (AUC=0.78), suggesting that incorporating more information certainly improves performance\n- Note that this comparison is not perfect as\n    - Limited time was spent on feature engineering for approach #1\n    - Deep learning models were only trained for 10 epoches to prevent overfitting (techniques to prevent overfitting should be employed)\n    - Hyperparameters were not optimized","1a718d21":"# 3 Approaches\n\n1. Standard ML approach involving handcrafted features & using sklearn's GradientBoostingClassifier to predict outcome\n2. NLP deep learning approach assuming each page visit represents a \"word\", and the sequence of page visits represents a \"sentence\"\n3. Similar to approach #2 but able to incorporate more innformation about each visit","ea3fbc48":"# Appendix (Visits per Visitor)","d7189684":"# Declare Global Variables \/ Functions"}}