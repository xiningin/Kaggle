{"cell_type":{"9d9d642d":"code","2f72312b":"code","55d493b6":"code","a350ebb8":"code","3bc9dfee":"code","561b2285":"code","6e420144":"code","5b6aaea7":"code","8b9e7728":"code","4d08047b":"code","78f408b8":"code","ab4b9753":"code","bfd20219":"code","1f6a1b00":"code","93c5a093":"code","e3456ec9":"code","b1a47739":"code","5255f2c1":"code","9d0be458":"code","f9ef315d":"code","8f27c4c2":"code","564a21e8":"code","27c81f25":"code","f8f04ac4":"code","83444937":"code","b264aae7":"code","8fcbe3b5":"code","8e7da222":"code","011c8438":"code","cca52aab":"code","a6916085":"code","203dfde3":"code","836e0f1c":"code","f88f2a54":"code","c720fe2b":"code","ec16bfc2":"code","61345e96":"code","43af4b50":"code","480ff9bf":"code","6793f60c":"code","7ec73dd4":"code","dbd718c8":"code","f63d6ad5":"code","a92535ee":"code","445b4337":"code","1c30ebef":"code","54646123":"code","9ceb9f4b":"code","653c21ab":"code","2b619cd6":"code","8622bb51":"code","a3c9c8fd":"code","6844520a":"code","dacdd98d":"code","ec840dd2":"code","d00b8ea9":"code","abbfdebf":"code","4704cbb3":"code","96e7cf74":"code","c162fd2a":"code","a99384d9":"code","04253ca5":"code","ea93ee2b":"code","581f7b42":"code","e5c17f62":"code","af022bcd":"code","0bbe1771":"code","9ede6597":"code","3021f815":"code","f3afd49d":"code","9ef959ab":"code","9e7934a7":"code","c323746f":"code","f3026dc8":"code","94963091":"code","c96c244b":"code","dca9ecf7":"code","939ec4ab":"code","036b0d1e":"code","7d9b79d7":"code","3b1b5aab":"code","b439366c":"code","443808f2":"code","d32626a0":"code","31d23587":"code","96762cf4":"code","9abedf45":"code","88f474b4":"code","a594c386":"code","39dea6e3":"code","3058b5f3":"code","40a8d7c0":"code","dd98233a":"markdown","0cac365a":"markdown","73ec7733":"markdown","7f9916fd":"markdown","51976b88":"markdown","67fca0a8":"markdown","43dc33aa":"markdown","5449e727":"markdown","66e197b4":"markdown","37057b5f":"markdown","6cdc03a9":"markdown","24026d0f":"markdown","7c784fa1":"markdown","a9bdbec7":"markdown","066cb2ad":"markdown","c7c81ca5":"markdown","961ebb62":"markdown","6aa078e6":"markdown","1690ef5c":"markdown","b9122c5f":"markdown","7b50ec46":"markdown","ba91d37b":"markdown","ae0b981c":"markdown","8c4755eb":"markdown","391161d2":"markdown","4675bff7":"markdown","9f36dbe3":"markdown","c529314d":"markdown","d629223e":"markdown"},"source":{"9d9d642d":"# Bibliotecas\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n%matplotlib inline\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.metrics import max_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","2f72312b":"# Carregando os Arquivos\n\n#TREINO\ndataset = pd.read_csv('train.csv')\n\n#TESTE\ntestset = pd.read_csv('test.csv')\n\n#EXEMPLO DE SUBMISS\u00c3O\nsubmission = pd.read_csv('sample_submission.csv')","55d493b6":"dataset.shape, testset.shape, submission.shape","a350ebb8":"#dataset de treino\ndataset.head(5)","3bc9dfee":"# dataset de teste\ntestset.head(5)","561b2285":"#visualizar estatisticas b\u00e1sicas do dataset de treino:  m\u00e9dia, percentagens, desvio padr\u00e3o, min e m\u00e1ximo.\ndataset.describe()","6e420144":"dataset.head(5)","5b6aaea7":"#rotulando a sa\u00edda: coluna \"Pressure\" da base de treino\nlabel = dataset.iloc[0: , 7]  \nlabel","8b9e7728":"#pegando todas as colunas no dataset de treino\ndata = dataset.iloc[0: , [0, 1, 2, 3, 4, 5, 6, 7]]\ndata.head(5)","4d08047b":"#pegando todas os dados do dataset de Teste\ntestdat = testset.iloc[0: , [0, 1, 2, 3, 4, 5, 6]]\ntestdat.head(5)","78f408b8":"#criando uma coluna de Pressure no dataset de test, e preenchendo com 0, para ser usada na previs\u00e3o final.\ntestdat.insert(len(testdat.columns), 'pressure', 0)\ntestdat.info()","ab4b9753":"#preenchendo com 0 os dados faltantes no dataset de treino\ndata = (data.fillna(0))\n\n#preenchendo com 0 os dados faltantes no dataset de teste\ntestdat = testdat.fillna(0)","bfd20219":"data.head(3)","1f6a1b00":"testdat.head(3)","93c5a093":"# Splitando os dados de treino em 70% e de teste em 30%\nX_train, X_test, y_train, y_test = train_test_split(data, label, random_state = 0, train_size = 0.7, )","e3456ec9":"# Visualizando como est\u00e1 a distribui\u00e7\u00e3o das colunas do conjunto de treinamento.\n\nsns.pairplot(X_train[[\"R\", \"C\", \"time_step\", \"u_in\",\"u_out\",\"pressure\"]], diag_kind=\"kde\")","b1a47739":"# Passando StandardScaler - Normaliza\u00e7\u00e3o dos dados.\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)","5255f2c1":"X_train","9d0be458":"X_test","f9ef315d":"# fazendo o apreendizado com o KNN Regressor\n# Regress\u00e3o baseada em K vizinhos mais pr\u00f3ximos.\n\n# n\u00e3o funcionou o classifier!\n# Knn = KNeighborsClassifier() \u00e9 usado apenas para classifica\u00e7\u00e3o, necesser\u00e1rio usar o KNeighborsRegressor() para regress\u00e3o.\n\n# usando o Knn para regress\u00e3o e ajustando os dados com o FIT com os dados de treino\n# usando knn=2, obteve um melhor resultado nas m\u00e9tricas de valida\u00e7\u00e3o, do que usar Knn = 3,4,5,7\n\nKnn = KNeighborsRegressor(n_neighbors=2, weights='distance')\nKnn.fit(X_train, y_train)","8f27c4c2":"# Plotando os valores de erro m\u00e1ximo calculado, para cada valor de n_neighbours testados\n\n# valores de n_nrighbors\nx = [2, 3, 4, 5, 7]\n# valores do erro m\u00e1ximo calculado\ny = [4.72, 5.34, 5.64,6.04, 6.62]\n#gr\u00e1fico:\nplt.plot(x,y, 'ro-')\nplt.ylabel('Erro m\u00e1ximo residual calculado')\nplt.xlabel('Valores de n_neighbors testados no modelo KNeighborsRegressor')\nplt.grid(True)\nplt.show()","564a21e8":"#fazendo a predi\u00e7\u00e3o encima dos dados de teste -> X_test\n\npredicao = Knn.predict(X_test)\nprint(predicao)","27c81f25":"# R2-Score Coeficiente de determina\u00e7\u00e3o - O melhor valor de R2-SCORE poss\u00edvel \u00e9 1, e pode ser negativo tamb\u00e9m.\n\nR2score = r2_score(predicao,y_test)\nprint('R2_Score da predi\u00e7\u00e3o \u00e9:', R2score)","f8f04ac4":"# Perda da regress\u00e3o, do erro absoluto mediano. - A sa\u00edda de erro absoluto m\u00e9dio \u00e9 um ponto flutuante n\u00e3o negativo. \n# O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_mediano_absoluto = median_absolute_error(predicao,y_test)\nprint ('O erro mediano absoluto da regress\u00e3o \u00e9:',erro_mediano_absoluto )","83444937":"#erro m\u00e9dio absoluto entre as previs\u00f5es de sa\u00edda e base de teste (press\u00e3o atual)\n#O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_medio_absoluto = mean_absolute_error(predicao,y_test)\nprint('O MAE, erro m\u00e9dio absoluto \u00e9:', erro_medio_absoluto)","b264aae7":"#erro m\u00e9dio quadr\u00e1tico entre as previs\u00f5es de sa\u00edda e base de teste (press\u00e3o atual)\n#O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_medio_quadratico = mean_squared_error(predicao,y_test)\nprint('O RMSE, erro m\u00e9dio quadratico \u00e9:',erro_medio_quadratico)","8fcbe3b5":"# Erro m\u00e1ximo calculado na predi\u00e7\u00e3o, melhor valor poss\u00edvel \u00e9 0.0\n# A fun\u00e7\u00e3o max_error calcula o erro residual m\u00e1ximo, uma m\u00e9trica que captura o pior\n# caso de erro entre o valor previsto e o valor verdadeiro.\n\nerro_maximo = max_error(predicao,y_test)\nprint('O erro m\u00e1ximo residual calculado foi de :',erro_maximo )","8e7da222":"#R2 score do modelo, quanto mais pr\u00f3ximo de 1, melhor se ajusta ao modelo treinado\n\nr2Score_modelo = Knn.score(X_train, y_train)\nprint('O R2score, o coeficiente de determina\u00e7\u00e3o do modelo foi de:', r2Score_modelo)","011c8438":"# variancia, o melhor valor poss\u00edvel \u00e9 1. Os valores muito abaixo de 1 n\u00e3o s\u00e3o bons. Quanto mais pr\u00f3ximo de 1, melhor o modelo.\n\nvariancia = explained_variance_score(y_test, predicao)\nprint('A Variancia do modelo \u00e9:', variancia)","cca52aab":"# Fazendo a predi\u00e7\u00e3o final,prevendo as press\u00f5es finais.\n\nresultado_final = Knn.predict(testdat)\nprint(resultado_final)","a6916085":"# construindo o dataframe final, como coluna 0 [\"id\"] e coluna 1 [\"pressure\"]\nindex = [dataset['pressure']]\ndf_saida = pd.DataFrame(data = resultado_final, index = testdat['id'], columns = ['pressure'])\n\n#passando o dataframe para um arquivo csv\ndf_saida.to_csv('.\/submission.csv', header=True)\nprint('.\/submission.csv')","203dfde3":"#data frame final para submiss\u00e3o\ndf_saida.head(10)","836e0f1c":"#tamanho da base esperada, de acordo com a competi\u00e7\u00e3o requisitou (4024000 de colunas).\nlen(df_saida)","f88f2a54":"#informa\u00e7\u00f5es estat\u00edsticas do data frame final\ndf_saida.describe()","c720fe2b":"# Carregando o modelo\nregresssao_linear = LinearRegression()","ec16bfc2":"# Treinando o modelo\nregresssao_linear.fit(X_train, y_train)","61345e96":"#predi\u00e7\u00e3o de x_test\n\ny_pred_regre = regresssao_linear.predict(X_test)\nprint('resposta da predi\u00e7\u00e3o \u00e9:', y_pred_regre)","43af4b50":"# R2-Score Coeficiente de determina\u00e7\u00e3o - O melhor valor de R2-SCORE poss\u00edvel \u00e9 1, e pode ser negativo tamb\u00e9m.\n\nR2score = r2_score(y_pred_regre,y_test)\nprint('R2_Score da predi\u00e7\u00e3o \u00e9:', R2score)","480ff9bf":"# Perda da regress\u00e3o, do erro absoluto mediano. - A sa\u00edda de erro absoluto m\u00e9dio \u00e9 um ponto flutuante n\u00e3o negativo. \n# O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_mediano_absoluto = median_absolute_error(y_pred_regre,y_test)\nprint ('O erro mediano absoluto da regress\u00e3o \u00e9:',erro_mediano_absoluto )","6793f60c":"#erro m\u00e9dio absoluto entre as previs\u00f5es de sa\u00edda e base de teste (press\u00e3o atual)\n#O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_medio_absoluto = mean_absolute_error(y_pred_regre,y_test)\nprint('O MAE, erro m\u00e9dio absoluto \u00e9:', erro_medio_absoluto)","7ec73dd4":"#erro m\u00e9dio quadr\u00e1tico entre as previs\u00f5es de sa\u00edda e base de teste (press\u00e3o atual)\n#O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_medio_quadratico = mean_squared_error(y_pred_regre,y_test)\nprint('O RMSE, erro m\u00e9dio quadratico \u00e9:',erro_medio_quadratico)","dbd718c8":"# Erro m\u00e1ximo calculado na predi\u00e7\u00e3o, melhor valor poss\u00edvel \u00e9 0.0\n# A fun\u00e7\u00e3o max_error calcula o erro residual m\u00e1ximo, uma m\u00e9trica que captura o pior\n# caso de erro entre o valor previsto e o valor verdadeiro.\n\nerro_maximo = max_error(y_pred_regre,y_test)\nprint('O erro m\u00e1ximo residual calculado foi de :',erro_maximo )","f63d6ad5":"#R2 score do modelo, quanto mais pr\u00f3ximo de 1, melhor se ajusta ao modelo treinado\n\nr2Score_modelo = regresssao_linear.score(X_train, y_train)\nprint('O R2score, o coeficiente de determina\u00e7\u00e3o do modelo foi de:', r2Score_modelo)","a92535ee":"# variancia, o melhor valor poss\u00edvel \u00e9 1. Os valores muito abaixo de 1 n\u00e3o s\u00e3o bons. Quanto mais pr\u00f3ximo de 1, melhor o modelo.\n\nvariancia = explained_variance_score(y_test, y_pred_regre)\nprint('A Variancia do modelo \u00e9:', variancia)","445b4337":"# Fazendo a predi\u00e7\u00e3o final,prevendo as press\u00f5es finais.\n# Sa\u00eddas da previs\u00e3o, resultado das press\u00f5es - regression lINEAR\n\nresultado_final_regressao = regresssao_linear.predict(testdat)\nprint(resultado_final_regressao)","1c30ebef":"# construindo o dataframe final como coluna 0 [\"id\"] e coluna 1 [\"pressure\"]\nindex = [dataset['pressure']]\ndf_saida2 = pd.DataFrame(data = resultado_final_regressao, index = testdat['id'], columns = ['pressure'])\n\n#passando o dataframe para um arquivo csv\ndf_saida2.to_csv('.\/submission2.csv', header=True)\nprint('.\/submission2.csv')","54646123":"df_saida2","9ceb9f4b":"#tamanho da base esperada, de acordo com a competi\u00e7\u00e3o requisitou (4024000 de colunas).\nlen(df_saida2)","653c21ab":"#informa\u00e7\u00f5es estat\u00edsticas do data frame final\ndf_saida2.describe()","2b619cd6":"print(X_train.shape)","8622bb51":"print(y_train.shape)","a3c9c8fd":"#sequ\u00eanciando o modelo\nmodelo = Sequential()\n\n# Adi\u00e7\u00e3o da primeira camada e primeira camada escondida\nmodelo.add(Dense(500, input_dim=8, activation='relu'))\n\n# Adi\u00e7\u00e3o da segunda camada escondida\nmodelo.add(Dense(100, activation='relu'))\n\n# Adi\u00e7\u00e3o da terceira camada escondida\nmodelo.add(Dense(50, activation='relu'))\n\n# Adi\u00e7\u00e3o da camada de dropout\ntf.keras.layers.Dropout(0.5)\n\n#Camada de sa\u00edda\nmodelo.add(Dense(1))\n\n# Compile model\nmodelo.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])","6844520a":"# treinando o modelo e pegando o hist\u00f3rico \nhistorico = modelo.fit(X_train, y_train, batch_size = 128, epochs = 30,  verbose=1)","dacdd98d":"# descri\u00e7\u00e3o do modelo\nmodelo.summary()","ec840dd2":"print(historico.history.keys())","d00b8ea9":"# pLot do hist\u00f3rico do erro loss, durante o treinamento do modelo.\n\nplt.plot(historico.history['mae'])\nplt.title('Hist\u00f3rico de treinamento do Modelo - Mae')\nplt.ylabel('mae')\nplt.xlabel('epoch')\nplt.legend(['mae'], loc='upper left')\nplt.show()","abbfdebf":"# previs\u00e3o de x_test\ny_pred_rede = modelo.predict(X_test)\nprint(y_pred_rede)","4704cbb3":"# R2-Score Coeficiente de determina\u00e7\u00e3o - O melhor valor de R2-SCORE poss\u00edvel \u00e9 1, e pode ser negativo tamb\u00e9m.\n\nR2score = r2_score(y_pred_rede,y_test)\nprint('R2_Score da predi\u00e7\u00e3o \u00e9:', R2score)","96e7cf74":"# Perda da regress\u00e3o, do erro absoluto mediano. - A sa\u00edda de erro absoluto m\u00e9dio \u00e9 um ponto flutuante n\u00e3o negativo. \n# O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_mediano_absoluto = median_absolute_error(y_pred_rede,y_test)\nprint ('O erro mediano absoluto da regress\u00e3o \u00e9:',erro_mediano_absoluto )","c162fd2a":"#erro m\u00e9dio absoluto entre as previs\u00f5es de sa\u00edda e base de teste (press\u00e3o atual)\n#O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_medio_absoluto = mean_absolute_error(y_pred_rede,y_test)\nprint('O MAE, erro m\u00e9dio absoluto \u00e9:', erro_medio_absoluto)","a99384d9":"#erro m\u00e9dio quadr\u00e1tico entre as previs\u00f5es de sa\u00edda e base de teste (press\u00e3o atual)\n#O melhor valor poss\u00edvel \u00e9 0,0.\n\nerro_medio_quadratico = mean_squared_error(y_pred_rede,y_test)\nprint('O RMSE, erro m\u00e9dio quadratico \u00e9:',erro_medio_quadratico)","04253ca5":"# Erro m\u00e1ximo calculado na predi\u00e7\u00e3o, melhor valor poss\u00edvel \u00e9 0.0\n# A fun\u00e7\u00e3o max_error calcula o erro residual m\u00e1ximo, uma m\u00e9trica que captura o pior\n# caso de erro entre o valor previsto e o valor verdadeiro.\n\nerro_maximo = max_error(y_pred_rede,y_test)\nprint('O erro m\u00e1ximo residual calculado foi de :',erro_maximo )","ea93ee2b":"# variancia, o melhor valor poss\u00edvel \u00e9 1. Os valores muito abaixo de 1 n\u00e3o s\u00e3o bons. Quanto mais pr\u00f3ximo de 1, melhor o modelo.\n\nvariancia = explained_variance_score(y_test, y_pred_rede)\nprint('A Variancia do modelo \u00e9:', variancia)","581f7b42":"# Fazendo a predi\u00e7\u00e3o final,prevendo as press\u00f5es finais.\n# Sa\u00eddas da previs\u00e3o, resultado das press\u00f5es - REDE NEURAL\n\ny_pred_rede_final = modelo.predict(testdat)\nprint(y_pred_rede_final)","e5c17f62":"len(y_pred_rede_final)","af022bcd":"# construindo o dataframe final como coluna 0 [\"id\"] e coluna 1 [\"pressure\"]\nindex = [dataset['pressure']]\ndf_saida3 = pd.DataFrame(data = y_pred_rede_final, index = testdat['id'], columns = ['pressure'])\n\n#passando o dataframe para um arquivo csv\ndf_saida3.to_csv('.\/submission3.csv', header=True)\nprint('.\/submission3.csv')","0bbe1771":"#tamanho da base esperada, de acordo com a competi\u00e7\u00e3o requisitou (4024000 de colunas).\nlen(df_saida3)","9ede6597":"#informa\u00e7\u00f5es estat\u00edsticas do data frame final\ndf_saida3.describe()","3021f815":"Knn2 = KNeighborsRegressor(n_neighbors=5)\nKnn2.fit(X_train, y_train)","f3afd49d":"#fazendo a predi\u00e7\u00e3o encima dos dados de teste -> X_test\n\npredicao2 = Knn2.predict(X_test)\nprint(predicao2)","9ef959ab":"# R2-Score Coeficiente de determina\u00e7\u00e3o - O melhor valor de R2-SCORE poss\u00edvel \u00e9 1, e pode ser negativo tamb\u00e9m.\n\nR2score = r2_score(predicao2,y_test)\nprint('R2_Score da predi\u00e7\u00e3o \u00e9:', R2score)","9e7934a7":"# Erro m\u00e1ximo calculado na predi\u00e7\u00e3o, melhor valor poss\u00edvel \u00e9 0.0\n# A fun\u00e7\u00e3o max_error calcula o erro residual m\u00e1ximo, uma m\u00e9trica que captura o pior\n# caso de erro entre o valor previsto e o valor verdadeiro.\n\nerro_maximo = max_error(predicao2,y_test)\nprint('O erro m\u00e1ximo residual calculado foi de :',erro_maximo )","c323746f":"# variancia, o melhor valor poss\u00edvel \u00e9 1. Os valores muito abaixo de 1 n\u00e3o s\u00e3o bons. Quanto mais pr\u00f3ximo de 1, melhor o modelo.\n\nvariancia = explained_variance_score(y_test, predicao2)\nprint('A Variancia do modelo \u00e9:', variancia)","f3026dc8":"# Fazendo a predi\u00e7\u00e3o final,prevendo as press\u00f5es finais.\n\nresultado_final2 = Knn2.predict(testdat)\nprint(resultado_final2)","94963091":"# construindo o dataframe final, como coluna 0 [\"id\"] e coluna 1 [\"pressure\"]\nindex = [dataset['pressure']]\ndf_saida4 = pd.DataFrame(data = resultado_final2, index = testdat['id'], columns = ['pressure'])\n\n#passando o dataframe para um arquivo csv\ndf_saida4.to_csv('.\/submission4.csv', header=True)\nprint('.\/submission4.csv')","c96c244b":"df_saida4","dca9ecf7":"# Carregando os Arquivos\n\n#TREINO\ntrain_data = pd.read_csv('train.csv')\n\n#TESTE\ntest_data = pd.read_csv('test.csv')\n\n#EXEMPLO DE SUBMISS\u00c3O\nsubmission5 = pd.read_csv('sample_submission.csv')","939ec4ab":"# rotulando a sa\u00edda, as press\u00f5es.\ntargets = train_data[['pressure']].to_numpy().reshape(-1, 80)\n\n# Dropando as colunas sem necessidade da base treino e da base teste\ntrain_data.drop(['pressure', 'id', 'breath_id', 'u_out'], axis=1, inplace=True)\ntest_data =  test_data.drop(['id', 'breath_id', 'u_out'], axis=1)","036b0d1e":"#Normalizando os dados\nfrom sklearn.preprocessing import RobustScaler\n\nRS = RobustScaler()\ntrain_data = RS.fit_transform(train_data)\ntest_data  = RS.transform(test_data)","7d9b79d7":"n_features = train_data.shape[-1]\n\ntrain_data = train_data.reshape(-1, 80, n_features)\ntest_data  = test_data.reshape(-1, 80, n_features)\n\nn_epochs = 50\nn_splits =  5","3b1b5aab":"X_train = train_data\ny_train = targets","b439366c":"#importando a camada TCN (Temporal Convolutional Network do Keras)\n\nfrom tcn import TCN, tcn_full_summary\n\nmodel = keras.models.Sequential([\n    TCN(input_shape=(80, n_features), nb_filters=64, return_sequences=True, dilations=[1, 2, 4, 8, 16, 32]),\n    keras.layers.Dense(1)\n])\n    \nmodel.compile(optimizer=\"adam\", loss=\"mae\",metrics=keras.metrics.MeanAbsoluteError())\n\n\n# Par\u00e2metros da rede:\n\n# Input shape:\n# 3D tensor with shape (batch_size, timesteps, input_dim). timesteps can be None. \n\n# nb_filters: Presente em qualquer arquitetura ConvNet. \n# Ele est\u00e1 vinculado ao poder preditivo do modelo e afeta o tamanho da sua rede. \n# Quanto mais, melhor, a menos que voc\u00ea comece a se ajustar demais.\n\n# dilations:controla a profundidade da camada TCN.\n# Normalmente, considere uma lista com v\u00e1rios valores pulando de dois em dois.\n\n# Ref:. https:\/\/pypi.org\/project\/keras-tcn\/","443808f2":"# Treinamento e hist\u00f3rico da rede\nhistory = model.fit(X_train, y_train,  epochs=30, batch_size=1024, verbose =1)","d32626a0":"# descri\u00e7\u00e3o do modelo\nmodel.summary()","31d23587":"# mostrando os par\u00e2metros de erros da rede\nprint(history.history.keys())","96762cf4":"# pLot do hist\u00f3rico do erro loss, durante o treinamento do modelo.\n\nplt.plot(history.history['loss'])\nplt.title('Erro do Modelo - Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","9abedf45":"# Fazendo a predi\u00e7\u00e3o final,prevendo as press\u00f5es finais.\n# Sa\u00eddas da previs\u00e3o, resultado das press\u00f5es - REDE NEURAL\n\npredict_final = model.predict(test_data)\nprint(predict_final)","88f474b4":"# predi\u00e7\u00e3o final para o arquivo de submiss\u00e3o. \ntest_preds = []\ntest_preds.append(model.predict(test_data).squeeze().reshape(-1, 1).squeeze())","a594c386":"# submiss\u00e3o\nsubmission5[\"pressure\"] = sum(test_preds)\/n_splits\nsubmission5.to_csv('submission5.csv', index=False)","39dea6e3":"submission5.head(10)","3058b5f3":"#informa\u00e7\u00f5es estat\u00edsticas do data frame final\nsubmission5.describe()","40a8d7c0":"len(submission5)","dd98233a":"#### Os melhores valores encontrados nas m\u00e9tricas de valida\u00e7\u00e3o para regress\u00e3o, usando: R2-Score, Erro M\u00e9dio Absoluto, Erro Mediano Absoluto, Erro M\u00e9dio Quadr\u00e1tico, Erro M\u00e1ximo e Vari\u00e2ncia, foi usar o modelo Linear Regression no dataset, obtendo assim tamb\u00e9m o melhor resultado no Leader Board da competi\u00e7\u00e3o do Kaggle. Apesar dos bons valores das m\u00e9tricas de regress\u00e3o para ambos os modelos, a melhor pontua\u00e7\u00e3o no LeaderBoard foi para a submiss\u00e3o do modelo Linear Regression. Melhor do que ter usado o dataset nos modelos Knn Neighbours Regressor , Rede Neural CNN e a camada TCN (Temporal Convolutional Network do Keras)","0cac365a":"### Usando a Rede Neural, com a camada temporal convolucional do Keras - TCN (Temporal Convolutional Network)\n","73ec7733":"#### O melhor resultado na pontua\u00e7\u00e3o da competi\u00e7\u00e3o do LeaderBoard, foi usando o Liner Regression","7f9916fd":"#### Preparando o arquivo de sa\u00edda para submiss\u00e3o e criando o arquivo final \"submisison.csv\"","51976b88":"### Usando o m\u00e9todo Regress\u00e3o Linear - LinearRegression","67fca0a8":"#### Prevendo as press\u00f5es finais","43dc33aa":"### Usando o M\u00e9todo knn Neighbors Regressor com os par\u00e2metros Default","5449e727":"#### Preparando o arquivo de sa\u00edda para submiss\u00e3o e criando o arquivo final \"submisison2.csv\":","66e197b4":"### M\u00e9todo atrav\u00e9s da Regress\u00e3o, basedo em k-nearest neighbors, usando o \" KNeighborsRegressor \", os dados s\u00e3o de natureza cont\u00ednua","37057b5f":"### M\u00e9todos Utilizados para submeter as predi\u00e7\u00f5es: \n### - Knn Neighbors Regressor\n### - Linear Regression\n### - Rede Neural Convolucional - CNN \n### - Rede Neural usando a camadaTemporal do Keras - TCN (Temporal Convolutional Network) .","6cdc03a9":"### Informa\u00e7\u00f5es:\n#### Nesta competi\u00e7\u00e3o, voc\u00ea simular\u00e1 um ventilador conectado ao pulm\u00e3o de um paciente sedado. As melhores apresenta\u00e7\u00f5es levar\u00e3o em considera\u00e7\u00e3o a conformidade e resist\u00eancia dos atributos pulmonares.\n\n#### A competi\u00e7\u00e3o ser\u00e1 pontuada como o erro absoluto m\u00e9dio entre as press\u00f5es previstas e reais durante a fase inspirat\u00f3ria de cada respira\u00e7\u00e3o. A fase expirat\u00f3ria n\u00e3o \u00e9 pontuada. A pontua\u00e7\u00e3o \u00e9 dada por: [X-Y], onde X \u00e9 o vetor da press\u00e3o prevista e Y \u00e9 o vetor das press\u00f5es reais em todas as respira\u00e7\u00f5es no conjunto de teste.\n\n\n#### Para cada id no conjunto de teste, voc\u00ea deve prever um valor para a vari\u00e1vel de press\u00e3o. O arquivo deve conter um cabe\u00e7alho e ter o seguinte formato:\n\n#### id, pressure\n#### 1,20\n#### 2,23\n#### 3,24\n#### etc..","24026d0f":"## Competi\u00e7\u00e3o do Kaggle","7c784fa1":"#### 1\u00b0 \"Linear Regression ()\"\n#### 2\u00b0 k-nearest neighbors, usando o \" KNeighborsRegressor () \"\n#### 3\u00b0 Rede Neural, com a camada temporal convolucional do Keras - \"TCN\" (Temporal Convolutional Network)\n#### 4\u00b0 Rede Neural Convolucional, \"CNN\", para regress\u00e3o.","a9bdbec7":"#### Preparando o arquivo de sa\u00edda para submiss\u00e3o e criando o arquivo final \"submisison4.csv\":","066cb2ad":"#### M\u00e9tricas de Regress\u00e3o, para a avalia\u00e7\u00e3o do modelo, usando o Knn Regressor","c7c81ca5":"### Conclus\u00f5es:","961ebb62":"#### Cada s\u00e9rie temporal representa uma respira\u00e7\u00e3o de aproximadamente 3 segundos. Os arquivos s\u00e3o organizados de forma que cada linha seja um intervalo de tempo em uma respira\u00e7\u00e3o e forne\u00e7a os dois sinais de controle, a press\u00e3o das vias a\u00e9reas resultante e os atributos relevantes do pulm\u00e3o, descritos a seguir.","6aa078e6":"#### Preparando o arquivo de sa\u00edda para submiss\u00e3o e criando o arquivo final \"submisison5.csv\":","1690ef5c":"### Preparando as bases de treino e teste para usar com o KNN Regressor (Regress\u00e3o)","b9122c5f":"### Nome da Competi\u00e7\u00e3o: Google Brain - Ventilator Pressure Prediction \n#### ( Simulando um ventilador conectado ao pulm\u00e3o de um paciente sedado )","7b50ec46":"### Usando Rede Neural - CNN -  para Regress\u00e3o:","ba91d37b":"#### Apart\u00edr do gr\u00e1fico acima, nota-se que quanto maior o valor de n_Neigbours testado no modelo, maior o valor do erro m\u00e1ximo residual calculado (max_error). A fun\u00e7\u00e3o max_error, calcula o erro residual m\u00e1ximo, uma m\u00e9trica que captura o pior caso de erro entre o valor previsto e o valor verdadeiro. Quanto menor o valor, melhor o modelo.","ae0b981c":"#### M\u00e9tricas de Regress\u00e3o para validar a Rede Neural - CNN","8c4755eb":"#### Colunas\nid - identificador de intervalo de tempo globalmente exclusivo em um arquivo inteiro.\n\nbreath_id - intervalo de tempo globalmente \u00fanico para respira\u00e7\u00f5es.\n\nR - atributo do pulm\u00e3o indicando o qu\u00e3o restrita as vias a\u00e9reas s\u00e3o (em cmH2O \/ L \/ S). Fisicamente, \u00e9 a mudan\u00e7a na press\u00e3o por mudan\u00e7a no fluxo (volume de ar por tempo). Intuitivamente, pode-se imaginar explodir um bal\u00e3o por um canudo. Podemos mudar R mudando o di\u00e2metro do canudo, com R mais alto sendo mais dif\u00edcil de soprar.\n\nC - atributo do pulm\u00e3o que indica o qu\u00e3o complacente o pulm\u00e3o \u00e9 (em mL \/ cmH2O). Fisicamente, esta \u00e9 a mudan\u00e7a no volume por mudan\u00e7a na press\u00e3o. Intuitivamente, pode-se imaginar o mesmo exemplo de bal\u00e3o. Podemos mudar C mudando a espessura do l\u00e1tex do bal\u00e3o, com C mais alto tendo l\u00e1tex mais fino e mais f\u00e1cil de soprar.\n\ntime_step - o carimbo de hora real.\n\nu_in - a entrada de controle para a v\u00e1lvula solen\u00f3ide inspirat\u00f3ria. Varia de 0 a 100.\n\nu_out - a entrada de controle para a v\u00e1lvula solen\u00f3ide explorat\u00f3ria. 0 ou 1.\n\npress\u00e3o - a press\u00e3o das vias a\u00e9reas medida no circuito respirat\u00f3rio, medida em cmH2O.","391161d2":"### Ranking dos modelos testados pela competi\u00e7\u00e3o do Kaggle:","4675bff7":"#### Preparando o arquivo de sa\u00edda para submiss\u00e3o e criando o arquivo final \"submisison3.csv\":","9f36dbe3":"#### M\u00e9tricas para a valida\u00e7\u00e3o da Regress\u00e3o Linear","c529314d":"#### Resultados com outros valores de Knn,  n_neighbors:\n##### Knn = 2, ERRO M\u00c1XIMO: 4,72, com  weights='distance'\n##### kNN = 2 , ERRO M\u00c1XIMO: 4,78, com Weights = 'default'\n##### kNN = 3 , ERRO M\u00c1XIMO: 5,34\n##### kNN = 4 , ERRO M\u00c1XIMO: 5,64\n##### kNN = 5 , ERRO M\u00c1XIMO: 6,04\n##### kNN = 7 , ERRO M\u00c1XIMO: 6,62\n\n\n\n\n##### Melhor valor encontrado de Knn , foi de n_neighbors = 2 e com weights='distance'\n##### Para vizinhos mais pr\u00f3ximos, o resultado \u00e9 melhor usando esse par\u00e2metro \"weights='distance \"","d629223e":"#### Normalizando os dados Splitados - StandardScaler"}}