{"cell_type":{"bd732dc1":"code","225b9b68":"code","c31cc36a":"code","0d6314b5":"code","fe412892":"code","8232d674":"code","24cdbb07":"code","cdad2945":"code","f973520a":"code","7ee970a0":"code","7eb974b7":"code","f7641076":"code","aa757d86":"code","a51ab677":"code","c0c4d955":"code","7d7801f3":"code","95d85529":"code","35df25fe":"code","f0c8667d":"code","1679e609":"code","0dbf4962":"code","5a351e23":"code","3557694a":"code","2d63b528":"markdown","ab8229a8":"markdown","5ab9a2ce":"markdown","1b321e1d":"markdown","4b7a2be2":"markdown","049b8c42":"markdown","218e41a3":"markdown","0d8adfcc":"markdown","30a7ba10":"markdown","f86233b9":"markdown","49056ff2":"markdown","8b1c126b":"markdown","6b63b6c8":"markdown","f3a9e094":"markdown","ab4d1f77":"markdown","08b87357":"markdown","2ac46861":"markdown","82f9408d":"markdown","aa180fe9":"markdown","5c1ce38b":"markdown"},"source":{"bd732dc1":"import urllib.request\nimport os\nimport zipfile\nimport random\n\nimport tensorflow as tf\nfrom tensorflow import keras as ks\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')","225b9b68":"data_url = \"https:\/\/download.microsoft.com\/download\/3\/E\/1\/3E1C3F21-ECDB-4869-8368-6DEBA77B919F\/kagglecatsanddogs_3367a.zip\"\ndata_file_name = 'cats_dogs.zip'\ndownload_dir = '\/tmp\/'\nurllib.request.urlretrieve(data_url, data_file_name)\nzip_ref = zipfile.ZipFile(data_file_name, 'r')\nzip_ref.extractall(download_dir)\nzip_ref.close()","c31cc36a":"os.listdir('\/tmp\/')","0d6314b5":"print(\"The number of Cat Images \", len(os.listdir('\/tmp\/PetImages\/Cat')))\nprint(\"The number of Dog Images \", len(os.listdir('\/tmp\/PetImages\/Dog')))","fe412892":"try:\n    os.mkdir('\/tmp\/cvd\/')\n    os.mkdir('\/tmp\/cvd\/training')\n    os.mkdir('\/tmp\/cvd\/testing')\n    os.mkdir('\/tmp\/cvd\/training\/cats')\n    os.mkdir('\/tmp\/cvd\/training\/dogs')\n    os.mkdir('\/tmp\/cvd\/testing\/cats')\n    os.mkdir('\/tmp\/cvd\/testing\/dogs')\nexcept:\n    print('error')","8232d674":"def split_data(source, training, testing, split_size):\n    files = []\n    for filename in os.listdir(source):\n        file = source + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(f'{filename} is corrupt or empty')\n        \n    training_length = int(len(files)* split_size)\n    testing_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[:training_length]\n    testing_set = shuffled_set[training_length:]\n    \n    for filename in training_set:\n        this_file = source + filename\n        dest = training + filename\n        copyfile(this_file, dest)\n    \n    for filename in testing_set:\n        this_file = source + filename\n        dest = testing + filename\n        copyfile(this_file, dest)\n\ncat_src_dir = '\/tmp\/PetImages\/Cat\/'\ndog_src_dir = '\/tmp\/PetImages\/Dog\/'\ntraining_cat_dir = '\/tmp\/cvd\/training\/cats\/'\ntraining_dog_dir = '\/tmp\/cvd\/training\/dogs\/'\ntesting_cat_dir = '\/tmp\/cvd\/testing\/cats\/'\ntesting_dog_dir = '\/tmp\/cvd\/testing\/dogs\/'\n\nsplit_size = 0.9\n\nsplit_data(cat_src_dir, training_cat_dir, testing_cat_dir, split_size)\nsplit_data(dog_src_dir, training_dog_dir, testing_dog_dir, split_size)","24cdbb07":"def resize_img(data_path):\n    for filename in os.listdir(data_path):\n        try:\n            img = plt.imread(os.path.join(data_path, filename))\n            img = cv.resize(img, (150, 150))\n            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n            cv.imwrite(data_path+filename, img)\n        except:\n            continue","cdad2945":"resize_img(training_cat_dir)\nresize_img(training_dog_dir)\nresize_img(testing_dog_dir)\nresize_img(testing_dog_dir)","f973520a":"next_cat_pic = [os.path.join(training_cat_dir, fname) for fname in random.sample(os.listdir(training_cat_dir), 5)]\nnext_dog_pic = [os.path.join(training_dog_dir, fname) for fname in random.sample(os.listdir(training_dog_dir), 5)]\n\nplt.figure(figsize=(25,10))\nfor i, img_path in enumerate(next_cat_pic + next_dog_pic):\n    ax = plt.subplot(2, 5, i+1)\n    ax.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img)","7ee970a0":"gpus = tf.config.experimental.list_logical_devices('GPU')\nstrategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\nprint('running on single gpu')","7eb974b7":"train_datagen = ImageDataGenerator(\n    rescale=1\/255.0, \n    rotation_range=40, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    shear_range=0.2, \n    zoom_range=0.2, \n    horizontal_flip=True, \n    fill_mode='nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1\/255.0)\n\n\n\ntraining_generator = train_datagen.flow_from_directory(\n    '\/tmp\/cvd\/training\/', \n    batch_size=100, \n    class_mode='binary', \n    target_size=(150, 150)\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    '\/tmp\/cvd\/testing\/', \n    batch_size=100, \n    class_mode='binary', \n    target_size=(150, 150)\n)","f7641076":"weights_url = 'https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweights_file = 'inception_v3.h5'\nurllib.request.urlretrieve(weights_url, weights_file)","aa757d86":"with strategy.scope():\n    pre_trained_model = InceptionV3(\n        input_shape=(150, 150, 3), \n        include_top=False, \n        weights=None\n    )\n    pre_trained_model.load_weights(weights_file)\n\n    for layer in pre_trained_model.layers:\n        layer.trainable = False\n    last_layer = pre_trained_model.get_layer('mixed7')\n    print(last_layer.output_shape)\n    last_output = last_layer.output","a51ab677":"def model(inputs):\n    x = layers.Flatten()(inputs)\n    x = layers.Dense(1024, activation='relu')(x)\n    x = layers.Dense(1, activation='sigmoid')(x)\n    model = Model(pre_trained_model.input, x)\n    return model\n\nwith strategy.scope():\n    model = model(last_output)\n    model.compile(optimizer=ks.optimizers.RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['acc'])","c0c4d955":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get('acc')>0.99):\n            print('\\nReached 99% accuracy so cancelling training')\n            self.model.stop_training = True\n\ncallbacks = myCallback()\n","7d7801f3":"history= model.fit(training_generator, validation_data=validation_generator, epochs=50, verbose=0, callbacks=[callbacks])","95d85529":"def plot_metrics(metric_name):\n    train_loss = history.history[metric_name]\n    epochs = range(len(train_loss))\n    val_loss = history.history['val_' + metric_name]\n    plt.figure(figsize=(5, 5))\n    plt.plot(epochs, train_loss, color='r')\n    plt.plot(epochs, val_loss, color='b')\n    plt.title(f'Model {metric_name}')\n    plt.legend([f'training_{metric_name}', f'val_{metric_name}'])\n    plt.xlabel('epochs')\n    plt.ylabel(f'{metric_name}')\n    plt.show()\n    ","35df25fe":"plt.style.use('seaborn')\nplot_metrics('loss')\nplot_metrics('acc')","f0c8667d":"def predict_class(filename, model, ax):\n    img = load_img(filename, target_size=(150, 150))\n    image = plt.imread(filename)\n    image = cv.resize(image, (200, 200))\n    ax.imshow(image)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    img = img_to_array(img)\n    img = img.reshape(1, 150, 150, 3)\n    img = img.astype('float32')\/255.0\n    result = model.predict(img)\n    if result[0][0] > 0.9:\n        ax.set_title('Dog | Score: ' + str(result[0][0]))\n    else:\n        ax.set_title('Cat | Score: ' + str(result[0][0]))\n","1679e609":"def urler(url, ax):\n    resource = urllib.request.urlopen(url)\n    output = open('file.jpg', 'wb')\n    output.write(resource.read())\n    output.close()\n    predict_class('file.jpg', model, ax)","0dbf4962":"url_list = [\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcS3bCwUCJW0BlgvKzh5KvHTdbOQ3wGPcEUnMQ&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRviwTGt6wboCe9ajzBJDy4aJ19NmhNv4dg2g&usqp=CAU',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRfNrh7pE_rneJlr31AhoLaGtZdX2qCBKV-EA&usqp=CAU',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcS9FhF-KCQL_pRcCYyOHlaWzYOL03QnvANbfw&usqp=CAU',\n    'https:\/\/s3.ap-southeast-1.amazonaws.com\/images.deccanchronicle.com\/dc-Cover-kg8a727q0cuucunk15mpfv2uv2-20170725190600.Medi.jpeg',\n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTNDH6Ggz1lwkaBTC4r3RqeF6KYTHuBNFE-bg&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRMFelkjsaJRYkSCRybp9szEDULwDffMKR-3g&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRxYAKQt_C0roPUU2-VYx6I_YKseX3hyOauQw&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRF8L1kksXIdsHlKTXyMHPCTfaxcu0CE9fIC2CX3Z4pO0mfKTv-n6d7FN-z6Rvlvs_AfwI&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRa__d0RbzBPaQrkrlg1E6ZLnz1EVHVB4dTMQ&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSEZ4n6vaYSFi8wNK1xNwiUNx969vRI7iS_A55O66dIdXNH2lxJSFTMwxjE-a-V2yyZAxA&usqp=CAU',  \n    'https:\/\/www.pinkvilla.com\/files\/styles\/amp_metadata_content_image_min_696px_wide\/public\/alia_bhatt_bids_goodbye_to_her_cat_sheeba_as_the_feline_passes_away_.jpg?itok=dNAseG1R', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT-k5F8HSK60Iwwj-x_kFFCg6anSVzWD_QFbA&usqp=CAU', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQ2Zvsf9hVwYoI3JbCwnZvnI5Cjbjk76a74YA&usqp=CAU', \n    'https:\/\/blog.mystart.com\/wp-content\/uploads\/shutterstock_288913766-e1551281043329.jpg', \n    'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcR4pbDrhn-j_GvNBSIRA3ZZwOGa8etrh4qJ7YXGRg-FzwAyujZuKyP_2VHZMToV6HJy4XA&usqp=CAU'\n    \n]","5a351e23":"n = 0\nfig = plt.figure(figsize=(22, 20))\naxs = fig.subplots(4, 4)\nfor i in range(4):\n    urler(url_list[n+0], axs[i, 0])\n    urler(url_list[n+1], axs[i, 1])\n    urler(url_list[n+2], axs[i, 2])\n    urler(url_list[n+3], axs[i, 3])\n    n += 4\nplt.tight_layout()\nplt.show()","3557694a":"model.save('cats_vs_dogs_IV3.h5')","2d63b528":"### *Get the InceptionV3 model from tensorflow.applications and Load the pretrained weights to the model and get the last layer alone for training to develop our model on top of a monster*","ab8229a8":"### *Load the image Dataset*","5ab9a2ce":"### *Creating a callback to end training after reaching 99% accuracy but I would just run for 50 epochs within that it won't get that much accuracy is my guess, even though our model would perform well*","1b321e1d":"# *Cats vs Dogs using InceptionV3*","4b7a2be2":"### *Lets see how well our model predicts for some new data*","049b8c42":"### *Resizing  all the Image , just to visualize it in a neat manner*","218e41a3":"### *Visualizing How well this Big guy has learnt*","0d8adfcc":"![image.png](attachment:d20e290d-1016-494b-a4a7-0d8953bdabde.png)","30a7ba10":"### *Training the Gigantic model* ","f86233b9":"### *Data augmentation*","49056ff2":"### *Create new dir for training and validation images*","8b1c126b":"### *Importing the Libraries*","6b63b6c8":"### *lets load the pretrained weights of inception_v3 so our training would be easy and gets well fit within few epochs*","f3a9e094":"## *The results from this model are great, it predicted super fine to these images, As I intendedly chose some images where it would fall as prey but it survived. We can  further Visualize how the model identified it to be a cat using saliency maps later .* ","ab4d1f77":"### *So i got some images of cats and dogs from google*","08b87357":"### *Creating our custom model on top inception_v3's last_layer to suit our model requirement for binary classification*","2ac46861":"### *Training InceptionV3 would eat up a day for training , so lets utilize GPU*","82f9408d":"### *Seeing the above visualization the model has both training and validation accuracy closer to 98% , And there is a lot of Noise seeing the visuals. Training was good where the accuracy seems to be growing inverted to the loss while the validation accuracy and loss has to drastic improvement compared to training. accuracy chart hides the models overfit while the loss chart clearly shows overfitting of the model*","aa180fe9":"### *Split the cats and dogs images for Training and Testing*","5c1ce38b":"### *Visualize the Provided images from our Training data drawn at random*"}}