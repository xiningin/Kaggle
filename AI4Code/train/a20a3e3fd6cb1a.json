{"cell_type":{"11511c30":"code","391969ce":"code","640f4ccc":"code","fd778817":"code","b2c3487d":"code","b47346d3":"code","cbfcbbf7":"code","315e2a8a":"code","22ad63d6":"code","8f6d024f":"code","ac518963":"code","cd10ac46":"code","8f9a5f1e":"code","92cc3499":"code","e1be0f53":"code","3d0a8d70":"code","a0f71bf9":"code","282d1cdf":"code","8a743ab1":"code","94771f73":"code","a7a4cc89":"code","f00d7060":"code","09d8f9b4":"code","e569eecc":"code","9ca8713f":"code","69a3bd01":"code","d8863465":"markdown","e7dabd60":"markdown","b63f879a":"markdown","56aee108":"markdown","6ff69636":"markdown","529f706c":"markdown","d246b6c7":"markdown","b0abeba6":"markdown","2411aa83":"markdown","359439dd":"markdown","8487d75e":"markdown","1ef9dee1":"markdown","6709be92":"markdown","76d723f8":"markdown"},"source":{"11511c30":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport tensorflow as tf\nimport itertools\nimport keras\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.applications import ResNet50\nfrom keras.applications import imagenet_utils\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img","391969ce":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","640f4ccc":"len(train.columns)","fd778817":"train['label'].unique()","b2c3487d":"train.shape","b47346d3":"test.shape","cbfcbbf7":"train.info()","315e2a8a":"train.head()","22ad63d6":"# reshape the first row of \"train\" into a 28 x 28 photo, excluding the \"label\" column\nnum1 = np.array(train.loc[0][1:]).reshape(28,28)\nprint(num1)","8f6d024f":"# display the image in a heatmap\nsns.heatmap(data=num1,cmap=\"gray\")","ac518963":"# display the next image in the train set using the same process as above\nnum2 = np.asarray(train.loc[1][1:]).reshape(28,28)\nsns.heatmap(num2,cmap=\"gray\")","cd10ac46":"nptrain = np.array(train)\nplt.figure(figsize=(3,4))\nfor j in range(10):\n    for i in range(len(nptrain)):\n        if nptrain[i][0] == j:\n            plt.subplot(3,4,j+1)\n            plt.imshow(nptrain[i][1:].reshape(28,28), interpolation='nearest')\n            plt.title(j)\n            break\nplt.show()","8f9a5f1e":"# create a countplot of the amount of times each number, or label, appears in the data\nsns.countplot(x=train[\"label\"],data=train,palette=\"magma\")\nplt.title(\"Distribution of Numbers\")\nplt.xlabel(\"Image Number\")\nplt.ylabel(\"Count\")","92cc3499":"# Load data\ny = train[\"label\"]\nx = train.drop(labels = [\"label\"], axis = 1) \n\n# Reshape data\nx = x.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","e1be0f53":"from sklearn.model_selection import train_test_split\n\n# Prepare training\/validation sets\nx_training, x_validation, y_training, y_validation = train_test_split(x,\n                                                                      y,\n                                                                      test_size=0.33,\n                                                                      shuffle=True)","3d0a8d70":"# Our neural network will categorize the best when we one hot encode all the targe values into 10 separate columns of 1's and 0's versus having 1 column with 10 possible values.\ny_training = to_categorical(y_training, num_classes = 10)\ny_validation = to_categorical(y_validation, num_classes = 10)","a0f71bf9":"from keras.preprocessing.image import ImageDataGenerator\n\n# Data augmentation\ndata_generator = ImageDataGenerator(rescale=1.\/255,\n                                    rotation_range=0.3,\n                                    zoom_range=0.15, \n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1)\ndata_generator.fit(x_training)","282d1cdf":"# Creates iterator to be used in fit_generator\ndatagen_iterator = data_generator.flow(x_training,y_training)","8a743ab1":"# This defines the Convolutional Neural Network and determines it's architecture\nmodel = Sequential()\n# First convolutional Layer\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\n# Second Convolutional Layer\nmodel.add(Conv2D(64,(3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\n# Third Convolutional Layer\nmodel.add(Conv2D(128,(3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\n# Flattens everything for the dense model\nmodel.add(Flatten())\n# Dense layer\nmodel.add(Dense(128, activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))\n# Output layer\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(),metrics=['accuracy'])","94771f73":"# This sets the batch size, number of epochs, and number of predicted classes for the future code block.\nbatch_size = 64\nepochs = 20","a7a4cc89":"# This code actually fits the model to the training set. Note: it does not use the data transformations specified above:\n# training_model_history = model.fit(x_training, y_training, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_validation, y_validation))","f00d7060":"model_history = model.fit_generator(datagen_iterator, epochs = epochs, validation_data = (x_validation, y_validation),\n                      verbose = 2, steps_per_epoch=x_training.shape[0] \/\/ batch_size)","09d8f9b4":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nfig.set_figwidth(20)\nfig.set_figheight(12)\nax[0].plot(model_history.history['loss'], color='orange', label=\"Training loss\")\nax[0].plot(model_history.history['val_loss'], color='green', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(model_history.history['accuracy'], color='orange', label=\"Training accuracy\")\nax[1].plot(model_history.history['val_accuracy'], color='green',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","e569eecc":"# This code block will print a confusion matrix for us\n\n# Predict the values from the validation dataset\ny_valid_pred = model.predict(x_validation)\ny_valid_pred = np.argmax(y_valid_pred,axis = 1)\ny_true = np.argmax(y_validation,axis = 1) \n# compute the confusion matrix\ncm = confusion_matrix(y_true, y_valid_pred) \n\nfigure = plt.figure(figsize=(20,12))\n\nplt.imshow(cm, cmap=plt.cm.Greens)\nplt.title(\"Confusion Matrix\")\nplt.colorbar()\nclasses = range(10)\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\n# this code displays the numbers using itertools and changes the font to white if any\n# humber is greater than half of the highest possible of each square - makes it more readable.\nthresh = cm.max() \/ 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","9ca8713f":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","69a3bd01":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_baseline.csv\",index=False)","d8863465":"# Understanding Data","e7dabd60":"### Looking at model performance","b63f879a":"### One Hot Encoding the Target Values","56aee108":"# Initial CNN Implementation","6ff69636":"# CNN Architecture and Training","529f706c":"## Examining Distributions of Categories in Train Data","d246b6c7":"### Train-Test Split","b0abeba6":"## Displaying Examples of Images","2411aa83":"### Reshaping Data","359439dd":"# Augmented CNN Implementation","8487d75e":"### Data Augmentation","1ef9dee1":"# Submitting Predictions on Test Set","6709be92":"# Preprocessing","76d723f8":"The train data is comprised of images with 784 pixels and a 'target' column, which has 10 possible values (hand-written digits), each ranging from 0 to 9."}}