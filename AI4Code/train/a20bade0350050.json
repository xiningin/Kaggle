{"cell_type":{"0ce61bd4":"code","6d831bb8":"code","b9a50fdc":"code","b0f66af5":"code","666eb781":"code","68c72786":"code","02a6764a":"code","2a219edb":"code","8ee9281c":"code","6748b5a5":"code","c0ee3677":"code","8ececb54":"code","4c45000e":"code","4b68a8af":"code","8fac5e7f":"code","124fdd4c":"code","c7581ce4":"code","d627cbbc":"code","96273dab":"markdown","a8418fc0":"markdown","4c5469ef":"markdown"},"source":{"0ce61bd4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d831bb8":"file_path = '..\/input\/bitcoin-tweets\/Bitcoin_tweets.csv'\n\ndf = pd.read_csv(file_path, sep=',')\n\ndf.head()","b9a50fdc":"# Let's limit the tweets to the following sources : Twitter Web App, Twitter Android, Twitter iPhone\nsources = ['Twitter Web App', 'Twitter for Android ', 'Twitter for iPhone']\ndf = df[df.source.isin(sources)]","b0f66af5":"# Let's format the user_verified column : convert to string & replace by 1 if true and 0 otherwise\nfunc = lambda x: 1 if x=='True' else 0\n\ndf['user_verified'] = df['user_verified'].map(lambda x:func(str(x)))","666eb781":"df.user_verified.value_counts()","68c72786":"df.drop(columns=['is_retweet','user_friends','user_favourites','source'], inplace=True)","02a6764a":"df_verified = df[df.user_verified==1]\ncols = ['user_description', 'text', 'hashtags']\npd.set_option('max_colwidth', None)\ndf_verified[df_verified.user_verified==1][cols]","2a219edb":"# Let's preprocess the tweets\n\nimport re \nimport nltk\n\n# Import nltk stopwords and customize it to add common crypto words that don't add too much information \nstopwords = nltk.corpus.stopwords.words('english')\ncrypto_words = ['btc','bitcoin','eth','etherum','crypto']\n\nstopwords = stopwords + crypto_words\n\ndef preprocess_tweet(tweet, stopwords):\n    \n    tweet = tweet.lower()\n    \n    tweet = tweet.replace('\\n\\n',' ')\n    \n    # remove english stopwords\n    tweet = ' '.join([word for word in tweet.split() if word not in stopwords])\n    \n    # regular expression that preprocess tweets\n    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)\",\" \", tweet).split())\n    \n    return tweet","8ee9281c":"df_verified['preprocess_tweets'] = df_verified['text'].map(lambda x:preprocess_tweet(x, stopwords=stopwords))","6748b5a5":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef words_cloud(df, col):\n    \n    text = ' '.join(str(comment) for comment in df[col])\n    \n    wordcloud = WordCloud(stopwords=stopwords, width=800, height=400, background_color=\"white\",max_words=70).generate(text)\n    \n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.rcParams['figure.figsize'] = (20, 20)\n    plt.axis(\"off\")\n    plt.show()\n\nwords_cloud(df_verified, 'preprocess_tweets')","c0ee3677":"import itertools\n\ndef vocab(df, col, nb_words, stopwords):\n    \n    vocab = df[col].str.split(expand=True).stack().value_counts().head(50).to_dict()\n    \n    vocab_sw = {key:value for (key,value) in vocab.items() if key not in stopwords}\n   \n    return dict(itertools.islice(vocab_sw.items(), nb_words))\n   \n   \n   \ndef plot_words(vocab):\n    \n    plt.rcParams['figure.figsize'] = (20, 10)\n    plt.show()\n\n    plt.xlim(0,len(vocab))\n    plt.xticks(rotation=90,fontsize=14)\n    plt.bar(vocab.keys(), vocab.values(), width=0.3, color='g')","8ececb54":"plot_words(vocab(df_verified, 'preprocess_tweets', 40, stopwords))","4c45000e":"from transformers import pipeline\n\nclassifier = pipeline('sentiment-analysis')","4b68a8af":"# test on a single tweet\nclassifier('Ark Invest believes Tesla\u2019s purchase of billions in bitcoin is a tipping point for the digital asset as it relates')","8fac5e7f":"def get_sentiment_score(tweet):\n    return classifier(tweet)[0]['score']\n\ndef get_sentiment_label(tweet):\n    return classifier(tweet)[0]['label']\n\ndf_verified['sentiment_score'] = df_verified['preprocess_tweets'].map(lambda x:get_sentiment_score(x))\ndf_verified['sentiment_label'] = df_verified['preprocess_tweets'].map(lambda x:get_sentiment_label(x))","124fdd4c":"df_verified[['preprocess_tweets','sentiment_score','sentiment_label']]","c7581ce4":"df_verified.sentiment_score.describe()","d627cbbc":"df_verified.sentiment_label.value_counts(normalize=True)","96273dab":"### Let's explore the user descriptions, their tweets and hashtags. Let's limit the exploration to the verified users","a8418fc0":"## Sentiment Analysis\n\nLet's use the transformers pretrained model","4c5469ef":"----"}}