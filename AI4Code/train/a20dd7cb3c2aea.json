{"cell_type":{"e4d4b338":"code","79152659":"code","dc7945f3":"code","0d51e169":"code","d071942d":"code","b199b69f":"code","0aa2b137":"code","544462b8":"code","199fab79":"code","dd8ab33c":"code","665fdd76":"code","9285067d":"code","d0007f39":"code","bb2cc54f":"code","0206f834":"code","bb13b606":"code","e6e20f91":"code","d63a8dc6":"code","69593b2a":"code","607ead1b":"code","9a68c530":"code","45dd3818":"markdown","d0b53bcd":"markdown","abcb184e":"markdown","4413b53d":"markdown","9fcd461e":"markdown","b06cbf8c":"markdown","e6938930":"markdown","78d7504f":"markdown","20d10de5":"markdown","acdd4d9a":"markdown","56b1500b":"markdown"},"source":{"e4d4b338":"#Imports for full program Exceution\n#For Data handling\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\n#Import sklearn pakages for modeling the data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor","79152659":"#Load the dataset check its structure\n# url = \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/cpu-performance\/machine.data\"\ncolumn_names = ['Vendor_Name', 'Model_Name', 'MYCT', 'MMIN', 'MMAX', 'CACH','CHMIN','CHMAX', 'PRP', 'ERP']\ndf = pd.read_csv('..\/input\/machinedata\/machine.data', names=column_names)\ndf.shape\ndf.info()","dc7945f3":"#Checking if any null values\ndf.isnull().sum()","0d51e169":"#Checking Data\ndf.head()","d071942d":"#To handle null value need to check correlation before loosing important data\n#To Check correlation all data should be nominal converting categorical to numerical and showing relation\n#Using sklearn preprocessing to encode\ndata=df\nfrom sklearn import preprocessing\n\nvendor=preprocessing.LabelEncoder()\nvendor.fit(data.Vendor_Name.unique())\ndata['Vendor_Name']=vendor.transform(data['Vendor_Name'])\nmodel=preprocessing.LabelEncoder()\nmodel.fit(data.Model_Name.unique())\ndata['Model_Name']=model.transform(data['Model_Name'])\n\ndata.corr()","b199b69f":"####################### Splitting Data ##############################################\n\n#preparing list to compare all models\nModel_Compare = [[]]\n\n#Feature Extraction As Vendor_Name and Model_Name don't have strong correlation with ERP\nfeature_list = ['MYCT', 'MMIN', 'MMAX', 'CACH','CHMIN','CHMAX', 'PRP']\n#prepare train and test data, taken 80% of Training Data and 20% of Test Data\nX_feature=data[feature_list]\nY_label=data.ERP\n\nX_feature_train,X_feature_test,Y_label_train,Y_label_test=train_test_split(X_feature,Y_label,test_size=0.2, \n                                     random_state=42, shuffle=True)\n\nprint('X_feature_training_set : ', X_feature_train.shape)\nprint('X_feature_test_set : ', X_feature_test.shape)\nprint('Y_label_train_set :', Y_label_train.shape) \nprint('Y_label_test_set : ', Y_label_test.shape)\n\n####################### Linear Regression Model ##############################################\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_feature_train,Y_label_train)\n\n#Make predictions\nY_pred = lin_reg.predict(X_feature_train)\n\nlr_r2_score = r2_score(Y_label_train,Y_pred)\n\n#Testing Score\ntest_score = lin_reg.score(X_feature_test, Y_label_test)\n\nprint('\\n'+16*'-'+\"Linear Regression:\"+16*'-')\nprint(\"R^2 score for lin_reg training set: %.2f\"%lr_r2_score)\nprint(\"Test-set score:\",test_score)\n\n\nModel_Compare[0] = ['Linear Regression', round(lr_r2_score, 3), round(test_score,3)]\n#print(Model_Compare)\n\n####################### Random Forest Model ##############################################\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(X_feature_train,Y_label_train)\n\n#Make predictions\nY_pred = forest_reg.predict(X_feature_train)\n\n\n#Calculating r2 score\nforest_r2_score = r2_score(Y_label_train,Y_pred)\n\n#Testing score\ntest_score = forest_reg.score(X_feature_test, Y_label_test)\n\nprint('\\n'+18*'-'+'Random Forest:'+18*'-')\nprint(\"R^2 score for forest training set: %.2f\"%forest_r2_score)\nprint(\"Test-set score:\",forest_reg.score(X_feature_test, Y_label_test))\n\nModel_Compare.append(['Random Forest', round(forest_r2_score, 3), round(test_score,3)])\n\n####################### Printing models comparision table ####################################\nprint('\\n'+7*'-'+'Model || With True Data || Result-1:'+7*'-')\n# Comparision_Table = Comparision_Table[1:]\nComparision_Table = DataFrame(Model_Compare, columns=['Model','R2 Score','Test-Score'])\nprint(Comparision_Table)","0aa2b137":"#As dataset is not having any null values imputing null values to explain importance of preprocessing of null value handling\nimport random\n\n# for col in df:\nfor col in df[['MYCT', 'MMIN', 'MMAX','CHMIN','CHMAX', 'PRP']]:\n    ori_rat = df[col].isna().mean()\n    ran = random.randint(0,15)\/100\n#     print(ran)\n    if ori_rat >= ran: continue\n\n    add_miss_rat = (ran - ori_rat) \/ (1 - ori_rat)\n    vals_to_nan = df[col].dropna().sample(frac=add_miss_rat).index\n    df.loc[vals_to_nan, col] = np.NaN\n\n\n#Putting random range cache memory in kilobytes negetive\n# df.CACH = df.apply(lambda x: (x.CACH*(-1))  if (x.CACH < 0 and x.CACH < 5) else x.CACH, axis=1)\ndf.CACH = df.apply(lambda x: (x.CACH*(-1))  if (x.CACH < 5) else x.CACH, axis=1)\n\n#Putting machine cycle time in nanoseconds as 0\ndf.MYCT = df.MYCT.replace(50, 0)","544462b8":"# There are two types of null\n# 1) Explicit [Using df dataset]\n# 2) Implicit [Using df_1]\ndf_1=df","199fab79":"# Checking Implicit nulls, So, we can put NaN values instead of unrealistic values and then\n# Next stage while handling explicit nulls it will be tackeled\n\ndf_1.describe()","dd8ab33c":"#Here we can see that CACH [cache memory in kilobytes] having negetive values\n#Cache memmory can be in negetive? Obviously not. So, putting null inplace of those\ndf_1.CACH = df.apply(lambda x: np.NaN if (x.CACH < 0) else x.CACH, axis=1)\n\n#Here we can see that MYCT [machine cycle time in nanoseconds] having value 0\n#It impossible, right?\ndf_1.MYCT = df.apply(lambda x: np.NaN if (x.MYCT == 0) else x.MYCT, axis=1)","665fdd76":"#Now checking explicit nulls\n(df_1.isnull().sum()).sort_values(ascending=False)","9285067d":"#Putting mean inplace of CACH and MYCT\ndf_1['CACH'] = df_1['CACH'].fillna(df_1['CACH'].mean())\ndf_1['MYCT'] = df_1['MYCT'].fillna(df_1['MYCT'].mean())","d0007f39":"#We have 209 rows only as resulted by df.shape, So ommision method is not economical here it will loose our data\n#Now, Here corr() method will give an idea, we can impute the value? Corr willapply only on numerical data \n#Our dataset has 2 columns with Categorical data lets convert those to numerical using encoding\n\nfrom sklearn import preprocessing\n\nvendor=preprocessing.LabelEncoder()\nvendor.fit(df_1.Vendor_Name.unique())\ndf_1['Vendor_Name']=vendor.transform(df_1['Vendor_Name'])\nmodel=preprocessing.LabelEncoder()\nmodel.fit(data.Model_Name.unique())\ndf_1['Model_Name']=model.transform(df_1['Model_Name'])\n\n\ndf_1.corr()","bb2cc54f":"#Top correletions with missing values\nfeature_list=df_1.corr()['MYCT'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'MYCT'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df_1.corr()['MMIN'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'MMIN'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df_1.corr()['MMAX'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'MMAX'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df_1.corr()['CHMIN'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'CHMIN'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df_1.corr()['CHMAX'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'CHMAX'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df_1.corr()['PRP'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'PRP'+10*'-'+'\\n',feature_list[1:2])","0206f834":"#Here MYCT [machine cycle time in nanoseconds] doesn't have any strong correlation\n#So we can put median in place of nulls [Popularity] -> Mean doesn't make sense as cycles can be in integer\ndf_1['MYCT'] = df_1['MYCT'].fillna(df_1['MYCT'].median())\n                               \n\n#Two features MMIN [minimum main memory in kilobytes] imputing with mean\ndf_1['MMIN'] = df_1['MMIN'].fillna(df_1['MMIN'].mean())\n               \n#CHMIN [Minimum channels in units] and CHMAX [maximum channels in units] with interpolation is good\nInter_cols = ['CHMIN', 'CHMAX']\nfor x in Inter_cols:\n    df_1.loc[:, x] = df_1.loc[:, x].interpolate()\n\n#Now PRP [published relative performance] and MMAX [maximum main memory in kilobytes] are highly correlated with ERP\n#grouping by Vendor_Name, plotting mean of each respectively\ndf_1[\"PRP\"] = df_1.groupby(\"Vendor_Name\").transform(lambda x: x.fillna(x.mean()))\ndf_1[\"MMAX\"] = df_1.groupby(\"Vendor_Name\").transform(lambda x: x.fillna(x.mean()))\n\n#If still any null values, drop it. Called Omission\ndf_1 = df_1.dropna()\n\n(df_1.isnull().sum()).sort_values(ascending=False)","bb13b606":"#Now, we don't have any inexplicit Nulls\n#Lets check Model accuracy\n####################### Splitting Data ##############################################\n\n#preparing list to compare all models\nModel_Compare2 = [[]]\ndata=df_1\n\nfeature_list = ['MYCT', 'MMIN', 'MMAX', 'CACH','CHMIN','CHMAX', 'PRP']\n#prepare train and test data, taken 80% of Training Data and 20% of Test Data\nX_feature=data[feature_list]\nY_label=data.ERP\n\nX_feature_train,X_feature_test,Y_label_train,Y_label_test=train_test_split(X_feature,Y_label,test_size=0.2, \n                                     random_state=42, shuffle=True)\n\nprint('X_feature_training_set : ', X_feature_train.shape)\nprint('X_feature_test_set : ', X_feature_test.shape)\nprint('Y_label_train_set :', Y_label_train.shape) \nprint('Y_label_test_set : ', Y_label_test.shape)\n\n####################### Linear Regression Model ##############################################\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_feature_train,Y_label_train)\n\n#Make predictions\nY_pred = lin_reg.predict(X_feature_train)\n\nlr_r2_score = r2_score(Y_label_train,Y_pred)\n\n#Testing Score\ntest_score = lin_reg.score(X_feature_test, Y_label_test)\n\nprint('\\n'+16*'-'+\"Linear Regression:\"+16*'-')\nprint(\"R^2 score for lin_reg training set: %.2f\"%lr_r2_score)\nprint(\"Test-set score:\",test_score)\n\n\nModel_Compare2[0] = ['Linear Regression', round(lr_r2_score, 3), round(test_score,3)]\n\n####################### Random Forest Model ##############################################\nforest_reg = RandomForestRegressor()\nforest_reg.fit(X_feature_train,Y_label_train)\n\n#Make predictions\nY_pred = forest_reg.predict(X_feature_train)\n\n\n#Calculating r2 score\nforest_r2_score = r2_score(Y_label_train,Y_pred)\n\n#Testing score\ntest_score = forest_reg.score(X_feature_test, Y_label_test)\n\nprint('\\n'+18*'-'+'Random Forest:'+18*'-')\nprint(\"R^2 score for forest training set: %.2f\"%forest_r2_score)\nprint(\"Test-set score:\",forest_reg.score(X_feature_test, Y_label_test))\n\nModel_Compare2.append(['Random Forest', round(forest_r2_score, 3), round(test_score,3)])\n\n\n####################### Printing models comparision table ####################################\n# Comparision_Table = Comparision_Table[1:]  Model || With Inexplict Null Handled Data || Result - 2\nprint('\\n'+2*'-'+'Model || Inexplicit Tackeled Data || Result-2:'+2*'-')\nComparision_Table_2 = DataFrame(Model_Compare2, columns=['Model','R2 Score','Test-Score'])\nprint(Comparision_Table_2)\n","e6e20f91":"#Taking processing only explicit nulls\n#Load the dataset check its structure\n# url = \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/cpu-performance\/machine.data\"\ncolumn_names = ['Vendor_Name', 'Model_Name', 'MYCT', 'MMIN', 'MMAX', 'CACH','CHMIN','CHMAX', 'PRP', 'ERP']\ndf = pd.read_csv('..\/input\/machinedata\/machine.data', names=column_names)\n#df.shape\n#df.info()\n\n#As dataset is not having any null values imputing null values to explain importance of preprocessing of null value handling\nimport random\n\n# for col in df:\nfor col in df[['MYCT', 'MMIN', 'MMAX','CHMIN','CHMAX', 'PRP']]:\n    ori_rat = df[col].isna().mean()\n    ran = random.randint(0,15)\/100\n#     print(ran)\n    if ori_rat >= ran: continue\n\n    add_miss_rat = (ran - ori_rat) \/ (1 - ori_rat)\n    vals_to_nan = df[col].dropna().sample(frac=add_miss_rat).index\n    df.loc[vals_to_nan, col] = np.NaN\n\n\n#Putting random range cache memory in kilobytes negetive\n# df.CACH = df.apply(lambda x: (x.CACH*(-1))  if (x.CACH < 0 and x.CACH < 5) else x.CACH, axis=1)\ndf.CACH = df.apply(lambda x: (x.CACH*(-1))  if (x.CACH < 5) else x.CACH, axis=1)\n\n#Putting machine cycle time in nanoseconds as 0\ndf.MYCT = df.MYCT.replace(50, 0)\n\n(df.isnull().sum()).sort_values(ascending=False)","d63a8dc6":"#Top correletions with missing values\nfeature_list=df.corr()['MYCT'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'MYCT'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df.corr()['MMIN'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'MMIN'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df.corr()['MMAX'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'MMAX'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df.corr()['CHMIN'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'CHMIN'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df.corr()['CHMAX'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'CHMAX'+10*'-'+'\\n',feature_list[1:2])\n\nfeature_list=df.corr()['PRP'].abs().sort_values(kind=\"quicksort\",ascending=False)\nprint('\\n\\n'+10*'-'+'PRP'+10*'-'+'\\n',feature_list[1:2])","69593b2a":"#Here MYCT [machine cycle time in nanoseconds] doesn't have any strong correlation\n#So we can put median in place of nulls [Popularity] -> Mean doesn't make sense as cycles can be in integer\ndf['MYCT'] = df['MYCT'].fillna(df['MYCT'].median())\n                               \n\n#Two features MMIN [minimum main memory in kilobytes] imputing with mean\ndf['MMIN'] = df['MMIN'].fillna(df['MMIN'].mean())\n               \n#CHMIN [Minimum channels in units] and CHMAX [maximum channels in units] with interpolation is good\nInter_cols = ['CHMIN', 'CHMAX']\nfor x in Inter_cols:\n    df.loc[:, x] = df.loc[:, x].interpolate()\n\n#Now PRP [published relative performance] and MMAX [maximum main memory in kilobytes] are highly correlated with ERP\n#grouping by Vendor_Name, plotting mean of each respectively\ndf[\"PRP\"] = df.groupby(\"Vendor_Name\").transform(lambda x: x.fillna(x.mean()))\ndf[\"MMAX\"] = df.groupby(\"Vendor_Name\").transform(lambda x: x.fillna(x.mean()))\n\n#If still any null values, drop it. Called Omission\n# df = df.dropna()\n\n(df.isnull().sum()).sort_values(ascending=False)\n","607ead1b":"#Now, we don't have any explicit Nulls\n#Lets check Model accuracy\n\n####################### Splitting Data ##############################################\n\n#preparing list to compare all models\nModel_Compare1 = [[]]\n# data=df\n\nfeature_list = ['MYCT', 'MMIN', 'MMAX', 'CACH','CHMIN','CHMAX', 'PRP']\n#prepare train and test data, taken 80% of Training Data and 20% of Test Data\nX_feature=data[feature_list]\nY_label=data.ERP\n\nX_feature_train,X_feature_test,Y_label_train,Y_label_test=train_test_split(X_feature,Y_label,test_size=0.2, \n                                     random_state=42, shuffle=True)\n\nprint('X_feature_training_set : ', X_feature_train.shape)\nprint('X_feature_test_set : ', X_feature_test.shape)\nprint('Y_label_train_set :', Y_label_train.shape) \nprint('Y_label_test_set : ', Y_label_test.shape)\n\n####################### Linear Regression Model ##############################################\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_feature_train,Y_label_train)\n\n#Make predictions\nY_pred = lin_reg.predict(X_feature_train)\n\nlr_r2_score = r2_score(Y_label_train,Y_pred)\n\n#Testing Score\ntest_score = lin_reg.score(X_feature_test, Y_label_test)\n\nprint('\\n'+16*'-'+\"Linear Regression:\"+16*'-')\nprint(\"R^2 score for lin_reg training set: %.2f\"%lr_r2_score)\nprint(\"Test-set score:\",test_score)\n\n\nModel_Compare1[0] = ['Linear Regression', round(lr_r2_score, 3), round(test_score,3)]\n#print(Model_Compare)\n\n####################### Random Forest Model ##############################################\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(X_feature_train,Y_label_train)\n\n#Make predictions\nY_pred = forest_reg.predict(X_feature_train)\n\n\n#Calculating r2 score\nforest_r2_score = r2_score(Y_label_train,Y_pred)\n\n#Testing score\ntest_score = forest_reg.score(X_feature_test, Y_label_test)\n\nprint('\\n'+18*'-'+'Random Forest:'+18*'-')\nprint(\"R^2 score for forest training set: %.2f\"%forest_r2_score)\nprint(\"Test-set score:\",forest_reg.score(X_feature_test, Y_label_test))\n\nModel_Compare1.append(['Random Forest', round(forest_r2_score, 3), round(test_score,3)])\n\n####################### Printing models comparision table ####################################\nprint('\\n'+3*'-'+'Model || Explicit Null Free Data || Result-3:'+3*'-')\n# Comparision_Table = Comparision_Table[1:]\nComparision_Table_1 = DataFrame(Model_Compare1, columns=['Model','R2 Score','Test-Score'])\nprint(Comparision_Table_1)","9a68c530":"print('\\n'+7*'-'+'Result-1 || With Actual Data:'+7*'-')\n# Comparision_Table = Comparision_Table[1:]\nComparision_Table = DataFrame(Model_Compare, columns=['Model','R2 Score','Test-Score'])\nprint(Comparision_Table)\n\n\nprint('\\n'+3*'-'+'Result-2 || Inexplicit Tackeled Data:'+2*'-')\nComparision_Table_2 = DataFrame(Model_Compare2, columns=['Model','R2 Score','Test-Score'])\nprint(Comparision_Table_2)\n\nprint('\\n'+3*'-'+'Result-3: || Explicit Null Free Data:'+3*'-')\n# Comparision_Table = Comparision_Table[1:]\nComparision_Table_1 = DataFrame(Model_Compare1, columns=['Model','R2 Score','Test-Score'])\nprint(Comparision_Table_1)","45dd3818":"### Model || With Only Explict Null Handled Data || Result - 3","d0b53bcd":"To coclude, it is always better to do Inexplicit null handling as a step of preprocessing.\nHere, small amount of data is there, though Inexplicit has slightly better accuracy. In large dataset if we don't do it, model will become vague and with no stastical power.","abcb184e":"Creating model and taking R^2 and Test score for comparing all three results.\nWhat if we don't tackele implic and explit nulls?\nFor 'Model || With True Data || Result-1' => Model_Compare [Result]","4413b53d":"What if we only handle explicit nulls and leave implicit nulls in the dataset?","9fcd461e":"As this dataset doesn't have any null value, randomly putting null and erroneous values to get the result after fixing it, and comapre. To understand the importance of null value handling.","b06cbf8c":"### Missing values handling","e6938930":"##### Dataset Information\nComputer Hardware Data Set: The estimated relative performance values using below features.\n\n##### Attribute Information\n1. Vendor name: 30\n(adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec,\ndg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson,\nmicrodata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry,\nsratus, wang)\n2. Model Name: many unique symbols\n3. MYCT: machine cycle time in nanoseconds (integer)\n4. MMIN: minimum main memory in kilobytes (integer)\n5. MMAX: maximum main memory in kilobytes (integer)\n6. CACH: cache memory in kilobytes (integer)\n7. CHMIN: minimum channels in units (integer)\n8. CHMAX: maximum channels in units (integer)\n9. PRP: published relative performance (integer)\n10. ERP: estimated relative performance from the original article (integer)\n\nDataset taking from:UCI Repository","78d7504f":"### Comparision of All Three","20d10de5":"### Model || With Inexplict Null Handled Data || Result - 2","acdd4d9a":"### Model || With True Data || Result - 1","56b1500b":"#### Randomly putting null values"}}