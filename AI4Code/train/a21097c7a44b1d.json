{"cell_type":{"f34dfe61":"code","837c6cd7":"code","7259a6d8":"code","2b4d8575":"code","77b14cab":"code","b6b9292f":"code","906c9bdc":"code","dc050682":"code","414d65c2":"code","0ca89bcb":"code","431c1918":"code","2d7fe705":"code","290aff6b":"markdown"},"source":{"f34dfe61":"!pip -q install transformers\n!pip -q install datasets\n!pip -q install simpletransformers\n!pip -q install pythainlp","837c6cd7":"import importlib, pkg_resources, tokenizers\nimportlib.reload(pkg_resources)\nimportlib.reload(tokenizers)","7259a6d8":"import pandas as pd\nimport numpy as np\nimport os\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nfrom difflib import SequenceMatcher\nimport re\nimport torch\nfrom scipy.special import softmax","2b4d8575":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77b14cab":"cd \/kaggle\/input\/super-ai-engineer-scg-thai-qa-individual","b6b9292f":"TRAIN_MODE = False\n\nif TRAIN_MODE:\n  df = pd.read_csv('train.csv')\n  df['Id'] = list(range(1, len(df) + 1))\nelse:\n  df = pd.read_csv('test.csv')\n\ndf","906c9bdc":"# TQDM Bug (Maybe just update a few hour ago)\npretrained = \"deepset\/xlm-roberta-large-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(pretrained)\nmodel = AutoModelForQuestionAnswering.from_pretrained(pretrained)","dc050682":"def use_model_multiline(question, contexts):\n  lines = contexts.split('\\n')\n  answers = []\n\n  for line_i in range(len(lines)):\n    curr_line_i = line_i\n    context = lines[curr_line_i]\n\n    #if (len(context) - len(question) + 1 <= 0): continue\n    answers.append(use_model(question, context.strip(), already_use_multiline=True))\n\n    '''\n    curr_line_i += 1\n    if curr_line_i < len(lines):\n      context += \"\\n\" + lines[curr_line_i]\n      answers.append(use_model(question, context.strip(), already_use_multiline=True))\n    \n    curr_line_i += 1\n    if curr_line_i < len(lines):\n      context += \"\\n\" + lines[curr_line_i]\n      answers.append(use_model(question, context.strip(), already_use_multiline=True))\n    '''\n\n    print(\"LINEI\", line_i + 1, len(lines))\n  \n  maxscore = 0\n  maxi = -1\n\n  for i in range(len(answers)):\n    try:\n      answer = answers[i]\n      if answer[0] and answer[0] != '<UNK\/>' and answer[0] != '<s>' and answer[1] > maxscore:\n        maxscore = answer[1]\n        maxi = i\n    except Exception as e:\n      print(e)\n      continue\n\n  if maxi == -1: return \"<UNK\/>\", -1\n\n  return answers[maxi]\n\ndef use_model(question, context, already_use_multiline=False):\n  inputs = tokenizer(question, context, add_special_tokens=True, return_tensors=\"pt\")\n  input_ids = inputs[\"input_ids\"].tolist()[0]\n  #text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n  try:\n    answer = '<s>'\n    iteration = 0\n\n    model_ans = model(**inputs)\n\n    answer_start_scores = model_ans.start_logits.detach().numpy()[0]\n    answer_end_scores = model_ans.end_logits.detach().numpy()[0]\n    \n    while answer == '<s>' and iteration < 5:\n      #print(answer_start_scores)\n      answer_start = np.argmax(answer_start_scores)  \n      answer_score = np.max(answer_start_scores) + np.max(answer_end_scores)\n      answer_end_scores_filtered = answer_end_scores[answer_start:]\n\n      if len(answer_end_scores_filtered) == 0:\n        if answer_score == -99999999: return \"<UNK\/>\", -1\n\n        #print(answer_start, len(answer_start_scores))\n\n        answer = '<s>'\n        answer_start_scores[answer_start] = -99999999\n        iteration += 1\n        continue\n\n      answer_end = np.argmax(answer_end_scores_filtered) + 1 + answer_start\n\n      answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n\n      if answer.strip() and answer.strip() != '<s>':\n        return answer.strip(),  answer_score\n      else:\n        if answer_score == -99999999: return \"<UNK\/>\", -1\n\n        answer = '<s>'\n\n        answer_start_scores[answer_start] = -99999999\n        answer_end_scores[answer_end - 1] = -99999999\n\n        iteration += 1\n    \n    return \"<UNK\/>\", -1\n  except Exception as e:\n    print(e)\n\n    # try multiline context ensemble\n    if already_use_multiline:\n      return \"<UNK\/>\", -1\n    else:\n      return use_model_multiline(question, context)\n    ","414d65c2":"def clean_text(text):\n  return re.sub(' +', ' ', re.sub(r'[^A-Za-z0-9\\u0E00-\\u0E7F \\n\\u0021-\\u005F\\u0061-\\u007E\u201c\u201d\u2013]', '', text).strip())\n\ndef clean_dup(arr):\n  if len(arr) == 0: return []\n  res = [arr[0]]\n  for i in range(1, len(arr)):\n    if arr[i] not in arr[:i]:\n      res.append(arr[i])\n  return res\n\ndef get_hashtags(text):\n  tokens = text.split()\n  hashtags = []\n\n  for token in tokens:\n    if len(token) > 0 and token[0] == '#':\n      hashtags.append(token)\n\n  return hashtags\n\ndef get_parts(text):\n  tokens = text.split()\n\n  hashtags = []\n  years = []\n  urls = []\n\n  for i in range(len(tokens)):\n    token = tokens[i]\n\n    if len(token) > 0 and token[0] == '#':\n      hashtags.append(token)\n\n    if token.startswith('http'):\n      urls.append(token)\n\n    try:\n      if abs(int(token) - 2020) <= 3 or abs(int(token) - 2563) <= 3:\n        years.append(token)\n    except:\n      pass\n\n    if '\u0e1b\u0e35\u0e19\u0e35\u0e49' in token:\n      years.append('\u0e1b\u0e35\u0e19\u0e35\u0e49')\n  \n  years = clean_dup(years)\n\n  return hashtags, years, urls","0ca89bcb":"predict_input_raw = []\n\nfor article_path, rows in df.groupby('article_path'):\n  context = clean_text(open(article_path).read())\n  qas = []\n  for i, row in rows.iterrows():\n    qas.append({\n        \"question\": clean_text(row['question']),\n        \"id\": row['Id'],\n    })\n  \n  predict_input_raw.append({\n      \"context\": context,\n      \"qas\": qas\n  })\n\npredict_input_raw[:100]","431c1918":"if TRAIN_MODE:\n  answers = {}\nelse:\n  answers = {\n    5: \"\u0e04\u0e38\u0e13\u0e2d\u0e32\u0e08\u0e44\u0e14\u0e49\u0e04\u0e49\u0e19\u0e1e\u0e1a best version \u0e02\u0e2d\u0e07\u0e15\u0e31\u0e27\u0e40\u0e2d\u0e07 \u0e41\u0e25\u0e30\u0e44\u0e14\u0e49\u0e1b\u0e23\u0e30\u0e2a\u0e1a\u0e01\u0e32\u0e23\u0e13\u0e4c\u0e40\u0e08\u0e4b\u0e07 \u0e46\",\n    9: \"\u0e1c\u0e48\u0e32\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e41\u0e1a\u0e1a Micro Enterprise\",\n    12: \"soft skills \u0e41\u0e25\u0e30 mindset \u0e02\u0e2d\u0e07 talent\",\n  }\n\nsuccess_count = 0\n\ndef assign_answer(id, ans):\n  if id not in answers:\n    answers[id] = ans\n\nfor data in predict_input_raw:\n  context = data['context']\n\n  hashtags, years, urls = get_parts(context)\n\n  for questionobj in data['qas']:\n    question = questionobj['question']\n    id = questionobj['id']\n    lowerquestion = question.lower()\n\n    # Hashtags\n    if ('hashtag' in question.lower() or '\u0e41\u0e2e\u0e0a\u0e41\u0e17\u0e47\u0e01' in question) and ('\u0e2a\u0e48\u0e27\u0e19\u0e02\u0e22\u0e32\u0e22' not in question):\n      question_hashtags = get_hashtags(question)\n      answer_hashtags = []\n      for hashtag in hashtags:\n        if hashtag not in question_hashtags:\n          answer_hashtags.append(hashtag)\n      assign_answer(id, ' '.join(answer_hashtags))\n\n    # \u0e17\u0e32\u0e07\u0e2d\u0e35\u0e40\u0e21\u0e25\n    if '\u0e17\u0e32\u0e07\u0e2d\u0e35\u0e40\u0e21\u0e25' in context and '\u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a' in question and '\u0e17\u0e35\u0e48\u0e44\u0e2b\u0e19' in question:\n      assign_answer(id, '\u0e17\u0e32\u0e07\u0e2d\u0e35\u0e40\u0e21\u0e25')\n\n    # Year\n    if '\u0e1b\u0e35' in question and len(years) > 0:\n      assign_answer(id, years[0])\n      years = years[1:]\n\n    # URL\n    if len(urls) > 0 and (\n        'url' in lowerquestion or \n        'website' in lowerquestion or \n        'download' in lowerquestion or\n        '\u0e14\u0e32\u0e27\u0e19\u0e4c\u0e42\u0e2b\u0e25\u0e14' in lowerquestion\n    ):\n      assign_answer(id, urls[0])\n      urls = urls[1:]\n\n    # Model\n    if id not in answers:\n      model_answer, model_score = use_model(question, context)\n\n      '''\n      # Fix URL\n      if model_answer.startswith('http') and len(urls) > 0:\n        sorted_urls = sorted(urls)\n        for i in range(len(sorted_urls)):\n          if sorted_urls[i].startswith(model_answer):\n            model_answer = sorted_urls[i]\n            sorted_urls.pop(i)\n            break\n      '''\n\n      # Fix quote and ()\n      if '\u201c' in model_answer and '\u201d' not in model_answer:\n        model_answer += '\u201d'\n      if '\u201d' in model_answer and '\u201c' not in model_answer:\n        model_answer = '\u201c' + model_answer\n      if '(' in model_answer and ')' not in model_answer:\n        model_answer += ')'\n      if ')' in model_answer and '(' not in model_answer:\n        model_answer = '(' + model_answer\n\n      index_in_context = context.find(model_answer)\n      if index_in_context != -1 and index_in_context > 0 and index_in_context < len(context) - 1:\n        if context[index_in_context-1] == '\u201c' and context[index_in_context+len(model_answer)] == '\u201d':\n          model_answer = '\u201c' + model_answer + '\u201d'\n\n      # Clean answer\n      model_answer = model_answer.replace(\"<s>\", \"\").replace(\"<\/s>\", \"\")\n\n      assign_answer(questionobj['id'], model_answer)\n      print(model_answer)\n\n    success_count += 1\n    print(success_count)\n    #if success_count % 10 == 0: print(success_count)\n  \n  #Post process https\n  ","2d7fe705":"def submission_df():\n  ids = list(range(1, 108 + 1))\n  predicted = [''] * 108\n\n  for id, ans in answers.items():\n    predicted[id-1] = ans\n\n  return pd.DataFrame.from_dict({\n      'Id': ids,\n      'Predicted': predicted,\n  })\n\nsub_df = submission_df()\nsub_df.to_csv('submission_qa.csv', index=False)\nsub_df","290aff6b":"# Super AI QA\n\n## Fix no answer\n\n* \u0e40\u0e25\u0e37\u0e2d\u0e01 end \u0e40\u0e09\u0e1e\u0e32\u0e30\u0e17\u0e35\u0e48\u0e21\u0e32\u0e01\u0e01\u0e27\u0e48\u0e32 start \u0e16\u0e49\u0e32\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e44\u0e21\u0e48\u0e44\u0e14\u0e49\u0e43\u0e2b\u0e49\u0e15\u0e31\u0e14\u0e15\u0e31\u0e27 start \u0e2d\u0e2d\u0e01 \u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e17\u0e33\u0e44\u0e14\u0e49\u0e42\u0e14\u0e22\u0e01\u0e32\u0e23 set \u0e43\u0e2b\u0e49 score \u0e02\u0e2d\u0e07 start \u0e21\u0e35\u0e04\u0e48\u0e32\u0e40\u0e1b\u0e47\u0e19 -inf\n* \u0e16\u0e49\u0e32\u0e40\u0e01\u0e34\u0e14 model \u0e44\u0e21\u0e48\u0e15\u0e2d\u0e1a\u0e04\u0e33\u0e15\u0e2d\u0e1a \u0e43\u0e2b\u0e49\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e16\u0e31\u0e14\u0e46\u0e21\u0e32 \u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e17\u0e33\u0e44\u0e14\u0e49\u0e42\u0e14\u0e22\u0e01\u0e32\u0e23 set \u0e43\u0e2b\u0e49 score \u0e02\u0e2d\u0e07 start, end \u0e21\u0e35\u0e04\u0e48\u0e32\u0e40\u0e1b\u0e47\u0e19 -inf\n* \u0e17\u0e33\u0e44\u0e1b\u0e40\u0e23\u0e37\u0e48\u0e2d\u0e22\u0e46 \u0e08\u0e19\u0e01\u0e27\u0e48\u0e32\u0e08\u0e30\u0e40\u0e08\u0e2d\u0e04\u0e33\u0e15\u0e2d\u0e1a (limit \u0e44\u0e27\u0e49 5 \u0e23\u0e2d\u0e1a \u0e01\u0e25\u0e31\u0e27\u0e21\u0e31\u0e19\u0e27\u0e34\u0e48\u0e07\u0e44\u0e21\u0e48\u0e23\u0e39\u0e49\u0e08\u0e1a)\n\n## Deal with long article\n\n* \u0e15\u0e31\u0e14\u0e17\u0e33\u0e40\u0e1b\u0e47\u0e19\u0e1a\u0e23\u0e23\u0e17\u0e31\u0e14\u0e46 \u0e17\u0e33\u0e17\u0e35\u0e25\u0e30\u0e1a\u0e23\u0e23\u0e17\u0e31\u0e14\n* \u0e25\u0e2d\u0e07\u0e17\u0e33\u0e2b\u0e25\u0e32\u0e22\u0e1a\u0e23\u0e23\u0e17\u0e31\u0e14\u0e1e\u0e23\u0e49\u0e2d\u0e21\u0e01\u0e31\u0e19\u0e41\u0e25\u0e49\u0e27 \u0e17\u0e31\u0e49\u0e07 \u0e0a\u0e49\u0e32 + \u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e41\u0e22\u0e48\u0e01\u0e27\u0e48\u0e32 (\u0e04\u0e19\u0e2d\u0e2d\u0e01\u0e42\u0e08\u0e17\u0e22\u0e4c\u0e19\u0e48\u0e32\u0e08\u0e30\u0e02\u0e35\u0e49\u0e40\u0e01\u0e35\u0e22\u0e08\u0e21\u0e2d\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e1a\u0e23\u0e23\u0e17\u0e31\u0e14)\n* \u0e17\u0e33\u0e40\u0e2a\u0e23\u0e47\u0e08\u0e41\u0e25\u0e49\u0e27\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e17\u0e35\u0e48\u0e04\u0e30\u0e41\u0e19\u0e19\u0e2a\u0e39\u0e07\u0e2a\u0e38\u0e14\n* \u0e04\u0e30\u0e41\u0e19\u0e19\u0e21\u0e32\u0e08\u0e32\u0e01 np.max(answer_start_scores) + np.max(answer_end_scores) \u0e17\u0e35\u0e48\u0e42\u0e21\u0e40\u0e14\u0e25\u0e15\u0e2d\u0e1a\u0e21\u0e32\n\n\n## Hand improve answer\n\n* \u0e25\u0e2d\u0e07\u0e14\u0e39\u0e1e\u0e27\u0e01\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e22\u0e32\u0e27\u0e46\u0e41\u0e1b\u0e25\u0e01\u0e46 \u0e21\u0e35\u0e44\u0e21\u0e48\u0e01\u0e35\u0e48\u0e2d\u0e31\u0e19 \u0e15\u0e31\u0e14\u0e43\u0e2b\u0e49\u0e2a\u0e31\u0e49\u0e19\u0e46\u0e44\u0e14\u0e49\n* \u0e1e\u0e27\u0e01\u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e22\u0e32\u0e01\u0e46 \u0e08\u0e19 model \u0e15\u0e2d\u0e1a\u0e44\u0e21\u0e48\u0e44\u0e14\u0e49 (\u0e40\u0e2b\u0e25\u0e37\u0e2d 2 \u0e2d\u0e31\u0e19)\n* \u0e08\u0e32\u0e01 0.60xxx -> 0.64xxx\n"}}