{"cell_type":{"7f999903":"code","cf99e778":"code","c87128d6":"code","230cb114":"code","cf020f8e":"code","3f14d6be":"code","6a6deaf9":"code","0eb8a845":"code","8eaffc16":"code","2ab2ece4":"code","7aec9a64":"code","fc573079":"code","0da5fd35":"code","31bea3f0":"code","89d2cbfc":"code","75f04127":"code","ed490b60":"code","975503d2":"code","8c6ef90b":"code","7631f9f7":"code","8ab726e4":"code","263451b0":"code","f6713d37":"code","24903d21":"code","dd365933":"code","9c85c34f":"code","f1c86858":"code","0c7856e3":"code","1e0f1ef6":"code","989308d6":"code","d04c1649":"code","e9451fa0":"code","0e123199":"code","4c8a5599":"code","2fdbae41":"code","c7c084ac":"code","b4fc4bd2":"code","8e4eb591":"code","b52d2957":"code","b5b9515c":"code","f92a6982":"code","149822bb":"code","db8efd7d":"code","d3bee4e4":"code","d28f32f5":"code","5a418e6f":"code","fe638e40":"code","a79d4134":"code","afe54c45":"code","dbb22011":"code","014c664b":"code","62a0e308":"code","81fef3c5":"code","92fb6ee2":"code","acae1359":"code","19fb5da0":"markdown"},"source":{"7f999903":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport zipfile\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf99e778":"root = '\/kaggle\/input\/dogs-vs-cats'\nroot_temp = '\/kaggle\/working\/'","c87128d6":"#Removes train and test folders\ntry:\n    os.rmdir(os.path.join(root_temp,'train'))\n    os.rmdir(os.path.join(root_temp,'test1'))\n    os.rmdir(os.path.join(root_temp,'val'))\nexcept OSError as error:\n    pass","230cb114":"#Unzips files\nwith zipfile.ZipFile(os.path.join(root,'train.zip'), 'r') as zip_ref:\n    zip_ref.extractall(os.path.join(root_temp))\nwith zipfile.ZipFile(os.path.join(root,'test1.zip'), 'r') as zip_ref:\n    zip_ref.extractall(os.path.join(root_temp))","cf020f8e":"#Confirm number of images\nprint('total number in training folder ', len(os.listdir(os.path.join(root_temp,'train'))))\nprint('total number in test folder ', len(os.listdir(os.path.join(root_temp,'test1'))))","3f14d6be":"#Confirm images in\ntrain_images = [fname for fname in os.listdir(os.path.join(root_temp,'train'))]\ntest_images = [fname for fname in os.listdir(os.path.join(root_temp,'test1'))]","6a6deaf9":"print('total number in training set ', len(train_images))\nprint('total number in test set ', len(test_images))","0eb8a845":"pd.DataFrame(train_images).head()","8eaffc16":"pd.DataFrame(test_images).head()","2ab2ece4":"train_cat = []\ntrain_dog = []\nfor image in train_images:\n    if 'cat' in image:\n        train_cat.append(image)\n    else: train_dog.append(image)","7aec9a64":"print('total number of cats in training set ', len(train_cat))\nprint('total number of dogs in training set ', len(train_dog))\nprint('total number of images in test set ', len(test_images))","fc573079":"try:\n    os.mkdir(os.path.join(root_temp,'train','cat'))\n    os.mkdir(os.path.join(root_temp,'train','dog'))\nexcept OSError:\n    pass","0da5fd35":"import shutil \n\nfor image in train_cat:\n    shutil.move(os.path.join(root_temp,'train',image),os.path.join(root_temp,'train','cat',image))\n    \nfor image in train_dog:\n    shutil.move(os.path.join(root_temp,'train',image),os.path.join(root_temp,'train','dog',image))\n\nroot_train = os.path.join(root_temp,'train') \ntrain_cat = os.path.join(root_train,'cat')\ntrain_dog = os.path.join(root_train,'dog')\n\nroot_val = os.path.join(root_temp,'val')\nval_cat = os.path.join(root_val,'cat')\nval_dog = os.path.join(root_val,'dog')\n\nroot_test = os.path.join(root_temp,'test1')\n\ntry:\n    os.mkdir(root_val)\n    os.mkdir(val_cat)\n    os.mkdir(val_dog)\nexcept OSError:\n    pass","31bea3f0":"for index in range(1500):\n    #moves first 1500 images from \/kaggle\/working\/train\/cat to \/kaggle\/working\/val\/cat \n    shutil.move(os.path.join(root_temp,'train','cat',os.listdir(os.path.join(root_temp,'train','cat'))[index]),val_cat)\n    shutil.move(os.path.join(root_temp,'train','dog',os.listdir(os.path.join(root_temp,'train','dog'))[index]),val_dog)","89d2cbfc":"#confirms the number of cats and dogs in folders\nprint('total number of cats in training folder ', len(os.listdir(train_cat)))\nprint('total number of dogs in training folder ', len(os.listdir(train_dog)))\nprint('total number of cats in validation folder ', len(os.listdir(val_cat)))\nprint('total number of dogs in validation folder ', len(os.listdir(val_dog)))\nprint('total number of iamges in testing folder ', len(os.listdir(root_test)))","75f04127":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(rescale = (1.\/255))\ntest_gen = ImageDataGenerator(rescale = (1.\/255))","ed490b60":"os.listdir(root_test)","975503d2":"len(os.listdir(root_test))","8c6ef90b":"test_dir = os.path.join(root_test,'test')\ntry :\n    os.mkdir(test_dir)\nexcept: OSError\npass\n\nfrom pathlib import Path\n\n#root test = \/kaggle\/working\/test1\n#test_dir = \/kaggle\/working\/test1\/test\nfor file in os.listdir(root_test):\n    if 'test' not in file:\n        shutil.move(root_test+'\/'+file, test_dir+'\/'+file)","7631f9f7":"len(os.listdir(os.path.join(root_test,'test')))","8ab726e4":"train_flow = train_gen.flow_from_directory(root_train, \n                                           target_size = (150,150),\n                                          batch_size=25,\n                                          class_mode = 'binary')\nval_flow = test_gen.flow_from_directory(root_val, \n                                        target_size = (150,150),\n                                        batch_size=25,\n                                        class_mode = 'binary')\ntest_flow = test_gen.flow_from_directory(root_test, \n                                        target_size = (150,150),\n                                        batch_size=25,\n                                        class_mode = 'binary',\n                                        shuffle = False)","263451b0":"desired_accuracy = 0.95\n\nclass my_callback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epochs, log ={}):\n        if (log.get('accuracy')>desired_accuracy):\n            print('\\Accuracy of {} reached, stopping training '.format(desired_accuracy))\n            self.model.stop_training = True\n\nstop_training_callback = my_callback","f6713d37":"# Modelling Time\n\nbasic_cnn = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","24903d21":"basic_cnn.summary()","dd365933":"basic_cnn.compile(loss = 'binary_crossentropy', metrics =['acc'], optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4))\n\nbasic_cnn_history = basic_cnn.fit_generator(train_flow,\n                   validation_data = val_flow,\n                   steps_per_epoch = 100,\n                   epochs = 50,\n                   validation_steps = 50)","9c85c34f":"def plot_results(model_history):\n    acc = model_history.history['acc']\n    val_acc = model_history.history['val_acc']\n    loss = model_history.history['loss']\n    val_loss = model_history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'r', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', label='Training Loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()","f1c86858":"plot_results(basic_cnn_history)","0c7856e3":"# Transfer Learning\npre_trainned_model = tf.keras.applications.InceptionV3(include_top = False,\n                                                       weights = 'imagenet',\n                                                       input_shape = (150,150,3))\n\nfor layer in pre_trainned_model.layers:\n    layer.trainable = False","1e0f1ef6":"pre_trainned_model.summary()","989308d6":"last_layer = pre_trainned_model.get_layer('mixed9_1')\n\npretrainned_last_output = last_layer.output\n\nx = tf.keras.layers.Flatten()(pretrainned_last_output)\nx = tf.keras.layers.Dense(512, activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n\nnew_model = tf.keras.models.Model(pre_trainned_model.input , x)\n\nnew_model.summary()","d04c1649":"desired_accuracy = 0.90\nclass my_callback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epochs, log={}):\n        if (log.get('val_acc')>desired_accuracy):\n            print('\\nDesired validation accuracy reached, stop training')\n            self.model.stop_training = True\ncallbacks = my_callback","e9451fa0":"new_model.compile(loss='binary_crossentropy', metrics = ['acc'], optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4))\nnew_model_history = new_model.fit_generator(train_flow,\n                                           validation_data = val_flow,\n                                           steps_per_epoch = 100,\n                                           epochs = 5,\n                                           validation_steps = 50,\n#                                            callbacks = [callbacks]\n                                           )","0e123199":"new_model_history.history.keys()","4c8a5599":"acc = new_model_history.history['acc']\nval_acc = new_model_history.history['val_acc']\nloss = new_model_history.history['loss']\nval_loss = new_model_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","2fdbae41":"last_layer = pre_trainned_model.get_layer('mixed7')\n\npretrainned_last_output = last_layer.output\n\nx = tf.keras.layers.Flatten()(pretrainned_last_output)\nx = tf.keras.layers.Dense(512, activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n\nnew_model_mixed7 = tf.keras.models.Model(pre_trainned_model.input , x)\n\nnew_model_mixed7.compile(loss='binary_crossentropy', metrics = ['acc'], optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4))\nnew_model_mixed7_history = new_model.fit_generator(train_flow,\n                                                    validation_data = val_flow,\n                                                    steps_per_epoch = 100,\n                                                    epochs = 5,\n                                                    validation_steps = 50,\n                                                  #callbacks = [callbacks]\n                                                  )","c7c084ac":"plot_results(new_model_mixed7_history)","b4fc4bd2":"last_layer = pre_trainned_model.get_layer('mixed1')\n\npretrainned_last_output = last_layer.output\n\nx = tf.keras.layers.Flatten()(pretrainned_last_output)\nx = tf.keras.layers.Dense(256, activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n\nnew_model_mixed1 = tf.keras.models.Model(pre_trainned_model.input , x)\n\nnew_model_mixed1.compile(loss='binary_crossentropy', metrics = ['acc'], optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-4))\nnew_model_mixed1_history = new_model.fit_generator(train_flow,\n                                                   validation_data = val_flow,\n                                                   steps_per_epoch = 100,\n                                                   epochs = 5,\n                                                   validation_steps = 50,\n                                                  #callbacks = [callbacks]\n                                                  )","8e4eb591":"#Lets try another application namely VGG\nfrom tensorflow.keras.applications import VGG16","b52d2957":"pretrain_vgg = VGG16(include_top = False,\n                    input_shape = (150,150,3),\n                    weights = 'imagenet')\n","b5b9515c":"for layer in pretrain_vgg.layers:\n    layer.trainable = False\n\npretrain_vgg.summary()","f92a6982":"pretrain_vgg_output =  pretrain_vgg.get_layer('block5_pool').output \n\nx = tf.keras.layers.Flatten()(pretrain_vgg_output)\nx = tf.keras.layers.Dense(512,activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(1,activation = 'sigmoid')(x)\n\npretrain_vgg_model = tf.keras.models.Model(pretrain_vgg.input, x)\npretrain_vgg_model.compile(loss = 'binary_crossentropy',\n                          metrics=['acc'],\n                          optimizer = tf.keras.optimizers.RMSprop(lr=0.00001))\npretrain_vgg_history = pretrain_vgg_model.fit_generator(train_flow,\n                                                       validation_data = val_flow,\n                                                       steps_per_epoch = 100,\n                                                       epochs = 10,\n                                                       validation_steps = 50)","149822bb":"plot_results(pretrain_vgg_history)","db8efd7d":"len(root_test)","d3bee4e4":"test_flow","d28f32f5":"predictions = pretrain_vgg_model.predict(test_flow)","5a418e6f":"len(predictions)","fe638e40":"predictions = [1 if pred > 0.5 else 0 for pred in predictions]","a79d4134":"predictions[0]","afe54c45":"#label_ids = test_flow.filenames","dbb22011":"label_ids = [fname for fname in os.listdir(test_dir)]","014c664b":"label_ids[0]","62a0e308":"import csv\ndata = zip(*(label_ids, predictions))\n\ndf = pd.DataFrame(data, columns = ['id' , 'label'])","81fef3c5":"df = df.set_index('id')","92fb6ee2":"df.head()","acae1359":"df.to_csv('submission.csv', index=False)","19fb5da0":"# Preprocessing\n\nBefore we can commence any form of Deep Learning, we will have to sort the images into training and testing folders. This is done in order to faciliate the ImageDataGenerator from Keras."}}