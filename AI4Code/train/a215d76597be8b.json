{"cell_type":{"c5fd8a5d":"code","7d660985":"code","c07fef65":"code","8d4d6e63":"code","0b2d0c60":"code","9d97f69a":"code","cd387f8a":"code","e0ea9dce":"code","d23de1c5":"code","74ff1acc":"code","0f47c096":"code","63ec53e1":"code","ddc19036":"code","a6ef0c01":"code","18b2bfeb":"code","129adfdd":"code","e935114e":"code","3d475196":"code","e5b57837":"code","62055cca":"code","862ff1a8":"code","5af3723c":"code","25f8858e":"code","6c7254a1":"code","90464273":"code","7edb5a8c":"code","e2e94bee":"code","61115ff8":"code","32bf5d08":"code","dc4ca5e8":"code","e2485885":"code","295211a3":"code","9c9a7ba6":"code","8081e2dc":"code","837a1e04":"code","3bd0e01a":"markdown","69abcee5":"markdown","66504ede":"markdown","cc2b799e":"markdown","70373440":"markdown","8e0ff6c7":"markdown","bbb1c4de":"markdown","ec54f805":"markdown","fd6f85d5":"markdown","ea10fdae":"markdown","655c503e":"markdown","7d4334d9":"markdown","67ddf863":"markdown"},"source":{"c5fd8a5d":"# To have reproducible results\nseed = 5 \nimport numpy as np \nnp.random.seed(seed)\nimport tensorflow as tf\ntf.set_random_seed(seed)","7d660985":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import GlobalMaxPooling2D, Dropout, Dense\nfrom keras.models import Sequential\nfrom keras.applications import DenseNet121\nfrom keras.optimizers import Adam\nfrom keras import layers\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nimport cv2 \n%matplotlib inline\nimport os\nprint(os.listdir('..\/input\/severstal-steel-defect-detection'))\nseed = 2019","c07fef65":"IMG_SIZE = 256\nBATCH_SIZE = 32","8d4d6e63":"traindf = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')\nsub = pd.read_csv('..\/input\/severstal-steel-defect-detection\/sample_submission.csv')","0b2d0c60":"traindf.head()","9d97f69a":"traindf.shape","cd387f8a":"print('Total Number of Train Images :', int(traindf.shape[0]\/4))\nprint('Total Number of Test Images :', int(sub.shape[0]\/4))","e0ea9dce":"df = traindf['ImageId_ClassId'].str.split(pat = '_', expand = True)\ndf.columns = ['ImageId', 'ClassId']\ntraindf = pd.concat([traindf, df], axis =1 )\ntraindf.head()","d23de1c5":"traindf['Mask_absent'] = traindf['EncodedPixels'].isna().astype(int)\ntraindf['Total_Masks_missing'] = traindf.groupby('ImageId')['Mask_absent'].transform('sum')\ntraindf['NoMask'] = (traindf['Total_Masks_missing'] == 4).astype(int)","74ff1acc":"traindf.to_csv('new_train.csv', index = False)","0f47c096":"traindf.head()","63ec53e1":"print(traindf['Total_Masks_missing'].value_counts())\ntraindf['Total_Masks_missing'].value_counts().plot.bar()","ddc19036":"traindf = traindf[['ImageId', 'NoMask']].drop_duplicates().reset_index(drop = True)","a6ef0c01":"traindf['NoMask'].value_counts().plot.bar()","18b2bfeb":"traindf['NoMask'] = traindf['NoMask'].astype(str)","129adfdd":"df = sub['ImageId_ClassId'].str.split('_', expand = True)\ndf.columns = ['ImageId', 'ClassId']\nsub = pd.concat([sub, df], axis = 1)","e935114e":"sub = pd.DataFrame(sub['ImageId'].drop_duplicates()).reset_index(drop = True)","3d475196":"train, val = train_test_split(traindf,test_size = 0.2, random_state = seed, shuffle = True)","e5b57837":"img_datagen = ImageDataGenerator(horizontal_flip = True,\n                                  vertical_flip = True,\n                                  zoom_range = 0.1,\n                                  rotation_range = 10,\n                                fill_mode='constant',\n                                cval=0.,\n                                rescale = 1.\/255)\n\ndatagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_datagen = img_datagen.flow_from_dataframe(train, directory = '..\/input\/severstal-steel-defect-detection\/train_images',\n                                                x_col = 'ImageId', y_col = 'NoMask', target_size = (IMG_SIZE, IMG_SIZE),\n                                               batch_size = BATCH_SIZE, seed = seed)\n\nval_datagen = datagen.flow_from_dataframe(val, directory = '..\/input\/severstal-steel-defect-detection\/train_images', \n                                          x_col = 'ImageId', y_col = 'NoMask', target_size = (IMG_SIZE, IMG_SIZE),\n                                               batch_size = BATCH_SIZE, seed = seed)","62055cca":"test_datagen = datagen.flow_from_dataframe(sub, directory = '..\/input\/severstal-steel-defect-detection\/test_images',\n                                          x_col = 'ImageId', target_size = (IMG_SIZE, IMG_SIZE),\n                                          batch_size = BATCH_SIZE, seed = seed, class_mode = None)","862ff1a8":"fig , ax = plt.subplots(3,3, figsize = (10,10))\n\nfor i in range(9):\n    imgid = traindf['ImageId'][i]\n    img = cv2.imread(f'..\/input\/severstal-steel-defect-detection\/train_images\/{imgid}')\n    ax[i\/\/3, i%3].imshow(img)\n    ax[i\/\/3, i%3].set_title(traindf['NoMask'][i])\n    ax[i\/\/3, i%3].axis('off')\n    \nplt.tight_layout()","5af3723c":"batch = train_datagen.next()\n\nfig , ax = plt.subplots(3,3, figsize = (10,10))\n\nfor i in range(9):\n    ax[i\/\/3, i%3].imshow(batch[0][i])\n    ax[i\/\/3, i%3].set_title(batch[1][i])\n    ax[i\/\/3, i%3].axis('off')\n    \nplt.tight_layout()","25f8858e":"from keras import backend as K\n\ndef recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n\ndef f1(y_true, y_pred):\n    precision_ = precision(y_true, y_pred)\n    recall_ = recall(y_true, y_pred)\n    return 2*((precision_*recall_)\/(precision_+recall_+K.epsilon()))\n","6c7254a1":"''' ## Credits\nAll credits are due to https:\/\/github.com\/qubvel\/efficientnet\nThanks so much for your contribution!\n\n## Usage:\nAdding this utility script to your kernel, and you will be able to \nuse all models just like standard Keras pretrained model. For details see\nhttps:\/\/www.kaggle.com\/c\/aptos2019-blindness-detection\/discussion\/100186\n\n## Pretrained Weights\nhttps:\/\/www.kaggle.com\/ratthachat\/efficientnet-keras-weights-b0b5\/\n'''\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom skimage.transform import resize\nimport tensorflow as tf\nimport keras.backend as K\nimport keras.layers as KL\nfrom keras.initializers import Initializer\nfrom keras.utils.generic_utils import get_custom_objects\n\nimport os\nimport re\nimport collections\nimport math\nimport six\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\n\nimport keras.models as KM\nfrom keras.utils import get_file\n\nMEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\nSTDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n\nMAP_INTERPOLATION_TO_ORDER = {\n    \"nearest\": 0,\n    \"bilinear\": 1,\n    \"biquadratic\": 2,\n    \"bicubic\": 3,\n}\n\n\ndef center_crop_and_resize(image, image_size, crop_padding=32, interpolation=\"bicubic\"):\n    assert image.ndim in {2, 3}\n    assert interpolation in MAP_INTERPOLATION_TO_ORDER.keys()\n\n    h, w = image.shape[:2]\n\n    padded_center_crop_size = int(\n        (image_size \/ (image_size + crop_padding)) * min(h, w)\n    )\n    offset_height = ((h - padded_center_crop_size) + 1) \/\/ 2\n    offset_width = ((w - padded_center_crop_size) + 1) \/\/ 2\n\n    image_crop = image[\n        offset_height : padded_center_crop_size + offset_height,\n        offset_width : padded_center_crop_size + offset_width,\n    ]\n    resized_image = resize(\n        image_crop,\n        (image_size, image_size),\n        order=MAP_INTERPOLATION_TO_ORDER[interpolation],\n        preserve_range=True,\n    )\n\n    return resized_image\n\n\ndef preprocess_input(x):\n    assert x.ndim in (3, 4)\n    assert x.shape[-1] == 3\n\n    x = x - np.array(MEAN_RGB)\n    x = x \/ np.array(STDDEV_RGB)\n\n    return x\n\nclass EfficientConv2DKernelInitializer(Initializer):\n    \"\"\"Initialization for convolutional kernels.\n    The main difference with tf.variance_scaling_initializer is that\n    tf.variance_scaling_initializer uses a truncated normal with an uncorrected\n    standard deviation, whereas here we use a normal distribution. Similarly,\n    tf.contrib.layers.variance_scaling_initializer uses a truncated normal with\n    a corrected standard deviation.\n    Args:\n      shape: shape of variable\n      dtype: dtype of variable\n      partition_info: unused\n    Returns:\n      an initialization for the variable\n    \"\"\"\n\n    def __call__(self, shape, dtype=K.floatx(), **kwargs):\n        kernel_height, kernel_width, _, out_filters = shape\n        fan_out = int(kernel_height * kernel_width * out_filters)\n        return tf.random_normal(\n            shape, mean=0.0, stddev=np.sqrt(2.0 \/ fan_out), dtype=dtype\n        )\n\n\nclass EfficientDenseKernelInitializer(Initializer):\n    \"\"\"Initialization for dense kernels.\n    This initialization is equal to\n      tf.variance_scaling_initializer(scale=1.0\/3.0, mode='fan_out',\n                                      distribution='uniform').\n    It is written out explicitly here for clarity.\n    Args:\n      shape: shape of variable\n      dtype: dtype of variable\n    Returns:\n      an initialization for the variable\n    \"\"\"\n\n    def __call__(self, shape, dtype=K.floatx(), **kwargs):\n        \"\"\"Initialization for dense kernels.\n        This initialization is equal to\n          tf.variance_scaling_initializer(scale=1.0\/3.0, mode='fan_out',\n                                          distribution='uniform').\n        It is written out explicitly here for clarity.\n        Args:\n          shape: shape of variable\n          dtype: dtype of variable\n        Returns:\n          an initialization for the variable\n        \"\"\"\n        init_range = 1.0 \/ np.sqrt(shape[1])\n        return tf.random_uniform(shape, -init_range, init_range, dtype=dtype)\n\n\nconv_kernel_initializer = EfficientConv2DKernelInitializer()\ndense_kernel_initializer = EfficientDenseKernelInitializer()\n\n\nget_custom_objects().update(\n    {\n        \"EfficientDenseKernelInitializer\": EfficientDenseKernelInitializer,\n        \"EfficientConv2DKernelInitializer\": EfficientConv2DKernelInitializer,\n    }\n)\n\nclass Swish(KL.Layer):\n    def call(self, inputs):\n        return tf.nn.swish(inputs)\n\n\nclass DropConnect(KL.Layer):\n    def __init__(self, drop_connect_rate=0.0, **kwargs):\n        super().__init__(**kwargs)\n        self.drop_connect_rate = drop_connect_rate\n\n    def call(self, inputs, training=None):\n        def drop_connect():\n            keep_prob = 1.0 - self.drop_connect_rate\n\n            # Compute drop_connect tensor\n            batch_size = tf.shape(inputs)[0]\n            random_tensor = keep_prob\n            random_tensor += tf.random_uniform(\n                [batch_size, 1, 1, 1], dtype=inputs.dtype\n            )\n            binary_tensor = tf.floor(random_tensor)\n            output = tf.div(inputs, keep_prob) * binary_tensor\n            return output\n\n        return K.in_train_phase(drop_connect, inputs, training=training)\n\n    def get_config(self):\n        config = super().get_config()\n        config[\"drop_connect_rate\"] = self.drop_connect_rate\n        return config\n\n\nget_custom_objects().update({\"DropConnect\": DropConnect, \"Swish\": Swish})\n\n\nIMAGENET_WEIGHTS = {\n    \"efficientnet-b0\": {\n        \"name\": \"efficientnet-b0_imagenet_1000.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b0_imagenet_1000.h5\",\n        \"md5\": \"bca04d16b1b8a7c607b1152fe9261af7\",\n    },\n    \"efficientnet-b0-notop\": {\n        \"name\": \"efficientnet-b0_imagenet_1000_notop.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b0_imagenet_1000_notop.h5\",\n        \"md5\": \"45d2f3b6330c2401ef66da3961cad769\",\n    },\n    \"efficientnet-b1\": {\n        \"name\": \"efficientnet-b1_imagenet_1000.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b1_imagenet_1000.h5\",\n        \"md5\": \"bd4a2b82f6f6bada74fc754553c464fc\",\n    },\n    \"efficientnet-b1-notop\": {\n        \"name\": \"efficientnet-b1_imagenet_1000_notop.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b1_imagenet_1000_notop.h5\",\n        \"md5\": \"884aed586c2d8ca8dd15a605ec42f564\",\n    },\n    \"efficientnet-b2\": {\n        \"name\": \"efficientnet-b2_imagenet_1000.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b2_imagenet_1000.h5\",\n        \"md5\": \"45b28b26f15958bac270ab527a376999\",\n    },\n    \"efficientnet-b2-notop\": {\n        \"name\": \"efficientnet-b2_imagenet_1000_notop.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b2_imagenet_1000_notop.h5\",\n        \"md5\": \"42fb9f2d9243d461d62b4555d3a53b7b\",\n    },\n    \"efficientnet-b3\": {\n        \"name\": \"efficientnet-b3_imagenet_1000.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b3_imagenet_1000.h5\",\n        \"md5\": \"decd2c8a23971734f9d3f6b4053bf424\",\n    },\n    \"efficientnet-b3-notop\": {\n        \"name\": \"efficientnet-b3_imagenet_1000_notop.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b3_imagenet_1000_notop.h5\",\n        \"md5\": \"1f7d9a8c2469d2e3d3b97680d45df1e1\",\n    },\n    \"efficientnet-b4\": {\n        \"name\": \"efficientnet-b4_imagenet_1000.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b4_imagenet_1000.h5\",\n        \"md5\": \"01df77157a86609530aeb4f1f9527949\",\n    },\n    \"efficientnet-b4-notop\": {\n        \"name\": \"efficientnet-b4_imagenet_1000_notop.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b4_imagenet_1000_notop.h5\",\n        \"md5\": \"e7c3b780f050f8f49c800f23703f285c\",\n    },\n    \"efficientnet-b5\": {\n        \"name\": \"efficientnet-b5_imagenet_1000.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b5_imagenet_1000.h5\",\n        \"md5\": \"c31311a1a38b5111e14457145fccdf32\",\n    },\n    \"efficientnet-b5-notop\": {\n        \"name\": \"efficientnet-b5_imagenet_1000_notop.h5\",\n        \"url\": \"https:\/\/github.com\/qubvel\/efficientnet\/releases\/download\/v0.0.1\/efficientnet-b5_imagenet_1000_notop.h5\",\n        \"md5\": \"a09b36129b41196e0bb659fd84fbdd5f\",\n    },\n}\n\n\nGlobalParams = collections.namedtuple(\n    \"GlobalParams\",\n    [\n        \"batch_norm_momentum\",\n        \"batch_norm_epsilon\",\n        \"dropout_rate\",\n        \"data_format\",\n        \"num_classes\",\n        \"width_coefficient\",\n        \"depth_coefficient\",\n        \"depth_divisor\",\n        \"min_depth\",\n        \"drop_connect_rate\",\n    ],\n)\nGlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n\nBlockArgs = collections.namedtuple(\n    \"BlockArgs\",\n    [\n        \"kernel_size\",\n        \"num_repeat\",\n        \"input_filters\",\n        \"output_filters\",\n        \"expand_ratio\",\n        \"id_skip\",\n        \"strides\",\n        \"se_ratio\",\n    ],\n)\n# defaults will be a public argument for namedtuple in Python 3.7\n# https:\/\/docs.python.org\/3\/library\/collections.html#collections.namedtuple\nBlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n\n\ndef efficientnet_params(model_name):\n    \"\"\"Get efficientnet params based on model name.\"\"\"\n    params_dict = {\n        # (width_coefficient, depth_coefficient, resolution, dropout_rate)\n        \"efficientnet-b0\": (1.0, 1.0, 224, 0.2),\n        \"efficientnet-b1\": (1.0, 1.1, 240, 0.2),\n        \"efficientnet-b2\": (1.1, 1.2, 260, 0.3),\n        \"efficientnet-b3\": (1.2, 1.4, 300, 0.3),\n        \"efficientnet-b4\": (1.4, 1.8, 380, 0.4),\n        \"efficientnet-b5\": (1.6, 2.2, 456, 0.4),\n        \"efficientnet-b6\": (1.8, 2.6, 528, 0.5),\n        \"efficientnet-b7\": (2.0, 3.1, 600, 0.5),\n    }\n    return params_dict[model_name]\n\n\nclass BlockDecoder(object):\n    \"\"\"Block Decoder for readability.\"\"\"\n\n    def _decode_block_string(self, block_string):\n        \"\"\"Gets a block through a string notation of arguments.\"\"\"\n        assert isinstance(block_string, str)\n        ops = block_string.split(\"_\")\n        options = {}\n        for op in ops:\n            splits = re.split(r\"(\\d.*)\", op)\n            if len(splits) >= 2:\n                key, value = splits[:2]\n                options[key] = value\n\n        if \"s\" not in options or len(options[\"s\"]) != 2:\n            raise ValueError(\"Strides options should be a pair of integers.\")\n\n        return BlockArgs(\n            kernel_size=int(options[\"k\"]),\n            num_repeat=int(options[\"r\"]),\n            input_filters=int(options[\"i\"]),\n            output_filters=int(options[\"o\"]),\n            expand_ratio=int(options[\"e\"]),\n            id_skip=(\"noskip\" not in block_string),\n            se_ratio=float(options[\"se\"]) if \"se\" in options else None,\n            strides=[int(options[\"s\"][0]), int(options[\"s\"][1])],\n        )\n\n    def _encode_block_string(self, block):\n        \"\"\"Encodes a block to a string.\"\"\"\n        args = [\n            \"r%d\" % block.num_repeat,\n            \"k%d\" % block.kernel_size,\n            \"s%d%d\" % (block.strides[0], block.strides[1]),\n            \"e%s\" % block.expand_ratio,\n            \"i%d\" % block.input_filters,\n            \"o%d\" % block.output_filters,\n        ]\n        if block.se_ratio > 0 and block.se_ratio <= 1:\n            args.append(\"se%s\" % block.se_ratio)\n        if block.id_skip is False:\n            args.append(\"noskip\")\n        return \"_\".join(args)\n\n    def decode(self, string_list):\n        \"\"\"Decodes a list of string notations to specify blocks inside the network.\n    Args:\n      string_list: a list of strings, each string is a notation of block.\n    Returns:\n      A list of namedtuples to represent blocks arguments.\n    \"\"\"\n        assert isinstance(string_list, list)\n        blocks_args = []\n        for block_string in string_list:\n            blocks_args.append(self._decode_block_string(block_string))\n        return blocks_args\n\n    def encode(self, blocks_args):\n        \"\"\"Encodes a list of Blocks to a list of strings.\n    Args:\n      blocks_args: A list of namedtuples to represent blocks arguments.\n    Returns:\n      a list of strings, each string is a notation of block.\n    \"\"\"\n        block_strings = []\n        for block in blocks_args:\n            block_strings.append(self._encode_block_string(block))\n        return block_strings\n\n\ndef efficientnet(\n    width_coefficient=None,\n    depth_coefficient=None,\n    dropout_rate=0.2,\n    drop_connect_rate=0.2,\n):\n    \"\"\"Creates a efficientnet model.\"\"\"\n    blocks_args = [\n        \"r1_k3_s11_e1_i32_o16_se0.25\",\n        \"r2_k3_s22_e6_i16_o24_se0.25\",\n        \"r2_k5_s22_e6_i24_o40_se0.25\",\n        \"r3_k3_s22_e6_i40_o80_se0.25\",\n        \"r3_k5_s11_e6_i80_o112_se0.25\",\n        \"r4_k5_s22_e6_i112_o192_se0.25\",\n        \"r1_k3_s11_e6_i192_o320_se0.25\",\n    ]\n    global_params = GlobalParams(\n        batch_norm_momentum=0.99,\n        batch_norm_epsilon=1e-3,\n        dropout_rate=dropout_rate,\n        drop_connect_rate=drop_connect_rate,\n        data_format=\"channels_last\",\n        num_classes=1000,\n        width_coefficient=width_coefficient,\n        depth_coefficient=depth_coefficient,\n        depth_divisor=8,\n        min_depth=None,\n    )\n    decoder = BlockDecoder()\n    return decoder.decode(blocks_args), global_params\n\n\ndef get_model_params(model_name, override_params=None):\n    \"\"\"Get the block args and global params for a given model.\"\"\"\n    if model_name.startswith(\"efficientnet\"):\n        width_coefficient, depth_coefficient, input_shape, dropout_rate = efficientnet_params(\n            model_name\n        )\n        blocks_args, global_params = efficientnet(\n            width_coefficient, depth_coefficient, dropout_rate\n        )\n    else:\n        raise NotImplementedError(\"model name is not pre-defined: %s\" % model_name)\n\n    if override_params:\n        # ValueError will be raised here if override_params has fields not included\n        # in global_params.\n        global_params = global_params._replace(**override_params)\n\n    # print('global_params= %s', global_params)\n    # print('blocks_args= %s', blocks_args)\n    return blocks_args, global_params, input_shape\n\n\n\n__all__ = [\n    \"EfficientNet\",\n    \"EfficientNetB0\",\n    \"EfficientNetB1\",\n    \"EfficientNetB2\",\n    \"EfficientNetB3\",\n    \"EfficientNetB4\",\n    \"EfficientNetB5\",\n    \"EfficientNetB6\",\n    \"EfficientNetB7\",\n]\n\n\ndef round_filters(filters, global_params):\n    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n    orig_f = filters\n    multiplier = global_params.width_coefficient\n    divisor = global_params.depth_divisor\n    min_depth = global_params.min_depth\n    if not multiplier:\n        return filters\n\n    filters *= multiplier\n    min_depth = min_depth or divisor\n    new_filters = max(min_depth, int(filters + divisor \/ 2) \/\/ divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_filters < 0.9 * filters:\n        new_filters += divisor\n    # print('round_filter input={} output={}'.format(orig_f, new_filters))\n    return int(new_filters)\n\n\ndef round_repeats(repeats, global_params):\n    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n    multiplier = global_params.depth_coefficient\n    if not multiplier:\n        return repeats\n    return int(math.ceil(multiplier * repeats))\n\n\ndef SEBlock(block_args, global_params):\n    num_reduced_filters = max(1, int(block_args.input_filters * block_args.se_ratio))\n    filters = block_args.input_filters * block_args.expand_ratio\n    if global_params.data_format == \"channels_first\":\n        channel_axis = 1\n        spatial_dims = [2, 3]\n    else:\n        channel_axis = -1\n        spatial_dims = [1, 2]\n\n    def block(inputs):\n        x = inputs\n        x = KL.Lambda(lambda a: K.mean(a, axis=spatial_dims, keepdims=True))(x)\n        x = KL.Conv2D(\n            num_reduced_filters,\n            kernel_size=[1, 1],\n            strides=[1, 1],\n            kernel_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=True,\n        )(x)\n        x = Swish()(x)\n        # Excite\n        x = KL.Conv2D(\n            filters,\n            kernel_size=[1, 1],\n            strides=[1, 1],\n            kernel_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=True,\n        )(x)\n        x = KL.Activation(\"sigmoid\")(x)\n        out = KL.Multiply()([x, inputs])\n        return out\n\n    return block\n\n\ndef MBConvBlock(block_args, global_params, drop_connect_rate=None):\n    batch_norm_momentum = global_params.batch_norm_momentum\n    batch_norm_epsilon = global_params.batch_norm_epsilon\n\n    if global_params.data_format == \"channels_first\":\n        channel_axis = 1\n        spatial_dims = [2, 3]\n    else:\n        channel_axis = -1\n        spatial_dims = [1, 2]\n\n    has_se = (\n        (block_args.se_ratio is not None)\n        and (block_args.se_ratio > 0)\n        and (block_args.se_ratio <= 1)\n    )\n\n    filters = block_args.input_filters * block_args.expand_ratio\n    kernel_size = block_args.kernel_size\n\n    def block(inputs):\n\n        if block_args.expand_ratio != 1:\n            x = KL.Conv2D(\n                filters,\n                kernel_size=[1, 1],\n                strides=[1, 1],\n                kernel_initializer=conv_kernel_initializer,\n                padding=\"same\",\n                use_bias=False,\n            )(inputs)\n            x = KL.BatchNormalization(\n                axis=channel_axis,\n                momentum=batch_norm_momentum,\n                epsilon=batch_norm_epsilon,\n            )(x)\n            x = Swish()(x)\n        else:\n            x = inputs\n\n        x = KL.DepthwiseConv2D(\n            [kernel_size, kernel_size],\n            strides=block_args.strides,\n            depthwise_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=False,\n        )(x)\n        x = KL.BatchNormalization(\n            axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n        )(x)\n        x = Swish()(x)\n\n        if has_se:\n            x = SEBlock(block_args, global_params)(x)\n\n        # output phase\n\n        x = KL.Conv2D(\n            block_args.output_filters,\n            kernel_size=[1, 1],\n            strides=[1, 1],\n            kernel_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=False,\n        )(x)\n        x = KL.BatchNormalization(\n            axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n        )(x)\n\n        if block_args.id_skip:\n            if (\n                all(s == 1 for s in block_args.strides)\n                and block_args.input_filters == block_args.output_filters\n            ):\n                # only apply drop_connect if skip presents.\n                if drop_connect_rate:\n                    x = DropConnect(drop_connect_rate)(x)\n                x = KL.Add()([x, inputs])\n        return x\n\n    return block\n\n\ndef EfficientNet(\n    input_shape, block_args_list, global_params, input_tensor=None, include_top=True, pooling=None\n):\n    batch_norm_momentum = global_params.batch_norm_momentum\n    batch_norm_epsilon = global_params.batch_norm_epsilon\n    if global_params.data_format == \"channels_first\":\n        channel_axis = 1\n    else:\n        channel_axis = -1\n\n    # Stem part\n    if input_tensor is None:\n        inputs = KL.Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            inputs = KL.Input(tensor=input_tensor, shape=input_shape)\n        else:\n            inputs = input_tensor\n    x = inputs\n    x = KL.Conv2D(\n        filters=round_filters(32, global_params),\n        kernel_size=[3, 3],\n        strides=[2, 2],\n        kernel_initializer=conv_kernel_initializer,\n        padding=\"same\",\n        use_bias=False,\n    )(x)\n    x = KL.BatchNormalization(\n        axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n    )(x)\n    x = Swish()(x)\n\n    # Blocks part\n    block_idx = 1\n    n_blocks = sum([block_args.num_repeat for block_args in block_args_list])\n    drop_rate = global_params.drop_connect_rate or 0\n    drop_rate_dx = drop_rate \/ n_blocks\n\n    for block_args in block_args_list:\n        assert block_args.num_repeat > 0\n        # Update block input and output filters based on depth multiplier.\n        block_args = block_args._replace(\n            input_filters=round_filters(block_args.input_filters, global_params),\n            output_filters=round_filters(block_args.output_filters, global_params),\n            num_repeat=round_repeats(block_args.num_repeat, global_params),\n        )\n\n        # The first block needs to take care of stride and filter size increase.\n        x = MBConvBlock(\n            block_args, global_params, drop_connect_rate=drop_rate_dx * block_idx\n        )(x)\n        block_idx += 1\n\n        if block_args.num_repeat > 1:\n            block_args = block_args._replace(\n                input_filters=block_args.output_filters, strides=[1, 1]\n            )\n\n        for _ in xrange(block_args.num_repeat - 1):\n            x = MBConvBlock(\n                block_args, global_params, drop_connect_rate=drop_rate_dx * block_idx\n            )(x)\n            block_idx += 1\n\n    # Head part\n    x = KL.Conv2D(\n        filters=round_filters(1280, global_params),\n        kernel_size=[1, 1],\n        strides=[1, 1],\n        kernel_initializer=conv_kernel_initializer,\n        padding=\"same\",\n        use_bias=False,\n    )(x)\n    x = KL.BatchNormalization(\n        axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n    )(x)\n    x = Swish()(x)\n\n    if include_top:\n        x = KL.GlobalAveragePooling2D(data_format=global_params.data_format)(x)\n        if global_params.dropout_rate > 0:\n            x = KL.Dropout(global_params.dropout_rate)(x)\n        x = KL.Dense(\n            global_params.num_classes, kernel_initializer=dense_kernel_initializer\n        )(x)\n        x = KL.Activation(\"softmax\")(x)\n    else:\n        if pooling == \"avg\":\n            x = KL.GlobalAveragePooling2D(data_format=global_params.data_format)(x)\n        elif pooling == \"max\":\n            x = KL.GlobalMaxPooling2D(data_format=global_params.data_format)(x)\n\n    outputs = x\n    model = KM.Model(inputs, outputs)\n\n    return model\n\n\ndef _get_model_by_name(\n    model_name, \n    input_shape=None, \n    input_tensor=None, \n    include_top=True, \n    weights=None, \n    classes=1000, \n    pooling=None\n):\n    \"\"\"Re-Implementation of EfficientNet for Keras\n    Reference:\n        https:\/\/arxiv.org\/abs\/1807.11626\n    Args:\n        input_shape: optional, if ``None`` default_input_shape is used\n            EfficientNetB0 - (224, 224, 3)\n            EfficientNetB1 - (240, 240, 3)\n            EfficientNetB2 - (260, 260, 3)\n            EfficientNetB3 - (300, 300, 3)\n            EfficientNetB4 - (380, 380, 3)\n            EfficientNetB5 - (456, 456, 3)\n            EfficientNetB6 - (528, 528, 3)\n            EfficientNetB7 - (600, 600, 3)\n        input_tensor: optional, if ``None`` default_input_tensor is used\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet).\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        pooling: optional [None, 'avg', 'max'], if ``include_top=False``\n            add global pooling on top of the network\n            - avg: GlobalAveragePooling2D\n            - max: GlobalMaxPooling2D\n    Returns:\n        A Keras model instance.\n    \"\"\"\n    if weights not in {None, \"imagenet\"}:\n        raise ValueError('Parameter `weights` should be one of [None, \"imagenet\"]')\n\n    if weights == \"imagenet\" and model_name not in IMAGENET_WEIGHTS:\n        raise ValueError(\n            \"There are not pretrained weights for {} model.\".format(model_name)\n        )\n\n    if weights == \"imagenet\" and include_top and classes != 1000:\n        raise ValueError(\n            \"If using `weights` and `include_top`\" \" `classes` should be 1000\"\n        )\n\n    block_agrs_list, global_params, default_input_shape = get_model_params(\n        model_name, override_params={\"num_classes\": classes}\n    )\n\n    if input_shape is None:\n        input_shape = (default_input_shape, default_input_shape, 3)\n        \n    model = EfficientNet(\n        input_shape,\n        block_agrs_list,\n        global_params,\n        input_tensor=input_tensor,\n        include_top=include_top,\n        pooling=pooling,\n    )\n\n    model.name = model_name\n\n    if weights:\n        if not include_top:\n            weights_name = model_name + \"-notop\"\n        else:\n            weights_name = model_name\n        weights = IMAGENET_WEIGHTS[weights_name]\n        weights_path = get_file(\n            weights[\"name\"],\n            weights[\"url\"],\n            cache_subdir=\"models\",\n            md5_hash=weights[\"md5\"],\n        )\n        model.load_weights(weights_path)\n\n    return model\n\n\ndef EfficientNetB0(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b0\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB1(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b1\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB2(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b2\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB3(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b3\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB4(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b4\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB5(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b5\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB6(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b6\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB7(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b7\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\nEfficientNetB0.__doc__ = _get_model_by_name.__doc__\nEfficientNetB1.__doc__ = _get_model_by_name.__doc__\nEfficientNetB2.__doc__ = _get_model_by_name.__doc__\nEfficientNetB3.__doc__ = _get_model_by_name.__doc__\nEfficientNetB4.__doc__ = _get_model_by_name.__doc__\nEfficientNetB5.__doc__ = _get_model_by_name.__doc__\nEfficientNetB6.__doc__ = _get_model_by_name.__doc__\nEfficientNetB7.__doc__ = _get_model_by_name.__doc__","90464273":"efficient = EfficientNetB3(\n    weights=None,\n    include_top=False,\n    input_shape=(IMG_SIZE,IMG_SIZE,3)\n)\n\nefficient.load_weights('..\/input\/efficientnet-keras-weights-b0b5\/efficientnet-b3_imagenet_1000_notop.h5')","7edb5a8c":"resnet50 = ResNet50(include_top = False, weights = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                   input_shape = (IMG_SIZE, IMG_SIZE, 3))","e2e94bee":"def build_model():\n    model = Sequential()\n    model.add(efficient)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(Dense(2, activation = 'softmax'))\n\n        \n    model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 0.00005), metrics = ['accuracy', precision, recall , f1])\n    \n    return model","61115ff8":"model = build_model()\n\nmodel.summary()","32bf5d08":"checkpoint = ModelCheckpoint('efficientnetB3.h5', monitor = 'val_acc', save_best_only = True, verbose = 1)\n\nreducelr = ReduceLROnPlateau(monitor = 'val_loss', patience = 5, min_lr = 1e-6, verbose = 1)\n\ncallbacks = [checkpoint, reducelr]","dc4ca5e8":"history = model.fit_generator(train_datagen, steps_per_epoch = train_datagen.samples\/\/BATCH_SIZE,\n                             epochs = 40, validation_data = val_datagen, validation_steps = val_datagen.samples\/\/BATCH_SIZE,\n                             callbacks = callbacks)","e2485885":"result = pd.DataFrame(history.history)\nresult[['loss', 'val_loss']].plot()\nresult[['acc', 'val_acc']].plot()","295211a3":"result[['precision', 'val_precision']].plot()\nresult[['recall', 'val_recall']].plot()\nresult[['f1', 'val_f1']].plot()","9c9a7ba6":"preds = model.predict_generator(test_datagen, steps = len(test_datagen))","8081e2dc":"test_preds = []\n\nfor prediction in preds:\n    test_preds.append(prediction[1])","837a1e04":"sub['NoMask'] = test_preds\n\nresult.to_csv('resnet50_history.csv', index = False)\nsub.to_csv('Test_missing_masks.csv', index = False)\ntraindf.to_csv('Train_missing_masks.csv', index= False)","3bd0e01a":"# <a id='4'>Original vs Augmented Images<\/a> ","69abcee5":"There are 23608 images which have no mask at all. Number of training images to train on later will decrease by significant amount. ","66504ede":"# <a id='6'>History of Model<\/a> ","cc2b799e":"Each image is repeated 4 times in the dataset, one time for each class. ","70373440":"# <a id='3'>Data Augmentation<\/a> ","8e0ff6c7":"# <a id='2'>Loading and Rearranging DataFrame<\/a> ","bbb1c4de":"<h1><center><font size=\"6\">SEVERSTAL STEEL <\/font><\/center><\/h1>\n\n\n\n\n<img src=\"https:\/\/thumbs.dreamstime.com\/b\/roll-steel-sheet-factory-d-rendering-79415588.jpg\" width=\"800\"><\/img>\n\n\n\n<br>","ec54f805":"# <a id='0'>Content<\/a>\n\n- <a href='#1'>Importing Basic Libraries<\/a> \n- <a href='#2'>Rearranging DataFrame<\/a> : A quick overview of the dataset and rearranging for our specific task\n- <a href='#3'>ImageDataGenerator<\/a>  : Data Augmentation to create Robust Model\n- <a href='#4'> Original Images vs Augmented Images <\/a> \n- <a href='#5'> Build Model and Train<\/a>    Build ResNet50 Model and Train it\n- <a href='#6'>Plot the history of training of model<\/a>      ","fd6f85d5":"**This kernel is motivated from xhlulu's kernel** \n\nhttps:\/\/www.kaggle.com\/xhlulu\/severstal-predict-missing-masks\n\n**If you like this kernel, please upvote this as well as the above kernel . Happy Kaggling**","ea10fdae":"# <a id='5'>Build and Train Model <\/a> ","655c503e":"# <a id='1'> Importing Basic Libraries<\/a> ","7d4334d9":"Basic Idea in this kernel is to identify all the test images which have no mask , that is, they are not defected. After this we will be left with only the defected images and then we can train maybe UNet on those images. Training only on the remaining images will help us train very fast compared to training on this large dataset. You can find the intersection of the test image ids from this kernel output and xhlulu's kernel output to get test images which are most likely non-defective. Xhlulu has usesd DenseNet while I have used ResNet50. ","67ddf863":"**Augmented Images**"}}