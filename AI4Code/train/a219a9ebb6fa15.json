{"cell_type":{"d8fa2693":"code","29cbb03e":"code","8506b4df":"code","4cbfff86":"code","fdce85b8":"code","d4b8f012":"code","7ad07cb7":"code","0726dd61":"code","9bf79e45":"code","6861b44d":"code","b1cbc988":"code","244c4837":"code","0e08c075":"code","304027a7":"code","d19a359f":"code","34bf630a":"code","09219c9a":"code","34edc6ff":"code","98b4210a":"code","eee2596c":"code","aa6c3f8d":"code","d7b38c8f":"code","d250209a":"code","10289b20":"code","48b40a86":"code","7f5b10c0":"code","e8f2d712":"code","c683e1fc":"code","97388438":"code","e4f0ce28":"markdown","5925de92":"markdown","eb625fe2":"markdown","d2ec6df8":"markdown","ae679fd7":"markdown","eadef27d":"markdown","d5c5b378":"markdown","f31d0def":"markdown"},"source":{"d8fa2693":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29cbb03e":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import scale\nimport sklearn.linear_model as skl_lm\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n#Libraries to import\n\nimport datetime as dt\nimport requests\nimport sys\nfrom itertools import chain\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import GridSearchCV","8506b4df":"train=pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-5\/test.csv\")\n\ndisplay(train.head())\ndisplay(train.describe())\ntrain.info()\ntrain.isnull().sum()\ntest.isnull().sum()\n\nprint(\"Number of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province\/State informed: \", train.loc[train['Province_State']!='None']['Country_Region'].unique())","4cbfff86":"test.isnull().sum()","fdce85b8":"ID=train['Id']\nFID=test['ForecastId']","d4b8f012":"train_date_min = train['Date'].min()\ntrain_date_max = train['Date'].max()\nprint('Minimum date from training set: {}'.format(train_date_min))\nprint('Maximum date from training set: {}'.format(train_date_max))","7ad07cb7":"test_date_min = test['Date'].min()\ntest_date_max = test['Date'].max()\nprint('Minimum date from test set: {}'.format(test_date_min))\nprint('Maximum date from test set: {}'.format(test_date_max))","0726dd61":"sns.pairplot(train)","9bf79e45":"fig = px.pie(train, values='TargetValue', names='Target')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","6861b44d":"fig = px.pie(train, values='TargetValue', names='Country_Region')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","b1cbc988":"fig = px.pie(train, values='Population', names='Country_Region')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","244c4837":"corr_matrix = train.corr()     #computing correlation between features and output\nprint(corr_matrix)","0e08c075":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","304027a7":"train=train.drop(columns=['County','Province_State','Id'])\ntest=test.drop(columns=['County','Province_State','ForecastId'])","d19a359f":"da= pd.to_datetime(train['Date'], errors='coerce')\ntrain['Date']= da.dt.strftime(\"%Y%m%d\").astype(int)\nda= pd.to_datetime(test['Date'], errors='coerce')\ntest['Date']= da.dt.strftime(\"%Y%m%d\").astype(int)","34bf630a":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nX = train.iloc[:,0].values\ntrain.iloc[:,0] = l.fit_transform(X.astype(str))\n\nX = train.iloc[:,4].values\ntrain.iloc[:,4] = l.fit_transform(X)","09219c9a":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nX = test.iloc[:,0].values\ntest.iloc[:,0] = l.fit_transform(X.astype(str))\n\nX = test.iloc[:,4].values\ntest.iloc[:,4] = l.fit_transform(X)","34edc6ff":"y_train=train['TargetValue']\nx_train=train.drop(['TargetValue'],axis=1)\n\nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=0)","98b4210a":"from sklearn.linear_model import LinearRegression\nlin_reg=LinearRegression()\nlin_reg.fit(x_train,y_train)\n\nprint(lin_reg.intercept_)\nprint(lin_reg.coef_)","eee2596c":"acc1=lin_reg.score(x_test,y_test)\nacc1","aa6c3f8d":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg2=PolynomialFeatures(degree=2)\nx_poly=poly_reg2.fit_transform(x_train)\nlin_reg_2=LinearRegression()\nlin_reg_2.fit(x_poly,y_train)\n\nprint(\"Coefficients of polynimial(degree2) are\", lin_reg_2.coef_)","d7b38c8f":"#comparing estimators\nfrom sklearn.ensemble import RandomForestRegressor \nmodel = RandomForestRegressor(n_jobs=-1)\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(x_train, y_train)\n    scores.append(model.score(x_test, y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)","d250209a":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\np = Pipeline([('scaler2' , StandardScaler()),\n                        ('RandomForestRegressor: ', RandomForestRegressor())])\np.fit(x_train , y_train)\nprediction = p.predict(x_test)","10289b20":"acc2=p.score(x_test,y_test)\nacc2","48b40a86":"predict=p.predict(test)","7f5b10c0":"output=pd.DataFrame({'id':FID,'TargetValue':predict})\noutput","e8f2d712":"a=output.groupby(['id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['id'])['TargetValue'].quantile(q=0.95).reset_index()","c683e1fc":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']\na","97388438":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","e4f0ce28":"> **Modeling**","5925de92":"Linear Regression performs poorly.","eb625fe2":"Random Forest","d2ec6df8":"Polynomial Regression","ae679fd7":"> ** **Visualization","eadef27d":"Linear Regression","d5c5b378":"The performance of the is well.","f31d0def":"> **Feature Selection**"}}