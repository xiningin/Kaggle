{"cell_type":{"442ee143":"code","b0f0adde":"code","c11280c8":"code","18f4f921":"code","861c423d":"code","1c868163":"code","4841b652":"code","51546435":"code","cd4c887b":"code","8541e2fd":"code","8a45fd6c":"code","a83afa46":"code","a1112f8a":"code","ec97a536":"code","578a9fa6":"code","136ef8e4":"code","1cd53d82":"code","1cce5640":"code","4c7eafdd":"code","acec26bc":"code","b15ed619":"code","7b718242":"code","ddb58001":"code","be459e98":"code","8d768212":"code","0beb7130":"code","4e0ba347":"code","e4669438":"code","17f18a20":"code","ab61cffd":"code","bf52c8fb":"code","18d16c3d":"code","afd13a87":"code","f505312a":"code","b43f834a":"code","06769d4c":"code","91c2d4d3":"code","e2382f97":"code","52611a79":"code","471338eb":"code","fee186f0":"code","1d226eef":"code","0b4d1fcc":"code","d06e453b":"code","5b1af7e1":"code","370dd85d":"code","53f7121b":"code","dcf21ec6":"code","c848f277":"code","a9150264":"code","0d9b81fc":"code","40879085":"code","8384feee":"code","e553015a":"code","2f6b8e89":"code","077b2da9":"code","b7cf5dfc":"code","93268d04":"code","e395d3bb":"code","a7f6776e":"code","06a4ee18":"code","5e26dbc5":"code","cfee0358":"code","503399b2":"code","3db90723":"code","c65e6b4e":"code","4a416985":"code","33807cc6":"code","413916d3":"code","d712dd11":"markdown","0bcf7246":"markdown","c7bd5fc4":"markdown","066191a3":"markdown","a34b535d":"markdown","bd4a00c1":"markdown","eb5776a5":"markdown","3163332d":"markdown","fbce4871":"markdown","35ab76b7":"markdown","57944184":"markdown","a734bce4":"markdown","71f1bdf9":"markdown","42afcd2d":"markdown","004d6f7d":"markdown"},"source":{"442ee143":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain =pd.read_csv(os.path.join(dirname,'train.csv'))\ntest =pd.read_csv(os.path.join(dirname,'test.csv'))\n\ntest_ID = test['Id']\ntrain=train.drop(\"Id\",axis=1)\ntest=test.drop(\"Id\",axis=1)\n\n# print(np.shape(train),np.shape(test))\n\n","b0f0adde":"plt.scatter(train['OpenPorchSF'],train['SalePrice'])\nplt.xlabel('OpenPorchSF',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","c11280c8":"plt.scatter(train['BsmtFinSF1'],train['SalePrice'])\nplt.xlabel('BsmtFinSF1',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","18f4f921":"plt.scatter(train['YearBuilt'],train['SalePrice'])\nplt.xlabel('YearBuilt',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","861c423d":"plt.scatter(train['OverallCond'],train['SalePrice'])\nplt.xlabel('OverallCond',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","1c868163":"plt.scatter(train['TotalBsmtSF'],train['SalePrice'])\nplt.xlabel('TotalBsmtSF',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","4841b652":"plt.scatter(train['GrLivArea'],train['SalePrice'])\nplt.xlabel('GrLivArea',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","51546435":"\ntrain=train.drop(train[(train['OpenPorchSF']>500) & (train['SalePrice']<100000)].index)\n\ntrain=train.drop(train[(train['BsmtFinSF1']>5000) & (train['SalePrice']<300000)].index)\n\ntrain=train.drop(train[(train['YearBuilt']<1900) & (train['SalePrice']>400000)].index)\n\ntrain=train.drop(train[(train['OverallCond']==2) & (train['SalePrice']>300000)].index)\n\ntrain=train.drop(train[(train['TotalBsmtSF']>3000) & (train['SalePrice']<300000)].index)\n\ntrain=train.drop(train[(train['GrLivArea']>3000) & (train['SalePrice']<300000)].index)","cd4c887b":"from scipy.stats import norm\nsns.distplot(train[\"SalePrice\"],fit=norm)\nmu,sigma= norm.fit(train['SalePrice'])\nprint(\"mu {}, sigma {}\".format(mu,sigma))","8541e2fd":"########## REMOVING SKEWEENESS ###########\ntrain['SalePrice']=np.log1p(train['SalePrice'])\nsns.distplot(train[\"SalePrice\"],fit=norm)\nmu,sigma= norm.fit(train['SalePrice'])\nprint(\"mu {}, sigma {}\".format(mu,sigma))","8a45fd6c":"ytrain=train.SalePrice.values","a83afa46":"# Concatenating train + test= all_data\nall_data=pd.concat((train,test)).reset_index(drop=True)","a1112f8a":"all_data=all_data.drop('SalePrice',axis=1)\n","ec97a536":"print(np.shape(all_data))","578a9fa6":"miss=all_data.isnull().sum()\nmiss=miss[miss>0]\nmiss=miss.sort_values(ascending=False)\nprint(miss)","136ef8e4":"all_data['PoolQC']=all_data['PoolQC'].fillna(\"None\")\nall_data['MiscFeature']=all_data['MiscFeature'].fillna(\"None\")\nall_data['Alley']=all_data['Alley'].fillna(\"None\")\nall_data['Fence']=all_data['Fence'].fillna(\"None\")\nall_data['FireplaceQu']=all_data['FireplaceQu'].fillna(\"None\")\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\nfor col in ('GarageQual','GarageCond','GarageFinish','GarageType'):\n    all_data[col]=all_data[col].fillna(\"None\")\n# Garageyrbuilt !!!!!!!!!    \nfor col in ('GarageYrBlt','GarageArea','GarageCars'):\n    all_data[col]=all_data[col].fillna(0)\n    \n","1cd53d82":"for col in ('BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2'):\n    all_data[col]=all_data[col].fillna(\"None\")\nfor col in ('BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath'):\n    all_data[col]=all_data[col].fillna(0)\n  ","1cce5640":"miss=all_data.isnull().sum()\nmiss=miss[miss>0]\nmiss=miss.sort_values(ascending=False)\nprint(miss)","4c7eafdd":"all_data['MasVnrType']=all_data['MasVnrType'].fillna(\"None\")\nall_data['MasVnrArea']=all_data['MasVnrArea'].fillna(0)\nall_data['MSZoning']=all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data=all_data.drop(['Utilities'],axis=1)\nall_data['Functional']=all_data['Functional'].fillna(\"Typ\")\nall_data['SaleType']=all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['KitchenQual']=all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior2nd']=all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['Exterior1st']=all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Electrical']=all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n","acec26bc":"miss=all_data.isnull().sum()\nmiss=miss[miss>0]\nmiss=miss.sort_values(ascending=False)\nprint(miss)","b15ed619":"all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","7b718242":"########################### MISSING VALUES HANDLED ########################","ddb58001":"print(np.shape(all_data))","be459e98":"#CHANGED\nall_data=all_data.drop(['Street'],axis=1)","8d768212":"#CHANGED\nall_data=all_data.drop(['PoolQC'],axis=1)","0beb7130":"############# Numerically represented categorical values .    NEED TO CONVERT THESE TO CATEGORICAL      ########################\n# MSSubClass OverallQual  OverallCond   YearBuilt   YearRemodAdd    BsmtFullBath   BsmtHalfBath   FullBath   HalfBath   BedroomAbvGr  KitchenAbvGr   TotRmsAbvGrd   Fireplaces   GarageYrBlt   GarageCars   MoSold   YrSold   ","4e0ba347":"#CHANGED\nfor col in ('MSSubClass' ,   'OverallCond'  ,'OverallQual', 'BedroomAbvGr',  'KitchenAbvGr', 'BsmtFullBath',   'BsmtHalfBath',   'FullBath',   'HalfBath' ,    'TotRmsAbvGrd' ,  'Fireplaces',   'GarageYrBlt',   'GarageCars'  , 'MoSold' ,  'YrSold'):\n    all_data[col]=all_data[col].astype(str)","e4669438":"# CATEGORICAL\n\n# ('MSSubClass', 'OverallQual',  'OverallCond' ,   'YearRemodAdd',    'BsmtFullBath',   'BsmtHalfBath',   'FullBath',   'HalfBath' ,  'BedroomAbvGr',  'KitchenAbvGr',   'TotRmsAbvGrd' ,  'Fireplaces',   'GarageYrBlt',   'GarageCars'  , 'MoSold' ,  'YrSold','MSZoning','Alley','LotShape','LandContour','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','Fence','MiscFeature','SaleType','SaleCondition', 'YearBuilt')","17f18a20":"# CATEGORICAL Features\nc=('MSSubClass', 'OverallQual',  'OverallCond' ,   'YearRemodAdd',    'BsmtFullBath',   'BsmtHalfBath',   'FullBath',   'HalfBath' ,  'BedroomAbvGr',  'KitchenAbvGr',   'TotRmsAbvGrd' ,  'Fireplaces',   'GarageYrBlt',   'GarageCars'  , 'MoSold' ,  'YrSold','MSZoning','Alley','LotShape','LandContour','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','Fence','MiscFeature','SaleType','SaleCondition', 'YearBuilt')\n","ab61cffd":"\ncat_list=list(c)\n","bf52c8fb":"######## LABEL ENCODING OF ALL CATEGORICAL FEATURES ###########\nfrom sklearn.preprocessing import LabelEncoder\nfor i in cat_list:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[i].values)) \n    all_data[i] = lbl.transform(list(all_data[i].values))","18d16c3d":"# Numerical_cols= all_data.columns-CategoricalColumns\nnumeric_col=[]\nfor col in all_data.columns:\n    if(col not in cat_list):\n        numeric_col.append(col)","afd13a87":"skew=all_data[numeric_col].skew()","f505312a":"print(skew)","b43f834a":"skew=skew[abs(skew) > 0.75]\nprint(len(skew))","06769d4c":"from scipy.special import boxcox1p\nlam=0.15\nfor i in skew.index:\n    all_data[i]=np.log1p(all_data[i])","91c2d4d3":"########### NORMALIZING NUMERIC FEATURES ####################\nfor col in numeric_col:\n    m=np.mean(all_data[col])\n    ma=np.max(all_data[col])\n    mi=np.min(all_data[col])\n    all_data[col]=(all_data[col]-m)\/(ma-mi)\n    ","e2382f97":"all_data=pd.get_dummies(all_data)\nprint(np.shape(all_data))","52611a79":"######### test + train = all_data ######\nq=np.shape(ytrain)[0]\ntrain=all_data[:q]\ntest=all_data[q:]","471338eb":"print(np.shape(train),np.shape(test))","fee186f0":"print(len(test.columns),len(train.columns))","1d226eef":"######## train = xtrain , val ###########\nfrom sklearn.model_selection import train_test_split\nxtrain, xval, ytrain, yval = train_test_split(train, ytrain, test_size=0.33,\n                                                      random_state=0)\n####################################### CHANGED TEST SIZE ##############################################","0b4d1fcc":"print('''XTRAIN {}   \nXVAL{}   \nXTEST{}'''.format(np.shape(xtrain),np.shape(xval),np.shape(test)))","d06e453b":"from sklearn.model_selection import cross_val_score","5b1af7e1":"# ########## lasso ######### {update :- it didn't help}\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n# lasso = make_pipeline(RobustScaler(), Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.00001, warm_start=False, positive=False, random_state=None, selection='cyclic'))","370dd85d":"from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import ElasticNet,BayesianRidge\nfrom sklearn.preprocessing import RobustScaler\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))","53f7121b":"import lightgbm as lgb\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.03, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","dcf21ec6":"from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)","c848f277":"from sklearn.kernel_ridge import KernelRidge\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)","a9150264":"from xgboost import XGBRegressor,XGBRFRegressor\nfrom lightgbm import LGBMRegressor","0d9b81fc":"######### CV #########\n\n#previous 1000\nscores=-1 * cross_val_score(XGBRegressor(n_estimators=2200,learning_rate=0.05),xtrain,ytrain,cv=5,scoring=\"neg_mean_absolute_error\")","40879085":"val_score=scores.mean()","8384feee":"print(val_score)","e553015a":"#LASSO\n# model1=lasso\n# model1.fit(xtrain,ytrain)","2f6b8e89":"#LGB\nmodel_lgb.fit(xtrain,ytrain)","077b2da9":"#GrBOOST\nGBoost.fit(xtrain,ytrain)","b7cf5dfc":"#KKR\nKRR.fit(xtrain,ytrain)","93268d04":"#ENET\nENet.fit(xtrain,ytrain)\n","e395d3bb":"#XGBOOST\nmodel=XGBRegressor(n_estimators=2200,learning_rate=0.05)\nmodel.fit(xtrain,ytrain)#,early_stopping_rounds=5,eval_set=[(xval,yval)],verbose=False)","a7f6776e":"x=model.predict(test)","06a4ee18":"# y=model1.predict(test)\n# y=np.expm1(y)","5e26dbc5":"x=np.expm1(x)","cfee0358":"z=model_lgb.predict(test)\nz=np.expm1(z)","503399b2":"q=GBoost.predict(test)\nq=np.expm1(q)","3db90723":"w=KRR.predict(test)\nw=np.expm1(w)","c65e6b4e":"e=ENet.predict(test)\ne=np.expm1(e)","4a416985":"x=(0.15*x+0.15*z)+0.7*(q+e+w)\/3\n","33807cc6":"output = pd.DataFrame({'Id': test_ID,\n                       'SalePrice': x})\noutput.to_csv('submission.csv', index=False)","413916d3":"print(\"That's all Folks !\")","d712dd11":"### **Normalizing NUMERICAL_COLUMNS to be between [0,1]**","0bcf7246":"### Removing potential Outlier data points { After careful analysis of the above scatter plots }","c7bd5fc4":"## *LABEL ENCODING OF CATEGORICAL FEATURES*:-\n\n### Label encoding categorical features as 'SalePrice'  depend on the individual order in which these categorical features are given","066191a3":"## *USING Multiple Models for final prediction* :-\n\n### Now I'll be using variour regression models and then will take their weighted average for final prediction on *test*","a34b535d":"### As we can see that *target* is right skewed, we will perform log transform ","bd4a00c1":"### Again using log transformation to remove skewness {as all of the numerical features have positive skew}","eb5776a5":" ### *Observation*:-   All of them have positive skew","3163332d":"### Now let's handel skew in all numerical features","fbce4871":"## *Numerically represented categorical values*:-\n\n### Some of the features are represented in numbers<int64>, when they should be in 'string' representing categorical features","35ab76b7":" ## Importing libraries","57944184":"### *Missing values*:-\n### We have a lot of features to handel (81 in total), so there is a potential chance for missing values","a734bce4":" Predict sales prices and practice feature engineering, RFs, and gradient boosting\n![image.png](attachment:image.png)\n \n ","71f1bdf9":"# Multi-model Advanced Regression:  House Prices","42afcd2d":"## Visualizing Scatter plots of various features with *target* SalePrice","004d6f7d":"### Now lets analyse our target i.e **SalePrice**, and see how it is distributed"}}