{"cell_type":{"62b52c47":"code","b6630ae9":"code","114dc8c6":"code","ae72c837":"code","4ead5a87":"code","3a14b037":"code","b80532ca":"code","847a177d":"code","b71e2f3d":"code","8963be9d":"code","770b53c6":"code","e171dc68":"code","f2f4bcb5":"code","25bf0c57":"code","50405f71":"code","2e201826":"code","1c36d528":"code","2f2547b2":"code","8abf54ef":"code","cfd19b46":"code","ad3e770b":"code","0d443b36":"code","bf82a798":"code","5a31355c":"code","5b9f9706":"code","2f00c17d":"code","c55f23d6":"code","c2601e66":"code","4ad23324":"code","6b7a43fd":"code","916d37f7":"code","339fce66":"code","87cb9488":"code","76234b22":"code","efe740f9":"code","864d2dac":"code","11cc90a3":"code","ab5c8012":"markdown","572e19c7":"markdown","a6fce87b":"markdown","33257cd7":"markdown","564ff316":"markdown","3b124c01":"markdown","79d9bb52":"markdown","c93edc24":"markdown","dd77150d":"markdown","1adc9908":"markdown","af848a6d":"markdown","25ba3c09":"markdown"},"source":{"62b52c47":"import itertools\nimport os\nimport numpy as np\n\nimport tensorflow as tf\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import array_to_img\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom time import strftime\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom IPython.display import display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","b6630ae9":"label_names = ['Plane','Car','Bird','Cat','Deer','Dog','Frog','Horse','Ship','Truck'] # Labels for all 10 classes in dataset.\n# The images are in 3-dimension array which need to be converted to 1-dimension for keras model fitting.\nimg_width = 32\nimg_height = 32\nimg_pixel = img_width*img_height\ncolor_channel = 3\ntotal_inputs = img_pixel*color_channel\nvalidation_size= 10000","114dc8c6":"type(cifar10) # Type of imported dataset from keras","ae72c837":"#Storing the Train and Test Data\n(x_train_full, y_train_full), (x_test_full, y_test_full) =  cifar10.load_data()","4ead5a87":"print(\"Type of output returned from load_data :\",type(x_train_full)) \nx_train_full.shape, x_test_full.shape","3a14b037":"# Using Keras array to image we can display the image\npic = array_to_img(x_train_full[7]) # Image at 7 location in train dataset\ndisplay(pic) ","b80532ca":"# To see the class of the image we navigate y_train to 7 location\ny_train_full[7][0], label_names[7]","847a177d":"# Matplotlib can be also used to display images\n\nplt.imshow(x_train_full[4])\nplt.title(label_names[y_train_full[4][0]], fontsize=15)\nplt.show()","b71e2f3d":"plt.figure(figsize=(20,8))\nfor i in range(10):\n    plt.subplot(1,10,i+1)\n    plt.imshow(x_train_full[i])\n    plt.title(label_names[y_train_full[i][0]])\n    plt.axis('off')","8963be9d":"# Lets see the shape of single image\nx_train_full[0].shape","770b53c6":"number_img, x, y, c = x_train_full.shape\nprint(\"Number of Images in train :\",number_img,\" Width :\",x, \" Height :\",y, \" Channels :\",c)","e171dc68":"number_img, x, y, c = x_test_full.shape\nprint(\"Number of Images in test :\",number_img,\" Width :\",x, \" Height :\",y, \" Channels :\",c)","f2f4bcb5":"#Driling down each pixel\nx_train_full[0][0][0] # this is the values for RGB","25bf0c57":"x_train_full[0][0][0][0], type(x_train_full[0][0][0][0])  # Unsigned Integer (+ve values)","50405f71":"# Maximum value for each color channel will be 255\n# Scaling all values by dividing with 255\n\nx_train_full, x_test_full = x_train_full\/255.0, x_test_full\/255.0","2e201826":"x_train_full[0][0][0][0], type(x_train_full[0][0][0][0])","1c36d528":"# 4-D data will not fit proper with neural networks\n# Converting each image data to single vector using numpy reshape\n\nx_train_full = x_train_full.reshape(x_train_full.shape[0],total_inputs)\nx_train_full.shape","2f2547b2":"x_test_full = x_test_full.reshape(x_test_full.shape[0],total_inputs)\nx_test_full.shape","8abf54ef":"x_val = x_train_full[:validation_size]\ny_val = y_train_full[:validation_size]\nx_val.shape","cfd19b46":"x_train = x_train_full[validation_size:]\ny_train = y_train_full[validation_size:]\nx_train.shape","ad3e770b":"# Model 1 will be a simple network without any regularization\n\nmodel_1 = Sequential([\n          Dense(units=128, input_dim=total_inputs, activation = 'relu', name='m1_hidden1'),\n          Dense(units=64, activation = 'relu', name='m1_hidden2'),\n          Dense(16, activation = 'relu', name='m1_hidden3'),\n          Dense(10, activation = 'softmax', name='output')\n])\n\nmodel_1.compile(optimizer='adam', \n                loss='sparse_categorical_crossentropy', \n                metrics='accuracy')\n\ntype(model_1)","0d443b36":"model_1.summary()","bf82a798":"# What is this parameters\n# inputs * units + bias\n# for 1 hidden layer\ntotal_inputs * 128 + 128","5a31355c":"# Model 2 with single Droupout Layer to inputs\n\nmodel_2 = Sequential()\nmodel_2.add(Dropout(rate=0.2, input_shape=(total_inputs,), seed=42))\nmodel_2.add(Dense(units=128, activation='relu', name='m2_hidden1'))\nmodel_2.add(Dense(units=64, activation='relu', name='m2_hidden2'))\nmodel_2.add(Dense(units=16, activation='relu', name='m2_hidden3'))\nmodel_2.add(Dense(units=10, activation='softmax', name='m2_output'))\n\n\nmodel_2.compile(optimizer='adam', \n                loss='sparse_categorical_crossentropy', \n                metrics='accuracy')","5b9f9706":"# Model 3 with two Droupout Layer\n\nmodel_3 = Sequential()\nmodel_3.add(Dropout(rate=0.2, input_shape=(total_inputs,), seed=42))\nmodel_3.add(Dense(units=128, activation='relu', name='m3_hidden1'))\nmodel_3.add(Dropout(rate=0.25, seed=42))\nmodel_3.add(Dense(units=64, activation='relu', name='m3_hidden2'))\nmodel_3.add(Dense(units=16, activation='relu', name='m3_hidden3'))\nmodel_3.add(Dense(units=10, activation='softmax', name='m3_output'))\n\n\nmodel_3.compile(optimizer='adam', \n                loss='sparse_categorical_crossentropy', \n                metrics='accuracy')","2f00c17d":"samples_per_batch = 1000\nmodels = [model_1, model_2, model_3]","c55f23d6":"%%time\nfor i,model in enumerate(models,1):\n    nr_epochs = 100\n    history = model.fit(x_train, y_train,batch_size=samples_per_batch, epochs=nr_epochs,\n                verbose=0, validation_data=(x_val,y_val))\n    \n    # summarize history for accuracy\n    plt.figure(figsize=(20,5))\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title(f'Model {i} accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n    \n    # summarize history for loss\n    plt.figure(figsize=(20,5))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title(f'Model {i} loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()","c2601e66":"x_val[0] # 1D array","4ad23324":"test = np.reshape(x_val[0], (1,x_val[0].shape[0]))","6b7a43fd":"np.set_printoptions(precision=3) # to avoid scientific notation of large numbers","916d37f7":"model_1.predict(test)","339fce66":"model_2.predict_classes(test)","87cb9488":"y_val[0] # To test above result","76234b22":"# Testing for first 10 images\nfor number in range(10):\n    test_img = np.expand_dims(x_val[number], axis=0)\n    predicted_val = model_2.predict_classes(test_img)[0]\n    print(f'Actual val: {y_val[number][0]}   Predicted val: {predicted_val}')","efe740f9":"model_1.metrics_names","864d2dac":"for i,model in enumerate(models, 1):\n    test_loss, test_accuracy = model.evaluate(x_test_full, y_test_full)\n    print(f'Model {i} : Test loss is {test_loss:0.3}, Test accuracy is {test_accuracy:0.1%}')","11cc90a3":"for n,model in enumerate(models, 1):\n    print(f\"Confusion matrix for Model {n}\")\n    prediction = model.predict_classes(x_test_full)\n    conf_matrix = confusion_matrix(y_true=y_test_full, y_pred=prediction)\n    \n    nr_cols = conf_matrix.shape[1]\n    nr_rows = conf_matrix.shape[0]\n    \n    print(f'Shape of Matrix: {conf_matrix.shape}, max value in matrix: {conf_matrix.max()}, min value in matrix: {conf_matrix.min()}')\n    \n    plt.figure(figsize=(10,10))\n    plt.imshow(conf_matrix, cmap=plt.cm.Greens)\n    plt.title(f\"Confusion matrix for Model {n}\", fontsize=16)\n    plt.ylabel(\"Actual labels\", fontsize=16)\n    plt.xlabel(\"Predicited labels\", fontsize=16)\n    tick_marks = np.arange(10)\n    plt.yticks(tick_marks, label_names)\n    plt.xticks(tick_marks, label_names)\n    plt.colorbar()\n\n    for i,j in itertools.product(range(nr_rows), range(nr_cols)):\n        plt.text(j,i, conf_matrix[i,j], horizontalalignment='center',\n                color='white' if conf_matrix[i,j]>450 else 'black')\n    plt.show()\n    \n    # Calculating recall, precesion and F score\n    recall = np.diagonal(conf_matrix)\/ np.sum(conf_matrix,axis=1)\n    precision = np.diagonal(conf_matrix)\/ np.sum(conf_matrix,axis=0)\n\n    avg_recall = np.mean(recall)\n    avg_precision = np.mean(precision)\n    fscore = 2*((avg_recall*avg_precision)\/(avg_recall+avg_precision))\n    print(f'Average Recall :{avg_recall:.2%} ')\n    print(f'Average Precision :{avg_precision:.2%} ')\n\n    print(f'F-score for model {n}: {fscore:.2%}')","ab5c8012":"#### Comfusion Matrix","572e19c7":"#### Importing necessary Packages","a6fce87b":"#### Define Neural Network using Keras","33257cd7":"#### Lets see how Prediction works by Predicting individual image","564ff316":"### This Notebook will walkthrough the Basic Neural Network for Image Recognition using the Keras's CIFAR10 dataset\n\n* Classify Images from 10 different classes from CIFAR10 dataset using Keras and Tensorflow\n* Model Accuracy is tested using F-score","3b124c01":"#### Constants ","79d9bb52":"### Create Validation dataset","c93edc24":"### Example image in 7 location","dd77150d":"#### Evaluation","1adc9908":"From the above output we got 4 values in shape\n* 1. Represents the Image Number\n* 2. Represents the number of rows\n* 3. Represents the number of columns\n* 4. Represents the colour channel\n\nFor colour Image we have 3 Channels: Red, Green, Blue \n![image.png](attachment:image.png)","af848a6d":"#### Preprocessing data","25ba3c09":"#### Fitting Model"}}