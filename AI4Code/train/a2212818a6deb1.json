{"cell_type":{"6ee3c2b0":"code","85c5e94d":"code","8081fbc2":"code","b1e4c8fa":"code","7ac0b8d5":"code","8ef29edd":"code","344c2b46":"code","71a8eb2d":"code","d8603b9b":"code","ce97c7a3":"code","e12341ec":"code","a6747d13":"code","e6b06db3":"code","d5476c51":"code","66db4e44":"code","d6bac05c":"code","6cef9a17":"code","90dd3e92":"code","7c3d0261":"code","a23ea1b1":"code","97520d76":"markdown","ada26653":"markdown","a52c37f0":"markdown","ae8b6711":"markdown","8b2565d2":"markdown","be117cc6":"markdown","33f0ce9d":"markdown","a2c35fcd":"markdown","7732777c":"markdown","0079a9dc":"markdown","e76aafdc":"markdown"},"source":{"6ee3c2b0":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nimport statsmodels\nfrom statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","85c5e94d":"train = pd.read_csv('..\/input\/hacklive-4\/Train.csv',index_col='ID')\ntest = pd.read_csv('..\/input\/hacklive-4\/Test.csv',index_col='ID')\nsub = pd.read_csv('..\/input\/hacklive-4\/SampleSubmission.csv',index_col='ID')","8081fbc2":"train","b1e4c8fa":"test","7ac0b8d5":"def plot_stock_price(stock_label):\n    plt.figure(figsize=(10,6))\n    plt.plot(train[train['stock']==stock_label]['Close'].values)\n    plt.xticks([])\n    plt.show()\nplot_stock_price(20)","8ef29edd":"plot_stock_price(68)","344c2b46":"market_price = train.groupby('Date')['Close'].mean()\nplt.figure(figsize=(10,6))\nplt.plot(market_price.values)\nplt.xticks([])\nplt.show()","71a8eb2d":"std = []\nunpredict = []\nfor st in range(103):\n    std.append(train[train['stock']==st]['Close'].std())\n    unpredict.append(train[train['stock']==st]['unpredictability_score'].mean())\nplt.figure(figsize=(8,6))\nplt.scatter(unpredict,std)\nplt.xlabel('Unpredictbility Score')\nplt.ylabel('Standard Deviation')\nplt.show()","d8603b9b":"import warnings\nwarnings.filterwarnings('error',category=statsmodels.tools.sm_exceptions.HessianInversionWarning)\nwarnings.filterwarnings('error',category=statsmodels.tools.sm_exceptions.ConvergenceWarning)\nwarnings.filterwarnings('error',category=RuntimeWarning)\nwarnings.filterwarnings('ignore',category=UserWarning)","ce97c7a3":"def train_arima(ts,exog,order,verbose=1):\n    \"\"\"\n    ts - time series to train on\n    exog - exogeneous variable of length same as that of ts\n    order - tuple of size 3 with coefficients corresponding to AR, I and MA parts of the model\n    verbose - 1 or 0 whether to print the info while running or not\n\n    returns fit model which can forecast the values\n    \"\"\"\n    model = statsmodels.tsa.arima.model.ARIMA(endog=ts, exog=exog, order=order)\n    try:\n        model_fit = model.fit()\n        return model_fit\n    except:\n        if verbose:\n            print('     The order is not valid for fitting the model')\n        return None","e12341ec":"def split_time_series(ts,train_size):\n    \"\"\"\n    ts - time series which needs to be split (numpy array)\n    train_size - size of the training data (0 to 1)\n\n    returns 2 time series (train_ts,val_ts)\n    \"\"\"\n    split_ind = int(train_size*ts.shape[0])\n    train_ts,val_ts = ts[:split_ind],ts[split_ind:]\n    return (train_ts,val_ts)","a6747d13":"def get_forecast_error(ts,ts_pred):\n    return np.round(np.sqrt(mean_squared_error(ts,ts_pred)),6)","e6b06db3":"def validate_arima_model(ts,exog,param_grid,train_size=0.8,verbose=1):\n    \"\"\"\n    ts - time series available for training and validation (numpy array)\n    exog - exogeneous variable of length same as that of ts\n    param_grid - dictionary of arima model orders. Has keys - (p,q,r) Ex: {'p':[1,2,3],'q':[0,1,2],'r':[2,3,4]}\n    returns best (p,q,r)\n    \"\"\"\n    num_models = len(param_grid['p'])*len(param_grid['q'])*len(param_grid['r'])\n    if verbose:\n        print('Total Number of models to be trained =',num_models)\n        print('')\n\n    train_ts,val_ts = split_time_series(ts,train_size)\n    train_exog,val_exog = split_time_series(exog,train_size)\n    forecast_steps = val_ts.shape[0]\n    orders_errors = []\n    best_error = np.inf\n    for p in param_grid['p']:\n        for q in param_grid['q']:\n            for r in param_grid['r']:\n                if verbose:\n                    print(f'The model order = ({p},{q},{r}):')\n                model_fit = train_arima(train_ts,exog=train_exog,order=(p,q,r),verbose=0)\n                if model_fit:\n                    val_forecast = model_fit.forecast(forecast_steps,exog=val_exog)\n                    error = get_forecast_error(val_ts,val_forecast)\n                    if verbose:\n                        print('    The error obtained = {:.4f}'.format(error))\n                    if error<best_error:\n                        best_error = error\n                        best_order = (p,q,r)\n\n                    orders_errors.append(((p,q,r),error))\n\n                if verbose:\n                    print('')\n    if verbose:\n        print(f'Best order =',best_order)\n        print('Best error = {:.4f}'.format(best_error))\n    return best_order,best_error,orders_errors","d5476c51":"def Predict_stockprice():\n    \"\"\"\n    st - Stock number\n    the function takes stock data and performs arima forecasting followed by prediction on test data\n    \"\"\"\n    best_orders = {}\n    least_errors = {}\n    pred_close_price = np.array([])\n    for st in range(103):\n        print('Stock label =',st)\n        ts = train[train['stock']==st]['Close'].values\n        exog = train[train['stock']==st]['holiday'].values \n        param_grid = {'p':[1,2,3],'q':[0,1,2],'r':[0,1,2,3]}\n        best_order,best_error,orders_errors = validate_arima_model(ts,exog,param_grid,train_size=0.8,verbose=0)\n        best_orders[st] = best_order\n        least_errors[st] = best_error\n        model_fit = train_arima(ts,exog,best_order,verbose=0)\n        k = 1\n        if model_fit==None:\n            orders_errors = sorted(orders_errors,key=lambda x:x[1],reverse=False)\n        while model_fit==None:\n            model_fit = train_arima(ts,exog,orders_errors[k][0],verbose=0)\n            best_orders[st] = orders_errors[k][0]\n            least_errors[st] = orders_errors[k][1]\n            k+=1\n        print('     Best order =',best_orders[st])\n        print('     Least error =',least_errors[st])\n        test_exog = test[test['stock']==st]['holiday'].values\n        steps = test_exog.shape[0]\n        forecasts = model_fit.forecast(steps,exog=test_exog)\n        pred_close_price = np.append(pred_close_price,forecasts)\n        print('')\n\n    return pred_close_price,best_orders,least_errors\n\noutput = Predict_stockprice()","66db4e44":"sub['Close'] = output[0]","d6bac05c":"plt.figure(figsize=(8,6))\nunpredict = train.groupby('stock')['unpredictability_score'].mean().values\nerrors = list(output[2].values())\nplt.scatter(unpredict,errors)\nplt.xlabel('Unpredictbility Score')\nplt.ylabel('Validation Error')\nplt.show()","6cef9a17":"def plot_validation_predictions(st,order_dict):\n    order = order_dict[st]\n    ts = train[train['stock']==st]['Close'].values\n    exog = train[train['stock']==st]['holiday'].values  \n    train_size=0.8\n    train_ts,val_ts = split_time_series(ts,train_size)\n    train_exog,val_exog = split_time_series(exog,train_size)\n    forecast_steps = val_ts.shape[0]\n    model_fit = train_arima(train_ts,exog=train_exog,order=order,verbose=0)\n    val_forecast = model_fit.forecast(forecast_steps,exog=val_exog)\n    plt.figure(figsize=(8,6))\n    start = len(ts)-len(val_forecast)\n    end = len(ts)\n    plt.plot(ts,label='True')\n    plt.plot(list(range(start,end)),val_forecast,label='Predicted')\n    plt.legend()\n    plt.show()","90dd3e92":"plot_validation_predictions(15,output[1])","7c3d0261":"plot_validation_predictions(78,output[1])","a23ea1b1":"sub.to_csv('Submission_file.csv')","97520d76":"### Model training and validation\nA variety of models are used for time series predictions. Some of the popular ones are ARIMA, VARMA, SARIMA, LSTM, GRU, CNN and HES(Holts Exponential Smoothing). ARIMA takes three hyperparameters. One coeeficient for auto regression, differencing and moving average each. The auto regression coeefficient could be decided based on acf and pacf plots. There are methods to decide other coefficients. Since there are a large number of stocks it would be tedious to do that. Hence a part of the time series is kept for validation. Grid search is performed for all the three hyperparameters and the one which results in the least error on the validation set is used to train on the entire time series and predictions are made. Also some of the orders could result in Convergence issues, some would not be suitable for training arima. They need to be taken care of while performing the grid search. Holiday column is an exogeneous variable (available for both train and test set). This is also passed to the model.","ada26653":"The data consists of stock prices of 103 stocks for a period of almost 2 years. We are required to predict closing price for the next 41 days. We are given data on Open, High, Low and Close prices along with a score for volatility of the stocks and also the data on holidays.","a52c37f0":"## Stock Price Prediction (Analytics Vidhya Competition)\nThis notebook uses ARIMA model to predict stock price. The predictions produce a score of 2.93 on the public leaderboard. ","ae8b6711":"### Load Data","8b2565d2":"The model has tried to find a linear fit and succeded to some extent","be117cc6":"The above figure shows the plot of standard deviation of the stocks versus the unpredictability score. As expected they are positively correlated.","33f0ce9d":"It is mostly a bull market. For a brief period of time most of the stocks went down and they picked up very quickly.","a2c35fcd":"## Please upvote if you like this notebook","7732777c":"### Import Libraries","0079a9dc":"The plot shows how the validation error increases with increase in stock volatility.","e76aafdc":"### Data Exploration"}}