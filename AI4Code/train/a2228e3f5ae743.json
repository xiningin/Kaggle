{"cell_type":{"39fdacf9":"code","b486a960":"code","538a6138":"code","962c640e":"code","1731301d":"code","50fc2563":"code","7d20a795":"code","30f87efe":"code","d82882f7":"markdown"},"source":{"39fdacf9":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import clear_output\nfrom matplotlib import pyplot as plt\n\nfrom keras.callbacks import Callback\nfrom keras.models import Model\nimport keras.layers as l","b486a960":"class PlotLearning(Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        \n        self.logs = []\n        \n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.i += 1\n        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n        \n        clear_output(wait=True)\n        \n        ax1.set_yscale('Log')\n        ax1.plot(self.x, self.losses, label=\"loss\")\n        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n        ax1.legend()\n        \n        ax2.plot(self.x, self.acc, label=\"acc\")\n        ax2.plot(self.x, self.val_acc, label=\"val_acc\")\n        ax2.legend()\n        \n        plt.show()\n        \n        \nplot = PlotLearning()","538a6138":"data = pd.read_csv('..\/input\/Iris.csv')\ndata = data.drop(['Id'] ,axis=1)\ndata.columns","962c640e":"encoder = LabelBinarizer()\nunique_labels = np.unique(data.Species)\ntransfomed_label = encoder.fit_transform(unique_labels)\nfor label, encoding in zip(unique_labels, transfomed_label):\n    print(label,'==>',encoding)","1731301d":"y = encoder.transform(data.Species.values)\n\ndata = data.drop(['Species'] ,axis=1)\n\nX = data.values\n\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle= True)","50fc2563":"input_layer = l.Input((4,))\n\nhidden = l.Dense(4, activation=None)(input_layer)\nhidden = l.BatchNormalization()(hidden)\nhidden = l.Activation('tanh')(hidden)\n\nhidden = l.Dense(8, activation=None)(hidden)\nhidden = l.BatchNormalization()(hidden)\nhidden = l.Activation('tanh')(hidden)\n\nhidden = l.Dense(8, activation=None)(hidden)\nhidden = l.BatchNormalization()(hidden)\nhidden = l.Activation('tanh')(hidden)\n\noutput = l.Dense(len(unique_labels), activation='softmax')(hidden)\n\nmodel = Model(input_layer, output)\nmodel.compile(\n    optimizer='Adam',\n    loss='categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel.summary()\nmodel.fit(x_train,y_train, epochs=100, validation_data=(x_valid, y_valid), shuffle=True, callbacks=[plot])","7d20a795":"model.evaluate(x_valid, y_valid)","30f87efe":"model.save('Iris Flower Classsifier.h5')","d82882f7":"**Custom Callback Defined Below to plot realtime accuracy loss graph**"}}