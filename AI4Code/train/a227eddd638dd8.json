{"cell_type":{"a7466fc2":"code","8a6e530a":"code","1133ff4f":"code","a44cee59":"code","a3712313":"code","1bf05529":"code","80364620":"code","36f66941":"code","581945f0":"code","1d70b603":"code","85121bab":"code","5d78b158":"code","8196601b":"code","a0676531":"code","32ba3626":"code","a46613ed":"code","e0908375":"code","7bc1c70d":"code","498fc4ef":"code","5a21babd":"markdown","d0af3c5f":"markdown","b813ed59":"markdown","ef982013":"markdown","9df52369":"markdown"},"source":{"a7466fc2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8a6e530a":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout","1133ff4f":"dataset_train = pd.read_csv('\/kaggle\/input\/google-stock-price\/Google_Stock_Price_Train.csv')\ntraining_set = dataset_train.iloc[:, 1:2].values","a44cee59":"# Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = sc.fit_transform(training_set)","a3712313":"X_train = []\ny_train = []\nfor i in range(60, 1258):\n    X_train.append(training_set_scaled[i-60:i, 0])\n    y_train.append(training_set_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)","1bf05529":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))","80364620":"regressor = Sequential()","36f66941":"regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))","581945f0":"regressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))","1d70b603":"regressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))","85121bab":"regressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))","5d78b158":"regressor.add(Dense(units = 1))","8196601b":"regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')","a0676531":"regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)","32ba3626":"dataset_test = pd.read_csv('\/kaggle\/input\/google-stock-price\/Google_Stock_Price_Test.csv')\nreal_stock_price = dataset_test.iloc[:, 1:2].values","a46613ed":"dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)","e0908375":"X_test = []\nfor i in range(60, 80):\n    X_test.append(inputs[i-60:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))","7bc1c70d":"predicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)","498fc4ef":"# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","5a21babd":"### Part 2 - Building the RNN\n","d0af3c5f":"### Importing the Keras libraries and packages\n","b813ed59":"# Visualising the results","ef982013":"### Part 3 - Making the predictions and visualising the results\n","9df52369":"### Importing the training set\n"}}