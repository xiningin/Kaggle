{"cell_type":{"cd174562":"code","e67de5e0":"code","8c26097a":"code","1f6b949f":"code","a553e8c8":"code","000192bf":"code","5af0644a":"code","2425026d":"code","d459de93":"code","87ebd20a":"code","2ab065da":"code","5a6d0e6d":"code","262ce4ea":"code","66d8c9ed":"code","73626211":"code","22a8f9b3":"code","67f8cdac":"code","097dc0b4":"code","1768e60b":"markdown","4773b58c":"markdown","7f3b6f7a":"markdown","f4d98800":"markdown","f55fb31e":"markdown","f2227901":"markdown","a9741e7b":"markdown","f2bcebc4":"markdown"},"source":{"cd174562":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e67de5e0":"data = pd.read_csv(\"..\/input\/pokemon.csv\")","8c26097a":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","1f6b949f":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","a553e8c8":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","000192bf":"# Plotting all data \ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\n# it is confusing","5af0644a":"# subplots\ndata1.plot(subplots = True)\nplt.show()","2425026d":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","d459de93":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True)","87ebd20a":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","2ab065da":"data.describe()","5a6d0e6d":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","262ce4ea":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","66d8c9ed":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","73626211":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","22a8f9b3":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","67f8cdac":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","097dc0b4":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","1768e60b":"**RESAMPLING PANDAS TIME SERIES**\n\n* Resampling: statistical method over different time intervals\n* Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\n* https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","4773b58c":"**In this part, you learn:**\n\n* Review of pandas\n* Building data frames from scratch\n* Visual exploratory data analysis\n* Statistical explatory data analysis\n* Indexing pandas time series\n* Resampling pandas time series","7f3b6f7a":"**INDEXING PANDAS TIME SERIES**\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","f4d98800":"**BUILDING DATA FRAMES FROM SCRATCH**\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n* zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","f55fb31e":"**REV\u0130EW of PANDAS**\n\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy","f2227901":"**Data Science Tutorial For Everyone #4**\n\n**Pandas Foundation:**\n\n* Review of pandas\n* Building data frames from scratch\n* Visual exploratory data analysis\n* Statistical explatory data analysis\n* Indexing pandas time series\n* Resampling pandas time series","a9741e7b":"**STATISTICAL EXPLORATORY DATA ANALYSIS**\n\nI already explained it at previous parts. However lets look at one more time.\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","f2bcebc4":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"}}