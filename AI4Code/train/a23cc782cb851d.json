{"cell_type":{"bf46384c":"code","1ff14922":"code","d44eac41":"code","31a3054d":"code","460462e4":"code","8ac3e0e0":"code","72b448a8":"code","84bfba33":"code","2efcc537":"code","80cc5368":"code","baa13fc7":"code","d53ece02":"code","286d93bf":"code","27277307":"code","ae1f79b8":"code","aee01e32":"code","23e8a3e1":"code","708ed365":"code","1725ba1d":"code","88ec02e0":"code","c5025a07":"code","ef4c01c8":"code","0d7cb929":"code","5c5a52ca":"code","5341b051":"code","f9212a46":"code","04cf6a2d":"code","b80b9db4":"code","57ac9d56":"code","b8385ae5":"code","8291f2af":"code","252dc90e":"code","156f85b5":"code","8f862dca":"code","9d4b4f68":"code","8ef42f5b":"code","042f5ec4":"code","0313c3a0":"code","3b249964":"code","c7b4be76":"code","bb1a8699":"code","665f4d7e":"code","27fad0a8":"code","ccdbf553":"code","c7a9d311":"code","d73c875f":"markdown","590a550a":"markdown","5b8fa59f":"markdown","8ba27ab0":"markdown","c70d32c5":"markdown","a2a687cb":"markdown","d8130606":"markdown","3ce89a9e":"markdown","feeee0f1":"markdown","3e4cd68c":"markdown","2fe6dbea":"markdown","a89a2a00":"markdown"},"source":{"bf46384c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ff14922":"#Loading\ndf = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","d44eac41":"#Examine first five rows\ndf.head()","31a3054d":"#get info\ndf.info()","460462e4":"#check stats\ndf.describe()","8ac3e0e0":"#number of rows and columns\ndf.shape","72b448a8":"#Check for nul values\ndf.isnull().sum()","84bfba33":"#Count of Fraudulent and normal transactions\ndf['Class'].value_counts()","2efcc537":"#Lets visualise it\nsns.barplot(x=df['Class'].value_counts().index,y=df['Class'].value_counts(),data=df)\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.title('Fraudulent Vs Normal Transactions')\nplt.show()","80cc5368":"#reationship between time and amount\nplt.scatter(df['Amount'],df['Time'],color='purple')\nplt.xlabel('Amount')\nplt.ylabel('Time')\nplt.show()","baa13fc7":"#Amount spent by each class\npivot = df.pivot_table(index=['Class'], values=['Amount'], aggfunc='sum')\npivot","d53ece02":"#Fraudulent transactions involve more money\nsns.barplot(x=df['Class'],y=df['Amount'],data=df)\nplt.show()","286d93bf":"#lets check the correlations of all variables with the target\nmatrix_corr = df.corr().index\nplt.figure(figsize=(20,26))\nsns.heatmap(df[matrix_corr].corr(),annot=True,cmap='YlOrRd')","27277307":"#lets get the x\nx=df[['V1', 'V2', 'V3', 'V4', 'V5', 'V7', 'V9', 'V10',\n       'V11', 'V12', 'V14', 'V16', 'V17', 'V18']]\n","ae1f79b8":"#lets get the y\ny = df['Class']","aee01e32":"#splitting\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","23e8a3e1":"#Count of Fraudulent and normal transactions\ndf['Class'].value_counts()","708ed365":"#Lets visualise it\nsns.barplot(x=df['Class'].value_counts().index,y=df['Class'].value_counts(),data=df)\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.title('Fraudulent Vs Normal Transactions')\nplt.show()","1725ba1d":"#setting oversampler\noversamp=RandomOverSampler(1)","88ec02e0":"#fit oversample on data\nx_train_os,y_train_os=oversamp.fit_sample(x_train,y_train)","c5025a07":"#instantiate logistic regression\nlog_classify = LogisticRegression(random_state=1)","ef4c01c8":"#logistic reg hyperparameters\nparam_dict = {'C': [0.1, 0.5, 1, 5, 10, 50, 100]}\nlog_model = GridSearchCV(log_classify, param_dict, cv=5, scoring='accuracy')","0d7cb929":"#fit to training data\nlog_model.fit(x_train_os,y_train_os)","5c5a52ca":"#predict test\ny_pred=log_model.predict(x_test)","5341b051":"#check the accuracy of the model\nprint(accuracy_score(y_test,y_pred))","f9212a46":"#check the recall and precisionof the model\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","04cf6a2d":"#instantiate naive bayes\nclf = GaussianNB()","b80b9db4":"#fit the model\nclf.fit(x_train_os,y_train_os)","57ac9d56":"#predict the test data\ny_pred_n  = clf.predict(x_test)","b8385ae5":"#check the accuracy\nprint(accuracy_score(y_test,y_pred_n))","8291f2af":"#check for recall and precision\nprint(confusion_matrix(y_test,y_pred_n))\nprint(classification_report(y_test,y_pred_n))","252dc90e":"#set the decision tree\nclf = tree.DecisionTreeClassifier(random_state=4)","156f85b5":"#fit to training data\nclf.fit(x_train_os,y_train_os)","8f862dca":"#predict the test data\ny_pred_t = clf.predict(x_test)","9d4b4f68":"#check the accuracy\nprint(accuracy_score(y_test,y_pred_t))","8ef42f5b":"#check for recall and precision\nprint(confusion_matrix(y_test,y_pred_t))\nprint(classification_report(y_test,y_pred_t))","042f5ec4":"print(\"Precision = {}\".format(precision_score(y_test, y_pred_t, average='macro')))\nprint(\"Recall = {}\".format(recall_score(y_test, y_pred_t, average='macro')))\nprint(\"Accuracy = {}\".format(accuracy_score(y_test, y_pred_t)))","0313c3a0":"#hard voting\nhard_vote = VotingClassifier(estimators=[ ('lr', log_model), ('nb', clf), ('dct', clf)], voting='hard')","3b249964":"#fit to training data\nhard_vote.fit(x_train_os,y_train_os)","c7b4be76":"#make predictions for the test set\ny_pred_h = hard_vote.predict(x_test)","bb1a8699":"#check recall and precision\nprint(confusion_matrix(y_test,y_pred_h))\nprint(classification_report(y_test,y_pred_h))","665f4d7e":"#soft vote\nsoft_vote = VotingClassifier(estimators=[ ('lr', log_model), ('nb', clf), ('dct', clf)], voting='soft')","27fad0a8":"#fit to training data\nsoft_vote.fit(x_train_os,y_train_os)","ccdbf553":"#predict the test\ny_pred_s = soft_vote.predict(x_test)","c7a9d311":"print(confusion_matrix(y_test,y_pred_s))\nprint(classification_report(y_test,y_pred_s))","d73c875f":"ENSEMBLE:VOTING CLASSIFIERS","590a550a":"# DEALING WITH IMBALANCED DATASET","5b8fa59f":"STEPS:\n* EXPLORATORY DATA ANALYSIS\n* FIXING IMBALANCE \n* FEATURE SELECTION\n* MODEL BUILDING","8ba27ab0":"NAIVE BAYES MODEL","c70d32c5":"# NOTE:MODEL WITH THE HIGHIEST RECALL WILL BE THE BEST MODEL ,SINCE WE ARE TRYING TO MININMIZE FALSE NEGATIVE(model predicting fruadulent transactions as normal)","a2a687cb":"# PLEASE LEAVE UR COMMENTS AND FEEDBACK","d8130606":"#  GOAL:CREDIT CARD FRAUD PREDICTION","3ce89a9e":"DATA EXPLOATION\n","feeee0f1":"LOGISTIC REGRESSION","3e4cd68c":"MODEL SUMMARY:\n* LOGISTIC REGRESSION(ACCURACY-97% AND RECALL- 94%).\n* NAIVE BAYES(ACCURACY-98 AND RECALL-92%)\n* DECISION TREE(ACCURACY-99% AND RECALL-85%)\n* HARD-VOTING-CLASSIFIER(ACCURACY-99% AND RECALL-84%)\n* SOFT-VOTING-CLASSIFIER(ACCURACY-","2fe6dbea":"# MODEL BUILDING","a89a2a00":"DECISION TREE MODEL"}}