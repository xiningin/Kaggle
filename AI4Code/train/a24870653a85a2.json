{"cell_type":{"956eb489":"code","195e6e8b":"code","7e1e515b":"code","1e535546":"code","aa010794":"code","e6cbba52":"code","e9ff11e0":"code","ae55aa08":"code","a4b20f11":"code","852e5cb1":"code","fd60a93c":"code","e6084d15":"code","9481db11":"code","d9e49521":"markdown","c7eb64b8":"markdown","326a200c":"markdown","8c4d3aba":"markdown","b0a59215":"markdown","b3bfe14b":"markdown","f2b22522":"markdown","08cd386b":"markdown"},"source":{"956eb489":"import os\nimport joblib\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\ntf.random.set_seed(42)\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline\n\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nmpl.rcParams['figure.dpi'] = 600\n\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('INFO')\n\n# ------------------------------------------------------------------------\n\ntrain_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\n\nx_train = train_df.drop(columns = 'label').values.reshape(-1, 28, 28)\ny_train = train_df['label'].values\nx_test = test_df.drop(columns = 'label').values.reshape(-1, 28, 28)\ny_test = test_df['label'].values\n\nlabel_names = [\n    'T-shirt\/top',\n    'Trouser',\n    'Pullover',\n    'Dress',\n    'Coat',\n    'Sandal',\n    'Shirt',\n    'Sneaker',\n    'Bag',\n    'Ankle Boot'\n]","195e6e8b":"train_df.describe()","7e1e515b":"i = np.random.randint(x_train.shape[0], size = 100)\n\nfig, axs = plt.subplots(10, 10, sharex = True, sharey = True, figsize = (15, 20))\nplt.subplots_adjust(wspace = .05, hspace = .3)\n\nx_select = x_train[i]\ny_select = y_train[i]\n\nfor i in range(10):\n    for j in range(10):\n        k = i * 10 + j\n        axs[i][j].imshow(255 - x_select[k], cmap = 'gray', vmin = 0, vmax = 255)\n        axs[i][j].axes.get_xaxis().set_visible(False)\n        axs[i][j].axes.get_yaxis().set_visible(False)\n        axs[i][j].set_title('%s' % label_names[y_select[k]])","1e535546":"test_df.describe()","aa010794":"i = np.random.randint(x_test.shape[0], size = 100)\n\nfig, axs = plt.subplots(10, 10, sharex = True, sharey = True, figsize = (15, 20))\nplt.subplots_adjust(wspace = .05, hspace = .3)\n\nx_select = x_test[i]\ny_select = y_test[i]\n\nfor i in range(10):\n    for j in range(10):\n        k = i * 10 + j\n        axs[i][j].imshow(255 - x_select[k], cmap = 'gray', vmin = 0, vmax = 255)\n        axs[i][j].axes.get_xaxis().set_visible(False)\n        axs[i][j].axes.get_yaxis().set_visible(False)\n        axs[i][j].set_title('%s' % label_names[y_select[k]])","e6cbba52":"x_label_counts_df = pd.DataFrame(train_df['label'].value_counts() \/ train_df.shape[0] * 100).reset_index()\nx_label_counts_df.columns = ['label', 'percent']\nx_label_counts_df['label'] = x_label_counts_df['label'].apply(lambda x: label_names[x])\n\nplt.figure(figsize = (10, 2))\n\nax = sns.barplot(\n    data = x_label_counts_df,\n    x = 'label',\n    y = 'percent',\n    color = sns.color_palette('Paired')[1]\n)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_title('Distribution of labels in the training data')\nax.set_xlabel('Label')\nax.set_ylabel('Percentage')\nax.set_ylim(0, 100)","e9ff11e0":"x_label_counts_df = pd.DataFrame(test_df['label'].value_counts() \/ test_df.shape[0] * 100).reset_index()\nx_label_counts_df.columns = ['label', 'percent']\nx_label_counts_df['label'] = x_label_counts_df['label'].apply(lambda x: label_names[x])\n\nplt.figure(figsize = (10, 2))\n\nax = sns.barplot(\n    data = x_label_counts_df,\n    x = 'label',\n    y = 'percent',\n    color = sns.color_palette('Paired')[1]\n)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_title('Distribution of labels in the test data')\nax.set_xlabel('Label')\nax.set_ylabel('Percentage')\nax.set_ylim(0, 100)","ae55aa08":"from tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\n\nN_CONV_BRANCHES = 2\nDROPOUT = 0.2\n\ninput_shape = (x_train.shape[1], x_train.shape[2], 1)\nn_classes = len(label_names)\n\ninputs = layers.Input(shape = input_shape)\n\nb_in = layers.experimental.preprocessing.Rescaling(1. \/ 255)(inputs)\n\nbranches = [b_in] * N_CONV_BRANCHES\n\nfor i in range(N_CONV_BRANCHES):\n    for filter_size in [64, 128, 256, 256]:\n        branches[i] = layers.Conv2D(\n            filters = filter_size,\n            kernel_size = 3,\n            padding = 'same',\n        )(branches[i])\n        branches[i] = layers.MaxPool2D(pool_size = (2, 2))(branches[i])\n        branches[i] = layers.ReLU()(branches[i])\n        branches[i] = layers.Dropout(DROPOUT)(branches[i])\n\nb_out = layers.concatenate(branches)\nb_out = layers.Flatten()(b_out)\n\nb_out = layers.Dense(units = 256)(b_out)\nb_out = layers.BatchNormalization()(b_out)\nb_out = layers.ReLU()(b_out)\nb_out = layers.Dropout(DROPOUT)(b_out)\n\noutputs = layers.Dense(units = n_classes)(b_out)\n\nmodel = Model(inputs, outputs)\ntf.keras.utils.plot_model(model, show_shapes = True, show_layer_names = False)","a4b20f11":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\noptimizer = Adam(\n    learning_rate = 5e-4,\n)\n\nmodel.compile(\n    optimizer = optimizer,\n    loss = SparseCategoricalCrossentropy(from_logits = True),\n    metrics = ['accuracy']\n)\n\nCHECKPOINT_DIR = '.\/checkpoint'\n\ncheckpoint_call = ModelCheckpoint(\n    filepath = CHECKPOINT_DIR,\n    save_weights_only = True,\n    monitor = 'val_accuracy',\n    mode = 'max',\n    save_best_only = True\n)\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_data = (x_test, y_test),\n    epochs = 50,\n    callbacks = [checkpoint_call],\n    batch_size = 1024,\n)","852e5cb1":"fig, axs = plt.subplots(1, 2, figsize = (10, 4))\nplt.subplots_adjust(wspace = .3)\nplt.suptitle('Learning curves')\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(ax = axs[0])\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot(ax = axs[1])\n\naxs[0].set_xlabel('Iterations')\naxs[0].set_ylabel('Loss')\naxs[0].legend(labels = ['Train', 'Test'])\n\naxs[1].set_xlabel('Iterations')\naxs[1].set_ylabel('Accuracy')\naxs[1].legend(labels = ['Train', 'Test'])","fd60a93c":"model.load_weights(CHECKPOINT_DIR)\npredictor_model = tf.keras.Sequential([model, layers.Softmax()])","e6084d15":"predictions = np.argmax(predictor_model.predict(x_test), axis = 1)\n\naccuracy = sum(predictions == y_test) \/ len(y_test)\n\nprint('Test accuracy: %.2f%%' % (accuracy * 100))","9481db11":"i = np.random.randint(x_test.shape[0], size = 100)\n\nx_select = x_test[i]\ny_select = y_test[i]\n\npredictions = predictor_model.predict(x_select)\ny_pred = np.argmax(predictions, axis = 1)\n\nfig, axs = plt.subplots(10, 10, sharex = True, sharey = True, figsize = (15, 22))\nplt.subplots_adjust(wspace = .05, hspace = .3)\n\nfor i in range(10):\n    for j in range(10):\n        k = i * 10 + j\n        pred_tick = '\u2713' if y_pred[k] == y_select[k] else '\u2717'\n        axs[i][j].imshow(255 - x_select[k], cmap = 'gray', vmin = 0, vmax = 255)\n        axs[i][j].axes.get_xaxis().set_visible(False)\n        axs[i][j].axes.get_yaxis().set_visible(False)\n        axs[i][j].set_title('%s (%s)\\n(%.2f%%)' % (label_names[y_pred[k]], pred_tick, predictions[k][y_pred[k]] * 100))","d9e49521":"## Training\n\nI've trained the model using the Adam optimiser, using accuracy as metric to choose the best weights, training with checkpoints. The optimiser runs 50 epochs with batch size 1024.","c7eb64b8":"# Dataset\n\n## Train data\n\n### Summary","326a200c":"## 100 random predictions on the test dataset","8c4d3aba":"### 100 random images from the test dataset","b0a59215":"## Test data\n\n### Summary","b3bfe14b":"# Data analysis\n\n## Distribution of labels\n\nThe dataset seems to be perfectly balanced, each class being represented in the same exact number of samples:","f2b22522":"### 100 random images from the train dataset","08cd386b":"# Model\n\n## Architecture\n\nI've obtained the best results so far with a convolutional model with two branches:"}}