{"cell_type":{"9f5a7add":"code","e0a51569":"code","f7f73cd4":"code","21993ded":"code","7c5ce61b":"code","85ed4988":"code","a8aaf317":"code","67549600":"code","e1f9db2d":"code","5057ec07":"code","dd98d03f":"code","8be937a8":"code","58d6f0df":"code","f57b066e":"code","15e0b948":"code","06b334a3":"code","73c24086":"code","ca25d3f4":"code","1531c153":"code","2a3c0dc7":"code","e4fdd939":"code","8690eaeb":"code","c18d1191":"code","88bf2490":"code","1ce2588f":"code","6e9b4d1a":"code","4ace55d2":"markdown","50123e5d":"markdown","378bd688":"markdown","abbed8bc":"markdown","3da3c914":"markdown","f814b6d3":"markdown","5cb88cdd":"markdown","c0536d7c":"markdown","a47c0bd0":"markdown","db921451":"markdown","a77fac3f":"markdown","ae97a8f2":"markdown","534921a4":"markdown","62c31826":"markdown"},"source":{"9f5a7add":"import torch\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import datasets, transforms, models, utils\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","e0a51569":"data_dir = '..\/input\/coin-data-sampled\/data_sampled\/data'\n\ntrain_dir = data_dir + '\/train'\nvalid_dir = data_dir + '\/validation'\ntest_dir = data_dir + '\/test'","f7f73cd4":"norm_mean = [0.485, 0.456, 0.406]\nnorm_std = [0.229, 0.224, 0.225]\n\n# norm_mean = [0.2972239085211309 , 0.24976049135203868, 0.28533308036347665]\n# norm_std = [0.2972239085211309, 0.24976049135203868, 0.28533308036347665]","21993ded":"train_transforms = transforms.Compose([transforms.Resize(224),\n                                        transforms.CenterCrop(224),\n                                        transforms.RandomRotation(45),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.RandomVerticalFlip(),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(\n                                            norm_mean,\n                                            norm_std\n                                        )\n                                      ])\n\nvalid_transforms = transforms.Compose([transforms.Resize(224),\n                                        transforms.CenterCrop(224),\n                                        transforms.ToTensor(), \n                                        transforms.Normalize(\n                                            norm_mean,\n                                            norm_std\n                                        )\n                                      ])\n\ntest_transforms = transforms.Compose([transforms.Resize(224),\n                                        transforms.CenterCrop(224),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(\n                                            norm_mean,\n                                            norm_std\n                                        )\n                                     ])\n\ntrain_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\nvalid_dataset = datasets.ImageFolder(valid_dir, transform=valid_transforms)\ntest_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=60, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=60, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=60, shuffle=True)","7c5ce61b":"dataloaders = {'train_loader': train_loader, 'valid_loader': valid_loader, 'test_loader': test_loader}","85ed4988":"def imshow_numpy(image, ax=None, title=None):\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10,8))\n        \n    ax.grid(False)\n\n    # PyTorch tensors assume the color channel is the first dimension\n    # but matplotlib assumes is the third dimension\n    image = image.transpose((1, 2, 0))\n    \n    \n    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n    image = np.clip(image, 0, 1)\n    \n    ax.imshow(image)\n    ","a8aaf317":"images, labels = next(iter(dataloaders['train_loader']))\ngrid_images = utils.make_grid(images) \nimshow_numpy(grid_images.numpy())","67549600":"import json\n\nwith open('..\/input\/cat-to-namejson\/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)\n    \n# Make sure it is loaded right\ncat_to_name[\"23\"]","e1f9db2d":"model_resnet = models.resnet34(pretrained=False)\n\n# Freeze parameters in pre trained ResNET\n#for param in model_resnet152.parameters():\n    #param.requires_grad = False\n\nout_classes = len(cat_to_name)\n\nmodel_resnet.fc = nn.Sequential(\n    nn.Linear(512, 512),\n    nn.ReLU(),\n    nn.Dropout(p=0.7),\n    nn.Linear(512, out_classes)\n)\n\n# Check the modified fc layer\nprint(model_resnet.fc)","5057ec07":"# Pre-trained  resnet34\nmodel_resnet34 = models.resnet34(pretrained=True)\n\n# Freeze parameters in pre trained ResNET\n#for param in model_resnet34.parameters():\n    #param.requires_grad = False\n\nout_classes = len(cat_to_name)\n\nmodel_resnet34.fc = nn.Sequential(\n    nn.Linear(512, 512),\n    nn.ReLU(),\n    nn.Dropout(p=0.7),\n    nn.Linear(512, out_classes)\n)\n\n# Check the modified fc layer\nprint(model_resnet34.fc)","dd98d03f":"is_GPU_available = torch.cuda.is_available()\n\nif is_GPU_available:\n    device = 'cuda'\n    print('training on GPU')\nelse:\n    device = 'cpu'\n    print('training on CPU')\n\n# Choose the model I want to choose\nmy_model = model_resnet34\n\nmy_model.to(device)","8be937a8":"my_model.class_to_idx = train_dataset.class_to_idx\n\ndef save_model(model, val_loss):\n    model = {\n        'state_dict': model.state_dict(),\n        'fc': model.fc,\n        'min_val_loss': val_loss,\n        'class_to_idx': model.class_to_idx,\n    }\n    \n    torch.save(model, 'checkpoint_cnn_resnet34.pth')","58d6f0df":"def load_checkpoint_resnet152(filepath):\n    checkpoint = torch.load(filepath)\n    model = models.resnet152(pretrained=True)\n    \n    # Freeze parameters (in case we want to train more)\n    for param in model.parameters():\n        param.requires_grad = False\n        \n    model.fc = checkpoint['fc']\n    model.load_state_dict(checkpoint['state_dict'])\n    model.class_to_idx = checkpoint['class_to_idx']\n    \n    return model","f57b066e":"def train (my_model, criterion, epochs = 15, lr=0.001, min_valid_loss=np.Inf):\n    best_model = my_model\n    optimizer = optim.SGD(my_model.parameters(), lr, momentum=0.9)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, verbose=True,\n                                                     patience=5, min_lr=0.00001)\n    \n    for epoch in range(epochs):\n        train_loss = 0.0\n        valid_loss = 0.0\n        accuracy = 0.0\n        \n        my_model.train()\n        for images, labels in dataloaders['train_loader']:\n            optimizer.zero_grad()\n\n            # Move tensors to GPU if available\n            inputs, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            output = my_model(inputs)\n\n            loss = criterion(output, labels)\n            loss.backward()\n\n            # Update weights\n            optimizer.step()\n            \n            train_loss += loss.item() * inputs.size(0)\n\n        my_model.eval()\n        for inputs, labels in dataloaders['valid_loader']:\n            # Move tensors to GPU if available\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            output = my_model(inputs)\n\n            val_loss = criterion(output, labels)\n            \n            valid_loss += val_loss.item() * inputs.size(0)\n            \n            # Accuracy\n            _, predicted = output.topk(1, dim=1)\n            equals = predicted == labels.view(*predicted.shape)\n            accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        # Calculate the losses\n        train_loss = train_loss\/len(dataloaders[\"train_loader\"].dataset)\n        valid_loss = valid_loss\/len(dataloaders[\"valid_loader\"].dataset)\n        accuracy = (accuracy\/len(dataloaders[\"valid_loader\"]))*100\n        \n        # Update lr\n        scheduler.step(valid_loss)\n        \n        print('Epoch {}'.format(epoch + 1))\n        print('Train loss: {0:.2f}'.format(train_loss))\n        print('Valid loss: {0:.2f}'.format(valid_loss))\n        print('Accuracy: {0:.2f}%'.format(accuracy))\n        \n        if valid_loss < min_valid_loss:\n            min_valid_loss = valid_loss\n            save_model(my_model, valid_loss)\n            # best_model stores the model with the lowest valid loss\n            best_model = my_model\n            print('Valid loss has decreased. Saving model...')\n        \n        print('--------------------------------------------')\n    return best_model","15e0b948":"my_model = my_model\nepochs = 100\nlr = 0.001\ncriterion = nn.CrossEntropyLoss()\nmin_loss = np.Inf","06b334a3":"my_model = train(my_model=my_model, criterion=criterion, epochs=epochs, lr=lr, min_valid_loss=min_loss)","73c24086":"# Load the best model\n# my_model = load_checkpoint_resnet152('..\/input\/checkpoint-cnn-resnet152-b\/checkpoint_cnn_resnet152_b.pth')\n","ca25d3f4":"def check_accuracy_on_test(model, data, cuda=False):\n    model.eval()\n    model.to(device) \n    \n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in (dataloaders[data]):\n            \n            images, labels = images.to(device), labels.to(device)\n            output = model(images)\n            _, predicted = torch.topk(output, 1)\n            \n            equals = predicted == labels.view(*predicted.shape)\n            correct += int(torch.sum(equals))\n            total += len(images)\n           \n    accuracy = '{0:.2f}'.format((correct \/ total)*100)    \n    print('Accuracy of the network on the test images: {}\/{} --> {}%'.format(correct, total, accuracy))\n    \ncheck_accuracy_on_test(my_model, 'test_loader', True)","1531c153":"import PIL\nfrom PIL import Image","2a3c0dc7":"def process_image (image):\n    image_pil = Image.open(image)\n    width, height = image_pil.size\n    if width > height:\n        image_pil.thumbnail((np.Inf, 256))\n    else:\n        image_pil.thumbnail((256, np.Inf))\n    \n    # Crop image\n    image_pil = image_pil.resize((224, 224))\n    \n    # Convert to numpy and normalize\n    np_image = np.array(image_pil)\/255\n                                            \n    mean = norm_mean\n    std = norm_std\n    np_image = (np_image - mean)\/std\n    \n    # Transpose for image to have the correct dimensions, depth first.\n    np_image = np_image.transpose(2, 0, 1)\n    \n    # Convert to tensor\n    tensor_image = torch.from_numpy(np_image).float()\n    \n    return tensor_image","e4fdd939":"test_image_path = '..\/input\/coin-data-sampled\/data_sampled\/data\/test\/10\/014__5 Centavos_brazil.jpg'\n\n# Permute dimensions just for plotting the image.\nprocessed_image = process_image(test_image_path).permute(1, 2, 0)\nimgplot = plt.imshow(processed_image)\nplt.show()","8690eaeb":"def predict(image, model, topk=102):\n    model.eval()\n    model.to(\"cpu\")\n    \n    # Load the image\n    image = image.unsqueeze(0)\n\n    # Forward pass.\n    output = model.forward(image)\n    # Get the top element\n    top_prob, top_class = torch.topk(output, topk)\n    \n    # Get the probabilities\n    sm = torch.nn.Softmax()\n    top_prob = sm(top_prob)\n    \n    # Convert to arrays.\n    top_prob = top_prob.squeeze().detach().numpy()\n    top_class = top_class.squeeze().detach().numpy()\n    \n    # Get only the top 5 items\n    top_prob = top_prob[:5]\n    top_class = top_class[:5]\n    \n    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n    \n    # Get the actual labels\n    top_classes = [idx_to_class[i] for i in top_class]\n    \n    return top_prob, top_classes","c18d1191":"len(cat_to_name)","88bf2490":"def get_class_name (model, top_class):\n    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n    # Get the actual labels\n    top_classes = [idx_to_class[i] for i in top_class]\n    \n    return top_classes","1ce2588f":"def plot_predictions(img, top_prob_array, classes, mapper, labels):\n    # imshow expects the 3rd dimension at the end.\n    img = img.numpy().transpose(1,2,0)\n    \n    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n    img = np.clip(img, 0, 1)\n    # The real coin name\n    coin_name = cat_to_name[str(labels[0])]\n    ax1.set_title(coin_name)\n    ax1.imshow(img)\n    \n    # The predictions\n    y_pos = np.arange(len(top_prob_array))\n    ax2.barh(y_pos, top_prob_array)\n    ax2.set_yticks(y_pos)\n    ax2.set_yticklabels([mapper[x] for x in classes])\n    ax2.invert_yaxis()\n    \n    if labels[0] == classes[0]:\n        print('Correct!')\n    else:\n        print('Incorrect!')","6e9b4d1a":"dataiter = iter(dataloaders[\"test_loader\"])\nimages, labels = dataiter.next()\nimg = images[0]\nlabels = get_class_name(my_model, labels.numpy())\n\n# Get the probabilities and classes\nprobs, classes = predict(img, my_model)\nplot_predictions(img, probs, classes, cat_to_name, labels)","4ace55d2":"### Pre-process input image\n\nWhen we recieve an input image we need to pre-process it so that it has the right dimensions as well as the proper normalizationo before we feed it to the  network.","50123e5d":"### Make a prediction\n\nThis function will make a prediction. We pass the function a pre-processed image and the model and it returns the top 5 predictions.","378bd688":"### Check for GPU","abbed8bc":"### Test accuracy","3da3c914":"### Sanity Checking \n\nBefore we finish lets check our predictions with some of our test images to make sure that the network is not doing anything strange.","f814b6d3":"# Coin Classifier","5cb88cdd":"### Defining hyperparameters","c0536d7c":"### Train the model","a47c0bd0":"### Load the models","db921451":"### Visualize the data","a77fac3f":"### Load the data","ae97a8f2":"### Label Mapping","534921a4":"### Save and Load the checkpoint","62c31826":"### Train the network"}}