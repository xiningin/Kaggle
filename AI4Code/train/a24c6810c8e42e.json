{"cell_type":{"836b0f08":"code","5365f887":"code","ac535c93":"code","9de49446":"code","ad405bda":"code","1e9ab164":"code","7633f5eb":"markdown","67821067":"markdown","b9e742ea":"markdown","4e71263d":"markdown","c783ccb7":"markdown"},"source":{"836b0f08":"import os, glob, pickle\nimport urllib.request\nimport zipfile\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nif 'kid' in os.getcwd():\n    INP = '\/home\/kid\/covid\/data'\n    WBANK = f'{INP}\/wbank'\n    OUT = f'{WBANK}\/WDIrevision20200701'\nelif 'kaggle' in os.getcwd():\n    INP = '\/kaggle\/input\/wdi20200701'\n    OUT = '\/kaggle\/working'\n    WBANK = f'{OUT}\/wbank'\n    os.mkdir(WBANK)\nelse:\n    INP = '\/home\/jupyter\/input'\n    OUT = '\/home\/jupyter\/output'\n    WBANK = f'{INP}\/wbank'\n\n# INPUT:\n# f'{INP}\/WDI_CETS.csv'\n# f'{INP}\/WDIrevision_additions.csv'\n# f'{INP}\/WDIrevision_deletions.csv'\n# f'{INP}\/WDIrevision_codechanges.csv'\n# f'{INP}\/continent.csv'\n# DOWNLOAD:\n# f'{WBANK}\/API_{code}*.csv'\n# 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv'\n# OUTPUT:\n# f'{OUT}\/wbank01july_meta.csv'\n# f'{OUT}\/wbank01july_year.csv'\n# f'{OUT}\/wbank01july_nullRatio.csv'\n# f'{OUT}\/wbank01july_continentalMedian.csv'\n# f'{OUT}\/wbank01july_data.csv'\n# f'{OUT}\/wbank01july_log.txt'","5365f887":"cets = pd.read_csv(f'{INP}\/WDI_CETS.csv')\nprint(len(cets), cets['Series Code'].nunique())\nrevision = {}\ndummy = []\nfor nam in ['additions', 'deletions', 'codechanges']:\n    revision[nam] = pd.read_csv(f'{INP}\/WDIrevision_{nam}.csv', delimiter=';', parse_dates=['Date'])","ac535c93":"revision['additions'].rename(columns={'Additions': 'add'}, inplace=True)\nrevision['deletions'].rename(columns={'Deletions': 'drop'}, inplace=True)\nrevision['codechanges'].rename(columns={'Change in code': 'drop',\n                                        'new code': 'add'}, inplace=True)\nrevised = pd.concat([revision['additions'], revision['deletions'], revision['codechanges']], ignore_index=True)\nrevised.sort_values(by='Date', inplace=True)\nrevised","9de49446":"orig_cets = cets.copy()\nfor row, rowData in revised.iterrows():\n    if isinstance(rowData['add'], str):\n        cets.loc[len(cets), 'Series Code'] = rowData['add']\n    if isinstance(rowData['drop'], str):\n        cets = cets.loc[cets['Series Code']!=rowData['drop']]\nprint(len(cets), cets['Series Code'].nunique())\n# CETS contains duplicate series codes. 1273 unique series code altogether.","ad405bda":"for code in cets['Series Code'].unique():\n    if len(glob.glob(f'{WBANK}\/API_{code}*.csv'))==0:\n        url = f'http:\/\/api.worldbank.org\/v2\/country\/all\/indicator\/{code}?source=2&downloadformat=csv'\n        filename, hdr = urllib.request.urlretrieve(url)\n        try:\n            with zipfile.ZipFile(filename, 'r') as zf:\n                zf.extractall(WBANK)\n        except Exception as excep:\n            print(code, excep)","1e9ab164":"def processCountry(df):\n    df['Country\/Region'].replace({'Taiwan*': 'Taiwan',\n                                  'US'     : 'United States'}, inplace=True)\n    df.loc[df['Province\/State']=='Hong Kong', 'Country\/Region'] = 'Hong Kong'\n    df = df.loc[(df['Country\/Region']!='Diamond Princess') & (df['Country\/Region']!='MS Zaandam')]\n    df = df[['Country\/Region']].drop_duplicates()\n    return df\n\ndef insertContinent(df):\n    continent = pd.read_csv(f'{INP}\/continent.csv')\n    df = pd.merge(df, continent, on='Country\/Region', how='left', validate='many_to_one')    \n    print('Countries without <continent>:', df.loc[df['continent'].isnull(), 'Country\/Region'].unique(), file=fp)\n    return df\n\ndef redress(df):\n    meta = df[['Indicator Code', 'Indicator Name']].drop_duplicates()\n    meta.rename(columns={'Indicator Code': 'Name', \n                         'Indicator Name': 'Variable'}, inplace=True)\n    assert len(meta) == 1\n    assert 'Country Name' in df.columns and 'Indicator Code' in df.columns and 'Indicator Name' in df.columns\n    df.rename(columns={'Country Name': 'Country',\n                       'Indicator Code': 'Name', \n                       'Indicator Name': 'Variable'}, inplace=True)\n    df.replace({ 'Bahamas, The'                  : 'Bahamas',\n                 'Brunei Darussalam'             : 'Brunei',\n                 'Myanmar'                       : 'Burma',\n                 'Congo, Rep.'                   : 'Congo (Brazzaville)',\n                 'Congo, Dem. Rep.'              : 'Congo (Kinshasa)',\n                 'Czech Republic'                : 'Czechia',\n                 'Egypt, Arab Rep.'              : 'Egypt',\n                 'Gambia, The'                   : 'Gambia',\n                 'Iran, Islamic Rep.'            : 'Iran',\n                 'Korea, Dem. People\u2019s Rep.'     : 'Korea, South',\n                 'Kyrgyz Republic'               : 'Kyrgyzstan',\n                 'Lao PDR'                       : 'Laos',\n                 'Russian Federation'            : 'Russia',\n                 'St. Kitts and Nevis'           : 'Saint Kitts and Nevis',\n                 'St. Lucia'                     : 'Saint Lucia',\n                 'St. Vincent and the Grenadines': 'Saint Vincent and the Grenadines',\n                 'Slovak Republic'               : 'Slovakia',\n                 'Syrian Arab Republic'          : 'Syria',\n                 'Taiwan, China'                 : 'Taiwan',\n                 'Venezuela, RB'                 : 'Venezuela',\n                 'Yemen, Rep.'                   : 'Yemen',\n                 'Hong Kong SAR, China'          : 'Hong Kong',\n                 'Sub-Saharan Africa'           : 'Western Sahara'}, inplace=True)\n    df.set_index('Country', inplace=True)\n    return df, meta\n\ndef insertWBANK(df):\n    dfs = {}\n    meta, data, record = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n    for nfile, file in enumerate(glob.glob(f'{WBANK}\/API_*.csv')):\n        nam = file.split('API_')[1].upper().split('_DS2_EN')[0]\n        dff, tismeta = redress(pd.read_csv(file, skiprows=[0, 1, 2, 3]))\n        dfs[nam] = dff\n        meta = pd.concat([meta, pd.read_csv(file.replace('API', 'Metadata_Indicator_API'), index_col='INDICATOR_CODE')])\n        assert tismeta['Name'].unique()[0].upper() == nam\n    del meta['Unnamed: 4']\n    count = 0\n    for nam in dfs.keys():\n        dff = dfs[nam]\n        flag = False\n        for country, countryData in dff.iterrows():\n            tmp = ~countryData.isnull()\n            year = tmp.index[np.where(tmp)[0].max()]\n            if year.isnumeric():\n                data.loc[country, countryData['Name']] = countryData[year]\n                record.loc[country, countryData['Name']] = year\n                flag = True\n        if not flag:\n            print('nothing from', nam, file=fp)\n            meta = meta.loc[meta.index != nam]\n        else:\n            count += 1\n    data.index.name = 'Country'\n    record.index.name = 'Country'\n    meta.to_csv(f'{OUT}\/wbank01july_meta.csv')\n    record.to_csv(f'{OUT}\/wbank01july_year.csv')\n    print('count, data.shape, meta.shape:', count, data.shape, meta.shape)\n\n    df = pd.merge(data, df, how='right', left_on='Country', right_on='Country\/Region', validate='one_to_many')\n    nullRatio = pd.DataFrame()\n    for col in meta.index:\n        nullRatio.loc[col, 'INDICATOR_NAME'] = meta.loc[col, 'INDICATOR_NAME']\n        nullRatio.loc[col, 'nullRatio'] = np.sum(df[col].isnull())\/df.shape[0]\n    #   print('{:.2f} {}'.format(np.sum(data[col].isnull())\/data.shape[0], meta.loc[col, 'INDICATOR_NAME']))\n    nullRatio.sort_values(by='nullRatio', inplace=True, ascending=False)\n    nullRatio.index.name = 'INDICATOR_CODE'\n    nullRatio.to_csv(f'{OUT}\/wbank01july_nullRatio.csv')\n\n    print('*** REMOVING CODES WHERE NULLRATIO EXCEEDS 20%:', df.shape, '-', len(nullRatio.index[nullRatio['nullRatio']>.2]), end=' ')\n    df = df[df.columns ^ nullRatio.index[nullRatio['nullRatio']>.2].to_list()]\n    print('=', df.shape)\n\n    continentalMedian = df.groupby('continent').median()\n    if continentalMedian.isnull().any().any():\n        print('data not available for calculating continental median of', continentalMedian.isnull().any().sum(), 'topic codes')\n        print('cols with null:', continentalMedian.isnull().sum(axis=1), file=fp)\n        continentalMedian.to_csv(f'{OUT}\/wbank01july_continentalMedian.csv')\n\n        print('*** REMOVING CODES WHERE CONTINENTAL MEDIAN CANNOT BE CALCULATED:', df.shape, '->')\n        df = df[df.columns ^ continentalMedian.columns[continentalMedian.isnull().any()]]\n        print(df.shape)\n        \n    for col in df.columns[df.columns.str.contains(r'\\.')]:    \n        for continent, continentData in df.groupby('continent'):\n            df.loc[continentData.index, col] = df.loc[continentData.index, col].fillna(continentalMedian.loc[continent, col])\n        df[col] = df[col].astype('float')\n    return df\n\nif 'kid' in os.getcwd():\n    df = pd.read_csv(f'{INP}\/corona-virus-time-series-dataset\/COVID-19\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv', dtype={'Confirmed': 'int'})\nelse:\n    df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv', dtype={'Confirmed': 'int'})\n\nfile = f'{OUT}\/wbank01july_log.txt'\nif os.path.exists(file):\n    os.rename(file, file.replace('log', 'log_last'))\nwith open(file, 'w') as fp:\n    df = (df.pipe(processCountry)\n            .pipe(insertContinent)\n            .pipe(insertWBANK))\nif os.path.exists(file.replace('log', 'log_last')):\n    os.system(\"diff {} {}\".format(file, file.replace('log', 'log_last')))\nassert df.isnull().any().any()==False\n\ndf.set_index('Country\/Region', inplace=True)\ndf.to_csv(f'{OUT}\/wbank01july_data.csv')\nprint(len(df.columns[df.columns.str.contains(r'\\.')]))","7633f5eb":"# World Development Indicators (WDI) 2020-July-1 version","67821067":"# 2. Download","b9e742ea":"# 1. Get indicators","4e71263d":"# 3. Generate pandas dataframe","c783ccb7":"This notebook\n* **begins with the original CETS (Catalog of Economic Time Series)[1] containing 1504 indicators and updates** the list according to additions, deletions and code changes released by World Bank on 1st July 2020[2]. This step produces a list of 1273 indicators, each uniquely identified by an indicator code. Indicators come coded according to the convention `TT.GGG.SSSS.EE`, where `TT` is the 2-character code for the topic, `GGG` the 3-character code for the general subject, `SSSS` the 4-character code for the specific subject and `EE` the 2-character code for the extension. As an example, `SH.IMM.HEPB` is the indicator code for *HepB3 immunization*, a social health (`SH`) indicator.\n* **downloads** the data for 1270 of the 1273 indicators; one .csv file per indicator. The 3 indicators missing (`SI.POV.2DAY`, `SI.POV.GAP2` and `TX.VAL.MRCH.R6.CD`), when searched [3], are reported as 'no longer available'. \n* **removes** 434 of the 1270 indicators. Indicators are identified for removal based on the proportion of missing values. The 434 identified for removal do not have data for >20% of the 187 countries of interest [4]. We are left with 1270 - 434 = 836 indicators.\n* **renames** some countries so that country names agree with those of [4].\n* **extracts the most recent value** (out of multiple years where data is available) for each indicator for each country. Which year's data gets taken for which country -- this info is logged in `f'{OUT}\/wbank01july_year.csv'`.\n* **fills any missing value** with the continental median of the respective indicator.\n* **collates the 836 indicators for 187 countries into a single 187x838 pandas dataframe**. The 2 additional columns are `Country\/Region` and `continent`.\n\n[1] http:\/\/databank.worldbank.org\/data\/download\/site-content\/WDI_CETS.xls\n\n[2] http:\/\/databank.worldbank.org\/data\/download\/WDIrevisions.xls\n\n[3] https:\/\/data.worldbank.org\/indicator\/\n\n[4] https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/"}}