{"cell_type":{"24c3b97c":"code","874bb9d7":"code","945ef647":"code","42aa8656":"code","df15d48f":"code","017ba34b":"code","cf362254":"code","6638cf9c":"code","3f7fb51e":"code","9035616d":"code","5020ed11":"code","cce7757c":"code","c64c7056":"code","6ee6184f":"code","202679d5":"code","8b26736e":"code","12176608":"code","72cd5f3d":"code","edfd0aa6":"code","03e7a1bd":"code","25c57995":"code","1ab38c62":"code","4eedd223":"code","3d39dd6c":"code","4bc9657e":"code","61781cba":"code","6903b269":"code","f2490a0f":"code","fd82cbd7":"code","d169b05e":"code","c643e30c":"code","bcc062b1":"markdown","3819b602":"markdown","03b15c52":"markdown","af572adf":"markdown","ac263ccd":"markdown","6a2b5fbf":"markdown","4e7d1faa":"markdown","363096da":"markdown","768a5c52":"markdown"},"source":{"24c3b97c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","874bb9d7":"import random\nfrom sklearn.metrics import mean_squared_error,roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom lightgbm import LGBMClassifier\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn import preprocessing\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","945ef647":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')","42aa8656":"print('Train size: ', len(train))\nprint('Test size: ', len(test))","df15d48f":"train.head()","017ba34b":"test.head()","cf362254":"train.info()","6638cf9c":"test.info()","3f7fb51e":"#Check if there'is null values\ntrain.isnull().sum()","9035616d":"#Check if there'is null values\ntest.isnull().sum()","5020ed11":"train.SibSp.value_counts()","cce7757c":"train.Parch.value_counts()","c64c7056":"train.Cabin.describe()","6ee6184f":"train.Ticket.describe()","202679d5":"# Numerical features distribution \ni = 1\nplt.figure()\nfig, ax = plt.subplots(1, 2,figsize=(20, 8))\nfor feature in ['Age','Fare']:\n    plt.subplot(1, 2,i)\n    sns.histplot(train[feature],color=\"blue\", kde=True,bins=100, label='train')\n    sns.histplot(test[feature],color=\"olive\", kde=True,bins=100, label='test')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","8b26736e":"#complete embarked with mode\ntrain['Embarked'].fillna(train['Embarked'].mode()[0], inplace = True)\ntest['Embarked'].fillna(test['Embarked'].mode()[0], inplace = True)\n\n#complete sex with mode\ntrain['Sex'].fillna(train['Sex'].mode()[0], inplace = True)\ntest['Sex'].fillna(test['Sex'].mode()[0], inplace = True)\n\n#complete missing age with mean\ntrain['Age'].fillna(train['Age'].mean(), inplace = True)\ntest['Age'].fillna(test['Age'].mean(), inplace = True)\n\n#complete missing fare with mean\ntrain['Fare'].fillna(test['Fare'].median(), inplace = True)\ntest['Fare'].fillna(test['Fare'].median(), inplace = True)","12176608":"# Categorical features distribution \ni = 1\nplt.figure()\nfig, ax = plt.subplots(3, 2,figsize=(20, 16))\nfor feature in ['Sex','Embarked','SibSp','Pclass','Parch']:\n    plt.subplot(3, 2,i)\n    sns.histplot(train[feature],color=\"blue\", label='train')\n    sns.histplot(test[feature],color=\"olive\", label='test')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","72cd5f3d":"# Target distibution\nsns.catplot(x=\"Survived\", kind=\"count\", palette=\"ch:.25\", data=train)","edfd0aa6":"columns = [c for c in train.columns if c not in ['PassengerId','Cabin','Ticket','Survived','Name']]","03e7a1bd":"#Features correlation\ncorr = train[columns+['Survived']].corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","25c57995":"train_objs_num = len(train)\ndataset = pd.concat(objs=[train[columns], test[columns]], axis=0)\ndataset_preprocessed = pd.get_dummies(dataset,columns=['Sex','Embarked','Parch','SibSp'])\ntrain_preprocessed = dataset_preprocessed[:train_objs_num]\ntest_preprocessed = dataset_preprocessed[train_objs_num:]","1ab38c62":"train_preprocessed","4eedd223":"test_preprocessed","3d39dd6c":"params = {'reg_alpha': 0.025698237956455088,\n 'reg_lambda': 0.2384750191428652,\n 'colsample_bytree': 0.9,\n 'subsample': 0.4,\n 'bagging_freq': 4,\n 'learning_rate': 0.02,\n 'max_depth': 100,\n 'num_leaves': 36,\n 'min_child_samples': 271,\n 'cat_smooth': 55,\n 'random_state': 48,\n 'n_estimators': 20000,\n 'metric': 'binary_logloss',\n \"objective\": \"binary\"}","4bc9657e":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold,StratifiedKFold\npreds = np.zeros(test.shape[0])        \nkf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True)                  \naccuracy=[]   # list contains accuracy for each fold  \nn=0   \nfor trn_idx, test_idx in kf.split(train[columns],train['Survived']):\n    X_tr,X_val=train_preprocessed.iloc[trn_idx],train_preprocessed.iloc[test_idx]\n    y_tr,y_val=train['Survived'].iloc[trn_idx],train['Survived'].iloc[test_idx]\n    model = LGBMClassifier(**params) \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False) \n    sub[str(n)] = model.predict(test_preprocessed)\n    accuracy.append(accuracy_score(y_val, model.predict(X_val))) \n    print(n+1,accuracy[n])                                                                                       \n    n+=1 ","61781cba":"np.mean(accuracy)","6903b269":"# most 10 important features for lgb model\nfrom optuna.integration import lightgbm as lgb\nlgb.plot_importance(model, max_num_features=10, figsize=(10,10))\nplt.show()","f2490a0f":"from sklearn.metrics import classification_report\nprint(classification_report(y_val, model.predict(X_val) ))","fd82cbd7":"sub","d169b05e":"df=sub[['0','1','2','3','4']].mode(axis=1) # select the most frequent predicted class by our model\nsub['Survived']=df[0]    \nsub=sub[['PassengerId','Survived']]\nsub['Survived']=sub['Survived'].apply(lambda x : int(x))\nsub.to_csv('submission.csv',index=False)","c643e30c":"sub","bcc062b1":"# One Hot Encoding for Encoding Categorical Features","3819b602":"# Hi kagglers \ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0f and Welcome to this new competition!","03b15c52":"# Exploratory Data Analysis","af572adf":"# Making a Submission","ac263ccd":"* As we can see the data is unbalanced that's why I'll use StratifiedKFold to split data","6a2b5fbf":"# I hope that you find this kernel usefull\ud83c\udfc4","4e7d1faa":"# Modeling","363096da":"## Impute missing values","768a5c52":"* I'm not going to consider the attributes Cabin, Ticket and PassengerId as important features in our training data"}}