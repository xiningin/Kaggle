{"cell_type":{"ef1f446c":"code","bff5acc0":"code","3c3c040b":"code","6c6c8977":"code","dbcb9775":"code","943313a8":"code","59a2818c":"code","a25fed92":"code","36144251":"code","7ad1b68a":"code","9683a652":"code","c7181432":"code","19a37bb5":"code","044694e5":"code","86debd33":"code","10c440bf":"code","f184ef21":"code","9c118935":"code","5288d246":"code","6c44ecfe":"code","8f24b001":"code","8c14d42e":"code","3b576890":"code","e775693a":"code","815715c6":"code","cb29740e":"code","a79cc7be":"markdown","08786f9d":"markdown","c3ee3a1c":"markdown","93f24f5b":"markdown","3ef50ba4":"markdown","8289a749":"markdown","5f8b552a":"markdown"},"source":{"ef1f446c":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nfrom cv2 import imread, createCLAHE \nimport cv2\n%matplotlib inline\nfrom numpy import load\nfrom numpy import savez_compressed\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom os import listdir\nfrom numpy import asarray\nfrom pydicom import dcmread\nimport glob \nfrom os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU\nfrom matplotlib import pyplot","bff5acc0":"train = pd.read_csv('\/kaggle\/input\/kvasirinstrument\/kvasir-instrument\/train.txt')","3c3c040b":"from numpy import savez_compressed","6c6c8977":"images_ = []\nmasks_ =  []\nsize=(256,256)\nfor i in range(len(train)):\n    name = train.values[i][0]\n    \n\n    img_name = '\/kaggle\/input\/kvasirinstrument\/kvasir-instrument\/images\/images\/'+ name + '.jpg'\n    img_mask = '\/kaggle\/input\/kvasirinstrument\/kvasir-instrument\/masks\/masks\/' + name + '.png'\n    \n    \n    \n    img = load_img(img_name, target_size=size)\n    img = img_to_array(img)\n    \n    mask = load_img(img_mask, target_size=size)\n    mask = img_to_array(mask)\n    images_.append(img)\n    masks_.append(mask)\n    \nimages_ =  np.array(images_)\nmasks_ = np.array(masks_)\nprint(images_.shape, masks_.shape)\nfilename = 'maps_256.npz'\nsavez_compressed(filename, images_, masks_)","dbcb9775":"plt.imshow(images_[0]\/255)","943313a8":"test = pd.read_csv('\/kaggle\/input\/kvasirinstrument\/kvasir-instrument\/test.txt')\nimages_ = []\nmasks_ =  []\nsize=(256,256)\nfor i in range(len(test)):\n    name = test.values[i][0]\n    \n\n    img_name = '\/kaggle\/input\/kvasirinstrument\/kvasir-instrument\/images\/images\/'+ name + '.jpg'\n    img_mask = '\/kaggle\/input\/kvasirinstrument\/kvasir-instrument\/masks\/masks\/' + name + '.png'\n    \n    \n    \n    img = load_img(img_name, target_size=size)\n    img = img_to_array(img)\n    \n    mask = load_img(img_mask, target_size=size)\n    mask = img_to_array(mask)\n    images_.append(img)\n    masks_.append(mask)\n    \nimages_ =  np.array(images_)\nmasks_ = np.array(masks_)\nprint(images_.shape, masks_.shape)\nfilename1 = 'testmaps_256.npz'\nsavez_compressed(filename1, images_, masks_)","59a2818c":"plt.imshow(images_[0]\/255)","a25fed92":"def plotMask(X,y):\n    sample = []\n    \n    for i in range(6):\n        left = X[i]\n        right = y[i]\n        combined = np.hstack((left,right))\n        sample.append(combined)\n        \n        \n    for i in range(0,6,3):\n\n        plt.figure(figsize=(25,10))\n        \n        plt.subplot(2,3,1+i)\n        plt.imshow(sample[i].astype('uint8'))\n        \n        plt.subplot(2,3,2+i)\n        plt.imshow(sample[i+1].astype('uint8'))\n        \n        \n        plt.subplot(2,3,3+i)\n        plt.imshow(sample[i+2].astype('uint8'))\n        \n        plt.show()","36144251":"# Load training and testing data\ndatatrain = load(filename)\nX_train, y_train = datatrain['arr_0'], datatrain['arr_1']\nplotMask(X_train, y_train)","7ad1b68a":"assert X_train.shape == y_train.shape","9683a652":"images = X_train\nmask  = y_train","c7181432":"from tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras import backend as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', dtype='float32')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(3, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","19a37bb5":"model = unet(input_size=(256,256,3))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n                  metrics=[dice_coef, 'binary_accuracy'])\nmodel.summary()","044694e5":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=3,\n                                   verbose=1, mode='min', epsilon=0.0002, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","86debd33":"from IPython.display import clear_output\nfrom tensorflow.keras.optimizers import Adam \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nmodel.compile(optimizer=Adam(lr=0.00001), \n              loss=[dice_coef_loss], \n           metrics = [dice_coef, 'binary_accuracy', 'AUC'])\n\ntrain_vol, validation_vol, train_seg, validation_seg = train_test_split((images)\/255, \n                                                            (mask>127).astype(np.float32), \n                                                            test_size = 0.1,random_state = 2018)\n\ntrain_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg, \n                                                            test_size = 0.1, \n                                                            random_state = 2018)","10c440bf":"len(train_vol)","f184ef21":"len(test_vol)","9c118935":"len(validation_vol)","5288d246":"\nplt.subplot(131)\nplt.imshow(train_vol[0])\nplt.title('train')\n\nplt.subplot(132)\nplt.imshow(test_vol[0])\nplt.title('test')\n\nplt.subplot(133)\nplt.imshow(validation_vol[0])\nplt.title('validation')","6c44ecfe":"loss_history = model.fit(x = train_vol,y = train_seg,batch_size = 8,epochs = 1000,validation_data =(test_vol,test_seg) , callbacks=callbacks_list)\n\nmodel.save('model.h5')","8f24b001":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(loss_history.history['loss'], '-', label = 'Loss')\nax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', label = 'Accuracy')\nax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',label = 'Validation Accuracy')\nax2.legend()","8c14d42e":"dcetrain = []\nfor i in range(len(train_vol)):\n    fg = model.evaluate(train_vol[i:i+1, :, :], train_seg[i:i+1, :, :])\n    dcetrain.append(fg[1])\ndf = pd.DataFrame(dcetrain)\ndf.to_csv('train.csv')","3b576890":"dcetest = []\nfor i in range(len(test_vol)):\n    fg = model.evaluate(test_vol[i:i+1, :, :], test_seg[i:i+1, :, :])\n    dcetest.append(fg[1])\ndf = pd.DataFrame(dcetest)\ndf.to_csv('test.csv')","e775693a":"dcevalidation_vol = []\nfor i in range(len(validation_vol)):\n    fg = model.evaluate(validation_vol[i:i+1, :, :], validation_seg[i:i+1, :, :])\n    dcevalidation_vol.append(fg[1])\ndf = pd.DataFrame(dcevalidation_vol)\ndf.to_csv('valid.csv')","815715c6":"data = load('testmaps_256.npz')\nX_test, y_test = data['arr_0'], data['arr_1']\nimages = X_test\nmask  = y_test\nimages.shape\nimages = images\/255 \nmask = (mask>127).astype(np.float32)\n\nplt.imshow(images[0])","cb29740e":"X_test, y_test = data['arr_0'], data['arr_1']\nimages = X_test\nmask  = y_test\nimages.shape\nimages = images\/255 \nmask = (mask>127).astype(np.float32)\ndcetrain = []\nfor i in range(len(images)):\n    fg = model.evaluate(images[i:i+1, :, :], mask[i:i+1, :, :])\n    dcetrain.append(fg[1])\ndf = pd.DataFrame(dcetrain)\ndf.to_csv('finaltest.csv')","a79cc7be":"# plot few samples","08786f9d":"# validation vol","c3ee3a1c":"# import all libraries","93f24f5b":"# prepare model","3ef50ba4":"# Final Test set ","8289a749":"# for testing evaluation ","5f8b552a":"# for training evaluation "}}