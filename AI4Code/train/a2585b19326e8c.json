{"cell_type":{"2ce65de2":"code","2a2f8127":"code","7f3373f0":"code","6b4907d3":"code","13b1fe5b":"code","8d26e021":"code","83aa3c2a":"code","43506a93":"code","35fcd728":"code","9ad132f2":"code","e2895df2":"code","36de4016":"code","b8c461ea":"code","c3ac197d":"code","33923d52":"code","47341464":"code","bfd81b14":"code","86db0372":"code","7a35ac05":"code","278dcd9a":"code","49a7139f":"code","b346d362":"code","43361594":"code","3ab4598a":"code","433016d6":"code","232ea00d":"code","ea9c9508":"code","b9408a6e":"code","c49c5ebb":"code","511795f7":"code","d4642f67":"code","90d5653a":"code","218f7731":"code","c9d5cd41":"code","d65533f5":"code","88b503fd":"code","2187868e":"code","70252f77":"code","2953a82a":"code","9d0271c3":"code","24cc8ffb":"code","da89e4d8":"code","473405df":"code","503cbdbd":"code","3e902a82":"markdown","3adc6cf5":"markdown","dfdec72d":"markdown","7bfeb9fe":"markdown","79110b5d":"markdown","17082970":"markdown","f7a6dfad":"markdown","0fc5edb1":"markdown","13751f80":"markdown","b334951d":"markdown","785b1fad":"markdown","2d252656":"markdown","1742199b":"markdown","9c867768":"markdown","83b35ec3":"markdown","11dc9a8b":"markdown","828b7e9e":"markdown","03a65a2e":"markdown"},"source":{"2ce65de2":"!pip install py7zr","2a2f8127":"!python -m py7zr x ..\/input\/cifar-10\/train.7z \/kaggle\/working\/","7f3373f0":"!python -m py7zr x ..\/input\/cifar-10\/test.7z \/kaggle\/working\/","6b4907d3":"!ls ..\/working","13b1fe5b":"train_images_path = \"\/kaggle\/working\/train\"\ntest_images_path = \"\/kaggle\/working\/test\"","8d26e021":"# !conda install --yes -c anaconda tensorflow\n\n# !conda install --yes -c conda-forge glob2\n# !conda install --yes -c conda-forge opencv\n\n# !conda install --yes -c anaconda numpy\n# !conda install --yes -c anaconda pandas\n\n# !conda install --yes -c conda-forge scikit-learn \n# !conda install --yes -c anaconda pydot\n# !conda install --yes -c conda-forge matplotlib","83aa3c2a":"# !conda update conda","43506a93":"!pip install tensorflow-gpu\n\n!pip install glob2\n!pip install opencv\n\n!pip install numpy\n!pip install pandas\n\n!pip install scikit-learn \n!pip install pydot\n!pip install matplotlib","35fcd728":"!ls \/kaggle\/working","9ad132f2":"import glob\nimport os\nimport cv2\nimport numpy as np \n        \n# Since the folders only contain Images, the size of the datasets is the number of files in it's folder\nnum_of_train_images = len(glob.glob(train_images_path+\"\/*\"))\nnum_of_test_images = len(glob.glob(test_images_path+\"\/*\"))\n\n# Let's create a dataset from the images\ntrain_images = [[]]*num_of_train_images\nfor dir_name, _, filenames in os.walk('\/kaggle\/working\/train'):\n    for filename in filenames:\n        image_index = int(filename.split(\".\")[0])-1\n        img = cv2.imread(os.path.join(dir_name,filename))\n        # Add the image to the dataset\n        train_images[image_index] = img\n        \ntest_images = [[]]*num_of_test_images\nfor dir_name, _, filenames in os.walk('\/kaggle\/working\/test'):\n    for filename in filenames:\n        image_index = int(filename.split(\".\")[0])-1\n        img = cv2.imread(os.path.join(dir_name,filename))\n        # Add the image to the dataset\n        test_images[image_index] = img\n        \n        \n# The RGB values are between 0 and 255, let's divide them so the values will be between 0 and 1\ntrain_images = np.asarray(train_images, dtype=float)\/255\ntest_images = np.asarray(test_images, dtype=float)\/255\n\n\n\n# # If you want, you can save the dataset and load it, instead of running this block each time\n# np.save(\"..\/working\/train_images.npy\", train_images)\n# np.save(\"..\/working\/test_images.npy\", test_images)","e2895df2":"test_images.shape","36de4016":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","b8c461ea":"# for Keras dataset only\n# Loading the dataset from Keras. Note: here we are also given the test labels.\n\n# import pandas as pd\n# import tensorflow as tf\n# from tensorflow import keras\n# data = keras.datasets.cifar10\n# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n# train_labels = pd.read_csv('..\/input\/cifar-10\/trainLabels.csv')\n# keras.utils.to_categorical(train_labels).astype('uint8')","c3ac197d":"# train_images = np.load(\"..\/working\/train_images.npy\")\n# test_images = np.load(\"..\/working\/test_images.npy\")","33923d52":"test_images.shape","47341464":"test_images.shape","bfd81b14":"train_labels = pd.read_csv('\/kaggle\/input\/cifar-10\/trainLabels.csv')\n\nprint(\"Number of train images: \", train_images.shape[0])\nprint(\"Number of test images: \", test_images.shape[0])","86db0372":"fig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = train_images[i]\n    fig.add_subplot(rows, columns, i, title=[train_labels.label[i]])\n    plt.imshow(img)\nplt.show()","7a35ac05":"import numpy as np \nimport pandas as pd \nfrom tensorflow import keras\n\n# Model architecture\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import Sequential, datasets,models,layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D, DepthwiseConv2D, BatchNormalization\nfrom tensorflow.keras.models import load_model\n\n# Data processing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical","278dcd9a":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n# Make sure you are running on a GPU!","49a7139f":"train_labels.head(5)","b346d362":"classes = list(set(list(train_labels.label)))\nclasses","43361594":"num_classes=len(classes)","3ab4598a":"labels_dict =  {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\nlabels_dict_reversed = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}","433016d6":"train_labels['Category'] = train_labels.label.map(labels_dict_reversed)","232ea00d":"# The categories are represented by numbers from 0 to 9.\n# Our network needs another representation- a vector of 0's and 1's.\n# This function converts the categories to a One-hot vector.\n# For example, if the label is 3, then the function will return [0,0,0,1,0,0,0,0,0,0]\ntrain_labels_categories = keras.utils.to_categorical(train_labels.Category, num_classes)#.astype('uint8')\n\n# Splitting the training data into train set and validation set\nx_train, x_val, y_train, y_val = train_test_split(train_images, train_labels_categories, random_state=0, test_size=0.05)\n\n# for Keras dataset only\n# x_test = test_images.astype('float32')\/255\n# y_test = keras.utils.to_categorical(test_labels, num_classes).astype('uint8')","ea9c9508":"train_labels_categories","b9408a6e":"x_train.shape","c49c5ebb":"x_val.shape","511795f7":"# Data augumetation\ndatagen = ImageDataGenerator(\n        rotation_range=0.3,  \n        zoom_range = 0.1,  \n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=True)\n","d4642f67":"model_layers = [\n    Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same', input_shape=(32, 32, 3)),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu, depth_multiplier=3),\n#     MaxPooling2D(2, 2),\n    Dropout(rate =0.1),\n    \n    \n    Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n#     MaxPooling2D(2, 2),\n    Dropout(rate = 0.1),\n    \n    Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n#     MaxPooling2D(2, 2),\n    Dropout(rate = 0.4),\n    \n    Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu),\n    \n    \n    Conv2D(256, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n    \n    \n    \n    Conv2D(512, (1, 1), activation='relu', strides=(2, 2), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu),\n    \n#     MaxPooling2D(2, 2),\n    Dropout(rate = 0.4),\n    \n    Flatten(),\n    Dropout(rate = 0.3),\n    Dense(2048, activation='relu'),\n    Dropout(rate = 0.3),\n    Dense(512, activation='relu'),\n    Dropout(rate = 0.4),\n    Dense(10, activation='softmax')\n] \nmodel = Sequential(model_layers)\n","90d5653a":"# A summary of the model. \n# We can see how many parameters are in each layer and the total number of parameters.\nmodel.summary()","218f7731":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","c9d5cd41":"# Visualization of the model\nkeras.utils.plot_model(model)","d65533f5":"# The last epoch does not necessarily produces the best model. \n# We want to choose our model wisely,\n# so we will save the model that achieved the highest accuracy on the validation set\nmcp_save = ModelCheckpoint('..\/working\/best_model', save_best_only=True, monitor='val_accuracy', mode='max')","88b503fd":"# Training the model on the augmented train set\n# We reached a score of ~90% after 100 epochs. 5 epochs won't get a score near that, but on Kaggle each epcoh takes a long time.\n# Choose the number of epochs that fits your machine. Same for batch_size, which we set to 512 on my machine.\nnum_of_epochs = 5\nbatch_size = 64 \n# The number of iteration in one epoch is ceil((size of training data)\/(batch size)). ceil(47,500\/64)=ceil(742.1875)=743\nmodel.fit(datagen.flow(x_train, y_train, batch_size=batch_size), validation_data=(x_val, y_val), callbacks=[mcp_save], epochs=num_of_epochs)","2187868e":"# for Keras dataset only\n# model.evaluate(x_test, y_test)","70252f77":"# Take the best model under the criterion chosen.\n# Here we took the model that achieved the highest accuracy on the validation set.\nmodel_ = load_model('..\/working\/best_model', compile=False)","2953a82a":"# Now let's use our model to predict the classes of each image in the test set\ntest_predictions = model.predict_classes(test_images)\ntest_predictions","9d0271c3":"test_predictions_df = pd.DataFrame(test_predictions)","24cc8ffb":"# It's easy to use the sample submission file to create our own submission file\nsamples = pd.read_csv(\"..\/working\/cifar-10\/sampleSubmission.csv\", index_col=False)\n\n# Replace the sample labels with those our model predicted\nsamples.label= test_predictions\n\n# Our model predicts the number of the classes of each image.\n# Kaggle is expecting a string, for example, if our model predicted \"2\" we need to translate it to \"bird\"\nsamples.replace({\"label\":labels_dict}, inplace=True)","da89e4d8":"# Let's see how our model predicted some images\nfig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = test_images[i]\n    fig.add_subplot(rows, columns, i, title=samples.label[i])\n    plt.imshow(img)\nplt.show()","473405df":"samples.to_csv(\"..\/working\/submission.csv\", index=False)","503cbdbd":"!kaggle competitions submit -c cifar-10 -f ..\/working\/submission.csv -m \"Submitted using the notebook\"","3e902a82":"We can see that the train accuracy keeps improving but the validation accuracy is not, Which means we are Overfitting the model to the data.","3adc6cf5":"![image.png](attachment:image.png)","dfdec72d":"## 2. data exploration","7bfeb9fe":"The data contains two folders and two files: <br>\n> train - a folder with 50,000 train images, which are labeled in trainLabels.csv <br>\n> test - a folder with 300,000 test Images with no labels <br>\n> trainLabels.csv - contains the labels of the train images <br>\n> sampleSubmission.csv - an example of the submission file expected by Kaggle","79110b5d":"## 3. Build the Model","17082970":"### Prepare the data","f7a6dfad":"# CIFAR-10 - Object Recognition in Images- for beginners (score: ~90%)","0fc5edb1":"## 5. Predict and create Submission file for Kaggle","13751f80":"We found two versions of the data- <br>\n> 1. from Kaggle <br>\n> 2. from Kers datasets <br>\n\nThe colors in the Kaggle dataset are different from those in the Keras dataset. <br>\nHowever, we found that the Keras dataset is easier to work with, <br>\nand you can find some commented lines regarding the keras dataset. <br>\nThis notebook uses the Kaggle dataset in order to make submission to Kaggle easier. <br>","b334951d":"## 4. Train the model","785b1fad":"In order to avoid Overfitting, it is recommended to use augmentation. <br>\nFor example, we can rotate the image, change the zoom and the centeralization.","2d252656":"## 1. Data","1742199b":"![image.png](attachment:image.png)","9c867768":"The images come in RBG format, 32X32 pixels. Therefore (32,32,3). <br>\nThere are 50,000 train images and 300,000 test images (in the Kaggle dataset) <br>\nLet's plot some train images with their true labels:","83b35ec3":"This notebook refers to Kaggle competition \"CIFAR-10 - Object Recognition in Images\",\nwhich can be found here: https:\/\/www.kaggle.com\/c\/cifar-10 . <br>\nIt is written for begginers as we were at when we joined the competition. <br>\nThe notebook was checked on a clean environment and it installs everything needed. <br>\nWe hope it will help you to get started. Feel free to contact us with any question or comment. <br><br>\nMaor Vaknin - vaknin.mj@gmail.com <br>\nItay Cohen - itaycohen89@gmail.com <br>","11dc9a8b":"### This section downloads and builds the data from Kaggle and installs the needed packages.\n### You only need to run it once. If It's not your first run, you can jump to section 2.","828b7e9e":"### prerequisites","03a65a2e":"### Install Kaggle API and download the data"}}