{"cell_type":{"7e6bc3f8":"code","489f2832":"code","3c643990":"code","c9609137":"code","04b91178":"code","133e6ece":"code","110257d8":"code","b3984de3":"code","dd94144d":"code","14903e33":"code","ac451d8f":"code","2c33bf49":"code","1a6da4a8":"code","a840752a":"code","d0ad822f":"code","3fbfae30":"code","3903eee3":"code","eeff2a81":"code","0f98ea40":"code","e5a9a171":"code","b17aba25":"code","6d630136":"code","5b19d74a":"code","47b26bf3":"code","f73b0296":"code","cbb3c1ef":"code","b36e97f3":"markdown","a0b897e5":"markdown","fb0c64b9":"markdown","a1159606":"markdown","b38cc4ac":"markdown","c80e30ef":"markdown","0185d312":"markdown","54ce705c":"markdown","30dc93df":"markdown","3cf7dcf5":"markdown","4ed55e1d":"markdown","2b3af800":"markdown","ab8b55e5":"markdown","218cebc2":"markdown","3803ebe3":"markdown","fd274994":"markdown"},"source":{"7e6bc3f8":"!nvidia-smi","489f2832":"!nvcc --version","3c643990":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","c9609137":"!pip install \/kaggle\/input\/detectron2\/omegaconf-2.0.6-py3-none-any.whl\n\n!pip install \/kaggle\/input\/detectron2\/iopath-0.1.8-py3-none-any.whl\n\n!pip install \/kaggle\/input\/detectron2\/fvcore-0.1.3.post20210317\/fvcore-0.1.3.post20210317\/\n\n!pip install \/kaggle\/input\/detectron2\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar\n\n!pip install \/kaggle\/input\/detectron2\/detectron2-0.4cu110-cp37-cp37m-linux_x86_64.whl","04b91178":"import warnings\nwarnings.filterwarnings('ignore') #Ignore \"future\" warnings and Data-Frame-Slicing warnings.\n\nimport numpy as np \nimport pandas as pd \nfrom datetime import datetime\nimport time\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nimport matplotlib.pyplot as plt\n\nfrom math import ceil\nfrom typing import Any, Dict, List\nfrom typing import List\nfrom dataclasses import dataclass, field\nfrom typing import Dict\nfrom numpy import ndarray\nfrom glob import glob\n\n\nimport os, json, cv2, random\nimport skimage.io as io\n\nimport pickle\nfrom pathlib import Path\nfrom typing import Optional\nfrom tqdm import tqdm\n\n# numba\nimport numba\nfrom numba import jit\n\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.utils.visualizer import ColorMode","133e6ece":"# --- configs ---\nthing_classes = [\n    \"atypical\",\n    \"indeterminate\",\n    \"negative\",\n    \"typical\"\n]\ndebug=False\n\ncategory_name_to_id = {class_name: index for index, class_name in enumerate(thing_classes)}\ncategory_name_to_id","110257d8":"import pandas as pd \ndf_meta = pd.read_csv(\"..\/input\/siim-covid19-resized-1024px\/meta.csv\")\ntest_meta=df_meta[df_meta.split==\"test\"]\n\n\ndef get_COVID19_data_dicts_test(\n    imgdir: Path, test_meta: pd.DataFrame, use_cache: bool = True, debug: bool = False,\n):\n    debug_str = f\"_debug{int(debug)}\"\n    cache_path = Path(\".\") \/ f\"dataset_dicts_cache_test.pkl\"\n    if not use_cache or not cache_path.exists():\n        print(\"Creating data...\")\n        # test_meta = pd.read_csv(imgdir \/ \"test_meta.csv\")\n        df_meta = pd.read_csv(\"..\/input\/siim-covid19-resized-1024px\/meta.csv\")\n        test_meta=df_meta[df_meta.split==\"test\"]\n        if debug:\n            test_meta = test_meta.iloc[:10]  # For debug....\n        # Load 1 image to get image size.\n        image_id = test_meta.iloc[0,0]\n        #image_path = str(imgdir \/ \"test\" \/ f\"{image_id}.jpg\")\n        image_path = str(f'..\/input\/siim-covid19-resized-1024px\/test\/{image_id}.jpg')\n        image = cv2.imread(image_path)\n        resized_height, resized_width, ch = image.shape\n        print(f\"image shape: {image.shape}\")\n\n        dataset_dicts = []\n        for index, test_meta_row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n            record = {}\n\n            image_id, height, width,s = test_meta_row.values\n            #filename = str(imgdir \/ \"test\" \/ f\"{image_id}.jpg\")\n            filename = str(f'..\/input\/siim-covid19-resized-1024px\/test\/{image_id}.jpg')\n            record[\"file_name\"] = filename\n            # record[\"image_id\"] = index\n            record[\"image_id\"] = image_id\n            record[\"height\"] = resized_height\n            record[\"width\"] = resized_width\n            # objs = []\n            # record[\"annotations\"] = objs\n            dataset_dicts.append(record)\n        with open(cache_path, mode=\"wb\") as f:\n            pickle.dump(dataset_dicts, f)\n\n    #print(f\"Load from cache {cache_path}\")\n    with open(cache_path, mode=\"rb\") as f:\n        dataset_dicts = pickle.load(f)\n    return dataset_dicts","b3984de3":"imgdir = \"..\/input\/siim-covid19-resized-1024px\"\nDatasetCatalog.register(\n    \"COVID19_data_test\", lambda: get_COVID19_data_dicts_test(imgdir, test_meta, debug=debug)\n)\n","dd94144d":"MetadataCatalog.get(\"COVID19_data_test\").set(thing_classes=thing_classes)\nmetadata = MetadataCatalog.get(\"COVID19_data_test\")\ndataset_dicts = get_COVID19_data_dicts_test(imgdir, test_meta, debug=debug)","14903e33":"from detectron2.config import get_cfg\ncfg = get_cfg()\nconfig_name = \"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\" \n#config_name = \"COCO-Detection\/faster_rcnn_R_101_C4_3x.yaml\"\ncfg.merge_from_file(model_zoo.get_config_file(config_name))\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # \n\n\ncfg.MODEL.WEIGHTS = \"..\/input\/d\/ammarnassanalhajali\/1siim-covid19-detectron2-weights\/output\/model_final.pth\"\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.180 # set the testing threshold for this model\n\npredictor = DefaultPredictor(cfg)","ac451d8f":"def format_pred(labels: ndarray, boxes: ndarray, scores: ndarray) -> str:\n    pred_strings = []\n    for label, score, bbox in zip(labels, scores, boxes):\n        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n        if label==2:\n            labelstr='none'\n        else:\n            labelstr='opacity'\n        pred_strings.append(f\"{labelstr} {score:0.3f} {xmin} {ymin} {xmax} {ymax}\") \n    return \" \".join(pred_strings)\n\ndef predict_batch(predictor: DefaultPredictor, im_list: List[ndarray]) -> List:\n    with torch.no_grad():  # https:\/\/github.com\/sphinx-doc\/sphinx\/issues\/4258\n        inputs_list = []\n        for original_image in im_list:\n            # Apply pre-processing to image.\n            if predictor.input_format == \"RGB\":\n                # whether the model expects BGR inputs or RGB\n                original_image = original_image[:, :, ::-1]\n            height, width = original_image.shape[:2]\n            # Do not apply original augmentation, which is resize.\n            # image = predictor.aug.get_transform(original_image).apply_image(original_image)\n            image = original_image\n            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n            inputs = {\"image\": image, \"height\": height, \"width\": width}\n            inputs_list.append(inputs)\n        predictions = predictor.model(inputs_list)\n        return predictions","2c33bf49":"if debug:\n    dataset_dicts = dataset_dicts[:30]\n\nresults_list = []\nindex = 0\nbatch_size = 1\n\nfig, ax = plt.subplots(2, 5, figsize =(20,8))\nindices=[ax[0][0],ax[1][0],ax[0][1],ax[1][1],ax[0][2],ax[1][2],ax[0][3],ax[1][3],ax[0][4],ax[1][4] ]\n\n\nfor i in tqdm(range(ceil(len(dataset_dicts) \/ batch_size))):\n    inds = list(range(batch_size * i, min(batch_size * (i + 1), len(dataset_dicts))))\n    dataset_dicts_batch = [dataset_dicts[i] for i in inds]\n    im_list = [cv2.imread(d[\"file_name\"]) for d in dataset_dicts_batch]\n    outputs_list = predict_batch(predictor, im_list)\n\n    for im, outputs, d in zip(im_list, outputs_list, dataset_dicts_batch):\n        resized_height, resized_width, ch = im.shape\n        # outputs = predictor(im)\n        #############################################################\n\n        if index < 10:\n            # format is documented at https:\/\/detectron2.readthedocs.io\/tutorials\/models.html#model-output-format\n            v = Visualizer(\n                im[:, :, ::-1],\n                metadata=metadata,\n                scale=0.8,\n                instance_mode=ColorMode.IMAGE_BW\n                # remove the colors of unsegmented pixels. This option is only available for segmentation models\n            )\n            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n            # cv2_imshow(out.get_image()[:, :, ::-1])\n            #cv2.imwrite(str(outdir \/ f\"pred_{index}.jpg\"), out.get_image()[:, :, ::-1])\n            \n            #cv2.imwrite(f\".\/pred_{index}.jpg\", out.get_image()[:, :, ::-1])\n            \n            indices[index].grid(False)\n            indices[index].imshow(out.get_image()[:, :, ::-1])\n            \n                        \n         ###############################################################   \n            \n            \n            \n        df_meta = pd.read_csv(\"..\/input\/siim-covid19-resized-1024px\/meta.csv\")\n        test_meta=df_meta[df_meta.split==\"test\"]\n        \n        image_id, dim0, dim1,s = test_meta.iloc[index].values\n\n        instances = outputs[\"instances\"]\n        if len(instances) == 0:\n            # No finding, let's set 2 1.0 0 0 1 1x. Negative\n            result = {\n                \"image_id\": image_id +\"_image\",\n                \"negative\": 1,\n                \"typical\": 0,\n                \"indeterminate\": 0,\n                \"atypical\": 0,\n                 \"PredictionString\": \"none 1 0 0 1 1\"}\n        else:\n            # Find some bbox...\n            # print(f\"index={index}, find {len(instances)} bbox.\")\n            fields: Dict[str, Any] = instances.get_fields()\n            pred_classes = fields[\"pred_classes\"]  # (n_boxes,)\n            pred_scores = fields[\"scores\"]\n            # shape (n_boxes, 4). (xmin, ymin, xmax, ymax)\n            pred_boxes = fields[\"pred_boxes\"].tensor\n\n            h_ratio = dim0 \/ resized_height\n            w_ratio = dim1 \/ resized_width\n            pred_boxes[:, [0, 2]] *= w_ratio\n            pred_boxes[:, [1, 3]] *= h_ratio\n\n            pred_classes_array = pred_classes.cpu().numpy()\n            pred_boxes_array = pred_boxes.cpu().numpy()\n            pred_scores_array = pred_scores.cpu().numpy()\n            pred_classes_scores_array=np.stack((pred_classes_array,pred_scores_array), axis=-1)\n            #{'atypical': 0, 'indeterminate': 1, 'negative': 2, 'typical': 3}\n            \n            \n            typical= np.sum(pred_classes_scores_array[pred_classes_scores_array[:,0]==3, 1],axis=0)\n            negative= np.sum(pred_classes_scores_array[pred_classes_scores_array[:,0]==2, 1],axis=0)\n            indeterminate= np.sum(pred_classes_scores_array[pred_classes_scores_array[:,0]==1, 1],axis=0)\n            atypical= np.sum(pred_classes_scores_array[pred_classes_scores_array[:,0]==0, 1],axis=0)\n            \n            total=typical+negative+indeterminate+atypical\n            \n            typical=typical\/total\n            negative=negative\/total\n            indeterminate=indeterminate\/total\n            atypical=atypical\/total\n            \n                \n            result = {\n                \"image_id\": image_id +\"_image\",\n                \"negative\": negative,\n                \"typical\": typical,\n                \"indeterminate\": indeterminate,\n                \"atypical\": atypical,\n                \"PredictionString\": format_pred(pred_classes_array, pred_boxes_array, pred_scores_array),\n            }\n        results_list.append(result)\n        index += 1","1a6da4a8":"df_img_pre=None\ndf_img_pre = pd.DataFrame(results_list)\ndf_img_pre","a840752a":"test_df=None\nfilepaths = glob('\/kaggle\/input\/siim-covid19-detection\/test\/**\/*dcm',recursive=True)\ntest_df = pd.DataFrame({'filepath':filepaths,})\ntest_df['image_id'] = test_df.filepath.map(lambda x: x.split('\/')[-1].replace('.dcm', '')+'_image')\ntest_df['study_id'] = test_df.filepath.map(lambda x: x.split('\/')[-3].replace('.dcm', '')+'_study')\ntest_df.drop(['filepath'], axis=1, inplace=True)\ntest_df","d0ad822f":"test_img_pre_df=None\ntest_img_pre_df=pd.merge(test_df, df_img_pre, on = 'image_id', how = 'left')\ntest_img_pre_df.sort_values('typical')","3fbfae30":"test_img_pre_df=test_img_pre_df.groupby(['study_id']).mean()\ntest_img_pre_df.reset_index(inplace = True) \ntest_img_pre_df.sort_values('typical')\ntest_img_pre_df=test_img_pre_df.fillna(0)\ntest_img_pre_df","3903eee3":"import numpy as np \nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]\nimage_len = df[df['id_last_str'] == 'e'].shape[0]\nprint(\"study_len:\" + str(study_len) + \"   image_len:\" + str(image_len))\ndf=df[df.id_last_str == 'y']\ndf","eeff2a81":"df_submission=None\ndf_submission=pd.merge(df,test_img_pre_df, left_on='id', right_on='study_id', how = 'left')\ndf_submission=df_submission.fillna(0)\n#df_submission.drop(['PredictionString'], axis=1, inplace=True)\ndf_submission","0f98ea40":"import numpy as np \nimport pandas as pd \nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]\n\nfor i in range(study_len):\n    negative =  df_submission.loc[i,'negative'] \n    typical = df_submission.loc[i,'typical']\n    indeterminate = df_submission.loc[i,'indeterminate']\n    atypical = df_submission.loc[i,'atypical']\n    \n    negative_st=''\n    typical_st=''\n    indeterminate_st=''\n    atypical_st=''\n\n    if negative>0:\n        negative_st =f'negative {negative:0.3f} 0 0 1 1 '\n    if typical>0:\n        typical_st =f'typical {typical:0.3f} 0 0 1 1 '\n    if indeterminate>0:\n        indeterminate_st =f'indeterminate {indeterminate:0.3f} 0 0 1 1 '\n    if atypical>0:\n        atypical_st =f'atypical {atypical:0.3f} 0 0 1 1 '\n\n    #study_str = f'{negative_st}{typical_st}{indeterminate_st}{atypical_st}'\n        \n    #study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'\n    study_str = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n    df.loc[i, 'PredictionString'] = study_str\n    \nsubmission_file_study = df[['id', 'PredictionString']]\nsubmission_file_study","e5a9a171":"submission_file_image = df_img_pre[['image_id', 'PredictionString']]\nsubmission_file_image.rename(columns={'image_id': 'id'}, inplace=True)\n#submission_file_image.PredictionString=\"none 1 0 0 1 1\"\nsubmission_file_image","b17aba25":"submission_file = pd.concat([submission_file_study, submission_file_image], ignore_index=[True])","6d630136":"#submission_file.to_csv('submission.csv', index=False)\nsubmission_file","5b19d74a":"df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\ndf.drop(['PredictionString'], axis=1, inplace=True)","47b26bf3":"submission_file1 = df.join(submission_file.set_index('id'), on = 'id')","f73b0296":"submission_file1","cbb3c1ef":"submission_file1.to_csv('submission.csv', index=False)","b36e97f3":"# configs","a0b897e5":"![download (1).jpg](attachment:442fb254-0ff3-4ceb-bf47-b15a57118389.jpg)","fb0c64b9":"# Install Pre-Built Detectron2","a1159606":"# Load model","b38cc4ac":"# References\n1. https:\/\/www.kaggle.com\/ammarnassanalhajali\/training-detectron2-for-blood-cells-detection\n1. https:\/\/www.kaggle.com\/corochann\/vinbigdata-detectron2-train\n1. https:\/\/www.kaggle.com\/corochann\/vinbigdata-detectron2-prediction\n","c80e30ef":"# Detectron2\nDetectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark.","0185d312":"### Hi kagglers, This is `inferance` notebook using `Detectron2`.\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","54ce705c":"## Training, EDA,and Dataset \n- [SIIM COVID-19 Detectron2 Training](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-covid-19-detectron2-training)\n- [SIIM-FISABIO-RSNA COVID-19 Detection-EDA](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-fisabio-rsna-covid-19-detection-eda)\n- [SIIM-COVID-19 Detection Training Labels (Dataset)](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siimcovid19-detection-training-label)\n\n","30dc93df":"### Other notebooks in this competition -YOLOv5\n- [\ud83d\ude80 COVID-19 Detection YOLOv5 3Classes [Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/covid-19-detection-yolov5-3classes-training)\n- [\ud83d\ude80 COVID-19 Detection YOLOv5 3Classes [Inference]\n](https:\/\/www.kaggle.com\/ammarnassanalhajali\/covid-19-detection-yolov5-3classes-inference)","3cf7dcf5":"# Inferance","4ed55e1d":"# Register Dataset","2b3af800":"# Installation\n* detectron2 is not pre-installed in this kaggle docker, so let's install it.\n* we need to know CUDA and pytorch version to install correct detectron2.","ab8b55e5":"!pip install detectron2 -f \\\n  https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu110\/torch1.7\/index.html","218cebc2":"# Import Libraries","3803ebe3":"# **SIIM COVID-19 Detectron2 [Inferance]**","fd274994":"* It seems CUDA=11.0 and torch==1.7.0 is used in this kaggle docker image.\n* See installation for details. https:\/\/detectron2.readthedocs.io\/en\/latest\/tutorials\/install.html"}}