{"cell_type":{"ce96d041":"code","7c0aee8f":"code","c290e205":"code","4220787c":"code","7561245b":"code","edde584c":"code","2fd49cc6":"code","3cc01a25":"code","cd8d3e58":"code","ff4b191f":"code","853da376":"code","d1781db3":"code","fdf1454b":"code","b29a8b14":"code","edfe2c40":"code","93c3f588":"code","0eae1822":"code","87b026f9":"code","a8ebe35a":"code","1cf51152":"code","0dd84788":"code","cec28fb7":"code","aab7830d":"code","76838392":"code","945a3c09":"code","6a54bf73":"code","fe041338":"code","e739b146":"code","111afa61":"code","cd380cd5":"code","dedfe847":"code","d6df453c":"code","56b7c841":"code","30c4f467":"code","c56fcae6":"code","ab05f380":"code","e2932d9d":"code","e8a96563":"code","714692be":"code","5413a9f3":"code","c32d1595":"code","df8361d7":"markdown","d95bcb63":"markdown","d9fb830c":"markdown"},"source":{"ce96d041":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c0aee8f":"import numpy as np                        ## Matrix functions\nimport matplotlib.pyplot as plt           ## PLotting\nimport pandas as pd                       ## To Work WIth Dataframes \nimport plotly.express as px               ## For Interactive Visualization\nimport plotly.graph_objects as go         ## For Detailed visual plots\nfrom collections import Counter         \nfrom plotly.subplots import make_subplots ## To Plot Subplots\nfrom wordcloud import WordCloud           ## To Generate Wordcloud\nfrom datetime import datetime             ## Work with timeseries data\n\nimport warnings\nwarnings.filterwarnings('ignore')","c290e205":"review = pd.read_csv('..\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv')\nreview.head()","4220787c":"review.apply(lambda x: sum(x.isnull()))","7561245b":"# Data Cleaning","edde584c":"review['Review']= review['Review'].apply(lambda x : str(x).replace('\\n', ' '))\nreview['Review']= review['Review'].apply(lambda x : x.lower())","2fd49cc6":"# Ratings distribution","3cc01a25":"review.apply(lambda x: len(x.unique()))","cd8d3e58":"review.groupby(by='Rating')['Review'].count()","ff4b191f":"# Extracting meaningful words from reviews","853da376":"import nltk\nfrom nltk.tokenize import word_tokenize\n\nreview['Words'] = review['Review'].apply(word_tokenize)\n\nfrom nltk.corpus import stopwords \n\nStopWords = set(stopwords.words('english'))\n\ndef clean_words(x):\n    words = []\n    for i in x:\n        if i.isalnum() and i not in StopWords:\n            words.append(i)\n    return words\n\nreview['Words'] = review['Words'].apply(clean_words)\nreview['Word Count'] = review['Words'].apply(lambda x : len(x))\ndel StopWords","d1781db3":"# Review length by Rating","fdf1454b":"fig = px.histogram(review, x='Word Count', color='Rating',\n            barmode = 'overlay', nbins=50, marginal = 'box')\nfig.update_layout(title = \"Word Count Distribution in Reviews by Ratings.\",\n                 xaxis_title = \"Word Count\",\n                 yaxis_title = \"No of Reviews\")\nfig.show()","b29a8b14":"review.drop('Word Count', axis = 1, inplace=True)","edfe2c40":"# Most common words by rating","93c3f588":"most_common = dict()\n\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Words'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Words by ratings and their word-counts:\")\npd.DataFrame(most_common)","0eae1822":"# Parts Of Speech","87b026f9":"review['POS'] = review['Words'].apply(nltk.pos_tag)","a8ebe35a":"# Adjectives","1cf51152":"def get_adjective(x):\n    adj = set(['JJ', 'JJR', 'JJS'])\n    word = []\n    for i in x:\n        if i[1] in adj:\n            word.append(i[0])\n    return word\n\nreview['ADJ'] = review['POS'].apply(get_adjective)\n\nmost_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['ADJ'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Adjectives by ratings:\")\npd.DataFrame(most_common)","0dd84788":"# Nouns","cec28fb7":"def get_noun(x):\n    noun = set(['NN', 'NNS', 'NNP', 'NNPS'])\n    word = []\n    for i in x:\n        if i[1] in noun:\n            word.append(i[0])\n    return word\n\nreview['Noun'] = review['POS'].apply(get_noun)\n\nreview.drop('POS', axis = 1, inplace = True)\n\nmost_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Noun'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Nouns by ratings:\")\npd.DataFrame(most_common)","aab7830d":"# Common Bigrams","76838392":"most_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Words'].tolist():\n        words.extend(i)\n    bigram = list(nltk.bigrams(words))\n    bigram = nltk.FreqDist(bigram)\n    bigram = bigram.most_common(10)\n    most_common['{}'.format(group)] = bigram\n\nprint(\"Most Common Bi-grams by Ratings:\")\npd.DataFrame(most_common)","945a3c09":"# Polarity And Subjectivity","6a54bf73":"from textblob import TextBlob\n\nreview['Subjectivity'] = review['Review'].apply(lambda x : TextBlob(x).sentiment.subjectivity)\nreview['Polarity'] = review['Review'].apply(lambda x : TextBlob(x).sentiment.polarity)","fe041338":"fig = px.histogram(review, x='Subjectivity', barmode='overlay', color='Rating')\nfig.update_layout(title = \"Subjectivity distribution in reviews of different ratings.\",\n                 xaxis_title = \"Subjectivity\",\n                 yaxis_title = \"Number of Reviews\")\nfig.show()","e739b146":"fig = px.histogram(review, x='Polarity', barmode='overlay', color='Rating')\n\nfig.update_layout(title = \"Polarity distribution in reviews of different ratings.\",\n                 xaxis_title = \"Subjectivity\",\n                 yaxis_title = \"Number of Reviews\")\nfig.show()","111afa61":"# I. Tf-idf","cd380cd5":"from sklearn.feature_extraction.text  import TfidfVectorizer\ntf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2),\n                    min_df = 1)","dedfe847":"from sklearn.model_selection import train_test_split\n\nX = review['Review']\ny = review['Rating']\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 1)\n\ntf_x_train = tf.fit_transform(x_train)\ntf_x_test = tf.transform(x_test)","d6df453c":"# Models","56b7c841":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nperformance = {'Model' : [],\n              'Accuracy Score' : [],\n              'Precision Score' : [],\n              'Recall Score' : [],\n              'f1 Score' : []}","30c4f467":"from sklearn.linear_model import LogisticRegression\n\nlr= LogisticRegression()\nlr.fit(tf_x_train, y_train)\npred = lr.predict(tf_x_test)\n\nperformance['Model'].append('LogisticRegression')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","c56fcae6":"from sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(tf_x_train, y_train)\npred = sgd.predict(tf_x_test)\n\nperformance['Model'].append('SGD')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","ab05f380":"from sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\nmnb.fit(tf_x_train, y_train)\npred = mnb.predict(tf_x_test)\n\nperformance['Model'].append('Multinomial NB')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","e2932d9d":"from sklearn.naive_bayes import BernoulliNB\n\nbnb = BernoulliNB()\nbnb.fit(tf_x_train, y_train)\npred = bnb.predict(tf_x_test)\n\nperformance['Model'].append('Bernoulli NB')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","e8a96563":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nrfc.fit(tf_x_train, y_train)\npred = rfc.predict(tf_x_test)\n\nperformance['Model'].append('Random Forest')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","714692be":"from statistics import mode\n\nclass voted_classifier():\n    def __init__(self):\n        self.classifiers = [lr, sgd, mnb, bnb, rfc]\n        \n    def classify(self, features):\n        names = ['lr', 'sgd', 'mnb', 'bnb', 'rfc']\n        i = 0 \n        votes = pd.DataFrame()\n        for classifier in self.classifiers:\n            pred = classifier.predict(features)\n            votes[names[i]] = pred\n            i+=1\n        return votes.mode(axis = 1)[0]","5413a9f3":"vc = voted_classifier()\npred = vc.classify(tf_x_test)\n\nperformance['Model'].append('Voted Classifier')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","c32d1595":"pd.DataFrame(performance)","df8361d7":"PREDICTIONS","d95bcb63":"Voted Classifier","d9fb830c":"> "}}