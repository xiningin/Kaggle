{"cell_type":{"49975bb3":"code","50c5d8f4":"code","dab92e4b":"code","83ea18e6":"code","a37af394":"code","f56356e2":"code","0a53d09f":"code","a5e03014":"markdown","75bc5ac2":"markdown"},"source":{"49975bb3":"#Necessary packages\nimport pandas as pd\nimport numpy as np\nimport os\nimport json\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score as cvs\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport keras\nimport tensorflow as tf\nfrom keras import models\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.losses import MeanSquaredError as mse\nimport sklearn.metrics\nfrom sklearn.metrics import confusion_matrix as cm\nfrom sklearn.metrics import precision_score, recall_score","50c5d8f4":"#Getting pathnames for each file in the input folder\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/news-headlines-dataset-for-sarcasm-detection'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#Function to parse data\ndef parse_data(file):\n    for l in open(file,'r'):\n        yield json.loads(l)\n\n#Taking in the data in one of the json files (I'm using the slightly larger one)\ndata = list(parse_data(\"\/kaggle\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset_v2.json\"))\ndata[0]","dab92e4b":"#Creating our X variable\nvectorizer = TfidfVectorizer(max_features=50, use_idf=False)\nheadlines = [i['headline'] for i in data]\nX = vectorizer.fit_transform(headlines).toarray()\n\n#Creating our y variable\ny = np.ravel([i['is_sarcastic'] for i in data])\n\n#Creating a train and test split\nX_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 1693)","83ea18e6":"#Now we're going to build the model with its layers\n\n#Initialize the model\nmodel = Sequential()\n\n#Add the input layer\nmodel.add(Dense(24, activation = 'softmax', input_shape = (50,)))\n\n#Add first hidden layer\nmodel.add(Dense(12, activation = 'softmax'))\n\n#Add second hidden layer\nmodel.add(Dense(8, activation = 'softmax'))\n\n#Add output layer\nmodel.add(Dense(1, activation='sigmoid'))","a37af394":"#Now we're going to compile the model\n#Our loss function is binary crossentropy\n#Our optimizer is adam\n\nmodel.compile(loss = 'binary_crossentropy', \n              optimizer = 'adam',\n              metrics = ['accuracy', 'mse'])\n\n#We're going to also fit the model\n#We're going to do 20 epochs\n#The batch size will be 224 to get ~100 iterations per epoch\nmodel.fit(X_train, y_train, epochs = 20,\n          batch_size = 224, verbose = 1)","f56356e2":"#Next, we'll test the model on the test dataset we set aside\n\n#Prediction on the X_test data, round each to an integer (either 0 or 1)\ny_pred = np.around(model.predict(X_test))\n\n#We're going to now look at the accuracy and loss\nscore = model.evaluate(X_test, y_test, verbose=1)\nprint(score)\n\n#We'll print precision and recall too\nprint(f\"Precision: {precision_score(y_test, y_pred)}\")\nprint(f\"Recall: {recall_score(y_test, y_pred)}\")","0a53d09f":"#Now we're going to make a confusion matri\n#The rows are the known labels, the columns are the predicted labels\nmatrix = cm(y_test, y_pred)\ndf = pd.DataFrame(columns = ['', 'is_sarcastic', 'not_sarcastic'])\ndf.loc[len(df)] = ['is_sarcastic', matrix[0][0], matrix[0][1]]\ndf.loc[len(df)] = ['not_sarcastic', matrix[1][0], matrix[1][1]]\nprint(df)","a5e03014":"****We need to separate the data from this list into X and y****  \nOur X is going to be a vectorized list of words from the headline.  \nOur y is going to be \"is_sarcastic\".  \nTo do this, we're going to use some NLP packages  ","75bc5ac2":"## Surestart Action Item Day 5\nThis notebook will train and test a basic neural network, using Keras, to determine whether a headline is sarcastic or not.  "}}