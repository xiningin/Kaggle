{"cell_type":{"28bcd287":"code","8bcc4ad3":"code","8c7168a4":"code","4ae8d67e":"code","25fa6d2f":"code","12f2e9f1":"code","3ad4cfaa":"code","039ecb76":"code","f929c10f":"code","d46e0a21":"code","d13fc56c":"code","a808a24d":"code","9ec0bd4b":"code","4e1a87d3":"code","726b404f":"code","ae9c36d2":"code","59064a41":"code","036dac1b":"code","40d38b82":"code","dab0da58":"code","8b38ea33":"code","27bde3f1":"code","32d64362":"code","ddfef424":"code","94733a38":"code","83bbae32":"code","1f4282b7":"code","5b017fba":"code","430d4835":"code","063b2245":"code","e27c0fa4":"code","eef81d4d":"code","f4162738":"code","d3eb173e":"code","f7700e25":"code","c0c99afb":"code","c0304d05":"markdown","a7581462":"markdown","6a7563a1":"markdown","019bba4a":"markdown","556afdea":"markdown","f3b8b594":"markdown","6854e251":"markdown","35d55f1f":"markdown","13afa36c":"markdown"},"source":{"28bcd287":"import torch\nimport torchvision\n\ntorch_version = torch.__version__\ntorchvision_version = torchvision.__version__\ncuda_version = torch.version.cuda\ncuda_version_major = int(cuda_version.split('.')[0])\n\nprint(f\"The torch version is: {torch_version}\")\nprint(f\"The torchvision version is: {torchvision_version}\")\nprint(f\"The CUDA version is: {cuda_version}\")\nprint(f\"The CUDA major version is: {cuda_version_major}\")","8bcc4ad3":"if cuda_version_major==10:\n    torch_install = \"torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html --upgrade -q\"\nelif cuda_version_major==11:\n    torch_install = \"torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html --upgrade -q\"\nelse:\n    print(f\"Check out which torch and torchvision versions are compatible with your CUDA version {cuda_version_major} are required\")\n    torch_install = \"I'm not gonna to install the thing! You're on your own :)\"\ntorch_install","8c7168a4":"!pip install {torch_install}","4ae8d67e":"!pip install fastai==2.3.1 --upgrade -q","25fa6d2f":"import fastai\nprint(f\"The fastai version is: {fastai.__version__}\")","12f2e9f1":"pip install git+git:\/\/github.com\/airctic\/icevision.git\\#egg=icevision[all] --upgrade -q","3ad4cfaa":"!pip install git+git:\/\/github.com\/airctic\/icedata.git --upgrade -q","039ecb76":"if cuda_version_major==10:\n    mmcv_install = \"mmcv-full==1.3.3 -f https:\/\/download.openmmlab.com\/mmcv\/dist\/cu101\/torch1.8.0\/index.html --upgrade -q\"\nelif cuda_version_major==11:\n    mmcv_install = \"mmcv-full==1.3.3 -f https:\/\/download.openmmlab.com\/mmcv\/dist\/cu111\/torch1.8.0\/index.html --upgrade -q\"\nelse:\n    print(f\"Check out which torch and torchvision versions are compatible with your CUDA version {cuda_version_major} are required\")\n    mmcv_install = \"I'm not gonna to install the thing! You're on your own :)\"\nmmcv_install","f929c10f":"!pip install {mmcv_install}","d46e0a21":"!pip install mmdet==2.12.0 --upgrade -q","d13fc56c":"!pip install yolov5-icevision --upgrade -q","a808a24d":"!pip install torchtext==0.9.0 --upgrade -q","9ec0bd4b":"!pip list","4e1a87d3":"from icevision.all import *","726b404f":"# Download the dataset\nurl = \"https:\/\/cvbp-secondary.z19.web.core.windows.net\/datasets\/object_detection\/odFridgeObjects.zip\"\ndest_dir = \"fridge\"\ndata_dir = icedata.load_data(url, dest_dir)","ae9c36d2":"# Download the dataset\nurl = \"https:\/\/cvbp-secondary.z19.web.core.windows.net\/datasets\/object_detection\/odFridgeObjects.zip\"\ndest_dir = \"fridge\"\ndata_dir = icedata.load_data(url, dest_dir)","59064a41":"# Create the parser\nparser = parsers.VOCBBoxParser(annotations_dir=data_dir \/ \"odFridgeObjects\/annotations\", images_dir=data_dir \/ \"odFridgeObjects\/images\")","036dac1b":"# Parse annotations to create records\ntrain_records, valid_records = parser.parse()","40d38b82":"parser.class_map","dab0da58":"# Transforms\n# size is set to 384 because EfficientDet requires its inputs to be divisible by 128\nimage_size = 384\ntrain_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\nvalid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])","8b38ea33":"# Datasets\ntrain_ds = Dataset(train_records, train_tfms)\nvalid_ds = Dataset(valid_records, valid_tfms)","27bde3f1":"# Show an element of the train_ds with augmentation transformations applied\nsamples = [train_ds[0] for _ in range(3)]\nshow_samples(samples, ncols=3)","32d64362":"model_type = models.mmdet.retinanet\nbackbone = model_type.backbones.resnet50_fpn_1x(pretrained=True)","ddfef424":"# Just change the value of selection to try another model\n\nselection = 0\n\n\nextra_args = {}\n\nif selection == 0:\n  model_type = models.mmdet.retinanet\n  backbone = model_type.backbones.resnet50_fpn_1x\n\nelif selection == 1:\n  # The Retinanet model is also implemented in the torchvision library\n  model_type = models.torchvision.retinanet\n  backbone = model_type.backbones.resnet50_fpn\n\nelif selection == 2:\n  model_type = models.ross.efficientdet\n  backbone = model_type.backbones.tf_lite0\n  # The efficientdet model requires an img_size parameter\n  extra_args['img_size'] = image_size\n\nelif selection == 3:\n  model_type = models.ultralytics.yolov5\n  backbone = model_type.backbones.small\n  # The yolov5 model requires an img_size parameter\n  extra_args['img_size'] = image_size\n\nmodel_type, backbone, extra_args","94733a38":"# Instantiate the mdoel\nmodel = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args) ","83bbae32":"# Data Loaders\ntrain_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=2, shuffle=True)\nvalid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=2, shuffle=False)","1f4282b7":"# show batch\nmodel_type.show_batch(first(valid_dl), ncols=4)","5b017fba":"metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]","430d4835":"learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)","063b2245":"learn.lr_find()","e27c0fa4":"learn.fine_tune(20, 1e-4, freeze_epochs=1)","eef81d4d":"class LightModel(model_type.lightning.ModelAdapter):\n    def configure_optimizers(self):\n        return SGD(self.parameters(), lr=1e-4)\n    \nlight_model = LightModel(model, metrics=metrics)","f4162738":"trainer = pl.Trainer(max_epochs=20, gpus=1)\ntrainer.fit(light_model, train_dl, valid_dl)","d3eb173e":"model_type.show_results(model, valid_ds, detection_threshold=.5)","f7700e25":"infer_dl = model_type.infer_dl(valid_ds, batch_size=4, shuffle=False)\npreds = model_type.predict_from_dl(model, infer_dl, keep_images=True)","c0c99afb":"show_preds(preds=preds[:4])","c0304d05":"## Get environment information","a7581462":"### currently the FASTAI learning doesn't work","6a7563a1":"## Training using Pytorch Lightning","019bba4a":"# Step 1: Install `IceVision`","556afdea":"## Using the model - inference and showing results\n\nThe first step in reviewing the model is to show results from the validation dataset. This is easy to do with the `show_results` function.","f3b8b594":"# Demo\n\nOnce you have run all the pip install steps above, click the virticle triple dots in the upper right of the notebook and select `Restart & Clear Cell Outputs`","6854e251":"## Happy Competition!\n\nIceVision is built around an awesome community where IceVision users learn from each other, and share their knowledge\/experience. Feel free to join our [forum](https:\/\/discord.gg\/JDBeZYK).","35d55f1f":"# Restart the kernel ;)","13afa36c":"# Updating Kaggle environment for IceVision"}}