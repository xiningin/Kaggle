{"cell_type":{"efdcbcc1":"code","ec47b28b":"code","53e9e4a5":"code","e19434d8":"code","d601406b":"code","e8cada9f":"code","2c17cc1d":"code","96de848a":"code","cc6feefb":"code","64a7003d":"code","60129af8":"code","c540260d":"code","22746402":"markdown","6bcd0414":"markdown","a0fbe76f":"markdown","6164d98f":"markdown","fd660528":"markdown","86421875":"markdown","91c2b037":"markdown","3830e0b8":"markdown","b7625570":"markdown"},"source":{"efdcbcc1":"#import a few libraries that will be used\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n#read in the data and examine the first 5 observations to get a feel for it\ndf = pd.read_csv(\"..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\") \ndf.head()","ec47b28b":"#Assess how many null values are in the dataframe\ndf.isnull().sum()","53e9e4a5":"df = df.fillna(0) #fill in null salary values with 0 since it's for students that were not placed.\ndf.describe()","e19434d8":"fig = plt.figure()\nfig.patch.set_facecolor('black')\nplt.rcParams['text.color'] = 'white'\nmy_circle=plt.Circle( (0,0), 0.7, color='black')\n\nplt.pie(df['gender'].value_counts(), labels=df['gender'].value_counts().index, autopct=\"%1.1f%%\")\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()\n\nfig = plt.figure()\nfig.patch.set_facecolor('black')\nplt.rcParams['text.color'] = 'white'\nmy_circle=plt.Circle( (0,0), 0.7, color='black')\n\nplt.pie(df['status'].value_counts(), labels=df['status'].value_counts().index, autopct=\"%1.1f%%\")\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()\n\nfig = plt.figure()\nfig.patch.set_facecolor('black')\nplt.rcParams['text.color'] = 'white'\nmy_circle=plt.Circle( (0,0), 0.7, color='black')\n\nplt.pie(df['specialisation'].value_counts(), labels=df['specialisation'].value_counts().index, autopct=\"%1.1f%%\")\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()\n\nfig = plt.figure()\nfig.patch.set_facecolor('black')\nplt.rcParams['text.color'] = 'white'\nmy_circle=plt.Circle( (0,0), 0.7, color='black')\n\nplt.pie(df['workex'].value_counts(), labels=df['workex'].value_counts().index, autopct=\"%1.1f%%\")\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()\n\nfig = plt.figure()\nfig.patch.set_facecolor('black')\nplt.rcParams['text.color'] = 'white'\nmy_circle=plt.Circle( (0,0), 0.7, color='black')\n\nplt.pie(df['degree_t'].value_counts(), labels=df['degree_t'].value_counts().index, autopct=\"%1.1f%%\")\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","d601406b":"sns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"gender\", hue=\"status\", data=df) #plot placement status by gender","e8cada9f":"sns.boxplot( x=\"salary\", y='gender', width =0.5, data = df); #boxplot of salary by gender\nplt.show()","2c17cc1d":"df1 = df\ndf1['gender'].replace({\"M\":0, \"F\":1}, inplace=True)\ndf1['hsc_b'].replace({\"Others\":0, \"Central\":1}, inplace=True)\ndf1['workex'].replace({\"No\":0, \"Yes\":1}, inplace=True)\ndf1['status'].replace({\"Not Placed\":0, \"Placed\":1}, inplace=True)\ndf1['specialisation'].replace({\"Mkt&HR\":0, \"Mkt&Fin\":1}, inplace=True)\n\ndf1['hsc_s_commerce'] = np.where(df1['hsc_s'] == 'Commerce',1,0)\ndf1['hsc_s_Science'] = np.where(df1['hsc_s'] == 'Science',1,0)\ndf1['hsc_s_Arts'] = np.where(df1['hsc_s'] == 'Arts',1,0)\ndf1['degree_sci&tech'] = np.where(df1['degree_t'] == 'Sci&Tech',1,0)\ndf1['degree_comm&mgmt'] = np.where(df1['degree_t'] == 'Comm&Mgmt',1,0)\ndf1['degree_other'] = np.where(df1['degree_t'] == 'Others',1,0)\n\ndf1=df1.drop(['sl_no','ssc_p','ssc_b','hsc_s','degree_t','salary'],axis=1)","96de848a":"#import some sklearn modules in order to perform the regresison\nfrom sklearn import metrics \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\ndf1.head() #look at the first 5 observations to ensure coding is correct","cc6feefb":"x = df1.drop('status', axis=1) #create df with only effect variables\ny = df1.status #create df with only response variable\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=4) #split frames into testing and training\nlogistic_regression = LogisticRegression(max_iter=500)","64a7003d":"logistic_regression.fit(x_train, y_train) #fit the training df's to a logistic regression model","60129af8":"y_pred = logistic_regression.predict(x_test) #predict y values with the model that was fit above\naccuracy = metrics.accuracy_score(y_test, y_pred) #calculate accuracy of the prediction to actual values\naccuracy_percentage = 100 * accuracy\nprint(accuracy_percentage)","c540260d":"import statsmodels.api as sm\nlogit_model=sm.Logit(y_train,x_train)\nresult=logit_model.fit()\nprint(result.summary2())\nprint(logit_model.fit().params)","22746402":"**In order to begin modeling, we'll need to set some of the categorical variables as numeric binary 0's and 1's since we're performing logistical regression. We'll also drop a few variables that should have no impact on placement (ex: salary, early education grades, etc..)**","6bcd0414":"**Legend**\n* gender: 1 = Female, 0 = Male\n* hsc_b: 1 = Central, 0 = Others\n* workex: 1= Yes, 0 = No\n* status: 1 = Placed, 0 = Not Placed\n* hsc_s_SPECIALISATION: 1 = True, 0 = False\n* degree_NAME: 1 = True, 0 = False\n","a0fbe76f":"**There are only null values in the salary field for candidates that were not placed. Since they are not placed, their salary can be replaced with a 0. Next we'll take a look to see if there are any strange values with the numeric variables. The only strange variable is salary, which may contain an outlier. the 75th percentile is 282.5K.**","6164d98f":"**Next we'll get an understanding of more specific data:**\n* Male\/Female percentages\n* Placed\/Not Placed percentages\n* Specialisation percentages\n* Work Experience percentages\n* Undergrad Degree percentages\n\n**I've hidden the code since it's a little long, but feel free to expand it**","fd660528":"**Surprisingly, gender is not a significant factor when determining placement status (P>0.05).**\n\n**There are only 4 effects that are significant: hsc_p, degree_p, workex, and mba_p. From the effect coefficients, we can infer that the higher the percentile in higher education and degree, the more likely a student is to be placed. Workex is also a contributing factor, and if a student has workex, they are more likely to be placed. The last factor, mba_p, is curious. It appears that the higher percentile, the lower the probability a student will be placed. I'd recommend futher investigation into this factor. Perhaps lower grades are accompanied with placement due to time constraints and studying.**","86421875":"**There's a few things we can take from these plots:**\n\n1. There's a significant differenec in the gender count; Males account for nearly 2 times the female count.\n2. Just over 2\/3 of the population have been placed into jobs.\n3. The specialisation is almost split evenly.\n4. Just over 2\/3 of the population did not have work experience.\n5. Comm&Mgmt is the highest undergrad degree represented with over 2\/3 of the population, followed by Sci&Tech.\n\n**Let's take a closer look at the gender aspect. Below we see that the placed to not placed ratio by gender highly favors the males (not placed accounts for 1\/3 of the male population), while while it is highly unfavorable for the females (almost 50% not placed). We'll keep this in mind for modeling later on, as gender should be a significant effect. The boxplot shows that the mean salary between genders does not greatly differ, but the male salary certainly has more range.**","91c2b037":"**This model predicted placement status with 83.33% accuracy against the test dataframe. That's a great prediction rate! I would be interested to see the results on additional datasets.**\n\n**Since Scikit-learn does not support statistical inference, if we want an ANOVA table of the effects with coefficents and p-values, we'll need to build the same model from statsmodels.**","3830e0b8":"![maxresdefault.jpg](attachment:maxresdefault.jpg)","b7625570":"**This notebook will explore student placement data from Jain University in Bangalore. It will clean, visually explore, and build a logistic model to predict placement status.**"}}