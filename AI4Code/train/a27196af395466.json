{"cell_type":{"34aef37a":"code","4ce50a7c":"code","69dd905d":"code","d4bd3849":"code","b033fc35":"code","a15e27cc":"code","5f79f3df":"code","0a30d32c":"code","0e92f8a4":"code","d1229e7d":"code","9cac7530":"code","a03f0258":"code","1985017d":"code","931f2cf7":"code","ba070a18":"code","1dd33fc2":"code","e0464994":"code","100a5b7f":"code","753dc1ea":"code","93024a1d":"code","f29bb2f9":"code","d1b51aed":"code","54f7ee13":"code","fdbd44da":"code","8de77c29":"code","b2bd40fb":"code","a877dfdd":"code","7ada2e5f":"code","dbfb0c3e":"code","85adc7a0":"code","2ef3f036":"code","78d34fe7":"code","1026ccae":"code","a9b0b5d7":"code","87daf75c":"code","774adcec":"code","c72031d0":"code","dc458035":"code","600c29b7":"markdown","09b5e148":"markdown"},"source":{"34aef37a":"import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nfrom torchvision import datasets, transforms, models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\n%matplotlib inline","4ce50a7c":"data_dir = '..\/input\/head-ct-hemorrhage-128-x-128\/head_ct (128x128)'\n#test_dir = '..\/input\/skin-cancer\/Skin cancer ISIC The International Skin Imaging Collaboration\/Test'\nclasses = os.listdir(data_dir)","69dd905d":"train_transform=transforms.Compose([\n        transforms.RandomRotation(10),      # rotate +\/- 10 degrees\n        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n        transforms.Resize(100),             # resize shortest side to 100 pixels\n        transforms.CenterCrop(100),         # crop longest side to 100 pixels at center\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n])","d4bd3849":"dataset = ImageFolder(data_dir, transform=train_transform)\nprint('Size of training dataset :', len(dataset))\n#testset = ImageFolder(test_dir, transform=train_transform)\n#print('Size of training testset :', len(testset))","b033fc35":"# view one image shape of the dataset.\nimg, label = dataset[100]\nprint(label)\nprint(img.shape)","a15e27cc":"# function for the showing the image.\ndef show_image(img, label):\n    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))","5f79f3df":"show_image(*dataset[20])","0a30d32c":"show_image(*dataset[100])","0e92f8a4":"torch.manual_seed(20)\nval_size = len(dataset)\/\/10\ntest_size = len(dataset)\/\/2\ntrain_size = len(dataset) - val_size - test_size","d1229e7d":"train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds)   ","9cac7530":"batch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)","a03f0258":"for images, labels in train_loader:\n    fig, ax = plt.subplots(figsize=(18,10))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n    break","1985017d":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","931f2cf7":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","ba070a18":"torch.cuda.is_available()","1dd33fc2":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","e0464994":"device = get_default_device()\ndevice","100a5b7f":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","753dc1ea":"print(type(test_loader))","93024a1d":"input_size = 3*100*100\noutput_size = 2     # Number of classe","f29bb2f9":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                   # Generate predictions\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","d1b51aed":"class CnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 100, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(100, 150, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 150 x 16 x 16\n\n            nn.Conv2d(150, 200, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(200, 200, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 200 x 8 x 8\n\n            nn.Conv2d(200, 250, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(250, 250, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 250 x 4 x 4\n\n            nn.Flatten(), \n            nn.Linear(36000, 3600),\n            nn.ReLU(),\n            nn.Linear(3600, 360),\n            nn.ReLU(),\n            nn.Linear(360, 50),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(50, 2))\n        \n    def forward(self, xb):\n        return self.network(xb)","54f7ee13":"model = CnnModel()\nmodel.cuda()\n#model","fdbd44da":"for images, labels in train_loader:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    #print('out[0]:', out[0])\n    break","8de77c29":"device = get_default_device()\ndevice","b2bd40fb":"train_dl = DeviceDataLoader(train_loader, device)\nval_dl = DeviceDataLoader(val_loader, device)\nto_device(model, device)","a877dfdd":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","7ada2e5f":"model = to_device(CnnModel(), device)","dbfb0c3e":"history=[evaluate(model, val_loader)]\nhistory","85adc7a0":"num_epochs = 4\nopt_func = torch.optim.Adam\nlr = 0.001","2ef3f036":"history+= fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","78d34fe7":"history+= fit(num_epochs, lr\/10, model, train_dl, val_dl, opt_func)","1026ccae":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()","a9b0b5d7":"plot_accuracies(history)","87daf75c":"plot_losses(history)","774adcec":"evaluate(model, test_loader)\ntorch.save(model.state_dict(), 'conv2d.pth')","c72031d0":"from sklearn.metrics import classification_report\n\npred = []\nY = []\nfor i, (x,y) in enumerate(test_loader):\n    with torch.no_grad():\n        outputs = model(x)\n    pred += [int(op.argmax()) for op in outputs]\n    Y += [int(yi) for yi in y]\n\nprint(classification_report(Y, pred))\n","dc458035":"from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(Y, pred, drop_intermediate=False)\n\nprint(fpr)\nprint(tpr)\nprint(thresholds)\n\nplt.figure(figsize = (8,6))\nplt.plot(fpr, tpr, marker='o')\nplt.title('ROC curve')\nplt.xlabel('FPR: False positive rate')\nplt.ylabel('TPR: True positive rate')\nplt.grid()","600c29b7":"# Conv2d Model","09b5e148":"# Head CT Hemorrhage Classify Torch Conv2d"}}