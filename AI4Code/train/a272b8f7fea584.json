{"cell_type":{"a4bde2ed":"code","7b21f095":"code","218cf260":"code","4deca58c":"code","a06895ac":"code","d3a34037":"code","a4ff6255":"code","8305a2e5":"code","1b81d75c":"code","cf45ea77":"code","16b43e44":"code","0275d280":"code","bd75686f":"code","ce30c0df":"code","04336aef":"code","61c50d18":"code","b0261782":"code","3359b4a9":"code","473805cb":"code","5833b906":"code","52a1ed38":"code","ba75d21c":"code","f6a935a1":"code","77a65807":"code","757d5875":"code","b3580886":"code","48f6bb77":"code","244edf6b":"code","b111463f":"code","08ac5803":"code","b972778a":"code","fe6b7586":"code","393dc26c":"code","c3870f21":"code","a05ef560":"code","706e12f3":"code","13fd6581":"code","8254d193":"code","fb7adb3e":"code","724b7840":"code","aa1a33f4":"code","4c2abc91":"code","37c11ab1":"code","0733b26a":"code","95b77a0e":"code","94268596":"code","00707c73":"code","f4449b9d":"code","708b071a":"code","5fd01284":"code","d265aed1":"code","40461c11":"code","0e5ebc95":"code","fb53dfb9":"code","20289d8c":"code","b722895a":"code","b1606f12":"code","c8675316":"code","b7c822f9":"code","3732ae3a":"code","f6270c35":"code","57a07fad":"code","e6340648":"code","eb4dc15b":"code","6440dd8e":"code","e2d898a5":"code","3ed4e57b":"code","ecfe545b":"code","ede54bca":"code","93410d34":"code","c4732232":"code","ff19a54d":"code","67b472f2":"code","711c0c43":"code","89f3ea52":"code","2c826b86":"code","28e7bc9c":"code","160f1126":"code","795cb554":"code","4a8d90e9":"code","2518e3e6":"code","8e7666a9":"code","035852a1":"code","714e4095":"code","5aa3ee42":"code","9c0cea5b":"code","f853dc89":"code","f2b707fb":"code","022cef3d":"code","720c395e":"markdown","b79062a7":"markdown","b2d48777":"markdown","02b926d7":"markdown","2ec37a19":"markdown","13b1b801":"markdown","7b936a51":"markdown","c284d58b":"markdown","c2a533d9":"markdown","714a5938":"markdown","afdce000":"markdown","ec8a0fff":"markdown","77de8f6a":"markdown","2a017c78":"markdown","0fbafd72":"markdown"},"source":{"a4bde2ed":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,StackingClassifier,VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn import preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","7b21f095":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\ntrain.set_index(\"id\",inplace=True)\ntest.set_index(\"id\",inplace=True)","218cf260":"print(train.shape)\nprint(test.shape)","4deca58c":"train.columns","a06895ac":"train.dtypes.value_counts().plot.pie(title='R\u00e9partition des variables par type')","d3a34037":"print('Nombre de valeures manquante Train {}'.format(train.isna().sum().sum()))\nprint('Nombre de valeures manquante Test  {}'.format(test.isna().sum().sum()))","a4ff6255":"train.head()","8305a2e5":"numeric_columns = train.select_dtypes(['float','int']).columns\nCat_columns=train.select_dtypes('object').columns","1b81d75c":"import pandas_profiling as pp\npp.ProfileReport(train)","cf45ea77":"train.describe()","16b43e44":"train.describe(include=['O'])","0275d280":"train['target'].value_counts(normalize=True)*100 ","bd75686f":"sns.countplot(x=\"target\", data=train,\n                   facecolor=(0, 0, 0, 0),\n                   linewidth=5,\n                   edgecolor=sns.color_palette(\"dark\", 3))","ce30c0df":"train.hist(bins=50, figsize=(20,15))\nplt.show()","04336aef":"positive_train = train[train['target'] == 1]\nnegative_train = train[train['target'] == 0]","61c50d18":"for col in train.select_dtypes('float'):\n    plt.figure(figsize=(3,3))\n    sns.distplot(positive_train[col], label='positive')\n    sns.distplot(negative_train[col], label='negative')\n    plt.legend()","b0261782":"for col in train.select_dtypes('float') :\n    Chiffre = train.groupby('target').agg({\n        col : ['median']\n    })\n    print( f'{col :-<5} {Chiffre} ')\n","3359b4a9":"def cp(n, b=220):\n    return sns.diverging_palette(1, b, n=n)\nmask = np.zeros_like(train[numeric_columns].corr())\nmask[np.triu_indices_from(mask)] = True\nfrom pylab import rcParams\nrcParams['figure.figsize'] = (12,8)\nsns.heatmap(\n    train[numeric_columns].corr(),\n    cmap = cp(200),\n    annot=True,\n    mask=mask,\n    center = 0,\n)","473805cb":"for col in train.select_dtypes('object'):\n    print(f'{col :-<5} {train[col].nunique():-<5} {train[col].unique()}')","5833b906":"Cinq_modalite_moins = []\nCinq_modalite_plus = []\n\nfor col in train.select_dtypes('object'):\n    if train[col].nunique() <= 5 :\n        Cinq_modalite_moins.append(col)\n    else:\n        Cinq_modalite_plus.append(col)","52a1ed38":"for col in Cinq_modalite_moins:\n    plt.figure(figsize=(3,3))\n    train[col].value_counts().plot.pie()","ba75d21c":"for col in Cat_columns:\n    if set(train[col].unique()) != set(test[col].unique()):\n        print(f\"La liste des variables avec des modalit\u00e9es diff\u00e9rents entre le test et le train: {col}\")","f6a935a1":"train_cat10 = set(train['cat10'].unique())\ntest_cat10 = set(test['cat10'].unique())\n\nprint(f'Modalit\u00e9s dans le train mais pas dans le test: {train_cat10.difference(test_cat10)}.')\nprint(f'Modalit\u00e9s dans le test mais pas dans le train: {test_cat10.difference(train_cat10)}.')","77a65807":"del train['cat10']\ndel test['cat10']","757d5875":"Cat_columns=train.select_dtypes('object').columns","b3580886":"for col in Cinq_modalite_moins:\n    plt.figure(figsize=(3,3))\n    sns.countplot(x=col, hue=\"target\", data=train,palette=\"Set3\")\n","48f6bb77":"train_alea = train.sample(n=130000,random_state=0)","244edf6b":"train.shape","b111463f":"train['target'].value_counts(normalize=True)*100 ","08ac5803":"trainset, testset = train_test_split(train_alea, test_size=0.2, random_state=0)","b972778a":"print(trainset['target'].value_counts())\nprint(testset['target'].value_counts())","fe6b7586":"for col in Cat_columns:\n    if set(trainset[col].unique()) != set(testset[col].unique()):\n        print(f\"La liste des variables avec des modalit\u00e9es diff\u00e9rents entre le test et le train: {col}\")","393dc26c":"def imputation(df):\n    df = df.dropna(axis=0)\n    df = df.dropna(axis=1)\n    df.drop_duplicates(keep = 'first', inplace=True)\n    return  df","c3870f21":"def encodage(df):\n    ohe = OneHotEncoder(sparse=False)\n    ohe.fit(df[Cat_columns])\n    df = pd.merge(df[numeric_columns], \n          pd.DataFrame(columns = ohe.get_feature_names().tolist(),\n              data = ohe.fit_transform(df[Cat_columns])).set_index(df.index),\n        left_index = True, right_index = True)\n    return df","a05ef560":"def preprocessing(df):\n    \n    df = encodage(df)\n    df = imputation(df)\n    \n    X = df.drop('target', axis=1)\n    y = df['target']\n    \n    print(y.value_counts(normalize=True))\n    \n    return X, y","706e12f3":"X_train, y_train = preprocessing(trainset)","13fd6581":"X_test, y_test = preprocessing(testset)","8254d193":"def evaluation(model):\n    \n    model.fit(X_train, y_train)\n    ypred = model.predict(X_test)\n    \n    print(confusion_matrix(y_test, ypred))\n    print(classification_report(y_test, ypred))\n    print(roc_auc_score(y_test, ypred))\n    \n    #N, train_score, val_score = learning_curve(model, X_train, y_train,\n    #                                          cv=2, scoring='accuracy',\n    #                                           train_sizes=np.linspace(0.1, 1, 10))\n    \n    \n    #plt.figure(figsize=(12, 8))\n    #plt.plot(N, train_score.mean(axis=1), label='train score')\n    #plt.plot(N, val_score.mean(axis=1), label='validation score')\n    #plt.legend()","fb7adb3e":"preprocessor = make_pipeline(SelectKBest(f_classif, k=10))","724b7840":"RandomForest = make_pipeline(RandomForestClassifier(random_state=0))\nAdaBoost = make_pipeline( AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\nridge = make_pipeline(RidgeClassifier(random_state=0))\nBagging = make_pipeline(BaggingClassifier(random_state=0))\nGradient= make_pipeline(GradientBoostingClassifier(random_state=0))\n\n#VotingClassifier =make_pipeline(VotingClassifier(random_state=0))","aa1a33f4":"dict_of_models = {'Bagging' : Bagging,\n                  'Gradient' : Gradient,\n                  'ridge' : ridge, \n                  'AdaBoost' : AdaBoost,\n                  #'SVM': SVM,\n                  'RandomForest': RandomForest\n                  \n                 }","4c2abc91":"for name, model in dict_of_models.items():\n    print(name)\n    evaluation(model)","37c11ab1":"estimators = [\n('RandomForest' ,make_pipeline(RandomForestClassifier(random_state=0))),\n('AdaBoost' ,make_pipeline( AdaBoostClassifier(random_state=0))),\n('ridge' , make_pipeline(RidgeClassifier(random_state=0))),\n('Gradient', make_pipeline(GradientBoostingClassifier(random_state=0)))\n ]","0733b26a":"#StackingClassifier =make_pipeline(StackingClassifier(random_state=0))\nclf = StackingClassifier(estimators=estimators)\nclf.fit(X_train, y_train).score(X_test, y_test)","95b77a0e":"clf.predict()","94268596":"y_pred = clf.predict(X_test)\n\nprint(roc_auc_score(y_test, ypred))\n","00707c73":"evaluation(clf)","f4449b9d":"RandomForest.get_params().keys()","708b071a":"hyper_params = {'randomforestclassifier__n_estimators':[1, 5,100,20,30 ],\n               'randomforestclassifier__max_depth' : [1,2,3,4,5],\n               'randomforestclassifier__n_jobs' : [-1,1]}","5fd01284":"grid = RandomizedSearchCV(RandomForest, hyper_params, scoring='accuracy', cv=4,\n                          n_iter=10)\n\ngrid.fit(X_train, y_train)\n","d265aed1":"print(grid.best_params_)\n\ny_pred = grid.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","40461c11":"evaluation(grid.best_estimator_)","0e5ebc95":"AdaBoost = make_pipeline( AdaBoostClassifier(random_state=0,n_estimators=500,learning_rate=1.3))","fb53dfb9":"evaluation(AdaBoost)","20289d8c":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","b722895a":"hyper_params = {'adaboostclassifier__n_estimators':[1, 50,100,150,500],\n               'adaboostclassifier__learning_rate' : [1.1,1.2,1.3,1.4,1.5],\n               'adaboostclassifier__algorithm' : ['SAMME','SAMME.R']}","b1606f12":"AdaBoost.get_params().keys()","c8675316":"grid = RandomizedSearchCV(AdaBoost, hyper_params, scoring='recall', cv=4,\n                          n_iter=10)\n\ngrid.fit(X_train, y_train)\n","b7c822f9":"RandomForest.get_params().keys()","3732ae3a":"hyper_params = {'adaboostclassifier__n_estimators':[1, 50,100,150,500],\n               'adaboostclassifier__learning_rate' : [1.1,1.2,1.3,1.4,1.5],\n               'adaboostclassifier__algorithm' : ['SAMME','SAMME.R']}","f6270c35":"grid = RandomizedSearchCV(AdaBoost, hyper_params, scoring='recall', cv=4,\n                          n_iter=10)\n\ngrid.fit(X_train, y_train)","57a07fad":"print(grid.best_params_)\n\ny_pred = grid.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","e6340648":"evaluation(grid.best_estimator_)","eb4dc15b":"from sklearn.metrics import precision_recall_curve","6440dd8e":"precision, recall, threshold = precision_recall_curve(y_test, grid.best_estimator_.decision_function(X_test))","e2d898a5":"plt.plot(threshold, precision[:-1], label='precision')\nplt.plot(threshold, recall[:-1], label='recall')\nplt.legend()","3ed4e57b":"def model_final(model, X, threshold=0):\n    return model.decision_function(X) > threshold","ecfe545b":"y_pred = model_final(grid.best_estimator_, X_test, threshold=0.5)","ede54bca":"f1_score(y_test, y_pred)","93410d34":"print(confusion_matrix(y_test, y_pred))","c4732232":"test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv')","ff19a54d":"test.set_index('id',inplace=True)","67b472f2":"numeric_columns = train.select_dtypes(['float']).columns","711c0c43":"test = encodage(test)\ntest = imputation(test)","89f3ea52":"ypred = model_final(grid.best_estimator_, test, threshold=0.5)","2c826b86":"ypred = pd.DataFrame(data=ypred, columns=['target2'])","28e7bc9c":"ypred['target']= np.where(ypred['target2']==True,1,0)","160f1126":"test.reset_index(inplace=True)","795cb554":"test=pd.merge(test,ypred,how='left',left_index=True,right_index=True)","4a8d90e9":"test['target'].value_counts(normalize=True)","2518e3e6":"sub = test[['id','target']]","8e7666a9":"sub.to_csv('submission.csv', index=False)","035852a1":"n_folds = 10\nseed_list = [i for i in range(2000, 2022)]","714e4095":"import random\ndef set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nset_seed(seed_list[0])","5aa3ee42":"train_oof_dict = {\n    'trans_1': 'train_rgr_epoch2000_probas8_params0_batch512.npy',\n    'trans_2': 'train_rgr_epoch2000_probas8_params1_batch512.npy',\n    'trans_3': 'train_rgr_epoch2000_probas8_params2_batch512.npy',\n    'trans_4': 'train_rgr_epoch2000_probas8_params3_batch512.npy',\n    'trans_5': 'train_rgr_epoch2000_probas8_params4_batch512.npy',\n    'trans_6': 'train_rgr_epoch2000_probas8_params5_batch512.npy',\n    'trans_7': 'train_rgr_epoch2000_probas8_params6_batch512.npy',\n    'lightgbm1': 'train_lgb.npy',\n    'lightgbm2': 'train_oof_lgbm_0.npy',\n    'lightgbm3': 'train_oof_lgbm_1.npy',\n    'xgboost': 'train_xgb.npy',\n    'catboost': 'train_cbt.npy',\n    'logistic_regression1': 'train_lr.npy',\n    'logistic_regression2': 'train_oof_lr_0.npy',\n    'random_forest': 'train_rf.npy',\n    'tabnet1': 'train_tabnet_0.npy',\n    'tabnet2': 'train_tabnet_1.npy',\n    'histgradient1': 'train_oof_hgb_0.npy',\n    'histgradient2': 'train_oof_hgb_1.npy',\n    'keras1': 'train_keras_0.npy',\n    'keras2': 'train_keras_1.npy'\n}\n\ntest_pred_dict = {\n    'trans_1': 'test_rgr_epoch2000_probas8_params0_batch512.npy',\n    'trans_2': 'test_rgr_epoch2000_probas8_params1_batch512.npy',\n    'trans_3': 'test_rgr_epoch2000_probas8_params2_batch512.npy',\n    'trans_4': 'test_rgr_epoch2000_probas8_params3_batch512.npy',\n    'trans_5': 'test_rgr_epoch2000_probas8_params4_batch512.npy',\n    'trans_6': 'test_rgr_epoch2000_probas8_params5_batch512.npy',\n    'trans_7': 'test_rgr_epoch2000_probas8_params6_batch512.npy',\n    'lightgbm1': 'test_lgb.npy',\n    'lightgbm2': 'test_preds_lgbm_0.npy',\n    'lightgbm3': 'test_preds_lgbm_1.npy',\n    'xgboost': 'test_xgb.npy',\n    'catboost': 'test_cbt.npy',\n    'logistic_regression1': 'test_lr.npy',\n    'logistic_regression2': 'test_preds_lr_0.npy',\n    'random_forest': 'test_rf.npy',\n    'tabnet1': 'test_tabnet_0.npy',\n    'tabnet2': 'test_tabnet_1.npy',\n    'histgradient1': 'test_preds_hgb_0.npy',\n    'histgradient2': 'test_preds_hgb_1.npy',\n    'keras1': 'test_keras_0.npy',\n    'keras2': 'test_keras_1.npy'\n}","9c0cea5b":"from pathlib import Path\nINPUT_PATH = Path(\"..\/input\/tabular-playground-series-mar-2021\")\n\nTRAIN_PATH = Path(\"train\")\nTEST_PATH = Path(\"..\/input\/tps-mar-2021-preprocessed-data\/preprocessed-data\/test\")\n","f853dc89":"TRAIN_PATH","f2b707fb":"train_df = pd.read_csv(INPUT_PATH \/ \"train.csv\")\ntest_df = pd.read_csv(INPUT_PATH \/ \"test.csv\")\nsub_df = pd.read_csv(INPUT_PATH \/ 'sample_submission.csv')","022cef3d":"oof_df = pd.DataFrame()\npreds_df = pd.DataFrame()\n\nfor name, train_oof in train_oof_dict.items():\n    oof_df = pd.concat([oof_df, pd.Series(np.load(TRAIN_PATH \/ train_oof), name=name)], axis=1)\n    \nfor name, test_pred in test_pred_dict.items():\n    preds_df = pd.concat([preds_df, pd.Series(np.load(TEST_PATH \/ test_pred), name=name)], axis=1)","720c395e":"<a id='1'><\/a>\n# <p style=\"font-family:newtimeroman; font-size:150%; text-align:center\">1. T\u00e9lechargement des donn\u00e9es <\/p>","b79062a7":"<a id='3.4'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">3.4 Variables num\u00e9riques<\/p>","b2d48777":"<a id='4'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:150%; text-align:center\">4. Mod\u00e8lisation<\/p>","02b926d7":"<a id='5'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:150%; text-align:center\">5. Optimisation<\/p>","2ec37a19":"<a id='3.5'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">3.5 Variables caract\u00e8res<\/p>","13b1b801":"## <p style=\"font-family:newtimeroman; font-size:200%; text-align:center\">Sommaire<\/p>\n\n* [1. T\u00e9lechargement des donn\u00e9es](#1)\n* [2. l'analyse du fichier](#2)\n     * [2.1 Forme du fichier](#2.1)\n     * [2.2 D\u00e9claration des variables](#2.2)\n* [3. Chiffres cl\u00e9s](#3)\n    * [3.1 pandas_profiling](#3.1)\n    * [3.2 Methode classique](#3.2)\n    * [3.3 Variables cibles](#3.3)\n    * [3.4 Variables num\u00e9riques](#3.4)\n    * [3.4 Variables caract\u00e8res](#3.5)    \n* [4. Mod\u00e8lisation](#4)\n* [5. Optimisation](#5)\n* [6. Fichier soumission](#6)\n\n \n   \n","7b936a51":"La variables Target = 26 % ","c284d58b":"<a id='3.1'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">3.1 pandas_profiling<\/p>","c2a533d9":"# Notebook en fran\u00e7ais.","714a5938":"<a id='3.2'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">3.2 Methode classique<\/p>","afdce000":"<a id='2.1'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">2.1 Forme du fichier<\/p>","ec8a0fff":"<a id='3.3'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">3.3 Variables cibles<\/p>","77de8f6a":"<a id='2.2'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:110%; text-align:center\">2.2 D\u00e9claration des variables<\/p>","2a017c78":"<a id='3'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:150%; text-align:center\">3. Chiffres cles<\/p>","0fbafd72":"<a id='2'><\/a>\n## <p style=\" font-family:newtimeroman; font-size:150%; text-align:center\">2. l'analyse du fichier<\/p>"}}