{"cell_type":{"a1f27559":"code","cfe0b8f2":"code","8e8ede7d":"code","4f2a683b":"code","29907fe9":"code","d62cfcc0":"code","64b588bc":"code","d3459604":"code","8ef50e9b":"code","3c9aa377":"code","9fe830bd":"code","3fca97dd":"code","31808003":"code","4c6377d3":"code","a78ae75b":"code","2f1abc90":"markdown","d0134f9b":"markdown","0f4b5b89":"markdown"},"source":{"a1f27559":"import os\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import KFold\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, LongformerTokenizer","cfe0b8f2":"device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )","8e8ede7d":"class config:\n    batch_size = 4\n    acc_steps = 8\n    max_len = 1024\n    lr = 2e-5\n    weight_decay=1e-3","4f2a683b":"label2segment={\n    0: 'Lead',\n    1: 'Lead',\n    \n    2: 'Position',\n    3: 'Position',\n    \n    4: 'Evidence',\n    5: 'Evidence',\n    \n    6: 'Claim',\n    7: 'Claim',\n    \n    8: 'Concluding Statement',\n    9: 'Concluding Statement',\n    \n    10: 'Counterclaim',\n    11: 'Counterclaim',\n    \n    12: 'Rebuttal',\n    13: 'Rebuttal'\n}","29907fe9":"class FeedbackModel(nn.Module):\n    def __init__(self, num_labels):\n        super(FeedbackModel, self).__init__()\n        modelconfig = AutoConfig.from_pretrained(config.model_name)\n\n        self.backbone = AutoModel.from_pretrained(config.model_name)\n        self.output = nn.Linear(modelconfig.hidden_size, num_labels)\n    \n    def forward(self, input_ids, attn_mask, rpercentile):\n        attn_outputs = self.backbone(input_ids, attn_mask)\n        y=self.output(attn_outputs.last_hidden_state)\n        return y","d62cfcc0":"class FeedbackDataset( torch.utils.data.Dataset ):\n    def __init__(self, df, tokenizer):\n        self.tokenizer=tokenizer\n        df=df.copy()\n        self.content = df.content.values\n    \n    def get_tokenized_inputs(self, essay):\n        tokenized_inputs = self.tokenizer(essay, is_split_into_words=True)\n        word_ids = tokenized_inputs.word_ids()\n        return (tokenized_inputs, word_ids)\n    \n    \n    def __getitem__(self, idx):\n        essay  = self.content[idx]\n        (tokenized_inputs, word_ids) = self.get_tokenized_inputs(essay)\n        word_ids[0] = -100\n        word_ids[-1] = -100\n        \n        input_ids = tokenized_inputs['input_ids'][:config.max_len]\n        attn_mask = tokenized_inputs['attention_mask'][:config.max_len]\n        word_ids = word_ids[:config.max_len]\n        seq_len = len(input_ids)\n        \n        if seq_len < config.max_len:\n            len_diff = config.max_len - seq_len\n            attn_mask += [0] * len_diff\n            input_ids += [self.tokenizer.pad_token_id] * len_diff\n            word_ids += [-100] * len_diff\n        \n        rpercentile = ((1 + np.arange(0, config.max_len))\/seq_len) - 0.5        \n        input_ids=torch.tensor(input_ids, dtype=torch.long)\n        attn_mask = torch.tensor(attn_mask, dtype=torch.long)\n        seq_len = torch.tensor(seq_len, dtype=torch.long)\n        word_ids= torch.tensor(word_ids, dtype=torch.long)\n        rpercentile = torch.tensor(rpercentile, dtype=torch.float32)\n        \n        return {\n            'input_ids': input_ids,\n            'attn_mask': attn_mask,\n            'word_ids': word_ids,\n            'seq_len': seq_len,\n            'rpercentile': rpercentile\n        }\n    def __len__(self):\n        return len(self.content)","64b588bc":"tokenizer=AutoTokenizer.from_pretrained('..\/input\/longformer-base-tokenizer\/longformer_base_tokenizer')\nmodel = torch.load('..\/input\/longformer-baseline-model\/model.pt', map_location = device)","d3459604":"def read_essay(filename):\n    essay_folder='..\/input\/feedback-prize-2021\/test'\n    filepath = os.path.join(essay_folder, filename)\n    essay = ''\n    with open(filepath) as file:\n        essay = file.read()\n    essay=essay.split()\n    return essay","8ef50e9b":"test_files = os.listdir('..\/input\/feedback-prize-2021\/test')\ntest_df = []\nfor filename in test_files:\n    test_df.append({\n        'id': filename.replace(\".txt\", ''),\n        'content': read_essay(filename)\n    })\ntest_df = pd.DataFrame.from_dict(test_df)","3c9aa377":"val_dataset   = FeedbackDataset(test_df, tokenizer)\nval_dataloader = torch.utils.data.DataLoader(val_dataset,\n                                             batch_size=2,\n                                             shuffle=False,\n                                             drop_last=False\n                                            )","9fe830bd":"def postprocess( y, word_ids):\n    seq_len = len(y)\n    prv_word_id=None\n    predSegment=[]\n    predTokens=[]\n    \n    preds=[]\n    for i in range(seq_len):\n        word_id = word_ids[i]\n        if  (word_id== -100) or (prv_word_id == word_id):\n            continue\n        prv_word_id = word_id\n        \n        if y[i] not in label2segment:\n            continue\n        \n        segment = label2segment[ y[i] ]\n        predSegment.append(segment)\n        predTokens.append( word_id )\n    \n    if len(predSegment) == 0:\n        return []\n    \n    if len(predSegment) == 1:\n        preds.append({\n            'segment': predSegment[0],\n            'word_ids': [predTokens[0]]\n        })\n        return preds\n    else:\n        num_tokens=len(predTokens)\n        prv_id=0\n        cur_id=0\n        prv_segment=predSegment[0]\n        \n        for i in range(1, num_tokens+1):\n            cur_id=i\n            if (i!=num_tokens) and \\\n                (predTokens[i] == 1+predTokens[i-1]) and \\\n                (predSegment[i] == predSegment[i-1]):\n                continue\n            \n            pred_token_list=[]\n            for j in range(prv_id, cur_id):\n                pred_token_list.append(predTokens[j])\n            \n            preds.append({\n                'segment': prv_segment,\n                'word_ids': pred_token_list\n            })\n            if i!=num_tokens:\n                prv_segment = predSegment[i]\n                prv_id=cur_id\n    return preds","3fca97dd":"def prediction(model, val_dataloader):\n    model.eval()\n    predvalues = []\n    for inputs in val_dataloader:\n        input_ids = inputs['input_ids']\n        attn_mask = inputs['attn_mask']\n        word_ids = inputs['word_ids']\n        seq_len = inputs['seq_len']\n        rpercentile = inputs['rpercentile']\n        batch_max_seqlen = torch.max(seq_len).item()\n        \n        input_ids = input_ids[:, :batch_max_seqlen].to(device)\n        attn_mask = attn_mask[:, :batch_max_seqlen].to(device)\n        rpercentile = rpercentile[:, :batch_max_seqlen].to(device)\n        with torch.no_grad():\n            yhat = model(input_ids, attn_mask, rpercentile).softmax(dim=-1).argmax(dim=-1).cpu()\n        \n        bsize = attn_mask.shape[0]\n        for i in range(bsize):\n            yhati = yhat[i].numpy()\n            word_ids_i = word_ids[i].numpy()\n            \n            pred_tokens = postprocess(yhati, word_ids_i)\n            for token in pred_tokens:\n                token['word_ids'] = [str(x) for x in token['word_ids']]\n                token['word_ids'] = ' '.join(token['word_ids'])\n            predvalues.append(pred_tokens)\n    return predvalues","31808003":"test_df['predvalues'] = prediction(model, val_dataloader)\ntest_df.head()","4c6377d3":"submission_data=[]\nfor index, row in test_df.iterrows():\n    predvalues = row.predvalues\n    \n    for pred in predvalues:\n        if len(pred['word_ids'].split()) == 1:\n            continue\n            \n        submission_data.append({\n            'id': row.id,\n            'class': pred['segment'],\n            'predictionstring': pred['word_ids']\n        })\nsubmission_df = pd.DataFrame.from_dict(submission_data)\nsubmission_df.head()","a78ae75b":"submission_df.to_csv(\"submission.csv\", index=False)","2f1abc90":"# dataset","d0134f9b":"# model","0f4b5b89":"# load models"}}