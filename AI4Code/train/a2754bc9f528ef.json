{"cell_type":{"fe806ac8":"code","556cf993":"code","16adb2bb":"code","3cfd1e1e":"code","18a9e079":"code","28f342e7":"code","91c804ee":"code","4ce5ed3e":"markdown","8fff8b4c":"markdown","23cc3938":"markdown","7a2fccf3":"markdown"},"source":{"fe806ac8":"import os, shutil\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Supress tensorflow log outputs","556cf993":"# Original dataset directory\npath = \"\/kaggle\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\"\n\n# Create fish dataset directory\n!mkdir fish_dataset\n\n# Iterate through all folders in directory and creates list of fishes\nfishes = []\nfor name in os.listdir(path):\n    if os.path.isdir(os.path.join(path, name)):\n        fishes.append(name)\n        \n# Copy over relavant folders to fish dataset directory (takes a while)\nfor fish in fishes:\n    fish_image_folder = os.path.join(path, fish, fish)\n    shutil.copytree(fish_image_folder, os.path.join(\".\/fish_dataset\", fish))","16adb2bb":"\"\"\"\nDirectory should now have the following structure so we can use tf.keras.preprocessing.image_dataset_from_directory:\nmain_directory\/\n...class_a\/\n......a_image_1.jpg\n......a_image_2.jpg\n...class_b\/\n......b_image_1.jpg\n......b_image_2.jpg\n\"\"\"\nprint(os.listdir(\".\/fish_dataset\"))\nprint(os.listdir(\".\/fish_dataset\/Gilt-Head Bream\")[:3])","3cfd1e1e":"img_size = (224, 224)\nbatch_size = 32\n\nds_train = tf.keras.preprocessing.image_dataset_from_directory(\n    \".\/fish_dataset\/\",\n    labels=\"inferred\",\n    label_mode=\"categorical\",  \n    color_mode=\"rgb\",\n    batch_size=batch_size,\n    image_size=img_size,  \n    shuffle=True,\n    seed=1,\n    validation_split=0.2,\n    subset=\"training\",\n)\n\nds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n    \".\/fish_dataset\/\",\n    labels=\"inferred\",\n    label_mode=\"categorical\",  \n    color_mode=\"rgb\",\n    batch_size=batch_size,\n    image_size=img_size,  \n    shuffle=True,\n    seed=1,\n    validation_split=0.2,\n    subset=\"validation\",\n)","18a9e079":"model = keras.Sequential([\n    layers.Input((224, 224, 3)),\n    \n    layers.Conv2D(16, 3, activation=\"relu\"),\n    layers.BatchNormalization(), # regularization\n    layers.MaxPooling2D(), \n    \n    layers.Conv2D(32, 3, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n    layers.Conv2D(64, 3, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    \n    layers.Dense(64, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2), # regularization\n    layers.Dense(9, activation=\"softmax\"),\n])","28f342e7":"model.compile(\n    optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n    loss = keras.losses.CategoricalCrossentropy(),\n    metrics = [\"accuracy\"],\n)","91c804ee":"model.fit(ds_train, batch_size=64, epochs=5, verbose=2, validation_data=ds_validation)","4ce5ed3e":"### Data Preprocessing","8fff8b4c":"### Create training and validation dataset","23cc3938":"### Imports","7a2fccf3":"### Simple CNN"}}