{"cell_type":{"0b974390":"code","88785992":"code","aa82ea6e":"code","86acf8fc":"code","01e2f5e0":"code","b5b613c3":"code","1ce8e70b":"code","2da59311":"code","e11c2e2c":"code","457acf2b":"code","81da643b":"code","45193690":"code","03bd0b24":"code","f3e0a5cb":"code","b1c08e5d":"code","dbf46396":"markdown","6199f2d4":"markdown","d8c9c4a3":"markdown","18891148":"markdown","e27ce53b":"markdown","44982f4e":"markdown","8e11072b":"markdown","0f1ca674":"markdown","5649185c":"markdown"},"source":{"0b974390":"import os\nfrom PIL import Image\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder","88785992":"encoder = OneHotEncoder()\nencoder.fit([[0], [1]])","aa82ea6e":"data = []\npaths = []\nresult = []\n\nfor r, d, f in os.walk(r'..\/input\/brain-mri-images-for-brain-tumor-detection\/yes'):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[0]]).toarray())\nresult[0]        ","86acf8fc":"paths = []\nfor r, d, f in os.walk(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\"):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[1]]).toarray())","01e2f5e0":"data = np.array(data)\ndata.shape","b5b613c3":"result = np.array(result)\nresult = result.reshape(139,2)\nresult.shape\n","1ce8e70b":"train_images, test_images, train_labels, test_labels = train_test_split(data, result, test_size=0.1, shuffle=True, random_state=1)","2da59311":"print('Train Images Shape', train_images.shape)\nprint('Train Labels Shape', train_labels.shape)\nprint('Test Images Shape', test_images.shape)\nprint('Test Labels Shape', test_labels.shape)","e11c2e2c":"inputs = tf.keras.Input(shape=(128, 128, 3))\n\nconv2d_layer = tf.keras.layers.Conv2D(32, (2,2), padding='Same')(inputs)\nconv2d_layer = tf.keras.layers.Conv2D(32, (2,2), activation='relu', padding='Same')(conv2d_layer)\n\nbn_layer = tf.keras.layers.BatchNormalization()(conv2d_layer)\nmp_layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(bn_layer)\ndrop = tf.keras.layers.Dropout(0.25)(mp_layer)\n\nconv2d_layer = tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding='Same')(drop)\nconv2d_layer = tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding='Same')(conv2d_layer)\n\nbn_layer = tf.keras.layers.BatchNormalization()(conv2d_layer)\nmp_layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(bn_layer)\ndrop = tf.keras.layers.Dropout(0.25)(mp_layer)\n\nflatten_layer = tf.keras.layers.Flatten()(drop)\n\ndense_layer = tf.keras.layers.Dense(512, activation='relu')(flatten_layer)\ndrop = tf.keras.layers.Dropout(0.5)(dense_layer)\noutputs = tf.keras.layers.Dense(2, activation='softmax')(drop)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs, name='tumor_model')\nmodel.summary()","457acf2b":"model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n             optimizer = tf.keras.optimizers.Adamax(),\n             metrics = ['accuracy'])","81da643b":"history = model.fit(train_images, train_labels,\n                   epochs=40,\n                   batch_size=128,\n                   validation_data=(test_images, test_labels))","45193690":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Test', 'Validation'], loc='upper right')\nplt.show()","03bd0b24":"def names(number):\n    if number==0:\n        return 'Its a Tumor'\n    else:\n        return 'No, Its not a tumor'","f3e0a5cb":"from matplotlib.pyplot import imshow\nimg = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y2.jpg\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","b1c08e5d":"img = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/19 no.jpg\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","dbf46396":"## Library","6199f2d4":"## Create Model With Functional API","d8c9c4a3":"## Fit Model","18891148":"## Preprocessing ","e27ce53b":"We are going to split and append the files in the yes folder, The content of NO folder are known and for surely the non brain tumor MRI images.","44982f4e":"## OneHotEncoding","8e11072b":"## Train and Test Data","0f1ca674":"1. Importing the OS library to deal with the opeation regarding File Read\/Write.\n2. Importing PIL to process and deal with images\/\n3. Importing Numpy to deal with numerical phase of data such as arrays\n4. Importing Pandas to deal with data\n5. Here we are using tensorflow to deal with image processing.\n6. Using Matplotlib to visualize the records \n7. We wants to use the Dark Background while visualizing that's why we have typed that. \n8. We will split the dataset into two train and test.\n9. One-hot encoding is essentially the representation of categorical variables as binary vectors. ","5649185c":"We are going to split and append the files in the yes folder, The content of yes folder are known and for surely the tumor MRI images."}}