{"cell_type":{"9876fe34":"code","6f6cd2b9":"code","c1ed7d5c":"code","0fb61b11":"code","10d36b3d":"code","3d5dc458":"code","35b64325":"code","5bf59bcc":"code","a843a93e":"code","b569b08c":"code","5ea3cc64":"code","6f4b302e":"code","78ebcdc3":"code","884cd784":"code","75de31b7":"code","eff5a8a4":"code","fa58f2ed":"code","fe47b1fe":"code","9a4d6cad":"code","f417f6ef":"code","b4697c09":"code","f48b2da2":"markdown","fe635540":"markdown","07274036":"markdown","f808f159":"markdown","6106aeca":"markdown","bb0f58af":"markdown","e19d6e61":"markdown"},"source":{"9876fe34":"import numpy as np\nimport pandas as pd\nimport os\nfrom random import shuffle\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","6f6cd2b9":"import numpy as np\nimport pandas as pd\nimport os\nfrom random import shuffle\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","c1ed7d5c":"import zipfile\n\nwith zipfile.ZipFile(\"..\/input\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/test.zip\",\"r\") as z:\n    z.extractall(\".\")","0fb61b11":"TRAIN_DIR = '\/kaggle\/working\/train\/'\nTEST_DIR = '\/kaggle\/working\/test\/'","10d36b3d":"import cv2","3d5dc458":"training_files = os.listdir(TRAIN_DIR)","35b64325":"training_files[0]","5bf59bcc":"cv2.imread(TRAIN_DIR + training_files[0]).shape","a843a93e":"test_files = os.listdir(TEST_DIR)","b569b08c":"test_files[0]","5ea3cc64":"IMG_SIZE = 50","6f4b302e":"def create_dataset(folder_path, flag_training=True):\n    def identify_label(file_name):\n        dog_or_cat = file_name.split('.')[0]\n        if dog_or_cat == 'cat':\n            return np.array([1, 0])\n        elif dog_or_cat == 'dog':\n            return np.array([0, 1])\n        \n    def identify_image_id(file_name):\n        return file_name.split('.')[0]\n    \n    result = []\n    for file_name in tqdm(os.listdir(folder_path)):\n        file_path = os.path.join(folder_path, file_name)\n        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        if flag_training:\n            img_data = np.array(img)\n            label = identify_label(file_name)\n            result.append([img_data, label])\n        else:\n            img_data = np.array(img)\n            img_id = identify_image_id(file_name)\n            result.append([img_data, img_id])\n    return result","78ebcdc3":"train_dataset = create_dataset(TRAIN_DIR)\ntest_dataset = create_dataset(TEST_DIR, flag_training=False)","884cd784":"import tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression","75de31b7":"FILTER_SIZE = 10\nLR = 1e-3\nEPOCH = 3","eff5a8a4":"class CNN:\n    def __init__(self):\n        self.model = self.__build_cnn()\n    \n    def fit(self, train_dataset):\n        x_train, y_train, x_val, y_val = self.__load_training_validation(train_dataset)\n        self.model.fit({'input': x_train}, {'targets': y_train}, \\\n                  validation_set=({'input': x_val}, {'targets': y_val}), \\\n                  n_epoch=EPOCH, snapshot_step=500, show_metric=True, run_id='model' )\n        \n    def predict(self, input_data_list):\n        return self.model.predict(input_data_list)\n               \n    def __build_cnn(self):\n        # Note: Input\n        cnn = input_data(shape = [None, IMG_SIZE, IMG_SIZE, 1], name = 'input')\n        \n        # Note:conv_2d - http:\/\/tflearn.org\/layers\/conv\/\n        #       The default padding will make output image size the same.\n        #       The default step size is 1.\n        #       max_pool_2d - http:\/\/tflearn.org\/layers\/conv\/#max-pooling-2d\n        \n        # Note: Layer 1 CNN with 32 filters and 5*5 filter size. \n        #       Dimension: (?, 50, 50, 1) -> (?, 50, 50, 32) -> (?, 10, 10, 32)\n        cnn = conv_2d(cnn, 32, FILTER_SIZE, activation='relu')\n        cnn = max_pool_2d(cnn, FILTER_SIZE)\n        # Note: Layer 2 CNN with 64 filters and 5*5 filter size.\n        #       Dimension: (?, 10, 10, 32) -> (?, 10, 10, 64) -> (?, 2, 2, 64)\n        cnn = conv_2d(cnn, 64, FILTER_SIZE, activation='relu')\n        cnn = max_pool_2d(cnn, FILTER_SIZE)\n        # Note: Layer 3 CNN with 128 filters and 5*5 filter size.\n        #       Dimension: (?, 2, 2, 64) -> (?, 2, 2, 128) -> (?, 1, 1, 128)\n        cnn = conv_2d(cnn, 128, FILTER_SIZE, activation='relu')\n        cnn = max_pool_2d(cnn, FILTER_SIZE)      \n        # Note: Layer 4 CNN with 64 filters and 5*5 filter size.\n        #       Output: (?, 1, 1, 128) -> (?, 1, 1, 64) -> (?, 1, 1, 64)\n        cnn = conv_2d(cnn, 64, FILTER_SIZE, activation='relu')\n        cnn = max_pool_2d(cnn, FILTER_SIZE)               \n        # Note: Layer 5 CNN with 32 filters and 5*5 filter size.\n        #       Output: (?, 1, 1, 64) -> (?, 1, 1, 32) -> (?, 1, 1, 32)\n        cnn = conv_2d(cnn, 32, FILTER_SIZE, activation='relu')\n        cnn = max_pool_2d(cnn, FILTER_SIZE)\n        \n        # Note: Layer 6 Fully Connected\n        #       Output: (?, 1, 1, 32) -> (?, 1024)\n        cnn = fully_connected(cnn, 1024, activation = 'relu')\n        # Note: Layer 7 Dropout\n        cnn = dropout(cnn, 0.8)\n        # Note: Layer 8 Fully Connected\n        #       Output: (?, 1024) -> (?, 2)\n        cnn = fully_connected(cnn, 2, activation='softmax')\n        \n        # Note: Output\n        cnn = regression(cnn, optimizer='adam', learning_rate = LR, \\\n                         loss='categorical_crossentropy', name='targets')\n        model = tflearn.DNN(cnn, tensorboard_dir='log')\n        \n        return model\n        \n    def __load_training_validation(self, train_dataset, validation_portion=0.2):\n        num_of_obs = len(train_dataset)\n        cutoff = int(num_of_obs * (1 - validation_portion))\n        train, validation = train_dataset[:cutoff], train_dataset[cutoff:]\n        \n        x_train = np.array([i[0] for i in train], dtype=np.float64).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n        y_train = np.array([i[1] for i in train], dtype=np.float64)\n        x_val = np.array([i[0] for i in validation], dtype=np.float64).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n        y_val = np.array([i[1] for i in validation], dtype=np.float64)\n        return x_train, y_train, x_val, y_val","fa58f2ed":"cnn = CNN()\ncnn.fit(train_dataset)","fe47b1fe":"def predict_some_test_samples_and_show(test_dataset):\n    fig = plt.figure()\n    for num, data in enumerate(test_dataset[:16]):\n        img_data, img_num = data[0], data[1]\n        img_data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n        pred_prob = cnn.predict([img_data])[0]\n        pred_label = 'Dog' if np.argmax(pred_prob) == 1 else 'Cat'\n        \n        subplot = fig.add_subplot(4, 4, num+1)\n        subplot.imshow(data[0], cmap='gray')\n        plt.title(pred_label)\n        subplot.axes.get_xaxis().set_visible(False)\n        subplot.axes.get_yaxis().set_visible(False)\n    \n    plt.tight_layout()\n    plt.show()","9a4d6cad":"def predict_for_all_examples(test_dataset):\n    img_ids, img_labels = [], []\n    for sample in tqdm(test_dataset):\n        img_data, img_id = sample[0], sample[1]\n        img_data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n        pred_prob = cnn.predict([img_data])[0]\n        pred_label = 1 if np.argmax(pred_prob) == 1 else 0 # Note: 1=dog, 0=cat\n        img_ids.append(img_id)\n        img_labels.append(pred_label)\n    return pd.DataFrame({'id': img_ids, 'label': img_labels})","f417f6ef":"predict_some_test_samples_and_show(test_dataset)","b4697c09":"submission = predict_for_all_examples(test_dataset)\nsubmission.to_csv('submission.csv', index=False,header=True)","f48b2da2":"# Explantory Data Analyisis","fe635540":"2.Train","07274036":"Kaggle: https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition\/notebooks","f808f159":"1.Model Definition","6106aeca":"3.Predict","bb0f58af":"# Prepare Data","e19d6e61":"# CNN Model"}}