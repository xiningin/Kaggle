{"cell_type":{"f4bc9e4d":"code","2794aa6e":"code","451ee553":"code","1dbdcea0":"code","7e1b0ca5":"code","ca55f845":"code","4193a646":"code","4ce36bef":"code","114bb3fe":"code","e17f86bb":"code","f20ba847":"code","79819ea2":"code","1c65ae0f":"code","d74fe6ad":"code","8548d8d7":"code","8960e2bb":"code","c6746f75":"code","4da8e5a7":"code","5652ba00":"code","05268b6a":"code","d5f51760":"code","4b455391":"code","48a86a74":"code","d8768c37":"code","54ded21a":"code","55c008ea":"code","d1e34ecc":"code","17d5d3dd":"code","927f22f0":"code","d2e200ae":"code","bf6d8053":"code","33fa30f9":"code","43106a6f":"code","33cf8186":"code","0c2459c5":"code","de6a3680":"code","12ef3192":"code","4612bfd3":"code","b2ef2587":"code","6160da58":"code","aae75396":"code","23fb16cf":"code","22226e76":"code","f6bf21cc":"code","9e1ab01a":"code","80f9b069":"code","1a3d9bc5":"code","bb03bafd":"markdown","002f00f4":"markdown","5adadc60":"markdown","4eb6830c":"markdown","94e50701":"markdown","15d2193b":"markdown","d985b987":"markdown","133572c1":"markdown","90e65515":"markdown","f57de7da":"markdown","cf9be540":"markdown","fa9589f6":"markdown","135cdad5":"markdown","baef76a8":"markdown"},"source":{"f4bc9e4d":"import tensorflow as tf\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\nimport os\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')","2794aa6e":"# Set image_size and batch_size\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\n\n# Target Directory\ndirectory = \"..\/input\/flowers-recognition\/flowers\"\n\n# Train Data\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(\n             directory,\n             subset='training',\n             validation_split=0.2,\n             image_size=IMAGE_SIZE,\n             batch_size=BATCH_SIZE,\n             seed=42)\n\n# Valid data\nvalid_data = tf.keras.preprocessing.image_dataset_from_directory(\n            directory,\n            subset='validation',\n            validation_split=0.2,\n            image_size=IMAGE_SIZE,\n            batch_size=BATCH_SIZE,\n             seed=42)","451ee553":"class_names = train_data.class_names\nclass_names","1dbdcea0":"label_encode = LabelEncoder()\nclass_names_label_encode = label_encode.fit_transform(class_names)\nclass_names_label_encode","7e1b0ca5":"img = plt.imread(\"..\/input\/flowers-recognition\/flowers\/daisy\/102841525_bd6628ae3c.jpg\")\nplt.imshow(img)\nplt.title(\"Daisy\")\nplt.axis(\"off\")\nplt.show();","ca55f845":"img = plt.imread(\"..\/input\/flowers-recognition\/flowers\/dandelion\/10200780773_c6051a7d71_n.jpg\")\nplt.imshow(img)\nplt.title(\"Dandelion\")\nplt.axis(\"off\")\nplt.show();","4193a646":"img = plt.imread(\"..\/input\/flowers-recognition\/flowers\/rose\/11233672494_d8bf0a3dbf_n.jpg\")\nplt.imshow(img)\nplt.title(\"rose\")\nplt.axis(\"off\")\nplt.show();","4ce36bef":"img = plt.imread(\"..\/input\/flowers-recognition\/flowers\/sunflower\/10386525695_2c38fea555_n.jpg\")\nplt.imshow(img)\nplt.title(\"Sunflower\")\nplt.axis(\"off\")\nplt.show();","114bb3fe":"img = plt.imread(\"..\/input\/flowers-recognition\/flowers\/tulip\/10686568196_b1915544a8.jpg\")\nplt.imshow(img)\nplt.title(\"Tulip\")\nplt.axis(\"off\")\nplt.show();","e17f86bb":"def preprocess_image(image, label, image_shape=224):\n    \n    img = tf.image.resize(image, [image_shape, image_shape])\n    img = img\/225.\n    \n    return tf.cast(img, tf.float32), label","f20ba847":"preprocess_image(image=img, label='tulip')","79819ea2":"# map the preprocess_image to train_data\ntrain_data = train_data.map(map_func=preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n# shuffle the data\ntrain_data = train_data.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n\n\n# map the preprocess_image to valid_data\nvalid_data = valid_data.map(map_func=preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n# shuffle the data\nvalid_data = valid_data.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)","1c65ae0f":"train_data, valid_data","d74fe6ad":"# Set random seed\ntf.random.set_seed(42)\n\n# model 1\nmodel_1 = Sequential([\n    Conv2D(filters=32, kernel_size=4, padding='same', activation='relu',input_shape=(224,224,3)),\n    MaxPool2D(2,2),\n    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n    MaxPool2D(2,2), \n    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n    MaxPool2D(2,2),\n    Dropout(0.5),\n    Flatten(),\n    Dense(len(class_names_label_encode), activation='softmax')\n])\n\n# Compile\nmodel_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer='adam',\n               metrics=['accuracy'])\n\n# Fit\nhistory_1 = model_1.fit(train_data,\n                       epochs=5,\n                       validation_data=valid_data)","8548d8d7":"# model_1 summary\nmodel_1.summary()","8960e2bb":"def plot_loss_curves(history):\n    \n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n\n    epochs = range(len(history.history['loss']))\n\n  # Plot loss\n    plt.plot(epochs, loss, label='training_loss')\n    plt.plot(epochs, val_loss, label='val_loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n\n  # Plot accuracy\n    plt.figure()\n    plt.plot(epochs, accuracy, label='training_accuracy')\n    plt.plot(epochs, val_accuracy, label='val_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend();","c6746f75":"plot_loss_curves(history=history_1)","4da8e5a7":"# Set random seed\ntf.random.set_seed(42)\n\n# model_2\nmodel_2 = Sequential([\n    Conv2D(filters=32, kernel_size=4, padding='same', activation='relu', input_shape=(224,224,3)),\n    MaxPool2D(2,2),\n    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n    MaxPool2D(2,2),\n    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n    MaxPool2D(2,2),\n    Conv2D(filters=128, kernel_size=5, padding='same', activation='relu'),\n    MaxPool2D(2,2),\n    Flatten(),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dense(len(class_names_label_encode), activation='softmax')\n])\n\n# Compile\nmodel_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer='adam',\n               metrics=['accuracy'])\n\n# Fit \nhistory_2 = model_2.fit(train_data,\n                       epochs=5,\n                       validation_data=valid_data)","5652ba00":"#model summary\nmodel_2.summary()","05268b6a":"# plot \nplot_loss_curves(history_2)","d5f51760":"# random seed\ntf.random.set_seed(42)\n\n# model_3\nmodel_3 = Sequential([\n    Conv2D(filters=32, kernel_size=4, padding='same', activation='relu', input_shape=(224,224,3)),\n    MaxPool2D(2,2),\n    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n    MaxPool2D(2,2),\n    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n    MaxPool2D(2,2),\n    Conv2D(filters=128, kernel_size=5, padding='same', activation='relu'),\n    MaxPool2D(3,3),\n    Conv2D(filters=128, kernel_size=5, padding='same', activation='relu'),\n    MaxPool2D(3,3),\n    Conv2D(filters=128,kernel_size=5, padding='same', activation='relu'),\n    MaxPool2D(3,3),\n    Flatten(),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dense(len(class_names_label_encode), activation='softmax')\n    \n])\n\n# compile\nmodel_3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n\n# fit \nhistory_3 = model_3.fit(train_data,\n                       epochs=5,\n                       validation_data=valid_data)","4b455391":"model_3.summary()","48a86a74":"plot_loss_curves(history_3)","d8768c37":"# Download Inception V3 model\nbase_model_inception = tf.keras.applications.inception_v3.InceptionV3(include_top=False)\n\n# Freeze the layers\nbase_model_inception.trainable=False\n\n# Inputs\ninputs = tf.keras.layers.Input(shape=(224,224,3), name='input_layer')\n\n# Scaling the values\nx = tf.keras.layers.experimental.preprocessing.Rescaling(1\/255.)(inputs)\n\n# Pass inputs to our base_model\nx = base_model_inception(inputs,training=False)\n\n# GlobalAveragePooling2D\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n# outputs\noutputs = tf.keras.layers.Dense(len(class_names_label_encode), activation='softmax')(x)\n\n# Build model\nmodel_4 = tf.keras.Model(inputs, outputs)\n\n# Compile the model\nmodel_4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer='adam',\n               metrics=['accuracy'])\n","54ded21a":"model_4.summary()","55c008ea":"# Fit the model\nhistory_4 = model_4.fit(train_data,\n                       epochs=5,\n                       validation_data=valid_data)","d1e34ecc":"plot_loss_curves(history_4)","17d5d3dd":"# Download and load resnet50 model\nbaseline_model_resnet50 = tf.keras.applications.resnet50.ResNet50(include_top=False)\n\n# Freeze the layer\nbaseline_model_resnet50.trainable= False\n\n# Inputs\ninputs = tf.keras.layers.Input(shape=(224,224,3))\n\n# Scaling\nx = tf.keras.layers.experimental.preprocessing.Rescaling(1\/255.)(inputs)\n\n# Pass inputs to our model\nx = baseline_model_resnet50(inputs,training=False)\n\n# GlobalAveragePooling2D\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n# Ouputs\noutputs = tf.keras.layers.Dense(len(class_names_label_encode),activation='softmax')(x)\n\n# Build model\nmodel_5 = tf.keras.Model(inputs,outputs)\n\n# Compile\nmodel_5.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer='adam',\n               metrics=['accuracy'])\n\n# Summary\nmodel_5.summary()","927f22f0":"# Fit the model\nhistory_5 = model_5.fit(train_data,\n                       epochs=5,\n                       validation_data=valid_data)","d2e200ae":"# plotlossscurve\nplot_loss_curves(history_5)","bf6d8053":"# Download base model\nbaseline_model_efficientnetb5 = tf.keras.applications.efficientnet.EfficientNetB5(include_top=False)\n\n# Freeze the layer\nbaseline_model_efficientnetb5.trainable = False\n\n# Inputs\ninputs = tf.keras.layers.Input(shape=(224,224,3))\n\n# Recaling\n#x = tf.keras.layers.experimental.preprocessing.Rescaling(1\/255.)(inputs)\n\n# pass inputs to our model\nx = baseline_model_efficientnetb5(inputs, training=False)\n\n# Global Average Pooling\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n# outputs\noutputs = tf.keras.layers.Dense(len(class_names_label_encode), activation='softmax')(x)\n\n# model_6\nmodel_6 = tf.keras.Model(inputs, outputs)\n\n# Compile\nmodel_6.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer='adam',\n               metrics=['accuracy'])\n\n# Summary\nmodel_6.summary()","33fa30f9":"# Fit the model\nhistory_6 = model_6.fit(train_data,\n                       epochs=5,\n                       validation_data = valid_data)","43106a6f":"# Checking the layer of best forming model(inception)\nfor layer_number, layer in enumerate(base_model_inception.layers):\n    print(layer_number, layer, layer.trainable)","33cf8186":"base_model_inception.summary()","0c2459c5":"## inceptionv3 architecture\nfrom tensorflow.keras.utils import plot_model\nplot_model(base_model_inception)","de6a3680":"base_model_inception.trainable = True\n\n# freeze all layers except last 15\nfor layer in base_model_inception.layers[:-15]:\n    layer.trainable = False\n\n# Recompile the model\nmodel_4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n               optimizer='adam',\n               metrics=['accuracy'])","12ef3192":"# Check the layers\nfor layer_number,layer in enumerate(base_model_inception.layers):\n    print(layer_number, layer, layer.trainable)","4612bfd3":"# refit the model\nhistory_model_4_fine_tune = model_4.fit(train_data,\n                                       epochs=10,\n                                       validation_data=valid_data,\n                                       initial_epoch=history_4.epoch[-1])","b2ef2587":"!wget https:\/\/raw.githubusercontent.com\/mrdbourke\/tensorflow-deep-learning\/main\/extras\/helper_functions.py","6160da58":"from helper_functions import compare_historys","aae75396":"compare_historys(history_4,\n                history_model_4_fine_tune)","23fb16cf":"# save the best performing model\nmodel_4.save(\"output\/best_performing_model\")","22226e76":"# load model\nloaded_model = tf.keras.models.load_model(\"output\/best_performing_model\")\nloaded_model","f6bf21cc":"# Evaluate\nloaded_model.evaluate(valid_data)","9e1ab01a":"# make prediction\npred_probs = loaded_model.predict(valid_data)\npred_probs[:10]","80f9b069":"# pred classes\npred_class = pred_probs.argmax(axis=1)\npred_class[:10]","1a3d9bc5":"# Unbatch the images and labels\ny_labels = []\nfor images, labels in valid_data.unbatch():\n    y_labels.append(labels.numpy().argmax())\ny_labels[:10]","bb03bafd":"**InceptionV3 model performed well when compared with ResNet50 and EfficientNetB5**\n\n**Now we will going to unfreeze layers(15) and perform fine-tuning**","002f00f4":"### Inception V3","5adadc60":"## Visaulize the images","4eb6830c":"## Modelling","94e50701":"## Transfer Learning","15d2193b":"## Model_3","d985b987":"### Resnet50","133572c1":"## Create a Preprocess_image function\n\nThe function returns to `float32` dtype and scale it between 0 & 1 with image_shape=224","90e65515":"#### Simple Dense Model","f57de7da":"## Batch & Prefetch","cf9be540":"## Fine-tuning","fa9589f6":"### Model_2","135cdad5":"## Setup","baef76a8":"## EfficientnetB5"}}