{"cell_type":{"cf64e68b":"code","098fdd48":"code","fae38093":"code","8901b49e":"code","e7c4be51":"code","54978cf2":"code","44372e7b":"code","ba71eda3":"code","9cdeb365":"code","f7e91ed2":"code","310c06cd":"code","a0ac359a":"code","b27055b8":"code","671d3aae":"code","4762d75f":"code","8d32c1e4":"code","3395a50c":"code","f4662b28":"code","0dd7ac8f":"code","a5f465d4":"code","fce57533":"code","a85d6659":"code","23876061":"code","3f1fa732":"code","25f21928":"code","03056acc":"code","846b27e0":"code","b832afbc":"code","a9b9e574":"code","43b2ce0c":"code","ecede46f":"code","b3018b79":"markdown","a8e4583f":"markdown","67c7f2e0":"markdown"},"source":{"cf64e68b":"from PIL import Image\nimport numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport os\n\nimport keras\nfrom keras import applications\nfrom keras.applications import VGG16 \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.layers import Flatten, Dense, GlobalAveragePooling2D\nfrom keras.optimizers import SGD\nfrom keras import backend as k \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom keras.preprocessing import image","098fdd48":"from glob import glob\nfrom keras.preprocessing.image import load_img, img_to_array\n\ntrain_0 = glob('\/kaggle\/input\/original-images\/Train\/0\/*', recursive=True)\ntrain_1 = glob('\/kaggle\/input\/original-images\/Train\/1\/*', recursive=True)\ntrain_2 = glob('\/kaggle\/input\/original-images\/Train\/2\/*', recursive=True)\ntrain_3 = glob('\/kaggle\/input\/original-images\/Train\/3\/*', recursive=True)","fae38093":"val_0 = glob('\/kaggle\/input\/original-images\/Valid\/0\/*', recursive=True)\nval_1 = glob('\/kaggle\/input\/original-images\/Valid\/1\/*', recursive=True)\nval_2 = glob('\/kaggle\/input\/original-images\/Valid\/2\/*', recursive=True)\nval_3 = glob('\/kaggle\/input\/original-images\/Valid\/3\/*', recursive=True)","8901b49e":"test_0 = glob('\/kaggle\/input\/original-images\/Test\/0\/*', recursive=True)\ntest_1 = glob('\/kaggle\/input\/original-images\/Test\/1\/*', recursive=True)\ntest_2 = glob('\/kaggle\/input\/original-images\/Test\/2\/*', recursive=True)\ntest_3 = glob('\/kaggle\/input\/original-images\/Test\/3\/*', recursive=True)","e7c4be51":"import pandas as pd\n\ntest_df = pd.read_csv('\/kaggle\/input\/original-images\/Label Files\/yTest.csv')\ntrain_df = pd.read_csv('\/kaggle\/input\/original-images\/Label Files\/yTrain.csv')\nval_df = pd.read_csv('\/kaggle\/input\/original-images\/Label Files\/yValid.csv')","54978cf2":"import cv2\ntrain_class2 =[]\ntrain_otherclasses = []\n\nfor i in train_2:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    train_class2.append(im1)\nfor i in train_0:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    train_otherclasses.append(im1)\nfor i in train_1:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    train_otherclasses.append(im1)\nfor i in train_3:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    train_otherclasses.append(im1)\n    ","44372e7b":"import cv2\nval_class2 =[]\nval_otherclasses = []\n\nfor i in val_2:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    val_class2.append(im1)\nfor i in val_0:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    val_otherclasses.append(im1)\nfor i in val_1:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    val_otherclasses.append(im1)\nfor i in val_3:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    val_otherclasses.append(im1)","ba71eda3":"import cv2\ntest_class2 =[]\ntest_otherclasses = []\n\nfor i in test_2:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    test_class2.append(im1)\nfor i in test_0:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    test_otherclasses.append(im1)\nfor i in test_1:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    test_otherclasses.append(im1)\nfor i in test_3:\n    im = cv2.imread(i)\n    im1 = cv2.resize(im, (224,224))\n    test_otherclasses.append(im1)","9cdeb365":"train_df.info()\ntest_df.info()\nval_df.info()","f7e91ed2":"train_label = train_df.pop('Class')\ntest_label = test_df.pop('Class')\nval_label = val_df.pop('Class')","310c06cd":"x_train_2 = np.stack(train_class2)\nx_train_rest = np.stack(train_otherclasses)\nx_val_2 = np.stack(val_class2)\nx_val_rest = np.stack(val_otherclasses)\nx_test_2 = np.stack(test_class2)\nx_test_rest = np.stack(test_otherclasses)","a0ac359a":"x_train_2.shape","b27055b8":"x_train_rest.shape","671d3aae":"x_val_2.shape","4762d75f":"x_val_rest.shape","8d32c1e4":"x_test_2.shape","3395a50c":"x_test_rest.shape","f4662b28":"train_label_2 =[]\ntrain_label_rest = []\nfor i in train_label:\n    if i == 2:\n        train_label_2.append(i)\n    else:\n        train_label_rest.append(i)","0dd7ac8f":"val_label_2 =[]\nval_label_rest = []\nfor i in val_label:\n    if i == 2:\n        val_label_2.append(i)\n    else:\n        val_label_rest.append(i)","a5f465d4":"test_label_2 =[]\ntest_label_rest = []\nfor i in test_label:\n    if i == 2:\n        test_label_2.append(i)\n    else:\n        test_label_rest.append(i)","fce57533":"from tensorflow.keras.utils import to_categorical\n\ny_train_2=to_categorical(train_label_2)\ny_train_rest=to_categorical(train_label_rest)\n\ny_train_2.shape,y_train_rest.shape","a85d6659":"y_val_2=to_categorical(val_label_2)\ny_val_rest=to_categorical(val_label_rest)\n\ny_val_2.shape, y_val_rest.shape","23876061":"y_test_2=to_categorical(test_label_2)\ny_test_rest=to_categorical(test_label_rest)\n\ny_test_2.shape, y_test_rest.shape","3f1fa732":"from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D,BatchNormalization,Dropout,Conv2D,MaxPool2D\nfrom keras.applications import ResNet50\n# Define model with different applications\nmodel = Sequential()\n\nmodel.add(ResNet50(include_top=False,input_tensor=None,input_shape=(224,224,3),weights='imagenet'))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(4, activation='softmax'))\n\nmodel.layers[0].trainable = False\nmodel.summary()","25f21928":"# Compile the model\n\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-3), metrics=['acc'])\n# Train the model\n#history = model.fit_generator(balanced_gen, steps_per_epoch, epochs=10, verbose=1, validation_data=balanced_val)\nhistory = model.fit(x_train_2, y_train_2, batch_size=32, epochs=10, verbose=1, validation_data=(x_val_2, y_val_2))","03056acc":"history = model.fit(x_train_rest, y_train_rest, batch_size=16, epochs=10, verbose=1, validation_data=(x_val_rest, y_val_rest))","846b27e0":"y_pred = model.predict(x_test)","b832afbc":"from sklearn.metrics import confusion_matrix\nimport numpy as np\n\ny_pred_labels = np.argmax(y_pred, axis=1)\ncm = confusion_matrix(test_label, y_pred_labels)","a9b9e574":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax=plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","43b2ce0c":"def show_plots(history, plot_title=None, fig_size=None):\n    \n    import seaborn as sns\n    \n    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs\n        Works with the history object returned by the train_model(...) call \"\"\"\n    assert type(history) is dict\n\n    # NOTE: the history object should always have loss & acc (for training data), but MAY have\n    # val_loss & val_acc for validation data\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss'] if 'val_loss' in history.keys() else None\n    \n    # accuracy is an optional metric chosen by user\n    # NOTE: in Tensorflow 2.0, the keys are 'accuracy' and 'val_accuracy'!! Why Google?? Why!!??\n    acc_vals = history['acc'] if 'acc' in history.keys() else None\n    if acc_vals is None:\n        # try 'accuracy' key, as used by the Tensorflow 2.0 backend\n        acc_vals = history['accuracy'] if 'accuracy' in history.keys() else None\n        \n    assert acc_vals is not None, \"Something wrong! Cannot read 'acc' or 'accuracy' from history.keys()\"\n        \n    val_acc_vals = history['val_acc'] if 'val_acc' in history.keys() else None\n    if val_acc_vals is None:\n        # try 'val_accuracy' key, could be using Tensorflow 2.0 backend!\n        val_acc_vals = history['val_accuracy'] if 'val_accuracy' in history.keys() else None    \n        \n    assert val_acc_vals is not None, \"Something wrong! Cannot read 'val_acc' ot 'val_acuracy' from history.keys()\"\n        \n    epochs = range(1, len(history['loss']) + 1)\n    \n    col_count = 1 if ((acc_vals is None) and (val_acc_vals is None)) else 2\n    \n    with sns.axes_style(\"darkgrid\"):\n        sns.set_context(\"notebook\", font_scale=1.1)\n        sns.set_style({\"font.sans-serif\": [\"Verdana\", \"Arial\", \"Calibri\", \"DejaVu Sans\"]})\n\n        f, ax = plt.subplots(nrows=1, ncols=col_count, figsize=((16, 5) if fig_size is None else fig_size))\n    \n        # plot losses on ax[0]\n        #ax[0].plot(epochs, loss_vals, color='navy', marker='o', linestyle=' ', label='Training Loss')\n        ax[0].plot(epochs, loss_vals, label='Training Loss')\n        if val_loss_vals is not None:\n            #ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n            ax[0].plot(epochs, val_loss_vals, label='Validation Loss')\n            ax[0].set_title('Training & Validation Loss')\n            ax[0].legend(loc='best')\n        else:\n            ax[0].set_title('Training Loss')\n    \n        ax[0].set_xlabel('Epochs')\n        ax[0].set_ylabel('Loss')\n        ax[0].grid(True)\n    \n        # plot accuracies, if exist\n        if col_count == 2:\n            #acc_vals = history['acc']\n            #val_acc_vals = history['val_acc'] if 'val_acc' in history.keys() else None\n\n            #ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n            ax[1].plot(epochs, acc_vals, label='Training Accuracy')\n            if val_acc_vals is not None:\n                #ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n                ax[1].plot(epochs, val_acc_vals, label='Validation Accuracy')\n                ax[1].set_title('Training & Validation Accuracy')\n                ax[1].legend(loc='best')\n            else:\n                ax[1].set_title('Training Accuracy')\n\n            ax[1].set_xlabel('Epochs')\n            ax[1].set_ylabel('Accuracy')\n            ax[1].grid(True)\n    \n        if plot_title is not None:\n            plt.suptitle(plot_title)\n    \n        plt.show()\n        plt.close()\n\n    # delete locals from heap before exiting (to save some memory!)\n    del loss_vals, epochs, acc_vals\n    if val_loss_vals is not None:\n        del val_loss_vals\n    if val_acc_vals is not None:\n        del val_acc_vals","ecede46f":"show_plots(history.history, \"ResNet50 Model\")\n","b3018b79":"balanced_gen = BalancedDataGenerator(x_train, y_train, train_datagen, batch_size=32)\nsteps_per_epoch = balanced_gen.steps_per_epoch\nbalanced_val = BalancedDataGenerator(x_val, y_val, val_datagen, batch_size=32)","a8e4583f":"**Resnet**","67c7f2e0":"from keras.utils.data_utils import Sequence\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.tensorflow import balanced_batch_generator\n\nclass BalancedDataGenerator(Sequence):\n    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n    def __init__(self, x, y, datagen, batch_size=32):\n        self.datagen = datagen\n        self.batch_size = min(batch_size, x.shape[0])\n        datagen.fit(x)\n        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n        self._shape = (self.steps_per_epoch * batch_size, *x.shape[1:])\n        \n    def __len__(self):\n        return self.steps_per_epoch\n\n    def __getitem__(self, idx):\n        x_batch, y_batch = self.gen.__next__()\n        x_batch = x_batch.reshape(-1, *self._shape[1:])\n        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()"}}