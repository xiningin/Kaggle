{"cell_type":{"c63f183d":"code","08e94d1a":"code","92318b5e":"code","54b57df4":"code","5506712b":"code","0055d910":"code","f2fbd226":"code","7d9d21a1":"code","350beab7":"code","e9046d85":"code","4f7ced41":"code","4420a17b":"code","0191fc59":"code","2db31c5b":"code","3ef4be60":"code","0aa367d5":"code","0839a422":"code","a1b3ab1d":"code","d3ce7c04":"code","096396df":"code","7974686b":"code","204d1d19":"code","d02e9114":"code","77f4e8dd":"code","371b95a2":"code","039d8036":"code","86e64fa6":"code","4d64369c":"code","0efe79dd":"markdown","83726e50":"markdown","2c4683f0":"markdown","7ff07f70":"markdown","0d112a25":"markdown","84c50b58":"markdown","f7e1a82b":"markdown","894685c0":"markdown","89e33bba":"markdown","57171a6f":"markdown","4f1c4226":"markdown","744633fb":"markdown","3ae2b164":"markdown","700e0e47":"markdown","23810d24":"markdown","5cad5a1a":"markdown","06b59f69":"markdown","fc0f0cb7":"markdown","aa33a757":"markdown","c9e9317c":"markdown","e89cb95c":"markdown","b7330939":"markdown","3287c1de":"markdown","bcbcfdff":"markdown"},"source":{"c63f183d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08e94d1a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","92318b5e":"df = pd.read_csv(\"..\/input\/breast-cancer-prediction\/data.csv\")","54b57df4":"df.head()","5506712b":"df.shape","0055d910":"print(\"\\nNull Values:\\n\", df.isnull().sum())","f2fbd226":"print(\"\\nMissing Values:\\n\", df.isna().sum())","7d9d21a1":"df.info()","350beab7":"df.describe()","e9046d85":"df_mean = df[df.columns[:11]]\ndf_se = df.drop(df.columns[1:11], axis=1);\ndf_se = df_se.drop(df_se.columns[11:], axis=1)\ndf_worst = df.drop(df.columns[1:21], axis=1)\n","4f7ced41":"df.diagnosis.value_counts()","4420a17b":"df.diagnosis.value_counts() \\\n    .plot(kind=\"bar\", width=0.1, color=[\"lightgreen\", \"cornflowerblue\"], legend=1, figsize=(8, 5))\nplt.xlabel(\"(0 = Benign) (1 = Malignant)\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.xticks(fontsize=12);\nplt.yticks(fontsize=12)\nplt.legend([\"Benign\"], fontsize=12)\nplt.show()","0191fc59":"def corrwithdia(dfx):\n    import matplotlib.pyplot as plt\n    name = str([x for x in globals() if globals()[x] is dfx][0])\n    if name == 'df':\n        x = \"All\"\n    elif name == 'df_mean':\n        x = \"Mean\"\n    elif name == 'df_se':\n        x = \"Squared Error\"\n    elif name == 'df_worst':\n        x = \"Worst\"\n    plt.figure(figsize=(20, 8))\n    dfx.drop('diagnosis', axis=1).corrwith(dfx.diagnosis).plot(kind='bar', grid=True, title=\"Correlation of {} Features with Diagnosis\".format(x), color=\"cornflowerblue\");","2db31c5b":"corrwithdia(df_mean)","3ef4be60":"corrwithdia(df_se)","0aa367d5":"corrwithdia(df_worst)","0839a422":"df_mean_cols = list(df.columns[1:11])\ndf_se_cols = list(df.columns[11:21])\ndf_worst_cols = list(df.columns[21:])","a1b3ab1d":"dfM = df[df['diagnosis'] == 1]\ndfB = df[df['diagnosis'] == 0]","d3ce7c04":"plt.rcParams.update({'font.size': 8})\nfig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))\naxes = axes.ravel()\nfor idx, ax in enumerate(axes):\n    ax.figure\n    binwidth = (max(df[df_mean_cols[idx]]) - min(df[df_mean_cols[idx]])) \/ 50\n    ax.hist([dfM[df_mean_cols[idx]], dfB[df_mean_cols[idx]]],\n            bins=np.arange(min(df[df_mean_cols[idx]]), max(df[df_mean_cols[idx]]) + binwidth, binwidth), alpha=0.5,\n            stacked=True, label=['M', 'B'], color=['b', 'g'])\n    ax.legend(loc='upper right')\n    ax.set_title(df_mean_cols[idx])\nplt.tight_layout()\nplt.show()","096396df":"plt.rcParams.update({'font.size': 8})\nfig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))\naxes = axes.ravel()\nfor idx, ax in enumerate(axes):\n    ax.figure\n    binwidth = (max(df[df_se_cols[idx]]) - min(df[df_se_cols[idx]])) \/ 50\n    ax.hist([dfM[df_se_cols[idx]], dfB[df_se_cols[idx]]],\n            bins=np.arange(min(df[df_se_cols[idx]]), max(df[df_se_cols[idx]]) + binwidth, binwidth), alpha=0.5,\n            stacked=True, label=['M', 'B'], color=['b', 'g'])\n    ax.legend(loc='upper right')\n    ax.set_title(df_se_cols[idx])\nplt.tight_layout()\nplt.show()","7974686b":"plt.rcParams.update({'font.size': 8})\nfig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))\naxes = axes.ravel()\nfor idx, ax in enumerate(axes):\n    ax.figure\n    binwidth = (max(df[df_worst_cols[idx]]) - min(df[df_worst_cols[idx]])) \/ 50\n    ax.hist([dfM[df_worst_cols[idx]], dfB[df_worst_cols[idx]]],\n            bins=np.arange(min(df[df_worst_cols[idx]]), max(df[df_worst_cols[idx]]) + binwidth, binwidth), alpha=0.5,\n            stacked=True, label=['M', 'B'], color=['b', 'g'])\n    ax.legend(loc='upper right')\n    ax.set_title(df_worst_cols[idx])\nplt.tight_layout()\nplt.show()","204d1d19":"def pairplot(dfx):\n    import seaborn as sns\n    name = str([x for x in globals() if globals()[x] is dfx][0])\n    if name == 'df_mean':\n        x = \"Mean\"\n    elif name == 'df_se':\n        x = \"Squared Error\"\n    elif name == 'df_worst':\n        x = \"Worst\"\n    sns.pairplot(data=dfx, hue='diagnosis', palette='crest', corner=True).fig.suptitle('Pairplot for {} Featrues'.format(x), fontsize = 20)","d02e9114":"pairplot(df_mean)","77f4e8dd":"pairplot(df_se)","371b95a2":"pairplot(df_worst)","039d8036":"corr_matrix = df.corr()  # Correlation Matrix\n\n# Mask for Heatmap\nmask = np.zeros_like(corr_matrix, dtype=np.bool)\nmask[np.triu_indices_from(corr_matrix)] = True\n\n# Correlation Matrix Heatmap including all features\nfig, ax = plt.subplots(figsize=(22, 10))\nax = sns.heatmap(corr_matrix, mask=mask, annot=True, linewidths=0.5, fmt=\".2f\", cmap=\"YlGn\");\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5);\nax.set_title(\"Correlation Matrix Heatmap including all features\");","86e64fa6":"for column in df:\n    plt.figure()\n    df.boxplot([column])\n    plt.show()","4d64369c":"from numpy import percentile\n# calculate interquartile range\nfor column in df.columns:\n    q25, q75 = percentile(df[column], 25), percentile(df[column], 75)\n    iqr = q75 - q25\n    print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n    # calculate the outlier cutoff\n    cut_off = iqr * 1.5\n    lower, upper = q25 - cut_off, q75 + cut_off\n    # identify outliers\n    outliers = [x for x in df[column] if x < lower or x > upper]\n    print('Identified outliers: %d' % len(outliers))\n    # remove outliers\n    outliers_removed = [x for x in df[column] if x >= lower and x <= upper]\n    print('Non-outlier observations: %d' % len(outliers_removed))\n    df = df[df[column] < upper]\n    plt.figure()\n    df.boxplot([column])\n    plt.show()","0efe79dd":"#### Information of data","83726e50":"#### Nucleus Worst Features vs Diagnosis","2c4683f0":"#### Extracting Mean, Squared Error and Worst Features with Diagnosis\n","7ff07f70":"#### Correlation Heartmap between Nucleus Feature","0d112a25":"#### Checking Missing Values","84c50b58":"#### Correlation of Worst Features with Diagnosis","f7e1a82b":"Mean Features:","894685c0":"#### Split into two Parts Based on Diagnosis","89e33bba":"#### Outliers","57171a6f":"#### Outlier removal","4f1c4226":"#### Nucleus Mean Features vs Diagnosis","744633fb":"#### Nucleus Squared Error Features vs Diagnosis","3ae2b164":"#### Checking Null Values","700e0e47":"#### Checking Multicollinearity Between Different Features","23810d24":"#### Statistical Description of Data","5cad5a1a":"Squared Error Features:","06b59f69":"#### Extracting Mean, Squared Error and Worst Features","fc0f0cb7":"### Correlation with diagnosis:","aa33a757":"Worst features:","c9e9317c":"#### Count Based On Diagnosis\n","e89cb95c":"### Loading Dataset into Pandas DataFrame","b7330939":"#### Correlation of Mean Features with Diagnosis\n","3287c1de":"#### Correlation of Squared Error Features with Diagnosis\n","bcbcfdff":"### Importing Necessary libraries"}}