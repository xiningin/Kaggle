{"cell_type":{"48331a86":"code","b4cc37e1":"code","7fb46ca1":"code","f657d183":"code","8e6c49e0":"code","67c43744":"code","84ea0f3d":"code","6fecedb2":"code","d6eaaa56":"code","80209075":"code","5c8f9799":"code","39040ccd":"code","673d7be2":"code","70bef5d1":"code","3cf5e7e3":"code","0fcbbca6":"code","aa7110f2":"code","402922aa":"code","ca8eed31":"code","0f5203fd":"code","f30d2472":"code","78bbcf67":"code","b0566b6c":"code","2a0825e0":"code","0f4d410d":"code","29668370":"code","4614db0b":"code","dfb01778":"code","c9573d3e":"code","3f799dc5":"code","050b5862":"code","395a5622":"code","b3b09890":"markdown","c196451f":"markdown","f23c4836":"markdown","d46ebe0f":"markdown","ac4145c4":"markdown","b10113ac":"markdown","51fba3e6":"markdown","b71b336e":"markdown","d6e6611e":"markdown"},"source":{"48331a86":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b4cc37e1":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","7fb46ca1":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nimport math","f657d183":"df = pd.read_csv(\"..\/input\/insurance\/insurance.csv\")","8e6c49e0":"df.head()","67c43744":"df.info()","84ea0f3d":"unique_vals = df['sex'].value_counts()\nprint(unique_vals)","6fecedb2":"df.charges.hist(bins=120)","d6eaaa56":"fig, axes = plt.subplots(1, 2, sharey=True) #We will plot bmi, age\n\nplot_bmi = sns.scatterplot(y = 'charges', x = 'bmi', data=df, ax = axes[0])\nplot_age = sns.scatterplot(y = 'charges', x = 'age', data=df, ax = axes[1])\n\nplt.show()","80209075":"fig, axes = plt.subplots(1,4,sharey=True) #We will plot children, smoker, region, sex; \n\nplot_children = sns.boxplot(y= 'charges', x=\"children\", data=df,  orient='v' , ax=axes[0])\nplot_smoker = sns.boxplot(y= 'charges',x=\"smoker\", data=df,  orient='v' , ax=axes[1])\nplot_region = sns.boxplot(y= 'charges',x=\"region\", data=df,  orient='v' , ax=axes[2])\nplot_sex = sns.boxplot(y= 'charges',x=\"sex\", data=df,  orient='v' , ax=axes[3])\nplot_region.set_xticklabels(labels=df['region'].unique(),rotation = 90)\nplot_sex.set_xticklabels(labels=df['sex'].unique(),rotation = 90)\nfor i in axes[1:4]:\n    i.set_ylabel('')   \n    \nplt.show()","5c8f9799":"#We have to make use of a function to take out sd and mean for each group to make the code DRY  \ndef mean_and_sd(indep_var):\n    val1 = df[indep_var].unique()[0]\n    val2 = df[indep_var].unique()[1]\n    var1 = df[df[indep_var] == val1]['charges']\n    mean1 = round(var1.mean(),2)\n    var2 = df[df[indep_var] == val2]['charges']\n    mean2 = round(var2.mean(),2)\n    print('{} mean - {} mean = {}'.format(val1,val2,mean1 - mean2))\n    #Standard Deviation\n    sd1 = np.std(df[df[indep_var] == val1]['charges'])\n    sd2 = np.std(df[df[indep_var] == val2]['charges'])\n    print('sd of {} is {}, and of {} is {}'.format(val1,round(sd1),val2,round(sd2)))","39040ccd":"mean_and_sd('sex')","673d7be2":"mean_and_sd('smoker')","70bef5d1":"from sklearn.preprocessing import OneHotEncoder\nonehotencoder = OneHotEncoder(categories='auto')\n\nvar1 = onehotencoder.fit_transform(df.region.values.reshape(-1,1)).toarray()\nvar1 = pd.DataFrame(var1)\nvar1.columns = ['region_1', 'region_2', 'region_3', 'region_4']\nvar1 = var1.iloc[:,0:3]\ndf = pd.concat([df, var1], axis=1)\n\n\n\nonehotencoder = OneHotEncoder(categories='auto')\nvar3 = onehotencoder.fit_transform(df.smoker.values.reshape(-1,1)).toarray()\nvar3 = pd.DataFrame(var3)\nvar3.columns = ['smoker_1', 'smoker_2']\nvar3 = var3.iloc[:,0]\ndf = pd.concat([df, var3], axis=1)\ndf = df.drop(columns = ['region','sex','smoker'])","3cf5e7e3":"df.head()","0fcbbca6":"df = df[['age', 'bmi', 'children', 'region_1', 'region_2', 'region_3',\n       'smoker_1', 'charges']]\ndf","aa7110f2":"from sklearn.model_selection import train_test_split\nX = df.iloc[:,0:7]\nY = df.iloc[:,7]\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 5)","402922aa":"print((x_train.shape,x_test.shape,y_train.shape,y_test.shape))","ca8eed31":"y_train = np.array(y_train).reshape(-1, 1)\ny_train = pd.DataFrame(y_train)\ny_test = np.array(y_test).reshape(-1, 1)\ny_test = pd.DataFrame(y_test)","0f5203fd":"print((x_train.shape,x_test.shape,y_train.shape,y_test.shape))","f30d2472":"from sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(x_train, y_train)\nlr_pred = reg.predict(x_test)\nprint(reg.coef_)","78bbcf67":"from sklearn.metrics import mean_squared_error\nmean_squared_error(lr_pred,y_test)","b0566b6c":"fig, ax = plt.subplots()\nax.plot([0,1],[0,1], transform=ax.transAxes)\n\nplt.scatter(lr_pred, y_test)\nplt.xlabel(\"Predicted Values\")\nplt.ylabel(\"Observed Values\")\n\nplt.show()","2a0825e0":"r2_lr = r2_score(y_test, lr_pred)\nmae_lr = mean_absolute_error(y_test, lr_pred)\nmse_lr = mean_squared_error(y_test, lr_pred)\nprint([r2_lr, mae_lr, mse_lr])","0f4d410d":"from sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(200)\nforest.fit(x_train, y_train)","29668370":"forest_pred = forest.predict(x_test)","4614db0b":"fig, ax = plt.subplots()\nax.plot([0,1],[0,1], transform=ax.transAxes)\n\nplt.scatter(forest_pred, y_test)\nplt.xlabel(\"Predicted Values\")\nplt.ylabel(\"Observed Values\")\n\nplt.show()","dfb01778":"r2_forest = r2_score(y_test, forest_pred)\nmae_forest = mean_absolute_error(y_test, forest_pred)\nmse_forest = mean_squared_error(y_test, forest_pred)\nprint([r2_forest, mae_forest, mse_forest])","c9573d3e":"import xgboost as xgb","3f799dc5":"xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n\nxgb_model.fit(x_train, y_train)\nxgb_pred = xgb_model.predict(x_test)","050b5862":"fig, ax = plt.subplots()\nax.plot([0,1],[0,1], transform=ax.transAxes)\n\nplt.scatter(xgb_pred, y_test)\nplt.xlabel(\"Predicted Values\")\nplt.ylabel(\"Observed Values\")\n\nplt.show()","395a5622":"r2_xgb = r2_score(y_test, xgb_pred)\nmae_xgb = mean_absolute_error(y_test, xgb_pred)\nmse_xgb = mean_squared_error(y_test, xgb_pred)\nprint([r2_xgb, mae_xgb, mse_xgb])","b3b09890":"# Evaluation of Random Forest Regressor","c196451f":"# Random Forest ","f23c4836":"**Unpaired t test results(Smoking-Charges)**\n\n**P value and statistical significance:**\n\n  The two-tailed P value is less than 0.0001\n  By conventional criteria, this difference is considered to be extremely statistically significant.","d46ebe0f":"Observations:\n1. Less number of people get high amount of insurance payouts.\n2. Relatively much higher number receive higher amounts on payouts.","ac4145c4":"# Evaluation of Linear Regression Model","b10113ac":"# Linear Regression","51fba3e6":"**Final Observations**\n1. Linear Regression Model was unable to perform upto respectable standards, and was considerably inferior to other models used.\n2. Random Forest Model performed significantly better, and had the highest R squared score.\n3. XG Boost Model was comparable to Random Forest Model and may be better at generalising the data.","b71b336e":"**Unpaired t test results(Gender-Charges)**\n\nP value and statistical significance:\n  The two-tailed P value equals 0.0030\n  By conventional criteria, this difference is considered to be very statistically significant.","d6e6611e":"# Evaluation of XG Boost"}}