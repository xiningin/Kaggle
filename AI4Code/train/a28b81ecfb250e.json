{"cell_type":{"d9846cab":"code","fa1a658d":"code","c2ea7b54":"code","379e3548":"code","2133443b":"code","7d30fd68":"code","b7a05654":"code","54905e56":"code","4c4cd31a":"code","2200c76c":"code","e678dcb5":"code","f7fe5baa":"code","fa033170":"code","7263a16a":"code","b01dbc7c":"code","6bbbe0e0":"code","0b7eca3b":"code","d94095c1":"markdown","addde290":"markdown","9226f22e":"markdown","d3803d8e":"markdown","5eccd97c":"markdown","ff41960c":"markdown","df1ff6ac":"markdown"},"source":{"d9846cab":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport pymc3 as pm\nimport theano.tensor as tt\n\nfrom scipy.stats import skew\n\nfrom sklearn.linear_model import Lasso, Ridge\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\n\nfrom priors_penalties_functions import BayesianGLM\nfrom priors_penalties_functions import plot_errors_and_coef_magnitudes, cross_validate_hyperparam_choices\n\nimport os\nprint(os.listdir(\"..\/input\"))","fa1a658d":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")","c2ea7b54":"train.head()","379e3548":"all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n                      test.loc[:,'MSSubClass':'SaleCondition']))\n\n#log transform the target:\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#log transform skewed numeric features:\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n\n# Create dummy variables\nall_data = pd.get_dummies(all_data)\n\n# Mean imputation\nall_data = all_data.fillna(all_data.mean())","2133443b":"X_train = all_data[:train.shape[0]]\nX_test = all_data[train.shape[0]:]\ny = train.SalePrice","7d30fd68":"selector = SelectKBest(f_regression, k=5)\nselector.fit(X_train, y)\n\nscaler = StandardScaler()\nscaler.fit(X_train, y)\n\ncolumns = X_train.columns[selector.get_support()]\n\nX_train = pd.DataFrame(selector.transform(scaler.transform(X_train)), columns=columns)\nX_test = pd.DataFrame(selector.transform(scaler.transform(X_test)), columns=columns)\n\nX_train.head()","b7a05654":"cv_splitter = KFold(5)","54905e56":"alphas = np.logspace(0, 6, num=20)\nalphas","4c4cd31a":"results_l2 = cross_validate_hyperparam_choices(alphas, X_train, y, cv_splitter, Ridge)\nresults_l2","2200c76c":"plot_errors_and_coef_magnitudes(results_l2, \"Effect of L2 Penalty on Validation Error & Paramter Magnitude\");","e678dcb5":"sigmas = np.sqrt(1 \/ alphas)\nsigmas","f7fe5baa":"results_normal = cross_validate_hyperparam_choices(sigmas, X_train, y, cv_splitter, BayesianGLM, \n                                                   is_bayesian=True, bayesian_prior_fn=pm.Normal)\nresults_normal","fa033170":"plot_errors_and_coef_magnitudes(results_normal, \n                                \"Effect of Prior Variance on Validation Error & Parameter Magnitude\",\n                                hyperparam_name=\"sigma\",\n                                reverse_x=True);","7263a16a":"results_l1 = cross_validate_hyperparam_choices(alphas, X_train, y, cv_splitter, Lasso)\nresults_l1","b01dbc7c":"plot_errors_and_coef_magnitudes(results_l1, \"Effect of L1 Penalty on Validation Error & Parameter Magnitude\");","6bbbe0e0":"results_laplace = cross_validate_hyperparam_choices(sigmas, X_train, y, cv_splitter, BayesianGLM, \n                                                   is_bayesian=True, bayesian_prior_fn=pm.Laplace)\nresults_laplace","0b7eca3b":"plot_errors_and_coef_magnitudes(results_laplace, \n                                \"Effect of Laplace Prior Variance on Validation Error & Parameter Magnitude\",\n                                hyperparam_name=\"sigma\",\n                                reverse_x=True);","d94095c1":"### Bayesian GLM\n\nIn the probabilistic formulation of linear regression, the response variable, $Y$, is treated as a random variable, equal to the weighted sum of the features, $\\beta X$, plus random noise. The noise is typically assumed to be Gaussian, hence the distribution of $Y$ is also Gaussian.\n\nThat is, $Y \\sim \\mathcal{N}(\\beta X, \\sigma^2)$, where $\\sigma^2$ is the variance of the noise term you would find in the standard formulation of linear regression, $Y = \\beta X + \\epsilon, \\epsilon \\sim \\mathcal{N}$, $(0 \\sigma^2)$.\n\nFurthermore, we can specify prior distributions over the parameters $\\beta$. A common choice is the Gaussian distribution. If we center this distribution around 0, this would indicate that we expect the parameters to be small. Choosing small values for the standard deviation of this prior would correspond to a tighter distribution, indicating a stronger initial belief in small parameters - similar to a large penalty in regularized least-squares regression.\n\nPyMC3 has a module dedicated to Bayesian GLMs (https:\/\/docs.pymc.io\/api\/glm.html). However, for some reason they will not sample in the Kaggle kernel environment. I suspect it has to do with some Theano backend operation, as my first attempt to make a function from scratch that involved dot products had similar behavior. In any case, I have made my own GLM class due to the problems the library function has in this programming environment. I've modeled it after the scikit-learn API so that I can use it in my cross-validation loop.","addde290":"# Empirically Investigating the Relationship Between Bayesian Priors and Regularization Penalty Terms\n\nIntroductions to Bayesian methods often remark that regularizing linear regression with an L2 penalty is equivalent to having a Gaussian prior over the distribution of coefficient terms in a linear model. In this notebook, I would like to explore this empirically, by comparing the cross-validated performance of both a MLE and a Bayesian formulation of linear regression. I will verify that an L2 penalty term corresponds to a Gaussian prior, that an L1 penalty corresponds to a Laplacean prior, and will examine the relationship between the tuning parameter values of the penalties and the dispersions of the prior distributions.","9226f22e":"### Preprocessing\n\nI will follow the methodology in https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models. That is, taking the log of skewed features, creating dummy variables for categorical features, and performing mean imputation.\n\nAfter these steps, I will choose just 5 features to work with in order to reduce the feature space to something that is feasible to sample with MCMC. Note that because of this step, predictions made by models will not do very well on the leaderboard (they are relatively simple models to begin with, being variants of simple linear regression). That is okay, because the purpose of this notebook is to explore an equivalence between two formulations of linear regression.","d3803d8e":"## Laplace Prior","5eccd97c":"## L1 Penalty (Lasso)","ff41960c":"## L2 Penalty (Ridge Regression)","df1ff6ac":"## Import\/Preprocess Data"}}