{"cell_type":{"530739b6":"code","d71cac01":"code","c6d7fc31":"code","418980e7":"code","8f5e4325":"code","02b6ccd3":"code","4401f86e":"code","f3713d59":"code","c14a30ad":"code","7875d933":"code","c32dedcb":"code","f7ca44f6":"code","bdc94f68":"code","48a4504b":"code","7d71b8b4":"code","757bfd5c":"code","2639634d":"code","37a6bd21":"code","c77ccf21":"code","af6cfba0":"code","9240155f":"code","d4c10d9d":"code","f090fa8f":"code","51293f0d":"code","06537fe0":"code","691e0106":"code","f356c65d":"code","fe26677c":"code","438f0fb9":"code","223d8f10":"code","72e0fa0b":"code","e7ab3bed":"code","80438d03":"code","c3395ac4":"code","0486479e":"code","85b744da":"code","1913cf20":"code","55bfd01e":"code","fefe2d7f":"code","f1519ddd":"code","e61c36c3":"code","ae48f3ed":"code","ab6c80ed":"code","54d962b7":"markdown","9854be4e":"markdown","e4cb1895":"markdown","ae727633":"markdown","b6caa3f0":"markdown","40141327":"markdown","520e8b40":"markdown","4e45387d":"markdown","fb41b44a":"markdown","6bb5e0ca":"markdown","87920051":"markdown","1c0c3749":"markdown","43d6ad60":"markdown","d2982eea":"markdown","a39115ff":"markdown","b2c76ccf":"markdown","7cb68af5":"markdown","5a376fd4":"markdown","e5574c58":"markdown","cd4b05ed":"markdown","5027e85a":"markdown","e56e80df":"markdown","27ab69b8":"markdown","8e073a2f":"markdown","fb532456":"markdown"},"source":{"530739b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d71cac01":"data = pd.read_csv(\"\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\")","c6d7fc31":"data.head()","418980e7":"data['status'] = data['status'].map({'Placed': 1, 'Not Placed': 0})\ndata.groupby(\"status\").count()","8f5e4325":"X = data.drop([\"sl_no\",\"status\",\"salary\"],axis=1)\ny= data[\"status\"]","02b6ccd3":"X.head(3),y.head(3)","4401f86e":"X_dummy = pd.get_dummies(X)\nX_dummy.head()","f3713d59":"from sklearn.model_selection import train_test_split\nnp.random.seed(42)\nX_train,X_test, y_train, y_test = train_test_split(X_dummy,y,test_size=0.2)","c14a30ad":"from sklearn.ensemble import RandomForestClassifier\nnp.random.seed(42)\nclf = RandomForestClassifier()\nclf.fit(X_train,y_train)\nclf.score(X_test,y_test)","7875d933":"y_pred = clf.predict(X_test)\ny_pred[:5]","c32dedcb":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","f7ca44f6":"clf.predict_proba(X_test[:5])","bdc94f68":"from sklearn.model_selection import cross_val_score\nnp.random.seed(42)\ncross_val_score(clf,X_dummy,y,cv=6)","48a4504b":"np.random.seed(42)\nclf_single_score = clf.score(X_test,y_test)\nclf_crossval_score = np.mean(cross_val_score(clf,X_dummy,y,cv=6))\npd.DataFrame([{\"Classification Single Score\":clf_single_score,\"Cross Validation Score\":clf_crossval_score}])","7d71b8b4":"from sklearn.metrics import roc_curve\ny_prob = clf.predict_proba(X_test)\ny_positive = y_prob[:,1]\n\n#Calculate false positive rate, true positive rate and thresholds\nfpr,tpr,thresholds = roc_curve(y_test,y_positive)\nfpr","757bfd5c":"import matplotlib.pyplot as plt\ndef plot_roc(fpr,tpr):\n    plt.plot(fpr,tpr,color='orange',label='ROC')\n    plt.plot([0,1],[0,1],color='darkblue',linestyle='--',label=\"Guessing\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"Receiver Operating Characteristics Curve (ROC)\")\n    plt.legend()\n    plt.show()\n    \nplot_roc(fpr,tpr)","2639634d":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_positive)","37a6bd21":"from sklearn.metrics import confusion_matrix\ny_pred = clf.predict(X_test)\nconfusion_matrix(y_test,y_pred)","c77ccf21":"pd.crosstab(y_test,y_pred,\n           rownames=[\"Actual Label\"],\n           colnames=[\"Predicted Label\"])","af6cfba0":"import seaborn as sns\nsns.set(font_scale=1.5)\nconf_mat = confusion_matrix(y_test,y_pred)\nsns.heatmap(conf_mat);","9240155f":"def plot_conf_mat(conf_mat):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3, 3))\n    ax = sns.heatmap(conf_mat,\n                     annot=True, # Annotate the boxes \n                     cbar=False)\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label');\n\nplot_conf_mat(conf_mat)","d4c10d9d":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(clf, X_dummy, y)","f090fa8f":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","51293f0d":"np.random.seed(42)\n#Default- Mean Accuracy\ncv_acc = cross_val_score(clf,X_dummy,y,cv=5)\n#Cross Validated Score\nprint(f\"The Cross Validated Accuracy : {np.mean(cv_acc)*100:.2f}%\")","06537fe0":"np.random.seed(42)\n#Accuracy Param\ncv_acc = cross_val_score(clf,X_dummy,y,cv=5,scoring=\"accuracy\")\n#Cross Validated Score\nprint(f\"The Cross Validated Accuracy : {np.mean(cv_acc)*100:.2f}%\")","691e0106":"np.random.seed(42)\n#Precision Param\ncv_acc = cross_val_score(clf,X_dummy,y,cv=5,scoring=\"precision\")\nprint(f\"The Cross Validated Precision : {np.mean(cv_acc)*100:.2f}%\")","f356c65d":"np.random.seed(42)\n#Recall Param\ncv_acc = cross_val_score(clf,X_dummy,y,cv=5,scoring=\"recall\")\nprint(f\"The Cross Validated Recall : {np.mean(cv_acc)*100:.2f}%\")","fe26677c":"np.random.seed(42)\n#F1 Param\ncv_acc = cross_val_score(clf,X_dummy,y,cv=5,scoring=\"f1\")\nprint(f\"The Cross Validated F1 score : {np.mean(cv_acc)*100:.2f}%\")","438f0fb9":"def classification_metrics(y_test,y_pred):\n    from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n    print(\"Classification Metrics: \")\n    print(f\"Accuracy: {accuracy_score(y_test,y_pred)*100 :.2f}%\")\n    print(f\"Precision: {precision_score(y_test,y_pred)*100 :.2f}%\")\n    print(f\"Recall: {recall_score(y_test,y_pred)*100 :.2f}%\")\n    print(f\"F1: {f1_score(y_test,y_pred)*100 :.2f}%\")\n    metric_dict = {\"accuracy\": round(accuracy_score(y_test,y_pred), 2),\n                   \"precision\": round(precision_score(y_test,y_pred), 2), \n                   \"recall\": round(recall_score(y_test,y_pred), 2),\n                   \"f1\": round(f1_score(y_test,y_pred), 2)}\n    return metric_dict\nbase_metrics = classification_metrics(y_test,y_pred)","223d8f10":"clf.get_params()","72e0fa0b":"grid = {\"n_estimators\":[10,100,500,1000,1500,2000],\n       \"max_depth\":[None,5,10,20,30],\n       \"max_features\":[\"auto\",\"sqrt\"],\n       \"min_samples_split\":[2,4,6],\n       \"min_samples_leaf\":[1,2,4]}","e7ab3bed":"np.random.seed(42)\nclf= RandomForestClassifier(n_jobs=1)\nfrom sklearn.model_selection import RandomizedSearchCV\nrs_clf = RandomizedSearchCV(estimator=clf,\n                   param_distributions=grid,\n                   n_iter=100, #Increasing too 100 from 20\n                   cv=5,\n                   verbose=2)\nrs_clf.fit(X_train,y_train)","80438d03":"rs_clf.best_params_","c3395ac4":"rs_y_preds = rs_clf.predict(X_test)\nrs_metrics = classification_metrics(y_test,rs_y_preds)","0486479e":"grid_2 = {'n_estimators':[2000,2500,3000],\n         'max_depth':[10],\n         'max_features':['auto','sqrt'],\n         'min_samples_split':[2,4],\n         'min_samples_leaf':[2]}","85b744da":"pd.DataFrame([grid,grid_2],index=['Grid1','Grid2'])","1913cf20":"from sklearn.model_selection import GridSearchCV\nnp.random.seed(42)\n\ngs_clf = GridSearchCV(estimator=clf,\n                     param_grid=grid_2,\n                     cv=5,\n                     verbose=2)\n\ngs_clf.fit(X_train,y_train);","55bfd01e":"gs_clf.best_params_","fefe2d7f":"gs_y_preds = gs_clf.predict(X_test)\ngs_metrics= classification_metrics(y_test,gs_y_preds)","f1519ddd":"compare_metrics = pd.DataFrame({\"baseline\": base_metrics,\n                                \"random search\": rs_metrics,\n                                \"grid search\": gs_metrics})\ncompare_metrics.plot.bar(figsize=(10, 8))","e61c36c3":"import pickle\n\n# Save an existing model to file\npickle.dump(gs_clf, open(\"gs_random_forest_model_1.pkl\", \"wb\"))","ae48f3ed":"# Load a saved model\nloaded_pickle_model = pickle.load(open(\"gs_random_forest_model_1.pkl\", \"rb\"))","ab6c80ed":"# Make predictions and evaluate the loaded model\npickle_y_preds = loaded_pickle_model.predict(X_test)\nclassification_metrics(y_test, pickle_y_preds)","54d962b7":"### Train and Test Data Split","9854be4e":"#### Visualizing Confusion Matrix","e4cb1895":"### Confusion Matrix","ae727633":"### Classification Report\n* Precision - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n* Recall - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n* F1 score - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n* Support - The number of samples each metric was calculated on.\n* Accuracy - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n* Macro avg - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into effect. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n* Weighted avg - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples).","b6caa3f0":"### Using Model to produce predictions","40141327":"# Improving model predictions through Experimentation (Hyperparameter Tuning)","520e8b40":"### Splitting Between X and y","4e45387d":"### Hyperparameter tuning using `GridSearchCV`","fb41b44a":"# Evaluation of Model","6bb5e0ca":"### Model Fitting","87920051":"#### Accuracy Score","1c0c3749":"### Area under Receiver Operating Characteristic Curve (ROC)","43d6ad60":"### Hyperparameter tuning using `RandomizedSearchCV`","d2982eea":"# Saving and Loading Model for later use","a39115ff":"### Scoring Metrics","b2c76ccf":"#### Cross Validation Score","7cb68af5":"# Getting the data ready","5a376fd4":"#### ROC Score","e5574c58":"# Choosing the right maching learning estimator\/aglorithm\/model \nand Fitting  chosen machine learning model to data and using it to make a prediction","cd4b05ed":"#### Converting Categorical Data to Numerical","5027e85a":"### Loading DataSet","e56e80df":"### Using Scoring Parameter","27ab69b8":"#### Prediction Probability","8e073a2f":"#### Single Score vs Cross Validation Score","fb532456":"### Classification Functions"}}