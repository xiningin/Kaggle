{"cell_type":{"17f57730":"code","86a1fc50":"code","01c4b769":"code","ff49c0bd":"code","a82f3ec2":"code","0305c993":"code","c7d3de41":"code","3a07ac5b":"code","51f25b0a":"code","33476611":"code","2784934a":"code","feaff4d2":"code","ee33f8cf":"code","9be37afa":"code","00fbe7d1":"code","3381af5c":"code","1d121de6":"code","c192e3b5":"code","692ca517":"code","cfecab40":"code","ca09abbd":"code","3ffcd392":"code","ba1668ea":"code","5dfe5ad3":"code","44b5470e":"code","3e010dad":"code","57bdd889":"code","d38f3463":"code","924c3fb8":"code","3cd1cd9e":"code","ea8c589b":"code","9e479747":"code","e15914e4":"code","02be832a":"code","6a3b86b2":"code","ddc64bb6":"code","f5477061":"code","b1be757f":"code","df6b731d":"code","a1ee370b":"code","9628697a":"code","d9abc3a6":"code","7c97ad95":"code","823087a1":"code","4ef1742a":"code","414a489b":"code","532fe177":"code","8eb7aa30":"code","b5829f7c":"code","c5a22d22":"code","16fa487c":"code","7112292c":"code","3b703fec":"code","953cf95e":"code","75529914":"code","0b63727b":"code","98a269ff":"code","678d458c":"code","3d096588":"code","7f9e3f58":"code","890efb05":"code","1c087739":"code","9cc04a00":"code","e92e2a4c":"code","cf52ac0d":"code","bd66cd20":"code","35f1a997":"code","fbd3fb7f":"code","4e706e7c":"code","86b4673c":"markdown","1af20ec1":"markdown","e2683c27":"markdown","b578efda":"markdown","41d1fdb6":"markdown","be9a1fda":"markdown","635eea82":"markdown","35114484":"markdown","947acdf8":"markdown","8158d4bb":"markdown","566ac673":"markdown","a50ec32f":"markdown","ef6cc789":"markdown","36002951":"markdown","ff26c261":"markdown","9e19b3aa":"markdown","e402a837":"markdown","4feb202a":"markdown","fd9740a2":"markdown","2bd0ff11":"markdown","8374910f":"markdown","ed4a3c14":"markdown","b54bbd73":"markdown","1a8ee765":"markdown"},"source":{"17f57730":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","86a1fc50":"from plotly.offline import iplot\nimport plotly as py","01c4b769":"import cufflinks as cf","ff49c0bd":"py.offline.init_notebook_mode(connected=True)\ncf.go_offline()","a82f3ec2":"df = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')","0305c993":"df.head()","c7d3de41":"df.drop(labels=['Title','Clothing ID'], axis=1,inplace=True)","3a07ac5b":"df.head()","51f25b0a":"df.isnull().sum()","33476611":"df.dropna(subset=['Review Text','Division Name'], inplace=True)","2784934a":"df.isnull().sum()","feaff4d2":"df.head()","ee33f8cf":"contractions = contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"I'd\": \"I would\",\n\"I'd've\": \"I would have\",\n\"I'll\": \"I will\",\n\"I'll've\": \"I will have\",\n\"I'm\": \"I am\",\n\"I've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as \/ so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what'll've\": \"what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"when's\": \"when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who will\",\n\"who'll've\": \"who will have\",\n\"who's\": \"who is\",\n\"who've\": \"who have\",\n\"why's\": \"why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you will\",\n\"you'll've\": \"you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}","9be37afa":"def cont_to_exp(x):\n    if type(x) is str:\n        x = x.replace('\\\\','')\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key,value)\n        return x\n    else:\n        return x\n        ","00fbe7d1":"df['Review Text']","3381af5c":"from textblob import TextBlob","1d121de6":"df['Polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)","c192e3b5":"df['review_len'] = df['Review Text'].apply(lambda x: len(x))","692ca517":"df['word_count'] = df['Review Text'].apply(lambda x: len(x.split()))","cfecab40":"## create function for finding average length of words per row\n\ndef get_avg_word_len(x):\n    words = x.split()\n    word_len = 0\n    for word in words:\n        word_len = word_len + len(word)\n        \n    return word_len \/ len(words)","ca09abbd":"df['avg_word_len'] = df['Review Text'].apply(lambda x: get_avg_word_len(x))","3ffcd392":"df.head()","ba1668ea":"df['Polarity'].iplot(kind = \"hist\", colors = 'red', bins = 50,\n                     xTitle = 'Polarity', yTitle = 'Count', title = 'Sentiment Polarity Distribution')","5dfe5ad3":"df['Rating'].iplot(kind = 'hist' , xTitle = 'Rating' , yTitle = 'Count' ,\n                  title = 'Review Rating Distribution')","44b5470e":"df['Age'].iplot(kind = 'hist' , bins = 40 , xTitle = 'Age' , yTitle = 'Count' ,\n               title = 'Reviewers Age Distribution' , colors = 'yellow' , linecolor = 'black')","3e010dad":"df['review_len'].iplot(kind = 'hist' , xTitle = 'Review Length' , yTitle = 'Count' ,\n                      title = 'Review Text Length Distribution' , colors = 'red' ,\n                      linecolor = 'black')","57bdd889":"df['word_count'].iplot(kind = 'hist' , xTitle = 'Number of Words' , yTitle = 'Count' ,\n                      title = 'Word Count Distribution' , linecolor = 'black')","d38f3463":"\n\ndf['avg_word_len'].iplot(kind = 'hist' , xTitle = 'Average' , yTitle = 'Count' ,\n                        title = 'Review Text Average Word Length')","924c3fb8":"df.groupby('Department Name')","3cd1cd9e":"##  We are using inbuilt function value_counts() for finding total values for each group\n\ndf['Department Name'].value_counts()","ea8c589b":"df['Department Name'].value_counts().iplot(kind = 'bar' , xTitle = 'Department' , yTitle = 'Count' ,\n                                          title = \"Bar Chart of Department's Name\")","9e479747":"df['Division Name'].value_counts().iplot(kind = 'bar' , xTitle = 'Division' , yTitle = 'Count' ,\n                                         title = \"Bar Chart of Division's Name\")","e15914e4":"df['Class Name'].value_counts().iplot(kind = 'bar' , xTitle = 'Class' , yTitle = 'Count' ,\n                                     title = \"Bar Chart of Classe's Name\")","02be832a":"from sklearn.feature_extraction.text import CountVectorizer","6a3b86b2":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer().fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","ddc64bb6":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(1, 1) , stop_words = 'english').fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","f5477061":"review_freq = get_top_n_words(df['Review Text'], 20)","b1be757f":"review_freq","df6b731d":"# converting review_freq into **dataframe** for visualization\n\ndf1 = pd.DataFrame(review_freq, columns = ['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1.iplot(kind = 'bar' , xTitle = 'Unigram' , yTitle = 'Count', title = 'Top 20 Unigram Words')","a1ee370b":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(2, 2) , stop_words = 'english').fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","9628697a":"review_freq = get_top_n_words(df['Review Text'], 20)","d9abc3a6":"review_freq","7c97ad95":"# converting review_freq into **dataframe** for visualization\n\ndf1 = pd.DataFrame(review_freq, columns = ['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1.iplot(kind = 'bar' , xTitle = 'Bigram' , yTitle = 'Count', title = 'Top 20 Bigram Words' ,\n         color = 'lightgreen')","823087a1":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(3, 3) , stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","4ef1742a":"review_freq = get_top_n_words(df['Review Text'], 20)","414a489b":"review_freq","532fe177":"# converting review_freq into **dataframe** for visualization\n\ndf1 = pd.DataFrame(review_freq, columns = ['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1.iplot(kind = 'bar' , xTitle = 'Trigram' , yTitle = 'Count', title = 'Top 20 Trigram Words',\n         color = 'lightviolet')","8eb7aa30":"import nltk","b5829f7c":"nltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","c5a22d22":"## Use **TextBlob** package fot solving tasks such as 'parts of speech tagging', 'noun phrase extraction' ,'sentiment analysis',etc\n\nblob = TextBlob(str(df['Review Text']))","16fa487c":"blob","7112292c":"nltk.download('tagsets')","3b703fec":"## This statement is used to provide all tags with their abbrevation\n\nnltk.help.upenn_tagset()","953cf95e":"blob.tags","75529914":"## Convert blob variable into DataFrame \n## POS - Parts of Speech\n\npos_df = pd.DataFrame(blob.tags , columns = ['Words' , 'POS'])\npos_df","0b63727b":"## We are calculating total number of occurence of each parts os speech (POS)\n\npos_df = pos_df['POS'].value_counts()\npos_df","98a269ff":"## Plotting pos_df value_counts\n\npos_df.iplot(kind = 'bar')","678d458c":"df.head(2)","3d096588":"## We can have clear idea of all numerical datas with each columns\n\nsns.pairplot(df)","7f9e3f58":"sns.catplot(x = 'Division Name' , y = 'Polarity' , data = df)","890efb05":"import plotly.express as px\nimport plotly.graph_objects as go","1c087739":"x1 = df[df['Recommended IND'] == 1]['Polarity']\nx0 = df[df['Recommended IND'] == 0]['Polarity']\nx1,x0","9cc04a00":"trace0 = go.Histogram(x = x0 , name = 'Not Recommended' , opacity = 0.7)\ntrace1 = go.Histogram(x = x1 , name = 'Recommended' , opacity = 0.7)","e92e2a4c":"data = [trace0 , trace1]\nlayout = go.Layout(barmode = 'overlay' , title = 'Distribution of Sentiment Polarity of Reviews Based on the Recommendation')\nfig = go.Figure(data = data , layout = layout)\n\niplot(fig)","cf52ac0d":"x1 = df[df['Recommended IND'] == 1]['Rating']\nx0 = df[df['Recommended IND'] == 0]['Rating']\nx1,x0","bd66cd20":"trace0 = go.Histogram(x = x0 , name = 'Not Recommended' , opacity = 0.7)\ntrace1 = go.Histogram(x = x1 , name = 'Recommended' , opacity = 0.7)","35f1a997":"data = [trace0 , trace1]\nlayout = go.Layout(barmode = 'overlay' , title = 'Distribution of Reviews Rating Based on the Recommendation')\nfig = go.Figure(data = data , layout = layout)\n\niplot(fig)","fbd3fb7f":"sns.jointplot(x = 'Polarity' , y = 'review_len' , data = df , kind = 'kde' , color = 'blue')","4e706e7c":"sns.jointplot(x = 'Polarity' , y = 'Age' , data = df , kind = 'kde' , color = 'blue')","86b4673c":"# Distribution of Unigram, Bigram and Trigram","1af20ec1":"# Text Cleaning","e2683c27":"Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n    \nAge: Positive Integer variable of the reviewers age.\n\nTitle: String variable for the title of the review.\n\nReview Text: String variable for the review body.\n\nRating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n\nRecommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n\nPositive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n\nDivision Name: Categorical name of the product high level division.\n\nDepartment Name: Categorical name of the product department name.\n\nClass Name: Categorical name of the product class name.","b578efda":"From above plot the **Polarity** is around **0.25** with **review-length** as **500**","41d1fdb6":"From the above Plot we could clearly see that **customers who recommend the product also gives negative review and vice versa**","be9a1fda":"# Trigram analysis without Stopword","635eea82":"We are going to select table where there is **Recommended IND =1** for recommending the product to others and **Recommended IND =0** for not recommending the product","35114484":"We are going to select table where there is **Recommended IND =1** for recommending the product to others and **Recommended IND =0** for not recommending the product","947acdf8":"# Distribution of Review Text Length and Word Length","8158d4bb":"# Feature Engineering\n- In this process we will be calculating the features before visualization","566ac673":"## Unigram analysis without Stopword","a50ec32f":"##  Bigram analysis without Stopword","ef6cc789":"## Distribution of Ratings Based on the Recommendation","36002951":"From the above Plot we could clearly see that **Rating with 5-stars full 100% recommend products whereas Ratings between (1,2) there no recommendation for products and Rating with 3-stars contains both subset of recommending and not-recommending**","ff26c261":"# Distribution of Department, Division, and Class","9e19b3aa":"## Distribution of Sentiment Polarity of Reviews Based on the Recommendation","e402a837":"## EDA ON Text Data","4feb202a":"From above plot the **Polarity** is around **0.25** with **Age** is in between **35 to 40**","fd9740a2":"# Bivariate Analysis","2bd0ff11":"# Distribution of Top 20 Parts-of-Speech POS Tags","8374910f":"## E-Commerce Clothing Reviews ","ed4a3c14":"# Distribution of Unigram, Bigram and Trigram without Stop Words\n\n### Stop Words are nothing but, the words like this,what,if,is,etc..","b54bbd73":"\n# Distribution of Sentiment Polarity","1a8ee765":"# Distribution of Reviews Rating and Reviewers Age"}}