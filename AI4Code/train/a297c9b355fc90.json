{"cell_type":{"031d78c1":"code","57619371":"code","bdc0c327":"code","1aedf605":"code","c3a61cbe":"code","37fd9a01":"code","42c723e7":"code","bb6a5271":"code","7186a7ac":"code","1f1aac15":"code","b41c1810":"code","c5bd1662":"code","c3dbb722":"code","739b9869":"code","f9329c75":"code","e24fd148":"code","53356cd6":"code","1002fba9":"code","d7d4de64":"code","077b9f1e":"code","c79b50d1":"code","d61d9545":"code","f76ce01c":"code","bf608fa0":"code","fbbf01bc":"markdown","c1283f02":"markdown","b6f733df":"markdown","9bd60260":"markdown","cfcbcc02":"markdown","b51aeb16":"markdown","c01674a8":"markdown","850a0437":"markdown","d07d56ce":"markdown","8d5fe331":"markdown","fb2c697a":"markdown"},"source":{"031d78c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport gc\nimport glob\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True) \nimport plotly.graph_objs as go\n\nfrom plotnine import *\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom geopy.geocoders import Nominatim\nimport folium\nfrom folium.plugins import HeatMap\nfrom folium.plugins import FastMarkerCluster\nfrom plotly import tools\nimport re\nfrom plotly.offline import init_notebook_mode, plot, iplot\nfrom wordcloud import WordCloud, STOPWORDS \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport missingno as msno\nimport glob\n\n%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","57619371":"df2 = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\", low_memory=False)\nprint(df2.shape)\ndf2.head().style.set_properties(**{'background-color':'white?',\n                                     'color': 'black'})","bdc0c327":"df1 = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\", low_memory=False)\nprint(df1.shape)\ndf1.head().style.set_properties(**{'background-color':'white?',\n                                     'color': 'black'})","1aedf605":"df = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/5802.csv\", low_memory=False)\nprint(df.shape)\ndf.head().style.set_properties(**{'background-color':'white?',\n                                     'color': 'black'})","c3a61cbe":"input_dir = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\"\ndistricts_df = pd.read_csv(os.path.join(input_dir, \"districts_info.csv\"))\ndistricts_df.shape","37fd9a01":"plt.figure(figsize=(16, 10))\nsns.countplot(y=\"state\",data=districts_df,order=districts_df.state.value_counts().index,palette=\"Greens\",linewidth=3)\nplt.title(\"State Freq Chart in District Information data\",font=\"Serif\", size=20,pad=20)\nplt.show()\n\ndistrict_df = districts_df\nstates = district_df.groupby(by ='state').count()[['district_id']]\n#abbreviations of all the US States\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ncodes = []\nfor i in states.index:\n    codes.append(us_state_abbrev[i])\n# print(codes)\ndata = dict(\n        type = 'choropleth',\n        colorscale = 'greens',\n        locations = codes,\n        locationmode = 'USA-states',\n        z = list(states['district_id']),\n        text = states.index,\n        colorbar = {'title':'States'},\n      )\nlayout = dict(title = 'States',\n              geo = dict(projection = {'type':'mercator'})\n             )\nlayout = dict(title= 'States with most districts mentioned',\n              geo = {'scope':'usa'})\n\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)\n","42c723e7":"plt.figure(figsize=(16, 10))\nsns.countplot(y=\"locale\",data=districts_df,order=districts_df.locale.value_counts().index,palette=\"Greens\",linewidth=3)\nplt.title(\"Locale Freq Chart in District Information data\",font=\"Serif\", size=20,pad=20)\nplt.show()","bb6a5271":"# df2.head()\nplt.figure(figsize=(16, 10))\nsns.countplot(y=\"Sector(s)\",data=df2,order=df2[\"Sector(s)\"].value_counts().index,palette=\"Greens\",linewidth=3)\nplt.title(\"Locale Freq Chart in Product Information data\",font=\"Serif\", size=20,pad=20)\nplt.show()","7186a7ac":"# df2.head()\nplt.figure(figsize=(16, 10))\nsns.countplot(y=\"Primary Essential Function\",data=df2,order=df2[\"Primary Essential Function\"].value_counts().index,palette=\"Greens\",linewidth=3)\nplt.title(\"Primary Essential Function Freq Chart in Product Information data\",font=\"Serif\", size=20,pad=20)\nplt.show()\n","1f1aac15":"products_df = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\nproducts_df.head()\ndistricts_df = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\ndistricts_df.head()\npath = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\n    \nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\n# engagement_df.head()","b41c1810":"col_list = ['#e5ecde','#cbdabd','#b1c79d','#98b57c','#7ea35b','#658249']\nmsno.bar(products_df, figsize=(16,5), fontsize=12,color=col_list)\nplt.title('Total values for each column in products data',fontsize =16,pad=20)\nplt.show()","c5bd1662":"msno.bar(engagement_df, figsize=(16,6), fontsize=12,color=col_list)\nplt.title('Total values for each column in engagements data',fontsize =16,pad=20)\nplt.show()","c3dbb722":"msno.bar(districts_df, figsize=(16,5), fontsize=12,color=col_list)\nplt.title('Total values for each column in districts data',fontsize =16,pad=20)\nplt.show()","739b9869":"df[['time', 'engagement_index']].set_index(['time']).plot(figsize = (16, 10),color='#7ea35b',grid=False, fontsize =12)\nplt.title('Engagement Over Time',pad=20,fontsize=20)\nplt.show()","f9329c75":"df[['time', 'pct_access']].set_index(['time']).plot(figsize = (16, 10),color='#7ea35b',grid=False, fontsize =12)#,title = )\nplt.title('PCT access Over Time',pad=20,fontsize=20)\nplt.show()","e24fd148":"cloud = WordCloud(width=1440, height=1080,stopwords={'nan'},colormap='Greens',background_color='white').generate(\" \".join(districts_df['state'].astype(str)))\nplt.figure(figsize=(16, 10))\nplt.title('A WordCloud of the various States in the database',fontsize=20,pad=40)\nplt.imshow(cloud)\nplt.axis('off')","53356cd6":"cloud = WordCloud(width=1440, height=1080,stopwords={'nan'},colormap='Greens',background_color='white').generate(\" \".join(products_df['Product Name'].astype(str)))\nplt.figure(figsize=(16, 10))\nplt.title('A WordCloud of the various Product Names',fontsize=20,pad=40)\nplt.imshow(cloud)\nplt.axis('off')","1002fba9":"cloud = WordCloud(width=1440, height=1080,stopwords={'nan'},colormap='Greens',background_color='white').generate(\" \".join(products_df['Provider\/Company Name'].astype(str)))\nplt.figure(figsize=(16, 10))\nplt.title('A WordCloud of the various Provider\/Company Names',fontsize=20,pad=40)\nplt.imshow(cloud)\nplt.axis('off')","d7d4de64":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport plotly.offline as py\nfrom plotly import tools\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\n\npd.options.mode.chained_assignment = None\n\n# Read the data\nus_data_path = \"\/kaggle\/input\/covid19-in-usa\/\"\nus_df = pd.read_csv(us_data_path + \"us_covid19_daily.csv\")\nus_states_df = pd.read_csv(us_data_path + \"us_states_covid19_daily.csv\")\nus_df[\"date\"] = pd.to_datetime(us_df[\"date\"], format=\"%Y%m%d\")\nus_states_df = us_states_df.reindex(index=us_states_df.index[::-1])\nus_states_df[\"date\"] = pd.to_datetime(us_states_df[\"date\"], format=\"%Y%m%d\").dt.date.astype(str)\n#us_states_df.head()\n\n# US state code to name mapping\nstate_map_dict = {'AL': 'Alabama',\n 'AK': 'Alaska',\n 'AS': 'American Samoa',\n 'AZ': 'Arizona',\n 'AR': 'Arkansas',\n 'CA': 'California',\n 'CO': 'Colorado',\n 'CT': 'Connecticut',\n 'DE': 'Delaware',\n 'DC': 'District of Columbia',\n 'D.C.': 'District of Columbia',\n 'FM': 'Federated States of Micronesia',\n 'FL': 'Florida',\n 'GA': 'Georgia',\n 'GU': 'Guam',\n 'HI': 'Hawaii',\n 'ID': 'Idaho',\n 'IL': 'Illinois',\n 'IN': 'Indiana',\n 'IA': 'Iowa',\n 'KS': 'Kansas',\n 'KY': 'Kentucky',\n 'LA': 'Louisiana',\n 'ME': 'Maine',\n 'MH': 'Marshall Islands',\n 'MD': 'Maryland',\n 'MA': 'Massachusetts',\n 'MI': 'Michigan',\n 'MN': 'Minnesota',\n 'MS': 'Mississippi',\n 'MO': 'Missouri',\n 'MT': 'Montana',\n 'NE': 'Nebraska',\n 'NV': 'Nevada',\n 'NH': 'New Hampshire',\n 'NJ': 'New Jersey',\n 'NM': 'New Mexico',\n 'NY': 'New York',\n 'NC': 'North Carolina',\n 'ND': 'North Dakota',\n 'MP': 'Northern Mariana Islands',\n 'OH': 'Ohio',\n 'OK': 'Oklahoma',\n 'OR': 'Oregon',\n 'PW': 'Palau',\n 'PA': 'Pennsylvania',\n 'PR': 'Puerto Rico',\n 'RI': 'Rhode Island',\n 'SC': 'South Carolina',\n 'SD': 'South Dakota',\n 'TN': 'Tennessee',\n 'TX': 'Texas',\n 'UT': 'Utah',\n 'VT': 'Vermont',\n 'VI': 'Virgin Islands',\n 'VA': 'Virginia',\n 'WA': 'Washington',\n 'WV': 'West Virginia',\n 'WI': 'Wisconsin',\n 'WY': 'Wyoming'}\n\nstate_code_dict = {v:k for k, v in state_map_dict.items()}\nstate_code_dict[\"Chicago\"] = 'Illinois'\n\ndef correct_state_names(x):\n    try:\n        return state_map_dict[x.split(\",\")[-1].strip()]\n    except:\n        return x.strip()\n    \ndef get_state_codes(x):\n    try:\n        return state_code_dict[x]\n    except:\n        return \"Others\"\n\ncovid_19_df = pd.read_csv(\"..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv\")\nus_covid_df = covid_19_df[covid_19_df[\"Country\/Region\"]==\"US\"]\nus_covid_df[\"Province\/State\"] = us_covid_df[\"Province\/State\"].apply(correct_state_names)\nus_covid_df[\"StateCode\"] = us_covid_df[\"Province\/State\"].apply(lambda x: get_state_codes(x))\n\ncumulative_df = us_covid_df.groupby(\"ObservationDate\")[\"Confirmed\", \"Deaths\", \"Recovered\"].sum().reset_index()\ncumulative_df['ObservationDate_1'] = pd.to_datetime(cumulative_df['ObservationDate'], dayfirst = False)\ncumulative_df = cumulative_df.sort_values(by=['ObservationDate_1'],axis=0)\n# cumulative_df['month'] = pd.DatetimeIndex(cumulative_df['ObservationDate_1'])\ncumulative_df['month'] = pd.to_datetime(cumulative_df['ObservationDate_1'],format='%m%Y', errors='coerce').dt.to_period('m')","077b9f1e":"cumulative_df = cumulative_df.head(345)","c79b50d1":"f, ax = plt.subplots(figsize=(16, 10))\nsns.despine(f)\nsns.barplot(x='month', y='Confirmed', data=cumulative_df,color='#A2D9CE').set(title='Covid-19 cases in the year 2020')","d61d9545":"f, ax = plt.subplots(figsize=(16, 10))\nsns.despine(f)\nsns.barplot(x='month', y='Deaths', data=cumulative_df,color='#73C6B6').set(title='Covid-19 deaths in the year 2020')","f76ce01c":"f, ax = plt.subplots(figsize=(16, 10))\nsns.despine(f)\nsns.barplot(x='month', y='Recovered', data=cumulative_df,color='#45B39D').set(title='Covid-19 recoveries in the year 2020')","bf608fa0":"%%html\n<marquee style='width: 90% ;height:70%; color: #45B39D ;'>\n    <b>Do UPVOTE if you like my work, I will be adding some more content to this kernel :) <\/b><\/marquee>","fbbf01bc":"Before we dive into understanding the relevant science behind the learning process, let\u2019s ground ourselves in a definition of learning that is drawn from research.\n\nLearning is a process that:\n\n- Is active - process of engaging and manipulating objects, experiences, and conversations in order to build mental models of the world (Dewey, 1938; Piaget, 1964; Vygotsky, 1986). Learners build knowledge as they explore the world around them, observe and interact with phenomena, converse and engage with others, and make connections between new ideas and prior understandings.\n\n- Builds on prior knowledge - and involves enriching, building on, and changing existing understanding, where \u201cone\u2019s knowledge base is a scaffold that supports the construction of all future learning\u201d (Alexander, 1996, p. 89).  \n\n- Occurs in a complex social environment - and thus should not be limited to being examined or perceived as something that happens on an individual level. Instead, it is necessary to think of learning as a social activity involving people, the things they use, the words they speak, the cultural context they\u2019re in, and the actions they take (Bransford, et al., 2006; Rogoff, 1998), and that knowledge is built by members in the activity (Scardamalia & Bereiter, 2006).\n\n- Is situated in an authentic context - provides learners with the opportunity to engage with specific ideas and concepts on a need-to-know or want-to-know basis (Greeno, 2006; Kolodner, 2006).\n\n- Requires learners\u2019 motivation and cognitive engagement to be sustained when learning complex ideas, because considerable mental effort and persistence are necessary.\n\nThe conditions for inputs to learning are clear, but the process is incomplete without making sense of what outputs constitute learning has taken place. At the core, learning is a process that results in a change in knowledge or behavior as a result of experience. Understanding what it takes to get that knowledge in and out (or promote behavioral change of a specific kind) can help optimize learning.","c1283f02":"## Checking the missing values ","b6f733df":"### Data description for products_info file\n\n\n- LP ID - The unique identifier of the product\n\n- URL - Web Link to the specific product\n\n- Product Name - Name of the specific product\n\n- Provider\/Company Name - Name of the product provider\n\n- Sector(s) - Sector of education where the product is used\n\n- Primary Essential Function - The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled","9bd60260":"## The Basic Data distributions","cfcbcc02":"## Basic Word Clouds","b51aeb16":"## Let's also bring in some Covid-19 data! \n\n\nLet's add some visualizations for the cases as well! Since this is impact of Covid-19 on Digital learning, we should also have a look at Covid-19 spread and trends, then we can try and find some patterns for it with Digital Learning during the time! ","c01674a8":"**If there are any suggesion for the notebook please comment, that would be helpful and I will try to implement your suggestions! :)?**\nSome of my other works:\n\n- [TPS-APR-21 EDA AND MODEL](https:\/\/www.kaggle.com\/udbhavpangotra\/tps-apr21-eda-model)\n\n- [Heart Attacks Extensive EDA and Visualizations](https:\/\/www.kaggle.com\/udbhavpangotra\/heart-attacks-extensive-eda-and-visualizations)\n\n- [WHAT ARE PEOPLE WATCHING IN GREAT BIRTAIN](https:\/\/www.kaggle.com\/udbhavpangotra\/what-do-people-use-youtube-for-in-great-britain)\n","850a0437":"### Data description for districts_info file\n- district_id - The unique identifier of the school district\n\n- state - The state where the district resides in\n\n- locale - NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.\n\n- pct_black\/hispanic - Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\n\n- pct_free\/reduced - Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n\n- countyconnectionsratio - ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.\n\n- pptotalraw - Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.","d07d56ce":"**How did COVID-19 impact education, and more specifically Digital Education!**\n\n\nThe COVID-19 pandemic has created the largest disruption of education systems in human history, affecting nearly 1.6 billion learners in more than 200 countries. Closures of schools, institutions and other learning spaces have impacted more than 94% of the world\u2019s student population. This has brought far-reaching changes in all aspects of our lives. Social distancing and restrictive movement policies have significantly disturbed traditional educational practices. Reopening of schools after relaxation of restriction is another challenge with many new standard operating procedures put in place.\n\nWithin a short span of the COVID-19 pandemic, many researchers have shared their works on teaching and learning in different ways. Several schools, colleges and universities have discontinued face-to-face teachings. There is a fear of losing 2020 academic year or even more in the coming future. The need of the hour is to innovate and implement alternative educational system and assessment strategies. The COVID-19 pandemic has provided us with an opportunity to pave the way for introducing digital learning. This kernel aims to provide a comprehensive report on the impact of the COVID-19 pandemic on online teaching and learning of various papers and indicate the way forward.","8d5fe331":"## The Basic File descriptions","fb2c697a":"### Data description for engagement_file\n\n- time - date in \"YYYY-MM-DD\"\n\n- lp_id - The unique identifier of the product\n\n- pct_access - Percentage of students in the district have at least one page-load event of a given product and on a given day\n\n- engagement_index - Total page-load events per one thousand students of a given product and on a given day"}}