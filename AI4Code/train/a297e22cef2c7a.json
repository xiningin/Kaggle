{"cell_type":{"b73271c5":"code","f848bf41":"code","729d8271":"code","6e68a93b":"code","d0bfe62b":"code","43be20c7":"code","eabb53a1":"code","7857dc97":"code","fae6e5f3":"code","2ef7efc8":"code","b6ce49f8":"code","43aa7dca":"code","6723e77f":"code","f42a8d3c":"code","4a94068d":"code","92af9a65":"code","54cfac59":"code","f3a1a79d":"code","a7ecaea0":"code","644bb574":"code","7e7d34c6":"code","f00578ce":"code","7026bc73":"code","5bcc0ff2":"code","623ae1c0":"code","b5b1660b":"code","18a057ac":"code","c708cdce":"code","f67d5704":"code","174e4131":"code","5f8fdcd9":"code","e8bb9630":"code","662681a0":"code","ed7568b8":"code","af64ad96":"code","c6c873a4":"code","31c4b5f9":"code","ac29b0fa":"code","3e864c8d":"code","a5ba3863":"code","ac33fad0":"code","caedfd88":"code","81798533":"code","bb3993a7":"code","94982238":"markdown","012000ae":"markdown","3de4bc3c":"markdown","17754ee3":"markdown","c4abc237":"markdown","63309648":"markdown","d73ae4f1":"markdown","c9a71676":"markdown","01f49aec":"markdown","8a998674":"markdown","6b4d2034":"markdown"},"source":{"b73271c5":"# Data Dictionary\n# Variable\tDefinition\tKey\n# survival\tSurvival\t0 = No, 1 = Yes\n# pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n# sex\tSex\t\n# Age\tAge in years\t\n# sibsp\t# of siblings \/ spouses aboard the Titanic\t\n# parch\t# of parents \/ children aboard the Titanic\t\n# ticket\tTicket number\t\n# fare\tPassenger fare\t\n# cabin\tCabin number\t\n# embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n# Variable Notes\n# pclass: A proxy for socio-economic status (SES)\n# 1st = Upper\n# 2nd = Middle\n# 3rd = Lower\n\n# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n# sibsp: The dataset defines family relations in this way...\n# Sibling = brother, sister, stepbrother, stepsister\n# Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\n# parch: The dataset defines family relations in this way...\n# Parent = mother, father\n# Child = daughter, son, stepdaughter, stepson\n# Some children travelled only with a nanny, therefore parch=0 for them.","f848bf41":"# Importing the usual libraries and filter warnings\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.pyplot import xticks\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","729d8271":"\n#train = pd.read_csv('train.csv')\n#test = pd.read_csv('test.csv')\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\nprint(train.shape,test.shape)\n#In the beginning it's important to check the size of your train and test data which later helps in \n#deciding the sample size while testing your model on train data","6e68a93b":"train.isnull().sum()","d0bfe62b":"test.isnull().sum()","43be20c7":"train.info()","eabb53a1":"train.describe()","7857dc97":"train.head()","fae6e5f3":"test.head()","2ef7efc8":"# To see the survival count\nax = sns.countplot(\"Survived\",data=train)\nax.set_title(\"Survival Count\")\nfor p in ax.patches:\n     ax.annotate(p.get_height(), (p.get_x()+0.15, p.get_height()+1))\nxticks(rotation=90)\n#Looks like the Target variable is not skewed","b6ce49f8":"# To see the survival count among male and female\nax = sns.countplot(\"Sex\",data=train,hue=\"Survived\")\nax.set_title(\"Looks like more number of female survived than men\")\nfor p in ax.patches:\n     ax.annotate(p.get_height(), (p.get_x()+0.15, p.get_height()+1))\nxticks(rotation=90)","43aa7dca":"#Interesting to see how people emabarked for Southamptom suffered the most casualties\nax = sns.countplot(\"Embarked\",data=train,hue=\"Survived\")\nfor p in ax.patches:\n     ax.annotate(p.get_height(), (p.get_x()+0.15, p.get_height()+1))\nxticks(rotation=90)\n#Looks like the passengers with Pclass=3 surviced the most","6723e77f":"ntrain = train.shape[0]\ny = train['Survived'].values\ndf = pd.concat([train.drop(columns=['Survived']), test])\ndf.shape","f42a8d3c":"df.isnull().sum()","4a94068d":"df.groupby(['Pclass','Sex']).mean()","92af9a65":"#The above Avg Age by PClass gives a very unique distinction \n#The people who survived in 1st Class were elderlies near 35-43Age group , those in lower classes were young ,\n#which could also mean kids survived ","54cfac59":"df.loc[(df[\"Pclass\"]==1) & (df[\"Sex\"]==\"female\") & (df[\"Age\"].isnull()),'Age'] = 37.0\ndf.loc[(df[\"Pclass\"]==1) & (df[\"Sex\"]==\"male\") & (df[\"Age\"].isnull()),'Age'] = 41.0\n\ndf.loc[(df[\"Pclass\"]==2) & (df[\"Sex\"]==\"female\") & (df[\"Age\"].isnull()),'Age'] = 27.0\ndf.loc[(df[\"Pclass\"]==2) & (df[\"Sex\"]==\"male\") & (df[\"Age\"].isnull()),'Age'] = 30.0\n\ndf.loc[(df[\"Pclass\"]==3) & (df[\"Sex\"]==\"female\") & (df[\"Age\"].isnull()),'Age'] = 22.0\ndf.loc[(df[\"Pclass\"]==3) & (df[\"Sex\"]==\"male\") & (df[\"Age\"].isnull()),'Age'] = 25.0","f3a1a79d":"df.isnull().sum()","a7ecaea0":"# Since most of the population onboard was embarked for Southampton and \n#just 2 rows were missing Embarked value so we would fill it with S\ndf[\"Embarked\"].fillna(\"S\",inplace=True)","644bb574":"# One value of fare is missing\ndf[df[\"Fare\"].isnull()]","7e7d34c6":"#Lets see whats the average value of fare by a passenger from Pclass = 3 and above the age of 40\ndf[(df[\"Pclass\"]==3) & (df.Age > 40) & (df.Sex == \"male\")].mean()","f00578ce":"#Fill the missing value with the average\ndf.loc[(df[\"Pclass\"]==3) & (df.Fare.isnull()) & (df.Sex == \"male\"), 'Fare'] = 8.5","7026bc73":"df.isnull().sum()","5bcc0ff2":"# Since almost a thousand people are missing Cabin its best we drop this column as we couldn't see any corelation between the \n# value of Cabin and Survived at this stage\ndf.drop(columns = [\"Cabin\"],inplace=True)","623ae1c0":"#df.dropna(inplace=True)","b5b1660b":"# Looks like we have dealt with all the missing values quickly \n# Later we could explore multiple other pro techniqies to deal with missing values but at this stage\n# we are looking for a quick model solution\ndf.isnull().sum()","18a057ac":"#We feel its better to drop these columns , maybe we could refer to some pro's notebooks to how use them in the model later\ndf_prep = df.drop(columns=['PassengerId','Name','Ticket'])","c708cdce":"df_prep.head()","f67d5704":"df_prep.info()","174e4131":"df_prep['Parch'] = df_prep['Parch'].apply(str)\ndf_prep['SibSp'] = df_prep['SibSp'].apply(str)\ndf_prep['Pclass'] = df_prep['Pclass'].apply(str)","5f8fdcd9":"# Categorical values need to be converted into numbers and one such simple approach is one hot encoding\nOneHot = pd.get_dummies(df_prep[['Pclass','Sex','SibSp','Parch','Embarked']])","e8bb9630":"OneHot.head()","662681a0":"df_prep =  df_prep.drop(columns=['Pclass','Sex','SibSp','Parch','Embarked'])\ndf_prep = pd.concat([df_prep,OneHot],axis=1)\ndf_prep.shape","ed7568b8":"#Once we have cleaned the data we will divide it back again into its orignal format of train and test\ndf_train = df_prep[:ntrain]\ndf_test = df_prep[ntrain:]","af64ad96":"df_train.head()","c6c873a4":"# Loading \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","31c4b5f9":"seed = 2\ntest_size = 0.2\n\nX_train, X_test, y_train, y_test = train_test_split(df_train,y, test_size = test_size , random_state = seed)\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape)","ac29b0fa":"# Logistic Regression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","3e864c8d":"accuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nroc_auc = roc_auc_score(y_test,y_pred)\ncv_score = cross_val_score(model,X_train,y_train,cv=7,scoring=\"accuracy\")\ncv_predict = cross_val_predict(model,X_train,y_train,cv=7)\nprint('Accuracy: %f' % accuracy)\nprint('Precision: %f' % precision)\nprint('Recall: %f' % recall)\nprint('F1 score: %f' % f1)\nprint('ROC AUC score: %f' % roc_auc)\nprint(\"Accuracy by cross val score : %0.2f (+\/- %0.2f)\" % (cv_score.mean(), cv_score.std() * 2))\nprint(\"Accuracy by cross val predict : %0.2f\" % (accuracy_score(y_train,cv_predict)))","a5ba3863":"confusion_matrix(y_test,y_pred)","ac33fad0":"confusion_matrix(y_train,cv_predict)\n","caedfd88":"# Lets try some hyperparameter tuning with Grid search\nparams = {'C':[0.01,0.1,1,10],\n           'penalty':['l1','l2']}\ngrid_search = GridSearchCV(model,params,cv=10,scoring='accuracy',return_train_score=True)\ngrid_search.fit(df_train,y)\ngrid_search.best_params_","81798533":"model = LogisticRegression(C=10,penalty='l2')\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nroc_auc = roc_auc_score(y_test,y_pred)\ncv_score = cross_val_score(model,X_train,y_train,cv=7,scoring=\"accuracy\")\ncv_predict = cross_val_predict(model,X_train,y_train,cv=7)\nprint('Accuracy: %f' % accuracy)\nprint('Precision: %f' % precision)\nprint('Recall: %f' % recall)\nprint('F1 score: %f' % f1)\nprint('ROC AUC score: %f' % roc_auc)\nprint(\"Accuracy by cross val score : %0.2f (+\/- %0.2f)\" % (cv_score.mean(), cv_score.std() * 2))\nprint(\"Accuracy by cross val predict : %0.2f\" % (accuracy_score(y_train,cv_predict)))","bb3993a7":"#Here is the code to make your submission\ntest[\"Survived\"] = model.predict(df_test)\nsubmission = test[['PassengerId','Survived']].copy()\nsubmission.to_csv(\"Titanic_kaggle.csv\",index=False)\n#Upload the file Titanic_kaggle.csv to the submission","94982238":"<a id='BS7'><\/a>\n\n### 7. Present your solution\n\n - At this point we have achived a Accuracy score of 79% with a precision of 84% which is not bad for a beginner\n - You are free to try other algorithms like Support Vector Machine \/ K Nearest Neighbours \/ Naive Bayes Agorithm \n - This approach doesn't rank you high on the leaderboard but hey now the real game begins\n - We are to revisit our Data Cleaning  approach ,try ensembling , try high level classification algorithms to improve our score on the leaderboard","012000ae":"<a id='BS1'><\/a>\n### 1. Define the problem\n\n - The problem at hand is to predict whether a passenger survived the Titanic disaster or not.\n - The Survival of a passenger is represented by Survival Column in the train data where 0 = No and 1 = yes\n - Test data doesn't contain this column , which we will predict based upon the model created on the train data\n - If you are unfamiliar with the Titanic accident read [here](https:\/\/www.history.com\/topics\/early-20th-century-us\/titanic)","3de4bc3c":"<a id='BS5'><\/a>\n### 5. Prepare\/Clean the Data\n - This stage reuires a lot of practice of various datasets for a Data Scientist to know what should be done, we will take the simplest approaches of the text book\n - In this stage we would like to fill in the missing values\n - Try to find outliers , values which are unexpected maybe you would not expect people's age to be negative or fare to be way too high to be true\n - Here i used a simple approach of using guessing people's age by Pclass and gender and replacing them with the average age in that section\n - In this stage its better to combine the train and test dataset minus the target variable and pre process it ","17754ee3":"## Titanic Solution ....an approach from a beginner's mindset\n\n - Titanic competition is a beginners dataset to join the Data Scientist community\n - This is perfect dataset to practice Logistic regression or Binary Classficiation algorithm\n - In the solution below we will simply focus on cleaning the data and quickly building the model \n - No complex code or strategies are used in this notebook \n - The problem is solved with simple libraries which a beginner learns during his early days of Data Science education\n \n*An expert Data Sceintist will always tell you that it's always important to model a problem in early stages and tune from thereafter so lets dive in*\n","c4abc237":"<a id='BS4'><\/a>\n\n### 4. Visualize the Data\n\n - Step 3 and 4(Analyze and Visualize) go hand in hand\n - It takes some practice to know which visualization graphs to use and draw correct inferences\n - Try to answer your curious questions for starters like \n     1. How many people survived and how many didn't\n     2. Who survived the most male or female\n     3. Is there any relationship between people who payed higher fare and survival rate\n - Mainly you would like to see the relationship between target class and input vairables ","63309648":"<a id='BS2'><\/a>\n### 2. Gather the Data\n\n - This step is easy while working with the Kaggle problems , data is already gathered and available in excel sheets\n - Real life Data Science problems will however require you to collect data from various sources  (Databases\/DataWarehouses\/etc.)","d73ae4f1":"<img src=\"https:\/\/cdn.vox-cdn.com\/thumbor\/Z3M6rKDTsQO3qjwu_a4v-J5rQKg=\/0x10:2000x1510\/1200x800\/filters:focal(0x10:2000x1510)\/cdn.vox-cdn.com\/uploads\/chorus_image\/image\/46125356\/titanicillustration.0.0.jpg\" width=500 height=500 \/>","c9a71676":"<a id='BS3'><\/a>\n### 3. Analyze the Dataset\n\n - A beginner's approach should be to first check the null values in the dataset,  use the isnull() function\n - Check the datatype of the variables , use the info() function\n - Use the describe() function to see the min max values \/ mean and standard deviation of the variables. Once you move to the next level you will realize the importance of checking these features\n - Lastly take a look at the data to get a feel of values in the dataset . By doing a head() of the dataset you will realize that column name will hardly affect the target variable \"Survived\" . Gender will although be intresting to see whether more women survided than men . Seeing expert solutions you will realize how people even engineered the name variable but we will skip for now from a novice perspective.","01f49aec":"<a id='BS6'><\/a>\n### 6. Select an approach of model and Decide a Performance metric\n - Since this is a binary classification problem you can zero in on the set of algorithms you are going to try for the model\n - It is very important at this stage to decide first on the performance metric before starting the model apply process\n - Decision on performance metric depends on deep understanding of the business \n - In the words of Andrew Ng you need to first decide your target and then make you team aim at it\n - For Binary classification you can choose between Precision\/Recall\/F1 score\/Accuracy , etc \n - For the sake of Kaggle competition we will choose Accuracy as a performance metric and try to improve our Accuracy of prediction","8a998674":"**PS : The below solution had a score of 0.76 on the kaggle leaderboard**","6b4d2034":"### Beginner's Steps to Approach a Data Science Problem \n\n1. [Define the problem](#BS1)\n2. [Gather the Data](#BS2)\n3. [Analyze the Dataset](#BS3) \n4. [Visualize the Dataset](#BS4)\n5. [Prepare\/Clean the Data](#BS5)\n6. [Select an approach of model and Decide a Performance metric](#BS6)\n7. [Present your solution](#BS7)"}}