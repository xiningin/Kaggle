{"cell_type":{"8b5bc87b":"code","af7d681d":"code","745a97fe":"code","fa283032":"code","d042f740":"code","87764baf":"code","832e11af":"code","a20afb4a":"code","d2bc41c7":"code","51c9d521":"code","fffa4ed5":"code","048b2ba5":"code","c7e5088e":"code","b34e5186":"code","0113b6f0":"code","93207eb4":"code","972df7a4":"code","58d9de9d":"code","3952138c":"code","4b627305":"markdown","3a525e9f":"markdown","e05ab4e7":"markdown","31911332":"markdown","38841c82":"markdown","9afc2342":"markdown","928a461b":"markdown","859c3f01":"markdown","097f8c39":"markdown","9a1d7bde":"markdown","0289056a":"markdown","d7264029":"markdown","44f9d009":"markdown","882a1c55":"markdown","839170f1":"markdown","a57bb1c5":"markdown","a6979b7a":"markdown","005c4964":"markdown","01e1177a":"markdown","616b9d9c":"markdown","334f6e94":"markdown"},"source":{"8b5bc87b":"import glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport pydicom\nimport numpy as np\nimport warnings\nimport multiprocessing\nimport os\nfrom skimage import morphology\nfrom skimage import feature\nfrom skimage import measure\nfrom skimage import util\nfrom skimage import transform\n\nwarnings.filterwarnings('ignore')","af7d681d":"sns.set_style('darkgrid')\nsns.set_context('notebook', font_scale=1.2)\nplt.rcParams['figure.figsize'] = [14, 8]\nplt.rcParams['lines.linewidth'] = 2.5\n\n# Get all data\ntr = pd.read_csv('..\/input\/stage_1_train_labels.csv')\ntr['aspect_ratio'] = (tr['width']\/tr['height'])\ntr['area'] = tr['width'] * tr['height']\n\ndef get_info(patientId, root_dir='..\/input\/stage_1_train_images\/'):\n    fn = os.path.join(root_dir, f'{patientId}.dcm')\n    dcm_data = pydicom.read_file(fn)\n    return {'age': dcm_data.PatientAge, \n            'gender': dcm_data.PatientSex, \n            'id': os.path.basename(fn).split('.')[0],\n            'pixel_spacing': float(dcm_data.PixelSpacing[0]),\n            'mean_black_pixels': np.mean(dcm_data.pixel_array == 0)}\n\npatient_ids = list(tr.patientId.unique())\nwith multiprocessing.Pool(4) as pool:\n    result = pool.map(get_info, patient_ids)\n    \ndemo = pd.DataFrame(result)\ndemo['gender'] = demo['gender'].astype('category')\ndemo['age'] = demo['age'].astype(int)\n\ntr = (tr.merge(demo, left_on='patientId', right_on='id', how='left')\n        .drop(columns='id'))","745a97fe":"boxes_per_patient = tr.groupby('patientId')['Target'].sum()\n\nax = (boxes_per_patient > 0).value_counts().plot.bar()\n_ = ax.set_title('Are the classes imbalanced?')\n_ = ax.set_xlabel('Has Pneumonia')\n_ = ax.set_ylabel('Count')\n_ = ax.xaxis.set_tick_params(rotation=0)","fa283032":"ax = boxes_per_patient.value_counts().plot.bar()\n_ = ax.set_title('How many cases are there per image?')\n_ = ax.set_xlabel('Number of cases')\n_ = ax.xaxis.set_tick_params(rotation=0)","d042f740":"centers = (tr.dropna(subset=['x'])\n           .assign(center_x=tr.x + tr.width \/ 2, center_y=tr.y + tr.height \/ 2))\nax = sns.jointplot(\"center_x\", \"center_y\", data=centers, height=9, alpha=0.1)\n_ = ax.fig.suptitle(\"Where is Pneumonia located?\", y=1.01)","87764baf":"g = sns.FacetGrid(col='Target', hue='gender', \n                  data=tr.drop_duplicates(subset=['patientId']), \n                  height=9, palette=dict(F=\"red\", M=\"blue\"))\n_ = g.map(sns.distplot, 'age', hist_kws={'alpha': 0.3}).add_legend()\n_ = g.fig.suptitle(\"What is the age distribution by gender and target?\", y=1.02, fontsize=20)","832e11af":"areas = tr.dropna(subset=['area'])\ng = sns.FacetGrid(hue='gender', data=areas, height=9, palette=dict(F=\"red\", M=\"blue\"), aspect=1.4)\n_ = g.map(sns.distplot, 'area', hist_kws={'alpha': 0.3}).add_legend()\n_ = g.fig.suptitle('What are the areas of the bounding boxes by gender?', y=1.01)","a20afb4a":"pixel_vc = tr.drop_duplicates('patientId')['pixel_spacing'].value_counts()\nax = pixel_vc.iloc[:6].plot.bar()\n_ = ax.set_xticklabels([f'{ps:.4f}' for ps in pixel_vc.index[:6]])\n_ = ax.set_xlabel('Pixel Spacing')\n_ = ax.set_ylabel('Count')\n_ = ax.set_title('How is the pixel spacing distributed?', fontsize=20)","d2bc41c7":"areas_with_count = areas.merge(pd.DataFrame(boxes_per_patient).rename(columns={'Target': 'bbox_count'}), \n                               on='patientId')\ng = sns.FacetGrid(hue='bbox_count', data=areas_with_count, height=8, aspect=1.4)\n_ = g.map(sns.distplot, 'area').add_legend()\n_ = g.fig.suptitle(\"How are the bounding box areas distributed by the number of boxes?\", y=1.01)","51c9d521":"from sklearn.mixture import GaussianMixture\nclf = GaussianMixture(n_components=2)\nclf.fit(centers[['center_x', 'center_y']])\ncenter_probs = clf.predict_proba(centers[['center_x', 'center_y']])\nZ = -clf.score_samples(centers[['center_x', 'center_y']])\noutliers = centers.iloc[Z > 17]\nfig, ax = plt.subplots()\ncenters.plot.scatter('center_x', 'center_y', c=Z, alpha=0.5, cmap='viridis', ax=ax)\noutliers.plot.scatter('center_x', 'center_y', c='red', marker='x', s=100, ax=ax)\n_ = ax.set_title('Where are the outliers?', fontsize=18)","fffa4ed5":"import matplotlib.patches as patches\n\ndef get_image(patientId, root_dir='..\/input\/stage_1_train_images\/'):\n    fn = os.path.join(root_dir, f'{patientId}.dcm')\n    dcm_data = pydicom.read_file(fn)\n    return dcm_data.pixel_array\n\ndef draw_bbs(bbs, ax):\n    for bb in bbs.itertuples():\n        rect = patches.Rectangle(\n            (bb.x, bb.y), bb.width, bb.height,\n            linewidth=2, edgecolor='red', facecolor='none')\n        ax.add_patch(rect)\n\ndef draw_image(img, bbs, ax):\n    ax.imshow(img, cmap='gray')\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    if bbs is not None:\n        draw_bbs(bbs, ax)\n\noutliers_15 = outliers.drop_duplicates(subset=['patientId']).iloc[:15]\nfig, axes = plt.subplots(3, 5)\nfor row, ax in zip(outliers_15.itertuples(), axes.flatten()):\n    img = get_image(row.patientId)\n    bbs = tr.loc[tr.patientId == row.patientId, ['x', 'y', 'width', 'height']]\n    draw_image(img, bbs, ax)\nfig.tight_layout(pad=-0.5)","048b2ba5":"ax = sns.boxplot(tr.mean_black_pixels)\n_ = ax.set_xlabel('Percentage of black pixels')\n_ = ax.set_title('Are there images with mostly black pixels?')","c7e5088e":"high_black_pixel_patientIds = tr.loc[tr.mean_black_pixels > 0.55, 'patientId'].drop_duplicates()\nfig, axes = plt.subplots(4, 5)\nfor i, (patient_id, ax) in enumerate(zip(high_black_pixel_patientIds, axes.flatten())):\n    row = tr.loc[tr.patientId == patient_id]\n    img = get_image(row.patientId.iloc[0])\n    bbs = row[['x', 'y', 'width', 'height']]\n    draw_image(img, bbs, ax)\nfig.tight_layout(pad=-1)","b34e5186":"high_white_pixel_patientIds = tr.loc[tr.mean_black_pixels < 0.000001, 'patientId'].drop_duplicates()\nfig, axes = plt.subplots(4, 5)\nfor patient_id, ax in zip(high_white_pixel_patientIds, axes.flatten()):\n    row = tr.loc[tr.patientId == patient_id]\n    img = get_image(row.patientId.iloc[0])\n    bbs = row[['x', 'y', 'width', 'height']]\n    draw_image(img, bbs, ax)\nfig.tight_layout(pad=-1)","0113b6f0":"high_black_pixel_images = np.empty(shape=(high_black_pixel_patientIds.shape[0], 1024, 1024))\n\nfor i, patient_id in enumerate(high_black_pixel_patientIds):\n    row = tr.loc[tr.patientId == patient_id]\n    img = get_image(row.patientId.iloc[0])\n    high_black_pixel_images[i] = img \n    \nhigh_black_pixel_contours = []\nfor img in high_black_pixel_images:\n    img2 = feature.canny(img != 0)\n    img2 = morphology.convex_hull_image(img2)\n    c = measure.find_contours(img2, 0)[0]\n    c = measure.approximate_polygon(c, 20)\n    high_black_pixel_contours.append(c)\n\nfig, axes = plt.subplots(4, 5)\ncontours = []\nfor c, img, ax in zip(high_black_pixel_contours, high_black_pixel_images, axes.flatten()):\n    draw_image(img, None, ax)\n    _ = ax.plot(c[:, 1], c[:, 0], '-b', linewidth=4)\nfig.tight_layout(pad=-1)","93207eb4":"def order_coordinates(coords):\n    \"\"\"Returns coordinates with order:\n    (top left, top right, bottom right, bottom left)\n    \"\"\"\n    coords = coords[:-1]\n    output = np.empty((4, 2), dtype=np.float32)\n    dists = coords[:, 1]**2 + coords[:, 0]**2\n    ratios = coords[:, 1]\/np.sqrt(dists)\n    \n    tl = coords[np.argmin(dists)]\n    br = coords[np.argmax(dists)]\n    \n    tr = coords[np.argmax(ratios)]\n    bl = coords[np.argmin(ratios)]\n    \n    output[0] = tl\n    output[1] = tr\n    output[2] = br\n    output[3] = bl\n    \n    return output[:,::-1]\n\ndef _convert_bb(bb, tfm):\n    x, y, w, h = bb.x, bb.y, bb.width, bb.height\n    pts = np.array([\n        [x, y],\n        [x + w, y],\n        [x + w, y + h],\n        [x, y + h]\n    ])\n    new_pts = tfm.inverse(pts)\n    pts_min = np.min(new_pts, axis=0)\n    pts_max = np.max(new_pts, axis=0)\n    \n    x, y = pts_min\n    w, h = pts_max - pts_min\n    \n    return np.array([x, y, w, h])\n\ndef convert_bbs(bboxs, tfm):\n    output = np.empty_like(bboxs, dtype=np.float32)\n    \n    for i, bb in enumerate(bboxs.itertuples()):\n        output[i] = _convert_bb(bb, tfm)\n    \n    return pd.DataFrame(output, columns=['x', 'y', 'width', 'height'])\n\nfig, axes = plt.subplots(4, 2, figsize=(8, 10))\n\norig_coords = np.array([[0, 0], [1024, 0], [1024, 1024], [0, 1024]])\ninteresting_idices = [0, 2, 3, 17]\n\nfor i, (ax1, ax2) in zip(interesting_idices, axes):\n    patient_id = high_black_pixel_patientIds.iloc[i]\n    img = high_black_pixel_images[i]\n    contour = high_black_pixel_contours[i]\n    \n    row = tr.loc[tr.patientId == patient_id]\n    bbs = row[['x', 'y', 'width', 'height']]\n    ordered_coors = order_coordinates(contour)\n    tform = transform.estimate_transform('projective', orig_coords, ordered_coors)\n    img_t = transform.warp(img, tform, output_shape=(1024, 1024))\n    \n    new_bbs = convert_bbs(bbs, tform)\n    _ = draw_image(img, bbs, ax1)\n    _ = draw_image(img_t, new_bbs, ax2)\n    \nfig.tight_layout(pad=-1)","972df7a4":"ax = sns.distplot(tr['aspect_ratio'].dropna(), norm_hist=True)\n_ = ax.set_title(\"What does the distribution of bounding aspect ratios look like?\")\n_ = ax.set_xlabel(\"Aspect Ratio\")","58d9de9d":"aspect_ratios = tr['aspect_ratio'].dropna()\nhigh_aspect_ratio_tr = (tr.iloc[aspect_ratios[aspect_ratios > aspect_ratios.quantile(q=0.99)].index]\n                          .drop_duplicates(['patientId']))\nfig, axes = plt.subplots(3, 5)\nfor row, ax in zip(high_aspect_ratio_tr.itertuples(), axes.flatten()):\n    img = get_image(row.patientId)\n    bbs = tr.loc[tr.patientId == row.patientId, ['x', 'y', 'width', 'height']]\n    draw_image(img, bbs, ax)\nfig.tight_layout(pad=-0.5)","3952138c":"g = sns.relplot(x='area', y='aspect_ratio', \n            data=tr.dropna(subset=['area', 'aspect_ratio']), \n            height=8, alpha=0.8, aspect=1.4,)\n_ = g.fig.suptitle(\"Is there a relationship between the bounding box's aspect ratio and area?\", y=1.005)","4b627305":"Most of objects used in the figures are defined in the next cell:","3a525e9f":"## What does the images with a high aspect ratio look like?\n[Back to top](#Questions)","e05ab4e7":"### More questions to come! \ud83e\uddd0","31911332":"## What does the mostly black pixels look like?\n[Back to top](#Questions)","38841c82":"## Are there images with mostly black pixels?\n[Back to top](#Questions)","9afc2342":"## Can tradiational image processing find a bounding box around the cropped images?\n[Back to top](#Questions)","928a461b":"## Can the bounding boxes be resized when cropping and resizing the cropped images?\n[Back to top](#Questions)","859c3f01":"## Load and Prepare data\n\nIn this section, the data is loaded and prepared for analysis.","097f8c39":"## How is the pixel spacing distributed?\n[Back to top](#Questions)","9a1d7bde":"# Q&A with Only Pictuers! (RSNA Pneumonia Detection Challenge)\n\nThis kernel poses and answers questions about the dataset using images!\n\n## Questions\n\n- [Are the classes imbalanced?](#Are-the-classes-imbalanced?)\n- [How many cases are there per image?](#How-many-cases-are-there-per-image?)\n- [Where is Pneumonia located?](#Where-is-Pneumonia-located?)\n- [What is the age distribution by gender and target?](#What-is-the-age-distribution-by-gender-and-target?)\n- [What are the areas of the bounding boxes by gender?](#What-are-the-areas-of-the-bounding-boxes-by-gender?)\n- [How is the pixel spacing distributed?](#How-is-the-pixel-spacing-distributed?)\n- [How are the bounding box areas distributed by the number of boxes?](#How-are-the-bounding-box-areas-distributed-by-the-number-of-boxes?)\n- [Where are the outliers?](#Where-are-the-outliers?)\n- [What does the outliers look like?](#What-does-the-outliers-look-like?)\n- [Are there images with mostly black pixels?](#Are-there-images-with-mostly-black-pixels?)\n- [What does the mostly black pixels look like?](#What-does-the-mostly-black-pixels-look-like?)\n- [What does the mostly white pixel images look like?](#What-does-the-mostly-white-pixel-images-look-like?)\n- [Can tradiational image processing find a bounding box around the cropped images?](#Can-tradiational-image-processing-find-a-bounding-box-around-the-cropped-images?)\n- [Can the bounding boxes be resized when cropping and resizing the cropped images?](#Can-the-bounding-boxes-be-resized-when-cropping-and-resizing-the-cropped-images?)\n- [How are the bounding box aspect ratios distributed?](#How-are-the-bounding-box-aspect-ratios-distributed?)\n- [What does the images with a high aspect ratio look like?](#What-does-the-images-with-a-high-aspect-ratio-look-like?)\n- [Is there a relationship between the bounding box's aspect ratio and area?](#Is-there-a-relationship-between-the-bounding-box's-aspect-ratio-and-area?)\n\nMore questions to come! \ud83e\uddd0","0289056a":"## What are the areas of the bounding boxes by gender?\n[Back to top](#Questions)","d7264029":"## How are the bounding box aspect ratios distributed?\n[Back to top](#Questions)","44f9d009":"## How many cases are there per image?\n[Back to top](#Questions)","882a1c55":"## Where is Pneumonia located?\n[Back to top](#Questions)","839170f1":"## Is there a relationship between the bounding box's aspect ratio and area?\n[Back to top](#Questions)","a57bb1c5":"## How are the bounding box areas distributed by the number of boxes?\n[Back to top](#Questions)","a6979b7a":"## What is the age distribution by gender and target?\n[Back to top](#Questions)","005c4964":"## What does the mostly white pixel images look like?\n[Back to top](#Questions)","01e1177a":"## What does the outliers look like?\n[Back to top](#Questions)","616b9d9c":"## Where are the outliers?\n[Back to top](#Questions)","334f6e94":"## Are the classes imbalanced?\n[Back to top](#Questions)"}}