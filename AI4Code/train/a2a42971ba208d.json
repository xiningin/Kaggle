{"cell_type":{"9c56d452":"code","15d617e7":"code","e20a3b8f":"code","659da02e":"code","e74a348f":"code","7be3ca1c":"code","f4b23303":"code","c3ecc63d":"code","bfe1bd1d":"code","12e269fc":"code","841fbd14":"code","fe058e47":"code","c9cc0c36":"code","d34d6663":"code","2a42463d":"code","45c0c3e9":"code","fb8e20bf":"code","4d8203fa":"code","3beff5ca":"code","71b00fb5":"code","743a7f80":"code","4107bfc6":"code","2f89ef5c":"code","99afbaa8":"code","16c3cbb0":"markdown"},"source":{"9c56d452":"# Check out CUDA version\nimport torch\n\ncuda_version_major = int(torch.version.cuda.split('.')[0])\ncuda_version_major","15d617e7":"# Torch - Torchvision - IceVision - IceData - MMDetection - YOLOv5 - EfficientDet Installation\n!wget https:\/\/raw.githubusercontent.com\/airctic\/icevision\/master\/icevision_install.sh\n\n# Choose your installation target: cuda11 or cuda10 or cpu\n!bash icevision_install.sh cuda11","e20a3b8f":"!pip install torchtext==0.11.0 --upgrade","659da02e":"# Restart kernel after installation\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)","e74a348f":"from icevision.all import *\nimport icedata","7be3ca1c":"# Download the dataset\nurl = \"https:\/\/cvbp-secondary.z19.web.core.windows.net\/datasets\/object_detection\/odFridgeObjects.zip\"\ndest_dir = \"fridge\"\ndata_dir = icedata.load_data(url, dest_dir)","f4b23303":"# Create the parser\nparser = parsers.VOCBBoxParser(annotations_dir=data_dir \/ \"odFridgeObjects\/annotations\", images_dir=data_dir \/ \"odFridgeObjects\/images\")","c3ecc63d":"# Parse annotations to create records\ntrain_records, valid_records = parser.parse()","bfe1bd1d":"# Transforms\n# size is set to 384 because EfficientDet requires its inputs to be divisible by 128\nimage_size = 384\ntrain_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\nvalid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])","12e269fc":"# Datasets\ntrain_ds = Dataset(train_records, train_tfms)\nvalid_ds = Dataset(valid_records, valid_tfms)","841fbd14":"# Show an element of the train_ds with augmentation transformations applied\nsamples = [train_ds[0] for _ in range(3)]\nshow_samples(samples, ncols=3)","fe058e47":"# Just change the value of selection to try another model\n\nselection = 0\n\nextra_args = {}\n\nif selection == 0:\n  model_type = models.mmdet.vfnet\n  backbone = model_type.backbones.resnet50_fpn_mstrain_2x\n\nelif selection == 1:\n  model_type = models.mmdet.retinanet\n  backbone = model_type.backbones.resnet50_fpn_1x\n  # extra_args['cfg_options'] = { \n  #   'model.bbox_head.loss_bbox.loss_weight': 2,\n  #   'model.bbox_head.loss_cls.loss_weight': 0.8,\n  #    }\n    \nelif selection == 2:\n  model_type = models.mmdet.faster_rcnn\n  backbone = model_type.backbones.resnet50_fpn_1x\n\n\nelif selection == 3:\n  # The Retinanet model is also implemented in the torchvision library\n  model_type = models.torchvision.retinanet\n  backbone = model_type.backbones.resnet50_fpn\n\nelif selection == 4:\n  model_type = models.ross.efficientdet\n  backbone = model_type.backbones.tf_lite0\n  # The efficientdet model requires an img_size parameter\n  extra_args['img_size'] = image_size\n\nelif selection == 5:\n  model_type = models.ultralytics.yolov5\n  backbone = model_type.backbones.small\n  # The yolov5 model requires an img_size parameter\n  extra_args['img_size'] = image_size\n\nmodel_type, backbone, extra_args","c9cc0c36":"# Instantiate the mdoel\nmodel = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args) ","d34d6663":"# Data Loaders\ntrain_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=2, shuffle=True)\nvalid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=2, shuffle=False)","2a42463d":"# show batch\nmodel_type.show_batch(first(valid_dl), ncols=4)","45c0c3e9":"metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]","fb8e20bf":"learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)","4d8203fa":"learn.lr_find()","3beff5ca":"lr = 2e-4 #1e-2 for EfficientDet, 1e-4 for the others. Check out the lr_find() plot\nlearn.fine_tune(20, lr, freeze_epochs=1)","71b00fb5":"# class LightModel(model_type.lightning.ModelAdapter):\n#     def configure_optimizers(self):\n#         return SGD(self.parameters(), lr=1e-4)\n    \n# light_model = LightModel(model, metrics=metrics)","743a7f80":"# trainer = pl.Trainer(max_epochs=20, gpus=1)\n# trainer.fit(light_model, train_dl, valid_dl)","4107bfc6":"model_type.show_results(model, valid_ds, detection_threshold=.5)","2f89ef5c":"infer_dl = model_type.infer_dl(valid_ds, batch_size=4, shuffle=False)\npreds = model_type.predict_from_dl(model, infer_dl, keep_images=True)","99afbaa8":"show_preds(preds=preds[:4])","16c3cbb0":"## Happy Competition!\n\nIceVision is built around an awesome community where IceVision users learn from each other, and share their knowledge\/experience. Feel free to join our [forum](https:\/\/discord.gg\/JDBeZYK)."}}