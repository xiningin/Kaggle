{"cell_type":{"fa663e1e":"code","fec48c09":"code","da975c7d":"code","1e636ea6":"code","1b9568a2":"code","507f1cc7":"code","49bcf21f":"code","21928728":"code","988792bb":"code","99030fad":"code","cae41ef5":"code","a162c060":"code","58be7c8e":"code","1ee9ca33":"code","010695fa":"code","8eb6b109":"code","13823cf0":"code","827b7d30":"code","858200c4":"code","2b10f31c":"code","baa33862":"code","5c5f95ff":"code","dc29bde4":"code","4123f28a":"code","b5a3a378":"code","9816e22e":"code","aa014c0e":"code","6aca90c7":"code","0963d143":"code","8be0e723":"code","06b643f4":"code","2ff74860":"code","94553a70":"code","2029b14a":"code","b10ce9a2":"code","f7fd74f2":"code","7b52fd47":"code","2d8f1c49":"code","8113d224":"code","d89f9835":"code","05140105":"code","f7da8a19":"code","24fcf7ec":"code","00ed65e0":"code","9e4fb673":"code","cf2a3626":"code","bf4f5c0c":"code","6b228906":"code","4831e42e":"code","a15ff637":"code","047a8db2":"code","00d6b683":"code","e1c7baef":"code","164d2b04":"code","5dc283ed":"code","ba0b15fb":"code","c2b8e722":"code","1e54fd47":"code","2788926f":"code","eb1a2c06":"code","91955c00":"markdown"},"source":{"fa663e1e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fec48c09":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","da975c7d":"submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndescription = pd.read_table(\"..\/input\/house-prices-advanced-regression-techniques\/data_description.txt\", delim_whitespace=True, error_bad_lines=False)","1e636ea6":"train.columns\n","1b9568a2":"train['SalePrice'].describe()\n","507f1cc7":"corrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","49bcf21f":"sns.distplot(train['SalePrice']);\n","21928728":"k = 20\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.75)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()\n","988792bb":"fig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()\n","99030fad":"train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<800000)].index)\n\n\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","cae41ef5":"var = 'TotalBsmtSF'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","a162c060":"train = train.drop(train[(train['TotalBsmtSF']>2800) & (train['SalePrice']<600000)].index)\n\n\nfig, ax = plt.subplots()\nax.scatter(train['TotalBsmtSF'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('TotalBsmtSF', fontsize=13)\nplt.show()","58be7c8e":"train_numeric = train.select_dtypes(include='number')\ntrain_numeric","1ee9ca33":"sns.distplot(train_numeric['SalePrice'], bins=50, kde=True, rug=True)\n","010695fa":"train_non_numeric = train.select_dtypes(exclude='number')\n\n\nplt.figure(figsize=(25,7))\nsns.countplot(x=\"SaleCondition\", data=train_non_numeric)","8eb6b109":"train_non_numeric = train.select_dtypes(exclude='number')\n\n\nplt.figure(figsize=(25,7))\nsns.countplot(x=\"Functional\", data=train_non_numeric)","13823cf0":"train_non_numeric = train.select_dtypes(exclude='number')\n\n\nplt.figure(figsize=(25,7))\nsns.countplot(x=\"HouseStyle\", data=train_non_numeric)","827b7d30":"train_non_numeric = train.select_dtypes(exclude='number')\n\n\nplt.figure(figsize=(25,7))\nsns.countplot(x=\"Functional\", data=train_non_numeric)","858200c4":"train_non_numeric = train.select_dtypes(exclude='number')\n\n\nplt.figure(figsize=(25,7))\nsns.countplot(x=\"LandContour\", data=train_non_numeric)","2b10f31c":"import math\ndef plot_multiple_countplots(df, cols):\n    num_plots = len(cols)\n    num_cols = math.ceil(np.sqrt(num_plots))\n    num_rows = math.ceil(num_plots\/num_cols)\n        \n    fig, axs = plt.subplots(num_rows, num_cols)\n    \n    for ind, col in enumerate(cols):\n        i = math.floor(ind\/num_cols)\n        j = ind - i*num_cols\n        \n        if num_rows == 1:\n            if num_cols == 1:\n                sns.countplot(x=df[col], ax=axs)\n            else:\n                sns.countplot(x=df[col], ax=axs[j])\n        else:\n            sns.countplot(x=df[col], ax=axs[i, j])\n            \n            \nplot_multiple_countplots(train_non_numeric, ['LandContour', 'HouseStyle', 'Functional', 'SaleCondition'])","baa33862":"print (\"Skew is:\", train.SalePrice.skew())\nplt.hist(train.SalePrice, color='green')\nplt.show()","5c5f95ff":"train['SalePrice'] = np.log(train.SalePrice)\nprint (\"Skew is:\", train['SalePrice'].skew())\nplt.hist(train['SalePrice'], color='green')\nplt.show()","dc29bde4":"train['SaleCondition'].value_counts()","4123f28a":"train['HouseStyle'].value_counts()","b5a3a378":"train['Functional'].value_counts()","9816e22e":"train['RoofStyle'].value_counts()","aa014c0e":"train['SaleType'].value_counts()\n","6aca90c7":"train_roof_year = train.groupby(['RoofStyle', 'SalePrice'])['YearBuilt'].count().reset_index()\ntrain_roof_year_pivot = train_roof_year.pivot(index='RoofStyle', columns='SalePrice', values='YearBuilt').fillna(0)\nsns.heatmap(train_roof_year_pivot, annot=True, fmt='.0f', cmap=\"YlGnBu\")","0963d143":"cols = ['HouseStyle', 'Functional', 'YearBuilt', 'SaleType', 'RoofStyle', 'SaleCondition', 'SalePrice']\ntrain_test = train[cols]\ntrain_test.head()","8be0e723":"numeric_columns = set(train_test.select_dtypes(include=['number']).columns)\nnon_numeric_columns = set(train_test.columns) - numeric_columns\nprint(numeric_columns)\nprint(non_numeric_columns)","06b643f4":"for c in non_numeric_columns:\n    cnt = train_test[c].value_counts()\n    small_cnts = list(cnt[cnt < 5].index)\n    \n    s_replace = {}\n    for sm in small_cnts:\n        s_replace[sm] = 'other'\n    \n    train_test[c] = train_test[c].replace(s_replace)\n    train_test[c] = train_test[c].fillna('other')","2ff74860":"from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# we are going to look at feature importances so we like putting random features to act as a benchmark.\ntrain_test['rand0'] = np.random.rand(train_test.shape[0])\ntrain_test['rand1'] = np.random.rand(train_test.shape[0])\ntrain_test['rand2'] = np.random.rand(train_test.shape[0])\n\n# testing for relationships.\n# for numeric targets.\nreg = GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, loss='ls', random_state=1)\n# for categorical targets.\nclf = GradientBoostingClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, loss='deviance', random_state=1)\n\ntrain_test['YearBuilt'] = train_test['YearBuilt'].fillna(0) # only YearBuilt should have missing values.\n        \n# try to predict one feature using the rest of others to test collinearity, so it's easier to interpret the results\nfor c in cols:\n    # c is the thing to predict.\n    \n    if c not in ['rand0', 'rand1', 'rand2']: \n\n        X = train_test.drop([c], axis=1) # drop the thing to predict.\n        X = pd.get_dummies(X)\n        y = train_test[c]\n\n        print(c)\n\n        if c in non_numeric_columns:\n            scoring = 'accuracy'\n            model = clf\n            scores = cross_val_score(clf, X, y, cv=5, scoring=scoring)\n            print(scoring + \": %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n        elif c in numeric_columns:\n            scoring = 'neg_root_mean_squared_error'\n            model = reg\n            scores = cross_val_score(reg, X, y, cv=5, scoring=scoring)\n            print(scoring.replace('neg_', '') + \": %0.2f (+\/- %0.2f)\" % (-scores.mean(), scores.std() * 2))\n        else:\n            print('what is this?')\n\n        model.fit(X, y)\n        train_importances = pd.DataFrame(data={'feature_name': X.columns, 'importance': model.feature_importances_}).sort_values(by='importance', ascending=False)\n        top5_features = train_importances.iloc[:5]\n        print('top 5 features:')\n        print(top5_features)\n\n        print()","94553a70":"# SaleType, SaleCondition\n\nsns.relplot(x='SaleCondition', y='SaleType', size='SalePrice', sizes=(7, 1200), data=train, aspect=4.0)","2029b14a":"missing = train.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","b10ce9a2":"train.shape","f7fd74f2":"test.shape","7b52fd47":"pd.set_option(\"display.max_columns\", 81)","2d8f1c49":"train.isna().sum().sum()","8113d224":"dataframe_train = train.drop('Id',1)\nY_train = dataframe_train['SalePrice']\ndf_features_train = dataframe_train.drop('SalePrice',1)\n\nprint(Y_train.shape, df_features_train.shape)","d89f9835":"df_features_test = test.drop('Id',1)\n\nprint(df_features_test.shape)","05140105":"na_total = df_features_train.isnull().sum().sort_values(ascending=False) ## FInding total null values\ndf_features_train.fillna(0,inplace=True)","f7da8a19":"na_total = df_features_test.isnull().sum().sort_values(ascending=False) ## FInding total null values\ndf_features_test.fillna(0,inplace=True)\n","24fcf7ec":"numeric_cols = [x for x in df_features_train.columns if ('Area' in x) | ('SF' in x)]+['LotFrontage','MiscVal','EnclosedPorch','3SsnPorch','ScreenPorch','OverallQual','OverallCond','YearBuilt']\n","00ed65e0":"categorical_cols = [x for x in df_features_train.columns if x not in numeric_cols]\n","9e4fb673":"numeric_cols_test = [x for x in df_features_test.columns if ('Area' in x) | ('SF' in x)]+['LotFrontage','MiscVal','EnclosedPorch','3SsnPorch','ScreenPorch','OverallQual','OverallCond','YearBuilt']","cf2a3626":"categorical_cols_test = [x for x in df_features_test.columns if x not in numeric_cols_test]","bf4f5c0c":"train_num = df_features_train[numeric_cols]\ntrain_cat = df_features_train[categorical_cols]\ntest_num = df_features_test[numeric_cols_test]\ntest_cat = df_features_test[categorical_cols_test]","6b228906":"Y_train = np.log(Y_train)\nY_train.hist()","4831e42e":"train = pd.concat([train_cat,train_num],axis=1)\ntrain.shape","a15ff637":"train_objs_num = len(train)\nprint(train_objs_num)","047a8db2":"test = pd.concat([test_cat,test_num],axis=1)\ntest.shape","00d6b683":"dataset = pd.concat(objs=[train, test], axis=0)\ndataset = pd.get_dummies(dataset)\n\ntrain = dataset[:train_objs_num]\ntest = dataset[train_objs_num:]\nprint(train.shape,test.shape)","e1c7baef":"from sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.impute import SimpleImputer","164d2b04":"model = linear_model.LinearRegression()\nmodel.fit(train,Y_train)","5dc283ed":"prediction =  model.predict(test)\nfinal_prediction = np.exp(prediction)\nprint(final_prediction)","ba0b15fb":"main_file_path = '..\/input\/house-prices-advanced-regression-techniques\/test.csv'\ndataframe = pd.read_csv(main_file_path)\ndataframe.head()\ndataframe.info()","c2b8e722":"dataframe['Id']","1e54fd47":"Submission = pd.DataFrame()\nSubmission['ID'] = dataframe.Id\nSubmission.info()","2788926f":"Submission['SalePrice'] = final_prediction\nprint(Submission.head())","eb1a2c06":"Submission.to_csv('submission.csv', index=False)","91955c00":"# Data exploration"}}