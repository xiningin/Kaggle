{"cell_type":{"00a60d31":"code","b8188abb":"code","bce35c67":"code","da21e3bb":"code","cbd3e266":"code","00629bb8":"code","03583a7c":"code","1eebded7":"code","be1662fb":"code","e04f62b9":"code","193ee4a8":"code","f58b81b2":"code","206fdf99":"code","0ec27eb5":"code","c29804cf":"code","a6d2b080":"code","9bb608cd":"code","490cf1a0":"code","f8346c69":"code","c72f844b":"code","7c2ca2ff":"code","7f013ed3":"code","339dfe53":"code","c9b020c6":"code","b22b7197":"code","86377c79":"code","9752c342":"code","d0544e63":"code","76cf8c0e":"code","a0d4e8f2":"code","961678ae":"code","7f41143e":"code","e6f32076":"code","b99f9554":"code","e299add4":"code","546a0bfb":"code","c29a5c81":"markdown","a09063ec":"markdown","f58e43b8":"markdown","6dfd94bd":"markdown","5fd60566":"markdown","cd45fcd5":"markdown","9bc4f627":"markdown","a67a42bf":"markdown","71966531":"markdown"},"source":{"00a60d31":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.experimental import enable_iterative_imputer  \nfrom sklearn.impute import IterativeImputer\n\nimport lightgbm as lgbm\nimport xgboost as xgb\nimport catboost as cat\n\nimport optuna\n\nimport missingno as msno\n\n%matplotlib inline","b8188abb":"train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")","bce35c67":"train.head(5)","da21e3bb":"train.info()","cbd3e266":"train[\"song_popularity\"].describe()","00629bb8":"sns.histplot(data=train, x=\"song_popularity\", bins=2);","03583a7c":"# Skewness\ntrain[\"song_popularity\"].value_counts(normalize=True)* 100","1eebded7":"# unique values ( <= 15 -> Categorical Features)\ntrain.nunique() > 15","be1662fb":"numerical_cols = ['song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'audio_valence']","e04f62b9":"train.isnull().sum()","193ee4a8":"msno.bar(train, color=(.6, .4, .4));","f58b81b2":"msno.matrix(train, color=(0.55, 0.25, 0.75));","206fdf99":"msno.heatmap(train);","0ec27eb5":"def corr_map(df):\n    corr = df[numerical_cols].corr()\n    mask = np.zeros_like(corr, dtype='bool')\n    mask[np.triu_indices_from(mask)] = True\n    plt.subplots(figsize=(11, 9))\n    sns.heatmap(corr, mask=mask, annot=True);    ","c29804cf":"corr_map(train[numerical_cols])","a6d2b080":"def feature_plot(df, feature, color, ax):\n    sns.kdeplot(data=df, x=feature, color=color, fill=True, ax = ax)\n    ax.set_title(feature)","9bb608cd":"fig, ax = plt.subplots(5, 2, figsize=(12,16))\ncounter = 0\nfor i in range(5):\n    for j in range(2):\n        feature_plot(train, numerical_cols[counter], \"red\", ax[i,j])\n        counter += 1\nplt.subplots_adjust(wspace=0.4, hspace=0.8)\nplt.show()","490cf1a0":"fig, ax = plt.subplots(1, 3, figsize=(16, 6))\nsns.countplot(x=train['time_signature'], ax = ax[0])\nsns.countplot(x=train['audio_mode'], ax = ax[1])\nsns.countplot(x=train['key'], ax = ax[2])\nplt.show()","f8346c69":"columns = [c for c in train.columns if c not in (\"id\", \"song_popularity\")]\nX = train[columns]\ny = train[\"song_popularity\"]","c72f844b":"def run(trial, data=X,target=y):\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=42)\n    params = {\n        'metric': 'auc', \n        'random_state': 22,\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [9000, 10000, 11000, 12000, 13000, 14000]),\n        'boosting_type': trial.suggest_categorical(\"boosting_type\", [\"gbdt\"]),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n        'bagging_fraction': trial.suggest_categorical('bagging_fraction', [.4, .5, .45, 0.6, 0.7]),\n        'feature_fraction': trial.suggest_categorical('feature_fraction', [.3, .4, .5, 0.6, 0.7, 0.80]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [.018, .0186, .0192, 0.0196, .0193, .0199]),\n        'max_depth': trial.suggest_int('max_depth', 5, 20, step=1),\n        'num_leaves' : trial.suggest_int('num_leaves', 650, 850, step=5),\n        'min_child_samples': trial.suggest_int('min_child_samples', 40, 80, step=5),      \n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 300, 600, step=20),\n        \"max_bin\": trial.suggest_int(\"max_bin\", 250, 350),\n        'min_gain_to_split': trial.suggest_categorical('min_gain_to_split', [0.02084372652774491, 0.01084372652774491, 0.03084372652774491]),\n    }\n    \n    clf = lgbm.LGBMClassifier(**params)  \n    clf.fit(\n            X_train, y_train,\n            eval_set=[(X_valid, y_valid), (X_train, y_train)],\n            callbacks=[lgbm.log_evaluation(period=100), lgbm.early_stopping(stopping_rounds=100)],           \n    )\n    \n    y_proba = clf.predict_proba(X_valid)[:, 1]\n    auc = roc_auc_score(y_valid, y_proba)\n    return auc","7c2ca2ff":"# best_params = optuna.create_study(direction='maximize')\n# best_params.optimize(run, n_trials=100)\n# best_params.best_params\n# best_params.best_value","7f013ed3":"imputer = IterativeImputer()\ntrain = pd.DataFrame(imputer.fit_transform(train), columns=train.columns)\ntest = pd.DataFrame(imputer.fit_transform(test), columns=test.columns)","339dfe53":"X = train[columns]\ny = train['song_popularity']\nX_test = test[columns]","c9b020c6":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = []\n\nlgbm_params = {\n    'boosting_type': 'gbdt',\n    'n_estimators': 9000,\n    'learning_rate': 0.0196,\n    'num_leaves': 740,\n    'min_child_samples': 60,\n    'max_depth': 12,\n    'min_data_in_leaf': 500,\n    'max_bin': 280,\n    'lambda_l1': 0.49149217034909334,\n    'lambda_l2': 0.017202393346011927,\n    'min_gain_to_split': 0.02084372652774491,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 1,\n    'feature_fraction': 0.4,\n}\n\nOOF_PREDS = np.array([0.0] * len(X))\nTEST_PREDS = np.array([0.0] * len(X_test))\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    \n    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n    y_train , y_valid = y.iloc[train_idx], y.iloc[val_idx]\n    \n    model = lgbm.LGBMClassifier(**lgbm_params)\n    model.fit(\n        X_train, \n        y_train,\n        eval_set=[(X_valid, y_valid), (X_train, y_train)],\n        callbacks=[lgbm.log_evaluation(period=100), lgbm.early_stopping(stopping_rounds=100)],\n\n    )\n    \n    valid_preds = model.predict_proba(X_valid)[:,1]\n    OOF_PREDS[val_idx] = valid_preds\n    score = roc_auc_score(y_valid, valid_preds)\n    scores.append(score)\n    print(f\"Fold: {fold}, AUC: {score}\")\n    test_pred = model.predict_proba(X_test)[:,1]\n    TEST_PREDS += test_pred \/ 5\n    \nprint(np.mean(scores))    \n    \n    ","b22b7197":"oof_preds = pd.DataFrame(columns = ['id', 'song_popularity'])\noof_preds['id'] = train.index\noof_preds['song_popularity'] = OOF_PREDS\noof_preds.to_csv(\"lgb_oof.csv\", index=False)\noof_preds","86377c79":"submission = pd.DataFrame(columns = ['id', 'song_popularity'])\nsubmission['id'] = test.index\nsubmission['song_popularity'] = TEST_PREDS\nsubmission.to_csv(\"lgb_test.csv\", index=False)\nsubmission","9752c342":"def run(trial, data=X,target=y):\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=42)\n    \n    param = {\n        'tree_method':'gpu_hist',\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': 4000,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }    \n    \n    clf = xgb.XGBClassifier(**param)\n    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid), (X_train, y_train)], verbose=20)\n    \n    y_proba = clf.predict_proba(X_valid)[:, 1]\n    auc = roc_auc_score(y_valid, y_proba)\n    return auc\n","d0544e63":"# best_params = optuna.create_study(direction='maximize')\n# best_params.optimize(run, n_trials=50)","76cf8c0e":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = []\n\nxgb_params= {\n    'tree_method':'gpu_hist', \n    'gpu_id': 0,\n    'max_depth': 12,\n    'n_estimators': 5600,\n    'learning_rate': 0.07074059946646541,\n    'subsample': 0.8,\n    'colsample_bytree': 0.6000000000000001,\n    'colsample_bylevel': 0.5,\n    'min_child_weight': 0.00390933891195369,\n    'reg_lambda': 2176.9882633091584,\n    'reg_alpha': 0.00027465681042320085,\n    'gamma': 0.45590270702576924\n}\n\n\nOOF_PREDS = np.array([0.0] * len(X))\nTEST_PREDS = np.array([0.0] * len(X_test))\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    \n    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n    y_train , y_valid = y.iloc[train_idx], y.iloc[val_idx]\n    \n    model = xgb.XGBRegressor(**xgb_params)\n    model.fit(X_train,y_train,verbose=20)\n    \n    valid_preds = model.predict(X_valid)\n    OOF_PREDS[val_idx] = valid_preds\n    score = roc_auc_score(y_valid, valid_preds)\n    scores.append(score)\n    print(f\"Fold: {fold} - AUC: {score}\")\n    test_pred = model.predict(X_test[columns])\n    TEST_PREDS += test_pred \/ 5\n    \nprint(f\"Mean: {np.mean(scores)}\")    ","a0d4e8f2":"oof_preds = pd.DataFrame(columns = ['id', 'song_popularity'])\noof_preds['id'] = train.index\noof_preds['song_popularity'] = OOF_PREDS\noof_preds.to_csv(\"xgb_oof.csv\", index=False)\noof_preds","961678ae":"submission = pd.DataFrame(columns = ['id', 'song_popularity'])\nsubmission['id'] = test.index\nsubmission['song_popularity'] = TEST_PREDS\nsubmission.to_csv(\"xgb_test.csv\", index=False)\nsubmission","7f41143e":"def run(trial, data=X,target=y):    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=42)\n    \n    param = {\n        'learning_rate': trial.suggest_discrete_uniform(\"learning_rate\", 0.001, 0.02, 0.001),\n        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n        'depth': trial.suggest_int('depth', 9, 15),\n        'min_child_samples': trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32]),\n        'iterations': trial.suggest_categorical('iterations', [5, 10, 15, 25, 50]),        \n    }    \n    clf = cat.CatBoostRegressor(**param)\n    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=20, early_stopping_rounds=100)\n    \n    y_proba = model.predict(X_valid)    \n    auc = roc_auc_score(y_valid, y_proba)\n    \n    return auc    ","e6f32076":"# best_params = optuna.create_study(direction='maximize')\n# best_params.optimize(run, n_trials=50)","b99f9554":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = []\n\nparams = {\n    'learning_rate': 0.007,\n    'depth': 10,\n    'l2_leaf_reg': 1.5,\n    'min_child_samples': 4\n}\n\nOOF_PREDS = np.array([0.0] * len(X))\nTEST_PREDS = np.array([0.0] * len(X_test))\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    \n    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n    y_train , y_valid = y.iloc[train_idx], y.iloc[val_idx]\n    \n    model = cat.CatBoostRegressor(**params)\n    model.fit(X_train, y_train,verbose=False)\n    \n    valid_preds = model.predict(X_valid)    \n    OOF_PREDS[val_idx] = valid_preds\n    score = roc_auc_score(y_valid, valid_preds)    \n    scores.append(score)    \n    print(f\"Fold: {fold} - AUC: {score}\")\n    test_pred = model.predict(X_test[columns])\n    TEST_PREDS += test_pred \/ 5\n    \nprint(f\"Mean: {np.mean(scores)}\")","e299add4":"oof_preds = pd.DataFrame(columns = ['id', 'song_popularity'])\noof_preds['id'] = train.index\noof_preds['song_popularity'] = OOF_PREDS\noof_preds.to_csv(\"cb_oof.csv\", index=False)\noof_preds","546a0bfb":"submission = pd.DataFrame(columns = ['id', 'song_popularity'])\nsubmission['id'] = test.index\nsubmission['song_popularity'] = TEST_PREDS\nsubmission.to_csv(\"cb_test.csv\", index=False)\nsubmission","c29a5c81":"# Features Analysis","a09063ec":"# EDA \n### Feature Distribution","f58e43b8":"### Categorical Features","6dfd94bd":"### Numeric Features","5fd60566":"# LGBM","cd45fcd5":"# Missing Values","9bc4f627":"# XGBoost","a67a42bf":"# CatBoost","71966531":"# Target Analysis"}}