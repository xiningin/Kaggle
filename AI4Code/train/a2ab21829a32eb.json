{"cell_type":{"04107dce":"code","e2b54182":"code","ca1d2862":"code","263989b9":"code","159e9b6b":"code","127f42cf":"code","98d88073":"code","c210de36":"code","ab8f4b3b":"code","2d70b9e7":"code","ea887605":"code","9002840c":"code","a3df0591":"code","887077be":"code","bc4e5608":"code","53eb3263":"code","75f7f60d":"code","2823101c":"code","6f454d76":"code","e49d816e":"code","0c2b7743":"code","0f80d273":"code","e5dff292":"code","b5e6232e":"code","c4969a84":"code","b0f77a80":"code","63af7341":"code","f5290b90":"code","354cc3ac":"code","01d01d05":"code","91fd3ff5":"code","2de70cae":"code","8dfeff58":"code","400ba027":"code","07bf054a":"code","42d3690f":"code","804e74c7":"code","1d796f0b":"code","f45ecda8":"code","b55bf7ba":"code","f06d65ed":"code","01c023d7":"code","d10f7844":"code","47039238":"code","f5e4cbe0":"code","1f09e11b":"code","8104ca52":"code","35fc411c":"code","8262ee42":"code","a12f556e":"code","af75d0b9":"code","12a97936":"code","b65b0ba3":"markdown","bfb96927":"markdown","3aba36df":"markdown","06ed0b71":"markdown","a33009d5":"markdown","696d3cfb":"markdown"},"source":{"04107dce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e2b54182":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n\nimport xgboost as xgb","ca1d2862":"import matplotlib.pyplot as plt\nplt.style.use('classic')","263989b9":"df = pd.read_csv('..\/input\/costa-rican-household-poverty-prediction\/train.csv', index_col='Id')\ndf.info()","159e9b6b":"df_nans = df.isna().sum()[df.isna().sum() >0]\ndf_nans","127f42cf":"df[df_nans.index].info()","98d88073":"df[df_nans.index].describe()","c210de36":"fig, axs = plt.subplots(1,5,figsize=(24,8))\n\nfor idx, col in enumerate(df_nans.index):\n    axs[idx].set_title(col)\n    axs[idx].boxplot(df[col].dropna(axis=0))\n\nplt.show()","ab8f4b3b":"def fill_nas(df):\n    df['v2a1'] = df['v2a1'].fillna(df['v2a1'].median())\n    df['meaneduc'] = df['meaneduc'].fillna(df['meaneduc'].median())\n    df['SQBmeaned'] = df['SQBmeaned'].fillna(df['SQBmeaned'].median())\n    df['v18q1'] = df['v18q1'].fillna(-1)\n    df['rez_esc'] = df['rez_esc'].fillna(-1)\n    return df","2d70b9e7":"df = fill_nas(df)","ea887605":"df.isna().sum()[df.isna().sum() >0]","9002840c":"df.select_dtypes(include=['object'])","a3df0591":"df['edjefe'].unique()","887077be":"df['edjefa'].unique()","bc4e5608":"df['dependency'].unique()","53eb3263":"def replace_yes_no(df, column):\n    df['{}_yes'.format(column)] = df[column].apply(lambda row: 1 if row=='yes' else 0)\n    df['{}_no'.format(column)] = df[column].apply(lambda row: 1 if row=='no' else 0)\n    df[column] = df[column].apply(lambda row: row if row not in ['yes', 'no'] else -1)\n    df[column] = pd.to_numeric(df[column])\n    return df","75f7f60d":"def replace_yes_no_all(df):\n    df = replace_yes_no(df, 'edjefe')\n    df = replace_yes_no(df, 'edjefa')\n    df = replace_yes_no(df, 'dependency')\n    return df","2823101c":"df = replace_yes_no_all(df)","6f454d76":"fig, axs = plt.subplots(1,3,figsize=(24,8))\n\naxs[0].hist(df['dependency'])\naxs[1].hist(df['edjefe'])\naxs[2].hist(df['edjefa'])\n\nplt.show()\n","e49d816e":"df.select_dtypes(include=['float64'])","0c2b7743":"df['Target']","0f80d273":"# add the number of people over 18 in each household\ndef add_over_18(df):\n    df['num_over_18'] = 0\n    df['num_over_18'] = df[df.age >= 18].groupby('idhogar').transform(\"count\")\n    df['num_over_18'] = df.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n    df['num_over_18'] = df['num_over_18'].fillna(0)\n    return df\n\ndf = add_over_18(df)\n# add some extra features, these were taken from another kernel\ndef extract_features(df):\n    df['bedrooms_to_rooms'] = df['bedrooms']\/df['rooms']\n    df['rent_to_rooms'] = df['v2a1']\/df['rooms']\n    df['tamhog_to_rooms'] = df['tamhog']\/df['rooms'] # tamhog - size of the household\n    df['r4t3_to_tamhog'] = df['r4t3']\/df['tamhog'] # r4t3 - Total persons in the household\n    df['r4t3_to_rooms'] = df['r4t3']\/df['rooms'] # r4t3 - Total persons in the household\n    df['v2a1_to_r4t3'] = df['v2a1']\/df['r4t3'] # rent to people in household\n    df['v2a1_to_r4t3'] = df['v2a1']\/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n    df['hhsize_to_rooms'] = df['hhsize']\/df['rooms'] # rooms per person\n    df['rent_to_hhsize'] = df['v2a1']\/df['hhsize'] # rent to household size\n    df['rent_to_over_18'] = df['v2a1']\/df['num_over_18']\n    # some households have no one over 18, use the total rent for those\n    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n    return df\n    \ndf = extract_features(df) ","e5dff292":"X = df.drop(['Target', 'idhogar'], axis=1)\ny = df['Target']","b5e6232e":"y = y.apply(lambda row: row-1)","c4969a84":"etc = ExtraTreesClassifier(n_estimators=50)\nclf = etc.fit(X, y)\nvs_model = SelectFromModel(clf, prefit=True)\nX_selected = vs_model.transform(X)\nX_selected","b0f77a80":"X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)","63af7341":"fit_params={\"eval_metric\" : 'merror', \n            \"eval_set\" : [(X_train,y_train), (X_test, y_test)],\n           }","f5290b90":"xgb_model = xgb.XGBClassifier(n_jobs=4)\nxgb_model.fit(X_train, y_train, **fit_params)","354cc3ac":"y_pred = xgb_model.predict(X_test)","01d01d05":"y_pred","91fd3ff5":"confusion_matrix(y_test, y_pred)","2de70cae":"accuracy_score(y_test, y_pred)","8dfeff58":"f1_score(y_test, y_pred, average='macro')","400ba027":"rf_model = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\nrf_model.fit(X_train, y_train)","07bf054a":"y_rf_pred = rf_model.predict(X_test)\nconfusion_matrix(y_test, y_rf_pred)","42d3690f":"accuracy_score(y_test, y_rf_pred)","804e74c7":"f1_score(y_test, y_rf_pred, average='macro')","1d796f0b":"gb_model = GradientBoostingClassifier(random_state=42)\ngb_model.fit(X_train, y_train)","f45ecda8":"y_gb_pred = gb_model.predict(X_test)\nconfusion_matrix(y_test, y_gb_pred)","b55bf7ba":"accuracy_score(y_test, y_gb_pred)","f06d65ed":"f1_score(y_test, y_gb_pred, average='macro')","01c023d7":"df_submit = pd.read_csv('..\/input\/costa-rican-household-poverty-prediction\/test.csv', index_col='Id')","d10f7844":"df_submit.isna().sum()[df_submit.isna().sum() >0]","47039238":"df_submit_cleaned = df_submit","f5e4cbe0":"df_submit_cleaned = replace_yes_no_all(df_submit_cleaned)\ndf_submit_cleaned = fill_nas(df_submit_cleaned)\ndf_submit_cleaned = add_over_18(df_submit_cleaned)\ndf_submit_cleaned = extract_features(df_submit_cleaned)","1f09e11b":"df_submit_cleaned = df_submit.drop(['idhogar'], axis=1)","8104ca52":"X_submit_selected = vs_model.transform(df_submit_cleaned)\nX_submit_selected","35fc411c":"y_submit_raw = rf_model.predict(X_submit_selected)","8262ee42":"y_submit = pd.DataFrame(y_submit_raw, index=df_submit_cleaned.index, columns=['Target'])","a12f556e":"y_submit['Target'].unique()","af75d0b9":"y_submit['Target'] = y_submit['Target'].apply(lambda row: row+1)\ny_submit['Target'].unique()","12a97936":"y_submit.to_csv('submission.csv')","b65b0ba3":"# xgboost","bfb96927":"# Finish","3aba36df":"# Random forest","06ed0b71":"# Feature Engineering\nfonte: https:\/\/www.kaggle.com\/skooch\/xgboost","a33009d5":"## Categorical","696d3cfb":"# Gradient Boosting"}}