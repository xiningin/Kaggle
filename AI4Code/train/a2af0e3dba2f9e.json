{"cell_type":{"a975917d":"code","6d44f594":"code","c1f31a73":"code","c2e948ae":"code","e6bac6ef":"code","babdb5c6":"code","a0641374":"code","c7969189":"code","c0899ee6":"code","86bf0a9f":"code","284397e7":"code","08ff4017":"code","45c42599":"code","7105b7e2":"code","6f6d6976":"code","40e3cc88":"code","f89e2eea":"code","82fd2dea":"code","3e97c4bc":"code","77582863":"code","18c4075c":"code","e15fa270":"markdown","8c0f6af4":"markdown","5679513d":"markdown","7d0cdab9":"markdown","14a2c361":"markdown","7c97d24f":"markdown","377a079d":"markdown","ce64d124":"markdown","dec95587":"markdown","aef9d34e":"markdown","39b2faf6":"markdown","68f4d699":"markdown","0359f981":"markdown","584775fa":"markdown"},"source":{"a975917d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport seaborn as sns\nsns.set(style='white', context='notebook', palette='Set2')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","6d44f594":"train_df = pd.read_csv(\"..\/input\/train_V2.csv\")\ntest_df = pd.read_csv(\"..\/input\/test_V2.csv\")","c1f31a73":"train_df.head()","c2e948ae":"train_df.describe()","e6bac6ef":"test_df.describe()","babdb5c6":"pd.DataFrame({'train':train_df.isna().sum(), 'test':test_df.isna().sum()})","a0641374":"train_df = train_df.dropna()","c7969189":"drop_features = [\"Id\", \"groupId\", \"matchId\"]\nfeats = [f for f in train_df.columns if f not in drop_features]\n\nplt.figure(figsize=(18,16))\nsns.heatmap(train_df[feats].corr(), linewidths=0.1,vmax=1.0,\n               square=True, linecolor='white', annot=True, cmap=\"RdBu\")","c0899ee6":"plt.figure(figsize=(12,6))\nsns.distplot(train_df['winPlacePerc'].values, bins=100, kde=False)","86bf0a9f":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","284397e7":"dataset = pd.concat([train_df, test_df], sort=True)\ndataset = reduce_mem_usage(dataset)","08ff4017":"plt.figure(figsize=(12,6))\nplt.title('Number of Team Members')\ntmp = dataset.groupby(['matchId','groupId'])['Id'].agg('count')\nsns.countplot(tmp)","45c42599":"plt.figure(figsize=(12,6))\nplt.title('Number of Team Members')\nax = sns.countplot(x='matchType', data=dataset)\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()","7105b7e2":"# https:\/\/www.kaggle.com\/rejasupotaro\/effective-feature-engineering\ndef min_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId','groupId'])[features].min()\n    return df.merge(agg, suffixes=['', '_min'], how='left', on=['matchId', 'groupId'])\n\ndef max_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].max()\n    return df.merge(agg, suffixes=['', '_max'], how='left', on=['matchId', 'groupId'])\n\ndef sum_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].sum()\n    return df.merge(agg, suffixes=['', '_sum'], how='left', on=['matchId', 'groupId'])\n\ndef median_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].median()\n    return df.merge(agg, suffixes=['', '_median'], how='left', on=['matchId', 'groupId'])\n\ndef mean_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n    return df.merge(agg, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n\ndef rank_by_team(df):\n    cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']\n    features = [col for col in df.columns if col not in cols_to_drop]\n    agg = df.groupby(['matchId', 'groupId'])[features].mean()\n    agg = agg.groupby('matchId')[features].rank(pct=True)\n    return df.merge(agg, suffixes=['', '_mean_rank'], how='left', on=['matchId', 'groupId'])","6f6d6976":"dataset = pd.concat([train_df, test_df], sort=True)\ndataset = reduce_mem_usage(dataset)\n\n# dataset = mean_by_team(dataset)\ndataset = rank_by_team(dataset)\ngc.collect()\n\ndataset.head()","40e3cc88":"from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.metrics import mean_absolute_error","f89e2eea":"def oof_model_preds(df, model, num_folds, params):\n    # Divide in training\/validation and test data\n    train_df = df[df['winPlacePerc'].notnull()]\n    test_df = df[df['winPlacePerc'].isnull()]\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n    del df\n    gc.collect()\n\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n\n    drop_features = ['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc']    \n    feats = [f for f in train_df.columns if f not in drop_features]\n\n    # Create model\n    if num_folds == 1:\n        train_x, valid_x, train_y, valid_y = train_test_split(train_df[feats], train_df['winPlacePerc'], test_size=0.2, random_state=1001)\n        model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n            eval_metric= 'mae', verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'])\n\n        oof_preds = model.predict(train_df[feats])\n        sub_preds = model.predict(test_df[feats])\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = model.feature_importances_\n        fold_importance_df[\"fold\"] = 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('MAE : %.6f' % (mean_absolute_error(train_df['winPlacePerc'], oof_preds)))\n        del train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    # Cross validation model\n    elif num_folds > 1:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['winPlacePerc'])):\n            train_x, train_y = train_df[feats].iloc[train_idx], train_df['winPlacePerc'].iloc[train_idx]\n            valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['winPlacePerc'].iloc[valid_idx]\n\n            model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n                eval_metric= 'mae', verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'])\n\n            oof_preds[valid_idx] = model.predict(valid_x)\n            sub_preds += model.predict(test_df[feats]) \/ folds.n_splits\n\n            fold_importance_df = pd.DataFrame()\n            fold_importance_df[\"feature\"] = feats\n            fold_importance_df[\"importance\"] = model.feature_importances_\n            fold_importance_df[\"fold\"] = n_fold + 1\n            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n            print('Fold %2d MAE : %.6f' % (n_fold + 1, mean_absolute_error(valid_y, oof_preds[valid_idx])))\n            del train_x, train_y, valid_x, valid_y\n            gc.collect()\n\n    print('Full MAE score %.6f' % mean_absolute_error(train_df['winPlacePerc'], oof_preds))\n    return oof_preds, sub_preds, feature_importance_df","82fd2dea":"import lightgbm as lgb\n\nparams = {\n    'num_leaves': 144,\n    'learning_rate': 0.1,\n    'n_estimators': 800,\n    'max_depth':12,\n    'max_bin':55,\n    'bagging_fraction':0.8,\n    'bagging_freq':5,\n    'feature_fraction':0.9,\n    'verbose':50, \n    'early_stopping_rounds':100\n    }\n\n# LightGBM parameters\nlgbm_reg = lgb.LGBMRegressor(num_leaves=params['num_leaves'], learning_rate=params['learning_rate'], \n                    n_estimators=params['n_estimators'], max_depth=params['max_depth'],\n                    max_bin = params['max_bin'], bagging_fraction = params['bagging_fraction'], \n                    bagging_freq = params['bagging_freq'], feature_fraction = params['feature_fraction'],\n                   )\n\nlgb_oof_preds, lgb_sub_preds, lgb_feature_importance_df = oof_model_preds(dataset, lgbm_reg, num_folds=4, params=params)","3e97c4bc":"def display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances.png')","77582863":"display_importances(lgb_feature_importance_df)","18c4075c":"sub = pd.DataFrame()\nsub['Id'] = test_df['Id']\nsub['winPlacePerc'] = lgb_sub_preds\nsub['winPlacePerc'][sub['winPlacePerc'] > 1] = 1\n\nsub.to_csv('lgb_submission.csv',index=False)","e15fa270":"pubg-simple-LightGBM\n\n### PUBG Finish Placement Prediction (Kernels Only)\nhttps:\/\/www.kaggle.com\/c\/pubg-finish-placement-prediction\n\nCan you predict the battle royale finish of PUBG Players?\n\n*What's the best strategy to win in PUBG?*\n\n### reference\n- https:\/\/www.kaggle.com\/rejasupotaro\/effective-feature-engineering\n- https:\/\/www.kaggle.com\/mlisovyi\/relativerank-of-predictions\/notebook\n- https:\/\/www.kaggle.com\/jsaguiar\/lightgbm-with-simple-features","8c0f6af4":"### check dataset","5679513d":"### Display\/plot feature importance","7d0cdab9":"### feature engineering [WIP]","14a2c361":"#### null check","7c97d24f":"### target\n*PUBG Finish Placement*","377a079d":"###  create submission file","ce64d124":"#### Correlation","dec95587":"##### Number of Team Members","aef9d34e":"### explore dataset","39b2faf6":"##### reduce memory","68f4d699":"### model\n- LightGBM","0359f981":"#### LightGBM","584775fa":"##### matchType"}}