{"cell_type":{"42c9bb42":"code","b7da2130":"code","7bcdf6e2":"code","bc17c855":"code","9549eabd":"code","b7b5acf8":"code","75034ddc":"code","83ba2e8e":"code","2779e568":"code","e49af91c":"code","f57b9570":"code","98ae3097":"code","d4a3478a":"code","1e6dc25a":"code","fa661f87":"code","567b9237":"code","1521fa60":"code","85b33e9f":"markdown","2b987ebc":"markdown","8f48dc78":"markdown","570cfdb3":"markdown","275d06eb":"markdown","412a877f":"markdown","bb23b5a1":"markdown","717e8aae":"markdown"},"source":{"42c9bb42":"#imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b7da2130":"#dataset\ndf = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf.head()","7bcdf6e2":"#Check the amount of missing values per column\ndf.isnull().sum()","bc17c855":"#Observe numbers of survivors and number of deaths and their respective percentages\nnum_1 = len(df.loc[df['Survived'] == 1])\nnum_0 = len(df.loc[df['Survived'] == 0])\nprint(\"Number of survivors: {0} ({1:2.2f}%)\".format(num_1, (num_1\/ (num_1 + num_0)) * 100))\nprint(\"Number of deaths: {0} ({1:2.2f}%)\".format(num_0, (num_0\/ (num_1 + num_0)) * 100))","9549eabd":"#Transform the strings of the 'Sex' column into numbers\ndf['Sex'] =df['Sex'].map({'female': 1, 'male': 0})\nnum_true = len(df.loc[df['Sex'] == True])\nnum_false = len(df.loc[df['Sex'] == False])\nprint(\"Number of women: {0} ({1:2.2f}%)\".format(num_true, (num_true\/ (num_true + num_false)) * 100))\nprint(\"N\u00famero of men   : {0} ({1:2.2f}%)\".format(num_false, (num_false\/ (num_true + num_false)) * 100))","b7b5acf8":"#Transform the strings of the 'Embarked' column into numbers\ndf['Embarked'] =df['Embarked'].map({'S': 2,'C': 1, 'Q': 0})\nnum_S = len(df.loc[df['Embarked'] == 2])\nnum_C = len(df.loc[df['Embarked'] == 1])\nnum_Q = len(df.loc[df['Embarked'] == 0])\nprint('Number of embarked S: {0} ({1:2.2f}%)'.format(num_S, (num_S\/ (num_S + num_C + num_Q)) * 100)) \nprint('Number of embarked C: {0} ({1:2.2f}%)'.format(num_C, (num_C\/ (num_S + num_C + num_Q)) * 100))\nprint('Number of embarked Q: {0} ({1:2.2f}%)'.format(num_Q, (num_Q\/ (num_S + num_C + num_Q)) * 100))","75034ddc":"#Dealing with empty data and checking if it worked\ndf['Age'].fillna(df['Age'].dropna().median(), inplace=True)\ndf['Embarked'].fillna(df['Embarked'].dropna().median(), inplace=True)\ndf.isnull().sum()","83ba2e8e":"#Correlation between some columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ntrain = df.drop(drop_elements, axis = 1)\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Correlation', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()","2779e568":"#Simple example of plotting collumns \nplt.hist(df['Age'], label=\"Age\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\nplt.hist(df['Pclass'], label = \"Class\")\nplt.grid(True)\nplt.legend()\nplt.show()","e49af91c":"#Splitting data between training and testing\nimport sklearn as sk\nfrom sklearn.model_selection import train_test_split\n#Feature Selection\nfeatures = ['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n# Variable to be predicted\nfeature_prev = ['Survived']\n# Objects\nX = df[features].values\nY = df[feature_prev].values\n\nsplit_test_size = 0.30\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = split_test_size, random_state = 42)\nprint(\"{0:0.2f}% train data\".format((len(X_train)\/len(df.index)) * 100))\nprint(\"{0:0.2f}% teste data\".format((len(X_test)\/len(df.index)) * 100))","f57b9570":"# Using Naive Bayes\nprint(\"++++++++++++++++++++++++Naive Bayes++++++++++++++++++++++++\")\nfrom sklearn.naive_bayes import GaussianNB\nmodelo_v1 = GaussianNB()\nmodelo_v1.fit(X_train, Y_train.ravel())\nfrom sklearn import metrics\nnb_predict_train = modelo_v1.predict(X_train)\nprint(\"Accuracy Train: {0:.4f}\".format(metrics.accuracy_score(Y_train, nb_predict_train)))\nnb_predict_test = modelo_v1.predict(X_test)\nprint(\"Accuracy Test: {0:.4f}\".format(metrics.accuracy_score(Y_test, nb_predict_test)))\nprint(\"Classification Report\")\nprint(metrics.classification_report(Y_test, nb_predict_test, labels = [1, 0]))","98ae3097":"#Using Random Forest\nprint(\"++++++++++++++++++++++++RANDOM FOREST++++++++++++++++++++++++\")\nfrom sklearn.ensemble import RandomForestClassifier\nmodelo_v2 = RandomForestClassifier(random_state = 42)\nmodelo_v2.fit(X_train, Y_train.ravel())\nrf_predict_train = modelo_v2.predict(X_train)\nprint(\"Accuracy Train: {0:.4f}\".format(metrics.accuracy_score(Y_train, rf_predict_train)))\nrf_predict_test = modelo_v2.predict(X_test)\nprint(\"Accuracy Test: {0:.4f}\".format(metrics.accuracy_score(Y_test, rf_predict_test)))\nprint()\nprint(\"Classification Report\")\nprint(metrics.classification_report(Y_test, rf_predict_test, labels = [1, 0]))","d4a3478a":"#Using Logistic Regression\nprint(\"++++++++++++++++++++++++LOGISTIC REGRESSION++++++++++++++++++++++++\")\nfrom sklearn.linear_model import LogisticRegression\nmodelo_v3 = LogisticRegression(C = 0.7, random_state = 42, max_iter = 1000)\nmodelo_v3.fit(X_train, Y_train.ravel())\nlr_predict_train = modelo_v1.predict(X_train)\nprint(\"Accuracy Train: {0:.4f}\".format(metrics.accuracy_score(Y_train, lr_predict_train)))\nlr_predict_test = modelo_v3.predict(X_test)\nprint(\"Accuracy Test: {0:.4f}\".format(metrics.accuracy_score(Y_test, lr_predict_test)))\nprint()\nprint(\"Classification Report\")\nprint(metrics.classification_report(Y_test, lr_predict_test, labels = [1, 0]))","1e6dc25a":"\"++++++++++++++++++++++++End of Train++++++++++++++++++++++++\"","fa661f87":"\"++++++++++++++++++++++++Begin of Test++++++++++++++++++++++++\"","567b9237":"df2 = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndf2.head()\n","1521fa60":"df2['Sex'] =df2['Sex'].map({'female': 1, 'male': 0})\ndf2['Embarked'] =df2['Embarked'].map({'S': 2,'C': 1, 'Q': 0})\ndf2['Age'].fillna(df2['Age'].dropna().median(), inplace=True)\ndf2['Embarked'].fillna(df2['Embarked'].dropna().median(), inplace=True)\ndf2['Fare'].fillna(df2['Fare'].dropna().median(), inplace=True)\nX2_test=pd.get_dummies(df2[features])\n\nmodelo_v4 = RandomForestClassifier(random_state = 42)\nmodelo_v4.fit(X_train, Y_train.ravel())\npredict_test = modelo_v4.predict(X2_test)\n\noutput = pd.DataFrame({'PassengerId': df2.PassengerId, 'Survived': predict_test})\noutput.to_csv('my_submission.csv', index=False)\n\"Your submission was saved!\"","85b33e9f":"Dealing with data","2b987ebc":"Building and training the model","8f48dc78":"Graphs","570cfdb3":"Among the three models presented, the one that showed the best results was Random Forest. So this will be the method applied in Test.csv","275d06eb":"Splitting","412a877f":"# Simple Predictive Analysis of Titanic Survivors Based on the Best of 3 Different Techniques","bb23b5a1":"Making Predictions with the best scored Trained Model","717e8aae":"Read the file, organize the data, apply the selected method"}}