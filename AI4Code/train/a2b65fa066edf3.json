{"cell_type":{"de3ddb3d":"code","88a5fa8e":"code","f70e267f":"code","ad5d841b":"code","4eb5b985":"code","949e12fe":"code","8ae25086":"code","10ee79f7":"code","677418f5":"code","1b0dd318":"code","7ba3b1fd":"code","529817b0":"code","9c9c804b":"code","59b4e332":"code","8eecb877":"code","24493168":"code","416a8280":"code","6c037656":"markdown","e4b872be":"markdown","3b21b833":"markdown","137ac61e":"markdown","07f98834":"markdown","8afceebc":"markdown","d2384e54":"markdown","2e3850b3":"markdown","2fdbafff":"markdown","03e4c38d":"markdown","68bf57bb":"markdown","9f8b5c2b":"markdown"},"source":{"de3ddb3d":"import tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport urllib3\n\n[train_ds, valid_ds, test_ds] , info = tfds.load(\"malaria\", \n                                                 split = ['train[:70%]', 'train[70%:85%]', 'train[85%:]'], \n                                                 shuffle_files=True, \n                                                 with_info=True)","88a5fa8e":"print(\"Training Dataset structure --> \" + str(train_ds))\nprint(\"Dataset Info --> \" + str(info))\nprint (\"******************************************\\n\")\n\nds_size = info.splits[\"train\"].num_examples\nds_names = info.features[\"label\"].names\nds_classes = info.features[\"label\"].num_classes\n\nprint (\"******************************************\\n\")\nprint (\"Num of training samples: \" + str(ds_size))\nprint (\"Classes: \" + str(ds_names))\nprint (\"Num of Classes: \" + str(ds_classes))","f70e267f":"for ex in train_ds.take(2):\n    print (ex)","ad5d841b":"# This works in Collab and my own personal Jupyter Notebook but not sure why it doesn't work in Kaggle, any ideas??\n#disp = tfds.show_examples(train_ds, info)","4eb5b985":"NEW_HEIGHT = 200\nNEW_WIDTH = 200\nBATCH_SIZE = 32","949e12fe":"def fix_image(ds):\n  ds[\"image\"] = tf.image.convert_image_dtype(ds[\"image\"], tf.float32)\n  ds[\"image\"] = tf.image.resize_with_crop_or_pad(ds[\"image\"], NEW_HEIGHT, NEW_WIDTH)\n  return ds[\"image\"], ds[\"label\"];","8ae25086":"fixed_train_ds = train_ds.map(fix_image).batch(BATCH_SIZE)\nfixed_valid_ds = valid_ds.map(fix_image).batch(BATCH_SIZE)\nfixed_test_ds = test_ds.map(fix_image).batch(BATCH_SIZE)","10ee79f7":"batch_image, batch_label = next(iter(fixed_train_ds))\n\nplt.figure(figsize= (16,12))\n\nfor i in range(16):\n    ax = plt.subplot(4,4,i+1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    plt.imshow(batch_image[i])\n    if batch_label[i]:\n        plt.title(ds_names[1])\n    else:\n        plt.title(ds_names[0])","677418f5":"def build_model (dropout=0.25, input_shape=[NEW_HEIGHT, NEW_WIDTH, 3]):\n    model = keras.models.Sequential()\n\n    model.add(keras.layers.InputLayer(input_shape=input_shape))\n    \n    model.add(keras.layers.Conv2D(32,3, padding=\"same\"))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.ReLU())            \n    model.add(keras.layers.MaxPooling2D(2,2, padding=\"same\"))\n\n    model.add(keras.layers.Conv2D(64,3, padding=\"same\"))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.ReLU())            \n    model.add(keras.layers.MaxPooling2D(2,2, padding=\"same\"))\n\n    model.add(keras.layers.Conv2D(128,3, padding=\"same\"))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.ReLU())            \n    model.add(keras.layers.MaxPooling2D(2,2, padding=\"same\"))\n\n    model.add(keras.layers.Conv2D(256,3, padding=\"same\"))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.ReLU())            \n    model.add(keras.layers.MaxPooling2D(2,2, padding=\"same\"))\n\n    model.add(keras.layers.Flatten())\n\n    model.add(keras.layers.Dense(256, activation='relu'))\n    model.add(keras.layers.Dropout(dropout))\n    \n    model.add(keras.layers.Dense(128, activation='relu'))\n    model.add(keras.layers.Dropout(dropout))\n\n    model.add(keras.layers.Dense(64, activation='relu'))\n    model.add(keras.layers.Dropout(dropout))\n\n    model.add(keras.layers.Dense(32, activation='relu'))\n \n    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n                  metrics=[tf.metrics.AUC(), \"accuracy\"])\n    return model","1b0dd318":"def build_res_model (dropout=0.25, input_shape=[NEW_HEIGHT, NEW_WIDTH, 3]):\n    model = keras.models.Sequential()\n\n    input_ = keras.layers.Input(shape=(input_shape))\n    \n    # First Residual Block\n    conv2_1 = keras.layers.Conv2D(64, 3, padding=\"same\",input_shape=input_shape) (input_)\n    conv2_1 = keras.layers.BatchNormalization() (conv2_1)\n    conv2_1 = keras.layers.ReLU() (conv2_1)\n    \n    conv2_2 = keras.layers.Conv2D(64,3, padding=\"same\") (conv2_1)\n    conv2_2 = keras.layers.BatchNormalization() (conv2_2)\n    conv2_2 = keras.layers.ReLU() (conv2_2)\n    \n    conv2_3 = keras.layers.Conv2D(64,3, padding=\"same\") (conv2_2)\n    conv2_3 = keras.layers.BatchNormalization() (conv2_3)\n    conv2_3 = keras.layers.ReLU() (conv2_3)\n    \n    # Concatenating the output from the first convolution in the block with the final \n    # convolution in the block (==> need the tensors to be in the same shape)\n    concat1 = keras.layers.Concatenate() ([conv2_1, conv2_3])\n    max2_1 = keras.layers.MaxPooling2D(2, padding=\"same\") (concat1)\n\n    # The 2nd Residual block after Pooling the concatenation from the previous block\n    conv2_4 = keras.layers.Conv2D(128,3, padding=\"same\") (max2_1)\n    conv2_4 = keras.layers.BatchNormalization() (conv2_4)\n    conv2_4 = keras.layers.ReLU() (conv2_4)        \n    \n    conv2_5 = keras.layers.Conv2D(128,3, padding=\"same\") (conv2_4)\n    conv2_5 = keras.layers.BatchNormalization() (conv2_5)\n    conv2_5 = keras.layers.ReLU() (conv2_5)\n\n    conv2_6 = keras.layers.Conv2D(128,3, padding=\"same\") (conv2_5)\n    conv2_6 = keras.layers.BatchNormalization() (conv2_6)\n    conv2_6 = keras.layers.ReLU() (conv2_6)\n\n    # Concatenating the output from the first convolution in the block with the final \n    # convolution in the block (==> need the tensors to be in the same shape)\n    concat2 = keras.layers.Concatenate() ([conv2_4, conv2_6])\n    max2_2 = keras.layers.MaxPooling2D(2, padding=\"same\") (concat2)\n\n    # The final Residual block after Pooling the concatenation from the previous block\n    conv2_7 = keras.layers.Conv2D(256,3, padding=\"same\") (max2_2)\n    conv2_7 = keras.layers.BatchNormalization() (conv2_7)\n    conv2_7 = keras.layers.ReLU() (conv2_7)        \n    \n    conv2_8 = keras.layers.Conv2D(256,3, padding=\"same\") (conv2_7)\n    conv2_8 = keras.layers.BatchNormalization() (conv2_8)\n    conv2_8 = keras.layers.ReLU() (conv2_8)\n\n    conv2_9 = keras.layers.Conv2D(256,3, padding=\"same\") (conv2_8)\n    conv2_9 = keras.layers.BatchNormalization() (conv2_9)\n    conv2_9 = keras.layers.ReLU() (conv2_9)\n\n    # Concatenating the output from the first convolution in the block with the final \n    # convolution in the block (==> need the tensors to be in the same shape)\n    concat3 = keras.layers.Concatenate() ([conv2_7, conv2_9])\n    max2_3 = keras.layers.GlobalAveragePooling2D() (concat3)\n\n    # Flatttening the output for the full connected network\n    flat1 = keras.layers.Flatten() (max2_3)\n\n    # A seres of Dense connected layer with dropouts in betweeen them\n    dense1 = keras.layers.Dense(256, activation='relu') (flat1)\n    dropout1 = keras.layers.Dropout(dropout) (dense1)\n    \n    dense2 = keras.layers.Dense(128, activation='relu') (dropout1)\n    dropout2 = keras.layers.Dropout(dropout) (dense2)\n\n    dense3 = keras.layers.Dense(64, activation='relu') (dropout2)\n    dropout3 = keras.layers.Dropout(dropout) (dense3)\n\n    dense4 = keras.layers.Dense(32, activation='relu') (dropout3)\n \n    output = keras.layers.Dense(1, activation=\"sigmoid\") (dense4)\n    \n    model = keras.Model (inputs=input_ , outputs=output)\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n                  metrics=[tf.metrics.AUC(), \"accuracy\"])\n    return model","7ba3b1fd":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"malaria_tfds.h5\", save_best_only=True)\n\nearlystop_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n\nmodel = build_model()\nhistory = model.fit(fixed_train_ds, epochs=40, validation_data=fixed_valid_ds,  callbacks=[checkpoint_cb, earlystop_cb])","529817b0":"model.load_weights(\"malaria_tfds.h5\")\nmodel.evaluate(fixed_test_ds)","9c9c804b":"auc = history.history[\"auc\"]\nval_auc = history.history[\"val_auc\"]\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(history.history[\"auc\"]))\n\nplt.figure(figsize=(16, 20))\nplt.subplot(3, 1, 1)\nplt.plot(epochs_range, auc, label='Training AUC')\nplt.plot(epochs_range, val_auc, label='Validation AUC')\nplt.legend(loc='lower right')\nplt.title('Training and Validation AUC')\n\nplt.subplot(3, 1, 2)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(3, 1, 3)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","59b4e332":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"malaria_tfds_res.h5\", save_best_only=True)\n\nmodel_res = build_res_model()\nhistory_res = model_res.fit(fixed_train_ds, epochs=40, validation_data=fixed_valid_ds,  callbacks=[checkpoint_cb, earlystop_cb])","8eecb877":"model_res.load_weights(\"malaria_tfds_res.h5\")\nmodel_res.evaluate(fixed_test_ds)","24493168":"auc_res = history_res.history[\"auc_1\"]\nval_auc_res = history_res.history[\"val_auc_1\"]\n\nacc_res = history_res.history['accuracy']\nval_acc_res = history_res.history['val_accuracy']\n\nloss_res = history_res.history['loss']\nval_loss_res = history_res.history['val_loss']\n\nepochs_range = range(len(history_res.history[\"auc_1\"]))\n\nplt.figure(figsize=(16, 20))\nplt.subplot(3, 1, 1)\nplt.plot(epochs_range, auc_res, label='Training AUC')\nplt.plot(epochs_range, val_auc_res, label='Validation AUC')\nplt.legend(loc='lower right')\nplt.title('Training and Validation AUC')\n\nplt.subplot(3, 1, 2)\nplt.plot(epochs_range, acc_res, label='Training Accuracy')\nplt.plot(epochs_range, val_acc_res, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(3, 1, 3)\nplt.plot(epochs_range, loss_res, label='Training Loss')\nplt.plot(epochs_range, val_loss_res, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","416a8280":"tf.saved_model.save(model_res, 'resMalaria')\n\n# Intialize the TFLite converter to load the SavedModel\nconverter = tf.lite.TFLiteConverter.from_saved_model('resMalaria')\n\n# Set the optimization strategy for 'size' in the converter \nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n\n# Use the tool to finally convert the model\ntflite_model = converter.convert()\n\ntflite_model_file = 'resMalaria.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)","6c037656":"# Training the Model\n\nCreating 2 callbacks to save the best model and to stop training if its stop improving after 5 epochs","e4b872be":"Using the provided show_examples method by tfds to see a few of the images with their labels & values","3b21b833":"# Evaluating the model against the Test set","137ac61e":"Displaying some of the converted images to see that their size is consistent and that we didn't corrupt the data in any way","07f98834":"Resizing the 3 datasets that will be used to train, validate and test our model","8afceebc":"# Building the model\n- Create the input layer\n- Create the convolutional\/Pooling layers\n  * They will half the filters at every layer the convulational layers increas\n  * The minimum # of filters will be 2 if there are too many layers\n- Falttening the layers so we can send them to the Dense layers\n- Create the dense layers\n  * A BatchNormalization Layer\n  * A Dense Layer\n  * A Dropout Layer\n- Final Dense layer with 1 unit","d2384e54":"# Exploring the data\n\n\n\n*   Looking at the structure of the dataset which shows that images are not a consistent size\n*   Display the number of training samples provided in the overall dataset\n\n\n*   Display the number of classes in the dataset\n*   Dispaly the labels of the classes in the dataset\n","2e3850b3":"# Setting the global variables that will be used throughout the model","2fdbafff":"# Importing the necessary libraries and loading the malaria dataset from TFDS\n\nSince there is only a training set available (from documentation provided with dataset), I decided to shuffle the data and split it into training, validation & testing sets from the start. ","03e4c38d":"# Conclusion\n\n* AUC is typically a better metric for logistic regression problems since the data could be skeweed towards one class due to natural occurence but the documentation provided in this dataset showed that both classes were equally represented so I decided to include accuracy also and let the numbers speak for themselves\n* Regardless of which metric you use have a 95%+ AUC\/Accurray would typically hint at some kind of overfitting but in this case I think the \"clean\" data played a major role in the outcome.  In real life you probably wouldn't get such a clean labelled data.","68bf57bb":"A function to resize the images to a consistent size that can be used by the model","9f8b5c2b":"Display a few samples just to make sure that they are all different sizes which checks out"}}