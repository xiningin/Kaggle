{"cell_type":{"7789ad0d":"code","c08dbfcb":"code","0b54db9a":"code","f158bb18":"code","96f532c1":"code","58bbecfe":"code","d8aa85b7":"code","887a4a7e":"code","be6fe1d6":"code","086f0d73":"code","788db472":"code","00e7bc60":"code","b3acc187":"code","910a5eff":"code","8e3adfeb":"code","2cee5e69":"markdown","6dcbb63d":"markdown","69ffcafc":"markdown","6f159484":"markdown","5aff614e":"markdown","780329c1":"markdown","5b44413b":"markdown","77628cc7":"markdown","70d3c7ab":"markdown","74e01eb3":"markdown","3f5ea493":"markdown","b69a049e":"markdown"},"source":{"7789ad0d":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom IPython import display\nimport matplotlib.pyplot as plt","c08dbfcb":"# data\nitemcol = [w.strip().replace(\" \",\"_\") for w in \"itemid | movie_title | release_date | video release date |IMDb URL | unknown | Action | Adventure | Animation |Children's | Comedy | Crime | Documentary | Drama | Fantasy |Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |Thriller | War | Western |\".split('|')]\nitemcol.remove('')\ndata = pd.read_csv(\"..\/input\/movielens-100k-dataset\/ml-100k\/u.data\",delimiter='\\t',\n                   names=['userid','itemid','rating','timestamp'])\nuser = pd.read_csv(\"..\/input\/movielens-100k-dataset\/ml-100k\/u.user\",delimiter='|',names=['userid','age','gender','occu','zip'])\nitem = pd.read_csv(\"..\/input\/movielens-100k-dataset\/ml-100k\/u.item\",delimiter='|',\n                   names=itemcol,encoding='latin_1')","0b54db9a":"data.head()","f158bb18":"print(data.shape)\nprint(user.shape)\nprint(item.shape)","96f532c1":"data.rating.describe()","58bbecfe":"n_item = item.shape[0] \nn_user = user.shape[0]\nprint('user id starts from %d and item id starts from %d'%(user.userid.describe()['min'],\n                                                          item.itemid.describe()['min']) )","d8aa85b7":"# indexing userid, movieid from 0\nitem['itemid'] = item['itemid'].apply(lambda x: x - 1)\nuser['userid'] = user['userid'].apply(lambda x: x - 1)\ndata['itemid'] = data['itemid'].apply(lambda x: x - 1)\ndata['userid'] = data['userid'].apply(lambda x: x - 1)","887a4a7e":"# Genre aggregate\ndef genre(series):\n    genres = series.index[6:-2]\n    \n    text = []\n    for i in genres:\n        if series[i] == 1:\n            text.append(i)\n    return \", \".join(text)\nitem['genre'] = item.apply(genre,axis=1)","be6fe1d6":"def split(data):\n    \"\"\"\n    Splits 100k data between train and test set, and builts corresponding rating matrix, A for each set\n    \"\"\"\n    n_user = data.userid.nunique()\n    n_item = data.itemid.nunique()\n    train,test = train_test_split(data,test_size=0.3)\n    def fun1(x):\n        A_train[x[0],x[1]] = x[2]\n        return x\n    def fun2(x):\n        A_test[x[0],x[1]] = x[2]\n        return x\n    A_train = np.zeros((n_user,n_item))\n    A_test = np.zeros((n_user,n_item))\n    train.apply(fun1, axis=1)\n    test.apply(fun2,axis=1)\n    return A_train, A_test","086f0d73":"class MF:\n    \"\"\"\n    Matrix factorization class. \n    \"\"\"\n    def __init__(self,lmbda = 0.01, learning_rate=0.001,max_iteration=10000,rank=10,verbose=True,gap=None):\n        \"\"\"\n        params\n        ------\n        lmbda: float. Regularizer parameter.\n        \n        learning_rate: float. Step size or learning rate of SGD\n        \n        max_iteration: int. \n        \n        rank: int. Embedding dimension of the U,V matrix where A = U.V\n        \n        verbose: bool. Whether to print iteration log or not.\n        \n        gap: bool. \n            Gap between each iteration log when verbose is true. Default value is 10th factor of max_iteration.\n        \"\"\"\n        self.lmbda = lmbda\n        self.lr = learning_rate\n        self.max_iteration = max_iteration\n        self.rank = rank\n        self.verb = verbose\n        self.gap = gap\n        self.U = None\n        self.V = None\n        self.gap = (max_iteration \/ 10) if gap is None else gap\n        \n    def mse(self,truth, pred):\n        \"\"\"Returns the mse of nonzero errors\"\"\"\n        pred = pred[truth.nonzero()].flatten()\n        truth = truth[truth.nonzero()].flatten()\n        return mean_squared_error(truth, pred)\n\n    def graph(self,testset=False):\n        \"\"\"\n        Training and test graph with other meta data.\n        \"\"\"\n        fig, ax = plt.subplots(facecolor='white',figsize=(10,5))\n        train = [w[0] for w in self.history]\n        test = [w[1] for w in self.history]\n        x = list(range(0,self.max_iteration+2,int(self.gap)))\n        ax.plot(x,train,color='red',label='Train MSE')\n        if testset==True:\n            ax.plot(x,test,color='green',label='Test MSE')\n        ax.legend()\n        ax.grid(True)\n        ax.set_xlabel(\"Iteration\")\n        ax.set_ylabel(\"MSE\")\n        caption = f'lmbda: {lmb} lr: {self.lr} iteration: {self.max_iteration}'\n        plt.title(caption)\n        plt.show()\n\n    def predict(self,query_embedding,type='neighbour',name='Aladdin',measure='cosine'):\n        \"\"\"\n        params\n        ------\n        query_embedding: 1D array. \n            Query's embeddding vector. For example if we want to find similar movies like Aladdin,\n            query_embedding will be Aladdin's vector from V. \n        V: array-like. 2d. Item embedding.\n        type: {similar, suggest}. \n            Not in use now. for future functionality.\n        name: str. Movie name.\n        measure: {dot,cosine}\n            similarity measure for query and V. \n\n        returns\n        -------\n        sim_vector: similarity vector between query_embedding and V.\n        \"\"\"\n        \n        u = query_embedding\n        V = self.V\n        if measure == 'cosine':\n            V = V \/ np.linalg.norm(V, axis=1, keepdims=True)\n            u = u \/ np.linalg.norm(u)\n        sim_vector = u.dot(V.T)\n        return sim_vector\n\n    \n    def SGD(self,A,rated_rows,rated_cols,A_test=None):\n        \"\"\"\n        Stochastic Gradient Descent. \n        \n        params\n        ------\n        A: 2D array. shape(n_user,n_item)\n            Training rating matrix. \n        \n        rated_rows: 1D array.\n            Observed indices rows from A. Meaning i where A_{i,j} > 0.\n        \n        rated_cols: 1D array.\n            Observed indices' column from A. Meaning j where A_{i,j} > 0.\n            \n        A_test: Test A.\n            *optional.*\n            \n        returns\n        -------\n        none\n        \"\"\"\n        print(\"Master Yoda has started teaching...\")\n        self.history= []\n        for itr in range(self.max_iteration):\n            # choosing an observed user,item combination\n            u = np.random.choice(rated_rows)\n            i = np.random.choice(rated_cols)\n            #forward pass\n            error = A[u,i] - np.dot(self.U[u], self.V[i])  # check this line alone\n    #         cost = error**2 + lmbda * (np.linalg.norm(self.U[u])**2 + np.linalg.norm(self.V[i])**2)        \n            # backward pass\n            tmp = self.U[u]\n            self.U[u] = self.U[u] + self.lr * (error * self.V[i] - self.lmbda * self.U[u])\n            self.V[i] = self.V[i] + self.lr * (error * tmp - self.lmbda * self.V[i])\n            \n            if (itr % self.gap) == 0 or itr == self.max_iteration - 1:\n                A_hat = np.dot(self.U,self.V.T)\n                train_mse = self.mse(A,A_hat)\n                test_mse = -1\n                if isinstance(A_test,np.ndarray):\n                    test_mse = self.mse(A_test,A_hat)\n                self.history.append((train_mse,test_mse))\n                if self.verb==True:\n                    print(\"iteration %d, TrainMSE: %.2f TestMSE: %.2f\"%\n                          (itr,train_mse,test_mse))\n    \n    def fit(self,A,A_test=None):\n        \"\"\"\n        Fit the U,V to A.\n        \"\"\"\n        rated_rows,rated_cols = A.nonzero()\n        n_user = A.shape[0]\n        n_item = A.shape[1]\n        if self.U is None:\n            self.U = np.random.rand(n_user,self.rank)\n            self.V = np.random.rand(n_item,self.rank)\n        # used in verbose mode\n        self.SGD(A,rated_rows,rated_cols,A_test)","788db472":"A_train,A_test = split(data)","00e7bc60":"lmb = 0.1\nlr = 0.001\nmx_itr = 60000\ngap = mx_itr \/ 10\nview = True\n\nmodel = MF(lmb,learning_rate=lr,max_iteration=mx_itr,rank=30,verbose=True)\nmodel.fit(A_train,A_test)\nmodel.graph(testset=True)","b3acc187":"def get_movie_suggestion(model,name='Aladdin'):\n    # might return multiple movies\n    movieids =  item[item['movie_title'].str.contains(name)].index.values\n    if len(movieids) == 0:\n        print('No movie found by that name. Remember, searching is case-sensitive')\n        return\n    print('Found ',len(movieids),'searching by: ',item.loc[movieids[0],'movie_title'])\n    query = model.V[movieids[0]] # a single movie embedding\n    sim_vector = model.predict(query)\n    item['similarity'] = sim_vector\n    top5 = item.sort_values(['similarity'],axis=0,inplace=False,ascending=False)[\n        ['itemid','movie_title','genre','similarity','IMDb_URL']\n    ].head()\n#     top5 = top5.append(item.loc[movieids[0],['itemid','movie_title','genre','similarity']])\n    display.display(top5)","910a5eff":"get_movie_suggestion(model,name='GoldenEye')","8e3adfeb":"# sample \nF = np.array([[0,4,0,5],\n             [0,5,0,2],\n             [0,0,2,4],\n             [0,5,1,2]])\nkid_model = MF(0.01,learning_rate=0.01,max_iteration=500,rank=2,verbose=True)\nkid_model.fit(F)\n# kid_model.graph()\nnewF = np.round(np.dot(kid_model.U,kid_model.V.T))\nnewF","2cee5e69":"# MF Class\nMatrix Factorizer","6dcbb63d":"Rating Matrix\n$$A^{user\\ \\times \\ item}$$","69ffcafc":"\nonly 100000 data point given, so data is highly sparse. But we'll try to work with dense matrix as it is more intuitive for us, the beginners. And unrated movies will be given 0. This won't create much problem as ratings for watched movies are 1 to 5.","6f159484":"# Some Preprocessing","5aff614e":"as we see, similarity is not good. no idea why. but the code looks alright and on a simple matrix it looks okay. see below.","780329c1":"> Indexing starts at 0\n\nAlbert Einstein","5b44413b":"This dataset has 100k movie ratings. Each rating is defined as user, x rated a movie, y using integer 1 to 5. 1 is the lowest rating and 5 is the highest.","77628cc7":"Trying the model","70d3c7ab":"**This Notebook implements [Non-negative Matrix Factorization](https:\/\/en.wikipedia.org\/wiki\/Non-negative_matrix_factorization)**\n\nEquations taken from: https:\/\/www.cs.cmu.edu\/~mgormley\/courses\/10601-s17\/slides\/lecture25-mf.pdf","74e01eb3":"Genres are merged for better interpretation","3f5ea493":"Low Rank Matrix\n$$\nU^{user \\ \\times \\ rank} \\\\\nV^{item \\ \\times \\ rank} \\\\\nwhere \\ rank=n\n$$","b69a049e":"# Notes\nlr > 0.009 might explode gradient\n\nlmbda > 0 makes training noisy\n\naround 0.10 difference between train and test"}}