{"cell_type":{"288990ad":"code","91dfdf6e":"code","de6ba78a":"code","eb7d5369":"code","f9666e24":"code","5e138198":"code","e4284a21":"code","3f40245b":"code","8435a9b7":"code","259a432d":"code","c78f9aba":"code","8282919d":"markdown","9754bc2b":"markdown","aab0510a":"markdown","209e4891":"markdown","4ec1c4e3":"markdown"},"source":{"288990ad":"#%load_ext tensorboard.notebook\n#%tensorboard --logdir logs\n\n#import a bunch of rubbish\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow\nimport tensorflow as tf\nimport csv as csv\nfrom IPython.display import display\nimport cv2 \nfrom matplotlib import pyplot as plt\nimport operator\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.activations import relu\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend\nimport os\nfrom random import shuffle \nfrom keras.callbacks import ModelCheckpoint\nfrom keras import optimizers\nfrom sklearn.metrics import confusion_matrix   \nimport math\n    \n    \nheight = 512\nwidth = 512\ncircle_img = np.zeros((height,width), np.uint8)\ncv2.circle(circle_img,(int(width\/2),int(height\/2)),255,1,thickness=-1)    \n    \nstart = time.time()\n\n#LOSS AND METRICS FOR LEARNING ALGORITHM\ndef gacc(y_true, y_pred): #general accuracy\n    return 1-(backend.mean(backend.abs(y_pred - y_true), axis=-1))\n\ndef right_acc(y_true, y_pred): #general accuracy\n    return 1-(backend.mean(backend.minimum(backend.abs((backend.round(y_pred*4) - y_true*4)*4),1), axis=-1))\n\ndef mean_absolute_error2(y_true, y_pred): #custom loss algorithm, actually a modded MAE\n    return backend.mean(backend.maximum((backend.abs(y_pred - y_true))-.124,0), axis=-1)\n\ndef std_error(y_true, y_pred): #std of the error\n    return backend.std((backend.abs(y_pred - y_true)))\n\ndef p_meanX(y_true, y_pred): #mean of all predictions - should ideally be .5\n    return backend.mean(y_pred, axis=-1)\n\ndef p_stdX(y_true, y_pred): #std of all predictions - should be ~0.32 to 0.35\n    return backend.std(y_pred)\n\n# Aaaaaaaaaaaaaaaaa\n\nend = time.time()\nprint(end - start)","91dfdf6e":"## Callable functions -- just shrink and hide this junk\n\ndef adjust_gamma(image, gamma=1.0): #old version of gamma correction\n    i = 0\n    invGamma = 1.0 \/ gamma\n    table = np.array([((i \/ 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n    return cv2.LUT(image, table)\n\ndef adjust_gamma2(img, gamma=1.0): #new colour balancer, normalises colour balance\n    new = [20,80,120]\n    newimge = np.zeros(512*512*3)\n    newimge = np.reshape(newimge,(512,512,3))\n    newimge[:,:,0] = img[:,:,0]*(min(2,(new[0] \/ np.mean(img[128:384,:,0]))))\n    newimge[:,:,1] = img[:,:,1]*(min(2,(new[1] \/ np.mean(img[128:384,:,1]))))\n    newimge[:,:,2] = img[:,:,2]*(min(2,(new[2] \/ np.mean(img[128:384,:,2]))))\n    newimge = np.clip(newimge,0,254)\n    img = newimge.astype(np.uint8)\n    return img\n\ndef autocrop(image, threshold=10): #is meant to get rid of the back borders (works most times)\n    if len(image.shape) == 3:\n        flatImage = np.max(image, 2)\n    else:\n        flatImage = image\n    assert len(flatImage.shape) == 2\n\n    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n    if rows.size:\n        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n    else:\n        image = image[:1, :1]\n    return image\n\ndef im_resize(img):\n    img = autocrop(img)\n    height,width, x = img.shape\n    margin = 0\n    if width <15 or height < 15:\n        img = zeros(512*512*3).reshape(512,512,3)\n        height,width, x = img.shape\n    if(width>=height):\n        margin = int(np.floor((width-height)\/2))\n        #print(height, width, margin)\n        crop_img = img[0:height,(width-height-margin):(height+margin)]\n    else:\n        margin = int(np.floor((height-width)\/2))\n        #print(height, width, margin)\n        crop_img = img[(height-width-margin):(width+margin),0:width]\n    img = cv2.resize(crop_img,(512,512),interpolation=cv2.INTER_AREA)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    return img\n\n#im_avg returns a tuple of the inner area of the cropped 512x512 image\ndef im_avg(img):\n    return cv2.mean(img[100:412,100:412])\n\nend = time.time()\nprint(end - start)","de6ba78a":"### Need to make a dataframe to do dataframe access of images and classications\n\n# probably should have done this in the image gen script\n\ndirnam=\"\/kaggle\/input\/finalimagese\/data\"\ndirnum=\"\/0\/\"\ndirname=dirnam+dirnum\nfor dirname, _, filenames in os.walk(dirname): pass\ndls0 = pd.DataFrame()\ndls0['name'] = filenames\ndls0['name'] = dirname + dls0['name'].astype(str)\ndls0['diagnosis'] = 0\n\ndirnum=\"\/1\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndls1 = pd.DataFrame()\ndls1['name'] = filenames\ndls1['name'] = dirnam+dirnum + dls1['name'].astype(str)\ndls1['diagnosis'] = .25\n\ndirnum=\"\/2\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndls2 = pd.DataFrame()\ndls2['name'] = filenames\ndls2['name'] = dirnam+dirnum + dls2['name'].astype(str)\ndls2['diagnosis'] = .5\n\ndirnum=\"\/3\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndls3 = pd.DataFrame()\ndls3['name'] = filenames\ndls3['name'] = dirnam+dirnum + dls3['name'].astype(str)\ndls3['diagnosis'] = .75\n\ndirnum=\"\/4\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndls4 = pd.DataFrame()\ndls4['name'] = filenames\ndls4['name'] = dirnam+dirnum + dls4['name'].astype(str)\ndls4['diagnosis'] = 1\n\ndirnam=\"\/kaggle\/input\/finalimagese\/data\"\ndirnum=\"\/0\/\"\ndirname=dirnam+dirnum\nfor dirname, _, filenames in os.walk(dirname): pass\ndlsA0 = pd.DataFrame()\ndlsA0['name'] = filenames\ndlsA0['name'] = dirnam+dirnum + dlsA0['name'].astype(str)\ndlsA0['diagnosis'] = 0\n\ndirnum=\"\/1\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsA1 = pd.DataFrame()\ndlsA1['name'] = filenames\ndlsA1['name'] = dirnam+dirnum + dlsA1['name'].astype(str)\ndlsA1['diagnosis'] = .25\n\ndirnum=\"\/2\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsA2 = pd.DataFrame()\ndlsA2['name'] = filenames\ndlsA2['name'] = dirnam+dirnum + dlsA2['name'].astype(str)\ndlsA2['diagnosis'] = .5\n\ndirnum=\"\/3\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsA3 = pd.DataFrame()\ndlsA3['name'] = filenames\ndlsA3['name'] = dirnam+dirnum + dlsA3['name'].astype(str)\ndlsA3['diagnosis'] = .75\n\ndirnum=\"\/4\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsA4 = pd.DataFrame()\ndlsA4['name'] = filenames\ndlsA4['name'] = dirnam+dirnum + dlsA4['name'].astype(str)\ndlsA4['diagnosis'] = 1\n\n\ndirnam=\"\/kaggle\/input\/finalimagese\/data\/data\"\ndirnum=\"\/0\/\"\ndirname=dirnam+dirnum\nfor dirname, _, filenames in os.walk(dirname): pass\ndlsB0 = pd.DataFrame()\ndlsB0['name'] = filenames\ndlsB0['name'] = dirnam+dirnum + dlsB0['name'].astype(str)\ndlsB0['diagnosis'] = 0\n\ndirnum=\"\/1\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsB1 = pd.DataFrame()\ndlsB1['name'] = filenames\ndlsB1['name'] = dirnam+dirnum + dlsB1['name'].astype(str)\ndlsB1['diagnosis'] = .25\n\ndirnum=\"\/2\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsB2 = pd.DataFrame()\ndlsB2['name'] = filenames\ndlsB2['name'] = dirnam+dirnum + dlsB2['name'].astype(str)\ndlsB2['diagnosis'] = .5\n\ndirnum=\"\/3\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsB3 = pd.DataFrame()\ndlsB3['name'] = filenames\ndlsB3['name'] = dirnam+dirnum + dlsB3['name'].astype(str)\ndlsB3['diagnosis'] = .75\n\ndirnum=\"\/4\/\"\nfor dirname, _, filenames in os.walk(dirnam+dirnum): pass\ndlsB4 = pd.DataFrame()\ndlsB4['name'] = filenames\ndlsB4['name'] = dirnam+dirnum + dlsB4['name'].astype(str)\ndlsB4['diagnosis'] = 1\n\ndls = pd.DataFrame().append([dlsA0, dlsA1, dlsA2, dlsA3, dlsA4, dlsB0, dlsB1, dlsB2, dlsB3, dlsB4],ignore_index = True)\ndlsV = pd.DataFrame().append([dls0, dls1, dls2, dls3, dls4],ignore_index = True)\ndls['name'] = dls['name'].astype(str)\n\ndls.reset_index(drop=True)\nprint(dls)\ndlsV = dlsV.sample(len(dlsV))\ndls = dls.sample(len(dls))\n\nend = time.time()\nprint(end - start)","eb7d5369":"def inception(x,depth):\n    x1 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x2 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x3 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x4 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x2 = Conv2D(depth, (1, 3), activation='relu', padding='same')(x2)\n    x2 = Conv2D(depth, (3, 1), activation='relu', padding='same')(x2)\n    x3 = Conv2D(depth, (1, 5), activation='relu', padding='same')(x3)\n    x3 = Conv2D(depth, (5, 1), activation='relu', padding='same')(x3)\n    x4 = Conv2D(depth, (1, 7), activation='relu', padding='same')(x4)\n    x4 = Conv2D(depth, (7, 1), activation='relu', padding='same')(x4)\n    x3a = AveragePooling2D(pool_size=(3, 3), strides=1, padding='same')(x)\n    x3b = Conv2D(depth, (1, 1), activation='relu', padding='same')(x3a)\n    d = concatenate([x1,x2,x3,x4,x3b], axis=-1)\n    return d\n\ndef reductionF(x,depth):\n    x1 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x1 = Conv2D(depth, (3, 3), strides=2, padding='same')(x1)\n    x2 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n    x2 = Conv2D(depth, (1, 1),  padding='same')(x2)\n    x1 = BatchNormalization()(x1)\n    x1 = Activation('relu')(x1)\n    x2 = BatchNormalization()(x2)\n    x2 = Activation('relu')(x2)\n    d = concatenate([x1,x2], axis=-1)\n    return d\n\ndef reductionI(x):\n    x1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(x)\n    x2 = AveragePooling2D(pool_size=(2, 2), strides=2, padding='same')(x)\n    d = concatenate([x1,x2], axis=-1)\n    return d\n\ndef reductionG(x,depth):\n    x1 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x1 = Conv2D(64, (3, 3), strides=2, padding='same')(x1)\n    x2 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n    x2 = Conv2D(depth, (1, 1), padding='same')(x2)\n    x3 = Conv2D(depth, (1, 1), activation='relu', padding='same')(x)\n    x3 = Conv2D(depth, (1, 7), activation='relu', padding='same')(x3)\n    x3 = Conv2D(depth, (7, 1), activation='relu', padding='same')(x3)\n    x3 = Conv2D(64, (3, 3), strides=2, padding='same')(x3)\n    x1 = BatchNormalization()(x1)\n    x1 = Activation('relu')(x1)\n    x2 = BatchNormalization()(x2)\n    x2 = Activation('relu')(x2)\n    x3 = BatchNormalization()(x3)\n    x3 = Activation('relu')(x3)\n    d = concatenate([x1,x2,x3], axis=-1)\n    return d\n\n\na = Input(shape=(512,512,3))\ny = BatchNormalization()(a)\ny1= reductionI(y)\nx = reductionF(y, 32)\ny= reductionI(y1)\nx = reductionF(x, 64)\nx1 = inception(x,64)\nx1 = Conv2D(64, (1, 1))(x1)\nx = concatenate([x1,x,y], axis=-1,name='128x128xinception')\nx = GaussianNoise(0.2)(x)\ny= reductionI(y)\nx = reductionG(x, 64)\nx1 = inception(x,64)\n#x1 = inception(x1,64)\nx1 = Conv2D(64, (1, 1))(x1)\nx = concatenate([x1,x,y], axis=-1,name='64x64xinception2')\ny= reductionI(y)\nx = reductionG(x, 64)\nx1 = inception(x,64)\n#x1 = inception(x1,64)\nx1 = Conv2D(64, (1, 1))(x1)\nx = concatenate([x1,x,y], axis=-1,name='32x32xinception2')\nx = GaussianNoise(0.5)(x)\ny= reductionI(y)\nx = reductionG(x, 64)\nx1 = inception(x,64)\n#x1 = inception(x1,64)\nx1 = Conv2D(64, (1, 1))(x1)\nx = concatenate([x1,x,y], axis=-1,name='16x16xinception2')\nx = reductionG(x, 64)\nx1 = inception(x,64)\n#x1 = inception(x1,64)\nx1 = Conv2D(64, (1, 1))(x1)\nx = concatenate([x1,x], axis=-1,name='8x8xinception2')\nx = GaussianNoise(0.5)(x)\nx = reductionG(x, 64)\nx = GaussianNoise(0.3)(x)\nx = Conv2D(32, (1, 1),name='4x4xconvolution')(x)\nx = AveragePooling2D(pool_size=(4, 4), strides=4, padding='valid')(x)\nx = Conv2D(1, (1, 1),name='1x1xconvolution')(x)\nx = Flatten()(x)\nb = Dense(1,activation='sigmoid')(x)\nmodel = Model(inputs=a, outputs=b)\n\nmodel.summary()\n\nmodel_rebuilt =1\n\nend = time.time()\nprint(end - start)","f9666e24":"datagen = ImageDataGenerator(\n    horizontal_flip=True,\n    vertical_flip=True\n)\nthe_flow = datagen.flow_from_dataframe(dls,x_col='name',y_col='diagnosis',shuffle=True, class_mode='raw',target_size=(512, 512), batch_size=32)\nthe_valid = datagen.flow_from_dataframe(dlsV,x_col='name',y_col='diagnosis',shuffle=True, class_mode='raw',target_size=(512, 512), batch_size=32)\n\nend = time.time()\nprint(end - start)","5e138198":"#Running a model\n\n\nfilepath=\"TheBestModel.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_right_acc', verbose=0, save_best_only=True, mode='max')\ncheckpoint2 = ModelCheckpoint(\"TheBestLoss.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, mode='min')\ncheckpoint3 = ModelCheckpoint(\"TheBestStd.hdf5\", monitor='val_std_error', verbose=0, save_best_only=True, mode='min')\ncheckpoint4 = ModelCheckpoint(\"TheBestTVAL.hdf5\", monitor='val_std_error', verbose=0, save_best_only=True, mode='min')\ncheckpoint5 = ModelCheckpoint(\"TheBestTLOSS.hdf5\", monitor='val_std_error', verbose=0, save_best_only=True, mode='min')\ncheckpoint6 = ModelCheckpoint(\"TheBestTSTD.hdf5\", monitor='val_std_error', verbose=0, save_best_only=True, mode='min')\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")\n\ncallbacks_list = [checkpoint,checkpoint2,checkpoint3,checkpoint4,checkpoint5,checkpoint6,tensorboard_callback]\n\nsgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\nmodel.compile(loss='mean_absolute_error', optimizer=sgd, metrics=[right_acc, std_error,p_meanX,p_stdX ])\n#datagen.fit(train_images)\n\nmodel_rebuilt =0\n\n#model.fit(x=train_images, y=train_labels, epochs=50, verbose =0,validation_split=0.1, shuffle=True) \n\nend = time.time()\nprint(end - start)\nfirstrun = 1","e4284a21":"batch_size = 32\nepochs = 100\nverboseX = 2\nsteps_per_e = 200\nvalidation_stepsX = 20\n\nif firstrun == 1:\n    !cp \/kaggle\/input\/goodkernel\/TheBestLoss.hdf5 \/kaggle\/working\/TheBestModel.hdf5\n    model.load_weights(filepath)\n    \nfirstrun = 0\nhist = model.fit_generator(the_flow, callbacks=callbacks_list, use_multiprocessing=False, shuffle=True, workers=1,steps_per_epoch=steps_per_e,\n               epochs=1, verbose =verboseX, validation_data=the_valid, validation_steps=validation_stepsX )\nhist = model.fit_generator(the_flow, callbacks=callbacks_list, use_multiprocessing=False, shuffle=True, workers=1,steps_per_epoch=steps_per_e,\n               epochs=epochs, verbose =verboseX, validation_data=the_valid, validation_steps=validation_stepsX )\n\nmodel.load_weights(filepath)\n\nend = time.time()\nprint(end - start)\n","3f40245b":"plt.plot(hist.history['right_acc'])\nplt.plot(hist.history['val_right_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nend = time.time()\nprint(end - start)","8435a9b7":"for dirname, _, filenames in os.walk('\/kaggle\/input\/aptos2019-blindness-detection\/train_images'):\n    pass\ndirname=\"\/kaggle\/input\/aptos2019-blindness-detection\/train_images\"\n    \ntrain = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv', header=0)\ntrain['diagnosis_2'] = 0\ntrain['diagnosis_3'] = 0\nbad = [0,0,0,0,0]\ntotal_type = [0,0,0,0,0]\n\nw = np.zeros((5,5)); w\nfor i in range(len(w)):\n    for j in range(len(w)):\n        w[i][j] = float(((i-j)**2)\/16) #as per formula, for this competition, N=5\n\nactuals = []\npred_list = []\n\ncount = 0\naccurat = 0\ninaccurat = 0\n#nimg = {}\nfor filename in filenames:\n    if filename[(len(filename)-4):] == \".png\":\n        img = cv2.imread(os.path.join(dirname, filename))\n        new_img = im_resize(img)\n        thisav = im_avg(new_img)\n        dgamma = thisav[0]+thisav[1]+thisav[2]\n        #new_img = adjust_gamma2(new_img,(((400) \/ dgamma)))\n        #new_img = np.divide(new_img,255.0)\n        count = count+1\n        k = np.reshape(new_img,(1,512,512,3))\n        \n        real_pred = min(4,max(0,model.predict(k)[0][0]*4))\n        pred = round(real_pred)  #np.round(real_pred)\n        real = train[train.id_code==filename[:-4]].diagnosis.item()\n        train.loc[train.id_code==filename[:-4],'diagnosis_2']=int(pred)\n        train.loc[train.id_code==filename[:-4],'diagnosis_3']=real_pred\n        #print(real, \" \", pred, \" \",real_pred)\n        actuals.append(real)\n        pred_list.append(int(pred))\n        total_type[real] +=1\n        if int(pred) == real:\n            accurat +=1\n        else:\n            inaccurat +=1\n            bad[real] += 1\n        if count % 100 == 0: \n            O = confusion_matrix(actuals, pred_list); print(O)\n            N=5\n            act_hist=np.zeros([N])\n            for item in actuals: \n                act_hist[item]+=1\n\n            pred_hist=np.zeros([N])\n            for item in pred_list: \n                pred_hist[item]+=1\n            E = np.outer(act_hist, pred_hist); E\n            E = E\/E.sum(); E.sum()\n            O = O\/O.sum(); O.sum()                    \n            num=0\n            den=0\n            for i in range(len(w)):\n                for j in range(len(w)):\n                    num+=w[i][j]*O[i][j]\n                    den+=w[i][j]*E[i][j]\n\n            weighted_kappa = (1 - (num\/den)); print(weighted_kappa)\n            \n            print(count, \" - Good: \",accurat, \" n Bad: \",inaccurat, \" - Bad: \",bad, \" Total = \",total_type, \" percent right = \",[1 - ((b) \/ (m)) for b,m in zip(bad, total_type)])\n \ntrain\n\nend = time.time()\nprint(end - start)","259a432d":"for dirname, _, filenames in os.walk('\/kaggle\/input\/aptos2019-blindness-detection\/test_images'):\n    pass\ndirname=\"\/kaggle\/input\/aptos2019-blindness-detection\/test_images\"\n    \ntest = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv', header=0)\ntest['diagnosis'] = 0\n\ntest_images = []\ntest_labels = []\ncount = 0\n#nimg = {}\nfor filename in filenames:\n    if filename[(len(filename)-4):] == \".png\":\n        img = cv2.imread(os.path.join(dirname, filename))\n        new_img = im_resize(img)\n        thisav = im_avg(new_img)\n        dgamma = thisav[0]+thisav[1]+thisav[2]\n        #new_img = adjust_gamma2(new_img,(((400) \/ dgamma)))\n        #new_img = np.divide(new_img,255.0)\n        count = count+1\n        #nimg[filename[:-4]] = new_img\n        k = np.reshape(new_img,(1,512,512,3))\n       # print(np.shape(k), np.shape(test_images))\n        #if len(test_images) ==0:\n        #    test_images = np.copy(k)\n        #else:\n        #    test_images=np.vstack([test_images,k])\n        #test_labels.append(test[test.id_code==filename[:-4]].diagnosis.item())\n        real_pred = min(4,max(0,model.predict(k)[0][0]*4))\n        pred = round(real_pred)  #np.round(real_pred)\n        test.loc[test.id_code==filename[:-4],'diagnosis']=int(pred)\n       # print(pred, int(pred))\n        \n        if count % 50 == 0: \n            print(count)\n     #   if count % 1000 == 0: \n            #break\n#test_labels = np.asarray(test_labels)    \ntest.to_csv('submission.csv',index=False)\ntest\n#pred = np.round(abs(model.predict(test_images))*4)\n#print(pred)\n\nend = time.time()\nprint(end - start)","c78f9aba":"a = np.round([8,3.56,4,5,6])\nprint(a.sort())\nprint(a)","8282919d":"## ML Time!\n### the Model\n\nLabels and training images are loaded and done\n\n","9754bc2b":"## Final Output Processing\nThis runs over the test sets and makes a final result submission.csv","aab0510a":"## Sanity Check\nChecks the model against all the training data - as we only used a subsample of 1000 images, that leaves 2662 images as well as the originals\ngood is good, bad is bad and the array is which images were not detected properly","209e4891":"## **Geoff's ok Kernel**\n\nJust a big mess at the moment\n\nThis page does some bad image manipulation and turns the images into a batch list for ml processing.\n\nIt crops the black and wide edges, resizes to 512 and poorly gamma corrects.\n\nModels still need to be saved and turned and used to process the test images.","4ec1c4e3":"### Model Generation Time!"}}