{"cell_type":{"a1b3551a":"code","e2fa9774":"code","d4341406":"code","1d3eec2a":"code","4e89326c":"code","9d202c37":"code","722ce7d5":"code","7d33ccef":"code","78c80cb8":"code","27d094a0":"code","b821f735":"code","82508ff5":"code","78ee2e01":"code","207c7f0e":"code","a263b32a":"code","3b6fd43e":"code","50eaaeae":"code","74e69998":"code","0f39c15d":"code","f6db9ddf":"code","9fe300d2":"code","93fc45ca":"code","045e8807":"code","7232bc7c":"code","fdc359e2":"markdown","697ce61a":"markdown","06d4a5d1":"markdown","40ee4dfb":"markdown","c4a673b9":"markdown","e54dc3fa":"markdown","33ee44cf":"markdown","0c96284b":"markdown"},"source":{"a1b3551a":"import numpy as np\nimport pandas as pd \nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e2fa9774":"class_names = ['glass', 'paper']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\nnb_classes = len(class_names)","d4341406":"def load_data():\n    datasets = ['..\/input\/garbage\/train','..\/input\/garbage\/test']\n    output = []\n    \n    for dataset in datasets:\n        images = []\n        labels = []\n        \n        print(\"Loading {} \".format(dataset))\n        for folder in os.listdir(dataset):\n            print(\"\/ \"+folder)\n            label = class_names_label[folder]\n            #label = class_names_label[folder]\n            print(label)\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                print(img_path)\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, (150,150)) \n                images.append(image)\n                labels.append(label)\n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')\n        \n        output.append((images, labels))\n    return output","1d3eec2a":"(train_images, train_labels), (test_images, test_labels) = load_data()","4e89326c":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","9d202c37":"train_labels[:10]","722ce7d5":"n_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format((150,150)))","7d33ccef":"import pandas as pd\n\n_, train_counts = np.unique(train_labels, return_counts=True)\n_, test_counts = np.unique(test_labels, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'test': test_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()","78c80cb8":"plt.pie(train_counts,\n        explode=(0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","27d094a0":"train_images = train_images \/ 255.0 \ntest_images = test_images \/ 255.0","b821f735":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","82508ff5":"display_random_image(class_names, train_images, train_labels)","78ee2e01":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","207c7f0e":"display_examples(class_names, train_images, train_labels)","a263b32a":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","3b6fd43e":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","50eaaeae":"history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)","74e69998":"def plot_accuracy_loss(history):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","0f39c15d":"plot_accuracy_loss(history)","f6db9ddf":"test_loss = model.evaluate(test_images, test_labels)","9fe300d2":"predictions = model.predict(test_images)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n\ndisplay_random_image(class_names, test_images, pred_labels)","93fc45ca":"def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n    \"\"\"\n        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n    \"\"\"\n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n\n    title = \"Some examples of mislabeled images by the classifier:\"\n    display_examples(class_names,  mislabeled_images, mislabeled_labels)\n","045e8807":"print_mislabeled_images(class_names, test_images, test_labels, pred_labels)","7232bc7c":"CM = confusion_matrix(test_labels, pred_labels)\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","fdc359e2":"## Import Packages","697ce61a":"Class names that include our test and train dataset for labeling the data","06d4a5d1":"## Sequential Model","40ee4dfb":"## Loading the Data","c4a673b9":"### Visualize the data","e54dc3fa":"## Explore the dataset","33ee44cf":"### Scale the data","0c96284b":"split test and train data"}}