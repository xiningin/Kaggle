{"cell_type":{"80ba5096":"code","402cae25":"code","cbc0b975":"code","7b6e46a6":"code","a96bc4c3":"code","15169081":"code","706ba916":"code","d72ced91":"code","63884370":"code","9d0b6fe5":"code","c07c6c0a":"code","8756cad8":"code","99da4af9":"code","d6786bd8":"code","c6b884b2":"code","35870a03":"code","8a018706":"code","e66514f1":"code","51b60fae":"code","f2f52f2a":"code","5ca217cd":"code","c798bd1f":"code","8ed72d25":"code","7f0d4f9c":"code","8f37f729":"code","2f0a76bf":"code","9989dd9e":"code","13a70b52":"markdown","f30e529a":"markdown","94fb0dbe":"markdown","ff60c486":"markdown","0399e320":"markdown","f57537ef":"markdown"},"source":{"80ba5096":"# General Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import date\n\n# sklearn for building and evaluation model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import preprocessing\n\nfrom xgboost import XGBRegressor","402cae25":"def split_num_cat_cols(df):\n    n_cols = (df.select_dtypes(exclude=[\"object\"])\n             .columns\n             .to_list())\n    c_cols = (df.select_dtypes(include=[\"object\"])\n             .columns\n             .to_list())\n        \n    return n_cols, c_cols\n\ndef get_RF_score(df):\n    X = df.drop([\"SalePrice\"], axis=1)\n    y = df[\"SalePrice\"]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n    \n    rf_model = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=-1)\n    rf_model.fit(X_train, y_train)\n    \n    pred = rf_model.predict(X_test)\n    rmse = mean_squared_error(np.log1p(y_test), np.log1p(pred), squared=False)\n    \n    return rmse\n    \ndef get_xgb_score(df):\n    X = df.drop([\"SalePrice\"], axis=1)\n    y = df[\"SalePrice\"]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n    xgb = XGBRegressor()\n    xgb.fit(X_train, y_train)\n    \n    pred = xgb.predict(X_test)\n    rmse = mean_squared_error(np.log1p(y_test), np.log1p(pred), squared=False)\n    \n    return rmse\n\n\n\ndef generate_rf_submission(train, test, sub):\n    \n    X = train.drop([\"SalePrice\"], axis=1)\n    y = train[\"SalePrice\"]\n    \n    rf_model = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=-1)\n    rf_model.fit(X, y)\n    \n    y_pred = rf_model.predict(test)\n    \n    sub[\"SalePrice\"] = y_pred\n    return sub\n        ","cbc0b975":"df = pd.read_csv(\"..\/input\/housepriceadvancedregressioncleandata\/clean_train.csv\")\ntest_df = pd.read_csv(\"..\/input\/housepriceadvancedregressioncleandata\/clean_test.csv\")\nsubmission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")","7b6e46a6":"# Calculating the base score on whole dataset\n\n# remove some mismatched cols\nodd_cols = [\"Condition1\", \"Condition2\", \"RoofMatl\", \"LandSlope\", \"Functional\", \"MiscFeature\"]\ntrain_df1 = df.drop(odd_cols, axis=1)\ntest_df1 = test_df.drop(odd_cols, axis=1)\n\n# Split the numerical and categorical cols\nn_cols, c_cols = split_num_cat_cols(train_df1)\n\n# Encode the categorical columns with OrdinalEncoder\nord_enc = preprocessing.OrdinalEncoder()\n\ntrain_df1[c_cols] = ord_enc.fit_transform(train_df1[c_cols])\ntest_df1[c_cols] = ord_enc.transform(test_df1[c_cols])\n\nrf_score = get_RF_score(train_df1.drop([\"Id\"],axis=1))\nxgb_score = get_xgb_score(train_df1.drop([\"Id\"], axis=1))\n\nprint(f\"Random Forest Score : {rf_score}\")\nprint(f\"XGB Score : {xgb_score}\")\n\n## make the submission file\nsub_1 = generate_rf_submission(train_df1.drop([\"Id\"],axis=1), test_df1.drop([\"Id\"],axis=1), submission)\nsub_1.to_csv(\"submission_1.csv\", index=False)","a96bc4c3":"print(train_df1.columns.to_list())","15169081":"# basic things for considering to buy new house\n# 1.location, 2.number of bedrooms, 3.garage, 4.poarch area, 5.overall condition of home etc.","706ba916":"# Calculate the score with some specific random Features\n\ncols = [\"MSZoning\", \"LotFrontage\", \"LotArea\", \"Street\", \"LotShape\",\n        \"Utilities\", \"Neighborhood\", \"BldgType\", \"HouseStyle\",\n        \"OverallQual\", \"YearBuilt\", \"GrLivArea\", \"GarageArea\", \"SalePrice\"]\n\nrf_score = get_RF_score(train_df1[cols])\nxgb_score = get_xgb_score(train_df1[cols])\n\nprint(f\"Random Forest Score : {rf_score}\")\nprint(f\"XGB Score : {xgb_score}\")","d72ced91":"# make the copy of the dataset\ndata1 = train_df1.copy()","63884370":"# Adding new features\ndata1[\"total_area\"] = (data1[\"LotFrontage\"]+data1[\"LotArea\"]+data1[\"LotShape\"]+data1[\"MasVnrArea\"]+data1[\"GrLivArea\"]+data1[\"GarageArea\"]+data1[\"PoolArea\"])\ndata1[\"house_age\"] = (date.today().year - data1[\"YearBuilt\"])\ndata1[\"overall_extr\"] = (data1[\"Exterior1st\"]+data1[\"Exterior2nd\"]+data1[\"ExterQual\"]+data1[\"ExterCond\"])\ndata1[\"overall_bmst\"] = (data1[\"BsmtQual\"]+data1[\"BsmtCond\"]+data1[\"BsmtExposure\"]+data1[\"BsmtFinType1\"]+data1[\"BsmtFinSF1\"]+\n                         data1[\"BsmtFinType2\"]+data1[\"BsmtFinSF2\"]+data1[\"BsmtUnfSF\"]+data1[\"TotalBsmtSF\"]+data1[\"BsmtFullBath\"]+data1[\"BsmtHalfBath\"])\ndata1[\"house_interior_cond\"] = (data1[\"overall_bmst\"]+data1[\"Heating\"]+data1[\"HeatingQC\"]+data1[\"CentralAir\"]+\n                                data1[\"Electrical\"]+data1[\"1stFlrSF\"]+data1[\"2ndFlrSF\"]+data1[\"BedroomAbvGr\"]+\n                                data1[\"KitchenAbvGr\"]+data1[\"TotRmsAbvGrd\"]+data1[\"Fireplaces\"]+data1[\"FireplaceQu\"])\ndata1[\"total_porch\"] = (data1[\"OpenPorchSF\"]+data1[\"EnclosedPorch\"]+data1[\"3SsnPorch\"]+data1[\"ScreenPorch\"])\ndata1[\"overall_garage\"] = (data1[\"GarageType\"]+data1[\"GarageFinish\"]+data1[\"GarageCars\"]+data1[\"GarageArea\"]+\n                           data1[\"GarageQual\"]+data1[\"GarageCond\"])\ndata1[\"garage_age\"] = (date.today().year - data1[\"GarageYrBlt\"])","9d0b6fe5":"# Calculate score\nrf_score = get_RF_score(data1.drop([\"Id\"],axis=1))\nxgb_score = get_xgb_score(data1.drop([\"Id\"], axis=1))\n\nprint(f\"Random Forest Score : {rf_score}\")\nprint(f\"XGB Score : {xgb_score}\")","c07c6c0a":"print(train_df1[n_cols].columns)","8756cad8":"# Adding new Feature with help of EDA (pairplot diagram)\n# link : https:\/\/www.kaggle.com\/bhagwangawali\/part-i-eda\n\n# make the copy of train and test set\ntrain_df2 = train_df1.copy()\ntest_df2 = test_df1.copy()\n\nnew_feature1 = pd.DataFrame()\nnew_feature1[\"f1_add\"] = train_df2[\"LotFrontage\"] + train_df2[\"LotArea\"]\nnew_feature1[\"f2_add\"] = train_df2[\"LotFrontage\"] + train_df2[\"BsmtFinSF1\"]\n\nnew_feature1[\"f3_add\"] = train_df2[\"MasVnrArea\"] + train_df2[\"BsmtFinSF1\"]\n\nnew_feature1[\"f4_add\"] = train_df2[\"BsmtUnfSF\"] + train_df2[\"GrLivArea\"]\nnew_feature1[\"f5_add\"] = train_df2[\"BsmtUnfSF\"] + train_df2[\"1stFlrSF\"]\nnew_feature1[\"f6_add\"] = train_df2[\"BsmtUnfSF\"] + train_df2[\"TotalBsmtSF\"]\nnew_feature1[\"f7_add\"] = train_df2[\"BsmtUnfSF\"] + train_df2[\"TotalBsmtSF\"]\n\nnew_feature1[\"f8_add\"] = train_df2[\"TotalBsmtSF\"] + train_df2[\"OpenPorchSF\"]\nnew_feature1[\"f9_add\"] = train_df2[\"TotalBsmtSF\"] + train_df2[\"GarageArea\"]\nnew_feature1[\"f10_add\"] = train_df2[\"TotalBsmtSF\"] + train_df2[\"GrLivArea\"]\nnew_feature1[\"f11_add\"] = train_df2[\"TotalBsmtSF\"] + train_df2[\"1stFlrSF\"]\n\nnew_feature1[\"f12_add\"] = train_df2[\"1stFlrSF\"] + train_df2[\"GarageArea\"]\nnew_feature1[\"f13_add\"] = train_df2[\"1stFlrSF\"] + train_df2[\"GrLivArea\"]\n\nnew_feature1[\"f14_add\"] = train_df2[\"GrLivArea\"] + train_df2[\"GrLivArea\"]\n\nall_data1 = pd.concat([train_df2, new_feature1], axis=1)","99da4af9":"# Calculate score\nrf_score = get_RF_score(all_data1.drop([\"Id\"],axis=1))\nxgb_score = get_xgb_score(all_data1.drop([\"Id\"], axis=1))\n\nprint(f\"Random Forest Score : {rf_score}\")\nprint(f\"XGB Score : {xgb_score}\")","d6786bd8":"new_feature2 = pd.DataFrame()\nnew_feature2[\"f1_mult\"] = train_df2[\"LotFrontage\"] * train_df2[\"LotArea\"]\nnew_feature2[\"f2_mult\"] = train_df2[\"LotFrontage\"] * train_df2[\"BsmtFinSF1\"]\n\nnew_feature2[\"f3_mult\"] = train_df2[\"MasVnrArea\"] * train_df2[\"BsmtFinSF1\"]\n\nnew_feature2[\"f4_mult\"] = train_df2[\"BsmtUnfSF\"] * train_df2[\"GrLivArea\"]\nnew_feature2[\"f5_mult\"] = train_df2[\"BsmtUnfSF\"] * train_df2[\"1stFlrSF\"]\nnew_feature2[\"f6_mult\"] = train_df2[\"BsmtUnfSF\"] * train_df2[\"TotalBsmtSF\"]\nnew_feature2[\"f7_mult\"] = train_df2[\"BsmtUnfSF\"] * train_df2[\"TotalBsmtSF\"]\n\nnew_feature2[\"f8_mult\"] = train_df2[\"TotalBsmtSF\"] * train_df2[\"OpenPorchSF\"]\nnew_feature2[\"f9_mult\"] = train_df2[\"TotalBsmtSF\"] * train_df2[\"GarageArea\"]\nnew_feature2[\"f10_mult\"] = train_df2[\"TotalBsmtSF\"] * train_df2[\"GrLivArea\"]\nnew_feature2[\"f11_mult\"] = train_df2[\"TotalBsmtSF\"] * train_df2[\"1stFlrSF\"]\n\nnew_feature2[\"f12_mult\"] = train_df2[\"1stFlrSF\"] * train_df2[\"GarageArea\"]\nnew_feature2[\"f13_mult\"] = train_df2[\"1stFlrSF\"] * train_df2[\"GrLivArea\"]\n\nnew_feature2[\"f14_mult\"] = train_df2[\"GrLivArea\"] * train_df2[\"GrLivArea\"]\n\nall_data2 = pd.concat([train_df2, new_feature2], axis=1)","c6b884b2":"# Calculate score\nrf_score = get_RF_score(all_data2.drop([\"Id\"],axis=1))\nxgb_score = get_xgb_score(all_data2.drop([\"Id\"], axis=1))\n\nprint(f\"Random Forest Score : {rf_score}\")\nprint(f\"XGB Score : {xgb_score}\")","35870a03":"# functions for getting high and low cardinality features from data set\ndef get_high_and_low_cardinality_feature(df):\n    high_cardi, low_cardi = [], []\n    \n    for col in df.columns:\n        if df[col].nunique() > 10:\n            high_cardi.append(col)\n        else:\n            low_cardi.append(col)\n    return high_cardi, low_cardi","8a018706":"# Convert the Feature into low and high cardinality \n\nodd_cols = [\"Condition1\", \"Condition2\", \"RoofMatl\", \"LandSlope\", \"Functional\", \"MiscFeature\"] + ['Utilities', 'HouseStyle', 'Heating', 'Electrical', 'GarageQual', 'PoolQC']\ntrain_df2 = df.drop(odd_cols, axis=1)\ntest_df2 = test_df.drop(odd_cols, axis=1)\n\ntrain_high_c, train_low_c = get_high_and_low_cardinality_feature(train_df2.drop([\"Id\", \"SalePrice\"], axis=1))\ntest_high_c, test_low_c = get_high_and_low_cardinality_feature(test_df2.drop([\"Id\"], axis=1))","e66514f1":"unmached_col= []\n\nfor col in cat1:\n    if len(set(train_df2[col].unique()) ^ set(test_df2[col].unique())) > 0:\n        unmached_col.append(col)\n\nunmached_col","51b60fae":"# low cardinality data\n# Split the columns into numerical and categorical feature\n_, cat1 = split_num_cat_cols(train_df2[train_low_c])\n_, cat2 = split_num_cat_cols(test_df2[test_low_c])\n\ntrain_hot = pd.get_dummies(data=train_df2[cat1], prefix=\"hot\")\ntest_hot = pd.get_dummies(data=test_df2[cat1], prefix=\"hot\")","f2f52f2a":"train_hot.shape, test_hot.shape","5ca217cd":"# high cardinality data\n\n# Split the columns into numerical and categorical feature\n_, cat3 = split_num_cat_cols(train_df2[train_high_c])\n_, cat4 = split_num_cat_cols(test_df2[test_high_c])\n\nord_enc = preprocessing.OrdinalEncoder()\n\nord_train = ord_enc.fit_transform(train_df2[cat3])\nord_test = ord_enc.transform(test_df2[cat4])\n\nord_train_df = pd.DataFrame(ord_train, columns=cat3)\nord_test_df = pd.DataFrame(ord_test, columns=cat4)","c798bd1f":"# Combine all data\nall_train_data = train_df2.drop(cat1+cat3, axis=1)\nall_test_data = test_df2.drop(cat1+cat3, axis=1)","8ed72d25":"all_train_1 = pd.concat([all_train_data, train_hot, ord_train_df], axis=1)\nall_test_1 = pd.concat([all_test_data, test_hot, ord_test_df], axis=1)","7f0d4f9c":"all_train_1.head()","8f37f729":"all_test_1.head()","2f0a76bf":"set(all_train_1.columns.to_list()) ^ set(all_test_1.columns.to_list())","9989dd9e":"# Calculate score\nrf_score = get_RF_score(all_train_1.drop([\"Id\"],axis=1))\n# xgb_score = get_xgb_score(all_train_1.drop([\"Id\"], axis=1))\n\nprint(f\"Random Forest Score : {rf_score}\")\n# print(f\"XGB Score : {xgb_score}\")","13a70b52":"### OneHot Encoding","f30e529a":"You can see by choosing some random specific feature will reduce the score","94fb0dbe":"## Load Data","ff60c486":"## Base Score","0399e320":"### Add some new features","f57537ef":"## General Feature Engineering"}}