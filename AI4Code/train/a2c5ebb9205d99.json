{"cell_type":{"d3b942e2":"code","7a16fd53":"code","fd82fb62":"code","e193b23a":"code","8eb86af9":"code","0144642f":"code","46f70efc":"code","f5e1f913":"code","0d5fa623":"markdown","25eaf5e0":"markdown","57b887b4":"markdown","8271193a":"markdown","aab845a2":"markdown","489d19e6":"markdown","1ddfc48b":"markdown"},"source":{"d3b942e2":"%%time\n\nimport os\nimport logging\nimport sys\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\n\nimport xgboost as xgbm","7a16fd53":"%%time\n\nfolds_dir = \"..\/input\/tps-september-2021-skfolds\/\"\ndata_dir = \"..\/input\/tabular-playground-series-sep-2021\/\"\n\ndf_train = pd.read_csv(folds_dir + \"train_folds.csv\")\ndf_test = pd.read_csv(data_dir + \"test.csv\")\nsubmission = pd.read_csv(data_dir + \"sample_solution.csv\")\n\nfeatures = [col for col in df_test.columns if \"f\" in col]\ndf_test = df_test[features]\n\n# constants\nTARGET = \"claim\"","fd82fb62":"%%time\n\ndef add_new_features(df):\n    # https:\/\/www.kaggle.com\/realtimshady\/single-simple-lightgbm\n    df[\"n_missing\"] = df[features].isna().sum(axis=1)\n    df[\"n_missing_std\"] = df.isna().std(axis=1).astype(\"float\")\n    df[\"abs_sum\"] = df[features].abs().sum(axis=1)\n    df[\"sem\"] = df[features].sem(axis=1)\n    df[\"std\"] = df[features].std(axis=1)\n    df[\"avg\"] = df[features].mean(axis=1)\n    df[\"max\"] = df[features].max(axis=1)\n    df[\"min\"] = df[features].min(axis=1)\n    \n    return df\n\ndf_train = add_new_features(df_train)\ndf_test = add_new_features(df_test)\n\nnew_features = [\"n_missing\", \"n_missing_std\", \"abs_sum\", \n             \"sem\", \"std\", \"avg\", \"max\", \"min\"]\n\nfeatures += new_features","e193b23a":"fill_value_dict = {\n    \"f1\": \"Mean\", \n    \"f2\": \"Median\", \n    \"f3\": \"Median\", \n    \"f4\": \"Median\", \n    \"f5\": \"Mode\", \n    \"f6\": \"Mean\", \n    \"f7\": \"Median\", \n    \"f8\": \"Median\", \n    \"f9\": \"Median\", \n    \"f10\": \"Median\", \n    \"f11\": \"Mean\", \n    \"f12\": \"Median\", \n    \"f13\": \"Mean\", \n    \"f14\": \"Median\", \n    \"f15\": \"Mean\", \n    \"f16\": \"Median\", \n    \"f17\": \"Median\", \n    \"f18\": \"Median\", \n    \"f19\": \"Median\", \n    \"f20\": \"Median\", \n    \"f21\": \"Median\", \n    \"f22\": \"Mean\", \n    \"f23\": \"Mode\", \n    \"f24\": \"Median\", \n    \"f25\": \"Median\", \n    \"f26\": \"Median\", \n    \"f27\": \"Median\", \n    \"f28\": \"Median\", \n    \"f29\": \"Mode\", \n    \"f30\": \"Median\", \n    \"f31\": \"Median\", \n    \"f32\": \"Median\", \n    \"f33\": \"Median\", \n    \"f34\": \"Mean\", \n    \"f35\": \"Median\", \n    \"f36\": \"Mean\", \n    \"f37\": \"Median\", \n    \"f38\": \"Median\", \n    \"f39\": \"Median\", \n    \"f40\": \"Mode\", \n    \"f41\": \"Median\", \n    \"f42\": \"Mode\", \n    \"f43\": \"Mean\", \n    \"f44\": \"Median\", \n    \"f45\": \"Median\", \n    \"f46\": \"Mean\", \n    \"f47\": \"Mode\", \n    \"f48\": \"Mean\", \n    \"f49\": \"Mode\", \n    \"f50\": \"Mode\", \n    \"f51\": \"Median\", \n    \"f52\": \"Median\", \n    \"f53\": \"Median\", \n    \"f54\": \"Mean\", \n    \"f55\": \"Mean\", \n    \"f56\": \"Mode\", \n    \"f57\": \"Mean\", \n    \"f58\": \"Median\", \n    \"f59\": \"Median\", \n    \"f60\": \"Median\", \n    \"f61\": \"Median\", \n    \"f62\": \"Median\", \n    \"f63\": \"Median\", \n    \"f64\": \"Median\", \n    \"f65\": \"Mode\", \n    \"f66\": \"Median\", \n    \"f67\": \"Median\", \n    \"f68\": \"Median\", \n    \"f69\": \"Mean\", \n    \"f70\": \"Mode\", \n    \"f71\": \"Median\", \n    \"f72\": \"Median\", \n    \"f73\": \"Median\", \n    \"f74\": \"Mode\", \n    \"f75\": \"Mode\", \n    \"f76\": \"Mean\", \n    \"f77\": \"Mode\", \n    \"f78\": \"Median\", \n    \"f79\": \"Mean\", \n    \"f80\": \"Median\", \n    \"f81\": \"Mode\", \n    \"f82\": \"Median\", \n    \"f83\": \"Mode\", \n    \"f84\": \"Median\", \n    \"f85\": \"Median\", \n    \"f86\": \"Median\", \n    \"f87\": \"Median\", \n    \"f88\": \"Median\", \n    \"f89\": \"Median\", \n    \"f90\": \"Mean\", \n    \"f91\": \"Mode\", \n    \"f92\": \"Median\", \n    \"f93\": \"Median\", \n    \"f94\": \"Median\", \n    \"f95\": \"Median\", \n    \"f96\": \"Median\", \n    \"f97\": \"Mean\", \n    \"f98\": \"Median\", \n    \"f99\": \"Median\", \n    \"f100\": \"Mode\", \n    \"f101\": \"Median\", \n    \"f102\": \"Median\", \n    \"f103\": \"Median\", \n    \"f104\": \"Median\", \n    \"f105\": \"Median\", \n    \"f106\": \"Median\", \n    \"f107\": \"Median\", \n    \"f108\": \"Median\", \n    \"f109\": \"Mode\", \n    \"f110\": \"Median\", \n    \"f111\": \"Median\", \n    \"f112\": \"Median\", \n    \"f113\": \"Mean\", \n    \"f114\": \"Median\", \n    \"f115\": \"Median\", \n    \"f116\": \"Mode\", \n    \"f117\": \"Median\", \n    \"f118\": \"Mean\"\n}\n\n\nfor col in tqdm(features):\n    if fill_value_dict.get(col)==\"Mean\":\n        fill_value = df_train[col].mean()\n    elif fill_value_dict.get(col)==\"Median\":\n        fill_value = df_train[col].median()\n    elif fill_value_dict.get(col)==\"Mode\":\n        fill_value = df_train[col].mode().iloc[0]\n    \n    df_train[col].fillna(fill_value, inplace=True)\n    df_test[col].fillna(fill_value, inplace=True)","8eb86af9":"%%time\n\npipe = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"constant\", missing_values=np.nan)),\n    (\"scaler\", RobustScaler())\n])\n\ndf_train[features] = pipe.fit_transform(df_train[features])\ndf_test[features] = pipe.transform(df_test[features])","0144642f":"def predict(df_train, df_test, folds=5):\n    test_preds = []\n    valid_preds = {}\n    scores = []\n    \n    params = {\n        \"random_state\": 42,\n        \"eval_metric\": \"auc\",\n        \"n_estimators\" : 8000,\n        \"use_label_encoder\" : \"False\",\n        \"max_depth\" : 3,\n        \"learning_rate\" : 0.027297134107723935,\n        \"colsample_bytree\" : 0.7843918860573006,\n        \"objective\" : \"binary:logistic\", \n        \"subsample\" : 0.7459596984766819,\n        \"gamma\" : 0.05008218776821978,\n        \"reg_alpha\" : 0.861755644724069,\n        \"reg_lambda\" : 0.11499104081826494,\n        \"min_child_weight\" : 227, \n        \"booster\" : \"gbtree\",\n        # cpu\n        #\"n_jobs\": -1,\n        # gpu\n        \"predictor\": \"gpu_predictor\",\n        \"tree_method\": \"gpu_hist\"\n    }\n    \n    for fold in range(folds):\n        x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n        x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        x_test = df_test.copy()\n        \n        valid_ids = x_valid.id.values.tolist()\n\n        y_train = x_train[TARGET]\n        y_valid = x_valid[TARGET]\n\n        x_train = x_train[features]\n        x_valid = x_valid[features]\n\n        model = xgbm.XGBClassifier(**params)\n        model.fit(\n            x_train, y_train,\n            eval_set=[(x_valid, y_valid)],\n            early_stopping_rounds=300,\n            verbose=1000\n        )\n        \n        valid_pred = model.predict_proba(x_valid)[:, 1]\n        test_pred = model.predict_proba(x_test)[:, 1]\n        \n        test_preds.append(test_pred)\n        valid_preds.update(dict(zip(valid_ids, valid_pred)))\n\n        score = roc_auc_score(y_valid, valid_pred)\n        print(f\"Fold {fold} | AUC: {score}\")\n        scores.append(score)\n    \n    test_preds = np.mean(np.column_stack(test_preds), axis=1)\n    valid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\n    \n    return test_preds, valid_preds, scores","46f70efc":"test_preds, valid_preds, scores = predict(df_train, df_test)\nprint(np.mean(scores), np.std(scores))","f5e1f913":"valid_preds.columns = [\"id\", \"xgb_pred_3\"]\nvalid_preds.to_csv(\"xgb_train_3.csv\", index=False)\n\ntest_preds_df = pd.DataFrame({\"id\": submission.id, \"xgb_pred_3\": test_preds})\ntest_preds_df.to_csv(\"xgb_test_3.csv\", index=False)\n\nsub = pd.DataFrame({\"id\": submission.id, \"claim\": test_preds})\nsub.to_csv(\"submission.csv\", index=False)","0d5fa623":"# TPS September 2021 - XGBoost Baseline","25eaf5e0":"## Predict","57b887b4":"## Feature engineering","8271193a":"## Load datasets","aab845a2":"## Save","489d19e6":"## Preprocessing","1ddfc48b":"## Import libraries"}}