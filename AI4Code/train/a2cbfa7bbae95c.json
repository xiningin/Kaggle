{"cell_type":{"7f586030":"code","71614cd2":"code","2b0da76b":"code","73bb38d5":"code","46d82f32":"code","48ffb245":"code","a3f3de9c":"code","bd6f5fb8":"code","cd2fcafb":"code","762c361e":"code","8017143e":"code","aa8df8e8":"code","290a7d53":"code","ceedd5f0":"code","df9ec309":"code","d68a7d15":"code","56d3ebdb":"code","d70cdecd":"code","e35f8732":"code","e58bef90":"code","90402c5b":"code","637dcb33":"code","48e736a1":"code","256a33b6":"code","1c72e8c3":"markdown"},"source":{"7f586030":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","71614cd2":"#loading dataset\n\ndf_data=pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")","2b0da76b":"\ndf_data.head(10)\n\n","73bb38d5":"df_data.info()","46d82f32":"#dropping columns with empty values\ndf_data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\ndf_data","48ffb245":"df_data.info()","a3f3de9c":"#count the number of rows and columns in the dataset\ndf_data.shape\n","bd6f5fb8":"#Count the number of malignant (M) or (B) cells\ndf_data['diagnosis'].value_counts()","cd2fcafb":"#visualize the count\nsns.countplot(df_data['diagnosis'], label='count')","762c361e":"#checking at the data types \ndf_data.dtypes\n","8017143e":"df_data.info()","aa8df8e8":"#Encode categorical data values\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_Y = LabelEncoder()\ndf_data.iloc[:,0]=df_data.iloc[:,0]=labelencoder_Y.fit_transform(df_data.iloc[:,0].values)\ndf_data.iloc[:,0]","290a7d53":"#create a pair plot diagnosis in orange\nsns.pairplot(df_data.iloc[:,0:6], hue='diagnosis')\n","ceedd5f0":"df_data.head(5)","df9ec309":"#Get the corelation of the columns\ndf_data.iloc[:,0:12].corr()","d68a7d15":"#visualize the corelation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_data.iloc[:,0:12].corr(), annot=True, fmt='.0%')","56d3ebdb":"#splitting the dataset into indepedent (X) and depedent (Y)\nX =df_data.iloc[:,1:30].values#features \nY =df_data.iloc[:,0].values#diagnosis\n","d70cdecd":"#split dataset into 75% training and 25% test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)","e35f8732":"#scaling our data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train= sc.fit_transform(X_train)\nX_test= sc.fit_transform(X_test)\n","e58bef90":"#create a function for the models\ndef models(X_train, Y_test):\n    #Logistic Regression\n    from sklearn.linear_model import LogisticRegression\n    log = LogisticRegression(random_state=0)\n    log.fit(X_train, Y_train)\n    \n    #decision tree\n    from sklearn.tree import DecisionTreeClassifier\n    tree= DecisionTreeClassifier(criterion = 'entropy', random_state=0)\n    tree.fit(X_train, Y_train)\n    \n    #Random forest classifier\n    from sklearn.ensemble import RandomForestClassifier\n    forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n    forest.fit(X_train, Y_train)\n    \n    #print the models accuracy \n    print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n    print('[1]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n    print('[2]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))\n    return log, tree, forest\n    ","90402c5b":"#getting all the models\nmodel= models(X_train, Y_train)","637dcb33":"#test model accuracy on test data on confusion metrics\nfrom sklearn.metrics import confusion_matrix \ncm = confusion_matrix(Y_test, model[0].predict(X_test))\n\nprint(cm)","48e736a1":"pred= model[2].predict(X_test)\nprint(pred)\nprint()\nprint(Y_test)","256a33b6":"#Print the prediction results\nprint(\"The patient does not have cancer?\",pred[0])","1c72e8c3":"Dropping the Unnamed column"}}