{"cell_type":{"14e7bccf":"code","88d72bf6":"code","68449cdb":"code","5f1b70ea":"code","146b6c8f":"code","bd30ea63":"code","c723cabe":"code","2ee9433d":"code","6b431a5a":"code","117745d3":"code","32f96c93":"code","0a8feabc":"code","0f8afe93":"code","dfba689b":"code","f0994c52":"code","2a368efd":"code","2d260983":"code","8fc79719":"code","58a8594f":"code","ebb5ea9c":"code","bb1991cd":"code","63be38ac":"code","c69bfe3a":"code","7d3939e4":"code","5f23930b":"code","11af6165":"code","334512b9":"code","7fcc983e":"code","a9289e85":"code","f6fa70d9":"code","0f80f01c":"code","8b9474ac":"code","01ca38a4":"code","17e262e7":"code","99a2b54f":"code","bd87960e":"code","420822c1":"code","c2b26d66":"code","03eafeaa":"code","6f75a47e":"code","c6366a2d":"code","43e3db2d":"code","a8b90bcd":"code","1238f531":"code","cf4577df":"code","61538c87":"markdown","731e43d1":"markdown","d04c8cad":"markdown","a4cf4f1b":"markdown","48f58dfe":"markdown","28290206":"markdown","42a1bc83":"markdown","924d7d24":"markdown","951c48f7":"markdown","b7633a75":"markdown","ec031d4d":"markdown","31302c12":"markdown","27882552":"markdown","37bfe0a7":"markdown","0d85f7c8":"markdown","0f3ae0fe":"markdown","ea84eab9":"markdown","981489e7":"markdown","7571209a":"markdown","e654fba8":"markdown","4a55c0d0":"markdown","f4e51469":"markdown","4494bae6":"markdown","01b177f2":"markdown","8c028ffe":"markdown","7620045a":"markdown","8c6f02fb":"markdown","9d5befec":"markdown","ec12149f":"markdown","64702e5e":"markdown","5b2247ed":"markdown","74c7db53":"markdown"},"source":{"14e7bccf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n%matplotlib inline","88d72bf6":"import os # accessing directory structure\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","68449cdb":"# import data from Excel csv sheet\ndftest = pd.read_csv('..\/input\/disease-prediction-using-machine-learning\/Testing.csv')\ndftrain = pd.read_csv('..\/input\/disease-prediction-using-machine-learning\/Training.csv')\n\n# show first 5 records of training dataset\ndftrain.head()","5f1b70ea":"# show first 5 records of test dataset\ndftest.head()","146b6c8f":"# return the object type, which is dataframe\nprint(type(dftrain), type(dftest))","bd30ea63":"# display the number of entries, the number and names of the column attributes, the data type and\n    # digit placings, and the memory space used\ndftrain.info()","c723cabe":"# identify null values\nnull_columns = dftrain.columns[dftrain.isnull().any()]\ndftrain[null_columns].isnull().sum()","2ee9433d":"# drop 'Unnamed: 133'\ndftrain.drop('Unnamed: 133', axis=1, inplace=True)\ndftrain.info()","6b431a5a":"# display the number of entries, the number and names of the column attributes, the data type and\n    # digit placings, and the memory space used\ndftest.info()","117745d3":"# identify null values\nnull_columns=dftest.columns[dftest.isnull().any()]\ndftest[null_columns].isnull().sum()","32f96c93":"colors = ['#3d84bf', '#295981']\ncolumns = list(dftrain.columns)\n# barplot of the count for all symptoms' absence and presence\nfor i in columns :\n    fig, ax = plt.subplots(figsize=(2,2))\n    bar = dftrain.groupby(i).size().plot(kind='bar', color=colors, ax=ax)\n    plt.xticks(rotation=0)\n    fig.suptitle(\"Count of Symptom \\\"\" + i + \"\\\"\")","0a8feabc":"colors = ['#3d84bf', '#295981']\n# barplot of the count for all symptoms' absence and presence\nfor i in columns :\n    fig, ax = plt.subplots(figsize=(2,2))\n    bar = dftest.groupby(i).size().plot(kind='bar', color=colors, ax=ax)\n    plt.xticks(rotation=0)\n    fig.suptitle(\"Count of Symptom \\\"\" + i + \"\\\"\")","0f8afe93":"# all symptoms, sorted alphabetically\nsorted(dftrain.prognosis.unique())","dfba689b":"# detect duplicated records\ndftest[dftest.duplicated(subset = None, keep = False)]","f0994c52":"# display the number of entries, the number and names of the column attributes, the data type and\n    # digit placings, and the memory space used\ndftrain.info()","2a368efd":"# display the number of entries, the number and names of the column attributes, the data type and\n    # digit placings, and the memory space used\ndftest.info()","2d260983":"# list and count the target class label names and their frequency\nfrom collections import Counter\ncount = Counter(dftrain['prognosis'])\ncount.items()","8fc79719":"import seaborn as sns\n# count of each target class label\nplt.figure(figsize = (30, 5))\nax = sns.countplot(dftrain['prognosis'], palette = 'PuBu')\nax.set_xticklabels(ax.get_xticklabels(), rotation = 40, ha = \"right\")\nplt.show()","58a8594f":"# list and count the target class label names and their frequency\ncount = Counter(dftest['prognosis'])\ncount.items()","ebb5ea9c":"# count of each target class label\nplt.figure(figsize = (30, 5))\nax = sns.countplot(dftest['prognosis'], palette = 'PuBu')\nax.set_xticklabels(ax.get_xticklabels(), rotation = 40, ha = \"right\")\nplt.show()","bb1991cd":"# list of all symptoms\ncolumns = list(dftrain.columns)\ncolumns","63be38ac":"colors = ['#3d84bf', '#295981']\n# barplot of the count for all symptoms' absence and presence\nfor i in columns :\n    fig, ax = plt.subplots(figsize=(2,2))\n    bar = dftrain.groupby(i).size().plot(kind='bar', color=colors, ax=ax)\n    plt.xticks(rotation=0)\n    fig.suptitle(\"Count of Symptom \\\"\" + i + \"\\\"\")","c69bfe3a":"colors = ['#3d84bf', '#295981']\n# barplot of the count for all symptoms' absence and presence\nfor i in columns :\n    fig, ax = plt.subplots(figsize=(2,2))\n    bar = dftest.groupby(i).size().plot(kind='bar', color=colors, ax=ax)\n    plt.xticks(rotation=0)\n    fig.suptitle(\"Count of Symptom \\\"\" + i + \"\\\"\")","7d3939e4":"# compare linear relationships between attributes using correlation coefficient generated using correlation heatmap\nplt.figure(figsize = (30, 30))\nsns.heatmap(dftrain.corr(), cmap = 'PuBu', annot = False)\nplt.show()","5f23930b":"# summary statistics of the attributes, including measures of central tendency and measures of dispersion\ndftrain.describe() ","11af6165":"# summary statistics of the attributes, including measures of central tendency and measures of dispersion\ndftest.describe() ","334512b9":"# classify and model the data using Multilayer Perceptron (MLP) Neural Network, Decision Tree (DT), and Random Forest (RF)\n    # machine learning algorithms\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport math\n\n# split dataset into attributes and labels\nX_train = dftrain.iloc[:, :-1].values # the training attributes\ny_train = dftrain.iloc[:, 132].values # the training labels\nX_test = dftest.iloc[:, :-1].values # the testing attributes\ny_test = dftest.iloc[:, 132].values # the testing labels","7fcc983e":"# using DT based on information gain\nclassifierDT = DecisionTreeClassifier(splitter='best', criterion='entropy', min_samples_leaf=2)\nclassifierDT.fit(X_train, y_train)","a9289e85":"# using RF classifier\nclassifierRF = RandomForestClassifier(criterion='entropy', min_samples_leaf=2)\nclassifierRF.fit(X_train, y_train)","f6fa70d9":"# using MLP classifier\nclassifierMLP = MLPClassifier()\nclassifierMLP.fit(X_train, y_train)","0f80f01c":"# use the chosen three models to make predictions on test data\ny_predMLP = classifierMLP.predict(X_test)\ny_predDT = classifierDT.predict(X_test)\ny_predRF = classifierRF.predict(X_test)","8b9474ac":"# for MLP model\n# using confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_predMLP))\nprint(classification_report(y_test, y_predMLP))\n\n# using accuracy performance metric\nfrom sklearn.metrics import accuracy_score\nprint(\"Train Accuracy: \", accuracy_score(y_train, classifierMLP.predict(X_train)))\nprint(\"Test Accuracy: \", accuracy_score(y_test, y_predMLP))","01ca38a4":"# for RF model\n# using confusion matrix\nprint(confusion_matrix(y_test, y_predRF))\nprint(classification_report(y_test, y_predRF))\n\n# using accuracy performance metric\nprint(\"Train Accuracy: \", accuracy_score(y_train, classifierRF.predict(X_train)))\nprint(\"Test Accuracy: \", accuracy_score(y_test, y_predRF))","17e262e7":"# for DT model\n# using confusion matrix\nprint(confusion_matrix(y_test, y_predDT))\nprint(classification_report(y_test, y_predDT))\n\n# using accuracy performance metric\nprint(\"Train Accuracy: \", accuracy_score(y_train, classifierDT.predict(X_train)))\nprint(\"Test Accuracy: \", accuracy_score(y_test, y_predDT))","99a2b54f":"# data to plot\nn_groups = 3\nalgorithms = ('Multilayer Perceptron (MLP) Neural Network', 'Decision Tree (DT)', 'Random Forest (RF)')\ntrain_accuracy = (accuracy_score(y_train, classifierMLP.predict(X_train))*100, \n                  accuracy_score(y_train, classifierDT.predict(X_train))*100, \n                  accuracy_score(y_train, classifierRF.predict(X_train))*100)\ntest_accuracy = (accuracy_score(y_test, y_predMLP)*100, \n                 accuracy_score(y_test, y_predDT)*100, \n                 accuracy_score(y_test, y_predRF)*100)\n\n# create plot\nfig, ax = plt.subplots(figsize=(15, 5))\nindex = np.arange(n_groups)\nbar_width = 0.3\nopacity = 0.8\nrects1 = plt.bar(index, train_accuracy, bar_width, alpha = opacity, color='Cornflowerblue', label='Train')\nrects2 = plt.bar(index + bar_width, test_accuracy, bar_width, alpha = opacity, color='Teal', label='Test')\nplt.xlabel('Algorithm') # x axis label\nplt.ylabel('Accuracy (%)') # y axis label\nplt.ylim(0, 115)\nplt.title('Comparison of Algorithm Accuracies') # plot title\nplt.xticks(index + bar_width * 0.5, algorithms) # x axis data labels\nplt.legend(loc = 'upper right') # show legend\nfor index, data in enumerate(train_accuracy):\n    plt.text(x = index - 0.035, y = data + 1, s = round(data, 2), fontdict = dict(fontsize = 8))\nfor index, data in enumerate(test_accuracy):\n    plt.text(x = index + 0.25, y = data + 1, s = round(data, 2), fontdict = dict(fontsize = 8))\nplt.show()","bd87960e":"# identify the important features in DT\nimp = classifierDT.feature_importances_\nimp","420822c1":"# combine list of symptoms and their feature importance into a 2D array\ncolumns = columns[:132]\ncolumn_names = ['symptom', 'importance']\ndf3 = np.vstack((columns, imp)).T\ndf3 = pd.DataFrame(df3, columns = column_names)\ndf3","c2b26d66":"coefficients = classifierDT.feature_importances_\n\n# set a minimum threshold for feature importance\nimportance_threshold = np.quantile(coefficients, q = 0.75)\nimport plotly.express as px\n\n# barplot of feature importance\nfig = px.bar(x = coefficients, y = columns, orientation = 'h', color = coefficients, \n             color_continuous_scale = [(0, '#b7d2e8'), (1, '#295981')], labels = {'x': \"Importance Value\", 'y': \"Feature\"}, \n             title = \"Feature Importance For Decision Tree Model\")\n\n# cut off value as the minimum threshold for feature importance\nfig.add_vline(x = importance_threshold, line_color = 'red', line_width = 0.8)\nfig.add_vrect(x0 = importance_threshold, x1 = 0, line_width = 0, fillcolor = 'red', opacity = 0.2)\nfig.show()","03eafeaa":"import numpy\n# identify features with feature importance values below the minimum threshold\nlow_importance_features = numpy.array(df3.symptom[np.abs(coefficients) <= importance_threshold])\ncolumns = list(low_importance_features)\ncolumns","6f75a47e":"for i in columns :\n    # drop low importance features\n    dftrain.drop(i, axis=1, inplace=True)\n    dftest.drop(i, axis=1, inplace=True)\ndftrain.info()","c6366a2d":"dftest.info()","43e3db2d":"# split dataset into attributes and labels\nX_train = dftrain.iloc[:, :-1].values # the training attributes\ny_train = dftrain.iloc[:, 33].values # the training labels\nX_test = dftest.iloc[:, :-1].values # the testing attributes\ny_test = dftest.iloc[:, 33].values # the testing labels\n\n# using DT based on information gain\nclassifierDT = DecisionTreeClassifier(splitter='best', criterion='entropy', min_samples_leaf=2)\nclassifierDT.fit(X_train, y_train)","a8b90bcd":"# for DT model\ny_predDT = classifierDT.predict(X_test)\n\n# using confusion matrix\nprint(confusion_matrix(y_test, y_predDT))\nprint(classification_report(y_test, y_predDT))\n\n# using accuracy performance metric\nprint(\"Train Accuracy: \", accuracy_score(y_train, classifierDT.predict(X_train)))\nprint(\"Test Accuracy: \", accuracy_score(y_test, y_predDT))","1238f531":"# new data on 33 attributes\nnewdata = [[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, \n            0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1]]\n\n# compute probabilities of assigning to each of the classes of prognosis\nprobaDT = classifierDT.predict_proba(newdata)\nprobaDT.round(4) # round probabilities to four decimal places, if applicable","cf4577df":"# make prediction of target class label\npredDT = classifierDT.predict(newdata)\npredDT","61538c87":"DT model has the best performance metrics of 100% for all four metrics of test accuracy, precision, recall, and F1-score. The RF model also achieved 100% for all, but this is not preferred as the time complexity will usually be larger. On the other hand, the MLP model have the precision of 99%, and 98% for all three of accuracy, recall, and F1-score. For all three chosen models, all the prognosis are almost perfectly classified and predicted. \n\nAlthough there are only small differences between the train and test accuracy and thus no overfitting in this sense, the 100% train accuracy still indicates that the learnt rules are specific for the train set and do not generalize well beyond the train set to the test set. This will be taken care of later on, when the best model is chosen.\n\nAccuracy indicates the overall proportion of correct predictions for all the three classes. The train accuracy is measured based on examples that the model was constructed on, while the test accuracy is based on those it has yet to see. DT achieved 100% for both train accuracy and test accuracy. \n\nHowever, it will be misleading to solely base decisions on this, as the dataset used is relatively small and biased. Recall and precision metrics are thus also considered to measure model performance. \n\nRecall indicates the proportion of correct predictions for each individual class, out of the corresponding actual class. In other words, the proportion of all actual classes that were predicted correctly. It was found that 100% of all actual classes were predicted correctly by DT. \n\nPrecision indicates the proportion of correct predictions for each individual class, out of the corresponding predicted class. In other words, the proportion of all predicted classes were actually predicted correctly. It was found that 100% of all predicted classes were actually predicted correctly by DT.\n\nHowever, recall and precision have an inverse relationship. In order to make them comparable for cases where they are both important, F1 score is introduced. F1-score, also known as F-score or F-measure, is used to make precision and recall comparable in cases where they are both important, by measuring their harmonic mean. This allows it to consider both metrics and punish extreme values more heavily. Therefore, F-score will compute the overall quality of translations produced by the chosen machine learning engine, which is 100% by the DT model.\n\nThe confusion matrix tabulates the predicted class vertically and the actual class horizontally.\n\nIn conclusion, the DT model using the parameter of best split, the criterion of entropy, and the minimum number of 2 leaves, is chosen as the best model for the prediction of disease prognosis.","731e43d1":"This clearly illustrates that data available for most target labels are proportionate, which will be taken note of for further data visualisations and analysis later on.\n\nMoving on to analyse the individual qualitative attributes of the 132 symptoms : ","d04c8cad":"These low importance features are dropped.","a4cf4f1b":"Task Highlights :\n\n> Perform Supervised Machine Learning on Disease Prediction dataset (https:\/\/www.kaggle.com\/kaushil268\/disease-prediction-using-machine-learning as at April 1, 2021)\n\n> Perform data visualization\n\n> Make use of different algorithms to predict target label\n\n> Show 3 different algorithms' accuracies with the help of graphs\n\nThe main problems to be solved by this data science task have been properly framed, in terms of client's goals, background information, and purpose of task. This ensures that the task is understood and explored to better inform the decision-making process on the possible range of approaches and solutions to the problems.\n\nThis task will extract relevant, representative, and sufficient case study data from a reputable and reliable online source. Appropriate preprocessing adjustments and data exploration will be performed on the data to ensure reliable and reasonable outcomes and outputs. For the data mining and modelling process, the popular classifier models of Decision Tree, Random Forest, and Multilayer Perceptron Neural Network will be fitted, analysed, and evaluated in terms of the performance metrics of accuracy, precision, recall, and F1-score in predicting the classifications of disease. All significant interpretations and observations will be noted and considered for future improvements. \n\nFollowing the purpose of this task, the primary focus will be on disease-related factors, which are a range of symptoms represented as 0 for absence and 1 for presence. Analysing these will help to identify concern areas and predict the disease prognosis.\n\n#### Note that throughout this task, the important points are differentiated using the Indented Quotes format.","48f58dfe":"DT model has an improved performance metrics of 95% test accuracy and recall, and 94% precision and F1-score. Thus, all the prognosis are almost perfectly classified and predicted, and the small difference of 0.8% between the train and test accuracy indicates this DT model suffers from neither overfitting nor underfitting. \n\nIn conclusion, the DT model using the parameter of best split, the criterion of entropy, and the minimum number of 2 leaves, is chosen as the final model for the prediction of disease prognosis using 33 predictors of symptoms.\n\nThe DT model is now ready to be deployed to predict new value instances. To do so, a data frame is created to describe the characteristics of a number of disease cases based on the symptoms. These new data instances will be passed to the DT model classifier to predict its target class label of disease prognosis. ","28290206":"Through this, it is found that there are no noises of impossible values or errors of inconsistent values.\n\nThe Winsorisation method is popularly chosen to handle numerical outliers, where outlier values are replaced with the minimum or maximum non-outlier value identified using the interquartile range (IQR) method. The acceptable value range to not be considered an outlier is [Q1-1.5IQR, Q3+1.5IQR], where Q1 is the first quartile of 25 percentile, Q3 is the third quartile of 75 percentile, and IQR is (Q3 \u2013 Q1).\n\nIn addition, impossible and extreme numerical values can be assumed as incorrect data entries, where they are identified as differing from the mean attribute value by a comparatively large margin.\n\nIn this case, no values were considered as outliers or impossible and extreme values, since all numerical values are reasonable and within an expected range in relation to the Disease Prediction's absence or present case study.\n\nDuplicated rows or records will not be dropped from the training dataset in this case. There is no certain redundancy which causes inaccurate results and outcomes, since the training dataset has no unique identfier that denotes separate entities. Despite this, the test dataset will still be checked for duplicated rows.","42a1bc83":"The dataset contains 4920 rows of records and 134 columns of attributes. The data types of the attributes consist of 1 qualitative discrete categorical, 132 quantitative discrete binary, and 1 quantitative continuous numerical float with 64 digit placings.\n\nThe memory space usage is at least 5 megabytes (MB).","924d7d24":"# Neo Ann Yi","951c48f7":"The dataset contains 42 rows of records and 133 columns of attributes. The data types of the attributes consist of 1 qualitative discrete categorical, and 132 quantitative discrete binary.\n\nThe memory space usage is at least 43.8 kilobytes (KB).","b7633a75":"# Thank you !","ec031d4d":"Next, a closer look at the individual diagnosis of each symptom will identify the frequency of occurence of its absence or presence.","31302c12":"# Data Collection\n\nThe first step of a data science task is to obtain, gather, and measure the necessary and targeted data from available internal or external data sources, and then compiled into an established system. In this case, version 1 of Disease Prediction dataset by KAUSHIL268 in Kaggle is used. The Excel csv file that was extracted as at 1 April 2021 for the purpose of this task is available at https:\/\/www.kaggle.com\/kaushil268\/disease-prediction-using-machine-learning.","27882552":"# Model Interpretation \n\nThe final crucial step of a data science project is the interpretation of the models and data, in terms of its predictive power and thus its ability to generalise unseen future data.\n\nFeature engineering will involve feature selection based on higher feature importance towards the chosen model. This yields a subset of features from the original set to better represent the data, thus enabling the machine learning algorithm to train faster and reducing the model's computational complexity and cost. The model can also be easier to interpret and become more comprehendible to humans, and in some cases achive improved accuracy when the right subset is chosen. \n\nThe feature importance of each symptom is identified and fully listed below.","37bfe0a7":"In summary, the datasets contain records for 132 predictors or independent or explanatory attributes, and an attribute for class label. The predictors all have discrete binary data values and no missing data values. \n\ndescribe() is used to obtain summary statistics including measures of central tendency such as mean and median, and measures of dispersion such as standard deviation, which are useful in providing a quick and simple description of the dataset and its characteristics. ","0d85f7c8":"Through this, it is found that there are no null values present in the test dataset.\n\nNext, errors of inconsistent data such as not comparable numerical measurement formats and data types are checked by analysing the bar plots.","0f3ae0fe":"'Unnamed: 133' is noticed to have all null values. It is dropped as it is a redundant attribute with missing values for all records.","ea84eab9":"Almost all symptoms have weak linear correlations, which is indicative that these symptoms do not come hand-in-hand. \n\nLastly, the summary statistics will be considered.","981489e7":"Through this, it is found that there are no noises of impossible values or errors of inconsistent values. All predictors have boolean values.\n\nFor the next step, unique() is used to check qualitative data for noises of impossible values such as incorrect mispelt data entries.","7571209a":"The dataframe format type will facilitate the use of a wider variety of syntax and methods for data analysis, including describe() and info().\n\nRegarding the attributes included in Disease Prediction dataset, there are 132 different disease symptoms, the first 3 recorded being 'itching', 'skin rash', and 'nodal skin eruptions'. The target class label is 'prognosis'.","e654fba8":"The training dataset contains 4920 rows of records and 133 columns of attributes. The data types of the attributes consist of 1 qualitative discrete categorical, and 132 quantitative discrete binary. The memory space usage is at least 5 MBs.\n\nThe test dataset contains 42 rows of records and 133 columns of attributes. The data types of the attributes consist of 1 qualitative discrete categorical, and 132 quantitative discrete binary. The memory space usage is at least 43.8 KBs.\n\nData pre-processing is now complete.","4a55c0d0":"There are no duplications in the test dataset.\n\nData integration is not needed, since only one dataset is used for training and testing each with no schema integrations, and thus no discernable entity identification issues or data value conflicts.\n\nData transformation will check overall range of values for the entire dataset. All values should fall under an acceptable small range to allow easy visualisations and modelling. It is found that all values already fall under a small range of [0, 1], specifically either 0 or 1 or also known as boolean, so there is no need for data transformation to scale the values into a comparable range for easy visualisations and modelling.\n\nData reduction may involve dropping redundant attributes through attribute dimensionality reduction. However, there are no related cases detected thus far.\n\nA correlation heatmap is used to list all the correlation coefficients in order to identify multicollinearity, in other words high intercorrelation above an absolute value of 0.5 between the a pair of attributes. For a pair of attributes with multicollinearity, one of them will be dropped since it would be redudant to include both of them with almost mirroring values and thus almost perfect descriptions of each other. Another reason is to prevent overfitting.\n\nThe correlation will compare and describe the linear connection and relationship between pairs of features, through the type of correlation and its strength. A positive correlation indicates that both features will change their values in the same direction, while a negative correlation indicates that both will change in opposite directions. The larger the correlation strength, the stronger the connection and relationship.\n\nHowever, Decision Tree, Random Forest, and Multilayer Perceptron Neural Network models are chosen as most appropriate classification models, and they are all immune to multicollinearity. As all are non-parametric models, Decision Tree in particular only examines one of the features at a time during the splitting process. Similarly, Neural Networks tend to be overparameterized while also having a parallel nature. For Random Forests, each tree only considers a subset of all the features, which reduces the feature space that each tree is optimizing over and thus combats the effects of multicollinearity. Due to these reasons and in the case of this Disease Prediction task where all predictors have boolean values, no attributes were removed as to not lose relevant information and degrade the overall process of EDA and supervised machine learning prediction.\n\nThe final dataset information is summarised below.","f4e51469":"# Data Modelling\n\nThe two datasets represent the split into two separate sets - the training set and test set. They both consist of the same attributes, but not the same attribute values. The training set is used to train and construct the classification models. The test set is used to predict the classifications of the new unbiased data that were not used to train the model, before evaluating the model performance based on the performance metrics of accuracy, precision, recall, and F1-score of those classifications. \n\nThe target class labels for both datasets have almost even distribution. It is assumed that the training and test sets are unbiased and representative of the target classes, such as already going through the process of using a list of random numbers starting from the random selected position to perform random splitting. The training subset takes up 4920 instances, whereas the test subset takes up 42 instances.\n\nThe machine Learning algorithms of Multilayer Perceptron (MLP) Neural Network, Decision Tree (DT), and Random Forest (RF), are chosen to fit to the dataset.\n\nFor the Multilayer Perceptron (MLP) Neural Network model, patterns of information are fed into the model via the input units, and these trigger the multiple layers of hidden units to ultimately arrive at the output units. The output is the computed values for the output-layer nodes.\n\nDecision tree is constructed based on parameters of best split strategy, and the criterion of entropy which utilises information gain to iteratively select the next node according to higher feature importance to optimise the quality of splits. The minimum number of leaves are restricted to 2. The outputs are the classification rules as extracted from the decision tree. These are determined by the flow sequence from the root node and the corresponding branches to the internal or decision nodes, then stopping when the leaf node representing the class label is reached. \n\nRandom Forest classifier will combine multiple base models of Decision Trees during its training period, using the strategy of ensemble machine learning methods. This will construct a single optimal predictive model, with the criterion of entropy which utilises information gain to iteratively select the next node according to higher feature importance to optimise the quality of splits. The minimum number of leaves are restricted to 2. The final output may be the mode class or the mean prediction of individual trees.","4494bae6":"The predicted class for the specified example is assigned as \"Gastroenteritis\", as its probability is the highest among that for the other classes of diseases. It is also safe to intepret this result as having 95% accuracy and recall, and 94% precision and F1-score, based on the DT model's performance metrics. \n\nPossible improvements can be to include other strong predictors of disease prognosis, such as other symptoms outside of the aforementioned 132. These predictors can be very relevant and thus useful to include in the model design.","01b177f2":"The final datasets contains 33 columns of predictors, out of the original 132. These are fed into the DT model with the parameter of best split, the criterion of entropy, and the minimum number of 2 leaves. The performance metrics of test accuracy, precision, recall, and F1-score are measured again for this new model. ","8c028ffe":"# Model Evaluation\n\nThe model performance is evaluated and validated by using the test set of 42 records to predict the classifications of these new unbiased data that were not used to train the model. The confusion matrix is then used to determine the performance metrics of accuracy, precision, recall, and F1-score, based on those classifications. The supports are 1 instance for each target class label of prognosis. This process ensures that the models are useful by being generalisable even when the specific training data used is extended to include new test data, or in technical terms \u2018avoid over fitting\u2019.","7620045a":"# Supervised Machine Learning on Disease Prediction","8c6f02fb":"Through this, it is found that there are no other null values present in the training dataset. ","9d5befec":"The symptom of 'fatique' is found to have the significantly largest predictive power of 0.1579, out of all the 132 predictors.\n\nOn the other hand, the low importance features are identified below.","ec12149f":"# Data Preprocessing\n\nData preprocessing is a data mining technique that transforms raw data into an understandable format. This process has four main stages \u2013 data cleaning, data integration, data transformation, and data reduction.\n\nData cleaning will filter, detect, and handle dirty data to ensure quality data and quality analysis results. In this case, there may be noises of impossible and extreme values and outliers, and missing values. The errors may include inconsistent data and redundant attributes and data.\n\nAs the first step, null values within the dataset will be identified, and appropriately replaced if possible.","64702e5e":"All occurences of symptoms are mostly absent, which is expected for a Disease Prognosis case study.\n\nFor these quantitative binary attributes of symptoms, their linear relationships and their strengths can be compared using a correlation heatmap.","5b2247ed":"Taking all of these into consideration, a minimum threshold for feature importance is set in order to identify features of low importance, and thus can be excluded from the final predictive model.","74c7db53":"# Exploratory Data Analysis (EDA)\n\nEDA aims to perform initial investigations on data before formal modeling and graphical representations and visualisations, in order to discover patterns, look over assumptions, and test hypothesis. The summarised information on main characteristics and hidden trends in data can help the doctor to identify concern areas and problems, and the resolution of these can boost their accuracy in diagosing diseases.\n\nTaking a closer look at the target class labels, as well as their frequency of occurences :"}}