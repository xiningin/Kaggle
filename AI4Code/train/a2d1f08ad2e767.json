{"cell_type":{"ca2e6109":"code","edc98f57":"code","a77d89e3":"code","14f66ff9":"code","52558652":"code","db10b612":"code","5ea0d399":"code","df77d333":"code","7f5e8599":"code","29e6f9be":"code","a2f4d6b5":"code","2e2a1d2d":"code","acf941cc":"code","abe0c4cd":"code","280c6653":"markdown"},"source":{"ca2e6109":"import os\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.image import ImageDataGenerator","edc98f57":"BASE_DIR = '..\/input\/'\nTRAIN_DIR = os.path.join(BASE_DIR, 'train\/train')\nTEST_DIR = os.path.join(BASE_DIR, 'test1\/test1')\n\nos.listdir(BASE_DIR)","a77d89e3":"def make_dataframe_from_dir(path):\n    filenames = os.listdir(path)\n    categories = []\n    \n    for filename in filenames:\n        if filename.split('.')[0] == 'dog':\n            categories.append(1)\n        else:\n            categories.append(0)\n\n    df = pd.DataFrame(\n        {\n            'filename': filenames,\n            'category': categories\n        }\n    )\n    \n    return df\n    \n    \ndf = make_dataframe_from_dir(TRAIN_DIR)\n\nprint(df.shape)\ndf.tail()","14f66ff9":"train_df, validation_df = train_test_split(df, test_size=0.20,random_state=43)","52558652":"print(train_df.shape)\nprint(validation_df.shape)","db10b612":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","5ea0d399":"model.summary()","df77d333":"from keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","7f5e8599":"train_df.category = train_df.category.astype('str')\nvalidation_df.category = validation_df.category.astype('str')","29e6f9be":"total_train = train_df.shape[0]\ntotal_validation = validation_df.shape[0]\nBATCH_SIZE = 20\n\nprint(\"total train {0}, validation {1}\".format(total_train, total_validation))\nprint(\"batch size: \", BATCH_SIZE)","a2f4d6b5":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    TRAIN_DIR,\n    x_col='filename',\n    y_col='category',\n    target_size=(150, 150),\n    batch_size=BATCH_SIZE,\n    class_mode='binary'\n)\n\nvalidation_generator = test_datagen.flow_from_dataframe(\n    validation_df,\n    TRAIN_DIR,\n    x_col='filename',\n    y_col='category',\n    target_size=(150, 150),\n    batch_size=BATCH_SIZE,\n    class_mode='binary'\n)","2e2a1d2d":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch=total_train\/\/BATCH_SIZE,\n    epochs=20,\n    validation_data=validation_generator,\n    validation_steps=total_validation\/\/BATCH_SIZE\n)","acf941cc":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Training acc')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Traiing loss')\nplt.plot(epochs, val_loss, 'b', label='Traiing loss')\nplt.legend()\n\nplt.show()","abe0c4cd":"test_df = make_dataframe_from_dir(TEST_DIR)\n\ntest_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df,\n    TEST_DIR,\n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=(150, 150),\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","280c6653":"### Create Testing Generator"}}