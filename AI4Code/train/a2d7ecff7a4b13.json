{"cell_type":{"1d0a15a2":"code","4a098260":"code","3ae4ebac":"code","ed8675c8":"code","afc76550":"code","a437789e":"code","2b8dad1d":"code","9b963a03":"code","dbc894b3":"code","13ce67fa":"code","026a3d16":"markdown","a920151e":"markdown"},"source":{"1d0a15a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n#Rock = 0, Paper = 1, Scissors = 2\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a098260":"!pip install -q -U kaggle_environments\nimport os #for file management\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #plotting import\nimport seaborn as sns #basic stat stuff\n\nfrom kaggle_environments import make, evaluate, utils #kaggle environments\n\nimport torch","3ae4ebac":"matrix = np.ones((3,3,3))\nprint(matrix[2,2,:])\nprint(matrix[0,0,:].argmax())","ed8675c8":"%%writefile random.py\nimport numpy as np\ndef random_agent(observation, configuration):\n    return int(np.random.randint(3))","afc76550":"%%writefile submission.py\nimport numpy as np\nimport json\n#import torch\n\nmatrix = np.ones((3,3,3)) * (1\/3) #so we can choose object based on what we chose and what the opponent chose transition matrix\nmatrix_freq = np.ones((3,3,3)) #frequency matrix\nprev_me = 0\nprev_op = 0\n#print(state_dict)\n\ndef copy_opponent_agent (observation, configuration):\n    \n    global prev_me, prev_op, matrix, matrix_freq\n        \n    if observation.step > 0:\n        #return (observation.lastOpponentAction + 1)%3\n        #prev_op = observation.lastOpponentAction #we store the last action of the opponent\n        \n        #from step > 1 we can update matrix because we know what we chose and what it chose\n        if observation.step > 1:\n            matrix_freq[prev_op, prev_me, observation.lastOpponentAction] += 1\n            matrix[prev_op, prev_me, :] = matrix_freq[prev_op, prev_me, :] \/ np.sum(matrix_freq[prev_op, prev_me, :]) \n            \n        \n        prev_op = observation.lastOpponentAction #we store the last action of the opponent  \n        \n        #choose the optimal choice based on the transition matrix\n        #choosing stochastically\n        prev_me = (np.random.choice(3, p=matrix[prev_op, prev_me, :]) + 1) % 3\n        \n        #print(matrix) \n        \n        state_dict = {\"transition tensor\" : matrix.tolist()}\n        with open('transition_matrix.json', 'a') as outfile:\n            json.dump(state_dict, outfile)\n            outfile.write(\"\\n\")\n        \n        return prev_me\n        \n              \n    else:\n        #prev_me = np.random.randint(0,3)\n        state_dict = {\"transition tensor\" : matrix.tolist()}\n        with open('transition_matrix.json', 'w') as outfile:\n            json.dump(state_dict, outfile)\n            outfile.write(\"\\n\")\n        prev_me = (np.random.choice(3, p=matrix[prev_op, prev_me, :]) + 1)%3\n        return prev_me\n        #json.dump(matrix_freq, outfile)","a437789e":"env = make(\"rps\", debug = True) #create the simulation environment\n\nenv.run([\"submission.py\", \"statistical\"]) #run it against random opponent\nenv.render(mode=\"ipython\", width=500, height=450) #render it","2b8dad1d":"#import json\n#with open('transition_matrix.json') as json_file:\n#    bandit_state = json.load(json_file)\n#print(bandit_state)","9b963a03":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"submission.py\", \"reactionary\"])\nenv.render(mode=\"ipython\", width=500, height=450)","dbc894b3":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"submission.py\", \"counter_reactionary\"])\nenv.render(mode=\"ipython\", width=500, height=450)","13ce67fa":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"submission.py\", \"random.py\"])\nenv.render(mode=\"ipython\", width=500, height=450)","026a3d16":"Create a random agent for testing","a920151e":"Running the environment"}}