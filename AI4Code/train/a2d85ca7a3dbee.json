{"cell_type":{"9dc48c56":"code","c2e5860d":"code","cfc65e30":"code","2c0ba97d":"code","7f663fd7":"code","b846a26e":"code","38840bf6":"code","8ae6d118":"code","ff097055":"code","a58632b8":"code","c1f7519f":"code","80d9da76":"code","8a9045be":"code","5b19a370":"code","7b645f4d":"code","a2b582d8":"code","a1e6340d":"markdown","986a583f":"markdown","2a62c158":"markdown","abfc9054":"markdown","0b7f6c7c":"markdown","18be737c":"markdown","b84dee5a":"markdown","5b3fc677":"markdown","4f9ce6fe":"markdown","62f5063a":"markdown","b0677824":"markdown","6aece401":"markdown","67a4ae56":"markdown","33dea716":"markdown","5a42e0ea":"markdown","2901ad28":"markdown","8a7006a5":"markdown"},"source":{"9dc48c56":"!git clone https:\/\/github.com\/rkuo2000\/yolov5 # detect.py was modified to generate raw xywh into .txt\n%cd yolov5","c2e5860d":"import torch\nfrom IPython.display import Image, clear_output  # to display images\nfrom utils.google_utils import gdrive_download  # to download models\/datasets\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","cfc65e30":"##--save-txt will output object coords in text file for each frame\n!python detect.py --weights yolov5x.pt --img-size 640 --conf 0.4 --source \/kaggle\/input\/input-video\/traffic360p.mp4 --save-txt","2c0ba97d":"!ls runs\/detect\/exp","7f663fd7":"import os\nimport pandas as pd\nimport numpy as np\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image","b846a26e":"# check .txt files\nlabels_path = 'runs\/detect\/exp\/labels\/'\ntxtfiles = os.listdir(labels_path)\n\nframe_no = []\nfor txtfile in txtfiles:\n    txt_no = txtfile.replace('traffic360p_','').replace('.txt', '')\n    frame_no.append(int(txt_no))\nframe_no.sort() \nprint('total frames = ', frame_no[-1])\n\nTOTAL_FRAMES = len(txtfiles)\nprint(TOTAL_FRAMES)","38840bf6":"# YOLOv5 model trained using COCO dataset, COCO labels are 80 objects below\nlabels = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n        'hair drier', 'toothbrush']","8ae6d118":"# read frames of the original video (.mp4)\nframes = []\ncap = cv2.VideoCapture('\/kaggle\/input\/input-video\/traffic360p.mp4') \nfor i in range(TOTAL_FRAMES):\n    _, frame = cap.read()\n    frames.append(frame)\n    \nplt.title('frame1')\nplt.imshow(cv2.cvtColor(frames[0], cv2.COLOR_BGR2RGB))\nplt.show()","ff097055":"# set Frame width and height (640,384)\n(img_W, img_H) = (640, 384)\n# set Y for traffic checking zone\n(Y1, Y2) = (214, 324)","a58632b8":"dfs = {}\n\nfor i in range(TOTAL_FRAMES):\n    f = open(labels_path+'traffic360p_'+str(frame_no[i])+'.txt', 'r')\n    lines = f.readlines()\n\n    # read objects from each line of .txt\n    objects = []\n    for line in lines:\n        line=line.rstrip()\n        obj = [int(float(i)) for i in line.split(' ')]\n        objects.append(obj)\n\n    # create dataframe\n    df = pd.DataFrame()\n    for object in objects:\n        class_id, x, y, w, h = object\n        item = {'class_id': class_id, 'x': x, 'y':y, 'w':w, 'h':h}\n        df = df.append(item, ignore_index=True)  \n        \n    # sort by value of y(ascending),x(descending)\n    df = df.sort_values(['y', 'x'],ascending=[False, True])\n\n    # only take vehicles between Y>214\n    dfs[i] = df[(df['y']>Y1)]\n    del df\n    \nprint(dfs[0])","c1f7519f":"for i in range(0,30,5):\n    frame = frames[i]\n    # draw zone for vehcile checking zone\n    img = cv2.line(frame, (0,Y1), ((img_W-1),Y1), (255,255,0), 2)\n    img = cv2.line(frame, (0,Y2), ((img_W-1),Y2), (255,255,0), 2)    \n    # draw box & index on center(x,y) of each vehcile on frame    \n    for j in range(len(dfs[i])):\n        cid=dfs[i].iloc[j].class_id\n        x  =int(dfs[i].iloc[j].x)\n        y  =int(dfs[i].iloc[j].y)\n        w  =int(dfs[i].iloc[j].w)\n        h  =int(dfs[i].iloc[j].h)\n        #print(i, x, y, w, h)\n    \n        if cid==2: color=(0,255,0) #cv2 BGR\n        if cid==7: color=(255,0,0) #cv2 BGR\n        x1 = x-int(w\/2)\n        y1 = y-int(h\/2)\n        x2 = x+int(w\/2)\n        y2 = y+int(h\/2)\n        img = cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)        \n        img = cv2.putText(img, labels[int(object[0])], (x1,y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0,0,255),1)\n        img = cv2.putText(img, str(j), (x,y), cv2.FONT_HERSHEY_COMPLEX, 0.7,(0,255,255),1) \n    \n    # save to frame_n.jpg\n    out_file = 'frame_'+str(frame_no[i])+'.jpg'\n    cv2.imwrite(out_file,img)\n    print('save '+out_file)","80d9da76":"Image('frame_'+str(frame_no[0])+'.jpg')","8a9045be":"# set Y for traffic checking zone\n(Y1, Y2) = (214, 324)\n# X for lanes\n(X1,X2,X3,X4,X5) = (65, 190, 323, 457, 612)","5b19a370":"lane_count   = [0,0,0,0,0,0]\nlane_status  = ['empty','empty','empty','empty','empty','empty']\nlane_previous= ['empty','empty','empty','empty','empty','empty']\n\n#for fno in range(30): #for debugging\nfor fno in range(TOTAL_FRAMES):\n    for i in range(len(dfs[fno])):\n        if dfs[fno].iloc[i].y<=Y2 and (dfs[fno].iloc[i].y+int(dfs[fno].iloc[i].h\/2))>=Y2:\n            if   dfs[fno].iloc[i].x>=0  and dfs[fno].iloc[i].x<X1: lane_no=0        \n            elif dfs[fno].iloc[i].x>=X1 and dfs[fno].iloc[i].x<X2: lane_no=1\n            elif dfs[fno].iloc[i].x>=X2 and dfs[fno].iloc[i].x<X3: lane_no=2\n            elif dfs[fno].iloc[i].x>=X3 and dfs[fno].iloc[i].x<X4: lane_no=3\n            elif dfs[fno].iloc[i].x>=X4 and dfs[fno].iloc[i].x<X5: lane_no=4\n            else: lane_no=5\n            lane_status[lane_no] = 'front'\n        elif dfs[fno].iloc[i].y>Y2 and (dfs[fno].iloc[i].y-int(dfs[fno].iloc[i].h\/2))<=Y2:\n            if dfs[fno].iloc[i].x>=0  and dfs[fno].iloc[i].x<X1: lane_no=0        \n            elif dfs[fno].iloc[i].x>=X1 and dfs[fno].iloc[i].x<X2: lane_no=1\n            elif dfs[fno].iloc[i].x>=X2 and dfs[fno].iloc[i].x<X3: lane_no=2\n            elif dfs[fno].iloc[i].x>=X3 and dfs[fno].iloc[i].x<X4: lane_no=3\n            elif dfs[fno].iloc[i].x>=X4 and dfs[fno].iloc[i].x<X5: lane_no=4 \n            else: lane_no=5\n            lane_status[lane_no] = 'back'\n    \n    # count increment by 1 if changing from front to back    \n    for i in range(6):\n        if lane_previous[i]=='front' and lane_status[i]=='back': \n            lane_count[i]+=1\n            \n    # update lane_status to lane_previous\n    for i in range(6):\n        lane_previous[i]=lane_status[i]","7b645f4d":"VIDEO_TIME = 28 # seconds\n# print out car count\nfor i in range(6):\n    print('Lane '+str(i)+' = '+str(lane_count[i]*60\/VIDEO_TIME)+' cars\/minutes')\n    \ntotal_count = 0\nfor i in range(6):\n    total_count += lane_count[i]\nprint('Total Flow: '+str(total_count*60\/VIDEO_TIME)+' car\/minutes')","a2b582d8":"lane_carlen= [0,0,0,0,0,0]\nlane_speed = [0,0,0,0,0,0]\nlane_begin = [0,0,0,0,0,0] # frame no. of begin (car hit Y2)\nlane_end   = [0,0,0,0,0,0] # frame no. of end   (car leave Y2)\n\nfor fno in range(TOTAL_FRAMES):\n    for i in range(len(dfs[fno])):\n        if  (dfs[fno].iloc[i].y+int(dfs[fno].iloc[i].h\/2))==Y2:\n            if   dfs[fno].iloc[i].x>=0  and dfs[fno].iloc[i].x<X1: lane_no=0        \n            elif dfs[fno].iloc[i].x>=X1 and dfs[fno].iloc[i].x<X2: lane_no=1\n            elif dfs[fno].iloc[i].x>=X2 and dfs[fno].iloc[i].x<X3: lane_no=2\n            elif dfs[fno].iloc[i].x>=X3 and dfs[fno].iloc[i].x<X4: lane_no=3\n            elif dfs[fno].iloc[i].x>=X4 and dfs[fno].iloc[i].x<X5: lane_no=4\n            else: lane_no=5\n            lane_begin[lane_no]=fno\n            lane_carlen[lane_no]=dfs[fno].iloc[i].h # record height for car length\n        elif (dfs[fno].iloc[i].y-int(dfs[fno].iloc[i].h\/2))==Y2:\n            if dfs[fno].iloc[i].x>=0  and dfs[fno].iloc[i].x<X1: lane_no=0        \n            elif dfs[fno].iloc[i].x>=X1 and dfs[fno].iloc[i].x<X2: lane_no=1\n            elif dfs[fno].iloc[i].x>=X2 and dfs[fno].iloc[i].x<X3: lane_no=2\n            elif dfs[fno].iloc[i].x>=X3 and dfs[fno].iloc[i].x<X4: lane_no=3\n            elif dfs[fno].iloc[i].x>=X4 and dfs[fno].iloc[i].x<X5: lane_no=4 \n            else: lane_no=5\n            lane_end[lane_no]=fno\n            \n            carlen = lane_carlen[lane_no]\n            carlen = carlen\/66*5    # estiate 66 pixels= 5 meters\n            # calculate car speed\n            lane_speed[lane_no]=int(carlen*3*6*6\/(lane_end[lane_no]-lane_begin[lane_no]+1))\n            print('frame:', fno)\n            print('Lane '+str(lane_no)+'. speed = '+str(lane_speed[lane_no])+' Km\/hr') #, car length ~='+str(carlen)+' meters')\n            print()\n            # clear lane_begin, lane_end and lane_speed\n            lane_begin[lane_no]=fno\n            lane_end[lane_no]=fno\n            lane_carlen[lane_no]=0","a1e6340d":"# YOLOv5 Object Detection","986a583f":"## Display full-size image","2a62c158":"### output_path: runs\/detect\/exp","abfc9054":"# Analyze Traffic (Detected Objects)","0b7f6c7c":"## Compare frame images ","18be737c":"### show\/check cars when y>Y1\n### counting cars at Y2","b84dee5a":"## Car Speed per lane","5b3fc677":"## Detect Video","4f9ce6fe":"#### Total: 844 frames = 28s x 30f\/s","62f5063a":"## Car Volume per lane","b0677824":"## Draw bbox on each frames","6aece401":"## The video length = 28s, 28s x30fps = 844 frames","67a4ae56":"### download below images to PC for using Paintbrush Tool to identify Lane x & y","33dea716":"## read frames' .txt to create dataframes","5a42e0ea":">     $ python detect.py --source 0  # webcam\n>                           file.jpg  # image \n>                            file.mp4  # video\n>                            path\/  # directory\n>                            path\/*.jpg  # glob\n>                            rtsp:\/\/170.93.143.139\/rtplive\/470011e600ef003a004ee33696235daa  # rtsp stream\n>                            rtmp:\/\/192.168.1.105\/live\/test  # rtmp stream\n>                            http:\/\/112.50.243.8\/PLTV\/88888888\/224\/3221225900\/1.m3u8  # http stream","2901ad28":"## Repro [Github](https:\/\/github.com\/ultralytics\/yolov5)  *(torch>=1.7.0, torchvision>=0.8.1)*","8a7006a5":"### read frames to show"}}