{"cell_type":{"bde8fb6e":"code","1dfbde1e":"code","286484b6":"code","34c55bb7":"code","3fb74e2f":"code","637bd197":"code","7b8cf6ee":"code","6fb4c22f":"code","b9ca6e41":"markdown","680dcb43":"markdown","57688ad1":"markdown","bb469f5c":"markdown","4efc06b4":"markdown","5e16fa47":"markdown","4f76478d":"markdown","4da3b376":"markdown","787ac456":"markdown"},"source":{"bde8fb6e":"import numpy as np\n\nimport matplotlib.pyplot as plt\nimport cv2","1dfbde1e":"classes = '..\/input\/yolo-coco-data\/coco.names'\nconfig = '..\/input\/yolo-coco-data\/yolov3.cfg'\nweights = '..\/input\/yolo-coco-data\/yolov3.weights'\n\nLABELS = open(classes).read().strip().split(\"\\n\")\nCOLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")    # Just to Colour the boxes","286484b6":"model = cv2.dnn.readNet(config, weights)     # 'readNet()' automatically directs the program to 'readNetFromDarknet(config, weights)'","34c55bb7":"img = cv2.imread('..\/input\/data-for-yolo-v3-kernel\/dog.jpg')         # Change Me!\n(H, W) = img.shape[:2]\nln = model.getLayerNames()\noutput_ln = [ln[i[0] - 1] for i in model.getUnconnectedOutLayers()]\n\nimg_blob = cv2.dnn.blobFromImage(img, 1\/255.0, (608,608))            # Re-Scaling is IMPORTANT\nmodel.setInput(img_blob)\noutputs = model.forward(output_ln)  ","3fb74e2f":"for i in outputs:\n    print(i.shape)        ","637bd197":"THRESHOLD = 0.3\nboxes = []\nconfidences = []\nclassIDs = []","7b8cf6ee":"for output in outputs[0]:\n    scores = output[5:]\n    classID = np.argmax(scores)\n    confidence = scores[classID]\n\n    if confidence > THRESHOLD:\n        \n        x = (output[0] - output[2]\/2) * W        # location in image = position of anchor_box * image_pixel value\n        y = (output[1] - output[3]\/2) * H\n\n        boxes.append([int(x), int(y), int(output[2]* W), int(output[3]* H)])\n        confidences.append(float(confidence))\n        classIDs.append(classID)","6fb4c22f":"idxs = cv2.dnn.NMSBoxes(boxes, confidences, THRESHOLD, THRESHOLD)\n\nfor idx in idxs:\n    idx = idx[0]\n    color = [int(c) for c in COLORS[classIDs[idx]]]\n    cv2.rectangle(img, (boxes[idx][0],boxes[idx][1]), (boxes[idx][0]+boxes[idx][2],boxes[idx][1]+boxes[idx][3]), color)\n    cv2.putText(img, \"{}  {:.2f}\".format(LABELS[classIDs[idx]], confidences[idx]), (boxes[idx][0],boxes[idx][1]), cv2.FONT_HERSHEY_SIMPLEX, 1, color)\n\ncv2.imwrite(\"example.png\", img)\nplt.imshow(img)","b9ca6e41":"## Model","680dcb43":"## Introduction\n\nThis Model is pre-trained for detection of 80 classes!!","57688ad1":"## Reference Directories","bb469f5c":"The Output is derived from 3 YOLO Layers for detection of Objects of different sizes.\n\nto know more visit [cv2_Official Website](https:\/\/opencv-tutorial.readthedocs.io\/en\/latest\/yolo\/yolo.html)","4efc06b4":"## Thank You!!","5e16fa47":"## Image Localization","4f76478d":"*variable \"Boxes\" contains*\n\n> [ (X_coordinate of_box_at_start), (Y_coordinate_of_box_at_start), (box_width), (box_height) ]","4da3b376":"## Prediction","787ac456":"## Importing Library"}}