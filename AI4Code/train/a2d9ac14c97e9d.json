{"cell_type":{"86c3c7bf":"code","7f1215e5":"code","0fd30bdd":"code","73edd90c":"code","9a3e6d04":"code","ba339b7b":"code","461119d0":"code","8f85f4c8":"code","176c9c1e":"code","505a646e":"code","75dd7024":"code","f688c199":"code","b8fcbdf7":"code","f04a1f20":"code","89e08b79":"code","74d0d95b":"code","16406b6b":"code","7d7cf3d1":"code","40c04138":"code","87cb6c7f":"code","3ab41ac8":"code","950bcf4c":"code","2f8a1e2f":"code","e3a12a7b":"code","cac770e1":"code","56efb27a":"code","d1c39c29":"code","33844cc7":"code","cce6576d":"code","1de68074":"code","85812799":"code","e22a52a9":"markdown","133b2302":"markdown","655a6880":"markdown","b1289b8c":"markdown","b49feb22":"markdown","1a53945d":"markdown","b8856d97":"markdown","44d3d5f9":"markdown"},"source":{"86c3c7bf":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom datetime import datetime","7f1215e5":"sns.set(rc={'figure.figsize':(10,5)})\n\ndf = pd.read_csv('..\/input\/netflix-stock-data-from-2002-to-2021\/NFLX.csv')\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.set_index('Date')\ndf.head()","0fd30bdd":"#df['Volume'].plot(label='x')\n#df['Volume'].rolling(window=12).mean().plot(label='y')\nsns.lineplot(x=df.index,y=df['Volume'],label='Volume')\nsns.lineplot(x=df.index,y=df['Volume'].rolling(window=12).mean(),label='Averaged volume')\nplt.title('Volume of stock versus time')","73edd90c":"df.plot(y=['High','Close','Open'],title='Netflix stock price')","9a3e6d04":"fig, (ax1,ax2,ax3) = plt.subplots(3,figsize=(15,10))\ndf.groupby(df.index.day).mean().plot(y=['High','Close','Low'],ax=ax1,xlabel='Day')\ndf.groupby(df.index.month).mean().plot(y=['High','Close','Low'],ax=ax2, xlabel='Month')\ndf.groupby(df.index.year).mean().plot(y=['High','Close','Low'], ax=ax3, xlabel='Year')","ba339b7b":"\nfig, (ax1,ax2,ax3) = plt.subplots(3,figsize=(15,10))\ndf.groupby(df.index.day).mean().plot(y='Volume',ax=ax1,xlabel='Day')\ndf.groupby(df.index.month).mean().plot(y='Volume',ax=ax2,xlabel='Month')\ndf.groupby(df.index.year).mean().plot(y='Volume', ax=ax3,xlabel='Year')","461119d0":"def plot_mean_std_over_time(data, feature_name, chunk_size,title=None):\n    feature = data[feature_name]\n    chunks = np.split(feature,chunk_size)\n\n    means = [np.mean(chunk) for chunk in chunks]\n    stds = [np.std(chunk) for chunk in chunks]\n    \n    if title:\n        plt.title(title)\n    \n    plt.plot(np.arange(len(means)),[feature.mean()]*len(means),label='Global mean', lw=1.5)\n    plt.scatter(x=np.arange(len(means)), y=means, label='Mean', s=100)\n    plt.plot(np.arange(len(stds)), [feature.std()] * len(stds), label='Global std', lw=1.5, color='orange')\n    plt.scatter(x=np.arange(len(stds)), y=stds, label='STD', color='orange', s=100)\n    plt.legend()","8f85f4c8":"plot_mean_std_over_time(df.iloc[:4800], 'Volume',20,\"Comparsion of Volume's mean and standard deviation over time\")","176c9c1e":"plot_mean_std_over_time(df.iloc[:4800], 'Close',20,\"Comparsion of Close's mean and standard deviation over time\")","505a646e":"from statsmodels.graphics.tsaplots import plot_acf \n\nplot_acf(df['Volume'])\nplt.ylim([-0.25,1.1])\nplt.title('Autocorrelation plot of Volume feature.')","75dd7024":"plot_acf(df['Close'])\nplt.ylim([-0.25,1.1])\nplt.title('Autocorrelation plot of Close feature.')","f688c199":"from statsmodels.tsa.seasonal import seasonal_decompose \n\ndecomposition = seasonal_decompose(df['Volume'],period=365,model='additive')\ndecomposition.plot();","b8fcbdf7":"decomposition = seasonal_decompose(df['Close'],period=365,model='additive')\ndecomposition.plot();","f04a1f20":"from statsmodels.tsa.stattools import adfuller\n\ntest = adfuller(df['Close'])\nadf_df = pd.DataFrame(data=test,columns=['Values'],\n                                        index=['Test statistic',\n                                        'P-value',\n                                        'Number of lags',\n                                        'Number of observation',\n                                        'Critical values',\n                                        'Information criteria'])\nadf_df","89e08b79":"diff1 = df['Close'].diff(1)[1:]\np_value = adfuller(diff1)\np_value","74d0d95b":"plt.title('Close value of the stock with different difference order')\nfor i in range(1,5):\n    p_value = adfuller(df['Close'].diff(i)[i:])[1]\n    plt.plot(df['Close'].diff(i).dropna(),label=f'P-value: {p_value}')\nplt.legend();","16406b6b":"def make_stationary(data: pd.Series, alpha = 0.05, max_diff = 10):\n    if adfuller(data)[1] < alpha:\n        return {'diff_order':0,\n                'time_series': data}\n    \n    p_values = [(i,adfuller(data.diff(i).dropna())[1]) for i in range(1,max_diff)]\n\n    significant = [p for p in p_values if p[1] < alpha]\n    significant = sorted(significant, key=lambda x: x[1])\n\n    diff_order = significant[0][0]\n    return {'diff_order': diff_order,\n            'time_series': np.array(data.diff(diff_order).dropna())}\n","7d7cf3d1":"data = make_stationary(df['Close'])\nplt.title(f\"Close features turned stationary with {data['diff_order']} differences.\")\nplt.plot(data['time_series'])","40c04138":"plt.title('Moving averages ran on stock price.')\nfor i in [0,3,6,12,48]:\n    plt.plot(df.rolling(i).mean()['Close'],label=f'MA{i}')\nplt.legend();","87cb6c7f":"seas_diff = df['Close'] - df['Close'].shift(12)\nseas_diff.plot()","3ab41ac8":"print(adfuller(seas_diff.dropna()))","950bcf4c":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n\nplot_acf(df['Close'].diff(2).dropna())\nplot_pacf(df['Close'].diff(2).dropna());","2f8a1e2f":"plot_acf(seas_diff.dropna())\nplot_pacf(seas_diff.dropna());","e3a12a7b":"stationary_ts = df['Close'].diff(2).dropna()\nstationary_ts = stationary_ts.resample('M').mean()\ntrain_len = int(0.7*len(stationary_ts))","cac770e1":"from statsmodels.tsa.statespace.sarimax import SARIMAX \n\nmodel = SARIMAX(stationary_ts.iloc[:train_len], \n                order=(1,2,1),\n                seasonal_order=(1,0,0,12))\n\nresult = model.fit()","56efb27a":"result.resid.plot(kind='kde')","d1c39c29":"start,end = stationary_ts.index.values[train_len], stationary_ts.index.values[-1]\npredictions = result.predict(start=start,end=end)\n\nplt.title('Forecasting Netflix stock price')\nstationary_ts.iloc[:train_len].plot()\n\npredictions.dropna().plot()","33844cc7":"plt.title(\"Comparing predicted stock price against actual stock price\")\nstationary_ts.loc[stationary_ts.index.year >2019].plot()\npredictions.dropna().loc[predictions.index.year > 2019].plot()","cce6576d":"def train_arima(p,q,train_per=0.7):\n    train_len = int(train_per*len(stationary_ts))\n    model = SARIMAX(stationary_ts.iloc[:train_len], \n                    order=(p,2,q),\n                    seasonal_order=(1,0,0,12))\n    \n    start,end = stationary_ts.index.values[train_len], stationary_ts.index.values[-1]\n    predictions = result.predict(start=start,end=end)\n\n    plt.title(f'Forecasting Netflix stock price with values of p={p} and q={q}')\n    stationary_ts.plot()\n    predictions.dropna().plot()\n    plt.show()","1de68074":"for p in [2,3,5]:\n    for q in [1,2]:\n        train_arima(p,q)","85812799":"from pandas.tseries.offsets import DateOffset \n\n\nts = pd.DataFrame(stat_ts)\nnew_dates = [df.index[-1] + DateOffset(months=x) for x in range(1,12)]\ndf_pred = pd.DataFrame(index=new_dates,columns=['Close'])\nts = pd.concat([ts,df_pred])\nts['predictions'] = np.nan","e22a52a9":"We indeed observe a few patterns that we shall test later on. That is:\n- Overall there is apparent trend in the stock price of netflix indicating for future growth in it's price. \n- From september onwards in each year there is a strong decrease in the stock price. We also note an increase in volume each year between September-October indicating for people noticing the fall of the stock and hurry to sell out yet after october there's a sharp change in direction with people less selling. It can be explaiend by the stock price \"stabilizing\" over the same period of time. \n- The months of summer seems to be sucessful for Netflix with apparent peak in July. It's a reasonable hypotesis considering titles are more likely to come out, teenagers are in vacation and spend more time using Netflix's service. \n\nNext to check if our data is predictable we shall plot it's mean and deviation over time to avoid dealing with unpredictable white noise.","133b2302":"Now that we learned the data is ineed not stationary we will use differencing for different N values and test stationarity for each values. ","655a6880":"Summary, iin order to use an ARIMA model to forecast a time series we do the following:\n\n- Split the time series into train and test data.\n- Check to see if the data is seasonal or not (In the case of a stock price it's most likely to be)\n- Apply differencing to turn the time series into stationary by using the ADF test (keep doing so until the ADF rejects and saves the order of differencing as d for ARIMA). \n- Use the autocorrelation and partial autocorrelation plot to estimate p,P and q,Q (P,Q are in case time series is seasonal)\n- Fine tune using GridSearch. ","b1289b8c":"Our p-value is below 0.05 so we do not need to differnce. Next for estimating p,q we use Autocorrelation and Partial Autocorrelation.","b49feb22":"We will test for stationarity for our data using ADF test. We will do so before applying any forecasting algorithm to know better if our data is need to be differenced and if so by how many times. \n\nThe ADF test is a hypotesis test with a null hypotesis stating the data is not stationary and alternative hypotesis stating the time series is ineed stationary. Hence when running the test if the returned p-value is greater than 0.05 we know the time seris is stationary and non-stationary otherwise.","1a53945d":"Now we turn to run the ARIMA model, we already learned the d parameters i.e the number of differences required to make the time series stationary. But because we deal with seasonal data, we work with stock price so we work in seasons of years, we need to estimate the seasonal paramters aswell and in particular the D value which is the seasonal difference.","b8856d97":"We note an autocorrelation resembeling a random walk for Close and a quick decrease in Volume implying less of correlation between past values.","44d3d5f9":"First we shall analyze the data by plotting the data over the whole duration and then over different periods to look for patterns."}}