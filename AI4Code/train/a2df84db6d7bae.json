{"cell_type":{"08c1318c":"code","6058ac81":"code","212ab44d":"code","4580d71a":"code","1183dd6e":"code","6e8faa02":"code","5ebaca3e":"code","072728c2":"code","86f98256":"code","ff8c7fe6":"code","9dc1c53a":"code","e363a060":"code","f6cced1d":"code","b723a292":"code","8054cdc1":"code","8fe8c8f1":"markdown","860adb2f":"markdown","211c974a":"markdown","bf1e1891":"markdown"},"source":{"08c1318c":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm.notebook as tqdm\nimport skimage.color","6058ac81":"df_train = pd.read_csv('..\/input\/fairface\/FairFace\/train_labels.csv')\ndf_train['split'] = 'train'\ndf_test = pd.read_csv('..\/input\/fairface\/FairFace\/val_labels.csv')\ndf_test['split'] = 'test'\ndf = pd.concat([df_train, df_test])\n\ndf = df.drop(columns=['service_test', 'gender', 'age'])","212ab44d":"df.describe()","4580d71a":"df['race'].value_counts().plot.bar()\nplt.show()\nplt.close()","1183dd6e":"df_train = df[df.split == 'train']\ndf_test = df[df.split == 'test']","6e8faa02":"def run_histogram_equalization(img_bgr):\n    \"\"\"Histogram eq of colour image.\n    \n    We convert BGR to YCrCb and select the Y channel (which represents brightness).\n    Perform histogram eq. on the Y and then convert back to BGR\n    \n    https:\/\/stackoverflow.com\/a\/38312281\/6594629\n    https:\/\/www.opencv-srf.com\/2018\/02\/histogram-equalization.htm\n    \"\"\"\n    img_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n    img_ycrcb[:, :, 0] = cv2.equalizeHist(img_ycrcb[:, :, 0])\n    img_bgr = cv2.cvtColor(img_ycrcb, cv2.COLOR_YCrCb2BGR)\n    return img_bgr\n\n\ndef segment_otsu(image_grayscale, img_BGR):\n    \"\"\"Segment using otsu binarization and thresholding.\"\"\"\n    threshold_value, threshold_image = cv2.threshold(image_grayscale, 0, 255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n    threshold_image_binary = 1 - (threshold_image \/ 255)\n    threshold_image_binary = np.repeat(threshold_image_binary[:, :, np.newaxis], 3, axis=2)\n    img_face_only = np.multiply(threshold_image_binary, img_BGR).astype('uint8')\n    return img_face_only\n\nimg_bgr = cv2.imread('..\/input\/fairface\/FairFace\/train\/1.jpg')\nprint(\"Original Image\")\nplt.imshow(img_bgr[:, :, ::-1])\nplt.show()\n\nprint(\"Original Image after Histogram eq.\")\nimg_bgr = run_histogram_equalization(img_bgr)\nplt.imshow(img_bgr[:, :, ::-1])\nplt.show()\n\nprint(\"Grayscale Image\")\nimg_grayscale = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\nplt.imshow(img_grayscale, cmap='gray')\nplt.show()\n\nprint(\"After segmentation using Otsu's method.\")\nimg_bgr = segment_otsu(img_grayscale, img_bgr)\nplt.imshow(img_bgr[:, :, ::-1])\nplt.show()\n\nprint(\"HSV space\")\nimg_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\nplt.imshow(img_hsv[:, :, ::-1])\nplt.show()\n\nprint(\"YCrCb space\")\nimg_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\nplt.imshow(img_ycrcb[:, :, ::-1])\nplt.show()\n    \nmask = (img_hsv[:, :, 0] <= 170) & \\\n    (img_ycrcb[:, :, 1] >= 140) & \\\n    (img_ycrcb[:, :, 1] <= 170) & \\\n    (img_ycrcb[:, :, 2] >= 90) & \\\n    (img_ycrcb[:, :, 2] <= 120)\n\nprint(\"After masking\")\nimg_bgr[~mask] = 0\nplt.imshow(img_bgr[:, :, ::-1])\nplt.show()\n\nblue = np.ma.array(img_bgr[:, :, 0], mask=~mask).mean()\ngreen = np.ma.array(img_bgr[:, :, 1], mask=~mask).mean()\nred = np.ma.array(img_bgr[:, :, 2], mask=~mask).mean()\n\nprint(f\"Final average skin tone RGB: {red}, {green}, {blue}\")\nplt.imshow([[[x \/ 255 for x in [red, green, blue]]]])\nplt.show()","5ebaca3e":"def predict_img(img_bgr, equalize=False):\n    if isinstance(img_bgr, str):\n        img_bgr = cv2.imread(img_bgr)\n    \n    if equalize:\n        img_bgr = run_histogram_equalization(img_bgr)\n\n    img_grayscale = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n\n    img_bgr = segment_otsu(img_grayscale, img_bgr)\n    del img_grayscale\n\n    img_bgr = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n    img_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n    \n    mask = (img_hsv[:, :, 0] <= 170) & \\\n        (img_ycrcb[:, :, 1] >= 140) & \\\n        (img_ycrcb[:, :, 1] <= 170) & \\\n        (img_ycrcb[:, :, 2] >= 90) & \\\n        (img_ycrcb[:, :, 2] <= 120)\n\n    img_bgr[~mask] = 0\n\n    blue = np.ma.array(img_bgr[:, :, 0], mask=~mask).mean()\n    green = np.ma.array(img_bgr[:, :, 1], mask=~mask).mean()\n    red = np.ma.array(img_bgr[:, :, 2], mask=~mask).mean()\n    \n    return blue, green, red","072728c2":"# We have a lot of data, subsample\nN_TRAIN = len(df_train)  # 2000\nN_TEST = len(df_test)  # int(0.2 * N_TRAIN)\n\nnp.random.seed(0)\ndf_train = df_train.loc[np.random.randint(0, len(df_train), N_TRAIN)]\ndf_test = df_test.loc[np.random.randint(0, len(df_test), N_TEST)]","86f98256":"x_train = np.array([predict_img(os.path.join('..\/input\/fairface\/FairFace', file_)) for file_ in tqdm.tqdm(df_train.file.values)])\nx_test = np.array([predict_img(os.path.join('..\/input\/fairface\/FairFace', file_)) for file_ in tqdm.tqdm(df_test.file.values)])","ff8c7fe6":"y_train, y_train_map = pd.Categorical(df_train.race).factorize()\ny_test, y_test_map = pd.Categorical(df_test.race).factorize()","9dc1c53a":"# Drop cases where segmentation fails\ntrain_idx = ~(np.isnan(x_train).any(axis=1))\nx_train = x_train[train_idx]\ny_train = y_train[train_idx]\n\ntest_idx = ~(np.isnan(x_test).any(axis=1))\nx_test = x_test[test_idx]\ny_test = y_test[test_idx]","e363a060":"# Add ita angle feature\ndef compute_ita(r, g, b):\n    l, a, b = skimage.color.rgb2lab([[[r, g, b]]], illuminant='D65', observer='10').flatten()\n    ita = (l - 50) \/ b\n    ita = np.arctan(ita)\n    ita = np.rad2deg(ita)\n    return ita\n\n\nb, g, r = predict_img(cv2.imread('..\/input\/fairface\/FairFace\/train\/1.jpg'))\ncompute_ita(r, g, b)\n\nita_train = np.array([[compute_ita(r, g, b)] for r, g, b in x_train])\nx_train = np.hstack((x_train, ita_train))\n\nita_test = np.array([[compute_ita(r, g, b)] for r, g, b in x_test])\nx_test = np.hstack((x_test, ita_test))","f6cced1d":"fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True)\n_labels = ['blue', 'green', 'red', 'ita']\nfor i, ax in enumerate(axs.flatten()):\n    scatter = ax.scatter(y_train, x_train[:, i], c=y_train, label=y_train)\n    ax.set_xlabel('Class')\n    ax.set_ylabel(_labels[i])\n    # legend = ax.legend(*scatter.legend_elements(), loc=\"lower left\", title=\"Classes\")\n    # ax.add_artist(legend)\n\nplt.show()\nplt.close()\ndel _labels","b723a292":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.metrics import confusion_matrix as cm, classification_report as cr\n\nrf = RFC(random_state=0).fit(x_train, y_train)\n\ny = rf.predict(x_train)\nprint(cm(y_true=y_train, y_pred=y))\nprint(cr(y_true=y_train, y_pred=y))","8054cdc1":"y = rf.predict(x_test)\nprint(cm(y_true=y_test, y_pred=y))\nprint(cr(y_true=y_test, y_pred=y))","8fe8c8f1":"# Classical skin segmentation model","860adb2f":"We first demonstrate the approach. It is my own implementation of the approach described here http:\/\/www.eleco.org.tr\/openconf_2017\/modules\/request.php?module=oc_proceedings&action=view.php&id=248&file=1\/248.pdf&a=Accept+as+Lecture\n\nThe goal is to extract the average RGB values of the skin pixels\n","211c974a":"# EDA + data_prep","bf1e1891":"Predict skin tone from image."}}