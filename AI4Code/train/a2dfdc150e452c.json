{"cell_type":{"1bfb8814":"code","1cea2f9b":"code","0cb99b67":"code","bc446a5b":"code","ba90c394":"code","54924c59":"code","0f921202":"code","133ecc30":"code","7f8557d1":"code","fdab3b2d":"code","64faa58e":"code","d594f623":"code","011f62bc":"code","391742ee":"code","7dfde7a4":"code","f06934e7":"code","cedaaa33":"code","b67f4619":"code","ce03324a":"code","0160e9fa":"code","fc15bc37":"code","1678b17d":"code","250af383":"code","b6042683":"code","1968ca8b":"code","65176fad":"code","9573862a":"code","e4de1fc7":"code","e03ef9b8":"code","f6813e0d":"code","65bf305c":"code","8872a2ef":"code","485d1f3f":"code","d817ee41":"code","f33b4734":"code","f1778472":"code","af85d036":"code","7b3e585c":"code","c6862f48":"code","0fa45bdc":"markdown","d9edd400":"markdown"},"source":{"1bfb8814":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1cea2f9b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n#img_shape=(128,128,3)\nimage_gen =ImageDataGenerator(rotation_range=20,\n                              width_shift_range=0.1,\n                              height_shift_range=0.1,\n                              rescale=1\/255,\n                              shear_range=0.1,\n                              zoom_range=0.1,\n                              horizontal_flip=True,\n                              fill_mode='nearest',\n                              validation_split=0.2)","0cb99b67":"train = image_gen.flow_from_directory('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',batch_size = 32, target_size = (224,224),\n                                     subset = 'training',shuffle = True)\n","bc446a5b":"valid = image_gen.flow_from_directory('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',batch_size = 32, target_size = (224,224),\n                                     subset = 'validation',shuffle = True)\n","ba90c394":"test=image_gen.flow_from_directory('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test', target_size = (224,224), batch_size = 32 ,shuffle = True)\n","54924c59":"import tensorflow as tf\nfrom tensorflow.keras.applications.densenet import DenseNet121","0f921202":"densenet= DenseNet121(input_shape=(224,224,3),include_top=False,weights=\"imagenet\")","133ecc30":"for layers in densenet.layers:\n    layers.trainable=False","7f8557d1":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom keras import layers\nmodeldense=Sequential()\nmodeldense.add(densenet)\nmodeldense.add(Dropout(0.5))\nmodeldense.add(Flatten())\nmodeldense.add(BatchNormalization())\nmodeldense.add(Dense(64,kernel_initializer='he_uniform'))\nmodeldense.add(BatchNormalization())\nmodeldense.add(Activation('relu'))\nmodeldense.add(Dropout(0.5))\nmodeldense.add(Dense(64,kernel_initializer='he_uniform'))\nmodeldense.add(BatchNormalization())\nmodeldense.add(Activation('relu'))\nmodeldense.add(Dropout(0.5))\nmodeldense.add(Dense(64,kernel_initializer='he_uniform'))\nmodeldense.add(BatchNormalization())\nmodeldense.add(Activation('relu'))\nmodeldense.add(Dropout(0.5))\nmodeldense.add(Dense(32,kernel_initializer='he_uniform'))\nmodeldense.add(BatchNormalization())\nmodeldense.add(Activation('relu'))\nmodeldense.add(Dropout(0.5))\nmodeldense.add(Dense(32,kernel_initializer='he_uniform'))\nmodeldense.add(BatchNormalization())\nmodeldense.add(Activation('relu'))\nmodeldense.add(Dense(4,activation='softmax'))","fdab3b2d":"modeldense.summary()","64faa58e":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        #f1_score,\n]","d594f623":"modeldense.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=METRICS)","011f62bc":"history=modeldense.fit(train,validation_data=valid,epochs=20)","391742ee":"import matplotlib.pyplot as plt\nplt.plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'])\nplt.plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'])\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend(['training', 'validation'])","7dfde7a4":"plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'])\nplt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'])\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend(['training', 'validation'])","f06934e7":"scores = modeldense.evaluate_generator(test)","cedaaa33":"print(\"Accuracy = \", scores[1])\nprint(\"Precision = \", scores[2])\nprint(\"Recall = \", scores[3])\nprint(\"AUC = \", scores[4])","b67f4619":"import tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n","ce03324a":"resnet = ResNet50(input_shape=(224,224,3), \n                   include_top=False,\n                   weights=\"imagenet\")","0160e9fa":"for layer in resnet.layers:\n    layer.trainable = False","fc15bc37":"import tensorflow\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom keras import layers\nmodel=Sequential()\nmodel.add(resnet)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dense(4,activation='softmax'))","1678b17d":"model.summary()","250af383":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 5)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","b6042683":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        #f1_score,\n]","1968ca8b":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=METRICS)","65176fad":"history=model.fit(train,validation_data=valid,epochs = 20,verbose = 1,callbacks=lr_scheduler)","9573862a":"scores = model.evaluate_generator(test)","e4de1fc7":"print(\"Accuracy = \", scores[1])\nprint(\"Precision = \", scores[2])\nprint(\"Recall = \", scores[3])\nprint(\"AUC = \", scores[4])","e03ef9b8":"import matplotlib.pyplot as plt\nplt.plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'])\nplt.plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'])\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.title(\"Resnet50\")\nplt.legend(['training', 'validation'])","f6813e0d":"plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'])\nplt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'])\nplt.xlabel(\"epochs\")\nplt.title(\"Resnet50\")\nplt.ylabel(\"loss\")\nplt.legend(['training', 'validation'])","65bf305c":"from tensorflow.keras.applications.xception import Xception\n\nxcepmodel = Xception(input_shape=(224,224,3), \n                   include_top=False,\n                   weights=\"imagenet\")","8872a2ef":"for layer in xcepmodel.layers:\n    layer.trainable = False","485d1f3f":"model=Sequential()\nmodel.add(xcepmodel)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dense(4,activation='softmax'))","d817ee41":"model.summary()","f33b4734":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=METRICS)","f1778472":"history=model.fit(train,validation_data=valid,epochs = 20,verbose = 1,callbacks=lr_scheduler)","af85d036":"import matplotlib.pyplot as plt\nplt.plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'])\nplt.plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'])\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend(['training', 'validation'])","7b3e585c":"scores = model.evaluate_generator(test)","c6862f48":"print(\"Accuracy = \", scores[1])\nprint(\"Precision = \", scores[2])\nprint(\"Recall = \", scores[3])\nprint(\"AUC = \", scores[4])","0fa45bdc":"**RESNET MODEL**","d9edd400":"XCEPTION MODEL"}}