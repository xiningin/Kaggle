{"cell_type":{"39e8f865":"code","10b04e25":"code","e00ce86a":"code","facff65a":"code","1d6385fd":"code","700eb90b":"code","51a0885b":"code","8e2d65a7":"code","65a720ce":"code","1ba15b22":"code","89701695":"code","4cff0db6":"code","68837094":"code","5e714262":"code","3048b523":"code","e21bbdef":"code","e1e4dacd":"code","76411f33":"code","faf991a2":"code","1efa46af":"code","bdc9b1e6":"code","ff4b0b2d":"code","9ec16ff5":"code","9253391e":"code","aa5fc3df":"code","ff4b7243":"code","8f893e70":"code","c615e4d2":"code","a96a56ae":"code","cbb64031":"code","3ac04342":"code","1fe61c73":"code","211bb9d4":"code","dd74f6f8":"code","77e7b41d":"code","19385fc7":"markdown","05aa1fd5":"markdown"},"source":{"39e8f865":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","10b04e25":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","e00ce86a":"FILEPATH = '..\/input\/Toronto_apartment_rentals_2018.csv'","facff65a":"data = pd.read_csv(FILEPATH)","1d6385fd":"data.head()","700eb90b":"df.info()","51a0885b":"# get the number of missing data points per column\nmissing_values_count = data.isnull().sum()\n\n# missing points in the first 10 \nmissing_values_count[0:10]","8e2d65a7":"def get_space(pre_content, total_space_count = 30):\n\n    current_space_count = total_space_count - len(pre_content)\n    \n    return pre_content + (\" \" * current_space_count)","65a720ce":"def show_missing_percentage(current_df):\n    \n    total_cells = np.product(current_df.shape)\n    total_missing = missing_values_count.sum()\n    \n    total_space_count = 20\n\n    print(get_space(\"Total cells\", total_space_count)+\": {}\".format(total_cells))\n    print(get_space(\"Total missing cells\", total_space_count)+\": {}\".format(total_missing))\n\n    missing_percentage = (total_missing \/ total_cells)\n\n    print(get_space(\"Missing Percentage\", total_space_count)+\": {:.2%}\".format(missing_percentage))","1ba15b22":"show_missing_percentage(df)","89701695":"data = data.dropna(axis=0)","4cff0db6":"data.Bathroom = data.Bathroom.astype(float).round().astype(int)","68837094":"data['Price'] = data['Price'].str.replace(',', '')\ndata['Price'] = data['Price'].str.replace('$', '')\ndata['Price'] = data['Price'].astype(float).round().astype(int)","5e714262":"df = data","3048b523":"y = data.Price","e21bbdef":"features = ['Bedroom', 'Bathroom', 'Den', 'Lat', 'Long']","e1e4dacd":"X = data[features]","76411f33":"# Building your model\n# define model\nmodel = DecisionTreeRegressor(random_state=1)","faf991a2":"# Fit model\nmodel.fit(X, y)","1efa46af":"print('Making predictions for the following 5 houses')\nprint(X.head())\n\nprint('The predictions are')\nprint(model.predict(X.head()))","bdc9b1e6":"train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.67, random_state = 34)","ff4b0b2d":"# Train and Test dataset size details\nprint(\"Train_x Shape :: \", train_X.shape)\nprint(\"Train_y Shape :: \", train_y.shape)\nprint(\"Test_x Shape :: \", test_X.shape)\nprint(\"Test_y Shape :: \", test_y.shape)","9ec16ff5":"clf = model.fit(X, y)","9253391e":"y_predicted = clf.predict(test_X)\n    \n# print('original values')\n# print(test_y)\n# print('predicted')\n# print(y_predicted)","aa5fc3df":"print(\"accuracy\", model.score(X, y) * 100)","ff4b7243":"from sklearn.neural_network import MLPClassifier\n\nmlpc_model = MLPClassifier().fit(train_X, train_y)","8f893e70":"from sklearn.linear_model import LinearRegression\n\nlir_model = LinearRegression().fit(X, y)\n\n# lir_model","c615e4d2":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier().fit(train_X, train_y)\n\n# rf_model","a96a56ae":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n\nknn_model = knn.fit(train_X, train_y)\n\n# knn_model","cbb64031":"from sklearn.linear_model import LogisticRegression\n\nlor = LogisticRegression(solver = \"liblinear\")\nlor_model = lor.fit(X,y)\n\n# lor_model","3ac04342":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier()\ndt_model = dt_model.fit(train_X, train_y)\n\n# dt_model","1fe61c73":"# from sklearn.svm import SVC\n\n# svm_model = SVC(kernel = \"linear\").fit(train_X, train_y)\n\n# svm_model","211bb9d4":"from sklearn.naive_bayes import GaussianNB\n\nganb = GaussianNB()\nganb_model = ganb.fit(train_X, train_y)\n\nganb_model","dd74f6f8":"models = [\n    mlpc_model,\n    rf_model,\n    knn_model,\n    lor_model,\n    dt_model,\n#     svm_model,\n    ganb_model\n]\n\nbest_model_accuracy = 0\nbest_model = None\n\nfor model in models:\n    \n    model_name = model.__class__.__name__\n    \n    y_pred = model.predict(test_X)\n    accuracy = accuracy_score(test_y, y_pred)\n    \n    print(\"-\" * 30)\n    print(model_name + \": \" )\n    \n    if(accuracy > best_model_accuracy):\n        best_model_accuracy = accuracy\n        best_model = model_name\n    \n    print(\"Accuracy: {:.2%}\".format(accuracy))","77e7b41d":"print(\"Best Model : {}\".format(best_model))\nprint(\"Best Model Accuracy : {:.2%}\".format(best_model_accuracy))","19385fc7":"Let's try various algorithms","05aa1fd5":"The result doesn't seem good. I will have to do more data cleanup, feature engineering and tuning to come up with the better results.\n\nYou can come back again after a while to get more accuracy."}}