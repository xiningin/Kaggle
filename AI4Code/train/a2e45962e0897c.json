{"cell_type":{"6318cbf5":"code","2369b9bb":"code","026d72b5":"code","b0bc1e05":"code","f2c12b4d":"code","ab9cb37b":"code","ee09dd69":"code","7ef49f6b":"code","bb76fcdf":"code","d016eeee":"code","2d463638":"code","db0cb169":"code","346592bb":"code","0c0102eb":"code","72185f47":"code","1b7f7d04":"code","663528fb":"code","e00d354d":"code","2eab2135":"code","22ecb610":"code","2b9bfabb":"code","14f4b828":"code","5f1a7b6c":"code","4293e37f":"code","829c832f":"code","c5b0170f":"code","b37047bc":"code","f23ac5ad":"code","a69524d0":"code","571f9f45":"code","a94cd9d4":"code","13ab1bbd":"code","99fb909b":"code","2ec55edb":"code","e9315b9a":"code","d877ee29":"code","0a2098de":"code","77d552b2":"code","47b912b7":"code","c5980dbb":"code","9ed7cc2d":"code","3d34e6da":"code","e8ab7c3d":"code","804e01b7":"code","f21b2aaf":"code","24adeb3e":"code","9fe48ef8":"code","d59f7aa0":"code","9814d0f1":"code","6f8c6289":"code","6d424de4":"code","22c3e04d":"code","c5f71b79":"code","9bd9031f":"code","16b115ac":"code","b396a4fd":"markdown","8b5255b3":"markdown","9b635237":"markdown","b95ddcc0":"markdown","d4a3df09":"markdown","51078b34":"markdown","6d1d6eec":"markdown","815a1f6b":"markdown","8ef26887":"markdown","c7123801":"markdown","a69c2173":"markdown","88d30e44":"markdown","83cb4663":"markdown","2d4d19c6":"markdown","f4fe7b89":"markdown","257d9a03":"markdown","f7e44b44":"markdown","174b2251":"markdown","38c7bf06":"markdown","84bbf582":"markdown","53197cde":"markdown","9cc1e170":"markdown","3439a8c9":"markdown","2045c888":"markdown","dbe6730f":"markdown","db7edeec":"markdown","0d72e82a":"markdown","4a7b092b":"markdown","e4f2bff2":"markdown","d14ac569":"markdown","2f3ffaa6":"markdown","9df80634":"markdown","314ed8a0":"markdown","4c67db71":"markdown","9417535b":"markdown","68143bee":"markdown","f0cbfdd5":"markdown","18fc97c9":"markdown"},"source":{"6318cbf5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, r2_score, roc_curve, roc_auc_score\n\nfrom pandas_profiling import ProfileReport\n\nfrom scipy.stats import norm","2369b9bb":"df = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","026d72b5":"df.head()","b0bc1e05":"print(\"Shape\")\nprint(df.shape)\nprint(\"-\"*100)\nprint(\"Columns\")\ncolumns = df.columns\nprint(columns)\nprint(\"-\"*100)\nprint(\"Data information: \")\nprint(df.info())\nprint(\"-\"*100)\nprint(\"Data description: \")\nprint(df.describe())\nprint(\"-\"*100)\nprint(\"Null values count: \")\nprint(df.isnull().sum())\nprint(\"-\"*100)","f2c12b4d":"print(\"Gender: \",df[\"gender\"].unique())\nprint(\"Hypertension: \",df[\"hypertension\"].unique())\nprint(\"Heart Disease: \",df[\"heart_disease\"].unique())\nprint(\"Ever Married: \",df[\"ever_married\"].unique())\nprint(\"Work Type: \",df[\"work_type\"].unique())\nprint(\"Residence type: \",df[\"Residence_type\"].unique())\nprint(\"Smoking status: \",df[\"smoking_status\"].unique())\nprint(\"Stroke: \",df[\"stroke\"].unique())","ab9cb37b":"print(df[\"gender\"].value_counts())\nsns.set(style=\"darkgrid\")\nsns.countplot(x=df[\"gender\"],data=df)","ee09dd69":"print(df[\"hypertension\"].value_counts())\nsns.countplot(x=df[\"hypertension\"], data=df)","7ef49f6b":"print(df[\"heart_disease\"].value_counts())\nsns.countplot(x=df[\"heart_disease\"], data=df)","bb76fcdf":"print(df[\"ever_married\"].value_counts())\nsns.countplot(x=df[\"ever_married\"], data=df)","d016eeee":"print(df[\"work_type\"].value_counts())\nsns.countplot(x=df[\"work_type\"], data=df)","2d463638":"print(df[\"Residence_type\"].value_counts())\nsns.countplot(x=df[\"Residence_type\"], data=df)","db0cb169":"print(df[\"smoking_status\"].value_counts())\nsns.countplot(x=df[\"smoking_status\"], data=df)","346592bb":"print(df[\"stroke\"].value_counts())\nsns.countplot(x=df[\"stroke\"], data=df)","0c0102eb":"sns.countplot(x=df[\"hypertension\"], hue=df[\"stroke\"], data=df)","72185f47":"sns.countplot(x=df[\"gender\"], hue=df[\"stroke\"], data=df)","1b7f7d04":"sns.countplot(x=df[\"heart_disease\"], hue=df[\"stroke\"], data=df)","663528fb":"sns.countplot(x=df[\"ever_married\"], hue=df[\"stroke\"], data=df)","e00d354d":"sns.countplot(x=df[\"work_type\"], hue=df[\"stroke\"], data=df)","2eab2135":"sns.countplot(x=df[\"Residence_type\"], hue=df[\"stroke\"], data=df)","22ecb610":"sns.countplot(x=df[\"smoking_status\"], hue=df[\"stroke\"], data=df)","2b9bfabb":"sns.distplot(df[\"age\"], fit=norm)","14f4b828":"sns.distplot(df[\"bmi\"], fit=norm)","5f1a7b6c":"sns.distplot(df[\"avg_glucose_level\"], fit=norm)","4293e37f":"sns.boxplot(x=df[\"age\"], data=df)","829c832f":"sns.boxplot(x=df[\"bmi\"], data=df)","c5b0170f":"sns.boxplot(x=df[\"avg_glucose_level\"], data=df)","b37047bc":"data = df.corr(method='pearson')\nfig = plt.figure(figsize=(15,8))\nsns.heatmap(data,annot=True,cbar=True,linewidths=1)","f23ac5ad":"print(\"Missing values in bmi before: \",df[\"bmi\"].isnull().sum())","a69524d0":"df[\"bmi\"].fillna(value=df[\"bmi\"].mean(), inplace=True)","571f9f45":"print(\"Missing values in bmi after: \",df[\"bmi\"].isnull().sum())","a94cd9d4":"q1,q3 = np.percentile(df[\"bmi\"],[25,75])\nprint(q1,q3)\niqr = q3-q1\nupper_bound = q3+(1.5*iqr)\nlower_bound = q1-(1.5*iqr)\nprint(\"upper bound: {}, lower bound: {}\".format(upper_bound,lower_bound))","13ab1bbd":"df.drop(df[df['bmi'] > upper_bound].index, inplace = True)\ndf.drop(df[df['bmi'] < lower_bound].index, inplace = True)","99fb909b":"print(\"After outlier removal\")\nfig, axes = plt.subplots(1, 2,figsize=(15,5))\nsns.boxplot(x=df[\"bmi\"], data=df, ax = axes[0])\nsns.distplot(df[\"bmi\"], fit=norm, ax = axes[1])","2ec55edb":"# There is only one \"other\" category in the gender. So, we should remove it.\ndf.drop(df[df[\"gender\"]==\"Other\"].index, inplace=True)","e9315b9a":"# For gender column.\nsex = pd.get_dummies(df[\"gender\"], drop_first=True)\ndf = pd.concat([df,sex],axis=1)","d877ee29":"# For Ever_married colummn.\nmarried_status = pd.get_dummies(df[\"ever_married\"], drop_first=True)\ndf = pd.concat([df, married_status], axis=1)","0a2098de":"# For Residence type column.\nresidence = pd.get_dummies(df[\"Residence_type\"], drop_first=True)\ndf = pd.concat([df, residence], axis=1)","77d552b2":"df[\"Work_Type\"] = df[\"work_type\"].map({'Private':0,'Self-employed':1, 'Govt_job':2, 'children':3, 'Never_worked':4})\ndf[\"Smoking_Status\"] = df[\"smoking_status\"].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})","47b912b7":"df.head()","c5980dbb":"df.drop([\"id\",\"gender\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\"],axis=1, inplace=True)\ndf.head()","9ed7cc2d":"df.rename(columns={\"Male\":\"Gender\",\"Yes\":\"Ever_Married\",\"Urban\":\"Residence_type\"}, inplace=True)\ndf.head()","3d34e6da":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state = 42)\nX = df.drop(['stroke'],axis=1)\ny = df['stroke']\nX,y= smote.fit_resample(X,y)\ny = pd.DataFrame({'stroke':y})\nsns.countplot(data = y, x = 'stroke', y= None)\nplt.show()\nprint(y.value_counts())","e8ab7c3d":"df = pd.concat([X,y],axis = 1)\ndf.head()","804e01b7":"X = df.drop([\"stroke\"], axis=1)\ny = df[\"stroke\"]","f21b2aaf":"from sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nX = ss.fit_transform(X)","24adeb3e":"x_train,x_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)","9fe48ef8":"lr = LogisticRegression(solver=\"liblinear\").fit(x_train,y_train)\ngnb = GaussianNB().fit(x_train,y_train)\nknnc = KNeighborsClassifier().fit(x_train,y_train)\ndtc = DecisionTreeClassifier(random_state=42).fit(x_train,y_train)\nrfc = RandomForestClassifier(random_state=42,verbose=False).fit(x_train,y_train)\nxgbc = XGBClassifier().fit(x_train,y_train)\ncatbc = CatBoostClassifier(verbose=False).fit(x_train,y_train)","d59f7aa0":"model_names = [lr,gnb,knnc,dtc,rfc,xgbc,catbc]","9814d0f1":"for model in model_names:\n    name = model.__class__.__name__\n    predict = model.predict(x_test)\n    CV = cross_val_score(model,x_test,y_test,cv=10,verbose=False).mean()\n    error = -cross_val_score(model,x_test,y_test,cv=10,scoring=\"neg_mean_squared_error\",verbose=False).mean()\n    print(name + \": \")\n    print(\"-\" * 50)\n    print(\"Accuracy Score: \",accuracy_score(y_test,predict))\n    print(\"Cross Validation Score: \",CV)\n    print(\"Error: \",np.sqrt(error))\n    print(\"R-square value: \",r2_score(y_test,predict))\n    print(\"Confusion matrix: \")\n    print(confusion_matrix(y_test,predict))\n    print(\"-\" * 100)","6f8c6289":"df = pd.DataFrame(columns=[\"MODELS\",\"Accuracy\"])\nfor model in model_names:\n    name = model.__class__.__name__\n    predict = model.predict(x_test)\n    accuracy = accuracy_score(y_test,predict)\n    result = pd.DataFrame([[name,accuracy*100]],columns=[\"MODELS\",\"Accuracy\"])\n    df = df.append(result)\n    \nfigure = plt.figure(figsize=(20,8))   \nsns.barplot(x=\"Accuracy\",y=\"MODELS\",data=df,color=\"k\")\nplt.xlabel(\"ACCURACY\")\nplt.ylabel(\"MODELS\")\nplt.xlim(0,100)\nplt.title(\"MODEL ACCURACY COMPARISON\")\nplt.show()","6d424de4":"df = pd.DataFrame(columns=[\"MODELS\",\"CV\"])\nfor model in model_names:\n    name = model.__class__.__name__\n    CV = cross_val_score(model,x_test,y_test,cv=10,verbose=False).mean()\n    result = pd.DataFrame([[name,CV*100]],columns=[\"MODELS\",\"CV\"])\n    df = df.append(result)\n    \nfigure = plt.figure(figsize=(20,8))   \nsns.barplot(x=\"CV\",y=\"MODELS\",data=df,color=\"k\")\nplt.xlabel(\"CV\")\nplt.ylabel(\"MODELS\")\nplt.xlim(0,100)\nplt.title(\"MODEL CROSS VALIDATION COMPARISON\")\nplt.show()","22c3e04d":"r_prob = [0 for _ in range(len(y_test))]\nr_auc = roc_auc_score(y_test,r_prob)\n","c5f71b79":"for model in model_names:\n    name = model.__class__.__name__\n    predict = model.predict_proba(x_test)[:,1]\n    auroc_score = roc_auc_score(y_test,predict)\n    print(name+\" score: \",auroc_score)\n    print(\"-\"*50)","9bd9031f":"r_fpr,r_tpr,_= roc_curve(y_test,r_prob)\nmodel_dict={}\n\nfor model in model_names:\n    name = model.__class__.__name__\n    predict = model.predict_proba(x_test)[:,1]\n    fpr,tpr,_= roc_curve(y_test,predict)\n    model_dict[name]=[fpr,tpr]","16b115ac":"plt.figure(figsize=(15,8))\nplt.plot(r_fpr,r_tpr,linestyle=\"--\")\nplt.plot(model_dict[\"LogisticRegression\"][0],model_dict[\"LogisticRegression\"][1],linestyle='dotted', label=\"LogisticRegression\")\nplt.plot(model_dict[\"GaussianNB\"][0],model_dict[\"GaussianNB\"][1],linestyle='dotted',label=\"GaussianNB\")\nplt.plot(model_dict[\"KNeighborsClassifier\"][0],model_dict[\"KNeighborsClassifier\"][1],linestyle='dotted', label=\"KNeighborsClassifier\")\nplt.plot(model_dict[\"DecisionTreeClassifier\"][0],model_dict[\"DecisionTreeClassifier\"][1],linestyle='dotted', label=\"DecisionTreeClassifier\")\nplt.plot(model_dict[\"RandomForestClassifier\"][0],model_dict[\"RandomForestClassifier\"][1],linestyle='dotted', label=\"RandomForestClassifier\")\nplt.plot(model_dict[\"XGBClassifier\"][0],model_dict[\"XGBClassifier\"][1],linestyle='dotted', label=\"XGBClassifier\")\nplt.plot(model_dict[\"CatBoostClassifier\"][0],model_dict[\"CatBoostClassifier\"][1],linestyle='dotted', label=\"CatBoostClassifier\")\n\nplt.title(\"ROC plot\")\nplt.xlabel(\"False positive rate.\")\nplt.ylabel(\"True positive rate.\")\nplt.legend()\nplt.show()","b396a4fd":"### ROC Curve","8b5255b3":"#### 3. Renaming the columns","9b635237":"### 8. Stroke","b95ddcc0":"### 5. Work type","d4a3df09":"#### 2. Target guided encoding","51078b34":"### AUROC Score","6d1d6eec":"### 1. Count of gender","815a1f6b":"# ROC_ Curve and ROC_AUC_SCORE\n### Prediction Probabilities","8ef26887":"#### We have recorded some missing values in BMI category.","c7123801":"### 2. Handeling categorical values\n#### 1. One hot encoding","a69c2173":"##### Now since we have converted all the categorical values to numerical, now we should drop all those columns.","88d30e44":"### 3. Heart Disease","83cb4663":"# Data preprocessing","2d4d19c6":"# Data visualization\n## Count plots","f4fe7b89":"### Model Cross Validation Comparison","257d9a03":"### 2. Count of hypertension","f7e44b44":"## Outlier analysis","174b2251":"##### It is clearly visible that our data is completely balanced. Now let's join back the updated dataset","38c7bf06":"### Heart disease vs stroke","84bbf582":"### 2. Outlier Removal\nThere are otliers present in the bmi category. Now to remove we can use z-score or either we can use IQR (interquatile Ranege)\nI have used IQR for the removal of teh outliers.\n\n1. IQR = Q3-Q1\n2. upper_boundry = Q3+(1.5*IQR)\n3. Lower bound = Q1-(1.5*IQR)","53197cde":"### 2. Balancing the dataset\n\nWe can see at the data visualization that out target category(\"Stroke\") is highly imbalanced. So, before movig farther to remove the outliers first we should balance the dataset. It can be done by two methods.\n\n        --> 1. Under sampaling\n        --> 2. Oversampling\n\nWe will be using Oversampling i.e bringing the minority class equal to majority calss. For this purpous i will be using a very famous technique called Synthetic Minority Oversampling Technique or SMOTE.","9cc1e170":"### Residence type vs Stroke","3439a8c9":"### 7. Smoking type","2045c888":"### 4. Standardizing the data.","dbe6730f":"### Married type vs Stroke","db7edeec":"### Model Comparison","0d72e82a":"## Distplot","4a7b092b":"### Work type vs stroke","e4f2bff2":"### Smoking status vs Stroke","d14ac569":"### 4. Married status","2f3ffaa6":"## Relation between Categories and strock","9df80634":"## Model Building\n#### Classification Models","314ed8a0":"### 6. Residence type","4c67db71":"#### Train Test Splitting","9417535b":"### 1. Handling missing values","68143bee":"## Correlation","f0cbfdd5":"### Gender vs Stroke","18fc97c9":"### Hypertension vs stroke"}}