{"cell_type":{"dfc86b1c":"code","cc73222b":"code","523a6bcb":"code","29d1368e":"code","21eda70d":"code","7cca3be8":"code","a9c171b1":"code","aa28f8dd":"code","60bb0880":"code","c9637bed":"code","321324ca":"code","34539b4d":"code","61e69b1b":"code","df4a328e":"code","ec401c72":"code","f631d9b7":"code","ed5e9245":"code","09b18443":"code","7bc2ae7b":"code","51ef1a1b":"code","f969bf78":"code","79bf8373":"code","9ec1a2c0":"code","b88097ba":"code","ce43c32b":"code","4adf9199":"code","a5579c84":"code","978aa8b0":"code","a8ac7845":"code","82a23f60":"code","1741654d":"code","9cf3b8e3":"code","647f62c8":"code","d04fd9d5":"code","b697368c":"code","23d4f2a3":"code","fcfd57cb":"code","5d80f64b":"code","90246e8a":"code","8b6cfd94":"code","9f2ff026":"code","a6bb244d":"code","e065c77e":"code","226449d3":"code","c1955859":"code","27ed2e4d":"code","94045145":"code","f3af6eaf":"code","bfafcd54":"code","5e253206":"code","daba5599":"markdown","ae8164e9":"markdown","44afdff6":"markdown","bd79a8fe":"markdown","dcc09885":"markdown","86ef0603":"markdown","4453fcd0":"markdown","d4e1f4c3":"markdown","7f5b5791":"markdown","77b650c8":"markdown","18592063":"markdown","c3e511b5":"markdown","8a568e34":"markdown","7b664c49":"markdown","1bea9c9e":"markdown","b88bdbcf":"markdown","7768e37a":"markdown","b3e39fa5":"markdown","de59b71a":"markdown","3eaa1aee":"markdown","0d64dbb5":"markdown","bc1777de":"markdown","49ecdbcc":"markdown","64b9ce3f":"markdown","6af63b7a":"markdown","4c297e11":"markdown","0cc92928":"markdown","bd5baf90":"markdown","be48ae4b":"markdown","e0d04f87":"markdown","4dbebc6b":"markdown","d62adf94":"markdown","c658af62":"markdown","39627c00":"markdown","707069f8":"markdown","c14deda7":"markdown","c5ee9def":"markdown","b1c3eb23":"markdown","50e12cd7":"markdown","24ce2ef4":"markdown","88962733":"markdown","b8f0ac69":"markdown","8a9c4f88":"markdown","de680885":"markdown","c78a2745":"markdown","0634afd7":"markdown","aacb540a":"markdown","0b61abe1":"markdown","5cb0c2fe":"markdown","ff5c70d7":"markdown","163f74f6":"markdown","325d42ba":"markdown","dc88a5dd":"markdown","71317975":"markdown","9756c1b2":"markdown"},"source":{"dfc86b1c":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n# classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","cc73222b":"import warnings\n\nwarnings.filterwarnings('ignore')\npd.set_option('Display.max_columns', None)\nsns.set_style('darkgrid')\n%matplotlib inline\nsns.set()","523a6bcb":"data = pd.read_csv('train_data.csv', na_values='?').drop(0, axis = 0).reset_index(drop = True)","29d1368e":"data.columns=['Id', 'age', 'workclass', 'final_weight', 'education', 'education_num', 'marital_status',\n              'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week',\n              'native_country', 'income']","21eda70d":"data.head(3)","7cca3be8":"data.describe()","a9c171b1":"# 3 colunas apresentam valores nulos\n# diversas colunas num\u00e9ricas est\u00e3o apresentadas como strings\ndata.replace('?', np.nan, inplace=True)\ndata.info()","aa28f8dd":"def work_missing_values(data):\n    '''\n    Return new data with no missing values for this problem\n    '''\n    \n    aux = data.copy()\n    # select index of rows that workclass is nan\n    aux_index = aux[aux['workclass'].isna()].index\n    \n    # fill nan with 'unknown'\n    aux['workclass'].loc[aux_index] = 'unknown'\n    aux['occupation'].loc[aux_index] = 'unknown'\n    \n    # complete missing of native_country and occupation with most frequent\n    cols = ['native_country', 'occupation']\n    for col in cols:\n        top = aux[col].value_counts().index[0]\n        aux[col] = aux[col].fillna(top)\n    aux.reset_index(drop = True)\n    \n    return aux","60bb0880":"data = work_missing_values(data)","c9637bed":"%%time\nfor column in data.columns:\n    try:\n        data[columns] = pd.to_numeric(data[columns])\n    except:\n        None","321324ca":"# simple way to get numerical columns (not memory responsible)\nnum_cols = list(data.describe().columns)","34539b4d":"%%time\nsns.pairplot(data[num_cols+['income']], vars=num_cols, \n             hue='income', palette='bwr');","61e69b1b":"fig, ax = plt.subplots(figsize=(20,8))\nfor index, col in enumerate(num_cols[1:]):\n    #print(data[col].nunique())\n    g1 = data[data.income=='>50K'].groupby([col], as_index=False).agg({'income':'count'})\n    g2 = data[data.income=='<=50K'].groupby([col], as_index=False).agg({'income':'count'})\n    z = g1.merge(g2, on=col, how='outer', suffixes=('_high', '_low')).fillna(0)\n    z['income_high'] = LabelEncoder().fit_transform(z.income_high)\n    z['income_low'] = LabelEncoder().fit_transform(z.income_low)\n    plt.subplot(2,3,index+1)\n    plt.scatter(x=z[col], y=[1 for i in range(z.shape[0])], s=10*z.income_high, color='blue')\n    plt.scatter(x=z[col], y=[0 for i in range(z.shape[0])], s=10*z.income_low, color='red')\n    plt.title(col)","df4a328e":"categ_cols = ['workclass', 'education', 'marital_status', 'occupation',\n              'relationship','race', 'sex', 'native_country']","ec401c72":"def bar_plots(data, categ_cols):\n    fig, ax = plt.subplots(figsize=(20, 3*len(categ_cols)\/2))\n    for i, col in enumerate(categ_cols):\n        axi = plt.subplot(len(categ_cols)\/2, 2, i+1)\n        h = data[data.income=='>50K'][col].value_counts().reset_index()\n        l = data[data.income=='<=50K'][col].value_counts().reset_index()\n        aux = l.merge(h, on='index', how='left')\n        # normalized data\n        aux.iloc[:, 1:] = aux.iloc[:, 1:].div(aux.iloc[:, 1:].sum(axis=1), axis=0)\n        aux.plot(kind='bar', x='index', y=col+'_x', ax=axi)\n        aux.plot(kind='bar', x='index', y=col+'_y', color='firebrick', alpha=0.6, ax=axi)\n        plt.xticks(rotation=80);\n        plt.title(col)\n        plt.legend(['<=50K', ' >50K'])\n        plt.xlabel('')\n    plt.subplots_adjust(hspace = 1)","f631d9b7":"bar_plots(data, categ_cols[:4])","ed5e9245":"bar_plots(data, categ_cols[4:])","09b18443":"def box_plot(data, num_cols, var_x='income', orientation = 'v',\n             rotate_x_label = False):\n    \n    fig, ax = plt.subplots(figsize=(20, 3*len(num_cols)\/2))\n    for i, col in enumerate(num_cols[1:]):\n        axi = plt.subplot(len(num_cols)\/2, 2, i+1)\n\n        df = pd.concat([data[col], data[var_x]], axis=1)\n        sns.boxplot(x=var_x, y=col, data=df, ax=axi, notch = True, \n                    palette = 'Wistia', orient = orientation)\n        plt.title('{} distribution analysis'.format(col))\n        if rotate_x_label:\n            ax.set_xticklabels(data[var_x].unique(), rotation=90)\n    plt.subplots_adjust(hspace = 0.7)","7bc2ae7b":"box_plot(data, num_cols)","51ef1a1b":"col_names=['Id', 'age', 'workclass', 'final_weight', 'education', 'education_num', 'marital_status',\n           'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week',\n           'native_country', 'income']\n\ntest = pd.read_csv('test_data.csv', names = col_names[:-1]).drop(0, axis = 0).reset_index(drop = True)","f969bf78":"train = pd.read_csv('train_data.csv', names = col_names).drop(0, axis = 0).reset_index(drop = True)\n\ntrain.replace('?', 'unknown', inplace=True)\ntrain['native_country'] = train.native_country.apply(lambda x: 1 if x=='United-States' else 0)\ntrain['marital_status'] = train.marital_status.apply(lambda x: 1 if x in ['Married-civ-spouse' or 'Married-AF-spouse'] else 0)\ntrain['workclass'] = train.workclass.apply(lambda x: 2 if x=='Self-emp-inc' else (0 if x in ['Without-pay', 'Never-worked'] else 1))\ntrain['occupation'] = train.occupation.apply(lambda x: 2 if x in ['Exec-managerial', 'Prof-specialty'] else (0 if x =='Priv-house-serv' else 1))\ntrain['relationship'] = train.relationship.apply(lambda x: 1 if x in ['Husband', 'Wife'] else 0)\ncateg_features = ['race', 'sex', 'native_country']\nfor feature in categ_features:\n    train[feature] = LabelEncoder().fit_transform(train[feature])\nX_train, y_train = train[col_names[:-1]], train['income']\nX_train.drop(columns=['education', 'Id'], inplace=True)\nfor col in X_train.columns:\n    try:\n        X_train[col] = pd.to_numeric(X_train[col])\n    except:\n        None\nX_train = StandardScaler().fit_transform(X_train)","79bf8373":"test = pd.read_csv('test_data.csv', names = col_names).drop(0, axis = 0).reset_index(drop = True)\n\ntest.replace('?', 'unknown', inplace=True)\ntest['native_country'] = test.native_country.apply(lambda x: 1 if x=='United-States' else 0)\ntest['marital_status'] = test.marital_status.apply(lambda x: 1 if x in ['Married-civ-spouse' or 'Married-AF-spouse'] else 0)\ntest['workclass'] = test.workclass.apply(lambda x: 2 if x=='Self-emp-inc' else (0 if x in ['Without-pay', 'Never-worked'] else 1))\ntest['occupation'] = test.occupation.apply(lambda x: 2 if x in ['Exec-managerial', 'Prof-specialty'] else (0 if x =='Priv-house-serv' else 1))\ntest['relationship'] = test.relationship.apply(lambda x: 1 if x in ['Husband', 'Wife'] else 0)\ncateg_features = ['race', 'sex', 'native_country']\nfor feature in categ_features:\n    test[feature] = LabelEncoder().fit_transform(test[feature])\nX_test, y_test = test[col_names[:-1]], test['income']\nX_test.drop(columns=['education', 'Id'], inplace=True)\nfor col in X_test.columns:\n    try:\n        X_test[col] = pd.to_numeric(X_test[col])\n    except:\n        None\nX_test = StandardScaler().fit_transform(X_test)","9ec1a2c0":"def explanation_fn(estimator, instance):\n    '''\n    fixed function for lime explanation for estimator and given example instance\n    '''\n    explainer = lime.lime_tabular.LimeTabularExplainer(X_train, training_labels=y_train, \n                                                   feature_names=X_train.columns, categorical_features = [1,3,4,5,6,12], \n                                                   class_names = ['<=50K', '>50K'])\n\n    exp = explainer.explain_instance(X_test[instance], estimator.predict_proba, num_features=6, top_labels=None)\n    exp.show_in_notebook(show_table=True, show_all=False)","b88097ba":"def outputPrediction(ids, predictions):\n    data = pd.DataFrame({'Id': ids, 'income': predictions})\n    return data","ce43c32b":"%%time\ntime_train = [2000]\n\n# train\n\nLogClf = LogisticRegression(solver = 'lbfgs', C = 1.0, penalty = 'l2', warm_start =  True)\n\nLogCV = cross_val_score(LogClf, X_train, y_train, cv = 10)\n\nLogClf.fit(X_train, y_train)\n\ncv_accuracy = [LogCV.mean()]\ncv_std = [LogCV.std()]\n\ncv_values = {}\ncv_values['Lin'] = LogCV\nprint('Logistic Regression CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(LogCV.mean(), LogCV.std()))","4adf9199":"%%time\ntime_train.append(30500)\n\n# train\n\nKNNClf = KNeighborsClassifier(n_neighbors = 19, p = 1, weights = 'uniform')\n\nKNNCV = cross_val_score(KNNClf, X_train, y_train, cv = 10)\n\nKNNClf.fit(X_train, y_train)\n\ncv_accuracy.append(KNNCV.mean())\ncv_std.append(KNNCV.std())\ncv_values['KNN'] = KNNCV\nprint('K-Nearest Neighboors CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(KNNCV.mean(), KNNCV.std()))","a5579c84":"%%time\ntime_train.append(170000)\n\n# train\n\nRFClf = RandomForestClassifier(n_estimators = 750, max_depth = 12)\n\nRFCV = cross_val_score(RFClf, X_train, y_train, cv = 10)\n\nRFClf.fit(X_train, y_train)\n\ncv_accuracy.append(RFCV.mean())\ncv_std.append(RFCV.std())\ncv_values['RF'] = RFCV\nprint('Random Forest CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(RFCV.mean(), RFCV.std()))","978aa8b0":"%%time\ntime_train.append(60000)\n\n# train\nXGBClf = XGBClassifier(max_depth = 4, n_estimators = 250)\n\nXGBCV = cross_val_score(XGBClf, X_train, y_train, cv = 10)\n\nXGBClf.fit(X_train, y_train)\n\ncv_accuracy.append(XGBCV.mean())\ncv_std.append(XGBCV.std())\ncv_values['XGB'] = XGBCV\nprint('XGBoost CV accuracy: {0:1.4f} +-{1:2.5f}\\n'.format(XGBCV.mean(), XGBCV.std()))","a8ac7845":"y_pred = XGBClf.predict(X_test)","82a23f60":"test['income'] = y_pred\ntest['income'] = test['income'].replace({0:'<=50K', 1:'>50k'})\ntest[['Id', 'income']].to_csv('sample_submission_Adult.csv', index=False)","1741654d":"data = pd.read_csv('..\/Extra\/train.csv', na_values='?').reset_index(drop = True)","9cf3b8e3":"data.head()","647f62c8":"data.describe()","d04fd9d5":"data.replace('?', np.nan).info()","b697368c":"def plotMap(data, sizes = None, colors = None, cmap = 'Blues', alpha = 0.7, title = 'Mapa'):\n    '''\n    plot on cartesian plan, coordinatedes according to lat long, with circle sizes em color scale\n    '''\n    v_sizes, v_colors = None, None\n    if sizes is not None:\n        scaler = MinMaxScaler()\n        v_sizes = scaler.fit_transform(data[sizes].values.reshape(-1,1))*100\n        v_sizes = v_sizes.reshape(-1)\n        \n    if colors is not None:\n        v_colors = data[colors]\n        \n    with plt.style.context('seaborn-whitegrid'):\n        data.plot.scatter('longitude', 'latitude', s = v_sizes, figsize = (11,7), c = v_colors, cmap = cmap, alpha = alpha)\n        plt.title(title)","23d4f2a3":"plotMap(data, sizes = 'median_income', colors = 'median_house_value', title = 'Income and house value visualization map')","fcfd57cb":"plotMap(data, sizes = 'population', colors = 'median_age', title = 'Population and ages visualization map', alpha = 0.7)","5d80f64b":"plt.figure(figsize=(14,7))\nsns.distplot(data['median_income'], color = 'Red', bins = 20);","90246e8a":"plt.figure(figsize=(14,7))\nsns.distplot(data['total_rooms'], color = 'Red', bins = 200);","8b6cfd94":"plt.figure(figsize=(14,7))\nsns.distplot(data['median_house_value'], color = 'Red', bins = 20);","9f2ff026":"plt.figure(figsize=(14,7))\nsns.boxplot(x = data['median_age'], y = data['median_house_value'], palette = 'Reds')","a6bb244d":"from scipy import stats","e065c77e":"#Retirando outliers da base\ndata_clean = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n\n#Reindexando para ajustar termos faltantes\ndata_clean = data_clean.assign(index = list(range(0, data_clean.iloc[:,0].size)))\ndata_clean = data_clean.set_index('index')","226449d3":"selected_columns = ['longitude', 'median_income', 'median_age', 'population']\ntarget = 'median_house_value'\n\nselected_base = pd.concat([data_clean[selected_columns], data_clean[target]], axis = 1)","c1955859":"scaler = {}\nfor col in selected_columns:\n    scaler[col] = StandardScaler()\n    selected_base[col] = scaler[col].fit_transform(selected_base[col].values.reshape(-1,1))\n    \nscaler[target] = MinMaxScaler()\nselected_base[target] = scaler[target].fit_transform(selected_base[target].values.reshape(-1,1))","27ed2e4d":"X, y = selected_base[selected_columns].values, selected_base[target].values","94045145":"# metrica para avaliar os regressores\n\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\nmsle = make_scorer(mean_squared_log_error)","f3af6eaf":"%%time\ntime_train = [40]\n\n# train\n\nLinReg = LinearRegression()\n\nLinCV = cross_val_score(LinReg, X, y.reshape(-1), cv = 10, scoring = msle)\n\nLinReg.fit(X, y)\n\ncv_accuracy = [LinCV.mean()]\ncv_std = [LinCV.std()]\ncv_values = {}\ncv_values['Lin'] = LinCV\nprint('Linear Regression CV msle: {0:1.4f} +-{1:2.5f}\\n'.format(LinCV.mean(), LinCV.std()))","bfafcd54":"%%time\ntime_train.append(310)\n\n# train\n\nKNNReg = KNeighborsRegressor(n_neighbors=30)\n\nKNNCV = cross_val_score(KNNReg, X, y, cv = 10, scoring = msle)\n\nKNNReg.fit(X, y)\n\ncv_accuracy.append(KNNCV.mean())\ncv_std.append(KNNCV.std())\ncv_values['KNN'] = KNNCV\nprint('KNN Regression CV msle: {0:1.4f} +-{1:2.5f}\\n'.format(KNNCV.mean(), KNNCV.std()))","5e253206":"%%time\ntime_train.append(18700)\n\n# train\n\nRFReg = RandomForestRegressor(n_estimators = 50, max_depth = 14)\n\nRFCV = cross_val_score(RFReg, X, y.reshape(-1), cv = 10, scoring = msle)\n\nRFReg.fit(X, y.reshape(-1))\n\ncv_accuracy.append(RFCV.mean())\ncv_std.append(RFCV.std())\ncv_values['RF'] = RFCV\nprint('RF Regression CV msle: {0:1.4f} +-{1:2.5f}\\n'.format(RFCV.mean(), RFCV.std()))","daba5599":"# 1. Read Databases","ae8164e9":"### 6.5. XGBoost","44afdff6":"***","bd79a8fe":"### 2.3. Boxplots","dcc09885":"##### SW:\n##### capital_gain: The best finding of this section is related to capital gain. If capital gain is extremely high, then it is certainly a high income observation. \n##### capital_loss: The same line of reasoning can be applied to capital_loss.","86ef0603":"### 6.3. K-Nearest Neighboor","4453fcd0":"# 7. Output Prediction","d4e1f4c3":"### 3.3. Scaling","7f5b5791":"### 6.2. Logistic Regression","77b650c8":"# Extra - California Household Prices","18592063":"***","c3e511b5":"### 4.2. radius scatter plot","8a568e34":"***","7b664c49":"***","1bea9c9e":"***","b88bdbcf":"# 3. Deal with missing data","7768e37a":"***","b3e39fa5":"### 4.2. K-Nearest Neighboors Regressor\n","de59b71a":"                           Escola Polit\u00e9cnica da Universidade de S\u00e3o Paulo\n                                         Data: 07\/12\/2019\n#       PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n### Applying different classifiers on the *adult* database\n#### Author: Guilherme Dello Russo\n\nThis notebook used the notebook uploaded by the hash 56 as inspiration ","3eaa1aee":"***","0d64dbb5":"***","bc1777de":"***","49ecdbcc":"# 5. Data Prep","64b9ce3f":"### 4.1. General pairplot","6af63b7a":"***","4c297e11":"***","0cc92928":"# 2. EDA","bd5baf90":"### 4.3. Random Forest Regressor\n","be48ae4b":"# 6. Machine Learning Algorithms Testing","e0d04f87":"***","4dbebc6b":"***","d62adf94":"***","c658af62":"### 6.4. Random Forest","39627c00":"##### SW:\n##### relationship: the best kind of relationship to have a high income is husband and wife, while Own-child is the worst one\n##### race: black and amer-indian-eskimo people are less well paid, while white and asian-pac-islander are better. Probably because of racism.\n##### sex: male people are better paid on average. probably because of social sexism\n##### native_country: there is no clear relationship between the native_country and the income as it would be expected. 1st world countrys doesn't seem to have an average high income while 3rd ones doesn't seem to have a lower one\n","707069f8":"# 4.4. Boxplot - distribution analysis","c14deda7":"***","c5ee9def":"##### Sw:\n##### workclass: without-pay and never-worked certainly receives an income lower than 50k. Also the better paid profession is the self-emp-inc\n##### education: up to the 11th grade shows a really low income, while after bachelors shows a really high one\n##### marital-status: only two types shows a high average income: married-AF-spouse and Married-civ-spouse\n##### occupation: Exec-managerial and Prof-specialty are high income occupations, while Priv-house-serv is a low income one","b1c3eb23":"***","50e12cd7":"# 4. Testing regressors","24ce2ef4":"##### SW: age, hours_per_week and education_num seems to be the be the most significant to determine income","88962733":"***","b8f0ac69":"##### SW: as seen before, the same kind of conclusions can be taken\n##### education_num: more education implies better paygrade\n##### hours_per_week: more hours per week implies better paygrade\n##### capital_gain positive outliers implies better paygrades","8a9c4f88":"### 4.1. Linear Regressor","de680885":"## 1. Import libraries","c78a2745":"***","0634afd7":"# 4.3. Barplots","aacb540a":"### 6.1. Model Comprehension","0b61abe1":"# 3. Data Cleaning","5cb0c2fe":"***","ff5c70d7":"### 2.1. Geoviews","163f74f6":"# 4. EDA","325d42ba":"### 3.1. Outliers","dc88a5dd":"### 3.2. Train base","71317975":"### 2.2. Distplots","9756c1b2":"# 2. Import databases"}}