{"cell_type":{"859110f8":"code","1648a81a":"code","771ca406":"code","3bc42655":"code","5552d6b0":"code","48e788b7":"code","c55e8b4a":"code","2e775bfe":"code","464ec86c":"code","178b7c17":"code","a6302672":"code","85c2a471":"code","cf342e83":"code","9e59451f":"code","85813f28":"code","99f2ecc6":"code","189e230d":"code","cd21b30d":"code","f0fcf387":"code","c420e482":"markdown","1cf87bb0":"markdown"},"source":{"859110f8":"PATH = '\/kaggle\/input\/petfinder-pawpularity-score'\n\nimport os\npath_img_train = os.path.join(PATH, 'train')\npath_img_test = os.path.join(PATH, 'test')\npath_train = os.path.join(PATH, 'train.csv')\npath_test = os.path.join(PATH, 'test.csv')\npath_submission = os.path.join(PATH, 'sample_submission.csv')","1648a81a":"import pandas as pd\ndf_train = pd.read_csv(path_train)\ndf_test = pd.read_csv(path_test)\ndf_train.head()","771ca406":"X_train_df = df_train.drop(['Id', 'Pawpularity'], axis=1).values.astype('float32')\ny_train = df_train['Pawpularity'].values.astype('float32')\n\nX_test_df = df_test.drop(['Id'], axis=1).values.astype('float32')","3bc42655":"import numpy as np\nfrom tensorflow import keras\nimport tensorflow as tf\ndef load_images_data(img_paths, input_shape=(150, 150)):\n    images = np.zeros((len(img_paths), input_shape[0], input_shape[1], 3))\n    for i, img_path in enumerate(img_paths):\n        img = keras.preprocessing.image.load_img(img_path, target_size=input_shape)\n        img = keras.preprocessing.image.img_to_array(img)\n        images[i] = img\n    return images\n\nimg_train_paths = df_train['Id'].apply(lambda x: os.path.join(path_img_train, x) + '.jpg')\nimg_test_paths = df_test['Id'].apply(lambda x: os.path.join(path_img_test, x) + '.jpg')\n\nimages_train = load_images_data(img_train_paths)\nimages_test = load_images_data(img_test_paths)\n","5552d6b0":"images_train = images_train \/ 255.0\nimages_test = images_test \/ 255.0","48e788b7":"base_model = keras.applications.VGG16(\n    include_top=False,\n    weights=None\n)\nbase_model.summary()","c55e8b4a":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n","2e775bfe":"def make_model_1():\n    base_model = keras.applications.VGG16(\n        include_top=False,\n        weights=None\n    )\n    \n    # instantiating the model in the strategy scope creates the model on the TPU\n    df_input = keras.layers.Input(shape=(X_train_df.shape[1],), dtype='float32', name='df')\n    dense_1 = keras.layers.Dense(10, activation='relu')(df_input)\n    dense_2 = keras.layers.Dense(5, activation='relu')(dense_1)\n    \n    image_input = keras.layers.Input(shape=(150,150,3), dtype='float32', name='image_input')\n    x = base_model(image_input)\n\n    x = keras.layers.Flatten()(x)\n    \n    concat = keras.layers.concatenate([dense_2, x], axis=-1)\n    y = keras.layers.Dense(256, activation='linear')(concat)\n    out_put = keras.layers.Dense(1, activation='linear')(y)\n    \n    model = keras.models.Model([df_input, image_input], out_put)\n    return model","464ec86c":"from tensorflow.keras import backend as K\n\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true))) \nwith tpu_strategy.scope():\n    model_1 = make_model_1()\n    model_1.compile(optimizer = keras.optimizers.RMSprop(lr=0.001), loss = root_mean_squared_error, \n                    metrics =[\"mse\"])\n\nmy_callbacks = [\n    keras.callbacks.EarlyStopping(patience=10)\n]\n\nmodel_1.fit([X_train_df, images_train], y_train, epochs=100, batch_size=128, steps_per_epoch=32, validation_split=0.2, callbacks=my_callbacks)","178b7c17":"pred_2nn = model_1.predict([X_test_df, images_test])","a6302672":"# from tensorflow import keras\n\n\n# def make_model():\n#     df_input = keras.layers.Input(shape=(X_train_df.shape[1],), dtype='float32', name='df')\n#     dense_1 = keras.layers.Dense(10, activation='relu')(df_input)\n#     dense_2 = keras.layers.Dense(5, activation='relu')(dense_1)\n    \n#     image_input = keras.layers.Input(shape=(150,150,3), dtype='float32', name='image_input')\n#     x = keras.layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n#     x = keras.layers.MaxPooling2D((2, 2))(x)\n#     x = keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n#     x = keras.layers.MaxPooling2D((2, 2))(x)\n#     x = keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n#     x = keras.layers.MaxPooling2D((2, 2))(x)\n#     x = keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n#     x = keras.layers.MaxPooling2D((2, 2))(x)\n\n#     x = keras.layers.Flatten()(x)\n    \n#     concat = keras.layers.concatenate([dense_2, x], axis=-1)\n#     y = keras.layers.Dense(256, activation='linear')(concat)\n#     out_put = keras.layers.Dense(1, activation='linear')(y)\n    \n#     model = keras.models.Model([df_input, image_input], out_put)\n#     return model\n\n# model = make_model()","85c2a471":"# from tensorflow.keras import backend as K\n# def root_mean_squared_error(y_true, y_pred):\n#         return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\n# model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, \n#               metrics =[\"mse\"])\n\n# my_callbacks = [\n#     keras.callbacks.EarlyStopping(patience=5)\n# ]\n\n# model.fit([X_train_df, images_train], y_train, epochs=100, validation_split=0.2, callbacks=my_callbacks)","cf342e83":"# pred1 = model.predict([X_test_df, images_test])\n# pred1","9e59451f":"import xgboost\nfrom sklearn.model_selection import RandomizedSearchCV\nimport time\n\nxgb_model = xgboost.XGBRegressor(n_estimators=100, eta=0.3, learning_rate=0.05)\nparams = {\n    'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n}\nxgb_model.fit(X_train_df, y_train)\npred_xgb = xgb_model.predict(X_test_df)","85813f28":"import lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV\nimport time\n\n\nlgb_model = lgb.LGBMRegressor(learning_rate=0.001, n_estimators=300)\nlgb_model.fit(X_train_df, y_train)\npred_lgb = lgb_model.predict(X_test_df)\n# # A parameter grid for XGBoost\n# params = {\n#     'n_estimators':[100, 200, 300, 500, 750],\n#     'learning_rate':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5], \n# }\n\n# reg = lgb.LGBMRegressor(nthread=-1)\n\n# # run randomized search\n# n_iter_search = 100\n# random_search = RandomizedSearchCV(reg, param_distributions=params,\n#                                    n_iter=n_iter_search, cv=5, iid=False, scoring='neg_root_mean_squared_error')\n\n# start = time.time()\n# random_search.fit(X_train_df, y_train)\n# print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n#       \" parameter settings.\" % ((time.time() - start), n_iter_search))\n\n# print(random_search.best_estimator_)\n# print(random_search.best_score_)","99f2ecc6":"pred_2nn","189e230d":"pred_lgb","cd21b30d":"pred_xgb","f0fcf387":"pred = (pred_2nn.reshape(-1) + pred_lgb.reshape(-1) + pred_xgb.reshape(-1))\/3\nimport pandas as pd\nsubmission = pd.read_csv(path_submission)\nsubmission['Pawpularity'] = pred\nsubmission.to_csv('submission.csv', index=False)","c420e482":"## Xgboost for tableau data","1cf87bb0":"## LightGBM"}}