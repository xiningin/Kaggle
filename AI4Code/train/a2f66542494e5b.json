{"cell_type":{"ad86690a":"code","d4b59a90":"code","0f46145e":"code","9adadc81":"code","27f9cc4c":"code","8601c4f6":"code","d41500e4":"code","755854c8":"code","67d26877":"code","bd4b277f":"code","1e7c3ad0":"code","60f8f023":"code","9f7bacb9":"code","d37b901d":"code","a416e89f":"code","8659d384":"code","771c5a25":"code","bc294a50":"code","eee65e80":"code","f23b234c":"code","272b375f":"code","efd24bf0":"code","c0fd4356":"code","ecc45fc7":"code","dca1053e":"code","72e66b2b":"code","43683fcc":"code","fea87a92":"code","cf538021":"code","82128283":"code","86135083":"code","78748af1":"code","78314324":"code","594b7302":"code","99e40756":"code","5503a769":"code","5e8611a9":"code","7aaaf07a":"code","1092419f":"code","8d4991c2":"code","72e7870d":"code","7ccffd20":"code","c2998c2e":"code","8c912218":"code","747cda97":"code","df1633dc":"code","06772243":"code","6c7c406f":"code","da9e116a":"code","6348372e":"code","f4a8330b":"code","7756cc7b":"code","8ce7bab9":"code","5492007d":"code","c01fabed":"code","7fd0b683":"code","341ba135":"code","71bf6155":"code","ccc0b433":"code","f090d29f":"code","a4140aa4":"code","bf26d493":"code","fb896b6e":"code","b6aa613b":"code","5fe02b78":"code","c54eb035":"code","fb9832a1":"code","b800873c":"code","53d56fd3":"code","c10bd3ed":"markdown","b76d6768":"markdown","4014a060":"markdown","76a004ff":"markdown","b44a1420":"markdown","3f2a4bd3":"markdown","b545ab53":"markdown","ccad380b":"markdown","9c993782":"markdown","ac8d5d46":"markdown","d3ad708a":"markdown","48dd6b8c":"markdown","ebe58ca8":"markdown","a1e6ad82":"markdown","3e3e61d9":"markdown","a216589a":"markdown","1f14e4fe":"markdown","6c704617":"markdown","22121f90":"markdown","ef307b7a":"markdown","b30a8dc5":"markdown","1fd3800f":"markdown","183f7ed7":"markdown","defb41c5":"markdown","1dc3284f":"markdown","5cd82554":"markdown","1d2fdbbf":"markdown","45e08daa":"markdown","dc0fccd8":"markdown","855dab5e":"markdown","07eb06dd":"markdown","887b81df":"markdown","3b8a34fa":"markdown","e1a59193":"markdown","ad1f14f8":"markdown","6eba23f5":"markdown","c4d5b4c6":"markdown","68689d8b":"markdown","0423da5c":"markdown","6395605e":"markdown","edb3f9c1":"markdown","d4ec7e45":"markdown","f4b70609":"markdown","8418f6ed":"markdown","78fe9f08":"markdown","881b8d32":"markdown","79414ea8":"markdown","cf837737":"markdown","94b8a451":"markdown"},"source":{"ad86690a":"# Importing necessary packages\nimport pandas as pd\npd.set_option('display.float_format', lambda x: '%.3f' % x) #Set the pandas display format to suppress scientific notation\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","d4b59a90":"# Defining dataset\nksdf = pd.read_csv('..\/input\/ks_projects2.csv')","0f46145e":"# Data has 378661 observations, and 15 variables\nksdf.shape\n","9adadc81":"# Viewing the first five rows of dataset\nksdf.head()","27f9cc4c":"# Describing the data set \nksdf.describe()","8601c4f6":"# Here we have more insights about data types and how many observations do we have for each variable\nksdf.info()","d41500e4":"# Here, we checked how many unique values are in categories and subcategories to use them later for the clustering\nksdf['main_category'].unique()","755854c8":"#Describe the unive values for different statuses of projects\nksdf['state'].unique()","67d26877":"ksdf['state'].value_counts(normalize = True)\n","bd4b277f":"# Remove all the rows where the state is undefined - we can't use them for the further predictions.\nksdf = ksdf[ksdf.state != 'undefined']","1e7c3ad0":"# A significant number of projects are still ongoing, as the numbers for these projects cannot be used for predictions.\nksdf = ksdf[ksdf.state != 'live']","60f8f023":"cleanup_nums = {\"state\":{\"failed\": 0, \"canceled\": 0, \"suspended\" :0, \"successful\" : 1, \"live\" : 1}}\nksdf[\"org_state\"] = ksdf[\"state\"]\nksdf.replace(cleanup_nums, inplace=True)\nksdf.head()","9f7bacb9":"ksdf['category'].unique()","d37b901d":"# We checked which currencies were the funds collected in, even though we will only use the converted values in USD for our analysis\nksdf['currency'].unique()","a416e89f":"ksdf.describe()","8659d384":"# We have also checked the missing values for each variable - it turns out that 4 projects don't have the name column filled in \n# There are 234 missing observations for USD_pledged column, so we can just drop this variable and use \"usd_pledged_real\" instead\nksdf.isnull().sum()","771c5a25":"#drop the category column\nksdf.drop(['category'], axis='columns', inplace=True)\n\n#As the 'usd' pleged' has a lot of NaN and null - we drop it\nksdf.drop(['usd pledged'], axis='columns', inplace=True)\n\n#drop the goal column\nksdf.drop(['goal'], axis='columns', inplace=True)\n\n#we don't need the ID\nksdf.drop(['ID'], axis='columns', inplace=True)","bc294a50":"#Presenting the data set after the variables drop. \nksdf.head()","eee65e80":"# First we need to convert the two columns including dates of launching projects and their deadlines to the right type\nksdf['deadline2'] = pd.to_datetime(ksdf['deadline'])\nksdf['launched2'] = pd.to_datetime(ksdf['launched'])\n","f23b234c":"  # Here, we created new column 'days' including the counts between launch dates and projects deadlines\n  ksdf['days'] = np.busday_count(pd.to_datetime(ksdf['launched2']).values.astype('datetime64[D]'), \\\n            pd.to_datetime(ksdf['deadline2']).values.astype('datetime64[D]'))","272b375f":"# We wanted to check what is the dates range and how much does it vary between different projects\n# From the maximum value of days, we figured out that the number is too high and probably some launch dates or deadlines are wrong, \n# as it seems from the mean value - most projects have rather short terms to collect funds\nksdf.describe()","efd24bf0":"#Remove all the projects that start in 1970 - it is obviously not correct\nksdf = ksdf[ksdf['launched2'].dt.year != 1970]\n","c0fd4356":"# After our cleaning, dataset still has 15 variables but the number of observations reduced to 372293\nksdf.shape","ecc45fc7":"\nsns.barplot(x=ksdf.org_state.value_counts().index, y=ksdf.org_state.value_counts())","dca1053e":"# Distribution of projectstates in different categories \nmy_temp_dataset = ksdf[ksdf.org_state == \"successful\"]\n\nax = sns.barplot(x=my_temp_dataset.main_category.value_counts().index, y=my_temp_dataset.main_category.value_counts())\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)","72e66b2b":"succesful_projects = pd.concat([ksdf.main_category.value_counts(), my_temp_dataset.main_category.value_counts()], axis=1)\n\nsuccesful_projects.columns.values[0] = \"total\"\nsuccesful_projects.columns.values[1] = \"succesful\"\nsuccesful_projects.sort_values(by='total')\n\nsuccesful_projects.plot(kind='bar', color=['#597DBE', '#A0C7F1'])","43683fcc":"# And now adding the hue function to see how distribution of succesfull and unsuccesfull projects across categories\nax = sns.barplot(x=\"main_category\", y=\"backers\", hue=\"state\", data=ksdf)\nax.set_xticklabels(ax.get_xticklabels(),rotation=30)","fea87a92":"#The following graph presents the average amount of backers from projects for each country \nax = sns.barplot(x=\"country\", y=\"backers\", data=ksdf)","cf538021":"my_cheap_projects = ksdf[ksdf.usd_goal_real <= 10000]\nvar = 'usd_goal_real'\ndata = pd.concat([my_cheap_projects['usd_pledged_real'], my_cheap_projects[var]], axis=1)\nmy_plot = data.plot.scatter(x=var,  y='usd_pledged_real');","82128283":"ksdf.corr()","86135083":"ksdf['main_category'].unique()","78748af1":"# We create a dataframe that only contains these columns\nksdf_clustering = ksdf[['state','backers','days','main_category','usd_pledged_real']]","78314324":"# To recode these we can use mapping\nmapping = {'Publishing' : 1, 'Film & Video' : 2, 'Music' : 3, 'Food' : 4, 'Design' : 5, 'Crafts' : 6, 'Games' : 7, 'Comics' : 8, 'Fashion' : 9, 'Theater': 10, 'Art' : 11, 'Photography' : 12,'Technology' : 13, 'Dance' : 14, 'Journalism' :15}","594b7302":"# Using mapping to recode to nummerical values\n# don't worry about the warning\nksdf_clustering['main_category'] = ksdf_clustering['main_category'].map(mapping)\n","99e40756":"# we can see that is was recoded to numerical values between 1 and 15\nksdf_clustering.describe()","5503a769":"z = ksdf_clustering.iloc[:,0:5]","5e8611a9":"# Feature scaling to transform each feature to have mean 0 and variance 1\n# we need to do it because our variables have different distributions and spreads\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nz = scaler.fit_transform(z)","7aaaf07a":"# Now for the clustering we need to import Scikit-Learn\n# We import KMeans and create a model object (let's for now assume there are 3 clusters)\n\nfrom sklearn.cluster import KMeans\nmodel = KMeans(n_clusters = 3)","1092419f":"# Now we can fit the clustering model\nmodel.fit(z)","8d4991c2":"# To find out which projects belong in which category\n\nksdf_clustering['cluster'] = model.labels_","72e7870d":"# Let's check out if there are actually projects in 3rd cluster \nksdf_clustering[ksdf_clustering['cluster'] == 2]","7ccffd20":"# the summary of our clustering\nksdf_clustering.info()","c2998c2e":"!pip install -u seaborn","8c912218":"# This code is optional if you want to visualize the clustering without further packages) \n# PCA will transform your 5 dimensions into 2, which can be used as X and Y coordinates\n# for a Scatterplot\n\n### ADVANCED CODE ####\nfrom sklearn.decomposition import PCA\npca = PCA()\nvisualization = pca.fit_transform(z)\nlabels = model.labels_\n\nplt.scatter(visualization[:,0],visualization[:,1], c = labels)\nplt.show()\n\n\n","747cda97":"# Let's check if there's any relation between clusters and the number of backers\nbackers = ksdf.backers\ngroups = pd.DataFrame({'cluster': labels, 'backers': backers})\nct = pd.crosstab(groups['cluster'], groups['backers'])\nprint(ct)","df1633dc":"# Here we create some vector to store our results for later\nresults = [0,0,0] ","06772243":"# First we create a variable containing only the nummerical values\nonly_nummerical = ksdf.iloc[:,7:]\nonly_nummerical.drop(['country'], axis='columns', inplace=True)\nonly_nummerical.drop(['deadline2'], axis='columns', inplace=True)\nonly_nummerical.drop(['launched2'], axis='columns', inplace=True)\nonly_nummerical.drop(['org_state'], axis='columns', inplace=True)\nonly_nummerical.head()","6c7c406f":"y = ksdf.iloc[:,11:12]","da9e116a":"# Import encoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode the labels to numbers\nlabelencoder_y = LabelEncoder()\ny = labelencoder_y.fit_transform(y)","6348372e":"# Scaling nummerical data\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX = scaler.fit_transform(only_nummerical)","f4a8330b":"# We can check our transform data using pandas describe\npd.DataFrame(X).describe()","7756cc7b":"# Splitting the dataset into the Training set and Test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)","8ce7bab9":"# We first import and train a Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression(random_state = 22)\n\nclassifier.fit(X_train, y_train)\n\n\n# After training the model we should jump further down (over the next 2 models)\n# To evaluate the results","5492007d":"from sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)\n\nprint(accuracies.mean())\nprint(accuracies.std())\nresults[0] = classifier.score(X_test, y_test)\nprint(results[0])","c01fabed":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n# Making a classification report\nfrom sklearn.metrics import classification_report\n\ncm = classification_report(y_test, y_pred)\nprint(cm)","7fd0b683":"# Transforming nummerical labels to original state types\n\ntrue_projects = labelencoder_y.inverse_transform(y_test)\n\npredicted_projects = labelencoder_y.inverse_transform(y_pred)","341ba135":"# Creating a pandas DataFrame and cross-tabulation\n\ndf = pd.DataFrame({'true_projects': true_projects, 'predicted_projects': predicted_projects}) \n\npd.crosstab(df.true_projects, df.predicted_projects)","71bf6155":"# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 22)\n\nclassifier.fit(X_train, y_train)","ccc0b433":"# Predicting the test set results from the test-set inputs\ny_pred = classifier.predict(X_test)","f090d29f":"# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)\n\n\n","a4140aa4":"print(accuracies.mean())\nprint(accuracies.std())\nresults[1] = classifier.score(X_test, y_test)\nprint(results[1])","bf26d493":"# Transforming nummerical labels to project statuses\n\ntrue_projects = labelencoder_y.inverse_transform(y_test)\n\npredicted_projects = labelencoder_y.inverse_transform(y_pred)","fb896b6e":"# Creating a pandas DataFrame and cross-tabulation\n\ndf = pd.DataFrame({'true_projects': true_projects, 'predicted_projects': predicted_projects}) \n\npd.crosstab(df.true_projects, df.predicted_projects)","b6aa613b":"# Finally we train a GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nclassifier = GradientBoostingClassifier(random_state=1000)\nclassifier.fit(X_train, y_train)","5fe02b78":"from sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)\n\nprint(accuracies.mean())\nprint(accuracies.std())\nresults[2] = classifier.score(X_test, y_test)\nprint(results[2])","c54eb035":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n# Making a classification report\nfrom sklearn.metrics import classification_report\n\ncm = classification_report(y_test, y_pred)\nprint(cm)","fb9832a1":"# Transforming nummerical labels to status types\n\ntrue_projects = labelencoder_y.inverse_transform(y_test)\n\npredicted_projects = labelencoder_y.inverse_transform(y_pred)","b800873c":"# Creating a pandas DataFrame and cross-tabulation\n\ndf = pd.DataFrame({'true_projects': true_projects, 'predicted_projects': predicted_projects}) \n\npd.crosstab(df.true_projects, df.predicted_projects)","53d56fd3":"my_data = pd.DataFrame({'cat': ['Logistic regresion', 'Random forest', 'Gradient Bosting Clasifier'], 'val': [results[0], results[1], results[2]]})\nax = sns.barplot(x = 'val', y = 'cat', \n              data = my_data, \n              color = '#10DF6B')\nax.set(xlabel='Performance of catagorical models', ylabel='models')\nplt.show()","c10bd3ed":"### And the best model is ... *Drumroll* ... GradientBoostingClassifier\n\nwe have made a graph to show how the different models compare.\nAs we can see the GradientBoostingClassifier is the one with the best performance on the test sets - with an accuracy of 88.3 % which is very good and sufficient to answer our research question. \n","b76d6768":"#Clustering\n","4014a060":"We want to know what are the statuses of projects and how many of them belong to each group.\n\nWe have found out that there are only 0,9% of **'undefined'** and, as we are not sure whether they succeed or not and what was the reason for that,  we decided to drop those observations, the same situation is with the **'live'** values - we understood that the projects are somehow ongoing, therefore it wouldn't be possible to analyze if it was a successful project or not","76a004ff":"### Problem formulation:\nWorking with a dataset of 'Kickstarter' projects we would like to analyze patterns between the projects, to predict which projects are succesfully funded, based on their characteristics. This information could be used to see if the projects are meeting the financial goals that they need to succeed and if a project is on track to being funded or failed.\n\n### Introduction:\n'Kickstarter' is a corporation maintaining crowdfunding for primarily creative and merchandising projects. The mission of the company is to \"Help bring creative projects to life\" and thus 150,836 projects has been funded since the company launch in 2009.\n\n### About the data:\n\n\n*   Retrieved from Kaggle.com\n*   The data was likely scraped from kickstarter.com in January 2018 by the author of the project on Kaggle as he has not been affiliated with kickstarter at any point on his LinkedIn\n*    As the data is \"second hand\" it also means there is allot of information we don't have, like how many times were each project visited by a kickstarter user etc. \n*   Consists of 15 variables with 378661 observations\n\n","b44a1420":"### 1. The distribution of project states\nOur goal with this exploration is to get an idea of how many projects actually succeed compared to the rest of the project states, which we to some extent, consider unsuccessful. In the graph bellow we can see that most projects fail to reach their goal and many are canecled. A good number of projects are successful though. ","3f2a4bd3":"So now that we gained an understanding of how the backers spread across categories, lets just for giggles see how they spread across countries. Maybe this will tell the creators where they need push their idea.","b545ab53":"One of the models that we can use is the Logistic Regression model. Lets see how it performs.\nFirst we train the model","ccad380b":"# Data Preparation\n\nIn order to make the process easier for everyone we stored the data on an external webserver that we own. Then we don't have to bother with the keggle API. This may not work on windows machines.\n\nThe data is split into two parts - we only use the second part (ks_projects2.csv) as it contains the most infromation to work with","9c993782":"# Working with dates","ac8d5d46":"# Predicting successful 'Kickstarter' Projects","d3ad708a":"# Supervised Machine Learning","48dd6b8c":"There's no any clear pattern, we can see from the cross tabulation that:\n- the biggest numbers of backers were classified to the third cluster (number 2 in Python)\n- the smallest numbers of backers are mostly classified in the second cluster (number 1 in Python) but also many observations fall into the first one\n","ebe58ca8":"### LogisticRegression","a1e6ad82":"# Exploratory Data Analysis","3e3e61d9":"Next we have to scale the data so that it all of equal importance in the model","a216589a":"### Random Forest Classifier model\n\nNOTE: This takes ~4 minuttes to run","1f14e4fe":"Hmm we seem to have some uncertainty or variation in our data judging by the error bars. But apart from that we can see that countries like Hong Kong and Singapore have projects with a high number of backers. Others like Mexico and Norway have fever backers on average. \n\n![alt text](https:\/\/78.media.tumblr.com\/1c64224112b9ca2412941cf5b69957aa\/tumblr_n2swrnPQUZ1tq4of6o1_400.gif)","6c704617":"First we create a copy of our data, where we use only the numberical collums to use in our clasification model. These are the values we will use to predict our *y* value.\n","22121f90":"### Gradient Boosting Classifier\nAnother method is the support vector classifier model - the results of this models is:\n\nNOTE: This takes a long ass time (>4 minutes)","ef307b7a":"# Unsupervised Machine Learning","b30a8dc5":"When analyzing the results in the crosstabulation we can se that especially the predicted *failed* projects creates disturbance as these should fall into mainly the *canceled* or *successful* column. As we are not satisfied with this level of accuracy, let's try with the more complex model *Random Forest*.","1fd3800f":"This model seams to suffer from some of the same issues as the RandomForest, however the accuracy on the test set is slightly higher with 88.3 %. This is the most accuracte model in our set","183f7ed7":"Now we would like to explore the distirbution of successful projects across categories. This will tell us which categories of projects are more likely to succeed in receiving the necessary funding. First, lets visualize it in a simple bar chart.","defb41c5":"We can see that the mean number of people supporting each project (**backers**) was 106 with the minimum value of 0 supporters for failed projects and maximum of 219382, the standard deviation was pretty big - 907 supporters\nThe other interesting variable is the **pledged amount in USD** with mean value of 9056 USD and standard deviation  of 90973 USD, which is probably caused by the very high maximum value\n\nSimilar pattern in data is for the **goals** of kickstarter projects, the mean value is around 45454USD with very high maximum value and big standard deviation","1dc3284f":"Based on the graph we can see that a lot of projects are centered around the 10000 USD and 5000 USD line. We can also see that there is a significant number of projects that don't achieve any significant funding (however the x- axis has a very big interval). Based on this plot we can say that a few projects really take off but most don't. ","5cd82554":"Even though the above-mentioned categories (*music*, *film* and *video)* had the highest number of succeeded projects, we can now see that they also have the highest numbers of failed projects. So now we know that the success rate is not as much a question about the categories being \"safer investments\" as they are simply the ones that are most popular in terms of types of projects.","1d2fdbbf":"In the following step, we will change the categorical values to some numbers we can work with later. As we want to simplify the later work, we will eliminate any doubt between if a project is funded or not. So we change all the catagories to either funded or not funded.\n\nwe change the following to funded (value of 1):\n*   Succesful\n\nwe change the following to unsuccesfull (value of 0)\n\n*   Failed\n*   Canceled\n*   Suspended\n\n\n","45e08daa":"Then we evaluate the model 5 times and take the \n\n\n*   Accuracy on the traning set (should be as high as posible)\n*   Standard deviation (should be as low as posible)\n*   Accuracy on the test set (should be as high as posible)\n\nwe store the accuracy on the model for later","dc0fccd8":"### 2. Number of successful projects in each category of projects","855dab5e":"So it seems that there are more projects with the topic of *music*, *film* and *video* that are succesful than those in *dance*, *crafts* and *journalism*. But this does not really provide a full picture since we left out the failed projects. So lets include those.","07eb06dd":"# Time for a big fall (data) cleaning \nWe can see that the dataset consists of project IDs and names, main categories and subcategories of projects, currency in which the fund was collected, dates of the launch and deadline for collecting the funds, how much money was pledged and what was the goal, if the fundraising was successful or failed, the amount of people supporting the project, country of the project and the amounts of money pledged (USD_pledged is the currency convertion made by kickstarter and the real value is based on some financial institution) and goal amount converted to USD dollars.\n\n\nIn the process of cleaning the data we will also explore some parts of it.\n\n\n","887b81df":"### 3. How do the backers spread across the categories of projects","3b8a34fa":"### 4. The relationship between funding goals and actual received fundings (in USD) \n\nWe want to explore the funding goal that the projects have and their actual received funding. So we compare their goal to their received funding. In order to get a plot that we are able to interpret, we will only look at the projects with a goal of less than 10000 USD.  ","e1a59193":"### This ID, what do we use it for?\nNothing - lets drop it","ad1f14f8":"### So many categories\nwe check the amount of unique values in the category column. As we can see, there are many unique variables, it would make it difficult to work with the dataset with so many catagories and they don't add any value. So we will just drop this column.","6eba23f5":"In general we can say that all the models have a hard time distingushing between failed and canceled projects. However, the accuracy of the prediction is very good and we have answered our problem formulation.\n\nBut if the models were to be included in a predictive manner, some additional work would needed to be done,  as they are based exclusively on the projects that are completed already.\n\n\n![alt text](https:\/\/www.lipstiq.com\/wp-content\/uploads\/2017\/07\/mic-drop-gif-7.gif)","c4d5b4c6":"So with this model the accuracy went from 74% to 87% which is an appreciable increase. This time the predicted *canceled* projects created the most disturbance as 1446 *failed* projects were incorrectly predicted here as. Though we are satisfied with the level of accuracy for this particular purpose we will go on to try with a third model *Gradient Boosting Classifier*.","68689d8b":"### Drop the columns like their hot\nNow we have explained why we want drop, now we drop them.\n\n![alt text](https:\/\/media1.tenor.com\/images\/ee6e23ca26193656e22c760a2e268f0c\/tenor.gif?itemid=9579084)","0423da5c":"In this exploratory part we would like to gain more knowledge about;\n1. The distribution of project states (*successful*, *failed*, *suspended* and *canceled*)\n2. Number of successful projects in each category of projects\n3. How do the backers spread across the categories of projects\n4. The relationship between funding goals and actual received  fundings (in USD) \n\n\n![alt text](https:\/\/i.imgflip.com\/2iookd.jpg)\n\n\n\n\n","6395605e":"\nNow let\u2019s dig into some supervised machine learning! Here our goal is to answer our problem formulation by predicting whether a project falls into a category of *succeeded*, *failed*, *canceled* or *suspended* based on its characteristics. We identified this as an issue of classification and will accordingly be working with three different classification models, interpret the results and assessing which one generates the best results; I.e. highest level of accuracy. \n\n","edb3f9c1":"In order to use the values we want to predict we have to encode these to numbers. This is done using the LabelEncoder","d4ec7e45":"We could also look at how many backers there are on average for each category. Below we can see that the projects that succeeded (state==1) have a much higher number of backers on average than those that fail (state==0). \nSome of the categories have way more backers like *design*, *games* and *technology*. It is likely because these projects are expensive to fund and thus require a larger number of backers to be successful.\n","f4b70609":"From the summary below, we can see that the biggest group of all projects was the **failed** ones, with the value of around 52% of all projects and the second biggest group (35%) was **successful**, the third and fourth group which will be left for analysis are canceled and suspended projects, which fall under category of unseccessful","8418f6ed":"### Changing the project state to numerical values for the further analysis\nIn order to work easier with the state of the project we want to change the catagorical values of the state column to numerical values","78fe9f08":"###Correlations\nFrom the matrix below we can see how strongly are different variables correlated with each other\nThe strongest correlations (both positive) are between variables **pledged, usd_pledged_real, and backers** the first very strong (around 95%) correlation can be ignored because the variables explain the same thing - the amount of money pledged for the project\nThe next strongest correlations between **backers and pledged funds** (around 72% and 75%) can be explained by the obvious fact that the more people were supporting each project, the more funds were collected\nThe rest of relations seem irrelevant.\n\nIn the supervised machine learning section we will look further into if we can find any relations across many variables.","881b8d32":"From the summary above it doesn't seem like there's any relation between project categories and cluster but most of the projects in the 3rd cluster seem to be successful","79414ea8":"###Principal Component Analysis (PCA)\nThe main goal of a PCA analysis is to identify patterns in data but also aims to detect the correlation between variables (which might be important for correlated projects goals and number of backers)\n\nWe wanted to cluster projects based on following variables:\n\n- state (successful or not)\n- number of backers\n- the amount of collected funds\n- main category of the project\n- duration of the money collection (days)","cf837737":"As we can see from the visualization, the clustering didn't work really well and it looks more like linear relationship between observations than distinct clusters, besides one of the clusters is very small and condensed in one place and the other one is pretty spread out\n\n---\n\n","94b8a451":"Next, we take the values that we want to predict, which is the state of the projects. These are assigned to *y*"}}