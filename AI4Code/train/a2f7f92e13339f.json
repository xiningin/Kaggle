{"cell_type":{"09609d26":"code","dc3d49c7":"code","cd7f646b":"code","63eed8b3":"code","36353344":"code","c14b026f":"code","58f18db3":"code","1ede7758":"code","6a158b6e":"code","e1ac5467":"code","805c4ac5":"code","14940b75":"code","1443758e":"code","407cb6da":"code","aefb9938":"code","c8c92b3c":"markdown","65b9c888":"markdown","6f245360":"markdown","6a5f8047":"markdown","6234d94c":"markdown","59abbfab":"markdown","7558fe05":"markdown","21176053":"markdown","2bddd54f":"markdown","1337e9d6":"markdown","d3d68142":"markdown","9fd608d6":"markdown","d6875fe0":"markdown","b6b69415":"markdown","f248736a":"markdown","b857789d":"markdown","2333563f":"markdown","fe6c7600":"markdown","aa9a902a":"markdown","5dd6fa79":"markdown"},"source":{"09609d26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport chart_studio.plotly as py\nfrom matplotlib_venn import venn3, venn3_circles\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfrom IPython.display import display, HTML\n\ndisplay(HTML(\"\"\"\n<style>\n.output {\n    display: flex;\n    align-items: center;\n    text-align: left;\n}\n<\/style>\n\"\"\"))\n\n# Any results you write to the current directory are saved as output.\n#pd.set_option('display.max_colwidth', -1)\n%matplotlib inline  \n\nmcr = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\nqu = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/questions_only.csv')\nschema = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/survey_schema.csv')\nother_response = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/other_text_responses.csv')\nmcr_data = mcr.drop(mcr.index[0])\n\nnlp_mask = (~mcr_data.Q27_Part_1.isna()) | (~mcr_data.Q27_Part_2.isna()) | (~mcr_data.Q27_Part_3.isna()) |(~mcr_data.Q27_Part_4.isna()) | (~mcr_data.Q27_Part_6.isna()) \nmachine_vision_mask = (~mcr_data.Q26_Part_1.isna()) | (~mcr_data.Q26_Part_2.isna()) | (~mcr_data.Q26_Part_3.isna()) | (~mcr_data.Q26_Part_4.isna()) | (~mcr_data.Q26_Part_5.isna()) | (~mcr_data.Q26_Part_7.isna())\ndata_scientis_mask = (mcr_data.Q5 == 'Data Scientist')\nsum(nlp_mask)*100\/len(mcr_data), sum(machine_vision_mask)*100\/len(mcr_data), sum(data_scientis_mask)*100\/len(mcr_data)","dc3d49c7":"fig = plt.figure(figsize=(10,6))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(y=['All Survey participants', 'People working as Data Scientist', 'People working on NLP', 'People working on Machine Vision'], \n            x=[len(mcr_data), sum(data_scientis_mask), sum(nlp_mask), sum(machine_vision_mask)], \n            palette=['#173F5F', '#02639B', '#F6D55C', '#3CAEA3'],\n                 color=\"#42A5F5\")\nax.set_xlabel('Count of people')\n\ntl = plt.title(\"Size of sub groups\", fontweight=\"bold\")","cd7f646b":"plt.figure(figsize=(8,8))\nv = venn3([set(mcr_data[nlp_mask].index), set(mcr_data[machine_vision_mask].index), set(mcr_data[data_scientis_mask].index)], set_labels = ('People working on NLP', 'People working on Machine Vision', 'People working as Data Scientist'))\ntl = plt.title(\"Interation between people working on NLP, Machine Vision and Data Scientists\", fontweight=\"bold\")\n","63eed8b3":"sns.set_style(\"whitegrid\")\n\nfig, ax = plt.subplots(figsize=(10,7))\nax = sns.countplot(x='Q1', data=mcr_data[nlp_mask], order=['18-21', '22-24', '25-29', '30-34', \n       '35-39','40-44','45-49','50-54','55-59','60-69', '70+'], color='#F6D55C')\nl = ax.set_xlabel('Age range')\nt = ax.set_title('Age distribution of NLP group', fontweight=\"bold\")","36353344":"gender = pd.DataFrame(mcr_data.Q2.value_counts()*100\/len(mcr_data))\ngender.columns = ['All']\ngender['NLP'] = mcr_data[nlp_mask].Q2.value_counts()*100\/len(mcr_data[nlp_mask])\ngender['MV'] = mcr_data[machine_vision_mask].Q2.value_counts()*100\/len(mcr_data[machine_vision_mask])\ngender['DS'] = mcr_data[data_scientis_mask].Q2.value_counts()*100\/len(mcr_data[data_scientis_mask]) \ngender = gender.drop(gender.index[[2, 3]])\n\n\nsns.set_style(\"whitegrid\")\n\n# Setting the positions and width for the bars\npos = list(range(2)) \nwidth = 0.2\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(10,7))\n\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        gender['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F', \n        # with label the first value in first_name\n        label=['Male', 'Female']) \nfor p in pos:\n    plt.text(x = p - 0.04 , y = list(gender['All'])[p]+0.5, s = str(round(list(gender['All'])[p], 1)), size = 11)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        gender['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B', \n        ) \nfor p in pos:\n    plt.text(x = p + width - 0.04 , y = list(gender['DS'])[p]+0.5, s = str(round(list(gender['DS'])[p], 1)), size = 11)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        gender['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - 0.04 , y = list(gender['NLP'])[p]+0.5, s = str(round(list(gender['NLP'])[p], 1)), size = 11)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        gender['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - 0.04 , y = list(gender['MV'])[p]+0.5, s = str(round(list(gender['MV'])[p], 1)), size = 11)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('Gender percentage across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(['Male', 'Female'])\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 100 ])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')\n#plt.grid()\n#plt.show()","c14b026f":"edu = pd.DataFrame(mcr_data[~mcr_data.Q4.isna()].Q4.value_counts()*100\/len(mcr_data[~mcr_data.Q4.isna()]))\nedu.columns = ['All']\nedu['NLP'] = mcr_data[(nlp_mask) & (~mcr_data.Q4.isna())].Q4.value_counts()*100\/len(mcr_data[(nlp_mask) & (~mcr_data.Q4.isna())])\nedu['MV'] = mcr_data[(machine_vision_mask) & (~mcr_data.Q4.isna())].Q4.value_counts()*100\/len(mcr_data[(machine_vision_mask) & (~mcr_data.Q4.isna())])\nedu['DS'] = mcr_data[(data_scientis_mask) & (~mcr_data.Q4.isna())].Q4.value_counts()*100\/len(mcr_data[(data_scientis_mask) & (~mcr_data.Q4.isna())])\n\nsns.set_style(\"whitegrid\")\n\n# Setting the positions and width for the bars\npos = list(range(3)) \nwidth = 0.2\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(10,7))\n\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F', \n        ) \nfor p in pos:\n    plt.text(x = p - 0.06 , \n             y = list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['All'])[p]+0.4, \n             s = str(round(list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['All'])[p], 1)), \n             size = 11)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B', \n        ) \nfor p in pos:\n    plt.text(x = p + width - 0.06, \n             y = list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['DS'])[p]+0.4, \n             s = str(round(list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['DS'])[p], 1)), size = 11)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - 0.06 , \n             y = list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['NLP'])[p]+0.4, \n             s = str(round(list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['NLP'])[p], 1)), \n             size = 11)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - 0.06 , y = list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['MV'])[p]+0.3, \n             s = str(round(list(edu.loc[['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree']]['MV'])[p], 1)), \n             size = 11)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('Education percentage across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(['Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree'])\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 60 ])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')\n#plt.grid()\n#plt.show()","58f18db3":"business = pd.DataFrame(mcr_data[~mcr_data.Q8.isna()].Q8.value_counts()*100\/len(mcr_data[~mcr_data.Q8.isna()]))\nbusiness.columns = ['All']\nbusiness['NLP'] = mcr_data[nlp_mask & (~mcr_data.Q8.isna())].Q8.value_counts()*100\/len(mcr_data[nlp_mask & (~mcr_data.Q8.isna())])\nbusiness['MV'] = mcr_data[machine_vision_mask & (~mcr_data.Q8.isna())].Q8.value_counts()*100\/len(mcr_data[machine_vision_mask & (~mcr_data.Q8.isna())])\nbusiness['DS'] = mcr_data[data_scientis_mask & (~mcr_data.Q8.isna())].Q8.value_counts()*100\/len(mcr_data[data_scientis_mask & (~mcr_data.Q8.isna())])\nbusiness.index = ['Exploring', 'Started using', 'Well established', 'Not using', 'Generating Insights', 'Dont Know']\n\nsns.set_style(\"whitegrid\")\n\n# Setting the positions and width for the bars\npos = list(range(6)) \nwidth = 0.2\ntx_size = 9\ntx_offset = 0.07\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(14,8))\ncols = ['Dont Know','Not using', 'Exploring', 'Generating Insights','Started using', 'Well established']\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        business.loc[cols]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F', \n        ) \nfor p in pos:\n    plt.text(x = p - tx_offset , \n             y = list(business.loc[cols]['All'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['All'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        business.loc[cols]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B', \n        ) \nfor p in pos:\n    plt.text(x = p + width - tx_offset, \n             y = list(business.loc[cols]['DS'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['DS'])[p], 1)), size = tx_size)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - tx_offset , \n             y = list(business.loc[cols]['NLP'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['NLP'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - tx_offset , y = list(business.loc[cols]['MV'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['MV'])[p], 1)), \n             size = tx_size)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('Using machine learning methods in business across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(cols)\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 40])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')\n#plt.grid()\n#plt.show()","1ede7758":" q9_na = (mcr_data.Q9_Part_1.isna() &\n mcr_data.Q9_Part_2.isna() &\n mcr_data.Q9_Part_3.isna() &\n mcr_data.Q9_Part_4.isna() &\n mcr_data.Q9_Part_5.isna() &\n mcr_data.Q9_Part_6.isna() &\n mcr_data.Q9_Part_7.isna() &\n mcr_data.Q9_Part_8.isna() ) \n\nact = pd.DataFrame(mcr_data[~q9_na][['Q9_Part_1',\n 'Q9_Part_2',\n 'Q9_Part_3',\n 'Q9_Part_4',\n 'Q9_Part_5',\n 'Q9_Part_6',\n 'Q9_Part_7']].melt().value.value_counts()*100\/len(mcr_data[~q9_na]))\nact.columns = ['All participants %']\nact['Data Scientists %'] = mcr_data[data_scientis_mask & (~q9_na)][['Q9_Part_1',\n 'Q9_Part_2',\n 'Q9_Part_3',\n 'Q9_Part_4',\n 'Q9_Part_5',\n 'Q9_Part_6',\n 'Q9_Part_7']].melt().value.value_counts()*100\/len(mcr_data[data_scientis_mask & (~q9_na)])\nact['NLP group %'] = mcr_data[nlp_mask & (~q9_na)][['Q9_Part_1',\n 'Q9_Part_2',\n 'Q9_Part_3',\n 'Q9_Part_4',\n 'Q9_Part_5',\n 'Q9_Part_6',\n 'Q9_Part_7']].melt().value.value_counts()*100\/len(mcr_data[nlp_mask & (~q9_na)])\nact['Machine Vision group %'] = mcr_data[machine_vision_mask & (~q9_na)][['Q9_Part_1',\n 'Q9_Part_2',\n 'Q9_Part_3',\n 'Q9_Part_4',\n 'Q9_Part_5',\n 'Q9_Part_6',\n 'Q9_Part_7']].melt().value.value_counts()*100\/len(mcr_data[machine_vision_mask & (~q9_na)])\n\n\n\n#act.index = ['Analyze Data', 'Build prototypes', 'improve existing ML models', 'build data infrastructure', 'build machine learning service', 'Do research', 'None']\nround(act,2)","6a158b6e":"business = pd.DataFrame(mcr_data[~mcr_data.Q11.isna()].Q11.value_counts()*100\/len(mcr_data[~mcr_data.Q11.isna()]))\nbusiness.columns = ['All']\nbusiness['NLP'] = mcr_data[nlp_mask & (~mcr_data.Q11.isna())].Q11.value_counts()*100\/len(mcr_data[nlp_mask & (~mcr_data.Q11.isna())])\nbusiness['MV'] = mcr_data[machine_vision_mask & (~mcr_data.Q11.isna())].Q11.value_counts()*100\/len(mcr_data[machine_vision_mask & (~mcr_data.Q11.isna())])\nbusiness['DS'] = mcr_data[data_scientis_mask & (~mcr_data.Q11.isna())].Q11.value_counts()*100\/len(mcr_data[data_scientis_mask & (~mcr_data.Q11.isna())])\n\nsns.set_style(\"whitegrid\")\n\n# Setting the positions and width for the bars\npos = list(range(6)) \nwidth = 0.2\ntx_size = 9\ntx_offset = 0.07\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(14,8))\ncols = ['$0 (USD)', '$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999','> $100,000 ($USD)']\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        business.loc[cols]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F', \n        ) \nfor p in pos:\n    plt.text(x = p - tx_offset , \n             y = list(business.loc[cols]['All'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['All'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        business.loc[cols]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B', \n        ) \nfor p in pos:\n    plt.text(x = p + width - tx_offset, \n             y = list(business.loc[cols]['DS'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['DS'])[p], 1)), size = tx_size)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - tx_offset , \n             y = list(business.loc[cols]['NLP'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['NLP'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - tx_offset , y = list(business.loc[cols]['MV'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['MV'])[p], 1)), \n             size = tx_size)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('machine learning and\/or cloud computing products spending across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(cols)\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 40])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')\n#plt.grid()\n#plt.show()","e1ac5467":"q13_na = (mcr_data.Q13_Part_1.isna() &\n mcr_data.Q13_Part_2.isna() &\n mcr_data.Q13_Part_3.isna() &\n mcr_data.Q13_Part_4.isna() &\n mcr_data.Q13_Part_5.isna() &\n mcr_data.Q13_Part_6.isna() &\n mcr_data.Q13_Part_7.isna() &\n mcr_data.Q13_Part_8.isna() & \n mcr_data.Q13_Part_9.isna() & \n mcr_data.Q13_Part_10.isna() & \n mcr_data.Q13_Part_11.isna() & \n mcr_data.Q13_Part_12.isna()\n         ) \n\nsns.set_style(\"whitegrid\")\n\nd = mcr_data[nlp_mask & (~q13_na)][['Q13_Part_1', 'Q13_Part_2', 'Q13_Part_3', 'Q13_Part_4', 'Q13_Part_5',\n       'Q13_Part_6', 'Q13_Part_7', 'Q13_Part_8', 'Q13_Part_9', 'Q13_Part_10',\n       'Q13_Part_11']].melt()\nd.loc[(d.value == 'University Courses (resulting in a university degree)'), 'value'] = 'University Courses'\nd.loc[(d.value == 'Kaggle Courses (i.e. Kaggle Learn)'), 'value'] = 'Kaggle'\nd.loc[(d.value == 'LinkedIn Learning'), 'value'] = 'LinkedIn'\n\nfig, ax = plt.subplots(figsize=(15,7))\nax = sns.countplot(x='value', data=d, color='#F6D55C')\nl = ax.set_xlabel('Course platform')\nt = ax.set_title('Distribution of course platform from NLP group', fontweight=\"bold\")","805c4ac5":"business = pd.DataFrame(mcr_data[~mcr_data.Q15.isna()].Q15.value_counts()*100\/len(mcr_data[~mcr_data.Q15.isna()]))\nbusiness.columns = ['All']\nbusiness['NLP'] = mcr_data[nlp_mask & (~mcr_data.Q15.isna())].Q15.value_counts()*100\/len(mcr_data[nlp_mask & (~mcr_data.Q15.isna())])\nbusiness['MV'] = mcr_data[machine_vision_mask & (~mcr_data.Q15.isna())].Q15.value_counts()*100\/len(mcr_data[machine_vision_mask & (~mcr_data.Q15.isna())])\nbusiness['DS'] = mcr_data[data_scientis_mask & (~mcr_data.Q15.isna())].Q15.value_counts()*100\/len(mcr_data[data_scientis_mask & (~mcr_data.Q15.isna())])\n\nsns.set_style(\"whitegrid\")\n\n# Setting the positions and width for the bars\npos = list(range(7)) \nwidth = 0.2\ntx_size = 9\ntx_offset = 0.07\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(14,8))\ncols = ['I have never written code', '< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        business.loc[cols]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F' \n        ) \nfor p in pos:\n    plt.text(x = p - tx_offset , \n             y = list(business.loc[cols]['All'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['All'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        business.loc[cols]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B'\n        ) \nfor p in pos:\n    plt.text(x = p + width - tx_offset, \n             y = list(business.loc[cols]['DS'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['DS'])[p], 1)), size = tx_size)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - tx_offset , \n             y = list(business.loc[cols]['NLP'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['NLP'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - tx_offset , y = list(business.loc[cols]['MV'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['MV'])[p], 1)), \n             size = tx_size)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('Coding experience across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(cols)\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 40])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')\n#plt.grid()\n#plt.show()","14940b75":"q16_na = (mcr_data.Q16_Part_1.isna() &\n mcr_data.Q16_Part_2.isna() &\n mcr_data.Q16_Part_3.isna() &\n mcr_data.Q16_Part_4.isna() &\n mcr_data.Q16_Part_5.isna() &\n mcr_data.Q16_Part_6.isna() &\n mcr_data.Q16_Part_7.isna() &\n mcr_data.Q16_Part_8.isna() & \n mcr_data.Q16_Part_9.isna() & \n mcr_data.Q16_Part_10.isna() & \n mcr_data.Q16_Part_11.isna() & \n mcr_data.Q16_Part_12.isna()\n         ) \nbusiness = pd.DataFrame(mcr_data[~q16_na][['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5',\n       'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9', 'Q16_Part_10',\n       'Q16_Part_11']].melt().value.value_counts().nlargest(5)*100\/len(mcr_data[~q16_na]))\n\nbusiness.columns = ['All']\n\nbusiness['NLP'] = mcr_data[nlp_mask & (~q16_na)][['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5',\n       'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9', 'Q16_Part_10',\n       'Q16_Part_11']].melt().value.value_counts()*100\/len(mcr_data[nlp_mask & (~q16_na)])\n\nbusiness['MV'] = mcr_data[machine_vision_mask & (~q16_na)][['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5',\n       'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9', 'Q16_Part_10',\n       'Q16_Part_11']].melt().value.value_counts()*100\/len(mcr_data[machine_vision_mask & (~q16_na)])\n\nbusiness['DS'] = mcr_data[data_scientis_mask & (~q16_na)][['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5',\n       'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9', 'Q16_Part_10',\n       'Q16_Part_11']].melt().value.value_counts()*100\/len(mcr_data[data_scientis_mask & (~q16_na)])\n\nbusiness.index = ['Jupyter',\n       'Visual Studio', 'RStudio', 'PyCharm',\n       'Notepad++']\nsns.set_style(\"whitegrid\")\n\n# Setting the positions and width for the bars\npos = list(range(5)) \nwidth = 0.2\ntx_size = 9\ntx_offset = 0.07\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(14,8))\ncols = ['Jupyter',\n       'Visual Studio', 'RStudio', 'PyCharm',\n       'Notepad++']\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        business.loc[cols]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F' \n        ) \nfor p in pos:\n    plt.text(x = p - tx_offset , \n             y = list(business.loc[cols]['All'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['All'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        business.loc[cols]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B'\n        ) \nfor p in pos:\n    plt.text(x = p + width - tx_offset, \n             y = list(business.loc[cols]['DS'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['DS'])[p], 1)), size = tx_size)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - tx_offset , \n             y = list(business.loc[cols]['NLP'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['NLP'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - tx_offset , y = list(business.loc[cols]['MV'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['MV'])[p], 1)), \n             size = tx_size)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('IDE across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(cols)\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 100])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')\n#plt.grid()\n#plt.show()","1443758e":"q17_na = (mcr_data.Q17_Part_1.isna() &\n mcr_data.Q17_Part_2.isna() &\n mcr_data.Q17_Part_3.isna() &\n mcr_data.Q17_Part_4.isna() &\n mcr_data.Q17_Part_5.isna() &\n mcr_data.Q17_Part_6.isna() &\n mcr_data.Q17_Part_7.isna() &\n mcr_data.Q17_Part_8.isna() & \n mcr_data.Q17_Part_9.isna() & \n mcr_data.Q17_Part_10.isna() & \n mcr_data.Q17_Part_11.isna() & \n mcr_data.Q17_Part_12.isna()\n         ) \n\nbusiness = pd.DataFrame(mcr_data[~q17_na][['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5',\n       'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10',\n       'Q17_Part_11']].melt().value.value_counts().nlargest(5)*100\/len(mcr_data[~q17_na]))\n\nbusiness.columns = ['All']\n\nbusiness['NLP'] = mcr_data[nlp_mask & (~q17_na)][['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5',\n       'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10',\n       'Q17_Part_11']].melt().value.value_counts()*100\/len(mcr_data[nlp_mask & (~q17_na)])\n\nbusiness['MV'] = mcr_data[machine_vision_mask & (~q17_na)][['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5',\n       'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10',\n       'Q17_Part_11']].melt().value.value_counts()*100\/len(mcr_data[machine_vision_mask & (~q17_na)])\n\nbusiness['DS'] = mcr_data[data_scientis_mask & (~q17_na)][['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5',\n       'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10',\n       'Q17_Part_11']].melt().value.value_counts()*100\/len(mcr_data[data_scientis_mask & (~q17_na)])\n\nbusiness.index = ['None', ' Kaggle Notebooks', ' Google Colab ',\n       ' Binder\/JupyterHub',\n       ' Google Cloud Notebook Products']\n\n\n# Setting the positions and width for the bars\npos = list(range(5)) \nwidth = 0.2\ntx_size = 9\ntx_offset = 0.07\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(14,8))\ncols = business.index\n\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        business.loc[cols]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F' \n        ) \nfor p in pos:\n    plt.text(x = p - tx_offset , \n             y = list(business.loc[cols]['All'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['All'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        business.loc[cols]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B'\n        ) \nfor p in pos:\n    plt.text(x = p + width - tx_offset, \n             y = list(business.loc[cols]['DS'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['DS'])[p], 1)), size = tx_size)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - tx_offset , \n             y = list(business.loc[cols]['NLP'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['NLP'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - tx_offset , y = list(business.loc[cols]['MV'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['MV'])[p], 1)), \n             size = tx_size)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('Hosted notebook products usage across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(cols)\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 100])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')","407cb6da":"q24_na = (mcr_data.Q24_Part_1.isna() &\n mcr_data.Q24_Part_2.isna() &\n mcr_data.Q24_Part_3.isna() &\n mcr_data.Q24_Part_4.isna() &\n mcr_data.Q24_Part_5.isna() &\n mcr_data.Q24_Part_6.isna() &\n mcr_data.Q24_Part_7.isna() &\n mcr_data.Q24_Part_8.isna() &\n mcr_data.Q24_Part_9.isna() &\n mcr_data.Q24_Part_10.isna() &       \n mcr_data.Q24_Part_11.isna() &       \n mcr_data.Q24_Part_12.isna()         \n          ) \n\nbusiness = pd.DataFrame(mcr_data[~q24_na][['Q24_Part_1', 'Q24_Part_2', 'Q24_Part_3', 'Q24_Part_4', 'Q24_Part_5',\n       'Q24_Part_6', 'Q24_Part_7', 'Q24_Part_8', 'Q24_Part_9', 'Q24_Part_10',\n       'Q24_Part_11']].melt().value.value_counts().nlargest(7)*100\/len(mcr_data[~q24_na]))\n\nbusiness.columns = ['All']\n\nbusiness['NLP'] = mcr_data[nlp_mask & (~q24_na)][['Q24_Part_1', 'Q24_Part_2', 'Q24_Part_3', 'Q24_Part_4', 'Q24_Part_5',\n       'Q24_Part_6', 'Q24_Part_7', 'Q24_Part_8', 'Q24_Part_9', 'Q24_Part_10',\n       'Q24_Part_11']].melt().value.value_counts()*100\/len(mcr_data[nlp_mask & (~q24_na)])\n\nbusiness['MV'] = mcr_data[machine_vision_mask & (~q24_na)][['Q24_Part_1', 'Q24_Part_2', 'Q24_Part_3', 'Q24_Part_4', 'Q24_Part_5',\n       'Q24_Part_6', 'Q24_Part_7', 'Q24_Part_8', 'Q24_Part_9', 'Q24_Part_10',\n       'Q24_Part_11']].melt().value.value_counts()*100\/len(mcr_data[machine_vision_mask & (~q24_na)])\n\nbusiness['DS'] = mcr_data[data_scientis_mask & (~q24_na)][['Q24_Part_1', 'Q24_Part_2', 'Q24_Part_3', 'Q24_Part_4', 'Q24_Part_5',\n       'Q24_Part_6', 'Q24_Part_7', 'Q24_Part_8', 'Q24_Part_9', 'Q24_Part_10',\n       'Q24_Part_11']].melt().value.value_counts()*100\/len(mcr_data[data_scientis_mask & (~q24_na)])\n\nbusiness.index = ['Linear', 'Trees Based',\n       'Gradient Boosting',\n       'CNN', 'Bayesian',\n       'RNN', 'DNN']\n\n\n# Setting the positions and width for the bars\npos = list(range(7)) \nwidth = 0.2\ntx_size = 9\ntx_offset = 0.07\n    \n# Plotting the bars\nfig, ax = plt.subplots(figsize=(14,8))\ncols = business.index\n\n# Create a bar with pre_score data,\n# in position pos,\nplt.bar(pos, \n        #using df['pre_score'] data,\n        business.loc[cols]['All'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9,\n        # with color\n        color='#173F5F' \n        ) \nfor p in pos:\n    plt.text(x = p - tx_offset , \n             y = list(business.loc[cols]['All'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['All'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with mid_score data,\n# in position pos + some width buffer,\nplt.bar([p + width for p in pos], \n        #using df['mid_score'] data,\n        business.loc[cols]['DS'],\n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#02639B'\n        ) \nfor p in pos:\n    plt.text(x = p + width - tx_offset, \n             y = list(business.loc[cols]['DS'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['DS'])[p], 1)), size = tx_size)\n\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*2 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['NLP'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#F6D55C', \n        ) \nfor p in pos:\n    plt.text(x = p + width*2 - tx_offset , \n             y = list(business.loc[cols]['NLP'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['NLP'])[p], 1)), \n             size = tx_size)\n\n# Create a bar with post_score data,\n# in position pos + some width buffer,\nplt.bar([p + width*3 for p in pos], \n        #using df['post_score'] data,\n        business.loc[cols]['MV'], \n        # of width\n        width, \n        # with alpha 0.9\n        alpha=0.9, \n        # with color\n        color='#3CAEA3', \n        ) \nfor p in pos:\n    plt.text(x = p + width*3 - tx_offset , y = list(business.loc[cols]['MV'])[p]+0.3, \n             s = str(round(list(business.loc[cols]['MV'])[p], 1)), \n             size = tx_size)\n           \n# Set the y axis label\nax.set_ylabel('Percentage')\n\n# Set the chart's title\nax.set_title('ML methods across groups', fontweight=\"bold\")\n\n# Set the position of the x ticks\nax.set_xticks([p + 1.5 * width for p in pos])\n\n# Set the labels for the x ticks\nax.set_xticklabels(cols)\n\n# Setting the x-axis and y-axis limits\nplt.xlim(min(pos)-width, max(pos)+width*5)\nplt.ylim([0, 110])\n\n# Adding the legend and showing the plot\nlg = plt.legend(['All participants', 'Data Scientists ', 'NLP group', 'Machine Vision group'], loc='upper right')","aefb9938":"q27_na = (mcr_data.Q27_Part_1.isna() &\n mcr_data.Q27_Part_2.isna() &\n mcr_data.Q27_Part_3.isna() &\n mcr_data.Q27_Part_4.isna() &\n mcr_data.Q27_Part_5.isna() &\n mcr_data.Q27_Part_6.isna() ) \n\n\nsns.set_style(\"whitegrid\")\n\nd = mcr_data[nlp_mask & (~q27_na)][['Q27_Part_1', 'Q27_Part_2', 'Q27_Part_3', 'Q27_Part_4', 'Q27_Part_5']].melt()\n\nd.loc[(d.value == 'Word embeddings\/vectors (GLoVe, fastText, word2vec)'), 'value'] = 'Word embeddings'\nd.loc[(d.value == 'Encoder-decorder models (seq2seq, vanilla transformers)'), 'value'] = 'Encoder-decorder'\nd.loc[(d.value == 'Contextualized embeddings (ELMo, CoVe)'), 'value'] = 'Contextualized embedd'\nd.loc[(d.value == 'Transformer language models (GPT-2, BERT, XLnet, etc)'), 'value'] = 'Transformer language mdls'\n\nfig, ax = plt.subplots(figsize=(10,7))\nax = sns.countplot(x='value', data=d, color='#F6D55C')\nl = ax.set_xlabel('NLP methods')\nt = ax.set_title('Usage of NLP methods from NLP group', fontweight=\"bold\")\n","c8c92b3c":"## Exploratory data analysis of survey responses","65b9c888":"## Introduction\n\n\n>*\"Homo sapiens conquered the world thanks above all to its unique language\"*  -[Sapiens](https:\/\/aax-us-east.amazon-adsystem.com\/x\/c\/QgPOnvgmI26xLqpI4aXU5swAAAFuxsm2EAEAAAFKAR33Bb4\/https:\/\/assoc-redirect.amazon.com\/g\/r\/https:\/\/www.amazon.com\/gp\/product\/0062316095\/ref=as_li_qf_asin_il_tl?imprToken=V9S-muRPdYsRhStBK-RBLw&slotNum=0&ie=UTF8&tag=farnamstreet-20&creative=9325&linkCode=w61&creativeASIN=0062316095&linkId=37b542556cc1eec0f302de27540ff2b4) *Yuval Noah Harari*\n\nAbout 70,000 or so years ago, our DNA showed a mutation which allowed us to make a leap that no other species, human or otherwise, was able to make: Cooperating flexibly in large groups with a unique and complex language. Harari calls this the \u201cCognitive Revolution.\u201d Language was important reason behind large-scale human cooperation which enabled humans to dominate the Earth.  -[Source Sapiens](https:\/\/aax-us-east.amazon-adsystem.com\/x\/c\/QgPOnvgmI26xLqpI4aXU5swAAAFuxsm2EAEAAAFKAR33Bb4\/https:\/\/assoc-redirect.amazon.com\/g\/r\/https:\/\/www.amazon.com\/gp\/product\/0062316095\/ref=as_li_qf_asin_il_tl?imprToken=V9S-muRPdYsRhStBK-RBLw&slotNum=0&ie=UTF8&tag=farnamstreet-20&creative=9325&linkCode=w61&creativeASIN=0062316095&linkId=37b542556cc1eec0f302de27540ff2b4)\n<br><br>Because of language we generate vast amount of unstructured data. According to the expert estimates 80 to 90 percent of the data in any organisation is unstructured.  Unstructured data files often include text, multimedia content, e-mail messages, word processing documents, videos, photos, audio files, presentations, webpages and many other kinds of business documents. Data is being generated as we speak, as we tweet, as we send messages on Whatsapp and in various other activities. Majority of this data exists in the textual form, which is highly unstructured in nature. Natural Language Processing(NLP) is discipline which deals with how computer process and analyse natural language data. According to ([wikipedia](https:\/\/en.wikipedia.org\/wiki\/Natural_language_processing)) definition-\n\n>Natural language processing (NLP) is a subfield of [linguistics](https:\/\/en.wikipedia.org\/wiki\/Linguistics), [computer science](https:\/\/en.wikipedia.org\/wiki\/Computer_science), [information engineering](https:\/\/en.wikipedia.org\/wiki\/Information_engineering_(field)), and [artificial intelligence](https:\/\/en.wikipedia.org\/wiki\/Artificial_intelligence) concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of [natural language data](https:\/\/en.wikipedia.org\/wiki\/Natural_language). Challenges in natural language processing frequently involve [speech recognition](https:\/\/en.wikipedia.org\/wiki\/Speech_recognition), [natural language understanding](https:\/\/en.wikipedia.org\/wiki\/Natural_language_understanding), and [natural language generation](https:\/\/en.wikipedia.org\/wiki\/Natural_language_generation).\n\nThe [history of natural language processing (NLP)](https:\/\/en.wikipedia.org\/wiki\/History_of_natural_language_processing) generally started in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled [\"Computing Machinery and Intelligence\"](https:\/\/en.wikipedia.org\/wiki\/Computing_Machinery_and_Intelligence) which proposed what is now called the [Turing test](https:\/\/en.wikipedia.org\/wiki\/Turing_test) as a criterion of intelligence. Here are the key historical events which have supported NLP advancements. ","6f245360":" # <font color=black>Insights into the NLP community from 2019 Kaggle ML and DS Survey <\/font>","6a5f8047":"### Coding experience\n* About 60% of NLP group has 1-5 years of coding experience\n* NLP group has more percentage of people having more than 5 years of experience than Machine Vision group\n* Data Science group has highest percentage of people who have coding experience of more than 3 years.","6234d94c":"### Activities that make up an important part of role at work\n* 58.07% of NLP group works on improve existing ML models which is highest among all groups.\n* 38% of NLP group works on research that advances the state of the art of machine learning.\n* More percentage of NLP group works on any of these ML activities than Machine Vision group.\n\n","59abbfab":"### Usage of ML methods\n* Recurrent Neural Networks are most popular among NLP group as more than 91% people are using RNNs from this group.\n* Convolutional Neural Networks are second most popular among NLP group with about 77% people using these.\n* More number of people are using CNN, RNN and DNN from NLP and Machine vision group as compared to Data Scientist group","7558fe05":"### Hosted notebook products\n* Google colab is popular among NLP and Machine vision group as about 50% people use google colab from these groups.\n* About 80% of NLP group is using at least one hosted notebook product.\n* Hosted notebook product are used more by NLP and Machine vision group than Data Scientist group","21176053":"### Usage of NLP methods\n* About 82% of NLP group is using Word embeddings\/vectors (GLoVe, fastText, word2vec)\n* 54% of NLP group is using Encoder-decorder models (seq2seq, vanilla transformers)\n* 40% of NLP group is using Transformer language models (GPT-2, BERT, XLnet, etc)\n* 22% of NLP group is using Contextualized embeddings (ELMo, CoVe) ","2bddd54f":"### Usage of data science course platforms\n* 94% of NLP group have begun or completed data science courses on some platform\n* Most popular platform is Coursera followed by U**nversity coursers, Kaggle and Udemy ","1337e9d6":"### Spending on machine learning and\/or cloud computing products\n\n* About 25% of NLP groups spends more than $10,000 on machine learning and\/or cloud computing products, which is 4% higher than Machine Vision group and about 1% higher than Data Scientist group.\n* 80% or more of NLP group is spending at least some amount on machine learning and\/or cloud computing products, which is highest of all groups.\n","d3d68142":"### Gender\n\n* We see that there is even more pronounced gender gap in NLP group as compared to all survey participants. \n* While there are about 16% Females in all survey data, we see that in NLP group there are only 11.5% \n* Machine Vision group has even lesser female participation at 10%","9fd608d6":"## Survey groups \nSurvey participants are divided into 4 groups. \n1. People working on NLP\n2. People working on Machine Vision\n3. People working as Data Scientist\n4. All Survey participants\n\nHere is the methodology for dividing survey participants into subgroups - \n\n>### 1. People working on NLP\nPeople working on NLP have been selected based on the answer given to question **Q27 - Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply)**. People who have selected any of the NLP methods (including other) are considered as people working on NLP. So these people have selected any of the following options - \n* **Q27_Part_1**- Word embeddings\/vectors (GLoVe, fastText, word2vec)\n* **Q27_Part_2** - Encoder-decorder models (seq2seq, vanilla transformers)\n* **Q27_Part_3** - Contextualized embeddings (ELMo, CoVe)\n* **Q27_Part_4** - Transformer language models (GPT-2, BERT, XLnet, etc)\n* **Q27_Part_6** - Other\n\n>### 2. People working on Machine Vision\nPeople working on Machine Vision have been selected based on answer given to question **Q26 Which categories of computer vision methods do you use on a regular basis? (Select all that apply)**. People who have selected any of the Machine vision methods (including other) are considered as people working on Machine Vision. So these people have selected any of the following options - \n* **Q26_Part_1** - General purpose image\/video tools (PIL, cv2, skimage, etc) \n* **Q26_Part_2** - Image segmentation methods (U-Net, Mask R-CNN, etc)\n* **Q26_Part_3** - Object detection methods (YOLOv3, RetinaNet, etc)\n* **Q26_Part_4** - Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)\n* **Q26_Part_5** -Generative Networks (GAN, VAE, etc)\n* **Q26_Part_7** - Other\n\n>### 3. People working as Data Scientist\nPeople working as Data Scientist are selected based on answer given to question **Q5 Select the title most similar to your current role (or most recent title if retired)**. People belong to this group if **Data Scientist** is selected as the answer to Q5. \n\n>### 4. All Survey participants\nThis set consists of everyone who participated in the survey.\n\nLet's check size of the groups and how these group interact with each other-\n* 12.95% people work on NLP methods \n* 21.75% work on Machine Vision methods \n* 20.71% people are working as Data Scientist. ","d6875fe0":"###  Integrated development environments (IDE's) \n* Most popular IDE is Jupyter (JupyterLab, Jupyter Notebooks, etc)\n* PyCharm and notepad++ are more popular among NLP group than other groups","b6b69415":"[Image Source](https:\/\/www.hostcomm.co.uk\/news\/2019\/evolution-natural-language-infographic)![image.png](attachment:image.png)","f248736a":"### Age\n* Majority of NLP group is aged between 22-34\n* Age trend of NLP group is similar to rest of the groups","b857789d":"[Image Source](https:\/\/www.attivio.com\/blog\/post\/what-natural-language-understanding)![image.png](attachment:image.png)","2333563f":"## Objectives\nThis analysis focuses on the people working on NLP methods. Key objectives of this notebook are - \n* To explore the survey data in order to analyse the people working on NLP within survey data. \n* To drill down on the NLP group while comparing it to other groups and all of the survey respondents.\n* Conclusion\n\nWe will take a looks at how survey participants have been divided into subgroups, followed by exploratory data analysis.","fe6c7600":"### Education\n\n* We see that people working on NLP, Machine Vision and Data Scientists have higher percentages of Master's and Doctorol Degrees. \n* In case of Doctorol degrees there about 4% difference between all survey data participants and NLP group.\n* Percentage of Master's degrees in people working as Data Scientists is significantly higher than other groups.","aa9a902a":"## Conclusion\n\nWe notice that only 13% of survey respondents are working on NLP methods. NLP group (from survey data) is relatively young, highly educated community with even more pronounced Male-Female gender gap. More than 57% of NLP group works for companies where ML methods are already productionised. NLP group works mostly on experimentation and iteration to improve existing ML models or building prototypes to explore applying machine learning to new areas. People working on NLP are spending significant amount on machine learning and\/or cloud computing product. Google colab is popular choice for hosted notebook products, while Jupyter and PyCharm are popular IDEs among NLP group. \n<br>\nCNN and RNN are first choice of ML methods while word embeddings\/vectors (GLoVe, fastText, word2vec), Encoder-decorder models are most used NLP methods. Most of NLP group continue to learn new data science skills using Blogs, Kaggle forums, Coursera, and YouTube. ","5dd6fa79":"### Incorporating machine learning methods into business\n* we see that almost 30% of NLP group is working on businesses where well established ML methods are in use (i.e., models in production for more than 2 years), which is highest in all other groups. \n* We also see that more people from NLP group are working for businesses where models are already in production (57%) as compared to Machine Vision group (50%)\n* More than 70% of NLP group is working on businesses which are using ML for generating insights or have models in production"}}