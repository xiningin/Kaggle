{"cell_type":{"894278ff":"code","9efe5955":"code","ecb9fb87":"code","277cf46f":"code","667271bd":"code","9abc14a0":"code","438b29e3":"code","cb606ea3":"code","d93378ba":"code","c902da9d":"code","17f20c50":"code","a26d1d18":"code","eab790a7":"code","b986889d":"code","05b96047":"code","42c0ca5f":"code","64a0a528":"code","fcd55abc":"markdown","059445f4":"markdown","a2f558cf":"markdown","35f4dbdc":"markdown","eb644a02":"markdown","9e4f3adc":"markdown","29294313":"markdown","d03341d3":"markdown","5ebeca0d":"markdown","3103c94d":"markdown","f4c50c26":"markdown","67932887":"markdown","2923e78d":"markdown","75866070":"markdown","37c127d1":"markdown","59fd14dd":"markdown","d4ddc3b4":"markdown","579597bc":"markdown","aff29cf8":"markdown"},"source":{"894278ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9efe5955":"# import required libraries\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nimport pandas as pd","ecb9fb87":"# getting url of the scrapping dataset\nurl = 'https:\/\/www.iplt20.com\/stats\/2019\/most-runs'","277cf46f":"df = pd.read_html(url,header=0)","667271bd":"df","9abc14a0":"len(df)","438b29e3":"# selecting that one table\ndf2020_players_run = df[0]","cb606ea3":"# load the dataset\ndf2020_players_run","d93378ba":"df2020_players_run.info()","c902da9d":"# remove '*' from HS column\ndf2020_players_run['HS'] = df2020_players_run['HS'].map(lambda x : x.rstrip('*'))","17f20c50":"df2020_players_run['Avg'].replace({'-':'NaN'},inplace=True)","a26d1d18":"# chaning dtype\nconvert_dict = {'HS': int , 'Avg' : float }\n\ndf2020_players_run = df2020_players_run.astype(convert_dict)","eab790a7":"# specify the url\nurl2 = 'https:\/\/www.iplt20.com\/points-table\/2020'\n\n# read html page\ndf_2 = pd.read_html(url2,header=0)\ndf_2","b986889d":"# we also have only 1 table (you can see it by clicking on the url)\n# selecting that one table\ndf2020_team = df_2[0]\n\n# load the dataset\ndf2020_team","05b96047":"# some basic info\ndf2020_team.info()","42c0ca5f":"df2020_team.drop(['Unnamed: 0'],axis=1,inplace=True)","64a0a528":"# after dropping the column\ndf2020_team.head()","fcd55abc":"So we already have scraped the first table from the specified URL.Now we will going to follow the same steps to scrap this table","059445f4":"In this notebook I am going to scrap IPL 2020 dataset with just few lines of code.So getting started towards it I am going to scrap two tables of IPL 2020 one is of point table of IPL teams and the another one is runs made by each player in IPL.Below are the table images which we are going to scrap.","a2f558cf":"![image.png](attachment:image.png)","35f4dbdc":"**If you like this notebook don't foget to upvote it :)**","eb644a02":"Now checking number of tables in our dataset","9e4f3adc":"Let's quikly check how our dataset looks like with a magic function .info() which tells us null values , dtype and shape of the dataset","29294313":"# Cleaning the dataset","d03341d3":"Changing the dtype of HS and Avg column to integer and float respectively","5ebeca0d":"So we have only 1 table in our dataset also on https:\/\/www.iplt20.com\/stats\/2020\/most-runs .So now we are going to select that one table and load it","3103c94d":"First of all we have to import all the required libraries","f4c50c26":"From above we can see that in HS column their is * which is unwanted so we are going to remove that","67932887":"Now we are going to read HTML webpage using read_html()","2923e78d":"**So here we are ,finally we have scraped the first table in just few lines of code also we have cleaned it up.Now we are going to scrap another table from https:\/\/www.iplt20.com\/points-table\/2020n** ","75866070":"# First dataset","37c127d1":"# Second Dataset","59fd14dd":"We don't have any null value in this dataset but we can see that we have a column named 'Unnamed: 0' which we do not require.So we are going to drop this column","d4ddc3b4":"# Import Libraries","579597bc":"In Avg column their are '-' in place of NaN value.So we will replace '-' to NaN and then will convert the dtype of the column.","aff29cf8":"![image.png](attachment:image.png)"}}