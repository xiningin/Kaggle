{"cell_type":{"e7b7abf9":"code","62e808fe":"code","603bac10":"code","e9238199":"code","feb2da28":"code","3a273feb":"code","4e848233":"code","faa37428":"code","1636bb24":"code","968c89fe":"code","0de11186":"code","2501f6a6":"code","ce5f6674":"code","2067110a":"code","c1d7a41b":"code","5ca5ba08":"code","1d22d677":"code","449f51b3":"markdown"},"source":{"e7b7abf9":"# Import the required libraries\n\nimport os\nimport random\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","62e808fe":"# Store the base directory path\n\nbase_dir = os.path.join(\"\/kaggle\/input\/kermany2018\/oct2017\/OCT2017 \/\")\nprint('Base directory --> ', os.listdir(base_dir))","603bac10":"# Store the train, validation and test directory paths\n\ntrain_dir = os.path.join(base_dir + \"train\/\")\nprint(\"Train Directory --> \", os.listdir(train_dir))\n\nvalidation_dir = os.path.join(base_dir + \"val\/\")\nprint(\"Validation Directory --> \", os.listdir(validation_dir))\n\ntest_dir = os.path.join(base_dir + \"test\/\")\nprint(\"Test Directory --> \", os.listdir(test_dir))","e9238199":"# Plot each type of image in the dataset\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 10))\n\ndrusen = random.choice(os.listdir(train_dir + \"DRUSEN\"))\ndrusen_image = load_img(train_dir + \"DRUSEN\/\" + drusen)\nax[0].imshow(drusen_image)\nax[0].set_title(\"DRUSEN\")\nax[0].axis(\"Off\")\n\ndme = random.choice(os.listdir(train_dir + \"DME\"))\ndme_image = load_img(train_dir + \"DME\/\" + dme)\nax[1].imshow(dme_image)\nax[1].set_title(\"DME\")\nax[1].axis(\"Off\")\n\ncnv = random.choice(os.listdir(train_dir + \"CNV\"))\ncnv_image = load_img(train_dir + \"CNV\/\" + cnv)\nax[2].imshow(cnv_image)\nax[2].set_title(\"CNV\")\nax[2].axis(\"Off\")\n\nnormal = random.choice(os.listdir(train_dir + \"NORMAL\"))\nnormal_image = load_img(train_dir + \"NORMAL\/\" + normal)\nax[3].imshow(normal_image)\nax[3].set_title(\"NORMAL\")\nax[3].axis(\"Off\")\n\nplt.show()","feb2da28":"INPUT_SHAPE = (150, 150, 3)","3a273feb":"model = tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = INPUT_SHAPE),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Flatten(),\n    \n    tf.keras.layers.Dense(4, activation = 'softmax')\n])\n            ","4e848233":"model.summary()","faa37428":"metrics_list = ['accuracy',\n                tf.keras.metrics.AUC(),\n                tfa.metrics.CohenKappa(num_classes = 4),\n                tfa.metrics.F1Score(num_classes = 4)]","1636bb24":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = metrics_list)","968c89fe":"train_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 100)","0de11186":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 16)","2501f6a6":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 44)","ce5f6674":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch = (83484\/100),\n    epochs = 10,\n    validation_data = validation_generator,\n    validation_steps = (32\/16),\n    verbose = 1)","2067110a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(7,7))\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (7,7))\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","c1d7a41b":"model.predict(test_generator, steps = int(968\/44))","5ca5ba08":"model.evaluate(test_generator)","1d22d677":"from sklearn.metrics import confusion_matrix, classification_report\nimport pandas as pd\n\nY_pred = model.predict(test_generator, int(968\/44))\ny_pred = np.argmax(Y_pred, axis = 1)\n\ncm = confusion_matrix(test_generator.classes, y_pred)\ndf_cm = pd.DataFrame(cm, list(test_generator.class_indices.keys()), list(test_generator.class_indices.keys()))\n\nfig, ax = plt.subplots(figsize = (10,8))\nsns.set(font_scale = 1.4) # for label size\nsns.heatmap(df_cm, annot = True, annot_kws = {\"size\": 16}, cmap = plt.cm.Blues)\nplt.title('Confusion Matrix\\n')\nplt.savefig('confusion_matrix.png', transparent = False, bbox_inches = 'tight', dpi = 400)\nplt.show()\n\nprint('Classification Report\\n')\ntarget_names = list(test_generator.class_indices.keys())\nprint(classification_report(test_generator.classes, y_pred, target_names = target_names))","449f51b3":"**This Notebook implements a 2 layer CNN on OCT images to classify the type of disease present in that image**"}}