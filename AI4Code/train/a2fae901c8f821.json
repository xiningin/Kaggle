{"cell_type":{"618e0eed":"code","0c37564d":"code","bf20d97f":"code","811bf754":"code","30dbd504":"code","b1f8b291":"code","17a73bde":"code","51d85dae":"code","bc94d752":"code","e00d982c":"code","f11a6ba1":"code","0dc4fd72":"code","cf2cd444":"code","a1cdd1f5":"code","26688f92":"code","a18332a3":"code","22a6b5f9":"code","d9e4950e":"code","25c03b53":"code","24477a46":"markdown","e4a38c90":"markdown","9ea41d56":"markdown","59ec1166":"markdown","206f39c5":"markdown","e9039190":"markdown","ea1a099c":"markdown","95078f04":"markdown"},"source":{"618e0eed":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom numba import jit\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom sklearn.cluster import KMeans\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"..\/input\"))\n\n","0c37564d":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n","bf20d97f":"# Descriptive statistics train\n# shape\nprint(train.shape)\n# types\nprint(train.dtypes)\n# info\nprint(train.info())\n# head\nprint(train.head(10))\n# descriptions, change precision to 2 places\nset_option('precision', 1)\ntrain.describe()","811bf754":"# Descriptive statistics test\n# shape\nprint(test.shape)\n# types\nprint(test.dtypes)\n# info\nprint(test.info())\n# head\nprint(test.head(10))\n# descriptions, change precision to 2 places\nset_option('precision', 1)\ntest.describe()","30dbd504":"# Analyzing missing values train\nprint(train.isnull().sum())","b1f8b291":"# Analyzing missing values test\nprint(test.isnull().sum())","17a73bde":"#Data visualization\nsns.countplot(train['target'])","51d85dae":"train.iloc[:,2:10].hist()\ntrain.iloc[:,11:20].hist()\ntrain.iloc[:,21:30].hist()\ntrain.iloc[:,31:40].hist()\ntrain.iloc[:,41:50].hist()\ntrain.iloc[:,51:60].hist()\ntrain.iloc[:,61:70].hist()\ntrain.iloc[:,71:80].hist()\ntrain.iloc[:,81:90].hist()\ntrain.iloc[:,101:110].hist()\ntrain.iloc[:,111:120].hist()\ntrain.iloc[:,121:130].hist()\ntrain.iloc[:,131:140].hist()\ntrain.iloc[:,141:150].hist()\ntrain.iloc[:,151:160].hist()\ntrain.iloc[:,161:170].hist()\ntrain.iloc[:,171:180].hist()\ntrain.iloc[:,181:190].hist()\ntrain.iloc[:,191:200].hist()\npyplot.show()","bc94d752":"test.iloc[:,1:10].hist()\ntest.iloc[:,11:20].hist()\ntest.iloc[:,21:30].hist()\ntest.iloc[:,31:40].hist()\ntest.iloc[:,41:50].hist()\ntest.iloc[:,51:60].hist()\ntest.iloc[:,61:70].hist()\ntest.iloc[:,71:80].hist()\ntest.iloc[:,81:90].hist()\ntest.iloc[:,101:110].hist()\ntest.iloc[:,111:120].hist()\ntest.iloc[:,121:130].hist()\ntest.iloc[:,131:140].hist()\ntest.iloc[:,141:150].hist()\ntest.iloc[:,151:160].hist()\ntest.iloc[:,161:170].hist()\ntest.iloc[:,171:180].hist()\ntest.iloc[:,181:190].hist()\ntest.iloc[:,191:199].hist()\npyplot.show()","e00d982c":"# some baseline features\ntrain['max'] = train.max(axis=1)\ntrain['min'] = train.min(axis=1)\ntrain['mean'] = train.mean(axis=1)\ntrain['sd'] = train.std(axis=1)\ntest['max'] = test.max(axis=1)\ntest['min'] = test.min(axis=1)\ntest['mean'] = test.mean(axis=1)\ntest['sd'] = test.std(axis=1)","f11a6ba1":"train.head()","0dc4fd72":"test.head()","cf2cd444":"@jit\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t\/\/2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","a1cdd1f5":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.335,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.041,\n    'learning_rate': 0.0083,\n    'max_depth': -1,\n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': -1\n}","26688f92":"#kfold = 15\n#folds = StratifiedKFold(n_splits=kfold, shuffle=False, random_state=44000)\nnum_folds = 11\nfeatures = [c for c in train.columns if c not in ['ID_code', 'target']]\n\nfolds = KFold(n_splits=num_folds, random_state=2319)\noof = np.zeros(len(train))\ngetVal = np.zeros(len(train))\npredictions = np.zeros(len(train.target))\nfeature_importance_df = pd.DataFrame()","a18332a3":"for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, train.target.values)):\n    \n    X_train, y_train = train.iloc[trn_idx][features], train.target.iloc[trn_idx]\n    X_valid, y_valid = train.iloc[val_idx][features], train.target.iloc[val_idx]\n    \n    X_tr, y_tr = augment(X_train.values, y_train.values)\n    X_tr = pd.DataFrame(X_tr)\n    \n    print(\"Fold idx:{}\".format(fold_ + 1))\n    trn_data = lgb.Dataset(X_tr, label=y_tr)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    \n    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) \/ folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) \/ folds.n_splits","22a6b5f9":"print(\"\\n >> CV score: {:<8.5f}\".format(roc_auc_score(train.target, oof)))","d9e4950e":"submission = pd.DataFrame({\"ID_code\": test.ID_code.values})\nsubmission[\"target\"] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)","25c03b53":"submission.head()","24477a46":"<a id=1><pre><b>Classification augment<\/b><\/pre><\/a>","e4a38c90":"# Build the Light GBM Model","9ea41d56":"<a id=1><pre><b>Load Packages<\/b><\/pre><\/a>","59ec1166":"<a id=1><pre><b>Parameters<\/b><\/pre><\/a>","206f39c5":"<a id=1><pre><b>Import the Data<\/b><\/pre><\/a>","e9039190":"# Submission","ea1a099c":"<h1><center><font size=\"6\">Santander Customer Transaction Prediction<\/font><\/center><\/h1>\n\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/4\/4a\/Another_new_Santander_bank_-_geograph.org.uk_-_1710962.jpg\/640px-Another_new_Santander_bank_-_geograph.org.uk_-_1710962.jpg\" width=\"500\"><\/img>\n\n<br>\n<b>\n    \nInspired from https:\/\/www.kaggle.com\/jesucristo\/santander-magic-lgb-0-901.<\/b>\n     \n","95078f04":"<a id=1><pre><b>Run LGBM model<\/b><\/pre><\/a>"}}