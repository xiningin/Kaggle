{"cell_type":{"05a72a6d":"code","f63b2b77":"code","ee1bf4e3":"code","2cb0c7ba":"code","3bf98278":"code","dc310ae0":"code","7405f6ac":"code","3b1129ce":"code","383ed122":"code","b85b966e":"code","9aa55072":"code","dd93f173":"code","66d07992":"code","20a89900":"code","89444f3b":"code","64bb689e":"code","bccef8de":"code","4dccfaa1":"code","af0d2393":"code","15c55a91":"code","4c3aed08":"code","6b8c38f8":"code","a600e9d6":"code","86eaa236":"code","eb4fb94d":"code","18a7818c":"code","441090d8":"code","166801b3":"code","b4e6d5e8":"code","5fd33469":"code","22af9405":"code","d8c9a791":"code","5e08524f":"code","df9ee73f":"code","5ba215a7":"code","ec275e9a":"code","0ad36f9a":"code","7df3c9c5":"code","66350020":"code","cbbaed12":"code","d750e31f":"code","30b93282":"code","893bd495":"code","b863eb2d":"code","9a5e2370":"code","d7b130d1":"code","4d400963":"code","905acbd3":"code","4f5726b4":"code","67540921":"code","2d0eb932":"code","5a8ed1ce":"code","919aae34":"code","d148193a":"code","7ac2a49e":"code","fcdd8315":"code","a9810c9c":"code","ee3163ac":"code","63e453b5":"code","d8c73b99":"code","698621af":"code","36654012":"code","36142f1f":"code","6e8e229f":"code","e8f943ae":"code","9362132f":"code","e926d685":"code","655b2c05":"code","51d4e773":"code","f56bbbe8":"code","940ed259":"code","ea3bf086":"code","1742a78f":"code","6063cbee":"code","3a09464f":"code","9d69f7c5":"markdown","bcb30c5b":"markdown","01b1932c":"markdown","d3cbec22":"markdown","f3862851":"markdown","d8c23590":"markdown","296ae9f2":"markdown","0abc4511":"markdown","47b2d883":"markdown","45fbbbbc":"markdown","3f6bf623":"markdown","52795826":"markdown","c0a59da1":"markdown","bd69fc78":"markdown","40d19c67":"markdown","ce0bf103":"markdown","9782661a":"markdown","e9f64939":"markdown","29a2a319":"markdown","f930289e":"markdown","a25ef6e9":"markdown","653ad163":"markdown","2ce40f9a":"markdown","08fbbf84":"markdown","adee95f3":"markdown","c3256b9b":"markdown","924d5511":"markdown","9536a298":"markdown","a6bd86b1":"markdown","fef2ea05":"markdown","f4da7743":"markdown","a96234cb":"markdown","935fe9a6":"markdown","fa92c501":"markdown","365bf937":"markdown","b4d83a79":"markdown","a9b693ad":"markdown","5dc704e0":"markdown","bba829b5":"markdown","fcdbe6c9":"markdown","10de24db":"markdown","9bb05d23":"markdown","fea62091":"markdown"},"source":{"05a72a6d":"# importing and file list\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom datetime import datetime, time\nfrom datetime import date\nimport holidays\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f63b2b77":"df = pd.read_csv(\"\/kaggle\/input\/hr-analytics-case-study\/in_time.csv\")\ndf.rename(columns={\"Unnamed: 0\":\"EmployeeID\"},inplace=True)\n\nus_holidays = holidays.US()\n\nholiday_list = []\nfor day in df.columns[1:]:\n    if (day in us_holidays):\n        holiday_list.append(day)\n\ntmp = df.isna().sum().sort_values(ascending=False)\ntmp = tmp[tmp == 4410].index.tolist()\n\nholiday_list = tmp + list(set(holiday_list) - set(tmp))\n\ndf = df.drop(holiday_list,axis=1)\n\n# Datetime tipine convert edildi.\ndf.iloc[:,1:] = df.iloc[:,1:].apply(pd.to_datetime)\n\nlate_entering = df.iloc[:,1:].T.apply(lambda dt : dt.dt.time > time(10,1,1)).sum()\nearly_entering = df.iloc[:,1:].T.apply(lambda dt : dt.dt.time < time(10,1,1)).sum()\n\ndf[\"late_entering\"] = late_entering\ndf[\"early_entering\"] = early_entering\n\n# Gelmedi\u011fi g\u00fcnlerin say\u0131s\u0131\ndf[\"not_come\"] = df.T.isna().sum()\n\ndf_in = df.iloc[:,1:-3].T\ndf_intime = df[[\"EmployeeID\",\"late_entering\",\"early_entering\",\"not_come\"]]\ndf.head(3)","ee1bf4e3":"# Sabah ba\u015flama Saati belirlenmesi\ndf[\"2015-01-05\"].hist(figsize=(10,5))","2cb0c7ba":"df = pd.read_csv(\"\/kaggle\/input\/hr-analytics-case-study\/out_time.csv\")\ndf.rename(columns={\"Unnamed: 0\":\"EmployeeID\"},inplace=True)\n\nus_holidays = holidays.US()\n\nholiday_list = []\nfor day in df.columns[1:]:\n    if (day in us_holidays):\n        holiday_list.append(day)\nlen(holiday_list)\ntmp = df.isna().sum().sort_values(ascending=False)\ntmp = tmp[tmp == 4410].index.tolist()\n\nholiday_list = tmp + list(set(holiday_list) - set(tmp))\n\ndf = df.drop(holiday_list,axis=1)\n\n# Datetime tipine convert edildi.\ndf.iloc[:,1:] = df.iloc[:,1:].apply(pd.to_datetime)\n\nlate_exit = df.iloc[:,1:].T.apply(lambda dt : dt.dt.time > time(17,1,1)).sum()\nearly_exit = df.iloc[:,1:].T.apply(lambda dt : dt.dt.time < time(17,1,1)).sum()\ndf[\"late_exit\"] = late_exit\ndf[\"early_exit\"] = early_exit\n\ndf_out = df.iloc[:,1:-3].T\ndf_outtime = df[[\"EmployeeID\",\"late_exit\",\"early_exit\"]]\ndf.head(3)","3bf98278":"# Calisma Saati \u00d6zellik \u00e7\u0131kar\u0131m\u0131\ndf_cal = (df_out - df_in).mean()\ndf_intime[\"working_hours\"] = df_cal.apply( lambda x : x \/ np.timedelta64(1, 'h') )","dc310ae0":"# Biti\u015f Saati belirlenmesi\ndf[\"2015-01-05\"].hist(figsize=(10,5))","7405f6ac":"general_data=pd.read_csv('\/kaggle\/input\/hr-analytics-case-study\/general_data.csv')\nemployee_survey_data=pd.read_csv('\/kaggle\/input\/hr-analytics-case-study\/employee_survey_data.csv')\nmanager_survey_data=pd.read_csv('\/kaggle\/input\/hr-analytics-case-study\/manager_survey_data.csv')\n\ngeneral_data.set_index('EmployeeID', inplace=True)\nemployee_survey_data.set_index('EmployeeID', inplace=True)\nmanager_survey_data.set_index('EmployeeID', inplace=True)\ndf_intime.set_index(\"EmployeeID\", inplace=True)\ndf_outtime.set_index(\"EmployeeID\", inplace=True)\n\ndata=pd.concat([general_data,employee_survey_data,manager_survey_data,df_intime,df_outtime],axis=1)\ndata","3b1129ce":" data.info()","383ed122":"data.isna().sum()","b85b966e":"data.loc[data[\"NumCompaniesWorked\"].isna(),\"NumCompaniesWorked\"] = 0\ndata.loc[data[\"NumCompaniesWorked\"].isna()]","9aa55072":"data.loc[data[\"TotalWorkingYears\"].isna()]\ndata.loc[data[\"TotalWorkingYears\"].isna(),\"TotalWorkingYears\"] = 0\n\nsns.histplot(data, x= \"TotalWorkingYears\")","dd93f173":"data[\"EnvironmentSatisfaction\"].hist()\ndata.loc[data[\"EnvironmentSatisfaction\"].isna(),\"EnvironmentSatisfaction\"] = 3","66d07992":"data[\"JobSatisfaction\"].hist()\ndata.loc[data[\"JobSatisfaction\"].isna(),\"JobSatisfaction\"] = 3","20a89900":"\ndata[\"WorkLifeBalance\"].hist()\ndata.loc[data[\"WorkLifeBalance\"].isna(),\"WorkLifeBalance\"] = 3","89444f3b":"data.info()","64bb689e":"# TO-DO will refactor this func\ndef drw_per(ax):\n    bars = ax.patches\n    half = int(len(bars)\/2)\n    left_bars = bars[:half]\n    right_bars = bars[half:]\n\n    for left, right in zip(left_bars, right_bars):\n        height_l = left.get_height()\n        height_r = right.get_height()\n        total = height_l + height_r\n\n        ax.text(left.get_x() + left.get_width()\/2., height_l + 40, '{0:.0%}'.format(height_l\/total), ha=\"center\")\n        ax.text(right.get_x() + right.get_width()\/2., height_r + 40, '{0:.0%}'.format(height_r\/total), ha=\"center\")","bccef8de":"data.groupby(\"BusinessTravel\").groups.keys()","4dccfaa1":"plt.figure(figsize=(8,6))\ndf = data[data[\"Attrition\"] == \"Yes\" ]\n\nax = sns.countplot(x='BusinessTravel', data= df, hue=\"Attrition\")\n","af0d2393":"data.groupby(\"Department\").groups.keys()","15c55a91":"plt.figure(figsize=(6,4))\ndf = data[data[\"Attrition\"] == \"Yes\"]\nax = sns.countplot(x='Department', data=df, hue=\"Attrition\")\n","4c3aed08":"data.columns","6b8c38f8":"data[\"DistanceFromHome\"].describe()","a600e9d6":"plt.figure(figsize=(8,6))\nax = sns.histplot(x='DistanceFromHome', data=data[ data[\"Attrition\"] == \"Yes\"])\n","86eaa236":"data[[\"Education\"]].value_counts()","eb4fb94d":"plt.figure(figsize=(8,6))\nax = sns.countplot(x='Education', data=data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")","18a7818c":"df = data.groupby(\"Education\")\ndf.groups.keys()","441090d8":"plt.figure(figsize=(20,10))\nn_cols = 3\nn_rows = 2\ni = 1\nfor key, grp in df:\n    plt.subplot(n_rows,n_cols,i)\n    i = i + 1\n    ax = sns.countplot(x='Education', data=grp, hue=\"EducationField\")\n    #drw_per(ax)","166801b3":"data.columns","b4e6d5e8":"plt.figure(figsize=(4,3))\nax = sns.countplot(x='Gender', data=data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")\ndrw_per(ax)","5fd33469":"data.columns","22af9405":"data[\"JobLevel\"].value_counts()","d8c9a791":"data[\"JobRole\"].value_counts()","5e08524f":"df = data.groupby(\"JobRole\")\nprint(len(df.groups.keys()))\ndf.groups.keys()","df9ee73f":"plt.figure(figsize=(16,8))\n\nax = sns.countplot(x='JobRole', data=data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")\n#drw_per(ax)","5ba215a7":"data.columns","ec275e9a":"plt.figure(figsize=(8,6))\nax = sns.countplot(x='MaritalStatus', data=data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")","0ad36f9a":"data[\"MonthlyIncome\"].describe()","7df3c9c5":"plt.subplot(1,2,1)\nsns.histplot(x='MonthlyIncome', data=data.loc[data[\"Attrition\"] == \"Yes\"])\n\nplt.subplot(1,2,2)\nsns.histplot(x='MonthlyIncome', data=data.loc[data[\"Attrition\"] == \"No\"])","66350020":"data.columns","cbbaed12":"data[\"NumCompaniesWorked\"].value_counts()","d750e31f":"df = data.groupby(\"NumCompaniesWorked\")\ndf.groups.keys()","30b93282":"plt.figure(figsize=(8,4))\nax = sns.countplot(x='NumCompaniesWorked', data= data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")","893bd495":"data.columns","b863eb2d":"plt.figure(figsize=(8,4))\nsns.countplot(x='PercentSalaryHike',data= data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")","9a5e2370":"data[\"TotalWorkingYears\"].value_counts()","d7b130d1":"plt.figure(figsize=(8,4))\nsns.countplot(x='TotalWorkingYears',data= data[ data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")","4d400963":"data.columns","905acbd3":"data[\"TrainingTimesLastYear\"].value_counts()","4f5726b4":"plt.figure(figsize=(8,4))\nax = sns.countplot(x=\"TrainingTimesLastYear\", data= data[ data[\"Attrition\"] == \"Yes\"] , hue=\"Attrition\")","67540921":"data[\"YearsAtCompany\"].describe()","2d0eb932":"plt.figure(figsize=(16,4))\nax = sns.countplot( x= \"YearsAtCompany\", data=data[data[\"Attrition\"] == \"Yes\"],hue=\"Attrition\")","5a8ed1ce":"data.columns","919aae34":"data[\"YearsWithCurrManager\"].value_counts()","d148193a":"plt.figure(figsize=(16,4))\nax = sns.countplot( x= \"YearsWithCurrManager\", data=data[data[\"Attrition\"] == \"Yes\"], hue=\"Attrition\")","7ac2a49e":"plt.figure(figsize=(16,4))\ndf = data[ data[\"Attrition\"] == \"Yes\"]\nplt.subplot(1,3,1)\nax = sns.countplot( x= \"EnvironmentSatisfaction\", data=df,hue=\"Attrition\")\n\nplt.subplot(1,3,2)\nax = sns.countplot( x= \"JobSatisfaction\", data=df,hue=\"Attrition\")\n\nplt.subplot(1,3,3)\nax = sns.countplot( x= \"WorkLifeBalance\", data=df,hue=\"Attrition\")\n","fcdd8315":"plt.figure(figsize=(16,8))\ndf = data[ data[\"Attrition\"] == \"Yes\"]\n\nplt.subplot(1,3,1)\nax = sns.countplot( x= \"JobInvolvement\", data=df,hue=\"Attrition\")\n\nplt.subplot(1,3,2)\nax = sns.countplot( x= \"PerformanceRating\", data=df,hue=\"Attrition\")\n\n","a9810c9c":"# imports \nfrom scipy.stats import sem\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_validate,RepeatedKFold,RepeatedStratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix,roc_auc_score,plot_roc_curve\nfrom sklearn import datasets, metrics, model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","ee3163ac":"data.replace({'Yes':1,'No':0},inplace=True)\nX = data.drop(['Attrition','Over18','StandardHours','EmployeeCount'],axis=1)\nY = data['Attrition']\nX = pd.get_dummies(X)\n\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, shuffle= True)","63e453b5":"def get_classifiers_models_scores_with_CV(X,Y,n_split=5, n_repeats = 5):\n    classifiers = [\n    LogisticRegression(C = 0.1, penalty= 'l2', solver= 'newton-cg'), # This parameters found with above hyperparameter optimizatiob\n    XGBClassifier(objective=\"binary:logistic\"),\n    CatBoostClassifier(verbose=0),\n    LGBMClassifier(),\n    SVC()\n    ]\n    estimators = []\n    name = []\n    acc = []\n    recall = []\n    precision = []\n    f1 = []\n    roc_auc = []\n   \n    se = []\n    cv = RepeatedStratifiedKFold(n_splits=n_split, n_repeats=n_repeats, random_state= 42)\n    scoring = [\"roc_auc\",\"accuracy\",\"recall\",\"precision\",\"f1\"]\n\n    for clf in classifiers:\n        \n        name.append(type(clf).__name__)\n\n        scores = cross_validate(clf,X,Y,cv=cv, scoring=scoring) #, n_jobs=-1\n\n        acc.append(scores[\"test_accuracy\"].mean())\n        recall.append(scores[\"test_recall\"].mean())\n        precision.append(scores[\"test_precision\"].mean())\n        f1.append(scores[\"test_f1\"].mean())\n        roc_auc.append(scores[\"test_roc_auc\"].mean())\n  \n        # standard_error = sample_standard_deviation \/ sqrt(number of repeats)\n        se.append(sem( (scores[\"test_roc_auc\"] ) ))\n\n        estimators.append(clf.fit(x_train,y_train))\n        \n\n    \n    models = pd.DataFrame({\n        'Estimator': estimators,\n        'Model': name,\n        'Accuracy': acc,\n        'Recall': recall,\n        'Precision':precision,\n        'F1':f1,\n        'ROC_AUC': roc_auc,\n        'SE':se\n        })\n\n\n    return models.sort_values(by='ROC_AUC', ascending=False)\n\ndef print_score(y_test,y_pred):\n    print(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, y_pred) * 100.0))\n    print(\"Precision: \",precision_score(y_test, y_pred))\n    print(\"Recall: \",recall_score(y_test, y_pred))\n    print(\"F1 Score: \",f1_score(y_test, y_pred))\n    print(\"ROC_AUC :\", roc_auc_score(y_test, y_pred))","d8c73b99":"%%time\nmodels = get_classifiers_models_scores_with_CV(X,Y)","698621af":"# sort scores with ROC_AUC \nmodels ","36654012":"# Select model that fitted with train data for result analysis\nmdl = models.loc[0,\"Estimator\"] # select LogisticRegression fitted model\nmdl\nprint_score(y_test, mdl.predict(x_test))","36142f1f":"plot_confusion_matrix(mdl, x_test, y_test)","6e8e229f":"plot_roc_curve(mdl, x_test, y_test)","e8f943ae":"# example of grid searching key hyperparametres for logistic regression\nfrom sklearn.model_selection import GridSearchCV\n\n\nmodel = LogisticRegression()\nsolvers = ['newton-cg', 'lbfgs', 'liblinear',\"sag\", \"saga\"]\npenalty = ['l2']\nc_values = [100, 10, 1.0, 0.1, 0.01]\n\n\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, cv=cv, scoring='roc_auc',error_score=0)\ngrid_result = grid_search.fit(X, Y)\n\nprint(\"Best F1 Score: %f using parameter %s\" % (grid_result.best_score_, grid_result.best_params_))\n\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nresults = (means,stds,params)\n","9362132f":"print(\"Best ROC_AUC Score: %f using parameter %s\" % (grid_result.best_score_, grid_result.best_params_))","e926d685":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.model_selection import cross_validate,RepeatedKFold\n\n\nmodel = LogisticRegression()\n\ncv_model = cross_validate(\n    model, X, Y, cv=RepeatedKFold(n_splits=5, n_repeats=5),\n    return_estimator=True, n_jobs=-1\n)\ncoefs = []\nfor est in cv_model['estimator']:\n    if(len(est.coef_) != 0 ):\n        coefs.append( est.coef_[0] * x_train.std(axis=0))\n        \n\ncoefs = pd.DataFrame(coefs,\n    columns=X.columns\n)\n\nplt.figure(figsize=(9, 30))\nsns.stripplot(data=coefs, orient='h', alpha=0.5)\nsns.boxplot(data=coefs, orient='h', saturation=0.5)\nplt.axvline(x=0, color='.5')\nplt.xlabel('Coefficient importance')\nplt.title('Coefficient importance and its variability')","655b2c05":"# Show feature coefficent values at top 20\ncoefs.apply(np.abs).mean().sort_values(ascending=False).head(20)","51d4e773":"from sklearn.ensemble import GradientBoostingClassifier, RandomForestRegressor\nfrom sklearn import tree\nimport time\n\n\ncols_for_drop = [] \nfeature_names = x_train.drop(columns=cols_for_drop).columns\nmodel = XGBClassifier()\nmodel.fit(x_train.drop(columns=cols_for_drop),y_train)","f56bbbe8":"from sklearn.inspection import permutation_importance\n\nresult = permutation_importance(\n    model, x_test.drop(columns=cols_for_drop), y_test, n_repeats=10, random_state=42, n_jobs=-1)\n\nforest_importances = pd.Series(result.importances_mean, index=feature_names)\nplt.figure(figsize=(30,10))\nforest_importances.plot.bar(yerr=result.importances_std)","940ed259":"#result = permutation_importance(model, x_train.drop(columns=cols_for_drop), y_train, n_repeats=10,random_state=42)\n\nperm_sorted_idx = result.importances_mean.argsort()\n\nplt.figure(figsize=(15, 20))\n\nplt.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n            labels=feature_names[perm_sorted_idx])\nplt.tight_layout()\nplt.show()","ea3bf086":"from xgboost import plot_importance,plot_tree\n\nplt.rcParams[\"figure.figsize\"] = (14, 14)\nplot_importance(model)\n","1742a78f":"from matplotlib.pylab import rcParams\n\nplt.rcParams[\"figure.figsize\"] = (250, 500)\nplot_tree(model)","6063cbee":"# use feature importance for feature selection\n\nfrom numpy import sort\nfrom sklearn.feature_selection import SelectFromModel\n\n\nmodel = XGBClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\npredictions = [round(value) for value in y_pred]\n\nthresholds = sort(model.feature_importances_)\n\nacc = []\nroc = []\nrecall = []\nprecision = []\nf1 = []\ntreshold = []\ndiff = []\n\nfor thresh in thresholds:\n    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n    select_X_train = selection.transform(x_train)\n    selection_model = XGBClassifier()\n    selection_model.fit(select_X_train, y_train)\n    select_X_test = selection.transform(x_test)\n    \n    acc.append(accuracy_score(y_test, predictions))\n    roc.append(roc_auc_score(y_test, predictions))\n    recall.append(recall_score(y_test, predictions))\n    precision.append(precision_score(y_test, predictions))\n    f1.append(f1_score(y_test, predictions))\n    features = list(x_train.columns[selection.get_support()])\n    treshold.append(features)\n    diff.append( list(set(x_train.columns) - set(features)) )\n\n    y_pred = selection_model.predict(select_X_test)\n    \n    predictions = [round(value) for value in y_pred]\n    accuracy = accuracy_score(y_test, predictions)\n    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n\nmodels = pd.DataFrame({\n        'Model': treshold,\n        'Diff':diff,\n        'Accuracy': acc,\n        'Recall': recall,\n        'Precision':precision,\n        'F1':f1,\n        'ROC_AUC': roc\n        })","3a09464f":"models","9d69f7c5":"[Xgboost Plot Importance](https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#xgboost.plot_importance)","bcb30c5b":"#### Observation\n\n- Most employees who left worked for 1 year","01b1932c":"# Feature \u0130mportance and Selection","d3cbec22":"#### Observation\n\n- Most employees who left is near office","f3862851":"### YearsWithCurrManager","d8c23590":"### Result Analysis ","296ae9f2":"# Training","0abc4511":"### TotalWorkingYears","47b2d883":"## Feature Selection","45fbbbbc":"### Hyperparameter Optimization for Logistic Regression","3f6bf623":"### EnvironmentSatisfaction & JobSatisfaction &  WorkLifeBalance","52795826":"# Feature Extraction with In-time and Out-Time data \n\n- [x] number of days off work\n- [x] number of late arrivals for work\n- [x] number of early arrivals for work\n- [x] number of late departures from work\n- [x] number of early departures from work\n- [x] mean working hours","c0a59da1":"### BusinessTravel","bd69fc78":"#### Observation\n\n- Most employees who left is male","40d19c67":"[Feature importance based on feature permutation](https:\/\/scikit-learn.org\/stable\/auto_examples\/ensemble\/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py)","ce0bf103":"#### Observation\n\n- Most employees who left worked in Research & Development","9782661a":"#### Observation\n\n- Most employees roles who left  is Research_Scientist, Sales Executive, Laboratory Technician","e9f64939":"## With LogisticRegression\n\n[plot_linear_model_coefficient_interpretation](https:\/\/scikit-learn.org\/stable\/auto_examples\/inspection\/plot_linear_model_coefficient_interpretation.html#checking-the-variability-of-the-coefficients)","29a2a319":"### Department","f930289e":"#### Observation\n\n- Most employees who left is Single, also married people are not less","a25ef6e9":"# Train Models Results","653ad163":"### MonthlyIncome","2ce40f9a":"# Train Models","08fbbf84":"#### Observation\n\n- Most employees who left worked for 1 year at company","adee95f3":"#### Observation\n\n- Most employees who left is who travel rarely\n","c3256b9b":"## With XGBClassifier ","924d5511":"### Imports","9536a298":"# Missing Values","a6bd86b1":"# DistanceFromHome","fef2ea05":"### YearsAtCompany","f4da7743":"#### Observation\n\n- Most employees who left worked for 1 year","a96234cb":"### Education","935fe9a6":"### Gender","fa92c501":"### TrainingTimesLastYear","365bf937":"#### Observation\n\n- Most employees who left has 3, 4 education level\n- Least employees who left has 5 education level","b4d83a79":"### NumCompaniesWorked","a9b693ad":"#### Observation\n\n- Employees who left environments satisfaction and Job Satisfaction varies.\n- Employees who left has normal Work Life Balance  ","5dc704e0":"- [Understanding the decision tree structure](https:\/\/scikit-learn.org\/stable\/auto_examples\/tree\/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py)\n- [Xgboost Plot Tree](https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#xgboost.plot_tree)","bba829b5":"# Exploration Data Analysis","fcdbe6c9":"### Preprocessing for Traning","10de24db":"### JobInvolvement & PerformanceRating","9bb05d23":"## Utils Funcs","fea62091":"### PercentSalaryHike"}}