{"cell_type":{"551d39dc":"code","0a5948c7":"code","17db2950":"code","f5aa066a":"code","08842605":"code","e7b58089":"code","3e61a126":"code","3f4b39d9":"code","f7252af5":"code","6527ee94":"code","7f4fd45c":"code","1dbe41b2":"code","261bd5b9":"code","cebdcd94":"code","6bc87265":"code","2d51be8f":"code","4ec95006":"code","c154c89a":"code","e11c8f24":"code","a44be4a9":"code","9269cedd":"code","3a9e8984":"code","0d01d334":"code","b6921e9e":"code","c8f37fa2":"code","5c5676b9":"code","52daac05":"code","5c9c0ee5":"code","8d199118":"code","d0a88906":"code","7c05cb07":"code","3a30c282":"code","a8640e97":"code","4e1e31d7":"code","6827dbfc":"code","52532a23":"code","300160e3":"code","bf4a3ec1":"code","99de9e70":"code","c23590c5":"code","ba95a5e7":"markdown"},"source":{"551d39dc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a5948c7":"df = pd.read_csv('..\/input\/vehicle-dataset-from-cardekho\/car data.csv')","17db2950":"df.head()","f5aa066a":"df.info()","08842605":"df.shape","e7b58089":"print(df['Seller_Type'].unique())\nprint(df['Transmission'].unique())\nprint(df['Owner'].unique())","3e61a126":"## Check Missing and Null Value\ndf.isnull().sum()","3f4b39d9":"df.describe()","f7252af5":"df.columns","6527ee94":"final_dataset =df[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]","7f4fd45c":"final_dataset.head()","1dbe41b2":"#Add a new column \"Current_Year\" in the dataframe\nfinal_dataset['Current_Year']=2020","261bd5b9":"final_dataset.head()","cebdcd94":"final_dataset['no_year'] = final_dataset['Current_Year']-final_dataset['Year']","6bc87265":"final_dataset.head()","2d51be8f":"final_dataset.drop(['Year'],axis =1,inplace=True)","4ec95006":"final_dataset.drop(['Current_Year'],axis =1,inplace=True)","c154c89a":"# drop first to avoid dummy vriable trap\nfinal_dataset= pd.get_dummies(final_dataset,drop_first=True)","e11c8f24":"final_dataset.head()","a44be4a9":"final_dataset.corr()","9269cedd":"import seaborn as sns","3a9e8984":"sns.pairplot(final_dataset)","0d01d334":"import matplotlib.pyplot as plt\n%matplotlib inline","b6921e9e":"corrmat = final_dataset.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize = (20,20))\n\n#PLot the heatmap\ng =sns.heatmap(final_dataset[top_corr_features].corr(),annot = True,cmap = 'RdYlGn')","c8f37fa2":"# independent and dependent feature\nX =final_dataset.iloc[:,1:]\ny = final_dataset.iloc[:,0]","5c5676b9":"## Feature Important\nfrom sklearn.ensemble import ExtraTreesRegressor\nmodel= ExtraTreesRegressor()\nmodel.fit(X,y)","52daac05":"print(model.feature_importances_)","5c9c0ee5":"# Plot the importance\nfeat_importance = pd.Series(model.feature_importances_,index = X.columns)\nfeat_importance.nlargest(5).plot(kind='barh')","8d199118":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.2)","d0a88906":"from sklearn.ensemble import RandomForestRegressor\nrf_random = RandomForestRegressor()","7c05cb07":"## Hyperparameter\nimport numpy as np\nn_estimators = [int(x) for x in np.linspace (start = 100, stop = 1200, num =12)]\nprint(n_estimators)","3a30c282":" #Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n\n\n","a8640e97":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","4e1e31d7":"## Use random grid to search for best hyperparameters\n## First create the base model to tune\nrf = RandomForestRegressor()","6827dbfc":"from sklearn.model_selection import RandomizedSearchCV","52532a23":"# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","300160e3":"rf_random.fit(X_train,y_train)","bf4a3ec1":"predictions=rf_random.predict(X_test)","99de9e70":"predictions","c23590c5":"sns.distplot(y_test-predictions)","ba95a5e7":"## Create a new feature using Year, because the car depreciation based on this feature aswell\n\n"}}