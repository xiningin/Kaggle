{"cell_type":{"8be17616":"code","7e843eb5":"code","02a75130":"code","1800b533":"code","2368a1c4":"code","ab880b5a":"code","727a8499":"code","01864ef1":"code","59e05f90":"code","eee3373d":"code","832065de":"code","24d0caba":"code","56d59561":"markdown","389c1cb4":"markdown","0466b031":"markdown","0ecdccf9":"markdown","4cb7d638":"markdown","c3cbf7b7":"markdown","82d6ae8c":"markdown","9c037d9e":"markdown","1f21f7be":"markdown","9c435474":"markdown","75154bdc":"markdown"},"source":{"8be17616":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport tensorflow\nimport re\nimport time \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","7e843eb5":"    \nlines=open('..\/input\/movie-conversations\/movie_lines.txt', encoding='utf-8',errors='ignore').read().split('\\n')\nconversations=open('..\/input\/movie-conversations\/movie_conversations.txt', encoding='utf-8',errors='ignore').read().split('\\n')\n","02a75130":"id2line={}\n\nfor line in lines:\n    _line=line.split(' +++$+++ ')\n    if len(_line) == 5:\n        id2line[_line[0]]=_line[4]\n        ","1800b533":"\nconversation_id=[]\n\nfor con in conversations :\n    _conversation=con.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n    conversation_id.append(_conversation.split(','))","2368a1c4":"quentions=[]\nanswers=[]\n\nfor conv in conversation_id:\n    for i in range(len(conv)-1):\n        quentions.append(id2line[conv[i]])\n        answers.append(id2line[conv[i+1]])\n        \nprint(quentions)\nprint(answers)\n        ","ab880b5a":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\"he's\", \"he is\", text)\n    text = re.sub(r\"she's\", \"she is\", text)\n    text = re.sub(r\"that's\", \"that is\", text)\n    text = re.sub(r\"what's\", \"what is\", text)\n    text = re.sub(r\"where's\", \"where is\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"won't\", \"will not\", text)\n    text = re.sub(r\"can't\", \"cannot\", text)\n    text = re.sub(r\"[-()\\\"#\/@;:<>{}+=~|.?,]\", \"\", text)\n    return text\n\n#clean clean_quentions clean_quentions \nclean_quentions=[]\nfor q in quentions:\n    clean_quentions.append(clean_text(q))\n        \n\nclean_answser=[]\nfor a in answers:\n    text=clean_text(a)\n    clean_answser.append(text)\n\n     ","727a8499":"word2count={}\n\nfor q in clean_quentions:\n    for word in q.split():\n        if word not in word2count:\n            word2count[word]=1\n        else:\n             word2count[word]+=1\n             \nfor a in  clean_answser :\n    for word in a.split():\n        if word not in word2count:\n            word2count[word]=1\n        else:\n             word2count[word]+=1","01864ef1":"number_word=0\nint_quentionword={}\nth=30\n\nfor word, count in word2count.items():\n    if(count>=th):\n        int_quentionword[word]=number_word\n        number_word+=1\n        \nnumber_word=0\nint_answerword={}\nth=30\n\nfor word, count in word2count.items():\n    if(count>=th):\n        int_answerword[word]=number_word\n        number_word+=1","59e05f90":"tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\nfor token in tokens:\n    int_quentionword[token] = len(int_quentionword) + 1\nfor token in tokens:\n    int_answerword[token] = len(int_answerword) + 1\n    ","eee3373d":"int_answerword={w_i : w for w,w_i in int_answerword.items() }\n\n#Add [EOS] for answers\nfor i in range(len(clean_answser)):\n    clean_answser[i]+=' <EOS>'\n    ","832065de":"q_2_int=[]\n\nfor q in clean_quentions:\n ints=[]\n for word in q.split():\n     if word not in int_quentionword:\n         ints.append(int_quentionword['<OUT>'])\n     else:\n         ints.append(int_quentionword[word])\n q_2_int.append(ints)\n         \nas_2_int=[]\n\nfor a in clean_answser:\n ints=[]\n for word in a.split():\n     if word not in int_answerword:\n         ints.append(int_answerword['<OUT>'])\n     else:\n         ints.append(int_answerword[word])\n as_2_int.append(ints)\n ","24d0caba":"sorted_clean_questions = []\nsorted_clean_answers = []\nfor length in range(1, 25 + 1):\n    for i in enumerate(q_2_int):\n        if len(i[1]) == length:\n            sorted_clean_questions.append(q_2_int[i[0]])\n            sorted_clean_answers.append(as_2_int[i[0]])","56d59561":"**Add the quentions and answers**\n\n\n        ","389c1cb4":"# **count word in Q and A**","0466b031":" # Sorting questions and answers by the length of questions","0ecdccf9":"# Translating all the questions and the answers into integers\n# and Replacing all the words that were filtered out by <OUT> ","4cb7d638":"# Add thrashold for count for each word ","c3cbf7b7":"# Adding the last tokens to these two dictionaries","82d6ae8c":"# Get the ID for each Quentions and answers","9c037d9e":"# *Read txt file from input file  movie lines and conversations*****","1f21f7be":"# **make invers answers **","9c435474":"**Build function to clean data and clean q and A **","75154bdc":"# Get ID for conversation"}}