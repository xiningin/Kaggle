{"cell_type":{"5fd4fe50":"code","e07c9a98":"code","0cfa3444":"code","825ec70d":"code","0ed571f1":"code","92b2b04b":"code","ab6bab2e":"code","48e1422f":"code","6ab2da50":"code","d8e7dde2":"code","6860b4a5":"code","502d1c86":"code","006a2768":"code","fca5216f":"code","eda823fe":"code","5c846a04":"code","52bb0359":"code","7441df6d":"code","91f07d18":"code","d0c3f9bf":"code","3df24fb0":"code","a9a5fd2a":"code","10469daf":"code","d184a031":"code","277050c9":"code","b5ff3f65":"code","39e8625c":"code","07ca1fb7":"code","83b76bb2":"code","6437c36d":"code","36dbf2b6":"code","e51838b2":"code","a58b0d95":"code","b6296393":"code","11c205d9":"code","19bf4e74":"code","ffbba8e1":"code","83cf223d":"markdown","e7bd3018":"markdown","1fa982f8":"markdown","0e0837be":"markdown","aa5d3fe0":"markdown","13178d80":"markdown","e9a6c0c5":"markdown","1eae227a":"markdown","e3f0e682":"markdown","eeb6d2b5":"markdown","febd4c8e":"markdown"},"source":{"5fd4fe50":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nimport pandas as pd\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import losses\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom tensorflow.keras.callbacks import LearningRateScheduler","e07c9a98":"train_set = '\/kaggle\/input\/digit-recognizer\/train.csv'","0cfa3444":"df_tr = pd.read_csv(train_set, sep=',')","825ec70d":"df_tr.head()","0ed571f1":"labels = np.array(df_tr)[:,0]\nlabels.shape","92b2b04b":"labels","ab6bab2e":"samples = np.array(df_tr)[:,1:]\nsamples.shape","48e1422f":"samples","6ab2da50":"img_arr = np.reshape(samples , (labels.shape[0], 28, 28, 1))\nimg_arr.shape","d8e7dde2":"plt.imshow(img_arr[100, :, :, 0], cmap=plt.cm.gray, interpolation='bilinear')","6860b4a5":"df_train, df_test = train_test_split(df_tr, train_size=0.85, test_size=0.15, random_state=42, shuffle = True)\ndf_train, df_val = train_test_split(df_train, train_size=0.8, test_size=0.2, random_state=42, shuffle = True)","502d1c86":"train_count = df_train['label'].value_counts()\nprint(\"Total : \", np.sum(train_count))\ntrain_count.plot(kind='bar', title='Train set Count')","006a2768":"val_count = df_val['label'].value_counts()\nprint(\"Total : \", np.sum(val_count))\nval_count.plot(kind='bar', title='validation set Count')","fca5216f":"test_count = df_test['label'].value_counts()\nprint(\"Total : \", np.sum(test_count))\ntest_count.plot(kind='bar', title='Test set Count')","eda823fe":"lb_style = LabelBinarizer()\nlb_results = lb_style.fit_transform(df_train[\"label\"])\ntr_labels = pd.DataFrame(lb_results, columns=lb_style.classes_)\ntr_labels.head()","5c846a04":"lb_style = LabelBinarizer()\nlb_results = lb_style.fit_transform(df_val[\"label\"])\nval_labels = pd.DataFrame(lb_results, columns=lb_style.classes_)\nval_labels.head()","52bb0359":"tr_img_arr = np.reshape(np.array(df_train)[:,1:] , (np.sum(train_count), 28, 28, 1))\nprint(tr_img_arr.shape)\n\nval_img_arr = np.reshape(np.array(df_val)[:,1:] , (np.sum(val_count), 28, 28, 1))\nprint(val_img_arr.shape)","7441df6d":"Generator = ImageDataGenerator(rescale = 1.\/255)\ntrain_Gen = Generator.flow(x=tr_img_arr,\n                y=np.array(tr_labels),\n                batch_size=32,\n                shuffle=True,\n                seed=1)\n\nval_Gen = Generator.flow(x=val_img_arr,\n                y=np.array(val_labels),\n                batch_size=32,\n                shuffle=True,\n                seed=1)","91f07d18":"model = Sequential()\nmodel.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding='same'))\nmodel.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\nmodel.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\nmodel.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\nmodel.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(84, activation = 'tanh', name='FC1'))\nmodel.add(layers.Dense(10, activation = 'softmax', name='FC2'))\nfor layer in model.layers:\n    layer.trainable = True","d0c3f9bf":"model.summary()","3df24fb0":"def step_decay(epoch, lr):\n    return 0.00025*np.exp(-0.09*epoch)\nSchedule = LearningRateScheduler(step_decay, verbose=1)","a9a5fd2a":"model.compile(loss = losses.CategoricalCrossentropy(),\n              optimizer = optimizers.Adam(),\n              metrics=['accuracy'])","10469daf":"History = model.fit(train_Gen, \n                    epochs=50,\n                    verbose=1,\n                    validation_data = val_Gen,\n                    callbacks = [Schedule])","d184a031":"x = np.arange(1, 50, 2) \ny = 0.00025*np.exp(-0.09*x)\nplt.plot(x, y)\nplt.xlabel('epoch') \nplt.ylabel('learning rate') \nplt.show()","277050c9":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\nt = f.suptitle('Model Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,51))\nax1.plot(epoch_list, History.history['accuracy'], label='Train Accuracy')\nax1.plot(epoch_list, History.history['val_accuracy'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 51, 2))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, History.history['loss'], label='Train Loss')\nax2.plot(epoch_list, History.history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, 51, 2))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","b5ff3f65":"test_img_arr = np.reshape(np.array(df_test)[:,1:] , (np.sum(test_count), 28, 28, 1))\nprint(test_img_arr.shape)\n\nlb_style = LabelBinarizer()\nlb_results = lb_style.fit_transform(df_test[\"label\"])\ntest_labels = pd.DataFrame(lb_results, columns=lb_style.classes_)\n\ntest_Gen = Generator.flow(x=test_img_arr,\n                y=None,\n                batch_size=32,\n                shuffle=False)","39e8625c":"test_Gen.reset()\ny_pred = model.predict(x = test_Gen, verbose = 1)\ny_pred","07ca1fb7":"Y_pred = (y_pred > 0.5).astype(int)\nY_pred","83b76bb2":"conf_mat = multilabel_confusion_matrix(y_true = np.array(test_labels), y_pred=Y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nprint('Confusion matrix:\\n', conf_mat)","6437c36d":"test_set = '\/kaggle\/input\/digit-recognizer\/test.csv'\ndf_test = pd.read_csv(test_set, sep=',')\ndf_test.head()","36dbf2b6":"tst_img_arr = np.reshape(np.array(df_test) , (28000, 28, 28, 1))\nprint(tst_img_arr.shape)","e51838b2":"test_Gen = Generator.flow(x=tst_img_arr,\n                y=None,\n                batch_size=32,\n                shuffle=False)","a58b0d95":"test_Gen.reset()\ny_pred = model.predict(x = test_Gen, verbose = 1)","b6296393":"pred = (y_pred > 0.5).astype(int)\npred","11c205d9":"predictions = np.argmax(pred, axis=1)\npredictions.shape","19bf4e74":"df_pred = pd.DataFrame({'ImageId':np.arange(1, 28001, 1),\n                      'Label':predictions})\ndf_pred","ffbba8e1":"df_pred.to_csv('\/kaggle\/working\/output.csv', index = False)","83cf223d":"# Model building","e7bd3018":"# Explore the dataset","1fa982f8":"# Preprocess the images arrays and the labels","0e0837be":"# Competition submission","aa5d3fe0":"**Training and validation generators for an efficient training**","13178d80":"# Model training","e9a6c0c5":"**Using learning rate decay for a better optimization**","1eae227a":"**Hot encoding of the training and the validation labels**","e3f0e682":"**We split the data into a training, validation and testing set**","eeb6d2b5":"# Model testing","febd4c8e":"**Reshaping the images arrays**"}}