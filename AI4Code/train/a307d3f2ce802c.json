{"cell_type":{"77edc067":"code","5aed83e9":"code","4cdc5d04":"code","30f4ab91":"code","5d443169":"code","0d281abf":"code","5bed80ff":"code","d68ef64f":"code","3353b58a":"code","1e8edb51":"code","c124842e":"code","91b88061":"code","7f637d1d":"code","a60ce1d3":"markdown","891c9d69":"markdown","bd0d6859":"markdown","6719adcb":"markdown","18a92eb3":"markdown","81366779":"markdown"},"source":{"77edc067":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport ipywidgets as widgets","5aed83e9":"# reading the dataset\ndataset = pd.read_csv('..\/input\/Advertising.csv')\ndataset.head()","4cdc5d04":"columns=dataset.columns\ncolumns","30f4ab91":"dataset=dataset[['TV', 'Radio', 'Newspaper', 'Sales']]\ndataset.head()","5d443169":"dataset.describe()","0d281abf":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.pairplot(dataset , plot_kws = {'alpha': 0.7, 's': 40, 'edgecolor': 'k', 'color':'red'})","5bed80ff":"corr=dataset.corr()\ncorr[corr==1]=np.nan\n\nsns.heatmap(corr, cmap='coolwarm', linewidths=2, annot=True)","d68ef64f":"import statsmodels.formula.api as smf\n\nlinear_regression_smf = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=dataset)\nfitted_model_smf = linear_regression_smf.fit()\nfitted_model_smf.summary()","3353b58a":"from sklearn.linear_model import LinearRegression\n\n\nlinear_regression_skl = LinearRegression()\nlinear_regression_skl.fit(dataset[['Radio', 'Newspaper', 'TV']], dataset['Sales'])\nprint(linear_regression_skl.coef_)\nprint(linear_regression_skl.intercept_)","1e8edb51":"# defining the gradient descent model\nimport random\n\ndef random_w(p):\n    return np.array([np.random.normal() for j in range(p)])\n\ndef hypothesis(X,w):\n    return np.dot(X,w)\n\ndef loss(X,w,y):\n    return hypothesis(X,w) -y\n\ndef squared_loss(X,w,y):\n    return loss(X,w,y)**2\n\ndef gradient(X,w,y):\n    gradients= list()\n    n=float(len(y))\n    for j in range(len(w)):\n        gradients.append(np.sum(loss(X,w,y)*X[:,j])\/n)\n    return gradients\n\ndef update(X,w,y, alpha = 0.001):\n    return [t - alpha*g for t,g in zip(w,gradient(X,w,y))]\n\ndef optimize(X, y, alpha = 0.001, eta = 10**-12, iterations=1000):\n    w=random_w(X.shape[1])\n    path = list()\n    for k in range(iterations):\n        SSL=np.sum(squared_loss(X,w,y))\n        new_w=update(X,w,y, alpha=alpha)\n        new_SSL=np.sum(squared_loss(X,new_w,y))\n        w=new_w\n        if k >= 5 and (new_SSL - SSL <= eta and new_SSL-SSL > -eta):\n            path.append(new_SSL)\n            return w, path\n        if k % (iterations \/ 20)==0:\n            path.append(new_SSL)\n    return w, path","c124842e":"#preparing the variables and standardizing it\nfrom sklearn.preprocessing import StandardScaler\n\nX=dataset[['Radio', 'Newspaper', 'TV']]\nobservations = len(dataset)\nstandarddization=StandardScaler()\nXst = standarddization.fit_transform(X)\noriginal_means=standarddization.mean_\noriginal_stds=standarddization.var_**0.5\nXst = np.column_stack((Xst, np.ones(observations)))\ny = dataset['Sales']","91b88061":"#using the gradient descent\nalpha = 0.02\nw, path = optimize(Xst, y, alpha, eta = 10**-12, \\\niterations = 20000)\nprint (\"These are our final standardized coefficients: \" + ', '.join(map(lambda x: \"%0.4f\" % x, w)))","7f637d1d":"#unstandardizing the coefficients\nunstandardized_betas = w[:-1]\/original_stds\nunstandardized_bias=w[-1]-np.sum(original_means\/original_stds*w[:-1])\nprint(unstandardized_betas)\nprint(unstandardized_bias)","a60ce1d3":"### Correlation matrix including the response variable","891c9d69":"## 3) Using Gradient Descent","bd0d6859":"## 1) Using statsmodel.formula.api to find the linear regression model on sales","6719adcb":"# Project 5. Multiple Linear Regression","18a92eb3":"## 2) Using ScikitLearn to find the linear regression model on sales","81366779":"## Understanding the relationships"}}