{"cell_type":{"5359557f":"code","b4cf030f":"code","ec428860":"code","c049b90c":"code","57326743":"code","5ef58f19":"code","9290d887":"code","22dcd04f":"code","570b1f65":"code","dd508975":"code","fb507205":"code","f1ba1cd4":"code","f4e1eae4":"code","974122fa":"code","05065cc3":"code","2da4cc50":"code","887a746c":"code","19027abc":"code","fa3eb39a":"code","d1cc8208":"code","01038a5e":"code","004586fb":"code","c9964a3c":"markdown","548aa978":"markdown","a05c7e44":"markdown","f9c84a05":"markdown","e95ffa44":"markdown","5c98c7d9":"markdown","6f2b58a1":"markdown","3dc3211c":"markdown","316cabd7":"markdown","bc331f5c":"markdown","87575228":"markdown","3a87ca81":"markdown","5ebc0273":"markdown","641b3b1a":"markdown","5d878ddc":"markdown","ffc9ab75":"markdown","e413fa33":"markdown"},"source":{"5359557f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b4cf030f":"#Shoes_Database\n\n\n#import packages I'll need\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndf = pd.read_csv('\/kaggle\/input\/womens-shoes-prices\/Datafiniti_Womens_Shoes.csv')\n\n#have a look at the data \ndf.head()","ec428860":"#find variables that might be interesting to analyse\n\nfor col in df.columns:\n    print(col)","c049b90c":"#firstly, let's check the information about brands\n\ndf2 = df['brand'].value_counts()\n\n#force it to stop trucate the results\npd.options.display.max_rows = 200\ndf2\n\n#some of them appear with different names, must change this\ndf['brand']=df['brand'].replace({'Adidas Outdoor':'adidas','dr. scholls':\"Dr. Scholl's\",'Adidas':'adidas',\n                                               'Brinley Co. Collection':'Brinley Co.', 'SKECHERS':'skechers',\n                                               })\n\n#check again all changes were done\nprint(df['brand'].value_counts())","57326743":"#secondly, I'll rename the variable that indicates the promotions, in order to make more obvious what it shows\n\ndf.rename(columns = {'prices.offer':'Promotion'}, inplace = True)\n\n#let's do a value count on these variables\n\nprint(df['Promotion'].value_counts())\nprint(df['Promotion'].value_counts().sum())\nprint(df['prices.isSale'].value_counts())\n\n","5ef58f19":"#for this, I'll use the variables prices.amountMax and prices.amountMin\n\ndf['priceDif'] = df['prices.amountMax'] - df['prices.amountMin']\ndf.head()","9290d887":"#now, it will be more interesting to calculate this difference as a percentage\n\ndf['priceDif%'] = (df['prices.amountMax'] - df['prices.amountMin'])\/df['prices.amountMax']\ndf.head()","22dcd04f":"df_promo = df[df['priceDif'] > 0]\ndf_promo ","570b1f65":"#let's keep only the price variables and the brand; filtering more:\n\ndf_promo = df_promo.filter(regex='price|brand|id')\nprint(df_promo)","dd508975":"#still, some of the price variables don't seem useful so I'll delete them\n\ndf_promo = df_promo.drop(['prices.sourceURLs','prices.size','prices.shipping',\n                           'prices.dateSeen','prices.currency'], axis = 1)\nfor col in df_promo.columns:\n    print(col)\n    \n","fb507205":"#now, let's study a bit more these brands that had the most important promotions\n\ndf_promo['brand'].value_counts()\n","f1ba1cd4":"pd.pivot_table(df_promo,index=[\"id\",\"prices.color\"]) ","f4e1eae4":"df_pivot_count = pd.pivot_table(df_promo,index=[\"brand\",\"id\",\"prices.color\"],aggfunc='count') \ndf_pivot_count = df_pivot_count[['priceDif','priceDif%','prices.amountMax','prices.amountMin','prices.isSale']]\ndf_pivot_count","974122fa":"df_pivot_count2 = pd.pivot_table(df_promo,index=[\"brand\",\"prices.color\"],aggfunc='count') \ndf_pivot_count2 = df_pivot_count2[['id','priceDif','priceDif%','prices.amountMax','prices.amountMin','prices.isSale']]\n\ndf_pivot_count2.sort_values(by = 'id', ascending = False)\n","05065cc3":"df_promo['priceDif%'].describe(include='all')","2da4cc50":"median_promo = df_promo['priceDif%'].median(axis = 0)\ndf_promo['promo_importance'] = 0","887a746c":"print(df_promo.columns.get_loc(\"priceDif%\"))\nprint(df_promo.columns.get_loc(\"promo_importance\")) #get the loc position of the columns\n\nfor i in range(1,7111): #using the count from the descriptives above\n    if (df_promo.iloc[i,12] >= median_promo):\n        df_promo.iloc[i,13] = 1\n\ndf_promo.head(50)","19027abc":"pivot = pd.pivot_table(df_promo,index=[\"brand\",\"promo_importance\"],values=['priceDif%'],aggfunc=[np.mean,len])\npivot2 = pivot.stack()\npivot2 #mean of priceDif and count of it,mean is not actually that interesting but len gives me the count","fa3eb39a":"pivot2.sort_values(by = ['promo_importance','len'], ascending = [0, 0])","d1cc8208":"df_new = df_promo.groupby(['promo_importance','brand']).count()\\\n.sort_values(by = ['priceDif%','promo_importance'], ascending = False)\ndf_new","01038a5e":"df_promo['bins'] = pd.cut(df_promo['priceDif%'], [0,0.2,0.4,0.6,0.8,1], include_lowest = True)\ndf_promo.head(10)","004586fb":"plt.title('Promotion value')\nplt.xlabel('promotion')\nplt.ylabel('value')\nplt.hist(df_promo['priceDif%'], bins = [0,0.2,0.4,0.6,0.8,1])","c9964a3c":"*This one is calculating an average, but I wanted more a count so... *","548aa978":"*voil\u00e0! Now there are splits by brand, ids and color, or, if ids seem not that important they can be removed\nfrom indexes and used to sort, below I sorted in a descending order to show which **brand x color** had the most \nitems in promotion*.","a05c7e44":"*Let's sort this pivot to get the brands with highest number of significant promotions (above median)*.","f9c84a05":"*Now, I wondered what actually means each observation, if ids are unique; well, from what can be seen below,\nthe ids are not unique, some have multiple observations but they are different by color, so one can consider each observation it's, let's name it, an item*.\n\n*As I find pivot tables very useful in Excel, I thought it would be interesting to use it in Python too, it makes\ndata more readable*.\n","e95ffa44":"*From this point on I'll isolate only the **observations that concern sales in promotion**;\n to do this, I'll consider that any reduction in price means is on sale, even if sometimes it's not stated explicitly*.","5c98c7d9":"*Making a new pivot table here to classify each brand on how many items with high promotions got\nand how many with low promotions*.","6f2b58a1":"*That's better*.","3dc3211c":"*So most promotions have a price reduction between 20% and 60%; makes sense*.\n\n*Still have some more graphs that I will add as soon as I get decide which ones are the best for this data*.","316cabd7":"*Finally, I'll split the variable thsat shows how big were the reductions in intervals, using some bins and a histogram for visual clarity*.","bc331f5c":"*Some of the variables don't seem that useful, might delete some later, now just as I said above I'll focus on brand and promotion related variables*.","87575228":"This notebook presents some very basic Python pandas, a bit of numpy and matplotlib tools applied on the Datafiniti_Womens_Shoes database (which has 10000 observations out of a bigger database) found here on Kaggle . \nAs the name very well suggests, the database contains information about various shoes like price, brand, color, if the item was on sale or not, and some other not that useful stuff.\n\nSo, I thought it would be interesting to have a look at the brands, make some cleaning on their names, and then have a look at promotions and how much price reduction these brands had for their products.\n\n","3a87ca81":"*The price reduction was between 3% and 85%, that's a big difference. In this case, let's classify these reductions into low and high using the median value , by creating a new variable*.","5ebc0273":"*Now it's interesting to have a look at the value of promotion*.","641b3b1a":"*Now, just as a test, I want to try to get same amount of detail using groupby:*","5d878ddc":"*Yep, it seems I got the same thing, good*.","ffc9ab75":"*Here can be noticed that, by using the counts on the 'Promotion' variable there are 121 observations, but by using the 'prices.isSale' counts there seem to be 170 observations. \nAs these 2 variables don't match it seems some data is incomplete so I'll create a new variable that will calculate the value of the price reduction, if there is one, and not use the 'Promotion' variable as I intended at the beginning .*\n","e413fa33":"*Let's start by importing the database and the needed packages and have a look at the data*."}}