{"cell_type":{"bd4c56d5":"code","701352d0":"code","df53e190":"code","b2350b94":"code","fdbe6e10":"code","dc2bceab":"code","b26c10b9":"code","cba58443":"code","d621c96c":"code","e1b06bc2":"code","da6ad4a6":"code","230f9d17":"code","6054dca2":"code","837dd3cf":"code","c6305c0d":"code","0d38cd28":"code","7d02ad3c":"code","85a0330e":"code","655cfc78":"code","92444034":"code","657353e3":"code","fa5d8f9c":"code","458c2669":"code","8a84a74e":"code","e37fe369":"code","4315e2c8":"code","7201a0b8":"code","55612f18":"markdown","7fac53db":"markdown","f9246d42":"markdown","797bf819":"markdown"},"source":{"bd4c56d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","701352d0":"# import libraries\nimport tensorflow as tf\nfrom tensorflow.keras import datasets,layers, models\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)","df53e190":"train_data = pd.read_csv('..\/input\/nicht-mnist\/train.csv',header=None, index_col =0)\ntest_data = pd.read_csv('..\/input\/nicht-mnist\/test.csv',header=None , index_col = 0)","b2350b94":"train_data.shape","fdbe6e10":"test_data.shape","dc2bceab":"train_data.head()","b26c10b9":"y = train_data[1]\nx = train_data.drop(columns=[1])","cba58443":"len(y.unique())","d621c96c":"y.value_counts()","e1b06bc2":"x = x \/ 255.0\ntest_data = test_data \/ 255.0","da6ad4a6":"x = x.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","230f9d17":"x.shape","6054dca2":"test_data.shape","837dd3cf":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder=LabelEncoder()\ny = pd.DataFrame(label_encoder.fit_transform(y))","c6305c0d":"from sklearn.model_selection import train_test_split\ntrain_x, val_x,train_y, val_y = train_test_split(x, y, test_size = 0.2, random_state=1)","0d38cd28":"from tensorflow import keras\nfrom keras.layers import Dense, Dropout\nfrom tensorflow.keras import regularizers","7d02ad3c":"cnn = models.Sequential()\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001),input_shape=(28, 28,1),padding = 'same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(Dropout(0.5))\n\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28,1),padding = 'same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\n\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.0001),padding = 'same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(Dropout(0.25))\n\ncnn.add(layers.Conv2D(256, (3, 3), activation='relu',padding = 'same'))\n\ncnn.add(layers.Flatten())\ncnn.add(layers.Dense(64, activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(layers.Dense(10))","85a0330e":"cnn.summary()","655cfc78":"cnn.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\ncnn_history = cnn.fit(train_x, train_y, epochs=100, batch_size=32,validation_data=(val_x, val_y),callbacks=[callbacks])","92444034":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(cnn_history.history['accuracy'], label='Training accuracy')\nplt.plot(cnn_history.history['val_accuracy'], label = 'Validation accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(cnn_history.history['loss'], label='Training Loss')\nplt.plot(cnn_history.history['val_loss'], label = 'Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n\ntest_loss, test_acc = cnn.evaluate(val_x,  val_y, verbose=2)\nprint('\\nTest accuracy:', test_acc)","657353e3":"probability_model = tf.keras.Sequential([cnn,tf.keras.layers.Softmax()])","fa5d8f9c":"predictions = probability_model.predict(test_data)","458c2669":"results = np.argmax(predictions,axis = 1)","8a84a74e":"results = pd.Series(results,name=\"target\")","e37fe369":"submission = pd.concat([pd.Series(range(0,9364),name = \"Id\"),results],axis = 1)","4315e2c8":"submission['target'] = label_encoder.inverse_transform(submission['target'])","7201a0b8":"submission.to_csv('nicht-mnist_cnn.csv', index=False)","55612f18":"## Prepare the data","7fac53db":"## Load the data","f9246d42":"## Explore the data","797bf819":"## CNN"}}