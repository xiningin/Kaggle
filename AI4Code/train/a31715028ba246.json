{"cell_type":{"6316b135":"code","a51ffa3a":"code","ba47d731":"code","37e150fe":"code","ccea245b":"code","4d514a83":"code","320358bf":"code","50ae147d":"code","583da306":"code","079c6420":"code","490ba802":"code","b630e631":"code","e6a61baa":"code","b66c9433":"markdown","c301ccb5":"markdown","d59ba3b0":"markdown","89518b37":"markdown"},"source":{"6316b135":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","a51ffa3a":"from sklearn.preprocessing import label_binarize\n\ntrain_data = pd.read_csv(\"..\/input\/train.csv\")\nfeature_cols = [x for x in train_data.columns if x not in [\"Target\", \"Id\", \"idhogar\"]]\nX = train_data[feature_cols]\ny = train_data.Target\ny_bin = label_binarize(y, [1,2,3,4])\n\n#Split train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train_bin, y_test_bin = train_test_split(X, y_bin, test_size=.1, random_state=42)\ny_train = list(map(lambda x: np.argmax(x)+1, y_train_bin))\ny_test = list(map(lambda x: np.argmax(x)+1, y_test_bin))","ba47d731":"#These columns are not numerical. They cannot be feed into any model. (Id and idhogar are obvious)\n[(x, y) for (x,y) in X_train.dtypes.to_dict().items() if y==\"O\"]","37e150fe":"#These columns have NaNs\n[x for x in X_train.columns if sum(X_train[x].isna())>0]","ccea245b":"fill_dict = {\"v2a1\": X_train.v2a1.median(), #Monthly rent payment\n             \"v18q1\": 0, #number of tablets household owns\n             \"rez_esc\": X_train.rez_esc.median(), #Years behind in school\n             \"meaneduc\": X_train.meaneduc.median(), #average years of education for adults (18+)\n            }\nX_train = X_train.fillna(fill_dict)\nX_test = X_test.fillna(fill_dict)\nX_train.SQBmeaned = np.sqrt(X_train.meaneduc)\nX_test.SQBmeaned = np.sqrt(X_test.meaneduc)\n[x for x in X_train.columns if sum(X_train[x].isna())>0]","4d514a83":"def clean_yes_no_column(serie, train=True, train_mean=None):\n    _serie = serie.apply(lambda x: 0 if x==\"no\" else x)\n    _serie = _serie.apply(lambda x: float(x) if x!=\"yes\" else x)\n    if train:\n        mean_value = _serie[_serie != \"yes\"].mean()\n    else:\n        mean_value = train_mean\n    return _serie.apply(lambda x: mean_value if x==\"yes\" else x)","320358bf":"#Clean those nasty categorical columns\nX_train.dependency = clean_yes_no_column(X_train.dependency)\nX_train.edjefe = clean_yes_no_column(X_train.edjefe)\nX_train.edjefa = clean_yes_no_column(X_train.edjefa)\n\nX_test.dependency = clean_yes_no_column(X_test.dependency, False, X_train.dependency.mean())\nX_test.edjefe = clean_yes_no_column(X_test.edjefe, False, X_train.edjefe.mean())\nX_test.edjefa = clean_yes_no_column(X_test.edjefa, False, X_train.edjefa.mean())","50ae147d":"from sklearn.metrics import roc_curve, auc, f1_score\nfrom itertools import cycle\nimport matplotlib.pyplot as plt\nfrom scipy import interp\n\ndef plot_roc_curve(y_score, y_test_bin, y_test, fig_size = (15,10)):\n    n_classes = y_train_bin.shape[1]\n    lw = 2\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(n_classes):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n    mean_tpr \/= n_classes\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n    plt.figure(figsize=fig_size)\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n             label='macro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"macro\"]),\n             color='navy', linestyle=':', linewidth=4)\n    \n    for i in range(n_classes):\n        plt.plot(fpr[i], tpr[i], lw=lw,\n                 label='ROC curve of class {0} (area = {1:0.2f})'\n                 ''.format(i, roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Some extension of Receiver operating characteristic to multi-class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    predictions = list(map(lambda x: np.argmax(x)+1, y_score))\n    F1 = f1_score(y_test, predictions, average=\"macro\")\n    return F1","583da306":"from sklearn.linear_model import logistic\n\nmodel = logistic.LogisticRegression()\nmodel.fit(X_train, y_train)\ny_score = model.predict_proba(X_test)\nplot_roc_curve(y_score, y_test_bin, y_test, (15, 10))","079c6420":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\ny_score = model.predict_proba(X_test)\nplot_roc_curve(y_score, y_test_bin, y_test, (15, 10))","490ba802":"train_data = pd.read_csv(\"..\/input\/train.csv\")\nfeature_cols = [x for x in train_data.columns if x not in [\"Target\", \"Id\", \"idhogar\"]]\nX = train_data[feature_cols]\ny = train_data.Target\nfill_dict = {\"v2a1\": X.v2a1.median(), #Monthly rent payment\n             \"v18q1\": 0, #number of tablets household owns\n             \"rez_esc\": X.rez_esc.median(), #Years behind in school\n             \"meaneduc\": X.meaneduc.median(), #average years of education for adults (18+)\n            }\nX = X.fillna(fill_dict)\nX.SQBmeaned = np.sqrt(X.meaneduc)\n\nX.dependency = clean_yes_no_column(X.dependency)\nX.edjefe = clean_yes_no_column(X.edjefe)\nX.edjefa = clean_yes_no_column(X.edjefa)\n\nmodel =  RandomForestClassifier()\nmodel.fit(X, y)\n\n#Split train-test\nX_test = pd.read_csv(\"..\/input\/test.csv\")\nX_test = X_test.fillna(fill_dict)\nX_test.SQBmeaned = np.sqrt(X_test.meaneduc)\n\nX_test.dependency = clean_yes_no_column(X_test.dependency, False, X_train.dependency.mean())\nX_test.edjefe = clean_yes_no_column(X_test.edjefe, False, X_train.edjefe.mean())\nX_test.edjefa = clean_yes_no_column(X_test.edjefa, False, X_train.edjefa.mean())","b630e631":"test_id = X_test.Id\ny_predict = model.predict(X_test[feature_cols])","e6a61baa":"pred = pd.DataFrame({\"Id\": test_id, \"Target\": y_predict})\npred.to_csv('submission.csv', index=False)\npred.head()","b66c9433":"Let\u00b4s try to make a submission, using the complete train dataset","c301ccb5":"A simple baseline","d59ba3b0":"## Define an evaluation function.\nThis function will plot roc curves for every class. It\u00b4s also good practice to keep one (or two) metrics as key metrics. In this case, the macro F1 score","89518b37":"# Data cleanup\nSome columns will be fitted with median. Others, will need to be manually cleaned, since they are mixed with categorical data \n"}}