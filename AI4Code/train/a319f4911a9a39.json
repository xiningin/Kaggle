{"cell_type":{"502e7437":"code","3c58fcb3":"code","69b527e3":"code","fa9f74da":"code","28709cb6":"code","46b8cb91":"code","f32db5b4":"code","4e9bfaf5":"code","41d54289":"code","95153f9a":"code","b799f974":"code","a1084f5a":"code","8976fe38":"code","53ec5885":"code","9826626b":"code","4861e200":"code","257097ae":"code","2f6d6d82":"code","1f6fda50":"code","cd91d306":"code","629a0eca":"code","5f7eaf02":"code","bbbcbdec":"code","301d493c":"code","0ffc510a":"code","55580319":"code","e37d3ebc":"code","b92e053f":"code","28600008":"code","ce354c5c":"code","27c2b46f":"code","b94e2c29":"code","71292c03":"code","aef4f846":"code","f8480175":"code","94664be2":"code","6c8810df":"code","32d8f262":"code","535ae423":"code","92289d91":"code","c21d752d":"code","dd275ac4":"code","d6eeda77":"code","28736f8f":"code","e2180c87":"code","c3bf5880":"code","94971333":"markdown","ce8b084f":"markdown","481299b4":"markdown","c1723039":"markdown","9d7341a5":"markdown","3dcf2bf5":"markdown","06b87720":"markdown","026fc9d6":"markdown","da010a45":"markdown","60cde7dd":"markdown","1d12565a":"markdown","5a3e927a":"markdown","a0aaee3f":"markdown","6197238b":"markdown","e22a8a30":"markdown","5b77e4cc":"markdown","f857921a":"markdown","b6bd75d5":"markdown","5ed528e4":"markdown","dbdeef51":"markdown","76d7b461":"markdown","8992fa3d":"markdown","c4ad2261":"markdown","5af2f00f":"markdown","0b3ab397":"markdown","e88df9ea":"markdown","54a87071":"markdown"},"source":{"502e7437":"import os\nimport pandas as pd\nimport numpy as np\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom lightgbm import LGBMRegressor\nimport joblib","3c58fcb3":"sales = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')\nsales.name = 'sales'\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\ncalendar.name = 'calendar'\nprices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nprices.name = 'prices'","69b527e3":"\nfor d in range(1942,1970):\n    col = 'd_' + str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)","fa9f74da":"sales_bd = np.round(sales.memory_usage().sum()\/(1024*1024),1)\ncalendar_bd = np.round(calendar.memory_usage().sum()\/(1024*1024),1)\nprices_bd = np.round(prices.memory_usage().sum()\/(1024*1024),1)","28709cb6":"#Downcast in order to save memory\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  \n\nsales = downcast(sales)\nprices = downcast(prices)\ncalendar = downcast(calendar)","46b8cb91":"sales_ad = np.round(sales.memory_usage().sum()\/(1024*1024),1)\ncalendar_ad = np.round(calendar.memory_usage().sum()\/(1024*1024),1)\nprices_ad = np.round(prices.memory_usage().sum()\/(1024*1024),1)","f32db5b4":"dic = {'DataFrame':['sales','calendar','prices'],\n       'Before downcasting':[sales_bd,calendar_bd,prices_bd],\n       'After downcasting':[sales_ad,calendar_ad,prices_ad]}\n\nmemory = pd.DataFrame(dic)\nmemory = pd.melt(memory, id_vars='DataFrame', var_name='Status', value_name='Memory (MB)')\nmemory.sort_values('Memory (MB)',inplace=True)\nfig = px.bar(memory, x='DataFrame', y='Memory (MB)', color='Status', barmode='group', text='Memory (MB)')\nfig.update_traces(texttemplate='%{text} MB', textposition='outside')\nfig.update_layout(template='seaborn', title='Effect of Downcasting')\nfig.show()","4e9bfaf5":"df = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()","41d54289":"df = pd.merge(df, calendar, on='d', how='left')\ndf = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') ","95153f9a":"group = sales.groupby(['state_id','store_id','cat_id','dept_id'],as_index=False)['item_id'].count().dropna()\ngroup['USA'] = 'United States of America'\ngroup.rename(columns={'state_id':'State','store_id':'Store','cat_id':'Category','dept_id':'Department','item_id':'Count'},inplace=True)\nfig = px.treemap(group, path=['USA', 'State', 'Store', 'Category', 'Department'], values='Count',\n                  color='Count',\n                  color_continuous_scale= px.colors.sequential.Sunset,\n                  title='Walmart: Distribution of items')\nfig.update_layout(template='seaborn')\nfig.show()","b799f974":"group_price_cat = df.groupby(['store_id','cat_id','item_id'],as_index=False)['sell_price'].mean().dropna()\nfig = px.violin(group_price_cat, x='store_id', color='cat_id', y='sell_price',box=True, hover_name='item_id')\nfig.update_xaxes(title_text='Store')\nfig.update_yaxes(title_text='Selling Price($)')\nfig.update_layout(template='seaborn',title='Distribution of Items prices wrt Stores across Categories',\n                 legend_title_text='Category')\nfig.show()","a1084f5a":"group = df.groupby(['year','date','state_id','store_id'], as_index=False)['sold'].sum().dropna()\nfig = px.violin(group, x='store_id', color='state_id', y='sold',box=True)\nfig.update_xaxes(title_text='Store')\nfig.update_yaxes(title_text='Total items sold')\nfig.update_layout(template='seaborn',title='Distribution of Items sold in the Stores',legend_title_text='State')\nfig.show()","8976fe38":"fig = go.Figure()\ntitle = 'Items sold over time'\nyears = group.year.unique().tolist()\nbuttons = []\ny=3\nfor state in group.state_id.unique().tolist():\n    group_state = group[group['state_id']==state]\n    for store in group_state.store_id.unique().tolist():\n        group_state_store = group_state[group_state['store_id']==store]\n        fig.add_trace(go.Scatter(name=store, x=group_state_store['date'], y=group_state_store['sold'], showlegend=True, \n                                   yaxis='y'+str(y) if y!=1 else 'y'))\n    y-=1\n\nfig.update_layout(\n        xaxis=dict(\n        #autorange=True,\n        range = ['2011-01-29','2016-05-22'],\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                     label=\"1m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=6,\n                     label=\"6m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=1,\n                     label=\"YTD\",\n                     step=\"year\",\n                     stepmode=\"todate\"),\n                dict(count=1,\n                     label=\"1y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=2,\n                     label=\"2y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=3,\n                     label=\"3y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=4,\n                     label=\"4y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(step=\"all\")\n            ])\n        ),\n        rangeslider=dict(\n            autorange=True,\n        ),\n        type=\"date\"\n    ),\n    yaxis=dict(\n        anchor=\"x\",\n        autorange=True,\n        domain=[0, 0.33],\n        mirror=True,\n        showline=True,\n        side=\"left\",\n        tickfont={\"size\":10},\n        tickmode=\"auto\",\n        ticks=\"\",\n        title='WI',\n        titlefont={\"size\":20},\n        type=\"linear\",\n        zeroline=False\n    ),\n    yaxis2=dict(\n        anchor=\"x\",\n        autorange=True,\n        domain=[0.33, 0.66],\n        mirror=True,\n        showline=True,\n        side=\"left\",\n        tickfont={\"size\":10},\n        tickmode=\"auto\",\n        ticks=\"\",\n        title = 'TX',\n        titlefont={\"size\":20},\n        type=\"linear\",\n        zeroline=False\n    ),\n    yaxis3=dict(\n        anchor=\"x\",\n        autorange=True,\n        domain=[0.66, 1],\n        mirror=True,\n        showline=True,\n        side=\"left\",\n        tickfont={\"size\":10},\n        tickmode=\"auto\",\n        ticks='',\n        title=\"CA\",\n        titlefont={\"size\":20},\n        type=\"linear\",\n        zeroline=False\n    )\n    )\nfig.update_layout(template='seaborn', title=title)\nfig.show()","53ec5885":"df['revenue'] = df['sold']*df['sell_price'].astype(np.float32)","9826626b":"def introduce_nulls(df):\n    idx = pd.date_range(df.date.dt.date.min(), df.date.dt.date.max())\n    df = df.set_index('date')\n    df = df.reindex(idx)\n    df.reset_index(inplace=True)\n    df.rename(columns={'index':'date'},inplace=True)\n    return df\n\ndef plot_metric(df,state,store,metric):\n    store_sales = df[(df['state_id']==state)&(df['store_id']==store)&(df['date']<='2016-05-22')]\n    food_sales = store_sales[store_sales['cat_id']=='FOODS']\n    store_sales = store_sales.groupby(['date','snap_'+state],as_index=False)['sold','revenue'].sum()\n    snap_sales = store_sales[store_sales['snap_'+state]==1]\n    non_snap_sales = store_sales[store_sales['snap_'+state]==0]\n    food_sales = food_sales.groupby(['date','snap_'+state],as_index=False)['sold','revenue'].sum()\n    snap_foods = food_sales[food_sales['snap_'+state]==1]\n    non_snap_foods = food_sales[food_sales['snap_'+state]==0]\n    non_snap_sales = introduce_nulls(non_snap_sales)\n    snap_sales = introduce_nulls(snap_sales)\n    non_snap_foods = introduce_nulls(non_snap_foods)\n    snap_foods = introduce_nulls(snap_foods)\n    fig = go.Figure()\n    #fig.add_trace(go.Scatter(x=non_snap_sales['date'],y=non_snap_sales[metric],name='Total '+metric+'(Non-SNAP)'))\n    #fig.add_trace(go.Scatter(x=snap_sales['date'],y=snap_sales[metric],name='Total '+metric+'(SNAP)'))\n    fig.add_trace(go.Scatter(x=non_snap_foods['date'],y=non_snap_foods[metric],\n                           name='Food '+metric+'(Non-SNAP)'))\n    fig.add_trace(go.Scatter(x=snap_foods['date'],y=snap_foods[metric],\n                           name='Food '+metric+'(SNAP)'))\n    fig.update_yaxes(title_text='Total items sold' if metric=='sold' else 'Total revenue($)')\n    fig.update_layout(template='seaborn',title=store)\n    fig.update_layout(\n        xaxis=dict(\n        #autorange=True,\n        range = ['2011-01-29','2016-05-22'],\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                     label=\"1m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=6,\n                     label=\"6m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=1,\n                     label=\"YTD\",\n                     step=\"year\",\n                     stepmode=\"todate\"),\n                dict(count=1,\n                     label=\"1y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=2,\n                     label=\"2y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=3,\n                     label=\"3y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=4,\n                     label=\"4y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(step=\"all\")\n            ])\n        ),\n        rangeslider=dict(\n            autorange=True,\n        ),\n        type=\"date\"\n    ))\n    return fig","4861e200":"cal_data = group.copy()\ncal_data = cal_data[cal_data.date <= '22-05-2016']\ncal_data['week'] = cal_data.date.dt.weekofyear\ncal_data['day_name'] = cal_data.date.dt.day_name()","257097ae":"def calmap(cal_data, state, store, scale):\n    cal_data = cal_data[(cal_data['state_id']==state)&(cal_data['store_id']==store)]\n    years = cal_data.year.unique().tolist()\n    fig = make_subplots(rows=len(years),cols=1,shared_xaxes=True,vertical_spacing=0.005)\n    r=1\n    for year in years:\n        data = cal_data[cal_data['year']==year]\n        data = introduce_nulls(data)\n        fig.add_trace(go.Heatmap(\n            z=data.sold,\n            x=data.week,\n            y=data.day_name,\n            hovertext=data.date.dt.date,\n            coloraxis = \"coloraxis\",name=year,\n        ),r,1)\n        fig.update_yaxes(title_text=year,tickfont=dict(size=5),row = r,col = 1)\n        r+=1\n    fig.update_xaxes(range=[1,53],tickfont=dict(size=10), nticks=53)\n    fig.update_layout(coloraxis = {'colorscale':scale})\n    fig.update_layout(template='seaborn', title=store)\n    return fig","2f6d6d82":"fig = plot_metric(df,'CA','CA_1','sold')\nfig.show()","1f6fda50":"fig = plot_metric(df,'CA','CA_1','revenue')\nfig.show()","cd91d306":"fig = plot_metric(df,'CA','CA_2','sold')\nfig.show()","629a0eca":"fig = plot_metric(df,'CA','CA_2','revenue')\nfig.show()","5f7eaf02":"fig = plot_metric(df,'CA','CA_3','sold')\nfig.show()","bbbcbdec":"fig = plot_metric(df,'CA','CA_3','revenue')\nfig.show()","301d493c":"fig = plot_metric(df,'CA','CA_4','sold')\nfig.show()","0ffc510a":"fig = plot_metric(df,'CA','CA_4','revenue')\nfig.show()","55580319":"fig = plot_metric(df,'TX','TX_1','sold')\nfig.show()","e37d3ebc":"fig = plot_metric(df,'TX','TX_1','revenue')\nfig.show()","b92e053f":"fig = plot_metric(df,'TX','TX_2','sold')\nfig.show()","28600008":"fig = plot_metric(df,'TX','TX_2','revenue')\nfig.show()","ce354c5c":"fig = plot_metric(df,'TX','TX_3','sold')\nfig.show()","27c2b46f":"fig = plot_metric(df,'TX','TX_3','revenue')\nfig.show()","b94e2c29":"fig = plot_metric(df,'WI','WI_1','sold')\nfig.show()","71292c03":"fig = plot_metric(df,'WI','WI_1','revenue')\nfig.show()","aef4f846":"fig = plot_metric(df,'WI','WI_2','sold')\nfig.show()","f8480175":"fig = plot_metric(df,'WI','WI_2','revenue')\nfig.show()","94664be2":"fig = plot_metric(df,'WI','WI_3','sold')\nfig.show()","6c8810df":"fig = plot_metric(df,'WI','WI_3','revenue')\nfig.show()","32d8f262":"#Store the categories along with their codes\nd_id = dict(zip(df.id.cat.codes, df.id))\nd_item_id = dict(zip(df.item_id.cat.codes, df.item_id))\nd_dept_id = dict(zip(df.dept_id.cat.codes, df.dept_id))\nd_cat_id = dict(zip(df.cat_id.cat.codes, df.cat_id))\nd_store_id = dict(zip(df.store_id.cat.codes, df.store_id))\nd_state_id = dict(zip(df.state_id.cat.codes, df.state_id))","535ae423":"#1\n#del group, group_price_cat, group_price_store, group_state, group_state_store, cal_data\n#gc.collect();\n\n#2\ndf.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\ncols = df.dtypes.index.tolist()\ntypes = df.dtypes.values.tolist()\nfor i,type in enumerate(types):\n    if type.name == 'category':\n        df[cols[i]] = df[cols[i]].cat.codes\n        \n#3\ndf.drop('date',axis=1,inplace=True)","92289d91":"lags = [1,2,3,6,12,24,36]\nfor lag in lags:\n    df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)","c21d752d":"df['iteam_sold_avg'] = df.groupby('item_id')['sold'].transform('mean').astype(np.float16)\ndf['state_sold_avg'] = df.groupby('state_id')['sold'].transform('mean').astype(np.float16)\ndf['store_sold_avg'] = df.groupby('store_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_sold_avg'] = df.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\ndf['dept_sold_avg'] = df.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_dept_sold_avg'] = df.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_item_sold_avg'] = df.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['cat_item_sold_avg'] = df.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['dept_item_sold_avg'] = df.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['state_store_sold_avg'] = df.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\ndf['state_store_cat_sold_avg'] = df.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_cat_dept_sold_avg'] = df.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)","dd275ac4":"df = df[df['d']>=36]","d6eeda77":"df.to_pickle('data.pkl')\ndel df\ngc.collect();","28736f8f":"data = pd.read_pickle('data.pkl')\nvalid = data[(data['d']>=1914) & (data['d']<1942)][['id','d','sold']]\ntest = data[data['d']>=1942][['id','d','sold']]\neval_preds = test['sold']\nvalid_preds = valid['sold']","e2180c87":"#Get the store ids\nstores = sales.store_id.cat.codes.unique().tolist()\nfor store in stores:\n    df = data[data['store_id']==store]\n    \n    #Split the data\n    X_train, y_train = df[df['d']<1914].drop('sold',axis=1), df[df['d']<1914]['sold']\n    X_valid, y_valid = df[(df['d']>=1914) & (df['d']<1942)].drop('sold',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sold']\n    X_test = df[df['d']>=1942].drop('sold',axis=1)\n    \n    #Train and validate\n    model = LGBMRegressor(\n        n_estimators=1000,\n        learning_rate=0.3,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        max_depth=8,\n        num_leaves=50,\n        min_child_weight=300\n    )\n    print('*****Prediction for Store: {}*****'.format(d_store_id[store]))\n    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n             eval_metric='rmse', verbose=20, early_stopping_rounds=20)\n    valid_preds[X_valid.index] = model.predict(X_valid)\n    eval_preds[X_test.index] = model.predict(X_test)\n    filename = 'model'+str(d_store_id[store])+'.pkl'\n    # save model\n    joblib.dump(model, filename)\n    del model, X_train, y_train, X_valid, y_valid\n    gc.collect()","c3bf5880":"#Set actual equal to false if you want to top in the public leaderboard :P\nactual = False\nif actual == False:\n    #Get the validation results(We already have them as less than one month left for competition to end)\n    validation = sales[['id']+['d_' + str(i) for i in range(1914,1942)]]\n    validation['id']=pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv').id\n    validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nelse:\n    #Get the actual validation results\n    valid['sold'] = valid_preds\n    validation = valid[['id','d','sold']]\n    validation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index()\n    validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n    validation.id = validation.id.map(d_id).str.replace('evaluation','validation')\n\n#Get the evaluation results\ntest['sold'] = eval_preds\nevaluation = test[['id','d','sold']]\nevaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()\nevaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n#Remap the category id to their respective categories\nevaluation.id = evaluation.id.map(d_id)\n\n#Prepare the submission\nsubmit = pd.concat([validation,evaluation]).reset_index(drop=True)\nsubmit.to_csv('submission.csv',index=False)","94971333":"### <a id='W2'>WI_2<\/a>\n","ce8b084f":"### CA_3\n","481299b4":"# Wisconsin","c1723039":"# Modelling and Prediction","9d7341a5":"# Below are some of the observations from the above plot:-\n  <li><b><u>California<\/u><\/b>: <b>CA_3<\/b> has sold the most number of items while, <b>CA_4<\/b> has sold the least number of items.<\/li>\n  <li><b><u>Texas<\/u><\/b>: <b>TX_2<\/b> and **TX_3** have sold the maximum number of items. <b>TX_1<\/b> has sold the least number of items.<\/li>\n  <li><b><u>Wisconsin<\/u><\/b>: <b>WI_2<\/b> has sold the maximum number of items while, <b>WI_3<\/b> has sold the least number of items.<\/li>\n  <li><b><u>USA<\/u><\/b>: <b>CA_3<\/b> has sold the most number of items while, <b>CA_4<\/b> has sold the least number of items.<\/li>\n<\/ul>\n\n","3dcf2bf5":"### <a id='C1'>CA_1<\/a>","06b87720":"# Reading the data","026fc9d6":"### TX2\n","da010a45":"# Feature Engineering\n\nLabel Encoding,\nIntroduce Lags,\nMean Encoding,\nRolling Window Weekly Mean,\n\n","60cde7dd":"Mean Encoding\n\n- item\n- state\n- store\n- category\n- department\n- category & department\n- store & item\n- category & item\n- department & item\n- state & store\n- state, store and category\n- store, category and department","1d12565a":"State wise Analysis\n  \nsales and revenue of all the stores individually across all the three states: California, Texas & Wisconsin. \nFirst plot shows the daily sales of a store. I have plotted the values separately for SNAP days. Also, SNAP promotes food purchase, I have plotted food sales as well to check if it really affects the food sales.\nSecond plot shows the daily revenue of a store with separate plotting for SNAP days\n\n","5a3e927a":" introduce a lot of Null values, so I'll remove data for first 35 days as I have introduced lags till 36 days.","a0aaee3f":" Introduce Lags\n\nAdding Lag features to the the target variable `sold`","6197238b":"# Melting the data\n Convert from wide to long format\n","e22a8a30":" Items Sold","5b77e4cc":"### <a id='W1'>WI_1<\/a>","f857921a":"Save the data for training.","b6bd75d5":"\nCombine price data from prices dataframe and days data from calendar dataset.","5ed528e4":"# Downcasting\n","dbdeef51":"### TX_3","76d7b461":"### <a id='W3'>WI_3<\/a>","8992fa3d":"# As can be seen from the plot above, food category items are quite cheap as compared with hobbies and household items. Hobbies and household items have almost the same price range.","c4ad2261":"\n# Texas","5af2f00f":"# Exploratory Data Analysis\n","0b3ab397":"California\n","e88df9ea":"### CA4\n","54a87071":"### <a id='T1'>TX_1<\/a>"}}