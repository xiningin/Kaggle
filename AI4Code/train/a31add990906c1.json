{"cell_type":{"51cf0865":"code","f3b50fc3":"code","5bcda291":"code","33d85265":"code","46e2d3e4":"code","305d87d2":"code","12527021":"code","d8e6876f":"code","fd4b613b":"code","6d20a95f":"code","a1518e5e":"code","8ee23225":"code","91e33b7e":"code","0b8ba06e":"code","296bc2d4":"code","b921824e":"code","c92d3820":"code","1c797a28":"code","f8fbfd26":"code","a42a4a31":"code","a5d40ed8":"code","c104f1b0":"code","cd9926a4":"code","800cd948":"code","935f126a":"code","4e51c3cd":"code","ffe0799c":"code","2eaa0a27":"code","7ef49386":"code","25c15585":"code","ba3bfc78":"code","601f532b":"code","dcfd604a":"code","5dd75d03":"code","c6170563":"code","5cafc699":"code","10b8b2f1":"code","c2c07167":"code","d00d263f":"code","4489ea0f":"code","9774beae":"code","6c75d8de":"code","c1444e84":"code","18ce2dc0":"code","2b52b1c9":"code","add309b3":"code","08e2d250":"code","b168de6e":"code","549cca91":"code","0aeee535":"code","f373b0ce":"code","b1b177a3":"code","27edeedd":"code","84c3fac3":"code","28cb6419":"code","ea2527e7":"code","5f16a3f5":"markdown","1d3e4548":"markdown","db3e6160":"markdown","859322cf":"markdown","74267759":"markdown","608c3d80":"markdown","1654cd22":"markdown","b3b4015c":"markdown","e9f811d2":"markdown","deddc8e3":"markdown","58d31d63":"markdown","e4413994":"markdown","f5e12ae3":"markdown","a27c4ae2":"markdown","c42ed0ee":"markdown","c00b5de6":"markdown","624c1668":"markdown","7c18bcff":"markdown","6b10a4d8":"markdown","99d0ac7c":"markdown","1e46b7a8":"markdown","063d8ac1":"markdown"},"source":{"51cf0865":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport os \n\nimport tensorflow as tf","f3b50fc3":"dir_path = \"..\/input\/dog-breed-identification\/\"\nos.listdir(dir_path)\n","5bcda291":"  for dirpath, dirnames, filenames in os.walk(dir_path ):\n    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","33d85265":"train_images_path = \"..\/input\/dog-breed-identification\/train\/\"\ntest_images_path = \"..\/input\/dog-breed-identification\/test\/\"","46e2d3e4":"#Lets read labels.csv file and check whats in that \nlabels_df = pd.read_csv(dir_path + 'labels.csv')\nprint(labels_df.head())\nprint(labels_df.describe())","305d87d2":"#Lets check if images in labels.csv is equal to images in our train folder \n\ndef is_equal_images(target_dir, target_df): \n    \"\"\"\n    This function will check if target_dir images are equal to image list in target_df\n    \"\"\"\n    len_target_dir = len(os.listdir(target_dir))\n    len_target_df = len(target_df)\n    if len_target_dir == len_target_df: \n        print(f\"Both are having same no of images:{len_target_dir}\")\n    else: \n        print(f\"Target dir having {len_target_dir} images while Target DF having {len_target_df}\")\n        \nis_equal_images(target_dir = train_images_path, target_df = labels_df)","12527021":"#check one image from training data\nfrom IPython.display import Image, display\nImage(train_images_path + '000bec180eb18c7604dcecc8fe0dba07.jpg')","d8e6876f":"#Check how many images per breed of dog. \n\nlabels_df['breed'].value_counts().plot.bar(figsize=(20,10))\nprint(f\"Average Images per breed:{int(labels_df['breed'].value_counts().sum()\/len(labels_df['breed'].unique()))}\")\nprint(f\"Total no of breeds:{len(labels_df['breed'].unique())}\")","fd4b613b":"#Create an array of train images \nfilenames = [train_images_path + fname + '.jpg' for fname in labels_df['id']]\nfilenames[:10]","6d20a95f":"# Create class names array \nclass_names = labels_df['breed'].unique()\nclass_names[:10]","a1518e5e":"target_labels = [breed for breed in labels_df['breed']]\ntarget_labels[:10]","8ee23225":"# Example: Turn one label into array of boolean \nprint(target_labels[0])\ntarget_labels[0] == class_names","91e33b7e":"#Lets do for all the labels \n\ntarget_labels_encoded = [label == np.array(class_names) for label in target_labels]\ntarget_labels_encoded[:2]","0b8ba06e":"# Example: Turning a boolean array into integers\nprint(target_labels[0]) # original label\nprint(np.where(class_names == target_labels[0])[0][0]) # index where label occurs\nprint(target_labels_encoded[0].argmax()) # index where label occurs in boolean array\nprint(target_labels_encoded[0].astype(int)) # there will be a 1 where the sample label occurs","296bc2d4":"#Import train test split from sklearn \n\nfrom sklearn.model_selection import train_test_split \n\n#Experiement with small data 1000 images \nNUM_IMAGES = 2000\n\n#Split data into training & validation \nX_train, X_val, Y_train, Y_val = train_test_split(filenames[:NUM_IMAGES], target_labels_encoded[:NUM_IMAGES], test_size=0.2, random_state=42)\n\nlen(X_train), len(X_val), len(Y_train), len(Y_val)","b921824e":"#Check our the training data \n\nX_train[0], Y_train[0]","c92d3820":"#Random image and its shape \nfrom matplotlib.pyplot import imread\n\nimg = imread(X_train[0])\nplt.imshow(img)\nprint(f\"Image Shape: {img.shape}\")","1c797a28":"tf.constant(img)","f8fbfd26":"tf.image.convert_image_dtype(img, tf.float32)","a42a4a31":"IMAGE_SIZE = 224\n\n# Lets write our preprocessing function\ndef process_image(image_path): \n    \"\"\"\n    This function will read image, resize the image and return into TF format. \n    Arguments: \n        image_path(str): Path of image\n    Returns: \n        img: Tensor image\n    \"\"\"\n    img = tf.io.read_file(image_path)\n    # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n    img = tf.io.decode_image(img, channels =3)\n    # Convert the colour channel values from 0-225 values to 0-1 values\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # Resize the image to our desired size (224, 244)\n    img = tf.image.resize_with_crop_or_pad(img, 224, 224)\n    return img\n","a5d40ed8":"# Create a simple function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n    \"\"\"\n    Takes an image file path name and the associated label,\n    processes the image and returns a tuple of (image, label).\n    \"\"\"\n    image = process_image(image_path)\n    return image, label\n\nget_image_label(X_train[10], Y_train[10])","c104f1b0":"BATCH_SIZE = 32 \n\n#Create function to create dataset batches \ndef create_data_batches(X, y=None, batch_size = BATCH_SIZE, valid_data= False, test_data=False): \n    \"\"\"\n    This function will help to accept Train Images (X) and labels (y). \n    Also Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n    Also accepts test data as input (no labels).\n    \"\"\"\n    if test_data: \n        print(\"Creating Test data\")\n        test_data = tf.data.Dataset.from_tensor_slices(tf.constant(X))\n        test_data = test_data.map(process_image).batch(BATCH_SIZE) \n        return test_data \n    \n    #Create validation data\n    if valid_data: \n        print(\"Creating Validation data\")\n        valid_data = tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n        valid_data = valid_data.map(get_image_label).batch(BATCH_SIZE)\n        return valid_data\n    \n    #Shuffle and create training data\n    else: \n        print(\"Creating Training Data\") \n        train_data = tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y))).shuffle(buffer_size = len(X))\n        train_data = train_data.map(get_image_label).batch(BATCH_SIZE) \n        return train_data \n        ","cd9926a4":"train_data = create_data_batches(X_train, Y_train)\nvalid_data = create_data_batches(X_val, Y_val, valid_data= True)","800cd948":"sample =next(iter(train_data))\nsample[0][0]","935f126a":"import matplotlib.pyplot as plt \n\ndef show_images(images, label): \n    \"\"\"\n    Display 25 Images with labels. \n    \"\"\"\n    #Setup the figure \n    plt.figure(figsize = (12,12)) \n    for i in range(0,25): \n        ax = plt.subplot(5, 5, i+1)\n        \n        plt.imshow(images[i])\n        \n        plt.title(class_names[tf.argmax(label[i])])\n        \n        plt.axis(\"off\")\n        ","4e51c3cd":"# Visualize training images from the training data batch\ntrain_images, train_labels = next(train_data.as_numpy_iterator())\nshow_images(train_images, train_labels)","ffe0799c":"# Visualize validation images from the validation data batch\nval_images, val_labels = next(valid_data.as_numpy_iterator())\nshow_images(val_images, val_labels)","2eaa0a27":"import tensorflow as tf \nfrom tensorflow.keras import layers \n\ndef create_model():\n    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top = False, \n                                                     classes = len(class_names)) \n    base_model.trainable = False \n\n    inputs = layers.Input(shape = (224,224,3))\n    x = base_model(inputs, training = False) \n    x = tf.keras.layers.GlobalAveragePooling2D(name= \"global_average_pooling\")(x)\n    x = layers.Dropout(0.2)(x)\n    outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n\n\n    ModelDogBreed = tf.keras.Model(inputs, outputs) \n\n    ModelDogBreed.compile(loss = \"categorical_crossentropy\", \n                         optimizer = tf.keras.optimizers.Adam(), \n                         metrics=[\"accuracy\"]) \n\n    return ModelDogBreed","7ef49386":"model = create_model()\n\n# Callbacks \n\nEarlyStoppingCallbacks = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=2, baseline=None, restore_best_weights=True\n)","25c15585":"ModelDogBreed_History = model.fit(train_data, \n                                         steps_per_epoch = len(train_data),\n                                         epochs = 5, \n                                         validation_data= valid_data, \n                                         validation_steps = len(valid_data),\n                                         callbacks = [EarlyStoppingCallbacks])","ba3bfc78":"model.evaluate(valid_data)","601f532b":"def plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n  Args:\n    history: TensorFlow model History object (see: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/History)\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","dcfd604a":"plot_loss_curves(ModelDogBreed_History)","5dd75d03":"predictions = model.predict(valid_data)\npredictions","c6170563":"predictions.shape","5cafc699":"# First prediction\nprint(predictions[0])\nprint(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {class_names[np.argmax(predictions[0])]}\") # the predicted label","10b8b2f1":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return class_names[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","c2c07167":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n  \"\"\"\n  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n  of images and labels.\n  \"\"\"\n  images = []\n  labels = []\n  # Loop through unbatched data\n  for image, label in data.unbatch().as_numpy_iterator():\n    images.append(image)\n    labels.append(class_names[np.argmax(label)])\n  return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(valid_data)\nval_images[0], val_labels[0]","d00d263f":"def plot_pred(prediction_probabilities, labels, images, n=1):\n  \"\"\"\n  View the prediction, ground truth label and image for sample n.\n  \"\"\"\n  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n  # Get the pred label\n  pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n  plt.imshow(image)\n  plt.xticks([])\n  plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\"\n\n  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","4489ea0f":"# View an example prediction, original image and truth label\nplot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images)","9774beae":"def plot_pred_conf(prediction_probabilities, labels, n=1):\n  \"\"\"\n  Plots the top 10 highest prediction confidences along with\n  the truth label for sample n.\n  \"\"\"\n  pred_prob, true_label = prediction_probabilities[n], labels[n]\n\n  # Get the predicted label\n  pred_label = get_pred_label(pred_prob)\n\n  # Find the top 10 prediction confidence indexes\n  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n  # Find the top 10 prediction confidence values\n  top_10_pred_values = pred_prob[top_10_pred_indexes]\n  # Find the top 10 prediction labels\n  top_10_pred_labels = class_names[top_10_pred_indexes]\n\n  # Setup plot\n  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n                     top_10_pred_values, \n                     color=\"grey\")\n  plt.xticks(np.arange(len(top_10_pred_labels)),\n             labels=top_10_pred_labels,\n             rotation=\"vertical\")\n\n  # Change color of true label\n  if np.isin(true_label, top_10_pred_labels):\n    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n  else:\n    pass\n","6c75d8de":"plot_pred_conf(prediction_probabilities=predictions,\n               labels=val_labels,\n               n=9)","c1444e84":"# Let's check a few predictions and their different values\ni_multiplier = 0\nnum_rows = 3\nnum_cols = 2\nnum_images = num_rows*num_cols\nplt.figure(figsize=(5*2*num_cols, 5*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_pred(prediction_probabilities=predictions,\n            labels=val_labels,\n            images=val_images,\n            n=i+i_multiplier)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_pred_conf(prediction_probabilities=predictions,\n                labels=val_labels,\n                n=i+i_multiplier)\nplt.tight_layout(h_pad=1.0)\nplt.show()","18ce2dc0":"# Remind ourselves of the size of the full dataset\nlen(filenames), len(target_labels_encoded)","2b52b1c9":"#Create training batch of data \n\nfull_data = create_data_batches(filenames, target_labels_encoded)","add309b3":"ModelDogBreed_FullData = create_model()  #Create model\nModelDogBreed_FullData.summary()  ","08e2d250":"#Train our final model \n\nFinalModelDogBreed_FullData_History = ModelDogBreed_FullData.fit(full_data, \n                                         steps_per_epoch = len(full_data),\n                                         epochs = 10,\n                                         callbacks = [EarlyStoppingCallbacks])","b168de6e":"# Load test image filenames (since we're using os.listdir(), these already have .jpg)\ntest_path = \"..\/input\/dog-breed-identification\/test\/\"\ntest_filenames = [test_images_path + fname for fname in os.listdir(test_images_path)]\n\ntest_filenames[:10]","549cca91":"#View some test images \nimg = imread(test_filenames[44])\nplt.imshow(img)","0aeee535":"# How many test images are there?\nlen(test_filenames)","f373b0ce":"# Create test data batch\ntest_data = create_data_batches(X=test_filenames, test_data=True)","b1b177a3":"# Make predictions on test data batch using the loaded full model\ntest_predictions = ModelDogBreed_FullData.predict(test_data,\n                                      verbose=1)","27edeedd":"# Create pandas DataFrame with empty columns\npreds_df = pd.DataFrame(columns=[\"id\"] + list(class_names))\npreds_df.head()","84c3fac3":"# Append test image ID's to predictions DataFrame\npreds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","28cb6419":"# Add the prediction probabilities to each dog breed column\npreds_df[list(class_names)] = test_predictions\npreds_df.head()","ea2527e7":"preds_df.to_csv(\"submission_with_mobilienetV2_1.csv\",\n                 index=False)","5f16a3f5":"#### Plot loss curves","1d3e4548":"Ok. In the labels, we have images 'id' and 'breed' which is actually our Target labels. These labels our model need to predict. Great! ","db3e6160":"Great, our function is working and processing images and returning image and label.\n\n### Creating Data Batches","859322cf":"Great, both are having no of images. That, means there are no missing files. ","74267759":"Since, our model can take a fixed image size (224,224) for our model. So, each of the image we will convert to this shape. \n\nWe can use `tf.constant()` to convert image to TF tensor. ","608c3d80":"#### Convert labels to one-hot encoded \n\n\ud83d\udd11**Remember:** An important concept in machine learning is converting your data to numbers before passing it to a machine learning model.","1654cd22":"#### Make prediction on the validation data","b3b4015c":"## 3. Preprocess the Dataset in Tensorflow format. \n\nSince, we are using Tensorflow for modeling, our data needs to be in Tensorflow format. \n\nA Tensor is a way to represent information in numbers. If you're familar with NumPy arrays (you should be), a Tensor can be thought of as a combination of NumPy arrays, except with the special ability to be used on a GPU.\n\nBecause of how TensorFlow stores information (in Tensors), it allows machine learning and deep learning models to be run on GPUs (generally faster at numerical computing).\n\nTo preprocess our image we will write a function to do so: \n\n1. Take image file path. \n2. Read image from path using Tensorflow. \n3. Convert image to Tensor. \n4. Resize our image into fixed Tensor shape (224,224,3) \n5. Return the image\n\n\ud83d\udcd1 **Refrence**: You can read more about Tensorflow dataset from here: https:\/\/www.tensorflow.org\/tutorials\/load_data\/images","e9f811d2":"#### Creating EfficientNetB0 model","deddc8e3":"# Using Tensorflow 2.x Transfer Learning to classify breeds of Dogs \ud83d\udc36\n\n### **About the competition ([Dog breed classification](https:\/\/www.kaggle.com\/c\/dog-breed-identification\/overview)):** \n\nThis compition is to predict the Dog breeds. It consists of a collection of 10,000+ labelled images of 120 different dog breeds. \n\n### **Kind of ML Problem**\nThis kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different breeds of dog. If we were only trying to classify dogs versus cats, it would be called binary classification.\n\n### **TensorFlow\/Deep Learning workflow we will be using:**\n![image.png](attachment:45ebf86f-9bea-48bb-819e-8289c86f70b9.png)\n\n1. Getting data ready import dataset.\n2. Visualize the Dataset. \n3. Preprocess the Dataset for Tensorflow format.\n4. Prepare Tensorflow Tranfer learning Model. \n5. Train the model. \n6. Visualize the model results. \n7. Predict on test model.","58d31d63":"## Preparing test dataset predictions for Kaggle","e4413994":"## Visualizing Images \n\nLet's build a function which helps us visualize what going on under the hood. ","f5e12ae3":"Wonderful! Now we've got our labels in a numeric format and our image filepaths easily accessible (they aren't numeric yet), let's split our data up.\n\n### Split Train & validation data","a27c4ae2":"As we can see from the, our image `dtype` is `uint8` and tensorflow like data into `float32`. And we will also normalize our images by diving by 255 for values between 0 and 1.","c42ed0ee":"## Getting data ready import dataset.","c00b5de6":"Hmm, We learnt from here two things: \n\n* There are 10222 images in train folder which will be used for training. \n* There are 10357 images in test folder which will be used for testing. ","624c1668":"## Train on full data\n\nRemember we created two list `filenames` for storing file paths of training data and `target_labels_encoded` for target labels of dog breed. ","7c18bcff":"## Creating Model ","6b10a4d8":"### 2.Visualize the input data \n\n","99d0ac7c":"* So, there are 120 breeds. \n* On an average there are around 85 images. Thats, a good number. \n\nSo, making ML model from scratch will not be good option as images are pretty less. \nSo, What can we do? \n\nWe can take help of **Transfer Learning**. \n\nThe process of using a pretrained model and adapting it to your own problem is called transfer learning. We do this because rather than train our own model from scratch (could be timely and expensive), we leverage the patterns of another model which has been trained to classify images. ","1e46b7a8":"## Process train & Test data","063d8ac1":"## What's next?\n\nWoah! What an effort. If you've made it this far, you've just gone end-to-end on a multi-class image classification problem.\n\nYou can try using other approaches to improve your model. \n\n1. [Trying another model from TensorFlow Hub](https:\/\/tfhub.dev\/) - Perhaps a different model would perform better on our dataset. One option would be to experiment with a different pretrained model from TensorFlow Hub or look into the tf.keras.applications module.\n2. [Data augmentation](https:\/\/www.tensorflow.org\/tutorials\/images\/data_augmentation) - Take the training images and manipulate (crop, resize) or distort them (flip, rotate) to create even more training data for the model to learn from. Check out the TensorFlow images documentation for a whole bunch of functions you can use on images. A great idea would be to try and replicate the techniques in this example cat vs. dog image classification notebook for our dog breeds problem.\n3. [Fine-tuning](https:\/\/www.tensorflow.org\/hub\/tf2_saved_model#fine-tuning) - The model we used in this notebook was directly from TensorFlow Hub, we took what it had already learned from another dataset (ImageNet) and applied it to our own. Another option is to use what the model already knows and fine-tune this knowledge to our own dataset (pictures of dogs). This would mean all of the patterns within the model would be updated to be more specific to pictures of dogs rather than general images."}}