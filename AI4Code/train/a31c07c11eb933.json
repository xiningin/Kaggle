{"cell_type":{"c9724f5d":"code","b463b86f":"code","7d1b453c":"code","3c82a338":"code","ee706e15":"code","29f14bef":"code","3ae2515a":"code","14812192":"code","6d15d8f8":"code","33128288":"code","f2cd4cd9":"code","09a5640f":"code","9bbd544a":"code","f58e5e58":"code","092495f0":"code","d449c0e6":"code","29b4dacb":"code","3907dd9e":"code","8285db4c":"code","1818bb37":"code","0f95dd08":"code","f6faada6":"code","709cda42":"code","65927919":"code","8a2d72b2":"code","a2c7560e":"code","68e97c9d":"code","97c04b14":"code","5d0587eb":"code","0944c910":"code","4ff55806":"code","2d64a70c":"code","6048a67d":"code","49597693":"code","98822ac6":"code","8a597fba":"code","81a52ac0":"code","a71e913a":"code","8d567702":"code","793c4d1a":"code","a25d6180":"code","c60322d1":"code","baea26a7":"code","0a315f93":"code","8bac9c38":"code","ac797ef6":"code","35804951":"code","b6a51678":"code","9f76a9ad":"code","a850dabb":"code","d3e94fcf":"code","a74e4ba4":"code","598b12c0":"code","f395d36c":"code","44c3a271":"code","b3a15479":"code","0092084d":"code","5eb08840":"code","de8308fa":"code","be2b9875":"code","704745ee":"code","8f00ca07":"code","6392398f":"code","cd73341d":"code","0c5cb281":"code","4d844bfb":"code","4608de73":"code","7b06dcf1":"code","0e92dd37":"code","8e3c10c7":"code","5a883aa9":"code","945e36e4":"code","4b778209":"code","b4333e60":"code","4e259685":"code","38d421ae":"code","f2d492c6":"code","2265af42":"code","e58e51d7":"code","c698c73a":"code","06120394":"code","b7749568":"code","cc832a91":"code","272198ff":"code","8bf20f8b":"code","0242b5fa":"code","21764ed6":"code","95051002":"code","df757f95":"code","2a432720":"code","e2461335":"code","138792e5":"code","6dcd58c3":"code","e20baa95":"code","d40d8fb9":"code","31509d8f":"code","e6a68262":"code","6b25904f":"code","3558a746":"code","fa5c673d":"code","79ce3d23":"code","69e5f7da":"code","6b0475b1":"code","700315cc":"code","bd38789d":"code","d7566c43":"code","db1b4ff2":"code","8f374f9f":"code","ac413936":"code","ed038713":"code","a8e61836":"code","b2a15552":"code","1a1ec13a":"code","b50d9dd5":"code","6096a0d8":"code","601b4c06":"code","88b081d9":"code","3d81d324":"code","faa3e3e7":"markdown","d625c746":"markdown","f693c0b9":"markdown","5e396540":"markdown","b7c45d41":"markdown","3d64ef14":"markdown","9c9bff1d":"markdown","28f65258":"markdown","56a51537":"markdown","fc7e9221":"markdown","0af556a2":"markdown"},"source":{"c9724f5d":"# load datasets from kaggle\ndef get_data():\n    !mkdir \/kaggle\n    !mkdir \/kaggle\/input\n    !pip install -q kaggle\n    from google.colab import files\n    files.upload()\n    !mkdir -p ~\/.kaggle\n    !mv kaggle.json ~\/.kaggle\/\n    !chmod 600 \/root\/.kaggle\/kaggle.json\n\n    !kaggle datasets download -d meraxes10\/bd-models\n    !unzip bd-models.zip -d \/kaggle\/input\/bd-models > \/dev\/null\n    !rm bd-models.zip    \n\n    !!kaggle datasets download -d azathoth42\/myanimelist\n    !unzip myanimelist.zip -d \/kaggle\/input\/myanimelist > \/dev\/null\n    !rm myanimelist.zip","b463b86f":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip","7d1b453c":"#get_data()","3c82a338":"!pip install pyspark > \/dev\/null","ee706e15":"import pyspark\nfrom pyspark.sql import SparkSession","29f14bef":"from pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import Window","3ae2515a":"import pyspark.ml.feature\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, CountVectorizer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.stat import Summarizer","14812192":"import numpy as np\nimport re\nimport gc","6d15d8f8":"SEED = 42","33128288":"ROOT = '\/kaggle\/input\/myanimelist\/'","f2cd4cd9":"from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SQLContext","09a5640f":"conf = SparkConf().set(\"spark.ui.port\", \"4050\") \\\n                  .set('spark.executor.memory', '9G') \\\n                  .set('spark.driver.memory', '7G') \\\n                  .set('spark.sql.autoBroadcastJoinThreshold', '-1')\n\nsc = pyspark.SparkContext(conf=conf)\nspark = SparkSession.builder.getOrCreate()","9bbd544a":"get_ipython().system_raw('.\/ngrok http 4050 &')","f58e5e58":"!curl -s http:\/\/localhost:4040\/api\/tunnels","092495f0":"!curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","d449c0e6":"anime_df = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n                                   .option(\"headers\", \"true\") \\\n                                   .option('escape','\"') \\\n                                   .option(\"inferSchema\", \"true\") \\\n                                   .load(ROOT + \"AnimeList.csv\", sep=',')","29b4dacb":"cols = ['title', 'title_english', 'title_japanese', 'title_synonyms', 'image_url', 'aired_string', 'background',\n       'broadcast', 'related', 'opening_theme', 'ending_theme', 'studio']\nanime_df = anime_df.drop(*cols)","3907dd9e":"cols = ['premiered', 'producer', 'licensor', 'rank']\nanime_df = anime_df.drop(*cols)","8285db4c":"cols = ['aired', 'duration', 'airing']\nanime_df = anime_df.drop(*cols)","1818bb37":"anime_df = anime_df.fillna('', subset=['genre'])","0f95dd08":"anime_df = anime_df.withColumn(\n    'genre',\n    split(regexp_replace('genre', ' ', ''), ',').cast(\"array<string>\").alias(\"genre\")\n)","f6faada6":"anime_df = anime_df.withColumn(\"episodes\", anime_df.episodes.cast('float'))\nanime_df = anime_df.withColumn(\"score\", anime_df.score.cast('float'))\nanime_df = anime_df.withColumn(\"scored_by\", anime_df.scored_by.cast('float'))\nanime_df = anime_df.withColumn(\"popularity\", anime_df.popularity.cast('float'))\nanime_df = anime_df.withColumn(\"members\", anime_df.members.cast('float'))\nanime_df = anime_df.withColumn(\"favorites\", anime_df.favorites.cast('float'))","709cda42":"anime_df.show(5)","65927919":"anime_df = CountVectorizer(inputCol=\"genre\", outputCol=\"genre_fv\").fit(anime_df).transform(anime_df)\nanime_df = anime_df.drop('genre')","8a2d72b2":"categoricalColumns = ['type', 'source', 'status', 'rating']\nstages = []\nfor categoricalCol in categoricalColumns:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n    stages += [stringIndexer, encoder]","a2c7560e":"numericCols = ['episodes', 'score', 'scored_by', 'popularity', 'members', 'favorites', 'genre_fv'] \nassemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"item_feats_profile\")\nstages += [assembler]","68e97c9d":"@udf(\"array<integer>\")\ndef indices(v):\n    return v.indices.tolist()","97c04b14":"pipeline = Pipeline(stages = stages)\npipelineModel = pipeline.fit(anime_df)\nanime_df = pipelineModel.transform(anime_df)","5d0587eb":"selectedCols = ['anime_id', 'item_feats_profile']\nanime_df = anime_df.select(selectedCols)","0944c910":"anime_df.show(5)","4ff55806":"user_df = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n                                   .option(\"headers\", \"true\") \\\n                                   .option('escape','\"') \\\n                                   .option(\"inferSchema\", \"true\") \\\n                                   .load(ROOT + \"UserList.csv\", sep=',')","2d64a70c":"user_df = user_df.filter(col('username').isNotNull())\nuser_df = user_df.filter(col('stats_episodes').isNotNull())","6048a67d":"cols = ['location', 'access_rank', 'stats_mean_score', 'birth_date', 'gender']\nuser_df = user_df.drop(*cols)","49597693":"cols = ['join_date', 'last_online']\nuser_df = user_df.drop(*cols)","98822ac6":"user_df = user_df.withColumn(\"user_id\", user_df.user_id.cast('float'))\nuser_df = user_df.withColumn(\"user_watching\", user_df.user_watching.cast('float'))\nuser_df = user_df.withColumn(\"user_completed\", user_df.user_completed.cast('float'))\nuser_df = user_df.withColumn(\"user_onhold\", user_df.user_onhold.cast('float'))\nuser_df = user_df.withColumn(\"user_dropped\", user_df.user_dropped.cast('float'))\nuser_df = user_df.withColumn(\"user_plantowatch\", user_df.user_plantowatch.cast('float'))\nuser_df = user_df.withColumn(\"user_days_spent_watching\", user_df.user_days_spent_watching.cast('float'))\nuser_df = user_df.withColumn(\"stats_rewatched\", user_df.stats_rewatched.cast('float'))\nuser_df = user_df.withColumn(\"stats_episodes\", user_df.stats_episodes.cast('float'))","8a597fba":"user_df.show(5)","81a52ac0":"cols = ['user_watching', 'user_completed', 'user_onhold', 'user_dropped', 'user_plantowatch', 'user_days_spent_watching', \n        'stats_rewatched', 'stats_episodes']\nassembler = VectorAssembler(inputCols=cols, outputCol=\"user_feats_profile\")\nstages = [assembler]","a71e913a":"pipeline = Pipeline(stages = stages)\npipelineModel = pipeline.fit(user_df)\nuser_df = pipelineModel.transform(user_df)","8d567702":"selectedCols = ['username', 'user_id', 'user_feats_profile']\nuser_df = user_df.select(selectedCols)","793c4d1a":"user_df.show(5)","a25d6180":"user_anime_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(ROOT + \"UserAnimeList.csv\")","c60322d1":"cols = ['my_watched_episodes', 'my_start_date', 'my_finish_date', 'my_status', 'my_rewatching', \n        'my_rewatching_ep', 'my_last_updated', 'my_tags']\nuser_anime_df = user_anime_df.drop(*cols)","baea26a7":"user_anime_df = user_anime_df.withColumn(\"anime_id\", user_anime_df.anime_id.cast('float'))\nuser_anime_df = user_anime_df.withColumn(\"my_score\", user_anime_df.my_score.cast('float'))","0a315f93":"user_anime_df = user_anime_df.na.drop()","8bac9c38":"user_anime_df = user_anime_df.filter(user_anime_df.my_score <= 10)","ac797ef6":"user_anime_df = user_anime_df.filter(user_anime_df.my_score != 0)","35804951":"user_anime_df.show(5)","b6a51678":"user_anime_df = user_anime_df.join(user_df, 'username', how='left')","9f76a9ad":"user_anime_df = user_anime_df.drop('username')","a850dabb":"user_anime_df = user_anime_df.join(anime_df, 'anime_id', how='left')","d3e94fcf":"user_anime_df = user_anime_df.na.drop()","a74e4ba4":"assembler = VectorAssembler(inputCols=[\"user_feats_profile\", \"item_feats_profile\"], outputCol=\"features\")","598b12c0":"user_anime_df = assembler.transform(user_anime_df)","f395d36c":"user_anime_df.show(5)","44c3a271":"(training, test) = user_anime_df.randomSplit([0.8, 0.2], seed=SEED)","b3a15479":"(training, valid) = training.randomSplit([0.9, 0.1], seed=SEED)","0092084d":"avg_score_by_anime = training.groupBy('anime_id').agg(avg('my_score').alias('preds_0'))","5eb08840":"avg_score = training.agg(avg('my_score').alias('overall_average'))","de8308fa":"c = avg_score.collect()","be2b9875":"valid = valid.join(avg_score_by_anime, 'anime_id', how='left')","704745ee":"valid = valid.fillna(c[0].overall_average, subset=['preds_0'])","8f00ca07":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"preds_0\")\nrmse = evaluator.evaluate(valid)","6392398f":"print(\"RMSE:\" + str(rmse))","cd73341d":"test = test.join(avg_score_by_anime, 'anime_id', how='left')","0c5cb281":"test = test.fillna(c[0].overall_average, subset=['preds_0'])","4d844bfb":"avg_score_by_user = training.groupBy('user_id').agg(avg('my_score').alias('preds_1'))","4608de73":"valid = valid.join(avg_score_by_user, 'user_id', how='left')","7b06dcf1":"valid = valid.fillna(c[0].overall_average, subset=['preds_1'])","0e92dd37":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"preds_1\")\nrmse = evaluator.evaluate(valid)","8e3c10c7":"print(\"RMSE:\" + str(rmse))","5a883aa9":"test = test.join(avg_score_by_user, 'user_id', how='left')","945e36e4":"test = test.fillna(c[0].overall_average, subset=['preds_1'])","4b778209":"from pyspark.ml.regression import RandomForestRegressor, RandomForestRegressionModel","b4333e60":"rf = RandomForestRegressor(featuresCol='features', labelCol='my_score', \n                           numTrees=5, maxMemoryInMB=1024,\n                           subsamplingRate=0.1)","4e259685":"#rf_model = rf.fit(training)","38d421ae":"rf_model = RandomForestRegressionModel.load('\/kaggle\/input\/bd-models\/rf_model')","f2d492c6":"valid = rf_model.transform(valid)","2265af42":"valid = valid.withColumnRenamed(\"prediction\", \"preds_2\")","e58e51d7":"test = rf_model.transform(test)","c698c73a":"test = test.withColumnRenamed(\"prediction\", \"preds_2\")","06120394":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"preds_2\")\nrmse = evaluator.evaluate(valid)","b7749568":"print(\"RMSE:\" + str(rmse))","cc832a91":"from pyspark.ml.regression import LinearRegression, LinearRegressionModel\nfrom pyspark.ml.feature import StandardScaler, StandardScalerModel","272198ff":"scaler = StandardScaler(inputCol=\"features\", \n                        outputCol=\"std_features\",\n                        withStd=True, withMean=True)","8bf20f8b":"#model_scaler = scaler.fit(training)","0242b5fa":"model_scaler = StandardScalerModel.load('\/kaggle\/input\/bd-models\/scaler_model')","21764ed6":"training = model_scaler.transform(training)\nvalid = model_scaler.transform(valid)\ntest = model_scaler.transform(test)","95051002":"lm = LinearRegression(featuresCol='std_features', labelCol='my_score', maxIter=10)","df757f95":"#lr_model = lm.fit(training)","2a432720":"lr_model = LinearRegressionModel.load('\/kaggle\/input\/bd-models\/lr_model')","e2461335":"valid = lr_model.transform(valid)\ntest = lr_model.transform(test)","138792e5":"valid = valid.withColumnRenamed(\"prediction\", \"preds_3\")\ntest = test.withColumnRenamed(\"prediction\", \"preds_3\")","6dcd58c3":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"preds_3\")\nrmse = evaluator.evaluate(valid)","e20baa95":"print(\"RMSE:\" + str(rmse))","d40d8fb9":"from pyspark.ml.recommendation import ALS, ALSModel\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit","31509d8f":"als = ALS(userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"my_score\", coldStartStrategy=\"drop\")\n\nparam_grid = ParamGridBuilder().addGrid(als.rank, [25]) \\\n                               .addGrid(als.regParam, [0.1, 0.15]) \\\n                               .addGrid(als.maxIter, [10]) \\\n                               .build()","e6a68262":"tvs = TrainValidationSplit(estimator=als,\n                           estimatorParamMaps=param_grid,\n                           evaluator=RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"prediction\"),\n                           trainRatio=0.8)","6b25904f":"maxIter = 10\nregParam = 0.1\nrank=25","3558a746":"als = ALS(maxIter=maxIter, regParam=regParam, rank=rank, \n          userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"my_score\",\n          coldStartStrategy=\"drop\")","fa5c673d":"#als_model = als.fit(training)","79ce3d23":"als_model = ALSModel.load('\/kaggle\/input\/bd-models\/als_model')","69e5f7da":"valid = als_model.transform(valid)\ntest = als_model.transform(test)","6b0475b1":"valid = valid.withColumnRenamed(\"prediction\", \"preds_4\")\ntest = test.withColumnRenamed(\"prediction\", \"preds_4\")","700315cc":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"preds_4\")\nrmse = evaluator.evaluate(valid)","bd38789d":"print(\"RMSE:\" + str(rmse))","d7566c43":"userRecs = als_model.recommendForAllUsers(10)","db1b4ff2":"userRecs.show(5)","8f374f9f":"alpha_0 = 0.1\nalpha_1 = 0.1\nalpha_2 = 0.1\nalpha_3 = 0.1\nalpha_4 = 0.6","ac413936":"valid = valid.fillna(c[0].overall_average)","ed038713":"valid = valid.withColumn('prediction', alpha_0*valid['preds_0'] + alpha_1*valid['preds_1'] + alpha_2*valid['preds_2'] + alpha_3*valid['preds_3'] + alpha_4*valid['preds_4'] )","a8e61836":"valid = valid.select(['anime_id', 'user_id', 'my_score', 'prediction'])","b2a15552":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"prediction\")\nrmse = evaluator.evaluate(valid)","1a1ec13a":"print(\"RMSE:\" + str(rmse))","b50d9dd5":"test = test.fillna(c[0].overall_average)","6096a0d8":"test = test.withColumn('prediction', alpha_0*test['preds_0'] + alpha_1*test['preds_1'] + alpha_2*test['preds_2'] + alpha_3*test['preds_3'] + alpha_4*test['preds_4'] )","601b4c06":"test = test.select(['anime_id', 'user_id', 'my_score', 'prediction'])","88b081d9":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"my_score\", predictionCol=\"prediction\")\nrmse = evaluator.evaluate(test)","3d81d324":"print(\"RMSE:\" + str(rmse))","faa3e3e7":"Split training, oof, test","d625c746":"User-anime data pre-processing","f693c0b9":"User data pre-processing","5e396540":"Anime data pre-processing","b7c45d41":"Random Forest","3d64ef14":"Test","9c9bff1d":"Linear Regression","28f65258":"ALS","56a51537":"Popularity based","fc7e9221":"Biased User Model","0af556a2":"Ensemble"}}