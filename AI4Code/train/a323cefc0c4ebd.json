{"cell_type":{"75db7f28":"code","72caad36":"code","66282be2":"code","8df877bc":"code","bf5f030a":"code","641b1aef":"code","2342ed2c":"code","1bfb671f":"code","b28af894":"code","665282fd":"code","6a946008":"code","dcb96216":"code","fa42b1e1":"code","fe2247ba":"code","44a8e368":"code","6a25f21c":"code","f92678cb":"markdown","d223b4b6":"markdown","b56a728e":"markdown","fa430879":"markdown","34933e83":"markdown","38004aff":"markdown"},"source":{"75db7f28":"#Usual Imports\nimport skimage.io\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nimport cv2\nimport torch\nfrom pathlib import Path\nimport pandas as pd\nfrom tqdm import tqdm","72caad36":"#Check input file\n!ls ..\/input\/prostate-cancer-grade-assessment\/train_images\/008069b542b0439ed69b194674051964.tiff","66282be2":"#Load input file and check dimensions\nfile_path = f'..\/input\/prostate-cancer-grade-assessment\/train_images\/008069b542b0439ed69b194674051964.tiff'\nimage = skimage.io.MultiImage(file_path)\nimage = cv2.cvtColor(image[0], cv2.COLOR_BGR2RGB)\nimage.shape","8df877bc":"#Display the file\nplt.imshow(image)","bf5f030a":"#Convert to torch and CHW format\ninput = torch.from_numpy(image)\ninput.transpose_(0, 2).shape","641b1aef":"# Create patches of size 512x512\npatch_size = 512\nstride=patch_size\n\npatches = input.data.unfold(0, 3, 3).unfold(1, patch_size, stride).unfold(2, patch_size, stride)\npatches.shape","2342ed2c":"def plot_image(tensor):\n    plt.figure()\n    plt.imshow(tensor.numpy().transpose(1, 2, 0))\n    plt.show()\n    \ndef showTensor(aTensor):\n    plt.figure()\n    plt.imshow(aTensor.numpy())\n    plt.colorbar()\n    plt.show()","1bfb671f":"#Load mask file\nmask_path = f'..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/008069b542b0439ed69b194674051964_mask.tiff'\nmask = skimage.io.MultiImage(mask_path)\nmask = cv2.cvtColor(mask[0], cv2.COLOR_BGR2RGB)\nmask.shape","b28af894":"#Only the third channel has the markings\nnp.unique(mask[:,:,2])","665282fd":"#Convert to torch and CHW format\ninput_mask = torch.from_numpy(mask)\ninput_mask.transpose_(0, 2).shape","6a946008":"mask_patches = input_mask.data.unfold(0, 3, 3).unfold(1, patch_size, stride).unfold(2, patch_size, stride)\nmask_patches.shape","dcb96216":"#Show a Random Patch\nplot_image(patches[0][40][3])\nshowTensor(mask_patches[0][40][3][-1]);","fa42b1e1":"train=pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/train.csv')\ncheck_score = train.loc[train['data_provider'] == 'radboud',['image_id','gleason_score']]","fe2247ba":"check_score=check_score.head(5)","44a8e368":"output=list()\nfor index, row in tqdm(check_score.iterrows()):\n    filename = row.image_id\n    gleason_score = row.gleason_score\n    mask_path = Path('..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/'+filename+'_mask.tiff')\n    mask = skimage.io.MultiImage(str(mask_path))\n    mask = cv2.cvtColor(mask[0], cv2.COLOR_BGR2RGB)\n    input_mask = torch.from_numpy(mask)\n    input_mask.transpose_(0, 2)\n\n    a,b = torch.unique(input_mask, return_counts=True)\n    a,b = a.numpy(),b.numpy()\n    i = 0 if a[0]!=0 else 1    \n    c = b[i:]\/np.sum(b[i:])*100\n\n    #dict(zip(a[1:], c))\n    final = [filename,[(k,v) for k,v in dict(zip(a[1:], c)).items()],gleason_score]\n    del mask_path,mask,input_mask, a,b,i,c \n    output = output+final\n    ","6a25f21c":"output","f92678cb":"## Get the percentage Distribution from Masks and cross check with Gleason Score","d223b4b6":"Based on the label distribution in the masks, it appears files '*004dd32d9cd167d9cc31c13b704498af*' and '*0068d4c7529e34fd4c9da863ce01a161*' are incorrectly labelled.\n\nThere is are no markings of \"cancerous epithelium (Gleason 3)\" but score is given as '3+3' in first case.\nIn the second \"cancerous epithelium (Gleason 3)\" is only 0.005% and no marking for \"cancerous epithelium (Gleason 4)\"\n\nMore checking might be needed to evaluate all the 5160 files marked in radboud.","b56a728e":"### Steps to create sliding window images slices with Pytorch\nSliding window is the standard approach used to process WSI, so that the input files can be accomodated in the GPU. The whole image is broken into tiles of regular size and then fed into classification or segmentation algorithms","fa430879":"# Pre-Processing and Analysis\n* Version 1: Create Patches from Images\n* Version 2: Create Patches from Masks\n* Version 3: Check if the marking distribution aligns with the Gleason Score given","34933e83":"![image.png](attachment:image.png)","38004aff":"The value '0' in the mask corresponds to background and unknown areas, let us avoid those and check the percentage distribution of other labels and see if it matches with the Gleason Score.\n\nWe are considering the markings made under 'radboud' category as its straight forward to derive the Gleason score based on the markings which range from 0 to 5."}}