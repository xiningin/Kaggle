{"cell_type":{"2e0caf7c":"code","77cf488b":"code","96b8415c":"code","cbb53dd8":"code","ae012d81":"code","dd2d3f92":"code","3df35b45":"code","653df4df":"code","f9899dda":"code","47ee903d":"code","cee45e78":"code","6a61fe0e":"code","31573b3d":"code","21bbac88":"code","54f2e0f4":"code","c431ad2c":"code","1a4520f4":"code","7e206ca8":"code","f12af1d4":"code","30e9ecfb":"code","712b6f8b":"code","7a779be9":"code","7d93bad6":"code","a66b772c":"code","f47ad926":"code","26ccb918":"code","09bdf4b4":"code","41400c13":"code","3534e7e5":"code","f8985976":"code","ee763d1a":"code","bc49e27c":"code","9d8a369c":"code","f0e52e49":"code","7f782945":"code","d861e078":"markdown","d87ab87b":"markdown","af73331f":"markdown","537cfabd":"markdown"},"source":{"2e0caf7c":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout , Lambda, Flatten\nfrom keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\nimport warnings \nwarnings.filterwarnings('ignore')","77cf488b":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","96b8415c":"train = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()","cbb53dd8":"test= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()\n","ae012d81":"X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","dd2d3f92":"X_train","3df35b45":"y_train","653df4df":"X_train = X_train.reshape(X_train.shape[0], 28, 28)\n\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);","f9899dda":"X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_train.shape","47ee903d":"X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nX_test.shape\n","cee45e78":"mean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px","6a61fe0e":"from keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes\n","31573b3d":"plt.title(y_train[9])\nplt.plot(y_train[9])\nplt.xticks(range(10));","21bbac88":"# fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","54f2e0f4":"from keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D","c431ad2c":"model= Sequential()\nmodel.add(Lambda(standardize,input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nprint(\"input shape \",model.input_shape)\nprint(\"output shape \",model.output_shape)","1a4520f4":"from keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","7e206ca8":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","f12af1d4":"from sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches=gen.flow(X_val, y_val, batch_size=64)","30e9ecfb":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, \n                    validation_data=val_batches, validation_steps=val_batches.n)","712b6f8b":"history_dict = history.history\nhistory_dict.keys()","7a779be9":"import matplotlib.pyplot as plt\n%matplotlib inline\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss_values, 'bo')\n# b+ is for \"blue crosses\"\nplt.plot(epochs, val_loss_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","7d93bad6":"plt.clf()   # clear figure\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\n\nplt.plot(epochs, acc_values, 'bo')\nplt.plot(epochs, val_acc_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.show()","a66b772c":"def get_fc_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(optimizer='Adam', loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","f47ad926":"fc = get_fc_model()\nfc.optimizer.lr=0.01","26ccb918":"history=fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","09bdf4b4":"from keras.layers import Convolution2D, MaxPooling2D","41400c13":"def get_cnn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Convolution2D(64,(3,3), activation='relu'),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","3534e7e5":"model= get_cnn_model()\nmodel.optimizer.lr=0.01","f8985976":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","ee763d1a":"gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                               height_shift_range=0.08, zoom_range=0.08)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches = gen.flow(X_val, y_val, batch_size=64)","bc49e27c":"model.optimizer.lr=0.001\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","9d8a369c":"from keras.layers.normalization import BatchNormalization\n\ndef get_bn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","f0e52e49":"model= get_bn_model()\nmodel.optimizer.lr=0.01\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","7f782945":"model.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(X, y, batch_size=64)\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","d861e078":"# Convolutional Neural Network ","d87ab87b":"## Convolutional neural networks are highly effective for dealing with images","af73331f":"# Data Augmentation techniques --> \n1. cropping \n2. Rotating \n3. Scale \n4. Translate \n5. Flip \n6. Adding Gausian Noise to input images \n","537cfabd":"# Fully Connected Model "}}