{"cell_type":{"94ec3403":"code","f069b527":"code","219c4c8f":"code","21a50d48":"code","c958d0a3":"code","a8301f57":"code","d7bf9098":"code","d2024cc0":"code","5bfdff19":"code","5c5876de":"code","6c52083c":"code","d2ab3a1f":"code","d3bdea5f":"code","c1466bfd":"code","3b7f93c6":"code","ebedbfd0":"code","bf1e668a":"code","e9100b26":"code","b897cf94":"code","44b9d521":"code","704d4ab2":"code","408f8f0d":"code","5337b54a":"code","b99f4232":"code","5cb0275d":"code","682a1d16":"code","73efad68":"code","2723f0d3":"code","65603b04":"code","74a243ba":"code","d3448465":"code","f8cee634":"code","dddf57db":"code","7507e0a2":"code","bdcfc6cd":"code","5a6ad2c2":"code","60029010":"code","1bb6b475":"code","98863495":"code","d41b1a3a":"code","2c85227a":"code","e0ac5612":"code","cafea263":"code","b416c888":"code","32d18f1b":"code","e31c3fcf":"code","74b38059":"code","207b018b":"markdown","df5fb197":"markdown","5a888fe0":"markdown","2635bcfb":"markdown","d4fcb74b":"markdown","a8672a7d":"markdown","b751a16a":"markdown","ffd5d3a4":"markdown"},"source":{"94ec3403":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f069b527":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","219c4c8f":"#import dataset\ntitanic_train = pd.read_csv('..\/input\/titanic\/train.csv')\ntitanic_test_x = pd.read_csv('..\/input\/titanic\/test.csv')\ntitanic_test_y = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","21a50d48":"titanic_test = pd.merge(titanic_test_x, titanic_test_y, on=\"PassengerId\")","c958d0a3":"titanic_test.head()","a8301f57":"titanic_overall = pd.concat([titanic_train, titanic_test], axis=0, ignore_index=True)\ntitanic_overall.head()","d7bf9098":"titanic_test.info()","d2024cc0":"titanic_overall.info()","5bfdff19":"titanic_overall.describe()","5c5876de":"titanic_overall.info()","6c52083c":"#count the number of missing values in each column\ntitanic_overall.isnull().sum()","d2ab3a1f":"plt.figure(figsize=(12,7))\nsns.heatmap(titanic_overall.isnull(), cbar=False, cmap='viridis')","d3bdea5f":"plt.figure(figsize=(12,7))\nsns.boxplot(x=titanic_overall['Pclass'], y=titanic_overall['Age'], palette='winter')","c1466bfd":"plt.figure(figsize=(12,7))\nbox_plot = sns.boxplot(x='Pclass', y='Age',data= titanic_overall, palette='winter')\ngrp = titanic_overall.groupby('Pclass')\npclass_median = titanic_overall.groupby(['Age'])['Pclass'].median()\nvertical_offset = titanic_overall['Age'].median() * 0.05\n\n# for xtick in box_plot.get_xticks():\n#     box_plot.text(xtick, pclass_median[xtick] + vertical_offset, pclass_median[xtick], \n#             horizontalalignment='center',size='x-small',color='w',weight='semibold')\n    \n# plt.show()","3b7f93c6":"#put average age for each cabin size to fill in the missing values of each cabin class for age\n#Class 1 avg ard 34\n#Class 2 avg ard 28\n#Class 3 avg ard \ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age\ntitanic_overall['Age'] = titanic_overall.apply(impute_age, axis=1)\nsns.heatmap(titanic_overall.isnull(),yticklabels=False, cbar=False,cmap='viridis')\ntitanic_overall.isnull().sum()\n","ebedbfd0":"#drop the whole cabin column\ntitanic_overall.drop('Cabin', axis=1, inplace=True)\ntitanic_overall.head()","bf1e668a":"titanic_overall.head()","e9100b26":"titanic_overall.isnull().sum()","b897cf94":"titanic_overall['Fare'].fillna(titanic_overall['Fare'].mean(),inplace=True)","44b9d521":"titanic_overall.iloc[1043:,:]","704d4ab2":"titanic_overall[pd.isnull(titanic_overall['Fare'])]","408f8f0d":"titanic_overall[pd.isnull(titanic_overall['Ticket'])]","5337b54a":"titanic_overall.dropna(inplace=True)         #dropna will remove the whole row with NaN","b99f4232":"titanic_overall.shape                         #originally 1309, 2 NaN from embarked, 1 NaN from Fare, so dropped 3 rows","5cb0275d":"titanic_overall.head()","682a1d16":"embark = pd.get_dummies(titanic_overall['Embarked'], drop_first=True)","73efad68":"sex = pd.get_dummies(titanic_overall['Sex'], drop_first=True)","2723f0d3":"#drop columns that are not required\ntitanic_overall.drop(['Sex', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)","65603b04":"titanic_overall.head()","74a243ba":"#Combine dummy variables to titanic_overall dataframe\ntitanic_overall = pd.concat([titanic_overall, sex, embark], axis=1)","d3448465":"titanic_overall.head()","f8cee634":"titanic_overall.drop('Survived', axis=1).head()","dddf57db":"titanic_overall['Survived'].head()","7507e0a2":"x = titanic_overall.drop('Survived', axis=1)\ny = titanic_overall['Survived']\n\n\ntrain = titanic_overall.iloc[:888,:]\ntest = titanic_overall.iloc[889:,:]\n\n\n","bdcfc6cd":"XX_train = train.drop('Survived', axis=1)\nyy_train = train['Survived']\n\nXX_test = test.drop('Survived', axis=1)\nyy_test = test['Survived']","5a6ad2c2":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(titanic_overall.drop('Survived', axis=1),\n#                                                      titanic_overall['Survived'], test_size=0.3,\n#                                                      random_state= 101)","60029010":"from sklearn.linear_model import LogisticRegression","1bb6b475":"logmodel = LogisticRegression()\nlogmodel.fit(XX_train, yy_train)","98863495":"predictions = logmodel.predict(XX_test)","d41b1a3a":"from sklearn.metrics import confusion_matrix","2c85227a":"accuracy= confusion_matrix(yy_test, predictions)","e0ac5612":"accuracy","cafea263":"from sklearn.metrics import accuracy_score","b416c888":"accuracy= accuracy_score(yy_test, predictions)\naccuracy","32d18f1b":"predictions","e31c3fcf":"XX_test.head()","74b38059":"my_submission = pd.DataFrame({'PassengerId': XX_test.PassengerId, 'Survived': predictions})\nmy_submission.to_csv('210619_submission.csv', index=False)","207b018b":"### Prepare Train and Test Data ","df5fb197":"### Training and Prediction","5a888fe0":"### Find out Missing Data\n\n#### Show Missing Value by Tabulation","2635bcfb":"### Data Cleaning: Remove\/Fill Missing Values\n\n#### Age and cabins columns gt missing values, so focus on these columns","d4fcb74b":"#### Show Missing Values by Visualization","a8672a7d":"### Prepare Submission File","b751a16a":"## Building a Logistic Regression Model\n\nLet's start by splitting our data into a training set and test set ","ffd5d3a4":"### Convert to Categorical Features (Dummy Variables)"}}