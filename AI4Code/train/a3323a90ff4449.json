{"cell_type":{"6f063ec9":"code","81797683":"code","ac18acb5":"code","f2a80bb2":"code","924b312f":"code","8bc1edd5":"code","bf6fb164":"code","c4bada0e":"code","8908e3a0":"code","1a52bb9c":"code","f592d7c2":"code","bbf0e727":"code","0bd4b6f9":"code","2b890295":"code","ab8487db":"code","34b30ff3":"code","7a4b86ea":"code","cc1ce9e0":"code","300a4b74":"code","1a5a7dec":"code","ccdf4981":"code","0ee30107":"code","17275c7d":"code","c70a9d00":"code","a498524b":"code","0208c38d":"code","3dd73c13":"code","60f9b081":"code","0eabd9a7":"code","8db2c0ed":"markdown","ff16d252":"markdown","9cf074e3":"markdown","bc17b59b":"markdown","03111474":"markdown","34c05d3c":"markdown","16aa0496":"markdown","f72d3a40":"markdown"},"source":{"6f063ec9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81797683":"df1 = pd.read_csv(\"\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\ndf1.head()","ac18acb5":"df1.shape","f2a80bb2":"df1.isnull().sum()","924b312f":"df1[\"output\"].value_counts()","8bc1edd5":"df1[\"sex\"].value_counts()","bf6fb164":"df1.info()","c4bada0e":"df1.nunique()","8908e3a0":"plt.figure(figsize = (10,6))\nsns.countplot(df1[\"output\"])","1a52bb9c":"sns.countplot(df1[\"sex\"])","f592d7c2":"sns.distplot(df1[\"age\"], kde = False)","bbf0e727":"plt.figure(figsize = (10,10))\nsns.countplot(df1[\"age\"])\nplt.title(\"Age Distribution\")","0bd4b6f9":"plt.figure(figsize = (12,12))\nsns.heatmap(df1.corr(), annot = True, cmap  =\"rocket\")","2b890295":"cat_var = [feature for feature in df1.columns if df1[feature].nunique()<10 and feature != \"output\"]\nfor var in cat_var:\n    sns.countplot(df1[var], hue = df1['output'])\n    plt.show()","ab8487db":"col_list = list(df1.columns)\nnum_var = [feature for feature in col_list if feature not in cat_var and feature!=\"output\"]\nfor num in num_var:\n    sns.boxplot(x = df1[\"output\"] , y=df1[num])\n    plt.show()","34b30ff3":"for num in num_var:\n    plt.style.use(\"ggplot\")\n    sns.distplot(df1[num], kde = False, color=\"green\")\n    plt.show()\n","7a4b86ea":"plt.figure(figsize=(10,10))\nsns.histplot(data=df1, x='age', hue='output')","cc1ce9e0":"\nplt.figure(figsize=(18,20))\nsns.pairplot(df1, hue = \"output\")","300a4b74":"df1.describe()\ndf1.head()","1a5a7dec":"df1.duplicated().sum()\ndf1.drop_duplicates(inplace=True)\ndf1","ccdf4981":"df1.shape","0ee30107":"X = df1.iloc [ : , : -1].values\nY = df1.iloc [ :, -1].values\nX","17275c7d":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=1)","c70a9d00":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx_train = ss.fit_transform(x_train)\nx_test = ss.transform(x_test)","a498524b":"from sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostClassifier\n","0208c38d":"acc_score = []\nmodel = [LogisticRegression(),SVC(),KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),GaussianNB()]\nfor m in model:\n    m.fit(x_train,y_train)\n    pred = m.predict(x_test)\n    score = accuracy_score(y_test,pred)\n    acc_score.append(score)","3dd73c13":"acc_score","60f9b081":"model_names = ['LogisticRegression', 'SVC','KNN', 'Decisiontree','RandomForest','GaussianNB']","0eabd9a7":"sns.barplot(x=acc_score, y=model_names, palette='mako')","8db2c0ed":"### Effect of Age on heart attack","ff16d252":"## Distribution of various numerical variables ","9cf074e3":"# Model Building and Standardization","bc17b59b":"## Visualising numerical data vs Output ","03111474":"# Exploratory Data Analysis","34c05d3c":"## Visualising categorical variables with output","16aa0496":"##  **LogisticRegression performed the best with an accuracy of 81.3% **","f72d3a40":"## Correlation between variables "}}