{"cell_type":{"8c0c64e7":"code","2beb77d9":"code","f216e0be":"code","1a911016":"code","20d5c742":"code","148e02f6":"code","0db8be27":"code","dd802429":"code","478e3996":"code","999f858a":"code","974999df":"code","eaed79e0":"code","675f626e":"code","ed6f92ed":"code","536f146d":"code","cb125224":"code","7c662faf":"code","ba5c597d":"code","c9012e50":"code","2f5c6664":"code","95423778":"code","44c065e0":"code","109f027a":"code","8698e3a2":"code","b75f0800":"code","4b962562":"code","bdf4da7a":"code","7512504e":"code","28547d4a":"code","f43a314c":"code","ff0a3b72":"code","e637987e":"code","0bbc5e51":"code","15e37eba":"code","4802e40c":"markdown","32f6e399":"markdown","7a3892dd":"markdown","e5229cf8":"markdown","3083d0c8":"markdown","7550ed42":"markdown","c6a1eb57":"markdown","d80b8e96":"markdown","e539f297":"markdown","fe5e0447":"markdown"},"source":{"8c0c64e7":"!pip install wordcloud\n!pip install nltk\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom math import log, sqrt\nimport pandas as pd\nimport numpy as np\nimport re\n%matplotlib inline","2beb77d9":"tweets = pd.read_csv('..\/input\/sentimental-analysis-for-tweets\/sentiment_tweets3.csv')\ntweets.head(20)","f216e0be":"tweets.drop(['Unnamed: 0'], axis = 1, inplace = True)","1a911016":"tweets['label'].value_counts()","20d5c742":"tweets.info()","148e02f6":"totalTweets = 8000 + 2314\ntrainIndex, testIndex = list(), list()\nfor i in range(tweets.shape[0]):\n    if np.random.uniform(0, 1) < 0.98:\n        trainIndex += [i]\n    else:\n        testIndex += [i]\ntrainData = tweets.iloc[trainIndex]\ntestData = tweets.iloc[testIndex]","0db8be27":"tweets.info()","dd802429":"trainData['label'].value_counts()","478e3996":"trainData.head()","999f858a":"testData['label'].value_counts()","974999df":"testData.head()","eaed79e0":"depressive_words = ' '.join(list(tweets[tweets['label'] == 1]['message']))\ndepressive_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(depressive_words)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(depressive_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()","675f626e":"positive_words = ' '.join(list(tweets[tweets['label'] == 0]['message']))\npositive_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(positive_words)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(positive_wc)\nplt.axis('off'), \nplt.tight_layout(pad = 0)\nplt.show()","ed6f92ed":"def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n    if lower_case:\n        message = message.lower()\n    words = word_tokenize(message)\n    words = [w for w in words if len(w) > 2]\n    if gram > 1:\n        w = []\n        for i in range(len(words) - gram + 1):\n            w += [' '.join(words[i:i + gram])]\n        return w\n    if stop_words:\n        sw = stopwords.words('english')\n        words = [word for word in words if word not in sw]\n    if stem:\n        stemmer = PorterStemmer()\n        words = [stemmer.stem(word) for word in words]   \n    return words","536f146d":"class TweetClassifier(object):\n    def __init__(self, trainData, method = 'tf-idf'):\n        self.tweets, self.labels = trainData['message'], trainData['label']\n        self.method = method\n\n    def train(self):\n        self.calc_TF_and_IDF()\n        if self.method == 'tf-idf':\n            self.calc_TF_IDF()\n        else:\n            self.calc_prob()\n\n    def calc_prob(self):\n        self.prob_depressive = dict()\n        self.prob_positive = dict()\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.tf_depressive[word] + 1) \/ (self.depressive_words + \\\n                                                                len(list(self.tf_depressive.keys())))\n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.tf_positive[word] + 1) \/ (self.positive_words + \\\n                                                                len(list(self.tf_positive.keys())))\n        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets \/ self.total_tweets, self.positive_tweets \/ self.total_tweets \n\n\n    def calc_TF_and_IDF(self):\n        noOfMessages = self.tweets.shape[0]\n        self.depressive_tweets, self.positive_tweets = self.labels.value_counts()[1], self.labels.value_counts()[0]\n        self.total_tweets = self.depressive_tweets + self.positive_tweets\n        self.depressive_words = 0\n        self.positive_words = 0\n        self.tf_depressive = dict()\n        self.tf_positive = dict()\n        self.idf_depressive = dict()\n        self.idf_positive = dict()\n        for i in range(noOfMessages):\n            message_processed = process_message(self.tweets.iloc[i])\n            count = list() #To keep track of whether the word has ocured in the message or not.\n                           #For IDF\n            for word in message_processed:\n                if self.labels.iloc[i]:\n                    self.tf_depressive[word] = self.tf_depressive.get(word, 0) + 1\n                    self.depressive_words += 1\n                else:\n                    self.tf_positive[word] = self.tf_positive.get(word, 0) + 1\n                    self.positive_words += 1\n                if word not in count:\n                    count += [word]\n            for word in count:\n                if self.labels.iloc[i]:\n                    self.idf_depressive[word] = self.idf_depressive.get(word, 0) + 1\n                else:\n                    self.idf_positive[word] = self.idf_positive.get(word, 0) + 1\n\n    def calc_TF_IDF(self):\n        self.prob_depressive = dict()\n        self.prob_positive = dict()\n        self.sum_tf_idf_depressive = 0\n        self.sum_tf_idf_positive = 0\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.tf_depressive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n                                                          \/ (self.idf_depressive[word] + self.idf_positive.get(word, 0)))\n            self.sum_tf_idf_depressive += self.prob_depressive[word]\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.prob_depressive[word] + 1) \/ (self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n            \n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.tf_positive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n                                                          \/ (self.idf_depressive.get(word, 0) + self.idf_positive[word]))\n            self.sum_tf_idf_positive += self.prob_positive[word]\n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.prob_positive[word] + 1) \/ (self.sum_tf_idf_positive + len(list(self.prob_positive.keys())))\n            \n    \n        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets \/ self.total_tweets, self.positive_tweets \/ self.total_tweets \n                    \n    def classify(self, processed_message):\n        pDepressive, pPositive = 0, 0\n        for word in processed_message:                \n            if word in self.prob_depressive:\n                pDepressive += log(self.prob_depressive[word])\n            else:\n                if self.method == 'tf-idf':\n                    pDepressive -= log(self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n                else:\n                    pDepressive -= log(self.depressive_words + len(list(self.prob_depressive.keys())))\n            if word in self.prob_positive:\n                pPositive += log(self.prob_positive[word])\n            else:\n                if self.method == 'tf-idf':\n                    pPositive -= log(self.sum_tf_idf_positive + len(list(self.prob_positive.keys()))) \n                else:\n                    pPositive -= log(self.positive_words + len(list(self.prob_positive.keys())))\n            pDepressive += log(self.prob_depressive_tweet)\n            pPositive += log(self.prob_positive_tweet)\n        return pDepressive >= pPositive\n    \n    def predict(self, testData):\n        result = dict()\n        for (i, message) in enumerate(testData):\n            processed_message = process_message(message)\n            result[i] = int(self.classify(processed_message))\n        return result","cb125224":"def metrics(labels, predictions):\n    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n    for i in range(len(labels)):\n        true_pos += int(labels.iloc[i] == 1 and predictions[i] == 1)\n        true_neg += int(labels.iloc[i] == 0 and predictions[i] == 0)\n        false_pos += int(labels.iloc[i] == 0 and predictions[i] == 1)\n        false_neg += int(labels.iloc[i] == 1 and predictions[i] == 0)\n    precision = true_pos \/ (true_pos + false_pos)\n    recall = true_pos \/ (true_pos + false_neg)\n    Fscore = 2 * precision * recall \/ (precision + recall)\n    accuracy = (true_pos + true_neg) \/ (true_pos + true_neg + false_pos + false_neg)\n\n    print(\"Precision: \", precision)\n    print(\"Recall: \", recall)\n    print(\"F-score: \", Fscore)\n    print(\"Accuracy: \", accuracy)","7c662faf":"sc_tf_idf = TweetClassifier(trainData, 'tf-idf')\nsc_tf_idf.train()\npreds_tf_idf = sc_tf_idf.predict(testData['message'])\nmetrics(testData['label'], preds_tf_idf)","ba5c597d":"sc_bow = TweetClassifier(trainData, 'bow')\nsc_bow.train()\npreds_bow = sc_bow.predict(testData['message'])\nmetrics(testData['label'], preds_bow)","c9012e50":"pm = process_message('Lately I have been feeling unsure of myself as a person & an artist')\nsc_tf_idf.classify(pm)","2f5c6664":"pm = process_message('Extreme sadness, lack of energy, hopelessness')\nsc_tf_idf.classify(pm)","95423778":"pm = process_message('Hi hello depression and anxiety are the worst')\nsc_tf_idf.classify(pm)","44c065e0":"pm = process_message('I am officially done with @kanyewest')\nsc_tf_idf.classify(pm)","109f027a":"pm = process_message('Feeling down...')\nsc_tf_idf.classify(pm)","8698e3a2":"pm = process_message('My depression will not let me work out')\nsc_tf_idf.classify(pm)","b75f0800":"pm = process_message('Loving how me and my lovely partner is talking about what we want.')\nsc_tf_idf.classify(pm)","4b962562":"pm = process_message('Very rewarding when a patient hugs you and tells you they feel great after changing the diet and daily habits')\nsc_tf_idf.classify(pm)","bdf4da7a":"pm = process_message('Happy Thursday everyone. Thought today was Wednesday so super happy tomorrow is Friday yayyyyy')\nsc_tf_idf.classify(pm)","7512504e":"pm = process_message('It\u2019s the little things that make me smile. Got our new car today and this arrived with it')\nsc_tf_idf.classify(pm)","28547d4a":"pm = process_message('Hi hello depression and anxiety are the worst')\nsc_bow.classify(pm)","f43a314c":"pm = process_message('My depression will not let me work out')\nsc_bow.classify(pm)","ff0a3b72":"pm = process_message('Feeling down...')\nsc_bow.classify(pm)","e637987e":"pm = process_message('Loving how me and my lovely partner is talking about what we want.')\nsc_bow.classify(pm)","0bbc5e51":"pm = process_message('Very rewarding when a patient hugs you and tells you they feel great after changing the diet and daily habits')\nsc_bow.classify(pm)","15e37eba":"pm = process_message('Happy Thursday everyone. Thought today was Wednesday so super happy tomorrow is Friday yayyyyy')\nsc_bow.classify(pm)","4802e40c":"# Positive Tweets","32f6e399":"# Installing and importing libraries\n","7a3892dd":"# Wordcloud Analysis","e5229cf8":"# Predictions with Bag-of-Words (BOW)\n# Depressive tweets","3083d0c8":"# Positive Tweets","7550ed42":"# Predictions with TF-IDF\n# Depressive Tweets","c6a1eb57":"# Splitting the Data in Training and Testing Sets\n\nAs you can see, I almost used all the data for training (98%) and rest for testing. Please note that this is not a very good practice always. You should always maintain somewhere around a 70-30 train-test split. ","d80b8e96":"# Detecting depression in Tweets using Bayes Theorem","e539f297":"**Pre-processing the data for the training: Tokenization, stemming, and removal of stop words**","fe5e0447":"# Loading the Data"}}