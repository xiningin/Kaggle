{"cell_type":{"7be42a97":"code","ebb2d54c":"code","331770f7":"code","34ec545c":"code","9242d325":"code","baba7fd8":"code","8b76d3e0":"code","67257e62":"code","4713361f":"markdown"},"source":{"7be42a97":"import os\n\nimport PIL\nfrom PIL import Image\nfrom PIL.ImageDraw import Draw\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom scipy.ndimage import affine_transform\nfrom keras import backend as K\n\nimport pandas as pd\nfrom tqdm import tqdm","ebb2d54c":"MODEL_BASE = '..\/input\/bounding-box-model'\nDATA = '..\/input\/humpback-whale-identification'\nTRAIN = os.path.join(DATA, 'train')\nTEST = os.path.join(DATA, 'test')","331770f7":"model = load_model(os.path.join(MODEL_BASE, 'cropping.model'))","34ec545c":"train_paths = [img for img in os.listdir(TRAIN)]\ntest_paths = [img for img in os.listdir(TEST)]","9242d325":"from PIL import Image as pil_image\n\n# Define useful constants\nimg_shape  = (128,128,1)\nanisotropy = 2.15\n\ndef center_transform(affine, input_shape):\n    hi, wi = float(input_shape[0]), float(input_shape[1])\n    ho, wo = float(img_shape[0]), float(img_shape[1])\n    top, left, bottom, right = 0, 0, hi, wi\n    if wi\/hi\/anisotropy < wo\/ho: # input image too narrow, extend width\n        w     = hi*wo\/ho*anisotropy\n        left  = (wi-w)\/2\n        right = left + w\n    else: # input image too wide, extend height\n        h      = wi*ho\/wo\/anisotropy\n        top    = (hi-h)\/2\n        bottom = top + h\n    center_matrix   = np.array([[1, 0, -ho\/2], [0, 1, -wo\/2], [0, 0, 1]])\n    scale_matrix    = np.array([[(bottom - top)\/ho, 0, 0], [0, (right - left)\/wo, 0], [0, 0, 1]])\n    decenter_matrix = np.array([[1, 0, hi\/2], [0, 1, wi\/2], [0, 0, 1]])\n    return np.dot(np.dot(decenter_matrix, scale_matrix), np.dot(affine, center_matrix))\n\n# Apply an affine transformation to an image represented as a numpy array.\ndef transform_img(x, affine):\n    matrix   = affine[:2,:2]\n    offset   = affine[:2,2]\n    x        = np.moveaxis(x, -1, 0)\n    channels = [affine_transform(channel, matrix, offset, output_shape=img_shape[:-1], order=1,\n                                 mode='constant', cval=np.average(channel)) for channel in x]\n    return np.moveaxis(np.stack(channels, axis=0), 0, -1)\n\ndef read_raw_image(p):\n    return pil_image.open(p)\n\ndef read_for_validation(x):\n    t  = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    t  = center_transform(t, x.shape)\n    x  = transform_img(x, t)\n    x -= np.mean(x, keepdims=True)\n    x \/= np.std(x, keepdims=True) + K.epsilon()\n    return x, t\n\ndef coord_transform(list, trans):\n    result = []\n    for x,y in list:\n        y,x,_ = trans.dot([y,x,1]).astype(np.int)\n        result.append((x,y))\n    return result\n\ndef read_array(p):\n    img = read_raw_image(p).convert('L')\n    return img_to_array(img)\n\ndef make_bbox(p):\n    raw = read_array(p)\n    width, height = raw.shape[1], raw.shape[0]\n    img,trans         = read_for_validation(raw)\n    a                 = np.expand_dims(img, axis=0)\n    x0, y0, x1, y1    = model.predict(a).squeeze()\n    (u0, v0),(u1, v1) = coord_transform([(x0,y0),(x1,y1)], trans)\n    bbox = [max(u0,0), max(v0,0), min(u1,width), min(v1,height)]\n    if bbox[0] >= bbox[2] or bbox[1] >= bbox[3]:\n        bbox = [0,0,width,height]\n    return bbox","baba7fd8":"bbox_df = pd.DataFrame(columns=['Image','x0','y0','x1','y1']).set_index('Image')","8b76d3e0":"for img in tqdm(train_paths):\n    bbox_df.loc[img] = make_bbox(os.path.join(TRAIN,img))\n    \nfor img in tqdm(test_paths):\n    bbox_df.loc[img] = make_bbox(os.path.join(TEST,img))","67257e62":"bbox_df.to_csv(\"bounding_boxes.csv\")","4713361f":"Reference\n\n- Awesome Kernel, thanks @martinpiotte : https:\/\/www.kaggle.com\/martinpiotte\/bounding-box-model\n- cropping.model: https:\/\/www.kaggle.com\/martinpiotte\/bounding-box-model\/output\n- Data: https:\/\/www.kaggle.com\/c\/humpback-whale-identification\/data"}}