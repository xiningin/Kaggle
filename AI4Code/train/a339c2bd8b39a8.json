{"cell_type":{"b922ce8f":"code","25baa2e2":"code","1e7b382c":"code","d0d0211b":"code","4e5e2048":"code","ead073be":"code","f3dc999f":"code","e4b8a5c4":"code","69f057f1":"code","163c2469":"code","a776f231":"code","6ad1fcb0":"code","430b9511":"code","bf53f639":"code","7d5c2d8f":"code","0b70adce":"code","7e4e83fe":"code","875dbce4":"code","3e290925":"code","6403a753":"code","e315ae3c":"code","26e128a8":"code","114b8cff":"code","ec1e7776":"code","e8daf54d":"code","ba9530ee":"code","82d66ae8":"code","6c64a548":"code","9c0eaae7":"code","c742c6a0":"code","cf2d0eb5":"code","8ac5062f":"code","fe6c62b3":"code","aed1a2be":"code","e7a0038e":"code","d6b68dea":"code","623448fe":"code","e263c36c":"code","b2dbae12":"code","c9ebc5b3":"code","02f1a4a6":"code","8f1fc370":"code","55fb1c05":"code","f3352a8c":"code","872d0420":"code","6e1d7dda":"code","32a5f1cb":"code","d0bc3f42":"code","7e18338b":"code","49693f9d":"code","04c36cf9":"code","1bb3abbd":"code","48106be4":"code","80d95b8c":"code","03fa4af9":"markdown","df87cd69":"markdown","0014e8a0":"markdown","b0391a17":"markdown","6d619a79":"markdown","40504d8c":"markdown","0e76e33a":"markdown","dbdf94d6":"markdown","5fd4a85e":"markdown","0a3077d5":"markdown","13193182":"markdown"},"source":{"b922ce8f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex3 import *\n\nprint(\"Setup completed\")","25baa2e2":"file_path = '..\/input\/gene-expression\/data_set_ALL_AML_train.csv'\nmissing_value_formats = [\"n.a.\",\"?\",\"NA\",\"n\/a\", \"na\", \"--\"]\n\ntrain_dataset = pd.read_csv(file_path, na_values = missing_value_formats)\nprint(train_dataset.head(10))","1e7b382c":"train_dataset.describe()","d0d0211b":"print(\"The dataset has\", train_dataset.shape[0], \"rows and\", train_dataset.shape[1], 'columns.')","4e5e2048":"print(\"The columns are:\")\nprint(train_dataset.columns)","ead073be":"correlation = train_dataset.corr()\nplt.figure(figsize=(50,50))\nsns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='viridis')\n\nplt.title('Correlation between different fearures')","f3dc999f":"train_dataset = train_dataset.drop('Gene Description', axis=1)\ntrain_dataset = train_dataset.drop('Gene Accession Number', axis=1)","e4b8a5c4":"cols = [col for col in train_dataset.columns if \"call\" not in col]\ntrain_dataset = train_dataset[cols]","69f057f1":"train_dataset.head()","163c2469":"file_path = '..\/input\/gene-expression\/actual.csv'\nmissing_value_formats = [\"n.a.\",\"?\",\"NA\",\"n\/a\", \"na\", \"--\"]\n\npatients_info = pd.read_csv(file_path, na_values = missing_value_formats)\nprint(patients_info.head(38))","a776f231":"patients_info[\"cancer\"] = patients_info[\"cancer\"].astype('category')\npatients_info[\"cancer_category\"] = patients_info[\"cancer\"].cat.codes\nprint(patients_info)","6ad1fcb0":"print(patients_info.columns)\ncancer_forms = patients_info.groupby(['cancer','cancer_category']).size().reset_index().rename(columns={0:'counter'})\ncancer_forms = cancer_forms[cancer_forms[\"counter\"] > 0]\n\nprint(cancer_forms)","430b9511":"train_dataset['cancer_type'] = patients_info[:38]['cancer_category']\n\ntrain_dataset.describe()","bf53f639":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ny = patients_info[:38]['cancer_category']\nscaled_data=scaler.fit_transform(train_dataset.drop('cancer_type', axis=1).T)","7d5c2d8f":"import numpy\nprint(scaled_data)\ncounter = 0\nfor element in scaled_data:\n    print(train_dataset.iloc[counter, [-1]].values)\n    element = numpy.append(element, train_dataset.iloc[counter, [-1]].values)\n    counter = counter + 1","0b70adce":"from sklearn.decomposition import PCA","7e4e83fe":"pca = PCA(n_components=30)","875dbce4":"X = pca.fit_transform(scaled_data)\ndf = pd.DataFrame(X)\nprint(df.shape)\nX_b = pd.DataFrame(df.iloc[:38, :])\nprint(X_b)\n","3e290925":"from sklearn.cluster import KMeans\nwcss=[]\n\n#we always assume the max number of cluster would be 10\n#you can judge the number of clusters by doing averaging\n###Static code to get max no of clusters\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","6403a753":"plt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()\n","e315ae3c":"kmeansmodel = KMeans(n_clusters= 2, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(X)","26e128a8":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n\n\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters')\n\nplt.legend()\nplt.show()","114b8cff":"from sklearn.metrics import silhouette_samples, silhouette_score\nsilhouette_avg = silhouette_score(X, y_kmeans)\nprint(\"For 2 clusters, the average silhouette_score is :\", silhouette_avg)","ec1e7776":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","e8daf54d":"print(X_b)\nX_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.7, random_state=0)\nprint(X_train)","ba9530ee":"train_random_forest = RandomForestClassifier(n_estimators = 2, random_state = 1)\ntrain_random_forest.fit(X_train, y_train)\npredictions_random_forest = train_random_forest.predict(X_test)\nprint(predictions_random_forest)\n\nprint(\"The accuracy for the decision tree classifier model is:\", accuracy_score(y_test, predictions_random_forest) *100, '%')","82d66ae8":"pca = PCA(n_components=15)","6c64a548":"X = pca.fit_transform(scaled_data)\nprint(X)","9c0eaae7":"wcss=[]\n\n#we always assume the max number of cluster would be 10\n#you can judge the number of clusters by doing averaging\n###Static code to get max no of clusters\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","c742c6a0":"plt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","cf2d0eb5":"kmeansmodel = KMeans(n_clusters= 6, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(X)","8ac5062f":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'magenta', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'brown', label = 'Cluster 5')\nplt.scatter(X[y_kmeans == 5, 0], X[y_kmeans == 5, 1], s = 100, c = 'purple', label = 'Cluster 6')\n\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters')\n\nplt.legend()\nplt.show()","fe6c62b3":"silhouette_avg = silhouette_score(X, y_kmeans)\nprint(\"For 6 clusters, the average silhouette_score is :\", silhouette_avg)","aed1a2be":"X = pca.fit_transform(scaled_data)\ndf = pd.DataFrame(X)\nprint(df.shape)\nX_b = pd.DataFrame(df.iloc[:38, :])\nprint(X_b)","e7a0038e":"X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.7, random_state=1)\nprint(X_train)","d6b68dea":"train_random_forest = RandomForestClassifier(n_estimators = 2, random_state = 1)\ntrain_random_forest.fit(X_train, y_train)\npredictions_random_forest = train_random_forest.predict(X_test)\nprint(predictions_random_forest)\n\nprint(\"The accuracy for the decision tree classifier model is:\", accuracy_score(y_test, predictions_random_forest) *100, '%')","623448fe":"pca = PCA(n_components=5)\nX = pca.fit_transform(scaled_data)\nprint(X)","e263c36c":"wcss=[]\n\n#we always assume the max number of cluster would be 10\n#you can judge the number of clusters by doing averaging\n###Static code to get max no of clusters\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","b2dbae12":"plt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","c9ebc5b3":"kmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(X)","02f1a4a6":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'magenta', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'cyan', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters')\nplt.legend()\nplt.show()","8f1fc370":"silhouette_avg = silhouette_score(X, y_kmeans)\nprint(\"For 5 clusters, the average silhouette_score is :\", silhouette_avg)","55fb1c05":"X = pca.fit_transform(scaled_data)\ndf = pd.DataFrame(X)\nprint(df.shape)\nX_b = pd.DataFrame(df.iloc[:38, :])\nprint(X_b)","f3352a8c":"X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.7, random_state=1)\nprint(X_train)\n\nprint(y)","872d0420":"train_random_forest = RandomForestClassifier(n_estimators = 2, random_state = 1)\ntrain_random_forest.fit(X_train, y_train)\npredictions_random_forest = train_random_forest.predict(X_test)\nprint(predictions_random_forest)\n\nprint(\"The accuracy for the decision tree classifier model is:\", accuracy_score(y_test, predictions_random_forest) *100, '%')","6e1d7dda":"pca = PCA(n_components=2)\nX = pca.fit_transform(scaled_data)\nprint(X)","32a5f1cb":"wcss=[]\n\n#we always assume the max number of cluster would be 10\n#you can judge the number of clusters by doing averaging\n###Static code to get max no of clusters\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","d0bc3f42":"plt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","7e18338b":"kmeansmodel = KMeans(n_clusters= 3, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(X)","49693f9d":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters')\n\nplt.legend()\nplt.show()","04c36cf9":"silhouette_avg = silhouette_score(X, y_kmeans)\nprint(\"For 2 clusters, the average silhouette_score is :\", silhouette_avg)","1bb3abbd":"X = pca.fit_transform(scaled_data)\ndf = pd.DataFrame(X)\nprint(df.shape)\nprint(df.head())\nX_b = pd.DataFrame(df.iloc[:38, :])\nprint(X_b)","48106be4":"X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.7, random_state=1)\nprint(X_train)","80d95b8c":"train_random_forest = RandomForestClassifier(n_estimators = 2, random_state = 1)\ntrain_random_forest.fit(X_train, y_train)\npredictions_random_forest = train_random_forest.predict(X_test)\nprint(predictions_random_forest)\n\nprint(\"The accuracy for the decision tree classifier model is:\", accuracy_score(y_test, predictions_random_forest) *100, '%')","03fa4af9":"For 15 components the silhouette score is 84% which is bigger than the score with 30 components","df87cd69":"# 3. 5 components","0014e8a0":"Random Forest","b0391a17":"# 4. 2 components","6d619a79":"# Scale the data\nScale the data in order to minimize the difference between the values","40504d8c":"Random forest","0e76e33a":"# Gene Classification\nThis dataset comes from a proof-of-concept study published in 1999 by Golub et al. It showed how new cases of cancer could be classified by gene expression monitoring (via DNA microarray) and thereby provided a general approach for identifying new cancer classes and assigning tumors to known classes. These data were used to classify patients with acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL).","dbdf94d6":"# PCA","5fd4a85e":"# 2. 15 components","0a3077d5":"# Read the data","13193182":"# 1. 30 components"}}