{"cell_type":{"e14188c1":"code","42a80236":"code","ac2806bd":"code","cfb9d086":"code","3dd6043b":"code","bb949364":"code","acc8c964":"code","3e81136c":"code","8364e3f0":"code","a4e7a132":"code","ce014206":"code","21c08b20":"markdown","ad6a861b":"markdown","28be37a0":"markdown"},"source":{"e14188c1":"import numpy as np \nimport pandas as pd \nimport os\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization,  UpSampling2D\nfrom tensorflow.keras.layers import ZeroPadding2D, AveragePooling2D, GlobalMaxPooling2D,MaxPooling2D\nfrom tensorflow.keras.layers import Conv2D, Input, Flatten, Add, Dropout, Activation\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, accuracy_score\n\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n# to ignore displaying warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","42a80236":"from glob import glob\nfrom tqdm import tqdm\n\nclass Utils:\n    \n    def __init__(self, path):\n        self.__glob(path)\n    \n    def __glob(self, path):\n        \"\"\"loading data using glob\"\"\"\n        self.path_lsts = [p for p in glob(path, recursive=True) if p.endswith('.png')]\n        print(\"Size of images:\", len(self.path_lsts))\n\n    def display_images(self, figure_row=4, figure_cols=4):\n        \"\"\"Display images \"\"\"\n        f, ax = plt.subplots(nrows= figure_row, ncols=figure_cols, \n                             figsize=(figure_row*figure_cols, figure_row*figure_cols)) \n        number_of_images = figure_row * figure_cols\n        images = []\n        for i in range(figure_row):\n            for j in range(figure_cols):\n                while True:\n                    rand = np.random.randint(0, len(self.path_lsts)-1)\n                    if rand not in images:\n                        images.append(rand)\n                        break\n                image=cv2.imread(self.path_lsts[rand])\n                ax[i, j].imshow(image, resample=True, cmap='gray')\n                ax[i, j].set_title(\"Class-\"+ self.path_lsts[rand][-5], fontsize=16)\n        plt.tight_layout()\n        plt.show()\n        print(\"Original Image Shape:\",image.shape)\n        \n    def load_images(self, dsize = (64, 64), n_images = -1):\n        \"\"\"loading images\"\"\"\n        images_path = self.path_lsts[:n_images]\n        self.X_image, self.y_image = [], []\n        \n        for path in tqdm(images_path):\n            image = load_img(path, target_size=dsize)\n            self.X_image.append(image)\n            #self.X_image.append(img_to_array(image)\/255.0)\n            self.y_image.append(int(path[-5]))\n            \n    def summary(self):\n        \"\"\"Display summary of data\"\"\"\n        print('Total number of images: {}'.format(len(self.X_image)))\n        print('Number of IDC(-) Images: {}'.format(len(self.X_image)-np.sum(self.y_image)))\n        print('Number of IDC(+) Images: {}'.format(np.sum(self.y_image)))\n        #print('Image shape (Width, Height, Channels): {}'.format(self.X_image[0].shape))\n    \n    def get_images(self):\n        \"\"\"Return images\"\"\"\n        return np.array(self.X_image), np.array(self.y_image)","ac2806bd":"#Helper Methods\nimport pickle\ndef save_pkl(path, data):\n    '''save pickle data into specified path '''\n    with open(path, \"wb\") as f:\n        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n\ndef load_pkl(path):\n    '''load pickle data from specified path'''\n    with open(path, \"rb\") as f:\n        pkl = pickle.load(f)\n    return pkl","cfb9d086":"#path to input dataset pattern for glob\npath = '\/kaggle\/input\/breast-histopathology-images\/*\/*\/*'\n\n#initialize utils\nutils = Utils(path)\n\n#display a few images randomly\nutils.display_images(figure_row=3)","3dd6043b":"#loading n_images with shape of (64, 64) and normalize it\ndsize = (32, 32)\n\nLOAD = False\n\nif LOAD:\n    path = '\/kaggle\/working\/breast-histopathology-image.sav'\n    utils.load_images(dsize=dsize, n_images=-1)\n    X, y = utils.X_image, utils.y_image\n    loaded_dataset = {\"X\":X, \"Y\":y}\n    save_pkl(path, loaded_dataset)\n    utils.summary()\nelse:\n    path = '\/kaggle\/input\/breasthistopathologyimagepkl\/breast-histopathology-image.sav'\n    loaded_dataset = load_pkl(path)\n    #utils.X_image, utils.y_image = loaded_dataset['X'], loaded_dataset['Y']\n    #X, y = utils.X_image, utils.y_image\n    X, y = loaded_dataset['X'], loaded_dataset['Y']\n\n#summary of the data\n#utils.summary()","bb949364":"#del utils\n#del loaded_dataset\ndef preprocess(images, y, normalize = True, size=-1):\n    for i in tqdm(range(len(images[:size]))):\n        if normalize:\n            img = img_to_array(images[i])\/255.0\n        else:\n            img = img_to_array(images[i])\n        images[i] = img\n        \n    return np.array(images), np.array(y)\n\nX, y = preprocess(X, y, size=-1)\nX_train, y_train = X[:150000], y[:150000]\nX_test, y_test = X[150001:200000], y[150001:200000]","acc8c964":"def identity_block(X, f, filters, stage, block):    \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    F1, F2, F3 = filters\n    \n    X_shortcut = X\n    \n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1, 1), \n               padding = 'valid', name = conv_name_base + '2a', \n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), \n               padding = \"same\", name = conv_name_base + \"2b\", \n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), \n               padding = \"valid\", name = conv_name_base + \"2c\", \n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):    \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n    X_shortcut = X\n\n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', \n               padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', \n               padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(F3, (1,1), strides = (1,1), name = conv_name_base + '2c', \n               padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    X_shortcut = Conv2D(F3, (1,1), strides = (s, s), padding = \"valid\", name = conv_name_base + \"1\", \n                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","3e81136c":"#K.set_image_dim_ordering('th')\n\ndef ResNet50(input_shape = (32, 32, 3), classes = 2):    \n    X_input = Input(input_shape)\n    \n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    #X = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3 \n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4 \n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    \n    X = AveragePooling2D()(X)\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n    \n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    \n    return model","8364e3f0":"model = ResNet50()\n\nmodel.summary()","a4e7a132":"history = model.fit(np.stack(X_train),  y_train, validation_split=0.1, \n              epochs=20, batch_size=32, verbose=1)\n","ce014206":"y_test_pred = model.predict(np.stack(X_test))\n\ny_test_pred = np.argmax(y_test_pred, axis=1)\n\nacc, f1, precision, recall = accuracy_score(y_test, y_test_pred),\\\n                             f1_score(y_test, y_test_pred), \\\n                             precision_score(y_test, y_test_pred), \\\n                             recall_score(y_test, y_test_pred)\n\nprint(\"Accuracy:\", acc)\nprint(\"F1-Score:\", f1)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\n","21c08b20":"# 3. Preprocessing","ad6a861b":"# 4. ResNet50","28be37a0":"# 1. Loading"}}