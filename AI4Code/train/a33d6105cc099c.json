{"cell_type":{"1a65f873":"code","8886ee77":"code","3baf08a5":"code","53b4cc60":"code","698f7207":"code","a61ba0db":"code","a822d636":"code","31854726":"code","3feb43c9":"code","7f788740":"code","2b2b2c53":"code","db5a157d":"code","db0f3d43":"code","18cc063b":"code","b688e4bd":"code","a60e5707":"code","f5d4025a":"code","23826c0c":"code","693c86cf":"code","6b25dd19":"code","6c831991":"code","b6137c42":"code","ff9e72d3":"code","fb3eecd4":"code","defcb956":"code","4f047e07":"code","b093219d":"code","886b73f5":"code","e2f769c4":"code","2196e12e":"code","3593398f":"code","f3bbdac9":"code","d9df1a1f":"code","ec2b5f6d":"code","ce790ada":"code","56956e1a":"markdown"},"source":{"1a65f873":"%run ..\/input\/python-recipes\/cmap_header.py\n%cmap_header Code Modules & Settings","8886ee77":"import os,h5py,pathlib,pylab as pl,seaborn as sb\nimport numpy as np,pandas as pd,tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing as tkp\nimport tensorflow.keras.layers as tkl,tensorflow.keras.models as tkm\nfrom IPython.display import display,Audio\nrs=42; tf.random.set_seed(rs); np.random.seed(rs)","3baf08a5":"%cmap_header Data Loading","53b4cc60":"datadir=pathlib.Path('data\/mini_speech_commands')\nif not datadir.exists():\n    tf.keras.utils.get_file(\n        'mini_speech_commands.zip',\n        origin='http:\/\/storage.googleapis.com\/download.tensorflow.org\/'+\\\n               'data\/mini_speech_commands.zip',\n        extract=True,cache_dir='.',cache_subdir='data')","698f7207":"names=np.array(tf.io.gfile.listdir(str(datadir)))\nnames=names[names!='README.md']\nprint('command names: ',names)","a61ba0db":"files=tf.io.gfile.glob(str(datadir)+'\/*\/*')\nfiles=tf.random.shuffle(files)\nnum_samples=len(files)\nprint('number of total examples:',num_samples)\nprint('number of examples per label:',\n      len(tf.io.gfile.listdir(str(datadir\/names[0]))))\nprint('examples of the file tensor:',files[:10])","a822d636":"train_files=files[:int(.8*num_samples)]\nvalid_files=files[int(.8*num_samples):int(.9*num_samples)]\ntest_files=files[-int(.1*num_samples):]","31854726":"%cmap_header File Processing","3feb43c9":"def get_audio(file_path):\n    audio,_=tf.audio.decode_wav(file_path)\n    return tf.squeeze(audio,axis=-1)\ndef get_label(file_path):\n    file_path=tf.strings.split(file_path,os.path.sep)\n    return file_path[-2]\ndef get_audio_and_label(file_path):\n    audio_binary=tf.io.read_file(file_path)\n    audio=get_audio(audio_binary)\n    label=get_label(file_path)\n    return audio,label\nget_label(files[0]).numpy()","7f788740":"AUTOTUNE=tf.data.AUTOTUNE\ntrain_files_ds=tf.data.Dataset.from_tensor_slices(train_files)\ntrain_audio_ds=train_files_ds.map(\n    get_audio_and_label,num_parallel_calls=AUTOTUNE)","2b2b2c53":"rows,cols=2,5\nfig,axes=pl.subplots(rows,cols,figsize=(12,6))\nfor i,(audio,label) in enumerate(train_audio_ds.take(rows*cols)):\n    ax=axes[i\/\/cols][i%cols]\n    ax.plot(audio.numpy(),color='slategray',alpha=.7)\n    ax.set_yticks(np.arange(-1.2,1.2,.2))\n    label=label.numpy().decode('utf-8')\n    ax.set_title('$\\mathbb{'+label+'}$',\n                 color='slategray',fontsize='xx-large')\npl.show()","db5a157d":"def get_spectrogram(audio,num=16000,frame_length=255,frame_step=128):\n    zeros=tf.zeros([num]-tf.shape(audio),dtype=tf.float32)\n    audio=tf.cast(audio,tf.float32)\n    equal_length=tf.concat([audio,zeros],0)\n    # a Fourier transform with time information\n    spectrogram=tf.signal.stft(\n        equal_length,frame_length=frame_length,frame_step=frame_step)\n    # the magnitude\n    spectrogram=tf.abs(spectrogram)\n    return spectrogram","db0f3d43":"for audio,label in train_audio_ds.take(1):\n    label=label.numpy().decode('utf-8')\n    spectrogram=get_spectrogram(audio)\nprint('label: ',label)\nprint('shape of audio tensors: ',audio.shape)\nprint('spectrogram shape: ',spectrogram.shape)\nprint('audio playback: ')\ndisplay(Audio(audio,rate=16000))","18cc063b":"def plot_spectrogram(spectrogram,ax):\n    log_spec=np.log(spectrogram.T)\n    height=log_spec.shape[0]\n    width=log_spec.shape[1]\n    x=np.linspace(0,np.size(spectrogram),num=width,dtype=int)\n    y=range(height)\n    ax.pcolormesh(x,y,log_spec,cmap='bone',shading='auto')\nfig,axes=pl.subplots(2,figsize=(12,6))\ntimescale=np.arange(audio.shape[0])\naxes[0].plot(timescale,audio.numpy(),alpha=.7,color='slategray')\naxes[0].set_title('$\\mathbb{'+'waveform'+'}$',\n                  color='slategray',fontsize='xx-large')\naxes[0].set_xlim([0,16000])\nplot_spectrogram(spectrogram.numpy(),axes[1])\naxes[1].set_title('$\\mathbb{'+'spectrogram'+'}$',\n                  color='slategray',fontsize='xx-large')\npl.show()","b688e4bd":"%cmap_header Data Building","a60e5707":"def get_spectrogram_and_label_id(audio,label):\n    spectrogram=get_spectrogram(audio)\n    spectrogram=tf.expand_dims(spectrogram,-1)\n    label_id=tf.argmax(label==names)\n    return spectrogram,label_id","f5d4025a":"def preprocess_ds(files):\n    files_ds=tf.data.Dataset.from_tensor_slices(files)\n    output_ds=files_ds.map(\n        get_audio_and_label,num_parallel_calls=AUTOTUNE)\n    output_ds=output_ds.map(\n        get_spectrogram_and_label_id,num_parallel_calls=AUTOTUNE)\n    return output_ds","23826c0c":"train_ds=preprocess_ds(train_files)\nvalid_ds=preprocess_ds(valid_files)\ntest_ds=preprocess_ds(test_files)","693c86cf":"rows,cols=3,5\nfig,axes=pl.subplots(rows,cols,figsize=(12,9))\nfor i,(spectrogram,label_id) in enumerate(train_ds.take(rows*cols)):\n    ax=axes[i\/\/cols][i%cols]\n    plot_spectrogram(np.squeeze(spectrogram.numpy()+.1**10),ax)\n    ax.set_title('$\\mathbb{'+names[label_id.numpy()]+'}$',\n                 color='slategray',fontsize='xx-large')\n    ax.axis('off')\npl.show()","6b25dd19":"%cmap_header Data H5Py Storing","6c831991":"def get_arrays(file_list):\n    spectr_arr,label_arr=[],[]\n    for i in range(len(file_list)):\n        audio,label=get_audio_and_label(file_list[int(i)])\n        spectrogram,label_id=\\\n        get_spectrogram_and_label_id(audio,label)\n        spectr_arr.append(spectrogram.numpy())\n        label_arr.append(label_id.numpy())\n    return np.array(spectr_arr),np.array(label_arr,dtype='int32')\nspectr_train,label_train=get_arrays(train_files)\nspectr_valid,label_valid=get_arrays(valid_files)\nspectr_test,label_test=get_arrays(test_files)","b6137c42":"print(spectr_train.shape,spectr_train.dtype,\n      label_train.shape,label_train.dtype,\n      spectr_valid.shape,spectr_valid.dtype,\n      label_valid.shape,label_valid.dtype,\n      spectr_test.shape,spectr_test.dtype,\n      label_test.shape,label_test.dtype)","ff9e72d3":"h5f='SpectrCommands124129.h5'\n#with h5py.File(h5f,'w') as f:\n#    f.create_dataset('spectr_train',data=spectr_train,\n#                     compression='gzip')\n#    f.create_dataset('label_train',data=label_train,\n#                     compression='gzip')\n#    f.create_dataset('spectr_valid',data=spectr_valid,\n#                     compression='gzip')\n#    f.create_dataset('label_valid',data=label_valid,\n#                     compression='gzip')\n#    f.create_dataset('spectr_test',data=spectr_test,\n#                     compression='gzip')\n#    f.create_dataset('label_test',data=label_test,\n#                     compression='gzip')\n#    f.close()\n#print('file size: %s'%list(os.stat(h5f))[6])","fb3eecd4":"h5path='..\/input\/spectrograms-of-audio-commands\/'\nwith h5py.File(h5path+h5f,'r') as f:\n    keys=list(f.keys())\n    print('file keys: '+', '.join(keys))\n    label_test=np.array(f[keys[0]])\n    label_train=np.array(f[keys[1]])\n    label_valid=np.array(f[keys[2]])\n    spectr_test=np.array(f[keys[3]])\n    spectr_train=np.array(f[keys[4]])\n    spectr_valid=np.array(f[keys[5]])\n    f.close()","defcb956":"rows,cols=3,5\nfig,axes=pl.subplots(rows,cols,figsize=(12,9))\nfor i in range(rows*cols):\n    ax=axes[i\/\/cols][i%cols]\n    plot_spectrogram(np.squeeze(spectr_train[i]+.1**10),ax)\n    ax.set_title('$\\mathbb{'+names[label_train[i]]+'}$',\n                 color='slategray',fontsize='xx-large')\n    ax.axis('off')\npl.show()","4f047e07":"%cmap_header Model Building & Training","b093219d":"for spectrogram,_ in train_ds.take(1):\n    input_shape=spectrogram.shape\nnum_labels=len(names)\nnorm_layer=tkp.Normalization()\nnorm_layer.adapt(train_ds.map(lambda x,_:x))\nmodel=tkm.Sequential([\n    tkl.InputLayer(input_shape=input_shape),\n    tkp.Resizing(32,32), \n    norm_layer,\n    tkl.Conv2D(32,3,activation='relu'),\n    tkl.Conv2D(96,3,activation='relu'),\n    tkl.MaxPooling2D(),\n    tkl.Dropout(.25),\n    tkl.Flatten(),\n    tkl.Dense(256,activation='relu'),\n    tkl.Dropout(.5),\n    tkl.Dense(num_labels),\n])\nmodel.summary()","886b73f5":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'],\n)","e2f769c4":"batch_size=64\ntrain_ds=train_ds.batch(batch_size)\nvalid_ds=valid_ds.batch(batch_size)\ntrain_ds=train_ds.cache().prefetch(AUTOTUNE)\nvalid_ds=valid_ds.cache().prefetch(AUTOTUNE)","2196e12e":"epochs=10\nhistory=model.fit(\n    train_ds,validation_data=valid_ds,epochs=epochs,\n    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1,patience=3))","3593398f":"def keras_history_plot(fit_history,fig_size,color):\n    keys=list(fit_history.history.keys())\n    list_history=[fit_history.history[keys[i]] for i in range(len(keys))]\n    dfkeys=pd.DataFrame(list_history).T\n    dfkeys.columns=keys\n    fig=pl.figure(figsize=(fig_size,fig_size\/1.5))\n    ax1=fig.add_subplot(2,1,1)\n    dfkeys.iloc[:,[int(0),int(2)]].plot(\n        ax=ax1,color=['slategray',color],grid=True)\n    ax2=fig.add_subplot(2,1,2)\n    dfkeys.iloc[:,[int(1),int(3)]].plot(\n        ax=ax2,color=['slategray',color],grid=True)\n    pl.tight_layout(); pl.show()\nkeras_history_plot(history,12,'purple')","f3bbdac9":"%cmap_header Model Evaluating","d9df1a1f":"test_audio,test_labels=[],[]\nfor audio,label in test_ds:\n    test_audio.append(audio.numpy())\n    test_labels.append(label.numpy())\ntest_audio=np.array(test_audio)\ntest_labels=np.array(test_labels)","ec2b5f6d":"test_preds=np.argmax(model.predict(test_audio),axis=1)\ntest_acc=sum(test_preds==test_labels)\/len(test_labels)\nprint(f'test accuracy:{test_acc:.0%}')","ce790ada":"confusion_mtx=tf.math.confusion_matrix(test_labels,test_preds) \npl.figure(figsize=(12,9))\nsb.heatmap(confusion_mtx,xticklabels=names,yticklabels=names, \n            annot=True,fmt='g')\npl.xlabel('Predictions'); pl.ylabel('Labels')\npl.show()","56956e1a":"## Reading Tutorials\n##### [Simple audio recognition: Recognizing keywords](https:\/\/www.tensorflow.org\/tutorials\/audio\/simple_audio)"}}