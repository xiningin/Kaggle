{"cell_type":{"3e0de4d6":"code","5ef0a0a9":"code","bc0f8eb3":"code","f5d4ebf9":"code","374c986f":"code","46b1dc1f":"code","06f5e659":"code","60efba29":"code","476da2df":"code","b117f386":"code","03a4a5b4":"code","f3d5b402":"code","0a076356":"code","13a878cd":"code","15c3cd72":"code","181e0ace":"code","93284387":"code","c183f857":"code","8c7abc7c":"code","171527d0":"code","e959099e":"code","9681eff3":"code","69d984d2":"code","72e627d2":"code","1ef47888":"code","b5e725cb":"code","447d73c1":"code","eba276a8":"code","3c3014e3":"code","63cd641f":"code","da5f89cc":"code","3d55ee36":"code","b7e65f01":"code","9a419e34":"code","eadb41c8":"code","26bdc6d0":"code","73bebf74":"code","633dc988":"code","11450a7a":"code","0ec3a509":"code","a9364c4e":"code","016b000f":"code","a91971f1":"code","46a0eff0":"code","c6aa2743":"code","cf668ae6":"code","914bbb78":"code","e6bead2a":"code","5529f2dd":"code","ac88dedf":"code","24eb62a4":"code","bef5bb1e":"code","10a1da29":"code","434f4837":"code","e2003206":"code","163e7c07":"markdown","c95f5d12":"markdown","a9133080":"markdown","c491d64c":"markdown","f47b94de":"markdown","bb6908ef":"markdown","7768be56":"markdown","2732c251":"markdown","27a0d22f":"markdown","c512adaa":"markdown","d4ce6852":"markdown","3c19a07d":"markdown","79e3126d":"markdown","81d7224e":"markdown","ec54e05b":"markdown","aed65c3a":"markdown","f271eedb":"markdown","4ebd7956":"markdown","bbdb551c":"markdown","04ef61ca":"markdown","fc0e828d":"markdown","19155950":"markdown","961fbd1f":"markdown","844a50a7":"markdown","a0e1d5d8":"markdown","8b97fdb0":"markdown","1febc7c3":"markdown","d91597c4":"markdown","61833bd3":"markdown","14ee15cd":"markdown"},"source":{"3e0de4d6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn import metrics","5ef0a0a9":"data = pd.read_csv('..\/input\/Bank_Personal_Loan_Modelling.csv')\ndata.head()","bc0f8eb3":"data.shape","f5d4ebf9":"data.info()","374c986f":"data[data['Experience'] < 0]['Experience'].count()","46b1dc1f":"#Since ZIP Code has 1 variable with 4 digits hence we converted to 5 digits by using most frequent value - mode of that column\ndata= data.replace('9307', np.nan)\ndata = data.apply(lambda x: x.fillna(x.mode(), axis = 0))\n#This step may not be necessary as we would be dropping this column later","06f5e659":"#Converted all of these columns into their actual figures\ndata[['Income', 'CCAvg', 'Mortgage']] = data[['Income', 'CCAvg', 'Mortgage']] * 1000","60efba29":"data.head()","476da2df":"data.groupby('Personal Loan').count()","b117f386":"data.describe().transpose()","03a4a5b4":"#Dropping ID column as it is not required\ndata = data.drop(['ID'], axis = 1)\ndata.head()","f3d5b402":"sns.pairplot(data)","0a076356":"plt.figure(figsize = (15,15))\nsns.heatmap(data.corr(), annot = True, cmap = 'plasma' )","13a878cd":"#Lets study the relation between Personal Loan, Income,CCAvg and CD Account as these share high correlation\nsns.scatterplot(y = 'Income', x = 'Age', data = data, hue = 'Personal Loan')","15c3cd72":"sns.scatterplot(x = 'Income', y = 'CCAvg', data = data, hue = 'Personal Loan')","181e0ace":"sns.scatterplot(x = 'Income', y = 'Experience', data = data, hue = 'Personal Loan')","93284387":"sns.scatterplot(x = 'Income', y = 'Securities Account', data = data, hue = 'Personal Loan')","c183f857":"sns.scatterplot(x = 'Income', y = 'CD Account', data = data, hue = 'Personal Loan')","8c7abc7c":"sns.scatterplot(x = 'CCAvg', y = 'CD Account', data = data, hue = 'Personal Loan')","171527d0":"sns.scatterplot(y = 'Education', x = 'Income', data = data, hue = 'Personal Loan')","e959099e":"sns.scatterplot(y = 'Education', x = 'CCAvg', data = data, hue = 'Personal Loan')","9681eff3":"sns.scatterplot(y = 'Mortgage', x = 'Income', data = data, hue = 'Personal Loan')","69d984d2":"sns.scatterplot(y = 'Family', x = 'Income', data = data, hue = 'Personal Loan')","72e627d2":"sns.scatterplot(x = 'Age', y = 'Income', data = data, hue = 'Personal Loan')","1ef47888":"#Find % of people who have availed for Loan\nnot_availed_Loan = len(data[data['Personal Loan'] == 0])\navailed_Loan = len(data[data['Personal Loan'] == 1])\n\nprint(\"% of people who did not avail Loan {:.2f}%\". format(not_availed_Loan\/ (data['Personal Loan'].count()) * 100))\n\nprint(\"% of people availed Loan {:.2f}%\". format(availed_Loan\/ (data['Personal Loan'].count()) * 100))\n                       ","b5e725cb":"data.head()","447d73c1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# To scale the dimensions we need scale function which is part of scikit preprocessing libraries\nfrom sklearn import preprocessing\nfrom scipy.stats import zscore\n\n\nX = data.drop(['Personal Loan','Age','Experience','ZIP Code','Online','CreditCard'], axis = 1)\ny = data['Personal Loan']","eba276a8":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\n\nX_train_scaled = preprocessing.scale(X_train)\nX_test_scaled = preprocessing.scale(X_test)\n\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train_scaled, y_train)\ny_pred = logreg.predict(X_test_scaled)","3c3014e3":"print('Train score: {}'.format(logreg.score(X_train_scaled, y_train) * 100))\nprint('Test score: {}'.format(logreg.score(X_test_scaled, y_test) * 100))","63cd641f":"print(metrics.confusion_matrix(y_test, y_pred))","da5f89cc":"accuracies = {}\nacc_logreg = logreg.score(X_test_scaled, y_test) * 100\naccuracies['Logistic Regression'] = acc_logreg\nprint(\"Logistic Regression Accuracy: {}\".format(acc_logreg))","3d55ee36":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train_scaled, y_train)","b7e65f01":"expected  = y_test\npredicted = nb.predict(X_test_scaled)\nprint(metrics.classification_report(expected, predicted))\nprint('Total accuracy:', np.round(metrics.accuracy_score(expected, predicted),2))","9a419e34":"print('Train score: {}'.format(nb.score(X_train_scaled, y_train) * 100))\nprint('Test score: {}'.format(nb.score(X_test_scaled, y_test) * 100))","eadb41c8":"print(metrics.confusion_matrix(expected, predicted))","26bdc6d0":"acc_nb = nb.score(X_test_scaled, y_test) * 100\naccuracies['Naive Bayes'] = acc_nb\nprint(\"Naive Bayes Accuracy: {}\".format(acc_nb))","73bebf74":"from sklearn.neighbors import KNeighborsClassifier\nfrom scipy.stats import zscore\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate\n\n\n# creating odd list of K for KNN\nmyList = list(range(1,10))\n\n# subsetting just the odd ones\nneighbors = list(filter(lambda x: x % 2 != 0, myList))\n# empty list that will hold accuracy scores\nac_scores = []\n\n# perform accuracy metrics for values from 1,3,5....19\nfor k in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    # predict the response\n    y_pred = knn.predict(X_test)\n    # evaluate accuracy\n    scores = accuracy_score(y_test, y_pred)\n    ac_scores.append(scores)\n\n\n# changing to misclassification error\nMSE = [1 - x for x in ac_scores]\n\n# determining best k\noptimal_k = neighbors[MSE.index(min(MSE))]\nprint(\"The optimal number of neighbors is %d\" % optimal_k)\n\n\nplt.plot(neighbors, MSE)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()","633dc988":"#the above graph sometimes shows 7, and sometimes 1 however as 1 is the right answer hence used it below.\n#If someone knows why this happens please share your inputs...\nknn = KNeighborsClassifier(n_neighbors = 1, weights = 'distance')","11450a7a":"X_z = X.apply(zscore)\nX_z.describe()","0ec3a509":"X = np.array(X_z)\ny = np.array(y)","a9364c4e":"print(X.shape)\nprint(y.shape)","016b000f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nknn.score(X_test, y_test)","a91971f1":"print('Train score: {}'.format(knn.score(X_train, y_train) * 100))\nprint('Test score: {}'.format(knn.score(X_test, y_test) * 100))","46a0eff0":"cm_knn = print(metrics.confusion_matrix(y_test, y_pred))\ncm_knn","c6aa2743":"acc_knn = knn.score(X_test, y_test) * 100\naccuracies['KNN'] = acc_knn","cf668ae6":"from sklearn import svm\nsvm = svm.SVC(gamma = 0.025, C = 3)\nsvm.fit(X_train_scaled, y_train)","914bbb78":"svm.score(X_test_scaled, y_test)","e6bead2a":"y_pred = svm.predict(X_test_scaled)\n\nprint('Train score: {}'.format(svm.score(X_train_scaled, y_train) * 100))\nprint('Test score: {}'.format(svm.score(X_test_scaled, y_test) * 100))","5529f2dd":"acc_svm = svm.score(X_test_scaled, y_test) * 100\naccuracies['SVM'] = acc_svm","ac88dedf":"print(metrics.confusion_matrix(y_test, y_pred))","24eb62a4":"sns.set_style('whitegrid')\nplt.figure(figsize = (8,5))\nplt.yticks(np.arange(0,100,10))\nsns.barplot(x = list(accuracies.keys()), y = list(accuracies.values()))","bef5bb1e":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Naive Bayes','K-Nearest Neighbors', 'Support Vector Machines'],\n    \n    'Score': [acc_logreg, acc_nb, acc_knn, acc_svm]\n    })\n\nmodels.sort_values(by='Score', ascending=True)","10a1da29":"y_cm_lr = logreg.predict(X_test_scaled)\ny_cm_nb = nb.predict(X_test_scaled)\ny_cm_knn = knn.predict(X_test)\ny_cm_svm = svm.predict(X_test_scaled)","434f4837":"from sklearn.metrics import confusion_matrix\ncm_lr = confusion_matrix(y_test, y_cm_lr)\ncm_knn = confusion_matrix(y_test, y_cm_knn)\ncm_svm = confusion_matrix(y_test, y_cm_svm)\ncm_nb = confusion_matrix(y_test, y_cm_nb)\n","e2003206":"plt.figure(figsize = (8,8))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\nplt.subplots_adjust(wspace = 0.4, hspace = 0.4)\n\nplt.subplot(2,2,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(cm_lr,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 12})\n\nplt.subplot(2,2,2)\nplt.title(\"KNN Confusion Matrix\")\nsns.heatmap(cm_knn, annot = True, cmap = \"Blues\", fmt = 'd', cbar = False, annot_kws = {\"size\": 12})\n\nplt.subplot(2,2,3)\nplt.title(\"NB Confusion Matrix\")\nsns.heatmap(cm_nb, annot = True, cmap = \"Blues\", fmt = 'd', cbar = False, annot_kws = {\"size\": 12})\n\nplt.subplot(2,2,4)\nplt.title(\"SVM Confusion Matrix\")\nsns.heatmap(cm_svm, annot = True, cmap = \"Blues\", fmt = 'd', cbar = False, annot_kws = {\"size\": 12})\n","163e7c07":"Income and CCAvg, Personal Loan share a positive correlation","c95f5d12":"People with 2+ years of education and high CCAvg & Income have higher chances of availing Loans","a9133080":"#### Model accuracy","c491d64c":"Family with more than 3 members have higher chances of availing loans","f47b94de":"We can conclude KNN is the best suited algorithm as it gives a good accuracy score of 96.73 on test data and confusion matrix gives a good prediction on no. of people availing the Loan.\n\n\nHence we would like to conclude that people having high Income & CCAvg, Family consisting of more than 3 members, having CD & Securities account have higher chances of availing Personal Loan","bb6908ef":"Members across all age groups with higher Income having higher CCAvg having a CD Account, Securities account and having a family of more than 3 members have higher probability of availing Loan.","7768be56":"## Using KNN","2732c251":"## Using Naive Bayes theorem","27a0d22f":"*I am still working on this piece, would be regularly updating this as and when I come across a better way to solve this..*","c512adaa":"## Data Pre-processing","d4ce6852":"**Test Accuracy of KNN Algorithm is 96.73**","3c19a07d":"Higher the Income and CCAvg, Higher is the probability of person having CD Account","79e3126d":"Income, CCAvg, Mortgage are highly right skewed","81d7224e":"**Test Accuracy of Naive Bayes Algorithm is 87.26**","ec54e05b":"Higher the Income and CCAvg, Higher is the probability of person availing Loan","aed65c3a":"## Compare","f271eedb":"## Import packages and Observe dataset","4ebd7956":"There is some linear relation between Income and Mortgage value","bbdb551c":"There is huge imbalance in dataset as only 480 have availed Loan","04ef61ca":"**Test Accuracy of Support Vector Machines Algorithm is 96.6**","fc0e828d":"## Using Support Vector Machines ","19155950":"People across all ages and having high income have availed Loans","961fbd1f":"People with Securities account have higher chances of availing personal loan","844a50a7":"Here we we would determine the probability of customer availing Loan, hence Personal Loan would be target variable (0 = No Loan) and (1 = Loan availed)","a0e1d5d8":"**Test Accuracy of Logistic Regression Algorithm is 94.39**","8b97fdb0":"## Exploratory Data Analytics","1febc7c3":"Analyzing the KNN confusion matrix\nTrue Positives (TP): we correctly predicted that 111 will take Loans\n\nTrue Negatives (TN): we correctly predicted that 1340 will not take loans\n\nFalse Positives (FP): we incorrectly predicted that 11 will take loans when they actually did not take Loans (Type - 1 Error)\n\nFalse Negatives (FN): we incorrectly predicted that 38 will not take Loans when they actually did take Loans (a \"Type II error\")","d91597c4":"Experience does not matter in comparison with people availing Loans","61833bd3":"## Using Logistic Regression","14ee15cd":"## Confusion Matrix"}}