{"cell_type":{"4f517cf9":"code","aa69e2e8":"code","d6b723fd":"code","50751d35":"code","c29263d5":"code","b58edf7a":"code","e5aee1d7":"code","709dd9a6":"code","574f7fb3":"code","7bc02f19":"code","ca1579af":"code","efb72b8a":"code","7e3381b6":"code","2636397a":"code","1cd22957":"code","8c9d5e59":"code","fe751f89":"code","994d0ee9":"code","9378499b":"code","a2692e0e":"code","04a141c8":"code","338f54c2":"code","6092a313":"code","1730ee24":"code","5abd16bc":"code","ab09065b":"code","dc8c45d7":"code","45fbb91d":"code","1e36a4cc":"code","ad3766f5":"code","9095b1a2":"code","89edeab8":"code","b0fce42f":"code","5b37db62":"code","c999e2c3":"code","4fdb64d0":"code","bc179da6":"code","f309923b":"code","8ab5644f":"code","05bcb216":"code","18a75d02":"code","2a082097":"code","a8e94366":"code","9e8a7e0e":"code","61e8387e":"markdown","a33f5ba3":"markdown","cf48f93f":"markdown","0192ee68":"markdown","8e05552b":"markdown","fd49eb8c":"markdown","db2d2561":"markdown","9caa711a":"markdown","d81e3083":"markdown","176cd72c":"markdown","feac4de8":"markdown","08d84c80":"markdown","237fe24e":"markdown","e35a1590":"markdown","a7778316":"markdown","ca132d7a":"markdown","af4fb1b9":"markdown","cda61566":"markdown","f18f86d7":"markdown","b683382f":"markdown","8a0d3519":"markdown","d9217181":"markdown","01baaddf":"markdown","3ed17788":"markdown","448ad960":"markdown","44a8afc5":"markdown","8438d937":"markdown","0a23b83a":"markdown","b470d739":"markdown","f571089e":"markdown","1606d776":"markdown","66195a43":"markdown"},"source":{"4f517cf9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa69e2e8":"basic_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nbasic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","d6b723fd":"print(basic_train.shape)\nbasic_train.head()","50751d35":"print(basic_test.shape)\nbasic_test.head()","c29263d5":"basic_train.info()","b58edf7a":"basic_train.isnull().sum()","e5aee1d7":"basic_test.info()","709dd9a6":"basic_test.isnull().sum()","574f7fb3":"basic_train.Sex.value_counts()\/len(basic_train)","7bc02f19":"sns.barplot(x='Sex', y='Survived',data=basic_train)\nplt.show()","ca1579af":"basic_train.Embarked.value_counts()\/len(basic_train)","efb72b8a":"sns.lineplot(x='Embarked', y='Survived', data=basic_train)\nplt.show()","7e3381b6":"sns.FacetGrid(basic_train, hue='Survived', height=8).map(sns.distplot,'Age').set_axis_labels('Age','Survived').add_legend()\nplt.show()","2636397a":"sns.barplot(x='Pclass',y='Survived' ,data=basic_train)\nplt.show()","1cd22957":"# Change NaN by Mode in Embarked column\nbasic_train.Embarked = basic_train.Embarked.fillna(basic_train.Embarked.mode()[0])\nbasic_test.Embarked = basic_test.Embarked.fillna(basic_test.Embarked.mode()[0])","8c9d5e59":"# Only test data has missing values for fare\npclass = basic_test.loc[basic_test.Fare.isnull(), 'Pclass'].values[0]\nmedian_fare = basic_test.loc[basic_test.Pclass== pclass, 'Fare'].median()\nbasic_test.loc[basic_test.Fare.isnull(), 'Fare'] = median_fare","fe751f89":"# Extracting first letter of the cabin string and mapping it in both data sets\nbasic_train.Cabin = basic_train.Cabin.str[0]\nbasic_test.Cabin = basic_test.Cabin.str[0]\n\ncabin_map = {'C':3, 'E':5, 'G':7, 'D':4, 'A':1, 'B':2, 'F':6, 'T':8}\nbasic_train.replace({'Cabin': cabin_map}, inplace=True)\nbasic_test.replace({'Cabin': cabin_map}, inplace=True)\n\n# Since the cabin has a very high percentage of missing values, we directly replace NaN with 0\nbasic_train.Cabin = basic_train.Cabin.fillna(0)\nbasic_test.Cabin = basic_test.Cabin.fillna(0)","994d0ee9":"basic_train['Family Size'] = basic_train.SibSp + basic_train.Parch + 1\nbasic_test['Family Size'] = basic_test.SibSp + basic_test.Parch + 1","9378499b":"basic_train['title'] = basic_train.Name.str.split(',', expand=True)[1].str.split('.',expand=True)[0]\nbasic_test['title'] = basic_test.Name.str.split(',', expand=True)[1].str.split('.',expand=True)[0]","a2692e0e":"# Mapping the Title values.\nmapping = {' Mr': 1, ' Mrs': 2, ' Dona':2, ' Miss':3, ' Master':4, ' Don':1, ' Rev':5, ' Dr':6, ' Mme':3,\n           ' Ms':3, ' Major':1, ' Lady':2, ' Sir':1, ' Mlle':3, ' Col':1, ' Capt':1,\n           ' the Countess':2, ' Jonkheer':1}\nbasic_train.replace({'title': mapping}, inplace=True)\nbasic_test.replace({'title': mapping}, inplace=True)","04a141c8":"for title, age in basic_train.groupby('title')['Age'].median().iteritems():\n    basic_train.loc[(basic_train['title']==title) & (basic_train['Age'].isnull()), 'Age'] = age\nfor title, age in basic_test.groupby('title')['Age'].median().iteritems():\n    basic_test.loc[(basic_test['title']==title) & (basic_test['Age'].isnull()), 'Age'] = age","338f54c2":"basic_train['FpP'] = basic_train['Fare']\/(basic_train['Family Size'])\nbasic_test['FpP'] = basic_test['Fare']\/(basic_test['Family Size'])","6092a313":"# Mapping the gender column\nsex_map = {'male': 1, 'female':0}\nbasic_train.replace({'Sex': sex_map}, inplace=True)\nbasic_test.replace({'Sex': sex_map}, inplace=True)","1730ee24":"# Mapping the Embarked (Port) column\nport_map = {'S':1, 'C':2, 'Q':3}\nbasic_train.replace({'Embarked': port_map}, inplace=True)\nbasic_test.replace({'Embarked': port_map}, inplace=True)","5abd16bc":"# Survived is our target column. Hence separating it from our data frame.\ntarget = basic_train['Survived']","ab09065b":"basic_train","dc8c45d7":"#dropping non-useful (non-features) columns from the dataframe \ntrain_df=basic_train.drop(['SibSp', 'Parch', 'Name', 'Ticket','Survived','Fare'], axis = 1)\ntest_df=basic_test.drop(['SibSp', 'Parch', 'Name', 'Ticket','Fare'], axis = 1)","45fbb91d":"train_df","1e36a4cc":"plt.subplots(figsize=(15,10))\nsns.heatmap(train_df.corr(),annot=True,cmap='Greens')\nplt.show()","ad3766f5":"X = train_df[['PassengerId', 'Pclass','Sex', 'Age','Cabin', 'title','Family Size', 'FpP', 'Embarked']]\ny = target\nX_test = test_df[['PassengerId', 'Pclass','Sex', 'Age','Cabin', 'title','Family Size','FpP', 'Embarked']]","9095b1a2":"sc = StandardScaler()\nX = sc.fit_transform(X)\nX_test = sc.transform(X_test)","89edeab8":"# random forest model creation\nrfc = RandomForestClassifier()\n# rfc = RandomForestClassifier(criterion = 'entropy', max_depth = 8, n_estimators = 500, random_state = 42)\nrfc.fit(X,y)\n# predictions\nrfc_predict = rfc.predict(X_test)","b0fce42f":"# rfc_predict","5b37db62":"# gradient booster\ngbr = GradientBoostingClassifier(max_depth=4, max_features='auto', n_estimators=100)\ngbr.fit(X,y)\n# prediction\ngbr_predict=gbr.predict(X_test)","c999e2c3":"dt = DecisionTreeClassifier(max_depth=4, max_features='auto')\ndt.fit(X,y)\n# prediction\ndt_predict = dt.predict(X_test)","4fdb64d0":"lr = LogisticRegression()\nlr.fit(X,y)\n# prediction\nlr_predict=lr.predict(X_test)","bc179da6":"param_grid = {\n#     'n_estimators': [50, 200, 500, 1000],\n    'max_features': ['auto'],\n    'max_depth': [4,5,6, 7, 8]\n}","f309923b":"CV = GridSearchCV(estimator = dt, param_grid = param_grid, cv = 5)\nCV.fit(X, y)\nCV.best_estimator_","8ab5644f":"\nrfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\ngbr_cv_score = cross_val_score(gbr, X, y, cv=10, scoring='roc_auc')\ndt_cv_score = cross_val_score(dt, X, y, cv=10, scoring='roc_auc')\nlr_cv_score = cross_val_score(lr, X, y, cv=10, scoring='roc_auc')","05bcb216":"print(\"=== Mean AUC Score ===\")\nprint(\"Mean AUC Score - Gradient Booster: \", gbr_cv_score.mean())\nprint(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\nprint(\"Mean AUC Score - Decision Tree: \", dt_cv_score.mean())\nprint(\"Mean AUC Score - Logistic Regression: \", lr_cv_score.mean())","18a75d02":"ids = basic_test['PassengerId']\nsubmit = pd.DataFrame()\nsubmit['PassengerId'] = ids\nsubmit['Survived'] = rfc_predict","2a082097":"submit","a8e94366":"# submit.Survived.value_counts()","9e8a7e0e":"submit.to_csv('submission17.csv',index=False)","61e8387e":"**The test data has 418 records. The Age, Fare and Cabin columns have missing values.**","a33f5ba3":"# Model ","cf48f93f":"# Feature Selection","0192ee68":"**Almost 65% of the travellers are male and 35% are female.**","8e05552b":"**NOTE: Accuracy of the model may depend significantly on the mapping of Titles. I've tried to map the Titles to the best of my understanding.**","fd49eb8c":"Replacing missing values in Age column with the median of Title group.","db2d2561":"***The Survived column is the target as it is absent from the test data set***","9caa711a":"**Survival rate is maximum for passengers who boarded at Port C (55%) while it is least for passengers who boarded at Port S(35%)**","d81e3083":"# Decision Tree","176cd72c":"# Importing Libraries","feac4de8":"**Survival rate is highest for first class travellers.**","08d84c80":"* **Correlation and Feature Importance**","237fe24e":"# Feature Engineering","e35a1590":"**Comparing the survival rate on the basis of gender gives us surprising results as there is heavy gender bias.\nAlmost 74% of female passengers survived while only 18% of male passengers made it out alive.**","a7778316":"**Maximum passengers boarded from Port S while the least boarded from Port Q**","ca132d7a":"* **Fare per Person Feature**","af4fb1b9":"# Input Data","cda61566":"* **Title Feature**","f18f86d7":"# Random Forest Classifier","b683382f":"# Logistic Regression","8a0d3519":"Tuning HyperParameters","d9217181":"# Almost 80% accuracy for beginners\n\n*This notebook will serve as a beginners guide to the competition. It is aimed at users with little knowledge about data science.*\n\nWe will perform the following steps in achieving our goals.\n* Importing necessary libraries\n* Importing and reading the data sets\n* Perform exploratory data analysis\n* Data Cleaning\n* Feature Engineering\n* Feature Scaling\n* Selecting and fitting a model\n* Predicting results\n\n**Please add any suggestions or questions in the comments below**","01baaddf":"* **Family Size Feature**","3ed17788":"# Gradient Booster Classifier","448ad960":"# Exploratory Data Analysis","44a8afc5":"*The code may look a little overwhelming, but if you look in between the lines, it simply extracts the title as it is formatted in the name column.*","8438d937":"**The training data set has 891 records. The Age, Cabin and Embarked columns have missing data**","0a23b83a":"# Feature Scaling","b470d739":"* **Visualization**","f571089e":"**Looking deeper into the training data set, we observe that there are 177(19.8%) missing values in the age column, 2(0.22%) missing values in the embarked columns whereas a whooping 687(77.1%) missing values in the cabin column.**","1606d776":"**There are 86 (20.57%) missing values in the age column, 1 (0.24%) missing value in fare columns and 327(78.23%) missing values in cabin column.**","66195a43":"**Survival rate is highest among middle aged men and women.**"}}