{"cell_type":{"4a1bcf24":"code","595fde0b":"code","6f54da5f":"code","9ad6516e":"code","deb06b3f":"code","0d7bd2f8":"code","d511b1f6":"code","0df6fdd6":"code","83dee92b":"code","299a2662":"code","0c11a2f6":"code","07589345":"code","a875aacf":"code","5961d8e4":"code","a3cfa3fd":"code","a816b992":"code","dace4fe4":"code","d9cf7b4b":"code","de2e33f2":"code","c709c8c3":"code","858c6ee5":"code","f15c5af1":"code","903d765b":"code","01fda112":"markdown","a4a8f922":"markdown","61723715":"markdown","ba591f87":"markdown","6409e624":"markdown","5aa79f7a":"markdown","43f197a3":"markdown","9e87781b":"markdown","755e2add":"markdown"},"source":{"4a1bcf24":"import numpy as np \nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport cv2\n\nfrom keras.callbacks import EarlyStopping","595fde0b":"# Create a list with the filepaths for training and testing\ntrain_img_Path = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\n\ntest_img_Path = '..\/input\/plant-pathology-2021-fgvc8\/test_images'\n\nimg_Path = '..\/input\/resized-plant2021\/img_sz_256'\n\ntrain = pd.read_csv(r'..\/input\/plant-pathology-2021-fgvc8\/train.csv')\n\nsample_submission = pd.read_csv(r'..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')","6f54da5f":"train.head()","9ad6516e":"print(f'Number of pictures in the training dataset: {train.shape[0]}\\n')\nprint(f'Number of different labels: {len(train.labels.unique())}\\n')\nprint(f'Labels: {train.labels.unique()}')","deb06b3f":"train['labels'].value_counts()","0d7bd2f8":"plt.figure(figsize=(14,7))\nb = sns.countplot(x='labels', data=train, order=sorted(train['labels'].unique()))\nfor item in b.get_xticklabels():\n    item.set_rotation(90)\nplt.title('Label Distribution', weight='bold')\nplt.show()","d511b1f6":"plt.figure(figsize=(20,40))\ni=1\nfor idx,s in train.head(9).iterrows():\n    img_path = os.path.join(img_Path,s['image'])\n    img=cv2.imread(img_path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    fig=plt.subplot(9,3,i)\n    fig.imshow(img)\n    fig.set_title(s['labels'])\n    i+=1","0df6fdd6":"CLASSES = train['labels'].unique().tolist()","83dee92b":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n# Preprocessing the Training set\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   shear_range = 0.1,\n                                   zoom_range = 0.1,\n                                   horizontal_flip = True,\n                                   validation_split=0.25)\n\ntrain_data = train_datagen.flow_from_dataframe(train,\n                                              directory=img_Path,\n                                              classes=CLASSES,\n                                              x_col=\"image\",\n                                              y_col=\"labels\",\n                                              target_size=(150, 150),\n                                              subset='training')\n\nval_data = train_datagen.flow_from_dataframe(train,\n                                            directory=img_Path,\n                                            classes=CLASSES,\n                                            x_col=\"image\",\n                                            y_col=\"labels\",\n                                            target_size=(150, 150),\n                                            subset='validation')","299a2662":"dict_classes = train_data.class_indices\ndict_classes","0c11a2f6":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import to_categorical\nfrom keras import Sequential\nfrom keras.applications import InceptionResNetV2, DenseNet169, ResNet152V2\nfrom tensorflow.keras.layers import Dense","07589345":"base_Net = ResNet152V2(include_top = False, \n                         weights = '..\/input\/keras-pretrained-models\/ResNet152V2_NoTop_ImageNet.h5', \n                         input_shape = train_data.image_shape, \n                         pooling='avg',\n                         classes = CLASSES)","a875aacf":"#Callbacks\nEarlyStop_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","5961d8e4":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_Net = Sequential()\nmodel_Net.add(base_Net)\nmodel_Net.add(Dense(12, activation=('softmax')))\n\nmodel_Net.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['AUC'])\nmodel_Net.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\nb = model_Net.fit(train_data, validation_data = val_data, epochs = 10,callbacks=my_callback, batch_size=128)","a3cfa3fd":"base_InceptionResNetV2 = InceptionResNetV2(include_top = False, \n                         weights = '..\/input\/keras-pretrained-models\/InceptionResNetV2_NoTop_ImageNet.h5', \n                         input_shape = train_data.image_shape, \n                         pooling='avg',\n                         classes = CLASSES)","a816b992":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_IResNet2 = Sequential()\nmodel_IResNet2.add(base_InceptionResNetV2)\nmodel_IResNet2.add(Dense(12, activation=('softmax')))\n\nmodel_IResNet2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_IResNet2.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\nc = model_IResNet2.fit(train_data, validation_data = val_data, epochs = 10,callbacks=my_callback, batch_size=128)","dace4fe4":"base_DenseNet169 = DenseNet169(include_top = False, \n                         weights = '..\/input\/keras-pretrained-models\/DenseNet169_NoTop_ImageNet.h5', \n                         input_shape = train_data.image_shape, \n                         pooling='avg',\n                         classes = CLASSES)","d9cf7b4b":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_dense = Sequential()\nmodel_dense.add(base_DenseNet169)\nmodel_dense.add(Dense(12, activation=('softmax')))\n\nmodel_dense.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_dense.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\nd = model_dense.fit(train_data, validation_data = val_data, epochs = 10,callbacks=my_callback, batch_size=128)","de2e33f2":"test_dir = '\/kaggle\/input\/plant-pathology-2021-fgvc8\/test_images\/'\ntest_df = pd.DataFrame()\ntest_df['image'] = os.listdir(test_dir)\n\ntest_data = train_datagen.flow_from_dataframe(dataframe=test_df,\n                                    directory=test_dir,\n                                    x_col=\"image\",\n                                    y_col=None,\n                                    batch_size=32,\n                                    seed=42,\n                                    shuffle=False,\n                                    class_mode=None,\n                                    target_size=(150, 150))","c709c8c3":"pred_net = model_Net.predict(test_data)\npred_iresnet2 = model_IResNet2.predict(test_data)\npred_dense = model_dense.predict(test_data)","858c6ee5":"pred = ((pred_net+pred_iresnet2+pred_dense)\/3).tolist()","f15c5af1":"for i in range(len(pred)):\n    pred[i] = np.argmax(pred[i])\n\n    \ndef get_key(val):\n    for key, value in dict_classes.items():\n        if val == value:\n            return key\n        \n\nfor i in range(len(pred)):\n    pred[i] = get_key(pred[i])","903d765b":"test_df['labels'] = pred\ntest_df.to_csv('submission.csv',index=False)","01fda112":"#### Defining the DenseNet169 Convolutional Neural Net:","a4a8f922":"* I am using the ResNet152V2, InceptionResNetV2, DenseNet169.","61723715":"Apples are one of the most important temperate fruit crops in the world. Foliar (leaf) diseases pose a major threat to the overall productivity and quality of apple orchards. The current process for disease diagnosis in apple orchards is based on manual scouting by humans, which is time-consuming and expensive.\n\nAlthough computer vision-based models have shown promise for plant disease identification, there are some limitations that need to be addressed. Large variations in visual symptoms of a single disease across different apple cultivars, or new varieties that originated under cultivation, are major challenges for computer vision-based disease identification. These variations arise from differences in natural and image capturing environments, for example, leaf color and leaf morphology, the age of infected tissues, non-uniform image background, and different light illumination during imaging etc.","ba591f87":"#### If you liked the Notebook Please Upvote It !\n#### Thank You","6409e624":"#### Importing libraries","5aa79f7a":"#### Making predictions on test data:","43f197a3":"## Plant Pathology 2021 - FGVC8\n#### Identify the category of foliar diseases in apple trees","9e87781b":"#### Defining the InceptionResNetV2 Convolutional Neural Net:","755e2add":"#### Defining the ResNet152V2 Convolutional Neural Net:"}}