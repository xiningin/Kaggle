{"cell_type":{"fa92cbc6":"code","a0b8d1d0":"code","1d11f88f":"code","a3747cff":"code","1bdbbe04":"code","5444846c":"code","9f6b1808":"code","82f4ccb8":"code","6a1c8b1c":"code","9b67746e":"code","2da5c1a2":"code","39e5f811":"code","a066a91b":"code","2200eb03":"code","1db0e677":"code","7ea8a3a1":"code","9cd4ed16":"code","f8bf81bf":"code","2a5082ec":"code","9527be48":"code","529542c4":"code","4f627e1d":"code","ba89314f":"code","1b80024f":"code","5fbf2246":"code","178e0530":"code","b0e7bd8c":"code","1ec6b74c":"code","ac3e7c2b":"code","e0e829d5":"code","9a2d1b1c":"code","6e42a83c":"code","8612d904":"code","62967cfe":"code","e9b7781a":"code","0721c730":"code","6850c76e":"code","6c91ab4a":"code","13eff0a7":"code","6cb4ca8f":"code","065e6bfa":"code","4ce47ce2":"code","e54f03cf":"code","49467acc":"code","087f7baf":"code","b3b7cff4":"code","d12a13d6":"code","2b0ee57e":"code","56d517a7":"code","20e18980":"code","a1d5d2e5":"code","044bc872":"markdown","d535f87f":"markdown","013ed5b7":"markdown","daebc207":"markdown","a97b345f":"markdown","2e955d2a":"markdown","b3005c2a":"markdown","03c7a25e":"markdown","ba23bcc1":"markdown","8a2f00c6":"markdown","c39396b9":"markdown","bd6a4c0c":"markdown","783f700f":"markdown","8edf0055":"markdown","2b15afa5":"markdown","f93ee9dd":"markdown","e8798f22":"markdown","9d6ee6a9":"markdown","1bb6d4c3":"markdown","660fb7a2":"markdown"},"source":{"fa92cbc6":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CyclicLR\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\nfrom glob import glob\nfrom skimage.io import imread\nfrom os import listdir\n\nimport time\nimport copy\nfrom tqdm import tqdm_notebook as tqdm","a0b8d1d0":"run_training = False\nretrain = False\nfind_learning_rate = False","1d11f88f":"files = listdir(\"..\/input\/breast-histopathology-images\/\")\nprint(len(files))","a3747cff":"files[0:10]","1bdbbe04":"files = listdir(\"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/\")\nlen(files)","5444846c":"base_path = \"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/\"\nfolder = listdir(base_path)\nlen(folder)","9f6b1808":"total_images = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    for c in [0, 1]:\n        patient_path = base_path + patient_id \n        class_path = patient_path + \"\/\" + str(c) + \"\/\"\n        subfiles = listdir(class_path)\n        total_images += len(subfiles)","82f4ccb8":"total_images","6a1c8b1c":"data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n\nk = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    patient_path = base_path + patient_id \n    for c in [0,1]:\n        class_path = patient_path + \"\/\" + str(c) + \"\/\"\n        subfiles = listdir(class_path)\n        for m in range(len(subfiles)):\n            image_path = subfiles[m]\n            data.iloc[k][\"path\"] = class_path + image_path\n            data.iloc[k][\"target\"] = c\n            data.iloc[k][\"patient_id\"] = patient_id\n            k += 1  \n\ndata.head(100)","9b67746e":"data.shape","2da5c1a2":"cancer_perc = data.groupby(\"patient_id\").target.value_counts()\/ data.groupby(\"patient_id\").target.size()\ncancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"Orange\", kde=False, bins=30)\nax[0].set_xlabel(\"Number of patches\")\nax[0].set_ylabel(\"Frequency\");\nax[0].set_title(\"How many patches do we have per patient?\");\nsns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"Tomato\", kde=False, bins=30)\nax[1].set_title(\"How much percentage of an image is covered by IDC?\")\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"% of patches with IDC\");\nsns.countplot(data.target, palette=\"Set2\", ax=ax[2]);\nax[2].set_xlabel(\"no(0) versus yes(1)\")\nax[2].set_title(\"How many patches show IDC?\");","39e5f811":"data.target = data.target.astype(np.int)","a066a91b":"pos_selection = np.random.choice(data[data.target==1].index.values, size=50, replace=False)\nneg_selection = np.random.choice(data[data.target==0].index.values, size=50, replace=False)","2200eb03":"fig, ax = plt.subplots(5,10,figsize=(20,10))\n\nfor n in range(5):\n    for m in range(10):\n        idx = pos_selection[m + 10*n]\n        image = imread(data.loc[idx, \"path\"])\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","1db0e677":"fig, ax = plt.subplots(5,10,figsize=(20,10))\n\nfor n in range(5):\n    for m in range(10):\n        idx = neg_selection[m + 10*n]\n        image = imread(data.loc[idx, \"path\"])\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","7ea8a3a1":"def extract_coords(df):\n    coord = df.path.str.rsplit(\"_\", n=4, expand=True)\n    coord = coord.drop([0, 1, 4], axis=1)\n    coord = coord.rename({2: \"x\", 3: \"y\"}, axis=1)\n    coord.loc[:, \"x\"] = coord.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    coord.loc[:, \"y\"] = coord.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    df.loc[:, \"x\"] = coord.x.values\n    df.loc[:, \"y\"] = coord.y.values\n    return df\n\ndef get_cancer_dataframe(patient_id, cancer_id):\n    path = base_path + patient_id + \"\/\" + cancer_id\n    files = listdir(path)\n    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n    path_names = path + \"\/\" + dataframe.filename.values\n    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n    dataframe.loc[:, \"path\"] = path_names\n    dataframe = dataframe.drop([0, 1, 4], axis=1)\n    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n    dataframe.loc[:, \"x\"] = dataframe.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    dataframe.loc[:, \"y\"] = dataframe.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    return dataframe\n\ndef get_patient_dataframe(patient_id):\n    df_0 = get_cancer_dataframe(patient_id, \"0\")\n    df_1 = get_cancer_dataframe(patient_id, \"1\")\n    patient_df = df_0.append(df_1)\n    return patient_df","9cd4ed16":"example = get_patient_dataframe(data.patient_id.values[0])\nexample.head()","f8bf81bf":"fig, ax = plt.subplots(5,3,figsize=(20, 27))\n\npatient_ids = data.patient_id.unique()\n\nfor n in range(5):\n    for m in range(3):\n        patient_id = patient_ids[m + 3*n]\n        example_df = get_patient_dataframe(patient_id)\n        \n        ax[n,m].scatter(example_df.x.values, example_df.y.values, c=example_df.target.values, cmap=\"coolwarm\", s=20);\n        ax[n,m].set_title(\"patient =>\" + patient_id)\n        ax[n,m].set_xlabel(\"y coord\")\n        ax[n,m].set_ylabel(\"x coord\")","2a5082ec":"def visualise_breast_tissue(patient_id, pred_df=None):\n    example_df = get_patient_dataframe(patient_id)\n    max_point = [example_df.y.max()-1, example_df.x.max()-1]\n    grid = 255*np.ones(shape = (max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n    mask = 255*np.ones(shape = (max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n    if pred_df is not None:\n        patient_df = pred_df[pred_df.patient_id == patient_id].copy()\n    mask_proba = np.zeros(shape = (max_point[0] + 50, max_point[1] + 50, 1)).astype(np.float)\n    \n    broken_patches = []\n    for n in range(len(example_df)):\n        try:\n            image = imread(example_df.path.values[n])\n            \n            target = example_df.target.values[n]\n            \n            x_coord = np.int(example_df.x.values[n])\n            y_coord = np.int(example_df.y.values[n])\n            x_start = x_coord - 1\n            y_start = y_coord - 1\n            x_end = x_start + 50\n            y_end = y_start + 50\n\n            grid[y_start:y_end, x_start:x_end] = image\n            if target == 1:\n                mask[y_start:y_end, x_start:x_end, 0] = 250\n                mask[y_start:y_end, x_start:x_end, 1] = 0\n                mask[y_start:y_end, x_start:x_end, 2] = 0\n            if pred_df is not None:\n                \n                proba = patient_df[\n                    (patient_df.x==x_coord) & (patient_df.y==y_coord)].proba\n                mask_proba[y_start:y_end, x_start:x_end, 0] = np.float(proba)\n\n        except ValueError:\n            broken_patches.append(example_df.path.values[n])\n    \n    \n    return grid, mask, broken_patches, mask_proba","9527be48":"example = \"13616\"\ngrid, mask, broken_patches,_ = visualise_breast_tissue(example)\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(grid, alpha=0.9)\nax[1].imshow(mask, alpha=0.8)\nax[1].imshow(grid, alpha=0.7)\nax[0].grid(False)\nax[1].grid(False)\nfor m in range(2):\n    ax[m].set_xlabel(\"y-coord\")\n    ax[m].set_ylabel(\"y-coord\")\nax[0].set_title(\"Breast tissue slice of patient: \" + patient_id)\nax[1].set_title(\"Cancer tissue colored red \\n of patient: \" + patient_id);","529542c4":"broken_patches","4f627e1d":"BATCH_SIZE = 32\nNUM_CLASSES = 2\n\nOUTPUT_PATH = \"\"\nMODEL_PATH = \"..\/input\/breastcancermodel\/\"\nLOSSES_PATH = \"..\/input\/breastcancermodel\/\"","ba89314f":"data.head()\ndata.loc[:, \"target\"] = data.target.astype(np.str)\ndata.info()","1b80024f":"patients = data.patient_id.unique()\n\ntrain_ids, sub_test_ids = train_test_split(patients,\n                                           test_size=0.3,\n                                           random_state=0)\ntest_ids, dev_ids = train_test_split(sub_test_ids, test_size=0.5, random_state=0)","5fbf2246":"print(len(train_ids)\/patients.shape[0]*100, len(dev_ids)\/patients.shape[0]*100, len(test_ids)\/patients.shape[0]*100)","178e0530":"print(len(train_ids), len(dev_ids), len(test_ids))","b0e7bd8c":"train_df = data.loc[data.patient_id.isin(train_ids),:].copy()\ntest_df = data.loc[data.patient_id.isin(test_ids),:].copy()\ndev_df = data.loc[data.patient_id.isin(dev_ids),:].copy()\n\ntrain_df = extract_coords(train_df)\ntest_df = extract_coords(test_df)\ndev_df = extract_coords(dev_df)","1ec6b74c":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(train_df.target, ax=ax[0], palette=\"Reds\")\nax[0].set_title(\"Train data\")\nsns.countplot(dev_df.target, ax=ax[1], palette=\"Blues\")\nax[1].set_title(\"Dev data\")\nsns.countplot(test_df.target, ax=ax[2], palette=\"Greens\");\nax[2].set_title(\"Test data\");","ac3e7c2b":"def my_transform(key=\"train\", plot=False):\n    train_sequence = [transforms.Resize((50,50)),\n                      transforms.RandomHorizontalFlip(),\n                      transforms.RandomVerticalFlip()]\n    val_sequence = [transforms.Resize((50,50))]\n    if plot==False:\n        train_sequence.extend([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n        val_sequence.extend([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n        \n    data_transforms = {'train': transforms.Compose(train_sequence),'val': transforms.Compose(val_sequence)}\n    return data_transforms[key]","e0e829d5":"class BreastCancerDataset(Dataset):\n    \n    def __init__(self, df, transform=None):\n        self.states = df\n        self.transform=transform\n      \n    def __len__(self):\n        return len(self.states)\n        \n    def __getitem__(self, idx):\n        patient_id = self.states.patient_id.values[idx]\n        x_coord = self.states.x.values[idx]\n        y_coord = self.states.y.values[idx]\n        image_path = self.states.path.values[idx] \n        image = Image.open(image_path)\n        image = image.convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n         \n        target = np.int(self.states.target.values[idx])\n        return {\"image\": image,\n                \"label\": target,\n                \"patient_id\": patient_id,\n                \"x\": x_coord,\n                \"y\": y_coord}","9a2d1b1c":"train_dataset = BreastCancerDataset(train_df, transform=my_transform(key=\"train\"))\ndev_dataset = BreastCancerDataset(dev_df, transform=my_transform(key=\"val\"))\ntest_dataset = BreastCancerDataset(test_df, transform=my_transform(key=\"val\"))","6e42a83c":"image_datasets = {\"train\": train_dataset, \"dev\": dev_dataset, \"test\": test_dataset}\ndataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"dev\", \"test\"]}","8612d904":"fig, ax = plt.subplots(3,6,figsize=(20,11))\n\ntrain_transform = my_transform(key=\"train\", plot=True)\nval_transform = my_transform(key=\"val\", plot=True)\n\nfor m in range(6):\n    filepath = train_df.path.values[m]\n    image = Image.open(filepath)\n    ax[0,m].imshow(image)\n    transformed_img = train_transform(image)\n    ax[1,m].imshow(transformed_img)\n    ax[2,m].imshow(val_transform(image))\n    ax[0,m].grid(False)\n    ax[1,m].grid(False)\n    ax[2,m].grid(False)\n    ax[0,m].set_title(train_df.patient_id.values[m] + \"\\n target: \" + train_df.target.values[m])\n    ax[1,m].set_title(\"Preprocessing for train\")\n    ax[2,m].set_title(\"Preprocessing for val\")","62967cfe":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\ndev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)","e9b7781a":"dataloaders = {\"train\": train_dataloader, \"dev\": dev_dataloader, \"test\": test_dataloader}","0721c730":"print(len(dataloaders[\"train\"]), len(dataloaders[\"dev\"]), len(dataloaders[\"test\"]))","6850c76e":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","6c91ab4a":"model = torchvision.models.resnet18(pretrained=False)\nif run_training:\n    model.load_state_dict(torch.load(\"..\/input\/pretrained-pytorch-models\/resnet18-5c106cde.pth\"))\nnum_features = model.fc.in_features\nprint(num_features)\n\nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, 512),\n    nn.ReLU(),\n    nn.BatchNorm1d(512),\n    nn.Dropout(0.5),\n    \n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.BatchNorm1d(256),\n    nn.Dropout(0.5),\n    \n    nn.Linear(256, NUM_CLASSES))\n\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n\nmodel.apply(init_weights)\nmodel = model.to(device)","13eff0a7":"weights = compute_class_weight(y=train_df.target.values, class_weight=\"balanced\", classes=train_df.target.unique())    \nclass_weights = torch.FloatTensor(weights)\nif device.type==\"cuda\":\n    class_weights = class_weights.cuda()\nprint(class_weights)","6cb4ca8f":"start_lr = 1e-6\nend_lr = 0.1","065e6bfa":"criterion = nn.CrossEntropyLoss(weight=class_weights)","4ce47ce2":"def f1_score(preds, targets):\n    \n    tp = (preds*targets).sum().to(torch.float32)\n    fp = ((targets-1)*preds).sum().to(torch.float32)\n    fn = (targets*(preds-1)).sum().to(torch.float32)\n    \n    epsilon = 1e-7\n    precision = tp \/ (tp + fp + epsilon)\n    recall = tp \/ (tp + fn + epsilon)\n    \n    f1_score = 2 * precision * recall\/(precision + recall + epsilon)\n    f1_score.requires_grad = is_training\n    return f1_score","e54f03cf":"def train_loop(model, criterion, optimizer, lr_find=False, scheduler=None, num_epochs = 3, lam=0.0):\n    since = time.time()\n    if lr_find:\n        phases = [\"train\"]\n    else:\n        phases = [\"train\", \"dev\", \"test\"]\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    loss_dict = {\"train\": [], \"dev\": [], \"test\": []}\n    lam_tensor = torch.tensor(lam, device=device)\n    \n    running_loss_dict = {\"train\": [], \"dev\": [], \"test\": []}\n    \n    lr_find_loss = []\n    lr_find_lr = []\n    smoothing = 0.2\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        \n        for phase in phases:\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n            \n            tk0 = tqdm(dataloaders[phase], total=int(len(dataloaders[phase])))\n\n            counter = 0\n            for bi, d in enumerate(tk0):\n                inputs = d[\"image\"]\n                labels = d[\"label\"]\n                inputs = inputs.to(device, dtype=torch.float)\n                labels = labels.to(device, dtype=torch.long)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        \n                        #l2_reg = torch.tensor(0., device=device)\n                        #for param in model.parameters():\n                            #l2_reg = lam_tensor * torch.norm(param)\n                        \n                        #loss += l2_reg\n            \n                        optimizer.step()\n                        # cyclical lr schedule is invoked after each batch\n                        if scheduler is not None:\n                            scheduler.step() \n                            \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n                if phase == 'train':\n                    if lr_find:\n                        scheduler.step()\n                        lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n                        lr_find_lr.append(lr_step)\n                \n                if counter==0:\n                    lr_find_loss.append(loss.item())\n                else:\n                    smoothed_loss = smoothing  * loss.item() + (1 - smoothing) * lr_find_loss[-1]\n                    lr_find_loss.append(smoothed_loss)\n     \n                counter += 1\n                \n                \n                tk0.set_postfix({'loss': running_loss \/ (counter * dataloaders[phase].batch_size),\n                                 'accuracy': running_corrects.double() \/ (counter * dataloaders[phase].batch_size)})\n                running_loss_dict[phase].append(running_loss \/ (counter * dataloaders[phase].batch_size))\n                \n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            loss_dict[phase].append(epoch_loss)\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            \n            # deep copy the model\n            if phase == 'dev' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n        print()\n        \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n    time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))              \n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    results = {\"model\": model,\n               \"loss_dict\": loss_dict,\n               \"running_loss_dict\": running_loss_dict,\n               \"lr_find\": {\"lr\": lr_find_lr, \"loss\": lr_find_loss}}\n    return results","49467acc":"import math\n\nif find_learning_rate:\n    lr_find_epochs=2\n    optimizer = optim.SGD(model.fc.parameters(), start_lr)\n    lr_lambda = lambda x: math.exp(x * math.log(end_lr \/ start_lr) \/ (lr_find_epochs * len(dataloaders[\"train\"])))\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n    results = train_loop(model, criterion, optimizer, lr_find=True, scheduler=scheduler, num_epochs=lr_find_epochs)\n    lr_find_lr, lr_find_loss = results[\"lr_find\"][\"lr\"], results[\"lr_find\"][\"loss\"]\n    \n    find_lr_df = pd.DataFrame(lr_find_loss, columns=[\"smoothed loss\"])\n    find_lr_df.loc[:, \"lr\"] = lr_find_lr\n    find_lr_df.to_csv(\"learning_rate_search.csv\", index=False)\n    \n    fig, ax = plt.subplots(1,2,figsize=(20,5))\n    ax[0].plot(np.array(lr_find_lr))\n    ax[1].plot(np.array(lr_find_loss))\n    ax[0].set_xlabel(\"Steps\")\n    ax[0].set_ylabel(\"Learning rate\")\n    ax[1].set_xlabel(\"Steps\")\n    ax[1].set_ylabel(\"Loss\");\n    \n    plt.figure(figsize=(20,5))\n    plt.plot(np.array(lr_find_lr), np.array(lr_find_loss), '-', color=\"tomato\");\n    plt.xlabel(\"Learning rate\")\n    plt.xscale(\"log\")\n    plt.ylabel(\"Smoothed Loss\")\n    plt.title(\"Searching for the optimal learning rate\");\nelse:\n    pass","087f7baf":"if run_training:\n    optimizer = optim.SGD(model.fc.parameters(), lr=0.01)\n    scheduler = CyclicLR(optimizer, base_lr=0.001, max_lr=0.01)\n    results = train_loop(model, criterion, optimizer, scheduler=scheduler, num_epochs = 15)\n    model, loss_dict, running_loss_dict = results[\"model\"], results[\"loss_dict\"], results[\"running_loss_dict\"]\n    \n    if device == \"cpu\":\n        OUTPUT_PATH += \".pth\"\n    else:\n        OUTPUT_PATH += \"_cuda.pth\"\n        \n    torch.save(model.state_dict(), OUTPUT_PATH)\n    \n    losses_df = pd.DataFrame(loss_dict[\"train\"],columns=[\"train\"])\n    losses_df.loc[:, \"dev\"] = loss_dict[\"dev\"]\n    losses_df.loc[:, \"test\"] = loss_dict[\"test\"]\n    losses_df.to_csv(\"losses_breastcancer.csv\", index=False)\n    \n    running_losses_df = pd.DataFrame(running_loss_dict[\"train\"], columns=[\"train\"])\n    running_losses_df.loc[0:len(running_loss_dict[\"dev\"])-1, \"dev\"] = running_loss_dict[\"dev\"]\n    running_losses_df.loc[0:len(running_loss_dict[\"test\"])-1, \"test\"] = running_loss_dict[\"test\"]\n    running_losses_df.to_csv(\"running_losses_breastcancer.csv\", index=False)\nelse:\n    if device == \"cpu\":\n        MODEL_PATH += \".pth\"\n    else:\n        MODEL_PATH += \"_cuda.pth\"\n    model.load_state_dict(torch.load(MODEL_PATH))\n    model.eval()\n    \n    losses_df = pd.read_csv(LOSSES_PATH + \"losses_breastcancer.csv\")\n    running_losses_df = pd.read_csv(LOSSES_PATH + \"running_losses_breastcancer.csv\")","b3b7cff4":"plt.figure(figsize=(20,5))\n\nplt.plot(losses_df[\"train\"], '-o', label=\"train\")\nplt.plot(losses_df[\"dev\"], '-o', label=\"dev\")\nplt.plot(losses_df[\"test\"], '-o', label=\"test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Weighted x-entropy\")\nplt.title(\"Loss change over epoch\")\nplt.legend();","d12a13d6":"fig, ax = plt.subplots(3,1,figsize=(20,15))\n\nax[0].plot(running_losses_df[\"train\"], '-o', label=\"train\")\nax[0].set_xlabel(\"Step\")\nax[0].set_ylabel(\"Weighted x-entropy\")\nax[0].set_title(\"Loss change over steps\")\nax[0].legend();\n\nax[1].plot(running_losses_df[\"dev\"], '-o', label=\"dev\", color=\"orange\")\nax[1].set_xlabel(\"Step\")\nax[1].set_ylabel(\"Weighted x-entropy\")\nax[1].set_title(\"Loss change over steps\")\nax[1].legend();\n\nax[2].plot(running_losses_df[\"test\"], '-o', label=\"test\", color=\"mediumseagreen\")\nax[2].set_xlabel(\"Step\")\nax[2].set_ylabel(\"Weighted x-entropy\")\nax[2].set_title(\"Loss change over steps\")\nax[2].legend();","2b0ee57e":"def sigmoid(x):\n    return 1.\/(1+np.exp(-x))","56d517a7":"def evaluate_model(model, predictions_df, key):\n    was_training = model.training\n    model.eval()\n\n    with torch.no_grad():\n        for i, data in enumerate(dataloaders[key]):\n            inputs = data[\"image\"].to(device)\n            labels = data[\"label\"].to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            proba = outputs.cpu().numpy().astype(np.float)\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"proba\"] = sigmoid(proba[:, 1])\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"true\"] = data[\"label\"].numpy().astype(np.int)\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"predicted\"] = preds.cpu().numpy().astype(np.int)\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"x\"] = data[\"x\"].numpy()\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"y\"] = data[\"y\"].numpy()\n            predictions_df.loc[i*BATCH_SIZE:(i+1)*BATCH_SIZE-1, \"patient_id\"] = data[\"patient_id\"]\n            \n    predictions_df = predictions_df.dropna()\n    return predictions_df","20e18980":"dev_predictions = pd.DataFrame(index = np.arange(0, dataset_sizes[\"dev\"]), columns = [\"true\", \"predicted\", \"proba\"])\ntest_predictions = pd.DataFrame(index = np.arange(0, dataset_sizes[\"test\"]), columns = [\"true\", \"predicted\", \"proba\"])\n\ndev_predictions = evaluate_model(model, dev_predictions, \"dev\")\ntest_predictions = evaluate_model(model, test_predictions, \"test\")","a1d5d2e5":"fig, ax = plt.subplots(3,3,figsize=(20,20))\n\nfor n in range(3):\n\n    idx = dev_predictions.patient_id.unique()[n]\n    grid, mask, broken_patches, mask_proba = visualise_breast_tissue(idx, pred_df=dev_predictions)\n\n\n    ax[n, 0].imshow(grid, alpha=0.9)\n    ax[n, 1].imshow(mask, alpha=0.8)\n    ax[n, 1].imshow(grid, alpha=0.7)\n    ax[n, 2].imshow(mask_proba[:,:,0], cmap=\"YlOrRd\")\n\n    for m in range(3):\n        ax[n, m].set_xlabel(\"y-coord\")\n        ax[n, m].set_ylabel(\"x-coord\")\n        ax[n, m].grid(False)\n        \n    ax[n, 0].set_title(\"Breast tissue slice of patient: \" + patient_id)\n    ax[n, 1].set_title(\"Cancer tissue colored red \\n of patient: \" + patient_id);\n    ax[n, 2].set_title(\"Cancer probability\");","044bc872":"Ok, in this folder we should find several images or a further substructure of folders.","d535f87f":"## Looking at healthy and cancer patches <a class=\"anchor\" id=\"patches\"><\/a>","013ed5b7":"# Setting up the machine learning workflow <a class=\"anchor\" id=\"workflow\"><\/a>","daebc207":"Ah ok. These are patient ids. For each patient we have an individual subfolder that contains image patches. \n\n### How many patients do we have?","a97b345f":"# The probability landscape of invasive ductal carcinoma <a class=\"anchor\" id=\"landscape\"><\/a>","2e955d2a":"### Settings","b3005c2a":"## Exploring the data structure","03c7a25e":"So far we can't stratify on the targets as we are splitting on patient ids. If we would like to include some target information we would need to create a feature that allows us to generate some balance. ","ba23bcc1":"### Storing the image_path, patient_id and the target","8a2f00c6":"Now it's 70 % train and 15 % for dev and test.","c39396b9":"No surprise. This matches the total number of patches. ","bd6a4c0c":"Let's use an example patient with id 13616: ","783f700f":"### Image dataset","8edf0055":"### Healthy patches","2b15afa5":"### Cancer patches","f93ee9dd":"Let's take a look at the target distributions between the datasets:","e8798f22":"# Exploratory analysis <a class=\"anchor\" id=\"eda\"><\/a>\n\n## What do we know about our data? <a class=\"anchor\" id=\"data\"><\/a>","9d6ee6a9":"### Model","1bb6d4c3":"### Data Loader","660fb7a2":"We can see that the test data has more cancer patches compared to healthy tissue patches than train or dev. We should keep this in mind!"}}