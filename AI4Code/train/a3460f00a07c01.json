{"cell_type":{"7fcb57d8":"code","2cd055ac":"code","076af7f1":"code","a02248c9":"code","37bba51d":"code","47950f8d":"code","1658cb71":"code","5cf5d148":"code","b492c1fe":"code","a497d28c":"code","607e7e5d":"code","8416d473":"code","ae186a90":"code","ecd66a2b":"code","c08181ae":"code","b129deda":"code","066306ef":"code","f6144398":"code","4eb5cb5c":"code","6ed531d7":"code","f45345ca":"code","4cf7e86f":"code","4ebcce4b":"code","c9275b7e":"code","492bd3fc":"code","1e2c89c3":"code","523495f9":"code","b5ff4927":"code","4da34547":"code","70ccc214":"code","825b7c83":"code","ea65026a":"code","11a651c7":"code","48a80dcb":"code","2381aa89":"code","21e5518e":"code","6925246d":"code","ef606dea":"code","4b07cd81":"code","472c927f":"markdown","857b3fb7":"markdown","1eb7d838":"markdown","c90490ef":"markdown","992d6b91":"markdown","45884183":"markdown","6728c480":"markdown","dd5628c5":"markdown","2cb153f6":"markdown","a824bfab":"markdown","b7e6b6da":"markdown","d19ae930":"markdown","90f29c03":"markdown","feee3e01":"markdown","4d3e46da":"markdown","0b4a46fa":"markdown","7c1972c5":"markdown","916b1a45":"markdown","507fe7e8":"markdown","df7632fd":"markdown","602503a7":"markdown","f4322d61":"markdown","64c4e866":"markdown","60c16122":"markdown","d64b0946":"markdown","71ed28a2":"markdown","fbba51c7":"markdown","76c74c86":"markdown","f95e1883":"markdown"},"source":{"7fcb57d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cd055ac":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom palettable.colorbrewer.qualitative import Pastel1_7\nfrom sklearn.preprocessing import MinMaxScaler\nfrom imblearn.over_sampling import SMOTE \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, confusion_matrix\nfrom sklearn.metrics import f1_score","076af7f1":"df=pd.read_csv('\/kaggle\/input\/travel-insurance\/travel insurance.csv')\ndf.head()","a02248c9":"df.shape","37bba51d":"df.columns","47950f8d":"df.rename(columns={ 'Agency Type':'Agency_Type', 'Distribution Channel':'Distribution_Channel', 'Product Name':'Product_Name','Net Sales':'Net_Sales', 'Commision (in value)':'Commision'},inplace=True)","1658cb71":"df.info()","5cf5d148":"df.isnull().sum().any\n","b492c1fe":"df=df.drop(['Gender'], axis=1)\ndf.head()","a497d28c":"column_keys=df.select_dtypes(include=['object']).columns.tolist()\nfor key in column_keys:\n    print('Unique elements of',key,'are: ')\n    print(df[key].unique(),end='\\n')\n    print(end='\\n')","607e7e5d":"df1 = df.groupby(by=[\"Destination\"]).size().reset_index(name=\"counts\")\ndf1.nlargest(15,['counts'])\ndf1['DestinationNew'] = np.where(df1['counts']>1090, df1['Destination'], 'Others')\nfig = px.pie(df1, values='counts', names='DestinationNew', title='Popular Destinations among insured')\nfig.show()","8416d473":"fig = plt.figure(figsize = (10, 5))\nplt.hist(df['Age'])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number of people\")\nplt.title(\"Distribution of Age\")\nplt.show()","ae186a90":"df2 = df.groupby(by=[\"Agency\"]).size().reset_index(name=\"counts\")\nfig = plt.figure(figsize = (10, 5))\nplt.bar(df2['Agency'], df2['counts'], color ='maroon', width = 0.4)\nplt.xlabel(\"Agency\")\nplt.ylabel(\"Number of people insured\")\nplt.title(\"People insured in different Insurance Agencies\")\nplt.show()","ecd66a2b":"df3 = df.groupby(by=[\"Product_Name\"]).size().reset_index(name=\"counts\")\nfig = px.pie(df3, values='counts', names='Product_Name', title='People insured under different plans')\nfig.show()","c08181ae":"df4=df.groupby(by=['Agency']).mean().reset_index()\ndf4.head()\nfig = plt.figure(figsize = (10, 5))\nplt.bar(df4['Agency'], df4['Commision'], color ='green', width = 0.4)\nplt.xlabel(\"Agency\")\nplt.ylabel(\"Avg. Commision\")\nplt.title(\"Average commision of agents in various agency\")\nplt.show()","b129deda":"fig = plt.figure(figsize = (10, 5))\nplt.bar(df4['Agency'], df4['Net_Sales'], color ='pink', width = 0.4)\nplt.xlabel(\"Agency\")\nplt.ylabel(\"Avg. Net Sales\")\nplt.title(\"Average Net Sales per agency\")\nplt.show()","066306ef":"df5=df.groupby(by=['Distribution_Channel']).size().reset_index(name=\"counts\")\nplt.bar(df5['Distribution_Channel'], df5['counts'], color ='purple',width = 0.4)\nplt.xlabel(\"Distribution Channel\")\nplt.ylabel(\"Number of people insured\")\nplt.title(\"People insured under different Distribution Channel\")\nplt.show()","f6144398":"df6=df.loc[df['Claim']=='Yes']\ndf7= df6.groupby(by=[\"Destination\"]).size().reset_index(name=\"counts\")\ndf8=df7.nlargest(5,['counts'])\nmy_circle = plt.Circle((0, 0), 0.6, color='white')\nplt.pie(df8['counts'], labels=df8['Destination'], autopct='%1.1f%%', colors=Pastel1_7.hex_colors)\nplt.title('Top 5 countries where insured are raising claim requests')\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","4eb5cb5c":"df9= df6.groupby(by=[\"Product_Name\"]).size().reset_index(name=\"counts\")\ndf10=df9.nlargest(5,['counts'])\nmy_circle = plt.Circle((0, 0), 0.6, color='white')\nplt.pie(df10['counts'], labels=df10['Product_Name'], autopct='%1.1f%%',colors=Pastel1_7.hex_colors)\nplt.title('Top 5 plans where insured are raising claim requests')\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","6ed531d7":"df11= df6.groupby(by=[\"Agency\"]).size().reset_index(name=\"counts\")\ndf12=df11.nlargest(5,['counts'])\nmy_circle = plt.Circle((0, 0), 0.6, color='white')\nplt.pie(df12['counts'], labels=df12['Agency'], autopct='%1.1f%%', colors=Pastel1_7.hex_colors)\nplt.title('Top 5 Agencies where insured are raising claim requests')\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","f45345ca":"df13=df.groupby(by=['Agency_Type']).size().reset_index(name=\"counts\")\nplt.bar(df13['Agency_Type'], df13['counts'], color ='red',width = 0.4)\nplt.xlabel(\"Agency Type\")\nplt.ylabel(\"Number of people insured\")\nplt.title(\"People insured under different Agency Type\")\nplt.show()","4cf7e86f":"df14 = df.groupby(by=[\"Claim\"]).size().reset_index(name=\"counts\")\nplt.bar(df14['Claim'], df14['counts'], color ='grey',width = 0.4)\nplt.xlabel(\"Claim\")\nplt.ylabel(\"Number of people insured\")\nplt.title(\"People Insured who requested for claim vs who did not\")\nplt.show()","4ebcce4b":"fig = plt.figure(figsize =(6,4 ))\nplt.boxplot(df['Duration'])\nplt.show()","c9275b7e":"index_duration = df[df['Duration'] < 0 ].index\ndf.drop(index_duration, inplace = True)","492bd3fc":"from sklearn import preprocessing\nlabel_encoder1 = preprocessing.LabelEncoder()\ndf['Agency']= label_encoder1.fit_transform(df['Agency'])\n  \nlabel_encoder2 = preprocessing.LabelEncoder()\ndf['Agency_Type']= label_encoder2.fit_transform(df['Agency_Type'])\n\nlabel_encoder3 = preprocessing.LabelEncoder()\ndf['Distribution_Channel']= label_encoder3.fit_transform(df['Distribution_Channel'])\n\nlabel_encoder4 = preprocessing.LabelEncoder()\ndf['Product_Name']= label_encoder4.fit_transform(df['Product_Name'])\n\nlabel_encoder5 = preprocessing.LabelEncoder()\ndf['Claim']= label_encoder5.fit_transform(df['Claim'])\n\n\nlabel_encoder6 = preprocessing.LabelEncoder()\ndf['Destination']= label_encoder6.fit_transform(df['Destination'])\n","1e2c89c3":"df","523495f9":"column_names = [\"Agency\", \"Agency_Type\", \"Distribution_Channel\",\"Product_Name\",\"Duration\",\"Destination\",\"Net_Sales\",\"Commision\",\"Age\",\"Claim\"]\ndf = df.reindex(columns=column_names)","b5ff4927":"plt.figure(figsize = (20,8))\nsns.heatmap(df.corr(), square=True,annot=True,cmap= 'coolwarm')","4da34547":"y=df.iloc[:,[-1]]\nX=df.drop(y.columns,axis = 1)","70ccc214":"X","825b7c83":"y","ea65026a":"sm = SMOTE(random_state=42)\nX_sm, y_sm = sm.fit_resample(X, y)\nprint(f'''Shape of X before SMOTE: {X.shape}\nShape of X after SMOTE: {X_sm.shape}''')\nprint('\\nBalance of positive and negative classes (%):')\ny_sm.value_counts(normalize=True) * 100","11a651c7":"X_sm","48a80dcb":"y_sm","2381aa89":"X_new=pd.DataFrame()\nto_scale = X_sm.columns\nmms = MinMaxScaler()\nX_new[to_scale] = mms.fit_transform(X_sm[to_scale])\nX_new.head()","21e5518e":"X_train, X_test, y_train, y_test = train_test_split(X_new, y_sm, test_size=0.25, random_state=42)","6925246d":"model = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\n","ef606dea":"print(f'Accuracy = {accuracy_score(y_test, preds):.2f}\\nRecall = {recall_score(y_test, preds):.2f}\\n')\ncm = confusion_matrix(y_test, preds)\nplt.figure(figsize=(8, 6))\nplt.title('Confusion Matrix', size=16)\nsns.heatmap(cm, annot=True, cmap='Blues');","4b07cd81":"f1_score(y_test, preds, average='macro')","472c927f":"The boxplot shows data distribution of the Duration feature. We can see that there are some outliers depicting negative values of duration i.e. Time which ideally is not possible.","857b3fb7":"LWC is the agency that gives maximum commision to its agents while EPX gives NIL.","1eb7d838":"Singapore tops the list with maximum number of claim request filed. ","c90490ef":"Dropped off negative values of Duration column.","992d6b91":"**Hey there!** \n\nThanks for stopping by and taking a look at this notebook. I would be really grateful if you could spend some time on the notebook and give me some areas of improvement. Looking forward to learning from you. \n\n**Cheers,\nKomal**","45884183":"Scaling is performed to keep the values in range of 0 and 1.","6728c480":"*Dataset has 11 columns and 63326 rows. Out of the 11 columns, Claim is a target variable.*","dd5628c5":"The maximum claim requests have come to the agency called C2B.","2cb153f6":"From the info, we know that there are 4 numerical columns while 7 are categorical.","a824bfab":"A pie chart depicting 15 most popular destinations among travel insured.Here, I have grouped countries which have less than 1090 insurance policies together into others.","b7e6b6da":"The net sales are highest for LWC while lowest for SSI.","d19ae930":"The Gender column has been dropped since majority of its values are null.","90f29c03":"Around 900 people have requested for claim out of total policy holders which is around 1.4%.","feee3e01":"Reordered the columns of the dataset to keep the target column i.e. Claim at the end.","4d3e46da":"The necessary columns have been successfully renamed.","0b4a46fa":"Looking at the dataset, its clear that the data is not linear. Hence, Random Forest Classifier should give some prominent results. ","7c1972c5":"SMOTE is performed to handle imbalance target class by oversampling.","916b1a45":"The above figure shows a histogram depicting the distribution of age. From the graph, the majory of people opting for travel insurance are of the age 35 to 50.","507fe7e8":"The majority of people are insured under EPX agency.","df7632fd":"Sepearting features and target variable into X and y respectively.","602503a7":"The pie chart depicts that majority of travel insured people have opted for Cancellation Plan.","f4322d61":"The majority claim requests are coming from Bronze Plan and Annual Silver Plan.","64c4e866":"Majority of people have got their insurance via Travel Agency.","60c16122":"Majority of people have opted for online mode of insurance distribution channel.","d64b0946":"The entire dataset is split into Training and test dataset.","71ed28a2":"Plotted the corelation coefficient to check the degree of colinearity which each individidual feature have with the output label. Clearly there is no high colinearity among any of the features. ","fbba51c7":"## A good accuracy of 97% and an f1 score of 0.97 is achieved through the model.","76c74c86":"Label encoding is used to transform categorical features.","f95e1883":"All the column names are listed above. Since there is whitespace between the 2 word column names, let's rename the column names to avoid any naming issues."}}