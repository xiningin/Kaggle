{"cell_type":{"c4d5fee3":"code","e2e88430":"code","8938ac9a":"code","ff769d56":"code","7857ff59":"code","001f2cf5":"code","dd3cc7f2":"code","fccf115f":"code","2dbe0d9f":"code","82a9b1f9":"code","7e587849":"code","661fa48e":"code","376f8ad2":"code","5a863937":"code","50d8f487":"markdown","6fe8599c":"markdown"},"source":{"c4d5fee3":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input","e2e88430":"train = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/train.csv')\ntest = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')","8938ac9a":"train.head()","ff769d56":"train['StudyInstanceUID'] = train['StudyInstanceUID'] + '.jpg'","7857ff59":"train.drop('PatientID',axis=1,inplace=True)","001f2cf5":"train.info()","dd3cc7f2":"train_datagen = keras.preprocessing.image.ImageDataGenerator(\n            preprocessing_function=preprocess_input,\n            validation_split=0.3,\n            rotation_range=25,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            horizontal_flip=True,\n            shear_range=0.15,\n            zoom_range=0.1,\n            fill_mode='nearest'\n            )","fccf115f":"test_datagen = keras.preprocessing.image.ImageDataGenerator(\n            preprocessing_function=preprocess_input)","2dbe0d9f":"train_ds = train_datagen.flow_from_dataframe(\n    dataframe=train, directory=\"..\/input\/ranzcr-clip-catheter-line-classification\/train\", \n    x_col=\"StudyInstanceUID\", y_col= test.columns[1:].to_list(),\n    class_mode=\"raw\", target_size=(313,313), batch_size=16, subset = \"training\")\n\nvalid_ds = train_datagen.flow_from_dataframe(\n    dataframe=train, directory=\"..\/input\/ranzcr-clip-catheter-line-classification\/train\", \n    x_col=\"StudyInstanceUID\", y_col=test.columns[1:].to_list(),\n    class_mode= \"raw\", target_size=(313,313), batch_size=16, subset = \"validation\")","82a9b1f9":"'''\ndef get_model():\n    base_model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\n    base_model.trainable = True \n    inputs = keras.layers.Input(shape=(313,313,3))\n    base_m = base_model(inputs)\n    global_avg = keras.layers.GlobalAveragePooling2D()(base_m)\n    batch_norm_1 = keras.layers.BatchNormalization()(global_avg)\n    dense_1 = keras.layers.Dense(128, activation='relu')(batch_norm_1)\n    dropout_1 = keras.layers.Dropout(0.4)(dense_1)\n    batch_norm_2 = keras.layers.BatchNormalization()(dropout_1)\n    dense_2 = keras.layers.Dense(128, activation='relu')(batch_norm_2)\n    dropout_2 = keras.layers.Dropout(0.4)(dense_2)\n    batch_norm_3 = keras.layers.BatchNormalization()(dropout_2)\n    dense_3 = keras.layers.Dense(64, activation='relu')(batch_norm_3)\n    dropout_3 = keras.layers.Dropout(rate=0.4)(dense_3)\n    predictions = keras.layers.Dense(11, activation='sigmoid')(dropout_3)\n    \n    model = keras.Model(inputs=inputs, outputs=predictions)\n    model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=['acc'])\n    \n    return model\n    \nmodel = get_model()\nmodel.summary()\n'''","7e587849":"model = keras.models.load_model('..\/input\/imagedatagen\/Best_Model.h5')","661fa48e":"checkpoint = keras.callbacks.ModelCheckpoint('.\/Best_Model.h5', \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode= 'min', \n                             save_weights_only = False)","376f8ad2":"history = model.fit(train_ds, \n                    validation_data = valid_ds,\n                    validation_steps = valid_ds.n\/\/valid_ds.batch_size,\n                    epochs = 20, \n                    callbacks = checkpoint,\n                    steps_per_epoch = train_ds.n\/\/train_ds.batch_size\n                   )","5a863937":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","50d8f487":"# Warning\n## This process is very very time consuming, use tf.data for faster data pipelines.","6fe8599c":"### First I trained 10 epochs with the above model and saved it. I again loaded it and trained. "}}