{"cell_type":{"25a947a6":"code","e15a6bfa":"code","c9df33ff":"code","480f0c70":"code","84f01ecd":"code","b2ea0d9f":"code","bd25abb1":"code","4ccd1b01":"code","b8b934f0":"code","32271476":"code","8f8ed314":"code","e90b72aa":"code","97ac2464":"code","3ee1cb03":"code","72fe1102":"code","e43d60c4":"code","c13c0c5d":"code","fce71425":"code","8c1a0e89":"code","f33650e4":"code","e0c283f1":"code","624b05a8":"code","ee2c4ad1":"code","773bdfd0":"code","e63e2e01":"code","3dd61026":"code","d8381150":"code","8b0e4123":"code","1c5522d2":"code","6471fc55":"code","66f54daf":"markdown","a5f8ac40":"markdown","51760988":"markdown","0b7faccd":"markdown"},"source":{"25a947a6":"# Data preprocessing\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport glob\n\n# Deep learning\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Conv3D, MaxPooling3D,GlobalAveragePooling3D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing import image\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e15a6bfa":"DATASET_DIR = \"..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\"\n\nos.listdir(DATASET_DIR)","c9df33ff":"normal_images = []\ncount = 0\n\nfor img_path in glob.glob(DATASET_DIR + \"\/Normal\/*\"):\n    count += 1\n    normal_images.append(image.load_img(str(img_path), target_size = (150,150,3)))\n    if count > 230:\n        break\n    \nfig = plt.figure()\nfig.suptitle(\"Normal Lungs\")\nplt.imshow(normal_images[0], cmap=\"gray\")\nplt.show()","480f0c70":"covid_images = []\nfor img_path in glob.glob(DATASET_DIR + \"\/COVID\/*\"): \n    covid_images.append(image.load_img(str(img_path), target_size = (150,150,3)))\n    \nfig = plt.figure()\nfig.suptitle(\"Covid-19 Patient's Lungs \")\nplt.imshow(covid_images[0], cmap = \"gray\")\nplt.show()","84f01ecd":"covid_images[0]","b2ea0d9f":"print(str(len(normal_images))+\" normal patient images\")\nprint(str(len(covid_images))+\" covid patient images\")","bd25abb1":"images_together = []\n\nfor i in normal_images:\n    images_together.append(img_to_array(i))\n    \nfor i in covid_images:\n    images_together.append(img_to_array(i))\n    \ntargets = np.zeros(len(images_together))\ntargets[:len(normal_images)-1] = 1 # normal-> 1, covid-19-> 0","4ccd1b01":"images_together[55].shape","b8b934f0":"print(\"image list length: \",len(images_together))\nprint(\"target list length: \",len(targets))","32271476":"targets = np.array(targets)\nprint(\"targets: \",targets.shape)\ntargets = targets.reshape(-1,1)\nprint(\"new shape of targets: \",targets.shape)","8f8ed314":"images_together = np.array(images_together)\nprint(\"shape of images together: \",images_together.shape)","e90b72aa":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(images_together, targets, test_size=0.25, stratify=targets)\n\nimages_together = np.concatenate((X_train, X_val))\ntargets = np.concatenate((y_train, y_val))","97ac2464":"IMG_W = 150\nIMG_H = 150\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 32\nBATCH_SIZE = 40","3ee1cb03":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = INPUT_SHAPE, activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 48, kernel_size = (3,3), activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\"))\n\nmodel.add(Dense(1, activation='linear'))\nmodel.compile(loss='mse', optimizer='adam')\n\nmodel.add(MaxPool2D(pool_size = (2,2), strides = (1,1)))\nmodel.add(Dropout(0.25))\n\n#fully connected\nmodel.add(Flatten())\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\n# compile \nmodel.compile(loss = \"binary_crossentropy\",\n             optimizer = \"rmsprop\",\n             metrics = [\"accuracy\"])","72fe1102":"model.summary()","e43d60c4":"#print(train_generator[0])","c13c0c5d":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  shear_range = 0.2,\n                                  zoom_range = 0.2,\n                                  horizontal_flip = True,\n                                  validation_split = 0.25)\n\n\ntrain_generator = train_datagen.flow(\nimages_together, targets,\nbatch_size = BATCH_SIZE,\nsubset = \"training\")\n\nvalidation_generator = train_datagen.flow(\nimages_together, targets,\nbatch_size = BATCH_SIZE,\nshuffle = False,\nsubset = \"validation\")\n\n#fitting\n# use model.fit insted of model.fit_generator\n#`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\nhist = model.fit(\ntrain_generator,\nsteps_per_epoch = (450*0.75)\/\/BATCH_SIZE,\nvalidation_data = validation_generator,\nvalidation_steps = (450*0.25)\/\/ BATCH_SIZE,\nepochs = EPOCHS)","fce71425":"plt.figure(figsize = (13,7))\nplt.plot(hist.history[\"accuracy\"])\nplt.plot(hist.history[\"val_accuracy\"])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Test\"], loc = \"upper left\")\n#plt.text(23,0.5,\"Current Training Accuracy: \"+str(np.round(hist.history[\"accuracy\"][-1]*100,2))+\"%\",fontsize = 18,color = \"black\")\n#plt.text(23,0.46,\"Current Validation Accuracy: \"+str(np.round(hist.history[\"val_accuracy\"][-1]*100,2))+\"%\",fontsize = 18,color = \"black\")\nplt.show()","8c1a0e89":"plt.figure(figsize = (13,7))\nplt.plot(hist.history[\"loss\"])\nplt.plot(hist.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Test\"], loc = \"upper right\")\n#plt.text(26,0.8,\"Current Training Loss: \"+str(np.round(hist.history[\"loss\"][-1],3)),fontsize = 18,color = \"black\")\n#plt.text(26,0.73,\"Current Validation Loss: \"+str(np.round(hist.history[\"val_loss\"][-1],3)),fontsize = 18,color = \"black\")\nplt.show()","f33650e4":"print(\"Training Accuracy: \"+str(np.round(hist.history[\"accuracy\"][-1]*100,2))+\"%\")\nprint(\"Validation Accuracy: \"+str(np.round(hist.history[\"val_accuracy\"][-1]*100,2))+\"%\")","e0c283f1":"model.save(\"cnn_covid_x-ray_v1.h5\")","624b05a8":"from tensorflow.keras.models import Sequential, save_model, load_model","ee2c4ad1":"filepath = (\".\/cnn_covid_x-ray_v1.h5\")","773bdfd0":"model = load_model(filepath, compile = True)\n","e63e2e01":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","3dd61026":"imagePath= (\"..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal\/Normal-1.png\")","d8381150":"from keras.preprocessing import image\n\ntest_image = image.load_img(imagePath, target_size = (155,155)) \ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\n\n#predict the result\nresult = model.predict(test_image)","8b0e4123":"p = model.predict(X_train)\n","1c5522d2":"print(p)","6471fc55":"classes = np.argmax(p, axis = 1)\nclasses","66f54daf":"<a id=\"2\"><\/a> <br>\n# Preparing Data for CNN","a5f8ac40":"<a id=\"3.1\"><\/a> <br>\n## Results","51760988":"<a id=\"3\"><\/a> <br>\n# CNN Model","0b7faccd":"<a id=\"1\"><\/a> <br>\n# Imports and Dataset"}}