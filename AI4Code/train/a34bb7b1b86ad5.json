{"cell_type":{"e7f82cda":"code","91029072":"code","fa4790ad":"code","07650609":"code","ca140c29":"code","6440c632":"code","54b7c527":"code","e69a5cef":"code","fe2a4ae6":"code","5f41637d":"code","4a3b6a2b":"code","9368cbf1":"code","ec99a8c8":"markdown","302ec0fd":"markdown","060f8a17":"markdown","38d5a2ef":"markdown","f7a621d9":"markdown"},"source":{"e7f82cda":"import os \nimport zipfile \nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model \nimport matplotlib.pyplot as plt\nimport random\nfrom shutil import copyfile\nimport random\nimport tensorflow as tf\nBATCH_SIZE = 10\n!pip install efficientnet\nimport efficientnet.tfkeras as efn\nNUM_CLASSES = 8\ndim = 256\ntrain_dir = \".\/train\"\nvalidation_dir = \".\/test\"\n","91029072":"def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = SOURCE + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + \" is zero length, so ignoring.\")\n\n    training_length = int(len(files) * SPLIT_SIZE)\n    testing_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[0:training_length]\n    testing_set = shuffled_set[training_length:]\n\n    for filename in training_set:\n        this_file = SOURCE + filename\n        destination = TRAINING + filename\n        copyfile(this_file, destination)\n\n    for filename in testing_set:\n        this_file = SOURCE + filename\n        destination = TESTING + filename\n        copyfile(this_file, destination)\n\n        ","fa4790ad":"os.mkdir(\".\/train\")\nos.mkdir(\".\/test\")\nfor i in ['amusement','anger','awe','contentment','disgust','excitement','fear','sadness']:\n    os.mkdir(os.path.join(\".\/train\",i))\n    os.mkdir(os.path.join(\".\/test\",i))","07650609":"split_size = .9\ninput_data = \"..\/input\/cleaned-emotion-dataset-aaai16\/emotion_dataset\"\nfor i in ['amusement\/','anger\/','awe\/','contentment\/','disgust\/','excitement\/','fear\/','sadness\/']:\n    split_data(os.path.join(input_data,i),os.path.join(\".\/train\",i), \n               os.path.join(\".\/test\",i), split_size)\n    ","ca140c29":"!mv -v .\/test\/excitement\/* .\/test\/amusement\/\n!mv -v .\/test\/contentment\/* .\/test\/amusement\/\n!mv -v .\/test\/disgust\/* .\/test\/fear\/\n!mv -v .\/train\/excitement\/* .\/train\/amusement\/\n!mv -v .\/train\/contentment\/* .\/train\/amusement\/\n!mv -v .\/train\/disgust\/* .\/train\/fear\/\n!rm -rf .\/train\/contentment\n!rm -rf .\/train\/excitement\n!rm -rf .\/test\/excitement\n!rm -rf .\/test\/contentment\n!rm -rf .\/train\/disgust\n!rm -rf .\/test\/disgust\n","6440c632":"# !ls .\/train\/amusement","54b7c527":"DEVICE = \"GPU\"\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","e69a5cef":"BATCH_SIZE = 10\ndim = 256\ntrain_dir = \".\/train\"\nvalidation_dir = \".\/test\"\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen  = ImageDataGenerator(rescale = 1.\/255) \n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0\/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir, batch_size = BATCH_SIZE, class_mode = 'categorical', target_size = (dim, dim))\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory( validation_dir,  batch_size = BATCH_SIZE, class_mode = 'categorical', target_size = (dim,dim ))","fe2a4ae6":"from keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import RMSprop\nimport keras\nimport pandas as pd\nimport numpy as np\nfrom keras import Sequential\nfrom keras_preprocessing.image import load_img, img_to_array\nfrom keras.layers import Dense,BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport efficientnet.tfkeras as efn\nimport os\nimport random\nfrom shutil import copyfile","5f41637d":"\nimport keras\nDEVICE = \"GPU\"\ndef get_model():\n    model_input = keras.Input(shape=(dim,dim, 3), name='imgIn')\n\n    # dummy = keras.layers.Lambda(lambda x: x)(model_input)\n\n    baseline = efn.EfficientNetB7(include_top=False,\n                               weights='noisy-student',\n                               input_shape=(dim, dim, 3))\n\n    x = baseline(model_input)\n#     x = (x)\n    print(x.shape)\n    out = keras.models.Sequential([\n#         keras.layers.Conv2D(filters=3000, kernel_size=2,padding = \"same\"),\n        keras.layers.Flatten(),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(NUM_CLASSES*10, activation='relu'),\n        keras.layers.BatchNormalization(),\n#         keras.layers.Dropout(0.2),\n        keras.layers.Dense(NUM_CLASSES, activation='softmax')])(x)\n        \n    \n    model = keras.Model(model_input, out, name='aNetwork')\n    model.get_layer(\"efficientnet-b7\").trainable = False\n    model.summary()\n    return model\n\n# learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5,\n#                                                     min_lr=0.00001)\nif DEVICE ==\"TPU\":\n    with strategy.scope():\n        model = get_model()\n        filepath=\"test2142214-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,\n        mode='max')\n        callbacks_list = [checkpoint]\n        model.compile(optimizer=RMSprop(lr=0.0001),\n                  loss='categorical_crossentropy',\n                  metrics=['acc'])\n#         model.fit(train_generator,validation_data=validation_generator,epochs = 10,batch_size = BATCH_SIZE,callbacks=callbacks_list)\nelse:\n    model = get_model()\n    filepath=\"{val_acc:.4f}-test2152312-weights-improvement-{epoch:02d}.hdf5\"\n    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=False,mode='max')\n    callbacks_list = [checkpoint]\n    model.compile(optimizer=RMSprop(lr=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n#     model = keras.models.load_model('my_model.h5')\n#     model.fit(train_generator,validation_data=validation_generator,epochs = 20,batch_size = BATCH_SIZE,callbacks=callbacks_list,shuffle=True)\n","4a3b6a2b":"label_map = (train_generator.class_indices)\nval_label_map = (validation_generator.class_indices)\nprint(label_map)\nprint(val_label_map)","9368cbf1":"NUM_CLASSES = 5\nfrom keras.models import save_model\ndef get_model2():\n    model_input = keras.Input(shape=(dim,dim, 3), name='imgIn')\n\n    # dummy = keras.layers.Lambda(lambda x: x)(model_input)\n\n    baseline = efn.EfficientNetB7(include_top=False,\n                               weights='noisy-student',\n                               input_shape=(dim, dim, 3))\n\n    x = baseline(model_input)\n#     x = (x)\n    print(x.shape)\n    out = keras.models.Sequential([\n#         keras.layers.Conv2D(filters=3000, kernel_size=2,padding = \"same\"),\n        keras.layers.Flatten(),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(NUM_CLASSES*10, activation='relu'),\n        keras.layers.BatchNormalization(),\n#         keras.layers.Dropout(0.2),\n        keras.layers.Dense(NUM_CLASSES, activation='softmax')])(x)\n        \n    \n    model = keras.Model(model_input, out, name='aNetwork')\n    model.get_layer(\"efficientnet-b7\").trainable = False\n    model.summary()\n    return model\n\n\nmodel = get_model2()\nfilepath=\"FiveClass-MODEL2-{val_acc:.4f}-test2162147-weights-improvement-{epoch:02d}.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=False,mode='max')\ncallbacks_list = [checkpoint]\nmodel.compile(optimizer=RMSprop(lr=0.0001),\n          loss='categorical_crossentropy',\n          metrics=['acc'])\n#     model = keras.models.load_model('my_model.h5')\nmodel.fit(train_generator,validation_data=validation_generator,epochs = 4,batch_size = BATCH_SIZE,callbacks=callbacks_list,shuffle=True)\nmodel.save(\".\\6epochmode.h5\")\n","ec99a8c8":"The code quality and readability will be improved soon. Hopefully you find it is useful! Some are written in Chinese and I will add English translation soon.","302ec0fd":"### The pipline \n1. Preprocess Image(Can be omitted)\n2. load pretrained model and do classfication. Useful model: resnet50, EfficientNet\n\n(in Chinese)\n1. \u9884\u5904\u7406\u56fe\u50cf(\u53ef\u4ee5\u7701\u7565)\n2. \u8f7d\u5165\u4e0e\u8bad\u7ec3\u7684model\uff0c\u8fdb\u884c\u5206\u7c7b\uff0c\u9664\u4e86Resnet50\u8fd8\u6709\u5176\u4ed6\u4e0d\u9519\u7684model\uff0c\u8fd9\u91cc\u9009\u7528Kaggle\u6d41\u884c\u7684EfficientNet\n\n#### \u8fd9\u91cc\u89e3\u91ca\u4e00\u4e0b\u5173\u4e8eexpand_dim\u548cpreprocess_input\u7684\u4f5c\u7528(notebook\u5c3e\u90e8\u6709\u66f4\u8be6\u7ec6\u7684\u89e3\u91ca)\n\u7b80\u5355\u800c\u8a00\uff0cexpand dim\u53ef\u4ee5\u589e\u52a0\u4e00\u4e2abatch\u7ef4\u5ea6\uff0cpreprocess_input\u53ef\u4ee5\u5f52\u4e00\u5316\u7b49\n```\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input\nimport numpy as np\n\nmodel = ResNet50(weights='imagenet')\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n```\n# pytorch Version\n```\nimport torchvision.models as models\ninception = models.inception_v3(pretrained=True)\n```","060f8a17":"## This notebook deals with the emotion classification task using tranfer learning","38d5a2ef":"## get_model\u548cget_model2\u6240\u83b7\u5f97\u7684\u6a21\u578b\u5341\u5206\u76f8\u4f3c\uff0c\u4f46\u662fget_model\u8fd4\u56de\u7684\u6a21\u578b\u51bb\u7ed3\u4e86efficientnet\u7684\u8bad\u7ec3","f7a621d9":"## Download data"}}