{"cell_type":{"78c3d13f":"code","61179707":"code","2a8341f4":"code","eb6c2f3e":"code","05e1d89a":"code","d0d9c50f":"code","182f2aad":"code","faf0ca62":"code","d0212177":"code","05284936":"code","eed75302":"code","d029ff9a":"code","75926b41":"code","80d9ab37":"code","8426d79b":"code","2f1f4bfb":"code","787e0f00":"code","4fd9d338":"code","fd2d42cc":"code","0a8d2b7b":"code","99e17774":"code","a58997be":"code","e3472152":"code","a41d9d78":"code","1202f169":"code","d8ef045f":"code","2cbf0c7d":"code","983cb9f7":"code","27c42407":"code","56266465":"code","91fcc2c8":"code","d98ea1d2":"code","824388b5":"code","e9453074":"code","6b42a4a3":"code","3157fa34":"markdown","6f973a25":"markdown","4c05a6ab":"markdown","1eeb9176":"markdown","e06476b4":"markdown","d2de8b9a":"markdown","f3dadf5b":"markdown","2b47bb45":"markdown","5208ca39":"markdown","94db4666":"markdown","03161cc9":"markdown","11b9b2d0":"markdown","06e594ea":"markdown","dca96c1a":"markdown","d0d61e4b":"markdown"},"source":{"78c3d13f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61179707":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nimport scikitplot as skplt\nimport time\nimport torch.nn.functional as F \nimport torch.optim as optim\nfrom torch.autograd import Variable","2a8341f4":"train = pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","eb6c2f3e":"train.head()","05e1d89a":"test.head()","d0d9c50f":"train.shape","182f2aad":"test.shape","faf0ca62":"train.describe()","d0212177":"test.describe()","05284936":"label_counts  = train[\"label\"].value_counts().sort_index()\nlabel_counts.plot.bar()","eed75302":"train['label'].nunique()","d029ff9a":"train_fe=train.iloc[:,1:]  # neglecting the label column\ntrain_lab=train['label']  # taking the labels column\n\ntest_fe=test.iloc[:,1:]  # neglecting the label column\ntest_lab=test['label']  # taking the labels column\n# converting to numpy 1d array\n\ntrain_fe_numpy = train_fe.to_numpy()\ntrain_lab_numpy = train_lab.to_numpy()\ntest_fe_numpy = test_fe.to_numpy()\ntest_lab_numpy=test_lab.to_numpy()","75926b41":"train_fe.head()","80d9ab37":"train_fe.iloc[0]","8426d79b":"def plot_img(data, label):\n    fig, axs = plt.subplots(2,2)\n    k = 0\n    for i in range(2):\n        for j in range(2):        \n            axs[i, j].imshow(data[k].reshape(28, 28))            \n            axs[i, j].set_ylabel(\"label:\" + str(label[k].item()))   \n            k +=4","2f1f4bfb":"plot_img(train_fe_numpy, train_lab_numpy)","787e0f00":"signs = {'0': 'A', '1': 'B', '2': 'C', '3': 'D', '4': 'E', '5': 'F', \n         '6': 'G', '7': 'H', '8': 'I', '10': 'K', '11': 'L', '12': 'M', \n         '13': 'N', '14': 'O', '15': 'P', '16': 'Q', '17': 'R', '18': 'S', \n         '19': 'T', '20': 'U', '21': 'V', '22': 'W', '23': 'X', '24': 'Y','25':'Z'}","4fd9d338":"reshaped_train = []\nfor i in train_fe_numpy:\n#     print(i)\n    reshaped_train.append(i.reshape(1, 28, 28))\ntrain_data = np.array(reshaped_train)\n\nreshaped_test = []\nfor i in test_fe_numpy:\n    reshaped_test.append(i.reshape(1,28,28))\ntest_data = np.array(reshaped_test)","fd2d42cc":"# train_data","0a8d2b7b":"train1,test1,train_label,test_label=train_test_split(train_fe_numpy,train_lab_numpy, test_size=0.2,random_state=42)","99e17774":"print(train1.shape)\nprint(train_label.shape)\nprint(test1.shape)\nprint(test_label.shape)","a58997be":"train_tensor = torch.as_tensor(train1).type(torch.FloatTensor)\ntrain_label = torch.as_tensor(train_label)\n\ntest_tensor = torch.as_tensor(test1).type(torch.FloatTensor)\ntest_label = torch.as_tensor(test_label)","e3472152":"class Convnet(nn.Module):\n    \n    def __init__(self):\n        super(Convnet, self).__init__()\n        \n        \n        self.conv1=nn.Conv2d(1,50,kernel_size=5)\n        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n         # L1 ImgIn shape=(?, 28, 28, 1)      # (n-f+2*p\/s)+1\n        #    Conv     -> (?, 24, 24, 50)\n        #    Pool     -> (?, 12, 12, 50)\n        \n        \n        self.conv2 = nn.Conv2d(50,60, kernel_size = 5)\n        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n        # L2 ImgIn shape=(?, 12, 12, 50)\n        #    Conv      ->(?, 8, 8, 60)\n        #    Pool      ->(?, 4, 4, 60)\n        \n        \n        self.conv3 = nn.Conv2d(60, 80,  kernel_size = 3)\n        # L3 ImgIn shape=(?, 4, 4, 60)\n        #    Conv      ->(?, 2, 2, 80)\n       \n        \n        \n        self.batch_norm1 = nn.BatchNorm2d(50)\n        self.batch_norm2 = nn.BatchNorm2d(60)\n        \n#         self.dropout1 = nn.Dropout2d()\n        \n        # L4 FC 2*2*80 inputs -> 250 outputs\n        self.fc1 = nn.Linear(80*2*2, 250) \n        self.fc2 = nn.Linear(250, 25)\n        \n        \n    def forward(self,x):\n        x=self.conv1(x)\n        x = self.batch_norm1(x)\n        x=F.relu(x)\n        x=self.pool1(x)\n        \n        x=self.conv2(x)\n        x = self.batch_norm2(x)\n        x=F.relu(x)\n        x=self.pool2(x)\n        \n        x=self.conv3(x)\n        x=F.relu(x)\n        \n        x = x.view(-1,80*2*2)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        x = F.log_softmax(x, dim=1)\n        \n        return x     ","a41d9d78":"net=Convnet()\n\nnet.eval()  ","1202f169":"def get_accuracy(predictions, true_labels):\n    _, predicted = torch.max(predictions, 1)\n    corrects = (predicted == true_labels).sum()\n    accuracy = 100.0 * corrects\/len(true_labels)\n    return accuracy.item()","d8ef045f":"def training(loader,model,epochs,criteria,optimizer):\n    \n    tr_accuracy,tr_loss= [], []\n    \n    model.train()\n   \n    \n    for epoch in range(epochs):\n        \n        train_loss = 0 \n        train_accuracy = 0\n        total_batch = 0\n        \n        t0=time.time()\n        for data,labels in loader:\n             # zero the parameters gradient to not accumulate gradients from previous iteration\n            optimizer.zero_grad()\n            \n            \n#             print(data.shape)\n#             print(labels.shape)\n#             put data into the model\n#             model(data.permute(50,5,5,1))\n#             data=data.reshape(50,60,5,5)\n            predictions = net(data)\n            \n            # calculating loss\n            loss = criterion(predictions, labels)\n            \n            # calculating accuracy\n            accuracy = get_accuracy(predictions, labels)\n            \n            # computing gradients\n            loss.backward()\n            \n            # changing the weights\n            optimizer.step()\n            \n            total_batch+=1\n            train_loss += loss.item()\n            train_accuracy += accuracy\n            \n        tfin= time.time()-t0   \n        acc=train_accuracy\/total_batch  \n        loss=train_loss\/total_batch\n        tr_accuracy.append(acc)\n        tr_loss.append(loss)\n        \n        print(\"Epoch {}\/{}\".format(epoch+1,epochs),\"Training Loss: {}\".format(loss),\"Training Accuracy: {}\".format(acc),\"Time: {} seconds\".format(tfin))\n        \n    return tr_accuracy, tr_loss   ","2cbf0c7d":"train_tensor.shape","983cb9f7":"train_tensor=train_tensor.reshape(21964,1,28,28) \/ 255","27c42407":"train_tensor.shape","56266465":"!pip install torchsummary\nfrom torchsummary import summary","91fcc2c8":"train_dataset = torch.utils.data.TensorDataset(train_tensor, train_label)\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size =50, shuffle = True)\n\nepochs = 30                                              # setting number of epochs\n\nnet = Convnet()                                          # initializing the  network\ncriterion = nn.CrossEntropyLoss()                        # setting criterion\noptimizer = torch.optim.SGD(net.parameters(), lr = 3e-4) # setting optimizer\n\ntr_acc, tr_loss = training(trainloader, net,epochs, criterion, optimizer)","d98ea1d2":"torch.save(net, 'model_trained.pt')","824388b5":"test_tensor.shape","e9453074":"test_tensor=test_tensor.reshape(5491,1,28,28) \/ 255","6b42a4a3":"val_pred = net(test_tensor)\nval_loss = criterion(val_pred, test_label)\nval_accuracy = get_accuracy(val_pred, test_label)\n \nprint(\"Loss: \", (val_loss.item()), \"Accuracy: \", (val_accuracy))\n\n# to get class with the maximum score as prediction\n_, val_predicted = torch.max(val_pred.data,1)            \n\nskplt.metrics.plot_confusion_matrix(test_label, val_predicted, figsize=(20,20))","3157fa34":"# Convolution Neural Network Architecture:->","6f973a25":"# These are the signs represented by labels:-","4c05a6ab":"# So we saw that all the predictions are class balanced..","1eeb9176":"# So Converting to 2D Format:-","e06476b4":"# The Input shape of a Pytorch CNN Model is (Number of Batch,Number of Channels,Height of an Image,Width of an Image).\n# So Reshaping :->","d2de8b9a":"# Function For Training:->","f3dadf5b":"# Saving the model for Future Use :->","2b47bb45":"# Checking The Accuracy of Test Data:->","5208ca39":"# Training:->","94db4666":"# Function For Getting Accuracy:->","03161cc9":"# The dataset consists of 1D arrays for each image. If we want it to work correctly with CNN, we will need to reshape it into a 2D format. In this specific case, we have 784 pixels of each image that can be reshaped to 28*28.","11b9b2d0":"# To use Pytorch we must convert the input vectors to tensors from numpy..","06e594ea":"# Splitting the Dataset:->","dca96c1a":"# Training Process:-->\n* Do a forward pass\n* Calculate loss function\n* Calculate the gradients\n* Change the weights based on gradients","d0d61e4b":"# Visualising some training examples with it's labels:-->"}}