{"cell_type":{"589feedf":"code","0e952446":"code","16d5346d":"code","49fad89f":"code","ebdcccf0":"code","4a216eef":"code","fc14d94f":"code","77e5d1bb":"code","ad18028f":"code","232c9b77":"code","79bd2fc8":"code","7a600f25":"code","7574ddd5":"code","78205eaa":"code","a7da050c":"code","fbcc2c65":"code","91bdacbd":"code","6df99d67":"code","a8768430":"code","a5b15551":"code","cfd8d8c7":"code","7954c8ff":"code","f8bbf0ad":"code","733a8155":"code","ea9d81f2":"code","e75f4ed2":"code","ffb75ac1":"code","cca40601":"code","f27e6b6f":"code","31879296":"code","77724aab":"code","5cf6bd8a":"code","fbb98e64":"code","d9623203":"code","8103fa90":"code","b05be593":"code","951e6ee5":"code","6af4456d":"code","ac13e1de":"code","45f2f458":"code","f425481c":"code","fb52fcb3":"code","47d6dca9":"code","7d176bce":"markdown","bfd94335":"markdown","92205f91":"markdown","b83c4eed":"markdown","3dadbfcf":"markdown","85dcbd90":"markdown","9f4a69b3":"markdown","0b4cd3a3":"markdown","7c1f39c0":"markdown","bd5fe91f":"markdown","e96f4ba0":"markdown","4e5e4b1b":"markdown","138a773e":"markdown","a019c200":"markdown","c745ceea":"markdown","1a4b3173":"markdown","848c6eab":"markdown","cfbdf17a":"markdown","ae3ec55e":"markdown","957e90e7":"markdown","6dd38f14":"markdown","28a42beb":"markdown","92a6c2c0":"markdown","5c979976":"markdown","20d769a5":"markdown","a223e504":"markdown","da502bb8":"markdown","92fafc8d":"markdown","73f3f5b9":"markdown","efb250f4":"markdown","b3824755":"markdown","0c5df9a2":"markdown","527a5363":"markdown","64db6ba3":"markdown","0cf515a8":"markdown"},"source":{"589feedf":"import pandas as pd;\nimport matplotlib.pyplot as plt\nfrom numpy import array\nfrom numpy import hstack\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import RNN, SimpleRNN\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nfrom keras.layers.core import Activation\nfrom keras.callbacks import LambdaCallback\nfrom sklearn.preprocessing import MinMaxScaler","0e952446":"import os\nprint(os.listdir(\"..\/input\/bike-sharing-dataset\"))\ndataset = pd.read_csv('..\/input\/bike-sharing-dataset\/day.csv')","16d5346d":"dataset.head()","49fad89f":"plt.figure(figsize=(15,10))\nplt.plot(dataset['cnt'], color='blue')\nplt.show()","ebdcccf0":"temp = dataset[dataset.yr == 1]\ntemp = temp[temp.mnth == 10]\nprint(temp.cnt.mean())","4a216eef":"temp.head()","fc14d94f":"print(dataset['cnt'][667], dataset['cnt'][668])","77e5d1bb":"dataset['cnt'][667] = 6414\ndataset['cnt'][668] = 6414","ad18028f":"one_hot = pd.get_dummies(dataset['weekday'], prefix='weekday')\ndataset = dataset.join(one_hot)","232c9b77":"one_hot = pd.get_dummies(dataset['weathersit'], prefix='weathersit')\ndataset = dataset.join(one_hot)","79bd2fc8":"one_hot = pd.get_dummies(dataset['mnth'], prefix='mnth')\ndataset = dataset.join(one_hot)","7a600f25":"scaler = MinMaxScaler(feature_range=(0, 1))\nscaled = scaler.fit_transform(array(dataset['cnt']).reshape(len(dataset['cnt']), 1))\nseries = pd.DataFrame(scaled)\nseries.columns = ['cntscl']","7574ddd5":"dataset = pd.merge(dataset, series, left_index=True, right_index=True)","78205eaa":"dataset.head()","a7da050c":"number_of_test_data = 50\nnumber_of_holdout_data = 50\nnumber_of_training_data = len(dataset) - number_of_holdout_data - number_of_test_data\nprint (\"total, train, test, holdout:\", len(dataset), number_of_training_data, number_of_test_data, number_of_holdout_data)","fbcc2c65":"datatrain = dataset[:number_of_training_data]\ndatatest = dataset[-(number_of_test_data+number_of_holdout_data):-number_of_holdout_data]\ndatahold = dataset[-number_of_holdout_data:]","91bdacbd":"in_seq1 = array(datatrain['holiday'])\nin_seq2 = array(datatrain['workingday'])\nin_seq3 = array(datatrain['temp'])\nin_seq4 = array(datatrain['atemp'])\nin_seq5 = array(datatrain['hum'])\nin_seq6 = array(datatrain['windspeed'])\nin_seq7 = array(datatrain['weekday_0'])\nin_seq8 = array(datatrain['weekday_1'])\nin_seq9 = array(datatrain['weekday_2'])\nin_seq10 = array(datatrain['weekday_3'])\nin_seq11 = array(datatrain['weekday_4'])\nin_seq12 = array(datatrain['weekday_5'])\nin_seq13 = array(datatrain['weekday_6'])\nin_seq14 = array(datatrain['weathersit_1'])\nin_seq15 = array(datatrain['weathersit_2'])\nin_seq16 = array(datatrain['weathersit_3'])\nout_seq_train = array(datatrain['cntscl'])","6df99d67":"in_seq1 = in_seq1.reshape((len(in_seq1), 1))\nin_seq2 = in_seq2.reshape((len(in_seq2), 1))\nin_seq3 = in_seq3.reshape((len(in_seq3), 1))\nin_seq4 = in_seq4.reshape((len(in_seq4), 1))\nin_seq5 = in_seq5.reshape((len(in_seq5), 1))\nin_seq6 = in_seq6.reshape((len(in_seq6), 1))\nin_seq7 = in_seq7.reshape((len(in_seq7), 1))\nin_seq8 = in_seq8.reshape((len(in_seq8), 1))\nin_seq9 = in_seq9.reshape((len(in_seq9), 1))\nin_seq10 = in_seq10.reshape((len(in_seq10), 1))\nin_seq11 = in_seq11.reshape((len(in_seq11), 1))\nin_seq12 = in_seq12.reshape((len(in_seq12), 1))\nin_seq13 = in_seq13.reshape((len(in_seq13), 1))\nin_seq14 = in_seq14.reshape((len(in_seq14), 1))\nin_seq15 = in_seq15.reshape((len(in_seq15), 1))\nin_seq16 = in_seq16.reshape((len(in_seq16), 1))\nout_seq_train = out_seq_train.reshape((len(out_seq_train), 1))","a8768430":"datatrain_feed = hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5, in_seq6, in_seq7, in_seq8, in_seq9, in_seq10, in_seq11, in_seq12, in_seq13, in_seq14, in_seq15, in_seq16, out_seq_train))","a5b15551":"in_seq1 = array(datatest['holiday'])\nin_seq2 = array(datatest['workingday'])\nin_seq3 = array(datatest['temp'])\nin_seq4 = array(datatest['atemp'])\nin_seq5 = array(datatest['hum'])\nin_seq6 = array(datatest['windspeed'])\nin_seq7 = array(datatest['weekday_0'])\nin_seq8 = array(datatest['weekday_1'])\nin_seq9 = array(datatest['weekday_2'])\nin_seq10 = array(datatest['weekday_3'])\nin_seq11 = array(datatest['weekday_4'])\nin_seq12 = array(datatest['weekday_5'])\nin_seq13 = array(datatest['weekday_6'])\nin_seq14 = array(datatest['weathersit_1'])\nin_seq15 = array(datatest['weathersit_2'])\nin_seq16 = array(datatest['weathersit_3'])\nout_seq_test = array(datatest['cntscl'])","cfd8d8c7":"in_seq1 = in_seq1.reshape((len(in_seq1), 1))\nin_seq2 = in_seq2.reshape((len(in_seq2), 1))\nin_seq3 = in_seq3.reshape((len(in_seq3), 1))\nin_seq4 = in_seq4.reshape((len(in_seq4), 1))\nin_seq5 = in_seq5.reshape((len(in_seq5), 1))\nin_seq6 = in_seq6.reshape((len(in_seq6), 1))\nin_seq7 = in_seq7.reshape((len(in_seq7), 1))\nin_seq8 = in_seq8.reshape((len(in_seq8), 1))\nin_seq9 = in_seq9.reshape((len(in_seq9), 1))\nin_seq10 = in_seq10.reshape((len(in_seq10), 1))\nin_seq11 = in_seq11.reshape((len(in_seq11), 1))\nin_seq12 = in_seq12.reshape((len(in_seq12), 1))\nin_seq13 = in_seq13.reshape((len(in_seq13), 1))\nin_seq14 = in_seq14.reshape((len(in_seq14), 1))\nin_seq15 = in_seq15.reshape((len(in_seq15), 1))\nin_seq16 = in_seq16.reshape((len(in_seq16), 1))\nout_seq_test = out_seq_test.reshape((len(out_seq_test), 1))","7954c8ff":"datatest_feed = hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5, in_seq6, in_seq7, in_seq8, in_seq9, in_seq10, in_seq11, in_seq12, in_seq13, in_seq14, in_seq15, in_seq16, out_seq_test))","f8bbf0ad":"in_seq1 = array(datahold['holiday'])\nin_seq2 = array(datahold['workingday'])\nin_seq3 = array(datahold['temp'])\nin_seq4 = array(datahold['atemp'])\nin_seq5 = array(datahold['hum'])\nin_seq6 = array(datahold['windspeed'])\nin_seq7 = array(datahold['weekday_0'])\nin_seq8 = array(datahold['weekday_1'])\nin_seq9 = array(datahold['weekday_2'])\nin_seq10 = array(datahold['weekday_3'])\nin_seq11 = array(datahold['weekday_4'])\nin_seq12 = array(datahold['weekday_5'])\nin_seq13 = array(datahold['weekday_6'])\nin_seq14 = array(datahold['weathersit_1'])\nin_seq15 = array(datahold['weathersit_2'])\nin_seq16 = array(datahold['weathersit_3'])\nout_seq_hold = array(datahold['cntscl'])","733a8155":"in_seq1 = in_seq1.reshape((len(in_seq1), 1))\nin_seq2 = in_seq2.reshape((len(in_seq2), 1))\nin_seq3 = in_seq3.reshape((len(in_seq3), 1))\nin_seq4 = in_seq4.reshape((len(in_seq4), 1))\nin_seq5 = in_seq5.reshape((len(in_seq5), 1))\nin_seq6 = in_seq6.reshape((len(in_seq6), 1))\nin_seq7 = in_seq7.reshape((len(in_seq7), 1))\nin_seq8 = in_seq8.reshape((len(in_seq8), 1))\nin_seq9 = in_seq9.reshape((len(in_seq9), 1))\nin_seq10 = in_seq10.reshape((len(in_seq10), 1))\nin_seq11 = in_seq11.reshape((len(in_seq11), 1))\nin_seq12 = in_seq12.reshape((len(in_seq12), 1))\nin_seq13 = in_seq13.reshape((len(in_seq13), 1))\nin_seq14 = in_seq14.reshape((len(in_seq14), 1))\nin_seq15 = in_seq15.reshape((len(in_seq15), 1))\nin_seq16 = in_seq16.reshape((len(in_seq16), 1))\nout_seq_hold = out_seq_hold.reshape((len(out_seq_hold), 1))","ea9d81f2":"datahold_feed = hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5, in_seq6, in_seq7, in_seq8, in_seq9, in_seq10, in_seq11, in_seq12, in_seq13, in_seq14, in_seq15, in_seq16, out_seq_hold))","e75f4ed2":"n_features = datatrain_feed.shape[1]\nn_input = 10\ngenerator_train = TimeseriesGenerator(datatrain_feed, out_seq_train, length=n_input, batch_size=len(datatrain_feed))","ffb75ac1":"generator_test = TimeseriesGenerator(datatest_feed, out_seq_test, length=n_input, batch_size=1)","cca40601":"generator_hold = TimeseriesGenerator(datahold_feed, out_seq_hold, length=n_input, batch_size=1)","f27e6b6f":"print(\"timesteps, features:\", n_input, n_features)","31879296":"model = Sequential()\n\nmodel.add(SimpleRNN(4, activation='relu', input_shape=(n_input, n_features), return_sequences = False))\nmodel.add(Dense(1, activation='relu'))\n\nadam = Adam(lr=0.0001)\nmodel.compile(optimizer=adam, loss='mse')","77724aab":"model.summary()","5cf6bd8a":"score = model.fit_generator(generator_train, epochs=3000, verbose=0, validation_data=generator_test)","fbb98e64":"losses = score.history['loss']\nval_losses = score.history['val_loss']\nplt.figure(figsize=(10,5))\nplt.plot(losses, label=\"trainset\")\nplt.plot(val_losses, label=\"testset\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.show()","d9623203":"df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})\n\nfor i in range(len(generator_test)):\n    x, y = generator_test[i]\n    x_input = array(x).reshape((1, n_input, n_features))\n    yhat = model.predict(x_input, verbose=2)\n    df_result = df_result.append({'Actual': scaler.inverse_transform(y)[0][0], 'Prediction': scaler.inverse_transform(yhat)[0][0]}, ignore_index=True)","8103fa90":"df_result['Diff'] = 100 * (df_result['Prediction'] - df_result['Actual']) \/ df_result['Actual']","b05be593":"df_result","951e6ee5":"mean = df_result['Actual'].mean()\nmae = (df_result['Actual'] - df_result['Prediction']).abs().mean()\n\nprint(\"mean: \", mean)\nprint(\"mae:\", mae)\nprint(\"mae\/mean ratio: \", 100*mae\/mean,\"%\")\nprint(\"correctness: \", 100 - 100*mae\/mean,\"%\")","6af4456d":"plt.figure(figsize=(15,10))\nplt.plot(df_result['Actual'], color='blue')\nplt.plot(df_result['Prediction'], color='red')\nplt.show()","ac13e1de":"df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})\n\nfor i in range(len(generator_hold)):\n    x, y = generator_hold[i]\n    x_input = array(x).reshape((1, n_input, n_features))\n    yhat = model.predict(x_input, verbose=2)\n    df_result = df_result.append({'Actual': scaler.inverse_transform(y)[0][0], 'Prediction': scaler.inverse_transform(yhat)[0][0]}, ignore_index=True)","45f2f458":"df_result['Diff'] = 100 * (df_result['Prediction'] - df_result['Actual']) \/ df_result['Actual']","f425481c":"df_result","fb52fcb3":"mean = df_result['Actual'].mean()\nmae = (df_result['Actual'] - df_result['Prediction']).abs().mean()\n\nprint(\"mean: \", mean)\nprint(\"mae:\", mae)\nprint(\"mae\/mean ratio: \", 100*mae\/mean,\"%\")\nprint(\"correctness: \", 100 - 100*mae\/mean,\"%\")","47d6dca9":"plt.figure(figsize=(15,10))\nplt.plot(df_result['Actual'], color='blue')\nplt.plot(df_result['Prediction'], color='red')\nplt.show()","7d176bce":"* Purpose: to practice solving a timeseries problem by using Recurrent Neural Network\n\n* Data: Bike Sharing in Washington D.C. Dataset\n\n* Applied Tools & Methods: TimeSeriesGenerator, SimpleRNN\n\n* Result: Around %80 correctness (calculated as 1-mae\/mean)\n\n* Further Studies: More advanced sequential methods like LSTM and GRU can be applied.","bfd94335":"### Data Preprocessing","92205f91":"#### Calculating the Correctness for Hold-Out Data","b83c4eed":"#### Data exploration and Manipulation","3dadbfcf":"#### Plot of Training and Test Loss Functions","85dcbd90":"#### Plot of Actuals and Predictions for Hold-Out Data","9f4a69b3":"### Predictions for Hold-Out Data","0b4cd3a3":"#### Training the Model","7c1f39c0":"We should apply one hot encoding for categorical features. In our case weekday, weathersit and mnth features are one hot encoded.","bd5fe91f":"#### Reading the dataset","e96f4ba0":"### Predictions for Test Data","4e5e4b1b":"### Modelling and Training","138a773e":"### Preparing 3-Dimensional Input for Sequential Model","a019c200":"We have created a small RNN with 4 nodes. \nNumber of total parameters in the model is 93. \nNumber of timesteps in one batch is 10. \nActivation function is relu both for RNN and Output layer.\nOptimizer is adam.\nLoss function is mean squared error.\nLearning rate is 0.0001.\nNumber of epocs is 3,000.","c745ceea":"#### One Hot Encoding","1a4b3173":"#### Predicting for Hold-Out Data","848c6eab":"Daily data has the following fields. Thanks to the people who prepared it because it is very well processed data with even scaled features. \n\ninstant: Record index\n\ndteday: Date\n\nseason: Season (1:springer, 2:summer, 3:fall, 4:winter)\n\nyr: Year (0: 2011, 1:2012)\n\nmnth: Month (1 to 12)\n\nholiday: weather day is holiday or not (extracted from Holiday Schedule)\n\nweekday: Day of the week\n\nworkingday: If day is neither weekend nor holiday is 1, otherwise is 0.\n\nweathersit: (extracted from Freemeteo)\n1: Clear, Few clouds, Partly cloudy, Partly cloudy\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\ntemp: Normalized temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n\natemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)\/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n\nhum: Normalized humidity. The values are divided to 100 (max)\n\nwindspeed: Normalized wind speed. The values are divided to 67 (max)\n\ncasual: count of casual users\n\nregistered: count of registered users\n\ncnt: count of total rental bikes including both casual and registered","cfbdf17a":"#### Scaling","ae3ec55e":"#### Data Splitting","957e90e7":"## Time Series Forecasting with Recurrent Neural Network (RNN)","6dd38f14":"#### Tabulating Actuals, Predictions and Differences","28a42beb":"#### Calculating the Correctness for Test Data","92a6c2c0":"#### Predicting for Test Data","5c979976":"* Number of bike sharing is 22 only at 2012-10-29 and such a low value deserves a special attention.\n\n* There was a hurricane at Washington at that day.\n\n* Since it is such an extraordinary day, hurricane and the following days data will be replaced by the average of that month.","20d769a5":"Thanks to the guys prepared the original data, they scaled all features. That is why we have to apply it only for our value Y which is cnt. It is also a discussion whether Y value should be scaled or not in sucha model but we did. ","a223e504":"### Abstract","da502bb8":"#### Plot of Actuals and Predictions for Test Data","92fafc8d":"by Haydar \u00d6zler and Tankut Tekeli","73f3f5b9":"### Explanation of the Study","efb250f4":"The following steps show the way how to prepare input for a sequential model by using TimeSeriesGenerator.","b3824755":"#### Creating the SimpleRNN Model","0c5df9a2":"#### Tabulating Actuals, Predictions and Differences for Hold-Out Data","527a5363":"#### Plot of 2 years number of sharing (cnt)","64db6ba3":"### Importing Libraries","0cf515a8":"We have created a model to predict how many bicycles will be rented in the following days. The features used like weather, temperature, working day are explained in the following sections in detail. \n\nWe have used SimpleRNN method in Keras library. It is one of the sequential models. The others are LSTM and GRU. \n\nSequential models have 3 dimension (sample size, time steps, features). Preparing 3D input is another challenge. Instead of trying to create a 3D array, we use TimeSeriesGenerator class which brings some other advantages like setting the batch size.\n\nWe skipped feature engineering and visualization parts because main purpose was to practice a sequential neural network. It is possible to have better achivements by applying these methods and then create a predictive model. \n\nData is 2 years daily data. Number of samples is 731. We have splitted it into 631, 50, 50 as train, test and hold-out data respectively.\n\nWe have measured the performance of the model with ( 1 - (mean average error) \/ (mean) ) and we have reached values around %80.\n\nThere are so many further studies: More feature engineering for better accuracy and trying other sequential models. "}}