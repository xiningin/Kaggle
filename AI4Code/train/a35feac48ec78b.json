{"cell_type":{"4f66b83a":"code","a54c3125":"code","ad94b81d":"code","b24712dc":"code","6d31b5f9":"code","c2ba4afd":"code","c2fab5af":"code","561228ca":"code","14782ef0":"code","2ff10496":"code","515cede9":"code","ce615803":"code","fcd433c8":"code","841c05e0":"code","4176d78f":"code","0b7001c3":"code","4c5415b9":"code","6e12aead":"code","4a3d3a54":"code","8fcd03ad":"markdown"},"source":{"4f66b83a":"import numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale \nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","a54c3125":"hit = pd.read_csv(\"..\/input\/hittlers\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","ad94b81d":"#Set and fit the model","b24712dc":"!pip install lightgbm","6d31b5f9":"from lightgbm import LGBMRegressor","c2ba4afd":"lgbm_model=LGBMRegressor()\nlgbm_model.fit(X_train,y_train)","c2fab5af":"# Prediction","561228ca":"y_pred=lgbm_model.predict(X_test,num_iteration=lgbm_model.best_iteration_)","14782ef0":"np.sqrt(mean_squared_error(y_test,y_pred))","2ff10496":"#Model Tuning","515cede9":"lgbm_model","ce615803":"#Important Params\n#learning_rate\n#n_estimators\n#max_depth","fcd433c8":"lgbm_grid = {\n    'colsample_bytree': [0.4, 0.5,0.6,0.9,1],\n    'learning_rate': [0.01, 0.1, 0.5,1],\n    'n_estimators': [20, 40, 100, 200, 500,1000],\n    'max_depth': [1,2,3,4,5,6,7,8] }\n\nlgbm = LGBMRegressor()\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_grid, cv=10, n_jobs = -1, verbose = 2)","841c05e0":"lgbm_cv_model.fit(X_train,y_train)","4176d78f":"lgbm_cv_model.best_params_","0b7001c3":"lgbm_tuned = LGBMRegressor(learning_rate = 0.1, \n                           max_depth = 5, \n                           n_estimators = 40,\n                          colsample_bytree = 0.4)\n\nlgbm_tuned = lgbm_tuned.fit(X_train,y_train)","4c5415b9":"y_pred= lgbm_tuned.predict(X_test)","6e12aead":"np.sqrt(mean_squared_error(y_test, y_pred))","4a3d3a54":"# We found 413 for KNN, \n#          367 for SVR,\n#          363 for Artifical Neural Network.\n#          376 for CART\n#          349 for Bagged Trees\n#          350 for Random Forest\n#          344 for GBM\n#          355 for XG Boosting\n#And now,  377 for Light GBM\n\n#In these models, the best one is GBM model for \"hitters\" data set, till now.","8fcd03ad":"# XG Boost Steps\n#### 1)Import and split\n#### 2)Set and fit the model\n#### 3)Predict\n#### 4)Model Tuning\n#### 5)Find best params, set and fit the model again, find final RMSE."}}