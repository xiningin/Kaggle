{"cell_type":{"e0f75469":"code","8d547d3d":"code","cc5e6a6a":"code","4e549239":"code","7d506472":"code","517db58c":"code","4362a04f":"code","0e482fb4":"code","eaabcd3e":"code","de399844":"code","d5843e5d":"code","d3750432":"code","d4f44a2c":"code","ea43a529":"code","b9034cc7":"code","80892df1":"code","321cd7c5":"code","59237d4a":"code","bd015e47":"code","e0f52051":"code","d474c045":"code","7f12929e":"code","4f2d0a9c":"code","deb27fa0":"code","41dacc9b":"code","4b660a4f":"code","8ddbe6e8":"code","d3def662":"code","72707239":"code","a5fbe025":"code","324c2809":"code","6fe514bb":"code","b1db612c":"code","8386c184":"markdown","c05cd754":"markdown","6c85fe2c":"markdown","b9c28ecf":"markdown"},"source":{"e0f75469":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport pydicom\nfrom skimage.transform import resize\n","8d547d3d":"submission_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv', index_col=None)\nimage_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/train_image_level.csv', index_col=None)\nstudy_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/train_study_level.csv', index_col=None)\n\nprint(f\"Train image level csv shape : {image_df.shape}\")\nprint(f\"Train study level csv shape : {study_df.shape}\")","cc5e6a6a":"import matplotlib.pyplot as plt\n\n# Data to plot\nlabels = 'Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance'\nsizes = [study_df['Negative for Pneumonia'].sum(), study_df['Typical Appearance'].sum(), study_df['Indeterminate Appearance'].sum(), study_df['Atypical Appearance'].sum()]\ncolors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\nexplode = (0.1, 0, 0, 0)  # explode 1st slice\n\n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=140)\n\nplt.axis('equal')\nplt.show()","4e549239":"study_df","7d506472":"submission_df","517db58c":"image_df","4362a04f":"i=0\nj=0\nk=0\nl=0\nm=0\ntrain_path=[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/siim-covid19-detection\/train\/'):\n    for filename in filenames:\n        str_split =filename.split('.')\n        if str_split[1]==\"dcm\" :\n            df=image_df[image_df['id'].str.contains(str_split[0])]\n            studydf=study_df[study_df.id.isin(df.StudyInstanceUID+'_study')]\n            lbl_folder=studydf.columns[studydf.eq(1).any()] \n            if lbl_folder=='Atypical Appearance':\n                if i<10:\n                    train_path.append(os.path.join(dirname, filename))\n                    i=i+1\n            elif lbl_folder=='Indeterminate Appearance':\n                if j<10:\n                    train_path.append(os.path.join(dirname, filename))\n                    j=j+1\n            elif lbl_folder=='Negative for Pneumonia':\n                if k<10:\n                    train_path.append(os.path.join(dirname, filename))\n                    k=k+1\n            elif lbl_folder=='Typical Appearance':\n                if l<10:\n                    train_path.append(os.path.join(dirname, filename))\n                    l=l+1\n            else :\n                if m<10:\n                    train_path.append(os.path.join(dirname, filename))\n                    m=m+1","0e482fb4":"for rows in train_path:\n    # specify your image path\n    try:\n        ct_dicom = pydicom.read_file(rows)\n        plt.imshow(ct_dicom.pixel_array, cmap='gray')\n        plt.show()\n    except:\n          pass\n    \n    \n  ","eaabcd3e":"import cv2\nimport os\nfrom skimage.transform import resize","de399844":"import pandas as pd\nimport numpy as np\nimport matplotlib.patches as patches\ndsimagedetails=[]\nbox=[]\nfor rows in train_path:\n    #rows=\"\/kaggle\/input\/siim-covid19-detection\/train\/ea44061da219\/bd68195b6b27\/a818e98c3f90.dcm\"\n    \n    imgname=rows.rsplit('\/', 1)[1]\n    str_split =imgname.split('.')\n    imagename=str_split[0]\n    img_size = 224\n    data=[]\n    df=image_df[image_df['id'].str.contains(imagename,regex=True)]\n    studydf=study_df[study_df.id.isin(df.StudyInstanceUID+'_study')]\n    imgclass=studydf.columns[studydf.eq(1).any()]\n    data_items = df['boxes'].items()\n    data_list = list(data_items)\n    boxes_df = pd.DataFrame(data_list)\n    if boxes_df.empty:\n        print('DataFrame is empty!')\n    else:\n        boxes_df[1].fillna(0, inplace=True)\n        if boxes_df[1].get(0) != 0:\n            ss=boxes_df[1].get(0).split('},')\n            x1=float(ss[0].split(',')[0].split(':')[1].strip())\n            y1=float(ss[0].split(',')[1].split(':')[1].strip())\n            width1=float(ss[0].split(',')[2].split(':')[1].strip())\n            if '}]' in ss[0].split(',')[3].split(':')[1].strip() :\n                height1=float(ss[0].split(',')[3].split(':')[1].strip().replace(\"}]\", \"\"))\n                box = [\n                       {'x' : x1, 'y' : y1, 'width' : width1, 'height' : height1},\n                      ]\n                dsimagedetails.append({'data':rows,'label' : imgclass[0],'x' : x1, 'y' : y1, 'width' : width1, 'height' : height1 })\n              \n            else:\n                height1=float(ss[0].split(',')[3].split(':')[1].strip()) \n                x2=float(ss[1].split(',')[0].split(':')[1].strip())\n                y2=float(ss[1].split(',')[1].split(':')[1].strip())\n                width2=float(ss[1].split(',')[2].split(':')[1].strip())\n                height2=float(ss[1].split(',')[3].split(':')[1].replace('}]', '').replace(\"'\", \"\").strip())\n                box = [\n                      {'x' : x1, 'y' : y1, 'width' : width1, 'height' : height1},\n                      {'x' : x2, 'y' : y2, 'width' : width2, 'height' : height2},\n                    ]\n                dsimagedetails.append({'data':rows,'label' : imgclass[0],'x1' : x1, 'y1' : y1,'x' : x2, 'y' : y2, 'width' : width1, 'height' : height1 })\n        dfbox= pd.DataFrame(box)\n    fig, a = plt.subplots(1,1)\n    fig.set_size_inches(5,5)\n    dicom_image = pydicom.read_file(rows) \n    try:\n        img = dicom_image.pixel_array\n                #print(path+imagename+'.jpg')\n              #scipy.misc.imsave (path+imagename+'.jpg', img)\n        a.imshow(img, cmap = 'gray')\n        for index, row in dfbox.iterrows(): \n            x, y, width, height  = row['x'], row['y'], row['width'], row['height']\n            rect = patches.Rectangle((x, y),\n                                     width, height,\n                                     linewidth = 2,\n                                     edgecolor = 'r',\n                                     facecolor = 'none')\n\n                # Draw the bounding box on top of the image\n            a.add_patch(rect)\n        plt.show()\n    except:\n        pass\n    ","d5843e5d":"dsimg=[]\nlabels = ['Atypical Appearance', 'Indeterminate Appearance', 'Negative for Pneumonia', 'Typical Appearance', 'Not Identified']\nimg_size = 224\nfor rows in dsimagedetails:\n    ds= pydicom.dcmread(rows['data'])\n    img_arr = ds.pixel_array\n    resized_arr = resize(img_arr, (224, 224), anti_aliasing=True)[...,::-1] # Reshaping images to preferred size\n    bb=np.array([rows['x'],row['y'],row['width'],row['height']])\n    for lrow in labels:\n        if rows['label']==lrow:\n            classnum=labels.index(label)\n        else:\n            classnum=4\n    dsimg.append(resized_arr,classnum,bb)\n    \n        \n    ","d3750432":"# define the amount of data that will be used training\nTRAIN_SPLIT = 0.5\n# the amount of validation data will be a percentage of the\n# *training* data\nVAL_SPLIT = 0.5\n# import the necessary packages\nimport random\nimport shutil\nimport os\n# grab the paths to all input images in the original input directory\n# and shuffle them\nrandom.seed(42)\nrandom.shuffle(dsimg)\n# compute the training and testing split\ni = int(len(dsimg) * TRAIN_SPLIT)\ntrainds = dsimg[:i]\nvalds = dsimg[i:]","d4f44a2c":"import seaborn as sns\nfrom tensorflow import keras \nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport tensorflow as tf\n","ea43a529":"trainds","b9034cc7":"x_train = []\ny_train = []\nx_val = []\ny_val = []\n\nfor feature, label,bb in trainds:\n    x_train.append(feature)\n    y_train.append(label)\n    z_train.append(bb)\nfor feature, label in valds:\n    x_val.append(feature)\n    y_val.append(label)\n    z_val.append(bb)\n# Normalize the data\nx_train = np.array(x_train) \/ 255\nx_val = np.array(x_val) \/ 255\n\nx_train =x_train.reshape(-1, 224, 224, 1)\ny_train=y_train = np.array(y_train)\nz_train=z_train = np.array(z_train)\n\nx_val =x_val.reshape(-1, 224, 224, 1)\ny_val = np.array(y_val)","80892df1":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)","321cd7c5":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","59237d4a":"model = Sequential()\nmodel.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,1)))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(2048,activation=\"relu\"))\nmodel.add(Dense(4, activation=\"softmax\"))\n\nmodel.build(input_shape=(224,224,3))\nmodel.summary()","bd015e47":"opt = Adam(lr=0.000001)\nmodel.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])","e0f52051":"print(x_val.shape)\nprint(x_train.shape)","d474c045":"history = model.fit(x_train,y_train,epochs = 50 , validation_data = (x_val,y_val))\n","7f12929e":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(50)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","4f2d0a9c":"tf.keras.utils.plot_model(model, show_shapes=True)","deb27fa0":"predictions = model.predict_classes(x_val)\npredictions = predictions.reshape(1,-1)[0]\nprint(predictions)","41dacc9b":"print(classification_report(y_val, predictions, target_names =['Atypical Appearance (Class 0)', 'Indeterminate Appearance (Class 1)', 'Negative for Pneumonia (Class 2)',  'Typical Appearance (Class 4)']))","4b660a4f":"test_path=[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/siim-covid19-detection\/test\/'):\n    for filename in filenames:\n        str_split =filename.split('.')\n        if str_split[1]==\"dcm\" :\n            test_path.append(os.path.join(dirname, filename))\n","8ddbe6e8":"random.shuffle(test_path)","d3def662":"testpath=[]\ni=0\nfor rows in test_path:\n    if i<51:\n        testpath.append(rows)\n        i=i+1","72707239":"probability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])","a5fbe025":"ds_finalsubmission=[]\nfor rows in test_path:        \n    try:\n        img=rows.rsplit('\/', 1)[1]\n        img=img.split('.')\n        img=img[0]+'_study'\n        dstest= pydicom.dcmread(rows)\n        img_arrtest = dstest.pixel_array\n        resized_arrtest = resize(img_arrtest, (224, 224), anti_aliasing=True)\n        x_test = np.array(resized_arrtest) \/ 255\n        x_test =x_test.reshape(-1, 224, 224, 1)\n        predictions = probability_model.predict(x_test)\n        predicted_label = np.argmax(predictions)\n        \n        if predicted_label==0:\n            title='atypical 1 0 0 1 1'\n        elif predicted_label==1:\n            title='intermediate 1 0 0 1 1'\n        elif predicted_label==2:\n            title='negative 1 0 0 1 1'\n        elif predicted_label==3:\n            title='typical 1 0 0 1 1'\n        elif predicted_label==4:\n            img=img[0]+'_image'\n            title='none 1 0 0 1 1'\n        ds_finalsubmission.append(img,title)\n    except: \n        pass\n               \n","324c2809":"df_finalsubmission=pd.DataFrame(ds_finalsubmission,columns = [\"Id\", \"PredictionString\"])","6fe514bb":"df_finalsubmission","b1db612c":"df_finalsubmission.to_csv('submission.csv',index=False)\n","8386c184":"This is a case of Image data augmentation.\nImage data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n\nTraining deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n\nThe Keras deep learning neural network library provides the capability to fit models using image data augmentation via the ImageDataGenerator class.\n how to improve image classification\nby using data augmentation and convolutional neural networks. Model\noverfitting and poor performance are common problems in applying neural network techniques. Approaches to bring intra-class differences down\nand retain sensitivity to the inter-class variations are important to maximize model accuracy and minimize the loss function. The image dataset, the effects of model overfitting were monitored\nwithin different model architectures in combination of data augmentation and hyper-parameter tuning. The model performance was evaluated\nwith train and test accuracy and loss, characteristics derived from the\nconfusion matrices, and visualizations of different model outputs. As a macro-architecture with 500 weighted layers, \nmodel is used for large scale image classification. In the presence of image\ndata augmentation, the overall model train accuracy is 96%, the\ntest accuracy is stabilized at 92%, and both the results of train and test\nlosses are below 0.5. The overall image classification error rate is dropped\nto 8%, while the single class misclassification rates are less than 7.5% in\neight out of ten image classes. Model architecture, hyper-parameter tuning, and data augmentation are essential to reduce model overfitting and\nhelp build a more reliable convolutional neural network model.","c05cd754":"Reading the csv to fetch the data and ","6c85fe2c":"From the above plot, it is clear that the typical appearance has highest number at the same time. Atypical Appearance has the lowest percentage","b9c28ecf":"Predicting the classes for the test data whose label are not given"}}