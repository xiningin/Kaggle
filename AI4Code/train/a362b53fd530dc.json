{"cell_type":{"12764c6f":"code","2d419c5e":"code","5e1f9ac9":"code","dc518c15":"code","2dd33a4a":"markdown","3a1abc19":"markdown","5e2f07c5":"markdown"},"source":{"12764c6f":"import pandas as pd \nimport datetime as dt\nimport matplotlib as mpl\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","2d419c5e":"def astype_cat(dd, cols):\n    for col in cols:\n        if isinstance(col, tuple):\n            col, idx1, idx2 = col\n            for idx in range(idx1, idx2+1):\n                full_col=col+str(idx)\n                dd[full_col]=dd[full_col].astype(\"category\")\n        else:\n            dd[col]=dd[col].astype(\"category\")\n            \ndef load(trans_filename, id_filename):\n    dd=pd.read_csv(trans_filename)\n    astype_cat(dd, [\"ProductCD\", (\"card\", 1, 6), \"addr1\", \"addr2\", \"P_emaildomain\", \"R_emaildomain\", (\"M\", 1, 9)])\n\n    ddid=pd.read_csv(id_filename)\n    astype_cat(ddid, [\"DeviceType\", \"DeviceInfo\", (\"id_\", 12, 38)])\n\n    dd=dd.merge(ddid, \"left\", \"TransactionID\")\n\n    #dd[\"datetime\"]=(dd[\"TransactionDT\"].apply(lambda x:dt.timedelta(seconds=x)+pd.Timestamp(\"2017-11-30\")))\n\n    return dd\n\ndd=load(\"..\/input\/train_transaction.csv\", \"..\/input\/train_identity.csv\")\nddtest=load(\"..\/input\/test_transaction.csv\", \"..\/input\/test_identity.csv\")\n\ndd.head()","5e1f9ac9":"cat_cols=dd.dtypes.loc[lambda x:x==\"category\"].index\n\nsns.set_palette(\"pastel\")\n\ndef plot_cat(dd, col):\n    mean_fraud=dd[\"isFraud\"].mean()\n\n    plt.figure(figsize=(15,10))\n\n    max_show_cats=30\n    cnts=dd[col].value_counts(normalize=True, dropna=False)\n    plot_cnts=cnts.iloc[:max_show_cats]\n    plt.bar(range(len(plot_cnts)), plot_cnts, width=0.9, tick_label=plot_cnts.index)\n    plt.xticks(rotation=45, ha=\"right\")\n    plt.ylabel(\"Category rate\")\n    plt.grid(False)\n    \n    test_cnts=ddtest[col].value_counts(normalize=True)\n    plt.step(range(len(plot_cnts)), test_cnts.reindex(plot_cnts.index).fillna(0), c=\"b\", where=\"mid\", label=\"Test data\")\n    plt.legend()\n    \n    fraud_rate=dd.groupby(col)[\"isFraud\"].mean()\n    if dd[col].isnull().any():\n        fraud_rate[np.nan]=dd.loc[dd[col].isnull(), \"isFraud\"].mean()\n        \n    ax_fraud=plt.gca().twinx()\n    ax_fraud.stem(range(len(plot_cnts)), fraud_rate.reindex(plot_cnts.index), linefmt=\"k:\", markerfmt=\"ko\")\n    ax_fraud.set_ylabel(\"Fraud rate\", color=\"k\")\n    ax_fraud.grid(False)\n    ax_fraud.axhline(mean_fraud, ls=\"--\", c=\"k\")\n    ax_fraud.set_ylim(bottom=0)\n\n    title=[col]\n    if len(cnts)>len(plot_cnts):\n        title.append(f\"({plot_cnts.sum():.0%} of data; {len(plot_cnts)}\/{len(cnts)} cats)\")\n    plt.title(\" \".join(title))\n    plt.show()\n    \n    \nfor cat in cat_cols:\n    plot_cat(dd, cat)","dc518c15":"mean_fraud=dd[\"isFraud\"].mean()\n\ndef plot_val(dd, col, logbin=True):\n    edges=np.histogram_bin_edges(list(dd[col].dropna())+list(ddtest[col].dropna()), bins=\"doane\")\n    plt.figure(figsize=(15,10))\n    plt.hist(dd[col], bins=edges, log=logbin)\n    plt.hist(ddtest[col], bins=edges, log=logbin, histtype=\"step\", color=\"b\")\n\n    fraud_rate=dd.groupby(pd.cut(dd[col], bins=edges))[\"isFraud\"].mean()\n    ax_fraud=plt.gca().twinx()\n    ax_fraud.stem(fraud_rate.index.map(lambda x:x.mid), fraud_rate, linefmt=\"k:\", markerfmt=\"ko\")\n    ax_fraud.set_ylabel(\"Fraud rate\", color=\"k\")\n    ax_fraud.grid(False)\n    ax_fraud.axhline(mean_fraud, ls=\"--\", c=\"k\")\n\n    plt.title(f\"{col}\")\n    plt.show()\n\nfor col in sorted(dd.columns.difference(set(cat_cols)|{\"datetime\", \"isFraud\"})):\n    plot_val(dd, col)","2dd33a4a":"# Categoricals","3a1abc19":"# Continuous","5e2f07c5":"This notebook plots exploratory plot with compressed information and fraud rate and value frequency in training and test sets."}}