{"cell_type":{"ea48a785":"code","a0fadea6":"code","2461c195":"code","e20d997e":"code","46d4fa3e":"code","d323ed91":"code","809a8359":"code","21e47e68":"code","f9bf8f3d":"code","0f838e9b":"code","2801a2e7":"code","a0826caa":"code","7c1c3724":"code","9b05a59a":"code","7f63f24c":"code","2a180767":"code","17106fab":"code","40f56241":"code","2b868765":"code","d84b3f22":"code","24c95be0":"code","96d7f58d":"code","4bbe1563":"code","f8edbdca":"code","2161b155":"markdown","d7b2d5b4":"markdown","c8ebd2da":"markdown","c05fb761":"markdown","291e4d72":"markdown","581f41cb":"markdown","df62fb23":"markdown","a98d2eaa":"markdown","cda62cc1":"markdown","cc133300":"markdown","549e97f2":"markdown","73de1533":"markdown"},"source":{"ea48a785":"import os\nimport cv2 \nimport numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","a0fadea6":"# Change variables\nTEST_DIR_PATH = '\/kaggle\/input\/airy-photo\/test'\nDATA_DIR_PATH = '\/kaggle\/input\/airy-photo\/train'","2461c195":"# Read dataset\n\ndata_raw = []\nfor class_dir in os.listdir(DATA_DIR_PATH):\n    class_absolute_dir = os.path.join(DATA_DIR_PATH, class_dir)\n    for class_file in os.listdir(class_absolute_dir):\n        absolute_file_path = os.path.join(class_absolute_dir, class_file)\n        img = cv2.imread(absolute_file_path, cv2.IMREAD_COLOR)\n        data_raw.append([\n            class_file, # file name act as id\n            absolute_file_path, \n            class_dir, # label \/ category \n            img.shape[0], # height\n            img.shape[1] # width\n        ])\n\ndata_pd = pd.DataFrame(data=data_raw, columns=['photo_id', 'file_path', 'category', 'height', 'width'])","e20d997e":"# Read testset\n\ntest_raw = []\nfor test_file in os.listdir(TEST_DIR_PATH):\n    absolute_file_path = os.path.join(TEST_DIR_PATH, test_file)\n    img = cv2.imread(absolute_file_path, cv2.IMREAD_COLOR)\n    test_raw.append([\n        test_file, # file name act as id\n        absolute_file_path, # absolute file path\n        img.shape[0], #height\n        img.shape[1] #width\n    ])\n\ntest_pd = pd.DataFrame(data=test_raw, columns=['photo_id', 'file_path', 'height', 'width'])","46d4fa3e":"# Read sample submission\n\nsample_submission = pd.read_csv('\/kaggle\/input\/airy-photo\/sample_submission.csv')","d323ed91":"from sklearn.metrics import f1_score, classification_report\n\ndef evaluation_report_airy_photo(prediction, target) -> None:\n    '''\n    This is the evaluation report for Airy Photo Classification.\n    Accept two pandas DataFrame, both contains 2 columns (photo_id, category)\n    '''\n    assert prediction.size == target.size, 'Prediction and target should have equal length.'\n    \n    print(classification_report(y_true=target, y_pred=prediction))\n    print('-----------------------------------------------------------')\n    evaluation_score = f1_score(y_true=target, y_pred=prediction, average='micro')\n    print('\\tMicro F1-score: {:.3f}'.format(evaluation_score))\n    print('-----------------------------------------------------------')\n    ","809a8359":"from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","21e47e68":"data_pd.head()","f9bf8f3d":"sample_submission.head()","0f838e9b":"# Change variables\nVALIDATION_PROPORTION = 0.3\nLABEL_ATTRIBUTE = 'category'","2801a2e7":"train_pd, val_pd = train_test_split(data_pd, test_size=VALIDATION_PROPORTION, stratify=data_pd.category, random_state=23)\ntrain_X_pd = train_pd.loc[:, train_pd.columns != LABEL_ATTRIBUTE]\ntrain_y_pd = train_pd.loc[:, LABEL_ATTRIBUTE]\nval_X_pd = val_pd.loc[:, val_pd.columns != LABEL_ATTRIBUTE]\nval_y_pd = val_pd.loc[:, LABEL_ATTRIBUTE]","a0826caa":"def show_image(img: np.array, ax = None) -> None:\n    '''\n    Display an image. Image is an numpy array (height, width, channel)\n    This function expect channel is in RGB color space.\n    '''\n    if ax is not None:\n        ax.imshow(img)\n    else:\n        plt.imshow(img)\n    \ndef read_image(file_path: str) -> np.array:\n    '''\n    Read an image form given a file name. Image is an numpy array (height, width, channel). \n    Channel is in RGB color space.\n    '''\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\ndef pad_and_crop_image(img: np.array, width: int, height:int, pad_value = [0, 0, 0]) -> np.array:\n    '''\n    This function receive a numpy array of img and the target size.\n    Add padding to bottom and right of the image.\n    '''\n    # Crop if current image size exceed target size\n    target_img = img[:height,:width]\n    # Pad the image if the size is not match the target size\n    border_bottom = height-target_img.shape[0]\n    border_right = width-target_img.shape[1]\n    target_img = cv2.copyMakeBorder(target_img, 0, border_bottom, 0, border_right, cv2.BORDER_CONSTANT, value = pad_value)\n    \n    return target_img\n\ndef resize_image(img: np.array, scale_ratio:float=1) -> np.array:\n    '''\n    Scale image to have size = original_size * scale\n    '''\n    height = int(round(img.shape[0] * scale_ratio))\n    width = int(round(img.shape[1] * scale_ratio))\n    target_img = cv2.resize(img,(width, height)) \n    return target_img\n\ndef preprocess_image(img, target_width, target_height):\n    '''\n    Resizing, pad or crop the image to match the target size\n    '''\n    # Choose to crop than pad\n    target_aspect_ratio = target_width \/ target_height\n    current_aspect_ratio = img.shape[1] \/ img.shape[0] \n    \n    if (current_aspect_ratio > target_aspect_ratio): # current width > target width\n        scale_ratio = target_height \/ img.shape[0]\n    else:\n        scale_ratio = target_width \/ img.shape[1]\n    \n    # Resize and crop\n    current_img = resize_image(img, scale_ratio)\n    current_img = pad_and_crop_image(current_img, width=target_width, height=target_height)\n    return current_img","7c1c3724":"train_y_pd.value_counts().plot(kind='bar');","9b05a59a":"SAMPLE_SIZE = 4\n\n# Sample SAMPLE_SIZE images for each category\ncategory_image_samples = train_pd.groupby('category')['file_path'].apply(lambda df: df.sample(SAMPLE_SIZE, random_state=23))\n\n# Prepare the figure\nnum_category = category_image_samples.index.get_level_values(0).unique().size\nfig, axes = plt.subplots(num_category, SAMPLE_SIZE)\nfig.set_size_inches(SAMPLE_SIZE * 6, num_category * 4)\n\nfor idx, (category, df_select) in enumerate(category_image_samples.groupby(level=0)):\n    row_ax = axes[idx]\n    \n    # Draw images\n    for ax, filename in zip(row_ax, df_select):\n        ax.axis('off')\n        img = read_image(filename)\n        show_image(img, ax)\n        ax.set_title(category, fontsize=20)\n\nfig.tight_layout()\nplt.show()","7f63f24c":"bedroom_proportion = float((train_y_pd == 'bedroom').sum()) \/ train_y_pd.size\nprint('Bedroom proportion: {:.2f}'.format( bedroom_proportion ))\nprint('If we predict all as bedroom, we will have micro recall = {:.2f}, and precision = {:.2f}'.format(bedroom_proportion, bedroom_proportion))\nprint('Thus the F1-score = {:.2f}'.format( 2 * bedroom_proportion * bedroom_proportion \/ (bedroom_proportion + bedroom_proportion) ))","2a180767":"benchmark_prediction = pd.DataFrame(\n    data = {\n        'photo_id': val_X_pd.photo_id,\n        'category': 'bedroom'\n    })\n\nevaluation_report_airy_photo(\n    prediction=benchmark_prediction.category, \n    target=val_y_pd)\n\nbenchmark_prediction = pd.DataFrame(\n    data = {\n        'photo_id': test_pd.photo_id,\n        'category': 'bedroom'\n    })\n\nbenchmark_prediction.to_csv('benchmark_prediction.csv', index=False)","17106fab":"# Change variables\nTARGET_WIDTH = 256\nTARGET_HEIGHT = 160","40f56241":"print( train_X_pd.width.value_counts() )\nprint( train_X_pd.height.value_counts() )","2b868765":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tensorflow import set_random_seed\nfrom numpy.random import seed\nimport tensorflow as tf\nimport keras.backend as K","d84b3f22":"class AiryPhotoModel():\n    BATCH_SIZE = 16\n    EPOCH = 50\n    \n    def __init__(self, model: Sequential, \n                 image_size = (256, 160), \n                 model_file_name = 'temp_model.h5' ):\n        self.is_trained = False\n        self.model = model\n        self.image_width = image_size[0]\n        self.image_height = image_size[1]\n        self.model_file_name = model_file_name\n        \n    def fit(self, file_paths: pd.Series, categories: pd.Series, val_file_paths: pd.Series, val_categories: pd.Series):\n        # Label encoding\n        self.label_encoder = OneHotEncoder(categories='auto')\n        self.label_encoder.fit(categories.values.reshape(-1,1))\n        \n        # Data\n        train_images = self._get_images(file_paths)\n        train_label_one_hot = self._transform_labels(categories)\n        \n        val_images = self._get_images(val_file_paths)\n        val_label_one_hot = self._transform_labels(val_categories)\n        \n        # Train model\n        earlystoping_callback = self._get_earlystoping_cb()\n        history = self.model.fit(\n            x=train_images, \n            y=train_label_one_hot, \n            batch_size=self.BATCH_SIZE, \n            epochs=self.EPOCH, \n            callbacks=[earlystoping_callback],\n            validation_data=(val_images, val_label_one_hot)\n        )\n        self.is_trained = True\n        \n        # Validation result\n        pred_one_hot = self.model.predict(val_images)\n        pred_label = self._inverse_transform_label(pred_one_hot)\n        evaluation_report_airy_photo(prediction=pred_label, target=val_categories)\n        \n        return history\n        \n    def predict(self, file_paths: pd.Series):\n        assert self.is_trained, 'Shoud train model before predict'\n        images = self._get_images(file_paths)\n        pred_one_hot = self.model.predict(images)\n        pred_label = self._inverse_transform_label(pred_one_hot)\n        return pred_label\n    \n    def _get_images(self, file_paths: pd.Series):\n        images = file_paths.apply(lambda fp: read_image(fp))\n        images = images.apply(lambda img: preprocess_image(img, target_height=self.image_height, target_width=self.image_width))\n        images = np.stack(images, axis=0) \n        images = images \/ 255.0\n        return images\n    \n    def _transform_labels(self, categories: pd.Series) -> np.array:\n        categories_one_hot = self.label_encoder.transform(categories.values.reshape(-1,1))\n        return categories_one_hot\n    \n    def _inverse_transform_label(self, categories_one_hot: np.array) -> pd.Series: \n        categories = self.label_encoder.inverse_transform(categories_one_hot)\n        categories = pd.Series(categories.reshape(-1))\n        return categories\n    \n    def _get_checkpoint_cb(self) -> ModelCheckpoint:\n        return  ModelCheckpoint(\n            self.model_file_name, \n            monitor='val_loss', \n            verbose=0, \n            save_best_only=True, \n            save_weights_only=False, \n            mode='auto', \n            period=1\n        )\n    \n    def _get_earlystoping_cb(self) -> EarlyStopping:\n        return EarlyStopping(\n            monitor='val_loss', \n            min_delta=0, \n            patience=5, \n            verbose=0, \n            mode='auto',  \n            restore_best_weights=True\n        )","24c95be0":"def plot_keras_train_history(history):\n    history_df = pd.DataFrame(history.history)\n    epochs = range(history_df.shape[0])\n\n    fig, ax = plt.subplots(1,2,figsize=(18,4))\n\n\n    ax[0].plot(epochs, history_df['loss'], label='Training loss')\n    ax[0].plot(epochs, history_df['val_loss'], label='Validation loss')\n    ax[0].set_title('Training and validation loss')\n    ax[0].legend()\n\n    ax[1].plot(epochs, history_df['acc'],label='Training accuracy')\n    ax[1].plot(epochs, history_df['val_acc'], label='Validation accuracy')\n    ax[1].set_title('Training and validation accuracy')\n    ax[1].legend()\n\n    plt.show()","96d7f58d":"from keras.applications.densenet import DenseNet121","4bbe1563":"# Ensure reproducibility\nseed(23)\nset_random_seed(23)\n\n# Define model, no transfer learning (weights=None)\nmodel = DenseNet121(include_top=True, weights=None, input_shape=(160, 256, 3), classes=10)\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train model\nairy_photo_model = AiryPhotoModel(model=model, image_size=(256, 160), model_file_name='airy_photo_densenet121.h5')\nhistory = airy_photo_model.fit(\n    file_paths = train_X_pd.file_path, \n    categories = train_y_pd,\n    val_file_paths = val_X_pd.file_path, \n    val_categories = val_y_pd)\n\nplot_keras_train_history(history)","f8edbdca":"pred_y = airy_photo_model.predict(test_pd.file_path)\npred_pd = pd.DataFrame(\n    data = {\n        'photo_id': test_pd.photo_id,\n        'category': pred_y\n    })\n\npred_pd.to_csv('airy_photo_densenet121.csv', index=False)","2161b155":"## Benchmark, predict with majority class","d7b2d5b4":"## Preprocessing functions","c8ebd2da":"## Split train and validation","c05fb761":"# Evaluation Metrics","291e4d72":"## Train DenseNet in Keras","581f41cb":"## Image size, resize","df62fb23":"## Class distribution and samples","a98d2eaa":"# Prediction Model, and Tunning","cda62cc1":"# EDA and Preprocessing\n","cc133300":"## Keras model wrapper","549e97f2":"# Data Preparation","73de1533":"## Data sample"}}