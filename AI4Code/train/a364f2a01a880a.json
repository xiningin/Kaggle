{"cell_type":{"ce0e82de":"code","b7042dfb":"code","1f70ddec":"code","9b3ce8f5":"code","2f3273ab":"code","0eebe02e":"markdown","5e48a24c":"markdown","2f954250":"markdown","cc932d6c":"markdown"},"source":{"ce0e82de":"!pip install --upgrade pip\n!pip install ..\/input\/nlpaug-0-0-14\/nlpaug-master\n!pip uninstall librosa --y","b7042dfb":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport transformers\n\nimport nlpaug.augmenter.word as naw","1f70ddec":"TOPK=20 \nACT = 'substitute' #'insert'\naug_bert = naw.ContextualWordEmbsAug(\n    model_path='bert-base-uncased',\n    action=ACT, top_k=TOPK,include_detail=True,aug_p=0.6)","9b3ce8f5":"original_text = \"testttt 123 http:\/\/curious.org\"\n\noutput = aug_bert.augment(original_text)\nnew_text = output[0]\nswaps = output[1]\n\nprint(\"Original:\", original_text)\nprint(\"Length:\", len(original_text))\nprint(\" \")\nprint(\"New:\",new_text)\nprint(\"Length:\", len(new_text))\nprint(\" \")\n\nfor s in swaps:\n    print(s)","2f3273ab":"a = original_text\nb = new_text\nfor i in range(max(len(a),len(b))):\n    try:\n        print(i,a[i],b[i])\n    except:\n        if len(b) > len(a):\n            print(i,\"~\",b[i])\n        else:\n            print(i,a[i],\"~\")","0eebe02e":"### Install nlpaug 0.0.14\nMust uninstall librosa or run into a error: https:\/\/github.com\/makcedward\/nlpaug\/issues\/127","5e48a24c":"A little hard to read but looking at positions of **original_text** vs. **new_text**","2f954250":"### Augment text using ContextualWordEmbsAug\n\nSource code https:\/\/github.com\/makcedward\/nlpaug\/blob\/master\/nlpaug\/augmenter\/word\/context_word_embs.py","cc932d6c":"### Issue:\n\nThe **'orig_start_pos'** doesn't align with **'orig_token'**.\n\nFor some tokens **'orig_start_pos'** is greater than the length of the **original_text**."}}