{"cell_type":{"c294a549":"code","5c533208":"code","5dbb0796":"code","72be1fdf":"code","a3e386c5":"code","b9b85794":"code","7c7c5a59":"code","673ae39c":"code","3fab9b3e":"code","ecf4058c":"code","10391b88":"code","80cb2bab":"code","a95f22b1":"code","f5c2372d":"code","11a3b869":"code","ac51b6e1":"code","faf7440b":"code","0ec7f696":"code","4399e61c":"code","b9dc4565":"code","d5cc98ec":"code","6b9f21fd":"code","52ffb86e":"code","7deb8852":"code","27d61810":"code","b32c7b22":"code","ba6ab333":"code","c9fc8313":"code","3b5570b3":"code","18023faf":"code","0e6fbf05":"code","874c7c83":"code","5d1240d5":"code","30bfbefe":"code","1ac93548":"code","bfb2d725":"code","25db1cc0":"code","84ea4ffc":"code","fe9badf8":"markdown","2fb7216b":"markdown","ea153a42":"markdown","3ccad825":"markdown","669c59e3":"markdown","cec57a5b":"markdown","06b969de":"markdown","491be0f7":"markdown","a666d750":"markdown","68b292e8":"markdown","0dd9d700":"markdown","c9c146a9":"markdown","ebd07b08":"markdown","f43292e5":"markdown","5b967054":"markdown","62e95501":"markdown","871e888e":"markdown","50ac5ba8":"markdown","f42661e4":"markdown","942dce5d":"markdown","c5daea0a":"markdown","8c3f8ef5":"markdown","8cbaf8d2":"markdown","f6da907c":"markdown","c2d35671":"markdown","483210b5":"markdown","2c03944b":"markdown","419e66a1":"markdown","86fec585":"markdown","ca153702":"markdown","249ca638":"markdown","8fcb856d":"markdown","9ac41219":"markdown","5d76acf2":"markdown","1699f8f1":"markdown","d79f79fb":"markdown","dfbc2175":"markdown","fc4fdb02":"markdown","8c133200":"markdown","1011f1c1":"markdown","a60626a4":"markdown","5da4900f":"markdown","371d8020":"markdown","7bd7d013":"markdown","4bf9eb6a":"markdown","0af600b5":"markdown","942cea51":"markdown","c7bc50e8":"markdown","66904f28":"markdown","f782f7ca":"markdown"},"source":{"c294a549":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.tseries.offsets import DateOffset\nfrom datetime import timedelta\nfrom statsmodels.tsa.arima.model import ARIMA \nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot \nfrom statsmodels.tsa.stattools import adfuller, acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom fbprophet import Prophet\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5c533208":"df= pd.read_csv('\/kaggle\/input\/champagne-data\/champagne.csv')\ndf.head()","5dbb0796":"\n## test for stationarity\ndef adfuller_test(sales):\n    result=adfuller(sales)\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n    if result[1] <= 0.05:\n        print(\"Data is stationary !\")\n    else:\n        print(\"Data is non-stationary !\")\n   \nadfuller_test(df.Sales)\n","72be1fdf":"# KPSS test\nfrom statsmodels.tsa.stattools import kpss\ndef kpss_test(series, **kw):    \n    statistic, p_value, n_lags, critical_values = kpss(series, **kw)\n    # Format Output\n    print(f'KPSS Statistic: {statistic}')\n    print(f'p-value: {p_value}')\n    print(f'num lags: {n_lags}')\n    print('Critial Values:')\n    for key, value in critical_values.items():\n        print(f'   {key} : {value}')\n    print(f'Result: The series is {\"not \" if p_value < 0.05 else \"\"}stationary !')\n\nkpss_test(df.Sales)\n\n","a3e386c5":"df['Month']=pd.to_datetime(df['Month'])\n\ndf.set_index('Month', inplace=True)\ndf.plot()\n","b9b85794":"df['month'] = [d.strftime('%b') for d in df.index]\ndf['year'] = [d.year for d in df.index]\ndf[['month','year']].head()","7c7c5a59":"sns.boxplot(x='year', y='Sales', data=df)","673ae39c":"sns.boxplot(x='month', y='Sales', data=df)","3fab9b3e":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return np.array(diff)\n\n\n# invert differenced value\ndef inverse_difference(history, yhat, interval=1):\n\treturn yhat + history[-interval]\ndf_sta= difference(df.Sales ,12) #12 because it is seasonal","ecf4058c":"## ADF Test   \nprint(adfuller_test(df_sta), kpss_test(df_sta))\n# KPSS test\n\n\n","10391b88":"## data is stationary now\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(df.Sales)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(df.Sales,12)\nplt.plot(new_ts)\nplt.plot()","80cb2bab":"fig=plt.figure(figsize=(8,8))\nax1=fig.add_subplot(211)\nfig=plot_acf(new_ts, lags=15,ax=ax1)\nax2=fig.add_subplot(212)\nfig=plot_pacf(new_ts, lags=15, ax=ax2)\n\n","a95f22b1":"autocorrelation_plot(df.Sales)","f5c2372d":"\n\nmodel=ARIMA(df['Sales'],order=(1,1,1))\nmodel_fit=model.fit()\ndf['forecast']= model_fit.predict(start=70, end=103, dynamic=True)\ndf[['Sales', 'forecast']].plot(figsize=(12,8))\n","11a3b869":"best_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(10)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = ARIMA(df['Sales'].values, order=(i,1,j)).fit()\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","ac51b6e1":"model=ARIMA(df['Sales'],order=(8,1,5))\nmodel_fit=model.fit()\ndf['forecast']= model_fit.predict(start=72, end=104 ,dynamic=True)\ndf[['Sales', 'forecast']].plot(figsize=(12,8))\n","faf7440b":"train_data= df.iloc[:72]\ntest_data= df.iloc[72:105]\n\ndef mean_absolute_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred) \/ y_true))\n\ndef evaluate_arima_model(X, arima_order, n):\n    \n    # prepare training dataset\n    X = X.astype('float32')\n    train_size = 72\n    train, test = X[0:train_size], X[train_size:]\n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    for t in range(len(test)):\n        # difference data\n        diff = difference(history, n)\n        model = ARIMA(diff, order=arima_order)\n        model_fit = model.fit()\n        y_pred = model_fit.forecast()[0]\n        y_pred = inverse_difference(history, y_pred, n) #remove seasonal trend \n        predictions.append(y_pred)\n        history.append(test[t])\n\n    mae = mean_absolute_error(test, predictions)\n    df['forecast']=np.nan\n    df['forecast'].iloc[72:105]=predictions\n    residuals=test-predictions\n    df['residuals']=np.nan\n    df['residuals'].iloc[72:105]=residuals\n    \n    fig, axs = plt.subplots(1, 2, figsize=(15,4))\n    axs[0].plot(df[['Sales','forecast']])\n    axs[0].set_title(\"predictions\")\n    axs[ 1].plot(df.residuals.iloc[72:105])\n    axs[1].set_title(\"residuals\")\n    axs[1].axes.get_xaxis().set_visible(False)\n    fig.tight_layout()\n    print(\"Mean Absolute Error :\")\n    return mae\n\n\n   #df[['Sales','forecast']].plot(figsize=(12,8))\n","0ec7f696":"evaluate_arima_model(df.Sales.values,(1,1,1),1)","4399e61c":"evaluate_arima_model(df.Sales.values,(1,1,1), 12)","b9dc4565":"model_sarimax= SARIMAX(df.Sales, order=(1,1,1), seasonal_order=(1,1,1,12)).fit()\n\ndf['forecast2']=model_sarimax.predict(start=72, end=105, dynamic=True) ## prediction for the last 3 years\n\ndf[['Sales','forecast2']].plot(figsize=(12,8))","d5cc98ec":"model_sarimax= SARIMAX(df.Sales, order=(8,1,5), seasonal_order=(8,1,5,12)).fit()\n\ndf['forecast3']=model_sarimax.predict(start=72, end=105, dynamic=True)\n\ndf[['Sales','forecast3']].plot(figsize=(12,8))","6b9f21fd":"res= pd.DataFrame(columns=['Mean Absolute Error'], index=['SARIMAX 1,1,1', 'SARIMAX 8,1,5',\"SARIMAX with cross\",\"SARIMAX cross with auto_arima\" ,'fbprophetModel', \"ARIMA without seasonal trend\"])\nres.iloc[0,0]=round(mean_absolute_error(df.Sales, df.forecast2),4)\nres.iloc[1,0]=round(mean_absolute_error(df.Sales, df.forecast3),4)\nres.iloc[5,0]=round(0.1779568046845573,4)\nres","52ffb86e":"predictions_rolling=pd.Series()\n\nfor date in test_data.index:\n    train_data=df[:date - timedelta(days=1)]      \n    model=SARIMAX(train_data.Sales, order=(1,1,1), seasonal_order=(1,1,1,12)).fit()\n    pred=model.predict(date)\n    predictions_rolling.loc[date]= pred.loc[date]\n\ndf['forecast4']= predictions_rolling\nres.iloc[2,0]=round(mean_absolute_error(df.Sales, df.forecast4),4)\nres\n\n","7deb8852":"df[['Sales','forecast4']].plot(figsize=(12, 8))","27d61810":"fig, axs = plt.subplots(3, sharex=True, sharey=True ,figsize=(12,8))\naxs[0].plot(df[['Sales','forecast2']])\naxs[1].plot(df[['Sales','forecast3']])\naxs[2].plot(df[['Sales','forecast4']])\naxs[0].set_title(\"SARIMAX 1,1,1\")\naxs[1].set_title(\"SARIMAX 8,5,1\")\naxs[2].set_title(\"SARIMAX rollingforecast\")","b32c7b22":"future_dates=[test_data.index[-1]+ DateOffset(months=x) for x in range(0, 24)]\n\nfuture_datest_df=pd.DataFrame(index=future_dates[0:], columns=df.columns)\nfuture_df=pd.concat([test_data, future_datest_df])\npredictions_rolling=pd.Series()\n\n\n\nfor end_date in future_df.index:\n    train_data=df[:end_date - timedelta(days=1)]      \n    model=SARIMAX(train_data.Sales, order=(1,1,1), seasonal_order=(1,1,1,12)).fit()\n    pred=model.predict(end_date)\n    predictions_rolling.loc[end_date]= pred.loc[end_date]\n\n\n\n\n\n\n","ba6ab333":"\nfuture_df['forecast5']= predictions_rolling\nfuture_df['Sales'].plot(figsize=(12, 8))\nfuture_df['forecast5'].iloc[32:].plot(figsize=(12, 8))","c9fc8313":"pip install pmdarima","3b5570b3":"from pmdarima.arima import auto_arima\narima_model= auto_arima(df['Sales'], start_p=1, d=1, start_q=1, max_p=5, max_q=5, max_d=5, m=12,   start_P = 0, D=1, start_Q=0, max_P=5, max_D=5, max_Q=5,seasonal = True, trace = True, error_action ='ignore',   suppress_warnings = True,  stepwise = True, n_fits=50) \narima_model.summary()","18023faf":"predictions_rolling=pd.Series()\n\nfor date in test_data.index:\n    train_data=df[:date - timedelta(days=1)]      \n    model=SARIMAX(train_data.Sales, order=(1,1,1), seasonal_order=(1,1,0,12)).fit()\n    pred=model.predict(date)\n    predictions_rolling.loc[date]= pred.loc[date]\n\ndf['forecast6']= predictions_rolling\nres.iloc[3,0]=round(mean_absolute_error(df.Sales, df.forecast6),4)\nres","0e6fbf05":"df2=train_data.copy()\ndf2.reset_index('Month', inplace=True)\ndf2=df2[['Month','Sales']]\ndf2.columns=['ds', 'y']\nmodel_prophet= Prophet(yearly_seasonality=True)\nmodel_prophet.fit(df2)","874c7c83":"test_data2=test_data.copy()\ntest_data2.drop(['month','year','forecast'], axis=1,inplace= True)\ntest_data2.columns=['ds']\ntest_data2.reset_index(inplace= True)\ntest_data2.drop(\"ds\", axis=1, inplace=True)\ntest_data2.columns=['ds']","5d1240d5":"forecast_test= model_prophet.predict(test_data2)\nforecast_test[['ds', 'yhat', 'yhat_lower','yhat_upper']].tail()","30bfbefe":"fu_df=forecast_test[['ds', 'yhat', 'yhat_lower','yhat_upper']]\ndf3=pd.DataFrame(index=test_data.index, columns=['y','y_hat'])\ndf3['y']=test_data.Sales\ndf3['y_hat']=fu_df['yhat'].values\ndf3.head()\n\ndf3['residuals']= df3.y-df3.y_hat\nres.iloc[4,0]=round(np.mean(abs(df3['residuals']\/df3['y'])),4)\nres","1ac93548":"sns.heatmap(res.astype(float), cmap = 'Blues', annot = True, linewidths = 1, cbar = False, annot_kws = {'fontsize': 12},\n          xticklabels=['MAE'] ,yticklabels = ['SARIMAX 1.1.1', 'SARIMAX 8.1.5', 'SARIMAX_CROSS(1, 1, 1)x(1, 1, 1, 12)','SARIMAX(1, 1, 1)(1, 1, 0, 12)','fbprophetModel',\"ARIMA Without seasonal trend\"])\nsns.set(font_scale = 1.5)\nplt.yticks(rotation = 0)\nplt.show()  ","bfb2d725":"df2=df.copy()\ndf2.reset_index('Month', inplace=True)\ndf2=df2[['Month','Sales']]\ndf2.columns=['ds', 'y']\nmodel_prophet= Prophet(yearly_seasonality=True)\nmodel_prophet.fit(df2)\n\nfuture=model_prophet.make_future_dataframe(periods=24, freq= 'MS')\nforecast= model_prophet.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower','yhat_upper']].tail()","25db1cc0":"model_prophet.plot(forecast)","84ea4ffc":"model_prophet.plot_components(forecast)","fe9badf8":"It's a bit better than before but we still have another problem which is : I am not taken into consideration the seasonal trend, therefore we have two options :\n\n1- use arima but with stationary data (remove seasonal trend)\n\n2- change the model and use SARIMA\n\nEarly we saw how data contains seasonal component therfore we should not use ARIMA but SARIMAX.\nSARIMAX is used on data sets that have seasonal cycles. The difference between ARIMA and SARIMAX is the seasonality and exogenous factors , seasonality and regular ARIMA don't mix well.\nBefore going for SARIMAX, Actually we can use ARIMA but we need first to differenciate it so we can remove the seasonal trend :\n\n","2fb7216b":"<a id=\"gsah\"><\/a>","ea153a42":"**ARIMA With Non-Stationary Data**","3ccad825":"# Imports\n<a id=\"lib\"><\/a>","669c59e3":"# Data visiualization\n<a id=\"dv\"><\/a>","cec57a5b":"We can see the difference between orginal data and transformed data we have no more seasonal trend.\nIdentifying and removing the seasonal component from the time series will result in a clearer relationship between input and output variables ","06b969de":"Now we can check again and see that our data is good","491be0f7":"So as we can see data is not stationary.\n* ADF test : if P-value >=0.5 than Data is not stationary\n* KPSS test : if P-value <0.5 than Data is not stationary \n","a666d750":"**Grid Search ARIMA Hyperparameters**","68b292e8":"auto_arima suggest that SARIMAX(1, 1, 1)x(1, 1, 0, 12) is the more appropriate model to use, well let's see ","0dd9d700":"let's see where seasonality exactly occurs :","c9c146a9":"we can see a greater prediction result\nlet's now plot the last three models and see the difference ","ebd07b08":"# SARIMAX\nFor this model we don't need to differentiate data it is done by the model. by specifying the hyperparameter in the seasonal_order to 12.\n\nth\n<a id=\"th\"><\/a>\n","f43292e5":"this method will prepare the data, differentiate it, forcast, reverse differenciality and calculate Mean absolute error\n\n","5b967054":"ase we can see there is higher trend in the last 3 months and slightly increase in terms of years\n\nTo remove the seasonal trend we need to differentiate data :\nDetrending by Differencing is one of the simplest methods for detrending a time series. A new series is constructed where the value at the current time step is calculated as the difference between the original observation and the observation at the previous time step:\nY= Y(t) - Y(t-1)\n\n\n","62e95501":"<a id=\"pred\"><\/a>\n","871e888e":"# Prediction for the next two years\n","50ac5ba8":"**Adfuller Test**\n<a id=\"adf\"><\/a>","f42661e4":"Now let's plot data to get more insight about why data is non-stationary","942dce5d":"<a id=\"conclusion\"><\/a>","c5daea0a":"data is non-stationary there is actually a seasonal trend because there is changes in each period of every year\n\n\n\n","8c3f8ef5":"Autocorrelation in this timeseries is the correlation of the values of Sales with respect to past values (t-l)of sales that occured before. where l is the number of lags. for example value of y in time t is influenced by the values of the last 60 months.\nAny correlation between 0.25 and -0.25 (in the y-axis)  are insignificant and are not important statistically.\nas we can see above starting from 60 months the correlation becomes insignificant.\n\nNow let's try different models starting with ARIMA  although it's a bit clear that it's not the best choice as we saw there is seasonal trend.\n\nfor now, I will use non-stationary data so we can see how bad results can be\n\n","8cbaf8d2":"Now let's visualize the results","f6da907c":"**Table of Contents**\n\n* [Importing Libraries](#lib)\n* [Stationarity](#section-one)\n    - [Adfuller Test](#adf)\n    - [Kpss Test](#kpss)\n* [Data Visualization](#dv)\n* [Differentiate data and check stationarity](#ds)\n* [ACF,PACF,autocorrelation_plot](#dapap)\n* [Modeling](#m)\n    - [ARIMA With Non-Stationary Data](#awnd)\n    - [Grid Search ARIMA hyperparameters](#gsah)\n    - [ARIMA with Stationary Data and removing seasonal Trend](#awsdawst)\n* [SARIMAX](#sarimax)\n    - [Tuning Hyperparameters](#th)\n    - [SARIMAX with Rolling Forecast Origin](#rfo)\n    - [Prediction for the next two years](#pred)\n* [Auto Arima for model selection](#aa)\n* [FBprophet](#fb)\n* [Conclusion](#conclusion)\n","c2d35671":"Now with n=12 we will remove seasonal trend and we will see a much better result","483210b5":"# Modeling\n<a id=\"awnd\"><\/a>","2c03944b":"# Stationarity \n\nFirst thing we should do when dealing with timeseries is checking for stationarity by using two methods : ADF and KPSS\n:means that the statistical properties of a time series i.e. mean, variance and covariance do not change over time. check this for more explanation : https:\/\/www.statsmodels.org\/dev\/examples\/notebooks\/generated\/stationarity_detrending_adf_kpss.html#Detrending-by-Differencing","419e66a1":"<a id=\"rfo\"><\/a>\n**SARIMAX with Rolling Forecast Origin** \n\nNow let's use another method with SARIMAX and try to improve results.\nThe way it works is to predict only one month in advance for each iteration ","86fec585":"<a id=\"th\"><\/a>","ca153702":"**Conclusion**\n\nAfter trying different techniques, fbprophet gave the lowest Mean Absolute Error of 0.16. and i think it's quite good results. On the other hand using ARIMA and taking into consideration the seasonal trend also gave quite good results with a MAE of 0.18.\n\n\nPlease give me your feedback or some advice on how to improve my work in the comment section and thank you for your time.\n\n\n","249ca638":"<a id=\"section-one\"><\/a>","8fcb856d":"Using SARIMAX with 8,1,5 shows less error. Which confirms that the second combination is better.\nHowever ARIMA without seasonal trend still doing better. \n\n\n","9ac41219":"# \n<a id=\"m\"><\/a>","5d76acf2":"Finally, let's make the predictions for the next 2years using fbprohpet","1699f8f1":"# Auto_Arima","d79f79fb":"<a id=\"dapap\"><\/a>","dfbc2175":"with the use of SARIMAX the prediction is clearly more accurate and predicts better seasonal components than ARIMA !\n\nLet's try the 8,1,5 combination and compare both combination","fc4fdb02":"If our data is fully stationary we should get random residuals so that model gives accurate results.\nwith n=1, we can see that residuals are not random and with the presence of the seasonal trend then after seasonal De-trend we get random residuals.and results did improve.\n","8c133200":"We can use this method to check for the best combination with respect to AIC.\n\nthe model with the least AIC is the best suited\n","1011f1c1":"moreover we can see the correlation in the timeseries with autocorrelation","a60626a4":"<a id=\"ds\"><\/a>\n# Differentiate data and check stationarity","5da4900f":"<a id=\"awsdawst\"><\/a>","371d8020":"Impressive results though there is no difference between SARIMAX(1, 1, 1)x(1, 1, 0, 12) and SARIMAX(1, 1, 1)x(1, 1, 1, 12) but it's a good way to infer the more appropriate model and check if we did the good choice. ","7bd7d013":"# ARIMA with Stationary Data and removing seasonal Trend","4bf9eb6a":"from these figures we can see that sales are experiencing some growth over the years\nand we can see seasonality occurs in the last 3 months ","0af600b5":"# FBprophet\n<a id=\"fb\"><\/a>","942cea51":"# ACF, PACF and Autocorrelation plots:\nAfter a time series has been stationarized by differencing, the next step in fitting an ARIMA model is to determine whether AR or MA terms are needed to correct any autocorrelation that remains in the differenced series, and will try some different combinations of terms and see what works best. By looking at the autocorrelation function (ACF) and partial autocorrelation (PACF) \n","c7bc50e8":"Before going for fbprophet let's try this package auto_arima which will search automatically for better combinations of with respect to AIC.\n<a id=\"aa\"><\/a>","66904f28":"**KPSS Test**\n<a id=\"kpss\"><\/a>","f782f7ca":"It looks even better ! let's confirm this by evaluating the mean absolute percent error \n\n\n\n\n"}}