{"cell_type":{"c08cc659":"code","d1f5b081":"code","6b1074db":"code","451b7232":"code","6ffe0144":"code","ea32a84c":"code","437d3d33":"code","595a7990":"code","7e1cca27":"code","805058ae":"code","1cc54e1c":"code","2474b843":"code","cadb3cf3":"code","0943c758":"code","edb93a65":"code","7349846b":"code","03d766e2":"code","64c93c99":"code","4f4d7e53":"code","6d03e634":"code","da4ac4b3":"code","bfacc574":"markdown","a4a198f8":"markdown","c0a84051":"markdown","c6aa1825":"markdown","3a9063c6":"markdown","213408b4":"markdown","18198a74":"markdown","3de9fed4":"markdown","916bd171":"markdown","ad6e3498":"markdown","8d47cbc7":"markdown","c0fde57b":"markdown","e9655b17":"markdown"},"source":{"c08cc659":"import warnings\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.preprocessing import StandardScaler\n# Preprocessing :\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom itertools import product\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_tree\nfrom sklearn.manifold import TSNE\nimport time\nfrom pandas import datetime\nfrom statsmodels.tsa.arima_model import ARIMA\n\n#Cloustering\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import KMeans","d1f5b081":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6b1074db":"warnings.filterwarnings('ignore')","451b7232":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","6ffe0144":"test.head()","ea32a84c":"#X_Train = train.drop('target', axis=1)\nX_Test = test.drop('id', axis=1).values\n#Y_Train = train['target']\nX_Test = StandardScaler().fit_transform(X_Test)","437d3d33":"train.head()\n#print(train.shape)","595a7990":"X_Train = train.drop('target', axis=1)\nX_Train = X_Train.drop('id', axis=1).values\nY_Train = train['target']\nX_Train = StandardScaler().fit_transform(X_Train)","7e1cca27":"plt.figure(figsize = (20,15))\ncorr=test.corr()\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)","805058ae":"plt.figure(figsize = (20,15))\ncorr=train.corr()\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)","1cc54e1c":"trainedmodel = LogisticRegression().fit(X_Train,Y_Train)\npredictions =trainedmodel.predict(X_Test)","2474b843":"print(predictions)","cadb3cf3":"trainedtree = tree.DecisionTreeClassifier().fit(X_Train, Y_Train)\npredictionstree = trainedtree.predict(X_Test)","0943c758":"import graphviz\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\ndata = export_graphviz(trainedtree,out_file=None,feature_names=test.drop(['id'], axis = 1).columns,\n                       class_names=['0', '1'],  \n                       filled=True, rounded=True,  \n                       max_depth=2,\n                       special_characters=True)\ngraph = graphviz.Source(data)\ngraph","edb93a65":"treepre = predictions\nprint(treepre)","7349846b":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = treepre\nsubmission.to_csv('submission.csv', index=False)","03d766e2":"model = XGBClassifier()\n\n# Train\nmodel.fit(X_Train, Y_Train)\n\nplot_tree(model)\nplt.figure(figsize = (50,55))\nplt.show()","64c93c99":"pca = PCA(n_components=2,svd_solver='full')\nX_reduced = pca.fit_transform(X_Train)\nX_test_reduced = pca.fit_transform(X_Test)","4f4d7e53":"reduced_data = X_reduced\n\ntrainednb = GaussianNB().fit(reduced_data, Y_Train)\ntrainedsvm = svm.LinearSVC().fit(reduced_data, Y_Train)\ntrainedforest = RandomForestClassifier(n_estimators=700).fit(reduced_data,Y_Train)\ntrainedmodel = LogisticRegression().fit(reduced_data,Y_Train)\n\n# Thanks to: https:\/\/scikit-learn.org\/stable\/auto_examples\/ensemble\/plot_voting_decision_regions.html\n\nx_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\ny_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                     np.arange(y_min, y_max, 0.1))\n\nf, axarr = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(10, 8))\n\nfor idx, clf, tt in zip(product([0, 1], [0, 1]),\n                        [trainednb, trainedsvm, trainedforest, trainedmodel],\n                        ['Naive Bayes Classifier', 'SVM',\n                         'Random Forest', 'Logistic Regression']):\n\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    \n\n    axarr[idx[0], idx[1]].contourf(xx, yy, Z,cmap=plt.cm.coolwarm, alpha=0.4)\n    axarr[idx[0], idx[1]].scatter(reduced_data[:, 0], reduced_data[:, 1], c=Y_Train,\n                                  s=20, edgecolor='k')\n    axarr[idx[0], idx[1]].set_title(tt)\n\nplt.show()","6d03e634":"kmeans = KMeans(n_clusters=2, random_state=0).fit(X_reduced)\nkpredictions = kmeans.predict(X_test_reduced)","da4ac4b3":"plt.scatter(X_test_reduced[kpredictions ==0,0], X_test_reduced[kpredictions == 0,1], s=100, c='red')\nplt.scatter(X_test_reduced[kpredictions ==1,0], X_test_reduced[kpredictions == 1,1], s=100, c='black')","bfacc574":"**PCA (Principal Component Analysis)**","a4a198f8":"# Cloustering","c0a84051":"**Logistic Regression**","c6aa1825":"**Decision Tree**","3a9063c6":"**K-Means Cloustering**","213408b4":"# Machine Learning","18198a74":"# Test-Set","3de9fed4":"# Training-Set","916bd171":"# Importing Libraries and Preprocessing","ad6e3498":"# Data Analysis","8d47cbc7":"# Instant Gratification Challenge","c0fde57b":"# Dimensionality Reduction","e9655b17":"**XGBC**"}}