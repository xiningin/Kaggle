{"cell_type":{"76661baf":"code","49be0ff7":"code","4ef40abb":"code","012d713d":"code","1f806aa2":"code","ecbf7b08":"code","c98f196f":"code","49c9671f":"code","c508e47e":"code","0ae6b604":"code","a1669566":"code","83442bab":"markdown","84e54c30":"markdown","93c1f6e3":"markdown","d9640f5e":"markdown","7abe1886":"markdown","abe5e018":"markdown","be62e5b6":"markdown","d0dace87":"markdown","d98071bc":"markdown","419f389b":"markdown","49048e10":"markdown","16a27521":"markdown","56d68715":"markdown","a591d7c3":"markdown"},"source":{"76661baf":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.feature_engineering_new.ex2 import *\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.feature_selection import mutual_info_regression\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\n\n# Load data\ndf = pd.read_csv(\"..\/input\/fe-course-data\/ames.csv\")\n\n\n# Utility functions from Tutorial\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","49be0ff7":"features = [\"YearBuilt\", \"MoSold\", \"ScreenPorch\"]\nsns.relplot(\n    x=\"value\", y=\"SalePrice\", col=\"variable\", data=df.melt(id_vars=\"SalePrice\", value_vars=features), facet_kws=dict(sharex=False),\n);","4ef40abb":"# View the solution (Run this cell to receive credit!)\nq_1.check()","012d713d":"X = df.copy()\ny = X.pop('SalePrice')\n\nmi_scores = make_mi_scores(X, y)","1f806aa2":"print(mi_scores.head(20))\n# print(mi_scores.tail(20))  # uncomment to see bottom 20\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores.head(20))\n# plot_mi_scores(mi_scores.tail(20))  # uncomment to see bottom 20","ecbf7b08":"# View the solution (Run this cell to receive credit!)\nq_2.check()","c98f196f":"sns.catplot(x=\"BldgType\", y=\"SalePrice\", data=df, kind=\"boxen\");","49c9671f":"# YOUR CODE HERE: \nfeature = \"GrLivArea\"\n\nsns.lmplot(\n    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n);","c508e47e":"# YOUR CODE HERE: \nfeature = \"MoSold\"\n\nsns.lmplot(\n    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n);","0ae6b604":"# View the solution (Run this cell to receive credit!)\nq_3.check()","a1669566":"mi_scores.head(10)","83442bab":"-------------------------------------------------------------------------------\n\nThe *Ames* dataset has seventy-eight features -- a lot to work with all at once! Fortunately, you can identify the features with the most potential.\n\nUse the `make_mi_scores` function (introduced in the tutorial) to compute mutual information scores for the *Ames* features:\n","84e54c30":"Still, the type of a dwelling seems like it should be important information. Investigate whether `BldgType` produces a significant interaction with either of the following:\n\n```\nGrLivArea  # Above ground living area\nMoSold     # Month sold\n```\n\nRun the following cell twice, the first time with `feature = \"GrLivArea\"` and the next time with `feature=\"MoSold\"`:","93c1f6e3":"# Introduction #\n\nIn this exercise you'll identify an initial set of features in the [*Ames*](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\/data) dataset to develop using mutual information scores and interaction plots.\n\nRun this cell to set everything up!","d9640f5e":"# 1) Understand Mutual Information\n\nBased on the plots, which feature do you think would have the highest mutual information with `SalePrice`?","7abe1886":"Now examine the scores using the functions in this cell. Look especially at top and bottom ranks.","abe5e018":"Do you recognize the themes here? Location, size, and quality. You needn't restrict development to only these top features, but you do now have a good place to start. Combining these top features with other related features, especially those you've identified as creating interactions, is a good strategy for coming up with a highly informative set of features to train your model on.\n\n# Keep Going #\n\n[**Start creating features**](https:\/\/www.kaggle.com\/ryanholbrook\/creating-features) and learn what kinds of transformations different models are most likely to benefit from.","be62e5b6":"-------------------------------------------------------------------------------\n\nTo start, let's review the meaning of mutual information by looking at a few features from the *Ames* dataset.","d0dace87":"# 3) Discover Interactions\n\nFrom the plots, does `BldgType` seem to exhibit an interaction effect with either `GrLivArea` or `MoSold`?","d98071bc":"The trend lines being significantly different from one category to the next indicates an interaction effect.","419f389b":"# A First Set of Development Features #\n\nLet's take a moment to make a list of features we might focus on. In the exercise in Lesson 3, you'll start to build up a more informative feature set through combinations of the original features you identified as having high potential.\n\nYou found that the ten features with the highest MI scores were:","49048e10":"**This notebook is an exercise in the [Feature Engineering](https:\/\/www.kaggle.com\/learn\/feature-engineering) course.  You can reference the tutorial at [this link](https:\/\/www.kaggle.com\/ryanholbrook\/mutual-information).**\n\n---\n","16a27521":"-------------------------------------------------------------------------------\n\nIn this step you'll investigate possible interaction effects for the `BldgType` feature. This feature describes the broad structure of the dwelling in five categories:\n\n> Bldg Type (Nominal): Type of dwelling\n>\t\t\n>       1Fam\tSingle-family Detached\t\n>       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n>       Duplx\tDuplex\n>       TwnhsE\tTownhouse End Unit\n>       TwnhsI\tTownhouse Inside Unit\n\nThe `BldgType` feature didn't get a very high MI score. A plot confirms that the categories in `BldgType` don't do a good job of distinguishing values in `SalePrice` (the distributions look fairly similar, in other words):","56d68715":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/221677) to chat with other Learners.*","a591d7c3":"# 2) Examine MI Scores\n\nDo the scores seem reasonable? Do the high scoring features represent things you'd think most people would value in a home? Do you notice any themes in what they describe? "}}