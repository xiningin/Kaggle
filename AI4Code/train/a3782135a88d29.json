{"cell_type":{"ef3f03b3":"code","042d8351":"code","aeeaed85":"code","23c15d62":"code","8ee48651":"code","1a3a1931":"code","f795b2ea":"code","a91cbc6f":"code","388f7ea7":"code","4057acd6":"code","5527241e":"code","865b7bb1":"code","43948f63":"code","afc0be60":"code","b973787d":"code","8f565491":"code","5ac8d256":"code","80229764":"code","2b456fce":"code","2fed787f":"code","480edecb":"code","f63c4aa0":"code","05249c20":"code","ec0cf322":"code","d546a9dd":"code","18a44f95":"code","ca5cd6cd":"code","ff57405a":"code","9c525d76":"markdown","777b1067":"markdown","9e03de3a":"markdown","06521c4d":"markdown","489d613e":"markdown","d0bab6e3":"markdown","16467419":"markdown","caa84b3b":"markdown","a10848ca":"markdown","133c2a51":"markdown","cf79ce16":"markdown","3c5b7f6f":"markdown","ff0374f3":"markdown","61171930":"markdown","1f06f445":"markdown","a050d45d":"markdown","d5e4fd70":"markdown","6a86a8dc":"markdown","4f0914a7":"markdown","b22ad939":"markdown","930c6bee":"markdown","a47dd0aa":"markdown"},"source":{"ef3f03b3":"#!pip uninstall -qy keras tensorflow\n#!pip uninstall -qy h5py numpy opencv-python\n#!pip install -qU keras tensorflow\n#!pip install -qU opencv-python \"numba<0.49\" \"numpy<19.0\" \"h5py<2.11\" backports.cached-property imgaug keras-segmentation scikit-learn \"matplotlib~=3.2.0\" keras-unet \"imgaug>=0.4.0\" \"tornado>5.1\" pynvml\n#!pip install -q keras==2.3.1 tensorflow==2.1.0 keras_applications==1.0.8 image-classifiers==1.0.0 efficientnet==1.0.0 gast==0.3.2 tensorboard==2.3.0\n!pip install -q segmentation_models","042d8351":"%env SM_FRAMEWORK=tf.keras\n\nimport json\nimport os\nimport pathlib\n\nfrom datetime import datetime\nfrom enum import Enum\nfrom glob import glob\nfrom math import ceil\nfrom dataclasses import dataclass, field\n\nimport numpy as np\nimport sklearn as sk\nimport sklearn.model_selection\nimport cv2 as cv\nimport tensorflow as tf\nimport tensorflow.keras as kr\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport multiprocessing as mp\nimport segmentation_models as sm\n\nfrom typing import Tuple, List, Dict, Any, Callable, Union, Iterator, Iterable","aeeaed85":"print(\"tensorflow version: {}\".format(tf.__version__))\nprint(\"keras version: {}\".format(kr.__version__))\nprint(\"available gpu: {}\".format(tf.test.gpu_device_name()))","23c15d62":"SEED = abs(hash(\"cookies\")) \/\/ 2**32\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","8ee48651":"EXPERIMENT_NAME = \"densenet121_tilling_256_final\"\nBACKBONE = \"densenet121\"\nPREPROCESSING_MASK_LIMITS_HSV = ((30,40,70), (80,255,255))\nIMAGES_PER_BATCH = 4\nINPUT_SIZE = (256,256)\nIMAGE_SUBSET = (3, 4)\nEPOCHS = 15","1a3a1931":"EXPERIMENT =\"{}_{}\".format(datetime.now().strftime(\"%m-%d_%H-%M\"), EXPERIMENT_NAME)","f795b2ea":"PATH_DATA = pathlib.Path(\"\/kaggle\/input\/\") \/ \"rose-eval-2019\"\n\nPATH_WORKING = pathlib.Path(\"\/kaggle\/working\")\n\nPATH_TRAINING = PATH_DATA \/ \"training\"\nPATH_TEST = PATH_DATA \/ \"test\"\nPATH_TEST_FINAL = PATH_DATA \/ \"test_final\"\n\nPATH_EXPERIMENT = PATH_WORKING \/ EXPERIMENT\n\nPATH_SUBMISSION = PATH_EXPERIMENT \/  \"submission.json\"\nPATH_SUBMISSION_ZIP = PATH_EXPERIMENT \/  \"{}.zip\".format(EXPERIMENT)","a91cbc6f":"os.makedirs(PATH_EXPERIMENT, exist_ok=True)","388f7ea7":"# defines the images' paths\nPATHS_TRAINING_IMAGES = [\n    *list((PATH_TRAINING).rglob(\"**\/Images\/*\")),\n    *list((PATH_TEST).rglob(\"**\/Images\/*\")),\n    #*list((PATH_TRAINING \/ \"Bipbip\").rglob(\"*\/Images\/*\")),\n    #*list((PATH_TRAINING \/ \"Weedelec\").rglob(\"*\/Images\/*\"))\n    #*list((PATH_TRAINING \/ \"Bipbip\" \/ \"Mais\" \/ \"Images\").rglob(\"*\")),\n    #*list((PATH_TRAINING \/ \"Roseau\" \/ \"Mais\" \/ \"Images\").rglob(\"*\")),\n    #*list((PATH_TRAINING \/ \"Weedelec\" \/ \"Mais\" \/ \"Images\").rglob(\"*\"))\n]\n\n# retieves the corresponding masks' paths\nPATHS_TRAINING_MASKS = [f.parents[1] \/ \"Masks\" \/ (f.stem + \".png\") for f in PATHS_TRAINING_IMAGES]\n\n# retrieves test images\nPATHS_TEST = [\n    *list((PATH_TEST_FINAL).rglob(\"**\/Images\/*\")),\n    #*list(PATH_TEST.rglob(\"*.jpg\")),\n    #*list(PATH_TEST.rglob(\"*.png\"))\n]\n\nprint(\"Found {} training images\".format(len(PATHS_TRAINING_IMAGES)))\nprint(\"Found {} test images\".format(len(PATHS_TEST)))","4057acd6":"mpl.rcParams['image.cmap'] = 'gray'\ndef show(*args):\n    \"\"\"\n    Showes input images in one row\n    \"\"\"\n    s = 10\n    _, axs = plt.subplots(1, len(args), figsize=(s*len(args),s*1.6))\n    \n    for i in range(len(args)):\n        axs[i].imshow(args[i])\n    plt.show()\n\ndef rescale(image):\n    \"\"\"\n    Rescales an image in a viewable image\n    ex. [-1.,1.] -> [0.,1.]\n    \"\"\"\n    mi, ma =  np.min(image), np.max(image)\n    \n    image = (image - mi) * 1. \/ (ma-mi)\n    \n    return image","5527241e":"import time\nclass Timer:\n    \"\"\"\n    Utility to test code speed\n    \"\"\"\n    def __init__(self):\n        self._begin = 0.\n        self._last = 0.\n    def start(self):\n        self._begin = time.perf_counter()\n        self._last = self._begin\n        return self\n    def check(self):\n        l, self._last = self._last, time.perf_counter()\n        return self._last - l\n    def pcheck(self, name=\"from last checkpoint\"):\n        print(\"{} {}s\".format(name,self.check()))","865b7bb1":"@dataclass\nclass ImageMeta:\n    \"\"\"\n    Class to store image metadata\n    \"\"\"\n    index: int\n    path: pathlib.Path\n    original_size: Tuple[int, int]\n    subset_amount: Tuple[int, int]\n    resized_size: Tuple[int, int] = None\n    subset_size: Tuple[int, int] = None\n    subsets: List[Tuple[int, int, int, int]] = field(init=False)\n\n    def __post_init__(self):\n        if self.resized_size is None:\n            self.resized_size = (self.subset_size[0] * self.subset_amount[0],self.subset_size[1] * self.subset_amount[1])\n        elif self.subset_size is None:\n            self.subset_size = (self.subset_size[0] \/\/ self.subset_amount[0],self.subset_size[1] \/\/ self.subset_amount[1])\n        \n        # generates the subsets for the patches\n        self.subsets = [(\n            y*self.subset_size[0], (y+1)*self.subset_size[0],\n            x*self.subset_size[1], (x+1)*self.subset_size[1]\n        )for y in range(self.subset_amount[0]) for x in range(self.subset_amount[1])]","43948f63":"class CustomDataset(tf.keras.utils.Sequence):\n    _seed = SEED\n\n    def __init__(self,\n                 paths_images: List[str],\n                 paths_masks: List[str] = None,\n                 image_data_generator_options: Dict = None,\n                 preprocessing_function: Callable[[np.array], np.array] = lambda x: x,\n                 postprocessing_function: Callable[[np.array], np.array] = lambda x: x,\n                 mask_decoding_function: Callable[[np.array], np.array] = lambda x: x,\n                 image_size: Tuple[int, int] = (256, 256),\n                 images_per_batch: int = 1,\n                 image_subset: Tuple[int,int] = (1,1),\n                 shuffle: bool = False\n                ):\n        '''\n        :param paths_images: A list of images' paths\n        :param paths_masks: The list of corresponding masks' paths or None if this is a prediction dataset\n        :param image_data_generator_options: The configuration for augmetnation generator\n        :param preprocessing_function: The preprocessing function is applies to the images before augumentation and resizing phases\n        :param postprocessing_function: The postprocessing function is applies to the images after the augmentation and resizing phases\n        :param mask_decoding_function: The decoding function is used to deconding mask files\n        :param image_size: The size of the output patches\n        :param images_per_batch: The number of images per batch, with 0 the batch will contain the whole dataset\n        :param image_subset: The number of the rows and columns to split images\n        :param shuffle: If it is True at each epoch the data are shuffled\n        '''\n        self._paths_images = paths_images\n        self._paths_masks = paths_masks\n        self._preprocessing_function = preprocessing_function\n        self._postprocessing_function = postprocessing_function\n        self._mask_decoding_function = mask_decoding_function\n        self._images_per_batch = images_per_batch\n        self._image_size = image_size\n        self._image_subset = image_subset\n        self._shuffle = shuffle\n        \n        self._transform_generator = self._get_transform_generator()\n        \n        # creates the list of the images indexes\n        self._indexes = np.arange(len(paths_images))\n        # shuffles them if required\n        if self._shuffle:\n            np.random.shuffle(self._indexes)\n        \n        self._image_data_generator = None\n        self._mask_data_generator = None\n        if image_data_generator_options is not None:\n            # creates a new generator for image augmentation\n            self._image_data_generator = kr.preprocessing.image.ImageDataGenerator(**image_data_generator_options)\n            # for mask generator remove the fill_mode to prevent creation of fake element in the mask\n            image_data_generator_options[\"fill_mode\"]=\"nearest\"\n            self._mask_data_generator = kr.preprocessing.image.ImageDataGenerator(**image_data_generator_options)\n        \n        # creates an empty list for the images metadata\n        self._images_meta = [None for _ in self._paths_images]\n\n    def __len__(self):\n        if self._images_per_batch == 0:\n            return 1\n        \n        return ceil(len(self._paths_images) \/ self._images_per_batch)\n\n    def __getitem__(self, batch_index: int) -> Union[np.array, Tuple[np.array, np.array]]:\n        batch_images=[]\n        batch_masks=[]\n        \n        # retrieves the subset of the images in the batch\n        batch_indexes = self._indexes if self._images_per_batch == 0 else self._indexes[batch_index * self._images_per_batch:(1 + batch_index) * self._images_per_batch]\n        \n        for i in batch_indexes:\n            if len(self._indexes) <= i:\n                break\n            \n            # gets the i-th image and mask patches \n            images, masks = self._get_data(i)\n            \n            batch_images += images\n            \n            if masks is not None:\n                batch_masks += masks\n        \n        # returns only the image batch if this is a prediction dataset\n        if self._paths_masks is None:\n            return np.array(batch_images)\n        \n        return np.array(batch_images), np.array(batch_masks)\n    \n    def _get_data(self, index: int) -> Tuple[np.array, Union[np.array, None]]:        \n        # loads the image from file\n        image = plt.imread(self._paths_images[index], np.uint8)\n        \n        # retrieves meta data for the image\n        if self._images_meta[index] is None:\n            self._images_meta[index] = ImageMeta(index, self._paths_images[index],\n                                                 original_size=image.shape[0:2],\n                                                 subset_size=self._image_size,\n                                                 subset_amount=self._image_subset)\n        meta = self._images_meta[index]\n        \n        # resizes image\n        image = cv.resize(image, meta.resized_size[::-1], cv.INTER_LINEAR)\n        \n        # applies the preprocessing function to the image\n        image = self._preprocessing_function(image)\n\n        transf_image, transf_mask = None, None\n        if self._image_data_generator is not None:\n            # gets a transformation\n            transf_image, transf_mask = next(self._transform_generator)\n\n            # applies the transformation to mask and image\n            image = self._image_data_generator.apply_transform(image, transf_image)\n        \n        # applies postprocessing function to the image\n        image = self._postprocessing_function(image)\n        \n        # splits image in patches\n        subset_images = []\n        for (y0,y1,x0,x1) in meta.subsets:\n            subset_images.append(image[y0:y1,x0:x1])\n        \n        # if this is a prediction dataset skips the processing of the mask\n        if self._paths_masks is None:\n            return subset_images, None\n        \n        # loads the mask from file\n        mask = plt.imread(self._paths_masks[index], np.uint8)\n        \n        # decodes the mask\n        mask = self._mask_decoding_function(mask)\n        \n        # resizes the mask\n        mask = cv.resize(mask, meta.resized_size[::-1], interpolation=cv.INTER_NEAREST)\n        \n        if transf_mask is not None:\n            # applies the transformation to mask\n            mask = self._mask_data_generator.apply_transform(mask, transf_mask)\n            \n            # removes the error given by interpolation\n            mask = np.round(mask)\n        \n        # splits the mask into patches\n        subset_masks = []\n        for (y0,y1,x0,x1) in meta.subsets:\n            subset_masks.append(mask[y0:y1,x0:x1])\n        \n        return subset_images, subset_masks\n    \n    def on_epoch_end(self) -> None:\n        # at each epoch end shuffles the images if required \n        if self._shuffle:\n            np.random.shuffle(self._indexes)\n\n    def _get_transform_generator(self):\n        # retrives a pseudo-random transformation from a generator for images and masks\n        while True:\n            yield (self._image_data_generator.get_random_transform(self._image_size, seed=CustomDataset._seed), \n                    self._mask_data_generator.get_random_transform(self._image_size, seed=CustomDataset._seed))\n            CustomDataset._seed += 1","afc0be60":"class MaskDecoding:\n    \"\"\"\n    Provides the function to decode mask files\n    \"\"\"\n    def __init__(self, include_ground: bool = True, merge_channels: bool = False):\n        \"\"\"\n        :param include_ground: If True create a channel (the last) also fo the background\n        :param merge_channels: if True use the sparse categories codification else use one-hot codification\n        \"\"\"\n        \n        self._include_ground = include_ground\n        self._merge_channels = merge_channels\n        \n        assert (not (self._include_ground and self._merge_channels)), \"include_ground and merge_channels both True will not give the expected result\"\n        \n    def __call__(self, mask: np.array) -> np.array:\n        # finds the pixels for crop and weed\n        channels = [\n            np.all(mask==[255,255,255],axis=2)[...,np.newaxis],\n            np.all(mask==[216, 67, 82],axis=2)[...,np.newaxis]\n        ]\n        \n        # if required creates a channel also for the background (include also the other channel) \n        if self._include_ground:\n            channels += [np.logical_or(np.all(mask==[0,0,0],axis=2), np.all(mask==[254,124,18],axis=2))[:,:,np.newaxis]]\n        \n        # create a single matrix with all the channels\n        mask = np.concatenate(channels, axis=2)\n        \n        # if required merges all the channels in one, with an unique value for each original channel\n        if self._merge_channels:\n            # generates a new array with the same size of the original mask \n            new_mask = np.zeros((*mask.shape[0:2],1), dtype=np.float)\n\n            # adds channels to new array on a single channel\n            for i in range(mask.shape[-1]):\n                new_mask[:,:,0] += mask[:,:,i] * (i + 1)\n\n            mask = new_mask\n\n        return mask.astype(dtype=np.float32)","b973787d":"def preprocessing_image(image: np.array) -> np.array:\n    \"\"\"\n    This function provide a simplified version of giveng image, removing a lot of background, not necessaried for the classification\n    \"\"\"\n    # changes the space color to hsv\n    image_hsv = cv.cvtColor(image.astype(np.uint8), cv.COLOR_RGB2HSV)\n\n    # filters the target color in the hsv space\n    designed_mask = cv.inRange(image_hsv, *PREPROCESSING_MASK_LIMITS_HSV)\n\n    # removes the small artifcat in the mask\n    denoised_mask = cv.morphologyEx(designed_mask, cv.MORPH_OPEN, cv.getStructuringElement(cv.MORPH_RECT, (7,7)))\n\n    # expands the target areas\n    dilatated_mask = cv.dilate(denoised_mask, np.ones((11,11),np.uint8), iterations = 5)\n\n    # removes all the not targeted content in the image\n    image_masked = cv.bitwise_and(image, image, mask = dilatated_mask)\n\n    return image_masked","8f565491":"# retirieves the prprocessing function for the net\npreprocessing_function = sm.get_preprocessing(BACKBONE)\n\n# defines a set of images augmention rules\ngenerator_options = dict(\n                rotation_range=20,\n                zoom_range=0.15,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                shear_range=0.15,\n                horizontal_flip=True,\n                fill_mode=\"constant\"\n            )\n\n# splits training and validation set\ndataset = sk.model_selection.train_test_split(PATHS_TRAINING_IMAGES,\n                                              PATHS_TRAINING_MASKS,\n                                              test_size=0.2,\n                                              random_state=SEED)\n\n# creates the training and validation dataset\nds_training = CustomDataset(\n    dataset[0],\n    dataset[2],\n    image_data_generator_options=generator_options,\n    preprocessing_function=preprocessing_image,\n    postprocessing_function=preprocessing_function,\n    mask_decoding_function=MaskDecoding(include_ground=True),\n    image_size=INPUT_SIZE,\n    images_per_batch=IMAGES_PER_BATCH,\n    image_subset=IMAGE_SUBSET,\n    shuffle=True\n)\nds_validation = CustomDataset(\n    dataset[1],\n    dataset[3],\n    image_data_generator_options=generator_options,\n    preprocessing_function=preprocessing_image,\n    postprocessing_function=preprocessing_function,\n    mask_decoding_function=MaskDecoding(include_ground=True),\n    image_size=INPUT_SIZE,\n    images_per_batch=IMAGES_PER_BATCH,\n    image_subset=IMAGE_SUBSET,\n    shuffle=True\n)\n\n# creates the test dataset\nds_test = CustomDataset(\n    PATHS_TEST,\n    preprocessing_function=preprocessing_image,\n    postprocessing_function=preprocessing_function,\n    image_size=INPUT_SIZE,\n    images_per_batch=IMAGES_PER_BATCH,\n    image_subset=IMAGE_SUBSET,\n)\n\nprint(\"{} images for training\".format(len(dataset[0])))\nprint(\"{} images for validation\".format(len(dataset[1])))\nprint(\"{} images to test\".format(len(PATHS_TEST)))","5ac8d256":"images, masks = ds_training[0]\nfor i in np.random.choice(images.shape[0], 3):\n    show(rescale(images[i]), masks[i,...,-3], masks[i,...,-2], masks[i,...,-1])","80229764":"def get_callbacks(\n                  save_model: bool = True,\n                  checkpoints: bool = False,\n                  tensorboard: bool = True,\n                  early_stopping: bool = True\n                  ) -> List[kr.callbacks.Callback]:\n    \"\"\"\n    Returns a list of desidered callbacks for the fit process\n    \"\"\"\n    callbacks = []\n    \n    if save_model:\n        os.makedirs(PATH_EXPERIMENT \/ \"model\", exist_ok=True)\n        callbacks.append(kr.callbacks.ModelCheckpoint(str(PATH_EXPERIMENT \/ \"model\"), save_best_only=True, mode='min'))\n\n    if checkpoints:\n        # if they are requesed, checkpoints will be saved in a specific experiment subdirecotry\n        os.makedirs(PATH_EXPERIMENT \/ \"checkpoints\", exist_ok=True)\n\n        callbacks.append(kr.callbacks.ModelCheckpoint(\n            str(PATH_EXPERIMENT \/ \"checkpoints\" \/ \"cp-{epoch:04d}.ckpt\")\n        ))\n\n    if tensorboard:\n        # if they are required, tensorboard files will be generated\n        os.makedirs(PATH_EXPERIMENT \/ \"tb_log\", exist_ok=True)\n\n        callbacks.append(kr.callbacks.TensorBoard(\n            PATH_EXPERIMENT \/ \"tb_log\",\n            histogram_freq=1,\n            profile_batch=0\n        ))\n    if early_stopping:\n        callbacks.append(kr.callbacks.EarlyStopping(\n            patience=5,\n            restore_best_weights=True\n        ))\n\n    return callbacks","2b456fce":"# retrieves a trained model form Segmentation_models module\nmodel = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=3, activation=\"softmax\", input_shape=(*INPUT_SIZE, 3))\n\n# define optimizer\noptim = kr.optimizers.Adam(1e-4)\n\n# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n# set class weights for dice_loss (crop: 1.; weed: 1.; background: .25;)\ndice_loss = sm.losses.DiceLoss(class_weights=np.array([1., 1., 0.25])) \nfocal_loss = sm.losses.CategoricalFocalLoss()\ntotal_loss = dice_loss + (1 * focal_loss)\n\n# defines the metrics, we only need meanIOU for the first two categories that the sm module provides \nmetrics = [\n    sm.metrics.IOUScore(threshold=0.5, class_indexes=[0,1])\n]\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, total_loss, metrics)\n\nmodel.summary()","2fed787f":"# starts the model training\ntraining_history = model.fit(\n    ds_training,\n    validation_data=ds_validation,\n    epochs=EPOCHS,\n    callbacks=get_callbacks()\n)","480edecb":"# Plot training & validation iou_score values\nplt.figure(figsize=(30, 5))\nplt.subplot(121)\nplt.plot(training_history.history['iou_score'])\nplt.plot(training_history.history['val_iou_score'])\nplt.title('Model iou_score')\nplt.ylabel('iou_score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(training_history.history['loss'])\nplt.plot(training_history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","f63c4aa0":"# computes the prediction exploiting the trained model\ntest_output = model.predict(ds_test)","05249c20":"# find the category with highest score for each pixel\nprediction = np.argmax(test_output,axis=-1)\n\n# recompose the 3 channels with no intersection and only 0. and 1.\nprediction = np.concatenate((\n    np.array(prediction == 0, dtype=np.uint8)[...,np.newaxis],\n    np.array(prediction == 1, dtype=np.uint8)[...,np.newaxis],\n    np.array(prediction == 2, dtype=np.uint8)[...,np.newaxis]\n), axis=-1)","ec0cf322":"prediction_iter=iter(list(prediction))\nrecomposed_prediction=[]\n\n# for each images in the test dataset get the masks tiles and recomposed them in the original image shape\nfor index in ds_test._indexes:\n    meta = ds_test._images_meta[index]\n    \n    masks=np.full((*meta.resized_size, 3), (0,0,0), dtype=np.uint8)\n    \n    for (y0,y1,x0,x1) in meta.subsets:\n        masks[y0:y1,x0:x1] = next(prediction_iter)\n    \n    recomposed_prediction.append(masks)","d546a9dd":"for i in np.random.choice(ds_test._indexes, 3):\n    show(plt.imread(ds_test._paths_images[i]), recomposed_prediction[i][...,0], recomposed_prediction[i][...,1], recomposed_prediction[i][...,2])","18a44f95":"def rle_encode(img):\n    '''\n    img: numpy array, 1 - foreground, 0 - background\n    Returns run length as string formatted\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","ca5cd6cd":"submission = {}\nfor m in ds_test._images_meta:\n    resized_masks = cv.resize(recomposed_prediction[m.index], dsize=m.original_size[::-1], interpolation=cv.INTER_NEAREST)\n    \n    submission[m.path.stem] = {\n        \"shape\": m.original_size,\n        \"crop\": m.path.parents[1].stem,\n        \"team\": m.path.parents[2].stem,\n        \"segmentation\": {\n            \"crop\": rle_encode(resized_masks[...,0]),\n            \"weed\": rle_encode(resized_masks[...,1])\n        }\n    }\n\nwith open(PATH_SUBMISSION, \"w\") as file:\n    json.dump(submission, file)","ff57405a":"from zipfile import ZipFile\nwith ZipFile(PATH_SUBMISSION_ZIP, \"w\") as f:\n    f.write(PATH_SUBMISSION, arcname = PATH_SUBMISSION.name)","9c525d76":"## Submission","777b1067":"Sets SEED to avoid randomness into dataset generator","9e03de3a":"Retrieves the dependencies:\n- [segmentation models](https:\/\/github.com\/qubvel\/segmentation_models)","06521c4d":"# Main","489d613e":"### Prediction recomposition\n\nThe predition tiles have to been recomposed in the shape of the original image","d0bab6e3":"Generates the **submission.json**","16467419":"### Training","caa84b3b":"### Utility","a10848ca":"Zips the submission file for the submission","133c2a51":"### Creation of the model","cf79ce16":"### Dataset tools","3c5b7f6f":"### creation of the report","ff0374f3":"### Dataset generation","61171930":"### Definition callbacks","1f06f445":"Defines base path","a050d45d":"## Model","d5e4fd70":"Defines the experiment configuration","6a86a8dc":"Cretes images list for the dataset","4f0914a7":"### Prediction","b22ad939":"## Dataset","930c6bee":"### Prediction processing","a47dd0aa":"## Initialization"}}