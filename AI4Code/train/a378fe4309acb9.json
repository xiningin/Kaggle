{"cell_type":{"22dd160d":"code","78c9f528":"code","a53c7771":"code","94c955b4":"code","77d234a2":"code","6ff63df6":"code","18e1e425":"code","09616582":"code","308f4791":"code","82f3d6bc":"markdown","4f6a00c9":"markdown","61fa50ff":"markdown","f0bfa0cb":"markdown","1e2d7bbe":"markdown"},"source":{"22dd160d":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers,Model,Sequential\n!pip install -q git+https:\/\/github.com\/tensorflow\/examples.git\nfrom tensorflow_examples.models.pix2pix import pix2pix\nfrom IPython.display import clear_output","78c9f528":"inputs = tf.keras.Input(shape=[256, 256, 3])\n\nbase_model =tf.keras.applications.MobileNetV2(input_shape=(256,256,3),weights='imagenet', include_top=False)\n# \u4f7f\u7528\u8fd9\u4e9b\u5c42\u7684\u6fc0\u6d3b\u8bbe\u7f6e\nlayer_names = [\n    'block_1_expand_relu',   # 64x64\n    'block_3_expand_relu',   # 32x32\n    'block_6_expand_relu',   # 16x16\n    'block_13_expand_relu',  # 8x8\n    'block_16_project',      # 4x4\n]\nskip_connect_layers = [base_model.get_layer(name).output for name in layer_names]\n# \u521b\u5efa\u7279\u5f81\u63d0\u53d6\u6a21\u578b\nencoder = tf.keras.Model(inputs=base_model.input, outputs=skip_connect_layers)\nencoder.trainable = False\n\ndecoder = [\n    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n]\ndef unet_model(output_channels,crop=False):\n    '''\n    crop\u53c2\u6570:True,\u8f93\u51famask\u4e0e\u539f\u56fe\u50cf\u8fdb\u884c\u63a9\u819c\u8fd0\u7b97\uff0c\u7f51\u7edc\u8f93\u51fa(none,h,w,3);\n            False,\u8f93\u51famask\u4e0d\u8fdb\u884c\u63a9\u819c\u8fd0\u7b97\uff0c\u7f51\u7edc\u8f93\u51fa(none,h,w,output_channels)\n    '''\n    x = inputs\n    # \u5728\u6a21\u578b\u4e2d\u964d\u9891\u53d6\u6837\n    skips = encoder(x)#\u4eceencoder\u4e2d\u5f15\u51fa\u591a\u4e2askip\u8fde\u63a5\u5c42\uff08\u5305\u542bbottleneck\uff09\n    x = skips[-1] #\u8fd9\u662fbottleneck\n    skips = reversed(skips[:-1]) #\u9664\u4e86bottleneck\u5916\u5176\u4f59skip \u5c42\n    # \u5347\u9891\u53d6\u6837\u7136\u540e\u5efa\u7acb\u8df3\u8dc3\u8fde\u63a5\n    for up, skip in zip(decoder, skips):\n        x = up(x)\n        #concat = tf.keras.layers.Concatenate()\n        x = tf.concat([x, skip],axis=-1)\n  # \u8fd9\u662f\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\n    last = layers.Conv2DTranspose(\n        output_channels, 3, strides=2,\n        padding='same',activation='sigmoid')  #64x64 -> 128x128\n    x = last(x)\n    \n    return Model(inputs=inputs, outputs=x)","a53c7771":"gen=unet_model(output_channels=1)#generator\ngen.summary()","94c955b4":"from tensorflow.keras.regularizers import l1,l2\nclass ConvBlock(layers.Layer):\n    '''\u5e26BN>>>Leaky relu\u6fc0\u6d3b\u7684\u5377\u79ef\u5757'''\n    def __init__(self,num_filters, kernel_size, strides=1,use_bn=True):\n        super(ConvBlock,self).__init__()\n        self.use_bn=use_bn\n        self.conv=layers.Conv2D(num_filters, kernel_size, strides,\n                      padding='same',kernel_initializer='he_uniform',\n                      kernel_regularizer=l1(0.01), use_bias=not self.use_bn)\n        self.bn = layers.BatchNormalization()\n        self.relu = layers.LeakyReLU(0.2)\n\n    def call(self,x):\n        x=self.conv(x)\n        if self.use_bn:\n            x=self.bn(x)\n        return self.relu(x)\n\ndef Critic(input_x,name='discriminator'):\n    '''\n    \u4e3b\u8981\u7528\u4e8e\u8ba1\u7b97Multi-scale loss,\u5bf9\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u7684feature map\u90fd\u8fdb\u884c\u4e86L1 loss\u8ba1\u7b97\uff0c\u53d6\u5e73\u5747\n    inputs:input image (none,h,w,3)\n    return:critic model\n    '''\n    shared1=ConvBlock(num_filters=64,kernel_size=7, strides=2,use_bn=False)(input_x)\n    shared2=ConvBlock(num_filters=128,kernel_size=5, strides=2,use_bn=True)(shared1)\n    shared3=ConvBlock(num_filters=256,kernel_size=4, strides=2,use_bn=True)(shared2)\n    shared4=ConvBlock(num_filters=512,kernel_size=4, strides=2,use_bn=True)(shared3)\n    #############\u4ee5\u4e0b\u662f\u6e90\u7801\u7684critic\u7ed3\u6784,\u989d\u5916\u591a\u4e86\u4e24\u4e2afeature map##############################\n    shared5=ConvBlock(num_filters=512,kernel_size=4, strides=2,use_bn=True)(shared4)\n    shared6=ConvBlock(num_filters=512,kernel_size=3, strides=2,use_bn=True)(shared5)\n    #flatten all feature map\uff0cthen concat them together\n    \n    feats_out=tf.concat([layers.Flatten()(input_x),1*layers.Flatten()(shared1),\n                         2*layers.Flatten()(shared2),2*layers.Flatten()(shared3),\n                         2*layers.Flatten()(shared4)],axis=-1)\n    return Model(inputs=input_x,outputs=feats_out)\n\n#disc=Critic(gen.output)\nx=tf.keras.Input(shape=[256, 256, 3])\ndisc=Critic(x)\n\ndisc.summary()","77d234a2":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom glob import glob\nfrom tqdm import tqdm","6ff63df6":"imgs_path = glob('..\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/images\/*.png')\nmasks_path = glob('..\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/masks\/*.png')\n\nimgs_path = sorted(imgs_path,key=lambda x:os.path.basename(x).split('_')[1:])\nmasks_path = sorted(masks_path,key=lambda x:os.path.basename(x).split('_')[1:])\nlen(imgs_path)==len(masks_path)\n\ndef load_img(img_path):\n    image = tf.io.read_file(img_path)\n    #image = tf.io.decode_image(image,channels=3,expand_animations=False,dtype='float32')\n    image = tf.io.decode_png(image,channels=3)\n    image = image[90:450,150:406,:]\n    image = tf.image.resize(image,[256, 256],#resize to target size\n                    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    return image\n@tf.function()\ndef preprocess(img_path,mask_path):\n    image=load_img(img_path)\n    mask =load_img(mask_path)\n    image=tf.cast(image,'float32')\n    mask = tf.cast(mask,'bool')\n    mask = tf.cast(mask,'float32')#mask\u4e3a\u8868\u793a\u6bcf\u4e2a\u50cf\u7d20\u7684categorical label\n    \n    image \/= 255. \n    if tf.random.uniform(()) > 0.5:\n        image=tf.image.flip_left_right(image)#\u968f\u673a\u5de6\u53f3\u7ffb\u8f6c\n        mask=tf.image.flip_left_right(mask)\n    #\u66f4\u591a\u6570\u636e\u589e\u5f3a\u65b9\u5f0f\u5f85\u8865\u5145\u5e94\u7528\n    return image,mask[:,:,:1]#\u4ec5\u9700\u8981\u5355\u901a\u9053\u6570\u636e\n\ntrain_set=tf.data.Dataset.from_tensor_slices((imgs_path[:1000],masks_path[:1000]))\ntrain_set=train_set.map(preprocess,num_parallel_calls=-1).shuffle(1000).batch(16)\ntest_set =tf.data.Dataset.from_tensor_slices((imgs_path[1000:],masks_path[1000:]))\ntest_set=test_set.map(preprocess,num_parallel_calls=-1).batch(16)","18e1e425":"gen_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)#generator\ndisc_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)#critic model\n\ndef dice_loss(pred_mask,gt_mask):\n    '''\u8ba1\u7b97GT Mask\u4e0eGenerator\u8f93\u51famask\u7684dice loss'''\n    pred_mask=layers.Flatten()(pred_mask)\n    gt_mask =layers.Flatten()(gt_mask)\n    gt_mask =tf.cast(gt_mask,'float32')\n    intersection = tf.math.reduce_sum(pred_mask*gt_mask)\n    \n    return 1-(2*intersection +1.0)\/(tf.math.reduce_sum(gt_mask) + tf.math.reduce_sum(pred_mask) + 1.0)\n\n@tf.function\ndef train_Critic_step(imgs, masks):\n    '''\u8bad\u7ec3Critic\u7684step\uff0c\u6700\u5927\u5316loss\uff0c\u4ee5\u63d0\u9ad8Critic\u9274\u522b\u80fd\u529b'''\n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        \n        pred_mask_ = gen(imgs, training=True)#gen\u8f93\u51fa\u9884\u6d4b\u7684mask\n\n        gt_mask=layers.multiply([imgs,masks])#gt_mask*imgs\n        pred_mask=layers.multiply([imgs,pred_mask_])#pred_mask*imgs\n        \n        gt_output=disc(gt_mask)#gt_mask*imgs\u7ecfcritic\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\n        pred_output=disc(pred_mask)#pred_mask*imgs\u7ecfcritic\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\n\n        #################\u8ba1\u7b97L1 loss\uff0c\u6ce8\u610f\u53d6-1*loss################MAX Critic loss\n        #################\u6b64\u5904\u53d6\u7684\u6b63loss\uff0c-1*loss\u8bad\u7ec3loss\u4f1a\u5f88\u7206\u70b8########################\n        l1_loss = tf.keras.losses.MAE(pred_output,gt_output)#\u5bf9\u6bcf\u4e2abatch\u5206\u522b\u8ba1\u7b97L1 LOSS\n        l1_loss = tf.reduce_mean(l1_loss)#\u8ba1\u7b97\u6574\u4e2abatch L1 LOSS\u7684\u5747\u503c\n        \n    ##########################\u8bad\u7ec3critic model,\u5219gen model\u53c2\u6570\u4e0d\u5fc5\u66f4\u65b0############\n    #gen_gradients = gen_tape.gradient(l1_loss,gen.trainable_variables)#\u8ba1\u7b97\u68af\u5ea6\n    #gen_optimizer.apply_gradients(zip(gen_gradients,gen.trainable_variables))#\u53cd\u5411\u4f20\u64ad\n    \n    disc_gradients = disc_tape.gradient(l1_loss,disc.trainable_variables)#\u8ba1\u7b97\u68af\u5ea6\n    disc_optimizer.apply_gradients(zip(disc_gradients,disc.trainable_variables))#\u53cd\u5411\u4f20\u64ad\n    \n    return l1_loss\n\n@tf.function\ndef train_Generator_step(imgs, masks):\n    '''\u8bad\u7ec3Generator\u7684step\uff0c\u6700\u5c0f\u5316loss\uff0c\u4ee5\u63d0\u9ad8Generator\u751f\u6210True mask\u80fd\u529b'''\n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        \n        pred_mask_ = gen(imgs, training=True)#gen\u8f93\u51fa\u9884\u6d4b\u7684mask\n\n        gt_mask=layers.multiply([imgs,masks])#gt_mask*imgs\n        pred_mask=layers.multiply([imgs,pred_mask_])#pred_mask*imgs\n        \n        gt_output=disc(gt_mask)#gt_mask*imgs\u7ecfcritic\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\n        pred_output=disc(pred_mask)#pred_mask*imgs\u7ecfcritic\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\n        #################\u8ba1\u7b97GT Mask\u4e0eGenerator\u8f93\u51famask\u7684dice loss###############\n        dice_losses=dice_loss(pred_mask_,masks)\n        #################\u8ba1\u7b97L1 loss################\n        l1_loss = tf.keras.losses.MAE(pred_output,gt_output)#\u53d6\u6b63\u503c\uff0cminimize GEN loss\n        \n        joint_loss=dice_losses + tf.reduce_mean(l1_loss)\n        \n    gen_gradients = gen_tape.gradient(joint_loss,gen.trainable_variables)#\u8ba1\u7b97\u68af\u5ea6\n    gen_optimizer.apply_gradients(zip(gen_gradients,gen.trainable_variables))#\u53cd\u5411\u4f20\u64ad\n    \n    ##########################\u8bad\u7ec3generator model,\u5219critic model\u53c2\u6570\u4e0d\u5fc5\u66f4\u65b0############\n    #disc_gradients = disc_tape.gradient(joint_loss,disc.trainable_variables)#\u8ba1\u7b97\u68af\u5ea6\n    #disc_optimizer.apply_gradients(zip(disc_gradients,disc.trainable_variables))#\u53cd\u5411\u4f20\u64ad\n    \n    return joint_loss\n","09616582":"#\u4fee\u6539\u7248\ndef train(num_epochs,lr=2e-4,decay=0.5):\n    '''\n    Generator\u8bad\u7ec3\u5b8c\u4e00\u4e2aepoch\uff0cCritic\u5e94\u8be5\u8bad\u7ec3\u591a\u4e2aepoch,maybe 5\n    decay:\u5b66\u4e60\u7387\u8870\u51cf\u7cfb\u6570\uff0c\u7b2c25\u4e2aepoch\u540e\u5f00\u59cb\u5e94\u7528\uff0c\u521d\u59cb\u5b66\u4e60\u73872e-4\n    \u4f18\u5316\u5668\u5207\u6362\u518d\u8bad\u7ec3\u591a\u4e2aepoch\u540e\uff0c\u7531Adam>>>SGD\n    '''\n    total_loss_C,total_loss_G=[],[]\n    for epoch in range(num_epochs):\n        \n        ###########test_set_visualize for every epoch begining################\n        for test_img,test_mask in test_set.take(1):\n            pred_mask=gen(test_img)\n            \n            #iou=tf.keras.metrics.MeanIoU(num_classes=2)\n            #iou.update_state(test_mask,pred_mask)#sample_weight=[0.2,0.8])\n            #tf.print(\"Mean IoU =\", iou.result().numpy())\n            \n            plt.figure(figsize=(15,15))\n            for i in range(16):\n                plt.subplot(4,4,i+1)\n                dst=np.vstack((pred_mask[i],test_mask[i]))\n                plt.imshow(dst)\n            plt.show()\n            \n        l1_losses_C=[]\n        #disc.trainable=True#activate Critic model\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0capply_gradients\u5b9e\u73b0\n        for step,(imgs,masks) in tqdm(enumerate(train_set)):\n            \n            #\u4e00\u4e2abatch\u6570\u636e\u5b8c\u6210\u4e00\u6b21\u68af\u5ea6\u66f4\u65b0>>>train_step\n            l1_loss=train_Critic_step(imgs,masks)\n            #print('l1_loss:',l1_loss.numpy())\n            l1_losses_C.append(l1_loss)\n            #print('l1_losses_C:',l1_losses_C)\n            \n            if step%5==0:\n                #\u6bcf\u969450\u4e2abatch \u8ba1\u7b97\u4e00\u6b21loss\n                #tf.print('current Critic loss is:',tf.reduce_mean(l1_losses_C))\n                total_loss_C.append(tf.reduce_mean(l1_losses_C))\n                l1_losses_C=[]#\u8ba1\u7b97\u4e00\u6b21loss\u540e\uff0c\u6e05\u7a7aloss\u7f13\u5b58\uff0c\u7d2f\u79ef\u4e0b\u4e00\u6b21loss\u8ba1\u7b97\n        \n        disc.trainable=False#fixed Critic model,\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0capply_gradients\u5b9e\u73b0\n        tf.print('Critic model has been trained {} epoch'.format(epoch+1))\n        tf.print('Start training Generator now!')\n        \n        l1_losses_G=[]\n        for step,(imgs,masks) in tqdm(enumerate(train_set)):\n            \n            l1_loss=train_Generator_step(imgs,masks)\n            #print('l1_loss:',l1_loss.numpy())\n            l1_losses_G.append(l1_loss.numpy())\n            #print('l1_losses_G:',l1_losses_G)\n            if step%5==0:\n                #\u6bcf\u969450\u4e2abatch \u8ba1\u7b97\u4e00\u6b21loss\n                #tf.print('current Generator loss is:',tf.reduce_mean(l1_losses_G))\n                total_loss_G.append(tf.reduce_mean(l1_losses_G))\n                l1_losses_G=[]\n        #######################\u6bcf\u969410\u4e2aepoch,model.val############################33\n        #for test_img,test_mask in test_set.take(1): \u524d\u9762\u5df2\u7ecf\u63d0\u53d6\u4e86\u6d4b\u8bd5\u96c6\u6570\u636e\n        if epoch % 2 == 0:\n            pred_mask_=gen(test_img)\n            pred_mask_=tf.where(pred_mask_>=0.5,1,0)\n            iou=tf.keras.metrics.MeanIoU(num_classes=2)\n            iou.update_state(test_mask,pred_mask_)#sample_weight=[0.2,0.8])\n            tf.print(\"Mean IoU =\", iou.result().numpy())\n        \n        #######################\u5230epoch>=25\u5f00\u59cb\u5b66\u4e60\u7387\u8c03\u6574############################33\n        if epoch % 5 == 0:\n\n            lr = lr*decay\n            if lr <= 0.00000001:\n                lr = 0.00000001\n            tf.print('Learning Rate: {:.6f}'.format(lr))\n            # print('K: {:.4f}'.format(k))\n            #tf.print('Max mIoU: {:.4f}'.format(max_iou))\n            \n        ############\u8bad\u7ec3\u5b8c\u4e00\u6bb5\u65f6\u95f4\u540e\uff0c\u4f18\u5316\u5668\u5207\u6362\u4e3aSGD#######################\n        if epoch ==10:\n            gen_optimizer = tf.keras.optimizers.SGD(lr)#generator\n            disc_optimizer = tf.keras.optimizers.SGD(lr)#critic model\n        # Display metrics at the end of each epoch.\n        #train_acc = metrics.result()\n        #print(\"Training Mean IOU over epoch: %.4f\" % (float(train_acc)))\n        # Reset training metrics at the end of each epoch\n        #metrics.reset_states()\n    \n    return total_loss_G,total_loss_C\n\nG_loss,C_loss=train(num_epochs=20,lr=2e-4,decay=0.5)","308f4791":"plt.plot(G_loss,label='Generator loss')\nplt.plot(C_loss,label='Crtic loss')\nplt.title('U-NET GAN Training loss')\nplt.legend()","82f3d6bc":"\u521b\u5efadiscriminator","4f6a00c9":"# \u8bad\u7ec3\u8fc7\u7a0b","61fa50ff":"def train(num_epochs,lr=2e-4,decay=0.5):\n    '''\n    Generator\u8bad\u7ec3\u5b8c\u4e00\u4e2aepoch\uff0cCritic\u5e94\u8be5\u8bad\u7ec3\u591a\u4e2aepoch,maybe 5\n    decay:\u5b66\u4e60\u7387\u8870\u51cf\u7cfb\u6570\uff0c\u7b2c25\u4e2aepoch\u540e\u5f00\u59cb\u5e94\u7528\uff0c\u521d\u59cb\u5b66\u4e60\u73872e-4\n    \u4f18\u5316\u5668\u5207\u6362\u518d\u8bad\u7ec3\u591a\u4e2aepoch\u540e\uff0c\u7531Adam>>>SGD\n    '''\n    total_loss_C,total_loss_G=[],[]\n    for epoch in range(num_epochs):\n        \n        ###########test_set_visualize for every epoch begining################\n        for test_img,test_mask in test_set.take(1):\n            pred_mask=gen(test_img)\n            \n            #iou=tf.keras.metrics.MeanIoU(num_classes=2)\n            #iou.update_state(test_mask,pred_mask)#sample_weight=[0.2,0.8])\n            #tf.print(\"Mean IoU =\", iou.result().numpy())\n            \n            plt.figure(figsize=(15,15))\n            for i in range(16):\n                plt.subplot(4,4,i+1)\n                dst=np.vstack((pred_mask[i],test_mask[i]))\n                plt.imshow(dst)\n            plt.show()\n            \n        l1_losses_C=[]\n        \n        #disc.trainable=True#activate Critic model\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0capply_gradients\u5b9e\u73b0\n        for step,(imgs,masks) in tqdm(enumerate(train_set)):\n            \n            #\u4e00\u4e2abatch\u6570\u636e\u5b8c\u6210\u4e00\u6b21\u68af\u5ea6\u66f4\u65b0>>>train_step\n            l1_loss=train_Critic_step(imgs,masks)\n            #print('l1_loss:',l1_loss.numpy())\n            l1_losses_C.append(l1_loss)\n            #print('l1_losses_C:',l1_losses_C)\n            \n            if step%50==0:\n                #\u6bcf\u969450\u4e2abatch \u8ba1\u7b97\u4e00\u6b21loss\n                tf.print('current Critic loss is:',tf.reduce_mean(l1_losses_C))\n                total_loss_C.append(tf.reduce_mean(l1_losses_C))\n        \n        disc.trainable=False#fixed Critic model,\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0capply_gradients\u5b9e\u73b0\n        tf.print('Critic model has been trained {} epoch'.format(epoch+1))\n        tf.print('Start training Generator now!')\n        \n        l1_losses_G=[]\n        for step,(imgs,masks) in tqdm(enumerate(train_set)):\n            \n            l1_loss=train_Generator_step(imgs,masks)\n            #print('l1_loss:',l1_loss.numpy())\n            l1_losses_G.append(l1_loss.numpy())\n            #print('l1_losses_G:',l1_losses_G)\n            if step%50==0:\n                #\u6bcf\u969450\u4e2abatch \u8ba1\u7b97\u4e00\u6b21loss\n                tf.print('current Generator loss is:',tf.reduce_mean(l1_losses_G))\n                total_loss_G.append(tf.reduce_mean(l1_losses_G))\n        #######################\u6bcf\u969410\u4e2aepoch,model.val############################33\n        #for test_img,test_mask in test_set.take(1): \u524d\u9762\u5df2\u7ecf\u63d0\u53d6\u4e86\u6d4b\u8bd5\u96c6\u6570\u636e\n        if epoch % 10 == 0:\n            pred_mask_=gen(test_img)\n            pred_mask_=tf.where(pred_mask_>=0.5,1,0)\n            iou=tf.keras.metrics.MeanIoU(num_classes=2)\n            iou.update_state(test_mask,pred_mask_)#sample_weight=[0.2,0.8])\n            tf.print(\"Mean IoU =\", iou.result().numpy())\n        \n        #######################\u5230epoch>=25\u5f00\u59cb\u5b66\u4e60\u7387\u8c03\u6574############################33\n        if epoch % 5 == 0:\n\n            lr = lr*decay\n            if lr <= 0.00000001:\n                lr = 0.00000001\n            tf.print('Learning Rate: {:.6f}'.format(lr))\n            # print('K: {:.4f}'.format(k))\n            #tf.print('Max mIoU: {:.4f}'.format(max_iou))\n            \n        ############\u8bad\u7ec3\u5b8c\u4e00\u6bb5\u65f6\u95f4\u540e\uff0c\u4f18\u5316\u5668\u5207\u6362\u4e3aSGD#######################\n            gen_optimizer = tf.keras.optimizers.SGD(lr)#generator\n            disc_optimizer = tf.keras.optimizers.SGD(lr)#critic model\n        # Display metrics at the end of each epoch.\n        #train_acc = metrics.result()\n        #print(\"Training Mean IOU over epoch: %.4f\" % (float(train_acc)))\n        # Reset training metrics at the end of each epoch\n        #metrics.reset_states()\n    \n    return total_loss_G,total_loss_C\n\nG_loss,C_loss=train(5,lr=2e-4,decay=0.5)","f0bfa0cb":"# \u6570\u636e\u96c6\u5904\u7406\u9884\u52a0\u8f7d","1e2d7bbe":"**Generator \u548c Critic model\u7684\u8bad\u7ec3\u8fc7\u7a0b\u662f\u5404\u81ealoss\u7684Min<->Max\u8fc7\u7a0b**"}}