{"cell_type":{"fb23f31e":"code","7b7d3a25":"code","dfc006d4":"code","9a3c4aca":"code","16e718e8":"code","9932404a":"code","a94b8072":"code","64cab258":"code","6357996b":"code","63216f58":"code","10ac5d10":"code","4764e237":"code","983faed5":"code","9582151b":"code","57e0f1ae":"code","169e890b":"code","4f46d394":"code","85c9457f":"code","97fff9ae":"code","c68bb1c1":"code","8b35578a":"code","1a78845a":"code","13640d87":"code","7303482f":"code","da89210e":"code","81005039":"code","98b91461":"code","717406da":"code","6fc26a3f":"code","4e5fa7e2":"code","99de3c5e":"code","b24f65f8":"markdown"},"source":{"fb23f31e":"import torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\nimport torchvision\nfrom torchvision import transforms, utils\n\nimport glob\nimport os","7b7d3a25":"en_dict = {}\npath = '..\/input\/quickdraw-doodle-recognition\/train_simplified'\n\nfilenames = glob.glob(os.path.join(path, '*.csv'))\n\nfilenames[:5]","dfc006d4":"def encode_labels():\n    counter = 0\n    for fn in filenames:\n        en_dict[fn[:-4].split('\/')[-1].replace(' ', '_')] = counter\n        counter += 1","9a3c4aca":"encode_labels()","16e718e8":"dec_dict = {v: k for k , v in en_dict.items()}\n\ndef decode_labels(label):\n    return dec_dict[label]","9932404a":"decode_labels(181)","a94b8072":"def get_label(nfile):\n    #print(nfile[:-4].split('\/')[-1].replace(' ', '_'))\n    return en_dict[nfile[:-4].split('\/')[-1].replace(' ', '_')]","64cab258":"get_label(\"..\/input\/quickdraw-doodle-recognition\/train_simplified\/The Eiffel Tower.csv\")","6357996b":"import pandas as pd\na = pd.read_csv('..\/input\/quickdraw-doodle-recognition\/train_simplified\/The Eiffel Tower.csv').head().iloc[0]['drawing']\na.split(']]')","63216f58":"import ast\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nnew = ast.literal_eval(a)\nnew[0]\n\ntime_color = True\n\nBASE_SIZE=256\nlw = 6\n\nimg = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\nfor t, stroke in enumerate(new):\n#     print(stroke)\n    for i in range(len(stroke[0]) - 1):\n        color = 255 - min(t,10) * 13 if time_color else 255\n        _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i+1], stroke[1][i+1]), color, lw)\n\nplt.imshow(img)","10ac5d10":"class DoodleDataset(Dataset):\n    def __init__(self, csv_file, root_dir, mode='train', nrows=1000, skiprows=None, size=256, transform=None):\n        self.root_dir = root_dir\n        file = os.path.join(root_dir, csv_file)\n        self.size=size\n        self.mode = mode\n        self.doodle = pd.read_csv(file, usecols=['drawing'], nrows=nrows, skiprows=skiprows)\n        self.transform = transform\n        if self.mode == 'train':\n            self.label = get_label(csv_file)\n    \n    @staticmethod\n    def _draw(raw_strokes, size=256, lw=6, time_color=True):\n        BASE_SIZE = 256\n        img = np.zeros((BASE_SIZE, BASE_SIZE),np.uint8 )\n        \n        for t, stroke in enumerate(raw_strokes):\n            for i in range(len(stroke[0]) - 1):\n                color = 255 - min(t,10) * 13 if time_color else 255\n                _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i+1], stroke[1][i+1]), color, lw)\n        \n        if size != BASE_SIZE:\n            return cv2.resize(img, (size, size))\n        \n        else:\n            return img\n    \n    def __len__(self):\n        return len(self.doodle)\n    \n    def __getitem__(self, index):\n        raw_strokes = ast.literal_eval(self.doodle.drawing[index])\n        sample = self._draw(raw_strokes, size=self.size, lw=2, time_color=True)\n        \n        if self.transform:\n            sample = self.transform(sample)\n        \n        if self.mode == 'train':\n            return (sample[None]\/255).astype('float32'), self.label\n        else:\n            return (sample[None]\/255).astype('float32')\n        ","4764e237":"SIZE = 224\nselect_nrows= 10000\n\ndoodles = ConcatDataset([DoodleDataset(fn.split('\/')[-1], path, mode='train', nrows=select_nrows, skiprows=None, size=SIZE, transform=None) for fn in filenames])\n","983faed5":"print(len(doodles))\n\ntrain_dataloader = DataLoader(doodles, batch_size=128, shuffle=True, num_workers=0)","9582151b":"def imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n\nfor images, label in train_dataloader:\n    break\n    ","57e0f1ae":"plt.figure(figsize=(16,24))\nimshow(torchvision.utils.make_grid(images[:24]))","169e890b":"def validation(get_loader,lossfn, scorefn):\n    model.eval()\n    loss, score = 0,0\n    vlen = len(get_loader)\n    \n    for X , y in get_loader:\n        X = X.to(device)\n        y = y.to(device)\n        output = model(X)\n        \n        loss += lossfn(output, y).item()\n        score += scorefn(output, y)[0].item()\n        \n    model.train()\n    return loss\/vlen, score\/vlen","4f46d394":"def accuracy(output, target, topk=(3,)):\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n        \n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1,-1).expand_as(pred))\n        \n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0,keepdim=True)\n            res.append(correct_k.mul_(100.0\/batch_size))\n        return res","85c9457f":"def mapk(output, target, k=3):\n    \"\"\"\n    Computes the mean average precision at k.\n    \n    Parameters\n    ----------\n    output (torch.Tensor): A Tensor of predicted elements.\n                           Shape: (N,C)  where C = number of classes, N = batch size\n    target (torch.int): A Tensor of elements that are to be predicted. \n                        Shape: (N) where each value is  0\u2264targets[i]\u2264C\u22121\n    k (int, optional): The maximum number of predicted elements\n    \n    Returns\n    -------\n    score (torch.float):  The mean average precision at k over the output\n    \"\"\"\n    with torch.no_grad():\n        batch_size = target.size(0)\n\n        _, pred = output.topk(k, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n\n        for i in range(k):\n            correct[i] = correct[i]*(k-i)\n            \n        score = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n        score.mul_(1.0 \/ (k * batch_size))\n        return score","97fff9ae":"a = torch.randn(10,2,220,200)\n\nk=5\na[:k].view(-1)","c68bb1c1":"model = torchvision.models.resnet18(pretrained=True)","8b35578a":"def squeeze_weights(m):\n    m.weight.data = m.weight.data.sum(dim=1)[:,None]\n    m.in_channels = 1\n\nmodel.conv1.apply(squeeze_weights)\n\nnum_classes = 340\n\nmodel.fc = nn.Linear(512, out_features=num_classes, bias=True)","1a78845a":"%%time\nmodel(torch.randn(12,1,224,224)).size()","13640d87":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = model.to(device)","7303482f":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.002, amsgrad = True)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000, 12000, 18000], gamma=0.5)","da89210e":"%%time\nepochs = 1\nlsize = len(train_dataloader)\nprint(f\"size of train : {lsize}\")\nitr =1\np_itr = 1000\nmodel.train()\ntloss, score =0,0\nfor epoch in range(epochs):\n    for X, y in train_dataloader:\n        X, y = X.to(device), y.to(device)\n        output = model(X)\n        loss = criterion(output, y)\n        tloss += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        score += mapk(output, y)[0].item()\n        scheduler.step()\n        \n        if itr %p_itr ==0 :\n            print('Iteration {} -> Train Loss: {:.4f}, MAP@3: {:.3f}'.format(itr, tloss\/p_itr, score\/p_itr))\n            tloss, score = 0, 0\n        itr +=1\n        if itr >= 6000:\n            break \n            #you can continue this for better model\n        ","81005039":"filename_pth = 'checkpoint_resnet18.pth'\ntorch.save(model.state_dict(), filename_pth)","98b91461":"testset = DoodleDataset('test_simplified.csv', '..\/input\/quickdraw-doodle-recognition\/', mode='test', nrows=None, size=SIZE)\ntestloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=0)","717406da":"import tqdm\n\nmodel.eval()\nmodel = model.to(device)\nlabels = np.empty((0,3))\n#labels = labels.to(device)\nfor x in tqdm.tqdm(testloader):\n    x = x.to(device)\n    output = model(x)\n    _, pred = output.topk(3, 1, True, True)\n    labels = np.concatenate([labels, pred.cpu()], axis = 0)","6fc26a3f":"%%time\nsubmission = pd.read_csv('..\/input\/quickdraw-doodle-recognition\/test_simplified.csv', index_col='key_id')\nsubmission.drop(['countrycode', 'drawing'], axis=1, inplace=True)\nsubmission['word'] = ''\nfor i, label in enumerate(labels):\n    submission.word.iloc[i] = \" \".join([decode_labels(l) for l in label])","4e5fa7e2":"submission.to_csv('submission.csv')","99de3c5e":"print(\"done\")","b24f65f8":"Taken from : https:\/\/www.kaggle.com\/leighplt\/pytorch-starter-kit"}}