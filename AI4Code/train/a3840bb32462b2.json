{"cell_type":{"c0d4f654":"code","f504aa1c":"code","fd83d7f4":"code","4a9b2db3":"code","0e8a7d96":"code","f262ec22":"code","911cc514":"code","15a7d069":"code","bd21892b":"code","c679970c":"code","c1c9185e":"code","efac7d4a":"code","de3d6e24":"code","56f18cf6":"code","ff7fb467":"code","001542d3":"code","2394c718":"code","bceedbfe":"code","7e1a451f":"code","3c30d43a":"code","61160309":"code","c5905870":"code","7ac849c3":"code","71f0f105":"code","6803b1e0":"code","7b976c50":"code","3b0f7757":"code","5edd2dbd":"code","e03287ea":"code","673fb05b":"code","9f530738":"markdown","6c9a9fe1":"markdown","fcae6b24":"markdown","56375256":"markdown","01252cf5":"markdown","6dff6f12":"markdown","7411df55":"markdown","b0ed3f0b":"markdown","e3a6905c":"markdown","05eccf34":"markdown"},"source":{"c0d4f654":"import torch\nfrom mpl_toolkits.mplot3d import Axes3D\n#from sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nfrom tqdm import tqdm\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nprint(f\"torch.__version__ = {torch.__version__}\")","f504aa1c":"ds = np.load(\"\/kaggle\/input\/ohe-sample-locus-variant-sample-names-snp-locus-names.npz\", allow_pickle=True)\n\nsample_axis = 0 # let's support two tensor layouts, defaulting to the shape (sample,locus,variant)\n\n\nlist(ds.keys())","fd83d7f4":"#%%time\nohe = ds[\"ohe\"]\nsample_names = ds[\"sample_names\"]\nsnp_locus_names = ds[\"snp_locus_names\"]\ndel ds\nprint(f\"ohe.shape = {ohe.shape} # (samples, SNP loci, variants)\")\nprint(f\"ohe.dtype = {ohe.dtype}\")","4a9b2db3":"acceleration_strategy = \"numpy\"\n\nif acceleration_strategy == \"numpy\":\n  dtype_int16 = np.int16  \nelif acceleration_strategy == \"cuda\":\n  if torch.cuda.is_available():\n    print('CUDA is available!')\n    device = torch.device(\"cuda:0\")    \n    dtype_int16 = torch.int16\n    ohe = torch.from_numpy(ohe).to(device)\nelse:\n  print('phew... no CUDA, no fun :-\/')\n  # pytorch is sometimes much slower than a plain numpy:\n  # https:\/\/discuss.pytorch.org\/t\/pytorch-much-slower-than-numpy-for-simple-arithmetics\/60757\n  # and is more RAM-aggressive:\n  # https:\/\/discuss.pytorch.org\/t\/pytorch-much-slower-than-numpy-for-simple-arithmetics\/60757\n  device = torch.device('cpu')\n  #dtype_int16 = np.int16\n  dtype_int16 = torch.int16\n  ohe = torch.from_numpy(ohe).to(device)\nprint(f\"type(ohe)={type(ohe)}\")","0e8a7d96":"def get_z(ohe, locus_variant_cnt, locus_variant_variating, locus, variant, sample_axis = sample_axis):\n  if sample_axis == 0: # typical layout: (sample, locus, variant)\n    A_hit = ohe[:,locus,variant]==1\n    ohe_l_A = ohe[A_hit,:,:] # very, very slow with PyTorch on CPU!\n  else: # vcf-ish layout: (locus,sample,variant)\n    A_hit = ohe[locus,:,variant]==1\n    ohe_l_A = ohe[:,A_hit,:]  \n  nA = ohe_l_A.shape[sample_axis]\n  #print(f'nA={nA}')\n  locus_variant_cnt_l_A = ohe_l_A.sum(axis=sample_axis, dtype=dtype_int16)\n  cnt_ohe_variating = locus_variant_cnt[locus_variant_variating] # we lose the shape here!\n  cnt_ohe_l_A_variating = locus_variant_cnt_l_A[locus_variant_variating]\n  tmp_p = (cnt_ohe_variating + cnt_ohe_l_A_variating) \/ float(ohe.shape[sample_axis] + nA)\n  z = (cnt_ohe_variating\/float(ohe.shape[sample_axis]) - cnt_ohe_l_A_variating\/float(nA)) \/ np.sqrt(\n      tmp_p*(1-tmp_p)*(1.0\/ohe.shape[sample_axis] + 1.0\/nA))\n  return z","f262ec22":"%%time\nlocus_variant_cnt = ohe.sum(axis=sample_axis, dtype=dtype_int16)\nprint(f\"locus_variant_cnt.dtype={locus_variant_cnt.dtype}\")\nprint(f\"locus_variant_cnt.shape={locus_variant_cnt.shape}\")","911cc514":"%%time\nlocus_variant_variating = locus_variant_cnt != 0\ncnt_locus_variant_variating = locus_variant_variating.sum()\nprint(locus_variant_variating.shape)\nprint(cnt_locus_variant_variating)","15a7d069":"%%time\nz = get_z(ohe, locus_variant_cnt, locus_variant_variating, locus=0, variant = 1)\nz.shape","bd21892b":"plt.rcParams['figure.figsize'] = 15,3\nplt.hist(z, 1000)\nplt.title(\"z-test for each locus-variant whether \\nP(locus,variant) = P(locus,variant|locus=0,variant=1))\")\nplt.show()","c679970c":"threshold = 4\nlv_was_neg_involved = np.zeros(cnt_locus_variant_variating, dtype=dtype_int16) # np.array(z < threshold, dtype=dtype_int16)\nlv_was_pos_involved = np.zeros(cnt_locus_variant_variating, dtype=dtype_int16) # np.array(z > threshold, dtype=dtype_int16)\n\nlv_z_pos_sum = np.zeros(cnt_locus_variant_variating, dtype=np.float)\nlv_z_neg_sum = np.zeros(cnt_locus_variant_variating, dtype=np.float)","c1c9185e":"# let's iterate over the locus-variants with the highest entropy, e.g. with probability ~= 0.5\nlvc = [(loc, variant, locus_variant_cnt[loc,variant]) for loc, variant in zip(\n    np.random.randint(ohe.shape[1], size = 2000), \n    np.random.randint(ohe.shape[2], size = 2000)) if np.abs(locus_variant_cnt[loc,variant]-850) < 200]\n\nfor l,v,c in tqdm(lvc): # [(0,1,locus_variant_cnt[0,1])] \n  z0 = get_z(ohe,locus_variant_cnt, locus_variant_variating, locus=l, variant = v)\n  #print(f\"locus={l}, variant={v}, count={c}, related found = {(np.abs(z0)>4).sum()}\")\n  #plt.hist(z0[z0.abs()>4],100)\n  #plt.show()\n  lv_z_neg_sum[z0<0] += z0[z0<0]\n  lv_z_pos_sum[z0>0] += z0[z0>0]\n  lv_was_neg_involved += np.array(z0 < -threshold, dtype = dtype_int16)\n  lv_was_pos_involved += np.array(z0 > threshold, dtype = dtype_int16)","efac7d4a":"fig,ax = plt.subplots(2,1)\nax[0].hist(lv_was_neg_involved[lv_was_neg_involved!=0], 200)\nax[1].hist(lv_was_pos_involved[lv_was_pos_involved!=0], 200)\nplt.show()","de3d6e24":"lv_was_neg_involved_as_tensor = np.zeros(locus_variant_cnt.shape)\nlv_was_neg_involved_as_tensor[locus_variant_variating] = lv_was_neg_involved\nidx = lv_was_neg_involved_as_tensor.ravel().argsort()\nprint(np.unravel_index(idx[-15:], lv_was_neg_involved_as_tensor.shape))","56f18cf6":"def print_some_superhubs(best_candidates_to_check = 100, min_neg_snp_links=100000, min_pos_snp_links = 100000, p_a_filter = lambda p: True):\n    for l,v in np.array(np.unravel_index(idx[-best_candidates_to_check:], lv_was_neg_involved_as_tensor.shape)).T:\n        if p_a_filter(locus_variant_cnt[l,v]\/ohe.shape[sample_axis]):\n            z = get_z(ohe,locus_variant_cnt, locus_variant_variating, locus=l, variant = v)\n            cnt_neg = (z < -threshold).sum()\n            cnt_pos = (z > threshold).sum()\n            if cnt_neg > min_neg_snp_links or cnt_pos > min_pos_snp_links:\n                print(f'l={l}({snp_locus_names[l]}),v={v}, Prob(l,v)={locus_variant_cnt[l,v]\/ohe.shape[sample_axis] :.3f}')\n                print(f\"outliers: left = {cnt_neg}, right = {cnt_pos}\")    \n","ff7fb467":"%%time\nprint(lv_was_neg_involved.max())\n\nprint_some_superhubs()","001542d3":"#z = get_z(ohe,locus_variant_cnt, locus_variant_variating, locus=1065678 \/\/ 4, variant = 1065678 % 4)\n#np.unravel_index(z, lv_was_neg_involved_as_tensor.shape)\n\nzidx_to_lv = np.array(locus_variant_variating.nonzero()).T\n\ndef inspect_locus_variant(locus, variant, zidx_to_lv, threshold = 4, draw_hist=True):\n    z = get_z(ohe,locus_variant_cnt, locus_variant_variating, locus, variant)\n    print(f\"locus={locus}({snp_locus_names[locus]}), variant={variant}, Prob(l,v)={locus_variant_cnt[locus, variant]\/ohe.shape[sample_axis] :.3f}\")\n    print(f\"z-range = {min(z),max(z)}\")\n    print(f\"z sorted: {np.sort(z)}\")\n    argsorted = np.argsort(z)\n    print(f\"z argsorted: {argsorted}\")\n    zargmax = z.argmax()\n    print(f\"z.argmin1() = {argsorted[1]} => {zidx_to_lv[argsorted[1]]}, 4*l+v={np.sum(np.array(zidx_to_lv[argsorted[1]])*np.array([4,1]))}\")\n    print(f\"z.argmax() = {zargmax} => {zidx_to_lv[zargmax]}, 4*l+v={np.sum(np.array(zidx_to_lv[z.argmax()])*np.array([4,1]))}\")\n    cor_with_argmin1 = np.corrcoef(ohe[:,locus, variant], # -locus_variant_cnt[locus, variant]\/ohe.shape[0], \n                                   ohe[:,zidx_to_lv[argsorted[1]][0], zidx_to_lv[argsorted[1]][1]]) # -locus_variant_cnt[zidx_to_lv[argsorted[1]][0], zidx_to_lv[argsorted[1]][1]]\/ohe.shape[0])\n    cor_with_argmax = np.corrcoef(ohe[:,locus, variant], ohe[:,zidx_to_lv[zargmax][0], zidx_to_lv[zargmax][1]])\n    print(f\"cor with argmin1 = {cor_with_argmin1[0,1]:.3f}\")\n    print(f\"cor with argmax = {cor_with_argmax[0,1]:.3f}\")\n    print(f\"number of z < {-threshold:.1f} is {(z< -threshold).sum()}\")\n    print(f\"number of z > {threshold:.1f} is {(z > threshold).sum()}\")\n    if draw_hist:\n        plt.hist(z, 500) # for the last one\n        plt.title(f\"z-test for each locus-variant whether \\nP(L,v) = P(L,v|l={locus},v={variant})\\nP(l={locus},v={variant})={round(locus_variant_cnt[locus,variant]\/ohe.shape[sample_axis],2)}\")\n        plt.show()","2394c718":"inspect_locus_variant(locus=219027, variant=3, zidx_to_lv = zidx_to_lv)","bceedbfe":"inspect_locus_variant(locus=262766, variant=3, zidx_to_lv = zidx_to_lv)","7e1a451f":"inspect_locus_variant(locus=1065678 \/\/ 4, variant = 1065678 % 4, zidx_to_lv = zidx_to_lv)","3c30d43a":"inspect_locus_variant(locus=74230 \/\/ 4, variant = 74230 % 4, zidx_to_lv = zidx_to_lv)","61160309":"%%time\nprint_some_superhubs(best_candidates_to_check=5000, min_neg_snp_links=15000, min_pos_snp_links = 15000, p_a_filter = lambda p: abs(p-0.5)<.1)","c5905870":"inspect_locus_variant(locus=128518, variant = 1, zidx_to_lv = zidx_to_lv)","7ac849c3":"inspect_locus_variant(locus= 159059, variant=1, zidx_to_lv = zidx_to_lv)","71f0f105":"inspect_locus_variant(locus=262766, variant = 3, zidx_to_lv = zidx_to_lv)","6803b1e0":"lv_zsum = np.abs(z) \n#print(lv_zsum.dtype)\nlv_was_involved = np.array(np.abs(z) > 4, dtype=dtype_int16)","7b976c50":"lvc = [(loc, variant, locus_variant_cnt[loc,variant]) for loc, variant in zip(\n    np.random.randint(ohe.shape[1], size = 5000), \n    np.random.randint(ohe.shape[2], size = 5000)) if np.abs(locus_variant_cnt[loc,variant]-850) < 200]\n\nfor l,v,c in lvc: # [(0,1,locus_variant_cnt[0,1])] \n  z0 = get_z(ohe,locus_variant_cnt, locus_variant_variating, locus=l, variant = v)\n  print(f\"locus={l}, variant={v}, count={c}, Prob(l,v)={locus_variant_cnt[l,v]\/ohe.shape[sample_axis]:%.2f}, related found = {(np.abs(z0)>4).sum()}\")\n  #plt.hist(z0[z0.abs()>4],100)\n  #plt.show()\n  lv_zsum += z0\n  lv_was_involved += np.array(np.abs(z0) > 4, dtype = dtype_int16)","3b0f7757":"plt.hist(lv_zsum, 1000)\nplt.show()","5edd2dbd":"#print(locus_variant_variating.shape)\nsome_cool_snp = np.array(locus_variant_variating.nonzero())[:,lv_was_involved>50].T\nprint(some_cool_snp)\nsnp_locus_names[some_cool_snp[:,0]]\n#lv_was_involved.shape","e03287ea":"for l,v in some_cool_snp:\n  z0 = get_z(ohe,locus_variant_cnt, locus_variant_variating, locus=l, variant = v)\n  print(f\"locus={l}, variant={v}, count={c}, related found = {(np.abs(z0)>4).sum()}\")\n","673fb05b":"plt.hist(lv_was_involved[lv_was_involved!=0], 1000)\nplt.show()","9f530738":"## Conclusion\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" button at the top of the kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling!","6c9a9fe1":"Oh, no! There are no automatic insights available for the file types used in this dataset. As your Kaggle kerneler bot, I'll keep working to fine-tune my hyper-parameters. In the meantime, please feel free to try a different dataset.","fcae6b24":"Let's mark the variating locus-variants:","56375256":"Let's calculate the z-statistic for locus-0, variant-1:\n","01252cf5":"Let's do a shallow scan for the locus-variants most involved in dependencies with other locus-variants.\nWe are going to consider here only those (l,v) that have probability ~0.5","6dff6f12":"Let's define a z-statistic for Bernoulli\/Binomial distributions","7411df55":"## Introduction\nGreetings from [Valery](https:\/\/www.kaggle.com\/valerykhamenya\/) and [Mikhail](https:\/\/www.kaggle.com\/ilfiore\/)! This is a kernel with starter code demonstrating how to start with SNP-analysis and begin exploring. Click the blue \"Fork Notebook\" button at the top of this kernel to start your own session.","b0ed3f0b":"Let's precalculate the counts for each locus-variant:","e3a6905c":"Let's load the dataset. The operation is lazy, don't get fooled by the blazing speed ;-)\n","05eccf34":"Here we'd choose the acceleration strategy, but currently we'll stick to numpy only, sorry:"}}