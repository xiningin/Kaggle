{"cell_type":{"842b2530":"code","79a11c15":"code","17e7205c":"code","210f7d55":"code","6eef7df0":"code","bf331a8b":"code","d2ff6487":"code","efeb8690":"code","74ac1736":"code","56082c16":"code","1d71c576":"code","ca748c2e":"code","556b153b":"code","b4bf6ad0":"code","98ee8e52":"code","47172818":"code","be923840":"code","312c9fe1":"code","966ebd02":"code","649e3ad6":"markdown","43b9fdd2":"markdown","6342d442":"markdown","fdef3ebb":"markdown","232c5789":"markdown","0b636644":"markdown","bc5cd20f":"markdown","9d2b4efe":"markdown","86cd60b6":"markdown"},"source":{"842b2530":"import random \nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import StandardScaler\nfrom IPython.display import display\nfrom sklearn.cluster import KMeans \nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.metrics import homogeneity_score, completeness_score, \\\nv_measure_score, adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n%matplotlib inline\n\nnp.random.seed(123)","79a11c15":"Data = pd.read_csv('..\/input\/train.csv') ","17e7205c":"Data.sample(5)","210f7d55":"print('Shape of the data set: ' + str(Data.shape))","6eef7df0":"#save labels as string\nLabels = Data['activity']\nData = Data.drop(['rn', 'activity'], axis = 1)\nLabels_keys = Labels.unique().tolist()\nLabels = np.array(Labels)\nprint('Activity labels: ' + str(Labels_keys))","bf331a8b":"#check for missing values\nTemp = pd.DataFrame(Data.isnull().sum())\nTemp.columns = ['Sum']\nprint('Amount of rows with missing values: ' + str(len(Temp.index[Temp['Sum'] > 0])) )","d2ff6487":"#normalize the dataset\nscaler = StandardScaler()\nData = scaler.fit_transform(Data)","efeb8690":"#check the optimal k value\nks = range(1, 10)\ninertias = []\n\nfor k in ks:\n    model = KMeans(n_clusters=k)\n    model.fit(Data)\n    inertias.append(model.inertia_)\n\nplt.figure(figsize=(8,5))\nplt.style.use('bmh')\nplt.plot(ks, inertias, '-o')\nplt.xlabel('Number of clusters, k')\nplt.ylabel('Inertia')\nplt.xticks(ks)\nplt.show()","74ac1736":"def k_means(n_clust, data_frame, true_labels):\n    \"\"\"\n    Function k_means applies k-means clustering alrorithm on dataset and prints the crosstab of cluster and actual labels \n    and clustering performance parameters.\n    \n    Input:\n    n_clust - number of clusters (k value)\n    data_frame - dataset we want to cluster\n    true_labels - original labels\n    \n    Output:\n    1 - crosstab of cluster and actual labels\n    2 - performance table\n    \"\"\"\n    k_means = KMeans(n_clusters = n_clust, random_state=123, n_init=30)\n    k_means.fit(data_frame)\n    c_labels = k_means.labels_\n    df = pd.DataFrame({'clust_label': c_labels, 'orig_label': true_labels.tolist()})\n    ct = pd.crosstab(df['clust_label'], df['orig_label'])\n    y_clust = k_means.predict(data_frame)\n    display(ct)\n    print('% 9s' % 'inertia  homo    compl   v-meas   ARI     AMI     silhouette')\n    print('%i   %.3f   %.3f   %.3f   %.3f   %.3f    %.3f'\n      %(k_means.inertia_,\n      homogeneity_score(true_labels, y_clust),\n      completeness_score(true_labels, y_clust),\n      v_measure_score(true_labels, y_clust),\n      adjusted_rand_score(true_labels, y_clust),\n      adjusted_mutual_info_score(true_labels, y_clust),\n      silhouette_score(data_frame, y_clust, metric='euclidean')))","56082c16":"k_means(n_clust=2, data_frame=Data, true_labels=Labels)","1d71c576":"k_means(n_clust=6, data_frame=Data, true_labels=Labels)","ca748c2e":"#change labels into binary: 0 - not moving, 1 - moving\nLabels_binary = Labels.copy()\nfor i in range(len(Labels_binary)):\n    if (Labels_binary[i] == 'STANDING' or Labels_binary[i] == 'SITTING' or Labels_binary[i] == 'LAYING'):\n        Labels_binary[i] = 0\n    else:\n        Labels_binary[i] = 1\nLabels_binary = np.array(Labels_binary.astype(int))","556b153b":"k_means(n_clust=2, data_frame=Data, true_labels=Labels_binary)","b4bf6ad0":"#check for optimal number of features\npca = PCA(random_state=123)\npca.fit(Data)\nfeatures = range(pca.n_components_)\n\nplt.figure(figsize=(8,4))\nplt.bar(features[:15], pca.explained_variance_[:15], color='lightskyblue')\nplt.xlabel('PCA feature')\nplt.ylabel('Variance')\nplt.xticks(features[:15])\nplt.show()","98ee8e52":"def pca_transform(n_comp):\n    pca = PCA(n_components=n_comp, random_state=123)\n    global Data_reduced\n    Data_reduced = pca.fit_transform(Data)\n    print('Shape of the new Data df: ' + str(Data_reduced.shape))","47172818":"# pca_transform(n_comp=3)\n# k_means(n_clust=2, data_frame=Data_reduced, true_labels=Labels)","be923840":"# colors = ['green', 'blue', 'orange', 'gray', 'pink', 'red']\n# fig = plt.figure(figsize=(12,8))\n# ax = fig.add_subplot(111, projection='3d')\n# for i in range(len(colors)):\n#     x = Data_reduced[:, 0][Labels == Labels_keys[i]]\n#     y = Data_reduced[:, 1][Labels == Labels_keys[i]]\n#     z = Data_reduced[:, 2][Labels == Labels_keys[i]]\n#     ax.scatter(xs=x, ys=y, zs=z, zdir='y', s=20, c=colors[i], alpha=0.2)\n\n# ax.set_xlabel('First Principal Component')\n# ax.set_ylabel('Second Principal Component')\n# ax.set_zlabel('Third Principal Component')\n# ax.set_title(\"PCA Scatter Plot\")\n# plt.show()","312c9fe1":"pca_transform(n_comp=1)\nk_means(n_clust=2, data_frame=Data_reduced, true_labels=Labels_binary)","966ebd02":"pca_transform(n_comp=2)\nk_means(n_clust=2, data_frame=Data_reduced, true_labels=Labels_binary)","649e3ad6":"### Dataset info\n\nHuman Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The experiments are carried out with a group of 30 volunteers within an age bracket of 19-48 years while each person performing six activities (*WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING*) wearing a smartphone (Samsung Galaxy S II) on the waist using its embedded accelerometer and gyroscope  captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiment are video-recorded to label the data manually. ","43b9fdd2":"**Inertia and Silhouette are much better  after reduction. **\n\n**check once clustering model for 2 components.**\n","6342d442":"**As the connection between clusters and original labels is poor ,stick with 2 clusters.**","fdef3ebb":"**The algorithm found patterns for Moving and Non-Moving activity with high level of accuracy.**\n\n**Lets Check how it cluster by 6 clusters (original number of classes).**","232c5789":"**No improvements here.**\n**suggestions for any interesting dataset to practice clustering are most welcome \nTHANK YOU.**\n\n*!**","0b636644":"### Principal component analysis (PCA)\n\n> Principal Component Analysis is a dimension-reduction tool that can be used to reduce a large set of variables to a small set that still contains most of the information in the large set.\n\n**2-cluster algorithm is able to find patterns for moving\/not-moving labels perfectly so far. let's see if it can further improve by dimension reduction. **","bc5cd20f":"## K-Means Clustering and PCA of Human Activity Recognition","9d2b4efe":"**here the best value (\"elbow\" of the line) for k is 2 (two clusters).**","86cd60b6":"**1 feature seems to be best fit for our algorithm.**"}}