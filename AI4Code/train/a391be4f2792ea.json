{"cell_type":{"193d26ad":"code","4a70ed29":"code","5120bdc2":"code","54e99ed4":"code","b22049bd":"code","85ebe70f":"code","9dedced2":"code","f7c026a4":"code","524c4bad":"code","cd085f84":"code","cefb706f":"code","a96bad44":"code","76de8a74":"code","148f6a83":"code","db97f98b":"code","f131f1f1":"code","37d5ba60":"code","62f34d5b":"code","62d30bd3":"code","4ab17f19":"code","09f6a23d":"code","d62d4067":"code","866188d8":"code","63b53fce":"code","4311c30e":"code","41949eed":"code","9f1ce74c":"code","7c8f92bf":"code","1fc2ffe8":"markdown","7df27e60":"markdown","964d2aa0":"markdown","54908e6c":"markdown","c9d57b39":"markdown","2f32ee0d":"markdown","8113fa4f":"markdown","a2f8c3ff":"markdown"},"source":{"193d26ad":"from skimage.io import imread\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport numpy as np\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.rcParams[\"figure.dpi\"] = 150\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})","4a70ed29":"sem_dir = Path('..') \/ 'input' \/ '3dsem'\nsem_files_df = pd.DataFrame({'path': list(sem_dir.glob('*.*'))})\nsem_files_df['id'] = sem_files_df['path'].map(lambda x: x.stem.lower())\nsem_files_df['suffix'] = sem_files_df['path'].map(\n    lambda x: x.suffix.lower()[1:])\nsem_files_df['index'] = sem_files_df['id'].map(lambda x: x[-2:])\nsem_files_df['prefix'] = sem_files_df['id'].map(lambda x: x[:5])\nsem_files_df['simple_name'] = sem_files_df.apply(\n    lambda x: '{prefix}-{suffix}'.format(**x), 1)\nimg_sem_df = sem_files_df[sem_files_df['suffix'].map(\n    lambda x: x in ['jpg', 'tif'])]\nimg_sem_df.sample(3)","5120bdc2":"img_summary_df = img_sem_df.pivot_table(index='index',\n                                        columns='prefix',\n                                        values='path',\n                                        aggfunc='first').\\\n    reset_index(drop=True)\nimg_summary_df","54e99ed4":"exp_list = img_summary_df.columns.tolist()\nprint(exp_list)","b22049bd":"c_exp = exp_list[1]\nc_img_df = img_summary_df[[c_exp]].dropna().copy()\nc_img_df.columns = ['path']\nc_img_df['base'] = c_img_df['path'].map(lambda c_path: c_path.stem)\nc_img_df['img'] = c_img_df['path'].map(\n    lambda c_path: imread(c_path, as_gray=True)[:-100])\nc_img_df.sample(2)","85ebe70f":"fig, m_axs = plt.subplots(1, len(c_img_df), figsize=(5*len(c_img_df), 5))\nfor c_ax, (_, c_row) in zip(m_axs, c_img_df.iterrows()):\n    c_ax.imshow(c_row['img'])\n    c_ax.set_title(c_row['base'])","9dedced2":"from skimage.feature import (corner_harris,\n                             corner_peaks, ORB)","f7c026a4":"descriptor_extractor = ORB(n_keypoints=1000)\n\n\ndef extract_points(in_img):\n    descriptor_extractor.detect_and_extract(in_img)\n    return {'keypoints': descriptor_extractor.keypoints,\n            'descriptors': descriptor_extractor.descriptors}\n\n\nc_img_df['descriptor'] = c_img_df['img'].map(extract_points)\nc_img_df['keypoints'] = c_img_df['descriptor'].map(lambda x: x['keypoints'])\nc_img_df['descriptors'] = c_img_df['descriptor'].map(\n    lambda x: x['descriptors'])\nc_img_df.sample(1)","524c4bad":"from skimage.feature import match_descriptors, plot_matches","cd085f84":"fig, m_axs = plt.subplots(len(c_img_df)-1, 2, figsize=(15, 5*len(c_img_df)))\nfor (ax3, ax2), (_, c_row), (_, n_row) in zip(m_axs, c_img_df.iterrows(),\n                                              c_img_df.shift(-1).dropna().iterrows()):\n    c_matches = match_descriptors(c_row['descriptors'],\n                                  n_row['descriptors'], cross_check=True)\n\n    plot_matches(ax3,\n                 c_row['img'], n_row['img'],\n                 c_row['keypoints'], n_row['keypoints'],\n                 c_matches)\n\n    ax2.plot(c_row['keypoints'][:, 0],\n             c_row['keypoints'][:, 1],\n             '.',\n             label=c_row['base'])\n\n    ax2.plot(n_row['keypoints'][:, 0],\n             n_row['keypoints'][:, 1],\n             '.',\n             label=n_row['base'])\n\n    for i, (c_idx, n_idx) in enumerate(c_matches):\n        x_vec = [c_row['keypoints'][c_idx, 0], n_row['keypoints'][n_idx, 0]]\n        y_vec = [c_row['keypoints'][c_idx, 1], n_row['keypoints'][n_idx, 1]]\n        dist = np.sqrt(np.square(np.diff(x_vec))+np.square(np.diff(y_vec)))\n        alpha = np.clip(50\/dist, 0, 1)\n\n        ax2.plot(\n            x_vec,\n            y_vec,\n            'k-',\n            alpha=alpha,\n            label='Match' if i == 0 else ''\n        )\n\n    ax2.legend()\n\n    ax3.set_title(r'{} $\\rightarrow$ {}'.format(c_row['base'], n_row['base']))","cefb706f":"last_idx = {}\ntrack_list = []\nidx_offset = c_img_df['keypoints'].map(len).sum()+1\nfor frame_idx, ((_, c_row), (_, n_row)) in enumerate(\n    zip(c_img_df.iterrows(),\n        c_img_df.shift(-1).dropna().iterrows())):\n\n    c_matches = match_descriptors(c_row['descriptors'],\n                                  n_row['descriptors'], cross_check=True)\n    next_idx = {}\n\n    for i, (c_idx, n_idx) in enumerate(c_matches):\n        x_vec = [c_row['keypoints'][c_idx, 0], n_row['keypoints'][n_idx, 0]]\n        y_vec = [c_row['keypoints'][c_idx, 1], n_row['keypoints'][n_idx, 1]]\n        dist = np.sqrt(np.square(np.diff(x_vec))+np.square(np.diff(y_vec)))[0]\n        tracked = c_idx in last_idx\n        if c_idx not in last_idx:\n            idx_offset += 1\n            cur_idx = idx_offset\n        else:\n            cur_idx = last_idx[c_idx]\n        next_idx[n_idx] = cur_idx\n        track_list += [{\n            'frame_idx': frame_idx,\n            'frame': c_row['base'],\n            'idx': cur_idx,\n            'tracked': tracked,\n            'x': c_row['keypoints'][c_idx, 0],\n            'y': c_row['keypoints'][c_idx, 1],\n            'xy_coord': c_row['keypoints'][c_idx],\n            'dist': dist\n        }]\n    last_idx = next_idx","a96bad44":"track_df = pd.DataFrame(track_list)\ntrack_df['dist'].hist(figsize=(5, 5))","76de8a74":"cut_dist = np.quantile(track_df['dist'], 0.80)\nprint(cut_dist)\nwell_tracked_df = track_df[track_df['dist'] <= cut_dist]\npivot_track_df = well_tracked_df.pivot_table(\n    index=['idx', 'frame', 'frame_idx'],\n    values=['x', 'y'],\n    aggfunc='first'\n).\\\n    reset_index()\npivot_track_df.sample(3)","148f6a83":"full_tracked = pivot_track_df.\\\n    pivot(index='idx',\n          columns='frame_idx',\n          values=['x', 'y']).\\\n    dropna()\nfull_tracked.sample(3)","db97f98b":"ft_vec = full_tracked.values\nx_vec = ft_vec[:, :3]\ny_vec = ft_vec[:, 3:]\nx_vec.shape, y_vec.shape","f131f1f1":"fig, ax1 = plt.subplots(1, 1, figsize=(5, 5))\nfor i in range(x_vec.shape[0]):\n    ax1.plot(x_vec[i, :], y_vec[i, :], '-')","37d5ba60":"dx_vec = x_vec-np.tile(x_vec[:, 0:1], x_vec.shape[1])\ndy_vec = y_vec-np.tile(y_vec[:, 0:1], y_vec.shape[1])","62f34d5b":"fig, ax1 = plt.subplots(1, 1, figsize=(5, 5))\nfor i in range(x_vec.shape[0]):\n    ax1.plot(dx_vec[i, :],\n             dy_vec[i, :],\n             '.-',\n             lw=0.5)","62d30bd3":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\ntheta = 3*np.arange(3)\nfor i in range(x_vec.shape[0]):\n    ax1.plot(\n        theta,\n        dx_vec[i, :],\n        '.-', \n        lw=0.25)\n    ax1.set_title(r'X vs $\\theta$')\n    ax2.plot(\n        theta,\n        dy_vec[i, :],\n        '.-',\n        lw=0.25\n    )\n    ax2.set_title(r'y vs $\\theta$')","4ab17f19":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline","09f6a23d":"quad_reg = make_pipeline(PolynomialFeatures(2),\n                         LinearRegression())","d62d4067":"theta_x = np.repeat(theta.reshape((1, -1)), dy_vec.shape[0], axis=0)\nquad_reg.fit(theta_x.reshape((-1, 1)),\n             dx_vec[:, :].reshape((-1, 1)))","866188d8":"x_coef = quad_reg.steps[-1][1].coef_\nx_coef","63b53fce":"quad_reg = make_pipeline(PolynomialFeatures(2),\n                         LinearRegression())","4311c30e":"quad_reg.fit(theta_x.reshape((-1, 1)),\n             dy_vec[:, :].reshape((-1, 1)))\ny_coef = quad_reg.steps[-1][1].coef_\ny_coef","41949eed":"new_tracked = full_tracked.copy()\nnew_tracked['x_0'] = new_tracked['x'][0]\nnew_tracked['y_0'] = new_tracked['y'][0]\nnew_tracked['y_vec'] = new_tracked['y'].apply(lambda x: x.tolist(), 1)\nnew_tracked['x_vec'] = new_tracked['x'].apply(lambda x: x.tolist(), 1)\nnew_tracked['x_bin'] = pd.qcut(new_tracked['x_0'], 4).cat.codes\nnew_tracked['y_bin'] = pd.qcut(new_tracked['y_0'], 4).cat.codes\nnew_tracked.sample(3)","9f1ce74c":"x_points = np.concatenate(c_img_df['keypoints'].map(lambda x: x[:, 0]).tolist(), 0)\ny_points = np.concatenate(c_img_df['keypoints'].map(lambda x: x[:, 1]).tolist(), 0)\nx_grid = np.linspace(x_points.min(), x_points.max(), 100)\ngrid_space = x_grid[1]-x_grid[0]\ny_grid = np.arange(y_points.min(), y_points.max(), grid_space)","7c8f92bf":"from scipy.interpolate import interp2d\nfig, m_axs = plt.subplots(4, 2, figsize=(15, 15))\n(ax0, ax1) = m_axs[0]\nax0.imshow(c_img_df['img'].iloc[0][::-1])\npos_dict = {}\nfor bin_dex, c_rows in new_tracked.groupby(['x_bin', 'y_bin']):\n    ax1.plot(c_rows['y_0'], c_rows['x_0'], '.', label='{}'.format(bin_dex))\n    x_vec = np.stack(c_rows['x_vec'].values)\n    y_vec = np.stack(c_rows['y_vec'].values)\n    quad_reg = make_pipeline(PolynomialFeatures(2),\n                         LinearRegression())\n    \n    xy_vec = np.concatenate([\n        x_vec[:, :].reshape((-1, 1)),\n        y_vec[:, :].reshape((-1, 1))], 1)\n    theta_x = np.repeat(theta.reshape((1, -1)), \n                        x_vec.shape[0], axis=0)\n    quad_reg.fit(theta_x.reshape((-1, 1)), xy_vec)\n    \n    x_coef = quad_reg.steps[-1][1].coef_[0, :]\n    y_coef = quad_reg.steps[-1][1].coef_[1, :]\n    pos_dict[(c_rows['x_0'].mean(), c_rows['y_0'].mean())]  = (x_coef, y_coef)\n    \nax1.axis('equal')\np_keys = list(pos_dict.keys())\nfor (ax2, ax3), i in zip(m_axs[1:], range(3)):\n    x_lin_func = interp2d(\n        [y for x,y in p_keys],\n        [x for x,y in p_keys],\n        [pos_dict[k][0][i] for k in p_keys])\n\n    ax2.imshow(x_lin_func(y_grid, x_grid))\n    ax2.set_title('$x^{}$ Term'.format(i))\n    ax2.axis('off')\n    \n    y_lin_func = interp2d(\n        [y for x,y in p_keys],\n        [x for x,y in p_keys],\n        [pos_dict[k][1][i] for k in p_keys])\n\n    ax3.imshow(y_lin_func(y_grid, x_grid))\n    ax3.set_title('$y^{}$ Term'.format(i))\n    ax3.axis('off')","1fc2ffe8":"# Filtering Matches\nWe can filter the matches by excluding the matches which are too far away (we expect mostly small changes)","7df27e60":"# Change to Differential Coordinates","964d2aa0":"# Fit Quadratic to the Values","54908e6c":"## Match Points\n\nHere we just match points on the descriptors","c9d57b39":"# Change to Angle Coordinates\n\n```\nThis dataset contains four 2D images from a biological sample called \n\"pollen grain from Brassica rapa\" and its 3D point cloud (.ply format) \nwhich could be easily converted to a surface model by MeshLab. \nThe set of 2D images were obtained by tilting the specimen stage 3 \ndegrees from one to the next in the image sequence.\n\nhttp:\/\/selibcv.org\/3dsem\/\n```","2f32ee0d":"# Calculate Descriptors","8113fa4f":"# Fit Quadratic by Region","a2f8c3ff":"# Load and Organize Measurements"}}