{"cell_type":{"eb36da0e":"code","11be1248":"code","e5177bd4":"code","f5f0ec3f":"code","3b7298b6":"code","eeab7a38":"code","bfc4d14b":"code","3418df83":"code","ab935d74":"code","f1d98be1":"code","45124da1":"code","078e8646":"code","4d276d7c":"code","19b403f1":"code","24a9dae4":"code","77171ffa":"code","9bac91bd":"markdown","d2826e8b":"markdown","ace973b5":"markdown","45573c9b":"markdown","14f1828c":"markdown","aade4245":"markdown","b3ffddcb":"markdown","b72de675":"markdown","655918a5":"markdown","b62e0152":"markdown","8a8476d1":"markdown","8931cd91":"markdown","9cb4d8b8":"markdown","fa2ac310":"markdown","3662a42b":"markdown","511f0167":"markdown","cee7e453":"markdown","5054c550":"markdown","e572197a":"markdown"},"source":{"eb36da0e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.metrics import confusion_matrix , classification_report \nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nfrom IPython.display import clear_output\nimport warnings\nwarnings.filterwarnings('ignore')","11be1248":"train_dir = \"..\/input\/emotion-detection-fer\/train\"\ntest_dir = \"..\/input\/emotion-detection-fer\/test\"\n\nSEED = 12\nIMG_HEIGHT = 48\nIMG_WIDTH = 48\nBATCH_SIZE = 64\nEPOCHS = 30\nFINE_TUNING_EPOCHS = 20\nLR = 0.01\nNUM_CLASSES = 7\nEARLY_STOPPING_CRITERIA=3\nCLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\nCLASS_LABELS_EMOJIS = [\"\ud83d\udc7f\", \"\ud83e\udd22\" , \"\ud83d\ude31\" , \"\ud83d\ude0a\" , \"\ud83d\ude10 \", \"\ud83d\ude14\" , \"\ud83d\ude32\" ]","e5177bd4":"preprocess_fun = tf.keras.applications.densenet.preprocess_input\n\ntrain_datagen = ImageDataGenerator(horizontal_flip=True,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.05,\n                                   rescale = 1.\/255,\n                                   validation_split = 0.2,\n                                   preprocessing_function=preprocess_fun\n                                  )\ntest_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  validation_split = 0.2,\n                                  preprocessing_function=preprocess_fun)\n\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\",\n                                                    seed = 12\n                                                   )\n\nvalidation_generator = test_datagen.flow_from_directory(directory = train_dir,\n                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                         batch_size = BATCH_SIZE,\n                                                         shuffle  = True , \n                                                         color_mode = \"rgb\",\n                                                         class_mode = \"categorical\",\n                                                         subset = \"validation\",\n                                                         seed = 12\n                                                        )\n\ntest_generator = test_datagen.flow_from_directory(directory = test_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = False , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = 12\n                                                  )","f5f0ec3f":"# Helper Functions\ndef display_one_image(image, title, subplot, color):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=16)\n    \ndef display_nine_images(images, titles, title_colors=None):\n    subplot = 331\n    plt.figure(figsize=(13,13))\n    for i in range(9):\n        color = 'black' if title_colors is None else title_colors[i]\n        display_one_image(images[i], titles[i], 331+i, color)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\n\ndef image_title(label, prediction):\n  # Both prediction (probabilities) and label (one-hot) are arrays with one item per class.\n    class_idx = np.argmax(label, axis=-1)\n    prediction_idx = np.argmax(prediction, axis=-1)\n    if class_idx == prediction_idx:\n        return f'{CLASS_LABELS[prediction_idx]} [correct]', 'black'\n    else:\n        return f'{CLASS_LABELS[prediction_idx]} [incorrect, should be {CLASS_LABELS[class_idx]}]', 'red'\n\ndef get_titles(images, labels, model):\n    predictions = model.predict(images)\n    titles, colors = [], []\n    for label, prediction in zip(classes, predictions):\n        title, color = image_title(label, prediction)\n        titles.append(title)\n        colors.append(color)\n    return titles, colors\n\nimg_datagen = ImageDataGenerator(rescale = 1.\/255)\nimg_generator = img_datagen.flow_from_directory(directory = train_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = 12\n                                                  )\nclear_output()\n\nimages, classes = next(img_generator)\nclass_idxs = np.argmax(classes, axis=-1) \nlabels = [CLASS_LABELS[idx] for idx in class_idxs]\ndisplay_nine_images(images, labels)","3b7298b6":"fig = px.bar(x = CLASS_LABELS_EMOJIS,\n             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] , \n             color = np.unique(train_generator.classes) ,\n             color_continuous_scale=\"Emrld\") \nfig.update_xaxes(title=\"Emotions\")\nfig.update_yaxes(title = \"Number of Images\")\nfig.update_layout(showlegend = True,\n    title = {\n        'text': 'Train Data Distribution ',\n        'y':0.95,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","eeab7a38":"def feature_extractor(inputs):\n    feature_extractor = tf.keras.applications.DenseNet169(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n                                               include_top=False,\n                                               weights=\"imagenet\")(inputs)\n    \n    return feature_extractor\n\ndef classifier(inputs):\n    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.5) (x)\n    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n    \n    return x\n\ndef final_model(inputs):\n    densenet_feature_extractor = feature_extractor(inputs)\n    classification_output = classifier(densenet_feature_extractor)\n    \n    return classification_output\n\ndef define_compile_model():\n    \n    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n    classification_output = final_model(inputs) \n    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n     \n    model.compile(optimizer=tf.keras.optimizers.SGD(0.1), \n                loss='categorical_crossentropy',\n                metrics = ['accuracy'])\n  \n    return model","bfc4d14b":"model = define_compile_model()\nclear_output()\n\n# Feezing the feature extraction layers\nmodel.layers[1].trainable = False\n\nmodel.summary()","3418df83":"earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                         patience=EARLY_STOPPING_CRITERIA,\n                                                         verbose= 1 ,\n                                                         restore_best_weights=True\n                                                        )\n\nhistory = model.fit(x = train_generator,\n                    epochs = EPOCHS ,\n                    validation_data = validation_generator , \n                    callbacks= [earlyStoppingCallback])\n\nhistory = pd.DataFrame(history.history)","ab935d74":"# Un-Freezing the feature extraction layers for fine tuning \nmodel.layers[1].trainable = True\n\nmodel.compile(optimizer=tf.keras.optimizers.SGD(0.001), #lower learning rate\n                loss='categorical_crossentropy',\n                metrics = ['accuracy'])\n\nhistory_ = model.fit(x = train_generator,epochs = FINE_TUNING_EPOCHS ,validation_data = validation_generator)\nhistory = history.append(pd.DataFrame(history_.history) , ignore_index=True)","f1d98be1":"x = px.line(data_frame= history , y= [\"accuracy\" , \"val_accuracy\"] ,markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Accuracy\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Accuracy vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","45124da1":"x = px.line(data_frame= history , \n            y= [\"loss\" , \"val_loss\"] , markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Loss\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Loss vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","078e8646":"model.evaluate(test_generator)\npreds = model.predict(test_generator)\ny_preds = np.argmax(preds , axis = 1 )\ny_test = np.array(test_generator.labels)","4d276d7c":"cm_data = confusion_matrix(y_test , y_preds)\ncm = pd.DataFrame(cm_data, columns=CLASS_LABELS, index = CLASS_LABELS)\ncm.index.name = 'Actual'\ncm.columns.name = 'Predicted'\nplt.figure(figsize = (20,10))\nplt.title('Confusion Matrix', fontsize = 20)\nsns.set(font_scale=1.2)\nax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')","19b403f1":"print(classification_report(y_test, y_preds))","24a9dae4":"fig, c_ax = plt.subplots(1,1, figsize = (15,8))\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    for (idx, c_label) in enumerate(CLASS_LABELS):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr,lw=2, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'black',linestyle='dashed', lw=4, label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(y_test , preds  , average = \"micro\"))\nplt.xlabel('FALSE POSITIVE RATE', fontsize=18)\nplt.ylabel('TRUE POSITIVE RATE', fontsize=16)\nplt.legend(fontsize = 11.5)\nplt.show()","77171ffa":"print(\"ROC-AUC Score  = \" ,roc_auc_score(to_categorical(y_test) , preds))","9bac91bd":"## Images with different emotions","d2826e8b":"<a id=\"im\"><\/a>\n# <center>IMPORTING LIBRARIES<\/center> ","ace973b5":"<a id=\"model\"><\/a>\n# <center> DenseNet169 Transfer Learning  <\/center>","45573c9b":"## Training model with freezed layers of DenseNer169","14f1828c":"## [1. Imports](#im) ##\n## [2. HyperParameters](#hp) ##\n## [3. Data Loading and Preprocessing](#data) ##\n## [4. DenseNet169 Model](#model)  ##\n## [5. Training and Fine Tuning](#train) ##\n## [6. Visualizing Results](#vis) ##","aade4245":"## Training plots","b3ffddcb":"## Confusion Matrix","b72de675":"<a id=\"train\"><\/a>\n# <center> Training and Fine-Tuning <\/center> ","655918a5":"<a id=\"hp\"><\/a>\n# <center>HYPERPARAMETRERS AND DIRECTORIES<\/center>","b62e0152":"# <center> \ud83d\ude21\ud83e\udd22\ud83d\ude31\ud83d\ude0a\ud83d\ude10\ud83d\ude14\ud83d\ude32 EMOTION DETECTION <\/center>\n## <center>If you find this notebook useful, support with an upvote\ud83d\udc4d<\/center>","8a8476d1":"## Summary of model","8931cd91":"**Created by Sanskar Hasija**\n\n**\ud83d\ude21\ud83e\udd22\ud83d\ude31\ud83d\ude0a\ud83d\ude10\ud83d\ude14\ud83d\ude32 Emotion Detection**\n\n**28 OCTOBER 2021**\n","9cb4d8b8":"## Fine Tuning","fa2ac310":"## Data distribution (count) among differnt emotions","3662a42b":"<a id=\"vis\"><\/a>\n# <center> Visualizing Results <\/center> ","511f0167":"## Classification Report ","cee7e453":"<a id=\"data\"><\/a>\n# <center> DATA LOADING AND PRE-PROCESSING<\/center>","5054c550":"## Model Evaluation","e572197a":"## Multiclass AUC Curve"}}