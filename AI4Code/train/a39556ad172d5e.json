{"cell_type":{"6bb8ad0c":"code","f42513b5":"code","d898ecb1":"code","39d9b778":"code","e80f3930":"code","e6373efc":"code","b9a7d823":"code","49a03eea":"code","af41e9cd":"code","4d6dfbd7":"code","3243d0e8":"code","8694db06":"code","ed7f0ac2":"code","063cf4dd":"code","19596a04":"code","c2b11028":"code","ce28a727":"code","485f9ecd":"code","27836f96":"code","454cf7cd":"code","e9b83cf6":"code","8cbd6097":"code","d45da47c":"code","24bdc586":"code","aec73bd6":"code","77efa1ba":"code","7163fbcf":"code","d44208f5":"code","7d795b98":"code","a65751b6":"code","e36032e0":"code","34c3ab9b":"code","9174bca7":"code","cdeb4522":"code","27dfc5c3":"code","65be1297":"code","4f0a8ec4":"code","cec3caa9":"code","aa73c78a":"markdown","f1ee915a":"markdown","77d550d6":"markdown","f3791d81":"markdown","8ddbd7f3":"markdown","704d2e71":"markdown","26009516":"markdown","5948881e":"markdown","ddd86e1e":"markdown","c708dd1c":"markdown","bf4d76d0":"markdown","18fdcf6f":"markdown","5f81a3d1":"markdown","02a3142b":"markdown","d067e958":"markdown","8a562353":"markdown","f3268202":"markdown","9c907dd3":"markdown","730c96ac":"markdown","f597930b":"markdown","c504814c":"markdown","3d3d84d2":"markdown","4d0076e2":"markdown","1cc284e9":"markdown","6812060c":"markdown","ce690d2e":"markdown"},"source":{"6bb8ad0c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\npd.pandas.set_option(\"display.max_columns\", None)\nfrom scipy.stats import skew, kurtosis\nfrom scipy import stats\n\ntraining = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmission = pd.DataFrame(columns=[\"Id\", \"SalePrice\"])\nsubmission[\"Id\"] = test[\"Id\"]\ntraining.head()","f42513b5":"train = training.drop(['SalePrice'], axis=1)\ntrain.drop('Id', axis=1, inplace=True)\ntest.drop('Id', axis=1, inplace=True)\n\nfeatures = pd.concat([train, test]).reset_index(drop=True)\nprint(\"The whole features shape: \",features.shape)","d898ecb1":"categFeat = features.describe(include = ['object']).columns.values\nprint(f\"We have: {categFeat.size} categorical features.\")","39d9b778":"features.describe(include = ['object'])","e80f3930":"sns.boxplot(x='PoolQC',y=training['SalePrice'], data=training)","e6373efc":"features['PoolQC'].isnull().mean()","b9a7d823":"sns.distplot(training['SalePrice'], fit=norm)","49a03eea":"print(f\"Skewness: {training['SalePrice'].skew()}\")\nprint(f\"Kurtosis: {training['SalePrice'].kurt()}\")","af41e9cd":"numerFeat = [var for var in features.columns if features[var].dtypes != 'O']\nprint(f\"We have {len(numerFeat)} numerical features including the Id and SalePrice: \")\nfeatures[numerFeat].describe()","4d6dfbd7":"yearFeat = [var for var in numerFeat if 'Yr' in var or 'Year' in var]\n\ndef plotYearVariable(df, var):\n    df[var] = df[\"YrSold\"]-df[var]\n    plt.scatter(df[var], df[\"SalePrice\"])\n    plt.ylabel(\"Sale Price\")\n    plt.xlabel(var)\n    plt.show()\n\nfor var in yearFeat:\n    if var !=\"YrSold\":\n        plotYearVariable(training, var)","3243d0e8":"discFeat = [var for var in numerFeat if len(\n    features[var].unique()) < 20 and var not in yearFeat+['Id']]\nprint(f\"We have: '{len(discFeat)} discrete features\")","8694db06":"contFeat = [\n    var for var in numerFeat if var not in discFeat + yearFeat + ['Id']]\n\nprint(f\"We have: {len(contFeat)} continuous features\")","ed7f0ac2":"def analyse_discrete(df, var):\n    df = df.copy()\n    df.groupby(var)['SalePrice'].median().plot.bar()\n    plt.title(var)\n    plt.ylabel('Median SalePrice')\n    plt.show()\n    \nfor var in discFeat:\n    analyse_discrete(training, var)","063cf4dd":"def analyse_continuous(df, var):\n    df[var].hist(bins=30)\n    plt.ylabel('Number of houses')\n    plt.xlabel(var)\n    plt.title(var)\n    plt.show()\n\nfor var in contFeat:\n    analyse_continuous(features, var)","19596a04":"def outliers(df, var):\n    if any(df[var] <= 0):\n        pass\n    else:\n        df[var] = np.log(df[var])\n        df.boxplot(column=var)\n        plt.title(var)\n        plt.ylabel(var)\n        plt.show()\n\nfor var in contFeat:\n    outliers(features, var)","c2b11028":"corr = training.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr, vmax=.8, square=True);","ce28a727":"vars_with_naN = [var for var in features.columns if features[var].isnull().sum() > 0]\nprint(f\"We have {len(vars_with_naN)} features with NaN value:\\n\\n {vars_with_naN}\")\n# features[vars_with_naN]isnull().mean()","485f9ecd":"NanVariables = [var for var in training.columns if training[var].isnull().sum() > 0]\ntraining[NanVariables].isnull().mean()","27836f96":"features['PoolQC'].fillna(\"NA\", inplace= True)\nfeatures['MiscFeature'].fillna(\"NA\", inplace= True)\nfeatures['Alley'].fillna(\"NA\", inplace=True)\nfeatures['Fence'].fillna(\"NA\", inplace= True)\nfeatures['FireplaceQu'].fillna(\"NA\", inplace= True)\nmedian = features['LotFrontage'].median()\nfeatures['LotFrontage'].fillna(median, inplace=True)\n\nfeatures['GarageCond'].fillna('NA', inplace= True)\nfeatures['GarageFinish'].fillna('NA', inplace= True)\nfeatures['GarageQual'].fillna('NA', inplace= True)\nfeatures['GarageType'].fillna('NA', inplace= True)\nfeatures['GarageYrBlt'].fillna(0, inplace= True)\n\nfeatures['BsmtExposure'].fillna('NA', inplace= True)\nfeatures['BsmtCond'].fillna('NA', inplace= True)\nfeatures['BsmtQual'].fillna('NA', inplace= True)\nfeatures['BsmtFinType1'].fillna('NA', inplace= True)\nfeatures['BsmtFinType2'].fillna('NA', inplace= True)\n\nfeatures['MasVnrType'].fillna('None', inplace= True)\nfeatures['MasVnrArea'].fillna(0, inplace= True)\n\nfeatures['MSZoning'].fillna(features['MSZoning'].mode()[0], inplace= True)\nfeatures['Functional'].fillna(features['Functional'].mode()[0], inplace= True)\nfeatures['BsmtHalfBath'].fillna(features['BsmtHalfBath'].mode()[0], inplace= True)\nfeatures['BsmtFullBath'].fillna(features['BsmtFullBath'].mode()[0], inplace= True)\n\nfeatures['Utilities'].fillna(features['Utilities'].mode()[0], inplace= True)\nfeatures['Electrical'].fillna(features['Electrical'].mode()[0], inplace= True)\nfeatures['Exterior1st'].fillna(features['Exterior1st'].mode()[0], inplace= True)\nfeatures['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0], inplace= True)\n\nfeatures['GarageCars'].fillna(features['GarageCars'].mode()[0], inplace= True)\nfeatures['GarageArea'].fillna(features['GarageArea'].mode()[0], inplace= True)\nfeatures['KitchenQual'].fillna(features['KitchenQual'].mode()[0], inplace= True)\nfeatures['BsmtFinSF1'].fillna(features['BsmtFinSF1'].mode()[0], inplace= True)\n\nfeatures['SaleType'].fillna(features['SaleType'].mode()[0], inplace= True)\nfeatures['TotalBsmtSF'].fillna(features['TotalBsmtSF'].mode()[0], inplace= True)\nfeatures['BsmtUnfSF'].fillna(features['BsmtUnfSF'].mode()[0], inplace= True)\nfeatures['BsmtFinSF2'].fillna(features['BsmtFinSF2'].mode()[0], inplace= True)","454cf7cd":"categorical_columns = features.select_dtypes(include= ['object']).columns\nprint(categorical_columns)","e9b83cf6":"one_hot_parameters = ['MSZoning' ,'Street', 'Alley', 'LandContour','LotConfig', 'Neighborhood','Condition1', 'Condition2',\n                      'RoofStyle', 'RoofMatl','Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating','GarageType', \n                     'PavedDrive', 'MiscFeature','SaleType', 'SaleCondition' ]","8cbd6097":"encoders = []\n\nfor col in categorical_columns :\n    if col not in one_hot_parameters :\n        encoders.append(col)","d45da47c":"len(encoders) + len(one_hot_parameters) == len(categorical_columns)","24bdc586":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor col in encoders :\n    features[col] = encoder.fit_transform(features[col].astype(str))","aec73bd6":"Hot_features = pd.get_dummies(features[one_hot_parameters], drop_first= True)\nfeatures = pd.concat([features.drop(one_hot_parameters, axis=1), Hot_features], axis=1)","77efa1ba":"features.columns","7163fbcf":"train_df = features.iloc[:1460,:]  \ntrain_df['SalePrice'] = training['SalePrice']\ntest_df = features.iloc[1460 :,:]  ","d44208f5":"X_train = train_df.drop('SalePrice', axis=1)\ny_train = train_df['SalePrice']\nX_test = test_df","7d795b98":"from sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, mean_squared_log_error, r2_score\n\nn_folds = 5\n\ncv = KFold(n_splits= 5, shuffle= True, random_state= 42).get_n_splits(X_train.values)\n\ndef test_1(model) :\n    msle = make_scorer(mean_squared_log_error)\n    rmsle = np.sqrt(cross_val_score(model, X_train, y_train, cv = cv, scoring= msle))\n    score_rmsle = [rmsle.mean()]\n    return score_rmsle\n\ndef test_2(model) :\n    r2 = make_scorer(r2_score)\n    r2_error = cross_val_score(model, X_train, y_train, cv = cv, scoring= r2)\n    score_r2 = [r2_error.mean()]\n    return score_r2","a65751b6":"import xgboost as xgb\nxg_boost = xgb.XGBRegressor(n_estimators= 1000)\ntest_1(xg_boost)","e36032e0":"from sklearn.ensemble import BaggingRegressor\n\nbagging_regressor = BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n                                     max_features=1.0, max_samples=1.0, n_estimators=1000,\n                                     n_jobs=None, oob_score=False, random_state=51, verbose=0, warm_start=False)\n\ntest_1(bagging_regressor)","34c3ab9b":"from sklearn.linear_model import Ridge\n\nridge = Ridge(alpha=500, copy_X=True, fit_intercept=True, max_iter=None, \n              normalize=False,  random_state=None, solver='auto', tol=0.001)\n\ntest_1(ridge)","9174bca7":"from sklearn.ensemble import GradientBoostingRegressor\n\ngradient_boosting_reg = GradientBoostingRegressor()\n\ntest_1(gradient_boosting_reg)","cdeb4522":"sub_df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsub_df.info()","27dfc5c3":"gradient_boosting_reg.fit(X_train, y_train)","65be1297":"predictions = gradient_boosting_reg.predict(X_test)","4f0a8ec4":"sub_df['SalePrice'] = predictions","cec3caa9":"sub_df.to_csv('Gradient_Boosting_Regressor.txt', index= False)","aa73c78a":"### We will consider continuous variables to all those that are not temporal or discrete variables in our train dataset. We can notice that they are not normally distributed, including the target variable 'SalePrice'.","f1ee915a":"# Missing Values","77d550d6":"## Loss function and Evaluation","f3791d81":"# 3-Ridge Regressor","8ddbd7f3":"# Numerical variables","704d2e71":"# The Outliers\n### Extreme values may affect the performance of a linear model, thus let's check the outliers:","26009516":"# 1-Xgboost","5948881e":"### We have 'year'a continuous factors in our data. Generally, the age of the house affects its price, let's confirm this.","ddd86e1e":"# Starting with The categorical features.","c708dd1c":"### The [](http:\/\/)box-plot shows the values of 'PoolQC'is covering a big range to the average of the price values. But if we look deeper to dicover that it has alot of NaN values which let me put in my considiration to drop this feature.","bf4d76d0":"<h3>The metrics show that as the longer the time between the house was built, remodeled and sale date, the lower the sale price, and that makes sense cause the house needs more repair money with the passage of the time.<\/h3>","18fdcf6f":"### The Nan values average:","5f81a3d1":"# 4-Gradient Boosting Regressor","02a3142b":"### Who can't notice the 'GrLivArea', 'OverallQual', and 'TotalBsmtSF' with strongest correlation with the price, but that does not mean that I can drop the other dark variables. \n","d067e958":"### These discrete variables tend to be qualifications, grading scales, or refer to the number of rooms, or units.we can analyse their contribution to the house price:","8a562353":"### The majority of the continuous variables seem to contain outliers!","f3268202":"# The Submission","9c907dd3":" ### For some variables we have more than 50% missing values! We need to recognize the relationship between values being missing and 'SalePrice' by evaluating the price of the house in those observations where the information is missing.","730c96ac":"# 2-Bagging Regressor","f597930b":"### To finish the exploratory data analysis section I'm going to use the best metric that can describe the numerical variables, let's see and think about different variables and their association value which present in the color of the variables.","c504814c":"## Encoder","3d3d84d2":"# Verifying the missing data 'NaN':","4d0076e2":"## Hi everyone.\n### This is my first kernel in kaggle, i hope you find it beneficial.","1cc284e9":"### Create train and test set","6812060c":"### Starting with the target, we can notice The distribution for our target 'Sale Price' shows that scale starts above 0, the data is positively skewed where the outliers located in the tail. The kurtoses slightly negative and the mean price is around 180k. Let's check other numerical variables:","ce690d2e":"# Discrete and Continuous Variables:"}}