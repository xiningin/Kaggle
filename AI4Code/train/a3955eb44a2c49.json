{"cell_type":{"2f684a84":"code","b1e1e053":"code","58dab270":"code","cf5221de":"code","17efadfd":"code","a54dd2e6":"code","a829754c":"code","8587101b":"code","a50b388c":"code","61e876a1":"code","3f4f5d46":"code","663dba89":"code","ab21bbcb":"code","319ba57c":"code","3824e1ab":"code","e2065a9b":"code","77b18642":"code","05a80e70":"code","a72fdc04":"code","e0eb0ebe":"code","6ff6e901":"code","dddd0625":"code","2aadf081":"code","e504ef57":"markdown","c3edb908":"markdown","78b11473":"markdown","6444abff":"markdown","cb3b16df":"markdown","2eab6590":"markdown","3e6bc80f":"markdown","ae15391c":"markdown","f19ac4f3":"markdown","45f0a54e":"markdown","4fb449e9":"markdown","a4a7135c":"markdown","dc122cec":"markdown","8e90c8db":"markdown","f11190f5":"markdown","f0fbc941":"markdown","4891a058":"markdown","3b9fca74":"markdown","fa2fb114":"markdown","34efa324":"markdown","c6856746":"markdown","ada1d87c":"markdown","eb689419":"markdown","6981d87b":"markdown","eb43ec9f":"markdown","bbd89879":"markdown","b7f1d3ed":"markdown","1e126134":"markdown"},"source":{"2f684a84":"#from kaggle.api.kaggle_api_extended import KaggleApi\n#api = KaggleApi()\n#api.authenticate()\n#api.dataset_download_files('benroshan\/factors-affecting-campus-placement', unzip=True)","b1e1e053":"import pandas as pd\n\n#placement_df = pd.read_csv(\"Placement_Data_Full_Class.csv\")\nplacement_df = pd.read_csv(\"..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\")\nplacement_df.drop(\"sl_no\", axis = 1, inplace= True)\nprint(placement_df.info())\nprint(placement_df.describe())\nplacement_df.head()","58dab270":"import seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef remove_spines_partial(axes):\n    for spine in [\"top\", \"right\"]:\n        axes.spines[spine].set_visible(False)\n\npct_df = placement_df.copy()\ncols = [\"ssc_p\", \"hsc_p\", \"degree_p\", \"mba_p\"]\npct_df = pct_df[cols + [\"status\"]]\npct_df = pd.melt(pct_df,id_vars = [\"status\"], value_vars = cols)\n\npct_df.rename(columns={\"value\": \"Percent\"}, inplace = True)\npct_df[\"variable\"].replace(to_replace=cols, value=[\"Secondary\", \"Higher Secondary\", \"Graduate\", \"Postgraduate (MBA)\"], inplace = True)\n\nplt.figure(figsize=(17,8))\npcts = sns.boxplot(x = \"status\", y= \"Percent\", hue = \"variable\", data = pct_df, palette = \"Set2\")\n\nremove_spines_partial(pcts)\n\npcts.legend(frameon=False)\npcts.set_title(\"Placement Status to Degree Percentages\", fontsize=20);","cf5221de":"def bar_labels(bars, axes):\n    # Taking bar artists and axes object and creates labels relating to the values\n    for bar in bars:\n        axes.text(bar.get_x() + bar.get_width()\/2, bar.get_y()+bar.get_height()\/2,\n                  bar.get_width(), fontsize = 10, fontweight=\"bold\",\n                  color = \"black\", ha = \"center\", va = \"center\")\n\ndef remove_spines(axes):\n    #Removing spines of a given axes object\n    for spine in axes.spines.values():\n        spine.set_visible(False)\n\ndef wedge_alpha(wedges):\n    for i in range(len(wedges[0])):\n        wedges[0][i].set_alpha(0.6)\n\n#Copying Df\nmajor_df = placement_df.loc[:,[\"status\", \"specialisation\", \"salary\"]].copy()\nplaced = major_df[major_df[\"status\"] == \"Placed\"].groupby(\"specialisation\").count()\nnot_placed = major_df[major_df[\"status\"] == \"Not Placed\"].groupby(\"specialisation\").count()\n\n#Creating gridspec\nfig = plt.figure(figsize=(14,7))\nspec = mpl.gridspec.GridSpec(2,2, figure = fig)\n\n#Creating first Chart - Barchart with Placed\/unplaced per specialisation\nnum = plt.subplot(spec[0,:])\nbars_placed = num.barh(placed.index, placed[\"status\"],height=0.4, color = \"green\", alpha = 0.6)\nbars_not_placed = num.barh(not_placed.index, not_placed[\"status\"],left=placed[\"status\"], \n                           height = 0.4, color = \"grey\", alpha = 0.5)\nplt.tick_params(bottom = False,\n               labelbottom = False,\n               left = False)\nnum.set_yticklabels([\"Marketing & Finance\", \"Marketing & HR\"])\n\nremove_spines(num)\n\nbar_labels(bars_placed, num)\nbar_labels(bars_not_placed, num)\nnum.legend(labels=[\"Placed\", \"Not Placed\"], frameon = False, loc=(0.85,1.1), prop={'size': 14})\n\n#Creating two piecharts for percentages\nmajor_df[\"count\"] = 1\nstudents = major_df.groupby([\"specialisation\", \"status\"]).count()\n\n#HR\npie_hr = plt.subplot(spec[1,0])\npie_hr.set_title(\"Marketing & HR\")\nplaced_hr_students = students.loc[(\"Mkt&HR\", \"Placed\"),\"count\"]\nnot_placed_hr_students = students.loc[(\"Mkt&HR\", \"Not Placed\"),\"count\"]\nwedges_hr = pie_hr.pie([placed_hr_students, not_placed_hr_students], colors=[\"green\", \"grey\"], \n                       startangle = 90, autopct=\"%1.1f%%\")\nwedge_alpha(wedges_hr)\n\n#Finance\npie_fin = plt.subplot(spec[1,1])\npie_fin.set_title(\"Marketing & Finance\")\nplaced_fin_students = students.loc[(\"Mkt&Fin\", \"Placed\"),\"count\"]\nnot_placed_fin_students = students.loc[(\"Mkt&Fin\", \"Not Placed\"),\"count\"]\nwedges_fin = pie_fin.pie([placed_fin_students, not_placed_fin_students], colors=[\"green\", \"grey\"], \n                         startangle = 90, autopct=\"%1.1f%%\")\nwedge_alpha(wedges_fin)\nplt.title(\"Placement Outcome per MBA Specialisation\");","17efadfd":"def spec_hist(pos, specialisation):\n    temp_df = major_df[\"salary\"][major_df[\"specialisation\"] == specialisation].to_frame()\n    mu = temp_df.values.mean()\n    sd = temp_df.values.std()\n    li = mu + 3*sd\n    \n    if pos == 0:\n        plt.subplot(spec2[1,pos])\n    else:\n        plt.subplot(spec2[1,pos], sharex = hist_hr)\n    plt.hist(temp_df[\"salary\"], bins = 25, color = palette[pos], linewidth=10)\n    plt.axvline(li, color='grey', linestyle='dashed', linewidth=1)\n    remove_spines(plt.gca())\n    \n    return plt.gca()\n\nmajor_df = major_df[[\"specialisation\", \"salary\"]].dropna()\nfig2 = plt.figure(figsize=(15,10))\n\nspec2 = mpl.gridspec.GridSpec(2,2, figure = fig2)\n\n#Create Main Boxplot\nplt.subplot(spec2[0,0:])\nsns.boxplot(x = \"specialisation\", y = \"salary\", data = major_df, showfliers = False, palette = \"Set2\", width = 0.3)\nremove_spines(plt.gca())\nplt.gca().set_xticklabels([\"Marketing & HR\", \"Marketing & Finance\"])\nplt.title(\"Salary per Specialisation\", fontsize=15, fontweight=\"bold\")\nplt.xlabel(None)\nplt.ylabel(\"Salary in IRN\")\nplt.tick_params(axis = \"x\",\n               labelbottom = False,\n               bottom = False)\n\n#Create Legend\npalette = sns.color_palette(palette=\"Set2\")\nhr_leg = mpl.patches.Patch(color=palette[0], label=\"Marketing & HR\")\nfin_leg = mpl.patches.Patch(color=palette[1], label=\"Marketing & Finance\")\nplt.legend(handles=[hr_leg, fin_leg], frameon = False, loc=(0.85,1.1), prop={'size': 12})\n\n\n#Create histograms\nhist_hr = spec_hist(0, \"Mkt&HR\")\nhist_fin = spec_hist(1, \"Mkt&Fin\")\nhist_hr.set_ylabel(\"Frequency\");","a54dd2e6":"fig3 = plt.figure(figsize=(15,8))\nug_df = placement_df[[\"degree_t\",\"status\"]].copy()\nug_df[\"degree_t\"].replace(to_replace = [\"Sci&Tech\", \"Comm&Mgmt\", \"Others\"], value = range(3), inplace = True)\n\nug_spec = sns.kdeplot(ug_df[\"degree_t\"][ug_df.status == \"Placed\"],\n                     color = \"g\",\n                     label = \"Placed\",\n                     shade = True)\nug_spec = sns.kdeplot(ug_df[\"degree_t\"][ug_df.status == \"Not Placed\"],\n                     color = \"grey\",\n                     label = \"Not Placed\",\n                     shade = True)\nug_spec.set_title(\"Kernel Density Estimation for Undergraduate Degrees\", fontsize=15)\nug_spec.set_xticks([0,1,2])\nug_spec.set_xticklabels([\"Science & Technology\", \"Commerce & Management\", \"Others\"])\nug_spec.set_ylabel(\"Probability\")\nug_spec.legend(frameon=False)\n\n\n\nremove_spines_partial(ug_spec)","a829754c":"import numpy as np\n\ndef create_countplot(criteria):\n    colors = {\"Placed\":\"green\",\"Not Placed\":\"grey\"}\n    ax = sns.countplot(x = criteria, hue = \"status\", data = placement_df, palette=colors, alpha = 0.5)\n    plt.legend(frameon=False)\n    remove_spines_partial(plt.gca())\n    return ax\n\ndef create_percent_barplot(criteria):\n    # Taking in Plot Criteria and returning stacked barchart with placement outcome\n    temp_df = placement_df.groupby([criteria, \"status\"]).count().reset_index()\n    temp_df = pd.pivot_table(temp_df, values = \"specialisation\", index = \"status\", columns = criteria)\n    if criteria == \"gender\":\n        temp_df = temp_df[temp_df.columns[::-1]]\n    total = np.asarray([first + second for first, second in zip(temp_df.iloc[0,:], temp_df.iloc[1,:])])\n    not_placed = np.asarray([temp_df.iloc[0,0], temp_df.iloc[0,1]])\/total*100\n    placed = np.asarray([temp_df.iloc[1,0], temp_df.iloc[1,1]])\/total*100\n    \n    ax = plt.bar(temp_df.columns, placed, color = \"g\", alpha = 0.5, label = \"Placed\", width = 0.7)\n    ax = plt.bar(temp_df.columns, not_placed, bottom = placed, color = \"grey\", alpha = 0.5, label = \"Not Placed\"\n                , width = 0.7)\n    plt.ylabel(\"Percent\")\n    plt.legend(frameon= False, loc =(1.005,1.005))\n    remove_spines_partial(plt.gca())\n    return plt.gca()\n\n\nfig5 = plt.figure(figsize=(11,6))\nwe = create_countplot(\"workex\")\n\nwe.set_title(\"Work Experience and Placement Outcome\", fontsize=15)\nwe.set_xlabel(\"Work Experience\", fontsize=12)\nwe.set_ylabel(\"Students\");\n","8587101b":"fig8 = plt.figure(figsize=(11,6))\nwe_pct = create_percent_barplot(\"workex\")\nwe_pct.set_title(\"Work Experience and Placement Outcome in %\", fontsize = 15)\nwe_pct.set_xlabel(\"Work Experience\", fontsize = 12)\nwe_pct.set_xticklabels([\"No\",\"Yes\"]);","a50b388c":"fig6 = plt.figure(figsize=(11,6))\n\ngender = create_countplot(\"gender\")\n\ngender.set_title(\"Gender and Placement Outcome\", fontsize=15)\ngender.set_xlabel(\"Gender\", fontsize = 12)\ngender.set_xticklabels([\"Male\", \"Female\"])\ngender.set_ylabel(\"Students\");\n","61e876a1":"fig9 = plt.figure(figsize=(11,6))\ngender_pct = create_percent_barplot(\"gender\")\ngender_pct.set_title(\"Gender and Placement Outcome in %\", fontsize = 15)\ngender_pct.set_xlabel(\"Gender\", fontsize = 12)\ngender_pct.set_xticklabels([\"Male\",\"Female\"]);","3f4f5d46":"# Consistency\ncomm_career = (placement_df[\"hsc_s\"] == \"Commerce\") & (placement_df[\"degree_t\"] == \"Comm&Mgmt\")\nsci_career = (placement_df[\"hsc_s\"] == \"Science\") & (placement_df[\"degree_t\"] == \"Sci&Tech\")\nplacement_df.insert(len(placement_df.columns) - 2, \"consistency\",np.where((comm_career) | (sci_career), 1, 0))\n\n# Talent\ndegree_p_90 = placement_df[\"degree_p\"] >= placement_df[\"degree_p\"].quantile(0.75)\nmba_p_90 = placement_df[\"mba_p\"] >= placement_df[\"mba_p\"].quantile(0.75)\n\nplacement_df.insert(len(placement_df.columns) - 2, \"is_talent\",np.where((degree_p_90) & (mba_p_90), 1, 0))","663dba89":"from sklearn.preprocessing import LabelEncoder\n# Encoding Features\nle = LabelEncoder()\ncols = [\"gender\", \"ssc_b\", \"hsc_b\", \"hsc_s\", \"degree_t\", \"workex\", \"specialisation\", \"status\"]\nplacement_df[cols] = placement_df[cols].apply(le.fit_transform)\n\n# Drop cells that would cause data leak\nplacement_df.drop([\"etest_p\", \"salary\"], axis = 1, inplace = True)\n\nplacement_df","ab21bbcb":"placement_df.info()","319ba57c":"mask = np.zeros_like(placement_df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize = (15,10))\nsns.heatmap(placement_df.corr(), \n            annot=True,\n            mask = mask,\n            cmap = \"coolwarm\",\n            linewidths = 1, \n            linecolor= \"w\",\n            center = 0,\n            fmt=\".2f\",\n            square=True)\nplt.title(\"Correlations\",fontsize = 18);","3824e1ab":"import scipy\n\nprint(\"p-values\")\nfor feature in placement_df.columns:\n    print(\"{}: {:.5f}\".format(feature, scipy.stats.pearsonr(placement_df[feature], placement_df[\"status\"])[1]))","e2065a9b":"from sklearn.preprocessing import StandardScaler\nX = placement_df.iloc[:,:-1]\ny = placement_df.iloc[:,-1]\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nlen(X)","77b18642":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.dummy import DummyClassifier\n\nparams = {\"strategy\" : [\"stratified\", \"most_frequent\", \"uniform\"]}\ndummy_clf = GridSearchCV(DummyClassifier(), params, cv = 10, scoring = \"roc_auc\").fit(X,y)","05a80e70":"from sklearn.neighbors import KNeighborsClassifier\nk = range(1,25)\nparams = {\"n_neighbors\" : k}\nknn_clf = GridSearchCV(KNeighborsClassifier(), params, cv = 10, scoring = \"roc_auc\").fit(X,y)","a72fdc04":"from sklearn.linear_model import LogisticRegression\nC = np.linspace(0.001,10,15)\nparams = {\"C\" : C}\nlr_clf = GridSearchCV(LogisticRegression(), params, cv = 10, scoring = \"roc_auc\").fit(X,y)","e0eb0ebe":"from sklearn.svm import SVC\n\nC = np.linspace(0.001,10,15)\ngammas = np.linspace(0.001,10,15)\nparams = {\"C\" : C, \"gamma\" : gammas}\nsvm_clf = GridSearchCV(SVC(), params, cv = 10, scoring = \"roc_auc\").fit(X,y)","6ff6e901":"from sklearn.ensemble import RandomForestClassifier\nn_est = range(100,151,10)\nmax_depth = range(2,10)\n\n\nparams = {\"n_estimators\": n_est, \"max_depth\" : max_depth}\n\nrf_clf = GridSearchCV(RandomForestClassifier(), params, cv = 10, scoring = \"roc_auc\").fit(X,y)","dddd0625":"clfs = {\"Dummy\" :dummy_clf, \"K Nearest Neighbors\" : knn_clf, \"Logistic Regression\" : lr_clf, \"Support Vector Machine\" : svm_clf, \n        \"Random Forest\" : rf_clf}\nresults = {}\n\nfor name, clf in clfs.items():\n    score = np.mean(clf.cv_results_[\"mean_test_score\"])\n    results[name] = score\n\nresults = pd.DataFrame(index = results,data = results.values(), columns = [\"AUC Score\"])\nresults.sort_values(\"AUC Score\", ascending = False)","2aadf081":"\nfeatures = [(criteria, lr_weight, rf_weigth) for criteria, lr_weight, rf_weigth in \n            zip(\n                placement_df.columns[:-1],\n                map(lambda x: abs(x),lr_clf.best_estimator_.coef_[0]), \n                map(lambda x: abs(x),rf_clf.best_estimator_.feature_importances_)\n                )\n            ]\nweighting = pd.DataFrame(features, columns = [\"Feature\", \"Weight LR (in %)\", \"Weight RF (in %)\"]).set_index(\"Feature\")\nweighting[\"Weight LR (in %)\"] = weighting[\"Weight LR (in %)\"].apply(lambda x: (x \/ weighting[\"Weight LR (in %)\"].sum()) * 100)\nweighting[\"Weight RF (in %)\"] = weighting[\"Weight RF (in %)\"].apply(lambda x: (x \/ weighting[\"Weight RF (in %)\"].sum()) * 100)\nweighting.sort_values(\"Weight LR (in %)\", ascending = False)","e504ef57":"## Additional Assumptions:\n\n- Students with an Undergraduate Degree in Science & Technology perform better than students in the other two faculties\n- Students with work experience are more successful in securing a placement position\n- Male students have a small advantage over female students","c3edb908":"### Salary Comparison of Successful Applicants","78b11473":"# Predictive Model","6444abff":"#### Key Take-Away\nRoughly 2\/3 of the course are male and 1\/3 are female. However, the male graduates seem not only slightly, but actually quite a bit more sucessful in finding a placement. They are more than 10% ahead.","cb3b16df":"### Degree Percentages and Recruitment Outcome","2eab6590":"<h1 align=\"center\"> Campus Recruitment <\/h1>\n\n![Recruitment](https:\/\/cdn.pixabay.com\/photo\/2017\/08\/05\/17\/16\/business-2584713_960_720.jpg)\nKaggle Dataset from Ben Roshan D: <br><\/br>\n[Source (Accessed 2020-05-21)](https:\/\/www.kaggle.com\/benroshan\/factors-affecting-campus-placement)\n\n<br><\/br>\n<br><\/br>\n\nMain fields of interest:\n- How do the student's degree results impact placement outcomes?\n- How does the MBA Specialisation impact the attractivity for employers?\n- What other assumptions can be made?\n- Can we reliably predict student placement outcome to better support students, who would not get one?","3e6bc80f":"#### Key Take-Away\nThe majority of the course have not got any work experience. As expected, those students with work experience have got a significant advantage.","ae15391c":"### Reading Data into DataFrame","f19ac4f3":"##### Key Take-Away\nEven Though many more students have undergraduate degrees in Commerce & Management, they actually outperform the Science & Tech degrees. It's also surprising, that students holding a degree from a different faculty and are archieving a placement are in the minority compared to those faculty peers wo are not landing a placement.","45f0a54e":"##### Dummy Classifier","4fb449e9":"### Gender <-> Placement","a4a7135c":"##### Logistic Regression","dc122cec":"#### General Objective\nThe main target is to find a placement for every student, while the cost of the measurements shouldn't explode. Therefore, it is the most suitable approach to use the area under curve in order to measure the effectiveness of the model.","8e90c8db":"### Preparing Data and Getting Insight","f11190f5":"### Outcome per Specialisation","f0fbc941":"### Undergraduate Degree\/Placement-Density","4891a058":"#### Most Important Feautures\n\n- Secondary Education Grade (ssc_p): 0.61\n- Higher Secondary School Grade (hsc_p): 0.49\n- Undergraduate Degree Grade (degree_p): 0.48\n- Work Experience: 0.28\n- MBA Specialisation: - 0.25","3b9fca74":"Creating \"Career Consistency\" as new feature. If a student always had a major in Commerce\/Science, they have a consistent career. \\\nCreating is_talent feature, that will result as true, if the person was in the 75%-quantile of their undergraduate degree grade and mba grade.","fa2fb114":"## Building Model","34efa324":"## Index <br><\/br>\n(Cell hyperlinks will only work with kernel session)\n\n<div class=\"alert alert-block alert-info\">\n\n1. [Visualizations](#Visualizations)<br>\n   - [Degree Percentages and Recruitment Outcome](#Degree-Percentages-and-Recruitment-Outcome)<br>\n   - [Outcome per Specialisation](#Outcome-per-Specialisation)<br>\n   - [Salary Comparison of Successful Applicants](#Salary-Comparison-of-Successful-Applicants)<br>\n   \n2. [Additional Assumptions](#Additional-Assumptions:)<br>\n   - [Undergraduate Degree\/Placement-Density](#Undergraduate-Degree\/Placement-Density)<br>\n   - [Work Experience <-> Placement](#Work-Experience-<->-Placement)<br>\n   - [Gender <-> Placement](#Gender-<->-Placement)<br>\n   \n3. [Predictive Model](#Predictive-Model)<br>\n   - [Preparing Data and Getting Insight](#Preparing-Data-and-Getting-Insight)<br>\n   - [Building Model](#Building-Model)<br>\n<\/div>","c6856746":"### Work Experience <-> Placement","ada1d87c":"##### Random Forest","eb689419":"##### KNN","6981d87b":"##### SVM","eb43ec9f":"## Visualizations","bbd89879":"### Classifier Comparison","b7f1d3ed":"#### Key Take-Away\nThose students with a finance MBA specialisation are archieving better placement outcomes and better salaries. The amount of outliers, who are earning uncommonly much is also higher for those majoring in finance.","1e126134":"- Encoding categorical features \n- Droping features, that might cause data leakage\n\nReason for dropping the employablility test:\nThis test will likely be available at a time, where we already want measurements to be active. The test will likely be available at a later stage and there most likely also is no option to use predicted scores as it would be possible for degree grades."}}