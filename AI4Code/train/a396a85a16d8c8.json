{"cell_type":{"756fd561":"code","664ea933":"code","ce3c3d2f":"code","9e521d3f":"code","fdfc09a1":"code","dfe03a95":"code","36a57f17":"code","224a8714":"code","cd6bf145":"code","a901a681":"code","a85ee272":"code","2acd798e":"code","e3c5de4b":"code","c6bc7e30":"markdown","beda9cf3":"markdown","b2a2c8da":"markdown","d0a64bb5":"markdown"},"source":{"756fd561":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import HTML\n\nimport gc\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 300)\npd.set_option(\"display.max_rows\", 15)\n#pd.set_option(\"display.max_rows\", None)\n\nfrom pandas_profiling import ProfileReport\n\nplt.style.use('ggplot')","664ea933":"train = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntest = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')","ce3c3d2f":"#Intro function for exploratory data analysis\ndef get_stats(df):\n    \"\"\"\n    Function returns a dataframe with the following stats for each column of df dataframe:\n    - Unique_values\n    - Percentage of missing values\n    - Percentage of zero values\n    - Percentage of values in the biggest category\n    - data type\n    \"\"\"\n    stats = []\n    for col in df.columns:\n        if df[col].dtype not in ['object', 'str', 'datetime64[ns]']:\n            zero_cnt = df[df[col] == 0][col].count() * 100 \/ df.shape[0]\n        else:\n            zero_cnt = 0\n\n        stats.append((col, df[col].nunique(),\n                      df[col].isnull().sum() * 100 \/ df.shape[0],\n                      zero_cnt,\n                      df[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n                      df[col].dtype))\n\n    df_stats = pd.DataFrame(stats, columns=['Feature', 'Unique_values',\n                                            'Percentage of missing values',\n                                            'Percentage of zero values',\n                                            'Percentage of values in the biggest category',\n                                            'type'])\n    # df_stats.sort_values('Percentage of zero values', ascending=False, inplace=True)\n\n    del stats\n    gc.collect()\n\n    return df_stats","9e521d3f":"get_stats(train)","fdfc09a1":"get_stats(test)","dfe03a95":"head_cols = [col for col in train.columns if ('g-' not in col)&('c-' not in col)]\ng_cols = [col for col in train.columns if 'g-' in col][:100]\nc_cols = [col for col in train.columns if 'c-' in col]\n\nincluded_cols = head_cols + g_cols + c_cols\nsplit_on = ['sig_id','g-0','c-0']","36a57f17":"profile = ProfileReport(train[included_cols], title=\"Pandas Profiling Report\", minimal=True)\nprofile","224a8714":"profile.to_file(\"pandas_profiler_output.html\")","cd6bf145":"display(HTML('<h2 id=\"home\"> Feature reference guide <\/h2>'))","a901a681":"# EDA detailed output\nclass EDA():\n    def __init__(self, train, test, included_cols, N=5, advanced_graph=True):\n        self.train = train\n        self.test = test\n        self.included_cols = included_cols\n        self.N = N\n        self.advanced_graph = advanced_graph\n\n    def h(self, content):\n        display(HTML(content))\n\n    def _desc(self, data, col, label):\n        d0 = data.describe().reset_index()\n        d0.columns = [col, label]\n        return d0.append({col: 'unique values', label: data.unique().shape[0]}, ignore_index=True) \\\n            .append({col: 'NaNs', label: data.isnull().sum()}, ignore_index=True) \\\n            .append({col: 'NaNs %', label: np.round(data.isnull().sum() \/ data.shape[0], 4)}, ignore_index=True) \\\n\n    def desc(self, col, categorical=False):\n\n        d0 = self._desc(self.train[col], col, 'Train')\n        d1 = self._desc(self.test[col], col, 'Test')\n\n        dd = d0.merge(d1)\n        display(dd)  \n        \n        if col not in ['sig_id']:\n            self.h('<b>Top  '+ str(self.N) +' most popular values (NaN = -999):<\/b>')\n            d0 = self.train[[col]].fillna(-999).value_counts(col).reset_index(drop=False)\n            d0.columns = [col,'Count'] \n            d1 = self.test[[col]].fillna(-999).value_counts(col).reset_index(drop=False)\n            d1.columns = [col,'Count'] \n            dd = d0.merge(d1, how='left', on=col).head(self.N)\n            dd = dd.rename({'Count_x': 'Count in Train (desc)', 'Count_y': 'Count in Test'}, axis=1)\n            display(dd)\n        \n            if self.advanced_graph and categorical:\n                fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n                d0.plot(kind='bar', x= col, y='Count', color='green', alpha=0.8, title='Train: ' + col, legend=False, xlabel='', ylabel='Count',rot=0, ax=axs[0])\n                d1.plot(kind='bar', x= col, y='Count', color='red', alpha=0.8, title='Test: ' + col, legend=False, xlabel='', rot=0, ax=axs[1])\n                plt.show()         \n\n        del dd, d0, d1\n        gc.collect()\n        \n    def desc_target(self, col, categorical=False):\n        dd = self._desc(self.train_target[col], col, 'Train target')\n        display(dd)     \n\n        del dd\n        gc.collect()    \n\n    def hist(self, col):\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        self.train[col].plot(kind='hist',bins=70, color='green', alpha=0.8, title='Train histogram: ' + col, ax=axs[0])\n        self.test[col].plot(kind='hist',bins=70, color='red', alpha=0.8, title='Test histogram: ' + col, ax=axs[1])\n        plt.ylabel('')\n        plt.show()\n\n    def corr(self, col):\n        num_vars = [f for f in self.train.columns if self.train[f].dtype != 'object']\n        corrs = self.train[num_vars].corrwith(self.train[col]).reset_index().sort_values(0, ascending=False).reset_index(\n            drop=True).rename({'index': 'Column', 0: 'Correlation with ' + col}, axis=1)\n        self.h('<b>Most correlated features with ' + col + ':<\/b>')\n        trx = pd.concat([corrs.head(self.N+1), corrs.dropna().tail(self.N)])\n\n        def linkx(val):\n            return '<a href=\"#c_{}\">{}<\/a>'.format(val, val) if val in self.included_cols else val\n\n        trx['Column'] = trx['Column'].apply(linkx)\n        self.h(trx.to_html(escape=False))\n\n        del trx, corrs\n        gc.collect()       \n\n    def numeric(self, col):\n        self.hist(col)\n        self.desc(col)\n        self.corr(col)\n\n    def categorical(self, col):\n        self.desc(col, categorical=True)\n\n    def run(self, col):\n        self.h('<h3 id=\"c_' + col + '\">' + col + '<\/h3>' + '<a style=\"font-size:11px\" href=\"#home\">(Jump to top)<\/a>')   \n        self.categorical(col) if self.train[col].dtype == 'object' else self.numeric(col)","a85ee272":"eda = EDA(train, test, included_cols)","2acd798e":"eda.h('<b id=\"home\">Links to features info:<\/b> ' + ', '.join([('<li>' if col in split_on else '') + '<a href=\"#c_' + col + '\">' + col + '<\/a>' for col in included_cols]))\neda.h('Train shape: <b>' + str(train.shape) + '<\/b>' + \n  '<br>Test shape: <b>' + str(test.shape) + '<\/b>')\neda.h('Train preview:')\ndisplay(train.head(10))","e3c5de4b":"for c in eda.included_cols:\n    eda.run(c)","c6bc7e30":"Here you might want to change the scope of features, included in the reference.","beda9cf3":"## Introductory stats ## ","b2a2c8da":"Actually I borrowed the idea and code from the cool kernel by @alijs [here](https:\/\/www.kaggle.com\/alijs1\/ieee-transaction-columns-reference) during IEEE-CIS Fraud Detection competition. Though I was quite unlucky in that contest, i did learn some good tricks. Now, preparing presentation about EDA techiniques for my colleagues and going through my notes, I thought I'd be happy if this universal approach might come in handy for someone here. \n\nThe idea is to generate basic stats for each column so you could get some first insights quickly and then save it easily as html doc to have always at hand.\nAlso I added some basic stats (get_stats function) I get used to gathering at the start of EDA. I've seen this code and its reincarnations across many Kaggle notebooks before and believe (but not quite sure) that it had originated by @artgor in one of his old kernels.\n\nUPDATE:\nAdded Pandas Profiling report stats ([pandas-profiling](https:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/master\/index.html)) as a good, easy-to-use alternative you can launch and go grab some coffee. It provides you with tons of auto-generated stats for each feature - just click on **toggle details** to see all metrics. I run it with **minimal=True** option (saved to pandas_profiler_output.html) since the standard, full API doesn't go well with such a large dataset. If you still want to try the full mode, you are free to do it - launch it, go grab some coffee, start your business, get married etc. When you get back, it may still be running.","d0a64bb5":"## Pandas Profiling stats ## "}}