{"cell_type":{"b53b229c":"code","61993af2":"code","9ab6a704":"code","5afa78f4":"code","be1de57d":"code","3d2f522c":"code","edad4450":"code","5a49154d":"code","9e82fa98":"code","d81a6979":"code","a353e991":"code","ee24c87e":"code","23dab1ee":"code","7b51fb23":"code","d3e8a1bf":"code","7ac90ba2":"code","744fa49f":"code","22dfe950":"code","c613a8cd":"code","cf6d3f26":"code","14944a80":"code","084cbbc0":"code","6589e5c0":"code","2e6257e3":"code","02e7a466":"code","fcd0dad0":"code","ca8723c9":"code","88e1980f":"code","42f8c8f4":"code","dcb314ab":"code","9420bc47":"code","005b3bd2":"code","0f939e94":"code","4d9f656c":"code","1b11da06":"code","440fe193":"code","daa0f087":"code","29441e8c":"code","c1229f13":"code","32a098a6":"code","662ebbe2":"code","760cd9ba":"code","5deabcae":"code","195ff5e1":"code","2a1d6c47":"code","894f569d":"code","9e2dbf60":"code","1a5f8675":"code","4bfd8952":"code","93585d1e":"code","d6c48931":"code","813424f1":"code","a510e31b":"code","1641f658":"code","ff62c530":"code","e0daf2d0":"code","165ca157":"code","27e1b4ac":"code","838f20ba":"code","c1d2d645":"code","7e35bf7c":"code","de9b7fa5":"code","dea0f732":"code","c158a4f7":"code","a8c01e25":"code","69dafd0a":"markdown","07ec1bfb":"markdown","c65209d0":"markdown","d730638d":"markdown","aae1da13":"markdown","883b6b98":"markdown"},"source":{"b53b229c":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.stem.porter import PorterStemmer\n\nimport re\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\nfrom collections import Counter\n\nfrom tqdm import tqdm\nimport os\n\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n# word cloud library\nfrom wordcloud import WordCloud\n\n# matplotlib\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir())","61993af2":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9ab6a704":"train_data = pd.read_csv(\"\/kaggle\/input\/mercari-price-suggestion-challenge\/train.tsv\", sep='\\t') \nprint(\"Shape of train_data\",train_data.shape)\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/mercari-price-suggestion-challenge\/test_stg2.tsv\", sep='\\t') \ntrain_data.head(3)\n\ntrain_data.describe().T","5afa78f4":"test_data.shape","be1de57d":"sum(train_data['price']==0)","3d2f522c":"### 874 items are free","edad4450":"plt.subplot(1,2,1)\n(train_data['price']).hist(bins=50, figsize=(20,10), range=[0,250], edgecolor = 'white',grid=False)\nplt.xlabel('price')\nplt.ylabel('frequency')\n\nplt.subplot(1,2,2)\nnp.log(train_data['price']).hist(bins=50, figsize=(20,10), range=[0,7], edgecolor = 'white', grid=False)\nplt.xlabel('log of price')\nplt.ylabel('frequency')\n\nplt.plot();\n","5a49154d":"## thus ditribution of price is log-normal","9e82fa98":"# Shipping","d81a6979":"sns.countplot(train_data['shipping'])\nplt.title('train shipping')","a353e991":"sns.countplot(test_data['shipping'])\nplt.title('test shipping')","ee24c87e":"### thus we can say train and test data for shipping has same distribution","23dab1ee":"price_ship0 = train_data[train_data['shipping']==1]['price'].values\nprice_ship1 = train_data[train_data['shipping']==0]['price'].values","7b51fb23":"plt.figure(figsize=(15,8), edgecolor = 'black')\nplt.hist(price_ship0, bins = 50, range=[0,250], alpha = 1, color = 'green', label = 'ship = 0')\nplt.hist(price_ship1, bins = 50, range=[0,250],alpha = 0.7, color = 'blue', label = 'ship = 1')\nplt.plot();\n","d3e8a1bf":"### generally the higher priced elements has shipping 1 i.e. paid by seller","7ac90ba2":"# item condition","744fa49f":"sns.countplot(train_data['item_condition_id'])","22dfe950":"sns.countplot(test_data['item_condition_id'])","c613a8cd":"sns.jointplot('item_condition_id','price',train_data, ratio = 3)","cf6d3f26":"### thus as item condition id increases price generally decreases","14944a80":"# brand name","084cbbc0":"train_data['brand_name'].nunique()","6589e5c0":"sum(train_data['brand_name'].isnull())","2e6257e3":"train_data.fillna('Nobrand',inplace = True)","02e7a466":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['brand_name'].value_counts()[:20].index),train_data['brand_name'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.title(\"Brands with their number of products\")\nplt.plot();","fcd0dad0":"### these are costlier brands","ca8723c9":"# category_names","88e1980f":"def sep_in_cat(x):\n    try:\n        if(len(x.split('\/'))<3):\n            return (x.split('\/')[0],'','')\n        return x.split('\/')\n    except:\n        return (\"No label\",\"No label\",\"No label\")","42f8c8f4":"train_data['cat1'], train_data['cat2'], train_data['cat3'] = zip(*train_data['category_name'].apply(lambda x: sep_in_cat(x)))","dcb314ab":"test_data['cat1'], test_data['cat2'], test_data['cat3'] = zip(*test_data['category_name'].apply(lambda x: sep_in_cat(x)))","9420bc47":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['cat1'].value_counts()[:20].index),train_data['cat1'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.plot();","005b3bd2":"### approx 6k points have no value","0f939e94":"train_data['cat2'].nunique()","4d9f656c":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['cat2'].value_counts()[:20].index),train_data['cat2'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.plot();","1b11da06":"train_data['cat3'].nunique()","440fe193":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['cat3'].value_counts()[:20].index),train_data['cat3'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.plot();","daa0f087":"# Preprocessing","29441e8c":"import re\n\ndef decontracted(phrase):\n    # specific\n    phrase = str(phrase)\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","c1229f13":"stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","32a098a6":"from tqdm import tqdm\n\n# tqdm is for printing the status bar\ndef clean_para(row):\n    preprocessed_item_description = []\n    sentance = row\n    sent = decontracted(sentance)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    # https:\/\/gist.github.com\/sebleier\/554280\n    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n    preprocessed_item_description.append(sent.lower().strip())\n    return preprocessed_item_description[0]\n","662ebbe2":"train_data['item_description'] = train_data['item_description'].apply(lambda x:clean_para(x))\ntest_data['item_description'] = test_data['item_description'].apply(lambda x:clean_para(x))","760cd9ba":"train_data['name'] = train_data['name'].apply(lambda x:clean_para(x))\ntest_data['name'] = test_data['name'].apply(lambda x:clean_para(x))","5deabcae":"def clean_simple(i):\n    temp = \"\"\n    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n        temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n        temp = temp.replace('&','_')\n        temp = temp.replace('-','_')\n        temp = temp.replace('+','_')\n        \n    return temp.strip()","195ff5e1":"train_data['cat1'] = train_data['cat1'].apply(lambda x:clean_simple(x))\ntrain_data['cat2'] = train_data['cat2'].apply(lambda x:clean_simple(x))\ntrain_data['cat3'] = train_data['cat3'].apply(lambda x:clean_simple(x))\n\ntest_data['cat1'] = test_data['cat1'].apply(lambda x:clean_simple(x))\ntest_data['cat2'] = test_data['cat2'].apply(lambda x:clean_simple(x))\ntest_data['cat3'] = test_data['cat3'].apply(lambda x:clean_simple(x))\n\n","2a1d6c47":"train_data['brand_name'] = train_data['brand_name'].apply(lambda x:clean_simple(str(x)))\ntest_data['brand_name'] = test_data['brand_name'].apply(lambda x:clean_simple(str(x)))\n","894f569d":"train_data.drop(columns = ['category_name'], inplace = True)\ntest_data.drop(columns = ['category_name'], inplace = True)","9e2dbf60":"#import h5py\n\n#train_data.to_hdf(\"train_data_preprocessed.h5\",key=\"train\")\n\n#test_data.to_hdf(\"test_data_preprocessed.h5\",key=\"test\")","1a5f8675":"train_data.head()","4bfd8952":"y=train_data['price'].values\ntrain_data.drop(['price'], axis=1, inplace=True)      # drop project is approved columns  \n\nx=train_data","93585d1e":"from sklearn.model_selection import train_test_split\n\nx_train,x_cv,y_train,y_cv= train_test_split(x,y,test_size=0.3,random_state=0)\n\nprint(\"Shape of train\",x_train.shape,y_train.shape)\nprint(\"Shape of cv\",x_cv.shape,y_cv.shape)\nprint(\"Shape of test\",test_data.shape)","d6c48931":"## OHE of categorical data","813424f1":"# OHE of subject category\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizercat1 = CountVectorizer(ngram_range = (1,2),)\nvectorizercat1.fit(x_train['cat1'].values) # fit has to happen only on train data\n\n\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_cat1 = vectorizercat1.transform(x_train['cat1'].values)\nx_cv_bow_cat_1 = vectorizercat1.transform(x_cv['cat1'].values)\nx_test_bow_cat_1 = vectorizercat1.transform(test_data['cat1'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_cat1.shape, y_train.shape)\nprint(x_cv_bow_cat_1.shape, y_cv.shape)\nprint(x_test_bow_cat_1.shape)\n\nprint(\"=\"*100)\n\n\nvectorizercat2 = CountVectorizer(ngram_range = (1,3),)\nvectorizercat2.fit(x_train['cat2'].values) # fit has to happen only on train data\n\n\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_cat2 = vectorizercat2.transform(x_train['cat2'].values)\nx_cv_bow_cat2 = vectorizercat2.transform(x_cv['cat2'].values)\nx_test_bow_cat2 = vectorizercat2.transform(test_data['cat2'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_cat2.shape, y_train.shape)\nprint(x_cv_bow_cat2.shape, y_cv.shape)\nprint(x_test_bow_cat2.shape)\n\nprint(\"=\"*100)\n\nvectorizercat3 = CountVectorizer(ngram_range = (1,4),)\nvectorizercat3.fit(x_train['cat3'].values) # fit has to happen only on train data\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_cat3 = vectorizercat3.transform(x_train['cat3'].values)\nx_cv_bow_cat3 = vectorizercat3.transform(x_cv['cat3'].values)\nx_test_bow_cat3 = vectorizercat3.transform(test_data['cat3'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_cat3.shape, y_train.shape)\nprint(x_cv_bow_cat3.shape, y_cv.shape)\nprint(x_test_bow_cat3.shape)\n\nprint(\"=\"*100)","a510e31b":"#brand name\nvectorizercat1 = CountVectorizer(ngram_range = (1,2))\nvectorizercat1.fit(x_train['brand_name'].values) # fit has to happen only on train data\n\n\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_brand_name = vectorizercat1.transform(x_train['brand_name'].values)\nx_cv_bow_brand_name = vectorizercat1.transform(x_cv['brand_name'].values)\nx_test_bow_brand_name = vectorizercat1.transform(test_data['brand_name'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_brand_name.shape, y_train.shape)\nprint(x_cv_bow_brand_name.shape, y_cv.shape)\nprint(x_test_bow_brand_name.shape)\n\nprint(\"=\"*100)","1641f658":"## TFIDF","ff62c530":"# item description\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer8 = TfidfVectorizer(ngram_range = (1,3), max_features = 80000)\n\ncleaned_item_description_xtr_tfidf = vectorizer8.fit_transform(x_train['item_description'])\nprint(\"Shape of matrix after one hot encodig \",cleaned_item_description_xtr_tfidf.shape)\ncleaned_item_description_xcv_tfidf = vectorizer8.transform(x_cv['item_description'])\nprint(\"Shape of matrix after one hot encodig \",cleaned_item_description_xcv_tfidf.shape)\n\n\ncleaned_item_description_xtest_tfidf = vectorizer8.transform(test_data['item_description'])\nprint(\"Shape of matrix after one hot encodig \",cleaned_item_description_xtest_tfidf.shape)\n\nprint(\"After vectorizations\")\nprint(cleaned_item_description_xtr_tfidf.shape, y_train.shape)\nprint(cleaned_item_description_xcv_tfidf.shape, y_cv.shape)\nprint(cleaned_item_description_xtest_tfidf.shape)\n\nprint(\"=\"*100)","e0daf2d0":"#name\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer9 = TfidfVectorizer(ngram_range = (1,2), max_features = 50000)\n\nclean_names_xtr_tfidf = vectorizer9.fit_transform(x_train['name'])\n\nclean_names_xcv_tfidf = vectorizer9.transform(x_cv['name'])\n\nclean_names_xtest_tfidf = vectorizer9.transform(test_data['name'])\n\nprint(\"After vectorizations\")\nprint(clean_names_xtr_tfidf.shape, y_train.shape)\nprint(clean_names_xcv_tfidf.shape, y_cv.shape)\nprint(clean_names_xtest_tfidf.shape)\n\nprint(\"=\"*100)","165ca157":"# shipping and item_condition\nfrom sklearn.preprocessing import MinMaxScaler # NORMALIZE\n\nmnn=MinMaxScaler()\nX_train_std = mnn.fit_transform(x_train[[\"item_condition_id\",\"shipping\" ]])\nX_cv_std = mnn.fit_transform(x_cv[[ \"item_condition_id\",\"shipping\" ]])\nX_test_std = mnn.transform(test_data[[ \"item_condition_id\",\"shipping\" ]])\nprint(X_train_std.shape)\nprint(X_cv_std.shape)\nprint(X_test_std.shape)","27e1b4ac":"from scipy.sparse import hstack\nX_train = hstack((x_train_bow_cat1 ,x_train_bow_cat2 ,x_train_bow_cat3 ,x_train_bow_brand_name,cleaned_item_description_xtr_tfidf, clean_names_xtr_tfidf, X_train_std)).tocsr()\n\nX_cv =    hstack((x_cv_bow_cat_1 ,x_cv_bow_cat2 ,x_cv_bow_cat3 ,x_cv_bow_brand_name, cleaned_item_description_xcv_tfidf, clean_names_xcv_tfidf, X_cv_std)).tocsr()\n\nX_test = hstack((x_test_bow_cat_1,x_test_bow_cat2 ,x_test_bow_cat3 ,x_test_bow_brand_name, cleaned_item_description_xtest_tfidf,clean_names_xtest_tfidf, X_test_std)).tocsr()\n\nprint(\"Final Data matrix\")\nprint(X_train.shape, y_train.shape)\nprint(X_cv.shape, y_cv.shape)\nprint(X_test.shape)\nprint(\"=\"*100)","838f20ba":"def rmsle(real, predicted):\n    sum=0.0\n    for x in range(len(predicted)):\n        if predicted[x]<0 or real[x]<0: #check for negative values\n            continue\n        p = np.log(predicted[x]+1)\n        r = np.log(real[x]+1)\n        sum = sum + (p - r)**2\n    return (sum\/len(predicted))**0.5","c1d2d645":"from sklearn.linear_model import SGDRegressor\n\nmodel = SGDRegressor()\nmodel.fit(X_train, y_train)","7e35bf7c":"train_preds = model.predict(X_train)\ncv_preds = model.predict(X_cv)\ntest_preds = model.predict(X_test)","de9b7fa5":"print(rmsle(y_train,train_preds),\"    \",rmsle(y_cv,cv_preds))","dea0f732":"result = pd.DataFrame({'test_id' : range(0,len(test_preds)),\n                       'price' : test_preds})","c158a4f7":"result.shape","a8c01e25":"\n\nresult.to_csv(\"submission.csv\", index = False)","69dafd0a":"train_data.describe().T","07ec1bfb":"plt.figure(figsize = (15,7))\nsns.barplot(top_15, [brand_mean_price[x] for x in top_15])\nplt.xticks(rotation = 45)\nplt.plot();","c65209d0":"# price","d730638d":"# EDA","aae1da13":"top_15= sorted(brand_mean_price, key = brand_mean_price.get, reverse = True)[:15]","883b6b98":"brand_mean_price={}\n\nfor brand in train_data['brand_name'].unique():\n    mean_price = train_data[train_data['brand_name'] == brand]['price'].mean()\n    brand_mean_price[brand] = mean_price"}}