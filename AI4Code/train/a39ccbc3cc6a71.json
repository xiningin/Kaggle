{"cell_type":{"7a553760":"code","0b744a52":"code","f13f373b":"code","f88be6bc":"code","b8c6c3c4":"code","bb2cb836":"code","ff0c2934":"code","245e92fd":"code","682bf375":"code","e73b34cf":"code","b4718e97":"code","289abfef":"code","53e681dc":"markdown","97ba6db5":"markdown","be3d9d51":"markdown"},"source":{"7a553760":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport os\nprint(os.listdir('..\/input'))\n\n%matplotlib inline","0b744a52":"data = pd.read_csv(\"..\/input\/car_evaluation.csv\")\ndata.head()","f13f373b":"# assigning column names \ndata.columns = [\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"value\"]\ndata.head()","f88be6bc":"# to view class distribution\ndata.value.value_counts().plot(kind='bar', title='Count (target)');","b8c6c3c4":"# Class count\nclass_count = data.value.value_counts()\n# for oversampling getting the max count\nmax_class = max(class_count)\n\n# Divide DataFrame by class\ndf_class_0 = data[data['value'] == \"acc\"]\ndf_class_1 = data[data['value'] == \"good\"]\ndf_class_2 = data[data['value'] == \"unacc\"]\ndf_class_3 = data[data['value'] == \"vgood\"]\n\n#Oversampling\ndf_class_0_over = df_class_0.sample(max_class,replace = True)\ndf_class_1_over = df_class_1.sample(max_class,replace = True)\n# df_class_2_over = df_class_2.sample(max_class) # not using maximum class\ndf_class_3_over = df_class_3.sample(max_class,replace = True)\n\ndata_os = pd.concat([df_class_0_over,df_class_1_over,df_class_3_over,df_class_2], axis = 0)\ndata_os.value.value_counts().plot(kind='bar', title='Count (target)');","bb2cb836":"# data cleansing\ndata_os.doors = data_os.doors.replace({\"5more\": 5}) \n# data_os.doors = data_os.doors.replace({\"3\":2,\"5\":4,\"2\":2,\"4\":4,5:4})\ndata_os.persons = data_os.persons.replace({\"more\": 5})\ndata_os.head()","ff0c2934":"# label encoding\nmap1 = {\"low\" : 1, \"med\":2,\"high\":3, \"vhigh\": 4}\nmap2 = {\"small\" : 1, \"med\":2,\"big\":3}\ndata_os[\"buying\"] = data_os[\"buying\"].map(map1)\ndata_os[\"maint\"] = data_os[\"maint\"].map(map1)\ndata_os[\"safety\"] = data_os[\"safety\"].map(map1)\ndata_os[\"lug_boot\"] = data_os[\"lug_boot\"].map(map2)\ndata_os.head()","245e92fd":"data_os[\"doors\"]  = pd.to_numeric(data_os[\"doors\"])\ndata_os[\"persons\"] = pd.to_numeric(data_os[\"persons\"])\n","682bf375":"data_os[\"car_type\"] = data_os[\"doors\"]+data_os[\"persons\"] # created feature\ntype_dict = {4:\"Coupe\",\n             5:\"Coupe\",\n            6:\"GT\",\n            7:\"Sedan\",\n            8:\"Hatchback\",\n            9:\"SUV\",\n            10:\"SUV\"}\n# data_os[\"car_type\"] = data_os[\"car_type\"].map(type_dict)\n\n# set(data_os[\"car_type\"].values.tolist())\ndata_os[\"car_type\"] = data_os[\"car_type\"].astype('category')","e73b34cf":"target = ['value']\nreject = target\nfeatures = [x for x in data_os.columns if x not in reject]\nx = data_os[features]\ny = data_os[target]","b4718e97":"xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.25, random_state = 0)\nprint(xTrain.shape)\nprint(xTest.shape)","289abfef":"import sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(n_jobs=-1,random_state=51)\n\nmodel.fit(xTrain,yTrain)\nprint(model.score(xTest,yTest))\nprint(sklearn.metrics.f1_score(yTest,model.predict(xTest),average='macro'))","53e681dc":"source :https:\/\/www.kaggle.com\/rafjaa\/resampling-strategies-for-imbalanced-datasets","97ba6db5":"## Data Description\n### Features\n<li><strong>buying:<\/strong> vhigh, high, med, low. <\/li>\n<li><strong>maint:<\/strong> vhigh, high, med, low. <\/li>\n<li><strong>doors: <\/strong>2, 3, 4, 5more. <\/li>\n<li><strong>persons:<\/strong> 2, 4, more. <\/li>\n<li><strong>lug_boot:<\/strong> small, med, big.<\/li> \n<li><strong>safety:<\/strong> low, med, high. <\/li>\n\n### Target\n<li><strong>buying:<\/strong> unacc, acc, good, vgood. <\/li>\n","be3d9d51":"Data is higly imbalanced and bisaed to unacc class. This will result in overfitting.\n<li> acc  - 22% <\/li>\n<li> good  - 3.9% <\/li>\n<li> unacc - 70% <\/li>\n<li> vgood - 3.7% <\/li>\n\nIf the model perdicts all input as unacc then it will be 70% accurate which is wrong.<br>\nHence we cannot conclude a model's performance just by accuracy.\n\nTo overcome this I'm oversampling it"}}