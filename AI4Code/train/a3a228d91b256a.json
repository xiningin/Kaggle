{"cell_type":{"84e6f753":"code","206fbacb":"code","e2713bfe":"code","a6179c5a":"code","ee604363":"code","79368089":"code","e3d4693e":"code","0f730011":"code","bfa6312f":"code","db7e8e90":"code","d742b210":"code","18a14557":"code","d323c20f":"code","9466e49a":"code","705f32b6":"code","a29979aa":"code","f5961192":"code","fedacbc6":"code","dc937f09":"code","ecb8b5da":"code","5d42447e":"code","982e8e32":"code","dbca4320":"code","d2427d8f":"code","452cbdce":"code","abc081f5":"code","3805c9a1":"code","901f7a0a":"code","d3de3757":"code","f7eb1815":"code","e734cfd5":"code","92c30536":"code","080cde7f":"code","b511cfba":"code","bad9009c":"code","77af2193":"code","76baa68d":"code","5ab753fe":"code","2adc34b4":"code","7d84b750":"code","5670043b":"code","bf2c8732":"code","fc7f6b8c":"markdown","d744bbd0":"markdown","e5be8063":"markdown","bc94e304":"markdown","1d7b4a96":"markdown","b12eaf74":"markdown","b08009c0":"markdown","45f0b9d4":"markdown","a2642433":"markdown","760f36ce":"markdown","f8496676":"markdown","e8ef600d":"markdown","d6e5912a":"markdown","0d3ea4a0":"markdown","089c1388":"markdown","b8bf7fb6":"markdown","1d5e9f58":"markdown","27931bc7":"markdown","da1e9d7f":"markdown","67347f61":"markdown","7f7be4e6":"markdown","6463c7ab":"markdown","a87a0dca":"markdown","4ad0d6f2":"markdown","e7a47d09":"markdown","2ea3a7f7":"markdown","651947a9":"markdown","865273cf":"markdown","abf8e356":"markdown"},"source":{"84e6f753":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","206fbacb":"ds_red = pd.read_excel('\/kaggle\/input\/\/dataset_modificado1.xlsx', index_col=0)","e2713bfe":"ds_red","a6179c5a":"ds_red.shape","ee604363":"ds_red.describe","79368089":"import numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\n","e3d4693e":"def dividir_treino_teste(data, perc_treinamento):\n  np.random.seed(0)\n  #np.random.shuffle(data)\n  divisao = int(data.shape[0] * perc_treinamento)\n  conj_treinamento = data[:divisao]\n  conj_teste = data[divisao:]\n  \n  return conj_treinamento,conj_teste","0f730011":"def gerar_atributos_labels(data):\n  \n  labels = data['SARS-Cov-2 exam result']\n\n  atributos = data.iloc[:,5:]\n\n  atributos= preprocessing.StandardScaler().fit(atributos).transform(atributos)\n\n  return atributos, labels","bfa6312f":"def decision_tree_previsto_real(data):\n    \n  # dividir o conjunto de dados em treinamento (70%) e teste\n  pac_treinamento, pac_teste = dividir_treino_teste(data, 0.7)\n\n  # gerar os conjuntos de atributos e labels para treinamento e testes\n  atributos_treinamento, labels_treinamento = gerar_atributos_labels(pac_treinamento)\n  atributos_teste, labels_teste = gerar_atributos_labels(pac_teste)\n\n  # cria uma inst\u00e2ncia de classificador por \u00e1rvore de decis\u00e3o\n  dtr = DecisionTreeClassifier()\n\n  # treina o classificador com os pacientes de treinamento\n  dtr.fit(atributos_treinamento,labels_treinamento)\n\n  # obt\u00e9m previs\u00f5es para os atributos de teste\n  previsoes = dtr.predict(atributos_teste)\n\n  # retorna as previs\u00f5es e os labels teste (reais)\n  return previsoes,labels_teste\n\n\n","db7e8e90":"from sklearn import preprocessing\n\nclasse_prevista, classe_real = decision_tree_previsto_real(ds_red)\n\n# mostra os 10 primeiros resultados\nprint(\"Alguns resultados iniciais...\\n   previsto,  real\")\nfor i in range(10):\n    print(\"{}. {}, {}\".format(i, classe_prevista[i], classe_real[i]))\n ","d742b210":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.tree import DecisionTreeClassifier\n#from support_functions import plot_confusion_matrix\n\n\n","18a14557":"# Implement the following function\ndef calcula_precisao(previsto, real):\n  previsoes = 0\n  previsoes_corretas = 0\n  for i in range(len(previsto)):\n    previsoes += 1\n    if(previsto[i] == real[i]):\n      previsoes_corretas += 1\n  return (previsoes_corretas \/ previsoes)\n    \n","d323c20f":"# split the data\natributos, labels = gerar_atributos_labels(ds_red)\n\n# train the model to get predicted and actual classes\ndtc = DecisionTreeClassifier()\nprevisto = cross_val_predict(dtc, atributos, labels, cv=10)\n\n# calculate the model score using your function\nmodel_score = calcula_precisao(previsto, labels)\nprint(\"Score de precis\u00e3o:\", model_score)\n\n# calculate the models confusion matrix using sklearns confusion_matrix function\nclass_labels = list(set(labels))\nmodel_cm = confusion_matrix(y_true=labels, y_pred=previsto, labels=class_labels)\n\nmodel_cm","9466e49a":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ndef random_forest_previsto_real(data, n_estimators):\n  \n  # gerar atributos e labels\n  atributos, labels = gerar_atributos_labels(data)\n\n  # instanciar um classificador por floresta aleat\u00f3ria\n  rfc = RandomForestClassifier(n_estimators=n_estimators)\n  \n  # obtem previsoes usando 10-fold cross validation\n  previsto = cross_val_predict(rfc,atributos,labels,cv=10)\n\n  # retorna valores previstos e reais\n  return previsto,labels\n\n\n# get the predicted and actual classes\nnum_arvores = 50              \nprevisto, real = random_forest_previsto_real(ds_red, num_arvores)\n\n# calculate the model score using your function\nprecisao = calcula_precisao(previsto, real)\nprint(\"Score de precis\u00e3o:\", precisao)\n\n# calculate the models confusion matrix using sklearns confusion_matrix function\nclass_labels = list(set(real))\nmodel_cm = confusion_matrix(y_true=real, y_pred=previsto, labels=class_labels)\n\nmodel_cm\n","705f32b6":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline","a29979aa":"ds_enc = pd.read_excel('\/kaggle\/input\/\/dataset_classif1.xlsx', index_col=0)","f5961192":"ds_enc","fedacbc6":"ds_enc.shape","dc937f09":"ds_enc['encaminhamento'].value_counts()","ecb8b5da":"import seaborn as sns\n\nbins = np.linspace(ds_enc.Hematocrit.min(), ds_enc.Hematocrit.max(), 10)\ng = sns.FacetGrid(ds_enc, col=\"Patient age quantile\", hue=\"encaminhamento\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Hematocrit', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","5d42447e":"atributos = ds_enc.iloc[:,3:]\n\nX = atributos\ny = ds_enc['encaminhamento'].values","982e8e32":"X","dbca4320":"y","d2427d8f":"X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","452cbdce":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4) #mantendo propor\u00e7\u00e3o de treinamento em 70%\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","abc081f5":"from sklearn.neighbors import KNeighborsClassifier","3805c9a1":"k = 3 \n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh","901f7a0a":"yhat = neigh.predict(X_test)\nyhat[0:5]","d3de3757":"lim=25\navg=np.zeros((lim-1))\nstdd=np.zeros((lim-1))\ncm=[];\nmaxacc = 0;\nbestk = 0;\nfor k in range(1,lim):\n    \n    #Train Model and Predict  \n    kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n    yhat = kNN_model.predict(X_test)\n    avg[k-1]=np.mean(yhat==y_test);\n    stdd[k-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\n    \n    print(\"k = \",k,\"*** accuracy = \",avg[k-1] )\n    \n    if avg[k-1] > maxacc:\n        bestk = k \n        maxacc = avg[k-1]\n   \nprint(\"The best value of k (best accuracy) is: \",bestk)","f7eb1815":"# Building the model again, using the k=7 with best accuracy\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\n#Train Model and Predict  \nkNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\nkNN_model","e734cfd5":"yhat = kNN_model.predict(X_test)\nyhat","92c30536":"from sklearn.tree import DecisionTreeClassifier","080cde7f":"dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4) #profundidade arbitr\u00e1ria por enquanto\ndt","b511cfba":"dt.fit(X_train,y_train)","bad9009c":"yhat1 = dt.predict(X_test)\nyhat1","77af2193":"avg=np.mean(yhat1==y_test);\nprint(\"*** accuracy = \",avg )","76baa68d":"from sklearn import svm\nmodsvm = svm.SVC()\nmodsvm.fit(X_train, y_train) ","5ab753fe":"yhat2 = modsvm.predict(X_test)\nyhat2","2adc34b4":"avg=np.mean(yhat2==y_test);\nprint(\"*** accuracy = \",avg )","7d84b750":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01).fit(X_train,y_train)\nLR","5670043b":"yhat3 = LR.predict(X_test)\nyhat3","bf2c8732":"avg=np.mean(yhat3==y_test);\nprint(\"*** accuracy = \",avg )","fc7f6b8c":"Portanto, dos dois modelos acima, o de floresta aleat\u00f3ria chega a uma melhor precis\u00e3o para diagn\u00f3stico positivo\/negativo.","d744bbd0":"# AN\u00c1LISE DE ENCAMINHAMENTO","e5be8063":"## FLORESTA ALEAT\u00d3RIA","bc94e304":"## \u00c1RVORE DE DECIS\u00c3O","1d7b4a96":"# AN\u00c1LISE DE PREVIS\u00c3O DE DIAGN\u00d3STICO","b12eaf74":"Normaliza\u00e7\u00e3o dos atributos","b08009c0":"Portanto o modelo KNN \u00e9 o que oferece a melhor precis\u00e3o.","45f0b9d4":"Para esta an\u00e1lise, foi gerada uma c\u00f3pia do dataset utilizado acima, onde as colunas: \"Patient addmited to regular ward\", \"Patient addmited to semi-intensive unit\", e \"Patient addmited to intensive care unit\" foram substitu\u00eddas pela coluna \"encaminhamento\", que possui os valores : \n\nRW --> Se \"Patient addmited to regular ward\" = 1\n\nSIU --> Se \"Patient addmited to semi-intensive unit\" = 1\n\nICU --> Se \"Patient addmited to intensive care unit\" = 1\n\nNONE --> Se as tr\u00eas colunas acima = 0\n\nAs demais colunas permanecem as mesmas utilizadas na an\u00e1lise inicial.\n\n","a2642433":"Calcular a precis\u00e3o :","760f36ce":"## Support Vector Machine","f8496676":"Cria\u00e7\u00e3o do modelo","e8ef600d":"## Decision Tree","d6e5912a":"Para a classifica\u00e7\u00e3o, utilizarei a t\u00e9cnica de clusteriza\u00e7\u00e3o - K Nearest Neighbor(KNN). \nVou manter os nomes em ingl\u00eas pois trata-se de c\u00f3digo que eu j\u00e1 havia desenvolvido em treinamento.\n\nEm seguida compararei com outras t\u00e9cnicas para ver qual tem a melhor precis\u00e3o - \n\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression","0d3ea4a0":"## Logistic Regression","089c1388":"De in\u00edcio, realizei uma an\u00e1lise no arquivo excel, e fiz uma s\u00e9rie de pr\u00e9-processamentos direto no arquivo.\n\n1) Das 5644 linhas, exclui todas as que tinham todas as colunas de atributos (vari\u00e1veis independentes ou features) sem valores. A base foi reduzida a 623 linhas.\n\n2) Em seguida, exclu\u00ed todas as colunas de atributos que n\u00e3o tinham valor para nenhuma linha, e (por enquanto) tamb\u00e9m as colunas categ\u00f3ricas. A base foi reduzida a 68 colunas.\n\n3) Coluna \"SARS-Cov-2 exam result\" teve os valores alterados : \"negative\" --> 0, \"positive\"--> 1. S\u00e3o 87 positivos na base reduzida.\n\n4) Portanto, ficamos com as colunas: SARS-Cov-2 exam result,\tPatient addmited to regular ward, Patient addmited to semi-intensive unit, e Patient addmited to intensive care unit como labels (vari\u00e1veis dependentes). Nesta primeira an\u00e1lise somente a primeira ser\u00e1 utilizada.\n\n5) As demais colunas ser\u00e3o os atributos. Patient ID n\u00e3o ser\u00e1 utilizado.\n\n6) C\u00e9lulas vazias (nan) foram preenchidas com zero\n\n","b8bf7fb6":"Abaixo uma breve an\u00e1lise gr\u00e1fica de um atributo exemplo (Hematocrit) observado versus o quantil de idade, mostrando o agrupamento por encaminhamento. \u00c9 poss\u00edvel ver que os encaminhamentos realizados (diferentes de NONE) concentram-se nas faixas de idade iniciais (beb\u00eas e rec\u00e9m nascidos) e idosos.","1d5e9f58":"Duas an\u00e1lises s\u00e3o necess\u00e1rias:\n\n1) a previs\u00e3o de diagn\u00f3stico positivo\/negativo para o v\u00edrus (coluna SARS-Cov-2 exam result). Aqui temos como sa\u00edda apenas uma coluna categ\u00f3rica.\n\n2) a previs\u00e3o de qual ser\u00e1 o encaminhamento para o paciente (colunas Patient addmited to regular ward, Patient addmited to semi-intensive unit, e Patient addmited to intensive care unit). Aqui, ent\u00e3o, temos 3 colunas categ\u00f3ricas.\n\n3) o modelo de classifica\u00e7\u00e3o escolhido foi o de \u00c1RVORES DE DECIS\u00c3O, depois comparado com FLORESTAS ALEAT\u00d3RIAS","27931bc7":"Divis\u00e3o da massa de dados em pacientes (linhas) de TREINAMENTO e TESTE","da1e9d7f":"Construir novamente o modelo, usando k = 4 para melhor precis\u00e3o, como obtido acima","67347f61":"Sele\u00e7\u00e3o dos labels e atributos, seguindo o mesmo crit\u00e9rio acima.","7f7be4e6":"## Classifica\u00e7\u00e3o","6463c7ab":"C\u00e1lculo da precis\u00e3o (accuracy) do modelo, e matriz de confus\u00e3o","a87a0dca":"Calcular a precis\u00e3o :","4ad0d6f2":"Iniciarei com 3 clusters; abaixo testaremos a precis\u00e3o para escolher um valor melhor.","e7a47d09":"An\u00e1lise da sa\u00edda do modelo gerado","2ea3a7f7":"### Carga do novo arquivo reduzido","651947a9":"Aqui escolheremos o melhor valor (melhor precis\u00e3o) para o n\u00famero de clusters","865273cf":"Divis\u00e3o das colunas em atributos (vari\u00e1veis independentes) e labels (r\u00f3tulos, vari\u00e1vel dependente). Tamb\u00e9m **normaliza** os atributos.","abf8e356":"## KNN"}}