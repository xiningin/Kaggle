{"cell_type":{"367a447e":"code","a3a2bb90":"code","f9633e51":"code","f53797d4":"code","902fbe96":"code","c8cb9a52":"code","5716197d":"code","eceeb8fb":"code","e3613131":"code","f47d8a2d":"code","d3457737":"code","eef9b07c":"code","738a7be2":"code","1becd22d":"code","4007285a":"code","b77a6321":"code","8fd3d084":"code","da0bd38f":"code","6c426c15":"code","154780cb":"code","4f7c43b8":"code","f2d088ab":"code","3b4dafc0":"code","8edce58c":"code","6b5cdab0":"code","0aefc517":"markdown","437150cc":"markdown","7ec8f289":"markdown","b7e44e90":"markdown","55b6a97f":"markdown","82dfefb2":"markdown","89cee81b":"markdown","65c0d5e2":"markdown","509f45c1":"markdown","206dac72":"markdown","2f7bdde5":"markdown","8b9185cc":"markdown","1911b487":"markdown"},"source":{"367a447e":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a3a2bb90":"# Let's load our csv data into DataFrame\ndf = pd.read_csv(\"\/kaggle\/input\/insurance-premium-prediction\/insurance.csv\")","f9633e51":"# Get an understanding of the columns and rows\ndf.info()","f53797d4":"# Take a peek into data\ndf.head()","902fbe96":"# Let's check for nulls first\ndf.isnull().any().any()","c8cb9a52":"df.age.unique()","5716197d":"df.sex.unique()","eceeb8fb":"df.sex.replace({'male':1, 'female':0}, inplace=True)","e3613131":"df.bmi.describe()","f47d8a2d":"df.children.unique()","d3457737":"df.smoker.unique()","eef9b07c":"df.smoker.replace({'yes':1, 'no':0}, inplace=True)","738a7be2":"df.region.unique()","1becd22d":"# Using Pandas get_dummies(), we can those new dummy columns.\n# After that we dont need the original region column, dropping it.\n# Concatenating the new dummy columns to the exisiting dataframe.\ndummies = pd.get_dummies(data=df['region'], drop_first=True).rename(columns=lambda x: 'region_' + str(x))\ndf.drop(['region'], inplace=True, axis=1)\ndf = pd.concat([df, dummies], axis=1)","4007285a":"df.expenses.describe()","b77a6321":"sns.boxplot(y=df.expenses)","8fd3d084":"df.expenses = df.expenses[df.expenses<50000]","da0bd38f":"sns.boxplot(y=df.expenses)","6c426c15":"df.dropna(inplace=True)","154780cb":"df.info()","4f7c43b8":"df.head()","f2d088ab":"x = df[df.columns[df.columns != 'expenses']]\ny = df.expenses","3b4dafc0":"# Statsmodels.OLS requires us to add a constant.\nx = sm.add_constant(x)\nmodel = sm.OLS(y,x)\nresults = model.fit()\nprint(results.summary())","8edce58c":"x.drop('sex',axis=1, inplace=True)\nmodel = sm.OLS(y,x)\nresults = model.fit()\nprint(results.summary())","6b5cdab0":"x.drop('region_northwest',axis=1, inplace=True)\nmodel = sm.OLS(y,x)\nresults = model.fit()\nprint(results.summary())\n","0aefc517":"R-squared:                       0.753<br>\nAdj. R-squared:                  0.752<hr>\n","437150cc":"# Medical Expense Prediction\nWe will try and predict the Medical expenses from an individual based on factors like age, sex, bmi etc. so that the Insurance company can set the premium accordingly.","7ec8f289":"Since there are 4 unique values we'll have to use on-hot-encoding technique to deal with this.","b7e44e90":"So finally,<br>\n**predicted_expense** = (**age** x 255.3) + (**bmi** x 318.62) + (**children** x 509.21) + (**smoker** x 23240) - (**region_southeast** x 777.08) - (**region_southwest** x 765.40)<br>\nSo, as we can see the highest factor that affects is if the person is a smoker or not! <mark>A smoker tends to pay 23,240 more medical expense than a non-smoker.<mark>","55b6a97f":"Now we will try to fit a model to this data and try to predict the expenses (dependent variable).","82dfefb2":"Since there are only 2 values, we can map yes:1 and no:0","89cee81b":"Brilliant! None of the rows have any null values. Let's take columns and see if we have to clean any data.","65c0d5e2":"### Data Cleaning","509f45c1":"We are done with data cleaning and preparation. <br>Let's have a look at the dataframe now.","206dac72":"Since there are only 2 values, we can map male:1 and female:0","2f7bdde5":"R-squared:                       0.753<br>\nAdj. R-squared:                  0.752<hr>\nR-squared remains the same but Adj. R-squared increased. That is because, Adj.R-squared takes the number of columns into consideration, whereas R-squared does not. So it's always good to look at Adj. R-squared while removing\/adding columns. In this case, removal of region_northwest has improved the model since Adj. R-squared increased and moved closer towards R-squared.","8b9185cc":"As we can see ,<br>R-squared: 0.753<br>Adj. R-squared: 0.752<hr>We also have p-values >0.05 for columns sex, region_northwest. We will remove these columns one by one and check the difference in the metrics of the model.","1911b487":"Seems like there are a lot of outlier data in our dependent variable. Since we don't have any evidence that these are typos or measurement errors, we will not be replacing these with any other value."}}