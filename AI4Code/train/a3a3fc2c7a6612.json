{"cell_type":{"731e4b3e":"code","416ab44d":"code","91f8e41f":"code","8b71fa4e":"code","31e71179":"code","56625e29":"code","19796f8d":"code","7b44f043":"code","1880acb0":"code","1da29b74":"code","afe00a02":"code","673517a8":"markdown","04186101":"markdown","dab46004":"markdown","213a26ad":"markdown","fead3d98":"markdown","f6e99853":"markdown"},"source":{"731e4b3e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\ndf = pd.read_csv('..\/input\/diabetes.csv')\nprint(df.isnull().any())\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\n\n# Any results you write to the current directory are saved as output.","416ab44d":"print(df.describe())","91f8e41f":"#check for the missing values\nprint(\"Number of rows with 0 values for each variable\")\nfor col in df.columns:\n    missing_rows = df.loc[df[col]==0].shape[0]\n    print(col + \": \" + str(missing_rows))\n","8b71fa4e":"import numpy as np\n\ndf['Glucose'] = df['Glucose'].replace(0, np.nan)\ndf['BloodPressure'] = df['BloodPressure'].replace(0, np.nan)\ndf['SkinThickness'] = df['SkinThickness'].replace(0, np.nan)\ndf['Insulin'] = df['Insulin'].replace(0, np.nan)\ndf['BMI'] = df['BMI'].replace(0, np.nan)\ndf['Glucose'] = df['Glucose'].fillna(df['Glucose'].mean())\ndf['BloodPressure'] = df['BloodPressure'].fillna(df['BloodPressure'].mean())\ndf['SkinThickness'] = df['SkinThickness'].fillna(df['SkinThickness'].mean())\ndf['Insulin'] = df['Insulin'].fillna(df['Insulin'].mean())\ndf['BMI'] = df['BMI'].fillna(df['BMI'].mean())","31e71179":"print(df.describe())","56625e29":"from sklearn import preprocessing\ndf_scaled=preprocessing.scale(df)\ndf_scaled=pd.DataFrame(df_scaled, columns=df.columns)\ndf_scaled['Outcome']=df['Outcome']\ndf=df_scaled\nprint(df.describe().loc[['mean', 'std','max'],].round(2).abs())","19796f8d":"from sklearn.model_selection import train_test_split\nx=df.loc[:,df.columns !='Outcome']\ny=df.loc[:,'Outcome']\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\nx_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.2)","7b44f043":"from keras.models import Sequential\nfrom keras.layers import Dense\nmodel=Sequential()\nmodel.add(Dense(units=32,activation='relu', input_dim=8))\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\nmodel.fit(x_train,y_train,epochs=200)\n","1880acb0":"\nprint(\"Training Accuracy:\"+ str((model.evaluate(x_train, y_train)[1]*100).round(2)))\n\nscores = model.evaluate(x_test, y_test)\nprint(\"Testing Accuracy:\" + str((scores[1]*100).round(2)))","1da29b74":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ny_test_pred = model.predict_classes(x_test)\nc_matrix = confusion_matrix(y_test, y_test_pred)\nax = sns.heatmap(c_matrix, annot=True, \n                 xticklabels=['No Diabetes','Diabetes'],\n                 yticklabels=['No Diabetes','Diabetes'], \n                 cbar=False, cmap='Greens')\nax.set_xlabel(\"Prediction\")\nax.set_ylabel(\"Actual\")","afe00a02":"from sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\ny_test_pred_probs = model.predict(x_test)\nFPR,TPR,_=roc_curve(y_test,y_test_pred_probs)\nplt.plot(FPR,TPR)\nplt.plot([0,1],[0,1],'--',color='Black')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","673517a8":"## 3. Define the model","04186101":"## 4. Evaluate the Model","dab46004":"## 1. Introduction","213a26ad":"# Machine Learning: Classification ","fead3d98":"We must not have missing values in the dataset while training, so I replaces all of those missing values","f6e99853":"## 2. Preparing the Data"}}