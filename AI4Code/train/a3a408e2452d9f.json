{"cell_type":{"6e7d4861":"code","a12ee0ad":"code","be90528b":"code","04d613f2":"code","bfbc7555":"code","03598b58":"code","db57dff5":"code","4b561960":"code","acb7350c":"code","0c42eacf":"code","6a90d239":"code","920727a7":"code","b622a143":"code","e041f9cb":"code","42178ce9":"code","108dcea1":"code","5c473880":"code","5b5c106b":"code","745fb59d":"code","99b5b1ba":"code","3840cd90":"code","39decb24":"markdown","80af0d94":"markdown","bf040afb":"markdown","4d3fc90e":"markdown","94643a95":"markdown","5b39ab3f":"markdown","9db14ab1":"markdown","b6d50b0a":"markdown","b40186ee":"markdown","f48f80a1":"markdown","8630f43b":"markdown","ff0a9797":"markdown","528caa53":"markdown","894d03b4":"markdown","4e295d2e":"markdown","5522a77d":"markdown"},"source":{"6e7d4861":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a12ee0ad":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\n# import cudf\nimport pandas as pd\nimport numpy as np\n# import cupy as cp\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\nimport seaborn as sns\n\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","be90528b":"train = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')\nfeatures = [c for c in train.columns if 'feature' in c]\n\n\n\n","04d613f2":"train.shape","bfbc7555":"train.describe()\n","03598b58":"correlations = train.corr(method='pearson')","db57dff5":"fig, axs = plt.subplots(figsize=(16, 16))\nsns.heatmap(correlations)","4b561960":"#  Missing Values\nprint('Train Nan Valued colas: %d' %train.isna().any().sum())","acb7350c":"n_features = 40\nnan_val = train.isna().sum()[train.isna().sum() > 0].sort_values(ascending=False)\nprint(nan_val)\n\n\nfig, axs = plt.subplots(figsize=(10, 10))\n\nsns.barplot(y = nan_val.index[0:n_features], \n            x = nan_val.values[0:n_features], \n            alpha = 0.8\n           )\n\nplt.title(f'NaN values of train dataset (Top {n_features})')\nplt.xlabel('NaN values')\nfig.savefig(f'nan_values_top_{n_features}_features.png')\nplt.show()\n","0c42eacf":"fig, axs = plt.subplots(1, 2, figsize=(16, 6))\nsns.distplot(train['resp'], ax=axs[0])\nsns.distplot(train['weight'], ax=axs[1])\nfig.savefig('resp_weight_distplot.png')","6a90d239":"fig, ax = plt.subplots(figsize=(16, 8))\n\nresp = train['resp'].cumsum()\nresp_1 = train['resp_1'].cumsum()\nresp_2 = train['resp_2'].cumsum()\nresp_3 = train['resp_3'].cumsum()\nresp_4 = train['resp_4'].cumsum()\n\nresp.plot(linewidth=2)\nresp_1.plot(linewidth=2)\nresp_2.plot(linewidth=2)\nresp_3.plot(linewidth=2)\nresp_4.plot(linewidth=2)\n\nax.set_xlabel (\"Trade\", fontsize=12)\nax.set_title (\"Cumulative Trade returns\", fontsize=18)\n\nplt.legend(loc=\"upper left\");\nplt.savefig('cummulative_trade_growth.png')","920727a7":"fig, ax = plt.subplots(figsize=(16, 12))\nsns.violinplot(data=train[[\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]], \n               inner=\"points\", \n               linewidth=1, \n               palette=\"Set3\", \n               ax=ax)    \nfig.savefig('resp_violinplot.png')","b622a143":"f_mean = train[features[1:]].mean()\ntrain = train.query('weight > 0').reset_index(drop = True)\n","e041f9cb":"train[features[1:]] = train[features[1:]].fillna(f_mean)\ntrain['action'] = (train['resp'] > 0).astype('int')\nnp.save('f_mean.npy', f_mean)","42178ce9":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","108dcea1":"batch_size = 4096\nhidden_units = [384, 896, 896, 394]\ndropout_rates = [\n    0.10143786981358652,\n    0.19720339053599725,\n    0.2703017847244654,\n    0.23148340929571917,\n    0.2357768967777311,\n]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-7\n\noof = np.zeros(len(train['action']))\ngkf = GroupKFold(n_splits = 5)\nfor fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n    X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n    y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n    \n    ckp_path = f'JSModel_{fold}.hdf5'\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n                            min_delta = 1e-4, mode = 'max')\n    ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n                          save_best_only = True, save_weights_only = True, mode = 'max')\n    es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                       baseline = None, restore_best_weights = True, verbose = 0)\n    model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 1000, \n              batch_size = batch_size, callbacks = [rlr, ckp, es], verbose = 0)\n                \n    oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n    score = roc_auc_score(y_val, oof[te])\n    print(f'Fold {fold} ROC AUC:\\t', score)\n    \n    # Finetune 3 epochs on validation set with small learning rate\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate \/ 100)\n    model.load_weights(ckp_path)\n    model.fit(X_val, y_val, epochs = 4, batch_size = batch_size, verbose = 0)\n    model.save_weights(ckp_path)","5c473880":"score_oof = roc_auc_score(train['action'].values, oof)\nprint(score_oof)","5b5c106b":"num_models = 2\n\nmodels = []\nfor i in range(num_models):\n    clf = create_mlp(len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    clf.load_weights(f'.\/JSModel_{i}.hdf5')\n    models.append(clf)\n","745fb59d":"f_mean = np.load('.\/f_mean.npy')\n","99b5b1ba":"env = janestreet.make_env()\nenv_iter = env.iter_test()","3840cd90":"opt_th =  0.502\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = 0.\n        for clf in models:\n            pred += clf(x_tt, training = False).numpy().item() \/ num_models\n        pred_df.action = np.where(pred >= opt_th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","39decb24":"# **Training**","80af0d94":"# **Submitting**","bf040afb":"**Resp Violin Plots**","4d3fc90e":"# **Understanding Data Features \ud83d\udcc8**","94643a95":"# **Understanding Data Spread**","5b39ab3f":"i use this notebook for reference https:\/\/www.kaggle.com\/gogo827jz\/jane-street-neural-network-starter","9db14ab1":"# **Missing Values**","b6d50b0a":"# **Import Libraries \ud83d\udcda**","b40186ee":"# **Importing Data \u270d**","f48f80a1":"# **Features Correlation**","8630f43b":"# **Exploratory Data Analysis \ud83d\udcca**","ff0a9797":"***preprocessing***","528caa53":"**Weight and Resp Distribution Plots**","894d03b4":"# **validation**","4e295d2e":"# How to validate a model on chronologically ordered data which also contains groups?\nSince it takes quite some time to get a utility (leaderboard) score back for our model, it would be nice to be able to 'locally' calculate an indication of a model's performance; independent of the (time expensive and limited) submission API. This would allow for much better tuning of hyper-parameters or other aspects of the model's training process.\n\nIn this notebook I want to lay out a couple of techniques that can be used to do this. For every step we will see that there is a problem with using it for this particular competition. Fortunately the last chapter provides a solution! If you are not interested in an introduction in test and validation techniques, then skip to the bottom. First up: train and test subsets.","5522a77d":"# **Load model**"}}