{"cell_type":{"cac43739":"code","24234542":"code","1fbb0e76":"code","aa0a8aed":"code","d1087dcb":"code","70a2b358":"code","d35d4da3":"code","c36582d0":"code","3d6bb7f2":"code","d0eb06a2":"code","c3193462":"code","0fbe34e8":"code","beeff491":"code","7045ad14":"code","17df7af0":"code","e9bcf8f9":"code","ae6f8556":"code","fd7c150f":"code","630da458":"code","c62a135c":"code","a6e6f06b":"code","6311194e":"code","71c47e19":"code","1482336d":"code","235dcbc5":"code","ca4f8a17":"code","96f119a2":"code","62607cdf":"code","7b25b2b8":"code","51cfe691":"code","7adca3a1":"code","766d68d7":"markdown","c82e6119":"markdown","cea36144":"markdown","35559957":"markdown","a3140c0f":"markdown","c5111f2a":"markdown","d5746de1":"markdown","66c09c20":"markdown","316e49be":"markdown","72957c42":"markdown","103b65a8":"markdown","aaccd548":"markdown","01ddbb34":"markdown"},"source":{"cac43739":"#Importing libraries\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport functools\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import *\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nsns.set()","24234542":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1fbb0e76":"df=pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","aa0a8aed":"#Check for null values\ndf.isnull().sum()","d1087dcb":"#Unique values in 'id'\ndf['id'].nunique()","70a2b358":"#Dropping 'id' and 'Unnamed: 32'\ndf.drop(['id','Unnamed: 32'],axis=1,inplace=True)","d35d4da3":"#Imb check\nprint(df['diagnosis'].value_counts())\nsns.countplot(data=df,x='diagnosis')\nplt.show()","c36582d0":"#Continous var\nContVar=[x for x in df.columns if x in df.loc[:,df.dtypes==np.float].columns]\nfor i in ContVar:\n    sns.distplot(df[i],color='red',label=i,kde=True)\n    plt.legend()\n    plt.show()","3d6bb7f2":"X= df.drop('diagnosis',axis=1).values\ny= df['diagnosis'].values","d0eb06a2":"#Encoding y\nle_y = LabelEncoder()\ny = le_y.fit_transform(y)","c3193462":"#Train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 0)","0fbe34e8":"#Scaling X\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","beeff491":"#All classifiers\nCompleteSummary=[]\nallClf = []\nallClf.append(['DECISION TREE', DecisionTreeClassifier(random_state=0)])\nallClf.append(['RANDOM FOREST', RandomForestClassifier(random_state=0)])\nallClf.append(['LOGISTIC REGRESSION', LogisticRegression(random_state=0)])\nallClf.append(['XGB', XGBClassifier(eval_metric= 'error')])\nallClf.append(['SVM', SVC(random_state=0,probability=True)])\nallClf.append(['KNN', KNeighborsClassifier()])","7045ad14":"def apply_model(model,X_train, X_test, y_train, y_test,CompleteSummary):\n    clf=model[1]\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    confmat = confusion_matrix(y_test, y_pred) \n    accuracies = cross_val_score(estimator = clf, X = X_train, y = y_train, cv = 15)   \n    roc = roc_auc_score(y_test, y_pred)  \n    precision = precision_score(y_test, y_pred)  \n    recall = recall_score(y_test, y_pred) \n    f1 = f1_score(y_test, y_pred)  \n    summary=[]\n    print(model[0])\n    summary.append(model[0])\n    print('CONFUSION MATRIX :')\n    ax = sns.heatmap(confmat, annot=True)\n    ax.set_ylim([0,2])\n    plt.show()\n    print('ACCURACY SCORE :',accuracy_score(y_test, y_pred)*100)\n    summary.append(accuracy_score(y_test, y_pred)*100)\n    print('K-F VALIDATION MEAN ACCURACY :',accuracies.mean()*100)\n    summary.append(accuracies.mean()*100)\n    print('ROC AUC SCORE :',roc)\n    summary.append(roc)\n    print('F1 :',f1)\n    summary.append(f1)\n    print('PRECISION :',precision)\n    summary.append(precision)\n    print('RECALL :',recall)\n    summary.append(recall)\n    CompleteSummary.append(summary)\n    print('x'.center(50,'-'))","17df7af0":"#Mapping the apply_model function\nlist(map(functools.partial(apply_model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test,CompleteSummary=CompleteSummary), allClf))","e9bcf8f9":"summary_df = pd.DataFrame(CompleteSummary, columns= ['Model Name', 'Accuracy Score', 'K-F Valid Mean Accuracy','ROC AUC Score', 'F1', 'Precision', 'Recall'])\nsummary_df.sort_values(by= ['Accuracy Score','K-F Valid Mean Accuracy'], inplace= True, ascending= False)\nsummary_df","ae6f8556":"ax=summary_df.plot.barh(x='Model Name', y={'Accuracy Score', 'K-F Valid Mean Accuracy'},figsize=(16,9))\nax.legend(bbox_to_anchor=(1,1))","fd7c150f":"#Simple NN\ndef nn(inp):\n    clf = Sequential()\n    clf.add(Dense(24, input_dim=inp, activation='relu'))\n    clf.add(Dropout(rate=0.1))\n    clf.add(Dense(24, activation='relu'))\n    clf.add(Dropout(rate=0.1))\n    clf.add(Dense(1, activation='sigmoid'))\n    clf.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\n    return clf","630da458":"X_train.shape","c62a135c":"clf=nn(30)\nclf_fit=clf.fit(X_train, y_train,validation_split= 0.2, epochs=100, batch_size=12)","a6e6f06b":"y_pred = clf.predict_classes(X_test)\nprint('Accuracy :',accuracy_score(y_pred,y_test)*100)","6311194e":"plt.plot(clf_fit.history['accuracy'],label='Training accuracy')\nplt.plot(clf_fit.history['val_accuracy'],label='Validation accuracy')\nplt.title('ACCURACY PLOT')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","71c47e19":"plt.plot(clf_fit.history['loss'],label='Training loss')\nplt.plot(clf_fit.history['val_loss'],label='Validation loss')\nplt.title('LOSS PLOT')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","1482336d":"from sklearn.decomposition import PCA\npca = PCA(n_components=10)\nX_train=pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nprint('VARIANCE EXPLAINED :',pca.explained_variance_ratio_.cumsum()[-1])","235dcbc5":"PCACompleteSummary=[]\nlist(map(functools.partial(apply_model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test,CompleteSummary=PCACompleteSummary), allClf))","ca4f8a17":"PCAsummary_df = pd.DataFrame(PCACompleteSummary, columns= ['Model Name', 'Accuracy Score', 'K-F Valid Mean Accuracy','ROC AUC Score', 'F1', 'Precision', 'Recall'])\nPCAsummary_df.sort_values(by= ['Accuracy Score','K-F Valid Mean Accuracy'], inplace= True, ascending= False)\nPCAsummary_df","96f119a2":"ax=PCAsummary_df.plot.barh(x='Model Name', y={'Accuracy Score', 'K-F Valid Mean Accuracy'},figsize=(16,9))\nax.legend(bbox_to_anchor=(1,1))","62607cdf":"clf=nn(10)\nclf_fit=clf.fit(X_train, y_train,validation_split= 0.2, epochs=100, batch_size=12)","7b25b2b8":"y_pred = clf.predict_classes(X_test)\nprint('Accuracy :',accuracy_score(y_pred,y_test)*100)","51cfe691":"plt.plot(clf_fit.history['accuracy'],label='Training accuracy')\nplt.plot(clf_fit.history['val_accuracy'],label='Validation accuracy')\nplt.title('ACCURACY PLOT')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","7adca3a1":"plt.plot(clf_fit.history['loss'],label='Training loss')\nplt.plot(clf_fit.history['val_loss'],label='Validation loss')\nplt.title('LOSS PLOT')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","766d68d7":"**FIN**","c82e6119":"Pass","cea36144":"All values are unique in 'id'. Can be dropped.\n(However, 'id' could've been assigned on the basis of age, which could play a role but its a long shot) ","35559957":"**SUMMARY**","a3140c0f":"All null(NaN) values in 'Unnamed: 32' (Drop)","c5111f2a":"**DIMENSIONALITY REDUCTION USING PCA (10 Components)**","d5746de1":"~95% variance is explained using 10 components. Can move forward.","66c09c20":"Density dist. for continous variables.","316e49be":"**SUMMARY PCA(10 Components)**","72957c42":"Trying a simple ANN","103b65a8":"Trying a simple ANN","aaccd548":"> **MODELS USED**\n> * XGB\n> * SVM\n> * KNN\n> * Decision Tree\n> * Random Forest\n> * Logistic Regression\n> * ANN","01ddbb34":"(To do Hyperparameter tuning)"}}