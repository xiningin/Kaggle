{"cell_type":{"8cda6f69":"code","2c97f730":"code","15e46e80":"code","806cc2ba":"code","bba3f453":"code","6bb70321":"code","1cde7cf1":"code","183ec433":"code","64e4e41f":"code","f260d779":"code","7bd849b1":"code","51e6e9fd":"code","aac4e5c9":"code","1329b41d":"code","967ba7a8":"code","81b52e42":"code","dcba7c34":"code","9bc56e36":"code","83fd6c77":"code","8bfda88e":"code","f672c867":"code","4ee1b858":"code","652bd9ae":"code","59983f85":"code","e53930cb":"code","71fbc7d7":"code","8d0ace65":"code","681fc20d":"code","f86b5d22":"code","f4b1d5bd":"code","6a1a6283":"code","6b720f32":"code","786232de":"code","c025017d":"code","808fce1e":"code","4977fa1a":"code","513e7d61":"code","e36991b8":"code","69d209c8":"code","ce59969e":"markdown","fda5d68d":"markdown","5452fbf3":"markdown","a0b0a668":"markdown","aa05a93a":"markdown","c90eba7c":"markdown","d97d4468":"markdown","c77984a0":"markdown","35ee284e":"markdown","1cd7903f":"markdown","83d872dd":"markdown","5b627f23":"markdown","c02d96ae":"markdown","e5089f44":"markdown","14b2f987":"markdown","4d67423a":"markdown","c11208d4":"markdown","97a65cf7":"markdown","73f65a28":"markdown","b0c9803a":"markdown","85d98a44":"markdown","0d864e82":"markdown","0b891141":"markdown","49c2743f":"markdown","7b30aebc":"markdown","b344672e":"markdown","22e88f81":"markdown","f279188a":"markdown","6d319ea3":"markdown","5e60b64c":"markdown","bc933795":"markdown","5b64ee05":"markdown","3e2bb066":"markdown"},"source":{"8cda6f69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2c97f730":"#reading in csv file and changing dtype of 'Reported Date column to datetime'\nmm_data = pd.read_csv('\/kaggle\/input\/missing-migrants-project\/MissingMigrants-Global-2019-12-31_correct.csv', parse_dates = ['Reported Date'])","15e46e80":"#dataset information\nmm_data.info()","806cc2ba":"#time period covered in data set\nprint('The Missing Migrants dataset covers the period {0} to {1}'.format(str(mm_data['Reported Date'][5986]), str(mm_data['Reported Date'][0])))","bba3f453":"#missing values\nmm_data.isnull().sum().sort_values(ascending=False)","6bb70321":"#extracting only the rows where 'Number Dead' is null\nnull_number_dead = mm_data[mm_data['Number Dead'].isnull()]\nprint('There are {} missing values in the \"Number Dead\" column.'.format(null_number_dead.shape[0]))","1cde7cf1":"null_number_dead.head()","183ec433":"#boolean mask to filter entries where number missing is not equal to total number dead and missing\nbool_null_number_dead = null_number_dead[null_number_dead['Minimum Estimated Number of Missing'] != null_number_dead['Total Dead and Missing']]","64e4e41f":"bool_null_number_dead","f260d779":"#extracting the rows where 'Number Dead', 'Minimum Estimated Number of Missing', and 'Number of Survivors' have missing data (ie NaN).\nmissing_data = mm_data[mm_data['Number Dead'].isnull() & mm_data['Minimum Estimated Number of Missing'].isnull() & mm_data['Number of Survivors'].isnull()]","7bd849b1":"missing_data","51e6e9fd":"#row 4226\nmm_data.loc[4226, 'Number Dead'] = 3\nmm_data.loc[4226, 'Total Dead and Missing'] = 3\n#row 5253\nmm_data.loc[5253, 'Number Dead' ] = 11\nmm_data.loc[5253, 'Number of Survivors'] = 15\nmm_data.loc[5253, 'Total Dead and Missing'] = 11\n#row 5337\nmm_data.loc[5667, 'Number Dead'] = 6\nmm_data.loc[5667, 'Total Dead and Missing'] = 6\n","aac4e5c9":"#replacing NaN with 0 in 'Number Dead' column\nmm_data['Number Dead'].fillna(0, inplace=True)","1329b41d":"#extracting only those entries where 'Minimum Estimated Number of Missing' is NaN\nnull_missing = mm_data[mm_data['Minimum Estimated Number of Missing'].isnull()]\nprint('There are {} missing values in the \"Minimum Estimated Number of Missing\" column.'.format(null_missing.shape[0]))","967ba7a8":"null_missing.head()","81b52e42":"#boolean mask to filter any values where number dead is not equal to total dead and missing\nbool_null_missing = null_missing[null_missing['Number Dead'] != null_missing['Total Dead and Missing']]\nbool_null_missing.shape[0]","dcba7c34":"#replacing NaN with 0 in 'Minimum Estimated Number of Missing' in main dataset, mm_data\nmm_data['Minimum Estimated Number of Missing'].fillna(0, inplace=True)","9bc56e36":"#extracting relevant row\nnull_loc_coord = mm_data[mm_data['Location Coordinates'].isnull()]\nnull_loc_coord","83fd6c77":"#replacing NaN with approximate location coordinate for row 3097\nmm_data.loc[3097, 'Location Coordinates'] = '20.191944, 12.9675'","8bfda88e":"#any missing values left to handle for columns we are interested in?\nmm_data[['Region of Incident', 'Reported Date', 'Reported Year', \n        'Reported Month', 'Number Dead', 'Minimum Estimated Number of Missing',\n        'Total Dead and Missing', 'Cause of Death', 'Location Coordinates']].isnull().sum()","f672c867":"import matplotlib.pyplot as plt\nimport folium\nimport seaborn as sns\n%matplotlib inline","4ee1b858":"#create new column of marker labels for folium map\nmarker_loc = mm_data['Location Description'] \nmarker_date = mm_data['Reported Date'].dt.date.astype(str)\nmarker_number = mm_data['Total Dead and Missing'].astype(str)\nmarker_cause = mm_data['Cause of Death']\n#adding object series into 'Marker Labels'\nmarker_labels = 'Location: ' + marker_loc + '; Date: '+ marker_date + '; Total Dead and Missing: ' + marker_number + '; Cause of Death: ' + marker_cause\nmm_data['Marker Label'] = marker_labels","652bd9ae":"#map of incidents\n\nfrom ast import literal_eval\nfrom folium.plugins import MarkerCluster\n\nincidents_map = folium.Map(location=[50,0], tiles = 'CartoDB dark_matter', zoom_start=3, min_zoom = 2.5, control_scale = True)\n\nmarker_cluster = MarkerCluster().add_to(incidents_map)\n\nfor i in range(mm_data.shape[0]):\n    loc = list(literal_eval(mm_data.iloc[i]['Location Coordinates']))\n    folium.Marker(\n        location = loc,\n        popup = mm_data.iloc[i]['Marker Label'], \n        tooltip = mm_data.iloc[i]['Marker Label'],\n        icon=folium.Icon(color='red'),\n    ).add_to(marker_cluster)\n\n\ndisplay(incidents_map)\n","59983f85":"from folium.plugins import HeatMap\n\n#create list of lists of coordinates and Total Dead and Missing\nvictims_array = []\nfor i in range(mm_data.shape[0]):\n    victims_array.append(list(literal_eval(mm_data.iloc[i]['Location Coordinates'])))\n    victims_array[i].append(float(mm_data.iloc[i]['Total Dead and Missing']))\n\n\nvictims_map = folium.Map(location=[50,0], tiles = 'CartoDB dark_matter', zoom_start=3, min_zoom = 2.5, control_scale = True)\nHeatMap(victims_array, min_opacity = 0.25).add_to(victims_map)\ndisplay(victims_map)\n","e53930cb":"#number of incidents\nincidents_reg_count = mm_data['Region of Incident'].value_counts()","71fbc7d7":"#bar graph\nsns.set(style=\"white\")\nplt.figure(figsize=(10,10))\nsns.barplot(incidents_reg_count.index, incidents_reg_count.values, palette='YlOrRd_r')\nplt.xlabel('Region', fontsize = 13)\nplt.xticks(rotation = 90)\nplt.ylabel('Number of Incidents', fontsize = 13)\nplt.title('Number of Incidents of Each Region (from January 2014 to December 2019)', fontsize = 15)\nplt.show()","8d0ace65":"#sort main data set in ascending order with regards to time and store in time_ordered_mmdata\ntime_ordered_mmdata = mm_data.sort_values(by='Reported Date', ascending=True)","681fc20d":"#extracting portion of dataset for regions US-Mexico Border, North Africa, and the Mediterranean\ntop_regions_data = time_ordered_mmdata[(time_ordered_mmdata['Region of Incident'] == 'US-Mexico Border') | \n                                       (time_ordered_mmdata['Region of Incident'] == 'North Africa') | \n                                       (time_ordered_mmdata['Region of Incident'] == 'Mediterranean')]","f86b5d22":"#add column of ones called 'Number of Incidents' to top_regions_data to be able to count\ntop_regions_data.loc[:,'Number of Incidents'] = 1","f4b1d5bd":"#grouping by year and region and counting number of incidents\nregion_year_group = top_regions_data.pivot_table(index=['Region of Incident','Reported Year'], values='Number of Incidents', aggfunc='count')\nregion_year_group","6a1a6283":"#plotting as line graphs\nsns.set(style = 'ticks' )\n\nmed = region_year_group.loc['Mediterranean']\nn_a = region_year_group.loc['North Africa']\nus_m =region_year_group.loc['US-Mexico Border']\n\nplt.figure(figsize=(10,10))\n\nplt.plot(med['Number of Incidents'], 'r:' ,label ='Mediterranean', marker = 'o', markersize = 5, mew = 2, linewidth = 3)\nplt.plot(n_a['Number of Incidents'], 'g:' ,label ='North Africa', marker = 'o', markersize = 5, mew = 2, linewidth = 3)\nplt.plot(us_m['Number of Incidents'], 'b:', label ='US-Mexico Border', marker = 'o', markersize = 5, mew = 2, linewidth = 3)\n\nplt.xlabel('Year', fontsize = 13)\nplt.ylabel('Number of Incidents', fontsize = 13)\nplt.title('Number of Incidents by Region (2014 - 2019)', fontsize = 15)\nplt.legend(loc='upper right')\n\nplt.show()\n","6b720f32":"#extracting causes of death (some entries have several causes of death)\n\n#import regular expression library\nimport re\n\n#dict of given causes of death and frequency\n#use regular expression to split string and ignore whitespace\ndict_type_count = {}\nfor d in mm_data['Cause of Death'].index:\n    list_temp = []\n    list_temp.extend(re.split(r'[,]\\s*',mm_data['Cause of Death'][d])) \n    for i in list_temp:\n        if i not in dict_type_count:\n            dict_type_count[i] = 1\n        else:\n            dict_type_count[i] += 1\n\n#converting dictionary into series\ndeath_type_count = pd.Series(dict_type_count)\nprint(death_type_count)","786232de":"#combine all values with 'unknown' as one entry with index 'Unknown', and combine any cause of death related to forms of transport  as 'Vehicle Accident' \ndict_repeated = {}\ndict_repeated['Unknown'] = 0\ndict_repeated['Vehicle Accident'] = 0\nreps = pd.Series(death_type_count.index)\n\nlist_reps =[]\n\nfor i in reps[reps.str.contains(r'[Uu]nknown')]:\n    dict_repeated['Unknown'] += death_type_count[i]\n    list_reps.append(i)\n        \nfor i in reps[reps.str.contains(r'\\b[Tt]ruck\\b')]:\n    dict_repeated['Vehicle Accident'] += death_type_count[i]\n    list_reps.append(i)\n    \nfor i in reps[reps.str.contains(r'[Tt]rain')]:\n    if i not in list_reps:\n        dict_repeated['Vehicle Accident'] += death_type_count[i]\n        list_reps.append(i)\n        \nfor i in reps[reps.str.contains(r'\\b[Bb]us\\b')]: \n    dict_repeated['Vehicle Accident'] += death_type_count[i]\n    list_reps.append(i)\n\nfor i in reps[reps.str.contains(r'[Vv]ehicle')]: \n    if i != 'Accident (non-vehicle)':\n        dict_repeated['Vehicle Accident'] += death_type_count[i]\n        list_reps.append(i)\n        \ndeath_type_count.drop(list_reps, inplace=True)\ndeath_type_count = death_type_count.append(pd.Series(dict_repeated))\nprint('The 10 biggest causes of deaths are: \\n{} '.format(death_type_count.sort_values(ascending=False)[:10]))","c025017d":"from wordcloud import WordCloud, STOPWORDS\n\n\nwordcloud = WordCloud(width = 3000, height = 2000 , background_color = 'black', colormap = 'Reds',\n                       stopwords = STOPWORDS).generate_from_frequencies(death_type_count.to_dict())\n\nfig = plt.figure(figsize = (30,25))\nplt.imshow(wordcloud)\nplt.axis('off')\n\nplt.show()\n","808fce1e":"mm_copy = mm_data.copy()\nmm_copy.loc[:, 'Number of Incidents'] = 1\nmm_copy.head()","4977fa1a":"season_pattern = mm_copy.pivot_table(index='Reported Month', values='Number of Incidents', aggfunc='sum') \nseason_pattern.reset_index(inplace=True)\n#season_pattern","513e7d61":"dict_months = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\nseason_pattern['Reported Month'] = season_pattern['Reported Month'].map(dict_months)","e36991b8":"season_pattern.sort_values(by='Reported Month', inplace=True)\n#check\n#season_pattern","69d209c8":"#plotting number of incidents by month\nimport calendar\nplt.figure(figsize=(10,10))\n\nplt.plot(season_pattern['Reported Month'], season_pattern['Number of Incidents'], 'b-', marker = 'o')\nplt.ylim(0, 700)\nplt.xlabel('Month',fontsize = 13)\nplt.xticks(np.arange(1,13), calendar.month_name[1:13], rotation=20)\nplt.ylabel('Number of Incidents', fontsize = 13)\nplt.title('Number of Incidents by Month', fontsize = 15)\nplt.show()","ce59969e":"### Examining the NaN values of the 'Minimum Estimated Number of Missing' column:","fda5d68d":"<font size = 3>**3. Are there any seasonal patterns in the number of incidents?**<\/font>","5452fbf3":"As a reminder, we are only interested in the columns **'Region of Incident', 'Reported Date', 'Reported Year', 'Reported Month', 'Number Dead', 'Minimum Estimated Number of Missing', 'Total Dead and Missing', 'Cause of Death',** and **'Location Coordinates'**.\n\nOf these columns, the single NaN value for **'Location Coordinates'** remains to be examined.","a0b0a668":"First, we will create a map of incidents using Folium. If you hover over or click on a marker, it will show you the details of the incident which occured there. You can zoom in on each hotspot marker.","aa05a93a":"Drowning is the biggest known cause of death. Other common causes of death are sickness, hypothermia, dehydartion, starvation, harsh weather\/ lack of adequate shelter, and vehicle accidents. When the causes of death are set out like this, it brings to the fore the reality of the asylum seekers' lives. Nobody willingly leaves relative safety to go out into the unknown unless there was a powerful push factor. ","c90eba7c":"## 3. THE QUESTIONS \n","d97d4468":"<font size = 3>**1. In which region  did the greatest number of reported incidents occur, and in which region did the least number of reported incidents occur (from January 2014 to December 2019)?**<\/font>","c77984a0":"Do we drop the 7 remaining entries with missing data involving the number of people affected? Since we will be examining the cause of death statistic, and these entries all report the cause of death, we will not drop these entries. Additionally, as we are changing the NaN values in the dead and missing columns to 0, the values for these columns will not affect the results of the kind of analysis which we will be doing.\n","35ee284e":"The US-Mexico Border experienced the greatest number of incidents in the given period, followed by North Africa, and the Mediterranean. These three regions far outstrip the other regions in the frequency of incidents. Central Asia experienced the least amount of incidents. \n\nA follow up question:\n<font size = 3>**How did the frequency of incidents in each of the top three regions change over the time period (in years)?**<\/font>","1cd7903f":"Now, we will input 0 in place of NaN in the 'Number Dead' column in the main dataset.","83d872dd":"We will create a word map to give an idea of what the biggest causes of death are.","5b627f23":"Comparing the HeatMap with the Marker map of incidents shows that while the US-Mexico border experienced more incidents, the area around North Africs (specifically Libya) claimed the greater number of victims. ","c02d96ae":"## 2. Handling missing data","e5089f44":"### **Examining the single missing value of 'Local Coordinates':**","14b2f987":"We will now create a HeatMap that shows the areas which claimed the most victims (Total Dead and Missing from 2014-2019).","4d67423a":"The 10 entries where the number of missing do not equal the total number dead and missing are entries with missing data for all the columns showing number of people affected. Some entries have URLs and these news sources mention the number dead or missing in the incident. We can use these sources to fill in the NaN values in the main dataset, mm_data.\n\nSo, before we replace NaN values with 0, we will use news sources to fill in the missing data in those entries in the main data set where possible. To begin, we will extract the rows where 'Number Dead', 'Minimum Estimated Number of Missing', and 'Number of Survivors' have missing data (ie NaN).","c11208d4":"**Questions to explore:**\n1. **In which region  did the greatest number of reported incidents occur and in which region did the least number of reported incidents occur?**\n2. **What were the biggest causes of death?**\n3. **Are there any seasonal patterns?**\n\nBefore delving into these questions, we must  explore the missing values in the dataset. For our purposes, we will only need the columns **'Region of Incident', 'Reported Date', 'Reported Year', 'Reported Month', 'Number Dead', 'Minimum Estimated Number of Missing', 'Total Dead and Missing', 'Cause of Death', **and** 'Location Coordinates'** (for mapping). So we will examine the NaN values where they exist for these columns only.","97a65cf7":"In this notebook, I will be exploring and visualising data about migrants who have died or have gone missing along migration routes worldwide. The source of the dataset is \"IOM's Missing Migrants Project\" . Please visit their website for more information [here](https:\/\/missingmigrants.iom.int\/).\n    \n\nThe 'Missing Migrants' dataset records the details of the incidents where migrants (commonly asylum-seekers and refugees) have died or gone missing from January 2014 to December 2019. The data only gives minimum estimates for the number of people affected, and the end of many of these human lives go unrecorded. \n\nBefore creating graphs, I handled the missing values in the columns that I wanted to work with. Then I created a Folium Marker map of incidents and a HeatMap, used Seaborn graphs to visualise data, and used regular expressions to find and extract strings to create a WordCloud.\n\nPlease visit this [Amnesty International link](https:\/\/www.amnesty.org\/en\/what-we-do\/refugees-asylum-seekers-and-migrants\/) for information on how migrants, asylum seekers and refugees are defined. \n\n","73f65a28":"On average over the years covered in the dataset, the number of incidents increase during the Northern Hemisphere's warmer months. Warmer months could bring favourable weather to attempt sea crossings, and also longer days (more sunlight) to travel.","b0c9803a":"The location description of this incident is given as Sahara Desert, Niger. From the Missing Migrants website, one of the locations on a migration routes through Niger is S\u00e9guedine, a town in central eastern Niger in the midst of the Sahara Desert. The location coordinates for this town (20.191944, 12.9675) will be a good approximation for the missing coordinate value in this entry.","85d98a44":"The North African region saw a increase in migrant incidents from 2014 and which peaked in 2016 when over 400 incidents where asyulum seekers perished or went missing. The US-Mexico border shows a steady increase in incident from 2014 to 2018. The incidents in the Mediterranean reached their peak in 2017.  ","0d864e82":"This map gives a very quick look into where migrant incidents have occured. Living in the UK, the Mediterranean crisis is predominantly on the news, and this gives the impression that most migrant incidents occur in southern Europe. As the map shows, it is widespread, and it is shocking to see the scale of suffering.","0b891141":"Checking the information sources associated with the first few entries in null_number_dead indicates that the 'Number Dead' value is null because no one repotedly died in that incident.  This is supported by a cursory glance at the first 5 entries which show that the 'Minimum Estimated Number of Missing' value is the same as the 'Total Dead and Missing' value. If this holds out for all entries in null_number_dead, then we can input 0 for the NaN 'Number Dead' values. Does this hold true for all the entries in null_number_dead? ","49c2743f":"There are no entries where the number of dead is diffierent from the total number of dead and missing so we can  replace the NaN values in the 'Minimum Estimated Number of Missing' column with 0.\n","7b30aebc":"There are 255 entries where 'Number Dead' is NaN.","b344672e":"The missing values of the columns we require have been addressed. We are now ready to answer the questions.","22e88f81":"## 1. About the dataset ","f279188a":"# MISSING MIGRANTS ","6d319ea3":"These are the same 10 entries which we saw above with bool_null_number_dead. We will now fill in the missing data where possible using the accompanying URLs. ","5e60b64c":"<font size = 3>**2. What was the biggest cause of death overall and for particular regions?**<\/font>","bc933795":"In the Missing Migrants dataset, there are 5987 entries and 20 columns. The columns cover the date and location of the incident, the demographic of the migrants involved, the cause and number of deaths, the number of missing migrants as a result of the incident, the number of survivors, links to news sources regarding the incident and the quality of the news sources.","5b64ee05":"### Examining the NaN values of the 'Number Dead' column:","3e2bb066":"Again, as with the 'Number Dead' column, the NaN values for this column indicate that no one is missing as result of the incidence as the value for the 'Number Dead' column is equal to the 'Total Dead and Missing' column. We can thus replace the NaN values in the 'Minimum Estimated Number of Missing' column with 0. It is best to double check that it holds true for all entries in null_missing."}}