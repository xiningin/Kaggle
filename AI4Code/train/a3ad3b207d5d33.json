{"cell_type":{"04925c6a":"code","1a823206":"code","c656769d":"code","199b8122":"code","f3d13ae3":"code","70a196c7":"code","315d80fe":"code","c6a4edbc":"code","fddb9da7":"code","3b77c012":"code","0732e49a":"code","e7af8abc":"code","d1ec18b9":"code","f177ff50":"code","5aea8ce2":"code","f8746ea8":"code","fa367a97":"code","436d599d":"code","46ab3ddd":"code","eb6063fc":"code","2abf8ff9":"code","1014df33":"code","1fca11bc":"code","2c8214e4":"code","d5ba0097":"code","d5742dd2":"code","73d549be":"code","dc65a020":"code","67418faa":"code","366ef18c":"code","418078d8":"code","74541389":"code","6c1a3921":"code","7e0f5485":"code","89aca582":"code","4a71a50f":"code","70a6fa19":"code","011e6dbe":"code","0b47befe":"code","b5d286e3":"code","077f388d":"code","9dd284a8":"code","c74fcd98":"code","cb24f9a6":"code","db79f877":"code","acedde33":"code","8b372dc9":"markdown","a70e0b32":"markdown","d5aac84f":"markdown","061387cb":"markdown","2b354f08":"markdown","01846326":"markdown","422d3eec":"markdown","8794092f":"markdown","5e6879f5":"markdown","c23ac7b7":"markdown","63b310c0":"markdown","7a8fb6e4":"markdown","4ad0b1aa":"markdown","89dd4217":"markdown"},"source":{"04925c6a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport os, gc, pickle, copy, datetime, warnings\nimport pycountry\n\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 500)\npd.options.display.float_format = '{:.2f}'.format","1a823206":"!ls -l ..\/input\/covid19-global-forecasting-week-2\/","c656769d":"# Read in data\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/train.csv\")\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/test.csv\")\n\ntt = pd.concat([train, test], sort=False)\ntt = train.merge(test, on=['Province_State','Country_Region','Date'], how='outer')\n\n# concat Country\/Region and Province\/State\ndef name_place(x):\n    try:\n        x_new = x['Country_Region'] + \"_\" + x['Province_State']\n    except:\n        x_new = x['Country_Region']\n    return x_new\ntt['Place'] = tt.apply(lambda x: name_place(x), axis=1)\n# tt = tt.drop(['Province_State','Country_Region'], axis=1)\ntt['Date'] = pd.to_datetime(tt['Date'])\ntt['doy'] = tt['Date'].dt.dayofyear\ntt['dow'] = tt['Date'].dt.dayofweek\ntt['hasProvidence'] = ~tt['Province_State'].isna()\n\n\ncountry_meta = pd.read_csv('..\/input\/covid19-forecasting-metadata\/region_metadata.csv')\ntt = tt.merge(country_meta, how='left')\n\ncountry_date_meta = pd.read_csv('..\/input\/covid19-forecasting-metadata\/region_date_metadata.csv')\n#tt = tt.merge(country_meta, how='left')\n\ntt['HasFatality'] = tt.groupby('Place')['Fatalities'].transform(lambda x: x.max() > 0)\ntt['HasCases'] = tt.groupby('Place')['ConfirmedCases'].transform(lambda x: x.max() > 0)\n\nfirst_case_date = tt.query('ConfirmedCases >= 1').groupby('Place')['Date'].min().to_dict()\nten_case_date = tt.query('ConfirmedCases >= 10').groupby('Place')['Date'].min().to_dict()\nhundred_case_date = tt.query('ConfirmedCases >= 100').groupby('Place')['Date'].min().to_dict()\nfirst_fatal_date = tt.query('Fatalities >= 1').groupby('Place')['Date'].min().to_dict()\nten_fatal_date = tt.query('Fatalities >= 10').groupby('Place')['Date'].min().to_dict()\nhundred_fatal_date = tt.query('Fatalities >= 100').groupby('Place')['Date'].min().to_dict()\n\ntt['First_Case_Date'] = tt['Place'].map(first_case_date)\ntt['Ten_Case_Date'] = tt['Place'].map(ten_case_date)\ntt['Hundred_Case_Date'] = tt['Place'].map(hundred_case_date)\ntt['First_Fatal_Date'] = tt['Place'].map(first_fatal_date)\ntt['Ten_Fatal_Date'] = tt['Place'].map(ten_fatal_date)\ntt['Hundred_Fatal_Date'] = tt['Place'].map(hundred_fatal_date)\n\ntt['Days_Since_First_Case'] = (tt['Date'] - tt['First_Case_Date']).dt.days\ntt['Days_Since_Ten_Cases'] = (tt['Date'] - tt['Ten_Case_Date']).dt.days\ntt['Days_Since_Hundred_Cases'] = (tt['Date'] - tt['Hundred_Case_Date']).dt.days\ntt['Days_Since_First_Fatal'] = (tt['Date'] - tt['First_Fatal_Date']).dt.days\ntt['Days_Since_Ten_Fatal'] = (tt['Date'] - tt['Ten_Fatal_Date']).dt.days\ntt['Days_Since_Hundred_Fatal'] = (tt['Date'] - tt['Hundred_Fatal_Date']).dt.days\n\n# Merge smoking data\nsmoking = pd.read_csv(\"..\/input\/smokingstats\/share-of-adults-who-smoke.csv\")\nsmoking = smoking.rename(columns={'Smoking prevalence, total (ages 15+) (% of adults)': 'Smoking_Rate'})\nsmoking_dict = smoking.groupby('Entity')['Year'].max().to_dict()\nsmoking['LastYear'] = smoking['Entity'].map(smoking_dict)\nsmoking = smoking.query('Year == LastYear').reset_index()\nsmoking['Entity'] = smoking['Entity'].str.replace('United States', 'US')\n\ntt = tt.merge(smoking[['Entity','Smoking_Rate']],\n         left_on='Country_Region',\n         right_on='Entity',\n         how='left',\n         validate='m:1') \\\n    .drop('Entity', axis=1)\n\n# Country data\ncountry_info = pd.read_csv('..\/input\/countryinfo\/covid19countryinfo.csv')\n\n\ntt = tt.merge(country_info, left_on=['Country_Region','Province_State'],\n              right_on=['country','region'],\n              how='left',\n              validate='m:1')\n\n# State info from wikipedia\nus_state_info = pd.read_html('https:\/\/simple.wikipedia.org\/wiki\/List_of_U.S._states_by_population')[0] \\\n    [['State','Population estimate, July 1, 2019[2]']] \\\n    .rename(columns={'Population estimate, July 1, 2019[2]' : 'Population'})\n#us_state_info['2019 population'] = pd.to_numeric(us_state_info['2019 population'].str.replace('[note 1]','').replace('[]',''))\n\ntt = tt.merge(us_state_info[['State','Population']],\n         left_on='Province_State',\n         right_on='State',\n         how='left')\n\ntt['pop'] = pd.to_numeric(tt['pop'].str.replace(',',''))\ntt['pop'] = tt['pop'].fillna(tt['Population'])\ntt['pop'] = pd.to_numeric(tt['pop'])\n\ntt['pop_diff'] = tt['pop'] - tt['Population']\ntt['Population_final'] = tt['Population']\ntt.loc[~tt['hasProvidence'], 'Population_final'] = tt.loc[~tt['hasProvidence']]['pop']\n\ntt['Confirmed_Cases_Diff'] = tt.groupby('Place')['ConfirmedCases'].diff()\ntt['Fatailities_Diff'] = tt.groupby('Place')['Fatalities'].diff()\nmax_date = tt.dropna(subset=['ConfirmedCases'])['Date'].max()\ntt['gdp2019'] = pd.to_numeric(tt['gdp2019'].str.replace(',',''))","199b8122":"# Correcting population for missing countries\n# Googled their names and copied the numbers here\npop_dict = {'Angola': int(29.78 * 10**6),\n            'Australia_Australian Capital Territory': 423_800,\n            'Australia_New South Wales': int(7.544 * 10**6),\n            'Australia_Northern Territory': 244_300,\n            'Australia_Queensland' : int(5.071 * 10**6),\n            'Australia_South Australia' : int(1.677 * 10**6),\n            'Australia_Tasmania': 515_000,\n            'Australia_Victoria': int(6.359 * 10**6),\n            'Australia_Western Australia': int(2.589 * 10**6),\n            'Brazil': int(209.3 * 10**6),\n            'Canada_Alberta' : int(4.371 * 10**6),\n            'Canada_British Columbia' : int(5.071 * 10**6),\n            'Canada_Manitoba' : int(1.369 * 10**6),\n            'Canada_New Brunswick' : 776_827,\n            'Canada_Newfoundland and Labrador' : 521_542,\n            'Canada_Nova Scotia' : 971_395,\n            'Canada_Ontario' : int(14.57 * 10**6),\n            'Canada_Prince Edward Island' : 156_947,\n            'Canada_Quebec' : int(8.485 * 10**6),\n            'Canada_Saskatchewan': int(1.174 * 10**6),\n            'China_Anhui': int(62 * 10**6),\n            'China_Beijing': int(21.54 * 10**6),\n            'China_Chongqing': int(30.48 * 10**6),\n            'China_Fujian' :  int(38.56 * 10**6),\n            'China_Gansu' : int(25.58 * 10**6),\n            'China_Guangdong' : int(113.46 * 10**6),\n            'China_Guangxi' : int(48.38 * 10**6),\n            'China_Guizhou' : int(34.75 * 10**6),\n            'China_Hainan' : int(9.258 * 10**6),\n            'China_Hebei' : int(74.7 * 10**6),\n            'China_Heilongjiang' : int(38.31 * 10**6),\n            'China_Henan' : int(94 * 10**6),\n            'China_Hong Kong' : int(7.392 * 10**6),\n            'China_Hubei' : int(58.5 * 10**6),\n            'China_Hunan' : int(67.37 * 10**6),\n            'China_Inner Mongolia' :  int(24.71 * 10**6),\n            'China_Jiangsu' : int(80.4 * 10**6),\n            'China_Jiangxi' : int(45.2 * 10**6),\n            'China_Jilin' : int(27.3 * 10**6),\n            'China_Liaoning' : int(43.9 * 10**6),\n            'China_Macau' : 622_567,\n            'China_Ningxia' : int(6.301 * 10**6),\n            'China_Qinghai' : int(5.627 * 10**6),\n            'China_Shaanxi' : int(37.33 * 10**6),\n            'China_Shandong' : int(92.48 * 10**6),\n            'China_Shanghai' : int(24.28 * 10**6),\n            'China_Shanxi' : int(36.5 * 10**6),\n            'China_Sichuan' : int(81.1 * 10**6),\n            'China_Tianjin' : int(15 * 10**6),\n            'China_Tibet' : int(3.18 * 10**6),\n            'China_Xinjiang' : int(21.81 * 10**6),\n            'China_Yunnan' : int(45.97 * 10**6),\n            'China_Zhejiang' : int(57.37 * 10**6),\n            'Denmark_Faroe Islands' : 51_783,\n            'Denmark_Greenland' : 56_171,\n            'France_French Guiana' : 290_691,\n            'France_French Polynesia' : 283_007,\n            'France_Guadeloupe' : 395_700,\n            'France_Martinique' : 376_480,\n            'France_Mayotte' : 270_372,\n            'France_New Caledonia' : 99_926,\n            'France_Reunion' : 859_959,\n            'France_Saint Barthelemy' : 9_131,\n            'France_St Martin' : 32_125,\n            'Netherlands_Aruba' : 105_264,\n            'Netherlands_Curacao' : 161_014,\n            'Netherlands_Sint Maarten' : 41_109,\n            'Papua New Guinea' : int(8.251 * 10**6),\n            'US_Guam' : 164_229,\n            'US_Virgin Islands' : 107_268,\n            'United Kingdom_Bermuda' : 65_441,\n            'United Kingdom_Cayman Islands' : 61_559,\n            'United Kingdom_Channel Islands' : 170_499,\n            'United Kingdom_Gibraltar' : 34_571,\n            'United Kingdom_Isle of Man' : 84_287,\n            'United Kingdom_Montserrat' : 4_922\n           }\n\ntt['Population_final'] = tt['Population_final'].fillna(tt['Place'].map(pop_dict))","f3d13ae3":"tt.loc[tt['Place'] == 'Diamond Princess', 'Population final'] = 2_670","70a196c7":"tt['ConfirmedCases_Log'] = tt['ConfirmedCases'].apply(np.log1p)\ntt['Fatalities_Log'] = tt['Fatalities'].apply(np.log1p)","315d80fe":"tt['Population_final'] = tt['Population_final'].astype('int')\ntt['Cases_Per_100kPop'] = (tt['ConfirmedCases'] \/ tt['Population_final']) * 100000\ntt['Fatalities_Per_100kPop'] = (tt['Fatalities'] \/ tt['Population_final']) * 100000\n\ntt['Cases_Percent_Pop'] = ((tt['ConfirmedCases'] \/ tt['Population_final']) * 100)\ntt['Fatalities_Percent_Pop'] = ((tt['Fatalities'] \/ tt['Population_final']) * 100)\n\ntt['Cases_Log_Percent_Pop'] = ((tt['ConfirmedCases'] \/ tt['Population_final']) * 100).apply(np.log1p)\ntt['Fatalities_Log_Percent_Pop'] = ((tt['Fatalities'] \/ tt['Population_final']) * 100).apply(np.log1p)\n\n\ntt['Max_Confirmed_Cases'] = tt.groupby('Place')['ConfirmedCases'].transform(max)\ntt['Max_Fatalities'] = tt.groupby('Place')['Fatalities'].transform(max)\n\ntt['Max_Cases_Per_100kPop'] = tt.groupby('Place')['Cases_Per_100kPop'].transform(max)\ntt['Max_Fatalities_Per_100kPop'] = tt.groupby('Place')['Fatalities_Per_100kPop'].transform(max)","c6a4edbc":"tt.query('Date == @max_date') \\\n    .query('Place != \"Diamond Princess\"') \\\n    .query('Cases_Log_Percent_Pop > -10000') \\\n    ['Cases_Log_Percent_Pop'].plot(kind='hist', bins=500)\nplt.show()","fddb9da7":"tt.query('Days_Since_Ten_Cases > 0') \\\n    .query('Place != \"Diamond Princess\"') \\\n    .dropna(subset=['Cases_Percent_Pop']) \\\n    .query('Days_Since_Ten_Cases < 40') \\\n    .plot(x='Days_Since_Ten_Cases', y='Cases_Log_Percent_Pop', style='.', figsize=(15, 5), alpha=0.2)\nplt.show()","3b77c012":"PLOT = False\nif PLOT:\n    for x in tt['Place'].unique():\n        try:\n            fig, ax = plt.subplots(1, 4, figsize=(15, 2))\n            tt.query('Place == @x') \\\n                .query('ConfirmedCases > 0') \\\n                .set_index('Date')['Cases_Log_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed log pct pop', ax=ax[0])\n            tt.query('Place == @x') \\\n                .query('ConfirmedCases > 0') \\\n                .set_index('Date')['Cases_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed cases', ax=ax[1])\n            tt.query('Place == @x') \\\n                .query('Fatalities > 0') \\\n                .set_index('Date')['Fatalities_Log_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed log pct pop', ax=ax[2])\n            tt.query('Place == @x') \\\n                .query('Fatalities > 0') \\\n                .set_index('Date')['Fatalities_Percent_Pop'] \\\n                .plot(title=f'{x} confirmed cases', ax=ax[3])\n        except:\n            pass\n        plt.show()","0732e49a":"tt.query('Date == @max_date')[['Place','Max_Cases_Per_100kPop',\n                               'Max_Fatalities_Per_100kPop','Max_Confirmed_Cases',\n                               'Population_final',\n                              'Days_Since_First_Case',\n                              'Confirmed_Cases_Diff']] \\\n    .drop_duplicates() \\\n    .sort_values('Max_Cases_Per_100kPop', ascending=False)","e7af8abc":"tt['Past_7Days_ConfirmedCases_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['ConfirmedCases'].std().to_dict())\ntt['Past_7Days_Fatalities_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['Fatalities'].std().to_dict())\n\ntt['Past_7Days_ConfirmedCases_Min'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['ConfirmedCases'].min().to_dict())\ntt['Past_7Days_Fatalities_Min'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200324').groupby('Place')['Fatalities'].min().to_dict())\n\ntt['Past_7Days_ConfirmedCases_Max'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200324').groupby('Place')['ConfirmedCases'].max().to_dict())\ntt['Past_7Days_Fatalities_Max'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200324').groupby('Place')['Fatalities'].max().to_dict())\n\ntt['Past_7Days_Confirmed_Change_of_Total'] = (tt['Past_7Days_ConfirmedCases_Max'] - tt['Past_7Days_ConfirmedCases_Min']) \/ (tt['Past_7Days_ConfirmedCases_Max'])\ntt['Past_7Days_Fatalities_Change_of_Total'] = (tt['Past_7Days_Fatalities_Max'] - tt['Past_7Days_Fatalities_Min']) \/ (tt['Past_7Days_Fatalities_Max'])","d1ec18b9":"tt['Past_21Days_ConfirmedCases_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['ConfirmedCases'].std().to_dict())\ntt['Past_21Days_Fatalities_Std'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['Fatalities'].std().to_dict())\n\ntt['Past_21Days_ConfirmedCases_Min'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['ConfirmedCases'].min().to_dict())\ntt['Past_21Days_Fatalities_Min'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200324').groupby('Place')['Fatalities'].min().to_dict())\n\ntt['Past_21Days_ConfirmedCases_Max'] = tt['Place'].map(tt.dropna(subset=['ConfirmedCases']).query('Date >= 20200310').groupby('Place')['ConfirmedCases'].max().to_dict())\ntt['Past_21Days_Fatalities_Max'] = tt['Place'].map(tt.dropna(subset=['Fatalities']).query('Date >= 20200310').groupby('Place')['Fatalities'].max().to_dict())\n\ntt['Past_21Days_Confirmed_Change_of_Total'] = (tt['Past_21Days_ConfirmedCases_Max'] - tt['Past_21Days_ConfirmedCases_Min']) \/ (tt['Past_21Days_ConfirmedCases_Max'])\ntt['Past_21Days_Fatalities_Change_of_Total'] = (tt['Past_21Days_Fatalities_Max'] - tt['Past_21Days_Fatalities_Min']) \/ (tt['Past_21Days_Fatalities_Max'])\n\ntt['Past_7Days_Fatalities_Change_of_Total'] = tt['Past_7Days_Fatalities_Change_of_Total'].fillna(0)\ntt['Past_21Days_Fatalities_Change_of_Total'] = tt['Past_21Days_Fatalities_Change_of_Total'].fillna(0)","f177ff50":"tt['Date_7Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 7] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_14Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 14] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_21Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 21] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_28Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 28] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_35Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 35] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_60Days_Since_First_Case'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Case'] == 60] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\n\ntt['Date_7Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 7] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_14Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 14] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_21Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 21] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_28Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 28] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_35Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 35] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_60Days_Since_Ten_Cases'] = tt['Place'].map(tt.loc[tt['Days_Since_Ten_Cases'] == 60] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\n\n\ntt['Date_7Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 7] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_14Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 14] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_21Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 21] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_28Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 28] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_35Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 35] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())\ntt['Date_60Days_Since_First_Fatal'] = tt['Place'].map(tt.loc[tt['Days_Since_First_Fatal'] == 60] \\\n    .set_index('Place')['Date'] \\\n    .to_dict())","5aea8ce2":"tt['CC_7D_1stCase'] = tt.loc[tt['Date_7Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_14D_1stCase'] = tt.loc[tt['Date_14Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_21D_1stCase'] = tt.loc[tt['Date_21Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_28D_1stCase'] = tt.loc[tt['Date_28Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_35D_1stCase'] = tt.loc[tt['Date_35Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\ntt['CC_60D_1stCase'] = tt.loc[tt['Date_60Days_Since_First_Case'] == tt['Date']]['ConfirmedCases']\n\ntt['F_7D_1stCase'] = tt.loc[tt['Date_7Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_14D_1stCase'] = tt.loc[tt['Date_14Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_21D_1stCase'] = tt.loc[tt['Date_21Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_28D_1stCase'] = tt.loc[tt['Date_28Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_35D_1stCase'] = tt.loc[tt['Date_35Days_Since_First_Case'] == tt['Date']]['Fatalities']\ntt['F_60D_1stCase'] = tt.loc[tt['Date_60Days_Since_First_Case'] == tt['Date']]['Fatalities']\n\ntt['CC_7D_10Case'] = tt.loc[tt['Date_7Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_14D_10Case'] = tt.loc[tt['Date_14Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_21D_10Case'] = tt.loc[tt['Date_21Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_28D_10Case'] = tt.loc[tt['Date_28Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_35D_10Case'] = tt.loc[tt['Date_35Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\ntt['CC_60D_10Case'] = tt.loc[tt['Date_60Days_Since_Ten_Cases'] == tt['Date']]['ConfirmedCases']\n\ntt['F_7D_10Case'] = tt.loc[tt['Date_7Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_14D_10Case'] = tt.loc[tt['Date_14Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_21D_10Case'] = tt.loc[tt['Date_21Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_28D_10Case'] = tt.loc[tt['Date_28Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_35D_10Case'] = tt.loc[tt['Date_35Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\ntt['F_60D_10Case'] = tt.loc[tt['Date_60Days_Since_Ten_Cases'] == tt['Date']]['Fatalities']\n\ntt['CC_7D_1Fatal'] = tt.loc[tt['Date_7Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_14D_1Fatal'] = tt.loc[tt['Date_14Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_21D_1Fatal'] = tt.loc[tt['Date_21Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_28D_1Fatal'] = tt.loc[tt['Date_28Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_35D_1Fatal'] = tt.loc[tt['Date_35Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\ntt['CC_60D_1Fatal'] = tt.loc[tt['Date_60Days_Since_First_Fatal'] == tt['Date']]['ConfirmedCases']\n\ntt['F_7D_1Fatal'] = tt.loc[tt['Date_7Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_14D_1Fatal'] = tt.loc[tt['Date_14Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_21D_1Fatal'] = tt.loc[tt['Date_21Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_28D_1Fatal'] = tt.loc[tt['Date_28Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_35D_1Fatal'] = tt.loc[tt['Date_35Days_Since_First_Fatal'] == tt['Date']]['Fatalities']\ntt['F_60D_1Fatal'] = tt.loc[tt['Date_60Days_Since_First_Fatal'] == tt['Date']]['Fatalities']","f8746ea8":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\ntt[['Place','Past_7Days_Confirmed_Change_of_Total','Past_7Days_Fatalities_Change_of_Total',\n    'Past_7Days_ConfirmedCases_Max','Past_7Days_ConfirmedCases_Min',\n   'Past_7Days_Fatalities_Max','Past_7Days_Fatalities_Min']] \\\n    .drop_duplicates() \\\n    .sort_values('Past_7Days_Confirmed_Change_of_Total')['Past_7Days_Confirmed_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 7 days', ax=axs[0])\ntt[['Place','Past_21Days_Confirmed_Change_of_Total','Past_21Days_Fatalities_Change_of_Total',\n    'Past_21Days_ConfirmedCases_Max','Past_21Days_ConfirmedCases_Min',\n   'Past_21Days_Fatalities_Max','Past_21Days_Fatalities_Min']] \\\n    .drop_duplicates() \\\n    .sort_values('Past_21Days_Confirmed_Change_of_Total')['Past_21Days_Confirmed_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 21 days', ax=axs[1])\nplt.show()\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\ntt[['Place','Past_7Days_Fatalities_Change_of_Total']] \\\n    .drop_duplicates()['Past_7Days_Fatalities_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 7 days', ax=axs[0])\ntt[['Place', 'Past_21Days_Fatalities_Change_of_Total']] \\\n    .drop_duplicates()['Past_21Days_Fatalities_Change_of_Total'] \\\n    .plot(kind='hist', bins=50, title='Distribution of Pct change confirmed past 21 days', ax=axs[1])\nplt.show()","fa367a97":"# Example of flat prop\ntt.query(\"Place == 'China_Chongqing'\").set_index('Date')['ConfirmedCases'].dropna().plot(figsize=(15, 5))\nplt.show()","436d599d":"# Assume the places with small rate of change will continue slow down of virus spread\nconstant_case_places = tt.loc[(tt['Past_21Days_Confirmed_Change_of_Total'] < 0.01) & (tt['ConfirmedCases'] > 10)]['Place'].unique()\nconstant_case_places","46ab3ddd":"# Assume the places with small rate of change will continue slow down of virus spread\nconstant_fatal_places = tt.loc[(tt['Past_21Days_Fatalities_Change_of_Total'] < 0.01) & (tt['Fatalities'] > 1)]['Place'].unique()\nconstant_fatal_places","eb6063fc":"# Example of flat prop\ntt.query(\"Place == 'Italy'\").set_index('Date')[['ConfirmedCases']].dropna().plot(figsize=(15, 5))\nplt.show()\ntt.query(\"Place == 'Italy'\").set_index('Date')[['ConfirmedCases_Log']].dropna().plot(figsize=(15, 5))\nplt.show()","2abf8ff9":"latest_summary_stats = tt.query('Date == @max_date') \\\n    [['Country_Region',\n      'Place',\n      'Max_Cases_Per_100kPop',\n      'Max_Fatalities_Per_100kPop',\n      'Max_Confirmed_Cases',\n      'Population_final',\n      'Days_Since_First_Case',\n      'Days_Since_Ten_Cases']] \\\n    .drop_duplicates()","1014df33":"latest_summary_stats.query('Place != \"Diamond Princess\"') \\\n    .query('Country_Region != \"China\"') \\\n    .plot(y='Max_Cases_Per_100kPop',\n          x='Days_Since_Ten_Cases',\n          style='.',\n          figsize=(15, 5))","1fca11bc":"tt.query('Province_State == \"Maryland\"')[['ConfirmedCases','Confirmed_Cases_Diff']]","2c8214e4":"from sklearn.linear_model import LinearRegression, ElasticNet","d5ba0097":"us_states = tt.query('Country_Region == \"US\"')['Place'].unique()\nus_states","d5742dd2":"for myplace in us_states:\n    try:\n        # Confirmed Cases\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']].dropna()\n        X = dat['Days_Since_Ten_Cases']\n        y = dat['ConfirmedCases_Log']\n        y = y.cummax()\n        dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']]\n        X_pred = dat_all['Days_Since_Ten_Cases']\n        en = ElasticNet()\n        en.fit(X.values.reshape(-1, 1), y.values)\n        preds = en.predict(X_pred.values.reshape(-1, 1))\n        tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'ConfirmedCases_Log_Pred1'] = preds\n        tt.loc[(tt['Place'] == myplace), 'ConfirmedCases_Pred1'] = tt['ConfirmedCases_Log_Pred1'].apply(np.expm1)\n        # Cap at 10 % Population\n        pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n        tt.loc[(tt['Place'] == myplace) & (tt['ConfirmedCases_Pred1'] > (0.05 * pop_myplace)), 'ConfirmedCases_Pred1'] = (0.05 * pop_myplace)\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n        # Fatalities\n        # If low count then do percent of confirmed:\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']].dropna()\n        if len(dat) < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.0001\n        elif tt.query('Place == @myplace')['Fatalities'].max() < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.0001\n        else:\n            X = dat['Days_Since_Ten_Cases']\n            y = dat['Fatalities_Log']\n            y = y.cummax()\n            dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']]\n            X_pred = dat_all['Days_Since_Ten_Cases']\n            en = ElasticNet()\n            en.fit(X.values.reshape(-1, 1), y.values)\n            preds = en.predict(X_pred.values.reshape(-1, 1))\n            tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'Fatalities_Log_Pred1'] = preds\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt['Fatalities_Log_Pred1'].apply(np.expm1)\n\n            # Cap at 0.0001 Population\n            pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n            tt.loc[(tt['Place'] == myplace) & (tt['Fatalities_Pred1'] > (0.0001 * pop_myplace)), 'Fatalities_Pred1'] = (0.0001 * pop_myplace)\n\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n        plt.show()\n    except:\n        print(f'============= FAILED FOR {myplace} =============')\n","73d549be":"myplace = 'US_Virgin Islands'\ndat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Place','Days_Since_Ten_Cases','ConfirmedCases']].dropna()","dc65a020":"tt.loc[tt['Place'].isin(us_states)].groupby('Place')['Fatalities_Pred1'].max().sum()","67418faa":"constant_fatal_places","366ef18c":"tt.loc[tt['Place'].isin(constant_fatal_places), 'ConfirmedCases_Pred1'] = tt.loc[tt['Place'].isin(constant_fatal_places)]['Place'].map(tt.loc[tt['Place'].isin(constant_fatal_places)].groupby('Place')['ConfirmedCases'].max())\ntt.loc[tt['Place'].isin(constant_fatal_places), 'Fatalities_Pred1'] = tt.loc[tt['Place'].isin(constant_fatal_places)]['Place'].map(tt.loc[tt['Place'].isin(constant_fatal_places)].groupby('Place')['Fatalities'].max())","418078d8":"for myplace in constant_fatal_places:\n    fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n    ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n    ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n    plt.show()","74541389":"remaining_places = pd.DataFrame(tt.groupby('Place')['ConfirmedCases_Pred1'].max().isna()).query('ConfirmedCases_Pred1').index.values\nprint(remaining_places)\nprint(len(remaining_places))","6c1a3921":"for myplace in remaining_places:\n    try:\n        # Confirmed Cases\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']].dropna()\n        X = dat['Days_Since_Ten_Cases']\n        y = dat['ConfirmedCases_Log']\n        y = y.cummax()\n        dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases_Log']]\n        X_pred = dat_all['Days_Since_Ten_Cases']\n        en = ElasticNet()\n        en.fit(X.values.reshape(-1, 1), y.values)\n        preds = en.predict(X_pred.values.reshape(-1, 1))\n        tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'ConfirmedCases_Log_Pred1'] = preds\n        tt.loc[(tt['Place'] == myplace), 'ConfirmedCases_Pred1'] = tt['ConfirmedCases_Log_Pred1'].apply(np.expm1)\n        # Cap at 10 % Population\n        pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n        tt.loc[(tt['Place'] == myplace) & (tt['ConfirmedCases_Pred1'] > (0.05 * pop_myplace)), 'ConfirmedCases_Pred1'] = (0.05 * pop_myplace)\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n        # Fatalities\n        # If low count then do percent of confirmed:\n        dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']].dropna()\n        if len(dat) < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.0001\n        elif tt.query('Place == @myplace')['Fatalities'].max() < 5:\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.0001\n        else:\n            X = dat['Days_Since_Ten_Cases']\n            y = dat['Fatalities_Log']\n            y = y.cummax()\n            dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities_Log']]\n            X_pred = dat_all['Days_Since_Ten_Cases']\n            en = ElasticNet()\n            en.fit(X.values.reshape(-1, 1), y.values)\n            preds = en.predict(X_pred.values.reshape(-1, 1))\n            tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'Fatalities_Log_Pred1'] = preds\n            tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt['Fatalities_Log_Pred1'].apply(np.expm1)\n\n            # Cap at 0.0001 Population\n            pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n            tt.loc[(tt['Place'] == myplace) & (tt['Fatalities_Pred1'] > (0.0001 * pop_myplace)), 'Fatalities_Pred1'] = (0.0001 * pop_myplace)\n\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n        plt.show()\n    except:\n        print(f'============= FAILED FOR {myplace} =============')\n","7e0f5485":"# Estimated total\ntt.groupby('Place')['Fatalities_Pred1'].max().sum()","89aca582":"# Clean Up any time the actual is less than the real\ntt['ConfirmedCases_Pred1'] = tt[['ConfirmedCases','ConfirmedCases_Pred1']].max(axis=1)\ntt['Fatalities_Pred1'] = tt[['Fatalities','Fatalities_Pred1']].max(axis=1)\n\ntt['ConfirmedCases_Pred1'] = tt['ConfirmedCases_Pred1'].fillna(0)\ntt['Fatalities_Pred1'] = tt['Fatalities_Pred1'].fillna(0)\n\n# Fill pred with\ntt.loc[~tt['ConfirmedCases'].isna(), 'ConfirmedCases_Pred1'] = tt.loc[~tt['ConfirmedCases'].isna()]['ConfirmedCases']\ntt.loc[~tt['Fatalities'].isna(), 'Fatalities_Pred1'] = tt.loc[~tt['Fatalities'].isna()]['Fatalities']\n\ntt['ConfirmedCases_Pred1'] = tt.groupby('Place')['ConfirmedCases_Pred1'].transform('cummax')\ntt['Fatalities_Pred1'] = tt.groupby('Place')['Fatalities_Pred1'].transform('cummax')","4a71a50f":"for myplace in tt['Place'].unique():\n    try:\n        # Confirmed Cases\n        fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n        ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(title=myplace, ax=axs[0])\n        ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(title=myplace, ax=axs[1])\n        plt.show()\n    except:\n        print(f'============= FAILED FOR {myplace} =============')","70a6fa19":"tt.groupby('Place')['Fatalities_Pred1'].max().sort_values()","011e6dbe":"# Questionable numbers\ntt.query('Place == \"Iran\"').set_index('Date')[['ConfirmedCases',\n                                               'ConfirmedCases_Pred1',]].plot(figsize=(15, 5))\n# Make Iran's Predictions Linear\n\ntt.query('Place == \"Iran\"').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5))","0b47befe":"dat.iloc[-10:]","b5d286e3":"for myplace in ['Iran']:\n\n    # Confirmed Cases\n    fig, axs = plt.subplots(1, 2, figsize=(15, 3))\n    dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases']].dropna()\n    dat = dat.iloc[-10:]\n    X = dat['Days_Since_Ten_Cases']\n    y = dat['ConfirmedCases']\n    y = y.cummax()\n    dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','ConfirmedCases']]\n    X_pred = dat_all['Days_Since_Ten_Cases']\n    en = ElasticNet()\n    en.fit(X.values.reshape(-1, 1), y.values)\n    preds = en.predict(X_pred.values.reshape(-1, 1))\n    tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'ConfirmedCases_Pred1'] = preds\n    # Cap at 10 % Population\n    pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n    tt.loc[(tt['Place'] == myplace) & (tt['ConfirmedCases_Pred1'] > (0.1 * pop_myplace)), 'ConfirmedCases_Pred1'] = (0.1 * pop_myplace)\n    ax = tt.query('Place == @myplace').set_index('Date')[['ConfirmedCases','ConfirmedCases_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[0])\n    # Fatalities\n    # If low count then do percent of confirmed:\n    dat = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities']].dropna()\n    dat = dat.iloc[-10:]\n    if len(dat) < 5:\n        tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n    elif tt.query('Place == @myplace')['Fatalities'].max() < 5:\n        tt.loc[(tt['Place'] == myplace), 'Fatalities_Pred1'] = tt.loc[(tt['Place'] == myplace)]['ConfirmedCases_Pred1'] * 0.001\n    else:\n        X = dat['Days_Since_Ten_Cases']\n        y = dat['Fatalities']\n        y = y.cummax()\n        dat_all = tt.query('Place == @myplace and Days_Since_Ten_Cases >= 0')[['Days_Since_Ten_Cases','Fatalities']]\n        X_pred = dat_all['Days_Since_Ten_Cases']\n        en = ElasticNet()\n        en.fit(X.values.reshape(-1, 1), y.values)\n        preds = en.predict(X_pred.values.reshape(-1, 1))\n        tt.loc[(tt['Place'] == myplace) & (tt['Days_Since_Ten_Cases'] >= 0), 'Fatalities_Pred1'] = preds\n\n        # Cap at 0.0001 Population\n        pop_myplace = tt.query('Place == @myplace')['Population_final'].values[0]\n        tt.loc[(tt['Place'] == myplace) & (tt['Fatalities_Pred1'] > (0.0005 * pop_myplace)), 'Fatalities_Pred1'] = (0.0005 * pop_myplace)\n\n    ax = tt.query('Place == @myplace').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5), title=myplace, ax=axs[1])\n    plt.show()","077f388d":"# Clean Up any time the actual is less than the real\ntt['ConfirmedCases_Pred1'] = tt[['ConfirmedCases','ConfirmedCases_Pred1']].max(axis=1)\ntt['Fatalities_Pred1'] = tt[['Fatalities','Fatalities_Pred1']].max(axis=1)\n\ntt['ConfirmedCases_Pred1'] = tt['ConfirmedCases_Pred1'].fillna(0)\ntt['Fatalities_Pred1'] = tt['Fatalities_Pred1'].fillna(0)\n\n# Fill pred with\ntt.loc[~tt['ConfirmedCases'].isna(), 'ConfirmedCases_Pred1'] = tt.loc[~tt['ConfirmedCases'].isna()]['ConfirmedCases']\ntt.loc[~tt['Fatalities'].isna(), 'Fatalities_Pred1'] = tt.loc[~tt['Fatalities'].isna()]['Fatalities']\n\ntt['ConfirmedCases_Pred1'] = tt.groupby('Place')['ConfirmedCases_Pred1'].transform('cummax')\ntt['Fatalities_Pred1'] = tt.groupby('Place')['Fatalities_Pred1'].transform('cummax')","9dd284a8":"# Questionable numbers\ntt.query('Place == \"Iran\"').set_index('Date')[['ConfirmedCases',\n                                               'ConfirmedCases_Pred1',]].plot(figsize=(15, 5))\n# Make Iran's Predictions Linear\n\ntt.query('Place == \"Iran\"').set_index('Date')[['Fatalities','Fatalities_Pred1']].plot(figsize=(15, 5))","c74fcd98":"ss = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/submission.csv')","cb24f9a6":"print(ss.shape)\nss.head()","db79f877":"mysub = tt.dropna(subset=['ForecastId'])[['ForecastId','ConfirmedCases_Pred1','Fatalities_Pred1']]\nmysub['ForecastId'] = mysub['ForecastId'].astype('int')\nmysub = mysub.rename(columns={'ConfirmedCases_Pred1':'ConfirmedCases',\n                      'Fatalities_Pred1': 'Fatalities'})\nmysub.to_csv('submission.csv', index=False)","acedde33":"# Questionable numbers\ntt.groupby('Date').sum()[['ConfirmedCases',\n                          'ConfirmedCases_Pred1',]].plot(figsize=(15, 5))\n# Make Iran's Predictions Linear\n\ntt.groupby('Date').sum()[['Fatalities',\n                          'Fatalities_Pred1']].plot(figsize=(15, 5))","8b372dc9":"# Summary Stats","a70e0b32":"# Make Iran's Predictions Linear","d5aac84f":"# Plot them all!!","061387cb":"# Linear Regression","2b354f08":"# List of Places to keep cases constant","01846326":"# Other Data Prep","422d3eec":"# Deal with Flattened location","8794092f":"# Data Preprocessing\nhttps:\/\/www.kaggle.com\/osciiart\/covid19-lightgbm","5e6879f5":"# Rob's Baseline Model","c23ac7b7":"# Make Submission","63b310c0":"# US States","7a8fb6e4":"# Remaining Locations\n## 217 left","4ad0b1aa":"# List of Places to keep fatailities constant","89dd4217":"# Features about cases since first case\/ fatality"}}