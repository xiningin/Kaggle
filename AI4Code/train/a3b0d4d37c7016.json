{"cell_type":{"5477d05c":"code","c633d965":"code","90b5bebb":"code","61816261":"code","27c31824":"code","7896b78f":"code","46ee394a":"code","6468de84":"code","a350fd88":"code","7bb95f31":"code","a1d84b3a":"code","7a536a48":"code","f54b3085":"code","fb24b783":"code","55b366e2":"code","e0412bb1":"code","8cad3cb8":"code","0073a1d7":"code","649d324b":"markdown","8f17d002":"markdown","d194a990":"markdown","dcec17de":"markdown","d7497d35":"markdown","bcde7e57":"markdown","af3b2ec7":"markdown","426ffbf7":"markdown","4f2dfaa0":"markdown","16b4b371":"markdown","7f21bb8a":"markdown","14777930":"markdown","3c93d36a":"markdown","397fdcf4":"markdown","01e15f8a":"markdown","d96221dd":"markdown","410fe649":"markdown"},"source":{"5477d05c":"import torch\ncuda_version_major = int(torch.version.cuda.split('.')[0])\n\n!wget https:\/\/raw.githubusercontent.com\/airctic\/icevision\/master\/icevision_install.sh\n!bash icevision_install.sh cuda11\n!pip install torchtext==0.11.0 --upgrade\n\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)","c633d965":"import os\nimport shutil\n\nfrom kaggle_secrets import UserSecretsClient\nimport copy \nimport time\n\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n\nimport numpy as np\nimport ast\n\nimport cv2\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport torch\nfrom icevision.all import *\n\nimport wandb\n\nfrom colorama import Fore, Back, Style\n\nfrom IPython.display import IFrame\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","90b5bebb":"TRAIN_PATH = \"..\/input\/tensorflow-great-barrier-reef\/train_images\"\nHEIGHT, WIDTH = 720, 1280\nimage_size = 640\n\nvid0_path = \"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\"\nvid1_path = \"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_1\"\nvid2_path = \"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_2\"\nvid_paths = [vid0_path, vid1_path, vid2_path]\n\nvid0_ls = [os.path.join(vid0_path,f) for f in os.listdir(vid0_path)]\nvid0_ls = sorted(vid0_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n\nvid1_ls = [os.path.join(vid1_path,f) for f in os.listdir(vid1_path)]\nvid1_ls = sorted(vid1_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n\nvid2_ls = [os.path.join(vid2_path,f) for f in os.listdir(vid2_path)]\nvid2_ls = sorted(vid2_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\nfiles_ls = [vid0_ls, vid1_ls, vid2_ls]\n\ntrain_df = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/train.csv\")","61816261":"def get_oldpath(x):\n    if x.video_id == 0:\n        path = os.path.join(vid0_path,str(x.video_frame)+\".jpg\")\n    elif x.video_id == 1:\n        path = os.path.join(vid1_path,str(x.video_frame)+\".jpg\")\n    else:\n        path = os.path.join(vid2_path,str(x.video_frame)+\".jpg\")\n        \n    return path\n\ndef get_newpath(x):\n    filename = f\"{x.video_id}_{x.video_frame}.jpg\"\n    return os.path.join(\".\/dataset\", filename)\n\ndef get_filename(x):\n    return f\"{x.video_id}_{x.video_frame}.jpg\"","27c31824":"train_df = train_df[train_df.annotations != \"[]\"]\ntrain_df[\"annotations\"] = train_df[\"annotations\"].map(lambda x : ast.literal_eval(x))\n\ntrain_df[\"filepath\"] = train_df.apply(lambda x : get_oldpath(x), axis=1)\ntrain_df[\"newpath\"] = train_df.apply(lambda x : get_newpath(x), axis=1)\ntrain_df[\"filename\"] = train_df.apply(lambda x : get_filename(x), axis=1)\n\nos.makedirs(\".\/dataset\",exist_ok=True)\n\nfor i in tqdm(range(len(train_df))):\n    src = train_df.iloc[i][\"filepath\"]\n    dst = train_df.iloc[i][\"newpath\"]\n    shutil.copy(src,dst)\n    \ntrain_df.head(2)","7896b78f":"df = train_df\ndf = df.explode(\"annotations\")\n\ndf[\"width\"] = [WIDTH]*len(df)\ndf[\"height\"] = [HEIGHT]*len(df)\ndf[\"label\"] = [\"starfish\"]*len(df)\n\ndf[\"xmin\"] = df.apply(lambda x : x.annotations[\"x\"], axis=1)\ndf[\"ymin\"] = df.apply(lambda x : x.annotations[\"y\"], axis=1)\ndf[\"xmax\"] = df.apply(lambda x : x.annotations[\"x\"]+x.annotations[\"width\"], axis=1)\ndf[\"ymax\"] = df.apply(lambda x : x.annotations[\"y\"]+x.annotations[\"height\"], axis=1)\n\ndf.loc[df[\"xmax\"] > 1280, \"xmax\"] = 1280\ndf.loc[df[\"ymax\"] > 720, \"ymax\"] = 720\n\ndf = df.drop([\"video_id\",\"sequence\",\"video_frame\",\"sequence_frame\",\"image_id\",\"annotations\",\"filepath\",\"newpath\"], axis=1)\ndf = df.reset_index(drop=True)\ndf.head(3)","46ee394a":"# Check https:\/\/www.kaggle.com\/debarshichanda\/pytorch-w-b-pawpularity-training for more details\ntry:\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('''If you want to use your W&B account, Follow these steps :\n            -> go to Add-ons {Below name of notebook} -> Secrets -> Add a new Secret\n            -> Label = wandb_api\n            -> Value = W&B access token from https:\/\/wandb.ai\/authorize \n         ''')","6468de84":"WANDB_CONFIG = {\n   \"project_name\" : \"Protect Great Barrier Reef\",\n   \"group_name\" : \"IceVision Training\",\n   \"job_type_data\" : \"Data Visualization\",\n    \"job_type_train\" : \"Training\",\n   \"anonymity\" : \"must\",\n    \"artifact\" : \"training_data\"\n}\n\nrun = wandb.init(\n    project = WANDB_CONFIG[\"project_name\"],\n    group = WANDB_CONFIG[\"group_name\"],\n    job_type = WANDB_CONFIG[\"job_type_data\"],\n    anonymous= WANDB_CONFIG[\"anonymity\"]\n)","a350fd88":"wb_table = wandb.Table(columns = [\n    \"filename\", \"Image\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"\n])\n\nfor i in tqdm(range(len(df))[:100]):\n    row = df.loc[i]\n    impath = os.path.join(\".\/dataset\",row[\"filename\"])\n    im = PIL.Image.open(impath)\n    bbox = [{\n            \"position\": {\n                \"minX\": int(row['xmin']),\n                \"maxX\": int(row[\"xmax\"]),\n                \"minY\": int(row[\"ymin\"]),\n                \"maxY\": int(row[\"ymax\"])\n            },\n            \"class_id\": 1,\n            \"box_caption\": \"starfish\",\n            \"domain\": \"pixel\"\n        }]\n        \n    image = wandb.Image(im,\n                        boxes = {\n                            \"ground_truth\": {\n                                \"box_data\": bbox,\n                                \"class_labels\" : {1: 'starfish'}\n                            }\n                        },\n                        classes = [{\"id\": 0, \"name\": \"background\"}, {\"id\": 1, \"name\": \"starfish\"}]\n                    )\n    \n    wb_table.add_data(row['filename'],\n                      image,\n                      row[\"xmin\"],\n                      row[\"ymin\"],\n                      row[\"xmax\"],\n                      row[\"ymax\"]\n                     )\n    \nwandb.log({'Data Visualization': wb_table})\nrun.finish()","7bb95f31":"frame = IFrame(run.url, width=1280, height=720)\nframe","a1d84b3a":"train_report = ProfileReport(df,title=\"Metadata of Training images\")\ntrain_report.to_file(\".\/train_metadata.html\")\ntrain_report","7a536a48":"class PGBRParser(Parser):\n    def __init__(self, template_record, data_dir, df):\n        super().__init__(template_record=template_record)\n\n        self.data_dir = data_dir\n        self.df = df\n        self.class_map = ClassMap(list(self.df['label'].unique()))\n\n    def __iter__(self) -> Any:\n        for o in self.df.itertuples():\n            yield o\n\n    def __len__(self) -> int:\n        return len(self.df)\n\n    def record_id(self, o) -> Hashable:\n        return o.filename\n\n    def parse_fields(self, o, record, is_new):\n        if is_new:\n            record.set_filepath(os.path.join(self.data_dir,o.filename))\n            record.set_img_size(ImgSize(width=o.width, height=o.height))\n            record.detection.set_class_map(self.class_map)\n\n        record.detection.add_bboxes([BBox.from_xyxy(o.xmin, o.ymin, o.xmax, o.ymax)])\n        record.detection.add_labels([o.label])","f54b3085":"template_record = ObjectDetectionRecord()\nparser = PGBRParser(template_record, \".\/dataset\", df)\n\ntrain_records, valid_records = parser.parse()\nprint(parser.class_map)\n\ntrain_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\nvalid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])\n\ntrain_ds = Dataset(train_records, train_tfms)\nvalid_ds = Dataset(valid_records, valid_tfms)\n\nsamples = [train_ds[0] for _ in range(3)]\nshow_samples(samples, ncols=3)","fb24b783":"model_type = models.mmdet.vfnet\nbackbone = model_type.backbones.resnet50_fpn_mstrain_2x(pretrained=True)\nmodel = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map)) \n\ntrain_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=4, shuffle=True)\nvalid_dl = model_type.valid_dl(valid_ds, batch_size=16, num_workers=4, shuffle=False)","55b366e2":"metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]","e0412bb1":"learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)\nlearn.fine_tune(20, 0.005, freeze_epochs=1)","8cad3cb8":"infer_dl = model_type.infer_dl([valid_ds[0],valid_ds[4],valid_ds[7],valid_ds[9]], batch_size=4, shuffle=False)\npreds = model_type.predict_from_dl(model, infer_dl, keep_images=True)\nshow_preds(preds=preds)","0073a1d7":"shutil.make_archive('.\/checkpoints',\n                    'zip',\n                    '.\/',\n                    'checkpoints')\n\nshutil.rmtree(\".\/checkpoints\")\nshutil.rmtree(\".\/dataset\")\nshutil.rmtree(\".\/wandb\")","649d324b":"<div style = \"font-family : Lucida Sans Typewriter;background: rgb(224,224,224);border-radius: 25px;\">\n    <h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Weights and Biases<\/h2>\n    <center><img src = \"https:\/\/i.imgur.com\/KISYcqD.png\" width=200 height = 200><\/center>\n    <a href = \"https:\/\/wandb.ai\/shanmukh\/Protect%20Great%20Barrier%20Reef\/runs\/2eywhb67\"; style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; text-align:center; font-size:25px\">Checkout Dashboard created for this notebook<\/a>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    Weights and Biases is a set of Machine Learning tools used for experiment tracking, dataset versioning, and collaborating on ML projects. Weights and Biases is useful in many applications such as\n    <\/p>  \n    <ul>\n          <li>Experiment Tracking<\/li>\n          <li>Hyperparameter Tuning<\/li>\n          <li>Data Visualization<\/li>\n          <li>Data and model Versioning<\/li>\n          <li>Collaborative Reports<\/li>\n    <\/ul>\n    <a href = \"https:\/\/wandb.ai\/site\">Go to offocial website for more tutorials and Documentation<\/a>\n<\/div>","8f17d002":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Import Libraries \ud83d\udcda<\/h1>","d194a990":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Metrics<\/h2>","dcec17de":"<center style = \"font-family: 'Lucida Console', 'Courier New', monospace;\">\n    <img src = \"https:\/\/blogger.googleusercontent.com\/img\/a\/AVvXsEj6-rQw5r22Bt47BUTtW5bn_dcWT7zMeADwtvsAHS3kBt6w8eWTmCM649ZcJcvosIMup6flKFIaI8p4M9ZzH1yXpEaMRjvwwfVZ_hMqgXCxtwNzEK25vTa-J2ly20by3M1zx7rTymo-tBI6Fq-mj1SJfCOXsOz0Ou1Esi4h2omvQSW98AjsONsVS-EA\" width=400 height = 200>\n    <h1 style = \"background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%);border-radius: 20px; font-size:30px\">Tensorflow - Help Protect the Great Barrier Reef \ud83c\udf1f\ud83d\udc20<\/h1>\n<\/center>\n\n<div style = \"background: rgb(224,224,224);border-radius: 42px;\">\n    <h1 style = \"font-family: Consolas; text-align:center; color:#FF69B4\">Introduction<\/h1>\n    <h2 style = \"font-family: Consolas; text-align:center\">Why this Competition \u2753<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    Australia's stunningly beautiful Great Barrier Reef is the world\u2019s largest coral reef and home to 1,500 species of fish, 400 species of corals, 130 species of sharks, rays, and a massive variety of other sea life.Unfortunately, the reef is under threat, in part because of the overpopulation of one particular starfish \u2013 the coral-eating crown-of-thorns starfish (or COTS for short).\n    <\/p>\n    <h2 style = \"font-family: Consolas; text-align:center\">Goal of Competition \ud83e\udd45<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    The goal of this competition is to accurately identify starfish in real-time by building an object detection model trained on underwater videos of coral reefs.\n    <\/p>\n<\/div>\n\n<div style = \"background: rgb(224,224,224);border-radius: 42px;\">\n    <h1 style = \"font-family: Consolas; text-align:center; color:#FF69B4\">Sponsors \ud83d\udcb0<\/h1>\n    <h2 style = \"font-family: Consolas; text-align:center\">TensorFlow<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks.\n    <\/p>\n    <h2 style = \"font-family: Consolas; text-align:center\">CSIRO<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    The Commonwealth Scientific and Industrial Research Organisation is an Australian Government agency responsible for scientific research. CSIRO works with leading organisations around the world.\n    <\/p>\n    <h2 style = \"font-family: Consolas; text-align:center\">GBRF<\/h2>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    The Great Barrier Reef Foundation is an Australian non-profit organisation established in 1999 to help protect and preserve the Great Barrier Reef. \n    <\/p>\n<\/div>\n\n<h2 style = \"font-family: Consolas\">More Details<\/h2>\n<p style = \"font-family : Lucida Sans Typewriter\">Check <a href = \"https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/data\">competition page<\/a> for details<\/p>\n<h2 style = \"font-family : Comic Sans MS\">Let's dive in \u2b07\ufe0f<\/h2>\n\n<center><img src = \"https:\/\/img.shields.io\/badge\/Upvote-If%20you%20found%20this%20notebook%20useful-blue\" width=400 height = 400><\/center>","d7497d35":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Initialize Constants \ud83d\udd30<\/h1>","bcde7e57":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Inference \ud83d\udd2e<\/h1>","af3b2ec7":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Data Parser<\/h2>","426ffbf7":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Modelling \ud83c\udfeb<\/h1>","4f2dfaa0":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Data Loader<\/h2>","16b4b371":"<div style = \"font-family : Lucida Sans Typewriter;background: rgb(224,224,224);border-radius: 25px;\">\n    <h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">IceVision<\/h2>\n    <center><img src = \"https:\/\/airctic.com\/0.11.0\/images\/icevision-logo-slogan.png\" width=200 height = 200><\/center>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    IceVision is the first agnostic computer vision framework to offer a curated collection with hundreds of high-quality pre-trained models from torchvision, MMLabs, and soon Pytorch Image Models. It orchestrates the end-to-end deep learning workflow allowing to train networks with easy-to-use robust high-performance libraries such as Pytorch-Lightning and Fastai<\/p> \n    IceVision Unique Features:\n    <ul>\n        <li>Data curation\/cleaning with auto-fix<\/li>\n        <li>Access to an exploratory data analysis dashboard<\/li>\n        <li>Pluggable transforms for better model generalization<\/li>\n        <li>Access to hundreds of neural net models<\/li>\n        <li>Acccss to multiple training loop libraries<\/li>\n        <li>Multi-task training to efficiently combine object detection, segmentation, and classification models<\/li>\n    <\/ul>\n    <a href = \"https:\/\/airctic.com\/0.11.0\/\">Go to offocial website for documentation<\/a>\n<\/div>","7f21bb8a":"<a href=\".\/checkpoints.zip\"> Download File <\/a>","14777930":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Install Libraries \u23ec<\/h1>","3c93d36a":"<h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Training<\/h2>","397fdcf4":"<div style = \"font-family : Lucida Sans Typewriter;background: rgb(224,224,224);border-radius: 25px;\">\n    <h2 style = \"font-family: 'Lucida Console', 'Courier New', monospace; border-radius: 20px; font-size:30px; text-align:center; ; color:#FF69B4\">Pandas Profiling<\/h2>\n    <center><img src = \"https:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/assets\/logo_header.png\" width=200 height = 200><\/center>\n    <p style = \"font-family : Lucida Sans Typewriter\">\n    Pandas profiling is an open source Python module with which we can quickly do an exploratory data analysis with just a few lines of code. Besides, if this is not enough to convince us to use this tool, it also generates interactive reports in web format that can be presented to any person, even if they don\u2019t know programming.\n    <\/p>  \n    <a href = \"https:\/\/pandas-profiling.github.io\/pandas-profiling\/\">Go to offocial website for documentation<\/a>\n<\/div>","01e15f8a":"<br>\n<h3 style = \"font-family: Consolas; text-align:center; color:#FF0000\">If you come this far, you could've got some insights from this notebook. An upvote would be very helpful :). Kindly comment if there are any doubts or mistakes<\/h3>\n\n<center><img src = \"https:\/\/img.shields.io\/badge\/Completed-The%20End-brightgreen\" width=300 height = 300><\/center>","d96221dd":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \"> Data Preprocessing \u2692\ufe0f\ud83d\udd2c<\/h1>","410fe649":"<h1 style = \"font-family: 'Lucida Console', 'Courier New', monospace; background: rgb(44,169,201);\nbackground: linear-gradient(180deg, rgba(44,169,201,1) 0%, rgba(1,94,125,1) 100%); border-radius: 20px; font-size:30px; text-align:center; \">Data Visualization \ud83d\udcca\ud83d\udcb9<\/h1>"}}