{"cell_type":{"d3795158":"code","ed150ff9":"code","87daa348":"code","90ea0eac":"code","7625b65b":"code","f0dc8e4b":"code","3a4881a9":"code","6e7a59fb":"code","5ed77acc":"code","4e3f4722":"code","560255db":"code","5633afd5":"code","48016fea":"code","d91be64e":"code","b3b05967":"code","ee789b42":"code","93da0127":"code","b7a8b2fe":"code","11691b11":"code","90078d67":"code","89687796":"code","41bda6ca":"code","9aedfea0":"code","e061f54a":"code","36e1adbb":"code","80f56700":"code","262fe24e":"code","cfe8eecb":"code","c73eaa9f":"code","0c1281b2":"code","e44f327b":"code","6193177d":"markdown","bcf4d67b":"markdown","988855d0":"markdown","4e3b7e05":"markdown","e70303cb":"markdown","08fc091f":"markdown","f741bd22":"markdown","464317f8":"markdown","7a2de6fa":"markdown","18c8a7f1":"markdown","c370b92c":"markdown","b6875fa7":"markdown","3d650581":"markdown","63bfffd8":"markdown"},"source":{"d3795158":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# data analysis and wrangling\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ed150ff9":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ncombine = [train,test]","87daa348":"train.head()","90ea0eac":"train.describe().drop(['count'],axis = 0).drop(['PassengerId'],axis = 1)","7625b65b":"train.describe(include = ['O'])","f0dc8e4b":"train[['Pclass','Survived']].groupby(['Pclass'],as_index = False).mean().sort_values(by='Survived',ascending = False)","3a4881a9":"train[['Sex','Survived']].groupby(['Sex'],as_index = False).mean().sort_values(by='Survived',ascending = False)","6e7a59fb":"train[['SibSp','Survived']].groupby(['SibSp'],as_index = False).mean().sort_values(by='Survived',ascending = False)","5ed77acc":"train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4e3f4722":"train = train.drop(['Cabin','Ticket'],axis = 1)\ntest = test.drop(['Cabin','Ticket'],axis = 1)","560255db":"combine = [train,test]\nfor data in combine:\n    data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False) #\u4f7f\u7528\u6b63\u5219\u63d0\u53d6\u79f0\u8c13,\u5373\\(Mr).\\\u683c\u5f0f","5633afd5":"pd.crosstab(train['Title'],train['Sex']) #\u4ea4\u53c9\u8868\u67e5\u770b\u79f0\u8c13\u4e0e\u6027\u522b","48016fea":"for data in combine:\n    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n                                           'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","d91be64e":"title_map = {'Master':0,'Miss':1,'Mr':2,'Mrs':3,'Rare':4}\nfor data in combine:\n    data['Title'] = data['Title'].map(title_map)\n    data['Title'] = data['Title'].fillna(5) #\u7f3a\u5931\u503c\u6807\u8bb0\u4e3a5","b3b05967":"train['Title'].value_counts()","ee789b42":"train = train.drop(['Name', 'PassengerId'], axis=1)\ntest = test.drop(['Name'], axis=1)","93da0127":"sex_map = {'male':1,'female':2}\ncombine = [train,test]\nfor data in combine:\n    data['Sex'] = data['Sex'].map(sex_map).astype(int)","b7a8b2fe":" data['Sex'] = data['Sex'].astype(int)","11691b11":"train.isnull().sum()","90078d67":"test.isnull().sum()","89687796":"combine = [train,test]\nfor data in combine:\n    data['Fare'] = data['Fare'].fillna(32.20)\n    data['Embarked'] = data['Embarked'].fillna('S')","41bda6ca":"guess_ages = np.zeros((2,3))\nfor dataset in combine:\n    for i in range(2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i+1) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i+1) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)","9aedfea0":"train['AgeBand'] = pd.cut(train['Age'],5)\ntrain[['AgeBand','Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","e061f54a":"def age_band(x):\n    if x<=16:\n        return 0\n    elif x>16 and x<= 32:\n        return 1\n    elif x>32 and x<=48:\n        return 2\n    elif x>48 and x<= 64:\n        return 3\n    else:return 4\n    \nfor data in combine:\n    data['Age'] = data['Age'].map(age_band)","36e1adbb":"train['FareBand'] = pd.qcut(train['Fare'],4)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","80f56700":"for dataset in combine:\n    #Fare\u5206\u7ea7\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    #Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n\n    \n","262fe24e":"train = train.drop(['AgeBand','FareBand'],axis = 1)","cfe8eecb":"X_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","c73eaa9f":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 3)\nacc_log","0c1281b2":"random_forest = RandomForestClassifier(n_estimators=90)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","e44f327b":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","6193177d":"**Clear the dataset**\n---","bcf4d67b":"\u5220\u9664\u65e0\u7528\u6570\u636e\n---","988855d0":"\u6027\u522b\n---\n\u7537\u60271, \u5973\u60272","4e3b7e05":"* \u5206\u7c7b","e70303cb":"\u5c06Age\\Fare\u5206\u7c7b\n---\n* \u5904\u7406\u7a7a\u503c","08fc091f":"\nparch\n---\nparch = 3(\u5f88\u53ef\u80fd\u662f\u56db\u53e3\u4e4b\u5bb6)\u7684\u751f\u8fd8\u7387\u6700\u9ad8","f741bd22":"* \u6839\u636e\u6027\u522b,pclass\u731c\u6d4b\u5e74\u9f84","464317f8":"sibsp\n---\n\u90a3\u4e9b\u53ea\u6709\u4e00\u4e2a\u5144\u5f1f\/\u59d0\u59b9\/\u914d\u5076\u7684\u751f\u8fd8\u7387\u6700\u9ad8,\u53ef\u80fd\u4e24\u4eba\u80fd\u5f7c\u6b64\u9f13\u52b1\u6d3b\u4e0b\u53bb,\u4eba\u6570\u8fc7\u591a\u5219\u7275\u6302\u8fc7\u591a,\u803d\u8bef\u7684\u9003\u751f","7a2de6fa":"\u521b\u5efa\u65b0\u7684\u7279\u5f81\n---\n* \u6839\u636e\u4e58\u5ba2\u7684**\u79f0\u8c13**\u5212\u5206\u7c7b\u522b(Mrs,Miss,Mr,Dr,etc)","18c8a7f1":"pclass(1 = Upper, 2 = Middle, 3 = Lower)\n---\n\n\u4f4d\u4e8e\u9876\u5c42\u7684\u4e58\u5ba2\u751f\u8fd8\u7387\u6700\u9ad8,\u663e\u7136\u6700\u9ad8\u5c42\u6700\u5229\u4e8e\u4ece\u7532\u677f\u4e0a\u9003\u751f","c370b92c":"sex\n---\n\n\u5973\u6027\u7684\u751f\u8fd8\u7387\u660e\u663e\u9ad8\u4e8e\u7537\u6027(\u8fd9\u5f88\u7ec5\u58eb)\n\n\u7537\u6027\u751f\u8fd8\u7387\u4ec5\u670918.89%","b6875fa7":"male:577\/891   about 64.76%","3d650581":"**Analyze by pivoting features : **\n---\n\n* pcalss:\u6240\u5728\u7684\u8239\u8231\u5c42\n* sex:\u6027\u522b\n* sibsp:\u540c\u8239\u5144\u5f1f\\\u59d0\u59b9\\\u914d\u5076\n* parch:\u540c\u8239\u7236\u6bcd\\\u5b50\u5973\n","63bfffd8":"Predict\n---"}}