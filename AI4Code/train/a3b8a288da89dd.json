{"cell_type":{"180f48c1":"code","b8504e50":"code","838dc698":"code","9394da2a":"code","378238ce":"code","af441527":"code","aba20101":"code","bfd7181c":"code","5b59a9a1":"code","68a65056":"code","34541e34":"code","5aac2629":"code","5e8503c0":"code","dd1313b8":"code","4490f421":"code","dac62930":"code","fa5fd272":"code","ae1e3034":"code","c42504b7":"code","d693f42a":"code","a8231c16":"code","e5a95c80":"code","4809e848":"code","de638c17":"code","6c69b2dc":"markdown","8471a224":"markdown","db0c9f23":"markdown","01656520":"markdown","299e65db":"markdown","ec9e0b3a":"markdown","f6734df4":"markdown"},"source":{"180f48c1":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport numpy as np","b8504e50":"# Request the webpage and get the text\nurlreq = requests.get('https:\/\/en.wikipedia.org\/wiki\/Comparison_of_North_American_ski_resorts')\n\n# Extract the text from the requested webpage\nurl = urlreq.text\n\n# Create a parse tree with BS using the html parser\nsoup = BeautifulSoup(url, 'html.parser')","838dc698":"# Transforming html table into a dataframe\ndfs = pd.read_html(url)\ndf = dfs[4] # 5th line\ndf","9394da2a":"df.head()","378238ce":"# Rename columns\ndf.rename(columns = {'Resort name and website':'Resort', 'Nearest city':'City', 'State\/province':'State', 'Adult weekend lift ticket window price (USD)':'Lift ticket (USD)'}, inplace=True)\n# Drop columns that are not necessary \ndf = df.drop(['Date statistics updated'], axis=1)","af441527":"# Check for duplicates\ndf.duplicated().sum()","aba20101":"# Check for missing values\n# df.isna().sum()\ndf.isna().sum().sort_values(ascending=False)","bfd7181c":"# Check datatypes of columns\ndf.dtypes","5b59a9a1":"# Exclude rows with missing values from 'City' column \ndf = df[df['City'].notna()] # only take values that are not missing","68a65056":"# Replace missing values in base elevation, total trails, total lifts, and vertical drop columns with mean of their respective column\ndf['Base elevation (ft)'].fillna(value=df['Base elevation (ft)'].mean(), inplace=True)\ndf['Vertical drop (ft)'].fillna(value=df['Vertical drop (ft)'].mean(), inplace=True)\ndf['Total trails'].fillna(value=df['Total trails'].mean(), inplace=True)\ndf['Total lifts'].fillna(value=df['Total lifts'].mean(), inplace=True)","34541e34":"# Change datatypes to 'int' to remove decimals\nconvert_dict = {'Base elevation (ft)': int, 'Total trails': int, 'Total lifts': int, 'Vertical drop (ft)': int}\n# Instead of individual coloumns we use a dictionary to convert and reduce work\ndf = df.astype(convert_dict)","5aac2629":"df","5e8503c0":"# Removing special characters from 'Lift ticket' column and replacing missing values with mean\ndf['Lift ticket (USD)'] = df['Lift ticket (USD)'].replace('$', '', regex=True)\ndf['Lift ticket (USD)'] = df['Lift ticket (USD)'].fillna(-1)\ndf['Lift ticket (USD)'] = df['Lift ticket (USD)'].astype(str)\nreplacers = {'-1':float('nan'), 'Private Club':float('nan'), 'Free':float('nan'), 'Temporarily Closed':float('nan'), '25\/season':float('nan'), '84.95[70]':float('84.95'), 'Closed Temporarily':float('nan')}\ndf['Lift ticket (USD)'] = df['Lift ticket (USD)'].replace(replacers)\ndf['Lift ticket (USD)'] = df['Lift ticket (USD)'].astype(float)\ndf['Lift ticket (USD)'].fillna(value=df['Lift ticket (USD)'].mean(), inplace=True)\n","dd1313b8":"# Change datatype to 'int' to remove decimals\ndf['Lift ticket (USD)'] = df['Lift ticket (USD)'].astype(int)","4490f421":"df","dac62930":"# Removing special characters from 'Avg annual snowfall' column and replacing missing values with mean\nreplacers1 = {'220[21]':float('220'), '80[58]':float('80'), '132[63]':float('132'), '180[69]':float('180'), '100[87]':float('100'), '120[89]':float('120'), '168[100]':float('168'), '8,464[102]':float('8464'), '311`':float('311'), '9,422[102]':float('9422')}\ndf['Avg annual snowfall (in)'] = df['Avg annual snowfall (in)'].replace(replacers1)\ndf['Avg annual snowfall (in)'] = df['Avg annual snowfall (in)'].astype(float)\ndf['Avg annual snowfall (in)'].fillna(value=df['Avg annual snowfall (in)'].mean(), inplace=True)\n","fa5fd272":"# Change datatype to 'int' to remove decimals\ndf['Avg annual snowfall (in)'] = df['Avg annual snowfall (in)'].astype(int)","ae1e3034":"# Removing special characters from 'Skiable acreage' column and replacing missing values with mean\ndf['Skiable acreage'] = df['Skiable acreage'].replace(replacers1)\ndf['Skiable acreage'] = df['Skiable acreage'].astype(float)\ndf['Skiable acreage'].fillna(value=df['Skiable acreage'].mean(), inplace=True)\n","c42504b7":"df","d693f42a":"# Change datatype to 'int' to remove decimals\ndf['Skiable acreage'] = df['Skiable acreage'].astype(int)","a8231c16":"# Removing special characters from 'Peak elevation' column and replacing missing values with mean\ndf['Peak elevation (ft)'] = df['Peak elevation (ft)'].replace(replacers1)\ndf['Peak elevation (ft)'] = df['Peak elevation (ft)'].astype(float)\ndf['Peak elevation (ft)'].fillna(value=df['Peak elevation (ft)'].mean(), inplace=True)","e5a95c80":"# Change datatype to 'int' to remove decimals \ndf['Peak elevation (ft)'] = df['Peak elevation (ft)'].astype(int)                                         ","4809e848":"# Confirming that all missing values are replaced\ndf.isna().sum().sort_values(ascending=False)","de638c17":"# Exporting data to a CSV \ndf.to_csv('ski_resort_analysis.csv', index=False)","6c69b2dc":"# Creating the csv file","8471a224":"# Web Scraping using Python","db0c9f23":"Web scraping was used to collect information from Wikipedia which was then transformed into a dataframe. However, this dataset is not available in the most useful format as is and must be cleaned before any analysis can be performed.  \n","01656520":"## Import Libraries","299e65db":"### Missing Values","ec9e0b3a":"## Data Cleaning and Manipulation","f6734df4":"### Special Characters"}}