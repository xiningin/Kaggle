{"cell_type":{"f89e05dd":"code","98cdb7c2":"code","e5049eaf":"code","bd4ac9bb":"code","9f5d43b6":"markdown","b9662bd1":"markdown","e555d503":"markdown"},"source":{"f89e05dd":"#libraries\nlibrary(\"readxl\")\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"iml\")\nlibrary(\"randomForest\")\nlibrary(\"gbm\")\nlibrary(\"devtools\")\nlibrary(\"caret\")\nlibrary(\"ggridges\")\nlibrary(\"readr\")\nlibrary(\"breakDown\")\nlibrary(\"tree\")\nlibrary(\"glmnet\")","98cdb7c2":"#plotting and stuff","e5049eaf":"input <- read_excel(\"EDU408.xls\")\ninput = na.omit(input)\ninput=input[-1]\n\nset.seed(1)\ntrain = sample(1:nrow(input), nrow(input)\/2)\ntree=tree(GradePASS~.,input,subset=train)\nsummary(tree)\nplot(tree)\ntext(tree,pretty=0)\ncv.Input=cv.tree(tree)\ncv.Input\nplot(cv.Input$size,cv.Input$dev,type='b')\nprune=prune.tree(tree,best=3)\nplot(prune)\ntext(prune,pretty=0)\nyhat=predict(tree,newdata=input[-train,])\ntest=as.numeric(unlist(input[-train,\"GradePASS\"]))\nplot(yhat,test)\nabline(0,1)\nmean((yhat-test)^2)\n\n#bagging\nset.seed(1)\nbag=randomForest(GradePASS~.,data=input,subset=train,mtry=13,importance=TRUE)\nbag\nyhat.bag = predict(bag,newdata=input[-train,])\nplot(yhat.bag,test)\nabline(0,1)\nmean((yhat.bag-test)^2)\nbag=randomForest(GradePASS~.,data=input,subset=train,mtry=13,ntree=25)\nyhat.bag = predict(bag,newdata=input[-train,])\nmean((yhat.bag-test)^2)\nset.seed(1)\nrf=randomForest(GradePASS~.,data=input,subset=train,mtry=6,importance=TRUE)\nyhat.rf = predict(rf,newdata=input[-train,])\nmean((yhat.rf-test)^2)\nimportance(rf)\nvarImpPlot(rf)\n\n#boosting \nset.seed(1)\nboost=gbm(GradePASS~.,data=input[train,],distribution=\"gaussian\",n.trees=5000,interaction.depth=4)\nsummary(boost)\npar(mfrow=c(1,2))\nplot(boost,i=\"labs\")\nplot(boost,i=\"quizzes\")\nyhat.boost=predict(boost,newdata=input[-train,],n.trees=5000)\nmean((yhat.boost-test)^2)\nboost=gbm(GradePASS~.,data=input[train,],distribution=\"gaussian\",n.trees=5000,interaction.depth=4,shrinkage=0.2,verbose=F)\nyhat.boost=predict(boost,newdata=input[-train,],n.trees=5000)\nmean((yhat.boost-test)^2)","bd4ac9bb":"data <- read_excel(\"EDU408.xls\")\n\nView(data)\nattach(data)\n\nsmp_siz = floor(0.75*nrow(data))\nsmp_siz\nset.seed(1)\ntrain_ind = sample(seq_len(nrow(data)),size = smp_siz) \n\ntrain = data[train_ind,]\ntest = data[-train_ind,]\n\ninstall.packages(\"rpart\")\nlibrary(\"rpart\")\n\nDecisionTreeModel <- rpart(data = train, method = 'class', formula = train, control = rpart.control(minsplit = 1, minbucket = 1,  cp = 0))\nplot(DecisionTreeModel)\ntext(DecisionTreeModel, pretty = 0)\nsummary(DecisionTreeModel)","9f5d43b6":"# Surrogat tree","b9662bd1":"# Banjnanov dio","e555d503":"# Bagging, boosting decision tree"}}