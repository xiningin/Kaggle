{"cell_type":{"0d8cb93b":"code","1b883779":"code","fa27f7a1":"code","e2a67188":"code","b17e89d3":"code","6ab9f23e":"code","c9c712e4":"code","54873d27":"code","f8e9ff52":"code","06dfe248":"code","918c309c":"code","9745db6f":"code","a58a7456":"code","037dfc2b":"code","f20a5335":"code","3bbf10c9":"code","0435f58a":"code","c1af63fc":"code","d8b75904":"code","bf580e70":"code","79bc770e":"code","247fb266":"code","cc1c30b1":"code","e7c1c51c":"code","5427f6c5":"code","8641de34":"code","62bc6cb1":"code","3b67c236":"code","c01a2fdd":"code","efcc362d":"code","7e3a6969":"code","5deaff3f":"code","313bcf9c":"code","74e1024a":"code","41d3755a":"code","59230724":"markdown"},"source":{"0d8cb93b":"import pandas as pd\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\n\n\nimport xgboost as xgb\n\nfrom tqdm.notebook import tqdm\n\ndef exponential(x, a, k, b):\n    return a*np.exp(x*k) + b\n\ndef funclog(x, a, b,c):\n    return a*np.log(b+x)+c\n\ndef rmse( yt, yp ):\n    return np.sqrt( np.mean( (yt-yp)**2 ) )\n\ndef pinball(y_true, y_pred, tao=0.5 ):\n    return np.max( [(y_true - y_pred)*tao, (y_pred - y_true)*(1 - tao) ], axis=0 ) \n\ndef calc_metric( df ):\n    tmp = df.copy()\n    tmp['m0'] = pinball( tmp['TargetValue'].values, tmp['q05'].values , 0.05 )\n    tmp['m1'] = pinball( tmp['TargetValue'].values, tmp['q50'].values , 0.50 )\n    tmp['m2'] = pinball( tmp['TargetValue'].values, tmp['q95'].values , 0.95 )\n    tmp['q'] = tmp['Weight']*(tmp['m0']+tmp['m1']+tmp['m2']) \/ 3\n    return tmp['q'].mean()","1b883779":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/train.csv')\n\ntrain['Date'] = pd.to_datetime( train['Date'] )\nmindate  = str(train['Date'].min())[:10]\nmaxdate  = str(train['Date'].max())[:10]\ntestdate = str( train['Date'].max() + pd.Timedelta(days=1) )[:10]\nprint( mindate, maxdate, testdate )\n\ntrain['County'] = train['County'].fillna('N')\ntrain['Province_State'] = train['Province_State'].fillna('N')\ntrain['Country_Region'] = train['Country_Region'].fillna('N')\ntrain['geo'] = train['Country_Region'] + '-' + train['Province_State'] + '-' + train['County']\n\nprint(train.shape)\ntrain['dedup'] = pd.factorize( train['geo'] + '-' + train['Target'] + '-' + train['Date'].apply(str) + '-' + train['Population'].apply(str) )[0]\ntrain.drop_duplicates(subset =\"dedup\", keep = 'first', inplace = True)\ndel train['dedup']\nprint(train.shape)\n\ntrain.sort_values( ['geo','Date'], inplace=True )\n\ntrain.head(5)","fa27f7a1":"test = pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/test.csv')\n\ntest['Date'] = pd.to_datetime( test['Date'] )\n#testdate = str( test['Date'].max() + pd.Timedelta(days=1) )[:10]\n#print( maxdate, testdate )\n\ntest['County'] = test['County'].fillna('N')\ntest['Province_State'] = test['Province_State'].fillna('N')\ntest['Country_Region'] = test['Country_Region'].fillna('N')\ntest['geo'] = test['Country_Region'] + '-' + test['Province_State'] + '-' + test['County']\n\nprint(test.shape)\ntest.sort_values( ['geo','Date'], inplace=True )\n\nprint(test.head())","e2a67188":"train = pd.concat( (train, test.loc[test.Date>=testdate]) , sort=False )\ntrain.sort_values( ['geo','Date'], inplace=True )\n\ntrain.loc[ (train.Date=='2020-04-24')&(train.geo=='Spain-N-N')&(train.Target=='ConfirmedCases'), 'TargetValue' ] = 6000\ntrain.loc[ (train.Date=='2020-04-29')&(train.geo=='France-N-N')&(train.Target=='ConfirmedCases'), 'TargetValue' ] = 1843.5\ntrain.loc[ (train.Date=='2020-04-22')&(train.geo=='France-N-N')&(train.Target=='ConfirmedCases'), 'TargetValue' ] = 2522","b17e89d3":"train0 = train.loc[ train.Target == 'ConfirmedCases' ].copy()\ntrain1 = train.loc[ train.Target == 'Fatalities' ].copy()\nfor t in [train0,train1]:\n    t['q05'] = 0\n    t['q50'] = 0\n    t['q95'] = 0\n\ntrain0 = train0.loc[ (train0.Date  >='2020-03-01') ].copy()\ntrain1 = train1.loc[ (train1.Date  >='2020-03-01') ].copy()\n    \ntest0 = test.loc[ test.Target == 'ConfirmedCases' ].copy()\ntest1 = test.loc[ test.Target == 'Fatalities' ].copy()\ntrain0.shape, test0.shape","6ab9f23e":"!ls -l ..\/input\/covid-w5-worldometer-scraper\/train_oldformat.csv","c9c712e4":"DF = pd.read_csv('..\/input\/covid-w5-worldometer-scraper\/train_oldformat.csv')\nDF['Date'] = pd.to_datetime( DF['Date'] )\n#testdate = str( test['Date'].max() + pd.Timedelta(days=1) )[:10]\n#print( maxdate, testdate )\n\nDF['County'] = DF['County'].fillna('N')\nDF['Province_State'] = DF['Province_State'].fillna('N')\nDF['Country_Region'] = DF['Country_Region'].fillna('N')\nDF['geo'] = DF['Country_Region'] + '-' + DF['Province_State'] + '-' + DF['County']\nDF","54873d27":"DF0 = train0.loc[ train0.Date == '2020-05-11' ].copy()\nDF0['ypred'] = DF0[['geo','Date']].merge( DF.loc[DF.Target=='ConfirmedCases'], on=['geo','Date'] , how='left' )['TargetValue'].values\n\nDF1 = train1.loc[ train1.Date == '2020-05-11' ].copy()\nDF1['ypred'] = DF1[['geo','Date']].merge( DF.loc[DF.Target=='Fatalities'], on=['geo','Date'] , how='left' )['TargetValue'].values","f8e9ff52":"train0['ypred'] = train0['TargetValue'].values\ntrain0['mpred'] = train0.groupby('geo')['TargetValue'].rolling(7).mean().values\ntrain0['Hstd']  = np.clip(train0['ypred'] - train0['mpred'], 0, 9999999999)\ntrain0['Lstd']  = np.clip(train0['ypred'] - train0['mpred'], -9999999999, 0)\n\ntrain0.loc[ train0.Date>='2020-04-27' ,'ypred'] = np.nan\ntrain0.loc[ train0.Date>='2020-04-27' ,'mpred'] = np.nan\ntrain0.loc[ train0.Date>='2020-04-27' ,'Hstd']  = np.nan\ntrain0.loc[ train0.Date>='2020-04-27' ,'Lstd']  = np.nan\n\ntrain0['Hstd']  = train0.groupby('geo')['Hstd'].rolling(28).std().values\ntrain0['Lstd']  = train0.groupby('geo')['Lstd'].rolling(28).std().values\n\ntrain0['Lstd']  = train0.groupby('geo')['Lstd'].fillna( method='ffill' )\ntrain0['Hstd']  = train0.groupby('geo')['Hstd'].fillna( method='ffill' )\ntrain0['ypred'] = train0.groupby('geo')['ypred'].fillna( method='ffill' )\ntrain0['mpred'] = train0.groupby('geo')['mpred'].fillna( method='ffill' )\n\ntrain0['q50'] = train0['TargetValue'].values\ntrain0.loc[ train0.Date>='2020-04-27' ,'q50']  = np.nan\ntrain0['q05'] = train0['q50']\ntrain0['q95'] = train0['q50']","06dfe248":"import statsmodels.api as sm\n\ncount = 1\nfor valday in [\n    '2020-04-27',\n    '2020-04-28',\n    '2020-04-29',\n    '2020-04-30',\n    '2020-05-01',\n    '2020-05-02',\n    '2020-05-03',\n    '2020-05-04',\n    '2020-05-05',\n    '2020-05-06',\n    '2020-05-07',\n    '2020-05-08',\n    '2020-05-09',\n    '2020-05-10',\n    ]:\n    \n    for i in np.arange(1,13,1):\n        train0['lag1'+str(i)] = train0.groupby('geo')['q50'].shift(i)\n    train0['std1']= train0.groupby('geo')['q50'].shift(1).rolling(7).std()\n    train0['std2']= train0.groupby('geo')['q50'].shift(1).rolling(14).std()\n    train0['std2']= train0.groupby('geo')['q50'].shift(1).rolling(21).std()\n    train0['std2']= train0.groupby('geo')['q50'].shift(1).rolling(28).std()\n    \n    \n    TRAIN = train0.loc[ (train0.Date  <'2020-04-27')&(train0.Date >='2020-04-01') ].copy()\n    VALID = train0.loc[ (train0.Date ==valday) ].copy()\n    \n    features = TRAIN.columns[9:]\n    features = [f for f in features if f not in ['geo','ForecastId','q05','q50','q95','ypred','qstd','Lstd','Hstd','mpred','flag']  ]\n\n    if valday == '2020-04-27':        \n        model05 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.05)\n        model50 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.50)\n        model95 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.95)\n        \n    #break\n    VALID['q05'] = model05.predict( VALID[features] ) - VALID['Lstd']*np.clip(0.25*count,0,3.5)\n    VALID['q50'] = model50.predict( VALID[features] )\n    VALID['q95'] = model95.predict( VALID[features] ) + VALID['Hstd']*np.clip(0.25*count,0,3.5)\n    \n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q50<VALID.q05 ,'q05'] = VALID.loc[ VALID.q50<VALID.q05 ,'q50']\n    VALID.loc[ VALID.q50>VALID.q95 ,'q95'] = VALID.loc[ VALID.q50>VALID.q95 ,'q50']\n\n    VALID['q05'] = VALID['q05']\/(1.02**count)\n    VALID['q50'] = VALID['q50']\n    VALID['q95'] = VALID['q95']*(1.02**count)\n    \n    VALID.loc[ VALID.q05<0  ,'q05'] = 0\n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q95<0  ,'q95'] = 0\n    \n    train0.loc[ (train0.Date ==valday),'q05'] = VALID['q05']\n    train0.loc[ (train0.Date ==valday),'q50'] = VALID['q50']\n    train0.loc[ (train0.Date ==valday),'q95'] = VALID['q95']\n   \n    print( calc_metric( VALID ), valday )\n    count+=1\n\nTMP0 = train0.loc[ (train0.Date>='2020-04-27')&(train0.Date<='2020-05-10') ].copy()\nprint( calc_metric( TMP0 ) )  ","918c309c":"train0['ypred'] = train0['TargetValue'].values\ntrain0['mpred'] = train0.groupby('geo')['TargetValue'].rolling(7).mean().values\ntrain0['Hstd']  = np.clip(train0['ypred'] - train0['mpred'], 0, 9999999999)\ntrain0['Lstd']  = np.clip(train0['ypred'] - train0['mpred'], -9999999999, 0)\n\n# train0.loc[ train0.Date>='2020-04-27' ,'ypred'] = np.nan\n# train0.loc[ train0.Date>='2020-04-27' ,'mpred'] = np.nan\n# train0.loc[ train0.Date>='2020-04-27' ,'Hstd']  = np.nan\n# train0.loc[ train0.Date>='2020-04-27' ,'Lstd']  = np.nan\n\ntrain0['Hstd']  = train0.groupby('geo')['Hstd'].rolling(28).std().values\ntrain0['Lstd']  = train0.groupby('geo')['Lstd'].rolling(28).std().values\n\ntrain0['Lstd']  = train0.groupby('geo')['Lstd'].fillna( method='ffill' )\ntrain0['Hstd']  = train0.groupby('geo')['Hstd'].fillna( method='ffill' )\ntrain0['ypred'] = train0.groupby('geo')['ypred'].fillna( method='ffill' )\ntrain0['mpred'] = train0.groupby('geo')['mpred'].fillna( method='ffill' )\n\ntrain0['q50'] = train0['TargetValue'].values\n#train0.loc[ train0.Date>='2020-04-27' ,'q50']  = np.nan\ntrain0['q05'] = train0['q50']\ntrain0['q95'] = train0['q50']\n\n\ncount = 1\nfor valday in [\n    '2020-05-11',\n    '2020-05-12',\n    '2020-05-13',\n    '2020-05-14',\n    '2020-05-15',\n    '2020-05-16',\n    '2020-05-17',\n    '2020-05-18',\n    '2020-05-19',\n    '2020-05-20',\n    '2020-05-21',\n    '2020-05-22',\n    '2020-05-23',\n    '2020-05-24',\n    '2020-05-25',\n    '2020-05-26',\n    '2020-05-27',\n    '2020-05-28',\n    '2020-05-29',\n    '2020-05-30',\n    '2020-05-31',\n    '2020-06-01',\n    '2020-06-02',\n    '2020-06-03',\n    '2020-06-04',\n    '2020-06-05',\n    '2020-06-06',\n    '2020-06-07',\n    '2020-06-08',\n    '2020-06-09',\n    '2020-06-10',\n]:\n    for i in np.arange(1,13,1):\n        train0['lag1'+str(i)] = train0.groupby('geo')['q50'].shift(i)#.fillna(0)\n    train0['std1']= train0.groupby('geo')['q50'].shift(1).rolling(7).std()\n    train0['std2']= train0.groupby('geo')['q50'].shift(1).rolling(14).std()\n    train0['std2']= train0.groupby('geo')['q50'].shift(1).rolling(21).std()\n    train0['std2']= train0.groupby('geo')['q50'].shift(1).rolling(28).std()\n    TRAIN = train0.loc[ (train0.Date  <'2020-05-11')&(train0.Date >='2020-04-01') ].copy()\n    VALID = train0.loc[ (train0.Date ==valday) ].copy()\n    \n    features = TRAIN.columns[9:]\n    features = [f for f in features if f not in ['geo','ForecastId','q05','q50','q95','ypred','qstd','Lstd','Hstd','mpred','flag']  ]\n\n    if valday == '2020-05-11':        \n        model05 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.05)\n        model50 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.50)\n        model95 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.95)\n        \n    #break\n    VALID['q05'] = model05.predict( VALID[features] ) - VALID['Lstd']*np.clip(0.25*count,0,3.5)\n    VALID['q50'] = model50.predict( VALID[features] )\n    VALID['q95'] = model95.predict( VALID[features] ) + VALID['Hstd']*np.clip(0.25*count,0,3.5)\n    \n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q50<VALID.q05 ,'q05'] = VALID.loc[ VALID.q50<VALID.q05 ,'q50']\n    VALID.loc[ VALID.q50>VALID.q95 ,'q95'] = VALID.loc[ VALID.q50>VALID.q95 ,'q50']\n\n    VALID['q05'] = VALID['q05']\/(1.02**count)\n    VALID['q50'] = VALID['q50']\n    VALID['q95'] = VALID['q95']*(1.02**count)\n    \n    VALID.loc[ VALID.q05<0  ,'q05'] = 0\n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q95<0  ,'q95'] = 0\n    \n    train0.loc[ (train0.Date ==valday),'q05'] = VALID['q05']\n    train0.loc[ (train0.Date ==valday),'q50'] = VALID['q50']\n    train0.loc[ (train0.Date ==valday),'q95'] = VALID['q95']\n   \n    print( calc_metric( VALID ), valday )\n    count+=1","9745db6f":"TMP0B = train0.loc[ (train0.Date>='2020-05-11') ].copy()\nTMP0B.shape","a58a7456":"train1['ypred'] = train1['TargetValue'].values\ntrain1['mpred'] = train1.groupby('geo')['TargetValue'].rolling(7).mean().values\ntrain1['Hstd']  = np.clip(train1['ypred'] - train1['mpred'], 0, 9999999999)\ntrain1['Lstd']  = np.clip(train1['ypred'] - train1['mpred'], -9999999999, 0)\n\ntrain1.loc[ train1.Date>='2020-04-27' ,'ypred'] = np.nan\ntrain1.loc[ train1.Date>='2020-04-27' ,'mpred'] = np.nan\ntrain1.loc[ train1.Date>='2020-04-27' ,'Hstd']  = np.nan\ntrain1.loc[ train1.Date>='2020-04-27' ,'Lstd']  = np.nan\n\ntrain1['Hstd']  = train1.groupby('geo')['Hstd'].rolling(28).std().values\ntrain1['Lstd']  = train1.groupby('geo')['Lstd'].rolling(28).std().values\n\ntrain1['Lstd']  = train1.groupby('geo')['Lstd'].fillna( method='ffill' )\ntrain1['Hstd']  = train1.groupby('geo')['Hstd'].fillna( method='ffill' )\ntrain1['ypred'] = train1.groupby('geo')['ypred'].fillna( method='ffill' )\ntrain1['mpred'] = train1.groupby('geo')['mpred'].fillna( method='ffill' )\n\ntrain1['q50'] = train1['TargetValue'].values\ntrain1.loc[ train1.Date>='2020-04-27' ,'q50']  = np.nan\ntrain1['q05'] = train1['q50']\ntrain1['q95'] = train1['q50']","037dfc2b":"train1['q50_cases'] = train1[['geo','Date']].merge( train0[['geo','Date','q50']], on=['geo','Date'], how='left' )['q50'].values\ntrain1.iloc[-60:,5:25]","f20a5335":"count = 1\nfor valday in [\n    '2020-04-27',\n    '2020-04-28',\n    '2020-04-29',\n    '2020-04-30',\n    '2020-05-01',\n    '2020-05-02',\n    '2020-05-03',\n    '2020-05-04',\n    '2020-05-05',\n    '2020-05-06',\n    '2020-05-07',\n    '2020-05-08',\n    '2020-05-09',\n    '2020-05-10',\n    ]:\n    \n    for i in np.arange(1,13,1):\n        train1['lag1'+str(i)] = train1.groupby('geo')['q50'].shift(i)\n        train1['lagCases1'+str(i)] = train1.groupby('geo')['q50_cases'].shift(i)\n    train1['std1']= train1.groupby('geo')['q50'].shift(1).rolling(7).std()\n    train1['std2']= train1.groupby('geo')['q50'].shift(1).rolling(14).std()\n    train1['std2']= train1.groupby('geo')['q50'].shift(1).rolling(21).std()\n    train1['std2']= train1.groupby('geo')['q50'].shift(1).rolling(28).std()\n    \n    TRAIN = train1.loc[ (train1.Date  <'2020-04-27')&(train1.Date >='2020-04-01') ].copy()\n    VALID = train1.loc[ (train1.Date ==valday) ].copy()\n    \n    features = TRAIN.columns[9:]\n    features = [f for f in features if f not in ['geo','ForecastId','q05','q50','q95','ypred','qstd','Lstd','Hstd','mpred','flag']  ]\n\n    if valday == '2020-04-27':        \n        model05 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.05)\n        model50 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.50)\n        model95 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.95)\n        \n    #break\n    VALID['q05'] = model05.predict( VALID[features] ) - VALID['Lstd']*np.clip(0.01*count,0,3.5)\n    VALID['q50'] = model50.predict( VALID[features] )\n    VALID['q95'] = model95.predict( VALID[features] ) + VALID['Hstd']*np.clip(0.01*count,0,3.5)\n    \n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q50<VALID.q05 ,'q05'] = VALID.loc[ VALID.q50<VALID.q05 ,'q50']\n    VALID.loc[ VALID.q50>VALID.q95 ,'q95'] = VALID.loc[ VALID.q50>VALID.q95 ,'q50']\n\n    VALID['q05'] = VALID['q05']\/(1.001**count)\n    VALID['q50'] = VALID['q50']\n    VALID['q95'] = VALID['q95']*(1.001**count)\n    \n    VALID.loc[ VALID.q05<0  ,'q05'] = 0\n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q95<0  ,'q95'] = 0\n    \n    train1.loc[ (train1.Date ==valday),'q05'] = VALID['q05']\n    train1.loc[ (train1.Date ==valday),'q50'] = VALID['q50']\n    train1.loc[ (train1.Date ==valday),'q95'] = VALID['q95']\n   \n    print( calc_metric( VALID ), valday )\n    count+=1\n\nTMP1 = train1.loc[ (train1.Date>='2020-04-27')&(train1.Date<='2020-05-10') ].copy()\nprint( calc_metric( TMP1 ) )","3bbf10c9":"train1.iloc[-60:,5:25]","0435f58a":"train1['ypred'] = train1['TargetValue'].values\ntrain1['mpred'] = train1.groupby('geo')['TargetValue'].rolling(7).mean().values\ntrain1['Hstd']  = np.clip(train1['ypred'] - train1['mpred'], 0, 9999999999)\ntrain1['Lstd']  = np.clip(train1['ypred'] - train1['mpred'], -9999999999, 0)\n\n# train1.loc[ train1.Date>='2020-04-27' ,'ypred'] = np.nan\n# train1.loc[ train1.Date>='2020-04-27' ,'mpred'] = np.nan\n# train1.loc[ train1.Date>='2020-04-27' ,'Hstd']  = np.nan\n# train1.loc[ train1.Date>='2020-04-27' ,'Lstd']  = np.nan\n\ntrain1['Hstd']  = train1.groupby('geo')['Hstd'].rolling(28).std().values\ntrain1['Lstd']  = train1.groupby('geo')['Lstd'].rolling(28).std().values\n\ntrain1['Lstd']  = train1.groupby('geo')['Lstd'].fillna( method='ffill' )\ntrain1['Hstd']  = train1.groupby('geo')['Hstd'].fillna( method='ffill' )\ntrain1['ypred'] = train1.groupby('geo')['ypred'].fillna( method='ffill' )\ntrain1['mpred'] = train1.groupby('geo')['mpred'].fillna( method='ffill' )\n\ntrain1['q50'] = train1['TargetValue'].values\n#train1.loc[ train1.Date>='2020-04-27' ,'q50']  = np.nan\ntrain1['q05'] = train1['q50']\ntrain1['q95'] = train1['q50']\n\ncount = 1\nfor valday in [\n    '2020-05-11',\n    '2020-05-12',\n    '2020-05-13',\n    '2020-05-14',\n    '2020-05-15',\n    '2020-05-16',\n    '2020-05-17',\n    '2020-05-18',\n    '2020-05-19',\n    '2020-05-20',\n    '2020-05-21',\n    '2020-05-22',\n    '2020-05-23',\n    '2020-05-24',\n    '2020-05-25',\n    '2020-05-26',\n    '2020-05-27',\n    '2020-05-28',\n    '2020-05-29',\n    '2020-05-30',\n    '2020-05-31',\n    '2020-06-01',\n    '2020-06-02',\n    '2020-06-03',\n    '2020-06-04',\n    '2020-06-05',\n    '2020-06-06',\n    '2020-06-07',\n    '2020-06-08',\n    '2020-06-09',\n    '2020-06-10',\n    ]:\n    \n    for i in np.arange(1,13,1):\n        train1['lag1'+str(i)] = train1.groupby('geo')['q50'].shift(i)\n        train1['lagCases1'+str(i)] = train1.groupby('geo')['q50_cases'].shift(i)\n    train1['std1']= train1.groupby('geo')['q50'].shift(1).rolling(7).std()\n    train1['std2']= train1.groupby('geo')['q50'].shift(1).rolling(14).std()\n    train1['std2']= train1.groupby('geo')['q50'].shift(1).rolling(21).std()\n    train1['std2']= train1.groupby('geo')['q50'].shift(1).rolling(28).std()\n    \n    TRAIN = train1.loc[ (train1.Date  <'2020-05-11')&(train1.Date >='2020-04-01') ].copy()\n    VALID = train1.loc[ (train1.Date ==valday) ].copy()\n    \n    features = TRAIN.columns[9:]\n    features = [f for f in features if f not in ['geo','ForecastId','q05','q50','q95','ypred','qstd','Lstd','Hstd','mpred','flag']  ]\n\n    if valday == '2020-05-11':        \n        model05 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.05)\n        model50 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.50)\n        model95 = sm.QuantReg(TRAIN['q50'], TRAIN[features]).fit(q=0.95)\n        \n    #break\n    VALID['q05'] = model05.predict( VALID[features] ) - VALID['Lstd']*np.clip(0.01*count,0,3.5)\n    VALID['q50'] = model50.predict( VALID[features] )\n    VALID['q95'] = model95.predict( VALID[features] ) + VALID['Hstd']*np.clip(0.01*count,0,3.5)\n    \n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q50<VALID.q05 ,'q05'] = VALID.loc[ VALID.q50<VALID.q05 ,'q50']\n    VALID.loc[ VALID.q50>VALID.q95 ,'q95'] = VALID.loc[ VALID.q50>VALID.q95 ,'q50']\n\n    VALID['q05'] = VALID['q05']\/(1.001**count)\n    VALID['q50'] = VALID['q50']\n    VALID['q95'] = VALID['q95']*(1.001**count)\n    \n    VALID.loc[ VALID.q05<0  ,'q05'] = 0\n    VALID.loc[ VALID.q50<0  ,'q50'] = 0\n    VALID.loc[ VALID.q95<0  ,'q95'] = 0\n    \n    train1.loc[ (train1.Date ==valday),'q05'] = VALID['q05']\n    train1.loc[ (train1.Date ==valday),'q50'] = VALID['q50']\n    train1.loc[ (train1.Date ==valday),'q95'] = VALID['q95']\n   \n    print( calc_metric( VALID ), valday )\n    count+=1\n    \nTMP1B = train1.loc[ (train1.Date>='2020-05-11') ].copy()\nTMP1B.shape    ","c1af63fc":"tmp = pd.concat( (TMP0,TMP1) )\ncalc_metric( tmp )","d8b75904":"VALID0 = train0.loc[ (train0.Date>='2020-05-11') , ['geo','Date','q05','q50','q95','TargetValue','Weight'] ].copy()\nVALID1 = train1.loc[ (train1.Date>='2020-05-11') , ['geo','Date','q05','q50','q95','TargetValue','Weight'] ].copy()\nVALID0.shape, VALID1.shape","bf580e70":"VALID0 = pd.concat( (TMP0,TMP0B) )\nVALID1 = pd.concat( (TMP1,TMP1B) )\nVALID0 = VALID0.reset_index(drop=True)\nVALID1 = VALID1.reset_index(drop=True)\nVALID0.shape, VALID1.shape","79bc770e":"#Write Public LB ground Truth\n\nTMP0['q05'] = TMP0['TargetValue']\nTMP0['q50'] = TMP0['TargetValue']\nTMP0['q95'] = TMP0['TargetValue']\n\nTMP1['q05'] = TMP1['TargetValue']\nTMP1['q50'] = TMP1['TargetValue']\nTMP1['q95'] = TMP1['TargetValue']","247fb266":"#Write external data\n\nTMP0B['ypred'] = TMP0B[['geo','Date']].merge( DF0[['geo','Date','ypred']], on=['geo','Date'], how='left' )['ypred'].values\nTMP1B['ypred'] = TMP1B[['geo','Date']].merge( DF1[['geo','Date','ypred']], on=['geo','Date'], how='left' )['ypred'].values\n\nTMP0B.loc[TMP0B.ypred.notnull(),'q05'] = TMP0B.loc[TMP0B.ypred.notnull(),'ypred']\nTMP0B.loc[TMP0B.ypred.notnull(),'q50'] = TMP0B.loc[TMP0B.ypred.notnull(),'ypred']\nTMP0B.loc[TMP0B.ypred.notnull(),'q95'] = TMP0B.loc[TMP0B.ypred.notnull(),'ypred']\n\nTMP1B.loc[TMP1B.ypred.notnull(),'q05'] = TMP1B.loc[TMP1B.ypred.notnull(),'ypred']\nTMP1B.loc[TMP1B.ypred.notnull(),'q50'] = TMP1B.loc[TMP1B.ypred.notnull(),'ypred']\nTMP1B.loc[TMP1B.ypred.notnull(),'q95'] = TMP1B.loc[TMP1B.ypred.notnull(),'ypred']\n\ndel TMP0B['ypred'], TMP1B['ypred']","cc1c30b1":"VALID0 = pd.concat( (TMP0,TMP0B) )\nVALID1 = pd.concat( (TMP1,TMP1B) )\nVALID0 = VALID0.reset_index(drop=True)\nVALID1 = VALID1.reset_index(drop=True)\nVALID0.shape, VALID1.shape","e7c1c51c":"tmp = train0.loc[ train0.geo == 'US-N-N' ].copy()\ntmp[['Date','q05','q50','q95']].plot(x='Date')","5427f6c5":"tmp = train0.loc[ train0.geo == 'Brazil-N-N' ].copy()\ntmp[['Date','q05','q50','q95']].plot(x='Date')","8641de34":"tmp = train1.loc[ train1.geo == 'US-N-N' ].copy()\ntmp[['Date','q05','q50','q95']].plot(x='Date')","62bc6cb1":"tmp = train1.loc[ train1.geo == 'Brazil-N-N' ].copy()\ntmp[['Date','q05','q50','q95']].plot(x='Date')","3b67c236":"tmp.iloc[-60:,5:25]","c01a2fdd":"# del test0['q05'],test0['q50'],test0['q95']\n# del test1['q05'],test1['q50'], test1['q95']","efcc362d":"test0['q05'] = pd.merge( test0[['geo','Date']], VALID0, on=['geo','Date'], how='left'  )['q05'].values\ntest0['q50'] = pd.merge( test0[['geo','Date']], VALID0, on=['geo','Date'], how='left'  )['q50'].values\ntest0['q95'] = pd.merge( test0[['geo','Date']], VALID0, on=['geo','Date'], how='left'  )['q95'].values\ntest1['q05'] = pd.merge( test1[['geo','Date']], VALID1, on=['geo','Date'], how='left'  )['q05'].values\ntest1['q50'] = pd.merge( test1[['geo','Date']], VALID1, on=['geo','Date'], how='left'  )['q50'].values\ntest1['q95'] = pd.merge( test1[['geo','Date']], VALID1, on=['geo','Date'], how='left'  )['q95'].values","7e3a6969":"test0.isnull().sum()","5deaff3f":"test0.loc[ test0.geo =='Zimbabwe-N-N' ]","313bcf9c":"q05 = test0[['ForecastId','q05']].copy()\nq50 = test0[['ForecastId','q50']].copy()\nq95 = test0[['ForecastId','q95']].copy()\nq05.columns = ['ForecastId','TargetValue']\nq50.columns = ['ForecastId','TargetValue']\nq95.columns = ['ForecastId','TargetValue']\nq05['ForecastId_Quantile'] = q05['ForecastId'].apply(str) + '_0.05'\nq50['ForecastId_Quantile'] = q50['ForecastId'].apply(str) + '_0.5'\nq95['ForecastId_Quantile'] = q95['ForecastId'].apply(str) + '_0.95'\ntst0 = pd.concat( (q05, q50, q95) )\n\nq05 = test1[['ForecastId','q05']].copy()\nq50 = test1[['ForecastId','q50']].copy()\nq95 = test1[['ForecastId','q95']].copy()\nq05.columns = ['ForecastId','TargetValue']\nq50.columns = ['ForecastId','TargetValue']\nq95.columns = ['ForecastId','TargetValue']\nq05['ForecastId_Quantile'] = q05['ForecastId'].apply(str) + '_0.05'\nq50['ForecastId_Quantile'] = q50['ForecastId'].apply(str) + '_0.5'\nq95['ForecastId_Quantile'] = q95['ForecastId'].apply(str) + '_0.95'\ntst1 = pd.concat( (q05, q50, q95) )\n\ntst = pd.concat( (tst0,tst1), sort=False )\ntst.sort_values( 'ForecastId', inplace=True )\n\ntst['TargetValue'] = tst['TargetValue'].fillna(0)\n\ntst[['ForecastId_Quantile','TargetValue']].to_csv( 'submission.csv', index=False )\ntst.head(6)","74e1024a":"sub = pd.read_csv('submission.csv')\nprint( sub.shape )\nsub.describe()","41d3755a":"sub = pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/submission.csv')\nprint( sub.shape )\nsub.describe()","59230724":"# Pinball 27-04 to 10-05"}}