{"cell_type":{"0038992a":"code","55c2d7cd":"code","e04adfe5":"code","c05cc5f0":"code","2ff960b3":"code","dd27fb8e":"code","ffa05531":"code","e9989dbd":"code","da3cedd4":"code","b05c8174":"code","3e2a8b02":"code","44802e4c":"code","0fedd667":"code","5d3fdf29":"code","89988864":"code","d87dc250":"code","475da2e3":"code","cf91b739":"code","100d70c1":"code","67eda6ba":"code","c2009467":"code","aefaebff":"code","11b37142":"code","a3df45a1":"code","ebf90e6f":"code","247af989":"code","1f557ee2":"code","6c5495aa":"markdown","1e9b3f96":"markdown","5d001a57":"markdown","cbdbd932":"markdown","94d9a9b2":"markdown","ff9d761e":"markdown","a4b5515d":"markdown","facb581d":"markdown","034a004b":"markdown","88a2beae":"markdown","2d77141d":"markdown","ca153c9a":"markdown","f905e1a7":"markdown"},"source":{"0038992a":"# Import necessary everyday os libs\nimport gc\nimport sys\n\n# Import the usual suspects\nimport numpy as np\nimport pandas as pd","55c2d7cd":"# Universal pandas dataframe memory footprint reducer for those dealing with big data but not that big that require spark\ndef df_footprint_reduce(df, skip_obj=False, skip_int=False, skip_float=False, print_comparison=True):\n    '''\n    :param df              : Pandas Dataframe to shrink in memory footprint size\n    :param skip_obj        : If not desired string columns can be skipped during shrink operation\n    :param skip_int        : If not desired integer columns can be skipped during shrink operation\n    :param skip_float      : If not desired float columns can be skipped during shrink operation\n    :param print_comparison: Beware! Printing comparison needs calculation of each columns datasize\n                             so if you need speed turn this off. It's just here to show you info                            \n    :return                : Pandas Dataframe of exactly the same data and dtypes but in less memory footprint    \n    '''\n    if print_comparison:\n        print(f\"Dataframe size before shrinking column types into smallest possible: {round((sys.getsizeof(df)\/1024\/1024),4)} MB\")\n    for column in df.columns:\n        if (skip_obj is False) and (str(df[column].dtype)[:6] == 'object'):\n            num_unique_values = len(df[column].unique())\n            num_total_values = len(df[column])\n            if num_unique_values \/ num_total_values < 0.5:\n                df.loc[:,column] = df[column].astype('category')\n            else:\n                df.loc[:,column] = df[column]\n        elif (skip_int is False) and (str(df[column].dtype)[:3] == 'int'):\n            if df[column].min() > np.iinfo(np.int8).min and df[column].max() < np.iinfo(np.int8).max:\n                df[column] = df[column].astype(np.int8)\n            elif df[column].min() > np.iinfo(np.int16).min and df[column].max() < np.iinfo(np.int16).max:\n                df[column] = df[column].astype(np.int16)\n            elif df[column].min() > np.iinfo(np.int32).min and df[column].max() < np.iinfo(np.int32).max:\n                df[column] = df[column].astype(np.int32)\n        elif (skip_float is False) and (str(df[column].dtype)[:5] == 'float'):\n            if df[column].min() > np.finfo(np.float16).min and df[column].max() < np.finfo(np.float16).max:\n                df[column] = df[column].astype(np.float16)\n            elif df[column].min() > np.finfo(np.float32).min and df[column].max() < np.finfo(np.float32).max:\n                df[column] = df[column].astype(np.float32)\n    if print_comparison:\n        print(f\"Dataframe size after shrinking column types into smallest possible: {round((sys.getsizeof(df)\/1024\/1024),4)} MB\")\n    return df","e04adfe5":"# Universal pandas dataframe null\/nan cleaner\ndef df_null_cleaner(df, fill_with=None, drop_na=False, axis=0):\n    '''\n    Very good information on dealing with missing values of dataframes can be found at \n    http:\/\/pandas.pydata.org\/pandas-docs\/stable\/missing_data.html\n    \n    :param df        : Pandas Dataframe to clean from missing values \n    :param fill_with : Fill missing values with a value of users choice\n    :param drop_na   : Drop either axis=0 for rows containing missing fields\n                       or axis=1 to drop columns having missing fields default rows                   \n    :return          : Pandas Dataframe cleaned from missing values \n    '''\n    df[(df == np.NINF)] = np.NaN\n    df[(df == np.Inf)] = np.NaN\n    if drop_na:\n        df.dropna(axis=axis,inplace=True)\n    if ~fill_with:\n        df.fillna(fill_with, inplace=True)\n    return df","c05cc5f0":"def feature_engineering(df,is_train=True):\n    if is_train:          \n        df = df[df['maxPlace'] > 1].copy()\n\n    target = 'winPlacePerc'\n    print('Grouping similar match types together')\n    df.loc[(df['matchType'] == 'solo'), 'matchType'] = 1\n    df.loc[(df['matchType'] == 'normal-solo'), 'matchType'] = 1\n    df.loc[(df['matchType'] == 'solo-fpp'), 'matchType'] = 1\n    df.loc[(df['matchType'] == 'normal-solo-fpp'), 'matchType'] = 1\n\n    df.loc[(df['matchType'] == 'duo'), 'matchType'] = 2\n    df.loc[(df['matchType'] == 'normal-duo'), 'matchType'] = 2\n    df.loc[(df['matchType'] == 'duo-fpp'), 'matchType'] = 2    \n    df.loc[(df['matchType'] == 'normal-duo-fpp'), 'matchType'] = 2\n\n    df.loc[(df['matchType'] == 'squad'), 'matchType'] = 3\n    df.loc[(df['matchType'] == 'normal-squad'), 'matchType'] = 3    \n    df.loc[(df['matchType'] == 'squad-fpp'), 'matchType'] = 3\n    df.loc[(df['matchType'] == 'normal-squad-fpp'), 'matchType'] = 3\n    \n    df.loc[(df['matchType'] == 'flaretpp'), 'matchType'] = 0\n    df.loc[(df['matchType'] == 'flarefpp'), 'matchType'] = 0\n    df.loc[(df['matchType'] == 'crashtpp'), 'matchType'] = 0\n    df.loc[(df['matchType'] == 'crashfpp'), 'matchType'] = 0\n    df.loc[(df['rankPoints'] < 0), 'rankPoints'] = 0\n    \n    print('Adding new features using existing ones')\n    df['headshotrate'] = df['kills']\/df['headshotKills']\n    df['killStreakrate'] = df['killStreaks']\/df['kills']\n    df['healthitems'] = df['heals'] + df['boosts']\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    df['killPlace_over_maxPlace'] = df['killPlace'] \/ df['maxPlace']\n    df['headshotKills_over_kills'] = df['headshotKills'] \/ df['kills']\n    df['distance_over_weapons'] = df['totalDistance'] \/ df['weaponsAcquired']\n    df['walkDistance_over_heals'] = df['walkDistance'] \/ df['heals']\n    df['walkDistance_over_kills'] = df['walkDistance'] \/ df['kills']\n    df['killsPerWalkDistance'] = df['kills'] \/ df['walkDistance']\n    df['skill'] = df['headshotKills'] + df['roadKills']\n    \n    print('Adding normalized features')\n    df['playersJoined'] = df.groupby('matchId')['matchId'].transform('count')\n    gc.collect()\n    df['killsNorm'] = df['kills']*((100-df['playersJoined'])\/100 + 1)\n    df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])\/100 + 1)\n    df['maxPlaceNorm'] = df['maxPlace']*((100-df['playersJoined'])\/100 + 1)\n    df['matchDurationNorm'] = df['matchDuration']*((100-df['playersJoined'])\/100 + 1)\n    df['headshotKillsNorm'] = df['headshotKills']*((100-df['playersJoined'])\/100 + 1)\n    df['killPlaceNorm'] = df['killPlace']*((100-df['playersJoined'])\/100 + 1)\n    df['killPointsNorm'] = df['killPoints']*((100-df['playersJoined'])\/100 + 1)\n    df['killStreaksNorm'] = df['killStreaks']*((100-df['playersJoined'])\/100 + 1)\n    df['longestKillNorm'] = df['longestKill']*((100-df['playersJoined'])\/100 + 1)\n    df['roadKillsNorm'] = df['roadKills']*((100-df['playersJoined'])\/100 + 1)\n    df['teamKillsNorm'] = df['teamKills']*((100-df['playersJoined'])\/100 + 1)\n    df['damageDealtNorm'] = df['damageDealt']*((100-df['playersJoined'])\/100 + 1)\n    df['DBNOsNorm'] = df['DBNOs']*((100-df['playersJoined'])\/100 + 1)\n    df['revivesNorm'] = df['revives']*((100-df['playersJoined'])\/100 + 1)    \n    \n    # Clean null values from dataframe\n    df = df_null_cleaner(df,fill_with=0)\n\n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchType\")\n    features.remove(\"maxPlace\")\n    \n    y = pd.DataFrame()\n    if is_train: \n        print('Preparing target variable')\n        y = df.groupby(['matchId','groupId'])[target].agg('mean')\n        gc.collect()\n        features.remove(target)\n        \n    print('Aggregating means')\n    means_features = list(df.columns)\n    means_features.remove(\"Id\")\n    means_features.remove(\"matchId\")\n    means_features.remove(\"groupId\")\n    means_features.remove(\"matchType\")  \n    means_features.remove(\"maxPlace\")\n    means_features.remove(\"playersJoined\")\n    means_features.remove(\"matchDuration\")\n    means_features.remove(\"numGroups\")\n    means_features.remove(\"teamKillsNorm\")\n    \n    if is_train:\n        means_features.remove(target)\n    \n    agg = df.groupby(['matchId','groupId'])[means_features].agg('mean')\n    gc.collect()\n    agg_rank = agg.groupby('matchId')[means_features].rank(pct=True).reset_index()\n    gc.collect()\n    \n    if is_train: \n        X = agg.reset_index()[['matchId','groupId']]\n    else: \n        X = df[['matchId','groupId']]\n\n    X = X.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    X = X.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    del agg, agg_rank\n    gc.collect()\n    \n    print('Aggregating maxes')\n    maxes_features = list(df.columns) \n    maxes_features.remove(\"Id\")\n    maxes_features.remove(\"matchId\")\n    maxes_features.remove(\"groupId\")\n    maxes_features.remove(\"matchType\")  \n    maxes_features.remove(\"DBNOsNorm\")\n    maxes_features.remove(\"damageDealtNorm\")\n    maxes_features.remove(\"headshotKillsNorm\")\n    maxes_features.remove(\"killPlaceNorm\")\n    maxes_features.remove(\"killPlace_over_maxPlace\")\n    maxes_features.remove(\"killPointsNorm\")\n    maxes_features.remove(\"killStreaksNorm\")\n    maxes_features.remove(\"killsNorm\")\n    maxes_features.remove(\"longestKillNorm\")\n    maxes_features.remove(\"matchDurationNorm\")\n    maxes_features.remove(\"matchDuration\")\n    maxes_features.remove(\"maxPlaceNorm\")\n    maxes_features.remove(\"maxPlace\")\n    maxes_features.remove(\"numGroups\")\n    maxes_features.remove(\"playersJoined\")\n    maxes_features.remove(\"revivesNorm\")\n    maxes_features.remove(\"roadKillsNorm\")\n    maxes_features.remove(\"teamKillsNorm\")\n\n    if is_train:\n        maxes_features.remove(target)\n    \n    agg = df.groupby(['matchId','groupId'])[maxes_features].agg('max')\n    gc.collect()\n    agg_rank = agg.groupby('matchId')[maxes_features].rank(pct=True).reset_index()\n    gc.collect()\n    X = X.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    X = X.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    del agg, agg_rank\n    gc.collect()\n    \n    print('Aggregating mins')\n    mins_features = list(df.columns) \n    mins_features.remove(\"Id\")\n    mins_features.remove(\"matchId\")\n    mins_features.remove(\"groupId\")\n    mins_features.remove(\"matchType\")  \n    mins_features.remove(\"DBNOsNorm\")\n    mins_features.remove(\"damageDealtNorm\")\n    mins_features.remove(\"headshotKillsNorm\")\n    mins_features.remove(\"killPlaceNorm\")\n    mins_features.remove(\"killPlace_over_maxPlace\")\n    mins_features.remove(\"killPointsNorm\")\n    mins_features.remove(\"killStreaksNorm\")\n    mins_features.remove(\"killsNorm\")\n    mins_features.remove(\"longestKillNorm\")\n    mins_features.remove(\"matchDurationNorm\")\n    mins_features.remove(\"matchDuration\")\n    mins_features.remove(\"maxPlaceNorm\")\n    mins_features.remove(\"maxPlace\")\n    mins_features.remove(\"numGroups\")\n    mins_features.remove(\"playersJoined\")\n    mins_features.remove(\"revivesNorm\")\n    mins_features.remove(\"roadKillsNorm\")\n    mins_features.remove(\"teamKillsNorm\")\n    \n    if is_train:\n        mins_features.remove(target)\n    \n    agg = df.groupby(['matchId','groupId'])[mins_features].agg('min')\n    gc.collect()\n    agg_rank = agg.groupby('matchId')[mins_features].rank(pct=True).reset_index()\n    gc.collect()\n    X = X.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    X = X.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    del agg, agg_rank\n    gc.collect()\n    \n    print('Aggregating group sizes')\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    gc.collect()\n    X = X.merge(agg, how='left', on=['matchId', 'groupId'])\n    print('Aggregating match means')\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    gc.collect()\n    X = X.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    print('Aggregating match sizes')\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    gc.collect()\n    X = X.merge(agg, how='left', on=['matchId'])\n    del df, agg\n    gc.collect()\n\n    X.drop(columns = ['matchId', \n                      'groupId'\n                     ], axis=1, inplace=True)  \n    gc.collect()\n    if is_train:\n        return X, y\n    \n    return X","2ff960b3":"X_train = pd.read_csv('..\/input\/train_V2.csv', engine='c')","dd27fb8e":"X_train = df_footprint_reduce(X_train, skip_obj=True)  # Reduce memory footprint inorder to fit in memory of Kaggle Docker image\ngc.collect()","ffa05531":"X_train, y_train = feature_engineering(X_train, True)\ngc.collect()","e9989dbd":"X_train = df_footprint_reduce(X_train, skip_obj=True) # Reduce memory footprint again after feature generation\ngc.collect()","da3cedd4":"# Import good old friend\nfrom sklearn.model_selection import train_test_split, GridSearchCV","b05c8174":"# Split dataset into train and validation set from %80 of x_train\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, \n                                                                y_train, \n                                                                test_size=0.2)\ngc.collect()","3e2a8b02":"# Import the real deal\nimport lightgbm as lgb","44802e4c":"# Initialize model with initial parameters given\nparameters = { 'objective': 'regression_l1',\n               'learning_rate': 0.01\n               #'bagging_fraction': 0.6,\n               #'bagging_seed': 0,\n               #'feature_fraction': 0.8\n             }","0fedd667":"def find_best_hyperparameters(model):\n    # Grid parameters for using in Gridsearch while tuning\n    gridParams = {\n        'learning_rate'         : [0.1, 0.01 , 0.05],\n        'n_estimators '         : [1000, 10000, 20000],\n        'bagging_fraction'      : [0.5, 0.6 ,0.7],\n        'feature_fraction'      : [0.5, 0.6 ,0.7],\n        'num_leaves'            : [31, 80, 140]\n    }\n    # Create the grid\n    grid = GridSearchCV(model, \n                        gridParams,\n                        verbose=5,\n                        cv=3)\n    # Run the grid\n    grid.fit(X_train, y_train)\n    print('Best parameters: %s' % grid.best_params_)\n    print('Accuracy: %.2f' % grid.best_score_)\n    return","5d3fdf29":"#find_best_hyperparameters(model)   # This takes time so comment out after finding your right parameters for model training","89988864":"X_train =  lgb.Dataset(X_train, label=y_train)\nX_validation =  lgb.Dataset(X_validation, label=y_validation)\ngc.collect()","d87dc250":"%%time\n# Train model with initial parameters given in initialize section\nmodel = lgb.train(parameters, \n                  X_train,\n                  num_boost_round = 40000,\n                  valid_sets=[X_validation,X_train])","475da2e3":"# Competition evaluation is based on mean absolute error so we calculate it over predictions from test data labels\nprint('The mean absolute error of model on validation set is:', model.best_score['valid_0']['l1'])","cf91b739":"import matplotlib.pyplot as plt\nimport seaborn as sns","100d70c1":"# feature importances\nfeature_imp = pd.DataFrame(sorted(zip(model.feature_importance(iteration=model.best_iteration),model.feature_name())), \n                           columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 50))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('Features')\nplt.tight_layout()\nplt.show()","67eda6ba":"# We can eliminate all of these columns because they have no importance to our model\nfeature_imp[feature_imp['Value']==0]","c2009467":"# Clean memory and load test set\ndel X_train, X_validation, y_train, y_validation, feature_imp \ngc.collect()","aefaebff":"test_x = pd.read_csv('..\/input\/test_V2.csv', engine='c')","11b37142":"test_x = df_footprint_reduce(test_x, skip_obj=True)\ngc.collect()","a3df45a1":"test_x = feature_engineering(test_x, False)\ngc.collect()","ebf90e6f":"pred_test = model.predict(test_x, num_iteration=model.best_iteration)\ndel test_x\ngc.collect()","247af989":"test_set = pd.read_csv('..\/input\/test_V2.csv', engine='c')","1f557ee2":"submission = pd.read_csv(\"..\/input\/sample_submission_V2.csv\")\nsubmission['winPlacePerc'] = pred_test\nsubmission.loc[submission.winPlacePerc < 0, \"winPlacePerc\"] = 0\nsubmission.loc[submission.winPlacePerc > 1, \"winPlacePerc\"] = 1\nsubmission = submission.merge(test_set[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\nsubmission_group = submission.groupby([\"matchId\", \"groupId\"]).first().reset_index()\nsubmission_group[\"rank\"] = submission_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\nsubmission_group = submission_group.merge(\n    submission_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n    on=\"matchId\", how=\"left\")\nsubmission_group[\"adjusted_perc\"] = (submission_group[\"rank\"] - 1) \/ (submission_group[\"numGroups\"] - 1)\nsubmission = submission.merge(submission_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\nsubmission[\"winPlacePerc\"] = submission[\"adjusted_perc\"]\nsubmission.loc[submission.maxPlace == 0, \"winPlacePerc\"] = 0\nsubmission.loc[submission.maxPlace == 1, \"winPlacePerc\"] = 1\nsubset = submission.loc[submission.maxPlace > 1]\ngap = 1.0 \/ (subset.maxPlace.values - 1)\nnew_perc = np.around(subset.winPlacePerc.values \/ gap) * gap\nsubmission.loc[submission.maxPlace > 1, \"winPlacePerc\"] = new_perc\nsubmission.loc[(submission.maxPlace > 1) & (submission.numGroups == 1), \"winPlacePerc\"] = 0\nassert submission[\"winPlacePerc\"].isnull().sum() == 0\nsubmission[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)","6c5495aa":"### Feature Engineering","1e9b3f96":"### Load dataset files","5d001a57":"#### First of all what is Gradient Boosting?\n##### Credits for this part goes to Sunil Ray \nDefinition: The term \u2018Boosting\u2019 refers to a family of algorithms which converts weak learner to strong learners.\n\nLet\u2019s understand this definition in detail by solving a problem of spam email identification:\n\nHow would you classify an email as SPAM or not? Like everyone else, our initial approach would be to identify \u2018spam\u2019 and \u2018not spam\u2019 emails using following criteria. If:<br\/>\n\n-Email has only one image file (promotional image), It\u2019s a SPAM<br\/>\n-Email has only link(s), It\u2019s a SPAM<br\/>\n-Email body consist of sentence like \u201cYou won a prize money of $ xxxxxx\u201d, It\u2019s a SPAM<br\/>\n-Email from our official domain \u201cAnalyticsvidhya.com\u201d , Not a SPAM<br\/>\n-Email from known source, Not a SPAM<br\/>\n\nAbove, we\u2019ve defined multiple rules to classify an email into \u2018spam\u2019 or \u2018not spam\u2019. But, do you think these rules individually are strong enough to successfully classify an email? No.<br\/>\n\nIndividually, these rules are not powerful enough to classify an email into \u2018spam\u2019 or \u2018not spam\u2019. Therefore, these rules are called as weak learner.<br\/>\n\nTo convert weak learner to strong learner, we\u2019ll combine the prediction of each weak learner using methods like:\n\u2022   Using average\/ weighted average<br\/>\n\u2022   Considering prediction has higher vote<br\/>\n\nFor example:  Above, we have defined 5 weak learners. Out of these 5, 3 are voted as \u2018SPAM\u2019 and 2 are voted as \u2018Not a SPAM\u2019. In this case, by default, we\u2019ll consider an email as SPAM because we have higher(3) vote for \u2018SPAM\u2019...<br\/>\nFor full blog post: https:\/\/www.analyticsvidhya.com\/blog\/2015\/11\/quick-introduction-boosting-algorithms-machine-learning\/\n\n#### Introduction to Gradient Boost Algorithms\n##### Credits for this part goes to my fellow friend Sefik Ilkin Serengil\nIt is a fact that decision tree based machine learning algorithms dominate Kaggle competitions. More than half of the winning solutions have adopted XGBoost. Recently, Microsoft announced its gradient boosting framework LightGBM. Nowadays, it steals the spotlight in gradient boosting machines. Kagglers start to use LightGBM more than XGBoost. Even though XGBoost might have higher accuracy, LightGBM runs previously 10 times and currently 6 times faster than XGBoost. Moreover, there are tens of solutions standing atop a challenge podium...<br\/>\nFor full blog post: https:\/\/sefiks.com\/2018\/10\/13\/a-gentle-introduction-to-lightgbm-for-applied-machine-learning\/\n\n#### Introduction to Gridsearch\nIt is in simple implementation of auto-hyperparameter tuning. scikit learn team integrated a GridsearchCV function inside of model_selection library of theirs. It exhaustively searches over specified parameter grid (multiple values for each hyperparameter) values for a given estimator. \n\nGridSearchCV implements a \u201cfit\u201d and a \u201cscore\u201d method on array of hyperparameters specified in grid params set. It also implements \u201cpredict\u201d, \u201cpredict_proba\u201d, \u201cdecision_function\u201d, \u201ctransform\u201d and \u201cinverse_transform\u201d if they are implemented in the estimator used and returns back best_score, best_parameters that fits your data for the training. So we leave trial-error part to scikit learn. \n\nUsage is simply:\n\nfrom sklearn import svm, datasets<br\/>\nfrom sklearn.model_selection import GridSearchCV<br\/>\niris = datasets.load_iris()<br\/>\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}<br\/>\nsvc = svm.SVC(gamma=\"scale\")<br\/>\nclf = GridSearchCV(svc, parameters, cv=5)<br\/>\nclf.fit(iris.data, iris.target)<br\/>\nsorted(clf.cv_results_.keys())","cbdbd932":"##### Credits for work at post processing section goes to:\n###### https:\/\/www.kaggle.com\/anycode\/simple-nn-baseline-4\n###### https:\/\/www.kaggle.com\/ceshine\/a-simple-post-processing-trick-lb-0237-0204","94d9a9b2":"### Feature importance","ff9d761e":"### Useful functions for community","a4b5515d":"### Iinitialize model","facb581d":"# LightGBM with Gridsearch and Feature Importance Attention","034a004b":"### Test \/ Validation split of dataset","88a2beae":"### Model Training","2d77141d":"### Prepare for submission ","ca153c9a":"### Model Prediction ","f905e1a7":"### Finding right hyperparameters for our model"}}