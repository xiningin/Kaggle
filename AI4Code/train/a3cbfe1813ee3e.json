{"cell_type":{"7bc777bd":"code","620fe9bf":"code","33988f0a":"code","29f11887":"code","3f7d1862":"code","12121c79":"code","8d02b637":"code","531fb106":"code","5936d50c":"code","2871d1f5":"code","7859f0d0":"code","bb02c1e9":"code","b52d27f8":"code","2f1bc0a9":"code","471eae52":"code","ba11ecfb":"code","d68d4dc1":"markdown","69f0124b":"markdown","de46175f":"markdown"},"source":{"7bc777bd":"import numpy as np \nimport pandas as pd \nimport os\nimport seaborn as sns\nimport networkx as nx\nimport csv\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\ntf.Session()\nfrom IPython.display import YouTubeVideo","620fe9bf":"print(os.listdir(\"..\/input\/\"))\nprint(os.listdir(\"..\/input\/frame-sample\/\/frame\"))\nprint(os.listdir(\"..\/input\/video-sample\/\/video\"))\nvideo_record00 = \"..\/input\/video-sample\/video\/train00.tfrecord\"\nframe_record00 = \"..\/input\/frame-sample\/\/frame\/train00.tfrecord\"","33988f0a":"label_names=pd.read_csv(\"..\/input\/label_names_2018.csv\")\nvocabulary=pd.read_csv(\"..\/input\/vocabulary.csv\")\nsample_submission=pd.read_csv(\"..\/input\/sample_submission.csv\")","29f11887":"print(label_names.head(5))\nprint('The Data in label_names is : {}'.format(label_names.shape))","3f7d1862":"print(vocabulary.head(5))\nprint('The data dictionary in vocabulary is : {}'.format(vocabulary.shape))","12121c79":"# Sample Submission File\nprint(sample_submission.head(5))","8d02b637":"#Tensorflow version\nprint(tf.__version__)","531fb106":"vid_ids = []\nlabels = []\nmean_rgb = []\nmean_audio = []\n\nfor train00 in tf.python_io.tf_record_iterator(video_record00):\n    train_f= tf.train.Example.FromString(train00)\n    vid_ids.append(train_f.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n    labels.append(train_f.features.feature['labels'].int64_list.value)\n    mean_rgb.append(train_f.features.feature['mean_rgb'].float_list.value)\n    mean_audio.append(train_f.features.feature['mean_audio'].float_list.value)\nprint('Number of videos in train00.tfrecord file  is : ',len(mean_rgb))\n#Let us randomly select a video id 18 \nprint('Select  a youtube video id:',vid_ids[18])\n# The list of 20 features of the video d 18 \nprint('First 20 features of a  selected youtube video is  (',vid_ids[18],'):')\nprint(mean_rgb[18][:20])","5936d50c":"vid_ids = []\nlabels = []\nmean_rgb = []\nmean_audio = []\n\nfor train00 in tf.python_io.tf_record_iterator(video_record00):\n    train_f= tf.train.Example.FromString(train00)\n    vid_ids.append(train_f.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n    labels.append(train_f.features.feature['labels'].int64_list.value)\n    mean_rgb.append(train_f.features.feature['mean_rgb'].float_list.value)\n    mean_audio.append(train_f.features.feature['mean_audio'].float_list.value)\nprint('Number of videos in train00.tfrecord file  is : ',len(mean_rgb))\n#Let us randomly select a video id 18 \nprint('Select  a youtube video id:',vid_ids[18])\n# The list of 20 features of the video d 18 \nprint('First 20 features of a  selected youtube video is  (',vid_ids[18],'):')\nprint(mean_rgb[18][:20])","2871d1f5":"YouTubeVideo('mLEJIW9HeIw')","7859f0d0":"feat_rgb = []\nfeat_audio = []\nrgb_frame = []\naudio_frame = []\nimport warnings\nwarnings.filterwarnings(action='ignore',category=UserWarning,module='tensorflow')\nfor train00 in tf.python_io.tf_record_iterator(frame_record00):        \n    train_f = tf.train.SequenceExample.FromString(train00)\n    num_frames = len( train_f .feature_lists.feature_list['audio'].feature)\n    sess = tf.InteractiveSession()\n    # iterate through frames\n    for i in range(num_frames):\n        rgb_frame.append(tf.cast(tf.decode_raw( train_f .feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8) ,tf.float32).eval())\n        audio_frame.append(tf.cast(tf.decode_raw( train_f .feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8),tf.float32).eval())\n    sess.close()\n    feat_rgb.append(rgb_frame)\n    feat_audio.append(audio_frame)\n    break","bb02c1e9":"print('The first video has %d frames' %len(feat_rgb[0]))","b52d27f8":"sns.lmplot(x='Index', y='TrainVideoCount', data=vocabulary , size=15)","2f1bc0a9":"with open('..\/input\/vocabulary.csv', 'r') as f:\n  vocabularylist = list(csv.reader(f))\nT1=[]\nfor l in vocabularylist:\n    if l[5] != 'NaN' and l[6] !='NaN' and l[5] != '' and l[6] !='' and l[5] !=  l[6] :\n        c1 = l[5]\n        c2 = l[6]\n        tuple = (c1, c2)\n    if l[5] != 'NaN' and l[7] !='NaN' and l[5] != '' and l[7] !='' and l[5] !=  l[7] :\n        c1 = l[5]\n        c2 = l[7]\n        tuple = (c1, c2)\n    if l[6] != 'NaN' and l[7] !='NaN' and l[6] != '' and l[7] !='' and l[7] !=  l[6] :\n        c1 = l[6]\n        c2 = l[7]\n        tuple = (c1, c2)\n    T1.append(tuple)\nedges = {k: T1.count(k) for k in set(T1)}\nedges","471eae52":"B = nx.DiGraph()\nnodecolor=[]\nfor ed, weight in edges.items():\n    if ed[0]!='Vertical2' and ed[0]!='Vertical3' and  ed[1]!='Vertical2' and ed[1]!='Vertical3':\n        B.add_edge(ed[0], ed[1], weight=weight)\nfor k in B.nodes:\n    if (k == \"Beauty & Fitness\"):\n        nodecolor.append('blue')\n    elif (k == \"News\"):\n        nodecolor.append('Magenta')\n    elif (k == \"Food & Drink\"):\n        nodecolor.append('crimson')\n    elif (k == \"Health\"):\n        nodecolor.append('green')\n    elif (k == \"Science\"):\n        nodecolor.append('yellow')\n    elif (k == \"Business & Industrial\"):\n        nodecolor.append('cyan')\n    elif (k == \"Home & Garden\"):\n        nodecolor.append('darkorange')\n    elif (k == \"Travel\"):\n        nodecolor.append('slategrey')\n    elif (k == \"Arts & Entertainment\"):\n        nodecolor.append('red')\n    elif (k == \"Games\"):\n        nodecolor.append('grey')\n    elif (k == \"People & Society\"):\n        nodecolor.append('lightcoral')\n    elif (k == \"Shopping\"):\n        nodecolor.append('maroon')\n    elif (k ==\"Computers & Electronics\"):\n        nodecolor.append('orangered')\n    elif (k == \"Hobbies & Leisure\"):\n        nodecolor.append('saddlebrown')\n    elif (k == \"Sports\"):\n        nodecolor.append('lawngreen')\n    elif (k == \"Real Estate\"):\n        nodecolor.append('deeppink')\n    elif (k == \"Finance\"):\n        nodecolor.append('springgreen')\n    elif (k == \"Reference\"):\n        nodecolor.append('royalblue')\n    elif (k == \"Autos & Vehicles\"):\n        nodecolor.append('turquoise')\n    elif (k == \"Internet & Telecom\"):\n        nodecolor.append('lime')\n    elif (k == \"Law & Government\"):\n        nodecolor.append('palegreen')\n    elif (k == \"Jobs & Education\"):\n        nodecolor.append('navy')\n    elif (k == \"Pets & Animals\"):\n        nodecolor.append('lightpink')\n    elif (k == \"Books & Literature\"):\n        nodecolor.append('lightpink')\n    \n                         ","ba11ecfb":"plt.figure(figsize = (15,15))\nnx.draw(B, pos=nx.circular_layout(B), node_size=1500, with_labels=True, node_color=nodecolor)\nnx.draw_networkx_edge_labels(B, pos=nx.circular_layout(B), edge_labels=nx.get_edge_attributes(B, 'weight'))\nplt.title('Weighted graph representing the relationship between the categories', size=20)\nplt.show()","d68d4dc1":"<h3>Lets  read the data from the frame  file<\/h3>","69f0124b":"As ID field in the TensorFlow record files is a <b>4-character string<\/b> ( e.g. ABCD). To get the YouTubeID, you can construct a URI like \/AB\/ABCD.js. As a real example, the ID <b>XE00<\/b> can be converted to a video ID via the URL <b>(http:\/\/data.yt8m.org\/2\/j\/i\/XE\/XE00.js.)<\/b>  The format of the file is JSONP, and should be self-explainatory.","de46175f":"<h3>Lets first read the data from the video file<\/h3>\n"}}