{"cell_type":{"728c15a5":"code","93206a80":"code","7b2ab218":"code","65097946":"code","5279294f":"code","fb71a9a9":"code","8f9c1d93":"code","26e9f30c":"code","1370821f":"markdown","2a68006b":"markdown","4debd980":"markdown","5edc2051":"markdown","db48f068":"markdown","fd0aa234":"markdown","dea23777":"markdown","9a0cda52":"markdown","84fbbbab":"markdown"},"source":{"728c15a5":"\n# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https:\/\/pypi.org\/simple\/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'\nfrom kaggle_environments import evaluate, make, utils\nimport random\nimport math\nimport time","93206a80":"env = make(\"connectx\", debug=True)\nconfiguration = env.configuration\nprint(configuration)","7b2ab218":"def MCTS_agent(observation, configuration):\n    \"\"\"\n    Connect X agent based on MCTS.\n    \"\"\"\n    import random\n    import math\n    import time\n    global current_state  # so tree can be recycled\n\n    init_time = time.time()\n    EMPTY = 0\n    T_max = configuration.timeout - 0.34  # time per move, left some overhead\n    Cp_default = 1\n\n    def play(board, column, mark, config):\n        \"\"\" Plays a move. Taken from the Kaggle environment. \"\"\"\n        columns = config.columns\n        rows = config.rows\n        row = max([r for r in range(rows) if board[column + (r * columns)] == EMPTY])\n        board[column + (row * columns)] = mark\n\n    def is_win(board, column, mark, config):\n        \"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\n        columns = config.columns\n        rows = config.rows\n        inarow = config.inarow - 1\n        row = min([r for r in range(rows) if board[column + (r * columns)] == mark])\n\n        def count(offset_row, offset_column):\n            for i in range(1, inarow + 1):\n                r = row + offset_row * i\n                c = column + offset_column * i\n                if (\n                        r < 0\n                        or r >= rows\n                        or c < 0\n                        or c >= columns\n                        or board[c + (r * columns)] != mark\n                ):\n                    return i - 1\n            return inarow\n\n        return (\n                count(1, 0) >= inarow  # vertical.\n                or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n                or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n                or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n        )\n\n    def is_tie(board):\n        \"\"\" Checks if a tie occured. \"\"\"\n        return not(any(mark == EMPTY for mark in board))\n\n    def check_finish_and_score(board, column, mark, config):\n        \"\"\" Returns a tuple where the first argument states whether game is finished and second argument returns score if game has finished. \"\"\"\n        if is_win(board, column, mark, config):\n            return (True, 1)\n        if is_tie(board):\n            return (True, 0.5)\n        else:\n            return (False, None)\n\n    def uct_score(node_total_score, node_total_visits, parent_total_visits, Cp=Cp_default):\n        \"\"\" UCB1 calculation. \"\"\"\n        if node_total_visits == 0:\n            return math.inf\n        return node_total_score \/ node_total_visits + Cp * math.sqrt(\n            2 * math.log(parent_total_visits) \/ node_total_visits)\n\n    def opponent_mark(mark):\n        \"\"\" The mark indicates which player is active - player 1 or player 2. \"\"\"\n        return 3 - mark\n\n    def opponent_score(score):\n        \"\"\" To backpropagate scores on the tree. \"\"\"\n        return 1 - score\n\n    def random_action(board, config):\n        \"\"\" Returns a random legal action (from the open columns). \"\"\"\n        return random.choice([c for c in range(config.columns) if board[c] == EMPTY])\n\n    def default_policy_simulation(board, mark, config):\n        \"\"\"\n        Run a random play simulation. Starting state is assumed to be a non-terminal state.\n        Returns score of the game for the player with the given mark.\n        \"\"\"\n        original_mark = mark\n        board = board.copy()\n        column = random_action(board, config)\n        play(board, column, mark, config)\n        is_finish, score = check_finish_and_score(board, column, mark, config)\n        while not is_finish:\n            mark = opponent_mark(mark)\n            column = random_action(board, config)\n            play(board, column, mark, config)\n            is_finish, score = check_finish_and_score(board, column, mark, config)\n        if mark == original_mark:\n            return score\n        return opponent_score(score)\n    \n    def find_action_taken_by_opponent(new_board, old_board, config):\n        \"\"\" Given a new board state and a previous one, finds which move was taken. Used for recycling tree between moves. \"\"\"\n        for i, piece in enumerate(new_board):\n            if piece != old_board[i]:\n                return i % config.columns\n        return -1  # shouldn't get here\n\n    class State():\n        \"\"\" \n        A class that represents nodes in the game tree.\n        \n        \"\"\"\n        def __init__(self, board, mark, config, parent=None, is_terminal=False, terminal_score=None, action_taken=None):\n            self.board = board.copy()\n            self.mark = mark\n            self.config = config\n            self.children = []\n            self.parent = parent\n            self.node_total_score = 0\n            self.node_total_visits = 0\n            self.available_moves = [c for c in range(config.columns) if board[c] == EMPTY]\n            self.expandable_moves = self.available_moves.copy()\n            self.is_terminal = is_terminal\n            self.terminal_score = terminal_score\n            self.action_taken = action_taken\n\n        def is_expandable(self):\n            \"\"\" Checks if the node has unexplored children. \"\"\"\n            return (not self.is_terminal) and (len(self.expandable_moves) > 0)\n\n        def expand_and_simulate_child(self):\n            \"\"\" Expands a random move from the legal unexplored moves, and runs a simulation of it \n            (Expansion + Simulation + Backpropagation stages in the MCTS algorithm description). \"\"\"\n            column = random.choice(self.expandable_moves)\n            child_board = self.board.copy()\n            play(child_board, column, self.mark, self.config)\n            is_terminal, terminal_score = check_finish_and_score(child_board, column, self.mark, self.config)\n            self.children.append(State(child_board, opponent_mark(self.mark),\n                                       self.config, parent=self,\n                                       is_terminal=is_terminal,\n                                       terminal_score=terminal_score,\n                                       action_taken=column\n                                       ))\n            simulation_score = self.children[-1].simulate()\n            self.children[-1].backpropagate(simulation_score)\n            self.expandable_moves.remove(column)\n\n        def choose_strongest_child(self, Cp):\n            \"\"\"\n            Chooses child that maximizes UCB1 score (Selection stage in the MCTS algorithm description).\n            \"\"\"\n            children_scores = [uct_score(child.node_total_score,\n                                         child.node_total_visits,\n                                         self.node_total_visits,\n                                         Cp) for child in self.children]\n            max_score = max(children_scores)\n            best_child_index = children_scores.index(max_score)\n            return self.children[best_child_index]\n            \n        def choose_play_child(self):\n            \"\"\" Choose child with maximum total score.\"\"\"\n            children_scores = [child.node_total_score for child in self.children]\n            max_score = max(children_scores)\n            best_child_index = children_scores.index(max_score)\n            return self.children[best_child_index]\n\n        def tree_single_run(self):\n            \"\"\"\n            A single iteration of the 4 stages of the MCTS algorithm.\n            \"\"\"\n            if self.is_terminal:\n                self.backpropagate(self.terminal_score)\n                return\n            if self.is_expandable():\n                self.expand_and_simulate_child()\n                return\n            self.choose_strongest_child(Cp_default).tree_single_run()\n\n        def simulate(self):\n            \"\"\"\n            Runs a simulation from the current state. \n            This method is used to simulate a game after move of current player, so if a terminal state was reached,\n            the score would belong to the current player who made the move.\n            But otherwise the score received from the simulation run is the opponent's score and thus needs to be flipped with the function opponent_score().            \n            \"\"\"\n            if self.is_terminal:\n                return self.terminal_score\n            return opponent_score(default_policy_simulation(self.board, self.mark, self.config))\n\n        def backpropagate(self, simulation_score):\n            \"\"\"\n            Backpropagates score and visit count to parents.\n            \"\"\"\n            self.node_total_score += simulation_score\n            self.node_total_visits += 1\n            if self.parent is not None:\n                self.parent.backpropagate(opponent_score(simulation_score))\n                \n        def choose_child_via_action(self, action):\n            \"\"\" Choose child given the action taken from the state. Used for recycling of tree. \"\"\"\n            for child in self.children:\n                if child.action_taken == action:\n                    return child\n            return None\n\n    board = observation.board\n    mark = observation.mark\n    \n    # If current_state already exists, recycle it based on action taken by opponent\n    try:  \n        current_state = current_state.choose_child_via_action(\n            find_action_taken_by_opponent(board, current_state.board, configuration))\n        current_state.parent = None  # make current_state the root node, dereference parents and siblings\n        \n    except:  # new game or other error in recycling attempt due to Kaggle mechanism\n        current_state = State(board, mark,  # This state is considered after the opponent's move\n                              configuration, parent=None, is_terminal=False, terminal_score=None, action_taken=None)\n   \n    # Run MCTS iterations until time limit is reached.\n    while time.time() - init_time <= T_max:\n        current_state.tree_single_run()\n        \n    current_state = current_state.choose_play_child()\n    return current_state.action_taken","65097946":"env.reset()\ntry:\n    del current_state\nexcept:\n    pass\n\nenv.run([MCTS_agent, MCTS_agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","5279294f":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) \/ sum(r[0] + r[1] for r in rewards)\n\n# Run multiple episodes to estimate its performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"random\"], num_episodes=20)))\nprint(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", MCTS_agent], num_episodes=20)))\nprint(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes=5)))\nprint(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes=5)))","fb71a9a9":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([MCTS_agent, None], width=500, height=450)","8f9c1d93":"import inspect\n\nsubmission_path = \"submission.py\"\n        \ndef write_agent_to_file(function, file):\n    with open(file, \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(MCTS_agent, submission_path)","26e9f30c":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\ntry:\n    submission = utils.read_file(\"\/kaggle\/working\/submission.py\")\n    agent = utils.get_last_callable(submission)\nfinally:\n    sys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","1370821f":"# Imports","2a68006b":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely.","4debd980":"# Write Submission File\n\n","5edc2051":"> # Play your Agent\nClick on any column to place a checker there (\"manually select action\").","db48f068":"# Check agent validity","fd0aa234":"# Functions","dea23777":"# Evaluate your agent","9a0cda52":"# Monte Carlo Tree Search (MCTS)\nThis is an agent that plays with UCT-MCTS.  \nCode is highly commented to be readable.","84fbbbab":"# Create ConnectX Environment"}}