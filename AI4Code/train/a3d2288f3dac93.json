{"cell_type":{"8987eeb2":"code","782cf846":"code","523dfb61":"code","68779c90":"code","8ec17d2c":"code","edb833b5":"code","b1739812":"code","d92fdbf4":"code","b3861259":"code","1c027ae4":"code","7151fe5a":"code","f27cb37f":"code","599116cc":"code","75afe190":"code","d6295e4e":"code","ff6e3b10":"code","328c9de6":"code","9df73a53":"code","4ad44d0d":"code","9a905b28":"code","5ffe87cd":"code","f1fa69f2":"code","1e4d3ea8":"code","edc17bc2":"code","fbdc6731":"code","bf25e3ec":"code","1462078a":"code","d9e3af61":"code","8fa8a88c":"code","39f33e48":"code","e48ada46":"code","ab9a358d":"code","632abe1c":"code","a6c68cea":"code","cd64468f":"code","09fedc62":"code","71d1eb95":"code","ea6be703":"code","f2ebdac0":"code","ca3478b2":"code","bf067a12":"code","88883e0c":"code","b01d228b":"markdown","731af3f1":"markdown","95647af8":"markdown","ff50c57a":"markdown","a7fd3db4":"markdown","f6c87978":"markdown","bff2fb5f":"markdown","d46043f0":"markdown","645249f6":"markdown","2a7063ca":"markdown","e82830da":"markdown"},"source":{"8987eeb2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","782cf846":"# Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics\nfrom sklearn.impute import *\n%matplotlib inline","523dfb61":"## Import Trainning data. \ntrain_raw = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain_raw.head()","68779c90":"train_raw.describe()","8ec17d2c":"## Import Trainning data. \ntest_raw = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest_raw.head()","edb833b5":"train_raw.columns","b1739812":"train_ID = train_raw['Id']\ntest_ID = test_raw['Id']\n# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain_raw.drop(['Id'], axis=1, inplace=True)\ntest_raw.drop(['Id'], axis=1, inplace=True)","d92fdbf4":"total = train_raw.isnull().sum().sort_values(ascending=False)\npercent = (train_raw.isnull().sum()\/train_raw.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nf, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=missing_data.index, y=missing_data['Percent'])\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\nmissing_data.head()","b3861259":"train_raw.isnull().sum()[train_raw.isnull().sum() > 0]","1c027ae4":"train_core = train_raw.drop(['PoolQC','Fence','MiscFeature','Alley','FireplaceQu'], axis=1)\ntest_core = test_raw.drop(['PoolQC','Fence','MiscFeature','Alley','FireplaceQu'], axis=1)","7151fe5a":"train_core.SalePrice = np.log1p(train_core.SalePrice)","f27cb37f":"#impulse train and test value\nfinal_imputer = SimpleImputer (strategy=\"most_frequent\")\ntrain_imputed = final_imputer.fit_transform(train_core.drop('SalePrice', axis=1).values)\ntest_imputed = final_imputer.transform(test_core.values)","599116cc":"#create data frame\ntrain_imputed = pd.DataFrame(train_imputed, columns = train_core.drop('SalePrice', axis=1).columns)\ntest_imputed = pd.DataFrame(test_imputed, columns = test_core.columns)","75afe190":"print(train_imputed.shape)\ntrain_imputed.head()","d6295e4e":"print(test_imputed.shape)\ntest_imputed.head()","ff6e3b10":"print(train_imputed.isnull().sum()[train_imputed.isnull().sum() > 0])\nprint(test_imputed.isnull().sum()[test_imputed.isnull().sum() > 0])","328c9de6":"print(train_imputed.shape)\nprint(test_imputed.shape)","9df73a53":"X = train_imputed.copy()\ny = train_core.SalePrice\nX_test = test_imputed.copy()","4ad44d0d":"# Get list of categorical variables\ns = (train_core.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(\"Categorical variables:\")\nprint(object_cols)","9a905b28":"train_ohe =  pd.get_dummies(X,columns=object_cols)\ntest_ohe = pd.get_dummies(X_test,columns=object_cols)\n# Get missing columns in the training test\nmissing_cols = set( train_ohe.columns ) - set( test_ohe.columns )\n# Add a missing column in test set with default value equal to 0\nfor c in missing_cols:\n    test_ohe[c] = 0\n# Ensure the order of column in the test set is in the same order than in train set\ntest_ohe = test_ohe[train_ohe.columns]","5ffe87cd":"print(train_ohe.shape)\nprint(test_ohe.shape)","f1fa69f2":"def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n\nn_valid = 300  # same as Kaggle's test set size\nn_trn = len(train_ohe)-n_valid\n\nX_train, X_val = split_vals(train_ohe, n_trn)\ny_train, y_val = split_vals(y, n_trn)\n\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","1e4d3ea8":"# Fit Random Forest on Training Set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators=40,random_state=123)\nregressor.fit(X_train, y_train)\n","edc17bc2":"import math\ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_val), y_val),\n                m.score(X_train, y_train), m.score(X_val, y_val)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","fbdc6731":"print_score(regressor)","bf25e3ec":"preds = np.stack([t.predict(X_val) for t in regressor.estimators_]) \n","1462078a":"np.mean(preds[:,0])","d9e3af61":"plt.plot([metrics.r2_score(y_val,np.mean(preds[:i+1],axis = 0))\\\n         for i in range(10)])","8fa8a88c":"regressor = RandomForestRegressor(n_estimators=20,n_jobs=-1)\nregressor.fit(X_train, y_train)\nprint_score(regressor)","39f33e48":"regressor = RandomForestRegressor(n_estimators=40,n_jobs=-1)\nregressor.fit(X_train, y_train)\nprint_score(regressor)","e48ada46":"regressor = RandomForestRegressor(n_estimators=80,n_jobs=-1)\nregressor.fit(X_train, y_train)\nprint_score(regressor)","ab9a358d":"plt.figure(figsize=(18,9))\nfeat_importances = pd.Series(regressor.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","632abe1c":"type(feat_importances)","a6c68cea":"feat_importances[:15].keys()","cd64468f":"feature_importances = pd.DataFrame(regressor.feature_importances_,\\\n                                    index=X_train.columns,\\\n                                    columns=['importance']).sort_values(by='importance', ascending=False)\nfeature_importances","09fedc62":"feature_importances.reset_index(inplace=True)\nfeature_importances","71d1eb95":"feature_importances[:15].plot('index', 'importance', figsize=(10,6), legend=False);","ea6be703":"def plot_fi(fi): \n    return fi.plot('index','importance','barh', figsize=(12,7), legend=False)\nplot_fi(feature_importances[:30])","f2ebdac0":"# most correlated features\ncorrmat = train_raw.corr()\ntop_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\nplt.figure(figsize=(10,10))\ng = sns.heatmap(train_raw[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","ca3478b2":" np.argsort(feat_importances)","bf067a12":"# Get predictions on processed test dataset.\npredictions = regressor.predict(test_ohe)","88883e0c":"sub = pd.DataFrame()\ntest_ID = test_ID\nsub['Id'] = test_ID\nsub['SalePrice'] = np.exp(predictions)\nsub.to_csv('submission.csv',index=False)","b01d228b":"## Submit result","731af3f1":"## Handle Missing Value","95647af8":"## Drop features have so much missing","ff50c57a":"## Plot importance features","a7fd3db4":"## Build Model","f6c87978":"## Model validation","bff2fb5f":"## Compare with high correlation featues","d46043f0":"## Plot missing data graph","645249f6":"## One Hot Encoding","2a7063ca":"## Log SalePrice","e82830da":"## Confirm train and test set don't have any missing value"}}