{"cell_type":{"7fa18be7":"code","56ef8138":"code","5b45d2f3":"code","a10384b9":"code","aacd2fda":"code","014c046d":"code","998d3694":"code","d6d27744":"code","e11a7398":"code","fe002d33":"code","77f95dac":"code","51f17a8e":"code","db3c4967":"code","4bacdec1":"code","edb01a29":"code","70898b4a":"code","c1cbac45":"markdown","c6dbd11a":"markdown","68345c94":"markdown","d2b6652b":"markdown","4543b952":"markdown","bf1b8ec2":"markdown","f0cb7838":"markdown","2b8f5cce":"markdown","d91e8221":"markdown","5ae733e6":"markdown","5b2b854b":"markdown","6ae19ab5":"markdown","d312840f":"markdown","a3c6b8a1":"markdown","cbf56ea2":"markdown","fccf7928":"markdown"},"source":{"7fa18be7":"from skimage import io\nimport os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.transform import rescale\nimport resnet\nimport tensorflow as tf\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import *\nfrom functools import partial\nimport tensorflow.keras.backend as K\nfrom itertools import product\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport warnings\nwarnings.simplefilter('ignore')","56ef8138":"DATASET_PATH = '.\/CXR_data\/'\n\n# There are two classes of images that we will deal with\ndisease_cls = ['effusion', 'nofinding']","5b45d2f3":"effusion_path = os.path.join(DATASET_PATH, disease_cls[0], '*')\neffusion = glob.glob(effusion_path)\neffusion = io.imread(effusion[0])\n\nnormal_path = os.path.join(DATASET_PATH, disease_cls[1], '*')\nnormal = glob.glob(normal_path)\nnormal = io.imread(normal[0])\n\nf, axes = plt.subplots(1, 2, sharey=True)\nf.set_figwidth(10)\n    \naxes[0].imshow(effusion, cmap='gray')\naxes[1].imshow(normal, cmap='gray')","a10384b9":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10,\n    width_shift_range=0,\n    height_shift_range=0,\n    vertical_flip=False,)\n\ndef preprocess_img(img, mode):\n    img = (img - img.min())\/(img.max() - img.min())\n    img = rescale(img, 0.25, multichannel=True, mode='constant')\n    \n    if mode == 'train':\n        if np.random.randn() > 0:\n            img = datagen.random_transform(img)\n    return img","aacd2fda":"img_channels = 1\nimg_rows = 256\nimg_cols = 256\nnb_classes = 2","014c046d":"class AugmentedDataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, mode='train', ablation=None, disease_cls = ['nofinding', 'effusion'], \n                 batch_size=32, dim=(256, 256), n_channels=1, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = {}\n        self.list_IDs = []\n        self.mode = mode\n        \n        for i, cls in enumerate(disease_cls):\n            paths = glob.glob(os.path.join(DATASET_PATH, cls, '*'))\n            brk_point = int(len(paths)*0.8)\n            if self.mode == 'train':\n                paths = paths[:brk_point]\n            else:\n                paths = paths[brk_point:]\n            if ablation is not None:\n                paths = paths[:int(len(paths)*ablation\/100)]\n            self.list_IDs += paths\n            self.labels.update({p:i for p in paths})\n        \n            \n        self.n_channels = n_channels\n        self.n_classes = len(disease_cls)\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n        \n        delete_rows = []\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            img = io.imread(ID)\n            img = img[:, :, np.newaxis]\n            if img.shape == (1024, 1024,1):\n                img = preprocess_img(img, self.mode)\n                X[i,] = img\n                y[i] = self.labels[ID]\n            else:\n                delete_rows.append(i)\n                continue\n                \n        X = np.delete(X, delete_rows, axis=0)\n        y = np.delete(y, delete_rows, axis=0)\n        \n        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)","998d3694":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit(training_generator, epochs=1, validation_data=validation_generator)","d6d27744":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit(training_generator, epochs=5, validation_data=None)","e11a7398":"class roc_callback(Callback):\n    \n    def on_train_begin(self, logs={}):\n        logs['val_auc'] = 0\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_p = []\n        y_v = []\n        for i in range(len(validation_generator)):\n            x_val, y_val = validation_generator[i]\n            y_pred = self.model.predict(x_val)\n            y_p.append(y_pred)\n            y_v.append(y_val)\n        y_p = np.concatenate(y_p)\n        y_v = np.concatenate(y_v)\n        roc_auc = roc_auc_score(y_v, y_p)\n        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n        logs['val_auc'] = roc_auc","fe002d33":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=20)\nvalidation_generator = AugmentedDataGenerator('val', ablation=20)\n\nauc_logger = roc_callback()\n\nmodel.fit(training_generator, epochs=5, validation_data=validation_generator, callbacks=[auc_logger])","77f95dac":"def w_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    cross_ent = K.categorical_crossentropy(y_true, y_pred, from_logits=False)\n    return cross_ent * final_mask\n\nbin_weights = np.ones((2,2))\nbin_weights[0, 1] = 5\nbin_weights[1, 0] = 5\nncce = partial(w_categorical_crossentropy, weights=bin_weights)\nncce.__name__ ='w_categorical_crossentropy'","51f17a8e":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss=ncce, optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit(training_generator, epochs=1, validation_data=None)","db3c4967":"class DecayLR(tf.keras.callbacks.Callback):\n    def __init__(self, base_lr=0.01, decay_epoch=1):\n        super(DecayLR, self).__init__()\n        self.base_lr = base_lr\n        self.decay_epoch = decay_epoch \n        self.lr_history = []\n        \n    def on_train_begin(self, logs={}):\n        K.set_value(self.model.optimizer.lr, self.base_lr)\n\n    def on_epoch_end(self, epoch, logs={}):\n        new_lr = self.base_lr * (0.5 ** (epoch \/\/ self.decay_epoch))\n        self.lr_history.append(K.get_value(self.model.optimizer.lr))\n        K.set_value(self.model.optimizer.lr, new_lr)","4bacdec1":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nsgd = optimizers.SGD(lr=0.005)\n\nbin_weights = np.ones((2,2))\nbin_weights[1, 1] = 10\nbin_weights[1, 0] = 10\nncce = partial(w_categorical_crossentropy, weights=bin_weights)\nncce.__name__ ='w_categorical_crossentropy'\n\nmodel.compile(loss=ncce,optimizer= sgd,\n              metrics=['accuracy'])\ntraining_generator = AugmentedDataGenerator('train', ablation=50)\nvalidation_generator = AugmentedDataGenerator('val', ablation=50)\n\nauc_logger = roc_callback()\nfilepath = 'models\/best_model.hdf5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n\ndecay = DecayLR()\n\nmodel.fit(training_generator, epochs=10, validation_data=validation_generator, callbacks=[auc_logger, decay, checkpoint])","edb01a29":"val_model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nval_model.load_weights('models\/best_model.hdf5')\n\neffusion_path = os.path.join(DATASET_PATH, disease_cls[0], '*')\neffusion = glob.glob(effusion_path)\neffusion = io.imread(effusion[-8])\nplt.imshow(effusion,cmap='gray')","70898b4a":"img = preprocess_img(effusion[:, :, np.newaxis], 'validation')\nval_model.predict(img[np.newaxis,:])","c1cbac45":"Our data is in the form of grayscale (black and white) images of chest x-rays. To perform our classification task effectively, we need to perform some pre-processing of the data.","c6dbd11a":"## END","68345c94":"## <font color=red> 5. Model building <a name='no5' \/>","d2b6652b":"## <font color=green>Bookmarks to Notebook Sections\n<font color=blue>\n1. Go to <a href=#no1>Introduction<\/a><br>\n2. Go to <a href=#no2>Importing Libraries<\/a><br>\n3. Go to <a href=#no3>Data Reading<\/a><br>\n4. Go to <a href=#no4>Data Augmentation<\/a><br>\n5. Go to <a href=#no5>Model Building<\/a><br>\n6. Go to <a href=#no6>Ablation Run<\/a><br>\n7. Go to <a href=#no7>Final Run<\/a><br>\n8. Go to <a href=#no8>Making a Prediction<\/a><br>","4543b952":"## <font color=red>4. Data Augmentation <a name='no3' \/>\n\nNow that we have read the images, the next step is data augmentation. We use the concept of a \"data generator\".","bf1b8ec2":"Neural networks have revolutionised image processing in several different domains. Among these is the field of medical imaging. In the following notebook, we will get some hands-on experience in working with Chest X-Ray (CXR) images.\n\nThe objective of this exercise is to identify images where an \"effusion\" is present. This is a classification problem, where we will be dealing with two classes - 'effusion' and 'nofinding'. Here, the latter represents a \"normal\" X-ray image.\n\nThis same methodology can be used to spot various other illnesses that can be detected via a chest x-ray. For the scope of this demonstration, we will specifically deal with \"effusion\".\n\nOur data is in the form of grayscale (black and white) images of chest x-rays. You can download the dataset from here: https:\/\/www.kaggle.com\/shaitender\/cxr-dataset","f0cb7838":"## <font color=red>6. Ablation Run <a name='no6' \/>","2b8f5cce":"Next, we read the \"effusion\" and \"nofinding\" images.","d91e8221":"We will be using a Resnet in this project. \n\nFor this to work, the script that defines the resnet model (resnet.py) should reside in the same folder as this notebook","5ae733e6":"## <font color=red>3. Data Reading <a name='no3' \/>","5b2b854b":"## <font color=red>2. Importing Libraries <a name='no2' \/>","6ae19ab5":"## <font color=red>8. Making a Prediction <a name='no8' \/>","d312840f":"## <font color=red>7. Final Run <a name='no7' \/>","a3c6b8a1":"After deeply examining our data and building some preliminary models, we are finally ready to build a model that will perform our prediction task.","cbf56ea2":"# Analysis of Chest X-Ray images","fccf7928":"## <font color=red>1. Introduction <a name='no1' \/>"}}