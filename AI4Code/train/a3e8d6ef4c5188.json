{"cell_type":{"271783bd":"code","6bbeb0a8":"code","d531d099":"code","3a4faab1":"code","520d23c6":"code","69323ed7":"code","d1a99960":"code","e2995d39":"code","f0cb20a6":"code","de563375":"code","f4cd170a":"code","131762d5":"code","9d0cd833":"code","97dbc3e5":"code","2897430f":"code","00698618":"code","36dabc51":"code","90e9a144":"code","26903038":"code","b8a192a1":"code","1a303f09":"code","7e7b905e":"code","042448c4":"code","6835d326":"code","50179f0d":"markdown","f4f4fff3":"markdown","f6a3898b":"markdown","bead0614":"markdown","d21db668":"markdown","4c4747be":"markdown","ad104705":"markdown"},"source":{"271783bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6bbeb0a8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n","d531d099":"data = pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")\ndata.head()","3a4faab1":"print(\"The Shape of the dataset: {} \".format(data.shape))","520d23c6":"print(\"Summary of the data: {}\\n\".format(data.info()))","69323ed7":"print(\"Summary of the data: {}\\n\".format(data.describe()))","d1a99960":"print(\"The Missing values in the dataset are : {}\".format(data.isnull().sum()))","e2995d39":"data.describe(include='all').transpose()","f0cb20a6":"#dropping variable veil_type\ndata = data.drop([\"veil-type\"], axis = 1)","de563375":"#seperating the dependant and independant variables.\nfeatures = data.columns\ntarget = 'class'\nfeatures = list(features.drop(target))\nfeatures","f4cd170a":"# There are 21 variables, so a plot is divided into 11 rows and 2 columns.\nfig, axs = plt.subplots(nrows=11, ncols=2, figsize=(11, 66))\n\nfor f, ax in zip(features, axs.ravel()):\n    sns.countplot(x=f, hue='class', data=data, ax = ax)","131762d5":"#Converting categories columns to number column(Label encoding)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nfor col in data.columns:\n    data[col] = le.fit_transform(data[col])\n","9d0cd833":"data.describe().transpose()","97dbc3e5":"plt.figure(figsize=(14,12))\nsns.heatmap(data.corr(),linewidths=.1,cmap=\"GnBu\", annot=True)","2897430f":"X = data.drop('class', axis=1)\ny = data['class']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = y, random_state=0)","00698618":"data.head()","36dabc51":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","90e9a144":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","26903038":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train_scaled, y_train)","b8a192a1":"y_pred = lr.predict(X_test_scaled)","1a303f09":"print(\"Accuracy score is {}\".format(lr.score(X_test_scaled, y_test)))","7e7b905e":"from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n\n#Let's see how our model performed\nprint(classification_report(y_test, y_pred))","042448c4":"#Confusion matrix for the LR classification\nprint(confusion_matrix(y_test, y_pred))","6835d326":"from sklearn.model_selection import cross_val_score\n\n#Now lets try to do some evaluation using cross validation.\nLR_eval = cross_val_score(estimator = lr, X = X_train_scaled, y = y_train, cv = 10)\nLR_eval.mean()\n","50179f0d":"![](http:\/\/)### Feature Scaling","f4f4fff3":"All of the features in this dataset are categorical. We need to transform to values. The target variable is 'e' (Edible) and 'p' (Poisonous). The Veil type has only one category. So, we will drop that columns has it doesnot give any value addition to the model. \nSome of the variables such as Veil-color, ring number, gill-attachment have higher percentage with respect to one category. We will see how to deal with that kind of variable.","f6a3898b":"### Logistic Regression","bead0614":"There are no values in the columns.","d21db668":"### Splitting the dataset","4c4747be":"Our Accuracy is 95%","ad104705":"Let us understand the graphs one by one.\n\ncap-shape: Categories 'x' and 'f' have approximately equal number of poisonous(p) and edible(e) mushrooms. They don't differentiate between 'p' and 'e'. Category 'b' has mostly edible mushrooms. Category 's' and 'c' have very small presence. (This might not be a good feature)\n\ncap-surface: Category 's' and 'y' have equal 'p' and 'e' mushrooms. Category 'f' have 50% more 'e' mushrooms. Very little presence of category 'g'. (This might not be a good feature)\n\ncap-color: Each category has both the types of mushrooms. (This might not be a good feature)\n\nbruises: Category 't' are majorly edible musrooms and category 'f' are poisonous.\n\nodor: Each category is either a poisonous or edible mushroom.\n\ngill-attachment: (This might not be a good feature)\n\ngill-spacing: It does not distinguish very clearly but can be a helpful feature.\n\ngill-size: Each category is either a poisonous or edible mushroom.\n\ngill-color: Here we can see, few colors distinguish very clearly between 'p' and 'e'\/\n\nstalk-shape: (This might not be a good feature)\n\nstalk-root: Can be used as a feature.\n\nstalk-surface-above-ring: Can be used as a feature.\n\nstalk-surface-below-ring: Can be used as a feature.\n\nstalk-color-above-ring: Can be used as a feature.\n\nstalk-color-below-ring: Can be used as a feature.\n\nveil-color: (This might not be a good feature)\n\nring-number: (This might not be a good feature)\n\nring-type: Can be used as a feature.\n\nspore-print-color: Can be used as a feature.\n\npopulation: Can be used as a feature.\n\nhabitat: Can be used as a feature.\n"}}