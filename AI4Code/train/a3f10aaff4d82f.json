{"cell_type":{"a8e9e996":"code","7dd66ab9":"code","f1f47341":"code","02fbb4f1":"code","69fe5d64":"code","4922d3bd":"code","83b2b36e":"code","78a88395":"code","3dc225b3":"code","c9387b23":"code","7d0929cd":"code","2b6ef36d":"code","769f1543":"code","f10f4371":"code","e5423ebb":"code","674d2fa1":"code","b8dd6c62":"code","30edf623":"markdown","e2cd206c":"markdown","7901dbe8":"markdown","cf8916d9":"markdown","02278489":"markdown","0c259e1c":"markdown","9022bb4a":"markdown","699cfe19":"markdown","101d3345":"markdown","9e15a79b":"markdown","42bf2bc3":"markdown","d598a305":"markdown"},"source":{"a8e9e996":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(ecommerce-customer-device-usage, Ecommerce Customers))\ndata= pd.read_csv(\"..\/input\/ecommerce-customer-device-usage\/Ecommerce Customers\")\ndata.head()\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7dd66ab9":"data.describe()","f1f47341":"data.info()","02fbb4f1":"%matplotlib inline\ndata.hist(bins= 8, figsize= (15, 15))","69fe5d64":"corr_matrix= data.corr()\ncorr_matrix[\"Yearly Amount Spent\"].sort_values(ascending= False)","4922d3bd":"from pandas.plotting import scatter_matrix\n\nattributes= [\"Yearly Amount Spent\",\"Length of Membership\", \"Time on App\", \"Avg. Session Length\", \"Time on Website\"]\nscatter_matrix(data[attributes], figsize=(15, 15))","83b2b36e":"data[\"Ceil_LoM\"]= np.ceil(data[\"Length of Membership\"])\ndata[\"Ceil_LoM\"].hist(bins= 7)","78a88395":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit= StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state= 42)\nfor train_index, test_index in split.split(data, data[\"Ceil_LoM\"]):\n    strat_train= data.iloc[train_index]\n    strat_test= data.iloc[test_index]\n","3dc225b3":"#To know the proportion of each data point in the entire data set\ndata[\"Ceil_LoM\"].value_counts()\/ len(data)","c9387b23":"#To know the proportion of each data point in the training set\nstrat_train[\"Ceil_LoM\"].value_counts()\/ len(strat_train)","7d0929cd":"#To know the proportion of each data point in the test set\nstrat_test[\"Ceil_LoM\"].value_counts()\/ len(strat_test)","2b6ef36d":"for set in strat_train, strat_test:\n    set.drop([\"Ceil_LoM\"], axis= 1, inplace= True)","769f1543":"X= strat_train[['Avg. Session Length','Time on App','Time on Website','Length of Membership']]\n\ny= strat_train[\"Yearly Amount Spent\"]\n","f10f4371":"from sklearn.linear_model import LinearRegression\nlin_reg= LinearRegression()\nlin_reg.fit(X, y)\n\nlin_reg.coef_","e5423ebb":"from sklearn.model_selection import cross_val_score\nscores= cross_val_score(lin_reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_score= np.sqrt(-scores)\n\ndef display_scores(score):\n    print(\"Scores:\", score)\n    print(\"Mean:\", score.mean())\n    print(\"Standard Deviation:\",score.std())\ndisplay_scores(rmse_score)","674d2fa1":"X_test= strat_test[['Avg. Session Length','Time on App','Time on Website','Length of Membership']]\n\ny_test= strat_test[\"Yearly Amount Spent\"] \n\npredictions= lin_reg.predict(X_test)\n\nplt.scatter(y_test,predictions, )\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')","b8dd6c62":"from sklearn import metrics\n\nprint('MAE :',\" \", metrics.mean_absolute_error(y_test,predictions))\nprint('MSE :',\" \", metrics.mean_squared_error(y_test,predictions))\nprint('RMAE :',\" \", np.sqrt(metrics.mean_squared_error(y_test,predictions)))","30edf623":"# Plotting the histograms for each feature.\nTo see the dispersion of the data points over the plot","e2cd206c":"**Well, I got to say it works like charm. Now that we have got ourselves training set and test set, we must get rid of that extra column that we added**","7901dbe8":"**From the correlation matrix, We can see that the best predictor of Yearly Amount Spent is Length of Membership**\nNow, We can see the plot of a histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis). ","cf8916d9":"**Let's see if that worked it's charm**","02278489":"# **Evaluating our model**","0c259e1c":"**We can clearly see that there are more than 300 datapoints that lie between 3 and 5, so, while splitting our dataset into training and test set, it is possible that many instances are missed from value <3 and >5. That's why we have to use stratiefiedShuffleSplit so that, all the instances are well covered in same proportion in both training and test set.**","9022bb4a":"**We can clearly see that Yearly Amount Spent is linearly dependent on Length of Membership. So, We must include Length of Membership as a feature.**\nNow let's look at Length of Membership more closely. Inorder to do that let's take ceil of Length of Membership and add this new feature in the dataset.","699cfe19":"**Training a linear Regression Model**","101d3345":"**Now, Let's try our model in test set**","9e15a79b":"# Looking for Correlation ","42bf2bc3":"**Now that our Linear Regression Model is trained, we'll evaluate our model in cross-validatin set**","d598a305":"**Now that we have got ourselves a training and test set well proportionated, We have to separate our features and label**"}}