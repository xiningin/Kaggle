{"cell_type":{"3944605a":"code","00bbd480":"code","93aaea4e":"code","a0f83a0d":"code","7347ca4b":"code","904a20c2":"markdown"},"source":{"3944605a":"# ! pip install sqlalchemy\n# ! rm \/kaggle\/working\/sqlite3.db\n!pip install scipy==1.4.1","00bbd480":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport copy\nfrom PIL import Image\nimport pydicom\nimport scipy.ndimage\nimport imageio\nfrom os import listdir\nfrom sqlalchemy import create_engine\nimport sqlite3\nfrom tqdm import tqdm\nfrom torchvision import transforms\nimport torch\nimport random\nfrom torch.utils import data\nimport torchvision.models as models\nfrom torch.utils.data import Dataset\nimport pydicom as dicom\nimport time\nfrom sklearn.model_selection import train_test_split","93aaea4e":"path = \"..\/input\/rsna-str-pulmonary-embolism-detection\/train\/\"\ntrain = pd.read_csv(\"..\/input\/rsna-str-pulmonary-embolism-detection\/train.csv\")\ntrain=train[[\"StudyInstanceUID\",\"SeriesInstanceUID\",\"SOPInstanceUID\",\"pe_present_on_image\"]]\n# pbar = range(0,train.shape[0])\n\n# pbar = tqdm(pbar, dynamic_ncols=True, smoothing=0.01)\n# bad_rows=[]\n# for i in pbar:\n# #     try:\n#     ds=dicom.dcmread(path+train.iloc[i,0]+'\/'+train.iloc[i,1]+'\/'+train.iloc[i,2]+'.dcm')\n#     dcm_sample=ds.pixel_array\n# #     except Exception:\n# #         print()\n# #         bad_rows.append(i)\n# train=train.drop(bad_rows)\n        \nprint(train.head())\n\ntrain_dataset, test_dataset = train_test_split(train, test_size=0.25, random_state=42)\n\nclass myNet(torch.nn.Module):\n    def __init__(self):\n#         super(myNet, self).__init__()\n        super().__init__()\n\n#         model = torch.hub.load('pytorch\/vision:v0.6.0', 'inception_v3', pretrained=False)\n        model=models.inception_v3(pretrained=True)\n        self.model=model\n#         model = models.mobilenet_v2(pretrained=True)\n        print(model)\n    \n        self.inception_layer = torch.nn.Sequential(*list(model.children())[:])\n        print(self.inception_layer)\n#         print(list(self.inception_layer.children()))\n\n        self.Linear_layer = torch.nn.Linear(2048, 1)\n        self.logistic_layer=torch.nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.inception_layer(x)\n#         x=self.model(x)\n        x = self.Linear_layer(x)\n        x = self.logistic_layer(x)\n        \n        return x\n\n\n\npreprocess = transforms.Compose([\n    transforms.Resize(299),\n    transforms.CenterCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ndef transform_to_hu(image):\n    pixel_array=copy.deepcopy(image.pixel_array)\n    pixel_array = pixel_array.astype(np.int16)\n    pixel_array[pixel_array <= -1000] = 0\n\n    intercept = image.RescaleIntercept\n    slope = image.RescaleSlope\n        \n    if slope != 1:\n        pixel_array = slope * pixel_array.astype(np.float64)\n        pixel_array = pixel_array.astype(np.int16)\n            \n    pixel_array += np.int16(intercept)\n    return pixel_array\n\n\nclass PEDataset(Dataset):\n    def __init__(self, transform,pd):\n        self.transform = transform\n        self.df=pd\n        \n    def __len__(self):\n        return self.df.shape[0]\n    def _load_image_from_index(self, index):\n        ds=dicom.dcmread(path+self.df.iloc[index,0]+'\/'+self.df.iloc[index,1]+'\/'+self.df.iloc[index,2]+'.dcm')\n        pixel_array=transform_to_hu(ds)\n#         print(ds.RescaleIntercept)\n#         print(pixel_array)\n#         print(pixel_array.max())\n#         print(pixel_array.min())\n#         print(transform_to_hu(ds))\n#         print(transform_to_hu(ds).max())\n#         print(transform_to_hu(ds).min())\n#         plt.figure()\n#         plt.subplot(1,2,1)\n#         plt.imshow(pixel_array)\n#         plt.subplot(1,2,2)\n#         plt.imshow(transform_to_hu(ds))\n#         plt.show()\n        pixel_array=transform_to_hu(ds)\n\n        temp=Image.fromarray((255 * (pixel_array+0.0 - pixel_array.min()) \/ (pixel_array.max()+0.0 - pixel_array.min())).astype(np.uint8)).convert(\"RGB\")\n#         print(temp)\n#         plt.figure()\n#         plt.subplot(1,2,1)\n#         plt.imshow(temp)\n#         plt.subplot(1,2,2)\n#         plt.imshow(transform_to_hu(ds),cmap=\"Greys_r\")\n#         plt.show()\n        img=self.transform(temp)\n\n        return img,self.df.iloc[index,3]\n    def __getitem__(self, index):\n        try:\n            img,label = self._load_image_from_index(index)\n        except:\n            index=random.random()*self.__len__()\n            img,label = self.__getitem__(int(index))\n        \n\n        return img,label\n\ndef data_sampler(dataset, shuffle):\n    if shuffle:\n        return data.RandomSampler(dataset)\n    else:\n        return data.SequentialSampler(dataset)    \ndataloaders={}\ntrain_dataset=PEDataset(preprocess,train_dataset)\ntest_dataset=PEDataset(preprocess,test_dataset)\ntrain_loader= data.DataLoader(train_dataset,batch_size=16,sampler=data_sampler(train_dataset, shuffle=True),drop_last=True)\ntest_loader= data.DataLoader(test_dataset,batch_size=16,sampler=data_sampler(test_dataset, shuffle=True),drop_last=True)\n\ndataloaders[\"train\"]=train_loader\ndataloaders[\"val\"]=test_loader\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    print(\"begin trainning\")\n    since = time.time()\n\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n \n    for epoch in tqdm(range(num_epochs), dynamic_ncols=True, smoothing=0.01):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                print(inputs.size())\n                inputs = inputs.cuda()\n                labels = labels.cuda()\n\n                optimizer.zero_grad()\n\n\n                with torch.set_grad_enabled(phase == 'train'):\n\n                    if is_inception and phase == 'train':\n\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() \/ len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history\nmynet=myNet()\ncriterion = torch.nn.MSELoss(size_average=False)\noptimizer = torch.optim.SGD(mynet.parameters(), lr=0.01)\ncriterion = torch.nn.CrossEntropyLoss()\ntrain_model(mynet.cuda(), dataloaders, criterion, optimizer, num_epochs=25, is_inception=False)\n\n\n\n","a0f83a0d":"def load_scans(dcm_path):\n    # otherwise we sort by ImagePositionPatient (z-coordinate) or by SliceLocation\n    slices = [pydicom.dcmread(dcm_path + \"\/\" + file) for file in listdir(dcm_path)]\n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    return slices","7347ca4b":"listdir(\"..\/input\/\")\n\nbasepath = \"..\/input\/rsna-str-pulmonary-embolism-detection\/\"\nlistdir(basepath)\n\ntrain = pd.read_csv(basepath + \"train.csv\")\ntest = pd.read_csv(basepath + \"test.csv\")\ntrain.shape\n\n# train.head()\n\ntrain[\"dcm_path\"] = basepath + \"train\/\" + train.StudyInstanceUID + \"\/\" + train.SeriesInstanceUID \n\nexample = train.dcm_path.values[1]\nscans = load_scans(example)\nprint(scans)","904a20c2":"Loading scans per folder.\nStudyInstanceUID - unique ID for each study (exam) in the data.\nSeriesInstanceUID - unique ID for each series within the study.\nSOPInstanceUID - unique ID for each image within the study (and data)."}}