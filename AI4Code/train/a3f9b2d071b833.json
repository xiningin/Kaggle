{"cell_type":{"4d522698":"code","ece38f5e":"code","ce0ab18a":"code","38b50cb0":"code","5ff4f083":"code","04a27c74":"code","522a4ec9":"code","c3f9c188":"code","816b39c2":"code","80505369":"code","d87e0a31":"code","9797b120":"code","a3851e29":"code","1c9ddac0":"code","cff689f3":"code","eb7f6a32":"code","0390bcc0":"code","ff868d1d":"code","c9610788":"code","f5586192":"code","f7ac854d":"code","a73d7ea5":"code","b44a84ef":"code","19fd4940":"code","033f7a99":"code","098beb10":"markdown","b4bb4072":"markdown","04b370ea":"markdown","550d09b5":"markdown","41a5679f":"markdown","e76b92bb":"markdown"},"source":{"4d522698":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport gc\nfrom tqdm.auto import tqdm","ece38f5e":"### DATA CONFIG\n\ntargets = ['target1','target2','target3','target4']\nSPLIT = pd.to_datetime('2020-01-01')\nfeatures = ['have_game']\nidentifiers = ['playerId','date']\n\n### MODEL CONFIG\n\n","ce0ab18a":"def compute_metric(ground_truth,predicted):\n    ground_truth_sorted = ground_truth.sort_values(identifiers).reset_index(drop=True)\n    predicted_sorted = predicted.sort_values(identifiers).reset_index(drop=True)\n    metric = (ground_truth_sorted[targets]-predicted_sorted[targets]).abs().mean()\n    metric.loc['CV'] = metric.mean()\n    return metric\n\ndef pair_correlation(df1,df2):\n    correlation_dfs = pd.merge(df1,df2,on=identifiers).corr()\n    cols1 = [x for x in df1.columns if x in correlation_dfs.columns and x not in df2.columns]\n    cols2 = [x for x in df2.columns if x in correlation_dfs.columns and x not in df1.columns]\n    return correlation_dfs.loc[cols1,cols2]","38b50cb0":"engagements = pd.read_csv('..\/input\/mlb-train-processed-data\/nextDayPlayerEngagement.csv',index_col=0).rename({'engagementMetricsDate':'date'},axis=1)\nengagements['date'] = pd.to_datetime(engagements['date'])-pd.to_timedelta('1 days')\nplayer_box_scores = pd.read_csv('..\/input\/mlb-train-processed-data\/playerBoxScores.csv',index_col=0).rename(columns={'gameDate':'date'})\nplayer_box_scores['date'] = pd.to_datetime(player_box_scores['date'])\nplayer_box_scores['have_game'] = 1\nplayer_box_scores = player_box_scores.drop_duplicates(['playerId','date'],keep='first')\ndf = pd.merge(engagements,player_box_scores,on=['playerId','date'],how='left')\ndf['have_game'] = df['have_game'].fillna(0)\ndel player_box_scores,engagements\ngc.collect()","5ff4f083":"df.groupby('have_game')[targets].describe().T","04a27c74":"correlations = df.corr()[['target1','target2','target3','target4']]\ncorrelations['mean_corr'] = correlations.mean(axis=1)\ncorrelations.sort_values('mean_corr',ascending=False).head(30)","522a4ec9":"df[df.have_game==1].sample(3)","c3f9c188":"df[df.have_game==0].sample(3)","816b39c2":"## Train Targets\ntrain_targets = df.loc[df.date<SPLIT,identifiers+targets].reset_index(drop=True)\nval_targets = df.loc[df.date>=SPLIT,identifiers+targets].reset_index(drop=True)\nprint(train_targets.shape,val_targets.shape)\n\n## Train Features\ntrain_features = df.loc[df.date<SPLIT,identifiers+features].reset_index(drop=True)\nval_features = df.loc[df.date>=SPLIT,identifiers+features].reset_index(drop=True)\nprint(train_features.shape,val_features.shape)\n\n## Compute Aggregate Features From Train\naggregate = train_targets[train_features.have_game==0].groupby('playerId')[targets].median().reset_index()\naggregate.columns = ['agg_'+x if 'target' in x else x for x in aggregate.columns]\n\ntrain_features = pd.merge(train_features,aggregate,on='playerId')\nval_features = pd.merge(val_features,aggregate,on='playerId')\nprint(train_features.shape,val_features.shape)\nprint(train_features.date.min(),train_features.date.max(),val_features.date.min(),val_features.date.max())\ntrain_features.sample(3)","80505369":"pair_correlation(train_targets,train_features)","d87e0a31":"pair_correlation(val_targets,val_features)","9797b120":"selected_features = ['have_game','agg_target1', 'agg_target2', 'agg_target3', 'agg_target4']","a3851e29":"class Regressor():\n\n    def fit(self,X,y):\n        temp = pd.concat([X,y],axis=1)\n        temp.columns = ['have_game','_','target']\n        neg,pos = temp.groupby('have_game').target.median().values\n        self.offset = (pos - neg)\n        \n    def predict(self,X):\n        offset = X.values[:,0]*self.offset\n        return np.clip(X.values[:,1] + offset,0,100)","1c9ddac0":"%%time\n# from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\n# reg = RandomForestRegressor(n_estimators=100,max_depth=6, random_state=0,n_jobs=-1,verbose=1)\npredicted = train_targets.sort_values(identifiers).reset_index(drop=True)[identifiers]\ngt = train_targets.sort_values(identifiers).reset_index(drop=True)\nregs = {}\nfor target in targets:\n    selected_features = features + ['agg_'+target]\n#     reg = Ridge(alpha=1.0)\n    reg = Regressor()\n    X = train_features.sort_values(identifiers).reset_index(drop=True)[selected_features]\n    y = train_targets.sort_values(identifiers).reset_index(drop=True)[target]\n    reg.fit(X, y)\n    print(target,reg.offset)\n    predicted[target] = reg.predict(X)\n    regs[target] = reg\n# predicted = pd.DataFrame(predicted,columns=targets)\nprint(\"Train Metrics: \",compute_metric(gt,predicted).to_dict())","cff689f3":"pd.merge(predicted,train_features,on=identifiers).groupby('have_game')[targets].mean()","eb7f6a32":"pd.merge(train_targets,train_features,on=identifiers).groupby('have_game')[targets].mean()","0390bcc0":"predicted = val_targets.sort_values(identifiers).reset_index(drop=True)[identifiers]\nfor target in tqdm(targets):\n    selected_features = features + ['agg_'+target]\n    X = val_features.sort_values(identifiers).reset_index(drop=True)[selected_features]\n    predicted[target] = regs[target].predict(X)\nprint(val_targets.shape,predicted.shape)\nprint(\"Val Metrics: \",compute_metric(val_targets,predicted).to_dict())","ff868d1d":"pd.merge(predicted,val_features,on=identifiers).groupby('have_game')[targets].mean()","c9610788":"pd.merge(val_targets,val_features,on=identifiers).groupby('have_game')[targets].mean()","f5586192":"pd.concat([train_targets.groupby('playerId').median().mean(),predicted.mean(),val_targets.groupby('playerId').median().mean()],axis=1)","f7ac854d":"pd.concat([train_targets.mean(),predicted.mean(),val_targets.mean()],axis=1)","a73d7ea5":"%%time\n\n## Train Targets & Features\ntrain_targets = df[identifiers+targets].reset_index(drop=True)\ntrain_features = df[identifiers+features].reset_index(drop=True)\n\n## Compute Aggregate Features From Train\naggregate = train_targets.groupby('playerId')[targets].median().reset_index()\naggregate.columns = ['agg_'+x if 'target' in x else x for x in aggregate.columns]\ntrain_features = pd.merge(train_features,aggregate,on='playerId')\n\nprint(train_features.shape,train_targets.shape)\ntrain_features.sample(3)\n\npair_correlation(train_targets,train_features)","b44a84ef":"%%time\npredicted = train_targets.sort_values(identifiers).reset_index(drop=True)[identifiers]\ngt = train_targets.sort_values(identifiers).reset_index(drop=True)\nregs = {}\nfor target in tqdm(targets):\n    selected_features = features + ['agg_'+target]\n    X = train_features.sort_values(identifiers).reset_index(drop=True)[selected_features]\n    y = train_targets.sort_values(identifiers).reset_index(drop=True)[target]\n    reg.fit(X, y)\n    predicted[target] = reg.predict(X)\n    regs[target] = reg\nprint(\"Train Metrics: \",compute_metric(gt,predicted).to_dict())","19fd4940":"import json\nimport matplotlib.pyplot as plt\n","033f7a99":"import mlb\nfrom tqdm.auto import tqdm\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    template = sample_prediction_df[['date_playerId']].reset_index()\n    template['playerId'] = template.date_playerId.apply(lambda x:x.split('_')[1]).astype(int)\n    test_box_scores = test_df['playerBoxScores'].fillna('[]').apply(lambda x:json.loads(x))\n    test_box_scores = list(np.concatenate(test_box_scores.values))\n    test_box_scores = pd.DataFrame(test_box_scores).rename(columns={'gameDate':'date'})\n    test_box_scores['date'] = test_box_scores.date.apply(lambda x:x.replace('-','')).astype(int)\n    test_box_scores['have_game'] = 1\n    test_box_scores = test_box_scores.drop_duplicates(identifiers)\n    df = pd.merge(template,test_box_scores,on=identifiers,how='left')\n    df['have_game'] = df['have_game'].fillna(0)\n    test_features = df[identifiers+features+['date_playerId']].reset_index(drop=True)\n    test_features = pd.merge(test_features,aggregate,on='playerId').sort_values(identifiers).reset_index(drop=True)\n    predicted = pd.DataFrame(index=df.date)\n    for target in tqdm(targets):\n        selected_features = features + ['agg_'+target]\n        X = test_features[selected_features]\n        predicted[target] = regs[target].predict(X)\n\n    predicted['date_playerId'] = test_features['date_playerId'].values\n    predicted.index = df.date\n    print(predicted.shape,sample_prediction_df.shape)\n    assert predicted.shape==sample_prediction_df.shape\n    env.predict(predicted)","098beb10":"### Modelling","b4bb4072":"### Read Data","04b370ea":"### Config","550d09b5":"### Training For Test","41a5679f":"### Submitting","e76b92bb":"### Truncated Validation"}}