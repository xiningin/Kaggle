{"cell_type":{"547a8262":"code","af0959dd":"code","465de08c":"code","c205abb0":"code","915b5b3d":"code","e2403296":"code","35418a12":"code","6a50a857":"code","a91fbc9b":"code","18780cbc":"code","dbd9b9eb":"code","01383bfa":"code","6b7980d9":"code","407ee426":"code","4c9549ce":"code","145d1a62":"code","c2c1b9c9":"code","80898579":"code","2ef6a98a":"code","fe8b567d":"code","899c472f":"code","6c5d6c9c":"code","912b9bde":"code","5d6f9b1d":"code","39ab0cbf":"code","5ec7c13e":"code","12f20f07":"code","33b8fa5c":"markdown","fcb8b8ab":"markdown","a4f76f5d":"markdown","ad591a09":"markdown","5ce07f7e":"markdown","ad67d1e9":"markdown","c24be090":"markdown","df63943f":"markdown","ee0d89df":"markdown"},"source":{"547a8262":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","af0959dd":"print(os.listdir(\"..\/input\/flowers\"))","465de08c":"from skimage import io\nfrom scipy.misc import imread, imresize, imshow\nimport random\nimport glob\nimport matplotlib.pyplot as plt\n% matplotlib inline\n\npath = \"..\/input\/flowers\"\nflowers_classes = ['daisy', 'sunflower', 'tulip', 'rose', 'dandelion']","c205abb0":"# Lets visualize one random picture from each type of flower\n\nfor i, type in enumerate(flowers_classes):\n    flower_path = os.path.join(path, flowers_classes[i], '*')\n    flower_path = glob.glob(flower_path)\n    rand_index = random.randint(0, len(flower_path))\n    image = io.imread(flower_path[rand_index])\n    size = image.shape\n    plt.xlabel(type+\" size: \"+str(size[0])+\" \"+str(size[1]))\n    plt.imshow(image)\n    plt.show()","915b5b3d":"IMG_SIZE = 150   ## Image size\nX = [] \nY = []","e2403296":"## Number of image for each type\n\nfor idx, type in enumerate(flowers_classes):\n    flower_path = os.path.join(path, flowers_classes[idx], '*')\n    flower_path = glob.glob(flower_path)\n    for i in range(len(flower_path)):\n        try:\n            image = io.imread(flower_path[i])\n            image = imresize(image, (IMG_SIZE, IMG_SIZE))\n            X.append(image)\n            Y.append(type)\n        except:\n            print(flower_path[i])\n            continue","35418a12":"rand_index = random.randint(0, len(X))\nimage = X[rand_index]\nlabel = Y[rand_index] \nplt.imshow(image)\nplt.suptitle(label)","6a50a857":"# function to plot n images using subplots\ndef plot_image(images, captions=None, cmap=None ):\n    f, axes = plt.subplots(1, len(images), sharey=True)\n    f.set_figwidth(15)\n    for ax,image in zip(axes, images):\n        ax.imshow(image, cmap)","a91fbc9b":"# plotting the original image and the RGB channels\nf, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\nf.set_figwidth(15)\nax1.imshow(image)\n\n# RGB channels\nax2.imshow(image[:, : , 0])\nax3.imshow(image[:, : , 1])\nax4.imshow(image[:, : , 2])\nf.suptitle('Different Channels of Image')","18780cbc":"image_after_normalization = image\/255\n\nplot_image([image, image_after_normalization], cmap='gray')","dbd9b9eb":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\nle=LabelEncoder()\ny=le.fit_transform(Y)\ny=to_categorical(y,5)\n","01383bfa":"## Create train. validation and test samples from input.\nfrom sklearn.model_selection import train_test_split\nX = np.array(X)\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\n\n## Lets takeout some data from training data as validation data\nx_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.1,random_state=42)","6b7980d9":"print(x_train[0].shape)\nprint(y_train[0].shape)\nprint(x_val[0].shape)\nprint(y_val[0].shape)\nprint(x_test[0].shape)\nprint(y_test[0].shape)","407ee426":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras import optimizers\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.optimizers import Adam","4c9549ce":"# Define model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\n\n# softmax layer\nmodel.add(Dense(5, activation='softmax'))\n\n# model summary\nmodel.summary()","145d1a62":"from keras.optimizers import Adam\noptimiser = Adam()\nmodel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])","c2c1b9c9":"batch_size=32\nepochs=100","80898579":"from keras.preprocessing.image import ImageDataGenerator\n\n# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.4,\n    height_shift_range=0.4,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True\n)\n\n# Note that the validation data should not be augmented!\nval_datagen = ImageDataGenerator(\n    rescale=1.\/255\n)\n\n# Flow training images in batches of 32 using train_datagen generator\ntrain_generator = train_datagen.flow(\n    x_train,\n    y_train,\n    batch_size=batch_size\n)\n\nval_generator = val_datagen.flow(\n    x_val,\n    y_val,\n    batch_size=batch_size\n)","2ef6a98a":"model_name = 'model' + '\/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model.h5'\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, cooldown=1, verbose=1)\nES = EarlyStopping(monitor='val_loss', patience=5)\ncallbacks_list = [checkpoint, LR, ES]","fe8b567d":"model_hist = model.fit_generator(train_generator, steps_per_epoch=len(x_train)\/batch_size, epochs=epochs, verbose=1, \n                    callbacks=callbacks_list, validation_data=val_generator, \n                    validation_steps=len(x_val)\/batch_size, class_weight=None, workers=1, initial_epoch=0)","899c472f":"plt.plot(model_hist.history['loss'])\nplt.plot(model_hist.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","6c5d6c9c":"plt.plot(model_hist.history['categorical_accuracy'])\nplt.plot(model_hist.history['val_categorical_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","912b9bde":"# getting predictions on val set.\npred=model.predict(x_val)\npred_digits=np.argmax(pred,axis=1)","5d6f9b1d":"# now storing some properly as well as misclassified indexes'.\ni=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_val)):\n    if(np.argmax(y_val[i])==pred_digits[i]):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(y_val)):\n    if(not np.argmax(y_val[i])==pred_digits[i]):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break","39ab0cbf":"str(le.inverse_transform([np.argmax([y_val[prop_class[0]]])]))","5ec7c13e":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(x_val[prop_class[count]])\n        ax[i,j].set_title(\"Predicted Flower : \"+str(le.inverse_transform([pred_digits[prop_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax([y_val[prop_class[count]]])])))\n        plt.tight_layout()\n        count+=1","12f20f07":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(x_val[mis_class[count]])\n        ax[i,j].set_title(\"Predicted Flower : \"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax([y_val[mis_class[count]]])])))\n        plt.tight_layout()\n        count+=1","33b8fa5c":"Lets prepare input data for the network","fcb8b8ab":"Lets convert all images to a fixed size of 150 x 150 and also create training dataset by assigning labels to the images","a4f76f5d":"Lets analyse original image and its RGB channels ","ad591a09":"Lets visualize some of the images first","5ce07f7e":"Lets check a random image and its label","ad67d1e9":"We can see that there are 5 directories of 5 different types of flowers. Each directory consists of images of that type.","c24be090":"## Also print Misclassified Images:","df63943f":"**Normalization**","ee0d89df":"## Visualizing Predictons on the Validation Set"}}