{"cell_type":{"09a2a93e":"code","291fa42d":"code","da32c71e":"code","28192e8b":"code","2c70596f":"code","bd13eaeb":"code","d97eddca":"code","7d958ff3":"code","edad961c":"code","21b3e9ed":"code","14cc9ca5":"code","8d96ae7a":"code","6f086d35":"code","f31994af":"code","c88c36ba":"code","be93ee5c":"markdown","065d031e":"markdown","ad7aa3b8":"markdown","f61c5dd2":"markdown","3bd90c03":"markdown","6cefb571":"markdown","933e2498":"markdown","5fd7909a":"markdown","6b96f37e":"markdown","5fd1948e":"markdown","179c43ce":"markdown","74180149":"markdown","49b77a10":"markdown","1e06e4c2":"markdown","56ad5811":"markdown","6986dd0d":"markdown","0ffc19a5":"markdown"},"source":{"09a2a93e":"from sklearn.datasets import fetch_20newsgroups\n\ncategories = ['alt.atheism', 'soc.religion.christian', \n              'comp.graphics', 'sci.med']\ntwenty_train = fetch_20newsgroups(\n    subset='train',\n    categories=categories,\n    shuffle=True,\n    random_state=42,\n    remove=('headers', 'footers'),\n)\ntwenty_test = fetch_20newsgroups(\n    subset='test',\n    categories=categories,\n    shuffle=True,\n    random_state=42,\n    remove=('headers', 'footers'),\n)","291fa42d":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline, make_pipeline\n\nvec = TfidfVectorizer(min_df=3, stop_words='english', ngram_range=(1, 2))\nsvd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\nlsa = make_pipeline(vec, svd)\n\nclf = SVC(C=150, gamma=2e-2, probability=True)\npipe = make_pipeline(lsa, clf)\npipe.fit(twenty_train.data, twenty_train.target)\npipe.score(twenty_test.data, twenty_test.target)","da32c71e":"def print_prediction(doc):\n    y_pred = pipe.predict_proba([doc])[0]\n    for target, prob in zip(twenty_train.target_names, y_pred):\n        print(\"{:.3f} {}\".format(prob, target))    \n\ndoc = twenty_test.data[0]\nprint_prediction(doc)","28192e8b":"import eli5\nfrom eli5.lime import TextExplainer\n\nte = TextExplainer(random_state=42)\nte.fit(doc, pipe.predict_proba)\nte.show_prediction(target_names=twenty_train.target_names)","2c70596f":"import re\ndoc2 = re.sub(r'(recall|kidney|stones|medication|pain|tech)', '', doc, flags=re.I)\nprint_prediction(doc2)","bd13eaeb":"print(te.samples_[0])","d97eddca":"len(te.samples_)","7d958ff3":"te.metrics_","edad961c":"import numpy as np\n\ndef predict_proba_len(docs):\n    # nasty predict_proba - the result is based on document length,\n    # and also on a presence of \"medication\"\n    proba = [\n        [0, 0, 1.0, 0] if len(doc) % 2 or 'medication' in doc else [1.0, 0, 0, 0] \n        for doc in docs\n    ]\n    return np.array(proba)    \n\nte3 = TextExplainer().fit(doc, predict_proba_len)\nte3.show_prediction(target_names=twenty_train.target_names)","21b3e9ed":"te3.metrics_","14cc9ca5":"from sklearn.pipeline import make_union\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.base import TransformerMixin\n\nclass DocLength(TransformerMixin):\n    def fit(self, X, y=None):  # some boilerplate\n        return self\n    \n    def transform(self, X):\n        return [\n            # note that we needed both positive and negative \n            # feature - otherwise for linear model there won't \n            # be a feature to show in a half of the cases\n            [len(doc) % 2, not len(doc) % 2] \n            for doc in X\n        ]\n    \n    def get_feature_names(self):\n        return ['is_odd', 'is_even']\n\nvec = make_union(DocLength(), CountVectorizer(ngram_range=(1,2)))\nte4 = TextExplainer(vec=vec).fit(doc[:-1], predict_proba_len)\n\nprint(te4.metrics_)\nte4.explain_prediction(target_names=twenty_train.target_names)","8d96ae7a":"from sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.linear_model import SGDClassifier\n\nvec_char = HashingVectorizer(analyzer='char_wb', ngram_range=(4,5))\nclf_char = SGDClassifier(loss='log')\n\npipe_char = make_pipeline(vec_char, clf_char)\npipe_char.fit(twenty_train.data, twenty_train.target)\npipe_char.score(twenty_test.data, twenty_test.target)","6f086d35":"eli5.show_prediction(clf_char, doc, vec=vec_char,\n                    targets=['sci.med'], target_names=twenty_train.target_names)","f31994af":"te = TextExplainer(random_state=42).fit(doc, pipe_char.predict_proba)\nprint(te.metrics_)\nte.show_prediction(targets=['sci.med'], target_names=twenty_train.target_names)","c88c36ba":"te = TextExplainer(char_based=True, n_samples=50000, random_state=42)\nte.fit(doc, pipe_char.predict_proba)\nprint(te.metrics_)\nte.show_prediction(targets=['sci.med'], target_names=twenty_train.target_names)","be93ee5c":"This pipeline is supported by eli5 directly, so in practice there is no need to use `TextExplainer` for it. We're using this pipeline as an example - it is possible check the \"true\" explanation first, without using `TextExplainer`, and then compare the results with `TextExplainer` results.","065d031e":"## Let's make it fail, again\n\nAnother possible issue is the dataset generation method. Not only feature extraction should be powerful enough, but auto-generated texts also should be diverse enough. \n\n`TextExplainer` removes random words by default, so by default it can't e.g. provide a good explanation for a black-box classifier which works on character level. Let's try to use `TextExplainer` to explain a classifier which uses char ngrams as features:","ad7aa3b8":"`TextExplainer` correctly figured out that 'medication' is important, but failed to account for \"len(doc) % 2\" condition, so the explanation is incomplete. We can detect this failure by looking at metrics - they are low:","f61c5dd2":"`TextExplainer` produces a different result:","3bd90c03":"* 'mean_KL_divergence' is a mean [Kullback\u2013Leibler divergence] for all target classes; it is also weighted by distance. KL divergence shows how well are probabilities approximated; **0.0 means a perfect match.**\n\n* 'score' is an accuracy score weighted by cosine distance between generated sample and the original document (i.e. texts which are closer to the example are more important). Accuracy shows how good are 'top 1' predictions. \n\n\nIn this example both accuracy and KL divergence are good; it means our white-box classifier usually assigns the same labels as the black-box classifier on the dataset we generated, and its predicted probabilities are close to those predicted by our LSA+SVM pipeline. ","6cefb571":"## Let's make it fail","933e2498":"# TextExplainer: debugging black-box text classifiers\n\n## Example problem: 20 Newsgroups dataset\n\nLet's load **20 Newsgroups** dataset and create a text processing pipeline which is hard to debug using conventional methods: SVM with RBF kernel trained on Latent Semantic Analysis features.","5fd7909a":"It is getting closer, but still not there yet. The problem is that it is much more resource intensive - you need a lot more samples to get non-noisy results. Here explaining a single example took more time than training the original pipeline.\n","6b96f37e":"The Pipeline is pretty sure the first message in test data belongs to **sci.med**","5fd1948e":"By default `TextExplainer` generates 5000 distorted texts (use `n_samples` argument to change the amount):","179c43ce":"Much better! It was a toy example, but the idea stands - **if you think something could be important, add it to the mix as a feature for `TextExplainer`.**","74180149":"## Should we trust the explanation?\n\nCheck the quality on a held-out dataset (which is also generated). \n`TextExplainer` does that by default and stores metrics in `metrics_` attribute:","49b77a10":"If (a big if...) we suspect that the fact document length is even or odd is important, it is possible to customize `TextExplainer` to check this hypothesis. \n\nTo do that, we need to create a vectorizer which returns both \"is odd\" feature and bag-of-words features, and pass this vectorizer to `TextExplainer`. This vectorizer should follow scikit-learn API. The easiest way is to use `FeatureUnion` - just make sure all transformers joined by `FeatureUnion` have `get_feature_names()` methods.","1e06e4c2":"## TextExplainer\nLet's use `eli5.lime.TextExplainer` to debug the prediction - to check **what was important in the document** to make this decision.","56ad5811":"## Why it works\n\nA simple sanity check is to remove or change the highlighted words, to confirm that they change the outcome","6986dd0d":"Scores look OK but not great...\n\nChange both dataset generation method (change\/remove individual characters, not only words) and feature extraction method (Tip: use **char ngrams** instead of words and word ngrams).\n\n`TextExplainer` has an option (`char_based=True`) to use char-based sampling and char-based classifier. If this makes a more powerful explanation engine why not always use it?","0ffc19a5":"Predicted probabilities changed a lot indeed. \n\nThis approach follows the **LIME algorithm**"}}