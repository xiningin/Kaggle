{"cell_type":{"86f56edb":"code","a9adf60f":"code","0bdda491":"code","028589c3":"code","6c687c0d":"code","6ed353af":"code","d4b3e37b":"code","3c98ab30":"code","bbe670eb":"code","18951ef1":"code","4d8e1ac5":"code","8cfdf27f":"code","3bb8d79b":"code","65fe1db9":"code","dd6ac41b":"code","5c310860":"code","8db5bc66":"code","04242f0f":"code","2296516c":"code","b2ea96d4":"code","fe0b2bf9":"code","bb71fce1":"code","115c7667":"code","704bfa1f":"code","af0dbc58":"code","799faf11":"code","60c1adbf":"code","b4b5aeeb":"code","52a276fd":"code","a7806991":"code","56f9f29b":"code","4f8ea2e0":"code","f493d6ea":"code","8cf1245c":"code","3446f244":"code","c48891ec":"code","387409d8":"code","ee9808bc":"code","2c5a6c65":"code","22833e82":"code","d0b94ad4":"code","85a51394":"code","d3cc390a":"code","77401788":"code","6dff85e9":"code","b94b30d5":"code","e2834305":"code","4958262d":"code","9374e9f5":"code","df0411ed":"code","91707e4c":"code","3fbfd7a9":"code","7046e72d":"code","eae6d13b":"code","b65dd8e8":"code","999731fa":"code","35a66663":"code","85439af5":"code","dc0222d8":"code","bf3cff29":"code","9aa2ab87":"code","92540ea8":"code","2bd9aabf":"code","71e4230e":"code","6c75749a":"code","95199a17":"markdown","b3c5e282":"markdown","1a93edf6":"markdown","e5bb99cc":"markdown","58954d84":"markdown","0d6635cb":"markdown","3d5ef453":"markdown","2196a2d1":"markdown","aa04ce84":"markdown","7edc19ba":"markdown","a5442482":"markdown"},"source":{"86f56edb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9adf60f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport folium\nfrom folium.plugins import HeatMap\nimport matplotlib.pyplot as plt\nplt.ticklabel_format(useOffset=False)\n\n%matplotlib inline\nimport math\nfrom datetime import datetime\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.metrics import log_loss","0bdda491":"data = pd.read_csv('..\/input\/dft-accident-data\/Accidents0515.csv')\n","028589c3":"data.head()","6c687c0d":"data.shape","6ed353af":"data.head()","d4b3e37b":"data.describe()","3c98ab30":"data.info()","bbe670eb":"data.isnull()","18951ef1":"data.isnull().sum()","4d8e1ac5":"data[\"Road_Type\"].value_counts().sort_values().plot.bar()\n","8cfdf27f":"data[\"Weather_Conditions\"].value_counts().sort_values().plot.bar()","3bb8d79b":"fig_dims = (10, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = \"Road_Type\", y = \"Number_of_Casualties\", data = data, ax = ax)\nplt.ylabel(\"Number of Casualities\", fontsize = 30)\nplt.xlabel(\"Road Type\", fontsize = 30)\nplt.xticks(rotation = 45, fontsize = 15)","65fe1db9":"fig_dims = (10, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = \"Weather_Conditions\", y = \"Number_of_Casualties\", data = data, ax = ax)\nplt.ylabel(\"Number of Casualities\", fontsize = 30)\nplt.xlabel(\"Weather Conditions\", fontsize = 30)\nplt.xticks(rotation = 45, fontsize = 15)","dd6ac41b":"fig_dims = (10, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = \"Road_Type\", y = \"Accident_Severity\", data = data, ax = ax)\nplt.ylabel(\"Accident Severity\", fontsize = 30)\nplt.xlabel(\"Road Type\", fontsize = 30)\nplt.xticks(rotation = 45, fontsize = 15)","5c310860":"fig_dims = (10, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = \"Weather_Conditions\", y = \"Accident_Severity\", data = data, ax = ax)\nplt.ylabel(\"Accident Severity\", fontsize = 30)\nplt.xlabel(\"Weather Conditions\", fontsize = 30)\nplt.xticks(rotation = 45, fontsize = 15)","8db5bc66":"def full_date(row):\n    try:\n        newdate = datetime.strptime(row['Date'] + ' ' + str(row['Time']), '%d\/%m\/%Y %H:%M') \n    except:\n        row['Time'] = '00:00'\n        newdate = datetime.strptime(row['Date'] + ' ' + str(row['Time']), '%d\/%m\/%Y %H:%M')\n    return newdate","04242f0f":"data['FullDate'] = data.apply(lambda row: full_date(row),axis=1)\ndata['datetime'] = pd.to_datetime(data['FullDate'])","2296516c":"plt.figure(figsize=(10,10))\ndata['FullDate'].groupby(data['FullDate'].dt.hour).count().plot(kind=\"bar\")","b2ea96d4":"df = data.set_index('datetime')\ndf.drop(['Date'], axis=1, inplace=True)\n\ndf.head()\ndf_years = df['FullDate'].groupby([df.index.year,df.index.month,df.Accident_Severity]).count()\ndf_years = df_years.reset_index(level=0, inplace=False)\n\ndf_years = df_years.rename(index=str, columns={'datetime':\"year\"})\n\ndf_years = df_years.reset_index(level=0, inplace=False)\n\ndf_years = df_years.rename(index=str, columns={'datetime':\"month\"})","fe0b2bf9":"df_years = df_years.reset_index(level=0, inplace=False)\n","bb71fce1":"df_pivot = pd.pivot_table(df_years, index=['month'],columns=['Accident_Severity','year'], values=['FullDate'])\ndf_pivot","115c7667":"df_pivot['FullDate']['3'].plot(figsize=(10,10),title='Slight')\n","704bfa1f":"df_pivot['FullDate']['2'].plot(figsize=(10,10),title='serious')\n","af0dbc58":"df_pivot['FullDate']['1'].plot(figsize=(10,10),title='Fatal')\n","799faf11":"data.isnull().sum()","60c1adbf":"sns.heatmap(data.isnull(), yticklabels = False, cmap = \"viridis\")","b4b5aeeb":"datad = data.drop([\"Junction_Detail\", \"Junction_Control\", \"LSOA_of_Accident_Location\"], axis = 1 )","52a276fd":"datad.isnull().sum()","a7806991":"datad = datad.dropna()","56f9f29b":"datad.isnull().sum()","4f8ea2e0":"sns.heatmap(datad.isnull(), yticklabels = False, cmap = \"viridis\")","f493d6ea":"datad = data.iloc[0:1000]","8cf1245c":"location = datad['Latitude'].mean(), datad['Longitude'].mean()\nm = folium.Map(location=location,zoom_start=15)\nfor i in range(0,len(datad)):\n    folium.Marker([datad['Latitude'].iloc[i],datad['Longitude'].iloc[i]]).add_to(m)","3446f244":"m","c48891ec":"location = datad['Latitude'].mean(), datad['Longitude'].mean()\nm = folium.Map(location=location,zoom_start=15)\n\nfor i in range(0,len(datad)):\n       \n    popup = folium.Popup('Accident', parse_html=True) \n    folium.Marker([datad['Latitude'].iloc[i],datad['Longitude'].iloc[i]],popup=popup).add_to(m)\nm","387409d8":"datad['Number_of_Casualties'].value_counts()","ee9808bc":"location = datad['Latitude'].mean(), datad['Longitude'].mean()\nm = folium.Map(location=location,zoom_start=15)\n\n#The num of casulaties for each accident can be determined and the colour assigned then added to the basemap.\nfor i in range(0,len(datad)):\n    num_of_casualties = datad['Number_of_Casualties'].iloc[i]\n    if num_of_casualties == 1:\n        color = 'blue'\n    elif num_of_casualties == 2:\n        color = 'green'\n    else:\n        color = 'red'\n    \n    popup = folium.Popup('Accident', parse_html=True) \n    folium.Marker([datad['Latitude'].iloc[i],datad['Longitude'].iloc[i]],popup=popup,icon=folium.Icon(color=color, icon='info-sign')).add_to(m)\n\nm\n","2c5a6c65":"datad.head()","22833e82":"datad.drop([\"Carriageway_Hazards\", \"Date\", \"Day_of_Week\", \"2nd_Road_Number\"], axis =1, inplace = True)","d0b94ad4":"datad = datad.iloc[0:1000]","85a51394":"datad.shape","d3cc390a":"datag = pd.get_dummies(datad[[\"Road_Type\",\"Pedestrian_Crossing-Human_Control\", \"Pedestrian_Crossing-Physical_Facilities\", \"Light_Conditions\", \"Weather_Conditions\", \"Road_Surface_Conditions\"]], drop_first = True)","77401788":"datag","6dff85e9":"kaggle_data = pd.concat([datad, datag], axis = 1)","b94b30d5":"kaggle_data","e2834305":"kaggle_data.drop([\"Road_Type\",\"Pedestrian_Crossing-Human_Control\", \"Pedestrian_Crossing-Physical_Facilities\", \"Light_Conditions\", \"Weather_Conditions\", \"Road_Surface_Conditions\"], axis =1, inplace = True)","4958262d":"#kaggle_data.drop([\"Time\"], axis = 1, inplace  = True)\n#kaggle_data.drop([\"Local_Authority_(Highway)\"], axis = 1, inplace  = True)\n","9374e9f5":"kaggle_data.drop([\"Did_Police_Officer_Attend_Scene_of_Accident\"], axis = 1, inplace  = True)\n","df0411ed":"X = kaggle_data.drop(\"Accident_Severity\", axis =1)\ny = kaggle_data[\"Accident_Severity\"]","91707e4c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)","3fbfd7a9":"X_train.shape","7046e72d":"X_train.columns","eae6d13b":"X_train.columns","b65dd8e8":"X_train_ = X_train[['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude',\n       'Latitude', 'Police_Force', 'Number_of_Vehicles',\n       'Number_of_Casualties', '1st_Road_Class',\n       '1st_Road_Number', 'Speed_limit', 'Junction_Detail', 'Junction_Control',\n       '2nd_Road_Class', 'Urban_or_Rural_Area']]","999731fa":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 2, metric = 'euclidean')","35a66663":"knn.fit(X_train_, y_train)","85439af5":"X_test_ = X_test[['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude',\n       'Latitude', 'Police_Force', 'Number_of_Vehicles',\n       'Number_of_Casualties', '1st_Road_Class',\n       '1st_Road_Number', 'Speed_limit', 'Junction_Detail', 'Junction_Control',\n       '2nd_Road_Class', 'Urban_or_Rural_Area']]","dc0222d8":"y_pred = knn.predict(X_test_)","bf3cff29":"from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n","9aa2ab87":"print(classification_report(y_test, y_pred))","92540ea8":"confusion_matrix(y_test, y_pred)","2bd9aabf":"accuracy_score(y_test, y_pred)","71e4230e":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train_, y_train)\nY_pred = decision_tree.predict(X_test_)\nacc_decision_tree1 = round(decision_tree.score(X_test_, y_test) * 100, 2)\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=Y_pred)\nprint(\"Accuracy\", acc_decision_tree1)\nprint(sk_report)\n### Confusion Matrix \npd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","6c75749a":"random_forest = RandomForestClassifier(n_estimators=200)\nrandom_forest.fit(X_train_,y_train)\nY_pred = random_forest.predict(X_test_)\nrandom_forest.score(X_test_, y_test)\nacc_random_forest1 = round(random_forest.score(X_test_, y_test) * 100, 2)\n\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=Y_pred)\nprint(\"Accuracy\" , acc_random_forest1)\nprint(sk_report)\npd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","95199a17":"# To Perform Exploratory Data Analysis on the Data and to Predict the Severity of Accident\n# I will follow the following various steps given as \n# 1- Collecting Data        \n# 2- Analyzing Data\n# 3- Data Wrangling\n# 4- Train & Test\n# 5- Predict the Severity of Accident\n","b3c5e282":"# Train & Test","1a93edf6":"Now i will be doing the train, test and split","e5bb99cc":"Split the data into Training & Testing Data","58954d84":"Now i will do data wrangling by removing the NAN values and un necessary colummns from the data","0d6635cb":"# Random Forest","3d5ef453":"# Decision Tree","2196a2d1":"In the first step, i will import all the required libraries","aa04ce84":"# K- Nearest Neighbors Classifier","7edc19ba":"Loading the Datasets","a5442482":"# Data Wrangling"}}