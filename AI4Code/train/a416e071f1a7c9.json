{"cell_type":{"a75c268e":"code","ec169b17":"code","5cbd1589":"code","d93d992c":"code","5668cc98":"code","c106009a":"code","32fcba75":"code","bbc7de8d":"code","f10d60ae":"code","315f53b9":"code","f74a2553":"code","3bcb45dd":"code","1032492d":"code","ffafb6bc":"code","6ec49943":"markdown","563aa58e":"markdown","6aa603a4":"markdown"},"source":{"a75c268e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport scipy.stats as stats\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec169b17":"df = pd.read_csv(\"\/kaggle\/input\/heart-disease-dataset-uci\/HeartDiseaseTrain-Test.csv\")\ndf.head()","5cbd1589":"#Let's count all the NaN from the Df\ndf.isna().sum()","d93d992c":"#Data is complete so let's go and start showing some data\ncolumns_to_plot = ['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','slope','vessels_colored_by_flourosopy','thalassemia']\ndf_columns_plot = df[columns_to_plot]\nfor column in df_columns_plot.columns.values:\n    print(column)\n    v_counts = df_columns_plot[column].value_counts(normalize=True)\n    print(v_counts)\n    v_counts.plot.barh()\n    plt.show()","5668cc98":"df_with_target_as_letters = df\n#If Kaggle wouldn't show that target columns are only 0 and 1 I would check if data were corrupted\ndf_with_target_as_letters['target_letters'] = df_with_target_as_letters['target'].apply(lambda x: 'No heart disease' if x == 0 else 'Heart Disease')","c106009a":"#Let's do the same with target column\n#Data is complete so let's go and start showing some data\n#columns_to_plot = ['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','slope','vessels_colored_by_flourosopy','thalassemia']\ndf_columns_plot = df_with_target_as_letters[columns_to_plot]\nfor column in df_columns_plot.columns.values:\n    sns.countplot(data=df_columns_plot,x=df_with_target_as_letters[column],hue=df_with_target_as_letters['target_letters'])\n    plt.show()","32fcba75":"#Test_Shapiro-Wilk This is new for me. What I understood was that this test helps to know if data is normally\n#distributed\ncolumns_numbers = ['age','cholestoral','Max_heart_rate','resting_blood_pressure']\nfor column in columns_numbers:\n    stat , p_value = stats.shapiro(df[column])\n    if p_value > 0.05:\n        print(\"Normally distributed\")\n    else:\n        print(\"Not a normal distribution\")\n    sns.histplot(data=df, x=column,kde=True)\n    plt.show()","bbc7de8d":"sns.relplot(data=df_with_target_as_letters, x=\"resting_blood_pressure\", y=\"age\", hue=\"target_letters\", col=\"fasting_blood_sugar\",row = 'sex')\nplt.show()\nsns.relplot(data=df_with_target_as_letters, x=\"cholestoral\", y=\"age\", hue=\"target_letters\", col=\"rest_ecg\",row = 'sex')\nplt.show()","f10d60ae":"#Something interesting was found. Most Heart Deseases come when the fasting blood sugar is lower than 120 mg\/ml. And Females tend to have more heart problems in this conditions.\ndict_column_value = {\n    'fasting_blood_sugar':'Lower than 120 mg\/ml',\n    'rest_ecg':['ST-T wave abnormality','Normal']\n    \n}\n\ndef column_show_male_female_info(column,value):\n    df_key_val = df.loc[df[key] == value]\n    df_key_val_f = df_key_val.loc[df_key_val['sex'] == 'Female']\n    df_key_val_m = df_key_val.loc[df_key_val['sex'] == 'Male']\n    v_counts_f = df_key_val_f['target_letters'].value_counts(normalize=True)\n    v_counts_m = df_key_val_m['target_letters'].value_counts(normalize=True)\n    return v_counts_f,v_counts_m\n\nfor key in dict_column_value:\n    if isinstance(dict_column_value.get(key),list):\n        for value in dict_column_value.get(key):\n            print('column:',key,'value:',value)\n            v_counts_f,v_counts_m = column_show_male_female_info(key,value)\n            print('Female \\n',v_counts_f)\n            print('Male \\n',v_counts_m)\n    else:\n        print('column:',key,'value:',dict_column_value.get(key))\n        v_counts_f,v_counts_m = column_show_male_female_info(key,dict_column_value.get(key))\n        print('Female \\n',v_counts_f)\n        print('Male \\n',v_counts_m)\n        \n\n","315f53b9":"#Preparing data\ndel df[\"target_letters\"]\ny = df['target']\ndel df[\"target\"]\n#To transform data from Categories to numbers\nX = pd.get_dummies(df,columns=[\"sex\", \"chest_pain_type\",\"fasting_blood_sugar\",\"rest_ecg\",\"exercise_induced_angina\",\"slope\",\"vessels_colored_by_flourosopy\",\"thalassemia\"], prefix=[\"sex\", \"chest_pain\",\"fasting\",\"ecg\",\"angina\",\"slope\",\"vessels\",\"tha\"])","f74a2553":"#Let's dive in doing the ML model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix,plot_roc_curve,classification_report\n","3bcb45dd":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=2)","1032492d":"def check_model_results(model,X_train, X_test, y_train, y_test):\n    y_pred = model.fit(X_train, y_train).predict(X_test)\n    #Confussion Matrix on \n    print(confusion_matrix(y_test, y_pred))\n    # Accuracy\n    print(accuracy_score(y_test, y_pred))\n    # Recall\n    print(recall_score(y_test, y_pred, average=None))\n    # Precision\n    print(precision_score(y_test, y_pred, average=None))\n    print(classification_report(y_test,y_pred))\n    print(plot_roc_curve(model,X_test,y_test))\n    \n    ","ffafb6bc":"models =  {\n    'NaiveBayes':GaussianNB(),\n    'RandomForest':RandomForestClassifier(n_estimators = 110),\n    'SupportVectorMachine':SVC(),\n    'DecisionTree':DecisionTreeClassifier(),\n    'KNeighboors':KNeighborsClassifier(1)\n}\nfor key,model in models.items():\n    print(key)\n    check_model_results(model,X_train, X_test, y_train, y_test)","6ec49943":"# **Models Results**\n**These three models gave us more than 90% accuracy:**\n* KNeighboors\n* Decision Tree\n* Random Forest\n\n**I hugely appreciate if you tell me what would you do differently or what pieces of the process did I miss.**\n\n**Thanks!**","563aa58e":"# Comments before starting\n**Please this is my first ML model i a lot of time. Can you tell me what did I miss? Or what would you do differently**\n\n**Thanks!**","6aa603a4":"# **EDA(Exploratory data analysis)**\n**First things first let's dive in in the data and do the EDA(Exploratory data analysis). These are the steps we are going to perform**\n* Remove the empty or missing values\n* Remove outliers\n* Do some aggregations\n* Show the Mean,Meadian and Mode with the Std Deviation and variance (Just some columns)\n* Remove the columns that won't help our ML model"}}