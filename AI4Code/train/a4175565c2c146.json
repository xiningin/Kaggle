{"cell_type":{"008ef695":"code","76d161b9":"markdown"},"source":{"008ef695":"#!\/usr\/bin\/python3\n# coding=utf-8\n#===========================================================================\n# This is a minimal baseline script to perform a classification on the \n# kaggle 'Titanic' data set, using the keras deep learning library \n# Carl McBride Ellis (14.IV.2020)\n#===========================================================================\n#===========================================================================\n# load up the libraries\n#===========================================================================\nimport pandas  as pd\nfrom   keras.models import Sequential\nfrom   keras.layers import Dense             # i.e.fully connected\n\n#===========================================================================\n# read in the data\n#===========================================================================\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data  = pd.read_csv('..\/input\/titanic\/test.csv')\n\n#===========================================================================\n# select some features of interest (\"ay, there's the rub\", Shakespeare)\n#===========================================================================\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n\n#===========================================================================\n# for the features that are categorical we use pd.get_dummies:\n# \"Convert categorical variable into dummy\/indicator variables.\"\n#===========================================================================\nX_train       = pd.get_dummies(train_data[features])\ny_train       = train_data[\"Survived\"]\nfinal_X_test  = pd.get_dummies(test_data[features])\n\n#===========================================================================\n# parameters for keras\n#===========================================================================\ninput_dim   = len(X_train.columns) # number of neurons in the input layer\nn_neurons   = 50            # number of neurons in the first hidden layer\nepochs      = 100           # number of training cycles\n\n#===========================================================================\n# keras model\n#===========================================================================\nmodel = Sequential()         # a model consisting of successive layers\n# input layer\nmodel.add(Dense(n_neurons, input_dim=input_dim, activation='relu'))\n# output layer, with one neuron\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#===========================================================================\n# train the model\n#===========================================================================\nmodel.fit(X_train, y_train, epochs=epochs, verbose=0)\n\n#===========================================================================\n# use the trained model to predict 'Survived' for the test data\n#===========================================================================\npredictions = model.predict(final_X_test)\n# set a threshold of 50% for classification, i.e. >0.5 is True\n# Note: the '*1' converts the Boolean array into an array containing 0 or 1\npredictions = (predictions > 0.5)*1\n\n#===========================================================================\n# write out CSV submission file\n#===========================================================================\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.flatten()})\noutput.to_csv('submission.csv', index=False)","76d161b9":"This is a minimalist script for classification of the 'Titanic' data set using the keras deep learning library. It produces a score of around 0.77511 (i.e. 324 out of 418 are correctly classified), but this is not good, nor is it the point: the purpose of this script is to serve as a basic starting baseline from which you can launch your own feature engineering, model\/parameter tuning with a grid search, stratified k-fold cross validation, different activation functions, topology, etc etc.."}}