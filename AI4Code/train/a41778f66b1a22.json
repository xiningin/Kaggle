{"cell_type":{"d3c291b3":"code","582d7448":"code","c8de5268":"code","01322295":"code","68a580fe":"code","ca841bf4":"code","d36d35a1":"code","4614a86a":"code","916b9b59":"code","6dfa4337":"code","ecb09623":"code","b85272bd":"code","e5e976e1":"code","09fdd3c2":"code","781e8bdc":"code","c4a054e7":"code","e8afc4f0":"code","006c4e49":"code","991d2c74":"code","98cf33e9":"code","fdc5944c":"code","a7a697c1":"code","008451e7":"code","8e4fb9a8":"code","6046ddca":"code","26e939e6":"code","adb35c2b":"code","d655bcac":"code","69bb314c":"code","10cfa701":"code","5453321c":"code","705bd9c0":"code","550f6a85":"code","25eb57d1":"code","26da1985":"code","207a00eb":"code","a936e7ce":"markdown","0cb9fda6":"markdown","c9c44fdd":"markdown","e6f8998b":"markdown","f9082306":"markdown","5f9a93cd":"markdown","9ed2d19f":"markdown","6dfd1cd0":"markdown","01aed05f":"markdown","70141a0b":"markdown","34c803bf":"markdown","1e76aebd":"markdown","a3ecf669":"markdown","49d6b513":"markdown","f909126c":"markdown","4dc6ab7b":"markdown","97a30289":"markdown","dc66bc83":"markdown","1fc82b27":"markdown","35e35f6d":"markdown","60276fdd":"markdown","d7e27767":"markdown","8dd89faf":"markdown","34538080":"markdown","bffc4bda":"markdown","926bdf4c":"markdown","ebfd0793":"markdown","88af52df":"markdown","0dc4e9fd":"markdown","3839f5fd":"markdown","bd9202eb":"markdown"},"source":{"d3c291b3":"#\nimport numpy as np\nimport pandas as pd \nimport random\n\n# image\nfrom PIL import Image\n\n# visu\nimport matplotlib.pyplot as plt\n\n# folder\nimport os\nimport glob\n\n# sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n#tensorflow\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","582d7448":"categories = [\"dandelion\", \"daisy\", \"sunflower\", \"tulip\", \"rose\"]","c8de5268":"%%time\n#\nimages_shapes = {\"height\": [], \"width\": []}\n#\nfor cat in categories:\n    filelist = glob.glob('\/kaggle\/input\/flowers-recognition\/flowers\/' + cat + '\/*.jpg')\n    for fname in filelist:\n        images_shapes[\"height\"].append(np.array(Image.open(fname)).shape[0])\n        images_shapes[\"width\"].append(np.array(Image.open(fname)).shape[1])","01322295":"display(\"Average height: \" + str(int(np.mean(images_shapes[\"height\"]))))\ndisplay(\"Average width: \" + str(int(np.mean(images_shapes[\"width\"]))))","68a580fe":"im_width = int(338\/2)\nim_height = int(253\/2)","ca841bf4":"display(\"Used height: \" + str(im_height))\ndisplay(\"Used width: \" + str(im_width))","d36d35a1":"data = []\ntarget = []","4614a86a":"%%time\nfor cat in categories:\n    filelist = glob.glob('\/kaggle\/input\/flowers-recognition\/flowers\/' + cat + '\/*.jpg')\n    target.extend([cat for _ in filelist])\n    data.extend([np.array(Image.open(fname).resize((im_width, im_height))) for fname in filelist])\n#\ndata_array = np.stack(data, axis=0)","916b9b59":"data_array.shape","6dfa4337":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, data_array.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(target[num_image])\n        ax.imshow(data_array[num_image]);","ecb09623":"pd.DataFrame(target).value_counts()\/len(target)","b85272bd":"X_train, X_test, y_train, y_test = train_test_split(data_array, np.array(target), random_state=43, test_size=0.2, stratify=target)","e5e976e1":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","09fdd3c2":"pd.DataFrame(y_train).value_counts()\/len(y_train)","781e8bdc":"pd.DataFrame(y_test).value_counts()\/len(y_test)","c4a054e7":"print(X_train.max())\nprint(X_train.min())","e8afc4f0":"X_test_norm = np.round((X_test\/255), 3).copy()\nX_train_norm = np.round((X_train\/255), 3).copy()","006c4e49":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, X_train_norm.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(y_train[num_image])\n        ax.imshow(X_train_norm[num_image]);","991d2c74":"display(np.array(y_train).shape)\ndisplay(np.unique(y_train))\ndisplay(np.array(y_test).shape)\ndisplay(np.unique(y_test))","98cf33e9":"encoder = LabelEncoder().fit(y_train)","fdc5944c":"y_train_cat = encoder.transform(y_train)\ny_test_cat = encoder.transform(y_test)","a7a697c1":"y_train_oh = to_categorical(y_train_cat)\ny_test_oh = to_categorical(y_test_cat)","008451e7":"pd.DataFrame(y_test_oh).head()","8e4fb9a8":"def initialize_model():\n    model = Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(im_height, im_width, 3), padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(120, activation='relu'))\n    model.add(layers.Dense(60, activation='relu'))\n    model.add(layers.Dropout(rate=0.2))\n    model.add(layers.Dense(5, activation='softmax'))\n\n    return model","6046ddca":"model = initialize_model()\nmodel.summary()","26e939e6":"def compile_model(model):\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=\"accuracy\")\n    return model","adb35c2b":"model = initialize_model()\nmodel = compile_model(model)\nes = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n\n#model = initialize_model()\nhistory = model.fit(X_train_norm, y_train_oh,\n                    batch_size=16,\n                    epochs=1000,\n                    validation_split=0.3,\n                    callbacks=[es])","d655bcac":"def plot_history(history, title='', axs=None, exp_name=\"\"):\n    if axs is not None:\n        ax1, ax2 = axs\n    else:\n        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    if len(exp_name) > 0 and exp_name[0] != '_':\n        exp_name = '_' + exp_name\n    ax1.plot(history.history['loss'], label='train' + exp_name)\n    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n    ax1.set_ylim(0., 2.2)\n    ax1.set_title('loss')\n    ax1.legend()\n\n    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n    ax2.set_ylim(0.25, 1.)\n    ax2.set_title('Accuracy')\n    ax2.legend()\n    return (ax1, ax2)\n\nplot_history(history, title='', axs=None, exp_name=\"\");","69bb314c":"model.evaluate(X_test_norm, y_test_oh, verbose=0)","10cfa701":"datagen = ImageDataGenerator(featurewise_center=False,\n                             featurewise_std_normalization=False,\n                             rotation_range=10,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             zoom_range=(0.8, 1.2),) \n#\ndatagen.fit(X_train_norm)","5453321c":"X_augmented = datagen.flow(X_train_norm, shuffle=False, batch_size=1)\n\nfor i, (raw_image, augmented_image) in enumerate(zip(X_train_norm, X_augmented)):\n    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n    ax1.imshow(raw_image)\n    ax2.imshow(augmented_image[0])\n    plt.show()\n    \n    if i > 10:\n        break","705bd9c0":"X_train_aug, X_val, y_train_aug, y_val = train_test_split(X_train_norm, y_train_oh, random_state=43, test_size=0.2, stratify=y_train_oh)","550f6a85":"model_aug = initialize_model()\nmodel_aug = compile_model(model_aug)\ntrain_flow = datagen.flow(X_train_aug, y_train_aug, batch_size=16)\nes = EarlyStopping(patience=15, monitor='val_accuracy', restore_best_weights=True)\n\n#model = initialize_model()\nhistory_aug = model_aug.fit(train_flow,\n                            validation_data=(X_val, y_val),\n                            epochs=100,\n                            callbacks=[es])","25eb57d1":"plot_history(history_aug, title='', axs=None, exp_name=\"\");","26da1985":"model_aug.evaluate(X_test_norm, y_test_oh, verbose=0)","207a00eb":"axs = plot_history(history_aug, exp_name='data_augmentation')\nplot_history(history ,axs=axs, exp_name='baseline')\nplt.show()","a936e7ce":"We try to improve the model accuracy by using the data augmentation. It consists in applying little transformation to input images without changing its label.\n\nFor this, we use `ImageDataGenerator` from tensorflow. It will generate images a little bit different from an original image so that it will be like the algorithm is training on more data","0cb9fda6":"# 2. Loading image data","c9c44fdd":"We can check by random images that each of them have the same size:","e6f8998b":"Applying on both train and test set:","f9082306":"# 5. Convolutionnal neural network","5f9a93cd":"We obtain almost 10% more accuracy on unseen data compared to the initial model!","9ed2d19f":"## Target encoding","6dfd1cd0":"# 4. Preparing the data","01aed05f":"<b>We need to create a validation set from train set:<\/b>","70141a0b":"Now, let's define the Convolutional Neural Network. \n\nThe CNN that is composed of:\n- a Conv2D layer with 32 filters, a kernel size of (3, 3), the relu activation function, a padding equal to `same` and the correct `input_shape`\n- a MaxPooling2D layer with a pool size of (2, 2)\n- a Conv2D layer with 64 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to `same`\n- a MaxPooling2D layer with a pool size of (2, 2)\n- a Conv2D layer with 128 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to `same`\n- a MaxPooling2D layer with a pool size of (3, 3)\n- a Flatten layer\n- a dense function with 120 neurons with the `relu` activation function\n- a dense function with 60 neurons with the `relu` activation function\n- a dropout layer (with a rate of 0.5), to regularize the network\n- a dense function related to your task: multiclassification","34c803bf":"Here I set an early stopping after 5 epochs and set the parameter `restore_best_weights` to `True` so that the weights of best score on monitored metric - here `val_accuracy` (accuracy on test set) - are restored when training stops. This way the model has the best accuracy possible on unseen data.","1e76aebd":"# 1. Imports","a3ecf669":"Now images are loaded and resized with a width of 169, and a height of 126 and stored in the numpy array:","49d6b513":"Because of memory limitation in Kaggle, keeping 338 x 253 is not possible. Let's divide the height and width by two.","f909126c":"Here again, we can check the normalised pictures randomly:","4dc6ab7b":"Here after, we can look at the original image, and the same image after its small transformation:","97a30289":"Let's train the model with this improvment:","dc66bc83":"# 6. Results","1fc82b27":"<div style=\"display: block; height: 500px; overflow:hidden;position: relative; padding-bottom:50px\">\n     <img src=\"https:\/\/imgur.com\/VF9rSJb.jpg\" style=\"position: absolute;top: 0px;border-radius: 20px; \">\n<\/div>","35e35f6d":"As indicated in the instructions, we use the random seed 43 and a test set size of 20% of the dataset. Moreover, we use the parameter `stratify`set to `target` so that the class repartition is maintained","60276fdd":"Here we convert targets. First, from string to numerical values, each category becoming an integer, from 0 to 4 (as there are five different flower categories):","d7e27767":"And now, we convert the result to one-hot encoded target so that they can be used to train a classification neural network. We use `to_categorical` from tensorflow library:","8dd89faf":"## Normalization\nTo ease the convergence of the algorithm, it is usefull to normalize the data. See here what are the maximum and minimum values in the data, and normalize it accordingly (the resulting image intensities should be between 0 and 1).","34538080":"# 3. Train test split","bffc4bda":"So we have 4317 tensor images of width 169 and height 126, each pixel being defined by three colors R, G, B:","926bdf4c":"# 7. Data augmentation","ebfd0793":"<b>Thank you for reading \ud83d\ude42<\/b> <br>if you have any remarks about the content of this notebook, if there are some mistakes or if you have suggestions for improvment, please feel free to comment","88af52df":"Fitting the encoder on train set:","0dc4e9fd":"There are five flower categories. The images are loaded in a numpy array as matrix and associated categories are loaded in an independent array.","3839f5fd":"We resize images so they all have the same width and height. We select the width as the mean width of all images and the height as the mean height of all images.","bd9202eb":"So we have an accuracy on unseen data of almost 70%."}}