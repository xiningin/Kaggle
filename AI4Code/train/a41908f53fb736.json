{"cell_type":{"50e64851":"code","8ea5ff3a":"code","f5b8a561":"code","08a252e8":"code","cf3aa8e2":"code","dfd358b3":"code","567c2baf":"code","5cfa57bd":"code","70495187":"code","cda695eb":"code","781e6c0d":"code","2e272834":"code","e727b392":"code","6a5efc78":"code","3647a922":"code","390a1ffe":"code","81d92235":"code","897a7232":"code","29630866":"code","92db0217":"code","29ed891c":"code","ae4f0cb7":"code","fbd48524":"code","3d7b10ec":"code","09fc7625":"code","75fe078a":"code","85aeedb6":"code","cfe7f850":"code","82687f3e":"code","f86cd830":"code","6393ef6c":"code","a5a87980":"code","69d7d722":"code","bac28801":"code","ff3a05a5":"code","e24127ec":"code","9e5dde94":"code","bc1ec4e3":"code","a6356773":"code","3af4231d":"code","14dce077":"code","d44cc82b":"code","faeacb08":"code","ed729d9d":"code","3f8bdb16":"code","ad765f1b":"code","77083607":"code","ab251a20":"code","677879f8":"code","f116043d":"code","dd9266a4":"code","365d91f1":"code","12be9576":"code","54b09be4":"code","e2b3a92a":"code","46dd7d16":"code","eb5ea75f":"code","31d88710":"markdown","9dde376f":"markdown","73cac0de":"markdown","73586e41":"markdown","57d8707b":"markdown","fd2cda78":"markdown","4c9174ab":"markdown","17df70f7":"markdown","2d57e470":"markdown","1cc06703":"markdown","07566501":"markdown","aa89404e":"markdown","449abb2e":"markdown","67d49890":"markdown","5d115b31":"markdown","977d08f9":"markdown","d0142e91":"markdown","40df001b":"markdown","8794119b":"markdown"},"source":{"50e64851":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ea5ff3a":"# libraries\nimport numpy as np \nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow .keras.models import Sequential \nfrom tensorflow .keras.layers import Flatten,Dropout, Dense\n\nfrom keras.preprocessing.image import  load_img,img_to_array\n\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport os","f5b8a561":"path = '..\/input\/lego-minifigures-classification\/'\njurassic_world_path = \"jurassic-world\/\"","08a252e8":"img = load_img(path+jurassic_world_path + \"0001\/001.jpg\")\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","cf3aa8e2":"x=img_to_array(img)\nprint(x.shape)","dfd358b3":"index_df = pd.read_csv('..\/input\/lego-minifigures-classification\/index.csv')\nindex_df.drop('Unnamed: 0', axis=1, inplace=True)\nindex_df.head(2)","567c2baf":"meta_df = pd.read_csv(path+'metadata.csv')\nmeta_df.head(2)","5cfa57bd":"data_df = pd.merge(index_df, meta_df[['class_id', 'minifigure_name']], on='class_id')\ndata_df.head(2)","70495187":"sample_df=data_df.sample(20)\nsample_df.head(5)","cda695eb":"plt.figure(figsize=(10,10))\ni=0\nfor i in range(20):\n    plt.subplot(4,5,i+1)\n    plt.grid(False)\n    img=load_img('..\/input\/lego-minifigures-classification\/'+sample_df['path'].values[i])\n    plt.imshow(img)\n    #plt.axis(\"off\")\n    plt.xlabel(sample_df['minifigure_name'].values[i])\n    i += 1\nplt.show()","781e6c0d":"data_df.info()","2e272834":"data_df.isnull().sum()","e727b392":"import plotly.graph_objects as go\ndf_minifigure_name=data_df['minifigure_name'].value_counts().to_frame().reset_index().rename(columns={'index':'minifigure_name','minifigure_name':'Count'})\n\nfig = go.Figure(go.Bar(\n    x=df_minifigure_name['minifigure_name'],y=df_minifigure_name['Count'],\n    marker={'color': df_minifigure_name['Count'], \n    'colorscale': 'agsunset'},  \n    text=df_minifigure_name['Count'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Minifigure Count',xaxis_title=\"Minifigure Name\",yaxis_title=\"Count\",title_x=0.5)\nfig.show()","6a5efc78":"# Training and Validation Dataframe \n\ntrain_set = data_df[data_df[\"train-valid\"] == 'train']\n\nvalidation_set = data_df[data_df[\"train-valid\"] == 'valid']","3647a922":"import cv2\n\n#We converted the pixels of the image data to array\n\n# Training Data Preprocessing\n\ntrain_Data = np.zeros((train_set.shape[0], 512, 512, 3))\n\nfor i in range(train_set.shape[0]):\n    \n    image = cv2.imread('..\/input\/lego-minifigures-classification\/' + train_set[\"path\"].values[i])\n    \n    #Converting BGR to RGB \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    #Resizing image to (512 x 512)\n    image = cv2.resize(image, (512,512))\n    \n    #Normalizing pixel values to [0,1]\n    train_Data[i] = image \/ 255.0\n\ntrainLabel = np.array(train_set[\"class_id\"])-1","390a1ffe":"#Validation Data Preprocessing\n\nvalid_Data = np.zeros((validation_set.shape[0], 512, 512, 3))\n\nfor i in range(validation_set.shape[0]):\n    \n    image = cv2.imread('..\/input\/lego-minifigures-classification\/' + validation_set[\"path\"].values[i])\n    \n    #Converting BGR to RGB \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    #Resizing image to (512 x 512)\n    image = cv2.resize(image, (512,512))\n    \n    #Normalizing pixel values to [0,1]\n    valid_Data[i] = image \/ 255.0\n\nvalidLabel = np.array(validation_set[\"class_id\"])-1","81d92235":"print('Train Label: ',trainLabel.shape)\nprint('Train Data: ',train_Data.shape)\nprint('Valid Data: ',valid_Data.shape)\nprint('Valid Label: ',validLabel.shape)","897a7232":"from tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\ndense_net = tf.keras.applications.DenseNet121()","29630866":"dense_net_layer=Dropout(0.5)(dense_net.layers[-2].output)\nnumber_of_classes = len(data_df['class_id'].unique())","92db0217":"last_layer = Dense(number_of_classes, activation=\"softmax\")(dense_net_layer)\nmodel = Model(dense_net.input, last_layer)","29ed891c":"model.compile(loss='sparse_categorical_crossentropy',\n              optimizer=Adam(0.0001),\n              metrics=['accuracy'])","ae4f0cb7":"print(model.summary())","fbd48524":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(filepath='model.h5', monitor=\"val_accuracy\", save_best_only=True, verbose=1)","3d7b10ec":"hist=model.fit(\n    train_Data, \n    trainLabel, \n    epochs=50, \n    validation_data=(valid_Data, validLabel), \n    shuffle=True, \n    batch_size=4, \n    callbacks=checkpoint\n)","09fc7625":"print(hist.history.keys())\nplt.plot(hist.history[\"loss\"], label = \"Train Loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()\n","75fe078a":"from tensorflow.keras import models as tf_models\n# Load the best model (we create for checkpoint to save the best model)\nmodel = tf_models.load_model('model.h5')","85aeedb6":"sample_df=data_df.sample(40)\n\nfrom sklearn.model_selection import train_test_split\n\ntest, _ = train_test_split(sample_df, test_size=0.5)","cfe7f850":"test","82687f3e":"for i in range(20):\n    \n    image = cv2.imread('..\/input\/lego-minifigures-classification\/'+test['path'].values[i])\n    image = cv2.resize(image, dsize=(512,512))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\/255\n    plt.imshow(image)\n    plt.xlabel(test['minifigure_name'].values[i]+'--'+str(test['class_id'].values[i]))\n    image = np.reshape(image, (1, 512, 512, 3))\n    ans = model.predict(image).argmax()\n    ans = ans+1\n    minifigure = meta_df[\"minifigure_name\"][meta_df[\"class_id\"] == ans].iloc[0]\n    print(\"Class:\", str(ans)+ \" Minifigure:\",minifigure)\n    plt.show()","f86cd830":"from keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims\nfrom matplotlib import pyplot\nfrom keras.preprocessing import image","6393ef6c":"img = load_img('..\/input\/lego-minifigures-classification\/marvel\/0004\/008.jpg')\n\ndata = img_to_array(img)\nsamples = expand_dims(data, 0)\ndatagen = ImageDataGenerator(rotation_range=120)\nit = datagen.flow(samples, batch_size=1)\nfor i in range(9):\n    pyplot.subplot(330 + 1 + i)\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    pyplot.imshow(image)\npyplot.show()","a5a87980":"train_set.info()","69d7d722":"test_df=train_set.copy()\ntest_df=test_df.sample(5)\ntest_df.head()\nindexs=test_df.index\nfor i in indexs:\n    train_set.drop(i, axis = 0,inplace = True)\n","bac28801":"test_df","ff3a05a5":"train_set.info()","e24127ec":"batch= 15\nsize= 256\nEpoch= 100","9e5dde94":"train_datagen = ImageDataGenerator(rescale=1.0\/255,\n                                   rotation_range=20,\n                                   width_shift_range=0.4, \n                                   height_shift_range=0.4,\n                                   fill_mode=\"nearest\",\n                                   zoom_range=0.4,\n                                   vertical_flip=True,\n                                   horizontal_flip=True,\n                                   brightness_range=[0.2,1.0])\nvalid_datagen = ImageDataGenerator(rescale=1.0\/255)","bc1ec4e3":"train_generator = train_datagen.flow_from_dataframe(dataframe=train_set, directory=path,\n                                                   x_col='path', y_col='minifigure_name', batch_size= batch,\n                                                   shuffle=True, target_size=(size,size))\nvalid_generator = valid_datagen.flow_from_dataframe(dataframe=validation_set, directory=path,\n                                                   x_col='path', y_col='minifigure_name', batch_size= batch,\n                                                   shuffle=False, target_size=(size,size))","a6356773":"from tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\ndense_net = tf.keras.applications.DenseNet121()","3af4231d":"\ndense_net_layer=Dropout(0.5)(dense_net.layers[-2].output)\nnumber_of_classes = len(data_df['class_id'].unique())-1","14dce077":"last_layer = Dense(number_of_classes, activation=\"softmax\")(dense_net_layer)\nmodel1 = Model(dense_net.input, last_layer)","d44cc82b":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel1.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])","faeacb08":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(filepath='model1.h5', monitor=\"val_accuracy\", save_best_only=True, verbose=1)","ed729d9d":"hist1 = model1.fit_generator(train_generator,\n                            epochs=Epoch,\n                            validation_data=valid_generator,\n                            callbacks=checkpoint)","3f8bdb16":"print(hist1.history.keys())\nplt.plot(hist1.history[\"loss\"], label = \"Train Loss\")\nplt.plot(hist1.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.plot(hist1.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist1.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()\n","ad765f1b":"test_df","77083607":"test_datagen = ImageDataGenerator(rescale=1.0\/255)\ntest_generator = test_datagen.flow_from_dataframe(dataframe=test_df, directory=path, x_col='path', y_col='minifigure_name', batch_size= 1,\n                                 shuffle=False, target_size=(size,size))","ab251a20":"model1.evaluate_generator(generator=valid_generator)","677879f8":"test_generator.reset()\npred=model1.predict_generator(test_generator,verbose=1)","f116043d":"predicted_classes=np.argmax(pred,axis=1)","dd9266a4":"predicted_classes","365d91f1":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_classes]","12be9576":"labels","54b09be4":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"path\":filenames,\n                      \"Predictions\":predictions})","e2b3a92a":"results","46dd7d16":"final_result = pd.merge(test_df[['minifigure_name','path']], results[['path', 'Predictions']], on='path')\nfinal_result","eb5ea75f":"for i in range(5):\n    \n    image = cv2.imread('..\/input\/lego-minifigures-classification\/'+final_result['path'].values[i])\n    image = cv2.resize(image, dsize=(512,512))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\/255\n    plt.imshow(image)\n    plt.xlabel(final_result['minifigure_name'].values[i]+'****'+final_result['Predictions'].values[i])\n    plt.show()","31d88710":"## <a id='3'>3. Data Preprocessing<\/a>","9dde376f":" # <a id='2'> 2.Data Analysis And  Visualization<\/a>\n\n","73cac0de":"## <a id='7'> <font color=\"LIGHTSEAGREEN\" size=+2.5><b>End Note<\/b><\/font> <\/a>\n\nI hope you enjoyed my kernel.If you like this notebook, an Upvote would be great ! :)\n\nI am new with data science. Please comments me your feedbacks to help me improve myself.\n\nThanks for your time","73586e41":"##  Sample Data \u0130mages ","57d8707b":"## <a id='9'> 9.Testing New Model And Visualization <\/a>","fd2cda78":"## <a id='6'> 6.Conclusion <\/a>\n\n* We do not have enough pictures.\n\n* My model is Overfitting.\n\n* We need more pictures","4c9174ab":"## <a id='17'> <font size=\"+2\" color=\"LIGHTSEAGREEN\"><b>Reference<\/b><\/font><br>\n* https:\/\/keras.io\/api\/\n* https:\/\/stackoverflow.com (for coding problems)\n* Other LEGO Minifigures kaggle nootbooks","17df70f7":"## Test Pictures","2d57e470":"## <a id='7'> 7.More Pictures <\/a>","1cc06703":"<font size=\"+2\" color=\"LIGHTSEAGREEN\"><b>My Other Kernels<\/b><\/font><br>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/book-review-ratings-data-analysis-visualization\" class=\"btn btn-primary\" style=\"color:white;\">Book Review Ratings Analysis & Visualization<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/insurance-prediction-lgbm-gbm-xgboost-eda\" class=\"btn btn-primary\" style=\"color:white;\">Insurance Prediction- LGBM,GBM,XGBoost EDA<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/fish-market-data-visualisation-machine-learning\" class=\"btn btn-primary\" style=\"color:white;\">Fish Market Data Visualisation & Machine Learning<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/seabron-plotly-for-beginners\" class=\"btn btn-primary\" style=\"color:white;\">Seabron & Plotly For Beginners<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/basketball-players-stats-data-visualisation\" class=\"btn btn-primary\" style=\"color:white;\">Basketball Players Stats Data Visualisation<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/women-s-football-results-visualization\" class=\"btn btn-primary\" style=\"color:white;\">Women's Football Results Visualization<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/us-police-shootings-data-visualisation\" class=\"btn btn-primary\" style=\"color:white;\">Us Police Shootings Data Visualisation<\/a>\n\n\n\n","07566501":"## Merging Data","aa89404e":"## Convert \u0130mages","449abb2e":"## Training and Validation Dataframe ","67d49890":"## <a id='8'> 8.New Model <\/a>","5d115b31":"## <a id='5'> 5.Testing Model And  Visualization<\/a>","977d08f9":"## <a id='4'>4. Transfer  DenseNet121 Model<\/a>","d0142e91":"# <a id='0'> Dataset Introduction <\/a>\n\nThis dataset contains a lot of pictures of various LEGO Minifigures.\nThere are several images in different poses or with different environments for each Minifigure in the dataset. You can use this dataset for the image classification tasks or try to create more interesting things. We have provided a label for each image: 'train' or 'valid'. You can use such data splitting or come up with your own.\n\n![](https:\/\/media.giphy.com\/media\/VeBeB9rR524RW\/giphy.gif)","40df001b":"# <a id='1'> 1. Importing Libraries and Dataset<\/a>","8794119b":"# Table of contents\n- <a href='#0'>  Dataset Introduction <\/a> \n- <a href='#1'>1. Importing Libraries and Dataset <\/a> \n- <a href='#2'>2. Data Analysis And  Visualization<\/a> \n- <a  href='#3'>3.Data Preprocessing <\/a> \n- <a href='#4'>4. Transfer DenseNet121 Model  <\/a> \n- <a href='#5'>5. Testing Model And Visualization <\/a>\n- <a href='#6'>6. Conclusion <\/a>\n- <a href='#7'>7.More Pictures <\/a>\n- <a href='#8'>8.New Model <\/a>\n- <a href='#9'>9.Testing New Model And Visualization <\/a>"}}