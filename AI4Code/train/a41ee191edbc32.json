{"cell_type":{"fa349ba4":"code","5ed6755b":"code","888ad546":"code","53567bd7":"code","740017ff":"code","3e424262":"code","4daafecb":"code","deb3feae":"code","354f9d85":"code","c33a1f8e":"code","68306360":"code","a0802b10":"code","2f5ee91b":"code","c88233ae":"code","48c9af96":"code","f88b2687":"code","5bdd6650":"code","85e29163":"code","2df52876":"code","790f3c89":"code","ef9aa703":"code","9b7fc449":"code","c3a37e02":"code","15c0dcd0":"code","48a98e5b":"code","9f707cd8":"code","7b92163f":"code","148dc275":"code","90b939c6":"code","641c38e2":"code","92ff4707":"markdown","94299038":"markdown","40a28a5b":"markdown","36ffeb4e":"markdown","c13ef27f":"markdown","ea9942e9":"markdown","710930d7":"markdown","12b36d38":"markdown"},"source":{"fa349ba4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ed6755b":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv', dtype = np.float32)\n\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv', dtype = np.float32)","888ad546":"sample = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsample","53567bd7":"import torch ","740017ff":"     \nfrom torch.autograd import Variable     \nimport torch.nn as nn \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib as plt\n\nfrom torch.utils.data import DataLoader\n","3e424262":"from sklearn.model_selection import train_test_split","4daafecb":"train","deb3feae":"\n\ntargets_numpy = train.label.values\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values\/255\n\nfeatures_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n                                                                             targets_numpy,\n                                                                             test_size = 0.2,\n                                                                             random_state = 42)\n\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)\n\nbatch_size = 100\nn_iters = 10000\nnum_epochs = n_iters \/ (len(features_train) \/ batch_size)\nnum_epochs = int(num_epochs)\n\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n","354f9d85":"class LeNet5(torch.nn.Module):\n    def __init__(self):\n\n        super(LeNet5, self).__init__()\n        \n        self.conv1 = torch.nn.Conv2d(\n            in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.act1  = torch.nn.Tanh()\n        self.pool1 = torch.nn.AvgPool2d(kernel_size=2)\n       \n        self.conv2 = torch.nn.Conv2d(\n            in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.act2  = torch.nn.Tanh()\n        self.pool2 = torch.nn.AvgPool2d(kernel_size=2)\n        \n        self.fc1   = torch.nn.Linear(32 * 4 * 4, 120)\n        self.act3  = torch.nn.Tanh()\n        \n        self.fc2   = torch.nn.Linear(120, 84)\n        self.act4  = torch.nn.Tanh()\n        \n        self.fc3   = torch.nn.Linear(84, 10)\n        \n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.act1(x)\n        x = self.pool1(x)\n        \n        x = self.conv2(x)\n        x = self.act2(x)\n        x = self.pool2(x)\n        \n        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n\n        x = self.fc1(x)\n        x = self.act3(x)\n        x = self.fc2(x)\n        x = self.act4(x)\n        x = self.fc3(x)\n        \n        return x\n\nlenet5 = LeNet5()","c33a1f8e":"batch_size = 100\nn_iters = 2500\nnum_epochs = n_iters \/ (len(features_train) \/ batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n    \n# Create CNN\nmodel = LeNet5()\n\n# Cross Entropy Loss \nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n","68306360":"count = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(100,1,28,28))\n        labels = Variable(labels)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        # Calculate softmax and ross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Iterate through test dataset\n            for images, labels in test_loader:\n                \n                test = Variable(images.view(100,1,28,28))\n                \n                # Forward propagation\n                outputs = model(test)\n                \n                # Get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # Total number of labels\n                total += len(labels)\n                \n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        if count % 500 == 0:\n            # Print Loss\n            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))","a0802b10":"import matplotlib.pyplot as plt\n\nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"LeNet: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"LeNet: Accuracy vs Number of iteration\")\nplt.show()","2f5ee91b":"class AlexNet(nn.Module):\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        \n        # Convolution 1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        # Max pool 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n     \n        # Convolution 2\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        # Max pool 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        \n        # Fully connected 1\n        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n    \n    def forward(self, x):\n        # Convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        # Max pool 1\n        out = self.maxpool1(out)\n        \n        # Convolution 2 \n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # Max pool 2 \n        out = self.maxpool2(out)\n        \n        # flatten\n        out = out.view(out.size(0), -1)\n\n        # Linear function (readout)\n        out = self.fc1(out)\n        \n        return out\n\n# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 2500\nnum_epochs = n_iters \/ (len(features_train) \/ batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n    \n# Create CNN\nmodel = AlexNet()\n\n# Cross Entropy Loss \nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)","c88233ae":"count = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(100,1,28,28))\n        labels = Variable(labels)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        # Calculate softmax and ross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Iterate through test dataset\n            for images, labels in test_loader:\n                \n                test = Variable(images.view(100,1,28,28))\n                \n                # Forward propagation\n                outputs = model(test)\n                \n                # Get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # Total number of labels\n                total += len(labels)\n                \n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        if count % 500 == 0:\n            # Print Loss\n            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))","48c9af96":"import matplotlib.pyplot as plt\n\nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"AlexNet: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"AlexNet: Accuracy vs Number of iteration\")\nplt.show()","f88b2687":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","5bdd6650":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv', dtype = np.float32)\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv', dtype = np.float32)","85e29163":"X_train = train.iloc[:, 1:]\nY_train = train.iloc[:, 0]\n\nX_train = np.array(X_train)\nY_train = np.array(Y_train)\n\nX_train = X_train \/ 255.0\n\nX_dev, X_val, Y_dev, Y_val = train_test_split(X_train, Y_train, test_size=0.03, shuffle=True, random_state=2019)\nT_dev = pd.get_dummies(Y_dev).values\nT_val = pd.get_dummies(Y_val).values\n\nX_dev = X_dev.reshape(X_dev.shape[0], 28, 28, 1)\nX_val = X_val.reshape(X_val.shape[0], 28, 28, 1)","2df52876":"data_generator = ImageDataGenerator(\n    rotation_range=10, \n            width_shift_range=0.1, \n            height_shift_range=0.1, \n            zoom_range=0.1   \n)\n\ndata_generator.fit(X_dev)","790f3c89":"from keras.layers import Input, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout, MaxPool2D, Flatten \nfrom keras.layers.merge import add\nfrom keras.activations import relu, softmax\nfrom keras.models import Model\nfrom keras import regularizers\nimport matplotlib.pyplot as plt","ef9aa703":"tf.debugging.set_log_device_placement(True)","9b7fc449":"with tf.device('\/CPU:0'):\n    model = tf.keras.Sequential()\n\n    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n    model.add(MaxPool2D(pool_size = (2,2), strides=None))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same',strides=(1, 1), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same',strides=(1, 1), activation='relu'))\n    model.add(MaxPool2D(pool_size = (2,2), strides=None))\n    model.add(Dropout(0.1))\n\n    #model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same',strides=(1, 1), activation='relu'))\n    #model.add(MaxPool2D(pool_size = (2,2), strides=None))\n    #model.add(Dropout(0.1))\n\n    model.add(Flatten())\n\n    model.add(BatchNormalization())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.1))\n\n    model.add(Dense(10, activation='softmax'))\n\n\n    adam = tf.keras.optimizers.Adam(lr=5e-4)\n    model.compile(\n        optimizer=adam, loss = 'sparse_categorical_crossentropy', \n        metrics = ['sparse_categorical_accuracy']\n    )\n\n    model.summary()","c3a37e02":"from keras.callbacks import ReduceLROnPlateau","15c0dcd0":"reduce_lr = ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', \n                                patience=3, \n                                verbose=1, \n                                factor=0.2, \n                                min_lr=1e-5)","48a98e5b":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","9f707cd8":"history = model.fit_generator(data_generator.flow(X_dev,Y_dev, batch_size=100), steps_per_epoch=len(X_dev)\/100, \n                    epochs=30, validation_data=(X_val, Y_val), callbacks=[reduce_lr]\n                   )","7b92163f":"fig, ax = plt.subplots(2,1, figsize=(15,15))\n\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['sparse_categorical_accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_sparse_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","148dc275":"X_test = test\n\nX_test = np.array(X_test)\n\nX_test = X_test \/ 255.0\n\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","90b939c6":"y_test = model.predict(X_test)\ny_test = np.argmax(y_test, axis=1)\n\nsub_out = sample\nsub_out['Label'] = y_test\nsub_out.head()","641c38e2":"sub_out.to_csv('out.csv', index=False)","92ff4707":"# AlexNet with Pytorch\n\nAlexNet is a pretty powerful architecture for image recognition, so I could not help but use it.","94299038":"# Anti-overfitting\n\nIn the model, I initially laid several layers that eject part of the neurons from the network. This is a good trick for fighting overfitting, but it's far from the only one.\n\nSo I used a callback, that reduces learning rate when a metric has stopped improving.","40a28a5b":"# Create model!\n\nWhen creating this fairly simple model, I relied on the AlexNet architecture.","36ffeb4e":"The following part for Pytorch was created according to [this lovely notebook](https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers)!","c13ef27f":"# LeNet5 with Pytorch","ea9942e9":"Cool! Our metrics for validation are always higher than those for training data, which means that our model does not overfit on training data.","710930d7":"# Keras time\n\nI love keras very much, and I really regret that my training in the field of neural networks did not start with this library.","12b36d38":"# Data augmentation\n\nData augmentation is a really important part of data preprocessing. In fact, this leads to a wide variety of data already completely known to us, which we are trying to complicate at the expense of various proto-formations, such as rotations by a certain number of degrees, an increase, and so on.\n"}}