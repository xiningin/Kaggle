{"cell_type":{"1cc1575a":"code","2e471923":"code","8eb17bb7":"code","fab86d75":"code","d05efa3a":"code","3a2fc98b":"code","afe9989b":"markdown","e54dcb2d":"markdown","7d8ab8ac":"markdown","8bdcabcc":"markdown","714d91c4":"markdown","c8b0a69c":"markdown","b5f02c43":"markdown","c9439ab4":"markdown","9dc3f7c9":"markdown","a6d8ac93":"markdown","e7120947":"markdown"},"source":{"1cc1575a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","2e471923":"#!!!!\n\n!pip install pycm\nfrom pycm import *\nfrom pycm import ConfusionMatrix\nimport statistics \nimport time\nfrom sklearn import metrics\n","8eb17bb7":"def multiClassStat(model, X_test, y_test, y_pred):\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    print('accuracy ', accuracy)\n    precision = metrics.precision_score(y_test, y_pred, average='macro')\n    print(\"precision \", precision)\n    y_prob = model.predict_proba(X_test)\n    try:\n        roc_auc = metrics.roc_auc_score(y_test, y_prob, average='macro', multi_class='ovr')\n    except ValueError as inst:\n        print(inst)\n    print(\"roc_auc \", roc_auc)\n    conf_mat = metrics.multilabel_confusion_matrix(y_test, y_pred)\n    TPR = 0\n    FPR = 0\n    for i in conf_mat:\n        TN = i[0][0]\n        FP = i[0][1]\n        FN = i[1][0]\n        TP = i[1][1]\n        print(TP)\n        TPR += 0 if (TP + FN) == 0 else TP \/ (TP + FN)\n        FPR += 0 if (FP + TN) == 0 else FP \/ (FP + TN)\n    TPR \/= len(conf_mat)\n    FPR \/= len(conf_mat)\n    print('TPR ', TPR)\n    print('FPR ', FPR)\n    PR_curve = 0\n    #for each class\n    for i,cls in zip(range(len(model.classes_)),model.classes_):\n        y_test_ = list(map(int, [num == cls for num in y_test]))\n        print(i)\n        print(cls)\n        print(y_test_)\n        precision_, recall_, thresholds = metrics.precision_recall_curve(y_test_, y_prob[:, i])\n        print(\"pr_curve \", metrics.auc(recall_, precision_))\n        PR_curve += metrics.auc(recall_, precision_)\n    print(len(y_prob[0]))\n    PR_curve \/= len(y_prob[0])\n    print(PR_curve)\n    return accuracy, TPR, FPR, precision, roc_auc, PR_curve\n\ndef binaryStat(model, X_test, y_test, y_pred):\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    precision = metrics.precision_score(y_test, y_pred)\n    print('precision , ', precision)\n    y_prob = model.predict_proba(X_test)\n    try:\n        roc_auc = metrics.roc_auc_score(y_test, y_prob[:, 1])\n    except ValueError as inst:\n        print(inst)\n        roc_auc = None\n    conf_mat = metrics.confusion_matrix(y_test, y_pred)\n    TN = conf_mat[0][0]\n    FP = conf_mat[0][1]\n    FN = conf_mat[1][0]\n    TP = conf_mat[1][1]\n    TPR = 0 if (TP + FN) == 0 else TP \/ (TP + FN)\n    FPR = 0 if (FP + TN) == 0 else FP \/ (FP + TN)\n    _precision, _recall, thresholds = metrics.precision_recall_curve(y_test, y_prob[:,1], )\n    PR_curve = metrics.auc(_recall, _precision)\n\n    return accuracy, TPR, FPR, precision, roc_auc, PR_curve\n\n\n","fab86d75":"\n\nmodel_params = {\n    \"algorithm\":[\"SAMME\"],\n    \"base_estimator__criterion\": [\"gini\", \"entropy\"],\n    \"learning_rate\": [0.1,0.5,0.8,1,1.5,3],\n    \"n_estimators\": [300,500,1000],\n    \"base_estimator__min_samples_split\": [1,3,5,10,50],\n    \"base_estimator__min_samples_leaf\": [1,3,5,10,50]\n    }\n\ndirname = \"\/kaggle\/input\/classification-datasets\/classification_datasets\"\ndf_redults = pd.DataFrame(columns=['dataset_name', 'algorithm_name', 'cross_validation', 'hyper_params',\n                          'accuracy', 'TPR', 'FPR', 'precision', 'roc_auc', 'PR_curve', 'training_time',\n                          'inference_time'])\n\n\n\n\ndf_redults.to_csv('results.csv')\nfor filename in os.listdir(dirname)[100:]: #withou lupus dataset\n \n    \n    print()\n    print(filename)\n    data = pd.read_csv(dirname+'\/'+filename)\n    print(data.dtypes)\n    data_count_target = data[data.columns[-1]].value_counts()\n    # remove classes with less than 10 lines\n    cls_count=0\n    dropped=False\n    for cls, cnt in data_count_target.iteritems():\n        cls_count += 1\n        if cnt < 10:\n            data = data[data[data.columns[-1]] != cls]\n            cls_count -= 1\n            dropped=True\n    if cls_count < 2:\n        print(\"dropping file:  \", filename)\n        continue\n    # convert to 0 1 labels\n    if cls_count==2 and dropped:\n        max_val = data[data.columns[-1]].value_counts().index[0]\n        data[data.columns[-1]] = data[data.columns[-1]].apply(lambda x: 0 if x == max_val else 1)\n    # strings- convert using  LabelEncoder\n    for i in data.columns:\n        if data[i].dtype == np.string_:\n            is_string_type=True\n        else:\n            is_string_type=False\n        \n        if is_string_type:\n            print(i)\n            enc = LabelEncoder()\n            data[i] = enc.fit_transform(data[i].astype(str))\n    data.fillna(0, inplace=True)\n    print(data)\n    \n    X = data.iloc[:,:-1]\n    y = data.iloc[:,-1]\n  \n    #####\n    #####\n    ######\n\n\n    #label encoder from categorial to int categories\n    le = preprocessing.LabelEncoder()\n    y =le.fit_transform(y.values.reshape(-1, 1))\n    y=pd.DataFrame(y)\n    \n    for column_name in X.columns:\n        if X[column_name].dtype == object:\n            X[column_name] = le.fit_transform(X[column_name])\n        else:\n            pass\n\n\n    \n    skf = StratifiedKFold(n_splits=10)\n    fold=0\n    \n    for train_index, test_index in skf.split(X, y):\n        fold+=1\n        print('fold: ',fold)\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        bdt_real_ = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=10,learning_rate=0.5)\n        best_params,result,rs_model = hyperparameter_tune(bdt_real_, model_params, 50, 3, X_train, y_train)\n        rs_model.fit(X_train, y_train)\n        \n\n        #optimal_model = RandomizedSearchCV(bdt_real_,\n        #                param_distributions=model_params,\n        #                n_iter=50,\n        #                cv=3,\n        #                n_jobs=-1,\n        #                random_state=43)\n        \n        optimal_model.fit(X_train,y_train)\n        #bdt_real=optimal_model\n        \n        #** \n        \n        start = time.time()\n        bdt_real.fit(X_train, y_train)\n        training_time = time.time() - start\n        start = time.time()\n        y_pred = bdt_real.predict(X_test)\n        inference_time = (time.time() - start) \/ len(X_test) # single inference time\n        inference_time *= 1000 # 1000 lines\n        \n        #######\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        if len(y_test[0].unique()) == 2:\n            \n            accuracy, TPR, FPR, precision, roc_auc, PR_curve = binaryStat(bdt_real, X_test, y_test, y_pred)\n        else:\n            accuracy, TPR, FPR, precision, roc_auc, PR_curve = multiClassStat(bdt_real, X_test, y_test, y_pred)\n        df_redults = df_redults.append({'dataset_name': filename , 'algorithm_name':'GradientBoosting',\n                                        'cross_validation': fold, 'hyper_params': rs_model.best_params_,\n                                        'accuracy': accuracy, 'TPR': TPR, 'FPR': FPR, 'precision': precision,\n                                        'roc_auc':roc_auc, 'PR_curve':PR_curve, 'training_time':training_time,\n                                        'inference_time':inference_time}, ignore_index=True)\n        print( rs_model.best_params_, accuracy, TPR, FPR, precision, roc_auc, PR_curve,\n              training_time, inference_time)\n    df_redults.to_csv('results.csv', mode='a', header=False)\n\n  ","d05efa3a":"\n#Online Multi-Class LPBoost\n\n\n#https:\/\/github.com\/amirsaffari\/online-multiclass-lpboost\n","3a2fc98b":"\n\n#Tianshi Gao, Daphne Koller, Multiclass Boosting with Hinge Loss based on Output Coding (ICML 2011)\n\n\n#https:\/\/github.com\/mlapin\/libsdca","afe9989b":"dirname = \"\/kaggle\/input\/classification-datasets\/classification_datasets\"\ndf_redults = pd.DataFrame(columns=['dataset_name', 'algorithm_name', 'cross_validation', 'hyper_params',\n                          'accuracy', 'TPR', 'FPR', 'precision', 'roc_auc', 'PR_curve', 'training_time',\n                          'inference_time'])\n\nfor filename in os.listdir(dirname+'\/'):\n    print (dirname+'\/'+filename)\n    \n    data = pd.read_csv(dirname+'\/'+filename)\n    print(filename)\n    \n    \n    train_csv = data\n\n    seed=100\n    train, validation = train_test_split(train_csv, test_size=0.3,random_state=seed) \n\n    train_X, train_y = train.iloc[:,:-1],train.iloc[:,-1]\n\n    test_X, test_y = validation.iloc[:,:-1],validation.iloc[:,-1]\n    \n    best_params, best_score, optimal_model = hyperparameter_tune(base_model, parameters, 5, 5, train_X, train_y)\n    \n    \n    \n    start_time = time.time()\n    prediction=optimal_model.predict(test_X)\n    #print(prediction)\n\n\n    ####\n\n    scores_accuracy = cross_val_score(bdt_real, test_X, test_y, cv=10, scoring=\"accuracy\")\n    #scores_accuracy = cross_val_score(bdt_real, X, y, cv=10, scoring=\"AUC\")\n\n\n    bdt_real.set_params(**optimal_model.best_params_)\n    start = time.time()\n    bdt_real.fit(train_X, train_y)\n    training_time = time.time() - start\n    start = time.time()\n    y_pred = bdt_real.predict(test_X)\n    inference_time = (time.time() - start) \/ len(test_X) # single inference time\n    inference_time *= 1000 # 1000 lines\n\n    y_true = test_y.tolist()\n    y_prediction = prediction.tolist()\n    print(len(y_true))\n    print(len(y_prediction))\n    \n    cm = ConfusionMatrix(actual_vector=y_true,predict_vector=y_prediction)\n\n    # based on https:\/\/www.pycm.ir\/doc\/#NPV-(Negative-predictive-value)\n\n    print(\"Accuracy\")\n    #print(cm.ACC)\n    ACC=statistics.mean(cm.ACC.values())\n    print(ACC)\n\n    print(\"Precision\")\n    precision = metrics.precision_score(test_y, y_pred)\n    print(precision)\n    \n    print(\"TPR\")\n    #print(cm.TPR)\n    TPR=statistics.mean(cm.TPR.values())\n    print(TPR)\n\n    print(\"FPR\")\n    #print(cm.FPR)\n    FPR=statistics.mean(cm.FPR.values())\n    print(FPR)\n\n\n    print(\"AUC\")\n    #print(cm.AUC)\n    AUC=statistics.mean(cm.AUC.values())\n    print(AUC)\n\n    print(\"AUPR\")\n    #print(cm.AUPR)\n    AUPR=statistics.mean(cm.AUPR.values())\n    print(AUPR)\n\n    print(\"RUNNING TUME\")\n    print(training_time)\n\n    print(\"Inference time \")\n    print(inference_time)\n\n\n    df_redults = df_redults.append({'dataset_name': filename , 'algorithm_name':'',\n                                    'cross_validation': fold, 'hyper_params': bdt_real.best_params,\n                                    'accuracy': ACC, 'TPR': TPR, 'FPR': FPR, 'precision': precision,\n                                    'roc_auc':roc_auc, 'PR_curve':PR_curve, 'training_time':training_time,\n                                    'inference_time':inference_time}, ignore_index=True)\n    print( rs_model.best_params_, accuracy, TPR, FPR, precision, roc_auc, PR_curve,training_time, inference_time)\n    df_redults.to_csv('results.csv', mode='a', header=False)\n    break\n\n\n\n\n","e54dcb2d":"import sklearn\nimport sklearn.model_selection\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\nimport time\nimport warnings\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n\nbdt_real = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=2),\n    n_estimators=600,\n    learning_rate=1)\n\nbdt_real.fit(train_X, train_y)\n\n\"\"\"\nscores_methods={\"accuracy\",\"precision\",\"recall\"}\n\nfor element in scores_methods:\n    print (element)\n    scores = cross_val_score(bdt_real, X, y, cv=10, scoring=element)\n    scores.mean(), scores.std()\n\n\nprint(sklearn.metrics.SCORERS.keys())\n\"\"\"\n","7d8ab8ac":"* # 1. Multi-class AdaBoosted Decision Trees\n","8bdcabcc":"# based on https:\/\/www.pycm.ir\/doc\/#NPV-(Negative-predictive-value)\n\nprint(\"Accuracy\")\nprint(cm.ACC)\nprint(\"***\")\nprint(statistics.mean(cm.ACC.values()))\nprint()\n\nprint(\"TPR\")\nprint(cm.TPR)\nprint(\"***\")\nprint(statistics.mean(cm.TPR.values()))\nprint()\n\nprint(\"FPR\")\nprint(cm.FPR)\nprint(\"***\")\nprint(statistics.mean(cm.FPR.values()))\nprint()\n\n\nprint(\"AUC\")\nprint(cm.AUC)\nprint(\"***\")\nprint(statistics.mean(cm.AUC.values()))\nprint()\n\nprint(\"AUPR\")\nprint(cm.AUPR)\nprint(\"***\")\nprint(statistics.mean(cm.AUPR.values()))\nprint()\n\nprint(\"RUNNING TUME\")\nprint(training_time)\nprint()\n\nprint(\"Inference time \")\nprint(inference_time)\nprint()\n\n\n\n\n","714d91c4":"#\n# License: BSD 3 clause\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_gaussian_quantiles\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nX, y = train_X, train_y\n\n\nbdt_real = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=2),\n    n_estimators=600,\n    learning_rate=1)\n\nbdt_discrete = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=2),\n    n_estimators=600,\n    learning_rate=1.5,\n    algorithm=\"SAMME\")\n\nbdt_real.fit(X, y)\nbdt_discrete.fit(X, y)\n\n\n\n\nreal_test_errors = []\ndiscrete_test_errors = []\n\nfor real_test_predict, discrete_train_predict in zip(\n        bdt_real.staged_predict(test_X), bdt_discrete.staged_predict(test_X)):\n    real_test_errors.append(\n        1. - accuracy_score(real_test_predict, test_y))\n    discrete_test_errors.append(\n        1. - accuracy_score(discrete_train_predict, test_y))\n\nn_trees_discrete = len(bdt_discrete)\nn_trees_real = len(bdt_real)\n\n# Boosting might terminate early, but the following arrays are always\n# n_estimators long. We crop them to the actual number of trees here:\ndiscrete_estimator_errors = bdt_discrete.estimator_errors_[:n_trees_discrete]\nreal_estimator_errors = bdt_real.estimator_errors_[:n_trees_real]\ndiscrete_estimator_weights = bdt_discrete.estimator_weights_[:n_trees_discrete]\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(131)\nplt.plot(range(1, n_trees_discrete + 1),\n         discrete_test_errors, c='black', label='SAMME')\n\nplt.plot(range(1, n_trees_real + 1),\n         real_test_errors, c='black',\n         linestyle='dashed', label='SAMME.R')\nplt.legend()\nplt.ylim(0.0, 1)\nplt.ylabel('Test Error')\nplt.xlabel('Number of Trees')\n\nplt.subplot(132)\nplt.plot(range(1, n_trees_discrete + 1), discrete_estimator_errors,\n         \"b\", label='SAMME', alpha=.5)\nplt.plot(range(1, n_trees_real + 1), real_estimator_errors,\n         \"r\", label='SAMME.R', alpha=.5)\nplt.legend()\nplt.ylabel('Error')\nplt.xlabel('Number of Trees')\nplt.ylim((.2,\n         max(real_estimator_errors.max(),\n             discrete_estimator_errors.max()) * 1.2))\nplt.xlim((-20, len(bdt_discrete) + 20))\n\nplt.subplot(133)\nplt.plot(range(1, n_trees_discrete + 1), discrete_estimator_weights,\n         \"b\", label='SAMME')\nplt.legend()\nplt.ylabel('Weight')\nplt.xlabel('Number of Trees')\nplt.ylim((0, discrete_estimator_weights.max() * 1.2))\nplt.xlim((-20, n_trees_discrete + 20))\n\n# prevent overlapping y-axis labels\nplt.subplots_adjust(wspace=0.25)\nplt.show()\n\n","c8b0a69c":"combined with chen - work\n","b5f02c43":"irrelevant","c9439ab4":"#!!!!\n#\n# License: BSD 3 clause\n\nimport matplotlib.pyplot as plt\nimport sklearn\nimport sklearn.model_selection\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\nimport time\nimport warnings\nfrom sklearn.datasets import make_gaussian_quantiles\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nimport time\n\n\n\n\ndef hyperparameter_tune(base_model, parameters, n_iter, kfold, X, y):\n    start_time = time.time()\n    \n    # Arrange data into folds with approx equal proportion of classes within each fold\n    k = StratifiedKFold(n_splits=kfold, shuffle=False)\n    \n    optimal_model = RandomizedSearchCV(base_model,\n                            param_distributions=parameters,\n                            n_iter=n_iter,\n                            cv=k,\n                            n_jobs=-1,\n                            random_state=43)\n    \n    optimal_model.fit(X, y)\n    stop_time = time.time()\n\n    scores = cross_val_score(optimal_model, X, y, cv=k, scoring=\"accuracy\")\n    \n    print(\"Elapsed Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(stop_time - start_time)))\n    print(\"====================\")\n    print(\"Cross Val Mean: {:.3f}, Cross Val Stdev: {:.3f}\".format(scores.mean(), scores.std()))\n    print(\"Best Score: {:.3f}\".format(optimal_model.best_score_))\n    print(\"Best Parameters: {}\".format(optimal_model.best_params_))\n    \n    return optimal_model.best_params_, optimal_model.best_score_, optimal_model\n\n\nbase_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),\n    n_estimators=600,\n    learning_rate=1)\n\nlots_of_parameters = {\n    \"max_depth\": [3, 5, 10, None],\n    \"n_estimators\": [100, 200, 300, 400, 500],\n    \"max_features\": [3,7,10,20,30,50],\n    \"criterion\": [\"gini\", \"entropy\"],\n    \"bootstrap\": [True, False],\n    \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9,15,50],\n\n}\nparameters = {\n    \"algorithm\":[\"SAMME\"],\n    \"base_estimator__criterion\": [\"gini\", \"entropy\"],\n    \"learning_rate\": [0.1,0.5,0.8,1,1.5,3],\n    \"n_estimators\": [100,300,500],\n    #\"base_estimator__min_samples_split\": [1,3,5,10],\n    #\"base_estimator__min_samples_leaf\": [1,3,5,10]\n    \n} #\"algorithm\": [\"SAMME.R\",\"SAMME\"],\n\nbest_params, best_score, optimal_model = hyperparameter_tune(base_model, parameters, 50, 3, train_X, train_y)","9dc3f7c9":"train_csv = pd.read_csv(\"\/kaggle\/input\/classification-datasets\/classification_datasets\/lupus.csv\")\n\nseed=100\ntrain, validation = train_test_split(train_csv, test_size=0.3,random_state=seed) \n\ntrain_X, train_y = train.iloc[:,:-1],train.iloc[:,-1]\n\ntest_X, test_y = validation.iloc[:,:-1],validation.iloc[:,-1]\n#\n\n\n\n\n#######################\nprint(test_y)\n\n#label encoder from categorial to int categories\nfrom sklearn import preprocessing\n\n\n\nle = preprocessing.LabelEncoder()\ntest_y=le.fit_transform(test_y.values.reshape(-1, 1))\ntest_y=pd.DataFrame(test_y)\nprint(test_y)\nprint(test_y[0].unique())\n\n\n\n","a6d8ac93":"\n\ny_true = test_y.tolist()\ny_prediction = prediction.tolist()\nprint(len(y_true))\nprint(len(y_prediction))\n\ncm = ConfusionMatrix(actual_vector=y_true,predict_vector=y_prediction)\nprint(cm)\n\n","e7120947":"#!!!!\n\nstart_time = time.time()\nprediction=optimal_model.predict(test_X)\n#print(prediction)\n\n\n####\n\n\nscores_accuracy = cross_val_score(bdt_real, test_X, test_y, cv=10, scoring=\"accuracy\")\n#scores_accuracy = cross_val_score(bdt_real, X, y, cv=10, scoring=\"AUC\")\n\nbdt_real = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=2),\n    n_estimators=600,\n    learning_rate=1)\n\n\n\nbdt_real.fit(train_X, train_y)\n\n\nbdt_real.set_params(**optimal_model.best_params_)\nstart = time.time()\nbdt_real.fit(train_X, train_y)\ntraining_time = time.time() - start\nstart = time.time()\ny_pred = bdt_real.predict(test_X)\ninference_time = (time.time() - start) \/ len(test_X) # single inference time\ninference_time *= 1000 # 1000 lines\n\n\n# valuse out..\nprint(training_time)\nprint(inference_time)"}}