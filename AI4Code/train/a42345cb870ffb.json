{"cell_type":{"bb94ddfd":"code","025423af":"code","e1794421":"code","805daa06":"code","5ca3ff7b":"code","bdc20afb":"code","7729f841":"code","6b25ea48":"code","8458d6d9":"code","4e3b2eb3":"code","345f9a7f":"code","48cf62fa":"code","867be38e":"code","f91acbb4":"code","063a9a75":"code","5a45116d":"code","ea4e7c6a":"code","59b590f5":"code","9d688425":"code","18d058b8":"code","bd9e6a76":"code","deb43bd2":"code","a806c4c3":"code","e10f0943":"code","ad15d2b3":"code","05a209c2":"code","f76ec564":"code","22f11029":"code","fe475e8f":"code","4ac2e100":"code","a1016a9b":"code","73564716":"code","5a1be0cc":"code","8ed26bc3":"markdown"},"source":{"bb94ddfd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport plotly.express as px\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n# Import libraries and set desired options\nimport os\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import hstack\n# !pip install eli5\nimport eli5\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display_html\n","025423af":"test = pd.read_csv('..\/input\/GiveMeSomeCredit\/cs-test.csv')\ntrain = pd.read_csv('..\/input\/GiveMeSomeCredit\/cs-training.csv')","e1794421":"train = train.fillna(0)\ntest = test.fillna(0)","805daa06":"logit = LogisticRegression(C=1, random_state=17, solver='liblinear')","5ca3ff7b":"%%time\n\ncv_scores1 = cross_val_score(logit, train, train.SeriousDlqin2yrs, cv=5, \n                            scoring='roc_auc', n_jobs=4) # hangs with n_jobs > 1, and locally this runs much faster","bdc20afb":"cv_scores1, cv_scores1.mean()","7729f841":"logit.fit(train, train.SeriousDlqin2yrs)","6b25ea48":"# A helper function for writing predictions to a file\ndef write_to_submission_file(predicted_labels, out_file,\n                             target='target', index_label=\"session_id\"):\n    predicted_df = pd.DataFrame(predicted_labels,\n                                index = np.arange(1, predicted_labels.shape[0] + 1),\n                                columns=[target])\n    predicted_df.to_csv(out_file, index_label=index_label)","8458d6d9":"logit_test_pred = logit.predict_proba(test)[:, 1]\nwrite_to_submission_file(logit_test_pred, 'subm1.csv') # 0.91807","4e3b2eb3":"subm = pd.read_csv('.\/subm1.csv')\nsubm","345f9a7f":"def train_and_predict(model, X_train, y_train, X_test, site_feature_names=train.columns, \n                      new_feature_names=None, cv=5, scoring='roc_auc',\n                      top_n_features_to_show=30, submission_file_name='submission.csv'):\n    \n    \n    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, \n                            scoring=scoring, n_jobs=4)\n    print('CV scores', cv_scores)\n    print('CV mean: {}, CV std: {}'.format(cv_scores.mean(), cv_scores.std()))\n    model.fit(X_train, y_train)\n    \n    if new_feature_names:\n        all_feature_names = site_feature_names + new_feature_names \n    else: \n        all_feature_names = site_feature_names\n\n    \n    if new_feature_names:\n        print('New feature weights:')\n    \n        print(pd.DataFrame({'feature': new_feature_names, \n                        'coef': model.coef_.flatten()[-len(new_feature_names):]}))\n    \n    test_pred = model.predict_proba(X_test)[:, 1]\n    write_to_submission_file(test_pred, submission_file_name) \n    \n    return cv_scores","48cf62fa":"cv_scores1 = train_and_predict(model=logit, X_train=train, y_train=train.SeriousDlqin2yrs, \n                  X_test=test, site_feature_names=train.columns,              \n                  cv=5, submission_file_name='subm1.csv')","867be38e":"train = train[['SeriousDlqin2yrs',\n       'RevolvingUtilizationOfUnsecuredLines', 'age',\n       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n       'NumberOfDependents']]\ntest = test[['SeriousDlqin2yrs',\n       'RevolvingUtilizationOfUnsecuredLines', 'age',\n       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n       'NumberOfDependents']]","f91acbb4":"test['MonthlyIncome'] = test['MonthlyIncome'].fillna(0.0)\ntrain['MonthlyIncome'] = train['MonthlyIncome'].fillna(0.0)\ntest['NumberOfDependents'] = test['NumberOfDependents'].fillna(test['NumberOfDependents'].median())\ntrain['NumberOfDependents'] = train['NumberOfDependents'].fillna(train['NumberOfDependents'].median())","063a9a75":"independent_columns_names = [x for x in train if x != 'SeriousDlqin2yrs']\nindependent_columns_names","5a45116d":"table = train\nX = table[independent_columns_names]\ny = table['SeriousDlqin2yrs']","ea4e7c6a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nlr = LogisticRegression(C=0.001, random_state=5, class_weight='balanced')\nscal = StandardScaler()\nlr.fit(scal.fit_transform(X), y)\n\npd.DataFrame({'feat': independent_columns_names,\n              'coef': lr.coef_.flatten().tolist()}).sort_values(by='coef', ascending=False)","59b590f5":"# BEFORE WAS: logit = LogisticRegression(C=1, random_state=17, solver='liblinear')\nlogit = LogisticRegression(C=0.001, random_state=5, class_weight='balanced', solver='liblinear')","9d688425":"%%time\n\ncv_scores1 = cross_val_score(logit, train[['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTimes90DaysLate', 'NumberOfTime60-89DaysPastDueNotWorse']], train.SeriousDlqin2yrs, cv=5, \n                            scoring='roc_auc', n_jobs=4) # hangs with n_jobs > 1, and locally this runs much faster","18d058b8":"cv_scores1, cv_scores1.mean()","bd9e6a76":"logit.fit(train, train.SeriousDlqin2yrs)","deb43bd2":"# A helper function for writing predictions to a file\ndef write_to_submission_file(predicted_labels, out_file,\n                             target='target', index_label=\"session_id\"):\n    predicted_df = pd.DataFrame(predicted_labels,\n                                index = np.arange(1, predicted_labels.shape[0] + 1),\n                                columns=[target])\n    predicted_df.to_csv(out_file, index_label=index_label)","a806c4c3":"test","e10f0943":"\nlogit_test_pred = logit.predict_proba(test)[:, 0]\nwrite_to_submission_file(logit_test_pred, 'subm3.csv') # 0.91807","ad15d2b3":"subm = pd.read_csv('.\/subm3.csv')\nsubm","05a209c2":"def train_and_predict(model, X_train, y_train, X_test, site_feature_names=train.columns, \n                      new_feature_names=None, cv=5, scoring='roc_auc',\n                      top_n_features_to_show=30, submission_file_name='submission.csv'):\n    \n    \n    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, \n                            scoring=scoring, n_jobs=4)\n    print('CV scores', cv_scores)\n    print('CV mean: {}, CV std: {}'.format(cv_scores.mean(), cv_scores.std()))\n    model.fit(X_train, y_train)\n    \n    if new_feature_names:\n        all_feature_names = site_feature_names + new_feature_names \n    else: \n        all_feature_names = site_feature_names\n\n    \n    if new_feature_names:\n        print('New feature weights:')\n    \n        print(pd.DataFrame({'feature': new_feature_names, \n                        'coef': model.coef_.flatten()[-len(new_feature_names):]}))\n    \n    test_pred = model.predict_proba(X_test)[:, 1]\n    write_to_submission_file(test_pred, submission_file_name) \n    \n    return cv_scores","f76ec564":"cv_scores1 = train_and_predict(model=logit, X_train=train, y_train=train.SeriousDlqin2yrs, \n                  X_test=test, site_feature_names=train.columns,              \n                  cv=5, submission_file_name='subm1.csv')","22f11029":"# Let's load the packages\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.inspection import permutation_importance\nimport shap\nfrom matplotlib import pyplot as plt\n\nplt.rcParams.update({'figure.figsize': (12.0, 8.0)})\nplt.rcParams.update({'font.size': 14})","fe475e8f":"X = df\ny = df.SeriousDlqin2yrs\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)","4ac2e100":"rf = RandomForestRegressor(n_estimators=100)\nrf.fit(X_train, y_train)","a1016a9b":"df.columns","73564716":"plt.barh(df[['RevolvingUtilizationOfUnsecuredLines', 'age',\n       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n       'NumberOfDependents']], rf.feature_importances_)","5a1be0cc":"sorted_idx = rf.feature_importances_.argsort()\nplt.barh(df.columns[sorted_idx], rf.feature_importances_[sorted_idx])\nplt.xlabel(\"Random Forest Feature Importance\")","8ed26bc3":"# Start"}}