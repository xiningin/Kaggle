{"cell_type":{"2ecd0b8c":"code","6ea28494":"code","97f7f7be":"code","d480eaa0":"code","ef27dcf7":"code","143572cf":"code","cffc4f3e":"code","a159536b":"code","a02f520e":"code","fc35ef2b":"code","0d6bd21f":"code","696f22fe":"code","11769fa2":"code","c0fb4c49":"code","b682a116":"code","ec22c7d3":"code","ee62aa84":"code","e5284aab":"code","c185b4f5":"code","d5708bb6":"code","f6bfe64b":"code","e7de2d2f":"code","ba8bd64a":"code","4a706f74":"code","8230252b":"code","333c0ed1":"code","17486007":"code","7a8bc3d9":"markdown","01b8fd56":"markdown","f1223213":"markdown","91bc6895":"markdown","a8350334":"markdown","bbf8825c":"markdown","c7dfe742":"markdown","a49b4f55":"markdown","d5f69b30":"markdown","c2fcd673":"markdown","ca786b7a":"markdown","8eb00dd8":"markdown","fc34569c":"markdown","331d2ff6":"markdown","bcbe12ac":"markdown","4119a0be":"markdown","fe242821":"markdown","e0e12b92":"markdown","16ae0a6d":"markdown"},"source":{"2ecd0b8c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6ea28494":"data = pd.read_csv(\"..\/input\/insurance\/insurance.csv\")\ndata.head()","97f7f7be":"print(data.shape)\nprint(data.dtypes)","d480eaa0":"data.isnull().sum()","ef27dcf7":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\ncat_feature = ['sex']\ncat_more_features = ['smoker', 'region']\nfeature_name = []\n\ndef num_cat(feature, feature_name):\n    label_enc = LabelEncoder()\n    label_enc.fit(feature)\n    label_feat = label_enc.transform(feature)\n    #print(label_enc.classes_)\n    \n    ohe = OneHotEncoder()\n    ohe.fit(label_feat.reshape(-1,1))\n    encoded_data = ohe.transform(label_feat.reshape(-1,1)).toarray()\n    feature_name = ohe.get_feature_names(input_features=[feature_name])\n    #print(feature_name)\n    return encoded_data, feature_name, label_enc.classes_\n\nfor i in cat_feature:\n    enc_dataI = num_cat(data[i], i)\n    tempI = enc_dataI[0]\n    clas = enc_dataI[2]\n    for ii in clas:\n        feature_name.append(i+'_'+ii)\n    \nfor j in cat_more_features:\n    enc_dataII = num_cat(data[j], j)\n    tempII = enc_dataII[0]\n    clas = enc_dataII[2]\n    for jj in clas:\n        feature_name.append(j+'_'+jj)\n    tempI = np.concatenate([tempI, tempII], axis=1)\n\nprint(feature_name)","143572cf":"cat_to_num = pd.DataFrame(tempI, columns=feature_name)\ndataN = cat_to_num.join(data[['age','bmi','children','charges']])","cffc4f3e":"plt.figure(figsize=(18,12))\nsns.heatmap(dataN.corr(), center=0, linewidths=0.5, cmap='YlGnBu')","a159536b":"sns.pairplot(data, hue=\"smoker\")","a02f520e":"sns.pairplot(data, hue=\"sex\")","fc35ef2b":"sns.distplot(data.charges)","0d6bd21f":"plt.hist(data.charges, bins=20)","696f22fe":"sns.boxplot(x='sex', y='charges', hue='smoker', data=data)","11769fa2":"sns.boxplot(x='children', y='charges', hue='smoker', data=data)","c0fb4c49":"plt.figure(figsize=(18,12))\nsns.boxplot(x='age',y='charges', hue='smoker', data=data)","b682a116":"sns.distplot(data[(data.bmi>30)]['charges'])","ec22c7d3":"sns.distplot(data[(data.bmi<=30)]['charges'])","ee62aa84":"sns.catplot(x='region', y='charges', hue='smoker', data=data, kind='violin')","e5284aab":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.ensemble import RandomForestRegressor","c185b4f5":"y = dataN.charges\nX = dataN.drop(['charges'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\nreg = LinearRegression()\nreg.fit(X_train, y_train)\nprint(reg.coef_)\nprint(reg.intercept_)\ny_train_pred = reg.predict(X_train)\ny_test_pred = reg.predict(X_test)","d5708bb6":"train_accu = r2_score(y_train, y_train_pred)\ntest_accu = r2_score(y_test, y_test_pred)\n\nprint(\"Linear Regression Train accuracy\", train_accu)\nprint(\"Test accuracy\", test_accu)","f6bfe64b":"reg_random = RandomForestRegressor(max_depth=10, random_state=1, n_estimators=200)\nreg_random.fit(X_train, y_train)\ny_train_randm = reg_random.predict(X_train)\ny_test_randm = reg_random.predict(X_test)\ntrain_accu_pred_randm = r2_score(y_train, y_train_randm)\ntest_accu_pred_randm = r2_score(y_test, y_test_randm)\n\nprint(\"train prediction accuracy\", train_accu_pred_randm)\nprint(\"test prediction accuracy\", test_accu_pred_randm )","e7de2d2f":"y_ln = np.log(dataN.charges)\nX_ln = dataN.drop(['charges'], axis=1)\nX_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(X_ln, y_ln, test_size=0.3)\nreg_ln = LinearRegression()\nreg_ln.fit(X_train_ln, y_train_ln)\ny_train_ln_pred = reg_ln.predict(X_train_ln)\ny_test_ln_pred = reg_ln.predict(X_test_ln)\nprint(\"log train accuracy\", r2_score(y_train_ln, y_train_ln_pred))\nprint(\"log test accuraacy\", r2_score(y_test_ln, y_test_ln_pred))","ba8bd64a":"rndm_ln = RandomForestRegressor(max_depth=10, random_state=1, n_estimators=200)\nrndm_ln.fit(X_train_ln, y_train_ln)\ny_trainrndm_pred = rndm_ln.predict(X_train_ln)\ny_testrndm_pred = rndm_ln.predict(X_test_ln)\nprint(\"random forest train accuracy\", r2_score(y_train_ln, y_trainrndm_pred))\nprint(\"random forest test accuracy\", r2_score(y_test_ln, y_testrndm_pred))","4a706f74":"from sklearn.model_selection import learning_curve\ndef learning_curves(algo, X, y, train_sizes, cv):\n    train_sizes, train_score, validation_score = learning_curve(estimator=algo, X=X, y=y, cv=cv, scoring='neg_mean_squared_error')\n    train_score_mean = -train_score.mean(axis=1)\n    validation_score_mean = -validation_score.mean(axis=1)\n    \n    plt.plot(train_sizes, train_score_mean, label=\"Training error\")\n    plt.plot(train_sizes, validation_score_mean, label=\"Validation Error\")\n    \n    plt.ylabel(\"MSE\", fontsize=10)\n    plt.xlabel(\"Train sizes\", fontsize=10)\n    \n    plt.title(\"Learning Curve\")\n    plt.legend(loc=\"best\")","8230252b":"train_sizes=[1,200,400,600,800,1000]","333c0ed1":"learning_curves(rndm_ln, X_ln, y_ln,train_sizes,5)","17486007":"learning_curves(reg_ln, X_ln, y_ln, train_sizes, 5)","7a8bc3d9":"This clears a lot about the charges paid by smoker increases with age and having median much more than non-smoker\n\n\nNow let's check for bmi \npeople having bmi greater than 30 and less than 30","01b8fd56":"RandomForest with Log Transformation:","f1223213":"This is right skewed :: mean is greater than median i.e. avg charges are more than median charge","91bc6895":"Median charges of smoker male is more than female.","a8350334":"Change the categorical variable to numerical data without using pd.get_dummies. It is not suggested to use pd.get_dummies in production ","bbf8825c":"Now combine the remaining columns of the dataset to this new dataframe.","c7dfe742":"For non-smoker it doesn't matter much, but for smoker southwest and southeast has higher median of charges \n\nNow let's check the predictions:\nfor numerical dataN","a49b4f55":"Now check with RandomForestRegressor ","d5f69b30":"Smoker having children spends more on charges\/insurance. \n\nLet's check with age, how many in age of 18 to 22 spends on charges. ","c2fcd673":"Lets load the dataset..","ca786b7a":"From the above pairplot few points can be deduced:\n    1. Smokers paying more charges with increasing age\n    2. For smokers charges increase with bmi while for non-smokers not that much ","8eb00dd8":"Will further analyze this dataset to reduce this overfitting... :) ","fc34569c":"It seems overfitting here let's check by drawing learning curve","331d2ff6":"This is good that there is no missing data, our task reduced!!\n","bcbe12ac":"**OneHot followed by LabelEncoder \/\/pd.get_dummies**","4119a0be":"From the heatmap, it is pretty clear that smoker has a postive correlation with charges. ","fe242821":"Now apply log transformation on charges as it was distributed right: right skewed ","e0e12b92":"The model suffers from high variance and low bias as observed ","16ae0a6d":"ohhoo, this is some strange behaviour of training error"}}