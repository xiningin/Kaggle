{"cell_type":{"b4c9e01e":"code","104b4f0d":"code","2fa2fadb":"code","4765b39e":"code","9f9edc89":"code","1bd6dd61":"code","b43b49a2":"code","aaa840bc":"code","9953d07c":"code","d276af07":"code","ee547dfe":"code","57fc93d2":"code","beb16f88":"code","e3469e51":"code","f90f432b":"code","62d99a14":"code","92a295b2":"code","f396c91b":"code","c9bd15a6":"code","f2b1183c":"code","5bc6553e":"code","e407598e":"code","75eb882e":"code","0cdc1f1f":"code","a00c65d4":"code","b91151c1":"code","66951d6c":"code","ee5c2e00":"code","68a7b686":"code","de02f14d":"code","f7f494c5":"code","5960c80b":"code","4c5e734e":"code","08a91651":"markdown","e9a26228":"markdown","1b2e10cb":"markdown","cbda29b7":"markdown","9a84349e":"markdown","26855fa3":"markdown","bad453a6":"markdown","1e17492b":"markdown","9c8b8bb3":"markdown","f9abb7c2":"markdown","18724942":"markdown","414ada04":"markdown","dc104339":"markdown","a20176d5":"markdown","0b865270":"markdown","f1870ea6":"markdown","191633f7":"markdown","3a69fa21":"markdown","ec583b70":"markdown","34fdaf53":"markdown","c2a794a8":"markdown","ff0b1611":"markdown","2a1cef00":"markdown","0c80c820":"markdown"},"source":{"b4c9e01e":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix","104b4f0d":"df = pd.read_csv('\/kaggle\/input\/telecom-users-dataset\/telecom_users.csv')","2fa2fadb":"df","4765b39e":"df.describe()","9f9edc89":"df.info()","1bd6dd61":"\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].apply(pd.to_numeric,errors='coerce')\ndf = df.drop(\"customerID\",axis= 1)\ndf['SeniorCitizen'] = df['SeniorCitizen'].astype(str)","b43b49a2":"cols = df.columns\nnum_cols = df._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))","aaa840bc":"\nfig, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8),(ax9,ax10,ax11,ax12),(ax13,ax14,ax15,ax16),(ax17,ax19,ax18,ax20)) = plt.subplots(5,4,figsize=(30,30)) \nax_list = [ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10,ax11,ax12,ax13,ax14,ax15,ax16,ax17]\ni=0\nfor col in cat_cols :\n    dict_data = df[col].value_counts().to_dict()\n    ax_list[i].bar(list(dict_data.keys()),list(dict_data.values()))\n    \n    if i==3:\n        ax_list[i].set_xticklabels(list(dict_data.keys()), rotation=50)\n        ax_list[i].tick_params(axis='x', which='major', labelsize=13)\n\n    ax_list[i].set_title(col)\n    i+=1\nax18.axis(\"off\")\nax19.axis(\"off\")\nax20.axis(\"off\")\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.8)\nplt.show()\n    ","9953d07c":"fig , (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,5)) \ndf[\"TotalCharges\"].astype(\"float\").hist(bins= 40,ax =ax1)\nax1.set_title( \"TotalCharges\")\ndf[\"MonthlyCharges\"].astype(\"float\").hist(bins= 20,ax =ax2)\nax2.set_title( \"MonthlyCharges\")\ndf[\"tenure\"].astype(\"float\").hist(bins= 30,ax =ax3)\nax3.set_title(\"tenure\")\nplt.show()\n","d276af07":"df_churned = df.loc[df[\"Churn\"]==\"Yes\"]\ndf_not_churned = df.loc[df[\"Churn\"]==\"No\"]","ee547dfe":"fig, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8),(ax9,ax10,ax11,ax12),(ax13,ax14,ax15,ax16),(ax17,ax19,ax18,ax20)) = plt.subplots(5,4,figsize=(30,30)) \nax_list = [ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10,ax11,ax12,ax13,ax14,ax15,ax16,ax17]\ni=0\nnum_churned = len(df_churned.index)\nnum_not_churned = len(df_not_churned.index)\nfor col in cat_cols :\n    dict_data_churned = df_churned[col].value_counts().to_dict()\n    value_churned = list(dict_data_churned.values())\n    \n    dict_data_not_churned = df_not_churned[col].value_counts().to_dict()\n    value_not_churned = list(dict_data_not_churned.values())\n    \n    x=np.arange(len(list(dict_data_not_churned.keys())))\n    \n    ax_list[i].bar(x + 0.3, [x \/ num_not_churned  for x in value_not_churned],width=0.3, label=\"Not Churned\")\n    ax_list[i].bar(x, [x \/ num_churned  for x in value_churned],width=0.3,label=\"Churned\")\n    if i==14:\n        ax_list[i].set_xticklabels(list(dict_data_not_churned.keys()), rotation=50)\n        ax_list[i].tick_params(axis='x', which='major', labelsize=13)\n\n    ax_list[i].set_title(col)\n    ax_list[i].set_xticklabels(list(dict_data_not_churned.keys()))\n    ax_list[i].set_xticks(x+0.15)\n    ax_list[i].legend()\n    i+=1\nax18.axis(\"off\")\nax19.axis(\"off\")\nax20.axis(\"off\")\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.8)\nplt.show()","57fc93d2":"df_not_churned_sample = df_not_churned.sample(n=1587)","beb16f88":"fig , (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,5)) \ndf_not_churned_sample[\"TotalCharges\"].astype(\"float\").hist(bins= 40,ax =ax1,label = \"Not Churned\")\ndf_churned[\"TotalCharges\"].astype(\"float\").hist(bins= 40,ax =ax1,label = \"Churned\",alpha=0.7)\n\nax1.set_title( \"TotalCharges\")\ndf_not_churned_sample[\"MonthlyCharges\"].astype(\"float\").hist(bins= 20,ax =ax2,label =\"Not Churned\")\ndf_churned[\"MonthlyCharges\"].astype(\"float\").hist(bins= 20,ax =ax2,label = \"Churned\",alpha=0.7)\n\nax2.set_title( \"MonthlyCharges\")\ndf_not_churned_sample[\"tenure\"].astype(\"float\").hist(bins= 30,ax =ax3,label =\"Not Churned\")\ndf_churned[\"tenure\"].astype(\"float\").hist(bins= 30,ax =ax3,label = \"Churned\",alpha=0.7)\n\nax3.set_title(\"tenure\")\nplt.legend()\nplt.show()","e3469e51":"fig , (ax1,ax2) = plt.subplots(1,2,figsize=(20,5)) \ndf_not_churned_sample.plot(kind=\"scatter\",x=\"MonthlyCharges\",y=\"tenure\",alpha = 0.3,title = \"Not Churned\",ax=ax1)\ndf_churned.plot(kind=\"scatter\",x=\"MonthlyCharges\",y=\"tenure\",alpha = 0.3,title = \"Churned\",ax=ax2)","f90f432b":"\ndf_above_70 = df.loc[df[\"MonthlyCharges\"].astype(\"float\")> 70]\ndf_below_70 = df.loc[df[\"MonthlyCharges\"].astype(\"float\")< 70]","62d99a14":"fig , (ax1,ax2) = plt.subplots(1,2,figsize=(20,5)) \ndict_data = df_above_70 [\"Churn\"].value_counts().to_dict()\nax1.pie(list(dict_data.values()),labels=list(dict_data.keys()),autopct='%1.2f%%',textprops={'fontsize': 13})\nax1.set_title( \"Churn Rate of Above 70 Monthly Chargeb\")\ndict_data = df_below_70 [\"Churn\"].value_counts().to_dict()\nax2.pie(list(dict_data.values()),labels=list(dict_data.keys()),autopct='%1.2f%%',textprops={'fontsize': 13})\nax2.set_title( \"Churn Rate of Below 70 Monthly Charge\")","92a295b2":"df_encoded = pd.get_dummies(df.iloc[:,:20])\ndf_encoded[\"Churn\"] = df[\"Churn\"]\ndf_encoded.loc[df_encoded[\"Churn\"]==\"Yes\",\"Churn\"]=\"1\"\ndf_encoded.loc[df_encoded[\"Churn\"]==\"No\",\"Churn\"]=\"0\"","f396c91b":"df_encoded","c9bd15a6":"df_encoded.dropna(inplace=True)\nX= df_encoded.iloc[:,1:47]\ny= df_encoded.iloc[:,47]\n","f2b1183c":"X_train , X_test, y_train , y_test = train_test_split(X,y , test_size=0.2, random_state=0)","5bc6553e":"X_train , X_val, y_train , y_val = train_test_split(X_train,y_train , test_size=0.2, random_state=0)","e407598e":"y_train.value_counts()","75eb882e":"2783\/1041","0cdc1f1f":"svc = SVC(class_weight='balanced',probability=True)\nsvc.fit(X_train,y_train)\ny_prob = svc.predict_proba(X_val)[:,1]\nscores = average_precision_score( y_val, y_prob,pos_label=\"1\")\nprint(\"AUPRC : \",scores )","a00c65d4":"lr = LogisticRegression(class_weight='balanced',max_iter = 10000)\nlr.fit(X_train,y_train)\ny_prob = lr.predict_proba(X_val)[:,1]\nscores = average_precision_score( y_val, y_prob,pos_label=\"1\")\nprint(\"AUPRC : \",scores )","b91151c1":"xgbc = XGBClassifier(scale_pos_weight=2.67)\nxgbc .fit(X_train,y_train)\ny_prob = xgbc .predict_proba(X_val)[:,1]\nscores = average_precision_score( y_val, y_prob,pos_label=\"1\")\nprint(\"AUPRC : \",scores )","66951d6c":"rfc = RandomForestClassifier(class_weight='balanced')\nrfc .fit(X_train,y_train)\ny_prob = rfc .predict_proba(X_val)[:,1]\nscores = average_precision_score( y_val, y_prob,pos_label=\"1\")\nprint(\"AUPRC : \",scores )","ee5c2e00":"param_grid = { \n    'C': [0.01,0.1,1],\n    'solver': ['liblinear', 'sag', 'lbfgs']\n}\n\nlr = LogisticRegression(class_weight='balanced',max_iter = 10000)\nauprc_scorer = make_scorer(average_precision_score, pos_label=\"1\",needs_proba=True)\nCV_lr = GridSearchCV(estimator=lr, param_grid=param_grid, cv= 3,scoring =auprc_scorer )\nCV_lr.fit(X_train, y_train)\ny_scores = CV_lr.predict_proba(X_val)[:,1]\nprint (\"Best Params :\" , CV_lr.best_params_)\nprint (\"\\n Best Accuracy :\", CV_lr.best_score_)\nprint(\"\\n AUPRC :\" , average_precision_score(y_val,y_scores,pos_label='1'))","68a7b686":"xgbc = XGBClassifier(scale_pos_weight=2.67,gamma=4,eta=0.06)\nxgbc .fit(X_train,y_train)\ny_prob = xgbc .predict_proba(X_train)[:,1]\nscore_train = average_precision_score( y_train, y_prob,pos_label=\"1\")\ny_prob = xgbc .predict_proba(X_val)[:,1]\nscore_val = average_precision_score( y_val, y_prob,pos_label=\"1\")\nprint(\"Training AUPRC : \",score_train)\nprint(\"Validaiton AUPRC : \",score_val )","de02f14d":"rfc = RandomForestClassifier(class_weight='balanced',max_features=\"sqrt\",n_estimators=50)\nrfc .fit(X_train,y_train)\ny_prob = rfc .predict_proba(X_train)[:,1]\nscore_train = average_precision_score( y_train, y_prob,pos_label=\"1\")\ny_prob = rfc .predict_proba(X_val)[:,1]\nscore_val = average_precision_score( y_val, y_prob,pos_label=\"1\")\nprint(\"Training AUPRC : \",score_train)\nprint(\"Validaiton AUPRC : \",score_val )","f7f494c5":"y_scores = xgbc.predict_proba(X_val)[:,1]\nprint(\"Precision-Recall Curve\\n\")\np, r, t = precision_recall_curve(y_val, y_scores,pos_label=\"1\")\nf1 = 2*p[:-1]*r[:-1]\/(r[:-1]+p[:-1])\nplt.plot(t, p[:-1], 'r-', label='Precision')\nplt.plot(t, r[:-1], 'b-', label='Recall')\nplt.plot(t, f1, 'g-', label='F1')\nplt.legend(loc='center left')\nplt.xlabel('Threshold')\n","5960c80b":"y_scores = xgbc.predict_proba(X_val)[:,1]\ny_pred = (y_scores >= 0.5).astype(int)\nconditions = [\n                (y_pred == 1),\n                (y_pred == 0)]\nchoices = [\"1\",\"0\"]\ny_pred  = np.select(conditions, choices)\n\nprint(\"\\n AUPRC :\" , average_precision_score(y_val,y_scores,pos_label='1'))\n\n    \nprint(\"Report:\")\nprint(classification_report(y_val, y_pred))\n\nconfusion_matrix_array = confusion_matrix(y_val,y_pred,normalize='true')  \ng= sns.heatmap(confusion_matrix_array, annot=True,yticklabels=[\"Act Not Churned\",\"Act Churned\"],xticklabels=[\"Pred Not Churned\",\"Pred Churned\"])\ng.set_yticklabels(g.get_yticklabels(), rotation = 0)","4c5e734e":"y_scores = xgbc.predict_proba(X_test)[:,1]\ny_pred = (y_scores >= 0.5).astype(int)\nconditions = [\n                (y_pred == 1),\n                (y_pred == 0)]\nchoices = [\"1\",\"0\"]\ny_pred  = np.select(conditions, choices)\n\nprint(\"\\n AUPRC :\" , average_precision_score(y_test,y_scores,pos_label='1'))\nconfusion_matrix_array = confusion_matrix(y_test,y_pred,normalize='true')\n    \nprint(\"Report:\")\nprint(classification_report(y_test, y_pred))\n\nconfusion_matrix_array = confusion_matrix(y_test,y_pred,normalize='true')  \ng= sns.heatmap(confusion_matrix_array, annot=True,yticklabels=[\"Act Not Churned\",\"Act Churned\"],xticklabels=[\"Pred Not Churned\",\"Pred Churned\"])\ng.set_yticklabels(g.get_yticklabels(), rotation = 0)\n","08a91651":"Tuned by GridSearch","e9a26228":"# Import Library","1b2e10cb":"## 2.2 Analysis","cbda29b7":"## 5.2 Treshold Tuning","9a84349e":"**Our best model is XGBClassifier**","26855fa3":"## 5.3 Final Evaluation","bad453a6":"# 5.Tuning ","1e17492b":"# Summary\n**Task : prediting if a customer is going to churn**\n\n**process: its pretty straight forward project,  <br>\n 1.we do some visualization and the analysis data by comparing churned customers with not-churned ones.<br>\n 2.we preprocces data , since data is skewed we use SMOTE<br>\n 3.training models.<br>\n 4.tuning the best model for optimal result<br>**\n","9c8b8bb3":"Tuned by hand","f9abb7c2":"**if a customer first month charge is above 70, their chance of Churning is twice of a below 70 customer**","18724942":"**1. \"Churned\" Customers have much less \"tenure\" than other customers, this shows most of these customers didnt come back after their first month**<br>\n**2. intrestingly, churned customers have had more \"MonthlyCharges\" than the rest, this is compatible with categorical data, which showed \"Churned\" customers had been subsricbed to more services**<br>\n**3. altough \"Monthly Charges\" in \"Churned\" customers are higher, their total charges are lower**","414ada04":"## 3.1 One-Hot Encoding","dc104339":"# 2.Visualizaition & Analysis","a20176d5":"**best model is logistic regression**","0b865270":"Tuned by hand","f1870ea6":"# 1.Loading Data","191633f7":"##  3.2 Train\/Validation\/Test Split","3a69fa21":"## 2.1 Visualization","ec583b70":"**the measurements are in fraction of \"Churned\" and \"Not Churned\" customers**<br>\n","34fdaf53":"# 3.Preprocessing","c2a794a8":"# 4.Training","ff0b1611":"**0.5 threshold seems good, the precision of churn predicitions is low, but in this threshold we get 75% recall of churned customers**","2a1cef00":"## 5.1 Hyperparameters","0c80c820":"**a difrrent representaiton of conclusions**"}}