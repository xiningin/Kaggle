{"cell_type":{"57670ef0":"code","91e62058":"code","c1b49766":"code","0e3d0ade":"code","0bb3d3f4":"code","1aface21":"code","1afd058f":"code","230f78cf":"code","7cf79d08":"markdown","2bd23e76":"markdown","5b06e83e":"markdown","f6fcd215":"markdown","5b4671e5":"markdown","7001684d":"markdown","510c713a":"markdown","92ce31d8":"markdown","67c5da73":"markdown"},"source":{"57670ef0":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","91e62058":"dataset = pd.read_csv('..\/input\/restaurant-reviews\/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)","c1b49766":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 1000):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","0e3d0ade":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, 1].values","0bb3d3f4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","1aface21":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","1afd058f":"y_pred = classifier.predict(X_test)","230f78cf":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","7cf79d08":"## Splitting the dataset into the Training set and Test set","2bd23e76":"## Making the Confusion Matrix","5b06e83e":"## Creating the Bag of Words model","f6fcd215":"## Importing the libraries","5b4671e5":"# Natural Language Processing","7001684d":"## Importing the dataset","510c713a":"## Predicting the Test set results","92ce31d8":"## Training the Naive Bayes model on the Training set","67c5da73":"## Cleaning the texts"}}