{"cell_type":{"26efc7d6":"code","e573fb3a":"code","a590d8bc":"code","bc4349dd":"code","c89df43b":"code","58309e47":"code","78098f35":"code","92df74fe":"code","3c16f70b":"code","580a2fe2":"code","279e04df":"code","76f8a66c":"code","968b5aaf":"code","185a7557":"code","e5bb3fe9":"code","c500f28e":"code","9cdea410":"code","3c195d28":"code","18deef58":"code","ddb9d38d":"code","6ecfbeec":"code","e0157d04":"code","119a27fa":"code","dcdc6542":"code","b1809b4f":"code","d0819073":"code","f2765bfc":"code","6e9578f7":"code","e18891ae":"code","e0ccad4e":"code","7f71c546":"code","e38d0a72":"code","56371ea2":"code","e8f17849":"code","a007cd0b":"code","dc715ea3":"code","814c5f33":"code","4d012ee2":"code","4361f309":"code","f67982f7":"code","3444d75b":"code","06e6ccd1":"code","f2eed772":"code","731d738d":"code","6dcbbbb8":"code","96e329e7":"code","88bd33e3":"code","958c34f2":"code","b378fb67":"code","6c3b755e":"code","2d5c625b":"code","4b7d922b":"code","34174f12":"code","8f9f12b7":"code","b9bd0193":"code","227165b3":"code","8867c06a":"code","e5b5d278":"code","58b0f48d":"code","f6aed2e0":"code","27addafc":"code","f1c35676":"code","7825d3ed":"code","7c5f00c4":"code","39eff110":"code","83fdcf4f":"code","fee7c14b":"code","4a7b52ce":"code","b8d3f11c":"code","19c867a1":"code","c6d950e1":"code","0042da7d":"code","01d6faa2":"code","12d26f38":"code","2911dabe":"code","f161c0fc":"code","45d4b187":"code","2c2402d5":"code","e8d0e0f4":"code","cc0e2507":"code","7abe9e2e":"code","f5f328c4":"code","1b120e90":"code","e45f81ca":"code","6c58ee89":"code","e8f7e6e8":"code","0e42d229":"code","4b03e8f0":"code","f9f3ec92":"code","56e3db13":"code","eeb7349b":"code","58da5cb2":"code","cb4c8e17":"code","d0a3ff9c":"code","f64067f0":"code","1621ca2d":"code","e7254dad":"code","183dd271":"code","389df9d9":"code","f64c6512":"code","da9a63d4":"code","66a36166":"code","4c00a285":"code","7a6faf84":"code","5aab117d":"code","96f22ef6":"code","601f685d":"code","03df96c1":"code","36d90c8b":"code","c8b84057":"code","d059729d":"code","d2760a95":"code","4f6422de":"code","e11a612a":"code","28f6b464":"code","0f891ed2":"code","e209ba7c":"code","202d82c9":"code","c18e46cc":"code","956fd9a6":"code","02613774":"code","cb33f66e":"code","358cc67a":"code","597a6b7e":"code","3f1016dd":"code","44002d66":"code","3e97c433":"code","2400aa73":"code","79cce1af":"code","2daa7033":"code","5a9189bc":"code","7e714de8":"code","da7eb4bb":"code","f5a3f562":"code","06137b58":"code","6afbc715":"code","257a1671":"code","30397306":"code","22e19676":"code","075610b1":"code","94b5b455":"code","6e3ea039":"code","950093fc":"code","63a34ef3":"code","f1bb4bcc":"code","79028a5c":"code","0e0d3012":"code","d89b947a":"code","1cd4b3c0":"code","cee7b052":"code","20637c3e":"code","940c91d6":"code","7ba7f451":"code","ab5c88eb":"code","7d3343b4":"code","6c50cbb0":"code","aea1d16a":"code","8da07dbd":"code","11f0a473":"code","393f0c68":"code","4e44b1f6":"code","73b8468c":"code","9cfcdc3c":"code","00df5537":"code","1a511dc6":"code","fdcc3122":"code","2d04386f":"code","4e8e8297":"code","c4dd602d":"code","2c278539":"code","ad294a6b":"code","e5070ee4":"code","6270ac04":"code","e8dcc3a3":"code","ee5ebc04":"markdown","b2c7598b":"markdown","88093ad7":"markdown","d69177c8":"markdown","a0ded705":"markdown","5be49a96":"markdown","5bcc24c8":"markdown","5a75550e":"markdown","58039853":"markdown","d5fddd66":"markdown","768ee629":"markdown","b4460893":"markdown","11144b68":"markdown","13a238d5":"markdown","55343f0e":"markdown","7cf01a7a":"markdown","fb22a98a":"markdown","960ee1ce":"markdown","af70c483":"markdown","093e0f5e":"markdown","d3876591":"markdown","7c2f504c":"markdown","bb565d2e":"markdown","c172b86e":"markdown","766e5580":"markdown","edbb81c3":"markdown","d7c81463":"markdown","48cf6a59":"markdown","358eb6bb":"markdown","42c803f8":"markdown","894b6be7":"markdown","4468009e":"markdown","755ab04e":"markdown","8868cff9":"markdown","cacbb688":"markdown","67e7ed6a":"markdown","e3a6743f":"markdown","a07cfdf8":"markdown","498f8686":"markdown","7876ac7e":"markdown","0562ec3f":"markdown","365a9246":"markdown","e10c9c3d":"markdown","5f6f3b8d":"markdown","1e2ce780":"markdown","c0298d41":"markdown","cf284d1c":"markdown","6a722127":"markdown","701f440c":"markdown","ed41b98e":"markdown","646fde0b":"markdown","c8f1f302":"markdown","21d2bfa4":"markdown","24b366d7":"markdown","69831d07":"markdown","71193dbf":"markdown","4f561f8e":"markdown","84c9b513":"markdown","313f3392":"markdown","4ac70c63":"markdown","3221ccec":"markdown","18c214dc":"markdown","776865c9":"markdown","77a4984a":"markdown","4e2cbe59":"markdown","41899f45":"markdown","48afccf1":"markdown","708813d0":"markdown","488dbe82":"markdown","e3bb3c8c":"markdown","1ce9710a":"markdown","e1b43419":"markdown","d891ea3b":"markdown","57d935f6":"markdown","d1d18266":"markdown","3176de03":"markdown","3b647d43":"markdown","d2dc779d":"markdown","07ee1379":"markdown","f8ea26e9":"markdown","34e99834":"markdown","f67d3524":"markdown","fef8acf6":"markdown","1eeb3ab4":"markdown","501ebd5e":"markdown","f3528bf5":"markdown","5e11337f":"markdown"},"source":{"26efc7d6":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport pandas_profiling\nfrom matplotlib import pyplot as plt\nimport matplotlib.cm as cm\nfrom pandas import Series, DataFrame\n\nsb.set(style=\"darkgrid\")","e573fb3a":"test = pd.read_csv(\"..\/input\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/train.csv\")","a590d8bc":"test.info()\nprint('---'*20)\ntrain.info()","bc4349dd":"print(\"Train is a {} by {} dataset.\".format(train.shape[0], train.shape[1]))\nprint(\"\\n\")\nprint(\"Test is a {} by {} dataset\".format(test.shape[0], test.shape[1]))","c89df43b":"print(train.isnull().sum(), sep='\\n')\nprint('-'*20)\nprint(test.isnull().sum(), sep='\\n')","58309e47":"sb.heatmap(train.isnull(), cbar = False)","78098f35":"sb.heatmap(test.isnull(), cbar = False)","92df74fe":"train.describe(include = 'all')","3c16f70b":"test.describe(include = 'all')","580a2fe2":"list(train.columns)","279e04df":"train.head()","76f8a66c":"train.drop('PassengerId', axis=1, inplace = True)\ntest.drop('PassengerId', axis=1, inplace = True)","968b5aaf":"ax1 = pd.crosstab(train.Survived, train.Pclass).plot(kind = 'bar')\nfor p in ax1.patches:\n    ax1.annotate(str(p.get_height()), (p.get_x() + 0.05, p.get_height() + 1))","185a7557":"ax2 = sb.countplot(x='Pclass', data=train)\nfor p in ax2.patches:\n    ax2.annotate(str(p.get_height()), (p.get_x() + 0.3, p.get_height() + 5))","e5bb3fe9":"train.Name","c500f28e":"pd.set_option('display.max_columns', None)  \npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)","9cdea410":"train.Name","3c195d28":"print(\"There are {} unique names in the train dataset.\".format(train.Name.nunique()))","18deef58":"train['Title'] = train.Name.str.extract(r'([a-zA-Z]+)\\.', expand=False)\ntrain.Title","ddb9d38d":"print(\"There are {} unique titles in the train dataset.\".format(train.Title.nunique()))","6ecfbeec":"train.Title.value_counts()","e0157d04":"train.loc[train.groupby('Title')['Title'].transform('size') < 10, 'Title'] = 'Others'","119a27fa":"train.Title.value_counts()","dcdc6542":"pd.crosstab(train.Survived, train.Title).plot(kind='bar')","b1809b4f":"Title_Survived=train[['Title', 'Survived']].groupby(['Title'], as_index=False) \\\n                    .mean().sort_values(by='Survived',ascending=False)\nTitle_Survived.rename(columns={'Survived':'Survival within Title Group'}, inplace = True)\n\nTitle_Survived['Title Frequency']=train.Title.value_counts(normalize=True) \\\n                    .reindex(Title_Survived.Title).tolist()\nTitle_Survived['Overall Survival']=train[train.Survived == 1].Title.value_counts(normalize=True) \\\n                    .reindex(Title_Survived.Title).tolist()","d0819073":"Title_Survived","f2765bfc":"Title_Survived.plot(kind='bar', legend=True)","6e9578f7":"train['Title']=train.Title.replace({'Mr':1,'Mrs':2,'Miss':3,'Master':4,'Others':5})","e18891ae":"train.drop('Name',axis=1,inplace=True)","e0ccad4e":"test['Title'] = test.Name.str.extract(r'([a-zA-Z]+)\\.', expand=False)","7f71c546":"test.Title.value_counts()","e38d0a72":"test.loc[test.groupby('Title')['Title'].transform('size') < 10, 'Title'] = 'Others'\ntest['Title']=test.Title.replace({'Mr':1,'Mrs':2,'Miss':3,'Master':4,'Others':5})\ntest.drop('Name',axis=1,inplace=True)","56371ea2":"train.head()","e8f17849":"test.head()","a007cd0b":"train.Sex.unique()","dc715ea3":"pd.crosstab(train.Survived, train.Sex).plot(kind='bar')","814c5f33":"train['Sex'] = train.Sex.replace({'male': 1, 'female': 0})","4d012ee2":"train.Sex.unique()","4361f309":"test['Sex'] = test.Sex.replace({'male': 1, 'female': 0})","f67982f7":"train.head()","3444d75b":"test.head()","06e6ccd1":"train['FamilySize'] = train.SibSp + train.Parch + 1 # add with one to account for that person in questions\ntrain['Alone'] = 1 # creating a new field 'Alone', intializing it to 1\ntrain.loc[train.SibSp + train.Parch > 0, 'Alone'] = 0 # those that are not alone will be set to 0","f2eed772":"pd.crosstab(train['FamilySize'], train['Survived']). \\\nplot(kind='bar', stacked=True, title=\"Survived by Family Size\")\n\npd.crosstab(train['FamilySize'], train['Survived'], normalize='index').\\\nplot(kind='bar', stacked=True, title=\"Survived by Family Size (%)\")","731d738d":"sb.kdeplot(train[train.Survived==1].FamilySize, shade=True);","6dcbbbb8":"pd.crosstab(train['Alone'], train['Survived']). \\\nplot(kind='bar', stacked=True, title=\"Survived without Family\")\n\npd.crosstab(train['Alone'], train['Survived'], normalize='index'). \\\nplot(kind='bar', stacked=True, title=\"Survived without Family (%)\")","96e329e7":"train['FamilySizeCategory'] = 1","88bd33e3":"train.loc[(train.FamilySize>= 2) & (train.FamilySize <= 4), 'FamilySizeCategory'] = 2\ntrain.loc[(train.FamilySize>= 5) & (train.FamilySize <= 7), 'FamilySizeCategory'] = 3\ntrain.loc[(train.FamilySize> 7), 'FamilySizeCategory'] = 4","958c34f2":"pd.crosstab(train['FamilySizeCategory'], train['Survived']). \\\nplot(kind='bar', stacked=True, title=\"Survived by Family Size Category\")\n\npd.crosstab(train['FamilySizeCategory'], train['Survived'], normalize='index').\\\nplot(kind='bar', stacked=True, title=\"Survived by Family Size Category (%)\")","b378fb67":"train.drop(['SibSp','Parch','FamilySize'], axis=1, inplace=True)","6c3b755e":"test['FamilySize'] = test.SibSp + test.Parch + 1 \ntest['Alone'] = 1 \ntest.loc[test.SibSp + test.Parch > 0, 'Alone'] = 0 \ntest['FamilySizeCategory'] = 1\ntest.loc[(test.FamilySize>= 2) & (test.FamilySize <= 4), 'FamilySizeCategory'] = 2\ntest.loc[(test.FamilySize>= 5) & (test.FamilySize <= 7), 'FamilySizeCategory'] = 3\ntest.loc[(test.FamilySize> 7), 'FamilySizeCategory'] = 4\ntest.drop(['SibSp','Parch','FamilySize'], axis=1, inplace=True)","2d5c625b":"train.head()","4b7d922b":"test.head()","34174f12":"print('There are {} missing values in Age field.'.format(train.Age.isnull().sum()))","8f9f12b7":"train.Age.value_counts(ascending = False)","b9bd0193":"plt.figure(figsize=(10, 6))\nsb.distplot(train.Age.dropna())","227165b3":"print('There are {} unique Age values (Null values are excluded).'.format(train.Age.nunique(dropna=True)))","8867c06a":"n = [1,5,7,10,15,20]\nplot = [0] * len(n)\nfig, axis = plt.subplots(nrows=3, ncols=2)\n\nfor i in range(len(n)):\n    bins=[j for j in range(0, train.Age.dropna().astype(int).max()+max(n), n[i])]\n    labels=[j*n[i] for j in range(1,len(bins))]\n    Age_Interval=pd.cut(train.Age, bins=bins, include_lowest=True, labels=labels)\n    pd.crosstab(Age_Interval, train.Survived).plot(kind='bar', ax=axis.flat[i], figsize=(15,15), \n                                         title = 'Age Intervals of {}'.format(n[i]))\n    plt.subplots_adjust(hspace=0.5, wspace = 0.5)","e5b5d278":"train[['Age','Survived']].groupby(['Survived']).mean()","58b0f48d":"train[['Age','Sex']].groupby(['Sex']).mean()","f6aed2e0":"train[['Age','Alone']].groupby(['Alone']).mean()","27addafc":"train[['Age','FamilySizeCategory']].groupby(['FamilySizeCategory']).mean()","f1c35676":"train[['Age','Pclass']].groupby(['Pclass']).mean()","7825d3ed":"train[['Age','Title']].groupby(['Title']).mean()","7c5f00c4":"print('The oldest person with title \\'Master\\' in the training dataset is {} years old.'\n      .format(int(train[train.Title==4].Age.max())))","39eff110":"train.loc[train.Title == 4,'Age'] = train.loc[train.Title == 4,'Age'].fillna(5)","83fdcf4f":"train[train.Title == 5].Age.isnull().sum()","fee7c14b":"train.loc[train.Title == 5,'Age'] = train.loc[train.Title == 5,'Age'].fillna(42)","4a7b52ce":"train[train.Title==3][['Age']].groupby([train.Title,train.Alone, train.Pclass]).mean()","b8d3f11c":"train.loc[(train.Title == 3)&(train.Alone == 0)&(train.Pclass == 1),'Age'] = \\\ntrain.loc[(train.Title == 3)&(train.Alone == 0)&(train.Pclass == 1),'Age'].fillna(25)\n\ntrain.loc[(train.Title == 3)&(train.Alone == 0)&(train.Pclass == 2),'Age'] = \\\ntrain.loc[(train.Title == 3)&(train.Alone == 0)&(train.Pclass == 2),'Age'].fillna(12)\n\ntrain.loc[(train.Title == 3)&(train.Alone == 0)&(train.Pclass == 3),'Age'] = \\\ntrain.loc[(train.Title == 3)&(train.Alone == 0)&(train.Pclass == 3),'Age'].fillna(10)\n\ntrain.loc[(train.Title == 3)&(train.Alone == 1)&(train.Pclass == 1),'Age'] = \\\ntrain.loc[(train.Title == 3)&(train.Alone == 1)&(train.Pclass == 1),'Age'].fillna(34)\n\ntrain.loc[(train.Title == 3)&(train.Alone == 1)&(train.Pclass == 2),'Age'] = \\\ntrain.loc[(train.Title == 3)&(train.Alone == 1)&(train.Pclass == 2),'Age'].fillna(31)\n\ntrain.loc[(train.Title == 3)&(train.Alone == 1)&(train.Pclass == 3),'Age'] = \\\ntrain.loc[(train.Title == 3)&(train.Alone == 1)&(train.Pclass == 3),'Age'].fillna(22)","19c867a1":"Title_value = [1,2]\nAlone_values = train.Alone.unique().tolist()\nPclass_values = train.Pclass.unique().tolist()","c6d950e1":"for i in range(1,len(Title_value)+1):\n    Age_TitleAloneClass = train[train.Title==i][['Age']].groupby([train.Title,train.Alone, train.Pclass]).mean()\n    for j in range(len(Alone_values)):\n        for k in range(1,len(Pclass_values)+1):\n            train.loc[(train.Title == i)&(train.Alone == j)&(train.Pclass == k),'Age'] \\\n            = train.loc[(train.Title == i)&(train.Alone == j)&(train.Pclass == k),'Age'] \\\n            .fillna(int(Age_TitleAloneClass.Age[i][j][k]))","0042da7d":"train[train.Title==2][['Age']].groupby([train.Title,train.Alone, train.Pclass]).mean()","01d6faa2":"train[train.Title==1][['Age']].groupby([train.Title,train.Alone, train.Pclass]).mean()","12d26f38":"train.Age.isnull().sum()","2911dabe":"bins=[j for j in range(0, train.Age.astype(int).max()+7, 7)]\nlabels=[j for j in range(1,len(bins))]\ntrain['AgeCategory'] = pd.cut(train.Age, bins=bins, include_lowest=True, labels=labels)","f161c0fc":"pd.crosstab(train.AgeCategory, train.Survived).plot(kind='bar')","45d4b187":"test.loc[test.Title == 4,'Age'] = test.loc[test.Title == 4,'Age'].fillna(5)\ntest.loc[test.Title == 5,'Age'] = test.loc[test.Title == 5,'Age'].fillna(42)\n\nTitle_value = [1,2,3]\nAlone_values = train.Alone.unique().tolist()\nPclass_values = train.Pclass.unique().tolist()\n\nfor i in range(1,len(Title_value)+1):\n    Age_TitleAloneClass = train[train.Title==i][['Age']].groupby([train.Title,train.Alone, train.Pclass]).mean()\n    for j in range(len(Alone_values)):\n        for k in range(1,len(Pclass_values)+1):\n            test.loc[(test.Title == i)&(test.Alone == j)&(test.Pclass == k),'Age'] \\\n            = test.loc[(test.Title == i)&(test.Alone == j)&(test.Pclass == k),'Age'] \\\n            .fillna(int(Age_TitleAloneClass.Age[i][j][k]))\n\nbins=[j for j in range(0, train.Age.astype(int).max()+7, 7)]\nlabels=[j for j in range(1,len(bins))]\ntest['AgeCategory'] = pd.cut(test.Age, bins=bins, include_lowest=True, labels=labels)","2c2402d5":"test.Age.isnull().sum()","e8d0e0f4":"train.drop('Age', axis=1, inplace=True)\ntest.drop('Age', axis = 1, inplace = True)","cc0e2507":"train.head()","7abe9e2e":"test.head()","f5f328c4":"train.Ticket","1b120e90":"train.Ticket.value_counts()","e45f81ca":"print('There are {} unique values in Ticket.'.format(train.Ticket.nunique()))","6c58ee89":"train.Ticket.value_counts()[train.Ticket.value_counts()>=3]","e8f7e6e8":"train[train.Ticket.str.extract('(?<!\\S)(\\d+)(?!\\S)', expand=False).isnull()]","0e42d229":"train.Ticket.str.extract('(?<!\\S)(\\d+)(?!\\S)', expand=False).dropna().astype(\n    str).map(len).value_counts().sort_index(ascending=False)","4b03e8f0":"Tickets_DigitsLength = \\\ntrain.Ticket.str.extract('(?<!\\S)(\\d+)(?!\\S)', expand=False).dropna(). \\\nastype(str).map(len).value_counts().sort_index(ascending=False)\n\nTickets_DigitsLength = Tickets_DigitsLength.reindex(\n    list(range(Tickets_DigitsLength.index.min(),Tickets_DigitsLength.index.max()+1)),\n    fill_value=0).sort_index(ascending=False)\n\nplt.figure()\nplt.figure(figsize=(20,10))\nax = sb.barplot([i for i in range(1,Tickets_DigitsLength.size+1)],\n            Tickets_DigitsLength.reindex(list(range(\n                Tickets_DigitsLength.index.min(),Tickets_DigitsLength.index.max()+1)),\n                                         fill_value=0), palette='hls')\n\nfor p in ax.patches:\n    ax.annotate(str(int(p.get_height())), (p.get_x() + 0.3, p.get_height() + 5), fontsize=15,\n               fontweight='bold')\n    \n\n\nax.set_title('Number of Digits in Tickets and their Frequencies')\nax.set_xlabel('Number of Digits')\nax.set_ylabel('Number of Occurance')\n\nplt.show()\n","f9f3ec92":"train.Ticket.str.extract(r'(\\d+)', expand=False).fillna(1).astype(str).map(len).max()","56e3db13":"Pclass_NumOfDigits_Corr = [0]*7 # 7 is the maximum number of digits we get in a ticket.\nfor i in range(1,8):\n    Pclass_NumOfDigits_Corr[i-1]=train.Pclass.corr(train.Ticket.str.extract(r'(?<!\\S)(\\d+)(?!\\S)', \n                expand=False).dropna().astype(str).str[0:i].astype('int64'))","eeb7349b":"plt.figure(figsize=(13,8))\nax3 = sb.barplot([i for i in range(1,8)], Pclass_NumOfDigits_Corr, palette=cm.YlGnBu(Pclass_NumOfDigits_Corr))\nfor p in ax3.patches:\n    ax3.annotate(str(p.get_height())[0:4], (p.get_x() + 0.2, p.get_height() + 0.01))\nax3.set_title('Correlation between Passenger class and Number of Digits in Ticket')\nax3.set_xlabel('Number of Digits Extracted');\nax3.set_ylabel('Correlation with Passenger Class');\nplt.ylim(0, 1)\nplt.show()","58da5cb2":"train['Ticket_FirstDigit'] = \\\ntrain.Ticket.str.extract(r'(?<!\\S)(\\d+)(?!\\S)', expand=False).fillna(0).astype(str).str[0:1].astype('int64')","cb4c8e17":"pd.crosstab(train.Ticket_FirstDigit,train.Survived).plot(kind='bar', figsize=(15,10), \n                        title='First Digit and Survival')\npd.crosstab(train.Ticket_FirstDigit,train.Pclass).plot(kind='bar', figsize=(15,10),\n                                                      title='First Digit and Passenger Class')\nplt.show()","d0a3ff9c":"digits_dict = {1:1, 2:2, 3:3, 0:4, 5:4, 6:4, 7:4, 8:4, 9:4}\ntrain.Ticket_FirstDigit.replace(digits_dict, inplace = True)","f64067f0":"train.Ticket.str.extract(r'^([^\\d]+\\d)', expand=False).replace('[^A-Za-z]', '', regex=True).value_counts()","1621ca2d":"print('There are {} that do not contain any letter in tickets'.format(\n    train.Ticket.str.extract(r'^([^\\d]+\\d)', expand=False).replace('[^A-Za-z]', '', regex=True).isnull().sum()))","e7254dad":"pd.crosstab(train.Ticket.str.extract(r'^([^\\d]+\\d)', expand=False).replace('[^A-Za-z]', '', regex=True)\n            ,train.Pclass).plot(kind='bar', figsize=(20,10), title='Ticket Letters - Passenger Class')\npd.crosstab(train.Ticket.str.extract(r'^([^\\d]+\\d)', expand=False).replace('[^A-Za-z]', '', regex=True),\n            train.Survived).plot(kind='bar', figsize=(20,10), title='Ticket Letters - Survival')","183dd271":"train['Ticket_Letter_Category']= \\\ntrain.Ticket.str.extract(r'^([^\\d]+\\d)', expand=False).replace('[^A-Za-z]', '', regex=True)","389df9d9":"Ticket_Letter_Count_Dict = train.Ticket_Letter_Category.value_counts().to_dict()","f64c6512":"train.Ticket_Letter_Category.value_counts()","da9a63d4":"Ticket_LetterCounts_dict1 = {'PC':1, 'CA':2,'A':3,'STONO':4}\n\nTicket_LetterCounts_dict2 = {k:5 for (k,v) in Ticket_Letter_Count_Dict.items() if v <= 15}\n\nTicket_LetterCounts_dict = {**Ticket_LetterCounts_dict1, **Ticket_LetterCounts_dict2}","66a36166":"train.Ticket_Letter_Category = train.Ticket_Letter_Category.replace(Ticket_LetterCounts_dict).fillna(5).astype('int64')","4c00a285":"test['Ticket_FirstDigit'] = \\\ntest.Ticket.str.extract(r'(?<!\\S)(\\d+)(?!\\S)', expand=False).fillna(0).astype(str).str[0:1].astype('int64')","7a6faf84":"test.Ticket_FirstDigit.replace(digits_dict, inplace = True)","5aab117d":"test['Ticket_Letter_Category']= \\\ntest.Ticket.str.extract(r'^([^\\d]+\\d)', expand=False).replace('[^A-Za-z]', '', regex=True)","96f22ef6":"Ticket_Letter_Count_Dict2 = test.Ticket_Letter_Category.value_counts().to_dict()\n\nTicket_LetterCounts_dict3 = {k:5 for (k,v) in Ticket_Letter_Count_Dict2.items() if v <= 15}\n\nTicket_LetterCounts_dict2 = {**Ticket_LetterCounts_dict1, **Ticket_LetterCounts_dict3}","601f685d":"test.Ticket_Letter_Category = test.Ticket_Letter_Category.replace(Ticket_LetterCounts_dict2).fillna(5).astype('int64')","03df96c1":"train.drop('Ticket', axis=1, inplace=True)\ntest.drop('Ticket', axis=1, inplace=True)","36d90c8b":"print(train.Ticket_FirstDigit.isnull().sum())\nprint(test.Ticket_FirstDigit.isnull().sum())\nprint(train.Ticket_Letter_Category.isnull().sum())\nprint(test.Ticket_Letter_Category.isnull().sum())","c8b84057":"print('There are {} unique values in Fare'.format(train.Fare.nunique()))","d059729d":"train.Fare.value_counts()[train.Fare.value_counts()>4]","d2760a95":"pd.cut(train.Fare, 6).value_counts()","4f6422de":"pd.crosstab(pd.cut(train.Fare, 6),train.Survived)","e11a612a":"pd.crosstab(pd.cut(train.Fare, 6),train.Pclass)","28f6b464":"pd.qcut(train.Fare, 6).value_counts()","0f891ed2":"pd.crosstab(pd.qcut(train.Fare, 6),train.Survived)","e209ba7c":"pd.crosstab(pd.qcut(train.Fare, 6),train.Pclass)","202d82c9":"FareCategory, bins = pd.qcut(train.Fare, 6, labels=[i+1 for i in range(6)], retbins=True)","c18e46cc":"train['FareCategory'] = FareCategory","956fd9a6":"test[test.Fare.isnull()]","02613774":"test[(test.Sex==1) & (test.Pclass==3) & (test.Title==1) & (test.Ticket_FirstDigit==3) & \n     (test.Ticket_Letter_Category==5)].Fare.mean()","cb33f66e":"test.Fare.fillna(9, inplace=True)","358cc67a":"test.isnull().sum()","597a6b7e":"test['FareCategory'] = pd.cut(test.Fare, bins=bins, labels=[i+1 for i in range(6)])","3f1016dd":"test.FareCategory.isnull().sum()","44002d66":"test[test.FareCategory.isnull()]","3e97c433":"test.FareCategory.fillna(1, inplace=True)","2400aa73":"train.drop('Fare', axis=1, inplace=True)\ntest.drop('Fare', axis=1, inplace=True)","79cce1af":"train","2daa7033":"train.Cabin","5a9189bc":"print('Cabin has {} missing values and {} unique values'.format(train.Cabin.isnull().sum(),train.Cabin.nunique()))","7e714de8":"train.Cabin.str.extract('([A-Za-z]?)')[0].value_counts()","da7eb4bb":"pd.crosstab(train.Cabin.str.extract('([A-Za-z]?)')[0], train.Survived).plot(kind='bar')","f5a3f562":"pd.crosstab(train.Cabin.str.extract('([A-Za-z]?)')[0], train.Pclass).plot(kind='bar')","06137b58":"train.Cabin.str.extract('(\\d{1})')[0].value_counts()","6afbc715":"pd.crosstab(train.Cabin.str.extract('(\\d{1})')[0], train.Survived).plot(kind='bar')","257a1671":"pd.crosstab(train.Cabin.str.extract('(\\d{1})')[0], train.Pclass).plot(kind='bar')","30397306":"Cabin_Dictionary = {'A':1, 'B':2, 'C':2, 'D':2, 'E':2, 'F':2, 'G':1, 'T':1}","22e19676":"set(train.Cabin.str.extract('([A-Za-z]?)')[0].unique()).difference(\n    set(test.Cabin.str.extract('([A-Za-z]?)')[0].unique()))","075610b1":"set(test.Cabin.str.extract('([A-Za-z]?)')[0].unique()).difference(\n    set(train.Cabin.str.extract('([A-Za-z]?)')[0].unique()))","94b5b455":"train.Cabin.fillna('T', inplace=True)\ntest.Cabin.fillna('T', inplace=True)","6e3ea039":"train['Cabin'] = train.Cabin.str.extract('([A-Za-z]?)')[0].replace(Cabin_Dictionary)","950093fc":"test['Cabin'] = test.Cabin.str.extract('([A-Za-z]?)')[0].replace(Cabin_Dictionary)","63a34ef3":"train","f1bb4bcc":"train.Embarked.value_counts()","79028a5c":"pd.crosstab(train.Embarked, train.Survived).plot(kind='bar')","0e0d3012":"pd.crosstab(train.Embarked, train.FareCategory).plot(kind='bar')","d89b947a":"pd.crosstab(train.Embarked, train.FamilySizeCategory).plot(kind='bar')","1cd4b3c0":"pd.crosstab(train.Embarked, train.Sex).plot(kind='bar')","cee7b052":"pd.crosstab(train.Embarked, train.Pclass).plot(kind='bar')","20637c3e":"train[train.Embarked.isnull()]","940c91d6":"train[(train.Survived == 1) & (train.Sex == 0) & (train.Alone == 1) & (train.Ticket_FirstDigit == 1) & \n      (train.FareCategory == 6)].Embarked.value_counts()","7ba7f451":"train.Embarked.fillna('C', inplace = True)","ab5c88eb":"Embarked_Dictionary = {'C':1, 'Q':2, 'S':3}","7d3343b4":"train.Embarked.replace(Embarked_Dictionary, inplace = True)\ntest.Embarked.replace(Embarked_Dictionary, inplace = True)","6c50cbb0":"train.Pclass","aea1d16a":"print(train.isnull().sum(), sep='\\n')\nprint('-'*20)\nprint(test.isnull().sum(), sep='\\n')","8da07dbd":"from sklearn.metrics import accuracy_score","11f0a473":"X_train = train.drop(['Survived'], axis=1)\ny_train = train[\"Survived\"]\nX_test  = test.copy()\nX_train.shape, y_train.shape, X_test.shape","393f0c68":"# Support Vector Machines\nfrom sklearn.svm import SVC\n\nsvc = SVC(gamma='auto')\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_train)\nacc_svc = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_svc)","4e44b1f6":"# Linear SVC\nfrom sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC(loss='hinge', max_iter=10000)\nlinear_svc.fit(X_train, y_train)\ny_pred = linear_svc.predict(X_train)\nacc_linear_svc = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_linear_svc)","73b8468c":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier(n_estimators=200,max_depth=7)\nrandomforest.fit(X_train, y_train)\ny_pred = randomforest.predict(X_train)\nacc_randomforest = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_randomforest)","9cfcdc3c":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecisiontree = DecisionTreeClassifier(max_depth=6, max_features='log2')\ndecisiontree.fit(X_train, y_train)\ny_pred = decisiontree.predict(X_train)\nacc_decisiontree = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_decisiontree)","00df5537":"# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier(n_iter_no_change=10, early_stopping=True)\nsgd.fit(X_train, y_train)\ny_pred = sgd.predict(X_train)\nacc_sgd = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_sgd)","1a511dc6":"# KNN or k-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=4, algorithm='brute')\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_train)\nacc_knn = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_knn)","fdcc3122":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=2, penalty='l2', max_iter = 1000)\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_train)\nacc_logreg = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_logreg)","2d04386f":"# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_train)\nacc_gaussian = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_gaussian)","4e8e8297":"# Perceptron\nfrom sklearn.linear_model import Perceptron\n\nperceptron = Perceptron(max_iter=1000, n_iter_no_change=5)\nperceptron.fit(X_train, y_train)\ny_pred = perceptron.predict(X_train)\nacc_perceptron = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_perceptron)","c4dd602d":"# Gradient Boosting Classifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier(n_estimators=200, learning_rate=0.5)\ngbk.fit(X_train, y_train)\ny_pred = gbk.predict(X_train)\nacc_gbk = round(accuracy_score(y_train, y_pred) * 100, 2)\nprint(acc_gbk)","2c278539":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n    'Score': [acc_svc, acc_knn, acc_logreg, \n              acc_randomforest, acc_gaussian, acc_perceptron,acc_linear_svc, acc_decisiontree,\n              acc_sgd, acc_gbk]})\nmodels.sort_values(by='Score', ascending=False)","ad294a6b":"SubmissionPrediction = logreg.predict(test)","e5070ee4":"PassengerId = [i for i in range(892,1310)]","6270ac04":"SubmissionPrediction_df = pd.DataFrame({'PassengerId': PassengerId, 'Survived':SubmissionPrediction })\nSubmissionPrediction_df.head()","e8dcc3a3":"SubmissionPrediction_df.to_csv(\"Submission.csv\", index = False)","ee5ebc04":"Now we apply the same changes to the train data set to be consistent.","b2c7598b":"Finally relationship between title and age is interesting. First let's remind ourselves about titles.\n\n<code> test['Title']=test.Title.replace({'Mr':1,'Mrs':2,'Miss':3,'Master':4,'Others':5}) <\/code>\n\nA very obvious observation is that those with title Master are very young. ","88093ad7":"Next we come across the <i>Pclass<\/i> field. This is a \"A proxy for socio-economic status (SES)\n<br> 1st = Upper\n<br> 2nd = Middle\n<br> 3rd = Lower\"\n<br>Let's explore more.","d69177c8":"And a quick sanity check.","a0ded705":"We can check if the code worked as intended.","5be49a96":"We note two values with Fare = 0 have not been categorized. They obviously belong to FareCategory = 1 and we can assign them now.","5bcc24c8":"# Explanatory Analysis - Getting to Know the Data and Feature Engineering ","5a75550e":"We can see right away that this field has many unique values so probably we need to categorize them. Again, there are many available options; however, I suggest looking into two options:\n<ol>\n<li>Diving them into groups of the same size, so for instance the cheapest 50 fares will be grouped together and then the next 50 together and so on.<\/li>\n<li>Diving them based on thresholds, so for instance those who paid a fare of less than 50 will be placed in one group and those that are in range [50, 100) in another group and so on.<\/li>\n<\/ol>\n\nWe will try to group them into 6 categories in each option and we will examine the findings for each case. I choose 6 because there are 3 Passenger Classes and choosing a number too close to 3 may make this field redundant. \n\n<b>Option 1:<\/b>","58039853":"The name of indivuals are irrelevant when it comes to survival. That is if a person's name is John, it does not really help us to determine whether John survived. It may give us the gender of the person, but we already have the Sex field. However, Name contains the title of people (i.e. Mr., Mrs.). That can give us more insight. First we need to extract them. Fortunately, we can tell the data is clean and all the titles are before a '.'. Therefore, we need to extract those characters that come before the dot. We are going to use some Regular Expression (re) technique for this part.","d5fddd66":"Let's see how many unique names are in the dataset.","768ee629":"As it can be seen, there is a a great survival rate for those in the second family size and no survival for number 4. Categories number 1 and 3 are really close. To avoid overfitting our modelling, we will drop <i>Family Size, SibSp<\/i> and <i>Parch<\/i> field and keep <i>Alone<\/i> and <i>Family Size Category <\/i> fields. Keeping <i>Alone<\/i> can help to distinguish between family size category 1 and 3 when training the model.","b4460893":"Now we can drop the <i>ticket<\/i> field and apply the same changes to test data set.","11144b68":"Next category we are going to look into is <i>Age<\/i>. As noted earlier, <i>Age<\/i> has many missing values and this is something that need to be addressed.","13a238d5":"So we can see majority of people with similar features are coming from Cherbourg, therefore we assign them that port for embarkation.","55343f0e":"Therefore, we can start to fill in missing ages for those with 'Master' title. Their average age is 4.5 years old, so we will assign them an age of 5 for those that are missing age.","7cf01a7a":"There does not seem to be much for exploration here; however, I will include a few plots and I will assign values 1, 2 and 3 to these three ports.","fb22a98a":"Now we are going to train our model using various Machine Learning techniques and compare the results at the end.\n\n","960ee1ce":"The preliminary analysis shows there are various groups of letters in ticket. Also majority of tickets do not contain a letter. Let's do some more exploration. For now we are going to keep all these groups of letters, keeping in mind we would put more emphasis on the number occurance of those groups. ","af70c483":"Now we are going to plot Title vs. Survived to see if we can determine any pattern.","093e0f5e":"Now we are going to make the feature ordinal and apply the same changes to the test data set.","d3876591":"For now, we will ignore missing values. \n<br>Leaving <i>Age<\/i> as-is is fine; however, following the same idea for creating <i>FamilySizeCategory<\/i>, we try to create <i>AgeCategory<\/i> feature based off of <i>Age<\/i>. We need to decide how we would like to cut off ages. Again, there are many options to go about this, but I propose to group them by age intervals. So for instance we can divide passengers based on their age group by 1, 5 or 10 years.\n<br> The next point to resolve is to choose a good number that capture important aspects. To this end, we can plot various age groups to get a better idea.","7c2f504c":"We can see those that are alone have a higher average age. Those that are with family have a lower average age which might be due to having kids that are younger.","bb565d2e":"After <i>PassengerId<\/i> we have the <i>Survived<\/i> field. This is a very important field filled with 0 and 1's, indicating whether a person survived the incident or not. Train dataset contains this field, but not test dataset. Our eventual goal is to predict those values for the test dataset.","c172b86e":"We make note that Age, Cabin and Embarked have missing values in train dataset and Age, Fare and Cabin have missing values in Test dataset. We can also visualize this using Seaborn.","766e5580":"# Training Model and Sumbission","edbb81c3":"There are some interesting observations we can make:\n<li> Majority of tickets begin with digits 1,2 and 3.<\/li>\n<li> Majority of ticket holders that their tickets begin with 1 belong to the upper class passengers. <\/li>\n<li> Majority of ticket holders that their tickets begin with 2 belong to the middle class passengers. <\/li>\n<li> Majority of ticket holders that their tickets begin with any other numbers belong to the upper class passengers. <\/li>\n<li> Tickets that begin with 1 is the only set of tickets and the number of survivals are higher than those that did not (with exception of tickets that begin with 9. We note there are not many of them.)<\/li>\n\nBased on these observations, we can group tickets into four categories\n<ol>\n    <li>Tickets that begin with 1.<\/li>\n    <li>Tickets that begin with 2.<\/li>\n    <li>Tickets that begin with 3.<\/li>\n    <li>Tickets that begin with any other number.<\/li>\n<\/ol>","d7c81463":"### Importing Libraries","48cf6a59":"We can see passengers that are in the Upper class are more likely to survive.","358eb6bb":"Surprisingly two values have not been categorized, which might be due to an issue with binning. We can look more into them now.","42c803f8":"We see majority of passengers that have their cabin information available are from the Upper class and many of them survived too.\n\nLet's extract first digtis now.","894b6be7":"Just a quick sanity check that everything is working as intended.","4468009e":"Now we do the same for the test data set.","755ab04e":"Average age based on survival is very close.","8868cff9":"Making changes to Test dataset","cacbb688":"Our first observation is that men are less likely to survive. We should expect to see a low rate of survival for men once we examine <i>Sex<\/i> field. More women survived than those that did not.\n\nNow we will examine the survival rate within a specific group, title frequency and overall survival rate based on each title. \n\n<ul>\n<li>Survival rate within a specific title group tells how many people of that title survived among themselves. For instance 79% of those that had a title 'Mrs' survived. <\/li>\n<li>Title Frequency tells us how many passengers had that specific title. For instance, only 4% of those in the traininig set were 'Master'. <\/li>\n<li>Overall Survival shows us survival rate in comparison to other groups. For instance, about 24% of survivals were titled 'Mr'. As we will see, only 23% of them were among the survivals. <\/li>\n<\/ul>\n\nYou should note Title Frequency and Overall Survival should add up to 1, while Survival within Title Group need not.","67e7ed6a":"A quick sanity check to make sure everything looks good so far.","e3a6743f":"It is safe to run the following code. If value counts for any of the values that were less than 10 in the train data set was more than 10 for the test data set, then we needed to pass in a dictionary. Passing in a dictionary is usually a more robust method.","a07cfdf8":"We are going to follow the same idea for those with Title 'Mr' and 'Mrs'. We can code this to speed up the process.","498f8686":"Now we can analyze <i>Cabin<\/i>, while noting it has many missing values.","7876ac7e":"Since there is only one indivdual with missing age in that group we can just assign 42 to it.","0562ec3f":"At this point we must have taken care of the missing age values. A quick sanity check that there is no other missing age:","365a9246":"We have analyzed all the features and now we will get started with training our models.","e10c9c3d":"We can see there is a strong correlation between Passenger Class and the first four number of digits on the ticket. Since the difference in correlation between the first digit and the first four digits is minimal, we will work with the first digit of the ticket going forward.\n\nWe are going to create a new field <i>Ticket_FirstDigit<\/i> that has the first digit as it appear on the ticket. To address the missing values (i.e. those that do not have digits), we assign the value of 0 for now. Let's see the relation of this field with survival and passenger class.","5f6f3b8d":"Now we get to <i>SibSp<\/i> and <i>Parch<\/i> fields. These are already numerical fields. According to the competition description:\n\n<ul>\n<li>sibsp: The dataset defines family relations in this way...\n<br>Sibling = brother, sister, stepbrother, stepsister\n<br>Spouse = husband, wife (mistresses and fianc\u00e9s were ignored) <\/li> <br>\n<li>parch: The dataset defines family relations in this way...\n<br>Parent = mother, father\n<br>Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them. <\/li>\n<\/ul>\n\nAmong various ways in regards to analysis of these two fields, here are three suggestions: \n<ol>\n<li>Combine the two fields and determine the family size of each individual.<\/li>\n<li>Determine if each person is alone <code> (SibSp + Parch = 0) <\/code> or not.<\/li>\n<li>Find people with the same last name to determine their family. This can get complicated since there might be people with the same last name but not from the same family or people that are part of one famliy but have different last names. <\/li>\n<\/ol>\n\nWe will utilize the first two suggestions. That is, we determine family size and whether each person is alone by him\/herself.","1e2ce780":"Parallel to previous point, the bigger the family size the lower average age becomes.\n\n","c0298d41":"Now we get to the last four features in this dataset:\n<li>Ticket<\/li>\n<li>Fare<\/li>\n<li>Cabin<\/li>\n<li>Embarked<\/li>\n\nLet's do some preliminary analysis on the Ticket field.","cf284d1c":"Extracing first digits may not tell us much this time.\n\nBased on the analysis we have done we can group cabins whose first letters correspond to more survivals than those that lost their lives into one (B, C, D, E, F) and the rest including those with missing values in another group. We will ingore first digits.","6a722127":"It appears some tickets are numeric values only and some other are alphanumeric. There is also a ticket 'LINE' that is alphabetical. \n\nLet's extract digits and letters for each ticket where applicable and generate some plots for further insights.\n\nFirst we will examine how many tickets do not contain any digits. We have already found tickets with 'LINE'. However, we need to solidify our observation.","701f440c":"We can see a lot of values occur less than 10 times. We can replace those titles with 'Others' instead.","ed41b98e":"As mentioned before, we are going to group age in 7 years interval now and create a new field <i>AgeCategory<\/i> instead.","646fde0b":"We can see <i>PassengerId<\/i> field is just an identifier and is irrelevant in determining if a person survives. Thefore, we can drop it for the rest of the analysis.","c8f1f302":"We can see after filling in the missing values, the plot kept its shape which can be a good sign. Now we can drop <i>Age<\/i> field and apply the same changes to the test dataset. ","21d2bfa4":"Now we can extarct letters and see if we can find any insights.","24b366d7":"We can see some name are trimmed with ... We can fix that by setting the following parameters.","69831d07":"And that matches our intuition. Now let's see their frequencies.","71193dbf":"The higher the passenger class the higher average age becomes.","4f561f8e":"Reminder of value counts:","84c9b513":"Similar to <i>Ticket<\/i>, <i>Cabin<\/i> is also formed by letters and digits. Let's extract letters and first digits as before.","313f3392":"We observe by grouping Fare into equal widths, majority of passengers are in the first group. It is interesting to see as soon as we move on to the second group of Fare size and onwards, all the passengers belong to Upper Class and most of them survived as well.\n\nLet's do the same analysis, this time with (almost) equal sizes.\n\n<b>Option 2:<\/b>","4ac70c63":"It appears there are 4 tickets in total that do not contain any digists and they are all denoted as 'LINE'. It is intersting to note that all of those passengers are in the lower socio-economic class, male, alone and embarked from the same place.\n\nFor now we will ignore these rows when extracting numbers from tickets. Next we will look into the number of digits and group them like that. So for instance we want to know the frequency of tickets with only one digit, two digits and so forth. As you might have noticed, some of the tickets that contain letters have digits in one group and another group of digist seperated by a space. The first row, for example, the ticket number is 'A\/5 21171'. For this part, we only extract digits after the space. So when we extract digits, we will get '21171' and not '52271'. Let's explore now.","3221ccec":"We can drop <i>Fare<\/i> now.","18c214dc":"For reference, these are the values that are assigned.","776865c9":"We note most of tickets are 6 digits long. We can visualize this with a barplot as well; however, note there is no 2 digit long ticket. Therefore we need to take care of that first. We do this by adding index 2 and assign the value of 0 to it. ","77a4984a":"By examining these plots, we can observe majority of passengers embarked from Cherbourg survived and they were in the upper class. We are going to replace these ordinal values. We also note there are misssing values in Embarked that needs to be addressed. As before, we will try to replace these values with information of passengers that share similar features.","4e2cbe59":"Now we are going to visualize the effects of family size and being alone on Survival.","41899f45":"By examing title and age we can also note those with title 'Miss' are relatively younger compared to those with titles 'Mr' and 'Miss'. We can dig deeper into this category by considering their Passenger Class and whether they were travelling by themselves.","48afccf1":"While these plots may be difficult to interpret, it is interesting to see that some letters in the ticket can easily determine the Passenger Class. For instance any tickets that starts with 'PC' correspond to upper level class and most of those passengers survived. On the other hand, passengers whose tickets begin with 'A' were from the lower class and they did not have a good chance of surviving.\n\nIt might be plausible to extract only the first letter in each ticket as we did for digits; however, I will keep these groups as they are and only consider those that occur more than 15 times. The rest, including the ones that do not contain a letter will placed in the same category.","708813d0":"Average age based on gender is also very similar, with men being slightly older than women.","488dbe82":"At this point we recall Fare has a missing value for the test data set. We will try to fill in the missing value by examining other passengers who share similar features.","e3bb3c8c":"### Importing CSV Files","1ce9710a":"While there are more passengers in Lower class, the number of survivors from the Upper class is more than Lower class. This goes to show the Passenger Class is an important feature and we will keep it. Since it's already in numercial format, no further manipulation is required.","e1b43419":"If you have made it this far, thank you! \ud83d\ude09\n\nI have taken advatange of many available online resources to publish this notebook, including some on Kaggle. I am by no means an expert in the subject. Please feel free to share your comments and thoughts and any feedback on how I can improve.\n\nThanks! \ud83d\ude4f","d891ea3b":"We analyzed <i>Title<\/i> field, which was derived from the Name field. Before moving on, we need to change this categorical variable to an ordinal so we can run models later. <i>Name<\/i> field can be dropped. In short, we should handle all the fields that have string and have some numerical values for them. \n<br> Also any changes  we make to train data set must be made to the test data set.","57d935f6":"Making sure Cabin's first letters in the test data set is in train data set.","d1d18266":"This confirms our observations when we were examining <i>Title<\/i>. Females were more likely so survive than men.\n\nWe can binarize our variable now.","3176de03":"Now can move on from <i>Ticket<\/i> and explore the next field, <i>Fare<\/i>","3b647d43":"Now let's look more into the next field, <i>Name<\/i>.","d2dc779d":"Next we are going to examine <i>Sex<\/i> field.","07ee1379":"We can observe when set a interval of 1 year, the plot becomes difficult to interpret. Similarly, grouping passengers to 20 year age groups is not that informative. Based on available plots, grouping by intervals of 7 years seem to capture essentials. Cutoffs of 5 and 10 are also good choices.\n\n<br> The plots also tells us young passengers were likely to survive.\n\nNow before creating <i>AgeCategory<\/i> field, we should fill in <i>Null<\/i> values in <i>Age<\/i>. Again, there are many possibilities. A very simple and quick yet effective method would be to utilize mean or median age. I'd suggest builiding upon this idea and consider other available features to determine the missing ages. \n\nWe can create different tables for a deeper understanding. First we start with age and survival.","f8ea26e9":"The next step would be to decide how many digits are important. If we keep all the digits, maybe we will not get a accurate picture. So we need to find the sweet spot. While noting that there might be correlation between number of digits with fields like Sex and Alone, we only put our focus towards number of digits and Passenger Class. One may expect there would be a correlation between the two. Let's explore this idea.","34e99834":"Based on these values we can make the following assignments for missing ages:","f67d3524":"Now let's see how many unique titles there are in the dataset. We should expect a number much lower than 891, the number of unique names.","fef8acf6":"Based on these plots, we can group family size to 4 seperate categories:\n<ol>\n    <li>Family Size is 1<\/li>\n    <li>Family Size is between 2 and 4 inclusive. <\/li>\n    <li>Family Size is between 5 to 7 inclusive.<\/li>\n    <li>Family Size is greater than 7. <\/li>\n<\/ol>\n\nThe reason for this is that we see a pattern for survival based on the size of the family. The bigger the family the less likely they are to survive. The 'medium' sized families (2 to 4) are most likely survive.\n\nTherefore we can create a new field <i>FamilySizeCategory<\/i> to account for that. We will visualize to see the results","1eeb3ab4":"This time we see the widths of our bins change drastically. There are 156 passengers that paid between 0 to 8 and there are 149 passengers that paid between ~52 to 512. One observation between the two kinds of analysis we have done remains the same and that is the more expensive the ticket, the more likely passengers survive. \n\n<br> I will go ahead with the second option and use that category, since it has more variety in Passenger Class. For the most part, groups are not inclusive to a certain class as in option 1 and apply the same changes to the Test data set while making sure we put them into same bins.","501ebd5e":"We get to the last field, <i>Embarked<\/i>. By description, embarked indicates port of embarkation:\n<li>C = Cherbourg<\/li>\n<li>Q = Queenstown<\/li>\n<li>S = Southampton<\/li>","f3528bf5":"Besides, those with title 'Others' have relatively higher age. Let's see how many of them are missing age.","5e11337f":"All names are unique as expected."}}