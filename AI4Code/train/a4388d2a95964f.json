{"cell_type":{"3abaa469":"code","96c62949":"code","270e6880":"code","4a96d084":"code","23d9272c":"code","39b5b630":"code","323ea5bb":"code","ed4d6866":"code","6ecea6e0":"code","63e849b5":"code","e4cffb72":"markdown","e65ab503":"markdown","c5eac4c6":"markdown","338a3cc0":"markdown","f3b439cb":"markdown","c61e1ec3":"markdown","2891460e":"markdown","f6285115":"markdown","ce3acbec":"markdown","d4ee46ec":"markdown","12454ec7":"markdown","dd909556":"markdown","6039bcfe":"markdown"},"source":{"3abaa469":"# Preliminaries\nimport pandas as pd\nimport numpy as np\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom category_encoders import CountEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.multioutput import MultiOutputClassifier\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","96c62949":"SEED = 42\nNFOLDS = 5\nDATA_DIR = '\/kaggle\/input\/lish-moa\/'\nnp.random.seed(SEED)","270e6880":"train = pd.read_csv(DATA_DIR + 'train_features.csv')\ntargets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n\ntest = pd.read_csv(DATA_DIR + 'test_features.csv')\nsub = pd.read_csv(DATA_DIR + 'sample_submission.csv')","4a96d084":"# drop id col\nX = train.iloc[:,1:].to_numpy()\nX_test = test.iloc[:,1:].to_numpy()\ny = targets.iloc[:,1:].to_numpy() ","23d9272c":"classifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\nclf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', classifier)\n               ])","39b5b630":"params = {'classify__estimator__colsample_bytree': 0.6522,\n          'classify__estimator__gamma': 3.6975,\n          'classify__estimator__learning_rate': 0.0503,\n          'classify__estimator__max_delta_step': 2.0706,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.5800,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8639\n         }\n\n_ = clf.set_params(**params)","323ea5bb":"oof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((test.shape[0], y.shape[1]))\noof_losses = []\nkf = KFold(n_splits=NFOLDS)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    \n    # drop where cp_type==ctl_vehicle (baseline)\n    ctl_mask = X_train[:,0]=='ctl_vehicle'\n    X_train = X_train[~ctl_mask,:]\n    y_train = y_train[~ctl_mask]\n    \n    clf.fit(X_train, y_train)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds \/ NFOLDS\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))","ed4d6866":"# set control train preds to 0\ncontrol_mask = train['cp_type']=='ctl_vehicle'\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))","6ecea6e0":"# set control test preds to 0\ncontrol_mask = test['cp_type']=='ctl_vehicle'\n\ntest_preds[control_mask] = 0","63e849b5":"# create the submission file\nsub.iloc[:,1:] = test_preds\nsub.to_csv('submission.csv', index=False)","e4cffb72":"# About this Notebook\n\nHello everyone ,\n<br>Its been long since I have written a detailed notebook in the way I love to and I was itching to do so. Kaggle competitions can be very intimidating at times given they not only need good machine learning skills but also heavy domain knowledge. People always ask me how and where to start with kaggle , how do I manage to do good in competitions which require heavy domain knowledge , What level of knowledge do we need before starting a Kaggle competition ,etc . This notebook is meant to answer all those questions and is specially for anyone who wants to start with live competitions but is overwhelmed by the shear amount of things that a live competitions bring to the table. I was thinking of writing this from a long time now , but I was waiting for the right competition and here we have it , \"good old tabular competition\" which is a rare sight at kaggle.\n\nSo without any further delay if you want to get started with live kaggle competitions or want to do good in kaggle competitions or need a detailed pathway on approaching kaggle competitions,etc , be sure to stick with me till the end of this notebook as <br>\n<b> This is a step by step guide on How to Tackle Any Kaggle Competition : The Noob's Way <\/b>\n\n<font color='orange'>Note :- This notebook is a part of my Series : Mr KnowNothing's Weekends , in which I have planned a lot of more things ,if you liked this notebook and are interested in more such content you can know more about the series and follow along<\/font> [here](https:\/\/github.com\/tanulsingh\/Mr_KnowNothing-s-Weekends) \n\n<b> Important Note : All the steps\/advices which I give in this notebook are from my personal experience and contain methods which I personally use. \nI still consider myself a Kaggle Noob who is trying to learn,hence everything which I write might not be the optimal way , its just a guide to help people, I request all Kagglers to correct me in the comments if they feel there might be a better approach for what I am following now . I would really appreciate views of other Kagglers \n    , Thanks<\/b>","e65ab503":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of Contents<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#data\" role=\"tab\" aria-controls=\"profile\">Phases of Kaggle\/Competitive Data Science<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#data\" role=\"tab\" aria-controls=\"profile\">My Advice on \"How to get Started with Kaggle\"<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#down\" role=\"tab\" aria-controls=\"messages\">Step 1 : Understanding the Problem Statement and Gathering Basic(Initial Domain Knowledge) Domain Knowledge<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#melt\" role=\"tab\" aria-controls=\"settings\">Step 2 : Understanding the Evaluation Metric <span class=\"badge badge-primary badge-pill\">4<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#eda\" role=\"tab\" aria-controls=\"settings\">Step 3: Exploratory Data Analysis ,Advanced Domain Knowledge Gathering and Choosing a Reliable CV<span class=\"badge badge-primary badge-pill\">5<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#fe\" role=\"tab\" aria-controls=\"settings\">Step 4: Setting up a Baseline and Gathering All your ideas in One place<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#pred\" role=\"tab\" aria-controls=\"settings\">Step 5: Skimming through all the dicussion threads and Notebooks , writing down the Ideas to try<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#pred\" role=\"tab\" aria-controls=\"settings\">Step 6: Perform Experiments and repeat<span class=\"badge badge-primary badge-pill\">8<\/span><\/a>","c5eac4c6":"`Now We Know most of things there was to , data wise and domain knowledge wise , its time to dive into actual Machine Learning Now , Let's build a proper relieable Cross Validation`\n\nWhat is actually a Relieable Cross Validation?\n\n* A relieable CV is something which resembles the test set as best as it can and has a high positive correlation with LB . [Here](https:\/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/159565) is a discussion thread where  GM's answer as to what is a reliable CV.\n\n* In public kernels most of the People are using multilabelStratifiedKfold As a CV strategy which feels ohk if we go by simple definition of stratifying the folds so that every label is equally represented but the problem lies for the labels which have very low Positive classes as seen in the EDA.\n\n* One more thought could be to do a GroupKfold after clustering as we know that the 23k data points have only 5k Unique drugs , so If we can somehow cluster those 5k unique drugs we will have all experiments for a single drug in one place and that opens a whole lot of possibilities and then we can also do groupkfold . Unfortunately since the data is scaled we were not able to cluster the data points effectively and hence had to drop the idea of groupkfold by clusters.\n\nFor now we have also settled for MUltilabelStratifiedKfold , I will update this notebook if I get any other Idea\n\nNow its time for step 4","338a3cc0":"# <a id='data'>Step 1 : Understanding the Problem Statement ,Gathering Basic(Initial Domain Knowledge) Domain Knowledge and Data<\/a>\n\nThe most important thing before starting any competition is to understand the Problem statement and see if it is something you can solve and are interested in . Then if it ticks all your boxes you can dive in , for me I think MoA is a gem of competition to learn and perfect your tabular data skills . \n\n` Now how do you analyze the problem statement ?`\n* You go through the description section , the Data section and sometimes present additional information section on the competition page . The idea is to ask questions about each and every thing , one at a time , googling everything \n\n` Below is step by step analysis of how I would have done it`:\n* We have to predict the Mechanism of Action of a drug , sounds simple , but what is mechanism of action of a drug? I tried to understand the definition from the description section , but its not really clear , ohk let me try google instead or perhaps a youtube video might help\n\nThe term \"mechanism of action\" is a pharmacological term commonly used when discussing medications or drugs. It refers to how the drug works on a molecular level in the body. -- GOOGLE\n\n* Ohk so I now Understand what is MoA of a drug. But how it is measured in quantitative terms so that I can predict it using ML?\n\nThis part is clear from the description itself , the approach is to treat a sample of human cells with the drug and then analyze the cellular responses with algorithms that search for similarity to known patterns in gene expression or cell viability patterns of drugs with known MoAs. \n\n* Great now its more clear , let's move on to see what we are given as data\n\nIn this competition, I will be predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data. It's important to note that its mentioned we are predicting MoA responses of different samples and not particularly mentioned that the samples are all unique drugs . Also in the description section they have mentioned that there are 5000 drugs whereas in the trainin set there are 23k data points \n\n* So now we have got the clear picture of what we have and we need to do . Given the gene expression features and cell viability features we have to predict the MoA responses of various samples. This is multiclass multilabel problem\n\nThis concludes our initial analysis and domain knowledge as for diving deep into what are the gene expression features , what do they mean , etc , we will explore each and every section in advanced Domain knowledge gathering step , for now its time for my step 2","f3b439cb":"# <a id='data'>Step 6: Perform Experiments and repeat <\/a>\n\nNow to win a silver and a gold in a Kaggle competition rely lies on following things (aside from forking of public kernel and having a bit of luck):\n* Having Unique Ideas \n* Doing a lot of experiments , reading a lot of new papers , thinking creatively and applying all those idea\n* Having a strong Cross Validation\n* Making a Stable Ensemble on that Cross Validation\n* And a lot of Dedication","c61e1ec3":"# Conclusion\n\nThanks for reading my notebook , I tried my best to share my experience with you of how I approach any problem on Kaggle , I hope that you find it helpful in some way , Please let me know in the comment sections if you follow the same strategy or where are the room for improvements etc\n\nAlso this is the first Notebook in my series in which I will be publishing articles like these every weekend so if you liked it , you can follow along with the github link on the top of this Notebook\n\nThanks","2891460e":"# <a id='data'>Step 3: Exploratory Data Analysis ,Advanced Domain Knowledge Gathering and Choosing a Reliable CV <\/a>\n\nIts about time that we kick-start a kernel and get a feel of the data , EDA helps to create questions about the data as well as answer them and that eventually leads to Advanced Domain Knowledge Gathering ","f6285115":"# <a id='data'>Phases of Kaggle\/Competitive Data Science<\/a>\n\nIn this section I try to answer <b>How to get started with Kaggle<\/b> as before learning how to tackle a competitive problem you should know where to begin right. In my experience , I feel there are following four stages of Kaggling or Competitve Data science for anyone :\n\n* Noobie\n* Had the Feel \/Intermediate \n* Seasoned\/Pro\n* Elite\n\nLet me frame a clear definition for each of the above so that you know on which stage you are currently in :\n\n### Noobie\nYou are a Noobie if :\n* you have read about data science and are really excited to start with it , but you are not sure how to...\n* you have just started your data science journey , have done some courses and now you are not sure where to go...\n* you have good knowledge of python but are getting started with data science \n* you are switching from a different background alltogether\n\nThere can be many more scenarios but you get the idea right?\n\n### Had the Feel \/ Intermediate\nYou are at intermediate level if:\n* you have participated in other hackathons on other smaller platforms like Analytics Vidhya , MachineHack ,Zindi ,etc but are afraid of Kaggle\n* you are good with tabular data competitions , EDA ,etc but are afraid of kaggle\n* you have done beginner level projects and now want to try your hands at real competitions, etc \n\n### Seasoned \/ Pro\nYou are a Pro if:\n* you have participated in Competitions before on other platforms and have got very good ranks but are new to kaggle\n* you are experienced data scientists working in big organizations but are new to kaggle\n* you have participated in live Kaggle competitions and managed to be in top 15 percent\n* you have written some very good kernels and are able to read and understand the advanced kernels etc\n* you have won several bronze medals in competitions\n* you are not afraid anymore but don't know how to get better in order to reach gold or silver not by chance but by pure work\n\n### Elite\nYou are an Elite if:\n* There is huge respect for you in the community\n* People follow you , admire you , look up to you\n* Have reached a stage of competition master or grandmaster\n\nThis is the stage which is a dream of every kaggler when they start right? These are the people whom we look upto and whom we want to follow , these are the people who have taught us , helped us , to reach all the way to pro level .\nThe people in Elite level are something different , I am talking about the brilliant Grandmasters whom we follow , whose kernels we drool over , whom we ask all the tough questions and they are kind enough to readily answer them.\n\n# <a id='data'>My Advice on \"How to get Started with Kaggle\"<\/a>\n\n<b> Now I believe you need to be atleast in intermediate stage to get started with kaggle but that doesnt mean you cant do competitive data science if you are in the Noobie stage . Below are my advices stage wise on \" How To Get Started With Kaggle \" <\/b>\n\n### Noobie\n\nIf you are in this stage means you are just starting , your pure focus should be to move into the `intermediate stage`, here is what you will need :-\n\n* Start with Python , main goal should be to atleast get to an intermediate level in python. Sources such as hackerearth and others can used.\n* Along with learning Python , Kaggle Learn courses are very good to transition into data science, focus should be on getting better with main python data science libraries like pandas , numpy ,scikit learn\n* Also you should keep practicing EDA and skills gained by kaggle learn courses ,by taking any dataset and exploring it with whatever knowledge you have with your own intuition and documenting main insights you might have found\n* Once all the above is done till a level that you are able to understand and write basic level codes , you can slowly start moving to starter level competitions , your focus should be doing only tabular data competitions . You can start by choosing playground kaggle competitions or go at a slightly smaller platform and practice there . This step is very crucial as you need to apply all the knowledge from kaggle learn courses and other places now to get a good rank in starter level competitions at sites like analytics vidhya and machine hack\n* Please note that delving into the maths and the algorithms themselves is not necessary at this stage and focus should be more on the applied part, if you are someone who likes the top down approach\n* Once you have gained good amount of confidence at exploring and modelling tabular data , try doing a unique personal project on tabular data and apply all the skills which you have acquired till now . The most important part with data science is your creativity and you must always use free will while dealing with data science projects and hence practice is necessary.\n\nVoila ! you are near about ready to transition into intermediate phase and you have already got a data science project to showcase , not bad , isn't it?\n\n### Intermediate\n\nIf you are here then it means you have sufficient applied knowledge in data science and have proven yourself with tabular data already .Now you want to enter the real competitions and want to make your name:\n\n* Live Kaggle competitions are tough and might be out of your league given your current skillset but that doesn't mean you can't do anything. The easiest way to get started with Kaggle competitions is to read kernels and write your own . Writing good kernels is a great way to boost your creativity, take any live kaggle competition , use whatever knowledge you have and publish a kernel (Don't worry no one is going to judge), read other people's kernels to get some ideas if the data is totally new to you , but be sure to put your original ideas as well in your kernels .Always remember the point of this exercise is to be creative , original and most of all learning to get comfortable with live kaggle comeptitions and not medals .\n* Don't worry if your kernels fail on upvotes ,if you learned something new by writing it then it was worth it , read the most upvoted kernels , try and understand why they got the upvotes .Kaggle community really appreciates original ideas and creativity so if you keep doing this you will surely get rewards . [Here](https:\/\/www.kaggle.com\/general\/89512#post516909) is a discussion thread in which Andrew (former notebooks rank 1) answers how to write good kernels.\n* Along with all this , its important that you now gain theoritical knowledge as well , learn one algorithm at a time , try to finish all the classical ones , read about different evaluation metrics(both for classification and regression) , bias-variance trade off , etc. The point is read atleast 10 articles everyday . Visit previous kaggle competitions , read best kernels there and make sure you are covering ground\n* Once you are done writing kernels for 3-4 live kaggle competitions in a way I explained with original ideas you will be familiar of how things work at kaggle and will be confident enough to enter a live kaggle competition . \n* There is a quote which I have formed for me and I thought it would be worth mentining ,\" If you are not learning anything new by writing a kernel or by participating in a competition or by doing a personal project ,then its really not worth it\". \n\n### Pro and Elite\n\nWell it would be completely vague if someone like me gives some advice to people in this category. I will say I am just thankful to these people to keep sharing their knowledge in such a easy way for people to understand . Due to presence of these people kaggle becomes such a great platform to learn and practice data science. I hope I keep learning and one day reach the ELITE stage \n\n\nNow when I was starting kaggle there was no tabular data competition so I had to learn a completely new thing altogether just to participate but luckily for you there is this tabular competition going on and you can get started , Now without further ado , lets get started with the steps for tackling any Live Kaggle Competition","ce3acbec":"I will not go into depths of EDA as my friend Gunes Evitan has already done a beautiful EDA in a very systematic way that I always follow. Also there are some beautiful kernels already written in that matter , I will provide link to that and only explain something which I figured out as a part of EDA and advanced domain knowledge gathering. `Please follow along the following Kernels before moving on `:\n\n* https:\/\/www.kaggle.com\/gunesevitan\/mechanisms-of-action-moa-prediction-eda\n* https:\/\/www.kaggle.com\/isaienkov\/mechanisms-of-action-moa-prediction-eda\n\nNow you might have a lot of questions after reading the EDA right? As I had a lot of them , Let's explore the questions and their answers my way:\n\n* What exactly our target columns mean?\n* What are these gene expression values exactly ? How were they calculated ? Why all of them have the same distribution? Are they all scaled? \n* What are the cell viability features ? Why are all labels zero where (cp_type = ctrl_vehicle) ie for control perturbations`\n* What there are 23k samples when there are only 5k drugs?\n* How can we use the non-scored targets?\n\nTo answer all these questions a lot of discussion threads were created , I will link all of them here :\n* [Answering what exactly is our target](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/180640)\n* [Why are there 23k samples when there are only 5k drugs](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/181010)\n* [Interpreting Gene Expression Features and yes they are scaled](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/180390)\n* [What are the cell viability features ? Why are all labels zero where (cp_type = ctrl_vehicle) ie for control perturbations](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/180304)","d4ee46ec":"# <a id='data'>Step 2 : Understanding the Evaluation Metric <\/a>\n\n* Another very important thing to understand is what is the evaluation metric against which our model\/solutions will be judged as then only we can do error analysis\/back tracking to improve our model's predictions . A good understanding of the competition metric can help in deriving a good post-processing strategy , also help in understanding which loss function to optimize etc\n\n* Luckily for everyone the Evaluation in this competition is done using mean column-wise log loss , which is fairly easy to understand and can be directly optimized by a lot of models \n\n`Here is how I analyze the Evaluation metric with respect to a competition`:\n* I analyse what is the maximum and minimum value the metric can achieve in its entire domain\n* I then try to check how sensitive the metric is to change in the original values . For that I scale the original targets by a few clicks and check the value of the metric in both directions \n* I then prepare code for visualization of loss against true and predicted values if possible\n\nAfter I am comfortable with the metric I then move on step 3 which is the most crucial of all ","12454ec7":"# <a id='data'>Step 5: Skimming through all the dicussion threads and Notebooks , writing down the Ideas to try <\/a>\n\nTwo  of the things that for me ,make Kaggle the best Data science platform in the world are the notebooks and discussions that best in the world post and share during the course of the competition . These make the learning in a single competition so immense that medals become secondary . Step 5 is all about making use of these two and learn from the best people and their best ideas . Also in the process you can improve the score .\n\nWhat I follow is I thoroughly go through all the discussion posts and add the ideas I want to try in a spreadsheet , I do the same with the notebooks . Then comes the exceution part , where I try and implement the saved ideas and keep what works for me .\n\nNow after this we move on the last step ","dd909556":"# <a id='data'>Step 4: Setting up a Baseline and Gathering All your ideas in One place <\/a>\n\nNow its time to build a baseline , By baseline we mean any model with just a naive implementation to test your cv and your first lb score , A baseline is something on which you do all your experimentations to improve and get to the best model\n\nNOTE :- Please note that baseline is the most solution you can build to a problem\n\nBut due to our EDA and Domain knowledge we already know few things and we will incorporate it in the baseline .\n* We know for control perturbations the labels are all zeros so we will remove those from training and validation, also we will make labels zero for those ids in the test set as well before submitting\n* We know that the numbers for gene expression are conveying only that the high numbers are high interaction for that gene and vice versa\n* We will use Xgboost just to show how to quickly build a baseline","6039bcfe":"Now that we have a baseline , we can collect all our ideas in one place without having looked at any public notebooks or dicussion threads just yet . I will list what ideas I have right now:\n\n* Training to predict train scored and non-scored targets but validate only on scored ones\n* Use different Dimensionality Reduction techniques to reduce the number of features to most important ones\n* Study the Train targets non-scored to find out how to utilize it more effectively as I think it will play a critical role in this competition\n* Try out Different DNNS , Lstms , Attention approach , Tabnet ,etc \n\nThat's all I can think of Right now , the idea should be to keep on adding in this list with your unique ideas which other people are not doing \nNow let's move onto the next section"}}