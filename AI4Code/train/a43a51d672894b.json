{"cell_type":{"78cd33b2":"code","8891e9d1":"code","4ee11edb":"code","e0e74b6d":"code","795965ed":"code","16958a73":"code","afb0ec85":"code","2f9a13f1":"code","5743ff83":"code","edc7624c":"code","d9dccaa8":"code","a4e2900b":"code","6f490d83":"code","f1a8e629":"code","2ff5c2ab":"code","5255820c":"code","8b01a197":"code","e171676e":"markdown","c19bd946":"markdown","d9ac69fb":"markdown","c14ba86b":"markdown","1d312a88":"markdown","155cd5ad":"markdown","b521ef75":"markdown","fe83eabb":"markdown","24b0ee3e":"markdown","91281d26":"markdown","bec85091":"markdown","40c78263":"markdown","1acbe03e":"markdown","4d6e372f":"markdown","0cd75fa1":"markdown","5909b7e8":"markdown","68f8cef4":"markdown"},"source":{"78cd33b2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nimport keras as keras\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","8891e9d1":"loaded_csv=pd.read_csv('\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Data\/Stocks\/ibm.us.txt', sep=',')\nloaded_csv['Date_datetime']=loaded_csv['Date'].apply(pd.to_datetime)\nloaded_csv.sort_values(by=['Date_datetime'], axis=0, ascending=True, inplace=True)","4ee11edb":"print('shape:\\n',loaded_csv.shape,'\\n')\nprint('head:\\n',loaded_csv.head(),'\\n')\nprint('info:');loaded_csv.info()\nprint('\\nhead:\\n',loaded_csv.describe(),'\\n')\nprint('last date data:\\n',loaded_csv.iloc[-1,:])","e0e74b6d":"number_of_rows=loaded_csv.shape[0]\nnumber_of_columns=loaded_csv.shape[1]\n\nnumber_of_nan_in_column=loaded_csv.isnull().sum(axis=0)\nnumber_of_nan_in_row=loaded_csv.isnull().sum(axis=1)\nprint('number_of_nan_in_column:\\n',number_of_nan_in_column)\nprint('\\nnumber_of_nan_in_row:\\n',number_of_nan_in_row)","795965ed":"# Having 0 values in OpenInt column is not a problem\n# because we won't use that column data\n# But, 0 value in Volume column will cause the error \n# when you devide some value by that 0 value\n# So, you need to resolve it. \n# I will delete the row which has 0 value in that Volume column\n\nloaded_csv.isin([0]).sum()","16958a73":"fig, ax = plt.subplots(2, 1, figsize=(20, 5))\n\nx_data1=loaded_csv['Date_datetime']\ny_data1=loaded_csv['Close']\nax[0].plot(x_data1,y_data1)\nax[0].set_title('Close price of IBM')\n\nx_data2=loaded_csv['Date_datetime']\ny_data2=loaded_csv['Volume']\nax[1].plot(x_data2,y_data2)\nax[1].set_title('Trade volumn of IBM')\n\nfig.tight_layout()\nplt.show()","afb0ec85":"# Download IBM stock price between 2017-11-11 and 2018-12-31\n\nimport pandas_datareader.data as web\n\nfuture_data = web.DataReader('IBM', 'stooq', '2017-11-11', '2018-12-31').reset_index()\nfuture_data['Date_datetime']=future_data['Date'].apply(pd.to_datetime)\nfuture_data=future_data.sort_values(by=['Date_datetime'], axis=0, ascending=True).reset_index(drop=True)\nprint(future_data)","2f9a13f1":"fig, ax = plt.subplots(2, 1, figsize=(20, 5))\n\nx_data1=loaded_csv['Date_datetime']\ny_data1=loaded_csv['Close']\nx_data1_2=future_data['Date_datetime']\ny_data1_2=future_data['Close']\nax[0].plot(x_data1,y_data1)\nax[0].plot(x_data1_2,y_data1_2,color='red')\nax[0].set_title('Close price of IBM')\n\nx_data2=loaded_csv['Date_datetime']\ny_data2=loaded_csv['Volume']\nx_data2_2=future_data['Date_datetime']\ny_data2_2=future_data['Volume']\nax[1].plot(x_data2,y_data2)\nax[1].plot(x_data2_2,y_data2_2,color='red')\nax[1].set_title('Trade volumn of IBM')\n\nfig.tight_layout()\nplt.show()","5743ff83":"loaded_csv[loaded_csv['Date_datetime']>'2016-01-01']","edc7624c":"loaded_csv=loaded_csv.drop(columns=['Date','OpenInt','Date_datetime'])\nfuture_data=future_data.drop(columns=['Date','Date_datetime'])","d9dccaa8":"print(loaded_csv.shape)\nloaded_csv=loaded_csv.drop(\n    loaded_csv[\n        (loaded_csv['Open'].isin([0]))|\n        (loaded_csv['High'].isin([0]))|\n        (loaded_csv['Low'].isin([0]))|\n        (loaded_csv['Close'].isin([0]))|\n        (loaded_csv['Volume'].isin([0]))\n    ].index)\nprint(loaded_csv.shape)\n\nprint(future_data.shape)\nfuture_data=future_data.drop(\n    future_data[\n        (future_data['Open'].isin([0]))|\n        (future_data['High'].isin([0]))|\n        (future_data['Low'].isin([0]))|\n        (future_data['Close'].isin([0]))|\n        (future_data['Volume'].isin([0]))\n    ].index)\nprint(future_data.shape)","a4e2900b":"close_at_t=loaded_csv['Close'].iloc[20:]\nclose_at_t_20=loaded_csv['Close'].shift(20).iloc[20:]\n\nfrom scipy.stats import pearsonr\ncorr, _ = pearsonr(close_at_t, close_at_t_20)\nprint('Pearsons correlation: {} (Very strong positive)'.format(corr.round(4)))","6f490d83":"fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n\nx_data=close_at_t\ny_data=close_at_t_20\nax.scatter(x_data,y_data)\nax.set_title('Scatter of Close price at time t and Close price at time t+2')\nax.set_xlabel('Close price at time t')\nax.set_ylabel('Close price at time t+20')\n\nfig.tight_layout()\nplt.show()","f1a8e629":"# print(loaded_csv.shape[0]-19)\n# 14040\nratio_df_list=[]\nfor i in range(0,loaded_csv.shape[0]-19,1):\n    one_criterion=loaded_csv.iloc[i,:]\n    one_small_df=loaded_csv.iloc[i:i+20,:]\n    ratio_df=(one_small_df\/one_criterion)-1\n    ratio_df_list.append(ratio_df)\nratio_np=np.array(ratio_df_list)\nprint(ratio_np.shape)\n\nratio_df_list_test=[]\nfor i in range(0,future_data.shape[0]-19,1):\n    one_criterion=future_data.iloc[i,:]\n    one_small_df=future_data.iloc[i:i+20,:]\n    ratio_df=(one_small_df\/one_criterion)-1\n    ratio_df_list_test.append(ratio_df)\nratio_test_np=np.array(ratio_df_list_test)\nprint(ratio_test_np.shape)","2ff5c2ab":"future_close_train=loaded_csv['Close'][19:].values\nprevious_close_train=loaded_csv['Close'][:-19].values\ny_train=(future_close_train\/previous_close_train)-1\n\nfuture_close_test=future_data['Close'][19:].values\nprevious_close_test=future_data['Close'][:-19].values\ny_test=(future_close_test\/previous_close_test)-1","5255820c":"def build_model(\n    inputs, output_size, neurons, activ_func=\"linear\", \n    dropout=0.10, loss=\"mae\", optimizer=\"adam\"):\n    \n    model = Sequential()\n    \n    # 32 dimension hidden vector is outputed from previous cell\n    model.add(LSTM(neurons, return_sequences=True, input_shape=(ratio_np.shape[1], ratio_np.shape[2])))\n    model.add(LSTM(neurons, return_sequences=True))\n    model.add(LSTM(neurons))\n    model.add(Dropout(dropout))\n    model.add(Dense(units=output_size))\n    model.add(Activation(activ_func))\n    model.compile(loss=loss, optimizer=optimizer)\n    return model\n\nnn_model = build_model(ratio_np, output_size=1, neurons = 32)\nprint(nn_model.summary())","8b01a197":"nn_history = nn_model.fit(\n    ratio_np, y_train, epochs=5, batch_size=1, verbose=2, shuffle=True)","e171676e":"### Check NaNs","c19bd946":"## Drop the rows which contain 0 value","d9ac69fb":"The notebook is ongoing in the writing","c14ba86b":"## Visualize downloaded time series stock price data which will be used as test data","1d312a88":"## Check the Pearson's correlation coefficient between \"Close price\" at time t and \"Close price\" at t+20","155cd5ad":"## Select proper amount of time series data for efficient training","b521ef75":"## Visualize time series stock price data","fe83eabb":"## Create time series train\/test target data","24b0ee3e":"## Perform training","91281d26":"## Download stock price data using pandas_datareader API","bec85091":"## Table of Contents\n\n- Overview of loaded data  \n    shape, head, info, describe, data of last date  \n    Check NaNs  \n    Check 0 value\n- Visualize time series stock price data  \n- Download stock price data using pandas_datareader API  \n- Visualize downloaded time series stock price data which will be used as test data  \n- Select proper amount of time series data for efficient training  \n- Drop the columns the model won't use for the training  \n- Drop the rows which contain 0 value  \n- Check the Pearson's correlation coefficient between \"Close price\" at time t and \"Close price\" at t+20  \n- Create time series train\/test data by reflecting pattern of volatility of all features for 20 days  \n- Create time series train\/test target data  \n- Build LSTM model for time series data training  \n- Perform training","40c78263":"## Create time series train\/test data by reflecting pattern of volatility of all features for 20 days","1acbe03e":"### Check 0 value","4d6e372f":"## Drop the columns the model won't use for the training","0cd75fa1":"### shape, head, info, describe, data of last date","5909b7e8":"## Overview of loaded data","68f8cef4":"## Build LSTM model for time series data training"}}