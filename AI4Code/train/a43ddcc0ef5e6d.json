{"cell_type":{"f672b415":"code","c843d596":"code","4d4d56e4":"code","6e1979bb":"code","32234ba7":"code","1147493c":"code","dd73dd4d":"code","2c38ec66":"code","05481dad":"code","1e2dee42":"code","ea7e168a":"code","b0750ded":"code","d05e5c3c":"code","16f5636a":"code","9f86d6eb":"code","0fbc4057":"code","b1f5b461":"code","21d11b82":"code","062e1bd9":"code","102b8eea":"code","e02b0cd9":"code","89e133fd":"code","91da89aa":"code","4029be6b":"code","7fabe84e":"code","03bf4857":"code","03296000":"code","3324baeb":"code","24c14d5d":"code","3a0995c0":"code","c04d88cb":"code","91e944bd":"code","32794f01":"code","105206aa":"code","929cbba8":"code","581a6787":"code","1bbc8a6d":"code","b76e7410":"code","e52447fb":"code","b34b5d70":"code","95bdfb80":"code","e9207869":"code","d158fad9":"code","2db77972":"code","e4520a31":"code","2361471f":"code","9fc69b7e":"code","eb14a31b":"code","8c2d8dca":"code","277e3f94":"code","ebbf8d77":"code","cd1e4292":"code","747cb981":"code","930400fb":"code","3dbc2770":"code","8f75db7f":"code","81b620e3":"code","ab5810f4":"code","1d4f1a4c":"code","2c371640":"code","59a15f53":"code","7b4fb522":"code","19ba1af8":"code","aea7aec0":"code","3521475d":"code","cf047641":"code","bb4c01b5":"code","94a701c3":"markdown","0784a36f":"markdown","d31b53d1":"markdown","50243ff4":"markdown","0448010b":"markdown","ba30002e":"markdown","7ff5e6b1":"markdown","53dbe6f6":"markdown","c84e0a48":"markdown","55d3a978":"markdown","629adbb7":"markdown","43c87e08":"markdown","19ab855d":"markdown","cd4709bd":"markdown","0dccdb00":"markdown","2b6eb598":"markdown","927db130":"markdown","3f68290b":"markdown","fc8d90be":"markdown","cc154569":"markdown","d3fe33e8":"markdown","66a44bda":"markdown","4ddb1db6":"markdown","c451fe91":"markdown","332b6379":"markdown","a230caa9":"markdown","7304c7cf":"markdown","89bde8aa":"markdown","8b1d61ba":"markdown","5631066a":"markdown","68cd7d33":"markdown","c7706759":"markdown","02f878dc":"markdown","b3452867":"markdown","28c1b6f1":"markdown","b29573c7":"markdown","302420e1":"markdown","8a987f94":"markdown","c275e6a2":"markdown","aac6a03b":"markdown","499cf871":"markdown","002402c6":"markdown","64654892":"markdown","2f119eac":"markdown","4be72bfb":"markdown","ba32ffe4":"markdown","24bde2a4":"markdown","091a7d2f":"markdown","0d9f50f3":"markdown","37345ef0":"markdown","5ddea7e6":"markdown","18771141":"markdown","ad3e32a0":"markdown"},"source":{"f672b415":"##################################################################################################################\n#  Team Members :\n#                 1-Abdullah Abdelhakeem\n#                 2-Mohamed Sebaie\n#                 3-Mohamed Mostafa\n#                 4-Osama Ahmed\n#                 5-Mahmoud Osama \n#\n#  Version: v1.1.0 (Submitted)\n#  Description: Seoul Bike Rental Prediction - AI-Pro - ITI\n#  \n#################################################################################################################","c843d596":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n#!pip install catboost\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# ignore the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(rc={'figure.figsize': [7, 7]}, font_scale=1.2)\n%config Completer.use_jedi=False\npd.set_option(\"display.max_columns\", None)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d4d56e4":"dataset_path = '\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/'\n\ndfTrainO = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\ndfTestO = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(dfTrainO.shape))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(dfTestO.shape))\ndfTrainO.head()","6e1979bb":"dictHoliday={\"No Holiday\":0,\"Holiday\":1}\ndictFunction={\"Yes\":1,\"No\":0}\ndictYears={2017:0,2018:1}","32234ba7":"def Preprocessing(df):\n    df[\"Date\"]            = pd.to_datetime(df[\"Date\"], format='%d\/%m\/%Y')\n    df[\"Year\"]            = df['Date'].dt.year\n    df[\"Month\"]           = df['Date'].dt.month\n    df[\"Day\"]             = df[\"Date\"].dt.day\n    df[\"DayName\"]         = df['Date'].dt.day_name()\n    df[\"DayNumber\"]       = df[\"Date\"].dt.dayofweek\n    df[\"WorkingDay\"]      = df['Date'].dt.weekday.apply(lambda x: 0 if (x == 5) | (x == 6) else 1)\n    df['WorkingDay']      = np.where((df['WorkingDay']==1 )& (df['Holiday']==\"Holiday\"), 0, df['WorkingDay'])\n    df[\"Holiday\"]         = df[\"Holiday\"].map(dictHoliday)\n    df[\"Functioning Day\"] = df[\"Functioning Day\"].map(dictFunction)\n    df[\"Year\"]            = df[\"Year\"].map(dictYears)\n    \n    df.rename(columns={\"Temperature(\ufffdC)\": 'Temperature',\"Dew point temperature(\ufffdC)\": 'Dew_Point',\n                             'Humidity(%)':'Humidity','Wind speed (m\/s)':'Wind_Speed','Visibility (10m)':'Visibility',\n                             'Solar Radiation (MJ\/m2)':'Solar_Radiation','Rainfall(mm)':'Rainfall',\n                             'Snowfall (cm)':'Snowfall','Functioning Day':'Functioning_Day'},inplace=True)\n    df['Temperature']=np.floor(df['Temperature']).astype(int)\n    \n    def extract_period_of_day1(hour):\n        if hour in range(12):\n            return 'Morning'\n        elif hour in range(12, 18):\n            return 'Afternoon'\n        elif hour in range(18, 22):\n            return 'Evening'\n        else:\n            return 'Night'\n    def extract_period_of_day2(hour):\n        if hour in range(6,19):\n            return 1\n        elif hour in range(19,24):\n            return 0\n        else:\n            return 0\n    def is_rush_hour(hour):\n        return 1 if hour in [8,16, 17, 18, 19, 20, 21, 22] else 0\n    def encode(data, col, max_val):\n        data[col + '_Sin'] = np.sin(2 * np.pi * data[col]\/max_val)\n        data[col + '_Cos'] = np.cos(2 * np.pi * data[col]\/max_val)\n        return data\n\n    df['Day_Period']   = df['Hour'].apply(extract_period_of_day1)\n    df['Rush_Hour']    = df['Hour'].apply(is_rush_hour)\n    df = encode(df,'Hour',23)\n    df = encode(df,'DayNumber',6)\n    df = encode(df,'Month',12)\n    return df","1147493c":"dfTrainNEW=Preprocessing(dfTrainO)\ndfTrainNEW.head()","dd73dd4d":"dfTestNEW=Preprocessing(dfTestO)\ndfTestNEW.head()","2c38ec66":"def ValueCounts(df):\n    for c in df.columns:\n        print(c+\"\\n\"+\"-----------------\"+\"\\n\")\n        print(df[c].value_counts().to_frame())\n        print(\"\\n\"+\"******************\"+\"\\n\")\n        \ndef UniqueValues(df,l):\n    for c in l:\n        print(c+\"\\n\"+\"-----------------\"+\"\\n\")\n        print(df[c].unique())\n        print(\"\\n\"+\"******************\"+\"\\n\")","05481dad":"ValueCounts(dfTrainNEW)","1e2dee42":"ValueCounts(dfTestNEW)","ea7e168a":"UniqueValues(dfTrainNEW,dfTrainNEW.columns)","b0750ded":"UniqueValues(dfTestNEW,dfTestNEW.columns)","d05e5c3c":"dfTrainNEW.describe().T","16f5636a":"dfTestNEW.describe().T","9f86d6eb":"dfTrainNEW.groupby('Hour')['y'].sum().plot(kind='bar');","0fbc4057":"dfTrainNEW.groupby('Seasons')['y'].sum().plot(kind='bar');","b1f5b461":"figure, axes = plt.subplots(nrows=3, ncols=3)\nfigure.set_size_inches(20,15)\nfigure.tight_layout()\nsns.kdeplot(dfTrainNEW['Temperature']    ,shade=True, ax=axes[0][0]);\nsns.kdeplot(dfTrainNEW['y']              ,shade=True, ax=axes[0][1]);\nsns.kdeplot(dfTrainNEW['Humidity']       ,shade=True, ax=axes[0][2]);\nsns.kdeplot(dfTrainNEW['Wind_Speed']     ,shade=True, ax=axes[1][0]);\nsns.kdeplot(dfTrainNEW['Visibility']     ,shade=True, ax=axes[1][1]);\nsns.kdeplot(dfTrainNEW['Dew_Point']      ,shade=True, ax=axes[1][2]);\nsns.kdeplot(dfTrainNEW['Solar_Radiation'],shade=True, ax=axes[2][0]);\nsns.kdeplot(dfTrainNEW['Rainfall']       ,shade=True, ax=axes[2][1]);\nsns.kdeplot(dfTrainNEW['Snowfall']       ,shade=True, ax=axes[2][2]);","21d11b82":"def SkewnessCheck(df,feature):\n    df['log'+feature]   =df[feature].apply(np.log1p)\n    df['sqrt'+feature]  =df[feature].apply(np.sqrt)\n    df['squar'+feature] =np.power(df[feature],2)\n    figure, axes = plt.subplots(nrows=1, ncols=4)\n    figure.set_size_inches(20,10)\n    sns.kdeplot(df['y']              ,shade=True, ax=axes[0]);\n    sns.kdeplot(df['log'+feature]    ,shade=True, ax=axes[1]);\n    sns.kdeplot(df['sqrt'+feature]   ,shade=True, ax=axes[2]);\n    sns.kdeplot(df['squar'+feature]  ,shade=True, ax=axes[3]);","062e1bd9":"SkewnessCheck(dfTrainNEW,'y')","102b8eea":"SkewnessCheck(dfTrainNEW,'Wind_Speed')","e02b0cd9":"SkewnessCheck(dfTrainNEW,'Visibility')","89e133fd":"SkewnessCheck(dfTrainNEW,'Solar_Radiation')","91da89aa":"SkewnessCheck(dfTrainNEW,'Rainfall')","4029be6b":"SkewnessCheck(dfTrainNEW,'Snowfall')","7fabe84e":"dfTestNEW['logWind_Speed']         =dfTestNEW['Wind_Speed'].apply(np.log1p)\ndfTestNEW['sqrtWind_Speed']        =dfTestNEW['Wind_Speed'].apply(np.sqrt)\ndfTestNEW['squarWind_Speed']       =np.power(dfTestNEW['Wind_Speed'],2)\ndfTestNEW['logVisibility']         =dfTestNEW['Visibility'].apply(np.log1p)\ndfTestNEW['sqrtVisibility']        =dfTestNEW['Visibility'].apply(np.sqrt)\ndfTestNEW['squarVisibility']       =np.power(dfTestNEW['Visibility'],2)\ndfTestNEW['logSolar_Radiation']    =dfTestNEW['Solar_Radiation'].apply(np.log1p)\ndfTestNEW['sqrtSolar_Radiation']   =dfTestNEW['Solar_Radiation'].apply(np.sqrt)\ndfTestNEW['squarSolar_Radiation']  =np.power(dfTestNEW['Solar_Radiation'],2)\ndfTestNEW['logRainfall']           =dfTestNEW['Rainfall'].apply(np.log1p)\ndfTestNEW['sqrtRainfall']          =dfTestNEW['Rainfall'].apply(np.sqrt)\ndfTestNEW['squarRainfall']         =np.power(dfTestNEW['Rainfall'],2)\ndfTestNEW['logSnowfall']           =dfTestNEW['Snowfall'].apply(np.log1p)\ndfTestNEW['sqrtSnowfall']          =dfTestNEW['Snowfall'].apply(np.sqrt)\ndfTestNEW['squarSnowfall']         =np.power(dfTestNEW['Snowfall'],2)","03bf4857":"dfTrainNEW.columns","03296000":"dfTrainNEW.drop(columns=['logy','squary','sqrtWind_Speed','squarWind_Speed', 'sqrtVisibility', 'logVisibility',\n                       'logSolar_Radiation','squarSolar_Radiation','logRainfall',\n                       'sqrtRainfall', 'squarRainfall', 'logSnowfall', 'sqrtSnowfall','squarSnowfall'],inplace=True)","3324baeb":"dfTrainNEW.info()","24c14d5d":"dfTestNEW.drop(columns=['sqrtWind_Speed', 'sqrtVisibility','squarWind_Speed', 'logVisibility',\n                       'logSolar_Radiation','squarSolar_Radiation','logRainfall',\n                       'sqrtRainfall', 'squarRainfall', 'logSnowfall', 'sqrtSnowfall','squarSnowfall'],inplace=True)","3a0995c0":"dfTestNEW.info()","c04d88cb":"FeatureList=['Seasons', 'Holiday', 'Functioning_Day', 'WorkingDay','DayName',\n                 'Month','Year','Day_Period', 'Rush_Hour']\ndef BarPlot(df,FeatureList):\n    fig = plt.figure(figsize=(20, 25))\n    i=1\n    for feature in FeatureList:\n        axes = fig.add_subplot(3, 3, i)\n        sns.barplot(data=df, x=feature, y='y', ax=axes)\n        axes.set(xlabel=feature, ylabel='Count', title='Average bike rentals across '+feature)\n        i+=1\n\nBarPlot(dfTrainNEW,FeatureList)","91e944bd":"sns.barplot(data=dfTrainNEW, x='Day', y='y')","32794f01":"f, axes = plt.subplots(5, 2, figsize=(20, 25))\n\nsns.boxplot(data=dfTrainNEW, y='y', x='Seasons'        , ax=axes[0][0],hue='Holiday')\nsns.boxplot(data=dfTrainNEW, y='y', x='Holiday'        , ax=axes[0][1])\nsns.boxplot(data=dfTrainNEW, y='y', x='Functioning_Day', ax=axes[1][0])\nsns.boxplot(data=dfTrainNEW, y='y', x='WorkingDay'     , ax=axes[1][1])\nsns.boxplot(data=dfTrainNEW, y='y', x='DayName'        , ax=axes[2][0])\nsns.boxplot(data=dfTrainNEW, y='y', x='Month'          , ax=axes[2][1])\nsns.boxplot(data=dfTrainNEW, y='y', x='Year'           , ax=axes[3][0])\nsns.boxplot(data=dfTrainNEW, y='y', x='Day_Period'     , ax=axes[3][1])\nsns.boxplot(data=dfTrainNEW, y='y', x='Rush_Hour'      , ax=axes[4][0])\nsns.boxplot(data=dfTrainNEW, y='y', x='Day'            , ax=axes[4][1])\n\nplt.show()","105206aa":"dfTrainNEW_w = dfTrainNEW[dfTrainNEW[\"WorkingDay\"] == 1]\ndfTrainNEW_nw = dfTrainNEW[dfTrainNEW[\"WorkingDay\"] == 0]\n\nbin_size = 4\ndfTrainNEW_w['Temp Round'] = dfTrainNEW_w['Temperature']\/\/bin_size\ndfTrainNEW_nw['Temp Round'] = dfTrainNEW_nw['Temperature']\/\/bin_size\n\nmean_count_vs_temp_w = dfTrainNEW_w.groupby('Temp Round')['y'].mean()\nmean_count_vs_temp_nw = dfTrainNEW_nw.groupby('Temp Round')['y'].mean()\nidx_w, idx_nw = range(len(mean_count_vs_temp_w)), range(len(mean_count_vs_temp_nw))\nlabels_w = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_w))]\nlabels_nw = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_nw))]\n\nfig = plt.figure(figsize=(18, 6))\naxes = fig.add_subplot(1, 2, 1)\nplt.bar(x=idx_w, height=mean_count_vs_temp_w)\nplt.xticks(idx_w, labels_w, rotation=90)\nplt.xlabel('Temp Bins')\nplt.ylabel('Average Count')\nplt.title('Working Days: Average count given across temperature range')\n\naxes = fig.add_subplot(1, 2, 2)\nplt.bar(x=idx_nw, height=mean_count_vs_temp_nw)\nplt.xticks(idx_nw, labels_nw, rotation=90)\nplt.xlabel('temp bins')\nplt.ylabel('Average Count')\nplt.title('Non-Working Days: Average count given across temperature range')\n\nplt.show()","929cbba8":"dfTrainNEW_R = dfTrainNEW[dfTrainNEW[\"Rush_Hour\"] == 1]\ndfTrainNEW_nR = dfTrainNEW[dfTrainNEW[\"Rush_Hour\"] == 0]\n\nbin_size = 4\ndfTrainNEW_R['Temp Round'] = dfTrainNEW_R['Temperature']\/\/bin_size\ndfTrainNEW_nR['Temp Round'] = dfTrainNEW_nR['Temperature']\/\/bin_size\n\nmean_count_vs_temp_w = dfTrainNEW_R.groupby('Temp Round')['y'].mean()\nmean_count_vs_temp_nw = dfTrainNEW_nR.groupby('Temp Round')['y'].mean()\nidx_w, idx_nw = range(len(mean_count_vs_temp_w)), range(len(mean_count_vs_temp_nw))\nlabels_w = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_w))]\nlabels_nw = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_nw))]\n\nfig = plt.figure(figsize=(18, 6))\naxes = fig.add_subplot(1, 2, 1)\nplt.bar(x=idx_w, height=mean_count_vs_temp_w)\nplt.xticks(idx_w, labels_w, rotation=90)\nplt.xlabel('Temp Bins')\nplt.ylabel('Average Count')\nplt.title('Rush Hours: Average count given across temperature range')\n\naxes = fig.add_subplot(1, 2, 2)\nplt.bar(x=idx_nw, height=mean_count_vs_temp_nw)\nplt.xticks(idx_nw, labels_nw, rotation=90)\nplt.xlabel('temp bins')\nplt.ylabel('Average Count')\nplt.title('Non-Rush Hours: Average count given across temperature range')\n\nplt.show()","581a6787":"dfTrainNEW_w  = dfTrainNEW[dfTrainNEW[\"Holiday\"] == 1]\ndfTrainNEW_nw = dfTrainNEW[dfTrainNEW[\"Holiday\"] == 0]\n\nbin_size = 4\ndfTrainNEW_w['Temp Round']  = dfTrainNEW_w['Temperature']\/\/bin_size\ndfTrainNEW_nw['Temp Round'] = dfTrainNEW_nw['Temperature']\/\/bin_size\n\nmean_count_vs_temp_w  = dfTrainNEW_w.groupby('Temp Round')['y'].mean()\nmean_count_vs_temp_nw = dfTrainNEW_nw.groupby('Temp Round')['y'].mean()\nidx_w, idx_nw = range(len(mean_count_vs_temp_w)), range(len(mean_count_vs_temp_nw))\nlabels_w = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_w))]\nlabels_nw = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_nw))]\n\nfig  = plt.figure(figsize=(18, 6))\naxes = fig.add_subplot(1, 2, 1)\nplt.bar(x=idx_w, height=mean_count_vs_temp_w)\nplt.xticks(idx_w, labels_w, rotation=90)\nplt.xlabel('Temp Bins')\nplt.ylabel('Average Count')\nplt.title('Working Days: Average count given across temperature range')\n\naxes = fig.add_subplot(1, 2, 2)\nplt.bar(x=idx_nw, height=mean_count_vs_temp_nw)\nplt.xticks(idx_nw, labels_nw, rotation=90)\nplt.xlabel('temp bins')\nplt.ylabel('Average Count')\nplt.title('Non-Working Days: Average count given across temperature range')\n\nplt.show()","1bbc8a6d":"f, axes = plt.subplots(1, 1, figsize=(15, 6))\nsns.boxplot(data=dfTrainNEW, y='y', x='Hour', hue='WorkingDay', ax=axes)\nhandles, _ = axes.get_legend_handles_labels()\naxes.legend(handles, ['Not a Working Day', 'Working Day'])\naxes.set(title='Hourly Count based on Working day or not')\n\nplt.show()","b76e7410":"f, axes = plt.subplots(1, 1, figsize=(15, 6))\nsns.boxplot(data=dfTrainNEW, y='y', x='Hour', hue='Rush_Hour', ax=axes)\nhandles, _ = axes.get_legend_handles_labels()\naxes.legend(handles, ['Not a Rush Hour', 'Rush Hour'])\naxes.set(title='Hourly Count based on Rush Hour or not')\n\nplt.show()","e52447fb":"f, axes = plt.subplots(nrows=2, ncols=1, figsize=(15, 18))\ngroup_work_hour = pd.DataFrame(dfTrainNEW.groupby(['WorkingDay', 'Hour'])['y'].mean()).reset_index()\nsns.pointplot(data=group_work_hour, x='Hour', y='y', hue='WorkingDay', ax=axes[0], legend=True)\nhandles, _ = axes[0].get_legend_handles_labels()\naxes[0].legend(handles, ['Not a Working Day', 'Working Day'])\naxes[0].set(xlabel='Hour in the day', ylabel='Count', title='Average Bike Rentals by the day if Working day or Not')\n\nhue_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ngroup_day_hour = pd.DataFrame(dfTrainNEW.groupby(['DayName', 'Hour'])['y'].mean()).reset_index()\nsns.pointplot(data=group_day_hour, x='Hour', y='y', hue='DayName', ax=axes[1], hue_order=hue_order)\naxes[1].set(xlabel='Hour in the day', ylabel='Count', title='Average Bike Rentals by the day across Weekdays')\n\nplt.show()","b34b5d70":"f, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 6))\ngroup_month = pd.DataFrame(dfTrainNEW.groupby(['Month', 'WorkingDay'])['y'].mean()).reset_index()\nsns.barplot(data=group_month, x='Month', y='y', hue='WorkingDay', ax=axes)\naxes.set(xlabel='Month', ylabel='Count', title='Average bike rentals per Month')\nhandles, _ = axes.get_legend_handles_labels()\naxes.legend(handles, ['Not a Working Day', 'Working Day'])\nplt.show()","95bdfb80":"corr_matrix = dfTrainNEW.corr()\nmask = np.array(corr_matrix)\nmask[np.tril_indices_from(mask)] = False\n\nfig = plt.figure(figsize=(25, 20))\nsns.heatmap(np.round(corr_matrix,2), mask=mask, annot=True, cbar=True, vmax=0.8, vmin=-0.8, cmap='RdYlGn')\nplt.show()","e9207869":"abs(dfTrainNEW.corr()[\"y\"]).sort_values(ascending=False)","d158fad9":"def OneHotEncoding(df,FeaturesL,Train_or_Test):\n    if Train_or_Test == 'Train':\n        dfTrainEncoded_Dummies = df.copy()\n        dfTrainEncoded_Dummies = pd.get_dummies(dfTrainEncoded_Dummies,columns=FeaturesL,drop_first=True)\n        return dfTrainEncoded_Dummies\n    elif Train_or_Test == 'Test':\n        dfTestEncoded_Dummies  = df.copy()\n        dfTestEncoded_Dummies  = pd.get_dummies(dfTestEncoded_Dummies, columns=FeaturesL,drop_first=True)\n        return dfTestEncoded_Dummies","2db77972":"class MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n\ndef LabelEncoding(df,FeaturesL,Train_or_Test):\n    if Train_or_Test == 'Train':\n        dfTrainEncoded_Labels = df.copy()\n        dfTrainEncoded_Labels = MultiColumnLabelEncoder(columns=FeaturesL).fit_transform(dfTrainEncoded_Labels)\n        return dfTrainEncoded_Labels\n    elif Train_or_Test == 'Test':\n        dfTestEncoded_Labels = df.copy()\n        dfTestEncoded_Labels = MultiColumnLabelEncoder(columns=FeaturesL).fit_transform(dfTestEncoded_Labels)\n        return dfTestEncoded_Labels","e4520a31":"FeaturesL=['DayName','Seasons','Day_Period']","2361471f":"dfTrainEncoded_Dummies=OneHotEncoding(dfTrainNEW,FeaturesL,'Train')","9fc69b7e":"abs(dfTrainEncoded_Dummies.corr()[\"y\"]).sort_values(ascending=False)","eb14a31b":"abs(dfTrainEncoded_Dummies.corr()[\"y\"]).sort_values().index","8c2d8dca":"dfTrainEncoded_Dummies.columns","277e3f94":"FeaturesL=['DayName','Seasons','Day_Period']","ebbf8d77":"dfTrainEncoded_Labels=LabelEncoding(dfTrainNEW,FeaturesL,'Train')","cd1e4292":"abs(dfTrainEncoded_Labels.corr()[\"y\"]).sort_values(ascending=False)","747cb981":"abs(dfTrainEncoded_Labels.corr()[\"y\"]).sort_values().index","930400fb":"FeaturesL=['DayName','Seasons','Day_Period']","3dbc2770":"dfTrainEncoded_Dummies=OneHotEncoding(dfTrainNEW, FeaturesL,'Train')\ndfTestEncoded_Dummies =OneHotEncoding(dfTestNEW,  FeaturesL,'Test')","8f75db7f":"dfTrainEncoded_Labels=LabelEncoding(dfTrainNEW, FeaturesL,'Train')\ndfTestEncoded_Labels =LabelEncoding(dfTestNEW,  FeaturesL,'Test')","81b620e3":"dfTrain = dfTrainEncoded_Dummies[['ID','y','DayNumber_Sin', 'DayNumber_Cos', 'Day_Period_Morning','Day', \n                                  'Month_Cos', 'Solar_Radiation','DayNumber', 'Month', \n                                  'Rush_Hour', 'Month_Sin', 'WorkingDay','Hour_Cos', \n                                  'Seasons_Winter', 'Hour_Sin', 'Rainfall', 'Hour',\n                                  'Humidity','Temperature', 'Functioning_Day']]","ab5810f4":"dfTest  = dfTestEncoded_Dummies[['ID','DayNumber_Sin', 'DayNumber_Cos', 'Day_Period_Morning','Day', \n                                 'Month_Cos', 'Solar_Radiation','DayNumber', 'Month', \n                                 'Rush_Hour', 'Month_Sin', 'WorkingDay','Hour_Cos', \n                                 'Seasons_Winter', 'Hour_Sin', 'Rainfall', 'Hour',\n                                 'Humidity','Temperature', 'Functioning_Day']]","1d4f1a4c":"# train_df= dfTrain[~dfTrain['Day'].isin([16,17,18,19,20])]\n# val_df  = dfTrain[dfTrain['Day'].isin([16,17,18,19,20])]\n\n# X_train = train_df.drop(columns=[\"ID\",\"y\"])\n# y_train = train_df['y']\n\n# X_val   = val_df.drop(columns=[\"ID\",\"y\"])\n# y_val   = val_df['y']","2c371640":"from sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(dfTrain, test_size=0.1, random_state=123,stratify =None)\nX_train = train_df.drop(columns=[\"ID\",\"y\"])\ny_train = train_df['y']\n################################################################################################\nX_val = val_df.drop(columns=[\"ID\",\"y\"])\ny_val = val_df['y']","59a15f53":"y_trainLog=np.log1p(y_train)\ny_valLog=np.log1p(y_val)","7b4fb522":"def normalize(df):\n    result = df.copy()\n    for feature_name in df.columns:\n        max_value = df[feature_name].max()\n        min_value = df[feature_name].min()\n        result[feature_name] = (df[feature_name] - min_value) \/ (max_value - min_value)\n    return result\n\n# X_train=normalize(X_train)\n# X_val=normalize(X_val)\n# dfTest=normalize(dfTest)\n\n# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler()\n# scaler.fit(X_train)\n# X_train = scaler.transform(X_train)\n# X_val = scaler.transform(X_val)\n\n# from sklearn.preprocessing import minmax_scale\n# X_train = minmax_scale(X_train, feature_range=(0, 1))\n# X_val = minmax_scale(X_val, feature_range=(0, 1))\n\n# from sklearn.preprocessing import RobustScaler\n# rb = RobustScaler()\n# X_train= rb.fit_transform(X_train)\n# X_val = rb.fit_transform(X_val)\n\n# from sklearn.preprocessing import StandardScaler\n# scaler  = StandardScaler()\n# scaler.fit(X_train)\n# X_train = scaler.transform(X_train)\n# X_val = scaler.transform(X_val)","19ba1af8":"from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import BaggingRegressor\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import r2_score","aea7aec0":"def rmsle(y_true, y_pred, convertExp=True):\n    # Apply exponential transformation function\n    if convertExp:\n        y_true = np.exp(y_true)\n        y_pred = np.exp(y_pred)\n        \n    # Convert missing value to zero after log transformation\n    log_true = np.nan_to_num(np.array([np.log(y+1) for y in y_true]))\n    log_pred = np.nan_to_num(np.array([np.log(y+1) for y in y_pred]))\n    \n    # Compute RMSLE\n    output = np.sqrt(np.mean((log_true - log_pred)**2))\n    return output","3521475d":"models = {\n    \"LinearRegression\":            LinearRegression(),\n    \"Ridge\":                       Ridge(),\n    \"Lasso\":                       Lasso(),\n    \"ElasticNet\":                  ElasticNet(),\n    \"KNeighborsRegressor\":         KNeighborsRegressor(), \n    \"DecisionTreeRegressor\":       DecisionTreeRegressor(),\n    \"RandomForestRegressor\":       RandomForestRegressor(),\n    \"BaggingRegressor\":            BaggingRegressor(),\n    \"AdaBoostRegressor\":           AdaBoostRegressor(),\n    \"CatBoostRegressor\":           CatBoostRegressor(verbose=False),\n    \"LGBMRegressor\":               LGBMRegressor(),\n    \"GradientBoostingRegressor\":   GradientBoostingRegressor(),\n    \"XGBRegressor\":                XGBRegressor()\n}","cf047641":"for name, model in models.items():\n    print(f'Using model: {name}')\n    model.fit(X_train, y_trainLog)\n    print(f\"train score : {model.score(X_train,y_trainLog)}\")\n    print(f'RMSLETrain: {rmsle(y_trainLog, model.predict(X_train))}')\n    print(f'RMSLEVal: {rmsle(y_valLog, model.predict(X_val))}')\n    print('-'*30)","bb4c01b5":"ID=dfTest[\"ID\"]\nX_test = dfTest.drop(columns=['ID'])\n\n# Train the Model\nModel=CatBoostRegressor(verbose=False,loss_function='MAE',n_estimators=1100,\n                        learning_rate=0.08842105263157894 ,depth=4,l2_leaf_reg=2,random_strength=700)\nModel.fit(X_train, y_trainLog)\n\n# Print RMSLE for Train and Validation\nprint(f'RMSLETrain: {rmsle(y_trainLog, Model.predict(X_train))}')\nprint(f'RMSLEVal: {rmsle(y_valLog, Model.predict(X_val))}')\n\n# Print the Features Importance of Cat Boost\nsorted_feature_importance = Model.feature_importances_.argsort()\nplt.barh(dfTest.drop(columns=['ID']).columns[sorted_feature_importance], \n        Model.feature_importances_[sorted_feature_importance], \n        color='turquoise')\nplt.xlabel(\"CatBoost Feature Importance\")\n\n\ndfTest.drop(columns=['ID']).columns[sorted_feature_importance]\n\n# Predict the Bikes Count for Test Data\ny_test_predicted = Model.predict(X_test)\n\ndfTest['y'] =np.floor(np.exp(y_test_predicted)).astype('int')\n\ndfTest['y'] = np.where(dfTest['Functioning_Day']==0, 0, dfTest['y'])\nyPredictTest=dfTest['y']\n\n\ndfTest.drop(columns=\"ID\",inplace=True)\ndfTest=pd.concat([dfTest, ID],axis=1)\ndfTest.head()\n\ndfTest[['ID', 'y']].to_csv('\/kaggle\/working\/submission.csv', index=False)\n# dfTest[['ID', 'y']].to_csv('submission.csv', index=False)\n","94a701c3":"# Read Train and Test Data","0784a36f":"## 1. One Hot Encoding","d31b53d1":"### Train","50243ff4":"## Case1","0448010b":"# Machine Learning Model ","ba30002e":"_______________________________","7ff5e6b1":"## Data fields","53dbe6f6":"## Case8","c84e0a48":"## `Solar_Radiation`","55d3a978":"![18738388_829586110528748_2528080115730434159_o-1.jpg](attachment:18738388_829586110528748_2528080115730434159_o-1.jpg)","629adbb7":"## `y`","43c87e08":"## Case7","19ab855d":"## 2. Label Encoding","cd4709bd":"________________________________________________","0dccdb00":"## Case9","2b6eb598":"# Preprocessing","927db130":"#### `SquareRoot` Y        ------> Best\n#### `Log` WindSpeed       ------> Best\n#### `Square` Visibility   ------> Best\n### `SolarRadiation`?? Original or SquareRoot","3f68290b":"## 1. One Hot Encoding","fc8d90be":"## Case3","cc154569":"## Features to Check: `y`, `Wind_Speed`,`Visibility`,`Solar_Radiation`,`Rainfall`,`Snowfall`","d3fe33e8":"## Drop the Columns we Don't Need","66a44bda":"##### The Seoul Metropolitan Government launched a public bike-sharing service in 2015 called Seoul Bikes (\u201cDdareungi\u201d in Korean). It was designed to be a self-operating rental service that could be used conveniently by anyone. Today in Seoul, there are over 150 rental stations centered in five areas of the city (Yeouido, Sangam, Sinchon, the 4 Great Gates area, and Seongsu). Currently there are 2,000 Seoul Bikes available to users, with plans to expand the project in the coming years. Seoul Bikes are a great way to travel distances that are a bit too far to walk, but a bit to close to bother with public transportation or a taxi. The bikes are eco-friendly, user friendly, and low-cost. Take a bike out for a spin and see a new side of Seoul.","4ddb1db6":"## `Wind_Speed`","c451fe91":"__________________________________________________","332b6379":"## Case10","a230caa9":"## Case6","7304c7cf":"## Train","89bde8aa":"# Import Required Libraries","8b1d61ba":"## Test Data","5631066a":"## Case5","68cd7d33":"# Value Counts and Uniques Equations","c7706759":"<h1 style=\"background-color:powderblue;\">Seoul Bike Rental Prediction - AI-Pro - ITI <\/h1>\n","02f878dc":"### Test","b3452867":"## `Visibility`","28c1b6f1":"## `Snowfall`","b29573c7":"## Case4","302420e1":"# Check the Correlation","8a987f94":"__________________________________________________","c275e6a2":"## Train Data","aac6a03b":"____________________________________________","499cf871":"# Correlations","002402c6":"## 2. Label Encoding","64654892":"________________","2f119eac":"## Case2","4be72bfb":"_________________________________________________","ba32ffe4":"## Do The Same To Test Data","24bde2a4":"# Plots To Visualize the Data","091a7d2f":"# Check for skewness","0d9f50f3":"# Categorical Columns Encoding","37345ef0":"_______________________________________________________","5ddea7e6":"# Team Members","18771141":"- `ID` - an ID for this instance\n- `Date` - year-month-day\n- `Hour` - Hour of he day\n- `Temperature` - Temperature in Celsius\n- `Humidity` - %\n- `Windspeed` - m\/s\n- `Visibility` - 10m\n- `Dew point temperature` - Celsius\n- `Solar radiation` - MJ\/m2\n- `Rainfall` - mm\n- `Snowfall` - cm\n- `Seasons` - Winter, Spring, Summer, Autumn\n- `Holiday` - Holiday\/No holiday\n- `Functional Day` - NoFunc(Non Functional Hours), Fun(Functional hours)\n- `y` - Rented Bike count (Target), Count of bikes rented at each hour","ad3e32a0":"## `Rainfall`"}}