{"cell_type":{"9498b45f":"code","22edfa56":"code","960abfa4":"code","7833da44":"code","d2cadfbc":"code","9da4906e":"code","a9556b81":"code","49416e72":"code","b51db3ec":"code","7816327d":"code","335c158b":"code","836b0eea":"code","d8c49892":"code","c0b10a27":"code","12bf99ee":"code","5b894d9c":"code","a50036df":"code","299817c6":"code","64594ab5":"code","b09ed50d":"code","afad2353":"code","ed83d106":"code","714bccd6":"code","24ee0cdf":"code","dbe08f7b":"code","f0ad5382":"code","28bc6ddd":"code","186b9a02":"code","4a74773d":"code","4a947248":"code","0079a75d":"code","ea1f9910":"code","7cbb8067":"code","a949f49d":"code","487ee937":"code","a175595a":"code","23cf3b6e":"code","b9c62b43":"code","b2032327":"code","5d8a7f91":"code","64561dab":"code","bd2c12ff":"markdown","4d015e2a":"markdown","61fa671a":"markdown","bbf96371":"markdown","9dba8c11":"markdown","46de07b5":"markdown","faac50e9":"markdown","afe8a268":"markdown","417d2768":"markdown","6401c3d1":"markdown","e4e8d3d1":"markdown","c3214187":"markdown","bb222b6b":"markdown","bbb3fd32":"markdown","1557aa96":"markdown","bc99e36c":"markdown","8340e9cd":"markdown","da4301ad":"markdown","0fe9e661":"markdown","b0421dc2":"markdown","c9408a8d":"markdown","33d34f33":"markdown","6d5fa28e":"markdown","f3482c52":"markdown","37d6aefa":"markdown","25f1a01c":"markdown","fd2b2d8c":"markdown","ef8f7f32":"markdown","d43d3fc9":"markdown","ee9baec0":"markdown","c6f359d4":"markdown","76887978":"markdown"},"source":{"9498b45f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22edfa56":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","960abfa4":"# Reading the csv file\ndata = pd.read_csv('\/kaggle\/input\/pakistans-largest-ecommerce-dataset\/Pakistan Largest Ecommerce Dataset.csv')\ndf = data.copy()","7833da44":"df.head()","d2cadfbc":"df.tail()","9da4906e":"df.columns","a9556b81":"df.dtypes","49416e72":"# Checking for missing \/ NaN values\ndf.isnull().sum()","b51db3ec":"# Doing a visual inspection of all columns\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","7816327d":"df.drop([\"Unnamed: 21\", \"Unnamed: 22\", \"Unnamed: 23\", \"Unnamed: 24\", \"Unnamed: 25\"], axis = 1, inplace=True)\ndf.dropna(subset=[\"item_id\"], axis=0, inplace=True)\ndf.rename(columns={\" MV \": \"MV\", \"category_name_1\": \"category_name\"}, inplace = True)","335c158b":"df=df.drop_duplicates()","836b0eea":"print(\"The number of rows with negative or zero Quantity:\",sum(n <= 0 for n in df.qty_ordered))\nprint(\"The number of rows with negative Price:\",sum(n < 0 for n in df.price))","d8c49892":"df['sku']=df['sku'].str.upper()","c0b10a27":"df['status'].value_counts()","12bf99ee":"df.groupby('BI Status')['status'].value_counts()","5b894d9c":"df['status'] = df['status'].replace('complete', 'Completed')\ndf['status'] = df['status'].replace('closed', 'Completed')\ndf['status'] = df['status'].replace('received', 'Completed')\ndf['status'] = df['status'].replace('paid', 'Completed')\ndf['status'] = df['status'].replace('cod', 'Completed')\ndf['status'] = df['status'].replace('order_refunded', 'Refund')\ndf['status'] = df['status'].replace('refund', 'Refund')\ndf['status'] = df['status'].replace('exchange', 'Refund')\ndf['status'] = df['status'].replace('pending', 'Pending')\ndf['status'] = df['status'].replace('payment_review', 'Pending')\ndf['status'] = df['status'].replace('processing', 'Pending')\ndf['status'] = df['status'].replace('holded', 'Pending')\ndf['status'] = df['status'].replace('pending_paypal', 'Pending')\ndf['status'] = df['status'].replace(r'\\\\N', 'Pending', regex=True)\ndf['status'] = df['status'].replace('fraud', 'Fraud')\ndf['status'] = df['status'].replace('canceled', 'Cancelled')","a50036df":"df['status'].value_counts()","299817c6":"df['BI Status'] = df['BI Status'].replace('#REF!', 'Net')","64594ab5":"df['BI Status'].value_counts()","b09ed50d":"df[df['status'].isnull()]","afad2353":"df['status'].fillna(\"Cancelled\",inplace=True)","ed83d106":"df['category_name'].value_counts()","714bccd6":"df['category_name'] = df['category_name'].replace(r'\\\\N', 'Unknown', regex=True)\ndf['category_name'].fillna(\"Unknown\",inplace=True)","24ee0cdf":"df[df['sku'].isnull()]","dbe08f7b":"df['sku'].fillna(\"Missing\",inplace=True)","f0ad5382":"df['sales_commission_code'].value_counts()","28bc6ddd":"df[df['sales_commission_code'].isnull()]","186b9a02":"df['sales_commission_code'].fillna(\"Missing\",inplace=True)\ndf['sales_commission_code'] = df['sales_commission_code'].replace(r'\\\\N', 'Missing', regex=True)","4a74773d":"df[df['Customer ID'].isnull()]","4a947248":"df['Customer ID'].fillna(\"0\",inplace=True)\ndf['Customer Since'].fillna(\"1-2018\",inplace=True)","0079a75d":"df.isnull().sum()","ea1f9910":"df[[\"item_id\"]] = df[[\"item_id\"]].astype(\"str\")\ndf[[\"Month\"]] = df[[\"Month\"]].astype(\"int\")\ndf[[\"Year\"]] = df[[\"Year\"]].astype(\"int\")\ndf[[\"qty_ordered\"]] = df[[\"qty_ordered\"]].astype(\"int\")\ndf[[\"Customer ID\"]] = df[[\"Customer ID\"]].astype(\"str\")\ndf[[\"increment_id\"]] = df[[\"increment_id\"]].astype(\"str\")","7cbb8067":"df.info()","a949f49d":"df = df.reset_index()","487ee937":"import plotly.graph_objects as go\n\ndf1 = df.groupby('status').size().reset_index(name='count').sort_values(by='count', ascending=False)\ndf1['Percentage'] = 100 * df1['count']  \/ df1['count'].sum()\n\n# Use textposition='auto' for direct text\nfig = go.Figure(data=[go.Bar(\n            x=df1['status'], \n            y=df1['count'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Transactions by Order Status\",\n    xaxis_title=\"Order Status\",\n    yaxis_title=\"count\",    \n    )\n\nfig.show()","a175595a":"df1 = df.groupby('category_name').size().reset_index(name='count').sort_values(by='count', ascending=False)\ndf1['Percentage'] = 100 * df1['count']  \/ df1['count'].sum()\n\n# Use textposition='auto' for direct text\nfig = go.Figure(data=[go.Bar(\n            x=df1['category_name'], \n            y=df1['count'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Transactions by Product Category\",\n    xaxis_title=\"Product Category\",\n    yaxis_title=\"count\",    \n    )\n\nfig.show()","23cf3b6e":"import plotly.express as px\npx.histogram(df, x='category_name', color = 'status', barmode='relative', title=\"Product Category wise Order Status\")","b9c62b43":"print(' Total Sales for all Transactions (inclusive of Discounts): ', df['grand_total'].sum())","b2032327":"# Calculation for sum\ndf1 = df.groupby('status')['grand_total'].sum().reset_index(name='sum').sort_values(by='sum', ascending=False)\ndf1['Percentage'] = 100 * df1['sum']  \/ df1['sum'].sum()\nfig = go.Figure(data=[go.Bar(\n            x=df1['status'], \n            y=df1['sum'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            marker = dict(color='rgba(255, 0, 0, 1)',line=dict(color='rgba(255, 0, 0, 1)',width=1)),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Total Sales by Order Status\",\n    xaxis_title=\"Order Status\",\n    yaxis_title=\"Total Sales\",    \n    )\n\nfig.show()","5d8a7f91":"# Calculation for sum\ndf1 = df.groupby('status')['grand_total'].sum().reset_index(name='sum')\ndf1['Percentage'] = 100 * df1['sum']  \/ df1['sum'].sum()\n\n# Calculation for count\ndf2 = df.groupby('status').size().reset_index(name='count')\ndf2['Percentage'] = 100 * df2['count']  \/ df2['count'].sum()\n\nx = df1['status'];\n\ntrace1 = {\n  'x': x,\n  'y': df2['Percentage'],\n  'name': 'Transactions',\n  'type': 'bar'\n};\n\ntrace2 = {\n  'x': x,\n  'y': df1['Percentage'],\n  'name': 'Total Sales',\n  'marker': dict(color='rgba(255, 0, 0, 1)'),\n  'type': 'bar'\n};\n\ndata = [trace1, trace2];\n\nfig = go.Figure(data=data)\n\nfig.update_layout(\n    title=\"Transactions and Total Sales by Order Status\",\n    xaxis_title=\"Order Status\",\n    yaxis_title=\"% of Total\",    \n    )\n\nfig.show()","64561dab":"temp = df.loc[df['status']=='Completed',['category_name','grand_total']]\ndf1 = temp.groupby('category_name')['grand_total'].sum().reset_index(name='sum').sort_values(by='sum', ascending=False)\ndf1['Percentage'] = 100 * df1['sum']  \/ df1['sum'].sum()\n\n# Use textposition='auto' for direct text\nfig = go.Figure(data=[go.Bar(\n            x=df1['category_name'], \n            y=df1['sum'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            marker=dict(color='rgba(255, 0, 0, 1)'),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Total Sales of Completed Transactions by Product Category\",\n    xaxis_title=\"Product Category\",\n    yaxis_title=\"Total Sales\",    \n    )\n\nfig.show()","bd2c12ff":"## Step 1: Data Pre-processing","4d015e2a":"##### Observations\n- There are 164 NaN values in the **'category_name'** column that can be filled using some information from **'sku'** column. Not doing it right now\n- 7850 transactions have a unicode label associated with them.\n- 164 transactions have NaN values.\n\n##### Actions\n- Replacing the unicode label and NaN values with label 'Unknown'","61fa671a":"##### Observations\n- There are a total of 11 rows where the 'Customer ID' column is NaN and exactly the same rows in 'Customer since' are also NaN, which makes sense and shows that these columns have a relationship.\n- All 11 records are from FY18, with the first record from 01-2018.\n- For keeping the records in dataset for analysis, a fake 'Customer ID' value of '0' can be assigned with '01-2018' assigned to all records in 'Customer Since' column\n\n##### Actions\n- Replaced 'Customer ID' with value **'0'** and 'Customer Since' with value **'01-2018'** for all NaN values","bbf96371":"#### Transactions by Category Name","9dba8c11":"##### Basic data quality and integrity checks","46de07b5":"#### Convert the datatypes of columns","faac50e9":"##### Dropping duplicate entries, if any, from the dataset","afe8a268":"##### Observations\n- All transactions marked as either **'complete' or 'closed'**, fall in the **'Net' category** for 'BI Status'\n- All transactions marked as **'received','paid','cod','exchanged' or something related to refund** are marked in **'Valid' category**\n- All transactions marked as **either 'canceled' or something to do with incomplete transation** are marked in **'Gross' category**\n- '#REF!' looks an erroneus label.\n\n##### Actions\n**Replace values inside the 'status' column by creating new labels**\n\n- **'complete','closed','received','paid','cod'** will belong to category **'Completed'**\n- **'order_refunded','refund', 'exchange'** will belong to category **'Refund'**\n- **'pending','payment_review','processing','holded','pending_paypal','\\N'** will beling to **'Pending'**\n- **'canceled'** will belong to **'Cancelled'**\n- **'fraud'** will belong to **'Fraud'**\n**Also replace the '#REF!'' entry to 'Net' in 'BI status'**","417d2768":"##### Convert all values in 'sku' column to upper case for uniformity","6401c3d1":"##### Observartions\n- Highest number of transactions **(315K or 54%)** belong to the **Completed** category\n- A very high number of transactions **(201K or 34%)** are getting cancelled\n- A sizeable number of transactions **(67K or 11.5%)** have some sort of refund associated.\n- Almost **46%** of transactions are not getting completed for some reason, meaning a lot can be done to **improve the conversion ratio**\n\n##### Actions\n- Analyze any relationship between **'Order Status' and 'Product Category'** so that it can be seen which product transactions are getting completed or cancelled. Also which products have the most refunds associated.\n- Analyze the cancellation and refunds as Revenue lost\n- Analyze any relationship between **'Order Status' and 'Payment Method'**","e4e8d3d1":"#### Handling NaN values in 'sku' column","c3214187":"##### Observations\n- Highest number of transactions **(115K or 20%)** happened for **Mobile & Tablets** whereas least number of transactions happened for **Books**","bb222b6b":"#### Transactions by Order Status","bbb3fd32":"#### To be continued","1557aa96":"##### Observations\n- Out of 26 columns, last 5 columns in the dataset contain NaN values for all records\n- Records at 464051 indices (from the bottom) contain NaN values for all columns\n- ' MV ' is an ambiguous column name with extra spaces\n- Some of the columns have incorrect data types\n\n##### Actions\n- Last 5 columns need to be dropped from the dataset\n- 464051 rows, containing NaN values need to be dropped from the dataset\n- Renamed the columns ' MV ' and 'category_name_1' to 'MV' and 'category_name'","bc99e36c":"#### Checking for Null values again and setting appropriate datatypes","8340e9cd":"#### Does Sales Amount follow the same pattern as Transactions??","da4301ad":"##### Observations\n- Almost **58% or Rs 2.9 Bn** of the total sales amount is **'cancelled'** which has a much higher percentage than the number of **cancelled transactions**.\n- E-commerce store has earned **32.73% or Rs 1.6 Bn** worth of revenue from Sales against a potential revenue of **Rs 4.98 Bn**\n\n##### Actions\n- A percentage wise comparison of 'Transactions' and 'Total Sales' needs to be done for better understanding","0fe9e661":"##### Observations\n**Completed Orders**\n- **Mens Fashion** has the highest number of transactions followed closely by **Mobile & Tablets**\n\n**Cancelled Orders**\n- Common amongst all the Product categories, but more transactions are cancelled than completed for Mobile & Tablets, Others, Entertainment and Unknown Product categories.\n- Highest number of transactions belong to **Mobile & Tablets** which are even greater than number of transactions which are completed.\n\n**Refunds**\n- Highest number of refunds happen for **Mobile & Tablets, Men's Fashion and Women's Fashion**\n\n##### Actions\n- Explore the same trends for 'Total Sales' and see if there is any symmetry or transactions do not have the same monetary impact","b0421dc2":"##### Observations\n- There are a lot of labels for 'status' column.\n- Need to check if any relationship exists between 'status' and 'BI Status' columns","c9408a8d":"#### Handling missing values in 'Customer ID' and 'Customer Since' columns","33d34f33":"##### Observation\n- **'Cancelled'** transactions have much higher monetary value than **'Completed'** transactions.\n- Almost **9% of revenue** is lost through **'Refund'**. **'Fraud' and 'Pending'** have minor contribution\n\n##### Actions\n- Explore the Total Sales generated only by the 'Completed' order status\n- Explore the Total Sales generated by order status other than 'Completed'","6d5fa28e":"#### Exploring all columns, finding and Imputing Null Values\n#### Categorical Variables","f3482c52":"#### Handling NaN values in 'category_name' column","37d6aefa":"##### Observations\n- The column has a large number of NaN values and there are more than 7000 types of values in this column\n- The column does not seem to add any value for further analysis and can be dropped at a later stage\n- At this stage, NaN values as well as unicode labels can be replaced with 'Missing'\n\n##### Actions\n- Replacing NaN and unicode values with **'Missing'**","25f1a01c":"#### Combined impact of Category Name and Order Status on Transactions","fd2b2d8c":"##### Handling Null values in 'status' column","ef8f7f32":"#### Best Selling Product Category\n\n##### Observations\n- **Mobile & Tablets** is the Best Selling category as it has the highest contribution to sales\n- **Mens Fashion**, despite having the most completed transactions, is the **5th highest contributor**\n- **Appliances** and **Entertainment** have 2nd and 3rd highest contribution to revenue, although the number of completed transactions for these products is low.\n- **Top 5** Productcategories are contributing almost **78% of the overall reveune**\n\n##### Actions\n- Dive deep in the best selling category to check the associated 'sku' column and see if top products can be pinpointed","d43d3fc9":"##### Observation\n- 15 NaN values in 'status' column have 'Gross' in the BI column meaning all these transactions are not valid\n\n##### Actions\n- Replacing NaN values with label **'Cancelled'** in line with our understanding of the data","ee9baec0":"## Step 2: Exploratory Data Analysis","c6f359d4":"##### Obsevations\n- 20 NaN values for **'sku'** exist in the dataset and these values can be replaced.\n\n##### Action\n- Replace NaN values with a new sku code **'Missing'**","76887978":"#### Handling missing values in 'Sales_commission_code' column"}}