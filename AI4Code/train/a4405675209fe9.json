{"cell_type":{"cdbf9e8e":"code","f929a191":"code","851a0f23":"code","3dea8f96":"code","28f86e61":"code","54069588":"code","e3c5e334":"code","f8e3dd46":"code","fd026595":"code","8f1149c4":"code","651b6a37":"code","d29d00a1":"code","22900689":"code","644ddee2":"code","20b9790f":"code","a5d3b359":"code","da447afe":"code","4ac11194":"code","6fb5c8a7":"code","271f902d":"code","a72a3719":"code","f4fd617e":"code","085c3148":"code","5eff9ffa":"code","de1ada37":"code","08704cc5":"code","fdcb3cb5":"code","742036df":"code","0feb62ac":"markdown","87453842":"markdown","aed1d954":"markdown","4ad7614b":"markdown","0a855157":"markdown","ea69ed92":"markdown","da7a0f66":"markdown","3fa4071d":"markdown","2e011cf8":"markdown","58c62149":"markdown","7f616c9a":"markdown","bac7594d":"markdown","3564c0e6":"markdown","2ac590dd":"markdown","c2bb6987":"markdown","58e25d8c":"markdown","0eef2cbf":"markdown","aa13d915":"markdown","16966994":"markdown","6fe2c5f3":"markdown"},"source":{"cdbf9e8e":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\nimport seaborn as sns\nsns.set_context('talk')\n\nSEED = 2021","f929a191":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/train.csv\")\n\n# In this Notebook, we use 50000 samples because to reduce calculation time\n# \u8a08\u7b97\u6642\u9593\u77ed\u7e2e\u306e\u305f\u3081\u3001\u4eca\u56de\u306f50000\u500b\u306e\u30c7\u30fc\u30bf\u306e\u307f\u4f7f\u3046\u3053\u3068\u306b\u3059\u308b\u3002\ntrain = train.sample(50000, random_state=SEED)\n\nX = train.drop([\"id\", \"target\"], axis=1)\ny = train.target\n\nprint(f\"X.shape: {X.shape}\")\nprint(f\"y.shape: {y.shape}\")","851a0f23":"from sklearn.model_selection import train_test_split\n\n# Split the data into training data and validation data.\n# \u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u7528\u30c7\u30fc\u30bf\u306b\u5206\u5272\u3059\u308b\u3002\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)\n\nprint(f\"X_train.shape: {X_train.shape}\")\nprint(f\"X_val.shape: {X_val.shape}\")","3dea8f96":"from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom keras import Sequential, layers\nfrom keras.callbacks import EarlyStopping","28f86e61":"from sklearn.metrics import mean_squared_error as mse\n\ndef rmse(pred, true):\n    return np.sqrt(mse(pred, true))","54069588":"reg = LinearRegression()\n\nreg.fit(X_train, y_train)\npred_reg = reg.predict(X_val)\n\nscore_reg = rmse(pred_reg, y_val)\nprint(score_reg)","e3c5e334":"ridge = Ridge(alpha=1.0)\n\nridge.fit(X_train, y_train)\npred_ridge = ridge.predict(X_val)\n\nscore_ridge = rmse(pred_ridge, y_val)\nprint(score_ridge)","f8e3dd46":"lasso = Lasso(alpha=0.9, max_iter=500)\n\nlasso.fit(X_train, y_train)\npred_lasso = lasso.predict(X_val)\n\nscore_lasso = rmse(pred_lasso, y_val)\nprint(score_lasso)","fd026595":"en = ElasticNet(alpha=1.2, l1_ratio=0.8, max_iter=1000)\n\nen.fit(X_train, y_train)\npred_en = en.predict(X_val)\n\nscore_en = rmse(pred_en, y_val)\nprint(score_en)","8f1149c4":"knr = KNeighborsRegressor(n_neighbors=7)\n\nknr.fit(X_train, y_train)\npred_knr = knr.predict(X_val)\n\nscore_knr = rmse(pred_knr, y_val)\nprint(score_knr)","651b6a37":"abr = AdaBoostRegressor(n_estimators=100, learning_rate=0.08, random_state=SEED)\n\nabr.fit(X_train, y_train)\npred_abr = abr.predict(X_val)\n\nscore_abr = rmse(pred_abr, y_val)\nprint(score_abr)","d29d00a1":"dt = DecisionTreeRegressor(max_depth=6)\n\ndt.fit(X_train, y_train)\npred_dt = dt.predict(X_val)\n\nscore_dt = rmse(pred_dt, y_val)\nprint(score_dt)","22900689":"rf = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=SEED)\n\nrf.fit(X_train, y_train)\npred_rf = rf.predict(X_val)\n\nscore_rf = rmse(pred_rf, y_val)\nprint(score_rf)","644ddee2":"et = ExtraTreesRegressor(n_estimators=100, max_depth=6, random_state=SEED)\n\net.fit(X_train, y_train)\npred_et = et.predict(X_val)\n\nscore_et = rmse(pred_et, y_val)\nprint(score_et)","20b9790f":"params_xgb = {\n    \"booster\": \"gbtree\",\n    \"objective\": \"reg:squarederror\",\n    \"eval_metric\": \"rmse\",\n    \"tree_method\": \"hist\",\n    \"max_depth\": 6,\n    \"eta\": 0.05,\n    \"colsample_bytree\": 0.7,\n    \"subsample\": 0.6,\n    \"random_state\": SEED\n}","a5d3b359":"d_train = xgb.DMatrix(X_train, label=y_train)\nd_val = xgb.DMatrix(X_val, label=y_val)","da447afe":"model_xgb = xgb.train(params=params_xgb,\n                      dtrain=d_train,\n                      num_boost_round=10000,\n                      early_stopping_rounds=20,\n                      verbose_eval=20,\n                      evals=[(d_train, \"train\"), (d_val, \"val\")])","4ac11194":"pred_xgb = model_xgb.predict(d_val, ntree_limit=model_xgb.best_ntree_limit)\nscore_xgb = rmse(pred_xgb, y_val)\nprint(score_xgb)","6fb5c8a7":"params_lgb = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.05,\n    \"num_leaves\": 31,\n    \"bagging_fraction\": 0.8,\n    \"feature_fraction\": 0.7,\n    \"random_state\": SEED\n}","271f902d":"lgb_train = lgb.Dataset(X_train, label=y_train)\nlgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)","a72a3719":"model_lgb = lgb.train(params=params_lgb,\n                      train_set=lgb_train,\n                      valid_sets=(lgb_train, lgb_val),\n                      num_boost_round=10000,\n                      early_stopping_rounds=20,\n                      verbose_eval=20)","f4fd617e":"pred_lgb = model_lgb.predict(X_val, num_iteration=model_lgb.best_iteration)\nscore_lgb = rmse(pred_lgb, y_val)\nprint(score_lgb)","085c3148":"callbacks = [EarlyStopping(monitor=\"val_mse\", patience=20)]","5eff9ffa":"NN = Sequential()\n\nNN.add(layers.Dense(128, activation=\"relu\", input_shape=(X_train.shape[1], )))\nNN.add(layers.Dense(64, activation=\"relu\"))\nNN.add(layers.Dense(64, activation=\"relu\"))\nNN.add(layers.Dense(32, activation=\"relu\"))\nNN.add(layers.Dense(32, activation=\"relu\"))\nNN.add(layers.Dense(10, activation=\"relu\"))\nNN.add(layers.Dense(1, activation=\"linear\"))\nNN.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n\nNN.summary()","de1ada37":"history = NN.fit(x=X_train,\n                 y=y_train,\n                 epochs=10000,\n                 batch_size=128,\n                 verbose=2,\n                 callbacks=callbacks,\n                 validation_data=(X_val, y_val))","08704cc5":"pred_nn = NN.predict(X_val)\nscore_nn = rmse(pred_nn, y_val)\nprint(score_nn)","fdcb3cb5":"regressors = pd.DataFrame([\"Linear Reg\", \"Rdige\", \"Lasso\", \"ElasticNet\", \"KNN\", \"AdaBoost\", \"DecisionTree\", \"RandomForest\", \"ExtraTrees\", \"XGBoost\", \"LightGBM\", \"NeuralNetwork\"], columns=[\"regressor\"])\n\nscores = pd.DataFrame([score_reg, score_ridge, score_lasso, score_en, score_knr, score_abr, score_dt, score_rf, score_et, score_xgb, score_lgb, score_nn], columns=[\"RMSE\"])\n\nresults = pd.concat([regressors, scores], axis=1)\nresults","742036df":"results_sorted = results.sort_values(\"RMSE\")\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=\"RMSE\", y=\"regressor\", data=results_sorted)\nplt.xlabel(\"RMSE\", fontsize=20)\nplt.ylabel(\"Regressor\", fontsize=20)\nplt.xlim(0.6, 0.8)\nplt.show()","0feb62ac":"Regressors introduced in this Notebook. \/ \u3053\u306eNotebook\u3067\u7d39\u4ecb\u3059\u308b\u56de\u5e30\u30e2\u30c7\u30eb  \n  \nLinear Regressor \/ \u7dda\u5f62\u56de\u5e30  \n  \nRidge \/ \u30ea\u30c3\u30b8\u56de\u5e30(L2\u6b63\u5247\u5316)  \n  \nLasso \/ \u30e9\u30c3\u30bd\u56de\u5e30(L1\u6b63\u5247\u5316)  \n  \nElasticNet Regressor(= Ridge + Lasso) \/ ElasticNet\u56de\u5e30(= \u30ea\u30c3\u30b8 + \u30e9\u30c3\u30bd)  \n  \nK Nearest Neighbors \/ k\u8fd1\u508d\u6cd5  \n  \nAdaBoost  \n  \nDecisionTree \/ \u6c7a\u5b9a\u6728  \n  \nRandomForest \/ \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8  \n  \nExtraTrees\n  \nXGBoost  \n  \nLightGBM  \n  \nNeural Network(=MLP) \/ \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(=\u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3)","87453842":"### LightGBM","aed1d954":"### RandomForest \/ \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8","4ad7614b":"# Modeling (\u30e2\u30c7\u30ea\u30f3\u30b0)","0a855157":"### AdaBoost","ea69ed92":"### ExtraTrees","da7a0f66":"### Neural Network(MLP) \/ \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(\u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3)","3fa4071d":"### XGBoost","2e011cf8":"======================================================================================================\n## \u53c2\u8003\u306b\u306a\u3063\u305f\u3089UpVote\u3057\u3066\u3044\u305f\u3060\u3051\u308b\u3068\u5b09\u3057\u3044\u3067\u3059\u3001\u3001\u3001  \n## If you find it helpful, I'd appreciate an UpVote!  \n======================================================================================================","58c62149":"### Ridge \/ \u30ea\u30c3\u30b8\u56de\u5e30","7f616c9a":"## In this Notebook, we will compare a number of regression models. It includes examples of how to use them.\n## \u3053\u306eNotebook\u3067\u306f\u3001\u305f\u304f\u3055\u3093\u306e\u56de\u5e30\u30e2\u30c7\u30eb\u3092\u6bd4\u8f03\u3057\u307e\u3059\u3002\u7c21\u5358\u306a\u4f7f\u3044\u65b9\u306e\u4f8b\u3082\u8f09\u305b\u3066\u3044\u308b\u306e\u3067\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002","bac7594d":"### K Nearest Neighbors \/ k\u8fd1\u508d\u6cd5","3564c0e6":"### Because I am beginner, I may not be good at writing code...  \n### \u521d\u5fc3\u8005\u306a\u306e\u3067\u30b3\u30fc\u30c9\u304c\u6c5a\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3001\u3059\u307f\u307e\u305b\u3093\u3001\u3001\u3001","2ac590dd":"\u8cea\u554f\u30fb\u30b3\u30e1\u30f3\u30c8\u7b49\u3042\u308c\u3070\"\u672c\u5f53\u306b\"\u6c17\u8efd\u306b\u3069\u3046\u305e\uff01  \n\u7b54\u3048\u3089\u308c\u308b\u7bc4\u56f2\u3067\u7b54\u3048\u307e\u3059\u3002","c2bb6987":"### Lasso \/ \u30e9\u30c3\u30bd\u56de\u5e30","58e25d8c":"### Linear Regression \/ \u7dda\u5f62\u56de\u5e30","0eef2cbf":"# Results Comparison \/ \u7d50\u679c\u3092\u6bd4\u8f03","aa13d915":"### DecisionTree \/ \u6c7a\u5b9a\u6728","16966994":"### ElasticNet","6fe2c5f3":"# Preparation Data (\u30c7\u30fc\u30bf\u306e\u6e96\u5099)"}}