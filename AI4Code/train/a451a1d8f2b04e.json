{"cell_type":{"5bea3397":"code","3163e882":"code","2d308095":"code","db831b61":"code","c2a5b737":"code","764b885d":"code","cec938af":"markdown","7aeafea0":"markdown","18f484cc":"markdown","75f67081":"markdown","f93629bc":"markdown","72c4b713":"markdown","1507d6c1":"markdown"},"source":{"5bea3397":"import tensorflow as tf\nfrom tensorflow.keras.layers import *","3163e882":"def create_model():\n    \n    inputs = tf.keras.Input(shape = (224,224,3,2,))\n    \n    input_a = inputs[:,:,:,:,0]\n    input_b = inputs[:,:,:,:,1]\n    \n    pretrained_model = tf.keras.models.load_model(\"..\/input\/vggface-using-tripletloss\/vgg_face_model.h5\")\n    \n    embed_model = tf.keras.Model(pretrained_model.layers[0].input,pretrained_model.layers[-2].output)\n    \n    embed_a = embed_model(input_a)\n    embed_b = embed_model(input_b)\n    \n    l1_layer = Lambda(lambda tensors:tf.math.abs(tensors[0] - tensors[1]),name = \"l1_layer\")\n    l1_distance = l1_layer([embed_a,embed_b])\n    \n    outputs = Dense(1,activation=\"sigmoid\")(l1_distance)\n    \n    siamese_model = tf.keras.Model(inputs,outputs)\n    \n    return embed_model,siamese_model\n\nembed,siamese = create_model()","2d308095":"siamese.summary()","db831b61":"embed.summary()","c2a5b737":"model = tf.keras.Model(siamese.layers[-3].input,siamese.layers[-3].output)\nmodel.summary()","764b885d":"def copyModel2Model(model_source,model_target,certain_layer=\"a\"):\n    i=0        \n    for tar,src in zip(model_target.layers,model_source.layers):\n        if tar.name==certain_layer:\n            break\n        if i%2 !=0:\n            print(model_source.layers[i].name,i)\n            try:\n                weights=src.get_weights()\n                tar.set_weights(weights)\n            except:\n                i+=1\n                continue\n    i+=1  \n    print(\"model source was copied into model target\")\n    return model_target \n\nembed_model = copyModel2Model(siamese,embed)\nembed_model.summary()","cec938af":"### Copying the weights from siamese to model we obtained above","7aeafea0":"### If you run the below cell, you will see that the 3rd layer from top is what we required finally {name: \"model (Functional) \"} (where we found embeddings of 2 images ie., **all the VGG FaceNet model is present in 3rd layer itself**. It's the key takeaway from thsi notebook where many will make mistake.)","18f484cc":"### Getting the model as expalined above.","75f67081":"# **This notebook will take you through the steps needed to extract the embeddings from Siamese netork**","f93629bc":"# In this way one can obtain embeddings of siamese network.If this helped you,give it a thumbs up \ud83e\udd70. Happy coding.","72c4b713":"## So, I am using a pretrained model ie., VGG Facenet to obtain embeddings. To know more details on how to use VGG FaceNet, Refer ot this [blog post](https:\/\/sefiks.com\/2018\/08\/06\/deep-face-recognition-with-keras\/#:~:text=VGG%2DFace%20is%20deeper%20than,layer%20structre%20as%20shown%20below.). I also put the model with pretrained weights in my [Faces Dataset](https:\/\/www.kaggle.com\/shanmukh05\/vggface-using-tripletloss)\n\n### Input shape will be: (BATCH_SZIE,HEIGHT,WIDTH,CHANNELS,2). I am taking l1_distance of both the embeddings and adding sigmoid layer at the top of it. \n### Finally I am taking both embed_model and siamese_model as output.","1507d6c1":"### To know about Siamese network, refer ot this [video lecture](https:\/\/www.youtube.com\/watch?v=6jfw8MuKwpI) by Andrew NG on siamese Network. \n#### Basically the idea is to ontain the embeddings for a given 2 images and compare them by l1 distance (In general as mentioned in Siamese paper, you can research on other ways of comparision like cosine similarity,euclidian distance etc.,)"}}