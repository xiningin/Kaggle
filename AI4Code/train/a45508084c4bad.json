{"cell_type":{"f60bd59a":"code","88040b18":"code","7ab3d6e9":"code","5cba3351":"code","0f992f1d":"code","d3f882b7":"code","501ca618":"code","9dadedd8":"code","4191579f":"code","e3e94e43":"code","8bc7a6e1":"code","a94c32ab":"code","4c22f869":"code","d4909112":"code","1f0eccf7":"code","7c9d43f7":"code","a9da59e2":"code","b2142093":"code","20066f42":"code","1aab6a64":"code","0f882070":"code","e29cf00a":"code","68783868":"code","520807f2":"code","6eb6d54e":"code","287b6bb9":"code","344f24fb":"code","40016e17":"code","a6c76b95":"code","ec364cf9":"code","52e788bf":"code","bd961f3c":"code","6ba23af8":"code","5ecbda16":"code","cec992a2":"code","29d1dc5c":"markdown","d30bdbe4":"markdown","1bb0ca95":"markdown","9a6db516":"markdown","6dc6e1a3":"markdown","78fd74ea":"markdown"},"source":{"f60bd59a":"%cd \"\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\"\n! ls","88040b18":"! mkdir \/kaggle\/working\/my_classes\n! cp -r NORMAL COVID 'Viral Pneumonia' \/kaggle\/working\/my_classes # move normal, covid, pneumonia folders into my classes folder","7ab3d6e9":"! ls \/kaggle\/working\/my_classes","5cba3351":"kaggle_root = \"\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\"\ndataset_root = \"\/kaggle\/working\/my_classes\"","0f992f1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport cv2\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import f1_score\n\nimport torch\nimport torch.nn as nn\n\nimport torchvision\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\n\n\n\n\n\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n\n\nimport torchvision.transforms as transforms\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3f882b7":"img1 = cv2.imread(kaggle_root +'\/COVID\/COVID (1).png',0)\nplt.imshow(img1, cmap='gray')\nplt.axis('off')\nplt.show()\nprint('COVID')\nprint(img1.shape)\nimg2 = cv2.imread(kaggle_root +'\/NORMAL\/NORMAL (1).png',0)\nplt.imshow(img2, cmap='gray')\nplt.axis('off')\nplt.show()\nprint('Normal')\nprint(img2.shape)\nimg3 = cv2.imread(kaggle_root +'\/Viral Pneumonia\/Viral Pneumonia (1).png',0)\nplt.imshow(img3, cmap='gray')\nplt.axis('off')\nplt.show()\nprint('Viral Pneumonia')\nprint(img3.shape)\n# # 1200 COVID-19 positive images, 1341 normal images, and 1345 viral pneumonia images","501ca618":"transform = transforms.Compose([transforms.Resize((255,255)),transforms.ToTensor()]) #to resize images and transform them to tensors","9dadedd8":"! pip install split-folders\n%cd \/kaggle\/working\n! mkdir output\nimport splitfolders\n# 80% training 10% validation 10% testing\nsplitfolders.ratio(dataset_root, output=\"output\", seed=1234, ratio=(0.8, 0.1, 0.1), group_prefix=None)\n","4191579f":"! ls output","e3e94e43":"output = \"\/kaggle\/working\/output\"\ntrain_data = output + '\/train'\nvalid_data = output + '\/val'\ntest_data = output + '\/test'\n","8bc7a6e1":"dataset_train = datasets.ImageFolder(train_data, transform=transform) # ImageFolder for each class COVID , Normal , Pneumia\ndataset_valid = datasets.ImageFolder(valid_data, transform=transform)\ndataset_test = datasets.ImageFolder(test_data, transform=transform)","a94c32ab":"dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True)\ndataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=32, shuffle=True)\ndataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=True)","4c22f869":"i = 0\nfor images, labels in dataloader_train:\n    print(images.shape)\n    print(labels, '\\n')\n    i += 1\n    if i == 2:\n        break","d4909112":"import torch.optim as optim\n\ndef run_model(model,dataloader,valid_loader, optimizer, train = True):\n    if train:\n        model.train()\n    pred=[]\n    labels=[]\n    loss=nn.CrossEntropyLoss()\n    total_loss=0\n    total_train = 0\n    correct_train = 0\n    valid_loss = 0.0\n    total_train_val=0.0\n    correct_train_val =0.0\n    \n    for(data,label) in dataloader:\n        data, label = data.cuda(), label.cuda()\n        optimizer.zero_grad()\n        if 'Inception3' in str(type(model)):\n            output, aux_output = model(data)\n            loss1 = loss(output, label)\n            loss2 = loss(aux_output, label)\n            loss_ = loss1 + 0.4*loss2\n        else:    \n            output= model(data)\n            loss_=loss(output,label)\n        \n        \n        total_loss+=loss_.item()\n        loss_.backward()\n        optimizer.step()\n        pred+=output.tolist()\n        labels+=label.tolist()\n        \n        # accuracy\n        _, predicted = torch.max(output.data, 1)\n        total_train += label.nelement() #\n        correct_train += predicted.eq(label.data).sum().item()\n        accuracy = correct_train \/ total_train\n    \n    # validate-the-model\n    model.eval()\n    for data, target in valid_loader:\n        data, target = data.cuda(), target.cuda()\n        output_valid = model(data)\n        loss_v = loss(output_valid, target)\n        \n        # accuracy validation \n        _, predicted = torch.max(output_valid.data, 1)\n        total_train_val += target.nelement() #\n        correct_train_val += predicted.eq(target.data).sum().item()\n        accuracy_val = correct_train_val \/ total_train_val\n        \n        # update-average-validation-loss \n        valid_loss += loss_v.item()\n\n\n    return labels,pred,total_loss\/len(dataloader),accuracy,accuracy_val,valid_loss\/len(valid_loader),model\n\n        \n\n# #criterion = nn.CrossEntropyLoss()","1f0eccf7":"def test_model(model,dataloader):\n    # test-the-model\n    predictions1 =[]\n    labels1=[]\n    model.eval()  # it-disables-dropout\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in dataloader:\n            \n            images, labels = images.cuda(), labels.cuda()\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()          \n            \n            \n            labels1.append(labels.item())\n            predictions1.append(predicted.item())\n            \n        \n        \n        labels1 = np.array(labels1)\n        predictions1 = np.array(predictions1)\n        \n        f1_pred = f1_score(labels1, predictions1, average='weighted')\n        print(\"F1 score (weighted): {:.3f}\" .format(f1_pred))\n          \n        print('Testing Accuracy: {:.3f} %' .format(100*(correct \/ total)))\n        \n        \n       \n\n  ","7c9d43f7":"class ConModel(nn.Module):\n    def __init__(self):\n        super(ConModel, self).__init__()  #inheriting functionality of nn module\n        self.conv1 = nn.Conv2d(3, 32,3, 1)  #defining layers  \n        self.conv2 = nn.Conv2d(32,64,3,1)\n        self.conv3 = nn.Conv2d(64,64,3,1)\n        self.dropout1= nn.Dropout(0.25)\n        self.dropout2= nn.Dropout(0.5)\n        self.fc1 = nn.Linear(238144, 128)\n        self.fc2 = nn.Linear(128, 84)  \n        self.fc3 = nn.Linear(84, 3)\n\n    def forward(self, x):\n        x=self.conv1(x)\n        x = F.relu(x)\n        x=self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x,2)\n        x=self.conv3(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x,2)\n        x = self.dropout1(x)\n        x = torch.flatten(x,1)\n        #print(x.shape)\n        x=self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(self.dropout2(x))\n        x = F.relu(x)\n        x=self.fc3(x)\n        output = F.log_softmax(x,dim=1)\n        return output\n        \n        \n\n","a9da59e2":"class ConModel_few(nn.Module):\n    def __init__(self):\n        super(ConModel_few, self).__init__()  #inheriting functionality of nn module\n        self.conv1 = nn.Conv2d(3, 32,3, 1)  #defining layers  \n        self.dropout1= nn.Dropout(0.25)\n        self.fc1 = nn.Linear(508032, 84)\n        self.fc2 = nn.Linear(84, 3)  \n        \n\n    def forward(self, x):\n        x=self.conv1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x,2)\n        x = self.dropout1(x)\n        x = torch.flatten(x,1)\n        #print(x.shape)\n        x=self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x) \n        output = F.log_softmax(x,dim=1)\n        return output\n        ","b2142093":"from sklearn.metrics import f1_score\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n\ncnn_model = ConModel()\ncnn_model.to(device)\n\nepoch = 5 #tunable hyperparameter\noptimizer = torch.optim.Adam(cnn_model.parameters(),0.00001,weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=.3,threshold=1e-4)\n\n# \nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(cnn_model,dataloader_train,dataloader_valid,optimizer)\n    cnn_model= model\n    print('Epoch {} CNN (many), Train Loss: {:.3f}'.format(e+1, loss),  'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n\nprint()\nprint(\"test cnn_model many\")\ntest_model(cnn_model,dataloader_test) \nprint()","20066f42":"train_transform = transforms.Compose([transforms.Resize((255,255)),transforms.RandomRotation(30),transforms.RandomHorizontalFlip(),transforms.ToTensor()]) #to resize images and transform them to tensors","1aab6a64":"dataset2_train = datasets.ImageFolder(train_data, transform=train_transform) # ImageFolder for each class COVID , Normal , Pneumia\ndataset2_valid = datasets.ImageFolder(valid_data, transform=train_transform)\ndataset2_test = datasets.ImageFolder(test_data, transform=train_transform)","0f882070":"trainloader = torch.utils.data.DataLoader(dataset2_train, batch_size=32, shuffle=True)\nvalidloader = torch.utils.data.DataLoader(dataset2_valid, batch_size=32, shuffle=True)\ntestloader = torch.utils.data.DataLoader(dataset2_test, batch_size=1, shuffle=True)","e29cf00a":"\ncnn2_model = ConModel()\ncnn2_model.to(device)\n\nepoch = 10 #tunable hyperparameter\noptimizer = torch.optim.Adam(cnn2_model.parameters(),0.00001,weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=.3,threshold=1e-4)\n\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy,accuracy_val ,valid_loss,model=run_model(cnn2_model,trainloader,validloader,optimizer)\n    cnn2_model= model\n    print('Epoch {} CNN with augemented Data, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\nprint()\nprint(\"test accuracy of CNN with augemented Data\")\ntest_model(cnn2_model,testloader) \nprint()","68783868":"\n\ncnn_model_few = ConModel_few()\ncnn_model_few.to(device)\n\nepoch = 5 #tunable hyperparameter\noptimizer = torch.optim.Adam(cnn_model_few.parameters(),0.00001,weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=.3,threshold=1e-4)\n\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy,accuracy_val ,valid_loss,model=run_model(cnn_model_few,dataloader_train,dataloader_valid,optimizer)\n    cnn_model_few= model\n    print('Epoch {} for CNN(few), Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\nprint()\nprint(\"test accuracy cnn_model_few layers\")\ntest_model(cnn_model_few,dataloader_test) \nprint()","520807f2":"class FullyManyModel(nn.Module):\n    def __init__(self):\n        super(FullyManyModel, self).__init__()  #inheriting functionality of nn module\n        self.dropout1= nn.Dropout(0.25)\n        self.dropout2= nn.Dropout(0.5)\n        self.fc1 = nn.Linear(48387, 2048)\n        self.fc2 = nn.Linear(2048, 1024)  \n        self.fc3 = nn.Linear(1024, 512)\n        self.fc4 = nn.Linear(512, 256)\n        self.fc5 = nn.Linear(256, 128)\n        self.fc6 = nn.Linear(128, 64)\n        self.fc7 = nn.Linear(64, 3)\n\n    def forward(self, x):\n        x = F.relu(x)\n        x = F.max_pool2d(x,2)\n        x = self.dropout1(x)\n        x = torch.flatten(x,1)\n        #print (x.shape)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(self.dropout2(x))\n        x = torch.flatten(x,1)\n        x = F.relu(x)\n        x = self.fc3(x)\n        x = F.relu(x)\n        x = self.fc4(x)\n        x = torch.flatten(x,1)\n        x = F.relu(x)\n        x = self.fc5(x)\n        x = F.relu(x)\n        x = self.fc6(x)\n        x = torch.flatten(x,1)\n        x = F.relu(x)\n        x = self.fc7(x)\n        output = F.log_softmax(x,dim=1)\n        return output","6eb6d54e":"class FullyFewModel(nn.Module):\n    def __init__(self):\n        super(FullyFewModel, self).__init__()  #inheriting functionality of nn module\n        self.dropout1= nn.Dropout(0.25)\n        self.fc1 = nn.Linear(48387, 84)\n        self.fc2 = nn.Linear(84, 3)  \n        \n\n    def forward(self, x):\n        x = F.relu(x)\n        x = F.max_pool2d(x,2)\n        x = self.dropout1(x)\n        x = torch.flatten(x,1)\n        #print(x.shape)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x) \n        output = F.log_softmax(x,dim=1)\n        return output","287b6bb9":"from sklearn.metrics import f1_score\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n\nfcnMany_model = FullyManyModel()\n\nfcnMany_model.to(device)\n\nepoch = 7 #tunable hyperparameter\noptimizer = torch.optim.Adam(fcnMany_model.parameters(),0.00001,weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=.3,threshold=1e-4)\n\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,fcnMany_model=run_model(fcnMany_model,dataloader_train,dataloader_valid,optimizer)\n    print('Epoch {} for Fully Connected Network (many), Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n    \nprint()\nprint(\"test accuracy fcnMany_model\")\ntest_model(fcnMany_model,dataloader_test) \nprint()","344f24fb":"fcnFew_model = FullyFewModel()\nfcnFew_model.to(device)\n\nepoch = 5 #tunable hyperparameter\noptimizer = torch.optim.Adam(fcnFew_model.parameters(),0.00001,weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=.3,threshold=1e-4)\n\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,fcnFew_model=run_model(fcnFew_model,dataloader_train,dataloader_valid,optimizer)\n    print('Epoch {}, Train Loss: {:.3f}'.format(e+1, loss), \"Training Accuracy: {:.3f}\" .format(accuracy),'Validation accuracy: {:.3f}'.format(accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n\nprint(\"test accuracy fcnFew_model\")\ntest_model(fcnFew_model,dataloader_test) \nprint()","40016e17":"def initialize_model(model_name, use_pretrained): #default:false\n\n    if model_name == \"resnet18\":\n        \"\"\" Resnet18\n        \"\"\"\n        resnet = models.resnet18(pretrained=use_pretrained) \n        \n       \n        if use_pretrained== True: #pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\n\n            num_ftrs = resnet.fc.in_features\n            resnet.fc = nn.Linear(num_ftrs, 3) #The last layer of the RestNet is a fully connected layer using nn.Linear\n            resnet.fc = resnet.fc.cuda() if torch.cuda.is_available() else resnet.fc\n            input_size = 255\n        else:\n            num_ftrs = resnet.fc.in_features\n            resnet.fc = nn.Linear(num_ftrs, 3) #3  output channels\n            resnet.fc = resnet.fc.cuda() if torch.cuda.is_available() else resnet.fc\n            input_size = 255\n            \n    \n    elif model_name == \"resnet50\":\n        resnet = models.resnet50(pretrained=use_pretrained) \n        if use_pretrained== True: #pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\n            num_ftrs = resnet.fc.in_features\n            resnet.fc = nn.Linear(num_ftrs, 3) #The last layer of the RestNet is a fully connected layer using nn.Linear\n            resnet.fc = resnet.fc.cuda() if torch.cuda.is_available() else resnet.fc\n            input_size = 255\n        else:\n            num_ftrs = resnet.fc.in_features\n            resnet.fc = nn.Linear(num_ftrs, 3) #3  output channels\n            resnet.fc = resnet.fc.cuda() if torch.cuda.is_available() else resnet.fc\n            input_size = 255\n        \n    return  resnet\n","a6c76b95":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nresnet_model= initialize_model(\"resnet18\", True)\nresnet_model.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer =  torch.optim.Adam(resnet_model.parameters(),0.00001,weight_decay=0.01)\nepoch = 5 #tunable hyperparameter\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(resnet_model,dataloader_train,dataloader_valid,optimizer)\n    resnet_model= model\n    print('Epoch {} for Pretrained ResNet 18, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\nprint()\nprint(\"test accuracy of resnet18 pretrained\")\ntest_model(resnet_model,dataloader_test) \nprint()\n\n# ----------------------------------------------------------------\n\nresnet_model= initialize_model(\"resnet18\", False)\nresnet_model.to(device)\n\nepoch = 5 #tunable hyperparameter\ne=0\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(resnet_model,dataloader_train,dataloader_valid,optimizer)\n    resnet_model= model\n    print('Epoch {} for ResNet 18, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\nprint()\n\nprint(\"test accuracy of ResNet 18 NOT pretrained\")\ntest_model(resnet_model,dataloader_test) \nprint()\n#-------------------------------------------------------------------    \n    \nresnet_model= initialize_model(\"resnet50\", True)\nresnet_model.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer =  torch.optim.Adam(resnet_model.parameters(),0.00001,weight_decay=0.01)\nepoch = 5 #tunable hyperparameter\ne=0\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(resnet_model,dataloader_train,dataloader_valid,optimizer)\n    resnet_model= model\n    print('Epoch {}  ResNet50 pretrained , Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n\nprint(\"test accuracy of ResNet50 pretrained\")\ntest_model(resnet_model,dataloader_test) \nprint()\n#-------------------------------------------------------------------\nresnet_model= initialize_model(\"resnet50\", False)\nresnet_model.to(device)\n\n\nepoch = 5 #tunable hyperparameter\ne=0\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(resnet_model,dataloader_train,dataloader_valid,optimizer)\n    resnet_model= model\n    print('Epoch {} ResNet50, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n\n\nprint(\"test accuracy of ResNet50 NOT pretrained\")\ntest_model(resnet_model,dataloader_test) \nprint()\n","ec364cf9":"def init_model(model_name, use_pretrained): #default:false\n\n    if model_name == \"densenet\":\n       \n        \n       \n        if use_pretrained== True: #pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\n            model_ft = models.densenet121(pretrained=use_pretrained)\n            #set_parameter_requires_grad(model_ft, feature_extract)\n            num_ftrs = model_ft.classifier.in_features\n            model_ft.classifier = nn.Linear(num_ftrs, 3)\n\n        else:\n            model_ft = models.densenet121(pretrained=use_pretrained)\n            #set_parameter_requires_grad(model_ft, feature_extract)\n            num_ftrs = model_ft.classifier.in_features\n            model_ft.classifier = nn.Linear(num_ftrs, 3)\n        \n            \n    \n        \n    return  model_ft","52e788bf":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nd_model= init_model(\"densenet\", True)\nd_model.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer =  torch.optim.Adam(d_model.parameters(),0.00001,weight_decay=0.01)\nepoch = 5 #tunable hyperparameter\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy,accuracy_val ,valid_loss,model=run_model(d_model,dataloader_train,dataloader_valid,optimizer)\n    d_model= model\n    print('Epoch {} for DenseNet Pretrained, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n\n    \nprint(\"test accuracy of densenet pretrained\")\ntest_model(resnet_model,dataloader_test) \nprint()    ","bd961f3c":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nd_model= init_model(\"densenet\", False)\nd_model.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer =  torch.optim.Adam(d_model.parameters(),0.00001,weight_decay=0.01)\nepoch = 5 #tunable hyperparameter\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy,accuracy_val ,valid_loss,model=run_model(d_model,dataloader_train,dataloader_valid,optimizer)\n    d_model= model\n    print('Epoch {} for DenseNet NOT Pretrained, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n\n    \n    \nprint(\"test accuracy of densenet NOT pretrained\")\ntest_model(resnet_model,dataloader_test) \nprint()","6ba23af8":"transform =transforms.Compose([transforms.Resize(312),transforms.CenterCrop(299),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ndataset_train_v = datasets.ImageFolder(train_data, transform=transform) # ImageFolder for each class COVID , Normal , Pneumia\ndataset_valid_v = datasets.ImageFolder(valid_data, transform=transform)\ndataset_test_v = datasets.ImageFolder(test_data, transform=transform)\ndataloader_train_v = torch.utils.data.DataLoader(dataset_train_v, batch_size=32, shuffle=True)\ndataloader_valid_v = torch.utils.data.DataLoader(dataset_valid_v, batch_size=32, shuffle=True)\ndataloader_test_v = torch.utils.data.DataLoader(dataset_test_v, batch_size=32, shuffle=True)","5ecbda16":"model_ft = models.inception_v3(pretrained=True)  \n# model_ft.logits.log_softmax(1)\n    \nnum_ftrs = model_ft.AuxLogits.fc.in_features\nmodel_ft.AuxLogits.fc = nn.Linear(num_ftrs, 3)\n\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs,3)\n\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_ft.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer =  torch.optim.Adam(model_ft.parameters(),0.00001,weight_decay=0.01)\nepoch = 5 #tunable hyperparameter\n\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(model_ft,dataloader_train_v,dataloader_valid_v,optimizer)\n    model_ft= model\n    print('Epoch {} for nception_v3 Pretrained, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n    \n    \nprint(\"test accuracy of nception_v3 pretrained\")\ntest_model(model_ft,dataloader_test) \nprint()\n    ","cec992a2":"model_ft = models.inception_v3(pretrained=False)  \n# model_ft.logits.log_softmax(1)\n    \nnum_ftrs = model_ft.AuxLogits.fc.in_features\nmodel_ft.AuxLogits.fc = nn.Linear(num_ftrs, 3)\n\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs,3)\n\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_ft.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer =  torch.optim.Adam(model_ft.parameters(),0.00001,weight_decay=0.01)\nepoch = 5 #tunable hyperparameter\n\n\nfor e in range(epoch):\n    labels , pred, loss, accuracy, accuracy_val,valid_loss,model=run_model(model_ft,dataloader_train_v,dataloader_valid_v,optimizer)\n    model_ft= model\n    print('Epoch {} for nception_v3 NOT Pretrained, Train Loss: {:.3f}'.format(e+1, loss), 'Train Accuracy: {:.3f}%'.format(100*accuracy),'Validation accuracy: {:.3f}%'.format(100*accuracy_val),'Validation Loss: {:.3f}'.format(valid_loss))\n    \n    \nprint(\"test accuracy of nception_v3 NOT pretrained\")\ntest_model(model_ft,dataloader_test) \nprint()\n    ","29d1dc5c":"**Inceptionv3**","d30bdbe4":"**ResNet Model 18-50**","1bb0ca95":"**Fully Connected Network**","9a6db516":"**Densenet**","6dc6e1a3":"Conv Neural Network Model\n","78fd74ea":"**Data Augementation**"}}