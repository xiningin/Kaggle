{"cell_type":{"a9d17352":"code","36ddb503":"code","626ca4fc":"code","e371d708":"code","607cbc6d":"code","2ea77226":"code","3b6b76aa":"code","af40229b":"code","9d77c127":"code","a402f424":"code","46ea4706":"code","c70f05b9":"code","7c86fcbb":"code","debde126":"code","5ef0bc46":"code","838ad337":"code","2c4a6675":"code","a6151d44":"code","6bb56e79":"code","94662a01":"code","5a372270":"code","fcde4b95":"code","7838ae03":"code","a748ada6":"code","aac14166":"code","31e6f3af":"code","4354389e":"code","949fbb0b":"code","5b6b211f":"code","af67cae9":"code","8f13d77e":"code","da0a3942":"code","b4f64f16":"code","b779fc42":"code","717cb3aa":"code","c9864fb4":"code","fd711178":"code","12bf38ac":"code","c4334d1a":"code","dc9fed6e":"code","f3304b8a":"code","814058cc":"code","fc819830":"code","e82b2f4a":"code","1de7a6fb":"code","0c0d36c3":"code","8e0d5bd5":"code","9512208b":"code","43ea1720":"code","e67d0056":"code","cf6af4e4":"code","f3762a8b":"code","9590b047":"code","c7887194":"code","76aa063d":"code","4b6af9ee":"code","1c9e47bb":"code","b236fdbf":"code","4c16bf1e":"code","b2dc1984":"markdown"},"source":{"a9d17352":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","36ddb503":"data = pd.read_csv('..\/input\/2017.csv')","626ca4fc":"data.info()","e371d708":"data.corr()","607cbc6d":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18)) #2 tane future aras\u0131nda corelation 1 ise bu\u0131nlar aralar\u0131nda dogru orant\u0131l\u0131d\u0131r.#figure size i ayarlar\u0131z \nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax) #mt ondal\u0131k rakam say\u0131s\u0131,annot true \u00fcst\u00fcne rakamlar yaz\u0131ls\u0131n m\u0131\nplt.show()","2ea77226":"data.head(10)#first 10 rows","3b6b76aa":"data.columns","af40229b":"# Line Plot\n\ndata['Economy..GDP.per.Capita.'].plot(kind = \"line\", color = \"red\",label = \"Economy.GDP.per.Capita.\",linewidth = 1, alpha = 0.6, grid = True,linestyle = \":\")\ndata['Health..Life.Expectancy.'].plot( color = \"green\",label = \"Health..Life.Expectancy.\",linewidth = 1, alpha = 0.5, grid = True,linestyle = \"-\")\nplt.legend(loc = \"upper right\")\nplt.xlabel(\"x axis\")\nplt.ylabel(\"y axis\")\nplt.title(\"Line Plot\")\nplt.show()","9d77c127":"# Scatter Plot \ndata.plot(kind='scatter', x='Economy..GDP.per.Capita.', y='Health..Life.Expectancy.',alpha = 0.7,color = 'orange')\nplt.xlabel('Economy..GDP.per.Capita.')              # label = name of label \nplt.ylabel('Health..Life.Expectancy.')\nplt.title('Economy..GDP.per.Capita.- Health.Life.Expectancy. Scatter Plot')            # title = title of plot","a402f424":"data['Economy..GDP.per.Capita.'].plot(kind = 'hist',bins = 30,figsize = (12,12))","46ea4706":"data_frame = data[['Economy..GDP.per.Capita.']]  # data[['Defense']] = data frame\ndate_series=data['Economy..GDP.per.Capita.']\nprint(type(data_frame))\nprint(type(date_series))","c70f05b9":"# 1 - Filtering Pandas data frame\nx = data['Health..Life.Expectancy.']>0.8\ndata[x]","7c86fcbb":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Health..Life.Expectancy.']>0.8) & (data['Economy..GDP.per.Capita.']>1.5)]","debde126":"# CLEANING DATA 2nd homework :)\n","5ef0bc46":"data = pd.read_csv('..\/input\/2017.csv')\ndata.head()  # head shows first 5 rows","838ad337":"# tail shows last 5 rows\ndata.tail()\n","2c4a6675":"# columns gives column names of features\ndata.columns","a6151d44":"# shape gives number of rows and columns in a tuble\ndata.shape","6bb56e79":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","94662a01":"# For example lets look frequency of pokemom types\nprint(data['Whisker.high'].value_counts(dropna =False))  # if there are nan values that also be counted\n","5a372270":"data.describe() #ignore null entries -only numeric types","fcde4b95":"data.info()\n","7838ae03":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Generosity')\nplt.show()","a748ada6":"# Firstly I create new data from main data to explain melt nore easily.\ndata_new=data.head()\ndata_new","aac14166":"# lets melt\n#frame=melt edilecek datam\u0131z\n# id_vars = what we do not wish to melt\/ yani ilgili s\u00fctunun yeni melt durumunda de\u011fi\u015fmeden ayn\u0131 kalmas\u0131n\u0131 saglamakt\u0131r\n# value_vars = what we want to melt \/de\u011fi\u015fecek k\u0131s\u0131m ilki variable ikincisi value yani asl\u0131nda o sat\u0131r\u0131 melt etmi\u015f eritmi\u015f olduk\nmelted = pd.melt(frame=data_new,id_vars = 'Country', value_vars= ['Economy..GDP.per.Capita.','Health..Life.Expectancy.'])\nmelted","31e6f3af":"# PIVOTING DATA\n# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Country', columns = 'variable',values='value')","4354389e":"# CONCATENATING DATA\n# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row\n\n","949fbb0b":"data1 = data['Country'].head()\ndata2= data['Happiness.Score'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 0 : adds dataframes in row\nconc_data_col","5b6b211f":"# DATA TYPES\ndata.dtypes","af67cae9":"# lets convert object(str) to categorical and int to float.\ndata['Country'] = data['Country'].astype('category')\ndata['Happiness.Rank'] = data['Happiness.Rank'].astype('float')\n","8f13d77e":"#new dttypes\ndata.dtypes","da0a3942":"# MISSING DATA and TESTING WITH ASSERT\ndata.info()\n# Lets drop nan values\n# data1=data   # also we will use data to fill missing value so I assign it to data1 variable\n# data1[\"Happiness.Rank\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# but not null variable-not avaible","b4f64f16":"assert  data['Happiness.Rank'].notnull().all() # returns nothing because we dont have nan values","b779fc42":"data.columns\n","717cb3aa":"# 4. PANDAS FOUNDATION \n\n# Plotting all data \ndata1 = data.loc[:,[\"Economy..GDP.per.Capita.\",\"Health..Life.Expectancy.\",\"Trust..Government.Corruption.\"]]\ndata1.plot()\n# it is confusing","c9864fb4":"# subplots\ndata1.plot(subplots = True)\nplt.show()","fd711178":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Economy..GDP.per.Capita.\",y = \"Trust..Government.Corruption.\")\nplt.show()","12bf38ac":"# INDEXING PANDAS TIME SERIES\ntime_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)#listeyi date time format\u0131na \u00e7evirmemizi saglar\nprint(type(datetime_object))","c4334d1a":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of our data and add it a time list\ndata2 = data.head()\ndate_list = [\"2000-01-10\",\"2000-02-10\",\"2000-03-10\",\"2001-03-15\",\"2001-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")#index de\u011fi\u015ftirmemizi saglar bu metod\ndata2 ","dc9fed6e":"# Now we can select according to our date index\nprint(data2.loc[\"2001-03-16\"])\nprint(data2.loc[\"2000-03-10\":\"1993-03-16\"])","f3304b8a":"# RESAMPLING PANDAS TIME SERIES\n# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","814058cc":"# Lets resample with month\ndata2.resample(\"M\").sum()\n# As you can see there are a lot of nan because data2 does not include all months","fc819830":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")#say\u0131sal k\u0131s\u0131mlarda bo\u015f olan k\u0131s\u0131mlar\u0131 linear olarak doldur","e82b2f4a":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").mean().interpolate(\"linear\")\n","1de7a6fb":"# MANIPULATING DATA FRAMES WITH PANDAS\n# read data\ndata = pd.read_csv('..\/input\/2017.csv')\n#data= data.set_index(\"#\")#id futurune u index yapt\u0131k yani 0 yerine 1 den baslayacak\ndata.head()","0c0d36c3":"# indexing using square brackets\ndata[\"Happiness.Rank\"][1]","8e0d5bd5":"# using loc accessor\ndata.loc[1,[\"Happiness.Rank\"]]","9512208b":"# Selecting only some columns\ndata[[\"Happiness.Score\",\"Family\"]].head(10)","43ea1720":"# SLICING DATA FRAME\n# Slicing and indexing series\ndata.loc[0:10,\"Happiness.Score\":\"Family\"]   # 10 and \"Defense\" are inclusive","e67d0056":"# Reverse slicing \ndata.loc[10:1:-1,\"Happiness.Score\":\"Family\"] ","cf6af4e4":"# From something to end\ndata.loc[0:10,\"Family\":] # en sonuncusuna kadar git","f3762a8b":"# FILTERING DATA FRAMES\n# Creating boolean series\nboolean = data.Freedom > 0.5\ndata[boolean]","9590b047":"# Combining filters\nfirst_filter = data.Freedom > 0.4\nsecond_filter = data.Generosity > 0.3 #nokta i\u00e7eren alanlar i\u00e7in farkl\u0131 bir g\u00f6sterim ile se\u00e7im yapar\u0131z aksi taktirde hata al\u0131r\u0131z data[hapiness.rank]gibi\ndata[first_filter & second_filter]","c7887194":"# Filtering column based others\ndata.Country[data.Freedom<0.2]","76aa063d":"# TRANSFORMING DATA\n# Plain python functions\ndef ekstra(n):\n    return n*2\ndata[\"Economy..GDP.per.Capita.\"].apply(ekstra)\n","4b6af9ee":"# Or we can use lambda function\ndata[\"Economy..GDP.per.Capita.\"].apply(lambda n : n*2)","1c9e47bb":"# Defining column using other columns\ndata[\"total_freedom_generosity\"] = data.Freedom + data.Generosity\ndata.head()","b236fdbf":"# HIERARCHICAL INDEXING\n# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/2017.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","4c16bf1e":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Country\",\"Happiness.Rank\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","b2dc1984":"<a id=\"20\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it."}}