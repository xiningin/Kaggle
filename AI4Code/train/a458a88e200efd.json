{"cell_type":{"41d5e247":"code","7d48c269":"code","57b41b8b":"code","4981f85e":"code","eccd8391":"code","d7d9a67a":"code","e8e2877d":"code","2c3e5cf5":"code","faaad9a1":"code","be7c15c1":"code","40458898":"code","d16b415f":"code","955a019e":"code","6b0f9fb5":"code","ce636f94":"code","c87295b8":"code","a3a5e304":"code","7935f8d8":"code","351c2ff2":"code","a64212c7":"code","f6e4b693":"code","a55b5d55":"code","e0db5f05":"code","a2cf9d59":"code","4c583b13":"code","163fc4fb":"code","d8fc9d5e":"markdown","1cd58e01":"markdown","a41cc7f0":"markdown","96b69e24":"markdown","fa846d00":"markdown","b533732f":"markdown","93caf893":"markdown","07a16f83":"markdown","0a57363b":"markdown"},"source":{"41d5e247":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nimport os","7d48c269":"b30 = []\nblist = []\nh30 = []\nhlist = []","57b41b8b":"pth1 = '\/kaggle\/input\/gearbox-fault-diagnosis\/BrokenTooth'\npth2 = '\/kaggle\/input\/gearbox-fault-diagnosis\/Healthy'","4981f85e":"for file in os.listdir(pth1):\n    blist.append(os.path.join(pth1, file))\nblist.sort()\nblist","eccd8391":"for file in os.listdir(pth2):\n    hlist.append(os.path.join(pth2, file))\nhlist.sort()\nhlist","d7d9a67a":"grouped = 100","e8e2877d":"for file in blist:\n    b30.append(pd.read_csv(file))","2c3e5cf5":"for file in hlist:\n    h30.append(pd.read_csv(file))","faaad9a1":"b30[8]","be7c15c1":"# This function computes the standard deviation for a sample, where:\n##  - df:        the dataset, one variable per column\n##  - grouped:   the number of consecutive points (rows) in the time series to compute the standard deviation\n##  - outcome:   column added to the dataset representing healthy(=1) or failure (=0)\n##  RETURNS a dataset (df_result) where each column is the time serie of every variable\n\ndef stdev_features(df, grouped, load, outcome):\n    #### Create empty dataframe with columns a1,a2,a3,a4\n    df_result = pd.DataFrame( [ np.zeros(len(df.columns)-2) ],columns= df.columns[:-2])\n\n    #### Aggregate in groups of nrows computing the standard deviation\n    # Remove load & failure columns, keeping only a1,a2,a3,a4\n    stdev_lenght=len(df.columns)-2\n    \n    #### Compute number of rows of the aggregated dataframe\n    nrows_raw = len(df.index)\n    nrows = math.floor(nrows_raw \/ grouped)\n    nrows_dropped = nrows_raw - nrows*grouped\n    print(\"nrows_raw=\", nrows_raw, \"   nrows=\", nrows, \"   Number of dropped rows of grouped= \", nrows_dropped\/grouped*100,\"%\\n\")\n    \n    # Iterate every 'grouped' rows and compute stdev per column\n    for i in range(nrows):\n        df_group = df.iloc[i*grouped:i*grouped+grouped,:]\n        df_stdev = pd.DataFrame(df_group.std()).transpose()\n        # Remove load & failure columns\n        df_stdev=df_stdev.iloc[:,:stdev_lenght]\n        # Add row of calculated stdev\n        df_result = df_result.append(df_stdev, ignore_index=True)\n\n        #print (\"i*grouped TO i*grouped+grouped\", i*grouped, i*grouped+grouped)\n        #print (\"row, df_stdev=\\n\", row, df_stdev.iloc[:,:])\n        #print (\"df_result=\\n\", df_result)\n        #print(\"row\", i, \"\\n\", df_group)\n\n\n    # Remove the first row (it was the seed of zeros for initializing df_result)\n    #print(df_result)\n    df_result = df_result.iloc[1:,:]\n    # Add the column for 'load'\n    df_result['load'] = load*np.ones((nrows,1))\n\n    # Add the column for 'failure'\n    failure = np.ones((nrows,1))\n    df_result['failure'] = outcome\n    print(df_result)\n    \n    return df_result","40458898":"b30[0].describe()","d16b415f":"b30_stdev = []\nh30_stdev = []","955a019e":"list(range(len(b30)))","6b0f9fb5":"for i in range(len(b30)):\n    load = 10*i\n\n    b30[i][\"load\"] = load\n\n    ##   0 is healthy\n    ##   1 is broken\n    failure = 1\n    b30[i]['failure'] = failure\n    \n    b30_stdev.append(stdev_features (df = b30[i], grouped = grouped, load = load, outcome = failure))","ce636f94":"for i in range(len(h30)):\n    load = 10*i\n\n    h30[i][\"load\"] = load\n\n    ##   0 is healthy\n    ##   1 is broken\n    failure = 0\n    h30[i]['failure'] = failure\n    \n    h30_stdev.append(stdev_features (df = h30[i], grouped = grouped, load = load, outcome = failure))","c87295b8":"len(b30_stdev)","a3a5e304":"print(\"Load 0%\")\nprint(\"-------\")\nstdev_bhz0 = pd.DataFrame(b30_stdev[0].iloc[:,:-2].mean()).transpose()\nstdev_hhz0 = pd.DataFrame(h30_stdev[0].iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz0)\nprint(\"Healthy:\\n\", stdev_hhz0)","7935f8d8":"print(\"Load 10%\")\nprint(\"--------\")\nstdev_bhz10 = pd.DataFrame(b30_stdev[1].iloc[:,:-2].mean()).transpose()\nstdev_hhz10 = pd.DataFrame(h30_stdev[1].iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz10)\nprint(\"Healthy:\\n\", stdev_hhz10)","351c2ff2":"b30hz_stdev = b30_stdev[0]","a64212c7":"for i in range(1,10):\n    b30hz_stdev = b30hz_stdev.append(b30_stdev[i])","f6e4b693":"b30hz_stdev.describe()","a55b5d55":"b30hz_stdev.to_csv('\/kaggle\/working\/b30hz_stdev_100.csv', index = False)","e0db5f05":"h30hz_stdev = h30_stdev[0]","a2cf9d59":"for i in range(1,10):\n    h30hz_stdev = h30hz_stdev.append(h30_stdev[i])","4c583b13":"h30hz_stdev.describe()","163fc4fb":"h30hz_stdev.to_csv('\/kaggle\/working\/h30hz_stdev_100.csv', index = False)","d8fc9d5e":"## Read datasets\n### Healthy gearbox","1cd58e01":"### Load= 0%","a41cc7f0":"## Export BROKEN dataframe as CSV","96b69e24":"## Compare stdev of acceleration traversing % load","fa846d00":"INPUT Number of rows for aggregated dataset","b533732f":"## Export HEALTHY dataframe as CSV","93caf893":"## Stacked BROKEN dataframe","07a16f83":"## Compute aggregated datasets\n### Function to compute aggregated features: standard deviation","0a57363b":"## Stacked HEALTHY dataframe"}}