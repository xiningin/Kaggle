{"cell_type":{"e49ca006":"code","9620c3ff":"code","0b12862b":"code","29aa0ccd":"code","d80f57c2":"code","f8d65ee5":"code","90e62e82":"code","5d301cb0":"code","e1768960":"code","d38184e2":"code","c837d454":"code","137631cc":"code","be438a3a":"code","1ed76fa3":"code","c628bd83":"code","c26cfc3c":"code","d2163449":"code","66bbaa89":"code","32ae48c9":"code","a6c5dc04":"code","930debec":"code","f1c781fa":"code","ccd2062b":"code","ae21f742":"code","b30a57eb":"code","e6db989e":"code","ee6b8c4d":"code","420766e2":"code","751cdb42":"code","9a729795":"code","73428055":"code","3083670d":"markdown","170deece":"markdown","19781c8b":"markdown","d74ed53a":"markdown","ae57334f":"markdown","29ac028a":"markdown","2f6b3401":"markdown","88b56d2b":"markdown","c7d99c41":"markdown","2df8a79d":"markdown","1109a67a":"markdown","175ee55c":"markdown","80680ca4":"markdown","0f180002":"markdown"},"source":{"e49ca006":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9620c3ff":"df_train = pd.read_csv(r'\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv')\ndf_train.head()","0b12862b":"import json \n\nwith open(r'\/kaggle\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json') as json_file: \n    label_map = json.load(json_file) \n\nlabel_map = {int(k):v for k,v in label_map.items()}\nlabel_map","29aa0ccd":"df_train['disease'] = df_train['label'].map(label_map)\ndf_train","d80f57c2":"import glob\ntrain_path = glob.glob(r'\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/*.jpg')\ntrain_path.sort()\nprint(len(train_path))","f8d65ee5":"df_train['path'] = train_path\ndf_train","90e62e82":"df_train.groupby(['disease']).size().plot(kind='bar')","5d301cb0":"import matplotlib.pyplot as plt\nfrom PIL import Image","e1768960":"img = Image.open(df_train.path[0])\nimg","d38184e2":"img.size","c837d454":"from tqdm.notebook import tqdm #to monitor progress\nnp.random.seed(42) #to get reproducible results","137631cc":"df_samp = pd.DataFrame()\n\ndf_samp = df_samp.append(df_train.sample(2000), ignore_index=True)\n\ndf_samp.groupby(by='disease').count()","be438a3a":"from sklearn.utils import shuffle\n\ndf_samp = shuffle(df_samp).reset_index(drop=True) #shuffling the dataframe","1ed76fa3":"from sklearn.model_selection import train_test_split\n\nX = df_samp.drop(columns=['label'])\ny = df_samp.label\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, stratify=y)\n\nprint(X_train.shape)\nprint(len(y_train))\nprint(X_valid.shape)\nprint(len(y_valid))","c628bd83":"compressed_size = (200,150)","c26cfc3c":"train_array = np.array([np.asarray(Image.open(path).resize(compressed_size, Image.ANTIALIAS)) for path in tqdm(X_train.path)])\nvalid_array = np.array([np.asarray(Image.open(path).resize(compressed_size, Image.ANTIALIAS)) for path in tqdm(X_valid.path)])\n\nprint(train_array.shape)\nprint(valid_array.shape)","d2163449":"plt.figure(figsize=(20,12))\n\nfor i, img in tqdm(enumerate(train_array[:5])):\n    plt.subplot(1, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(img)\n    plt.title(X_train.disease.iloc[i])\n    plt.xlabel(X_train.image_id.iloc[i])\n\nplt.show()","66bbaa89":"plt.figure(figsize=(20,12))\n\nfor i, img in tqdm(enumerate(valid_array[:5])):\n    plt.subplot(1, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(img)\n    plt.title(X_valid.disease.iloc[i])\n    plt.xlabel(X_valid.image_id.iloc[i])\n\nplt.show()","32ae48c9":"print(f'Length of the training array is {len(train_array)}')\nprint(f'Shape of the training array is {train_array.shape}')\nprint(f'Shape of each training image array is {train_array[0].shape}')","a6c5dc04":"train_array.resize(len(train_array), train_array.shape[1]*train_array.shape[2]*train_array.shape[3])\n\nprint(f'New length of the training array is {len(train_array)}')\nprint(f'New shape of the training array is {train_array.shape}')\nprint(f'New shape of each training image array is {train_array[0].shape}')","930debec":"valid_array.resize(len(valid_array), valid_array.shape[1]*valid_array.shape[2]*valid_array.shape[3])\n\nprint(f'New length of the validation array is {len(valid_array)}')\nprint(f'New shape of the validation array is {valid_array.shape}')\nprint(f'New shape of each validation image array is {valid_array[0].shape}')","f1c781fa":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(class_weight='balanced', verbose=5, n_jobs=-1)","ccd2062b":"lr.fit(train_array, y_train)","ae21f742":"preds = lr.predict(valid_array)\npreds","b30a57eb":"from sklearn.metrics import confusion_matrix, classification_report, f1_score\nimport seaborn as sns\n\nlabel = sorted(y_valid.unique())\nsns.heatmap(confusion_matrix(y_valid, preds), annot=True, square=True, fmt='g', \n            xticklabels=label, yticklabels=label, cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(classification_report(y_valid, preds))","e6db989e":"test_path = glob.glob(r'\/kaggle\/input\/cassava-leaf-disease-classification\/test_images\/*.jpg')\ntest_path.sort()\nprint(len(test_path))\ntest_path","ee6b8c4d":"Image.open(test_path[0])","420766e2":"test_array = np.array([np.asarray(Image.open(path).resize(compressed_size, Image.ANTIALIAS)) for path in tqdm(test_path)])\ntest_array.resize(len(test_array), test_array.shape[1]*test_array.shape[2]*test_array.shape[3])","751cdb42":"submission = lr.predict(test_array)\nsubmission","9a729795":"submission_df = pd.DataFrame({'image_id':[path.split('\/')[-1] for path in test_path], \n                              'label':submission})\nsubmission_df","73428055":"submission_df.to_csv('\/kaggle\/working\/submission.csv', index=False)","3083670d":"An accuracy of 54% is definitely not bad for a simple logreg model trained on just 4.3% of the training set, and with the training images compressed by a factor of 8 (random guessing would give an accuracy of 20%).\n\nLets see how we can improve this accuracy in further versions of this notebook.\nWould love you have your suggestions too!","170deece":"# Creating Training DF\n\nWe will create a dataframe containing the training image ID, label, and path","19781c8b":"# Train-Test split","d74ed53a":"#### To take equal number of samples from each category\ndf_samp = pd.DataFrame()\n\nfor label in tqdm(df_train.label.unique()):\n    df_samp = df_samp.append(df_train[df_train.label==label].sample(100), \n                           ignore_index=True)\n\ndf_samp.groupby(by='disease').count()","ae57334f":"Each image is of size 800x600 pixels","29ac028a":"This is a very imbalanced dataset","2f6b3401":"# Submission","88b56d2b":"The training input array currently has 700 rows, with each row containing the image array.\n\nSince a LogReg model accepts each input as a row array, we need to reshape our image arrays to a single row having `150`x`200`x`3` values.\n\nThe shape of the input array will then become `(700, 150*200*3)`","c7d99c41":"# Model Instantiation and Training","2df8a79d":"# Taking a subsample of the set to prevent RAM overflow","1109a67a":"# Disclaimer\nThis is supposed to be a baseline notebook for those starting with image classification. Please don't expect SoTA results :D","175ee55c":"# Prediction and Evaluation","80680ca4":"# First look at the Images","0f180002":"# Reducing image size and saving images as arrays"}}