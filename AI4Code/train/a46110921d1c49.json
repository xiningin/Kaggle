{"cell_type":{"b650627c":"code","f7e0c130":"code","df8ae619":"code","fe5eeae0":"code","3838cb00":"code","f01127df":"code","1cf9fa9c":"code","e241c85f":"code","ef478b51":"code","bd5208cd":"code","84ad1a03":"code","2d49eb6c":"code","d7d06146":"code","a24e21c4":"code","a4ae95d5":"code","b862adcd":"code","cb4601aa":"code","3041bafd":"code","bad281e3":"code","5565c123":"code","e4167ca5":"code","cba95663":"code","995b63c8":"code","ff2a35af":"code","3f59ad7c":"code","10c87bce":"code","11eeae9a":"code","90509dbc":"code","1be2334e":"markdown","f683a4a4":"markdown","570cef47":"markdown","d74e9ea4":"markdown","c5f7c15d":"markdown","97f89037":"markdown","169290d2":"markdown","6ba24df1":"markdown","a57f4af0":"markdown","bdfff52e":"markdown","a35fafa6":"markdown","6955ddd3":"markdown"},"source":{"b650627c":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import PolynomialFeatures, LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\n\nimport sklearn.pipeline as pp\n\n# allow plot to appear directly in the notebook\n%matplotlib inline\n\n# \npd.set_option('max_columns', 24)","f7e0c130":"pumpkin_nw = pd.read_csv('..\/input\/a-year-of-pumpkin-prices\/new-york_9-24-2016_9-30-2017.csv')\npumpkin_la = pd.read_csv('..\/input\/a-year-of-pumpkin-prices\/los-angeles_9-24-2016_9-30-2017.csv')\n\n# checking the first 5 row of new_york data\npumpkin_la.head()","df8ae619":"# checking the first 5 row of los_angeles data \npumpkin_nw.head()","fe5eeae0":"# check both the dataframe columns are same\n\npumpkin_la.columns.values in pumpkin_nw.columns.values","3838cb00":"# print now of row and columsn\npumpkin_la.shape, pumpkin_nw.shape","f01127df":"# append both the data frame\n\npumpkin_la_nw = pumpkin_la.append(pumpkin_nw)","1cf9fa9c":"# check the new combine data frame\npumpkin_la_nw.shape","e241c85f":"# checkin for missing values\npumpkin_la_nw.isnull().sum()","ef478b51":"# check both the low and mostly low an high and mostly high price are same or not\n\ncols = ['Low Price', 'High Price']\ncols2 = ['Mostly Low', 'Mostly High']\ndef check_price(cols, cols2):\n    for j, no in enumerate(cols):\n        col1_value = pumpkin_la_nw[cols[j]].values\n        col2_value = pumpkin_la_nw[cols2[j]].values\n\n        if col1_value not in col2_value:\n\n            print(col1_value ,'---------'  ,col2_value)\n\ncheck_price(cols, cols2)","bd5208cd":"# keep only the below columns and drop all\n \nnew_cols_name = ['Item Size', 'price']","84ad1a03":"# take the average of the price\npumpkin_la_nw['price'] = pumpkin_la_nw['Low Price'] + pumpkin_la_nw['High Price'] \/ 2","2d49eb6c":"pumpkin_la_nw.head()","d7d06146":"# keep only the selected columns\n\npumpkin_la_nw = pumpkin_la_nw.drop([c for c in pumpkin_la_nw.columns if c not in new_cols_name], axis='columns')","a24e21c4":"pumpkin_la_nw.head()","a4ae95d5":"# check missing values \npumpkin_la_nw.isnull().sum()","b862adcd":"# there are 24 missing values in 'item size' column\n# will fill those missing value with the most common value\npumpkin_la_nw['Item Size'].value_counts()","cb4601aa":"# will fill those missing value with the most common value\npumpkin_la_nw['Item Size'].fillna('lge', inplace=True)","3041bafd":"# verify if there is any missing vaues\npumpkin_la_nw.isnull().sum()","bad281e3":"# transform all the categorical value to numeric value\n\nlabel_enode = LabelEncoder()\n\npumpkin_la_nw.iloc[:, 0:-1] = pumpkin_la_nw.iloc[:, 0:-1].apply(LabelEncoder().fit_transform)","5565c123":"pumpkin_la_nw","e4167ca5":"# checking for outliers in price\n\nsns.boxplot(pumpkin_la_nw['price'])","cba95663":"# splitting into dependent and independent variable\nx = pumpkin_la_nw.iloc[:,0:-1]\ny = pumpkin_la_nw.iloc[:, -1]","995b63c8":"# set the degree of the polyniomial\ny_poly = PolynomialFeatures(degree=4).fit_transform(x)","ff2a35af":"\n# add a const of\nx2 = sm.add_constant(x)\n\n# use old for prediction\npg_stats_model = sm.OLS(y, x2)\n\n# fit the model\nresults = pg_stats_model.fit()\n\nprint(results.summary())","3f59ad7c":"# train and test split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","10c87bce":"# create an instance of logistic regression\nlogistic_model = LinearRegression()\n\n# fit the data\nlogistic_model.fit(x_train, y_train)\n\n# predict with the test set\ny_predict = logistic_model.predict(x_test)\n\n# predict with the training set\ny_predict_train = logistic_model.predict(x_train)","11eeae9a":"print('The Accuracy  on the training dataset is: ', logistic_model.score(x_train, y_train) )\nprint('The Accuracy r2  on the training dataset is: ',r2_score(y_train,y_predict_train) )   \n\nprint(\"\")\n# Model Accuracy on testing dataset\nprint('The Accuracy  on the testing dataset is: ', logistic_model.score(x_test, y_test) )\n\nprint(\"\")\n# The Root Mean Squared Error (RMSE)\nprint('The RMSE  on the training dataset is: ', np.sqrt(mean_squared_error(y_train,y_predict_train)))\nprint('The RMSE  on the testing dataset is: ',np.sqrt(mean_squared_error(y_test,logistic_model.predict(x_test))))\n\nprint(\"\")\n# The Mean Absolute Error (MAE)\nprint('The MAE  on the training dataset is: ',mean_absolute_error(y_train,y_predict_train))\nprint('The MAE  on the testing dataset is: ',mean_absolute_error(y_test,logistic_model.predict(x_test)))\n\n\nprint(\"\")\n# Coefficients\nprint('Coefficients: ', logistic_model.coef_ )\n\nprint(\"\")\n# The Intercept\nprint('Intercept: ', logistic_model.intercept_)\n","90509dbc":"plt.style.use('fivethirtyeight')\n\npd.Series((y_test - y_predict)).value_counts().sort_index().plot.bar(\n    title='$y - \\hat{y}$',\n    figsize=(16, 5)\n)","1be2334e":"## Loading Libraries","f683a4a4":"### Let's estimate the model coefficients using stats model","570cef47":"## Feature selection","d74e9ea4":"## Modal Evaluation metrics","c5f7c15d":"## Encoding","97f89037":"# SCIKIT-LEARN ","169290d2":"# STATSMODELS","6ba24df1":"## Loading the dataset","a57f4af0":"## Modeling","bdfff52e":"## Split the data","a35fafa6":" ##  Spliting the data","6955ddd3":"## Exploring data"}}