{"cell_type":{"5ecdc14b":"code","f24448d3":"code","f74e780a":"code","24b90b78":"code","0854e87e":"code","b025e143":"code","e85e7790":"code","461d417f":"code","60b4816d":"code","97da64c5":"code","33b9263e":"code","65e8181e":"code","d823d49c":"code","0e2938ef":"code","e350c797":"code","ad43b7ea":"code","3e8ba310":"markdown","58fbaa3f":"markdown","ac5870a0":"markdown","75dca68b":"markdown","4eea8d46":"markdown","f5dcee49":"markdown","c2ae6656":"markdown","49021aaa":"markdown","c489c9de":"markdown","1c99d574":"markdown","ca5138eb":"markdown","faf5244d":"markdown","3ea8adfb":"markdown","66bfe8a6":"markdown"},"source":{"5ecdc14b":"PATH_DATASET = \"\/kaggle\/input\/mnist-in-csv\/\"\nTRAINING_DATASET = \"mnist_train.csv\"\nTESTING_DATASET = \"mnist_test.csv\"","f24448d3":"import pandas as pd\nimport os\n\ndef load_dataset(filename, path_dataset=PATH_DATASET):\n    print(\"LOADED: \" + filename)\n    return pd.read_csv(os.path.join(path_dataset, filename))\n    \ntrain = load_dataset(TRAINING_DATASET)\ntest = load_dataset(TESTING_DATASET)","f74e780a":"train.info()","24b90b78":"test.info()","0854e87e":"train.head()","b025e143":"test.head()","e85e7790":"x_train, y_train, x_test, y_test = train.drop(['label'], axis=1), train.label, test.drop(['label'], axis=1), test.label","461d417f":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=3)\nknn_clf.fit(x_train, y_train)","60b4816d":"# from sklearn.model_selection import GridSearchCV\n# from sklearn.neighbors import KNeighborsClassifier\n\n# param_grid = [{\"weights\": [\"uniform\", \"distance\"], \"n_neighbors\": [3, 4, 5]}]\n\n# knn_clf = KNeighborsClassifier()\n# grid_search = GridSearchCV(knn_clf, param_grid, cv=2, verbose=3)\n# grid_search.fit(x_train, y_train)","97da64c5":"y_test_pred = knn_clf.predict(x_test)","33b9263e":"y_test_pred","65e8181e":"y_test","d823d49c":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_test_pred)","0e2938ef":"from sklearn.metrics import precision_score\n\nprecision_score(y_test, y_test_pred, average=\"micro\")","e350c797":"from sklearn.metrics import recall_score\n\nrecall_score(y_test, y_test_pred, average=\"micro\")","ad43b7ea":"from sklearn.metrics import f1_score\n\nf1_score(y_test, y_test_pred, average=\"micro\")","3e8ba310":"# MAKING PREDICTIONS","58fbaa3f":"### RECALL\nrecall = (tp) \/ (tp + fn)","ac5870a0":"# IMPORT DATA","75dca68b":"# MODEL TRAINING","4eea8d46":"> As you can see, both the training set and testing are loaded as panda DataFrame with the first columns as the labels (y) of each row. In total there are 785 columns including the labels column. Therefore, in order to create a training set, and testing set, we need to drop the labels for both train.csv and test.csv.","f5dcee49":"# GLOBAL VARIABLES","c2ae6656":"### F1 SCORE\nf1 = 2 * (precision * recall) \/ (precision + recall)","49021aaa":"### SIMPLE ACCURACY\nsimple accuracy = (tp + tn) \/ (tp + tn + fp + fn)","c489c9de":"# ACCURACY TESTING","1c99d574":"> One method that can be used to classify multiclass dataset is the K Nearest Neighbors algorithm.","ca5138eb":"> The parameters used to construct the KNeighborsClassifiers might not be the combinations that yeilds the highest accuracy. To that end, we still need to find the best parameters that will yield highest accuracy. Hence, one possible way is to use Grid Search.","faf5244d":"# EXPLORING DATA","3ea8adfb":"### PRECISION\nprecision = (tp) \/ (tp + fp)","66bfe8a6":"> In classification problems, accuracy testing algorithms includes the follow:\n- simple accuracy\n- precision\n- recall\n- f1-score\n- roc (auc)"}}