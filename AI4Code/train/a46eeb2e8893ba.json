{"cell_type":{"bf492f29":"code","216a1240":"code","7c2ba8c0":"code","86ec02d3":"code","56cc8397":"code","beeabbdc":"code","90cffed4":"code","ceb103e4":"code","a41c4625":"code","ae0a1565":"code","6f6cc9d5":"code","4e57b614":"code","0a05fc79":"code","da457b43":"code","db823332":"code","8517ea39":"code","90de0d48":"code","2dc9c4da":"code","6d61e505":"code","5206bca7":"code","385a0f28":"markdown"},"source":{"bf492f29":"import sys\nsys.path.append('..\/input\/timm-3monthsold\/pytorch-image-models-master 2')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.notebook import tqdm\nimport os, gc\nimport random\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport zipfile\nimport collections\nfrom PIL import Image\nfrom sklearn import preprocessing\nfrom random import randint\nfrom glob import glob\nimport shutil\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torchvision\nfrom torchvision import transforms\nimport albumentations as A\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed = 2020\nseed_everything(seed)\nsz1 = 224\nsz2 = 384\nNFOLDS = 5\npet_num = 4\n\n#ImageNet\nmean = np.array([[[0.485, 0.456, 0.406]]])\nstd = np.array([[[0.229, 0.224, 0.225]]])","216a1240":"test_df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv')\n#test_df = pd.concat([pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv')]*900, ignore_index=True)\ntest_df['class'] = -1\ntest_df['conf'] = -1\ntest_ids = test_df.Id.to_list()\n#test_ids = ['0013fd999caf9a3efe1352ca1b0d937e', '0009c66b9439883ba2750fb825e1d7db', '0007de18844b0dbbb5e1f607da0606e0']\ntest_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\"\n#test_dir = '\/kaggle\/input\/petfinder2-sample-images\/'\nshutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')","7c2ba8c0":"tmp = pd.DataFrame(columns=test_df.columns)\ntmp","86ec02d3":"!python detect.py\\\n--weights \/kaggle\/input\/ultralyticsyolov5aweights\/yolov5x.pt\\\n--class 15 16\\\n--img 512\\\n--conf 0.3\\\n--iou 0.5\\\n--source $test_dir\\\n--name inference\\\n--save-txt --save-conf --exist-ok","56cc8397":"os.chdir('\/kaggle\/working')\nsave_dir = f'\/kaggle\/working\/crop_images\/'\nos.makedirs(save_dir, exist_ok=True)","beeabbdc":"for n, image_id in tqdm(enumerate(test_ids)):\n    orig_image = cv2.imread(f'\/kaggle\/input\/petfinder-pawpularity-score\/test\/{image_id}.jpg')\n    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    height = orig_image.shape[0]\n    width = orig_image.shape[1]\n    try:\n        file_path = f'\/kaggle\/working\/yolov5\/runs\/detect\/inference\/labels\/{image_id}.txt'\n        f = open(file_path, 'r')\n        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n        data = data[:, [0, 5, 1, 2, 3, 4]]\n        data = data[np.argsort(data[:, 1])[::-1]]  #sort by conf\n        for i, d in enumerate(data):\n            xmin = int((d[2]-d[4]\/2)*width)\n            ymin = int((d[3]-d[5]\/2)*height)\n            xmax = int((d[2]+d[4]\/2)*width)\n            ymax = int((d[3]+d[5]\/2)*height)\n            width_half = (xmax - xmin) \/\/ 2\n            height_half = (ymax - ymin) \/\/ 2\n            r = np.maximum(width_half, height_half)\n            xc = (xmin + xmax) \/\/ 2\n            yc = (ymin + ymax) \/\/ 2\n            final_xmin = np.maximum(xc-r, 0)\n            final_ymin = np.maximum(yc-r, 0)\n            final_xmax = np.minimum(xc+r, width)\n            final_ymax = np.minimum(yc+r, height)\n            crop_img = orig_image[final_ymin:final_ymax, final_xmin:final_xmax, :]\n            np.save(save_dir + f'{image_id}-{i}', crop_img.astype(np.uint8))\n            df = pd.DataFrame(columns=test_df.columns)\n            df.loc[0, 'Id'] = f'{image_id}-{i}'\n            df.loc[0, 'class'] = d[0]\n            df.loc[0, 'conf'] = d[1]\n            tmp = tmp.append(df, ignore_index=True)\n            \n    except:\n        np.save(save_dir + f'{image_id}-0', orig_image.astype(np.uint8))\n        df = pd.DataFrame(columns=test_df.columns)\n        df.loc[0, 'Id'] = f'{image_id}-0'\n        df.loc[0, 'class'] = 'NA'\n        df.loc[0, 'conf'] = 'NA'\n        tmp = tmp.append(df, ignore_index=True)","90cffed4":"tmp = tmp.rename(columns={'Id': 'Id2'})\ntmp['img_idx'] = tmp['Id2'].apply(lambda x: x.split('-')[1])\ntmp['Id'] = tmp['Id2'].apply(lambda x: x.split('-')[0])\ntmp","ceb103e4":"class Dataset(Dataset):\n    def __init__(self, df, size, transform=None):\n        self.df = df\n        self.size = size\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_id = self.df.loc[idx, 'Id2']\n        img = np.load(f'\/kaggle\/working\/crop_images\/{image_id}.npy')\n        img = cv2.resize(img, (self.size, self.size)).astype(np.float32)\n        \n        if self.transform:\n            sample = self.transform(image=img)\n            img = sample['image']\n        \n        img = (img\/255.0 - mean) \/ std\n        img = np.transpose(img, (2, 0, 1))\n        img = torch.from_numpy(img)\n\n        return img\n    \n    \nclass Dataset2(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_id = self.df.loc[idx, 'Id']\n        img = np.load(f'\/kaggle\/working\/crop_images\/{image_id}.npy').astype(np.float32)\n        \n        if self.transform:\n            sample = self.transform(image=img)\n            img = sample['image']\n        \n        img = (img\/255.0 - mean) \/ std\n        img = np.transpose(img, (2, 0, 1))\n        img = torch.from_numpy(img)\n\n        return img\n    \n\ndef inference_fn1(data_loader, model, device):\n    model.eval()    \n    val_preds = []\n    \n    for i, x in enumerate(data_loader):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred = model(img)\n            val_preds.append(nn.Softmax()(pred).detach().cpu().numpy())\n            \n    val_preds = np.concatenate(val_preds)\n                \n    return val_preds\n\n\ndef inference_fn2(data_loader, model, device):\n    model.eval()    \n    val_preds = []\n    \n    for i, x in enumerate(data_loader):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred = model(img)\n            val_preds.append(nn.Sigmoid()(pred).detach().cpu().numpy() * 100)\n            \n    val_preds = np.concatenate(val_preds)\n                \n    return val_preds\n\n\nclass Model(nn.Module):\n    def __init__(self, model_name=None, pretrained=False, num_classes=100):\n        super().__init__()\n        self.model = timm.create_model(\n            model_name=model_name, \n            in_chans=3, \n            pretrained=pretrained\n            )\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","a41c4625":"#224x224\n#5folds\n#cropped imgs\ntest_ds = Dataset(df=tmp, size=sz1, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=256, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions1 = 0\npredictions2 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint1-weight-016\/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction1 = inference_fn1(test_dl, model1, device)\n    predictions1 += (target_cols.reshape(-1, 100) * prediction1.reshape(-1, 100)).sum(axis=1) \/ NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint2-weight-011\/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction2 = inference_fn2(test_dl, model2, device).flatten()\n    predictions2 += prediction2 \/ NFOLDS\n    \n    del model1, model2, prediction1, prediction2\n    gc.collect()\n    \ntmp['pred1'] = predictions1\ntmp['pred2'] = predictions2\n\ndel test_ds, test_dl, predictions1, predictions2\ngc.collect()","ae0a1565":"#384x384\n#5folds\n#cropped imgs\ntest_ds = Dataset(df=tmp, size=sz2, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions3 = 0\npredictions4 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint1-weight-068\/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction3 = inference_fn1(test_dl, model1, device)\n    predictions3 += (target_cols.reshape(-1, 100) * prediction3.reshape(-1, 100)).sum(axis=1) \/ NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint2-weight-028\/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction4 = inference_fn2(test_dl, model2, device).flatten()\n    predictions4 += prediction4 \/ NFOLDS\n    \n    del model1, model2, prediction3, prediction4\n    gc.collect()\n    \ntmp['pred3'] = predictions3\ntmp['pred4'] = predictions4\n\ndel test_ds, test_dl, predictions3, predictions4\ngc.collect()","6f6cc9d5":"tmp","4e57b614":"#postprocessing by multi-pets\ntest_df = tmp.groupby('Id').head(pet_num).groupby('Id').mean().reset_index()\ntest_df","0a05fc79":"sub = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\ncoorabi = pd.concat(\n    [sub, \n     test_df[['pred1']], \n     test_df[['pred2']], \n     test_df[['pred3']], \n     test_df[['pred4']]\n    ], axis=1\n)\ncoorabi","da457b43":"!rm -r \/kaggle\/working\/yolov5\n!rm -r \/kaggle\/working\/crop_images","db823332":"#fastai\n#224x224\n#5folds\n#original imgs\nimport fastai\nfrom fastai.vision.all import *\nfrom fastai.callback.all import *\nimport torchvision.models as torch_models\n\ndef petfinder_rmse(input, target):\n    return 100 * torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ntest_df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv')\ntest_df['Path'] = '..\/input\/petfinder-pawpularity-score\/test\/' + test_df['Id'] + '.jpg'\npredictions5 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    learn = load_learner(fname = Path(f'\/kaggle\/input\/petfinder2-swint3-weight-001\/swint3_fold_{fold}.pkl'), cpu=False)\n    test_dl = learn.dls.test_dl(test_df)\n    preds, _ = learn.get_preds(dl=test_dl)\n    predictions5 += preds * 100 \/ NFOLDS\n    del learn, test_dl, preds\n    gc.collect()\n    \ncoorabi['pred5'] = predictions5\n\ndel predictions5\ngc.collect()","8517ea39":"#224x224\n#5folds\n#center crop\ntest_df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv')\ntest_ids = test_df.Id.to_list()\nos.chdir('\/kaggle\/working')\nsave_dir = f'\/kaggle\/working\/crop_images\/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor n, image_id in tqdm(enumerate(test_ids)):\n    orig_image = cv2.imread(f'\/kaggle\/input\/petfinder-pawpularity-score\/test\/{image_id}.jpg')\n    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    height = orig_image.shape[0]\n    width = orig_image.shape[1]\n    xc = width \/\/ 2\n    yc = height \/\/ 2\n    r = np.minimum(xc, yc)\n    xmin = np.maximum(xc-r, 0)\n    ymin = np.maximum(yc-r, 0)\n    xmax = np.minimum(xc+r, width)\n    ymax = np.minimum(yc+r, height)\n    crop_img = orig_image[ymin:ymax, xmin:xmax, :]\n    crop_img = cv2.resize(crop_img, (sz1, sz1)).astype(np.uint8)\n    np.save(save_dir + f'{image_id}', crop_img)\n\ntest_ds = Dataset2(df=coorabi, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=256, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions6 = 0\npredictions7 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint1-weight-076\/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction6 = inference_fn1(test_dl, model1, device)\n    predictions6 += (target_cols.reshape(-1, 100) * prediction6.reshape(-1, 100)).sum(axis=1) \/ NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint2-weight-036\/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction7 = inference_fn2(test_dl, model2, device).flatten()\n    predictions7 += prediction7 \/ NFOLDS\n    \n    del model1, model2, prediction6, prediction7\n    gc.collect()\n    \ncoorabi['pred6'] = predictions6\ncoorabi['pred7'] = predictions7\n\n!rm -r \/kaggle\/working\/crop_images\ndel test_ds, test_dl, predictions6, predictions7\ngc.collect()","90de0d48":"#384x384\n#5folds\n#center crop\ntest_df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv')\ntest_ids = test_df.Id.to_list()\nos.chdir('\/kaggle\/working')\nsave_dir = f'\/kaggle\/working\/crop_images\/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor n, image_id in tqdm(enumerate(test_ids)):\n    orig_image = cv2.imread(f'\/kaggle\/input\/petfinder-pawpularity-score\/test\/{image_id}.jpg')\n    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    height = orig_image.shape[0]\n    width = orig_image.shape[1]\n    xc = width \/\/ 2\n    yc = height \/\/ 2\n    r = np.minimum(xc, yc)\n    xmin = np.maximum(xc-r, 0)\n    ymin = np.maximum(yc-r, 0)\n    xmax = np.minimum(xc+r, width)\n    ymax = np.minimum(yc+r, height)\n    crop_img = orig_image[ymin:ymax, xmin:xmax, :]\n    crop_img = cv2.resize(crop_img, (sz2, sz2)).astype(np.uint8)\n    np.save(save_dir + f'{image_id}', crop_img)\n\ntest_ds = Dataset2(df=coorabi, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions8 = 0\npredictions9 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint1-weight-077\/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction8 = inference_fn1(test_dl, model1, device)\n    predictions8 += (target_cols.reshape(-1, 100) * prediction8.reshape(-1, 100)).sum(axis=1) \/ NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'\/kaggle\/input\/petfinder2-swint2-weight-037\/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction9 = inference_fn2(test_dl, model2, device).flatten()\n    predictions9 += prediction9 \/ NFOLDS\n    \n    del model1, model2, prediction8, prediction9\n    gc.collect()\n    \ncoorabi['pred8'] = predictions8\ncoorabi['pred9'] = predictions9\n\n!rm -r \/kaggle\/working\/crop_images\ndel test_ds, test_dl, predictions8, predictions9\ngc.collect()","2dc9c4da":"coorabi['Pawpularity'] = ((coorabi['pred1'] * 0.275 + coorabi['pred2'] * 0.225 + coorabi['pred3'] * 0.275 + coorabi['pred4'] * 0.225) * 0.75 + coorabi['pred5'] * 0.25) * 0.6 + (coorabi['pred6'] * 0.22 + coorabi['pred7'] * 0.18 + coorabi['pred8'] * 0.33 + coorabi['pred9'] * 0.27) * 0.4","6d61e505":"coorabi","5206bca7":"coorabi[['Id', 'Pawpularity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","385a0f28":"# \u30af\u30fc\u30e9\u30d3 part"}}