{"cell_type":{"b6e2e663":"code","e28558dc":"code","c875159b":"code","4953b163":"code","51fe4135":"code","b8dce06b":"code","8840844f":"code","75e22d7c":"code","287141b2":"code","6798c00f":"code","b3b282fa":"code","0789417c":"code","7c939406":"code","9f8615ff":"code","35fd37a8":"code","fa5c3f1c":"code","954ed292":"code","4c1c198f":"code","8a66ddd3":"code","8eb2a0fc":"code","71f49a05":"code","de23af39":"code","b69c8ec3":"code","e495fb16":"code","e7bd6125":"code","e8335cf3":"code","64242aca":"code","b1b46c80":"code","aaff291c":"code","9743de23":"code","0a56d36b":"code","d835ee34":"code","0a04a176":"code","3a5707eb":"code","1e7ec680":"markdown","dba1a8c6":"markdown","000f0728":"markdown","d37caddc":"markdown","551b903b":"markdown","933e2fb7":"markdown","b3746fae":"markdown","755a3b02":"markdown","f0cb87c6":"markdown","1aa6da3b":"markdown","9d787b00":"markdown","ae2892d7":"markdown","28face38":"markdown","87197833":"markdown","cd2ed078":"markdown","8399ece9":"markdown","9d32c82b":"markdown"},"source":{"b6e2e663":"! mkdir trainJPEG testJPEG","e28558dc":"! mkdir trainJPEG\/trainimg trainJPEG\/trainmask testJPEG\/testimg testJPEG\/testmask","c875159b":"! pwd","4953b163":"import os, sys\nfrom PIL import Image","51fe4135":"for infile in os.listdir(\"\/kaggle\/input\/ultrasound-nerve-segmentation\/train\/\"):\n    #print(\"file : \" + infile)\n    \n    if infile[-3:] == \"tif\":\n        \n        if infile[-8:-4] == \"mask\":\n            file = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/train\/\" + infile\n            outfile = \"\/kaggle\/working\/trainJPEG\/trainmask\/\"+ infile[:-9] + \".jpeg\"\n            im = Image.open(file)\n            out = im.convert(\"RGB\")\n            out.save(outfile, \"JPEG\", quality=100)\n        else:\n            fileImg = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/train\/\" + infile\n            outfileImg = \"\/kaggle\/working\/trainJPEG\/trainimg\/\"+ infile[:-3] + \"jpeg\"\n            imImg = Image.open(fileImg)\n            outImg = imImg.convert(\"RGB\")\n            outImg.save(outfileImg, \"JPEG\", quality=100)","b8dce06b":"for infile in os.listdir(\"\/kaggle\/input\/ultrasound-nerve-segmentation\/test\/\"):\n    #print(\"file : \" + infile)\n    \n    if infile[-3:] == \"tif\":\n        \n        if infile[-8:-4] == \"mask\":\n            file = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/test\/\" + infile\n            outfile = \"\/kaggle\/working\/testJPEG\/testmask\/\"+ infile[:-9] + \".jpeg\"\n            im = Image.open(file)\n            out = im.convert(\"RGB\")\n            out.save(outfile, \"JPEG\", quality=100)\n        else:\n            fileImg = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/test\/\" + infile\n            outfileImg = \"\/kaggle\/working\/testJPEG\/testimg\/\"+ infile[:-3] + \"jpeg\"\n            imImg = Image.open(fileImg)\n            outImg = imImg.convert(\"RGB\")\n            outImg.save(outfileImg, \"JPEG\", quality=100)  ","8840844f":"import cv2\nimport matplotlib.pyplot as plt\nf, axarr = plt.subplots(2,4)\n\nimg1 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainimg\/10_103.jpeg')\nimg2 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainmask\/10_103.jpeg')\nimg3 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainimg\/10_104.jpeg')\nimg4 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainmask\/10_104.jpeg')\n\nimg5 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainimg\/10_109.jpeg')\nimg6 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainmask\/10_109.jpeg')\nimg7 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainimg\/10_112.jpeg')\nimg8 = cv2.imread('\/kaggle\/working\/trainJPEG\/trainmask\/10_112.jpeg')\n\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)\n\naxarr[0,2].imshow(img5)\naxarr[0,3].imshow(img6)\naxarr[1,2].imshow(img7)\naxarr[1,3].imshow(img8)","75e22d7c":"! git clone https:\/\/github.com\/Tessellate-Imaging\/Monk_Object_Detection.git","287141b2":"! cd Monk_Object_Detection\/9_segmentation_models\/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install","6798c00f":"DATA_DIR = '\/kaggle\/working\/'","b3b282fa":"import os\nimport sys\nsys.path.append(\"Monk_Object_Detection\/9_segmentation_models\/lib\/\");","0789417c":"from train_segmentation import Segmenter","7c939406":"gtf = Segmenter();","9f8615ff":"img_dir = \"\/kaggle\/working\/trainJPEG\/trainimg\/\";\nmask_dir = \"\/kaggle\/working\/trainJPEG\/trainmask\/\";","35fd37a8":"classes_dict = {\n    'background': 0, \n    'nerves': 1,\n};\nclasses_to_train = ['background', 'nerves'];","fa5c3f1c":"gtf.Train_Dataset(img_dir, mask_dir, classes_dict, classes_to_train)","954ed292":"img_dir = \"\/kaggle\/working\/testJPEG\/testimg\/\";\nmask_dir = \"\/kaggle\/working\/testJPEG\/testmask\/\";","4c1c198f":"gtf.Val_Dataset(img_dir, mask_dir)","8a66ddd3":"gtf.List_Backbones();","8eb2a0fc":"gtf.Data_Params(batch_size=2, backbone=\"efficientnetb3\", image_shape=[580, 420])","71f49a05":"gtf.List_Models();","de23af39":"gtf.Model_Params(model=\"Linknet\")","b69c8ec3":"gtf.Train_Params(lr=0.001)","e495fb16":"gtf.Setup();","e7bd6125":"gtf.Train(num_epochs=5);","e8335cf3":"gtf.Visualize_Training_History();","64242aca":"from infer_segmentation import Infer","b1b46c80":"gtf = Infer();","aaff291c":"classes_dict = {\n    'background': 0, \n    'nerves': 1,\n};\nclasses_to_train = ['nerves'];","9743de23":"gtf.Data_Params(classes_dict, classes_to_train, image_shape=[580, 420])","0a56d36b":"gtf.Model_Params(model=\"Linknet\", backbone=\"efficientnetb3\", path_to_model='best_model.h5')","d835ee34":"gtf.Setup();","0a04a176":"gtf.Predict(\"\/kaggle\/working\/trainJPEG\/trainimg\/10_103.jpeg\", vis=True);","3a5707eb":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread(\"\/kaggle\/working\/trainJPEG\/trainmask\/10_103.jpeg\", 0)\ncv2.imwrite(\"tmp.jpg\", img)\n\nfrom IPython.display import Image\nImage(filename=\"tmp.jpg\")","1e7ec680":"# Converting the dataset into MONK format","dba1a8c6":"Convert .tif image into .jpeg or .png format and also structure the dataset as required","000f0728":"# Load Dataset","d37caddc":"# To contribute to Monk AI or Monk Object Detection repository raise an issue in the git-repo or DM us on linkedin\n\n* Abhishek - https:\/\/www.linkedin.com\/in\/abhishek-kumar-annamraju\/\n* Akash - https:\/\/www.linkedin.com\/in\/akashdeepsingh01\/","551b903b":"# Installation","933e2fb7":"# Train Params","b3746fae":"# Train","755a3b02":"# [Monk Object Detection](https:\/\/github.com\/Tessellate-Imaging\/Monk_Object_Detection)","f0cb87c6":"# Monk Format\n\n# Dataset Directory Structure\n  \n  \n  root_dir\n  \n      |\n      | \n      |         \n      |----train_img_dir\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on) \n      |\n      |----train_mask_dir\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on)\n      |\n      |----val_img_dir (optional)\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on)\n      |\n      |----val_mask_dir (optional)\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on)","1aa6da3b":"# Load Model","9d787b00":"# Setup","ae2892d7":"# [Tessellate Imaging](https:\/\/www.tessellateimaging.com\/)\n\n# Check out \n\n# [Monk AI](https:\/\/github.com\/Tessellate-Imaging\/monk_v1)\n\n*Monk is a low code Deep Learning tool and a unified wrapper for Computer Vision.*\n\n**Monk features**\n\n    - low-code\n    - unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n    - syntax invariant wrapper\n\n**Enables developers**\n\n    - to create, manage and version control deep learning experiments\n    - to compare experiments across training metrics\n    - to quickly find best hyper-parameters\n    \n\n# [Monk GUI](https:\/\/github.com\/Tessellate-Imaging\/Monk_Gui)\n\n*A Graphical user Interface for deep learning and computer vision over Monk Libraries*\n\n# [Pytorch Tutorial](https:\/\/github.com\/Tessellate-Imaging\/Pytorch_Tutorial)\n\n*A set of jupyter notebooks on pytorch functions with examples*","28face38":"Run these commands\n\n* git clone https:\/\/github.com\/Tessellate-Imaging\/Monk_Object_Detection.git\n\n* cd Monk_Object_Detection\/9_segmentation_models\/installation\n\nSelect the right requirements file and run\n\ncat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install","87197833":"# Training your own segmenter","cd2ed078":"# Inference","8399ece9":"* For colab use the command below\n\n! cd Monk_Object_Detection\/9_segmentation_models\/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n\n\n* For Local systems and cloud select the right CUDA version\n\n! cd Monk_Object_Detection\/9_segmentation_models\/installation && cat requirements_cuda10.0.txt | xargs -n 1 -L 1 pip install","9d32c82b":"*A one-stop repository for low-code easily-installable object detection pipelines.*"}}