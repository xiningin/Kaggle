{"cell_type":{"d356e811":"code","f456d438":"code","a869a0f0":"code","dfe0bc4b":"code","e5ba1743":"code","3e258dca":"code","380c8639":"code","61a021c3":"code","d5744643":"code","cd90a250":"code","7fb39164":"code","5b138fde":"code","955bad01":"code","40e4dbd3":"code","7ad5e554":"code","cd5d7006":"code","4daac85d":"code","5e4f7206":"code","8a2a51f7":"code","df0293fc":"code","adadf216":"code","229fc871":"code","8bb7c087":"code","72f34875":"code","bf411612":"code","aa354c95":"code","55612109":"code","422da6e0":"code","6f47cfdb":"code","52cbbaf9":"code","24624237":"code","05f3b3ba":"code","e65f354e":"code","7b3fc514":"code","973935a3":"code","7a985d0f":"code","abf04bd0":"code","3bf9c0b7":"code","0dea06cf":"code","1c035a06":"code","662b52c2":"code","e510d886":"code","9f959794":"code","40bf9852":"code","d74ae6ab":"code","d94d18d7":"code","772357bc":"code","85575f45":"code","9ffaf3de":"code","ba328404":"code","816cc386":"code","77d8c482":"code","4b38f7d9":"code","f4150492":"code","3e653551":"code","a0d99d0a":"code","e0b0e6b8":"code","2bbbf4a9":"code","bb5dcc1a":"markdown","54896d5c":"markdown","65e46381":"markdown","d9aac515":"markdown","d73000b6":"markdown","6edc95a3":"markdown","f5438a64":"markdown","fa0cc4b0":"markdown","6b87e3b0":"markdown","aaa6c3d9":"markdown","0a05ac50":"markdown","49127dda":"markdown","7c3b898c":"markdown","ab5c33a6":"markdown","12d06003":"markdown","3aee9be9":"markdown","86d7b3e6":"markdown","56d229a9":"markdown","64f841e6":"markdown","a7da5da5":"markdown","65d30bf8":"markdown","efdad092":"markdown","aece8445":"markdown","66085677":"markdown","6051b7b1":"markdown","45c9decf":"markdown","b8fb1102":"markdown"},"source":{"d356e811":"from IPython.display import Markdown as md\nfrom IPython.display import HTML\n\nTITLE = 'feature engineering'\nEMOTICON = ' \ud83e\uddf0'\n\nPART_NO = 1\nTOTAL_PARTS_NO = 10\n\nORD_LIST = ['0th', '1st', '2nd', '3rd', '4th'\n            '5th', '6th', '7th', '8th', '9th', '10th']\n\nNOTEBOOK_NAME = f\"TPSJan22 {PART_NO}\/{TOTAL_PARTS_NO}: {TITLE+EMOTICON}\"\nNOTEBOOK_URL = f\"https:\/\/www.kaggle.com\/fergusfindley\/tpsjan22-{PART_NO}-{TOTAL_PARTS_NO}-{TITLE.replace(' ', '-')}\"\n\nHTML(f'''<div class=\"alert alert-block alert-info\">\nIf you find <a href={NOTEBOOK_URL}>this notebook<\/a> useful or you just like it, please upvote \u25b2.<br>\nIf you are using any part of this notebook, please link to <a href={NOTEBOOK_URL}>{NOTEBOOK_NAME}<\/a> notebook.<br>\nIn case of any question\/feedback don't hesitate to <a href={NOTEBOOK_URL}\/comments>comment<\/a> below.\n<\/div>''')","f456d438":"HTML(f'''<h1><center>{NOTEBOOK_NAME}<\/center><\/h1>\n<h2><center><b>TL;DR<\/b> Very first step on a road to victory.<\/center><\/h2>\n<center>\n<h3><span style=\"color:#20BEFF;\">This is the {ORD_LIST[PART_NO]} part of <a href=\"https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\/discussion\/301276\">TPSJan22 series<\/a><\/span><\/h3><\/center>''')","a869a0f0":"import numpy as np\nimport pandas as pd\n\npd.set_option('display.max_rows', 500)\n\nfrom kaggle_colors_util import *\n\nimport gc","dfe0bc4b":"RANDOM_STATE = 42\n\nDIRECTORY_PATH = \"..\/input\/tabular-playground-series-jan-2022\"\nTRAIN_CSV = DIRECTORY_PATH + \"\/train.csv\"\nTEST_CSV = DIRECTORY_PATH + \"\/test.csv\"\nSUBMISSION_CSV = DIRECTORY_PATH + \"\/sample_submission.csv\"\n\nID = 'row_id'\nTARGET = 'num_sold'\nDATE = 'date'\n\ncountries = ['Finland', 'Norway', 'Sweden']\ncountries_iso = ['FIN', 'NOR', 'SWE']\ncurrencies = ['EUR', 'NOK', 'SEK']\nstores = ['KaggleMart', 'KaggleRama']\nproducts = ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']","e5ba1743":"# time series data common new feature  \nYEAR = \"year\"\nQUARTER = \"quarter\"\nMONTH = \"month\"\nWEEK = \"week\"\nDAY = \"day\"\n\nDAYOFYEAR = \"dayofyear\"\nDAYOFMONTH = \"dayofmonth\"\nDAYOFWEEK = \"dayofweek\"\nDAY_NAME = \"day_name\"\nMONTH_NAME = \"month_name\"","3e258dca":"train_df = pd.read_csv(TRAIN_CSV, parse_dates=[DATE], index_col=[ID])\ntest_df = pd.read_csv(TEST_CSV, parse_dates=[DATE], index_col=[ID])\nsubmission_df = pd.read_csv(SUBMISSION_CSV)\n\ntest_ids = test_df.index\n\ndfs_dict = {\"train\":train_df, \"test\":test_df}","380c8639":"df = train_df.copy()\ndf[DATE] = df[DATE].dt.to_period('D')\ndf = df.set_index([DATE, 'country', 'store', 'product'])","61a021c3":"Y = df.unstack(['country', 'store', 'product'])","d5744643":"X = pd.concat([train_df.drop(columns=[TARGET]), test_df])  # easier feature generation for both test&train DataFrames at the same time\ntest_min_date = test_df[DATE].min()\nval_min_date = pd.to_datetime('2018-01-01')  # whole 2018 as a validation set\ntrain_max_date = pd.to_datetime('2017-12-31')","cd90a250":"def get_basic_ts_features(df):\n    df[YEAR] = df[DATE].dt.year\n    df[QUARTER] = 'Q' + df[DATE].dt.quarter.astype(str)\n    df[MONTH] = df[DATE].dt.month\n    df[MONTH_NAME] = df[DATE].dt.month_name()\n    df[WEEK]= df[DATE].dt.isocalendar().week.astype(int)\n    \n    df[DAY] = df[DATE].dt.day\n    df[DAY_NAME] = df[DATE].dt.day_name()  \n    df[DAYOFWEEK] = df[DATE].dt.dayofweek\n    df['is_weekend'] = (df[DAYOFWEEK]>=5).astype(int)\n    \n    df[DAYOFMONTH] = df[DATE].dt.days_in_month\n\n    df[DAYOFYEAR] = df[DATE].dt.dayofyear\n    df.loc[(df[DATE].dt.is_leap_year) & (df[DAYOFYEAR] >= 60), DAYOFYEAR] -= 1\n    \n    return df  ","7fb39164":"X = get_basic_ts_features(X)","5b138fde":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nmin_date = min(X[DATE])\nmax_date = max(X[DATE])\ndate_range = pd.date_range(min_date, max_date)\nfourier = CalendarFourier(freq=\"A\", order=14)  # 14 sin\/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=date_range,            # as date_range is with daily frequency weekdays will be on-hot encoded \n    constant=True,               # dummy feature for bias (y-intercept)\n    order=3,                     # trend (order 3 means cubed)\n    seasonal=True,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\ntime_df = dp.in_sample().reset_index().rename(columns={'index':DATE})  # create features for dates in date_range\n\n# renaming one-hot encoded weekdays for better interpretability \n# (order is determined by the first day in the dataset - 2015-01-01 is Thursday)\n\ndays_dict = dict(zip(list(time_df.filter(regex='s\\(\\d,\\d\\)').columns), ['Fri','Sat','Sun','Mon','Tue','Wed']))\ntime_df = time_df.rename(columns=days_dict)\n\ntime_df.loc[:, 'const':'Wed'] = time_df.loc[:, 'const':'Wed'].astype(int)  # memory optimization","955bad01":"X = X.merge(time_df, on=[DATE])","40e4dbd3":"from holidays import CountryHoliday","7ad5e554":"def get_country_holidays(country, years_list):\n    festivities = CountryHoliday(country, years=years_list)\n    festivities_df = pd.DataFrame.from_dict(festivities, orient='index').reset_index().rename(columns={'index':DATE, 0:'festivity_name'})\n    festivities_df[DATE] = pd.to_datetime(festivities_df[DATE])\n    if country == 'Sweden':\n        festivities_df = festivities_df[festivities_df['festivity_name']!='S\u00f6ndag']  # for Sweden all Sundays are set as holidays... :\/\n    \n    additional_dates = [[pd.to_datetime(f'{year}-12-24'), 'Christmas Eve'] for year in years_list]\n    additional_dates += [[pd.to_datetime(f'{year}-12-31'), 'Saint Sylvester'] for year in years_list]\n    additional_dates += [[pd.to_datetime(f'{year}-01-01'), 'New Year'] for year in years_list]\n    additional_festivities_df = pd.DataFrame(additional_dates, columns=[DATE, 'festivity_name'])    \n        \n    festivities_df = festivities_df.append(additional_festivities_df, ignore_index=True)\n    return festivities_df.sort_values(DATE)","cd5d7006":"years_list = list(range(min_date.year, max_date.year+1))\n\nfor country_iso in countries_iso:\n    X[f'is_festivity_in_{country_iso}'] = X[DATE].isin(get_country_holidays(country_iso, years_list)[DATE]).astype(int)","4daac85d":"def days_till_next_holiday(country, date):\n    country_holidays_dates = get_country_holidays(country, [date.year, date.year+1])[DATE]\n    next_date = min([holidays_date for holidays_date in country_holidays_dates if holidays_date >= date])\n    return (next_date - date).days","5e4f7206":"%%time\n# TODO how to optimize below as it's over 3 mins run\nX['days_till_next_holiday'] = X.apply(lambda x: days_till_next_holiday(x['country'], x[DATE]), axis=1)","8a2a51f7":"from dateutil.easter import easter\nfrom dateutil.relativedelta import relativedelta","df0293fc":"# The model must know the date of Easter and account for higher demand in the week after Easter.\n\neaster_week_df = pd.DataFrame()\neaster_week_df[DATE] = date_range\neaster_week_df['easter_week'] = 0\n\nfor year in range(min_date.year, max_date.year+1):\n    easter_week_dates = pd.date_range(easter(year) - relativedelta(days=1), easter(year) + relativedelta(days=8))\n    easter_week_df.loc[easter_week_df[DATE].isin(easter_week_dates), 'easter_week'] = 1\n\neaster_timestamp = easter_week_df[DATE].apply(lambda date: pd.Timestamp(easter(date.year)))\neaster_week_df['days_from_easter'] = (easter_week_df[DATE] - easter_timestamp).dt.days.clip(-4, 7)\n\nwhitsunday_timestamp = easter_week_df[DATE].apply(lambda date: pd.Timestamp(easter(date.year) + relativedelta(days=49)))\neaster_week_df['days_from_whitsunday'] = (easter_week_df[DATE] - whitsunday_timestamp).dt.days.clip(-3, 8)","adadf216":"X = X.merge(easter_week_df, on=[DATE])","229fc871":"# There's a clearly higher demand after Christmas and till the end of the first week of January\n\nxmas_newyear_df = pd.DataFrame()\nxmas_newyear_df[DATE] = date_range\nxmas_newyear_df['xmas_newyear'] = 0\n\nxmas_newyear_peak_df = pd.DataFrame()\nxmas_newyear_peak_df[DATE] = date_range\nxmas_newyear_peak_df['xmas_newyear_peak'] = 0\n\nfor year in range(min_date.year-1, max_date.year+1):  # we need to take into consideration also 2014\n    xmas_eve = pd.to_datetime(f'{year}-12-24')\n    xmas_newyear_break = pd.date_range(xmas_eve, xmas_eve + relativedelta(days=14))\n    xmas_newyear_df.loc[xmas_newyear_df[DATE].isin(xmas_newyear_break), 'xmas_newyear'] = 1\n    \n    xmas_newyear_peak = pd.date_range(xmas_eve + relativedelta(days=4), xmas_eve + relativedelta(days=8))\n    xmas_newyear_peak_df.loc[xmas_newyear_peak_df[DATE].isin(xmas_newyear_peak), 'xmas_newyear_peak'] = 1","8bb7c087":"X = X.merge(xmas_newyear_df, on=[DATE])\nX = X.merge(xmas_newyear_peak_df, on=[DATE])","72f34875":"may_june_nov_df = pd.DataFrame()\nmay_june_nov_df[DATE] = date_range\n\n# Last Sunday of May\nsun_may_date = may_june_nov_df.date.dt.year.map({2015: pd.Timestamp(('2015-05-31')),\n                                                 2016: pd.Timestamp(('2016-05-29')),\n                                                 2017: pd.Timestamp(('2017-05-28')),\n                                                 2018: pd.Timestamp(('2018-05-27')),\n                                                 2019: pd.Timestamp(('2019-05-26'))})\nmay_june_nov_df['days_from_sun_may'] = (may_june_nov_df[DATE] - sun_may_date).dt.days.clip(-7, 3)\n\n# Last Wednesday of June\nwed_june_timestamp = may_june_nov_df[DATE].dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                                        2016: pd.Timestamp(('2016-06-29')),\n                                                        2017: pd.Timestamp(('2017-06-28')),\n                                                        2018: pd.Timestamp(('2018-06-27')),\n                                                        2019: pd.Timestamp(('2019-06-26'))})\nmay_june_nov_df['days_from_wed_jun'] = (may_june_nov_df[DATE] - wed_june_timestamp).dt.days.clip(-5, 5)\n\n# First Sunday of November (second Sunday is Father's Day)\nsun_nov_timestamp = may_june_nov_df[DATE].dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                                       2016: pd.Timestamp(('2016-11-6')),\n                                                       2017: pd.Timestamp(('2017-11-5')),\n                                                       2018: pd.Timestamp(('2018-11-4')),\n                                                       2019: pd.Timestamp(('2019-11-3'))})\nmay_june_nov_df['days_from_sun_nov'] = (may_june_nov_df[DATE] - sun_nov_timestamp).dt.days.clip(-1, 9)","bf411612":"X = X.merge(may_june_nov_df, on=[DATE])","aa354c95":"!pip -qqq install forex-python\n\nfrom forex_python.converter import get_rates\n# https:\/\/ratesapi.io is a free API for current and historical foreign exchange rates published by European Central Bank. The rates are updated daily 3PM CET.","55612109":"from tqdm import tqdm\n\nexchange_rate_df = pd.DataFrame()\nexchange_rate_df[DATE] = date_range\n\nfor day in tqdm(date_range):\n    try:\n        xr = get_rates(\"USD\", day)\n    except RatesNotAvailableError:\n        print(f\"{day} RatesNotAvailableError: Currency Rates Source Not Ready\")\n    for currency in currencies:\n        exchange_rate_df.loc[exchange_rate_df[DATE]==day, 'xr_'+currency] = xr[currency]","422da6e0":"X = X.merge(exchange_rate_df, on=[DATE])","6f47cfdb":"!pip -qqq install wbgapi\n\nimport wbgapi as wb  # pythonic access to the World Bank's data API ","52cbbaf9":"# with following command one can check variety of topics included in World Bank's data\n\nwb.topic.Series().to_frame().tail()","24624237":"# more detailed view for particular country and time frame\n\nwb.data.DataFrame(wb.topic.members(21), 'FIN', time=range(2015, 2018), labels=True, skipBlanks=True).head()  ","05f3b3ba":"# easy to use search feature\n\n# wb.search('Price Index')","e65f354e":"def get_topic_data(topic, column_name='values', start_year=2015, end_year=2019, return_log=False):\n    \n    if return_log:\n            return wb.data.DataFrame(topic, economy=countries_iso, time=range(start_year, end_year+1),\n                             labels=True, numericTimeKeys=True)\\\n                             .set_index('Country')\\\n                             .unstack().reset_index()\\\n                             .rename(columns={'level_0':'year', 'Country':'country', 0:column_name+'_log'})\\\n                             .set_index(['year', 'country']).apply(np.log1p)\n        \n    return wb.data.DataFrame(topic, economy=countries_iso, time=range(start_year, end_year+1),\n                             labels=True, numericTimeKeys=True)\\\n                             .set_index('Country')\\\n                             .unstack().reset_index()\\\n                             .rename(columns={'level_0':'year', 'Country':'country', 0:column_name})\\\n                             .set_index(['year', 'country'])","7b3fc514":"total_pop_df = get_topic_data('SP.POP.TOTL', 'wb_total_population', return_log=True)  # SP.POP.TOTL - Population, total\n\nlabor_force_df = get_topic_data('SL.TLF.TOTL.IN', 'wb_labor_force', return_log=True)  # SL.TLF.TOTL.IN - Labor force, total\n\nimports_from_hi_df = get_topic_data('TM.VAL.MRCH.HI.ZS', 'wb_imports_from_hi')  \n# TM.VAL.MRCH.HI.ZS - Merchandise imports from high-income economies (% of total merchandise imports)\n\ngdp_df = get_topic_data('NY.GDP.MKTP.KD', 'wb_gdp', return_log=True)  # NY.GDP.MKTP.KD - GDP (constant 2015 US$)\n\ngdp_per_capita_df = get_topic_data('NY.GDP.PCAP.KD', 'wb_gdp_per_capita')  # NY.GDP.PCAP.KD - GDP per capita (constant 2015 US$)\n\nprice_index_df = get_topic_data('FP.CPI.TOTL', 'wb_price_index')  # FP.CPI.TOTL - Consumer price index (2010 = 100)\n\ncomm_com_df = get_topic_data('BM.GSR.CMCP.ZS', 'wb_comm_com')  # BM.GSR.CMCP.ZS - Communications, computer, etc. (% of service imports, BoP)","973935a3":"wb_df = pd.concat([total_pop_df, labor_force_df, imports_from_hi_df, \n                   gdp_df, gdp_per_capita_df, price_index_df, comm_com_df], \n                  axis=1)","7a985d0f":"X = X.merge(wb_df.reset_index(), on=['year', 'country'])","abf04bd0":"geo_df = wb.economy.DataFrame(countries_iso)[['name', 'capitalCity', 'latitude', 'longitude']]  # will be needed later for weather features","3bf9c0b7":"!pip -qqq install meteostat","0dea06cf":"from meteostat import Daily, Point","1c035a06":"meteo_df = pd.DataFrame()\nfor country in geo_df['name']:\n    lat = geo_df.loc[geo_df['name']==country, 'latitude'].values[0]\n    long = geo_df.loc[geo_df['name']==country, 'longitude'].values[0]\n    \n    station = Point(lat, long)\n\n    data = Daily(station, min_date, max_date)\n    data = data.fetch()\n    data = data.reset_index()[['time', 'tavg', 'snow']].rename(columns={'time':DATE, 'tavg':'meteo_temp_avg', 'snow':'meteo_snow'})\n    data['meteo_snow'] = data['meteo_snow'].fillna(0).astype(int)\n    data['country'] = country\n    meteo_df = meteo_df.append(data)\n    \nmeteo_df = meteo_df.fillna(method='ffill')","662b52c2":"X = X.merge(meteo_df, on=[DATE, 'country'])","e510d886":"kaggle_comp = pd.read_csv('..\/input\/meta-kaggle\/Competitions.csv', parse_dates=['EnabledDate', 'DeadlineDate'])\n\ncompetition_cols = ['EnabledDate', 'DeadlineDate', 'HostSegmentTitle', 'TotalTeams', 'TotalCompetitors', 'TotalSubmissions', 'Slug', 'Title', 'Id']\n\nkaggle_comp = kaggle_comp.loc[(kaggle_comp['EnabledDate']>'2014-06-01') & (kaggle_comp['EnabledDate']<'2020-06-01'), competition_cols]\\\n                         .rename(columns={'Id':'CompetitionId'})","9f959794":"kaggle_teams = pd.read_csv('..\/input\/meta-kaggle\/Teams.csv', parse_dates=['LastSubmissionDate'], low_memory=False)\n\nteams_cols = ['Id', 'CompetitionId']\n\nkaggle_teams = kaggle_teams[teams_cols].rename(columns={'Id':'TeamId'})","40bf9852":"kaggle_subs = pd.read_csv('..\/input\/meta-kaggle\/Submissions.csv', parse_dates=['SubmissionDate'])\n\nsubmissions_cols = ['Id', 'SubmittedUserId', 'TeamId', 'SubmissionDate', 'IsAfterDeadline']\n\nkaggle_subs = kaggle_subs.loc[(kaggle_subs['SubmissionDate']>='2015-01-01') & (kaggle_subs['SubmissionDate']<'2020-01-01') & (kaggle_subs['IsAfterDeadline']==False), \n                              submissions_cols]\\\n                              .rename(columns={'Id':'SubmissionId'})","d74ae6ab":"kaggle_all_df = kaggle_comp.merge(kaggle_teams, how='left', on='CompetitionId')\\\n                           .merge(kaggle_subs, how='left', on='TeamId')\\","d94d18d7":"kaggle_subs_num_df = kaggle_all_df.groupby('SubmissionDate')['SubmissionId'].nunique()\\\n                                  .to_frame().reset_index()\\\n                                  .rename(columns={'SubmissionDate':DATE, 'SubmissionId':'kaggle_subs_num'})","772357bc":"kaggle_comp_num_df = kaggle_all_df.groupby('SubmissionDate')['CompetitionId'].nunique()\\\n                                  .to_frame().reset_index()\\\n                                  .rename(columns={'SubmissionDate':DATE, 'CompetitionId':'kaggle_comp_num'})","85575f45":"X = X.merge(kaggle_subs_num_df, on=[DATE])\n\nX = X.merge(kaggle_comp_num_df, on=[DATE])","9ffaf3de":"del kaggle_all_df, kaggle_comp, kaggle_subs, kaggle_teams, kaggle_subs_num_df, kaggle_comp_num_df\ngc.collect()","ba328404":"IGNORE_COLS = ['year', 'month', 'dayofweek', 'day_name']\nFEATURES = [col for col in X.columns if col not in IGNORE_COLS+[TARGET]+[ID]]","816cc386":"X = pd.get_dummies(X[FEATURES], drop_first=True)","77d8c482":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8', 'uint8', 'int16', 'uint16', 'int32', 'uint32',\n                'int64', 'uint64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if 'int' in str(col_type).lower():\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n \n    return df","4b38f7d9":"X = reduce_mem_usage(X)","f4150492":"X = pd.merge(left=X, left_index=True,\n             right=pd.concat([train_df.drop(columns=[TARGET]), test_df]).drop(columns=[DATE]), right_index=True,\n             how='left')","3e653551":"X_train_df = X.loc[X[DATE]<val_min_date]  # 2015-2017\nX_val_df = X.loc[(val_min_date<=X[DATE]) & (X[DATE]<test_min_date)]  # 2018\nX_test_df = X.loc[X[DATE]>=test_min_date]  # 2019","a0d99d0a":"X_train_df.to_pickle(\"X_train_df.pkl\")\nX_val_df.to_pickle(\"X_val_df.pkl\")\nX_test_df.to_pickle(\"X_test_df.pkl\")","e0b0e6b8":"Y.loc[:train_max_date].to_pickle(\"Y_train_df.pkl\")\nY.loc[val_min_date:].to_pickle(\"Y_val_df.pkl\")\n\ndf.loc[(slice(None,train_max_date), slice(None), slice(None)), :].to_pickle(\"Y_train_stacked_df.pkl\")\ndf.loc[(slice(val_min_date,None), slice(None), slice(None)), :].to_pickle(\"Y_val_stacked_df.pkl\")","2bbbf4a9":"HTML(f'''\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:{COLOR_GREY};\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n    <p style=\"padding: 10px; color:white;\">\nIf you find this notebook useful or you just like it, please upvote \u25b2.<br>\n        Use this link <a href={NOTEBOOK_URL}>{NOTEBOOK_NAME}<\/a> to cite.\n        Questions\/feedback? \u2192 <a href={NOTEBOOK_URL}\/comments>comment<\/a>.\n    <\/p>\n<\/div>''')\n","bb5dcc1a":"<a id=\"holidays\"><\/a>\n## **<span style=\"color:#58355E;\">Holidays<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","54896d5c":"<a id=\"kaggle-data\"><\/a>\n## **<span style=\"color:#58355E;\">Kaggle data<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","65e46381":"[forex-python](https:\/\/forex-python.readthedocs.io\/en\/latest\/index.html) free foreign exchange rates, bitcoin prices and currency conversion.","d9aac515":"<a id=\"toc\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"toc\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Table of contents<\/center><\/h1>","d73000b6":"<a id=\"time-step-trend-and-fourier\"><\/a>\n## **<span style=\"color:#58355E;\">Time-step, trend and Fourier features<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","6edc95a3":"<div class=\"alert alert-block alert-success\">  \nYupi! We've reached the end of this notebook \ud83d\udcdd <br>Hope it was helpful \ud83d\ude0a\n<\/div>","f5438a64":"<a id=\"train-val-test\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"save\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Split to train, val and test<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","fa0cc4b0":"<a id=\"world-bank\"><\/a>\n## **<span style=\"color:#58355E;\">World Bank's data - macro, financial and sector databases under your fingertips<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","6b87e3b0":"<hr>","aaa6c3d9":"***","0a05ac50":"<a id=\"feature-engineering\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"feature-engineering\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Feature engineering<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","49127dda":"<a id=\"libraries\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"libraries\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Libraries<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","7c3b898c":"<a id=\"basic-date-based\"><\/a>\n## **<span style=\"color:#58355E;\">Basic date-based features<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","ab5c33a6":"\n> * [Kaggle's Time Series Tutorial: Seasonality](https:\/\/www.kaggle.com\/ryanholbrook\/seasonality)\n> * [Accessing World Bank data](https:\/\/blogs.worldbank.org\/opendata\/introducing-wbgapi-new-python-package-accessing-world-bank-data)\n> * [Meteostat library](https:\/\/github.com\/meteostat\/meteostat-python)","12d06003":"<a id=\"references\"><\/a>\n<h1 id=\"references\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>References<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","3aee9be9":"<a id=\"weather\"><\/a>\n## **<span style=\"color:#58355E;\">Weather<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","86d7b3e6":"<a id=\"exchange-rate\"><\/a>\n## **<span style=\"color:#58355E;\">Exchange rate<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","56d229a9":"<a id=\"reduce-mem-usage\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"save\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Convert types to reduce memory usage<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","64f841e6":"<a id=\"easter-xmas\"><\/a>\n## **<span style=\"color:#58355E;\">Easter and Christmas breaks<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","a7da5da5":"<a id=\"load-datasets\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"load-datasets\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Load Datasets<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","65d30bf8":"<a id=\"one-hot-encode\"><\/a>\n## **<span style=\"color:#58355E;\">One-Hot encoding<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","efdad092":"***","aece8445":"<a id=\"save\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 id=\"save\" class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#20BEFF; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Save<\/center><\/h1>\n    \n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a>","66085677":"[wbgapi](https:\/\/pypi.org\/project\/world-bank-data\/) provide access to huge compilation of relevant, high-quality, and internationally comparable statistics about global development and the fight against poverty. The database contains 1,400 time series indicators for 217 economies and more than 40 country groups, with data for many indicators going back more than 50 years.","6051b7b1":"To query World Bank (WB) database you'll need so called `topic` which is string type code like for example *'SP.POP.TOTL'* (Population, total). \n[Here](http:\/\/databank.worldbank.org\/data\/download\/site-content\/WDI_CETS.xls) you\u2019ll find a file listing the indicators in the WDI database (which includes the IDS indicators), with the second worksheet containing code breakdowns and descriptions for each component.\n\nBy providing additional information you can get data for specific time frame and\/or country (in WB called `economy`)","45c9decf":"<a id=\"may-june-nov\"><\/a>\n## **<span style=\"color:#58355E;\">May-June-Nov<\/span>**\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"Go to TableOfContents\">Go to TOC<\/a> ","b8fb1102":"0. [References](#references) \ud83c\udf93\n1. [Libraries](#libraries) \ud83d\udcda\n1. [Load Datasets](#load-datasets) \ud83e\uddf1\n1. [Feature engineering](#feature-engineering) \ud83e\uddf0\n    1. [Basic date-based](#basic-date-based)\n    1. [Time-step, trend and fourier](#time-step-trend-and-fourier)\n    1. [Holidays](#holidays)\n    1. [Easter and Christmas breaks](#easter-xmas)\n    1. [May-June-Nov](#may-june-nov)\n    1. [Exchange rate](#exchange-rate)\n    1. [World Bank's data](#world-bank)\n    1. [Weather](#weather)\n    1. [Kaggle data](#kaggle-data)\n1. [Save](#save) \ud83d\udcbe"}}