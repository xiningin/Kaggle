{"cell_type":{"399d0499":"code","d4d06d86":"code","3e8fc721":"code","6a047d82":"code","d2ab629e":"code","009c4d63":"code","bf641c05":"code","75baef27":"code","c45ed302":"code","7436dee6":"markdown","1a367e52":"markdown","24bca849":"markdown","8955af8b":"markdown","ed035749":"markdown","55ec7c9f":"markdown","775b4e7c":"markdown","bcb052b7":"markdown"},"source":{"399d0499":"import json\nimport re\nimport unidecode\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ndf = pd.read_json('..\/input\/train.json')\ndf = df.head(10000)\n\nlabel_encoder = LabelEncoder()\ndf['y'] = label_encoder.fit_transform(df['cuisine'].values)\nclass_names = label_encoder.classes_.tolist()\n\ndf['num_ingredients'] = df['ingredients'].apply(len)\ndf = df[df['num_ingredients'] > 1]\n\ndf['ingredients'] = df['ingredients'].apply(lambda x: ' '.join(x))\n\nlemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients_text):\n    ingredients_text = ingredients_text.lower()\n    ingredients_text = ingredients_text.replace('-', ' ')\n    words = []\n    for word in ingredients_text.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) <= 2: continue\n        if '\u2019' in word: continue\n        word = re.sub('[.,()!]', '', word)\n        word = lemmatizer.lemmatize(word)\n        if len(word) > 0: words.append(word)\n    return ' '.join(words)\n\nvectorizer = make_pipeline(\n    FunctionTransformer(lambda x: [preprocess(ingredients) for ingredients in x], validate=False),\n    TfidfVectorizer(sublinear_tf=True, stop_words='english'),\n    FunctionTransformer(lambda x: x.astype('float16'), validate=False)\n)","d4d06d86":"train, val = train_test_split(df, random_state=42)\n\nx_train = vectorizer.fit_transform(train['ingredients'].values)\nx_val = vectorizer.transform(val['ingredients'].values)\ny_train = train['y'].values\ny_val = val['y'].values","3e8fc721":"estimator = SVC(\n    C=50,\n    kernel='rbf',\n    gamma=1.4,\n    coef0=1,\n    cache_size=500,\n    probability=True\n)\nclassifier = OneVsRestClassifier(estimator, n_jobs=-1)\nclassifier.fit(x_train, y_train)","6a047d82":"y_pred = label_encoder.inverse_transform(classifier.predict(x_val))\nval['pred'] = y_pred\ny_true = label_encoder.inverse_transform(y_val)\n\nprint(f'accuracy score on train data: {accuracy_score(y_true, y_pred)}')\n\ndef report2dict(cr):\n    rows = []\n    for row in cr.split(\"\\n\"):\n        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n        if len(parsed_row) > 0: rows.append(parsed_row)\n    measures = rows[0]\n    classes = defaultdict(dict)\n    for row in rows[1:]:\n        class_label = row[0]\n        for j, m in enumerate(measures):\n            classes[class_label][m.strip()] = float(row[j + 1].strip())\n    return classes\nreport = classification_report(y_true, y_pred)\npd.DataFrame(report2dict(report)).T","d2ab629e":"explainer = LimeTextExplainer(class_names=class_names)\nclassifier_fn = make_pipeline(vectorizer, classifier).predict_proba\ndef explain(recipe):\n    display(recipe[['id', 'cuisine', 'pred', 'ingredients']])\n    text_instance = recipe['ingredients'].values[0]\n    explainer.explain_instance(\n        text_instance,\n        classifier_fn,\n        top_labels=1,\n        num_features=6\n    ).show_in_notebook()","009c4d63":"val[val['cuisine'] == 'japanese'].head(10)[['id', 'cuisine', 'pred', 'ingredients']]","bf641c05":"explain(val[val['id'] == 26634])\nexplain(val[val['id'] == 17628])\nexplain(val[val['id'] == 36372])","75baef27":"explain(val[val['id'] == 11331])\nexplain(val[val['id'] == 49040])","c45ed302":"my_recipe = '''\n1. Add the chicken and sweet peppers to the cooker.\n2. Leave the tortillas and chedder cheese.\n3. Finish with sprinkled olives and a dollop of sour cream on top.\n'''\nexplainer.explain_instance(\n    my_recipe,\n    classifier_fn,\n    top_labels=1,\n    num_features=6\n).show_in_notebook()","7436dee6":"I may not be able to answer correctly if I'm asked if these recipes are Japanese or not.\nI'd say that it's an Indian recipe if turmeric is used, and it's an Italian recipe if mozzarella is the main ingredient of the recipe.\n\nIt looks more like mislabeled data. We may not need to care about it (or should we remove it from the training dataset?)\n\nBy the way, we can give text directly to LIME. You can make your own recipe. Let's see how it's classified.","1a367e52":"# Let's check on Japanese recipes\n\nsince I'm familiar with Japanese recipes (I was working at a Japanese restaurant).","24bca849":"(I downsampled the dataset to speed up training.)","8955af8b":"# Explaining predictions\n\nNow we have a trained model. To convince myself, I used LIME which is a library for explaining what machine learning models are doing.\n\n<img src=\"https:\/\/github.com\/marcotcr\/lime\/raw\/master\/doc\/images\/twoclass.png\" width=\"720\">\n\n<div align=\"center\">\n_[marcotcr\/lime: Lime: Explaining the predictions of any machine learning classifier](https:\/\/github.com\/marcotcr\/lime)_\n<\/div>\n\nYou can find how LIME explains models here: [\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https:\/\/arxiv.org\/abs\/1602.04938)","ed035749":"# Taste predictions\n\nWe've seen the preprocess ([What are ingredients?](https:\/\/www.kaggle.com\/rejasupotaro\/what-are-ingredients)), representations ([Representations for ingredients](https:\/\/www.kaggle.com\/rejasupotaro\/representations-for-ingredients)), and model ([Let's cook model](https:\/\/www.kaggle.com\/rejasupotaro\/let-s-cook-model)).\nThe model works pretty well (0.82491, Top 3%!) but I'm wondering if it really performs well on unseen recipes.\n\nIn this Kernel, I asked the model to explain how the cuisine is determined.\n\n_Let me skip the proprocess part because it's the same._","55ec7c9f":"![taco time](https:\/\/media1.giphy.com\/media\/PrRVvcwgty7K0\/giphy.gif)","775b4e7c":"It makes sense. \"sake\", \"mirin\", and \"miso\" are Japanese specific ingredients.\n\nNext, let's see misclassfied Japanese recipes.","bcb052b7":"First, let's see correctly classified Japanese recipes."}}