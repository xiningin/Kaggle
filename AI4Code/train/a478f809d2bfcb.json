{"cell_type":{"47414e65":"code","af0cea70":"code","e4f738f0":"code","f4874a15":"code","9e19a838":"code","82ceb050":"code","1deff4ab":"code","6bda11f6":"code","5eca17a2":"code","4e40f9b2":"code","4d1b3b40":"code","dc679321":"code","2e3ed80d":"code","af0c7372":"code","0333d937":"code","642906e4":"code","921dafc8":"markdown"},"source":{"47414e65":"#import the libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport seaborn as sns","af0cea70":"#load the data\ndf = pd.read_csv(\"..\/input\/us-consumer-finance-complaints\/consumer_complaints.csv\")\ndf.head()","e4f738f0":"#looking at the attributes and null values if any\ndf.info()","f4874a15":"#slicing out the necessary columns\ndf = df[['product', 'consumer_complaint_narrative']]\ndf = df[pd.notnull(df['consumer_complaint_narrative'])]\ndf.head()","9e19a838":"#adding a new column for product (text to categorical values)\ndf['category_id']=df['product'].factorize()[0]\ndf.head()","82ceb050":"df.groupby('product').consumer_complaint_narrative.count()","1deff4ab":"#making a bar plot\nfig = plt.figure(figsize=(8,6))\ndf.groupby('product').consumer_complaint_narrative.count().plot.bar(ylim=0)\nplt.show()","6bda11f6":"#splitting the datas\nX_train, X_test, y_train, y_test = train_test_split(df['consumer_complaint_narrative'], df['product'])","5eca17a2":"#converting object to numeric values\nlb = LabelEncoder()\ny_train = lb.fit_transform(y_train)\ny_test = lb.fit_transform(y_test)","4e40f9b2":"#transforming text into features with Tfidf\ntfidf = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\ntfidf.fit(df['consumer_complaint_narrative'])\nX_train_tfidf = tfidf.transform(X_train)\nX_test_tfidf = tfidf.transform(X_test)","4d1b3b40":"#creating and fitting a model\nmodel = LogisticRegression()\nmodel.fit(X_train_tfidf, y_train)","dc679321":"#Lets check the accuracy score\ny_predict = model.predict(X_test_tfidf)\nprint(accuracy_score(y_test, y_predict))\nconf_mat = confusion_matrix(y_test, y_predict)","2e3ed80d":"#creating a dictionary for products\ncategory_id_df = df[['product', 'category_id']].drop_duplicates().sort_values('category_id')\ncategory_to_id = dict(category_id_df.values)\nid_to_category = dict(category_id_df[['category_id','product']].values)","af0c7372":"id_to_category","0333d937":"fig, ax = plt.subplots(figsize=(8,6))\nsns.heatmap(conf_mat, annot=True, fmt='d', cmap=\"BuPu\", xticklabels=category_id_df[['product']].values, yticklabels=category_id_df[['product']].values)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","642906e4":"#lets test our prediction with a random text\ntexts = [\"This company refuses to provide me verification and validation of debt\"+ \"per my right under the FDCPA. I do not believe this debt is mine.\"]\ntext_features = tfidf.transform(texts)\npredictions = model.predict(text_features)\nprint(texts)\nprint(\" - Predicted as: '{}'\".format(id_to_category[predictions[0]]))","921dafc8":"### we can see that Debt_collection and Mortgage have the maximum complaints.\nLets split and train our data"}}