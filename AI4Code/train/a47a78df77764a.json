{"cell_type":{"e8da8d9d":"code","d1833c13":"code","e7f431af":"code","5c7d28d6":"code","bbe0b5ed":"code","bb733f75":"code","8ddd066a":"code","d2275710":"code","5f88aa54":"code","79ee5b1c":"code","665e6907":"code","87d23913":"code","59621825":"code","6baf72a7":"code","b1d87ac8":"code","eee6a630":"code","6809c0a5":"code","db3dde16":"code","bf618070":"code","66f86dd7":"code","e6692c23":"code","634a28d2":"code","890b5426":"code","45c35779":"code","68b14ad6":"code","a003008f":"code","8d5064ff":"code","aff19814":"code","fbc6d9dd":"code","8b693d43":"code","ffe2ccc0":"code","68c8802a":"code","030522bb":"code","230a4f92":"code","31bd38bb":"code","5a1f2b95":"code","ceae4c4a":"code","c47ca96d":"code","46c71a02":"code","89609167":"code","e80c5d82":"code","f01aa5b1":"code","d024ca26":"code","27cd684a":"code","e78d23e2":"code","d92871f9":"code","0a124f40":"code","ca798500":"code","c9e31651":"code","c31fd803":"code","7af3d5ed":"code","1bd8efdd":"code","605c7dc9":"code","2395291a":"code","831502fe":"code","8d836879":"code","21454cb1":"code","ca0dc206":"code","edf03405":"code","b09de5f0":"code","a0db6d7f":"code","7e3dfce5":"code","7405abf0":"code","305a10ba":"code","c3f09554":"code","c15d8098":"code","911c90e8":"code","6a8c36fd":"code","068808ba":"code","52fc5760":"code","f1400d82":"code","1cb04f8a":"code","d961c0fb":"code","42320d5a":"code","1f16a1f5":"code","ed79f551":"code","267a412b":"code","3d396a22":"code","b0417d56":"code","f7c799c1":"code","5c37c68e":"code","a00d8dcc":"code","69fc39ee":"code","4a1030d2":"code","c29553d4":"code","b9f8c629":"code","62b9e385":"code","5ea2cb55":"code","621d51c4":"code","c3198e91":"code","369ceb11":"code","df91bc1e":"code","98c171cd":"code","2b8efdc6":"code","9dd00b9c":"code","2cdfbe03":"code","d8dc9418":"code","f80c3bd5":"code","f46ac2b5":"code","973cb8d6":"code","9f07374a":"code","0674d53a":"code","afbb3604":"code","7db1b6fa":"code","850dc907":"code","44f49944":"code","a4386649":"code","1d711399":"code","2a034a84":"code","9a911e83":"code","d815cfb7":"code","3d39f7df":"code","150cdac8":"code","2e9bcb80":"code","5a20eb9b":"code","032b24cc":"code","99c62411":"code","abc42764":"code","57013a98":"code","18b37f68":"code","9b58938a":"code","b349a13a":"code","c9e12371":"code","b495fb20":"code","4c13c2c3":"code","d06ee2ca":"code","d4a90e3b":"markdown","8d4cd2b2":"markdown","84779490":"markdown","feddffb0":"markdown","af602e37":"markdown","a7540f1b":"markdown","d814f673":"markdown","7f080580":"markdown","a0642bea":"markdown","b960a8f5":"markdown","6a58cff3":"markdown","e38cb562":"markdown","232cd8a0":"markdown","e8b62992":"markdown","f7de3fe3":"markdown","42f942ed":"markdown","e51adb5e":"markdown","9467228c":"markdown","53134250":"markdown","0d565c57":"markdown","1385abab":"markdown","d6fe9b6e":"markdown","c4f0269d":"markdown","b48da77c":"markdown","e0498b93":"markdown","ee0a8a8f":"markdown","6395602c":"markdown","4b34e7d6":"markdown","0762278a":"markdown","00eda19b":"markdown","c84f0eab":"markdown","1c36b54f":"markdown","8bf36e65":"markdown","a8e51b35":"markdown","366433e6":"markdown","ed49549b":"markdown","fa5e3b4a":"markdown","43c57fc1":"markdown","a2d3e560":"markdown","7ddd02c7":"markdown","830769b9":"markdown","694b7c8d":"markdown","44f5b35c":"markdown","6447ec0e":"markdown","b1010f9f":"markdown","64fdcc71":"markdown","a349fdae":"markdown"},"source":{"e8da8d9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #comprehensive library for creating static, animated, and interactive visualizations in Python\nimport seaborn as sns #data visualization library based on matplotlib\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1833c13":"run start","e7f431af":"train_data = pd.read_csv(\"\/kaggle\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")\ntrain_data.head()","5c7d28d6":"train_data.describe()\n","bbe0b5ed":"test_data = pd.read_csv(\"\/kaggle\/input\/loan-prediction-problem-dataset\/test_Y3wMUE5_7gLdaTN.csv\")\ntest_data.head()","bb733f75":"train_data.info()","8ddd066a":"train_data.isnull().sum()","d2275710":"print(\"Mean of LoanAmount:\", train_data['LoanAmount'].mean())\ntrain_data['LoanAmount'] = train_data['LoanAmount'].fillna(train_data['LoanAmount'].mean())\nprint(train_data.loc[:, 'LoanAmount'])\n#pd.notnull(train_data[\"LoanAmount\"])","5f88aa54":"print(\"Median of Credit_History:\", train_data['Credit_History'].median())\ntrain_data['Credit_History'] = train_data['Credit_History'].fillna(train_data['Credit_History'].median())\nprint(train_data.loc[:, 'Credit_History'])\n#pd.notnull(train_data[\"Credit_History\"])","79ee5b1c":"print(\"Gender Male:\", sum(train_data['Gender'] == 'Male'))\nprint(\"Gender Female:\", sum(train_data['Gender'] == 'Female'))\n\ntrain_data['Gender'] = train_data['Gender'].fillna('Male')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Married Yes:\", sum(train_data['Married'] == 'Yes'))\nprint(\"Married No:\", sum(train_data['Married'] == 'No'))\n\ntrain_data['Married'] = train_data['Married'].fillna('Yes')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Dependents 0:\", sum(train_data['Dependents'] == '0'))\nprint(\"Dependents 1:\", sum(train_data['Dependents'] == '1'))\n\ntrain_data['Dependents'] = train_data['Dependents'].fillna('0')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Self_Employed Yes:\", sum(train_data['Self_Employed'] == 'Yes'))\nprint(\"Self_Employed No:\", sum(train_data['Self_Employed'] == 'No'))\n\ntrain_data['Self_Employed'] = train_data['Self_Employed'].fillna('No')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Mean of Loan_Amount_Term:\", train_data['Loan_Amount_Term'].median())\ntrain_data['Loan_Amount_Term'] = train_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].median())\n#print(train_data.loc[:, 'Loan_Amount_Term'])\n#pd.notnull(train_data[\"Loan_Amount_Term\"])","665e6907":"train_data['Gender'].value_counts()","87d23913":"train_data['Married'].value_counts()","59621825":"train_data['Education'].value_counts()\n#more graduated people seem to apply for a loan","6baf72a7":"train_data['Self_Employed'].value_counts()\n#Self employed people seem not to apply for a loan","b1d87ac8":"train_data['Property_Area'].value_counts()\n#quite balanced","eee6a630":"plt.boxplot(train_data['ApplicantIncome'])","6809c0a5":"plt.boxplot(train_data['CoapplicantIncome'])","db3dde16":"plt.boxplot(train_data['LoanAmount'])","bf618070":"plt.boxplot(train_data['Loan_Amount_Term'])","66f86dd7":"plt.boxplot(train_data['Credit_History'])","e6692c23":"sns.scatterplot(x='Property_Area',y='Loan_Status',data=train_data)","634a28d2":"print(pd.crosstab(train_data['Property_Area'],train_data['Loan_Status']))","890b5426":"sns.countplot(train_data['Property_Area'],hue=train_data['Loan_Status'])","45c35779":"sns.scatterplot(x='Self_Employed',y='Loan_Status',data=train_data)","68b14ad6":"sns.scatterplot(x='Credit_History',y='Loan_Status',data=train_data)","a003008f":"print(pd.crosstab(train_data['Credit_History'],train_data['Loan_Status']))","8d5064ff":"sns.countplot(train_data['Credit_History'],hue=train_data['Loan_Status'])","aff19814":"print(pd.crosstab(train_data['Gender'],train_data['Loan_Status']))","fbc6d9dd":"sns.countplot(train_data['Gender'],hue=train_data['Loan_Status'])","8b693d43":"print(pd.crosstab(train_data['Married'],train_data['Loan_Status']))","ffe2ccc0":"sns.countplot(train_data['Married'],hue=train_data['Loan_Status'])","68c8802a":"print(pd.crosstab(train_data['Self_Employed'],train_data['Loan_Status']))","030522bb":"sns.countplot(train_data['Self_Employed'],hue=train_data['Loan_Status'])","230a4f92":"print(pd.crosstab(train_data['Education'],train_data['Loan_Status']))","31bd38bb":"sns.countplot(train_data['Education'],hue=train_data['Loan_Status'])","5a1f2b95":"train_data['Loan_Status'].replace('N',0,inplace=True)\ntrain_data['Loan_Status'].replace('Y',1,inplace=True)\n\n#train_data.head()","ceae4c4a":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nle=LabelEncoder()\nohe=OneHotEncoder()\n\ntrain_data2 = train_data\n\ntrain_data2=train_data2.drop(labels=['Loan_ID'],axis=1)\ntrain_data2['Property_Area']=le.fit_transform(train_data2['Property_Area'])\n# 0 == 'Rural',1 == 'Semiurban', 2 == 'Urban' \ntrain_data2['Dependents']=le.fit_transform(train_data2['Dependents'])\n# 0 == 0, 1 == 1, 2== 2, 3 == '+3'\n\ntrain_data2=pd.get_dummies(train_data2)\n\ntrain_data2.dtypes","c47ca96d":"train_data2.info()","46c71a02":"train_data2.head()","89609167":"train_data2.corr()","e80c5d82":"plt.title('Correlation Matrix')\nsns.heatmap(train_data2.corr(),annot=True)","f01aa5b1":"train_data2.head()","d024ca26":"train_data3 = train_data2\n\ntrain_data3=train_data3.drop(labels=['ApplicantIncome'],axis=1)\ntrain_data3=train_data3.drop(labels=['CoapplicantIncome'],axis=1)\ntrain_data3=train_data3.drop(labels=['LoanAmount'],axis=1)\ntrain_data3=train_data3.drop(labels=['Loan_Amount_Term'],axis=1)\ntrain_data3=train_data3.drop(labels=['Gender_Female'],axis=1)\ntrain_data3=train_data3.drop(labels=['Married_No'],axis=1)\ntrain_data3=train_data3.drop(labels=['Education_Not Graduate'],axis=1)\ntrain_data3=train_data3.drop(labels=['Self_Employed_Yes'],axis=1)\n\ntrain_data3.head(10)","27cd684a":"plt.title('Correlation Matrix (Update)')\nsns.heatmap(train_data3.corr(),annot=True)","e78d23e2":"#train_data3=train_data3.drop('Self_Employed_No',1)\n#train_data3=train_data3.drop('Dependents',1)\n\n#train_data3.head()","d92871f9":"X = train_data3.drop('Loan_Status', 1)\nY = train_data3['Loan_Status']","0a124f40":"train_data3.head()","ca798500":"print(len(X))\nX.head()","c9e31651":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=6)\n\nprint('Shape of x_train is: ',x_train.shape)\nprint('Shape of x_test is: ',x_test.shape)\nprint('Shape of y_train is: ',y_train.shape)\nprint('Shape of y_test is: ',y_test.shape)","c31fd803":"from sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)","7af3d5ed":"print(logreg.score(x_train, y_train))\nacc_log = round(logreg.score(x_train, y_train) * 100, 2)\nprint(round(acc_log,2,), \"%\")","1bd8efdd":"#Predicting trest dataset\npred = logreg.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccsc_log = round(accuracy_score(y_test,pred) * 100,2)\nprint('The accuracy of Logistic Regression is: ',accsc_log, '%' )","605c7dc9":"print(pred)","2395291a":"from sklearn import metrics\nlg_cm = metrics.confusion_matrix(y_test, pred)\nlg_cm","831502fe":"from sklearn.metrics import ConfusionMatrixDisplay\nlgcm_display = ConfusionMatrixDisplay(lg_cm, display_labels=[0,1]).plot()","8d836879":"print(metrics.recall_score(y_test,pred))\nprint(metrics.precision_score(y_test,pred))\nprint(metrics.f1_score(y_test,pred))","21454cb1":"data={'y_test':y_test,'pred':pred}\npd.DataFrame(data=data)","ca0dc206":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression(normalize=True)\nlinreg.fit(x_train,y_train)","edf03405":"print(linreg.score(x_train,y_train))\nacc_linreg = round(linreg.score(x_train, y_train) * 100, 2)\nprint(round(acc_linreg,2,), \"%\")","b09de5f0":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)","a0db6d7f":"print(dt.score(x_train,y_train))\nacc_dt = round(dt.score(x_train, y_train) * 100, 2)\nprint(round(acc_dt,2,), \"%\")","7e3dfce5":"pred1=dt.predict(x_test)\naccsc_dt = round(accuracy_score(y_test,pred1)* 100, 2)\nprint('The accuracy of Logistic Regression is: ', accsc_dt, '%')","7405abf0":"dt_cm = metrics.confusion_matrix(y_test,pred1)\ndt_cm","305a10ba":"dtcm_display = ConfusionMatrixDisplay(dt_cm, display_labels=[0,1]).plot()","c3f09554":"print(metrics.f1_score(y_test,pred1))\nprint(metrics.recall_score(y_test,pred1))\nprint(metrics.precision_score(y_test,pred1))","c15d8098":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn.fit(x_train,y_train)","911c90e8":"print(knn.score(x_train,y_train))\nacc_knn = round(knn.score(x_train, y_train) * 100, 2)\nprint(round(acc_knn,2,), \"%\")","6a8c36fd":"pred2=knn.predict(x_test)\naccsc_knn = round(accuracy_score(y_test,pred2) * 100, 2)\nprint('The accuracy of k-nearest neighbor regression: ', accsc_knn, '%')","068808ba":"knn_cm = metrics.confusion_matrix(y_test,pred2)\nknn_cm","52fc5760":"knncm_display = ConfusionMatrixDisplay(knn_cm, display_labels=[0,1]).plot()","f1400d82":"print(metrics.f1_score(y_test,pred2))\nprint(metrics.recall_score(y_test,pred2))\nprint(metrics.precision_score(y_test,pred2))","1cb04f8a":"from sklearn.svm import SVC\nsvm = SVC(kernel = 'linear', random_state = 0)\nsvm.fit(x_train, y_train)","d961c0fb":"print(svm.score(x_train,y_train))\nacc_svm = round(svm.score(x_train, y_train) * 100, 2)\nprint(round(acc_svm,2,), \"%\")","42320d5a":"pred3=svm.predict(x_test)\naccsc_svm = round(accuracy_score(y_test,pred3) * 100, 2)\nprint('The accuracy of support vector machine regression: ', accsc_svm, '%' )","1f16a1f5":"svm_cm = metrics.confusion_matrix(y_test,pred3)\nsvm_cm","ed79f551":"svmcm_display = ConfusionMatrixDisplay(svm_cm, display_labels=[0,1]).plot()","267a412b":"print(metrics.f1_score(y_test,pred3))\nprint(metrics.recall_score(y_test,pred3))\nprint(metrics.precision_score(y_test,pred3))","3d396a22":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)","b0417d56":"print(nb.score(x_train,y_train))\nacc_nb = round(nb.score(x_train, y_train) * 100, 2)\nprint(round(acc_nb,2,), \"%\")","f7c799c1":"pred4=nb.predict(x_test)\naccsc_nb = round(accuracy_score(y_test,pred4) * 100, 2)\nprint('The accuracy of naives bayes regression: ', accsc_nb, '%')","5c37c68e":"nb_cm = metrics.confusion_matrix(y_test,pred4)\nnb_cm","a00d8dcc":"nbcm_display = ConfusionMatrixDisplay(nb_cm, display_labels=[0,1]).plot()","69fc39ee":"print(metrics.f1_score(y_test,pred4))\nprint(metrics.recall_score(y_test,pred4))\nprint(metrics.precision_score(y_test,pred4))","4a1030d2":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf.fit(x_train, y_train)","c29553d4":"print(rf.score(x_train,y_train))\nacc_rf = round(rf.score(x_train, y_train) * 100, 2)\nprint(round(acc_rf,2,), \"%\")","b9f8c629":"acc_rf = round(rf.score(x_train, y_train) * 100, 2)\nprint(round(acc_rf,2,), \"%\")","62b9e385":"pred5=rf.predict(x_test)\naccsc_rf = round(accuracy_score(y_test,pred4) * 100, 2) \nprint('The accuracy of random forest classification: ', accsc_rf, '%')","5ea2cb55":"rf_cm = metrics.confusion_matrix(y_test,pred5)\nrf_cm","621d51c4":"rfcm_display = ConfusionMatrixDisplay(rf_cm, display_labels=[0,1]).plot()","c3198e91":"print(metrics.f1_score(y_test,pred5))\nprint(metrics.recall_score(y_test,pred5))\nprint(metrics.precision_score(y_test,pred5))","369ceb11":"results = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'Support Vector Machines', 'Naive Bayes', 'Random Forest',],\n    'Score': [acc_log, acc_dt, acc_knn, acc_svm, acc_nb, acc_rf]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(7)","df91bc1e":"results_acc = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'Support Vector Machines', 'Naive Bayes', 'Random Forest',],\n    'Score': [accsc_log, accsc_dt, accsc_knn, accsc_svm, accsc_nb, accsc_rf]})\nresult_df = results_acc.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(7)","98c171cd":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(rf, x_train, y_train, cv=10, scoring = \"accuracy\")\n\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","2b8efdc6":"importances = rf.feature_importances_\nimportance = pd.DataFrame({'Feature':x_train.columns,'Importance':np.round(importances,8)})\nimportance = importance.sort_values('Importance',ascending=False).set_index('Feature')\n\nimportance.head(9)","9dd00b9c":"importance.plot.bar()","2cdfbe03":"from sklearn.metrics import precision_score, recall_score\n\nprint(\"Precision:\", precision_score(y_test, pred5))\nprint(\"Recall:\", recall_score(y_test, pred5))","d8dc9418":"test_data.head()","f80c3bd5":"test_data.info()","f46ac2b5":"test_data.isnull().sum()","973cb8d6":"test_data['Gender'] = test_data['Gender'].fillna('Male')\ntest_data['Dependents'] = test_data['Dependents'].fillna('0')\ntest_data['Self_Employed'] = test_data['Self_Employed'].fillna('No')\ntest_data['LoanAmount'] = test_data['LoanAmount'].fillna(train_data['LoanAmount'].median())\ntest_data['Loan_Amount_Term'] = test_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].median())\ntest_data['Credit_History'] = test_data['Credit_History'].fillna(train_data['Credit_History'].median())\n\ntest_data2 = test_data\n\ntest_data2=test_data2.drop(labels=['Loan_ID'],axis=1)\ntest_data2['Property_Area']=le.fit_transform(test_data2['Property_Area'])\n# 0 == 'Rural',1 == 'Semiurban', 2 == 'Urban' \ntest_data2['Dependents']=le.fit_transform(test_data2['Dependents'])\n# 0 == 0, 1 == 1, 2== 2, 3 == '+3'\n\ntest_data2=pd.get_dummies(test_data2)\n\ntest_data3 = test_data2\n\ntest_data3=test_data3.drop(labels=['ApplicantIncome'],axis=1)\ntest_data3=test_data3.drop(labels=['CoapplicantIncome'],axis=1)\ntest_data3=test_data3.drop(labels=['LoanAmount'],axis=1)\ntest_data3=test_data3.drop(labels=['Loan_Amount_Term'],axis=1)\ntest_data3=test_data3.drop(labels=['Gender_Female'],axis=1)\ntest_data3=test_data3.drop(labels=['Married_No'],axis=1)\ntest_data3=test_data3.drop(labels=['Education_Not Graduate'],axis=1)\ntest_data3=test_data3.drop(labels=['Self_Employed_Yes'],axis=1)\n\ntest_data3['Credit_History'] = test_data3['Credit_History'].fillna(train_data['Credit_History'].median())\n\ntest_data3.head(10)","9f07374a":"import shap #package used to calculate Shap values\n\n#creates object that can calculate shap values\nexplainer = shap.TreeExplainer(rf, x_train)\n\n#calculates Shap Values\nshap_values_test = explainer.shap_values(test_data3)","0674d53a":"np.shape(shap_values_test[1])","afbb3604":"np.around(shap_values_test[1] * 100 , 2)","7db1b6fa":"shap_test = pd.DataFrame(np.around(shap_values_test[1] * 100 , 2), columns= ['Shap Dependents','Shap Credit_History','Shap Property_Area', 'Shap Gender_Male', 'Shap Married_Yes', 'Shap Education_Graduate', 'Shap Self_Employed_No'])\nshap_test","850dc907":"shap_test['Shap ApplicantIncome'] = 'null'\nshap_test['Shap CoapplicantIncome'] = 'null'\nshap_test['Shap LoanAmount'] = 'null'\nshap_test['Shap Loan_Amount_Term'] = 'null'\n\nshap_test","44f49944":"y_pred = rf.predict(test_data3)","a4386649":"y_pred_proba = rf.predict_proba(test_data3)\ny_pred_proba = y_pred_proba[:,0]","1d711399":"y_pred_proba = np.around(y_pred_proba * 100, 0)\ny_pred_proba","2a034a84":"y_pred_proba.mean()","9a911e83":"test_data['Gender'].replace('Male','Maennlich',inplace=True)\ntest_data['Gender'].replace('Female','Weiblich',inplace=True)\ntest_data['Married'].replace('Yes','Ja',inplace=True)\ntest_data['Married'].replace('No','Nein',inplace=True)\ntest_data['Education'].replace('Graduate','Abschluss',inplace=True)\ntest_data['Education'].replace('Not Graduate','Kein Abschluss',inplace=True)\ntest_data['Self_Employed'].replace('Yes','Ja',inplace=True)\ntest_data['Self_Employed'].replace('No','Nein',inplace=True)\ntest_data['Credit_History'].replace(1.0,'Vorliegend',inplace=True)\ntest_data['Credit_History'].replace(0.0,'Nicht vorliegend',inplace=True)\ntest_data['Property_Area'].replace('Rural','Laendlich',inplace=True)","d815cfb7":"output = pd.DataFrame({\n        \"Kredit_ID\": test_data[\"Loan_ID\"],\n        \"Geschlecht\": test_data[\"Gender\"],\n        \"Shap Geschlecht in %\": shap_test[\"Shap Gender_Male\"],\n        \"Verheiratet\": test_data[\"Married\"],\n        \"Shap Verheiratet in %\": shap_test[\"Shap Married_Yes\"],\n        \"Angehoerige\": test_data[\"Dependents\"],\n        \"Shap Angehoerige in %\": shap_test[\"Shap Dependents\"],\n        \"Ausbildung\": test_data[\"Education\"],\n        \"Shap Ausbildung in %\": shap_test[\"Shap Education_Graduate\"],\n        \"Selbstbeschaeftigt\": test_data[\"Self_Employed\"],\n        \"Shap Selbstbeschaeftigt in %\": shap_test[\"Shap Self_Employed_No\"],\n        \"Antragstellereinkommen\": test_data[\"ApplicantIncome\"],\n        \"Shap Antragstellereinkommen in %\": shap_test[\"Shap ApplicantIncome\"],\n        \"Mitantragstellereinkommen\": test_data[\"CoapplicantIncome\"],\n        \"Shap Mitantragstellereinkommen in %\": shap_test[\"Shap CoapplicantIncome\"],\n        \"Kredithoehe\": test_data[\"LoanAmount\"],\n        \"Shap Kredithoehe in %\": shap_test[\"Shap LoanAmount\"],\n        \"Kreditlaufzeit\": test_data[\"Loan_Amount_Term\"],\n        \"Shap Kreditlaufzeit in %\": shap_test[\"Shap Loan_Amount_Term\"],\n        \"Kreditgeschichte\": test_data[\"Credit_History\"],\n        \"Shap Kreditgeschichte in %\": shap_test[\"Shap Credit_History\"],\n        \"Immobilienbereich\": test_data[\"Property_Area\"],\n        \"Shap Immobilienbereich in %\": shap_test[\"Shap Property_Area\"],\n        \"Kreditgewaehrung\": y_pred,\n        \"Kreditgewaehrung_prozentual\": y_pred_proba\n    })\noutput['Kreditgewaehrung'].replace(1,'Ja', inplace=True)\noutput['Kreditgewaehrung'].replace(0,'Nein', inplace=True)\n\noutput.head()\noutput.to_csv('CSV_test.csv', index=False)\noutput.to_excel(\"Excel_test.xlsx\")\noutput.to_json(\"JSON_test.json\", orient='records')","3d39f7df":"output.head(10)","150cdac8":"#calculates Shap Values\nshap_values_train = explainer.shap_values(X)\n\n","2e9bcb80":"shap.summary_plot(shap_values_train[0], X, plot_type=\"bar\")","5a20eb9b":"shap.summary_plot(shap_values_train[0], X, plot_type=\"dot\")","032b24cc":"shap.dependence_plot('Credit_History', shap_values_train[1], X)\nshap.dependence_plot('Property_Area', shap_values_train[1], X)\nshap.dependence_plot('Dependents', shap_values_train[1], X)\nshap.dependence_plot('Married_Yes', shap_values_train[1], X)\nshap.dependence_plot('Gender_Male', shap_values_train[1], X)\nshap.dependence_plot('Education_Graduate', shap_values_train[1], X)\nshap.dependence_plot('Self_Employed_No', shap_values_train[1], X)","99c62411":"print(np.shape(shap_values_train[1]))\nprint(np.around(shap_values_train[1] * 100, 2))\nshap_train = pd.DataFrame(np.around(shap_values_train[1] * 100, 2), columns= ['Shap Dependents','Shap Credit_History','Shap Property_Area', 'Shap Gender_Male', 'Shap Married_Yes', 'Shap Education_Graduate', 'Shap Self_Employed_No'])\nshap_train","abc42764":"print(shap_train['Shap Dependents'].mean())\nprint(shap_train['Shap Credit_History'].mean())\nprint(shap_train['Shap Property_Area'].mean())\nprint(shap_train['Shap Gender_Male'].mean())\nprint(shap_train['Shap Married_Yes'].mean())\nprint(shap_train['Shap Education_Graduate'].mean())\nshap_train['Shap Self_Employed_No'].mean()","57013a98":"shap_train['Shap ApplicantIncome'] = 'null'\nshap_train['Shap CoapplicantIncome'] = 'null'\nshap_train['Shap LoanAmount'] = 'null'\nshap_train['Shap Loan_Amount_Term'] = 'null'\n\nshap_train","18b37f68":"y_pred_train = rf.predict(X)\ny_pred_train","9b58938a":"y_pred_train_proba = rf.predict_proba(X)\ny_pred_train_proba = y_pred_train_proba[:,0]","b349a13a":"y_pred_train_proba = np.around(y_pred_train_proba * 100, 0)\ny_pred_train_proba ","c9e12371":"print(y_pred_train_proba.mean())\nX.mean()","b495fb20":"conditions = [\n    (y_pred_train == 1) & (train_data[\"Loan_Status\"] == 1),\n    (y_pred_train == 0) & (train_data[\"Loan_Status\"] == 0),\n    (y_pred_train == 1) & (train_data[\"Loan_Status\"] == 0),\n    (y_pred_train == 0) & (train_data[\"Loan_Status\"] == 1)\n]\nchoices = ['TP', 'TN', 'FP', 'FN']\ntrain_data['ConfusionMatrix'] = np.select(conditions, choices)\ntrain_data['ConfusionMatrix']","4c13c2c3":"train_data['Gender'].replace('Male','Maennlich',inplace=True)\ntrain_data['Gender'].replace('Female','Weiblich',inplace=True)\ntrain_data['Married'].replace('Yes','Ja',inplace=True)\ntrain_data['Married'].replace('No','Nein',inplace=True)\ntrain_data['Education'].replace('Graduate','Abschluss',inplace=True)\ntrain_data['Education'].replace('Not Graduate','Kein Abschluss',inplace=True)\ntrain_data['Self_Employed'].replace('Yes','Ja',inplace=True)\ntrain_data['Self_Employed'].replace('No','Nein',inplace=True)\ntrain_data['Credit_History'].replace(1.0,'Vorliegend',inplace=True)\ntrain_data['Credit_History'].replace(0.0,'Nicht vorliegend',inplace=True)\ntrain_data['Property_Area'].replace('Rural','Laendlich',inplace=True)\n\noutput_train_data = pd.DataFrame({\n        \"Kredit_ID\": train_data[\"Loan_ID\"],\n        \"Geschlecht\": train_data[\"Gender\"],\n        \"Shap Geschlecht in %\": shap_train[\"Shap Gender_Male\"],\n        \"Verheiratet\": train_data[\"Married\"],\n        \"Shap Verheiratet in %\": shap_train[\"Shap Married_Yes\"],\n        \"Angehoerige\": train_data[\"Dependents\"],\n        \"Shap Angehoerige in %\": shap_train[\"Shap Dependents\"],\n        \"Ausbildung\": train_data[\"Education\"],\n        \"Shap Ausbildung in %\": shap_train[\"Shap Education_Graduate\"],\n        \"Selbstbeschaeftigt\": train_data[\"Self_Employed\"],\n        \"Shap Selbstbeschaeftigt in %\": shap_train[\"Shap Self_Employed_No\"],\n        \"Antragstellereinkommen\": train_data[\"ApplicantIncome\"],\n        \"Shap Antragstellereinkommen in %\": shap_train[\"Shap ApplicantIncome\"],\n        \"Mitantragstellereinkommen\": train_data[\"CoapplicantIncome\"],\n        \"Shap Mitantragstellereinkommen in %\": shap_train[\"Shap CoapplicantIncome\"],\n        \"Kredithoehe\": train_data[\"LoanAmount\"],\n        \"Shap Kredithoehe in %\": shap_train[\"Shap LoanAmount\"],\n        \"Kreditlaufzeit\": train_data[\"Loan_Amount_Term\"],\n        \"Shap Kreditlaufzeit in %\": shap_train[\"Shap Loan_Amount_Term\"],\n        \"Kreditgeschichte\": train_data[\"Credit_History\"],\n        \"Shap Kreditgeschichte in %\": shap_train[\"Shap Credit_History\"],\n        \"Immobilienbereich\": train_data[\"Property_Area\"],\n        \"Shap Immobilienbereich in %\": shap_train[\"Shap Property_Area\"],\n        \"Kreditgewaehrung\": y_pred_train,\n        \"Kreditgewaehrung_prozentual\": y_pred_train_proba,\n        \"Kreditgewaehrung_Realitaet\": train_data[\"Loan_Status\"],\n        \"ConfusionMatrix\": train_data['ConfusionMatrix']\n        })\n\noutput_train_data['Kreditgewaehrung'].replace(1,'Ja', inplace=True)\noutput_train_data['Kreditgewaehrung'].replace(0,'Nein', inplace=True)\n\noutput_train_data['Kreditgewaehrung_Realitaet'].replace(1,'Ja', inplace=True)\noutput_train_data['Kreditgewaehrung_Realitaet'].replace(0,'Nein', inplace=True)\n\n\noutput_train_data.to_csv(\"CSV_train_data.csv\", index=False)\noutput_train_data.to_excel(\"Excel_train_data.xlsx\")\noutput_train_data.to_json(\"JSON_train_data.json\", orient='records')","d06ee2ca":"output_train_data.head(10)","d4a90e3b":"-----------------------------------------------------------------","8d4cd2b2":"<h1>SVM<\/h1>","84779490":"<h1>Linear regression<\/h1>","feddffb0":"<h1>Splitting train and test dataset<\/h1>","af602e37":"<h1>Feature importance<\/h1>","a7540f1b":"true positives: 89 [1,1]<br>\ntrue negatives: 14 [0,0]<br>\nfalse negatives: 1 [1,0]<br>\nfalse positives: 19 [0,1]<br>","d814f673":"true positives: 86 [1,1]<br>\ntrue negatives: 12 [0,0]<br>\nfalse negatives: 4 [1,0]<br>\nfalse positives: 21 [0,1]<br>","7f080580":"<h1>Univariate Analysis<\/h1>","a0642bea":"<h1>Adaption of test_data<\/h1>","b960a8f5":"<h1>K-NN<\/h1>","6a58cff3":"<h3>From all married applicants around 72% get a loan.<\/h3>","e38cb562":"Loan_Status is most correlated with Credit_History and least correlated with Self_Employed_No, Dependents<br>\nConsider dropping!!!","232cd8a0":"<h1>Bivariate Analysis<\/h1>","e8b62992":"<h1>Logistic regression<\/h1>","f7de3fe3":"<h3>Out of all graduates around 71% get a loan.<\/h3>","42f942ed":"true positives: 89 [1,1]<br>\ntrue negatives: 14 [0,0]<br>\nfalse negatives: 1 [1,0]<br>\nfalse positives: 19 [0,1]<br>","e51adb5e":"score() takes a feature matrix X_test and the expected target values y_test. Predictions for X_test are compared with y_test and either accuracy (for classifiers) or R\u00b2 score (for regression estimators) is returned.","9467228c":"The shap_values object above is a list with two arrays. The first array is the SHAP values for a negative outcome (doesn't get loan), and the second array is the list of SHAP values for the positive outcome (gets loan). We typically think about predictions in terms of the prediction of a positive outcome, so we'll pull out SHAP values for positive outcomes (pulling out shap_values[1]).","53134250":"<h1>Random forest classification<\/h1>","0d565c57":"true positives: 89 [1,1]<br>\ntrue negatives: 14 [0,0]<br>\nfalse negatives: 1 [1,0]<br>\nfalse positives: 19 [0,1]<br>","1385abab":"now dependent categorial variabls are converted to continous variables.","d6fe9b6e":"<h1>Recoding to numerical values<\/h1>","c4f0269d":"<p>around 84% seems a good acuracy score for first try.<\/p>","b48da77c":"<h1>Decision tree<\/h1>","e0498b93":"<h1>Which is the best model?<\/h1>","ee0a8a8f":"<p>.corr() to calculate pearson's r, spearman's rho and kendall's tau<\/p>","6395602c":"<h3>Out of all <b>not self employed<\/b> 70% get a loan.<br>\n<s>Out of all  <b>self employed<\/b> 67% get a loan.<\/s><\/h3>","4b34e7d6":"filling the rest of the mising values, always by average value","0762278a":"train_data.info() shows that some values are missing.\n<br>These will be investigated in next code cell","00eda19b":"<h1>OUTPUT<\/h1>","c84f0eab":"<h3>males seem to have higher chances than females<\/h3>","1c36b54f":"<h1>K-Fold Cross Validation<\/h1>","8bf36e65":"<h1>Naives Bayes<\/h1>","a8e51b35":"<h1>Adaption of train_data<\/h1>","366433e6":"Creating missing Credit_History values by median<br>\nmean doesn't make sense as it is something around 0.8","ed49549b":"<h3>From all semiurban people around 77% get a loan. Thus this feature seems very useful to me.<\/h3>","fa5e3b4a":"<p>This model has a average accuracy of 74% with a standard deviation of 6%. The standard deviation shows how precise the stimates are.<br>\n   Thus this means that the accurcay of thi model can differ <b>+ - 6%<\/b><br>\n<\/p>","43c57fc1":"<p>The model predicts 82% of the time, a given loan correctly (precision). The recall tells us that it predicted the loan status of 94 % of the people who actually got a loan.<\/p>","a2d3e560":"true positives: 85 [1,1]<br>\ntrue negatives: 15 [0,0]<br>\nfalse negatives: 5 [1,0]<br>\nfalse positives: 18 [0,1]<br>","7ddd02c7":"<h1>Shap Values of test_data<\/h1>","830769b9":"<p>Random Forest seams to be the best option since it provides a good blackbox model.<br>\nNext step will be ckecking random forest when using cross validation.<\/p>","694b7c8d":"<h1>Shap Values of train_data<\/h1>","44f5b35c":"true positives: 82 [1,1]<br>\ntrue negatives: 16 [0,0]<br>\nfalse negatives: 8 [1,0]<br>\nfalse positives: 17 [0,1]<br>","6447ec0e":"missing values in gender, married, dependents, self_employed, loan_amount(crit), loan_amount_term, credit_history(crit).<br>\nFilling the mising values of loan_amount by the mean of all of its values.","b1010f9f":"base value for shap_values_train","64fdcc71":"scatterplots are used for determining the strength between two variables.<br>\nx-axis is the independent variable, y-axis is the dependent variable ","a349fdae":"<h3>notice that the dependent variable Loan_Status is dependent only on Credit_History. So this will be kept while all the others which are not related with Loan_Status will be discarded.<\/h3> "}}