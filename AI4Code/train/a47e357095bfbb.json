{"cell_type":{"da55e8a1":"code","4b3d7cee":"code","734e3480":"code","fd6c195b":"code","546c464b":"code","95ca7ac3":"code","6c9a0292":"code","2075935c":"code","e52a5bb1":"code","12320e18":"code","d109e4b7":"code","1752eccc":"code","49c34b91":"code","02133edc":"code","aa540449":"code","b2663d9a":"code","0660025a":"code","c56c4244":"code","08bf8bc1":"code","b519053a":"code","6f91008a":"code","b38bbc32":"code","6fdfb041":"markdown","8f25da7d":"markdown","548f9c46":"markdown","de7d1106":"markdown","a5191ae5":"markdown"},"source":{"da55e8a1":"import tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","4b3d7cee":"# Plots display settings\nplt.rcParams['figure.figsize'] = 12, 8\nplt.rcParams.update({'font.size': 14})","734e3480":"FILE_PATH = '\/kaggle\/input\/gold-price-prediction-dataset\/FINAL_USO.csv'","fd6c195b":"TARGET_COLUMN = 'adj close'","546c464b":"# Tensorflow settings\nEPOCHS = 1000\nPATIENCE = 5\nBATCH_SIZE = 64","95ca7ac3":"def daily_returns(df: pd.DataFrame, column: str) -> pd.DataFrame:\n    \"\"\"Function computes daily return values for selected parameter.\n    :param df: DataFrame with original values\n    :param column: Name of the column with selected parameter\n    :return: Updated DataFrame\n    \"\"\"\n    df[f'{column}_returns'] = df[column] \/ df[column].shift(1) - 1\n    return df\n\n\ndef calculate_macd(df: pd.DataFrame, column: str,\n                   nslow: int = 26, nfast: int = 12) -> pd.DataFrame:\n    \"\"\"Function computes moving average convergence-divergence (MACD)\n    indicator for price values from selected 'column' in 'df'.\n    :param df: DataFrame with original values\n    :param column: Name of the column to use\n    :param nslow: Larger time span\n    :param nfast: Shorter time span\n    :return: Updated DataFrame containing difference and MACD values\n    \"\"\"\n    # Difference between two exponential moving averages\n    # to measure momentum in a security\n    emaslow = df[column].ewm(\n        span=nslow, min_periods=nslow, adjust=True, ignore_na=False\n    ).mean()\n    emafast = df[column].ewm(\n        span=nfast, min_periods=nfast, adjust=True, ignore_na=False\n    ).mean()\n    df[f'dif_{column}'] = emafast - emaslow\n    # 9 days MACD indicator\n    df[f'macd_{column}'] = df[f'dif_{column}'].ewm(\n        span=9, min_periods=9, adjust=True, ignore_na=False\n    ).mean()\n    return df\n\n\ndef calculate_rsi(df: pd.DataFrame, column: str,\n                  periods: int = 14) -> pd.DataFrame:\n    \"\"\"Function computes Relative Strength Index (RSI)\n    for price values from selected 'column' in 'df'.\n    :param df: DataFrame with original values\n    :param column: Name of the column to use\n    :param periods: Number of days\n    :return: Updated DataFrame with RSI values\n    \"\"\"\n    # Price difference with the previous day\n    delta = df[column].diff()\n\n    # Gain and loss\n    up, down = delta.copy(), delta.copy()\n    up[up < 0] = 0\n    down[down > 0] = 0\n\n    avg_gain = up.ewm(com=periods, adjust=False).mean()\n    avg_loss = down.ewm(com=periods, adjust=False).mean().abs()\n\n    df[f'rsi_{column}'] = 100 - 100 \/ (1 + avg_gain \/ avg_loss)\n    return df\n\n\ndef calculate_sma(df: pd.DataFrame, column: str,\n                  periods: int = 15) -> pd.Series:\n    \"\"\"Function computes Simple Moving Average (SMA)\n    for price values from selected 'column' in 'df'.\n    :param df: DataFrame with original values\n    :param column: Name of the column to use\n    :param periods: Number of days\n    :return: Series with SMA values\n    \"\"\"\n    return df[column].rolling(window=periods, min_periods=periods, center=False).mean()\n\n\ndef calculate_bands(df: pd.DataFrame, column: str,\n                    peroids: int = 15) -> pd.DataFrame:\n    \"\"\"Function calculates Bollinger Bands\n    for price values from selected 'column' in 'df'.\n    :param df: DataFrame with original values\n    :param column: Name of the column to use\n    :param peroids: Number of days\n    :return: Updated DataFrame containing upper and lower band values\n    \"\"\"\n    std = df[column].rolling(window=peroids, min_periods=peroids, center=False).std()\n    sma = calculate_sma(df, column)\n    df[f'upper_band_{column}'] = sma + (2 * std)\n    df[f'lower_band_{column}'] = sma - (2 * std)\n    return df\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses\n    mae = hist.history['loss']\n    val_mae = hist.history['val_loss']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(mae) + 1)\n\n    plt.plot(x_axis, mae, 'bo', label='Training')\n    plt.plot(x_axis, val_mae, 'ro', label='Validation')\n    plt.title('Training and validation MSE')\n    plt.ylabel('Loss (MSE)')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","6c9a0292":"# Original data\ndata = pd.read_csv(FILE_PATH,\n                   index_col='Date',\n                   parse_dates=True,\n                   infer_datetime_format=True)\ndata.columns = data.columns.str.lower()\n\n# Select only the features related to gold prices\ndata = data[['open', 'high', 'low', 'close', 'adj close']]\ndata.head()","2075935c":"print(f'Dataset size: {data.shape}')","e52a5bb1":"# Price history\nplt.plot(data[TARGET_COLUMN])\nplt.title('Gold Price')\nplt.show()","12320e18":"# Calculate daily returns for gold adjusted close price\ndata = daily_returns(data, TARGET_COLUMN)","d109e4b7":"# Add technical indicators for adjusted gold price\ndata = calculate_rsi(data, TARGET_COLUMN)\ndata = calculate_bands(data, TARGET_COLUMN)\ndata = calculate_macd(data, TARGET_COLUMN)\ndata.tail()","1752eccc":"# As a result of calculating rolling indicators and shifting\n# DataFrame has some missing values at the head and tail.\ndata.dropna(inplace=True)","49c34b91":"# Create iterables containing input features\n# and corresponding next day's prices\ninput_features = data.iloc[:-1, :].values\ntargets = data.iloc[1:, :][TARGET_COLUMN].values.reshape(-1, 1)","02133edc":"# Scale down predicted values for better model convergence\nscaler = MinMaxScaler()\ntargets = scaler.fit_transform(targets)","aa540449":"# Leave latest periods of the time series for test and validation purposes\ntrain_data = input_features[:-120]\nval_data = input_features[-120:-50]\ntest_data = input_features[-50:]\n\ntrain_targets = targets[:-120]\nval_targets = targets[-120:-50]\ntest_targets = targets[-50:]\n\nprint(f'Train data: {train_data.shape}')\nprint(f'Validation data: {val_data.shape}')\nprint(f'Test data: {test_data.shape}')\n\n# Total number of input features\nn_features = train_data.shape[1]","b2663d9a":"# Create tensorflow dataset objects\ntrain_ds = tf.data.Dataset.from_tensor_slices(\n    (train_data, train_targets))\\\n    .shuffle(buffer_size=len(train_data))\\\n    .batch(BATCH_SIZE)\n\nval_ds = tf.data.Dataset.from_tensor_slices(\n    (val_data, val_targets)).batch(BATCH_SIZE)\n\ntest_ds = tf.data.Dataset.from_tensor_slices(\n    (test_data, test_targets)).batch(BATCH_SIZE)","0660025a":"# Normalization layer to scale numeric data\nnormalizer = tf.keras.layers.experimental.preprocessing.Normalization(\n    input_shape=(n_features,)\n)\nnormalizer.adapt(train_data)","c56c4244":"# Densely connected neural network\nmodel = tf.keras.models.Sequential(\n    [\n        normalizer,\n        tf.keras.layers.Dense(\n            64, activation='relu',\n            kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n        tf.keras.layers.Dense(\n            32, activation='relu',\n            kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n        tf.keras.layers.Dense(1)\n    ]\n)\n\nmodel.compile(optimizer='adam', loss='mse',\n              metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\nmodel.summary()","08bf8bc1":"# Train the model until validation accuracy stops improving\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=PATIENCE, restore_best_weights=True\n)\n\nhistory = model.fit(train_ds,\n                    epochs=EPOCHS,\n                    verbose=2,\n                    validation_data=val_ds,\n                    callbacks=[early_stop])","b519053a":"plot_history(history)","6f91008a":"# Evaluate the model on the test set\ntest_loss, test_mape = model.evaluate(test_ds)\nprint(f'MSE loss on test data: {test_loss}\\nMAPE: {test_mape}')","b38bbc32":"# Forecasts for validation and test periods\npred_val = model.predict(val_ds)\npred_val = scaler.inverse_transform(pred_val)\npred_test = model.predict(test_ds)\npred_test = scaler.inverse_transform(pred_test)\n\n# Visualize forecast vs. actual prices\nplt.plot(data[-150:][TARGET_COLUMN], label='Actual data')\nplt.plot(data[-120:-50].index, pred_val.ravel(), label='Validation forecast')\nplt.plot(data[-50:].index, pred_test.ravel(), label='Test forecast')\nplt.title('Gold Price')\nplt.legend()\nplt.show()","6fdfb041":"From the end of 2011 till beginning of 2016 gold price was mostly in a downward trend. In 2016-2018 gold price was fluctuating in a range from approximately 105 to 130. Using this time series to train a model could couse an issue. Most of the available data, which will be used for training, does not reflect the current price trends observed in the latest periods. However, when predicting the price just one step ahead it could be sufficient.","8f25da7d":"## Data processing","548f9c46":"## Create and train a model","de7d1106":"# Model for Predicting Gold Price\n\n**Mean Absolute Percentage Error (MAPE)** of the model on the test data is about **3%**.\n\n[Original dataset](https:\/\/www.kaggle.com\/sid321axn\/gold-price-prediction-dataset) in csv format contains 1718 rows and 80 columns in total, including stock indexes, currency exchange rates and stock prices for several precious metals. The goal is to predict future adjusted close price for the GOLD ETF.\n\nTesting various sets of input features to predict the gold priced showed that better accuracy is achieved when using only the prices of gold for previous periods and technical indicators based on these prices.\n\nFunctions for calculating technical indicators were copied (with modifications) from [this notebook](https:\/\/www.kaggle.com\/sid321axn\/gold-price-prediction-using-machine-learning). Instead of sklearn regression models used by the author of the dataset in the original notebook **densely connected neural network** is applied to predict the next day's gold price.","a5191ae5":"## Functions"}}