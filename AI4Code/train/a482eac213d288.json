{"cell_type":{"b5b5f446":"code","ff38acf8":"code","ab52d4f5":"code","a2a1f310":"code","a70d64b2":"code","998c41db":"code","66b14acf":"code","5aac1836":"code","4ecaeadf":"code","ede69757":"code","86cb5b5d":"code","4f8d3aaf":"code","1ed20b17":"code","403b4e62":"code","e202da65":"code","ea99c69e":"code","d94098df":"code","c1b686e7":"code","7a125daf":"code","dfd315ee":"code","ccb8abaa":"code","b7bbd8be":"code","a6334b06":"code","a141debc":"code","93b1091c":"code","40596d4f":"code","f1106c2c":"code","d2049446":"code","d9a8ed27":"code","c7223be0":"code","e3a08808":"code","a6fb0026":"code","9d15ea51":"code","986c70ec":"code","be0faa64":"code","caff6918":"code","51d6e95d":"code","2f2ccaa3":"code","564e713a":"code","11b71f5b":"code","bedcbf38":"code","6643c2d0":"code","4c4a0aaf":"code","ea712058":"code","3ca0868e":"code","afab93af":"code","cb3fb804":"code","5425c7d5":"code","b45eab45":"code","f32ce77e":"code","2c7588f8":"code","55132c62":"code","61c6d599":"code","43b90533":"code","4cb4a310":"code","ea2375c4":"code","deeb31f1":"code","84a2a696":"code","1c6c0538":"code","443f1696":"code","b2d1edb8":"code","8a3ddfd4":"code","06ec8e8e":"code","957f5dd2":"code","21a1cf37":"code","5eff9158":"code","20f18447":"code","b8b915c5":"code","23d6ccbe":"code","78d1f880":"code","f722d6c6":"code","0fdaad2d":"markdown","27c3064b":"markdown","0a870b54":"markdown","b5aa3e37":"markdown","af07a034":"markdown","f2ba4ace":"markdown","159e2b55":"markdown"},"source":{"b5b5f446":"import os\nimport pandas as pd\n\nimport numpy as np\n\nfrom sklearn.linear_model import Ridge, Lasso, LinearRegression\nfrom sklearn.model_selection import KFold, RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax, zscore\nfrom multiprocessing import cpu_count\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ff38acf8":"np.random.seed = 42","ab52d4f5":"data_dir = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/'\n\np_train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), index_col=0)\np_test = pd.read_csv(os.path.join(data_dir, \"test.csv\"), index_col=0)\np_sample = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))","a2a1f310":"# fig, ax = plt.subplots(figsize=(30,10))\nsns.scatterplot(x='GrLivArea', y='SalePrice', hue='OverallQual', data=p_train, palette='RdBu')","a70d64b2":"# Numerical cols\ncols = list(X_train.select_dtypes('number').columns)\nfig, axs = plt.subplots(int(np.sqrt(len(cols))), int(np.sqrt(len(cols))), figsize=(30, 30))\nfor col, ax in zip(cols, axs.ravel()):\n    sns.regplot(x=X_train[col], y=y_train, ax=ax);","998c41db":"p_train","66b14acf":"from scipy import stats\n\n# # Remove outliers \np_train.drop(p_train[(p_train['OverallQual']<5) & (p_train['SalePrice']>200000)].index, inplace=True)\np_train.drop(p_train[(p_train['GrLivArea']>4500) & (p_train['SalePrice']<300000)].index, inplace=True)\np_train.reset_index(drop=True, inplace=True)","5aac1836":"cols = [\"MSZoning\"] \n\n# a = []\n# for n in X.Neighborhood.unique():\n#     X[cols].mode().iloc[0]\n#     a.app\n# X[cols].mode().iloc[0]\np_train.groupby(['MSSubClass'])[cols].agg(pd.Series.mode).head(10)","4ecaeadf":"cols = [\"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"Electrical\", \"KitchenQual\", \"Functional\"] \n\n# a = []\n# for n in X.Neighborhood.unique():\n#     X[cols].mode().iloc[0]\n#     a.app\n# X[cols].mode().iloc[0]\np_train.groupby(['Neighborhood'])[cols].agg(pd.Series.mode).head(5)","ede69757":"# Train + Test features\nX_train = p_train.drop(\"SalePrice\", axis=1)\nX_test = p_test\nX = pd.concat([X_train, X_test])\n\n# Get labels (logarithmic due to distribution)\ny_train = np.log1p(p_train.loc[:,\"SalePrice\"])","86cb5b5d":"# No variance\nX = X.drop(['Utilities'], axis=1)","4f8d3aaf":"X['MasVnrType'].value_counts()","1ed20b17":"# Fill PoolQC where it should be\nmask = (X['PoolQC'].isna() & (X['PoolArea'] > 0))\nX.loc[mask, ['PoolQC', 'PoolArea', 'OverallQual']] # Filling 3 rows based on overall quality of the house (assuming by intuition)","403b4e62":"# Fill NaNs with modes for basement columns where basement data is partially missing\n# We don't fill for fully missing because that means no basement\ncols = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\ntemp = (X[cols].isna().sum(axis=1))\nmask = (temp > 0) & (temp < 5)\nX.loc[mask, cols] = X.loc[mask, cols].fillna(X.mode().iloc[0])\nX.mode()[cols]\nX.loc[mask, cols]","e202da65":"# Fill MasVnrType with non-na mode if MasVnrArea is not NaN (1 sample fixed)\nmask = X['MasVnrType'].isna() & X['MasVnrArea'].notna()\nmode = X.loc[X['MasVnrType'] != 'None','MasVnrType'].mode()[0]\nX.loc[mask, 'MasVnrType'] = X.loc[mask, 'MasVnrType'].fillna(mode)\nprint('Filled with ' + mode)","ea99c69e":"# Impute MSZoning values based on modes in each MSSubClass.\nX['MSZoning'] = X.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))","d94098df":"# Impute missing values\n\n# Categorical (big number of nans (79+))\n# NaNs here indicate lack of something (no pool, no basement, etc)\ncols = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageCond\", \"GarageQual\", \"GarageFinish\", \"GarageType\", \"BsmtCond\", \"BsmtExposure\", \"BsmtQual\", \"BsmtFinType2\", \"BsmtFinType1\", \"MasVnrType\"]\nX[cols] = X[cols].fillna(\"None\")\n\n# Impute using Neighborhoos mode (small numbers of NaNs)\ncols = [\"MSZoning\", \"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"Electrical\", \"KitchenQual\", \"Functional\"]\nX[cols] = X.groupby(\"Neighborhood\")[cols].transform(lambda x: x.fillna(x.mode()[0]))\n\n# Impute using Neighborhoods median\ncols = [\"GarageArea\", \"LotFrontage\"]\nX[cols] = X.groupby(\"Neighborhood\")[cols].transform(lambda x: x.fillna(x.median()))\n\n# Numerical\ncols = [\"GarageYrBlt\", \"MasVnrArea\", \"BsmtHalfBath\", \"BsmtFullBath\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"GarageCars\"]\nX[cols] = X[cols].fillna(0)","c1b686e7":"assert X.isna().sum().sum() == 0","7a125daf":"ordinalised_cols = []","dfd315ee":"fig, axs = plt.subplots(int(np.floor(np.sqrt(len(cols)))), int(np.ceil(np.sqrt(len(cols)))), figsize=(25,15))\ncols = [\n 'ExterQual',\n#  'ExterCond',\n#  'BsmtQual',\n 'BsmtCond',\n 'HeatingQC',\n 'KitchenQual',\n#  'FireplaceQu',\n 'GarageQual',\n 'GarageCond',\n 'PoolQC',\n]\n\norder = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\nfor col, ax in zip(cols, np.hstack(axs)):\n    print(col, X[col].unique() ,np.unique(pd.Categorical(X[col], categories=order, ordered=True).codes))\n#     print(X[col].value_counts())\n    X[col+'_int'] = pd.Categorical(X[col], categories=order, ordered=True).codes\n    ordinalised_cols.append(col)\n    print(list(X[col].value_counts()))\n    sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], inner=None, ax=ax)\n#     sns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None'] + order, ax=ax)\n#     sns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None'] + order, ax=ax)\n#     sns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None'] + order, ax=ax)\n","ccb8abaa":"# Looks good\ncol = 'LotShape'\norder=['Reg', 'IR1', 'IR2', 'IR3']\nprint(X[col].value_counts())\nX[col + '_int'] = pd.Categorical(X[col], categories=order, ordered=True).codes\nordinalised_cols.append(col)\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), hue=X[col], order=order)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=order)\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=order)\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=order)","b7bbd8be":"# Does not look that informative\ncol = 'LandSlope'\nX[col + '_int'] = pd.Categorical(X[col], categories=['Gtl', 'Mod', 'Sev'], ordered=True).codes\nordinalised_cols.append(col)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Gtl', 'Mod', 'Sev'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Gtl', 'Mod', 'Sev'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Gtl', 'Mod', 'Sev'])","a6334b06":"# Looks good\n# col = 'GarageFinish'\n# X[col + '_int'] = pd.Categorical(X[col], categories=['Unf', 'RFn', 'Fin'], ordered=True).codes\n# ordinalised_cols.append(col)\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'Unf', 'RFn', 'Fin'])","a141debc":"# Looks good. -1 seems a much lower than others though\ncol = 'BsmtExposure'\nX[col + '_int'] = pd.Categorical(X[col], categories=['No', 'Mn', 'Av', 'Gd'], ordered=True).codes\nordinalised_cols.append(col)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'No', 'Mn', 'Av', 'Gd'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'No', 'Mn', 'Av', 'Gd'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'No', 'Mn', 'Av', 'Gd'])\n","93b1091c":"X[['BsmtExposure', 'BsmtExposure_int']].sample(11)","40596d4f":"# Looks all over place\ncol = 'Functional'\nX[col + '_int'] = pd.Categorical(X[col], categories=['Min2', 'Min1', 'Typ'], ordered=True).codes # ???\nprint(X[col].value_counts())\nX[col + '_int'] = pd.Categorical(X[col], categories=['Typ','Min1','Min2','Maj1','Maj2','Mod', 'Sev'], ordered=True).codes # ???\nX[col].unique().tolist(), X[col + '_int'].unique().tolist()\n# ordinalised_cols.append(col)\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Typ','Min1','Min2','Maj1','Maj2','Mod', 'Sev'])\n# sns.violinplot(x=col+'_int', y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1))\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Typ','Min1','Min2','Maj1','Maj2','Mod', 'Sev'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Typ','Min1','Min2','Maj1','Maj2','Mod', 'Sev'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Typ','Min1','Min2','Maj1','Maj2','Mod', 'Sev'])","f1106c2c":"# # Shit according to FI (looks all over place)\ncol = 'HouseStyle'\nX[col + '_int'] = pd.Categorical(X[col], categories=['2.5Fin','2Story','1Story','SLvl','2.5Unf','1.5Fin', 'SFoyer', '1.5Unf'], ordered=True).codes # ???\nX['HouseStyle_1st'] = 1*(X['HouseStyle'] == '1Story')\nX['HouseStyle_2st'] = 1*(X['HouseStyle'] == '2Story')\nX['HouseStyle_15st'] = 1*(X['HouseStyle'] == '1.5Fin')\nordinalised_cols.append(col)\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['2.5Fin','2Story','1Story','SLvl','2.5Unf','1.5Fin', 'SFoyer', '1.5Unf'])\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['2.5Fin','2Story','1Story','SLvl','2.5Unf','1.5Fin', 'SFoyer', '1.5Unf'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['2.5Fin','2Story','1Story','SLvl','2.5Unf','1.5Fin', 'SFoyer', '1.5Unf'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['2.5Fin','2Story','1Story','SLvl','2.5Unf','1.5Fin', 'SFoyer', '1.5Unf'])","d2049446":"col = 'Foundation'\nX[col + '_int'] = pd.Categorical(X[col], categories=['PConc', 'CBlock', 'BrkTil'], ordered=True).codes # to int\nX[col + '_int'] = X[col + '_int'].replace(-1, X['Foundation_int'].max() + 1) # What's not defined before is highest\nX[col].unique(), X[col + '_int'].unique()\nordinalised_cols.append(col)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=[\"PConc\", 'Wood',  \"CBlock\",'Stone', 'BrkTil', 'Slab'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=[\"PConc\", 'Wood',  \"CBlock\",'Stone', 'BrkTil', 'Slab'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=[\"PConc\", 'Wood',  \"CBlock\",'Stone', 'BrkTil', 'Slab'])\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=[\"PConc\", 'Wood',  \"CBlock\",'Stone', 'BrkTil', 'Slab'])","d9a8ed27":"# Masonry\n# Looks ordinal if we combine BrkCmn and None into one (since they have the same distributions)\ncol = 'MasVnrType'\nX[col + '_int'] = pd.Categorical(X[col].replace('BrkCmn', 'BrkCmn\/None').replace('None','BrkCmn\/None'),\n                                 categories=['BrkCmn\/None', 'BrkFace', 'Stone'], ordered=True).codes # 'Stone', 'BrkFace',  'BrkCmn', 'None'\nordinalised_cols.append(col)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'BrkCmn', 'BrkFace',  'Stone'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'BrkCmn', 'BrkFace',  'Stone'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'BrkCmn', 'BrkFace',  'Stone'])\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'BrkCmn', 'BrkFace',  'Stone'])","c7223be0":"# col = 'BsmtFinType1'\n# X[col + '_int'] = pd.Categorical(X[col], categories=['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'], ordered=True).codes\n# X[col + '_int'] = X[col + '_int'].replace(-1, X[col + '_int'].max() + 1) # What's not defined before is highest\n# X[col + '_Unf'] = 1*(X[col] == 'Unf')\n# ordinalised_cols.append(col)\n# X[col].unique(), X[col + '_int'].unique()\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'])","e3a08808":"# col = 'BsmtFinType2'\n# cats = ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']\n# X[col + '_int'] = pd.Categorical(X[col], categories=cats, ordered=True).codes\n# X[col + '_int'] = X[col + '_int'].replace(-1, X[col + '_int'].max() + 1) # What's not defined before is highest\n# X[col + '_Unf'] = 1*(X[col] == 'Unf')\n# ordinalised_cols.append(col)\n# X[col].unique(), X[col + '_int'].unique()\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=cats)","a6fb0026":"# Looks good\ncol = 'PavedDrive'\nX[col + '_int'] = pd.Categorical(X[col], categories=['N', 'P', 'Y'], ordered=True).codes\nordinalised_cols.append(col)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['N', 'P', 'Y'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['N', 'P', 'Y'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['N', 'P', 'Y'])\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['N', 'P', 'Y'])","9d15ea51":"# # Looks good\n# col = 'CentralAir'\n# X[col + '_int'] = pd.Categorical(X[col], categories=['N', 'Y'], ordered=True).codes\n# ordinalised_cols.append(col)\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['N', 'Y'])","986c70ec":"# Looks good\ncol = 'Street'\nX[col + '_int'] = pd.Categorical(X[col], categories=['Grvl', 'Pave'], ordered=True).codes\nordinalised_cols.append(col)\nsns.boxplot(x=col, y=\"SalePrice\",  color=\"1\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Grvl', 'Pave'])\nsns.stripplot(x=col, y=\"SalePrice\", size=1.5, color=\"red\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Grvl', 'Pave'])\nsns.pointplot(x=col, y=\"SalePrice\", color=\"0\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Grvl', 'Pave'])\n# sns.violinplot(x=col, y=\"SalePrice\", data=pd.concat([X.loc[p_train.index], y_train], axis=1), order=['Grvl', 'Pave'])","be0faa64":"# X['HasWoodDeck'] = (X['WoodDeckSF'] > 0) * 1\n# X['HasOpenPorch'] = (X['OpenPorchSF'] > 0) * 1\n# X['HasEnclosedPorch'] = (X['EnclosedPorch'] > 0) * 1\n# X['Has3SsnPorch'] = (X['3SsnPorch'] > 0) * 1\n# X['HasScreenPorch'] = (X['ScreenPorch'] > 0) * 1\nX['YearsSinceRemod'] = X['YrSold'].astype(int) - X['YearRemodAdd'].astype(int)\n# X['OverallQualCond'] = X['OverallQual'] + X['OverallCond']","caff6918":"# Total square footage (total, porch, bath) FE\nX[\"TotalSF\"] = X[\"GrLivArea\"] + X[\"TotalBsmtSF\"] # Total square footage\nX[\"TotalPorchSF\"] = X[\"OpenPorchSF\"] + X[\"EnclosedPorch\"] + X[\"3SsnPorch\"] + X[\"ScreenPorch\"] # Total porch square footage\nX[\"TotalBath\"] = X[\"FullBath\"] + X[\"BsmtFullBath\"] + 0.5 * (X[\"BsmtHalfBath\"] + X[\"HalfBath\"]) # Total baths","51d6e95d":"# Categorise categorial variables\n# YrSold is also categorical to provide flexibility (esp. due to 2008 financial crisis)\ncols = [\"MSSubClass\", \"YrSold\"]\nX[cols] = X[cols].astype(\"category\")","2f2ccaa3":"# Reprsent months as x,y coordinates on a circle to capture the seasonality better\n# http:\/\/blog.davidkaleko.com\/feature-engineering-cyclical-features.html\nif 'MoSold' in X:\n    X[\"SinMoSold\"] = np.sin(2 * np.pi * X[\"MoSold\"] \/ 12)\n    X[\"CosMoSold\"] = np.cos(2 * np.pi * X[\"MoSold\"] \/ 12)\n    X = X.drop(\"MoSold\", axis=1)","564e713a":"# del X['BsmtFinType1'] # Much worse than new features\n# del X['LandSlope'] # Much worse than new feature","11b71f5b":"# import matplotlib.pyplot as plt\n\n# plt.matshow(X_train.corr())\n# plt.show()","bedcbf38":"# # Add logs (areas, baths, cars, fireplaces, years)\n# cols = [\n#     'LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n#      'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n#      'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n#      'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n#      'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','YearRemodAdd','TotalSF'\n# ]\n\n# for col in cols:\n#     X[col+'_log'] = np.log1p(X[col])\n","6643c2d0":"# # Add squares\n# cols = [\n#     'YearRemodAdd', 'LotFrontage_log', \n#     'TotalBsmtSF_log', '1stFlrSF_log', '2ndFlrSF_log', 'GrLivArea_log',\n#     'GarageCars_log', 'GarageArea_log',\n#     'OverallQual','ExterQual_int','BsmtQual_int','GarageQual_int','FireplaceQu_int','KitchenQual_int'\n# ]\n\n# for col in cols:\n#     X[col+'_sq'] = np.square(X[col])","4c4a0aaf":"# Numerical cols\ncols = list(X_train.select_dtypes('number').columns)\nfig, axs = plt.subplots(int(np.sqrt(len(cols))), int(np.sqrt(len(cols))), figsize=(30, 30))\nfor col, ax in zip(cols, axs.ravel()):\n    sns.regplot(x=X_train[col], y=y_train, ax=ax);","ea712058":"# Making sure no NaNs left after FE\ntemp = X.isna().sum()\nassert temp.sum() == 0, temp[temp > 0]","3ca0868e":"# Drop original cols that got ordinalised\nprint(X.shape)\nprint(f\"Dropping {len(ordinalised_cols)} ordinalised cols: {ordinalised_cols}\")\nX = X.drop(ordinalised_cols, axis=1)\nprint(X.shape)","afab93af":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr=X.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nplt.figure(figsize = (20,15))\nsns.heatmap(corr, mask=mask,  center=0, linewidths=.01, annot=False, cmap='PiYG')","cb3fb804":"sns.pairplot(pd.concat([X.loc[p_train.index], y_train], axis=1), y_vars='SalePrice', x_vars=sorted(list(X.columns.values)), markers=\".\", height=3)","5425c7d5":"skew = X.drop([], axis=1).skew(numeric_only=True).abs()\ncols = skew[skew > .5].index\nfig, axs = plt.subplots(int(np.sqrt(len(cols))), int(np.sqrt(len(cols))), figsize=(30, 30))\nfor col, ax in zip(cols, axs.ravel()):\n    sns.distplot(X[col], ax=ax)\n# X[cols[0]].distplot()","b45eab45":"# Transform highly skewed features using boxcox1p and boxcox_normmax, and scale features using RobustScaler.\n# Only transform real numeric (not ordinal converted)\n# skew = X.drop([col for col in X.columns if '_int' in col], axis=1).skew(numeric_only=True).abs()\n# skew = X.drop([col for col in X.columns if ('_int' in col) or ('_sq' in col) or ('_log' in col)], axis=1).skew(numeric_only=True).abs()\n# skew = X.drop([col for col in X.columns if ('_sq' in col) or ('_log' in col)], axis=1).skew(numeric_only=True).abs()\nskew = X.drop([], axis=1).skew(numeric_only=True).abs()\ncols = skew[skew > .5].index\nprint(skew[skew > .5].sort_values(ascending=False))\nfor col in cols:\n    if X[col].min() > 0: # Error is thrown when negative values exist\n        X[col] = boxcox1p(X[col], boxcox_normmax(X[col] + 1))","f32ce77e":"fig, axs = plt.subplots(int(np.sqrt(len(cols))), int(np.sqrt(len(cols))), figsize=(30, 30))\nfor col, ax in zip(cols, axs.ravel()):\n    sns.distplot(X[col], ax=ax)","2c7588f8":"cols = X.select_dtypes(np.number).columns\nX[cols] = RobustScaler().fit_transform(X[cols])","55132c62":"fig, axs = plt.subplots(int(np.sqrt(len(cols))), int(np.sqrt(len(cols))), figsize=(30, 30))\nfor col, ax in zip(cols, axs.ravel()):\n    sns.distplot(X[col], ax=ax)","61c6d599":"# Convert all categorical variables into dummy variables.\nX = pd.get_dummies(X)","43b90533":"# temp = X[X.select_dtypes('object').columns].nunique() # TODO High cardinalities to binary\n# temp[temp > 5]\n# for k, v in temp[temp > 5].iteritems():\n#     print(k, ':', X[k].unique())","4cb4a310":"# Recover train\/test features\nX_train = X.loc[p_train.index]\nX_test = X.loc[p_test.index]","ea2375c4":"# To remove outliers, we fit a linear model to the training data and remove examples with a studentized residual greater than 3.\nresiduals = y_train - LinearRegression().fit(X_train, y_train).predict(X_train)\noutliers = residuals[np.abs(zscore(residuals)) > 3].index\n\nprint(f'Removed {len(outliers)} outliers')\nX_train = X_train.drop(outliers)\ny_train = y_train.drop(outliers)","deeb31f1":"# Set up CV strategy (5-folds, RMSE)\nkf = KFold(n_splits=5, random_state=0, shuffle=True)\nrmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\nscorer = make_scorer(rmse, greater_is_better=False)","84a2a696":"gbm = XGBRegressor(n_estimators=2000, max_depth=4, learning_rate=0.01)","1c6c0538":"gbm = GradientBoostingRegressor(n_estimators=2000, max_depth=4, learning_rate=0.01)","443f1696":"gbm.fit(X_train, y_train)","b2d1edb8":"[c for c in X_train.columns]","8a3ddfd4":"# Get feature importances\nfeature_importances = gbm.feature_importances_\nfeature_importances = 100.0 * (feature_importances \/ feature_importances.max())\nfi = pd.DataFrame({'col': X_train.columns, 'val': feature_importances})\n\n# Combine categorical's into one\nfi['col_og'], fi['col_suffix'] = fi['col'].str.split('_', 1).str\nfi['col_agg'] = np.where((fi['col_suffix']!='int') & (fi['col_suffix']!='sq') & (fi['col_suffix']!='log'),fi['col_og'], fi['col'])\nfi_agg = fi.groupby('col_agg').sum().reset_index().sort_values('val', ascending=False).reset_index(drop=True)\n\n# Plot log1p for easier viewing\nfi_agg['log_val'] = np.log1p(fi_agg['val'])\nfi_agg.plot(kind='barh', figsize=(20,30), x='col_agg', y='log_val')","06ec8e8e":"# Define hyperparam optimisation using random search\ndef random_search(model, grid, n_iter=100):\n    n_jobs = max(cpu_count() - 2, 1)\n    search = RandomizedSearchCV(model, grid, n_iter, scorer, n_jobs=n_jobs, cv=kf, random_state=0, verbose=True)\n    return search.fit(X_train, y_train)","957f5dd2":"# Optimise various models (Ridge, Lasso, SVR, LGBM, GBM)\nprint('Ridge')\nridge_search = random_search(Ridge(), {\"alpha\": np.logspace(-1, 2, 500)})\nprint('Lasso')\nlasso_search = random_search(Lasso(), {\"alpha\": np.logspace(-5, -1, 500)})\n# print('GAM')\n# gam = LinearGAM().gridsearch()\n# print('Support Vector Machines')\n# svr_search = random_search(SVR(), {\"C\": np.arange(1, 100), \"gamma\": np.linspace(0.00001, 0.001, 50), \"epsilon\": np.linspace(0.01, 0.1, 50)})\n# print('LGBM')\n# lgbm_search = random_search(LGBMRegressor(n_estimators=4000, max_depth=4), {\"colsample_bytree\": np.linspace(0.2, 0.7, 6), \"learning_rate\": np.logspace(-3, -1, 100)})\n# print('GBM')\n# gbm_search = random_search(GradientBoostingRegressor(n_estimators=4000, max_depth=4), {\"max_features\": np.linspace(0.2, 0.7, 6), \"learning_rate\": np.logspace(-3, -1, 100)})\n# print('XGB')\n# xgb_search = random_search(XGBRegressor(n_estimators=4000, max_depth=4), {\"max_features\": np.linspace(0.2, 0.7, 6), \"learning_rate\": np.logspace(-3, -1, 100)})","21a1cf37":"grid_searches = [\n    ridge_search,\n    lasso_search,\n#     svr_search,\n#     lgbm_search,\n#     gbm_search,\n#     xgb_search,\n]\n\n# Get the best models\nmodels = [search.best_estimator_ for search in grid_searches]","5eff9158":"# Optimise stacked ensemble of the best models\nstack_search = random_search(StackingCVRegressor(models, Ridge(), cv=kf), {\"meta_regressor__alpha\": np.logspace(-3, -2, 500)}, n_iter=20)\nmodels.append(stack_search.best_estimator_)","20f18447":"preds = [model.predict(X_test) for model in models]","b8b915c5":"# Average all models (10% weight each) + ensemble (50% weight)\n# preds = np.average(preds, axis=0, weights=[0.05] * 4 + [0.8] * 1)\npreds = np.average(preds, axis=0, weights=[0.2] * 2 + [0.6] * 1)\n# preds = np.average(preds, axis=0, weights=[0.1] * 5 + [0.5] * 1)\n# preds = np.average(preds, axis=0, weights=[0.1] * 4 + [0.6] * 1)\n# preds = np.average(preds, axis=0, weights=[0.1] * 2 + [0.2] * 2 + [0.4] * 1)","23d6ccbe":"sns.distplot(np.log1p(p_train['SalePrice']))","78d1f880":"# # Create submission\nsubmission = pd.DataFrame({\"Id\": p_sample[\"Id\"], \"SalePrice\": np.exp(preds)})\n\n# # Copied from other notebooks sort out low and high value predictions\n# q1 = submission['SalePrice'].quantile(0.0042)\n# q2 = submission['SalePrice'].quantile(0.99)\n# # Quantiles helping us get some extreme values for extremely low or high values \n# submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n# submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n\nsubmission.to_csv(\"submission.csv\", index=False)","f722d6c6":"# Print out best hyperparams for each model\nfor search in grid_searches:\n    print(search.best_estimator_)\n    print(search.best_params_)\n    print(search.best_score_)\n    print('-'*20)","0fdaad2d":"### Discard useless columns","27c3064b":"### Preprocessing (After FE)","0a870b54":"### Feature importances","b5aa3e37":"#### Other FE","af07a034":"### Fill NA","f2ba4ace":"> ### Final\nGridSearch","159e2b55":"### Categorical to Ordinal convertion"}}