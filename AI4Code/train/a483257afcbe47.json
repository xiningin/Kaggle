{"cell_type":{"8eb4c795":"code","2779bed6":"code","7e1ad40e":"code","a9e04eb4":"code","cc1fd8f2":"code","98b3dd3a":"code","c13db093":"markdown"},"source":{"8eb4c795":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport gc\ngc.enable()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2779bed6":"df = pd.read_csv('..\/input\/gstore-data-cleaning\/starting_point.csv', \n                 parse_dates=['date'],\n                 dtype={'fullVisitorId':'str'},\n                 infer_datetime_format=True)\ndf.loc[(df.is_train == 1) & (df.totals_transactionRevenue.isnull()), 'totals_transactionRevenue'] = 0","7e1ad40e":"random_seed = 42\ndef rmse(actual, preds):\n    return mean_squared_error(actual, preds) ** (.5)\ndef generate_user_level_features(df):\n    agg_dict = {'totals_hits':['sum'],\n                'totals_pageviews':['sum'],\n                'totals_transactionRevenue':lambda x: np.log1p(x.sum())}\n    df_agg = df.groupby(['is_train', 'fullVisitorId']).agg(agg_dict)\n    df_agg.columns = ['totals_hits', 'totals_pageviews', 'target']\n    df_agg.reset_index('is_train', inplace=True)\n        \n    return df_agg[df_agg.is_train == 1].drop('is_train', axis=1), df_agg[df_agg.is_train == 0].drop(['is_train', 'target'], axis=1)\n\ndef generate_visit_level_features(df):\n    df['target'] = np.log1p(df['totals_transactionRevenue'])\n    return df.set_index('fullVisitorId').loc[lambda x: x.is_train == 1, ['totals_hits', 'totals_pageviews', 'target']], df.set_index('fullVisitorId').loc[lambda x: x.is_train == 0, ['totals_hits', 'totals_pageviews']]\n\n\ndef kfold_crossval(df, target, stratified=True, nfolds=4):\n    if stratified:\n        kf = StratifiedKFold(nfolds, random_state=random_seed)\n    else:\n        kf = KFold(nfolds, random_state=random_seed)\n    stratified_target = [1 if x >0 else 0 for x in target.values]\n    return kf.split(df.values, stratified_target)\n\ndef agg_user_level(df, preds, targets=None):\n    if targets is not None:\n        df['target'] = targets\n    df['PredictedLogRevenue'] = preds\n    return df\n\ndef agg_visit_level(df, preds, targets=None):\n    if targets is not None:\n        df['target'] = np.expm1(targets)\n        cols = ['target', 'PredictedLogRevenue']\n    else:\n        cols = ['PredictedLogRevenue']\n    df['PredictedLogRevenue'] = np.expm1(preds)\n    df_tmp = df[cols].reset_index().groupby('fullVisitorId').sum().apply(lambda x: np.log1p(x))\n    return df_tmp\n    \ndef lgbm_predict(train_x, train_y, valid_x, valid_y, test_x):\n    lgbm_params = {\"objective\" : \"regression\", \"metric\" : \"rmse\", \n                   \"max_depth\": 8, \"min_child_samples\": 20, \"reg_alpha\": 0.2, \"reg_lambda\": 0.2,\n                   \"num_leaves\" : 257, \"learning_rate\" : 0.1, \"subsample\" : 0.9, \"colsample_bytree\" : 0.9, \n                   \"subsample_freq \": 5, 'n_estimators':5000, 'random_state':random_seed}\n    \n    clf = LGBMRegressor(**lgbm_params)\n    \n    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n            eval_metric= 'rmse', verbose= 500, early_stopping_rounds= 100)\n    \n    fold_importance_df_lgb = pd.DataFrame()\n    fold_importance_df_lgb[\"feature\"] = train_x.columns\n    fold_importance_df_lgb[\"importance\"] = clf.feature_importances_\n    \n    val_preds = clf.predict(valid_x, num_iteration=clf.best_iteration_)\n    \n    test_preds = clf.predict(test_x, num_iteration=clf.best_iteration_)\n    \n    return np.clip(val_preds, 0, None), np.clip(test_preds, 0, None), fold_importance_df_lgb\n    ","a9e04eb4":"def cv_predict(df, feature_generator, validation_generator, aggregator, predictor):\n    train_df, test_df = feature_generator(df)\n    \n    split_idx = validation_generator(train_df.drop('target', axis=1), train_df['target'])\n    \n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    hold = []\n    feature_imp = []\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(split_idx):\n        train_x, train_y = train_df.drop('target', axis=1).iloc[train_idx], train_df['target'].iloc[train_idx]\n        valid_x, valid_y = train_df.drop('target', axis=1).iloc[valid_idx], train_df['target'].iloc[valid_idx]\n        \n        valid_preds, test_preds, fold_importance_df_lgb = predictor(train_x, train_y, valid_x, valid_y, test_df)\n        \n        sub_preds += test_preds\n        \n        agg_valid_x = aggregator(valid_x, valid_preds, valid_y)\n        \n        print('Fold {} : {}'.format(n_fold, rmse(agg_valid_x['target'].values, agg_valid_x['PredictedLogRevenue'].values)))\n        \n        fold_importance_df_lgb[\"fold\"] = n_fold\n        \n        hold.append(agg_valid_x)\n        feature_imp.append(fold_importance_df_lgb)\n    oof_df = pd.concat(hold)\n    df_feature_imp = pd.concat(feature_imp)\n    print('Full : {}'.format(rmse(oof_df['target'].values, oof_df['PredictedLogRevenue'].values)))\n    \n    sub_preds  = sub_preds\/(n_fold + 1)\n    \n    agg_test_X = aggregator(test_df, sub_preds)\n    \n    cols = df_feature_imp[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:50].index\n    best_features_lgb = df_feature_imp.loc[df_feature_imp.feature.isin(cols)]\n    plt.figure(figsize=(14,10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features_lgb.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances.png')\n        \n    return agg_test_X, oof_df , feature_imp   \n        \n        \n    \n    ","cc1fd8f2":"# #### visit level predicitons\n# final_df, oof_df, feature_imp = cv_predict(df, generate_visit_level_features, kfold_crossval, agg_visit_level, lgbm_predict)\n\n# final_df[['PredictedLogRevenue']].to_csv('lgbm_visit_preds.csv')\n\n# oof_df[['target', 'PredictedLogRevenue']].to_csv('oof_lgbm_visit_preds.csv')","98b3dd3a":"#### user level preds\nfinal_df, oof_df, feature_imp = cv_predict(df, generate_user_level_features, kfold_crossval, agg_user_level, lgbm_predict)\n\nfinal_df[['PredictedLogRevenue']].to_csv('lgbm_user_preds.csv')\n\noof_df[['target', 'PredictedLogRevenue']].to_csv('oof_lgbm_user_preds.csv')","c13db093":"### Feature Generation Functions"}}