{"cell_type":{"7db93c21":"code","f7c2114a":"code","e2ab0cb2":"code","acf4b10d":"code","b7ebfdc7":"code","79cbe4ec":"code","55da8c4c":"code","1d4c0c72":"code","a2da7e78":"code","2d220ee9":"code","4f71d68b":"code","141dc464":"code","a049b99e":"code","ebccd4d6":"code","82f8ed07":"code","823f05f5":"code","fb23d685":"code","425a1554":"code","2c07186d":"code","153a9215":"code","f3edea8d":"code","71dbc737":"code","ba02fd24":"code","3863a092":"markdown","5fad64eb":"markdown","564a285a":"markdown","9849e94d":"markdown","33acdf02":"markdown","2acf01be":"markdown","fe069d89":"markdown","2a29681e":"markdown","ce99242c":"markdown","59327813":"markdown","c3d70872":"markdown","81bce555":"markdown","5dcfd079":"markdown"},"source":{"7db93c21":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","f7c2114a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e2ab0cb2":"BASE = \"\/kaggle\/input\/nlp-getting-started\/\"\ntrain = pd.read_csv(BASE + \"train.csv\")\ntest = pd.read_csv(BASE + \"test.csv\")\nsub = pd.read_csv(BASE + \"sample_submission.csv\")","acf4b10d":"tweets = train[['text', 'target']]\ntweets.head()","b7ebfdc7":"tweets.target.value_counts()","79cbe4ec":"tweets.shape","55da8c4c":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","1d4c0c72":"def remove_punctuation(text):\n    '''a function for removing punctuation'''\n    import string\n    # replacing the punctuations with no space, \n    # which in effect deletes the punctuation marks \n    translator = str.maketrans('', '', string.punctuation)\n    # return the text stripped of punctuation marks\n    return text.translate(translator)","a2da7e78":"tweets['text'] = tweets['text'].apply(remove_punctuation)\ntweets.head(10)","2d220ee9":"# extracting the stopwords from nltk library\nsw = stopwords.words('english')\n# displaying the stopwords\nnp.array(sw);","4f71d68b":"def stopwords(text):\n    '''a function for removing the stopword'''\n    # removing the stop words and lowercasing the selected words\n    text = [word.lower() for word in word_tokenize(text) if word.lower() not in sw]\n    # joining the list of words with space separator\n    return \" \".join(text)","141dc464":"tweets['text'] = tweets['text'].apply(stopwords)\ntweets.head(10)","a049b99e":"# create an object of stemming function\nstemmer = PorterStemmer()\n\ndef stemming(text):    \n    '''a function which stems each word in the given text'''\n    text = [stemmer.stem(word) for word in word_tokenize(text)]\n    return \" \".join(text) ","ebccd4d6":"tweets['text'] = tweets['text'].apply(stemming)\ntweets.head(10)","82f8ed07":"vectorizer = CountVectorizer(analyzer='word', binary=True, stop_words='english')\nvectorizer.fit(tweets['text'])","823f05f5":"X = vectorizer.transform(tweets['text']).todense()\ny = tweets['target'].values\nX.shape, y.shape","fb23d685":"from sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import f1_score","425a1554":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)","2c07186d":"model = LogisticRegression(C=1.0, random_state=111)\nmodel.fit(X_train, y_train)","153a9215":"y_pred = model.predict(X_test)\n\nf1score = f1_score(y_test, y_pred)\nprint(f\"Model Score: {f1score * 100:.2f} %\")","f3edea8d":"tweets_test = test['text']\ntest_X = vectorizer.transform(tweets_test).todense()\ntest_X.shape","71dbc737":"lr_pred = model.predict(test_X)","ba02fd24":"sub['target'] = lr_pred\nsub.to_csv(\"submission.csv\", index=False)\nsub.head()","3863a092":"# 2. Data preparation","5fad64eb":"# 5. Prediction and Submition","564a285a":"<h3>Thanks For Being Here. <span style='color:red'>UPVOTE<\/span> If Interested .. Feel Free In Comments<\/h3>","9849e94d":"# 4. Evaluate the model","33acdf02":"# 4. Machine learning","2acf01be":"<center><h2 style='color:red'>NLP: The Simplest Way<br><span>By Kassem@elcaiseri<\/span><\/h2><\/center>\n<h3>NLP with Disaster Tweets (NLTK + Sklearn)<\/h3>\n* **1. Introduction**\n* **2. Data Preparation**\n* **3. Text Processing**\n* **4. Machine learning**\n* **5. Evaluate the model**\n* **5. Prediction and Submition**\n* **6. References**\n<hr>\n\n* Update: using **word_tokenize()** rather than **text.split()**","fe069d89":"# 3. Text Processing\n","2a29681e":"## Remove Stopwords","ce99242c":"## Remove Punctuation","59327813":"As you can see score imporved from 75% in last version to 77% with simple preprocessing change.","c3d70872":"# 6. References\n* https:\/\/www.kaggle.com\/elcaiseri\/toxicity-bias-logistic-regression-tfidfvectorizer\n* http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html\n* https:\/\/www.kaggle.com\/itratrahman\/nlp-tutorial-using-python\/notebook","81bce555":"# 1. Introduction\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they\u2019re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).<br>\n**Goal** .. Predict which Tweets are about real disasters and which ones are not","5dcfd079":"## Stemming operations\nStemming operation bundles together words of same root. E.g. stem operation bundles \"response\" and \"respond\" into a common \"respon"}}