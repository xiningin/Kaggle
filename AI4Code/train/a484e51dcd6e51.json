{"cell_type":{"3b1e9f6e":"code","a52ba953":"code","419f02fa":"code","636da624":"code","cc3cca2b":"code","f4f5aa1c":"code","24acb90c":"code","2e5ed395":"code","3ded9a48":"code","5f51f4d2":"code","dd085ae2":"code","6e6743a3":"code","6ad0e6c5":"code","82fbdd59":"code","d7c2d457":"code","00a7b0ca":"code","8eec63ca":"code","12f42dec":"code","df953da9":"code","f2d83642":"code","86cb3f8c":"code","c80f276d":"code","0002ab7c":"code","86763ec5":"code","f2ce975d":"code","79873833":"code","9a5781d0":"code","572d15cf":"code","68abfff9":"code","3b9f27f5":"code","5f11f299":"code","52a2c16b":"code","66e8019e":"code","d2db6a48":"code","7a6b34d5":"markdown","2c3ef2f7":"markdown","fd0b197f":"markdown","e08b69c3":"markdown","41ca1406":"markdown","b6de6d03":"markdown"},"source":{"3b1e9f6e":"#Import Necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error, mean_squared_log_error","a52ba953":"#Load and Check Data\ntrain_data = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest_data = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","419f02fa":"print('Train Shape: ', train_data.shape)\nprint('Test Shape: ', test_data.shape)","636da624":"train_data.sample(5)","cc3cca2b":"X = train_data.iloc[:, 0:9]\nY = train_data['count']\n\nprint('Train X Shape: ', X.shape)\nprint('Train Y Shape: ', Y.shape)\nprint('Test Shape: ', test_data.shape)","f4f5aa1c":"#check the missing values\ntrain_data.isna().sum(axis=0)","24acb90c":"sns.displot(Y, kde=True)","2e5ed395":"sns.displot(np.log(Y), kde=True)","3ded9a48":"sns.histplot(X.season, bins=4)","5f51f4d2":"sns.displot(X.temp, kde=True)","dd085ae2":"sns.displot(X.atemp, kde=True)","6e6743a3":"sns.displot(X.windspeed, kde=True)","6ad0e6c5":"sns.displot(X.humidity, kde=True)","82fbdd59":"from sklearn.base import BaseEstimator, TransformerMixin\nimport calendar\nfrom datetime import datetime\n\nclass ProcessDateTime(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Transforming datetime...')\n        \n        x_copy = X.copy()\n        x_copy['month'] = x_copy.datetime.apply(lambda x : calendar.month_name[datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").weekday()])\n        x_copy['weekday'] = x_copy.datetime.apply(lambda x : calendar.day_name[datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").weekday()])\n        x_copy['hour'] = x_copy.datetime.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").hour)\n        x_copy['minute'] = x_copy.datetime.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").minute)\n        x_copy = x_copy.drop(['datetime'], axis=1)\n        \n        return x_copy","d7c2d457":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime())\n])\n\npipeline.fit_transform(X)","00a7b0ca":"class ProcessSeasonWeather(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Transforming season and weather...')\n        x_copy = X.copy()\n        x_copy['season'] = x_copy['season'].map({\n            1: 'Spring',\n            2: 'Summer',\n            3: 'Fall',\n            4: 'Winter'\n        })\n        x_copy['weather'] = x_copy['weather'].map({\n            1: \"Clear+FewClouds+PartlyCloudy,PartlyCloudy\",\n            2: \"Mist+Cloudy,Mist+BrokenClouds,Mist+FewClouds,Mist\",\n            3: \"LightSnow,LightRain+Thunderstorm+ScatteredClouds,LightRain+ScatteredClouds\",\n            4: \"HeavyRain+IcePallets+Thunderstorm+Mist,Snow+Fog\" \n        })\n        return x_copy","8eec63ca":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather())\n])","12f42dec":"pipeline.fit_transform(X)","df953da9":"class DummyEncoding(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Dummy encoding...')\n        x_copy = X.copy()\n        x_copy = pd.get_dummies(x_copy)\n        return x_copy\n\n    \nclass RemoveFeature(BaseEstimator, TransformerMixin):\n    def __init__(self, features=[]):\n        self._features = features\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Removing features...')\n        x_copy = X.copy()\n        for f in self._features:\n            if f in x_copy.columns:\n                x_copy = x_copy.drop([f], axis=1)\n        return x_copy","f2d83642":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(features=['windspeed']))\n])","86cb3f8c":"pipeline.fit_transform(X)","c80f276d":"from sklearn.preprocessing import StandardScaler","0002ab7c":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(features=['windspeed'])),\n    ('scaler', StandardScaler())\n])","86763ec5":"pipeline.fit_transform(X)","f2ce975d":"#Why we did not fit test data like we did form train data?\npipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(['windspeed'])),\n    ('scaler', MinMaxScaler())\n])\n\npipeline.fit(X)\nX = pipeline.transform(X)\nX_test = pipeline.transform(test_data)","79873833":"print(X.shape)\nprint(X_test.shape)","9a5781d0":"pd.DataFrame(X)","572d15cf":"lr = LinearRegression()\nsgd = SGDRegressor()\nrr = Ridge()\nls = Lasso()\nen = ElasticNet()","68abfff9":"import sklearn","3b9f27f5":"sklearn.metrics.SCORERS.keys()","5f11f299":"cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=27)\n\ngrid_ridge_lasso = {\n    'alpha': np.arange(0, 1, 0.05)\n}\n\ngrid_elastic = {\n    'alpha': np.arange(0, 1, 0.05),\n    'l1_ratio': np.arange(0, 1, 0.05)\n}\n\nlr_score = cross_val_score(lr, X, np.log(Y+0.0001), cv=cv, scoring='neg_mean_squared_log_error')\nsgd_score = cross_val_score(sgd, X, np.log(Y+0.0001), cv=cv, scoring='neg_mean_squared_log_error')\n\nrr_search = GridSearchCV(rr, grid_ridge_lasso, cv=cv, scoring='neg_mean_squared_log_error')\nrr_score = rr_search.fit(X, np.log(Y+0.0001))\n\nls_search = GridSearchCV(ls, grid_ridge_lasso, cv=cv, scoring='neg_mean_squared_log_error')\nls_score = ls_search.fit(X, np.log(Y+0.0001))\n\nen_search = GridSearchCV(en, grid_elastic, cv=cv, scoring='neg_mean_squared_log_error')\nen_score = en_search.fit(X, np.log(Y+0.0001))","52a2c16b":"print(np.mean(lr_score))\nprint(np.mean(sgd_score))\n\nprint(rr_score.best_score_)\nprint(ls_score.best_score_)\nprint(en_score.best_score_)","66e8019e":"predictions = np.exp(rr_score.best_estimator_.predict(X_test))\npredictions = predictions.astype('int')","d2db6a48":"pd.DataFrame({\n    'datetime': test_data.datetime,\n    'count': predictions\n}).to_csv('\/kaggle\/working\/submission_file.csv', index=False)","7a6b34d5":"**Try using StandardScaler instead of MinMaxScaler and see what happens.**","2c3ef2f7":"**Models**","fd0b197f":"# Name: MD. Azharul Islam <br>\n# ID: 181-35-2329","e08b69c3":"**Bike Sharing Demand**","41ca1406":"**Preprocessing & Feature Engineering with Pipeline**","b6de6d03":"**Exploratory Analysis**"}}