{"cell_type":{"5cef2732":"code","cf808db9":"code","f0cd949a":"code","68d9d656":"code","e6e8f77d":"code","173cc259":"code","858356ce":"code","59953b36":"code","274c0b16":"code","7cf8b5f2":"code","b07910ad":"code","b6d07d2e":"code","92f86e38":"code","d8782dc2":"code","246d37ea":"code","a579f412":"code","3c3d1dc4":"code","a3354ad9":"code","f20f7af5":"code","c4d0911f":"code","80e27b1d":"code","8f95fb9f":"code","cb32b7f7":"code","4be3585f":"code","d8e4bba5":"code","ca207a63":"code","6804aeab":"code","f8610c3b":"code","09821e79":"code","56d0856f":"code","6f2bdb5b":"code","e2ee061d":"code","e4b32542":"code","336b57f8":"code","111cdcaa":"code","58796d3b":"code","444b61b4":"code","6e87c02c":"code","ffd27953":"code","1c9155e3":"code","be3b9804":"code","ab669182":"code","93061b20":"code","8fb0d6fb":"code","0e1853b3":"code","a3e8810b":"code","1cd1a389":"code","1089a2f7":"code","d257bbf2":"code","adaf0f2e":"code","3917c5bc":"code","8d278f4b":"code","6375569f":"code","8b974250":"code","3ea31282":"code","def2d557":"code","fc651f94":"code","22faeed5":"code","6177b905":"code","3cbd4166":"code","cdcfd9e5":"code","440fcd88":"code","a888ab84":"code","bc4cadec":"code","98e9ded9":"code","104dc003":"code","6cd31539":"code","1bec7a59":"code","c89f7387":"code","029977fd":"code","0b6bfe8d":"code","05fe9bd4":"code","6b327661":"code","c7e12518":"code","76b2e703":"code","635455d1":"code","295c79f5":"code","5ca4907d":"code","e2efa4e3":"code","a5a007ce":"code","6086616d":"code","839f50fb":"code","2c2c710c":"code","ef2ba1cc":"code","ae0fce4a":"code","d8ba2642":"code","ed40391f":"code","2140a26a":"markdown","dd8825ee":"markdown","d49338cb":"markdown","3dd82047":"markdown","31233476":"markdown","352b6516":"markdown","34464e27":"markdown","0172ee5f":"markdown","c6fe9bae":"markdown","ffc81370":"markdown","051968a5":"markdown","bb94d7b7":"markdown","9c4a8c95":"markdown","282453a2":"markdown","9851edcc":"markdown","374bd7ae":"markdown","ca99b025":"markdown","618369fd":"markdown","af6c6b4c":"markdown","ba159d0d":"markdown","300da266":"markdown"},"source":{"5cef2732":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf808db9":"import numpy  as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#plt.rcParams.update({'font.size': 18})\n#plt.style.use('fivethirtyeight')\nplt.style.use('seaborn-white')\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","f0cd949a":"train_data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv',index_col=0,dtype={4: np.float32, 5: np.float32,6: np.float32,7: np.float32})\ntest_data  = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv', index_col=0,dtype={4: np.float32, 5: np.float32,6: np.float32,7: np.float32})\nsample     = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","68d9d656":"train_data.head()","e6e8f77d":"train_data.info()","173cc259":"test_data.head()","858356ce":"train_data.isnull().sum().to_frame()","59953b36":"test_data.isnull().sum().to_frame()","274c0b16":"breath_one = train_data[train_data['breath_id'] == 3928].reset_index(drop=True)\nbreath_one","7cf8b5f2":"breath_one.nunique().to_frame()","b07910ad":"fig,axes = plt.subplots(3,1,figsize=(12,15))\nsns.lineplot(x='time_step',y='u_in',data=breath_one,ax=axes[0])\naxes[0].set_title(\"u_in\")\nsns.lineplot(x='time_step',y='u_out',data=breath_one,ax=axes[1])\naxes[1].set_title(\"u_out\")\nsns.lineplot(x='time_step',y='pressure',data=breath_one,ax=axes[2])\naxes[2].set_title(\"pressure\")","b6d07d2e":"breath_one.describe()","92f86e38":"train_data.R.value_counts().to_frame()","d8782dc2":"train_data.C.value_counts().to_frame()","246d37ea":"train_data.describe()","a579f412":"fig,axes = plt.subplots(1,1,figsize=(10,5))\nsns.histplot(data=train_data,x=\"pressure\",ax=axes)","3c3d1dc4":"#add feature last_value_u_in\nidxmax_time_step = train_data.groupby('breath_id')['time_step'].idxmax()\nlast_value_u_in = train_data.loc[idxmax_time_step, ['breath_id','u_in']]\nlast_value_u_in.columns = ['breath_id','last_value_u_in']\n\ntrain_data = train_data.merge(last_value_u_in, on='breath_id')\ntrain_data","a3354ad9":"#add feature last_value_u_in\nidxmax_time_step = test_data.groupby('breath_id')['time_step'].idxmax()\nlast_value_u_in = test_data.loc[idxmax_time_step, ['breath_id','u_in']]\nlast_value_u_in.columns = ['breath_id','last_value_u_in']\n\ntest_data = test_data.merge(last_value_u_in, on='breath_id')\ntest_data","f20f7af5":"#add feature mean value u_in\nmean_u_in = train_data.groupby('breath_id')['u_in'].mean().to_frame()\nmean_u_in.columns = ['mean_value_u_in']\ntrain_data = train_data.merge(mean_u_in,on='breath_id')","c4d0911f":"train_data","80e27b1d":"#add feature mean value u_in\nmean_u_in = test_data.groupby('breath_id')['u_in'].mean().to_frame()\nmean_u_in.columns = ['mean_value_u_in']\ntest_data = test_data.merge(mean_u_in,on='breath_id')\ntest_data","8f95fb9f":"train_data['diff_u_in'] = train_data.groupby('breath_id')['u_in'].diff()","cb32b7f7":"train_data = train_data.fillna(0)","4be3585f":"train_data","d8e4bba5":"test_data['diff_u_in'] = test_data.groupby('breath_id')['u_in'].diff()\ntest_data = test_data.fillna(0)","ca207a63":"train_data['diff_diff_u_in'] = train_data.groupby('breath_id')['diff_u_in'].diff()\ntrain_data = train_data.fillna(0)\ntrain_data","6804aeab":"test_data['diff_diff_u_in'] = test_data.groupby('breath_id')['diff_u_in'].diff()\ntest_data = test_data.fillna(0)\ntest_data","f8610c3b":"train_data['u_in_cumsum'] = (train_data['u_in']).groupby(train_data['breath_id']).cumsum()\ntest_data['u_in_cumsum'] = (test_data['u_in']).groupby(test_data['breath_id']).cumsum()","09821e79":"#add feature sum value u_in\nsum_u_in = train_data.groupby('breath_id')['u_in'].sum().to_frame()\nsum_u_in.columns = ['sum_value_u_in']\ntrain_data = train_data.merge(sum_u_in,on='breath_id')","56d0856f":"#add feature sum value u_in\nsum_u_in = test_data.groupby('breath_id')['u_in'].sum().to_frame()\nsum_u_in.columns = ['sum_value_u_in']\ntest_data = test_data.merge(sum_u_in,on='breath_id')","6f2bdb5b":"train_data[\"u_in_cumsum_rate\"] = train_data[\"u_in_cumsum\"] \/ train_data[\"sum_value_u_in\"]\ntest_data[\"u_in_cumsum_rate\"] = test_data[\"u_in_cumsum\"] \/ test_data[\"sum_value_u_in\"]","e2ee061d":"#sum breath_id has all zero u_in\ntrain_data[train_data[\"sum_value_u_in\"] == 0]","e4b32542":"test_data[test_data[\"sum_value_u_in\"] == 0]","336b57f8":"train_data[train_data[\"breath_id\"] == 3928]","111cdcaa":"#so,null to zero\ntrain_data = train_data.fillna(0)\ntest_data = test_data.fillna(0)","58796d3b":"train_data['lag_u_in'] = train_data.groupby('breath_id')['u_in'].shift(1)\ntrain_data = train_data.fillna(0)","444b61b4":"test_data['lag_u_in'] = test_data.groupby('breath_id')['u_in'].shift(1)\ntest_data = test_data.fillna(0)","6e87c02c":"train_data['lag_2_u_in'] = train_data.groupby('breath_id')['u_in'].shift(2)\ntrain_data = train_data.fillna(0)","ffd27953":"test_data['lag_2_u_in'] = test_data.groupby('breath_id')['u_in'].shift(2)\ntest_data = test_data.fillna(0)","1c9155e3":"train_data['lag_-1_u_in'] = train_data.groupby('breath_id')['u_in'].shift(-1)\ntrain_data = train_data.fillna(0)\ntest_data['lag_-1_u_in'] = test_data.groupby('breath_id')['u_in'].shift(-1)\ntest_data = test_data.fillna(0)","be3b9804":"train_data['lag_-2_u_in'] = train_data.groupby('breath_id')['u_in'].shift(-2)\ntrain_data = train_data.fillna(0)\ntest_data['lag_-2_u_in'] = test_data.groupby('breath_id')['u_in'].shift(-2)\ntest_data = test_data.fillna(0)","ab669182":"train_data['lag_-3_u_in'] = train_data.groupby('breath_id')['u_in'].shift(-3)\ntrain_data = train_data.fillna(0)\ntest_data['lag_-3_u_in'] = test_data.groupby('breath_id')['u_in'].shift(-3)\ntest_data = test_data.fillna(0)","93061b20":"train_data['lag_3_u_in'] = train_data.groupby('breath_id')['u_in'].shift(3)\ntrain_data = train_data.fillna(0)\ntest_data['lag_3_u_in'] = test_data.groupby('breath_id')['u_in'].shift(3)\ntest_data = test_data.fillna(0)","8fb0d6fb":"train_data[\"max_u_in_breathid\"] = train_data.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")\ntest_data[\"max_u_in_breathid\"] = test_data.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")","0e1853b3":"train_data[\"R*C\"] = train_data['R'] * train_data['C']\ntest_data['R*C'] = test_data['R'] * test_data['C']","a3e8810b":"## add breath_id__u_in__min\ntrain_data['breath_id__u_in__min'] = train_data.groupby(['breath_id'])['u_in'].transform('min')\ntest_data['breath_id__u_in__min'] = test_data.groupby(['breath_id'])['u_in'].transform('min')","1cd1a389":"## add breath_id__u_in__diffmax & breath_id__u_in__diffmean\ntrain_data['breath_id__u_in__diffmax'] = train_data.groupby(['breath_id'])['u_in'].transform('max') - train_data['u_in']\ntrain_data['breath_id__u_in__diffmean'] = train_data.groupby(['breath_id'])['u_in'].transform('mean') - train_data['u_in']\n\ntest_data['breath_id__u_in__diffmax'] = test_data.groupby(['breath_id'])['u_in'].transform('max') - test_data['u_in']\ntest_data['breath_id__u_in__diffmean'] = test_data.groupby(['breath_id'])['u_in'].transform('mean') - test_data['u_in']","1089a2f7":"train_data['u_in_partition_out_sum'] = train_data.groupby(['breath_id',\"u_out\"])['u_in'].transform(\"sum\")\ntest_data['u_in_partition_out_sum'] = test_data.groupby(['breath_id',\"u_out\"])['u_in'].transform(\"sum\")","d257bbf2":"##add feature area (??)\ntrain_data['area'] = train_data['time_step'] * train_data['u_in']\ntrain_data['area'] = train_data.groupby('breath_id')['area'].cumsum()\ntest_data['area'] = test_data['time_step'] * test_data['u_in']\ntest_data['area'] = test_data.groupby('breath_id')['area'].cumsum()","adaf0f2e":"GRAPH = True\nif(GRAPH):\n    sample_train = train_data.sample(frac=0.001)\n    sample_train = sample_train[sample_train[\"u_out\"] == 0]\n    #check scatter with pressure and (last_value_u_in |mean_value_u_in| u_in_diff)\n    fig,axes = plt.subplots(3,7,figsize=(25,15))\n    sns.scatterplot(data=sample_train,x='last_value_u_in',y='pressure',ax=axes[0][0])\n    sns.scatterplot(data=sample_train,x='mean_value_u_in',y='pressure',ax=axes[0][1])\n    sns.scatterplot(data=sample_train,x='diff_u_in',y='pressure',ax=axes[0][2])\n    sns.scatterplot(data=sample_train,x='u_in_cumsum',y='pressure',ax=axes[0][3])\n    sns.scatterplot(data=sample_train,x='time_step',y='pressure',ax=axes[0][4])\n    sns.scatterplot(data=sample_train,x='diff_diff_u_in',y='pressure',ax=axes[0][5])\n    sns.scatterplot(data=sample_train,x='sum_value_u_in',y='pressure',ax=axes[0][6])\n    sns.scatterplot(data=sample_train,x='u_in_cumsum_rate',y='pressure',ax=axes[1][0])\n    sns.scatterplot(data=sample_train,x='lag_u_in',y='pressure',ax=axes[1][1])\n    sns.scatterplot(data=sample_train,x='lag_2_u_in',y='pressure',ax=axes[1][2])\n    sns.scatterplot(data=sample_train,x='max_u_in_breathid',y='pressure',ax=axes[1][3])\n    sns.scatterplot(data=sample_train,x='R*C',y='pressure',ax=axes[1][4])\n    sns.scatterplot(data=sample_train,x='lag_-3_u_in',y='pressure',ax=axes[1][5])\n    sns.scatterplot(data=sample_train,x='lag_3_u_in',y='pressure',ax=axes[1][6])\n    sns.scatterplot(data=sample_train,x='breath_id__u_in__min',y='pressure',ax=axes[2][0])\n    sns.scatterplot(data=sample_train,x='breath_id__u_in__diffmax',y='pressure',ax=axes[2][1])\n    sns.scatterplot(data=sample_train,x='breath_id__u_in__diffmean',y='pressure',ax=axes[2][2])\n    sns.scatterplot(data=sample_train,x='u_in_partition_out_sum',y='pressure',ax=axes[2][3])\n    sns.scatterplot(data=sample_train,x='area',y='pressure',ax=axes[2][4])","3917c5bc":"GRAPH = True\nif(GRAPH):\n    sample_train = train_data.sample(frac=0.001)\n    sample_train = sample_train[sample_train[\"u_out\"] == 1]\n    #check scatter with pressure and (last_value_u_in |mean_value_u_in| u_in_diff)\n    fig,axes = plt.subplots(3,7,figsize=(25,15))\n    sns.scatterplot(data=sample_train,x='last_value_u_in',y='pressure',ax=axes[0][0])\n    sns.scatterplot(data=sample_train,x='mean_value_u_in',y='pressure',ax=axes[0][1])\n    sns.scatterplot(data=sample_train,x='diff_u_in',y='pressure',ax=axes[0][2])\n    sns.scatterplot(data=sample_train,x='u_in_cumsum',y='pressure',ax=axes[0][3])\n    sns.scatterplot(data=sample_train,x='time_step',y='pressure',ax=axes[0][4])\n    sns.scatterplot(data=sample_train,x='diff_diff_u_in',y='pressure',ax=axes[0][5])\n    sns.scatterplot(data=sample_train,x='sum_value_u_in',y='pressure',ax=axes[0][6])\n    sns.scatterplot(data=sample_train,x='u_in_cumsum_rate',y='pressure',ax=axes[1][0])\n    sns.scatterplot(data=sample_train,x='lag_u_in',y='pressure',ax=axes[1][1])\n    sns.scatterplot(data=sample_train,x='lag_2_u_in',y='pressure',ax=axes[1][2])\n    sns.scatterplot(data=sample_train,x='max_u_in_breathid',y='pressure',ax=axes[1][3])\n    sns.scatterplot(data=sample_train,x='R*C',y='pressure',ax=axes[1][4])\n    sns.scatterplot(data=sample_train,x='lag_-3_u_in',y='pressure',ax=axes[1][5])\n    sns.scatterplot(data=sample_train,x='lag_3_u_in',y='pressure',ax=axes[1][6])\n    sns.scatterplot(data=sample_train,x='breath_id__u_in__min',y='pressure',ax=axes[2][0])\n    sns.scatterplot(data=sample_train,x='breath_id__u_in__diffmax',y='pressure',ax=axes[2][1])\n    sns.scatterplot(data=sample_train,x='breath_id__u_in__diffmean',y='pressure',ax=axes[2][2])\n    sns.scatterplot(data=sample_train,x='u_in_partition_out_sum',y='pressure',ax=axes[2][3])\n    sns.scatterplot(data=sample_train,x='area',y='pressure',ax=axes[2][4])","8d278f4b":"del fig\ndel axes\ndel sample_train","6375569f":"import gc\ngc.collect()","8b974250":"train_data[\"train_test\"] = \"train\"\ntest_data[\"train_test\"] = \"test\"","3ea31282":"train_test_all = pd.concat([train_data,test_data],axis=0)","def2d557":"del train_data\ndel test_data\ngc.collect()","fc651f94":"train_test_all","22faeed5":"train_test_all['R_C'] = [f'{r}_{c}' for r, c in zip(train_test_all['R'], train_test_all['C'])]","6177b905":"train_test_all.info()","3cbd4166":"train_test_all = pd.get_dummies(train_test_all,columns=[\"R_C\"])","cdcfd9e5":"train_test_all.columns","440fcd88":"##add feaure time_diff\ntrain_test_all['time_diff']=train_test_all.time_step.diff().fillna(0)","a888ab84":"train_data = train_test_all[train_test_all[\"train_test\"] == \"train\"]","bc4cadec":"test_data = train_test_all[train_test_all[\"train_test\"] == \"test\"]","98e9ded9":"del train_test_all\ngc.collect()","104dc003":"LM = True\nu_out_zero_only = False ## if train from only u_out=0 data ","6cd31539":"#train\n#X_train = train_data[['R','C','time_step','u_in','u_out','last_value_u_in','mean_value_u_in','diff_u_in','u_in_cumsum']]\nif(u_out_zero_only):\n    train_data = train_data[train_data[\"u_out\"] == 0]\n    train_data = train_data.reset_index(drop=True)\nX_train = train_data.drop([\"pressure\",\"breath_id\",\"train_test\"],axis=1)\ny_train = train_data['pressure']\nX_test = test_data.drop([\"pressure\",\"breath_id\",\"train_test\"],axis=1)\n\nif(LM):\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    #print(scaler.mean_)\n\n    X_train_std = scaler.transform(X_train)\n\n\n    lm = LinearRegression().fit(X_train_std, y_train)\n    print(\"coefficient of determination = \",lm.score(X_train_std, y_train))\n\n\n    #test\n    #X_test = test_data[['R','C','time_step','u_in','u_out','last_value_u_in','mean_value_u_in','diff_u_in','u_in_cumsum']]\n    \n    X_test_std = scaler.transform(X_test)\n    sample['pressure'] = lm.predict(X_test_std)\n\n    sample.to_csv(\"submission_lm.csv\",index=False)","1bec7a59":"if(LM):\n    #plot scatter of corrct-predict of train_in_sample\n    insample_result = pd.DataFrame()\n    insample_result['correct'] = y_train\n    insample_result['result'] = lm.predict(X_train_std)\n\n    fig,axes = plt.subplots(1,1,figsize=(10,10))\n    sns.scatterplot(data=insample_result,x='correct',y='result',ax=axes)\n\n    x = np.linspace(0, 60, 10)\n    y = x\n    axes.plot(x, y, color = \"k\")","c89f7387":"if(LM):\n    #calc insample MSE\n    insample_MSE = mean_absolute_error(insample_result['correct'],insample_result['result'])\n    print(insample_MSE)","029977fd":"if(LM):\n    del insample_result\n    del fig\n    del axes\n    del X_train_std\n    del X_test_std\n\ndel test_data","0b6bfe8d":"NEW_GBM = False","05fe9bd4":"from sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import GroupKFold \nfrom sklearn.model_selection import  KFold\nfrom sklearn import metrics","6b327661":"y_train","c7e12518":"#for scatterplot of lightgbm val\ngbm_val_result = pd.DataFrame()\ngbm_val_result['correct'] = y_train","76b2e703":"if(NEW_GBM):\n    scores = []\n    feature_importance = pd.DataFrame()\n    columns = [col for col in train_data.columns if col not in ['id', 'breath_id', 'pressure',\"train_test\"]]\n\n    models = []\n    X = X_train\n    y = y_train\n\n    del X_train\n    del y_train\n\n    params = {'objective': 'regression',\n              'learning_rate': 0.25,\n              \"boosting_type\": \"gbdt\",\n              'min_data_in_leaf':600,\n              'max_bin': 196,\n              #'device':'gpu',\n              'feature_fraction':0.4,\n              'lambda_l1':36, 'lambda_l2':80,\n              'max_depth':16,\n              'num_leaves':1000,\n              \"metric\": 'mae',\n              'n_jobs': -1\n             }\n    folds = GroupKFold(n_splits=5)\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(train_data, y, groups=train_data['breath_id'])):\n        print(f'Fold {fold_n} started at {time.ctime()}')\n        X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        model = lgb.LGBMRegressor(**params, n_estimators=8000)\n        model.fit(X_train, y_train, \n                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                verbose=100, early_stopping_rounds=10)\n        score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n\n        models.append(model)\n        scores.append(score)\n\n        y_pred = model.predict(X_valid)\n\n        gbm_val_result.loc[valid_index,[\"result\"]] = y_pred #for scatterplot\n\n\n\n        fold_importance = pd.DataFrame()\n        fold_importance[\"feature\"] = columns\n        fold_importance[\"importance\"] = model.feature_importances_\n        fold_importance[\"fold\"] = fold_n + 1\n        feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","635455d1":"if(NEW_GBM):\n    for model in models:\n        sample['pressure'] += model.predict(X_test)\n    sample['pressure'] \/= 5\n\n    sample.to_csv('submission.csv', index=False)","295c79f5":"if(NEW_GBM):\n    fig,axes = plt.subplots(1,1,figsize=(10,10))\n    sns.scatterplot(data=gbm_val_result,x='correct',y='result',ax=axes)\n\n    x = np.linspace(0, 60, 10)\n    y = x\n    axes.plot(x, y, color = \"k\")","5ca4907d":"#GroupID for Group-KFold\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom tqdm import tqdm_notebook as tqdm\nimport lightgbm as lgb\ngroups = train_data[\"breath_id\"]\n#groups","e2efa4e3":"#for scatterplot of lightgbm val\n#gbm_val_result = pd.DataFrame()\n#gbm_val_result['correct'] = y_train","a5a007ce":"OLD_GBM = True\nif(OLD_GBM):\n    # CV Averaging\n    scores = []\n    importance = []\n    y_pred_test = np.zeros(len(X_test)) #array for predict value\n    gkf = GroupKFold(n_splits=5)\n\n    for i, (train_ix, test_ix) in tqdm(enumerate(gkf.split(X_train, y_train, groups))):\n\n        X_train_, y_train_, groups_train_ = X_train.iloc[train_ix], y_train.iloc[train_ix], groups[train_ix]\n        X_val, y_val, groups_val = X_train.iloc[test_ix], y_train.iloc[test_ix], groups[test_ix]\n\n        print('Train Groups', np.unique(groups_train_))\n        print('Val Groups', np.unique(groups_val))\n        print(X_train_.shape, X_val.shape)\n\n        model = lgb.LGBMRegressor(random_state=71, importance_type='gain')\n\n        model.fit(X_train_, y_train_)\n        y_pred = model.predict(X_val)\n\n        gbm_val_result.loc[test_ix,[\"result\"]] = y_pred #for scatterplot\n\n        y_pred_test += model.predict(X_test) # add predict value\n\n        score =  mean_absolute_error(y_val, y_pred)\n        scores.append(score) \n\n        #importance\n        importance_df = pd.DataFrame(model.feature_importances_, index = X_test.columns, columns=['importance'])\n        importance.append(importance_df)\n\n        print('CV Score of Fold_%d is %f' % (i, score))","6086616d":"if(OLD_GBM):\n    print(scores)\n    print(np.mean(scores))","839f50fb":"if(OLD_GBM):\n    for df in importance:\n        display(df.sort_values('importance',ascending=False))","2c2c710c":"if(OLD_GBM):\n    y_pred_test_submit = y_pred_test\/5 #n_splits=5\n    sample['pressure'] = y_pred_test_submit\n    sample.to_csv(\"submission.csv\",index=False)","ef2ba1cc":"if(OLD_GBM):\n    fig,axes = plt.subplots(1,1,figsize=(10,10))\n    sns.scatterplot(data=gbm_val_result,x='correct',y='result',ax=axes)\n\n    x = np.linspace(0, 60, 10)\n    y = x\n    axes.plot(x, y, color = \"k\")","ae0fce4a":"XGBRegressor = False","d8ba2642":"if(XGBRegressor):\n    #train\n    xgb = XGBRegressor(objective='reg:squarederror', n_estimators=700)\n    xgb.fit(X_train, y_train)\n\n\n    print(\"coefficient of determination = \", xgb.score(X_train, y_train))\n\n    #test\n    sample['pressure'] = xgb.predict(X_test)\n    sample.to_csv(\"submission_xgb.csv\",index=False)","ed40391f":"if(XGBRegressor):\n    #plot scatter of corrct-predict of train_in_sample\n    insample_result = pd.DataFrame()\n    insample_result['correct'] = y_train\n    insample_result['result'] = xgb.predict(X_train)\n\n    fig,axes = plt.subplots(1,1,figsize=(10,10))\n    sns.scatterplot(data=insample_result,x='correct',y='result',ax=axes)\n\n    x = np.linspace(0, 60, 10)\n    y = x\n    axes.plot(x, y, color = \"k\")","2140a26a":"#### add feature: max_u_in_breathid","dd8825ee":"#### add feature: lag2 of u_in","d49338cb":"#### add feature : diff of value_u_in","3dd82047":"#### add feature lag -3 and 3 u_in","31233476":"#### add feature etc..","352b6516":"#### LightGBM (old)","34464e27":"#### scatter plot (u_out = 0)","0172ee5f":"###  XGBRegressor","c6fe9bae":"#### add feature : u_in_cumsum_rate","ffc81370":"### LIghtGBM","051968a5":"#### sum breath_id has all zero u_in","bb94d7b7":"#### add feature: R*C","9c4a8c95":"#### add feature:sum_value_u_in","282453a2":"#### add feature lag -1 and -2 u_in","9851edcc":"#### add feature: comsum of u_in","374bd7ae":"### add feature: R_C","ca99b025":"#### add feature:diff_diff_u_in","618369fd":"#### add feature: lag of u_in","af6c6b4c":"#### scatter plot (u_out = 1)","ba159d0d":"## Simple Regression Submit","300da266":"#### "}}