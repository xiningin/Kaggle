{"cell_type":{"508756ce":"code","573455dd":"code","8852ee65":"code","c9473b91":"code","635ffc4d":"code","6eca09da":"code","22adeb49":"code","ebf4209a":"code","f09613b4":"code","faee6784":"code","a7c338b5":"code","ca9882ba":"code","a7a44dc7":"code","275136c0":"code","f4735e85":"markdown","2a071797":"markdown","40d0bfa5":"markdown","332ef8ec":"markdown","b5b96fc9":"markdown","1090548a":"markdown","4784cfce":"markdown","5c2ad2d6":"markdown","05088a1f":"markdown"},"source":{"508756ce":"!pip install -q --upgrade wandb\n\nimport wandb\nwandb.login()","573455dd":"import os\nimport gc\nimport cv2\nimport ast\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline","8852ee65":"TRAIN_PATH = '..\/input\/siim-covid19-resized-to-256px-jpg\/train\/'\nIMG_SIZE = 256\nNUM_SAMPLES_TO_VIZ = 32","c9473b91":"# Load image level csv file\ndf = pd.read_csv('..\/input\/siim-covid19-detection\/train_image_level.csv')\n# Load study level csv file\nlabel_df = pd.read_csv('..\/input\/siim-covid19-detection\/train_study_level.csv')\n\n# Modify values in the id column\ndf['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)\n# Add absolute path\ndf['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\n# Get image level labels\ndf['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n\n# Modify values in the id column\nlabel_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)\n# Rename the column id with StudyInstanceUID\nlabel_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n\n# Merge both dataframes\ndf = df.merge(label_df, on='StudyInstanceUID',how=\"left\")\ndf.head(2)","635ffc4d":"print(f'Number of unique image in training dataset: {len(df)}')\n\nbbox_nan_num = df['boxes'].isna().sum()\nprint(f'Number of images without any bbox annotation: {bbox_nan_num}')","6eca09da":"# Label encode study-level labels\nlabels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values\nlabels = np.argmax(labels, axis=1)\n\ndf['study_level'] = labels\ndf.head(2)","22adeb49":"class_label_to_id = {\n    'Negative for Pneumonia': 0,\n    'Typical Appearance': 1,\n    'Indeterminate Appearance': 2,\n    'Atypical Appearance': 3\n}\n\nclass_id_to_label = {val: key for key, val in class_label_to_id.items()}","ebf4209a":"# Load meta.csv file\nmeta_df = pd.read_csv('..\/input\/siim-covid19-resized-to-256px-jpg\/meta.csv')\ntrain_meta_df = meta_df.loc[meta_df.split == 'train']\ntrain_meta_df.columns = ['id', 'dim0', 'dim1', 'split']\ntrain_meta_df.head(2)","f09613b4":"df = df.merge(train_meta_df, on='id',how=\"left\")\ndf.head(5)","faee6784":"# Since there are over 2000 rows without bounding box coordinates.\nopacity_df = df.dropna(subset = [\"boxes\"], inplace=False)\nopacity_df = opacity_df.reset_index(drop=True)","a7c338b5":"# Get the raw bounding box \n# Ref: https:\/\/www.kaggle.com\/yujiariyasu\/plot-3positive-classes\ndef get_bbox(row):\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row.label.split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l))\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []  \n            \n    return bboxes\n\n# Scale the bounding boxes.\ndef scale_bbox(row, bboxes):\n    # Get scaling factor\n    scale_x = IMG_SIZE\/row.dim1\n    scale_y = IMG_SIZE\/row.dim0\n    \n    scaled_bboxes = []\n    for bbox in bboxes:\n        x = int(np.round(bbox[0]*scale_x, 4))\n        y = int(np.round(bbox[1]*scale_y, 4))\n        x1 = int(np.round(bbox[2]*(scale_x), 4))\n        y1= int(np.round(bbox[3]*scale_y, 4))\n\n        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n        \n    return scaled_bboxes\n\n# To log a bounding box, you'll need to provide a dictionary with \n# the following keys and values to the boxes keyword argument of wandb.Image.\ndef wandb_bbox(image, bboxes, true_label, class_id_to_label):\n    all_boxes = []\n    for bbox in bboxes:\n        box_data = {\"position\": {\n                        \"minX\": bbox[0],\n                        \"minY\": bbox[1],\n                        \"maxX\": bbox[2],\n                        \"maxY\": bbox[3]\n                    },\n                     \"class_id\" : int(true_label),\n                     \"box_caption\": class_id_to_label[true_label],\n                     \"domain\" : \"pixel\"}\n        all_boxes.append(box_data)\n    \n\n    return wandb.Image(image, boxes={\n        \"ground_truth\": {\n            \"box_data\": all_boxes,\n          \"class_labels\": class_id_to_label\n        }\n    })","ca9882ba":"sampled_df = opacity_df.sample(NUM_SAMPLES_TO_VIZ).reset_index(drop=True)\n\nrun = wandb.init(project='kaggle-covid', \n                 config={'competition': 'siim-fisabio-rsna', '_wandb_kernel': 'ayut'},\n                 job_type='visualize_sample_bbox')\n\nwandb_bbox_list = []\nfor i in tqdm(range(NUM_SAMPLES_TO_VIZ)):\n    row = sampled_df.loc[i]\n    # Load image\n    image = cv2.imread(row.path)\n    # Get bboxes\n    bboxes = get_bbox(row)\n    # Scale bounding boxes\n    scale_bboxes = scale_bbox(row, bboxes)\n    # Get ground truth label\n    true_label = row.study_level\n    \n    wandb_bbox_list.append(wandb_bbox(image, \n                                      scale_bboxes, \n                                      true_label, \n                                      class_id_to_label))\n    \nwandb.log({\"radiograph\": wandb_bbox_list})\n\nrun.finish()\n\nrun","a7a44dc7":"# W&B image\ndef wandb_bbox(image, bboxes, true_label, class_id_to_label, class_set):\n    all_boxes = []\n    for bbox in bboxes:\n        box_data = {\"position\": {\n                        \"minX\": bbox[0],\n                        \"minY\": bbox[1],\n                        \"maxX\": bbox[2],\n                        \"maxY\": bbox[3]\n                    },\n                     \"class_id\" : int(true_label),\n                     \"box_caption\": class_id_to_label[true_label],\n                     \"domain\" : \"pixel\"}\n        all_boxes.append(box_data)\n    \n\n    return wandb.Image(image, boxes={\n        \"ground_truth\": {\n            \"box_data\": all_boxes,\n          \"class_labels\": class_id_to_label\n        }\n    }, classes=class_set)","275136c0":"run = wandb.init(project='kaggle-covid', \n                 config={'competition': 'siim-fisabio-rsna', '_wandb_kernel': 'ayut'},\n                 job_type='visualize-everything')\n\nclass_set = wandb.Classes([{'id': id, 'name': name} for id, name in class_id_to_label.items()])\n\n\ntable = wandb.Table(columns=['ImageID', 'StudyInstanceUID', 'Radiogram', 'image-label', 'study-label',\n                             'Negative', 'Typical', 'Indeterminate', 'Atypical',\n                             'ori_dim0', 'ori_dim1', 'split'])\n\n# create an artifact for all the raw data\nviz_at = wandb.Artifact('eda', type=\"basic-eda\")\n\nfor i in tqdm(range(len(df))):\n    row = df.loc[i]\n    # Load image\n    image = cv2.imread(row.path)\n    # Get bboxes\n    bboxes = get_bbox(row)\n    # Scale bounding boxes\n    scale_bboxes = scale_bbox(row, bboxes)\n    # Get ground truth label\n    true_label = row.study_level\n    # Get image with bounding boxes\n    wandb_img = wandb_bbox(image, \n                           scale_bboxes, \n                           true_label, \n                           class_id_to_label,\n                           class_set)\n    \n    # Add info in the table as new row\n    table.add_data(row.id, row.StudyInstanceUID, wandb_img, row.image_level, row.study_level,\n                   row['Negative for Pneumonia'], row['Typical Appearance'], row['Indeterminate Appearance'], row['Atypical Appearance'],\n                   row.dim0, row.dim1, row.split)\n    \n    del row, wandb_img\n    _ = gc.collect()\n    \n# wandb.log({'radiogram_eda': table})\nviz_at.add(table, \"Radiogram EDA\")\nrun.log_artifact(viz_at)\nrun.finish()","f4735e85":"> \ud83d\udccc Click on the [run page](https:\/\/wandb.ai\/ayush-thakur\/kaggle-covid\/runs\/3vxougc9?workspace=user-ayush-thakur) to interactively play with the bounding box coordinates. \n\n> \ud83d\udccc Click on the \u2699\ufe0f icon to interact with the UI.","2a071797":"\n\n## [Check out the Table $\\rightarrow$](https:\/\/wandb.ai\/ayush-thakur\/kaggle-covid\/artifacts\/basic-eda\/eda\/c17893f765f142a4acbf\/files\/Radiogram%20EDA.table.json)\n\n![img](https:\/\/i.imgur.com\/zdRSgtn.gif)","40d0bfa5":"# Work In Progress\n\nUpcoming:\n* ~Visualize the entire training dataset using W&B Tables.~\n* ~Visualize Metadata~.\n* Get insight from the tables.","332ef8ec":"# Better Data Understanding using W&B Tables","b5b96fc9":"# Imports and Setups","1090548a":"# Load Dataset\n\nThis competition is unique because of how the data is presented and thus the problem statement. The DICOM formatted radiograms of chest scans are available in this directory structure `study\/series\/images`. What's `study` and `image`?\n \nThere are 6334 unique chest scans or `images` while 6054 unique `study` directories. This means that in some study directory there are more than one images. \n\nIn this competition, the task is to provide image level predictions - `none` vs `opacity` as well as study level predictions - `negative`, `typical`, `atypical`, `indeterminate`. Thus we will build two separate classifiers - one for study level prediction and another for image level prediction. Then when bounding boxes or localization?\n\nFor images with `opacity` label i.e, image-level label, we need to train an object detector for localization. \n\n* `train_study_level.csv`: Study level labels.\n\n* `train_image_level.csv`: Image level labels.\n\nIn this kernel we will try to understand the relationship better.","4784cfce":"# Hyperparams","5c2ad2d6":"## Visualize Bounding Boxes\n\nThis section will walk you through the steps required to use W&B to log bounding boxes. \n\nNotes: \n* Since some of the images don't have bounding box coordinates we will drop those rows. \n* The steps below can be used as it is with a training pipeline with littleeee modification. \n\nNote: Even though the `true_label` is `opacity` or `none` but I have logged the study-level labels for more insight. Every image with bounding box coordinates belong to `opacity` label.","05088a1f":"This kernel can be used to visualize the bounding boxes interactively using W&B and will walk you through the process of logging bounding boxes. \n\nThis kernel can be considered a simple EDA kernel with the focus on deriving insights by interactively playing with the bounding boxes for each images.\n\n![img](https:\/\/i.imgur.com\/3vk2h3j.gif)\n\n### Credits\n\n* I am using [xhlulu's](https:\/\/www.kaggle.com\/xhlulu) resized dataset. Check out his amazing [kernel](https:\/\/www.kaggle.com\/xhlulu\/siim-covid-19-convert-to-jpg-256px) that can be used to generate resized images with different resolution. The uploaded 256x256 Kaggle dataset is [here](https:\/\/www.kaggle.com\/xhlulu\/siim-covid19-resized-to-256px-jpg)."}}