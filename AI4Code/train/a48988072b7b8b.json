{"cell_type":{"6b3b95b9":"code","3454e54d":"code","7514ccb9":"code","6a848480":"code","27c53b07":"code","fb453fc1":"code","8403de76":"code","8a31f2ae":"code","b7d7b632":"code","8eee193b":"code","5b0cec83":"code","172efd2d":"code","248e904f":"code","9a3e39ef":"code","0e12779e":"code","69ebebf1":"code","6d7e9c9b":"code","43e10ba8":"code","8489c0a2":"code","33785c43":"code","05b443bd":"code","55f4d7c6":"code","fb625385":"code","2de51a82":"code","45c64ba5":"code","ed39902e":"code","b72380f8":"code","a5d530ec":"code","797df3f8":"code","a3173e83":"code","4d7650a0":"code","82db3a00":"code","06ecdf6b":"code","abe66d60":"code","a2d53515":"code","e4030dba":"code","b8550ec3":"code","7447074a":"code","9cbb164b":"code","84cc4902":"code","f63c197a":"code","7b67fc31":"code","528601f6":"code","da49763e":"code","e01648cf":"code","d16455e9":"code","213e7634":"code","ab48f319":"code","16e6b497":"code","92dc28ff":"code","cc643a2b":"code","29abab89":"code","a1a17156":"code","44c28bd8":"code","2e42e3f2":"code","f29b18ec":"code","d989c6d3":"code","5eb69b6c":"code","61257c44":"code","5d924782":"code","6ee1d722":"code","27a9a968":"code","17c08797":"code","a4caa855":"code","319945ad":"code","3bc68fe3":"code","721a10cb":"code","deba43de":"code","2cf7e7fe":"code","ede956da":"code","ca71478e":"code","ae4954f3":"code","8336eb48":"code","8299df60":"code","1bb3b741":"code","48fc4681":"code","950c4560":"markdown","f40a701c":"markdown","f12f7f96":"markdown","4b7a8cfa":"markdown","dcc90703":"markdown","040e1089":"markdown","1275b416":"markdown","2e72806f":"markdown","d81d3d8f":"markdown","d1334dc5":"markdown","d1487e1e":"markdown","6803cbd6":"markdown","5f86316b":"markdown","f52bf88d":"markdown","64339921":"markdown","d430432e":"markdown","df0389e6":"markdown","d993fbb3":"markdown","57c71b28":"markdown"},"source":{"6b3b95b9":"!pip install ttach\n# \u5b89\u88c5TTA\u5305","3454e54d":"!pip install git+https:\/\/github.com\/ildoonet\/cutmix \n# \u5b89\u88c5CutMix","7514ccb9":"# \u5b89\u88c5ResNeSt\u6a21\u578b\u5305\n!pip install resnest --pre","6a848480":"# \u5bfc\u5165\u5404\u79cd\u5305\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport ttach as tta\nfrom resnest.torch import resnest50\n\nfrom cutmix.cutmix import CutMix\nfrom cutmix.utils import CutMixCrossEntropyLoss\n\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom sklearn.model_selection import KFold\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\n# This is for the progress bar.\nfrom tqdm import tqdm\n","27c53b07":"# \u770b\u770blabel\u6587\u4ef6\u957f\u5565\u6837\nlabels_dataframe = pd.read_csv('..\/input\/classify-leaves\/train.csv')\nlabels_dataframe.head(5)","fb453fc1":"# \u628alabel\u6587\u4ef6\u6392\u4e2a\u5e8f\nleaves_labels = sorted(list(set(labels_dataframe['label'])))\nn_classes = len(leaves_labels)\nprint(n_classes)\nleaves_labels[:10]","8403de76":"# \u628alabel\u8f6c\u6210\u5bf9\u5e94\u7684\u6570\u5b57\nclass_to_num = dict(zip(leaves_labels, range(n_classes)))\nclass_to_num","8a31f2ae":"# \u518d\u8f6c\u6362\u56de\u6765\uff0c\u65b9\u4fbf\u6700\u540e\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\nnum_to_class = {v : k for k, v in class_to_num.items()}\nnum_to_class","b7d7b632":"# \u7ee7\u627fpytorch\u7684dataset\uff0c\u521b\u5efa\u81ea\u5df1\u7684\nclass TrainValidData(Dataset):\n    def __init__(self, csv_path, file_path, resize_height=224, resize_width=224, transform=None):\n        \"\"\"\n        Args:\n            csv_path (string): csv \u6587\u4ef6\u8def\u5f84\n            img_path (string): \u56fe\u50cf\u6587\u4ef6\u6240\u5728\u8def\u5f84\n\n        \"\"\"\n        \n        # \u9700\u8981\u8c03\u6574\u540e\u7684\u7167\u7247\u5c3a\u5bf8\uff0c\u6211\u8fd9\u91cc\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\u5c3a\u5bf8\u4e0d\u4e00\u81f4#\n        self.resize_height = resize_height\n        self.resize_width = resize_width\n\n        self.file_path = file_path\n        self.to_tensor = transforms.ToTensor() #\u5c06\u6570\u636e\u8f6c\u6362\u6210tensor\u5f62\u5f0f\n        self.transform = transform\n\n        # \u8bfb\u53d6 csv \u6587\u4ef6\n        # \u5229\u7528pandas\u8bfb\u53d6csv\u6587\u4ef6\n        self.data_info = pd.read_csv(csv_path, header=None)  #header=None\u662f\u53bb\u6389\u8868\u5934\u90e8\u5206\n        # \u6587\u4ef6\u7b2c\u4e00\u5217\u5305\u542b\u56fe\u50cf\u6587\u4ef6\u540d\u79f0\n        self.image_arr = np.asarray(self.data_info.iloc[1:,0]) #self.data_info.iloc[1:,0]\u8868\u793a\u8bfb\u53d6\u7b2c\u4e00\u5217\uff0c\u4ece\u7b2c\u4e8c\u884c\u5f00\u59cb\u4e00\u76f4\u8bfb\u53d6\u5230\u6700\u540e\u4e00\u884c\n        # \u7b2c\u4e8c\u5217\u662f\u56fe\u50cf\u7684 label\n        self.label_arr = np.asarray(self.data_info.iloc[1:,1])\n        # \u8ba1\u7b97 length\n        self.data_len = len(self.data_info.index) - 1\n\n    def __getitem__(self, index):\n        # \u4ece image_arr\u4e2d\u5f97\u5230\u7d22\u5f15\u5bf9\u5e94\u7684\u6587\u4ef6\u540d\n        single_image_name = self.image_arr[index]\n\n        # \u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\n        img_as_img = Image.open(self.file_path + single_image_name)\n        \n        #\u5982\u679c\u9700\u8981\u5c06RGB\u4e09\u901a\u9053\u7684\u56fe\u7247\u8f6c\u6362\u6210\u7070\u5ea6\u56fe\u7247\u53ef\u53c2\u8003\u4e0b\u9762\u4e24\u884c\n        # if img_as_img.mode != 'L':\n        #     img_as_img = img_as_img.convert('L')\n        \n        #\u8bbe\u7f6e\u597d\u9700\u8981\u8f6c\u6362\u7684\u53d8\u91cf\uff0c\u8fd8\u53ef\u4ee5\u5305\u62ec\u4e00\u7cfb\u5217\u7684nomarlize\u7b49\u7b49\u64cd\u4f5c\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor()\n        ])\n        img_as_img = transform(img_as_img)\n\n        # \u5f97\u5230\u56fe\u50cf\u7684 label\n        label = self.label_arr[index]\n        number_label = class_to_num[label]\n\n        return (img_as_img, number_label)  #\u8fd4\u56de\u6bcf\u4e00\u4e2aindex\u5bf9\u5e94\u7684\u56fe\u7247\u6570\u636e\u548c\u5bf9\u5e94\u7684label\n\n    def __len__(self):\n        return self.data_len","8eee193b":"# \u7ee7\u627fpytorch\u7684dataset\uff0c\u521b\u5efa\u81ea\u5df1\u7684\nclass TestData(Dataset):\n    def __init__(self, csv_path, file_path, resize_height=224, resize_width=224, transform = None):\n        \"\"\"\n        Args:\n            csv_path (string): csv \u6587\u4ef6\u8def\u5f84\n            img_path (string): \u56fe\u50cf\u6587\u4ef6\u6240\u5728\u8def\u5f84\n\n        \"\"\"\n        \n        # \u9700\u8981\u8c03\u6574\u540e\u7684\u7167\u7247\u5c3a\u5bf8\uff0c\u6211\u8fd9\u91cc\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\u5c3a\u5bf8\u4e0d\u4e00\u81f4#\n        self.resize_height = resize_height\n        self.resize_width = resize_width\n\n        self.file_path = file_path\n        self.transform = transform\n        self.to_tensor = transforms.ToTensor() #\u5c06\u6570\u636e\u8f6c\u6362\u6210tensor\u5f62\u5f0f\n\n        # \u8bfb\u53d6 csv \u6587\u4ef6\n        # \u5229\u7528pandas\u8bfb\u53d6csv\u6587\u4ef6\n        self.data_info = pd.read_csv(csv_path, header=None)  #header=None\u662f\u53bb\u6389\u8868\u5934\u90e8\u5206\n        # \u6587\u4ef6\u7b2c\u4e00\u5217\u5305\u542b\u56fe\u50cf\u6587\u4ef6\u540d\u79f0\n        self.image_arr = np.asarray(self.data_info.iloc[1:,0]) #self.data_info.iloc[1:,0]\u8868\u793a\u8bfb\u53d6\u7b2c\u4e00\u5217\uff0c\u4ece\u7b2c\u4e8c\u884c\u5f00\u59cb\u4e00\u76f4\u8bfb\u53d6\u5230\u6700\u540e\u4e00\u884c\n        # \u8ba1\u7b97 length\n        self.data_len = len(self.data_info.index) - 1\n        \n    def __getitem__(self, index):\n        # \u4ece image_arr\u4e2d\u5f97\u5230\u7d22\u5f15\u5bf9\u5e94\u7684\u6587\u4ef6\u540d\n        single_image_name = self.image_arr[index]\n\n        # \u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\n        img_as_img = Image.open(self.file_path + single_image_name)\n        \n        #\u5982\u679c\u9700\u8981\u5c06RGB\u4e09\u901a\u9053\u7684\u56fe\u7247\u8f6c\u6362\u6210\u7070\u5ea6\u56fe\u7247\u53ef\u53c2\u8003\u4e0b\u9762\u4e24\u884c\n        # if img_as_img.mode != 'L':\n        #     img_as_img = img_as_img.convert('L')\n        \n        #\u8bbe\u7f6e\u597d\u9700\u8981\u8f6c\u6362\u7684\u53d8\u91cf\uff0c\u8fd8\u53ef\u4ee5\u5305\u62ec\u4e00\u7cfb\u5217\u7684nomarlize\u7b49\u7b49\u64cd\u4f5c\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor()\n        ])\n        img_as_img = transform(img_as_img)\n\n\n        return img_as_img\n\n    def __len__(self):\n        return self.data_len","5b0cec83":"train_transform = transforms.Compose([\n    # \u968f\u673a\u88c1\u526a\u56fe\u50cf\uff0c\u6240\u5f97\u56fe\u50cf\u4e3a\u539f\u59cb\u9762\u79ef\u76840.08\u52301\u4e4b\u95f4\uff0c\u9ad8\u5bbd\u6bd4\u57283\/4\u548c4\/3\u4e4b\u95f4\u3002\n    # \u7136\u540e\uff0c\u7f29\u653e\u56fe\u50cf\u4ee5\u521b\u5efa224 x 224\u7684\u65b0\u56fe\u50cf\n    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0 \/ 4.0, 4.0 \/ 3.0)),\n    transforms.RandomHorizontalFlip(),\n    # \u968f\u673a\u66f4\u6539\u4eae\u5ea6\uff0c\u5bf9\u6bd4\u5ea6\u548c\u9971\u548c\u5ea6\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n    # \u6dfb\u52a0\u968f\u673a\u566a\u58f0\n    transforms.ToTensor(),\n    # \u6807\u51c6\u5316\u56fe\u50cf\u7684\u6bcf\u4e2a\u901a\u9053\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\nval_test_transform = transforms.Compose([\n    transforms.Resize(256),\n    # \u4ece\u56fe\u50cf\u4e2d\u5fc3\u88c1\u5207224x224\u5927\u5c0f\u7684\u56fe\u7247\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","172efd2d":"train_val_path = '..\/input\/classify-leaves\/train.csv'\ntest_path = '..\/input\/classify-leaves\/test.csv'\n# csv\u6587\u4ef6\u4e2d\u5df2\u7ecfimages\u7684\u8def\u5f84\u4e86\uff0c\u56e0\u6b64\u8fd9\u91cc\u53ea\u5230\u4e0a\u4e00\u7ea7\u76ee\u5f55\nimg_path = '..\/input\/classify-leaves\/'\n\ntrain_val_dataset = TrainValidData(train_val_path, img_path)\ntest_dataset = TestData(test_path, img_path, transform = val_test_transform)\nprint(train_val_dataset.data_info)\nprint(test_dataset.data_info)","248e904f":"# \u662f\u5426\u8981\u51bb\u4f4f\u6a21\u578b\u7684\u524d\u9762\u4e00\u4e9b\u5c42\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        model = model\n        for param in model.parameters():\n            param.requires_grad = False\n\n# ResNeSt\u6a21\u578b\ndef resnest_model(num_classes, feature_extract = False):\n    model_ft = resnest50(pretrained=True)\n    set_parameter_requires_grad(model_ft, feature_extract)\n    num_ftrs = model_ft.fc.in_features\n    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n\n    return model_ft","9a3e39ef":"# \u770b\u4e00\u4e0b\u662f\u5728cpu\u8fd8\u662fGPU\u4e0a\ndef get_device():\n    return 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndevice = get_device()\nprint(device)","0e12779e":"!nvidia-smi","69ebebf1":"# Configuration options\nk_folds = 5\nnum_epochs = 30\nlearning_rate = 1e-4\nweight_decay = 1e-3\ntrain_loss_function = CutMixCrossEntropyLoss(True)\nvalid_loss_function = nn.CrossEntropyLoss()\n# For fold results\nresults = {}\n\n# Set fixed random number seed\ntorch.manual_seed(42)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=k_folds, shuffle=True)","6d7e9c9b":"# Start print\nprint('--------------------------------------')\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):\n\n  # Print\n  print(f'FOLD {fold}')\n  print('--------------------------------------')\n\n  # Sample elements randomly from a given list of ids, no replacement.\n  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n\n  # Define data loaders for training and testing data in this fold\n  trainloader = torch.utils.data.DataLoader(\n                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2), \n                      batch_size=32, sampler=train_subsampler, num_workers=0)\n  validloader = torch.utils.data.DataLoader(\n                      TrainValidData(train_val_path, img_path, transform = val_test_transform),\n                      batch_size=32, sampler=valid_subsampler, num_workers=0)\n  \n  # Initialize a model and put it on the device specified.\n  model = resnest_model(176)\n  model = model.to(device)\n  model.device = device\n  \n  # Initialize optimizer\n  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)\n  scheduler = CosineAnnealingLR(optimizer,T_max=10)\n\n  # Run the training loop for defined number of epochs\n  for epoch in range(0,num_epochs):\n    model.train()\n    # Print epoch\n    print(f'Starting epoch {epoch+1}')\n    # These are used to record information in training\n    train_losses = []\n    train_accs = []\n    # Iterate the training set by batches\n    for batch in tqdm(trainloader):\n      # Move images and labels to GPU\n      imgs, labels = batch\n      imgs = imgs.to(device)\n      labels = labels.to(device)\n      # Forward the data\n      logits = model(imgs)\n      # Calculate loss\n      loss = train_loss_function(logits,labels)\n      # Clear gradients in previous step\n      optimizer.zero_grad()\n      # Compute gradients for parameters\n      loss.backward()\n      # Update the parameters with computed gradients\n      optimizer.step()\n      # Compute the accuracy for current batch.\n      # acc = (logits.argmax(dim=-1) == labels).float().mean()\n      # Record the loss and accuracy.\n      train_losses.append(loss.item())\n      # train_accs.append(acc)\n    print(\"\u7b2c%d\u4e2aepoch\u7684\u5b66\u4e60\u7387\uff1a%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n    scheduler.step()\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = np.sum(train_losses) \/ len(train_losses)\n    # train_acc = np.sum(train_accs) \/ len(train_accs)\n    # Print the information.\n    # print(f\"[ Train | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n    print(f\"[ Train | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {train_loss:.5f}\")\n\n  # Train process (all epochs) is complete\n  print('Training process has finished. Saving trained model.')\n  print('Starting validation')\n\n  # Saving the model\n  print('saving model with loss {:.3f}'.format(train_loss))\n  save_path = f'.\/model-fold-{fold}.pth'\n  torch.save(model.state_dict(),save_path)\n  # Start Validation\n  model.eval()\n  valid_losses = []\n  valid_accs = []\n  with torch.no_grad():\n    for batch in tqdm(validloader):\n      imgs, labels = batch\n      # No gradient in validation\n      logits = model(imgs.to(device))\n      loss = valid_loss_function(logits,labels.to(device))\n      acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n      # Record loss and accuracy\n      valid_losses.append(loss.item())        \n      valid_accs.append(acc)\n    # The average loss and accuracy\n    valid_loss = np.sum(valid_losses)\/len(valid_losses)\n    valid_acc = np.sum(valid_accs)\/len(valid_accs)\n    print(f\"[ Valid | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n    print('Accuracy for fold %d: %d' % (fold, valid_acc))\n    print('--------------------------------------')\n    results[fold] = valid_acc\n# Print fold results\nprint(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\nprint('--------------------------------')\ntotal_summation = 0.0\nfor key, value in results.items():\n  print(f'Fold {key}: {value} ')\n  total_summation += value\nprint(f'Average: {total_summation\/len(results.items())} ')","43e10ba8":"testloader = torch.utils.data.DataLoader(\n                      TestData(test_path, img_path, transform = val_test_transform),\n                      batch_size=32, num_workers=0)","8489c0a2":"## predict\nmodel = resnest_model(176)\n\n# create model and load weights from checkpoint\nmodel = model.to(device)\n# load the all folds\nfor test_fold in range(k_folds):\n  model_path = f'.\/model-fold-{test_fold}.pth'\n  saveFileName = f'.\/submission-fold-{test_fold}.csv'\n  model.load_state_dict(torch.load(model_path))\n\n  # Make sure the model is in eval mode.\n  # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n  model.eval()\n  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(200,200)) # Test-Time Augmentation\n\n  # Initialize a list to store the predictions.\n  predictions = []\n  # Iterate the testing set by batches.\n  for batch in tqdm(testloader):\n      \n      imgs = batch\n      with torch.no_grad():\n          logits = tta_model(imgs.to(device))\n      \n      # Take the class with greatest logit as prediction and record it.\n      predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n\n  preds = []\n  for i in predictions:\n      preds.append(num_to_class[i])\n\n  test_data = pd.read_csv(test_path)\n  test_data['label'] = pd.Series(preds)\n  submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n  submission.to_csv(saveFileName, index=False)\n  print(\"ResNeSt Model Results Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")","33785c43":"# \u8bfb\u53d65\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u7ed3\u679c\ndf0 = pd.read_csv('.\/submission-fold-0.csv')\ndf1 = pd.read_csv('.\/submission-fold-1.csv')\ndf2 = pd.read_csv('.\/submission-fold-2.csv')\ndf3 = pd.read_csv('.\/submission-fold-3.csv')\ndf4 = pd.read_csv('.\/submission-fold-4.csv')","05b443bd":"# \u5f80\u7b2c0\u6298\u7ed3\u679c\u91cc\u6dfb\u52a0\u6570\u5b57\u5316\u6807\u7b7e\u5217\nlist_num_label0 = []\nfor i in df0['label']:\n  list_num_label0.append(class_to_num[i])\ndf0['num_label0']=list_num_label0\ndf0.head()","55f4d7c6":"# \u5f80\u7b2c1\u6298\u7ed3\u679c\u91cc\u6dfb\u52a0\u6570\u5b57\u5316\u6807\u7b7e\u5217\nlist_num_label1 = []\nfor i in df1['label']:\n  list_num_label1.append(class_to_num[i])\ndf1['num_label1']=list_num_label1\ndf1.head()","fb625385":"# \u5f80\u7b2c2\u6298\u7ed3\u679c\u91cc\u6dfb\u52a0\u6570\u5b57\u5316\u6807\u7b7e\u5217\nlist_num_label2 = []\nfor i in df2['label']:\n  list_num_label2.append(class_to_num[i])\ndf2['num_label2']=list_num_label2\ndf2.head()","2de51a82":"# \u5f80\u7b2c3\u6298\u7ed3\u679c\u91cc\u6dfb\u52a0\u6570\u5b57\u5316\u6807\u7b7e\u5217\nlist_num_label3 = []\nfor i in df3['label']:\n  list_num_label3.append(class_to_num[i])\ndf3['num_label3']=list_num_label3\ndf3.head()","45c64ba5":"# \u5f80\u7b2c4\u6298\u7ed3\u679c\u91cc\u6dfb\u52a0\u6570\u5b57\u5316\u6807\u7b7e\u5217\nlist_num_label4 = []\nfor i in df4['label']:\n  list_num_label4.append(class_to_num[i])\ndf4['num_label4']=list_num_label4\ndf4.head()","ed39902e":"# \u51c6\u5907\u6574\u54085\u6298\u7684\u7ed3\u679c\u5230\u540c\u4e00\u4e2aDataFrame\ndf_all = df0.copy()\ndf_all.drop(['label'],axis=1,inplace=True)\ndf_all.head()","b72380f8":"# \u6574\u54085\u6298\u7684\u6570\u5b57\u5316\u6807\u7b7e\u7ed3\u679c\u5230\u540c\u4e00\u4e2aDataFrame\ndf_all['num_label1']=list_num_label1\ndf_all['num_label2']=list_num_label2\ndf_all['num_label3']=list_num_label3\ndf_all['num_label4']=list_num_label4\ndf_all.head()","a5d530ec":"# \u5bf9df_all\u8fdb\u884c\u8f6c\u7f6e\uff0c\u65b9\u4fbf\u6c42\u4f17\u6570\ndf_all_transpose = df_all.copy().drop(['image'],axis=1).transpose()\ndf_all_transpose.head()","797df3f8":"# \u6c42\u5f97\u6295\u7968\u4f17\u6570\ndf_mode = df_all_transpose.mode().transpose()\ndf_mode.head()","a3173e83":"# \u628a\u6295\u7968\u7ed3\u679c\u7684\u6570\u5b57\u5316\u6807\u7b7e\u8f6c\u6210\u5b57\u7b26\u4e32\u6807\u7b7e\nvoting_class = []\nfor each in df_mode[0]:\n  voting_class.append(num_to_class[each])\nvoting_class","4d7650a0":"# \u5c06\u6295\u7968\u7ed3\u679c\u7684\u5b57\u7b26\u4e32\u6807\u7b7e\u6dfb\u52a0\u5230df_all\u4e2d\ndf_all['label'] = voting_class\ndf_all.head()","82db3a00":"# \u63d0\u53d6image\u548clabel\u4e24\u5217\u4e3a\u6700\u7ec8\u7684\u7ed3\u679c\ndf_submission = df_all[['image','label']].copy()\ndf_submission.head()","06ecdf6b":"# \u4fdd\u5b58\u5f53\u524d\u6a21\u578b\u5f97\u5230\u7684\u6700\u7ec8\u7ed3\u679c\ndf_submission.to_csv('.\/submission-resnest.csv', index=False)\nprint('Voting results of resnest successfully saved!')","abe66d60":"# \u662f\u5426\u8981\u51bb\u4f4f\u6a21\u578b\u7684\u524d\u9762\u4e00\u4e9b\u5c42\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        model = model\n        for param in model.parameters():\n            param.requires_grad = False\n\n# resnext50_32x4d\u6a21\u578b\ndef resnext_model(num_classes, feature_extract = False, use_pretrained=True):\n\n    model_ft = models.resnext50_32x4d(pretrained=use_pretrained)\n    set_parameter_requires_grad(model_ft, feature_extract)\n    num_ftrs = model_ft.fc.in_features\n    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n\n    return model_ft","a2d53515":"# Configuration options\nk_folds = 5\nnum_epochs = 30\nlearning_rate = 1e-3\nweight_decay = 1e-3\ntrain_loss_function = CutMixCrossEntropyLoss(True)\nvalid_loss_function = nn.CrossEntropyLoss()\n# For fold results\nresults = {}\n\n# Set fixed random number seed\ntorch.manual_seed(42)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=k_folds, shuffle=True)","e4030dba":"# Start print\nprint('--------------------------------------')\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):\n\n  # Print\n  print(f'FOLD {fold}')\n  print('--------------------------------------')\n\n  # Sample elements randomly from a given list of ids, no replacement.\n  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n\n  # Define data loaders for training and testing data in this fold\n  trainloader = torch.utils.data.DataLoader(\n                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2), \n                      batch_size=128, sampler=train_subsampler, num_workers=0)\n  validloader = torch.utils.data.DataLoader(\n                      TrainValidData(train_val_path, img_path, transform = val_test_transform),\n                      batch_size=128, sampler=valid_subsampler, num_workers=0)\n  \n  # Initialize a model and put it on the device specified.\n  model = resnext_model(176)\n  model = model.to(device)\n  model.device = device\n  \n  # Initialize optimizer\n  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)\n#   optimizer = SWA(our_optimizer, swa_start=5, swa_freq =5, swa_lr=0.05)\n  scheduler = CosineAnnealingLR(optimizer,T_max=10)\n\n  # Run the training loop for defined number of epochs\n  for epoch in range(0,num_epochs):\n    model.train()\n    # Print epoch\n    print(f'Starting epoch {epoch+1}')\n    # These are used to record information in training\n    train_losses = []\n    train_accs = []\n    # Iterate the training set by batches\n    for batch in tqdm(trainloader):\n      # Move images and labels to GPU\n      imgs, labels = batch\n      imgs = imgs.to(device)\n      labels = labels.to(device)\n      # Forward the data\n      logits = model(imgs)\n      # Calculate loss\n      loss = train_loss_function(logits,labels)\n      # Clear gradients in previous step\n      optimizer.zero_grad()\n      # Compute gradients for parameters\n      loss.backward()\n      # Update the parameters with computed gradients\n      optimizer.step()\n      # Compute the accuracy for current batch.\n      # acc = (logits.argmax(dim=-1) == labels).float().mean()\n      # Record the loss and accuracy.\n      train_losses.append(loss.item())\n      # train_accs.append(acc)\n    print(\"\u7b2c%d\u4e2aepoch\u7684\u5b66\u4e60\u7387\uff1a%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n    scheduler.step()\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = np.sum(train_losses) \/ len(train_losses)\n    # train_acc = np.sum(train_accs) \/ len(train_accs)\n    # Print the information.\n    # print(f\"[ Train | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n    print(f\"[ Train | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {train_loss:.5f}\")\n\n  # Train process (all epochs) is complete\n  print('Training process has finished. Saving trained model.')\n  print('Starting validation')\n\n  # Saving the model\n  print('saving model with loss {:.3f}'.format(train_loss))\n  save_path = f'.\/model-fold-{fold}.pth'\n  torch.save(model.state_dict(),save_path)\n  # Start Validation\n  model.eval()\n  valid_losses = []\n  valid_accs = []\n  with torch.no_grad():\n    for batch in tqdm(validloader):\n      imgs, labels = batch\n      # No gradient in validation\n      logits = model(imgs.to(device))\n      loss = valid_loss_function(logits,labels.to(device))\n      acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n      # Record loss and accuracy\n      valid_losses.append(loss.item())        \n      valid_accs.append(acc)\n    # The average loss and accuracy\n    valid_loss = np.sum(valid_losses)\/len(valid_losses)\n    valid_acc = np.sum(valid_accs)\/len(valid_accs)\n    print(f\"[ Valid | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n    print('Accuracy for fold %d: %d' % (fold, valid_acc))\n    print('--------------------------------------')\n    results[fold] = valid_acc\n# Print fold results\nprint(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\nprint('--------------------------------')\ntotal_summation = 0.0\nfor key, value in results.items():\n  print(f'Fold {key}: {value} ')\n  total_summation += value\nprint(f'Average: {total_summation\/len(results.items())} ')","b8550ec3":"testloader = torch.utils.data.DataLoader(\n                      TestData(test_path, img_path, transform = val_test_transform),\n                      batch_size=128, num_workers=0)","7447074a":"## predict\nmodel = resnext_model(176)\n\n# create model and load weights from checkpoint\nmodel = model.to(device)\n# load the all folds\nfor test_fold in range(k_folds):\n  model_path = f'.\/model-fold-{test_fold}.pth'\n  saveFileName = f'.\/submission-fold-{test_fold}.csv'\n  model.load_state_dict(torch.load(model_path))\n\n  # Make sure the model is in eval mode.\n  # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n  model.eval()\n  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(200,200))\n\n  # Initialize a list to store the predictions.\n  predictions = []\n  # Iterate the testing set by batches.\n  for batch in tqdm(testloader):\n      \n      imgs = batch\n      with torch.no_grad():\n          logits = tta_model(imgs.to(device))\n      \n      # Take the class with greatest logit as prediction and record it.\n      predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n\n  preds = []\n  for i in predictions:\n      preds.append(num_to_class[i])\n\n  test_data = pd.read_csv(test_path)\n  test_data['label'] = pd.Series(preds)\n  submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n  submission.to_csv(saveFileName, index=False)\n  print(\"ResNeXt Model Results Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")","9cbb164b":"df0 = pd.read_csv('.\/submission-fold-0.csv')\ndf1 = pd.read_csv('.\/submission-fold-1.csv')\ndf2 = pd.read_csv('.\/submission-fold-2.csv')\ndf3 = pd.read_csv('.\/submission-fold-3.csv')\ndf4 = pd.read_csv('.\/submission-fold-4.csv')","84cc4902":"list_num_label0 = []\nfor i in df0['label']:\n  list_num_label0.append(class_to_num[i])\ndf0['num_label0']=list_num_label0\ndf0.head()","f63c197a":"list_num_label1 = []\nfor i in df1['label']:\n  list_num_label1.append(class_to_num[i])\ndf1['num_label1']=list_num_label1\ndf1.head()","7b67fc31":"list_num_label2 = []\nfor i in df2['label']:\n  list_num_label2.append(class_to_num[i])\ndf2['num_label2']=list_num_label2\ndf2.head()","528601f6":"list_num_label3 = []\nfor i in df3['label']:\n  list_num_label3.append(class_to_num[i])\ndf3['num_label3']=list_num_label3\ndf3.head()","da49763e":"list_num_label4 = []\nfor i in df4['label']:\n  list_num_label4.append(class_to_num[i])\ndf4['num_label4']=list_num_label4\ndf4.head()","e01648cf":"df_all = df0.copy()\ndf_all.drop(['label'],axis=1,inplace=True)\ndf_all.head()","d16455e9":"df_all['num_label1']=list_num_label1\ndf_all['num_label2']=list_num_label2\ndf_all['num_label3']=list_num_label3\ndf_all['num_label4']=list_num_label4\ndf_all.head()","213e7634":"df_all_transpose = df_all.copy().drop(['image'],axis=1).transpose()\ndf_all_transpose.head()","ab48f319":"df_mode = df_all_transpose.mode().transpose()\ndf_mode.head()","16e6b497":"voting_class = []\nfor each in df_mode[0]:\n  voting_class.append(num_to_class[each])\nvoting_class","92dc28ff":"df_all['label'] = voting_class\ndf_all.head()","cc643a2b":"df_submission = df_all[['image','label']].copy()\ndf_submission.head()","29abab89":"df_submission.to_csv('.\/submission-resnext.csv', index=False)\nprint('ResNeXt voting results successfully saved!')","a1a17156":"# \u662f\u5426\u8981\u51bb\u4f4f\u6a21\u578b\u7684\u524d\u9762\u4e00\u4e9b\u5c42\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        model = model\n        for param in model.parameters():\n            param.requires_grad = False\n\n# densenet161\u6a21\u578b\ndef dense_model(num_classes, feature_extract = False, use_pretrained=True):\n\n    model_ft = models.densenet161(pretrained=use_pretrained)\n    set_parameter_requires_grad(model_ft, feature_extract)\n    num_ftrs = model_ft.classifier.in_features\n    model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n\n    return model_ft","44c28bd8":"# Configuration options\nk_folds = 5\nnum_epochs = 30\nlearning_rate = 1e-4\nweight_decay = 1e-3\ntrain_loss_function = CutMixCrossEntropyLoss(True)\nvalid_loss_function = nn.CrossEntropyLoss()\n# For fold results\nresults = {}\n\n# Set fixed random number seed\ntorch.manual_seed(42)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=k_folds, shuffle=True)","2e42e3f2":"# Start print\nprint('--------------------------------------')\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids,valid_ids) in enumerate(kfold.split(train_val_dataset)):\n\n  # Print\n  print(f'FOLD {fold}')\n  print('--------------------------------------')\n\n  # Sample elements randomly from a given list of ids, no replacement.\n  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n  valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n\n  # Define data loaders for training and testing data in this fold\n  trainloader = torch.utils.data.DataLoader(\n                      CutMix(TrainValidData(train_val_path, img_path, transform = train_transform), num_class=176, beta=1.0, prob=0.5, num_mix=2), \n                      batch_size=32, sampler=train_subsampler, num_workers=0)\n  validloader = torch.utils.data.DataLoader(\n                      TrainValidData(train_val_path, img_path, transform = val_test_transform),\n                      batch_size=32, sampler=valid_subsampler, num_workers=0)\n  \n  # Initialize a model and put it on the device specified.\n  model = dense_model(176)\n  model = model.to(device)\n  model.device = device\n  \n  # Initialize optimizer\n  optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay= weight_decay)\n  scheduler = CosineAnnealingLR(optimizer,T_max=10)\n\n  # Run the training loop for defined number of epochs\n  for epoch in range(0,num_epochs):\n    model.train()\n    # Print epoch\n    print(f'Starting epoch {epoch+1}')\n    # These are used to record information in training\n    train_losses = []\n    train_accs = []\n    # Iterate the training set by batches\n    for batch in tqdm(trainloader):\n      # Move images and labels to GPU\n      imgs, labels = batch\n      imgs = imgs.to(device)\n      labels = labels.to(device)\n      # Forward the data\n      logits = model(imgs)\n      # Calculate loss\n      loss = train_loss_function(logits,labels)\n      # Clear gradients in previous step\n      optimizer.zero_grad()\n      # Compute gradients for parameters\n      loss.backward()\n      # Update the parameters with computed gradients\n      optimizer.step()\n      # Compute the accuracy for current batch.\n#       acc = (logits.argmax(dim=-1) == labels).float().mean()\n      # Record the loss and accuracy.\n      train_losses.append(loss.item())\n#       train_accs.append(acc)\n    print(\"\u7b2c%d\u4e2aepoch\u7684\u5b66\u4e60\u7387\uff1a%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n    scheduler.step()\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = np.sum(train_losses) \/ len(train_losses)\n#     train_acc = np.sum(train_accs) \/ len(train_accs)\n    # Print the information.\n#     print(f\"[ Train | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n    print(f\"[ Train | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {train_loss:.5f}\")\n\n  # Train process (all epochs) is complete\n  print('Training process has finished. Saving trained model.')\n  print('Starting validation')\n\n  # Saving the model\n  print('saving model with loss {:.3f}'.format(train_loss))\n  save_path = f'.\/model-fold-{fold}.pth'\n  torch.save(model.state_dict(),save_path)\n  # Start Validation\n  model.eval()\n  valid_losses = []\n  valid_accs = []\n  with torch.no_grad():\n    for batch in tqdm(validloader):\n      imgs, labels = batch\n      # No gradient in validation\n      logits = model(imgs.to(device))\n      loss = valid_loss_function(logits,labels.to(device))\n      acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n      # Record loss and accuracy\n      valid_losses.append(loss.item())        \n      valid_accs.append(acc)\n    # The average loss and accuracy\n    valid_loss = np.sum(valid_losses)\/len(valid_losses)\n    valid_acc = np.sum(valid_accs)\/len(valid_accs)\n    print(f\"[ Valid | {epoch + 1:03d}\/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n    print('Accuracy for fold %d: %d' % (fold, valid_acc))\n    print('--------------------------------------')\n    results[fold] = valid_acc\n# Print fold results\nprint(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\nprint('--------------------------------')\ntotal_summation = 0.0\nfor key, value in results.items():\n  print(f'Fold {key}: {value} ')\n  total_summation += value\nprint(f'Average: {total_summation\/len(results.items())} ')","f29b18ec":"testloader = torch.utils.data.DataLoader(\n                      TestData(test_path, img_path, transform = val_test_transform),\n                      batch_size=32, num_workers=0)","d989c6d3":"## predict\nmodel = dense_model(176)\n\n# create model and load weights from checkpoint\nmodel = model.to(device)\n# load the all folds\nfor test_fold in range(k_folds):\n  model_path = f'.\/model-fold-{test_fold}.pth'\n  saveFileName = f'.\/submission-fold-{test_fold}.csv'\n  model.load_state_dict(torch.load(model_path))\n\n  # Make sure the model is in eval mode.\n  # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n  model.eval()\n  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(200,200))\n\n  # Initialize a list to store the predictions.\n  predictions = []\n  # Iterate the testing set by batches.\n  for batch in tqdm(testloader):\n      \n      imgs = batch\n      with torch.no_grad():\n          logits = tta_model(imgs.to(device))\n      \n      # Take the class with greatest logit as prediction and record it.\n      predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n\n  preds = []\n  for i in predictions:\n      preds.append(num_to_class[i])\n\n  test_data = pd.read_csv(test_path)\n  test_data['label'] = pd.Series(preds)\n  submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n  submission.to_csv(saveFileName, index=False)\n  print(\"Dense Model Results Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")","5eb69b6c":"df0 = pd.read_csv('.\/submission-fold-0.csv')\ndf1 = pd.read_csv('.\/submission-fold-1.csv')\ndf2 = pd.read_csv('.\/submission-fold-2.csv')\ndf3 = pd.read_csv('.\/submission-fold-3.csv')\ndf4 = pd.read_csv('.\/submission-fold-4.csv')","61257c44":"list_num_label0 = []\nfor i in df0['label']:\n  list_num_label0.append(class_to_num[i])\ndf0['num_label0']=list_num_label0\ndf0.head()","5d924782":"list_num_label1 = []\nfor i in df1['label']:\n  list_num_label1.append(class_to_num[i])\ndf1['num_label1']=list_num_label1\ndf1.head()","6ee1d722":"list_num_label2 = []\nfor i in df2['label']:\n  list_num_label2.append(class_to_num[i])\ndf2['num_label2']=list_num_label2\ndf2.head()","27a9a968":"list_num_label3 = []\nfor i in df3['label']:\n  list_num_label3.append(class_to_num[i])\ndf3['num_label3']=list_num_label3\ndf3.head()","17c08797":"list_num_label4 = []\nfor i in df4['label']:\n  list_num_label4.append(class_to_num[i])\ndf4['num_label4']=list_num_label4\ndf4.head()","a4caa855":"df_all = df0.copy()\ndf_all.drop(['label'],axis=1,inplace=True)\ndf_all.head()","319945ad":"df_all['num_label1']=list_num_label1\ndf_all['num_label2']=list_num_label2\ndf_all['num_label3']=list_num_label3\ndf_all['num_label4']=list_num_label4\ndf_all.head()","3bc68fe3":"df_all_transpose = df_all.copy().drop(['image'],axis=1).transpose()\ndf_all_transpose.head()","721a10cb":"df_mode = df_all_transpose.mode().transpose()\ndf_mode.head()","deba43de":"voting_class = []\nfor each in df_mode[0]:\n  voting_class.append(num_to_class[each])\nvoting_class","2cf7e7fe":"df_all['label'] = voting_class\ndf_all.head()","ede956da":"df_submission = df_all[['image','label']].copy()\ndf_submission.head()","ca71478e":"df_submission.to_csv('.\/submission-densenet.csv', index=False)\nprint('Densenet results successfully saved!')","ae4954f3":"df_resnest = pd.read_csv('..\/input\/classify-leaves-results\/submission-resnest.csv')\ndf_resnext = pd.read_csv('..\/input\/classify-leaves-results\/submission-resnext.csv')\ndf_densenet = pd.read_csv('..\/input\/classify-leaves-results\/submission-densenet.csv')","8336eb48":"df_all = df_resnest.copy()\ndf_all.rename(columns = {'label':'label_resnest'},inplace=True)\ndf_all['label_resnext'] = df_resnext.copy()['label']\ndf_all['label_densenet'] = df_densenet.copy()['label']\ndf_all.head()","8299df60":"df_all['label']=0\nfor rows in range(len(df_all)):\n    if (df_all['label_resnest'].iloc[rows]==df_all['label_resnext'].iloc[rows]) or (df_all['label_resnest'].iloc[rows]==df_all['label_densenet'].iloc[rows]):\n        df_all['label'].iloc[rows] = df_all.copy()['label_resnest'].iloc[rows]\n    elif df_all['label_resnext'].iloc[rows]==df_all['label_densenet'].iloc[rows]:\n        df_all['label'].iloc[rows] = df_all.copy()['label_resnext'].iloc[rows]\n    else:\n        df_all['label'].iloc[rows] = df_all.copy()['label_resnest'].iloc[rows]\ndf_all.head()","1bb3b741":"df_final = df_all.copy()[['image','label']]\ndf_final.head()","48fc4681":"df_final.to_csv('.\/submission.csv', index=False)\nprint('Final results successfully saved!')","950c4560":"## **\u6811\u53f6\u5206\u7c7b\u8bfe\u7a0b\u7ade\u8d5b**\n- \u9996\u5148\u8981\u591a\u8c22Neko Kiku\u63d0\u4f9b\u7684baseline\u4ee3\u7801\uff0c\u601d\u8def\u975e\u5e38\u6e05\u6670\uff1b\n- \u672c\u4ee3\u7801\u601d\u60f3\u5f88\u7b80\u5355\uff0c\u4e09\u4e2a\u81ed\u76ae\u5320\u8d5b\u8fc7\u8bf8\u845b\u4eae\uff0c\u603b\u5171\u8bad\u7ec3\u4e863\u4e2a\u4f18\u79c0\u7684\u6a21\u578b\uff08ResNeSt+ResNeXt+DenseNet\uff09,\u6700\u540e\u8fdb\u884c\u96c6\u6210\uff0c\u7ed3\u679c\u4f1a\u66f4\u52a0\u9c81\u68d2\uff08\u516c\u699c\u7b2c12\u5347\u5230\u79c1\u699c\u7b2c7\u4e5f\u4fa7\u9762\u53cd\u6620\u4e86\u5176\u9c81\u68d2\u6027\uff09\uff1b\n- \u4ee3\u7801\u662f\u5728\u672c\u5730\u8ba1\u7b97\u673a\u4e0a\u8dd1\u7684\uff0c\u7531\u4e8eKaggle\u7684\u8fd0\u884c\u65f6\u95f4\u6709\u9650\u5236\uff0c\u65e0\u6cd5\u5206\u4eab\u8fd0\u884c\u5b8c\u6240\u6709\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u6211\u5c06\u6211\u672c\u5730\u5404\u4e2a\u6a21\u578b\u8fd0\u884c\u7684\u7ed3\u679c\u9644\u5728\u4e86input\u6587\u4ef6\u5939\u91cc\u63d0\u4f9b\u7ed3\u679c\u53c2\u8003\uff0c\u4ee5\u53ca\u65b9\u4fbf\u8d70\u5b8c\u4ee3\u7801\u6574\u4e2a\u6d41\u7a0b\uff1b\n- \u603b\u7ed3\u4e86\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u7684\u51e0\u4e2a\u5c0f\u6280\u5de7\uff1a\n1. \u6570\u636e\u589e\u5f3a\uff1a\u7279\u522b\u662fCutMix\u548c\u9884\u6d4b\u65f6\u5019\u5bf9test\u6837\u672c\u8fdb\u884cTTA(Test Time Augmentation);\n2. \u6a21\u578b\uff1a\u53ef\u4f7f\u7528\u8868\u73b0\u8f83\u597d\u7684\u9884\u8bad\u7ec3\u8fc7\u7684\u6a21\u578b\uff1b\n3. \u4f18\u5316\u5668\uff1a\u4f7f\u7528AdamW\uff08\u5bf9\u4e8e\u542b\u6709L2\u6b63\u5219\u9879\u7684\u4f18\u5316\uff0c\u5982weight decay\uff09\uff0c\u5b66\u4e60\u7387\u91c7\u7528cosine\u5b66\u4e60\u7387CosineAnnealingLR;\n4. \u4ea4\u53c9\u9a8c\u8bc1\uff1a\u4f7f\u7528K\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff1b","f40a701c":"### **\u6570\u636e\u8bfb\u53d6\u4e0e\u9884\u5904\u7406**","f12f7f96":"## **\u57fa\u4e8eDenseNet\u6a21\u578b\u90e8\u5206**","4b7a8cfa":"### **ResNeXt\u6a21\u578b**","dcc90703":"## **\u57fa\u4e8eResNeXt\u6a21\u578b\u90e8\u5206**","040e1089":"### **\u9884\u6d4b**","1275b416":"### **ResNeSt\u76845\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u7ed3\u679c\u6295\u7968**","2e72806f":"### **\u8bad\u7ec3**","d81d3d8f":"### **ResNeXt\u76845\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u7ed3\u679c\u6295\u7968**","d1334dc5":"### **\u9884\u6d4b**","d1487e1e":"## **\u57fa\u4e8eResNeSt\u6a21\u578b\u90e8\u5206**","6803cbd6":"### **\u9884\u6d4b**","5f86316b":"### **\u8bad\u7ec3**","f52bf88d":"## **\u6700\u7ec8\u7ed3\u679c\u96c6\u6210\uff08\u6295\u7968\u65b9\u5f0f\uff09**","64339921":"### **\u6574\u7406\u6570\u636e\u96c6**","d430432e":"### **DenseNet\u6a21\u578b**","df0389e6":"### **DenseNet\u76845\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u7ed3\u679c\u6295\u7968**","d993fbb3":"### **\u8bad\u7ec3**","57c71b28":"### **ResNeSt\u6a21\u578b**"}}