{"cell_type":{"e5ec710f":"code","9cfd2897":"code","f2d41e26":"code","f548c0aa":"code","0f15c8f8":"code","3dd2e471":"code","80e29997":"code","54d0c749":"code","feb77f77":"code","0e67ddab":"code","ef34815d":"code","83700657":"code","e91ea2fb":"code","3ac107e3":"code","57ca616c":"code","4aebb070":"code","61734cd7":"code","5119b956":"code","529ae409":"code","207f5a86":"code","08b37a7f":"code","64446463":"code","9d6bddd1":"code","8f189500":"code","e398732a":"code","114069ed":"code","f615e11b":"code","c6be296a":"markdown","1619a107":"markdown","4655fe82":"markdown","20f9f42f":"markdown","4c039361":"markdown","685f7efb":"markdown","0e5d797d":"markdown","b641eb14":"markdown","5fe21092":"markdown","194d26f9":"markdown","04c05eaa":"markdown","a56b29c8":"markdown","4c0e63a2":"markdown","f6fc8a10":"markdown","741a944f":"markdown","fa8051f0":"markdown","e24b1c9b":"markdown","1ba80b18":"markdown","b05f2a8c":"markdown","803d4e28":"markdown"},"source":{"e5ec710f":"#python basics\nfrom matplotlib import pyplot as plt\nimport math, os, re, time, random\nimport numpy as np, pandas as pd, seaborn as sns\n\n#bare minimum to use tensorflow\nimport tensorflow as tf\n\n#for model evaluation\nfrom sklearn.model_selection import train_test_split","9cfd2897":"#create a rank 0 tensor\nrank_0_tensor = tf.constant(1)\nprint(rank_0_tensor); print('')\n\n#create a rank 1 tensor\nrank_1_tensor = tf.constant([1, 0, 0])\nprint(rank_1_tensor); print('')\n\n#create a rank 2 tensor\nrank_2_tensor = tf.constant([[1, 0, 0],\n                             [0, 1, 0],\n                             [0, 0, 1]])\nprint(rank_2_tensor)","f2d41e26":"#create a rank 0 tensor\nrank_0_tensor = tf.constant(1, dtype = tf.float16)\nprint(rank_0_tensor); print('')\n\n#create a rank 1 tensor\nrank_1_tensor = tf.constant([1, 0, 0], dtype = tf.float32)\nprint(rank_1_tensor); print('')\n\n#create a rank 2 tensor\nrank_2_tensor = tf.constant([[1, 0, 0],\n                             [0, 1, 0],\n                             [0, 0, 1]], dtype = tf.int32)\nprint(rank_2_tensor)","f548c0aa":"print(f\"Element type: {rank_2_tensor.dtype}\")\nprint(f\"Number of dimensions: {rank_2_tensor.ndim}\")\nprint(f\"Shape of tensor: {rank_2_tensor.shape}\")\nprint(f\"Elements along axis 0 of tensor: {rank_2_tensor.shape[0]}\")\nprint(f\"Elements along the last axis of tensor: {rank_2_tensor.shape[-1]}\")\nprint(f\"Total number of elements: {tf.size(rank_2_tensor).numpy()}\")","0f15c8f8":"#convert to NumPy array with .numpy()\nprint(type(rank_2_tensor.numpy()))\nprint(rank_2_tensor.numpy()); print('')\n\n#convert to NumPy array by performing np operation on it\ntensor_to_array = np.add(rank_2_tensor, 1)\nprint(type(tensor_to_array))\nprint(tensor_to_array); print('')\n\n#convert to tensor by performing tf operation on it\narray_to_tensor = tf.add(rank_2_tensor.numpy(), 1)\nprint(array_to_tensor)","3dd2e471":"model = tf.keras.models.Sequential()\n\n#add relu activated layer with 256 nodes\nmodel.add(tf.keras.layers.Dense(256, activation='relu', input_shape = (784,)))\n\n#add swish activated layer with 128 nodes\nmodel.add(tf.keras.layers.Dense(128, activation='swish'))\n\n#add softmax output layer that predicts 10 different classes\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n\n#compile model \nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n\n#check model architecture\nmodel.summary()","80e29997":"model = tf.keras.models.Sequential([\n\n#add relu activated layer with 256 nodes\ntf.keras.layers.Dense(256, activation = 'relu', input_shape = (784,)),\n\n#add swish activated layer with 128 nodes\ntf.keras.layers.Dense(128, activation = 'swish'),\n\n#add softmax output layer that predicts 10 different classes\ntf.keras.layers.Dense(10, activation = 'softmax')\n    \n])\n\n#compile model \nmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])\n\n#check model architecture\nmodel.summary()","54d0c749":"#define an input\ninputs = tf.keras.Input(shape = (784,))\n\n#add a relu layer to act on the inputs\nx = tf.keras.layers.Dense(256, activation = 'relu')(inputs)\n\n#repeat with swish layer\nx = tf.keras.layers.Dense(128, activation = 'swish')(x)\n\n#define outputs\noutputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n\n#build model with inputs\/outputs\nmodel = tf.keras.Model(inputs = inputs, outputs = outputs)\n\n#compile model \nmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])\n\n#check model architecture\nmodel.summary()","feb77f77":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\n#sneak peek\ntrain.head()","0e67ddab":"#sneak peek\ntest.head()","ef34815d":"#remove label from train and store as separate dataframe\nlabels = train['label']\ntrain = train.drop('label', axis = 1)\n\ntrain = train \/ 255.0\ntest = test \/ 255.0","83700657":"train = train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","e91ea2fb":"labels = tf.one_hot(labels, depth = 10).numpy()","3ac107e3":"#view sample image from our training set\nplt.imshow(train[5][:,:,0], cmap = plt.cm.binary);","57ca616c":"#demo ImageDataGenerator functionality\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n                                                          rotation_range = 20,  \n                                                          zoom_range = 0.1,  \n                                                          width_shift_range = 0.1, \n                                                          height_shift_range = 0.1\n)","4aebb070":"#preview augmented images from generator\nsample = train[9,].reshape((1,28,28,1))\nsample_labels = labels[9,].reshape((1,10))\nplt.figure(figsize=(15,4.5))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    train2, labels2 = datagen.flow(sample,sample_labels).next()\n    plt.imshow(train2[0].reshape((28,28)),cmap = plt.cm.binary)\n    plt.axis('off')\nplt.subplots_adjust(wspace=-0.1, hspace=-0.1)\nplt.show()","61734cd7":"#how many epochs to train each CNN\nEPOCHS = 45\n\n#batch size of each CNN\nBATCH_SIZE = 64\n\n#how many CNNs to create and train\nNUM_NETS = 25\n\n#for training progress\nVERBOSE = 0","5119b956":"#build and train NUM_NETS different CNNs\nmodel = [0] * NUM_NETS\nfor j in range(NUM_NETS):\n    model[j] = tf.keras.models.Sequential()\n\n    model[j].add(tf.keras.layers.Conv2D(32, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1)))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Conv2D(32, kernel_size = 3, activation = 'relu'))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Conv2D(32, kernel_size = 5, strides = 2, padding = 'same', activation = 'relu'))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Dropout(0.4))\n\n    model[j].add(tf.keras.layers.Conv2D(64, kernel_size = 3, activation = 'relu'))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Conv2D(64, kernel_size = 3, activation = 'relu'))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Conv2D(64, kernel_size = 5, strides = 2, padding = 'same', activation = 'relu'))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Dropout(0.4))\n\n    model[j].add(tf.keras.layers.Conv2D(128, kernel_size = 4, activation = 'relu'))\n    model[j].add(tf.keras.layers.BatchNormalization())\n    model[j].add(tf.keras.layers.Flatten())\n    model[j].add(tf.keras.layers.Dropout(0.4))\n    model[j].add(tf.keras.layers.Dense(10, activation = 'softmax'))\n\n    model[j].compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])","529ae409":"#lower learning rate each epoch\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n\n#create list to add training history to\nhistory = [0] * NUM_NETS\n\nfor j in range(NUM_NETS):\n    #create a validation set to evaluate our model(s) performance\n    X_train, X_val, y_train, y_val = train_test_split(train, labels, test_size = 0.1)\n    STEPS_PER_EPOCH = X_train.shape[0] \/\/ 64\n    \n    history[j] = model[j].fit_generator(datagen.flow(X_train, y_train, batch_size = BATCH_SIZE),\n                                        epochs = EPOCHS, steps_per_epoch = STEPS_PER_EPOCH,  \n                                        validation_data = (X_val, y_val), callbacks = [lr_callback],\n                                        verbose = VERBOSE)\n    \n    #display training results\n    print(f\"CNN {j + 1}: Epochs={EPOCHS}, Train accuracy={max(history[j].history['categorical_accuracy'])}, Validation accuracy={max(history[j].history['val_categorical_accuracy'])}\")","207f5a86":"#define function to visualize learning curves\ndef plot_learning_curves(histories): \n    fig, ax = plt.subplots(1, 2, figsize = (20, 10))\n    \n    #plot accuracies\n    for i in range(0, NUM_NETS):\n        ax[0].plot(histories[i].history['categorical_accuracy'], color = 'C0')\n        ax[0].plot(histories[i].history['val_categorical_accuracy'], color = 'C1')\n\n    #plot losses\n    for i in range(0, NUM_NETS):\n        ax[1].plot(histories[i].history['loss'], color = 'C0')\n        ax[1].plot(histories[i].history['val_loss'], color = 'C1')\n\n    #create legend\n    ax[0].legend(['train', 'validation'], loc = 'upper left')\n    ax[1].legend(['train', 'validation'], loc = 'upper right')\n    \n    #set master title\n    fig.suptitle(\"Model Performance\", fontsize=14)\n    \n    #label axis\n    ax[0].set_ylabel('Accuracy')\n    ax[0].set_xlabel('Epoch')\n    ax[1].set_ylabel('Loss')\n    ax[1].set_xlabel('Epoch')\n    \nplot_learning_curves(history)","08b37a7f":"#average predictions\npreds = np.zeros( (test.shape[0],10) ) \nfor j in range(NUM_NETS):\n    preds += model[j].predict(test) \/ NUM_NETS\n    \n#save raw predictions to disk to experiment with further ensembling\nprobs = pd.DataFrame(preds)\nprobs.to_csv('ensemble_probs')\nprobs.columns = probs.columns.astype(str)\n\nprint(probs.columns)\nprobs.head()","64446463":"#steal ids from sample submission\nsubmission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission['Label'] = preds.argmax(axis = 1)\nsubmission.to_csv(\"ensemble.csv\", index = False)\nsubmission.head(10)","9d6bddd1":"#sanity check\nsubmission.shape","8f189500":"prev_cnn_probs = pd.read_csv('..\/input\/mnistsavedprobs\/ensemble_probs')\nprev_cnn_probs = prev_cnn_probs.drop('Unnamed: 0', axis = 1)      #for formatting reasons\nprint(prev_cnn_probs.columns)\nprev_cnn_probs.head()","e398732a":"#make new probabilites by blending with past training results\nnew_probs = probs.add(prev_cnn_probs).divide(2)\nnew_probs.head()","114069ed":"#steal ids from sample submission\nsubmission2 = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission2['Label'] = new_probs.values.argmax(axis = 1)\nsubmission2.to_csv(\"ensemble2.csv\", index = False)\nsubmission2.head(10)","f615e11b":"#sanity check\nsubmission2.shape","c6be296a":"**We can see the effects of augmentation from the above graph. The training accuracy and loss for all the CNNs is roughly the same, but the *validation* accuracy and loss are different. This shows that each of these models trains similarly, but they *generalize* differently, so averaging their predictions will result in even better generalization.**","1619a107":"# Submission\n\n**Last but not least, we need to create a submission file for Kaggle. We simply predict with each model that we trained and average them for our final predictions.**\n\n**Once these models finish training and predicting, you can save their predictions as a `.csv` file to import offline for further prediction blending and experimentation:**\n\n### 1. This Submission","4655fe82":"**Now, the last way to build a NN with `tf.keras` is with the Functional API where you begin with the `Input` and chain layer calls to specify how the model does its forward pass, and then you define the model from inputs and outputs:**","20f9f42f":"**Now we can view some training samples with `plt.imshow` remembering that our images are in the shape `batchsize, 28, 28, 1`, so we select only the first two dimensions like so:** ","4c039361":"**Now that we have explored tensors and building neural networks with `tf.keras`, let's proceed by building a neural network to classify handwritten digits:**","685f7efb":"# TensorFlow Overview\n\n**TensorFlow is an end-to-end open source platform for machine learning. You can use `tf.keras` as a high-level API to build and train neural networks in TensorFlow. As you can read about [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/Model), these `tf.keras` models can take NumPy arrays, dictionaries, and tensor-objects as inputs.**\n\n**Arrays and dictionaries we are familiar with, but tensors are new. Before asking *what* a tensor is, let's ask *why* we would use them instead of these other more familiar Python objects. For one, we can put tensors into a `tf.data` dataset or a generator and access them in batches so that the full dataset never needs to be loaded into memory. This is particularly useful in computer vision problems because we can apply augmentation actively during training (more on this later in the notebook) and save precious memory space.**\n\n**Furthermore, once we have data in these tensor-based objects, we can easily train with GPUs and TPUs. You can perform computations on these datasets with local GPU devices or TPU clouds for significantly faster training. While I won't demonstrate this local GPU training\/cloud TPU training in this notebook, you can read more about it [here](https:\/\/www.tensorflow.org\/guide\/gpu) and [here](https:\/\/www.tensorflow.org\/guide\/tpu) and there are many Kaggle notebooks on the subject (I have some).**\n\n\n### 1. Tensors\n\n**So, what is a tensor? You can think of a tensor as a multi-dimensional array: a number is a rank 0 tensor, vectors are rank 1 tensors, matrices are rank 2 tensors, and so on to higher dimensions. While this definition is far too loose for the mathematician or physicist, it will work for ML purposes.**\n\n**Let's quickly explore these tensor objects:**","0e5d797d":"### Augmentation\n\n**This is where we convert our data to tensors: `tf.keras.preprocessing.image.ImageDataGenerator` creates batches of tensor image data with real-time (online) augmentation. Note that augmenting during training is different than generating additional samples via augmentation and adding them before training. In the latter, augmentation is applied as a preprocessing step to increase the size of the data, so the model will see an augmented images multiple times during training (depending on the number of epochs). With online augmentation, the model sees different images at each epoch, so the model generalizes better since it has seen more *unique* samples.**\n\n**I have applied random rotations, zooms, and shifts to the images. For a full list of the augmentations that can be applied with `ImageDataGenerator` see [here](https:\/\/keras.io\/api\/preprocessing\/image\/). In general, you want to augment your images as much as possible without changing the meaning of the image. What do I mean by this? Well, it makes since to perform vertical flips with images of flowers because a vertically flipped sunflower still looks like a sunflower. But a vertically flipped 6 is a 9...and a flipped 4 is nothing, so we shouldn't apply these transformations for our images. The augmentations you perform and the extent to which you perform them is specific to the task at hand.**\n\n**So for our digit images, we rotate them, but not too much to the point that 6's become 9's; we zoom in on them, but not to the point that a 9 becomes a 1; etc.**","b641eb14":"# Model Training\n\n**Neural networks are random in nature because of the fact that the weights of the nodes in each layer are randomly initalized at the beginning of training. From an experimental perspective, this means we need to run many experiments with the same parameters and average their results to compare different model architectures, augmentations, and processesing techniques. From a prediction perspective, this means we can train the same model many different times and use each of these trained models to predict, taking an average (weighted or not) for our final predictions:**\n\n**The model architecture here is taken from 4X Kaggle Grandmaster [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte)'s notebook that can be found [here](https:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist\/output)**","5fe21092":"### 2. Previous Submissions\n\n<code>\nEPOCHS = 40  \nBATCH_SIZE = 64  \nNUM_NETS = 25   \n<\/code>\n<br><\/br>\n\n**I am very curious about the extent to which this type of CNN blending increases accuracy. If 50 CNNs blended together outperform a single CNN, then do 100 CNNs also outperform 50 CNNs? What about 1000 CNNs? At what point do we see diminishing returns to performance? We can use this notebook in an iterative way where each commit saves the CNN ensemble (probability) predictions as a `.csv` file. Then, in future commits of the notebook, we blend these previous CNN ensemble predictions with the current CNN ensemble predictions to see if our LB score goes up:**","194d26f9":"**The way that our data is structured is not ideal for computer vision problems. We can still use it in a neural network, but we cannot use any `tf.keras.layers.Conv2D` layers because the images are currently represented by a flat array with 784 values. To treat this array as an image so that we can convolve it, we must reshape things a bit.**\n\n\n**Note that we must provide a value for the channel depth when we reshape these array into image format. For greyscale images, our shape is `[batchsize, 28, 28, 1]` but if our images were RGB formatted, we would have `[batchsize, 28, 28, 3]`. We can use `-1` for the `batchsize` parameter to indicate that we don't actually care about what number goes in there:** ","04c05eaa":"**You can create the same neural network without using `model.add()` by placing the layers directly within the `Sequential` class like so:**","a56b29c8":"**To get the specs on a tensor, we can use the following block of code (taken from [here](https:\/\/www.tensorflow.org\/guide\/tensor)):**","4c0e63a2":"**All tensors can be explicitly converted to NumPy arrays using the `.numpy()` method. Furthermore, TensorFlow operations automatically convert NumPy arrays to Tensors and NumPy operations autmatically convert Tensors to NumPy arrays. This makes it very easy to switch between the two:**","f6fc8a10":"**We can now encode our labels such that they become one hot vectors. You can do this many different ways; I elected to do it with `tf.one_hot`**","741a944f":"**We can see that our data is already flattened out: for each image we have `28 * 28 = 784` columns representing the value of each pixel. The first thing we will do is map these pixel values from the range [0, 225] to [0, 1]:**","fa8051f0":"# Getting Data\n\n**Kaggle provides the image data to us in the form of `.csv` files that we can easily convert to DataFrames with `pd.read_csv` to quickly explore:**","e24b1c9b":"**Once you define this generator, you can access its contents using `.flow()`:**","1ba80b18":"### 2. Neural Networks\n\n**There are several different ways to create a neural network with `tf.keras`. The easiest way is to initialize a model as a `Sequential` object and then call `model.add()` on it to add layers to it.**","b05f2a8c":"**You can change the type of the entries in these tensors by using the `dtype` parameter like so:**","803d4e28":"**To get as diverse a set of CNNs as possible, we don't set a seed for the `random_state` arguement of `train_test_split` and we place it within the training loop so that each model is trained\/evaluated on a different subset of the data**"}}