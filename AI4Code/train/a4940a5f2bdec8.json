{"cell_type":{"93cf0825":"code","d89f4e3d":"code","9e8f2538":"code","2eb2b48d":"code","5ab1881d":"code","c151266f":"code","f6a04405":"code","9fb14dfa":"code","44c7e8ba":"code","af6ec131":"code","9c0c7d0e":"code","e7320b64":"code","1cba5417":"markdown","61647f28":"markdown"},"source":{"93cf0825":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d89f4e3d":"from keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers import Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dense\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.utils import to_categorical\n\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n%matplotlib inline","9e8f2538":"input_path = Path(\"..\/input\")\n\n# Path to training images and corresponding labels provided as numpy arrays\nkmnist_train_images_path = input_path\/\"kmnist-train-imgs.npz\"\nkmnist_train_labels_path = input_path\/\"kmnist-train-labels.npz\"\n\n# Path to the test images and corresponding labels\nkmnist_test_images_path = input_path\/\"kmnist-test-imgs.npz\"\nkmnist_test_labels_path = input_path\/\"kmnist-test-labels.npz\"","2eb2b48d":"# Load the training data from the corresponding npz files\nkmnist_train_images = np.load(kmnist_train_images_path)['arr_0']\nkmnist_train_labels = np.load(kmnist_train_labels_path)['arr_0']\n\n# Load the test data from the corresponding npz files\nkmnist_test_images = np.load(kmnist_test_images_path)['arr_0']\nkmnist_test_labels = np.load(kmnist_test_labels_path)['arr_0']\n\nprint(f\"Number of training samples: {len(kmnist_train_images)} where each sample is of size: {kmnist_train_images.shape[1:]}\")\nprint(f\"Number of test samples: {len(kmnist_test_images)} where each sample is of size: {kmnist_test_images.shape[1:]}\")","5ab1881d":"# Let's see how the images for different labels look like\nrandom_samples = []\nfor i in range(10):\n    samples = kmnist_train_images[np.where(kmnist_train_labels==i)][:3]\n    random_samples.append(samples)\n\n# Converting list into a numpy array\nrandom_samples = np.array(random_samples)\n\n# Visualize the samples\nf, ax = plt.subplots(10,3, figsize=(10,20))\nfor i, j in enumerate(random_samples):\n    ax[i, 0].imshow(random_samples[i][0,:,:], cmap='gray')\n    ax[i, 1].imshow(random_samples[i][1,:,:], cmap='gray')\n    ax[i, 2].imshow(random_samples[i][2,:,:], cmap='gray')\n    \n    ax[i,0].set_title(str(i))\n    ax[i,0].axis('off')\n    ax[i,0].set_aspect('equal')\n    \n    ax[i,1].set_title(str(i))\n    ax[i,1].axis('off')\n    ax[i,1].set_aspect('equal')\n    \n    ax[i,2].set_title(str(i))\n    ax[i,2].axis('off')\n    ax[i,2].set_aspect('equal')\nplt.show()","c151266f":"batch_size = 128\nnum_classes = 10\nepochs = 15\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# input shape\ninput_shape = (img_rows, img_cols, 1)","f6a04405":"# Process the train and test data in the exact same manner as done for MNIST\nx_train = kmnist_train_images.astype('float32')\nx_test = kmnist_test_images.astype('float32')\nx_train \/= 255\nx_test \/= 255\n\nx_train = x_train.reshape(x_train.shape[0], *input_shape)\nx_test = x_test.reshape(x_test.shape[0], *input_shape)\n\n# convert class vectors to binary class matrices\ny_train = to_categorical(kmnist_train_labels, num_classes)\ny_test = to_categorical(kmnist_test_labels, num_classes)","9fb14dfa":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n","44c7e8ba":"model.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nH = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))","af6ec131":"# Check the test loss and test accuracy \nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1]*100)","9c0c7d0e":"# Save the model\nmodel.save('model.h5')","e7320b64":"# Plotting the result\n\nplt.style.use('ggplot')\nplt.figure()\nplt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, epochs), H.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, epochs), H.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on CIFAR-10\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()\nplt.show()","1cba5417":"## Data preprocessing","61647f28":"## Build the model "}}