{"cell_type":{"e59cbdc1":"code","8b46c8a1":"code","b8f69c64":"code","2619f787":"code","1c5cd58d":"code","b75ae9d7":"code","bcb6847f":"code","cac40dc4":"code","424fad87":"code","7b026208":"code","cf234d1f":"code","8fed686d":"code","15486ac4":"code","1f177d18":"code","b458730a":"code","c8f7a2b8":"code","f7a70e8b":"code","dd67a1c0":"code","ba3bba56":"code","b241bf46":"code","38e05f3b":"code","d534c538":"code","569671f9":"code","ed44dc98":"code","859fed69":"code","73535ae6":"code","4ee0fd24":"code","fbe96453":"code","f267abcb":"code","adb310e0":"markdown","dff4a9a5":"markdown","c65c8b36":"markdown","deb4e528":"markdown","ee1f4f29":"markdown","9d3544c7":"markdown","a8d80783":"markdown","cb9b1dae":"markdown","9d82e38f":"markdown","aad90647":"markdown","4bc68bee":"markdown","ac2afaa4":"markdown","1b7c819a":"markdown","77934f17":"markdown","3d514f5c":"markdown"},"source":{"e59cbdc1":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\n\nimport os\nfrom pathlib import Path\n\n# importer la lib pour cross valider le model\nfrom sklearn.model_selection import cross_val_score\n\n# importer la lib pour la regression de Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\n\n# importer la lib pour la regression de Random Forest\nfrom sklearn.linear_model import SGDRegressor\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.model_selection import ShuffleSplit\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\n\n\n%matplotlib inline","8b46c8a1":"#train = pd.read_csv('training\/train.csv')\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsample = pd.read_csv('..\/input\/sample_submission.csv')\n","b8f69c64":"train.head()","2619f787":"train.dtypes","1c5cd58d":"train.info()","b75ae9d7":"train.isna().sum()","bcb6847f":"train.trip_duration.min()\n","cac40dc4":"train.trip_duration.max()","424fad87":"fig, ax = plt.subplots(ncols=1, nrows=1,figsize=(12,10))\nplt.ylim(40.6, 40.9)\nplt.xlim(-74.1,-73.7)\nax.scatter(train['pickup_longitude'],train['pickup_latitude'], s=0.0002, alpha=1)","7b026208":"plt.subplots(figsize=(18,7))\nplt.title(\"R\u00e9partition des outliers\")\ntrain.boxplot()","cf234d1f":"#train.loc[train.trip_duration<4000,\"trip_duration\"].hist(bins=120)\ntrain['trip_duration'] = np.log(train['trip_duration'].values)","8fed686d":"train['passenger_count'].value_counts()","15486ac4":"import math\n\ndef haversine(lat1, lon1, lat2, lon2):\n   R = 6372800  # Earth radius in meters\n   phi1, phi2 = math.radians(lat1), math.radians(lat2)\n   dphi       = math.radians(lat2 - lat1)\n   dlambda    = math.radians(lon2 - lon1)\n\n   a = math.sin(dphi\/2)**2 + \\\n       math.cos(phi1)*math.cos(phi2)*math.sin(dlambda\/2)**2\n\n   return 2*R*math.atan2(math.sqrt(a), math.sqrt(1 - a))\n\ntrain['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\ntest['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n\ntrain['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\ntest['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n\ntrain['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\ntest['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))","1f177d18":"train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\ntrain['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime'])\ntest['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n\ntrain['hour'] = train.pickup_datetime.dt.hour\ntrain['day'] = train.pickup_datetime.dt.dayofweek\ntrain['month'] = train.pickup_datetime.dt.month\ntest['hour'] = test.pickup_datetime.dt.hour\ntest['day'] = test.pickup_datetime.dt.dayofweek\ntest['month'] = test.pickup_datetime.dt.month","b458730a":"train.isnull().sum()","c8f7a2b8":"col_diff = list(set(train.columns).difference(set(test.columns)))","f7a70e8b":"train.head()","dd67a1c0":"y_train = train[\"trip_duration\"] # <-- target\nX_train = train[[\"vendor_id\",\"passenger_count\",\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\",\"dropoff_latitude\",\"month\",\"hour\",\"day\",\"dist\"]] # <-- features\n\nX_datatest = test[[\"vendor_id\",\"passenger_count\",\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\",\"dropoff_latitude\",\"month\",\"hour\",\"day\",\"dist\"]]","ba3bba56":"# declarer le model et l'entrainer\n\n#sgd = SGDRegressor()\n#sgd.fit(X_train, y_train)","b241bf46":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","38e05f3b":"rfr = RandomForestRegressor(n_estimators=100,min_samples_leaf=10, min_samples_split=15, max_depth=80,verbose=0,max_features=\"auto\",bootstrap=True,n_jobs=-1)\nrfr.fit(X_train, y_train)","d534c538":"# Trop long\n# calculer les scores de cross validation du model selon une decoupe du dataset de train\ncv_scores = cross_val_score(rfr, X_train, y_train, cv=5, scoring= 'neg_mean_squared_log_error')","569671f9":"cv_scores","ed44dc98":"for i in range(len(cv_scores)):\n    cv_scores[i] = np.sqrt(abs(cv_scores[i]))\ncv_scores\n","859fed69":"train_pred = rfr.predict(X_datatest)\ntrain_pred[:5]","73535ae6":"train_pred","4ee0fd24":"my_submission = pd.DataFrame({\"id\": test.id, \"trip_duration\": np.exp(train_pred)})\nprint(my_submission)","fbe96453":"my_submission.to_csv('submission.csv', index=False)\n","f267abcb":"my_submission.head()","adb310e0":"distances","dff4a9a5":"Dans 1 minute, il y a 60 secondes  \nDans 1 heure, il y a 60 minutes. donc 60 * 60= 3600secondes  \nDans 1 journ\u00e9e, il y a 24 heures. donc 24*3600= 86400 secondes.  \n=> 3526282\/86400 = 40,81344907 jours\n\n\nOn peut voir qu'il y a un temps de trajet minimum de 1 seconde et un maximum de 40 jours.\nIl faudra les enlever car cela va fausser les r\u00e9sultats.  \nDans mon cas, je juge qu'un temps de trajet dans un taxi doit \u00eatre comprise entre 5 minutes et quelques heures.","c65c8b36":"#### 3.1 Gestion des Outliers","deb4e528":"Suppression vitesse incoh\u00e9rente & distance\n","ee1f4f29":"# 5. S\u00e9lection de mod\u00e8les et\/ou datasets (si il y en a plusieurs)****","9d3544c7":"1. 1. On pourra choisir un trip_duration max (4000) et trip_duration_min (0 car les trip_durations peuvent \u00eatre nulls ou annul\u00e9es)","a8d80783":"In this competition, Kaggle is challenging you to build a model that predicts the total ride duration of taxi trips in New York City. Your primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables.\n\nLongtime Kagglers will recognize that this competition objective is similar to the ECML\/PKDD trip time challenge we hosted in 2015. But, this challenge comes with a twist. Instead of awarding prizes to the top finishers on the leaderboard, this playground competition was created to reward collaboration and collective learning.\n\nWe are encouraging you (with cash prizes!) to publish additional training data that other participants can use for their predictions. We also have designated bi-weekly and final prizes to reward authors of kernels that are particularly insightful or valuable to the community.","cb9b1dae":"# 4. Features engineering : selection, extraction, creation","9d82e38f":"# 3. Data preprocessing :","aad90647":"# 2. Data exploration","4bc68bee":"# Import\n","ac2afaa4":"#### 3.4 Scaling des donn\u00e9es","1b7c819a":"# 6. Entrainement du ou des mod\u00e8le(s) & Predictions","77934f17":"# 1. Data loading","3d514f5c":"#### 3.2 Missing values handling"}}