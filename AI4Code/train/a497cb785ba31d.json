{"cell_type":{"58d95dcd":"code","7468d877":"code","9f055005":"code","7ba26260":"code","fb931595":"code","5dd704a5":"code","bdaa2670":"code","03817a70":"code","f91db84a":"code","d8e45d9f":"code","b31b977a":"code","19ed7a8c":"code","b190cb13":"code","3429a12a":"code","fb4a5563":"code","4c8bc52a":"code","00becdd6":"code","ffcbc2c4":"code","76752b1c":"code","1560ed14":"code","e07a91ec":"code","edbcca58":"code","b7df937e":"code","d47037dd":"code","e3efe7b5":"code","9265e296":"code","90c67179":"markdown","bcd485c5":"markdown","3f920ae6":"markdown","94e4b082":"markdown","c4e15ec6":"markdown","7aa3146e":"markdown","f6bee88d":"markdown","8796af70":"markdown","33244a95":"markdown"},"source":{"58d95dcd":"# Importing all the required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7468d877":"# Loading the all the data set\ntrain_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv')\ntrain_trans = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')\n\ntest_identity = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\ntest_trans = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv')","9f055005":"# Data Shape\nprint('Data Shape of train identity :', train_identity.shape)\nprint('Data Shape of train transaction :', train_trans.shape)\n\nprint('Data Shape of test identity :', test_identity.shape)\nprint('Data Shape of test transaction :', test_trans.shape)","7ba26260":"# Data Overview\nprint(\"Train Identity\")\ntrain_identity.head(10).T","fb931595":"# Data Overview\nprint(\"Train Transaction\")\ntrain_trans.head(10).T","5dd704a5":"# Merging the dataset\ntrain_merged = pd.merge(train_trans, train_identity, on = 'TransactionID')\ntest_merged = pd.merge(test_trans, test_identity, on = 'TransactionID')","bdaa2670":"del train_identity, train_trans, test_identity, test_trans","03817a70":"# Target in Analysis\nplt.subplots(figsize = (6,6))\ntrain_merged['isFraud'].value_counts().plot('pie')\nplt.show()","f91db84a":"# Missing Values\nmissing_values = ((train_merged.isnull().sum()\/len(train_merged)).sort_values(ascending = False))*100\nprint(\"Missing Values\")\nprint(missing_values)","d8e45d9f":"# Removing all the variables having more than 90% of the missing value\ncols_to_remove = missing_values[missing_values>=90].index.tolist()","b31b977a":"# Removing above columns from train and test data\ntrain_merged.drop(cols_to_remove, axis =1, inplace = True)\ntest_merged.drop(cols_to_remove, axis =1, inplace = True)","19ed7a8c":"train_merged.head(10).T","b190cb13":"# Splitting data into categorical and numerical\ncategorial_data = train_merged.select_dtypes(include = ['object'])\nnumerical_data = train_merged.select_dtypes(exclude = ['object'])","3429a12a":"categorial_data.head(10).T","fb4a5563":"categorial_data.describe().T","4c8bc52a":"# ProductCD Analysis\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\nsns.countplot('ProductCD', data = categorial_data, ax=ax[0])\nsns.countplot(categorial_data['ProductCD'], hue = numerical_data['isFraud'], ax=ax[1])\nplt.subplots_adjust(wspace = 0.5)\nplt.show()","00becdd6":"# Card4 Analysis\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\nsns.countplot('card4', data = categorial_data, ax=ax[0])\nsns.countplot(categorial_data['card4'], hue = numerical_data['isFraud'], ax=ax[1])\nplt.subplots_adjust(wspace = 0.5)\nplt.show()","ffcbc2c4":"# Card6 Analysis\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\nsns.countplot('card6', data = categorial_data, ax=ax[0])\nsns.countplot(categorial_data['card6'], hue = numerical_data['isFraud'], ax=ax[1])\nplt.subplots_adjust(wspace = 0.5)\nplt.show()","76752b1c":"# P_emaildomain\nplt.figure(figsize=(20, 6))\nsns.countplot('P_emaildomain', data = categorial_data)\nplt.xticks(rotation=90)\nplt.show()","1560ed14":"temp = pd.DataFrame(categorial_data['P_emaildomain'].value_counts())\ntemp['%cent'] = temp['P_emaildomain']\/temp['P_emaildomain'].sum()*100\ntemp['others'] = np.where(temp['%cent'] > 1, temp.index, 'others')\np_email_mapping = temp['others'].to_dict()\ncategorial_data['P_emaildomain_new'] = categorial_data['P_emaildomain'].map(p_email_mapping)","e07a91ec":"# P_email and P_email_new Analysis\nfig, ax = plt.subplots(1, 2, figsize=(20, 6))\ncategorial_data['P_emaildomain'].value_counts().plot(kind = 'bar', ax = ax[0])\ncategorial_data['P_emaildomain_new'].value_counts().plot(kind = 'bar', ax = ax[1])\nplt.show()","edbcca58":"# R_emaildomain\nplt.figure(figsize=(20, 6))\ncategorial_data['R_emaildomain'].value_counts().plot(kind = 'bar')\nplt.show()","b7df937e":"# M4\n# R_emaildomain\nplt.figure(figsize=(20, 6))\ncategorial_data['M4'].value_counts().plot(kind = 'pie')\nplt.show()","d47037dd":"# Taking all the variable started with id\nid_cols = categorial_data.columns[categorial_data.columns.str.startswith('id')].tolist()\n# Removing id_30, id_31, id_33: Want to look at them separately due to high number of levels in it\ncols_to_remove = ['id_30', 'id_31', 'id_33']\nfor i in cols_to_remove:\n    id_cols.remove(i)","e3efe7b5":"fig, ax = plt.subplots(5, 2, figsize = (15, 20),\n                       gridspec_kw={'hspace' : 0.5, 'wspace':0.2})\nax = np.reshape(ax, (10))\n\nfor col, axis in zip(id_cols, ax):\n    sns.countplot(categorial_data[col], ax = axis)","9265e296":"#cols_to_remove = ['id_30', 'id_31', 'id_33']\n# id_30\nplt.figure(figsize=(20, 6))\ncategorial_data['id_30'].value_counts().plot(kind = 'bar')\nplt.show()","90c67179":"Target : isFraud is highly imbalanced which is common in real world problems","bcd485c5":"### Basic Data Summary\n","3f920ae6":"ProductCD has only 4 categorical levels , will do one hot encoding of ProductCD\n","94e4b082":"M4 has only three categories in it with M2 level has in majority.","c4e15ec6":"# Analysis of Categorical Data\n","7aa3146e":"1. Top 3 P_emaildomain used are\n1. gmail.com\n2. hotmail.com\n3. anonymous.com\n\n> We can combine few P_emaildomain into one based on their frequency and we can combine gmail and gmail.com","f6bee88d":"The most occuring level is windows. I will create one more variable where I will keep only Windows, MAC OS, iOS","8796af70":"Most of the data in columns starting with \"id\" is binary and having values like\n1. Found and Not Found\n2. T and F ","33244a95":"# WIP "}}