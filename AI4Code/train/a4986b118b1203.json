{"cell_type":{"7f811d87":"code","f4a5e6c9":"code","895771f0":"code","56cccfab":"code","c3c55098":"code","40ac86cd":"code","80005dc3":"code","e2f6cffb":"code","05474f7f":"code","877a4da8":"code","cf885d85":"code","322d65f6":"code","6ea12dff":"code","e8ab026a":"code","69ad30d3":"code","df60354c":"code","06b9e1da":"code","0f582c17":"code","c828d62a":"code","88992acd":"code","176fdebb":"code","b73fbdf8":"code","4bd55a5c":"code","64a5c371":"code","026ef692":"code","f51a806f":"code","8a942468":"code","8d9da3e9":"code","fadeecb5":"code","686d44f3":"code","adf482cd":"code","17c056d0":"code","97e85767":"code","ff8dd55a":"code","37b56a3f":"code","eaccecbb":"markdown","4e8a35a2":"markdown","84d60b84":"markdown","07955044":"markdown","330ac74d":"markdown","6b1cb258":"markdown","5dc5284a":"markdown","fd221944":"markdown","3735d3d5":"markdown","aac28c1e":"markdown","e680a782":"markdown"},"source":{"7f811d87":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","f4a5e6c9":"# Load Data\ndf = pd.read_csv('\/kaggle\/input\/google-play-store-apps\/googleplaystore.csv')","895771f0":"df.head()","56cccfab":"df.info()","c3c55098":"df.isnull().sum()","40ac86cd":"df.dropna(inplace = True)","80005dc3":"df.info()","e2f6cffb":"df.drop(labels = ['Current Ver','Android Ver','App'], axis = 1, inplace = True)","05474f7f":"df.head()","877a4da8":"category_list = df['Category'].unique().tolist() \ncategory_list = ['cat_' + word for word in category_list]\ndf = pd.concat([df, pd.get_dummies(df['Category'], prefix='cat')], axis=1)","cf885d85":"df.head()","322d65f6":"le = preprocessing.LabelEncoder()\ndf['Genres'] = le.fit_transform(df['Genres'])","6ea12dff":"df.head()","e8ab026a":"le = preprocessing.LabelEncoder()\ndf['Content Rating'] = le.fit_transform(df['Content Rating'])","69ad30d3":"df['Price'] = df['Price'].apply(lambda x : x.strip('$'))","df60354c":"df['Installs'] = df['Installs'].apply(lambda x : x.strip('+').replace(',', ''))","06b9e1da":"df['Type'] = pd.get_dummies(df['Type'])","0f582c17":"df[\"Size\"] = [str(round(float(i.replace(\"k\", \"\"))\/1024, 3)) if \"k\" in i else i for i in df.Size]","c828d62a":"df['Size'] = df['Size'].apply(lambda x: x.strip('M'))\ndf[df['Size'] == 'Varies with device'] = 0\ndf['Size'] = df['Size'].astype(float)","88992acd":"df[\"Size\"]","176fdebb":"df['new'] = pd.to_datetime(df['Last Updated'])\ndf['lastupdate'] = (df['new'] -  df['new'].max()).dt.days","b73fbdf8":"df.head()","4bd55a5c":"x = df.drop(labels=[\"Rating\",\"Category\", \"Last Updated\", \"new\"], axis = 1)\ny = df['Rating']","64a5c371":"x.head()","026ef692":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)","f51a806f":"lr = LinearRegression()\nlr.fit(x_train, y_train)","8a942468":"accuracy = lr.score(x_test,y_test)\n'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'","8d9da3e9":"knn = KNeighborsRegressor(n_neighbors=50)\nknn.fit(x_train, y_train)","fadeecb5":"accuracy = knn.score(x_test,y_test)\n'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'","686d44f3":"n_neighbors = np.arange(1, 50, 1)\nscores = []\nfor n in n_neighbors:\n    knn.set_params(n_neighbors=n)\n    knn.fit(x_train, y_train)\n    scores.append(knn.score(x_test, y_test))\nplt.figure(figsize=(7, 5))\nplt.title(\"Effect of Estimators\")\nplt.xlabel(\"Number of Neighbors K\")\nplt.ylabel(\"Score\")\nplt.plot(n_neighbors, scores)","adf482cd":"print(\"max accuracy is: \", max(scores))\nprint(\"K value to achieve this result: \", n_neighbors[scores.index(max(scores))])","17c056d0":"tr = DecisionTreeRegressor()\ntr.fit(x_train, y_train)","97e85767":"accuracy = tr.score(x_test, y_test)\n'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'","ff8dd55a":"rf = RandomForestRegressor(n_jobs=-1)\nestimators = np.arange(10, 150, 10)\nscores = []\nfor n in estimators:\n    rf.set_params(n_estimators=n)\n    rf.fit(x_train, y_train)\n    scores.append(rf.score(x_test, y_test))\nplt.figure(figsize=(7, 5))\nplt.title(\"Effect of Estimators\")\nplt.xlabel(\"no. estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)","37b56a3f":"print(\"max accuracy is: \", max(scores))\nprint(\"the number of estimators required to achieve this result: \", estimators[scores.index(max(scores))])","eaccecbb":"### Linear Regression","4e8a35a2":"### Train-Test Split","84d60b84":"### Decision Tree","07955044":"I will drop all missing values since almost all of the missing values are in the Rating column and that is our target, the column we will predict.","330ac74d":"# Modeling","6b1cb258":"# Data Cleaning","5dc5284a":"Now we will convert categorical variables to numeric so that they can work smoothly with machine learning algorithms.","fd221944":"### K-Nearest Neighbors","3735d3d5":"### Random Forest","aac28c1e":"In this notebook, we will predict app ratings using machine learning algorithms.","e680a782":"We also drop unnecessary features that we will not use in our machine learning algorithm."}}