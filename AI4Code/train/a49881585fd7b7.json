{"cell_type":{"9a426332":"code","17031303":"code","69838f61":"code","01e9a5cf":"code","87d357de":"code","3592faef":"code","010acde9":"code","7f471449":"code","ccbce7ba":"code","59b6c8ff":"code","f1bfb22d":"code","a6488269":"code","0dd8180e":"code","3efa5608":"code","09e602d4":"code","14c03214":"code","07512869":"code","c658ce70":"code","10799a51":"code","895230c9":"code","31b8abfd":"code","f91f0cd5":"code","9483e69f":"code","2d839c3e":"code","abb08e61":"code","da2acda9":"code","a184c832":"markdown","de6e520e":"markdown","b43461bc":"markdown","7236f84d":"markdown","a254eaa3":"markdown","5dadc70e":"markdown","17066193":"markdown","1cbb61d6":"markdown","cea02c4a":"markdown","fc2fd875":"markdown","f1ea6333":"markdown","4f4cda5f":"markdown","59e1998c":"markdown","40fcba28":"markdown","d61fabc5":"markdown","27a0bfff":"markdown","b5faf295":"markdown","254d08b7":"markdown"},"source":{"9a426332":"import os\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport skimage\nfrom skimage import io, transform\nfrom IPython.display import Image, display\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import LSTM, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\nimg_size = 100\ntrain_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Training\/'\ntest_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Test\/'\n\ndef get_data(folder_path):\n    imgs = []\n    indices = []\n    labels = []\n    for idx, folder_name in enumerate(os.listdir(folder_path)[:35]):\n        if not folder_name.startswith('.'):\n            labels.append(folder_name)\n            for file_name in tqdm(os.listdir(folder_path + folder_name)):\n                if not file_name.startswith('.'):\n                    img_file = io.imread(folder_path + folder_name + '\/' + file_name)\n                    if img_file is not None:\n                        img_file = transform.resize(img_file, (img_size, img_size))\n                        imgs.append(np.asarray(img_file))\n                        indices.append(idx)\n    imgs = np.asarray(imgs)\n    indices = np.asarray(indices)\n    labels = np.asarray(labels)\n    return imgs, indices, labels\n\nX_train, y_train, train_labels = get_data(train_dir)\nX_test, y_test, test_labels = get_data(test_dir)","17031303":"print('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)\nprint('y_train:', y_train)\nprint('y_test:', y_test)\n# print('First image - X_train:', X_train[0])\n\nnum_categories = len(np.unique(y_train))\n\nnew_X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3]).astype('float32')\nnew_X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], X_test.shape[3]).astype('float32')\nnew_y_train = keras.utils.to_categorical(y_train, num_categories)\nnew_y_test = keras.utils.to_categorical(y_test, num_categories)","69838f61":"def display_imgs(folder_path):\n    for idx, folder_name in enumerate(os.listdir(folder_path)):\n        if idx % 25 == 0:\n            if not folder_name.startswith('.'):\n                for idx2, file_name in enumerate(tqdm(os.listdir(folder_path + folder_name))):\n                    if idx2 % 75 == 0:\n                        if not file_name.startswith('.'):\n                            img_filename = folder_path + folder_name + '\/' + file_name\n                            display(Image(filename=img_filename))","01e9a5cf":"display_imgs(train_dir)","87d357de":"display_imgs(test_dir)","3592faef":"def evaluate_model(model, batch_size, epochs):\n    history = model.fit(new_X_train, new_y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(new_X_test, new_y_test))\n    score = model.evaluate(new_X_test, new_y_test, verbose=0)\n    print('***Metrics Names***', model.metrics_names)\n    print('***Metrics Values***', score)","010acde9":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.25))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(128, activation='relu'))\nconvolutional.add(Dropout(0.5))\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])\n\nevaluate_model(convolutional, 128, 5)","7f471449":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.6))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(128, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])\n\nevaluate_model(convolutional, 128, 7)","ccbce7ba":"def run_with_loss(loss):\n    convolutional = Sequential()\n\n    convolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\n    convolutional.add(Conv2D(64, (3, 3), activation='relu'))\n    convolutional.add(MaxPooling2D(pool_size=(2, 2)))\n    convolutional.add(Dropout(0.6))\n\n    convolutional.add(Flatten())\n    convolutional.add(Dense(128, activation='relu'))\n    convolutional.add(Dropout(0.6))\n    convolutional.add(Dense(num_categories, activation='softmax'))\n\n    convolutional.summary()\n    convolutional.compile(loss=loss, optimizer=Adam(), metrics=['accuracy'])\n\n    evaluate_model(convolutional, 128, 5)\n\nlosses = ['mean_squared_error', 'mean_absolute_error', 'mean_squared_logarithmic_error']\n\nfor loss in losses:\n    run_with_loss(loss)","59b6c8ff":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\n# CHANGE\nconvolutional.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nconvolutional.add(Conv2D(256, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(512, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])\n\nevaluate_model(convolutional, 128, 5)","f1bfb22d":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\n# CHANGE\nconvolutional.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nconvolutional.add(Conv2D(256, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(512, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])\n\nevaluate_model(convolutional, 32, 5)","a6488269":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(2,2), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (2, 2), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\n# CHANGE\nconvolutional.add(Conv2D(128, kernel_size=(2,2), activation='relu'))\nconvolutional.add(Conv2D(256, (2, 2), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(512, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])\n\nevaluate_model(convolutional, 32, 5)","0dd8180e":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\n# CHANGE\nconvolutional.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nconvolutional.add(Conv2D(256, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(512, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=.0005), metrics=['accuracy'])\n\nevaluate_model(convolutional, 32, 5)","3efa5608":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\n# CHANGE\nconvolutional.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nconvolutional.add(Conv2D(256, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(512, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(BatchNormalization())\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=.0005), metrics=['accuracy'])\n\nevaluate_model(convolutional, 32, 5)","09e602d4":"y_pred = convolutional.predict(new_X_test, batch_size=None, verbose=0, steps=None).argmax(axis=-1)\nres_crosstab = pd.crosstab(y_pred, y_test)\n\ndict_idx_fruit = {idx: label for idx, label in enumerate(test_labels)}\nprint(dict_idx_fruit)\n\nres_crosstab","14c03214":"for idx in range(num_categories):\n    accuracy = res_crosstab.loc[idx, idx] \/ res_crosstab.loc[:, idx].sum()\n    flag = '***LOW***' if accuracy < 0.8 else ''\n    print(dict_idx_fruit[idx])\n    print('   ', flag, 'accuracy \u2013', round(accuracy * 100, 2), '%')","07512869":"# Run on Kaggle with GPU \n\nimport os\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport skimage\nfrom skimage import io, transform\nfrom IPython.display import Image, display\n\nimport keras\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import LSTM, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\nimg_size = 100\ntrain_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Training\/'\ntest_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Test\/'\n\ndef get_data(folder_path):\n    imgs = []\n    indices = []\n    labels = []\n    for idx, folder_name in enumerate(os.listdir(folder_path)[:35]):\n        if not folder_name.startswith('.'):\n            labels.append(folder_name)\n            for file_name in tqdm(os.listdir(folder_path + folder_name)):\n                if not file_name.startswith('.'):\n                    img_file = io.imread(folder_path + folder_name + '\/' + file_name)\n                    if img_file is not None:\n                        img_file = transform.resize(img_file, (img_size, img_size))\n                        imgs.append(np.asarray(img_file))\n                        indices.append(idx)\n    imgs = np.asarray(imgs)\n    indices = np.asarray(indices)\n    labels = np.asarray(labels)\n    return imgs, indices, labels\n\nX_train, y_train, train_labels = get_data(train_dir)\nX_test, y_test, test_labels = get_data(test_dir)","c658ce70":"num_categories = len(np.unique(y_train))\n\nnew_X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3]).astype('float32')\nnew_X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], X_test.shape[3]).astype('float32')\nnew_y_train = keras.utils.to_categorical(y_train, num_categories)\nnew_y_test = keras.utils.to_categorical(y_test, num_categories)","10799a51":"def evaluate_model(model, batch_size, epochs):\n    history = model.fit(new_X_train, new_y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(new_X_test, new_y_test))\n    score = model.evaluate(new_X_test, new_y_test, verbose=0)\n    print('***Metrics Names***', model.metrics_names)\n    print('***Metrics Values***', score)","895230c9":"convolutional = Sequential()\n\nconvolutional.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3],)))\nconvolutional.add(Conv2D(64, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nconvolutional.add(Conv2D(256, (3, 3), activation='relu'))\nconvolutional.add(MaxPooling2D(pool_size=(2, 2)))\nconvolutional.add(Dropout(0.35))\n\nconvolutional.add(Flatten())\nconvolutional.add(Dense(512, activation='relu'))\nconvolutional.add(Dropout(0.6))\nconvolutional.add(BatchNormalization())\nconvolutional.add(Dense(num_categories, activation='softmax'))\n\nconvolutional.summary()\nconvolutional.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=.0005), metrics=['accuracy'])\n\nevaluate_model(convolutional, 32, 5)","31b8abfd":"# Save model to disk\nmodel_json = convolutional.to_json()\nwith open(\"cnn_model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nconvolutional.save_weights(\"cnn_model.h5\")\nprint(\"CNN model saved to disk\")","f91f0cd5":"# Load model from disk\njson_file = open('cnn_model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\nloaded_model.load_weights(\"cnn_model.h5\")\nprint(\"CNN model loaded from disk\")","9483e69f":"y_pred = loaded_model.predict(new_X_test, batch_size=None, verbose=0, steps=None).argmax(axis=-1)\nres_crosstab = pd.crosstab(y_pred, y_test)\n\ndict_idx_fruit = {idx: label for idx, label in enumerate(test_labels)}\nprint(dict_idx_fruit)\n\nres_crosstab","2d839c3e":"for idx in range(num_categories):\n    accuracy = res_crosstab.loc[idx, idx] \/ res_crosstab.loc[:, idx].sum()\n    flag = '***LOW***' if accuracy < 0.75 else ''\n    print(dict_idx_fruit[idx])\n    print('   ', flag, 'accuracy \u2013', round(accuracy * 100, 2), '%')","abb08e61":"for idx in range(35):\n    for idx2 in range(35):\n        accuracy = res_crosstab.loc[idx, idx] \/ res_crosstab.loc[:, idx].sum()\n        if idx != idx2 and res_crosstab.loc[idx, idx2] != 0:\n            pred_fruit = dict_idx_fruit[idx]\n            actual_fruit = dict_idx_fruit[idx2]\n            num_mistakes = res_crosstab.loc[idx, idx2]\n            sing_or_plural = 's' if num_mistakes > 1 else ''\n            print('- {} {}{} mistaken for {}{}'.format(num_mistakes, actual_fruit, sing_or_plural, pred_fruit, sing_or_plural))","da2acda9":"def get_one_img_per_fruit(folder_path):\n    printouts = []\n    for idx, folder_name in enumerate(os.listdir(folder_path)[:35]):\n        if not folder_name.startswith('.'):\n            for idx2, file_name in enumerate(tqdm(os.listdir(folder_path + folder_name))):\n                if idx2 == 0:\n                    if not file_name.startswith('.'):\n                        img_filename = folder_path + folder_name + '\/' + file_name\n                        display(Image(filename=img_filename))\n                        \n                        current_img = io.imread(img_filename)\n                        current_img = transform.resize(current_img, (img_size, img_size))\n                        current_img = np.asarray(current_img)\n                        current_img = np.asarray([current_img])\n                        \n                        current_pred = loaded_model.predict(current_img, batch_size=None, verbose=0, steps=None).argmax(axis=-1)\n                        current_pred = dict_idx_fruit[current_pred[0]]\n                        \n                        is_incorrect = 'INCORRECT' if folder_name != current_pred else ''\n                        \n                        msg = '{} \u2013\u00a0predicted as {} {}'.format(folder_name, current_pred, is_incorrect)\n                        print(msg)\n                        printouts.append(msg)\n    return printouts\n                    \nprintouts = get_one_img_per_fruit(test_dir)\n\nfor msg in printouts:\n    print(msg)","a184c832":"This is yielding better performance \u2013\u00a0it is still slightly overfitting from the 3rd epoch on, but validation accuracy is hovering at ~85%, with a max of ~87%. \n\n### Strategy 5 \u2013\u00a0Decrease Kernel Size [Not Successful]","de6e520e":"## Data Wrangling","b43461bc":"## Prediction Demo with Loaded Model","7236f84d":"### Examples of Training Images","a254eaa3":"## Problem Points in Model","5dadc70e":"### Examples of Test Images","17066193":"This model is still overfitting from the 3rd epoch onwards, but I am getting a slightly better performance with best validation accuracy of ~85%.\n\n### Strategy 4 \u2013\u00a0Decrease Batch Size [Successful]","1cbb61d6":"From the above epochs, I can already see that my model is over-fitting on my training data from the 3rd epoch on \u2013\u00a0we can see that the model's testing accuracy is OVER 15% higher than its validation accuracy by the 3rd epoch. The highest validation accuracy comes at the 4th epoch (~81%), and drops in the subsequent epoch. \n\nOverall, my model is performing at ~81% accuracy at its best, but is drastically overfitting. I will now be attempting to optimize this model. \n\n## Optimizing the CNN Model\n### Strategy 1 \u2013\u00a0Increase Dropout Rates to Counter Overfitting","cea02c4a":"## Running Final Model On More Data","fc2fd875":"### Evaluating Finalized Model","f1ea6333":"Increasing the dropout does help with overfitting \u2013\u00a0it doesn't overfit until the 3rd epoch, and even then by a smaller percentage, but that overfit percentage does go back up by the 4th and 5th epoch. \n\nOverall, this model seems to have a better performance than my initial model, hovering at ~84% validation accuracy at its best, with less overfitting.\n\n### Strategy 2 \u2013\u00a0Use Different Loss Functions [Not Successful]","4f4cda5f":"None of these other loss functions show a significant improvement over the original loss function of 'categorical_crossentropy'. Of the 3 attempted, 'mean_squared_error' performed the best, coming in with a validation accuracy of ~73% before overfitting.\n\n### Strategy 3 \u2013\u00a0Add More Convolutional Layers [Successful]","59e1998c":"## Initial Model Selection\n### Convolutional Neural Network (CNN)","40fcba28":"Decreasing the learning rate resulted in slightly higher accuracy rates, though it did slightly increase the runtime of the model. I will be keeping this lower learning rate, as I don't believe the speed decrease was significant enough to be a detriment to the model.\n\n## Finalizing Model\n\nCombine all successful optimizing strategies (additional convolutional layers, increased dropout rates, decreased batch size, etc.), alongside Batch Normalization, for a final optimized model.","d61fabc5":"# Using Deep Learning to Identify Images of Fruits\n\nI will be using deep learning techniques via the Keras API to train a Convolutional Neural Network (CNN) model on a dataset of fruit images, and evaluate this model's accuracy on a separate test dataset of fruit images.\n\nI will be focusing on optimizing my CNN model to give me the highest possible accuracy on both my training & test data.\n\n## Importing Training & Test Images","27a0bfff":"Decreasing kernel size doesn't yield any significant improvements \u2013\u00a0if anything, it causes the model to overfit earlier and to reach a slightly lower maximum validation accuracy (~85%). \n\n### Strategy 6 \u2013\u00a0Decrease Learning Rate [Successful]","b5faf295":"## Conclusion\n\nThe final CNN model is performing 3% better than the initial model, with a validation accuracy of 99.4% and training accuracy of 99.9%. There is very little overfitting (0.5%) \u2013 less than in the original model.\n\nLooking at the crosstab by category, it is obvious that most fruits are being predicted accurately, with a handful (e.g. nectarines, granadillas) that are more difficult to distinguish and thus bringing the accuracy of the overall model down. In the future, we could add more images to train on pairs of fruits that are being mistaken for each other (i.e. Nectarines vs. Apple Red 1s, Apple Golden 3s vs. Apple Granny Smiths, etc.).\n\nCould also do TensorBoard visualizations to visualize model performance, but Kaggle GPU was limiting factor in this realm.","254d08b7":"## Exploratory Data Analysis"}}