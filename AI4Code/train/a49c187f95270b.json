{"cell_type":{"586243e2":"code","c01146c9":"code","9d8d799c":"code","7cf4c98c":"code","e3b1d948":"code","3f61f9f7":"markdown","c597a447":"markdown","1cd27127":"markdown","f61b2679":"markdown"},"source":{"586243e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c01146c9":"metrics = [\"winrate\", \"consistency\", \"aerc\", \"ewr\", \"kfai\", \"sas\"]\ndf = pd.read_csv(\"..\/input\/top_200.csv\")\ndf.head(3)","9d8d799c":"df[metrics].corr(\"pearson\")","7cf4c98c":"#sns.set_style(\"whitegrid\")\nsns.set_context(\"notebook\", font_scale=1.5)\na4_dims = (11.7, 8.27)\nfig, ax = plt.subplots(figsize=a4_dims)\n\nlabels = ['Win Rate', 'Consistency', 'AERC', 'EWR', 'KFAI', 'SAS']\ng = sns.heatmap(df[metrics].corr(\"pearson\"), square=True, cmap=\"RdBu_r\", annot=True, vmin=0, vmax=1, xticklabels=labels, yticklabels=labels, ax=ax)\nplt.yticks(rotation=0)\nplt.show()","e3b1d948":"labels = ['ADHD consistency', 'AERC', 'EWR', 'KFAI', 'SAS']\ny_vars = [\"consistency\", \"aerc\", \"ewr\", \"kfai\", \"sas\"]\ng = sns.PairGrid(df, x_vars=['winrate'], y_vars=y_vars, aspect=1.6, height=5)\ng = g.map(plt.scatter, marker=\"+\", vmin=0, vmax=100)\nfor ax, label in zip(g.axes, labels):\n    ax[0].yaxis.set_label_text(label)\n    ax[0].xaxis","3f61f9f7":"## Is there a good performance metric for KeyForge?\n\nAfter the unique card game [KeyForge](https:\/\/www.keyforgegame.com\/) was released in November 2018 several attempts were made to evaluate the \"performance\" of a unique deck of KeyForge cards. After being prominently featured on several KeyForge fan made websites some of these metrics generated lots of interest.\n\nCurrently 5 metrics are especially interesting:\n\n* [ADHD V3.0](https:\/\/docs.google.com\/spreadsheets\/d\/1C7Zrwz8zXnlvT7D4532EMYmHZ1Twj7oZDKVesRqAo8o\/edit#gid=1801938585)\n* [AERC](https:\/\/decksofkeyforge.com\/about\/sas)\n* [KFAI](https:\/\/www.reddit.com\/r\/KeyforgeGame\/comments\/b0dffv\/new_alpha_servicescore_kfai\/)\n* [SAS](https:\/\/decksofkeyforge.com\/about\/sas)\n* [EWR](https:\/\/expectedwinratemetric.000webhostapp.com\/)\n\nThus it is now time to evaluate the quality of these metrics. I got the idea from one of these metrics (EWR) as [they posted data about the 200 decks](https:\/\/expectedwinratemetric.000webhostapp.com\/top-200-decks-by-games-and-wins\/) that were played the most in official chainbound events. \n\nAfter adding the other 4 metrics to that table, the data looks like this:","c597a447":"## Appendix\n\nCorrelation coefficients are nice but I want to see the actual relationships of the 5 metrics to the winrate.","1cd27127":"## What does it mean?\n**Most of the metrics have a correlation coefficient of ~ 0.3. The metrics are not especially useful to predict the actual winrate of a deck.** \n\nOne should not mistake any of the metrics for a garanty to success at a chainbound event. There is no evidence that a low SAS, ADHD or EWP deck is indeed inferior.\n\nNote: KFAI performs a bit better compared to the other metrics. Little is known about the method how KFAI scores are derived. The author used a not otherwise specified neural network. The network was trained on the about 5000 decks that were used in chainbound events. Whether the results are useful to evaluate decks that haven't been used yet, will be seen.","f61b2679":"## Evaluation\n\nTo evaluate the performance of the 4 metrics I am going to compute the correlation coefficients of the relationship of the actual win rate and any of the 5 metrics.\n\nA [correlation coefficient](https:\/\/en.wikipedia.org\/wiki\/Correlation_coefficient) measures the relationship between two variables. According to Wikipedia:\n\n> Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics. They all assume values in the range from \u22121 to +1, where \u00b11 indicates the strongest possible agreement and 0 the strongest possible disagreement.\n\nHere I am going to use the [Pearson correlation coefficent](https:\/\/en.wikipedia.org\/wiki\/Pearson_product-moment_correlation_coefficient). \n\nBut what does a certain value of a correlation coefficent look like? To get a visual impression here is a chart from the above Wikipedia article:\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/d\/d4\/Correlation_examples2.svg\/1000px-Correlation_examples2.svg.png)\n\n*(Chart done by Denis Boigelot released into the public domain.)*\n\nSo let's compute the correlation of the 4 metrics to the actual win rate: "}}