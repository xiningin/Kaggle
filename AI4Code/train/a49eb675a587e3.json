{"cell_type":{"1f6e37f2":"code","a7e8882a":"code","9c31dd23":"code","fc6a079f":"code","f5256170":"code","bf67c9a1":"code","071626cb":"code","4efd53ad":"code","e757c6e4":"code","d2ea77a7":"code","c459b01a":"code","4011747e":"code","99f83a9b":"code","f65fcc8b":"code","a4ffd388":"code","f2a95072":"code","63b03c73":"code","c9b7beb5":"code","3c912fab":"code","e168c60d":"code","f3592710":"code","ca0e97f9":"code","24bddab9":"code","c09a7c2f":"code","5027fa87":"code","46e78619":"code","7c2614f1":"code","1e0f403c":"code","cfb1932b":"code","3b2476f5":"code","7ccd3a88":"code","b062d600":"code","96470c3e":"code","dab2150a":"code","12c32c70":"code","7b3a3ada":"code","a1c112f4":"code","354b10c1":"code","9e0dc2ad":"code","e7f534ad":"code","0b9db9a3":"code","3eb855e7":"code","25f0eb5c":"code","f08d430b":"code","e143d14e":"code","11632882":"code","dccc5aca":"code","914d5ff0":"code","5c95223a":"code","98c2c9e0":"code","b213d989":"code","31329a21":"code","2f6dfe8b":"code","5a063db5":"code","5b18cfb4":"code","a1eddd06":"code","ac20f9e7":"markdown","f4e6cb3b":"markdown","144cbee3":"markdown","c2f52d6c":"markdown","fa020953":"markdown","0c7ff15b":"markdown","a46a52d7":"markdown","3af2738d":"markdown","520e3968":"markdown","921eabb9":"markdown","f77faf69":"markdown","649d6097":"markdown","50c3615e":"markdown","c9b0e1f6":"markdown","59b6d2a3":"markdown","c4e388e7":"markdown","10fd40d0":"markdown","df10730c":"markdown"},"source":{"1f6e37f2":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn","a7e8882a":"import warnings\nwarnings.filterwarnings('ignore')","9c31dd23":"dataset = pd.read_csv('..\/input\/mall-customers\/Mall_Customers.csv')\ndataset.sample(5)","fc6a079f":"dataset.index","f5256170":"#get information about data!!\ndataset.info()\n# Gender is object !!! I must gender convert int!","bf67c9a1":"# check miss value\ndataset.isnull().sum()\n# Dont have any miss value","071626cb":"# ENCODING Convert object to int\ndataset_select = dataset.replace({ 'Gender': {'Male':0 , 'Female':1}} )","4efd53ad":"dataset_select","e757c6e4":"# delete CustomerID from data frame\ndataset_select.drop([\"CustomerID\"], axis=1,inplace=True)","d2ea77a7":"dataset_select","c459b01a":"# Finding out the correlation between the features\ncorr = dataset_select.corr()\ncorr.shape","4011747e":"plt.figure(figsize=(20,20))\nsns.heatmap(corr, cbar=True, square= True, annot=True, annot_kws={'size':20}, cmap='YlGnBu')","99f83a9b":"print('seaborn: %s' % sns.__version__)","f65fcc8b":"dataset_select.columns ","a4ffd388":"dataset_select.columns = dataset_select.columns.str.replace(' ','_')","f2a95072":"dataset_select","63b03c73":"sns.displot(data = dataset_select, x = \"Annual_Income_(k$)\",hue = 'Genre') ","c9b7beb5":"plt.rcParams['figure.figsize'] = (18, 8)\nplt.subplot(1, 2, 1)\nsns.set(style = 'whitegrid')\nsns.distplot(dataset['Annual Income (k$)'])\nplt.title('Distribution of Annual Income', fontsize = 20)\nplt.xlabel('Range of Annual Income')\nplt.ylabel('Count')\n\n\nplt.subplot(1, 2, 2)\nsns.set(style = 'whitegrid')\nsns.distplot(dataset['Age'], color = 'red')\nplt.title('Distribution of Age', fontsize = 20)\nplt.xlabel('Range of Age')\nplt.ylabel('Count')\nplt.show()","3c912fab":"sns.countplot(dataset['Age'], palette = \"Set3\")\nplt.title('Distribution of Age', fontsize =10)\nplt.show()","e168c60d":"sns.displot(dataset, x=\"Annual Income (k$)\")\n\n","f3592710":"sns.pairplot(dataset_select)\nplt.title('Pairplot for the Data', fontsize = 20)\nplt.show()","ca0e97f9":"sns.displot(data=dataset, x=\"Annual Income (k$)\",hue='Genre',kind ='kde')","24bddab9":"sns.displot(data=dataset, x=\"Age\",hue='Genre',kind ='kde')","c09a7c2f":"sns.displot(data=dataset, x=\"Spending Score (1-100)\",hue='Genre',kind ='kde')","5027fa87":"sns.catplot(x='Spending Score (1-100)', y=\"Genre\",hue ='Genre',kind=\"violin\", data=dataset)","46e78619":"sns.catplot(x='Annual Income (k$)', y=\"Genre\",hue ='Genre',kind=\"violin\", data=dataset)","7c2614f1":"sns.catplot(x='Age', y=\"Genre\",hue ='Genre',kind=\"swarm\", data=dataset)","1e0f403c":"sns.lineplot(x = dataset['Annual Income (k$)'],y = dataset['Age'],color = 'green')","cfb1932b":"sns.lineplot(x =dataset['Spending Score (1-100)'],y = dataset['Age'],color = 'red')","3b2476f5":"from sklearn.cluster import KMeans\n","7ccd3a88":"dataset","b062d600":"# Select Age and Spending Score (1-100)\nX = dataset.iloc[:, [2, 4]].values","96470c3e":"wcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    #k-means++ is an algorithm for choosing the initial values (or \"seeds\") for the k-means clustering algorithm.\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","dab2150a":"#  Find  Elbow Curve\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","12c32c70":"# n_clusters = 4 --> Elbow Curve\nkmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)","7b3a3ada":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Age')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","a1c112f4":"# Annual Income (k$) and Spending Score (1-100)\nX = dataset.iloc[:, [3, 4]].values","354b10c1":"wcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    #k-means++ is an algorithm for choosing the initial values (or \"seeds\") for the k-means clustering algorithm.\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    \n#  Find  Elbow Curve\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()    ","9e0dc2ad":"# n_cluster = 5\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 2)\ny_kmeans = kmeans.fit_predict(X)\n","e7f534ad":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","0b9db9a3":"dataset.describe()","3eb855e7":"# Annual Income (k$) and Spending Score (1-100)\nX = dataset.iloc[:, [2, 3]].values","25f0eb5c":"wcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    #k-means++ is an algorithm for choosing the initial values (or \"seeds\") for the k-means clustering algorithm.\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    \n#  Find  Elbow Curve\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()    ","f08d430b":"# n_cluster = 4\nkmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 2)\ny_kmeans = kmeans.fit_predict(X)\n","e143d14e":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Age')\nplt.ylabel('Annual Income (k$)')\nplt.legend()\nplt.show()","11632882":"dataset_select","dccc5aca":"# Annual Income (k$) and Spending Score (1-100)\nX = dataset[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]","914d5ff0":"wcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    #k-means++ is an algorithm for choosing the initial values (or \"seeds\") for the k-means clustering algorithm.\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    \n#  Find  Elbow Curve\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()   ","5c95223a":"# n_cluster = 6 FOR 3 parameter---->'Age', 'Annual Income (k$)', 'Spending Score (1-100)'\n\n\ny_kmeans = KMeans(n_clusters = 6, init = 'k-means++', random_state = 2).fit(X)\n\nX_clustered = X.copy()\nX_clustered.loc[:,'Cluster'] =y_kmeans.labels_ # append labels to points\n\n","98c2c9e0":"from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(7, 7))\nax = Axes3D(fig, rect=[0, 0, .99, 1], elev=20, azim=210)\nax.scatter(X_clustered['Age'],\n           X_clustered['Annual Income (k$)'],\n           X_clustered['Spending Score (1-100)'],\n           c=X_clustered['Cluster'],\n           s=35, edgecolor='k', cmap=plt.cm.Set1)\n\nax.w_xaxis.set_ticklabels([])\nax.w_yaxis.set_ticklabels([])\nax.w_zaxis.set_ticklabels([])\nax.set_xlabel('Age')\nax.set_ylabel('Annual Income (k$)')\nax.set_zlabel('Spending Score (1-100)')\nax.set_title('3D view of K-Means 6 clusters')\nax.dist = 12\n\nplt.show()","b213d989":"from sklearn.cluster import DBSCAN","31329a21":"X = dataset[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]","2f6dfe8b":"from itertools import product\n\neps_values = np.arange(8,12.75,0.25) # eps values to be investigated\nmin_samples = np.arange(3,10) # min_samples values to be investigated\nDBSCAN_params = list(product(eps_values, min_samples))","5a063db5":"# label=-1 means the point is an outlier. Rest of the values represent the label\/cluster number starting from 0\n#\nB=[]\nD=[]\nSil = []\nfor p in DBSCAN_params:\n    DBS = DBSCAN(eps=p[0], min_samples=p[1]).fit(X)\n    B.append(DBS)\n    D.append(DBS.labels_)\n    Sil.append(sklearn.metrics.silhouette_score(X, DBS.labels_))\nmax_index = Sil. index(max(Sil)) \nlabel = D[max_index]\nlabel = label.tolist()\n#set() method is used to convert any of the iterable to sequence of iterable elements with distinct elements,\n#                                        commonly called Set. \nprint(set(label))\n# This command determines whether there is a negative number one in the existing list or not. ---> find outlier  \nprint((1 if -1 in label else 0))\nn_clusters=len(set(label))- (1 if -1 in label else 0)\nprint('No of best clusters:',n_clusters)\nB[max_index]\n\n  \n","5b18cfb4":"X = dataset[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]","a1eddd06":"from sklearn.cluster import DBSCAN\ny_DB=DBSCAN(eps=12.5,min_samples=4,metric='euclidean').fit(X)\nX_clustered = X.copy()\nX_clustered.loc[:,'Cluster'] =y_DB.labels_ # append labels to points\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(7, 7))\nax = Axes3D(fig, rect=[0, 0, .99, 1], elev=20, azim=210)\nax.scatter(X_clustered['Age'],\n           X_clustered['Annual Income (k$)'],\n           X_clustered['Spending Score (1-100)'],\n           c=X_clustered['Cluster'],\n           s=35, edgecolor='k', cmap=plt.cm.Set1)\n\nax.w_xaxis.set_ticklabels([])\nax.w_yaxis.set_ticklabels([])\nax.w_zaxis.set_ticklabels([])\nax.set_xlabel('Age')\nax.set_ylabel('Annual Income (k$)')\nax.set_zlabel('Spending Score (1-100)')\nax.set_title('3D view of K-Means 5 clusters')\nax.dist = 12\n\nplt.show()\n\n\n","ac20f9e7":"## DBSACN","f4e6cb3b":"# In the following section, I used an innovative method so that the loop was used to calculate the maximum value and the most appropriate hyperparameters.","144cbee3":"<div class=\"alert alert-block alert-info\" dir=\"ltr\" style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 20pt;\">K-means <\/span><\/strong>\n<p style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\"> \n<\/div>","c2f52d6c":"<img src = \"https:\/\/miro.medium.com\/max\/5760\/1*_SRbz8535-CxPzo6IL9pBA.png\" width=80%>","fa020953":"<div class=\"alert alert-block alert-info\" dir=\"ltr\" style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\">Prepare Data and EDA <\/span><\/strong>\n<p style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\"> \n<\/div>","0c7ff15b":"## Strorytelling - Visualization","a46a52d7":"# Thank you for your attention","3af2738d":"## Trani the Model (Clustering)","520e3968":"<div class=\"alert alert-block alert-info\" dir=\"ltr\" style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\">load Data <\/span><\/strong>\n<p style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\"> \n<\/div>","921eabb9":"## Using K-means in Action","f77faf69":"## Load and Prepare Data","649d6097":" <div class=\"alert alert-block alert-info\" dir=\"ltr\" style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 20pt;\">DBSCAN <\/span><\/strong>\n<p style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\"> \n<\/div>","50c3615e":" <div class=\"alert alert-block alert-info\" dir=\"ltr\" style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 20pt;\">The End <\/span><\/strong>\n<p style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\"> \n<\/div>","c9b0e1f6":"<div class=\"alert alert-block alert-success\">\n    <h1 align=\"center\">Machine Learning in Python<\/h1>\n    <h3 align=\"center\">Clustering<\/h3>\n<\/div>","59b6d2a3":"# In this section we tried to prepare the values below ****eps & min**** by giving a range as a list","c4e388e7":"## Importing the libraries","10fd40d0":"<div class=\"alert alert-block alert-info\" dir=\"ltr\" style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\">Strorytelling - Visualization <\/span><\/strong>\n<p style=\"text-align: center;\"><strong><span style=\"font-family: courier new, courier; font-size: 18pt;\"> \n<\/div>","df10730c":"## EDA & Data Preprocessing"}}