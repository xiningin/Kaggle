{"cell_type":{"438f5d48":"code","257c4d3c":"code","68afcb4c":"code","2757c2ea":"code","0fcc2fd9":"code","8f34fe2e":"code","786ffbd9":"code","bc686ba3":"code","f8f0a2f0":"code","fbbc081a":"code","120fdaa9":"code","7e6c6739":"markdown","05272ceb":"markdown","ec3dda6d":"markdown","d6897957":"markdown","1033b536":"markdown","d698586c":"markdown","d7b6fb33":"markdown","e5c4d2b0":"markdown","b2ea8889":"markdown"},"source":{"438f5d48":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.collections import LineCollection\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import Image, display\nfrom skimage import io\nfrom skimage.transform import rotate as sk_rotate\nimport math\n%matplotlib inline","257c4d3c":"PATH = '..\/input\/mlcourse-dota2-win-prediction\/'\ntrain = pd.read_csv(PATH + 'train_features.csv', index_col='match_id_hash')\ntarget = pd.read_csv(PATH + 'train_targets.csv', index_col='match_id_hash')\nimage = io.imread('https:\/\/i.imgur.com\/a7KCt5J.jpg')","68afcb4c":"# I am adding jitter because x and y are integers.\n# This is just an aid for visualization in the plot.\n# In the competition we would not do this with the real data!\n\ntrain['r1_x'] = train['r1_x']*(1+np.random.normal(loc=0, scale=0.01, size=len(train)))\ntrain['r1_y'] = train['r1_y']*(1+np.random.normal(loc=0, scale=0.01, size=len(train)))\n","2757c2ea":"# set up the main figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\n# initialize the subplots as blank scatterplots\nscat1, = ax1.plot([], [], 'o', color='blue', alpha=0.1)\nscat2, = ax2.plot([], [], 'o', color='red', alpha=0.1)\nscat = [scat1, scat2]\n\n# turn axis lines and ticks off; add the background image of the map\n# the \"extent\" tells matplotlib how to stretch the image\nax1.axis('off')\nax2.axis('off')\nax1.imshow(image, extent=[65, 190, 65, 185], alpha=0.35);\nax2.imshow(image, extent=[65, 190, 65, 185], alpha=0.35);\n\n# set the subplot axis limits and title font\nfor ax in [ax1, ax2]:\n    ax.set_ylim(70, 190)\n    ax.set_xlim(70, 190)\n    ax.set_title('', fontweight=\"bold\", size=20)\n    ax.grid()\n\n# the matplotlib \"FuncAnimation\" class requires an init and animate function\ndef init():\n    scat[0].set_data([], [])\n    scat[1].set_data([], [])\n    return scat\n\ndef animate(i):\n    # i is frames incrementing\n    minutes = i*2\n    train_cut = train.query('game_time < 60*@minutes')\n    target_cut = target.loc[train_cut.index]['radiant_win']\n    \n    # update Radiant win plot\n    x = train_cut[target_cut==1]['r1_x']\n    y = train_cut[target_cut==1]['r1_y']\n    scat[0].set_data(x, y)\n    ax1.title.set_text(f'r1 loc for Radiant WIN at time < {minutes} minutes')\n    \n    # update Radiant loss plot\n    x = train_cut[target_cut==0]['r1_x']\n    y = train_cut[target_cut==0]['r1_y']\n    scat[1].set_data(x, y)\n    ax2.title.set_text(f'r1 loc for Radiant LOSS at time < {minutes} minutes')\n\n    return scat\n\nanim = FuncAnimation(\n    fig,\n    animate,\n    init_func=init,\n    frames=21,\n    interval=500,   # time in milliseconds between each frame\n    blit=True\n);\n\nplt.close(fig)  # don't show fig yet... suspense!!!\n\nanim.save('map.gif', writer='imagemagick');","0fcc2fd9":"# in order to diplay in Jupyter notebook, we need to wrap it as\ndisplay(Image(url='map.gif'))","8f34fe2e":"minutes = 30\ntrain_cut = train.query('game_time < 60*@minutes')\ntarget_cut = target.loc[train_cut.index]['radiant_win']\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.imshow(image, extent=[65, 190, 65, 185], alpha=0.6);\n\nplt.scatter(train_cut[target_cut==1]['r1_x'], train_cut[target_cut==1]['r1_y'], alpha=0.1, c='blue');\nplt.title(f'r1 loc for Radiant WIN at time < {minutes} minutes', fontweight=\"bold\", size=20);\n\n# annotation lines\nl1 = [(83, 95), (170, 175)]\nl2 = [(83, 77), (170, 157)]\nl3 = [(100, 180), (180, 100)]\nl4 = [(70, 145), (145, 70)]\n\nlc = LineCollection([l1, l2, l3, l4], color = ['k', 'k'], lw=2) # linestyle='dashed', \nplt.gca().add_collection(lc)\nplt.axis('off');\n\nplt.subplot(1, 2, 2)\nplt.imshow(image, extent=[65, 190, 65, 185], alpha=0.6);\nplt.scatter(train_cut[target_cut==0]['r1_x'], train_cut[target_cut==0]['r1_y'], alpha=0.1, c='red');\nplt.title(f'r1 loc for Radiant LOSS at time < {minutes} minutes', fontweight=\"bold\", size=20);\n\nlc = LineCollection([l1, l2, l3, l4], color = ['k', 'k'], lw=2) # linestyle='dashed', \nplt.gca().add_collection(lc);\nplt.axis('off');","786ffbd9":"map_center = (127., 127.)\n\ndef rotate(origin, point, angle):\n    \"\"\"\n    Rotate a point counterclockwise by a given angle around a given origin.\n    The angle should be given in radians.\n    \"\"\"\n    ox, oy = origin\n    px, py = point\n\n    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n    return qx, qy","bc686ba3":"train['r1_x_rot'] = train.apply(lambda row: rotate(map_center, (row.r1_x, row.r1_y), 0.785398)[0], axis=1)\ntrain['r1_y_rot'] = train.apply(lambda row: rotate(map_center, (row.r1_x, row.r1_y), 0.785398)[1], axis=1)","f8f0a2f0":"# and we have to rotate the map image as well :-)\nimage_rot = sk_rotate(image, angle=45, resize=True)","fbbc081a":"# rotate our annotation lines\n\nl1_rot = []\nl2_rot = []\nl3_rot = []\nl4_rot = []\n\nfor pt in l1:\n    l1_rot.append(rotate(map_center, pt,  0.785398))\nfor pt in l2:\n    l2_rot.append(rotate(map_center, pt,  0.785398))\nfor pt in l3:\n    l3_rot.append(rotate(map_center, pt,  0.785398))\nfor pt in l4:\n    l4_rot.append(rotate(map_center, pt,  0.785398))    \n","120fdaa9":"minutes = 30\ntrain_cut = train.query('game_time < 60*@minutes')\ntarget_cut = target.loc[train_cut.index]['radiant_win']\nplt.figure(figsize=(22,10))\nplt.subplot(1, 2, 1)\nplt.imshow(image_rot, extent=[54, 200, 47, 203], alpha=0.6);\nplt.scatter(train_cut[target_cut==1]['r1_x_rot'], train_cut[target_cut==1]['r1_y_rot'], alpha=0.1, c='blue');\nplt.title(f'r1 loc for Radiant WIN at time < {minutes} minutes', fontweight=\"bold\", size=20);\n\nlc = LineCollection([l1_rot, l2_rot, l3_rot, l4_rot], color = ['k', 'k'], lw=2) # linestyle='dashed', \nplt.gca().add_collection(lc)\n\nplt.axis('off');\nplt.subplot(1, 2, 2)\nplt.imshow(image_rot, extent=[54, 200, 47, 203], alpha=0.6);\nplt.scatter(train_cut[target_cut==0]['r1_x_rot'], train_cut[target_cut==0]['r1_y_rot'], alpha=0.1, c='red');\nplt.title(f'r1 loc for Radiant LOSS at time < {minutes} minutes', fontweight=\"bold\", size=20);\n\nlc = LineCollection([l1_rot, l2_rot, l3_rot, l4_rot], color = ['k', 'k'], lw=2) # linestyle='dashed', \nplt.gca().add_collection(lc)\nplt.axis('off');","7e6c6739":"With the addition of the **rotation points**, now GBDT can split parallel to a board axis and capture important hero location in a **single split** (or just two in the case of finding heroes in the middle lane). We will leave both the raw `r1_x`, `r2_x`, etc. and add the rotated points.\n\nI got the idea to rotate the map from a watching a talk on YouTube by [@cpmpml](https:\/\/www.kaggle.com\/cpmpml) at [Kaggle Days Paris](https:\/\/www.youtube.com\/watch?v=VC8Jc9_lNoY). He talks about rotating apartment location coordinates for New York City so that XGBoost can split easily on the avenues and streets (NYC is not naturally longitude and lattitude parallel).\n\nThanks for looking at my kernel!","05272ceb":"Watch it loop a few times. You can see some clear pattern in the case of Radiant wins which makes sense ...\n\n- **less** times where R1 is near his or her home\n- **more** times when R1 is near Dire home\n\nNote also that there is a lot of presence in the **middle lane**.","ec3dda6d":"We make new features with each hero's location rotated 45 degrees counterclockwise.","d6897957":"<center>\n\n### \"Always pay respect to EDA\". --[@utility](https:\/\/www.kaggle.com\/utility)\n\n","1033b536":"We want to capture regions **separated by diagonals**. With the addition of the annotation lines, we can see clearly that certain areas of the map are important to distinguish between Radiant win or loss. To make it easy for GBDT to separate on these diagonals with a single (or just two) splits, we can **rotate** the board by -45 (need in radians, $45^{\\circ} \\pi 180 =  0.785398$ radians).","d698586c":"<center>\n\n![image.png](attachment:image.png)\n\n### **Dota 2 Board Map 6.86 Patch**","d7b6fb33":"# Dota 2 EDA on Coordinates (Animated!)\n\nby [@marketneutral](https:\/\/www.kaggle.com\/marketneutral)\n\nThis notebook contains some fragments of EDA (Exploratory Data Analysis) which I used profitably in this competition. It also shows how to animate `matplotlib` plots for your future medal winning Kaggle kernels. I do not give you final features themselves in this kernel...but you can figure them out from the EDA.\n\nNote that I am not a Dota player -- I've never played! Thanks to [@koshiu](https:\/\/www.kaggle.com\/koshiu) for help finding the right map image for this kernel! :-)\n","e5c4d2b0":"# Hero Location Over Time\n\nLocation of heroes proved to be a fruitful area of feature engineering. Before engineering, it's EDA time... Let's look at an animation to answer the question: \"how does the location of Radiant Hero 1 differ in cases of **Radiant Win** vs **Radiant Loss** as a function of `game_time`\"? Then we can extrapolate and perhaps make team-wise features...\n","b2ea8889":"# Map Orientation\n\nWhen you make features there are a couple philosophies... *heavy* vs *light* engineering. Light means you make some small transformation to make the feature simply more compatible with the model. Heavy means...well...you make some significant transformations, combine features explicitly, and explicitly specify interactions. Let's think about light engineering here. We posit above that target (Radiant Win) is proportional to a strong presenence of Radiant Heroes near Dire home. In the case of GBDT (e.g., `LightGBM`), the model should find this on it's own if it splits on `r1_x`, `r1_y`, etc. But...there is a problem. One possible issue is with the *map orientation*. A decision tree can only make splits **parallel to an axis.** We saw in `mlcourse.ai` materials:\n\nSource: https:\/\/mlcourse.ai\/articles\/topic3-dt-knn\/\n![image.png](attachment:image.png)\n\nIn this case, to split on the diagonal you need many splits and a deep tree. That's silly and too complex, especially in the case of GBDT where we will want a large ensemble of shallow trees. To capture a separation on the diagonal uses up too many splits. So what can we do?"}}