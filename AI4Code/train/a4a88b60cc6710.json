{"cell_type":{"7dc1febb":"code","3f46cbb6":"code","918a0c57":"code","0d469bf3":"code","2d87a53e":"code","323ce6fd":"code","55fa712c":"code","17211940":"code","24bc51bc":"code","4847c23a":"code","94fe73c1":"code","97687040":"code","ebe0b941":"code","3b66c7ae":"code","259c3de9":"code","3f3f1b49":"code","759ddb18":"code","c2bb8b19":"code","28c033f1":"code","fc1cfaa9":"code","c3cc9381":"code","bfaefe23":"code","8fd7d8d2":"code","b6279c2e":"code","76f08c5b":"code","4bba1d58":"code","30165787":"code","834108e4":"code","8b7444de":"code","ee881d5a":"code","92cf657e":"code","c449335b":"code","18ae7c03":"code","f8c753ce":"code","9fe2a154":"code","a4f1e4e6":"code","2e3e92d4":"code","6582fa46":"markdown","6aca76ac":"markdown","f89d85e0":"markdown","7460430d":"markdown","ca537f7d":"markdown","3e3c339b":"markdown","3739bb62":"markdown","b128e18a":"markdown","cf087b13":"markdown","de05c4cf":"markdown","eb9f9926":"markdown","18d5f792":"markdown","c79597a7":"markdown","502b0bc8":"markdown","4f27beb9":"markdown","b23dd689":"markdown","0df5a1c7":"markdown","ce95a407":"markdown","576812d6":"markdown","3daa49e5":"markdown","62bd5e29":"markdown","2dbe3f78":"markdown","c5a017de":"markdown"},"source":{"7dc1febb":"import json\n","3f46cbb6":"#List of names of .json files\njson_files = [\"ver1_scrapedweb-1023.json\", \"ver1_scrapedweb-1024.json\", \"ver1_scrapedweb-1025.json\",\n              \"ver1_scrapedweb-1026.json\", \"ver1_scrapedweb-1027.json\", \"ver1_scrapedweb-1030.json\",\n              \"ver1_scrapedweb-1031.json\", \"ver1_scrapedweb-1032.json\", \"ver1_scrapedweb-1033.json\",\n              \"ver1_scrapedweb-1034.json\", \"ver1_scrapedweb-1035.json\", \"ver1_scrapedweb-1036.json\",\n              \"ver1_scrapedweb-1037.json\", \"ver1_scrapedweb-1063.json\", \"ver1_scrapedweb-1065.json\",\n              \"ver1_scrapedweb-1068.json\", \"ver1_scrapedweb-107.json\", \"ver1_scrapedweb-1070.json\",\n              ]","918a0c57":"text =[]\nfor i in range(18):\n    path = \"..\/input\/scrapedweb-text\/{0}\".format(json_files[i])\n    f = open(path,)\n    data = json.load(f)\n    text.append(data)\ntext","0d469bf3":"pip install pyLDAvis","2d87a53e":"import os\nimport pandas as pd\nimport re\nimport numpy as np\n\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim_models  \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n","323ce6fd":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nstop_words.append('n')\nstop_words.append('r')","55fa712c":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()","17211940":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()","24bc51bc":"from nltk.util import bigrams\nnltk.download('punkt')\nnltk.download('wordnet')","4847c23a":"filtered_text = []     #TO STORE THE PROCESSED DATA\n\nbigrams = []    \nfor t in text:\n    filtered_sentence = \"\"\n    stemmed_list = []\n    lemmatized_list = []\n    \n    sentence = str(t)\n\n    #Data Cleansing\n    sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n\n\n    #Removing numbers\n    sentence = re.sub(r'[0-9]', '', sentence)\n    \n    #Tokenization\n    words = nltk.word_tokenize(sentence)\n    \n    #Stop words removal\n    words = [w for w in words if not w in stop_words]\n    \n    #Stemming\n    for word in words:\n        stemmed_word = stemmer.stem(word)\n        stemmed_list.append(stemmed_word)\n        \n    #Lemmatization\n    for s_word in stemmed_list:\n        lemmatized_word = lemmatizer.lemmatize(s_word)\n        lemmatized_list.append(lemmatized_word)\n\n    \n    lemmatized_list = [i for i in lemmatized_list if len(i) >= 3]\n    \n    filtered_text.append(lemmatized_list)  ","94fe73c1":"filtered_text","97687040":"len(filtered_text)","ebe0b941":"# Build the bigram and trigram models\nbigram = gensim.models.Phrases(filtered_text) # higher threshold fewer phrases.\ntrigram = gensim.models.Phrases(bigram[filtered_text])  \n\n# Faster way to get a sentence clubbed as a trigram\/bigram\nbigram_mod = gensim.models.phrases.Phraser(bigram)\ntrigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# See trigram example\nfor i in range(len(filtered_text)):\n    print(trigram_mod[bigram_mod[filtered_text[i]]])","3b66c7ae":"# Create Dictionary\nid2word = corpora.Dictionary(filtered_text)\n\n# Create Corpus\ntexts = filtered_text\n\n# Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in texts]\n\n# View\nprint(corpus)","259c3de9":"id2word[0]","3f3f1b49":"len(corpus)","759ddb18":"# Human readable format of corpus (term-frequency)\n[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n","c2bb8b19":"lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=7, \n                                           random_state=0,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)","28c033f1":"# Print the Keyword in the 10 topics\nfrom pprint import pprint\npprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","fc1cfaa9":"Topics = [\"Art\", \"Vacation\", \"Music\", \"Person\", \"Movie\", \"Art Education\", \"Movie\"]","c3cc9381":"table_head = ['Topic', 'Keywords']","bfaefe23":"df = pd.DataFrame(zip(Topics, lda_model.print_topics()), columns= table_head)\ndf","8fd7d8d2":"# Compute Perplexity\nprint('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=filtered_text, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","b6279c2e":"# Visualize the topics\nimport pyLDAvis.gensim_models\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\nvis\n","76f08c5b":"# 1. Wordcloud of Top N words in each topic\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.colors as mcolors\n\ncols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n\ncloud = WordCloud(stopwords=stop_words,\n                  background_color='white',\n                  width=2500,\n                  height=1800,\n                  max_words=30,\n                  colormap='tab10',\n                  contour_color='steelblue',\n                  color_func=lambda *args, **kwargs: cols[i])\n\ntopics = lda_model.show_topics(formatted=False)\n\nfig, axes = plt.subplots(3, 2, figsize=(10,10), sharex=True, sharey=True)\n\nfor i, ax in enumerate(axes.flatten()):\n    fig.add_subplot(ax)\n    topic_words = dict(topics[i][1])\n    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n    plt.gca().imshow(cloud)\n    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n    plt.gca().axis('off')\n\n\nplt.subplots_adjust(wspace=20, hspace=20)\nplt.axis('off')\nplt.margins(x=10, y=10)\nplt.tight_layout()\nplt.show()","4bba1d58":"import os\ndef install_java_jdk():\n  !apt-get install -y openjdk-8-jdk-headless -qq > \/dev\/null\n  os.environ[\"JAVA_HOME\"] = \"\/usr\/lib\/jvm\/java-8-openjdk-amd64\"\n  !java -version\n\ninstall_java_jdk","30165787":"!wget http:\/\/mallet.cs.umass.edu\/dist\/mallet-2.0.8.zip\n!unzip mallet-2.0.8.zip","834108e4":"from google.colab import drive\ndrive.mount('\/content\/gdrive')\n%cd gdrive","8b7444de":"os.environ['MALLET_HOME'] = '\/content\/mallet-2.0.8'\nmallet_path = '\/content\/mallet-2.0.8\/bin\/mallet'","ee881d5a":"ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus = corpus, num_topics = 7, id2word = id2word)","92cf657e":"# Show Topics\npprint(ldamallet.show_topics(formatted=False))\n\n# Compute Coherence Score\ncoherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=filtered_text, dictionary=id2word, coherence='c_v')\ncoherence_ldamallet = coherence_model_ldamallet.get_coherence()\nprint('\\nCoherence Score: ', coherence_ldamallet)","c449335b":"def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values","18ae7c03":"model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=filtered_text, start=2, limit=40, step=6)","f8c753ce":"# Show graph\nlimit=40; start=2; step=6;\nx = range(start, limit, step)\nplt.plot(x, coherence_values)\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.show()","9fe2a154":"# Print the coherence scores\nfor m, cv in zip(x, coherence_values):\n    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 3))","a4f1e4e6":"Topic_distribution= []\nfor i in range(18):\n  tokens = [stemmer.stem(token) for token in nltk.word_tokenize(text[i].lower()) if token not in stop_words]\n  print(lda_model[id2word.doc2bow(tokens)][0])\n  Topic_distribution.append(lda_model[id2word.doc2bow(tokens)][0])","2e3e92d4":"tab_head = [\"Web Page File\", \"Tokenized Text\", \"Topics Distribution\"]\ndf_data = pd.DataFrame(zip(text,filtered_text, Topic_distribution), columns = tab_head)\nprint(df_data)","6582fa46":"### Extracting text from .json files.","6aca76ac":"## PROCESSED TEXT","f89d85e0":"FOR LEMMATIZATION","7460430d":"### Bigram amd Trigram Formation","ca537f7d":"### Creating the dictionary and the corpus needed for topic Modeling.","3e3c339b":"### TERM FREQUENCY","3739bb62":"CLEANING AND FILTERING RAW TEXT","b128e18a":"FOR BIGRAMS","cf087b13":"FOR STEMMING","de05c4cf":"## Word Clouds of Top N Keywords in Each Topic","eb9f9926":"### LdaMallet Model","18d5f792":"## VIEWING THE TOPICS IN LDA MODEL","c79597a7":"The coherence score obtained from LdaMallet model is lower as compared to LdaModel.","502b0bc8":"### DATAFRAME :\nDISPLAYING THE PERCENTAGE DISTRIBUTION OF TOPICS IN EACH DOCUMNET","4f27beb9":"### FOR STOPWORDS","b23dd689":"## BUILDING THE LDA TOPIC MODEL","0df5a1c7":"Following code is to access mallet in Google Colab.","ce95a407":"### IMPORTING .JSON FILES","576812d6":"## TOPICS DISTRIBUTION","3daa49e5":"### LDA MALLET","62bd5e29":"## IMPORTING THE LIBRARIES AND INSTALLING THE PACKAGES","2dbe3f78":"### Visualizing the topics-keywords","c5a017de":"### Computing Model Perplexity and Coherence Score"}}