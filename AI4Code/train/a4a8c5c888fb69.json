{"cell_type":{"c3b32ff4":"code","1ee6c834":"code","7ded3042":"code","2f374230":"code","5300cbb1":"code","c2a0afde":"code","6f9428f0":"code","f933ef69":"code","a3c7bd8f":"code","e428316d":"code","f756d6f4":"code","fc1870b8":"code","d0b28398":"code","2d3e4202":"code","fd6a4f09":"code","b8c7288f":"code","232906f8":"code","72c8ca48":"code","ab2886b2":"code","091ef506":"code","ac330e7a":"code","6772e3ee":"code","fec76044":"code","3a965dd8":"code","b5c36b11":"code","3db36613":"code","4cc37cb4":"code","701af123":"code","c1fb10b7":"code","5ee44bf5":"code","3a91cfe8":"code","ac2075d9":"code","a5209315":"code","4841bdaf":"code","7ee050fb":"code","8596ac6f":"code","9dc15d0f":"code","40c7f40c":"code","6763b9d7":"code","67ea2a95":"code","d82f3d11":"code","4aad5981":"code","4468212e":"code","e332d58b":"code","0f7b5a2a":"code","7828b410":"code","feacc542":"code","131460ce":"code","169d77be":"code","4250c458":"code","0894c78e":"code","07cab289":"code","db70f065":"code","cdb3ef5e":"code","2838e67e":"code","82c318d5":"code","cf4d34e7":"code","2805d1a1":"code","85becbd2":"code","adeab0a3":"code","2ecbb338":"code","d68bd1ad":"code","d88fb21e":"code","426bc2c5":"code","4fbbe71d":"code","5fa983e6":"code","88a1723e":"code","6c5e3a63":"code","45620a3b":"code","e472a713":"code","21557699":"code","ce3eb483":"code","df24c8c2":"code","f36ae357":"code","60561c09":"markdown","da3eb852":"markdown","b47a2234":"markdown","812d7eb4":"markdown","a5ad3a01":"markdown","0c0684d0":"markdown","4d41431a":"markdown","864e5774":"markdown","739d661e":"markdown","dda10ab3":"markdown","20d99cb4":"markdown","d3339fe2":"markdown","be6e4d88":"markdown","db9e21b5":"markdown","a897a385":"markdown","fe7df3ea":"markdown","4422fea5":"markdown","8f158ab2":"markdown","aeafa55f":"markdown","bd17b839":"markdown","0cc05662":"markdown","6527f05c":"markdown","0769ac1a":"markdown","873af69c":"markdown","4092dda8":"markdown","c9a0fbc2":"markdown","7e4536d6":"markdown","215ed38c":"markdown","561c50c2":"markdown","719f0811":"markdown","e3e96ef6":"markdown","ccefeae6":"markdown","440b5158":"markdown","2821f11e":"markdown"},"source":{"c3b32ff4":"import numpy as np\nimport keras\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n# calculate accuracy measures and confusion matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, auc\nwarnings.filterwarnings('ignore')","1ee6c834":"import tensorflow as tf\nprint(tf.__version__)","7ded3042":"\n#importing the dataset, set RowNumber as index\n#load the csv file and make the data frame\ndf = pd.read_csv('\/kaggle\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv',index_col='RowNumber')","2f374230":"df.shape # 10,000 rows, 13 columns","5300cbb1":"df.head(2) #Exited is target column","c2a0afde":"#Check datatypes\ndf.info()","6f9428f0":"#Check for missing values\ndf.isna().sum()","f933ef69":"#look at distribution of exited and non-exited customers","a3c7bd8f":"sns.countplot(x=\"Exited\", data=df)","e428316d":"sns.countplot(x=\"Gender\", data=df)","f756d6f4":"sns.countplot(x=\"Geography\", data=df)","fc1870b8":" sns.countplot(x=\"Exited\", hue=\"Gender\", data=df)","d0b28398":" sns.countplot(x=\"Exited\", hue=\"Geography\", data=df)","2d3e4202":"#Lets Check Distribution of exited\/non-exited Customers as per the age","fd6a4f09":"sns.distplot(df['Age'][df['Exited']==0],color='blue',label='non-exited')\nsns.distplot(df['Age'][df['Exited']==1],color='red',label='exited')\nplt.show()\n\n","b8c7288f":"df.columns","232906f8":"# Convert data into feature and Target set. Also CustomerId and Surname will not contribute to model building\n#hence we wil drop these 2 colmns as well\nX=df.drop(labels=['CustomerId','Surname','Exited'], axis=1) # Feature Set\ny=df['Exited'] # Target set","72c8ca48":"X.info()","ab2886b2":"# Geography and gender are object type, we will convert this into one hot encoding","091ef506":"X= pd.get_dummies(X)","ac330e7a":"X.info()","6772e3ee":"#Lets Check first few rows of feature set","fec76044":"X.head()","3a965dd8":"from sklearn.model_selection import train_test_split\n#test train split\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","b5c36b11":"#hCheck Shape of test\/trainset\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","3db36613":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","4cc37cb4":"X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']].head(2)","701af123":"X_train.head(2)","c1fb10b7":"scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])","5ee44bf5":"X_train_scaled=scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])","3a91cfe8":"# Transform test set on the same fit as train set\nX_test_scaled=scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])","ac2075d9":"# Put back scaled data into the dataframe for the columns which  have been scaled while keeping other data intact\nX_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]=X_train_scaled","a5209315":"X_train.head(2)","4841bdaf":"X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]=X_test_scaled","7ee050fb":"X_test.head(2)","8596ac6f":"# Convert Data into Numpy arrays\nX_train_array=np.array(X_train)\nX_test_array=np.array(X_test)\ny_train_array=np.array(y_train)\ny_test_array=np.array(y_test)","9dc15d0f":"\nX_train_array.shape,X_test_array.shape,y_train_array.shape,y_test_array.shape#check shapes of array","40c7f40c":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_2'))\n\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))\n","6763b9d7":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","67ea2a95":"model.summary()","d82f3d11":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n          batch_size = 32)","4aad5981":"model.predict(X_test_array)[:5] # Observe first 5 probabilities","4468212e":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","e332d58b":"y_test_preds[:5] # Observe First 5 predictions","0f7b5a2a":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test, y_test_preds)","7828b410":"print('Test Metrics at 0.5 Threshold with basic DNN model\\n')\nTest_Metrics_Basic_DNN=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test, y_test_preds), \n                   precision_score(y_test, y_test_preds),\n                   f1_score(y_test, y_test_preds)], columns=['Basic DNN'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_Basic_DNN)","feacc542":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","131460ce":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","169d77be":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n          batch_size = 32)","4250c458":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","0894c78e":"print('Test Metrics at 0.5 Threshold with 3 Hidden layer DNN model\\n')\nTest_Metrics_3_HiddenLayer_DNN=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['3 Hidden Layer DNN'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_3_HiddenLayer_DNN)","07cab289":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","db70f065":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n# Batch Normalization Layer\n#model.add(tf.keras.layers.BatchNormalization())\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","cdb3ef5e":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","2838e67e":"model.summary()","82c318d5":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n          batch_size = 32)","cf4d34e7":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","2805d1a1":"print('Test Metrics at 0.5 Threshold with  Batch Norm after each hidden layer DNN model\\n')\nTest_Metrics_BatchNorm=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['BatchNorm Hidden layers'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_BatchNorm)","85becbd2":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","adeab0a3":"from keras import initializers","2ecbb338":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, kernel_initializer='he_normal', bias_initializer='Ones',activation='relu', name='Layer_1'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(13, kernel_initializer='he_normal',bias_initializer='Ones',activation='relu', name='Layer_2'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(10,kernel_initializer='he_normal',bias_initializer='Ones', activation='relu', name='Layer_3'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","d68bd1ad":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","d88fb21e":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=50,\n          batch_size = 32)","426bc2c5":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","4fbbe71d":"print('Test Metrics at 0.5 Threshold withv Weight and Bias initialization &  Batch Norm after each hidden layer DNN model\\n')\nTest_Metrics_Weight_Init=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['Weight Initialize'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_Weight_Init)","5fa983e6":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","88a1723e":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n\n# Dropout layer\nmodel.add(tf.keras.layers.Dropout(0.5))\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n\n\n# Dropout layer\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","6c5e3a63":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","45620a3b":"model.summary()","e472a713":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=100,\n          batch_size = 32, verbose=0)","21557699":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","ce3eb483":"print('Test Metrics at 0.5 Threshold Dropout DNN model\\n')\nTest_Metrics_DropOut=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['DropOut'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_DropOut)","df24c8c2":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","f36ae357":"Model_Comparison_df=Test_Metrics_Basic_DNN\nModel_Comparison_df['3 Hidden Layer DNN']=Test_Metrics_3_HiddenLayer_DNN['3 Hidden Layer DNN']\nModel_Comparison_df['BatchNorm Hidden layers']=Test_Metrics_BatchNorm['BatchNorm Hidden layers']\nModel_Comparison_df['Weight Initialize']=Test_Metrics_Weight_Init['Weight Initialize']\nModel_Comparison_df['DropOut']=Test_Metrics_DropOut['DropOut']\n#Model_Comparison_df['Naive Bayes']=Naive_Bayes_metrics['Naive Bayes']\nModel_Comparison_df","60561c09":"Bank has bout 4500 female customers and 5500 male customers","da3eb852":"#### C) Using Weight and Bias initializer","b47a2234":"#### B) With Batch normalisation after each hidden layer","812d7eb4":"#### 5. Normalize the train and test data \n\na)Normalise Following features using standard scaler: CreditScore,Age, tenure,Balance,NumOfProducts,EstimatedSalary as these  have running\/continuous values\n\nb)We will not normalise following features as they have discrete values either 0 or 1: HasCrCard,IsActiveMember,Geography_France,Geography_Germany,Geography_Spain,Gender_Female,Gender_Male\n","a5ad3a01":"#### Confusion Matrix","0c0684d0":"Data set has has only around 2000 exited customers and about 8000 Customers are still with Bank- it has bias towards existing customers.","4d41431a":"Age distribution of customers who exited bank is normally distributed while those who stays with bank is right skewed\nindicating that most of the existing customers of bank are lower than 50 years of age. This may also indicate that\nold age customers have exited the bank.","864e5774":"#### 1. Read the dataset","739d661e":"#### Accuracy has dropped","dda10ab3":"Above plot says that female customers have higher propensity to exit the Bank","20d99cb4":"#### 4. Divide the data set into training and test sets","d3339fe2":"Surname, Gender and Gepgraphy are Object type","be6e4d88":"#### 2. Drop the columns which are unique for all users like IDs & 3. Distinguish the feature and target set","db9e21b5":"#### Overall Accuracy, recall and F1 score has improved after adding Batch Normalisation after each hidden layer","a897a385":"Customers from Germany have highest propensity to to exit the Bank","fe7df3ea":"### MODEL BUILDING","4422fea5":"#### 5.Predict the results using 0.5 as a threshold","8f158ab2":"#### Fit Model & Prediction","aeafa55f":"#### A) With 3 Dense Layer","bd17b839":"Object columns- Geography and Genders have been converted to one hot encoded columns","0cc05662":" There is no missing values","6527f05c":"##### Summarise Model","0769ac1a":"Most of the Customers are from France,  Customers from spain and Genrmany are about half in numbers of France","873af69c":"### MODEL TUNING","4092dda8":"##### Convert Data into Numpy arrays","c9a0fbc2":"### EDA & Data Preprocessing","7e4536d6":"##### Following step puts back scaled data into the dataframe for the columns which  have been scaled while keeping other data intact","215ed38c":"### MODEL COMPARISON","561c50c2":"#### D) Apply Dropout","719f0811":"##### Among the models tried above Model with bath normalization after each hidden layer gives best Accurracy and F1 score","e3e96ef6":"##### Compile Model","ccefeae6":"#### Still Accuracy has not improved ","440b5158":"#### 6. Initialize & build the model (Basic Model with 2 hidden layers)","2821f11e":"##### Not much improvement in accuracy, precision has improved, recall has gone down,overall accuracy is almost same"}}