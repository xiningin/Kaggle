{"cell_type":{"b479a37b":"code","cdd7632e":"code","d0487cba":"code","e38d60a5":"code","fd8626f9":"code","9c1f94cb":"code","3670c48c":"code","a80b984f":"code","7450ce36":"code","a1fed9c1":"code","b2b3f823":"code","786d54a6":"code","cf281fdc":"code","a4a309af":"code","dd74b055":"code","17242310":"code","ef7c516f":"code","d7d978ad":"code","d6b7d643":"code","8e043e12":"code","538c1a83":"code","b0644ae6":"code","8da9f910":"code","304884e5":"code","9d499fc2":"code","6e68f13f":"code","9a65cf58":"code","26c275bc":"code","cebdba01":"code","84d0cdb9":"code","594707f9":"code","e2a250f0":"code","eafb33e9":"code","36d1aca0":"code","a61441f4":"code","2c8fde76":"code","0203aba7":"code","18e864e2":"code","68dcc4b0":"markdown","2d0ddbf2":"markdown","18d879e7":"markdown","f8f9453e":"markdown","632249e9":"markdown","f19a62e1":"markdown","1b7473e9":"markdown","07574091":"markdown","c8b094e7":"markdown","b46f9d8a":"markdown","504ed409":"markdown","6d5bb1e0":"markdown","7988f95d":"markdown","d62f199e":"markdown","05eca71c":"markdown","b5d5a7e3":"markdown","2e74ef5d":"markdown","b0d12997":"markdown","64a22a70":"markdown","b88fdb80":"markdown","0b2ebcbd":"markdown","385de956":"markdown","72b96e3c":"markdown","3e5441af":"markdown","767e00ea":"markdown","47025f6b":"markdown","06c4e62e":"markdown","ad31a23a":"markdown","259b40b7":"markdown","d0b75284":"markdown","a4ab2204":"markdown","f83c2454":"markdown","e4020f5d":"markdown","8d903665":"markdown","8732cae5":"markdown","36bf79dd":"markdown","5af50157":"markdown","422e2391":"markdown","6010bfa4":"markdown","33199e05":"markdown","d6da15dd":"markdown","0a633d1e":"markdown","6b7badc3":"markdown"},"source":{"b479a37b":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB2\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport ipywidgets as widgets\nimport io\nfrom PIL import Image\nfrom IPython.display import display,clear_output\nfrom warnings import filterwarnings\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cdd7632e":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n\nsns.palplot(colors_dark)\nsns.palplot(colors_green)\nsns.palplot(colors_red)","d0487cba":"labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']","e38d60a5":"X_train = []\ny_train = []\nX_train1 = []\ny_train1 = []\nimage_size = 150\nfor i in labels: \n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Training',i)\n    for j in tqdm(os.listdir(folderPath)): #barra di caricamento\/progresso\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size, image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \n        X_train1.append(img)\n        y_train1.append(i)\n        \nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Testing',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \n        X_train1.append(img)\n        y_train1.append(i)\n\n\n\n# tot training = 826+395+822+827\n# tot testing = 100+105+115+74\n\n","fd8626f9":"datagen = ImageDataGenerator()\n\ntransform_parameters1={'tx' : 30, 'theta' : 45}\ntransform_parameters2={'ty' : -30, 'theta' : 225}\n\nfolderPath2 = os.path.join('..\/input\/notumor-new')\nfig, axs = plt.subplots(nrows=3, ncols=2, figsize=(15,10))\ni=0\nfor j in tqdm(os.listdir(folderPath2)):\n    img = cv2.imread(os.path.join(folderPath2, j))\n    img = cv2.resize(img, (image_size, image_size))\n    X_train.append(img)\n    y_train.append('no_tumor')\n    \n    \n    img2 = datagen.apply_transform(img, transform_parameters1)\n    X_train.append(img2)\n    y_train.append('no_tumor')\n    \n    \n    img3 = datagen.apply_transform(img, transform_parameters2)\n    X_train.append(img3)\n    y_train.append('no_tumor')\n    \n    # plot of the first two images with the modified ones\n    if i < 2:\n        axs[0,i].imshow(img)\n        axs[0,i].set_title('original')\n        axs[0,i].axis('off')\n        axs[1,i].imshow(img2)\n        axs[1,i].set_title('modified')\n        axs[1,i].axis('off')\n        axs[2,i].imshow(img3)\n        axs[2,i].set_title('modified')\n        axs[2,i].axis('off')\n        \n    \n    \n    i=i+1\n    \n","9c1f94cb":"X_train = np.array(X_train)\ny_train = np.array(y_train)\n\nX_train, y_train = shuffle(X_train,y_train, random_state=101)\n\n","3670c48c":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)","a80b984f":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)","7450ce36":"effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","a1fed9c1":"model = effnet.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(4,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=effnet.input, outputs = model)","b2b3f823":"model.summary()","786d54a6":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","cf281fdc":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True, mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","a4a309af":"history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])\n","dd74b055":"filterwarnings('ignore')\n\nepochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy\/Loss',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()","17242310":"pred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_test,axis=1)","ef7c516f":"print(classification_report(y_test_new,pred))","d7d978ad":"fig,ax=plt.subplots(1,1,figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test_new,pred,normalize='true'),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\nfig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n\nplt.show()","d6b7d643":"X_train1=np.array(X_train1)\ny_train1=np.array(y_train1)\n\nX_train1, y_train1 = shuffle(X_train1,y_train1, random_state=101)\nX_train1,X_test1,y_train1,y_test1 = train_test_split(X_train1,y_train1, test_size=0.1,random_state=101)","8e043e12":"y_train_new1 = []\nfor i in y_train1:\n    y_train_new1.append(labels.index(i))\ny_train1 = y_train_new1\ny_train1 = tf.keras.utils.to_categorical(y_train1)\n\n\ny_test_new1 = []\nfor i in y_test1:\n    y_test_new1.append(labels.index(i))\ny_test1 = y_test_new1\ny_test1 = tf.keras.utils.to_categorical(y_test1)","538c1a83":"effnet2 = EfficientNetB2(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","b0644ae6":"model = effnet2.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(4,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=effnet2.input, outputs = model)\n\nmodel.summary()","8da9f910":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","304884e5":"tensorboard = TensorBoard(log_dir = 'logs')\n\ncheckpoint = ModelCheckpoint(\"effnet2.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","9d499fc2":"history = model.fit(X_train1,y_train1,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","6e68f13f":"filterwarnings('ignore')\n\nepochs = [i for i in range(12)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy\/Loss EfficientNetB2',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()","9a65cf58":"pred = model.predict(X_test1)\npred = np.argmax(pred,axis=1)\ny_test_new1 = np.argmax(y_test1,axis=1)","26c275bc":"print(classification_report(y_test_new1,pred))","cebdba01":"fig,ax=plt.subplots(1,1,figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test_new1,pred, normalize='true'),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\nfig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n\nplt.show()","84d0cdb9":"X_train1=preprocess_input(X_train1)\nX_test1=preprocess_input(X_test1)","594707f9":"base_model = VGG16(input_shape=X_train1[0].shape, include_top = False, weights = 'imagenet')\nbase_model.trainable= False\n\nflatten_layer=layers.Flatten()\ndrop_layer = layers.Dropout(0.5)\nprediction_layer = layers.Dense(4, activation='softmax')\n\n\nmodel = models.Sequential([\n    base_model,\n    flatten_layer,\n    drop_layer,\n    prediction_layer\n])\n\nmodel.summary()","e2a250f0":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","eafb33e9":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"model.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","36d1aca0":"history = model.fit(X_train1,y_train1,validation_split=0.1, epochs =13, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","a61441f4":"filterwarnings('ignore')\n\nepochs = [i for i in range(13)]\nfig, ax = plt.subplots(1,2,figsize=(14,7))\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nfig.text(s='Epochs vs. Training and Validation Accuracy\/Loss VGG16',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\nsns.despine()\nax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label = 'Training Accuracy')\nax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Accuracy')\nax[0].legend(frameon=False)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Accuracy')\n\nsns.despine()\nax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n           label ='Training Loss')\nax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n           label = 'Validation Loss')\nax[1].legend(frameon=False)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Training & Validation Loss')\n\nfig.show()","2c8fde76":"pred = model.predict(X_test1)\npred = np.argmax(pred,axis=1)\ny_test_new1 = np.argmax(y_test1,axis=1)","0203aba7":"print(classification_report(y_test_new1,pred))","18e864e2":"fig,ax=plt.subplots(1,1,figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test_new1,pred, normalize='true'),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\nfig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n\nplt.show()","68dcc4b0":"# Color","2d0ddbf2":"In the following passages labels are created and the original dataset is loaded.\n","18d879e7":"By looking at the predictions on the test set we can say the perfomances are still very high: it seems that the original model was not contaminated by the umbalances of the no tumor class.","f8f9453e":"Plot of: the validation and training accuracy, the validation and training loss.\nThe performances during the training of the model are the same of the original one.","632249e9":"Dividing the dataset into **Training** and **Testing** sets, testing set is 10% of all the data.","f19a62e1":"Plot of: the validation and training accuracy; the validation and training loss. Despite the number of learnable parameters is heavily increased than in EfficientNetB0, we can not see remarkable improvements; in particular the original model has got approximately 4M of trainable parameters, while the newest 7,7M. This leads us to prefer the original Network for this task.","1b7473e9":"Performing **One Hot Encoding** on the labels after converting it into numerical values:","07574091":"# Transfer Learning with EfficientNetB2\nWe will use here the EfficientNetB2 on the original data set.\nAlso in this case the layers added are: GlobalAveragePooling2D, Dropout and Dense with softmax.","c8b094e7":"---","b46f9d8a":"# Training The Model","504ed409":"# Transfer Learning","6d5bb1e0":"We compile the model with categorical cross entropy as loss function, Adam as optimizer and accuracy as metric.\nThen, we'll be using TensorBoard, ModelCheckpoint and ReduceLROnPlateau callback functions","7988f95d":"We finally compile our model using as loss function the categorical cross entropy, the Adam optimizer which we have seen is the best and the accuracy as metric.","d62f199e":"# Introduction\nIn this second notebook we will apply some modifications to see if they can be proposed to improve the original model. \nFirst we will performe data augmentation on 130 new images for the no tumor class.\nThen, on the original dataset, we will use two different networks for transfer learning to evaluate how they work with respect to EfficientNetB0.","05eca71c":"# Evaluation","b5d5a7e3":"# New data and Data augmentation\nWe looked for a new dataset to have more images for the no tumor class and in partcular to have them coronal or sagittal. In fact in the original dataset there were mainly assial images and the class was made of only 500 samples while the others contained around 900 images. These images were selected by hand from the dataset available at the link https:\/\/www.kaggle.com\/masoudnickparvar\/brain-tumor-mri-dataset, among the testing images for no tumor class. Finally we saved them as \"notumor-new\".\nTwo types of augmentation are applied to the images that are loaded from the dataset notumor-new: a traslation of 30 on the x axis with a rotation of 45, a translation of -30 on the y axis with a rotation of 225.\nWe do this to evaluate if the original model was learning something wrong from the images, for example that the no tumor class is characterized by assial images, or if it was influenced by the minor number of samples of this class with respect to the others.","2e74ef5d":"The argmax function is used to get as prediction the class with the higher probability","b0d12997":"# Evaluation","64a22a70":"---","b88fdb80":"# Training the model","0b2ebcbd":"**One hot encoding**","385de956":"# Prediction","72b96e3c":"# Importing Libraries","3e5441af":"Creation of the model: we add to the base model of VGG16 a flatten layer, a dropout layer and a dense layer in a sequential way. The parameters of the base model will not be trainable.","767e00ea":"We compile the model with categorical cross entropy as loss function, Adam as optimizer and accuracy as metric.\nThen, we'll be using TensorBoard, ModelCheckpoint and ReduceLROnPlateau callback functions","47025f6b":"Plot of: the validation and training accuracy; the validation and training loss. In this second attempt, a VGG16 pre-trained model has been adopted. As depicted from the graphics, we do not achieve comparable results to the original pre-trained Network. This is probably due to the decreased number of learnable parameters of VGG16, from 4M of learnable parameters of the original model, to 33k in VGG16 (we preferred to freeze the VGG16 base model parameters). Given these facts, also in this case we prefer EfficientNetB0 to accomplish this tumor classification task.","06c4e62e":"# Training the model","ad31a23a":"# Evaluation","259b40b7":"The first passage is data pre-processing: in fact this is not included in the netwrok, as it happens in efficient net.","d0b75284":"---","a4ab2204":"# Prediction","f83c2454":"# Transfer learning with two new networks: EfficientNetB2 and VGG16","e4020f5d":"---","8d903665":"---","8732cae5":"---","36bf79dd":"\n\n\n\n# Transfer Learning with VGG16","5af50157":"# Prediction","422e2391":"X_train and y_train are transformed into arrays and data are shuffled","6010bfa4":"# Data Preperation","33199e05":"**Callbacks** -> Callbacks can help you fix bugs more quickly, and can help you build better models. They can help you visualize how your model\u2019s training is going, and can even help prevent overfitting by implementing early stopping or customizing the learning rate on each iteration.<br><br>\nBy definition, \"A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\"\n\nIn this notebook, we'll be using **TensorBoard, ModelCheckpoint and ReduceLROnPlateau** callback functions","d6da15dd":"Deep Learning applied to Neuroscience and Rehabilitation\n\nAA 2021\/22\n\nFranceschin Sarah, Grisi Caterina, Pozza Giacomo, Tonello Alessio, Viberti Andrea","0a633d1e":"We use here the EfficientNetB0 as in the original file, but with the new dataset we've created, because we want to evaluate the performances changing only the dataset.\nAlso the layers added are the same: GlobalAveragePooling2D, Dropout and Dense with softmax.\n","6b7badc3":"We will now try two different networks to see their perfomances.\nFor this part we will use the original dataset that was saved in X_train1 and y_train1.\n"}}