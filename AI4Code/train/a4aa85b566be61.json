{"cell_type":{"86659d1e":"code","1d833f75":"code","3418cec1":"code","ed2ff974":"code","75d7a5f5":"code","babfa8db":"code","e16021cb":"code","3b311fa3":"code","ea6012dc":"code","085f3a96":"code","8fbc355b":"code","297ece84":"code","e234cdd3":"code","f78bc8cb":"code","eb4314a1":"code","f4ec7d31":"code","02a5d59d":"code","24f95f19":"code","7c017e8b":"code","5e4b881b":"code","78309b15":"code","567e9f2c":"code","6c22e86f":"code","2138a959":"code","65978c40":"code","44af2ec5":"code","27701ff3":"code","c12f6cc2":"code","bdf516c3":"code","ea3a2345":"code","da1cf3c1":"code","025e2a68":"code","2785f953":"code","cbb3dcef":"code","4ea856c7":"code","84f740c9":"code","6494d4dd":"code","6fa376d7":"code","6a12ec07":"code","695632d8":"code","c85cabe8":"code","19ba797a":"markdown","4604aeff":"markdown","c2f01d33":"markdown","c41ec59f":"markdown","43e7b998":"markdown","8b2b7fa1":"markdown","c3d75039":"markdown","dd686085":"markdown","1276f2ec":"markdown","a83fb298":"markdown","d0e33f63":"markdown","8d9f76d2":"markdown","44de0d42":"markdown","f0e2913d":"markdown","582e2834":"markdown","52d38367":"markdown","bdfe5c01":"markdown","2e29cea7":"markdown","9d5c4914":"markdown"},"source":{"86659d1e":"import numpy as np\nimport pandas as pd","1d833f75":"import tensorflow as tf\n\nprint(tf.__version__)","3418cec1":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set.\n    # On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","ed2ff974":"EPOCHS = 75\nDROP_RATE = 0.4\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nRESIZE_SIZE = (224, 224)\nTTA_COUNT = 10\n\nMODEL_VERSION = 'V17'","75d7a5f5":"DATA_DIR = '..\/input\/digit-recognizer\/'\n\ndef read_df(file_name):\n    file_path = DATA_DIR + file_name\n    data_df = pd.read_csv(file_path)\n    return data_df","babfa8db":"train_df = read_df('train.csv')\n\ntrain_df","e16021cb":"IMAGE_SIZE = (28, 28)\nIMAGE_SHAPE = (*IMAGE_SIZE, 1)\n\ndef get_images_from(data_df):\n    pixels_df = data_df.loc[ : , 'pixel0':'pixel783' ]\n    pixels_array = pixels_df.to_numpy(dtype=np.uint8)\n    images = pixels_array.reshape(-1, *IMAGE_SHAPE)\n    return images","3b311fa3":"def get_labels_from(data_df):\n    labels = data_df['label'].to_numpy(dtype=np.int32)\n    return labels ","ea6012dc":"X = get_images_from(train_df)\ny = get_labels_from(train_df)\n\nprint(X.shape)\nprint(y.shape)","085f3a96":"from PIL import Image\n\nRESIZE_SHAPE = (*RESIZE_SIZE, 1)\n\ndef resize_image(orig_np):\n    reshape_np = np.reshape(orig_np, IMAGE_SIZE)\n    orig_im = Image.fromarray(reshape_np)\n    resized_im = orig_im.resize(RESIZE_SIZE, Image.LANCZOS)\n    resized_np = np.asarray(resized_im, dtype=np.uint8)\n    resized_reshaped_np = np.reshape(resized_np, RESIZE_SHAPE)\n    return resized_reshaped_np","8fbc355b":"def resize_images(orig_nps):\n    n_images = orig_nps.shape[0]\n    resized_shape = (n_images, *RESIZE_SHAPE)\n    resized_nps = np.empty(resized_shape, dtype=np.uint8)\n\n    for i in range(n_images):\n        if i % 100 == 0:\n            print('.', end='', flush=True)\n        x_np = orig_nps[i]\n        resized_nps[i] = resize_image(x_np)\n    print()\n    \n    return resized_nps","297ece84":"X_resized = resize_images(X)\n\nprint(X_resized.shape)","e234cdd3":"import matplotlib.pyplot as plt\n\ndef plot_image(image, title=None, subplot=(1, 1, 1)):\n    plt.subplot(*subplot)\n    image_shape = (image.shape[0], image.shape[1])\n    reshaped_image = image.reshape(image_shape)\n    plt.imshow(reshaped_image, cmap='gray')\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')","f78bc8cb":"plot_image(X_resized[1], 'Resized image')\nplt.show()","eb4314a1":"import tensorflow.keras.backend as K\nimport math\n\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation \/ 180.\n    shear = math.pi * shear \/ 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one\/height_zoom,zero,zero, zero,one\/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))","f4ec7d31":"def do_transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n#     DIM = IMAGE_SIZE[0]\n    DIM = RESIZE_SIZE[0]\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 10. * tf.random.normal([1],dtype='float32')\n    shr = 5. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    h_shift = DIM * 0.05 * tf.random.normal([1],dtype='float32') \n    w_shift = DIM * 0.05 * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM\/\/2,-DIM\/\/2,-1), DIM )\n    y = tf.tile( tf.range(-DIM\/\/2,DIM\/\/2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM\/\/2+XDIM+1,DIM\/\/2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n#     return tf.reshape(d,[DIM,DIM,3]),label\n    return tf.reshape(d,[DIM,DIM,1]),label","02a5d59d":"def randints(shape, minval, maxval):\n    # maxval+1 to include maxval for the result.\n    # generated range is [minval, maxval) (maxval is not included)\n    return tf.random.uniform(\n        shape=shape, minval=minval, maxval=maxval+1, dtype=tf.int32)","24f95f19":"def make_range_mask(size, start, end):\n    indice = tf.range(size, dtype=tf.int32)\n    start_mask = (start <= indice)\n    end_mask = (indice <= end)\n    range_mask = start_mask & end_mask\n    return range_mask\n\ndef make_region_mask(image_height, image_width, top, left, bottom, right):\n    row_mask = make_range_mask(image_height, top, bottom)\n    col_mask = make_range_mask(image_width, left, right)\n    region_mask = row_mask[ ... , tf.newaxis] & col_mask[ tf.newaxis, ... ]\n    reshaped_region_mask = region_mask[ ..., tf.newaxis]\n    return reshaped_region_mask","7c017e8b":"def do_cutout(orig_image, label):\n    # At most mask_ratio * mask_ratio = 0.25 of image is cut.\n    mask_ratio = 0.5\n    \n    image_shape = tf.shape(orig_image)\n    image_height = image_shape[0]\n    image_width = image_shape[1]\n    mask_h = tf.cast(tf.cast(image_height, tf.float32) * mask_ratio, tf.int32)\n    mask_w = tf.cast(tf.cast(image_width, tf.float32) * mask_ratio, tf.int32)\n    mask_value = 0.0\n\n    top = randints([], -mask_h \/\/ 2, image_height - mask_h \/\/ 2)\n    left = randints([], -mask_w \/\/ 2, image_width - mask_w \/\/ 2)\n    bottom = top + mask_h\n    right = left + mask_w\n\n    cut_region = make_region_mask(\n        image_height, image_width, top, left, bottom, right)\n    cutout_image = tf.where(cut_region, mask_value, orig_image)\n    return cutout_image, label","5e4b881b":"unique_y = np.unique(y)\nlabel_count = len(unique_y)\n\nprint(unique_y)\nprint(label_count)","78309b15":"AUTO = tf.data.experimental.AUTOTUNE\n\ndef make_dataset(\n        X_np, y_np,\n        transform=False, cutout=False, repeat=False, shuffle=False):\n    def _cast_to_float(x, y):\n        return tf.cast(x, tf.float32), y\n\n    ds = tf.data.Dataset.from_tensor_slices((X_np, y_np))\n    ds = ds.map(_cast_to_float, num_parallel_calls=AUTO)\n    if shuffle:\n        ds = ds.shuffle(2048)\n    if transform:\n        ds = ds.map(do_transform, num_parallel_calls=AUTO)\n    if cutout:\n        ds = ds.map(do_cutout, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE)\n    if repeat:\n        ds = ds.repeat()\n\n    return ds","567e9f2c":"def make_train_ds(X_np, y_np):\n    ds = make_dataset(\n        X_np, y_np, transform=True, cutout=True, repeat=True, shuffle=True)\n    return ds\n\ndef make_val_ds(X_np, y_np):\n    ds = make_dataset(\n        X_np, y_np, transform=False, cutout=False, repeat=False, shuffle=False)\n    return ds\n\ndef make_test_ds(X_np):\n    # Make dummy labals, because there are no labels for test data.\n    y_np = np.zeros(X_np.shape[0], dtype=np.int32)\n    # Only geometric transform is applied for Test Time Augmentation.\n    ds = make_dataset(\n        X_np, y_np, transform=True, cutout=False, repeat=False, shuffle=False)\n    return ds","6c22e86f":"from sklearn.model_selection import StratifiedKFold\n\nNFOLD = 5\nk_fold = StratifiedKFold(n_splits=NFOLD)\n\nfold_index_list = []\nfor train_index, val_index in k_fold.split(X_resized, y):\n    fold_index_list.append((train_index, val_index))\n\ndef get_fold(fold_i):\n    train_index, val_index = fold_index_list[fold_i]\n    X_train, y_train = X_resized[train_index], y[train_index]\n    X_val, y_val = X_resized[val_index], y[val_index]\n    \n    train_ds = make_train_ds(X_train, y_train)\n    val_ds = make_val_ds(X_val, y_val)\n    return train_ds, val_ds","2138a959":"def calc_steps_per_epoch(fold_i):\n    train_index, val_index = fold_index_list[fold_i]\n    steps_per_epoch = (len(train_index) + BATCH_SIZE - 1) \/\/ BATCH_SIZE\n    return steps_per_epoch","65978c40":"row = 10; col = 10;\norig_ds = make_dataset(\n    X_resized[ :row], None, transform=False,\n    cutout=False, repeat=False, shuffle=True).unbatch()\n\nplt.figure(figsize=(1.5 * col, 1.5 * row))\nfor i, (orig_img, orig_label) in enumerate(iter(orig_ds)):\n    orig_elem_ds = tf.data.Dataset.from_tensors((orig_img, orig_label))\n    aug_elem_ds = orig_elem_ds.repeat(count=col - 1) \\\n        .map(do_transform).map(do_cutout)\n    plot_image(orig_img.numpy(), subplot=(row, col, i*col + 1))\n    for j, (aug_img, aug_label) in enumerate(iter(aug_elem_ds)):\n        plot_image(aug_img.numpy(), subplot=(row, col, i*col + j + 2))\nplt.show()","44af2ec5":"from tensorflow.keras.applications.resnet50 import ResNet50\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\n\nMODEL_INPUT_SHAPE = (*RESIZE_SIZE, 3)\n\ndef make_model(name):\n    with strategy.scope():\n        inputs = L.Input(shape=RESIZE_SHAPE, name=\"input\")\n        # Scale from 0..255 to 0..1\n        scaled = L.Lambda(lambda v: v \/ 255.0, name='scaling')(inputs)\n        # Makes 3 color channels from gray scale image.\n        img_input = L.Concatenate(name='concat')([scaled, scaled, scaled])\n        x = ResNet50(\n            include_top=False, weights='imagenet',\n            input_shape=MODEL_INPUT_SHAPE, pooling='avg')(img_input)\n        x = L.Dropout(DROP_RATE, name=\"dropout\")(x)\n        outputs = L.Dense(label_count, activation='sigmoid', name='classify')(x)\n        model = M.Model(inputs=inputs, outputs=outputs, name=name)\n\n    model.compile(\n        optimizer='adam',\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=['accuracy'])\n    return model","27701ff3":"model = make_model('model')\n\nmodel.summary()","c12f6cc2":"import math\n\nLR_START = 0.00001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = min(5, EPOCHS \/\/ 5)\nLR_SUSTAIN_EPOCHS = 0\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        phase = math.pi * decay_epoch_index \/ decay_total_epochs\n        cosine_decay = 0.5 * (1 + math.cos(phase))\n        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n    return lr\n\ndef make_lr_callback():\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n    return lr_callback\n\nrng = [i for i in range(EPOCHS)]\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, lr_y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\". \\\n      format(lr_y[0], max(lr_y), lr_y[-1]))","bdf516c3":"def make_best_model_file_path(fold_i):\n    file_name = \"best_model_{0}_{1}.hdf5\".format(MODEL_VERSION, fold_i)\n    return file_name","ea3a2345":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ndef make_model_check_point(fold_i):\n    best_model_file_path = make_best_model_file_path(fold_i)\n    return ModelCheckpoint(\n        best_model_file_path, monitor='val_accuracy', mode='max',\n        verbose=0, save_best_only=True, save_weights_only=False, period=1)","da1cf3c1":"initial_weights_file_path = \"initial_weights.hdf5\"\n\nmodel.save_weights(initial_weights_file_path)","025e2a68":"history_list = []\nfor fold_i in range(NFOLD):\n    print(\"#\" * 40)\n    print(\"# Fold {0}\".format(fold_i))\n    \n    train_ds, val_ds = get_fold(fold_i)\n    steps_per_epoch = calc_steps_per_epoch(fold_i)\n    lr_callback = make_lr_callback()\n    check_point = make_model_check_point(fold_i)\n\n    model.load_weights(initial_weights_file_path)\n    history = model.fit(\n        train_ds, epochs=EPOCHS, steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        callbacks=[lr_callback, check_point], verbose=0)\n    history_list.append(history)\n\n    best_acc = max(history.history['accuracy'])\n    best_val_acc = max(history.history['val_accuracy'])\n    print(\n        \"Fold {0}: accuracy={1:.5f}, val_accuracy={2:.5f}\".format(\n        fold_i, best_acc, best_val_acc))","2785f953":"def plot_history(history, title, labels, ylim, subplot):\n    plt.subplot(*subplot)\n    plt.title(title)\n    for label in labels:\n        plt.plot(history.history[label], label=label)\n    plt.ylim(ylim)\n    plt.legend()","cbb3dcef":"n_rows = len(history_list)\nplt.figure(figsize=(15, 4 * n_rows))\nfor i, history in enumerate(history_list):\n    plot_history(\n        history, \"Loss\", ['loss', 'val_loss'],\n        (0.0, 0.2), (n_rows, 2, 2*i + 1))\n    plot_history(\n        history, \"Accuracy\", ['accuracy', 'val_accuracy'],\n        (0.98, 1.0), (n_rows, 2, 2*i + 2))\nplt.tight_layout()\nplt.show()","4ea856c7":"test_df = read_df('test.csv')\n\ntest_df","84f740c9":"X_test = get_images_from(test_df)\n\nprint(X_test.shape)","6494d4dd":"X_test_resized = resize_images(X_test)\n\nprint(X_test_resized.shape)","6fa376d7":"def make_val_pred_file_path(fold_i):\n    file_name = \"val_pred_{0}_{1}\".format(MODEL_VERSION, fold_i)\n    return file_name","6a12ec07":"model_pred = np.zeros((X_test_resized.shape[0], label_count))\nfor fold_i in range(NFOLD):\n    best_model_file_path = make_best_model_file_path(fold_i)\n    model.load_weights(best_model_file_path)\n\n    train_ds, val_ds = get_fold(fold_i)\n    val_pred = model.predict(val_ds)\n    val_pred_file_name = make_val_pred_file_path(fold_i)\n    np.save(val_pred_file_name, val_pred)\n    \n    test_ds = make_test_ds(X_test_resized)\n    print(\"Fold {0}\".format(fold_i), end='', flush=True)\n    for i in range(TTA_COUNT):\n        print('.', end='', flush=True)\n        model_pred += model.predict(test_ds)\n    print()\n        \ny_pred = np.argmax(model_pred, axis=1)\nprint(y_pred.shape)","695632d8":"submission_df = read_df('sample_submission.csv')\n\nsubmission_df","c85cabe8":"submission_df['Label'] = y_pred\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\n!head submission.csv","19ba797a":"<a name=\"Training\"><\/a>\n## Training\n\nTrain the models with cross validation data. Then, draw plots for loss and accuracy to check the process.","4604aeff":"<a name='TrainingData'><\/a>\n### Training Data\n\nRead CSV file for the training data to DataFrame, then split it into images and labels.","c2f01d33":"<a name=\"DataSetup\"><\/a>\n## Data Setup\n<a name=\"TensorflowDataset\"><\/a>\n### Tensorflow Dataset\n\nTo feed data to the model runs on TPU, tensorflow dataset is necessary.","c41ec59f":"<a name=\"DrawSampleImages\"><\/a>\n### Draw Sample Images\n\nLet's see some sample images.","43e7b998":"<a name=\"Preparation\"><\/a>\n## Preparation\n\n<a name=\"ImportLibraries\"><\/a>\n### Import Libraries\n\nImport necessary libraries. Other libraries will be imported as necessary.","8b2b7fa1":"## ResNet50 only train.csv [0.99778]\n\nThis notebook tries to get as much accuracy as possible by using only 'train.csv'. The points are:\n\n* Use ResNet50 as the model.\n* Increase the image size to 224x224.\n* Data augmentation by geometric transform and cutout. \n* 5 fold cross validation by Stratified K Fold.\n* Test Time Augmentation.\n* Use Tensorflow runs on TPU.\n\nThe contents are as follows:\n\n* <a href=\"#Preparation\">Preparation<\/a>\n    * <a href=\"#ImportLibraries\">Import Libraries<\/a>\n    * <a href=\"#TPUDetection\">TPU Detection<\/a>\n    * <a href=\"#Constants\">Constants<\/a>\n    * <a href=\"#TrainingData\">Training Data<\/a>\n    * <a href=\"#ResizeImage\">Resize Image<\/a>\n* <a href=\"#DataArgmentation\">Data Argmentation<\/a>\n    * <a href=\"#GeometricTransform\">Geometric Transform<\/a>\n    * <a href=\"#Cutout\">Cutout<\/a>\n* <a href=\"#DataSetup\">Data Setup<\/a>\n    * <a href=\"#TensorflowDataset\">Tensorflow Dataset<\/a>\n    * <a href=\"#CrossValidation\">Cross Validation<\/a>\n    * <a href=\"#DrawSampleImages\">Draw Sample Images<\/a>\n* <a href=\"#Model\">Model<\/a>\n    * <a href=\"#ResNet50\">ResNet50<\/a>\n    * <a href=\"#LearningRate\">Learning Rate<\/a>\n    * <a href=\"#ModelCheckPoint\">Model Check Point<\/a>\n    * <a href=\"#InitialWeights\">Initial Weights<\/a>\n* <a href=\"Training\">Training<\/a>\n* <a href=\"Prediction\">Prediction<\/a>\n    * <a href=\"#TestData\">Test Data<\/a>\n    * <a href=\"#TestTimeAugmentation\">Test Time Augmentation<\/a>\n    * <a href=\"#Submit\">Submit<\/a>","c3d75039":"<a name=\"Prediction\"><\/a>\n## Prediction\n<a name=\"TestData\"><\/a>\n### Test Data\n\nRead CSV file for the test data, get images and resize.","dd686085":"<a name=\"ModelCheckPoint\"><\/a>\n### Model Check Point\n\nSaves the best model according to val_accuracy.","1276f2ec":"<a name=\"Submit\"><\/a>\n### Submit\n\nSubmit the prediction result.","a83fb298":"<a name=\"TestTimeAugmentation\"><\/a>\n### Test Time Augmentation\n\nPredict the test images 10 times with augmented data. This reduces the result fluctuation. To augment the data, geometric transform is used.","d0e33f63":"<a name=\"ResizeImage\"><\/a>\n### Resize Image\n\nThe bigger image size, the better accuracy. To resize, Image.resize() with LANCZOS filter is used.","8d9f76d2":"<a name=\"InitialWeights\"><\/a>\n### Initial Weights\n\nSaves initial weights to reset the model to the initial state. Making new model would be better for variety, however, it took more time than loading initial weights.","44de0d42":"<a name=\"TPUDetection\"><\/a>\n### TPU Detection\n\nTo run ResNet50, TPU is mandatory.","f0e2913d":"<a name=\"DataArgmentation\"><\/a>\n## Data Argmentation\n<a name=\"GeometricTransform\"><\/a>\n### Geometric Transform\n\nThe methods below are taken from [Rotation Augmentation GPU\/TPU - [0.96+]](https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96).","582e2834":"<a name=\"CrossValidation\"><\/a>\n### Cross Validation\n\nTo utilize all the training data, 5 fold cross validation is used. To split the data,  [sklearn.model_selection.StratifiedKFold](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.StratifiedKFold.html) is used.","52d38367":"<a name=\"Constants\"><\/a>\n### Constants\n\nDefine constants.","bdfe5c01":"<a name=\"Cutout\"><\/a>\n### Cutout\n\nThe paper is [here](https:\/\/arxiv.org\/abs\/1708.04552).","2e29cea7":"<a name=\"Model\"><\/a>\n## Model\n<a name=\"ResNet50\"><\/a>\n### ResNet50\n\nResNet50 with imagenet weights is used as the model.","9d5c4914":"<a name=\"LearningRate\"><\/a>\n### Learning Rate\n\nThe method below are taken from [Rotation Augmentation GPU\/TPU - [0.96+]](https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96). The original was exponential decay. I changed to cosine decay."}}