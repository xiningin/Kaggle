{"cell_type":{"794b83da":"code","02dbd400":"code","e90b0a1d":"code","96befee8":"code","e77a9086":"code","c978d8fd":"code","9335b4d3":"code","c5682997":"code","817363b6":"code","c62ad407":"code","1c60a96b":"code","4cf54c0f":"code","1af77607":"code","f2ddc9f3":"code","b8d3e754":"code","4c891627":"code","2576984a":"code","3b27975c":"code","37c91723":"code","af0e7d08":"code","957cb475":"code","7bb0b223":"code","523fc031":"code","59a77eec":"code","b7993caf":"markdown","975758af":"markdown","f6c3501a":"markdown","add47c74":"markdown","0d6bf3a5":"markdown"},"source":{"794b83da":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport random\nimport cv2","02dbd400":"## Declare Directory\ntrain_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\"\nval_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\"\ntest_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\"\n\nclasses = [\"With Mask\", \"Without Mask\"]","e90b0a1d":"n = 5\n## Check Image\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"\/WithMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"\/WithMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"With Mask\")\nplt.show()   \n\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"\/WithoutMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"\/WithoutMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"Without Mask\")\nplt.show()   ","96befee8":"## Data Augmentation \nfrom keras.preprocessing.image import ImageDataGenerator","e77a9086":"# Dataset Loader\ntrain_datagen = ImageDataGenerator(\n                                rescale=1.\/255,\n                                rotation_range=0.2,\n                                #width_shift_range=0.1,\n                                #height_shift_range=0.1,\n                                shear_range=0.2,\n                                #zoom_range=0.09,\n                                horizontal_flip=True,\n                                vertical_flip=False,\n                                #validation_split=0.1\n                                )\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)","c978d8fd":"# Image Generator Config\ntarget_size = (150, 150)\nbatch_size = 16\n\n# Load Dataset\ntrain_dataset = train_datagen.flow_from_directory(train_dir,\n                                                  target_size=target_size,\n                                                  batch_size=batch_size,\n                                                  class_mode=\"categorical\",\n                                                  shuffle=True)\n\nval_dataset = val_datagen.flow_from_directory(val_dir,\n                                              target_size=target_size,\n                                              batch_size=batch_size,\n                                              class_mode=\"categorical\",\n                                              shuffle=False)","9335b4d3":"# Import\nimport keras\nfrom keras import layers\nfrom keras.applications import MobileNetV2\n\n# Initiate Baseline Model\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))","c5682997":"# Freezing Layer\nfor layer in base_model.layers:\n    layer.trainable = False","817363b6":"model = keras.Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2, activation=\"softmax\"))","c62ad407":"model.summary()","1c60a96b":"## Setting backprop of model (how this model learning)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics =\"accuracy\")","4cf54c0f":"# Training\nEPOCHS = 10\nhistory = model.fit_generator(train_dataset,\n                               steps_per_epoch=len(train_dataset)\/\/train_dataset.batch_size,\n                               validation_data=val_dataset, \n                               validation_steps=len(val_dataset)\/\/val_dataset.batch_size,\n                               epochs=EPOCHS, \n                               )","1af77607":"## Review Our Model\nimport matplotlib.gridspec as gridspec\n\nfig = plt.figure(figsize=(14,5))\ngrid = gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\nfig.add_subplot(grid[0])\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nfig.add_subplot(grid[1])\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\n#plt.savefig(\"Training_result.jpg\",dpi=300)","f2ddc9f3":"# Load Test Dataset\ntest_dataset = val_datagen.flow_from_directory(test_dir,\n                                            target_size=target_size,\n                                            batch_size=1,\n                                            class_mode=None,\n                                            shuffle=False)","b8d3e754":"probabilities = model.predict_generator(test_dataset)","4c891627":"y_pred = probabilities.argmax(axis=-1)\ny_test = test_dataset.classes","2576984a":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns","3b27975c":"print(\"Accuracy Score of Model:\", accuracy_score(y_pred,y_test))","37c91723":"labels = [\"No Mask\",\"Mask\"]\n\nfig, ax = plt.subplots(figsize=(8,7))\nsns.heatmap(confusion_matrix(y_test,y_pred),xticklabels=labels, ax=ax,\n                                       yticklabels=labels, annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 20})\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nplt.title(\"Confusion matrix\",fontsize=30)","af0e7d08":"import glob\nimport random","957cb475":"def preprocessing_img(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150, 150))\n    img = np.array(img)\n    img = np.expand_dims(img, axis=0)\n    img = img\/255\n    return img\n","7bb0b223":"random_test_img = random.choice(glob.glob(test_dir+\"\/*\/*\"))\nprint(random_test_img)\nimg_test = cv2.imread(random_test_img)\nimg_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\nplt.imshow(img_test)\nplt.show()","523fc031":"img_test = preprocessing_img(img_test)\nresult = model.predict(img_test)\nscore = np.max(result)\npredicted_class = classes[np.argmax(result)]\nprint(predicted_class)\nprint(\"Confident: \", score)","59a77eec":"model.save(\"face-masked-detection.h5\")","b7993caf":"# Test with Visualization","975758af":"# 3. Reviewing Model","f6c3501a":"# 1. Preparation","add47c74":"# Save Model","0d6bf3a5":"# 2. Deep Learning Model"}}