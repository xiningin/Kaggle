{"cell_type":{"46848b44":"code","238d2d83":"code","f3d84056":"code","6e409c9e":"code","99c66770":"code","006d49ce":"code","6b37b3e9":"code","ad3017ef":"code","a892f35e":"code","4e4b0d1d":"code","341ecb42":"code","7dbec9fc":"code","0cc47ef9":"code","697baae0":"code","c29594ad":"code","d6dd6b26":"code","0d371a8d":"code","0f2722e1":"code","959fa0ff":"code","3946e835":"code","fe95e4c6":"code","6f07a8ba":"code","3b73978d":"code","d1c14e18":"code","a1e6523e":"code","d31d7c3b":"code","16664e36":"code","1d7810de":"code","3ac87511":"code","92a333cc":"code","e98869e3":"code","e0a28229":"code","52133a05":"code","f4868622":"code","4fba2a55":"code","57288cbe":"code","819323df":"code","7c2974ea":"code","a23f22fc":"code","e9140fc7":"code","5e34529c":"code","ea567802":"code","99dfd46e":"code","ad210209":"code","e730bef4":"code","d8db9a67":"markdown","5e9190cd":"markdown","c82508dc":"markdown","8e9cad67":"markdown","0e3dabac":"markdown","e542c856":"markdown","a7ead916":"markdown","08cc5606":"markdown","35234b35":"markdown","76ab3e5e":"markdown","8a308093":"markdown","edf8f148":"markdown","3119905d":"markdown","03921a41":"markdown","28c42a7d":"markdown","0bf56489":"markdown","07f9d0eb":"markdown","58ba7126":"markdown","57dfe0b4":"markdown","aeb64b82":"markdown","99630ef5":"markdown","9db19aa5":"markdown","8c4fca37":"markdown","d673b965":"markdown","4a1852f8":"markdown","36c9631a":"markdown","ebe31807":"markdown","fe8246fc":"markdown","eb846684":"markdown","6c17e518":"markdown","344ca155":"markdown","8522cdff":"markdown","b0c36db5":"markdown","50d18a4d":"markdown","1bc15915":"markdown","fc1f0397":"markdown"},"source":{"46848b44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","238d2d83":"# Import the necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score,recall_score\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nsns.set(color_codes=True)\n%matplotlib inline\n%config InlineBackend.figure_formats = {'png', 'retina'}\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","f3d84056":"# Load the dataset\ndf = pd.read_csv('..\/input\/hr-analytics-dataset\/HR.csv')\ndf.head()","6e409c9e":"# Display dataset shape\ndf.shape","99c66770":"# Display descriptive statistics\ndf.describe()","006d49ce":"# Display data information\ndf.info()","6b37b3e9":"# Check the distribution of \"satisfaction_level\"\ndf[\"satisfaction_level\"].hist()","ad3017ef":"# Impute missing values in \"Age\" with median\ndf[\"satisfaction_level\"] = df[\"satisfaction_level\"].fillna(df[\"satisfaction_level\"].median())","a892f35e":"# Check the values of \"department\"\ndf['department'].value_counts()","4e4b0d1d":"# Check the valus of the \"salary\"\ndf['salary'].value_counts()","341ecb42":"# Convert categorical variables into numeric, dummy variables.\n\n# Convert \"department\" into dummy variables\ndf = pd.concat([df, pd.get_dummies(df[\"department\"], prefix=\"department\")], axis=1).drop(columns=[\"department\"])\n\n# Convert \"salary\" into dummy variables\ndf = pd.concat([df, pd.get_dummies(df[\"salary\"], prefix=\"salary\")], axis=1).drop(columns=[\"salary\"])\n\n# Display the part of the train set to see if the categorical variables were properly converted.\ndf.head(10)","7dbec9fc":"# Split data into train and test Datasets\n\n# Separate the dataset into features and target\nX = df.drop(['left'],axis=1)\ny = df['left']\n\n# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, stratify=y, random_state=101)","0cc47ef9":"# Scale the data\n\n# Standardize the columns the values of which are out of 0-1 range\nscaler = StandardScaler().fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","697baae0":"# Check the data balance\n\n# Count the number of churn (=1)\ny.value_counts()","c29594ad":"### Check the churn rate\nchurn_rate = (sum(df['left'])\/len(df['left'].index))*100\nchurn_rate","d6dd6b26":"# Initiate the model\nbase_lm = LogisticRegression()\n# Fit the model\nbase_lm_model = base_lm.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_lm_pred=base_lm_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_lm_accuracy = accuracy_score(y_test, base_lm_pred)\nbase_lm_precision = precision_score(y_test, base_lm_pred)\nbase_lm_recall = recall_score(y_test, base_lm_pred)\nbase_lm_f1 = 2 * (base_lm_precision * base_lm_recall) \/ (base_lm_precision + base_lm_recall)\n\n# Calculate AUC score\nbase_lm_probs = base_lm.predict_proba(X_test)\nbase_lm_probs = base_lm_probs[:,1]\nbase_lm_auc = roc_auc_score(y_test, base_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_lm_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_lm_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_lm_pred))","0d371a8d":"# Initiate the model\nbase_knn = KNeighborsClassifier()\n# Fit the model\nbase_knn_model = base_knn.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_knn_pred=base_knn_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_knn_accuracy = accuracy_score(y_test, base_knn_pred)\nbase_knn_precision = precision_score(y_test, base_knn_pred)\nbase_knn_recall = recall_score(y_test, base_knn_pred)\nbase_knn_f1 = 2 * (base_knn_precision * base_knn_recall) \/ (base_knn_precision + base_knn_recall)\n\n# Calculate AUC score\nbase_knn_probs = base_knn.predict_proba(X_test)\nbase_knn_probs = base_knn_probs[:,1]\nbase_knn_auc = roc_auc_score(y_test, base_knn_probs)\n\n# Display the metrics\nprint(\"KNN Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_knn_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_knn_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_knn_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_knn_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_knn_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_knn_pred))","0f2722e1":"# Initiate the model\nbase_svc = SVC(kernel='rbf',probability=True)\n# Fit the model\nbase_svc_model = base_svc.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_svc_pred = base_svc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_svc_accuracy = accuracy_score(y_test, base_svc_pred)\nbase_svc_precision = precision_score(y_test, base_svc_pred)\nbase_svc_recall = recall_score(y_test, base_svc_pred)\nbase_svc_f1 = 2 * (base_svc_precision * base_svc_recall) \/ (base_svc_precision + base_svc_recall)\n\n# Calculate AUC score\nbase_svc_probs = base_svc.predict_proba(X_test)\nbase_svc_probs = base_svc_probs[:,1]\nbase_svc_auc = roc_auc_score(y_test, base_svc_probs)\n\n# Display the metrics\nprint(\"SVM Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_svc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_svc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_svc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_svc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_svc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_svc_pred))","959fa0ff":"# Initiate the model\nbase_tree = DecisionTreeClassifier()\n# Fit the model\nbase_tree_model = base_tree.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_tree_pred=base_tree_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_tree_accuracy = accuracy_score(y_test, base_tree_pred)\nbase_tree_precision = precision_score(y_test, base_tree_pred)\nbase_tree_recall = recall_score(y_test, base_tree_pred)\nbase_tree_f1 = 2 * (base_tree_precision * base_tree_recall) \/ (base_tree_precision + base_tree_recall)\n\n# Calculate AUC score\nbase_tree_probs = base_tree.predict_proba(X_test)\nbase_tree_probs = base_tree_probs[:,1]\nbase_tree_auc = roc_auc_score(y_test, base_tree_probs)\n\n# Display the metrics\nprint(\"Decision Tree Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_tree_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_tree_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_tree_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_tree_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_tree_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_tree_pred))","3946e835":"# Initiate the model\nbase_rfc = RandomForestClassifier()\n# Fit the model\nbase_rfc_model = base_rfc.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_rfc_pred=base_rfc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_rfc_accuracy = accuracy_score(y_test, base_rfc_pred)\nbase_rfc_precision = precision_score(y_test, base_rfc_pred)\nbase_rfc_recall = recall_score(y_test, base_rfc_pred)\nbase_rfc_f1 = 2 * (base_rfc_precision * base_rfc_recall) \/ (base_rfc_precision + base_rfc_recall)\n\n# Calculate AUC score\nbase_rfc_probs = base_rfc.predict_proba(X_test)\nbase_rfc_probs = base_rfc_probs[:,1]\nbase_rfc_auc = roc_auc_score(y_test, base_rfc_probs)\n\n# Display the metrics\nprint(\"Random Forest Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_rfc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_rfc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_rfc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_rfc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_rfc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_rfc_pred))","fe95e4c6":"# Initiate the model\nbase_adb = AdaBoostClassifier()\n# Fit the model\nbase_adb_model = base_adb.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_adb_pred=base_adb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_adb_accuracy = accuracy_score(y_test, base_adb_pred)\nbase_adb_precision = precision_score(y_test, base_adb_pred)\nbase_adb_recall = recall_score(y_test, base_adb_pred)\nbase_adb_f1 = 2 * (base_adb_precision * base_adb_recall) \/ (base_adb_precision + base_adb_recall)\n\n# Calculate AUC score\nbase_adb_probs = base_adb.predict_proba(X_test)\nbase_adb_probs = base_adb_probs[:,1]\nbase_adb_auc = roc_auc_score(y_test, base_adb_probs)\n\n# Display the metrics\nprint(\"AdaBoost Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_adb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_adb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_adb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_adb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_adb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_adb_pred))","6f07a8ba":"# Initiate the model\nbase_xgb = XGBClassifier()\n# Fit the model\nbase_xgb_model = base_xgb.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_xgb_pred = base_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_xgb_accuracy = accuracy_score(y_test, base_xgb_pred)\nbase_xgb_precision = precision_score(y_test, base_xgb_pred)\nbase_xgb_recall = recall_score(y_test, base_xgb_pred)\nbase_xgb_f1 = 2 * (base_xgb_precision * base_xgb_recall) \/ (base_xgb_precision + base_xgb_recall)\n\n# Calculate AUC score\nbase_xgb_probs = base_xgb.predict_proba(X_test)\nbase_xgb_probs = base_xgb_probs[:,1]\nbase_xgb_auc = roc_auc_score(y_test, base_xgb_probs)\n\n# Display the metrics\nprint(\"XGBoost Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_xgb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(base_xgb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(base_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_xgb_pred))","3b73978d":"# Since this is an imbalanced data, apply SMOTE to the training set\nfrom imblearn.over_sampling import SMOTE\nsmote=SMOTE()\nsmote_X_train, smote_y_train = smote.fit_sample(X_train,y_train)\n\n# Check if SMOTE were properly applied\nsmote_y_train.value_counts()","d1c14e18":"# Initiate the model\nsmote_lm = LogisticRegression()\n\n# Fit the model\nsmote_lm_model = smote_lm.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_lm_pred=smote_lm_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_lm_accuracy = accuracy_score(y_test, smote_lm_pred)\nsmote_lm_precision = precision_score(y_test, smote_lm_pred)\nsmote_lm_recall = recall_score(y_test, smote_lm_pred)\nsmote_lm_f1 = 2 * (smote_lm_precision * smote_lm_recall) \/ (smote_lm_precision + smote_lm_recall)\n\n# Calculate AUC score\nsmote_lm_probs = smote_lm.predict_proba(X_test)\nsmote_lm_probs = smote_lm_probs[:,1]\nsmote_lm_auc = roc_auc_score(y_test, smote_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_lm_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_lm_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_lm_pred))","a1e6523e":"# Initiate the model\nsmote_knn = KNeighborsClassifier()\n\n# Fit the model\nsmote_knn_model = smote_knn.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_knn_pred=smote_knn_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_knn_accuracy = accuracy_score(y_test, smote_knn_pred)\nsmote_knn_precision = precision_score(y_test, smote_knn_pred)\nsmote_knn_recall = recall_score(y_test, smote_knn_pred)\nsmote_knn_f1 = 2 * (smote_knn_precision * smote_knn_recall) \/ (smote_knn_precision + smote_knn_recall)\n\n# Calculate AUC score\nsmote_knn_probs = smote_knn.predict_proba(X_test)\nsmote_knn_probs = smote_knn_probs[:,1]\nsmote_knn_auc = roc_auc_score(y_test, smote_knn_probs)\n\n# Display the metrics\nprint(\"KNN Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_knn_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_knn_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_knn_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_knn_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_knn_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_knn_pred))","d31d7c3b":"# Initiate the model\nsmote_svc = SVC(kernel='rbf',probability=True)\n\n# Fit the model\nsmote_svc_model = smote_svc.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_svc_pred=smote_svc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_svc_accuracy = accuracy_score(y_test, smote_svc_pred)\nsmote_svc_precision = precision_score(y_test, smote_svc_pred)\nsmote_svc_recall = recall_score(y_test, smote_svc_pred)\nsmote_svc_f1 = 2 * (smote_svc_precision * smote_svc_recall) \/ (smote_svc_precision + smote_svc_recall)\n\n# Calculate AUC score\nsmote_svc_probs = smote_svc.predict_proba(X_test)\nsmote_svc_probs = smote_svc_probs[:,1]\nsmote_svc_auc = roc_auc_score(y_test, smote_svc_probs)\n\n# Display the metrics\nprint(\"SVM Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_svc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_svc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_svc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_svc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_svc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_svc_pred))","16664e36":"# Initiate the model\nsmote_tree = DecisionTreeClassifier()\n\n# Fit the model\nsmote_tree_model = smote_tree.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_tree_pred=smote_tree_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_tree_accuracy = accuracy_score(y_test, smote_tree_pred)\nsmote_tree_precision = precision_score(y_test, smote_tree_pred)\nsmote_tree_recall = recall_score(y_test, smote_tree_pred)\nsmote_tree_f1 = 2 * (smote_tree_precision * smote_tree_recall) \/ (smote_tree_precision + smote_tree_recall)\n\n# Calculate AUC score\nsmote_tree_probs = smote_tree.predict_proba(X_test)\nsmote_tree_probs = smote_tree_probs[:,1]\nsmote_tree_auc = roc_auc_score(y_test, smote_tree_probs)\n\n# Display the metrics\nprint(\"Decision Tree Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_tree_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_tree_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_tree_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_tree_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_tree_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_tree_pred))","1d7810de":"# Initiate the model\nsmote_rfc = RandomForestClassifier()\n\n# Fit the model\nsmote_rfc_model = smote_rfc.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_rfc_pred = smote_rfc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_rfc_accuracy = accuracy_score(y_test, smote_rfc_pred)\nsmote_rfc_precision = precision_score(y_test, smote_rfc_pred)\nsmote_rfc_recall = recall_score(y_test, smote_rfc_pred)\nsmote_rfc_f1 = 2 * (smote_rfc_precision * smote_rfc_recall) \/ (smote_rfc_precision + smote_rfc_recall)\n\n# Calculate AUC score\nsmote_rfc_probs = smote_rfc.predict_proba(X_test)\nsmote_rfc_probs = smote_rfc_probs[:,1]\nsmote_rfc_auc = roc_auc_score(y_test, smote_rfc_probs)\n\n# Display the metrics\nprint(\"Random Forest Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_rfc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_rfc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_rfc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_rfc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_rfc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_rfc_pred))","3ac87511":"# Initiate the model\nsmote_adb = AdaBoostClassifier()\n\n# Fit the model\nsmote_adb_model = smote_adb.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_adb_pred = smote_adb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_adb_accuracy = accuracy_score(y_test, smote_adb_pred)\nsmote_adb_precision = precision_score(y_test, smote_adb_pred)\nsmote_adb_recall = recall_score(y_test, smote_adb_pred)\nsmote_adb_f1 = 2 * (smote_adb_precision * smote_adb_recall) \/ (smote_adb_precision + smote_adb_recall)\n\n# Calculate AUC score\nsmote_adb_probs = smote_adb.predict_proba(X_test)\nsmote_adb_probs = smote_adb_probs[:,1]\nsmote_adb_auc = roc_auc_score(y_test, smote_adb_probs)\n\n# Display the metrics\nprint(\"AdaBoost Classifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_adb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_adb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_adb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_adb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_adb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_adb_pred))","92a333cc":"# Initiate the model\nsmote_xgb = XGBClassifier()\n\n# Fit the model\nsmote_xgb_model = smote_xgb.fit(smote_X_train, smote_y_train.ravel())\n\n# Make Predictions\nsmote_xgb_pred = smote_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_xgb_accuracy = accuracy_score(y_test, smote_xgb_pred)\nsmote_xgb_precision = precision_score(y_test, smote_xgb_pred)\nsmote_xgb_recall = recall_score(y_test, smote_xgb_pred)\nsmote_xgb_f1 = 2 * (smote_xgb_precision * smote_xgb_recall) \/ (smote_xgb_precision + smote_xgb_recall)\n\n# Calculate AUC score\nsmote_xgb_probs = smote_xgb.predict_proba(X_test)\nsmote_xgb_probs = smote_xgb_probs[:,1]\nsmote_xgb_auc = roc_auc_score(y_test, smote_xgb_probs)\n\n# Display the metrics\nprint(\"XGBClassifier: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_xgb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smote_xgb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smote_xgb_pred))","e98869e3":"# Combined SMOTE and Edited Nearest Neighbors sampling for imbalanced classification\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import EditedNearestNeighbours\n\n# define sampling\nsmoteenn_X_train, smoteenn_y_train=SMOTEENN(\n    enn=EditedNearestNeighbours(sampling_strategy='majority')).fit_sample(X_train,y_train)\n\n# Check if SMOTE-ENN were properly applied\nsmoteenn_y_train.value_counts()","e0a28229":"# Initiate the model\nsmoteenn_lm = LogisticRegression()\n\n# Fit the model\nsmoteenn_lm_model = smoteenn_lm.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_lm_pred=smoteenn_lm_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_lm_accuracy = accuracy_score(y_test, smoteenn_lm_pred)\nsmoteenn_lm_precision = precision_score(y_test, smoteenn_lm_pred)\nsmoteenn_lm_recall = recall_score(y_test, smoteenn_lm_pred)\nsmoteenn_lm_f1 = 2 * (smoteenn_lm_precision * smoteenn_lm_recall) \/ (smoteenn_lm_precision + smoteenn_lm_recall)\n\n# Calculate AUC score\nsmoteenn_lm_probs = smoteenn_lm.predict_proba(X_test)\nsmoteenn_lm_probs = smoteenn_lm_probs[:,1]\nsmoteenn_lm_auc = roc_auc_score(y_test, smoteenn_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_lm_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_lm_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_lm_pred))","52133a05":"# Initiate the model\nsmoteenn_knn = KNeighborsClassifier()\n\n# Fit the model\nsmoteenn_knn_model = smoteenn_knn.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_knn_pred=smoteenn_knn_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_knn_accuracy = accuracy_score(y_test, smoteenn_knn_pred)\nsmoteenn_knn_precision = precision_score(y_test, smoteenn_knn_pred)\nsmoteenn_knn_recall = recall_score(y_test, smoteenn_knn_pred)\nsmoteenn_knn_f1 = 2 * (smoteenn_knn_precision * smoteenn_knn_recall) \/ (smoteenn_knn_precision + smoteenn_knn_recall)\n\n# Calculate AUC score\nsmoteenn_knn_probs = smoteenn_knn.predict_proba(X_test)\nsmoteenn_knn_probs = smoteenn_knn_probs[:,1]\nsmoteenn_knn_auc = roc_auc_score(y_test, smoteenn_knn_probs)\n\n# Display the metrics\nprint(\"KNN Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_knn_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_knn_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_knn_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_knn_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_knn_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_knn_pred))","f4868622":"# Initiate the model\nsmoteenn_svc = SVC(kernel='rbf',probability=True)\n\n# Fit the model\nsmoteenn_svc_model = smoteenn_svc.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_svc_pred=smoteenn_svc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_svc_accuracy = accuracy_score(y_test, smoteenn_svc_pred)\nsmoteenn_svc_precision = precision_score(y_test, smoteenn_svc_pred)\nsmoteenn_svc_recall = recall_score(y_test, smoteenn_svc_pred)\nsmoteenn_svc_f1 = 2 * (smoteenn_svc_precision * smoteenn_svc_recall) \/ (smoteenn_svc_precision + smoteenn_svc_recall)\n\n# Calculate AUC score\nsmoteenn_svc_probs = smoteenn_svc.predict_proba(X_test)\nsmoteenn_svc_probs = smoteenn_svc_probs[:,1]\nsmoteenn_svc_auc = roc_auc_score(y_test, smoteenn_svc_probs)\n\n# Display the metrics\nprint(\"SVM Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_svc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_svc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_svc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_svc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_svc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_svc_pred))","4fba2a55":"# Initiate the model\nsmoteenn_tree = DecisionTreeClassifier()\n\n# Fit the model\nsmoteenn_tree_model = smoteenn_tree.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_tree_pred=smoteenn_tree_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_tree_accuracy = accuracy_score(y_test, smoteenn_tree_pred)\nsmoteenn_tree_precision = precision_score(y_test, smoteenn_tree_pred)\nsmoteenn_tree_recall = recall_score(y_test, smoteenn_tree_pred)\nsmoteenn_tree_f1 = 2 * (smoteenn_tree_precision * smoteenn_tree_recall) \/ (smoteenn_tree_precision + smoteenn_tree_recall)\n\n# Calculate AUC score\nsmoteenn_tree_probs = smoteenn_tree.predict_proba(X_test)\nsmoteenn_tree_probs = smoteenn_tree_probs[:,1]\nsmoteenn_tree_auc = roc_auc_score(y_test, smoteenn_tree_probs)\n\n# Display the metrics\nprint(\"Decision Tree Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_tree_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_tree_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_tree_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_tree_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_tree_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_tree_pred))","57288cbe":"# Initiate the model\nsmoteenn_rfc = RandomForestClassifier()\n\n# Fit the model\nsmoteenn_rfc_model = smoteenn_rfc.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_rfc_pred = smoteenn_rfc_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_rfc_accuracy = accuracy_score(y_test, smoteenn_rfc_pred)\nsmoteenn_rfc_precision = precision_score(y_test, smoteenn_rfc_pred)\nsmoteenn_rfc_recall = recall_score(y_test, smoteenn_rfc_pred)\nsmoteenn_rfc_f1 = 2 * (smoteenn_rfc_precision * smoteenn_rfc_recall) \/ (smoteenn_rfc_precision + smoteenn_rfc_recall)\n\n# Calculate AUC score\nsmoteenn_rfc_probs = smoteenn_rfc.predict_proba(X_test)\nsmoteenn_rfc_probs = smoteenn_rfc_probs[:,1]\nsmoteenn_rfc_auc = roc_auc_score(y_test, smoteenn_rfc_probs)\n\n# Display the metrics\nprint(\"Random Forest Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_rfc_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_rfc_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_rfc_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_rfc_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_rfc_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_rfc_pred))","819323df":"# Initiate the model\nsmoteenn_adb = AdaBoostClassifier()\n\n# Fit the model\nsmoteenn_adb_model = smoteenn_adb.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n\n# Make Predictions\nsmoteenn_adb_pred = smoteenn_adb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_adb_accuracy = accuracy_score(y_test, smoteenn_adb_pred)\nsmoteenn_adb_precision = precision_score(y_test, smoteenn_adb_pred)\nsmoteenn_adb_recall = recall_score(y_test, smoteenn_adb_pred)\nsmoteenn_adb_f1 = 2 * (smoteenn_adb_precision * smoteenn_adb_recall) \/ (smoteenn_adb_precision + smoteenn_adb_recall)\n\n# Calculate AUC score\nsmoteenn_adb_probs = smoteenn_adb.predict_proba(X_test)\nsmoteenn_adb_probs = smoteenn_adb_probs[:,1]\nsmoteenn_adb_auc = roc_auc_score(y_test, smoteenn_adb_probs)\n\n# Display the metrics\nprint(\"AdaBoost Classifier: SMOTE-ENN\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smoteenn_adb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(smoteenn_adb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(smoteenn_adb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smoteenn_adb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smoteenn_adb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,smoteenn_adb_pred))","7c2974ea":"# Initiate the model\nsmoteenn_xgb = XGBClassifier()\n# Fit the model\nsmoteenn_xgb_model =smoteenn_xgb.fit(smoteenn_X_train, smoteenn_y_train.ravel())\n# Make Predictions\nsmoteenn_xgb_pred = smoteenn_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmoteenn_xgb_accuracy = accuracy_score(y_test, smoteenn_xgb_pred)\nsmoteenn_xgb_precision = precision_score(y_test, smoteenn_xgb_pred)\nsmoteenn_xgb_recall = recall_score(y_test, smoteenn_xgb_pred)\nsmoteenn_xgb_f1 = 2 * (smoteenn_xgb_precision * smoteenn_xgb_recall) \/ (smoteenn_xgb_precision + smoteenn_xgb_recall)\n\n# Calculate AUC score\nsmoteenn_xgb_probs = smoteenn_xgb.predict_proba(X_test)\nsmoteenn_xgb_probs = smoteenn_xgb_probs[:,1]\nsmoteenn_xgb_auc = roc_auc_score(y_test, smoteenn_xgb_probs)\n\n# Display the metrics\nprint(\"XGB Classifier: SMOTEENN\")\nprint(\" - Accuracy: \", smoteenn_xgb_accuracy)\nprint(\" - Precision: \", smoteenn_xgb_precision)\nprint(\" - Recall: \", smoteenn_xgb_recall)\nprint(\" - F1 score: \", smoteenn_xgb_f1)\nprint(\" - AUC score: \", smoteenn_xgb_auc)\n\n# Display the confusion matrix\nprint(confusion_matrix(y_test,smoteenn_xgb_pred))","a23f22fc":"# Create Results Table: Accuracy \npd.options.display.float_format = '{:.3f}'.format\n\nacc_list = [\n    [base_lm_accuracy, base_knn_accuracy, base_svc_accuracy, base_tree_accuracy, base_rfc_accuracy,\n     base_adb_accuracy, base_xgb_accuracy],\n    [smote_lm_accuracy, smote_knn_accuracy, smote_svc_accuracy, smote_tree_accuracy, smote_rfc_accuracy,\n     smote_adb_accuracy, smote_xgb_accuracy],\n    [smoteenn_lm_accuracy, smoteenn_knn_accuracy, smoteenn_svc_accuracy, smoteenn_tree_accuracy, \n     smoteenn_rfc_accuracy,smoteenn_adb_accuracy, smoteenn_xgb_accuracy]]\n\nacc_df = pd.DataFrame(acc_list)\nacc_df.index = ['BASE','SMOTE','SMOTE-ENN']\nacc_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']   \n\n# Create Results Table: Recall\nrec_list = [\n    [base_lm_recall, base_knn_recall, base_svc_recall, base_tree_recall, base_rfc_recall,\n     base_adb_recall, base_xgb_recall],\n    [smote_lm_recall, smote_knn_recall, smote_svc_recall, smote_tree_recall, smote_rfc_recall,\n     smote_adb_recall, smote_xgb_recall],\n    [smoteenn_lm_recall, smoteenn_knn_recall, smoteenn_svc_recall, smoteenn_tree_recall, \n     smoteenn_rfc_recall,smoteenn_adb_recall, smoteenn_xgb_recall]]\n\nrec_df = pd.DataFrame(rec_list)\nrec_df.index = ['BASE','SMOTE','SMOTE-ENN']\nrec_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']\n\n# Create Results Table: F1\nf1_list = [\n    [base_lm_f1, base_knn_f1, base_svc_f1, base_tree_f1, base_rfc_f1,base_adb_f1, base_xgb_f1],\n    [smote_lm_f1, smote_knn_f1, smote_svc_f1, smote_tree_f1, smote_rfc_f1,smote_adb_f1, smote_xgb_f1],\n    [smoteenn_lm_f1, smoteenn_knn_f1, smoteenn_svc_f1, smoteenn_tree_f1,smoteenn_rfc_f1,smoteenn_adb_f1, \n     smoteenn_xgb_f1]]\n\nf1_df = pd.DataFrame(f1_list)\nf1_df.index = ['BASE','SMOTE','SMOTE-ENN']\nf1_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']\n\n# Create Results Table: AUC\nauc_list = [\n    [base_lm_auc, base_knn_auc, base_svc_auc, base_tree_auc, base_rfc_auc,base_adb_auc, base_xgb_auc],\n    [smote_lm_auc, smote_knn_auc, smote_svc_auc, smote_tree_auc, smote_rfc_auc,smote_adb_auc, smote_xgb_auc],\n    [smoteenn_lm_auc, smoteenn_knn_auc, smoteenn_svc_auc, smoteenn_tree_auc,smoteenn_rfc_auc,smoteenn_adb_auc, \n     smoteenn_xgb_auc]]\n\nauc_df = pd.DataFrame(auc_list)\nauc_df.index = ['BASE','SMOTE','SMOTE-ENN']\nauc_df.columns = ['Logistic Regression','KNN','SVM','Decision Tree','Random Forest','AdaBoost','XGBoost']","e9140fc7":"print(\"Accuracy\")\nacc_df","5e34529c":"print(\"Recall\")\nrec_df","ea567802":"print(\"F1 score\")\nf1_df","99dfd46e":"print(\"AUC\")\nauc_df","ad210209":"# Import the library for ROC curve.\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nns_probs = [0 for _ in range(len(y_test))]\n\nprob_lm = base_lm_model.predict_proba(X_test)\nprob_lm = prob_lm[:,1]\n\nprob_knn = base_knn_model.predict_proba(X_test)\nprob_knn = prob_knn[:,1]\n\nprob_svc = base_svc_model.predict_proba(X_test)\nprob_svc = prob_svc[:,1]\n\nprob_tree = base_tree_model.predict_proba(X_test)\nprob_tree = prob_tree[:,1]\n\nprob_rfc = base_rfc_model.predict_proba(X_test)\nprob_rfc = prob_rfc[:,1]\n\nprob_adb = base_adb_model.predict_proba(X_test)\nprob_adb = prob_adb[:,1]\n\nprob_xgb = base_xgb_model.predict_proba(X_test)\nprob_xgb = prob_xgb[:,1]","e730bef4":"ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nlm_fpr, lm_tpr, _ = roc_curve(y_test, prob_lm)\nknn_fpr, knn_tpr, _ = roc_curve(y_test, prob_knn)\nsvc_fpr, svc_tpr, _ = roc_curve(y_test, prob_svc)\ntree_fpr, tree_tpr, _ = roc_curve(y_test, prob_tree)\nrfc_fpr, rfc_tpr, _ = roc_curve(y_test, prob_rfc)\nadb_fpr, adb_tpr, _ = roc_curve(y_test, prob_adb)\nxgb_fpr, xgb_tpr, _ = roc_curve(y_test, prob_xgb)\n\nplt.figure(figsize=(8, 6))\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='Based on Majority')\nplt.plot(lm_fpr, lm_tpr, marker='.', label='Logistic')\nplt.plot(knn_fpr, knn_tpr, marker='.', label='KNN')\nplt.plot(svc_fpr, svc_tpr, marker='.', label='SVM')\nplt.plot(tree_fpr, tree_tpr, marker='.', label='Decision Tree')\nplt.plot(rfc_fpr, rfc_tpr, marker='.', label='Random Forest')\nplt.plot(adb_fpr, adb_tpr, marker='.', label='AdaBoost')\nplt.plot(xgb_fpr, xgb_tpr, marker='.', label='XGBoost')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.legend()\nplt.show()","d8db9a67":"- \"satisfaction_level\" contains 2 missing values. Let's input them. \n\n- Wwe need to convert categorical variables into dummy variables: \"department\", \"salary\" ","5e9190cd":"### Decision Tree Classifier with SMOTE","c82508dc":"### Random Forest Classifier with SMOTE-ENN","8e9cad67":"### SVM with SMOTE","0e3dabac":"### Logistic Regression with SMOTE-ENN","e542c856":"### SVM with Imbalanced Data","a7ead916":"### Logistic Regression with Imbalanced Data","08cc5606":"### XGBoost Classifier with SMOTE","35234b35":"### KNN with SMOTE","76ab3e5e":"## Classification with SMOTE-ENN","8a308093":"### Input missing values","edf8f148":"### KNN with Imbalanced Data","3119905d":"### XGBoost with Imbalance Data","03921a41":"- The data is not uniformly or normally distributed.\n\n- The variable is a continuous variable, so let's impute them withe the median.","28c42a7d":"Both \"department\" and \"salary\" contain more than two values. So let's use get_dummies to create dummy variables.","0bf56489":"KNN with SMOTE-ENN","07f9d0eb":"### Perform SMOTE","58ba7126":"### Random Forest with Imbalanced Data","57dfe0b4":"### AdaBoost Classifier with SMOTE","aeb64b82":"### Convert categorical varaibles into dummy variables","99630ef5":"### ROC Curve","9db19aa5":"The employee churn rate is 23.8. We can say that it is an imbalanced dataset.","8c4fca37":"## Data Preprocessing","d673b965":"### XGBoost Classifier with SMOTE-ENN","4a1852f8":"### Decision Tree Classifier with SMOTE-ENN","36c9631a":"### Decision Tree with Imbalanced Data","ebe31807":"## Classification with Imbalanced Data","fe8246fc":"# Load and Explore Dataset","eb846684":"SMOTE successfully made the dataset balanced","6c17e518":"### AdaBoost with Imbalanced Data","344ca155":"### Random Forest Classifier with SMOTE","8522cdff":"## Classification with SMOTE","b0c36db5":"### Logisgic Regression with SMOTE","50d18a4d":"### Train-Test split","1bc15915":"### AdaBoost with SMOTE-ENN","fc1f0397":"SVM Classifier with SMOTE-ENN"}}