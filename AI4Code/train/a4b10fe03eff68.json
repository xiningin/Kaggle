{"cell_type":{"a7254dc6":"code","87ebef2e":"code","b6229a74":"code","879b25ff":"code","3d382b23":"code","28b9c89d":"code","efae53ff":"code","3e41cb39":"code","daa04810":"code","3790d348":"code","d21d2b25":"code","9517b5fc":"code","3c253f26":"code","6a99c702":"code","1389dfbc":"code","77d85385":"code","4ed21a52":"code","0685e7b8":"code","8560890f":"code","752243c4":"code","53e9802e":"code","524e6074":"code","0affb4af":"code","51aca978":"code","675a8e16":"code","1a4c1143":"code","b4e2f163":"code","709e3d0d":"code","a68f41c4":"code","2cc449ce":"code","4cb730dc":"code","b1c74e78":"code","2a810c14":"code","ef0c5c43":"code","e66ac4a8":"code","9ad447cb":"code","1ac07fc3":"code","fc4b157b":"code","3e0d820a":"markdown","78fd6b8e":"markdown","d7557121":"markdown","546a77dc":"markdown","b9336d10":"markdown","eb822151":"markdown","3d01955f":"markdown","3f6deca6":"markdown"},"source":{"a7254dc6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical \nimport time\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\nfrom keras.layers import Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport cv2\n  \n\n# set seed for reproducibility\nnp.random.seed(0)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","87ebef2e":"from PIL import Image, ImageFilter\n\n\ndef imageprepare(argv):\n    \"\"\"\n    This function returns the pixel values.\n    The imput is a png file location.\n    \"\"\"\n    im = Image.open(argv).convert('L')\n    width = float(im.size[0])\n    height = float(im.size[1])\n    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels\n\n    if width > height:  # check which dimension is bigger\n        # Width is bigger. Width becomes 20 pixels.\n        nheight = int(round((20.0 \/ width * height), 0))  # resize height according to ratio width\n        if (nheight == 0):  # rare case but minimum is 1 pixel\n            nheight = 1\n            # resize and sharpen\n        img = im.resize((20, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n        wtop = int(round(((28 - nheight) \/ 2), 0))  # calculate horizontal position\n        newImage.paste(img, (4, wtop))  # paste resized image on white canvas\n    else:\n        # Height is bigger. Heigth becomes 20 pixels.\n        nwidth = int(round((20.0 \/ height * width), 0))  # resize width according to ratio height\n        if (nwidth == 0):  # rare case but minimum is 1 pixel\n            nwidth = 1\n            # resize and sharpen\n        img = im.resize((nwidth, 20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n        wleft = int(round(((28 - nwidth) \/ 2), 0))  # caculate vertical pozition\n        newImage.paste(img, (wleft, 4))  # paste resized image on white canvas\n\n    # newImage.save(\"sample.png\n\n    tv = list(newImage.getdata())  # get pixel values\n\n    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n    tva = [(255 - x) * 1.0 \/ 255.0 for x in tv]\n    #print(tva)\n    return tva\n\n# precess input image: convert into numpy and reshape \nlen_private_handwriting = 9 # this depends on the number of files in private-handwriting dataset\nprivate_list = []\nfor i in range(1,len_private_handwriting+1):\n    path = '\/kaggle\/input\/private-handwriting\/0' + str(i) + '.png'\n    \n    img = cv2.imread(path)\n    plt.imshow(img)\n    plt.show()\n    \n    private_list.append(imageprepare(path))","b6229a74":"for im in private_list:\n    plt.imshow(np.array(im).reshape(28,28))  # (rows, columns)\n    # the label of the first number\n    plt.show() ","879b25ff":"# read the data\ndf_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\n\ndf_train.shape, df_test.shape","3d382b23":"new_df = pd.DataFrame(columns=df_test.columns)\nfor i in range(9):\n    new_df.loc[i] = private_list[i]\nnew_df","28b9c89d":"df_test.head()","efae53ff":"y = df_train['label']\ny = to_categorical(y, num_classes=10) # split into 10 classes for the y value","3e41cb39":"y[0]","daa04810":"train = df_train.iloc[:,1:].values.reshape(-1,28,28,1)\ntest = df_test.iloc[:,:].values.reshape(-1,28,28,1)\nnew = new_df.iloc[:,:].values.reshape(-1,28,28,1)","3790d348":"for i in range(9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(train[i], cmap=plt.get_cmap('gray'))","d21d2b25":"for i in range(9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(test[i], cmap=plt.get_cmap('gray'))","9517b5fc":"for i in range(9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(new[i], cmap=plt.get_cmap('gray'))","3c253f26":"train = train.reshape((train.shape[0], 28*28)).astype('float64') \/ 255\ntest = test.reshape((test.shape[0], 28*28)).astype('float64') \/ 255\nnew = new.reshape((new.shape[0], 28*28)).astype('float64') \/ 255","6a99c702":"print('Train shape:', train.shape)\nprint('Test shape:', test.shape)\nprint('New shape:', new.shape)","1389dfbc":"x_train, x_val , y_train, y_val = train_test_split(train, y, test_size=0.1, random_state=42) \nx_train.shape, x_val.shape, y_train.shape, y_val.shape","77d85385":"# view the first number\n# the reason to be 28 * 28 is that 28^2 = 784\nplt.imshow(x_train[0].reshape(28, 28))  # (rows, columns)\n# the label of the first number\nplt.title(f\"Digit: {y_train[0]}\")\nplt.show() ","4ed21a52":"# build the model\nmodel = Sequential()\nmodel.add(Dense(256, input_dim=784, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))","0685e7b8":"from keras.datasets import mnist\nfrom keras.utils.np_utils import to_categorical\n(x_train_1, y_train_1), (x_val_1, y_val_1) = mnist.load_data()\nprint('Train: X=%s, y=%s' % (x_train_1.shape, y_train_1.shape))\nprint('Test: X=%s, y=%s' % (x_val_1.shape, y_val_1.shape))","8560890f":"x_train_1 = x_train_1.reshape((x_train_1.shape[0], 28*28)).astype('float64') \/ 255\nx_val_1 = x_val_1.reshape((x_val_1.shape[0], 28*28)).astype('float64') \/ 255\ny_train_1 = to_categorical(y_train_1)\ny_val_1 = to_categorical(y_val_1)","752243c4":"new_x_train = np.concatenate((x_train_1, x_val_1), axis=0)\nnew_y_train = np.concatenate((y_train_1, y_val_1), axis=0)","53e9802e":"print('new_x_train shape:', new_x_train.shape)\nprint('new_y_train shape:', new_y_train.shape)","524e6074":"x_val, x_test , y_val, y_test = train_test_split(train, y, test_size=0.15, random_state=42)","0affb4af":"optimizer = tf.keras.optimizers.Adam(0.0005)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nprint(optimizer.learning_rate)\nstart = time.time()\nhistory = model.fit(new_x_train, new_y_train, epochs=40, batch_size=64, validation_data = (x_val,y_val))\nend = time.time()\nprint(\"Algorithm time is {} s:\".format(round(end-start)))","51aca978":"plt.rcParams[\"figure.figsize\"] = (10,10)\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","675a8e16":"# see the model structure\nmodel.summary()","1a4c1143":"result = model.predict(x_test)","b4e2f163":"result","709e3d0d":"# evaluate the model\nloss_and_metrics = model.evaluate(x_val, y_val, verbose=2)\n\nprint(\"Val Loss\", loss_and_metrics[0])\nprint(\"Val Accuracy\", loss_and_metrics[1])","a68f41c4":"predictions = model.predict(test)\npredictions = np.argmax(predictions , axis=1)","2cc449ce":"submission=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission['Label']=predictions\nsubmission.to_csv('submission.csv', index=False)","4cb730dc":"test.shape","b1c74e78":"new.shape","2a810c14":"test[0]","ef0c5c43":"new[0]","e66ac4a8":"new[1]","9ad447cb":"plt.imshow(new[1].reshape(28, 28))  # (rows, columns)\n# the label of the first number\nplt.title(f\"Digit: \")\nplt.show() ","1ac07fc3":"plt.imshow(test[1].reshape(28, 28))  # (rows, columns)\n# the label of the first number\nplt.title(f\"Digit: \")\nplt.show() ","fc4b157b":"#1, 2, 3, 4, 5, 6, 7, 8\nnp.argmax(model.predict(new), axis=1)","3e0d820a":"### View an Image in More Detail","78fd6b8e":"# Check https:\/\/www.kaggle.com\/huangjingstark\/private-handwriting ","d7557121":"## Modeling","546a77dc":"Before training a model in Keras, we need to specify an *optimizer* to perform the gradient descent, a *loss function* to be minimized, and (optionally) any *performance metrics*. The optimization algorithm we'll use for this course is called [\"Adam\"](https:\/\/keras.io\/api\/optimizers\/adam\/), which generally performs well regardless of what kind of problem you're trying to solve.","b9336d10":"Generally the bigger the batch, the more stable our stochastic gradient descent updates will be. But beware of GPU memory limitations! We're going for a batch size of 128 and 25 epochs.","eb822151":"## Reading the dataset","3d01955f":"The models recognize these numbers as 8 because of overfitting","3f6deca6":"to plot the numbers we need to convert the first row in the dataframe to a numpy array, & then reshape it by (28,28) to look like an image."}}