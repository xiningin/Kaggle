{"cell_type":{"983fc48c":"code","7f1ef0cd":"code","d933986f":"code","9f2e1cd9":"code","54313a17":"code","21479bd3":"code","2b54f676":"code","1fd49eb4":"code","04f96523":"code","ad99fcc7":"code","9138ff1e":"code","05c58e73":"code","b666f1cc":"code","9879c14d":"code","96f8dcdb":"code","373a2996":"code","3b193bd3":"code","d32cacb7":"code","2adfaa83":"code","f57e6bc6":"code","3be076da":"code","485adefa":"code","8f0b94e1":"code","1815f835":"code","2e3e9f98":"code","6590d744":"code","f924a8ee":"code","fb5f8d9a":"code","46feafc2":"code","afda3630":"code","1eb21382":"code","e5b66c71":"code","16d070d9":"code","7708106e":"code","3847af96":"code","64fdcf68":"code","9f33c538":"code","29b6018f":"code","3d809d9b":"code","c3d32f12":"code","794d141d":"code","749dee55":"code","ff24b240":"code","5d9c0c93":"markdown","424cd970":"markdown","dbef439f":"markdown","375c612d":"markdown","f7d03293":"markdown","597a9551":"markdown","4bb05fe7":"markdown","59895683":"markdown","b4fc18d1":"markdown","896feb2e":"markdown","39c871b5":"markdown","1ee29d92":"markdown","273216ef":"markdown","12fc5c4a":"markdown","70c5168d":"markdown"},"source":{"983fc48c":"import warnings\nwarnings.filterwarnings(\"ignore\")","7f1ef0cd":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport xgboost as xgb\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n\nfrom sklearn.experimental import enable_hist_gradient_boosting # experimental\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\nfrom IPython.display import display, Markdown, Latex","d933986f":"# matplotlib\nplt.rc('font', size=15)\nplt.rc('axes', titlesize=18)  \nplt.rc('xtick', labelsize=10)  \nplt.rc('ytick', labelsize=10)\n\n# seaborn\nsns.set_style(\"whitegrid\")","9f2e1cd9":"class Config:\n    RANDOM_STATE = 2021\n    TRAIN_DATA = '..\/input\/tabular-playground-series-aug-2021\/train.csv'\n    TEST_DATA = '..\/input\/tabular-playground-series-aug-2021\/test.csv'\n    SUBMISSION = '..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv'    \n    SUBMISSION_FILE = 'submission.csv'\n    TEST_SIZE = 0.3\n    \n    INDEX = 'id'\n    TARGET = 'loss'\n    FEATURES = ['f{}'.format(i) for i in range(0, 100)]\n    COLUMNS = FEATURES + [TARGET]\n    \n    @staticmethod\n    def set_seed():\n        random.seed(Config.RANDOM_STATE)\n        np.random.seed(Config.RANDOM_STATE)\n\nConfig.set_seed()","54313a17":"train_data = pd.read_csv(Config.TRAIN_DATA)\ntrain_data.head(5)","21479bd3":"test_data = pd.read_csv(Config.TEST_DATA)\ntest_data.head(5)","2b54f676":"train_data[Config.COLUMNS].describe().T","1fd49eb4":"train_data[Config.COLUMNS].describe().T.style.bar(\n    subset=['mean'], color='Bules'\n).background_gradient(subset=['50%'], cmap='Blues') # highlight median","04f96523":"def plot_pdf(\n    data:pd.DataFrame, \n    feature:str, \n    title='Estimate pdf',\n    ax=None):\n    \"\"\" Plots the estimated pdf. \n    \"\"\"\n    if ax == None:\n        fig, ax = plt.subplots(1, 1)\n    \n    # plot pdf\n    sns.kdeplot(\n        data=data[feature], \n        palette='Blues_r',\n        cumulative=False,\n        legend=True,\n        ax=ax)\n    \n    ax.set_title(title)\n    ax.set_xlabel('Feature {}'.format(feature))\n    ax.set_ylabel('Density')\n    \n    return ax","ad99fcc7":"def plot_cdf(\n    data:pd.DataFrame, \n    feature:str, \n    title='Empirical cdf', \n    ax=None):\n    \"\"\" Plots the empirical cdf. \n    \"\"\"\n    if ax == None:\n        fig, ax = plt.subplots(1, 1)\n    \n    # plot pdf\n    sns.kdeplot(\n        data=data[feature], \n        palette='Blues_r',\n        cumulative=True,\n        legend=True,\n        ax=ax)\n    \n    ax.set_title(title)\n    ax.set_xlabel('Feature {}'.format(feature))\n    ax.set_ylabel('Probability')\n    \n    return ax","9138ff1e":"def plot_qq(\n    data:pd.DataFrame, \n    feature:str, \n    title='QQ-Plot', \n    ax=None):\n    \"\"\" QQ-Plot. \n    \"\"\"\n    if ax == None:\n        fig, ax = plt.subplots(1, 1)\n    \n    # qq plot\n    sm.qqplot(\n        data[feature], \n        line='45',\n        fmt='--',\n        ms=0.1,\n        ax=ax)\n    \n    ax.set_title(title)\n    return ax","05c58e73":"def plot_feature_vs_target(\n    data:pd.DataFrame, \n    feature:str,\n    target:str=Config.TARGET,\n    title='Feature vs. Target', \n    ax=None):\n    \"\"\" Fetaure vs. Target scatter plot \n    \"\"\"\n    if ax == None:\n        fig, ax = plt.subplots(1, 1)\n    \n    # scatter plot\n    sns.scatterplot(\n        x=data[feature], \n        y=data[target], \n        ax=ax, \n        alpha=0.4)\n    \n    ax.set_title(title)\n    ax.set_xlabel('Feature {}'.format(feature))\n    ax.set_ylabel('Target')\n    \n    return ax","b666f1cc":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n\nplot_pdf(train_data, Config.TARGET, ax=ax[0])\nplot_cdf(train_data, Config.TARGET, ax=ax[1])\nplot_qq(train_data, Config.TARGET, ax=ax[2])\n\nplt.show()","9879c14d":"def plot_target(target_data, ax=None):\n    \"\"\"\n    \"\"\"\n    if ax == None:\n        fig, ax = plt.subplots(1, 1)\n\n    sns.histplot(\n        x=target_data,\n        palette=sns.color_palette(),\n        stat='probability',\n        discrete=True\n    )\n    \n    ax.set_title('Target distribution')\n    ax.set_xlabel('Target values')\n    \n    return ax","96f8dcdb":"fig, ax = plt.subplots(1, 1, figsize=(12, 7))\nplot_target(train_data[Config.TARGET], ax=ax)\n\nplt.show()","373a2996":"# Target `loss` distribution\ntarget_distribution = pd.DataFrame({\n    'count': train_data[[Config.TARGET]].value_counts(),\n    'percent': np.round(train_data[[Config.TARGET]].value_counts() \/ train_data.shape[0], 3)\n})\n\ntarget_distribution","3b193bd3":"train_data[[Config.TARGET]].describe().T","d32cacb7":"feature_info = pd.DataFrame({\n    'feature': train_data[Config.FEATURES].columns,\n    'skewness': train_data[Config.FEATURES].skew(),\n    'kurtosis': train_data[Config.FEATURES].kurt(),\n    \n    \n}).set_index('feature')\n\nfeature_info","2adfaa83":"# normalize data \nscaler = StandardScaler()\n\nscaled_train_data = train_data.copy()\nscaled_test_data = test_data.copy()\n\nscaled_train_data[Config.FEATURES] = scaler.fit_transform(scaled_train_data[Config.FEATURES])\nscaled_test_data[Config.FEATURES] = scaler.transform(scaled_test_data[Config.FEATURES])\n\nscaled_train_data[Config.TARGET] = StandardScaler().fit_transform(scaled_train_data[[Config.TARGET]])","f57e6bc6":"for feature in Config.FEATURES:\n    display(Markdown('#### Plot feature `{}`'.format(feature)))\n            \n    fig, ax = plt.subplots(1, 4, figsize=(25, 5))\n\n    plot_pdf(scaled_train_data, feature, ax=ax[0]) # train pdf\n    plot_pdf(scaled_test_data, feature, ax=ax[0])  # test pdf\n    plot_cdf(scaled_train_data, feature, ax=ax[1])\n    plot_qq(scaled_train_data, feature, ax=ax[2])\n    plot_feature_vs_target(scaled_train_data, feature, ax=ax[3])\n\n    plt.show()","3be076da":"corr_matrix = train_data[Config.COLUMNS].corr()","485adefa":"plt.figure(figsize = (20, 15))\n\nsns.heatmap(\n    corr_matrix, \n    annot = False, \n    cmap = 'Blues', \n    mask = np.triu(corr_matrix), \n    linewidths = 0.1, \n    linecolor = 'white', \n    cbar = True\n)\n\nplt.show()","8f0b94e1":"from sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D","1815f835":"n_components = 100\npca = make_pipeline(\n    MinMaxScaler(),\n    PCA(n_components=n_components, \n        random_state=Config.RANDOM_STATE)\n)\n\npca_cols = ['pc{}'.format(i) for i in range(1, n_components + 1)]\ncomponents = pca.fit_transform(train_data[Config.FEATURES])","2e3e9f98":"pca_data = pd.DataFrame({Config.TARGET: train_data[Config.TARGET]})\n\nfor i in range(1, n_components + 1):\n    pca_data[pca_cols[i-1]] = components[:, i-1]\n\npca_data = pca_data.sample(frac=0.08, random_state=Config.RANDOM_STATE)","6590d744":"variance = pca['pca'].explained_variance_ratio_\nvar=np.cumsum(np.round(variance, decimals=3)*100)\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\n\nax[0].plot(variance)\nax[0].set_xlabel('# of Components')\nax[0].set_ylabel('Explained variance')\nax[0].set_title(\"PCA Analysis\")\n\nax[1].plot(var)\nax[1].set_ylabel('% Variance Explained')\nax[1].set_xlabel('# of Components')\n\nfig.tight_layout()\nfig.show()","f924a8ee":"def plot_pca(data, x, y, ax=None):\n    if ax == None:\n        fig, ax = plt.subplots(1, 1)\n\n    sns.scatterplot(\n        data=data,\n        x=x, \n        y=y,\n        hue=Config.TARGET,\n        palette='Blues_r',\n        alpha=0.4, \n        ax=ax)","fb5f8d9a":"fig, ax = plt.subplots(1, 4, figsize=(25, 5))\n\nplot_pca(pca_data, 'pc1', 'pc2', ax=ax[0])\nplot_pca(pca_data, 'pc2', 'pc3', ax=ax[1])\nplot_pca(pca_data, 'pc3', 'pc4', ax=ax[2])\nplot_pca(pca_data, 'pc4', 'pc5', ax=ax[3])\n\nplt.show()","46feafc2":"fig, ax = plt.subplots(1, 5, figsize=(25, 5))\n\nplot_pdf(pca_data, 'pc1', ax=ax[0]) \nplot_pdf(pca_data, 'pc2', ax=ax[1]) \nplot_pdf(pca_data, 'pc3', ax=ax[2]) \nplot_pdf(pca_data, 'pc4', ax=ax[3]) \nplot_pdf(pca_data, 'pc5', ax=ax[4]) \n\nfig.tight_layout()\nfig.show()","afda3630":"fig = plt.figure(figsize=(10, 10))\n\nax = fig.add_subplot(111, projection='3d')\nax.scatter(\n    pca_data['pc1'], \n    pca_data['pc2'], \n    pca_data['pc3'],\n    alpha=0.8,\n    c=pca_data[Config.TARGET],\n    cmap='Blues'\n)\n\nfig.show()","1eb21382":"pd.DataFrame({\n    'data_set': ['train', 'test'],\n    'missing_values': [\n        train_data.isna().sum().sum(), \n        test_data.isna().sum().sum()\n    ]\n}).set_index('data_set')","e5b66c71":"def rmse(y_true, y_pred):\n    \"\"\"RMSE Score\n    \"\"\"\n    return np.sqrt(mean_squared_error(y_true, y_pred))","16d070d9":"score = pd.DataFrame({\n    'model': [],\n    'rmse': []\n}).set_index('model')","7708106e":"X_data = train_data[Config.FEATURES]\ny_data = train_data[Config.TARGET]\n\n# spit data into train and validation data sets\nX_train, X_vaild, y_train, y_vaild = train_test_split(\n    X_data,\n    y_data,\n    test_size=Config.TEST_SIZE, \n    random_state=Config.RANDOM_STATE\n)","3847af96":"print(f'Train size     : {X_train.shape[0]}')\nprint(f'Validation size: {X_vaild.shape[0]}')","64fdcf68":"def create_model(regressor):\n    \"\"\"\n    \"\"\"\n    model = TransformedTargetRegressor(\n        regressor=make_pipeline(\n            StandardScaler(),\n            PowerTransformer(),\n            regressor\n        ), \n        transformer=StandardScaler()\n    )\n    return model","9f33c538":"models = [\n    ('lr', create_model(LinearRegression())),\n    ('ridge', create_model(Ridge(alpha=0.75))),\n    ('hgb', create_model(HistGradientBoostingRegressor())),\n    ('gb', create_model(GradientBoostingRegressor())),\n    ('xgb', create_model(xgb.XGBRegressor())),\n    ('rf', create_model(RandomForestRegressor()))\n]\n\nweights = [0.1, 0.1, 0.4, 0.1, 0.2, 0.1]","29b6018f":"model = VotingRegressor(\n    estimators = models,\n    weights = weights,\n    n_jobs = -1,\n    verbose=True\n)\n\ny_pred = model.fit(X_train, y_train).predict(X_vaild)\nscore = rmse(y_vaild, y_pred)\n\nprint('RMSE: {}'.format(score))","3d809d9b":"result_data = pd.DataFrame({\n    'pred': y_pred,\n    'true': y_vaild\n})","c3d32f12":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n\nplot_pdf(result_data, 'pred', ax=ax[0])\nplot_pdf(result_data, 'true', ax=ax[0])\n\nplot_cdf(result_data, 'pred', ax=ax[1])\nplot_cdf(result_data, 'true', ax=ax[1])\n\nplot_feature_vs_target(result_data, 'pred', target='true', ax=ax[2])\n\nplt.show()","794d141d":"y_pred_submission = model.predict(test_data[Config.FEATURES])","749dee55":"submission_data = pd.DataFrame({\n    Config.INDEX: test_data[Config.INDEX],\n    Config.TARGET: y_pred_submission,\n}).set_index(Config.INDEX)\n\nsubmission_data","ff24b240":"# save submission file\nsubmission_data.to_csv(Config.SUBMISSION_FILE)","5d9c0c93":"## Principal component analysis (PCA)","424cd970":"### Notes\n\n* The traing data set has 250000 observations with 102 features.\n* The test data set has 150000 observations with 101 features.\n* The `loss` cloumn is the target variable, which takes only integer values between 0 and 42.","dbef439f":"### Missing values\n\nThere are no rows with missing values in both data sets.","375c612d":"## Import Data","f7d03293":"## Submission","597a9551":"## Data preprocessing","4bb05fe7":"## Modeling","59895683":"# Tabular Playground Series - Aug 2021","b4fc18d1":"## Correlation\n\nThe features and the target variables all have a low correlation with each other.","896feb2e":"### Notes\n\n* The distribution of the target variable `loss` is discrete, taking values $0,\\dots,42$.\n* Mean $\\mu=6.81392$ and std $\\sigma=7.940179$.","39c871b5":"### Target `loss`","1ee29d92":"## Imports","273216ef":"### Features `f0` - `f99`","12fc5c4a":"## Configuration","70c5168d":"## Exploratory data analysis (EDA)"}}