{"cell_type":{"6c43bf9b":"code","52ba5a07":"code","0537518e":"code","c167f190":"code","b438bd7b":"code","749a893b":"code","68e0edf0":"code","2e7b2c3f":"code","0d1a916f":"code","e847d915":"code","04f27480":"code","fac980a2":"code","1e830558":"code","1ff44d93":"code","2ecbeae9":"code","e773c1d8":"code","19d1e7d1":"code","ea1ff187":"code","c36a6ce9":"code","866f646e":"code","e4b9cb7a":"code","db12b35b":"markdown","307b563e":"markdown","02ead2ac":"markdown","428d85df":"markdown","1a5ecd45":"markdown","2ab13a51":"markdown","c1461e0a":"markdown","617576ee":"markdown","7fdbd14e":"markdown","63ed2cbd":"markdown","6c3c01b5":"markdown","a8e9eb5d":"markdown","4fdbd86b":"markdown","43e620b8":"markdown","13a2c94f":"markdown","5a43881b":"markdown","4bb3f9ff":"markdown"},"source":{"6c43bf9b":"!node --version","52ba5a07":"!pip install kaggle-environments -U","0537518e":"from kaggle_environments import make","c167f190":"# create the environment. You can also specify configurations for seed and loglevel as shown below. If not specified, a random seed is chosen. \n# loglevel default is 0. \n# 1 is for errors, 2 is for match warnings such as units colliding, invalid commands (recommended)\n# 3 for info level, and 4 for everything (not recommended)\n# set annotations True so annotation commands are drawn on visualizer\n# set debug to True so print statements get shown\nenv = make(\"lux_ai_2021\", configuration={\"seed\": 562124210, \"loglevel\": 2, \"annotations\": True}, debug=True)","b438bd7b":"# run a match between two simple agents, which are the agents we will walk you through on how to build!\nsteps = env.run([\"simple_agent\", \"simple_agent\"])\n# if you are viewing this outside of the interactive jupyter notebook \/ kaggle notebooks mode, this may look cutoff\n# render the game, feel free to change width and height to your liking. We recommend keeping them as large as possible for better quality.\n# you may also want to close the output of this render cell or else the notebook might get laggy\nenv.render(mode=\"ipython\", width=1050, height=600)","749a893b":"# run this if using kaggle notebooks\n!cp -r ..\/input\/lux-ai-2021\/* .\n# if working locally, download the `simple\/lux` folder from here https:\/\/github.com\/Lux-AI-Challenge\/Lux-Design-2021\/tree\/master\/kits\/python\n# and we recommend following instructions in there for local development with python bots","68e0edf0":"# for kaggle-environments\nfrom lux.game import Game\nfrom lux.game_map import Cell, RESOURCE_TYPES, Position\nfrom lux.constants import Constants\nfrom lux.game_constants import GAME_CONSTANTS\nfrom lux import annotate\nimport math\nimport sys\n\n# we declare this global game_state object so that state persists across turns so we do not need to reinitialize it all the time\ngame_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    ### Do not edit ###\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    ### AI Code goes down here! ### \n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n    \n    # add debug statements like so!\n    if game_state.turn == 0:\n        print(\"Agent is running!\", file=sys.stderr)\n        actions.append(annotate.circle(0, 0))\n    return actions","2e7b2c3f":"steps = env.run([agent, \"simple_agent\"])","0d1a916f":"env.render(mode=\"ipython\", width=1050, height=600)","e847d915":"# this snippet finds all resources stored on the map and puts them into a list so we can search over them\ndef find_resources(game_state):\n    resource_tiles: list[Cell] = []\n    width, height = game_state.map_width, game_state.map_height\n    for y in range(height):\n        for x in range(width):\n            cell = game_state.map.get_cell(x, y)\n            if cell.has_resource():\n                resource_tiles.append(cell)\n    return resource_tiles\n\n# the next snippet finds the closest resources that we can mine given position on a map\ndef find_closest_resources(pos, player, resource_tiles):\n    closest_dist = math.inf\n    closest_resource_tile = None\n    for resource_tile in resource_tiles:\n        # we skip over resources that we can't mine due to not having researched them\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.COAL and not player.researched_coal(): continue\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.URANIUM and not player.researched_uranium(): continue\n        dist = resource_tile.pos.distance_to(pos)\n        if dist < closest_dist:\n            closest_dist = dist\n            closest_resource_tile = resource_tile\n    return closest_resource_tile","04f27480":"# lets look at some of the resources found\nresource_tiles = find_resources(game_state)\nfor i in range(5):\n    cell = resource_tiles[i]\n    print(\"Cell at\", cell.pos, \"has\")\n    print(cell.resource.type, cell.resource.amount)","fac980a2":"# lets see if we do find some close resources\ncell = find_closest_resources(Position(1, 1), game_state.players[0], resource_tiles)\nprint(\"Closest resource at\", cell.pos, \"has\")\nprint(cell.resource.type, cell.resource.amount)","1e830558":"game_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    ### Do not edit ###\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    ### AI Code goes down here! ### \n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n    \n    # add debug statements like so!\n    if game_state.turn == 0:\n        print(\"Agent is running!\", file=sys.stderr)\n\n    resource_tiles = find_resources(game_state)\n    \n    for unit in player.units:\n        # if the unit is a worker (can mine resources) and can perform an action this turn\n        if unit.is_worker() and unit.can_act():\n            # we want to mine only if there is space left in the worker's cargo\n            if unit.get_cargo_space_left() > 0:\n                # find the closest resource if it exists to this unit\n                closest_resource_tile = find_closest_resources(unit.pos, player, resource_tiles)\n                if closest_resource_tile is not None:\n                    # create a move action to move this unit in the direction of the closest resource tile and add to our actions list\n                    action = unit.move(unit.pos.direction_to(closest_resource_tile.pos))\n                    actions.append(action)\n    \n    return actions","1ff44d93":"env = make(\"lux_ai_2021\", configuration={\"seed\": 562124210, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run([agent, \"simple_agent\"])\nenv.render(mode=\"ipython\", width=1050, height=800)","2ecbeae9":"# snippet to find the closest city tile to a position\ndef find_closest_city_tile(pos, player):\n    closest_city_tile = None\n    if len(player.cities) > 0:\n        closest_dist = math.inf\n        # the cities are stored as a dictionary mapping city id to the city object, which has a citytiles field that\n        # contains the information of all citytiles in that city\n        for k, city in player.cities.items():\n            for city_tile in city.citytiles:\n                dist = city_tile.pos.distance_to(pos)\n                if dist < closest_dist:\n                    closest_dist = dist\n                    closest_city_tile = city_tile\n    return closest_city_tile\n\n\n#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\ndef enough_to_broaden(pos, player):\n    energy_dict = []\n    if len(player.cities) > 0:\n        for k, city in player.cities.items():\n            energy_dict.append([city.fuel, city.light_upkeep * 10 ,city.citytiles[0].pos])\n            \n    # if everything is ok build city if not show the location\n    if energy_dict.sort(key = lambda x: x[0])[0] > 230:\n        return True\n    else:\n        dist = [i[2].distance_to(pos) for i in energy_dict if i[0] < 230]\n    \n    closest_dist = math.inf\n    for d in dist:\n        if d < closest_dist:\n            closest_dist = d\n            closest_city_tile = city_tile\n                \n    return closest_city_tile\n    \n","e773c1d8":"get_city_tiles_energy(game_state.players[0])","19d1e7d1":"game_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    ### Do not edit ###\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    ### AI Code goes down here! ### \n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n    \n    # add debug statements like so!\n    if game_state.turn == 0:\n        print(\"Agent is running!\", file=sys.stderr)\n\n    resource_tiles = find_resources(game_state)\n        \n    for unit in player.units:\n        \n        # if the unit is a worker (can mine resources) and can perform an action this turn\n        if unit.is_worker() and unit.can_act():\n            # we want to mine only if there is space left in the worker's cargo\n            if unit.get_cargo_space_left() > 0:\n                # find the closest resource if it exists to this unit\n                closest_resource_tile = find_closest_resources(unit.pos, player, resource_tiles)\n                if closest_resource_tile is not None:\n                    # create a move action to move this unit in the direction of the closest resource tile and add to our actions list\n                    action = unit.move(unit.pos.direction_to(closest_resource_tile.pos))\n                    actions.append(action)\n            else:\n                # find the closest citytile and move the unit towards it to drop resources to a citytile to fuel the city\n                closest_city_tile = find_closest_city_tile(unit.pos, player)\n                if closest_city_tile is not None:\n                    # create a move action to move this unit in the direction of the closest resource tile and add to our actions list\n                    action = unit.move(unit.pos.direction_to(closest_city_tile.pos))\n                    actions.append(action)\n    \n    return actions","ea1ff187":"env = make(\"lux_ai_2021\", configuration={\"seed\": 562124210, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run([agent, \"simple_agent\"])\nenv.render(mode=\"ipython\", width=1050, height=800)","c36a6ce9":"%%writefile agent.py\n# for kaggle-environments\nfrom lux.game import Game\nfrom lux.game_map import Cell, RESOURCE_TYPES\nfrom lux.constants import Constants\nfrom lux.game_constants import GAME_CONSTANTS\nfrom lux import annotate\nimport math\nimport sys\n\n### Define helper functions\n\n# this snippet finds all resources stored on the map and puts them into a list so we can search over them\ndef find_resources(game_state):\n    resource_tiles: list[Cell] = []\n    width, height = game_state.map_width, game_state.map_height\n    for y in range(height):\n        for x in range(width):\n            cell = game_state.map.get_cell(x, y)\n            if cell.has_resource():\n                resource_tiles.append(cell)\n    return resource_tiles\n\n# the next snippet finds the closest resources that we can mine given position on a map\ndef find_closest_resources(pos, player, resource_tiles):\n    closest_dist = math.inf\n    closest_resource_tile = None\n    for resource_tile in resource_tiles:\n        # we skip over resources that we can't mine due to not having researched them\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.COAL and not player.researched_coal(): continue\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.URANIUM and not player.researched_uranium(): continue\n        dist = resource_tile.pos.distance_to(pos)\n        if dist < closest_dist:\n            closest_dist = dist\n            closest_resource_tile = resource_tile\n    return closest_resource_tile\n\ndef find_closest_city_tile(pos, player):\n    closest_city_tile = None\n    if len(player.cities) > 0:\n        closest_dist = math.inf\n        # the cities are stored as a dictionary mapping city id to the city object, which has a citytiles field that\n        # contains the information of all citytiles in that city\n        for k, city in player.cities.items():\n            for city_tile in city.citytiles:\n                dist = city_tile.pos.distance_to(pos)\n                if dist < closest_dist:\n                    closest_dist = dist\n                    closest_city_tile = city_tile\n    return closest_city_tile\n\ngame_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    ### Do not edit ###\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    ### AI Code goes down here! ### \n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n\n    resource_tiles = find_resources(game_state)\n    \n    for unit in player.units:\n        # if the unit is a worker (can mine resources) and can perform an action this turn\n        if unit.is_worker() and unit.can_act():\n            # we want to mine only if there is space left in the worker's cargo\n            if unit.get_cargo_space_left() > 0:\n                # find the closest resource if it exists to this unit\n                closest_resource_tile = find_closest_resources(unit.pos, player, resource_tiles)\n                if closest_resource_tile is not None:\n                    # create a move action to move this unit in the direction of the closest resource tile and add to our actions list\n                    action = unit.move(unit.pos.direction_to(closest_resource_tile.pos))\n                    actions.append(action)\n            else:\n                # find the closest citytile and move the unit towards it to drop resources to a citytile to fuel the city\n                closest_city_tile = find_closest_city_tile(unit.pos, player)\n                if closest_city_tile is not None:\n                    # create a move action to move this unit in the direction of the closest resource tile and add to our actions list\n                    action = unit.move(unit.pos.direction_to(closest_city_tile.pos))\n                    actions.append(action)\n    \n    return actions","866f646e":"!tar -czf submission.tar.gz *","e4b9cb7a":"import json\nreplay = env.toJSON()\nwith open(\"replay.json\", \"w\") as f:\n    json.dump(replay, f)","db12b35b":"## Submit\nNow open the \/kaggle\/working folder and find submission.tar.gz, download that file, navigate to the \"MySubmissions\" tab in https:\/\/www.kaggle.com\/c\/lux-ai-2021\/ and upload your submission! It should play a validation match against itself and once it succeeds it will be automatically matched against other players' submissions. Newer submissions will be prioritized for games over older ones. Your team is limited in the number of succesful submissions per day so we highly recommend testing your bot locally before submitting.","307b563e":"Now lets watch a match where our agent plays against a sample agent and see if it moves towards the resources! We can then verify by watching the replay and seeing our orange unit (team 0) move towards a nearby forest and collect wood","02ead2ac":"## Create a submission\nNow we need to create a .tar.gz file with main.py (and agent.py) at the top level. We can then upload this!","428d85df":"With this function, we are ready to start surviving the nights! The code below rewrites our agent to now have units who have full cargos to head towards the closest citytile and drop off their resources to fuel the city.","1a5ecd45":"The `make` function is used to create environments that can then run the game given agents. Agents refer to programmed bots that play the game given observations of the game itself. \n\nIn addition to making the environment, you may also pass in special configurations such as the number of episode steps (capped at 361) and the seed.\n\nNow lets create our environment using `make` and watch a Episode! (We will be using the seed 562124210 because it's fun)","2ab13a51":"Next, we have to import the `make` function from the `kaggle_environments` package","c1461e0a":"## Suggestions \/ Strategies\n\nThere are a lot of places that could be improved with the agent we have in this tutorial notebook. Here are some!\n\n- Using the build city action to build new cities and thus build new units\n- Having cities perform research each turn to unlock new resources\n- Writing collision-free code that lets units move smoothly around and through each other when navigating to targets\n- Mining resources near your opponent's citytiles so they have less easy access to resources\n- Using carts to deliver resources from far away clusters of wood, coal, uranium to a city in need\n- Sending worker units over to the opponent's roads and pillaging them to slow down their agent\n- Optimizing over how much to mine out of forests before letting them regrow so you can build more cities and get sustainable fuel","617576ee":"# Lux AI Season 1 Python Tutorial Notebook\n\nWelcome to Lux AI Season 1!\n\nThis notebook is the basic setup to use Jupyter Notebooks and the `kaggle-environments` package to develop your bot. If you plan to not use Jupyter Notebooks or any other programming language, please see our [Github](https:\/\/github.com\/Lux-AI-Challenge\/Lux-Design-2021). The following are some important links!\n\n- Competition Page: https:\/\/www.kaggle.com\/c\/lux-ai-2021\/\n\n- Online Visualizer: https:\/\/2021vis.lux-ai.org\/\n\n- Specifications: https:\/\/www.lux-ai.org\/specs-2021\n\n- Github: https:\/\/github.com\/Lux-AI-Challenge\/Lux-Design-2021\n\n- Bot API: https:\/\/github.com\/Lux-AI-Challenge\/Lux-Design-2021\/tree\/master\/kits\n\nAnd if you haven't done so already, we **highly recommend** you join our Discord server at https:\/\/discord.gg\/aWJt3UAcgn or at the minimum follow the kaggle forums at https:\/\/www.kaggle.com\/c\/lux-ai-2021\/discussion. We post important announcements there such as changes to rules, events, and opportunities from our sponsors!\n\nNow let's get started!\n\n## Prerequisites\n\nWe assume that you have a basic knowledge of Python and programming. It's okay if you don't know the game specifications yet! Feel free to always refer back to https:\/\/www.lux-ai.org\/specs-2021.\n\n## Basic Setup\n\nFirst thing to verify is that you have **Node.js v12 or above**. The engine for the competition runs on Node.js (for many good reasons including an awesome visualizer) and thus it is required. You can download it [here](https:\/\/nodejs.org\/en\/download\/). You can then verify you have the appropriate version by running\n","7fdbd14e":"We will also need Kaggle Environments","63ed2cbd":"Ok so woah, what just happened? We just ran a match, that's what :)\n\nThere's a number of quality of life features in the visualizer, which you can also find embedded on the kaggle competition page when watching replays or on the online visualizer when using replay files. \n\nIf you find this replay viewer slow, you can also download a local copy of this replay viewer in addition to lowering the graphics quality, see https:\/\/github.com\/Lux-AI-Challenge\/LuxViewer2021 for instructions.\n\nAt this point, we recommend reading the [game specifications](https:\/\/www.lux-ai.org\/specs-2021) a bit more to understand how to build a bot that tries to win the game.","6c3c01b5":"## CLI Tool\n\nThere's a separate CLI tool that can also be used to run matches. It's recommended for Jupyter Notebook users to stick with just this notebook, and all other users including python users to follow the instructions on https:\/\/github.com\/Lux-AI-Challenge\/Lux-Design-2021\n\nThe other benefit however of using the CLI tool is that it generates much smaller, \"stateless\" replays and also lets you run a mini leaderboard on multiple bots ranked by various ranking algorithms","a8e9eb5d":"Ok now that our agent finds and collects resources but our citytile was consumed by darkness! What now? Well units can only carry so much resources before they can't collect anymore. And to keep your City alive, you must move your unit on top of any CityTile that is in that City. (Recall that a City is composed of connected CityTiles)","4fdbd86b":"Unfortunately it's not that easy. This agent will eventually lose and all units and cities will fall to darkness! We will need to write something to help the agent first find resources and then collect them.\n\nLet's first run a game with our empty agent, which will populate the `game_state` variable and we can now work with it and look into how we would proceed with finding resources.","43e620b8":"## Additional things to check out\n\nMake sure you check out the Bot API at https:\/\/github.com\/Lux-AI-Challenge\/Lux-Design-2021\/tree\/master\/kits\n\nThis documents what you can do using the starter kit files in addition to telling you how to use the annotation debug commands that let you annotate directly on a replay (draw lines, circle things etc.)\n\nYou can also run the following below to save a episode to a JSON replay file. These are the same as what is shown on the leaderbaord and you can upload the replay files to the online replay viewer https:\/\/2021vis.lux-ai.org\/\n\n\nFor a local (faster) version of the replay viewer, follow installation instructions here https:\/\/github.com\/Lux-AI-Challenge\/Lux-Viewer-2021","13a2c94f":"## Building from Scratch\n\nThe following bit of code is all you need for a empty agent that does nothing","5a43881b":"Ok now that we have code to find resources closest to a given position, lets code our agent to use this and tell its units to go to the closest resource and mine them! We can copy our empty agent code and add a loop that loops over all our units and make them move towards the resources","4bb3f9ff":"We have something that survives! We are now ready to submit something to the leaderboard. The code below compiles all we have built so far into one file that you can then submit to the competition leaderboard"}}