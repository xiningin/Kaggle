{"cell_type":{"27518a75":"code","6d3bb4e4":"code","498bdf17":"code","12824bc5":"code","e4ebabba":"code","fd124dd5":"code","c8f0a502":"code","287163c1":"code","54264e34":"code","f5253a5e":"code","a606674f":"code","eb918bf5":"code","4a6121e4":"code","258a376a":"code","5f749c7b":"code","006a33cd":"code","4942fb2b":"code","125c2bcf":"code","1d714352":"code","febdc5fe":"code","a6116110":"code","83b5c794":"code","3e9aef2b":"code","16502433":"code","48fc65f7":"code","b2583023":"markdown","4bff0b26":"markdown","c0f41d06":"markdown","2771840b":"markdown","674c64d8":"markdown","0bcdd30d":"markdown","650801da":"markdown","5c7596fc":"markdown","5112ba52":"markdown","f762e2f3":"markdown","4a235160":"markdown","930735c9":"markdown","0887d74b":"markdown","39ee30bc":"markdown","34a4e7a0":"markdown","c2f0d5cc":"markdown","21eec658":"markdown","8aeed375":"markdown","db364c10":"markdown","f8adb28f":"markdown"},"source":{"27518a75":"!pip install -q -U pip\n!pip install -q neptune-client","6d3bb4e4":"import os\nimport math\nimport time\nimport random\n\nimport yaml\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport albumentations as A\nimport torch\nfrom torch.utils import data as torch_data\nfrom torch import nn as torch_nn\nfrom torch.nn import functional as torch_functional\nimport torchvision\nfrom sklearn import metrics as sk_metrics\nfrom sklearn import model_selection as sk_model_selection\nimport neptune","498bdf17":"def load_neptune_config(config_path):\n    \"\"\"\n    Load info about neptune from .yaml file with the next format:\n    \n    api_token: <your secret token from neptune>\n    project_qualified_name: <your neptune project name>\n    \n    \"\"\"\n    with open(config_path) as file:\n        neptune_config = yaml.load(file, Loader=yaml.FullLoader)\n    return neptune_config\n\n\nneptune_config = load_neptune_config(\"..\/input\/neptune-config\/config.yaml\")","12824bc5":"config = {\n    \"seed\": 42,\n    \n    \"valid_size\": 0.3,\n    \"image_size\": (512, 512),\n    \n    \"train_batch_size\": 4,\n    \"valid_batch_size\": 1,\n    \"test_batch_size\": 1,\n    \n    \"model\": \"mobilenet_v2\",\n    \n    \"max_epochs\": 50,\n    \"model_save_path\": \"model-best.torch\",\n    \"patience_stop\": 3,\n    \n    \"optimizer\": \"adam\",\n    \"adam_lr\": 0.0001,\n    \n    \"criterion\": \"cross_entropy\",\n}\n\nneptune_settings = {\n    \"active\": True,\n    \"log_images\": True,\n    \"log_artifacts\": False, # set True to save model weights\n}\n\nif neptune_settings[\"active\"]:\n    \n    neptune.init(\n        api_token=neptune_config[\"api_token\"], \n        project_qualified_name=neptune_config[\"project_qualified_name\"],\n    )\n\n    neptune.create_experiment(\n        name=f\"{config['model']}_experiment\",\n        params=config,\n        upload_source_files=os.listdir(os.getcwd()),\n    )\n\n    neptune.append_tag(\"data-version: 20\")","e4ebabba":"# The directory to the dataset\nBASE_DIR = '..\/input\/lego-minifigures-classification\/'\nPATH_INDEX = os.path.join(BASE_DIR, \"index.csv\")\nPATH_TEST = os.path.join(BASE_DIR, \"test.csv\")\nPATH_METADATA = os.path.join(BASE_DIR, \"metadata.csv\")","fd124dd5":"# Try to set random seet that our experiment repeated between (We have some problem to set seed with GPU)\ndef set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n\nset_seed(config[\"seed\"])","c8f0a502":"# Read information about dataset\ndf = pd.read_csv(PATH_INDEX)\n\ntmp_train, tmp_valid = sk_model_selection.train_test_split(\n    df, \n    test_size=config[\"valid_size\"], \n    random_state=config[\"seed\"], \n    stratify=df['class_id'],\n)\n\n\ndef get_paths_and_targets(tmp_df):\n    # Get file paths\n    paths = tmp_df[\"path\"].values\n    # Create full paths (base dir + concrete file name)\n    paths = list(\n        map(\n            lambda x: os.path.join(BASE_DIR, x), \n            paths\n        )\n    )\n    # Get labels\n    targets = tmp_df[\"class_id\"].values\n    \n    return paths, targets\n\n\n# Get train file paths and targets\ntrain_paths, train_targets = get_paths_and_targets(tmp_train)\n\n# Get valid file paths and targets\nvalid_paths, valid_targets = get_paths_and_targets(tmp_valid)\n\ndf_test = pd.read_csv(PATH_TEST)\n# Get test file paths and targets\ntest_paths, test_targets = get_paths_and_targets(df_test)","287163c1":"# Calculate the total number of classes in the dataset (len of unique labels in data)\ndf_metadata = pd.read_csv(PATH_METADATA)\nn_classes = df_metadata.shape[0]\nprint(\"Number of classes: \", n_classes)","54264e34":"class DataRetriever(torch_data.Dataset):\n    def __init__(\n        self, \n        paths, \n        targets, \n        image_size,\n        transforms=None,\n        preprocess=None,\n    ):\n        self.paths = paths\n        self.targets = targets\n        self.image_size = image_size\n        self.transforms = transforms\n        self.preprocess = preprocess\n          \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, index):\n        img = cv2.imread(self.paths[index])\n        img = cv2.resize(img, self.image_size)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        if self.preprocess:\n            img = self.preprocess(img)\n        \n        y = torch.tensor(self.targets[index] - 1, dtype=torch.long)\n            \n        return {'X': img, 'y': y}","f5253a5e":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.Rotate(limit=30, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=20, max_w_size=20, fill_value=0, p=0.25),\n            A.Cutout(num_holes=8, max_h_size=20, max_w_size=20, fill_value=1, p=0.25),\n            A.HorizontalFlip(p=0.5),\n            A.RandomContrast(limit=(-0.3, 0.3), p=0.5),\n            A.RandomBrightness(limit=(-0.4, 0.4), p=0.5),\n            A.Blur(p=0.25),\n        ], \n        p=1.0\n    )\n\ndef get_preprocess():\n    return torchvision.transforms.Compose(\n        [\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225]\n            ),\n        ]\n    )","a606674f":"train_data_retriever = DataRetriever(\n    train_paths, \n    train_targets, \n    image_size=config[\"image_size\"],\n    transforms=get_train_transforms(),\n    preprocess=get_preprocess(),\n)\n\nvalid_data_retriever = DataRetriever(\n    valid_paths, \n    valid_targets, \n    image_size=config[\"image_size\"],\n    preprocess=get_preprocess(),\n)\n\ntest_data_retriever = DataRetriever(\n    test_paths, \n    test_targets, \n    image_size=config[\"image_size\"],\n    preprocess=get_preprocess(),\n)","eb918bf5":"train_loader = torch_data.DataLoader(\n    train_data_retriever,\n    batch_size=config[\"train_batch_size\"],\n    shuffle=True,\n)\n\nvalid_loader = torch_data.DataLoader(\n    valid_data_retriever, \n    batch_size=config[\"valid_batch_size\"],\n    shuffle=False,\n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever, \n    batch_size=config[\"test_batch_size\"],\n    shuffle=False,\n)","4a6121e4":"def denormalize_image(image):\n    return image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n\n# Let's visualize some batches of the train data\nfig = plt.figure(figsize=(16, 16))\nfor i_batch, batch in enumerate(train_loader):\n    images, labels = batch[\"X\"], batch[\"y\"]\n    for i in range(len(images)):\n        plt.subplot(4, 4, 4 * i_batch + i + 1)\n        plt.imshow(denormalize_image(images[i].permute(1, 2, 0).numpy()))\n        plt.title(labels[i].numpy())\n        plt.axis(\"off\")\n    if i_batch >= 3:\n        break\n        \nif neptune_settings[\"active\"] and neptune_settings[\"log_images\"]:\n    neptune.log_image(\"data-examples\", fig)","258a376a":"# Let's visualize some batches of the train data\nfig = plt.figure(figsize=(16, 16))\nfor i_batch, batch in enumerate(valid_loader):\n    images, labels = batch[\"X\"], batch[\"y\"]\n    plt.subplot(4, 4, i_batch + 1)\n    plt.imshow(denormalize_image(images[0].permute(1, 2, 0).numpy()))\n    plt.title(labels[0].numpy())\n    plt.axis(\"off\")\n    if i_batch >= 15:\n        break\n        \nif neptune_settings[\"active\"] and neptune_settings[\"log_images\"]:\n    neptune.log_image(\"data-examples\", fig)","5f749c7b":"def init_model_mobilenet_v2(n_classes):\n    net = torch.hub.load(\"pytorch\/vision:v0.6.0\", \"mobilenet_v2\", pretrained=True)\n    net.classifier = torch_nn.Linear(\n        in_features=1280, \n        out_features=n_classes, \n        bias=True,\n    )\n    return net\n\ndef init_model_resnet18(n_classes):\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet18', pretrained=True)\n    net.classifier = torch_nn.Linear(\n        in_features=512, \n        out_features=n_classes, \n        bias=True,\n    )\n    return net\n\ndef init_model_resnet101(n_classes):\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'resnet101', pretrained=True)\n    net.classifier = torch_nn.Linear(\n        in_features=2048, \n        out_features=n_classes, \n        bias=True,\n    )\n    return net\n\ndef init_model_vgg16(n_classes):\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'vgg16', pretrained=True)\n    net.classifier[6] = torch_nn.Linear(\n        in_features=4096, \n        out_features=n_classes, \n        bias=True,\n    )\n    return net\n\ndef init_model_resnext50_32x4d(n_classes):\n    net = torch.hub.load('pytorch\/vision:v0.6.0', 'resnext50_32x4d', pretrained=True)\n    net.classifier = torch_nn.Linear(\n        in_features=2048, \n        out_features=n_classes, \n        bias=True,\n    )\n    return net","006a33cd":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy().argmax(axis=1).astype(int)\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count \/ self.n + last_n \/ self.n * self.avg","4942fb2b":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n    \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n        history = {\n            \"train_loss\": [],\n            \"train_score\": [],\n            \"valid_loss\": [],\n            \"valid_score\": [],\n        }\n        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            history[\"train_loss\"].append(train_loss)\n            history[\"train_score\"].append(train_score)\n            history[\"valid_loss\"].append(valid_loss)\n            history[\"valid_score\"].append(valid_score)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            if neptune_settings[\"active\"]:\n                neptune.log_metric(f'train_loss', train_loss)\n                neptune.log_metric(f'train_accuracy', train_score)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n            if neptune_settings[\"active\"]:\n                neptune.log_metric(f'valid_loss', valid_loss)\n                neptune.log_metric(f'valid_accuracy', valid_score)\n            \n            if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n        \n        return history\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            images = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n\n            self.optimizer.step()\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                images = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(images)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n        \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            save_path,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","125c2bcf":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif config[\"model\"] == \"mobilenet_v2\":\n    model = init_model_mobilenet_v2(n_classes)\nelif config[\"model\"] == \"resnet18\":\n    model = init_model_resnet18(n_classes)\nelif config[\"model\"] == \"resnet101\":\n    model = init_model_resnet101(n_classes)\nelif config[\"model\"] == \"vgg16\":\n    model = init_model_vgg16(n_classes)\nelif config[\"model\"] == \"resnext50_32x4d\":\n    model = init_model_resnext50_32x4d(n_classes)\n    \nmodel.to(device)\n\nif config[\"optimizer\"] == \"adam\":\n    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"adam_lr\"])\n\nif config[\"criterion\"] == \"cross_entropy\":\n    criterion = torch_functional.cross_entropy\n\ntrainer = Trainer(\n    model, \n    device, \n    optimizer, \n    criterion, \n    LossMeter, \n    AccMeter\n)\n\nhistory = trainer.fit(\n    config[\"max_epochs\"], \n    train_loader, \n    valid_loader, \n    config[\"model_save_path\"], \n    config[\"patience_stop\"],\n)\n\nif neptune_settings[\"active\"] and neptune_settings[\"log_artifacts\"]:\n    neptune.log_artifact(config[\"model_save_path\"])","1d714352":"# Visualize train and valid loss \nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(history['train_loss'], label='train loss')\nplt.plot(history['valid_loss'], label='valid loss')\nplt.xticks(fontsize=14)\nplt.xlabel(\"Epoch number\", fontsize=15)\nplt.yticks(fontsize=14)\nplt.ylabel(\"Loss value\", fontsize=15)\nplt.legend(fontsize=15)\nplt.grid()\n\n# Visualize train and valid accyracy \nplt.subplot(1, 2, 2)\nplt.plot(history['train_score'], label='train acc')\nplt.plot(history['valid_score'], label='valid acc')\nplt.xticks(fontsize=14)\nplt.xlabel(\"Epoch number\", fontsize=15)\nplt.yticks(fontsize=14)\nplt.ylabel(\"Accuracy score\", fontsize=15)\nplt.legend(fontsize=15)\nplt.grid();","febdc5fe":"# Load the best model\ncheckpoint = torch.load(config[\"model_save_path\"])\n\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\noptimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\nbest_valid_score = checkpoint[\"best_valid_score\"]\nn_epoch = checkpoint[\"n_epoch\"]\n\nmodel.eval()\n\nprint(f\"Best model valid score: {best_valid_score} ({n_epoch} epoch)\")","a6116110":"# Save the model predictions and true labels\ny_pred = []\ny_test = []\nfor batch in test_loader:\n    y_pred.extend(model(batch['X'].to(device)).argmax(axis=-1).cpu().numpy())\n    y_test.extend(batch['y'])\n\n# Calculate needed metrics\ntest_accuracy = sk_metrics.accuracy_score(y_test, y_pred)\ntest_f1_macro = sk_metrics.f1_score(y_test, y_pred, average=\"macro\")\n\nprint(f\"Accuracy score on test data:\\t{test_accuracy}\")\nprint(f\"Macro F1 score on test data:\\t{test_f1_macro}\")\n\nif neptune_settings[\"active\"]:\n    neptune.log_metric(f'test_accuracy', test_accuracy)\n    neptune.log_metric(f'test_f1_macro', test_f1_macro)","83b5c794":"# Load metadata to get classes people-friendly names\nlabels = df_metadata['minifigure_name'].tolist()\n\n# Calculate confusion matrix\nconfusion_matrix = sk_metrics.confusion_matrix(y_test, y_pred)\n# confusion_matrix = confusion_matrix \/ confusion_matrix.sum(axis=1)\ndf_confusion_matrix = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n\n# Show confusion matrix\nfig = plt.figure(figsize=(12, 12))\nsn.heatmap(df_confusion_matrix, annot=True, cbar=False, cmap='Oranges', linewidths=1, linecolor='black')\nplt.xlabel('Predicted labels', fontsize=15)\nplt.xticks(fontsize=12)\nplt.ylabel('True labels', fontsize=15)\nplt.yticks(fontsize=12)\n\nif neptune_settings[\"active\"] and neptune_settings[\"log_images\"]:\n    neptune.log_image('error-analysis', fig)","3e9aef2b":"error_images = []\nerror_label = []\nerror_pred = []\nerror_prob = []\nfor batch in test_loader:\n    _X_test, _y_test = batch['X'], batch['y']\n    pred = torch.softmax(model(_X_test.to(device)), axis=-1).detach().cpu().numpy()\n    pred_class = pred.argmax(axis=-1)\n    if pred_class != _y_test.cpu().numpy():\n        error_images.extend(_X_test)\n        error_label.extend(_y_test)\n        error_pred.extend(pred_class)\n        error_prob.extend(pred.max(axis=-1))","16502433":"fig = plt.figure(figsize=(16, 16))\nfor ind, image in enumerate(error_images):\n    plt.subplot(math.ceil(len(error_images) \/ int(len(error_images) ** 0.5)), int(len(error_images) ** 0.5), ind + 1)\n    plt.imshow(denormalize_image(image.permute(1, 2, 0).numpy()))\n    plt.title(f\"Predict: {labels[error_pred[ind]]} ({error_prob[ind]:.2f}) Real: {labels[error_label[ind]]}\")\n    plt.axis(\"off\")\n\nif neptune_settings[\"active\"] and neptune_settings[\"log_images\"]:\n    neptune.log_image(\"error-analysis\", fig)","48fc65f7":"if neptune_settings[\"active\"]:\n    neptune.stop()","b2583023":"<a id=\"11\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Model training<center><h2>","4bff0b26":"<a id=\"13\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Error analysis - Confusion matrix<center><h2>","c0f41d06":"![](https:\/\/i.imgur.com\/4cPQlEN.jpg)","2771840b":"<a id=\"14\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Error analysis - Misclassified samples<center><h2>","674c64d8":"We need to turn internet on to install client for Neptune.ai","0bcdd30d":"<a id=\"5\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Train and valid retrievers<center><h2>","650801da":"<a id=\"9\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Loss and metric calculating classes<center><h2>","5c7596fc":"## We use simple MobileNetV2 model as a backbone","5112ba52":"<a id=\"4\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Augmentations<center><h2>","f762e2f3":"<a id=\"3\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Data sample retriever class<center><h2>","4a235160":"<a id=\"8\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Model creating class<center><h2>","930735c9":"For using Neptune.ai you need to specify special token (you can get it from the Neptune client).   \nFor security reasons we need to create private dataset and set there our secret token and project name as in the client on Neptune.   \nFor example we can create neptune-config dataset and specify config.yaml there","0887d74b":"<a id=\"10\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Model training class<center><h2>","39ee30bc":"<a id=\"1\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Configurations<center><h2>","34a4e7a0":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [1. Configurations](#1)\n* [2. Data reading](#2)\n* [3. Data sample retriever class](#3)\n* [4. Augmentations](#4)\n* [5. Train and valid retrievers](#5)   \n* [6. Batch train and valid data loaders](#6)\n* [7. Data visualizations](#7)\n* [8. Model creating class](#8)\n* [9. Loss and metric calculating classes](#9)\n* [10. Model training class](#10)\n* [11. Model training](#11)\n* [12. Final validation check](#12)\n* [13. Error analysis - Confusion matrix](#13)\n* [14. Error analysis - Misclassified samples](#14)\n","c2f0d5cc":"# PyTorch Modeling for [LEGO Minifigures Classification](https:\/\/www.kaggle.com\/ihelon\/lego-minifigures-classification) dataset\n\nThis is the guide about using pretrained models in **PyTorch** and logging experiments with [**Neptune.ai**](https:\/\/neptune.ai\/).   \nWe will use MobileNetV2 model (with options to change the base model) to predict which Lego Figure is in the image.\n","21eec658":"<a id=\"12\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Final validation check<center><h2>","8aeed375":"<a id=\"6\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Batch train and valid data loaders<center><h2>","db364c10":"<a id=\"7\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Data visualizations<center><h2>","f8adb28f":"<a id=\"2\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>Data reading<center><h2>"}}