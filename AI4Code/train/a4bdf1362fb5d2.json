{"cell_type":{"70502be7":"code","a44c6f80":"code","53f08b3c":"code","c56248cb":"code","b8350601":"code","b6704b49":"code","d2703317":"code","4dada39e":"code","e9cd3303":"code","561a8b54":"code","60ccfb01":"code","820362c4":"code","3f63bb57":"code","aba7b70b":"code","d8bb3677":"code","ac20951d":"code","3bf0d5d7":"code","87a9e506":"code","81db0c3f":"code","ef95f06f":"code","daf95647":"code","edfb54ae":"markdown","bfee8cdd":"markdown","5f7d12a6":"markdown","4df47d03":"markdown","8e519f58":"markdown","dc01faad":"markdown"},"source":{"70502be7":"# Importing the librares\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout","a44c6f80":"# Reading the dataset file\ndataset = pd.read_csv('..\/input\/mechanical-properties-of-low-alloy-steels\/MatNavi Mechanical properties of low-alloy steels.csv')\ncolumns = list(dataset.columns)\n\nprint(dataset.head())   # Print first 5 rows of dataset\nprint(\"\\n\")\nprint(*columns, sep=' | ')\nprint(\"\\n\")","53f08b3c":"corr = dataset.corr()\nplt.subplots(figsize=(20,15))\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True)","c56248cb":"# x includes all the input features including the composition of the alloy and temperature\n# y includes the mechanical properties of the alloy which are to be predicted by the model\nx = dataset.iloc[:, 1:16].values\ny = dataset.iloc[:, 16:].values\n\n# Making the train test split\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, shuffle = True, random_state = 2)","b8350601":"# Scaling down the inputs and outputs\n# Scaling method used here is : scaled_value = (x - mean)\/(std_dev) \n\nsc_x = StandardScaler()\nsc_x.fit(x_train)\nx_train_sc = sc_x.transform(x_train)\nx_test_sc = sc_x.transform(x_test)\n\nsc_y = StandardScaler()\nsc_y.fit(y_train)\ny_train_sc = sc_y.transform(y_train)\ny_test_sc = sc_y.transform(y_test)\n\n#    ______________________________________________\n#   |  Scaled Variables    |   Unscaled Variables  |\n#   |______________________|_______________________|\n#   |    x_train_sc        |       x_train         | \n#   |    x_test_sc         |       x_test          |\n#   |    y_train_sc        |       y_train         | \n#   |    y_test_sc         |       y_test          | \n#   |    y_rf_pred_sc      |       y_rf_pred       |\n#   |    y_nn_pred_sc      |       y_nn_pred       |\n#   |______________________|_______________________|","b6704b49":"# To be used later while visualizing results\nactual_proof_strength = np.transpose(y_test)[0]\nactual_tensile_strength = np.transpose(y_test)[1]\nactual_pct_elongation = np.transpose(y_test)[2]\nactual_pct_reduction_area = np.transpose(y_test)[3]","d2703317":"# Building the Neural Network\n\nmodel = Sequential()\nmodel.add(Dense(units = 15, kernel_initializer = 'normal', activation = 'tanh', input_dim = 15))\nmodel.add(Dense(units = 30, kernel_initializer = 'normal', activation = 'tanh'))\nmodel.add(Dense(units = 45, kernel_initializer = 'normal', activation = 'tanh'))\nmodel.add(Dense(units = 40, kernel_initializer = 'normal', activation = 'tanh'))\nmodel.add(Dense(units = 30, kernel_initializer = 'normal', activation = 'tanh'))\nmodel.add(Dense(units = 20, kernel_initializer = 'normal', activation = 'tanh'))\nmodel.add(Dense(units = 10, kernel_initializer = 'normal', activation = 'tanh'))\nmodel.add(Dense(units = 4, kernel_initializer = 'normal', activation = 'tanh'))\n\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mean_squared_error'])","4dada39e":"# Training the model and predicting the results\nhistory = model.fit(x_train_sc, y_train_sc, batch_size = 256, shuffle=True, epochs = 2000)\ny_nn_pred_sc = model.predict(x_test_sc)","e9cd3303":"# Determining the model's accuracy\nr2_nn = r2_score(y_test_sc, y_nn_pred_sc)\nmse_nn = mean_squared_error(y_test_sc, y_nn_pred_sc)\nmae_nn = mean_absolute_error(y_test_sc, y_nn_pred_sc)\nprint('R\\u00b2_score = ' + str(round(r2_nn, 2)) + '              Higher is better')\nprint('mean_squared_error = ' + str(round(mse_nn, 2)) + '    Lower is better')\nprint('mean_absolute_error = ' + str(round(mae_nn, 2)) + '   Lower is better')","561a8b54":"# Visualizing the model's learning history\nplt.figure(figsize=(10, 6))\nplt.plot(history.history['mean_squared_error'])\nplt.title('Model Error', fontsize=20)\nplt.ylabel('Mean Squared Error', fontsize=14)\nplt.xlabel('Number of Epochs', fontsize=14)\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","60ccfb01":"# Scaling up the outputs back to original\ny_nn_pred = sc_y.inverse_transform(y_nn_pred_sc)\n\n# Visualizing the accuracy of predicted values\nnn_predicted_proof_strength = np.transpose(y_nn_pred)[0]\nnn_predicted_tensile_strength = np.transpose(y_nn_pred)[1]\nnn_predicted_pct_elongation = np.transpose(y_nn_pred)[2]\nnn_predicted_pct_reduction_area = np.transpose(y_nn_pred)[3]","820362c4":"# Plotting graphs for 0.2% Proof Strength and Tensile Strength\nfig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,7))\n\nax0.scatter(nn_predicted_proof_strength, actual_proof_strength, color = 'hotpink', s=18)\nx3 = np.linspace(0, 800, 1000)\ny3 = x3\nax0.plot(x3, y3)\nax0.set_title('0.2% Proof Strength', fontsize = 20)\nax0.set_xlabel('predicted_proof_strength', fontsize = 14)\nax0.set_ylabel('actual_proof_strength', fontsize = 14)\n\nax1.scatter(nn_predicted_tensile_strength, actual_tensile_strength, color = 'hotpink', s=18)\nx4 = np.linspace(100, 900, 1000)\ny4 = x4\nax1.plot(x4, y4)\nax1.set_title('Tensile Strength', fontsize = 20)\nax1.set_xlabel('predicted_tensile_strength', fontsize = 14)\nax1.set_ylabel('actual_tensile_strength', fontsize = 14)\n\nplt.show()","3f63bb57":"# Plotting graphs for % Elongation and % Reduction in Area\nfig, (ax2,ax3) = plt.subplots(1,2,figsize=(16,7))\n\nax2.scatter(nn_predicted_pct_elongation, actual_pct_elongation, color = 'hotpink', s=18)\nx3 = np.linspace(0, 60, 1000)\ny3 = x3\nax2.plot(x3, y3)\nax2.set_title('% Elongation', fontsize = 20)\nax2.set_xlabel('predicted_pct_elongation', fontsize = 14)\nax2.set_ylabel('actual_pct_elongation', fontsize = 14)\n\nax3.scatter(nn_predicted_pct_reduction_area, actual_pct_reduction_area, color = 'hotpink', s=18)\nx4 = np.linspace(20, 100, 1000)\ny4 = x4\nax3.plot(x4, y4)\nax3.set_title('% Reducton in Area', fontsize = 20)\nax3.set_xlabel('predicted_pct_reduction_area', fontsize = 14)\nax3.set_ylabel('actual_pct_reduction_area', fontsize = 14)\n\nplt.show()","aba7b70b":"# r2_score for each mechanical property\nr2_proof_strength_nn = r2_score(actual_proof_strength, nn_predicted_proof_strength)\nr2_tensile_strength_nn = r2_score(actual_tensile_strength, nn_predicted_tensile_strength)\nr2_pct_elongation_nn = r2_score(actual_pct_elongation, nn_predicted_pct_elongation)\nr2_pct_reduction_area_nn = r2_score(actual_pct_reduction_area, nn_predicted_pct_reduction_area)\nprint('R\\u00b2_score for 0.2% Proof Strength = ' + str(round(r2_proof_strength_nn, 2)))\nprint('R\\u00b2_score for Tensile strength    = ' + str(round(r2_tensile_strength_nn, 2)))\nprint('R\\u00b2_score for % Elongation        = ' + str(round(r2_pct_elongation_nn, 2)))\nprint('R\\u00b2_score for % Reduction in Area = ' + str(round(r2_pct_reduction_area_nn, 2)))","d8bb3677":"# Random Forest Regressor\nregressor = RandomForestRegressor(n_estimators=100, criterion='mse')\nregressor.fit(x_train_sc, y_train_sc)\ny_rf_pred_sc = regressor.predict(x_test_sc)\n\n# Calculating accuracy metrics\nr2_rf = r2_score(y_test_sc, y_rf_pred_sc)\nmse_rf = mean_squared_error(y_test_sc, y_rf_pred_sc)\nmae_rf = mean_absolute_error(y_test_sc, y_rf_pred_sc)\n\n# Printing the results\nprint('R\\u00b2_score = ' + str(round(r2_rf, 2)) + '              Higher is better')\nprint('mean_squared_error = ' + str(round(mse_rf, 2)) + '    Lower is better')\nprint('mean_absolute_error = ' + str(round(mae_rf, 2)) + '   Lower is better')","ac20951d":" # Scaling up the inputs\ny_rf_pred = sc_y.inverse_transform(y_rf_pred_sc)\n\n# Visualizing the accuracy of predicted results\nrf_predicted_proof_strength = np.transpose(y_rf_pred)[0]\nrf_predicted_tensile_strength = np.transpose(y_rf_pred)[1]\nrf_predicted_pct_elongation = np.transpose(y_rf_pred)[2]\nrf_predicted_pct_reduction_area = np.transpose(y_rf_pred)[3]","3bf0d5d7":"# Plotting graphs for 0.2% Proof Strength and Tensile Strength\nfig, (ax4,ax5) = plt.subplots(1,2,figsize=(16,7))\n\nax4.scatter(rf_predicted_proof_strength, actual_proof_strength, color = 'hotpink', s=18)\nx3 = np.linspace(0, 800, 1000)\ny3 = x3\nax4.plot(x3, y3)\nax4.set_title('0.2% Proof Strength', fontsize = 20)\nax4.set_xlabel('predicted_proof_strength', fontsize = 14)\nax4.set_ylabel('actual_proof_strength', fontsize = 14)\n\nax5.scatter(rf_predicted_tensile_strength, actual_tensile_strength, color = 'hotpink', s=18)\nx4 = np.linspace(100, 900, 1000)\ny4 = x4\nax5.plot(x4, y4)\nax5.set_title('Tensile Strength', fontsize = 20)\nax5.set_xlabel('predicted_tensile_strength', fontsize = 14)\nax5.set_ylabel('actual_tensile_strength', fontsize = 14)\n\nplt.show()","87a9e506":"# Plotting graphs for % Elongation and % Reduction in Area\nfig, (ax6,ax7) = plt.subplots(1,2,figsize=(16,7))\n\nax6.scatter(rf_predicted_pct_elongation, actual_pct_elongation, color = 'hotpink', s=18)\nx3 = np.linspace(0, 60, 1000)\ny3 = x3\nax6.plot(x3, y3)\nax6.set_title('% Elongation', fontsize = 20)\nax6.set_xlabel('predicted_pct_elongation', fontsize = 14)\nax6.set_ylabel('actual_pct_elongation', fontsize = 14)\n\nax7.scatter(rf_predicted_pct_reduction_area, actual_pct_reduction_area, color = 'hotpink', s=18)\nx4 = np.linspace(20, 100, 1000)\ny4 = x4\nax7.plot(x4, y4)\nax7.set_title('% Reducton in Area', fontsize = 20)\nax7.set_xlabel('predicted_pct_reduction_area', fontsize = 14)\nax7.set_ylabel('actual_pct_reduction_area', fontsize = 14)\n\nplt.show()","81db0c3f":"# r2_score for each mechanical property\nr2_proof_strength_rf = r2_score(actual_proof_strength, rf_predicted_proof_strength)\nr2_tensile_strength_rf = r2_score(actual_tensile_strength, rf_predicted_tensile_strength)\nr2_pct_elongation_rf = r2_score(actual_pct_elongation, rf_predicted_pct_elongation)\nr2_pct_reduction_area_rf = r2_score(actual_pct_reduction_area, rf_predicted_pct_reduction_area)\nprint('R\\u00b2_score for 0.2% Proof Strength = ' + str(round(r2_proof_strength_rf, 2)))\nprint('R\\u00b2_score for Tensile strength    = ' + str(round(r2_tensile_strength_rf, 2)))\nprint('R\\u00b2_score for % Elongation        = ' + str(round(r2_pct_elongation_rf, 2)))\nprint('R\\u00b2_score for % Reduction in Area = ' + str(round(r2_pct_reduction_area_rf, 2)))","ef95f06f":"fig= plt.figure(figsize=(15,8))\nX = ['r2_score', 'mse', 'mae']\nnn = [r2_nn, mse_nn, mae_nn]\nrf = [r2_rf, mse_rf, mae_rf]\n  \nX_axis = np.arange(len(X))\n  \nplt.bar(X_axis - 0.2, nn, 0.4, label = 'Neural Network')\nplt.bar(X_axis + 0.2, rf, 0.4, label = 'Random Forest Regressor')\n  \nplt.xticks(X_axis, X, fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Metric\", fontsize=18)\nplt.ylabel(\"Value\", fontsize=18)\nplt.title(\"Comparision of both models\", fontsize=22)\nplt.legend(fontsize = 18)\nplt.grid()\nplt.show()","daf95647":"fig= plt.figure(figsize=(17,10))\nX = ['0.2% Proof Strength', 'Tensile Strength', '% Elongation', '% Reduction in Area']\nnn = [r2_proof_strength_nn, r2_tensile_strength_nn, r2_pct_elongation_nn, r2_pct_reduction_area_nn]\nrf = [r2_proof_strength_rf, r2_tensile_strength_rf, r2_pct_elongation_rf, r2_pct_reduction_area_rf]\n  \nX_axis = np.arange(len(X))\n  \nplt.bar(X_axis - 0.2, nn, 0.4, label = 'Neural Network')\nplt.bar(X_axis + 0.2, rf, 0.4, label = 'Random Forest Regressor')\n  \nplt.xticks(X_axis, X, fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Metric\", fontsize=18)\nplt.ylabel(\"Value\", fontsize=18)\nplt.title(\"Comparision of both models\", fontsize=22)\nplt.legend(fontsize = 18)\nplt.grid()\nplt.show()","edfb54ae":"# Conclusion\n \nThe random forest regressor performs better in each category and overall as compared to neural networks. Being computationally cheap to train, manually easer to fine-tune and highly versatile to fit itself on a complex data containing regressions within clusters, this model makes for an ideal choice for prediction of mechanical properties of low-alloy steels with R\u00b2 score of 0.91 which is significantly greater than R\u00b2 score of Neural Network which is 0.82","bfee8cdd":"# Random Forest Regression","5f7d12a6":"# Data Preprocessing","4df47d03":"# Comparing both the models","8e519f58":"# Regression using Neural Network","dc01faad":"##From above diagram following conclusions can be made:\n\n1.   Temperature has significant influence on % Elongation and % Reduction in area.\n2.   0.2% Proof Strength is highly influenced by presence of V, Ni, Mn, Mo, Ceq, Si, Al, Cr, C and Cu in decreasing order.\n3.   Tensile Strength is highly influenced by presence of V and moderately influenced by presence of Mo, Ni, Cr, C and Mn in decreasing order.\n4.   Tensile Strength is also highly related to 0.2% Proof Strength.\n5.   % Elongation and % Reduction in Area show maximum correlation with each other followed by temperature. \n6.   % Elongation is moderately influenced by presence of P and slightly influenced by presence of Al\n7.   % Reduction in Area is moderately influenced by presence of Al, Ceq, Si and Mn.\n\n"}}