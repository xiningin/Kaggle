{"cell_type":{"4783df9a":"code","fa15ec3b":"code","d7c3e081":"code","f85fd6ed":"code","d4a7c361":"code","cf199006":"code","78702c91":"code","60bd5aa6":"code","61c929dc":"code","b3afd405":"code","85047736":"code","e1788d4d":"code","0fb24b4c":"code","a64ad694":"code","681c9283":"code","19e42d38":"code","7da41147":"code","1a2515f2":"code","41de913a":"code","b8e3946e":"code","b7593340":"code","db627170":"code","2190ba07":"code","ae9c4a8e":"code","bbd7bef0":"code","c5ed85db":"code","08a0d4be":"code","c286487e":"code","d495e355":"code","8c3db9cb":"code","97e467e7":"code","e411d92a":"code","9b14e779":"code","783e21fa":"code","da37d67f":"code","296d41a3":"code","32181991":"code","8aa6f582":"code","18d11f4d":"code","7ced1c0a":"code","68de12c9":"code","b0765d7a":"code","deef8299":"code","9d28cb4f":"code","4e25ba0b":"code","8c04d796":"code","f04fa5b8":"code","2ebe1b9f":"code","26e00142":"code","86a5f7cf":"markdown","1d38025b":"markdown","0eb88e76":"markdown","894fbb84":"markdown","c1e50b0d":"markdown","39543300":"markdown","29badd9c":"markdown","7d19498b":"markdown","3cb78d65":"markdown","b8f0f1b6":"markdown","874f3049":"markdown","db5526be":"markdown","0f4f23d7":"markdown","eb74b3df":"markdown"},"source":{"4783df9a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa15ec3b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set()\n%matplotlib inline","d7c3e081":"pip install openpyxl","f85fd6ed":"train_data=pd.read_excel(r\"..\/input\/flight-price\/Data_Train.xlsx\")","d4a7c361":"pd.set_option('display.max_columns',None)","cf199006":"train_data.head(5)","78702c91":"train_data.columns","60bd5aa6":"train_data['Duration'].value_counts()","61c929dc":"train_data.isnull().sum()","b3afd405":"train_data.dropna(inplace=True)","85047736":"train_data.isnull().sum()","e1788d4d":"train_data['journey_day']=pd.to_datetime(train_data.Date_of_Journey,format=\"%d\/%m\/%Y\").dt.day\ntrain_data['journey_month']=pd.to_datetime(train_data.Date_of_Journey,format=\"%d\/%m\/%Y\").dt.month","0fb24b4c":"train_data.head()","a64ad694":"train_data['journey_year']=pd.to_datetime(train_data.Date_of_Journey,format=\"%d\/%m\/%Y\").dt.year","681c9283":"train_data.journey_year.nunique()","19e42d38":"train_data.drop(['journey_year',\"Date_of_Journey\"],inplace=True,axis=1)","7da41147":"train_data['dep_hour']=pd.to_datetime(train_data.Dep_Time).dt.hour\ntrain_data['dep_minute']=pd.to_datetime(train_data.Dep_Time).dt.minute","1a2515f2":"train_data.drop(\"Dep_Time\",inplace=True,axis=1)","41de913a":"train_data[\"Arrival_hour\"] = pd.to_datetime(train_data.Arrival_Time).dt.hour\ntrain_data[\"Arrival_min\"] = pd.to_datetime(train_data.Arrival_Time).dt.minute\ntrain_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)","b8e3946e":"train_data['Duration'][0].split()","b7593340":"duration = list(train_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2: \n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\" \n        else:\n            duration[i] = \"0h \" + duration[i]          \n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0])) \n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1])) ","db627170":"train_data['duration_hours']=duration_hours\ntrain_data['duration_mins']=duration_mins\ntrain_data.drop('Duration',axis=1,inplace=True)","2190ba07":"plt.figure(figsize=(30,5))\nsns.barplot(x='Airline',y='Price',data=train_data)","ae9c4a8e":"dummies =pd.get_dummies(train_data[[\"Airline\", \"Source\", \"Destination\"]],drop_first=True)\ntrain_data = train_data.drop([\"Airline\", \"Source\", \"Destination\"],axis=1)\ntrain_data= pd.concat([train_data,dummies],axis=1)","bbd7bef0":"train_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)","c5ed85db":"train_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)","08a0d4be":"train_data.shape","c286487e":"test_data = pd.read_excel(r\"..\/input\/flight-price\/Test_set.xlsx\")","d495e355":"test_data.head()","8c3db9cb":"# Preprocessing\ntest_data.dropna(inplace = True)\nprint(test_data.isnull().sum())\n\n# Date_of_Journey\ntest_data[\"journey_day\"] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day\ntest_data[\"journey_month\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format = \"%d\/%m\/%Y\").dt.month\ntest_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n\n# Dep_Time\ntest_data[\"dep_hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\ntest_data[\"dep_min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\ntest_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n\n# Arrival_Time\ntest_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\ntest_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\ntest_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n\n# Duration\nduration = list(test_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n\n# Adding Duration column to test set\ntest_data[\"duration_hours\"] = duration_hours\ntest_data[\"duration_mins\"] = duration_mins\ntest_data.drop([\"Duration\"], axis = 1, inplace = True)\n\n\n# Categorical data\ndummies =pd.get_dummies(test_data[[\"Airline\", \"Source\", \"Destination\"]],drop_first=True)\ntest_data = test_data.drop([\"Airline\", \"Source\", \"Destination\"],axis=1)\ntest_data= pd.concat([test_data,dummies],axis=1)\n\n\n# Additional_Info contains almost 80% no_info\n# Route and Total_Stops are related to each other\ntest_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n\n# Replacing Total_Stops\ntest_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n\nprint(\"Shape of test data : \", test_data.shape)\n\n","97e467e7":"X=train_data.drop('Price',axis=1)\ny=train_data.Price","e411d92a":"X.head()","9b14e779":"from sklearn.ensemble import ExtraTreesRegressor\nselection = ExtraTreesRegressor()\nselection.fit(X, y)","783e21fa":"#plot graph of feature importances for better visualization\n\nplt.figure(figsize = (14,7))\nimp_features= pd.Series(selection.feature_importances_, index=X.columns)\nimp_features.nlargest(20).plot(kind='barh')\nplt.show()","da37d67f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =101)","296d41a3":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(X_train, y_train)","32181991":"pred=rf.predict(X_test)","8aa6f582":"from sklearn.metrics import mean_absolute_error,mean_squared_error","18d11f4d":"print(mean_absolute_error(pred,y_test))","7ced1c0a":"rf.score(X_test,y_test)","68de12c9":"from sklearn.model_selection import RandomizedSearchCV","b0765d7a":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","deef8299":"# Create the random grid\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}","9d28cb4f":"# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf,\n                               param_distributions = random_grid,scoring='neg_mean_squared_error',\n                               n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","4e25ba0b":"rf_random.fit(X_train,y_train)","8c04d796":"rf_random.best_params_","f04fa5b8":"prediction = rf_random.predict(X_test)","2ebe1b9f":"y_prediction = rf_random.predict(X_test)","26e00142":"from sklearn import metrics\nmetrics.r2_score(y_test,prediction)","86a5f7cf":"### There are only two missing values , so drop these rows.","1d38025b":"### Converting categoerical features into numeric by using \"OneHot encoding\".","0eb88e76":"### Training the data.","894fbb84":"## Model Selection","c1e50b0d":"# Thank You for your time, Consider upvoting if you like my work.Happy kaggling!","39543300":"## Hyper parametric tuning using RandomizedSearchCV","29badd9c":"## After hyper parametric tuning, the score has increased bt 2% i.e from 82% to 84%.","7d19498b":"### Repeating the same for other features","3cb78d65":"### Check for missing values","b8f0f1b6":"### Journey year is unique so we can drop \"journey_year\" and \"Date_of_journey\"","874f3049":"### Splitting 'Date of journey' into two columns.","db5526be":"### Selecting most important features using \"ExtraTreeRegressor \"","0f4f23d7":"### Repeating he same for test data set.","eb74b3df":"### Converting \"Duration\" feature into numeric by the following function"}}