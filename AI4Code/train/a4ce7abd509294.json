{"cell_type":{"759dc6ac":"code","4915d569":"code","37de9dc3":"code","05f9d214":"code","32801c85":"code","e2bb65f7":"code","9daeeb97":"code","ca8ccb5f":"code","c1764c77":"code","e4728f8e":"code","b8131fd2":"code","c923a695":"code","b9743347":"code","2e7c2507":"code","d25aea12":"code","41aeeb74":"code","0da91386":"code","6877730f":"code","ea921093":"code","cde1af0f":"code","8f9fe695":"markdown","6102e862":"markdown","3ea70f16":"markdown"},"source":{"759dc6ac":"# DATA_PATH = '..\/input\/'\nDATA_PATH = '..\/input\/shopee-product-matching\/'","4915d569":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n\n#\u5229\u7528GPU\u7684\u5e93\n#torch GPU\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\n#\u8ba1\u7b97F1\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )#n\u4e3a\u4ea4\u53c9\u5546\u54c1\u4e2a\u6570\uff0c\u8ba1\u7b97\u6807\u7b7e\u4e0e\u76ee\u6807\u7ed3\u679c\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score","37de9dc3":"COMPUTE_CV = True\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\n\nif COMPUTE_CV:\n    train = pd.read_csv(DATA_PATH + 'train.csv')\n    train['image'] = DATA_PATH + 'train_images\/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\nelse:\n    train = pd.read_csv(DATA_PATH + 'test.csv')\n    train['image'] = DATA_PATH + 'test_images\/' + train['image']\n    train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n    \nprint('train shape is', train.shape )\ntrain.head()","05f9d214":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","32801c85":"if COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('CV score for baseline =',train.f1.mean())\n    #\u805a\u7c7b\u7ed3\u679c\u5305\u62ec\u81ea\u5df1\u7684\uff0c0.5 \u9700\u8981\u5927\u4e8e0.5","e2bb65f7":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\n#\u81ea\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u5bf9\u6240\u6709\u56fe\u7247\u8fdb\u884c\u8bfb\u53d6\n#d=ShopeeImageDataset()\n\nclass ShopeeImageDataset(Dataset):\n    def __init__(self, img_path, transform):\n        self.img_path = img_path\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n        img = self.transform(img)\n        return img\n    \n    def __len__(self):\n        return len(self.img_path)#\u6c42\u591a\u5c11\u4e2a","9daeeb97":"\nimagedataset = ShopeeImageDataset(\n    train['image'].values,#\u56fe\u7247\u8def\u5f84\n    transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),   #Pillow\u7c7b\u578b\uff0c\u8f6c\u6210tensor\u7c7b\u578b\uff0c\u77e9\u9635  255---\u300b0-1\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]))             #\u56fe\u7247\u8f6c\u6362\uff0c\u6240\u6709\u90fd\u8f6c\u5230\u76f8\u540c\u5927\u5c0f\uff0cNormalize\u9884\u8bad\u7ec3\u597d\u7684\n \n    #\u6279\u91cf\u8bfb\u53d6\uff0cbatch_size\u5341\u5f20\u56fe\u7247\uff1bshuffle \u987a\u5e8f\u8bfb\u53d6\uff1b num \u8d77\u591a\u5c11\u76d1\u5236\nimageloader = torch.utils.data.DataLoader(\n    imagedataset,\n    batch_size=10, shuffle=False, num_workers=2\n)","ca8ccb5f":"class ShopeeImageEmbeddingNet(nn.Module):\n    def __init__(self):  #\u521d\u59cb\u5316\n        super(ShopeeImageEmbeddingNet, self).__init__()\n         #     \n        model = models.resnet18(True)#\u4f7f\u7528\u9884\u8bad\u7ec3\u53c2\u6570\n        model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1)) #meanpooling - maxpooling   \n        #meanpooling\u4fa7\u91cd\u5747\u503c\uff0c max\u4fa7\u91cd\u6781\u5927\u503c\u66f4\u52a0\u6709\u6548\n        model = nn.Sequential(*list(model.children())[:-1])#\u53bb\u9664\u5168\u8fde\u63a5\u5c42\uff0c\u53ea\u8981\u5377\u79ef\u5c42\n        \n        model.eval()#\u5173\u95edbn\uff0c\u5173\u95eddropout\n        self.model = model\n        #\u6b63\u5411\u4f20\u64ad\n    def forward(self, img):        \n        out = self.model(img)\n        return out","c1764c77":"#shell\uff0c \u521b\u5efa\u672c\u5730\u7684\u8bad\u7ec3\u96c6\uff0c\u8d4b\u503c\u6743\u91cd\n!mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\/\n!cp ..\/input\/pretrained-pytorch-models\/resnet18-5c106cde.pth \/root\/.cache\/torch\/hub\/checkpoints\/","e4728f8e":"DEVICE = 'cuda' #\u4f20\u5230GPU\n\nimgmodel = ShopeeImageEmbeddingNet()\nimgmodel = imgmodel.to(DEVICE)\n\nimagefeat = []\nwith torch.no_grad(): #\u4e0d\u9700\u8981\u68af\u5ea6\uff0c\u53ea\u9700\u6b63\u5411\u8bfb\u53d6\n    for data in tqdm_notebook(imageloader):\n        data = data.to(DEVICE)\n        feat = imgmodel(data)\n        feat = feat.reshape(feat.shape[0], feat.shape[1])\n        feat = feat.data.cpu().numpy()\n        \n        imagefeat.append(feat)","b8131fd2":"from sklearn.preprocessing import normalize\n\n# l2 norm to kill all the sim in 0-1\nimagefeat = np.vstack(imagefeat)\nimagefeat = normalize(imagefeat)","c923a695":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(imagefeat)","b9743347":"preds = []\nCHUNK = 1024*4\n\nimagefeat = cupy.array(imagefeat)\n\nprint('Finding similar images...')\nCTS = len(imagefeat)\/\/CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = cupy.matmul(imagefeat, imagefeat[a:b].T).T\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n    for k in range(b-a):\n        IDX = cupy.where(distances[k,]>0.95)[0]\n        # IDX = np.where(distances[k,]>0.95)[0][:]\n        o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \n# del imagefeat, imgmodel","2e7c2507":"train['oof_cnn'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","d25aea12":"# from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embeddings = model.fit_transform(train_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","41aeeb74":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)\/\/CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        # IDX = np.where(cts[k,]>0.7)[0]\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel model, text_embeddings","0da91386":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","6877730f":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","ea921093":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    train['f1'] = train.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train.f1.mean() )\n\ntrain['matches'] = train.apply(combine_for_sub,axis=1)","cde1af0f":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","8f9fe695":"# title TFIDF","6102e862":"# image hash","3ea70f16":"# image CNN"}}