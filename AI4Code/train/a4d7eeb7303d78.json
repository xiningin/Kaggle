{"cell_type":{"4b6de198":"code","63e22d74":"code","823aec85":"code","c6ea0d65":"code","45111383":"code","a966c9aa":"code","97a4e3d7":"code","3b4a8323":"code","aa1ae7e3":"code","28a1b4d5":"code","cb17d342":"code","e4fbdddf":"code","6b334102":"code","005b20d9":"code","265ccfbd":"code","5b0ac02b":"code","92af0507":"markdown","7531f0ba":"markdown","8e4c4a0a":"markdown","f9ebe471":"markdown","ed7936aa":"markdown","80122ec4":"markdown","3ec3dac2":"markdown","acc59026":"markdown","a85a4cf4":"markdown","02d13585":"markdown","e46cab31":"markdown"},"source":{"4b6de198":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","63e22d74":"import warnings\nwarnings.filterwarnings('ignore')","823aec85":"df=pd.read_csv('\/kaggle\/input\/loan-default-dataset\/Loan_Default.csv')\nprint(df.shape)\ndf.head()\n","c6ea0d65":"target='Status'\npreds = [x for x in list(df) if x not in [target]]\nlen(preds)","45111383":"df.isnull().sum()","a966c9aa":"## first split the data into train and test ###\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.1, random_state=999, stratify=df[target])\ntrain.shape, test.shape","97a4e3d7":"!pip install autoviml","3b4a8323":"from autoviml.Auto_ViML import Auto_ViML","aa1ae7e3":"## The baseline accuracy needed for the model is 75% ####\ntrain[target].value_counts(1)","28a1b4d5":"m, feats, trainm, testm = Auto_ViML(train, target, test,\n                            sample_submission='',\n                            scoring_parameter='', KMeans_Featurizer=False,\n                            hyper_param='RS',feature_reduction=True,\n                             Boosting_Flag='CatBoost', Binning_Flag=False,\n                            Add_Poly=0, Stacking_Flag=False,Imbalanced_Flag=False,\n                            verbose=1)","cb17d342":"train[['Interest_rate_spread', target]].corr()","e4fbdddf":"### But once the NaN values are filled we can see that they are both oppositely correlated ##\ntrainm[['Interest_rate_spread', target]].corr()","6b334102":"df1=df.drop(['rate_of_interest',\n'Interest_rate_spread',],axis=1)\ndf1.shape","005b20d9":"### we need to do train, test split again ###\ntrain, test = train_test_split(df1, test_size=0.1, random_state=999, stratify=df[target])\ntrain.shape, test.shape","265ccfbd":"m2, feats2, trainm2, testm2 = Auto_ViML(train, target, test,\n                            sample_submission='',\n                            scoring_parameter='', KMeans_Featurizer=False,\n                            hyper_param='RS',feature_reduction=True,\n                             Boosting_Flag='CatBoost', Binning_Flag=False,\n                            Add_Poly=0, Stacking_Flag=False,Imbalanced_Flag=False,\n                            verbose=1)","5b0ac02b":"### Let us see how well the model performed on the held out test data ##\nfrom sklearn.metrics import classification_report\nprint(classification_report(test[target], testm[target+'_predictions']))","92af0507":"# 2. Let's select the top 10 features using AutoViML since it selects top features automatically","7531f0ba":"# 3.Comparing the model using AutoViML","8e4c4a0a":"# We will run AutoViML again but with those 2 variables removed","f9ebe471":"# In some features, there are a lot of NaN but that is not an issue as we will see later","ed7936aa":"## AutoViML automatically shows feature importance - from this chart above we can see that 'Interest_rate_spread' alone is good enough to predict the target variable 'status'. Let's see how well they are correlated.","80122ec4":"##  So we need to drop all interest related variables and then re-run AutoViML","3ec3dac2":"# We can see that we get about 74% Macro Average in F1-Score which is not bad but we can improve through additional feature engineering","acc59026":"# If you liked this notebook, check out the AutoViML Github\nhttps:\/\/github.com\/AutoViML\/Auto_ViML","a85a4cf4":"# 1.Data importing and preprocessing","02d13585":"# This notebook is derived from the following notebook. Thanks to Tetsuya\nhttps:\/\/www.kaggle.com\/sasakitetsuya\/prediction-model-by-feature-engineering","e46cab31":"## So the accuracy has reduced but not that much. We also see that only 3 variables are important\n1. age\n1. credit_type\n1. Upfront_charges"}}