{"cell_type":{"2da9cebf":"code","9eda43a2":"code","b333eb21":"code","00cb3470":"code","5a1582b2":"code","5feb5005":"code","7c3ad821":"code","9a22c50c":"code","931934f8":"code","03936d58":"code","12e32d3d":"code","8c2f96e2":"code","63662e0d":"code","bfca3260":"code","28af5d1d":"code","932a9dbc":"code","026e1571":"code","ef34c37d":"code","f85a4469":"code","3d0f42e4":"code","3ab545d9":"code","b7f35a69":"code","63495330":"code","ac9e9bca":"code","1110b937":"code","9f34badf":"code","47ce0f00":"code","a54593a1":"code","cf925f3d":"code","28cb1afd":"code","4d0b9411":"code","62c2b88c":"code","8169621e":"code","b165f829":"code","4631e7c6":"code","cf20ffee":"code","caaf06d9":"code","d37ecedd":"code","32d1dd6b":"code","c978549c":"code","10ada32a":"code","90b36c4f":"code","b2c5c385":"code","6cb02162":"code","0e111b12":"code","40baa220":"code","cffb8bed":"markdown","4a682ad6":"markdown","5917233b":"markdown","bf91f795":"markdown","02840881":"markdown","832fa89f":"markdown","2168f82e":"markdown","f2aa4678":"markdown","aa9b5fdb":"markdown","4e58f7d3":"markdown","f487eb47":"markdown","5a6e0d7a":"markdown","169f24e4":"markdown","fc289617":"markdown","daf8ecd6":"markdown"},"source":{"2da9cebf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9eda43a2":"# Carregando os dados\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","b333eb21":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","00cb3470":"# Vamos visualizar os dados\ndf_all.info()","5a1582b2":"# Vamos aumentar o n\u00famero de colunas para o info mostrar\ndf_all.info(max_cols=145)","5feb5005":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","7c3ad821":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","9a22c50c":"#Vamos criar uma coluna com a f\u00f3rmula descrita no dicion\u00e1rio de dados\ndf_all['dependency_calculated'] = (df_all['hogar_nin'] + df_all['hogar_mayor']) \/ (df_all['hogar_adul'])\ndf_all['dependency_calculated'].head()","931934f8":"#Vamos criar uma coluna c\u00f3pia de dependency, mas substituindo as strings por inteiros\ndf_all['dependency_test'] = df_all['dependency'].replace('yes',1).replace('no',0)\ndf_all['dependency_test'].head()","03936d58":"#Vamos comparar os valores\ndf_all[['dependency','dependency_calculated','dependency_test','hogar_nin','hogar_mayor','hogar_adul','hogar_total']].head(20)","12e32d3d":"#Dropando as colunas com erro de c\u00e1lculo\ndf_all.drop(['dependency','dependency_test'],axis=1,inplace=True)","8c2f96e2":"# vamos analisar se temos NA ou inf na coluna\ndf_all.dependency_calculated.value_counts()","63662e0d":"# setar pandas para deixar os valores inf como na\npd.set_option('mode.use_inf_as_na', True)","bfca3260":"# localizar os 36 valores infinitos\ndf_all.dependency_calculated.isna().sum()","28af5d1d":"# substituir os valores por -1\ndf_all['dependency_calculated'].fillna(-1, inplace=True)\ndf_all.dependency_calculated.isna().sum()","932a9dbc":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","026e1571":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","ef34c37d":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","f85a4469":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","3d0f42e4":"# Visualizando do comando info\ndf_all.info(max_cols=145)","3ab545d9":"# Verificando os valores nulos\ndf_all.isnull().sum()","b7f35a69":" # 1. Verificando os valores de aluguel (v2a1) para os chefes\/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","63495330":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","ac9e9bca":"# 2. An\u00e1lise de v18q (relacao com v18q1)\ndf_all['v18q'].value_counts()","1110b937":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","9f34badf":"# 3. Verificando valores nulos de rez_esc\nprint('Porcentagem de Valores Nulos:',(df_all['rez_esc'].isnull().sum() \/ len(df_all))*100)","47ce0f00":"# Prenchendo com -1 os valores nulos de rez_esc (estrat\u00e9gia do outlier)\ndf_all['rez_esc'].fillna(-1, inplace=True)","a54593a1":"# 4. Verificando valores nulos de meaneduc\nprint('Porcentagem de Valores Nulos:',(df_all['meaneduc'].isnull().sum() \/ len(df_all))*100)\nprint('Quantidade de Valores Nulos:',df_all['meaneduc'].isnull().sum() )","cf925f3d":"#M\u00e9dia e mediana de meaneduc\ndf_all.meaneduc.mean(), df_all.meaneduc.median()","28cb1afd":"#Preenchendo os valores nulos de meaneduc com o valor de 9 anos de estudos (entre m\u00e9dia e mediana), ou seja, uma tend\u00eancia geral dos dados\ndf_all['meaneduc'].fillna(9, inplace=True)","4d0b9411":"# 5. Verificando valores nulos de SQBmeaned\nprint('Porcentagem de Valores Nulos:',(df_all['SQBmeaned'].isnull().sum() \/ len(df_all))*100)","62c2b88c":"# Prenchendo com -1 os valores nulos de SQBmeaned (estrat\u00e9gia do outlier)\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\n","8169621e":"#Visualiza\u00e7\u00e3o dados\ndf_all.info(max_cols=145)","b165f829":"df_all.isnull().sum().sort_values()","4631e7c6":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","cf20ffee":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","caaf06d9":"# Histograma da Vari\u00e1vel Target\nsns.histplot(data=train, x=\"Target\", bins = 4)\nplt.show()","d37ecedd":"# Verificando valores absolutos\ntrain['Target'].value_counts()","32d1dd6b":"# Verificando as porcentagens\ntrain['Target'].value_counts(normalize=True)","c978549c":"# Dividindo dataset treino em X,y\n\nX, y = train[feats], train[['Target']]","10ada32a":"# Importando a biblioteca\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Fazendo o over-sampling\nros = RandomOverSampler(random_state=42)\nX_ros,y_ros= ros.fit_resample(X,y)\n\n# Verificando os dados\ny_ros['Target'].value_counts()","90b36c4f":"# Trabalhando com XGBoost\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier(n_estimators=250, learning_rate=0.09, random_state=42)\n\n# Treinando o modelo\nxgb.fit(X_ros, y_ros)","b2c5c385":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = xgb.predict(test[feats]).astype(int)","6cb02162":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","0e111b12":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","40baa220":"fig=plt.figure(figsize=(15, 20))\n\n# Avaliando a importancia de cada coluna (cada vari\u00e1vel de entrada)\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","cffb8bed":"### Dependency\n\nDe acordo com o dicion\u00e1rio de dados, \n\n> dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)\/(number of member of household between 19 and 64)","4a682ad6":"Estamos diante de um caso de classifica\u00e7\u00e3o multiclasse em que as classes est\u00e3o desbalanceadas (a categoria 4.0 ocupa 63% do dataset). Vamos usar **Over Sampling** para aumentar as classes minorit\u00e1rias.","5917233b":"### Verifica\u00e7\u00e3o dos dados p\u00f3s tratamento","bf91f795":"### Features que possuem missing values\n\n1. v2a1 = valor aluguel mensal\n2. v18q1 = quantidade de tablets que os propriet\u00e1rios da casa possuem\n3. rez_esc = anos antes da escola\n4. meaneduc = m\u00e9dia ded anos de educa\u00e7\u00e3o nos adultos\n5. SQBmeaned = quadrado da m\u00e9dia dos anos de educa\u00e7\u00e3o dos adultos","02840881":"Analisando esses valores, percebemos que os valores que est\u00e3o na coluna \"dependency\" n\u00e3o correspondem a f\u00f3rmula na descri\u00e7\u00e3o do dicion\u00e1rio de dados.\nA decis\u00e3o nesse caso ser\u00e1 dropar a coluna dependency que estava no dataset original (com erros de c\u00e1lculo) e manter a coluna calculada.","832fa89f":"A escolha para preenchimento dos valores nulos por -1 foi intencional. A ideia \u00e9 n\u00e3o tentar excluir essa coluna e tamb\u00e9m de n\u00e3o perder nenhum dado. Como o algoritmo usado ser\u00e1 Random Forest, o uso de -1 (outlier) ser\u00e1 para \"for\u00e7ar\" a \u00e1rvore a dispensar os valores -1.","2168f82e":"A quantidade de valores nulos na feature v18q (possui tablet), que \u00e9 bin\u00e1ria, bate com o valor de missing values da feature quantidade de tablets. Basta substituir valores nulos por 0.","f2aa4678":"## Problema de Gest\u00e3o\n\nQueremos montar um modelo que seja capaz de identifcar qual casa precisa de mais assist\u00eancia social da Costa Rica.\n\nEstamos diante de um problema de **classifica\u00e7\u00e3o multiclasse**.","aa9b5fdb":"Percebemos a grande quantidade de valores armazenados como \"yes\" e \"no\" (strings).\n\nVisto no dicion\u00e1rio de dados que o 'yes' pode ser substitu\u00eddo por 1 e que o 'no' pode ser substitu\u00eddo por 0.\n\nVamos calcular e verificar se isso pode ser feito.","4e58f7d3":"### Tratamento de Valores Ausentes","f487eb47":"### Visualiza\u00e7\u00e3o da Vari\u00e1vel Target","5a6e0d7a":"### edjefa e edjefe\n\nDe acordo com o dicion\u00e1rio de dados,\n\n> years of education of **female** head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n\n> years of education of **male** head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0","169f24e4":"### Features dtype object","fc289617":"### XGBoost ap\u00f3s Over Sampling","daf8ecd6":"# XGBoost \n\nNesse notebook ser\u00e1 feito:\n\n* An\u00e1lise Explorat\u00f3ria dos Dados\n* Tratamento de Classes Desbalanceadas\n* XGBoost\n"}}