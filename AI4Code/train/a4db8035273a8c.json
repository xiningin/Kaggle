{"cell_type":{"775e453c":"code","b23bc03d":"code","7f260662":"code","a1957218":"code","26cac3f6":"code","8cdb8819":"code","2aaf4180":"code","edbee5ed":"code","f73dcfc5":"code","f0864f44":"code","26790146":"code","87173ce1":"code","3372615d":"code","ead18121":"code","bb048b54":"code","0a82eaf7":"code","79ab926d":"code","7f99b7e7":"code","3a94adf5":"code","be91fb0e":"code","248cdec8":"code","53b31552":"code","240133e3":"code","6add691e":"code","0952a9d6":"code","69929195":"code","7227f02f":"code","4bae21de":"markdown","36e4d18a":"markdown","6177817b":"markdown","bdaa0d7e":"markdown","2a9f0285":"markdown","0fd32e12":"markdown","773c24d4":"markdown","30aae924":"markdown","6bd645e1":"markdown","bc5c8097":"markdown","56a0d923":"markdown","9dbf4217":"markdown"},"source":{"775e453c":"# Import all the important    \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import optimize, stats    \n%matplotlib inline","b23bc03d":"df_train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndf_shops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ndf_items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\ndf_item_categories = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","7f260662":"df_train.head(4)","a1957218":"df_shops.head(4)\n","26cac3f6":"df_items.head(4)","8cdb8819":"df_item_categories.head(4)","2aaf4180":"df_test.head(4)","edbee5ed":"# we check data type of all columns\ndf_train.info()","f73dcfc5":"#date is object so we will change Dtype from object to datetime64\ndf_train['date']=pd.to_datetime(df_train['date'])","f0864f44":"#now we check if there is any null values present in dataset\ndf_train.isnull().sum()","26790146":"df_train['date']=df_train['date'].dt.strftime('%Y-%m')","87173ce1":"df_train.head().sort_values(by='date')","3372615d":"df_train.drop(['date_block_num','item_price'] , axis =1, inplace= True)","ead18121":"df_train.head().sort_values(by='date')","bb048b54":"df=df_train.groupby(['date','shop_id','item_id']).sum()\ndf.head()","0a82eaf7":"df = df.pivot_table(index=['shop_id','item_id'], columns='date', values='item_cnt_day', fill_value=0)\ndf.reset_index(inplace=True)\ndf.head()","79ab926d":"df_test= pd.merge(df_test , df , on = ['shop_id', 'item_id'], how = 'left')\ndf_test.drop(['ID', '2013-01'], axis =1, inplace=True)\ndf_test= df_test.fillna(0)","7f99b7e7":"df_test.head()","3a94adf5":"from sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import resample\nfrom sklearn.pipeline import Pipeline","be91fb0e":"Y_train = df['2015-10'].values\nX_train = df.drop(['2015-10'], axis = 1)\nX_test = df_test","248cdec8":"x_train, x_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.2, random_state=101)","53b31552":"LR = LinearRegression()\nLR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, LR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, LR.predict(x_test)))\nprint('Test set score:', LR.score(x_train,y_train))","240133e3":"RFR = RandomForestRegressor(n_estimators = 100)\nRFR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, RFR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, RFR.predict(x_test)))\nprint('Test set score:', RFR.score(x_train,y_train))","6add691e":"prediction = RFR.predict(X_test)","0952a9d6":"prediction = list(map(round, prediction))","69929195":"df_submission = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nprint(df_submission.shape)\ndf_submission.head()","7227f02f":"df_submission['item_cnt_month'] = prediction\ndf_submission.to_csv('prediction.csv', index=False)\ndf_submission.head()","4bae21de":"In this data set date format is 02-10-2015 but we only need month and year\nSO we delete date day and keep only month and year","36e4d18a":"## Predicting Future Sales","6177817b":"### Linear Regression","bdaa0d7e":"### Read all the data files","2a9f0285":"## Machine Learning Model","0fd32e12":"You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.","773c24d4":"### Training and Testing Data","30aae924":"#### Data fields\n* ID - an Id that represents a (Shop, Item) tuple within the test set\n* shop_id - unique identifier of a shop\n* item_id - unique identifier of a product\n* item_category_id - unique identifier of item category\n* item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n* item_price - current price of an item\n* date - date in format dd\/mm\/yyyy\n* date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n* item_name - name of item\n* shop_name - name of shop\n* item_category_name - name of item category","6bd645e1":"### Data Description\n#### File descriptions\n* sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n* test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n* sample_submission.csv - a sample submission file in the correct format.\n* items.csv - supplemental information about the items\/products.\n* item_categories.csv - supplemental information about the items categories.\n* shops.csv- supplemental information about the shops.","bc5c8097":"Now we will groupby our data with reference to date, shop_id, item_id","56a0d923":"Now,in dataset 'date_block_num' = consicutive month number and 'item_price' is given\nBut for our prediction we do not need these columns so we will deletd these columns","9dbf4217":"Now after group by we will make pivot table for easy understanding \nwe keep shop_id and item_id as index\nwe keep date as columns and fill item_cnt_day in value"}}