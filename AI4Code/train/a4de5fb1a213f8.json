{"cell_type":{"ff922b37":"code","2429516e":"code","aff6cdec":"code","fa2fabe7":"code","d09026ae":"code","32d14702":"code","4ed6b7bc":"code","d47c82eb":"code","f2c39a62":"code","5a178676":"code","70649484":"code","a0b7a999":"code","c32229c9":"code","f88d66f1":"code","acf2d708":"code","50f0333a":"code","1a61464f":"code","369dd9f9":"code","b29fab94":"code","ecfe1056":"code","652cfe94":"code","375c33ae":"code","3e215b1f":"code","48939da0":"code","86a94b1b":"code","3f52dfdf":"code","52b980b3":"code","2a5f0a63":"code","c6be89ae":"code","03486b2b":"code","197da4f5":"code","610905cd":"markdown","eef209b4":"markdown","3b1ebd8a":"markdown"},"source":{"ff922b37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nfrom skimage.transform import resize\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2429516e":"path = Path('..\/input')","aff6cdec":"train_df = pd.read_json(path\/'train.json')","fa2fabe7":"train_df.head()","d09026ae":"train_df.dtypes","32d14702":"img = np.array(train_df.audio_embedding[0])\nplt.imshow(img)","4ed6b7bc":"img = np.array(train_df.audio_embedding[97])\nplt.imshow(img)","d47c82eb":"plt.imshow(resize(img\/255, (10,128), mode='reflect'))","f2c39a62":"plt.imshow(resize(img\/255, (10,128), mode='constant'))","5a178676":"def convert_audio_embedding(e):\n    img = np.array(e, dtype=np.float32)\/255\n    if img.shape != (10,128):\n        img = resize(img, (10,128), mode='constant')\n    return img","70649484":"plt.imshow(convert_audio_embedding(train_df.audio_embedding[97]))","a0b7a999":"audio_embeddings = np.array(list(map(convert_audio_embedding,train_df.audio_embedding)))\naudio_embeddings = audio_embeddings.reshape((-1,1, 10, 128)).astype(np.float32)\naudio_embeddings.shape","c32229c9":"is_turkey =train_df.is_turkey.values.reshape((-1,1)).astype(np.float32)\nis_turkey.shape","f88d66f1":"X_tensor = torch.from_numpy(audio_embeddings)\ny_tensor = torch.from_numpy(is_turkey)","acf2d708":"train_dataset = TensorDataset(X_tensor, y_tensor)\ndl = DataLoader(train_dataset, batch_size=16,shuffle=True)","50f0333a":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 3, 2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(3, 16, 2)\n        self.fc1 = nn.Linear(16 * 1 * 31, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 1)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 1 * 31)\n        x = F.relu(x)\n        x = F.relu(self.fc1(x))\n        x = F.relu(x)\n        x = F.relu(self.fc2(x))\n        x = F.relu(x)\n        x = self.fc3(x)\n        x = torch.sigmoid(x)\n        return x\n\n\nnet = Net()","1a61464f":"x, y = iter(dl).next()\ny_hat = net(x)","369dd9f9":"x.shape,y.shape, y_hat.shape","b29fab94":"import torch.optim as optim\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.)","ecfe1056":"for epoch in range(10):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(dl, 0):\n        # get the inputs\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n\n    print('[{0:d},{1:2d}] loss: {2:.3f}'.format(epoch + 1, i + 1, running_loss \/ len(dl)))\nprint('Finished Training')","652cfe94":"x, y = iter(dl).next()\ny_hat = net(x)","375c33ae":"y-(y_hat>0.5).float()","3e215b1f":"test_df = pd.read_json(path\/'test.json')","48939da0":"test_df.shape","86a94b1b":"audio_embeddings = np.array(list(map(convert_audio_embedding,test_df.audio_embedding)))\naudio_embeddings = audio_embeddings.reshape((-1,1, 10, 128)).astype(np.float32)\naudio_embeddings.shape","3f52dfdf":"X_tensor = torch.from_numpy(audio_embeddings)","52b980b3":"pred = net(X_tensor)","2a5f0a63":"pred = (pred>0.6).int().numpy()","c6be89ae":"submission = pd.DataFrame({'vid_id': test_df.vid_id.values, 'is_turkey': pred.flatten()})","03486b2b":"submission.head(5)","197da4f5":"submission.to_csv(\"submission.csv\", index=False)","610905cd":"### Prepare data","eef209b4":"### Load train data","3b1ebd8a":"### Test set"}}