{"cell_type":{"257ecad8":"code","5aeac13a":"code","3ac6ce0a":"code","ca324393":"code","a7197152":"code","fef44ed6":"code","c6fb17e9":"code","8ec251be":"code","13bedaec":"code","26596641":"code","8d857065":"code","386cb22f":"code","ff416a51":"code","8c73bf71":"code","6f7aaa4c":"code","b2420804":"code","56957702":"code","c499ccc9":"code","5ff2605a":"code","651d9272":"code","7dd6c793":"code","d52b1425":"code","4ee2a782":"code","62604a41":"code","3b2a2a86":"code","d4c94deb":"code","86fc9d68":"code","c39c1f3e":"code","75739d6b":"code","9860210a":"code","03a5417f":"code","d5173792":"markdown","aa206407":"markdown","97d9970d":"markdown","629d2315":"markdown","9130f057":"markdown","89a4f956":"markdown","cd1bfeec":"markdown"},"source":{"257ecad8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style = \"darkgrid\")\n# !pip install datawig\n# import datawig # impute missing values \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5aeac13a":"path = \"..\/input\/porto-seguro-safe-driver-prediction\/train.csv\"\ndata = pd.read_csv(path)","3ac6ce0a":"data.head(10) # display top 10 rows","ca324393":"data = data.drop(['id'], axis = 1)","a7197152":"# number of rows and columns in dataset\nrows = data.shape[0]\ncolumns = data.shape[1]\nprint(\"Data has {} rows, {} columns\".format(rows, columns))","fef44ed6":"data.info()","c6fb17e9":"# number of nulls in dataset\nnulls = (data.isna().sum()\/rows)*100\nnulls","8ec251be":"# replace -1 with NaN\ndata = data.replace(to_replace = -1, value = np.nan)\n# calculate nulls count\nnulls = (data.isna().sum()\/rows)*100\nnulls","13bedaec":"# threshold value for nulls %\nnull_threshold = 15\n# columns to drop with nulls % greater than threshold\ndrop_nulls = []\n# columns with null % less than threshold (to be imputed)\nretain_nulls = []\n\nprint(\"Columns with nulls more than threshold :\\n\")\nfor i in nulls.index:\n    if(nulls[i]>null_threshold):\n        print(i, nulls[i])\n        drop_nulls.append(i)\n    elif(nulls[i]>0):\n        retain_nulls.append(i)\n","26596641":"data = data.drop(drop_nulls, axis = 1)","8d857065":"from sklearn.model_selection import train_test_split\n\n# dependent variables\nX = data.drop(['target'], axis = 1)\n# independent variable\ny = data['target']\n\n# split data into train and validation part\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 5)","386cb22f":"# categorical columns\ncat_columns = []\n\nfor i in X_train.columns:\n    if('cat' in i):\n        cat_columns.append(i)\n\ncat_columns","ff416a51":"# convert list to np.array\ncat_columns = np.array(cat_columns)\n\n# not using the following columns since they are of binary nature thus no need to encode\ncat_columns = cat_columns[(cat_columns!='ps_ind_04_cat') & (cat_columns!='ps_car_02_cat') & \n           (cat_columns!='ps_car_07_cat') & (cat_columns!='ps_car_08_cat')]","8c73bf71":"# encode categorical variable using LeaveOneOutEncoding technique\n# !pip install category_encoders\nfrom category_encoders import LeaveOneOutEncoder\n\n# intialise encoder\nencoder = LeaveOneOutEncoder(cols = cat_columns)","6f7aaa4c":"# fit and encode data\nX_train = encoder.fit_transform(X_train, y_train)\nX_val = encoder.transform(X_val)","b2420804":"# columns to use as input to imputer\nimputer_columns = []\n\nfor i in X_train.columns:\n    if(i not in retain_nulls):\n        imputer_columns.append(i)","56957702":"!pip install datawig\nimport datawig\n\ndef ImputeNulls(train, val, imputer_columns, output_column):\n    ''' \n    Replaces nulls in output_column\n    \n    Args:\n        train, val (DataFrame) : Training and validation datasets\n    \n    Returns:\n        tuple : train and validation datasets with imputed values\n    '''\n#     intialise imputer\n    imputer = datawig.SimpleImputer(\n        input_columns=imputer_columns,\n        output_column=output_column\n        )\n#     fit \n    imputer.fit(train_df = train)\n#     impute missing values\n#     imputer = datawig.SimpleImputer.load('.\/ps_car_14')\n    train = imputer.predict(train)\n    val = imputer.predict(val)\n    return (train, val)","c499ccc9":"# map columns with imputed values to fill against nulls\nfill_nulls = {}\n\nfor i in retain_nulls[:-1]:\n    fill_nulls[i] = X_train[i].median()\n    X_train[i] = X_train[i].fillna(value=fill_nulls[i])\n    X_val[i] = X_val[i].fillna(value=fill_nulls[i])","5ff2605a":"X_train, X_val = ImputeNulls(X_train, X_val, imputer_columns, retain_nulls[-1])\nX_train = X_train.drop(['ps_car_14'], axis = 1)\nX_val = X_val.drop(['ps_car_14'], axis = 1)","651d9272":"def handleOutliers(data, to_return = False):\n    ''' \n    Removes outliers from each column and reports the data loss\n    \n    Args:\n        data (DataFrame) : The DataFrame to remove outliers from\n        to_return (bool) :  - Default value False\n                            - Whether to return the DataFrame after removing outliers\n    \n    Returns:\n        DataFrame : data free from outliers\n    '''\n#     calculate first quantile\n    Q1 = data.quantile(0.25)\n#     calculate third quantile\n    Q3 = data.quantile(0.75)\n#     calculate inter quartile range\n    IQR1 = Q3-Q1\n\n#     initialise data w\/o outliers (drop outliers)\n    data_c = data[~((data < (Q1-1.5*IQR1))|(data > (Q3+1.5*IQR1))).any(axis = 1)] \n    \n#     report data loss\n    print('Data loss is {}%'.format(((len(data) - len(data_c))\/len(data))*100))\n    \n    if(to_return):\n        return data_c.reset_index(drop = True)","7dd6c793":"handleOutliers(X_train)","d52b1425":"def countOutliers(data, column):\n    ''' \n    Calculates the number of outliers in given column\n    \n    Args:\n        data (DataFrame) : The dataset in form of Pandas DataFrame\n        column (string) : The column to report number of outliers in\n    \n    Returns:\n        int : percentage of outliers in column\n    '''\n#     calculate first quantile\n    Q1 = data[column].quantile(0.25)\n#     calculate third quantile\n    Q3 = data[column].quantile(0.75)\n#     calculate inter quartile range\n    IQR1 = Q3-Q1\n    \n#     % of outliers in the column\n    return (len(data[((data[column] < (Q1-1.5*IQR1))|(data[column] > (Q3+1.5*IQR1)))])\/len(data))*100","4ee2a782":"# percentage of outliers in each column\noutliers = {}\n\nfor column in X_train.columns:\n    outliers[column] = countOutliers(X_train, column)","62604a41":"# sort in decreasing order\noutliers = dict(sorted(outliers.items(), key=lambda item: item[1], reverse = True))","3b2a2a86":"def OutliersInfo(threshold_outliers, outliers):\n    '''\n    Finds number of columns in data with more than threshold percentage of outliers\n    \n    Args:\n        thershold_outliers (int) : maximum percentage of outliers acceptable in dataset\n        outliers (dict) : map of columns with number of outliers in each\n    \n    Returns:\n        list : Columns with more than thershold percent of outliers\n    '''\n\n#     remove columns with more than threshold\n    to_drop_outliers = []\n\n    for i in outliers:\n        if(outliers[i] <= threshold_outliers):\n            break\n        elif(i != 'target'):\n            to_drop_outliers.append(i)\n            \n    return to_drop_outliers","d4c94deb":"# thersholds to check\nthresholds_outliers = [i for i in range(21)]\n# number of columns for each threshold\nthreshold_outliers_values = []\n\nfor i in thresholds_outliers:\n    threshold_outliers_values.append(len(OutliersInfo(i, outliers)))\n    \n# plot\nsns.lineplot(x=thresholds_outliers, y=threshold_outliers_values)\nplt.xlabel(\"Thresholds\")\nplt.ylabel(\"Columns\")\nplt.show()","86fc9d68":"threshold_outliers = 4\n\n# columns with more than threshold of outliers\ndrop_outliers = OutliersInfo(threshold_outliers, outliers)\n\nprint(\"Columns with more than {}% of values as Outliers are {}\".format(threshold_outliers, len(drop_outliers)))","c39c1f3e":"# drop outliers\nX_train = X_train.drop(drop_outliers, axis = 1)\nX_val = X_val.drop(drop_outliers, axis=1)","75739d6b":"#columns with constant value\ndrop_constant_valued = ['ps_ind_02_cat', 'ps_ind_10_bin', 'ps_ind_11_bin'\n                       , 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14']\n\nX_train = X_train.drop(drop_constant_valued, axis=1)\nX_val = X_val.drop(drop_constant_valued, axis=1)","9860210a":"X_train = handleOutliers(X_train, True)","03a5417f":"!pip install dataprep\nfrom dataprep.eda import plot\nplot(X_train)","d5173792":"IT IS MENTIONED IN DATA DESCRIPTION THAT -1 REPRESENTS MISSING VALUES","aa206407":"# ","97d9970d":"## Handle Constant Valued columns","629d2315":"# DATA PREPROCESSING","9130f057":"## HANDLE NULLS","89a4f956":"## HANDLE CATEGORICAL VARIABLES","cd1bfeec":"## SPLIT INTO TRAIN & VALIDATION PARTS"}}