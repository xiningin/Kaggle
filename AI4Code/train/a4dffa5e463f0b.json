{"cell_type":{"5db11a57":"code","59c8fd98":"code","d486bdfb":"code","450ebeff":"code","46bd7526":"code","d4c7edcf":"code","26c787e0":"code","d8f8df6f":"code","6e1d1fdc":"code","5902f630":"code","05bc4846":"code","45f31130":"code","53b6ebe3":"code","b1d60e0b":"code","9114a2ca":"code","e9db44d4":"code","14da9c4f":"code","6d505d14":"code","228d7448":"code","8e5f8ccf":"code","1e097242":"code","603d891b":"code","670ce8ba":"code","41541926":"code","fa34a4d6":"code","9fe2ded7":"code","55aa759e":"code","32c4810d":"code","6fc22eb3":"code","7abd9af7":"code","093b872e":"code","e99c4f05":"code","eb7beacd":"code","eb919276":"code","3f00b8f7":"code","9961942d":"markdown","80465e79":"markdown","06dbc692":"markdown","85e5666a":"markdown","207f6442":"markdown","ef9b1595":"markdown","09801910":"markdown","c4a72e62":"markdown","5cf59135":"markdown","182f8636":"markdown","844c905a":"markdown","2102d834":"markdown","0d8064aa":"markdown","48cdcc17":"markdown","1bc4efdf":"markdown","7bcb7380":"markdown","bb6cca69":"markdown","4c4096b4":"markdown","af24ddf6":"markdown"},"source":{"5db11a57":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # making plots and charts\nimport requests # getting data through APIs\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","59c8fd98":"# Import the data from CSV file and save it to a dataframe\n\nbitstamp = pd.read_csv('..\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2019-08-12.csv')","d486bdfb":"# Inspect the first a few rows of the data to see what potential cleaning is needed\n\nbitstamp.head()","450ebeff":"# Check the number of rows, columns and the datatypes of each column\n\nbitstamp.info()","46bd7526":"# Quickly check the statistics of all the data in each column to see if they make sense\n# Based on my common sense historically the prices of Bitcoins went from 0 to an all \n# time high of around $20,000 per coin\n\nbitstamp.describe()","d4c7edcf":"# Inspect the shape of the dataset\n\nbitstamp.shape","26c787e0":"# There are around 1.2 million rows of data with missing values\n\nbitstamp['Open'].value_counts(dropna = False)","d8f8df6f":"# Do a quick histogram plot here to see the distribution of prices\n\nbitstamp['Open'].plot('hist')","6e1d1fdc":"# Do a quick box plot here to see the distribution of prices\n\nbitstamp.boxplot(column=['Open', 'High', 'Low', 'Close'])","5902f630":"# Set the index of the dataset to be the time of each observation in YYYY-MM-DD HH-MM-SS\n\nbitstamp.set_index(pd.to_datetime(bitstamp['Timestamp'], unit='s'), inplace=True, drop=True)","05bc4846":"# Inspect the dataset again\n\nbitstamp.head()","45f31130":"# Fill the missing values using the forward fill method. \n# This method is appropriate here since the missing values in the original dataset were caused\n# by the fact that there were not trading actions during those time periods, so it is safe to assume\n# that the prices remained constant when there were no trading. Forward fill method takes the latest\n# price data up to that point and filled it forward in time.\n\nbitstamp.fillna(method = 'ffill', inplace = True)","53b6ebe3":"# Inspect again\n\nbitstamp.head()","b1d60e0b":"# Also check the latest data. These values seem to make sense as compared to the actual prices in August this year\n\nbitstamp.tail()","9114a2ca":"# Plot a histogram again to check the price distributions\n\nbitstamp['Close'].plot('hist')","e9db44d4":"# Save the useful columns from the original dataset into a new and clean dataset called bitstamp_clean\n\nbitstamp_clean = bitstamp.loc[:, ['Open', 'High', 'Low', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price']]","14da9c4f":"# Inspect the information of the clean dataset\n\nbitstamp_clean.info()","6d505d14":"# Plot the time series price data\n\nbitstamp_clean.plot(y='Close')","228d7448":"# Create a log-log plot of the closing prices for the past 7 years\n\nbitstamp_clean.plot(y='Close', logx=True, logy=True)","8e5f8ccf":"# Obtain Bitcoin wallet data from Quandl \n# (which is a dataset of number of wallets hosts using My Wallet Service on each day from 2009 to 2019. )\n\nwallet = pd.read_csv('..\/input\/bitcoin-my-wallet-number-of-users\/BCHAIN-MWNUS.csv')","1e097242":"# Inspect the first 5 rows to see the latest wallet data\n\nwallet.head()","603d891b":"# Inspect the last 5 rows to see the oldest data from 2009\n\nwallet.tail()","670ce8ba":"# Convert the date column to datetime format for easier processing later\n# Also rename the columns while we are here\n\nwallet['Date'] = pd.to_datetime(wallet['Date'])\nwallet.rename(columns = {'Date': 'Date', 'Value': 'Wallets'}, inplace = True)","41541926":"# Group our Bitcoin price data by day so that it could be plotted on the same scale\n# against the daily wallet data\n\nbitstamp_clean_day = bitstamp_clean.resample('D').mean()","fa34a4d6":"# Create a date column in the bitstamp_clean_day dataframe\n\nbitstamp_clean_day['Date'] = bitstamp_clean_day.index","9fe2ded7":"# Inspect the first 5 rows to confirm that the timestamps are indeed grouped by days\n\nbitstamp_clean_day.head()","55aa759e":"# Join the two dataframes (bitstamp_clean_day and wallet) by matching their dates columns\n\ndf = pd.merge(bitstamp_clean_day, wallet, how='inner', on='Date')","32c4810d":"# Inspect the first a few rows to confirm the data looks good to go\n\ndf.head()","6fc22eb3":"# Plot both daily prices and daily number of wallets for Bitcoin on the same graph\n\nplt.plot(df['Date'], df['Close'], 'r', df['Date'], df['Wallets']\/10000, 'b')\nplt.yscale('log')\nplt.xlabel('Year')\nplt.ylabel ('Price and Number of Wallets')\nplt.title('Bitcoin Price compared to the Number of Wallets')\nplt.legend(labels = ['Price', 'Wallets'])\nplt.show()","7abd9af7":"# Import the Bitcoin difficulty dataset\n\ndiff = pd.read_csv('..\/input\/bitcoin-difficulty\/BCHAIN-DIFF.csv')","093b872e":"# Rename the columns for easier processing\n# Also change the data format of the \"Date\" column while we are here\n\ndiff.rename(columns = {'Date': 'Date', 'Value': 'Difficulty'}, inplace = True)\ndiff['Date'] = pd.to_datetime(diff['Date'])","e99c4f05":"# Inspect the first a few rows of the dataset\n\ndiff.head()","eb7beacd":"# Merge these data with Bitcoin price dataframe for comparison later\n\ndf2 = pd.merge(bitstamp_clean_day, diff, how='inner', on='Date')","eb919276":"# Inspect the first a few rows of df2\n\ndf2.head()","3f00b8f7":"# Plot both daily prices and level of difficulty for Bitcoin mining on the same graph\n\nplt.plot(df2['Date'], df2['Close'], 'r', df2['Date'], df2['Difficulty']\/100000, 'b')\nplt.yscale('log')\nplt.xlabel('Year')\nplt.ylabel ('Price and Level of Difficulty')\nplt.title('Bitcoin Price compared to the Level of Difficulty')\nplt.legend(labels = ['Price', 'Difficulty'])\nplt.show()","9961942d":"Now the trend of the prices seem to be more clear. There is a steady increasing trend over the past 7 years for Bitcoin prices.","80465e79":"Now let's import an additional dataset \"[Bitcoin My Wallet Number of Users](https:\/\/www.quandl.com\/data\/BCHAIN\/MWNUS)\" which tells us the number of Bitcoin wallets using My Wallet Services on a global scale. This is an indicator of the degree of adoption of Bitcoins worldwide.","06dbc692":"[Future work] plot histogram in log scale too","85e5666a":"Now we are ready to visualize the relationship between prices and number of wallets.","207f6442":"## Data Wrangling\n\nFirst let's obtain and clean our Bitcoin price dataset to get ready for analysis.","ef9b1595":"hmmm.... Seems there are a lot of missing values, and the first column is coded in Unix time.","09801910":"There are 8 columnns and around 4 million rows of data. The datatypes seem to be fine since they are mostly float64, which is suitable for price data.","c4a72e62":"From the above plot it seems that there is some kind of correlation between the number of wallets (which implies the degree of adoption of Bitcoins worldwide) and the prices of Bitcoins on a log scale. Therefore, by monitoring the level of increase\/decrease of total number of wallets on a global scale, it is possible to predict the overall trend of Bitcoin prices over the next couple of years. Also it is worth noting that the rate of change for both quantities seem to be slowing down, indicating the level of volatility is being more stablized.","5cf59135":"Now let's import another dataset \"[Bitcoin Difficulty](https:\/\/www.quandl.com\/data\/BCHAIN\/DIFF)\" which is a measure of how difficult it is to find a hash below a given target. This is an indicator of the level of difficulty of Bitcoin mining, which in turn implies the level of scarcity of new Bitcoin supply.","182f8636":"# Bitcoin Data Analysis\n#### Oct 2019  |   Work in Progress   |   Jason Su","844c905a":"[Future work] Add a test of normality","2102d834":"Back then there were only 2 wallets!","0d8064aa":"## Introduction\n\nBitcoin was the first cryptocurrency and is still the largest cyrptocurrency by market capitalization. Some people think of it as an investment vehicle (similar to commodities in nature) while others think of it as a store of value (similar to gold). Bitcoin was designed to be a decentralized global virtual currency with minimum friction in transactions and a high level of security due to the nature of its underlying blockchain network. Since its inception Bitcoin has been rapidly adopted by enthusiasts and investors worldwide. Now it is traded on multiple online exchanges on the internet by virtually everyone in the world. Consequently, the number of factors affecting the price movements of the Bitcoins is huge and the underlying mechanisms are complex. Every investor wishes to gain a competitive advantage in predicting the price movements of Bitcoins. In this notebook I try to analyze the relationships between historical Bitcoin price movements and other relevant indicators such as the level of Bitcoin adoption, the level of difficulty in Bitcoin mining, etc, with the objective to gain insights into how different factors would affect the prices of Bitcoins and how this knowledge would convert to a strategic advantage in everyday Bitcoin trading. ","48cdcc17":"Again there seems to be a certain kind of correlation here between the level of mining difficulty and price increase over a long run. The level of difficulty of Bitcoin mining has been steadily increasing ever since it was first invented. This difficulty mechanism was hard coded into the blockchain network to ensure that Bitcoins can maintain its scarcity (fixed supply) and therefore prevent the inflation issues that we would experience with traditional currencies. Therefore, it makes perfect economic sense that as the level of supply of Bitcoins decreases its prices would go up.","1bc4efdf":"### Historical Bitcoin Price Data\n\nThe following dataset comes from [here](https:\/\/www.kaggle.com\/mczielinski\/bitcoin-historical-data) (Bitcoin price data at 1-minute intervals from select exchanges during the time period from Jan 2012 to August 2019): ","7bcb7380":"The mean, min and max values of each price column here seems to be in line with my impressions.","bb6cca69":"The below is a chart of the price of bitcoin going from 2012 to 2019. Similar plots can be found at any website which lists the price of bitcoin.","4c4096b4":"This notebook is a work in progress. I will keep updating it in the next couple of months. : )","af24ddf6":"The above plot only tells part of the story. To make more sense of such a volatile dataset, let's plot the same values again but in log scales to see the trends in more appropriate scales."}}