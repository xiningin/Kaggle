{"cell_type":{"0b83aa4b":"code","69b60352":"code","34215678":"code","27dec06b":"code","32a6e87d":"code","b2fa09d8":"code","3519e397":"code","0b82ff0c":"code","918738b3":"code","b6576154":"code","da847298":"code","a3f41b56":"code","32e2c4c6":"code","1c2570ce":"code","de34d81c":"code","44712318":"markdown","9c08d8bd":"markdown","a56ce8f2":"markdown","02827f97":"markdown","1da9edb6":"markdown","acd9ef0d":"markdown","dde541ad":"markdown","81338952":"markdown","ea4b8896":"markdown","46316267":"markdown","efc6f5e4":"markdown","f95b6df2":"markdown"},"source":{"0b83aa4b":"from random import random\nimport numpy as np\n\nfrom matplotlib import pyplot\nfrom matplotlib.patches import PathPatch\nfrom matplotlib.path import Path\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense","69b60352":"def random_rectangle():\n    width, height = random(), random()\n    points = list()\n    points.append([0.0,0.0])\n    points.append([width, 0.0])\n    points.append([width, height])\n    points.append([0.0, height])\n    \n    return points\n\nrectangle = random_rectangle()\nprint(rectangle)","34215678":"# plot a rectangle\ndef plot_rectangle(rect):\n  # close the rectangle path\n    rect.append(rect[0])\n  # define path\n    codes = [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY]\n    path = Path(rect, codes)\n    axis = pyplot.gca()\n    patch = PathPatch(path)\n  # add shape to plot\n    axis.add_patch(patch)\n    axis.set_xlim(-0.1,1.1)\n    axis.set_ylim(-0.1,1.1)\n    pyplot.show()\nrect = random_rectangle()\nplot_rectangle(rect)","27dec06b":"# generate input and output sequences for one random rectangle\ndef get_samples():\n    # generate rectangle\n    rect = random_rectangle()\n    X, y = list(), list()\n    # create input output pairs for each coordinate\n    for i in range(1, len(rect)):\n        X.append(rect[i-1])\n        y.append(rect[i])\n    # convert input sequence shape to have 1 time step and 2 features\n    X, y = np.array(X), np.array(y)\n    X = X.reshape((X.shape[0], 1, 2))\n    return X, y\n\nX, y = get_samples()\nfor i in range(X.shape[0]):\n    print(X[i][0], '=>', y[i])","32a6e87d":"# use a fit LSTM model to generate a new rectangle from scratch\ndef generate_rectangle(model):\n    rect = list()\n    # use [0,0] to seed the generation process\n    last = np.array([0.0,0.0]).reshape((1, 1, 2))\n    rect.append([[y for y in x] for x in last[0]][0])\n    # generate the remaining 3 coordinates\n    for _ in range(3):\n        # predict the next coordinate\n        yhat = model.predict(last, verbose=0)\n        # use this output as input for the next prediction\n        last = yhat.reshape((1, 1, 2))\n        # store coordinate\n        rect.append([[y for y in x] for x in last[0]][0])\n    return rect\n\n\ndef define_model():\n    # define model\n    model = Sequential()\n    model.add(LSTM(10, input_shape=(1, 2))) \n    model.add(Dense(2, activation='linear'))\n    model.compile(loss='mae', optimizer='adam')\n    model.summary()\n    \n    return model","b2fa09d8":"model = define_model()\n\n# fit model\nfor i in range(100):\n    X, y = get_samples()\n    model.fit(X, y, epochs=1, verbose=0, shuffle=False)","3519e397":"# generate new shapes from scratch\nrect = generate_rectangle(model)\nplot_rectangle(rect)","0b82ff0c":"model = define_model()\n\n# fit model\nfor i in range(500):\n    X, y = get_samples()\n    model.fit(X, y, epochs=1, verbose=0, shuffle=False)","918738b3":"# generate new shapes from scratch\nrect = generate_rectangle(model)\nplot_rectangle(rect)","b6576154":"model = define_model()\n\n# fit model\nfor i in range(5000):\n    X, y = get_samples()\n    model.fit(X, y, epochs=1, verbose=0, shuffle=False)","da847298":"# generate new shapes from scratch\nrect = generate_rectangle(model)\nplot_rectangle(rect)","a3f41b56":"model = define_model()\n\n# fit model\nfor i in range(15000):\n    X, y = get_samples()\n    model.fit(X, y, epochs=1, verbose=0, shuffle=False)","32e2c4c6":"# generate new shapes from scratch\nrect = generate_rectangle(model)\nplot_rectangle(rect)","1c2570ce":"model = define_model()\n\n# fit model\nfor i in range(25000):\n    X, y = get_samples()\n    model.fit(X, y, epochs=1, verbose=0, shuffle=False)","de34d81c":"# generate new shapes from scratch\nrect = generate_rectangle(model)\nplot_rectangle(rect)","44712318":"<h3><center>Plot Rectangle<\/center><\/h3>","9c08d8bd":"<h3>Training with 100 Examples","a56ce8f2":"<h3><center>Generate Random Rectangles","02827f97":"<h3>Training with 500 Examples","1da9edb6":"<center><h2>Shape Generation Problem<\/h2><\/center>\n<br>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nWe can frame the problem of generating random shapes as a sequence generation problem.<br> We can take drawing a rectangle as a sequence of points in the clockwise direction with 4 points in two-dimensional space:<br><br>\n    <ul>\n        <li>Bottom Left (BL): [0, 0]\n        <li>Bottom Right (BR): [1, 0]\n        <li>Top Right (TR): [1, 1]\n        <li>Top Left: [0, 1]\n    <\/ul>   \n    Each coordinate can be taken as one time step, with each of the x and y axes representing separate features. <br>Starting from 0,0, the task is to draw the remaining 4 points of the rectangle with consistent widths and heights. <br>We will frame this problem as a one-coordinate generation problem, e.g. a one-to-one sequence prediction problem. <br>Given a coordinate, predict the next coordinate. Then given the coordinate predicted at the last time step, predict the next coordinate, and so on.\n<blockquote>\n[0,0] => [x1, y1]<br>\n[x1,y1] => [x2, y2]<br>\n[x2,y2] => [x3, y3]\n    <\/blockquote>\n    <br>\n<\/div>\n\n![image.png](attachment:image.png)","acd9ef0d":"<h3>Training with 15000 Examples","dde541ad":"<h3><center>Rectangle to Sequence","81338952":"<h3>Training with 5000 Examples","ea4b8896":"<center><h3>The Generative LSTM<\/h3><\/center>\n<br>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    Given a large corpus of sequence data, such as text documents, LSTM models can be designed to learn the general structural properties of the corpus, and when given a seed input, can generate new sequences that are representative of the original corpus.\n    <br><br>\n    Language modeling is by far the most studied application of Generative LSTMs, perhaps because of the use of standard datasets where model performance can be quantified and compared.<br> This approach has been used to generate text on a suite of interesting language modeling problems, such as:<br>\n    <ul>\n        <li>Generating Wikipedia articles (including markup).\n        <li>Generating snippets from great authors like Shakespeare.\n            <li>Generating technical manuscripts (including markup).\n                <li>Generating computer source code.\n                    <li>Generating article headlines.\n    <\/ul>\n    The approach has also been applied to different domains where a large corpus of existing sequence information is available and new sequences can be generated one step at a time, such as:\n\udbff\udc00 <ul>\n    <li>Handwriting generation.\n    <li>Music generation.\n    <li>Speech generation.\n    <\/ul>","46316267":"<h3>Training with 25000 Examples","efc6f5e4":"<h3><center>Fitting Model","f95b6df2":"<h3><center>Importing Libraries"}}