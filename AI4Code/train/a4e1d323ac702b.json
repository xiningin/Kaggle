{"cell_type":{"8e185e55":"code","0e542e3a":"code","1fa67b43":"code","6666f15c":"code","2b1c6f21":"code","929519d5":"code","0b4bdc37":"code","86ee73ac":"code","94f3359a":"code","0a6ff2f1":"code","2013f094":"code","ba234e16":"code","a2cd8194":"code","48f0de37":"code","a9ebf3cc":"code","a866960a":"code","0d5b3526":"code","22698a77":"code","5bbe0ffc":"markdown","b0d36f0c":"markdown","b62c0a90":"markdown","35954b72":"markdown","39123fb0":"markdown","5993e032":"markdown","92c93a32":"markdown","2677e5da":"markdown","290bec35":"markdown"},"source":{"8e185e55":"import numpy as np\nimport pandas as pd\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping","0e542e3a":"train=pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ntest=pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","1fa67b43":"y_train=train['label']\ny_test=test['label']\ndel train['label']\ndel test['label']","6666f15c":"x_train=train.values\nx_test=test.values","2b1c6f21":"print(x_train.shape, x_test.shape)","929519d5":"x_train=x_train.reshape(-1,28,28,1)\nx_test=x_test.reshape(-1,28,28,1)","0b4bdc37":"# Normalize the data\nx_train = x_train \/ 255\nx_test = x_test \/ 255\n","86ee73ac":"import matplotlib.pyplot as plt\nplt.imshow(x_train[0][:,:,0],cmap='gray')\nplt.title(y_train[0])\nplt.show()","94f3359a":"import seaborn as sns\n","0a6ff2f1":"g = sns.countplot(y_train)\n\ny_train.value_counts()","2013f094":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\ny_train = label_binarizer.fit_transform(y_train)\ny_test = label_binarizer.fit_transform(y_test)","ba234e16":"y_train[0]","a2cd8194":"datagen = ImageDataGenerator(\n        rotation_range=10, \n        zoom_range = 0.1,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1)  \n\n\ndatagen.fit(x_train)","48f0de37":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)","a9ebf3cc":"model = Sequential()\nmodel.add(Conv2D(100 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units = 512 , activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units = 24 , activation = 'softmax'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","a866960a":"history = model.fit(datagen.flow(x_train,y_train, batch_size = 128) ,epochs = 30 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduction, EarlyStopping(monitor='val_accuracy', patience=3)])","0d5b3526":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.legend()\nplt.show()","22698a77":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy on test data\", score[1]*100)","5bbe0ffc":"# Data Preprocessing\n### Removing dependent column y from the dataframe. ","b0d36f0c":"# Image Augmentation\n### Image augmentation is used to prevent overfitting as it creates augmented images that help the model to learn better.\n\nRefer the documention of [ImageDataGenerator](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator)","b62c0a90":"### Check the distribution of the dataset.","35954b72":"# Importing Dataset","39123fb0":"# Model Creation and Training","5993e032":"Refer the documentation of [ReduceLROnPlateau](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/ReduceLROnPlateau)","92c93a32":"# Sign Language MNIST\n### Contents of the notebook.\n* Importing dataset.\n* Data Preprocessing.\n* Image Augmentation.\n* Model creation and training.\n* Testing model on test data.\n\n### About the dataset\n* The dataset format is patterned to match closely with the classic MNIST.\n* Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (**and no cases for 9=J or 25=Z because of gesture motions**).\n* The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, pixel1,pixel2\u2026.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.\n\n![](https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets%2F3258%2F5337%2Famer_sign2.png?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1596398964&Signature=cUKmt2o%2F060VyoeUu9jpOYUhkcJ%2F639zVXND24JizRxQ1q0qxVQYYg3OYK0huHN9prmoh1yGEkbF9H4ipkmZmbwEN5wyWC2xjhqpjArXDlv%2BWUr9i7G%2BVQiPrdr%2F06BFyooOjsjJ5t7D%2FKwgp%2BAStYtGHrOyhaOxFfJcmphxG1PYz7qGTQtJ6EL9qDn%2BdshCtI1qbJb%2FYawL9azzBSbpj86ju%2F3QSkGlitK%2BYk8R9z9ZWDC6Hpe9Z89WbTnhIPYMqgMho6GfYuEVJenAdw8bJ2fdLVUV0XL06afQseEXVxiBOrqI8W1xWcO2gm94l1qBjRL%2BmHsAI4moEHrtJv3EFA%3D%3D)","2677e5da":"### Use LabelBinarizer to convert dependent variables into [one-hot vectors](https:\/\/hackernoon.com\/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)","290bec35":"### Reshaping the Arrays so that 2D images can be formed that will be used in CNN layers."}}