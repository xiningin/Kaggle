{"cell_type":{"78afe104":"code","9ed5d38b":"code","f08bd8c7":"code","94abbc23":"code","39620f90":"code","85f85502":"code","c4402631":"code","51f2c80b":"code","74f739a1":"code","41bcac0f":"code","d25a5d13":"code","afb05837":"code","f8b1dcdf":"code","b2b8b46e":"code","32cfc733":"code","ee39a118":"code","2083fcf6":"code","6cf8d7a4":"code","ae190b7c":"markdown","f2775707":"markdown","e37de55a":"markdown","ddf8a59d":"markdown","d744d1ac":"markdown","e4116622":"markdown","337f4563":"markdown"},"source":{"78afe104":"import fastai.vision as fv","9ed5d38b":"fv.__version__","f08bd8c7":"path_test =  fv.Path('\/kaggle\/input\/test');\npath_train = fv.Path('\/kaggle\/input\/train'); path_train.ls()","94abbc23":"fv.np.random.seed(1)\n\n### \u521b\u5efaDataBunch\n\ndata = fv.ImageDataBunch.from_folder(path_train,\n                                  test=path_test, \n                                  ds_tfms=fv.get_transforms(),\n                                  valid_pct=0.25,\n                                  size=128, \n                                  bs=32,\n                                  num_workers=0)\ndata.normalize(fv.imagenet_stats)\ndata","39620f90":"learn = fv.cnn_learner(data, \n                      fv.models.resnet18, \n                      metrics=fv.error_rate,\n                      model_dir=\"\/kaggle\/working\/\")","85f85502":"learn.save('start')\n!ls .","c4402631":"print('there are ', len(learn.layer_groups), 'layer_groups in this leaner object')","51f2c80b":"\nfor g in learn.layer_groups[:]:\n    print(len(g), 'layers')\n    num_trainables = fv.np.array([hasattr(l, 'weight') for l in g]).sum()\n    print(num_trainables, 'layers with weights')\n    num_bn = fv.np.array([isinstance(l, fv.bn_types) for l in g]).sum()\n    print(num_bn, \"BN layers Not be frozen\")\n    print(num_trainables - num_bn, 'layers which can be frozen')\n    print('')\n    print(g)","74f739a1":"learn.summary()","41bcac0f":"l = learn.layer_groups[0][0]; l","d25a5d13":"learn.train_bn","afb05837":"print(fv.bn_types)\nisinstance(l, fv.bn_types)","f8b1dcdf":"fv.requires_grad(l, False)","b2b8b46e":"learn.freeze_to(0) # freeze layer group before group 0\nlearn.summary()","32cfc733":"learn.freeze_to(1) # freeze layer group before group 1\nlearn.summary()","ee39a118":"len(learn.layer_groups)","2083fcf6":"assert(len([1,2])>1)\n# assert(len([2])>1)","6cf8d7a4":"learn.create_opt?","ae190b7c":"fv.requires_grad?\n\n```python\nSignature: fv.requires_grad(m:torch.nn.modules.module.Module, b:Union[bool, NoneType]=None) -> Union[bool, NoneType]\nDocstring: If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\nFile:      \/opt\/conda\/lib\/python3.6\/site-packages\/fastai\/torch_core.py\nType:      function\n```","f2775707":"#### How many layer_groups in Resnet 18","e37de55a":"```python\nlearn.freeze??\n\nSignature: learn.freeze() -> None\nSource:   \n    def freeze(self)->None:\n        \"Freeze up to last layer group.\"\n        assert(len(self.layer_groups)>1)\n        self.freeze_to(-1)\n        self.create_opt(defaults.lr) # also create an optimizer for learner\nFile:      \/opt\/conda\/lib\/python3.6\/site-packages\/fastai\/basic_train.py\nType:      method\n```","ddf8a59d":"```python\nlearn.freeze_to??\n\n\nSignature: learn.freeze_to(n:int) -> None\nSource:   \n    def freeze_to(self, n:int)->None:\n        \"Freeze layers up to layer group `n`.\"\n        for g in self.layer_groups[:n]:\n            for l in g:\n                if not self.train_bn or not isinstance(l, bn_types): requires_grad(l, False)\n        for g in self.layer_groups[n:]: requires_grad(g, True)\n        self.create_opt(defaults.lr)\nFile:      \/opt\/conda\/lib\/python3.6\/site-packages\/fastai\/basic_train.py\nType:      method\n```","d744d1ac":"The `freeze_to` source code can be understood as the following pseudo-code:\n```python\ndef freeze_to(self, n:int)->None:\n    for g in self.layer_groups[:n]: freeze \n    for g in self.layer_groups[n:]: unfreeze\n```    \nIn other words, for example, `freeze_to(1)` is to freeze layer group 0 and unfreeze the rest layer groups, and `freeze_to(3)` is to freeze layer groups 0, 1, and 2 but unfreeze the rest layer groups (if there are more layer groups left).       \n\nBoth `freeze` and `unfreeze` [sources](https:\/\/github.com\/fastai\/fastai\/blob\/master\/fastai\/basic_train.py#L216) are defined using `freeze_to`:    \n- When we say `freeze`, we mean that in the specified layer groups the `requires_grad` of all layers with weights (except BatchNorm layers) are set `False`, so the layer weights won't be updated during training.     \n- when we say `unfreeze`, we mean that in the specified layer groups the `requires_grad` of all layers with weights (except BatchNorm layers) are set `True`, so the layer weights will be updated during training.","e4116622":"You can experiment `freeze_to`, `freeze` and `unfreeze` with the following experiment.","337f4563":"```python\nlearn.unfreeze??\n\nSignature: learn.unfreeze()\nSource:   \n    def unfreeze(self):\n        \"Unfreeze entire model.\"\n        self.freeze_to(0)\n        self.create_opt(defaults.lr) # then create an optimizer for learner\nFile:      \/opt\/conda\/lib\/python3.6\/site-packages\/fastai\/basic_train.py\nType:      method\n```"}}