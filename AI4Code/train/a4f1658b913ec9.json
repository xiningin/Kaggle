{"cell_type":{"db8ce0b8":"code","24c2f405":"code","00a92200":"code","52150814":"code","d5d0bdd5":"code","76cf0201":"code","42f01a9d":"code","6ea2fe57":"code","8b1e9074":"code","3500a0ce":"markdown","b0df7e9e":"markdown","d5f5bd0b":"markdown","fe88ae74":"markdown","6ea2cfab":"markdown"},"source":{"db8ce0b8":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nprint(tf.__version__)","24c2f405":"# preparing data\n\nTRAIN_DIR = \"..\/input\/dogs-vs-cats\/train\/train\"\nTEST_DIR = \"..\/input\/dogs-vs-cats\/test1\/test1\"\n\nTRAIN_SIZE = len([name for name in os.listdir(TRAIN_DIR)])\nTEST_SIZE = len([name for name in os.listdir(TEST_DIR)])\nprint(\"Number of training images:\", TRAIN_SIZE)\nprint(\"Number of test images:\", TEST_SIZE)\n\nVALID_FRACTION = 0.2\nBATCH_SIZE = 100\nEPOCHS = 50\n\nIMAGE_WIDTH = IMAGE_HEIGHT = 150\n\n# creating df with train labels\ntrain_filenames = os.listdir(TRAIN_DIR)\ntrain_labels = []\nfor filename in train_filenames:\n    label = filename.split('.')[0]\n    train_labels.append(label)\n\ntrain_df = pd.DataFrame({\n    'id': train_filenames,\n    'label': train_labels\n})\n\n# splitting to train & valid\ntrain_df, valid_df = train_test_split(train_df, test_size=VALID_FRACTION)\n\n# augmentation settings, for now just normalizing\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(    \n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    rescale=1.\/255.,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n    )\n\n# not doing any data augmentation on validation test set\nvalid_datagen  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255.)\n\n# creating train and valid generators (not using valid_split to avoid doing data augmentation on validation set)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    TRAIN_DIR, \n    x_col='id',\n    y_col='label',\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    class_mode='binary',\n    batch_size=BATCH_SIZE\n)\n\nvalid_generator = valid_datagen.flow_from_dataframe(\n    valid_df, \n    TRAIN_DIR, \n    x_col='id',\n    y_col='label',\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    class_mode='binary',\n    batch_size=BATCH_SIZE\n)","00a92200":"model = tf.keras.models.Sequential([\n    # the images were resized by ImageDataGenerator 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # since we have only 2 classes to predict we can use 1 neuron and sigmoid\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])\n\nmodel.summary()\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n    loss='binary_crossentropy',\n    metrics = ['accuracy'])\n\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n    mode='min',\n    restore_best_weights=True, \n    verbose=1,\n    patience=5)","52150814":"tf.keras.utils.plot_model(model)","d5d0bdd5":"%%time\n\n# training\nhistory = model.fit_generator(train_generator,\n    validation_data=valid_generator,\n    steps_per_epoch=round(TRAIN_SIZE*(1.-VALID_FRACTION)\/BATCH_SIZE),\n    validation_steps=round(TRAIN_SIZE*VALID_FRACTION\/BATCH_SIZE),\n    epochs=EPOCHS,\n    callbacks=[es],\n    verbose=1)","76cf0201":"#plotting\n\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc = history.history['accuracy']\nval_acc = history.history[ 'val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Training and validation loss')","42f01a9d":"%%time\n\n# preparing testing data\ntest_filenames = os.listdir(TEST_DIR)\ntest_df = pd.DataFrame({\n    'id': test_filenames\n})\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0\/255.)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df, \n    TEST_DIR, \n    x_col='id',\n    y_col=None,\n    class_mode=None,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\nyhat = model.predict_generator(test_generator, steps=np.ceil(TEST_SIZE\/BATCH_SIZE))","6ea2fe57":"# sigmoid returns probability between 0 and 1, need to convert it to an integer class\nyhat = [1 if y > 0.5 else 0 for y in yhat]\n\ntest_df['label'] = yhat\n\n# restoring back to class names (dog|cat)\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['label'] = test_df['label'].replace(label_map)\n\n# encoding according to submission format, 1 = dog, 0 = cat\ntest_df['label'] = test_df['label'].replace({ 'dog': 1, 'cat': 0 })\n\ntest_df.to_csv('submission.csv', index=False)","8b1e9074":"test_df.head()","3500a0ce":"# Creating model","b0df7e9e":"# Generating predictions","d5f5bd0b":"# Preparing data","fe88ae74":"# Training","6ea2cfab":"# Creating submission file"}}