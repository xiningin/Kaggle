{"cell_type":{"850c78c1":"code","cf02471d":"code","f27c6e01":"code","de65c25a":"code","18fb22a8":"code","f485eaad":"code","08836374":"code","5dab8a8e":"code","977dd52f":"code","ec232f13":"code","fe950270":"code","5c86a252":"code","94c1fb21":"code","d75d2596":"code","6f4bcd9b":"code","8f52569c":"code","158a2cf5":"code","4a29ba95":"code","23783cbb":"code","c60862e0":"code","c5d97bf5":"code","a48f27e0":"code","e31a706c":"code","82ce0a6c":"code","c0b314b2":"code","450ee51e":"markdown","0e04dcc6":"markdown","f5db1cc5":"markdown","4365503b":"markdown","61c565b3":"markdown","321740a8":"markdown","ace71bc5":"markdown","e6d57d42":"markdown","48e5b57e":"markdown","a309c95c":"markdown","6f7c0a06":"markdown","e3658e6f":"markdown"},"source":{"850c78c1":"pip install seaborn==0.11.0","cf02471d":"import pandas as pd\nimport numpy as np\n#  load the dataset and mark the gaps\ndata = pd.read_csv('\/kaggle\/input\/sanfranciso-crime-dataset\/Police_Department_Incidents_-_Previous_Year__2016_.csv')\nfor column in data:\n    data[column] = data[column].apply(lambda x: np.nan if x == \"NONE\" else x)","f27c6e01":"#  remove uninformative signs\ndata = data[data.columns[1:-4]]\ndata = data.drop([\"Resolution\"], axis=1)\n#  remove duplicates and gaps\ndata = data.drop_duplicates().dropna()\n#  we will convert the time into a convenient format\ndata[\"Date\"] = pd.to_datetime(data[\"Date\"])\ndata[\"Time\"] = pd.to_datetime(data[\"Time\"])\n#  Let's add a new feature\ndata[\"Month\"] = data[\"Date\"].dt.month","de65c25a":"#  Let's bring the lines back to normal form\ndata[\"Address\"] = data[\"Address\"].apply(lambda x: x.strip().lower() \\\n                                        .replace(\".\", \"\") \\\n                                        .replace('\\\\.', '') \\\n                                        .replace('\\\\bstreet\\\\b', 'st') \\\n                                        .replace('\\\\bapartment\\\\b', 'apt') \\\n                                        .replace('\\\\bav\\\\b', 'ave'))\n\n#  Pull all the streets out of the lines\ndata[\"Address2\"] = data[\"Address\"].apply(lambda x: x[x.index(\"of\")+2:].strip() if \"\/\" not in x else x[x.index(\"\/\")+1:].strip())","18fb22a8":"data.head()","f485eaad":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12, 7))\nsns.histplot(data.Date)","08836374":"plt.figure(figsize=(12, 7))\nsns.histplot(data.Time)","5dab8a8e":"en = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September',\n          'October', 'November', 'December']\n\nweek = ['Sunday', \n        'Monday', \n        'Tuesday', \n        'Wednesday', \n        'Thursday',  \n        'Friday', \n        'Saturday']\n\ntemp_data = []\n\nfor month in range(1, 13):\n    temp = data[data.Month == month][\"DayOfWeek\"].value_counts()\n    summary = sum(temp.to_list())\n    #print(f\"Month : {en[month - 1]}\")\n    zipped = zip(temp.index, temp.values)\n    zipped = sorted(zipped, key=lambda x: week.index(x[0]))\n    #s = \"{} {} {} {} {} {} {}\".format(*[i[0] for i in zipped])\n    #print(s)\n    temp_data.append([round(i[1] \/ summary * 100, 2) for i in zipped])\n    #print(\"{:.2%} {:.2%} {:^7.2%} {:^9.2%} {:^8.2%} {:.2%} {:^8.2%}\".format(*[i[1] \/ summary for i in zipped]))\n    #print(\"-\" * len(s))\n\ndf = pd.DataFrame(index=en, columns=week, data=temp_data)\ndf","977dd52f":"plt.figure(figsize=(15, 10))\nsns.heatmap(df.corr(), annot=True)","ec232f13":"temp = data[\"DayOfWeek\"].value_counts()\nsummary = sum(temp.to_list()) \nprint(\"{:^29}\".format(\"DayOfWeek\"))\nprint(\"-\" * 29)\ntemp_data = []\nfor name, value in zip(temp.index, temp.values):\n    temp_data.append(round(value \/ summary * 100, 2))\n    print(\"Coefficient {:<9}: {:.2%}\".format(name, value \/ summary))\ndf = pd.DataFrame(index=temp.index, columns=[\"coefficient\"], data=temp_data)","fe950270":"labels = df.index\nsizes = df.coefficient\nexplode = (0.2, 0, 0, 0, 0, 0, 0)\n\nfig1, ax1 = plt.subplots(figsize=(10, 7), dpi=70)\n\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nax1.legend(labels, loc=\"upper right\") \nplt.tight_layout()\nplt.title(\"DayOfWeek\")\nplt.show()","5c86a252":"t = data.Address2.value_counts()\ndf = pd.DataFrame(data=t.values, index=t.index, columns=['coefficient'])\nsummary = sum(t.values)\ndf[\"coefficient\"] = round(df[\"coefficient\"] \/ summary * 100, 2)\ndf.head()","94c1fb21":"labels = df.index[:10]\nsizes = df.coefficient[:10]\nexplode = ([0.1]*3 + [0]*(len(labels) - 3))\n\nfig1, ax1 = plt.subplots(figsize=(10, 7), dpi=70)\n\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nax1.legend(labels, loc=\"upper right\") \nplt.tight_layout()\nplt.title(\"Top 10 streets\")\nplt.show()","d75d2596":"plt.figure(figsize=(7, 5), dpi=90)\nsns.boxenplot(data=df[\"coefficient\"])","6f4bcd9b":"t = df[df[\"coefficient\"] <= 1.1].median()[0]\nprint(f\"A street can be considered safe if its index <= {t}\")","8f52569c":"t = data.Descript.value_counts()\ndf = pd.DataFrame(data=t.values, index=t.index, columns=['coefficient'])\nsummary = sum(t.values)\ndf[\"coefficient\"] = round(df[\"coefficient\"] \/ summary * 100, 2)\ndf.head()","158a2cf5":"plt.figure(figsize=(7, 5), dpi=90)\nsns.boxenplot(data=df[\"coefficient\"])","4a29ba95":"t = df[df[\"coefficient\"] <= 3].median()[0]\nprint(f\"The crime can be considered significant if x >= {t}\")","23783cbb":"t = data.Category.value_counts()\ndf = pd.DataFrame(data=t.values, index=t.index, columns=['coefficient'])\nsummary = sum(t.values)\ndf[\"coefficient\"] = round(df[\"coefficient\"] \/ summary * 100, 2)\ndf.head()","c60862e0":"labels = df.index[:10]\nsizes = df.coefficient[:10]\nexplode = ([0.1] + [0]*(len(labels) - 1))\n\nfig1, ax1 = plt.subplots(figsize=(10, 7), dpi=70)\n\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=80)\nax1.axis('equal')\nax1.legend(labels, loc=\"upper right\") \nplt.title(\"Top 10 Categories\")\nplt.tight_layout()\nplt.show()","c5d97bf5":"plt.figure(figsize=(7, 5), dpi=90)\nsns.boxenplot(data=df[\"coefficient\"])","a48f27e0":"m = data[\"Address\"].apply(lambda x: int(x[:x.index(\"block of\")].strip()) if \"block of\" in x else np.nan).sort_values().median()\nprint(f\"Median height of buildings where the crimes took place (as indicated): {round(m)}\")","e31a706c":"t = data.PdDistrict.value_counts()\ndf = pd.DataFrame(data=t.values, index=t.index, columns=['coefficient'])\nsummary = sum(t.values)\ndf[\"coefficient\"] = round(df[\"coefficient\"] \/ summary * 100, 2)\ndf","82ce0a6c":"labels = df.index[:10]\nsizes = df.coefficient[:10]\nexplode = ([0.1] + [0]*(len(labels) - 1))\n\nfig1, ax1 = plt.subplots(figsize=(10, 7), dpi=70)\n\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=80)\nax1.axis('equal')\nax1.legend(labels, loc=\"upper right\") \nplt.title(\"Top 10 dangerous areas\")\nplt.tight_layout()\nplt.show()","c0b314b2":"import folium\nt = data.PdDistrict.value_counts()\ndf = pd.DataFrame(data=t.values, index=t.index, columns=['count'])\ndf = df.reset_index()\ndf.rename({'index': 'Neighborhood'}, axis='columns', inplace=True)\n\ngjson = r'https:\/\/cocl.us\/sanfran_geojson'\nsf_map = folium.Map(location=[37.77, -122.42], zoom_start=12)\nsf_map.choropleth(\n    geo_data=gjson,\n    data=df,\n    columns=['Neighborhood', 'count'],\n    key_on='feature.properties.DISTRICT',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Crime Rate in San Francisco'\n)\nsf_map","450ee51e":"Most common - car theft (11.74%)","0e04dcc6":"# Preparing data for processing\n\n> Cleaning\n\n> Elimination of unnecessary signs\n\n> Processing addresses\n\n> Creation of new features","f5db1cc5":"Most dangerous area - SOUTHERN\n\nThe safest - PARK","4365503b":"Let's look at the distribution of our data and the number of their occurrences in time","61c565b3":"We see that the following features correlate with each other (significant at x> = 0.5):\n\nFriday - Saturday = 0.58\n\nWednesday - Tuesday = 0.5\n\nWe conclude that if a crime occurred on one day of the pair, then there is a great chance that on the other day there will be a crime from the pair.","321740a8":"The most dangerous streets: mission, market, bryant\n\nIt can be seen that there are outliers in the data - these are the first 5 values","ace71bc5":"For each month, find the coefficient of occurrence of the day of the week to look at the correlation between them","e6d57d42":"# Analytical part\n\n\n> Charts\n\n> Conclusions","48e5b57e":"# Conclusions:\n\n1. Data is evenly distributed\n2. Safe time: 3 - 7 am\n\n   Dangerous time: 17 - 19 pm\n4. The \"Friday - Saturday\" and \"Wednesday - Tuesday\" have a mathematical relationship\n\n     If a crime occurred on one day of the pair, then there is a great chance that on the other day there will be a crime from the pair.\n\n5. Most crimes occurred on Friday\n6. The most dangerous streets: mission, market, bryant\n7. The most common crime is car theft (11.74%)\n8. The most dangerous area - SOUTHERN\n\n     The safest - PARK\n9. Most frequent crimes: LARCENY\/THEFT, OTHER OFFENSES, NON-CRIMINAL, ASSAULT, VANDALISM\n10. Median height of buildings where crimes occurred (as indicated): 700","a309c95c":"There are a lot of outliers in the data, it's hard to say anything concrete\n\nMost frequent crimes: LARCENY\/THEFT, OTHER OFFENSES, NON-CRIMINAL, ASSAULT, VANDALISM","6f7c0a06":"Conclusion: Friday was the most frequent crime scene","e3658e6f":"Note that the data is not described by a normal distribution, which means that the null hypothesis of data normality can be rejected.\n\nIt can be seen from the graph that the greatest number of crimes occurs between 17 - 19 pm\n\nThe safest time is between 3 - 7 am"}}