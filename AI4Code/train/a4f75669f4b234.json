{"cell_type":{"2c5229ed":"code","54039d4d":"code","1fd841b2":"code","5166648d":"code","631e7b5c":"code","adf5b4a5":"code","60f234c2":"code","45796d15":"code","b76f75a2":"code","ecabbdb7":"code","0b461014":"markdown","1f9af2a6":"markdown","7ad6f7d8":"markdown","afdff01c":"markdown","ed564c28":"markdown","5a0d2071":"markdown","dfbe11bb":"markdown","dd8596e5":"markdown","f0ab6478":"markdown","98d8a08f":"markdown","9eebc99b":"markdown","f304f106":"markdown","a0884907":"markdown","4a9c62ed":"markdown","a49c8fc8":"markdown","bd16d6ec":"markdown","2a4e7065":"markdown","2db45048":"markdown"},"source":{"2c5229ed":"# import the necessary libraries \nimport nltk \nimport string \nimport re ","54039d4d":"def text_lowercase(text): \n    return text.lower() \n\ninput_str = \"HEY, how are you? this is an example to CONVERT text to LOWERCASe!!\"\ntext_lowercase(input_str) ","1fd841b2":"# Remove numbers \ndef remove_numbers(text): \n    result = re.sub(r'\\d+', '', text) \n    return result \n  \ninput_str = \"There are so many cars in this city87659\"\nremove_numbers(input_str) ","5166648d":"# import the inflect library \nimport inflect \np = inflect.engine() \n\n# convert number into words \ndef convert_number(text): \n    # split string into list of words \n    temp_str = text.split() \n    # initialise empty list \n    new_string = [] \n\n    for word in temp_str: \n        # if word is a digit, convert the digit to numbers and append into the new_string list \n        if word.isdigit(): \n            temp = p.number_to_words(word) \n            new_string.append(temp) \n\n        # append the word as it is \n        else: \n            new_string.append(word) \n\n    # join the words of new_string to form a string \n    temp_str = ' '.join(new_string) \n    return temp_str \n\ninput_str = 'We ordered 10 pizzas and ate 9 of them'\nconvert_number(input_str) ","631e7b5c":"# remove punctuation \ndef remove_punctuation(text): \n    translator = str.maketrans('', '', string.punctuation) \n    return text.translate(translator) \n\ninput_str = \"What a lovely day! Just a day, at a time.\"\nremove_punctuation(input_str) ","adf5b4a5":"# remove whitespace from text \ndef remove_whitespace(text): \n    return \" \".join(text.split()) \n\ninput_str = \"Why don't     we go to    the beach     \"\nremove_whitespace(input_str) \n","60f234c2":"from nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \n\n# remove stopwords function \ndef remove_stopwords(text): \n    stop_words = set(stopwords.words(\"english\")) \n    word_tokens = word_tokenize(text) \n    filtered_text = [word for word in word_tokens if word not in stop_words] \n    return filtered_text \n\nexample_text = \"This is an example and we are going to remove the stopwords from this.\"\nremove_stopwords(example_text) ","45796d15":"from nltk.stem.porter import PorterStemmer \nfrom nltk.tokenize import word_tokenize \nstemmer = PorterStemmer() \n\n# stem words in the list of tokenised words \ndef stem_words(text): \n    word_tokens = word_tokenize(text) \n    stems = [stemmer.stem(word) for word in word_tokens] \n    return stems \n\ntext = 'Stemming is the process of getting the root form of a word'\nstem_words(text) \n","b76f75a2":"nltk.download('wordnet')","ecabbdb7":"from nltk.stem import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize \nlemmatizer = WordNetLemmatizer() \n# lemmatize string \ndef lemmatize_word(text): \n    word_tokens = word_tokenize(text) \n    # provide context i.e. part-of-speech \n    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n    return lemmas \n\ntext = 'Stemming is the process of getting the root form of a word'\nlemmatize_word(text) \n","0b461014":"We lowercase the text so that the words LOWER, lower and LOwer have the same tagging and are considered as one word.","1f9af2a6":"### Remove whitespaces","7ad6f7d8":"If the analysis does not require number data then we can ger rid of it.\n","afdff01c":"We can also convert the numbers into words. This can be done by using the inflect library.","ed564c28":"Stemming is the process of getting the root form of a word. Stem or root is the part to which inflectional affixes (-ed, -ize, -de, -s, etc.) are added.\nThere are mainly three algorithms for stemming. These are the Porter Stemmer, the Snowball Stemmer and the Lancaster Stemmer. Porter Stemmer is the most common among them.","5a0d2071":"### Stemming","dfbe11bb":"### Convert numbers","dd8596e5":"We need to remove unnecessary whitespaces in the text","f0ab6478":"### Text lowercase","98d8a08f":"Stopwords are words that do not contribute to the meaning of a sentence. They can safely be removed without causing any change in the meaning of the sentence. The NLTK library has a set of stopwords and we can use these to remove stopwords from our text and return a list of word tokens.","9eebc99b":"### Remove numbers","f304f106":"We remove punctuations so that all the words are treated in the same way- hello! hello, hello. hello; should all have the same tagging","a0884907":"When our data contains text data, we need to apply pre-processing steps to transform the textual words into numerical features that can be used with machine learning algorithms. \nIn this notebook, we will explore text preprocessing techniques in Python using the NLTK (Natural Language Toolkit) library.\n\nLet's begin!","4a9c62ed":"### Lemmatization","a49c8fc8":"Lemmatization also converts a word to its root form. The only difference is that lemmatization ensures that the root word belongs to the language. We will get valid words if we use lemmatization.","bd16d6ec":"### Remove punctuations","2a4e7065":"### Remove default stopwords","2db45048":"![![stopwords%20nltk.JPG](attachment:stopwords%20nltk.JPG)](http:\/\/)"}}