{"cell_type":{"f5a9f422":"code","62bc2e16":"code","5e6f80ce":"code","83c6cd99":"code","b82297ea":"code","bee33f68":"code","cdd38b20":"code","cd85f0e5":"code","248f221b":"code","a5ef3ad7":"code","bf6f4c69":"markdown","7c2a83d2":"markdown"},"source":{"f5a9f422":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","62bc2e16":"#reading the files\ntrain = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\ntest = pd.read_csv(\"..\/input\/learn-together\/test.csv\")\n\ny = train.Cover_Type\ntest_id = test['Id']","5e6f80ce":"##PREPROCESSING\nimport pickle\n\nif os.path.isfile(\"X.pickle\"):\n    with open( \"X.pickle\", \"rb\" ) as fh1:\n        X = pickle.load(fh1)\n    with open('test.pickle', 'rb') as fh2:\n        test = pickle.load(fh2)\nelse:\n    #dropping Soil_Type7 and Soil_Type15\n    train = train.drop(['Id','Soil_Type7', 'Soil_Type15'], axis = 1)\n    test_id = test['Id']\n    test = test.drop(['Id','Soil_Type7', 'Soil_Type15'], axis = 1)\n\n    #prepare data for training the model\n    X = train.drop(['Cover_Type'], axis = 1)\n\n    #reducing Soil_Type cols to single col \n    X = X.iloc[:, :14].join(X.iloc[:, 14:].dot(range(1,39)).to_frame('Soil_Type1'))\n    test = test.iloc[:, :14].join(test.iloc[:, 14:].dot(range(1,39)).to_frame('Soil_Type1'))\n    #print(X.columns)\n    #reducing Wilderness_Area to single col \n    X = X.iloc[:,:10].join(X.iloc[:,10:-1].dot(range(1,5)).to_frame('Wilderness_Area1')).join(X.iloc[:,-1])\n    test = test.iloc[:,:10].join(test.iloc[:,10:-1].dot(range(1,5)).to_frame('Wilderness_Area1')).join(test.iloc[:,-1])\n\n    #horizontal and vertical distance to hydrology can be easily combined\n    cols = ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology']\n    X['Distance_to_hydrology'] = X[cols].apply(np.linalg.norm, axis=1)\n    X = X.drop(cols, axis = 1)\n    test['Distance_to_hydrology'] = test[cols].apply(np.linalg.norm, axis=1)\n    test = test.drop(cols, axis = 1)\n\n    #shot in the dark - convert like colour tuples to grayscale\n    cols = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    weights = pd.Series([0.299, 0.587, 0.114], index=cols)\n    X['Hillshade'] = (X[cols]*weights).sum(1)\n    X = X.drop(cols, axis = 1)\n    test['Hillshade'] = (test[cols]*weights).sum(1)\n    test = test.drop(cols, axis=1)\n\n    #pickling data for quick access\n    with open('X.pickle', 'wb') as fh1:\n        pickle.dump(X, fh1)\n    with open('test.pickle', 'wb') as fh2:\n        pickle.dump(test, fh2)\n\nprint(X.columns)","83c6cd99":"#split data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","b82297ea":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nmodel = RandomForestClassifier(n_estimators=100)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_val)\nval_mae = mean_absolute_error(y_val,y_pred)\nprint('Sixth try mae of RFClassifier with base parameters: ', val_mae)","bee33f68":"print('Random search','-'*20)\n#preparing model\nfrom sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 11)]\n#n_estimators = [100, 125, 150, 180, 200, 250]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n#max_depth =  [50, 60, 70, 80, 90, 100]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","cdd38b20":"rf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                    n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, y_train)\nprint('rf_random.best_params_:',rf_random.best_params_)","cd85f0e5":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors \/ test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    return accuracy\n\nprint('Base model','-'*20)\nbase_model = model\nbase_model.fit(X_train, y_train)\nbase_accuracy = evaluate(base_model, X_val, y_val)\nprint('Random search estimator','-'*20)\nbest_random = rf_random.best_estimator_\nrandom_accuracy = evaluate(best_random,  X_val, y_val)","248f221b":"y_pred = best_random.predict(X_val)\nval_mae = mean_absolute_error(y_val,y_pred)\nprint('Sixth try mae with RS RFClassifier: ', val_mae)","a5ef3ad7":"test_pred = best_random.predict(test)\noutput = pd.DataFrame({'Id': test_id, 'Cover_Type': test_pred.astype(int)})\noutput.to_csv('submission.csv', index=False)","bf6f4c69":"# With nothing better to do - tuning the classifier parameters","7c2a83d2":"## Not applying gridsearch as it is taking ages - not the best tool for a noob."}}