{"cell_type":{"ed0ad89c":"code","dbfa8f46":"code","8be95c0f":"code","b51076d2":"code","b10e59e2":"code","2af8044d":"code","44659f68":"code","cf1bf058":"code","e9c84b11":"code","f5fafd33":"code","54c540fa":"code","ac1905cd":"code","37f87683":"code","0a987598":"code","3ccb67ef":"code","ecaad757":"code","b611f69d":"code","65470c0f":"code","b0a09781":"markdown","6df7a559":"markdown","3c11b5eb":"markdown","1713c53e":"markdown","faca55d8":"markdown","66f57f2b":"markdown","fe4cf910":"markdown","939a1290":"markdown","a750f920":"markdown","bd6e9f48":"markdown","7c827214":"markdown","54f7435b":"markdown","46e714b5":"markdown","69dbe976":"markdown","13357124":"markdown","23206cbc":"markdown","2b586091":"markdown","dd5ff54c":"markdown","235838ba":"markdown","4693dba3":"markdown","dd24350f":"markdown","29fbf7b2":"markdown","e7b75520":"markdown","a86fe0e2":"markdown"},"source":{"ed0ad89c":"#import necessary modules\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\n\nseed =1 #for reproductability\nnp.random.seed(seed)\n\n# read data\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nprint(train.shape)\nprint(test.shape)","dbfa8f46":"# use float values\nXtrain = (train.iloc[:, 1:].values).astype('float32')\nytrain = (train.iloc[:, 0].values).astype('int32')\nXtest = test.values.astype('float32')\n\n#reshape data into 28x28 samples\nXtrain = Xtrain.reshape(Xtrain.shape[0],28,28)\nXtest = Xtest.reshape(Xtest.shape[0],28,28)\nprint(Xtrain.shape)\nprint(Xtest.shape)","8be95c0f":"# example of images\ndef showImages(X, n):\n  images = X.shape[0]\n  steps = n*n\n  step = int(images\/steps)\n\n  plt.figure(figsize=(7,7))\n  plt.title('Examples of images')\n\n  for i in range(steps):\n    plt.subplot(n,n,i+1)\n    plt.imshow(X[i*step])\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n  plt.show()\n\nshowImages(Xtrain, 12)","b51076d2":"#standarize\nmean = Xtrain.mean().astype(np.float32)\nstd = Xtrain.std().astype(np.float32)\ndef standarize(X):\n  return (X-mean)\/std\n\nXtrain = standarize(Xtrain)\nXtest = standarize(Xtest)\n","b10e59e2":"#build categorical output\nprint(\"output exaples:\", ytrain[0:20])\nytrain = keras.utils.to_categorical(ytrain)\nnum_classes = ytrain.shape[1]\nprint(\"output categorized examples\", ytrain[0:5])","2af8044d":"Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.10, random_state=1)\nprint(Xtrain.shape)\nprint(Xval.shape)","44659f68":"#simple multiperceptron model\ndef MultiPerceptronModel():\n  model = keras.Sequential()\n  model.add(keras.layers.Flatten(input_shape=(28,28)))\n  model.add(keras.layers.Dense(10, activation='softmax'))\n  model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n  return model\nmodel=MultiPerceptronModel()\nprint(model.summary())","cf1bf058":"#set number of epochs\nep = 5    \nhist = model.fit(Xtrain, ytrain, epochs=ep, verbose=1)\nprint(\"loss:\", hist.history['loss'][ep-1], \"acc:\", hist.history['accuracy'][ep-1])","e9c84b11":"def validate(model, Xval):\n  ypred = model.predict_classes(Xval, verbose=0)\n  metrics = keras.metrics.Accuracy()\n  metrics.update_state(ypred, np.argmax(yval, axis=1))\n  print(\"Validation accuracy:\", metrics.result().numpy())\n\nvalidate(model, Xval)","f5fafd33":"def NeuralNetworkModel():\n  model = keras.Sequential()\n  model.add(keras.layers.Flatten(input_shape=(28,28)))\n  model.add(keras.layers.Dense(512, activation='relu'))\n  model.add(keras.layers.Dense(256, activation='relu'))\n  model.add(keras.layers.Dense(96, activation='relu'))\n  model.add(keras.layers.Dense(24, activation='relu'))\n  model.add(keras.layers.Dense(10, activation='softmax'))\n  print(\"input shape \",model.input_shape)\n  print(\"output shape \",model.output_shape)\n  #model.compile(optimizer=keras.optimizers.RMSprop(lr=0.001),\n  model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n  return model;\n\nmodel=NeuralNetworkModel()\nprint(model.summary())","54c540fa":"#fit model\nep = 5    \nhist = model.fit(Xtrain, ytrain, epochs=ep, verbose=1)\nprint(\"loss:\", hist.history['loss'][ep-1], \"acc:\", hist.history['accuracy'][ep-1])\n#validate model\nvalidate(model, Xval)","ac1905cd":"def ConvNeuralNetworkModel():\n  model = keras.Sequential()\n  model.add(keras.layers.Convolution2D(32, (3, 3), activation='relu'))\n  model.add(keras.layers.Convolution2D(32, (3, 3), activation='relu'))\n  model.add(keras.layers.MaxPooling2D())\n  model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n  model.add(keras.layers.Convolution2D(64, (3, 3), activation='relu'))\n  model.add(keras.layers.MaxPooling2D())\n  model.add(keras.layers.Flatten())\n  model.add(keras.layers.Dense(512, activation='relu'))\n  model.add(keras.layers.Dense(10, activation='softmax'))\n  #gen = keras.preprocessing.image.ImageDataGenerator()\n  model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n  return model\n\nmodel=ConvNeuralNetworkModel()","37f87683":"Xtrain = Xtrain.reshape(Xtrain.shape[0], 28, 28,1)\nXval = Xval.reshape(Xval.shape[0], 28, 28,1)\nXtest = Xtest.reshape(Xtest.shape[0], 28, 28,1)\nprint(Xtrain.shape)","0a987598":"ep = 5   \n#verbose is set to verbose=0, because it generates to much logs\nhist = model.fit(Xtrain, ytrain, epochs=ep, verbose=0)\nprint(\"loss:\", hist.history['loss'][ep-1], \"acc:\", hist.history['accuracy'][ep-1])\n#validate model\nvalidate(model, Xval)\n","3ccb67ef":"print(model.summary())","ecaad757":"def ConvNeuralNetworkFitModel():\n  fitlayer = keras.layers.Dropout(0.1)\n  #fitlayer = keras.layers.BatchNormalization()\n  model = keras.Sequential()\n  model.add(keras.layers.Convolution2D(32, (3, 3), activation='relu'))\n  model.add(fitlayer)\n  model.add(keras.layers.Convolution2D(32, (3, 3), activation='relu'))\n  model.add(keras.layers.MaxPooling2D())\n  model.add(fitlayer)\n  model.add(keras.layers.Convolution2D(64, (3, 3), padding='same', activation='relu'))\n  model.add(fitlayer)\n  model.add(keras.layers.Convolution2D(64, (3, 3), padding='same', activation='relu'))\n  model.add(keras.layers.MaxPooling2D())\n  model.add(fitlayer)\n  model.add(keras.layers.Flatten())\n  model.add(keras.layers.Dense(512, activation='relu'))\n  model.add(fitlayer)\n  model.add(keras.layers.Dense(10, activation='softmax'))\n  model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n  return model;\n\nmodel = ConvNeuralNetworkFitModel()","b611f69d":"#use image generator\ngen = keras.preprocessing.image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, shear_range=0.3,\n                         height_shift_range=0.1, zoom_range=0.1)\nbatches = gen.flow(Xtrain, ytrain, batch_size=64)\nval_batches = gen.flow(Xval, yval, batch_size=64)\n","65470c0f":"#set number of epochs\nep = 5  \n#verbose is set to verbose=0, because it generates to much logs\nmodel.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=ep, verbose=0,\n                    validation_data=val_batches, validation_steps=val_batches.n)\nprint(\"loss:\", hist.history['loss'][ep-1], \"acc:\", hist.history['accuracy'][ep-1])\n#validate model\nvalidate(model, Xval)","b0a09781":"Standarize input values","6df7a559":"This kernel shows how to build keras models for digit recognition from perceptron to advanced CNN models\n","3c11b5eb":"See the model structure","1713c53e":"Simple perceptron has quite good accuracy about 0.92. Validation is a bit smaller. It suggest slight overfitting.","faca55d8":"Split train values for validation purposes","66f57f2b":"Fit and validate model","fe4cf910":"Fit model","939a1290":"1. Prepare and visualize data","a750f920":"1. Addvanced CNN model with dropout\/batch normaliztion and augmentation","bd6e9f48":"1. Neural network model\n\nI prepared NN model where number of parameters decresses in each hidden layer.","7c827214":"Fit and validate model","54f7435b":"6. Next steps\n\nCNN with dropout and 50 epochs can give up to 99.4%. You can test it with diffrent values of dropout, epochs, or other mmeta parameters like structure of CNN.\n\nDon't forget predict results for Xtest output and submit it.\n\nGood luck and thank you.","46e714b5":"Change output from 0-9 values to categorized output","69dbe976":"Fit and validate model","13357124":"1. Convolutional neural network (CNN) model ","23206cbc":"Validate results","2b586091":"Organize data","dd5ff54c":"CNN and next models use resahped input structure","235838ba":"Accuracy is much better than for perceptron. But overfitting is also visible 98.1% versus 96.9%.","4693dba3":"1. Perceptron\n\nIn case of digits there is 0-9 output. Instead of simple perceptron whre there is only 0 or 1 output, here correct output is chosen using softmax function","dd24350f":"Adding augmentation.","29fbf7b2":"Show digit examples","e7b75520":"Import necessary modules and files","a86fe0e2":"Accuracy is again higher, but overfiting is still to high"}}