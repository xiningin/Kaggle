{"cell_type":{"a2e3a965":"code","d13026b5":"code","b128e10a":"code","c590b1e2":"code","c82b9d84":"code","04e071be":"code","85852ed0":"code","4c0e2ae3":"code","7616d194":"code","a6a12aa1":"code","6edabbc5":"code","6bdc48b7":"code","35146617":"code","09b885e0":"code","7ffe6291":"code","ff1fbca6":"code","f640ea0a":"code","b78697ab":"code","c0fa11b8":"code","97ebf513":"code","c13be547":"code","2ab4371c":"code","ec4729c2":"code","6816f035":"code","ca7af81a":"code","04141533":"code","de565b96":"code","26542740":"code","be8e0a96":"code","e5bdc9d0":"code","d57b7ffd":"code","276ea0c8":"code","b5a246e9":"code","ff7bc8cb":"code","7621e0af":"code","ab1e5162":"code","11b6f657":"code","4a6ae978":"code","ce71997c":"code","fd3051c4":"code","9bbd0df3":"code","fe26f11e":"code","5c410b6f":"code","7bfbd593":"code","d90b1efa":"code","4a0946e1":"code","da99fda5":"code","7f19eac2":"markdown","0211335a":"markdown","f5c2cae7":"markdown","f6040b00":"markdown","305d4796":"markdown","78bb3089":"markdown","c058454a":"markdown","3a913ae2":"markdown","1be68290":"markdown"},"source":{"a2e3a965":"!pip install git+https:\/\/github.com\/tensorflow\/examples.git","d13026b5":"# GENERAL\n\nimport os\nimport os.path\nfrom pathlib import Path\nimport time\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport math\nimport glob\nimport cv2\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\n\n# I PACKAGES\n\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D,\\\nZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU, Conv2DTranspose, Input\nfrom tensorflow.keras import models\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow_examples.models.pix2pix import pix2pix\n\n# WARNINGS\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\n\n\nAUTO_MODEL_TUNE = tf.data.AUTOTUNE # if it is needed","b128e10a":"RGB_SEG_PATH = Path(\"..\/input\/semantic-drone-dataset\/RGB_color_image_masks\/RGB_color_image_masks\")\nORIGINAL_IMG_PATH = Path(\"..\/input\/semantic-drone-dataset\/dataset\/semantic_drone_dataset\/original_images\")","c590b1e2":"SEG_PNG_LIST = list(RGB_SEG_PATH.glob(r\"*.png\"))\nORIGINAL_JPG_LIST = list(ORIGINAL_IMG_PATH.glob(r\"*.jpg\"))","c82b9d84":"SEG_PNG_LIST = sorted(SEG_PNG_LIST)\nORIGINAL_JPG_LIST = sorted(ORIGINAL_JPG_LIST)","04e071be":"print(len(SEG_PNG_LIST))\nprint(len(ORIGINAL_JPG_LIST))","85852ed0":"TRAIN_SEG = SEG_PNG_LIST[:70]\nTRAIN_ORIGINAL = ORIGINAL_JPG_LIST[:70]\n\nTEST_SEG = SEG_PNG_LIST[350:]\nTEST_ORIGINAL = ORIGINAL_JPG_LIST[350:]","4c0e2ae3":"print(len(TRAIN_SEG))\nprint(len(TRAIN_ORIGINAL))\n\nprint(len(TEST_SEG))\nprint(len(TEST_ORIGINAL))","7616d194":"TRAIN_SEG[1]","a6a12aa1":"TRAIN_ORIGINAL[1]","6edabbc5":"TRAIN_SEG_SERIES = pd.Series(TRAIN_SEG,name=\"TRAIN_SEG\").astype(str)\nTRAIN_ORIGINAL_SERIES = pd.Series(TRAIN_ORIGINAL,name=\"TRAIN_ORIGINAL\").astype(str)\n\nTEST_SEG_SERIES = pd.Series(TEST_SEG,name=\"TEST_SEG\").astype(str)\nTEST_ORIGINAL_SERIES = pd.Series(TEST_ORIGINAL,name=\"TEST_ORIGINAL\").astype(str)","6bdc48b7":"MAIN_PROCESS_DATA = pd.concat([TRAIN_SEG_SERIES,TRAIN_ORIGINAL_SERIES,TEST_SEG_SERIES,TEST_ORIGINAL_SERIES],axis=1)","35146617":"MAIN_PROCESS_DATA","09b885e0":"MAIN_PROCESS_DATA[\"TRAIN_SEG\"][1]","7ffe6291":"MAIN_PROCESS_DATA[\"TRAIN_ORIGINAL\"][1]","ff1fbca6":"for picking_random_range in range(5):\n    \n    EXAMPLE_SEG = cv2.cvtColor(cv2.imread(MAIN_PROCESS_DATA[\"TRAIN_SEG\"][picking_random_range]),cv2.COLOR_BGR2RGB)\n    EXAMPLE_ORIGINAL = cv2.cvtColor(cv2.imread(MAIN_PROCESS_DATA[\"TRAIN_ORIGINAL\"][picking_random_range]),cv2.COLOR_BGR2RGB)\n    \n    EXAMPLE_SEG_TEST = cv2.cvtColor(cv2.imread(MAIN_PROCESS_DATA[\"TEST_SEG\"][picking_random_range]),cv2.COLOR_BGR2RGB)\n    EXAMPLE_ORIGINAL_TEST = cv2.cvtColor(cv2.imread(MAIN_PROCESS_DATA[\"TEST_ORIGINAL\"][picking_random_range]),cv2.COLOR_BGR2RGB)\n    \n    figure,axis = plt.subplots(1,4,figsize=(17,17))\n    \n    axis[0].set_title(\"TRAIN SEG\")\n    axis[0].axis(\"off\")\n    axis[0].imshow(EXAMPLE_SEG)\n    \n    axis[1].set_title(\"TRAIN ORG\")\n    axis[1].axis(\"off\")\n    axis[1].imshow(EXAMPLE_ORIGINAL)\n    \n    axis[2].set_title(\"TEST SEG\")\n    axis[2].axis(\"off\")\n    axis[2].imshow(EXAMPLE_SEG_TEST)\n    \n    axis[3].set_title(\"TEST ORG\")\n    axis[3].axis(\"off\")\n    axis[3].imshow(EXAMPLE_ORIGINAL_TEST)\n    \n    plt.tight_layout()\n    plt.show()","f640ea0a":"import pickle","b78697ab":"from tensorflow.keras.models import model_from_yaml","c0fa11b8":"BUFFER_SIZE = 400\nBATCH_SIZE = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nOUTPUT_CHANNELS = 3\nLAMBDA = 100\nEPOCHS = 40\nTYPE_ARRAY = \"float32\"","97ebf513":"TRAIN_SEG_MAIN = []\nTRAIN_ORG_MAIN = []\n\nTEST_SEG_MAIN = []\nTEST_ORG_MAIN = []\n\nfor x_seg,x_org in zip(MAIN_PROCESS_DATA.TRAIN_SEG,MAIN_PROCESS_DATA.TRAIN_ORIGINAL):\n    \n    READING_SEG = cv2.cvtColor(cv2.imread(x_seg),cv2.COLOR_BGR2RGB)\n    READING_ORG = cv2.cvtColor(cv2.imread(x_org),cv2.COLOR_BGR2RGB)\n    \n    RESIZE_SEG = cv2.resize(READING_SEG,(IMG_WIDTH,IMG_HEIGHT))\n    RESIZE_ORG = cv2.resize(READING_ORG,(IMG_WIDTH,IMG_HEIGHT))\n    \n    REDUCE_SEG = RESIZE_SEG \/ 255.\n    REDUCE_ORG = RESIZE_ORG \/ 255.\n    \n    TRAIN_SEG_MAIN.append(REDUCE_SEG)\n    TRAIN_ORG_MAIN.append(REDUCE_ORG)\n    \n    \nfor x_seg,x_org in zip(MAIN_PROCESS_DATA.TEST_SEG,MAIN_PROCESS_DATA.TEST_ORIGINAL):\n    \n    READING_SEG = cv2.cvtColor(cv2.imread(x_seg),cv2.COLOR_BGR2RGB)\n    READING_ORG = cv2.cvtColor(cv2.imread(x_org),cv2.COLOR_BGR2RGB)\n    \n    RESIZE_SEG = cv2.resize(READING_SEG,(IMG_WIDTH,IMG_HEIGHT))\n    RESIZE_ORG = cv2.resize(READING_ORG,(IMG_WIDTH,IMG_HEIGHT))\n    \n    REDUCE_SEG = RESIZE_SEG \/ 255.\n    REDUCE_ORG = RESIZE_ORG \/ 255.\n    \n    TEST_SEG_MAIN.append(REDUCE_SEG)\n    TEST_ORG_MAIN.append(REDUCE_ORG)","c13be547":"print(np.shape(np.array(TRAIN_SEG_MAIN)))\nprint(np.shape(np.array(TRAIN_ORG_MAIN)))\nprint(np.shape(np.array(TEST_SEG_MAIN)))\nprint(np.shape(np.array(TEST_ORG_MAIN)))","2ab4371c":"TEST_SEG_MAIN = TEST_SEG_MAIN[:20]\nTEST_ORG_MAIN = TEST_ORG_MAIN[:20]","ec4729c2":"print(np.shape(np.array(TEST_SEG_MAIN)))\nprint(np.shape(np.array(TEST_ORG_MAIN)))","6816f035":"ARRAY_TRAIN_SEG = np.array(TRAIN_SEG_MAIN,dtype=TYPE_ARRAY)\nARRAY_TRAIN_ORG = np.array(TRAIN_ORG_MAIN,dtype=TYPE_ARRAY)\nARRAY_TEST_SEG = np.array(TEST_SEG_MAIN,dtype=TYPE_ARRAY)\nARRAY_TEST_ORG = np.array(TEST_ORG_MAIN,dtype=TYPE_ARRAY)","ca7af81a":"TARGET_TENSOR = tf.data.Dataset.from_tensor_slices(ARRAY_TRAIN_ORG).batch(BATCH_SIZE)\nOUTPUT_TENSOR = tf.data.Dataset.from_tensor_slices(ARRAY_TRAIN_SEG).batch(BATCH_SIZE)\n\nTEST_TENSOR = tf.data.Dataset.from_tensor_slices(ARRAY_TEST_ORG).batch(BATCH_SIZE)","04141533":"print(TARGET_TENSOR.element_spec)\nprint(OUTPUT_TENSOR.element_spec)\nprint(TEST_TENSOR.element_spec)","de565b96":"def DOWN_SAMPLE(filter_layer,size_layer,batch_norm=True):\n    \n    Initialize_Range = tf.random_normal_initializer(0.,0.04)\n    \n    Model = Sequential()\n    \n    Model.add(Conv2D(filter_layer,\n                    size_layer,\n                    use_bias=False,\n                    strides=2,\n                    padding=\"same\",\n                    kernel_initializer=Initialize_Range))\n    \n    if batch_norm:\n        \n        Model.add(BatchNormalization())\n        \n        \n    return Model","26542740":"def UP_SAMPLE(filter_layer,size_layer,drop_out=False):\n    \n    Initialize_Range = tf.random_normal_initializer(0.,0.04)\n    \n    Model = Sequential()\n    \n    Model.add(Conv2DTranspose(filter_layer,\n                             size_layer,\n                             use_bias=False,\n                             strides=2,\n                             padding=\"same\",\n                             kernel_initializer=Initialize_Range))\n    \n    Model.add(BatchNormalization())\n    \n    if drop_out:\n        \n        Model.add(Dropout(0.5))\n        \n    Model.add(ReLU())\n    \n    return Model","be8e0a96":"def Generator_Creation(width_i,height_i,dimension_i):\n    \n    INPUT_LAYER = Input(shape=[width_i,height_i,dimension_i])\n    \n    DOWN_LIST = [\n        \n        DOWN_SAMPLE(64,2,batch_norm=False),\n        DOWN_SAMPLE(128,2,batch_norm=False),\n        DOWN_SAMPLE(256,2),\n        DOWN_SAMPLE(512,2),\n        DOWN_SAMPLE(512,2),\n        DOWN_SAMPLE(512,2),\n        DOWN_SAMPLE(512,2),\n        DOWN_SAMPLE(512,2)\n    ]\n    \n    \n    UP_LIST = [\n        \n        UP_SAMPLE(512,2,drop_out=True),\n        UP_SAMPLE(512,2,drop_out=True),\n        UP_SAMPLE(512,2),\n        UP_SAMPLE(512,2),\n        UP_SAMPLE(256,2),\n        UP_SAMPLE(128,2),\n        UP_SAMPLE(64,2)\n    ]\n    \n    \n    Ini_Kernel = tf.random_normal_initializer(0.,0.04)\n    \n    TRANS_LAYER = Conv2DTranspose(OUTPUT_CHANNELS,\n                                  4,\n                                  strides=2,\n                                 padding=\"same\",\n                                 kernel_initializer=Ini_Kernel,\n                                 activation=\"tanh\")\n    \n    LAST_X = INPUT_LAYER\n    \n    SKIPPING_PRE_LAYER = []\n    \n    for x_down in DOWN_LIST:\n        \n        LAST_X = x_down(LAST_X)\n        SKIPPING_PRE_LAYER.append(LAST_X)\n        \n    SKIPPING_PRE_LAYER = reversed(SKIPPING_PRE_LAYER[:-1])\n    \n    for x_up,x_skip in zip(UP_LIST,SKIPPING_PRE_LAYER):\n        \n        LAST_X = x_up(LAST_X)\n        LAST_X = tf.keras.layers.Concatenate()([LAST_X,x_skip])\n        \n    LAST_X = TRANS_LAYER(LAST_X)\n    \n    return tf.keras.Model(inputs=INPUT_LAYER,outputs=LAST_X)","e5bdc9d0":"Generation_Model = Generator_Creation(IMG_WIDTH,IMG_HEIGHT,OUTPUT_CHANNELS) ","d57b7ffd":"def Discrimination_Creation(width_i,height_i,dimension_i):\n    \n    Ini_Kernel = tf.random_normal_initializer(0.,0.04)\n    \n    INPUT_LAYER = Input(shape=[width_i,height_i,dimension_i])\n    TARGET_LAYER = Input(shape=[width_i,height_i,dimension_i])\n    \n    LAYER_IN = tf.keras.layers.concatenate([INPUT_LAYER,TARGET_LAYER])\n    \n    DS_1 = DOWN_SAMPLE(64,2,False)(LAYER_IN)\n    DS_2 = DOWN_SAMPLE(64,2)(DS_1)\n    DS_3 = DOWN_SAMPLE(64,2)(DS_2)\n    \n    ZP_1 = ZeroPadding2D()(DS_3)\n    CONV2D_1 = Conv2D(512,\n                     2,\n                     strides=1,\n                     kernel_initializer=Ini_Kernel,\n                     use_bias=False)(ZP_1)\n    \n    BH_1 = BatchNormalization()(CONV2D_1)\n    ACT_1 = LeakyReLU()(BH_1)\n    \n    ZP_2 = ZeroPadding2D()(ACT_1)\n    \n    LAYER_LAST = Conv2D(1,2,strides=1,\n                       kernel_initializer=Ini_Kernel)(ZP_2)\n    \n    return tf.keras.Model(inputs=[INPUT_LAYER,TARGET_LAYER],outputs=LAYER_LAST)","276ea0c8":"Discrimination_Model = Discrimination_Creation(IMG_WIDTH,IMG_HEIGHT,OUTPUT_CHANNELS)","b5a246e9":"LOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy(from_logits=True)","ff7bc8cb":"def Generation_Loss(disc_out,gen_out,target_out):\n    \n    GAN_LOSS = LOSS_FUNCTION(tf.ones_like(disc_out),disc_out)\n    ABS_ERROR_LOSS = tf.reduce_mean(tf.abs(target_out - gen_out))\n    \n    TOTAL_LOSS = GAN_LOSS + (LAMBDA * ABS_ERROR_LOSS)\n    \n    return TOTAL_LOSS,GAN_LOSS,ABS_ERROR_LOSS","7621e0af":"def Discriminator_Loss(org_out,seg_out):\n    \n    ORG_OUT = LOSS_FUNCTION(tf.ones_like(org_out),org_out)\n    SEG_OUT = LOSS_FUNCTION(tf.zeros_like(seg_out),seg_out)\n    \n    TOTAL_LOSS = ORG_OUT + SEG_OUT\n    \n    return TOTAL_LOSS","ab1e5162":"GENERATOR_OPT = tf.keras.optimizers.RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\nDISCRIMINATOR_OPT = tf.keras.optimizers.RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)","11b6f657":"os.mkdir(\".\/OUT_CLASS\")","4a6ae978":"READ_PREDICT_SINGLE = []\n\ndef generate_images_single(model, test_input, tar, number_i):\n    \n    prediction = model(test_input, training=True)\n    \n    plt.figure(figsize=(8, 8))\n    \n    plt.imshow(prediction[0])\n    plt.savefig('.\/OUT_CLASS\/out_res_{:04d}.png'.format(number_i))\n    \n    READING_PRE = cv2.cvtColor(cv2.imread('.\/OUT_CLASS\/out_res_{:04d}.png'.format(number_i)),cv2.COLOR_BGR2RGB)\n    READ_PREDICT_SINGLE.append(READING_PRE)\n    \n    plt.axis('off')\n    \n    plt.tight_layout()    \n    plt.show()","ce71997c":"os.mkdir(\".\/MULTI_CLASS\")","fd3051c4":"READ_PREDICT_MULTI = []\n\ndef generate_images_for_example(model, test_input, tar, number_i):\n    \n    prediction = model(test_input, training=True)\n    \n    RESULT_IN_OUT_LIST = [test_input[0], tar[0], prediction[0]]\n    \n    \n    figure,axis = plt.subplots(1, 3,figsize=(14,14))\n\n    axis[0].imshow(RESULT_IN_OUT_LIST[0])\n    axis[0].axis('off')\n\n    axis[1].imshow(RESULT_IN_OUT_LIST[1])\n    axis[1].axis('off')\n\n    axis[2].imshow(RESULT_IN_OUT_LIST[2])\n    axis[2].axis('off')\n    \n    plt.savefig('.\/MULTI_CLASS\/multi_res_{:04d}.png'.format(number_i))\n    \n    READING_PRE = cv2.cvtColor(cv2.imread('.\/MULTI_CLASS\/multi_res_{:04d}.png'.format(number_i)),cv2.COLOR_BGR2RGB)\n    READ_PREDICT_MULTI.append(READING_PRE)\n    \n    plt.tight_layout()\n    plt.show()","9bbd0df3":"@tf.function\n\ndef Train_Process(INPUT_TENSOR,TARGET_TENSOR,EPOCH):\n    \n    with tf.GradientTape() as GEN_TAPE, tf.GradientTape() as DISC_TAPE:\n        \n        GENERATION_OUT = Generation_Model(INPUT_TENSOR,training=True)\n        \n        DISCRIMINATION_REAL = Discrimination_Model([INPUT_TENSOR,TARGET_TENSOR],training=True)\n        DISCRIMINATION_FAKE = Discrimination_Model([INPUT_TENSOR,GENERATION_OUT],training=True)\n        \n        GEN_TOTAL_LOSS,GENERATOR_LOSS,GEN_MEAN_ABS_ERROR = Generation_Loss(DISCRIMINATION_FAKE,\n                                                                          GENERATION_OUT,\n                                                                          TARGET_TENSOR)\n        \n        \n        DISC_LOSS = Discriminator_Loss(DISCRIMINATION_REAL,DISCRIMINATION_FAKE)\n        \n        \n        \n    Generator_Gradient = GEN_TAPE.gradient(GEN_TOTAL_LOSS,Generation_Model.trainable_variables)\n    Discriminator_Gradient = DISC_TAPE.gradient(DISC_LOSS,Discrimination_Model.trainable_variables)\n    \n    GENERATOR_OPT.apply_gradients(zip(Generator_Gradient,Generation_Model.trainable_variables))\n    DISCRIMINATOR_OPT.apply_gradients(zip(Discriminator_Gradient,Discrimination_Model.trainable_variables))","fe26f11e":"#EXAMPLE_INP,EXAMPLE_TAR = next(iter(TARGET_TENSOR.take(1))),next(iter(OUTPUT_TENSOR.take(1)))\n\ncounting_img = 0\n\nfor epoch in range(EPOCHS):\n\n    n_count = 0\n    \n    for image_x, image_y in tf.data.Dataset.zip((TARGET_TENSOR.take(epoch),OUTPUT_TENSOR.take(epoch))):\n        \n        Train_Process(image_x, image_y, epoch)\n        print(str(counting_img))\n        if n_count % 10 == 0:\n            \n            print (\".\", end='')\n            \n        n_count += 1\n        \n    \n        clear_output(wait=True)\n        \n        \"\"\"generate_images_single(Generation_Model,\n                              image_x,\n                              image_y,\n                              counting_img)\"\"\"\n        \n        generate_images_for_example(Generation_Model,\n                                    image_x,\n                                    image_y,\n                                    counting_img)\n    \n    \n    \n    \n        counting_img = counting_img + 1","5c410b6f":"print(Generation_Model.summary())","7bfbd593":"Generation_Model.save(\"model_basis.p\")","d90b1efa":"MODEL_TRAINED_yaml = Generation_Model.to_yaml()\nwith open(\"model_train.yaml\", \"w\") as yaml_file:\n    yaml_file.write(MODEL_TRAINED_yaml)","4a0946e1":"Generation_Model.save_weights(\"model_traing_weights.h5\")","da99fda5":"Pickle_SAVE= open(\"model_trained.p\",\"wb\")\npickle.dump(Generation_Model,Pickle_SAVE)\npickle_out.close()","7f19eac2":"### LOSS FUNCTION AND CREATING EACH","0211335a":"### GENERATOR AND DISCRIMINATOR CREATION","f5c2cae7":"### TRAINING - PROCESS","f6040b00":"# DATA PREPARING PROCESS","305d4796":"#  ALL MODEL PROCESS","78bb3089":"# PATHING AND READING PROCESS","c058454a":"### TRAINING STEP FUNCTION - MAIN","3a913ae2":"### OPTIMIZATION FUNCTION AND GENERATION IMAGES","1be68290":"### LAYER CREATION"}}