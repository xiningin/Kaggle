{"cell_type":{"7e02ceca":"code","f6afc40e":"code","69ed95f7":"code","15f15214":"code","001071cf":"code","8a36f95f":"code","8767e928":"code","6a76eae4":"code","d46790a0":"code","d480f0aa":"code","dbe5f9c6":"code","b5182ec4":"code","7862d76b":"code","b959f15e":"code","9e397180":"code","a5099e35":"code","8d85951a":"code","d4a824b8":"code","50770c62":"code","db44ffc5":"code","c1109fcc":"code","36f075d7":"code","58be4ba8":"code","a15c0698":"code","f83e8fce":"code","2c6df635":"code","06ed9ac0":"code","86ec689a":"code","87531b9a":"code","8ece924a":"markdown","51409fde":"markdown","16364b62":"markdown","4cf37250":"markdown","b115c8f4":"markdown","3b6cec52":"markdown","ac4645a3":"markdown","bac2322b":"markdown","63936016":"markdown","28ba3d2d":"markdown","33225476":"markdown","a0fc85fd":"markdown","2da6d8bc":"markdown","40138bc4":"markdown","bb2646ca":"markdown","2d47beee":"markdown","c33311fd":"markdown"},"source":{"7e02ceca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6afc40e":"train_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\nprint('The shape of training dataset : ', train_df.shape)\nprint('The shape of testing dataset : ', test_df.shape)","69ed95f7":"train_df.head(5)","15f15214":"train = np.array(train_df, dtype = 'float32')\ntest = np.array(test_df, dtype = 'float32')","001071cf":"x_train = train[:,1:]\/255\n\ny_train = train[:,0]\n\nx_test= test[:,1:]\/255\n\ny_test=test[:,0]","8a36f95f":"X_train, X_validate,y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state = 5000)\nprint('The size of training data after model selection : ', X_train.shape, y_train.shape)\nprint('The size of Validation data after model selection : ', X_validate.shape, y_validate.shape)","8767e928":"class_names = ['T_shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nplt.figure(figsize=(17, 17))\n\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.grid(False)\n    plt.imshow(x_train[i].reshape((28,28)))\n    plt.colorbar()\n    label_index = int(y_train[i])\n    plt.title(class_names[label_index])\nplt.show()","6a76eae4":"#Assigning image dimensions for model\nimg_rows = 28\nimg_cols = 28\nimg_shape = (img_rows, img_cols,1)\n\nX_train = X_train.reshape(X_train.shape[0],*img_shape)\nx_test = x_test.reshape(x_test.shape[0],*img_shape)\nX_validate = X_validate.reshape(X_validate.shape[0],*img_shape)\n","d46790a0":"model = tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape = img_shape),\n        tf.keras.layers.Dense(512, activation = 'relu'),\n        tf.keras.layers.Dense(10, activation = 'softmax') #since we want a probability based output\n])\nmodel.compile(optimizer = 'adam',\n             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n             metrics = ['accuracy'])\nhistory = model.fit(X_train, y_train, epochs = 20, verbose=2, validation_data=(X_validate, y_validate))","d480f0aa":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy without Dropout')","dbe5f9c6":"print('Training accuracy without dropout included : ', history.history['accuracy'][-1])\nprint('Validation accuracy without dropout included : ', history.history['val_accuracy'][-1])","b5182ec4":"model = tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape = img_shape),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(512, activation = 'relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(10, activation = 'softmax') #since we want a probability based output\n])\n","7862d76b":"model.summary()","b959f15e":"model.compile(optimizer = 'adam',\n             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n             metrics = ['accuracy'])","9e397180":"history = model.fit(X_train, y_train, epochs = 20, verbose=2, validation_data=(X_validate, y_validate))","a5099e35":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy using Dropout')","8d85951a":"print('Training accuracy after dropout included : ', history.history['accuracy'][-1])\nprint('Validation accuracy after dropout included : ', history.history['val_accuracy'][-1])","d4a824b8":"test_loss, test_acc = model.evaluate(X_validate, y_validate)","50770c62":"predictions = model.predict(X_validate)","db44ffc5":"np.argmax(predictions[0])","c1109fcc":"print(predictions[11])","36f075d7":"np.sum(predictions[11])","58be4ba8":"cnn_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), padding='same', activation=tf.nn.relu,\n                           input_shape=(28, 28, 1)),\n    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.6),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])","a15c0698":"cnn_model.summary()\ncnn_model.compile(optimizer = 'adam',\n             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n             metrics = ['accuracy'])","f83e8fce":"history = cnn_model.fit(X_train, y_train, epochs = 15, verbose=2, validation_data=(X_validate, y_validate))","2c6df635":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","06ed9ac0":"print('Training accuracy on CNN model : ', history.history['accuracy'][-1])\nprint('Validation accuracy on CNN model : ', history.history['val_accuracy'][-1])","86ec689a":"test_loss, test_acc = cnn_model.evaluate(X_validate, y_validate, batch_size=32)","87531b9a":"predictions = cnn_model.predict(X_validate)\nprint('Display the indices of the maximum values along an axis : {}'.format(np.argmax(predictions[0])))\nprint('Displaying the predictions : \\n{}'.format(predictions[11]))\nprint('Total sum of these indices : {}'.format(np.sum(predictions[11])))","8ece924a":"# Model Development","51409fde":"**Description of model is shown below**","16364b62":"**Before we start with model layout let's do some basic things**","4cf37250":"# Load the Libraries","b115c8f4":"1. **So what we observed here is that the model tended to overfit i.e., memorize the training data and so the accuracy came to aound 95%, however it failed to perform better on validation set and as a result the validation loss was high.**\n2. **For the second case however with dropout included, the model did not overfit and training accuracy went down validation accuracy remained same for both the cases but the loss on validation set drastically reduced.**\n\nThis emplies in order to avoid overfitting Dropout is an good alternative","3b6cec52":"# Data Visualization","ac4645a3":"**Let us split the training and test datasets**","bac2322b":"# Load and Explore Dataset","63936016":"**Now we start with converting the pixel values into array format**","28ba3d2d":"# Discussion\nThough the accuracy obtained on validation set using CNN was good this model still needs improvement and will be updating it in next versions!!\nCNN model was updated to include Dropout and as a result Validation accuracy and Loss both were very good\n\nDo upvote my Kernel if you liked it. It is my first implementation code on CNN","33225476":"**Lets check the plots**","a0fc85fd":"**With Dropout**","2da6d8bc":"# Import the Fashion MNIST dataset\n\nThis guide uses the Fashion MNIST dataset, which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 \u00d7 28 pixels), as seen here:\nFashion MNIST sprite\nFigure 1. Fashion-MNIST samples (by Zalando, MIT License).\n \n<table>\n  <tr><td>\n    <img src=\"https:\/\/tensorflow.org\/images\/fashion-mnist-sprite.png\"\n         alt=\"Fashion MNIST sprite\" width=\"600\">\n  <\/td><\/tr>\n  <tr><td align=\"center\">\n    <b>Figure 1.<\/b> <a href=\"https:\/\/github.com\/zalandoresearch\/fashion-mnist\">Fashion-MNIST samples<\/a> (by Zalando, MIT License).<br\/>&nbsp;\n  <\/td><\/tr>\n<\/table>\n \n \n \n\nFashion MNIST is intended as a drop-in replacement for the classic MNIST dataset\u2014often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n\nThis guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n\nWe will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow, using the Datasets API:\n","40138bc4":"# Simple layered Neural Network","bb2646ca":"**Plots after using dropout**","2d47beee":"# CNN Model","c33311fd":"**Without Dropout**"}}