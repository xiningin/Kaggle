{"cell_type":{"eb5e0ae4":"code","cec5ec8b":"code","96e47a17":"code","4fe92ca6":"code","1e686902":"code","b25f1892":"code","ff48900b":"code","edf56636":"code","db27d0aa":"code","fc7328a3":"code","087d80f9":"code","1905b352":"code","73b6bc4e":"code","6bb2d6e7":"code","33b6859a":"code","3c22e2f3":"code","e561ec2b":"code","f1608a26":"code","5471a5ce":"code","a1cecce5":"code","a0d5cb12":"code","fa953898":"code","a072d5a0":"code","e683e30e":"code","99e4fedb":"code","0b71ff09":"code","19006fd4":"code","7d5a03e8":"code","2c30c8b9":"code","29b9eeaf":"code","cc0b1f3f":"code","fb9ead2b":"code","aab50831":"code","1c3407d7":"code","73ef4a6d":"code","39e5ccbd":"code","791c3933":"code","03fc27c1":"code","9190ed3a":"code","2e8aa26d":"code","9ab62ac0":"code","d8446cb4":"markdown","ecd1578a":"markdown","c353499b":"markdown","675d9b5f":"markdown","09a8eed1":"markdown","3bd4c58b":"markdown","49d3048f":"markdown","9b4c81f9":"markdown","f3e01a50":"markdown","8c9fffa5":"markdown","76fb3335":"markdown","170a31ac":"markdown","85554173":"markdown","8797d91f":"markdown","ca64fe9c":"markdown","f09bdeba":"markdown","0b630e25":"markdown","75ec6962":"markdown","87a164fc":"markdown","2b481256":"markdown","1bc172d0":"markdown"},"source":{"eb5e0ae4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cec5ec8b":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","96e47a17":"# Basic Checking of shapes\nprint('Number of Training Examples {}'.format(train_df.shape))\nprint('Number of Test Examples {}'.format(test_df.shape))\nprint('Train Features:\\n', train_df.columns)\nprint('Test Features\\n', test_df.columns)","4fe92ca6":"train_df.info()","1e686902":"test_df.info()","b25f1892":"def concat_df(train_data, test_data):\n    return pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\ndef divide_df(merged_df):\n    return merged_df.loc[:890], merged_df.loc[891:].drop(['Survived'], axis=1)\n\ndf = concat_df(train_df, test_df)","ff48900b":"df.corr().abs()","edf56636":"age_by_pclass_sex = df.groupby(['Sex', 'Pclass'])[['Age']].apply(lambda x: x.sum())\nage_by_pclass_sex","db27d0aa":"df['Age'] = df.groupby(['Sex','Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","fc7328a3":"df[df['Embarked'].isna()]","087d80f9":"df['Embarked'] = df['Embarked'].fillna('S') # Filling Southampton as this is the value for martha evelyn","1905b352":"df[df['Fare'].isna()]","73b6bc4e":"fare_for_alone_traveller_of_3rd_class = df.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()[3,0,0]\ndf['Fare'] = df['Fare'].fillna(fare_for_alone_traveller_of_3rd_class)","6bb2d6e7":"cabin_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'M']\ndef map_to_deck(cabin: str) -> str:\n    for deck in cabin_decks:\n        if deck in cabin:\n            return deck\n    return cabin\ndf['Cabin'] = df['Cabin'].fillna('M')\ndf['Cabin'] = df['Cabin'].apply(map_to_deck)\ndf['Cabin'] = df['Cabin'].replace('T', 'A')\nsurvival_by_deck = {}\nfor deck, survived in zip(df['Cabin'], df['Survived']):\n    if deck == \"Missing\":\n        continue\n    if np.isnan(survived):\n        continue\n    if deck not in survival_by_deck:\n        survival_by_deck[deck] = [0,0]\n    survival_by_deck[deck][int(survived)]+=1\nfor k, v in survival_by_deck.items():\n    survival_by_deck[k] = v[1]\/(v[0]+v[1])\nsns.barplot(x=list(survival_by_deck.keys()), y=list(survival_by_deck.values()))","33b6859a":"df.groupby(['Pclass', 'Cabin']).size()","3c22e2f3":"df['Cabin'] = df['Cabin'].replace(['A', 'B', 'C'], 'ABC')\ndf['Cabin'] = df['Cabin'].replace(['D', 'E'], 'DE')\ndf['Cabin'] = df['Cabin'].replace(['F', 'G'], 'FG')\ndf['Cabin'].value_counts()","e561ec2b":"df.isna().sum()","f1608a26":"train_df, test_df = divide_df(df)","5471a5ce":"survived_stats = df['Survived'].value_counts().reset_index()\nplt.figure(figsize=(8,6))\nsns.barplot(x=survived_stats['index'], y=survived_stats['Survived'])\nplt.title('Survival Percentage')\ntotal = survived_stats['Survived'].sum()\nplt.xlabel('')\nplt.xticks((0,1), ['Not Survived {:.2f}%'.format(survived_stats.loc[0,'Survived']\/total), 'Survived {:.2f}%'.format(survived_stats.loc[1,'Survived']\/total) ])","a1cecce5":"plt.figure(figsize=(10,10))\n\nplt.subplot(1,2,1)\nplt.title('Train set correlations')\nsns.heatmap(train_df.corr(), annot=True, linewidth=0.5, cmap='coolwarm')\n\nplt.subplot(1,2,2)\nplt.title('Test set correlations')\nsns.heatmap(test_df.corr(), annot=True, linewidth=0.5, cmap='coolwarm')\nplt.tight_layout()","a0d5cb12":"plt.figure(figsize=(16,10))\nplt.subplot(1,2,1)\nsns.distplot(a=train_df[train_df['Survived'] == 1]['Age'], label='Survived')\nsns.distplot(a=train_df[train_df['Survived'] == 0]['Age'], label='Not Survived')\nplt.title('Distribution of Age and Survival')\nplt.legend()\n\nplt.subplot(1,2,2)\nsns.distplot(a=train_df['Age'], label='Train Set')\nsns.distplot(a=test_df['Age'], label='Test Set')\nplt.title('Ages Test set vs train set')\nplt.legend()","fa953898":"plt.figure(figsize=(16,6))\nplt.subplot(1,2,1)\nsns.distplot(a=train_df[train_df['Survived'] == 1]['Fare'], label='Survived')\nsns.distplot(a=train_df[train_df['Survived'] == 0]['Fare'], label='Not Survived')\nplt.title('Distribution of Fare and Survival')\nplt.legend()\n\nplt.subplot(1,2,2)\nsns.distplot(a=train_df['Fare'], label='Train Set')\nsns.distplot(a=test_df['Fare'], label='Test Set')\nplt.title('Fares Test set vs train set')\nplt.legend()","a072d5a0":"def plot_data(categoryA):\n    data = train_df.groupby([categoryA, 'Survived']).size().reset_index()\n    data.rename(columns={0:'Count'}, inplace=True)\n    sns.barplot(x=categoryA, y='Count', hue='Survived', data=data)\n    plt.title('{} vs Survival'.format(categoryA))\n    \n# embarked_vs_survival = train_df.groupby(['Embarked', 'Survived']).size().reset_index()\n# embarked_vs_survival.rename(columns={0:'Count'}, inplace=True)\nplt.figure(figsize=(20,10))\nplt.subplot(2,3,1)\nplot_data('Embarked')\n\nplt.subplot(2,3,2)\nplot_data('Sex')\n\nplt.subplot(2,3,3)\nplot_data('Pclass')\n\nplt.subplot(2,3,4)\nplot_data('SibSp')\n\nplt.subplot(2,3,5)\nplot_data('Parch')\n\nplt.subplot(2,3,6)\nplot_data('Cabin')\n\nplt.tight_layout()\n","e683e30e":"titles = ['Mr', 'Mrs', 'Ms','Master', 'Dr','Miss', 'Don', 'Capt', 'Col', 'Dona', 'Rev', 'Mlle', 'Mme', 'Major', 'Jonkheer', 'Countess']\ndef to_title(name: str) -> str:\n    for title in titles:\n        if title in name:\n            return title\n    return name\ndef replace_titles(x: pd.DataFrame) -> str:\n    title=x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n        return 'Army\/Clergy\/Doctor'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\ndf['Title'] = df['Name'].apply(to_title)\ndf['Title'] = df.apply(replace_titles, axis=1)\ndf.head(10)","99e4fedb":"\ntitle_df = df.groupby(['Title', 'Survived']).size().reset_index()\nplt.figure(figsize=(14,8))\nsns.barplot(x='Title', y=0, hue='Survived', data=title_df)","0b71ff09":"df['Family_size'] = df['SibSp'] + df['Parch']\nfamily_size_df = df.groupby(['Family_size', 'Survived']).size()\nplt.figure(figsize=(16,10))\nsns.barplot(x='Family_size', y=0, hue='Survived', data=family_size_df.reset_index())\npercentages = []\nfor i in range(11):\n    try:\n        percentage = family_size_df.loc[(i,1.0)]\/family_size_df.loc[i].sum()\n        percentages.append(percentage)\n    except:\n        percentage = 0\n        percentages.append(percentage)\nlabels = ['Size {} \\nSurvived {:.2f}%'.format(i, percentages[i]) for i in range(11)]\nplt.xticks(tuple(range(11)), labels)\nfamily_size_df.head(25)","19006fd4":"df.head()","7d5a03e8":"df['AgeClass'] = df['Age']*df['Pclass']\ndf.head()","2c30c8b9":"from sklearn.preprocessing import LabelEncoder\n\nle_cols = ['Sex', 'Embarked','Title','Cabin']\nfor col in le_cols:\n    df[col] = LabelEncoder().fit_transform(df[col])\ncols_to_drop = ['Name', 'Ticket']\ndf.head()\ndf = df.drop(cols_to_drop, axis=1)\ntrain_df, test_df = divide_df(df)\ntrain_df.head()","29b9eeaf":"test_df.head()","cc0b1f3f":"X = train_df.drop(['Survived','PassengerId'], axis=1)\ny = train_df.Survived\nprint(X.shape, y.shape)\nX.head()","fb9ead2b":"import time\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\n\ncat_cols = ['Embarked', 'Title', 'Sex', 'Pclass', 'Cabin',]\nord_cols = ['Family_size',  'SibSp', 'Parch']\nnum_cols = ['AgeClass','Age', 'Fare',]\npreprocessing = ColumnTransformer(transformers=[\n    ('cat_cols', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n    ('ord_cols',SimpleImputer(), ord_cols ),\n     ('numerical_cols', StandardScaler(), num_cols),\n])\npipeline = Pipeline(steps=[\n    ('preprocessing', preprocessing),\n    ('model', RandomForestClassifier(random_state=0, n_jobs=-1)),\n])\nparam_grid = {\n        'model__max_depth': [5, 10, 15],\n        'model__min_samples_split': [10, 20, 30],\n        'model__n_estimators': [100, 200, 300],\n        'model__min_samples_leaf': [5, 10, 15],\n        \"model__bootstrap\": [True],\n        \"model__criterion\": [\"entropy\"]\n}\n\nclf = GridSearchCV(estimator=pipeline,param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=10)\nstart = time.time()\nclf.fit(X,y)\nprint('Took {}s'.format(time.time()-start))\nprint('Best Score: {} ,\\n Param: {}'.format(clf.best_score_, clf.best_params_))","aab50831":"# estimator = clf.best_estimator_","1c3407d7":"scores = cross_val_score(estimator=clf.best_estimator_, X=X, y=y, n_jobs=-1, scoring='accuracy', cv=10)\nprint(scores.mean(), scores.std())\nX.head()","73ef4a6d":"test_df.head()","39e5ccbd":"from sklearn.metrics import accuracy_score\npipeline = clf.best_estimator_\npipeline.fit(X,y)\nprint(accuracy_score(y, pipeline.predict(X)))","791c3933":"X.head()","03fc27c1":"test_df.head()","9190ed3a":"X_test = test_df.drop(['PassengerId'], axis=1)\nX_test.head()","2e8aa26d":"prediction = np.array(pipeline.predict(X_test), dtype=np.int)\noutput = pd.DataFrame({'PassengerId':test_df.PassengerId, 'Survived':prediction})\noutput.head()","9ab62ac0":"output.to_csv('submission.csv', index=False)","d8446cb4":"Here we can see Age 86\/418 Fare 1\/418 Cabin 327\/418 has missing values.","ecd1578a":"## Combining Train And Test Datasets\nWe will be combining train_df and test_df so that whatever preprocessing we apply get applied to both of them and then we can seperate them and make predictions on test data using our model. I admit that in reality you will not have  a test dataset available to you and you will be required to build machine learning pipelines. But for my first competition I guess this is a start. I will improve the code later.","c353499b":"So it seems that people travelling alone has only 30% chance of surviving whereas these chances progressively improve with family sizes of 1,2,3 having percentages 55%, 58%, 72% and then as family size further increases chances of survival go kaboom","675d9b5f":"It turns out people of cabin D, B, E most likely survived whereas cabin A, G had less than 50% chance of  survival. ","09a8eed1":"## Embarked\nWe will fill the missing values of embarked feature.","3bd4c58b":"## Target Distribution","49d3048f":"## Creating new features\nA feature such as family size makes sense rather than having seperate SibSp and Parch features we will try to create such a feature.","9b4c81f9":"Creating a interaction term AgeClass","f3e01a50":"Below models have been found using Hyper Paramter Tuning","8c9fffa5":"We will train our model on full dataset for the submission.","76fb3335":"## Fare\nIt is missing for only one person.","170a31ac":"# Feature Engineering","85554173":"## Categorical Features","8797d91f":"In the correlation table below you can see that Fare is best correlated with Pclass, Parch, Age, SibSp so we can fill this according to the median fare of the class. Let us group them by Pclass, Parch, SibSp.","ca64fe9c":"# Exploratory Data Analysis\n* PassengerId\nThis features just uniquely determines the passanger and will be used for identification purposes only.\n* Survived\nOur target variable. Take the values 0 and 1 where 1 corresponds to survivors.\n* Pclass \nThis variable defines class (socio-economic status) of our passenger takes values 1,2,3 \n* Name Sex Age Fare are self explanatory.\n* SibSp \nThis refers to number of siblings or spouse aboard on titanic for this person.\n* Parch\nThis refers to number of parents or children aboard on titanic for this person.\n* Cabin \nIt is the cabin number of passengers.\n* Embarked\nIt is the port of embarkation has three unique values\n    * C Cheerburg \n    * Q Queenstown\n    * S Southampton\n","f09bdeba":"## Cabin \nCabin has has about 77% of values missing. Dropping such a coloumn makes absolute sense. But still some of the cabin may have higher surival rates as the cabins represent decks in which cabins are related. Let us see the passengers distribution in cabins.","0b630e25":"## Name\nWe will extract titles from name and replace the title with name.","75ec6962":"We will use RandomForestSince it has the highest accuracy on cross validation score.","87a164fc":"As we can see Age 179\/891 , Cabin 687\/891 and Embarked 889\/891 columns have missing values. ","2b481256":"## Age\nMissing values in age can be best filled by using median. But median of whole dataset is not a good choice.\nWe will fill the age according to median of Pclass and Sex. As can be seen by correlation plot below.","1bc172d0":"It turns out that Cabin A, B, C was reserved for 1st class passengers.  Here we will group them according to their class."}}