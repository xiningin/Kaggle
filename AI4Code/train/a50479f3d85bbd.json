{"cell_type":{"d4af915a":"code","4c0f8fbe":"code","a5180c69":"code","20bcb51e":"code","a715538b":"code","6c110279":"code","c16c7242":"code","2bb4425b":"code","520cb75b":"code","3dca798b":"code","9626f0ee":"code","10333531":"code","1ac6ecc0":"code","24ad4590":"code","daee1d43":"code","832ebc4c":"code","d8a8ca41":"code","9c6a7c89":"code","d4b562a8":"code","52f1e059":"code","b0cf6f7f":"code","ddec6b6b":"code","87d8a5cd":"code","1430ba46":"code","1b3fe69a":"code","114c5758":"code","17cb7922":"code","413caf79":"code","dbb30fc7":"code","6c056dff":"code","344a4322":"code","e440904f":"code","28f50f81":"code","3f692a7b":"code","0715c3bb":"code","b0ccef5d":"code","721a6a11":"code","21217b00":"code","4966acdf":"code","25313178":"code","10aafde7":"code","fb02fca6":"code","38aa5554":"code","35377ad0":"code","60812b36":"code","dd21dfec":"code","cfdec50a":"code","8b6fe0c5":"code","4777efa4":"code","859416b2":"code","29fbccc0":"code","dd4d2435":"code","7d8f9e1e":"code","5ca0806c":"code","ade0474a":"code","742ef10f":"code","b8d7826c":"code","1c6dcc3d":"code","00a7f82f":"code","21376465":"code","e02964ee":"code","6a81ef52":"code","bbe6d641":"code","9d174827":"code","ca25ed99":"code","521c6e8d":"code","7ee09ddd":"code","f05a7a2a":"code","7a5b0432":"code","d4414662":"code","c7e3c7f3":"code","500128c1":"code","78df1e2f":"code","832aa62d":"code","cdedc4bd":"code","dade2017":"code","d3b49e1b":"code","61334e01":"code","f94fcea6":"code","8b14375e":"code","bc3a94e4":"code","0d9dc4e4":"code","c8d181e0":"code","4bb31698":"code","652bba32":"code","4368f6d1":"code","79ddcd55":"code","e5b58937":"code","c2abde43":"code","7facb4d8":"markdown","95cf01c3":"markdown","1e8b9f91":"markdown","cee14e88":"markdown","0042e502":"markdown","1ae4f2b0":"markdown","50f2bab2":"markdown","0c2af007":"markdown","bbd3f24f":"markdown","8d03cd47":"markdown","7302405a":"markdown","c1c3760d":"markdown","ee890766":"markdown","19e7e3df":"markdown","c39b0cf6":"markdown","6760576b":"markdown","4317a6af":"markdown","1dc3aa35":"markdown","e89dce72":"markdown","dc5b5bff":"markdown","56525238":"markdown","a072fc0c":"markdown","a0457370":"markdown","184c92e0":"markdown","edfa2a6f":"markdown","05baba91":"markdown","63c76ca6":"markdown","0cf9259c":"markdown","31b3cff2":"markdown","4d023d31":"markdown","52c72cd3":"markdown","9d8d8f13":"markdown","20fb1bb3":"markdown","89de52bc":"markdown","56f177c4":"markdown","85add0f4":"markdown","7041cb76":"markdown","b25cee60":"markdown","7e5d8c0c":"markdown","4ca8427b":"markdown"},"source":{"d4af915a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom scipy.stats import uniform\n%matplotlib inline","4c0f8fbe":"from xgboost import XGBRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom mlxtend.preprocessing import minmax_scaling","a5180c69":"import warnings\nwarnings.filterwarnings(\"ignore\")","20bcb51e":"# show unique values in the column\ndef show_uniq(col):\n    print('Train: {}'.format(train[col].unique()))\n    print('Test: {}'.format(test[col].unique()))","a715538b":"# show unique values in the columns\ndef show_uniqs(cols):\n    for col in cols:\n        print(col)\n        show_uniq(col)\n        print('=======================================')","6c110279":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')","c16c7242":"cat_original_columns = train.select_dtypes(exclude=np.number).columns # categorical columns\nnum_original_columns = train.select_dtypes(include=np.number).columns.drop('Id') # numerical columns","2bb4425b":"train.head()","520cb75b":"train.shape","3dca798b":"# columns with gaps\nempty_columns_train = train.columns[[ind for ind,x in enumerate(train.isnull().any()) if x]]","9626f0ee":"# number of gaps in all columns\ncount_empty_columns_train = train[empty_columns_train].isnull().sum(axis = 0)\ncount_empty_columns_train","10333531":"plt.figure(figsize=(15,7))\nploting = sns.barplot(x = count_empty_columns_train.index,y = count_empty_columns_train.values)\nplt.xticks(rotation=30)","1ac6ecc0":"(train.shape[0]\/100)*40","24ad4590":"for c, name_col in zip(count_empty_columns_train,count_empty_columns_train.index):\n    if c > 584:\n        print(name_col)","daee1d43":"test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","832ebc4c":"test.shape","d8a8ca41":"# columns with gaps\nempty_columns_test = test.columns[[ind for ind,x in enumerate(test.isnull().any()) if x]]","9c6a7c89":"# number of gaps in all columns\ncount_empty_columns_test = test[empty_columns_test].isnull().sum(axis = 0)\ncount_empty_columns_test","d4b562a8":"plt.figure(figsize=(15,7))\nploting = sns.barplot(x = count_empty_columns_test.index,y = count_empty_columns_test.values)\nplt.xticks(rotation=30)","52f1e059":"for col in count_empty_columns_test.index:\n    if col not in count_empty_columns_train:\n        print(col)","b0cf6f7f":"garage_colums = []\nregexp = re.compile(r\"([-a-zA-Z]+)?\"+r\"Garage\"+r\"([-a-zA-Z]+)?\")\nfor col in train.columns:\n    if regexp.search(col):\n        garage_colums.append(col)\ngarage_colums = np.array(garage_colums)\ngarage_colums","ddec6b6b":"train[garage_colums].info()","87d8a5cd":"test[garage_colums].info()","1430ba46":"garage_num_cols = train[garage_colums].select_dtypes(include=np.number).columns # numerical garage columns\ngarage_cat_cols = train[garage_colums].select_dtypes(exclude=np.number).columns # categorical garage columns","1b3fe69a":"for col in garage_num_cols:\n    train[col] = train[col].fillna(0)\n    test[col] = test[col].fillna(0)","114c5758":"# Shows if there is another notation for nan in the data\nshow_uniqs(garage_cat_cols)","17cb7922":"for col in garage_cat_cols:\n    train[col] = train[col].fillna('NA')\n    test[col] = test[col].fillna('NA')\n    # show column if classes in test column not in train \n    if not set(test[col].unique()).issubset(train[col].unique()):\n        print(col)","413caf79":"basement_colums = []\nregexp = re.compile(r\"([-a-zA-Z]+)?\"+r\"Bsmt\"+r\"([-a-zA-Z]+)?\")\nfor col in train.columns:\n    if regexp.search(col):\n        basement_colums.append(col)\nbasement_colums = np.array(basement_colums)\nbasement_colums","dbb30fc7":"train[basement_colums].info()","6c056dff":"test[basement_colums].info()","344a4322":"basement_num_cols = train[basement_colums].select_dtypes(include=np.number).columns\nbasement_cat_cols = train[basement_colums].select_dtypes(exclude=np.number).columns","e440904f":"for col in basement_num_cols:\n    train[col] = train[col].fillna(0)\n    test[col] = test[col].fillna(0)","28f50f81":"show_uniqs(basement_cat_cols)","3f692a7b":"# show column if classes in test column not in train \nfor col in basement_cat_cols:\n    train[col] = train[col].fillna('NA')\n    test[col] = test[col].fillna('NA')\n    if not set(test[col].unique()).issubset(train[col].unique()):\n        print(col)","0715c3bb":"masvnr_colums = []\nregexp = re.compile(r\"([-a-zA-Z]+)?\"+r\"MasVnr\"+r\"([-a-zA-Z]+)?\")\nfor col in train.columns:\n    if regexp.search(col):\n        masvnr_colums.append(col)\nmasvnr_colums = np.array(masvnr_colums)\nmasvnr_colums","b0ccef5d":"train[masvnr_colums].info()","721a6a11":"test[masvnr_colums].info()","21217b00":"masvnr_num_cols = train[masvnr_colums].select_dtypes(include=np.number).columns\nmasvnr_cat_cols = train[masvnr_colums].select_dtypes(exclude=np.number).columns","4966acdf":"# if we have a missing value in MasVnrArea column than we have missing value in MasVnrType column on a same row\nall(train.loc[train['MasVnrArea'].isnull()].index == train.loc[train['MasVnrType'].isnull()].index)","25313178":"train.loc[train['MasVnrArea'] == 0][masvnr_colums].head()","10aafde7":"train['MasVnrArea'] = train['MasVnrArea'].fillna(0)\ntest['MasVnrArea'] = test['MasVnrArea'].fillna(0)","fb02fca6":"show_uniqs(masvnr_cat_cols)","38aa5554":"train['MasVnrType'] = train['MasVnrType'].fillna('None')\ntest['MasVnrType'] = test['MasVnrType'].fillna('None')","35377ad0":"show_uniqs(masvnr_cat_cols)","60812b36":"pool_colums = []\nregexp = re.compile(r\"([-a-zA-Z]+)?\"+r\"Pool\"+r\"([-a-zA-Z]+)?\")\nfor col in train.columns:\n    if regexp.search(col):\n        pool_colums.append(col)\npool_colums = np.array(pool_colums)\npool_colums","dd21dfec":"show_uniqs(pool_colums)","cfdec50a":"train.loc[train['PoolQC'].isnull()][pool_colums].head()","8b6fe0c5":"train['PoolQC'] = train['PoolQC'].fillna('NA')\ntest['PoolQC'] = test['PoolQC'].fillna('NA')","4777efa4":"show_uniq('Alley')","859416b2":"train['Alley'] = train['Alley'].fillna('NA')\ntest['Alley'] = test['Alley'].fillna('NA')","29fbccc0":"fireplace_colums = []\nregexp = re.compile(r\"([-a-zA-Z]+)?\"+r\"Fireplace\"+r\"([-a-zA-Z]+)?\")\nfor col in train.columns:\n    if regexp.search(col):\n        fireplace_colums.append(col)\nfireplace_colums = np.array(fireplace_colums)\nfireplace_colums","dd4d2435":"show_uniqs(fireplace_colums)","7d8f9e1e":"train['FireplaceQu'] = train['FireplaceQu'].fillna('NA')\ntest['FireplaceQu'] = test['FireplaceQu'].fillna('NA')","5ca0806c":"show_uniq('Fence')","ade0474a":"train['Fence'] = train['Fence'].fillna('NA')\ntest['Fence'] = test['Fence'].fillna('NA')","742ef10f":"misc_colums = []\nregexp = re.compile(r\"([-a-zA-Z]+)?\"+r\"Misc\"+r\"([-a-zA-Z]+)?\")\nfor col in train.columns:\n    if regexp.search(col):\n        misc_colums.append(col)\nmisc_colums = np.array(misc_colums)\nmisc_colums","b8d7826c":"show_uniq('MiscFeature')","1c6dcc3d":"train['MiscFeature'] = train['MiscFeature'].fillna('NA')\ntest['MiscFeature'] = test['MiscFeature'].fillna('NA')","00a7f82f":"show_uniq('Electrical')","21376465":"train = train.drop(train.loc[train['Electrical'].isnull()].index)","e02964ee":"for i in test['Neighborhood'].unique():\n    if test.MSZoning[test['Neighborhood'] == i].isnull().sum() > 0:\n        test.loc[test['Neighborhood'] == i,'MSZoning'] = \\\n        test.loc[test['Neighborhood'] == i,'MSZoning'].fillna(test.loc[test['Neighborhood'] == i,'MSZoning'].mode()[0]) ","6a81ef52":"test['Exterior2nd'].fillna('None', inplace=True) \ntest['Exterior1st'].fillna(test['Exterior1st'].mode()[0], inplace=True)        \ntest['SaleType'].fillna(test['SaleType'].mode()[0], inplace=True)                \ntest['KitchenQual'].fillna(test['KitchenQual'].mode()[0], inplace=True)    \ntest['Functional'].fillna(test['Functional'].mode()[0], inplace=True)       \ntest['Utilities'].fillna(test['Utilities'].mode()[0], inplace=True)  ","bbe6d641":"train['LotFrontage'].fillna(train['LotFrontage'].median(), inplace=True)\ntest['LotFrontage'].fillna(test['LotFrontage'].median(), inplace=True)","9d174827":"y_train = train['SalePrice']\ntrain = train.drop('SalePrice',axis=1)\ntrain = train.drop('Id',axis=1)","ca25ed99":"test_id = test['Id']\ntest = test.drop('Id', axis=1)","521c6e8d":"df = train.append(test)","7ee09ddd":"df['GarageCond'] = df['GarageCond'].map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['GarageQual'] = df['GarageQual'].map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['BsmtCond'] =  df['BsmtCond'].map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['BsmtExposure'] = df['BsmtExposure'].map({'NA':0, 'No':1, 'Mn':2, 'Av':3, 'Gd':4})\ndf['BsmtFinType1'] = df['BsmtFinType1'].map({'NA':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\ndf['BsmtFinType2'] = df['BsmtFinType2'].map({'NA':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\ndf['BsmtQual'] = df['BsmtQual'].map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['PoolQC'] = df['PoolQC'].map({'NA':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\ndf['Alley'] = df['Alley'].map({'NA':0, 'Grvl':1, 'Pave':2})\ndf['FireplaceQu'] = df['FireplaceQu'].map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['ExterCond'] = df['ExterCond'].map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['ExterQual'] = df['ExterQual'].map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['KitchenQual'] = df['KitchenQual'].map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['LandSlope'] = df['LandSlope'].map({'Sev':1, 'Mod':2, 'Gtl':3}) \ndf['PavedDrive'] = df['PavedDrive'].map({'N':1, 'P':2, 'Y':3})\ndf['Functional'] = df['Functional'].map({'Sal':1, 'Sev':2, 'Maj2':3, 'Maj1':4, 'Mod':5, 'Min2':6, 'Min1':7, 'Typ':8})\ndf['HeatingQC'] = df['HeatingQC'].map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\ndf['Street'] = df['Street'].map({'Grvl':1, 'Pave':2})\ndf['Utilities'] = df['Utilities'].map({'ELO':1, 'NoSeWa':2, 'NoSewr':3, 'AllPub':4})\n# Age have information about Month, because we can drop MoSold\ndf=df.drop('MoSold',axis=1)\n# in description MSSubClass is categorical data\ndf['MSSubClass'] = df['MSSubClass'].map({20:'class1', 30:'class2', 40:'class3', 45:'class4',\n                                   50:'class5', 60:'class6', 70:'class7', 75:'class8',\n                                   80:'class9', 85:'class10', 90:'class11', 120:'class12',\n                                   150:'class13', 160:'class14', 180:'class15', 190:'class16'})","f05a7a2a":"cat_columns = df.select_dtypes(exclude=np.number).columns \nnum_columns = df.select_dtypes(include=np.number).columns ","7a5b0432":"# visualize the distribution of each numerical feature\ntemp = pd.melt(df, value_vars=num_columns)\ngrid = sns.FacetGrid(temp, col=\"variable\",  col_wrap=5 , size=3.0, \n                     aspect=1.0,sharex=False, sharey=False)\ngrid.map(sns.distplot, \"value\")\nplt.show()","d4414662":"# box-plot of each numerical feature\ntemp = pd.melt(df, value_vars=num_columns)\ngrid = sns.FacetGrid(temp, col=\"variable\",  col_wrap=5 , size=3.0, \n                     aspect=1.0,sharex=False, sharey=False)\ngrid.map(sns.boxplot, \"value\")\nplt.show()","c7e3c7f3":"df = df.reset_index()\ndf = df.drop('index',axis = 1)","500128c1":"drop_id = df[df['LotArea'] > 100000].index","78df1e2f":"# we can to remove lines only from training\ndrop_id = drop_id[drop_id < 1459]","832aa62d":"# change some position in dataframe.\ndf['MasVnrArea'][df[df['MasVnrArea'] > 1500].index] = df['MasVnrArea'].mean()\ndf['Utilities'][df[df['Utilities']==2].index] = df['Utilities'].mean()","cdedc4bd":"df = df.drop(drop_id)","dade2017":"df = df.reset_index()","d3b49e1b":"y_train = y_train.drop(drop_id)","61334e01":"# create of list of dummy variables for drop\ndummy_drop = []\nfor i in cat_columns:\n    dummy_drop += [ i+'_'+str(df[i].unique()[-1]) ]\n\ndf = pd.get_dummies(df,columns=cat_columns) \n# drop the last column generated from each categorical feature\ndf = df.drop(dummy_drop,axis=1)","f94fcea6":"X_train  = df[:-1459].drop(['index'], axis=1)\nX_test  = df[-1459:].drop(['index'], axis=1)\n\nscaler = StandardScaler()\nX_train[num_columns]= scaler.fit_transform(X_train[num_columns])\nX_test[num_columns]= scaler.transform(X_test[num_columns])\n\nX_train.shape, X_test.shape ","8b14375e":"y_train_log = np.log(y_train)","bc3a94e4":"xgb = XGBRegressor()\nxgb.fit(X_train, y_train)\nimp_feature = pd.DataFrame(xgb.feature_importances_ ,columns = ['Importance'],index = X_train.columns)\nimp_feature = imp_feature.sort_values(['Importance'], ascending = False)\n\nprint(imp_feature)","0d9dc4e4":"ans = {}\n# choose the most important feature\nfor i in range(1, 222):\n    imp_col = imp_feature.iloc[:i].index\n    # these parameters are taken from previous experiments\n    ridge = KernelRidge(alpha = 0.5263157894736842, coef0 = 3.5, degree = 2, kernel ='polynomial')\n    ridge = ridge.fit(X_train[imp_col], y_train_log)\n    ans[i] = np.sqrt(mean_squared_error(y_train_log,ridge.predict(X_train[imp_col])))","c8d181e0":"minimum = ans[1]\nind_min = 1\nfor ind in range(1,len(ans.values())):\n    if ans[ind] < minimum:\n        minimum = ans[ind]\n        ind_min = ind","4bb31698":"imp_col = imp_feature.iloc[:ind_min+1].index","652bba32":"# metric\ndef neg_rmse(y_true, y_pred):\n    return -1.0*np.sqrt(mean_squared_error(y_true,y_pred))\n\nneg_rmse = make_scorer(neg_rmse)","4368f6d1":"model = KernelRidge(alpha = 0.6842105263157894, coef0 = 3.5, degree = 2, kernel = 'polynomial')\n\nmodel.fit(X_train[imp_col], y_train_log)\n\nprint(\"RMSE of the whole training set: {}\".format(np.sqrt(mean_squared_error(y_train_log,model.predict(X_train[imp_col])))))","79ddcd55":"# inverse conversion to logarithm\ny_pred = np.exp(model.predict(X_test[imp_col]))","e5b58937":"def save_ans(ans, pasanger_id, name_alg):\n    submission = pd.DataFrame({'Id':pasanger_id,'SalePrice':ans})\n    print(submission.shape) \n    filename = r'.\/{}.csv'.format(name_alg)\n    submission.to_csv(filename,index=False)\n    print('Saved file: ' + filename)","c2abde43":"save_ans(y_pred, test_id,'submission')","7facb4d8":"# 4. Anomaly","95cf01c3":"## 1.2 Test","1e8b9f91":"# 1. Downloading and exploring data","cee14e88":"# 3. Encoding\n\nSome of the properties can be processed manually, for example:\n\n**OverallQual**\n\n+ EX = 5\n+ GD = 4\n\nEX > GD and 5 > 4. The meaning will remain.\n\nBut we can't do that to others, for example:\n\n**MasVnrType**:\n\n+ BrkFace = 5\n+ Stone = 4\n\nTherefore, it is better to do it by hand, rather than using one hot encoding from sklearn","0042e502":"This will be important when transforming data","1ae4f2b0":"A lot of feature have missing values. Let's look at those that have more than 40% passes.","50f2bab2":"Let's look at the columns in which there are missing values on the test, but not on train","0c2af007":"Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. Therefore, we convert the data to a logarithm","bbd3f24f":"## 2.8 MiscFeature","8d03cd47":"ridge = KernelRidge()\n\nparameters = {'alpha': np.linspace(0, 1,20), 'kernel': ['polynomial','sigmoid','chi2','laplacian'], \n              'degree': [2], 'coef0':np.linspace(0, 3.5,21)}\n\ngrid_cv = GridSearchCV(estimator = ridge,\n                                   param_grid = parameters,\n                                   cv = 3,\n                                   scoring = neg_rmse,\n                                   n_jobs = -1)\n\ngrid_cv = grid_cv.fit(X_train[imp_col], y_train_log)\n\nprint(\"Parameters of the best_estimator:\")\n\nprint(grid_cv.best_params_)\n\nprint(\"Mean cross-validated RMSE of the best_estimator: {}\".format(-grid_cv.best_score_))\n\nmodel = grid_cv.best_estimator_\n\nprint(\"RMSE of the whole training set: {}\".format(np.sqrt(mean_squared_error(y_train_log,model.predict(X_train[imp_col])))))","7302405a":"## 2.1 Garage","c1c3760d":"Working with numerical missing data. Use it even for data because i'm gonna use random forest","ee890766":"# 6. Chose the most important feature","19e7e3df":"## 1.1 Train","c39b0cf6":"There is a pass in Electical, but there is only one, so we will delete this row","6760576b":"## 2.2 Basement","4317a6af":"The parameters for the model are taken from the cell next to it. For some reason kaggle runs this cell with a lot of errors. You can try to run this code at home or go to [github](https:\/\/github.com\/GubanovDenis\/kaggle-house-prices\/blob\/main\/house_prices_kernel_ridge.ipynb).\n","1dc3aa35":"## 2.7 Fence","e89dce72":"***Hi, everybody.***\n\n**This is my first notebook submission.**\n\n**I would like to know your opinion on this notebook. How i can improve it or fix some bugs?**\n\n**P.S. I am not a native English speaker. If you see an error or something is not clear, write in the comments, it will help me a lot.**\n\n**Thank you in advance.**","dc5b5bff":"# 2. Processing of missing values in groups","56525238":"## 2.4 Pool","a072fc0c":"Working with numerical missing data","a0457370":"# 7. Model","184c92e0":"## 2.6 Fireplace","edfa2a6f":"Working with numerical missing data","05baba91":"Working with categorical missing data","63c76ca6":"Working with categorical missing data","0cf9259c":"## 2.11 Other except LotFrontage","31b3cff2":"## 2.3 Masonry veneer ","4d023d31":"+ Alley - Missing values mean the absence of an alley\n+ FireplaceQu - Missing values mean the absence of a fireplace\n+ PoolQC - Missing values mean the absence of a pool\n+ Fence - Missing values mean the absence of a fence\n+ MiscFeature - Missing values mean the absence of a other feature.","52c72cd3":"Working with categorical missing data","9d8d8f13":"# 5. Encoding categorical\n\n\nCreate dummy variables and delete the last column generated from each categorical feature","20fb1bb3":"Encoding","89de52bc":"## 2.13 Drop SalePrice and Id from data","56f177c4":"## 2.12 LootFrontage","85add0f4":"## 2.10 MSZoning\nShould correlate with the location","7041cb76":"## 2.5 Alley","b25cee60":"## 7.1 Kernel Ridge","7e5d8c0c":"Let's create a new dataset that contains training and a test. It's easier to convert data this way","4ca8427b":"## 2.9 Electrical"}}