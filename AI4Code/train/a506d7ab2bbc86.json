{"cell_type":{"9ff17e96":"code","77669c57":"code","3fec397b":"code","adb0f297":"code","fd698ef2":"code","14331f1f":"code","bbf99898":"code","a9c6b8e5":"code","e6c790b7":"code","ae328ce4":"code","8824e437":"code","d3c04b04":"code","503f9d95":"code","0d48b873":"code","626be14c":"code","e962f3bf":"code","cd7706c4":"code","7805cb92":"code","ac0df8bf":"code","a7f815d6":"code","71aae07c":"markdown","423fc7d1":"markdown","9d0e0ee8":"markdown","d33808f3":"markdown","73f3cb99":"markdown","f9f07e9f":"markdown","72ce7806":"markdown","994428f6":"markdown","4503db83":"markdown","2fc8b91a":"markdown","021a13f6":"markdown"},"source":{"9ff17e96":"# Basic libraries\nimport pandas as pd\nimport numpy as np\nimport time\nimport datetime\nimport gc\n\n# Data preprocessing\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\n\n# LightGBM\nimport lightgbm as lgb\n\n# Validation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use(\"fivethirtyeight\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","77669c57":"# load master data\ntrain = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")\ncalendar = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")\nprice = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv\")","3fec397b":"# for submisson data\nvalid_df = pd.DataFrame(np.array(train.iloc[:,-28:])).astype(\"int16\")","adb0f297":"def calendar_preprocessing(df=calendar):\n    # int_col, change to light\n    int16_col = [\"wm_yr_wk\", \"wday\", \"month\", \"year\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n    df[int16_col] = df[int16_col].astype(\"int16\")\n    \n    # dtype of date is changed datetime64\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    # create month of day \n    df[\"mday\"] = df[\"date\"].dt.day.astype(\"int8\")\n    \n    # OrdinalEncoding\n    # event object to numerical, ordinal encoder\n    list_col = [\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n    # fill na by str 'no'\n    df[list_col] = df[list_col].fillna(\"na\")\n    # Roop \n    for i in list_col:\n        ce_oe = ce.OrdinalEncoder(cols=i, handle_unknown='impute') # Create instance of OrdinalEncoder\n        df = ce_oe.fit_transform(df)\n        df[i] = df[i].astype(\"int16\") # change to light dtype\n        \n    # shift 28days\n    col = ['wm_yr_wk', 'wday', 'month', 'year', 'event_name_1', 'event_type_1', \n           'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI','mday']\n    # Roop\n    for c in col:\n        df['shift28_{}'.format(c)] = df[c].shift(-28).fillna(1000).astype(\"int16\") # tempolary na is filled 1000\n\n    # Drop unnecessaly columns\n    df.drop(col, axis=1, inplace=True)\n    # drop weekday columns\n    df.drop(\"weekday\", axis=1, inplace=True)\n    # * for memory drop not important column\n    df.drop([\"shift28_event_type_1\", \"shift28_event_name_2\", \"shift28_event_type_2\"], axis=1, inplace=True)\n\n    return df\n\ndef price_preprocessing(df=price):\n    # int_col, change to light\n    int16_col = [\"wm_yr_wk\"]\n    df[int16_col] = df[int16_col].astype(\"int16\")\n    float16_col = [\"sell_price\"]\n    df[float16_col] = df[float16_col].astype(\"float16\")\n    \n    # shift 28days to upward\n    col = ['wm_yr_wk', 'sell_price']\n    df['shift28_{}'.format(col[0])] = df[col[0]].shift(-28).fillna(1000).astype(\"int16\") # tempolary na is filled 1000\n    df['shift28_{}'.format(col[1])] = df[col[1]].shift(-28).fillna(1000).astype(\"float16\") # tempolary na is filled 1000\n        \n\n    # Drop unnecessaly columns\n    df.drop(col, axis=1, inplace=True)\n    \n    return df\n\ndef train_preprocessing(df=train):\n    # int_col, change to light\n    int16_col = df.loc[:,\"d_1\":].columns\n    # dtype change\n    df[int16_col] = df[int16_col].astype(\"int16\")\n    \n    # for memory and light calculation, date range change to 3years, first date flag is d_818\n    drop_col = df.loc[:,\"d_1\":\"d_817\"]\n    df.drop(drop_col, axis=1, inplace=True)\n    \n    # change shape to vertical\n    id_col = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n    df = df.melt(id_vars=id_col, var_name=\"d\", value_name=\"volume\")\n\n    return df","fd698ef2":"# exe calendar data preprocessing\ncalendar = calendar_preprocessing(df=calendar)\ncalendar.dtypes","14331f1f":"# exe price data preprocessing\nprice = price_preprocessing(df=price)\nprice.dtypes","bbf99898":"# exe train data preprocessing\ntrain = train_preprocessing(df=train)\ntrain.dtypes","a9c6b8e5":"# data merge\n# train + calendar\nmaster = pd.merge(train, calendar, left_on=\"d\", right_on=\"d\", how=\"left\")\n\n# master + price\nmaster = pd.merge(master, price, left_on=[\"store_id\", \"item_id\", \"shift28_wm_yr_wk\"],\n                      right_on=[\"store_id\", \"item_id\", \"shift28_wm_yr_wk\"], how='left')","e6c790b7":"del train, calendar, price\ngc.collect()","ae328ce4":"# Data preprocessing and create trainig data and validation data and test data\n\n# 1) id_col change to light by changing numerical int columns\n# 2) drop \"d\" columns\n# 3) create lag features of volume\n# 3-1) lag 7 and 14 and 28, lag features is change difference from latest volume\n# 3-2) Rolling mean window is (7,28)\n# 4) Drop noise date, Xmas\n# 5) Special features\n# 6) target data\n\ndef Create_train_test_dataset(df=master, random_state=10):\n    # 0, No data of sell_price value is dropped\n    df.dropna(inplace=True)\n    # 1)\n    id_col = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n    for i in id_col:\n        ce_oe = ce.OrdinalEncoder(cols=i, handle_unknown='impute') # Create instance of OrdinalEncoder\n        df = ce_oe.fit_transform(df)\n        df[i] = df[i].astype(\"int16\") # change to light dtype\n    ###########################################################\n    # 2)\n    df.drop(\"d\", axis=1, inplace=True)\n    ###########################################################\n    # 3-1)\n    lags = [7, 14, 28]\n    for l in lags: # tempolary fillna by 1000\n        df[\"lag_{}\".format(l)] = df.groupby(\"id\")[\"volume\"].transform(lambda x: x.shift(l)).fillna(1000).astype(\"int16\")\n        df[\"lag_d_{}\".format(l)] = df.groupby(\"id\")[\"volume\"].transform(lambda x: x.shift(l) - x.shift(0)).fillna(1000).astype(\"int16\")\n    ###########################################################\n    # 3-2)    \n    window = [7,28]\n    for w in window:# tempolary fillna by 1000\n        for l in lags:\n            df[\"rolling_{}_lag_{}\".format(w,l)] = df.groupby(\"id\")[\"volume\"].transform(lambda x: x.rolling(w).mean().shift(l)).fillna(1000).astype(\"float16\")\n            df[\"rolling_{}_lag_d_{}\".format(w,l)] = df.groupby(\"id\")[\"volume\"].transform(lambda x: x.rolling(w).mean().shift(l) - x.rolling(w).mean().shift(0)).fillna(1000).astype(\"float16\")\n    ###########################################################\n    # 5-1) \n    # volume range\n    list_vol_flag = []\n    for v in df[\"volume\"]:\n        if v == 0:\n            flg = 0\n            list_vol_flag.append(flg)\n        elif v == 1:\n            flg = 1\n            list_vol_flag.append(flg)\n        elif v == 2:\n            flg = 2\n            list_vol_flag.append(flg)\n        elif v > 2 and v <= 5:\n            flg = 3\n            list_vol_flag.append(flg)\n        elif v > 5 and v <=20:\n            flg = 4\n            list_vol_flag.append(flg)\n        else :\n            flg=5\n            list_vol_flag.append(flg)\n    df[\"vol_range\"] = list_vol_flag\n    df[\"vol_range\"] = df[\"vol_range\"].astype(\"int16\")\n    \n    # 5-2)\n    # price lag(changing sell_price)\n    s_lag = [1,7]\n    for sl in s_lag: # tempolary fillna by 1000\n        df[\"lag_price_{}\".format(sl)] = df.groupby(\"id\")[\"shift28_sell_price\"].transform(lambda x: x.shift(sl) - x.shift(0)).fillna(1000).astype(\"float16\")\n    \n    ###########################################################\n    # target data columns, 28days future shift\n    df[\"target\"] = df.groupby(\"id\")[\"volume\"].transform(lambda x:x.shift(-28)).fillna(0).astype(\"int16\")\n    ###########################################################    \n    # 4) and create explanatory data and target data, and cut 56days that is tempolary filled\n    Xmas_date = [pd.datetime(2013,12,25), pd.datetime(2014,12,25), pd.datetime(2015,12,25)]\n    X = df[(df[\"date\"] <= df[\"date\"].max() - datetime.timedelta(days=28))\n            & (df[\"date\"] > df[\"date\"].min() + datetime.timedelta(days=56))].set_index(\"date\").drop(Xmas_date).drop([\"target\"], axis=1)\n    y = df[(df[\"date\"] <= df[\"date\"].max() - datetime.timedelta(days=28))\n            & (df[\"date\"] > df[\"date\"].min() + datetime.timedelta(days=56))].set_index(\"date\").drop(Xmas_date)[\"target\"]\n        \n    X_test = df[df[\"date\"] > df[\"date\"].max() - datetime.timedelta(days=28)].set_index(\"date\").drop([\"target\"], axis=1)\n    ###########################################################\n    # validation dataset\n    # Train test split\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=random_state)\n        \n    return X_train, X_val, y_train, y_val, X_test","8824e437":"%%time\n# Create dataset\nX_train, X_val, y_train, y_val, X_test = Create_train_test_dataset(df=master, random_state=10)","d3c04b04":"del master\ngc.collect()","503f9d95":"def lgbm_val(X_train, X_val, y_train, y_val):\n    # create dataset\n    train = lgb.Dataset(X_train, label = y_train)\n    valid = lgb.Dataset(X_val, label = y_val)\n    \n    # parameter setting\n    params = {\n        'metric': 'rmse',\n        'objective': 'poisson',\n        'seed': 200,\n        'force_row_wise' : True,\n        'learning_rate' : 0.07,\n        'lambda': 0.1,\n        'num_leaves': 60,\n        'sub_row' : 0.7,\n        'bagging_freq' : 1,\n        'colsample_bytree': 0.85\n    }\n    \n    # fitting\n    lgbm = lgb.train(params, \n                    train, \n                    num_boost_round = 800, \n                    valid_sets = [valid], \n                    early_stopping_rounds = 50,\n                    verbose_eval = 5)\n    \n    # plot feature importance by gain\n    lgb.plot_importance(lgbm, importance_type=\"gain\", precision=0, figsize=(6, 13));\n    \n    # MSE and R2 prediction\n    pred_train = lgbm.predict(X_train)\n    pred_val = lgbm.predict(X_val)\n    \n    return pred_train, pred_val, lgbm","0d48b873":"%%time\n# Ececution lgbm val\npred_train, pred_val, lgbm = lgbm_val(X_train, X_val, y_train, y_val)","626be14c":"print(\"MSE train %.3f\" % mean_squared_error(y_true=y_train, y_pred=pred_train))\nprint(\"MSE validation %.3f\" % mean_squared_error(y_true=y_val, y_pred=pred_val))\nprint(\"R2 score train %.3f\" % r2_score(y_true=y_train, y_pred=pred_train))\nprint(\"R2 score validation %.3f\" % r2_score(y_true=y_val, y_pred=pred_val))","e962f3bf":"del X_train, X_val, y_train, y_val, pred_train, pred_val\ngc.collect()","cd7706c4":"%%time\n# prediction\npred_test = lgbm.predict(X_test)\n\n# reshape and change to dataframe\npred = np.array(pred_test, dtype='float16')\npred = np.reshape(pred, (30490, 28), order='F')\npred_df = pd.DataFrame(pred)\n\npred_df.head()","7805cb92":"# submission\ncol = sample.loc[:,'F1':].columns\n\nsample[col] = pd.concat([pred_df, pred_df]).values # eval data is insert by prediction, tempolary\n\n# Submission data\nsample.to_csv(\"submission.csv\", index=False)","ac0df8bf":"sample.head()","a7f815d6":"sample.describe()","71aae07c":"Previous kernel<br>\n1st submission<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/m5-forecasting-eda-and-lgbm-prediction<br>\nEDA<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/eda-of-m5-forecast-data-categorical-and-timeserie","423fc7d1":"# create LGBM model and prediction","9d0e0ee8":"# Submission data","d33808f3":"## Data preprocessing","73f3cb99":"![train%20test%20data%20plan%204,%20M5%20forecast.jpg](attachment:train%20test%20data%20plan%204,%20M5%20forecast.jpg)","f9f07e9f":"Define functions","72ce7806":"I tried M5 forecast predicsion.This is my 2nd submission.<br>\nThe difference from the previous time is that the data shape of the training model was changed, not only the lag feature amount but also the date and the price feature amount were added, and from the EDA result, the category according to the lag value narrowing and the volume This is the point where variables are added.","994428f6":"![train%20test%20data%20plan%203,%20M5%20forecast.jpg](attachment:train%20test%20data%20plan%203,%20M5%20forecast.jpg)","4503db83":"Direction","2fc8b91a":"## Libraries","021a13f6":"## Data loading"}}