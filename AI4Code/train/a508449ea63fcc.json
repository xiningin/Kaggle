{"cell_type":{"437af8b3":"code","71ecaccb":"code","9fc4c520":"code","812356ae":"code","fca9fdb6":"code","e3f48b90":"code","3802fddb":"code","c11a2da3":"code","733a8f94":"code","6fb352d4":"code","11886e3f":"code","985ec26d":"code","152022ef":"code","fe1a67ef":"code","58e83174":"code","7c643ea4":"code","74795b12":"code","485e86d3":"code","976ee2f3":"code","8d68f80b":"code","3f809d1f":"code","4aee8c2a":"code","a6cf61ab":"code","1eba0d1b":"code","d7d2faf2":"code","4f5bdd3a":"code","a32fb699":"code","4bbe08e2":"code","61edc52c":"code","4088b9e7":"code","68ce4720":"markdown","30eaa99d":"markdown","aa4cd780":"markdown","b1e6dadb":"markdown","1c17f15c":"markdown","d18108d6":"markdown","e921bea1":"markdown","e26cbc4e":"markdown","d83523df":"markdown","fbf3955f":"markdown"},"source":{"437af8b3":"import os\ndef resolve_dir(Dir):\n    if not os.path.exists(Dir):\n        os.makedirs(Dir)","71ecaccb":"import pandas as pd\nimport numpy as np\n\nDataDir_1 = '\/kaggle\/input\/covid-19-xray-dataset'\nDataDir_2 = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray'\n\nprint(os.listdir(DataDir_1))\nprint(os.listdir(DataDir_2))","9fc4c520":"train_image_dir = DataDir_2 + '\/train'\ntest_image_dir = DataDir_2 + '\/test'\nval_image_dir = DataDir_2 + '\/val'\n\nimport cv2\nfrom tqdm import tqdm\n\nX_original = []\ny_original = []\n\nIMG_SIZE = 150\nColorCh = 1\n\nCATEGORIES = [\"NORMAL\",\"PNEUMONIA\"]\n\ndef getClass(num):\n    if num == 1:\n        return 2\n    else:\n        return 0\n    \ndef getColor():\n    if ColorCh == 1:\n        return cv2.IMREAD_GRAYSCALE\n    else:\n        return cv2.IMREAD_COLOR\n\ndef prepareData(Dir,loading):\n    for category in CATEGORIES:\n        path = os.path.join(Dir,category)\n        class_num = CATEGORIES.index(category)\n        \n        for img in tqdm(os.listdir(path)):\n            try:\n                img = cv2.imread(os.path.join(path,img), getColor())\n                \n                if ColorCh == 3:\n                    img = cv2.cvtColor(normal_image, cv2.COLOR_BGR2RGB)\n                    \n                #gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2GRAY)\n                \n                resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n\n                X_original.append(resized)\n                y_original.append(getClass(class_num))\n\n            except Exception as e:\n                pass\n\n\nprepareData(train_image_dir,'train_dataset')\nprepareData(test_image_dir,'test_dataset')\nprepareData(val_image_dir, 'val_dataset')","812356ae":"pneumonia_features = np.array(X_original).reshape(-1 , IMG_SIZE * IMG_SIZE * ColorCh)\npneumonia_label = np.array(y_original)\n\npneumonia_df = pd.DataFrame(pneumonia_features, dtype=np.int32)\npneumonia_df['label'] = pneumonia_label\n#pneumonia_df = pneumonia_df.sample(frac = 1, random_state=73)\n\npneumonia_df","fca9fdb6":"%%time\n# be patient, reading csv's may take some time ETC: < 20 sec ,low_memory=False\ncovid = pd.read_csv('..\/input\/covid-19-xray-dataset\/covid_19.csv', low_memory=False)\n\ncovid_features = covid.drop([\"label\"],axis = 1).to_numpy()\ncovid_labels = covid['label'].to_numpy()\n\ncovid_df = pd.DataFrame(covid_features, dtype=np.int32)\ncovid_df['label'] = covid_labels\n\ncovid_df","e3f48b90":"virus_df = pd.concat([pneumonia_df,covid_df ], ignore_index=False)\nvirus_df = virus_df.sample(frac = 1, random_state=73)\nvirus_df","3802fddb":"#virus_df.to_csv('virus_df.csv', header=False, index=False)\n#from IPython.display import FileLink\n#FileLink(r'.\/virus_df.csv')","c11a2da3":"print('> DataFrame shape: ',virus_df.shape)\nprint('> {} images '.format(virus_df.shape[0]))\nprint('> {} --> {} * {} pixels for each image ({}d scaled)'.format(virus_df.shape[1],IMG_SIZE,IMG_SIZE, ColorCh))","733a8f94":"label_count = pd.Series(virus_df['label'].values.ravel()).value_counts()\n\nprint('> Class 0 - Normal:\\t',label_count[0])\nprint('> Class 1 - Covid: \\t',label_count[1])\nprint('> Class 2 - Pneumonia: \\t',label_count[2])","6fb352d4":"print('> Class 0 - Normal:\\t',label_count[0])\nprint('> Class 1 - Covid: \\t',label_count[1])\nprint('> Class 2 - Pneumonia: \\t',label_count[2])","11886e3f":"import matplotlib.pyplot as plt\n\ndef getClassName(item):\n    if item == 1:\n        return 'COVID_19'\n    if item == 0:\n        return 'NORMAL'\n    if item == 2:\n        return 'PNEUMONIA'\n\ndef print_images(samples): \n    images = np.array(samples.drop([\"label\"],axis = 1), dtype='int32')\n    labels = samples['label'].to_numpy()    \n    fig=plt.figure(figsize=(20, 8))\n    columns = 4\n    rows = 1\n    \n    for i, image in enumerate(images):\n        fig.add_subplot(rows,columns,i + 1)\n        title = '{}'.format(getClassName(labels[i]))\n        \n        if ColorCh == 3:            \n            Sample_image = image.reshape(IMG_SIZE, IMG_SIZE, ColorCh)\n        \n        if ColorCh == 1:\n            Sample_image = image.reshape(IMG_SIZE, IMG_SIZE)\n            \n        plt.imshow(Sample_image, cmap='gray')\n        plt.title(title)\n        \n    plt.show()\n        \n\nnormal_samples = (virus_df[virus_df['label']==0].iloc[0:4])\nprint_images(normal_samples)\n\ncovid_samples = (virus_df[virus_df['label']==1].iloc[0:4])\nprint_images(covid_samples)\n\npneumonia__samples = (virus_df[virus_df['label']==2].iloc[0:4])\nprint_images(pneumonia__samples)\n\n%matplotlib inline","985ec26d":"from sklearn.model_selection import StratifiedShuffleSplit\n\nfeatures = virus_df.drop([\"label\"],axis = 1).to_numpy()\nlabels = virus_df['label'].to_numpy()\n\nstratified_sample = StratifiedShuffleSplit(n_splits=3, test_size=0.17, random_state=73)","152022ef":"for train_index, test_index in stratified_sample.split(features, labels):\n    X_train, test_X = features[train_index], features[test_index]\n    y_train, test_y = labels[train_index], labels[test_index]\n    \nhalf_size = np.int(len(test_X) \/ 2)\nX_val, y_val = test_X[0:half_size], test_y[0:half_size]\nX_test, y_test = test_X[half_size:], test_y[half_size:]","fe1a67ef":"# data summary\nprint('> {} train size'.format(X_train.shape[0]))\nprint('> {} test size'.format(X_test.shape[0]))\nprint('> {} val size'.format(X_val.shape[0]))","58e83174":"# normalize\nX_train_nn = X_train.reshape(-1,IMG_SIZE,IMG_SIZE,ColorCh) \/ 255\nX_test_nn = X_test.reshape(-1,IMG_SIZE,IMG_SIZE,ColorCh) \/ 255\nX_val_nn = X_val.reshape(-1,IMG_SIZE,IMG_SIZE,ColorCh) \/ 255\ninput_shape = X_train_nn.shape[1:]\n\nprint(input_shape)","7c643ea4":"# TPU init\nTPU_INIT = True\nimport tensorflow as tf\n\nif TPU_INIT:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","74795b12":"from tensorflow.keras.layers import Activation, Input ,Conv2D, MaxPooling2D, MaxPool2D, Dropout, Dense, Activation, Flatten, SeparableConv2D, DepthwiseConv2D, AveragePooling2D, GlobalAveragePooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom keras import regularizers\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n\nkernel_regularizer = regularizers.l2(0.0001)\n#kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)\nbias_regularizer=regularizers.l2(1e-4)\nactivity_regularizer=regularizers.l2(1e-5)\n\nfinal_activation = 'softmax'\nentropy = 'sparse_categorical_crossentropy'\n\nn_classes = len(label_count)\nprint('N_classes: ', n_classes)","485e86d3":"def CustomNet():\n    model = tf.keras.models.Sequential()\n    \n    model.add(tf.keras.Input(shape=input_shape))\n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n    \n    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n    \n    model.add(Conv2D(filters=128, kernel_size=(5,5), padding='same', activation='relu'))        \n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n\n    model.add(Conv2D(filters=256, kernel_size=(5,5), padding='same', activation='relu'))        \n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.7))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.7))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.7))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.7))\n    \n    model.add(Dense(3,activation='softmax'))\n    return model\n\nfrom tensorflow.keras.applications import MobileNet, MobileNetV2\n\ndef MobileNet_Model():\n    baseModel = MobileNet(\n                          weights=None,\n                          include_top=False, input_tensor=Input(shape=input_shape))    \n    baseModel.trainable = True\n    headModel = baseModel.output\n\n    headModel = AveragePooling2D(pool_size=(4))(headModel)\n    headModel = Flatten()(headModel)\n    \n    #headModel = GlobalAveragePooling2D()(headModel)\n    \n    headModel = Dense(512, activation=\"relu\")(headModel)\n    headModel = Dropout(0.7)(headModel)\n    headModel = Dense(512, activation=\"relu\")(headModel)\n    headModel = Dropout(0.7)(headModel)  \n    headModel = Dense(512, activation=\"relu\")(headModel)\n    headModel = Dropout(0.7)(headModel)  \n    headModel = Dense(512, activation=\"relu\")(headModel)\n    headModel = Dropout(0.7)(headModel)\n    \n    headModel = Dense(n_classes, activation=final_activation)(headModel)\n    model = Model(inputs = baseModel.input, outputs = headModel)\n    \n    return model\n    \n    \n    \ndef AlexNet_Model():\n    AlexNet = Sequential()\n  \n    AlexNet.add(Conv2D(filters=96, kernel_size=11, strides=4, activation='relu', input_shape = input_shape))\n    AlexNet.add(MaxPool2D(pool_size=3, strides=2))\n\n    AlexNet.add(Conv2D(filters=256, kernel_size=5, padding='same', activation='relu'))\n    AlexNet.add(MaxPool2D(pool_size=3, strides=2))\n\n    AlexNet.add(Conv2D(filters=384, kernel_size=3, padding='same', activation='relu'))\n    AlexNet.add(Conv2D(filters=384, kernel_size=3, padding='same', activation='relu'))\n    AlexNet.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n    AlexNet.add(MaxPool2D(pool_size=3, strides=2))\n    \n    AlexNet.add(Flatten())\n\n    #AlexNet.add(GlobalAveragePooling2D())\n    \n    AlexNet.add(Dense(512, activation=\"relu\"))\n    AlexNet.add(Dropout(0.8))\n    AlexNet.add(Dense(512, activation=\"relu\"))\n    AlexNet.add(Dropout(0.8))\n    AlexNet.add(Dense(512, activation=\"relu\"))\n    AlexNet.add(Dropout(0.8))\n    AlexNet.add(Dense(512, activation=\"relu\"))\n    AlexNet.add(Dropout(0.8))\n    \n    AlexNet.add(Dense(3, activation=final_activation))\n\n    return AlexNet\n\n    \ndef VGG_Model():\n    vgg_model = Sequential()\n\n    vgg_model.add(Conv2D(input_shape=(input_shape),filters=64,kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    vgg_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    vgg_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    \n    vgg_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    \n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    \n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    vgg_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    vgg_model.add(Flatten())\n    \n    vgg_model.add(Dense(units=4096,activation=\"relu\"))\n    vgg_model.add(Dropout(0.8))\n    vgg_model.add(Dense(units=4096,activation=\"relu\"))\n    vgg_model.add(Dropout(0.8))\n    \n    vgg_model.add(Dense(units=n_classes, activation=final_activation))\n\n    model = vgg_model\n    return model","976ee2f3":"EPOCHS = 500\npatience = 25\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\nbatch_size = 16\n\n#Stochastic Gradient Descent\nif TPU_INIT:\n    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n\n\ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        return (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n\nclass end_callback(Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if ((logs.get('accuracy')>=0.999)):\n            print(\"\\nLimits Reached cancelling training!\")\n            self.model.stop_training = True","8d68f80b":"def load_model():\n    #model = CustomNet()\n    #model = AlexNet_Model()\n    model = VGG_Model()\n    #model = MobileNet_Model()\n    \n    model.compile(Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss=entropy,metrics=['accuracy'])\n    return model\n    \nif TPU_INIT:    \n    with tpu_strategy.scope():\n        model = load_model()\nelse:\n    model = load_model()\n\nprint(model.summary())\n\n\ncheckpoint_filepath = 'Model_Weights.h5'\n!rm -rf {checkpoint_filepath}\nearly_stopping = EarlyStopping(patience = patience, monitor='val_loss', mode='min', restore_best_weights=True)\n\nmodel_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n                                        save_weights_only=True,\n                                        monitor='val_loss',\n                                        mode='min',\n                                        save_best_only=True)\n\nlr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n\nmy_callbacks = [\n    early_stopping,\n    model_checkpoints,\n    lr_callback,\n    end_callback()\n]\n\nhistory = model.fit(X_train_nn ,y_train, epochs=EPOCHS,\n                        callbacks=my_callbacks,\n                        validation_data = (X_val_nn, y_val),\n                        batch_size=batch_size)\n\nmodel.load_weights(checkpoint_filepath)\n\nfrom IPython.display import clear_output\nclear_output()\n\nprint(model.summary())\nprint('Total Epochs :', len(history.history['loss']))\nprint('Accuracy on train:',history.history['accuracy'][-1],'\\tLoss on train:',history.history['loss'][-1])\nprint('Accuracy on val :',history.history['val_accuracy'][-1],'\\tLoss on val:',history.history['val_loss'][-1])","3f809d1f":"# CNN training results\nval_loss, val_accuracy = model.evaluate(X_val_nn, y_val, verbose=0)\n\ndef get_best_epoch():\n    for key, item in enumerate(history.history.items()):\n        (name, arr) = item\n        if name == 'val_loss':\n            for i in range(len(arr)):\n                if round(val_loss, 2) == round(arr[i], 2):\n                    return i\n        \n\nindex = get_best_epoch()\nprint('Best Epochs: ', index)\n\ntrain_accuracy = history.history['accuracy'][index]\ntrain_loss = history.history['loss'][index]\n\ntest_loss, test_accuracy = model.evaluate(X_test_nn, y_test, verbose=0)\n\nprint('Accuracy on train:',train_accuracy,'\\tLoss on train:',train_loss)\nprint('Accuracy on test:',test_accuracy,'\\tLoss on test:',test_loss)\nprint('Accuracy on val:',val_accuracy,'\\tLoss on val:',val_loss)\n\n\ndef print_graph(item):\n    train_values = history.history[item][0:index]\n    plt.plot(train_values)\n    test_values = history.history['val_' + item][0:index]\n    plt.plot(test_values)\n    plt.legend(['training','validation'])\n    plt.title('Training and validation '+ item)\n    plt.xlabel('epoch')\n    plt.show()\n\nprint_graph('loss')\nprint_graph('accuracy')","4aee8c2a":"def _n_Rows_to_render(n_wrongs):\n    if(n_wrongs <= 5):\n        return 1\n    if(n_wrongs <= 10):\n        return 2\n    if(n_wrongs <= 15):\n        return 3\n    if(n_wrongs <= 20):\n        return 4\n    if(n_wrongs <= 25):\n        return 5\n    \nfrom sklearn import metrics\n\ndef test_set_results(name,pred_value):\n    corr_pred = metrics.confusion_matrix(y_test,pred_value)\n    n_correct = np.int((corr_pred[0][0] + corr_pred[1][1] + corr_pred[2][2]))\n    print('...'*15)\n    print('> ',name,'Correct Predictions:',n_correct)\n    n_wrongs = np.int((corr_pred[0][1] + corr_pred[0][2]) + (corr_pred[1][0] + corr_pred[1][2]) + (corr_pred[2][0]  + corr_pred[2][1]))\n    print('> ',name,'Wrong Predictions:',n_wrongs)\n    print('...'*15)\n    #print(corr_pred)\n    print('Confusion Matrix')\n    import seaborn as sns\n    sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Blues\")\n    plt.show() \n    \n    columns = 5\n    rows = _n_Rows_to_render(n_wrongs)\n    wrong_pred_fig=plt.figure(figsize=(20, 10))\n    \n    print('Wrongly Predicted images')\n    i = 0\n    for row_index, (input, prediction, label) in enumerate(zip (X_test, pred_value, y_test)):\n        if prediction != label:\n            title = (\"id:{}, Predicted: {}, Correct: {}\").format(row_index,prediction,label)\n            if n_wrongs <= 25:\n                wrong_pred_fig.add_subplot(rows,columns,i + 1)\n                image = X_test[row_index].reshape(IMG_SIZE, IMG_SIZE, ColorCh)\n                plt.imshow(image,cmap='gray',aspect=1)\n                plt.axis('off')\n                plt.title(title)\n                i = i + 1\n            \n    plt.show()","a6cf61ab":"print('Model Evaluation on the test_set')\n\ncnn_test_model = model.predict(X_test_nn)\ncnn_prob = []\n\ndef getClass(val):\n    normal = val[0]\n    covid = val[1]\n    pneumonia = val[2]\n    \n    if((normal > covid) & (normal > pneumonia)):\n        return 0\n    \n    if((pneumonia > normal) & (pneumonia > covid)):\n        return 2\n    \n    if((covid > normal) & (covid > pneumonia)):\n        return 1\n\n    \nfor i in range(len(X_test)):\n    pred = getClass(cnn_test_model[i])\n    cnn_prob.append(pred)\n\ntest_set_results('CNN',cnn_prob)","1eba0d1b":"image_id = 66\n\ndef print_results(val):\n  if val == 0:\n    return 'Normal (-ve)'\n  if val == 1:\n    return 'COVID_19 (+ve)'\n  if val == 2:\n    return 'Baterial (+ve)'\n\nsample_cnn_pred = model.predict(X_test_nn[image_id].reshape(1,IMG_SIZE,IMG_SIZE,1))\nprobability = getClass(sample_cnn_pred[0])\n\nprint('CNN Prediction:',print_results(probability))\nprint('Correct Answer:',print_results(y_test[image_id]))\n\nplt.imshow(X_test[image_id].reshape(IMG_SIZE,IMG_SIZE),cmap='gray')\nplt.show()","d7d2faf2":"from IPython.display import FileLink","4f5bdd3a":"# tensorflow model\nos.system('rm -f \/kaggle\/working\/covid_cnn_model.h5')\nmodel.save('covid_cnn_model.h5')\nFileLink(r'.\/covid_cnn_model.h5')","a32fb699":"# Saving tensorflow js model\nos.system('rm -f \/kaggle\/working\/tfjsmodel.zip && rm -f \/kaggle\/working\/my_tfjs\/*')\nos.system('pip install tensorflowjs')\nos.system('tensorflowjs_converter --input_format=keras covid_cnn_model.h5 my_tfjs')\nimport shutil\nshutil.make_archive('tfjsmodel', 'zip', 'my_tfjs')\nFileLink(r'.\/tfjsmodel.zip')","4bbe08e2":"# Saving TF-lite-model\n#tf_lite_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n#open(\"covid_model_lite.tflite\", \"wb\").write(tf_lite_model)\n#FileLink(r'.\/covid_model_lite.tflite')","61edc52c":"print('Saved Models :', os.listdir('\/kaggle\/working\/'))","4088b9e7":"from IPython.display import IFrame\nIFrame(src='https:\/\/model-tester.web.app\/covid_19', width='100%', height=1000)","68ce4720":"## Data Preprocessing","30eaa99d":"## Tensorflow JS model \n+ Supported Platforms: (Android, IOS, WEB)","aa4cd780":"### Single image test","b1e6dadb":"## Preparing dataframes","1c17f15c":"## Multiclass classification with CNN","d18108d6":"## Saving Model","e921bea1":"## Restoring Best Weights","e26cbc4e":"## Data Summary","d83523df":"## Combining (pneumonia & covid_19) datasets","fbf3955f":"## Model evaluation"}}