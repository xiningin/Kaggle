{"cell_type":{"f2435b6d":"code","0a3940c8":"code","8d37b7e8":"code","538c1a7b":"code","6c957847":"code","078c2798":"code","4d3c60d0":"code","3a132b91":"code","e7eee6ac":"code","62080a69":"code","db7b3eef":"code","dc7cb8bb":"code","1177a1e8":"code","a1e15672":"code","382ea37e":"code","8cb8f9b5":"code","5b8fb0f6":"code","cb7e35ba":"code","b9a68026":"code","f30d3d94":"code","4e1227fd":"code","4bda5c3d":"code","9909b3da":"markdown","088b9db0":"markdown","8b68481e":"markdown","ecc33fc8":"markdown"},"source":{"f2435b6d":"%pylab inline\nimport pandas as pd","0a3940c8":"train_data = pd.read_csv(\"..\/input\/datamining2021\/train_data.csv\", encoding=\"utf8\")","8d37b7e8":"train_data.head()","538c1a7b":"train_data.author.unique().shape","6c957847":"target = pd.read_csv(\"..\/input\/datamining2021\/train_target.csv\")","078c2798":"target.head()","4d3c60d0":"subreddits = train_data.subreddit.unique()\nsubreddits_map = pd.Series(index=subreddits, data=arange(subreddits.shape[0]))","3a132b91":"from scipy import sparse","e7eee6ac":"def extract_features(group):\n    group_subreddits = group['subreddit']\n    group_subreddits = group_subreddits[group_subreddits.isin(subreddits_map.index)].values\n    idxs = subreddits_map.loc[group_subreddits].values\n    v = sparse.dok_matrix((1, subreddits.shape[0]))\n    for idx in idxs:\n        if not np.isnan(idx):\n            v[0, idx] = 1\n    return v.tocsr()\n\nextract_features(train_data[train_data.author=='RedThunder90'])","62080a69":"features_dict = {}\n\nfor author, group in train_data.groupby('author'):\n    features_dict[author] = extract_features(group)","db7b3eef":"X = sparse.vstack([features_dict[author] for author in target.author])\nX","dc7cb8bb":"y = target.gender","1177a1e8":"def extract_text(group):\n    group_text = group['body'].values\n    return \" \".join(group_text)\n\nextract_text(train_data[train_data.author=='RedThunder90'])","a1e15672":"text_dict = {}\n\nfor author, group in train_data.groupby('author'):\n    text_dict[author] = extract_text(group)","382ea37e":"author_text = [text_dict[author] for author in target.author]\nauthor_text[0][:100]","8cb8f9b5":"# YOUR CODE HERE\n\nclass Model():\n    def predict_proba(self, X):\n        return np.zeros((X.shape[0], 2))\n    \nmodel = Model()","5b8fb0f6":"test_data = pd.read_csv(\"..\/input\/datamining2021\/test_data.csv\", encoding=\"utf8\")","cb7e35ba":"features_dict = {}\n\nfor author, group in test_data.groupby('author'):\n    features_dict[author] = extract_features(group)","b9a68026":"X_test = sparse.vstack([features_dict[author] for author in test_data.author.unique()])\nX_test","f30d3d94":"y_pred = model.predict_proba(X_test)[:,1]","4e1227fd":"solution = pd.DataFrame({\"author\":test_data.author.unique(), \"gender\":y_pred})\nsolution.head()","4bda5c3d":"# solution.to_csv(\"solution.csv\", index=False)","9909b3da":"# Feature Extraction","088b9db0":"# Prepare the solution","8b68481e":"# Load the train data","ecc33fc8":"# Model Selection"}}