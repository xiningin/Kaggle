{"cell_type":{"adf99283":"code","12641f30":"code","54d8c974":"code","81dce67e":"code","c80b4fe5":"code","cfdbcd21":"code","8dcf4b02":"code","785507fd":"code","e69e710d":"code","f8182dc9":"code","ae5d675d":"code","aad0d1f0":"code","48081968":"code","3bb811fb":"code","bd40043d":"code","ac392be6":"code","0be8730d":"code","c146b0ce":"code","e7d1cea1":"code","c685d950":"code","e98dbe90":"code","3a9f0a27":"markdown","622a5d4a":"markdown","d1a7fd2a":"markdown","9efad526":"markdown","000ad09f":"markdown","2f3d3c05":"markdown","4177c71b":"markdown","9121dedf":"markdown","dfeaf280":"markdown","33f6d6c7":"markdown","21b60299":"markdown","b5d42df1":"markdown","7cf02b19":"markdown","c2b283c5":"markdown","e5422b5e":"markdown","55d313d7":"markdown","2be207c8":"markdown","e1b7cb9a":"markdown","ca6f346d":"markdown","77e8fa70":"markdown"},"source":{"adf99283":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\nwarnings.filterwarnings(\"ignore\")","12641f30":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsamplesub_df = pd.read_csv('..\/input\/sample_submission.csv')","54d8c974":"train_df.head()","81dce67e":"test_df.head()","c80b4fe5":"samplesub_df.head()","cfdbcd21":"print(train_df.shape, test_df.shape,samplesub_df.shape)","8dcf4b02":"print(train_df['target'].unique())","785507fd":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.countplot(train_df['target'])","e69e710d":"plt.figure(figsize=[8,8])\ntrain_df['target'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',shadow=True)\nplt.show()","f8182dc9":"print(train_df['target'].value_counts())\nTotal = np.add(train_df['target'].where(train_df['target']==1).value_counts(), \n               train_df['target'].where(train_df['target']==0).value_counts())\nprint('target 1 : ',(train_df['target'].where(train_df['target']==1).value_counts()\/Total)*100)\nprint('target 0 : ',100 - (train_df['target'].where(train_df['target']==1).value_counts()\/Total)*100)","ae5d675d":"print(train_df.isnull().any().sum())\nprint(test_df.isnull().any().sum())","aad0d1f0":"train_df.describe()","48081968":"cols = ['target','id']\nX = train_df.drop(cols,axis=1)\ny = train_df['target']\nX_test = test_df.drop('id',axis=1)","3bb811fb":"from sklearn.model_selection import cross_val_score\n\n#defining a generic Function to give ROC_AUC Scores in table format for better readability\ndef crossvalscore(model):\n    scores = cross_val_score(model,X,y,cv=5,scoring='roc_auc',n_jobs=-1)\n    acc = cross_val_score(model,X,y,cv=5,scoring='accuracy',n_jobs=-1)\n    rand_scores = pd.DataFrame({\n    'cv':range(1,6),\n    'roc_auc score':scores,\n    'accuracy score':acc\n    })\n    print('AUC :',rand_scores['roc_auc score'].mean())\n    print('accuracy :',rand_scores['accuracy score'].mean())\n    return rand_scores.sort_values(by='roc_auc score',ascending=False)","bd40043d":"from sklearn.ensemble import RandomForestClassifier\nrand_clf = RandomForestClassifier(max_depth=2,random_state=42)\ncrossvalscore(rand_clf)","ac392be6":"#logistic regression using PCA\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\npca = PCA(n_components=42)\nX_new = pca.fit_transform(X)\n\nlog_clf = LogisticRegression(C = 0.1, class_weight= 'balanced', penalty= 'l1', solver= 'liblinear',random_state=42)\nscores = cross_val_score(log_clf,X_new,y,cv=5,scoring='roc_auc',n_jobs=-1)\nacc = cross_val_score(log_clf,X_new,y,cv=5,scoring='accuracy',n_jobs=-1)\nrand_scores = pd.DataFrame({\n'cv':range(1,6),\n'roc_auc score':scores,\n'accuracy score':acc\n})\nprint('AUC :',rand_scores['roc_auc score'].mean())\nprint('accuracy :',rand_scores['accuracy score'].mean())\nrand_scores.sort_values(by='roc_auc score',ascending=False)","0be8730d":"from sklearn.linear_model import LogisticRegression\n#simple logistic regression with lasso regularization\nlog_clf = LogisticRegression(C = 0.1, class_weight= 'balanced', penalty= 'l1', solver= 'liblinear',random_state=42)\ncrossvalscore(log_clf)","c146b0ce":"from sklearn.feature_selection import RFE\nlog_clf = LogisticRegression(C = 0.1, class_weight= 'balanced', penalty= 'l1', solver= 'liblinear',random_state=42)\nselector = RFE(log_clf,21)\nselector.fit(X,y)\ncrossvalscore(selector)","e7d1cea1":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(loss='log',penalty='elasticnet')\ncrossvalscore(sgd_clf)","c685d950":"from sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import VotingClassifier,BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nlog_clf = LogisticRegression(C = 0.1, class_weight= 'balanced', penalty= 'l1', solver= 'liblinear',random_state=42)\nlog_selector = RFE(log_clf,21)\nlog_selector.fit(X,y)\nrand_clf = RandomForestClassifier(max_depth=2,random_state=42)\nsvm_clf = SVC(gamma='auto',probability=True, random_state=42)\nextra_clf = ExtraTreesClassifier(max_depth=2,random_state=42)\n#ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200,algorithm='SAMME.R', learning_rate=0.5, random_state=42)\n\nvoting_clf = VotingClassifier(\n    estimators = [('lr',log_selector),('rf',rand_clf),('ex',extra_clf),('sv',svm_clf)],\n    voting='soft')\ncrossvalscore(selector)","e98dbe90":"voting_clf.fit(X,y)\n\n#submission = pd.read_csv('..\/input\/sample_submission.csv')\n#submission['target'] = voting_clf.predict_proba(X_test)\n#submission.to_csv('submission1.csv', index=False)","3a9f0a27":"Visualizing how balanced the training set is,","622a5d4a":"Load the data into training set & test set","d1a7fd2a":"Though soft voting classifier gave me better ROC_AUC socre on training set,i got just 0.822 Public score for some reason.\n\nso i had to settle with Logistic Regression with lasso + RFE model which gave 0.841 public score","9efad526":"Luckily we don't have any missing values in both training set & test set.\nnothing to do more here..","000ad09f":"**3. logistic regression with lasso regularization and recursive feature elimination**","2f3d3c05":"**4. Soft Voting Classifier**","4177c71b":"**Final ROC_AUC SCORE (Public score) = 0.841**\n\n* Basic EDA\n* RandomForestClassifer\n* LogisticRegression (+lasso)\n* Feature selection - RFE, PCA","9121dedf":"**LogisticRegression using PCA data**","dfeaf280":"* RandomForest Classifier has just avg 0.63 roc_auc score with an accuracy of 64%.\nlet's try some other algorithm","33f6d6c7":"training set has more features than observations. It is a small dataset which leads to overfitting easily for many algorithms with default hyperparameters","21b60299":"**2. Logistic Regression with Regularization**","b5d42df1":"**1. RandomForest Classifier**","7cf02b19":"avg roc_auc score is now 0.74 with 65% accuracy.\n\nThis is better than RandomForestClassifier scores","c2b283c5":"Just the mathematical way of above graph,","e5422b5e":"avg roc_auc score is improved to 0.813 now with an accuracy of 68%.","55d313d7":"***avg roc_auc score is now 0.814 with 70% accuracy.***\n\nThis is the best score i got compared to all above algorithms","2be207c8":"**BASIC EDA**","e1b7cb9a":"we dont need 'Id' column as it is unnecessary for model training,","ca6f346d":"Just two classes we need to predict. either 1 or 0","77e8fa70":"**Just trying Logistic regression with elastic net**\n\nimplements logistic regression with elastic net penalty (SGDClassifier(loss=\"log\", penalty=\"elasticnet\"))."}}