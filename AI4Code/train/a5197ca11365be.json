{"cell_type":{"932b725c":"code","f2c69a37":"code","3e8416f8":"code","fbc5f7cb":"code","1f7bd433":"code","546c75ea":"code","ca8e69d8":"markdown"},"source":{"932b725c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f2c69a37":"import pandas as pd\nimport math\nimport scipy.stats as st\nfrom sklearn.preprocessing import MinMaxScaler\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n","3e8416f8":"#reading the dataset\ndf_ = pd.read_csv(\"..\/input\/amazon-reviews\/amazon_review.csv\")\ndf = df_.copy()\n\ndf.head(20)\ndf.describe().T\ndf[\"overall\"].value_counts()\n\"\"\"\nRating     Vote\n5.00000    3922\n4.00000     527\n1.00000     244\n3.00000     142\n2.00000      80\n\n\"\"\"\n\ndf.sort_values(\"day_diff\", ascending = False).head(20)\ndf[\"overall\"].mean()\n#4.5875\n","fbc5f7cb":"#time based weighted average\n\n\n#reaching and observing quantiles for variable \"day_diff\".\n#%10,%25,%50,%75.\ndf[\"day_diff\"].max()\na = df[\"day_diff\"].quantile(0.10)\n#167\nb = df[\"day_diff\"].quantile(0.25)\n#281\nc = df[\"day_diff\"].quantile(0.50)\n#431\nd = df[\"day_diff\"].quantile(0.75)\n#601\n\ndf.loc[df[\"day_diff\"] <= 167, \"overall\"].mean() * 30 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > a) & (df[\"day_diff\"] <= b), \"overall\"].mean() * 21 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > b) & (df[\"day_diff\"] <= c), \"overall\"].mean() * 19 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > c) & (df[\"day_diff\"] <= d), \"overall\"].mean() * 17 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > d) & (df[\"day_diff\"] <= 1064), \"overall\"].mean() * 13 \/ 100\n#functionalizing\ndef time_weighted_average(dataframe,w1 = 30,w2 = 21 ,w3 = 19, w4 = 17 ,w5 = 13):\n   return dataframe.loc[dataframe[\"day_diff\"] <= 167, \"overall\"].mean() * w1 \/ 100 + \\\n    dataframe.loc[(dataframe[\"day_diff\"] > a) & (dataframe[\"day_diff\"] <= b), \"overall\"].mean() * w2 \/ 100 + \\\n    dataframe.loc[(dataframe[\"day_diff\"] > b) & (dataframe[\"day_diff\"] <= c), \"overall\"].mean() * w3 \/ 100 + \\\n    dataframe.loc[(dataframe[\"day_diff\"] > c) & (dataframe[\"day_diff\"] <= d), \"overall\"].mean() * w4 \/ 100 + \\\n    dataframe.loc[(dataframe[\"day_diff\"] > d) & (dataframe[\"day_diff\"] <= 1064), \"overall\"].mean() * w5 \/ 100\ntime_weighted_average(df)\n#4.6299\n\n#normal average was 4.5875 so we made a considerable difference by using time weighted average.\n","1f7bd433":"#User Review Based Average\n\n#we should focus on \"helpful_yes\".\ndf[\"helpful_yes\"].describe().T\ndf[\"helpful_yes\"].unique()\n\ndf.groupby(\"overall\").agg({\"reviewText\":\"count\"})\n\n#let's create a variable for observing \"thumbs down\".\ndf[\"helpful_no\"] = df[\"total_vote\"] - df[\"helpful_yes\"]\ndf.head()\n\n\n#average rating by up\/down\n\ndef up_down_average(x,y):\n   if x + y == 0:\n      return 0\n    return  x \/ (x + y)\n\nup_down_average(20, 15)\n\n#up_down_average rating\n\ndf[\"up_down_ratio\"] = df.apply(lambda x: up_down_average(x[\"helpful_yes\"], x[\"helpful_no\"]), axis=1)\n\ndf[\"up_down_ratio\"].max()\ndf.sort_values(\"overall\").head(20)\n","546c75ea":"\n#wilson lower bound\n\"\"\"\nwith wilson lower bound we'll sort the reviews better.\n\"lower bound of Wilson score confidence interval for a Bernoulli parameter provides a way to sort a product based on positive and negative ratings.\"\n\"\"\"\n\n\ndef wilson_lower_bound(up, down, confidence=0.95):\n    \"\"\"\n    Wilson Lower Bound Score hesapla\n\n    - Bernoulli parametresi p i\u00e7in hesaplanacak g\u00fcven aral\u0131\u011f\u0131n\u0131n alt s\u0131n\u0131r\u0131 WLB skoru olarak kabul edilir.\n    - Hesaplanacak skor \u00fcr\u00fcn s\u0131ralamas\u0131 i\u00e7in kullan\u0131l\u0131r.\n\n    - Not:\n    E\u011fer skorlar 1-5 aras\u0131ndaysa 1-3 negatif, 4-5 pozitif olarak i\u015faretlenir ve bernoulli'ye uygun hale getirilebilir.\n    Bu beraberinde baz\u0131 problemleri de getirir. Bu sebeple bayesian average rating yapmak gerekir.\n\n    Parameters\n    ----------\n    up: int\n        up count\n    down: int\n        down count\n    confidence: float\n        confidence\n\n    Returns\n    -------\n    wilson score: float\n\n    \"\"\"\n    n = up + down\n    if n == 0:\n        return 0\n    z = st.norm.ppf(1 - (1 - confidence) \/ 2)\n    phat = 1.0 * up \/ n\n    return (phat + z * z \/ (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z \/ (4 * n)) \/ n)) \/ (1 + z * z \/ n)\n\n\ndf[\"wilson_lower_bound\"] = df.apply(lambda x: wilson_lower_bound(x[\"helpful_yes\"], x[\"helpful_no\"]), axis=1)\ndf.sort_values(\"wilson_lower_bound\", ascending=False).head(20)\n","ca8e69d8":"Our goal in this project is to properly rank ratings and comments on an SD card. We'll use Amazon data. We'll sort user reviews by time weighted average and wilson lower bound method.\n\n**Dataset\n\nThis dataset contains amazon product information and various metadata.It includes product with the most comments in the electronics category and its ratings and reviews.\n\nVARIABLES\n\nreviewerID <- UserID\n\nasin <- ProductID\n\nreviewerName <- Username\n\nhelpful <- likes and dislikes[x,y]\n\nreviewText <- user-written review\n\noverall <- rating value of the product\n\nsummary <- summary of the review text\n\nunixReviewTime <- user's rating time by unix time\n\nreviewTime <- user's rating time (raw)\n\nday_diff <- Number of days since review\n\nhelpful_yes <- number of likes the review received\n\ntotal_vote <- total vote"}}