{"cell_type":{"1319f173":"code","5f058c3f":"code","081380e2":"code","4b12c27a":"code","54b9739f":"code","76157227":"code","d468d870":"code","a09eebcd":"code","b5a69f8a":"code","2e5f9aa5":"code","152517d6":"code","f0b53507":"code","822cd483":"code","dbe890a3":"code","02a873e4":"code","452bda1c":"code","cfa7e3f9":"code","7605d260":"code","8c1bb883":"code","ce4313e5":"code","4dccf292":"code","5f7ce109":"code","73ff7d61":"code","a1eaaae6":"code","d5a82c52":"code","486caaec":"code","2b16b814":"code","f2a87754":"code","25fe3cbc":"code","28359595":"code","041e0f97":"code","683dce6f":"code","694b0d73":"code","237f8a84":"code","066e52bb":"code","00df4d81":"code","b581399d":"code","3f14bea9":"code","4296e37f":"code","edecbae4":"code","fcb05491":"code","1374e86a":"code","178df264":"code","c839e619":"code","b6fb25b6":"code","d9265193":"markdown","e1f8cd9e":"markdown","a0cd31eb":"markdown","0efdded4":"markdown","8c96c447":"markdown","602db2b6":"markdown","59927989":"markdown","8e59e685":"markdown","91264a48":"markdown","a8737802":"markdown","79a9b1d0":"markdown","d58e3f07":"markdown","0f118136":"markdown","97a460a2":"markdown"},"source":{"1319f173":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom sklearn.neighbors import  KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n","5f058c3f":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","081380e2":"le = LabelEncoder()","4b12c27a":"train.info()","54b9739f":"print(\"numeric columns or continuous variables\")\nprint(train.select_dtypes(include='number').columns)\nprint(\"--------------------------------------------\")\nprint(\"Category variables\")\nprint(train.select_dtypes(include='object').columns)","76157227":"sns.countplot('Survived',data=train)\n","d468d870":"not_survived =  (train['Survived'].value_counts()[0] \/ len(train['Survived']) ) * 100 \nsurvived = 100 - not_survived\nprint(\"Survived : {:.2f}% , Not Survived : {:.2f}%\".format(survived,not_survived))","a09eebcd":"f,ax = plt.subplots(1,3,figsize=(16,4))\nsns.countplot(x='Sex',data=train , ax=ax[0])\nsns.countplot(x='Survived',hue='Sex',data=train , ax=ax[1])\nsns.countplot(x='Survived',hue='Sex',data=train[(train['Sex'] == 'female')] , ax=ax[2] , palette=\"Set2\")\n","b5a69f8a":"f,ax = plt.subplots(1,3,figsize=(16,4))\nsns.countplot(x='Pclass',data=train , ax=ax[0])\nsns.countplot(x='Survived',hue='Pclass',data=train , ax=ax[1])\nsns.countplot(x='Survived',hue='Pclass',data=train[(train['Pclass'] == 3)] , ax=ax[2])\n","2e5f9aa5":"f,ax = plt.subplots(1,3,figsize=(16,4))\nsns.pointplot(x='Survived',y='Fare',data=train,ax=ax[0])\nsns.boxplot(x='Fare',data=train,ax=ax[1])\nsns.pointplot(x='Pclass',y='Fare',data=train,ax=ax[2])\nprint(train['Fare'].describe())","152517d6":"sns.distplot(train[train['Survived'] == 1]['Fare'])\nsns.distplot(train[train['Survived'] == 0]['Fare'])\n# plt.hist(train[train['Survived'] == 1]['Fare'], normed=True, alpha=0.5)\n# plt.hist(train[train['Survived'] == 0]['Fare'], normed=True, alpha=0.5)\n# sum(train[train['Fare']>263]['Survived'] == 1)","f0b53507":"# # g = sns.FacetGrid(data = train, hue = \"Survived\", legend_out=True,size=5)\n# # g = g.map(sns.kdeplot, \"Age\")\n# # g.add_legend();\nsns.kdeplot(train['Age'],hue='Survived', shade=True)\n","822cd483":"f,ax = plt.subplots(1,3,figsize=(16,4))\nsns.countplot(x='Embarked',data=train , ax=ax[0])\nsns.countplot(x='Survived',hue='Embarked',data=train , ax=ax[1])\nsns.countplot(hue='Pclass',x='Embarked',data=train,ax=ax[2])","dbe890a3":"f,ax = plt.subplots(1,2,figsize=(16,6))\nsns.pointplot(x=\"SibSp\", y=\"Survived\",hue='Sex',data=train,ax=ax[0])\nsns.pointplot(x=\"Parch\", y=\"Survived\",hue='Sex',data=train,ax=ax[1])","02a873e4":"all_dataset = pd.concat([train,test],sort=False)","452bda1c":"missing_value = all_dataset.isnull().sum().sort_values(ascending=False) \/ len(all_dataset) * 100\nmissing_value = missing_value[missing_value != 0]\nmissing_value = pd.DataFrame({'Missing value' :missing_value,'Type':missing_value.index.map(lambda x:all_dataset[x].dtype)})\nmissing_value.plot(kind='bar',figsize=(16,4))\nplt.show()","cfa7e3f9":"# Missing value people boarding on Pclass 1 lets take mode from pclass 1 people and fill it\n# No missing value in test set\nembarked_mode = train[train['Pclass']==1]['Embarked'].mode()[0]\ntrain['Embarked'].fillna(embarked_mode,inplace=True)","7605d260":"train['Age'].describe()","8c1bb883":"train['Title'] = train['Name'].str.split(\", \").str[1].str.split(\".\").str[0]\ntest['Title'] = test['Name'].str.split(\", \").str[1].str.split(\".\").str[0]\n","ce4313e5":"def replaceTitle(fromValue,to):\n    x = dict.fromkeys(fromValue, to) \n    return x\n\n\n\ntrain['Title'] = train['Title'].replace(replaceTitle(['Mlle','Mme','Ms'], 'Miss'))\ntrain['Title'] = train['Title'].replace(replaceTitle(['Dr','Major','Capt','Sir','Don'], 'Mr'))\ntrain['Title'] = train['Title'].replace(replaceTitle(['Lady','the Countess'], 'Mrs'))\ntrain['Title'] = train['Title'].replace(replaceTitle(['Jonkheer','Col','Rev'], 'Unknown'))\n\ntest['Title'] = test['Title'].replace(replaceTitle(['Mlle','Mme','Ms'], 'Miss'))\ntest['Title'] = test['Title'].replace(replaceTitle(['Dr','Major','Capt','Sir','Don'], 'Mr'))\ntest['Title'] = test['Title'].replace(replaceTitle(['Lady','the Countess'], 'Mrs'))\ntest['Title'] = test['Title'].replace(replaceTitle(['Jonkheer','Col','Rev'], 'Unknown'))","4dccf292":"train['Age']= train.groupby('Title')['Age'].transform(lambda x:x.fillna(int(round(x.mean()))))\ntest['Age']= train.groupby('Title')['Age'].transform(lambda x:x.fillna(int(round(x.mean()))))","5f7ce109":"train['Age'] = pd.cut(train['Age'],5)\ntest['Age'] = pd.cut(test['Age'],5)\ntrain['Age'] = le.fit_transform(train['Age'])\ntest['Age'] = le.fit_transform(test['Age'])","73ff7d61":"g = sns.FacetGrid(data = train, hue = \"Title\", legend_out=True,size=5)\ng = g.map(sns.kdeplot, \"Age\")\ng.add_legend();","a1eaaae6":"fill_fair = test[(test['Embarked']=='S') & (test['Pclass'] == 3) & (test['Title']=='Mr') ]['Fare'].mean()\ntest['Fare'].fillna(fill_fair,inplace=True)","d5a82c52":"train['Fare_cat'] = pd.qcut(train['Fare'],5)\ntest['Fare_cat'] = pd.qcut(test['Fare'],5)\ntrain['Fare_cat'] = le.fit_transform(train['Fare_cat'])\ntest['Fare_cat'] = le.fit_transform(test['Fare_cat'])","486caaec":"train.loc[~train['Cabin'].isnull(),'Cabin'] = train[~train['Cabin'].isnull()]['Cabin'].str[0]","2b16b814":"train['Cabin'] = train.groupby(['Fare_cat'])['Cabin'].transform(lambda x:x.fillna(x.mode()[0]))\ntest['Cabin'] = test.groupby(['Fare_cat'])['Cabin'].transform(lambda x:x.fillna(x.mode()[0]))\n# train['Cabin'].value_counts()\n\ntrain['Cabin'].isnull().sum()","f2a87754":"corr = train.corr().sort_values(by='Survived',ascending=False)\nplt.subplots(figsize=(16,8))\nsns.heatmap(corr,annot=True)","25fe3cbc":"all_dataset = pd.concat([train,test],sort=False)\ny = all_dataset['Survived']\nall_dataset.drop('Survived',axis=1,inplace=True)","28359595":"#### Feature Engineering","041e0f97":"all_dataset['TotalFamilySize'] = all_dataset['SibSp'] + all_dataset['Parch']\nall_dataset['IsAlone'] = 1 * (all_dataset['TotalFamilySize'] == 0)\nall_dataset['child_ladies_first'] = 1 * ((all_dataset['Sex'] == 'female') | (all_dataset['Title'] == 'Master'))","683dce6f":"all_dataset.drop(['SibSp','Parch','PassengerId','Name','Ticket'],axis=1,inplace=True)","694b0d73":"all_dataset = pd.get_dummies(all_dataset,drop_first=True)","237f8a84":"#### Model Predictions","066e52bb":"from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","00df4d81":"kfold = StratifiedKFold(n_splits=10)","b581399d":"train_len = train.shape[0]\nX_train = all_dataset[:train_len]\nX_test = all_dataset[train_len:]\n\ndef cv_score(classifier):\n    return cross_val_score(classifier,X_train,y=train['Survived'],scoring='accuracy',cv=kfold)","3f14bea9":"voting_classifier = VotingClassifier(estimators=[\n        ('lr', LogisticRegression()), ('rf', RandomForestClassifier()), ('svc', SVC(probability=True))], voting='soft')\nclassifer_result = []\nclassifer_result.append(LogisticRegression(random_state=42))\nclassifer_result.append(RandomForestClassifier(random_state=42))\nclassifer_result.append(KNeighborsClassifier())\nclassifer_result.append(GaussianNB())\nclassifer_result.append(SVC(random_state=42))\nclassifer_result.append(LinearSVC(random_state=42))\nclassifer_result.append(voting_classifier)\n","4296e37f":"cv_results = []\nfor classifier in classifer_result:\n    cv_results.append(cv_score(classifier).mean())","edecbae4":"cv_results","fcb05491":"voting_classifier.fit(X_train,train['Survived'])\npredictions = voting_classifier.predict(X_test)","1374e86a":"predictions","178df264":"submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","c839e619":"submission['Survived'] = predictions\n","b6fb25b6":"submission.to_csv(\"submission.csv\",index=False)","d9265193":"Observations :\n*     Pclass - TicketClass(1 = 1st, 2 = 2nd, 3 = 3rd) \n*     We can see that 3rd class people count are higher in the ship but survival rate is pretty low (80% of them not survived).\n*     More than 75% of the 1st class people were survived. \n    \n    \n    ","e1f8cd9e":"#### Analysing the Target Feature","a0cd31eb":"Observations : \n* Parch - survival rate is increased when 1-3 parents but drops heavely when parch count > 3\n* Sibsp - survival rate drops when the sibsp count increase, we expect negative correlation.\n* suvival rate is zero when the count of sibsp >= 5 and parch > 5\n\n    ","0efdded4":"#### Regression or Classification problem ?\n\nOur goal is to predict **Survived** variable which has value of either 1(survived) or 0(not survived). \nSo to predict discrete class, We use classification model.","8c96c447":"Let's analyse what are the features that makes this much difference","602db2b6":"plot shows that most of the people were not survied.","59927989":"Observations : \n*     Like Pclass, Fair features also shows that people who pays more were survived\n*     we can see that huge variance in the fare, so we will convert it into discrete value.\n*     On the 3rd plot, Fair decreases when the standard reduces.","8e59e685":"#### visualize missing data","91264a48":"Observations : \n*     Mean value is 29 , we can't assign this value to either children or older people. \n*     We have to figure out a way to fill accordingly\n*     Might be title help lets analyse that","a8737802":"#### Fill missing values","79a9b1d0":"Observations : \n*     Embarked - C = Cherbourg, Q = Queenstown, S = Southampton\n*     S were high in count and mostly boarding on Pclass - 3 but their survival rate is very low\n    ","d58e3f07":"#### Correleation","0f118136":"#### The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).","97a460a2":"Observations : \n*     Eventhough male were the higher in count but their survival rate was pretty low.\n*     More than 75% of the females were survived. \n    "}}