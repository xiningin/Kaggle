{"cell_type":{"791a6790":"code","87d2e3f8":"code","36433540":"code","279c3049":"code","baf0b8ba":"code","7eb95669":"code","2bbc5dcc":"code","95ebc41b":"code","d94227b8":"code","30bae9f5":"code","e42a9bc0":"code","57f6c376":"code","8d71794f":"code","fa69b41b":"code","24e89a13":"code","30b3c522":"code","7d62086b":"code","f850138b":"code","78a2b7f3":"code","dfad5c0f":"code","1a882caa":"code","a3520ff1":"code","d698b876":"markdown","72044e5d":"markdown","3c74bcb0":"markdown","edeb767e":"markdown","bbd20581":"markdown","4907629b":"markdown","3785e4c6":"markdown","803b0d1a":"markdown","ad2bcd4d":"markdown","80119582":"markdown","81d7d8d2":"markdown","ad17118c":"markdown","de64c346":"markdown","f1876221":"markdown","22279b3f":"markdown","448377ec":"markdown"},"source":{"791a6790":"import numpy as np \nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch import optim\nimport matplotlib.pyplot as plt\ntorch.manual_seed(200)","87d2e3f8":"def extract_data(torch_subset):\n    df = torch_subset.dataset.iloc[torch_subset.indices]\n    x = torch.from_numpy(df.values[ : , 1:]).reshape(-1, 28, 28).to(torch.float)\n    y = torch.from_numpy(df.values[:, 0]).to(torch.long)\n    \n    return x, y\n    \n    \ndef split(dataframe):\n    val_size = len(dataframe)\/\/6\n    train_size = len(dataframe) - val_size\n    \n    train, valid = torch.utils.data.random_split(dataframe, [train_size, val_size])\n\n    return extract_data(train), extract_data(valid)\n\ndef show_img(X, y):\n    fig = plt.figure(figsize=(20, 5))\n    for i in range(10):\n        ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        ax.imshow(X[i].view(28, 28))\n        ax.set_title(str(y[i].item()))","36433540":"class MNISTDS(torch.utils.data.Dataset):\n    def __init__(self, images, targets, transforms=None):\n        self.images = images.unsqueeze(1) \/ 255\n        self.targets = targets\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, i):\n        if self.transforms:\n            x = self.transforms(self.images[i])\n        else:\n            x = self.images[i]\n        return x, self.targets[i]","279c3049":"train_df = pd.read_csv('..\/input\/ahdd1\/csvTrainImages 60k x 784\/csvTrainImages 60k x 784.csv')\ntest_df = pd.read_csv('..\/input\/ahdd1\/csvTestImages 10k x 784.csv')\n\ntrain_label = pd.read_csv('..\/input\/ahdd1\/csvTrainLabel 60k x 1.csv')\ntest_label = pd.read_csv('..\/input\/ahdd1\/csvTestLabel 10k x 1.csv') ","baf0b8ba":"train_df.shape, train_label.shape, test_df.shape, test_label.shape","7eb95669":"train = pd.concat([train_label, train_df], axis=1)\n\ntrain.head(3)","2bbc5dcc":"(X_train, y_train), (X_val, y_val) = split(train)\nX_test = torch.Tensor(test_df.values).reshape(-1, 28, 28)","95ebc41b":"show_img(X_train, y_train)","d94227b8":"import torchvision.transforms as transforms\n\ntransform = torch.nn.Sequential(\n    transforms.RandomAffine(degrees=90, scale=(1.1, 1.1), fillcolor=None),\n)\nscripted_transforms = torch.jit.script(transform)","30bae9f5":"show_img(scripted_transforms(X_train), y_train)","e42a9bc0":"trainset = MNISTDS(X_train, y_train, scripted_transforms)\nvalidset = MNISTDS(X_val, y_val)","57f6c376":"batch_size = 100\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(validset, batch_size=batch_size, shuffle=True)","8d71794f":"class Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.batch_1 = nn.BatchNorm2d(32)\n        \n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n        self.batch_2 = nn.BatchNorm2d(32)\n        \n        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2, padding=2)\n        self.batch_3 = nn.BatchNorm2d(32)\n        \n        self.conv4 = nn.Conv2d(32, 64, kernel_size=3)\n        self.batch_4 = nn.BatchNorm2d(64)\n        \n        self.conv5 = nn.Conv2d(64, 64, kernel_size=3)\n        self.batch_5 = nn.BatchNorm2d(64)\n        \n        self.conv6 = nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=2)\n        self.batch_6 = nn.BatchNorm2d(64)\n        \n        \n        self.fc1 = nn.Linear(1024, 128) \n        self.fc2 = nn.Linear(128, 10)\n        \n        self.dropout_4 = nn.Dropout(p=0.4)\n        \n    def forward(self, x):\n        x = x.view(x.shape[0], 1, 28, 28)\n      \n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.batch_1(x)\n\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.batch_2(x)\n        \n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.batch_3(x)\n        \n        x = self.dropout_4(x)\n        \n        x = self.conv4(x)\n        x = F.relu(x)\n        x = self.batch_4(x)\n\n        x = self.conv5(x)\n        x = F.relu(x)\n        x = self.batch_5(x)\n        \n        x = self.conv6(x)\n        x = F.relu(x)\n        x = self.batch_6(x)\n\n        x = self.dropout_4(x)\n      \n        x = x.view(-1, 1024)\n        \n        x = self.fc1(x)\n        x = F.relu(x)\n\n        x = self.dropout_4(x)\n        x = self.fc2(x)\n        \n        return x\n    \nmodel = Classifier()","fa69b41b":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel.to(device)\nprint(device)","24e89a13":"loss_function = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.35)","30b3c522":"epoch = 20\ntrain_losses, valid_losses = [], []\nvalid_loss_min = np.Inf\n\nfor i in range(epoch):\n    tot_train_loss = 0\n    \n    model.train()\n    \n    for images, labels in train_loader:\n \n        pred = model(images.to(device))\n        loss = loss_function(pred, labels.to(device))\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        tot_train_loss += loss.item()\n        \n    else:\n        tot_valid_loss = 0\n        valid_correct = 0\n        \n        model.eval()\n        with torch.no_grad():\n        \n            for images, labels in valid_loader:      \n                pred = model(images.to(device))\n                loss = loss_function(pred, labels.to(device))\n                tot_valid_loss += loss.item()\n        \n        train_loss = tot_valid_loss \/ len(train_loader.dataset)\n        valid_loss = tot_valid_loss \/ len(valid_loader.dataset)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        \n        print(\"Epoch: {}\/{}.. \".format(i+1, epoch),\n              \"Training Loss: {:.3f}.. \".format(train_loss),\n              \"Test Loss: {:.3f}.. \".format(valid_loss),\n              )\n        \n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), 'model.pt')\n            valid_loss_min = valid_loss","7d62086b":"plt.plot(train_losses, label='Train Loss')\nplt.plot(valid_losses, label='Valid Loss')","f850138b":"model = Classifier()\nmodel.load_state_dict(torch.load('model.pt'))\n\nmodel.to(device)","78a2b7f3":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, images):\n        self.images = images.unsqueeze(1).to(device) \/ 255\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, i):\n        return self.images[i]\n    \n    \ntestset = TestDataset(X_test)\ntest_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)","dfad5c0f":"preds_class = np.array([], dtype=int)\n\nwith torch.no_grad():\n    for images in test_loader:\n        preds = model(images.to(device)).cpu()\n        preds_class = np.append(preds_class, preds.argmax(dim=1))","1a882caa":"show_img(X_test, preds_class)","a3520ff1":"from sklearn.metrics import accuracy_score\n\nprint(f'Accuracy score {accuracy_score(test_label, preds_class)*100:.2f}')","d698b876":"## Predict test data","72044e5d":"### View augmented data","3c74bcb0":"## Create dataset and dataloader","edeb767e":"# CNN","bbd20581":"## Use GPU if available","4907629b":"## Load best model","3785e4c6":"## Imports","803b0d1a":"# Deep learning Approach","ad2bcd4d":"## Load data and transform to torch tesnors","80119582":"### Train valid loss","81d7d8d2":"# Check accuracy","ad17118c":"## Data Augmentation","de64c346":"# Custom Dataset","f1876221":"### Explore","22279b3f":"### Train and validate","448377ec":"## Utilities"}}