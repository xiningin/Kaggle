{"cell_type":{"4a9abe59":"code","92b31c3e":"code","16d0c497":"code","fc06c8ed":"code","ae235eb3":"code","8b670353":"code","e367de8e":"code","9c57c4f4":"code","86d37d8b":"code","55fb83b8":"code","58e7f027":"code","8935536e":"code","2effe1c7":"code","6fba2207":"code","2d17d0dc":"code","7044b043":"code","90f10b54":"code","265c356f":"code","49aeebe5":"code","9ffa992c":"code","5f106145":"code","ae192be9":"code","27b8b7b1":"code","2b1a9cd5":"code","484815d7":"code","0c4db84a":"code","1b347a50":"code","7a47ecca":"code","19919073":"code","b5b84cf3":"code","9110c366":"code","61a74cec":"code","c827c019":"code","448d781c":"code","bfe030e1":"code","12479a39":"code","23e809b5":"code","333c5294":"code","ebca1639":"code","8f66392e":"code","d5deb236":"code","3e606acd":"code","e96698a0":"code","f73c1a74":"code","37564d59":"code","d450c881":"code","8328cd34":"code","cbb1fc7e":"code","ac1c8877":"code","5780ddf2":"code","3cc2a4a9":"code","5ecc7be2":"code","4d26bdce":"code","8d5e6cf3":"code","ccfdea7f":"code","73aa92b2":"code","89fe0c7f":"code","7609f5b6":"code","fa66e8bd":"code","2d6d6cda":"code","14c6c059":"code","c1a4f467":"code","08d0e5d7":"code","7a00f7ba":"code","497bb4a9":"code","9e640f42":"code","abf51867":"code","d21615be":"code","3f1ba04f":"code","53bf6469":"code","bda9709d":"code","e99a511f":"markdown","e9616cf1":"markdown","f951e960":"markdown","1128bf1b":"markdown","5f0ec714":"markdown","0df71b9b":"markdown","d3e7bf41":"markdown","0a6fa065":"markdown","650d84bd":"markdown","62347350":"markdown","e1af366a":"markdown","b6dac46f":"markdown","6230729f":"markdown","7800d520":"markdown","ad6da104":"markdown","da63682d":"markdown","de784a3d":"markdown","1c4247fe":"markdown","4200491f":"markdown","7f8b7c8e":"markdown","9018d56e":"markdown","cbda915e":"markdown","2a2b9d07":"markdown"},"source":{"4a9abe59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92b31c3e":"def showver(col):\n    try:\n        print(\"{} version: {}\". format(col.__name__, col.__version__))\n    except AttributeError:\n        try:\n            print(\"{} version: {}\". format(col.__name__, col.version))\n        except AttributeError:\n            pass\n        \nimport sys #access to system parameters https:\/\/docs.python.org\/3\/library\/sys.html\nshowver(sys)    \n\nimport numpy as np # linear algebra\nshowver(np)\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nshowver(pd)\n\nimport missingno as miss\nshowver(miss)\n\nimport matplotlib.pyplot as plt\nshowver(plt)\n\nimport squarify\nshowver(squarify)\n\nimport random\nshowver(random)\n\nimport datetime\nshowver(datetime)\n\nimport re\nshowver(re)\n\nfrom collections import Counter\nshowver(Counter)\n\nfrom nltk.corpus import stopwords #removes and, in, the, a ... etc\nshowver(stopwords)\n\nimport plotly.express as px\nshowver(px)\n\nfrom bs4 import BeautifulSoup\nshowver(BeautifulSoup)\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint('-' * 43)\n","16d0c497":"FILEPATH = '\/kaggle\/input\/60k-stack-overflow-questions-with-quality-rate\/data.csv'","fc06c8ed":"df = pd.read_csv(FILEPATH)\ndf.sample(10)","ae235eb3":"df.describe(include = \"all\")","8b670353":"df.info()","e367de8e":"df.isnull().sum()","9c57c4f4":"miss.bar(df)\nplt.show()","86d37d8b":"df.duplicated(subset=None, keep='first')","55fb83b8":"len(df[df.duplicated()])","58e7f027":"def get_tech_keys(tag):\n    \n    if(not tag):\n        return tag\n    \n    tag = tag.replace('><', ',')\n    \n    tag = tag.replace('<', '')\n    \n    tag = tag.replace('>', '')\n    \n    return tag","8935536e":"df['TechKeys'] = df['Tags'].apply(get_tech_keys)","2effe1c7":"df.head()","6fba2207":"tech_keys = df['TechKeys'].tolist()","2d17d0dc":"tech_keys","7044b043":"tech_key_list   = []\ntech_key_values = None\nindex_counter = 0\ntech_key_index_list = []\n\nfor item in tech_keys:\n    item_parts = item.split(',')\n    \n    for item_ in item_parts:\n        \n        tech_key_index_list.append(index_counter)\n        tech_key_list.append(item_)\n        index_counter += 1\n    \ndf_tech_key_new = pd.DataFrame({'id' : tech_key_index_list, 'tech_key' : tech_key_list}) ","90f10b54":"df_tech_key_new.head()","265c356f":"len(df_tech_key_new)","49aeebe5":"df_tech_key_new.tech_key.value_counts().nlargest(10)","9ffa992c":"def get_tags_counts(col):\n    \n    if(not col):\n        return 0\n    \n    tags_count = len(col.split(','))\n    \n    return tags_count","5f106145":"df['TagsCount'] = df['TechKeys'].apply(get_tags_counts)","ae192be9":"df.head()","27b8b7b1":"df_sub = df[['Id', 'Title', 'Tags', 'TagsCount']][0:25]","2b1a9cd5":"df_sub.head()","484815d7":"def highlight_max_custom(s, color = 'lightgreen'):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: '+color if v else '' for v in is_max]","0c4db84a":"df_sub.style.apply(highlight_max_custom, color = '#CFFE96',  axis = 0, subset=['TagsCount'])","1b347a50":"df.Y.unique()","7a47ecca":"def get_question_level(level):\n    \n    if(not level):\n        return level\n    \n    if(level == 'LQ_CLOSE'):\n        return 3\n    \n    if(level == 'LQ_EDIT'):\n        return 2\n    \n    if(level == 'HQ'):\n        return 1\n    \n    return level","19919073":"df['Level'] = df['Y'].apply(get_question_level)","b5b84cf3":"df.head()","9110c366":"# import matplotlib.pyplot as plt\n\ndef show_donut_plot(col):\n    \n    rating_data = df.groupby(col)[['Id']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['Id']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot: SOF Questions by ' +str(col), loc='center')\n    \n    plt.show()","61a74cec":"show_donut_plot('Level')","c827c019":"show_donut_plot('TagsCount')","448d781c":"# import squarify\n\ndef show_treemap(col, max_labels = 10):\n    df_type_series = df.groupby(col)['Id'].count().sort_values(ascending = False).head(20)\n\n    type_sizes = []\n    type_labels = []\n    for i, v in df_type_series.items():\n        type_sizes.append(v)\n        \n        type_labels.append(str(i) + ' ('+str(v)+')')\n\n\n    fig, ax = plt.subplots(1, figsize = (12,12))\n    squarify.plot(sizes=type_sizes, \n                  label=type_labels[:max_labels],  # show labels for only first 10 items\n                  alpha=.2 )\n    \n    plt.title('TreeMap: SOF Questions by '+ str(col))\n    plt.axis('off')\n    plt.show()","bfe030e1":"show_treemap('Level')","12479a39":"# print random body (random column data)\n# import random\n\n# df.at[df.index[random.randint(0, len(df))], 'Body']","23e809b5":"def code_available(content):\n    \n    if('<code>' in content):\n        return True\n    \n    return False","333c5294":"df['code_available'] = df['Body'].apply(code_available)","ebca1639":"df.head()","8f66392e":"show_donut_plot('code_available')","d5deb236":"# import datetime\n\ndef get_week(col):\n    \n    return col.strftime(\"%V\")","3e606acd":"# Create new columns for Month, Year Created\ndf['CreationDatetime'] = pd.to_datetime(df['CreationDate']) \ndf['CreationMonth'] = df['CreationDatetime'].dt.month.astype(int)\ndf['CreationYear'] = df['CreationDatetime'].dt.year.astype(int)\ndf['CreationWeek'] = df['CreationDatetime'].apply(get_week).astype(int)","e96698a0":"# df.info()","f73c1a74":"show_donut_plot('CreationMonth')","37564d59":"show_treemap('CreationMonth')","d450c881":"show_donut_plot('CreationYear')","8328cd34":"show_donut_plot('CreationWeek')","cbb1fc7e":"show_treemap('CreationYear')","ac1c8877":"show_treemap('CreationWeek', 18)","5780ddf2":"df_tech_key_new","3cc2a4a9":"def show_donut_plot_techkey(col):\n    \n    rating_data = df_tech_key_new.groupby(col)[['id']].count().head(50)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['id']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot by ' +str(col), loc='center')\n    \n    plt.show()","5ecc7be2":"show_donut_plot_techkey('tech_key')","4d26bdce":"def show_treemap_tech_key(col):\n    df_type_series = df_tech_key_new.groupby(col)['id'].count().sort_values(ascending = False).head(50)\n\n    type_sizes = []\n    type_labels = []\n    for i, v in df_type_series.items():\n        type_sizes.append(v)\n        \n        type_labels.append(str(i) + ' ('+str(v)+')')\n\n\n    fig, ax = plt.subplots(1, figsize = (12,12))\n    squarify.plot(sizes=type_sizes, \n                  label=type_labels[:25],  # show labels for only first 10 items\n                  alpha=.2 )\n    plt.title('TreeMap by '+ str(col))\n    plt.axis('off')\n    plt.show()","8d5e6cf3":"show_treemap_tech_key('tech_key')","ccfdea7f":"def show_donut_plot_2cols(col1, col1_val, col2):\n    \n    df1 = df[df[col1] == col1_val]\n    \n    rating_data = df1.groupby(col2)[['Id']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['Id']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot by ' +str(col1) + ' and ' +str(col2), loc='center')\n    \n    plt.show()","73aa92b2":"show_donut_plot_2cols('CreationYear', 2016, 'Level')","89fe0c7f":"show_donut_plot_2cols('CreationYear', 2016, 'code_available')","7609f5b6":"df.head()","fa66e8bd":"df.Y.unique()","2d6d6cda":"import re\n\ncode_start = '<code>'\ncode_end   = '<\/code>'\n\ndef get_codes(content):\n    \n    if('<code>' not in content):\n        return None\n    \n    code_list = []\n    \n    loop_counter = 0\n    while(code_start in content):\n\n        code_start_index = content.index(code_start)\n        if(code_end not in content):\n            code_end_index = len(content)\n        else:\n            code_end_index = content.index(code_end)\n\n        substring_1 = content[code_start_index : (code_end_index + len(code_end) )]\n \n        code_list.append(substring_1)\n        \n        content = content.replace(substring_1, '')\n        \n        loop_counter += 1\n\n    \n    return ' '.join(code_list)\n\ndef  clean_text(content):\n    \n    content = content.lower()\n    \n    content = re.sub('<.*?>+', '', content)\n    \n    content = re.sub(r\"(@[A-Za-z0-9]+)|^rt|http.+?\", \"\", content)\n    content = re.sub(r\"(\\w+:\\\/\\\/\\S+)\", \"\", content)\n    content = re.sub(r\"([^0-9A-Za-z \\t])\", \" \", content)\n    content = re.sub(r\"^rt|http.+?\", \"\", content)\n    content = re.sub(\" +\", \" \", content)\n\n    # remove numbers\n    content = re.sub(r\"\\d+\", \"\", content)\n    \n    return content\n\ndef get_non_codes(content):\n    \n    loop_counter = 0\n    while(code_start in content):\n\n        code_start_index = content.index(code_start)\n        if(code_end not in content):\n            code_end_index = len(content)\n        else:\n            code_end_index = content.index(code_end)\n\n        substring_1 = content[code_start_index : (code_end_index + len(code_end) )]\n\n        content = content.replace(substring_1, ' ')\n        \n        loop_counter += 1\n        \n    content = clean_text(content)\n\n    return content","14c6c059":"df['Body_code'] = df['Body'].apply(get_codes)\ndf['Body_content'] = df['Body'].apply(get_non_codes)","c1a4f467":"# from collections import Counter\n# from nltk.corpus import stopwords\n\nstopwords1 = stopwords.words('english')\n\n\n\ndf['content_words'] = df['Body_content'].apply(lambda x:str(x).split())","08d0e5d7":"def remove_short_words(content):\n\n    new_content_list = []\n    for item in content:\n        \n        if(len(item) > 2):\n            new_content_list.append(item)\n    \n    return new_content_list\n    ","7a00f7ba":"df['content_words'] = df['content_words'].apply(remove_short_words)","497bb4a9":"df.head()","9e640f42":"words_collection = Counter([item for sublist in df['content_words'] for item in sublist if not item in stopwords1])\nfreq_word_df = pd.DataFrame(words_collection.most_common(30))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0, subset=None)","abf51867":"# import plotly.express as px\n\nfig = px.scatter(freq_word_df, x=\"frequently_used_word\", y=\"count\", color=\"count\", title = 'Frequently used words - Scatter plot')\nfig.show()","d21615be":"fig = px.pie(freq_word_df, values='count', names='frequently_used_word', title='Stackoverflow Questions - Frequently Used Word')\nfig.show()","3f1ba04f":"fig = px.sunburst(df, path=['CreationYear', 'CreationMonth'], values='Level',\n                  color='Level', hover_data=['Level'])\nfig.show()","53bf6469":"fig = px.sunburst(df, path=['CreationYear', 'CreationMonth'], values='code_available',\n                  color='code_available', hover_data=['code_available'])\nfig.show()","bda9709d":"fig = px.strip(df, x=\"CreationMonth\", y=\"code_available\", orientation=\"h\", color=\"CreationYear\")\nfig.show()","e99a511f":"**Observation:**\n\n* We can clearly see that Javascript and Python are dominating the questions followed by Java.\n* We know that Java is lagging behind, not able to compete with Python since 2013.\n* I am surprised to see Android comes 4th place. \n* Where is Node.js? Hello?","e9616cf1":"**Final Notes:**\n\nI am adding things still. You can come back and check for more information.\n\nAlso, if you **like my notebook**, <font style=\"color:blue;size:14px;\">please upvote it<\/font> as it will motivate me to come up with better approach in the upcoming notebooks.\n","f951e960":"## 1. Let's find if there is any duplicates. ","1128bf1b":"## Data Basics","5f0ec714":"### Year, Date and Week Columns\n\nLet's create more columns from the `CreationDatetime`. We will have `CreationMonth`, `CreationYear`, and `CreationWeek`","0df71b9b":"**Observation:**\n\n* We can see that there is no duplicates involved in this dataset which is a good sign!","d3e7bf41":"Warning:\n\nThere is something in this donut plot which I can't figure it out at the momemnt. However, I will come back and fix them soon.","0a6fa065":"## Word Cleanup\n\nAs the body contains both code and content, we will have to remove code from the content. We will start doing it in the code below.\n\nAlso, we will do a little cleaning on the content by removing stop words and less than 3 characters. ","650d84bd":"### Visual on Null","62347350":"<font color=\"blue\" size=+1.5><b>Check out my other kernels<\/b><\/font>\n\n<div style=\"margin-bottom: 20px;\">\n    &nbsp;\n<div style=\"float:left; margin-right:10px;\">\n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/amazon-review-prediction-using-spacy\" class=\"btn btn-info\" style=\"color:white;\">Amazon review prediction using spaCy<\/a>\n<\/div>\n \n<div style=\"float:left; margin-right:10px;\"> \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/titanic-prediction\" class=\"btn btn-info\" style=\"color:white;\">Titanic Prediction<\/a>\n<\/div>\n\n<div style=\"float:left; margin-right:10px;\">   \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/loan-status-prediction\" class=\"btn btn-info\" style=\"color:white;\">Loan Status Prediction<\/a>\n<\/div>\n<\/div>\n    \n<div style=\"float:left; margin-right:10px;\">    \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/kollywood-prediction\" class=\"btn btn-info\" style=\"color:white;\">Kollywood Data Prediction<\/a><br><br>\n<\/div>    \n\n<div style=\"float:left; margin-right:10px;\">    \n<a href=\"https:\/\/www.kaggle.com\/kamalkhumar\/sms-spam-or-not-base\" class=\"btn btn-info\" style=\"color:white;\">SMS Spam or Not Prediction<\/a><br><br>\n<\/div>    ","e1af366a":"**Observation:**\n\n* `code` and `like` are used most in the questions. Everyone is looking for code huh?","b6dac46f":"### Code Available Sunburst","6230729f":"## About the Dataset:\n\n* Total questions collected is 60,000.\n* Questions are from 2016 to 2020.\n* There are 3 categories involoved: \n    1. HQ: High-quality posts with 30+ score and without a single edit.\n    2. LQ_EDIT: Low-quality posts with a negative score and with multiple community edits. However, they still remain open after the edits.\n    3. LQ_CLOSE: Low-quality posts that were closed by the community without a single edit.","7800d520":"### Tech Keys\n\nAs Tags come as extra html characters, it is hard to understand which tech keys are mostly used. So, we have to clean them up to get the tech keys.\n","ad6da104":"**Observation:**\n\n* Almost half of the contents don't have code in the body.","da63682d":"#### Tags Count\n\nLet's try to add a column by counting tags as this might help us to identify the quality of the question (I am guessing).\n\n","de784a3d":"### Question Level Sunburst Plot","1c4247fe":"### Question Level\n\nLet's come up with a new column called level based on the question quality.\n\n* L1 - High Quality \n* L2 - Low Quality but open\n* L3 - Low Quality Closed\n","4200491f":"### Code Available Strip Plot","7f8b7c8e":"**Observation:**\n\n* As the questions are equally divided, we don't have much to say here.","9018d56e":"Everything is hunky-dory! So, no worries about NA\/null data!","cbda915e":"### Import Libraries","2a2b9d07":"To Do:\n\n* Introduce Quality Level (L1 - High, L2 - Low but open, L3 - Poor)\n* Predict the LQ_Close items based on the question content (like what phrase is used)\n* Treemap with categories\n* Donut plot with category\n* Donut plot with year and category\n* Which month too much Poor question"}}