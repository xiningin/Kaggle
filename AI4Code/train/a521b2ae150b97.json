{"cell_type":{"a1128f65":"code","bb8c1080":"code","b9f6bcb3":"code","3c9493d7":"code","3e1b92a3":"code","27892c83":"code","02f820e4":"code","8d46b6e5":"code","155546b3":"code","3fa4fe9c":"code","df34d4a8":"code","df75f90a":"code","ccffba99":"code","24d5cfef":"code","76e2e464":"code","2aea13b0":"code","a47b787f":"code","e74e151b":"code","e1002d87":"code","f26374c2":"code","e35260e7":"markdown","dc240039":"markdown","291810a7":"markdown","16f1cd73":"markdown","90d2ccbf":"markdown","726df415":"markdown","8a7d152f":"markdown","88c3b826":"markdown","ba0c62c2":"markdown","4dce59bf":"markdown","347423eb":"markdown"},"source":{"a1128f65":"import numpy as np \nimport pandas as pd \nimport os\nimport torch\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt \nimport torch.nn.functional as F \n\ndata_dir = '..\/input\/yoga-pose-image-classification-dataset\/dataset'\n#print(os.listdir(data_dir))\nclass_name=os.listdir(data_dir)","bb8c1080":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision import transforms as T,datasets","b9f6bcb3":"class CNFG:\n    epochs =20                             \n    lr = 0.001                             \n    batch_size = 16                        \n    model_name = 'tf_efficientnet_b4_ns'    \n    img_size = 224\n    \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:{}\".format(device))","3c9493d7":"data_transform = T.Compose([\n                             T.Resize(size=(CNFG.img_size,CNFG.img_size)), # Resizing the image to be 224 by 224\n                             T.RandomRotation(degrees=(-20,+20)), #Randomly Rotate Images by +\/- 20 degrees, Image argumentation for each epoch\n                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n\n])","3e1b92a3":"data = datasets.ImageFolder(data_dir,       \n                    transform=data_transform)\ntotal_count = len(data)","27892c83":"train_count = int(0.6 * total_count) \nvalid_count = int(0.3 * total_count)\ntest_count = total_count - train_count - valid_count\ntrain_data, val_data, test_data = torch.utils.data.random_split(data, (train_count, valid_count, test_count))","02f820e4":"def show_image(image,label,get_denormalize = True):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    if get_denormalize == True:\n        image = image*std + mean\n        image = np.clip(image,0,1)\n        plt.imshow(image)\n        plt.title(label)\n        \n    else: \n        plt.imshow(image)\n        plt.title(label)\n\ndef show_grid(image,title = None):\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    image = image*std + mean\n    image = np.clip(image,0,1)\n    \n    plt.figure(figsize=[15, 15])\n    plt.imshow(image)\n    if title != None:\n        plt.title(title)\n\n\ndef accuracy(y_pred,y_true):\n    y_pred = F.softmax(y_pred,dim = 1)\n    top_p,top_class = y_pred.topk(1,dim = 1)\n    equals = top_class == y_true.view(*top_class.shape)\n    return torch.mean(equals.type(torch.FloatTensor))\n\n\ndef view_classify(image,ps,label):\n    \n    class_name = ['NORMAL', 'PNEUMONIA']\n    classes = np.array(class_name)\n\n    ps = ps.cpu().data.numpy().squeeze()\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    \n    image = image*std + mean\n    img = np.clip(image,0,1)\n    \n    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    return None","8d46b6e5":"img, label = train_data[0]\nshow_image(img, label)","155546b3":"trainloader = DataLoader(train_data,batch_size=CNFG.batch_size,shuffle=True)\nprint(\"No. of batches in trainloader:{}\".format(len(trainloader))) \nprint(\"No. of Total examples:{}\".format(len(trainloader.dataset)))\n\nvalidationloader = DataLoader(val_data,batch_size=CNFG.batch_size,shuffle=True)\nprint(\"No. of batches in validationloader:{}\".format(len(validationloader)))  \nprint(\"No. of Total examples:{}\".format(len(validationloader.dataset)))\n\ntestloader = DataLoader(test_data,batch_size=CNFG.batch_size,shuffle=True)\nprint(\"No. of batches in testloader:{}\".format(len(testloader))) \nprint(\"No. of Total examples:{}\".format(len(testloader.dataset)))","3fa4fe9c":"class_name","df34d4a8":"dataiter = iter(trainloader)\nimages,labels = dataiter.next()\n\nout = make_grid(images,nrow=4)\n\nshow_grid(out,title = [class_name[x] for x in labels])","df75f90a":"!pip install timm","ccffba99":"from torch import nn\nimport torch.nn.functional as F\nimport timm # PyTorch Image Models\n\nmodel = timm.create_model(CNFG.model_name,pretrained=True) #load pretrained model","24d5cfef":"len(class_name)","76e2e464":"#Updating the pretrained model:\nfor param in model.parameters():\n    param.requires_grad=False\n\nmodel.classifier = nn.Sequential(\n    nn.Linear(in_features=1792, out_features=625), #1792 is the orginal in_features\n    nn.ReLU(), #ReLu to be the activation function\n    nn.Dropout(p=0.3),\n    nn.Linear(in_features=625, out_features=256),\n    nn.ReLU(),\n    nn.Linear(in_features=256, out_features=107), \n)\n\n","2aea13b0":"!pip install torchsummary","a47b787f":"from torchsummary import  summary\nmodel.to(device)# move the model to GPU\nsummary(model,input_size=(3,224,224))","e74e151b":"class ModelTrainer():\n    \n    def __init__(self,criterion = None,optimizer = None,schedular = None):\n        \n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.schedular = schedular\n    \n    def train_batch_loop(self,model,trainloader):\n        \n        train_loss = 0.0\n        train_acc = 0.0\n        \n        for images,labels in tqdm(trainloader): \n            \n            # move the data to CPU\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = self.criterion(outputs,labels)\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            train_loss += loss.item()\n            train_acc += accuracy(outputs,labels)\n            \n        return train_loss \/ len(trainloader), train_acc \/ len(trainloader) \n\n    \n    def valid_batch_loop(self,model,validloader):\n        \n        valid_loss = 0.0\n        valid_acc = 0.0\n        \n        for images,labels in tqdm(validloader):\n            \n            # move the data to CPU\n            images = images.to(device) \n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = self.criterion(outputs,labels)\n            \n            valid_loss += loss.item()\n            valid_acc += accuracy(outputs,labels)\n            \n        return valid_loss \/ len(validloader), valid_acc \/ len(validloader)\n            \n        \n    def fit(self,model,trainloader,validloader,epochs):\n        \n        valid_min_loss = np.Inf \n        \n        for i in range(epochs):\n            \n            model.train() \n            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader) \n            \n            model.eval()  \n            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader) \n            \n            if avg_valid_loss <= valid_min_loss :\n                print(\"Valid_loss decreased {} --> {}\".format(valid_min_loss,avg_valid_loss))\n                torch.save(model.state_dict(),'YogaAsanas.pt')\n                valid_min_loss = avg_valid_loss\n\n                \n            print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(i+1, avg_train_loss, avg_train_acc))\n            print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(i+1, avg_valid_loss, avg_valid_acc))","e1002d87":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = CNFG.lr)\n\ntrainer = ModelTrainer(criterion,optimizer)\ntrainer.fit(model,trainloader,validationloader,epochs = CNFG.epochs)","f26374c2":"# model.load_state_dict(torch.load('YogaAsanas.pt'))\n# model.eval()\n\navg_test_loss, avg_test_acc = trainer.valid_batch_loop(model,testloader)\n\n\nprint(\"Test Loss : {}\".format(avg_test_loss))\nprint(\"Test Acc : {}\".format(avg_test_acc))","e35260e7":"# Training accuracy of 61.6%!\nClassifying among 107 classes surely needs some more data and resources!","dc240039":"# Classifying 107 classes of Yoga Asanas using state-of-the-art pre-trained EfficientNet model in PyTorch\n\n**EfficientNetv2:**\n\n![](https:\/\/serge-m.github.io\/media\/2020-07-01-which-backbone-to-choose\/efficientnet.png)\n","291810a7":"# Evaluating the data","16f1cd73":"# Creating the configurations class","90d2ccbf":"# Importing EfficientNet model!","726df415":"# Transforming the data","8a7d152f":"# Training the model!","88c3b826":"# Importing the libraries","ba0c62c2":"# Defining some functions","4dce59bf":"# Splitting the data","347423eb":"# Data Loaders!"}}