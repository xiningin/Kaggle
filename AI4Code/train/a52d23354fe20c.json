{"cell_type":{"0a383bbb":"code","9a9a4d82":"code","efaf3e1a":"code","51bd47f9":"code","ccf750c7":"code","8edf3d27":"code","a90ab056":"code","97989391":"code","176bd7d2":"code","c420c332":"code","009675a3":"code","f9d56fce":"code","e2c9258d":"code","f3471333":"code","d3b8a72e":"code","a7db694d":"code","7025bd92":"code","8f092587":"markdown","e8cfe1c2":"markdown","e5e5cc57":"markdown","034cd5aa":"markdown","f1c61807":"markdown","22a2c8ef":"markdown","8e8f5488":"markdown","844efbe7":"markdown","4b68a541":"markdown","d0192cd5":"markdown","3e3cf08c":"markdown","e79150ca":"markdown","acc2405d":"markdown","e2186879":"markdown"},"source":{"0a383bbb":"import itertools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport warnings\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.utils.np_utils import to_categorical\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nSEED = 7\nSPLIT = 0.1\nEPOCHS = 40\nBATCH_SIZE = 100\nnp.random.seed(SEED)\nwarnings.filterwarnings('ignore')\n%matplotlib inline","9a9a4d82":"# Read the CSV\nmnist_train_path = '..\/input\/digit-recognizer\/train.csv'\nmnist_test_path = '..\/input\/digit-recognizer\/test.csv'\n\ntrain_original = pd.read_csv(mnist_train_path)\ntest_original = pd.read_csv(mnist_test_path)\n\n# Preserve original\nX_train = train_original.drop('label', axis=1).copy()\nX_test = test_original.copy()\ny_train = train_original['label'].copy()\nprint('Train data shape: {}'.format(X_train.shape))\nprint('Test data shape: {}'.format(X_test.shape))","efaf3e1a":"fig, ax = plt.subplots()\nfig.set_size_inches(11, 8)\nfig=sns.countplot(y_train)\nplt.xlabel('Labels')\nplt.ylabel('Count')\nplt.title('Distribution of Labels')\nplt.show(fig)","51bd47f9":"y_train.value_counts()","ccf750c7":"X_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","8edf3d27":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)","a90ab056":"fig, ax = plt.subplots()\nfig.set_size_inches(11, 8)\nfig = plt.imshow(X_train[1][:,:,0])\nplt.title('Sample Image')\nplt.show(fig)","97989391":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n                                                  test_size = SPLIT,\n                                                  random_state=SEED)","176bd7d2":"y_train = to_categorical(y_train, num_classes=10)\ny_val = to_categorical(y_val, num_classes=10)","c420c332":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","009675a3":"# Get optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Compile the model\nmodel.compile(optimizer = optimizer , loss = 'categorical_crossentropy', metrics=['accuracy'])\n\n# Make learning rate annealer\nlrr = ReduceLROnPlateau(monitor='val_acc', \n                        patience=3, \n                        verbose=1, \n                        factor=0.5, \n                        min_lr=0.00001)","f9d56fce":"datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.12, \n        width_shift_range=0.12,\n        height_shift_range=0.12,\n        horizontal_flip=False,\n        vertical_flip=False)\n\ndatagen.fit(X_train)","e2c9258d":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=BATCH_SIZE),\n                              epochs = EPOCHS,\n                              validation_data = (X_val,y_val),\n                              verbose = 2,\n                              steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n                              callbacks=[lrr])","f3471333":"fig, ax = plt.subplots(2,1)\nfig.set_size_inches(11, 8)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","d3b8a72e":"#\u00a0Helper method for confusion matrix\ndef plot_confusion_matrix(confusion_mat, classes):\n    fig, ax = plt.subplots()\n    fig.set_size_inches(11, 8)\n    fig = plt.imshow(confusion_mat, interpolation='nearest')\n    plt.title('Confusion matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.show(fig)","a7db694d":"y_pred = model.predict(X_val)\ny_pred_classes = np.argmax(y_pred,axis = 1) \ny_actual = np.argmax(y_val,axis = 1) \nconfusion_mat = confusion_matrix(y_actual, y_pred_classes) \nplot_confusion_matrix(confusion_mat, classes = range(10)) ","7025bd92":"results = model.predict(X_test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name='Label')\nsub = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsub.to_csv('mnist_submission.csv',index=False)","8f092587":"### Normalization\n\nI\u00b4m going to perform a grayscale normalization to reduce color intensity differences, and to scale the data in the 0-1 range.","e8cfe1c2":"## Data Preparation\n### Load the Data","e5e5cc57":"## Evaluate the Model","034cd5aa":"### Label Distribution","f1c61807":"## Augment the Data","22a2c8ef":"## Build the CNN Model\n\nHere, I\u00b4m using the Keras Sequential API, building one layer at a time from input to output.\n\nThe layers are:\n    * A pair of Conv2D layers with 32 filters\n    * A MaxPool2D layer\n    * A Dropout layer\n    * Two more Conv2D layers with 64 filters\n    * A MaxPool2D layer\n    * A Dropout layer\n    * A Flatten layer\n    * A RELU activation layer\n    * A SoftMax output layer\n","8e8f5488":"### Make Train-Validation Split","844efbe7":"# MNIST Digit Recognizer\n## Description\n\n* data files contain gray-scale images of hand-drawn digits\n* Digits range from zero through nine.\n* Each image is 28x28\n* The training data set has 785 columns\n* First column (label) is the target\n* Each pixel column in the training is named pixelx, where x is an integer between 0 and 783, inclusive\n* The test data set contains 28000 images\n* Output columns should be ImageId and Label\n* Evaluation metric is the categorization accuracy","4b68a541":"## Predict and Submit","d0192cd5":"Predict and Plot Confusion Matrix","3e3cf08c":"### Reshape to 28x28","e79150ca":"### Encode the Labels","acc2405d":"## Fit the Model","e2186879":"### Sample Image"}}