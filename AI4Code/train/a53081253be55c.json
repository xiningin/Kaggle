{"cell_type":{"bbb6d617":"code","97649b72":"code","ee01674b":"code","ed6d9ec1":"code","a71cd93b":"code","ecddc2c2":"code","4caf0c06":"code","4b8351b5":"code","507a51ad":"code","9a801c0f":"code","ef42d9e2":"code","4d569001":"code","bdaf7b61":"code","2fb1c534":"code","d33ec39e":"code","60ec8878":"code","dbd73ab1":"code","b1cb6758":"code","06c53894":"code","8d5af69b":"code","b464aeb9":"code","53064ac4":"code","84d8f055":"code","8b8c3fe5":"code","40cbac52":"code","0e454915":"code","c6992c51":"code","24052f8f":"code","f1af18da":"code","28d39139":"code","598af977":"code","add4cce8":"code","9f4e5e7a":"code","3a554f97":"code","2110b215":"code","c4465e7e":"code","91405a87":"code","d41a49be":"code","f6450a01":"code","103ab365":"code","2181035a":"code","5c04bf48":"code","54460c6a":"code","cec57588":"code","9ecbdf0c":"code","273bc631":"code","31e868a7":"code","f10d2538":"code","86f5fb9b":"code","fef978c9":"code","b2e79b80":"code","a5cc9c8d":"code","6dee51d8":"code","55a75cc7":"code","3ee293fd":"code","618c198a":"code","aa5c672a":"code","e2e0e90d":"code","7cffc1ed":"code","22d415e4":"code","70c5de02":"code","bf8e9f6c":"code","0d2db152":"code","6dd6e9a4":"code","ab9b6d8b":"code","d3e32050":"code","26cf346f":"code","ecb49358":"code","1d783b0d":"markdown","862bd13e":"markdown","77796ebb":"markdown","ee8c1573":"markdown","2d1b47c9":"markdown","b256f82b":"markdown","69f4d012":"markdown","9ac9c3c7":"markdown","76bf27d0":"markdown","8fd2e4e4":"markdown","cf6e4f0d":"markdown","1ff44b4d":"markdown","df9f9718":"markdown","e8fa5605":"markdown","34d7323b":"markdown","a0c463c1":"markdown","af20770f":"markdown"},"source":{"bbb6d617":"import pandas as pd\n\n#import dataset\ndata = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\n#Export dataset\ndata.to_csv('output.csv')\n","97649b72":"#Returns by default top five rows\ndata.head()","ee01674b":"#Returns by default last five rows\ndata.tail()","ed6d9ec1":"#Returns column names\ndata.columns ","a71cd93b":"#Returns column data types\ndata.dtypes ","ecddc2c2":"#Returns (Rows, Columns) of th dataset\ndata.shape ","4caf0c06":"#Returns total count of non NA values for each column\ndata.count()","4b8351b5":"#Returns basic statistical information of numeric columns only\ndata.describe() ","507a51ad":"#Returns information of string columns\ndata.describe(include=object)","9a801c0f":"#Returns information about dataframe like index dtype and column dtypes, non-null values and memory usage\ndata.info()","ef42d9e2":"#Returns distinct count of observations for each column\ndata.nunique()","4d569001":"#Returns count of unique values for series(columns in our case)\ndata['Pclass'].value_counts()","bdaf7b61":"#Rename the column names\ndata.rename(columns= {\"Name\":\"Full Name\"})","2fb1c534":"#Drop columns\ndata.drop(columns=['Name','Survived','Pclass'])","d33ec39e":"#Selects one column data\ndata['Name']","60ec8878":"#Selects more than one column data\ndata[['Sex','Name']]","dbd73ab1":"#Filters data based on condition\ndata[data['Age']>50]","b1cb6758":"#Filters all rows and 3 columns(sex,pclass,age)\ndata.loc[:, ['Sex','Pclass','Age']]","06c53894":"#Filters 100 to 400 rows and 2 columns(survived, sex)\ndata.loc[100:400 :,['Survived','Sex']]","8d5af69b":"#Filters all rows and columns from survived to sex (Survived, Pclass, Name, Sex)\ndata.loc[:, 'Survived':'Sex']","b464aeb9":"#Filters rows based on condition (sex=female) and all columns\ndata.loc[data['Sex']=='female', ]","53064ac4":"#Filters all rows and 1 to 4 columns\n#index starts from zero and ignores last index while filtering  \ndata.iloc[ :,1:4]","84d8f055":"#Filters all rows and 1,4,6 columns\ndata.iloc[:,[1,4,6]]","8b8c3fe5":"#Filters rows from 150 to 400 and and 2,7,3 columns\ndata.iloc[150:400:,[2,7,3]]","40cbac52":"#Returns Survived column wise count\ndata.groupby('Survived').count()","0e454915":"#Returns max age based on sex column\ndata.groupby('Sex')['Age'].max()","c6992c51":"#Returns min age based on sex, survived columns\ndata.groupby(['Sex','Survived'])['Age'].min()","24052f8f":"#Multiple aggregation functions  \n#Returns min,max age based on parch & survived\ndata.groupby(['Parch','Survived'])['Age'].agg([min, max])","f1af18da":"#Sorts the dataset based on specified single column(default it sorts in ascending order)\ndata.sort_values(by='Name')","28d39139":"#Sorts the dataset based on specified single column in decending order\ndata.sort_values(by='Name', ascending=False)","598af977":"#Returns True or False \ndata.isnull()\ndata.isna()","add4cce8":"#Fills all NA's with zero for both string nd numeric\n\n#NA's can be filled with mean,median or mode as well. \ndata.fillna(0)","9f4e5e7a":"#Drops rows if row have at least one NA value\ndata.dropna(how='any') ","3a554f97":"#Drops rows if the row have all NA values\ndata.dropna(how='all')","2110b215":"#Drops columns if the column have at least one NA value\ndata.dropna(axis='columns', how='any')","c4465e7e":"#Checks if whole row appears elsewhere with same values. \ndata.duplicated()","91405a87":"#checks if there is any duplicate values of particular column\ndata.duplicated('Age')","d41a49be":"#drops duplicate records \ndata.drop_duplicates()","f6450a01":"#drops duplicates from particular column\ndata.drop_duplicates('Age')","103ab365":"#sets index based on specified column \ndata.set_index('Sex')","2181035a":"#sets index based on specified columns\ndata1 = data.set_index(['Sex','PassengerId'])\ndata1","5c04bf48":"#reset index \ndata1.reset_index()","54460c6a":"#melt() function is used to convert dataframe from wide format to long format\ndata.melt(id_vars='PassengerId')","cec57588":"#we can use melt() function for particular columns as well\ndata.melt(id_vars='PassengerId', value_vars=['Survived','Sex'], var_name='Columns', value_name='Column_values')","9ecbdf0c":"#pivot() function is used to reshape dataframe based on index\/columns values. Results into multiindex \n# don't support aggregation function\n\ndata.pivot(index='PassengerId', columns='Sex')","273bc631":"#we can use pivot() function for particular columns as well\ndata.pivot(index='PassengerId', columns='Sex', values=['Survived','Pclass','Age'])\n\n","31e868a7":"#pivot_table is used for data aggregation \n#Obersvations are filled with sum of age values\n\ndata.pivot_table(index='PassengerId', columns='Sex', values='Age', aggfunc='sum')\n","f10d2538":"#Let's create data frames to demonstrate Merge and Concat functions\n\ndf1 = pd.DataFrame({\"x1\": [\"a\",\"b\",\"c\",\"d\"], \"x2\":[12.0, 23.2, 56, 45.4]})\ndf2 = pd.DataFrame({\"x1\": [\"a\",\"b\",\"c\",\"e\"], \"x3\":[9.5, 37.0, 77,38.9]})","86f5fb9b":"df1","fef978c9":"df2","b2e79b80":"#Merge function ","a5cc9c8d":"#merges come data based on x1 column: inner join (a,b,c)\npd.merge(df1,df2,on=\"x1\")","6dee51d8":"#merges both data based on x1 column: outer join (a,b,c,d,e)\n#while merging if data is not there then it will replace with NaN value\n\npd.merge(df1,df2,on=\"x1\", how=\"outer\")","55a75cc7":"#merges common data from both dataset and remaining data from left dataset \n#while merging if data is not there then it will replace with NaN value\n\npd.merge(df1,df2,on=\"x1\", how=\"left\")","3ee293fd":"#merges common data from both dataset and remaining data from right dataset \n#while merging if data is not there then it will replace with NaN value\n\npd.merge(df1,df2,on=\"x1\", how=\"right\")","618c198a":"#concat function","aa5c672a":"#by default performs outer join and works row wise\npd.concat([df1,df2])","e2e0e90d":"#axis will be labeled 0, \u2026, n - 1\npd.concat([df1,df2], ignore_index=True)","7cffc1ed":"#concatnates column wise\npd.concat([df1,df2], axis=1)","22d415e4":"pd.concat([df1,df2], join=\"inner\")","70c5de02":"#Load the dataset, for date formating I am using applestock price dataset.\n\ndata1 = pd.read_csv('https:\/\/raw.githubusercontent.com\/Ekta-Manvar\/Pandas-For-Data-Analysis\/master\/applestock.csv')\n\ndata1.head()","bf8e9f6c":"#check the datatypes\ndata1.dtypes\n\n#date column is object type not datetime format","0d2db152":"#to_datetime() - converts any format to datetime format\n\ndata1['Date'] = pd.to_datetime(data1['Date'])\ndata1.dtypes","6dd6e9a4":"#extract year, month, day from date column \n\ndata1['Year'] = data1['Date'].dt.year\ndata1['Month'] = data1['Date'].dt.month\ndata1['day'] = data1['Date'].dt.day\n\ndata1.head()","ab9b6d8b":"#pd.DatetimeIndex() - sets date as index\ndata1.index = pd.DatetimeIndex(data1['Date'])\n\n#once we set date as index, needs to del date column \ndata1.drop(columns=['Date'], inplace=True)\n\ndata1.head()","d3e32050":"#Resample() - resamples time series data based on specified frequency\ndata1['High'].resample('M').sum()\n\n#current date frequncy is daily","26cf346f":"data1['Close'].resample('W').mean()","ecb49358":"#date_range() - creates array of datetime \n\n#creates 10 dates starting from 2020-01-05 with WEEK frequency\ndate1 = pd.date_range(start='2020-01-05', periods=10, freq='W')\n\n#creates 10 dates ending date is 2020-03-10 with MONTH frequency\ndate2 = pd.date_range(end='2020-03-10', periods=10, freq='M')\n\n#creates 10 dates ending date is 2020-03-10 with MONTH frequency\ndate3 = pd.date_range(start='2020-01-01', end='2020-06-01', freq='SM')\n\npd.DataFrame({\"Date1\": date1, \"Date2\": date2, \"Date3\": date3})\n","1d783b0d":" **Table of Content**\n \nIf you are new to pandas and want to learn pandas in 10 minutes so this notebook is for you. \n \n 1. <a href=\"#ied\">Importing and Exporting Data<\/a>\n 2. <a href=\"#vid\">Viewing and Inspecting Data<\/a>\n 3. <a href=\"#sfd\">Selecting and Filtering Data <\/a>\n 4. <a href=\"#gsd\">Grouping and Sorting Data<\/a>\n 5. <a href=\"#mdd\">Handling Missing and Duplicate Data<\/a>\n 6. <a href=\"#sri\">Setting and Resetting Index<\/a>\n 7. <a href=\"#rd\">Reshaping data<\/a>\n 8. <a href=\"#md\">Merging Data<\/a>\n 9. <a href=\"#df\">Date Formating<\/a>\n \n \n \n \n \n \n \n \n \n \n \n \n \n ","862bd13e":"# <a id=\"rd\">Reshaping data <\/a>","77796ebb":"# <a id=\"sri\">Setting and Resetting Index<\/a>","ee8c1573":"\n\n# <a id=\"mdd\">Handling Missing and Duplicate Data<\/a>\n \n ","2d1b47c9":"Age, Cabin, Embarked columns dropped.","b256f82b":"Let's start by importing the panda's library. Below is the syntax to import the library. Import is the keyword, pandas is a library name, and pd is the alias. By using alias all the functions of pandas are accessed.\n\nThe first step in the data science project is to import the dataset. Often you will work with a common separate value(CSV) file. read_csv() function is used to import the dataset and to_csv()  is used to export the dataset.\u00a0\n\nData is the variable name and the variable is used to store any kind of data. Any variable name can be used. Different file formats of data can be imported and exported like Excel, Html, JSON, etc.","69f4d012":"# <a id=\"df\">Date Formating<\/a>","9ac9c3c7":"In our case, we don't have any such row that has all NA values.","76bf27d0":"See how rows got decreased from 891 to 183, be cautious when you use dropna() function because it drops a lot of valuable data.","8fd2e4e4":"#  <a id=\"ied\">Importing and Exporting Data<\/a>","cf6e4f0d":"#  <a id=\"md\">Merging Data<\/a>","1ff44b4d":"\n#  <a id=\"vid\">Viewing and Inspecting Data<\/a>\n\n","df9f9718":"\n\n# <a id=\"gsd\">Grouping and Sorting Data<\/a>\n\n","e8fa5605":"\n# <a id=\"sfd\">Selecting and Filtering Data <\/a>\n\n","34d7323b":"See how rows got decreased from 891 to 89, be cautious when you use drop_duplicates() function because it drops a lot of valuable data. In our case obviously with the same age group travelled in titanic. Just used for example only.","a0c463c1":"In our case, we don't have any duplicate records.","af20770f":"Now Sex, PassengerId columns are reset back to normal columns."}}