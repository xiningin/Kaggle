{"cell_type":{"07b570da":"code","96948448":"code","0e32d27b":"code","ecd73726":"code","8b1a5cae":"code","544ab3f9":"code","c7fe707c":"code","a5b0c5a2":"code","e13b5bc5":"code","00d3f946":"code","f7c516fe":"code","2b5ce436":"code","a1b8c994":"code","7e7ad7aa":"code","c6a1be6c":"code","10150a9f":"code","cfe3d6c9":"code","fc3e3417":"code","77b5c466":"code","fc0d31af":"code","7fb8b7e6":"code","6911b4b3":"code","987b1c27":"code","6e4d5918":"code","08266d83":"code","21f33072":"code","da9b9414":"code","c040372e":"code","7a263e23":"code","ea49f436":"code","ecf0f059":"code","a8fe3a28":"code","aa72febf":"code","797e131d":"code","8b5d25ba":"code","3d60449e":"code","70349e27":"code","bf6c073c":"code","ae4113da":"code","61f8d7d2":"code","50f319b4":"code","858824fb":"code","6bf3fe06":"code","1a03bf42":"code","50199d1a":"code","c883470e":"code","76161dd6":"code","9911ed5f":"code","161ef978":"code","fd283e69":"code","73d76dbd":"code","83b86be1":"code","08fafde9":"code","60a83e4c":"code","6ea28226":"code","83bea08f":"code","0e5da2db":"code","0f3b648d":"code","5b8d5852":"code","1e49a152":"code","06ee1f0f":"code","467b3acd":"code","7eee998a":"code","651a97bf":"code","e6ffc0ca":"code","9f63c815":"code","2410969d":"code","fc55ff6b":"code","f835c079":"code","f93591ff":"code","a2b1cfc3":"code","a350fb9b":"code","66e5446d":"code","1cdb5327":"code","82134292":"code","0c69f4c6":"code","50dbb93f":"code","2808df20":"code","4b8d5f55":"code","9f9f4918":"code","8e5c1fa2":"code","173442d6":"code","f14879e1":"code","121add12":"code","18154749":"code","78204fc1":"code","12444777":"code","baf7be34":"code","23c6b5b3":"markdown","2208ce37":"markdown","0e1f4901":"markdown","51f4ea25":"markdown","15441ed0":"markdown","cac0cfda":"markdown","ee3f2fc1":"markdown","add805c2":"markdown","353dbd11":"markdown","a94ae652":"markdown","5c98bc23":"markdown","6b9a5602":"markdown","d0c0d46b":"markdown","67c643f3":"markdown","ced50e30":"markdown","d232008a":"markdown"},"source":{"07b570da":"## Importing Libraries ##\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nsns.set()\n# plt.style.use('seaborn-colorblind')\n# sns.color_palette(COLOR_PALETTE)\nCOLOR_PALETTE = 'Blues_d'\n%matplotlib inline\npd.set_option('display.max_columns', 500)\nfrom IPython.display import Markdown, display","96948448":"## Helper Functions for printing conversational dialogues\n\ndef pm(text):\n    PM_text = \"<div style= 'background-color:rgb(247, 247, 247); border:1px solid rgb(207,207,207); border-color:rgb(207,207,207); padding: 10px'>\\\n    <span style=\\\"color: black;  font-family:  'Helvetica Neue', Helvetica, Arial, sans-serif; \\\nfont-weight: 400;  letter-spacing: -0.004em; line-height: 1.58; font-style: italic;\\\"> \" + text +\" <\/span><\/div>\"\n    display(Markdown(PM_text))\n    \n    \ndef response(text):\n    my_response = \"<div style= 'background-color:rgb(247, 247, 247); border:1px solid rgb(207,207,207); border-color:rgb(107,107,107); padding: 10px'> \\\n    <span style='color: black;  font-family: medium-content-serif-font, Georgia, Cambria, 'Times New Roman', Times, serif; \\\n    font-weight: 400; letter-spacing: -0.004em; line-height: 1.58; '>\"+ text +\"<\/span><\/div>\"\n    display(Markdown(my_response))","0e32d27b":"## Reading Data\n\ndir = '..\/input\/kaggle-survey-2019'\ndir2 ='..\/input'\nmcq = pd.read_csv(dir+'\/multiple_choice_responses.csv')\ntext = pd.read_csv(dir+'\/other_text_responses.csv')\nquestions = pd.read_csv(dir+'\/questions_only.csv')\nsurvey = pd.read_csv(dir+'\/survey_schema.csv')\n\n# Historical Data\nmcq_2017 = pd.read_csv(dir2+'\/kaggle-survey-2017\/multipleChoiceResponses.csv', encoding='latin-1');\nmcq_2018 = pd.read_csv(dir2+'\/kaggle-survey-2018\/multipleChoiceResponses.csv');\n\n\n## Change Interest Country Here\ncountry = 'India'\ncountry_to_compare= 'United States of America'\n#assert(country in country_list),\"Please choose a valid country. List is here: \\n\"+ \"\\n\".join(country_list)\nprint('My country of Interest is '+ country)","ecd73726":"pm(\"PM: Hello Harveen, Welcome to my office. My assistant tells me that you are of the best analysts in India today.\")\nresponse(\"Me: My pleasure sir. I always wanted to meet you in person. It's an honor to be here.\")\npm(\"PM: Today I have called you for a very important reason that is in the interest of the country. As I talk, do let me know if this topic interests you.\")\nresponse(\"Me: Sir, I always wanted to join the Indian Army so that I can serve my country. Unfortunately that did not happen, if today I am getting a chance to serve my country in any way, I would like to take it. If it is of nation's interest then it is my interest.\")\npm(\"PM: That's the spirit. We are delighted to have such enthusiastic individuals as you are.\")\nresponse(\"Me: Not all battle's are fought on battlefield sir. Please let me know how can I contribute to my country?\")\npm(\"PM: Harveen, the world has gone through numerous Industrial revolutions. The First Industrial Revolution used water and steam power to mechanize production. The invention of the steam engine created a new type of energy back then. The Second used electric power to create mass production. Usage of steel to build ships, railroads at a less price point increased with introduction of Bicycle and automobiles as well.\u00a0\")\nresponse(\"Me: Right Sir!\")\npm(\"PM: The Third used electronics and information technology to automate production. This revolution witnessed the rise of electronics\u200a-\u200awith the transistor and microprocessor\u200a-\u200abut also the rise of telecommunications and computers. And Now we have the fourth revolution.\")\nresponse(\"Me: Yes! The Digital Revolution\")\npm(\"PM: Yes, Absolutely, in this Digital Revolution we are seeing the emergence of Internet and other emerging technology breakthroughs in fields such as artificial intelligence, robotics, the Internet of Things, autonomous vehicles etc.\")\nresponse(\"Me: AI is currently the talk of the town sir!\")\npm(\"PM: Right, and we should be too! \\\"I feel Artificial intelligence, machine learning, Internet of Things, blockchain & big data hold potential to take India to new heights\\\". \\\"India was not independent when the first and second industrial revolution happened. When third industrial revolution happened, India was struggling with challenges of just attained independence\\\". \\\"While the previous industrial revolutions eluded the country, India's contribution to the 4th Industrial Revolution would be astonishing\\\"\")\nresponse(\"Me: Absolutely sir, I am delighted to hear that you are thinking in all perspectives.\")\npm(\"PM: I want India to become a superpower in the 4th Industrial Revolution and for this I need inputs from your side.\")\nresponse(\"Me: Sure sir! Just order.\")\npm(\"PM: While we are launching a lot of schemes in association with NITI Ayog in India and trying to use Artificial Intelligence in every possible way ever, I need to understand from the ground level on how the Indian Techies and students are adopting this Technology. I need an in-depth analysis on what is the age group, qualification, gender, compensation, job titles, companies of these Techies so that we can roll out better policies which can actually benefit them and which can help me in achieving my dream of becoming superpower in 4th Industrial revolution.\")\n\nresponse(\"Me: I understood sir. You are in luck, Kaggle which is a platform for Data Science currently posted their survey from techies all over the world who are working in this technology. This survey is conducted annually. I happen to do an analysis on the data they have provided.\")\npm(\"PM: That is great! Please show me analysis as much in depth as possible.\")\nresponse(\"Me: Sure sir. First of all, a total of 19,717 people from 171 countries responded to this survey. The respondent of this survey are the techies\/students who use Kaggle to participate in Data Science competitions. Since Artificial Intelligence involves working with Data, so Data Science is a sub-field of AI.\")\n\n\npm(\"PM: Great! No matter what science, it has the power to change the world! Look at our scientists in ISRO doing wonders for the country.\")\nresponse(\"Me: Absolutely sir. So a total of 4786 participants were from India. I understand that this is not a large number but this sample represents the whole population.\")\npm(\"PM: Oh! You mean, when we have elections, like the exit polls are conducted. Is it something similar\u00a0?\")\nresponse(\"Me: Yes sir. And you will be glad to know that India had the maximum number of respondents which comprises close to 24.3% of the total participants.\")","8b1a5cae":"\n## Helper function to annotated bar plots\ndef show_bar_plot(x , y,  data, hue = None, axis = 'vertical', title= None, show_percent = True, xlabel = None, ylabel= None, legend= None):\n  if hue is None:\n    ax = sns.barplot(y = y , x = x, data = data, palette=(COLOR_PALETTE))\n  if hue is not None:\n    ax = sns.barplot(y = y , x = x, hue=hue, data = data, palette=(COLOR_PALETTE))\n  plt.title(title)\n  if show_percent:\n    if axis == 'vertical':\n      for p in ax.patches:\n        percentage = '{:.2f}%'.format(p.get_y() + p.get_height())\n        x = p.get_x() + p.get_width()\/2\n        y = p.get_y() + p.get_height() + 0.4\n        ax.text(x, y, percentage, ha=\"center\") \n\n\n    elif axis == 'horizontal':    \n      for p in ax.patches:\n        percentage = '{:.2f}%'.format(p.get_x() + p.get_width())\n        x = p.get_x() + p.get_width() + 0.2\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n \n  if xlabel is not None:\n    plt.xlabel(xlabel);\n  if ylabel is not None:\n    plt.ylabel(ylabel);\n \n  plt.show()\n\n\n## Helper function to break labels if they are lengthy. Labels are broken by spaces.\ndef break_labels(df, column):\n    unique_vals = df[column].unique()\n    dict_val = {}\n    for item in unique_vals:\n        arr = item.split(' ')\n        new_name = \"\\n\".join(arr)\n        dict_val[item] = new_name\n    df[column] = df[column].map(dict_val)\n    return df\n\n## Helper function to show point plots\ndef show_point_plot(x , y,  data= None, hue = None, axis = 'vertical', title= None, show_percent = False, xlabel = None, ylabel= None, legend= None):\n  if data is not None:\n      data = break_labels(data, x)\n\n      if hue is None:\n        ax = sns.pointplot(y = y , x = x, data = data, palette=(COLOR_PALETTE))\n      if hue is not None:\n        ax = sns.pointplot(y = y , x = x, hue=hue, data = data, palette=(COLOR_PALETTE))\n      plt.title(title)\n\n      if show_percent:\n          for c in ax.collections:\n            for of in c.get_offsets():\n                val = str(round(of[1],2))\n                ax.annotate(val, of)\n\n\n      if xlabel is not None:\n        plt.xlabel(xlabel);\n      if ylabel is not None:\n        plt.ylabel(ylabel);\n      plt.show()\n  else:\n\n      if hue is None:\n        ax = sns.pointplot(y = y , x = x,  palette=(COLOR_PALETTE))\n      if hue is not None:\n        ax = sns.pointplot(y = y , x = x, hue=hue,  palette=(COLOR_PALETTE))\n      plt.title(title)\n\n      if show_percent:\n          for c in ax.collections:\n            for of in c.get_offsets():\n                val = str(round(of[1],2))\n                ax.annotate(val, of)\n\n\n      if xlabel is not None:\n        plt.xlabel(xlabel);\n      if ylabel is not None:\n        plt.ylabel(ylabel);\n      plt.show()\n\ndef show_cat_plot(x , y,  data, hue = None, col=None, sharex= False, sharey=False, kind='bar', col_wrap=None, title= None, show_percent = False, xlabel = None, ylabel= None, legend= None):\n    ax = sns.catplot(y = y , x = x, hue=hue, col=col, data = data, palette=(COLOR_PALETTE),kind=kind, col_wrap=col_wrap, sharex = sharex, sharey=sharey)\n    plt.title(title)\n\n    if xlabel is not None:\n        plt.xlabel(xlabel);\n    if ylabel is not None:\n        plt.ylabel(ylabel);\n\n    plt.show()\n    \n    \n## Helper function to get the counts of unique classes per column. This is a configurable function.\ndef value_counts(df, column, normalize= True, rename= 'Percentage', return_percent= True):\n    if normalize:\n        if rename is not None and return_percent:\n            mod_df= df[column].value_counts(normalize=normalize).rename(rename).mul(100).reset_index()\n            mod_df= mod_df.rename(columns ={'index':column})\n            return mod_df\n    else:\n        mod_df= df[column].value_counts(normalize=False).rename('Count').reset_index()\n        mod_df= mod_df.rename(columns ={'index':column})\n        return mod_df\n\n## Helper function to combine dataframe of selected country with data frames of rest of the world. Certain checks are done to make sure the lists sizes are equal\ndef combine_row_country(df_country, df_row, country_compare='ROW'):\n    df_country['Geography'] = country\n    df_row['Geography'] = country_compare\n    concat = pd.concat([df_country,  df_row], axis = 0).reset_index(drop=True)\n    column = list(df_country.columns)[0]\n    length_1 = list(df_country[column].unique())\n    length_2 = list(df_row[column].unique())\n    dict_more=[]\n    if(len(length_1) == len(length_2)):\n        return concat\n    elif(len(length_1) > len(length_2)):\n        not_present = []\n        for col in length_1:\n            if col not in length_2:\n                not_present.append(col)\n        for col in not_present:\n            dict_more.append([col, 0, country_compare])\n            \n    elif(len(length_1) < len(length_2)):\n        not_present = []\n        for col in length_2:\n            if col not in length_1:\n                not_present.append(col)\n        for col in not_present:\n            dict_more.append([col, 0, country])\n\n    new_df = pd.DataFrame(dict_more, columns=[column, 'Percentage', 'Geography'])\n    #print(new_df)\n    concat = pd.concat([concat,  new_df], axis = 0).reset_index(drop=True)\n    return concat\n\n## Helper function to combine historical data from previous years\ndef combine_historical(df_2018, df_2019, column):\n    df_2018['Year'] = '2018'\n    df_2019['Year'] = '2019'\n    \n    concat = pd.concat([df_2018,  df_2019], axis = 0).reset_index(drop=True)\n    #column = list(df_country.columns)[0]\n    length_1 = list(df_2018[column].unique())\n    length_2 = list(df_2019[column].unique())\n    dict_more=[]\n    if(len(length_1) == len(length_2)):\n        return concat\n    elif(len(length_1) > len(length_2)):\n        not_present = []\n        for col in length_1:\n            if col not in length_2:\n                not_present.append(col)\n        for col in not_present:\n            dict_more.append([col, 0, '2019'])\n            \n    elif(len(length_1) < len(length_2)):\n        not_present = []\n        for col in length_2:\n            if col not in length_1:\n                not_present.append(col)\n        for col in not_present:\n            dict_more.append([col, 0, '2018'])\n\n    new_df = pd.DataFrame(dict_more, columns=[column, 'Percentage', 'Year'])\n    concat = pd.concat([concat,  new_df], axis = 0).reset_index(drop=True)\n    return concat\n\n## Helper function to map column using a dictionary\ndef map_column(df, col, dict_map):\n    df[col] = df[col].map(dict_map)\n    df = df[~df[col].isnull()].reset_index(drop=True)\n    return df\n\n## Helper function to combine historical values from previous 3 years\ndef combine_historical_3(df_2017, df_2018, df_2019, col, map_dict= None):\n    historical_3 = value_counts(df_2019, col)\n    historical_2 = value_counts(df_2018, col)\n    historical_1 = value_counts(df_2017, col)\n    \n    historical_1['Year'] = 2017\n    historical_2['Year'] = 2018\n    historical_3['Year'] = 2019\n    \n    historical_concat = pd.concat([historical_1, historical_2, historical_3])\n    \n    if map_dict is not None:\n        historical_concat = map_column(historical_concat, col, map_dict)\n    return historical_concat\n\n## Helper function to apply group by using multiple parameters\ndef multiple_group_by(df, groupby, map_col1 = None, map_col2 = None, year= None):\n    \n    grouped = df.groupby(groupby).agg('count')[['Time']].reset_index()\n    col1 = groupby[0]\n    col2 = groupby[1]\n    \n    if map_col1 is not None:\n        grouped = map_column(grouped, col1, map_col1)\n    \n    col1_unique = grouped[col1].unique()\n    col2_unique = grouped[col2].unique()\n    \n\n    _pd_new = pd.DataFrame()\n\n    for col_1 in col1_unique:\n        filter_group = grouped[grouped[col1] == col_1]\n        sum_group = filter_group['Time'].sum()\n        \n        for col_2 in col2_unique:\n            filter_group_2 = filter_group[(filter_group[col2] == col_2)]\n            if(len(filter_group_2) > 1):\n                filter_group_2 = filter_group_2.groupby(groupby).agg('sum')[['Time']].reset_index()\n            filter_group_2['Percentage'] = filter_group_2['Time'] \/ sum_group * 100\n            _pd_new = pd.concat([_pd_new, filter_group_2])\n    \n    if map_col2 is not None:\n        _pd_new = map_column(_pd_new, col2, map_col2)\n    if year is not None:\n        _pd_new['Year'] = year\n    return _pd_new\n\n## Helper function to combine multiple answers into one column\ndef multiple_answers(limit, df, col, mod_name):\n    dict_local = {}\n\n    for i in range(1, limit+1):\n        col_name = col + str(i)\n        new_col_name = df[col_name].value_counts().reset_index().iloc[0,0]\n        dict_local[new_col_name]  = df[col_name].value_counts().reset_index().iloc[0,1]\n\n    new_df = pd.DataFrame(dict_local, index=[0])\n    new_df = new_df.melt()\n    new_df = new_df.sort_values(by='value', ascending=False)\n    new_df = new_df.rename(columns= {'variable':mod_name, 'value':'Count'})\n    return new_df","544ab3f9":"## changing column names for better readability\ncolumn_mapping = {'Time from Start to Finish (seconds)':'Time',\n'Q1':'Age',\n'Q2':'Gender',\n'Q3':'Country',\n'Q4':'Degree',\n'Q5':'Job Title',\n'Q6':'Company Size',\n'Q7':'Team Size',\n'Q8':'ML Status in Company',\n'Q10':'Compensation Status',\n'Q11':'Money Spent'\n}\n\nmcq = mcq.rename(columns= column_mapping)\nmcq= mcq.drop([0], errors='ignore')\n\n## changing column names for better readability. 2018 columns are different as compared to 2019 columns\ncolumn_mapping_2018 = {'Time from Start to Finish (seconds)':'Time',\n'Q2':'Age',\n'Q1':'Gender',\n'Q3':'Country',\n'Q4':'Degree',\n'Q6':'Job Title',\n'Q8':'Team Size',\n'Q9':'Company Size',                       \n'Q7':'ML Status in Company',\n'Q10':'Compensation Status',\n'Q11':'Money Spent'\n}\nmcq_2018 = mcq_2018.rename(columns = column_mapping_2018)\nmcq_2018 = mcq_2018.drop([0], errors='ignore')\n\n## changing column names for better readability. 2017 columns are totaly different as compared to 2019 columns\ncolumn_mapping = {'Age':'Age',\n'GenderSelect':'Gender',\n'Country':'Country',\n'FormalEducation':'Degree',\n'CurrentJobTitleSelect':'Job Title',\n'EmployerSize':'Company Size',\n'EmployerSizeChange':'Team Size',\n'EmployerMLTime':'ML Status in Company',\n'CompensationAmount':'Compensation Status',\n'WorkMethodsFrequencyTimeSeriesAnalysis' : 'Time'\n}\n\n## Creating different dataframes to make the analysis easier\nmcq_2017 = mcq_2017.rename(columns = column_mapping)\nmcq_2017 = mcq_2017.drop([0], errors='ignore')\n\nmcq_country = mcq[(mcq['Country'] == country)]\nmcq_country_compare = mcq[(mcq['Country'] == country_to_compare)]\nmcq_row = mcq[~(mcq['Country'] == country)]\n\nmcq_country_2017 = mcq_2017[(mcq_2017['Country'] == country)]\nmcq_row_2017 = mcq_2017[~(mcq_2017['Country'] == country)]\n\nmcq_country_2018 = mcq_2018[(mcq_2018['Country'] == country)]\nmcq_row_2018 = mcq_2018[~(mcq_2018['Country'] == country)]\n","c7fe707c":"\nprint(\"Total Number of Respondents from \"+country+\": \"+str(len(mcq_country)))\nprint(\"Total Percentage of \"+country+\"n Respondents: \"+ str(round(len(mcq_country) \/ len(mcq) *100, 2)) + \"%\") \ntotal_respondents = len(mcq) - len(mcq_country)\n\n\nlabels = [country,'ROW']\n\nfig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(aspect=\"equal\"))\nwedges, texts = ax.pie([ len(mcq_country), total_respondents], wedgeprops=dict(width=0.5), startangle=-0)\nbbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\nkw = dict(arrowprops=dict(arrowstyle=\"-\"),\n          bbox=bbox_props, zorder=0, va=\"center\")\n\nfor i, p in enumerate(wedges):\n    ang = (p.theta2 - p.theta1)\/2. + p.theta1\n    y = np.sin(np.deg2rad(ang))\n    x = np.cos(np.deg2rad(ang))\n    #print(ang, x, y)\n    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n    connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n    kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n    ax.annotate(labels[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n                horizontalalignment=horizontalalignment, **kw)\nplt.title(\"Respondents from \"+country+\" vs ROW\")\nplt.show()\n","a5b0c5a2":"pm(\"PM: Great, what about from USA and China?\")\n","e13b5bc5":"top_respondents = value_counts(mcq, 'Country')\ntop_5_respondents = top_respondents.head(5)\n\n\nyour_country = top_respondents[top_respondents['Country']==country]\nrank =  int( your_country.index[0] + 1 )\nfilter_top_5 = top_5_respondents[top_5_respondents['Country'] == country]\nif len(filter_top_5) == 0:\n    top_5_respondents = pd.concat([ your_country, top_5_respondents])\n\nprint(\"Rank in terms of correspondents of your country \"+country+\" is: \"+str(rank))\n\nfig, ax = plt.subplots(figsize=(10,7))\nshow_bar_plot(x='Country', y='Percentage', data=top_5_respondents, title='Top 5 Respondents')\n","00d3f946":"response(\"Me: USA stood second with 15.6 % respondents followed by Brazil and Japan. China did not had enough respondents so it is not in top 5 sir.\")\npm(\"PM: Interesting, to know. And how have these respondents ratio increased over the years as you have told that this is an annual survey?\")\nresponse(\"Me: Here you go sir\")","f7c516fe":"mcq_country_2017 = mcq_2017[(mcq_2017['Country'] == country)]\nmcq_country_2018 = mcq_2018[(mcq_2018['Country'] == country)]\n\ncountry_responses_total = [ len(mcq_country_2017), len(mcq_country_2018), len(mcq_country)]\n\noverall_responses_total = [ len(mcq_2017), len(mcq_2018), len(mcq)]\n\ntotal_repsonses = country_responses_total + overall_responses_total\n\nyear_responses = ['2017', '2018', '2019'] * 2\ncountry_responses = [country] * 3 + ['Overall'] * 3\n\nseries1 = pd.Series(total_repsonses)\nseries2 = pd.Series(year_responses)\nseries3 = pd.Series(country_responses)\n\ndict_responses = {'Responses' : series1, 'Year' : series2, 'Geography' : series3}\n\ntest = pd.DataFrame(dict_responses)\ntest\n#test.melt()\n\nfig, ax= plt.subplots(figsize=(15,5))\nsns.pointplot(x = 'Year', y = 'Responses',  data=test[test['Geography'] == country], title='Respondents by Year from India');\nplt.title(\"Number of Responses from \"+country+\" over the years\")\nfig, ax = plt.subplots(figsize=(15,5))\nsns.pointplot(x = 'Year', y = 'Responses',  data=test[test['Geography'] == 'Overall'], title='Respondents by Year from India');\nplt.title(\"Overall Number of Responses over the years.\");","2b5ce436":"pm(\"PM:\u200aGreat. So let's move on! As you speak I will maintain a list of positives and negatives as well.\")","a1b8c994":"response(\"Me: So sir, the first thing I want to focus on is the Age group of these people. Since AI is the new and emerging technology we need a mix of young and experienced blood to drive this sector.\")\npm(\"PM: Absolutely. While experience brings in reliability, youth brings in creativity.\")\nresponse(\"Me: Haha. So the age group are as follows:\")","7e7ad7aa":"## AGE\n\n#age = mcq_country.Q1.value_counts(normalize=True).rename('Percentage').mul(100).reset_index()\nage = value_counts(mcq_country, 'Age')\nage_row = value_counts(mcq_row, 'Age')\n\nage_concat = combine_row_country(age, age_row)\n\nfig, ax = plt.subplots(figsize=(14,8))\nshow_bar_plot(x='Age' ,y= 'Percentage', data = age, axis = 'vertical', title= 'Age Group for '+country, xlabel='Age Group', ylabel='Percentage')\n\nage_compare = value_counts(mcq_country_compare, 'Age')\nage_compare = combine_row_country(age, age_compare, 'USA')\n","c6a1be6c":"response(\"Me: 1. More than 75% people are in the age group 18\u201329.\u00a0<br> \\\n2. 10% of the respondents are from a higher age group who may be at senior architect, technologist level. <br> \\\n3. Surpisingly there are records for people in the category > 60. So this shows there is no age for passion. People of age 60 years are also using Data Science to run their businesses or just for the learning purpose.\u00a0<br> \\\n4. But the good part is more than half of the current or prospective Data Scientists are way too young which is a positive sign as the youth is interested in this. <br> \\\n5. On the other hand, when you reach a higher age, some saturation comes in terms of learning, but that is not the case here. 16% people are in the age group 30\u201339. <br>\")\n\npm(\"PM: Great, and how is this compared to the Rest of the world?\")","10150a9f":"fig, ax = plt.subplots(figsize=(14,8))\nshow_bar_plot(x='Age' ,y= 'Percentage', hue='Geography', data = age_concat, axis = 'vertical', title= 'Age Group for '+country+' vs ROW', xlabel='Age Group', ylabel='Percentage')","cfe3d6c9":"response(\"Me: Highly positive sir. <br><br> \\\nWe have the highest youth percentage as compared to the rest of the world. But there is also a worry sign here. We have high percentages of youth but as you can see we have started declining from age group 25\u201329 onwards as compared to the world. As you said youth brings creativity, but this creativity needs direction and that direction can only be given by senior, experienced people. <br> \\\n<br>Another factor for this could be Brain Drain, but that is just a speculation at the moment.\")\n\npm(\"PM: Yes, you are right! I have on small request, I also want to see a one on one comparison with USA. I believe USA is our direct competitor and I should be aware of that too!\")\nresponse(\"Me: Here you go sir!\")","fc3e3417":"fig, ax = plt.subplots(figsize=(15,5))\nshow_point_plot(x='Age' ,y= 'Percentage',hue='Geography', data = age_compare, title='Age group comparison for '+country+' vs '+country_to_compare)","77b5c466":"pm(\"PM: It looks pretty much the same as we did in comparison to the rest of the world. Youth ratio is 30\u20135, then 26\u201310 then they always have more experienced people than us.\")\nresponse(\"Me: Exactly sir, you have a talent for reading graphs sir.\")\n\npm(\"PM: What is the diversity in this age group? How are the girls of our nation doing?\")\nresponse(\"Me: Even I am very much interested in this because recently I attended an event arranged by Google in Bangalore. The host asked \\\"How many women are AI Scientists or Data Scientists\\\". Only 5 hands went up from around 200 Females present at the venue. I was quite surprised by this. Lets see what happens here.\")","fc0d31af":"## gender\n\ngender = value_counts(mcq_country, 'Gender')\nfig, ax = plt.subplots(figsize=(8,6))\nshow_bar_plot(x='Gender' ,y= 'Percentage', data = gender, axis = 'vertical', xlabel='Gender', ylabel='Percentage', title='Gender Division in '+country)","7fb8b7e6":"response(\"Me: Sir, the numbers are not at all encouraging. Out of all the respondents only 16% are females.\")\npm(\"PM: That is very very disappointing.\")\nresponse(\"Me: Exactly, if this is a war then how can we win a war if half of the population does not takes part?\")","6911b4b3":"gender_row = value_counts(mcq_row, 'Gender')\ngender_concat = combine_row_country(gender, gender_row)\n\nfig, ax = plt.subplots(figsize=(8,6))\nshow_bar_plot(x='Gender' ,y= 'Percentage', data = gender_concat, hue='Geography', axis = 'vertical', title= 'Gender Percentages for '+country+' and ROW', xlabel='Age Group', ylabel='Percentage')\n","987b1c27":"response(\"Me: And this number not even in India but even in the rest of the world is quite discouraging.\")\npm(\"PM: So this is true for even the younger generation that is coming in?\")","6e4d5918":"filter_age_gender = mcq_country.groupby(['Gender','Age']).count().reset_index()[['Gender','Age','Country']]\nfilter_age_gender =  filter_age_gender.loc[filter_age_gender['Gender'].isin(['Male', 'Female'])]\n\nlist_groups = list(filter_age_gender['Age'].unique())\nlocal_dict = {}\n\nfor group in list_groups:\n  #print(group)\n  female = filter_age_gender.loc[((filter_age_gender['Age'] == group) & (filter_age_gender['Gender'] == 'Female'))]['Country']\n  male = filter_age_gender.loc[((filter_age_gender['Age'] == group) & (filter_age_gender['Gender'] == 'Male'))]['Country']\n  if(len(female) >0):\n    female = int(female)\n  else:\n    local_dict[group] = 0\n    continue;\n  if(len(male) >0):\n    male = int(male)\n  else:  \n    local_dict[group] = 0\n    continue;\n  \n  #print(female)\n  if female!=0 and male!=0:\n    local_dict[group] = male \/ female\n\nratio_df = pd.DataFrame(local_dict, index = [0])\nratio_df = ratio_df.melt()\nfig, ax = plt.subplots(figsize=(12,6))\nshow_bar_plot(x = 'variable', y='value', data= ratio_df, show_percent=False, title='Diversity in terms of gender in DS teams', xlabel='Age Group', ylabel='Number of Males per 1 Female')\n## Not putting here\n","08266d83":"response(\"Me: Unfortunately yes sir. The numbers tell the same story as in this chart. <br><br> \\\n<b>You know what this means sir, if we have a Data Science team of 12, then only 2 will be female and 10 will be male.<\/b> \")\n\npm(\"PM: Negative point noted and circled. India needs to be an example to break this gender bias.\u00a0\")\nresponse(\"Me: Absolutely sir, and not only gender bias but degree bias also.\")\npm(\"PM: What do you mean?\")\nresponse(\"Me: Sir, my personal belief is <b>\\\"Degrees don't matter, your attitude does\\\"<\/b>.  A major factor why the young people are not able to get good jobs in this field is that the companies are demanding PHD's and Masters in this field. Now to be very frank, they want qualified people but if you ask someone 5 years back that did they see this wave of AI coming, then nobody would have predicted that. And that is what I want to show you here\")","21f33072":"degrees_propotion = value_counts(mcq_country,'Degree') #mcq_country['Degree'].value_counts(normalize=True).rename('Percentage').mul(100).reset_index()\n\nfig, ax = plt.subplots(figsize=(7,6))\nshow_bar_plot(y='Degree' ,x= 'Percentage', data = degrees_propotion, axis = 'horizontal', xlabel='Percentage',ylabel='Degree', title='Degree Holders in '+country)\n\n\ndegrees_propotion_row = value_counts(mcq_row,'Degree')\ndegree_concat = combine_row_country(degrees_propotion, degrees_propotion_row)\n\n","da9b9414":"response(\"Me: 1. Close to 50% of Data Scientist or ML Engineers are Bachelors and surpirsinly 36% are Masters.<br> \\\n         2. I am assuming Masters people are the one's who have done Masters in Computers or Electronics and not in some specific field like Data Science or ML, because I can't recall a college providing Masters degree before 2017.<br> \\\n         3. As most of the Job boards require, there are only 5% people with Doctoral Degrees. This is an indicator that why there is a talent shortage because if the employer is not flexible with the degree requirement then from where will they hire? \")\n\nfig, ax = plt.subplots(figsize=(7,6))\nshow_bar_plot(y='Degree' ,x= 'Percentage', hue='Geography', data = degree_concat, axis = 'horizontal', xlabel='Percentage',ylabel='Degree', title='Degree Holders - '+country+' vs ROW')\n","c040372e":"response(\"Me: On the other hand if you see India vs ROW you will observe that most of the people from other parts of the world have done their masters or PHD degrees. The comparison of 5% to 17% PHD's is the one figure where we are losing.\")\n\npm(\"PM: That is another serious concern, Harveen. Over the past years we have included a lot of reforms for our PHD students, including a proposal to increase their stipend by 100% but I am shocked to see these numbers.\")\nresponse(\"Me: I understand that sir, but those reforms are not working. If you see our comparison with US, then you will feel this as well. Nearly 50% of their respondents are masters and they have 4 times the PHD's that India has.\")","7a263e23":"\ndegree_compare = value_counts(mcq_country_compare, 'Degree')\ndegree_compare = combine_row_country(degrees_propotion, degree_compare, 'USA')\nfig, ax = plt.subplots(figsize=(15,5))\nshow_point_plot(x='Degree' ,y= 'Percentage',hue='Geography', data = degree_compare, title='Degree Holder Comparison for '+country+' vs '+country_to_compare)","ea49f436":"pm(\"PM: That's disappointing.\u00a0\")\nresponse(\"Me: Not everything is disappointing sir.\")\npm(\"PM: What do you mean?\")\nresponse(\"Me: Statistics can be sometimes deceptive sir. If you see the historical analysis, you will be able to understand that the percentage of Masters and PHD's has been increasing over the years.\")","ecf0f059":"\nmap_dict= {'Bachelor\u2019s degree' : 'Bachelors', \"Bachelor's degree\":'Bachelors', 'Master\u2019s degree': 'Masters',\n           \"Master's degree\": 'Masters', 'Doctoral degree':'PHDs'\n          }\n\ndegree_historical = combine_historical_3(mcq_country_2017, mcq_country_2018,  mcq_country, 'Degree',map_dict)\nax = sns.catplot(x=\"Year\", y=\"Percentage\", aspect=0.8,  col=\"Degree\", data=degree_historical, col_wrap =3, sharex = False, sharey=True, kind='bar', palette=COLOR_PALETTE, margin_titles=True);\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Historical Degree Holders Comparison for \"+country);\n","a8fe3a28":"response(\"Me: <b>Also you will be happy to know that the ratio of girls pursuing PHD's has increased by 1.5 times from 2017.<\/b>\")","aa72febf":"dict_gender = {\"Female\":'Female', 'Male':'Male'}\nhist1 = multiple_group_by(mcq_country.copy(), ['Degree', 'Gender'], map_dict, dict_gender, 2019)\nhist2 = multiple_group_by(mcq_country_2018.copy(), ['Degree', 'Gender'], map_dict, dict_gender, 2018)\nhist3 = multiple_group_by(mcq_country_2017.copy(), ['Degree', 'Gender'], map_dict, dict_gender, 2017)\n\nhist_concat = pd.concat([hist1, hist2, hist3])\nax = sns.catplot(x=\"Year\", y=\"Percentage\", hue='Gender', aspect=0.8,  col=\"Degree\", data=hist_concat, kind=\"bar\", col_wrap=3, sharex=False, sharey=True, palette=COLOR_PALETTE);\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Historical Degree Holders Gender wise Comparison for \"+country);\n","797e131d":"pm(\"PM: That is a great great sign. I need to understand at what point in terms of age does an individual takes a decision to go for higher studies?\")\n    \nresponse(\"Me: Here you go!\")","8b5d25ba":"degree_age = mcq_country.groupby(['Degree','Age']).agg('count').reset_index()[['Degree', 'Age', 'Gender']]\n\n\nfig, ax = plt.subplots(figsize=(15,7))\n\ndegree_age.pivot('Age','Degree','Gender').plot.bar(stacked=True,width=0.8, ax=ax)\nax.set_xlabel('Age group')\nax.set_ylabel('Count')\nax.set_title('Degrees held according to Age Groups');","3d60449e":"response(\"Me: The number of masters is increasing from age group 22-24 onwards. Maybe respondents feel that at this age is the right time to pursue masters and advance career in Data Science.\")\npm(\"PM: This is great to see that by 35-39 most of the techies attain their masters but I agree with you, there should not be any degree bias. A prime example is sitting in front of you. I used to see tea and with just a simple degree I am now the PM of India.\")\n\nresponse(\"Me: Truly well said sir. Let's move on to Job Titles\")\npm(\"PM: When I was back in Silicon valley previous year, I saw they have very different job titles as we have in India like SDE and all.\")\nresponse(\"Me: Wow! I am amazed that you have knowledge about the job titles as well. When Data Science was not there, then engineers who write code where called software engineer but now since they have moved to Data Science field they are proudly called 'Data Scientists' and <b>'Data Scientist is the sexiest job of 21st century'<\/b>\")","70349e27":"pm(\"PM: Which takes me to my next question. How many % of the respondents are Data Scientists currently. Because I am assuming that a lot of people are still in transition.\")\nresponse(\"Me: Absolutely, but you have luck here.\")","bf6c073c":"## Job title\n\njob_title = value_counts(mcq_country, 'Job Title')\nfig, ax= plt.subplots(figsize=(14,7))\n\nplt.xticks(rotation=90)\nshow_bar_plot(x='Job Title' ,y= 'Percentage', data = job_title, axis = 'vertical',xlabel='Designation', ylabel='Percentage', title='Job Titles for '+country)\n\n\njob_title_row = value_counts(mcq_row, 'Job Title')\njob_title_concat = combine_row_country(job_title, job_title_row)\n","ae4113da":"pm(\"PM: Wow! About 17% of the respondents are data scientists.\")\n\nresponse(\"Me: 1. Yes, and about 15% are Software Engineers. <br> \\\n2. 33% of the respondents are students maybe in college or passed out looking for job change. <br> \\\n3. This means that in the coming years we will get more students turning into professionals who are interested in Data Science because these students started way early in their college. So the job creators need to create a lot of new jobs like Machine Learning Intern, Data Science intern to support the interest of wider public. Also Trainee Data Scientist, Jr. Data Scientist positions will pop up in future. <br><br> \\\n\u00a0But there is a negative sign in the graph. \")\n\npm(\"PM: What\u00a0?\")\nresponse(\"Me: India has just 3% research scientists.\")\npm(\"PM: What do research scientists primarily do?\")\nresponse(\"Me: They advance the state of the art in any technology.\")\npm(\"PM: So we do not have enough researchers currently. How do we do as compared to the rest of the world.?\")","61f8d7d2":"fig, ax= plt.subplots(figsize=(14,7))\nplt.xticks(rotation=90)\nshow_bar_plot(x='Job Title' ,y= 'Percentage',hue='Geography' ,data = job_title_concat, axis = 'vertical',xlabel='Designation', ylabel='Percentage', title='Job Titles for '+country+' vs ROW')\n","50f319b4":"response(\"Me: Not good.\")\npm(\"PM: So, the rest of the world has 3 times more researchers than India has. This is again a very serious issue.\")\nresponse(\"Me: Yes sir. If you compare with USA also, it is the same statistic.\")","858824fb":"job_title_compare = value_counts(mcq_country_compare, 'Job Title')\njob_title_compare = combine_row_country(job_title, job_title_compare, 'USA')\nfig, ax = plt.subplots(figsize=(15,5))\nshow_point_plot(x='Job Title' ,y= 'Percentage',hue='Geography', data = job_title_compare, title='Job Titles for '+country+' vs '+country_to_compare);\n","6bf3fe06":"pm(\"PM: Yes, and how is this affected over the years?\")\n\nresponse(\"Me: Here is the historical analysis sir\")","1a03bf42":"mcq_2017['Job Title'].unique()\n\ndict_job_title = {'Data Scientist' : 'Data Scientist', 'Software Developer\/Software Engineer': 'Software Engineer', 'Software Engineer': 'Software Engineer',\n                 'Scientist\/Researcher':'Research Scientist', 'Research Scientist':'Research Scientist','Student':'Student'}\n\n\n\njob_title_concat = combine_historical_3(mcq_country_2017, mcq_country_2018, mcq_country , 'Job Title', dict_job_title)\n\none_record = {'Job Title' : 'Student', 'Percentage' : mcq_country_2017['StudentStatus'].value_counts(normalize= True, dropna= False).reset_index().iloc[1,1]*100, 'Year': 2017}\n\ndf_one_record = pd.DataFrame(one_record, index=[0])\njob_title_concat = pd.concat([df_one_record, job_title_concat]).reset_index(drop=True)\n\nax= sns.catplot(x=\"Year\", y=\"Percentage\", aspect =0.9,  col=\"Job Title\", data=job_title_concat, col_wrap =2, sharex = False, sharey=True, kind='bar', palette=COLOR_PALETTE);\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Historical Job Title Comparison for \"+country);\n","50199d1a":"response(\"Me: Over the years, students have increased, the Software Engineers have decreased and Data Scientists have increased while research scientists have also increased not rapidly but slowly atleast.\")\npm(\"PM: So the decrease in Software Engineer roles is that people are loosing their jobs?\")\nresponse(\"Me: Not exactly sir. Since there is so much hype for Data Science and ML in the market, companies are luring people into Data Scientist roles but the popularity of Software Engineer means some companies might want Data Science in addition to some work from Software Engineering life cycle. \\\n<br><br>Also Data Science is built on top of Statistics and you can see that Statisticians have fell out of favour with the advent of Machine Learning roles. \")\npm(\"PM: Yes, but in the early chart, I could see another problem. 6% people are not employed. So I want to ask you the hard question. Has the unemployment rate increased or decreased in India?\")","c883470e":"mcq_2019_job_title = mcq_country['Job Title'].value_counts(normalize= True).reset_index()\nmcq_2019_job_title = np.squeeze( mcq_2019_job_title[mcq_2019_job_title['index'] == 'Not employed'][['Job Title']].values )\nmcq_2018_job_title = mcq_country_2018['Job Title'].value_counts(normalize= True).reset_index()\nmcq_2018_job_title = np.squeeze( mcq_2018_job_title[mcq_2018_job_title['index'] == 'Not employed'][['Job Title']].values )\nmcq_2017_job_title = mcq_country_2017['EmploymentStatus'].value_counts(normalize= True, dropna=False).reset_index()\nmcq_2017_job_title = np.squeeze( mcq_2017_job_title[mcq_2017_job_title['index'] == 'Not employed, but looking for work'][['EmploymentStatus']].values )\n\nx= ['2017', '2018', '2019']\ny = [mcq_2017_job_title * 100, mcq_2018_job_title * 100, mcq_2019_job_title* 100 ]\n\nfig, ax = plt.subplots(figsize=(8,6))\nax = sns.pointplot(x, y)\nsns.barplot(ax=ax, x=x, y=y, palette=COLOR_PALETTE)\n\nfor c in ax.collections:\n            for of in c.get_offsets():\n                #print(of[1])\n                val = str(round(of[1],2))\n                #print(val)\n                #of[1] = of[1] + 4\n                ax.annotate(val, of)\nplt.title(\"Unemployment Rate in \"+country);\nplt.xlabel('Year')\nplt.ylabel('Unemployment Rate');","76161dd6":"response(\"Me: Here are the numbers, sir\")\npm(\"PM: That's good to see. But it is not encouraging, if people with such high skills are not getting jobs then what will happen to those who have not even acquired these skills as of now. I will definitely note this down.\")","9911ed5f":"response(\"Me: Absolutely Sir, another factor that is very crucial is that where are these engineers working. I mean in big companies, startups and all.\")\npm(\"PM: Yes, I am interested in this as we have rolled out a lot of policies in Startup India and given so much tax rebates to big IT companies. So, if there is a requirement for change of any policies in these companies then we can advise them to do so.\")\nresponse(\"Me: Interesting!\")","161ef978":"## Company Size\n\ncompany_size = value_counts(mcq_country, 'Company Size')\ncompany_size_row = value_counts(mcq_row, 'Company Size')\ncompany_size_concat = combine_row_country(company_size, company_size_row)\n\nfig, ax= plt.subplots(figsize=(8,6))\nshow_bar_plot(y='Company Size' ,x= 'Percentage', data = company_size, axis = 'horizontal', xlabel='Percentage', ylabel='Strength', title='Strength of Companies')","fd283e69":"response(\"Me: Most of the people work in large organizations. Obviously they have a lot of money to burn in employee upskilling, hardware investment and wait for the right client who can give hefty compensation for that investment.\")\npm(\"PM: Hmm, most of the employers in Indian IT are service based companies like Infosys, TCS, Accenture, Wipro, HCL.\")\nresponse(\"Me: This can be a positive as well as a negative point. While service based companies are keen on investing and have money to invest, they are also very keen to shut down the investment if no returns are made in a particular time frame.\")\n\nresponse(\"Me: See this India vs ROW chart.\")","73d76dbd":"fig, ax= plt.subplots(figsize=(8,6))\nshow_bar_plot(y='Company Size' ,x= 'Percentage', hue='Geography', data = company_size_concat, axis = 'horizontal', xlabel='Percentage', ylabel='Strength', title='Strength of Companies')\n","83b86be1":"response(\"Me: As you can see 20% people from the rest of the world are working in Product Based companies with strength from 1000\u20139999. It is my assumption that this strength corresponds to a product company. <br>\\\n<br>And interestingly 30% of the techies from the rest of the world working in Data Science are engaged in early stage startups. Even India is not behind and stands at 26%. This shows that we need to support the early stage startups even more as they are creating employment in this field.\")","08fafde9":"company_size_compare = value_counts(mcq_country_compare, 'Company Size')\ncompany_size_compare = combine_row_country(company_size, company_size_compare, 'USA')\nfig, ax = plt.subplots(figsize=(15,5))\nshow_point_plot(x='Company Size' ,y= 'Percentage',hue='Geography', data = company_size_compare, title='Company Size comparison for '+country +' vs '+country_to_compare)","60a83e4c":"response(\"Me: Another factor that supports this is the fact we are ahead of USA in terms on employment in startups. About one forth of the US techies are working in Product based companies.\")","6ea28226":"map_company_size = {'Fewer than 10 employees' : 'Startup', '10 to 19 employees' : 'Startup','20 to 99 employees' : 'Startup', '0-49 employees':'Startup',\n'100 to 499 employees' : 'Mid Size Startup' , '50-249 employees' : 'Mid Size Startup' , '250-999 employees' : 'Mid Size Startup',\n '1000-9,999 employees' : 'Product Based' , '5,000 to 9,999 employees' : 'Product Based', '1,000 to 4,999 employees':'Product Based',\n '10,000 or more employees' : 'Large IT', '> 10,000 employees' : 'Large IT' }\n\ncompany_size_2017 = value_counts( map_column(mcq_country_2017.copy(), 'Company Size', map_company_size), 'Company Size')\ncompany_size_2017['Year'] = 2017\ncompany_size_2019 = value_counts( map_column(mcq_country.copy(), 'Company Size', map_company_size), 'Company Size')\ncompany_size_2019['Year'] = 2019\ncompany_size_historical = pd.concat([company_size_2017, company_size_2019])\ncompany_size_historical\nax = sns.catplot(x='Year', y='Percentage', aspect=0.9, col='Company Size', data = company_size_historical, sharex= False, col_wrap= 2, kind='bar', palette=COLOR_PALETTE)\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Historical Company Size Comparison for \"+country);\n","83bea08f":"response(\"Me: Even if you see the historical you will see a slight rise in people working in early stage startups and mid size startups. \\\nSOme of the promising startups recognized by Niti Ayog. \")\n\npm(\"PM: Absolutely, we support startups through Startup Indian Initiative, and this way people are getting jobs, investors are getting money, the government is getting support of startups to solve real life problems which is plus for everyone.\")\n\nresponse(\"Me: Absolutely! Look at the next chart, it is exciting as well.\")","0e5da2db":"company_size_2017 = map_column(mcq_country_2017.copy(), 'Company Size', map_company_size)\ncompany_size_2017['Year'] = 2017\n\ncompany_size_2019 = map_column(mcq_country.copy(), 'Company Size', map_company_size)\ncompany_size_2019['Year'] = 2019\n\ncols= ['Job Title', 'Year', 'Time', 'Company Size']\ncompany_size_historical = pd.concat([ company_size_2017[cols], company_size_2019[cols] ])\n# company_size_2019\n\ncompany_size_historical\n\ndict_job_title_company = {'Data Scientist' : 'Data Scientist', 'Software Developer\/Software Engineer': 'Software Engineer', 'Software Engineer': 'Software Engineer',\n                 'Scientist\/Researcher':'Research Scientist', 'Research Scientist':'Research Scientist'}\n\ncompany_jt_2017 = multiple_group_by(company_size_2017, ['Company Size', 'Job Title'],  map_col2=dict_job_title_company, year= 2017)\ncompany_jt_2019 = multiple_group_by(company_size_2019, ['Company Size', 'Job Title'],  map_col2=dict_job_title_company, year = 2019)\n\ncompany_jt_concat = pd.concat([company_jt_2017, company_jt_2019])\ncompany_jt_concat\n\nax = sns.catplot(x='Year', y='Percentage', hue='Job Title', aspect=0.9,col='Company Size', data = company_jt_concat, sharex= False, col_wrap= 2, kind='bar', palette=COLOR_PALETTE)\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Historical Company wise Degree Holders Comparison for \"+country);\n","0f3b648d":"response(\"Me: And another interesting fact is that most of the Data Scientists and research scientists are working in Startups only. This shows the fact the startups are AI Driven. While the Software Engineering roles are increasing in IT and Product based companies, these companies are seeing a declining trend in terms of Data Scientists being employed.\")","5b8d5852":"pm(\"PM: When you say that company is AI focused, does that means that all the people working in companies are working on AI products?\")\nresponse(\"Me: Let's see sir.\")","1e49a152":"## Individuals?\n\nindi = value_counts(mcq_country, 'Team Size')\nindi_row = value_counts(mcq_row, 'Team Size')\nindi_concat = combine_row_country(indi, indi_row)\n\nfig, ax= plt.subplots(figsize=(15,7))\nshow_bar_plot(x='Team Size' ,y= 'Percentage', hue='Geography', data = indi_concat, axis = 'vertical', title='No of Individuals repsonsible for Data Science',xlabel='Number', ylabel='Percentage')\n\nindi_compare = value_counts(mcq_country_compare, 'Team Size')\nindi_compare = combine_row_country(indi, indi_compare, 'USA')\nfig, ax = plt.subplots(figsize=(15,5))\nshow_point_plot(x='Team Size' ,y= 'Percentage',hue='Geography', data = indi_compare, title='No of Individuals repsonsible for Data Science for '+country+' vs '+country_to_compare)\n","06ee1f0f":"pm(\"PM: Great, most of the companies have dedicated teams.\")\nresponse(\"Me: Absolutely, they have a dedicated teams to ensure working in different domain sub technologies like Computer Vision, Natural Language Processing, classical machine learning.\\\n<br><br> But you see that 15% of the companies still do not have a Data Science team, which I assume will improve in coming years\")\n\npm(\"PM: So when you say companies do not have a Data Science Team so does this means they are not using Artificial Intelligence in their company or products?\")","467b3acd":"## Current Company ML?\n\ncurrent_ML = value_counts(mcq_country, column ='ML Status in Company') \ncurrent_ML_row = value_counts(mcq_row, column ='ML Status in Company') \ncurrent_ML_concat = combine_row_country(current_ML, current_ML_row)\n\ndict = {'We are exploring ML methods (and may one day put a model into production)' : 'Exploring ML methods \\n(May put a model into production one day)',\n        'We recently started using ML methods (i.e., models in production for less than 2 years)': 'Recently started using ML methods \\n(models in production < 2 years)',\n       'We have well established ML methods (i.e., models in production for more than 2 years)':'Well established ML methods \\n(models in production > 2 years)',\n       'No (we do not use ML methods)':'No, we do not use ML methods',\n       'I do not know':'No idea',\n       'We use ML methods for generating insights (but do not put working models into production)':'ML models for Generating insights \\n(but do not put working models into production)'}\n\ncurrent_ML_concat['ML Status in Company'] = current_ML_concat['ML Status in Company'].map(dict)\n\n\nfig, ax= plt.subplots(figsize=(10,6))\n\nshow_bar_plot(y='ML Status in Company' ,x= 'Percentage', hue='Geography', data = current_ML_concat, axis = 'horizontal', xlabel='Percentage', ylabel='',title='State of AI in production in '+country)\n","7eee998a":"response(\"Me: See this graphic sir. This answers your question.<br> \\\n<br>1. 11.7 % of the people don\\'t even know if ML or DL is being used in their company. This is bad, if they don\\'t even know about their company how will they advance into higher roles.<br>\\\n<br>2. 16%, I repeat 16% people have bluntly said that they do not use ML or DL in their company.  <br>\\\n<br>3. Also 22% are just exploring the capabilities of Machine Learning and have not put a model into production till Date. This means they do not have an end product ready which uses AI as of now. <br>\\\n<br>4. But all is not lost. Still 21% of the companies are using ML from past 2 years and have deployed models while the other 18% have just started and catching up. \")","651a97bf":"current_ML_compare = value_counts(mcq_country_compare, 'ML Status in Company')\ncurrent_ML_compare = combine_row_country(current_ML, current_ML_compare, 'USA')\nfig, ax = plt.subplots(figsize=(15,5))\nshow_point_plot(x='ML Status in Company' ,y= 'Percentage',hue='Geography', data = current_ML_compare, title='State of AI in '+country+' vs '+country_to_compare)","e6ffc0ca":"response(\"Me: A worrysome statistic if you compare with our competitor USA is that they have about 15% more companies who are using AI in their products or services. This shows that how early and steadily they have adopted the technology and we should also do the same. \")\n\npm(\"PM: So which are the companies that are incubating this technology more? Is it the startups or service based?\")\n\nresponse(\"Me: Here you go sir\")","9f63c815":"dict_status_ml = {'More than 10 years' : 'Experienced Well Establised Methods', '6-10 years':'Experienced Well Establised Methods', 'We have well established ML methods (i.e., models in production for more than 2 years)':'Experienced Well Establised Methods',\n'I do not know':\"Don't know\",\"Don't know\":\"Don't know\",\n  'Less than one year':'Inexperienced', '1-2 years':'Inexperienced', 'We recently started using ML methods (i.e., models in production for less than 2 years)' :'Inexperienced'     }\n\ncompany_size_2017 = map_column(mcq_country_2017.copy(), 'Company Size', map_company_size)\ncompany_size_2017['Year'] = 2017\n\ncompany_size_2019 = map_column(mcq_country.copy(), 'Company Size', map_company_size)\ncompany_size_2019['Year'] = 2019\n\ncols= ['ML Status in Company', 'Year', 'Time', 'Company Size']\n\n\ncompany_ml_2017 = multiple_group_by(company_size_2017, ['Company Size', 'ML Status in Company'],  map_col2=dict_status_ml, year= 2017)\ncompany_ml_2019 = multiple_group_by(company_size_2019, ['Company Size', 'ML Status in Company'],  map_col2=dict_status_ml, year = 2019)\n\ncompany_ml_concat = pd.concat([company_ml_2017, company_ml_2019])\ncompany_ml_concat = company_ml_concat.reset_index(drop=True)\n\nax = sns.catplot(x='Year', y='Percentage', aspect=0.8, hue='ML Status in Company', col='Company Size', data = company_ml_concat, sharex= False, col_wrap= 2, kind='bar', palette=COLOR_PALETTE)\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"State of AI according to Company Sizes for \"+country);\n","2410969d":"response(\"Me: In Large IT companies the technology has been adapted quite quickly. But this adaptation is not uniform, the inexperienced professionals have also increased. \\\n         On the other hand, in startups or product companies, experienced techies have increased which is a very good sign for us.\")\npm(\"PM: Great! How are these individuals compensated? I know as a PM, I should not have such interests, but I want to understand if people with certain skills, degrees, gender are paid differently.\")\n\nresponse(\"Me: Compensation is a million dollar question sir. And this is one reason why India is loosing so much of its talent\")\n\npm(\"PM: Are you indicating towards brain drain?\")\n\nresponse(\"Me: I will let the numbers speak for themselves sir.\")","fc55ff6b":"## Compensation\n\ncompensation = value_counts(mcq_country, 'Compensation Status')\ncompensation_row = value_counts(mcq_row, 'Compensation Status')\ncompensation_concat = combine_row_country(compensation, compensation_row)\ncompensation_concat\n\nfig, ax= plt.subplots(figsize=(8,16))\nshow_bar_plot(y='Compensation Status' ,x= 'Percentage', hue='Geography',  data = compensation_concat, axis = 'horizontal', xlabel='Percentage', ylabel='Salary Range in USD', title='Salary Range of Data Scientists in '+country)\n\ncompensation_compare = value_counts(mcq_country_compare, 'Compensation Status')\ncompensation_compare = combine_row_country(compensation, compensation_compare, 'USA')\ncompensation_compare = compensation_compare.sort_values(by='Compensation Status')\n\ns = compensation_compare['Compensation Status'].str.len().sort_values().index\ncompensation_compare = compensation_compare.reindex(s)","f835c079":"response(\"Me: <br>1. 19% ML and DS people are just doing it as an hobby as they are not employed or they are just interning given the fact we had a large number of student ratio<br>\\\n<br>2. Apart from that the salary ranges mostly from 5000-15000 USD which is not high enough even from Indian Standards. Maybe these ranges indicate the opening salary of fresh hires in digital units of some big MNC's<br>\\\n<br>3. Another popular bracket is 16000- 25000 USD which can account for people working in the Industry from past 3-5 years and might have recently adopted data science\")","f93591ff":"fig, ax = plt.subplots(figsize=(15,5))\nplt.xticks(rotation='90')\nshow_point_plot(x='Compensation Status' ,y= 'Percentage',hue='Geography', data = compensation_compare, title='Salary Ranges of '+country+' vs '+country_to_compare)","a2b1cfc3":"response(\"Me: This is a chart that is another game changer. \\\n    You can clearly see that Indian's mostly earn in the range 10,000 to 15,000 USD which is very low if you compare it to US. In US, a data Scientist earns somewhat between 100k - 150k which is almost 10 times as that of Indian salary.\")\n\npm(\"PM: Yes but the standard of living is also high in US, isn't it?\")\n    \nresponse(\"Me: Yes sir, but still more the money more people can save also\")\n\npm(\"PM: Can you please convert these compensation ranges to Indian salary?\")\n\nresponse(\"Me: Sure sir. L means Lakh (1,00,000 Indian Rupees) and C means Crore (1,00,00,000 Indian Rupees)\")","a350fb9b":"mcq_country['Compensation Status'].unique()\ndict_salary = {'Band 1: Intern Income': ['$0-999'] , \n'Band 2: 1.5L - 3.5L': ['2,000-2,999', '3,000-3,999', '1,000-1,999', '4,000-4,999' ],\n'Band 3: 3.6L - 7.7L': ['5,000-7,499', '7,500-9,999'],\n'Band 4: 7.8L - 14.2L': ['10,000-14,999', '15,000-19,999'],\n'Band 5: 14.3L - 21.3L': ['20,000-24,999', '25,000-29,999'], \n'Band 6: 21.4L - 35.6L': ['30,000-39,999', '40,000-49,999'],\n'Band 7: 35.7L - 49.8L': ['50,000-59,999', '60,000-69,999'],\n'Band 8: 49.9L - 64.1L': ['70,000-79,999', '80,000-89,999'],\n'Band 9: 64.2L - 89L': ['90,000-99,999','100,000-124,999'],\n'Band 10: 89.1L - 1.42C': ['125,000-149,999','150,000-199,999'],\n'Band 11: 1.42C - 2.1C': ['200,000-249,999','250,000-299,999'],\n'Band 12: 2.2C - 3.5C': ['300,000-500,000'],\n'Band 13: > 3.5C': ['> $500,000']}\n\nreverse_dict = {}\nfor key, value in dict_salary.items():\n    for val in value:\n        reverse_dict[val] = key\n\n        salary_2019 = map_column(mcq_country.copy(), 'Company Size', map_company_size)\nsalary_2019['Year'] = 2019\n\n#cols= ['Compensation Status', 'Year', 'Time', 'Company Size']\n#salary_2019\n\ncompany_ml_2019 = multiple_group_by(salary_2019, ['Compensation Status', 'Company Size'], map_col1=reverse_dict)\ncompany_ml_2019 =  company_ml_2019.sort_values('Compensation Status')\n\ncompany_ml_2019 = break_labels(company_ml_2019, 'Company Size')\nax = sns.catplot(x='Company Size', y='Percentage', col='Compensation Status', aspect=0.95,  data= company_ml_2019, col_wrap=2, kind='bar', sharex= False, palette=COLOR_PALETTE )\nplt.subplots_adjust(top=0.95)\nax.fig.suptitle(\"Compensation variation according to company for \"+country);\n","66e5446d":"response(\"Me: So if you see a company size wise breakup for the compensation structured in bands, you will be able to observe startups provide the most internships. While it is highly unclear due to lack of data the entire salary group for different companies, but IT companies are not the best paymasters.\")","1cdb5327":"salary_2019 = map_column(mcq_country.copy(), 'Job Title', dict_job_title_company)\nsalary_2019['Year'] = 2019\n\n#cols= ['Compensation Status', 'Year', 'Time', 'Company Size']\n#salary_2019\n\ncompany_ml_2019 = multiple_group_by(salary_2019, ['Compensation Status', 'Job Title'], map_col1=reverse_dict)\ncompany_ml_2019 =  company_ml_2019.sort_values('Percentage')\n\nax = sns.catplot(col='Job Title', x='Percentage', y='Compensation Status', aspect=0.5, height=10, data= company_ml_2019, col_wrap=3, kind='bar', sharex= False, palette=COLOR_PALETTE )\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Salary comparison according to Job Title for \"+country);\n","82134292":"response(\"Me: The salary for software engineer varies a lot. But out of Data Scientist and Research Scientists, Research Scientists have a well defined salary range.\")","0c69f4c6":"salary_2019 = map_column(mcq_country.copy(), 'Degree', map_dict)\nsalary_2019['Year'] = 2019\n\n\ncompany_ml_2019 = multiple_group_by(salary_2019, ['Compensation Status', 'Degree'], map_col1=reverse_dict)\n\nax= sns.catplot(col='Degree', x='Percentage', y='Compensation Status', aspect=0.5, height=10, data= company_ml_2019, col_wrap=3, kind='bar', sharex= False, palette=COLOR_PALETTE )\n\nplt.subplots_adjust(top=0.9)\nax.fig.suptitle(\"Salary Comparison according to degree for \"+country);","50dbb93f":"response(\"Me: If you observe from qualification perspective in terms of degree, you will observe that Bachelors are paid less on average than masters. \\\n    Masters are paid somewhat in the range 1CR-3CR. And on an average PHD's are also paid more than Masters.\")\n\npm(\"PM: I think this is very much correct and will be present all around the globe, but still I can see some outliers. Some people with bachelors are earning more than 3.5 Cr.\")\n\nresponse(\"Me: Exceptions are everywhere sir.\")\n\npm(\"PM: Exactly, nothing can stop talent. What about the gender pay gap in India?\")","2808df20":"salary_2019 = map_column(mcq_country.copy(), 'Gender', dict_gender)\nsalary_2019['Year'] = 2019\n\n\ncompany_ml_2019 = multiple_group_by(salary_2019, ['Compensation Status', 'Gender'], map_col1=reverse_dict)\ntotal_female = company_ml_2019.groupby('Gender').sum().reset_index()[['Gender', 'Time']].iloc[0,1]\ntotal_male = company_ml_2019.groupby('Gender').sum().reset_index()[['Gender', 'Time']].iloc[1,1]\n\n\ndef normalized_row(row):\n  if row['Gender'] == 'Female':\n    row['Degree_P'] = (row['Time'] \/ total_female) * 100\n  if row['Gender'] == 'Male':\n    row['Degree_P'] = (row['Time'] \/ total_male) * 100\n  return row\n\ncompany_ml_2019 = company_ml_2019.apply(normalized_row, axis=1)\nfig, ax = plt.subplots(figsize=(15,7))\nplt.xticks(rotation=90)\nshow_bar_plot('Compensation Status', 'Degree_P', hue='Gender', data=company_ml_2019, title='Salary Brackets of respondents with respect to gender', xlabel='Salary Range', ylabel='Percentage', show_percent= False);","4b8d5f55":"response(\"Me: Seeing the chart, it is very hard but still it reveals. I don't want to say this but yes, <b>There is a gender pay gap.<\/b>\")\n\npm(\"PM: At an entry level package there are a lot of females which indicates they are paid less and as the package increases the number of females reduce. Indeed another negative point. \\\nI think we have discussed enough on the personal Information. Let's talk about the investment companies are making.\")\n\nresponse(\"Me: Sir, this is a very hardware intensive field which means that a lot of money is spent on Hardware rather than software. Let's see how companies are spending money\")\n","9f9f4918":"## Money Spent\n\nmoney = value_counts(mcq_country, 'Money Spent')\nmoney_row = value_counts(mcq_row, 'Money Spent')\nmoney_concat = combine_row_country(money, money_row)\n\nfig, ax= plt.subplots(figsize=(8,6))\nplt.xticks(rotation=90)\nshow_bar_plot(x='Money Spent' ,y= 'Percentage', hue='Geography', data = money_concat, axis = 'vertical', xlabel='Money Spent', ylabel='Percentage',title='Money Spent on CC\/ML products')\n\nmoney_compare = value_counts(mcq_country_compare, 'Money Spent')\nmoney_compare = combine_row_country(money, money_compare, 'USA')\n\nfig, ax = plt.subplots(figsize=(15,5))\n#plt.xticks(rotation=90)\nshow_point_plot(x='Money Spent' ,y= 'Percentage',hue='Geography', data = money_compare)\n","8e5c1fa2":"response(\"Me: As it is clear from the graph, there is not much investment from Indian point of view. Companies are investing but not that much. <br>\\\n<br> On the other hand you can see Americans companies are making significant investment in Hardware and Cloud products. There is a gap of about 20% which needs to be filled.\")\n\npm(\"PM: Absolutely, when I talk about making smart cities in India, I often stress on the fact that our infrastructure needs to improve if we need to develop smarter roads. Same is the case here, we can't help companies in any way but through Startup India we can just consult the companies on this.\")\n\nresponse(\"Me: Absolutely Sir, which brings me to the last point in today's discussion\")\n\npm(\"PM: Go ahead! I think I have now the full knowledge on what to do, just let me know how to spread the message\")\n\nresponse(\"Me: This is exactly what my last point is. Let's look at the Media Sources and Platforms Indian students are using for AI\")\n","173442d6":"## Media Sources\nlimit = 12\n\nmedia = multiple_answers(limit, mcq_country, 'Q12_Part_', 'Media Sources')\nmedia['Percentage']= (media.Count \/  media.Count.sum()) * 100\nmedia_row = multiple_answers(limit, mcq_row, 'Q12_Part_', 'Media Sources')\nmedia_row['Percentage']= (media_row.Count \/  media_row.Count.sum()) * 100\nmedia_concat = combine_row_country(media, media_row)\n\n#media_sources\nfig, ax= plt.subplots(figsize=(8, 10))\nshow_bar_plot(y='Media Sources' ,x= 'Percentage', hue='Geography', data = media_concat, axis = 'horizontal', ylabel='Source', xlabel='Percentage', title='Data Science Media Sources')\n#media_concat\n\nmedia_compare = multiple_answers(limit, mcq_country_compare, 'Q12_Part_', 'Media Sources')\nmedia_compare['Percentage']= (media_compare.Count \/  media_compare.Count.sum()) * 100\nmedia_compare = combine_row_country(media, media_compare, 'USA')\n\n\nfig, ax= plt.subplots(figsize=(15,5))\nshow_point_plot(x='Media Sources' ,y= 'Percentage',hue='Geography', data = media_compare, title='Media Sources for '+country+' vs '+country_to_compare)\n","f14879e1":"response(\"Me: 1. So sir, Kaggle is the most preferred platform for Data Science in India.<br> \\\n2. Other Digital Media like Towards Data Science, Analytics Vidhya are preferred because of blog posts and all.\\\n         3. Apart from that youtubers like Siraj Raval also spread the work.\\\n\")\n\npm(\"PM: Great! Why don't you create your youtube channel. I feel you will get a lot of subscribers\")\n\nresponse(\"Me: Sure sir, it is work in progress as of now.\")","121add12":"## Media Sources\nlimit = 12\n\nmedia = multiple_answers(limit, mcq_country, 'Q13_Part_', 'Platforms')\nmedia['Percentage']= (media.Count \/  media.Count.sum()) * 100\nmedia_row = multiple_answers(limit, mcq_row, 'Q13_Part_', 'Platforms')\nmedia_row['Percentage']= (media_row.Count \/  media_row.Count.sum()) * 100\nmedia_concat = combine_row_country(media, media_row)\n\n#media_sources\nfig, ax= plt.subplots(figsize=(9,10))\nshow_bar_plot(y='Platforms' ,x= 'Percentage', hue='Geography', data = media_concat, axis = 'horizontal', ylabel='Source', xlabel='Percentage', title='Data Science Media Sources')\n#media_concat\n\nmedia_compare = multiple_answers(limit, mcq_country_compare, 'Q13_Part_', 'Platforms')\nmedia_compare['Percentage']= (media_compare.Count \/  media_compare.Count.sum()) * 100\nmedia_compare = combine_row_country(media, media_compare, 'USA')\n\n\nfig, ax= plt.subplots(figsize=(15,5))\nshow_point_plot(x='Platforms' ,y= 'Percentage',hue='Geography', data = media_compare, title='Data Science Sources for '+country+ 'vs '+country_to_compare)\n","18154749":"response(\"Regarding Plaforms for Data Science where students study.<br> \\\n         1. Coursera (founded by Andrew Ng) from China leads the race followed by Udemy and Datacamp <br> \\\n         2. An interesting fact in this chart is that close to 15% Americans attain knowledge from Universities as compared to 7% in India<br> \\\n         \")\n\npm(\"PM: Are there any Indian platforms that are going ahead?\")","78204fc1":"text_response = text.copy()\n#text_response = text_response[text_response['Country'] == country]\n\ntext_response['count'] = 1\ntext_response['ML_algo'] = text_response['Q13_OTHER_TEXT'].str.lower()\ntext_response\ntext_response[['ML_algo','count']].groupby('ML_algo').sum()[['count']].sort_values('count', ascending=False)\n\n# Create wordcloud\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nplt.figure(figsize=[15,8])\n\n# Create and generate a word cloud image:\nide_words = ' '.join(text_response['ML_algo'].dropna().values)\nwordcloud = WordCloud(colormap=\"tab10\",\n                      width=1200,\n                      height=480,\n                      normalize_plurals=False,\n                      background_color=\"white\",\n                      random_state=5).generate(ide_words)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","12444777":"response(\"Me: Absolutely sir, you will be so happy to know that nptel is one of the leading platforms in India\")\n\npm(\"PM: Oh yes, how could I forget National Programme on Technology Enhanced Learning.<br><br>\\\nIt an initiative by seven Indian Institutes of Technology (IIT Bombay, Delhi, Guwahati, Kanpur, Kharagpur, Madras and Roorkee) and Indian Institute of Science (IISc) for creating courses.<br><br>\\\nThis is the biggest plus point in our discussion today. Thanks for bringing this up.\")\n\nresponse(\"Me: No problem sir. But not only nptel, upgrad, applied AI course, analytics vidhya, great learning are also the preferred choices for some students\")\n\npm(\"PM: That is great.<br><br>\\\nI can't thank you enough for all this detailed analysis. I have got a lot of working points for me.\")\n\npm(\"PM: Positives: <br>\\\n1.\tYouth Percentage Increasing <br><br>\\\n2.\tRatio of girls pursuing PHD\u2019s increased by 1.5 times from 2017 <br><br>\\\n3.\tStrong Startup Presence. <br><br>\\\n4.\tStartups creating employment for young generation<br><br>\\\n5.\tNPTEL creating valuable courses <br><br>\\\n6.\tGreat startup ecosystem in Edtech space. <br><br>\\\n\\\nNegatives:<br>\\\n1.\tLack of Experienced professionals <br><br>\\\n2.\tOnly 16% females <br><br>\\\n3.\tOnly 5% PHD\u2019s <br><br>\\\n4.\tIndia has 3 times less researchers than ROW. <br><br>\\\n5.\t6% unemployment rate <br><br>\\\n6.\tLow salary as compared to other nations <br><br>\\\n7.\tGender Pay gap. <br><br>\\\n\")\n   \n","baf7be34":"response(\"Me: These are just a few points sir. I hope you will bring huge reforms in AI through your yognas.\")\npm(\"PM: Absolutely. You know India has partnerships with other nations to strengthen the country\u2019s artificial intelligence industry. These countries are Germany, Singapore, Canada, Russia, UAE, China\")\n\nresponse(\"Me: That's great sir. I wish you all the best for the new policies and reforms.\")\npm(\"PM: Anything you would like to suggest in particular?\")\nresponse(\"Me: Sir, I am waiting for a day when India will have their own minister of Artificial Intelligence and we make Self Driving Cars Legal.\")\npm(\"PM: Minister of AI as appointed by Dubai. Sure, one of the candidates has to be you for that post\" )\nresponse(\"Me: Why do you think I suggested that?\")\npm(\"PM: Haha. Thank you Harveen for all your hard work.\")\n","23c6b5b3":"## Closing Comments\n\nThank you for taking out time to read this. AI in India is in promising state but brain drain has hurt India a lot and will continue to do so if no actions are taken on time.\n\nI just want to thank myself for continuously devoting time to this kernel as I promised myself in the starting of this competition.","2208ce37":"I was just about to shake hands with PM and the alarm went off. Even though Mr. Modi was keen to make me the Minister of AI, I was more interested to become PM of India.","0e1f4901":"## 6. **Individuals For Data Science**\n\n","51f4ea25":"## 4. **Job Title:**","15441ed0":"## 3. **Degree:**","cac0cfda":"## 2. **Gender**: \n","ee3f2fc1":"**I love my mother country India, and I am trying to understand the environment India provides currently in India.**","add805c2":"## 1. **Age**: \n","353dbd11":"## Storyline\n\nA month back I started this competition. Seeing the data, I figured out so many secrets about the Data Science Landscape in India. I wanted to rush to the head of the country and explain him the next superpower in the world but ! No matter what somethings are not possible. I coded for this notebook 4 days and night straight.\n\nThis survey affected so much in my subconsious mind that in my dream, I fulfilled my dream. Hard to understand? I am here to explain. In my dream, the Prime Minister of India, Mr. Narendra Modi calls me to get some insights about the AI community in India. What happens next is a true story of what exactly happened step by step in my dream.\n\nSo let's start!\n\n![](https:\/\/images.livemint.com\/img\/2019\/08\/30\/600x338\/20190808295L_1565277936009_1567148847532.jpg)","a94ae652":"## 9. **Money Spent on Cloud Computing\/ ML Products**","5c98bc23":"## 5. **Company Size**","6b9a5602":"![](https:\/\/www.analyticsindiamag.com\/wp-content\/uploads\/2019\/01\/14creation-ai.gif)","d0c0d46b":"## 8. **Compensation**\n","67c643f3":"## 10. **Media Sources & Platforms**\n","ced50e30":"##### Data Preprocessing","d232008a":"## 7. **Current Company using ML**"}}