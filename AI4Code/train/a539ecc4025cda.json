{"cell_type":{"194bfdbd":"code","c903a608":"code","1934e60b":"code","a7efa7af":"code","23ab4146":"code","bdb4d722":"code","8f98c4a2":"code","83c1e144":"code","b24e78d4":"code","54f4f1a0":"code","9e0f4094":"code","7a0e3b67":"code","c22664fc":"code","e35da760":"code","e8818173":"code","7c8b2379":"code","c9c80981":"code","f1e5c8ae":"code","eba5576d":"code","a3234513":"code","92475862":"code","765af566":"markdown"},"source":{"194bfdbd":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os, cv2, random\nimport numpy as np\nimport pandas as pd\n%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline \n\nfrom keras.models import Sequential\nfrom keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import np_utils, to_categorical","c903a608":"path = '\/kaggle\/input\/flower-recognition\/flower_recognition\/'","1934e60b":"train_label = pd.read_csv(path + 'train.csv')\ntrain_label.head()","a7efa7af":"unique_train_label = np.unique(train_label['category'].values)\nunique_train_label","23ab4146":"plt.figure(figsize=(33, 15))\nsns.countplot(train_label['category'])\nplt.show()","bdb4d722":"# Displaying one image to check\nimg=mpimg.imread(path + 'train\/3261.jpg')\nimgplot = plt.imshow(img)\nplt.show()","8f98c4a2":"# train image names along with paths\ntrain_image_name = [path+'train\/'+str(each)+'.jpg' for each in train_label['image_id'].values.tolist()]\ntrain_image_name[:5]","83c1e144":"test_label = pd.read_csv(path + 'test.csv')\ntest_label.head()","b24e78d4":"# train image names along with paths\ntest_image_name = [path+'test\/'+str(each)+'.jpg' for each in test_label['image_id'].values.tolist()]\ntest_image_name[:5]","54f4f1a0":"# preparing data by processing images using opencv\nROWS = 64\nCOLS = 64\nCHANNELS = 1\n\ndef read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) #cv2.IMREAD_GRAYSCALE\n    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n\n\ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image.T\n        if i%2000 == 0: print('Processed {} of {}'.format(i, count))    \n    return data\n\ntrain = prep_data(train_image_name)\ntest = prep_data(test_image_name)","9e0f4094":"optimizer = RMSprop(lr=1e-4)\nobjective = 'categorical_crossentropy'\n\n\ndef flower_recognition():\n    \n    model = Sequential()\n\n    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(1, ROWS, COLS), activation='relu'))\n    model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n\n    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n    \n    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n    \n    model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n    model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n    model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n\n\n\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    \n    model.add(Dense(103, activation='softmax'))\n\n#     model.add(Activation('softmax'))\n\n    model.compile(loss=objective, optimizer='adam', metrics=['accuracy'])\n    return model\n\n\nmodel = flower_recognition()","7a0e3b67":"model.summary()","c22664fc":"labs = to_categorical(train_label['category'])","e35da760":"nb_epoch = 10\nbatch_size = 16\n\n## Callback for loss logging per epoch\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.val_losses = []\n        \n    def on_epoch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')        \n        \nhistory = LossHistory()","e8818173":"model.fit(train, labs, batch_size=batch_size, epochs=nb_epoch,\n              validation_split=0.25, verbose=1, shuffle=True, callbacks=[history, early_stopping])","7c8b2379":"predictions = model.predict(test)","c9c80981":"max(predictions[0])","f1e5c8ae":"loss = history.losses\nval_loss = history.val_losses\n\nplt.figure(figsize=(33, 15))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('VGG-16 Loss Trend')\nplt.plot(loss, 'blue', label='Training Loss')\nplt.plot(val_loss, 'green', label='Validation Loss')\nplt.xticks(range(0, nb_epoch)[0::2])\nplt.legend()\nplt.show()","eba5576d":"predicted = []\nfor i in range(len(predictions)):\n    predicted.append(np.argmax(predictions[i]))","a3234513":"test_label['category'] = predicted\ntest_label.head()","92475862":"test_label.to_csv('test_submission.csv', index=False)","765af566":"### Creating VGG 16 model for training it on male and female data"}}