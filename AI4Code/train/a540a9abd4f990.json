{"cell_type":{"28e51107":"code","0b496c2a":"code","a469bfe5":"code","5d92420f":"code","678561b7":"code","3d80aee4":"code","6d116081":"code","855c6f4d":"code","afc62cf3":"code","96386f20":"code","f24ee61d":"code","8fddad1b":"code","e5eb5dc8":"code","5474ac80":"code","7563c5d7":"code","cd2f3e07":"code","6cd48c7c":"code","8d8151cf":"code","ef81f6ff":"code","70f3fdaf":"code","a250fcd5":"code","1ce33d83":"code","d86eef22":"code","101a4de0":"code","cfa2d331":"markdown","9d861d7f":"markdown","cf58385d":"markdown","f83372c7":"markdown","47848448":"markdown","dc493b21":"markdown","7cf57d16":"markdown","1e57289e":"markdown","2ee2c977":"markdown","16a41a6f":"markdown","9d0cc85c":"markdown","a6039213":"markdown","a5b81278":"markdown","fe1a6486":"markdown","62c31f66":"markdown","6fb4030f":"markdown","c687dd4b":"markdown","24001a9e":"markdown","4c73bcb4":"markdown","70c8789c":"markdown","aed2aa9a":"markdown"},"source":{"28e51107":"import pandas as pd\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()","0b496c2a":"# Read the file as a DataFrame\nfile_path = '..\/input\/mobile-games-ab-testing\/cookie_cats.csv'\ndf = pd.read_csv(file_path)\ndf.head()","a469bfe5":"# See the info of df\ndf.info()","5d92420f":"# Turn the data type of the version column to \"category\"\ndf['version'] = df['version'].astype('category')\ndf['version'].dtype","678561b7":"# Create a frequency table by version\nfreq_by_ver = df['version'].value_counts(ascending=True)\nfreq_by_ver","3d80aee4":"# Plot a countplot(barplot) of versions\nax = sns.countplot(x=df['version'], order=freq_by_ver.index)\n\n# Label the bars\nabs_values = freq_by_ver.values\nperc_values = round((freq_by_ver \/ freq_by_ver.sum()) * 100, 2).values\nlabels = [f'{item[0]} ({item[1]}%)' for item in zip(abs_values, perc_values)]\n\nax.bar_label(container=ax.containers[0], labels=labels)\n\n# Label the chart\nax.set_title('Number of records by version', size=18)\nax.set_xlabel('Version')\nax.set_ylabel('Count')","6d116081":"df['sum_gamerounds'].describe()","855c6f4d":"plt.plot(df['sum_gamerounds'])\nprint(df['sum_gamerounds'].nlargest(10))","afc62cf3":"df = df[df['sum_gamerounds'] < df['sum_gamerounds'].max()]\nplt.plot(df['sum_gamerounds'])\ndf['sum_gamerounds'].describe()","96386f20":"def ecdf(data):\n    \"\"\"Generate the ecdf data points from data\"\"\"\n    \n    # Get the length of the data\n    n = len(data)\n    # Sort the data point: x\n    x = np.sort(data)\n    # Generate an array of evenly divided points between 0 and 1\n    y = np.arange(1, n+1) \/ n\n    \n    return x, y","f24ee61d":"# Generate the ecdf data points for plotting\nrounds = df['sum_gamerounds']\nx, y = ecdf(rounds)\n\n# plot the ecdf\nplt.figure(figsize=(10, 6))\n_ = plt.plot(x, y, marker='.', linestyle='none')\n\n# label the graph\nxlabel = 'Total number of game rounds'\nylabel = 'ECDF'\ntitle = 'ECDF of the total number of game rounds'\n_ = plt.xlabel(xlabel)\n_ = plt.ylabel(ylabel)\n_ = plt.title(title, size=18)\n\n# Annotate a data point for explanation\nplt.annotate(text='(500, 0.99)', xy=(500, 0.99), xytext=(500, 0.9), color='r', arrowprops={'arrowstyle':'fancy', 'color':'r'})","8fddad1b":"rounds_to_see = [0, 3, 5, 10, 20, 29, 30, 39, 40, 70, 100, 500]\nprob_list = []\nfor game_round in rounds_to_see:\n    prob_list.append(round(y[(x <= game_round).sum() - 1] * 100 , 2))\n\nrounds_df = pd.DataFrame(prob_list, index=rounds_to_see, columns=['Percentage'])\nprint(rounds_df)","e5eb5dc8":"rounds_diff = rounds_df - rounds_df.shift(1).fillna(0)\nrounds_diff['Percentage'] = rounds_diff['Percentage'].map(lambda x: round(x, 2))\nprint(rounds_diff)","5474ac80":"# Create subplots for plotting\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Get labels for bar charts \nlabels = list(rounds_df.index.map(str))\nbase = rounds_df.shift(1).fillna(0)['Percentage'].values\nincrease = rounds_diff['Percentage'].values\n# Plot the stacked bar chart\nax.bar(labels, base , label='base', color='r', alpha=0.5)\nax.bar(labels, increase, bottom=base, label='increase', color='r')\n\n# Label the chart\nax.bar_label(container=ax.containers[1], labels=rounds_df['Percentage'], size=16)\nax.bar_label(container=ax.containers[1], labels=rounds_diff['Percentage'], label_type='center', size=12)\nax.set_title('Cumulative percentage of the amount of players till certain levels\/rounds', size= 20)\nax.set_xlabel('Level\/round', size=16)\nax.set_ylabel('Percentage of players (%)', size=16)\nax.legend(fontsize='x-large')","7563c5d7":"# Generate a round counts frequency table by version\nrounds_by_ver = df.groupby('version')['sum_gamerounds'].value_counts(normalize=True, sort=False)\n\n# Calculate cumulative sum for each version\nrounds_by_ver = rounds_by_ver.groupby(level=0).cumsum()\n\n# Filter out levels later than 30 for the \"gate_30\" version and later than 40 for the other version\nrounds_by_ver = rounds_by_ver.reset_index(name='proportion')\nrounds_by_ver = rounds_by_ver.query('(version==\"gate_30\" & sum_gamerounds<=50) | (version==\"gate_40\" & sum_gamerounds<=50)')\n\n# Plot a side-by-side bar chart\nplt.figure(figsize=(16, 9))\nsns.barplot(data=rounds_by_ver, x='sum_gamerounds', y='proportion', hue='version')\n\n# Label the chart\nplt.xlabel('Level\/round')\nplt.ylabel('Proportion')\nplt.title('Cumulative proportion of the amount of players by levels and by version', size= 20)\nplt.legend(fontsize='x-large')\n\n# Annotate an interesting bar\nplt.annotate(text='gate_30 surpasses gate_40', \n             xy=(39, 0.7), \n             xytext=(35, 0.75), \n             color='r', \n             arrowprops={'arrowstyle':'fancy', 'color':'r'})","cd2f3e07":"df.groupby(['version'])['retention_1', 'retention_7'].mean()","6cd48c7c":"pd.DataFrame(df.groupby(['retention_1', 'retention_7'])['userid'].count()\/ len(df))","8d8151cf":"def permutation_sample(data1, data2):\n    \"\"\"Generate a permutation sample from two datasets\"\"\"\n    \n    # Concatenate the datasets: data\n    data = np.concatenate((data1, data2))\n    \n    # Permute the data: permuted_data\n    permuated_data = np.random.permutation(data)\n    \n    # Split the permuted_data into two: perm_sample_1 and perm_sample_2\n    perm_sample_1 = permuated_data[:len(data1)]\n    perm_sample_2 = permuated_data[len(data1):]\n    \n    return perm_sample_1, perm_sample_2","ef81f6ff":"def draw_perm_reps(data_1, data_2, func, size=1):\n    \"\"\"Generate multiple permutation replicates.\"\"\"\n\n    # Initialize array of replicates: perm_replicates\n    perm_replicates = np.empty(size)\n\n    for i in range(size):\n        # Generate permutation sample\n        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n\n        # Compute the test statistic\n        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n\n    return perm_replicates","70f3fdaf":"def diff_of_means(data_1, data_2):\n    \"\"\"Difference in means of two arrays.\"\"\"\n\n    # The difference of means of data_1, data_2: diff\n    diff = np.mean(data_1) - np.mean(data_2)\n\n    return diff","a250fcd5":"# Get both the retention data of \"gate_30\" and \"gate_40\"\ngate30 = df[df['version']=='gate_30']['retention_1']\ngate40 = df[df['version']=='gate_40']['retention_1']\n\n# Compute difference of mean impact force from experiment: empirical_diff_means\nempirical_diff_means = diff_of_means(gate30, gate40)\n\n# Draw 10,000 permutation replicates: perm_replicates\nperm_replicates = draw_perm_reps(gate30, gate40,\n                                 diff_of_means, size=10000)\n\n# Compute p-value: p\np = np.sum(perm_replicates >= empirical_diff_means) \/ len(perm_replicates)\n\n# Print the result\nprint('p-value =', p)","1ce33d83":"# Visualize the simulation result\nplt.figure(figsize=(16, 8))\nsns.distplot(perm_replicates, norm_hist=True, bins=100)\n\n# Label the chart\nplt.xlabel('Difference of rentention rate between 30-version and 40-version', size=16)\nplt.ylabel('PDF', size=16)\nplt.title('Day-1 Retention rate difference under null hypothesis', size=22)\nplt.axvline(x=empirical_diff_means, color='r')\nplt.annotate(text='p-value', \n             xy=(0.008, 5), \n             xytext=(0.010, 15), \n             color='r', \n             size=20,\n             arrowprops={'arrowstyle':'fancy', 'color':'r'})","d86eef22":"# Get both the retention data of \"gate_30\" and \"gate_40\"\ngate30 = df[df['version']=='gate_30']['retention_7']\ngate40 = df[df['version']=='gate_40']['retention_7']\n\n# Compute difference of mean impact force from experiment: empirical_diff_means\nempirical_diff_means = diff_of_means(gate30, gate40)\n\n# Draw 10,000 permutation replicates: perm_replicates\nperm_replicates = draw_perm_reps(gate30, gate40,\n                                 diff_of_means, size=10000)\n\n# Compute p-value: p\np = np.sum(perm_replicates >= empirical_diff_means) \/ len(perm_replicates)\n\n# Print the result\nprint('p-value =', p)","101a4de0":"# Visualize the simulation result\nplt.figure(figsize=(16, 8))\nsns.distplot(perm_replicates, norm_hist=True, bins=100)\n\n# Label the chart\nplt.xlabel('Difference of rentention rate between 30-version and 40-version', size=16)\nplt.ylabel('PDF', size=16)\nplt.title('Day-7 Retention rate difference under null hypothesis', size=22)\nplt.axvline(x=empirical_diff_means, color='r')\nplt.annotate(text='p-value', \n             xy=(0.009, 1), \n             xytext=(0.009, 15), \n             color='r', \n             size=20,\n             arrowprops={'arrowstyle':'fancy', 'color':'r'})","cfa2d331":"# Define the Business Problem\n## Project description\nCookie Cats is a hugely popular mobile puzzle game developed by Tactile Entertainment. It's a classic \"connect three\" style puzzle game where the player must connect tiles of the same color in order to clear the board and win the level. It also features singing cats. We're not kidding!\n\nAs players progress through the game they will encounter gates that force them to wait some time before they can progress or make an in-app purchase. In this project, we will analyze the result of an A\/B test where the first gate in Cookie Cats was moved from **level 30 to level 40**. In particular, we will analyze the impact on **player retention**. ([Datacamp](https:\/\/app.datacamp.com\/learn\/projects\/184))\n## Problem Definition\n> Did the change made on the position of the gate affect the player retention rate?","9d861d7f":"![image.png](attachment:image.png)\n_source: [Tectile Games](https:\/\/tactilegames.com\/cookie-cats\/)_","cf58385d":"# Infer from the results and give business recommendations\nThe two NHSTs above rejected the null hypothesis under assumption of normal distribution.\n\nSo,, we can be sure that both the day-1 retention rate and the day-7 retention rate are higher when the gate is at level 30 than at level 40. \n\nAll in all, answering to the business problem we defined earlier, the conclusion is:\n> If the key metric is retention rate, meaning that we want high retention rate, we should **not** move the gate from level 30 to level 40.\n\nFurthermore, we might be want to ask why the gate_30 version has a higher retention rate, because, intuitively, we think that the later the obstacle, the longer the players would play the game. One explanation could be __hedonic adaption__. According to [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Hedonic_treadmill):\n> Hedonic adaptation is a process or mechanism that reduces the affective impact of emotional events. Generally, hedonic adaptation involves a happiness \"set point\", whereby humans generally maintain a constant level of happiness throughout their lives, despite events that occur in their environment. The process of hedonic adaptation is often conceptualized as a treadmill, since no matter how hard one tries to gain an increase in happiness, one will remain in the same place.\n\nBased on this, we can say that because players will get more and more tired of the game if they play it continously. As a result, the gate serves as a forceful stop to the gaming session and resets the \"tireness bar\". Thus, the enjoyment is then prolonged. But when the gate is moved to level 40, fewer players make it far enough, and they are more likely to quit the game because they simply got bored of it.","f83372c7":"From this chart, we identify several issues that we might be interested in:\n1. Around __4.43%__ of the players did not finish even one game round, and we might want to ask:\n    - did they encounter any problem when they are playing the game (e.g. game crashes\/ malfuncting in-game UIs...)\n    - did their data have problems finding their way in our database (maybe some of them downloaded the game and never connected to the internet again)\n    - did they find Cookie Cats boring and chose not to play it? If so, why? Furthermore, why did they download it at the first place? Does that mean we are recruiting the wrong types of players?\n\n\n2. Around __20%__ of the players played __no more than 3 rounds__ and around __40%__ stopped before __level 11__. If a round of a game takes 3 minutes to finish on average, it means we lose __20%__ of the players after they play the game for __9 minutes__ and __40%__ of them after __30 minutes__ averagely. This is alarming and we might be suspecting that:\n    - The tutorial does not provide good-enough instructions, so players get confused and leave early.\n    - The overall level design of the entry-levels is not attrative enough, so players find it repetitive and quit.\n    - The game crashes constantly before the players can go any further.\n\n\n3. Over __63%__ of the players did not reach __level 30 or higher__, so we would like to ask:\n    - what made them stop beforing reaching the first gate (at least in the \"gate_30\" version)?\n    - is this churn rate what we are expecting? If not, what can we do to improve?\n    - how does this affect our A\/B tests?\n\n\nThese questions are good starting points for further investigations that might lead to improvements of Cookie Cats, and we surely have to collaborate with teams to carry on any further actions. \n\nFollowing, we zoom in on the \"gates\" to understand what usually happened when players reach their gates.","47848448":"- The __uninterested__: the players who did not come back on day-1 and also did not comback on day-7 are half of the samples. \n- The __come-back-later__: the cases mentioned above only account for around 4%\n- The __come-and-go__: the players who came back on day-1 but not on day-7 are around 30% of the samples.\n- The __long-stayed__: the players who are relatively interested in the game count for around 15%","dc493b21":"# Summary\nThis notebook analyzes the data form an A\/B test conducted on Cookie Cats, a mobile connect-three-style puzzle game. The null hypothesis significance tests show the original version has better retention rates than the tested version does. The notebook is written in Python and the libraries used are __Pandas__, __Numpy__, __Matplotlib__, and __Seaborn__.","7cf57d16":"Seeing the p-value is lower than 0.001, which is extremely small. We can be very confident to say the difference between the retention rates is real and that gate_30 version has indeed better day-7 retention rate than gate_40 version does.","1e57289e":"# Conduct Exploratory Data Analysis (EDA)\nLet's start by examining the graph of the empirical cumulative distribution function of \"sum_gamerounds\" to have a glimpse of player behavior. We start by defining several functions that will be used repetitively later.","2ee2c977":"# Simulate the hypothesis\n## Permutation\nHere, we use simple permutation techniques to simulate the null hypothesis to see what the data would look if the day-1 retention rates for each version are identical. ","16a41a6f":"# Work Flow\n1. Define the business problem\n2. Detect potential problems (e.g. outliers, missing values, out-of-range\/categoory date, etc.) and fix them\n3. Conduct Exploratory Data Analysis (EDA)\n4. Formulate Hypothesis\n5. Simulate the hypothesis\n6. Infer from the results and give business recommendations","9d0cc85c":"The p-value is around 0.038, and this tells us:\n> The probabitlity of obtaining of a value of the test statistic that is **at least as extreme** as what we observed in the empirical data, **under the assumption that the null hypothesis is true**, is around 0.0368.\n\n_Note: The p-value has nothing to do with the probabiltiy that the null hypothesis is true._\n\nThe p-value is relatively small, so we might reasonably believe that a difference between the retention rates of the 2 versions is real. Since the empirical difference is positive, we can reasonably decide that the gate_30 version has a better day-1 retention rate than gate_40 version does.\n\nLet's now walk through the same flow again, but we use the day-7 retention instead.","a6039213":"The numbers of records in each of the two groups are almost equal. \n\nFollowing, we proceed to examine the summary statistics of the \"sum_gamerounds\" column.\n## Outliers in Game Rounds","a5b81278":"The day-1 retention rate, which means the proportion of players who came back to play the game one day after the installation, was around 45% fo both veriosn, and the day-7 retention rate was around 19%. The is quite alarming because it means, on average, we lost over an half of the player one day after they installed the game. Although the players who did not play the game on day-1 could come back to play again days after, the chance is pretty rare. We can actually see it through the following frequecy table.\n\n_Note: day-0 is the day when the player install and the game_","fe1a6486":"# Detect and Fix Potential Problems\n## Preparation","62c31f66":"- It seems that there is no missing value presented in the dataset.\n- Since there are only 2 unique values in the version column, we can transform the data type of this column to \"category\"\n\n## Counts by Version","6fb4030f":"Seems like there is an outlier value as high as 49854, and the number is so high that it dwarfs all the other values. This could be caused by:\n- an error resulted from manual data key-in processes \n- problematic data aggregations from multiple sources\n- cheating behaviors from the player side\n- the hard-work a relentlessly hardcore player\n- or else!\n\nWe definitely need to work with the product\/engineer team to further investigate the problem. For now, it would be easier to just delete this record.","c687dd4b":"Let's now take a look at the record counts by version","24001a9e":"An easy way to understand this graph is to think that each date point indicates the percentage of players who played less than or equal to the rounds of that point. For example, if game rounds = 500, we can see the corresponding y value is around 0.99. This means that 99% of the players in the dataset played less than or equal to 500 rounds.\nWe can further use ecdf to understand more about the player behavior by see the corresponding values of different Xs.","4c73bcb4":"# Formulate Hypothesis\n> Hypothesis testing is about testing how reasonable the observed data is, assuming the hypothesis is true.\n## The pipeline for hypothesis testing\n- Clearly state the null hypothesis\n- Define the test statistic\n- Generate many sets of simulated data assuming the null hypothesis is true\n- Compute the test statistic for each simulated data set\n- The p-value is the fraction of the simulated data sets for which the test statistic is at least as extreme as for the real data\n\n\nFollowing, we are going to conduct an null hypothesis significance test (NHST) to see if there is truly a retention rate difference between the two versions. First, we need to state the null hypothesis, which is the hypothesis that this A\/B test tests against. \n> The null hypothesis is that there is no siginificant difference on the retention rate between the two versions.\n\nSo, the test statistics is the difference in the retention rate, which happens to be the mean of the boolean data.","70c8789c":"# Mobile Game In-game Data Analysis: A\/B Testing on Retention Rate with Cookie Cats","aed2aa9a":"From this chart, we observe that before level 30, the proportion of players for the _gate_30_ version is lower than the the one for the _gate_40_ version. In between level 30 to level 40, the gap closes in and the former surpasses the latter, as annotated in the chart. This is quite interesting and we may suspect that:\n> Setting the gate at level 30 is better at retaining the players becasue, compared to the _gate_40_ data, there are more propotions of players who reached higher levels after the gate. However, we need to be cautious about establishing any conclusion simply based on this information.\n\nWe need to look at the retention rates to better formulate ideas about which version is better."}}