{"cell_type":{"2146e559":"code","fdd602ce":"code","bf5afb24":"code","9ea4215d":"code","0239c3ad":"code","98af2ce8":"code","9856d57e":"code","df20a8f6":"code","f2cd8574":"code","8b32cd50":"code","e2649e4d":"code","9e65fb52":"code","a3cd8c3c":"code","59c58b38":"code","1f7b24a7":"code","7c2a75ba":"code","a4f606ed":"code","2fcf5f9f":"code","286ee3f9":"code","d928a68f":"code","4c392218":"code","96ae6544":"code","5ca0d95c":"code","25fc4d7a":"code","fddb985e":"code","b74a5e24":"code","0191b78c":"code","f7812120":"code","b47d666a":"code","68f804d8":"code","f43d75ba":"code","d5ca4833":"code","313c94cb":"code","677fdad0":"code","82f694a1":"code","b32e35c6":"code","ec0f2441":"code","d87f4dcb":"code","45c22739":"code","499e7eac":"code","22b6f3ba":"code","931d6dbe":"code","60d2ead9":"code","c0195f5b":"code","1529ed0c":"code","653aa91f":"code","63c4e442":"code","c840fd3e":"code","212b1e11":"code","10a8c2de":"markdown","27573976":"markdown","4ed38ff0":"markdown","db44586a":"markdown","38bc51cc":"markdown","92d82f12":"markdown","05ed9220":"markdown","0356e71a":"markdown","4499bbfa":"markdown"},"source":{"2146e559":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fdd602ce":"titanic_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nprint(titanic_data.head())\ntitanic_data.info()# <\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043e\u0431\u0449\u0435\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 titanic_data>\ntitanic_data.isnull().sum()# <\u0441\u0443\u043c\u043c\u0430\u0440\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432, \u0432\u044b\u044f\u0432\u043b\u0435\u043d\u043d\u044b\u0445 \u043c\u0435\u0442\u043e\u0434\u043e\u043c isnull() \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 titanic_data>\ntitanic_data.duplicated().sum()# <\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u0443\u043c\u043c\u0430\u0440\u043d\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0434\u0443\u0431\u043b\u0438\u043a\u0430\u0442\u043e\u0432 \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 titanic_data>\ntitanic_data.describe()#\u043e\u043f\u0438\u0441\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0430 (five-summary statistics)","bf5afb24":"# \u0421\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435 \u0432\u0441\u0435\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\npair_plot = sns.PairGrid(titanic_data)\npair_plot.map(plt.scatter)","9ea4215d":"#\u043c\u043e\u0436\u0435\u043c \u0443\u0431\u0440\u0430\u0442\u044c \u0441\u043b\u0438\u0448\u043a\u043e\u043c \"\u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435\" \u0434\u0430\u043d\u043d\u044b\u0435\ntitanic_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1, inplace = True)","0239c3ad":"# \u0421\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435 \u043e\u0442\u043e\u0431\u0440\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0439 \u043c\u043e\u043c\u0435\u043d\u0442 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\npair_plot_2 = sns.PairGrid(titanic_data)\npair_plot_2.map(plt.scatter)","98af2ce8":"#\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043f\u043e\u0431\u043b\u0438\u0436\u0435\nsns.jointplot(x = 'Age', y = 'Fare', data = titanic_data)\nsns.jointplot(x = 'Age', y = 'Survived', data = titanic_data)\nsns.jointplot(x = 'Fare', y = 'Survived', data = titanic_data)","9856d57e":"#\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u0440\u0435\u0434\u0438 \u0432\u044b\u0436\u0438\u0432\u0448\u0438\u0445 \u043c\u0443\u0436\u0447\u0438\u043d \u0438 \u0436\u0435\u043d\u0449\u0438\u043d\nsns.catplot(x = 'Sex', col = 'Survived', kind = 'count', data = titanic_data)","df20a8f6":"#\u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0441\u0432\u043e\u0434\u043d\u044b\u0435 \u0442\u0430\u0431\u043b\u0438\u0446\u044b (\u0442\u0430\u0431\u043b\u0438\u0446\u044b \u0441\u043e\u043f\u0440\u044f\u0436\u0435\u043d\u043d\u043e\u0441\u0442\u0438)\npd.crosstab(titanic_data['Embarked'], titanic_data['Survived'], margins = True).style.background_gradient()","f2cd8574":"#\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u043e\u0433\u043e, \u043a\u0430\u043a \u043c\u0435\u043d\u044f\u043b\u0430\u0441\u044c \u0434\u043e\u043b\u044f \u0432\u0438\u0436\u0438\u0432\u0448\u0438\u0445 \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043f\u043e\u043b\u0430\nsns.catplot('Sex', 'Survived', kind = 'point', data = titanic_data)","8b32cd50":"pd.crosstab([titanic_data.Sex, titanic_data.Survived], titanic_data.Age, margins = True).style.background_gradient()","e2649e4d":"#\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0444\u043e\u0440\u043c\u0443 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e violinplot\nsns.violinplot(titanic_data['Fare'])","9e65fb52":"sns.violinplot(titanic_data['Age'])","a3cd8c3c":"# \u0421\u0442\u0440\u043e\u0438\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u043c\u0430\u0442\u0440\u0438\u0446\u0443 (SibSp Parch Age and Fare values) and Survived \ntitanic_data_new = titanic_data.copy()\ntitanic_data_new['Sex'] = titanic_data_new['Sex'].map({'female': 0, 'male': 1})\ntitanic_data_new['Embarked'] = titanic_data_new['Embarked'].map({'S': 0, 'C': 1, 'Q' : 2})\nsns.heatmap(titanic_data_new[[\"Survived\", \"Sex\",\"SibSp\",\"Parch\",\"Age\",\"Fare\", 'Embarked']].corr(),annot=True, cmap = \"coolwarm\")","59c58b38":"#\u041f\u043e\u043b\u0435\u0437\u043d\u0430\u044f \u0432\u0435\u0449\u044c!!!\nfrom pandas_profiling import ProfileReport\nprofile = ProfileReport(titanic_data, title = 'Pandas Profiling Report')\nprofile","1f7b24a7":"print(titanic_data[titanic_data['Embarked'].isnull()])\n#Stone, Mrs. George Nelson (Martha Evelyn) \n#Mrs Stone boarded the Titanic in Southampton on 10 April 1912 \n#and was travelling in first class with her maid Amelie Icard. \n#She occupied cabin B-28. https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html\n#Miss Rose Am\u00e9lie Icard, 38, was born in Vaucluse, France on 31 October 1872, her father Marc Icard lived at Mafs \u00e1 Murs (?).\n#She boarded the Titanic at Southampton as maid to Mrs George Nelson Stone.\n#She travelled on Mrs Stone's ticket (#113572).\ntitanic_data[titanic_data['PassengerId'] == 62] = titanic_data[titanic_data['PassengerId'] == 62].fillna('S')\ntitanic_data[titanic_data['PassengerId'] == 830] = titanic_data[titanic_data['PassengerId'] == 830].fillna('S')","7c2a75ba":"#\u0443\u0434\u0430\u043b\u044f\u0435\u043c \u043b\u0438\u0448\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435(\u0441\u0442\u043e\u043b\u0431\u0446\u044b)\nX_train = titanic_data.drop(['PassengerId','Name','Ticket','Cabin'], axis = 1)#\u043f\u043e\u043a\u0430 \u043d\u0435 \u0441\u043e\u0432\u0441\u0435\u043c X_train\n#\u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430\nprint(X_train.isnull().sum())\n# <\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u0443\u043c\u043c\u0430\u0440\u043d\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0434\u0443\u0431\u043b\u0438\u043a\u0430\u0442\u043e\u0432 \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 X_train>\nY_train = X_train['Survived']\nX_train = X_train.drop('Survived', axis = 1)","a4f606ed":"#\u0443\u0434\u043e\u0441\u0442\u043e\u0432\u0435\u0440\u0438\u043c\u0441\u044f, \u0447\u0442\u043e \u043b\u0438\u0448\u043d\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u0442 (3 \u043d\u0435 \u0434\u0430\u043d\u043e, \u043f\u043e \u043a\u0440\u0430\u0439\u043d\u0435\u0439 \u043c\u0435\u0440\u0435, \u0432 \u0442\u043e\u0442 \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0442\u0430\u043a \u0431\u044b\u043b\u043e)\nprint(X_train['Sex'].unique())\n#\u041f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u043c \u0432 \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0434\u043b\u044f \u0443\u0434\u043e\u0431\u0441\u0442\u0432\u0430 \"\u0441\u043a\u0430\u0440\u043c\u043b\u0438\u0432\u0430\u043d\u0438\u044f\" \u043c\u043e\u0434\u0435\u043b\u044f\u043c, \u043f\u0443\u0441\u0442\u044c male = 1, female = 0\ndef find_sex_and_replace(table):\n    table['Sex'] = table['Sex'].map({'female': 0, 'male': 1})\n    return table[(table['Sex'] == 'male') | (table['Sex'] == 'female')]['Sex'].count()\nprint(find_sex_and_replace(X_train))\nX_train.head()","2fcf5f9f":"#\u0442\u043e \u0436\u0435 \u0441\u0430\u043c\u043e\u0435 \u0434\u0435\u043b\u0430\u0435\u043c \u0434\u043b\u044f Embarked\nX_train['Embarked'].unique()","286ee3f9":"def find_Embarked_and_replace(table):\n    '''# one-hot encoding\n    table = pd.concat([table, pd.get_dummies(data = table['Embarked'], prefix=\"Embarked\")], axis=1)\n    table = table.drop(['Embarked'], axis = 1)'''\n    table.loc[table['Embarked'] == 'S','Embarked'] = 0\n    table.loc[table['Embarked'] == 'C','Embarked'] = 1\n    table.loc[table['Embarked'] == 'Q','Embarked'] = 2\n    return table\nX_train = find_Embarked_and_replace(X_train)\nX_train.head()","d928a68f":"#\u043e\u0441\u0442\u0430\u043b\u043e\u0441\u044c \u0440\u0430\u0437\u043e\u0431\u0440\u0430\u0442\u044c\u0441\u044f \u0441 Age, \u0434\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u044d\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0435\nsns.distplot(X_train['Age'], kde=False, bins=20)","4c392218":"#\u043f\u043e\u0441\u0442\u0440\u043e\u0438\u043c boxplot, \u0431\u043e\u043b\u0435\u0435 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0432\u043d\u044b\u0439 \u0433\u0440\u0430\u0444\u0438\u043a\nsns.boxplot(data=X_train['Age'])\n#\u0442\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u043c\u043e\u0436\u043d\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0435 \u043d\u0430 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \n#\u0432 \u0438\u043d\u0442\u0435\u0440\u0432\u0430\u043b\u0435 std +- sigma (\u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u0442\u0430\u043a), \u0447\u0442\u043e\u0431\u044b \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043d\u0435 \u0441\u0438\u043b\u044c\u043d\u043e \u0441\u043c\u0435\u0441\u0442\u0438\u043b\u043e\u0441\u044c","96ae6544":"'''X_median = X_train['Age'].median()\nX_mean = int(X_train['Age'].mean(axis=0))\nX_std = int(X_train['Age'].std(axis=0))\np = np.linspace(0, 1, num = int(2*X_std))\np \/= p.sum() # \u0438\u0437-\u0437\u0430 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0439 \u0435\u0434\u0438\u043d\u0438\u0446\u044b \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u044c\nX_train['Age'] = X_train['Age'].fillna(np.random.choice(np.arange(X_mean - X_std, X_mean + X_std, 1), p = p))\nsns.boxplot(data = X_train['Age'])\nprint('\u0421\u0442\u0430\u0440\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043c\u0435\u0434\u0438\u0430\u043d\u044b: {},\\n\u041d\u043e\u0432\u043e\u0435: {}'.format(X_median, X_train['Age'].median()))'''\n#\u0437\u0430\u043c\u0435\u0442\u0438\u043c, \u0447\u0442\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u0435\u043f\u0435\u0440\u044c \u0437\u0430 \u043f\u0440\u0435\u0434\u0435\u043b\u0430\u043c\u0438 1.5 \u043c\u0435\u0436\u043a\u0432\u0430\u043d\u0442\u0438\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0430\u0445\u0430 \u0438\u043c\u0435\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\nX_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())","5ca0d95c":"#\u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c, \u0447\u0442\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c\nX_train.info()\n# \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u043c \u0432\u043e\u0437\u0440\u0430\u0441\u0442 \u0432 \u0446\u0435\u043b\u043e\u0435 \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0438 \u0431\u044b\u0441\u0442\u0440\u0435\u0435\nX_train = X_train.astype({\"Age\": int, \"Fare\": int})","25fc4d7a":"#\u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0434\u0440\u0443\u0433\u0438\u0435 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438\nX_train.head()\nsns.distplot(X_train['Fare'], kde=False, bins=100)\n#\u0432\u0438\u0434\u043d\u044b \u043f\u043e\u0434\u043e\u0437\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u043f\u043e\u043c\u0435\u0448\u0430\u0442\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\n#\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u044c \u043f\u043e \u0433\u0440\u0443\u043f\u043f\u0430\u043c Fare \u0438 Age\n\ndef convert_to_fare_category(table): \n    table.loc[table['Fare'] <= 10,'Fare'] = 1\n    table.loc[((table['Fare'] > 10) & (table['Fare'] <= 25)),'Fare'] = 2\n    table.loc[((table['Fare'] > 25) & (table['Fare'] <= 50)),'Fare'] = 3\n    table.loc[((table['Fare'] > 50) & (table['Fare'] <= 75)),'Fare'] = 4\n    table.loc[((table['Fare'] > 75) & (table['Fare'] <= 100)),'Fare'] = 5\n    table.loc[(table['Fare'] > 100),'Fare'] = 6\n    \n    return table\n\ndef convert_to_age_category(table):\n    table.loc[table['Age'] <= 15, 'Age'] = 0\n    table.loc[((table['Age'] > 15) & (table['Age'] <= 20)), 'Age'] = 1\n    table.loc[((table['Age'] > 20) & (table['Age'] <= 26)), 'Age'] = 2\n    table.loc[((table['Age'] > 26) & (table['Age'] <= 28)), 'Age'] = 3\n    table.loc[((table['Age'] > 28) & (table['Age'] <= 35)), 'Age'] = 4\n    table.loc[((table['Age'] > 35) & (table['Age'] <= 45)),'Age'] = 5\n    table.loc[(table['Age'] > 45),'Age'] = 6\n\n    return table\n\nX_train = convert_to_fare_category(X_train)\nX_train = convert_to_age_category(X_train)","fddb985e":"sns.distplot(X_train['Fare'], kde=False, bins=6)","b74a5e24":"sns.distplot(X_train['Age'], kde=False, bins=6)","0191b78c":"X_train['familySize'] = X_train['SibSp'] + X_train['Parch'] + 1\nX_train.drop(['SibSp', 'Parch', 'Fare', 'Embarked'], axis=1, inplace = True)\n#X_train['isAlone'] = np.where((X_train['familySize'] > 1),0,X_train['familySize'])\n#\u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0441\u043c\u0435\u0449\u0435\u043d\u043e \u0432 \u0441\u0442\u043e\u0440\u043e\u043d\u0443 \u0443\u043c\u0435\u0440\u0448\u0438\u0445, \u043c\u043e\u0436\u043d\u043e \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432\u044b\u0431\u043e\u0440\u043a\u0443\nX_train.head()\nsns.countplot(Y_train)","f7812120":"#\u043d\u0443\u0436\u043d\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u0441\u044d\u043c\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n#\u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c SMOTE(\u0434\u043e\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043c\u0435\u043d\u044c\u0448\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443)\nos = SMOTE(random_state=0)\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=2)\n#\u0434\u043e\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \nos_x_train, os_y_train=os.fit_sample(x_train, y_train)\n\nos_x_train = pd.DataFrame(data = os_x_train, columns=x_train.columns)\nos_y_train = pd.Series(data = os_y_train)","b47d666a":"sns.countplot(os_y_train)\n# \u041c\u044b \u043c\u043e\u0436\u0435\u043c \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c \u0447\u0438\u0441\u043b\u0430 \u043d\u0430\u0448\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nprint(\"\u0414\u043b\u0438\u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043e\u0432\u0435\u0440\u0441\u0435\u043c\u043f\u043b\u0438\u043d\u0433\u043e\u043c \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442: {}\".format(len(os_y_train)))\nprint(\"\u0427\u0438\u0441\u043b\u043e \u0443\u043c\u0435\u0440\u0448\u0438\u0445 \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 \u0441 \u043e\u0432\u0435\u0440\u0441\u0435\u043c\u043f\u043b\u0438\u043d\u0433\u043e\u043c: {}\".format(len(os_y_train[os_y_train==0])))\nprint(\"\u0427\u0438\u0441\u043b\u043e \u0432\u044b\u0436\u0438\u0432\u0448\u0438\u0445 \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 \u0441 \u043e\u0432\u0435\u0440\u0441\u0435\u043c\u043f\u043b\u0438\u043d\u0433\u043e\u043c: {}\".format(len(os_y_train[os_y_train==1])))\n#\u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u044b","68f804d8":"X_train.head()","f43d75ba":"# 1 \u043c\u043e\u0434\u0435\u043b\u044c - \u0434\u0435\u0440\u0435\u0432\u043e\nfrom sklearn import tree\nfrom sklearn.model_selection import cross_val_score\ndef use_DecisionTreeClassifier(x_train, y_train, x_test, y_test):\n    #\u0434\u0435\u043b\u0438\u043c \u043d\u0430 train \u0438 test \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n    scores_data = pd.DataFrame()\n    for max_depth in range(1, 50): # 50 - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430\n        clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)#\u043a\u0440\u0438\u0442\u0435\u0440\u0438\u0439 - \u044d\u043d\u0442\u0440\u043e\u043f\u0438\u044f\n        clf.fit(x_train, y_train)                                                  #\u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n        train_score = clf.score(x_train, y_train)                                  #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 train\n        test_score = clf.score(x_test, y_test)                                     #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 test\n        mean_cross_val_score = cross_val_score(clf, x_train, y_train, cv=10).mean() #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n        scores_data = scores_data.append(\n                          pd.DataFrame({'max_depth': [max_depth],\n                                        'train_score': [train_score],\n                                        'test_score': [test_score],\n                                        'cross_val_score': [mean_cross_val_score]}))\n\n    scores_data_long = pd.melt(scores_data, id_vars=['max_depth'], value_vars=['train_score', 'test_score', 'cross_val_score'],\n                              var_name='set_type', value_name='score')\n    sns.lineplot(x=\"max_depth\", y=\"score\", hue=\"set_type\", data=scores_data_long)\n    \n    best_score_on_cross_validation = scores_data_long[scores_data_long['set_type'] == 'cross_val_score'].groupby(by = 'set_type')['score'].max().values[0]\n    print(\"\u041b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0430 \u043a\u0440\u043e\u0441\u0441 - \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438: {:.5f}\".format(best_score_on_cross_validation))\n    print(scores_data_long[scores_data_long['set_type'] == 'cross_val_score'].head(20))","d5ca4833":"#\u0431\u0435\u0437 \u0441\u0435\u043c\u043f\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\nuse_DecisionTreeClassifier(x_train, y_train, x_test, y_test)\n#\u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 - \u0433\u043b\u0443\u0431\u0438\u043d\u0430 5","313c94cb":"#\u0441\u0442\u0440\u043e\u0438\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043e\u0448\u0438\u0431\u043e\u043a\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\ndef default_metrics(clf, x_test, y_test):\n    y_pred = clf.predict(x_test)\n    matrix = confusion_matrix(y_test, y_pred)\n    print(matrix)\n    print(classification_report(y_test, y_pred))","677fdad0":"clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 4)\nclf.fit(x_train, y_train)\ndefault_metrics(clf, x_test, y_test)","82f694a1":"#\u0441 \u0441\u0435\u043c\u043f\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\u043c\nuse_DecisionTreeClassifier(os_x_train, os_y_train, x_test, y_test)\n#\u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 - \u0433\u043b\u0443\u0431\u0438\u043d\u0430 5","b32e35c6":"clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 8)\nclf.fit(os_x_train, os_y_train)\ndefault_metrics(clf, x_test, y_test)","ec0f2441":"clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)# \u0434\u043e\u0431\u0430\u0432\u0438\u043c min_samples_leaf\nclf.fit(x_train, y_train)","d87f4dcb":"from IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\nimport sklearn","45c22739":"graph = Source(sklearn.tree.export_graphviz(clf, out_file=None,\n                                   feature_names=list(x_train),\n                                   class_names=['Negative','Positive'],\n                                   filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","499e7eac":"#2. \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u043c \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0443\u044e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e\nfrom sklearn.linear_model import LogisticRegression\nscores_data = pd.DataFrame()\nfor C in np.power(10, np.array(range(-3, 3)), dtype=float):\n    logreg  = LogisticRegression(C = C, n_jobs = -1)\n    logreg.fit(os_x_train, os_y_train)\n    train_score = logreg.score(os_x_train, os_y_train)                                   #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 train\n    test_score = logreg.score(x_test, y_test)                                            #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 test\n    mean_cross_val_score = cross_val_score(logreg, os_x_train, os_y_train , cv=10).mean() #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n    scores_data = scores_data.append(\n                      pd.DataFrame({'C': [C],\n                                    'train_score': [train_score],\n                                    'test_score': [test_score],\n                                    'cross_val_score': [mean_cross_val_score]}))\n\nscores_data_long = pd.melt(scores_data, id_vars=['C'], value_vars=['train_score', 'test_score', 'cross_val_score'],\n                          var_name='set_type', value_name='score')\nsns.lineplot(x=\"C\", y=\"score\", hue=\"set_type\", data=scores_data_long)","22b6f3ba":"#\u0438\u0449\u0435\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c\nbest_score_on_cross_validation = scores_data_long[scores_data_long['set_type'] == 'cross_val_score'].groupby(by = 'set_type')['score'].max().values[0]\nprint(\"\u041b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0430 \u043a\u0440\u043e\u0441\u0441 - \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438: {:.5f}\".format(best_score_on_cross_validation))\nscores_data_long[scores_data_long['set_type'] == 'cross_val_score']\n# \u0421 = 0.100 - \u043b\u0443\u0447\u0448\u0438\u0439 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438","931d6dbe":"logit = LogisticRegression(C = 10.0, n_jobs = -1)\nlogit.fit(x_train, y_train)\ndefault_metrics(logit, x_test, y_test)","60d2ead9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ndef findBestParamsRandomForestClassifier(x_train, y_train):\n    clf = RandomForestClassifier()\n    parameters = ({'n_estimators': [5, 10, 20, 30, 50, 75, 100], 'criterion': ['gini', 'entropy']})\n    grid_search_CV = GridSearchCV(clf, parameters, cv = 10, n_jobs = -1)\n    grid_search_CV.fit(x_train, y_train)\n    print(\"Best params: \", grid_search_CV.best_params_)\n    ","c0195f5b":"findBestParamsRandomForestClassifier(x_train, y_train)","1529ed0c":"forest_clf = RandomForestClassifier(n_estimators= 100)\nforest_clf.fit(x_train, y_train)\ndefault_metrics(forest_clf, x_test, y_test)","653aa91f":"example = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nprint(example.head())\n\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nprint(test.head())\nprint(test.info())\n#\u043b\u0443\u0447\u0448\u0438\u0439 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\n'''clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 4)\nclf.fit(x_train, y_train)'''\n\nforest_clf = RandomForestClassifier(n_estimators= 100)\nforest_clf.fit(x_train, y_train)","63c4e442":"#\u0440\u0430\u0437\u0431\u0438\u0440\u0430\u0435\u043c\u0441\u044f \u0441 Age\n'''X_mean = int(test['Age'].mean(axis=0))\nX_std = int(test['Age'].std(axis=0))\np = np.linspace(0, 1, num = int(2*X_std))\np \/= p.sum() # \u0438\u0437-\u0437\u0430 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0439 \u0435\u0434\u0438\u043d\u0438\u0446\u044b \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u044c\ntest['Age'] = test['Age'].fillna(np.random.choice(np.arange(X_mean - X_std, X_mean + X_std, 1), p = p))'''\ntest['Age'] = test['Age'].fillna(X_train['Age'].median())\n#\u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435\n#Survived Pclass Sex Age SibSp Parch Fare Embarked \nfind_sex_and_replace(test)\ntest = find_Embarked_and_replace(test)\n#\u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\n\n#fare_old_woman = test[(test['Age'] == 5) & (test['Embarked_S'] == 1)]['Fare'].mode().min()\n#\u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0431\u044b \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e \u043f\u043e\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 \u043d\u0435\u0439\n#test['Fare'] = test['Fare'].fillna(fare_old_woman)\n\ntest = convert_to_fare_category(test) \nprint(test.head())\ntest = convert_to_age_category(test)\ntest = test.astype({\"Age\": int, \"Fare\": int})\n\ntest['familySize'] = test['SibSp'] + test['Parch'] + 1\ntest.drop(['SibSp', 'Parch', 'Name','Ticket','Cabin'], axis=1, inplace = True)\ntest.info()","c840fd3e":"'''result = forest_clf.predict(test.drop(['PassengerId'], axis = 1))\n'''\nresult = clf.predict(test.drop(['PassengerId'], axis = 1))","212b1e11":"submission = pd.DataFrame({'PassengerId': test.PassengerId,'Survived':result})\nsubmission.Survived = submission.Survived.astype(int)\nfilename = 'Titanic Predictions.csv'\nsubmission.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","10a8c2de":"# 3. \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0433\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430","27573976":"\u0421\u0435\u043c\u043f\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0435 \u0434\u0430\u043b\u043e \u0434\u043e\u043b\u0436\u043d\u043e\u0433\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430, \u043d\u043e precision \u0443 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0441 1 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043b\u043e\u0441\u044c, \u0447\u0442\u043e \u0438 \u043e\u0436\u0438\u0434\u0430\u043b\u043e\u0441\u044c, \u043e\u0434\u043d\u0430\u043a\u043e F-\u043c\u0435\u0440\u0430 \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043b\u0430\u0441\u044c","4ed38ff0":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044c \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432!","db44586a":"\u0410\u043d\u0441\u0430\u043c\u0431\u043b\u044c \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 \u043b\u0443\u0447\u0448\u0435!","38bc51cc":"\u0414\u0435\u0440\u0435\u0432\u043e \u0441\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u0443\u0447\u0448\u0435, \u0447\u0435\u043c \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f","92d82f12":"# 1. \u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","05ed9220":"\u041f\u043e\u0445\u043e\u0436\u0435, \u0447\u0442\u043e Fare \u0438\u043c\u0435\u0435\u0442 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e \u0441 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c\u044e \u0432\u044b\u0436\u0438\u0432\u0430\u043d\u0438\u044f","0356e71a":"\u0421\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435","4499bbfa":"# 2. \u0421\u0442\u0440\u043e\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u0438"}}