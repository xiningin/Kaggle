{"cell_type":{"bb53edc4":"code","d0cc01ff":"code","2f73394e":"code","296590e3":"code","7968e43d":"code","7216fb6c":"code","65e09bb6":"code","985f4e32":"code","c0dd3206":"code","f3062f1e":"code","26ec8273":"code","cf48d5d1":"code","89693396":"code","92bcb187":"code","2dccf2b9":"code","635cea80":"code","57269ca0":"code","c060a08e":"code","9ad8489f":"code","8c73e32e":"code","62377734":"code","72632065":"code","cc93e70d":"code","30fb562e":"markdown","9d227163":"markdown","48e9fcc9":"markdown","909931c4":"markdown","65f58f47":"markdown","67f1b02c":"markdown","1d009b02":"markdown"},"source":{"bb53edc4":"import numpy as np\nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport matplotlib.markers\nimport os\nimport seaborn as sns\nimport pprint\nimport string\nimport re\n\nfrom tqdm import tqdm\n\nplt.style.use('ggplot')\ntqdm.pandas()","d0cc01ff":"df_train = pd.read_csv('..\/input\/train.csv')","2f73394e":"df_train.shape","296590e3":"df_train.info()","7968e43d":"df_train.head()","7216fb6c":"# import the json file to view the categories\n\nwith open('..\/input\/categories.json', 'rb') as handle:\n    cat_details = json.load(handle)","65e09bb6":"pprint.pprint(cat_details)","985f4e32":"category_mapper = {}\nproduct_type_mapper = {}\n\nfor category in cat_details.keys():\n    for key, value in cat_details[category].items():\n        category_mapper[value] = key\n        product_type_mapper[value] = category","c0dd3206":"# Display category mapper\n\ncategory_mapper","f3062f1e":"# Display product mapper\n\nproduct_type_mapper","26ec8273":"# Apply the mapper to get new columns - category_type and product_type\n\ndf_train['Category_type'] = df_train['Category'].map(category_mapper)\ndf_train['Product_type'] = df_train['Category'].map(product_type_mapper)","cf48d5d1":"plt.figure(figsize=(12,6))\nplot = sns.countplot(x='Product_type', data=df_train)\nplt.title('Product Type %', fontsize=20)\nax = plot.axes\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height() * 100 \/ df_train.shape[0]:.2f}%',\n                (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                ha='center', \n                va='center', \n                fontsize=11, \n                color='black',\n                xytext=(0,7), \n                textcoords='offset points')","89693396":"for product in cat_details.keys():\n    plt.figure(figsize=(20,6))\n    plot = sns.countplot(x='Category_type', \n                         data = df_train.loc[df_train['Product_type'] == product, :], \n                         order = df_train.loc[df_train['Product_type'] == product, 'Category_type'].value_counts().index)\n    plt.xticks(rotation=90)\n    plt.title(f'Category breakdown ({product})', fontsize=20)\n    ax = plot.axes\n\n    for p in ax.patches:\n        ax.annotate(f'{p.get_height() * 100 \/ df_train.shape[0]:.2f}%',\n                    (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                    ha='center', \n                    va='center', \n                    fontsize=11, \n                    color='black',\n                    xytext=(0,7), \n                    textcoords='offset points')\n    plt.show()","92bcb187":"from nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud","2dccf2b9":"df_train.head()","635cea80":"def preprocessing(titles_array):\n    \n    processed_array = []\n    \n    for title in titles_array:\n        \n        # remove digits and other non-alphabets symbols with space (i.e. keep only alphabets and whitespaces)\n        processed_title = re.sub('[^a-zA-Z ]', '', title.lower())\n        words = processed_title.split()\n        \n        # remove words that have length of 1\n        processed_array.append([word for word in words if len(word) > 1])\n    \n    return processed_array","57269ca0":"def get_freqdist_wc(titles, product_type, num_words=30):\n    \n    freq_dist = FreqDist([word for title in titles for word in title])\n    wordcloud = WordCloud(background_color='White').generate_from_frequencies(freq_dist)\n    \n    plt.figure(figsize=(22,6))\n    plt.subplot2grid((1,5),(0,0),colspan=2)\n    plt.imshow(wordcloud,interpolation='bilinear')\n    plt.axis('off')\n\n    plt.subplot2grid((1,5),(0,2),colspan=3)\n    plt.title(f'Frequency Distribution ({product_type}, Top {num_words})', fontsize=20)\n    freq_dist.plot(num_words, marker='|', markersize=20)\n\n    plt.tight_layout()\n    plt.show()","c060a08e":"mobile_titles = df_train.loc[df_train['Product_type'] == 'Mobile','title'].values\nfashion_titles = df_train.loc[df_train['Product_type'] == 'Fashion','title'].values\nbeauty_titles = df_train.loc[df_train['Product_type'] == 'Beauty','title'].values\n\nmobile_titles_p = preprocessing(mobile_titles)\nfashion_titles_p = preprocessing(fashion_titles)\nbeauty_titles_p = preprocessing(beauty_titles)","9ad8489f":"get_freqdist_wc(mobile_titles_p, 'Mobile')","8c73e32e":"get_freqdist_wc(fashion_titles_p, 'Fashion')","62377734":"get_freqdist_wc(beauty_titles_p, 'Beauty')","72632065":"def process_and_plot(cat_type, num_words = 10):\n    titles = df_train.loc[df_train['Category_type'] == cat_type,'title'].values\n    processed_titles = preprocessing(titles)\n    print(f'{cat_type}\\'s total counts:\\t {len(titles)}')\n    print(f'{len(titles) * 100\/ df_train.shape[0]:.2f}% of the training set.')\n    get_freqdist_wc(processed_titles, cat_type, num_words)\n    ","cc93e70d":"for category in tqdm(list(category_mapper.values())):\n    process_and_plot(category)","30fb562e":"# **A further drill-down to look at Frequency Distribution by Category**","9d227163":"# **Check out the distributions of product types and category types**","48e9fcc9":"# **Start off with Product Type for a macro view**","909931c4":"# **A Simple Exploratory Data Analysis**","65f58f47":"# **Start off by loading all the necessary files**\n\nAnd map the categories and product type back to the dataset, for ease of exploratory analysis.","67f1b02c":"# **Summary of findings on the feature 'Title'**\n1. For 'Mobile', the sub-categories have distinct keywords. Which means 'Title' alone should be a strong predictor of sub-categories.\n2. For 'Fashion', the sub-categories have overlapping keywords (e.g. wanita - which means 'women' in Bahasa, dress), this is the one that require image recognition to differentiate its sub-categories.\n3. For 'Beauty', it is a little in between 'Mobile' and 'Fashion', certain sub-categories like 'lipstick', 'other lip cosmetics', 'lip liner' are like sub-categories of each other and share similar keywords.  \n4. Overall, 'Title' seems to be a robust predictor for categories (product_type), can be used as an intermediate model to provide information to other models.","1d009b02":" # **Lets explore the 'title' feature. (e.g. Frequency Distribution, Word Cloud)**\n \n Do standard text processing stuff like removal of symbols and numbers (which are unlikely to have any predictive power)\n Will only remove word with length = 1 (contrary to standard pre-processing step of removing any words with length < 3), because certain short words like 'gb' 'bb' have high predictive power for certain product type."}}