{"cell_type":{"718f9506":"code","7660d9b9":"code","cad95aa0":"code","06b31fed":"code","392982fc":"code","5832679e":"code","9e088ae1":"code","658f14dc":"code","0ccd24cf":"code","a0308b30":"code","33b567b7":"code","b147b77d":"code","f76791b0":"code","4e515cbd":"code","dfedba51":"code","735e4083":"code","0cd91153":"code","7905885a":"code","00b422d6":"code","379f2f5c":"code","7c141df1":"code","13be9763":"code","f1894580":"code","14e57efe":"code","e4d0133b":"markdown","e3aa277c":"markdown","9517e50f":"markdown","e28b3027":"markdown"},"source":{"718f9506":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport folium\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7660d9b9":"measure_df = pd.read_csv('\/kaggle\/input\/air-pollution-in-seoul\/AirPollutionSeoul\/Measurement_summary.csv')\nserverity_df = pd.read_csv('\/kaggle\/input\/air-pollution-in-seoul\/AirPollutionSeoul\/Original Data\/Measurement_item_info.csv')","cad95aa0":"\ndef severitySO2(x):\n    severity = \"\"\n    if(x <= 0.02):\n        severity = \"Good\"\n    elif((x > 0.02) & (x <= 0.05)):\n        severity = \"Normal\"\n    elif((x > 0.05) & (x <= 0.15)):\n        severity = \"Bad\"\n    elif((x > 0.15) & (x <= 1.0)):\n        severity = \"Very Bad\"\n    return severity\n\ndef severityNO2(x):\n    severity = \"\"\n    if(x <= 0.03):\n        severity = \"Good\"\n    elif((x > 0.03) & (x <= 0.06)):\n        severity = \"Normal\"\n    elif((x > 0.06) & (x <= 0.2)):\n        severity = \"Bad\"\n    elif((x > 0.2) & (x <= 2.0)):\n        severity = \"Very Bad\"\n    return severity\n    \ndef severityCO(x):\n    severity = \"\"\n    if(x <= 2):\n        severity = \"Good\"\n    elif((x > 2) & (x <= 9)):\n        severity = \"Normal\"\n    elif((x > 9) & (x <= 15)):\n        severity = \"Bad\"\n    elif((x > 15) & (x <= 50)):\n        severity = \"Very Bad\"\n    return severity\n    \ndef severityO3(x):\n    severity = \"\"\n    if(x <= 0.03):\n        severity = \"Good\"\n    elif((x > 0.03) & (x <= 0.09)):\n        severity = \"Normal\"\n    elif((x > 0.09) & (x <= 0.15)):\n        severity = \"Bad\"\n    elif((x > 0.15) & (x <= 0.5)):\n        severity = \"Very Bad\"\n    return severity\n\ndef severityPM10(x):\n    severity = \"\"\n    if(x <= 30):\n        severity = \"Good\"\n    elif((x > 30) & (x <= 80)):\n        severity = \"Normal\"\n    elif((x > 80) & (x <= 150)):\n        severity = \"Bad\"\n    elif((x > 150) & (x <= 600)):\n        severity = \"Very Bad\"\n    return severity\n    \ndef severityPM25(x):\n    severity = \"\"\n    if(x <= 15):\n        severity = \"Good\"\n    elif((x > 15) & (x <= 35)):\n        severity = \"Normal\"\n    elif((x > 35) & (x <= 75)):\n        severity = \"Bad\"\n    elif((x > 75) & (x <= 500)):\n        severity = \"Very Bad\"\n    return severity","06b31fed":"date_time = measure_df['Measurement date'].str.split(\" \", n=1, expand=True)\nmeasure_df['date'] = date_time[0]\nmeasure_df['time'] = date_time[1]\nmeasure_df = measure_df.drop(['Measurement date'], axis=1)","392982fc":"measure_df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]].describe()","5832679e":"print(\"-1 Values in all columns\")\nprint(\"Total Rows : \", measure_df.shape)\nprint(\"SO2   : \",measure_df[measure_df.SO2 == -1].shape[0])\nprint(\"NO2   : \",measure_df[measure_df.NO2 == -1].shape[0])\nprint(\"CO    : \",measure_df[measure_df.CO == -1].shape[0])\nprint(\"O3    : \",measure_df[measure_df.O3 == -1].shape[0])\nprint(\"PM10  : \",measure_df[measure_df.PM10 == -1].shape[0])\nprint(\"PM2.5 : \",measure_df[measure_df['PM2.5'] == -1].shape[0])\n","9e088ae1":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=-1, strategy='mean')\ndf_imputed = pd.DataFrame(imp.fit_transform(measure_df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]]))\ndf_imputed.columns = measure_df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]].columns\ndf_imputed.index = measure_df.index\nremain_df = measure_df[measure_df.columns.difference([\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"])]\ndf = pd.concat([remain_df, df_imputed], axis=1)\ndf.head()","658f14dc":"df['SO2 Severity'] = df.apply(lambda row: severitySO2(row['SO2']), axis=1)\ndf['NO2 Severity'] = df.apply(lambda row: severityNO2(row['NO2']), axis=1)\ndf['CO Severity'] = df.apply(lambda row: severityCO(row['CO']), axis=1)\ndf['O3 Severity'] = df.apply(lambda row: severityO3(row['O3']), axis=1)\ndf['PM10 Severity'] = df.apply(lambda row: severityPM10(row['PM10']), axis=1)\ndf['PM2.5 Severity'] = df.apply(lambda row: severityPM25(row['PM2.5']), axis=1)","0ccd24cf":"df.head()","a0308b30":"df_mean_date = df.groupby(['date'], as_index=False).agg({'SO2':'mean', 'NO2':'mean', 'O3':'mean', 'CO':'mean', 'PM10':'mean', 'PM2.5':'mean'})\ndf_mean_date['date'] = pd.to_datetime(df_mean_date.date)\ndf_mean_date.head()","33b567b7":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='SO2')","b147b77d":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='NO2')","f76791b0":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='CO')","4e515cbd":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='O3')","dfedba51":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='PM10')","735e4083":"plt.figure(figsize=(50,10)) \nsns.lineplot(data=df_mean_date, x='date',y='PM2.5')","0cd91153":"plt.figure(figsize = (20,8))        \nsns.heatmap(df[[\"SO2\",\"NO2\",\"O3\",\"CO\",\"PM10\",\"PM2.5\"]].corr(),annot=True, cmap = 'coolwarm')","7905885a":"main_df = pd.read_csv('\/kaggle\/input\/air-pollution-in-seoul\/AirPollutionSeoul\/Measurement_summary.csv')\nexecept_date_df = df[df.columns.difference([\"date\",\"time\"])]\nmain_df['Measurement date'] = pd.to_datetime(main_df['Measurement date'])\nmain_df = pd.concat([main_df['Measurement date'], execept_date_df], axis=1)\nmain_df['hour'] = main_df['Measurement date'].apply(lambda x: x.hour)\nmain_df['month'] = main_df['Measurement date'].apply(lambda x: x.month)\nmain_df['day'] = main_df['Measurement date'].apply(lambda x: x.day)\nmain_df['week'] = main_df['Measurement date'].apply(lambda x: x.week)\nmain_df['year'] = main_df['Measurement date'].apply(lambda x: x.year)\nmain_df.head()","00b422d6":"main_df['month'].unique()","379f2f5c":"main_df_2017 = main_df.loc[main_df['year'] == 2017]\nmain_df_2018 = main_df.loc[main_df['year'] == 2018]\nmain_df_2019 = main_df.loc[main_df['year'] == 2019]","7c141df1":"from folium.plugins import HeatMap\ndef generateBaseMap(default_location=[37.572016, 127.005007], default_zoom_start=12):\n    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n    return base_map\n# base_map = generateBaseMap()\n# HeatMap(data=main_df[['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n# base_map","13be9763":"df_year_list = []\nfor year in main_df.year.sort_values().unique():\n    df_year_list.append(main_df.loc[main_df.year == year, ['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).mean().reset_index().values.tolist())\nfrom folium.plugins import HeatMapWithTime\nbase_map = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_year_list, radius=70, gradient={0.05: 'blue', 0.5: 'green', 0.75: 'yellow', 1.0: 'red'}, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map)\nbase_map","f1894580":"df_month_list_2017 = []\nfor month in main_df_2017.month.sort_values().unique():\n    df_month_list_2017.append(main_df_2017.loc[main_df_2017.month == month, ['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).mean().reset_index().values.tolist())\nfrom folium.plugins import HeatMapWithTime\nbase_map = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_month_list_2017, radius=70, gradient={0.05: 'blue', 0.5: 'green', 0.75: 'yellow', 1.0: 'red'}, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map)\nbase_map","14e57efe":"df_week_list_2017 = []\nfor week in main_df_2017.week.sort_values().unique():\n    df_week_list_2017.append(main_df_2017.loc[main_df_2017.week == week, ['Latitude', 'Longitude', 'PM2.5']].groupby(['Latitude', 'Longitude']).mean().reset_index().values.tolist())\nfrom folium.plugins import HeatMapWithTime\nbase_map = generateBaseMap(default_zoom_start=11)\nHeatMapWithTime(df_week_list_2017, radius=50, gradient={0.05: 'blue', 0.5: 'green', 0.75: 'yellow', 1.0: 'red'}, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map)\nbase_map","e4d0133b":"Creating function for each particulate type to assign severity category as Good, Normal, Bad or Very Bad.","e3aa277c":"The dataset has the information about the air pollution of Seoul, Korea. \n1. Measurement Summary -- It is the combined form of the 3 detailed dataset. It included different gases concentration values measured at different lattitude\/longitude at different timestamp. \n2. Measurement Item Info -- It provide us the information about the severity of the concentration of any particulate.","9517e50f":"Breaking measurement date into date and time individual columns","e28b3027":"It has been observed that, there are some null values as -1 which could have occured because of the mistake in reading and mistake in the apparatus."}}