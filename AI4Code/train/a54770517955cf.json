{"cell_type":{"1d8365ee":"code","0fb2a3d6":"code","abb8c1d9":"code","5c0e3d9a":"code","96c37cf5":"code","eb5c3ce2":"code","e7551524":"code","6c0434c0":"code","d732b8e3":"code","2b88f3c9":"code","afcbab4a":"code","2bf3e784":"code","3d6fe32c":"code","0eac7cdd":"code","8cc7986f":"markdown","45aabe67":"markdown","df5b2cb2":"markdown","2e29d2d5":"markdown","d8efdb31":"markdown","0a22c2c1":"markdown"},"source":{"1d8365ee":"# import those packages that I need\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm # to see the running process\nfrom skimage.io import imread, imshow # to read the image from workspace\nfrom skimage.transform import resize # resize those data to a certain size for training\nimport matplotlib.pyplot as plt # for plotting\n%matplotlib inline\nimport os\nimport keras \nfrom keras.utils.np_utils import to_categorical # for One-Hot Encoding\nfrom sklearn.model_selection import train_test_split # for generating validation set (X_val, Y_val)\n\nfrom keras.applications.resnet50 import ResNet50 # the well-known CNN model imported for transfer learning\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau # built-in callbacks in keras \nfrom keras.preprocessing.image import ImageDataGenerator # for data augmentation\nfrom keras import backend as K\nfrom keras.optimizers import Adam # the model optimizer that I choose for this task\nfrom keras.regularizers import l1,l2 # L1, L2 regularization to avoid overfitting\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport itertools\n\n# the following remark(code) can be used to see all the files in the 'input' folder in the Workspace\n\n'''\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''","0fb2a3d6":"# function for loading training images and labeling them in the same time according to which folder they come from, 'dogs' or 'cats'\n\ndef read_image_train(folder,resize_hight = 224, resize_width = 224):\n    \n    DATA_ROOT = \"..\/input\/\"\n    dogs = np.ones((1,resize_hight,resize_width,3))\n    cats = np.ones((1,resize_hight,resize_width,3))\n    \n    dogs_label=[]\n    cats_label=[]\n    \n    for image_type in os.listdir(folder):\n        # print(image_type)\n        if image_type == 'dogs':\n            for image_name in tqdm(os.listdir(folder + '\/' + image_type)):\n                # print(image_name)\n                im = imread(os.path.join(DATA_ROOT,folder + '\/' + image_type + '\/' + image_name))\n                # print(im.shape)\n                dog_size = im.size\n#                 if dog_size >= (resize_hight*resize_width):\n                if dog_size >= 0:\n                    im_resized = resize(im, (resize_hight, resize_width), anti_aliasing=True)\n                    im_resized = im_resized[np.newaxis,:,:,:]\n                    # print(im_resized.shape)\n                    dogs = np.concatenate((dogs,im_resized),axis=0)\n                    dogs_label.append(0)\n                    \n        elif image_type == 'cats':\n            for image_name in tqdm(os.listdir(folder +'\/'+ image_type)):\n                # print(image_name)\n                im = imread(os.path.join(DATA_ROOT,folder + '\/' +image_type + '\/' +image_name))\n                # print(im.shape)\n                cat_size = im.size\n#                 if cat_size >= (resize_hight*resize_width):\n                if cat_size >= 0:\n                    im_resized = resize(im, (resize_hight, resize_width), anti_aliasing=True)\n                    im_resized = im_resized[np.newaxis,:,:,:]\n                    # print(im_resized.shape)\n                    cats = np.concatenate((cats,im_resized),axis=0)\n                    cats_label.append(1)\n                    \n    dogs = np.delete(dogs,(0),axis=0)\n    cats = np.delete(cats,(0),axis=0)\n    image_array = np.concatenate((dogs,cats),axis = 0)\n    print(image_array.shape)\n\n    dogs_label = np.asarray(dogs_label)\n    cats_label = np.asarray(cats_label)\n    label = np.concatenate((dogs_label,cats_label),axis=0)\n    print(label.shape)\n    \n    return image_array, label","abb8c1d9":"# function for loading the testing data and getting their ID at the same time\n# the reason that getting the ID is for the submission csv file because the probability of class should match the image name\n\ndef read_image_test(folder,resize_hight = 224, resize_width = 224):\n    \n    DATA_ROOT = \"..\/input\/\"\n    img = np.ones((1,resize_hight,resize_width,3))\n    names = []\n    \n    for image_name in tqdm(os.listdir(folder)):\n        # print(image_name)\n        im = imread(os.path.join(DATA_ROOT,folder + '\/' + image_name))\n        # print(im.shape)\n        \n        im_resized = resize(im, (resize_hight, resize_width), anti_aliasing=True)\n        im_resized = im_resized[np.newaxis,:,:,:]\n        # print(im_resized.shape)\n        img = np.concatenate((img,im_resized),axis=0)\n        name_split = image_name.split('.')\n        names.append(name_split[0])\n\n                    \n    img = np.delete(img,(0),axis=0)\n    names = np.asarray(names)\n    print(\"The shape of image\",img.shape)\n    print(\"The shape of image name :\", names.shape)\n    \n    return img , names","5c0e3d9a":"# Now, We are able to load those data that we need for this task.\n# loading images and transform them into numpy array with labels (cats: 1,dogs:0)\n\nx_train, y_train = read_image_train('\/kaggle\/input\/ml-marathon-final\/data\/kaggle_dogcat\/train')\nx_test, names = read_image_test('\/kaggle\/input\/ml-marathon-final\/data\/kaggle_dogcat\/test')","96c37cf5":"# normalization\nx_train = x_train.astype('float32')\n# x_train \/= 255\nx_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\nx_train -= x_train_mean\nx_train \/= x_train_std\n\nx_test = x_test.astype('float32')\n# x_test \/= 255\nx_test_mean = np.mean(x_test)\nx_test_std = np.std(x_test)\nx_test -= x_test_mean\nx_test \/= x_test_std\n\n# label : one-hot encoding \nnum_class = 2\ny_trainHOT = keras.utils.to_categorical(y_train, num_class)\n\n# extract 1\/4 training data as validation data\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_trainHOT, test_size=0.25, random_state=42)\n\n# print out the shape of images and labels\nprint(\"The shape of x_train: \",X_train.shape)\nprint(\"The shape of y_train: \",Y_train.shape)\nprint(\"The shape of x_val: \",X_val.shape)\nprint(\"The shape of y_val: \",Y_val.shape)\n\nprint(\"The shape of x_test: \",x_test.shape)","eb5c3ce2":"# hyperparameters\nresize_hight = 224\nresize_width = 224\nNUM_CLASSES = 2\nbatch_size = 4  \nepochs = 50\nlearning_rate = 1e-5\naug = False\ninitial_train = True","e7551524":"# construct the ResNet50 from keras.applications.resnet50 (the packages that i import above!)\nResNet50_model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(resize_hight,resize_width,3))\n\nx = ResNet50_model.output\nx = Flatten()(x)\nx = Dropout(0.5)(x)\noutput_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\nResNet50_model_final = Model(inputs=ResNet50_model.input, outputs=output_layer)\n\nResNet50_model_final.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\nResNet50_model_final.summary()","6c0434c0":"# Data augmentation: Although I may not use it, it is worth trying :)\ntrain_datagen = ImageDataGenerator(shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(shear_range=0.2,\n                                 zoom_range=0.2,\n                                 horizontal_flip=True)\n\n# callbacks\nreduce_lr = ReduceLROnPlateau(factor=0.5, \n                              min_lr=1e-12, \n                              monitor='val_loss', \n                              patience=9, \n                              verbose=1)\n\nearlystop = EarlyStopping(monitor=\"val_acc\", \n                          patience=5, \n                          verbose=1)\n\n# save the model for future usage\nmodel_save='model_shuffle_noAug_allimage_bs4.h5' \nmodel_checkpoint = ModelCheckpoint(filepath=model_save, \n                                   monitor=\"val_loss\", \n                                   save_best_only=True)","d732b8e3":"# training\nif initial_train == True:\n    if aug == True:\n        train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size,shuffle=False)\n        validation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size,shuffle=False)\n    \n        history = ResNet50_model_final.fit_generator(train_generator,\n                                steps_per_epoch=len(X_train) \/\/ batch_size,\n                                epochs=epochs,\n                                verbose=1,\n                                validation_data=validation_generator,\n                                validation_steps = len(X_val) \/\/ batch_size,\n                                shuffle=True,\n                                callbacks = [model_checkpoint,earlystop,reduce_lr])\n    else:\n        history = ResNet50_model_final.fit(X_train,Y_train,\n                                batch_size = batch_size,\n                                epochs=epochs,\n                                verbose=1,\n                                validation_data= (X_val,Y_val),\n                                shuffle=True,\n                                callbacks = [model_checkpoint,earlystop,reduce_lr])\n\n\n    # Collect results\n    train_loss = ResNet50_model_final.history.history[\"loss\"]\n    valid_loss = ResNet50_model_final.history.history[\"val_loss\"]\n    train_acc = ResNet50_model_final.history.history[\"acc\"]\n    valid_acc = ResNet50_model_final.history.history[\"val_acc\"]\n\nelse:\n    ResNet50_model_final = keras.models.load_model(\"\/kaggle\/input\/cats-dogsclassification\/model_shuffle_noAug_allimage.h5\")\n    \nscore = ResNet50_model_final.evaluate(X_val,Y_val)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","2b88f3c9":"# plot the accuracy and loss during every epoch\n\nplt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\nplt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\nplt.legend()\nplt.title(\"Loss\")\nplt.show()\n\nplt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\nplt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\nplt.legend()\nplt.title(\"Accuracy\")\nplt.show()","afcbab4a":"# functin that plot the confusion matrix, helping understand the performance of the model\ndef plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm=(cm*100+.01).astype(int)\/100\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","2bf3e784":"# to plot the ROC curve to see the performance of our model\n\nY_val_roc = np.argmax(Y_val,axis=1) # ground truth\n# ResNet50_model_final = keras.models.load_model(\"\/kaggle\/input\/cats-dogsclassification\/model_noshuffle_noAug_allimage.h5\")\ny_probas = ResNet50_model_final.predict(X_val) # prediction (probability)\nY_pred_classes = np.argmax(y_probas,axis=1) \nfpr, tpr, _ = roc_curve(Y_val_roc,Y_pred_classes)\nroc_auc = auc(fpr, tpr)\n\nfig = plt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","3d6fe32c":"# plot the confusion matrix\ndict_characters = {0:'Dog',1:'Cat'}\nconfusion_mtx = confusion_matrix(Y_val_roc, Y_pred_classes) \nplot_confusion_matrix(confusion_mtx, classes =list(dict_characters.values()))\nplt.show()","0eac7cdd":"# make prediction on testing data and output the csv file for submission\nif not initial_train == True: \n    ResNet50_model_final = keras.models.load_model(\"\/kaggle\/input\/cats-dogsclassification\/model_shuffle_noAug_allimage.h5\")\n\ny_probas = ResNet50_model_final.predict(x_test)\n\n# read the sample_submission as my csv file format\ntest = pd.read_csv(\"\/kaggle\/input\/ml-marathon-final\/sample_submission.csv\")\ntest['Predicted'] = y_probas[:,1]\ntest['ID'] = names\ntest = test[[\"ID\", \"Predicted\"]]\ntest= test.sort_values(by=['ID'])\ntest.to_csv(\"20190816ResNet50_bs4.csv\", header=[\"ID\", \"Predicted\"], index=False) # submission format\ntest.head(10)","8cc7986f":"# Plot the result !!!\nAfter training several epochs, let's check our model's performance. Following is loss and accuracy of training set and validation set during each epoch. I also plot a ROC curve and calculate the area under curve (AUC value) to evaluate the model. Lastly, I also plot a  confusion matrix to check the model performance as well.","45aabe67":"# Preprocessing\nFor every image, the range of pixel values varies. So if the image data isn't preprocessed, it may influence the training result. One of the most common ways of preprocessing is normalization. Other ways like histogram matching, gamma correction are worth trying as well. But for this case, I choose simple normalization to preprocess those image data. Hope that it works!!!","df5b2cb2":"# Transfer Learning: ResNet50\nDue to my desperate attempt to use a simple CNN model for this task, which the accuracy and the ROC-AUC value is very low, I gave up on trying to build a descent and simple CNN model on my own. Taking ResNet50 model's extrodinary performance on image classification, I build a model based on it (Transfer Learning) and load the pretrained weight that is pretrained on ImageNet dataset. \"'include_top' = False\" means that the last fully-connected layer will be removed, so we should add our fully-connected layer to complete the ResNet50-based CNN model.","2e29d2d5":"# Let's get it!!!\nIn the begining, off course, the packages that I need should be imported properly. Almost every package imported is followed a remark that explains the purpose. Hope that it is very easy to read and that it helps anyone who check this kernel understand my codes :)","d8efdb31":"# Load training and testing data!!!\n\nThe most important thing in supervised learning is the labeled data for training. Those images that feature either dogs or cats are located in the Workspace. So, to load them into this kernel, let's build functions for the training data and testing data. ","0a22c2c1":"# Let's make prediction on testing image!!!\nIt seems that our ResNet50 CNN model is quite good. So, let's move to our last and the most important step: Prediction. After we get the probability of class of each image, it is necessary to form a csv file that has the same format as the sample_submission.csv file. So I will read the sample_submission.csv file as my format and write my result (prediction on testing image) into this file."}}