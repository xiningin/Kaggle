{"cell_type":{"3ca4a265":"code","1e281599":"code","40ff92a1":"code","1cd99625":"code","e52d3ca8":"code","264fdbad":"code","5396c6ca":"code","1e4fb24c":"code","c5d88dbf":"markdown","7347e5c8":"markdown","91f8e126":"markdown"},"source":{"3ca4a265":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nfrom sklearn import model_selection, preprocessing, metrics\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport shap\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Any results you write to the current directory are saved as output.","1e281599":"train = pd.read_csv('..\/input\/andrews-features-only\/X_tr.csv')\ntest = pd.read_csv('..\/input\/andrews-features-only\/X_test.csv')","40ff92a1":"train.shape","1cd99625":"test.shape","e52d3ca8":"features = train.columns\ntrain['target'] = 0\ntest['target'] = 1","264fdbad":"train_test = pd.concat([train, test], axis =0)\n\ntarget = train_test['target'].values","5396c6ca":"param = {'num_leaves': 50,\n         'min_data_in_leaf': 30, \n         'objective':'binary',\n         'max_depth': 5,\n         'learning_rate': 0.006,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 27,\n         \"metric\": 'auc',\n         \"verbosity\": -1}\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=15)\noof = np.zeros(len(train_test))\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_test.values, target)):\n    print(\"fold n\u00b0{}\".format(fold_))\n    trn_data = lgb.Dataset(train_test.iloc[trn_idx][features], label=target[trn_idx])\n    val_data = lgb.Dataset(train_test.iloc[val_idx][features], label=target[val_idx])\n\n    num_round = 30000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1400)\n    oof[val_idx] = clf.predict(train_test.iloc[val_idx][features], num_iteration=clf.best_iteration)","1e4fb24c":"feature_imp = pd.DataFrame(sorted(zip(clf.feature_importance(),train.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).head(20))\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')","c5d88dbf":"Whoa, that's a pretty significant AUC! At AUC of 0.85 there is a very significant difference between the train and test sets, and a very very good chance of a major shakeup ...\n\nLet's look now at the top 20 \"adversarial\" features.","7347e5c8":"For the features I'll use a good set of engineered features. Feature angineering was done by Andrew, and I had just created a separate kernel where they can be looked at in their own right and saved:\n\nhttps:\/\/www.kaggle.com\/tunguz\/andrews-features-only","91f8e126":"With a very small dataset, lots and lots of different engineered features, vastly different CV and LB scores, and high inconsisency of LB scores with just slight changes in seed, this competition is overripe for a major shakupe. In this kernel we'll take a look at adveserial validation, and what it may portend about the shakeup."}}