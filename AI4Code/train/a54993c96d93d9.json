{"cell_type":{"a6e912cc":"code","268cbe42":"code","a74ed2f1":"code","f7f2fe6b":"code","f051b718":"code","65c82626":"code","d2a698e9":"code","325a6896":"code","6e09d6a9":"code","517b558f":"code","b9e73268":"code","4a71e7a1":"code","f0b46adb":"code","e4245de6":"code","dd2d97f9":"code","d034145d":"code","81c93916":"code","ff7c0982":"markdown","85bb02b9":"markdown","83c69212":"markdown","ba12028d":"markdown","4a31694e":"markdown","89517daf":"markdown","77a1e868":"markdown","4a8e2425":"markdown","01c573e6":"markdown","b1da06ca":"markdown","54139613":"markdown","0296cad5":"markdown","2515300b":"markdown","40ca2914":"markdown","6e28cdf3":"markdown","cd365711":"markdown","d234831c":"markdown","ff0c3e46":"markdown","723cfc1b":"markdown","b12aebe5":"markdown"},"source":{"a6e912cc":"import numpy as np\nimport pandas as pd\nimport pandas_profiling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","268cbe42":"from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier ,RandomForestClassifier ,GradientBoostingClassifier\n#from xgboost import XGBClassifier \nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import Ridge,Lasso\nfrom sklearn.metrics import roc_auc_score ,mean_squared_error,accuracy_score,classification_report,roc_curve,confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats.mstats import winsorize\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split\npd.set_option('display.max_columns',None)\nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six","a74ed2f1":"# accessing to the folder where the file is stored\npath = '..\/input\/banking-project-term-deposit\/new_train.csv'\n\n# Load the dataframe\ndataframe = pd.read_csv(path)\n\nprint('Shape of the data is: ',dataframe.shape)\n\ndataframe.head()\n\n","f7f2fe6b":"\n# IDENTIFYING NUMERICAL FEATURES\n\nnumeric_data = dataframe.select_dtypes(include=np.number) # select_dtypes selects data with numeric features\nnumeric_col = numeric_data.columns                                                                # we will store the numeric features in a variable\n\nprint(\"Numeric Features:\")\nprint(numeric_data.head())\nprint(\"====\"*20)","f051b718":"\n# IDENTIFYING CATEGORICAL FEATURES\ncategorical_data = dataframe.select_dtypes(exclude=np.number) # we will exclude data with numeric features\ncategorical_col = categorical_data.columns                                                                              # we will store the categorical features in a variable\n\n\nprint(\"Categorical Features:\")\nprint(categorical_data.head())\nprint(\"====\"*20)\n","65c82626":"# CHECK THE DATATYPES OF ALL COLUMNS:\n    \nprint(dataframe.dtypes)\n","d2a698e9":"# To identify the number of missing values in every feature\n\n# Finding the total missing values and arranging them in ascending order\ntotal = dataframe.isnull().sum()\n\n# Converting the missing values in percentage\npercent = (dataframe.isnull().sum()\/dataframe.isnull().count())\nprint(percent)\ndataframe.head()","325a6896":"# imputing missing values with mean\n\nfor column in numeric_col:\n    mean = dataframe[column].mean()\n    dataframe[column].fillna(mean,inplace = True)\n    \n#   imputing with median\n# for column in numeric_col:\n#     mean = dataframe[column].median()\n#     dataframe[column].fillna(mean,inpalce = True)\n","6e09d6a9":"# we are finding the percentage of each class in the feature 'y'\nclass_values = (dataframe['y'].value_counts()\/dataframe['y'].value_counts().sum())*100\nprint(class_values)","517b558f":"# Selecting the categorical columns\ncategorical_col = dataframe.select_dtypes(include=['object']).columns\nplt.style.use('ggplot')\n# Plotting a bar chart for each of the cateorical variable\nfor column in categorical_col:\n    plt.figure(figsize=(20,4))\n    plt.subplot(121)\n    dataframe[column].value_counts().plot(kind='bar')\n    plt.title(column)","b9e73268":"# Impute mising values of categorical data with mode\nfor column in categorical_col:\n    mode = dataframe[column].mode()[0]\n    dataframe[column] = dataframe[column].replace('unknown',mode)\n","4a71e7a1":"dataframe.drop(['pdays','previous'],1,inplace=True)","f0b46adb":"\n\nfor column in categorical_col:\n    plt.figure(figsize=(20,4))\n    plt.subplot(121)\n    sns.countplot(x=dataframe[column],hue=dataframe['y'],data=dataframe)\n    plt.title(column)    \n    plt.xticks(rotation=90)","e4245de6":"numeric_col = dataframe.select_dtypes(include=np.number).columns\n\nfor col in numeric_col:    \n    dataframe[col] = winsorize(dataframe[col], limits=[0.05, 0.1],inclusive=(True, True))\n\n# Now run the code snippet to check outliers again","dd2d97f9":"# Initializing lable encoder\nle = LabelEncoder()\n\n# Initializing Label Encoder\nle = LabelEncoder()\n\n# Iterating through each of the categorical columns and label encoding them\nfor feature in categorical_col:\n    try:\n        dataframe[feature] = le.fit_transform(dataframe[feature])\n    except:\n        print('Error encoding '+feature)","d034145d":"#dataframe.to_csv('..\/data\/preprocessed_data.csv',index=False)\ndataframe.to_csv(r\"C:\\Users\\gangu\\OneDrive\\Desktop\\GreyAtom\\preprocessed_data.csv\",index=False)","81c93916":"from pandas_profiling import ProfileReport\nprof = ProfileReport(dataframe)\nprof","ff7c0982":"### Dropping the columns `pdays` & `previous`","85bb02b9":"## Data Loading and Cleaning\n\n","83c69212":"### Fill null values in continuous features\n\nThere are no null values in any of the continuous columns in this dataset. But when null values exist in a continuous column, a good approach would be to impute them.\n\nThere exists many approach to missing-data imputation and they usually depend on your problem and how your data algorithm behaves. If the features are numeric you can use simple approaches, such as average values and sampling from the feature distribution.\n\n- Missing values in continuous data are mostly imputed using mean or median. What to choose depends on a lot of factors and is to be decided by you\n- Let's write a code snippet that will take the dataframe and the impute missing data with either mean or mode, depending on the user's choice.","ba12028d":"\n### Observations : \n- The class distribution in the target is ~89:11. This is a clear indication of imbalance.\n- By now you should be well familiar with the methods on how to deal with the imbalance in data.","4a31694e":"### Check for Class Imbalance\n\nClass imbalance occurs when the observations belonging to one class in the target are significantly higher than the other class or classes. A class distribution of **80:20 or greater** is typically considered as an imbalance for a binary classification. \n\nSince most machine learning algorithms assume that data is equally distributed, applying them on imbalanced data often results in bias towards majority classes and poor classification of minority classes. Hence we need to identify & deal with class imbalance. \n\nThe code below that takes the target variable and outputs the distribution of classes in the target.","89517daf":"###  Importing necessary libraries\n\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks.","77a1e868":"### Check Missing Data \n\nOne of the main steps in data preprocessing is handling missing data. Missing data means absence of observations in columns that can be caused while procuring the data, lack of information, incomplete results etc. Feeding missing data to your machine learning model could lead to wrong prediction or classification. Hence it is necessary to identify missing values and treat them.\n\n- In the code below, we calculate the total missing values and the percentage of missing values in every feature of the dataset.\n- The code ideally returns a dataframe consisting of the feature names as index and two columns having the count and percentage of missing values in that feature.","4a8e2425":"###  Importing necessary libraries\n\nThe following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks.","01c573e6":"### Check Numeric and Categorical Features\n\nLooking at the dataset, we think we can identify the categorical and continuous columns in it. Right? But it might also be possible that the numerical values are represented as strings in some feature. Or the categorical values in some features might be represented as some other datatypes instead of strings. Hence it's good to check for the datatypes of all the features.\n","b1da06ca":"### Observation :\n\nUsing winsorization has resulted in removal of all the outliers from the numerical columns.  You can even use normalization or standardization for dealing with outliers. ","54139613":"\n### Load and Prepare dataset\n\n- In this task, we'll load the dataframe in pandas, drop the unnecessary columns and display the top five rows of the dataset.","0296cad5":"### Function to Label Encode Categorical variables\n\nBefore applying our machine learning algorithm, we need to recollect that any algorithm can only read numerical values. It is therefore essential to encode categorical features into numerical values. Encoding of categorical variables can be performed in two ways:\n- Label Encoding\n- One-Hot Encoding.\n\nFor the given dataset, we are going to label encode the categorical columns. \n\n- In the code below we will perform label encoding on all the categorical features and also the target (since it is categorical) in the  dataset. You can modify the below function in order to perform One-Hot Encoding as well.","2515300b":"### Imputing `unknown` values of categorical columns \n\nIn the previous task we have seen some categorical variables have a value called `unknown`. `unknown` values are a kind of missing data.\nDepending on the use case, we can decide how to deal with these values. One method is to directly impute them with the mode value of respective columns.\n\n- The code below imputes the value `unknown` in the categorical columns with the mode value of that column. You can modify this function to replace any unwanted value(for e.g `NaN` value) in a column with a value of your choice.","40ca2914":"# Understanding the dataset\n\n**Data Set Information**\n\nThe data is related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be subscribed ('yes') or not ('no') subscribed.\n\nThere are two datasets:\n`train.csv` with all examples (32950) and 21 inputs including the target feature, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]\n\n`test.csv` which is the test data that consists  of 8238 observations and 20 features without the target feature\n\nGoal:- The classification goal is to predict if the client will subscribe (yes\/no) a term deposit (variable y).\n\n**Features**\n\n|Feature|Feature_Type|Description|\n|-----|-----|-----|\n|age|numeric|age of a person|  \n|job |Categorical,nominal|type of job ('admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')|  \n|marital|categorical,nominal|marital status ('divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)|  \n|education|categorical,nominal| ('basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown') | \n|default|categorical,nominal| has credit in default? ('no','yes','unknown')|  \n|housing|categorical,nominal| has housing loan? ('no','yes','unknown')|  \n|loan|categorical,nominal| has personal loan? ('no','yes','unknown')|  \n|contact|categorical,nominal| contact communication type ('cellular','telephone')|  \n|month|categorical,ordinal| last contact month of year ('jan', 'feb', 'mar', ..., 'nov', 'dec')| \n|day_of_week|categorical,ordinal| last contact day of the week ('mon','tue','wed','thu','fri')|  \n|duration|numeric| last contact duration, in seconds . Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no')|\n|campaign|numeric|number of contacts performed during this campaign and for this client (includes last contact)|  \n|pdays|numeric| number of days that passed by after the client was last contacted from a previous campaign (999 means client was not previously contacted)|  \n|previous|numeric| number of contacts performed before this campaign and for this client|  \n|poutcome|categorical,nominal| outcome of the previous marketing campaign ('failure','nonexistent','success')|  \n\n**Target variable (desired output):**  \n\n|Feature|Feature_Type|Description|\n|-----|-----|-----|\n|y | binary| has the client subscribed a term deposit? ('yes','no')|","6e28cdf3":"### Observations:\n\n- The common traits seen for customers who have subscribed for the term deposit are :\n    - Customers having administrative jobs form the majority amongst those who have subscirbed to the term deposit with technicians being the second majority.\n    - They are married \n    - They hold a university degree\n    - They do not hold a credit in default\n    - Housing loan doesn't seem a priority to check for since an equal number of customers who have and have not subscribed to it seem to have subscribed to the term deposit.\n    - Cell-phones should be the preferred mode of contact for contacting customers.","cd365711":"### Observations :\n\nFrom the above visuals, we can make the following observations: \n- The top three professions that our customers belong to are - administration, blue-collar jobs and technicians.\n- A huge number of the customers are married.\n- Majority of the customers do not have a credit in default\n- Many of our past customers have applied for a housing loan but very few have applied for personal loans.\n- Cell-phones seem to be the most favoured method of reaching out to customers.\n- Many customers have been contacted in the month of **May**.\n- The plot for the target variable shows heavy imbalance in the target variable. \n- The missing values in some columns have been represented as `unknown`. `unknown` represents missing data. In the next task, we will treat these values.  ","d234831c":"###  Univariate analysis of Categorical columns\n\nUnivariate analysis means analysis of a single variable. It\u2019s mainly describes the characteristics of the variable.\n\nIf the variable is categorical we can use either a bar chart or a pie chart to find the distribution of the classes in the variable.\n\n- The code plots the frequency of all the values in the categorical variables. \n","ff0c3e46":"### Treating outliers in the continuous columns\n\n- Outliers can be treated in a variety of ways. It depends on the skewness of the feature.\n- To reduce right skewness, we use roots or logarithms or reciprocals (roots are weakest). This is the most common problem in practice.\n- To reduce left skewness, we take squares or cubes or higher powers.\n- But in our data, some of the features have negative values and also the value 0. In such cases, square root transform or logarithmic transformation cannot be used since we cannot take square root of negative values and logarithm of zero is not defined.\n- Hence for this data we use a method called **Winsorization**. In this method we define a confidence interval of let's say 90% and then replace all the outliers below the 5th percentile with the value at 5th percentile and all the values above 95th percentile with the value at the 95th percentile. It is pretty useful when there are negative values and zeros in the features which cannot be treated with log transforms or square roots. Do read up on it more [here](https:\/\/www.statisticshowto.datasciencecentral.com\/winsorize\/)\n\nLets' write a code below that treats all the outliers in the numeric features using winsorization.","723cfc1b":"### Bivariate Analysis - Categorical Columns\n\nBivariate analysis involves checking the relationship between two variables simultaneously. In the code below, we plot every categorical feature against the target by plotting a barchart. ","b12aebe5":"# Problem Statement\n\n### Business Use Case\n\nThere has been a revenue decline for a Portuguese bank and they would like to know what actions to take. After investigation, they found out that the root cause is that their clients are not depositing as frequently as before. Knowing that term deposits allow banks to hold onto a deposit for a specific amount of time, so banks can invest in higher gain financial products to make a profit. In addition, banks also hold better chance to persuade term deposit clients into buying other products such as funds or insurance to further increase their revenues. As a result, the Portuguese bank would like to identify existing clients that have higher chance to subscribe for a term deposit and focus marketing efforts on such clients.\n\n### Data Science Problem Statement\n\nPredict if the client will subscribe to a term deposit based on the analysis of the marketing campaigns the bank performed.\n\n### Evaluation Metric\nWe will be using AUC - Probability to discriminate between subscriber and non-subscriber. \n\n### Objective of this template notebook\n\nThe main objective of this template is to take you through the entire working pipeline that was followed while appraoching a Machine Learning problem.\n\n"}}