{"cell_type":{"c058e40f":"code","c1ac98cf":"code","45fb3244":"code","0cdc28f6":"code","a1a0cb5e":"code","91f0b224":"code","73824eff":"code","c351c044":"code","e6ad22ae":"code","8d276c51":"code","70573552":"code","0b6d2c55":"code","bc084fc8":"code","3d7d4131":"code","f327c3b1":"code","797b0c40":"code","095018fd":"code","f5100a86":"code","6f84b45d":"code","adeb0a9f":"code","99798e3d":"code","aab1f796":"code","57d89e8a":"code","339b8d4e":"code","d1a32881":"code","cf8e3163":"code","5479e89a":"code","eb33c567":"code","b2b9b95d":"code","eff539ff":"code","99cf035a":"code","b1153f4e":"code","3da03804":"markdown"},"source":{"c058e40f":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n#SVG(model_to_dot(model).create(prog='dot', format='svg'))\ndef inv_sigmoid(s):\n    return -np.log(1\/s-1)","c1ac98cf":"import json\nimport pandas as pd\nimport os\nimport h5py\nimport glob\n\nimport cv2\nfrom IPython.display import Image  \nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Rectangle\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as K\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n%matplotlib inline\n\nnum_classes = 11\n#input_shape = (224, 224, 3)\n#input_shape = (60, 120, 3)\ninput_shape = (416, 416, 3)\n\n\ndef imagePath(mode):       \n    #imagePath = glob.glob(dir_path +'\/*.png')\n    SVHNPath = '..\/input\/street-view-house-numbers'\n    dirName = os.path.join(SVHNPath, mode, mode)\n    imagePath = []\n    #files = os.path.join(SVHNPath, mode, mode, '*.png')\n    for filename in os.listdir(dirName):\n        #print('process folder : %s' % mode)      \n        filenameParts = os.path.splitext(filename)\n        if filenameParts[1] != '.png':\n           continue\n        imagePath.append(int(filenameParts[0]))\n    imagePath.sort()\n    [f'{dirName}\/{name}.png' for name in imagePath]\n    return [f'{dirName}\/{name}.png' for name in imagePath]\n\ndef mat_to_dataset(mat_path):\n    f = h5py.File(mat_path, mode='r')\n    datasets = {}\n    files_count = len(f['digitStruct']['name'])\n    for i in range(files_count):\n        name_uint16 = f[f['digitStruct']['name'][i,0]][:]\n        name = ''.join(chr(n) for n in name_uint16)\n        \n        bbox = {}\n        box_i = f[f['digitStruct']['bbox'][i,0]]\n        length = box_i['label'].shape[0]\n        for key in ['height', 'label', 'left', 'top', 'width']:\n            l = []\n            if key=='label':\n                l = [ int(str(int(f[box_i[key][index,0]][0][0]))[-1]) if length > 1 else int(box_i[key][0][0]) for index in range(length) ]\n            else:\n                l = [ int(f[box_i[key][index,0]][0][0]) if length > 1 else int(box_i[key][0][0]) for index in range(length) ]\n            bbox[key] = l\n        datasets[name] = bbox\n        print(f'Loading {i} \/ {files_count}.\\r', end='') \n    print() \n    print(f'{i+1} records loaded.') \n    return datasets\n\ndef save_dataset_from_mat(mode='train'):\n    dirpath = '..\/input\/street-view-house-numbers'\n    mat_path = f'{dirpath}\/{mode}_digitStruct.mat'\n    dataset = mat_to_dataset(mat_path)\n    \n    filename = f'{mode}.json'\n    with open(filename, 'w') as outfile:    \n        json.dump(dataset, outfile)\n        \ndef save_to_npy(d):\n    d = {'x_train':x_train,'y_train':y_train,'x_test':x_test,'y_test':y_test}\n    with open('data.npy', 'wb') as f:\n        np.save(f,d)\ndef load_from_npy():\n    d = np.load('data.npy', allow_pickle=True)\n    x_train,y_train,x_test, y_test = d.item()['x_train'],d.item()['y_train'],d.item()['x_test'],d.item()['y_test']\n    return (x_train,y_train),(x_test, y_test)\n\ndef pad_with_char(string, char):    \n    return string + (6 - len(list(string))) * char\n\ndef label_padding(label, length=6):\n    array = np.zeros((len(label), length),dtype=np.int32)\n    array.fill(10)\n    for i,l in enumerate(label):\n        for j,c in enumerate(l):\n            array[i,j] = c\n    return array\n\ndef loadData(input_shape, num_classes):\n    x_train, y_train = loadDataWithMode('train' ,input_shape, num_classes)\n    x_test,  y_test  = loadDataWithMode('test' ,input_shape, num_classes)\n    d = {'x_train':x_train,'y_train':y_train,'x_test':x_test,'y_test':y_test}\n    #with open('data.npy', 'wb') as f:\n        #np.save(f,d)\n    return (x_train, y_train), (x_test,  y_test)\n\ndef loadDataWithMode(mode ,input_shape, num_classes):\n    # load train_data\n    train_path = imagePath(mode)\n    length = 100#len(train_path)   \n    if mode=='test':\n        length=200\n    h,w,c = input_shape\n    x_train = np.zeros((length,h,w,c))\n    for i in range(length):\n        img = cv2.imread(train_path[i])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (w,h)) \n        img = img \/ 255      \n        x_train[i] = img\n        print(f'Loading {mode} examples {i+1}\/{length}.\\r', end='')\n    \n    train_json = json.load(open(f'..\/input\/svhn-label\/{mode}.json'))\n    train_label = [train_json[x]['label'] for x in train_json]\n    train_label = label_padding(train_label)\n    y_train = keras.utils.to_categorical(train_label, num_classes)\n    y_train = y_train[:length].reshape(length,-1)\n    \n    print()\n    #print(f'x_{mode}.shape:{x_train.shape}')\n    #print(f'y_{mode}.shape:{y_train.shape}')\n    return (x_train,y_train)\n\n#train_label[i]\n#img = cv2.resize(img, (28, 28)) \n#plt.imshow(img)\n#(x_train,y_train),(x_test, y_test) = loadData(input_shape, num_classes)\n#(x_train,y_train),(x_test, y_test) = load_from_npy()\n#print(f'x_train.shape:{x_train.shape}')\n#print(f'y_train.shape:{y_train.shape}')\n#print(f'x_test.shape:{x_test.shape}')\n#print(f'y_test.shape:{y_test.shape}')","45fb3244":"# create a YOLOv3 Keras model and save it to file\n# based on https:\/\/github.com\/experiencor\/keras-yolo3\nimport struct\nimport numpy as np\nfrom keras.layers import Conv2D\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import UpSampling2D\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model\n\ndef _conv_block(inp, convs, skip=True):\n\tx = inp\n\tcount = 0\n\tfor conv in convs:\n\t\tif count == (len(convs) - 2) and skip:\n\t\t\tskip_connection = x\n\t\tcount += 1\n\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n\t\tx = Conv2D(conv['filter'],\n\t\t\t\t   conv['kernel'],\n\t\t\t\t   strides=conv['stride'],\n\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n\treturn add([skip_connection, x]) if skip else x\n\ndef make_yolov3_model():\n\tinput_image = Input(shape=(None, None, 3))\n\t# Layer  0 => 4\n\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n\t# Layer  5 => 8\n\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n\t# Layer  9 => 11\n\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n\t# Layer 12 => 15\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n\t# Layer 16 => 36\n\tfor i in range(7):\n\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n\tskip_36 = x\n\t# Layer 37 => 40\n\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n\t# Layer 41 => 61\n\tfor i in range(7):\n\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n\tskip_61 = x\n\t# Layer 62 => 65\n\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n\t# Layer 66 => 74\n\tfor i in range(3):\n\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n\t# Layer 75 => 79\n\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n\t# Layer 80 => 82\n\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n\t\t\t\t\t\t\t  {'filter':  48, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n\t# Layer 83 => 86\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n\tx = UpSampling2D(2)(x)\n\tx = concatenate([x, skip_61])\n\t# Layer 87 => 91\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n\t# Layer 92 => 94\n\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n\t\t\t\t\t\t\t  {'filter': 48, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n\t# Layer 95 => 98\n\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n\tx = UpSampling2D(2)(x)\n\tx = concatenate([x, skip_36])\n\t# Layer 99 => 106\n\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n\t\t\t\t\t\t\t   {'filter': 48, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n\treturn model\n\nclass WeightReader:\n\tdef __init__(self, weight_file):\n\t\twith open(weight_file, 'rb') as w_f:\n\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n\t\t\trevision, = struct.unpack('i', w_f.read(4))\n\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n\t\t\t\tw_f.read(8)\n\t\t\telse:\n\t\t\t\tw_f.read(4)\n\t\t\ttranspose = (major > 1000) or (minor > 1000)\n\t\t\tbinary = w_f.read()\n\t\tself.offset = 0\n\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n\n\tdef read_bytes(self, size):\n\t\tself.offset = self.offset + size\n\t\treturn self.all_weights[self.offset-size:self.offset]\n\n\tdef load_weights(self, model):\n\t\tfor i in range(106):\n\t\t\ttry:\n\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n\t\t\t\tif i not in [81, 93, 105]:\n\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n\t\t\t\t\tgamma = self.read_bytes(size) # scale\n\t\t\t\t\tmean  = self.read_bytes(size) # mean\n\t\t\t\t\tvar   = self.read_bytes(size) # variance\n\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n\t\t\t\tif len(conv_layer.get_weights()) > 1:\n\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n\t\t\t\telse:\n\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n\t\t\t\t\tconv_layer.set_weights([kernel])\n\t\t\texcept ValueError:\n\t\t\t\tprint(\"no convolution #\" + str(i))\n\n\tdef reset(self):\n\t\tself.offset = 0\n\n# define the model\nmodel = make_yolov3_model()\n# load the model weights\n#weight_reader = WeightReader('..\/input\/yolov3\/yolov3.weights')\n# set the model weights into the model\n#weight_reader.load_weights(model)\n# save the model to file\nmodel.save('model_yolo.h5')\n#model.save_weights('weight_yolo.h5')","0cdc28f6":"import numpy as np\nfrom numpy import expand_dims\nfrom keras.models import load_model\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Rectangle\n\nclass BoundBox:\n\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n\t\tself.xmin = xmin\n\t\tself.ymin = ymin\n\t\tself.xmax = xmax\n\t\tself.ymax = ymax\n\t\tself.objness = objness\n\t\tself.classes = classes\n\t\tself.label = -1\n\t\tself.score = -1\n\n\tdef get_label(self):\n\t\tif self.label == -1:\n\t\t\tself.label = np.argmax(self.classes)\n\n\t\treturn self.label\n\n\tdef get_score(self):\n\t\tif self.score == -1:\n\t\t\tself.score = self.classes[self.get_label()]\n\n\t\treturn self.score\n\ndef _sigmoid(x):\n\treturn 1. \/ (1. + np.exp(-x))\n\ndef decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n\tgrid_h, grid_w = netout.shape[:2]\n\tnb_box = 3\n\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n\tnb_class = netout.shape[-1] - 5\n\tboxes = []\n\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n\n\tfor i in range(grid_h*grid_w):\n\t\trow = int(i \/ grid_w)\n\t\tcol = int(i % grid_w)\n\t\tfor b in range(nb_box):\n\t\t\t# 4th element is objectness score\n\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n\t\t\tif(objectness.all() <= obj_thresh): continue\n\t\t\t# first 4 elements are x, y, w, and h\n\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n\t\t\tx = (col + x) \/ grid_w # center position, unit: image width\n\t\t\ty = (row + y) \/ grid_h # center position, unit: image height\n\t\t\tw = anchors[2 * b + 0] * np.exp(w) \/ net_w # unit: image width\n\t\t\th = anchors[2 * b + 1] * np.exp(h) \/ net_h # unit: image height\n\t\t\t# last elements are class probabilities\n\t\t\tclasses = netout[int(row)][col][b][5:]\n\t\t\tbox = BoundBox(x-w\/2, y-h\/2, x+w\/2, y+h\/2, objectness, classes)\n\t\t\tboxes.append(box)\n\treturn boxes\n\ndef correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n\tnew_w, new_h = net_w, net_h\n\tfor i in range(len(boxes)):\n\t\tx_offset, x_scale = (net_w - new_w)\/2.\/net_w, float(new_w)\/net_w\n\t\ty_offset, y_scale = (net_h - new_h)\/2.\/net_h, float(new_h)\/net_h\n\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) \/ x_scale * image_w)\n\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) \/ x_scale * image_w)\n\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) \/ y_scale * image_h)\n\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) \/ y_scale * image_h)\n\ndef _interval_overlap(interval_a, interval_b):\n\tx1, x2 = interval_a\n\tx3, x4 = interval_b\n\tif x3 < x1:\n\t\tif x4 < x1:\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn min(x2,x4) - x1\n\telse:\n\t\tif x2 < x3:\n\t\t\t return 0\n\t\telse:\n\t\t\treturn min(x2,x4) - x3\n\ndef bbox_iou(box1, box2):\n\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n\tintersect = intersect_w * intersect_h\n\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n\tunion = w1*h1 + w2*h2 - intersect\n\treturn float(intersect) \/ union\n\ndef do_nms(boxes, nms_thresh):\n\tif len(boxes) > 0:\n\t\tnb_class = len(boxes[0].classes)\n\telse:\n\t\treturn\n\tfor c in range(nb_class):\n\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n\t\tfor i in range(len(sorted_indices)):\n\t\t\tindex_i = sorted_indices[i]\n\t\t\tif boxes[index_i].classes[c] == 0: continue\n\t\t\tfor j in range(i+1, len(sorted_indices)):\n\t\t\t\tindex_j = sorted_indices[j]\n\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n\t\t\t\t\tboxes[index_j].classes[c] = 0\n\n# load and prepare an image\ndef load_image_pixels(filename, shape):\n\t# load the image to get its shape\n\timage = load_img(filename)\n\twidth, height = image.size\n\t# load the image with the required size\n\timage = load_img(filename, target_size=shape)\n\t# convert to numpy array\n\timage = img_to_array(image)\n\t# scale pixel values to [0, 1]\n\timage = image.astype('float32')\n\timage \/= 255.0\n\t# add a dimension so that we have one sample\n\timage = expand_dims(image, 0)\n\treturn image, width, height\n\n# get all of the results above a threshold\ndef get_boxes(boxes, labels, thresh):\n\tv_boxes, v_labels, v_scores = list(), list(), list()\n\t# enumerate all boxes\n\tfor box in boxes:\n\t\t# enumerate all possible labels\n\t\tfor i in range(len(labels)):\n\t\t\t# check if the threshold for this label is high enough\n\t\t\tif box.classes[i] > thresh:\n\t\t\t\tv_boxes.append(box)\n\t\t\t\tv_labels.append(labels[i])\n\t\t\t\tv_scores.append(box.classes[i]*100)\n\t\t\t\t# don't break, many labels may trigger for one box\n\treturn v_boxes, v_labels, v_scores\n\n# draw all results\ndef draw_boxes(filename, v_boxes, v_labels, v_scores):\n\t# load the image\n\tdata = plt.imread(filename)\n\t# plot the image\n\tplt.imshow(data)\n\t# get the context for drawing boxes\n\tax = plt.gca()\n\t# plot each box\n\tfor i in range(len(v_boxes)):\n\t\tbox = v_boxes[i]\n\t\t# get coordinates\n\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n\t\t# calculate width and height of the box\n\t\twidth, height = x2 - x1, y2 - y1\n\t\t# create the shape\n\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n\t\t# draw the box\n\t\tax.add_patch(rect)\n\t\t# draw text and score in top left corner\n\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n\t\tplt.text(x1, y1, label, color='white')\n\t# show the plot\n\tplt.show()","a1a0cb5e":"def encode(df,grid_list, num_box, num_classes, anchors_list, net_h, net_w):    \n    yhat = []\n    length = len(df)\n    boxes = [[]] * len(df)  \n    for index in range(len(df)):\n        print(f'Loading examples {index+1}\/{length}.\\r', end='')\n        r = df.iloc[index,:]\n        filename, width, height, left, top, label = r['index'], r['width'], r['height'], r['left'], r['top'], r['label']\n        origin_x, origin_y = r['image_w_h']\n        bsize = 5 + num_classes\n        grid_boxes = [] \n        for i in range(len(width)):             \n            w, h, x, y, l = width[i], height[i], left[i], top[i], label[i]\n            x = x + w \/ 2\n            y = y + h \/ 2\n            x = x \/ origin_x\n            y = y \/ origin_y     \n            w = w \/ origin_x * net_w\n            h = h \/ origin_y * net_h\n            grid_idx, anchor_idx = get_best_anchor(anchors_list, [w,h])\n            grid = grid_list[grid_idx]\n            grid_x , grid_y = grid, grid\n            \n            x = x * grid_x\n            y = y * grid_y\n            col = int(x)\n            row = int(y)\n            x = x - col\n            y = y - row\n            #x = inv_sigmoid(x)\n            #y = inv_sigmoid(y)\n            w = np.log(w \/ anchors_list[grid_idx][2 * anchor_idx + 0])\n            h = np.log(h \/ anchors_list[grid_idx][2 * anchor_idx + 1])\n            score = 1\n            ybox = np.zeros((bsize,))   \n            ybox[:5] = x,y,w,h,score\n            ybox[5:] = keras.utils.to_categorical(l, num_classes)\n            position = (row,col)\n            bbox = grid_idx, row, col, anchor_idx, ybox.copy()        \n            grid_boxes.append(bbox)\n        boxes[index] = grid_boxes\n    return boxes","91f0b224":"def iou(box1, box2):\n    w1, h1 = box1\n    w2, h2 = box2\n    inter_w = min(w1,w2)\n    inter_h = min(h1,h2)\n    intersect = inter_w * inter_h\n    union = w1 * h1 + w2 * h2 - intersect\n    return intersect \/ union\n\ndef get_best_anchor(anchors, box):\n    l1,l2 = len(anchors),len(anchors[0])\/\/2\n    array_iou = np.zeros((l1,l2))\n    for i in range(l1):\n        anchor = anchors[i]\n        for j in range(l2):\n            array_iou[i,j] = iou(box,[anchor[j*2],anchor[j*2+1]])\n    #print(array_iou)\n    ind = np.unravel_index(np.argmax(array_iou, axis=None), array_iou.shape)\n    return ind","73824eff":"def kmeans_xufive(ds, k):\n    \"\"\"k-means\u805a\u7c7b\u7b97\u6cd5\n\n    k       - \u6307\u5b9a\u5206\u7c07\u6570\u91cf\n    ds      - ndarray(m, n)\uff0cm\u4e2a\u6837\u672c\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6837\u672cn\u4e2a\u5c5e\u6027\u503c\n    \"\"\"\n\n    m, n = ds.shape # m\uff1a\u6837\u672c\u6570\u91cf\uff0cn\uff1a\u6bcf\u4e2a\u6837\u672c\u7684\u5c5e\u6027\u503c\u4e2a\u6570\n    result = np.empty(m, dtype=np.int) # m\u4e2a\u6837\u672c\u7684\u805a\u7c7b\u7ed3\u679c\n    cores = np.empty((k, n)) # k\u4e2a\u8d28\u5fc3\n    cores = ds[np.random.choice(np.arange(m), k, replace=False)] # \u4ecem\u4e2a\u6570\u636e\u6837\u672c\u4e2d\u4e0d\u91cd\u590d\u5730\u968f\u673a\u9009\u62e9k\u4e2a\u6837\u672c\u4f5c\u4e3a\u8d28\u5fc3\n    \n    count=0\n    while True: # \u8fed\u4ee3\u8ba1\u7b97\n        #d = np.square(np.repeat(ds, k, axis=0).reshape(m, k, n) - cores)\n        #distance = np.sqrt(np.sum(d, axis=2)) # ndarray(m, k)\uff0c\u6bcf\u4e2a\u6837\u672c\u8ddd\u79bbk\u4e2a\u8d28\u5fc3\u7684\u8ddd\u79bb\uff0c\u5171\u6709m\u884c\n        count+=1\n        print(f'\\rcount: {count}',end='')\n        distance = np.ones((m,k))\n        for mm in range(m):\n            for kk in range(k):\n                distance[mm,kk] = 1 - iou(ds[mm,:],cores[kk,:])\n        index_min = np.argmin(distance, axis=1) # \u6bcf\u4e2a\u6837\u672c\u8ddd\u79bb\u6700\u8fd1\u7684\u8d28\u5fc3\u7d22\u5f15\u5e8f\u53f7\n\n        if (index_min == result).all(): # \u5982\u679c\u6837\u672c\u805a\u7c7b\u6ca1\u6709\u6539\u53d8\n            return result, cores # \u5219\u8fd4\u56de\u805a\u7c7b\u7ed3\u679c\u548c\u8d28\u5fc3\u6570\u636e\n\n        result[:] = index_min # \u91cd\u65b0\u5206\u7c7b\n        for i in range(k): # \u904d\u5386\u8d28\u5fc3\u96c6\n            items = ds[result==i] # \u627e\u51fa\u5bf9\u5e94\u5f53\u524d\u8d28\u5fc3\u7684\u5b50\u6837\u672c\u96c6\n            cores[i] = np.mean(items, axis=0) # \u4ee5\u5b50\u6837\u672c\u96c6\u7684\u5747\u503c\u4f5c\u4e3a\u5f53\u524d\u8d28\u5fc3\u7684\u4f4d\u7f6e\n                                  \ndef test_cluster(result,cores):\n    plt.scatter(ds[:,0], ds[:,1], s=1, c=result.astype(np.int))\n    plt.scatter(cores[:,0], cores[:,1], marker='x', c=np.arange(k))\n    plt.axis('equal')\n    plt.show()\n\ndef get_box_shape(df, net_h, net_w):    \n    yhat = []\n    length = len(df)\n    box_h = []\n    box_w = []  \n    for index in range(length):\n        #print(f'Loading examples {index+1}\/{length}.\\r', end='')\n        r = df.iloc[index,:]\n        width, height = r['width'], r['height']\n        origin_x, origin_y = r['image_w_h']\n        for i in range(len(width)):             \n            w, h = width[i], height[i]\n            w = w \/ origin_x * net_w\n            h = h \/ origin_y * net_h\n            #box_shape.append((w, h))\n            box_w.append(w)\n            box_h.append(h)     \n    return np.stack((box_w,box_h),axis=1)\n\ndef get_anchors(df):\n    l = get_box_shape(df, 416, 416)\n    #df = pd.DataFrame({'w':l[0],'h':l[1]})\n    result, cores =  kmeans_xufive(l, 9)\n    anchors = np.array(cores, dtype=int)\n    size = [x[0]*x[1] for x in anchors]\n    index = np.argsort(size)[::-1]\n    return anchors[index,:].reshape(3,6).tolist()","c351c044":"#a = get_anchors(df_train) \n# [[99, 335, 75, 314, 59, 323], [62, 249, 45, 292, 46, 207], [32, 250, 34, 159, 21, 116]]","e6ad22ae":"def image_dir(mode):\n    return '..\/input\/streetclassify\/input\/input\/' + mode + '\/'\ndef label_file(mode):\n    return '..\/input\/streetclassify\/input\/input\/' + mode + '.json'\n\ndef get_image_w_h(df, mode):\n    l = len(df)\n    shape = [None] * l\n    for index in range(l):\n        filename = df.loc[index,'index']\n        filename = image_dir(mode) + filename\n        img = plt.imread(filename)\n        shape[index] = img.shape[1], img.shape[0]\n    df['image_w_h'] = shape\n        \ndef get_dataset(mode):\n    if os.path.exists():\n        return pd.read_csv(f'..\/input\/practice-with-svhn\/{mode}.csv')\n    df = pd.read_json(label_file(mode)).T.reset_index()\n    df = df.iloc[:,:]\n    get_image_w_h(df, mode)\n    #df = df_train.head(4)\n    grid_list = [13,26,52]\n    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n    anchors = [[99, 335, 75, 314, 59, 323], [62, 249, 45, 292, 46, 207], [32, 250, 34, 159, 21, 116]]\n\n    boxes = encode(df, grid_list, 3, num_classes, anchors, 416, 416)\n    df[f'grid'] = boxes\n    #train_label = label_padding(df['label'])\n    #digit = keras.utils.to_categorical(train_label, num_classes, dtype='int32')\n    #df['digit'] = list(digit.reshape(digit.shape[0],-1))\n    #df['dhex'] = [int(''.join([str(l[i]) if i<len(l) else 'a' for i in range(6)]),16) for l in df['label']]\n    return df\n\ndef get_submit(file):\n    df = pd.read_csv(file)#.reset_index()\n    return df \n\ndef json_to_dataset(file):\n    df = pd.read_json(file).T.reset_index()\n    label = df['label'].copy()#[train_json[x]['label'] for x in train_json])\n    train_label = label_padding(label)\n    df['digit_raw'] = [int(''.join([str(n) for n in l])) for l in label]\n    digit = keras.utils.to_categorical(train_label, num_classes, dtype='int32')\n    df['digit'] = list(digit.reshape(digit.shape[0],-1))\n    #df[f'Digit'] = train_label.reshape(train_label.shape[0],-1).tolist()\n    train_label = train_label.astype(str)\n    df['Digit'] = train_label.tolist()\n    t = train_label.transpose(1,0)\n    df['count'] = [str(len(l)) for l in label]\n    df['dhex'] = [int(''.join([str(l[i]) if i<len(l) else 'a' for i in range(6)]),16) for l in df['label']]\n    for i in range(6):\n        df[f'D{i}'] = t[i].tolist()\n    return df    ","8d276c51":"df_train = get_dataset('train')\ndf_val = get_dataset('val')\ndf_test = get_submit('..\/input\/streetclassify\/input\/input\/test_A_sample_submit.csv')","70573552":"#a = df_val.iloc[:,:]\n#df_train.to_csv('train.csv')\n#df_val.to_csv('val.csv')","0b6d2c55":"batch_size = 8\ntrain_dir = '..\/input\/streetclassify\/input\/input\/train'\n#train_dir = '..\/input\/street-view-house-numbers\/train\/train'\nval_dir = '..\/input\/streetclassify\/input\/input\/val'\n#val_dir = '..\/input\/street-view-house-numbers\/test\/test'\ntest_dir = '..\/input\/streetclassify\/input\/input\/test_a'\n#int_to_char = ['zero','one','two', 'three', 'four','five','six','seven','eight','nine','ten']\nint_to_char = ['0','1','2', '3', '4','5','6','7','8','9','10']\n\ntrainGen = keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                        #rotation_range=5,\n                                                        #width_shift_range=0.2,\n                                                        #height_shift_range=0.2,\n                                                        #channel_shift_range=0.2,\n                                                        #zoom_range=0.2,\n                                                        #validation_split=0.3\n                                                       )\ntrain_gen = trainGen.flow_from_dataframe(df_train.iloc[:],                 #dataframe\n                                               #directory=train_folder,     #\u6839\u76ee\u5f55\uff08\u5f53\u524d\u8def\u5f84\uff09\n                                               directory=train_dir,     #\u6839\u76ee\u5f55\uff08\u5f53\u524d\u8def\u5f84\uff09\n                                               x_col='index',\n                                               #y_col='dhex',#'D0',\n                                               y_col='grid',#'D0',\n                                               #y_col=['D0','D1','D2','D3','D4','D5'],\n                                               #classes=int_to_char[:],\n                                               target_size=input_shape[0:2],\n                                               batch_size=batch_size,\n                                               seed=3,\n                                               shuffle=True,\n                                               class_mode='raw',\n                                              )\nvalidGen = keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\nvalid_gen = validGen.flow_from_dataframe(df_val.iloc[:],                 #dataframe\n                                               #directory=train_folder,     #\u6839\u76ee\u5f55\uff08\u5f53\u524d\u8def\u5f84\uff09 \n                                               directory=val_dir,     #\u6839\u76ee\u5f55\uff08\u5f53\u524d\u8def\u5f84\uff09 \n                                               x_col='index',\n                                               #y_col='dhex',#'D0',\n                                               y_col='grid',\n                                               #y_col=['D0','D1','D2','D3','D4','D5'],\n                                               #classes=int_to_char[:],\n                                               target_size=input_shape[0:2],\n                                               batch_size=batch_size,\n                                               seed=3,\n                                               shuffle=False,\n                                               class_mode='raw',\n                                              )\ntest_gen =  validGen.flow_from_dataframe(df_test.iloc[:],\n                                               directory=test_dir,\n                                               x_col='file_name',\n                                               y_col=None,\n                                               target_size=input_shape[0:2],\n                                               batch_size=batch_size,\n                                               seed=3,\n                                               shuffle=False,\n                                               class_mode=None,\n                                              )\n#'multi_output',)\"binary\", \"categorical\", \"input\", \"multi_output\", \"raw\", sparse\" or None.\ndef MyGenerator(generator):\n    grid_list = [13,26,52]\n    anchors = [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]\n    \n    num_box = len(anchors[0])\/\/2\n    while(True):\n        x, y = next(generator)\n        bz = y.shape[0]\n        box_size = y[0][0][4].shape[0]\n        y_true = [np.zeros((bz,g,g,num_box*box_size)) for g in grid_list]        \n        for index in range(bz):\n            for grid in y[index]:\n                grid_index, row, col, b = grid[:4]\n                y_true[grid_index][index, row, col, b*box_size:(b+1)*box_size] = grid[4]\n        #b = dhex_to_sparse(y)\n        #y = keras.utils.to_categorical(b,11).reshape(-1,66)\n        yield x,y_true\n        \ntrain_generator = MyGenerator(train_gen)\nvalid_generator = MyGenerator(valid_gen)\ntest_generator = MyGenerator(test_gen)","bc084fc8":"def get_sample(df, **kw):\n    i = np.random.randint(len(df)) \n    if 'array' in kw:\n        i = np.random.randint(len(array))\n        img = array[i]\n        label = df[\"label\"][i]\n        print(f'From array:')\n    elif 'generator' in kw:\n        #img = next(generator)[0][0]\n        #img = trainGen.random_transform(x_train[i],seed=None)\n        generator = kw['generator']\n        bz = generator.batch_size\n        #i=0\n        img = generator[i\/\/bz][0][i%bz,...]\n        label = generator[i\/\/bz][1][i%bz]\n        label = hex(label)\n        print(i)\n        print(f'From generator:')\n    else:\n        path = f'..\/input\/street-view-house-numbers\/train\/train\/{df[\"index\"][i]}'\n        path = f'..\/input\/streetclassify\/input\/input\/train\/{df[\"index\"][i]}'\n        print(path)\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        label = df[\"label\"][i]\n        print('From path:')\n    plt.imshow(img)\n    print(f'Example {i}:')\n    print(f'shape: {img.shape}')\n    print(f'label: {label}')\n    return img\n\n#img = get_sample(df_train.iloc[:1,:])#, generator=train_generator","3d7d4131":"class LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []        \n        self.accuracy = []\n        self.accuracy1 = []\n        self.accuracy2 = []\n\n        self.val_losses = []\n        self.val_accuracy = []\n        \n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        self.accuracy.append(logs.get('my_metric_fn')) \n    \n        #self.val_losses.append(logs.get('val_loss'))   \n        #self.val_acc.append(logs.get('val_acc'))\n        \ndef dhex_to_sparse(a):\n    output_list = []\n    for _ in range(6):\n        output_list.append(a % 16)\n        a = a\/\/16    \n    outputs = K.stack(output_list[::-1],1)\n    y = outputs\n    return y\n\ndef yolo_loss(y_true, y_pred):\n    y_true = tf.reshape(y_true,(-1,6,11)) \n    y_pred = tf.reshape(y_pred,(-1,6,11))\n    losses = keras.losses.categorical_crossentropy(y_true, y_pred)\n    return K.sum(losses,-1)\n\ndef yolo_metric(y_true, y_pred):\n    y_true = tf.reshape(y_true,(-1,6,11)) \n    y_pred = tf.reshape(y_pred,(-1,6,11))\n    return K.cast(K.sum(K.cast(K.equal(K.argmax(y_true),\n                          K.argmax(y_pred)), \n                               K.floatx()), \n                        axis=-1)==6,\n                  K.floatx())","f327c3b1":"def simple():\n    model = keras.Sequential(\n        [\n            keras.Input(shape=input_shape),\n            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n            layers.MaxPooling2D(pool_size=(2, 2)),\n            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n            layers.MaxPooling2D(pool_size=(2, 2)),\n        ]\n    )\n    return model\n\ndef fixed():\n    pre_model = keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=input_shape)\n    x = layers.Flatten()(pre_model.output)\n    x = [layers.Dense(num_classes, activation=\"softmax\")(x) for i in range(6)]\n    outputs = layers.concatenate(x)\n    #out = layers.Dense(num_classes, activation=\"softmax\")(pre_model.output)\n    model = keras.Model(inputs=pre_model.inputs,outputs=outputs)\n    return model\n\ndef yolo():\n    pre_model = keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=input_shape)\n    outputs = layers.Conv2D(32, kernel_size=(1, 1), activation=\"relu\")(pre_model.output)\n    model = keras.Model(inputs=pre_model.inputs,outputs=outputs)\n    return model\n\ndef create_model():\n    model = yolo()    \n    #model = keras.models.load_model(f'..\/input\/practice-with-svhn\/{model_file}', custom_objects=custom_objects)\n    opt = keras.optimizers.Adam(lr=0.001)\n    model.compile(opt, loss=yolo_loss, metrics=[yolo_metric])\n    \n    return model","797b0c40":"model_version = 3\nmodel_file = f'model_v{model_version}.h5'","095018fd":"custom_objects={                         \n                }\n#model = keras.models.load_model(f'..\/input\/practice-with-svhn\/model_v2.h5')\n#model = keras.models.load_model(f'..\/input\/practice-with-svhn\/{model_file}', custom_objects=custom_objects)\n#batch_size = 32\n#H = model.fit(x_train, y_true, batch_size=batch_size,epochs=epochs,validation_split=0.1)","f5100a86":"#model = create_model()","6f84b45d":"logdir = os.path.join('hourse_num')#'.\/hourse_num'\nif not os.path.exists(logdir):\n    os.mkdir(logdir)\n    \noutput_model_file = os.path.join(logdir, model_file)\n\ncallbacks=[\n    keras.callbacks.TensorBoard(logdir),\n    keras.callbacks.ModelCheckpoint(output_model_file,\n                                    save_best_only = True,\n                                    save_weights_only = False),\n    keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3),\n    LossHistory()\n]","adeb0a9f":"opt = keras.optimizers.Adam(lr=0.001)\nmodel.compile(opt, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"])","99798e3d":"#from kaggle_secrets import UserSecretsClient\n#user_secrets = UserSecretsClient()\n#user_credential = user_secrets.get_gcloud_credential()\n#user_secrets.set_tensorflow_credential(user_credential)\nepochs = 1\n\n#batch_size = 32\ntrain_num = train_gen.samples\nvalid_num = valid_gen.samples\nprint(train_num, valid_num)\n#history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1,shuffle=True)\nh = LossHistory()\n#H = model.fit_generator(train_generator)\nH = model.fit_generator(train_generator,\n                        steps_per_epoch=train_num\/\/batch_size,\n                        validation_data=MyGenerator(valid_generator),\n                        validation_steps=valid_num\/\/batch_size,                              \n                        epochs=epochs,\n                        callbacks=[callbacks])","aab1f796":"model.save('model_v3.h5')\n#model.save(model_file)\n#model = keras.models.load_model(callbacks[1].filepath,custom_objects)\n#model = keras.models.load_model('model_v4.h5')","57d89e8a":"# plot the training loss and accuracy\nN = epochs\nplt.style.use(\"ggplot\")\n\nplt.figure()\n#plt.plot(H.history[\"loss\"], label=\"train_loss\")\nh = callbacks[3]\nplt.plot(h.losses, label=\"train_loss\")\n\n#plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"lower left\")\n\nplt.savefig(\"loss.png\")\n\n#plt.figure()\n#plt.plot(H.history[\"loss\"], label=\"train_loss\")\n#plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n#plt.plot(H.history[\"sparse_metric_fn\"], label=\"train_accuracy\")\n#plt.plot(H.history[\"val_sparse_metric_fn\"], label=\"val_accuracy\")\n#plt.title(\"Accuracy\")\n#plt.xlabel(\"Epoch #\")\n#plt.ylabel(\"Accuracy\")\n#plt.legend(loc=\"lower left\")\n\n#plt.savefig(\"accuracy.png\")","339b8d4e":"%load_ext tensorboard\n\n# Open an embedded TensorBoard viewer\n%tensorboard --logdir {hourse_num}","d1a32881":"NUM_TEST_IMAGES = valid_gen.samples\nevaluater = model.evaluate_generator(valid_generator,\n\tsteps=(NUM_TEST_IMAGES \/\/ batch_size) + 1, verbose=1)","cf8e3163":"# Get False Labeled\nNUM_TEST_IMAGES = valid_gen.n\n#predIdxs = model.predict_generator(val, steps=(NUM_TEST_IMAGES \/\/ batch_size) + 1, verbose=1)\ntrain_gen[0][0][0:1]\npredIdxs = model.predict(train_gen[0][0][0:1])\n#print(predIdxs[0].reshape(-1,6,11).argmax(-1))\n#predIdxs.shape","5479e89a":"for x in predIdxs:\n    print(x.shape)","eb33c567":"from numpy import expand_dims\nfrom keras.models import load_model\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom matplotlib import pyplot\nfrom matplotlib.patches import Rectangle\n\nclass BoundBox:\n    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n        self.xmin = xmin\n        self.ymin = ymin\n        self.xmax = xmax\n        self.ymax = ymax\n        self.objness = objness\n        self.classes = classes\n        self.label = -1\n        self.score = -1\n\n    def get_label(self):\n        if self.label == -1:\n            self.label = np.argmax(self.classes)\n\n        return self.label\n\n    def get_score(self):\n        if self.score == -1:\n            self.score = self.classes[self.get_label()]\n\n        return self.score\n\ndef _sigmoid(x):\n    return 1. \/ (1. + np.exp(-x))\n\ndef decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n    grid_h, grid_w = netout.shape[:2]\n    nb_box = 3\n    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n    nb_class = netout.shape[-1] - 5\n    boxes = []\n    netout[..., :2]  = _sigmoid(netout[..., :2])\n    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n\n    for i in range(grid_h*grid_w):\n        row = i \/ grid_w\n        col = i % grid_w\n        for b in range(nb_box):\n            # 4th element is objectness score\n            objectness = netout[int(row)][int(col)][b][4]\n            if(objectness.all() <= obj_thresh): continue\n            # first 4 elements are x, y, w, and h\n            x, y, w, h = netout[int(row)][int(col)][b][:4]\n            x = (col + x) \/ grid_w # center position, unit: image width\n            y = (row + y) \/ grid_h # center position, unit: image height\n            w = anchors[2 * b + 0] * np.exp(w) \/ net_w # unit: image width\n            h = anchors[2 * b + 1] * np.exp(h) \/ net_h # unit: image height\n            # last elements are class probabilities\n            classes = netout[int(row)][col][b][5:]\n            box = BoundBox(x-w\/2, y-h\/2, x+w\/2, y+h\/2, objectness, classes)\n            boxes.append(box)\n    return boxes\n\ndef correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n    new_w, new_h = net_w, net_h\n    for i in range(len(boxes)):\n        x_offset, x_scale = (net_w - new_w)\/2.\/net_w, float(new_w)\/net_w\n        y_offset, y_scale = (net_h - new_h)\/2.\/net_h, float(new_h)\/net_h\n        boxes[i].xmin = int((boxes[i].xmin - x_offset) \/ x_scale * image_w)\n        boxes[i].xmax = int((boxes[i].xmax - x_offset) \/ x_scale * image_w)\n        boxes[i].ymin = int((boxes[i].ymin - y_offset) \/ y_scale * image_h)\n        boxes[i].ymax = int((boxes[i].ymax - y_offset) \/ y_scale * image_h)\n\ndef _interval_overlap(interval_a, interval_b):\n    x1, x2 = interval_a\n    x3, x4 = interval_b\n    if x3 < x1:\n        if x4 < x1:\n            return 0\n        else:\n            return min(x2,x4) - x1\n    else:\n        if x2 < x3:\n             return 0\n        else:\n            return min(x2,x4) - x3\n\ndef bbox_iou(box1, box2):\n    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n    intersect = intersect_w * intersect_h\n    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n    union = w1*h1 + w2*h2 - intersect\n    return float(intersect) \/ union\n\ndef do_nms(boxes, nms_thresh):\n    if len(boxes) > 0:\n        nb_class = len(boxes[0].classes)\n    else:\n        return\n    for c in range(nb_class):\n        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n        for i in range(len(sorted_indices)):\n            index_i = sorted_indices[i]\n            if boxes[index_i].classes[c] == 0: continue\n            for j in range(i+1, len(sorted_indices)):\n                index_j = sorted_indices[j]\n                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n                    boxes[index_j].classes[c] = 0\n\n# load and prepare an image\ndef load_image_pixels(filename, shape):\n    # load the image to get its shape\n    image = load_img(filename)\n    width, height = image.size\n    # load the image with the required size\n    image = load_img(filename, target_size=shape)\n    # convert to numpy array\n    image = img_to_array(image)\n    # scale pixel values to [0, 1]\n    image = image.astype('float32')\n    image \/= 255.0\n    # add a dimension so that we have one sample\n    image = expand_dims(image, 0)\n    return image, width, height\n\n# get all of the results above a threshold\ndef get_boxes(boxes, labels, thresh):\n    v_boxes, v_labels, v_scores = list(), list(), list()\n    # enumerate all boxes\n    for box in boxes:\n        # enumerate all possible labels\n        for i in range(len(labels)):\n            # check if the threshold for this label is high enough\n            if box.classes[i] > thresh:\n                v_boxes.append(box)\n                v_labels.append(labels[i])\n                v_scores.append(box.classes[i]*100)\n                # don't break, many labels may trigger for one box\n    return v_boxes, v_labels, v_scores\n\n# draw all results\ndef draw_boxes(filename, v_boxes, v_labels, v_scores):\n    # load the image\n    data = pyplot.imread(filename)\n    # plot the image\n    pyplot.imshow(data)\n    # get the context for drawing boxes\n    ax = pyplot.gca()\n    # plot each box\n    for i in range(len(v_boxes)):\n        box = v_boxes[i]\n        # get coordinates\n        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n        # calculate width and height of the box\n        width, height = x2 - x1, y2 - y1\n        # create the shape\n        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n        # draw the box\n        ax.add_patch(rect)\n        # draw text and score in top left corner\n        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n        pyplot.text(x1, y1, label, color='white')\n    # show the plot\n    pyplot.show()\n\n# load yolov3 model\n#model = load_model('model.h5')\n# define the expected input shape for the model\ninput_w, input_h = 416, 416\n# define our new photo\nphoto_filename = image_dir('train') + '\/000000.png'\n# load and prepare image\nimage, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n# make prediction\nyhat = model.predict(image)\n# summarize the shape of the list of arrays\nprint([a.shape for a in yhat])\n# define the anchors\nanchors = [[99, 335, 75, 314, 59, 323], [62, 249, 45, 292, 46, 207], [32, 250, 34, 159, 21, 116]]\n# define the probability threshold for detected objects\nclass_threshold = 0.6\nboxes = list()\nfor i in range(len(yhat)):\n    # decode the output of the network\n    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n# correct the sizes of the bounding boxes for the shape of the image\ncorrect_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n# suppress non-maximal boxes\ndo_nms(boxes, 0.5)\n# define the labels\nlabels = ['0','1','2', '3', '4','5','6','7','8','9','10']\n# get the details of the detected objects\nv_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n# summarize what we found\nfor i in range(len(v_boxes)):\n    print(v_labels[i], v_scores[i])\n# draw what we found\ndraw_boxes(photo_filename, v_boxes, v_labels, v_scores)","b2b9b95d":"def predict(predIdxs):\n    p_list = [None] * predIdxs.shape[0]\n    p = predIdxs.reshape(-1,6,11).argmax(-1)\n    for i in range(p.shape[0]):\n        l = ''\n        for j in range(p.shape[1]):\n            if p[i,j]==10:\n                break        \n            l += str(p[i,j])\n        p_list[i] = l\n    return p_list\n\ndf = pd.DataFrame({'x': df_val['index'],\n                   'label': df_val['label'],\n                   'prediction': predict(predIdxs),\n                  })\ndf['acc'] = sparse_metric_fn(df_val['dhex'],predIdxs)\nd = df.query('acc != 1')\ni=50","eff539ff":"#i = np.random.randint(len(df))\nexample = d.iloc[i,:]\npath = f'..\/input\/streetclassify\/input\/input\/val\/{example[\"x\"]}'\nprint(path)\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nlabel1 = example[\"label\"]\nlabel2 = example[\"prediction\"]\n\nprint('From path:')\nplt.imshow(img)\n#print(f'Example {i}:')\n#print(f'shape: {img.shape}')\nprint(f'label: {label1}')\nprint(f'prediction: {label2}')\ni=i+1","99cf035a":"NUM_TEST_IMAGES = test_generator.samples\n#predIdxs = model.predict_generator(test_generator, steps=(NUM_TEST_IMAGES \/\/ batch_size) + 1, verbose=1)\npredIdxs = model.predict(x_train[:10])\nprint(predIdxs[0:10].reshape(-1,6,11).argmax(-1))\n\npredIdxs.shape","b1153f4e":"submit_path = '..\/input\/streetclassify\/input\/input\/test_A_sample_submit.csv'\ndf_submit = pd.read_csv(submit_path)\ndf_submit['file_code'] = predict(predIdxs)\ndf_submit.to_csv('test_submit.csv')\ndf_submit\n#predict(predIdxs)","3da03804":"# Get Started"}}