{"cell_type":{"743df918":"code","e603325a":"code","c2bd3320":"code","6f243aec":"code","4f763087":"code","c2ac24d4":"code","7e7b8e0e":"code","391bdeb7":"code","4d777bde":"code","6698e631":"code","d0296d8c":"code","102ba627":"code","31d24c52":"code","b520cfa5":"code","3f4bc190":"code","d6112976":"code","426fd467":"code","1d9524e5":"code","adf46f97":"code","c6ba4447":"code","b682bdd7":"code","3b54045e":"code","658d631b":"code","ec92e4dc":"code","1cc210ca":"code","1fc168d8":"code","e7b21d88":"code","b297ef47":"code","95b4024f":"code","ec452ea8":"code","60afe0da":"code","de875280":"code","202cca6d":"code","dfaf563d":"code","1936586e":"code","499e9e11":"code","071e0db0":"code","d46378d8":"code","7d05fa5b":"code","62a59e7b":"code","66fa5daf":"code","4c689205":"code","e7210949":"code","29345601":"code","a96ecef4":"code","4c5b842c":"code","5297204d":"code","4163d0f5":"code","d1aa5dbc":"code","7326f676":"code","d583f91c":"code","b9923584":"code","3dd20b11":"code","e73d5c43":"code","445bca5b":"code","08a6835d":"code","1cd209c7":"code","0d4df37b":"code","edc1cf5f":"code","b5f3a346":"code","4705bf40":"code","4e751576":"code","7c35156f":"code","e002a767":"code","0be65f58":"code","4c6e53b7":"code","361e0b52":"code","08cf2289":"code","78cb3d6a":"code","e6894366":"code","089502fa":"code","a456c863":"code","49e4406f":"code","c5d6c032":"code","82750cfd":"code","71a4987b":"code","84f0aad9":"code","e93b11fe":"code","82b690d4":"code","bf05c6d7":"code","49efb8b3":"code","b276c0a4":"code","27559dfc":"code","1b82f3cc":"code","e121f642":"code","27fe0fe3":"code","bc2cbbb4":"code","ae61b3ac":"code","3e1a035e":"code","ccebd795":"code","5fac670f":"code","b63241e4":"code","afba01d8":"code","df00342b":"code","df41f7c3":"code","e04b2325":"code","a9f1f429":"code","b9010627":"code","3cb657d6":"code","b48c8bfd":"code","1a50b9e4":"code","21183b8f":"code","013c01fe":"markdown","4288d4bc":"markdown","946ec2b4":"markdown","1de219c9":"markdown","a0207053":"markdown","a9cf4f8d":"markdown","589de8e1":"markdown","a75c24e0":"markdown","50879d9a":"markdown","3e0230dc":"markdown","408681e2":"markdown","be9d6f6a":"markdown","647a731c":"markdown","9769092a":"markdown","70501566":"markdown","c06eb40d":"markdown","eb1771d6":"markdown","dbc813e9":"markdown","03b9d6f0":"markdown","768eb88d":"markdown","5b55df64":"markdown","789f7c54":"markdown","b7aea4a7":"markdown","ce230992":"markdown","bb97e905":"markdown","caba2ed9":"markdown","9221f779":"markdown","c0a5080c":"markdown","654004b1":"markdown","3f3e886d":"markdown","2d8b840d":"markdown","5c0e4cd5":"markdown","d094295f":"markdown","306d381c":"markdown","9b2b0382":"markdown","4452a708":"markdown"},"source":{"743df918":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e603325a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nimport os\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import LocalOutlierFactor\n\npd.pandas.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","c2bd3320":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head(5)","6f243aec":"# How to catch outliers ?\n\nq1 = df['Age'].quantile(0.25)\nq3 = df['Age'].quantile(0.75)\niqr = q3 - q1  # iqr = Interquartile range\n\nup = q3 + 1.5 * iqr\nlow = q1 -1.5 * iqr\n\nprint(low, up)","4f763087":"# Is there any outlier or not ?\n\ndf[(df[\"Age\"] > up) | (df[\"Age\"] < low)].any(axis=None)\n","c2ac24d4":"def outlier_thresholds(dataframe, col_name):\n        quartile1 = dataframe[col_name].quantile(0.25)\n        quartile3 = dataframe[col_name].quantile(0.75)\n        interquantile_range = quartile3 - quartile1\n        up_limit = quartile3 + 1.5 * interquantile_range\n        low_limit = quartile1 - 1.5 * interquantile_range\n        return low_limit, up_limit\n\noutlier_thresholds(df, \"Fare\")\n\nlow, up = outlier_thresholds(df, \"Fare\")\nprint(low, up)","7e7b8e0e":"# Outliers are only valied for numerical variables\n\nnum_cols = [col for col in df.columns if df[col].dtypes != 'O' and col != 'PassengerId']\nprint(num_cols)","391bdeb7":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\n\nfor i in num_cols:\n    print(i, check_outlier(df, i))","4d777bde":"def grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\ngrab_outliers(df, \"Age\")","6698e631":"grab_outliers(df, \"Age\", True)","d0296d8c":"# RECAP\n\n\n# outlier_thresholds(df, \"Age\")\n# check_outlier(df, \"Age\")\n# grab_outliers(df, \"Age\", True)","102ba627":"def remove_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers","31d24c52":"for i in num_cols:\n    df = remove_outlier(df, i)  \n    \nprint(df)","b520cfa5":"# Let's check df after removing outliers\n\ndf[(df[\"Age\"] > up) | (df[\"Age\"] < low)].any(axis=None)","3f4bc190":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')","d6112976":"# In this function, instead of assign variable, 'loc' has been used. Changes become permanent on their own, no need to assign\n\ndef replace_with_thresholds(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if low_limit > 0:\n        dataframe.loc[(dataframe[col_name] < low_limit), col_name] = low_limit\n        dataframe.loc[(dataframe[col_name] > up_limit), col_name] = up_limit\n    else:\n        dataframe.loc[(dataframe[col_name] > up_limit), col_name] = up_limit","426fd467":"for col in num_cols:\n    print(col, check_outlier(df, col))","1d9524e5":"for col in num_cols:\n    replace_with_thresholds(df, col)","adf46f97":"# Let's check df after re=assign outliers\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))","c6ba4447":"# RECAP\n\n# outlier_thresholds(df, \"Age\")\n# check_outlier(df, \"Age\")\n# grab_outliers(df, \"Age\", index=True)","b682bdd7":"dff = pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ndff.head()","3b54045e":"# Removing numerical variables \n\ndff.drop(['cut','color', 'clarity'], axis=1, inplace = True)\ndff.head()","658d631b":"clf = LocalOutlierFactor(n_neighbors=20)\nclf.fit_predict(dff)\ndff_scores = clf.negative_outlier_factor_","ec92e4dc":"# To understand LOF scores and data, adding LOF scores as a variable\n\ndff['LOF_scores'] = dff_scores\ndff.sort_values('LOF_scores', ascending=False)","1cc210ca":"# Finding threshold by using cores on the chart\n\nscores = pd.DataFrame(np.sort(dff_scores))\nscores.plot(stacked=True, xlim=[0, 20], style='.-')\nplt.show()","1fc168d8":"# As seen, there is an elbow at around 3 point. This is threshold. \n\nthreshold_value = np.sort(dff_scores)[3]\nprint(threshold_value)","e7b21d88":"# Outliers\n\ndff[dff_scores < threshold_value]\n","b297ef47":"dff[dff_scores < threshold_value].drop(axis=0, labels=dff[dff_scores < threshold_value].index)","95b4024f":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\n\ndf.head()","ec452ea8":"# Is there any missing value? \n\ndf.isnull().any()","60afe0da":"# Sum of missing values?\n\ndf.isnull().sum()","de875280":"# Number and ration of missing values\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns\n\nmissing_values_table(df)\nmissing_values_table(df, True)","202cca6d":"df.dropna()","dfaf563d":"#  Mean works for just numerical variables\n\ndff = df.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0)\n\ndff.isnull().sum()","1936586e":"# Median or mod can be used for categorical variables\n# If number of value more than 10, that variable has high cardinality ('Cabin')\n\ndff = dff.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0)\n\ndff.isnull().sum()","499e9e11":"V1 = np.array([1, 3, 6, np.NaN, 7, 1, np.NaN, 9, 15])\nV2 = np.array([7, np.NaN, 5, 8, 12, np.NaN, np.NaN, 2, 3])\nV3 = np.array([np.NaN, 12, 5, 6, 14, 7, np.NaN, 2, 31])\n\ndf = pd.DataFrame(\n    {\"V1\": V1,\n     \"V2\": V2,\n     \"V3\": V3}\n)\n\nprint(df)","071e0db0":"from sklearn.impute import SimpleImputer\n\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n\nimp_mean.fit(df)\nimp_mean.transform(df)","d46378d8":"V1 = np.array([1, 3, 6, np.NaN, 7, 1, np.NaN, 9, 15])\nV2 = np.array([7, np.NaN, 5, 8, 12, np.NaN, np.NaN, 2, 3])\nV3 = np.array([np.NaN, 12, 5, 6, 14, 7, np.NaN, 2, 31])\nV4 = np.array([\"IT\", \"IT\", \"IK\", \"IK\", \"IK\", \"IK\", \"IT\", \"IT\", \"IT\"])\n\ndf = pd.DataFrame(\n    {\"salary\": V1,\n     \"V2\": V2,\n     \"V3\": V3,\n     \"departman\": V4}\n)\n\nprint(df)","7d05fa5b":"V1 = np.array([1, 3, 6, np.NaN, 7, 1, np.NaN, 9, 15])\n","62a59e7b":"# Assign values according to average in their departments, more sensitive assignment\n\ndf[\"salary\"].fillna(df.groupby(\"departman\")[\"salary\"].transform(\"mean\"))","66fa5daf":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')","4c689205":"# These methods are used to define non-random missing values. ","e7210949":"msno.bar(df)\nplt.show()","29345601":"msno.matrix(df)\nplt.show()","a96ecef4":"msno.heatmap(df)\nplt.show()","4c5b842c":"na_cols = missing_values_table(df, True)\n\ndef missing_vs_target(dataframe, target, na_columns):\n    temp_df = dataframe.copy()\n    for col in na_columns:\n        temp_df[col + '_NA_FLAG'] = np.where(temp_df[col].isnull(), 1, 0)\n            ## ONEMLI, EKSIK GORDUGUN YERE BIR DIGERINE SIFIR YAZ\n    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_NA_\")].columns\n    for col in na_flags:\n        print(pd.DataFrame({\"TARGET_MEAN\": temp_df.groupby(col)[target].mean(),\n                            \"Count\": temp_df.groupby(col)[target].count()}), end=\"\\n\\n\\n\")\n\nmissing_vs_target(df, \"Survived\", na_cols)","5297204d":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","4163d0f5":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit_transform(df['Sex'])[0:5]","d1aa5dbc":"# Way to see which one is zero\n\nle.inverse_transform([0, 1])\n","7326f676":"def label_encoder(dataframe, binary_col):\n    labelencoder = preprocessing.LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n","d583f91c":"binary_cols = [col for col in df.columns if df[col].dtypes == \"O\"\n               and len(df[col].unique()) == 2]","b9923584":"for i in binary_cols:\n    label_encoder(df,i)","3dd20b11":"# In our stituation just'Sex' variable is binary.\n\ndf.head()","e73d5c43":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","445bca5b":"pd.get_dummies(df, columns = ['Embarked']).head()","08a6835d":"# Missing values for Embarked also added as a variable\n\npd.get_dummies(df, columns=[\"Embarked\"], dummy_na=True).head()","1cd209c7":"# Dummy variable trap.\n\npd.get_dummies(df, columns=[\"Embarked\"], drop_first=True).head()","0d4df37b":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","edc1cf5f":"# functionalize\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\n\nohe_cols = [col for col in df.columns if 10 >= len(df[col].unique()) > 2]","b5f3a346":"one_hot_encoder(df, ohe_cols).head()","4705bf40":"one_hot_encoder(df, ohe_cols, drop_first=True).head()","4e751576":"df = pd.read_csv('..\/input\/application-train\/application_train.csv')\ndf.head()","7c35156f":"df[\"NAME_EDUCATION_TYPE\"].value_counts()","e002a767":"cat_cols = [col for col in df.columns if df[col].dtypes == 'O']","0be65f58":"def cat_summary(dataframe, col_name):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print('### ### ### ### ### ### ### ')\n    ax = sns.countplot(x=dataframe[col_name], data=dataframe)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n    plt.tight_layout()\n    plt.show()","4c6e53b7":"for i in cat_cols:\n    cat_summary(df, i)","361e0b52":"df.groupby('NAME_INCOME_TYPE').agg({'TARGET' : 'mean'})","08cf2289":"df['NAME_INCOME_TYPE'].value_counts() \/ len(df)","78cb3d6a":"# Rare variables, threshold is 10%\n\n[i for i in df.columns if df[i].dtypes == 'O' and (df[i].value_counts() \/ len(df) < 0.10).any(axis = None)]","e6894366":"df = pd.read_csv('..\/input\/application-train\/application_train.csv')\ndf.head()","089502fa":"def rare_analyser(dataframe, target, rare_perc):\n\n    rare_columns = [col for col in dataframe.columns if dataframe[col].dtypes == 'O'\n                    and (dataframe[col].value_counts() \/ len(dataframe) < rare_perc).any(axis=None)]\n\n    for col in rare_columns:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n\nrare_analyser(df, \"TARGET\", 0.01)","a456c863":"def rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n                    and (temp_df[col].value_counts() \/ len(temp_df) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() \/ len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n\n    return temp_df\n\n\nnew_df = rare_encoder(df, 0.01)","49e4406f":"# Let's check it, after encoding \n\nnew_df[new_df[\"ORGANIZATION_TYPE\"].str.contains(\"Rare\")].head()","c5d6c032":"rare_analyser(new_df, \"TARGET\", 0.01)","82750cfd":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","71a4987b":"from sklearn.preprocessing import StandardScaler","84f0aad9":"scaler = StandardScaler().fit(df[[\"Age\"]])\ndf[\"Age\"] = scaler.transform(df[[\"Age\"]])\ndf[\"Age\"].head(10)","e93b11fe":"df[\"Age\"].describe().T","82b690d4":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","bf05c6d7":"from sklearn.preprocessing import RobustScaler","49efb8b3":"transformer = RobustScaler().fit(df[[\"Age\"]])\ndf[\"Age\"] = transformer.transform(df[[\"Age\"]])\ndf[\"Age\"].describe().T","b276c0a4":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","27559dfc":"from sklearn.preprocessing import MinMaxScaler","1b82f3cc":"transformer = MinMaxScaler().fit(df[[\"Age\"]])\ndf[\"Age\"] = transformer.transform(df[[\"Age\"]])\n\ndf[\"Age\"].describe().T","e121f642":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","27fe0fe3":"df[\"Age\"] = np.log(df[\"Age\"])\ndf[\"Age\"].describe().T","bc2cbbb4":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","ae61b3ac":"df.loc[df['Age'] < 18, 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['Age'] >= 18) & (df['Age'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['Age'] >= 56), 'NEW_AGE_CAT'] = 'senior'\n\ndf.head(15)","3e1a035e":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","ccebd795":"# A value of 1 is assigned to those whose cabin information is not empty\n\ndf['NEW_CABIN_BOOL'] = df['Cabin'].notnull().astype('int')\n\ndf.head()","5fac670f":"# if sum of 'SibSp' and 'Parch' more than 0, add a new variable called 'NEW_IS_ALONE' and assign 'NO' for these passenger.\n\ndf.loc[((df['SibSp'] + df['Parch']) > 0), \"NEW_IS_ALONE\"] = \"NO\"\ndf.head(10)","b63241e4":"df[\"NEW_NAME_COUNT\"] = df['Name'].str.len()\n\n# OR\n\n# df[\"NEW_NAME_COUNT\"]  = df['Name'].apply(lambda x: len(x))","afba01d8":"df.head()","df00342b":"df[\"NEW_NAME_WORD_COUNT\"] = df[\"Name\"].apply(lambda x: len(str(x).split(\" \")))\ndf.head()","df41f7c3":"# Finding passenger who has doctor title, and assignment as new variable called 'NEW_NAME_DR'\n\ndf[\"NEW_NAME_DR\"] = df[\"Name\"].apply(lambda x: len([x for x in x.split() if x.startswith(\"Dr\")]))\n","e04b2325":"df[\"NEW_NAME_DR\"]","a9f1f429":"# There were 10 doctors and half of it survived.\n\ndf.groupby(\"NEW_NAME_DR\").agg({\"Survived\": [\"mean\", \"count\"]})","b9010627":"df = pd.read_csv('..\/input\/d\/atilaysamiloglu\/titanic\/titanic.csv')\ndf.head()","3cb657d6":"df['NEW_TITLE'] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in df.Name]\ndf['NEW_TITLE'].head()","b48c8bfd":"df.head()","1a50b9e4":"df.loc[(df['Sex'] == 'male') & (df['Age'] <= 21), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['Sex'] == 'male') & ((df['Age'] > 21) & (df['Age']) < 50), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['Sex'] == 'male') & (df['Age'] > 50), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['Sex'] == 'female') & (df['Age'] <= 21), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['Sex'] == 'female') & ((df['Age'] > 21) & (df['Age']) < 50), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['Sex'] == 'female') & (df['Age'] > 50), 'NEW_SEX_CAT'] = 'seniorfemale'","21183b8f":"df.head(10)","013c01fe":"# 1. STANDARTSCALER\n\n### z = (x - u) \/ s\n\n### u: mean\n### s: standard deviation","4288d4bc":"# OUTLIERS","946ec2b4":"## Assignment with Scikit - Learn ","1de219c9":"# ENCODING\n\n## It makes categorical variables binary as 1 and 0.\n","a0207053":"## Advanced Analytics","a9cf4f8d":"## Fill in missing values according to categorical variables","589de8e1":"## Fiiling with lamda and apply","a75c24e0":"#############################################\n# FEATURE ENGINEERING & DATA PRE-PROCESSING\n#############################################\n\n# 1. OUTLIERS\n#    - Capture Outliers: boxplot, outlier_thresholds, check_outlier, grab_outliers\n#    - Solving Outlier Problem: Deletion, re-assignment with thresholds, Local Outlier Factor\n\n# 2. MISSING VALUES\n#    - Capture Missing Values\n#    - Solving Missing Value Problem: Delete, fill with Lambda and Apply, fill in according to categorical variables\n#    - Advanced Analytics: Structure and Randomness Analysis, missing_vs_target\n\n# 3. LABEL ENCODING\n\n# 4. ONE-HOT ENCODING\n\n# 5. RARE ENCODING\n\n# 6. STANDARDIZATION: StandardScaler, RobustScaler, MinMaxScaler, Log, Numeric to Categorical\n\n# 7. FEATURE EXTRACTION: NA_FLAG, BOOL, BINARY, LETTER COUNT, WORD COUNT, SPECIAL_CHAR\n\n# 8. INTERACTIONS: Addition, multiplication, combination, weighting\n\n# 9. END TO END APPLICATION","50879d9a":"# 4. LOG SCALER\n\n### Due to log, it assigns smallest to largest","3e0230dc":"## LABEL ENCODING\n\n### It is just for binary variables.","408681e2":"# 3. MINMAXSCALER\n\n### It assings value between given 2 numbers.\n### Default value is between 0 and 1.","be9d6f6a":"## 1. Analysis of scarcity and abundance of categorical variables","647a731c":"#  RARE ENCODING\n\n## There are 3 steps.\n\n## 1. Analysis of scarcity and abundance of categorical variables.\n## 2. Analyzing the relationship between rare categories and dependent variable.\n## 3. Writing code","9769092a":"## Catching Outliers","70501566":"## Deleting","c06eb40d":"### WORD COUNT","eb1771d6":"## CATCHING SPECIAL FEATURES\n","dbc813e9":"## Deleting","03b9d6f0":"## 2. ROBUSTSCALER\n\n### (x - median) \/IQR","768eb88d":"## Solving Outliers Problem","5b55df64":"## Relationship between Missing Values and Dependent Variable","789f7c54":"## 2. Analyzing the relationship between rare categories and dependent variable.","b7aea4a7":"## Let's Functionalize","ce230992":"# MISSING VALUES","bb97e905":"## Re-assignment with Thresholds","caba2ed9":"## 8. INTERACTIONS","9221f779":"### LETTER COUNT","c0a5080c":"# 7.FEATURE EXTRACTION\n\n## NA_FLAG, BOOL, BINARY\n## LETTER COUNT\n## WORD COUNT\n## CATCHING SPECIAL FEATUES\n## CATCHING TITLES","654004b1":"## Writing rare encoding","3f3e886d":"### NA_FLAG, BOOL, BINARY","2d8b840d":"### CATCHING TITLES","5c0e4cd5":"## Deleting outliers","d094295f":"# One Hot Encoding\n\n## It is for variables that have more than 2 unique value.","306d381c":"# 5.NUMERIC TO CATEGORICAL SCALER","9b2b0382":"# Multivariate Outlier Analysis\n\n## Local Outlier Factor","4452a708":"# FEATURE SCALING\n\n## 1.STANDARTSCALER, \n## 2.ROBUSTSCALER, \n## 3.MINMAXSCALER, \n## 4.LOG SCALER, \n## 5.NUMERIC TO CATEGORICAL SCALER"}}