{"cell_type":{"4d99d951":"code","f4f843b9":"code","fa13fd68":"code","a1881857":"code","e4db0f08":"code","3e5e4737":"code","a1dc49a9":"code","3ffdf280":"code","35d02e31":"code","01c3d154":"code","af25a4c1":"code","1a987d9a":"code","9586f881":"code","d884ff1f":"code","dc36e595":"code","592a7957":"code","69b3a1e5":"code","941624c8":"code","2cc93b9c":"code","ad5d994d":"code","56e5fcf3":"code","4ce3d9e6":"code","b37e7ac3":"code","f12128cd":"code","39f7edbe":"code","0190f3ed":"code","0b8cad5c":"markdown","b2842f6b":"markdown","a312c18f":"markdown","fa83d598":"markdown","f5442a42":"markdown","7572dbb5":"markdown","3de17190":"markdown","60cab07b":"markdown"},"source":{"4d99d951":"!nvidia-smi","f4f843b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.makedirs('\/tmp\/yolov5',exist_ok=True)","fa13fd68":"!git clone https:\/\/github.com\/kumar-shubham-ml\/yolov5\n!cp -r yolov5\/. \/tmp\/yolov5\/.\n!rm -r yolov5","a1881857":"ls -lh \/tmp\/yolov5\/","e4db0f08":"FOLD = 1\nN_CLASSES = 1\nIMG_SIZE = 512\nBATCH_SIZE = 16\nN_EPOCHS = 20\nMODEL_NAME = 'yolov5x'\nCHECKPOINTS_ROOT = f\"{MODEL_NAME}_fold{FOLD}_img{IMG_SIZE}\"\nEVALUATE = True\nRELEASE = None #One of 1-5 (Refer: https:\/\/github.com\/ultralytics\/yolov5\/tags)  #### If None, picks the latest version\nprint(CHECKPOINTS_ROOT)","3e5e4737":"%%writefile data.yaml\n\n\ntrain: \/tmp\/images\/train\nval: \/tmp\/images\/val\n\n# number of classes\nnc: 1\n\n# class names\nnames: ['0']","a1dc49a9":"%%writefile hyperparameters.yaml\n\n# Hyperparameters for training from scratch\n\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum\/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 3.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 10.0  # image rotation (+\/- deg)\ntranslate: 0.1  # image translation (+\/- fraction)\nscale: 0.5  # image scale (+\/- gain)\nshear: 0.0  # image shear (+\/- deg)\nperspective: 0.0  # image perspective (+\/- fraction), range 0-0.001\nflipud: 0.0  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 1.0  # image mosaic (probability)\nmixup: 0.0  # image mixup (probability)\ncopy_paste: 0.0","3ffdf280":"# Read in the model config\ntry:\n    with open(f'\/tmp\/yolov5\/models\/{MODEL_NAME}.yaml',) as file :\n        filedata = file.read()\nexcept:\n    with open(f'\/tmp\/yolov5\/models\/hub\/{MODEL_NAME}.yaml',) as file :\n        filedata = file.read()\n\n# Replace the target string\nfiledata = filedata.replace('nc: 80', f'nc: {N_CLASSES}' )\n\n# Write the file out again\nwith open(f'{MODEL_NAME}.yaml','w') as file:\n    file.write(filedata)\n\nprint(filedata)","35d02e31":"!pip install -r \/tmp\/yolov5\/requirements.txt >\/dev\/null 2>&1","01c3d154":"mask_root = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\/'\nimg_root = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/'\nall_imgs = os.listdir(img_root)","af25a4c1":"os.makedirs('\/tmp\/images\/train\/',exist_ok=True)\nos.makedirs('\/tmp\/images\/val\/',exist_ok=True)\nos.makedirs('\/tmp\/labels\/train\/',exist_ok=True)\nos.makedirs('\/tmp\/labels\/val\/',exist_ok=True)","1a987d9a":"print(open('..\/input\/siim-lung-boxes-1\/CHNCXR_0001_0.txt').read())","9586f881":"image_file = all_imgs[0]","d884ff1f":"import os\nfrom tqdm.auto import tqdm\nimport joblib\n# TRAIN_ROOT_IMAGES = '..\/input\/siim-covid-images-jpegs\/images\/'\nimg_root = '\/kaggle\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/'\nmask_root = '\/kaggle\/input\/siim-lung-boxes-1\/'\ndef arrange_images_and_labels(i,image_file):\n    text_file = image_file.replace('.png','.txt')\n    if i%5==FOLD:\n        os.system(f\"cp '{img_root}{image_file}' \/tmp\/images\/val\/{image_file}\")\n        os.system(f\"cp '{mask_root}{text_file}' \/tmp\/labels\/val\/{text_file}\")\n    else:\n        os.system(f\"cp '{img_root}{image_file}' \/tmp\/images\/train\/{image_file}\")\n        os.system(f\"cp '{mask_root}{text_file}' \/tmp\/labels\/train\/{text_file}\")\n_ = joblib.Parallel(n_jobs=16)(\n    joblib.delayed(arrange_images_and_labels)(i,image_file) for i,image_file in tqdm(enumerate(all_imgs))\n)","dc36e595":"!ls \/tmp\/images\/train\/ | wc -l","592a7957":"!ls \/tmp\/labels\/train\/ | wc -l","69b3a1e5":"!ls \/tmp\/images\/val\/ | wc -l","941624c8":"!ls \/tmp\/labels\/val\/ | wc -l","2cc93b9c":"import time\nstart = time.time()","ad5d994d":"# ## Download Model\nif RELEASE:\n    !wget https:\/\/github.com\/ultralytics\/yolov5\/releases\/download\/v{RELEASE}.0\/{MODEL_NAME}.pt","56e5fcf3":"!WANDB_MODE=\"dryrun\" python3 \/tmp\/yolov5\/train.py --img {IMG_SIZE} --batch {BATCH_SIZE} --epochs {N_EPOCHS} --data data.yaml --cfg {MODEL_NAME}.yaml --name {CHECKPOINTS_ROOT} --weights {MODEL_NAME}.pt --device 0 --hyp hyperparameters.yaml --cache","4ce3d9e6":"print(time.time()-start)","b37e7ac3":"## Visualise Results for single batch\n\nimport matplotlib.pyplot as plt\nprint(\"Targets\")\nplt.figure(figsize=(30,30))\nplt.imshow(plt.imread(f'runs\/train\/{CHECKPOINTS_ROOT}\/test_batch0_labels.jpg'))\nplt.show()\nprint(\"Prediction\")\nplt.figure(figsize=(30,30))\nplt.imshow(plt.imread(f'runs\/train\/{CHECKPOINTS_ROOT}\/test_batch0_pred.jpg'))\nplt.show()","f12128cd":"os.makedirs(CHECKPOINTS_ROOT,exist_ok=True)","39f7edbe":"!cp -r runs\/train\/{CHECKPOINTS_ROOT}\/weights {CHECKPOINTS_ROOT}\/.\n!rm -r runs\n!rm -r wandb","0190f3ed":"!ls -lh","0b8cad5c":"## Model Config","b2842f6b":"## Prepare Data","a312c18f":"## Visualisation","fa83d598":"## Data Config","f5442a42":"## Resolve Requirements Conflicts","7572dbb5":"## Config","3de17190":"## Hyperparameters\n\n","60cab07b":"## Train"}}