{"cell_type":{"41ddadd2":"code","9ceec9e9":"code","c9b1282b":"code","1b12f658":"code","576e73c6":"code","c8f53af2":"code","e9176ef2":"code","2e2db7ac":"code","ab64cba1":"code","ae92eb0a":"code","719e78a1":"code","809ed190":"code","f3f1b915":"code","11ea3f63":"code","ddcfe04b":"code","2b0b65e1":"code","7af457d7":"code","33762e2d":"code","deabe451":"code","7a4da845":"code","dbe0e717":"code","8be51a64":"code","b48a544e":"code","25360248":"code","5e3dfe0c":"code","c1fd25ce":"code","65299cce":"code","f85dea77":"code","cf155f37":"code","dc541aea":"code","f00f0c45":"markdown","8a305af8":"markdown","c2f12a62":"markdown","02edfcc1":"markdown","434d2470":"markdown","7fc28c36":"markdown","1aaf101a":"markdown","e278181b":"markdown","0264bbc9":"markdown","8e9cda74":"markdown","838ec2d6":"markdown","1454d171":"markdown","ba144bff":"markdown","f3392d61":"markdown","26b3e3dd":"markdown","d075e179":"markdown","beb0657b":"markdown","a63ecbe2":"markdown","da71172e":"markdown","808e9198":"markdown","036565de":"markdown","907d92d2":"markdown"},"source":{"41ddadd2":"from scipy.signal import butter, detrend, filtfilt\nfrom lini_read_bcidat import lini_read_bcidat\nimport numpy as np\n\n# default params\ndp = {'car': 1, 'ica': 0, 'local_tend': 1, 'norm': 1, 'filtro': []}\ndw = [-300, 800]\ndch = np.arange(10)\n\n\ndef obten_p300_bci2000(f, channels=dch, window=dw, paco=dp, decimation=False, decimation_samples=4):\n\n    data = lini_read_bcidat(f)\n    raw_signal, states_matrix, labels, paco['fs'] = data\n\n    states = {}\n\n    if decimation:\n        idx = np.arange(0, raw_signal.shape[0], decimation_samples)\n\n        raw_signal = raw_signal[idx, :]\n        states_matrix = states_matrix[idx, :]\n\n    for i, label in enumerate(labels):\n        states[label] = states_matrix[:, i]\n\n    vi = int(np.round(np.abs(window[0]) * paco['fs'] \/ 1000))\n    vf = int(np.round(window[1] * paco['fs'] \/ 1000))\n\n    t = np.linspace(window[0], window[1], vf + vi)\n    if not paco['filtro']:\n        low = 2 \/ paco['fs']\n        high = 24 \/ paco['fs']\n\n        b, a = butter(4, [low, high], btype='bandpass')\n        paco['filtro'].append({'b': b, 'a': a})\n\n    signal = raw_signal[:, channels].copy()\n    n_muestras, n_canales = signal.shape\n\n    if paco['car'] == 1:\n        signal = detrend(signal.T, type='constant', bp=0)\n        signal = signal.T\n        signal = detrend(signal, type='constant', bp=0)\n\n    if len(paco['filtro']) != 0:\n        for item in paco['filtro']:\n            signal = filtfilt(item['b'], item['a'], signal.T).T\n\n    ind = (np.array(np.where(np.diff(states['StimulusCode']) > 0)) + 1).reshape(-1)\n    ind = ind[np.where(ind <= n_muestras - vf)]\n\n    letras = (np.where(np.diff(states['PhaseInSequence']) > 0))[0]\n    letras = np.concatenate([letras[0::2], [letras[-1]]])\n\n    data = np.zeros([ind.shape[0], int(vf + vi), n_canales])\n    etiqueta = -np.ones((ind.shape[0], 2))\n\n    for i, index in enumerate(ind):\n        rowcol = states['StimulusCode'][index]\n\n        if index - vi < 0:\n            raise ValueError('tiempo inicial muy largo')\n\n        data[i, :, :] = signal[index - vi:index + vf, :]\n\n        if states['StimulusType'][index] == 1:\n            etiqueta[i, :] = [1, rowcol]\n        else:\n            etiqueta[i, :] = [-1, rowcol]\n\n    return (raw_signal, signal, data, etiqueta, ind, states, t, letras)","9ceec9e9":"processed = obten_p300_bci2000('..\/input\/akimpech\/P300db\/ACS\/ACS001\/ACSS001R01.dat', decimation=True)\nraw_signal, signal, data, etiqueta, ind, states, t, letras = processed","c9b1282b":"import matplotlib.pyplot as plt\n\ndef plot_channel(t, data, etiquetas, channel):\n    plt.title('Channel {}'.format(channel + 1))\n    plt.plot(t, data[etiqueta[:, 0] == 1, :, channel].mean(axis=0), label='ERP')\n    plt.plot(t, data[etiqueta[:, 0] == -1, :, channel].mean(axis=0), label='Background')\n    plt.xlabel('Time [ms]')\n    plt.ylabel('a.u')\n    plt.legend(loc='lower left')","1b12f658":"plt.figure(figsize=(20, 10))\n\nfor i in range(2):\n    for j in range(5):\n        plt.subplot(2, 5, i * 5 + j + 1)\n        plot_channel(t, data, etiqueta, i * 5 + j)\n\nplt.tight_layout()\nplt.show()","576e73c6":"import sklearn\nimport os\n\n\ndef load_train(train_path, window=[-300, 800]):\n    data = None\n    \n    for filename in os.listdir(train_path):\n        full = os.path.join(train_path, filename)\n        \n        if '.dat' in full:\n            print('[+] Loading {}'.format(full))\n            \n            rt, st, da, et, it, sta, tt, lt = obten_p300_bci2000(full, decimation=True)\n            \n            if data is None:\n                data = da\n                t = tt\n                etiquetas = et\n            else:\n                data = np.vstack([data, da])\n                etiquetas = np.vstack([etiquetas, et])\n                \n    return data, etiquetas, t\n\n\ndef plot_confusion_matrix(cm, ax=None, cbar=True):\n    # Code inspired in https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/fd237278e\/sklearn\/metrics\/_plot\/confusion_matrix.py\n    \n    labels = ['Background', 'ERP']\n    \n    im = ax.imshow(cm)\n    cmap_min, cmap_max = im.cmap(0), im.cmap(256)\n    \n    if cbar:\n        ax.figure.colorbar(im)\n    \n    ax.set_xticks(np.arange(len(labels)))\n    ax.set_yticks(np.arange(len(labels)))\n    \n    ax.set_ylim((len(labels) - 0.5, -0.5))\n    \n    ax.set_xticklabels(labels)\n    ax.set_yticklabels(labels)\n    \n    ax.set_ylabel('True label')\n    ax.set_xlabel('Predicted label')\n    \n    thresh = (cm.max() - cm.min()) \/ 2\n    \n    for i in range(len(labels)):\n        for j in range(len(labels)):\n            color = cmap_max if cm[i, j] < thresh else cmap_min\n            text = ax.text(j, i, cm[i, j], ha='center', va='center', color=color)","c8f53af2":"base_path = '..\/input\/akimpech\/P300db\/ACS\/ACS001\/'\n\nsignal, etiquetas, t = load_train(base_path)","e9176ef2":"signal.shape","2e2db7ac":"print('# of signals of type background: {}'.format(np.where(etiquetas[:, 0] == -1)[0].shape[0]))\nprint('# of signals of type erp: {}'.format(np.where(etiquetas[:, 0] == 1)[0].shape[0]))","ab64cba1":"import sklearn\nimport sklearn.svm\nimport sklearn.ensemble\nimport sklearn.model_selection\n\n\nsss = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\nclassifier = sklearn.svm.SVC(kernel='rbf', gamma='scale', class_weight='balanced', random_state=0)","ae92eb0a":"def clf_confusion_matrix(signal, labels, clf_class, channels, kwargs):\n    # Channels is an array containing the channels to plot\n    # Classifier is the class to use as the classifier\n    # kwargs are the parameters for the classifier as dictionary\n    \n    classifiers = []\n    y_preds = {}\n\n    for train_index, test_index in sss.split(signal, labels):\n        train_X = signal[train_index, :, :]\n        train_y = labels[train_index]\n\n        test_X = signal[test_index, :, :]\n        test_y = labels[test_index]\n\n        for channel in channels:\n            print('[+] Training classifier for channel {}...'.format(channel + 1), end='')\n            classifier = clf_class(**kwargs)\n            classifier.fit(train_X[:, :, channel], train_y)\n            print(' Done')\n\n            classifiers.append(('Channel {} classifier'.format(channel + 1), channel, classifier))\n\n        test_erp = None\n        test_nerp = None\n\n        for feature, label in zip(test_X, test_y):\n            feature = feature[np.newaxis, :, :]\n\n            if label == 0:\n                if test_nerp is None:\n                    test_nerp = feature\n                else:\n                    test_nerp = np.vstack([test_nerp, feature])\n\n                latest = test_nerp\n\n            elif label == 1:\n                if test_erp is None:\n                    test_erp = feature\n                else:\n                    test_erp = np.vstack([test_erp, feature])\n\n                latest = test_erp\n\n            for label, channel, classifier in classifiers:\n                if channel not in y_preds:\n                    y_preds[channel] = []\n\n                pred = classifier.predict(latest[:, :, channel].mean(axis=0).reshape(1, -1))[0]\n                y_preds[channel].append(pred)\n\n        # Plotting section\n        plt.figure(figsize=(8, 4 * len(channels)))\n        for i, channel in enumerate(channels):\n            print('Plotting channel', channel)\n            \n            plt.subplot(len(channels), 2, i * 2 + 1)\n\n            plt.title('Classification With Averaging.\\nChannel {}'.format(channel + 1))\n            cm = sklearn.metrics.confusion_matrix(test_y, y_preds[channel])\n            plot_confusion_matrix(cm, ax=plt.gca(), cbar=False)\n            \n            plt.subplot(len(channels), 2, i * 2 + 2)\n            \n            preds = classifier.predict(test_X[:, :, channel])\n            cm_without = sklearn.metrics.confusion_matrix(test_y, preds)\n            \n            plt.title('Classification Without Averaging.\\nChannel {}'.format(channel + 1))\n            plot_confusion_matrix(cm_without, ax=plt.gca(), cbar=False)\n\n            plt.tight_layout()\n        \n        plt.show()","719e78a1":"labels = (etiquetas[:, 0] + 1) \/\/ 2\n\nsvm_params = {\n    'kernel': 'rbf',\n    'gamma': 'scale',\n    'class_weight': 'balanced',\n    'random_state': 0,\n}\n\nclf_confusion_matrix(signal, labels, sklearn.svm.SVC, [1,], svm_params)","809ed190":"clf_confusion_matrix(signal, labels, sklearn.svm.SVC, np.arange(signal.shape[2]), svm_params)","f3f1b915":"rnd_parameters = {\n    'class_weight': 'balanced',\n    'random_state': 0,\n    'max_features': 'log2',\n    'min_samples_split': 10,\n    'max_depth': 50,\n}\n\nclf_confusion_matrix(signal, labels, sklearn.ensemble.RandomForestClassifier, [1,], rnd_parameters)","11ea3f63":"channel_selection = [1, 2, 3, 5, 7]\nclassifiers = []\n\nfor channel in channel_selection:\n    print('[+] Training classifier for channel {}... '.format(channel + 1), end='')\n    classifier = sklearn.svm.SVC(kernel='rbf', gamma='scale', class_weight='balanced')\n    classifier.fit(signal[:, :, channel], labels)\n    print('Done')\n    \n    classifiers.append(('Classifier channel {}'.format(channel + 1), channel, classifier))","ddcfe04b":"test_path = '..\/input\/akimpech\/P300db\/ACS\/ACS002\/'\nsignal_test, etiquetas_test, t = load_train(test_path)","2b0b65e1":"from scipy.special import expit\n\n\ndef make_labels_sweep(input_labels):\n    # Impute missing values with zeros\n    reps = 12 - (input_labels.shape[0] % 12)\n    missing = np.zeros((reps, 2))\n    \n    input_labels = np.vstack([input_labels, missing])\n    \n    splits = np.split(input_labels, int(input_labels.shape[0] \/ 12))\n    labels = []\n    \n    for split in splits:\n        labels.append(1 * (split[split[:, 1].argsort()][:, 0] == 1))\n        \n    return labels\n\n\ndef get_predictions(signal, clfs):\n    predictions = []\n    names = []\n    \n    for name, channel, clf in clfs:\n        prediction = clf.decision_function(signal[:, :, channel])\n        \n        names.append(name)\n        predictions.append(prediction)\n        \n    arr = np.array(predictions)\n    scores = np.sum(expit(arr), axis=0)\n    \n    return {'scores': scores, 'names': names, 'predictions': predictions}\n\n\nmatrix = [\n    ['a', 'b', 'c', 'd', 'e', 'f'],\n    ['g', 'h', 'i', 'j', 'k', 'l'],\n    ['m', 'n', 'o', 'p', 'q', 'r'],\n    ['s', 't', 'u', 'v', 'w', 'x'],\n    ['y', 'z', '_', '1', '2', '3'],\n    ['4', '5', '6', '7', '8', '9'],\n]","7af457d7":"def predict(signal_test, etiquetas_test, clfs):\n    # Impute missing values with zeros\n    reps = 12 - (etiquetas_test.shape[0] % 12)\n    missing = np.zeros((reps, 2))\n    \n    etiquetas_test = np.vstack([etiquetas_test, missing])\n    \n    sweeps = np.array_split(etiquetas_test[:, 1], int(etiquetas_test.shape[0] \/ 12))\n    \n    r_sum = np.zeros((12, signal_test.shape[1], signal_test.shape[2]))\n    letters = []\n    \n    bn = 0\n    i = 0\n    for sweep in sweeps:\n        sweep_data = np.zeros((12, signal_test.shape[1], signal_test.shape[2]))\n        \n        for row in sweep:\n            if row > 0:\n                row = int(row - 1)\n                sweep_data[row, :, :] = signal_test[i, :, :]\n                \n                i += 1\n        \n        r_sum = r_sum + sweep_data\n        \n        if bn % 14 == 0 and bn > 0:\n            channel_predictions = get_predictions(r_sum \/ 15, clfs)\n            \n            row_score, col_score = channel_predictions['scores'][:6], channel_predictions['scores'][6:]\n            m1, m2 = max(row_score), max(col_score)\n            p1, p2 = np.where(row_score == m1)[0][0], np.where(col_score == m2)[0][0]\n            \n            letters.append(matrix[p1][p2])\n            \n            bn = 0\n            r_sum = np.zeros((12, signal_test.shape[1], signal_test.shape[2]))\n\n        else:\n            bn += 1\n            \n    return ''.join(letters)","33762e2d":"predict(signal_test, etiquetas_test, classifiers)","deabe451":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass OCLNN(torch.nn.Module):\n    def __init__(self, n_channels, n_samples, channel_order=None):\n        super(OCLNN, self).__init__()\n        \n        if n_channels == 0:\n            if channel_order is None:\n                raise ValueError('if n_channels equals 0, channel_order must be specified.')\n                \n            n_channels = len(channel_order)\n        \n        div = n_samples \/\/ 15\n        \n        self.conv1 = nn.Conv1d(n_channels, 16, div, stride=div)\n        self.dropout  = nn.Dropout(p=0.25)\n        self.linear = nn.Linear(self.out_shape(self.conv1, n_samples), 2)\n        \n        if torch.cuda.is_available():\n            device = torch.device('cuda')\n        else:\n            device = torch.device('cpu')\n            \n        print('[+] Using device', device)\n        \n        self.to(device)\n        self.device = device\n        self.channel_order = channel_order\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        \n        return x\n    \n    def fit(self, signal, labels, epochs=1000):\n        # Assuming the current signal shape is (batch, data, channels)\n        # Assuming labels come directly from obten_p300...\n        \n        signal = np.swapaxes(signal, 1, 2)\n        labels = (labels[:, 0] + 1) \/\/ 2\n        \n        if self.channel_order is not None:\n            signal = signal[:, self.channel_order, :]\n        \n        criteron = torch.nn.CrossEntropyLoss().to(self.device)\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n\n        torch_signal = torch.from_numpy(signal).float().to(self.device)\n        torch_labels = torch.from_numpy(labels).long().to(self.device)\n\n        for t in range(epochs):\n            y_pred = model(torch_signal).float()\n            loss = criteron(y_pred.float(), torch_labels)\n\n            if t % 100 == 99:\n                print('[+] Loss at epoch {}: {:.6f}'.format(t, loss.item()))\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n    def predict(self, signal):\n        # Assuming signal is in the form: (batch, samples, channels)\n        \n        signal = np.swapaxes(signal, 1, 2)\n        \n        if self.channel_order is not None:\n            signal = signal[:, self.channel_order, :]\n        \n        signal = torch.from_numpy(signal).float().to(self.device)\n        predictions = F.softmax(self(signal), dim=1)\n        \n        return predictions.detach().cpu().numpy()\n    \n    def speller_predictions(self, data):\n        preds = self.predict(data)\n        \n        row_idx = np.argmax(preds[:6, 1])\n        col_idx = np.argmax(preds[6:, 1])\n\n        vector = np.zeros(preds.shape[0], dtype='uint8')\n\n        vector[row_idx] = 1\n        vector[col_idx + 6] = 1\n\n        return row_idx, col_idx, vector\n        \n    def out_shape(self, conv, len_in):        \n        num = len_in + 2 * conv.padding[0] - conv.dilation[0] * (conv.kernel_size[0] - 1) - 1\n        den = conv.stride[0]\n        \n        return ((np.floor(num \/ den) + 1) * conv.out_channels).astype('uint64')","7a4da845":"signal, etiquetas, t = load_train(base_path)","dbe0e717":"n_channels = signal.shape[2]\nn_samples = signal.shape[1]\n\nmodel = OCLNN(n_channels, n_samples)","8be51a64":"print(model)","b48a544e":"model.fit(signal, etiquetas)","25360248":"bincount = np.bincount(labels.astype('uint8'))\n\nw0 = signal.shape[0] \/ (2 * bincount[0])\nw1 = signal.shape[0] \/ (2 * bincount[1])","5e3dfe0c":"signal_test, etiquetas_test, t = load_train('..\/input\/akimpech\/P300db\/ACS\/ACS002\/')","c1fd25ce":"test_labels = (etiquetas_test[:, 0] + 1) \/\/ 2\n\nif etiquetas_test.shape[0] % 12 > 0:\n    reps = 12 - (etiquetas_test.shape[0] % 12)\n    missing = np.zeros((reps, 2))\n    \n    etiquetas_test = np.vstack([etiquetas_test, missing])","65299cce":"preds = model.predict(signal_test)\npreds = 1 * (preds[:, 0] < preds[:, 1])","f85dea77":"test_nerp = None\ntest_erp = None\n\nmeaned_pred = []\n\nfor etiqueta, test_sig in zip(test_labels, signal_test):\n    test_sig = test_sig[np.newaxis, :, :]\n    \n    if etiqueta == 0:\n        if test_nerp is None:\n            test_nerp = test_sig\n        \n        else:\n            test_nerp = np.vstack([test_nerp, test_sig])\n            \n        last = test_nerp\n            \n    elif etiqueta == 1:\n        if test_erp is None:\n            test_erp = test_sig\n        \n        else:\n            test_erp = np.vstack([test_erp, test_sig])\n            \n        last = test_erp\n\n    pred = model.predict(last.mean(axis=0)[np.newaxis, :, :])[0]\n    \n    pred = 1 * (pred[0] < pred[1])\n    meaned_pred.append(pred)","cf155f37":"deep_cm_mean = sklearn.metrics.confusion_matrix(test_labels, meaned_pred)\ndeep_cm = sklearn.metrics.confusion_matrix(test_labels, preds)\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.title('Confusion Matrix for OCLNN\\nWithout Averaging')\nplot_confusion_matrix(deep_cm, ax=plt.gca())\n\nplt.subplot(1, 2, 2)\nplt.title('Confusion Matrix for OCLNN\\nWith Averaging')\nplot_confusion_matrix(deep_cm_mean, ax=plt.gca())\n\nplt.tight_layout()\nplt.show()","dc541aea":"sweeps = np.split(etiquetas_test[:, 1], int(etiquetas_test.shape[0] \/ 12))\n\nr_sum = np.zeros((12, signal_test.shape[1], signal_test.shape[2]))\nletters = []\n\nbn = 0\ni = 0\n\nfor sweep in sweeps:\n    sweep_data = np.zeros((12, signal_test.shape[1], signal_test.shape[2]))\n        \n    for row in sweep:\n        if row > 0:\n            row = int(row - 1)\n            sweep_data[row, :, :] = signal_test[i, :, :]\n            \n            i += 1\n            \n    r_sum = r_sum + sweep_data\n    \n    if bn % 14 == 0 and bn > 0:\n        # Prediction per row here\n        row_idx, col_idx, vec = model.speller_predictions(r_sum \/ 15)\n        \n        letters.append(matrix[row_idx][col_idx])\n        \n        bn = 0\n        r_sum = np.zeros((12, signal_test.shape[1], signal_test.shape[2]))\n        \n    else:\n        bn += 1\n        \nprint(''.join(letters))","f00f0c45":"# SVM Classifier for a Single Channel","8a305af8":"# Loading a Single File","c2f12a62":"Once loaded the signals, it is necessary to create the matrix that was being displayed in the scren to determine the letter that the subject was observing. Likewise, it is necessary to create a fuction that returns the labels for each sweep of the matrix; this is a simmulation of an online classifier.","02edfcc1":"## Speller Classification with OCLNN","434d2470":"Now that we have the general concept behind creating a classifier for this dataset we can create a classifier that tries to predict the letters that the subject tried to spell on the P300 speller. For that, we will train a classifier for each channel selected, it can be either only for a subset of channels or the whole range of channels. In this notebook we are selecting channels 2, 3, 4, 6, and 8. The training data will be obtained from the first trial of the subject, while the test data will be obtained from the second trial.","7fc28c36":"## Testing OCLNN","1aaf101a":"## Training","e278181b":"# Preprocessing","0264bbc9":"We have loaded all the files that are located in the folder `base_path`. We can see that in total there are 2,871 signals with 282 samples for each of the 10 channels.","8e9cda74":"The correct word was \"sushi\"","838ec2d6":"A simple CNN architecture that only has three layers: convolution, dropout and fully connected as output.","1454d171":"# Speller classification","ba144bff":"The following code block realizes predictions on the average of the signals.","f3392d61":"# Neural Network. OCLNN Implementation\n\nThe following CNN architecture is based on the following paper: [https:\/\/www.ijcai.org\/Proceedings\/2018\/0222.pdf](http:\/\/https:\/\/www.ijcai.org\/Proceedings\/2018\/0222.pdf).","26b3e3dd":"We also need to be careful while creating a classifier because there are more signals of type *background* than *ERP*. The dataset is unbalanced.","d075e179":"The following code block realizes predictions on the raw dataset; without realizing any type of averaging.","beb0657b":"# Random Forest Classifier","a63ecbe2":"# Data Exploration","da71172e":"With this knowledge, we can create a basic SVM Classifier using `scikit-learn`.","808e9198":"We need to impute missing values to the signal, if it is not divisible by 12; because each sweep consists of 12 different flashes accross the screen, maybe the user interrupted the trial before it was finished.","036565de":"In this code block we will be doing the following:\n1. Selecting the channel which we will train the classifier.\n2. For `n_splits` iterations, the data will be split into two separate groups: train and test.\n3. Training the classifier with the train data.\n4. Iterate over the test data and average over time the background signal and erp signal. \n    1. For each iteration, classify the type of signal (background, erp).\n5. After iterating and averaging the test data, the classifier will be run in the whole test data, without averaging.\n6. Plot the confusion matrix for both results.","907d92d2":"Bear in mind that this results were obtained with a SVM classifier using only one channel of information and with the data downsampled. One more efficient approach would be to create a classifier for each channel of the data to create a *voting* system to determine the label of the current signal. The following code shows the confusion matrices for the 10 different channels."}}