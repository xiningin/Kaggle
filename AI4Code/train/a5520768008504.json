{"cell_type":{"5b86f05e":"code","11d76958":"code","80c84363":"code","2e8cae9c":"code","5accd86d":"code","5126695d":"code","471ebca2":"code","233ab157":"code","4a028adb":"code","c3a50b27":"code","d7273c04":"code","dcc2a811":"code","b85cb1a2":"code","f0504e40":"code","9e1eaadd":"code","06e9d82d":"code","10bf3954":"code","c47e2a9a":"code","27f3fc58":"code","28db557b":"code","63ac10c9":"code","16c112d7":"code","4c773626":"code","80dfd5cd":"markdown","cec4ff96":"markdown","ff42ab99":"markdown","493d4c20":"markdown","190d394f":"markdown","c2d78fb7":"markdown"},"source":{"5b86f05e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","11d76958":"df = pd.read_csv(\"..\/input\/Classified Data\",index_col=0)","80c84363":"df.head()","2e8cae9c":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","5accd86d":"scaler.fit(df.drop('TARGET CLASS',axis=1))","5126695d":"scaled_features = scaler.transform(df.drop('TARGET CLASS',axis=1))","471ebca2":"df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])","233ab157":"df_feat.head()","4a028adb":"sns.pairplot(df,hue='TARGET CLASS')","c3a50b27":"df['TARGET CLASS'].value_counts()","d7273c04":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(df_feat,df['TARGET CLASS'],test_size=0.3)","dcc2a811":"from sklearn.neighbors import KNeighborsClassifier\n","b85cb1a2":"knn = KNeighborsClassifier(n_neighbors=1)","f0504e40":"knn.fit(X_train,y_train)","9e1eaadd":"pred = knn.predict(X_test)","06e9d82d":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score","10bf3954":"print(confusion_matrix(y_test,pred))","c47e2a9a":"print(classification_report(y_test,pred))","27f3fc58":"accuracy_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    score = cross_val_score(knn,df_feat,df['TARGET CLASS'],cv=10)\n    accuracy_rate.append(score.mean())  ","28db557b":"error_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    score = cross_val_score(knn,df_feat,df['TARGET CLASS'],cv=10)\n    error_rate.append(1-score.mean())  \nerror_rate","63ac10c9":"error_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\nerror_rate","16c112d7":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n        markerfacecolor='red', markersize=10)\n#plt.plot(range(1,40),accuracy_rate,color='blue', linestyle='dashed', marker='o',\n#         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","4c773626":"# NOW WITH K=23\nknn = KNeighborsClassifier(n_neighbors=23)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=23')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","80dfd5cd":"## Using KNN\n\nRemember that we are trying to come up with a model to predict whether someone will TARGET CLASS or not. We'll start with k=1.","cec4ff96":"### Choosing a K Value\nLet's go ahead and use the elbow method to pick a good K Value:","ff42ab99":"# K Nearest Neighbors with Python\n\nYou've been given a classified data set from a company! They've hidden the feature column names but have given you the data and the target classes. \n\nWe'll try to use KNN to create a model that directly predicts a class for a new data point based off of the features.\n\nLet's grab it and use it!","493d4c20":"### Predictions and Evaluations\nLet's evaluate our KNN model!","190d394f":"Here we can see that that after arouns K>23 the error rate just tends to hover around 0.06-0.05 Let's retrain the model with that and check the classification report!","c2d78fb7":"## Standardize the Variables\n\nBecause the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale."}}