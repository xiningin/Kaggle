{"cell_type":{"14ce04a8":"code","06b7d990":"code","767a1caa":"code","543c5294":"code","a3695ee8":"code","c3be5339":"code","f17608a8":"code","aaf167dd":"code","fed1c4cc":"code","7e4ad6b4":"code","d2be32df":"code","da865262":"code","2c22462c":"code","0038078c":"code","cb289251":"code","e976f79c":"code","66b0b1ce":"code","80707f22":"code","cb6b27c7":"code","cdf24535":"code","4c44bb1a":"code","411f7c9d":"code","3ab8c16c":"code","0f03491d":"code","685daef2":"code","09d3a10e":"code","11ab0dcf":"markdown","cc0ea95f":"markdown","7a9f1b0f":"markdown","6ab683ad":"markdown","9b2d65b7":"markdown"},"source":{"14ce04a8":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport time\nimport os\nimport copy\n\nimport glob\nfrom PIL import Image\n\nfrom scipy.special import softmax\n\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport matplotlib.image as mpimg\nmpl.rcParams['figure.dpi'] = 200","06b7d990":"img_size = (300, 300)\n\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(img_size),\n        transforms.ToTensor()\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(img_size),\n        transforms.ToTensor()\n    ]),\n}\n\ndata_dir = '\/kaggle\/input\/animal-faces\/afhq\/'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","767a1caa":"# plot data:\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 4))\n#fig.suptitle(\"Training Data\", fontsize=20)\n\nimg1 = data_dir + 'train\/wild\/flickr_wild_000769.jpg'\nax[0].axis('off')\nax[0].imshow(mpimg.imread(img1))\n\nimg2 = data_dir + 'train\/cat\/pixabay_cat_000250.jpg'\nax[1].axis('off')\nax[1].imshow( mpimg.imread(img2))\nax[1].set(title = \"Training data\")\n\nimg3 = data_dir + 'train\/dog\/pixabay_dog_000368.jpg'\nax[2].axis('off')\nax[2].imshow(mpimg.imread(img3));","543c5294":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","a3695ee8":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n            running_loss = 0.0\n            running_corrects = 0\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n        print()\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","c3be5339":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)\n        \n# function that accepts an image path and returns a format to be consumed by the model \ndef process_img (img_path) : \n    transform_pipeline = transforms.Compose([transforms.Resize(img_size),\n                                             transforms.ToTensor()])\n    img = transform_pipeline(Image.open(img_path).convert(\"RGB\")).to(device)\n    return (img.unsqueeze(0))","f17608a8":"torch.manual_seed(42)\nnp.random.seed(42)\n\nPATH = \"\/kaggle\/resnet18_state_dict.pkl\"\nmodel_conv = torchvision.models.resnet18(pretrained=True)\n#model_conv = torch.hub.load('pytorch\/vision:v0.6.0', 'mobilenet_v2', pretrained=True) # mobilenet\n\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, len(class_names), bias = False)\nfor param in model_conv.fc.parameters():\n    param.requires_grad = True\n    \n# training:\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\nwd = 5e-4\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9, weight_decay = wd)\n\n# Decay LR by a factor of 0.1 every 4 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=4, gamma=0.1)","aaf167dd":"model_conv = train_model(model = model_conv, \n                         criterion = criterion, \n                         optimizer = optimizer_conv,\n                         scheduler = exp_lr_scheduler, \n                         num_epochs = 10)","fed1c4cc":"# find a dog that is predicted as \"dog\" with less than 94% probability \nlow_prob_dogs = []\nfor pth in glob.glob(data_dir + 'val\/dog\/*') :\n    _ = softmax(model_conv(process_img(pth))[0].cpu().detach().numpy())\n    _ind = np.argmax(_) # index of prediction \n    if class_names[_ind] == \"dog\" :\n        if _[_ind] < 0.94 :\n            low_prob_dogs.append(pth)\n            \nlow_prob_dogs","7e4ad6b4":"#!pip install backpack-for-pytorch","d2be32df":"#!pip install backpack-for-pytorch\n\nfrom math import *\nfrom backpack import extend, backpack, extensions\nfrom torch.distributions.multivariate_normal import MultivariateNormal","da865262":"# hack to remove the last layer of ResNet and extract features\nfeature_extr = nn.Sequential(*list(model_conv.children())[:-1])\nprint(\"Number of features: \", list(feature_extr.parameters())[-1].shape[0])\n\n# training script\nW = list(model_conv.fc.parameters())[0] #list(model_conv.parameters())[-2]\nshape_W = W.shape\n\n# Use BackPACK to get the Kronecker-factored last-layer covariance\n_ = extend(model_conv.fc)\nloss_func = extend(nn.CrossEntropyLoss(reduction='sum'))\n\nfor x_train, y_train in dataloaders[\"train\"] :\n    x_train = x_train.to(device)\n    y_train = y_train.to(device)\n    loss = loss_func(model_conv(x_train), y_train)\n    with backpack(extensions.KFAC()): # calculate the hessian \n        loss.backward()\n\n# The Kronecker-factored Hessian of the negative log-posterior\nA, B = W.kfac\n\nprint(\"LL Laplace Approx complete\")","2c22462c":"# predict method\n@torch.no_grad()\ndef predict(x):\n    x = x.to(device)\n    phi = feature_extr(x).reshape(1, list(feature_extr.parameters())[-1].shape[0])\n    # MAP prediction\n    m = phi @ W.T\n    v = torch.diag(phi @ V @ phi.T).reshape(-1, 1, 1) * U\n    output_dist = MultivariateNormal(m, v)\n    # MC-integral\n    n_sample = 2500\n    py = 0\n    for _ in range(n_sample):\n        out_s = output_dist.rsample()\n        py += torch.softmax(out_s, 1)\n    py \/= n_sample\n    smx = np.round(softmax(m.cpu().numpy())[0], 2) # rounded softmax prediction\n    laplace = np.round(py.cpu().numpy()[0], 2) # rounded prediction from llla\n    smx_top = (class_names[np.argmax(smx)], smx[np.argmax(smx)])\n    laplace_top = (class_names[np.argmax(laplace)], laplace[np.argmax(laplace)])\n    return (smx, laplace, smx_top, laplace_top)","0038078c":"# The weight decay used for training is the Gaussian prior's precision\nprec0 = 2.5 # increasing causes the predictions to approach the softmax preds, decreasing causes it to tend to uniform\n\n# The posterior covariance's Kronecker factors\nU = torch.inverse(A + sqrt(prec0)*torch.eye(shape_W[0]).to(device))\nV = torch.inverse(B + sqrt(prec0)*torch.eye(shape_W[1]).to(device))","cb289251":"## Softmax only model: \nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\nimg1 = '..\/input\/unseendata\/me.jpeg'\nax[0].axis('off')\nax[0].imshow(mpimg.imread(img1))\n_p1 = predict(process_img(img1))\nax[0].set(title = \"Prediction: \" + str(_p1[2][0]) + '\\n' + 'Probability: ' + str(_p1[2][1]));\n\nimg2 = data_dir + 'val\/dog\/pixabay_dog_001356.jpg' #flickr_dog_000849.jpg' # 101\nax[1].axis('off')\nax[1].imshow( mpimg.imread(img2))\n_p2 = predict(process_img(img2))\nax[1].set(title = \"Prediction: \" + str(_p2[2][0]) + '\\n' + 'Probability: ' + str(_p2[2][1]));","e976f79c":"# Softmax model + LLLA model\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\nimg1 = '..\/input\/unseendata\/me.jpeg'\nax[0].axis('off')\nax[0].imshow(mpimg.imread(img1))\nax[0].set(title = \"LLLA: \" + str(predict(process_img(img1))[3]) + '\\n' +\n                  \"Softmax: \" + str(predict(process_img(img1))[2]))\n\nimg2 = data_dir + 'val\/dog\/pixabay_dog_001356.jpg'\nax[1].axis('off')\nax[1].imshow( mpimg.imread(img2))\nax[1].set(title = \"LLLA: \" + str(predict(process_img(img2))[3]) + '\\n' +\n                  \"Softmax: \" + str(predict(process_img(img2))[2]));\n\n# img3 = data_dir + 'val\/cat\/flickr_cat_000709.jpg'\n# ax[2].axis('off')\n# ax[2].imshow(mpimg.imread(img3))\n# ax[2].set(title = \"LLLA: \" + str(predict(process_img(img3))[3]) + '\\n' +\n#                   \"Softmax: \" + str(predict(process_img(img3))[2]));","66b0b1ce":"# run the model over the validation set and plot histograms of the top predicted class\nsoftmax_preds = []\nbayesian_preds = []\ntrue_labels = []\nimg_paths = []\nfor imgs, lbls in dataloaders[\"val\"] :\n    for i in range(len(lbls)) :\n        img_paths.append(imgs[i])\n        p_ = predict(imgs[i].unsqueeze(0))\n        softmax_preds.append(p_[2])\n        bayesian_preds.append(p_[3])\n        true_labels.append(class_names[lbls[i].numpy()])\n\nsoftmax_preds = np.array(softmax_preds)\nbayesian_preds = np.array(bayesian_preds)\ntrue_labels = np.array(true_labels)\n\nprint(\"Softmax validation set accuracy: \", np.mean(true_labels == list(map(lambda x: x[0], softmax_preds))))\nprint(\"Laplace Approximation validation set accuracy: \", np.mean(true_labels == list(map(lambda x: x[0], bayesian_preds))))","80707f22":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n\nsns.distplot(list(map(lambda x: x[1], softmax_preds)), kde = False, ax = ax[0]).set_title(\"Softmax Predictions - Animal Validation Data\")\nax[0].set(xlabel = \"Top class probability\")\n\nsns.distplot(list(map(lambda x: x[1], bayesian_preds)), kde = False, ax = ax[1]).set_title(\"LLLA Predictions - Animal Validation Data\")\nax[1].set(xlabel = \"Top class probability\");","cb6b27c7":"low_ind = np.arange(1500)[np.array(list(map(lambda x: x[1], bayesian_preds)), dtype = float) < 0.45]\nhi_ind = np.arange(1500)[np.array(list(map(lambda x: x[1], bayesian_preds)), dtype = float) > 0.8]","cdf24535":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12, 7))\nfig.suptitle(\"LLLA Low Confidence Predictions\", fontsize=12)\n\nfor i, ax in enumerate(ax.flatten()) :\n    if i == sum(low_ind) : \n        ax.axis('off')\n        break\n    inp = img_paths[low_ind[i]]\n    inp = inp.numpy().transpose((1, 2, 0))\n    ax.axis('off')\n    ax.set(title = \"LLLA: \" + str(bayesian_preds[low_ind[i]]) + '\\n' + \"Softmax: \" + str(softmax_preds[low_ind[i]]))\n    ax.imshow(inp);","4c44bb1a":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12, 7))\nfig.suptitle(\"LLLA High Confidence Predictions\", fontsize=12)\n\nfor i, ax in enumerate(ax.flatten()) :\n    if i == sum(hi_ind) : \n        ax.axis('off')\n        break\n    inp = img_paths[hi_ind[i]]\n    inp = inp.numpy().transpose((1, 2, 0))\n    ax.axis('off')\n    ax.set(title = \"LLLA: \" + str(bayesian_preds[hi_ind[i]]) + '\\n' + \"Softmax: \" + str(softmax_preds[hi_ind[i]]))\n    ax.imshow(inp);","411f7c9d":"# set a threshold on the prediction, anything below the threshold will be predicted as \"other\"\nthresholds = [0.4, 0.45, 0.5, 0.55, 0.6, 0.7]\nsoftmax_accuracies = []\nbayesian_accuracies = []\n\nfor threshold in thresholds :\n    thresh_softmax_preds = []\n    thresh_bayesian_preds = []\n    thresh_true_labels = []\n    thresh_img_paths = []\n    for imgs, lbls in dataloaders[\"val\"] :\n        for i in range(len(lbls)) :\n            thresh_img_paths.append(imgs[i])\n            p_ = predict(imgs[i].unsqueeze(0))\n            thresh_softmax_preds.append(p_[2])\n            if p_[3][1] > threshold :\n                thresh_bayesian_preds.append(p_[3])\n            else : \n                thresh_bayesian_preds.append((\"other\", 1.0))\n            thresh_true_labels.append(class_names[lbls[i].numpy()])\n\n    thresh_softmax_preds = np.array(thresh_softmax_preds)\n    thresh_bayesian_preds = np.array(thresh_bayesian_preds)\n    thresh_true_labels = np.array(thresh_true_labels)\n    softmax_accuracies.append(np.mean(thresh_true_labels == list(map(lambda x: x[0], thresh_softmax_preds))))\n    bayesian_accuracies.append(np.mean(thresh_true_labels == list(map(lambda x: x[0], thresh_bayesian_preds))))\n    print(\"Softmax validation set accuracy: \", \n          np.mean(thresh_true_labels == list(map(lambda x: x[0], thresh_softmax_preds))))\n    print(\"Laplace Approximation validation set accuracy: \", \n          np.mean(thresh_true_labels == list(map(lambda x: x[0], thresh_bayesian_preds))))","3ab8c16c":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 2))\nsns.lineplot(thresholds, bayesian_accuracies, ax = ax, \n             label = \"LLLA Accuracies\",\n             color = sns.xkcd_rgb[\"denim blue\"])\nsns.lineplot(thresholds, softmax_accuracies, ax = ax,\n             label = \"Softmax Accuracies\",\n             color = sns.xkcd_rgb[\"pale red\"])\nax.legend(loc = \"lower left\", fontsize=8);","0f03491d":"#Image.open(glob.glob('\/kaggle\/input\/simpsons-faces\/cropped\/*')).resize(img_size)\nsimpsons_pths = glob.glob('\/kaggle\/input\/simpsons-faces\/cropped\/*')[:300]\n\n# plot data:\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 4))\nimg1 = simpsons_pths[1]\nax[0].axis('off')\nax[0].imshow(mpimg.imread(img1))\n\nimg2 = simpsons_pths[20]\nax[1].axis('off')\nax[1].imshow( mpimg.imread(img2))\nax[1].set(title = \"Out-of-distribution Data\")\n\nimg3 = simpsons_pths[11]\nax[2].axis('off')\nax[2].imshow(mpimg.imread(img3));","685daef2":"simpsons_bayesian = []\nsimpsons_softmax = []\n\nfor img_pth in simpsons_pths: \n    _p = predict(process_img(img_pth))\n    simpsons_bayesian.append(_p[3])\n    simpsons_softmax.append(_p[2])","09d3a10e":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n\nsns.distplot(list(map(lambda x: x[1], simpsons_softmax)), ax = ax[0]).set_title(\"Softmax Top Predictions - Simpsons Data\")\nax[0].set(xlabel = \"Top class probability\")\n\nsns.distplot(list(map(lambda x: x[1], simpsons_bayesian)), ax = ax[1]).set_title(\"LLLA Top Predictions - Simpsons Data\")\nax[1].set(xlabel = \"Top class probability\");","11ab0dcf":"### Non-Animal Images\n\nParse some non-animal images through both models and observe the confidence.","cc0ea95f":"### Dealing with Overconfidence in Neural Networks: Bayesian Approach\n\nCode in this notebook is adapted from [this](https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html) transfer learning tutorial and [this](https:\/\/proceedings.icml.cc\/static\/paper_files\/icml\/2020\/780-Paper.pdf) paper, whose code is [here](https:\/\/github.com\/wiseodd\/last_layer_laplace\/blob\/master\/bnn_laplace_multiclass.ipynb).\n\nAlso for dealing with the over confidence problem: https:\/\/github.com\/max-andr\/relu_networks_overconfident\n\nThere is an associated blog post with this code that can be found [here](https:\/\/jramkiss.github.io\/2020\/07\/29\/overconfident-nn\/)","7a9f1b0f":"### Friends\n\nWhich one of my friends is a cat - removed before making public","6ab683ad":"### Last Layer Laplace Approximation","9b2d65b7":"### Setting a Threshold\n\nLet's see how the accuracy is affected if we set a threshold?"}}