{"cell_type":{"a41ebaae":"code","5c2acb69":"code","9518a895":"code","89ffea84":"code","484cf9a8":"code","6c5ce2ba":"code","aa2eb9d2":"code","665884b1":"code","f05d0cd0":"code","dd42b4cf":"code","07649815":"code","f251c162":"code","f9360f08":"code","69e4b765":"code","26b80c84":"code","bc5bee84":"code","d384a35a":"markdown","00515d87":"markdown","23f6e59c":"markdown","30b939fb":"markdown"},"source":{"a41ebaae":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os,re, random,cv2","5c2acb69":"from keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense,BatchNormalization,Dropout\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","9518a895":"TRAIN_DIR_CAT = '..\/input\/dogs-vs-cats\/dataset\/dataset\/training_set\/cats\/'\ntrain_img_cats = [TRAIN_DIR_CAT+i for i in os.listdir(TRAIN_DIR_CAT)] # use this for full dataset\nTRAIN_DIR_DOG = '..\/input\/dogs-vs-cats\/dataset\/dataset\/training_set\/dogs\/'\ntrain_img_dogs = [TRAIN_DIR_DOG+i for i in os.listdir(TRAIN_DIR_DOG)] # use this for full dataset","89ffea84":"def make_data(list_img,enc):\n    X=[]\n    y=[]\n    count = 0\n    random.shuffle(list_img)\n    for img in list_img:\n       #X.append(Image.open(img).resize((inp_wid,inp_ht), Image.ANTIALIAS))\n       X.append(cv2.resize(cv2.imread(img), (inp_wid,inp_ht), interpolation=cv2.INTER_CUBIC))\n       y.append(enc)\n    return X,y","484cf9a8":"inp_wid = 128\ninp_ht = 128\nbatch_size = 16","6c5ce2ba":"X_cat,y_cat = make_data(train_img_cats,0)\nX_dog,y_dog = make_data(train_img_dogs,1)\nc = list(zip(X_cat+X_dog,y_cat+y_dog))\nrandom.shuffle(c)\nX,Y = list(zip(*c))\nprint(len(X))\nprint(len(Y))","aa2eb9d2":"X_train, X_val, Y_train, Y_val = train_test_split(X[0:4000],Y[0:4000], test_size=0.125, random_state=1)","665884b1":"n_train = len(X_train)\nn_val = len(X_val)","f05d0cd0":"model = Sequential()\n\n# layer num 1\nmodel.add(Conv2D(32,(3,3),input_shape=(inp_wid,inp_ht,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# layer num 2\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# layer num 3\nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# layer num 4\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","dd42b4cf":"train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\nval_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)","07649815":"train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)\nval_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)","f251c162":"earlystop = EarlyStopping(patience=10)","f9360f08":"lrr = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","69e4b765":"callbacks = [earlystop,lrr]","26b80c84":"history = model.fit_generator(\n    train_generator, \n    steps_per_epoch=n_train \/\/ batch_size,\n    epochs=32,\n    validation_data=val_generator,\n    validation_steps=n_val \/\/ batch_size,\n    callbacks = callbacks\n)","bc5bee84":"model.save_weights(\"model_weights.h5\")\nmodel.save('model_keras.h5')","d384a35a":"## Callbacks","00515d87":"# Neural net","23f6e59c":"# Training Generator","30b939fb":"# Prepare Traning Data"}}