{"cell_type":{"1d34f475":"code","af181a8d":"code","85944148":"code","36b811b9":"code","a74a4bb3":"code","d6da341b":"code","520b290c":"code","157475a2":"code","bdc7dfd0":"code","bc2ba793":"code","b689d866":"code","dcb66a0b":"code","6a7ce310":"code","7e031b19":"code","cbf38d1a":"code","4ef1c3f4":"code","bfedd288":"code","a57556eb":"code","0347d59f":"code","46433e74":"code","860ffd68":"code","843fff0e":"code","b9790490":"code","f1e80413":"code","4b85bb8a":"code","a7f28293":"code","f2542a65":"code","af18a4b3":"code","99caacd7":"code","5fd64d8c":"code","1c8a32bf":"code","d6f20437":"markdown","fcbd5eb2":"markdown","810c912f":"markdown","8e8ae667":"markdown","646d3ccd":"markdown","588e4a03":"markdown","60d3d827":"markdown","64334cb5":"markdown","27cc6d44":"markdown","3c614936":"markdown","2d23d780":"markdown","de2818fd":"markdown","80b51d3a":"markdown","a9c90080":"markdown","19bd5a72":"markdown","128c2a28":"markdown","56cf2c87":"markdown","79ec7692":"markdown","63e84193":"markdown","685acf0a":"markdown","959ad360":"markdown","27aa9747":"markdown","f16147a1":"markdown","c6fb2ac3":"markdown","ff65fa0c":"markdown","8b6102f8":"markdown","e0e55459":"markdown","ad6b9086":"markdown","40d74e12":"markdown","7825f789":"markdown","25d07521":"markdown"},"source":{"1d34f475":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af181a8d":"import cv2\nimport imageio\nimport matplotlib.pyplot as plt\n\ndef load_my_image(img_name):\n    return imageio.imread(img_name)\n\n\ndef load_my_images(_max=5011):\n    directory='..\/input\/pascal-voc-2007\/VOCtrainval_06-Nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    dir_list=os.listdir(directory)\n    images=[]\n    for index,path in enumerate(dir_list):\n        if index>_max:\n            return np.array(images)\n        full_path=directory+path\n        image=load_my_image(full_path)\n        images.append(np.array(image))\n    return np.array(images)\n\n        ","85944148":"   \ndef plot_losses_with_psnr(titles,history,kind):\n    plt.figure(figsize=(20,9))\n    for title in titles:\n        plt.plot(history.history[title])\n    plt.title('Model '+kind)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(titles, loc='upper left')\n    plt.show()\n\ndef plot_psnr(history):\n    psnr = [x for x in history.history.keys() if 'PSNR' in x]\n    losses  = [x for x in history.history.keys() if 'PSNR' not in x]\n    plot_losses_with_psnr(losses,history,'loss')\n    plot_losses_with_psnr(psnr,history,'psnr')","36b811b9":"from keras import backend as K\ndef PSNR(y_true, y_pred):\n    max_pixel = 1.0\n    return (10.0 * K.log((max_pixel ** 2) \/ (K.mean(K.square(y_pred - y_true), axis=-1)))) \/ 2.303","a74a4bb3":"imgs_bad=[]\nimgs_mid=[]\nimgs_good=[]\nimages=load_my_images(100)\nfor img in images:\n    img_bad=cv2.resize(img,(72,72))\n    img_mid=cv2.resize(img,(144,144))\n    img_good=cv2.resize(img,(288,288))\n    imgs_bad.append(img_bad\/255.0)\n    imgs_mid.append(img_mid\/255.0)\n    imgs_good.append(img_good\/255.0)\n\nimgs_bad=np.array(imgs_bad)\nimgs_mid=np.array(imgs_mid)\nimgs_good=np.array(imgs_good)","d6da341b":"imgs_bad=[]\nimgs_mid=[]\nimgs_good=[]\nimages=load_my_images()\nfor img in images:\n    img_bad=cv2.resize(img,(72,72))\n    img_mid=cv2.resize(img,(144,144))\n    img_good=cv2.resize(img,(288,288))\n    imgs_bad.append(img_bad)\n    imgs_mid.append(img_mid)\n    imgs_good.append(img_good)\n\nimgs_bad=np.array(imgs_bad)\nimgs_mid=np.array(imgs_mid)\nimgs_good=np.array(imgs_good)","520b290c":"def next_images(images1,images2,images3,start,end,num_of_epochs=1):\n    for e in range(num_of_epochs):\n        for i,(image1,image2,image3) in enumerate(zip(images1[start:end],images2[start:end],images3[start:end])):\n            yield np.expand_dims((image1\/255.0),axis=0),[np.expand_dims((image2\/255.0),axis=0),np.expand_dims((image3\/255.0),axis=0)]\n    ","157475a2":"x_part3_train=next_images(imgs_bad,imgs_mid,imgs_good,1000,5011,5)\nx_part3_val=next_images(imgs_bad,imgs_mid,imgs_good,0,1000,5)\nx_part3_test=next_images(imgs_bad,imgs_mid,imgs_good,0,1000,5)","bdc7dfd0":"def plot_imgs(rows,cols,imgs_list):\n    fig,ax=plt.subplots(rows,cols,figsize=(20,9))\n    for i in range(len(imgs_list)):\n        if len(imgs_list)\/\/cols >1:\n            ax[i\/\/cols,i%cols].imshow(imgs_list[i])\n        else:\n            ax[i].imshow(imgs_list[i])\ncurrent_img=4;\nplot_imgs(1,3,[imgs_bad[current_img],imgs_mid[current_img],imgs_good[current_img]])","bc2ba793":"from keras.layers import Conv2D,UpSampling2D\nfrom keras import Input,Model\n\ndef my_first_model():\n    my_input=Input(shape=(72,72,3))\n    x_lay=Conv2D(64,3,activation='relu',padding='same')(my_input)\n    x_lay=Conv2D(64,3,activation='relu',padding='same')(x_lay)\n    x_lay=UpSampling2D()(x_lay)\n    x_lay=Conv2D(3,1,activation='sigmoid',padding='same',name='output')(x_lay)\n    return Model(my_input,x_lay)\n\nmodel=my_first_model()\nmodel.compile(loss='mse',metrics=[PSNR],optimizer='adam')\n\nhistory=model.fit(imgs_bad[:80],imgs_mid[:80],validation_data=[imgs_bad[80:],imgs_mid[80:]],epochs=20)","b689d866":"plot_psnr(history)","dcb66a0b":"preds=model.predict(imgs_bad[80:])\nfor i in range(0,20):\n    plot_imgs(1,4,[imgs_bad[i+80],imgs_mid[i+80],imgs_good[i+80],preds[i]])","6a7ce310":"from keras.layers import Conv2D,UpSampling2D,LeakyReLU\nfrom keras import Input,Model\ndef my_second_model():\n    my_input=Input(shape=(None,None,3), name='input')\n    x_lay=Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(my_input)\n    x_lay=Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(x_lay)\n    x_lay=UpSampling2D()(x_lay)\n    up_sample2=UpSampling2D()(x_lay)\n    up_sample2=Conv2D(3,1,activation='sigmoid',padding='same',name='288')(up_sample2)\n    x_lay=Conv2D(3,1,activation='sigmoid',padding='same',name='144')(x_lay)\n    return Model(my_input,outputs=[x_lay,up_sample2])\n\nmodel2=my_second_model()\nmodel2.compile(loss='mse',metrics=[PSNR],optimizer='adam')\n\nhistory2=model2.fit_generator(x_part3_train,steps_per_epoch=4011,epochs=5,validation_data=x_part3_val,validation_steps=1000)","7e031b19":"preds=model2.predict_generator(x_part3_test,1000)\nfor i in range(0,20):\n    plot_imgs(1,5,[imgs_bad[i],imgs_mid[i],imgs_good[i],preds[0][i],preds[1][i]])","cbf38d1a":"plot_psnr(history2)","4ef1c3f4":"from keras.layers import Conv2D,UpSampling2D,Activation,Add\nfrom keras import Input,Model\ndef residual_bolck(my_shape):\n    _input=Input(shape=(None,None,my_shape))\n    x_lay=Conv2D(my_shape,3,activation=LeakyReLU(0.2),padding='same')(_input)\n    x_lay=Conv2D(my_shape,3,activation=LeakyReLU(0.2),padding='same')(x_lay)\n    x_lay= Add()([_input,x_lay])\n    return Model(_input,Activation('relu')(x_lay))","bfedd288":"from keras.layers import Conv2D,UpSampling2D\nfrom keras import Input,Model\ndef my_third_model():\n    my_input=Input(shape=(None,None,3))\n    x_lay=Conv2D(32,3,activation=LeakyReLU(0.2),padding='same')(my_input)\n    x_lay=residual_bolck(32)(x_lay)\n    x_lay=residual_bolck(32)(x_lay)\n    x_lay=UpSampling2D()(x_lay)\n    up_sample2=residual_bolck(32)(x_lay)\n    up_sample2=UpSampling2D()(up_sample2)\n    up_sample2=Conv2D(3,1,activation='sigmoid',padding='same',name='288')(up_sample2)\n    x_lay=Conv2D(3,1,activation='sigmoid',padding='same',name='144')(x_lay)\n    return Model(my_input,outputs=[x_lay,up_sample2])\n\nmodel3=my_third_model()\nmodel3.compile(loss='mse',metrics=[PSNR],optimizer='adam')\n\nhistory3=model3.fit_generator(x_part3_train,steps_per_epoch=4011,epochs=5,validation_data=x_part3_val,validation_steps=1000)","a57556eb":"preds=model3.predict_generator(x_part3_test,1000)\nfor i in range(0,20):\n    plot_imgs(1,5,[imgs_bad[i],imgs_mid[i],imgs_good[i],preds[0][i],preds[1][i]])","0347d59f":"plot_psnr(history3)","46433e74":"from keras.layers import Conv2D,UpSampling2D,Activation,Concatenate\nfrom keras import Input,Model\ndef dilated_bolck(my_shape):\n    _input=Input(shape=(None,None,my_shape))\n    x_lay1=Conv2D(my_shape,3,activation='relu',dilation_rate=(1,1),padding='same')(_input)\n    x_lay2=Conv2D(my_shape,3,activation='relu',dilation_rate=(2,2),padding='same')(_input)\n    x_lay3=Conv2D(my_shape,3,activation='relu',dilation_rate=(4,4),padding='same')(_input)\n    x_lay=Concatenate()([x_lay1,x_lay2,x_lay3])\n    x_lay=Activation('relu')(x_lay)\n    x_lay=Conv2D(my_shape,3,activation='relu',padding='same')(x_lay)\n    return Model(_input,x_lay)","860ffd68":"from keras.layers import Conv2D,UpSampling2D,LeakyReLU\nfrom keras import Input,Model\ndef my_forth_model():\n    my_input=Input(shape=(None,None,3))\n    x_lay=Conv2D(32,3,activation=LeakyReLU(0.2),padding='same')(my_input)\n    x_lay=dilated_bolck(32)(x_lay)\n    x_lay=dilated_bolck(32)(x_lay)\n    x_lay=UpSampling2D()(x_lay)\n    up_sample2=dilated_bolck(32)(x_lay)\n    up_sample2=UpSampling2D()(up_sample2)\n    up_sample2=Conv2D(3,1,activation='sigmoid',padding='same',name='288')(up_sample2)\n    x_lay=Conv2D(3,1,activation='sigmoid',padding='same',name='144')(x_lay)\n    return Model(my_input,outputs=[x_lay,up_sample2])\n\nmodel4=my_forth_model()\nmodel4.compile(loss='mse',metrics=[PSNR],optimizer='adam')\n\nhistory4=model4.fit_generator(x_part3_train,steps_per_epoch=4011,epochs=5,validation_data=x_part3_val,validation_steps=1000)","843fff0e":"preds=model4.predict_generator(x_part3_test,1000)\nfor i in range(0,20):\n    plot_imgs(1,5,[imgs_bad[i],imgs_mid[i],imgs_good[i],preds[0][i],preds[1][i]])","b9790490":"plot_psnr(history4)","f1e80413":"from tensorflow.keras.layers import Conv2D,UpSampling2D,Concatenate,LeakyReLU\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import Input,Model\nvgg_lay = VGG16(weights='imagenet', include_top=False, input_shape = (None,None, 3))\nvgg_lay = Model(inputs=vgg_lay.input,outputs=vgg_lay.get_layer(\"block1_conv2\").output)","4b85bb8a":"def my_fifth_model():\n    my_input=Input(shape=(None,None,3))\n    x_lay=Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(my_input)\n    x_lay=Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(x_lay)\n    x_lay2=vgg_lay(my_input)\n    x_lay2=Concatenate()([x_lay,x_lay2])\n    x_lay2=UpSampling2D()(x_lay2)\n    x_lay2=Conv2D(3,1,activation='sigmoid',padding='same',name='144')(x_lay2)\n    up_sample2=UpSampling2D()(x_lay2)\n    up_sample2=Conv2D(3,1,activation='sigmoid',padding='same',name='288')(up_sample2)\n    return Model(my_input,outputs=[x_lay2,up_sample2])\n\nmodel5=my_fifth_model()\nmodel5.compile(loss='mse',metrics=[PSNR],optimizer='adam')\n\nhistory5=model5.fit_generator(x_part3_train,steps_per_epoch=4011,epochs=5,validation_data=x_part3_val,validation_steps=1000)","a7f28293":"preds=model5.predict_generator(x_part3_test,1000)\nfor i in range(0,20):\n    plot_imgs(1,5,[imgs_bad[i],imgs_mid[i],imgs_good[i],preds[0][i],preds[1][i]])","f2542a65":"plot_psnr(history5)","af18a4b3":"from tensorflow.keras.layers import Conv2D,UpSampling2D,Concatenate,Lambda,LeakyReLU\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import Input,Model\nvgg_lay = VGG16(weights='imagenet', include_top=False, input_shape = (None,None, 3))\nvgg_lay = Model(inputs=vgg_lay.input,outputs=vgg_lay.get_layer(\"block1_conv2\").output)","99caacd7":"def my_sixth_model():\n    my_input=Input(shape=(None,None,3))\n    x_lay=Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(my_input)\n    x_lay=Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(x_lay)\n    x_lay2=vgg_lay(my_input)\n    x_lay2=Concatenate()([x_lay,x_lay2])\n    x_lay2 = Lambda(lambda x:tf.nn.depth_to_space(x,2),name=\"lambda\")(x_lay2)\n    x_lay2=Conv2D(3,1,activation='sigmoid',padding='same',name='144')(x_lay2)\n    \n    up_space2 = Conv2D(64,3,activation='sigmoid',padding='same')(x_lay2)\n    up_space2 = Lambda(lambda x:tf.nn.depth_to_space(x,2),name=\"lambda_b\")(up_space2)\n    up_space2=Conv2D(3,1,activation='sigmoid',padding='same',name='288')(up_space2)\n    return Model(my_input,outputs=[x_lay2,up_space2])\n\nmodel6=my_sixth_model()\nmodel6.compile(loss='mse', metrics=[PSNR],optimizer='adam')\n\nhistory6=model6.fit_generator(x_part3_train,steps_per_epoch=4011,epochs=5,validation_data=x_part3_val,validation_steps=1000)","5fd64d8c":"preds=model6.predict_generator(x_part3_test,1000)\nfor i in range(0,20):\n    plot_imgs(1,5,[imgs_bad[i],imgs_mid[i],imgs_good[i],preds[0][i],preds[1][i]])","1c8a32bf":"plot_psnr(history6)","d6f20437":"### show some images\nin the images is hard to see any differences from last models.","fcbd5eb2":"# Assignment 3 Deep Learning\n### Yuval Sabag 205712151\nassignment 3 with pascal-voc-2007 dataset.\nin this report i will show and explain about predicting high reslution images from low resolution images by creating a model that studies the transformation needed to move from low resolution pictures to high resolution pictures.\ni will use images in 72X72 resolution, 144X144 resolution and 288X288 resolution.","810c912f":"## compute my first model\nas we can see, this model is pretty naive like requested and we train only on 100 pictures.","8e8ae667":"# show and compare the pictures\nthe pictures are smoother than the first model. we can see the improvement.","646d3ccd":"# building my forth model\nnow we will try to switch the residual block in a dilated block with 3 convolution layers and concatenate them.","588e4a03":"### load images for the rest of the models\nload the images in a regular way and divide them by 255.0 in a generator.","60d3d827":"## build my fifth model\nnow we will try to use a VGG16 layer, and concatenate it to the convolution layers.","64334cb5":"### print the model losses\nI can see that by the result it is not the highest psnr we have got. ","27cc6d44":"## building my sixth model\nnow we will try to use depth to space of tensorflow and hope to make better results.","3c614936":"## print some images\nin the images is hard to see any differences from last models.","2d23d780":" ### resize and load for first model\n load 100 picuters for the first model. load them normally. divide by 255.0 to get values between 0 to 1. to train and calculate faster.","de2818fd":"## building and training my second model\nnow I will try one more layer of upsampling and connect it to the output. I will use 5 epochs because in more epochs i get overfitting.\nanother thing we will try is to use leaky relu instead of relu to not loose the values to 0. i checked the results with leaky relu instead of relu, and i found out that the leaky relu get better results and not overfit like relu. this is because we don't loose values to 0.","80b51d3a":"## plot losses\nas we can see and as I said before the psnr is growing as long as the loss is going down. the psnr is in the area of 25-26. pretty good for a first model, and for training on 100 pictures only.","a9c90080":"### plot functions\nplot the losses and the psnr result for checking the model.","19bd5a72":"# **conclusion**\nwe can conclude that the use of leaky relu helped to make the picture smother. in addition the psnr is good measurment to investigate the results. we can see that our second model was the best, eith the best, smoothest, best looking pictures, and the highest psnr.","128c2a28":"## print some images\nI don't see any improvement from the last model. so we can make insight that the use in residual block is not helping very much.","56cf2c87":"### build and train the model.","79ec7692":"### print the model losses\nin the images is hard to see any differences from last models.","63e84193":"# plot the losses graph \nwe can see that the train psnr is in the area of 31-32 which is much better than the first model. we can see the pictures, and make insights thar the psnr is really good measurment for super resulotion.","685acf0a":"### frist we will prepare the residual block","959ad360":"## Building my third model\nnow we will use residual block and swich the convolution layers with it. ","27aa9747":"## print the third model losses\nwe can see a little improvement in the psnr(0.1-0.2 improvement). not something that we can conclude from on our model. ","f16147a1":" Load Images functions ","c6fb2ac3":"## Print some of the images\nhere is an example of a picture from the dataset.\nthe left one is 72X72 resulotion, the middle is 144X144 resulution and the right ne 288X288 resulotion.","ff65fa0c":"## psnr loss function\npsnr loss function is a function to check the loss in super resoultion. psnr is a result of dividing by the mse and that is why as long as the mse is lower, the psnr is greater. when the mse is zero the psnr is infinity. ","8b6102f8":"### now we will train the model.","e0e55459":"### generator function\nget 3 kinds of images reside each of them and generate in triples.\nbelow I make my first generated data","ad6b9086":"## print the model losses\nwe can see that the model start to overfit from the second epoch, and that we didn't get any improvement from last models.","40d74e12":"### print the model losses\nwe can see that with this change, we get a model that does'nt overfit over 5 epochs, but we didn't get any improvement in the psnr.","7825f789":"## show some predictions compare to the real images\nas we can see, the model putput picture (the most right one), is not smooth and in the next models i will try to make it better.","25d07521":"## building the dilated block"}}