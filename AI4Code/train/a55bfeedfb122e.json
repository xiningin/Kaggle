{"cell_type":{"9608da36":"code","23d19692":"code","22e95ca7":"code","f57ba1b3":"code","d11459a5":"code","18c07c22":"code","b9082838":"code","314f6bd9":"code","1dff3929":"code","db300542":"code","fe0fc96c":"code","67393518":"code","89f519da":"code","20fe05da":"code","276d3057":"code","4819a4be":"code","60d96365":"code","85d626ba":"code","73e63078":"code","898c5d8d":"code","e369ed60":"code","636ddd76":"code","78d5c025":"code","093c717b":"code","f0a1bc00":"markdown","64a8cd2f":"markdown","8f2d1a1d":"markdown","796e2b32":"markdown","eb1825b6":"markdown","490708d6":"markdown","095f037e":"markdown","afe4c0d6":"markdown","240b3278":"markdown","9594d562":"markdown","600c3002":"markdown","eb167db3":"markdown","56409340":"markdown","3bcaef88":"markdown","5dcb6f23":"markdown","dfed07fb":"markdown","ddf7b8c7":"markdown","e90df872":"markdown","9ae2eb46":"markdown","44d206a8":"markdown","38426bfe":"markdown","caf02af4":"markdown"},"source":{"9608da36":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nnp.random.seed(64) # initialize a random seed, this will help us make the random stuff reproducible. \nimport warnings\nwarnings.filterwarnings('ignore') # ignore jupyter's warnings, this is only used for the purpose of the blog post","23d19692":"data = pd.read_csv(os.path.join('..', 'input', 'KaggleV2-May-2016.csv'), parse_dates=['AppointmentDay', 'ScheduledDay'],\n                   dtype={\n                       'Scholarship': bool,\n                       'Hipertension': bool,\n                       'Diabetes': bool,\n                       'Alcoholism': bool\n                        },\n                   index_col='AppointmentID'\n)","22e95ca7":"data.head()","f57ba1b3":"sns.countplot(data['No-show']);","d11459a5":"data['IsMale'] = data['Gender'] == 'M'","18c07c22":"drop_columns = ['ScheduledDay', 'AppointmentDay', 'PatientId', 'Gender', 'Neighbourhood']\ndata.drop(drop_columns, inplace=True, axis=1)","b9082838":"data.head()","314f6bd9":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics","1dff3929":"X = data.drop('No-show', axis=1)\ny = data['No-show']\nx_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y)","db300542":"model = LogisticRegression()\nmodel.fit(x_train, y_train)\npred = model.predict(x_test)\nprint('score on training set:', model.score(x_train, y_train))\nprint('score on test set:', model.score(x_test, y_test))","fe0fc96c":"print(metrics.classification_report(y_true=y_test, y_pred=pred))","67393518":"y_yes = y_train[y_train == 'Yes']\nx_yes = x_train.loc[y_yes.index]\n\ny_no = y_train[y_train == 'No']\nx_no = x_train.loc[y_no.index]","89f519da":"oversample_X = pd.concat([x_no, x_yes, x_yes, x_yes, x_yes])\noversample_y =  pd.concat([y_no, y_yes, y_yes, y_yes, y_yes])","20fe05da":"model = LogisticRegression()\nmodel.fit(oversample_X, oversample_y)\npred = model.predict(x_test)\nprint('score on test set:', model.score(x_test, y_test))\nprint(metrics.classification_report(y_true=y_test, y_pred=pred))","276d3057":"y_yes = y_train[y_train == 'Yes']\nx_yes = x_train.loc[y_yes.index]","4819a4be":"y_no = y_train[y_train == 'No']\nundersample_y_no = y_no.sample(y_yes.shape[0])\n\nundersample_x_no = x_train.loc[undersample_y_no.index]","60d96365":"undersample_y = pd.concat([undersample_y_no, y_yes])\nundersample_X = pd.concat([undersample_x_no, x_yes])","85d626ba":"model = LogisticRegression()\nmodel.fit(undersample_X, undersample_y)\npred = model.predict(x_test)\nprint('score on test set:', model.score(x_test, y_test))\nprint(metrics.classification_report(y_true=y_test, y_pred=pred))","73e63078":"from imblearn.over_sampling import SMOTE\n\nx_train_smote, y_train_smote = SMOTE(ratio='auto', k_neighbors=5, m_neighbors=10,\n      out_step=0.5, kind='regular', svm_estimator=None, n_jobs=-1).fit_sample(x_train, y_train)","898c5d8d":"from collections import Counter\n\nprint('The original class distribution: {},'.format(Counter(y_train)))\nprint('After SMOTE class distribution:  {}'.format(Counter(y_train_smote)))","e369ed60":"model = LogisticRegression()\nmodel.fit(x_train_smote, y_train_smote)\npred = model.predict(x_test)\nprint('score on test set:', model.score(x_test, y_test))\nprint(metrics.classification_report(y_true=y_test, y_pred=pred))","636ddd76":"from sklearn.utils import class_weight\ntrain_weights = class_weight.compute_sample_weight('balanced', y=y_train)","78d5c025":"model = LogisticRegression()\nmodel.fit(x_train, y_train, sample_weight=train_weights)\npred = model.predict(x_test)\nprint('score on test set:', model.score(x_test, y_test))\nprint(metrics.classification_report(y_true=y_test, y_pred=pred))","093c717b":"model = LogisticRegression(class_weight='balanced')\nmodel.fit(x_train, y_train)\npred = model.predict(x_test)\nprint('score on test set:', model.score(x_test, y_test))\nprint(metrics.classification_report(y_true=y_test, y_pred=pred))","f0a1bc00":"At first glance this is looking like a very good score for this pretty simple model and data.\nLet's look at the classification report to see the scores for each class.","64a8cd2f":"### 2) Give weights to samples\/classes in your data.\n#### Sample & Class Weight\n\nSample-Weights is an array of weights that are assigned to individual samples.\nThis array tells the classifier which samples should have more influence on the predictions.\n\n\nWe use Sample-Weight in the same way on samples from the same class, so in our case it's more like Class-Weight.\nHigher Class-Weight\/Sample-Weight means you want to put more emphasis on this class\/sample.\n\n\n**Sample-Weight and Class-Weight give weights to a sample\/class to use a modified loss function.**","8f2d1a1d":"You can compute sample-weights by using the \"utils\" sub-module of Sklearn.\nThe function above, computes the same sample-weight for each class instance, so it would be same as class-weight.\nThe \u201cbalanced\u201d mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data.\n\n\nThe sample-weights array go to the 'fit' method.","796e2b32":"The default parameters of the \"SMOTE\" had the same results as the simple oversampling in this case.\nI'll recommend changing the \"SMOTE\" parameters and maybe using other methods from this [imblearn](https:\/\/pypi.org\/project\/imblearn\/) module.","eb1825b6":"After we took a look at the dataset. I would like to know how my class labels are distributed:","490708d6":"### Conclusion\nAs far as I know, there isn't a \"good\" way to deal with imbalanced data.\nI have showed you some ways to deal with the problem, but I'm sure there are a lot more ways out there, just search for them.\n\n\nWhen I encounter an imbalanced data problem, I try some of the methods and see what works best. Sometimes I would even try to combine methods, like over and under sampling together.\n\n\n**Hope this helps**","095f037e":"This is way better.\nWe can see we have a lower score on the \"No\" recall but a better score on the overall \"Yes\" predictions.","afe4c0d6":"#### Undersample\nUndersample only on the train data and predict on the imbalanced test data.\nWe would basically drop some of the data - again, simple as that.","240b3278":"After this further look you can see this is a very bad.\nAlthogh we got almost 80% accuracy score we actually have a model which isn't that smart (and not that good).\n**It always predicts a show-up** (\"No\" means the person did show to the appointment).\n\nThe test data contains of 27631 samples, 5579 (~20%) samples are 'Yes' and the rest (~80%) are 'No'.\nThe model predicts 'No' all the time, and this is why we have 100% recall and only 80% precision scores.\n\nThis model won't achieve our goal and help us predict if the patient is or isn't going to show-up.\nThe model will always say the patient is going to show, no matter what is the data.\n\n\n**This is a great example why the simple accuracy score evaluating matrix is not always good.**\nIn this types of problems accuracy score won't give you a good evaluation of your model.","9594d562":"In some of Sklearn's algorithms you can pass a \"class-weight\" parameter instead of computing it as I just showed you.\nLet's see an example of that:","600c3002":"This is looking as an imbalanced data indeed.\nAlmost 4 times more 'No' instances than 'Yes' ones.","eb167db3":"### 1) Resample your data\n\nResample your data is basically over-sampling or under-sampling your training data.\n**Over-sampling** is the process of **adding or duplicating** one (or more) class' data points in order to balance the ratio between class distributions in a data set.\n**Under-sampling** is the process of **removing** one (or more) class' data points in order to balance the ratio between class distributions in a data set.\n[You can read more about these techniques here](https:\/\/en.wikipedia.org\/wiki\/Oversampling_and_undersampling_in_data_analysis)\nI'll show you the basic ways of oversampling and undersampling, as well as a synthetic way of doing so.\n\n#### How Do I Choose between over and under sampling?\n<span style=\"color:green\"> The Oversampling's plus is using all the variety of the data and not losing any sample.<\/span>\n<span style=\"color:red\">It's downside is increasing the number of samples, which can make some algorithms slower.<\/span>\n\n<span style=\"color:green\">The Undersampling's plus is by decreasing the number of samples which can yield faster running algorithms.<\/span>\n<span style=\"color:red\">It's downside is losing some of the data's variety, which in some cases can damage the results.<\/span>\n\nIn my opinion the best way is to do **both** over and under sampling at the same time.\nBy this I mean undersample a bit from the majority class but don't compare the ratio with the minority class, and oversample the minority class a bit but not to much as well.\n\n\n#### Oversample\nOversample only on the train data and predict on the imbalanced test data.\nWe would basically duplicate some of the data - simple as that.","56409340":"### Modelling\nLoad more modules","3bcaef88":"In this case the oversampling and the undersampling were almost the same.","5dcb6f23":"### Initilize a first simple model","dfed07fb":"#### Synthetic Minority Over-sampling Technique (SMOTE)\nThis is basically generating more samples from the minority class.\nThe SMOTE algorithm is based on the K-nearest neighbors technique.\nCreating additional data points close to the minority class.\n\nWe will use the SMOTE algorithm by using the [imbalanced-learn\/imblearn module](http:\/\/contrib.scikit-learn.org\/imbalanced-learn\/stable\/).\nThis module has a lot of intresting methods. We will start with the \"SMOTE\" method under \"over_sampling\".","ddf7b8c7":"From reading the dataset's info [here](https:\/\/www.kaggle.com\/joniarroba\/noshowappointments) and from playing with the data earlier, I have some knowledge about the features' types, so I'll load them with the relevant dtype.","e90df872":"Same scores for sample and class weights.\nIn this case the scores are very similar to the manual over\/under sampling as well.","9ae2eb46":"# Applied Imbalanced Data Solutions\n\n#### What Is Imbalanced Data?\n\nImbalanced data is when the classes are not represented equally.\nOne class has a lot more instances than the other class (or classes).\n\nA lot of real world datasets and problems don't have equal number of samples in each class.\nThe most common example of an imbalanced problem is fraud detection where most of the data is not a fraud ...\n\nImbalanced datasets can cause a lot of frustration.\nIn this blog post I'll show you some of the ways I deal with imbalanced datasets.\n\n#### Which dataset are we going to use ?\nWe will use the [\"Medical Appointment No Shows\" dataset from Kaggle](https:\/\/www.kaggle.com\/joniarroba\/noshowappointments).\nThis dataset includes 300k medical appointments and 15 variables (characteristics) of each appointment.\nThe goal is to predict if the patient is or isn't going to show-up.\n\nThis blog's purpose is just to show how to handle imbalanced data, therefore I won't get into much data cleaning and feature engineering.\n\nWe'll load some modules, load the data and initilize a first basic model.","44d206a8":"We used the the default parameters of the \"SMOTE\" method.\nOf course changing these parameters can yield better results.\n\nLet's see how the \"SMOTE\" method changed the distribution of our train data:","38426bfe":"As I mentioned before, I'll first initilize a very simple model for demonstration purpose only.\nSo for now I'll drop date and categorical features, which would have required some feature extraction and engineering work.\n\nLet's see our data now:\n","caf02af4":"There are some possible ways to deal with this imbalanced problem. The two main ways are:\n\n1) Resample your data.\n2) Give weights to samples\/classes in your data."}}