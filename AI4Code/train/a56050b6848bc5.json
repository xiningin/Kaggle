{"cell_type":{"7cd42241":"code","0919af90":"code","8119c572":"code","189a91eb":"code","d5b85dfa":"code","5880dfca":"code","40891ac7":"code","579b569b":"code","fd420581":"code","bb9dfbee":"code","2fe8fffb":"code","5390ae76":"code","77364823":"code","70d14433":"code","d7ccc2f2":"code","6f83dd7b":"code","4120d2f3":"code","aea2df94":"code","23de546c":"code","50d486e9":"code","21659b54":"code","3dbee80a":"code","8fd75c1f":"code","3d7169e0":"code","017d4934":"code","aaae811d":"code","bf61f886":"code","6c4ddde2":"code","c1084d8b":"code","084808ff":"code","a2fabfaf":"code","7e649486":"code","8f675d38":"code","08fd2359":"markdown","469837ac":"markdown","a1113e62":"markdown","42231664":"markdown","01618f46":"markdown","e521dd84":"markdown","fbb5f28d":"markdown","a9cce14f":"markdown","34e58fa1":"markdown","1033622b":"markdown","33497364":"markdown","36217cbc":"markdown","aaead5e8":"markdown","01e9cd91":"markdown","4a9a8169":"markdown","417251ea":"markdown","2ff63187":"markdown","fcf39f68":"markdown","93dec1e2":"markdown"},"source":{"7cd42241":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# PreProcessing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\n#clustering\nfrom scipy.spatial.distance import cdist,pdist\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans\n\nfrom mpl_toolkits.mplot3d import Axes3D\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0919af90":"data = pd.read_csv('\/kaggle\/input\/marketing-data\/marketing_data.csv')","8119c572":"todayy = pd.Timestamp('28\/2\/21')\ndata['Dt_Customer']= pd.to_datetime(data['Dt_Customer'])\ndata['Dt_Customer'] = (todayy - data['Dt_Customer']).dt.days","189a91eb":"data['Spending']=data['MntWines']+data['MntFruits']+data['MntMeatProducts']+data['MntFishProducts']+data['MntSweetProducts']+data['MntGoldProds']\ndata['Transactions']=data['NumWebPurchases']+data['NumCatalogPurchases']+data['NumStorePurchases']\ndata=data[['ID','Spending','Transactions','Recency','Dt_Customer']]\ndata = data[data['Transactions'] > 1] # customers with repeated purchases, implying number of transactions must be at least 2\ndata = data[data['Spending'] > 0]","d5b85dfa":"#statistical summary\nprint(\"Summary of the last 2 years spending\")\nprint(\"Number of transactions: \", data['Transactions'].sum())\nprint(\"Total sales: \",data['Spending'].sum())\nprint(\"Number of customers:\", data['ID'].nunique())","5880dfca":"recency = data[['ID','Recency']]\nrecency","40891ac7":"frequency = data[['ID','Spending']]\nfrequency","579b569b":"monetary = data[['ID','Transactions']]\nmonetary","fd420581":"temp = recency.merge(frequency,on='ID')\nRFM_Segmentation  = temp.merge(monetary,on='ID')\nRFM_Segmentation.columns = ['ID','Recency','Frequency','Monetary']\nRFM_Segmentation","bb9dfbee":"#Elbow Method\nsse={}\ntx_recency = RFM_Segmentation[['Recency']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000,random_state=0).fit(tx_recency)\n    tx_recency[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ \nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","2fe8fffb":"#silhouette\nkmeans=KMeans(n_clusters=2,random_state=0)\nkmeans.fit(tx_recency)\n\nlabels=kmeans.labels_\nsilhouette_score(tx_recency,labels,metric='euclidean')\n\ns_score=[]\n\nnumber_of_cluster = range(2,11)\n\nfor i in number_of_cluster:\n    kmeans=KMeans(n_clusters=i,random_state=0)\n    kmeans.fit(tx_recency)\n    labels=kmeans.labels_\n    s_score.append(silhouette_score(tx_recency,labels,metric='euclidean'))\n    \nplt.figure(figsize=(12,7))\n\nsns.lineplot(number_of_cluster,s_score)\nsns.scatterplot(number_of_cluster,s_score)\n\nplt.xticks(number_of_cluster)\nplt.xlabel('number of cluster')\nplt.ylabel('silloutte score')","5390ae76":"#make column for Recency Cluster\nkmeans = KMeans(n_clusters=2,random_state=0)\nkmeans.fit(RFM_Segmentation[['Recency']])\nRFM_Segmentation['RecencyCluster'] = kmeans.labels_\n\n#visualization Recency cluster\nplt.figure(figsize=(10,10))\n\nsns.scatterplot(x='Recency', y ='Recency',data=RFM_Segmentation,hue='RecencyCluster')\nplt.show()","77364823":"#Elbow Method\nsse={}\ntx_Frequency = RFM_Segmentation[['Frequency']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000,random_state=0).fit(tx_Frequency)\n    tx_Frequency[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ \nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()\n","70d14433":"#silhouette\nkmeans=KMeans(n_clusters=2,random_state=0)\nkmeans.fit(tx_Frequency)\n\nlabels=kmeans.labels_\nsilhouette_score(tx_Frequency,labels,metric='euclidean')\n\ns_score=[]\n\nnumber_of_cluster = range(2,11)\n\nfor i in number_of_cluster:\n    kmeans=KMeans(n_clusters=i,random_state=0)\n    kmeans.fit(tx_Frequency)\n    labels=kmeans.labels_\n    s_score.append(silhouette_score(tx_Frequency,labels,metric='euclidean'))\n    \nplt.figure(figsize=(12,7))\n\nsns.lineplot(number_of_cluster,s_score)\nsns.scatterplot(number_of_cluster,s_score)\n\nplt.xticks(number_of_cluster)\nplt.xlabel('number of cluster')\nplt.ylabel('silloutte score')","d7ccc2f2":"#make column Frequency Cluster\nkmeans = KMeans(n_clusters=2,random_state=0)\nkmeans.fit(RFM_Segmentation[['Frequency']])\nRFM_Segmentation['FrequencyCluster'] = kmeans.labels_\n\n#visualization Frequency cluster\nplt.figure(figsize=(10,10))\n\nsns.scatterplot(x='Frequency', y ='Frequency',data=RFM_Segmentation,hue='FrequencyCluster')\nplt.show()\n","6f83dd7b":"#for reverse cluster value, cause the higher frequency is better\nRFM_Segmentation['FrequencyCluster']=np.where(RFM_Segmentation['FrequencyCluster']==1,0,1)","4120d2f3":"#Elbow Method\nsse={}\ntx_Monetary = RFM_Segmentation[['Monetary']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000,random_state=0).fit(tx_Monetary)\n    tx_Monetary[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_ \nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","aea2df94":"#silhouette\nkmeans=KMeans(n_clusters=2,random_state=0)\nkmeans.fit(tx_Monetary)\n\nlabels=kmeans.labels_\nsilhouette_score(tx_Monetary,labels,metric='euclidean')\n\ns_score=[]\n\nnumber_of_cluster = range(2,11)\n\nfor i in number_of_cluster:\n    kmeans=KMeans(n_clusters=i,random_state=0)\n    kmeans.fit(tx_Monetary)\n    labels=kmeans.labels_\n    s_score.append(silhouette_score(tx_Monetary,labels,metric='euclidean'))\n    \nplt.figure(figsize=(12,7))\n\nsns.lineplot(number_of_cluster,s_score)\nsns.scatterplot(number_of_cluster,s_score)\n\nplt.xticks(number_of_cluster)\nplt.xlabel('number of cluster')\nplt.ylabel('silloutte score')\n","23de546c":"#make column for Monetary Cluster\nkmeans = KMeans(n_clusters=10,random_state=0)\nkmeans.fit(RFM_Segmentation[['Monetary']])\nRFM_Segmentation['MonetaryCluster'] = kmeans.labels_\n\n#visualization Monetary cluster\nplt.figure(figsize=(10,10))\n\nsns.scatterplot(x='Monetary', y ='Monetary',data=RFM_Segmentation,hue='MonetaryCluster')\nplt.show()\n","50d486e9":"RFM_Segmentation","21659b54":"X=RFM_Segmentation[['Recency','Frequency','Monetary']]","3dbee80a":"X","8fd75c1f":"fig = plt.figure(figsize=(10,10))\nax= fig.add_subplot(111,projection='3d')\n\nx=X['Recency']\ny=X['Frequency']\nz=X['Monetary']\nax.scatter(x,y,z,c='r',marker='o')\n\nax.set_xlabel('Recency')\nax.set_ylabel('Frequency')\nax.set_zlabel('Monetary')\n\nplt.show()","3d7169e0":"#elbow method\n#clustering variation\nnumber_of_cluster = range(2,11)\nclusterings=[KMeans(n_clusters=k,random_state=0).fit(X) for k in number_of_cluster]\ncentroids= [k.cluster_centers_ for k in clusterings]\n\n#within sum square, utk cari jarak \nD_k=[cdist(X,cent,'euclidean') for cent in centroids]\ncIdx=[np.argmin(D,axis=1) for D in D_k]\ndist=[np.min(D,axis=1)for D in D_k]\navg_withinSS=[sum(d)\/X.shape[0] for d in dist]\n\n#visualisasi\nplt.figure(figsize=(12,7))\nsns.lineplot(number_of_cluster,avg_withinSS)\nsns.scatterplot(number_of_cluster,avg_withinSS)\n\nplt.xticks(number_of_cluster)\n\nplt.xlabel('Number Of Clusters')\nplt.ylabel('average within sum square')","017d4934":"#Sillhoutte\ns_score=[]\n\nnumber_of_cluster = range(2,11)\n\nfor i in number_of_cluster:\n    kmeans=KMeans(n_clusters=i,random_state=0)\n    kmeans.fit(X)\n    labels=kmeans.labels_\n    s_score.append(silhouette_score(X,labels,metric='euclidean'))\n    \n#viasulisasi\nplt.figure(figsize=(12,7))\n\nsns.lineplot(number_of_cluster,s_score)\nsns.scatterplot(number_of_cluster,s_score)\n\nplt.xticks(number_of_cluster)\nplt.xlabel('number of cluster')\nplt.ylabel('silloutte score')","aaae811d":"#final result we decide to use 2 cluster (based on silloutte score)\n\nkmeans=KMeans(n_clusters=2,random_state=0)\nkmeans.fit(X)\nRFM_Segmentation['cluster']=kmeans.labels_\n\n#visualisasi\nfig=plt.figure(figsize=(10,10))\nax= fig.add_subplot(111,projection='3d')\n\nax.scatter(X['Recency'][RFM_Segmentation['cluster']==0],X['Frequency'][RFM_Segmentation['cluster']==0],X['Monetary'][RFM_Segmentation['cluster']==0], c='r', marker='o')\nax.scatter(X['Recency'][RFM_Segmentation['cluster']==1],X['Frequency'][RFM_Segmentation['cluster']==1],X['Monetary'][RFM_Segmentation['cluster']==1], c='b', marker='x')\n\n\nax.set_ylabel('Recency')\nax.set_zlabel('Frequency')\nax.set_xlabel('Monetary')\n\nplt.legend(('cluster0','cluster1'))\n\nplt.show()","bf61f886":"RFM_Segmentation['RF_Score'] = RFM_Segmentation['RecencyCluster'] + RFM_Segmentation['FrequencyCluster']\nRFM_Segmentation.groupby('RF_Score')['Recency','Frequency','Monetary'].mean()","6c4ddde2":"#Clustering naming based on unique RFM values\ndef rfm_label(df):\n    if df['RF_Score'] == 2:\n        return 'Priority'\n    elif ((df['RF_Score'] == 1)):\n        return 'Loyal'\n    else:\n        return 'Need Attention'","c1084d8b":"RFM_Segmentation['RFM_Label'] = RFM_Segmentation.apply(rfm_label, axis=1)\nRFM_Segmentation","084808ff":"#plot distribution\nplt.figure(figsize=(12,10))\n# Plot distribution of R\nplt.subplot(3, 1, 1); sns.distplot(RFM_Segmentation['Recency'])\n# Plot distribution of F\nplt.subplot(3, 1, 2); sns.distplot(RFM_Segmentation['Frequency'])\n# Plot distribution of M\nplt.subplot(3, 1, 3); sns.distplot(RFM_Segmentation['Monetary'])\n# Show the plot\nplt.show()","a2fabfaf":"sns.countplot(y='RFM_Label',data=RFM_Segmentation)","7e649486":"#analyss persegment\n# Calculate average values for each RFM segment, and return a size of each segment \nRFM_interpret = RFM_Segmentation.groupby('RFM_Label').agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'Monetary': ['mean', 'count'],\n}).round(1)\n# Print the aggregated dataset\nRFM_interpret","8f675d38":"#segment vizual R and F\n#monetary just for agg\nimport squarify\nRFM_interpret.columns = ['Recencymean','Frequencymean', 'Monetarymean','Count']\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(16, 9)\nsquarify.plot(sizes=RFM_interpret['Count'], \n              label=['Priority', 'Loyal','Needs Attention'], alpha=.6 )\nplt.title(\"RFM Segments\",fontsize=22,fontweight=\"bold\")\nax.set_xlabel('Recency',fontsize=12)\nax.set_ylabel('Frequency',fontsize=12)\nplt.axis('on')\nplt.show()","08fd2359":"**INTERPRETATION**\n\n*Customers is for customers who are already members of the company*\n\n**Priority**\n>Cust the most frequent shopping (low recency), most often keep intouch with the company through the purchase of products from several market places as well as the most spending money to the company.\n\n>advice: For Priority segmentation treat such as giving more rewards, giving info and testers on each new product, because usually they help promote to the nearest person. As well as with more rewards for priority segments will attract customers who are under Priority to increase membership \/ segment\n\n\n**Loyal**\n>Cust who have not long shopped our products, and the value has a sufficient fre quency and monetary value. This customer is under the Priority segment, usually they shop only if there is a discount or urgent need. we can see that loyal dominates the segmentation.\n\n>advice : for loyal segmentation is better cust given a small discount but in frequency often against some products in turn in order to increase frequency and monetary.\n\n**Needs Attention**\n>Cust who have not bought our product for a long time. This segment should be more considered because this segment has a high probability to break up members \/ not extend the member company, which can result in decreased sales in the long run (because branding is weak with few customers)\n\n>Advice: Ask for advice to this segment about what the shortcomings of the product sold or in terms of service. Because usually cust turned because there is no match with the product \/ service, As well as provide a special Discount for this segment.\n\n    **SUMMARY SUGGESTION**\nThis segmentation is made to know the right treatment to each customer with the aim of maintaining Customer membership, after knowing the segment of each customer then the company can hold membership levels based on existing Segments and provide different rewards. And there can be challenges to increase membership, so that customers compete with each other to shop.\n\n\n","469837ac":"based on elbow method there ae 3 or 4 clusters","a1113e62":"RFM is segmentation based on customer behavior.(Spending, cunsumption habbit, product\/service usage, previously purchased product)\n\n>- Recency (R): The last time cust. bought a product.\n>- Frequency (F): Frequency of cust. make a purchase\n>- Monetary Value(M): The total value of expenditure from cust(because there is no price on the dataset will be calculated from the summation of the purchased product without multiplying the product price)\n\nWill be create 2 additional variables:\n\n>- Variable __*Spending*__ Total of 6 Products that have been purchased.\n>- Variable __*Transactions*__ Total of the number of times a customer buys a product.\n\n**Workflow:**\n    \n1. First looking for R&F&M value, after obtaining the value of Recency, Frequency and Monetary we will search the number of clusters from each column RFM using elbow and silloutte method. \n2. Recheck the number of clusters if using Recency, Frequency and Monetary at once.\n3. After getting the right number of clusters, rfm class will be created which contains the total of cluster score to get the right number of segmentation.\n","42231664":"*Based on elbow method has 2 clusters while based on sillhoutte score monetary has 10 clusters(and the number of clusters will continue to grow if the range n_cluster enlarged) this indicates* **the absence of clusters in Monetary** *which could be due to the absence of price data from each product.*","01618f46":"****Recency Cluster****","e521dd84":"Based on Elbow method and sillhoutte method, Recency has 2 clusters","fbb5f28d":"# **Make RF Score**","a9cce14f":"SUMMARY\n\nafter we compared 2 different methods and the result is same, there are 2 clusters. so the cluster will be selected is 2. and Segmentation will be based on rf(Recency Frequency) Score value, because Monetary has no cluster and is only used for aggregate","34e58fa1":"# Find Number of Clusters from Recency,Frequency,Monetary","1033622b":"# *Frequency*","33497364":"**Data Cleansing**","36217cbc":"****Monetary Cluster****","aaead5e8":"*Recency*\nnorm distribution Means that the average customer does have recency with an even frequency\n\n*Frequency*\nleftSkewed Means uneven distribution, more customers have low frequency than high frequency value\n\n*Monetary*\nleftSkewed Means many customers who shop for small amounts.","01e9cd91":"# *Recency*","4a9a8169":"Based on Elbow method and sillhoutte method, Recency has 2 clusters","417251ea":"# *Monatary*","2ff63187":"**Create 2 Variable**","fcf39f68":"**Frequency Clusters**","93dec1e2":"# Check Number of Cluster with other method"}}