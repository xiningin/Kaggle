{"cell_type":{"ecd4c0bc":"code","92cfb4a7":"code","9c69b768":"code","b9aee25c":"code","69c38c23":"code","b73a7a6c":"code","f9164d91":"code","208aa84f":"code","5cbbacf9":"code","e7661742":"code","74b54fec":"markdown","4cd1133f":"markdown"},"source":{"ecd4c0bc":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler #whatever the scaling method you decide\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import GroupKFold #for balanced division of data\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, SequentialSampler","92cfb4a7":"train_path = '..\/input\/ventilator-pressure-prediction\/train.csv'\ntest_path = '..\/input\/ventilator-pressure-prediction\/test.csv'","9c69b768":"#this piece of code is from one of the notebooks here in this competition\ndef difference_operator(df, feature):\n    col_name = f\"{feature}_diff\"\n    df[col_name] = (\n        df[feature].shift(-1).fillna(method=\"ffill\")\n        - df[feature].shift(1).fillna(method=\"bfill\")\n    ) \/ (\n        df[\"time_step\"].shift(-1).fillna(method=\"ffill\")\n        - df[\"time_step\"].shift(1).fillna(method=\"bfill\")\n    )\n    return df","b9aee25c":"#extracting some extra features from the main  \"u_in\" feature  MAY help our model!!! \n\ndef get_extra_features(df):   \n    df['state'] = df['R'].astype(str) + '_' + df['C'].astype(str)\n    df = df.merge(pd.get_dummies(df[\"state\"], prefix=\"state\"), left_index=True, right_index=True).drop([\"state\"], axis=1)\n    df['time_diff'] = df['time_step'].diff().fillna(0)\n    df['flow_diff'] = df['u_in'].diff().fillna(0)\n    df['flow_cum'] = df['u_in'].cumsum()\n        \n    df[\"flow_lag1\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(1).fillna(method=\"bfill\")\n    df[\"flow_back1\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-1).fillna(method=\"ffill\"))\n    df[\"flow_lag2\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(2).fillna(method=\"bfill\")\n    df[\"flow_back2\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-2).fillna(method=\"ffill\"))\n    df[\"flow_lag3\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(3).fillna(method=\"bfill\")\n    df[\"flow_back3\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-3).fillna(method=\"ffill\"))\n    df[\"time_lag\"] = (df.groupby(\"breath_id\")[\"time_step\"].shift(1).fillna(method=\"bfill\"))\n    df[\"time_back\"] = (df.groupby(\"breath_id\")[\"time_step\"].shift(-1).fillna(method=\"ffill\"))\n\n    df[\"area\"] = df[\"time_back\"] * df[\"u_in\"]\n    df[\"segment\"] = (1-df[\"u_out\"])\n    df[\"area_cum\"] = df.groupby([\"breath_id\"])[\"area\"].cumsum()\n    \n    df['flow_diff2'] = df['u_in']-df['flow_lag1']\n    df['flow_diff3'] = df['u_in']-df['flow_lag2']\n    df['flow_diff4'] = df['u_in']-df['flow_lag3']\n    \n    difference_operator(df, \"u_in\")\n    difference_operator(df, \"u_in_diff\")\n    difference_operator(df, \"u_in_diff_diff\")\n    difference_operator(df, \"u_in_diff_diff_diff\")\n        \n    difference_operator(df, \"area\")\n    difference_operator(df, \"area_diff\")\n    difference_operator(df, \"area_diff_diff\")\n    difference_operator(df, \"area_diff_diff_diff\")\n    return df","69c38c23":"#getting our data preprocessed , divided and grouped by 'breath_id'\ndef get_data(scaler= None):\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    train = get_extra_features(train)\n    test = get_extra_features(test)\n    feats = [ 'u_in', 'time_diff','flow_diff','flow_cum', 'flow_lag1', 'flow_back1', 'flow_lag2', 'flow_back2',\n            'flow_lag3', 'flow_back3', 'time_lag', 'time_back', 'area', 'area_cum', \n            'u_in_diff', 'u_in_diff_diff', 'u_in_diff_diff_diff', 'u_in_diff_diff_diff_diff',\n            'area_diff', 'area_diff_diff', 'area_diff_diff_diff', 'area_diff_diff_diff_diff',\n            'flow_diff2', 'flow_diff3', 'flow_diff4']\n    \n    test.loc[:, 'pressure'] = 0\n    test.loc[:, 'fold'] = -1\n    \n    not_to_scale = [ 'state_20_10', 'state_20_20', 'state_20_50', 'state_50_10',\n       'state_50_20', 'state_50_50', 'state_5_10', 'state_5_20', 'state_5_50','segment']\n                              \n    if scaler is not None :                          \n        trans = make_column_transformer((scaler, feats),remainder='passthrough',n_jobs=-1)\n    \n        train[feats] = trans.fit_transform(train[feats])\n        test[feats] = trans.transform(test[feats])\n    \n    Fold = GroupKFold(n_splits=10)   #whatever how many fold we want to split the data\n    \n    groups = train['breath_id'].values\n    for f, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n        train.loc[val_index, 'fold'] = int(f)\n    train['fold'] = train['fold'].astype(int)\n                              \n    train = train.groupby('breath_id').agg(list).reset_index(drop=True)\n    test = test.groupby('breath_id').agg(list).reset_index(drop=True)\n    train['fold'] = train['fold'].apply(lambda x: x[0])\n    test['fold'] = test['fold'].apply(lambda x: x[0])\n \n    train = train[feats + not_to_scale + ['pressure']+['fold']]\n    test = test[feats + not_to_scale + ['pressure']+['fold']]\n    \n    return {\n        'train' :train,\n        'test' : test,\n    }","b73a7a6c":"data = get_data(scaler=MinMaxScaler()) #or whatever","f9164d91":"train = data['train']\ntest = data['test']\n#train.head()     #check your data","208aa84f":"#we can save our preprocessed data if we want \nimport pickle\nwith open('preprocessed_data', 'wb') as handle:\n    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)","5cbbacf9":"class VentilatorData(Dataset):\n    def __init__(self, df, flip=0):\n        super().__init__()\n        self.df = df.values.tolist()\n        self.flip = flip              # percentage for data augmentation if we wish \n    def __getitem__(self, idx):\n        row = self.df[idx]\n        tensors = torch.as_tensor(row[:-2], dtype = torch.float)   #all rows except the ['fold', pressure]\n        segment = torch.as_tensor(row[-3], dtype=torch.long)    #thats the 'segment' or the 'u_out' row\n        target = torch.as_tensor(row[-2], dtype=torch.float)   #the 'pressure row'\n        \n        if np.random.rand() < self.flip:    #use it for sum augmentition\n            tensors = tensors.flip(-1)\n        return {\n            'tensors':tensors,\n            'segment':segment,\n            'target':target,\n        }\n    def __len__(self):\n        return len(self.df)","e7661742":"loader = DataLoader(VentilatorData(train), 64)\nbatch = next(iter(loader))\nbatch['tensors'].shape, batch['target'].shape, batch['segment'].shape","74b54fec":"# we can start building our models ","4cd1133f":"# to be continued !\n"}}