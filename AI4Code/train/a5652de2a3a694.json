{"cell_type":{"bfbf311e":"code","a7125b00":"code","dba6e7c6":"code","b6f24434":"code","0b376784":"code","b20ebc37":"code","15d7d2df":"code","c8a50e22":"code","470090c3":"code","c24780ef":"code","571db819":"code","3e7151db":"code","21a670ac":"code","93b73389":"markdown","f437194b":"markdown","13628030":"markdown","8d0582ea":"markdown","9e33522d":"markdown","7761f0d5":"markdown","19015f5a":"markdown","f74fb1b3":"markdown","42f26bef":"markdown","4e3ab701":"markdown","feef3612":"markdown","11eabcb9":"markdown","194fcad6":"markdown","a88ded60":"markdown","ce38cb5f":"markdown"},"source":{"bfbf311e":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nfrom skimage import data\n\nmatplotlib.rcParams['font.size'] = 12","a7125b00":"fig, axes = plt.subplots(1, 2, figsize=(8, 4))\nax = axes.ravel()\n\n# loading default data from scikit-learn library\nimages = data.stereo_motorcycle()\nax[0].imshow(images[0])\nax[0].axis(False)\nax[1].imshow(images[1])\nax[1].axis(False)\n\nfig.tight_layout()\nplt.show()","dba6e7c6":"images = ('brick', 'camera', 'cell', 'checkerboard',  \n          'clock',  'colorwheel','grass','gravel', \n          'hubble_deep_field', 'immunohistochemistry',  'moon', 'page', \n          'retina', 'rocket',  'text', 'shepp_logan_phantom' )\n\nrows =4\ncols =4\nf, ax = plt.subplots(rows, cols, figsize = (15,12))\ni=0\n\nfor name in images:\n    caller = getattr(data, name)\n    image = caller()\n    if image.ndim == 2:\n        ax[int(i\/rows),int(i % rows)].imshow(image, cmap = plt.cm.gray)\n    else:\n        ax[int(i\/rows),int(i % rows)].imshow(image)\n    ax[int(i\/rows),int(i % rows)].set_title(name)\n    ax[int(i\/rows),int(i % rows)].axis('off')\n    i+=1\nplt.show()   \n","b6f24434":"from mpl_toolkits.mplot3d import Axes3D\nfrom skimage.morphology import (square, rectangle, diamond, disk, cube,\n                                octahedron, ball, octagon, star)\n\n# Generate 2D  structuring elements.\nstruc_2d = { \"square(15)\": square(15),\n            \"rectangle(15, 10)\": rectangle(15, 10),\n            \"diamond(7)\": diamond(7),\n            \"disk(7)\": disk(7),\n            \"octagon(7, 4)\": octagon(7, 4),\n            \"star(5)\": star(5)\n}\n\n# Generate 3D  structuring elements.\nstruc_3d = {\"cube(11)\": cube(11),\n            \"octahedron(5)\": octahedron(5),\n            \"ball(5)\": ball(5)}\n\n# Visualize the elements.\nfig = plt.figure(figsize=(20, 20))\n\nidx = 1\nfor title, struc in struc_2d.items():\n    ax = fig.add_subplot(3, 3, idx)\n    ax.imshow(struc, cmap=\"Paired\", vmin=0, vmax=12)\n    for i in range(struc.shape[0]):\n        for j in range(struc.shape[1]):\n            ax.text(j, i, struc[i, j], ha=\"center\", va=\"center\", color=\"w\")\n    ax.set_axis_off()\n    ax.set_title(title)\n    idx += 1\n\nfor title, struc in struc_3d.items():\n    ax = fig.add_subplot(3, 3, idx, projection=Axes3D.name)\n    ax.voxels(struc)\n    ax.set_title(title)\n    idx += 1\n\nfig.tight_layout()\nplt.show()","0b376784":"from scipy import ndimage as ndi\nimport matplotlib.cm as cm\nfrom skimage import data\nfrom skimage import color\nfrom skimage.util import view_as_blocks\n\n\n# get astronaut from skimage.data in grayscale\nl = color.rgb2gray(data.astronaut())\n\n# size of blocks\nblock_shape = (4, 4)\n\n# see astronaut as a matrix of blocks (of shape block_shape)\nview = view_as_blocks(l, block_shape)\n\n# collapse the last two dimensions in one\nflatten_view = view.reshape(view.shape[0], view.shape[1], -1)\n\n# resampling the image by taking either the `mean`,\n# the `max` or the `median` value of each blocks.\nmean_view = np.mean(flatten_view, axis=2)\nmax_view = np.max(flatten_view, axis=2)\nmedian_view = np.median(flatten_view, axis=2)\n\n# display resampled images\nfig, axes = plt.subplots(2, 2, figsize=(15, 15), sharex=True, sharey=True)\nax = axes.ravel()\n\nl_resized = ndi.zoom(l, 2, order=3)\nax[0].set_title(\"Original rescaled with\\n spline interpolation (order=3)\")\nax[0].imshow(l_resized, extent=(0, 128, 128, 0),cmap=cm.Greys_r)\n\nax[1].set_title(\"Block view with\\n local mean pooling\")\nax[1].imshow(mean_view, cmap=cm.Greys_r)\n\nax[2].set_title(\"Block view with\\n local max pooling\")\nax[2].imshow(max_view, cmap=cm.Greys_r)\n\nax[3].set_title(\"Block view with\\n local median pooling\")\nax[3].imshow(median_view, cmap=cm.Greys_r)\n\nfor a in ax:\n    a.set_axis_off()\n\nfig.tight_layout()\nplt.show()","b20ebc37":"from skimage.color import rgb2gray\n\noriginal = data.astronaut()\ngrayscale = rgb2gray(original)\n\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\nax = axes.ravel()\n\nax[0].imshow(original)\nax[0].set_title(\"Original\")\nax[0].axis(False)\nax[1].imshow(grayscale, cmap=plt.cm.gray)\nax[1].set_title(\"Grayscale\")\nax[1].axis(False)\n\nfig.tight_layout()\nplt.show()","15d7d2df":"from skimage.color import rgb2hsv\n\nrgb_img = data.coffee()\nhsv_img = rgb2hsv(rgb_img)\nhue_img = hsv_img[:, :, 0]\nsat_img = hsv_img[:,:,1]\nvalue_img = hsv_img[:, :, 2]\n\nfig, (ax0, ax1, ax2, ax3) = plt.subplots(ncols=4, figsize=(8, 2))\n\nax0.imshow(rgb_img)\nax0.set_title(\"RGB image\")\nax0.axis('off')\nax1.imshow(hue_img, cmap='hsv')\nax1.set_title(\"Hue channel\")\nax1.axis('off')\nax2.imshow(sat_img)\nax2.set_title('Saturation\\nChannel')\nax2.axis('off')\nax3.imshow(value_img)\nax3.set_title(\"Value channel\")\nax3.axis('off')\n\nfig.tight_layout()\n","c8a50e22":"hue_threshold = 0.04\nbinary_img = hue_img > hue_threshold\n\nfig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(8, 3))\n\nax0.hist(hue_img.ravel(), 512)\nax0.set_title(\"Histogram of the Hue \\nchannel with threshold\")\nax0.axvline(x=hue_threshold, color='r', linestyle='dashed', linewidth=2)\nax0.set_xbound(0, 0.12)\nax1.imshow(binary_img)\nax1.set_title(\"Hue-thresholded image\")\nax1.axis('off')\n\nfig.tight_layout()","470090c3":"fig, ax0 = plt.subplots(figsize=(4, 3))\n\nvalue_threshold = 0.10\nbinary_img = (hue_img > hue_threshold) | (value_img < value_threshold)\n\nax0.imshow(binary_img)\nax0.set_title(\"Hue and value thresholded image\")\nax0.axis('off')\n\nfig.tight_layout()\nplt.show()","c24780ef":"from skimage import exposure\nfrom skimage.exposure import match_histograms\n\nreference = data.coffee()\nimage = data.chelsea()\n\nmatched = match_histograms(image, reference, multichannel=True)\n\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n                                    sharex=True, sharey=True)\nfor aa in (ax1, ax2, ax3):\n    aa.set_axis_off()\n\nax1.imshow(image)\nax1.set_title('Source')\nax2.imshow(reference)\nax2.set_title('Reference')\nax3.imshow(matched)\nax3.set_title('Matched')\n\nplt.tight_layout()\nplt.show()","571db819":"fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))\n\n\nfor i, img in enumerate((image, reference, matched)):\n    for c, c_color in enumerate(('red', 'green', 'blue')):\n        img_hist, bins = exposure.histogram(img[..., c], source_range='dtype')\n        axes[c, i].plot(bins, img_hist \/ img_hist.max())\n        img_cdf, bins = exposure.cumulative_distribution(img[..., c])\n        axes[c, i].plot(bins, img_cdf)\n        axes[c, 0].set_ylabel(c_color)\n\naxes[0, 0].set_title('Source')\naxes[0, 1].set_title('Reference')\naxes[0, 2].set_title('Matched')\n\nplt.tight_layout()\nplt.show()","3e7151db":"from skimage.color import rgb2hed\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Create an artificial color close to the original one\ncmap_hema = LinearSegmentedColormap.from_list('mycmap', ['white', 'navy'])\ncmap_dab = LinearSegmentedColormap.from_list('mycmap', ['white',\n                                             'saddlebrown'])\ncmap_eosin = LinearSegmentedColormap.from_list('mycmap', ['darkviolet',\n                                               'white'])\n\nihc_rgb = data.immunohistochemistry()\nihc_hed = rgb2hed(ihc_rgb)\n\nfig, axes = plt.subplots(2, 2, figsize=(7, 6), sharex=True, sharey=True)\nax = axes.ravel()\n\nax[0].imshow(ihc_rgb)\nax[0].set_title(\"Original image\")\n\nax[1].imshow(ihc_hed[:, :, 0], cmap=cmap_hema)\nax[1].set_title(\"Hematoxylin\")\n\nax[2].imshow(ihc_hed[:, :, 1], cmap=cmap_eosin)\nax[2].set_title(\"Eosin\")\n\nax[3].imshow(ihc_hed[:, :, 2], cmap=cmap_dab)\nax[3].set_title(\"DAB\")\n\nfor a in ax.ravel():\n    a.axis('off')\n\nfig.tight_layout()","21a670ac":"from skimage.exposure import rescale_intensity\n\n# Rescale hematoxylin and DAB signals and give them a fluorescence look\nh = rescale_intensity(ihc_hed[:, :, 0], out_range=(0, 1))\nd = rescale_intensity(ihc_hed[:, :, 2], out_range=(0, 1))\nzdh = np.dstack((np.zeros_like(h), d, h))\n\nfig = plt.figure()\naxis = plt.subplot(1, 1, 1, sharex=ax[0], sharey=ax[0])\naxis.imshow(zdh)\naxis.set_title(\"Stain separated image (rescaled)\")\naxis.axis('off')\nplt.show()","93b73389":"<a id=\"6\"><\/a>\n<font color=\"black\" size=+2.5><b>6. Histogram matching<\/b><\/font><br>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a> <br>\n\nThis example demonstrates the feature of histogram matching. It manipulates the pixels of an input image so that its histogram matches the histogram of the reference image. If the images have multiple channels, the matching is done independently for each channel, as long as the number of channels is equal in the input image and the reference.\n\nHistogram matching can be used as a lightweight normalisation for image processing, such as feature matching, especially in circumstances where the images have been taken from different sources or in different conditions (i.e. lighting).","f437194b":"# Objective\n\nThe aim of this kernel is to provide a hands on tutorial in different image processing techniques offered by [`scikit-image`](https:\/\/scikit-image.org\/) library. [`scikit-image`](https:\/\/scikit-image.org\/)  is a collection of algorithms for image processing. It is available free of charge and free of restriction. It provides us with high-quality, peer-reviewed code, written by an active community of volunteers.\n\n<font size=\"+1\"><b><u>Learning Sources:<\/u><\/b><\/font><br>\nI have learned them from [scikit-image user guide](https:\/\/scikit-image.org\/docs\/stable\/user_guide.html), [scikit-image on stackoverflow](https:\/\/stackoverflow.com\/questions\/tagged\/scikit-image) and [scikit-image forum](https:\/\/forum.image.sc\/tags\/scikit-image) and deployed them on some of the datasets available in kaggle platform.There are two parts of my kernel.\n\n<font size=\"+1\"><b><u>Acknowledgements:<\/u><\/b><\/font><br>\n&#9673; St\u00e9fan van der Walt, Johannes L. Sch\u00f6nberger, Juan Nunez-Iglesias, Fran\u00e7ois Boulogne, Joshua D. Warner, Neil Yager, Emmanuelle Gouillart, Tony Yu and the scikit-image contributors. **scikit-image: Image processing in Python. PeerJ 2:e453 (2014)** https:\/\/doi.org\/10.7717\/peerj.453\n","13628030":"Now we can easily manipulate the hematoxylin and DAB \u201cchannels\u201d","8d0582ea":"Also in the scikit-learn library there are tons of sample data available. You can easily call that data by the name and use that data for any operation. \nJust you have to know the name of the data and you can readily use them for any testing purpose. For more you can have a look at [API reference of skimage.data](https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.data.html). ","9e33522d":"<a id=\"5\"><\/a>\n<font color=\"black\" size=+2.5><b>5. RGB to HSV<\/b><\/font><br>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a> <br>\nThis example illustrates how RGB to HSV (Hue, Saturation, Value) conversion 1 can be used to facilitate segmentation processes.\n\n> Usually, objects in images have distinct colors (hues) and luminosities, so that these features can be used to separate different areas of the image. In the RGB representation the hue and the luminosity are expressed as a linear combination of the R,G,B channels, whereas they correspond to single channels of the HSV image (the Hue and the Value channels). A simple segmentation of the image can then be effectively performed by a mere thresholding of the HSV channels.  We first load the RGB image and extract the Hue and Value channels:","7761f0d5":"To illustrate the effect of the histogram matching, we plot for each RGB channel, the histogram and the cumulative histogram. Clearly, the matched image has the same cumulative histogram as the reference image for each channel.","19015f5a":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of content<\/h3>\n    \n* [Loading Libraries](#0)\n  \n<font color=\"brown\" size=+1><b>Basic Operations<\/b><\/font><br>\n&#9632;  [1.  Basic Image View](#1)<br>\n\n<font color=\"brown\" size=+1><b>Operation on Numpy Arrays<\/b><\/font><br>\n&#9632;  [2. Generate Structuring Elements](#2)<br>\n&#9632;  [3. Block Views on Images\/Arrays](#3)<br>\n\n<font color=\"brown\" size=+1><b>Manipulating exposure and color channels<\/b><\/font><br>\n&#9632; [4. RGB to Grayscale](#4)<br>\n&#9632; [5. RGB to HSV](#5)<br>\n&#9632; [6. Histogram Matching](#6)<br>    \n&#9632; [7. Immunohistochemical Staining Colors Separation](#7)<br>\n&#9632; [8. Adapting Gray-scale Filters to RGB Images](#8)<br>\n&#9632; [9. Filtering regional maxima](#9) <br>\n&#9632; [10. Histogram Equalization](#10)<br>\n&#9632; [11. Local Histogram Equalization](#11)\n\n\n  ","f74fb1b3":"<a id=\"7\"><\/a>\n<font color=\"black\" size=+2.5><b>7. Immunohistochemical Staining Colors Separation<\/b><\/font><br>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a> <br>\n\n\nColor deconvolution consists of the separation of features by their colors.\n\nIn this example we separate the immunohistochemical (IHC) staining from the hematoxylin counterstaining. The separation is achieved with the method described in 1, known as \u201ccolor deconvolution\u201d.\n\nThe IHC staining expression of the FHL2 protein is here revealed with Diaminobenzidine (DAB) which gives a brown color.\n\n\n[1] A. C. Ruifrok and D. A. Johnston, \u201cQuantification of histochemical staining by color deconvolution.,\u201d Analytical and quantitative cytology and histology \/ the International Academy of Cytology [and] American Society of Cytology, vol. 23, no. 4, pp. 291-9, Aug. 2001.","42f26bef":"We then set a threshold on the Hue channel to separate the cup from the background:","4e3ab701":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSDSH7J3HcXkjC0ftWuIL8gn2Tj4ZHMIUV8ZQ&usqp=CAU)","feef3612":"<a id=\"4\"><\/a>\n<font color=\"black\" size=+2.5><b>4. RGB to Grayscale<\/b><\/font><br>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a><br>\n\n\nThis example converts an image with RGB channels into an image with a single grayscale channel. The value of each grayscale pixel is calculated as the weighted sum of the corresponding red, green and blue pixels as:\n\n$$Y = 0.2125 R + 0.7154 G + 0.0721 B$$\nThese weights are used by CRT phosphors as they better represent human perception of red, green and blue than equal weights.","11eabcb9":"<a id=\"1\"><\/a>\n<font color=\"black\" size=+2.5><b>1. Basic Image View<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>","194fcad6":"We finally perform an additional thresholding on the Value channel to partly remove the shadow of the cup:","a88ded60":"<a id=\"2\"><\/a>\n<font color=\"black\" size=+2.5><b>2. Generate Structuring Elements<\/b><\/font><br>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>\n\n\nThis example shows how to use functions in `skimage.morphology` to generate structuring elements. The title of each plot indicates the call of the function. These morphology items are necessary for different morphological operations selection, morphological segmentation, dilation, erosion, top-hat filtering, opening, closing, boosting etc. For basic understanding of mprphological image processings, you can have a look at this [medium blog](https:\/\/medium.com\/@himnickson\/morphological-operations-in-image-processing-cb8045b98fcc) ","ce38cb5f":"<a id=\"3\"><\/a>\n<font color=\"black\" size=+2.5><b>3. Block Views on Images\/Arrays<\/b><\/font><br>\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOC<\/a>\n\n\nThis example illustrates the use of view_as_blocks from [skimage.util()](https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.util.html#module-skimage.util). Block views can be incredibly useful when one wants to perform local operations on non-overlapping image patches.<br>\nWe use astronaut from `skimage.data` and virtually \u2018slice\u2019 it into square blocks. Then, on each block, we either pool the mean, the max or the median value of that block. The results are displayed altogether, along with a spline interpolation of order 3 rescaling of the original astronaut image."}}