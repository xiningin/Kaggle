{"cell_type":{"f5000528":"code","6c5cc6d3":"code","05db5025":"code","2ee45a56":"code","074ef324":"code","26397145":"code","57d7bed3":"code","207b25be":"code","a59ae18e":"code","8e6f7d43":"code","631af829":"code","900b0500":"code","6cec9174":"code","0de9dab6":"markdown","8bd29f67":"markdown","78d891a2":"markdown","ca374cba":"markdown","e6c934ef":"markdown","f6bb4510":"markdown"},"source":{"f5000528":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport sys\nimport time\nimport copy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models","6c5cc6d3":"# Get the available device\n\nif torch.cuda.is_available():\n    dev = \"cuda:0\"  # Gpu\nelse:\n    dev = \"cpu\"\ndevice = torch.device(dev)","05db5025":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\n\ntrainset = torchvision.datasets.ImageFolder(root=\"\/kaggle\/input\/100-bird-species\/train\/\", transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, num_workers=0, shuffle=True)\n\ntestset = torchvision.datasets.ImageFolder(root=\"\/kaggle\/input\/100-bird-species\/test\/\", transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, num_workers=0, shuffle=False)\n\ndataloaders = {\n    \"train\": trainloader,\n    \"test\": testloader\n}\ndatasizes = {\n    \"train\": len(trainset),\n    \"test\": len(testset)\n}\nCLASSES = list(trainset.class_to_idx.keys())","2ee45a56":"def imshow(img, size=(10, 10)):\n    img = img \/ 2 + 0.5\n    npimg = img.numpy()\n    if size:\n        plt.figure(figsize=size)\n    \n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(\"One mini batch\")\n    plt.axis(\"off\")\n    plt.pause(0.001)","074ef324":"dataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\nimshow(torchvision.utils.make_grid(images))","26397145":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16*53*53, 2809)\n        self.fc2 = nn.Linear(2809, 512)\n        self.fc3 = nn.Linear(512, len(CLASSES))\n        \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16*53*53)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nnet.to(device)","57d7bed3":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)","207b25be":"for epoch in range(2):\n    running_loss = 0.0\n    best_acc = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        _, preds = torch.max(outputs, 1)\n        corrects = torch.sum(preds == labels.data)\n        # print Running loss\n        running_loss += loss.item()\n        if i % 100 == 99:\n            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss \/ 100))\n            running_loss = 0.0\n    print(\"Epoch: {} Accuracy: {}\".format(epoch, corrects.double()\/datasizes[\"train\"]))","a59ae18e":"def train_model(model, criterion, optimizer, scheduler, epochs=25):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(epochs):\n        print(\"Epoch {}\/{}\".format(epoch, epochs-1))\n        print(\"-\"*10)\n        \n        for phase in [\"train\", \"test\"]:\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0 \n            \n            # Iterate over data\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                # Zero the parametsrs\n                optimizer.zero_grad()\n                \n                # Forward\n                with torch.set_grad_enabled(phase == \"train\"):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n                    \n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == \"train\":\n                scheduler.step()\n            \n            epoch_loss = running_loss \/ datasizes[phase]\n            epoch_acc = running_corrects.double()\/datasizes[phase]\n            \n            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n            if(phase == \"test\" and epoch_acc > best_acc):\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n        print()\n    \n    time_elapsed = time.time() - since\n    print(\"Training complete in {:0f}m {:0f}s\".format(time_elapsed\/\/60, time_elapsed%60))\n    print(\"Best val Acc: {}:4f\".format(best_acc))\n    \n    # load best model parameters\n    model.load_state_dict(best_model_wts)\n    return model","8e6f7d43":"model_ft = models.resnet18(pretrained=True)\n\n# turn training false for all layers, other than fc layer\nfor param in model_ft.parameters():\n    param.requires_grad = False\n    \nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, len(CLASSES))\nmodel_ft = model_ft.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.003, momentum=0.9)\nexp_lr_sc = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","631af829":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_sc, epochs=5)","900b0500":"def imshowaxis(ax, img, orig, pred):\n    img = img \/ 2 + 0.5\n    npimg = img.numpy()\n    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n    if orig != pred:\n        ax.set_title(orig + \"\\n\" + pred, color=\"red\")\n    else:\n        ax.set_title(orig + \"\\n\" + pred)\n    ax.axis(\"off\")\n\n\ndef vis_model(model, num_images=25):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    figure, ax = plt.subplots(5, 5, figsize=(20, 20))\n    \n    \n    with torch.no_grad():\n        for i , (inputs, labels) in enumerate(dataloaders[\"test\"]):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            for i in range(5):\n                for j in range(5):\n                    if images_so_far < num_images:\n                        imshowaxis(ax[i][j], inputs.cpu().data[images_so_far], CLASSES[labels[images_so_far]], CLASSES[preds[images_so_far]])\n                    else:\n                        model.train(mode=was_training)\n                        return\n                    images_so_far += 1\n        model.train(mode=was_training)\n","6cec9174":"# Title: Original vs Predicted \nvis_model(model_ft)","0de9dab6":"## Simple classification using pytorch\n\nIn this notebook I will try to demonstate usage of pytorch for simple image classfication task. We will create a simple CNN and then try transfer learning using a pretrained model(ResNet18)\n\n","8bd29f67":"## Defining a simple CNN","78d891a2":"### Utilities for loading training and testing image dataset","ca374cba":"### Pretrained Results\n\nIn only 4-5 epochs we crossed 94% accuracy , without even breaking a sweat.\nWe can improve it further by \n1. More data augmentation and transformation while loading like Rotating image randomly, or Cropped selection and Scaled to make model more scale and rotate invariant\n2. Fine tune model by playing with learning rate, and number of epochs\netc","e6c934ef":"### Training simple CNN","f6bb4510":"As we can see, we did not get a good accuracy at all and will not get a good one from this model, because model is not upto the mark to do classification of 150 classes.\n\nSo we will use a pretrained model and edit its last fully connected layer and train ONLY that last layer.\nWe will use generic model training function form pytorch documentation (because its all we need, no changes at all)"}}