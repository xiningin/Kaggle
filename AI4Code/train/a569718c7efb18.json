{"cell_type":{"75b45ee1":"code","283be1c6":"code","17e6b6fd":"code","83f3c2ae":"code","6c5fdd8e":"code","68f0f643":"code","8ad34dbb":"code","076104e8":"code","544252e9":"code","67236855":"code","32f9e92a":"code","14ead431":"code","3118bdfd":"code","476a70c5":"code","22bad194":"markdown","b8f7fcb6":"markdown"},"source":{"75b45ee1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","283be1c6":"df_gb = (\n    pd.read_csv('\/kaggle\/input\/youtube-new\/GBvideos.csv')\n)\n\ndf_gb.head()","17e6b6fd":"df_gb[['views','likes']].plot(kind='scatter', x='views', y='likes')","83f3c2ae":"df_gb_channel = (\n    df_gb\n    .assign(\n        log_likes = lambda x: np.log(x.likes + 0.5)\n    )\n    .groupby('channel_title')\n    .agg({\n        'video_id':'nunique',\n        'likes': ['mean', 'std'],\n        'log_likes': ['mean', 'std'],\n        'views': 'mean',\n    })\n    .sort_values(('video_id', 'nunique'), ascending=False)\n)\ndf_gb_channel.head(10)","6c5fdd8e":"\ndf_gb['tag_list'] = df_gb.tags.str.split('|')","68f0f643":"df_gb_tags_long = []\nfor index, row in df_gb[['video_id', 'tag_list']].iterrows():\n    video_id = row['video_id']\n    tags = row['tag_list']\n    for tag in tags:\n        df_gb_tags_long.append({'video_id':video_id,'tag':tag})\ndf_gb_tags_long = pd.DataFrame(df_gb_tags_long)","8ad34dbb":"tag_summary = (\n    df_gb_tags_long\n    .assign(tag=lambda x: x.tag.str.lower())\n    .set_index('video_id')\n    .join(df_gb.set_index('video_id'))\n    .reset_index()\n    .groupby('tag')\n    .agg({'video_id':'nunique', 'likes':'mean', 'views':'mean'})\n    .sort_values('video_id', ascending=False)\n)\n\ntag_summary.head(10).likes.plot(kind='barh')","076104e8":"tag_summary.assign(video_id =lambda x: np.log(x + 0.5)).plot(x='video_id', y='likes', kind='scatter')","544252e9":"tag_summary.sort_values('likes', ascending=False).query('video_id>100')","67236855":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline","32f9e92a":"features = ['views', 'comment_count']\n\nX = df_gb\ny = df_gb['likes']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","14ead431":"from sklearn.base import BaseEstimator, TransformerMixin\n\n\nclass BasePipeStep(BaseEstimator, TransformerMixin):\n\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        return X\n\nclass SelectColumns(BasePipeStep):\n\n    def __init__(self, columns):\n        self.columns = columns\n    \n    def transform(self, X):\n        X = X.copy()\n        return X[self.columns]\n\nclass PopularTagFeature(BasePipeStep):\n        \n    def fit(self,X, y=None):\n        df_gb_tags_long = []\n        for index, row in X[['video_id', 'tag_list']].iterrows():\n            video_id = row['video_id']\n            tags = row['tag_list']\n            for tag in tags:\n                df_gb_tags_long.append({'video_id':video_id,'tag':tag})\n        df_gb_tags_long = pd.DataFrame(df_gb_tags_long)\n        self.tag_summary = (\n            df_gb_tags_long\n            .assign(tag=lambda x: x.tag.str.lower())\n            .set_index('video_id')\n            .join(X.set_index('video_id'))\n            .reset_index()\n            .groupby('tag')\n            .agg({'video_id':'nunique', 'likes':'mean', 'views':'mean'})\n            .sort_values('likes', ascending=False)\n            .head(30)\n            .index\n            .values\n        )\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X['high_tag']  = 0\n\n        for tag in self.tag_summary:\n            X['high_tag']  += np.where(X.tags.str.contains(tag),1,0)\n        return X\n    \nclass UnpopularTagFeature(BasePipeStep):\n        \n    def fit(self,X, y=None):\n        df_gb_tags_long = []\n        for index, row in X[['video_id', 'tag_list']].iterrows():\n            video_id = row['video_id']\n            tags = row['tag_list']\n            for tag in tags:\n                df_gb_tags_long.append({'video_id':video_id,'tag':tag})\n        df_gb_tags_long = pd.DataFrame(df_gb_tags_long)\n        self.tag_summary = (\n            df_gb_tags_long\n            .assign(tag=lambda x: x.tag.str.lower())\n            .set_index('video_id')\n            .join(X.set_index('video_id'))\n            .reset_index()\n            .groupby('tag')\n            .agg({'video_id':'nunique', 'likes':'mean', 'views':'mean'})\n            .sort_values('likes')\n            .head(30)\n            .index\n            .values\n        )\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X['low_tag']  = 0\n\n        for tag in self.tag_summary:\n            X['low_tag']  += np.where(X.tags.str.contains(tag),1,0)\n        return X\n \nclass TimeFeatures(BasePipeStep):\n    \n    def transform(self, X):\n        X = X.copy()\n        return X.assign(\n            publish_time = lambda x: pd.to_datetime(x.publish_time),\n            month = lambda x: x.publish_time.dt.month,\n            hour = lambda x: x.publish_time.dt.hour, \n        )\n\nclass HotEncode(BasePipeStep):\n    \n    def __init__(self, columns):\n        self.columns = columns\n        \n    def transform(self, X):\n        X = X.copy()\n        return pd.get_dummies(X, columns=self.columns, drop_first=True)\n        \n\n\npreprocessing = Pipeline([\n    ('popular_tags', PopularTagFeature()),\n    ('unpopular_tage', UnpopularTagFeature()),\n    ('time_features', TimeFeatures()),\n    ('select_columns', SelectColumns([\n        'views','comment_count',\n        'high_tag', 'low_tag',\n        'month', 'hour',\n        'comments_disabled', 'ratings_disabled',\n        'video_error_or_removed'\n    ])),\n    ('hot_encode', HotEncode([\n        'comments_disabled', 'ratings_disabled',\n        'video_error_or_removed'\n    ]))\n])\n\npipe = Pipeline([\n    ('preprocessing', preprocessing),\n    ('learning', xgb.XGBRegressor() )\n])","3118bdfd":"pipe.fit(X_train, y_train)","476a70c5":"from sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\npredictions = pipe.predict(X_test)\nerror = mean_squared_error(y_test, predictions, squared=False)\nprediction_r2_score = r2_score(y_test, predictions)\nprint(f'Mean squared error: {error:,.3f}')\nprint(f'R2 score: {prediction_r2_score}')\nf, ax = plt.subplots(figsize=(10,5))\nax.scatter(y_test, predictions)","22bad194":"# Building up a pipe\n\nBase model Mean squared error: 5,622,979,887.790","b8f7fcb6":"# Lets start by looking at the different channels - presumably some channels produce more likes?"}}