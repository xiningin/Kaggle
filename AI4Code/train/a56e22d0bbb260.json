{"cell_type":{"f9087670":"code","09b753ac":"code","66866b1a":"code","112caa25":"code","57ecd39c":"code","6cdb1c4c":"code","f8e5abc4":"code","5a7be64e":"code","74b596f9":"code","be2e6a33":"code","26d6adc7":"code","ce59dee6":"code","3b593dc0":"code","9b9cc120":"code","e1b79ed9":"code","d0fd0c63":"code","6a55cac0":"code","e566fb8a":"code","75f2a4bc":"code","3712eee9":"code","e25b46d9":"code","f599971a":"code","714aa049":"code","d238d360":"code","b178c9b8":"code","595fbc84":"code","84bdafc6":"code","a28f2575":"code","9d129232":"code","0e69cd15":"code","ac8c5e52":"code","6e8d0557":"code","d3744885":"code","1fc19ce1":"code","c732732a":"code","b3c0f2ec":"code","33a9b0cf":"code","9b4fe0b5":"code","7374f227":"code","dc285f06":"code","41fe2e2c":"code","bfe86843":"code","43837518":"code","47dec19b":"code","01cb2744":"code","e07f617c":"code","624a98b3":"code","77aa0ed4":"code","ac01358f":"code","33ac1789":"code","d97850bd":"code","e736050d":"code","fd01f3e0":"code","f87337b6":"code","24a31c0b":"code","0f259ff8":"code","5095f00d":"code","d671ac2f":"code","5b16dd43":"code","a0031efc":"code","23645ace":"code","b40ed523":"code","7f632f35":"code","3bf028e8":"code","77ff9ffc":"code","788307df":"code","47a0a4df":"code","4249e85d":"code","c5cd1d0c":"code","c9d9e817":"code","26819e73":"code","2061a0c3":"markdown","93529227":"markdown","493d5fe3":"markdown","8c39429d":"markdown","a4934575":"markdown","2fa033cb":"markdown","0d4e93fd":"markdown","1abf00d5":"markdown","03b0560d":"markdown","6c153aa5":"markdown","15119f59":"markdown","73eb33de":"markdown","0f240f6b":"markdown","ddf231c4":"markdown","a9d207b4":"markdown","d25ff027":"markdown","805782d3":"markdown","3a69e8dc":"markdown","5cea8a2e":"markdown","5df9b2aa":"markdown","10fd6f72":"markdown","124ceae3":"markdown","6b37525b":"markdown","2245ff15":"markdown","45add719":"markdown","fff93d68":"markdown","4a7e0df4":"markdown","7c54341b":"markdown","a3316159":"markdown","bebaaca7":"markdown","e6d4c28f":"markdown","51015a17":"markdown","7caa9a79":"markdown","ccc06b5e":"markdown","be5b9294":"markdown"},"source":{"f9087670":"# Apologies if some packages are imported down further in the notebook.\n#...it's a work in progress and sometimes I forget to bring them back up.\n# Also, if there is much code and many packages and I just want to reuse one sections, I have to remember which packages went with it.\n\n%matplotlib inline\n\n\n\n!pip install PyPDF2\n!pip install textstat\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport re #search in strings.\n\nimport plotly.plotly as py\nimport cufflinks as cf\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom wordcloud import WordCloud\nimport textstat\n\npd.set_option('max_colwidth', 10000)  # this is important because the requirements are sooooo long \n\nimport warnings\nwarnings.filterwarnings('ignore')   # get rid of the matplotlib warnings\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport pandasql                    # https:\/\/github.com\/yhat\/pandasql\nfrom pandasql import sqldf\npysqldf = lambda q: sqldf(q, globals())","09b753ac":"input_dir = '..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Job Bulletins\/'\n\ndef getListOfFiles(dirName):\n# create a list of file and sub directories \n# names in the given directory \n    listOfFile = os.listdir(dirName)\n    allFiles = list()\n    # Iterate over all the entries\n    for entry in listOfFile:\n    # Create full path\n        fullPath = os.path.join(dirName, entry)\n        # If entry is a directory then get the list of files in this directory \n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\nlistOfFiles = getListOfFiles(input_dir)\ndf_bulletins = pd.DataFrame(listOfFiles, columns = ['job_position'])\ndf_bulletins.head(2)","66866b1a":"# Clean up of the job_position name\ndf_positions = pd.DataFrame()\ndf_positions['job_position'] = (df_bulletins['job_position']\n                                .str.replace(input_dir, '', regex=False)\n                                .str.replace('.txt', '', regex=False)\n                                .str.replace('\\d+', '')\n                                .str.replace(r\"\\s+\\(.*\\)\",\"\")\n                                .str.replace(r\"REV\",\"\"))\n\n#Remove the numbers\ndf_positions['class_code'] = (df_bulletins['job_position']\n                              .str.replace(input_dir, '', regex=False)\n                              .str.replace('.txt', '', regex=False)\n                              .str.extract('(\\d+)'))\n\ndisplay(df_positions.head(2))\n# Add the Text fields of Salary, Duties and Minimum REQ\n","112caa25":"#Convert the txt files to a table:\nimport glob\npath = input_dir # use your path\nall_files = glob.glob(path + \"\/*.txt\")\nli = []\n\nfor filename in all_files:\n    with open (filename, \"r\",errors='replace') as myfile:\n        data=pd.DataFrame(myfile.readlines())\n        #df = pd.read_csv(filename, header=0,error_bad_lines=False, encoding='latin-1')\n    li.append(data)\nframe = pd.concat(li, axis=1, ignore_index=True)\n#pd.read_csv(listOfFiles,header = None)\nframe = frame.replace('\\n','', regex=True)\n","57ecd39c":"frame.head(10)","6cdb1c4c":"# Here the loop should start, for each text file do:\ndef getString(col_i, frame):\n    try:\n        filter = frame[col_i] != \"\"\n        bulletin = frame[col_i][filter]\n       \n        isal = min(bulletin[bulletin.str.contains('SALARY',na=False)].index.values) #take the sum to convert the array to an int...TO CHANGE\n        inot = max(bulletin[bulletin.str.contains('NOTES:',na=False)].index.values) # NOTES\n        iexm = max(bulletin[bulletin.str.contains('THIS EXAMINATION',na=False)].index.values) # EXAMS\n        idut = min(bulletin[bulletin.str.contains('DUTIES',na=False)].index.values) # DUTIES\n        ireq = min(bulletin[bulletin.str.contains('REQUIREMENT',na=False)].index.values) #REQUIREMENTS\n        ipro = min(bulletin[bulletin.str.contains('PROCESS',na=False)].index.values) # PROCESS NOTES\n        icode = min(bulletin[bulletin.str.contains('Class Code',na=False)].index.values)\n        iend = max(bulletin[bulletin.str.contains('discriminate',na=False)].index.values)\n        \n        class_code = sum(bulletin.str.extract('(\\d+)').iloc[icode].dropna().astype('int'))\n        \n        salary       = (bulletin.loc[isal+1:idut-1]).to_string()\n        duties       = (bulletin.loc[idut+1:ireq-1]).to_string()\n        requirements = (bulletin.loc[ireq+1:ipro-1]).to_string()\n        exam         = (bulletin.loc[iexm+1:iend-1]).to_string()\n        process      = (bulletin.loc[ipro+1:inot-1]).to_string()\n        notes        = (bulletin.loc[inot+1:iexm-1]).to_string()\n        return (class_code, salary, duties, requirements,exam,process, notes)\n    except:\n        return (np.nan,np.nan,np.nan,np.nan, np.nan, np.nan, np.nan)\n    \njobsections = pd.DataFrame()\n#getString(0,bulletin)\nfor col_i in range(frame.shape[1]):\n    #print(col_i)\n    #print(list(getString(col_i,frame)))\n    prop = getString(col_i,frame)\n    prop = pd.DataFrame(list(prop)).T\n    jobsections = jobsections.append(prop)","f8e5abc4":"jobsections.head(2)","5a7be64e":"jobsections.columns = ['class_code','salary','duties','requirements', 'exam', 'process', 'notes']\njobsections['class_code'] = pd.to_numeric(jobsections['class_code'],downcast='integer')\ndf_positions['class_code'] = pd.to_numeric(df_positions['class_code'], downcast='integer')\n#df_positions['class_code']\ndf_jobs = df_positions.merge(jobsections, left_on='class_code',right_on='class_code', how='outer')\ndisplay(df_jobs.dropna())","74b596f9":"pd.set_option('max_colwidth', 10000)\n\njobsections['requirements'].head(1)","be2e6a33":"# Read the whole text.\ntext = df_jobs['duties'].values\n\ntext = str(text)\n\n\n# Generate a word cloud image\nwordcloud = WordCloud().generate(text)\n\n# Display the generated image:\n# the matplotlib way:\nimport matplotlib.pyplot as plt\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\n\n# lower max_font_size\nwordcloud = WordCloud(max_font_size=40).generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","26d6adc7":"import PyPDF2   #https:\/\/pythonhosted.org\/PyPDF2\/PdfFileReader.html\n\n# Get the pdf files.\ninput_dir = '..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Additional data\/PDFs\/'\n\nlistOfFiles = getListOfFiles(input_dir)\nlistOfFiles[0:10]\n# commenting out for now as it outputs a large amount of data and this seems to disrupt the viewing of the kernel. \n","ce59dee6":"df_opening_pdfs = pd.DataFrame(listOfFiles, columns = ['opening_pdf'])\n\n# Clean up the pdf opening names\n\ndf_openings = pd.DataFrame()\ndf_openings['job_position'] = (df_opening_pdfs['opening_pdf']\n                                .str.replace(input_dir, '', regex=False)\n                                .str.replace('.txt', '', regex=False)\n                                .str.replace('\\d+', '')\n                                .str.replace(r\"\\s+\\(.*\\)\",\"\")\n                                .str.replace(r\"REV\",\"\"))\n\n#Remove the numbers\ndf_openings['class_code'] = (df_opening_pdfs['opening_pdf']\n                              .str.replace(input_dir, '', regex=False)\n                              .str.replace('.txt', '', regex=False)\n                              .str.extract('(\\d+)'))\n\n\ndf_openings['version'] =       df_opening_pdfs['opening_pdf'].str.slice(start=-10,stop=-4)\n\n\npdfFile = PyPDF2.PdfFileReader('..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Additional data\/PDFs\/2018\/December\/Dec 7\/SENIOR PERSONNEL ANALYST 9167 120718.pdf', 'rb')\n#pdfFile = df_opening_pdfs['opening_pdf']\nmetadata = pdfFile.getDocumentInfo()\nmetadata\n#pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n#df_openings['info'] = pdfReader.getPage(1) \n                           \ndf_openings.head(2)\n# Add the Text fields of Salary, Duties and Minimum REQ\n\n\n#pdfFileObj = open('..\/input\/CityofLA\/CityofLA\/Additional_data\/PDFs\/2018\/February\/Feb_2\/SOLID_WASTE_DISPOSAL_SUPERINTENDENT_4108_020218.pdf','rb') #'rb' for read binary mode \n#pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n#pdfReader.numPages.pageObj = pdfReader.getPage(1) #'1' is the page number pageObj.extractText()","3b593dc0":"pdfFile = PyPDF2.PdfFileReader('..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Additional data\/PDFs\/2018\/December\/Dec 7\/SENIOR PERSONNEL ANALYST 9167 120718.pdf', 'rb')\n#pdfFile = df_opening_pdfs['opening_pdf']\nDocumentInfo = pdfFile.getDocumentInfo()\nDocumentInfo\n# commenting out for now as it outputs a large amount of data and this seems to disrupt the viewing of the kernel. ","9b9cc120":"pdfFields = pdfFile.getNumPages()\npdfFields\n# commenting out for now as it outputs a large amount of data and this seems to disrupt the viewing of the kernel. ","e1b79ed9":"pdfPageLayout = pdfFile.getPageLayout()\npdfPageLayout\n# commenting out for now as it outputs a large amount of data and this seems to disrupt the viewing of the kernel. ","d0fd0c63":"pdfPageMode = pdfFile.getOutlines()\npdfPageMode\n# commenting out for now as it outputs a large amount of data and this seems to disrupt the viewing of the kernel. ","6a55cac0":"pdfFile.numPages \npageObj = pdfFile.getPage(1)\npdftext= pageObj.extractText()\n\npdftext\n# commenting out for now as it outputs a large amount of data and this seems to disrupt the viewing of the kernel. ","e566fb8a":"#import textstat\n\n# 2018\/December\/Dec 7\/SENIOR PERSONNEL ANALYST 9167 \n\ntest_data = (\n    \"The examination will consist of a qualifying multiple\"\n    \"-choice test, an advisory essay, an advisory oral presentation, and an interview.\"\n    \" The qualifying written test will consist of \"\n    \"multiple-choice questions in which emphasis may be placed on the candidate's expertise and knowledge of:\"\n    \" Civil Service selection procedures; Equal Employment Opportunity \"\n    \"(EEO) policies; Americans with Disabilities Act (ADA) regulations; Family and Medical Leave Act (FMLA); \"\n    \"Fair Labor Standards Act (FLSA); and demonstrated proficiency and \"\n    \"familiarity with the City's authoritative documents sufficient to identify the appropriate source, \"\n    \"interpret complex written material, and effectively interpret provisions of the City Charter, \"\n    \"Administrative Code, City Code of Ethics, Memoranda of Understandin (MOUs) provisions,\"\n    \" Mayor's Executive Directives, and Personnel Department rules, policies and procedures, \"\n    \"including Civil Service Commission (CSC) Rules, Personnel Department Policies and Personnel Department Procedures Manual; \"\n    \"interpret complex data such as legislation, technical reports, and graphs; principles and practices of supervision,\"\n    \" including training, counseling, and disciplining subordinate staff; and other necessary knowledge, skills, and abilities.\"\n    \"Prior to the multiple-choice test, applicants will be required to prepare some written material related to the work \"\n    \"of a Senior Personnel Analyst employed by the City of Los Angeles. \"\n    \"This essay material will not be separately scored, but will be presented to the interview board \"\n    \"for discussion with the candidate and for consideration in the overall evaluation of the candidate's qualifications.\"\n    \"The advisory essay will be administered on-line. Candidates will receive an e-mail from the City of Los Angeles \"\n    \"outlining the specific steps needed to complete the on-line advisory essay. \"\n    \"Candidates will be required to complete the on-line advisory essay between FRIDAY, JANUARY 11, 2019 and \"\n    \"SUNDAY, JANUARY 13, 2019. Additional instructions will be sent via e-mail. \"\n    \"Candidates who fail to complete the advisory essay as instructed may be disqualified.\"\n    \"The multiple-choice test will be proctored and administered on-line during a single session. \"\n    \"Candidates invited to participate in the on-line multiple-choice test will be able to take the test \"\n    \"as instructed from a remote location using a computer with a webcam and a reliable internet connection. \"\n    \"Candidates will receive an e-mail from the City of Los Angeles outlining the dates and \"\n    \"specific steps on how to take the multiple-choice test and advisory essay on-line\"\n)\n\nprint ('Flesch reading ease ' + str(textstat.flesch_reading_ease(test_data)))\nprint ('smog index ' + str(textstat.smog_index(test_data)))\nprint ('Flesch Kincaid ' + str(textstat.flesch_kincaid_grade(test_data)))\nprint ('Coleman Liau indextex ' + str(textstat.coleman_liau_index(test_data)))\nprint ('Automated readability index ' + str(textstat.automated_readability_index(test_data)))\nprint ('Dale Chall readability score ' + str(textstat.dale_chall_readability_score(test_data)))\nprint ('Difficult Words ' + str(textstat.difficult_words(test_data)))\nprint ('Linsear Write Formula ' +str(textstat.linsear_write_formula(test_data)))\ntextstat.gunning_fog(test_data)\ntextstat.text_standard(test_data)","75f2a4bc":"# Let's take another sample\n\n\ndf_opening_pdfs.head(2)\n\n# Clean up the pdf opening names\n\ndf_openings = pd.DataFrame()\ndf_openings['job_position'] = (df_opening_pdfs['opening_pdf']\n                                .str.replace(input_dir, '', regex=False)\n                                .str.replace('.txt', '', regex=False)\n                                .str.replace('\\d+', '')\n                                .str.replace(r\"\\s+\\(.*\\)\",\"\")\n                                .str.replace(r\"REV\",\"\"))\n\n#Remove the numbers\ndf_openings['class_code'] = (df_opening_pdfs['opening_pdf']\n                              .str.replace(input_dir, '', regex=False)\n                              .str.replace('.txt', '', regex=False)\n                              .str.extract('(\\d+)'))\n\n\ndf_openings['version'] =       df_opening_pdfs['opening_pdf'].str.slice(start=-10,stop=-4)\n\npdfFile = PyPDF2.PdfFileReader('..\/input\/data-science-for-good-city-of-los-angeles\/cityofla\/CityofLA\/Additional data\/PDFs\/2018\/September\/Sept 21\/PAINTER 3423 092118.pdf', 'rb')\n#pdfFile = df_opening_pdfs['opening_pdf']\nmetadata = pdfFile.getDocumentInfo()\nmetadata\n#pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n#df_openings['info'] = pdfReader.getPage(1) \n                           \ndf_openings.head()","3712eee9":"pdfFile.numPages \npageObj = pdfFile.getPage(1)\npdftext= pageObj.extractText()\n\npdftext","e25b46d9":"# A painter!!!\n\n\ndef replace(value):\n  return re.sub(r'\\n', r'', value)\n\npdftext_clean = replace(pdftext)\npdftext_clean\n                                \nprint ('Flesch Reading Ease ' + str(textstat.flesch_reading_ease(pdftext_clean)))\nprint ('Smog Index ' + str(textstat.smog_index(pdftext_clean)))\nprint ('Flesch Kincaide grade ' + str(textstat.flesch_kincaid_grade(pdftext_clean)))\nprint ('Coleman Liau Index ' + str(textstat.coleman_liau_index(pdftext_clean)))\nprint ('Automated Readability Index ' + str(textstat.automated_readability_index(pdftext_clean)))\nprint ('Dale Chall Readability Score ' + str(textstat.dale_chall_readability_score(pdftext_clean)))\nprint ('Difficult Words ' + str(textstat.difficult_words(pdftext_clean)))\nprint ('Linsear Write Formula '+  str(textstat.linsear_write_formula(pdftext_clean)))\nprint ('Gunning Fog ' + str(textstat.gunning_fog(pdftext_clean)))\nprint('Text Standard ' + str(textstat.text_standard(pdftext_clean)))","f599971a":"pdftext_clean","714aa049":"basic = \"SELECTION PROCESS  The examination will consist entirely of a weighted multiple-choice test administered and proctored on-line. In the on-line multiple-choice test, the following competencies may be evaluated: Mathematics, Teamwork, Equipment Operation, including the operation of hydraulic equipment, such as paint sprayers, scissor lift, and boom lift used to apply paint to surfaces at elevated heights; Safety Focus, including: safety procedures, regulations, and restrictions as required by the California Occupational Safety and Health Administration, South Coast Air Quality Management District, Environmental Protection Act, and California Department of Toxic Substances Control, including procedures necessary when using paints and coatings containing volatile organic compounds, handling and disposing of hazardous or toxic wastes, and working near energized electrical equipment or with toxic and flammable materials; safety procedures and personal protective equipment required when preparing surfaces and applying paint; safety requirements that must be adhered to when using stepladders, extension ladders, and scaffolds; safety procedures required when using high pressure equipment for the preparation of surfaces and application of paint; equipment used to ventilate an area during and\/or after painting; and Job Knowledge, including knowledge of: protective and decorative coverings, and the procedures used to mix and apply them; methods, tools, and materials used to prepare a wide variety of surfaces for painting; methods, tools, and equipment used to apply paint or protective coatings to a wide variety of surfaces; other necessary skills, knowledge, and abilities.   Additional information can be obtained by going to http:\/\/per.lacity.org\/index.cfm?content=jobanalyses and clicking on Competencies under Painter. \"","d238d360":"# Painter   54th and 55th grade???  Good grief\n\npdftext_clean = basic                \nprint ('Flesch Reading Ease ' + str(textstat.flesch_reading_ease(pdftext_clean)))\nprint ('Smog Index ' + str(textstat.smog_index(pdftext_clean)))\nprint ('Flesch Kincaide grade ' + str(textstat.flesch_kincaid_grade(pdftext_clean)))\nprint ('Coleman Liau Index ' + str(textstat.coleman_liau_index(pdftext_clean)))\nprint ('Automated Readability Index ' + str(textstat.automated_readability_index(pdftext_clean)))\nprint ('Dale Chall Readability Score ' + str(textstat.dale_chall_readability_score(pdftext_clean)))\nprint ('Difficult Words ' + str(textstat.difficult_words(pdftext_clean)))\nprint ('Linsear Write Formula '+  str(textstat.linsear_write_formula(pdftext_clean)))\nprint ('Gunning Fog ' + str(textstat.gunning_fog(pdftext_clean)))\nprint('Text Standard ' + str(textstat.text_standard(pdftext_clean)))","b178c9b8":"scores = pd.read_csv('..\/input\/city-of-la-readbility-scores\/reading_level_samples_combined.csv', header=0)\nscores.head(20)","595fbc84":"# Longest words\nlongwords = scores['Longest Word Letters Words'].values\n\ntext = str(longwords)\n# Generate a word cloud image\nwordcloud = WordCloud(max_font_size=50, max_words=200, background_color=\"white\").generate(text)\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n","84bdafc6":"# Words with 7 letters\n\nsns.distplot(scores['Words With Seven Letters'], kde=False, rug=True)\n\n\nprint(' Median Words With Seven Letters ' + str(scores['Words With Seven Letters'].median(axis=0)))\nprint(' Mean Words With Seven Letters ' + str(scores['Words With Seven Letters'].mean(axis=0)))\n#print('Mode Word Count ' + str(scores['Word Count'].mode))\nprint('Percentiles')\nscores['Words With Seven Letters'].describe(percentiles = [.10,.20,.3,.4,.5,.6,.7,.8,.9,.95,.97,1])\nprint('Standard Deviations')\nscores['Words With Seven Letters'].std(axis=0)\nplt.show()","a28f2575":"# Which job codes are in the 95% percentile and above\nscores.rename(columns={'Words With Seven Letters': 'Words_With_Seven_Letters'}, inplace=True)\nbigwordsq = \"\"\"\nselect distinct item, Words_With_Seven_Letters\nfrom scores\nwhere Words_With_Seven_Letters > 700\norder by Words_With_Seven_Letters desc\"\"\"\nbigwords = pysqldf(bigwordsq)\nprint(bigwords)\n\n# If you look closely, you will see many of these job titles fall on the list of hard-to-fill positions.","9d129232":"scores.columns","0e69cd15":"# Read the whole text.\nlongsyll = scores['Longest Word Syllables Words'].values\n\ntext = str(longsyll)\n# Generate a word cloud image\nwordcloud = WordCloud(max_font_size=50, max_words=120, background_color=\"white\").generate(text)\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n\n# Which of the following high syllable words might be candidates for improvement?\n# periodically\n# reconciliation\n# availability\n# identification\n# electronically\n# responsibilities\n# interdepartmental\n# specifications\n# opportunities","ac8c5e52":"# Total Syllable Count\nsns.distplot(scores['Syllable Count'], kde=False, rug=True);\n\nprint('Syllable Count ' + str(scores['Syllable Count'].median(axis=0)))\n#print('Mode Word Count ' + str(scores['Word Count'].mode))\nprint('Percentiles')\nscores['Syllable Count'].describe(percentiles = [.10,.20,.3,.4,.5,.6,.7,.8,.9,.95,.97,1])\nprint('Standard Deviations')\nscores['Syllable Count'].std(axis=0)","6e8d0557":"# Which job codes are in the 80% percentile and above\nscores.rename(columns={'Syllable Count': 'Total_Syllable_Count'}, inplace=True)\ntotalsyllsq = \"\"\"\nselect distinct item, Total_Syllable_Count\nfrom scores\nwhere Total_Syllable_Count > 3000\norder by Total_Syllable_Count desc\"\"\"\ntotalsylls = pysqldf(totalsyllsq)\nprint(totalsylls)\nplt.show()\n# based on the AMA reponse of which positions prove most challenging, we see that some have very high total syllable counts\n# I'm not even displaying all available rows - I recommend printing to CSV and reviewing the total list\n\n# Accountant\n# Accounting Clerk\n# Applications Programmer\n# Assistant Street Lighting Electrician   <-- 3040\n# Building Mechanical Inspector\n# Detention Officer\n# Electrical Mechanic                           \n# Equipment Mechanic                             \n# Field Engineering Aide\n# Housing Inspector\n# Housing Investigator\n# Librarian                                      <-- Librarian 4163\n# Security Officer\n# Senior Administrative Clerk\n# Senior Custodian\n# Senior Equipment Mechanic\n# Tree Surgeon                                   <-- 5856\n# In the future, our Personnel Department expects to find it challenging to fill the following classes:\n\n# IT-related classes (e.g., Applications Programmer)   <-- systems analyst 16382, DBA 4810, systems programmer 4217, IS Manager 3006\n# Wastewater classes                                   \n# Inspector classes                                    \n# Journey-level classes","d3744885":"sns.distplot(scores['Word Count'], kde=False, rug=True);","1fc19ce1":"print('Mean Word Count ' + str(scores['Word Count'].mean(axis=0)))\nprint('Median Word Count ' + str(scores['Word Count'].median(axis=0)))\n#print('Mode Word Count ' + str(scores['Word Count'].mode))\nprint('Percentiles')\nscores['Word Count'].describe(percentiles = [.10,.20,.3,.4,.5,.6,.7,.8,.9,.95,.97,1])\nprint('Standard Deviations')\nscores['Word Count'].std(axis=0)\n# The median and mean word count are pretty aligned, but there are some outliers\n","c732732a":"# Which job codes are in the 97% percentile and above\nscores.rename(columns={'Word Count': 'Word_Count'}, inplace=True)\ntoomanywordsq = \"\"\"\nselect distinct item, Word_Count\nfrom scores\nwhere Word_Count > 2100\norder by Word_Count desc\"\"\"\ntoomanywords = pysqldf(toomanywordsq)\ntoomanywords\n\n# based on the AMA reponse of which positions prove most challenging, we see that some have very high word counts\n# Accountant\n# Accounting Clerk\n# Applications Programmer\n# Assistant Street Lighting Electrician\n# Building Mechanical Inspector\n# Detention Officer\n# Electrical Mechanic                            <-- Electric Distribution Mechanic 2625\n# Equipment Mechanic                             <-- heavy duty equipment mechanic 2114\n# Field Engineering Aide\n# Housing Inspector\n# Housing Investigator\n# Librarian                                      <-- Librarian 2141\n# Security Officer\n# Senior Administrative Clerk\n# Senior Custodian\n# Senior Equipment Mechanic\n# Tree Surgeon                                   <-- 3437\n# In the future, our Personnel Department expects to find it challenging to fill the following classes:\n\n# IT-related classes (e.g., Applications Programmer)   <-- systems analyst 9019, DBA 2429, systems programmer 2220\n# Wastewater classes                                   <-- underground distribution constuction mechanic 2780\n# Inspector classes                                    <-- environmental 2134\n# Journey-level classes","b3c0f2ec":"# Gender (runs on a scale Female 0 to Male 100). There is documentation that it is noted that there is an inherent issue with this scale.\n\nax = sns.swarmplot(x=\"Gender Number\", y=\"Rating\", data=scores, order='A,B,C,D,E')","33a9b0cf":"scores.head(2)","9b4fe0b5":"# I believe I will have to try to join the job name with the file name\n# I need to create a new column on the scores , job_title\n# I will need to clean up the Item column\n        # Remove underscores\n        # Only bring in the words, or the first n spaces          Yes, this code would be better structured for reuse....\n\nscores['job_title'] = (scores['Item']\n                                .str.replace('.txt', '', regex=False)\n                                .str.replace('.pdf', '', regex=False)\n                                .str.replace('_', ' ', regex=False)\n                                .str.replace('\\d+', '')\n                                .str.replace(r\"\\s+\\(.*\\)\",\"\")\n                                .str.replace(r\"REV\",\"\")\n                                .str.upper() )\n\nscores['class_code'] = (scores['Item']\n                              .str.replace(input_dir, '', regex=False)\n                              .str.replace('.txt', '', regex=False)\n                              .str.extract('(\\d+)'))\nscores.head(10)\n\n# class code isn't perfect...\n# combination of all caps, applying  .str.upper() ","7374f227":"# if you've seen my other kernels, you'll know I like pandasql. \n# It's not as efficient at joining tables, but I find it more readable (no pun intended!)\n\nimport pandasql                    # https:\/\/github.com\/yhat\/pandasql\nfrom pandasql import sqldf\npysqldf = lambda q: sqldf(q, globals())\n\njoined = \"\"\"\nselect \na.job_position as job_position1,a.class_code as class_code1, b.item as item2, b.job_title as job_title2, b.class_code as class_code2, a.notes\nfrom df_jobs a\nleft outer join scores b\non a.job_position = b.job_title\n\"\"\"\n\n# setting up the left outer join to list all of the text and pdfs with score to the list of job titles we created earlier\njoined2 = \"\"\"\nselect a.*, b.*\nfrom df_jobs b\nleft outer join scores a\non b.job_position = a.job_title\n\"\"\"\ndf_joined2x = pysqldf(joined2)\nprint(df_joined2x)\n# downloading to take a good look\ndf_joined2x.to_csv('descriptions_and_readability_scores.csv')\n\n","dc285f06":"what = \"\"\"\n\nSELECT substr(requirements, 1, pos-1) AS req_num1,\n       substr(requirements, pos+1) AS req_desc1,\n       substr(requirements, pos+2) AS req_num2,\n       substr(requirements, pos+3) AS req_desc2\nFROM\n  (SELECT *,\n          instr(requirements,'.') AS pos\n   FROM df_jobs)\n\n\"\"\"\n\ndf_whatx = pysqldf(what)\ndf_whatx.head(10)\n\n# 1. = 453\n# 2. = 449\n# 3. = 236\n# 4. = 124\n# 5. = 69\n# 6. = 34\n# 7. = 22\n# 8. = 10\n# 9. = 6\n# first byte is not a number, blank, or '.' 2\n# second byte not a number 109\n# third = 2\n# fourth = 2  fifth = 2 6th = 2 7th = 259\n# annoying, need to strip the spaces off the front  trim()","41fe2e2c":"df_jobs1 = df_jobs\ndf_jobs1['requirements'] = df_jobs1['requirements'].astype('str')\nx = pd.DataFrame(df_jobs1['requirements'].str.split().values.tolist())\n#x = pd.DataFrame(df_jobs1.requirements.str.split('.', expand=True).values,\n#             columns=['Req1', 'Req2'])\n#df_jobs1[['Req1','Req2']] = df_jobs1.requirements.str.split(\"1.\",expand=True,)\nx.head(2)\n\n# this is garbage output but I'll leave it here to show what this code results in.","bfe86843":"# Warning - will run loooong\n#tryit_df = df_jobs.head(10)\ntryit = \"\"\"\nwith separators as ( values ('1.'), ('2.'), ('3.'), ('4.') ),\n  source (s) as ( select requirements from tryit_df ),\n  bag (q) as ( -- POSITIONS OF ALL SEPARATORS\n    with dim (len) as ( select length(s) from source ),\n    ndx (n) as (\n      select 1 union all select n+1 from ndx, dim where n < len\n    ) select 0 --> PSEUDO SEPARATOR IN FRONT OF SOURCE STRING\n      union all select n from ndx, source where substr(s, n, 1) in separators\n      union all select len+1 from dim --> PSEUDO SEPARATOR AT BOTTOM\n  ),\n  pre (p) as ( -- POSITIONS OF SEPARATORS PRECEDING NON SEPARATORS\n    select q from bag where not q+1 in bag\n  ) select printf(\"%2d %2d <%s>\", p, z, substr(s, p+1, z-p-1)) from (\n      select p, (select min(q) from bag where q > p) as z from pre where z\n    ), source\n    limit 30;\n\"\"\"\n\n#tryitx = pysqldf(tryit)\n#tryitx.head()\n\n#pandasql - again, not the most efficient....\n# I tried to Commit entire set but got : PandaSQLException: (sqlite3.OperationalError) database or disk is full\n# I am interested to see how this technique works so I will try it on a single row.","43837518":"# Goal 3 - What are the most common requirements words to start looking at?\nimport collections\nimport matplotlib.cm as cm\nfrom matplotlib import rcParams\nfrom wordcloud import WordCloud, STOPWORDS\n%matplotlib inline\n\n#reqwords = df_jobs['requirements'].values\nreqwords = ' '.join(df_jobs['requirements'].str.lower())\ntext = str(reqwords)\nstopwords = ['apply', 'nan', '1.', '2.', '3.', '4.', '5', '6', '7.', 'a.', 'b.', 'c.', 'd.','st...', 'a...',\n             '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n              '23', '24', '25', '26', '27','28','29','30','31', '32', '33', '34', '35', '36', '37', \n               '38', '39', '50', 'one', 'two', 'three', 'four', 'five', 'six','seven','eight','nine','ten',\n            'eleven', 'twelve', 'must', 'may', 'notes:','...', 't...']  + list(STOPWORDS)\n\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords,width=800, height=400).generate(text)\nplt.figure( figsize=(20,10) )\nplt.imshow(wordcloud)\n\n# looks like they want full time paid service of a specific time period!","47dec19b":"filtered_words = [word for word in reqwords.split() if word not in stopwords]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(40):\n    words.append(letter)\n    counts.append(count)\ncolors = cm.rainbow(np.linspace(0, 1, 10))\nrcParams['figure.figsize'] = 20, 10\n\nplt.title('Top words in the requirements')\nplt.xlabel('Count')\nplt.ylabel('Words')\nplt.barh(words, counts, color=colors)\n\n# rainbow for inclusion lol","01cb2744":"degreesq = \"\"\"\nselect\ndistinct\nclass_code,\ncase when requirements like '%full-time%' or requirements like '%Full-time%' \n        or requirements like '%full time%' or requirements like '%Full time%'\n    then 1 else 0 end as full_time\n,case when requirements like '%part-time%' or requirements like '%Part-time%' \n        or requirements like '%part time%' or requirements like '%Part time%'\n    then 1 else 0 end as part_time\n,case when requirements like '%month%' or requirements like '%year%' then 1 else 0 end as time_in_job_required\n,case when requirements like '%Degree%' or requirements like '%degree%' then 1 else 0 end as degree_required\n,case when requirements like '%Cert%' or requirements like '%cert%' then 1 else 0 end as certification_required\n,case when requirements like '%Graduat%' or requirements like '%graduat%' then 1 else 0 end as graduation_required\n,case when requirements like '%apprentic%' or requirements like '%Apprentic%' then 1 else 0 end as apprenticeship_required\n,case when requirements like '%license%' or requirements like '%License%' then 1 else 0 end as license_required\nfrom df_jobs\norder by class_code desc\n\n\"\"\"\n\ndegrees = pysqldf(degreesq)\ndegrees.head(2)\n\n# some of the class_codes don't look right. I ran this query up top after I created the df and it still looks that way so it didn't get messed up in the meantime\n","e07f617c":"# Goal #3 continue\n# Here I tried to extract some data to see if this is efficient. Not too bad but the wording varies in the job bulletins.\nreqq = \"\"\"\nwith list as (\nselect\ndistinct\nclass_code,\ncase when requirements like '%full-time%' or requirements like '%Full-time%' or requirements like '%full time%' or requirements like '%Full time%' \nthen 1 else 0 end as full_time\n,case when requirements like '%part-time%' or requirements like '%Part-time%' or requirements like '%part time%' or requirements like '%Part time%' then 1 else 0 end as part_time\n,case when requirements like '%month%' or requirements like '%year%'\n        or requirements like '%uarter%' or requirements like '%ours%'\nthen 1 else 0 end as time_in_job_required\n,case when requirements like '%GED%' or requirements like '%G.E.D%'\n        or requirements like '%igh school%' or requirements like '%HS%' or requirements like '%H.S.%'\nthen 1 else 0 end as GED_HS_required\n,case when requirements like '%Degree%' or requirements like '%degree%' \nthen 1 else 0 end as degree_required\n,case when requirements like '%Cert%' or requirements like '%cert%' \nthen 1 else 0 end as certification_required\n,case when requirements like '%school%' or requirements like '%School%' or requirements like '%training%'\n   or requirements like '%Training%' or requirements like '%Course%' or requirements like '%course%'\n   or requirements like '%Academy%' or requirements like '%academy%' \n   or requirements like '%Instruction%' or requirements like '%instruction%'\nthen 1 else 0 end as coursework_required\n,case when requirements like '%Graduat%' or requirements like '%graduat%' \nthen 1 else 0 end as graduation_required\n,case when requirements like '%apprentic%' or requirements like '%Apprentic%' \nthen 1 else 0 end as apprenticeship_required\n,case when requirements like '%license%' or requirements like '%License%' \nthen 1 else 0 end as license_required\n,case when requirements like '%college%' or requirements like '%College%' or requirements like '%university%' or requirements like '%University%' \nthen 1 else 0 end as college_required\n, case when lower(requirements) like '%four years of college%' then '4'\n       when lower(requirements) like '%bachelor%' then '4'\n       when lower(requirements) like '%master%' then '6?'\n       when requirements like '%PHD%' or requirements like 'Doctorate' or requirements like 'Doctoral' \n         or requirements like '%PhD%' or requirements like '%JD%' or requirements like '%MD%' then '6'\n       else ' ' end as school_years\n, case when requirements like '%bachelor%' or requirements like '%Bachelor%' then 'Bachelors'\n       when requirements like '%master%' or requirements like '%Master%' then 'Masters possible'\n       when requirements like '%PHD%' or requirements like 'Doctorate' or requirements like 'Doctoral' then 'Doctorate'\n         or requirements like '%PhD%' or requirements like '%JD%' or requirements like '%MD%'\n       else ' ' end as degree_level\n,case when requirements like '%urrently employed with the City of L%'  or requirements like '%urrent employment with the City of L%' \nthen 1 else 0 end as current_employee\n, case when requirements like '%ne year of full-time paid experience%' then 12\n       when requirements like '%wo years of full-time paid experience%' then 24\n       when requirements like '%hree years of full-time paid experience%' then 36\n       when requirements like '%our years of full-time paid experience%'  then 48\n       when requirements like '%ive years of full-time paid experience%' then 60\n       when requirements like '%ix years of full-time paid experience%' then 72\n       when requirements like '%even years of full-time paid experience%' then 84\n       when requirements like '%ight years of full-time paid experience%' then 96\n       when requirements like '%ine years of full-time paid experience%' then 108\n       when requirements like '%ten years of full-time paid experience%' then 120\n       when requirements like '%Ten years of full-time paid experience%' then 120\n       when requirements like '%ne year of part-time paid experience%' then 12\n       when requirements like '%wo years of part-time paid experience%' then 24\n       when requirements like '%hree years of part-time paid experience%' then 36\n       when requirements like '%our years of part-time paid experience%'  then 48\n       when requirements like '%ive years of part-time paid experience%' then 60\n       when requirements like '%ix years of part-time paid experience%' then 72\n       when requirements like '%even years of part-time paid experience%' then 84\n       when requirements like '%ight years of part-time paid experience%' then 96\n       when requirements like '%ine years of part-time paid experience%' then 108\n       when requirements like '%ten years of part-time paid experience%' then 120\n       when requirements like '%Ten years of part-time paid experience%' then 120\n       when requirements like '%wenty four months of%' then 24\n       when requirements like '%wenty-four months of%' then 24\n       when requirements like '%ne month of%' then 1\n       when requirements like '%wo months of%' then 2\n       when requirements like '%hree months of%' then 3\n       when requirements like '%our months of%' then 4\n       when requirements like '%ive months of%' then 5\n       when requirements like '%ix months of%' then 6\n       when requirements like '%even months of%' then 7\n       when requirements like '%ight months of%' then 8\n       when requirements like '%ine months of%' then 9\n       when requirements like '%ten months of%' then 10\n       when requirements like '%Ten months of%' then 10\n       when requirements like '%leven months of%' then 11\n       when requirements like '%welve months of%' then 12\n       when requirements like '%ighteen months of%' then 18\n       when requirements like '%wenty four months of%' then 24\n       else 0 end as months_ft\n,case when requirements like '%14 years of age%' then 14\n      when requirements like '%15 years of age%' then 15\n      when requirements like '%16 years of age%' then 16\n      when requirements like '%17 years of age%' then 17\n      when requirements like '%18 years of age%' then 18\n      when requirements like '%19 years of age%' then 19\n      when requirements like '%20 years of age%' then 20\n      when requirements like '%20 1\/2 years of age%' then 20.5\n      when requirements like '%21 years of age%' then 21\n      when requirements like '%25 years of age%' then 25\n else 0 end as min_age\n , case when requirements like '%valid California driver required%' then 1 else 0 end as CA_DL_required  -- this isn't correct\n , case when requirements like '%valid California driver%' then 1 else 0 end as CA_DL_may_be_required\n , case when requirements like '%CDL%' or requirements like '%C.D.L.%' then 1 else 0 end as CDL_required\n , case when requirements like '%lass A%' then 1 else 0 end as Class_A_required\n , case when requirements like '%lass B%' then 1 else 0 end as Class_B_required\n  , case when requirements like '%lass C%' then 1 else 0 end as Class_C_required\n , case when requirements like '%ourney%' then 1 else 0 end as Journey_Level_Required\n , case when requirements like '%enior%'  then 1 else 0 end as Senior_Exp_Required\n , case when requirements like '%upervisor%' then 1 else 0 end as Supervisor_Exp_Required\n , case when requirements like '%anager%' then 1 else 0 end as Manager_Exp_Required\n,requirements\n\n, case when upper(exam) like '%ONLY ON AN OPEN COMPETITIVE BASIS%' then 'OPEN'\n        when upper(exam) like '%INTERDEPARTMENTAL PROMOTIONAL AND AN OPEN COMPETITIVE BASIS%'\n        or  upper(exam) like '%INTERDEPARTMENTAL PROMOTIONAL AND OPEN COMPETITIVE BASIS%'\n        or  upper(exam) like '%INTERDEPARTMENTAL PROMOTIONAL AND OPEN COMPETITVE BASIS%'\n        or  upper(exam) like '%COMPETITIVE AND INTERDEPARTMENTAL PROMOTIONAL BASIS%'\n        or  upper(exam) like '%OPEN COMPETITIVE AND AN INTERDEPARTMENTAL PROMOTIONAL BASIS%'\n        or  upper(exam) like '%OPEN COMPETITIVE BASIS%'\n        then 'OPEN_INT_PROM'\n        when upper(exam) like '%INTERDEPARMENTAL PROMOTIONAL BASIS%'\n        or  upper(exam) like '%INTERDEPARTMENTAL PROMOTIONAL BASIS%'\n        or  upper(exam) like '%INTERDEPARTMENTAL PROMOTIONAL BASIS ONLY%'\n        then 'INT_DEPT_PROM'\n        when upper(exam) like '%DEPARTMENTAL PROMOTIONAL BASIS%'\n        then 'DEPT_PROM'\n        else ' ' end as availability_details\nfrom df_jobs\norder by class_code desc\n)\nselect l.* from df_jobs j\ninner join list l\non j.class_code = l.class_code\n--where l.one_year_ft = 1\n--or    l.two_years_ft = 1\n--or    l.three_years_ft = 1\n--or    l.four_years_ft = 1\n\n\n\"\"\"\n\nreqs = pysqldf(reqq)\nreqs.to_csv('requirements.csv')\n# print to csv to take a look","624a98b3":"reqs.head()","77aa0ed4":"import networkx as nx\nG = nx.DiGraph()\nG.add_edges_from(\n    [('1429', '1431a'), ('1431a', '1431b'), ('1431a', '1455'), \n     ('1431b', '1409'), ('1455', '1409'),\n     ('1409', '975')])\n\nval_map = {'1429': 1.0,\n           '1409': 0.5714285714285714,\n           '975': 0.0}\n\nvalues = [val_map.get(node, 0.25) for node in G.nodes()]\n\n# Specify the edges you want here\nred_edges = [('1431b', '1409'), ('1409', '975')]\nedge_colours = ['black' if not edge in red_edges else 'red'\n                for edge in G.edges()]\nblack_edges = [edge for edge in G.edges() if edge not in red_edges]\n\n# Need to create a layout when doing\n# separate calls to draw nodes and edges\npos = nx.spring_layout(G)\nnx.draw_networkx_nodes(G, pos, cmap=plt.get_cmap('jet'), \n                       node_color = values, node_size = 500)\nnx.draw_networkx_labels(G, pos)\nnx.draw_networkx_edges(G, pos, edgelist=red_edges, edge_color='r', arrows=True)\nnx.draw_networkx_edges(G, pos, edgelist=black_edges, arrows=False)\n","ac01358f":"%matplotlib inline\n\n\njob_graph = pd.read_csv('..\/input\/city-of-la-job-graph\/Job_Graph.csv', header=0)   #,nrows=125)\njob_graph['Job_1'] = job_graph['Job_1'].astype(str)\njob_graph['Job_2'] = job_graph['Job_2'].astype(str)\njobs =  list(job_graph.Job_1.unique())\npromotions = list(job_graph.Job_2.unique())\npromotions[0:10]\n\n","33ac1789":"#dict(zip(promotions, promotions))","d97850bd":"#[Job_2 for Job_2 in promotions]","e736050d":"plt.figure(figsize=(12, 12))\n# Inspiration from  http:\/\/jonathansoma.com\/lede\/algorithms-2017\/classes\/networks\/networkx-graphs-from-source-target-dataframe\/\n# 1. Create the graph\ng = nx.from_pandas_edgelist(job_graph, source = 'Job_1', target = 'Job_2', edge_attr=None, create_using=None)\n\n# 2. Create a layout for our nodes \nlayout = nx.spring_layout(g,iterations=20)\n\n# 3. Draw the parts we want\n# Edges thin and grey\n# Jobs_1 small and grey\n# Promotions sized according to their number of connections\n# Promotions blue\n# Labels for Promotions ONLY\n# Promotions that are highly connected are a highlighted color\n\n# Go through every promotion ask the graph how many\n# connections it has. Multiply that by 80 to get the circle size\npromotion_size = [g.degree(Job_2) * 80 for Job_2 in promotions]\nnx.draw_networkx_nodes(g, \n                       layout,\n                       nodelist=promotions, \n                       node_size=promotion_size, # a LIST of sizes, based on g.degree\n                       node_color='lightblue')\n\n# Draw all jobs\nnx.draw_networkx_nodes(g, layout, nodelist=jobs, node_color='#cccccc', node_size=100)\n\n# Draw all jobs with most promotional ops\nhot_jobs = [Job_1 for Job_1 in jobs if g.degree(Job_1) > 1]\nnx.draw_networkx_nodes(g, layout, nodelist=hot_jobs, node_color='orange', node_size=100)\n\nnx.draw_networkx_edges(g, layout, width=1, edge_color=\"#cccccc\")\n\nnode_labels = dict(zip(promotions, promotions))\nnx.draw_networkx_labels(g, layout, labels=node_labels)\n\nplt.axis('off')\nplt.title(\"Promotions\")\nplt.show()\n\n# toooooo much! It looks like a swarm of gnats\n# I did more on this in my spin-off kernel","fd01f3e0":"catq = \"\"\" SELECT DISTINCT Category from job_graph order by category asc\"\"\"\ncategories = pysqldf(catq)\ncategories","f87337b6":"# Please answer the following questions\n\n# Which category would you like to check?\ncategory = \"'Job_Title'\"\n\n# What is your current position?\ncurrent_position = \"'%Officer%'\"\n","24a31c0b":"### I'm going to start with just the Job_Title category\nquery_text = \"SELECT * FROM job_graph where Category = %(category)s and (Job_1 like %(current_position)s or Job_2 like %(current_position)s)\"%locals()\njob_titles_g = sqldf(query_text)   #,(current_position,current_position))\njob_titles_g.head(10)\n","0f259ff8":"from graphviz import Digraph\ndot = Digraph(comment='Promotions')\n\nfor index, row in job_titles_g.iterrows():\n    dot.edge(str(row[\"Job_1\"]), str(row[\"Job_2\"]), label='')\n\ndot\n","5095f00d":"# Please answer the following questions\n\n# Which category would you like to check?\ncategory = \"'Job_Title'\"\n\n# What is your current position?\ncurrent_position = \"'%Accountant%'\"\n\n#################################################################\nquery_text = \"SELECT * FROM job_graph where Category = %(category)s and (Job_1 like %(current_position)s or Job_2 like %(current_position)s)\"%locals()\njob_titles_g = sqldf(query_text)   #,(current_position,current_position))\njob_titles_g.head()\ndot = Digraph(comment='Promotions')\n\nfor index, row in job_titles_g.iterrows():\n    dot.edge(str(row[\"Job_1\"]), str(row[\"Job_2\"]), label='')\ndot","d671ac2f":"# All Categories\n# What is your current position?  all lower-case please\ncurrent_position = \"'%officer%'\"\n\n#################################################################\nquery_text = \"SELECT * FROM job_graph where  (lower(Job_1) like %(current_position)s or lower(Job_2) like %(current_position)s)\"%locals()\njob_titles_g = sqldf(query_text)   #,(current_position,current_position))\njob_titles_g.head()\ndot = Digraph(comment='Promotions')\n\nfor index, row in job_titles_g.iterrows():\n    dot.edge(str(row[\"Job_1\"]), str(row[\"Job_2\"]), label='')\ndot","5b16dd43":"# All Categories\n# What is your current position or interest? all-lower case please\ncurrent_position = \"'%fire%'\"\n\n#################################################################\nquery_text = \"SELECT * FROM job_graph where  (lower(Job_1) like '%Fire%' or lower(Job_2) like '%Fire%')\"\n#query_text = \"SELECT * FROM job_graph where  (lower(Job_1) like %(current_position)s or lower(Job_2) like %(current_position)s)\"%locals()\njob_titles_g = sqldf(query_text)   #,(current_position,current_position))\njob_titles_g.head()\ndot = Digraph(comment='Promotions')\n\nfor index, row in job_titles_g.iterrows():\n    dot.edge(str(row[\"Job_1\"]), str(row[\"Job_2\"]), label='')\ndot","a0031efc":"job_graph.head(10)","23645ace":"# All Categories\n# What is your current position or interest? all-lower case please\ncurrent_position = \"'%nurse%'\"\n\n#################################################################\nquery_text = \"SELECT * FROM job_graph where  (lower(Job_1) like %(current_position)s or lower(Job_2) like %(current_position)s)\"%locals()\njob_titles_g = sqldf(query_text)   #,(current_position,current_position))\njob_titles_g.head()\ndot = Digraph(comment='Promotions')\n\nfor index, row in job_titles_g.iterrows():\n    dot.edge(str(row[\"Job_1\"]), str(row[\"Job_2\"]), label='')\ndot","b40ed523":"df_jobs.columns","7f632f35":"df_openings.columns","3bf028e8":"majors = pd.read_csv('..\/input\/fivethirtyeight-college-majors-dataset\/majors-list.csv', header=0)\nmajors.head()","77ff9ffc":"# I am examining some of the fields\nquestion = \"\"\"\nselect * from majors j\nwhere lower(j.Major) like '%physical science%' \n\"\"\"\nfound_majors = pysqldf(question)\nfound_majors.head()","788307df":"# reversing the lookup\nquestion = \"\"\"\nselect * from df_jobs j\nwhere lower(j.requirements) like '%physical sciences%' \n\"\"\"\nfound_majors = pysqldf(question)\nfound_majors.head()","47a0a4df":"# which majors are we finding?\n#result = []\n#found_majors = []\n#def find_majors(x):\n#    sub = x.lower()\n#    sub = 'biology'\n#    print(sub)\n#    if (reqs['requirements'].str.find(sub).all != -1): \n#         print(sub)\n#    else: \n#         x#print(sub)\n#       \n#result = [find_majors(x) for x in majors['Major']]\n#print(x)\n#reqs.head(200)\n\n## The differences in the naming of the majors on the list and in the requirements is challenging\n# what about requirements that state several majors?   This isn't going to work....","4249e85d":"question = \"\"\"\nselect * from reqs where requirements like '%fine arts%'\n\"\"\"\nMajors1 = pysqldf(question)\nMajors1.head()","c5cd1d0c":"csv_prep1 = \"\"\"\nselect \n' ' as FILE_NAME\n, j.job_position  as JOB_CLASS_TITLE\n, r.class_code as JOB_CLASS_NO\n,' ' as REQUIREMENT_SET_ID\n,' ' as REQUIREMENT_SUBSET_ID\n,j.duties  as JOB_DUTIES\n,r.school_years as EDUCATION_YEARS\n, case when GED_HS_required = 1 then 'HIGH SCHOOL'\n       when degree_required = 1 then 'COLLEGE OR UNIVERSITY'\n       when apprenticeship_required = 1 then 'APPRENTICESHIP'\n       else null end as SCHOOL_TYPE\n\n,' ' as EDUCATION_MAJOR\n, case when cast(r.months_ft as int) > 0 then cast(r.months_ft as int)\/12.00 else null end as EXPERIENCE_LENGTH\n, case when r.full_time then 'FULL-TIME'\n       when r.part_time then 'PART-TIME' else ' ' end as FULL_TIME_PART_TIME\n,' ' as EXP_JOB_CLASS_TITLE\n,' ' as EXP_JOB_CLASS_ALT_RESP\n,' ' as EXP_JOB_CLASS_FUNCTION\n,' ' as COURSE_COUNT\n,' ' as COURSE_LENGTH\n,' ' as COURSE_SUBJECT\n,' ' as MISC_COURSE_DETAILS\n, case when r.CA_DL_required =  1 then 'R' else 'P' end as DRIVERS_LICENSE_REQ\n,' ' as DRIV_LIC_TYPE\n, case when r.Class_B_required = 1 then 'B'\n       when r.Class_C_required = 1 then 'C' else ' ' end as ADDTL_LIC\n, r.availability_details as EXAM_TYPE\n, j.salary as ENTRY_SALARY_GEN\n,' ' as ENTRY_SALARY_DWP\n,' ' as OPEN_DATE\n\nfrom reqs r\ninner join df_jobs j\non j.class_code = r.class_code\n\n\n\"\"\"\ncsv_prep = pysqldf(csv_prep1)\ncsv_prep.head(2)\ncsv_prep.to_csv('csv_prep1.csv')","c9d9e817":"# readability job title cleanup.. some of these are pdfs so it should be interesting. There are dupe job names too.\nscores['Title'] = (scores['Item']\n                                .str.replace(input_dir, '', regex=False)\n                                .str.replace('.txt', '', regex=False)\n                                .str.replace('\\d+', '')\n                                .str.replace('.pdf', '')\n                                .str.replace('__', '')\n                                .str.replace(r\"\\s+\\(.*\\)\",\"\")\n                                .str.replace(r\"REV\",\"\")\n                                .str.replace(r\" updated \",\"\")).str.upper()\n\nscores['Title'] = scores['Title'].str.replace('_$', '').str.replace('^_', '')\nscores['Title'] = scores['Title'].str.replace('_', ' ')\nscores.head(20)","26819e73":"# scores     look at education requirements using the job graph file\n\n###  This isn't working perfectly - trying to match across job titles but there are variations in naming (such as I,II etc) \n#    or I didn't have a writing sample\nreqscoresq = \"\"\"\nselect distinct Job_1, Job_2, Category, Rating\nfrom \njob_graph j\nleft outer join scores s\non upper(substr(j.Job_2,1,10)) = upper(substr(s.Title,1,10))\nwhere Category = 'Education'\nand Rating in ('A', 'B', 'C', 'D', 'E', 'F')\norder by Rating desc\n \n\"\"\"\nreqscores = pysqldf(reqscoresq)\nreqscores.head(100)\n","2061a0c3":"#### Packages to import.   Custom import required\n\n PyPDF2    https:\/\/pythonhosted.org\/PyPDF2\/PdfFileReader.html\n \n textstat https:\/\/pypi.org\/project\/textstat\/","93529227":"### Let's pull in a good list of college majors\nhttps:\/\/www.kaggle.com\/fivethirtyeight\/fivethirtyeight-college-majors-dataset\n\n### Possibly the listing of required college majors could be standardized","493d5fe3":"# Goal 2- Too many words\n\n700+ being too many\n\nThe very fact that scale of my distribution plot goes over 8000 is not good.\n\nShorten your sentences - https:\/\/medium.com\/@bloghands\/tips-and-tools-for-improving-your-content-readability-score-eed82e2ffa87\nLet\u2019s say your readability analyzer says your work is too complicated. You can make significant improvements by shortening the longest sentences. If you have a long sentence, try to create two. A helpful rule is: \u201cOne idea, one sentence.\u201d","8c39429d":"# Goal 2 - Gender numbers affect ratings\n\ngender numbers that are lower - or at least on this scale, most likely in the middle, rate higher.","a4934575":"I generated the readability scores using Readable.com during a 24-hour free demo period. I did not have enough time to process all text and pdf's, but I got a good representation. I dowloaded each output for each file that I processed and merged into a single csv.\n\nThis csv has been published here on Kaggle and is available for your use:  \n\nhttps:\/\/www.kaggle.com\/silverfoxdss\/city-of-la-readbility-scores","2fa033cb":"### Prep : Convert the information in the txt files in a table\n","0d4e93fd":"# Goal 3 - Requirements","1abf00d5":"# Goal 2 - Text Reading Levels","03b0560d":"# Goal 3 : Dynamic Job Graph","6c153aa5":"# Goal 2 - Too Many Syllables\n\nToo many Syllables\n\nWords that seem common: Identification, Responsibilities\n\nWords that probably are problematic: Interdepartmental, reconciliation (unless it's an accounting or auditing position)\n\nUse fewer syllables : https:\/\/medium.com\/@bloghands\/tips-and-tools-for-improving-your-content-readability-score-eed82e2ffa87\nUse one- and two-syllable words when you can. Avoid using longer words unless they are widely used and familiar.\n","15119f59":"https:\/\/www.geeksforgeeks.org\/readability-index-pythonnlp\/\n\nTo apply the formula:\n\nSelect several 100-word samples throughout the text.\nCompute the average sentence length in words (divide the number of words by the number of sentences).\nCompute the percentage of words NOT on the Dale\u2013Chall word list of 3, 000 easy words.\nCompute this equation\n\n Raw score = 0.1579*(PDW) + 0.0496*(ASL) + 3.6365\nHere,\nPDW = Percentage of difficult words not on the Dale\u2013Chall word list.\nASL = Average sentence length\nThe Gunning fog Formula\n\nGrade level= 0.4 * ( (average sentence length) + (percentage of Hard Words) )\nHere, Hard Words = words with more than two syllables.\nSmog Formula\n\nSMOG grading = 3 + \u221a(polysyllable count).\nHere, polysyllable count = number of words of more than two syllables in a \nsample of 30 sentences.\nFlesch Formula\n\nReading Ease score = 206.835 - (1.015 \u00d7 ASL) - (84.6 \u00d7 ASW)\nHere,\nASL = average sentence length (number of words divided by number of sentences)\nASW = average word length in syllables (number of syllables divided by number of words)\nAdvantages of Readability Formulae:\n\n1. Readability formulas measure the grade-level readers must have to be to read a given text. Thus provides the writer of the text with much needed information to reach his target audience.\n\n2. Know Before hand if the target audience can understand your content.\n\n3. Easy-to-use.\n\n4. A readable text attracts more audience.\n\nDisadvantages of Readability Formulae:\n\n1. Due to many readability formulas, there is an increasing chance of getting wide variations in results of a same text.\n\n2. Applies Mathematics to Literature which isn\u2019t always a good idea.\n\n3. Cannot measure the complexity of a word or phrase to pinpoint where you need to correct it.","73eb33de":"![image.png](attachment:image.png)","0f240f6b":"Prep : Look for keywords, and append the following strings to the final dataframe","ddf231c4":"### Pick and choose which categories to display\nIf you recall from earlier, this is our df\njob_graph = pd.read_csv('..\/input\/city-of-la-job-graph\/Job_Graph.csv', header=0,nrows=125)\njob_graph['Job_1'] = job_graph['Job_1'].astype(str)\njob_graph['Job_2'] = job_graph['Job_2'].astype(str)","a9d207b4":"# Goal 2 - Readability Metrics\n\n## I ran the Painter text through readable.com to get some industry measurement standards.\n\nInteresting to see that syllables, length of words, and length of sentence are key drivers of the scoring. I think I can work with those.\n\nNote:  I have all of the reports from the jobs I ran available\nhttps:\/\/www.kaggle.com\/silverfoxdss\/painteranalysis","d25ff027":"#### I am creating a file from the bulletins\n\nIt's too large to show at once so I created a column named categories so you can pick and choose what to display.\nI would hope for an interactive graph, but this will do for now.","805782d3":"## City of LA - Job postings should be an invitation, not a barrier\n\n#### If you are having issues viewing the kernel due to size, just fork it and you'll be able to see it much clearer.\n","3a69e8dc":"## Explore - What is the structure of the PDF?","5cea8a2e":"## Explore - Duties Wordcloud","5df9b2aa":" This is definitely going to be a wander (in circles, for sure)\n\n The goal (I believe):\n \n     Given an employee's current state\n             a. current job title\/code\n             b. length of time in current position\n             c. highest level of education\n             d. apprentice stints\n             e. age\n             \n                  Identify current or upcoming promotional activities\n                  \n     Assumption: Ignore lateral moves","10fd6f72":"#### Goal #3 - Considering what we want to trigger a behavior nudge for a current employee to apply for a promotion\n\nTime in prereq position met, \nAge?, \nNew degree or certification\n\nPretend that we have a file of current employee status similar to such: (for simplicity, just their current job counts) :\nEmployee ID,  Current Job Code,  Current Job Full-time Months in Service,  Current Job Part-time Months in Service, Paid Position Flag, \nAccredited PhD Major, Accredited Masters Major, Accredited Bachelors Major, Accredited Associates Major, High School\/GED Completed, Some College Completed, Certification1, Certification2, Certification3, Certification4, Certification5, Drivers License Flag, CDL Flag \n","124ceae3":"## One Hypothesis : \n\n### Adjusting the readability-level of job postings based on education requirements of that post will increase interest in job postings for those limited written English comprehension skills.\n\nUpon initial analysis, the very first job text was at the 23rd and 24th grade level!!!!   A Painter.  I don't think that is reasonable to expect your average painter to be able to read at a post-doc level!\n\nIt's no suprise they might have trouble attracting talent\n\n\"The goal is to convert a folder full of plain-text job postings into a single structured CSV file and then to use this data to: (1) identify language that can negatively bias the pool of applicants; (2) improve the diversity and quality of the applicant pool; and\/or (3) make it easier to determine which promotions are available to employees in each job class.\"\n\nBreaking it down into:  (in all sort of orders in my notebooks as I work in different areas)\n     - Prep\n     - Explore\n     - Goal 1 - create a single structured CSV file\n     - Goal 2 - improve diversity and quality of applicant pool  (focus on readability)\n     - Goal 3 - identify promotional opportunities  (req identification and promotion graphs)\n                \n### Consider upvoting if any of this is of interest or value to you. Thanks!\n\n# Goal 1: Results\nI don't have any yet for this based on the sample that was provided. I struggle with the usefulness of the layout as we don't have insight into the process that will consume it. The files I am creating are inputs to my analysis and recommendations for goals 2 and 3.\nTowards the end of the kernel, I have started creating the submission csv...still much work to do. \n\nThere are some discussion going on it here: https:\/\/www.kaggle.com\/c\/data-science-for-good-city-of-los-angeles\/discussion\/92339#latest-534057\n\n# Goal 2 : Results and Recommendations\nI'm reviewing some ideas as I go along. I AM seeing that some of the job codes that pop up as problematic are also on the list of positions that are challenging to fill - tree surgeon is an example.\n\n1. grade level too high - Simplify\n -  too many high-syllable words\n -  too many words in a sentence\n \n2. the content might be overly-formal, reducing readability and industry tends to label this as 'male' (judge that as you may)\n\n3. the length of the postings is generally way too long and exceeds 700 word limit\n    - Simplify or visually break up the description\n    \n4. the postings appear to be developed for the employer, not the prospects\n    - How to get the legal verbage in while still attracting prospect?\n    - Here is a great kernel by @koalaberarski on the use of pronouns:\n            https:\/\/www.kaggle.com\/koalabearski\/how-la-uses-we-you-and-applicant-to-hire\n    - Perhaps a redesign of the job posting creating a visual separations.\n        Section 1: Woo the prospect with the advantages of that position and working for the City of LA. Includes job description.\n                   What is the growth of this position? Why should they work for the City of LA and not somewhere else.\n                   Once you've enticed them, then you can start scaring them off with a long list of requirements\n        Visual Break\n        Section 2: Requirements. What is a real 'requirement' and what is preferred?\n                   Referencing the 'Employer Tip' in this report: \n                   https:\/\/business.linkedin.com\/talent-solutions\/blog\/diversity\/2019\/how-women-find-jobs-gender-report\n        Visual Break\n        Section 3: Application Process. Make it organized so the prospect can see the exact order of the steps of the process.\n                    OR - separate it completely. First get them interested and self-identify as qualified. \n                    Then send them to a page of simple step by step instructions in plain language.\n                   \n\n# Goal 3 : Results and Recommendations\nAssuming an employee database that stores pertinant data point, it would be advisable to create a table that stores the unique features of each job position (possibly job postings). A compare is done and when a threshold is met, a trigger communication is sent to the current employee of the promotional opportunity. This can also be done for prospects if they enter information and ask to be informed of opportunities. I have extracted some key requirements features manually. I allow inputs to determine the graph viz. Try it out!\nOnce I have the details nailed and the csv created and if I have time, I will reverse engineer for automation. (note: not enought time)\n\n#### Check out my spin-off kernel Fun with Graphs: https:\/\/www.kaggle.com\/silverfoxdss\/city-of-la-fun-with-job-graphs\n\nRecommendations: \n\n     Standardize the degrees and coursework selections (such as a drop-down) so that they can be more easily mapped\n     Standardize the education type into a dropdown so that four-year-degree and Bachelor's are synched up. \n         Some postings state four-year-college but not necessarily a degree. \n     Standardize the job titles across the different data sources\n         Ideally, job titles should match in the requirements and across documents and job graphs\n     Standardize the certification, license, and training course names across descriptions","6b37525b":"# Goal 2 - Bring in the generated scores and take a look","2245ff15":"## Prep : Load file titles","45add719":"select distinct exams for debugging\nCOMPETITIVE AND INTERDEPARTMENTAL PROMOTIONAL BASIS\nDEPARTMENTAL PROMOTIONAL BASIS\nINTERDEPARMENTAL PROMOTIONAL BASIS\nINTERDEPARTMENTAL PROMOTIONAL AND AN OPEN COMPETITIVE BASIS\nINTERDEPARTMENTAL PROMOTIONAL AND OPEN COMPETITIVE BASIS\nINTERDEPARTMENTAL PROMOTIONAL AND OPEN COMPETITVE BASIS\nINTERDEPARTMENTAL PROMOTIONAL BASIS\nINTERDEPARTMENTAL PROMOTIONAL BASIS ONLY\nNone\nONLY ON AN OPEN COMPETITIVE BASIS\nOPEN COMPETITIVE AND AN INTERDEPARTMENTAL PROMOTIONAL BASIS\nOPEN COMPETITIVE BASIS\n\n","fff93d68":"# Goal 3 - Promotional Graphs","4a7e0df4":"# Goal 2 - Combining Readability Metrics with the job details  \n\n#### Back to Goal 2 again","7c54341b":"# Goal #1","a3316159":"#### Application Developer - simplified\nApplication Developer  1429\nto Programmer Analyst I, II, III, IV 1431a\nApplications \nto Programmer Analyst V 1431b or Systems Programmer I, II, III 1455\nmanager 1409\n\nDirector of Systems 975","bebaaca7":"### Prep : Clean up the file names","e6d4c28f":"# Explore - Getting Smart\n\n#### White Paper: Gender, Genre, and Writing Style in Formal Written Texts \n    http:\/\/u.cs.biu.ac.il\/~koppel\/papers\/male-female-text-final.pdf\n\n\n#### What's a good readability score? \n    For grade levels, the result of most of the scoring algorithms, the score corresponds roughly to the number of years of education a person has had - based on the USA education system.\n    A grade level of around 10-12 is roughly the reading level on completion of high school.\n    Text to be read by the general public should aim for a grade level of around 8. Written by Steve Linney \n\n#### Readability calculations\n    https:\/\/www.geeksforgeeks.org\/readability-index-pythonnlp\/\n    \n#### Comments on length - no more than 700 words\n    https:\/\/www.mightyrecruiter.com\/blog\/6-appalling-job-postings-and-what-you-can-learn-from-them\/\n    \n#### Diversity considerations\n    https:\/\/www.fastcompany.com\/3044094\/how-changing-one-word-in-job-descriptions-can-lead-to-more-diverse-candid\n    https:\/\/www.tmhra.org\/ADAToolkit\/5-WriteADA-JobDescrip.pdf\n    https:\/\/slator.com\/demand-drivers\/linguistic-diversity-in-the-us-hits-record-high\/","51015a17":"# Goal 2: Words too long\n\nShorten your words : https:\/\/medium.com\/@bloghands\/tips-and-tools-for-improving-your-content-readability-score-eed82e2ffa87\nWith a little thought, you will normally be able to exchange a long word for a short word or words.\n\nWords like \u2018proximity\u2019 become \u2018near.\u2019 \u2018Furthermore\u2019 may become \u2018also.\u2019","7caa9a79":"# Explore - PDFs\nLet's take a look\n","ccc06b5e":"### Goal 2 - Time to figure out how to join the document dataframe to the readability dataframe","be5b9294":"# More to come!"}}