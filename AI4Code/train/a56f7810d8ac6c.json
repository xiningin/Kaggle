{"cell_type":{"ba795674":"code","1ef32964":"code","0bd84de1":"code","4dbc17e0":"code","f969b5c6":"code","edc762bf":"code","7304566f":"code","f4c651e8":"code","bb8adf5b":"code","c58a5706":"code","6acd78a3":"code","b2aba97f":"code","0027b037":"code","37b0a2d4":"code","357a2f2f":"code","65a1edf4":"code","256741dd":"code","87d03dc1":"code","85b67509":"code","ea28c288":"markdown"},"source":{"ba795674":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option(\"display.max_columns\", None)\n# pd.\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ef32964":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")","0bd84de1":"print(len(train_df))","4dbc17e0":"train_df.head(5)","f969b5c6":"Summary = pd.DataFrame(train_df.dtypes, columns = ['Dtype'])\nSummary['null'] = train_df.isnull().sum()\nSummary['max'] = train_df.max()\nSummary['min'] = train_df.min()\nSummary['first'] = train_df.iloc[0, :]\nSummary['second'] = train_df.iloc[1, :]\nSummary['third'] = train_df.iloc[2, :]","edc762bf":"Summary","7304566f":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc","f4c651e8":"y = train_df[\"target\"]\ntrain_df = train_df.drop([\"target\", \"id\"], axis = 1)","bb8adf5b":"test_df = test_df.drop(\"id\", axis = 1)","c58a5706":"train_df[\"mean\"] = train_df.mean(axis = 1)\ntrain_df[\"med\"] = train_df.median(axis = 1)\ntrain_df[\"std\"] = train_df.std(axis = 1)\ntrain_df[\"skew\"] = train_df.skew(axis = 1)\n\ntest_df[\"mean\"] = test_df.mean(axis = 1)\ntest_df[\"med\"] = test_df.median(axis = 1)\ntest_df[\"std\"] = test_df.std(axis = 1)\ntest_df[\"skew\"] = test_df.skew(axis = 1)","6acd78a3":"X_train, X_test, y_train, y_test = train_test_split(train_df,y, test_size = 0.20, stratify = y, random_state = 123)","b2aba97f":"len(X_train)\nlen(X_test)","0027b037":"scaler = StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train))\nX_test = pd.DataFrame(scaler.transform(X_test))","37b0a2d4":"lr = LogisticRegression(random_state=123, C = 0.0001, penalty = 'l2')\nlr.fit(X_train, y_train)","357a2f2f":"y_pred = lr.predict_proba(X_test)\ny_pred = y_pred[:, 1]","65a1edf4":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(auc(fpr, tpr))\n# The score is without adding features, 0.7469048481960304\n# The score is with exrta features 0.746916605626198\n# using just 20 percent data for testing, cause yeah, the more the better 0.7469685919166085\n# score when used C = 0.005, 0.7469690275350676\n# score when used C = 0.001 0.746970662771196\n# score when used c = 0.0001 0.7469809539794716\n# score when used skew as a feature as well 0.7470002189835658","256741dd":"test_df = scaler.transform(test_df)","87d03dc1":"y_res = lr.predict_proba(test_df)\ny_res = y_res[:, 1]","85b67509":"sub[\"target\"] = y_res\nsub.to_csv(\"lr1.csv\", index=False)\nsub.head(10)","ea28c288":"### Reading data"}}