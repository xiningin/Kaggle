{"cell_type":{"514d725d":"code","44088c83":"code","4588bb25":"code","536d2ccf":"code","f33ec78e":"code","28033291":"code","65f192e7":"code","23eca63d":"code","7557dcc1":"code","0ff2286b":"code","1da5c0e2":"code","0cadda7d":"code","6dffb194":"code","593b609c":"code","04358c72":"code","6f053b40":"code","4519d2b3":"code","6f33470c":"code","160a5f56":"code","ea71efd3":"markdown","2d4a972b":"markdown","a9509070":"markdown","ff0aa06c":"markdown","6d1fd408":"markdown","92c3b049":"markdown","3605dc45":"markdown","9062a20b":"markdown","2f7fdbd8":"markdown","6d327c70":"markdown","0bd61c0b":"markdown","32d5446c":"markdown","3b248d99":"markdown"},"source":{"514d725d":"import pandas as pd\nimport numpy as np\n\nimport time\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nfrom sklearn.model_selection import KFold,StratifiedKFold","44088c83":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D\nfrom tensorflow.keras.optimizers import Adadelta\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,LearningRateScheduler,EarlyStopping\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.version.VERSION)","4588bb25":"# Reading the Train and Test Datasets.\n\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","536d2ccf":"# Let's see the shape of the train and test data\nprint(train.shape, test.shape)","f33ec78e":"train.head()","28033291":"train.describe()","65f192e7":"fig=plt.figure(figsize=(14,8))\ncolumns = 8\nrows = 3\nfor i in range(1, rows*columns+1):\n    \n    digit_array = train.loc[i-1, \"pixel0\":]\n    arr = np.array(digit_array)   \n    image_array = np.reshape(arr, (28,28))   \n    \n    \n    fig.add_subplot(rows, columns, i)\n    plt.title(\"Label:\"+train.loc[i-1,\"label\"].astype(\"str\"))\n    plt.imshow(image_array, cmap=plt.cm.binary)\n    \nplt.show()","23eca63d":"ax=sns.countplot(train.loc[:,\"label\"])","7557dcc1":"# dividing the data into the input and output features to train make the model learn based on what to take in and what to throw out.\ntrain_X = train.loc[:, \"pixel0\":\"pixel783\"]\ntrain_y = train.loc[:, \"label\"]\n","0ff2286b":"treshhold=0.1\ntrain_X[train_X<treshhold]=0\ntest[test<treshhold]=0","1da5c0e2":"train_X = train_X \/ 255.0\ntest_X = test \/ 255.0\n\ntrain_X = train_X.values.reshape(-1,28,28,1)\ntest_X = test_X.values.reshape(-1,28,28,1)\ntrain_y = to_categorical(train_y, num_classes = 10)","0cadda7d":"\ndef build_model(input_shape=(28, 28, 1)):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = 3, activation='swish', input_shape = (28, 28, 1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 3, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64, kernel_size = 3, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 3, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(128, kernel_size = 4, activation='swish'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n\n    \n    return model","6dffb194":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images","593b609c":"#learning_rate_reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='accuracy',   # quality to be monitored \n                                            patience=3,          # no of epoch with no improvement after learning rate will be reduced\n                                            verbose=1,           # update message\n                                            factor=0.8,          # reducing learning rate \n                                            min_lr=0.001)       # lower bound learning rate \n\n# DECREASE LEARNING RATE EACH EPOCH\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n\n\nearly_stop=EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto',\n    baseline=None, restore_best_weights=True)","04358c72":"%%time\n\nnets=10\n\nmodel = [0] *nets\nhistory = [0] * nets\n\n\nskf = StratifiedKFold(n_splits=nets, shuffle = True, random_state=1)\nskf.get_n_splits(train_X, train['label'])\nprint(skf)\n\nnumber=0\n\n\nfor train_index, test_index in skf.split(train_X, train['label']):\n    print(\"SPLIT \",number,\" TRAIN index:\", train_index, \"TEST index:\", test_index)\n    \n    X_train, X_val = train_X[train_index], train_X[test_index]\n    y_train, y_val = train_y[train_index], train_y[test_index]\n    \n    model[number]=build_model()\n    model[number].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    history[number] =model[number].fit(datagen.flow(X_train,y_train), epochs=100 ,validation_data = (X_val,y_val) ,\n     batch_size=100, verbose = 0,callbacks = [annealer,early_stop])\n    \n    metrics=pd.DataFrame(history[number].history)\n    display(metrics)\n    \n    \n    number+=1","6f053b40":"for number in range(0,nets):\n    model[number].save(\"StratifiedKFold_10_batch100_double_val_loss_\"+str(number)+\".h5\")","4519d2b3":"# ENSEMBLE PREDICTIONS AND SUBMIT\nresults = np.zeros( (test_X.shape[0],10) ) \nfor j in range(nets):\n    results = results + model[j].predict(test_X)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"StratifiedKFold_10_batch100_double_val_loss.csv\",index=False)","6f33470c":"def show_test_digits(indexes):    \n    columns = 10\n    rows = len(indexes)\/\/columns +1    \n    fig=plt.figure(figsize=(14,rows*2))    \n    \n    for plot_id, i in enumerate(indexes,1):     \n        fig.add_subplot(rows, columns, plot_id)                     \n        plt.title(\"predict:\"+submission.loc[i,\"Label\"].astype(\"str\"))\n        plt.axis(\"off\")\n        plt.imshow(np.reshape(test_X[i], (28,28)), cmap=plt.cm.binary)\n           \n    plt.show()\n\n","160a5f56":"show_test_digits(range(500,530))","ea71efd3":"### Early Stop","2d4a972b":"### Take a look at train data","a9509070":"### Import necessaries","ff0aa06c":"### Save Models","6d1fd408":"### Numbers distribution","92c3b049":"### New","3605dc45":"### Create 10 CNN Models","9062a20b":"Looks good)\n### Consider upvoting if it was helpful! \ud83d\ude03","2f7fdbd8":"### Normalize Data","6d327c70":"### Let's see the result","0bd61c0b":"### Data Augmentation","32d5446c":"### Building a Sequential Model","3b248d99":"## Ensemble  CNN"}}