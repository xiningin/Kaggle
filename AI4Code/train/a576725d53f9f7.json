{"cell_type":{"e50f0bd8":"code","7ede8ce1":"code","588284f8":"code","c3e3046c":"code","ec9fa249":"code","33d08861":"code","f15a524d":"code","1b123bba":"code","5c94a954":"code","c080377d":"code","19a83871":"code","aae7258f":"code","54d1db65":"code","fb93a6d2":"code","74157d1b":"code","9cdd5c29":"code","61674f16":"code","ca56738a":"code","f18aa14c":"code","935de180":"code","99f27821":"code","960ed400":"code","49e71e44":"code","2f11579a":"code","f7b595be":"code","6dd84fa1":"code","ba628668":"code","5c3a3354":"code","97e0c0b7":"code","b2c11b67":"code","b3afac6e":"code","9bf1c8dd":"code","77dba4ec":"code","dd5160e6":"code","a187a515":"code","8b17f4e4":"code","da42c352":"code","765b40e8":"code","9a81b2e3":"code","91537b78":"code","5b2d0102":"code","f9da141b":"code","f4078ad9":"code","5e23fea2":"code","154ccb97":"code","2d0344d4":"code","1aa35754":"code","3ccb000c":"code","30d813e0":"code","7d4276c1":"code","372be6c9":"code","b49f7a06":"code","5539aa62":"code","14b3ac99":"code","a694209d":"code","426d6a14":"code","a470a68c":"code","d9cf2c7b":"code","bd5db828":"code","88862328":"code","5fe8a3f3":"code","3279525c":"code","ce6a05cb":"code","e2c09b04":"code","8351aded":"code","25961600":"code","0ed2a7d5":"code","232fc963":"code","49bd3861":"code","b00a681d":"code","691cad58":"code","b1413945":"code","2c180ac9":"code","0c5f3d7f":"code","3d3ebe01":"code","f5f3c37b":"code","25b1c4a0":"code","fefd7b77":"code","ed7b6239":"code","771f1f86":"code","f279a76b":"code","e3c6a203":"markdown","25678798":"markdown","6a1e9ae1":"markdown","fa80578d":"markdown","697b8cee":"markdown","16badecf":"markdown","4f29ae67":"markdown","ef7f8dd1":"markdown","8c3dba8f":"markdown","c45dd374":"markdown","90da8707":"markdown","19835a1e":"markdown","8f810010":"markdown","42a23992":"markdown","a365d5e6":"markdown","38b7fde8":"markdown","0f10de38":"markdown","cdbbe043":"markdown","dec1a226":"markdown","77103f5b":"markdown","054f56ac":"markdown","3af9109c":"markdown","9369dfa7":"markdown","add76118":"markdown","f1b83f12":"markdown","53fa8330":"markdown","893d5391":"markdown","1ae49040":"markdown","2bcaf30b":"markdown","86fe1526":"markdown","eb6c71dd":"markdown","e5207f6b":"markdown","1c9c2d65":"markdown","b1b74a53":"markdown","0904733c":"markdown","353b56f3":"markdown","72394333":"markdown","48a4d22f":"markdown","eff96fd2":"markdown","49f14148":"markdown","ac5e4618":"markdown","78a757fb":"markdown","a6b43111":"markdown","a2f41af6":"markdown","e4c4a419":"markdown"},"source":{"e50f0bd8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\n\nfrom math import sqrt\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom mlxtend.regressor import StackingRegressor\n\nfrom sklearn.externals import joblib","7ede8ce1":"df = pd.read_csv('..\/input\/train.csv')","588284f8":"df.shape","c3e3046c":"df.columns","ec9fa249":"df.head(10)","33d08861":"df.dtypes[df.dtypes == 'object']","f15a524d":"df.isnull().sum()","1b123bba":"df.info()","5c94a954":"df.describe()","c080377d":"df.describe(include = ['object'])","19a83871":"df.sort_values('TIMESTAMP',inplace = True)","aae7258f":"df.head()","54d1db65":"df['year'] = df['TIMESTAMP'].apply(lambda x :datetime.datetime.fromtimestamp(x).year) \ndf['month'] = df['TIMESTAMP'].apply(lambda x :datetime.datetime.fromtimestamp(x).month) \ndf['month_day'] = df['TIMESTAMP'].apply(lambda x :datetime.datetime.fromtimestamp(x).day) \ndf['hour'] = df['TIMESTAMP'].apply(lambda x :datetime.datetime.fromtimestamp(x).hour) \ndf['week_day'] = df['TIMESTAMP'].apply(lambda x :datetime.datetime.fromtimestamp(x).weekday()) ","fb93a6d2":"df.head()","74157d1b":"plt.figure(figsize = (10,10))\nplt.pie(df['year'].value_counts(), labels = df['year'].value_counts().keys(),autopct = '%.1f%%')","9cdd5c29":"plt.figure(figsize = (5,5))\nplt.title('Count of trips per day of week')\nsns.countplot(y = 'week_day', data = df)\nplt.xlabel('Count')\nplt.ylabel('Day')","61674f16":"plt.figure(figsize = (10,10))\nplt.title('Count of trips per month')\nsns.countplot(y = 'month', data = df)\nplt.xlabel('Count')\nplt.ylabel('Month')","ca56738a":"plt.figure(figsize = (10,10))\nplt.title('Count of trips per hour')\nsns.countplot(y = 'hour', data = df)\nplt.xlabel('Count')\nplt.ylabel('Hours')","f18aa14c":"df['MISSING_DATA'].value_counts()","935de180":"df.drop(df[df['MISSING_DATA'] == True].index, inplace = True)","99f27821":"df['MISSING_DATA'].unique()","960ed400":"df[df['POLYLINE'] =='[]']['POLYLINE'].value_counts()","49e71e44":"df.drop(df[df['POLYLINE'] =='[]']['POLYLINE'].index, inplace = True)","2f11579a":"df[df['POLYLINE'] =='[]']['POLYLINE'].value_counts()","f7b595be":"df['Polyline Length'] = df['POLYLINE'].apply(lambda x : len(eval(x))-1)","6dd84fa1":"df['Trip Time(sec)'] = df['Polyline Length'].apply(lambda x : x * 15)","ba628668":"df.head()","5c3a3354":"df['Trip Time(sec)'].describe()","97e0c0b7":"df.groupby('week_day').mean()","b2c11b67":"df['DAY_TYPE'].isnull().sum()","b3afac6e":"df = pd.get_dummies(df, columns=['CALL_TYPE'])","9bf1c8dd":"df.shape","77dba4ec":"df = df.drop_duplicates()\nprint(df.shape)","dd5160e6":"df.to_csv('Cleaned_data.csv', index = None)","a187a515":"df = df.iloc[:50000]","8b17f4e4":"df.shape","da42c352":"X = df[['Polyline Length', 'CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C']]\ny = df['Trip Time(sec)']","765b40e8":"s = StandardScaler()\nX = s.fit_transform(X)","9a81b2e3":"print(np.mean(X))\nnp.std(X)","91537b78":"X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.3)","5b2d0102":"print(\"The size of training input is\", X_train.shape)\nprint(\"The size of training output is\", y_train.shape)\nprint(50 *'*')\nprint(\"The size of testing input is\", X_test.shape)\nprint(\"The size of testing output is\", y_test.shape)","f9da141b":"y_train_pred = np.ones(X_train.shape[0]) * y_train.mean() #Predicting the train results","f4078ad9":"y_test_pred = np.ones(y_test.shape[0]) * y_train.mean() #Predicting the test results","5e23fea2":"print(\"Train Results for Baseline Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","154ccb97":"print(\"Test Results for Baseline Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","2d0344d4":"k_range  =list(range(1,30)) \nparam =dict(n_neighbors =k_range)\nknn_regressor =GridSearchCV(KNeighborsRegressor(),param,cv =10)\nknn_regressor.fit(X_train,y_train)","1aa35754":"print(knn_regressor.best_estimator_)\nknn_regressor.best_params_","3ccb000c":"y_train_pred =knn_regressor.predict(X_train) ##Predict train result\ny_test_pred =knn_regressor.predict(X_test) ##Predict test result","30d813e0":"print(\"Train Results for KNN Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","7d4276c1":"print(\"Test Results for KNN Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","372be6c9":"params ={'alpha' :[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\nridge_regressor =GridSearchCV(Ridge(), params ,cv =5,scoring = 'neg_mean_absolute_error', n_jobs =-1)\nridge_regressor.fit(X_train ,y_train)","b49f7a06":"print(ridge_regressor.best_estimator_)\nridge_regressor.best_params_","5539aa62":"y_train_pred =ridge_regressor.predict(X_train) ##Predict train result\ny_test_pred =ridge_regressor.predict(X_test) ##Predict test result","14b3ac99":"print(\"Train Results for Ridge Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","a694209d":"print(\"Test Results for Ridge Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","426d6a14":"params ={'alpha' :[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\nlasso_regressor =GridSearchCV(Lasso(), params ,cv =15,scoring = 'neg_mean_absolute_error', n_jobs =-1)\nlasso_regressor.fit(X_train ,y_train)","a470a68c":"print(lasso_regressor.best_estimator_)\nlasso_regressor.best_params_","d9cf2c7b":"y_train_pred =lasso_regressor.predict(X_train) ##Predict train result\ny_test_pred =lasso_regressor.predict(X_test) ##Predict test result","bd5db828":"print(\"Train Results for Lasso Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","88862328":"print(\"Test Results for Lasso Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","5fe8a3f3":"depth  =list(range(3,30))\nparam_grid =dict(max_depth =depth)\ntree =GridSearchCV(DecisionTreeRegressor(),param_grid,cv =10)\ntree.fit(X_train,y_train)","3279525c":"print(tree.best_estimator_)\ntree.best_params_","ce6a05cb":"y_train_pred =tree.predict(X_train) ##Predict train result\ny_test_pred =tree.predict(X_test) ##Predict test result","e2c09b04":"print(\"Train Results for Decision Tree Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","8351aded":"print(\"Test Results for Decision Tree Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","25961600":"tuned_params = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 300, 400, 500], 'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\nmodel = RandomizedSearchCV(XGBRegressor(), tuned_params, n_iter=20, scoring = 'neg_mean_absolute_error', cv=5, n_jobs=-1)\nmodel.fit(X_train, y_train)","0ed2a7d5":"print(model.best_estimator_)\nmodel.best_params_","232fc963":"y_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)","49bd3861":"print(\"Train Results for XGBoost Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","b00a681d":"print(\"Test Results for XGBoost Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","691cad58":"tuned_params = {'n_estimators': [100, 200, 300, 400, 500], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\nrandom_regressor = RandomizedSearchCV(RandomForestRegressor(), tuned_params, n_iter = 20, scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1)\nrandom_regressor.fit(X_train, y_train)","b1413945":"print(random_regressor.best_estimator_)\nrandom_regressor.best_params_","2c180ac9":"y_train_pred = random_regressor.predict(X_train)\ny_test_pred = random_regressor.predict(X_test)","0c5f3d7f":"print(\"Train Results for Random Forest Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","3d3ebe01":"print(\"Test Results for Random Forest Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","f5f3c37b":"# Initializing models\nridge = Ridge()\nlasso = Lasso()\ntree = DecisionTreeRegressor()\nknn = KNeighborsRegressor()\n\nstack = StackingRegressor(regressors = [ridge, lasso, knn], meta_regressor = tree)\nstack.fit(X_train, y_train)","25b1c4a0":"print(stack.regr_)\nstack.meta_regr_","fefd7b77":"y_train_pred = stack.predict(X_train)\ny_test_pred = stack.predict(X_test)","ed7b6239":"print(\"Train Results for Stacking Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\nprint(\"R-squared: \", r2_score(y_train.values, y_train_pred))","771f1f86":"print(\"Test Results for Stacking Regressor Model:\")\nprint(50 * '-')\nprint(\"Root mean squared error: \", sqrt(mse(y_test, y_test_pred)))\nprint(\"R-squared: \", r2_score(y_test, y_test_pred))","f279a76b":"win_model = RandomForestRegressor(n_estimators = 200, min_samples_split = 2, min_samples_leaf = 1)\nwin_model.fit(X_train, y_train)\njoblib.dump(win_model, 'winnig_model_random_forest.pkl')","e3c6a203":"\nThere are many missing values in ORIGIN_CALL and ORIGIN_STAND because may be all the taxi users have not called the via phone and they have not started their trip from taxi stand.","25678798":"In stacking method we stack many different ML models to get the better results.","6a1e9ae1":"There were 2 duplicate rows which was dropped.","fa80578d":"Filtering out categorical features.","697b8cee":"#### Data Standardization","16badecf":"#### 6. XGBoost","4f29ae67":"#### 7. Random Forest Regressor","ef7f8dd1":"#### Load the taxi trajectory data from CSV file","8c3dba8f":"\nThe 4th and 5th day of week has almost same number of trips and rest all the days have almost similar number of trips. This means that we can say each and every day of week required same number of taxies irrespective of weekend or working day.","c45dd374":"#### Data Preparation for ML models.","90da8707":"* TRIP_ID (string) : It contains an unique identifier for each trip\n* CALL_TYPE (char) :  It identifies the way used to demand this service. It may contain one of three possible values.\n                      1. 'A' : if this trip was dispatched from the central\n                      2. 'B' : if this trip was demanded directly to a taxi driver on a specific stand\n                      3. 'C' : otherwise (i.e. a trip demanded on a random street)\n* ORIGIN_CALL (integer) :  It contains an unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip\u2019s customer if CALL_TYPE=\u2019A\u2019. Otherwise, it assumes a NULL value\n* ORIGIN_STAND (integer): It contains an unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE=\u2019B\u2019. Otherwise, it assumes a NULL value\n* TAXI_ID: (integer): It contains an unique identifier for the taxi driver that performed each trip\n* TIMESTAMP (integer) : Unix Timestamp (in seconds). It identifies the trip\u2019s start\n* DAYTYPE (char) : It identifies the daytype of the trip\u2019s start. It assumes one of three possible values\n                    1. 'B' : if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.)\n                    2. 'C' : if the trip started on a day before a type-B day\n                    3. 'A' : otherwise (i.e. a normal day, workday or weekend)\n* MISSING_DATA (Boolean) : It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing.\n* POLYLINE (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string.The last list item corresponds to the trip\u2019s destination while the first one represents its start. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The POLYLINE can have multiple pairs of longitude and latitude\n\n\nThe total travel time of the trip (the prediction target) is defined as the (number of points-1) x 15 seconds. For example, a trip with 101 data points in POLYLINE has a length of (101-1) * 15 = 1500 seconds. \n\n\n\n\n##### Type of Machine Learning task : \nIt is an regression problem where given a set of features we need to predict the total travel time by taxi from starting of ride to the destination in seconds.\n                    \n                ","19835a1e":"Describing the categorical features.","8f810010":"#### Save the winnig model to disk","42a23992":"\n14th and 15th hour may be the peak hours, office time, school time because lot of taxies are used between this time.","a365d5e6":"On an average each day of week 648 to 750 seconds of journey were travelled.","38b7fde8":"## Data Overview","0f10de38":"#### We have provided with the dataset describing a complete year (from 1 july 2013 to 30 june 2014) of the trajectories for all the 442 taxies running in the city of portugal.\n#### We are hired by the transportation industry of portugal and want to predict the total travel time of the trip based on the attributes given in the datasets.","cdbbe043":"The dataset has around 171K instances each of which has 9 different feature values.","dec1a226":"#### 2. KNN Regressor","77103f5b":"\nOn an average we can say that every month has atleast 120000 taxi trips planned.","054f56ac":"We can see the DAY_TYPE has only 1 unique value and that is 'A' which means that all the trips are started on normal day or weekend. Also the 5901 observations don't have the POLYLINE values means we cannot calculate the travel time for those trips.","3af9109c":"For 10 instances the GPS data steam is not complete and there can be one or more locations missing. Such a data points wont gives us the appropriate trip time so we can drop such observations.","9369dfa7":"#### Performace Metric\nSince it is an regression problem we will use Root Mean Squared error (RMSE) and R-squared as regression metric.\n\n#### Importing Libraries","add76118":"We can see that the training RMSE error is low but testing RMSE error is high which means that model is overfitting.","f1b83f12":"#### Dropping the duplicates","53fa8330":"#### One Hot Encoding for Call Type","893d5391":"#### 5. Decision Tree Regressor","1ae49040":"Each data point corresponds to one complete trip. It contains a total 9 features","2bcaf30b":"### Machine Learning Models","86fe1526":"Above description clear that the minimum travelling time by the taxi is 15 seconds and maximum is 58200 seconds i.e.around 16 hours 16 min.","eb6c71dd":"#### Convreting a POLYLINE into the total travelling time.","e5207f6b":"Also some of the POLYLINES values are missing in which we cannot find the trip time, dropping such observations is also the good idea.","1c9c2d65":"From the above all the models that we have trained most of them are overfitted including some ensemble teachniques also. But the random forest algorithm gives pretty good results. So the random forest is the best suited model for this dataset.","b1b74a53":"#### 8. Stacking","0904733c":"#### Train and Test splits : 70-30","353b56f3":"Displying the first 10 rows.","72394333":"\nFrom the above pie chart it is clear that there are equal number of taxi trips in both the year.","48a4d22f":"#### 4. Lasso Regression","eff96fd2":"\nPie chart for the year","49f14148":"#### Saving the final dataframe for future use.","ac5e4618":"# Taxi Trajectory","78a757fb":"##### Sorting the entire dataset based on the timestamp","a6b43111":"### EDA, Data Cleaning and Feature Engineering","a2f41af6":"#### 3. Ridge Regressor","e4c4a419":"#### 1. Baseline Model\n* In baseline model the predicted trip time would be simply the average of all trip time.\n* We will use this baseline model to perform hypothesis testing for other ML complex models."}}