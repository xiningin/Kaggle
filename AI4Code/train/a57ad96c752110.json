{"cell_type":{"5553ace7":"code","87f283df":"code","7713ac5e":"code","4a90c50a":"code","f6713834":"code","5de5b760":"code","3956fa1c":"code","ab46a775":"code","b7e20497":"code","5c148372":"code","8242af69":"code","5e32ecb8":"code","79342b04":"code","da87a6ae":"code","51ce6cfb":"code","f0ed29f5":"code","ebbf84c9":"code","6e53bc78":"code","81356fbc":"code","d94baa9a":"code","1b847814":"code","be48d39a":"code","4dc52dd3":"code","b0a308d6":"code","360c566b":"code","d5738f1a":"code","bb8c876f":"code","d5bdc612":"code","e34557a2":"code","52e82665":"code","23a8172f":"code","57ef4f2d":"code","e109f3cf":"code","ed8beed1":"code","54609e96":"code","2b3300c2":"code","8a4ad5a2":"code","d8210cc7":"code","db1df58b":"code","1fa898d9":"code","fec55803":"markdown","2bace1e6":"markdown"},"source":{"5553ace7":"!python --version","87f283df":"import pkg_resources\ndists = [d for d in pkg_resources.working_set]\nprint(dists)","7713ac5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nsub=pd.read_csv(\"..\/input\/predicttheglobalspreadofcovid19\/SampleSubmission.csv\")\nsub.head()\nnew=sub['Territory X Date'].str.split(\" X \", n = 1, expand = True) \nsub[\"Country_Region\"]=new[0]\nsub[\"Date\"]=new[1]\n\n# test=pd.read_csv(\"..\/input\/covid19globalforecastingweek4\/test.csv\")\ntest = pd.read_csv('..\/input\/predicttheglobalspreadofcovid19\/new_test.csv')\ntest.head()\ntest2=test.groupby(['Province_State','Country_Region']).size().reset_index()\ntest2.columns=['Province_State','Country_Region','Count']\nsub=sub.merge(test2,how=\"left\",on=\"Country_Region\")\nsub.drop(['Count'],1,inplace=True)\nsub['Date'] = pd.to_datetime(sub['Date'], format='%m\/%d\/%y')\nsub['ForecastId']=sub.index+1\nsub.head()","4a90c50a":"%matplotlib inline\nimport pandas as pd\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\npd.set_option('display.max_columns', 99)\npd.set_option('display.max_rows', 99)\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\nimport datetime as dt\nimport xgboost as xgb\nfrom sklearn import preprocessing\nfrom scipy.stats import gmean","f6713834":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nimport seaborn as sns\nsns.set_palette(sns.color_palette('tab20', 20))\n\nimport plotly.express as px\nimport plotly.graph_objects as go","5de5b760":"\nDATA_PATH = '..\/input\/covid19-metadata'\nDATEFORMAT = '%Y-%m-%d'\n\n\ndef get_comp_data(COMP):\n    train = pd.read_csv(f'{COMP}\/train.csv')\n    test = sub.copy()#pd.read_csv(f'{COMP}\/test.csv')\n    test['Date']=test['Date'].astype(str)\n    submission = pd.read_csv(f'{COMP}\/submission.csv')\n    print(train.shape, test.shape, submission.shape)\n    train['Country_Region'] = train['Country_Region'].str.replace(',', '')\n    test['Country_Region'] = test['Country_Region'].str.replace(',', '')\n\n    train['Location'] = train['Country_Region'] + '-' + train['Province_State'].fillna('')\n\n    test['Location'] = test['Country_Region'] + '-' + test['Province_State'].fillna('')\n\n    train['LogConfirmed'] = to_log(train.ConfirmedCases)\n    train['LogFatalities'] = to_log(train.Fatalities)\n    train = train.drop(columns=['Province_State'])\n    test = test.drop(columns=['Province_State'])\n\n    country_codes = pd.read_csv(f'{DATA_PATH}\/country_codes.csv', keep_default_na=False)\n    train = train.merge(country_codes, on='Country_Region', how='left')\n    test = test.merge(country_codes, on='Country_Region', how='left')\n\n    train['DateTime'] = pd.to_datetime(train['Date'])\n    test['DateTime'] = pd.to_datetime(test['Date'])\n\n    train = train.sort_values(by='Date')\n    test = test.sort_values(by='Date')\n\n    train = train.fillna('#N\/A')\n    test = test.fillna('#N\/A')\n\n    return train, test, submission\n\n\ndef process_each_location(df):\n    dfs = []\n    for loc, df in df.groupby('Location'):\n        df = df.sort_values(by='Date')\n        df['Fatalities'] = df['Fatalities'].cummax()\n        df['ConfirmedCases'] = df['ConfirmedCases'].cummax()\n        df['LogFatalities'] = df['LogFatalities'].cummax()\n        df['LogConfirmed'] = df['LogConfirmed'].cummax()\n        df['LogConfirmedNextDay'] = df['LogConfirmed'].shift(-1)\n        df['ConfirmedNextDay'] = df['ConfirmedCases'].shift(-1)\n        df['DateNextDay'] = df['Date'].shift(-1)\n        df['LogFatalitiesNextDay'] = df['LogFatalities'].shift(-1)\n        df['FatalitiesNextDay'] = df['Fatalities'].shift(-1)\n        df['LogConfirmedDelta'] = df['LogConfirmedNextDay'] - df['LogConfirmed']\n        df['ConfirmedDelta'] = df['ConfirmedNextDay'] - df['ConfirmedCases']\n        df['LogFatalitiesDelta'] = df['LogFatalitiesNextDay'] - df['LogFatalities']\n        df['FatalitiesDelta'] = df['FatalitiesNextDay'] - df['Fatalities']\n        dfs.append(df)\n    return pd.concat(dfs)\n\n\ndef add_days(d, k):\n    return dt.datetime.strptime(d, DATEFORMAT) + dt.timedelta(days=k)\n\n\ndef to_log(x):\n    return np.log(x + 1)\n\n\ndef to_exp(x):\n    return np.exp(x) - 1\n\n\ndef create_features(train_set):\n    dfs = []\n    for loc, df in train_set.groupby('Location'):\n        df = df.sort_values(by='Date').copy()\n        df['f_lc_7d'] = df['LogConfirmed'].shift(7)\n        df['f_lf_7d'] = df['LogFatalities'].shift(7)\n        df['f_lc_3d'] = df['LogConfirmed'].shift(3)\n        df['f_lf_3d'] = df['LogFatalities'].shift(3)\n        df['f_lc_1d'] = df['LogConfirmed'].shift(1)\n        df['f_lf_1d'] = df['LogFatalities'].shift(1)\n        df['f_lc_0d'] = df['LogConfirmed']\n        df['f_lf_0d'] = df['LogFatalities']\n        df['f_fc_rate'] = np.clip((to_exp(df['LogFatalities']) + 1) \/ (to_exp(df['LogConfirmed']) + 1), 0, 0.15)\n        dfs.append(df)\n    dfs = pd.concat(dfs)\n    dfs['d_lc_7d'] = dfs['f_lc_0d'] - dfs['f_lc_7d']\n    dfs['d_lf_7d'] = dfs['f_lf_0d'] - dfs['f_lf_7d']\n    dfs['d_lc_3d'] = dfs['f_lc_3d'] - dfs['f_lc_3d']\n    dfs['d_lf_3d'] = dfs['f_lf_3d'] - dfs['f_lf_3d']\n    dfs['d_lc_1d'] = dfs['f_lc_0d'] - dfs['f_lc_1d']\n    dfs['d_lf_1d'] = dfs['f_lf_0d'] - dfs['f_lf_1d']\n    return dfs\n","3956fa1c":"\nCOMP = '..\/input\/covid19globalforecastingweek4'\nstart = dt.datetime.now()\ntrain, test, submission = get_comp_data(COMP)\ntrain.shape, test.shape, submission.shape\ntrain.head(2)\ntest.head(2)\n\nTRAIN_START = train.Date.min()\nTEST_START = test.Date.min()\nTRAIN_END = train.Date.max()\nTEST_END = test.Date.max()\nprint(TRAIN_START, TRAIN_END, TEST_START, TEST_END)","ab46a775":"train_clean = process_each_location(train)\n\nprint('train cleaned', train_clean.shape)\n\ntrain_clean = train_clean[[\n    'Location', 'Date', 'continent',\n    'LogConfirmed', 'LogFatalities',\n    'LogConfirmedDelta', 'LogFatalitiesDelta'\n]]\n\ncontinent_encoder = preprocessing.LabelEncoder()\ntrain_clean['f_continent'] = continent_encoder.fit_transform(train_clean.continent)\n\ntrain_features = create_features(train_clean)\ntrain_features.head()","b7e20497":"def predict(min_child_weight, eta, colsample_bytree, max_depth, subsample,\n           NROUND, PRECISION, DECAY, WEIGHT_NORM, MIN_DATE):\n    train, test, submission = get_comp_data(COMP)\n    train_clean = process_each_location(train)\n    print('train cleaned', train_clean.shape)\n\n    train_clean = train_clean[[\n        'Location', 'Date', 'continent',\n        'LogConfirmed', 'LogFatalities',\n        'LogConfirmedDelta', 'LogFatalitiesDelta'\n    ]]\n\n    continent_encoder = preprocessing.LabelEncoder()\n    train_clean['f_continent'] = continent_encoder.fit_transform(train_clean.continent)\n\n    train_features = create_features(train_clean)\n\n    VALID_CUTOFF = TRAIN_END\n\n    features = [\n        'f_lc_7d', 'f_lf_7d', 'f_lc_3d', 'f_lf_3d', 'f_continent',\n        'f_lc_1d', 'f_lf_1d', 'f_lc_0d', 'f_lf_0d', 'f_fc_rate'\n    ]\n    diff_features = ['d_lc_7d', 'd_lf_7d', 'd_lc_3d', 'd_lf_3d', 'd_lc_1d', 'd_lf_1d']\n    features = features + diff_features\n    print(f'{len(features)} features: ')\n    print(features)\n    \n    fix = {\n    'lambda': 1., 'nthread': 3, 'booster': 'gbtree',\n    'silent': 1, 'eval_metric': 'rmse',\n    'objective': 'reg:squarederror'}\n    config = dict(\n        min_child_weight=min_child_weight,\n        eta=eta, colsample_bytree=colsample_bytree,\n        max_depth=max_depth, subsample=subsample)\n    config.update(fix)\n\n    Xtr = train_features[(train_features.Date >= MIN_DATE) & (train_features.Date < VALID_CUTOFF)].copy()\n    Xtr['days'] = -(pd.to_datetime(train_features.Date) - dt.datetime.strptime(VALID_CUTOFF, DATEFORMAT)).dt.days\n    \n    print(Xtr.shape)\n    print(config)\n    print(PRECISION, NROUND, DECAY, WEIGHT_NORM)\n\n    def weighting(days):\n        return 1. \/ days ** WEIGHT_NORM\n\n    dtrain_lc = xgb.DMatrix(Xtr[features].round(PRECISION), label=Xtr.LogConfirmedDelta, weight=weighting(Xtr.days))\n    dtrain_lf = xgb.DMatrix(Xtr[features].round(PRECISION), label=Xtr.LogFatalitiesDelta, weight=weighting(Xtr.days))\n\n    model_lc = xgb.train(config, dtrain_lc, NROUND, evals=[(dtrain_lc, 'train-lc')], verbose_eval=100)\n    model_lf = xgb.train(config, dtrain_lf, NROUND, evals=[(dtrain_lf, 'train-lf')], verbose_eval=100)\n\n    # Predict\n\n    predictions = Xtr.copy()\n    predictions = train_features[(train_features.Date >= MIN_DATE) & (train_features.Date <= VALID_CUTOFF)].copy()\n    predictions.LogConfirmedDelta = np.nan\n    predictions.LogFatalitiesDelta = np.nan\n\n    for i, d in enumerate(pd.date_range(VALID_CUTOFF, add_days(TEST_END, 1))):\n        last_day = str(d).split(' ')[0]\n        next_day = dt.datetime.strptime(last_day, DATEFORMAT) + dt.timedelta(days=1)\n        next_day = next_day.strftime(DATEFORMAT)\n\n        p_next_day = predictions[predictions.Date == last_day].copy()\n        p_next_day.Date = next_day\n        p_next_day['plc'] = model_lc.predict(xgb.DMatrix(p_next_day[features].round(PRECISION)))\n        p_next_day['plf'] = model_lf.predict(xgb.DMatrix(p_next_day[features].round(PRECISION)))\n\n        p_next_day.LogConfirmed = p_next_day.LogConfirmed + np.clip(p_next_day['plc'], 0, None) * DECAY ** i\n        p_next_day.LogFatalities = p_next_day.LogFatalities + np.clip(p_next_day['plf'], 0, None) * DECAY ** i\n\n        predictions = pd.concat([predictions, p_next_day], sort=True)\n        predictions = create_features(predictions)\n\n    predictions['PC'] = to_exp(predictions.LogConfirmed)\n    predictions['PF'] = to_exp(predictions.LogFatalities)\n    return predictions","5c148372":"decay = 0.99\nprediction_1 = predict(min_child_weight=5, eta=0.01, colsample_bytree=0.8, max_depth=5, subsample=0.9,\n           NROUND=800, PRECISION=2, DECAY=decay, WEIGHT_NORM=0.25, MIN_DATE='2020-03-22')\nprediction_2 = predict(min_child_weight=7, eta=0.01, colsample_bytree=0.7, max_depth=6, subsample=0.8,\n           NROUND=1000, PRECISION=2, DECAY=decay, WEIGHT_NORM=0.23, MIN_DATE='2020-03-15')\nprediction_3 = predict(min_child_weight=3, eta=0.01, colsample_bytree=0.6, max_depth=7, subsample=0.7,\n           NROUND=1200, PRECISION=2, DECAY=decay, WEIGHT_NORM=0.2, MIN_DATE='2020-03-08')\nprediction_4 = predict(min_child_weight=3, eta=0.011, colsample_bytree=0.75, max_depth=10, subsample=0.6,\n           NROUND=1200, PRECISION=3, DECAY=decay, WEIGHT_NORM=0.15, MIN_DATE='2020-03-15')\nprediction_5 = predict(min_child_weight=10, eta=0.008, colsample_bytree=0.75, max_depth=10, subsample=0.6,\n           NROUND=1500, PRECISION=3, DECAY=decay, WEIGHT_NORM=0.2, MIN_DATE='2020-03-22')\nprediction_6 = predict(min_child_weight=20, eta=0.01, colsample_bytree=0.7, max_depth=5, subsample=0.85,\n           NROUND=1000, PRECISION=3, DECAY=decay, WEIGHT_NORM=0.3, MIN_DATE='2020-03-22')","8242af69":"cols = ['Location', 'Date', 'PC', 'PF']\np12 = pd.merge(prediction_1[cols], prediction_2[cols], on=['Location', 'Date'], suffixes=['_1', '_2'])\np34 = pd.merge(prediction_3[cols], prediction_4[cols], on=['Location', 'Date'], suffixes=['_3', '_4'])\np56 = pd.merge(prediction_5[cols], prediction_6[cols], on=['Location', 'Date'], suffixes=['_5', '_6'])\n\npreds = pd.merge(p12, p34, on=['Location', 'Date'])\npreds = pd.merge(preds, p56, on=['Location', 'Date'])\npreds.head()\n\nc = preds.loc[preds.Date >= '2020-04-15'].corr()\nc\nfig = px.imshow(c)\nfig.show()","5e32ecb8":"pcs = ['PC_1', 'PC_2', 'PC_3', 'PC_4', 'PC_5', 'PC_6']\npfs = ['PF_1', 'PF_2', 'PF_3', 'PF_4', 'PF_5', 'PF_6']\npreds['PC'] = to_exp(to_log(preds[pcs]).mean(axis=1))\npreds['PF'] = to_exp(to_log(preds[pfs]).mean(axis=1))\npreds.tail()","79342b04":"top_locations = preds[preds.Date == TRAIN_END].sort_values(by='PF', ascending=False).Location.values[:25]\nfig3 = px.line(preds[preds.Location.isin(top_locations)],\n               x='Date', y='PC', color='Location')\n_ = fig3.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'COVID-19 Predicted Cumulative Confirmed Cases by Location [Updated: {TRAIN_END}]'\n)\nfig3.show()","da87a6ae":"top_locations = preds[preds.Date == TRAIN_END].sort_values(by='PF', ascending=False).Location.values[:25]\nfig3 = px.line(preds[preds.Location.isin(top_locations)],\n               x='Date', y='PF', color='Location')\n_ = fig3.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'COVID-19 Predicted Cumulative Deaths by Location [Updated: {TRAIN_END}]'\n)\nfig3.show()","51ce6cfb":"total = preds.groupby('Date')[['PC', 'PF'] + pcs + pfs].sum().reset_index()\ntotal.tail()\nfig2 = px.line(pd.melt(total, id_vars=['Date']), x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'COVID-19 Cumulative Prediction Total [Updated: {TRAIN_END}]'\n)\nfig2.show()","f0ed29f5":"my_submission = test.copy()\nmy_submission = my_submission.merge(preds)\nmy_submission['ConfirmedCases'] = my_submission['PC']\nmy_submission['Fatalities'] = my_submission['PF']\nmy_submission.shape\nmy_submission.head()","ebbf84c9":"my_submission[['ForecastId', 'ConfirmedCases', 'Fatalities']].to_csv('submission.csv', index=False)\nmy_submission.groupby('Date')[['ConfirmedCases', 'Fatalities']].sum().reset_index().tail()","6e53bc78":"end = dt.datetime.now()\nprint('Finished', end, (end - start).seconds, 's')","81356fbc":"my_submission['target']=my_submission['Fatalities'].fillna(0)\nmy_submission.sort_values(by='Territory X Date',inplace=True)\nmy_submission[['Territory X Date','target']].to_csv(\"submission_beluga.csv\",index=False)\nmy_submission[['Territory X Date','target']].tail()","d94baa9a":"my_submission[['Territory X Date','target']].head()","1b847814":"sub=pd.read_csv(\"submission.csv\")\nsub.head()","be48d39a":"test = pd.read_csv('..\/input\/predicttheglobalspreadofcovid19\/new_test.csv')\ntest=test.merge(sub,on=\"ForecastId\",how=\"left\")\ntest.to_csv('submissionBELUGA.csv', index=None)\ntest.head()","4dc52dd3":"best=pd.read_csv(\"submissionBELUGA.csv\")\nbest['Country_Region'].value_counts()","b0a308d6":"sub=pd.read_csv(\"..\/input\/predicttheglobalspreadofcovid19\/SampleSubmission.csv\")\nsub.shape","360c566b":"new=sub['Territory X Date'].str.split(\" X \", n = 1, expand = True) \nsub[\"Country_Region\"]=new[0]\nsub[\"Date\"]=new[1]\nsub['Date'] = pd.to_datetime(sub['Date'], format='%m\/%d\/%y')\nsub['Date']= sub['Date'].astype(str)\nprint(sub.shape)\nsub.head()","d5738f1a":"print(best.shape)\nbest.head()","bb8c876f":"best2=best.groupby(['Country_Region','Date'])['Fatalities'].sum().reset_index()\nbest2.loc[best2['Country_Region']==\"US\",'Country_Region']=\"United States of America (the)\"\nbest2.loc[best2['Country_Region']==\"Russia\",'Country_Region']=\"Russian Federation (the)\"\nbest2.loc[best2['Country_Region']==\"United Kingdom\",'Country_Region']=\"United Kingdom of Great Britain and Northern Ireland (the)\"\nbest2.loc[best2['Country_Region']==\"Iran\",'Country_Region']=\"Iran (Islamic Republic of)\"\nbest2.loc[best2['Country_Region']==\"Venezuela\",'Country_Region']=\"Venezuela (Bolivarian Republic of)\"\nbest2.loc[best2['Country_Region']==\"United Arab Emirates\",'Country_Region']=\"United Arab Emirates (the)\"\nbest2.loc[best2['Country_Region']==\"Gambia\",'Country_Region']=\"Gambia (the)\"\nbest2.loc[best2['Country_Region']==\"Netherlands\",'Country_Region']=\"Netherlands (the)\"\nbest2.loc[best2['Country_Region']==\"Niger\",'Country_Region']=\"Niger (the)\"\nbest2.loc[best2['Country_Region']==\"Tanzania\",'Country_Region']=\"United Republic of Tanzania (the)\"\nbest2.loc[best2['Country_Region']==\"Vietnam\",'Country_Region']=\"Viet Nam\"\nbest2.loc[best2['Country_Region']==\"Bahamas\",'Country_Region']=\"Bahamas (the)\"\nbest2.loc[best2['Country_Region']==\"Bolivia\",'Country_Region']=\"Bolivia (Plurinational State of)\"\nbest2.loc[best2['Country_Region']==\"Central African Republic\",'Country_Region']=\"Central African Republic (the)\"\nbest2.loc[best2['Country_Region']==\"Congo\",'Country_Region']=\"Congo (the)\"\nbest2.loc[best2['Country_Region']==\"Comoros\",'Country_Region']=\"Comoros (the)\"\nbest2.loc[best2['Country_Region']==\"Korea, South\",'Country_Region']=\"Republic of Korea (the)\"\nbest2.loc[best2['Country_Region']==\"Democratic Republic of the Congo\",'Country_Region']=\"Democratic Republic of the Congo (the)\"\nbest2.loc[best2['Country_Region']==\"Dominican Republic\",'Country_Region']=\"Dominican Republic (the)\"\nbest2.loc[best2['Country_Region']==\"Moldova\",'Country_Region']=\"Republic of Moldova (the)\"\nbest2.loc[best2['Country_Region']==\"Sudan\",'Country_Region']=\"Sudan (the)\"\nbest2.loc[best2['Country_Region']==\"Syria\",'Country_Region']=\"Syrian Arab Republic (the)\"\nbest2.loc[best2['Country_Region']==\"Philippines\",'Country_Region']=\"Philippines (the)\"\nbest2.loc[best2['Country_Region']==\"Congo (Kinshasa)\",'Country_Region']=\"Democratic Republic of the Congo (the)\"\nbest2.loc[best2['Country_Region']==\"Congo (Brazzaville)\",'Country_Region']=\"Congo (the)\"\nbest2.loc[best2['Country_Region']==\"Cote d'Ivoire\",'Country_Region']=\"C\u00f4te d'Ivoire\"\nbest2.loc[best2['Country_Region']==\"Laos\",'Country_Region']=\"Lao People's Democratic Republic (the)\"\nsub=sub.merge(best2,how=\"left\",on=['Country_Region','Date'])\nsub['target']=sub['Fatalities'].fillna(0)\nprint(sub.shape)\nsub.head()","d5bdc612":"sub[['Territory X Date','target']].to_csv(\"ma20200417_beluga.csv\",index=False)\nprint(sub[['Territory X Date','target']].shape)\nsub[['Territory X Date','target']].head()","e34557a2":"a=sub.groupby(['Date'])['Fatalities'].sum().reset_index()\na[30:50]","52e82665":"# sub1=pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/submission.csv\")\n# print(sub1.shape)\n# sub2=pd.read_csv(\"..\/input\/covid19globalforecastingweek4\/submission.csv\")\n# print(sub2.shape)\n# train=pd.read_csv(\"..\/input\/covid19globalforecastingweek4\/train.csv\")\n# print(train.shape)\n# train.head()","23a8172f":"# test=pd.read_csv(\"..\/input\/covid19globalforecastingweek4\/test.csv\")\n# print(test.shape)\n# test.head()","57ef4f2d":"# best=pd.read_csv(\"submission_beluga.csv\")\n# print(best.shape)\n# best.head()","e109f3cf":"# best=pd.read_csv(\"submission.csv\")\n# print(best.shape)\n# best.head()","ed8beed1":"# best=best.merge(test,how=\"left\",on=\"ForecastId\")\n# print(best.shape)\n# best.head()","54609e96":"# sub=pd.read_csv(\"..\/input\/predicttheglobalspreadofcovid19\/SampleSubmission.csv\")\n# print(sub.shape)\n# sub.head()","2b3300c2":"# new=sub['Territory X Date'].str.split(\" X \", n = 1, expand = True) \n# sub[\"Country_Region\"]=new[0]\n# sub[\"Date\"]=new[1]\n# sub['Date'] = pd.to_datetime(sub['Date'], format='%m\/%d\/%y')\n# sub['Date']= sub['Date'].astype(str)\n# sub.head()\n","8a4ad5a2":"# best2=best.groupby(['Country_Region','Date'])['Fatalities'].sum().reset_index()\n# best2.loc[best2['Country_Region']==\"US\",'Country_Region']=\"United States of America (the)\"\n# best2.loc[best2['Country_Region']==\"Russia\",'Country_Region']=\"Russian Federation (the)\"\n# best2.loc[best2['Country_Region']==\"United Kingdom\",'Country_Region']=\"United Kingdom of Great Britain and Northern Ireland (the)\"\n# best2.loc[best2['Country_Region']==\"Iran\",'Country_Region']=\"Iran (Islamic Republic of)\"\n# best2.loc[best2['Country_Region']==\"Venezuela\",'Country_Region']=\"Venezuela (Bolivarian Republic of)\"\n# best2.loc[best2['Country_Region']==\"United Arab Emirates\",'Country_Region']=\"United Arab Emirates (the)\"\n# best2.loc[best2['Country_Region']==\"Gambia\",'Country_Region']=\"Gambia (the)\"\n# best2.loc[best2['Country_Region']==\"Netherlands\",'Country_Region']=\"Netherlands (the)\"\n# best2.loc[best2['Country_Region']==\"Niger\",'Country_Region']=\"Niger (the)\"\n# best2.loc[best2['Country_Region']==\"Tanzania\",'Country_Region']=\"United Republic of Tanzania (the)\"\n# best2.loc[best2['Country_Region']==\"Vietnam\",'Country_Region']=\"Viet Nam\"\n# best2.loc[best2['Country_Region']==\"Bahamas\",'Country_Region']=\"Bahamas (the)\"\n# best2.loc[best2['Country_Region']==\"Bolivia\",'Country_Region']=\"Bolivia (Plurinational State of)\"\n# best2.loc[best2['Country_Region']==\"Central African Republic\",'Country_Region']=\"Central African Republic (the)\"\n# best2.loc[best2['Country_Region']==\"Congo\",'Country_Region']=\"Congo (the)\"\n# best2.loc[best2['Country_Region']==\"Comoros\",'Country_Region']=\"Comoros (the)\"\n# best2.loc[best2['Country_Region']==\"Korea, South\",'Country_Region']=\"Republic of Korea (the)\"\n# best2.loc[best2['Country_Region']==\"Democratic Republic of the Congo\",'Country_Region']=\"Democratic Republic of the Congo (the)\"\n# best2.loc[best2['Country_Region']==\"Dominican Republic\",'Country_Region']=\"Dominican Republic (the)\"\n# best2.loc[best2['Country_Region']==\"Moldova\",'Country_Region']=\"Republic of Moldova (the)\"\n# best2.loc[best2['Country_Region']==\"Sudan\",'Country_Region']=\"Sudan (the)\"\n# best2.loc[best2['Country_Region']==\"Syria\",'Country_Region']=\"Syrian Arab Republic (the)\"\n# best2.head()","d8210cc7":"# sub=sub.merge(best2,how=\"left\",on=['Country_Region','Date'])\n# sub['target']=sub['Fatalities'].fillna(0)\n# sub[['Territory X Date','target']].to_csv(\"ma20200417_beluga.csv\",index=False)\n# sub[['Territory X Date','target']].head()","db1df58b":"# print(sub[['Territory X Date','target']].shape)","1fa898d9":"# sub[['Territory X Date','target']].tail()","fec55803":"## Create submission","2bace1e6":"### Zindi Format"}}