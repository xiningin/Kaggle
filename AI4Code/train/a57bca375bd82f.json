{"cell_type":{"3319ab66":"code","3e17ee8f":"code","bc9fcc13":"code","90d7203d":"code","66141bc9":"code","e6212c5c":"code","86cbf07e":"code","0aaeb345":"code","808743c9":"code","46922eba":"code","a59d9e3a":"code","f347680e":"code","e5eae16a":"code","c34cc532":"code","4cd13e00":"code","1d143c54":"code","5c56acd4":"code","7ff982d7":"code","d5461af8":"code","dc653c3d":"code","1c13f61b":"code","a96611e9":"code","3ca97314":"code","f65fe745":"code","2dcdb238":"code","afbccbee":"code","66b9ebec":"code","46255874":"code","7b916265":"code","d00155fe":"markdown","3c2af6f3":"markdown","25d40e90":"markdown","00c93293":"markdown","0cdfe402":"markdown","42b7844a":"markdown","34dceec2":"markdown","9cd118e6":"markdown","f3b23429":"markdown","1a02784c":"markdown","3e249b9a":"markdown","70645d83":"markdown","e40980ae":"markdown","e62ed5ab":"markdown","581e5fab":"markdown","59ee36e2":"markdown","eb3e8716":"markdown","3423129a":"markdown","31d2e48f":"markdown"},"source":{"3319ab66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e17ee8f":"df=pd.read_csv('..\/input\/gender-classification\/Transformed Data Set - Sheet1.csv')","bc9fcc13":"df.head()","90d7203d":"df.isnull().sum()","66141bc9":"df.info()","e6212c5c":"import matplotlib.pyplot as plt\nimport seaborn as sns","86cbf07e":"\nfig, axes = plt.subplots(nrows=5, ncols=1, figsize=(10,18))\nfor i in range(len(df.columns)):\n    sns.countplot(data=df, x=df.iloc[:,i],ax=axes[i])\n    ","0aaeb345":"len(df)","808743c9":"X=df.drop('Gender',axis=1)\ny=df['Gender']","46922eba":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","a59d9e3a":"cols=list(X.columns)","f347680e":"cols","e5eae16a":"from sklearn.preprocessing import OneHotEncoder\nonehot= OneHotEncoder()\nfrom sklearn.compose import ColumnTransformer\nclt = ColumnTransformer([('binarize',onehot,cols)], remainder='passthrough')","c34cc532":"X_train=clt.fit_transform(X_train)","4cd13e00":"X_test=clt.transform(X_test)","1d143c54":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\ntest_score=[]\nfor i in range(1,30):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    y_hat=knn.predict(X_test)\n    score= 1-accuracy_score(y_test,y_hat)\n    test_score.append(score)","5c56acd4":"plt.plot(test_score)","7ff982d7":"knn.get_params()","d5461af8":"from sklearn.model_selection import GridSearchCV\nn_val=list(range(1,40))\nparam_grid={'n_neighbors':n_val}\nmodel = GridSearchCV(knn,param_grid=param_grid, cv=10, scoring='accuracy')","dc653c3d":"model.fit(X_train,y_train)","1c13f61b":"model.best_estimator_.get_params()","a96611e9":"grid_cv_predict = model.predict(X_test)","3ca97314":"accuracy_score(y_test,grid_cv_predict)","f65fe745":"plt.figure(figsize=(18,10))\npd.DataFrame(model.cv_results_)['mean_test_score'].plot()\nplt.title('Mean Test score using KNN')","2dcdb238":"from sklearn.linear_model import LogisticRegressionCV\nlogit = LogisticRegressionCV()\nlogit.fit(X_train,y_train)","afbccbee":"Logit_pred=model.predict(X_test)\naccuracy_score(y_test,Logit_pred)","66b9ebec":"from sklearn.svm import SVC\nsvc =SVC()\nsvc.fit(X_train,y_train)\npred_svc = svc.predict(X_test)\naccuracy_score(y_test,pred_svc)","46255874":"print(classification_report(y_test,pred_svc))","7b916265":"sns.heatmap(confusion_matrix(y_test,pred_svc), annot=True)","d00155fe":"# KNN with GridSearchCV","3c2af6f3":"Best Parameters in KNN using GridSearchCV","25d40e90":"# Read Data","00c93293":"How ever the Accuracy score for the model is 54%, so lets try with different models","0cdfe402":"Accuracy score is better compared to other 2 models. ","42b7844a":"Lets us first evaluate with KNeighboutClassifier with different n_neighbour values","34dceec2":"Lets do the crossvalidation using GridSearchCV with KNN","9cd118e6":"# Encode categorical values","f3b23429":"all 4 features are object type and there is no null values in the data set. so we need to go with onehot encoding to convert the categorical values.","1a02784c":"Plot all columns using SNS countplot.","3e249b9a":"# Conclusion\nReason for the low accuracy:\n1. Dataset is small - 66 rows\n2. we splited the data set with Test & Train datasets.","70645d83":"# Initial Data Analysis","e40980ae":"We are getting the same values as KNN","e62ed5ab":"# KNeighboursClassifier","581e5fab":"# Logistic Regression - Cross Validation","59ee36e2":"# # Support Vector Machine - Classification","eb3e8716":"# Importing plotting libraries","3423129a":"# Train Test Split","31d2e48f":"# Creating model & metrics"}}