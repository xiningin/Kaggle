{"cell_type":{"58fd59a1":"code","fc760584":"code","d20a093d":"code","21e9d0f9":"code","1a29aa3c":"code","d1bc383d":"code","db780f5c":"code","e6c26590":"code","d9aa3277":"code","1150065c":"code","b7e71404":"code","badb4051":"code","3ab128ef":"code","fc376961":"code","c26043e1":"code","77c29032":"code","5a013eb6":"code","458db2ab":"code","642cc57b":"markdown","258981c9":"markdown","86745213":"markdown","003c9332":"markdown","e26fb524":"markdown","27a5dc58":"markdown","9149ab77":"markdown","96beb199":"markdown","3173edd4":"markdown"},"source":{"58fd59a1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\n\nfrom collections import defaultdict\n\n\nfrom sklearn import datasets\nfrom sklearn.datasets import make_blobs\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os, cv2, json\n\n\nnp.random.seed(42)","fc760584":"WORK_DIR='..\/input\/spectf\/'\nos.listdir(WORK_DIR)","d20a093d":"test=pd.read_csv(os.path.join(WORK_DIR,\"SPECTF_test.csv\"))\ntest","21e9d0f9":"target_values = test['Class'].copy()\ntest.drop('Class', axis=1, inplace=True, errors=\"ignore\")\n","1a29aa3c":"target_values","d1bc383d":"test","db780f5c":"X=test\ny=target_values","e6c26590":"clusters=len(np.unique(y))","d9aa3277":"clusters","1150065c":"X=X.values","b7e71404":"def euclidean_dis(x1, x2):\n    return np.sqrt(np.sum((x1 - x2)**2))","badb4051":"class KMeans:\n    \n    def __init__(self,data,k,max_ite):\n        self.data=data\n        self.k=k\n        self.max_ite=max_ite\n        \n    def predict(self):\n\n        centroids = defaultdict(int)\n        \n        K=self.k\n        max_iter=self.max_ite\n        \n        for i in range(K):\n            centroids[i] = self.data[i]\n\n\n\n        r=0\n\n\n        for i in range(max_iter):\n            r=r+1\n            classes=defaultdict(list)\n            \n            for key in range(K):\n                classes[key]=[]\n            for datapoint in self.data:\n                distance=[]\n                for j in range(K):\n\n                    dis=euclidean_dis(datapoint,centroids[j])\n\n                    distance.append(dis)\n                mindis=min(distance)\n\n                index=distance.index(mindis)\n                classes[index].append(datapoint)\n                old_centroid=dict(centroids)\n\n            for t in range(K):\n                class_=classes[t]\n\n\n                new_centroid=np.mean(class_,axis=0)\n                centroids[t]=new_centroid\n            flg=1\n            for t in range(K):\n\n                a=centroids[t]\n                b=old_centroid[t]\n                if np.sum((a - b)\/b * 100) > 0.001:\n                    flg = 0\n\n\n\n            if flg==1:\n                break\n\n\n        return classes,centroids","3ab128ef":"kmeans=KMeans(X,clusters,10000)\n\nclasses,centroids=kmeans.predict()\n\n\nfor i in range(0,2):\n    classes[i]=np.array(classes[i]).tolist()\n    \nfor i in range(0,2):\n    print(len(classes[i]))\nprint(centroids)","fc376961":"class0=[]\nclass1=[]\n\nfor i in range(len(y)):\n\n    if y[i]=='Yes':\n        class0.append(X[i])\n    else:\n        class1.append(X[i])\nclass0=np.array(class0).tolist()\nclass1=np.array(class1).tolist()\n\n\n\n# utility function\n\ndef subset(array1,array2):\n    flg=0\n    for i in range(len(array1)):\n        if(array2==array1[i]):\n            flg=1\n            break\n    if(flg==1):\n        return True\n    else:\n        return False\n    \n\n# confusion matrix\n    \ndef confusion_matrix(a,b,classes):\n    \n    cm=[[0 for i in range(len(classes))] for i in range(len(classes))]\n\n    for element in class0:\n\n\n        if subset(classes[0],element):\n            cm[0][0]=cm[0][0]+1\n        elif subset(classes[1],element):\n            cm[0][1]=cm[0][1]+1\n\n\n\n    for element in class1:\n\n        if subset(classes[0],element):\n            cm[1][0]=cm[1][0]+1\n        elif subset(classes[1],element):\n            cm[1][1]=cm[1][1]+1\n        \n\n            \n    return cm\n\n\n# performance metrics\n            \nclass Metrics:\n    \n    def __init__(self,confusion_m):\n        self.confusion_m=confusion_m\n        self.total=np.sum(confusion_m)\n        self.diagonal=np.sum(np.diag(confusion_m))\n    \n    def accuracy(self):\n        accuracy=(self.diagonal\/self.total)\n        return accuracy\n    \n    def recall(self):\n        recall=np.diag(self.confusion_m)\/np.sum(self.confusion_m,axis=1)\n        recall=np.mean(recall)\n        return recall\n    \n    def precision(self):\n        precision=np.diag(self.confusion_m)\/np.sum(self.confusion_m,axis=0)\n        precision=np.mean(precision)\n        return precision\n    \n    def f1_score(self,precision,recall):\n        f1_score=(2*precision*recall)\/(precision+recall)\n        \n        return f1_score\n","c26043e1":"matrix=confusion_matrix(class0,class1,classes)\nperformance=Metrics(matrix)\n\naccuracy=performance.accuracy()\nrecall=performance.recall()\nprecision=performance.precision()\nf1_score=performance.f1_score(precision,recall)\n\nprint('confusion matrix is:',end='\\n')\nprint(np.array(matrix),end='\\n')\n\nprint(\"Accuracy of the model is {}\".format(accuracy*100))\nprint(\"Recall of the model is {}\".format(recall*100))\nprint(\"Precision of the model is {}\".format(precision*100))\nprint(\"F1-Score of the model is {}\".format(f1_score*100))","77c29032":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 2, init = 'k-means++', random_state = 42)\ny_k = kmeans.fit_predict(X)","5a013eb6":"y","458db2ab":"ans=0\n\nfor i,j in zip(y_k,y):\n    if i==0 and j=='No':\n        ans+=1\n    elif i==1 and j=='Yes':\n        ans+=1\n\nprint('Accuracy is: {}'.format(ans*100\/110))","642cc57b":"# confusion matrix","258981c9":"# KMeans Implementation","86745213":"# Function to calculate euclidean distance","003c9332":"# Kmeans Implementation from scratch on cardiac spectf imaging dataset","e26fb524":"# kmeans using inbuilt library","27a5dc58":"# conclusion : use inbulit library","9149ab77":"# prediction","96beb199":"> # load the dataset","3173edd4":"# performance metrics"}}