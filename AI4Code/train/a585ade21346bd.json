{"cell_type":{"3ad7e410":"code","c43f3143":"code","556063ec":"code","5681a2ac":"code","9c82f62d":"code","5add50f3":"code","3c542809":"code","662f8dab":"code","a15808f3":"code","7099fedf":"code","0017e83c":"code","6c43176d":"code","d42b55e9":"code","f70f99fa":"code","0ded5b4f":"code","eb1c6fa3":"code","fbb0808a":"code","e29d5c99":"code","45e4c60e":"code","41b946c1":"code","ff42fd7e":"markdown","a6b16cd6":"markdown","eb06f2d9":"markdown","509e408c":"markdown","78031abc":"markdown","8d0caa95":"markdown","d8afd7eb":"markdown"},"source":{"3ad7e410":"!pip install livelossplot","c43f3143":"!pip install 'tensorflow==2.1'\nfrom livelossplot.tf_keras import PlotLossesCallback\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n\nimport numpy as np\nnp.random.seed(42)\nimport warnings;warnings.simplefilter('ignore')\n%matplotlib inline\nprint('Tensorflow version:', tf.__version__)","556063ec":"train_images=pd.read_csv('..\/input\/setidataset\/train\/images.csv',header=None)\ntrain_labels=pd.read_csv('..\/input\/setidataset\/train\/labels.csv',header=None)\n\nval_images=pd.read_csv('..\/input\/setidataset\/validation\/images.csv',header=None)\nval_labels=pd.read_csv('..\/input\/setidataset\/validation\/labels.csv',header=None)","5681a2ac":"train_images.head()","9c82f62d":"train_labels.head()","5add50f3":"val_images.head()","3c542809":"val_labels.shape","662f8dab":"print(\"Training Shape: \",train_images.shape,train_labels.shape)\nprint(\"Validation Shape: \",val_images.shape,val_labels.shape)","a15808f3":"# Data Reshape That suitable for Convolutional Neural Networks\nx_train = train_images.values.reshape(3200,64,128,1)\nx_val = val_images.values.reshape(800,64,128,1)\n\ny_train=train_labels.values\ny_val=val_labels.values","7099fedf":"y_val.shape","0017e83c":"# Task:3 Training images randomely and draw them\nplt.figure(0,figsize=(12,12))\nfor i in range(1,4):\n    plt.subplot(1,3,i)\n# np.squeeze is used to delete non  useful dimension in (64,128,1) and transform the shape into (64,128) in order to fit into plt.imshow    \n    img=np.squeeze(x_train[np.random.randint(0,x_train.shape[0])])\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img,cmap='gray')","6c43176d":"# Data augmentation using ImageDataGenerator\n# An input batch of images is presented to the ImageDataGenerator.\n# The ImageDataGenerator transforms each image in the batch by a series of random translations, rotations, etc.\n# The randomly transformed batch is then returned to the calling function.\n#The ImageDataGenerator is not returning both the original data and the transformed data \u2014 the class only returns the randomly transformed data.\n# Ref:https:\/\/www.pyimagesearch.com\/2019\/07\/08\/keras-imagedatagenerator-and-data-augmentation\/\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen_train=ImageDataGenerator(horizontal_flip=True)\ndatagen_train.fit(x_train)\n\ndatagen_val=ImageDataGenerator(horizontal_flip=True)\ndatagen_val.fit(x_val)","d42b55e9":"from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint","f70f99fa":"# Initialising the CNN\nmodel = Sequential()\n# 1st Convolution\nmodel.add(Conv2D(32 , (5 , 5) , padding = \"same\" , input_shape = (64 , 128 , 1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2 , 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(64 , (5 , 5) , padding = \"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2 , 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer\nmodel.add(Dense(1024))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(4, activation=\"softmax\"))","0ded5b4f":"# Here, we have a initial learning rate that is fixed during first 5 steps and decreases exponentially afterwards\ninitial_learning_rate = 0.005\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                initial_learning_rate = initial_learning_rate,\n                decay_steps = 5,\n                decay_rate = 0.96,\n                staircase = True\n)\noptimizers = Adam(learning_rate = lr_schedule)","eb1c6fa3":"\nmodel.compile(optimizer = optimizers , loss = \"categorical_crossentropy\" , metrics = ['accuracy'])\nmodel.summary()","fbb0808a":"checkpoint = ModelCheckpoint(\"model_weight.h5\" , monitor = \"val_loss\" , save_weights_only = True,\n                            mode = \"min\" , verbose = 0)\ncallbacks = [PlotLossesCallback() , checkpoint]\n\nbatch_size = 32\n\nhistory = model.fit(\n        datagen_train.flow(x_train , y_train , batch_size = batch_size , shuffle = True),\n        steps_per_epoch = len(x_train) \/\/ batch_size,\n        validation_data = datagen_val.flow(x_val , y_val , batch_size = batch_size , shuffle = True),\n        validation_steps = len(x_val) \/\/ batch_size,\n        epochs = 15,\n        callbacks = [checkpoint]\n)","e29d5c99":"model.evaluate(x_val, y_val)","45e4c60e":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nimport seaborn as sns\n\ny_true = np.argmax(y_val, 1)\ny_pred = np.argmax(model.predict(x_val), 1)\nprint(metrics.classification_report(y_true, y_pred))\nprint(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true, y_pred))","41b946c1":"# Values of Recall from above confusion table can be seen on the diagonal below\nlabels = [\"squiggle\", \"narrowband\", \"noise\", \"narrowbanddrd\"]\n\nax= plt.subplot()\nsns.heatmap(metrics.confusion_matrix(y_true, y_pred, normalize='true'), annot=True, ax = ax, cmap=plt.cm.Blues); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);","ff42fd7e":"# Training A Model","a6b16cd6":"In this project, you will learn the basics of using Keras with TensorFlow as its backend and use it to solve an image classification problem. The data consists of 2D spectrograms of deep space radio signals collected by the Allen Telescope Array at the SETI Institute. The spectrograms will be treated as images to train an image classification model to classify the signals into one of four classes. By the end of the project, you will have built and trained a convolutional neural network from scratch using Keras to classify signals from space.\n\nThe model could be optimized using hyperparameter tuning. However, the goal of this notebook is not to build a high performing classifier, rather to show the basic steps to build an image classifier using convolutional neural network. The readers can also get the idea of\n\n* data augmentation using ImageDataGenerator, and \n* Way of saving the weights of a model at some interval which can later be used for transfer learning through 'callbacks' during fitting the model","eb06f2d9":"# Task1: Import Libraries","509e408c":"# All Done For Preprocessing Lets Make CNN Model","78031abc":"# **Buils 2D Spectogram**","8d0caa95":"# Shedule Learning Rate and Compile the Model","d8afd7eb":"# **Task:4 Now Create Data Generator For Training And Validation Data**"}}