{"cell_type":{"90413800":"code","c19be80f":"code","9ff209ec":"code","e5e5d8e1":"code","139ad9df":"code","2567d599":"code","79d0fe72":"code","c9eeccd4":"code","4d64e5ef":"code","db8b58c9":"code","b013189d":"code","35a50051":"code","b8ad47a4":"code","1b1b8098":"code","cf964750":"code","6ba3f8a4":"code","1881b90e":"code","a1c1945e":"code","3b220346":"code","bcf80cd5":"code","f5a3667f":"code","6fffe82d":"code","ae4dae26":"code","9c89db24":"code","0b6f55b9":"code","a2f76b59":"markdown","30413312":"markdown","72e2f449":"markdown","ff092cf0":"markdown","b9346f7e":"markdown","e8b6aed0":"markdown","349aad83":"markdown","9ad2adc1":"markdown","0e7eaf00":"markdown","7f9ba271":"markdown","99295702":"markdown","922587ee":"markdown","52cac404":"markdown","d0a67ac0":"markdown","c6101158":"markdown","a93a5054":"markdown","ab0bd84b":"markdown","35530066":"markdown","58ebc0a9":"markdown","3fa5e69e":"markdown","55811c6c":"markdown","0a23149a":"markdown","26056572":"markdown","5266c6d0":"markdown","51cb4ebe":"markdown","4c881877":"markdown"},"source":{"90413800":"!pip install -U lightautoml","c19be80f":"\nimport os\nimport time\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport torch\n\n\nfrom lightautoml.automl.presets.text_presets import TabularNLPAutoML\nfrom lightautoml.tasks import Task\nfrom lightautoml.report.report_deco import ReportDecoNLP","9ff209ec":"N_THREADS = 4\nN_FOLDS = 3\nRANDOM_STATE = 42\nTIMEOUT = 5 * 6 * 2 # * 5 # * 6 * 2 * 5\nTARGET_NAME = 'target'","e5e5d8e1":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","139ad9df":"train_data = pd.read_csv('..\/input\/lightautoml-course-finals\/train.csv')\ntrain_data.head()","2567d599":"%%time\n\ntrain_data.shape","79d0fe72":"%%time\n\ntest_data = pd.read_csv('..\/input\/lightautoml-course-finals\/test.csv')\ntest_data.head()","c9eeccd4":"test_data.shape","4d64e5ef":"%%time\n\nsample_sub = pd.read_csv('..\/input\/lightautoml-course-finals\/sample_submission.csv')\nsample_sub.head()","db8b58c9":"sample_sub.shape","b013189d":"for col in ['text_0', 'text_1']:\n    train_data[col] = train_data[col].map(lambda x: ' '.join(x[1:-1].split(',')))\n    test_data[col] = test_data[col].map(lambda x: ' '.join(x[1:-1].split(',')))","35a50051":"train_data['text_0'].values","b8ad47a4":"%%time\n\npseudolabels = pd.read_csv('..\/input\/lightautoml-nlp-baseline\/lightautoml_NLP_benchmark.csv')\npseudolabels.head()","1b1b8098":"test_data[TARGET_NAME] = pseudolabels[TARGET_NAME]","cf964750":"ALL_DF = pd.concat([train_data, test_data]).reset_index(drop = True)\nprint(ALL_DF.shape)","6ba3f8a4":"ALL_DF['weight'] = [1.001] * len(train_data) + [0.999] * len(test_data)","1881b90e":"def f1_metric(y_true, y_pred, sample_weight, **kwargs):\n    mask = (sample_weight > 1)\n    return f1_score(y_true[mask], (y_pred[mask] > 0.5).astype(int), **kwargs)\n\ntask = Task('binary', metric = f1_metric, greater_is_better = True)","a1c1945e":"roles = {'target': TARGET_NAME,\n         'text': ['text_0', 'text_1'],\n         'weights': 'weight' # for pseudolabelling\n         }","3b220346":"%%time \n\nautoml = TabularNLPAutoML(task = task, \n                           timeout = TIMEOUT,\n                           cpu_limit = N_THREADS,\n                           general_params = {'use_algos': [['linear_l2', 'lgb']]},\n                           reader_params = {'cv': N_FOLDS, 'n_jobs': N_THREADS, 'random_state': RANDOM_STATE},\n                           linear_pipeline_params = {'text_features': \"tfidf\"},\n                           gbm_pipeline_params = {'text_features': \"embed\"},\n                           text_params = {'lang': 'multi'}\n                          )\n\noof_pred = automl.fit_predict(ALL_DF, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))","bcf80cd5":"oof_pred_train = oof_pred.data[:len(train_data), 0]","f5a3667f":"print('OOF score: {}'.format(f1_score(train_data[TARGET_NAME].values, (oof_pred_train > 0.5).astype(int))))","6fffe82d":"best_sc = -1\nbest_w = None\nfor w in np.arange(0, 1.01, 0.01):\n    sc = f1_score(train_data[TARGET_NAME].values, (oof_pred_train > w).astype(int))\n    if sc > best_sc:\n        best_sc = sc\n        best_w = w\n        print(best_sc, round(best_w, 2))","ae4dae26":"print('Check score with optimized threshold...')\nprint('OOF score: {}'.format(f1_score(train_data[TARGET_NAME].values, (oof_pred_train > best_w).astype(int))))","9c89db24":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'\n              .format(test_pred, test_pred.shape))","0b6f55b9":"sample_sub[TARGET_NAME] = (test_pred.data[:, 0] > best_w).astype(int)\nsample_sub.to_csv('lightautoml_NLP_benchmark_with_pseudolabelling.csv', index = False)","a2f76b59":"The sample data check \ud83d\udc4d","30413312":"The test data dimension (176484, 109) \ud83d\udc4d","72e2f449":"I got strange value of Time left -12.189147472381592 secs on TIMEOUT = 30, so I changed that param to 60.  \ud83d\udc4d\nAutoml preset training completed in 225.00 seconds.\noof_pred:\narray([[0.00112443],\n       [       nan],\n       [0.00014254],\n       ...,\n       [0.10237131],\n       [0.00818292],\n       [0.04814068]], dtype=float32)\nShape = (517720, 1)\nCPU times: user 4min 1s, sys: 20 s, total: 4min 21s\nWall time: 3min 45s","ff092cf0":"In next the cell we are going to create LightAutoML model with `TabularAutoML` class - preset with default model structure like in the image below:\n\n<img src=\"https:\/\/github.com\/sberbank-ai-lab\/lightautoml-datafest-workshop\/raw\/master\/imgs\/tutorial_blackbox_pipeline.png\" alt=\"TabularAutoML preset pipeline\" style=\"width:70%;\"\/>\n\nin just several lines. Let's discuss the params we can setup:\n- `task` - the type of the ML task (the only **must have** parameter)\n- `timeout` - time limit in seconds for model to train\n- `cpu_limit` - vCPU count for model to use\n- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc. For example, we setup `n_jobs` threads for typization algo, `cv` folds and `random_state` as inside CV seed.\n- `general_params` - we use `use_algos` key to setup the model structure to work with (Linear and LGBM model on the first level and their weighted composition creation on the second). This setup is only to speedup the kernel, you can remove this `general_params` setup if you want the whole LightAutoML model to run.\n\n**Important note**: `reader_params` key is one of the YAML config keys, which is used inside `TabularAutoML` preset. [More details](https:\/\/github.com\/sberbank-ai-lab\/LightAutoML\/blob\/master\/lightautoml\/automl\/presets\/tabular_config.yml) on its structure with explanation comments can be found on the link attached. Each key from this config can be modified with user settings during preset object initialization. To get more info about different parameters setting (for example, ML algos which can be used in `general_params->use_algos`) please take a look at our [article on TowardsDataScience](https:\/\/towardsdatascience.com\/lightautoml-preset-usage-tutorial-2cce7da6f936).\n\nWe will use `ReportDeco` decorator and work with the decorated version in the same way as we do with usual one. ","b9346f7e":"Upvote is the best motivator \ud83d\udc4d","e8b6aed0":"The init steps \ud83d\udc4d","349aad83":"Now real test. \ud83d\udc4d\nPrediction for test data:\narray([[2.4130579e-05],\n       [1.1629598e-03],\n       [1.6938054e-04],\n       ...,\n       [9.7196393e-02],\n       [6.0690972e-03],\n       [3.2510236e-02]], dtype=float32)\nShape = (176484, 1)\nCPU times: user 11.8 s, sys: 1.12 s, total: 12.9 s\nWall time: 14 s","9ad2adc1":"Please do not forget to upvote \ud83d\udc4d","0e7eaf00":"The union of test and train data for pseudo labels \n(517720, 110) \ud83d\udc4d","7f9ba271":"The test data with baseline results \ud83d\udc4d","99295702":"The test data dimension (176484, 2) \ud83d\udc4d","922587ee":"The labels check \ud83d\udc4d array(['17747  23336  12816  11710  20535  16601  23603  11529  5728',\n       '6692  24519  13740  11341  15612  15623  5566  2491  15623  2491  12341  17325  5059  12963  13994  14425  13172  23746',\n       '12316  409  23785  1923  24122  6859  12932  24122  409', ...,\n       '21995  14484  10342  22710  23104  22710  12584  24204  13516  7623  9129',\n       '12782  1945',\n       '9127  20119  8978  2319  14947  10147  19094  23364  7957'],\n      dtype=object)","52cac404":"The comparision with baseline.  \ud83d\udc4d OOF score: 0.40311326873562764","d0a67ac0":"The target column role setup \ud83d\udc4d","c6101158":"The trick for separation of pseudo labels and real labels. \ud83d\udc4d","a93a5054":"The links.. \ud83d\udc4d","ab0bd84b":"The train data check \ud83d\udc4d","35530066":"The test data check \ud83d\udc4d","58ebc0a9":"Simple words spitting \ud83d\udc4d","3fa5e69e":"The train data dimension (341236, 110) \ud83d\udc4d","55811c6c":"- [Official LightAutoML github repo](https:\/\/github.com\/sberbank-ai-lab\/LightAutoML)\n- [LightAutoML documentation](https:\/\/lightautoml.readthedocs.io\/en\/latest)","0a23149a":"The NLP baseline benchmark import \ud83d\udc4d","26056572":"The trick with pseudo labels weight.  \ud83d\udc4d\n0.15756549550820753 0.0\n0.31840631749831466 0.01\n0.34906996937982726 0.02","5266c6d0":"The result saving. \ud83d\udc4d","51cb4ebe":"The constants \ud83d\udc4d","4c881877":"The Light AutoML configuration  \ud83d\udc4d"}}