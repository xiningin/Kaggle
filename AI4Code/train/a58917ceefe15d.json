{"cell_type":{"2eba0d86":"code","7dca77f1":"code","1b2d8075":"code","5f0dd023":"code","491b950f":"code","7394f8c6":"code","65ca256c":"code","f1dd579c":"code","8ba443f1":"code","353b9694":"code","da83309d":"code","bc411de2":"code","f841ab04":"code","ca940248":"code","ea347094":"code","6c78aaae":"code","49f68439":"code","ecbde30a":"code","da72266d":"code","3ba2f570":"code","5c4ade70":"code","aed06b12":"code","ca007e89":"code","db6fcdf3":"code","97f2fc6d":"code","279972bb":"code","8c22ef47":"code","6483a465":"code","de78cf11":"code","03558ba0":"code","c3934659":"code","96d4eee1":"code","19d47808":"code","5b333713":"code","a05a3380":"code","595c84ab":"code","5058b857":"code","39d631a0":"code","89231bb3":"code","1acb0a59":"code","beddbf75":"code","8b54158d":"code","711c7da7":"code","d7b5f9bf":"code","5228ced0":"code","e6a0bc5e":"code","e90bfb1e":"code","225fb4e6":"code","88bd19f3":"code","87a81082":"code","44b3b96f":"code","0785ba68":"code","e9f5b509":"code","df27a9cb":"code","a0ea174b":"code","72200352":"code","d8ac38a7":"code","b3fdc1e4":"code","ea400225":"markdown","e57361c2":"markdown","a2967dbc":"markdown","21dea730":"markdown","66890eeb":"markdown","2dc4cc4d":"markdown","44520a88":"markdown","35c9f8ab":"markdown","05dfd312":"markdown","f25a02f5":"markdown","4f8af254":"markdown","b6fbc966":"markdown","549881c2":"markdown","7ede2144":"markdown","17bdb9fa":"markdown","3efd42cf":"markdown","f6b501c2":"markdown","7639220d":"markdown","e2b9a098":"markdown","48bdd07d":"markdown","27dbe7c0":"markdown","4af1f5cf":"markdown","d56ca34d":"markdown","877a4893":"markdown","2b340255":"markdown","6e45100c":"markdown"},"source":{"2eba0d86":"# Import necessary libraries.\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Dense, \n    Dropout, \n    Flatten, \n    Conv2D, \n    MaxPooling2D, \n    MaxPool2D,\n    GlobalMaxPooling2D,\n    BatchNormalization\n)\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix","7dca77f1":"# Set the path to the dataset folder. (The dataset contains image folder: \"train\")\nbase_path = '\/content\/drive\/My Drive\/'\ntrain_path = base_path+\"data\/plant-seedlings-classification.zip\"\nextract_path = base_path+'data\/Extracted\/' # To extract the above seeding classification zip\nsave_extracted = base_path+'data\/Save\/'","1b2d8075":"from google.colab import drive\ndrive.mount('\/content\/drive')","5f0dd023":"# Make different folders for train and test data in the current directory of Google Colab notebook. (using mkdir)\n!mkdir extract_path","491b950f":"# Extract the files from dataset to temp_train and temp_test folders (as the dataset is a zip file.)\nfrom zipfile import ZipFile\nwith ZipFile(train_path, 'r') as zip:\n  zip.extractall(extract_path)","7394f8c6":"# Extract Image and Label\ndef get_data(path):\n  files = glob(path)\n\n  trainImg = []                                              # Initialize empty list to store the image data as numbers.\n  trainLabel = []                                            # Initialize empty list to store the labels of images\n  j = 1\n  num = len(files)\n  print(\"Total #:\",num)\n  # Obtain images and resizing, obtain labels\n  for img in files:\n      '''\n      Append the image data to trainImg list.\n      Append the labels to trainLabel list.\n      '''\n      print(str(j) + \"\/\" + str(num))\n      trainImg.append(cv2.resize(cv2.imread(img), (128, 128)))  # Get image (with resizing to 128x128)\n      trainLabel.append(img.split('\/')[-2])  # Get image label (folder name contains the class to which the image belong)\n      j += 1\n\n  trainImg = np.asarray(trainImg)  # Train images set\n  trainLabel = pd.DataFrame(trainLabel)  # Train labels set\n  return (trainImg, trainLabel)\n\n# Extract Train dataset\npath = extract_path+\"train\/*\/*.png\"    # The path to all images in training set. (* means include all folders and files.)\nprint('reading data from:',path)\ntrainImg, trainLabel = get_data(path)\n","65ca256c":"print(f\"Training image array shape:{trainImg.shape}\")\nprint(f\"Training target labels:{trainLabel.shape}\")","f1dd579c":"# Save data to file \nnp.save(save_extracted+'trainImg.npy', trainImg)\nnp.save(save_extracted+'trainLabel.npy', trainLabel)","8ba443f1":"# Load data to file\ntrainImg = np.load(save_extracted+'trainImg.npy')\ntrainLabel = np.load(save_extracted+'trainLabel.npy', False, True)\n\ntrainImg.shape, trainLabel.shape","353b9694":"# Check Images\ni = 0\nimg = trainImg[i]\nlabel = trainLabel[0][i]\nprint(f'Image name:{label}')\nplt.imshow(img)","da83309d":"i = 500\nimg = trainImg[i]\nlabel = trainLabel[0][i]\nprint(f'Image name:{label}')\nplt.imshow(img)","bc411de2":"i = 1000\nimg = trainImg[i]\nlabel = trainLabel[0][i]\nprint(f'Image name:{label}')\nplt.imshow(img)","f841ab04":"sobel = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=5)\nplt.imshow(sobel)","ca940248":"trainImg = trainImg.astype('float32')\ntrainImg \/= 255\n# Check the nomalized data\nprint(f'Shape of the Train array:{trainImg.shape}')\nprint(f'Minimum value in the Train Array:{trainImg.min()}')\nprint(f'Maximum value in the Train Array:{trainImg.max()}')\n","ea347094":"# Step#1: Split train and test set\nX_train, X_test, y_train, y_test = train_test_split(trainImg, trainLabel, test_size=0.3, random_state=42)\nX_train.shape, X_test.shape","6c78aaae":"# Step#2: Split validation from test set\nX_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\nX_test.shape, X_validation.shape","49f68439":"from sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.fit_transform(y_test)\ny_validation = encoder.fit_transform(y_validation)","ecbde30a":"# Display target variable\ny_train[0]","da72266d":"# Preview the image before Gaussian Blur\nplt.imshow(X_train[1], cmap='gray')","3ba2f570":"plt.imshow(cv2.GaussianBlur(X_train[1], (15,15), 0))","5c4ade70":"# Now we apply the gaussian blur to each 128x128 pixels array (image) to reduce the noise in the image\nfor idx, img in enumerate(X_train):\n  X_train[idx] = cv2.GaussianBlur(img, (5, 5), 0)","aed06b12":"# Preview the image after Gaussian Blur\nplt.imshow(X_train[0], cmap='gray')","ca007e89":"# Gaussian Blue to Test and Validation sets\nfor idx, img in enumerate(X_test):\n  X_test[idx] = cv2.GaussianBlur(img, (5, 5), 0)\n\nfor idx, img in enumerate(X_validation):\n  X_validation[idx] = cv2.GaussianBlur(img, (5, 5), 0)","db6fcdf3":"def create_model(input_shape, num_classes):\n  # Initialize CNN Classified\n  model = Sequential()\n\n  # Add convolution layer with 32 filters and 3 kernels\n  model.add(Conv2D(32, (3,3), input_shape=input_shape, padding='same', activation=tf.nn.relu))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(rate=0.25))\n\n  # Add convolution layer with 32 filters and 3 kernels\n  model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.relu))\n  model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.relu))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(rate=0.25))\n\n  # Add convolution layer with 32 filters and 3 kernels\n  model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.relu))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(rate=0.25))\n\n  # Flatten the 2D array to 1D array\n  model.add(Flatten())\n\n  # Create fully connected layers with 512 units\n  model.add(Dense(512, activation=tf.nn.relu))\n  model.add(Dropout(0.5))\n\n\n  # Adding a fully connected layer with 128 neurons\n  model.add(Dense(units = 128, activation = tf.nn.relu))\n  model.add(Dropout(0.5))\n\n  # The final output layer with 12 neurons to predict the categorical classifcation\n  model.add(Dense(units = num_classes, activation = tf.nn.softmax))\n  return model","97f2fc6d":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.95):\n      print(\"\\nReached 95% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()\n\nes = EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=10)","279972bb":"input_shape = X_train.shape[1:] # Input shape of X_train\nnum_classes = y_train.shape[1] # Target column size\n\nmodel = create_model(input_shape, num_classes)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Optimizer\n# optimizer = tf.keras.optimizers.SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n\nmodel.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","8c22ef47":"history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=30, batch_size=100, callbacks=[callbacks])","6483a465":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epoch', fontsize=18)\nplt.ylabel(r'Loss', fontsize=18)\nplt.legend(('loss train','loss validation'), loc=0)","de78cf11":"\n# Print accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epoch', fontsize=18)\nplt.ylabel(r'Loss', fontsize=18)\nplt.legend(('accuracy train','accuracy validation'), loc=0)","03558ba0":"loss, accuracy = model.evaluate(X_test, y_test)\nprint('Test loss: {:.2f} \\n Test accuracy: {:.2f}'.format(loss, accuracy))\n\nloss, accuracy = model.evaluate(X_train, y_train)\nprint('Train loss: {:.2f} \\n Train accuracy: {:.2f}'.format(loss, accuracy))","c3934659":"model1 = create_model(input_shape, num_classes)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Optimizer\n\nmodel1.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel1.summary()","96d4eee1":"history = model1.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=18, callbacks=[callbacks])","19d47808":"loss, accuracy = model1.evaluate(X_test, y_test)\nprint('Test loss: {:.2f} \\n Test accuracy: {:.2f}'.format(loss, accuracy))\n\nloss, accuracy = model1.evaluate(X_train, y_train)\nprint('Train loss: {:.2f} \\n Train accuracy: {:.2f}'.format(loss, accuracy))","5b333713":"from keras.models import load_model\nmodel.save(save_extracted+'final_model.h5')","a05a3380":"model.load_weights(save_extracted+'final_model.h5')","595c84ab":"y_pred = model1.predict(X_test)\ny_pred = (y_pred > 0.5) ","5058b857":"print(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))","39d631a0":"df_cm = pd.DataFrame(cm, index = [i for i in range(0,12)],\n                     columns = [i for i in range(0,12)])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, fmt='d')","89231bb3":"print(\"=== Classification Report ===\")\nprint(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))","1acb0a59":"y_pred = encoder.inverse_transform(y_pred)\n\nindex = 2\nplt.imshow(X_test[index], cmap='gray')\nprint(\"Predicted label:\", y_pred[index])","beddbf75":"index = 3\nplt.imshow(X_test[index], cmap='gray')\nprint(\"Predicted label:\", y_pred[index])","8b54158d":"index = 33\nplt.imshow(X_test[index], cmap='gray')\nprint(\"Predicted label:\", y_pred[index])","711c7da7":"index = 36\nplt.imshow(X_test[index], cmap='gray')\nprint(\"Predicted label:\", y_pred[index])","d7b5f9bf":"index = 59\nplt.imshow(X_test[index], cmap='gray')\nprint(\"Predicted label:\", y_pred[index])","5228ced0":"# Extract Train dataset\npath = extract_path+\"test\/*.png\"  # The path to all images in test set.\n# predictionImg, predictionLabel = get_data(path)","e6a0bc5e":"filenames = []\nfor img in glob(path):\n  img_split = img.split(\"\/\")\n  filenames.append(img_split[len(img_split)-1])","e90bfb1e":"print(predictionImg.shape)\nprint(predictionLabel.shape)","225fb4e6":"# Saving the data to file for future use [avoiding the extraction]\nnp.save(save_extracted+'predictionImg.npy', predictionImg)\nnp.save(save_extracted+'predictionLabel.npy', predictionLabel)\nprint('saved')","88bd19f3":"# Load prediction data from directory\npredictionImg = np.load(save_extracted+'predictionImg.npy')\npredictionLabel = np.load(save_extracted+'predictionLabel.npy', False, True)\npredictionImg.shape, predictionLabel.shape","87a81082":"print('------------------------')\npredictionImg = predictionImg.astype('float32')\npredictionImg \/= 255\nprint(f'Shape of the Prediction array:{predictionImg.shape}')\nprint(f'Minimum value in the Prediction Array:{predictionImg.min()}')\nprint(f'Maximum value in the Prediction Array:{predictionImg.max()}')","44b3b96f":"for idx, img in enumerate(predictionImg):\n  predictionImg[idx] = cv2.GaussianBlur(img, (5, 5), 0)","0785ba68":"y_pred = model1.predict(predictionImg)\nprint('Prediction:', y_pred)","e9f5b509":"y_pred = encoder.inverse_transform(y_pred)\n(unique, counts) = np.unique(y_pred, return_counts=True)\nprint('Unique:',unique, 'Counts:',counts)","df27a9cb":"y_pred","a0ea174b":"index = 2\nplt.imshow(predictionImg[index], cmap='gray')\nprint(\"Predicted label:\", y_pred[index])\n","72200352":"df = pd.DataFrame(filenames, columns=['file'])\ndf['species'] = y_pred","d8ac38a7":"df.head()","b3fdc1e4":"df.to_csv(save_extracted+\"result.csv\", index=False)","ea400225":"* Model is overfitting since training accuracy is 95% and testing accuracy is 81%. let's stop it before 18 epoch","e57361c2":"* **Precision**: Out of all the positive classes we have predicted correctly, how many are actually positive.\n* **Recall**: Out of all the positive classes, how much we predicted correctly. It should be high as possible.\n* **F1-Score**: F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution","a2967dbc":"* Prediction label wouldn't be useful here since it has value as 'test', the model will predict these labels","21dea730":"#### Explore the data by visualizing it from various categories","66890eeb":"* Few training image has less quality, but it might overcome in pre-processing \n","2dc4cc4d":"# Pre-processing","44520a88":"# [Add on] Predict the Label for Test test in the original dataset","35c9f8ab":"Storing the data into file to save the time in extract and read","05dfd312":"# Model Retrain","f25a02f5":"* The early stopping helping model to balance accuracy b\/w test and training. Let's save the mode for future re-training","4f8af254":"### Confusion matrix","b6fbc966":"### Unzipping Prediction files & Normalize it:","549881c2":"# Model Evaluation","7ede2144":"* **Sequential:** Defines a Sequence of layers\n* **Conv2D:** Keras Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n* **MaxPool2D:** The objective is to down-sample an input representation\n* **Flatten:** Convert the 2D to 1D array\n* **Dense:** Adds a layers of neurons\n* **Activation Functions:**:\n\n\n> **Relu:** Relu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n\n> **Softmax:** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!\n\n\n","17bdb9fa":"# Unziping train file:","3efd42cf":"### Split the dataset\nSplit the dataset into training, testing, and validation set.\n(Hint: First split train images and train labels into training and testing set with test_size = 0.3. Then further split test data into test and validation set with test_size = 0.5)","f6b501c2":"# EDA","7639220d":"### Gaussian Blurring\nImage blurring is achieved by convolving the image with a low-pass filter kernel. It is useful for removing noise. It actually removes high frequency content (e.g: noise, edges) from the image resulting in edges being blurred when this is filter is applied. ","e2b9a098":"### Normalize the Data\n* The Data (Train image and testing image) needs to be normalized to 0-1 by diving the values by 255","48bdd07d":"# Import Libraries and Data Load","27dbe7c0":"* There is an alternate way to convert the target variable to one-hot\n1. Convert String categorical to numeric\n2. Use *tensorflow.keras.utils.to_categorical* to convert to binary array","4af1f5cf":"# Create a Model\n\nSteps:\n\n\n1. Initialize CNN Classifier\n2. Add Convolution layer with 32 kernels of 3x3 shape\n3. Add Maxpooling layer of size 2x2\n4. Flatten the input array\n5. Add dense layer with relu activation function\n6. Dropout the probability \n7. Add softmax Dense layer as output\n\n","d56ca34d":"# Project: Plant Seedlings Classicication.\n\n### Data Description:\n\n- You are provided with a training set and a test set of images of plant seedlings at various stages of grown. \n- Each image has a filename that is its unique id. \n- The dataset comprises 12 plant species.\n- The goal of the competition is to create a classifier capable of determining a plant's species from a photo.\n\n### Dataset:\n- The project is from a dataset from Kaggle.\n- Link to the Kaggle project site:https:\/\/www.kaggle.com\/c\/plant-seedlings-classification\/data\n- The dataset has to be downloaded from the above Kagglewebsite.\n\n### Context:\n\n- Can you differentiate a weed from a crop seedling?\n- The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n- The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has recently released a dataset containing images of unique plants belonging to 12 species at several growth stages.\n\n### Objective:\n- To implement the techniques learnt as a part of the course.\n\n### Learning Outcomes:\n- Pre-processing of image data.\n- Visualization of images.\n- Building CNN.\n- Evaluate the Model.","877a4893":"### Visualize predictions","2b340255":"### One Hot encoding to target values","6e45100c":"### Model Prediction"}}