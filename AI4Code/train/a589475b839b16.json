{"cell_type":{"374a431d":"code","86f5c829":"code","df2545cd":"code","44f108e3":"code","ea623917":"code","fb4b85c2":"code","33eed15f":"code","cc710b47":"code","4af43643":"code","db324032":"code","6bcfe6f5":"code","fab2cb36":"code","cc1a3b3a":"code","147213a8":"code","8e7311ee":"code","6fbd28dc":"code","34d10b3a":"code","355059f8":"code","9bb82438":"code","5a7d7f4e":"code","1812bb4b":"code","d9111c2a":"code","bdbcc8c0":"code","10aa6949":"code","dd20107d":"code","4d0b04f0":"code","1215d963":"code","52b730d9":"code","1d3838ca":"code","d286d3fe":"code","eae90e8a":"code","b360291c":"code","d72db322":"code","ebb3c2e9":"code","382c1a6c":"code","8a78f5c1":"code","07ed01e6":"code","53d10b2e":"code","19267fa2":"code","7c421d64":"code","2325b551":"code","084cffd3":"code","6499db9e":"code","8c5dc18b":"code","7441adb7":"code","12916607":"code","c0b82296":"code","5272038c":"code","a1dd88bb":"code","2a7062b9":"code","f05102d1":"code","45fb86f3":"code","2df536e5":"code","eb1a259b":"code","0af0f70c":"code","7ea9eb56":"code","7fe14010":"code","9c3fcbb1":"code","52bb9010":"code","be039f9a":"code","47e656cf":"code","e21fd18a":"code","007cb8bf":"code","0e6eec80":"code","a65f162e":"code","06fc609c":"code","24ec25fb":"code","e684e3e6":"code","3efbb702":"code","9bb8a82a":"code","dc4c23f2":"code","019fe43a":"code","d515fa35":"code","5d8e315f":"code","5d9a1df7":"code","3acafbca":"code","8f9115cf":"code","e24689e7":"code","465867e3":"code","666a079e":"code","e6938892":"code","8f142a9b":"code","343bb0d6":"code","a406b5c0":"code","edc432fa":"code","fa51fb40":"code","d1c01661":"code","24b9875f":"code","253047cd":"code","47381930":"code","7ed804a5":"code","eabee169":"code","1e9d0da6":"code","a499a624":"code","19b738d4":"code","9e373867":"code","6527c18d":"code","831c7255":"code","ec5d8a3c":"code","362e76fa":"code","8fa27ae1":"code","e652e931":"code","5de0c441":"code","c42c57a8":"code","5a49bff0":"code","e3059d11":"code","7fa66334":"code","0bd37c65":"code","58931bd2":"code","59e1a223":"code","8cec0f95":"code","53b20c63":"code","522bbbae":"code","7c60b265":"code","7f2f8138":"code","393252a5":"code","b20ee86d":"code","22653395":"code","4f434650":"code","a43bb43d":"code","f91ddd01":"code","5e07dd30":"markdown","d7cc708f":"markdown","ed60e80c":"markdown","41aaa0b0":"markdown","8b522069":"markdown","e1ff733b":"markdown","3a328d41":"markdown","30afac9d":"markdown","c1f4d7ca":"markdown","4fad6aab":"markdown","5be4d179":"markdown","3c549a65":"markdown","4f3e4bab":"markdown","851610c0":"markdown","fc7b6399":"markdown"},"source":{"374a431d":"import os,sys,random,gc\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras import Input,models,layers,optimizers,preprocessing\nfrom keras.datasets import mnist,imdb,reuters,boston_housing\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16\nfrom keras.models import load_model\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n%matplotlib inline","86f5c829":"(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n\nprint(train_images.shape)\nprint(train_labels.shape)\nprint(test_images.shape)\nprint(test_labels.shape)","df2545cd":"# reshape 3-ndim tensor(60000,28,28) to 2-nidm tensor(60000,512)\ntrain_x = train_images.reshape((60000,28*28))\ntest_x = test_images.reshape((10000,28*28))\n# scale 0~255 to 0~1\ntrain_x = train_x.astype(\"float32\")\/255\ntest_x = test_x.astype(\"float32\")\/255\n# labels transform\ntrain_y = to_categorical(train_labels)\ntest_y = to_categorical(test_labels)","44f108e3":"from keras import models,layers\n\n# build network framework\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(512,activation=\"relu\",input_shape=(28*28,))) # \u6570\u636e\u84b8\u998f\uff0c\u7a20\u5bc6\u8fde\u63a5\uff08\u5168\u8fde\u63a5\uff09\u795e\u7ecf\u5c42\uff0c\u4e00\u9636\u5f20\u91cf\uff0c\u5411\u91cf\u957f\u5ea6\u4e3a28*28\nnetwork.add(layers.Dense(10,activation=\"softmax\")) # \u8f93\u51fa\u5c42\uff0c10\u4e2a\u6807\u7b7e\uff0c\u6fc0\u6d3b\u51fd\u6570\u4e3asoftmax\uff0c\u4e00\u822c\u7528\u4e8e\u591a\u5206\u7c7b\n\n# compile\uff1aloss function, optimizer, metric\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\n# train model\nnetwork.fit(train_x,train_y,epochs=5,batch_size=128)\n\n# evaluate model\ntest_loss,test_acc = network.evaluate(test_x,test_y)\n\nprint(\"test loss:\",test_loss)\nprint(\"test accuracy:\",test_acc)\ngc.collect()","ea623917":"print(\"\u5f20\u91cf\u9636\uff1a\",train_images.ndim)\nprint(\"\u5f20\u91cf\u5f62\u72b6\uff1a\",train_images.shape)\nprint(\"\u5f20\u91cf\u6570\u636e\u7c7b\u578b\uff1a\",train_images.dtype)","fb4b85c2":"import matplotlib.pyplot as plt\nplt.imshow(train_images[4],cmap=plt.cm.binary)","33eed15f":"(train_data,train_labels),(test_data,test_labels) = imdb.load_data(num_words=10000) # \u53ea\u4fdd\u7559\u51fa\u73b0\u6b64\u5904\u6700\u591a\u768410000\u4e2a\u5355\u8bcd\n\nprint(train_data.shape)\nprint(train_labels.shape)\nprint(test_data.shape)\nprint(test_labels.shape)","cc710b47":"def review(vec,dict_):\n    dict_ = {v:k for k,v in dict_.items()}\n    return \" \".join([dict_.get(int(v)-3,\"?\") for v in vec])","4af43643":"dict_ = imdb.get_word_index()\n\nprint(train_data[0])\nprint(review(train_data[0],dict_))\nprint(train_labels[0])\ngc.collect()","db324032":"def vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences),dimension))\n    for i,sequence in enumerate(sequences):\n        results[i, sequence] = 1\n    return results\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\nprint(x_train.shape)\nprint(x_train[0])\nprint(x_test.shape)\nprint(x_test[0])","6bcfe6f5":"network = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# train and validation\nx_val = x_train[:10000]\nx_train_partial = x_train[10000:]\ny_val = train_labels[:10000]\ny_train_partial = train_labels[10000:]\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(15000\/512)*20\nhistory = network.fit(x_train_partial,y_train_partial,epochs=20,batch_size=512,validation_data=(x_val,y_val))\n\nhistory.history\n\ngc.collect()","fab2cb36":"history_df = pd.DataFrame(history.history)\nhistory_df[[\"loss\",\"val_loss\"]].plot()","cc1a3b3a":"history_df[[\"accuracy\",\"val_accuracy\"]].plot()","147213a8":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=512)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","8e7311ee":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=512)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","6fbd28dc":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=128)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","34d10b3a":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=512)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","355059f8":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"mse\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=512)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","9bb82438":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"tanh\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(16,activation=\"tanh\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=512)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","5a7d7f4e":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(32,activation=\"relu\",input_shape=(10000,))) # relu\u6574\u6d41\u6fc0\u6d3b\u51fd\u6570\u5b9e\u73b0\u8868\u793a\u7a7a\u95f4\u975e\u7ebf\u6027\nnetwork.add(layers.Dense(64,activation=\"relu\"))\nnetwork.add(layers.Dense(1,activation=\"sigmoid\")) # sigmoid\u5c06\u8f93\u51fa\u538b\u7f29\u52300~1\u4e4b\u95f4\u4f5c\u4e3a\u4e8c\u5206\u7c7b\u7684\u7c7b\u522b\u6982\u7387\u503c\n\nnetwork.compile(loss=\"binary_crossentropy\", # \u9002\u7528\u4e8e\u8f93\u51fa\u6982\u7387\u503c\u7684\u4e8c\u5206\u7c7b\u6a21\u578b\n               optimizer=\"rmsprop\", # SGD\u7684\u53d8\u79cd\n               metrics=[\"accuracy\"])\n\n# W\u8fed\u4ee3\u66f4\u65b0\u6b21\u6570=(25000\/512)*20\nnetwork.fit(x_train,train_labels,epochs=4,batch_size=512)\n\nresult = network.evaluate(x_test,test_labels)\n\nresult","1812bb4b":"(train_data,train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)\n\nprint(train_data.shape)\nprint(train_labels.shape)\nprint(test_data.shape)\nprint(test_labels.shape)\n\ndict_ = reuters.get_word_index()\nprint(review(train_data[0],dict_))\nprint(review(test_data[0],dict_))","d9111c2a":"x_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)","bdbcc8c0":"# \u529f\u80fd\u7b49\u4ef7\u4e8eto_categorical\ndef to_one_hot(seqs,dimension=46):\n    results = np.zeros((len(seqs),dimension))\n    for i,seq in enumerate(seqs):\n        results[i,seq] = 1\n    return results\n\ny_train = to_one_hot(train_labels)\ny_test = to_one_hot(test_labels)\n\nprint(y_train[0])\nprint(y_test[0])","10aa6949":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(64,activation=\"relu\",input_shape=(10000,))) # \u9690\u85cf\u5355\u5143\u6570\u8bbe\u7f6e\u4e3a64\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u8868\u793a\u7a7a\u95f4\u53bb\u8bc6\u522b\u590d\u6742\u768446\u4e2a\u7c7b\u522b\u7684\u8868\u793a\nnetwork.add(layers.Dense(64,activation=\"relu\"))\nnetwork.add(layers.Dense(46,activation=\"softmax\")) # softmax\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa46\u4e2a\u7c7b\u522b\u5bf9\u5e94\u7684\u6982\u7387\uff0c\u6982\u7387\u548c\u4e3a1\n\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nx_val = x_train[:1000]\nx_train_part = x_train[1000:]\ny_val = y_train[:1000]\ny_train_part = y_train[1000:]\n\nhistory = network.fit(x_train_part,y_train_part,epochs=20,batch_size=512,validation_data=(x_val,y_val))","dd20107d":"history_df = pd.DataFrame(history.history)\n\nhistory_df[[\"loss\",\"val_loss\"]].plot()","4d0b04f0":"history_df[[\"accuracy\",\"val_accuracy\"]].plot()","1215d963":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(64,activation=\"relu\",input_shape=(10000,))) # \u9690\u85cf\u5355\u5143\u6570\u8bbe\u7f6e\u4e3a64\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u8868\u793a\u7a7a\u95f4\u53bb\u8bc6\u522b\u590d\u6742\u768446\u4e2a\u7c7b\u522b\u7684\u8868\u793a\nnetwork.add(layers.Dense(64,activation=\"relu\"))\nnetwork.add(layers.Dense(46,activation=\"softmax\")) # softmax\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa46\u4e2a\u7c7b\u522b\u5bf9\u5e94\u7684\u6982\u7387\uff0c\u6982\u7387\u548c\u4e3a1\n\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nnetwork.fit(x_train,y_train,epochs=7,batch_size=512)\n\nresult = network.evaluate(x_test,y_test)\n\nprint(result)","52b730d9":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(64,activation=\"relu\",input_shape=(10000,))) # \u9690\u85cf\u5355\u5143\u6570\u8bbe\u7f6e\u4e3a64\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u8868\u793a\u7a7a\u95f4\u53bb\u8bc6\u522b\u590d\u6742\u768446\u4e2a\u7c7b\u522b\u7684\u8868\u793a\nnetwork.add(layers.Dense(4,activation=\"relu\"))\nnetwork.add(layers.Dense(46,activation=\"softmax\")) # softmax\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa46\u4e2a\u7c7b\u522b\u5bf9\u5e94\u7684\u6982\u7387\uff0c\u6982\u7387\u548c\u4e3a1\n\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nx_val = x_train[:1000]\nx_train_part = x_train[1000:]\ny_val = y_train[:1000]\ny_train_part = y_train[1000:]\n\nhistory = network.fit(x_train_part,y_train_part,epochs=20,batch_size=512,validation_data=(x_val,y_val))","1d3838ca":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(64,activation=\"relu\",input_shape=(10000,))) # \u9690\u85cf\u5355\u5143\u6570\u8bbe\u7f6e\u4e3a64\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u8868\u793a\u7a7a\u95f4\u53bb\u8bc6\u522b\u590d\u6742\u768446\u4e2a\u7c7b\u522b\u7684\u8868\u793a\nnetwork.add(layers.Dense(128,activation=\"relu\"))\nnetwork.add(layers.Dense(46,activation=\"softmax\")) # softmax\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa46\u4e2a\u7c7b\u522b\u5bf9\u5e94\u7684\u6982\u7387\uff0c\u6982\u7387\u548c\u4e3a1\n\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nx_val = x_train[:1000]\nx_train_part = x_train[1000:]\ny_val = y_train[:1000]\ny_train_part = y_train[1000:]\n\nhistory = network.fit(x_train_part,y_train_part,epochs=20,batch_size=512,validation_data=(x_val,y_val))","d286d3fe":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(64,activation=\"relu\",input_shape=(10000,))) # \u9690\u85cf\u5355\u5143\u6570\u8bbe\u7f6e\u4e3a64\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u8868\u793a\u7a7a\u95f4\u53bb\u8bc6\u522b\u590d\u6742\u768446\u4e2a\u7c7b\u522b\u7684\u8868\u793a\nnetwork.add(layers.Dense(64,activation=\"relu\"))\nnetwork.add(layers.Dense(64,activation=\"relu\"))\nnetwork.add(layers.Dense(64,activation=\"relu\"))\nnetwork.add(layers.Dense(46,activation=\"softmax\")) # softmax\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa46\u4e2a\u7c7b\u522b\u5bf9\u5e94\u7684\u6982\u7387\uff0c\u6982\u7387\u548c\u4e3a1\n\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nx_val = x_train[:1000]\nx_train_part = x_train[1000:]\ny_val = y_train[:1000]\ny_train_part = y_train[1000:]\n\nhistory = network.fit(x_train_part,y_train_part,epochs=20,batch_size=512,validation_data=(x_val,y_val))","eae90e8a":"gc.collect()\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(16,activation=\"relu\",input_shape=(10000,))) # \u9690\u85cf\u5355\u5143\u6570\u8bbe\u7f6e\u4e3a64\uff0c\u7528\u4e8e\u6784\u5efa\u66f4\u590d\u6742\u7684\u8868\u793a\u7a7a\u95f4\u53bb\u8bc6\u522b\u590d\u6742\u768446\u4e2a\u7c7b\u522b\u7684\u8868\u793a\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(16,activation=\"relu\"))\nnetwork.add(layers.Dense(46,activation=\"softmax\")) # softmax\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa46\u4e2a\u7c7b\u522b\u5bf9\u5e94\u7684\u6982\u7387\uff0c\u6982\u7387\u548c\u4e3a1\n\nnetwork.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nx_val = x_train[:1000]\nx_train_part = x_train[1000:]\ny_val = y_train[:1000]\ny_train_part = y_train[1000:]\n\nhistory = network.fit(x_train_part,y_train_part,epochs=50,batch_size=512,validation_data=(x_val,y_val))","b360291c":"(train_data,train_targets),(test_data,test_targets) = boston_housing.load_data()\n\nprint(train_data.shape)\nprint(train_data[0])\nprint(train_targets.shape)\nprint(test_data.shape)\nprint(test_data[0])\nprint(test_targets.shape)","d72db322":"mean_ = train_data.mean(axis=0)\nstd_ = train_data.std(axis=0)\ntrain_data -= mean_\ntrain_data \/= std_\ntest_data -= mean_\ntest_data \/= std_","ebb3c2e9":"def build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64,activation=\"relu\",input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64,activation=\"relu\"))\n    model.add(layers.Dense(1))\n    model.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\n    return model","382c1a6c":"gc.collect()\nk=5\nfold_size = train_data.shape[0]\/\/k\nall_scores = []\nfor i in range(k):\n    x_train = np.concatenate([\n        train_data[:i*fold_size],\n        train_data[(i+1)*fold_size:]\n    ],axis=0)\n    y_train = np.concatenate([\n        train_targets[:i*fold_size],\n        train_targets[(i+1)*fold_size:]\n    ],axis=0)\n    x_val = train_data[i*fold_size:(i+1)*fold_size]\n    y_val = train_targets[i*fold_size:(i+1)*fold_size]\n    \n    model = build_model()\n    model.fit(x_train,y_train,epochs=100,batch_size=1,verbose=0)\n    val_mse,val_mae = model.evaluate(x_val,y_val,verbose=0)\n    all_scores.append(val_mae)\n\nprint(np.mean(all_scores),all_scores)","8a78f5c1":"gc.collect()\nk=5\nfold_size = train_data.shape[0]\/\/k\nall_scores = []\nfor i in range(k):\n    x_train = np.concatenate([\n        train_data[:i*fold_size],\n        train_data[(i+1)*fold_size:]\n    ],axis=0)\n    y_train = np.concatenate([\n        train_targets[:i*fold_size],\n        train_targets[(i+1)*fold_size:]\n    ],axis=0)\n    x_val = train_data[i*fold_size:(i+1)*fold_size]\n    y_val = train_targets[i*fold_size:(i+1)*fold_size]\n    \n    model = build_model()\n    history = model.fit(x_train,y_train,epochs=500,batch_size=1,verbose=0,validation_data=(x_val,y_val))\n    all_scores.append(history.history[\"val_mae\"])\n\nall_scores = [np.mean([score[i] for score in all_scores]) for i in range(500)]","07ed01e6":"pd.DataFrame({\"VAL-MAE\":all_scores}).plot()","53d10b2e":"pd.DataFrame({\"VAL-MAE\":all_scores[10:100]}).plot()","19267fa2":"pd.DataFrame({\"VAL-MAE\":np.array(all_scores[10:-1])*.9+np.array(all_scores[11:])*.1}).plot()","7c421d64":"gc.collect()\nmodel.fit(x_train,y_train,epochs=65,batch_size=1,verbose=0)\nresult = model.evaluate(test_data,test_targets)\nprint(result)","2325b551":"gc.collect()\nmodel.fit(x_train,y_train,epochs=65,batch_size=16,verbose=0)\nresult = model.evaluate(test_data,test_targets)\nprint(result)","084cffd3":"gc.collect()\nmodel = models.Sequential()\n# output shape=26 26 32, 26 26\u7531(3,3)\uff0c\u4e5f\u5c31\u662f\u7a97\u53e3\u5927\u5c0f\u51b3\u5b9a\uff0c\u901a\u9053\u657032\u7531\u5165\u53c232\u51b3\u5b9a\nmodel.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(28,28,1,)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n\n# \u4e0b\u9762\u8fd9\u4e09\u5c42\u7528\u4e8e\u591a\u7c7b\u522b\u6982\u7387\u8f93\u51fa\uff0c\u4e0d\u5c5e\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u7684\u6838\u5fc3\u5c42\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64,activation=\"relu\"))\nmodel.add(layers.Dense(10,activation=\"softmax\"))\nmodel.summary()","6499db9e":"(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n\ntrain_x = train_images.reshape((60000,28,28,1))\ntest_x = test_images.reshape((10000,28,28,1))\n\ntrain_x = train_x.astype(\"float32\")\/255\ntest_x = test_x.astype(\"float32\")\/255\n\ntrain_y = to_categorical(train_labels)\ntest_y = to_categorical(test_labels)\n\nmodel.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nmodel.fit(train_x,train_y,epochs=5,batch_size=128)\n\ntest_loss,test_acc = model.evaluate(test_x,test_y)\n\nprint(\"test loss:\",test_loss)\nprint(\"test accuracy:\",test_acc)","8c5dc18b":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(28,28,1,)))\nmodel.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64,activation=\"relu\"))\nmodel.add(layers.Dense(10,activation=\"softmax\"))\n\nmodel.compile(optimizer=\"rmsprop\",\n               loss=\"categorical_crossentropy\",\n               metrics=[\"accuracy\"])\n\nmodel.fit(train_x,train_y,epochs=5,batch_size=128)\n\ntest_loss,test_acc = model.evaluate(test_x,test_y)\n\nprint(\"test loss:\",test_loss)\nprint(\"test accuracy:\",test_acc)","7441adb7":"!mkdir ..\/working\/train\n!mkdir ..\/working\/test\n!mkdir ..\/working\/validation\n!mkdir ..\/working\/train\/dogs\n!mkdir ..\/working\/validation\/dogs\n!mkdir ..\/working\/test\/dogs\n!mkdir ..\/working\/train\/cats\n!mkdir ..\/working\/validation\/cats\n!mkdir ..\/working\/test\/cats\n!mkdir ..\/working\/models\n\nimport os\ncats = []\ndogs = []\nfor f in os.listdir(\"..\/input\/dogs-vs-cats\/train\/train\"):\n    if f.startswith(\"cat\") and f.endswith(\"jpg\") and len(cats)<2000:\n        cats.append(f)\n    elif f.startswith(\"dog\") and f.endswith(\"jpg\") and len(dogs)<2000:\n        dogs.append(f)\n\nfor cat in cats[:1000]:\n    os.system(\"cp ..\/input\/dogs-vs-cats\/train\/train\/\"+cat+\" ..\/working\/train\/cats\/\")\nfor cat in cats[1000:1500]:\n    os.system(\"cp ..\/input\/dogs-vs-cats\/train\/train\/\"+cat+\" ..\/working\/validation\/cats\/\")\nfor cat in cats[1500:]:\n    os.system(\"cp ..\/input\/dogs-vs-cats\/train\/train\/\"+cat+\" ..\/working\/test\/cats\/\")\nfor dog in dogs[:1000]:\n    os.system(\"cp ..\/input\/dogs-vs-cats\/train\/train\/\"+dog+\" ..\/working\/train\/dogs\/\")\nfor dog in dogs[1000:1500]:\n    os.system(\"cp ..\/input\/dogs-vs-cats\/train\/train\/\"+dog+\" ..\/working\/validation\/dogs\/\")\nfor dog in dogs[1500:]:\n    os.system(\"cp ..\/input\/dogs-vs-cats\/train\/train\/\"+dog+\" ..\/working\/test\/dogs\/\")\n\ntrain_dir = \"..\/working\/train\"\ntest_dir = \"..\/working\/test\"\nvalidation_dir = \"..\/working\/validation\"\nprint(len(os.listdir(train_dir)))\nprint(len(os.listdir(validation_dir)))\nprint(len(os.listdir(test_dir)))","12916607":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512,activation=\"relu\"))\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\nmodel.summary()","c0b82296":"model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"acc\"])","5272038c":"gc.collect()\ntrain_generator = ImageDataGenerator(rescale=1.\/255)\ntest_generator = ImageDataGenerator(rescale=1.\/255)\n\ntrain_iter = train_generator.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")\nvalidation_iter = test_generator.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")\n\nhistory = model.fit_generator(\n    train_iter,steps_per_epoch=100, # \u8be5\u53c2\u6570\u8868\u793a\u6bcf\u6b21epoch\u8fed\u4ee3\u6b21\u6570\uff0c\u6b21\u6570\u4e3a(1000+1000)\/20\n    epochs=30,\n    validation_data=validation_iter,validation_steps=50 # \u4e0e\u4e0a\u8ff0steps\u4e00\u81f4\uff0c\u6b21\u6570\u4e3a(500+500)\/20\n)\n\nmodel.save(\"..\/working\/models\/cats_dogs_1.h5\")","a1dd88bb":"history_1 = pd.DataFrame(history.history)\nhistory_1[[\"loss\",\"val_loss\"]].plot()","2a7062b9":"history_1[[\"acc\",\"val_acc\"]].plot()","f05102d1":"gc.collect()\ndata_gen = ImageDataGenerator(rotation_range=40,width_shift_range=.2,height_shift_range=.2,\n                              shear_range=.2,zoom_range=.2,horizontal_flip=True,fill_mode=\"nearest\")\nimg = image.load_img(\"..\/working\/train\/dogs\/\"+os.listdir(\"..\/working\/train\/dogs\")[0], target_size=(150,150))\nimg_arr = image.img_to_array(img)\nimg_arr = img_arr.reshape((1,)+img_arr.shape) # reshape to 1 150 150 3\ni=0\nplt.imshow(image.img_to_array(img))\nfor batch in data_gen.flow(img_arr,batch_size=1):\n    plt.figure(i+1)\n    plt.imshow(image.array_to_img(batch[0]))\n    i+=1\n    if i%3==0:\n        break\nplt.show()","45fb86f3":"gc.collect()\ntrain_generator = ImageDataGenerator(rescale=1.\/255,rotation_range=40,\n                                     width_shift_range=.2,height_shift_range=.2,\n                                    shear_range=.2,zoom_range=.2,horizontal_flip=True)\ntest_generator = ImageDataGenerator(rescale=1.\/255)\ntrain_iter = train_generator.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")\nvalidation_iter = test_generator.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(.5)) # drop\u6bd4\u4f8b\uff0c\u5904\u7406\u8fc7\u62df\u5408\u95ee\u9898\nmodel.add(layers.Dense(512,activation=\"relu\"))\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"acc\"])\n\nhistory = model.fit_generator(\n    train_iter,steps_per_epoch=100, # \u8be5\u53c2\u6570\u8868\u793a\u6bcf\u6b21epoch\u8fed\u4ee3\u6b21\u6570\uff0c\u6b21\u6570\u4e3a(1000+1000)\/20\n    epochs=30,\n    validation_data=validation_iter,validation_steps=50 # \u4e0e\u4e0a\u8ff0steps\u4e00\u81f4\uff0c\u6b21\u6570\u4e3a(500+500)\/20\n)\n\nmodel.save(\"..\/working\/models\/cats_dogs_2.h5\")","2df536e5":"history_2 = pd.DataFrame(history.history)\nhistory_2[[\"loss\",\"val_loss\"]].plot()","eb1a259b":"history_2[[\"acc\",\"val_acc\"]].plot()","0af0f70c":"conv_base = VGG16(weights=\"imagenet\",include_top=False,input_shape=(150,150,3))\nconv_base.summary()","7ea9eb56":"gc.collect()\n# VGG16\u505a\u7279\u5f81\u63d0\u53d6\u8f93\u51fafeature\uff0c\u5373\u4e0d\u4f7f\u7528\u6570\u636e\u589e\u5f3a\ndata_gen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 20\ndef extract_feature(path,sample_count):\n    features = np.zeros(shape=(sample_count,4,4,512))\n    labels = np.zeros(shape=(sample_count))\n    generator = data_gen.flow_from_directory(\n        path,target_size=(150,150),batch_size=batch_size,class_mode=\"binary\"\n    )\n    i=0\n    for input_batch,label_batch in generator:\n        features_batch = conv_base.predict(input_batch)\n        features[i*batch_size:(i+1)*batch_size]=features_batch\n        labels[i*batch_size:(i+1)*batch_size]=label_batch\n        i+=1\n        if i*batch_size >= sample_count:\n            break\n    return features,labels\n\ntrain_features,train_labels = extract_feature(train_dir,2000)\ntest_features,test_labels = extract_feature(test_dir,1000)\nvalidation_features,validation_labels = extract_feature(validation_dir,1000)\n\n# \u624b\u52a8\u5c55\u5f00\ntrain_features = np.reshape(train_features,(2000,4*4*512))\ntest_features = np.reshape(test_features,(1000,4*4*512))\nvalidation_features = np.reshape(validation_features,(1000,4*4*512))\n\n# \u7ed3\u6784\u4ece\u539f\u59cb\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u53d8\u4e3a\u53ea\u6709\u4e24\u4e2a\u9690\u542b\u5c42\u7684\u7ebf\u6027\u53e0\u52a0\u7ed3\u6784\uff0c\u76f8\u5f53\u4e8e\u4e4b\u524d\u7684\u5377\u79ef\u5c42\u5df2\u7ecf\u88ab\u5377\u79ef\u57fa\u4ee3\u66ff\u4e86\nmodel = models.Sequential()\nmodel.add(layers.Dense(256,activation=\"relu\",input_shape=(4*4*512,)))\nmodel.add(layers.Dropout(.5))\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss=\"binary_crossentropy\",metrics=[\"acc\"])\n\nhistory = model.fit(train_features,train_labels,epochs=30,batch_size=20,validation_data=(validation_features,validation_labels))","7fe14010":"history_3 = pd.DataFrame(history.history)\nhistory_3[[\"loss\",\"val_loss\"]].plot()","9c3fcbb1":"history_3[[\"acc\",\"val_acc\"]].plot()","52bb9010":"gc.collect()\n# \u5c06\u5377\u79ef\u57fa\u4f5c\u4e3a\u4e00\u4e2a\u7f51\u7edc\u5c42\u6dfb\u52a0\u5230\u62d3\u6251\u7ed3\u6784\u4e2d\uff0c\u5e94\u7528\u6570\u636e\u589e\u5f3a\ntrain_generator = ImageDataGenerator(rescale=1.\/255,rotation_range=20,\n                                     width_shift_range=.1,height_shift_range=.1,\n                                    shear_range=.2,zoom_range=.2,horizontal_flip=True)\ntest_generator = ImageDataGenerator(rescale=1.\/255)\ntrain_iter = train_generator.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")\nvalidation_iter = test_generator.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")\n\nconv_base = VGG16(weights=\"imagenet\",include_top=False,input_shape=(150,150,3))\nconv_base.trainable = False\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256,activation=\"relu\"))\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\nmodel.summary()","be039f9a":"gc.collect()\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss=\"binary_crossentropy\",metrics=[\"acc\"])\n\nhistory = model.fit_generator(\n    train_iter,steps_per_epoch=100, # \u8be5\u53c2\u6570\u8868\u793a\u6bcf\u6b21epoch\u8fed\u4ee3\u6b21\u6570\uff0c\u6b21\u6570\u4e3a(1000+1000)\/20\n    epochs=30,\n    validation_data=validation_iter,validation_steps=50 # \u4e0e\u4e0a\u8ff0steps\u4e00\u81f4\uff0c\u6b21\u6570\u4e3a(500+500)\/20\n)","47e656cf":"history_4 = pd.DataFrame(history.history)\nhistory_4[[\"loss\",\"val_loss\"]].plot()","e21fd18a":"history_4[[\"acc\",\"val_acc\"]].plot()","007cb8bf":"gc.collect()\n# Fine tuning\nrefreeze = False\nfor layer in conv_base.layers:\n    if layer == \"block5_conv1\":\n        refreeze = True\n    if refreeze:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\n# \u53d6\u66f4\u5c0f\u7684\u5b66\u4e60\u7387\uff0c\u4fdd\u8bc1\u5bf9\u4e8e\u539f\u7f51\u7edc\u8868\u793a\u7684\u66f4\u65b0\u662f\u5fae\u5c0f\u7684\nmodel.compile(optimizer=optimizers.RMSprop(lr=3e-6),loss=\"binary_crossentropy\",metrics=[\"acc\"])\n\n# \u89e3\u51bb\u5377\u79ef\u57fa\u4e2d\u90e8\u5206\u5c42\uff0c\u57fa\u4e8e\u4e4b\u524d\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5c42\u505a\u8054\u5408\u8bad\u7ec3\nhistory = model.fit_generator(\n    train_iter,steps_per_epoch=100, # \u8be5\u53c2\u6570\u8868\u793a\u6bcf\u6b21epoch\u8fed\u4ee3\u6b21\u6570\uff0c\u6b21\u6570\u4e3a(1000+1000)\/20\n    epochs=50,\n    validation_data=validation_iter,validation_steps=50 # \u4e0e\u4e0a\u8ff0steps\u4e00\u81f4\uff0c\u6b21\u6570\u4e3a(500+500)\/20\n)","0e6eec80":"history_5 = pd.DataFrame(history.history)\nhistory_5[[\"loss\",\"val_loss\"]].plot()","a65f162e":"history_5[[\"acc\",\"val_acc\"]].plot()","06fc609c":"model = load_model(\"..\/working\/models\/cats_dogs_2.h5\")\nmodel.summary()","24ec25fb":"gc.collect()\nimg_path = \"..\/working\/test\/dogs\/\"+random.choice(os.listdir(\"..\/working\/test\/dogs\"))\nimg = image.load_img(img_path,target_size=(150,150))\nimg_tensor = image.img_to_array(img)\nprint(img_tensor.shape)\nimg_tensor = np.expand_dims(img_tensor,axis=0)\nimg_tensor \/= 255.\nprint(img_tensor.shape)\n\nlayer_outputs = [layer.output for layer in model.layers[:8]] # \u53ea\u83b7\u53d6\u524d8\u5c42\uff0c\u4e5f\u5c31\u662f\u5377\u79ef\u5c42\u548c\u6700\u5927\u6c60\u5c42\u7684\u8f93\u51fa - \u4e2d\u95f4\u8f93\u51fa\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(img_tensor)\nfor i in range(len(activations)):\n    print(activations[i].shape) # \u8f93\u51fa\u7684shape\n\n\n# \u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u7b2c\u516b\u4e2a\u8fc7\u6ee4\u5668\nplt.figure(figsize=(15,20))\nplt.subplot(5,1,1)\nplt.imshow(img_tensor[0])\n\nidx = random.choice(list(range(activations[0].shape[3])))\nvec = activations[0][0,:,:,idx]\nplt.subplot(5,4,5)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,9)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[1][0,:,:,idx]\nplt.subplot(5,4,13)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,17)\nplt.imshow(vec,cmap=\"viridis\")\n\nidx = random.choice(list(range(activations[2].shape[3])))\nvec = activations[2][0,:,:,idx]\nplt.subplot(5,4,6)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,10)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[3][0,:,:,idx]\nplt.subplot(5,4,14)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,18)\nplt.imshow(vec,cmap=\"viridis\")\n\nidx = random.choice(list(range(activations[4].shape[3])))\nvec = activations[4][0,:,:,idx]\nplt.subplot(5,4,7)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,11)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[5][0,:,:,idx]\nplt.subplot(5,4,15)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,19)\nplt.imshow(vec,cmap=\"viridis\")\n\nidx = random.choice(list(range(activations[6].shape[3])))\nvec = activations[6][0,:,:,idx]\nplt.subplot(5,4,8)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,12)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[7][0,:,:,idx]\nplt.subplot(5,4,16)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,20)\nplt.imshow(vec,cmap=\"viridis\")","e684e3e6":"gc.collect()\nlayer_names = [layer.name for layer in model.layers]\nimages_per_row = 16\nfor layer_name, layer_activation in zip(layer_names,activations):\n    n_features = layer_activation.shape[-1]\n    size = layer_activation.shape[1]\n    n_cols = n_features \/\/ images_per_row\n    display_grid = np.zeros((size*n_cols,images_per_row*size))\n    for col in range(n_cols):\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,:,:,col*images_per_row+row]\n            channel_image = ((channel_image - channel_image.mean())\/channel_image.std())*64+128\n            channel_image = np.clip(channel_image,0,255).astype(\"uint8\")\n            display_grid[col*size:(col+1)*size,row*size:(row+1)*size] = channel_image\n    scale = 1.\/size\n    plt.figure(figsize=(scale*display_grid.shape[1],scale*display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid,aspect=\"auto\",cmap=\"viridis\")","3efbb702":"gc.collect()\nimg_path = \"..\/working\/test\/cats\/\"+random.choice(os.listdir(\"..\/working\/test\/cats\"))\nimg = image.load_img(img_path,target_size=(150,150))\nimg_tensor = image.img_to_array(img)\nprint(img_tensor.shape)\nimg_tensor = np.expand_dims(img_tensor,axis=0)\nimg_tensor \/= 255.\nprint(img_tensor.shape)\n\nlayer_outputs = [layer.output for layer in model.layers[:8]] # \u53ea\u83b7\u53d6\u524d8\u5c42\uff0c\u4e5f\u5c31\u662f\u5377\u79ef\u5c42\u548c\u6700\u5927\u6c60\u5c42\u7684\u8f93\u51fa - \u4e2d\u95f4\u8f93\u51fa\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(img_tensor)\nfor i in range(len(activations)):\n    print(activations[i].shape) # \u8f93\u51fa\u7684shape\n\n\n# \u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u7b2c\u516b\u4e2a\u8fc7\u6ee4\u5668\nplt.figure(figsize=(15,20))\nplt.subplot(5,1,1)\nplt.imshow(img_tensor[0])\n\nidx = random.choice(list(range(activations[0].shape[3])))\nvec = activations[0][0,:,:,idx]\nplt.subplot(5,4,5)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,9)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[1][0,:,:,idx]\nplt.subplot(5,4,13)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,17)\nplt.imshow(vec,cmap=\"viridis\")\n\nidx = random.choice(list(range(activations[2].shape[3])))\nvec = activations[2][0,:,:,idx]\nplt.subplot(5,4,6)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,10)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[3][0,:,:,idx]\nplt.subplot(5,4,14)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,18)\nplt.imshow(vec,cmap=\"viridis\")\n\nidx = random.choice(list(range(activations[4].shape[3])))\nvec = activations[4][0,:,:,idx]\nplt.subplot(5,4,7)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,11)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[5][0,:,:,idx]\nplt.subplot(5,4,15)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,19)\nplt.imshow(vec,cmap=\"viridis\")\n\nidx = random.choice(list(range(activations[6].shape[3])))\nvec = activations[6][0,:,:,idx]\nplt.subplot(5,4,8)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,12)\nplt.imshow(vec,cmap=\"viridis\")\nvec = activations[7][0,:,:,idx]\nplt.subplot(5,4,16)\nplt.imshow(np.clip(((vec-vec.mean())\/vec.std())*64+128,0,255).astype(\"uint8\"),cmap=\"viridis\")\nplt.subplot(5,4,20)\nplt.imshow(vec,cmap=\"viridis\")","9bb8a82a":"gc.collect()\nlayer_names = [layer.name for layer in model.layers]\nimages_per_row = 16\nfor layer_name, layer_activation in zip(layer_names,activations):\n    n_features = layer_activation.shape[-1]\n    size = layer_activation.shape[1]\n    n_cols = n_features \/\/ images_per_row\n    display_grid = np.zeros((size*n_cols,images_per_row*size))\n    for col in range(n_cols):\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,:,:,col*images_per_row+row]\n            channel_image = ((channel_image - channel_image.mean())\/channel_image.std())*64+128\n            channel_image = np.clip(channel_image,0,255).astype(\"uint8\")\n            display_grid[col*size:(col+1)*size,row*size:(row+1)*size] = channel_image\n    scale = 1.\/size\n    plt.figure(figsize=(scale*display_grid.shape[1],scale*display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid,aspect=\"auto\",cmap=\"viridis\")","dc4c23f2":"# cat_output = model.output[:,0]\n# last_conv_layer = model.get_layer(\"conv2d_3\")\n# grads = K.gradients(cat_output,last_conv_layer.output)[0]\n# pooled_grads = K.mean(grads,axis=(0,1,2))\n# iterate = K.function([model.input],[pooled_grads,last_conv_layer.output[0]])\n# pooled_grads_value,conv_layer_output_value = iterate(img_tensor)\n# for i in range(512):\n#     conv_layer_output_value[:,:,i]*=pooled_grads_value[i]\n# heatmap = np.mean(conv_layer_output,axis=-1)\n# heatmap = np.maximum(heatmap,0)\n# heatmap \/= np.max(heatmap)\n# plt.matshow(heatmap)","019fe43a":"gc.collect()\n(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=10000) # \u83b7\u53d6\u51fa\u73b0\u6b21\u6570\u6700\u591a\u7684\u524d10000\u4e2a\u5355\u8bcd\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=100) # \u6587\u672c\u622a\u53d6\u524d20\u4e2a\u5355\u8bcd\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=100)\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","d515fa35":"# \u5229\u7528Embedding\u5c42\u5b66\u4e60\u8bcd\u5d4c\u5165\u5b57\u5178\n# \u5d4c\u5165\u5c42\u540e\u76f4\u63a5\u63a5\u5168\u8fde\u63a5\u5c42\u505a\u5206\u7c7b\u4efb\u52a1\uff0c\u7f3a\u9677\u5728\u4e8e\u6a21\u578b\u65e0\u6cd5\u5168\u9762\u7684\u8003\u8651token\u4e4b\u95f4\u7684\u5173\u7cfb\u4ee5\u53ca\u4e0a\u4e0b\u6587\u3001\u8bed\u5883\u7b49\uff0c\u800c\u662f\u4e00\u4e2a\u4e00\u4e2a\u7684\u9488\u5bf9\u5355\u4e2atoken\u505a\u8ba1\u7b97\n# you love i\u548ci love you\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u6a21\u578b\u65e0\u6cd5\u5206\u8fa8\u5176\u5dee\u5f02\nmodel = models.Sequential()\nmodel.add(layers.Embedding(10000,8,input_length=100)) # 10000\u4e3a\u4e0a\u8ff0\u7d22\u5f15\u6700\u5927\u503c+1\uff0c8\u4e3a\u5355\u4e2atoken\u5411\u91cf\u5316\u540e\u7684\u5411\u91cf\u957f\u5ea6\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=[\"acc\"])\n\nmodel.summary()","5d8e315f":"gc.collect()\nhistory = model.fit(x_train,y_train,epochs=10,batch_size=32,validation_split=.2)\nhistory_df = pd.DataFrame(history.history)\nhistory_df[[\"loss\",\"val_loss\"]].plot()","5d9a1df7":"history_df[[\"acc\",\"val_acc\"]].plot()","3acafbca":"gc.collect()\ntimesteps = 10\ninput_features = 8\noutput_features = 16\n\ninput_seq = np.random.random((timesteps,input_features))\n\nW = np.random.random((output_features,input_features))\nU = np.random.random((output_features,output_features))\nB = np.random.random((output_features,))\n\noutput_seq = []\nstate_t = np.zeros((output_features,))\nfor input_t in input_seq:\n    output_t = np.tanh(np.dot(W,input_t)+np.dot(U,state_t)+B)\n    output_seq.append(output_t)\n    state_t = output_t\n    \nprint(input_seq)\nprint(output_seq)","8f9115cf":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Embedding(10000,32))\nmodel.add(layers.SimpleRNN(32)) # \u6bcf\u4e2a\u5e8f\u5217\u7684\u5904\u7406\u53ea\u8f93\u51fa\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u5bf9\u5e94\u7684\u7ed3\u679c\nmodel.summary()","e24689e7":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Embedding(10000,32))\nmodel.add(layers.SimpleRNN(32,return_sequences=True)) # \u8f93\u51fa\u6240\u6709\u65f6\u95f4\u6b65\u7684\u7ed3\u679c\nmodel.summary()","465867e3":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Embedding(10000,32))\nmodel.add(layers.SimpleRNN(32,return_sequences=True)) # \u5806\u53e0\u5faa\u73af\u5c42\nmodel.add(layers.SimpleRNN(32,return_sequences=True))\nmodel.add(layers.SimpleRNN(32,return_sequences=True))\nmodel.add(layers.SimpleRNN(32))\nmodel.summary()","666a079e":"gc.collect()\nmax_features,maxlen,batch_size = 10000,500,32\n(input_train,y_train),(input_test,y_test) = imdb.load_data(num_words=max_features)\ninput_train = preprocessing.sequence.pad_sequences(input_train,maxlen=maxlen)\ninput_test = preprocessing.sequence.pad_sequences(input_test,maxlen=maxlen)\nprint(input_train.shape)\nprint(y_train.shape)\nprint(input_test.shape)\nprint(y_test.shape)","e6938892":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Embedding(max_features,32))\nmodel.add(layers.SimpleRNN(32))\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"acc\"])\n\nhistory = model.fit(input_train,y_train,epochs=10,batch_size=batch_size,validation_split=.2)","8f142a9b":"history_df = pd.DataFrame(history.history)\nhistory_df[[\"loss\",\"val_loss\"]].plot()","343bb0d6":"history_df[[\"acc\",\"val_acc\"]].plot()","a406b5c0":"gc.collect()\nmodel = models.Sequential()\nmodel.add(layers.Embedding(max_features,32))\nmodel.add(layers.LSTM(32)) # \u7f13\u89e3SimpleRNN\u4e2d\u7531\u4e8e\u68af\u5ea6\u6d88\u5931\u5bfc\u81f4\u7684\u65e0\u6cd5\u8bc6\u522b\u957f\u671f\u4f9d\u8d56\u95ee\u9898\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"acc\"])\n\nhistory = model.fit(input_train,y_train,epochs=10,batch_size=batch_size,validation_split=.2)","edc432fa":"history_df = pd.DataFrame(history.history)\nhistory_df[[\"loss\",\"val_loss\"]].plot()","fa51fb40":"history_df[[\"acc\",\"val_acc\"]].plot()","d1c01661":"jc_df = pd.read_csv(\"..\/input\/jena-climate-2009-2016\/jena_climate_2009_2016.csv\")\njc_df.head()","24b9875f":"jc_df[\"T (degC)\"].plot()","253047cd":"jc_df.iloc[:1440][\"T (degC)\"].plot() # \u6bcf\u5929144\u4e2a\u70b9\uff0c\u524d10\u5929\u6e29\u5ea6\u6570\u636e","47381930":"# \u6807\u51c6\u5316\nfloat_data = jc_df.drop(\"Date Time\",axis=1).values\nmean = float_data[:200000].mean(axis=0)\nfloat_data -= mean\nstd = float_data[:20000].std(axis=0)\nfloat_data \/= std\nfloat_data","7ed804a5":"# \u5229\u7528yield\u5173\u952e\u5b57\u6784\u5efa\u65f6\u95f4\u5e8f\u5217\u6837\u672c\u53ca\u5176target\u751f\u6210\u5668\ndef generator(data,lookback,delay,min_index,max_index,shuffle=False,batch_size=128,step=6):\n    '''\n    data\n    lookback\n    delay\n    min_index,max_index\n    shuffle\n    batch_size\n    step\n    '''\n    max_index = len(data)-delay-1 if max_index is None else max_index\n    i = min_index + lookback\n    while True:\n        if shuffle:\n            rows = np.random.randint(min_index+lookback,max_index,size=batch_size)\n        else:\n            i = min_index + lookback if i + batch_size >= max_index else i\n            rows = np.arange(i,min(i+batch_size,max_index))\n            i += len(rows)\n        samples = np.zeros((len(rows),lookback\/\/step,data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        for j,row in enumerate(rows):\n            indices = range(rows[j]-lookback,rows[j],step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j]+delay][1]\n        yield samples,targets","eabee169":"lookback,step,delay,batch_size = 1440,6,144,128\ntrain_gen = generator(data=float_data,lookback=lookback,delay=delay,min_index=0,max_index=200000,shuffle=True,step=step,batch_size=batch_size)\nval_gen = generator(data=float_data,lookback=lookback,delay=delay,min_index=200001,max_index=300000,shuffle=True,step=step,batch_size=batch_size)\ntest_gen = generator(data=float_data,lookback=lookback,delay=delay,min_index=300001,max_index=None,shuffle=True,step=step,batch_size=batch_size)\n\nval_steps = (300000-200001-lookback) \/\/ batch_size\ntest_steps = (len(float_data)-300001-lookback) \/\/ batch_size","1e9d0da6":"# naive method\ndef evaluate_naive_method():\n    batch_maes = []\n    for step in range(val_steps):\n        samples,targets = next(val_gen)\n        preds = samples[:,-1,1]\n        mae = np.mean(np.abs(preds-targets))\n        batch_maes.append(mae)\n    print(\"naive method mae=\",np.mean(batch_maes))\nevaluate_naive_method()","a499a624":"# \u5bc6\u96c6\u8fde\u63a5\u7f51\u7edc\u6a21\u578b\nmodel = models.Sequential()\nmodel.add(layers.Flatten(input_shape=(lookback\/\/step,float_data.shape[-1])))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=optimizers.RMSprop(),loss='mae')\nhistory = model.fit_generator(train_gen,steps_per_epoch=500,epochs=20,validation_data=val_gen,validation_steps=val_steps)","19b738d4":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot()","9e373867":"# RNN GRU\u57fa\u51c6\u6a21\u578b\nmodel = models.Sequential()\nmodel.add(layers.GRU(32,input_shape=(None,float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=optimizers.RMSprop(),loss='mae')\nhistory = model.fit_generator(train_gen,steps_per_epoch=500,epochs=20,validation_data=val_gen,validation_steps=val_steps)","6527c18d":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot()","831c7255":"# RNN GRU+Dropout\nmodel = models.Sequential()\nmodel.add(layers.GRU(32,dropout=.2,recurrent_dropout=.2,input_shape=(None,float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=optimizers.RMSprop(),loss='mae')\nhistory = model.fit_generator(train_gen,steps_per_epoch=500,epochs=20,validation_data=val_gen,validation_steps=val_steps)","ec5d8a3c":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot()","362e76fa":"# RNN GRU\u5806\u53e0+Dropout\nmodel = models.Sequential()\nmodel.add(layers.GRU(32,dropout=.1,recurrent_dropout=.5,return_sequence=True,input_shape=(None,float_data.shape[-1])))\nmodel.add(layers.GRU(64,activation='relu',dropout=.1,recurrent_dropout=.5))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=optimizers.RMSprop(),loss='mae')\nhistory = model.fit_generator(train_gen,steps_per_epoch=500,epochs=20,validation_data=val_gen,validation_steps=val_steps)","8fa27ae1":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot()","e652e931":"# Sequential\u6784\u5efa\u7684\u90fd\u662f\u7ebf\u6027\u5806\u53e0\u5c42\u7684\u6a21\u578b\uff0c\u7ed3\u6784\u7b80\u5355\u660e\u4e86\uff0c\u5355\u8f93\u5165\u5355\u8f93\u51fa\uff1b\n# Keras\u51fd\u6570\u5f0fAPI\u53ef\u4ee5\u6784\u5efa\u7c7b\u56fe\u7ed3\u6784\u6a21\u578b\uff0c\u4e14\u652f\u6301\u591a\u8f93\u5165\u3001\u591a\u8f93\u51fa\uff1b\n# \u591a\u6a21\u6001\u8f93\u5165\uff1a\u6587\u672c\u3001\u7ed3\u6784\u5316\u6570\u636e\u3001\u56fe\u7247\u5171\u540c\u670d\u52a1\u4e8e\u4e00\u4e2a\u4efb\u52a1\uff1b\n\ninput_tensor = Input(shape=(64,))\nx = layers.Dense(32,activation=\"relu\",input_shape=(64,))(input_tensor)\nx = layers.Dense(32,activation=\"relu\")(x)\noutput_tensor = layers.Dense(10,activation=\"softmax\")(x)\n\nmodel = models.Model(input_tensor,output_tensor)\nmodel.summary()\n\nmodel.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\")\n\nx_train = np.random.random((1000,64))\ny_train = np.random.random((1000,10))\nmodel.fit(x_train,y_train,epochs=10,batch_size=128)\nmodel.evaluate(x_train,y_train)","5de0c441":"def reweight_distribution(distribution, temperature=.5):\n    distribution = np.log(distribution)\/temperature\n    distribution = np.exp(distribution)\n    return distribution\/np.sum(distribution)","c42c57a8":"arr = np.array([0.1,0.2,0.3,0.4])\nprint(arr)\nprint(reweight_distribution(arr,.01))\nprint(reweight_distribution(arr,.1))\nprint(reweight_distribution(arr,.5))\nprint(reweight_distribution(arr,.8))\nprint(reweight_distribution(arr,1.))","5a49bff0":"# VAE\u7f16\u7801\u5668\u7f51\u7edc\nimg_shape = (28,28,1)\nbatch_size = 16\nlatent_dim = 2 # \u6f5c\u5728\u7a7a\u95f4\u7ef4\u5ea6\n\ninput_img = Input(shape=img_shape)\nx = layers.Conv2D(32,3,padding=\"same\",activation=\"relu\")(input_img)\nx = layers.Conv2D(64,3,padding=\"same\",activation=\"relu\",strides=(2,2))(x)\nx = layers.Conv2D(64,3,padding=\"same\",activation=\"relu\")(x)\nx = layers.Conv2D(64,3,padding=\"same\",activation=\"relu\")(x)\nshape_before_flattening = K.int_shape(x)\nx = layers.Flatten()(x)\nx = layers.Dense(32,activation=\"relu\")(x)\nz_mean = layers.Dense(latent_dim)(x) # \u8f93\u5165\u56fe\u50cf\u6700\u7ec8\u88ab\u7f16\u7801\u5668\u7f16\u7801\u4e3az_mean\u548cz_log_var\u4e24\u4e2a\u53c2\u6570\nz_log_var = layers.Dense(latent_dim)(x)","e3059d11":"# # VAE\u7f16\u7801\u5668\u7f51\u7edc\n# img_shape = (500,1)\n# batch_size = 16\n# latent_dim = 2 # \u6f5c\u5728\u7a7a\u95f4\u7ef4\u5ea6\n\n# input_img = Input(shape=img_shape)\n# x = layers.Conv1D(32,3,padding=\"same\",activation=\"relu\")(input_img)\n# x = layers.Conv1D(64,3,padding=\"same\",activation=\"relu\",strides=2)(x)\n# x = layers.Conv1D(64,3,padding=\"same\",activation=\"relu\")(x)\n# x = layers.Conv1D(64,3,padding=\"same\",activation=\"relu\")(x)\n# shape_before_flattening = K.int_shape(x)\n# x = layers.Flatten()(x)\n# x = layers.Dense(32,activation=\"relu\")(x)\n# z_mean = layers.Dense(latent_dim)(x) # \u8f93\u5165\u56fe\u50cf\u6700\u7ec8\u88ab\u7f16\u7801\u5668\u7f16\u7801\u4e3az_mean\u548cz_log_var\u4e24\u4e2a\u53c2\u6570\n# z_log_var = layers.Dense(latent_dim)(x)","7fa66334":"# \u6f5c\u5728\u7a7a\u95f4\u7684\u91c7\u6837\u51fd\u6570\n# \u4f7f\u7528z_mean\u548cz_log_var\u751f\u6210\u7a7a\u95f4\u4e2d\u7684\u4e00\u4e2a\u70b9\ndef sampling(args):\n    z_mean_,z_log_var_ = args\n    epsilon = K.random_normal(shape=(K.shape(z_mean_)[0],latent_dim),mean=0.,stddev=1.)\n    return z_mean_ + K.exp(.5*z_log_var_) * epsilon\nz = layers.Lambda(sampling)([z_mean,z_log_var])","0bd37c65":"# # \u6f5c\u5728\u7a7a\u95f4\u7684\u91c7\u6837\u51fd\u6570\n# # \u4f7f\u7528z_mean\u548cz_log_var\u751f\u6210\u7a7a\u95f4\u4e2d\u7684\u4e00\u4e2a\u70b9\n# def sampling(args):\n#     z_mean_,z_log_var_ = args\n#     epsilon = K.random_normal(shape=(K.shape(z_mean_)[0],latent_dim),mean=0.,stddev=1.)\n#     return z_mean_ + K.exp(.5*z_log_var_) * epsilon\n# z = layers.Lambda(sampling)([z_mean,z_log_var])","58931bd2":"# VAE\u89e3\u7801\u5668\u7f51\u7edc\uff0c\u5c06\u6f5c\u5728\u7a7a\u95f4\u7684\u70b9\u6620\u5c04\u4e3a\u56fe\u50cf\ndecoder_input = Input(K.int_shape(z)[1:])\nx = layers.Dense(np.prod(shape_before_flattening[1:]),activation=\"relu\")(decoder_input)\nx = layers.Reshape(shape_before_flattening[1:])(x)\nx = layers.Conv2DTranspose(32,3,padding=\"same\",activation=\"relu\",strides=(2,2))(x)\nx = layers.Conv2D(1,3,padding=\"same\",activation=\"sigmoid\")(x)\ndecoder = models.Model(decoder_input,x)\nz_decoded = decoder(z) # \u7f16\u7801\u5668\u4e0e\u89e3\u7801\u5668\u7ec4\u5408","59e1a223":"# # VAE\u89e3\u7801\u5668\u7f51\u7edc\uff0c\u5c06\u6f5c\u5728\u7a7a\u95f4\u7684\u70b9\u6620\u5c04\u4e3a\u56fe\u50cf\n# decoder_input = Input(K.int_shape(z)[1:])\n# x = layers.Dense(np.prod(shape_before_flattening[1:]),activation=\"relu\")(decoder_input)\n# x = layers.Reshape(shape_before_flattening[1:])(x)\n# x = layers.Conv1DTranspose(32,3,padding=\"same\",activation=\"relu\",strides=2)(x)\n# x = layers.Conv1D(1,3,padding=\"same\",activation=\"sigmoid\")(x)\n# decoder = models.Model(decoder_input,x)\n# z_decoded = decoder(z) # \u7f16\u7801\u5668\u4e0e\u89e3\u7801\u5668\u7ec4\u5408","8cec0f95":"# \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u5c42\nclass CustomVariationalLayer(keras.layers.Layer):\n    def vae_loss(self,x,z_decoded,z_mean,z_log_var):\n        x = K.flatten(x)\n        z_decoded = K.flatten(z_decoded)\n        xent_loss = keras.metrics.binary_crossentropy(x,z_decoded)\n        k1_loss = -5e-4 * K.mean(1+z_log_var-K.square(z_mean)-K.exp(z_log_var),axis=-1)\n        return K.mean(xent_loss+k1_loss)\n    def call(self,inputs):\n        x,z_decoded,z_mean,z_log_var = inputs\n        loss = self.vae_loss(x,z_decoded,z_mean,z_log_var)\n        self.add_loss(loss,inputs=inputs)\n        return x\n\ny = CustomVariationalLayer()([input_img,z_decoded,z_mean,z_log_var])","53b20c63":"# # \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u5c42\n# class CustomVariationalLayer(keras.layers.Layer):\n#     def vae_loss(self,x,z_decoded,z_mean,z_log_var):\n#         x = K.flatten(x)\n#         z_decoded = K.flatten(z_decoded)\n#         xent_loss = keras.metrics.binary_crossentropy(x,z_decoded)\n#         k1_loss = -5e-4 * K.mean(1+z_log_var-K.square(z_mean)-K.exp(z_log_var),axis=-1)\n#         return K.mean(xent_loss+k1_loss)\n#     def call(self,inputs):\n#         x,z_decoded,z_mean,z_log_var = inputs\n#         loss = self.vae_loss(x,z_decoded,z_mean,z_log_var)\n#         self.add_loss(loss,inputs=inputs)\n#         return x\n\n# y = CustomVariationalLayer()([input_img,z_decoded,z_mean,z_log_var])","522bbbae":"# \u5b9e\u4f8b\u5316\u6a21\u578b\u5e76\u8bad\u7ec3\uff0c\u4e0d\u9700\u8981\u6307\u5b9aloss\uff0c\u4e5f\u4e0d\u9700\u8981y_train\nvae = models.Model(input_img,y)\nvae.compile(optimizer=\"RMSprop\",loss=None)\nvae.summary()","7c60b265":"gc.collect()\n(x_train,_),(x_test,y_test) = mnist.load_data()\nx_train = x_train.astype(\"float32\") \/ 255.\nx_train = x_train.reshape(x_train.shape+(1,))\nx_test = x_test.astype(\"float32\") \/ 255.\nx_test = x_test.reshape(x_test.shape+(1,))\n\nvae.fit(x=x_train,y=None,shuffle=True,epochs=10,batch_size=batch_size,validation_data=(x_test,None))","7f2f8138":"# gc.collect()\n# max_features,maxlen,batch_size = 10000,500,32\n# (x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=max_features)\n# x_train = preprocessing.sequence.pad_sequences(input_train,maxlen=maxlen)\n# x_test = preprocessing.sequence.pad_sequences(input_test,maxlen=maxlen)\n# print(x_train.shape)\n# print(y_train.shape)\n# print(x_test.shape)\n# print(y_test.shape)\n\n# vae.fit(x=x_train,y=None,shuffle=True,epochs=10,batch_size=batch_size,validation_data=(x_test,None))","393252a5":"# n=15\n# print(np.linspace(0.05,0.95,n)) # \u83b7\u53d6a\u5230b\u7684n\u7b49\u5206\u96c6\u5408\n# print(norm.ppf(np.linspace(0.05,0.95,n))) # ppf\uff1a\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u7684\u9006\u51fd\u6570\uff0c\u8fd4\u56de\u4f20\u5165x\u5bf9\u5e94\u7684\u6b63\u6001\u5206\u5e03\u7684x\u8f74\u5750\u6807\uff0c0\u5bf9\u5e940.5\uff0c\u4e24\u4fa7\u4f9d\u6b21\u7c7b\u63a8","b20ee86d":"# \u4ece\u6f5c\u5728\u7a7a\u95f4\u91c7\u6837\uff0c\u89e3\u7801\u6210\u56fe\u50cf\nn = 15\ndigit_size = 28\nfigure = np.zeros((digit_size*n, digit_size*n))\ngrid_x = norm.ppf(np.linspace(0.05,0.95,n))\ngrid_y = norm.ppf(np.linspace(0.05,0.95,n))\nfor i,yi in enumerate(grid_x):\n    for j,xi in enumerate(grid_y):\n        z_sample = np.array([[xi,yi]])\n        z_sample = np.tile(z_sample,batch_size).reshape(batch_size,2)\n        x_decoded = decoder.predict(z_sample,batch_size=batch_size)\n        digit = x_decoded[0].reshape(digit_size,digit_size)\n        figure[i*digit_size:(i+1)*digit_size,j*digit_size:(j+1)*digit_size] = digit\n\nplt.figure(figsize=(10,10))\nplt.imshow(figure,cmap=\"Greys_r\")","22653395":"# # \u4ece\u6f5c\u5728\u7a7a\u95f4\u91c7\u6837\uff0c\u89e3\u7801\u6210\u6587\u672c\n# n = 15\n# digit_size = maxlen\n# figure = np.zeros((digit_size*n, digit_size*n))\n# grid_x = norm.ppf(np.linspace(0.05,0.95,n))\n# grid_y = norm.ppf(np.linspace(0.05,0.95,n))\n# for i,yi in enumerate(grid_x):\n#     for j,xi in enumerate(grid_y):\n#         z_sample = np.array([[xi,yi]])\n#         z_sample = np.tile(z_sample,batch_size).reshape(batch_size,2)\n#         x_decoded = decoder.predict(z_sample,batch_size=batch_size)\n#         digit = x_decoded[0].reshape(digit_size,)\n#         print(digit)\n#         break\n#     break","4f434650":"xi,yi = norm.ppf([0.95,0.05])\nprint(xi,yi)\nz_sample = np.array([[xi,yi]])\nz_sample = np.tile(z_sample,batch_size).reshape(batch_size,2)\nx_decoded = decoder.predict(z_sample,batch_size=batch_size)\ndigit = x_decoded[0].reshape(digit_size,digit_size)\nplt.imshow(digit,cmap=\"Greys_r\")","a43bb43d":"xi,yi = norm.ppf([0.85,0.15])\nprint(xi,yi)\nz_sample = np.array([[xi,yi]])\nz_sample = np.tile(z_sample,batch_size).reshape(batch_size,2)\nx_decoded = decoder.predict(z_sample,batch_size=batch_size)\ndigit = x_decoded[0].reshape(digit_size,digit_size)\nplt.imshow(digit,cmap=\"Greys_r\")","f91ddd01":"xi,yi = norm.ppf([0.75,0.25])\nprint(xi,yi)\nz_sample = np.array([[xi,yi]])\nz_sample = np.tile(z_sample,batch_size).reshape(batch_size,2)\nx_decoded = decoder.predict(z_sample,batch_size=batch_size)\ndigit = x_decoded[0].reshape(digit_size,digit_size)\nplt.imshow(digit,cmap=\"Greys_r\")","5e07dd30":"## \u751f\u6210\u5f0f\u6df1\u5ea6\u5b66\u4e60\n\n\u987e\u540d\u601d\u4e49\uff0c\u4e0d\u662f\u7528\u4e8e\u88ab\u52a8\u6027\uff08\u76ee\u6807\u8bc6\u522b\uff09\u3001\u53cd\u5e94\u6027\uff08\u9a7e\u9a76\u6c7d\u8f66\uff09\uff0c\u800c\u662f\u521b\u9020\u6027\u7684\u4efb\u52a1\uff1b","d7cc708f":"## \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u4e8e\u65f6\u5e8f\u5e8f\u5217\n\n- \u5faa\u73afdropout\uff1b\n- \u5806\u53e0\u5faa\u73af\u5c42\uff1b\n- \u53cc\u5411\u5faa\u73af\uff1b\n\n\u65f6\u5e8f\u5e8f\u5217\u95ee\u9898\u62bd\u8c61\uff1a\n1. \u8bbetimestep=10min\uff0c\u6bcf\u4e2astep\u91c7\u96c6\u4e00\u6b21\u6570\u636e\uff1b\n2. \u7ed9\u5b9alookback\u4e2astep\u4e4b\u5185\u7684\u6570\u636e\uff1b\n3. \u80fd\u591f\u9884\u6d4bdelay\u4e2astep\u4e4b\u540e\u7684\u67d0\u4e2atarget\uff1b","ed60e80c":"## \u8bc4\u4f30\u6a21\u578b\n\n1. \u6570\u636e\u4ee3\u8868\u6027\uff1a\u4e0d\u5e73\u8861\u7c7b\u522b\u7684\u6309\u6bd4\u4f8b\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff1b\n2. \u65f6\u95f4\u7bad\u5934\uff1a\u65f6\u5e8f\u6570\u636e\u6309\u65f6\u95f4\u524d\u540e\u5212\u5206\uff1b\n3. \u6570\u636e\u5197\u4f59\uff1a\u907f\u514d\u8bad\u7ec3\u96c6\u4e0e\u9a8c\u8bc1\u96c6\u4e2d\u51fa\u73b0\u91cd\u590d\u6570\u636e\uff0c\u8fd9\u4e2a\u7ed3\u679c\u7c7b\u4f3c\u6570\u636e\u6cc4\u9732\uff1b\n\n## \u795e\u7ecf\u7f51\u7edc\u7684\u6570\u636e\u9884\u5904\u7406\n\n1. \u5411\u91cf\u5316\n2. \u6807\u51c6\u5316\n3. \u7f3a\u5931\u3001\u5f02\u5e38\u5904\u7406\n\n## \u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u5de5\u7a0b\n\n1. \u63d0\u9ad8\u6a21\u578b\u8fd0\u884c\u901f\u5ea6\uff1b\n2. \u51cf\u5c11\u6a21\u578b\u4f9d\u8d56\u7684\u6570\u636e\u91cf\uff1b\n\n\u56e0\u6b64\u5bf9\u4e8eDL\uff0c\u7279\u5f81\u5de5\u7a0b\u4f9d\u7136\u662f\u6709\u7528\u7684\uff1b\n\n## \u8fc7\u6b20\u62df\u5408\n\n\u6a21\u578b\u5bf9\u4e8e\u6570\u636e\u4e2d\u7684\u8868\u793a\u7684\u5b66\u4e60\u662f\u4e0d\u8db3\u8fd8\u662f\u8fc7\u591a\uff1b\n\n\u6b63\u5219\u5316\uff1a\u9650\u5236\u6a21\u578b\u5b58\u50a8\u7684\u4fe1\u606f\u91cf\uff0c\u6216\u5bf9\u5176\u52a0\u4ee5\u7ea6\u675f\uff1b\n\n\u624b\u6bb5\uff1a\n1. \u51cf\u5c11\u7f51\u7edc\u5927\u5c0f\uff0c\u4e5f\u5c31\u51cf\u5c11\u4e86\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u4e2a\u6570\uff0c\u4e5f\u5c31\u51cf\u5c11\u4e86\u5b58\u50a8\u7684\u4fe1\u606f\u91cf\uff0c\u9650\u5236\u4e86\u8868\u793a\u7a7a\u95f4\uff1b\n2. \u6dfb\u52a0\u6743\u91cd\u6b63\u5219\u5316\uff1b\n3. \u589e\u52a0dropout\u6b63\u5219\u5316\uff1a\u8bad\u7ec3\u4e2d\uff0c\u6bcf\u5c42\u7684\u8f93\u51fa\u4e2d\u6709\u4e00\u5b9a\u6bd4\u4f8b\u7684\u7279\u5f81\u88ab\u4e22\u5f03\uff0c\u5373\u8bbe\u7f6e\u4e3a0\uff0c\u4e00\u822c0.2\u52300.5\u4e4b\u95f4\uff0c\u6ce8\u610f\u6d4b\u8bd5\u65f6\uff0c\u5219\u4e0d\u4f1a\u8fdb\u884c\u4e22\u5f03\uff0c\u56e0\u6b64\u6b64\u65f6\u7684\u8f93\u51fa\u9700\u8981\u6309drop\u6bd4\u4f8b\u7f29\u5c0f\uff0c\u56e0\u6b64\u6d4b\u8bd5\u4e2d\u6bd4\u8bad\u7ec3\u4e2d\u6709\u66f4\u591a\u7684\u5355\u5143\u88ab\u6fc0\u6d3b\uff0c\u9700\u8981\u7f29\u5c0f\u5e73\u8861\u5904\u7406\uff08PS\uff1a\u8fd9\u4e24\u4e2a\u8ba1\u7b97\u8fc7\u7a0b\u5982\u679c\u90fd\u653e\u5230\u8bad\u7ec3\u4e2d\u505a\uff0c\u5219\u6d4b\u8bd5\u65f6\u4e0d\u9700\u8981\u7f29\u5c0f\u5904\u7406\uff0c\u5f53\u7136\u5728\u8bad\u7ec3\u4e2d\u5219\u662f\u6309\u6bd4\u4f8b\u653e\u5927\uff09\uff1b\n\nDropout\u601d\u60f3\uff1a\u5728\u5c42\u7684\u8f93\u51fa\u4e2d\u4eba\u5de5\u5f15\u5165\u566a\u58f0\uff0c\u4ee5\u6253\u7834\u90a3\u4e9b\u4e0d\u663e\u8457\u7684\u3001\u5076\u7136\u53d1\u73b0\u7684\u8868\u793a\/\u6a21\u5f0f\uff0c\u4ee5\u6b64\u5b9e\u73b0\u964d\u4f4e\u8fc7\u62df\u5408\uff0c\u91cd\u8981\u7684\u8868\u793a\u7406\u5e94\u662f\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u7684\uff1b\n\n## DL\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\n\n\u9488\u5bf9\u4e0d\u7528\u7684\u573a\u666f\u4e1a\u52a1\uff0c\u4e0d\u540c\u7c7b\u578b\uff08\u4e0d\u540c\u9636\u7684\u5f20\u91cf\uff09\u6570\u636e\uff0c\u9700\u8981\u4f7f\u7528\u4e0d\u540c\u7684\u7f51\u7edc\u62d3\u6251\u67b6\u6784+\u795e\u7ecf\u5c42\u6765\u6784\u5efa\u6a21\u578b\uff0c\u4f8b\u5982\u666e\u904d\u7528\u4e8eCV\u9886\u57df\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1b","41aaa0b0":"## \u53d8\u5206\u81ea\u7f16\u7801\u5668VAE\u4e0e\u751f\u6210\u5f0f\u5bf9\u6297\u7f51\u7edcGAN","8b522069":"## \u5faa\u73af\u795e\u7ecf\u7f51\u7edc - RNN\n\n\u5faa\u73af\u7684\u76ee\u7684\u5728\u4e8e\u4e00\u6b65\u4e00\u6b65\u7684\u8ba1\u7b97\u65f6\u95f4\u6b65\u5185\u7ed3\u679c\u5e76\u4f5c\u4e3a\u72b6\u6001\u5411\u540e\u4f20\u9012\uff0c\u5faa\u73af\u4f5c\u7528\u4e8e\u5355\u4e2a\u8f93\u5165\u5e8f\u5217\u4e0a\uff08\u7c7b\u4f3c\u4eba\u773c\u626b\u8fc7\u4e00\u5927\u6bb5\u8bdd\u65f6\uff0c\u4f1a\u4e00\u5c0f\u6bb5\u4e00\u5c0f\u6bb5\u7684\u770b\uff0c\u540c\u65f6\u5927\u8111\u4e2d\u7684\u5185\u5bb9\u6a21\u578b\u4f1a\u6839\u636e\u5df2\u7ecf\u770b\u8fc7\u7684\u5185\u5bb9\u5b9e\u65f6\u66f4\u65b0\uff0c\u6700\u540e\u770b\u5b8c\u6574\u53e5\u8bdd\uff0c\u5e76\u7406\u89e3\u4e86\u5b83\u7684\u610f\u601d\uff09\uff0c\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u5e8f\u5217\u4e4b\u95f4\uff0c\u72b6\u6001\u4f1a\u88ab\u91cd\u7f6e\uff1b\n\n- SimpleRNN\uff1a\u6700\u7b80\u5355\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0cSimpleRNN\u7684\u95ee\u9898\u5728\u4e8e\u5f53\u5904\u4e8e\u65f6\u523bt\uff0c\u7406\u8bba\u8bf4\uff0c\u6b64\u65f6\u6a21\u578b\u5e94\u8be5\u8bb0\u4f4f\u6240\u6709\u4e4b\u524d\u7684\u65f6\u95f4\u6b65\u89c1\u8fc7\u7684\u4fe1\u606f\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u5b83\u4e0d\u53ef\u80fd\u5b66\u4e60\u5230\u8fd9\u79cd**\u957f\u671f\u4f9d\u8d56**\uff0c\u539f\u56e0\u5728\u4e8e**\u68af\u5ea6\u6d88\u5931\u95ee\u9898**\uff1b\n- LSTM\uff1a\u957f\u77ed\u671f\u8bb0\u5fc6\uff0c\u662fSimpleRNN\u7684\u4e00\u79cd\u53d8\u4f53\uff0c\u7b80\u5355\u5730\u8bf4\u5b83\u589e\u52a0\u4e86\u4e00\u79cd\u53ef\u4ee5\u8de8\u8d8a\u591a\u4e2a\u65f6\u95f4\u6b65\u4f20\u9012\u4fe1\u606f\u7684\u673a\u5236\uff0c\u4ee5\u89e3\u51b3SimpleRNN\u7684\u957f\u671f\u4f9d\u8d56\u6355\u83b7\u4e0d\u5230\u7684\u95ee\u9898\uff1b\n- GRU\uff1a\n\nRNN\u9ad8\u7ea7\u7528\u6cd5\uff1a\n- \u5faa\u73afdropout\uff1a\n- \u5806\u53e0\u5faa\u73af\u5c42\uff1a\n- \u53cc\u5411\u5faa\u73af\uff1a","e1ff733b":"## \u7535\u5f71\u8bc4\u8bba\u60c5\u611f\u5206\u7c7b\n\n- \u6570\u636e\u6e90\uff1aIMDB\uff1b\n- \u7279\u70b9\uff1a\u8bc4\u8bba\u5411\u91cf\u957f\u5ea6\u4e0d\u4e00\uff0c\u8fd9\u4e2a\u957f\u5ea6\u5bf9\u5e94\u7684\u662f\u8bc4\u8bba\u6587\u672c\u7684\u957f\u5ea6\uff1b\n\n\u6574\u6570\u5e8f\u5217\u9700\u8981\u5904\u7406\u540e\u518d\u9001\u5165\u7f51\u7edc\uff1a\n- \u65b9\u6cd51\uff1a\u586b\u5145\u5e8f\u5217\uff0c\u4f7f\u5176\u5177\u6709\u76f8\u7b49\u7684\u957f\u5ea6\uff0c\u7136\u540e\u9001\u5165Embedding\u5c42\uff1b\n- \u65b9\u6cd52\uff1aone-hot\u5904\u7406\uff0c\u6bcf\u4e2a\u5e8f\u5217\u8f6c\u4e3a\u957f\u5ea6\u4e3a10000\uff08num_words\uff09\u7684\u5411\u91cf\uff0c\u7136\u540e\u9001\u5165Dense\u5c42\u5904\u7406\uff1b","3a328d41":"## \u65b0\u95fb\u591a\u5206\u7c7b\n\n\u5355\u6807\u7b7e\u3001\u591a\u5206\u7c7b\u95ee\u9898\uff1b","30afac9d":"# Python Deep Learning\n\nNotebook\u5185\u5bb9\u5168\u90e8\u6765\u6e90\u4e8e\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\uff0c\u6db5\u76d6\u4e66\u4e2d\u5168\u90e8\u5185\u5bb9\uff0c\u4ee5\u7ec3\u4e60\u4e3a\u4e3b\uff0c\u7406\u8bba\u77e5\u8bc6\u8f83\u5c11\uff0c\u8be5\u4e66\u4f5c\u8005\uff1aFrancois Chollet\uff0c\u5373Keras\u4e4b\u7236\uff0c\u8be5\u4e66\u8bd1\u8005\uff1a\u5f20\u4eae\uff1b","c1f4d7ca":"The end.\nFrom SIBAT.","4fad6aab":"## \u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53ef\u89c6\u5316\n\n\u5bf9\u4e8e\u89c6\u89c9\u4e16\u754c\u4efb\u52a1\uff0c\u76f8\u5173\u53ef\u89c6\u5316\u65b9\u6cd5\u751a\u81f3\u8981\u597d\u4e8e\u4eba\u5de5\u7279\u5f81\u5de5\u7a0b\u7684\u53ef\u89c6\u5316\u6548\u679c\uff0c\u8fd9\u4e0e\u89c6\u89c9\u4e16\u754c\u7684\u5e73\u79fb\u4e0d\u53d8\u3001\u5c42\u6b21\u7a7a\u95f4\u7b49\u7279\u6027\u4e0e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u8868\u793a\u7279\u5f81\u60f3\u7b26\u5408\u6709\u5f88\u5927\u5173\u7cfb\uff0c\u540c\u6837\u7684\u7ed3\u6784\u7528\u4e8e\u5176\u4ed6\u4efb\u52a1\uff0c\u53ef\u89c6\u5316\u6548\u679c\u53ef\u80fd\u5c31\u6ca1\u8fd9\u4e48\u7406\u60f3\uff1b\n\n- \u5377\u79ef\u6838\u8f93\u51fa\u7ed3\u679c\u53ef\u89c6\u5316\uff08\u6df1\u5ea6\u4e3aN\u4e2a\u8fc7\u6ee4\u5668\uff09\uff1b\n","5be4d179":"## \u9ad8\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6700\u4f73\u5b9e\u8df5\n\n- Keras\u51fd\u6570\u5f0fAPI\uff1b\n- Keras\u56de\u8c03\u51fd\u6570\uff1b\n- TensorBoard\u53ef\u89c6\u5316\u5de5\u5177\uff1b\n- \u5f00\u53d1\u5148\u8fdb\u6a21\u578b\u7684\u91cd\u8981\u6700\u4f73\u5b9e\u8df5\uff1b\n    - \u9ad8\u7ea7\u67b6\u6784\u6a21\u5f0f\uff1a\n        1. \u6279\u6807\u51c6\u5316\uff1b\n        2. \u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff1b\n        3. \u6b8b\u5dee\u8fde\u63a5\uff1b\n    - \u8d85\u53c2\u6570\u4f18\u5316\uff1b\n    - \u96c6\u6210\u6a21\u578b\uff1b\n\n\u591a\u6a21\u6001\u6570\u636e\u8f93\u5165\uff1a\n- \u6784\u5efa\u591a\u4e2a\u6a21\u578b\uff0c\u6bcf\u4e2a\u6a21\u578b\u5904\u7406\u4e00\u79cd\u8f93\u5165\uff0c\u6700\u540e\u7ed3\u679c\u52a0\u6743\u878d\u5408 - \u7f3a\u70b9\uff1a\u591a\u4e2a\u6a21\u578b\u5b66\u4e60\u7684\u5185\u5bb9\u53ef\u80fd\u662f\u4e92\u76f8\u5197\u4f59\u7684\uff0c\u6570\u636e\u5206\u6563\u964d\u4f4e\u4e86\u5047\u8bbe\u7a7a\u95f4\u7684\u53ef\u80fd\u6027\uff1b\n- \u6784\u5efa\u5355\u4e2a\u6a21\u578b\u540c\u65f6\u5904\u7406\u591a\u4e2a\u8f93\u5165 - \u4f18\u70b9\uff1a\u4e0d\u9700\u8981\u989d\u5916\u5904\u7406\u7ed3\u679c\uff0c\u5bf9\u6570\u636e\u7684\u4f7f\u7528\u5145\u5206\u4e14\u4e0d\u4f1a\u5197\u4f59\uff1b\n\n\u591a\u4efb\u52a1\u8f93\u51fa\uff1a\n- \u6784\u5efa\u591a\u4e2a\u6a21\u578b - \u7f3a\u70b9\uff1a\u4f1a\u6709\u91cd\u590d\u5de5\u4f5c\u91cf\uff0c\u6570\u636e\u7279\u5f81\u4e92\u76f8\u662f\u76f8\u5173\u7684\uff1b\n- \u6784\u5efa\u5355\u4e2a\u6a21\u578b\u8f93\u51fa\u591a\u4e2a\u4efb\u52a1\u8f93\u51fa - \u4f18\u70b9\uff1a\u4efb\u52a1\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u4f7f\u5f97\u6a21\u578b\u6d45\u5c42\u8868\u793a\u4f1a\u5bf9\u5404\u4e2a\u4efb\u52a1\u90fd\u6709\u7528\uff1b","3c549a65":"## DL\u5e94\u7528\u4e8e\u5e8f\u5217\u95ee\u9898\n\n- \u6587\u672c\u5e8f\u5217\uff1b\n- \u65f6\u95f4\u5e8f\u5217\uff1b\n- \u5176\u4ed6\u5e8f\u5217\uff1b\n\n\u5e8f\u5217\u95ee\u9898\u7279\u70b9\uff1a\u5e8f\u5217\u5143\u7d20\u524d\u540e\u5173\u7cfb\u3001\u4e0a\u4e0b\u6587\u3001\u5386\u53f2\u4f9d\u8d56\u6027\uff1b\n\n\u5bf9\u4e8e\u6587\u672c\u5e8f\u5217\u7ec4\u6210\u5355\u5143\uff1a\n- \u5b57\uff1b\n- \u8bcd\uff1b\n- n-grams\uff0c\u8bcd\u7ec4\u5bf9\uff1b\n\u79f0\u4e3atoken\uff0c\u5206\u8bcd\u66f4\u4e00\u822c\u7684\u6307\u7684\u662f\u5c06\u6587\u672c\u8f6c\u4e3atoken\u96c6\u5408\uff0c\u53ea\u4e0d\u8fc7\u4e00\u822c\u503c\u5f97\u662f\u5206\u4e3a**\u8bcd**\u7684\u96c6\u5408\uff1b\n\n\u6587\u672c\u6570\u636e\u5411\u91cf\u5316\uff1a\n- one-hot\uff1b\n- token\u5d4c\u5165\uff08\u4e00\u822c\u6307\u8bcd\u5d4c\u5165\uff09\uff1b","4f3e4bab":"## \u5377\u79ef\u795e\u7ecf\u7f51\u7edc - \u732b\u72d7\u5206\u7c7b\n\n- \u5c0f\u578b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1a0.74\uff1b\n- \u6570\u636e\u589e\u5f3a+dropout\uff1a0.8\uff1b\n- \u9884\u8bad\u7ec3\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff1a0.9\uff1b\n- \u5fae\u8c03\u9884\u8bad\u7ec3\u7f51\u7edc\uff1a0.9\uff1b","851610c0":"## \u6ce2\u58eb\u987f\u623f\u4ef7\u56de\u5f52\u9884\u6d4b","fc7b6399":"## \u795e\u7ecf\u7f51\u7edc\u6570\u5b66\u57fa\u7840"}}