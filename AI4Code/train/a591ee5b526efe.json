{"cell_type":{"785817a7":"code","ea82e767":"code","35ea5fca":"code","aa9b5f38":"code","9f0d6c48":"code","0a0a2af8":"code","ee364f96":"code","7623424d":"code","7dc72b26":"code","cf43e4f5":"code","5283eb57":"code","7a77b9ee":"code","a40bcccf":"code","36cd82bd":"code","bf7e0900":"code","b4f9bcea":"code","0b748f0d":"code","235880f6":"code","be16f664":"code","d3d38f33":"code","8875970c":"code","dd518174":"code","cf75b480":"code","bb7854f6":"code","4b99cda8":"code","a7bdedef":"code","87b20f72":"code","5643eb8f":"code","d38c3b76":"code","1e1b7864":"code","5a5f1198":"markdown","c6a73fb5":"markdown","6da7e79b":"markdown","ab4f4bae":"markdown","c0901f78":"markdown","867daf8d":"markdown","99221f9a":"markdown","34a8bb49":"markdown","07d12f54":"markdown","6546b764":"markdown","6ed45b27":"markdown","8e7209f6":"markdown","54941c3d":"markdown","811a9935":"markdown","61658831":"markdown","447be0e1":"markdown","596600b0":"markdown","c8074f2d":"markdown","6a5a7b62":"markdown","0d8f9f59":"markdown","d4312f5a":"markdown","37d28e17":"markdown","eb642480":"markdown","da60053f":"markdown","4a975b96":"markdown","44b5cc8a":"markdown","aaa7ba4e":"markdown","8c9e033a":"markdown","37133597":"markdown","0ee1f449":"markdown","1a0a101f":"markdown"},"source":{"785817a7":"library(caret)","ea82e767":"# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \n\n#scikit-learn.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder ","35ea5fca":"Iris=pd.read_excel('C:Users\/phiji\/Downloads\/Iris.xlsx')","aa9b5f38":"Iris","9f0d6c48":"df.head(10)","0a0a2af8":"df.shape","ee364f96":"df.columns # names of all coumns.","7623424d":"df.drop(['Id'],axis=1,inplace=True)","7dc72b26":"df.index # indices of rows.","cf43e4f5":"df.isnull().any()","5283eb57":"msno.matrix(df) # just one final time to visualize.","7a77b9ee":"for col in df.columns:\n    print(\"Number of values in column \" ,col,\" : \",df[col].count())","a40bcccf":"df.describe()","36cd82bd":"def plot(feature):\n    fig,axes=plt.subplots(1,2)\n    sns.boxplot(data=df,x=feature,ax=axes[0])\n    sns.distplot(a=df[feature],ax=axes[1],color='#ff4125')\n    fig.set_size_inches(15,5)","bf7e0900":"plot('SepalLengthCm')","b4f9bcea":"plot('SepalWidthCm')","0b748f0d":"plot('PetalLengthCm')","235880f6":"plot('PetalWidthCm')","be16f664":"sns.factorplot(data=df,x='Species',kind='count')","d3d38f33":"le=LabelEncoder()\ndf['Species']=le.fit_transform(df['Species'])","8875970c":"scaler=StandardScaler()\nscaled_df=scaler.fit_transform(df.drop('Species',axis=1))\nX=scaled_df\nY=df['Species'].as_matrix()","dd518174":"df.head(10)","cf75b480":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42)","bb7854f6":"clf_lr=LogisticRegression(C=10)\nclf_lr.fit(x_train,y_train)\npred=clf_lr.predict(x_test)\nprint(accuracy_score(pred,y_test))","4b99cda8":"clf_knn=KNeighborsClassifier()\nclf_knn.fit(x_train,y_train)\npred=clf_knn.predict(x_test)\nprint(accuracy_score(pred,y_test))","a7bdedef":"clf_svm_lin=LinearSVC()\nclf_svm_lin.fit(x_train,y_train)\npred=clf_svm_lin.predict(x_test)\nprint(accuracy_score(pred,y_test))","87b20f72":"clf_svm=SVC()\nclf_svm.fit(x_train,y_train)\npred=clf_svm.predict(x_test)\nprint(accuracy_score(pred,y_test))","5643eb8f":"models=[LogisticRegression(),LinearSVC(),SVC(),KNeighborsClassifier()]\nmodel_names=['LogisticRegression','LinearSVM','rbfSVM','KNearestNeighbors']\n\nacc=[]\nd={}\n\nfor model in range(len(models)):\n    clf=models[model]\n    clf.fit(x_train,y_train)\n    pred=clf.predict(x_test)\n    acc.append(accuracy_score(pred,y_test))\n     \nd={'Modelling Algo':model_names,'Accuracy':acc}","d38c3b76":"acc_frame=pd.DataFrame(d)\nacc_frame","1e1b7864":"sns.factorplot(data=acc_frame,y='Modelling Algo',x='Accuracy',kind='bar',size=5,aspect=1.5)","5a5f1198":"#### LABEL ENCODING THE TARGET","c6a73fb5":"[ **1 ) Importing Various Modules**](#content1)\nlibrary(caret)","6da7e79b":"## Please star\/upvote if you liked it.","ab4f4bae":"## CONTENTS::","c0901f78":"<a id=\"content4\"><\/a>\n## 4 ) Preparing the Data","867daf8d":"#### kNN","99221f9a":"####  VISUALIZING THE DISTRIBUTIION OF FEATURES.","34a8bb49":"## Iris Species Dataset            ","07d12f54":"#### LOGISTIC REGRESSION","6546b764":"This shows the different statistical quantities like mean, median etc.. of all the numeric columns in the data frame.","6ed45b27":"#### Linear Support Vector Machine(SVM)","8e7209f6":"<a id=\"content2\"><\/a>\n## 2 ) Loading the Dataset","54941c3d":"<a id=\"content6\"><\/a>\n## 6 ) COMPARING DIFFERENT ALGORITHMS","811a9935":"##  THE END !!!","61658831":"Since the algorithms accept only numeric values we will encode the 'Species' column using the Labelencoder() from scikit learn.","447be0e1":"<a id=\"content1\"><\/a>\n## 1 ) Importing Various Modules","596600b0":"#### SVM (with 'rbf' kernel)","c8074f2d":"This shows that there aren't any 'Nan' values in any column.","6a5a7b62":"The dataset has 150 rows and 5 columns out of which the 'Species' is our target variable which we want to predict. ","0d8f9f59":"<a id=\"content5\"><\/a>\n## 5 ) MODELLING","d4312f5a":"## Please star\/ upvote if you find it helpful.","37d28e17":"Since the data frame is already indexed we will drop the 'Id' column.","eb642480":" [ **3 )Exploring the Dataset**](#content3)","da60053f":"#### Now we can check if any column has any null or 'Nan' values or not.","4a975b96":" [ **4 ) Preparing the Data**](#content4)","44b5cc8a":"Normalizing the features give better performance. Hence I have normalized all the features by scaling them to 0 mean and a unit standard deviation.","aaa7ba4e":" [ **5 ) Modelling**](#content5)","8c9e033a":"#### NORMALIZING FEATURES ","37133597":"<a id=\"content3\"><\/a>\n## 3 ) Exploring the Dataset","0ee1f449":"#### SPLITTING INTO TRAINING & VALIDATION SETS.","1a0a101f":" [ **6 ) Comparing Different Algortihms**](#content6)"}}