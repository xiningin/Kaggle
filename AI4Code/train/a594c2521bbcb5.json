{"cell_type":{"e0464fcf":"code","4d49cecb":"code","e4fcee12":"code","a253421b":"code","9d6290a6":"markdown","303e25da":"markdown","f76270fd":"markdown","7a68c84e":"markdown"},"source":{"e0464fcf":"import pandas as pd\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\ndf_swin = pd.read_csv(\"..\/input\/oof-preds-for-paw\/swin_large_patch4_window12_384_in22k_oof.csv\")\nscores = []\nfor i in range(10):\n\ttrain = df_swin.sample(n=1700).reset_index(drop=True)\n\ttrue = train[\"true\"].values\n\tswin_pred = train[\"pred\"].values\n\tscores.append(mean_squared_error(true, swin_pred, squared=False))\nprint(f\"std = {np.std(scores)}\")\nprint(f\"mean ={np.mean(scores)}\")\nprint(f\"best_cv = {min(scores)}\")\nprint(f\"worst_cv = {max(scores)}\")\nprint(f\"difference between worst and best cv {max(scores) - min(scores)}\")\n","4d49cecb":"\n\nscores = []\nfor i in range(100):\n\ttrain = df_swin.sample(n=1700).reset_index(drop=True)\n\ttrue = train[\"true\"].values\n\tswin_pred = train[\"pred\"].values\n\tscores.append(mean_squared_error(true, swin_pred, squared=False))\nprint(f\"std = {np.std(scores)}\")\nprint(f\"mean ={np.mean(scores)}\")\nprint(f\"best_cv = {min(scores)}\")\nprint(f\"worst_cv = {max(scores)}\")\nprint(f\"difference between worst and best cv {max(scores) - min(scores)}\")\n","e4fcee12":"\nscores = []\nfor i in range(2352):\n\ttrain = df_swin.sample(n=1700).reset_index(drop=True)\n\ttrue = train[\"true\"].values\n\tswin_pred = train[\"pred\"].values\n\tscores.append(mean_squared_error(true, swin_pred, squared=False))\nprint(f\"std = {np.std(scores)}\")\nprint(f\"mean ={np.mean(scores)}\")\nprint(f\"best_cv = {min(scores)}\")\nprint(f\"worst_cv = {max(scores)}\")\nprint(f\"difference between worst and best cv {max(scores) - min(scores)}\")\n","a253421b":"\n#5100 is the number of total images we have in the private test set\nscores = []\nfor i in range(2352):\n\ttrain = df_swin.sample(n=5100).reset_index(drop=True)\n\ttrue = train[\"true\"].values\n\tswin_pred = train[\"pred\"].values\n\tscores.append(mean_squared_error(true, swin_pred, squared=False))\nprint(f\"std = {np.std(scores)}\")\nprint(f\"mean ={np.mean(scores)}\")\nprint(f\"best_cv = {min(scores)}\")\nprint(f\"worst_cv = {max(scores)}\")\nprint(f\"difference between worst and best cv {max(scores) - min(scores)}\")\n","9d6290a6":"We try this now again 100 times. This time its even worse. Now lets try with the current number of teams which at the time of writing were  2,352","303e25da":"I guess no explantion is needed here. Now we move onto on how much luck can help on the Private LB\n","f76270fd":"First try in which we randomly take 1700 images from 9912 images and check their cv score for 10 times. From this we can see that you just need some luck to have a really  large impact on your ranking and you can just end up winning a gold if you have some good luck","7a68c84e":"Still a large amount of luck is involed in this. If my validation method is true then this is a cause of big concern. Would love to hear your guys thought on this.\n"}}