{"cell_type":{"204f4e1b":"code","6e1a2717":"code","60a5ff80":"code","37a024e0":"code","8b02176f":"code","66b424fb":"code","5fb6cb4c":"code","7388646f":"code","24537e7d":"code","6877bd4b":"code","c39f7bf4":"code","468c9547":"code","31c65234":"code","e127133a":"markdown","8ed5983d":"markdown","025758e0":"markdown","bbdd6d18":"markdown","d06e2419":"markdown","4398605f":"markdown","d59ed235":"markdown","75aee552":"markdown","003ba9f5":"markdown","30474506":"markdown","a3f3ec99":"markdown","c40f0d3a":"markdown","5f9fd739":"markdown","9ee46df2":"markdown","8da02360":"markdown","0fa9a447":"markdown","73807797":"markdown","3f34af13":"markdown","6c714ea7":"markdown","8df93100":"markdown","b632398a":"markdown","e52c1b12":"markdown","19658eba":"markdown","810a081e":"markdown","8654d682":"markdown","45c14c07":"markdown","1d6d9559":"markdown","6ba3b1f8":"markdown","33d720fb":"markdown","ca9c8079":"markdown","29f11dc2":"markdown","e0eefdfd":"markdown","e4792910":"markdown","a71db3b4":"markdown","0ea77481":"markdown","9b9e4539":"markdown","d4b8e795":"markdown","933a7ce4":"markdown","71fe29fb":"markdown"},"source":{"204f4e1b":"#import os\n#print(os.listdir(\".\/\"))","6e1a2717":"from copy import deepcopy\nimport os\nimport pandas as pd\nimport csv\nimport numpy as np\nimport keras\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\n","60a5ff80":"start_size = 28\n\ndata = pd.read_csv(\"..\/input\/train.csv\")\ndf = pd.DataFrame(data)\n\nall_linear_data = df.as_matrix(columns=df.columns[1:])\nall_labels = df.as_matrix(columns=df.columns[:1])\n    \nall_image_data = all_linear_data.reshape((df.shape[0], start_size, start_size, 1))\nall_image_data = all_image_data \/ 255.0\nall_labels = keras.utils.to_categorical(all_labels, 10)\n\nvalidation_start = int((1 - 0.1) * all_image_data.shape[0])\n\ntrain_data = all_image_data[0:validation_start]\ntrain_labels = all_labels[0:validation_start]\nvalidation_train_data = all_image_data[validation_start:]\nvalidation_labels = all_labels[validation_start:]\n\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\ntest_df = pd.DataFrame(test_data)\n\nall_linear_test_image_data = test_df.as_matrix(columns=df.columns[1:])\nall_test_image_data = all_linear_test_image_data.reshape((test_df.shape[0], start_size, start_size, 1))\nall_test_image_data  = all_test_image_data  \/ 255.","37a024e0":"def get_lr_metrics(optimizer):\n    def lr(y_true, y_pred):\n        return optimizer.lr\n    return lr\n\ndef get_model():\n    model = Sequential()\n\n    model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n    \n    return model\n\n\nmodel = get_model()\nopimizer = Adam(1e-4)\nmodel.compile(optimizer=opimizer, loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", get_lr_metrics(opimizer)])","8b02176f":"datagen_args = dict(rotation_range=20,\n                    width_shift_range=0.1,\n                    height_shift_range=0.1,\n                    shear_range=0.1,\n                    zoom_range=0.1)\ndatagen = ImageDataGenerator(**datagen_args)\n\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n                                            patience=5,\n                                            verbose=1,\n                                            factor=0.85,\n                                            min_lr=1e-10)\n\nweights_fname = 'mnist'\ncheckpoints = ModelCheckpoint(weights_fname + '-best.h5', monitor='val_acc', verbose=1,\n                              save_best_only=True, save_weights_only=True, mode='max', period=1)\n\nhistory = model.fit_generator(datagen.flow(train_data, train_labels, batch_size=64),\n                              epochs=60, steps_per_epoch=train_data.shape[0]\/\/64, # 0.9969 on 53th epoch\n                              validation_data=(validation_train_data, validation_labels),\n                              callbacks=[checkpoints, learning_rate_reduction],\n                              verbose=0)","66b424fb":"fig, ax = plt.subplots(2, 1)\n\nax[0].plot(history.history['loss'], color='b', label='Training loss')\nax[0].plot(history.history['val_loss'], color='r', label='validation loss', axes=ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label='Training accuracy')\nax[1].plot(history.history['val_acc'], color='r', label='Validation accuracy')\nlegend = ax[1].legend(loc='best', shadow=True)\n","5fb6cb4c":"def plot_confusion_matrix(cm,\n                          classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n     \n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment='center',\n                 color='white' if cm[i, j] > thresh else 'black')\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \ntrain_predicted_ohe = model.predict(all_image_data)\ntrain_predicted_numbers = np.argmax(train_predicted_ohe, axis=1)\ntrained_true_numbers = np.argmax(all_labels, axis=1)\n\npredict_ohe = model.predict(all_test_image_data)\n\nconfusion_mtx = confusion_matrix(trained_true_numbers, train_predicted_numbers)\nplot_confusion_matrix(confusion_mtx, classes=range(10))","7388646f":"def show_num_errors():\n    all_errors = confusion_mtx.sum()\n    for ind in range(10):\n        all_errors = all_errors - confusion_mtx[ind, ind]\n\n    print('------------------------------')\n    print(f'all errors: {all_errors} from {all_image_data.shape[0]} ( {100.0 * all_errors \/ all_image_data.shape[0]} percent)')\n    print('------------------------------')\n    \nshow_num_errors()","24537e7d":"def display_all_problem_images():\n    # display errors for each cipher\n    for cipher in range(10):\n        number_errors = confusion_mtx[cipher, :].sum() - confusion_mtx[cipher, cipher]\n\n        for index in range(10):\n            num_errors = confusion_mtx[cipher, index]\n            if (index == cipher) or (num_errors == 0):\n                continue\n\n            print(f\"True label is {cipher}, but predicted is {index}\")\n\n            num_rows = 1 + num_errors \/\/ 10        \n            plt.figure(figsize=(10 * 1, num_rows * 1))\n            plt.axis('off')    \n\n            current_error = 0\n            current_index = 0\n            while current_error < num_errors:\n                if  (trained_true_numbers[current_index] == cipher) and (train_predicted_numbers[current_index] == index):\n                    ax = plt.subplot(num_rows, 10, current_error + 1)\n                    ax.xaxis.set_major_locator(ticker.NullLocator())\n                    ax.xaxis.set_minor_locator(ticker.NullLocator())\n                    ax.yaxis.set_major_locator(ticker.NullLocator())\n                    ax.yaxis.set_minor_locator(ticker.NullLocator())                \n                    plt.imshow(all_image_data[current_index].reshape(start_size, start_size), cmap='gray')\n                    current_error = current_error + 1\n                current_index = current_index + 1\n\n            plt.show()\n            \n#display_all_problem_images()","6877bd4b":"for index in range(0, 10):\n    \n    print(f'index is {index} from 0-9')\n    \n    model = get_model()\n    opimizer = Adam(1e-4)\n    model.compile(optimizer=opimizer, loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\", get_lr_metrics(opimizer)])    \n    \n    model.load_weights(weights_fname + '-best.h5')\n    \n    history = model.fit_generator(datagen.flow(train_data, train_labels, batch_size=64),\n                                  epochs=55, steps_per_epoch=train_data.shape[0]\/\/64,\n                                  validation_data=(validation_train_data, validation_labels),\n                                  callbacks=[checkpoints, learning_rate_reduction],\n                                  initial_epoch=0,\n                                  verbose=0)\n    \n    train_predicted_ohe_current = model.predict(all_image_data)\n    train_predicted_ohe = train_predicted_ohe + train_predicted_ohe_current\n    train_predicted_numbers = np.argmax(train_predicted_ohe, axis=1)\n\n    confusion_mtx = confusion_matrix(trained_true_numbers, train_predicted_numbers)\n    plot_confusion_matrix(confusion_mtx, classes=range(10))\n    \n    show_num_errors()\n    \n    predict_ohe_current = model.predict(all_test_image_data)\n    predict_ohe = predict_ohe + predict_ohe_current","c39f7bf4":"display_all_problem_images()","468c9547":"results = np.argmax(predict_ohe, axis=1)\nresults = pd.Series(results, name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), results], axis=1)","31c65234":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"mnist_results1.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","e127133a":"**6. Errors**","8ed5983d":"**7. Fitting**\n\n    I saved the best weights into h5 file. Now I am going to load them, and fit again. Data generator each time wil produce slightly different data, so I hope to find other slightly different local maximum for approximate function and to use those new weights for another prediction. I hope, new and old prediction would be different. Then I will repeat the same procedure a few times and each weights set will vote for each image. Then I will select the best digit for each image.","025758e0":"True label is 8, but predicted is 6\n![image.png](attachment:image.png)","bbdd6d18":"**2. Model**","d06e2419":"**------------------------------\n\nall errors: 86 from 42000 ( 0.20476190476190476 percent)\n\n------------------------------**","4398605f":"    I do not know what exactly helped: many iterations or averaging. Anyway, I posted last results and has 0.997 accuracy (top 10%).","d59ed235":"**6.1. Show all problem images**","75aee552":"True label is 9, but predicted is 8\n![image.png](attachment:image.png)","003ba9f5":"True label is 4, but predicted is 1\n![image.png](attachment:image.png)","30474506":"True label is 1, but predicted is 7\n![image.png](attachment:image.png)","a3f3ec99":"True label is 2, but predicted is 0\n![image.png](attachment:image.png)","c40f0d3a":"True label is 8, but predicted is 9\n![image.png](attachment:image.png)","5f9fd739":"**9. Downloading**","9ee46df2":"True label is 2, but predicted is 7\n![image.png](attachment:image.png)","8da02360":"![image.png](attachment:image.png)","0fa9a447":"True label is 9, but predicted is 4\n![image.png](attachment:image.png)","73807797":"**5. Confusion matrix**","3f34af13":"**9. Predicting**","6c714ea7":"**8. Results**\n\n    Finally, I have got val_acc = 0.99762 and 44 errors on the train dataset.\n    I want to show all problem images from the train dataset.\n    Then I run the code above one more time and have got val_acc = 0.99762 and 39 errors.\n    Next time I got the same result.\n    So, this is my final result.","8df93100":"True label is 9, but predicted is 7\n![image.png](attachment:image.png)","b632398a":"**0. Libraries**","e52c1b12":"**There are many good explanation for beginners, but I started from https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\nand continued with https:\/\/www.kaggle.com\/cdeotte\/how-to-choose-cnn-architecture-mnist\n\nI tried to modify images after image generator and to noise them, but it did not help.\n\nSo, pp. 0-5 are standart**","19658eba":"True label is 4, but predicted is 7\n![image.png](attachment:image.png)","810a081e":"True label is 4, but predicted is 9\n![image.png](attachment:image.png)","8654d682":"True label is 8, but predicted is 1\n![image.png](attachment:image.png)","45c14c07":"**4. Curves**","1d6d9559":"**3. Running**\n\n    First time I chose 100 epochs, but saw val_acc reachs the best value 0.99690 at 53th epochs and changed 100 in 60.","6ba3b1f8":"Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.7714946120104284e-05.\n\nEpoch 00059: val_acc did not improve from 0.99667\n\nEpoch 00060: val_acc did not improve from 0.99667","33d720fb":"True label is 6, but predicted is 4\n![image.png](attachment:image.png)","ca9c8079":"True label is 5, but predicted is 6\n![image.png](attachment:image.png)","29f11dc2":"True label is 3, but predicted is 9\n![image.png](attachment:image.png)","e0eefdfd":"True label is 8, but predicted is 5\n![image.png](attachment:image.png)","e4792910":"True label is 7, but predicted is 1\n![image.png](attachment:image.png)","a71db3b4":"True label is 8, but predicted is 2\n![image.png](attachment:image.png)","0ea77481":"True label is 3, but predicted is 5\n![image.png](attachment:image.png)","9b9e4539":"**1. Loading and prepare data**","d4b8e795":"![image.png](attachment:image.png)","933a7ce4":"You could see many problem images are really problematic. But from those 39 images I see 8 can be recognized right.","71fe29fb":"![image.png](attachment:image.png)"}}