{"cell_type":{"c3f41459":"code","4ba1b4cd":"code","12921e71":"code","e45f4075":"code","3f6bd3ed":"code","9a3f43a0":"code","f35bf3db":"code","e6057c15":"code","50e8ec6e":"code","1b894c86":"code","f9b849c1":"code","686668bc":"code","4e8e4a7c":"code","35edde28":"code","0cb40462":"code","42bc37f2":"code","1e938bb4":"code","ceb05f68":"code","2b6d785d":"code","d7090778":"code","9c95a81e":"code","3c5793c5":"code","0837d325":"code","4f4ade2a":"code","f42fe83a":"code","2b93fb2c":"markdown","7a78f5ee":"markdown","eed832a9":"markdown","c927f400":"markdown","6e02feda":"markdown","a1fc243e":"markdown","0526df09":"markdown","03077eaa":"markdown","f6e70b7f":"markdown","f360ae3c":"markdown","a931f550":"markdown","fcaca52f":"markdown","bf9e0b7f":"markdown","b5049fc2":"markdown","f44e9f5a":"markdown","3162d355":"markdown","33874599":"markdown","6a74ba52":"markdown","82d11fc1":"markdown"},"source":{"c3f41459":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom string import punctuation\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4ba1b4cd":"train_df = pd.read_csv('\/kaggle\/input\/fake-news\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/fake-news\/test.csv')","12921e71":"train_df.head(5)","e45f4075":"test_df.head(5)","3f6bd3ed":"train_df.isna().sum()","9a3f43a0":"test_df.isna().sum()","f35bf3db":"train_df.fillna(\"missing\",inplace = True)\ntest_df.fillna(\"missing\",inplace = True)","e6057c15":"print(\"Train Shape: \",train_df.shape)\nprint(\"Test Shape: \",test_df.shape)","50e8ec6e":"train_df['text'] = train_df['text'] + \" \" + train_df['title'] + \" \" + train_df['author']\ndel train_df['title']\ndel train_df['author']\ndel train_df['id']","1b894c86":"test_df['text'] = test_df['text'] + \" \" + test_df['title'] + \" \" + test_df['author']\ndel test_df['title']\ndel test_df['author']\ndel test_df['id']","f9b849c1":"print(\"Train Shape: \",train_df.shape)\nprint(\"Test Shape: \",test_df.shape)","686668bc":"stop = set(stopwords.words('english'))\npnc = list(punctuation)\nstop.update(pnc)","4e8e4a7c":"stemmer = PorterStemmer()\ndef stem_text(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            word = stemmer.stem(i.strip())\n            final_text.append(word)\n    return \" \".join(final_text)","35edde28":"train_df['text'] = (train_df['text'].astype(str)).apply(stem_text)\nprint('Train done!')\ntest_df['text'] = (test_df['text'].astype(str)).apply(stem_text)\nprint('Test done!')","0cb40462":"print(train_df.shape)\nprint(test_df.shape)","42bc37f2":"X = train_df['text']\ny = train_df['label']","1e938bb4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)","ceb05f68":"test_df = test_df['text']","2b6d785d":"print('X_train shape: ',X_train.shape)\nprint('y_train shape: ',y_train.shape)\nprint('X_test shape: ',X_test.shape)\nprint('y_test shape: ',y_test.shape)\nprint('test_df shape: ',test_df.shape)","d7090778":"cv = CountVectorizer(min_df=0,max_df=1,ngram_range=(1,3))\n\ncv_train = cv.fit_transform(X_train)\ncv_test = cv.transform(X_test)\ncv_test_df = cv.transform(test_df)\n\nprint('Train data shape: ',cv_train.shape)\nprint('Validation data shape: ',cv_test.shape)\nprint('Test data shape: ',cv_test_df.shape)","9c95a81e":"nb = MultinomialNB()","3c5793c5":"nb.fit(cv_train, y_train)","0837d325":"pred_nb = nb.predict(cv_test)","4f4ade2a":"score = metrics.accuracy_score(y_test, pred_nb)\nprint(score)","f42fe83a":"pred_nbs = nb.predict(cv_test_df)\nsub_df = pd.read_csv('..\/input\/fake-news\/submit.csv')\nsub_df['label'] = pred_nbs\nsub_df.to_csv('sample_sub_nb.csv', index = False)","2b93fb2c":"Develop a machine learning program to identify when an article might be fake news. Run by the UTK Machine Learning Club.","7a78f5ee":"## Data Preprocessing","eed832a9":"Perform Stemming for both train and test data","c927f400":"## Load Data","6e02feda":"### Submission","a1fc243e":"## Evaluation\n\nThe evaluation metric for this competition is accuracy, a very straightforward metric.\n\naccuracy=correct predictionscorrect predictions+incorrect predictions\nAccuracy measures false positives and false negeatives equally, and really should only be used in simple cases and when classes are of (generally) equal class size","0526df09":"### Define Model","03077eaa":"### Fit Model","f6e70b7f":"### Evaluation","f360ae3c":"### Train Data","a931f550":"Handling NULL values","fcaca52f":"Let's merge Title and Author in Text for both Train and Test data","bf9e0b7f":"## So let's begin here...","b5049fc2":"Performing Count vectorization for our train, validation and test data.","f44e9f5a":"### Prediction","3162d355":"Check for NULL values","33874599":"# Fake News","6a74ba52":"Splitting data for validation","82d11fc1":"## Naive Bayes"}}