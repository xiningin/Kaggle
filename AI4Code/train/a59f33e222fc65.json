{"cell_type":{"cc797044":"code","ea5a531a":"code","faeb1555":"code","8bddb6dc":"code","aec24c62":"code","6f903c2b":"code","0ca38fbc":"code","c7864ead":"code","448f97f5":"code","5af52f75":"code","ee584407":"code","e3584a32":"code","b27004e2":"code","3a113a26":"code","c81658a5":"code","2bbe3d48":"code","eef86bcb":"code","8c009f38":"code","6eb2758c":"code","2d9391eb":"code","70cc3c44":"code","37d569d0":"code","c291559c":"code","af481e5d":"code","08d3e67c":"code","ff9049b0":"code","17f6c256":"code","9e4b6287":"code","eb8ba165":"code","06bba92b":"code","3c99ec74":"code","591df6bc":"code","517e89cb":"code","f40feb08":"code","fd53d100":"code","e28da8f5":"code","048d01cf":"code","505d5924":"code","0f0657a8":"code","a3dc9f90":"code","c19c7a40":"code","924b3761":"code","c15cf7f4":"code","a4f57f89":"code","6c96980f":"code","a5fde168":"code","96ff4a78":"code","b541cbc4":"code","38940bb2":"code","c394da1c":"code","11a9aacb":"code","775a68de":"code","65ad0993":"markdown","3094a891":"markdown","15859243":"markdown","acd5d712":"markdown","03b892c3":"markdown","9a2badb8":"markdown","4a8ecdba":"markdown","0c449f43":"markdown","6145aa20":"markdown","8da19e57":"markdown","59cff7d2":"markdown","cbc28a7a":"markdown","51f71092":"markdown","24115a32":"markdown","f669b283":"markdown","81baed81":"markdown","14c81bef":"markdown","f80146a1":"markdown","36af8865":"markdown","efa65426":"markdown","0d968519":"markdown","c6ddaa35":"markdown","07ab139e":"markdown","69278da7":"markdown","1674e26d":"markdown","f4aec9ed":"markdown","64460c42":"markdown","a5eb2411":"markdown","e05cd4fa":"markdown","4318bdc5":"markdown","06595b54":"markdown","99cabdcd":"markdown","84d7f60b":"markdown","d901bc26":"markdown","85ca04d9":"markdown","cf5a2e0f":"markdown","2cb1bb24":"markdown","f4abce32":"markdown","9bd91330":"markdown","a23f231e":"markdown","3c6d050d":"markdown"},"source":{"cc797044":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom surprise import KNNWithMeans\nfrom surprise import Dataset\nfrom surprise import accuracy\nfrom surprise.model_selection import train_test_split\nfrom surprise.model_selection import split\nfrom surprise import Dataset,Reader\nfrom surprise.model_selection import cross_validate\nfrom surprise.model_selection import GridSearchCV\nfrom collections import defaultdict\n\n%matplotlib inline\nsns.set(style=\"darkgrid\",color_codes=True)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\n","ea5a531a":"# load the dataset\nrdata = pd.read_csv('\/kaggle\/input\/amazon-product-reviews\/ratings_Electronics (1).csv',names=['userid','productid','rating','timestamp'])","faeb1555":"# lets make a copy of the data so that all the transformation is done on the copy and not on the main dataset\nt1data=rdata.copy()","8bddb6dc":"# step 2.1: browse through the first few columns\nt1data","aec24c62":"## identifying the range of the ratings\nnp.sort(t1data['rating'].unique())","6f903c2b":"### analysing the first few records \nt1data.head()","0ca38fbc":"#dropping timestamp column since it is not much of value add\nt1data=t1data.drop(\"timestamp\",axis=1)","c7864ead":"t1data.head()","448f97f5":"t1data.info()","5af52f75":"## count of each attribute in the dataset\n\nunique_users =len(np.unique(t1data.userid))\nunique_pdts = len(np.unique(t1data.productid))\nprint('Total number of users is: ',unique_users,'\\n')\nprint('Total number of products is: ',unique_pdts,'\\n')","ee584407":"### lets analyse the spread of data\nt1data.describe().T","e3584a32":"# Identify Duplicate records in the data \n# It is very important to check and remove data duplicates. \n# Else our model may break or report overly optimistic \/ pessimistic performance results\ndupes=t1data.duplicated()\nprint(' The number of duplicates in the dataset are:',sum(dupes), '\\n','There are no duplicates in the dataset')","b27004e2":"# checking if there are any null values\nt1data.isnull().any()","3a113a26":"a=t1data.groupby('rating')['rating'].count()","c81658a5":"# Attributes in the Group\nAtr1g1='userid'\nAtr2g1='productid'\nAtr3g1='rating'\ndata=t1data","2bbe3d48":"##EDA: Spread\n# fig, ax = plt.subplots(1,2,figsize=(16,8)) \nplt.figure(figsize=(8,6))\nsns.distplot(data[Atr3g1]);","eef86bcb":"# EDA: count of ratings:\nplt.figure(figsize=(8,6))\nsns.countplot(data[Atr3g1]);","8c009f38":"t2data=t1data.copy()\nt2data = t2data[t2data.groupby('userid')['userid'].transform('size') > 49]\nt2data=pd.DataFrame(t2data)","6eb2758c":"t2data=t2data.reset_index(drop=True)","2d9391eb":"t2data.head()","70cc3c44":"shape_t2data=t2data.shape\nprint('The shape of the new dataframe is',shape_t2data,'which means there are',shape_t2data[0],'rows of ratings and',shape_t2data[1],'attributes of userid, productid and rating.')","37d569d0":"## lets check the count of ratings given by the users\nratings_per_user = t2data.groupby(by='userid')['rating'].count().sort_values(ascending=False)\nratings_per_user","c291559c":"reader = Reader(rating_scale=(1, 5))","af481e5d":"t3data=Dataset.load_from_df(t2data[['userid','productid','rating']],reader)\nt3data","08d3e67c":"trainset, testset = train_test_split(t3data, test_size=.30, random_state=1)","ff9049b0":"print(type(testset))\nprint(type(trainset))","17f6c256":"# First we will group by product ids and then display mean ratings for the products. For better visualization we will display first 5 records.\nt2data.groupby('productid')['rating'].mean().head()","9e4b6287":"## Next we want to look at which product has got the highest rating. FOr the same same we will sort the productid by the mean ratings.\n## We then displayed top 10 products which have the highest ratings\n# this analysis is also inconclusive since top ratings dont add value without the count\nt2data.groupby('productid')['rating'].mean().sort_values(ascending=False).head(10)","eb8ba165":"## Next lets try and analyse the products which have been rated the most\nt2data.groupby('productid')['rating'].count().sort_values(ascending=False).head()","06bba92b":"t2data_product_ratings =pd.DataFrame(t2data.groupby('productid')['rating'].mean())\nt2data_product_ratings['ratings_count'] = pd.DataFrame(t2data.groupby('productid')['rating'].count())\nt2data_product_ratings.head()","3c99ec74":"t2data_product_ratings.sort_values(by='ratings_count',ascending=False)","591df6bc":"t2data_product_ratings['score'] = t2data_product_ratings['rating']*t2data_product_ratings['ratings_count']","517e89cb":"plt.figure(figsize=(8,6))\nsns.jointplot(x='rating', y='ratings_count', data=t2data_product_ratings, alpha=0.4)","f40feb08":"t2data_product_ratings.sort_values(by='score',ascending=False)","fd53d100":"print('the top 5 recommendations are:') \nt2data_product_ratings.sort_values(by='score',ascending=False).head()","e28da8f5":"### Lets build the model","048d01cf":"data = t3data","505d5924":"algo_knn = KNNWithMeans()\nalgo_knn.fit(trainset)","0f0657a8":"predictions_knn = algo_knn.test(testset)","a3dc9f90":"# get RMSE\nprint(\"User-based Model : Test Set\")\naccuracy.rmse(predictions_knn, verbose=True)","c19c7a40":"## We could use item-item based collaborative filtering. Since everytime we used it, google colab crashed giving out of memory issues. \n#We tried executing on local machine as well but no luck. Another option could be trucating the data to reduce memory requirements.\n# But that approach dint appear apt to follow.","924b3761":"\nsim_options = {\n    \"name\": [\"msd\", \"cosine\",\"pearson_baseline\"],\n    \"min_support\": [3, 4, 5],\n    \"user_based\": [True],\n    \"k\":[5,10,20,30,40,50,100]\n    \n}","c15cf7f4":"param_grid = {\"sim_options\": sim_options,\"verbose\":[True,False]}\ngs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"],cv=3)\ngs.fit(data)","a4f57f89":"print(gs.best_score[\"rmse\"])\nprint(gs.best_params[\"rmse\"])","6c96980f":"algo = KNNWithMeans(sim_options={'name': 'pearson_baseline', 'min_support': 5, 'user_based': True,'k':5},verbose= True,c=3)\nalgo.fit(trainset)","a5fde168":"# run the trained model against the testset\npredictions = algo.test(testset)\npredictions","96ff4a78":"print('the top 5 recommendations are:') \nt2data_product_ratings.sort_values(by='score',ascending=False).head()","b541cbc4":"# get RMSE\nprint('For the User-based Model, the accuracy of the Test Set is:')\naccuracy.rmse(predictions, verbose=True)","38940bb2":"cross_validate(algo, t3data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","c394da1c":"def get_top_n(predictions,n=5):\n  top_n=defaultdict(list)\n  for uid,iid,true_r,est,_ in predictions:\n    top_n[uid].append((iid,est))\n  for uid,user_ratings in top_n.items():\n    user_ratings.sort(key=lambda x: x[1],reverse=True)\n    top_n[uid]=user_ratings[:n]\n  return top_n","11a9aacb":"top_n=get_top_n(predictions)","775a68de":"print('top 5 recommended products for each user are:')\ntop_n","65ad0993":"### Step 6: Evaluate both the models.","3094a891":"challenges\n- it is not personalised. We are not catering to an individuals preference. Since same kind of recommendations are done to every new user on to the site.\n- While, it increases the probability of purchase; since before this we dint have any recommendation system because we dint have any information. But now we have some information with which we are recommending products to people. \n- However, that percentage of increase of probability of sale is marginally increased. \n- Hence, in the next section, we will evaluate other recommendation systems. beginning with collaborative filtering model.","15859243":"As seen in the above dataframe the top 5 popular recommendations are products \n1. B003ES5ZUU\n2. B0088CJT4U\n3. B000N99BBC\n4. B007WTAJTO\n5. B00829TIEK","acd5d712":"Online E-commerce websites like Amazon, Flipkart uses different recommendation models to provide different suggestions to different users. Amazon currently uses item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n\nDataset:<br>\n- The dataset comprises of  7824482 rows of user who have rated different products at different times.\n\nObjective of the project:<br>\n- Build a recommendation system to recommend products to customers based on the their previous ratings for other products.","03b892c3":"Popularity based recommendation system works with the trend. It basically uses the items which are in trend right now. For example, if any product which is usually bought by every new user then there are chances that it may suggest that item to the user who just signed up","9a2badb8":"As discussed earlier, these 5 products will be recommended to all the users irrespective of their personal likes and dis-likes. We'll give further explanations in the last section wherein we'll summarise the models.","4a8ecdba":"### Step 2 Take a subset of the dataset to make it less sparse\/ denser. ( For example, keep the users only who has given 50 or more number of ratings )","0c449f43":"The dataframe above also gives us inconclusive recommendations. Since it doesnt tell us between (lets say) product 1 which has low rating but high count of vote and product 2 which has higher rating but lesser count of vote, which one is the first recommendation.\nHence, we will add another column to this dataframe and call it score. The column score will be a multiple of rating and rating count. We will sort the column score in the descending order and that will give us the top recommendations.","6145aa20":"The list above captures product recommendations for each user. These are recommended basis an users preferences and likes (referring the ratings done by them on the other products). The model can help users discover new interests w.r.t products. while the model might not know the user's interest but still it might recommend products because similar users are interested in that product.","8da19e57":"##### Step 7.2: Collaborative Filtering model:<br>\nLets identify the top 5 recommendations for each user:","59cff7d2":"popularity based Recommendation systems dont consider the count of people giving ratings; so if 1 person give 5 rating to a product; \nPopularity based recommendation will consider it to be similar to let's say if there are 500 people who give 5 rating to the same product.\nHence, an individual's recommendation can impact the recommendations made to a new user.<br>\nTo ensure that our recommendation is not impacted by the count of people giving better ratings; as an example for enhanced analysis lets keep the users who have given 50 or more than 50 number of ratings","cbc28a7a":"The ratings are in the range of [1,5]","51f71092":"Collaborative filtering addresses limitations of the popularity basis recommendation systems.\ncollaborative filtering uses similarities between users and items to provide recommendations.\ncollaborative filtering models can recommend a product to user X based on the interests of a similar user Y.","24115a32":"Clearly there are no null values","f669b283":"### Step 3: Split the data randomly into train and test dataset. ( For example, split it in 70\/30 ratio)","81baed81":"### Step 4: Build Popularity Recommender model.","14c81bef":"As seen above, even though, the product ending with 647 has a high rating; but there is only 1 rating against it; Hence, this product might not be popular and hence cant be recommended to other users.\nNext, we will sort the products basis the rating counts in the descending order to identify the products with the best rating and the rating counts.","f80146a1":"##### step 6.2: Evaluate collaborative filtering model","36af8865":"As discussed in the previous step. Since popularity based recommendations don't consider the count of people recommending. Hence, recommendations can easily be influenced even if lesser count customers have recommended. To help with that, we reduced our dataset to include only those customers who have given 50 or more ratings.\nIn this section, we will build popularity based recommendation system and arrive that products which can be recommended to the new customers.","efa65426":"### Step 5: Build Collaborative Filtering model.","0d968519":"### Step 7: Get top - K ( K = 5) recommendations. \nSince our goal is to recommend new products for each user based on his\/her habits, we will recommend 5 new products.","c6ddaa35":"We will use grid-search to arrive at the best hyper parameters.","07ab139e":"- The range of rating is [1,5] with a median of 5. The mean is less than median which means that there could be slight skewness on the left.\nThere might be few outliars on the left; we will plot a box plot to confirm the same.","69278da7":"As seen in the section above; the product id ending with T4U has been rated the most with the count 206; The product id ending with ZUU is the second most rated product.\nThis will also not give us the recommendations; since it doesnt tell us what was the rating of these products. So next we will create a dataframe wherein we will have 2 columns; \ncolumn 1: the count of rating\ncoulmn 2: the mean rating\nThat will help us in building up the recommendations for any new user who logs into our website","1674e26d":"##### step 7.1: Popularity based recommendation systems:<br>\nAs seen in the previous section, the top 5 popular recommendations are products\n\n- B003ES5ZUU\n- B0088CJT4U\n- B000N99BBC\n- B007WTAJTO\n- B00829TIEK","f4aec9ed":"#### Pre-steps 1: Import the necessary libraries","64460c42":"Step 8.2: Collaborative filtering model:<br>\n- Leveraging the collaborative filtering model, we were able to recommend top 5 products for each user. \n- The distictive feature of collaborative filtering is that the recommendations are not generic in nature; but are customized for each user basis their likings.\n- Hence, collaborative filtering technique is the preferred technique over popularity based recommendation system.","a5eb2411":"-  we can notice that the first product id ending with 647 has a rating of 5; the second product id ending with 813 has a mean rating of 3. \n-  The third product id ending with 998 has a mean rating of 2.5. \n- All of these rating are in-conclusive since we dont know how many users gave these rating.\n-  there could be a case wherein only one user rated product 1 (ending with 647). Hence, going by this we might recommend product 1; which might not be correct","e05cd4fa":"##### Step 6.1 evaluate Popularity based model","4318bdc5":"##### Step 8.1: Popularity based recommender system: <br>\n- The Popularity based recommender provide a general count of recommended products to all the users. They are not sensitive to the interests and tastes of a particular user. <br>\n- Popularity based Recommender system might be a good starting point for a new business where we dont have any user reviews and hence customization basis user preferences might not be possible. Hence, they might increase the probablity of purchase since for the new business there doesnt exist any user information. However, the probablity of increase in purchase would most likely be marginal.\n- Since they dont consider an individuals interests \/ likes \/ dislikes; hence it is not a solution which can be recommended to all.\n- Also, consider a scenario where in a user has already bought a product and that product is high rated product. Popularity based recommender system wont consider this fact that the user has already bought the product and will continue to recommend the same product.\n- While we got 5 products which could be recommended to the users but for the reasons mentioned above, popularity based recommender systems are not a ideal way of recommendations.","06595b54":"From the countplot above, it appears that a lot of products have got a rating of 5; \nit might appear that there is a lot of noise in the data; There also might be cases wherein few products have high ratings but the count of ratings is less.\nWe will try to clear all the noises in the next sections.","99cabdcd":"We will use KNN algorithm for prediction. First we will select default parameters and check the RMSE. Post which we will use hyper parameters for tuning and arrive at the best parameters for our model","84d7f60b":"#### Note: We are unable to run a item-item based model with the command 'user_based': False; since the RAM requirement is much more than the available RAM. Everytime we try to execute the same; the session crashes giving errors. We tried on local machine with 8 GB RAM but no luck.","d901bc26":"### Step 8: Summarising the insights","85ca04d9":"- There are 3 columns. \n  - user id and product id are of type object while rating is of type float","cf5a2e0f":"The range of ratings is clearly visible. There are around 1540 users with a range of [50,520]","2cb1bb24":"Lets build the model","f4abce32":"There are a lot of products who have a mean rating of 5; however, the analysis wont be conclusive since we dont know how many users rated these products.","9bd91330":"#### Step1: Read and explore the given dataset.","a23f231e":"As seen while building the popularity based model. The 5 products which will be recommended to all the users basis the popularity are:","3c6d050d":"However, The problems with popularity based recommendation system is that the personalization is not available with this method i.e. even though we know the behaviour of the user you cannot recommend items accordingly."}}