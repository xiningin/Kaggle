{"cell_type":{"abab7851":"code","073cacc6":"code","23293b76":"code","439de6e0":"code","75f5e0f7":"code","2a0fa965":"code","3e2adca3":"code","081f74a5":"code","9042798d":"code","69c65f0d":"code","88681e70":"code","3e966936":"code","c1d47848":"code","258d4730":"code","8ae5ef33":"code","459c15ff":"code","a44d8ccd":"code","d7d4a07c":"code","a48b4dab":"code","fcb1e65a":"code","27235dbc":"code","a56a5d85":"code","0c63dd53":"code","632addd2":"code","b96de107":"code","988d8ae6":"code","93dcdaf5":"code","5c597a4a":"code","d36e622c":"code","f5cdd96e":"code","bb032ae1":"code","5ccc73f6":"code","8ff14325":"code","8f4fe7f2":"code","1860dc6c":"code","1fa86902":"code","f5175870":"code","c32fe159":"code","d8be29c6":"code","821687a4":"code","763a8771":"code","29833ad0":"code","99f45828":"code","c551aec9":"code","eb50feea":"code","a6374e92":"code","dc471595":"code","8bd2c5dd":"code","34d45d97":"markdown","4de441be":"markdown","5ad3d005":"markdown","28aa3baa":"markdown","53295be2":"markdown","1644eb1c":"markdown","9cc4c997":"markdown","6837371b":"markdown","20b03789":"markdown","393ebde7":"markdown","22bacfce":"markdown","ce86cec6":"markdown","23f05e8b":"markdown","f6f86a28":"markdown","bd8bd241":"markdown","9e664ecf":"markdown","aed4e40b":"markdown","0f1bbf31":"markdown"},"source":{"abab7851":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","073cacc6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import  confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix","23293b76":"df = pd.read_csv('..\/input\/engineering-placements-prediction\/collegePlace.csv')\ndf","439de6e0":"df.head()","75f5e0f7":"df.tail()","2a0fa965":"df.dtypes","3e2adca3":"df.size","081f74a5":"df.shape","9042798d":"df.columns","69c65f0d":"df.info()","88681e70":"df.describe()","3e966936":"df.duplicated().sum()","c1d47848":"df.drop(['Gender','Stream'],axis = 1).skew()","258d4730":"df.drop(['Gender','Stream'],axis = 1).corr()","8ae5ef33":"df.skew()","459c15ff":"df.isnull().sum()","a44d8ccd":"df['Gender'].value_counts()","d7d4a07c":"sns.countplot(x = 'Gender',data=df)\nplt.show()","a48b4dab":"df['Stream'].value_counts()","fcb1e65a":"# HereI I changed categorical types in column stream for my convinient and for better visualisation\nfor i in df['Stream']:\n    if i == 'Computer Science':\n        df['Stream'].replace(i,'CS',inplace = True)\n    elif i == 'Information Technology':\n        df['Stream'].replace(i,'IT',inplace = True)\n    elif i == 'Electronics And Communication':\n        df['Stream'].replace(i,'EC',inplace = True)\ndf['Stream']","27235dbc":"sns.countplot(x = 'Stream',data=df)\nplt.show()","a56a5d85":"fig = px.histogram(df, 'Age',color=\"Gender\",title=\"<b>Average Age Gender wise<\/b>\")\nfig.add_vline(x=df['Age'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\nfig.show()","0c63dd53":"fig = px.histogram(data_frame = df,x = \"Stream\",color=\"PlacedOrNot\", title=\"<b>Counts of Stream<\/b>\",pattern_shape_sequence=['x'])\nfig.show()\n#Majority of candidate are Computer Science Student and they are also large in number who got placement as compare to other Streams","632addd2":"fig = px.histogram(data_frame = df,x = \"Gender\",color=\"PlacedOrNot\", title=\"<b>Counts of Stream<\/b>\",pattern_shape_sequence=['x'])\nfig.show()\n#males placed morethan females","b96de107":"df1 = df.groupby('Stream').agg({'Age':'mean','Internships' : 'sum', \"CGPA\":'mean','PlacedOrNot':'sum'})\ndf1","988d8ae6":"px.bar(data_frame=df1, barmode='group',\n       title = \"<b>Stream wise Analyzing<\/b>\")\n#From Computer Science degree most of the student placed","93dcdaf5":"fig = px.histogram(data_frame = df[df['Internships']==0],x = \"PlacedOrNot\",color=\"PlacedOrNot\",title = \"<b>No Internship Experience Vs Placement<\/b>\")\nfig.update_layout(bargap=0.2)\nfig.show()\n#if person don't have any Internship Experience, it will not much effect on his\/her placement. Majority of the student who don't have any Internship Experience has passed the placement exam","5c597a4a":"plt.figure(figsize=(6,8))\nx = df.drop(['Gender','Stream'],axis = 1)\nfor i in x.columns[:4]:\n    sns.histplot(x[i],kde = False)\n    plt.show()","d36e622c":"plt.figure(figsize=(6,8))\nx = df.drop(['Gender','Stream'],axis = 1)\nfor i in x.columns[4:]:\n    sns.histplot(x[i],kde = True)\n    plt.show()","f5cdd96e":"# Heat map for corelation\nplt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()","bb032ae1":"x = df.drop(['Gender','Stream'],axis = 1)\nfor i in x.columns:\n    sns.boxplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","5ccc73f6":"#Violin plot\nx = df.drop(['Gender','Stream'],axis = 1)\nfor i in x.columns:\n    sns.violinplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","8ff14325":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in x.columns:\n    count_outliers(df,i)","8f4fe7f2":"df","1860dc6c":"n = 'Gender'\ndf_ohe = df.copy()\nlabel_3 = pd.get_dummies(df_ohe,prefix = n ,columns=[n],drop_first=False)\nlabel_3.insert(loc=2, column=n, value=df[n].values)\nlabel_3.drop([n],axis = 1,inplace = True)\nlabel_3","1fa86902":"n = 'Stream'\nlabel_3 = label_3.copy()\nlabel_4 = pd.get_dummies(label_3,prefix = n ,columns=[n],drop_first=False)\nlabel_4.insert(loc=2, column=n, value=df[n].values)\nlabel_4.drop([n],axis = 1,inplace = True)\nlabel_4","f5175870":"label_4 = label_4[['Age', 'Gender_Male', 'Gender_Female',\n             'Stream_EC','Stream_CS','Stream_IT',\n             'Stream_Mechanical', 'Stream_Electrical', \"Stream_Civil\",\n             \"Internships\",\"CGPA\",'Hostel',\n             'HistoryOfBacklogs', 'PlacedOrNot']]","c32fe159":"label_4","d8be29c6":"scaler = StandardScaler()\n\nscaler.fit(label_4.drop('PlacedOrNot',axis=1))\n\nscaled_features = scaler.transform(label_4.drop('PlacedOrNot',axis=1))","821687a4":"scaled_features = pd.DataFrame(scaled_features, columns = label_4.columns[:-1])\nscaled_features.head()","763a8771":"corrmat = label_4.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,15))\ng=sns.heatmap(label_4[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","29833ad0":"# Splitting your train and test data\nX_train, X_test, y_train, y_test = train_test_split(scaled_features,label_4['PlacedOrNot'],test_size = 0.25,random_state = 0)","99f45828":"knn = KNeighborsClassifier()","c551aec9":"knn.fit(X_train,y_train)","eb50feea":"pred = knn.predict(X_test)\npred","a6374e92":"p = pd.DataFrame(data = [pred,y_test])\nd = p.transpose()\nd.rename(columns={0: 'pred', 1: 'y_test'},inplace = True)\nd","dc471595":"\nprint(classification_report(y_test,pred))","8bd2c5dd":"cmat = confusion_matrix(y_test,pred)\nprint('TN - True Negative {}'.format(cmat[0,0]))\nprint('FP - False Positive {}'.format(cmat[0,1]))\nprint('FN - False Negative {}'.format(cmat[1,0]))\nprint('TP - True Positive {}'.format(cmat[1,1]))\nprint('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\nprint('Misclassification Rate: {}'.format(np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))))","34d45d97":"### heatmap of corelation of your latest dataframe after encoding","4de441be":"## Boxplot for checking outliers","5ad3d005":"### Encoding","28aa3baa":"# Step 1: Importing Libraries","53295be2":"# Exploratory Data Analysis(EDA)","1644eb1c":"### label Encoding\n### Backward Difference Encoding\n### Hashing Encoding\n### Helmert Encoding\n### James-Stein Encoder\n### Leave One Out Encoder\n### M-estimate Encoder\n### Mean Target Encoder\n### Polynomial Encoding\n### Sum Encoding\n### Weight Of Evidence Encoding\n### BaseN Encoding\n### Ordinal Encoding\n### One Hot Encoding\n### Binary Encoding\n### Frequency Encoding\n### Catboost Encoding","9cc4c997":"### Here I used label encoder there are more 16 encoders you can use","6837371b":"# Classification Report(Confusion matrix)","20b03789":"# Prediction Using KNN","393ebde7":"### Here first we need to do null value treatment and outliers rectification according to our need. In my data frame there are no null values and outliers rectification is not needed\n## NULL VALUE TREATMENT:\n### If there are outliers you shouldnot fill your null value with mean of that column\n### For qualitative data we need to use mode\n### If there are many null values in particular column we can remove that column same applies for rows\n### Avoid droping or deleting rows and columns since there will be lose of your data.\n## OUTLIER TREATMENT:\n### First avoid deleting rows or columns with coutliers\n### We can fill outlier values with null and then again we need to do null value treatment\n### Here if you apply mean or median to null values, fill the null values with mean or median of outliers values of that particular column not with mean or median of whole column\n### U can avoid this outlier treatment step if you outlier number is less or for small data or depending on your dataset","22bacfce":"# Feature scaling\n### U should do scaling on only when you are applying distance based algorithms","ce86cec6":"# Step 2:  Loading DataSet","23f05e8b":"### Reaarange columns","f6f86a28":"## More visualisation of numerical columns","bd8bd241":"# Data Preprocessing","9e664ecf":"# Data Visualisation","aed4e40b":"## checking outliers and displaying number of outliers in each column","0f1bbf31":"## UPVOTE IF U LIKE"}}