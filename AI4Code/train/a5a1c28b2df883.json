{"cell_type":{"3a06370f":"code","b61c5e12":"code","5266c43d":"code","73df979b":"code","6588a080":"code","994988a9":"code","c0cb866d":"code","0dfeebf4":"code","c32c3392":"code","804494d7":"code","273e53cd":"code","0b58130e":"code","2cf50e09":"code","dae47900":"code","e5ffcb4d":"code","ead6a51c":"code","1c415d81":"code","70d8f106":"code","7a583af6":"code","4cc7cc5d":"code","a52ca7a7":"code","cb47dffd":"code","937d72e0":"code","6cd80800":"code","d9394711":"code","38e6dc84":"code","377867f2":"code","cdd5ec74":"code","532e97a9":"code","00676d68":"code","aa754326":"code","5e40cb28":"code","94ba8cc2":"markdown"},"source":{"3a06370f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b61c5e12":"# Importing required libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Machine Learning model Algorithms\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\n\n#performance metrics for classification model\nfrom sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nimport warnings\nwarnings.simplefilter(\"ignore\")","5266c43d":"data = pd.read_csv('..\/input\/lungcancer\/survey_lung_cancer.csv')\ndata.head()","73df979b":"data.shape","6588a080":"# Checking Data types\ndata.info()","994988a9":"# Checking for null values\ndata.isnull().sum()","c0cb866d":"# Checking patient with lung cancer according their Age\ndata[[\"AGE\", \"LUNG_CANCER\"]].groupby(\"AGE\").count()","0dfeebf4":"# Checking patient with lung cancer according their Gender\ndata[[\"GENDER\", \"LUNG_CANCER\"]].groupby(\"GENDER\").count()","c32c3392":"#Checking Unique value in Age column\ndata.AGE.unique()","804494d7":"# Using Label Encoder to converting categorical features to Numerical values\nle = LabelEncoder()\nfor i in data.columns:\n    if data[i].dtypes=='object':\n        data[i] = le.fit_transform(data[i])\ndata.head()","273e53cd":"# Check for outlier using box plot\nplt.figure(figsize=(30,10))\ndata.boxplot()","0b58130e":"# Checking Correlation between different features\ncorrmat = data.corr()\nfig = plt.figure(figsize=(15,15))\nsns.heatmap(corrmat, cbar=True, annot=True, square=True, fmt='.2f', \n           annot_kws={'size':10})\nplt.show()","2cf50e09":"corrmat","dae47900":"data.columns","e5ffcb4d":"# Pearson's correlation is used to find linear relationship between independent and dependent variables\nfrom scipy.stats import pearsonr\nvar = ['GENDER', 'AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY','PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',\n       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH','SWALLOWING DIFFICULTY', 'CHEST PAIN']\nfor col in var:\n    coef, pval = pearsonr(data[col], data.LUNG_CANCER)\nprint('Correlation b\/w Lung Cancer and %s - coef: %.2f, pval: %f' %(col, coef, pval))","ead6a51c":"# Visualizing Total_booking Vs other features to generate insights\nfig, axs = plt.subplots(ncols=2, nrows=8, figsize=(12,20))\ni = 0\nj = 0\nfor var in ['GENDER', 'AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY',\n       'PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',\n       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',\n       'SWALLOWING DIFFICULTY', 'CHEST PAIN']:\n    sns.regplot(x='LUNG_CANCER', y=var, data =data, ax= axs[i][j])\n    j +=1\n    if j>1:\n        i += 1\n        j =0","1c415d81":"X = data.drop([\"LUNG_CANCER\"], axis=1)\ny = data[\"LUNG_CANCER\"]","70d8f106":"# Applying train test split in data\nX_train,X_test,y_train,y_test=train_test_split(X, y,test_size=0.20, random_state = 7)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","7a583af6":"lr = LinearRegression()\nlr.fit(X_train, y_train)\nprint(\"The final coefficients after training is :\", lr.coef_)\nprint(\"The final intercept after training is :\", lr.intercept_)","4cc7cc5d":"predicted = lr.predict(X)\nprint(\"Prediction values: \", predicted[:8])\nprint(\"Actual values:\\n\", data[['CHRONIC DISEASE','LUNG_CANCER']][:8])","a52ca7a7":"# checking r2 Score, MAE, RMSE values of model\ny_pred = lr.predict(X_test)\nprint(\"r2 score of model is:\", r2_score(y_test,y_pred))\nprint(\"MAE of model is:\", mean_absolute_error(y_test,y_pred))\nprint(\"RMSE of model is:\", mean_squared_error(y_test,y_pred))","cb47dffd":"#Cross Validation\n# fitting a model and computing the score 5 consecutive times (with different splits each time)\nscores = cross_val_score(lr, X, y, cv=5)\n\nprint(\"Scores:\",scores)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","937d72e0":"k_fold  = KFold(n_splits=5)\nscores = cross_val_score(lr, X, y, cv=k_fold, scoring='neg_mean_squared_error')\n\nprint(\"Scores:\",scores)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","6cd80800":"from sklearn.preprocessing import PolynomialFeatures\ndegree_max = 6\n\nscores = []\ncv_scores = []\nfor i in range(1, degree_max+1):\n    poly = PolynomialFeatures(i)\n    X_poly = poly.fit_transform(X)\n    slm_poly = LinearRegression()\n    slm_poly.fit(X_poly, y)\n    predict_poly = slm_poly.predict(X_poly)\n    score = mean_squared_error(y, predict_poly)\n    scores.append(score)\n    \n    #Generate mean of cross validation scores\n    cv_scores.append(cross_val_score(slm_poly, X_poly, y, cv=5, scoring='neg_mean_squared_error'))","d9394711":"scoring = ['neg_mean_squared_error', 'r2']\nscores = cross_validate(lr, X, y, scoring=scoring,cv=5, return_train_score=False)\nprint(sorted(scores.keys()))\n\nprint('Mean squared error:',scores['test_neg_mean_squared_error'].mean())\nprint('r2:',scores['test_r2'].mean())","38e6dc84":"#Computing bootstrap\n\ndata = data.LUNG_CANCER\nsample_1 = np.random.choice(data, len(data))\n\nprint(\"Mean: %.4f, Median: %.4f, and Standard Deviation: %.4f of MEDV\" \n      %(np.mean(data), np.median(data), np.std(data)))\nprint(\"Mean: %.4f, Median: %.4f, and Standard Deviation: %.4f of sample\" \n      %(np.mean(sample_1), np.median(sample_1), np.std(sample_1)))","377867f2":"#Ridge Regression\n\nfrom sklearn.linear_model import Ridge\n\nclf = Ridge(alpha=1.0)\n\n# fitting a model and computing the score 5 consecutive times (with different splits each time)\nscores = cross_val_score(clf, X, y, cv=5)\n\nprint(\"Scores:\",scores)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","cdd5ec74":"#The Lasso\nfrom sklearn.linear_model import Lasso\nclf = Lasso(alpha=0.1)\n\n# fitting a model and computing the score 5 consecutive times (with different splits each time)\nscores = cross_val_score(clf, X, y, cv=5)\n\nprint(\"Scores:\",scores)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","532e97a9":"print('Mean Squared Error: %0.4f'%mean_squared_error(y_test,y_pred))\nprint('Root Mean Squared Error %.4f'%np.sqrt(mean_squared_error(y_test,y_pred)))\nprint('R2 Score: %0.4f'%r2_score(y_test,y_pred))\ncv_lin_model=cross_val_score(LinearRegression(),X,y,cv=10)\n#Accuracy\nprint('Accuracy : %.4f (+\/- %.3f)'%(cv_lin_model.mean(),cv_lin_model.std()*2))","00676d68":"params = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}","aa754326":"reg = GradientBoostingRegressor(**params)\nreg.fit(X_train, y_train)\n\nmse = mean_squared_error(y_test, reg.predict(X_test))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))","5e40cb28":"test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\nfor i, y_pred in enumerate(reg.staged_predict(X_test)):\n    test_score[i] = reg.loss_(y_test, y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, reg.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","94ba8cc2":"There is a Linear relationship between the variables "}}