{"cell_type":{"7bb2355b":"code","46c72ea0":"code","5504c898":"code","3d9a39aa":"code","688aacfe":"code","9bd59dcd":"code","9fbe5af9":"code","8e12b119":"code","0899cf92":"code","7039bcdd":"code","7c02f20d":"code","f7d43119":"code","b71a2694":"code","c5751c6a":"code","644e40bf":"code","069dc47d":"code","75dcc52b":"code","00a34a1f":"code","d1f7368f":"code","88737541":"code","6a53d10c":"code","dfde7a33":"code","5f81951e":"code","b5aa2d4f":"code","7c9028a1":"markdown","0b0bade7":"markdown","26179bce":"markdown","f9fdd598":"markdown","a7b9593a":"markdown","6e8f7afc":"markdown","f1749f81":"markdown","a23860d5":"markdown"},"source":{"7bb2355b":"import torchvision\nimport  torch.nn as nn\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms,models,datasets\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nfrom torch import optim","46c72ea0":"train_data_dir = '\/kaggle\/input\/cat-and-dog\/training_set\/training_set'\n\ntransform = transforms.Compose([transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor()])\n\ndataset = torchvision.datasets.ImageFolder(train_data_dir, transform= transform)\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=400 ,shuffle=True)","5504c898":"test_data_dir = '\/kaggle\/input\/cat-and-dog\/test_set\/test_set'\n\ntransform = transforms.Compose([transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor()])\n\ndataset = torchvision.datasets.ImageFolder(train_data_dir, transform= transform)\ntest_loader = torch.utils.data.DataLoader(dataset, batch_size=400 ,shuffle=True)","3d9a39aa":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    plt.figure(figsize=(20,150))\n    plt.imshow(inp)\n\ninputs, classes = next(iter(train_loader))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs, scale_each= True)\n\nimshow(out)","688aacfe":"model = models.densenet121(pretrained = True)","9bd59dcd":"for params in model.parameters():\n    params.requires_grad = False","9fbe5af9":"from collections import OrderedDict\n\nclassifier = nn.Sequential(OrderedDict([\n    ('fc1',nn.Linear(1024,500)),\n    ('relu',nn.ReLU()),\n    ('fc2',nn.Linear(500,2)),\n    ('Output',nn.LogSoftmax(dim=1))\n]))\n\nmodel.classifier = classifier","8e12b119":"model = model.cuda()","0899cf92":"test_dir=\"\/kaggle\/input\/cat-and-dog\/test_set\"\ntrain_dir=\"\/kaggle\/input\/cat-and-dog\/training_set\"\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nbatch_size=64\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\ntarget_size = (100, 100),\nbatch_size = batch_size,\ncolor_mode='rgb',\nclass_mode = 'binary',\nshuffle=True)\n\ntest_set = test_datagen.flow_from_directory(test_dir,\ntarget_size = (100, 100),\nbatch_size = batch_size,\ncolor_mode='rgb',\nclass_mode = 'binary')","7039bcdd":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\nfrom keras.optimizers import adam\nimport numpy as np\n# Initialising the CNN\nclassifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Conv2D(32, (3, 3), input_shape = (100, 100, 3)))\nclassifier.add(Activation(\"relu\"))\nclassifier.add(MaxPooling2D(pool_size = (3, 3)))\nclassifier.add(Conv2D(64, (3, 3), input_shape = (100, 100, 3)))\nclassifier.add(Activation(\"relu\"))\nclassifier.add(MaxPooling2D(pool_size = (3, 3)))\n\nclassifier.add(Flatten())\n\nclassifier.add(Dense(64))\nclassifier.add(Activation(\"relu\")) \nclassifier.add(Dense(128))\nclassifier.add(Activation(\"relu\")) \nclassifier.add(Dense(activation = 'sigmoid', units=1))","7c02f20d":"classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","f7d43119":"classifier.fit_generator(training_set,\n                        steps_per_epoch=np.ceil(training_set.samples \/ batch_size),\n                        epochs=20,\n                        validation_steps=np.ceil(test_set.samples \/ batch_size),\n                         validation_data=test_set\n                        )\n","b71a2694":"import joblib\n# save the model to disk\nfilename = 'finalized_model.sav'\njoblib.dump(model, filename)","c5751c6a":"import matplotlib.pyplot as plt\n# from tensorflow.keras.preprocessing import image\n# test_image = image.load_img(\"\/kaggle\/input\/dogs-vs-cats\/train\/dogs\/dog.1.jpg\", target_size = (200, 200)) \n# plt.imshow(test_image)\n# plt.grid(None) \n# plt.show()\nimport cv2\nsample_path='\/kaggle\/input\/dogs-vs-cats\/train\/dogs\/dog.1.jpg'\ntest_image=cv2.imread(sample_path)\npimg = test_image(test_image).unsqueeze(0).to(device)\nplt.imshow(pimg)\nprint(pimg.shape)","644e40bf":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nimg = Image.open(sample_path)\nnimg = np.array(img)\nplt.imshow(nimg)\npimg = transform(img).unsqueeze(0).to(device)\npimg.shape","069dc47d":"res_list= [\"It's a cat !\",\"It's a dog !\"]\nprediction = model(pimg)\n_, tpredict = torch.max(prediction.data, 1)\nprint(res_list[classes[tpredict[0].item()]])","75dcc52b":"model = joblib.load('finalized_model.sav')\nest_loss = classifier.evaluate(test_images, test_labels)","00a34a1f":"model = joblib.load('finalized_model.sav')\n\npredictions = classifier(test_image)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1)","d1f7368f":"loaded_model = joblib.load('finalized_model.sav')\nres_list= [\"It's a cat !\",\"It's a dog !\"]\ntest_image = image.img_to_array(test_image)\ntest_image_final = np.expand_dims(test_image, axis = 0)\n\nprint(res_list[int(loaded_model.predict(test_image))])","88737541":"import tensorflow as tf  \nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","6a53d10c":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","dfde7a33":"history = model.fit(training_set, test_set, batch_size=128, epochs=20, validation_split = 0.2)","5f81951e":"# testing the model\n\ndef testing_image(image_directory):\n    model = joblib.load('finalized_model.sav')\n    test_image = image.load_img(image_directory, target_size = (64, 64))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    result = model.predict(test_image)\n    print(result)\n    if result[0][0]  == 1:\n        prediction = 'Dog'\n    else:\n        prediction = 'Cat'\n    return prediction","b5aa2d4f":"print(testing_image('\/kaggle\/input\/dogs-vs-cats\/train\/dogs\/dog.1.jpg'))","7c9028a1":"optimizer= optim.Adam(model.classifier.parameters())\ncriterian= nn.NLLLoss()\nlist_train_loss=[]\nlist_test_loss=[]\n\nfor epoch in range(10):\n    train_loss= 0\n    test_loss= 0\n    for bat,(img,label) in enumerate(train_loader):\n        \n        # moving batch and lables to gpu\n        img = img.to('cuda:0')\n        label = label.to('cuda:0')\n        \n        model.train()\n        optimizer.zero_grad()\n\n        output = model(img)\n        loss = criterian(output,label)\n        loss.backward()\n        optimizer.step()\n        train_loss = train_loss+loss.item()\n        #print(bat)\n\n    accuracy=0\n    for bat,(img,label) in enumerate(test_loader):\n        img = img.to('cuda:0')\n        label = label.to('cuda:0')\n\n        model.eval()\n        logps= model(img)\n        loss = criterian(logps,label)\n\n        test_loss+= loss.item()\n        ps=torch.exp(logps)\n        top_ps,top_class=ps.topk(1,dim=1)\n        equality=top_class == label.view(*top_class.shape)\n        accuracy +=torch.mean(equality.type(torch.FloatTensor)).item()\n\n    list_train_loss.append(train_loss\/20)\n    list_test_loss.append(test_loss\/20)\n    print('epoch: ',epoch,'    train_loss:  ',train_loss\/20,'   test_loss:    ',test_loss\/20,'    accuracy:  ',accuracy\/len(test_loader))","0b0bade7":"**importing required libraries**","26179bce":"# Loading train and test data","f9fdd598":"# References:\nhttps:\/\/towardsdatascience.com\/all-the-steps-to-build-your-first-image-classifier-with-code-cf244b015799\n","a7b9593a":"# Dog-Cat Image classifier\n**Prob statement :**\nPredict the image input as Dog or cat.\n\n**Steps** :\nConvolutional Neural Network(or CNN).\nSo basically what is CNN \u2013 as we know its a machine learning algorithm for machines to understand the features of the image with foresight and remember the features to guess whether the name of the new image fed to the machine.\nCNN:-https:\/\/towardsdatascience.com\/all-the-steps-to-build-your-first-image-classifier-with-code-cf244b015799\n\n\nReferences:\nhttps:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html\n\n","6e8f7afc":"# Taking batch size of 400 images","f1749f81":"# Moving the model to gpu","a23860d5":"# Loading Densenet121 model"}}