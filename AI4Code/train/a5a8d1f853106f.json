{"cell_type":{"6b7b1216":"code","034c9153":"code","1312b866":"code","923fc6f7":"code","a154071d":"code","4ad7cfbb":"code","cf67ee12":"code","c140e8e2":"code","d0ebf771":"code","a25b5756":"code","324ace68":"code","5617ad21":"code","8b67eed0":"code","2cba9127":"code","aa535b52":"code","02dadc7b":"code","9e5efd75":"code","186372bd":"code","2f9a7103":"code","331559fc":"code","26090ada":"code","d808b2bc":"code","7046e7ab":"code","0617f023":"code","0185a5f6":"code","de08d8e5":"code","e0cd95d2":"code","9e26d3f4":"code","5f7af4bb":"code","907cce88":"code","8284366c":"code","ddb0a624":"code","11f93d22":"code","d5268dc1":"code","39dd4830":"code","3182ba29":"code","72a2a15e":"code","11fabff8":"code","3921f6e0":"code","bc5cf018":"code","04f58e0b":"code","bd8e10ff":"code","85e9c386":"code","e56e37b3":"code","1259fc90":"code","4aac309f":"code","34934675":"code","9e01fe91":"code","eef5de50":"code","51dda86f":"code","ba40cd47":"code","a2205357":"code","99ef0048":"code","b262a6f1":"code","a1f15d0a":"code","6df09781":"code","08bf15f5":"code","9aea5e55":"code","f8ac5d36":"code","6f8654f7":"code","76e56469":"code","c5d420d3":"code","4561884d":"code","69a18bfe":"code","2b2a8268":"code","466cd300":"code","456b540e":"code","cc1077f8":"code","428b641a":"code","bbdb1822":"code","c1d3eddb":"code","4be437e6":"code","ff2055be":"code","f27723d3":"code","e4624738":"code","7e010bfd":"code","c1c8b2f1":"code","f402bfd6":"code","6522d5d0":"code","a1fe9980":"code","f6f585c9":"code","bb23318f":"code","78b5a469":"code","c74f5b5d":"code","76b5d598":"code","265f6146":"code","b76c7f09":"code","5f3f815a":"code","2ee8fd92":"code","96585e66":"code","69055f0c":"code","7070b074":"code","f2ff7869":"code","a012a5c8":"code","990cfff8":"code","a0d66672":"code","06962658":"code","d061ada7":"code","6b20ed6d":"markdown","997ebb61":"markdown","4ce34ca7":"markdown","1759e21f":"markdown","08a394b5":"markdown","f41d9cb9":"markdown","23198ba5":"markdown","96ad7668":"markdown","e63c870e":"markdown","e8fd59a6":"markdown","7abacbc2":"markdown","ae905085":"markdown","daed4f96":"markdown","2d9711cc":"markdown","4504a36b":"markdown","621f3e69":"markdown","59aa6d0b":"markdown","267b5852":"markdown","707a918a":"markdown","1e3b4c81":"markdown","ac7efc3b":"markdown","8b1d8d90":"markdown","9c01e663":"markdown","fbc973dc":"markdown","853e8883":"markdown","28ffd9bf":"markdown","180717bb":"markdown","3f162c51":"markdown","00325883":"markdown","5a01227c":"markdown","c8832222":"markdown","baf41d4b":"markdown","9e929920":"markdown","fdb2dc14":"markdown","6b31b7b5":"markdown","2fbeac8b":"markdown","c98976bf":"markdown","cb7fab53":"markdown","ec601184":"markdown","0d592005":"markdown","2835d5f8":"markdown","0a24bb1c":"markdown","421737cb":"markdown","04bbfe67":"markdown","3ab00571":"markdown","cfb98fb4":"markdown","f7e20196":"markdown","0910366e":"markdown","02764b8d":"markdown","bf1920e5":"markdown","8de40266":"markdown","8679052d":"markdown","98645025":"markdown","5a7c2bc9":"markdown","b650448c":"markdown","21241638":"markdown","9a91d850":"markdown","0d178c47":"markdown","b3cad323":"markdown","35a70b97":"markdown","e700cd69":"markdown","0770edcb":"markdown","c3643200":"markdown","68a929f5":"markdown","48c7118a":"markdown","93369994":"markdown","cbb2d84d":"markdown","815b1af2":"markdown","4e9bbef1":"markdown","5e50fe42":"markdown","0c89c1e5":"markdown","fa531da5":"markdown","fc6dbd35":"markdown","d5a0e6a1":"markdown","df372717":"markdown","13c7214e":"markdown","423302c6":"markdown","0fe6d94c":"markdown","61a32901":"markdown","4f2c2e32":"markdown","60e50eac":"markdown","17101539":"markdown","d8cb7880":"markdown","a0111468":"markdown","f2e203a8":"markdown","79b105e8":"markdown"},"source":{"6b7b1216":"# Importing libraries\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport seaborn as sns #visualization\nimport matplotlib.pyplot as plt #visualization\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import (plot_confusion_matrix, confusion_matrix, \n                             accuracy_score, mean_squared_error, r2_score, \n                             roc_auc_score, roc_curve, classification_report, \n                             precision_recall_curve, auc, f1_score, \n                             average_precision_score, precision_score, recall_score)\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import scale, StandardScaler, RobustScaler, MinMaxScaler\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\n%config InlineBackend.figure_format = 'retina'\n\n# to display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);  # to display all columns and rows\npd.set_option('display.float_format', lambda x: '%.2f' % x) # The number of numbers that will be shown after the comma.\n","034c9153":"churn = pd.read_csv(\"..\/input\/churn-for-bank-customers\/churn.csv\", index_col = 0)\nchurn.head() # first five row of the dataset","1312b866":"# checking dataset\n\nprint (\"Rows     : \" ,churn.shape[0])\nprint (\"Columns  : \" ,churn.shape[1])\nprint (\"\\nFeatures : \\n\" ,churn.columns.tolist())\nprint (\"\\nMissing values :  \", churn.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",churn.nunique())","923fc6f7":"churn.describe().T","a154071d":"churn[\"Exited\"].value_counts()","4ad7cfbb":"#Separating churn and non churn customers\nexited     = churn[churn[\"Exited\"] == 1]\nnot_exited = churn[churn[\"Exited\"] == 0]","cf67ee12":"df = churn.drop(['CustomerId', 'Surname'], axis = 1)\ndf.head()","c140e8e2":"fig, axarr = plt.subplots(2, 3, figsize=(18, 6))\nsns.countplot(x = 'Geography', hue = 'Exited',data = df, ax = axarr[0][0])\nsns.countplot(x = 'Gender', hue = 'Exited',data = df, ax = axarr[0][1])\nsns.countplot(x = 'HasCrCard', hue = 'Exited',data = df, ax = axarr[0][2])\nsns.countplot(x = 'IsActiveMember', hue = 'Exited',data = df, ax = axarr[1][0])\nsns.countplot(x = 'NumOfProducts', hue = 'Exited',data = df, ax = axarr[1][1])\nsns.countplot(x = 'Tenure', hue = 'Exited',data = df, ax = axarr[1][2])\n","d0ebf771":"_, ax = plt.subplots(1, 3, figsize=(18, 6))\nplt.subplots_adjust(wspace=0.3)\nsns.swarmplot(x = \"NumOfProducts\", y = \"Age\", hue=\"Exited\", data = df, ax= ax[0])\nsns.swarmplot(x = \"HasCrCard\", y = \"Age\", data = df, hue=\"Exited\", ax = ax[1])\nsns.swarmplot(x = \"IsActiveMember\", y = \"Age\", hue=\"Exited\", data = df, ax = ax[2])","a25b5756":"facet = sns.FacetGrid(df, hue = \"Exited\", aspect = 3)\nfacet.map(sns.kdeplot, \"Age\", shade = True)\nfacet.set(xlim = (0, df[\"Age\"].max()))\nfacet.add_legend()\n\nplt.show();","324ace68":"_, ax =  plt.subplots(1, 2, figsize = (15, 7))\ncmap = sns.cubehelix_palette(light = 1, as_cmap = True)\nsns.scatterplot(x = \"Age\", y = \"Balance\", hue = \"Exited\", cmap = cmap, sizes = (10, 200), data = df, ax = ax[0])\nsns.scatterplot(x = \"CreditScore\", y = \"Balance\", hue = \"Exited\", cmap = cmap, sizes = (10, 200), data = df, ax = ax[1]);","5617ad21":"plt.figure(figsize = (10, 10))\nsns.swarmplot(x = \"HasCrCard\", y = \"Age\", data = df, hue = \"Exited\")","8b67eed0":"corr = df.corr()\ncorr.style.background_gradient(cmap = 'coolwarm')","2cba9127":"# NumOfProducts variable is converted to string values.\nNumOfProd = []\nfor i in df['NumOfProducts']:\n    if i == 1:\n        NumOfProd.append('A')\n    elif i == 2:\n        NumOfProd.append('B')\n    elif i == 3:\n        NumOfProd.append('C')\n    else:\n        NumOfProd.append('D')\n        \ndf['NumOfProducts'] = NumOfProd\ndf.head()","aa535b52":"dummies = pd.get_dummies(df[['Geography', 'Gender', 'NumOfProducts']], drop_first = True) \nX_ = df.drop(['Geography', 'Gender', 'NumOfProducts'], axis = 1)\ndf_1 = pd.concat([X_, dummies], axis = 1)\ndf_1.head()","02dadc7b":"df_1.Balance = df_1.Balance + 1 # To get rid of the problem of dividing by 0\ndf_1['SalBal'] = df_1.EstimatedSalary \/ df_1.Balance #The ratio of variables EstimatedSalary and Balance is assigned as a new variable\ndf_1.head()\n","9e5efd75":"df_1.head()","186372bd":"# Standardization on four features\nX_s = pd.DataFrame(df_1[['CreditScore', 'Balance', 'EstimatedSalary', 'SalBal']], \n                   columns = ['CreditScore', 'Balance', 'EstimatedSalary', 'SalBal'])\n\nMinMax = MinMaxScaler(feature_range = (0, 1)).fit(X_s)\nX_s = MinMax.transform(X_s)\nX_st = pd.DataFrame(X_s, columns = ['CreditScore', 'Balance', 'EstimatedSalary', 'SalBal'])\nX_st.index = X_st.index + 1\nX_st.head()","2f9a7103":"# We define the dataset with standardized variables as df_2.\ndf_2 = df_1.drop(['CreditScore', 'Balance', 'EstimatedSalary', 'SalBal'], axis = 1)\ndf_2 = pd.concat([df_2, X_st], axis = 1, ignore_index = False)\ndf_2.head()","331559fc":"# credit scores are divided into 6 classes.\nCreditScoreClass = []\nfor cs in churn.CreditScore:\n    if 400 <= cs < 500:\n        CreditScoreClass.append(1)\n    elif 500 <= cs < 700:\n        CreditScoreClass.append(2)\n    elif  700 <= cs < 800:\n        CreditScoreClass.append(3)\n    elif  800 <=  cs < 850:\n        CreditScoreClass.append(4)\n    elif  850 <= cs: \n        CreditScoreClass.append(5)\n    elif 400 > cs :\n        CreditScoreClass.append(0)\n\ndf_2['CreditScoreClass'] = CreditScoreClass\ndf_2.drop('CreditScore', axis = 1, inplace = True)\ndf_2.head()","26090ada":"y = df_2['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nmodels = [\n    LogisticRegression(),\n    KNeighborsClassifier(),\n    SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GradientBoostingClassifier(),\n    LGBMClassifier(),\n    XGBClassifier()]\n\nresult = []\nresults = pd.DataFrame(columns = [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    names = model.__class__.__name__\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    scores = cross_val_score(model, X_test, y_test, cv = 10, scoring = 'accuracy')\n    result = pd.DataFrame([[names, acc * 100, \n                            np.mean(scores) * 100]], \n                          columns = [\"Models\", \"Accuracy\", \"Avg_Accuracy\"])\n    results = results.append(result)\nresults","d808b2bc":"avg_accuracies={}\naccuracies={}\nroc_auc={}\npr_auc={}","7046e7ab":"def cv_score(name, model, folds):\n    scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n    avg_result = []\n    for sc in scores:\n        scores = cross_val_score(model, X_test, y_test, cv = folds, scoring = sc)\n        avg_result.append(np.average(scores))\n    df_avg_score = pd.DataFrame(avg_result)\n    df_avg_score = df_avg_score.rename(index={0: 'Accuracy',\n                                             1:'Precision',\n                                             2:'Recall',\n                                             3:'F1 score',\n                                             4:'Roc auc'}, columns = {0: 'Average'})\n    avg_accuracies[name] = np.round(df_avg_score.loc['Accuracy'] * 100, 2)\n    values = [np.round(df_avg_score.loc['Accuracy'] * 100, 2),\n            np.round(df_avg_score.loc['Precision'] * 100, 2),\n            np.round(df_avg_score.loc['Recall'] * 100, 2),\n            np.round(df_avg_score.loc['F1 score'] * 100, 2),\n            np.round(df_avg_score.loc['Roc auc'] * 100, 2)]\n    plt.figure(figsize = (15, 8))\n    sns.set_palette('mako')\n    ax = sns.barplot(x = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'Roc auc'], y = values)\n    plt.yticks(np.arange(0, 100, 10))\n    plt.ylabel('Percentage %', labelpad = 10)\n    plt.xlabel('Scoring Parameters', labelpad = 10)\n    plt.title('Cross Validation ' + str(folds) + '-Folds Average Scores', pad = 20)\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 1.02))\n    plt.show()","0617f023":"def conf_matrix(ytest, pred):\n    plt.figure(figsize = (15, 8))\n    global cm1\n    cm1 = confusion_matrix(ytest, pred)\n    ax = sns.heatmap(cm1, annot = True, cmap = 'Blues')\n    plt.title('Confusion Matrix', pad = 30)","0185a5f6":"def metrics_score(cm):\n    total = sum(sum(cm))\n    accuracy = (cm[0, 0] + cm[1, 1]) \/ total\n    precision = cm[1, 1] \/ (cm[0, 1] + cm[1, 1])\n    sensitivity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n    f1 = 2 * (precision * sensitivity) \/ (precision + sensitivity)\n    specificity = cm[0,0] \/ (cm[0, 1] + cm[0, 0])\n    values = [np.round(accuracy * 100, 2),\n            np.round(precision * 100, 2),\n            np.round(sensitivity * 100, 2),\n            np.round(f1 * 100, 2),\n            np.round(specificity * 100, 2)]\n    plt.figure(figsize = (15, 8))\n    sns.set_palette('magma')\n    ax = sns.barplot(x = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'Specificity'], y = values)\n    plt.yticks(np.arange(0, 100, 10))\n    plt.ylabel('Percentage %', labelpad = 10)\n    plt.xlabel('Scoring Parameter', labelpad = 10)\n    plt.title('Metrics Scores', pad = 20)\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 1.02))\n    plt.show()","de08d8e5":"def plot_roc_curve(fpr, tpr):\n    plt.figure(figsize = (8, 6))\n    plt.plot(fpr, tpr, color = 'Orange', label = 'ROC')\n    plt.plot([0, 1], [0, 1], color = 'black', linestyle = '--')\n    plt.ylabel('True Positive Rate', labelpad = 10)\n    plt.xlabel('False Positive Rate', labelpad = 10)\n    plt.title('Receiver Operating Characteristic (ROC) Curve', pad = 20)\n    plt.legend()\n    plt.show()","e0cd95d2":"def plot_precision_recall_curve(recall, precision):\n    plt.figure(figsize = (8,6))\n    plt.plot(recall, precision, color = 'orange', label = 'PRC')\n    plt.ylabel('Precision', labelpad = 10)\n    plt.xlabel('Recall', labelpad = 10)\n    plt.title('Precision Recall Curve', pad = 20)\n    plt.legend()\n    plt.show()","9e26d3f4":"y = df_2['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nlog_model = LogisticRegression()\nlog_model.fit(X_train, y_train)\nprediction1 = log_model.predict(X_test)\naccuracy1 = log_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy1 * 100)","5f7af4bb":"accuracies['Linear Regression'] = np.round(accuracy1 * 100, 2)","907cce88":"conf_matrix(y_test, prediction1)","8284366c":"metrics_score(cm1)","ddb0a624":"cv_score('Linear Regression', log_model, 5)","11f93d22":"probs = log_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc1 = roc_auc_score(y_test, probs)\nroc_auc['Linear Regression'] = np.round(auc1, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc1)\nfpr1, tpr1, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr1, tpr1)","d5268dc1":"precision1, recall1, _ = precision_recall_curve(y_test, probs)\nauc_score1 = auc(recall1, precision1)\npr_auc['Linear Regression'] = np.round(auc_score1, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score1)\nplot_precision_recall_curve(recall1, precision1)","39dd4830":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nKNN_model = KNeighborsClassifier()\nKNN_model.fit(X_train, y_train)\nprediction2 = KNN_model.predict(X_test)\naccuracy2 = KNN_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy2 * 100)","3182ba29":"accuracies['KNeighbors Classifier'] = np.round(accuracy2 * 100, 2)","72a2a15e":"conf_matrix(y_test, prediction2)","11fabff8":"metrics_score(cm1)","3921f6e0":"cv_score('KNeighbors Classifier', KNN_model, 5)","bc5cf018":"probs = KNN_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc2 = roc_auc_score(y_test, probs)\nroc_auc['KNeighbors Classifier'] = np.round(auc2, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc2)\nfpr2, tpr2, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr2, tpr2)","04f58e0b":"precision2, recall2, _ = precision_recall_curve(y_test, probs)\nauc_score2 = auc(recall2, precision2)\npr_auc['KNeighbors Classifier'] = np.round(auc_score2, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score2)\nplot_precision_recall_curve(recall2, precision2)","bd8e10ff":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nSVC_model = SVC(probability = True)\nSVC_model.fit(X_train, y_train)\nprediction3 = SVC_model.predict(X_test)\naccuracy3 = SVC_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy3 * 100)","85e9c386":"accuracies['Support Vector Machine Classifier'] = np.round(accuracy3 * 100, 2)","e56e37b3":"conf_matrix(y_test, prediction3)","1259fc90":"metrics_score(cm1);","4aac309f":"cv_score('Support Vector Machine Classifier', SVC_model, 5)","34934675":"probs = SVC_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc3 = roc_auc_score(y_test, probs)\nroc_auc['Support Vector Machine Classifier'] = np.round(auc3, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc3)\nfpr3, tpr3, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr3, tpr3)","9e01fe91":"precision3, recall3, _ = precision_recall_curve(y_test, probs)\nauc_score3 = auc(recall3, precision3)\npr_auc['Support Vector Machine Classifier'] = np.round(auc_score3, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score3)\nplot_precision_recall_curve(recall3, precision3)","eef5de50":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nCART_model = DecisionTreeClassifier(max_depth = 10, min_samples_split = 50)\nCART_model.fit(X_train, y_train)\nprediction4 = CART_model.predict(X_test)\naccuracy4 = CART_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy4 * 100)","51dda86f":"accuracies['Classification and Regression Tree'] = np.round(accuracy4 * 100, 2)","ba40cd47":"conf_matrix(y_test, prediction4)","a2205357":"metrics_score(cm1)","99ef0048":"cv_score('Classification and Regression Tree', CART_model, 5)","b262a6f1":"probs = CART_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc4 = roc_auc_score(y_test, probs)\nroc_auc['Desicion Tree Classifier']=np.round(auc4, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc4)\nfpr4, tpr4, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr4, tpr4)","a1f15d0a":"precision4, recall4, _ = precision_recall_curve(y_test, probs)\nauc_score4 = auc(recall4, precision4)\npr_auc['Desicion Tree Classifier'] = np.round(auc_score4, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score4)\nplot_precision_recall_curve(recall4, precision4)","6df09781":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nrf_model = RandomForestClassifier(max_features = 3, min_samples_split = 10, n_estimators = 200)\nrf_model.fit(X_train, y_train)\nprediction5 = rf_model.predict(X_test)\naccuracy5 = rf_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy5 * 100)","08bf15f5":"#rf_params = {\"n_estimators\": [100, 200, 500, 1000], \"max_features\": [3, 5, 7, 8], \"min_samples_split\": [2, 5, 10, 20]}\n#rf_cv_model = GridSearchCV(rf, rf_params, cv = 10, n_jobs = -1, verbose = 2).fit(X_train, y_train)\n#rf_cv_model.best_params_","9aea5e55":"accuracies['Random Forests'] = np.round(accuracy5 * 100, 2)","f8ac5d36":"conf_matrix(y_test, prediction5)","6f8654f7":"metrics_score(cm1)","76e56469":"cv_score('Random Forests', rf_model, 5)","c5d420d3":"probs = rf_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc5 = roc_auc_score(y_test, probs)\nroc_auc['Random Forests Classifier']=np.round(auc5, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc5)\nfpr5, tpr5, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr5, tpr5)","4561884d":"precision5, recall5, _ = precision_recall_curve(y_test, probs)\nauc_score5 = auc(recall5, precision5)\npr_auc['Random Forests'] = np.round(auc_score5,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score5)\nplot_precision_recall_curve(recall5, precision5)","69a18bfe":"feature_imp = pd.Series(rf_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","2b2a8268":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\ngbm_model = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 5, n_estimators = 300)\ngbm_model.fit(X_train, y_train)\nprediction6 = gbm_model.predict(X_test)\naccuracy6 = gbm_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy6 * 100)","466cd300":"#gbm_params = {\"learning_rate\": [0.1, 0.01, 0.001, 0.05],\"n_estimators\": [100, 300, 500, 1000], \"max_depth\":[2, 3, 5, 8]}\n#gbm_cv_model= GridSearchCV(gbm_model, gbm_params, cv = 10, n_jobs = -1, verbose = 2).fit(X_train, y_train)\n#gbm_cv_model.best_params_","456b540e":"accuracies['Gradient Boosting Machines'] = np.round(accuracy6 * 100, 2)","cc1077f8":"conf_matrix(y_test, prediction6)","428b641a":"metrics_score(cm1)","bbdb1822":"cv_score('Gradient Boosting Machines', gbm_model, 5)","c1d3eddb":"probs = gbm_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc6 = roc_auc_score(y_test, probs)\nroc_auc['Gradient Boosting Machine Classifier'] = np.round(auc6, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc6)\nfpr6, tpr6, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr6, tpr6)","4be437e6":"precision6, recall6, _ = precision_recall_curve(y_test, probs)\nauc_score6 = auc(recall6, precision6)\npr_auc['Gradient Boosting Machine Classifier'] = np.round(auc_score6, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score6)\nplot_precision_recall_curve(recall6, precision6)","ff2055be":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","f27723d3":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nxgb_model = XGBClassifier(learning_rate = 0.01, max_depth = 5, n_estimators = 1000, subsample = 0.8)\nxgb_model.fit(X_train, y_train)\nprediction7 = xgb_model.predict(X_test)\naccuracy7 = xgb_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy7 * 100)","e4624738":"#xgb_params = {\"n_estimators\": [100, 500, 1000], \"subsample\":[0.5, 0.8 ,1], \"max_depth\":[3, 5, 7], \"learning_rate\":[0.1, 0.001, 0.01, 0.05]}\n#xgb_cv_model = GridSearchCV(xgb_model, xgb_params, cv = 10, n_jobs = -1, verbose = 2).fit(X_train, y_train)\n#xgb_cv_model.best_params_","7e010bfd":"accuracies['XGBoost Classifier'] = np.round(accuracy7 * 100, 2)","c1c8b2f1":"conf_matrix(y_test, prediction7)","f402bfd6":"metrics_score(cm1)","6522d5d0":"cv_score('XGBoost Classifier', xgb_model, 5)","a1fe9980":"probs = xgb_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc7 = roc_auc_score(y_test, probs)\nroc_auc['XGB Machine Classifier']=np.round(auc7, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc7)\nfpr7, tpr7, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr7, tpr7)","f6f585c9":"precision7, recall7, _ = precision_recall_curve(y_test, probs)\nauc_score7 = auc(recall7, precision7)\npr_auc['XGB Machine Classifier'] = np.round(auc_score7, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score7)\nplot_precision_recall_curve(recall7, precision7)","bb23318f":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","78b5a469":"y = df_1['Exited']\nX = df_2.drop('Exited', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nlgbm_model = LGBMClassifier(learning_rate = 0.1, max_depth = 2, n_estimators = 500)\nlgbm_model.fit(X_train, y_train)\nprediction8 = lgbm_model.predict(X_test)\naccuracy8 = lgbm_model.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy8 * 100)","c74f5b5d":"#lgbm_params = {\"learning_rate\": [0.001, 0.01, 0.1], \"n_estimators\": [200, 500, 100], \"max_depth\":[1,2,5,8]}\n#lgbm_cv_model = GridSearchCV(lgbm_model,lgbm_params, cv = 10, n_jobs = -1, verbose = 2).fit(X_train, y_train)\n#lgbm_cv_model.best_params_","76b5d598":"accuracies['LightGBM Classifier'] = np.round(accuracy8 * 100, 2)","265f6146":"conf_matrix(y_test, prediction8)","b76c7f09":"metrics_score(cm1)","5f3f815a":"cv_score('LightGBM Classifier', lgbm_model, 5)","2ee8fd92":"probs = lgbm_model.predict_proba(X_test)\nprobs = probs[:, 1]\nauc8 = roc_auc_score(y_test, probs)\nroc_auc['LightGBM Classifier'] = np.round(auc8, 2)\nprint('Area under the ROC Curve (AUC): %.2f' % auc8)\nfpr8, tpr8, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr8, tpr8)","96585e66":"precision8, recall8, _ = precision_recall_curve(y_test, probs)\nauc_score8 = auc(recall8, precision8)\npr_auc['LightGBM Classifier'] = np.round(auc_score8, 2)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score8)\nplot_precision_recall_curve(recall8, precision8)","69055f0c":"feature_imp = pd.Series(gbm_model.feature_importances_,\n                        index = X_train.columns).sort_values(ascending = False)\n\nsns.barplot(x = feature_imp, y = feature_imp.index)\nplt.xlabel('Feature Important Scores')\nplt.ylabel('Features')\nplt.title(\"Feature Important Range\")\nplt.show()","7070b074":"\nmodels_tuned = [\n    log_model,\n    KNN_model,\n    SVC_model,\n    CART_model,\n    rf_model,\n    gbm_model,\n    lgbm_model,\n    xgb_model]\n\nresult = []\nresults = pd.DataFrame(columns = [\"Models\",\"Accuracy\"])\n\nfor model in models_tuned:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    scores = cross_val_score(model, X_test, y_test, cv = 10, scoring = 'accuracy')\n    result = pd.DataFrame([[names, acc * 100, \n                            np.mean(scores) * 100]], \n                          columns = [\"Models\", \"Accuracy\", \"Avg_Accuracy\"])\n    results = results.append(result)\nresults","f2ff7869":"plt.figure(figsize = (15, 8))\nsns.set_palette('cividis')\nax = sns.barplot(x = list(accuracies.keys()), y = list(accuracies.values()))\nplt.yticks(np.arange(0, 100, 10))\nplt.ylabel('Percentage %', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Accuracy Scores Comparison', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 1.02))\nplt.show()","a012a5c8":"plt.figure(figsize = (15, 8))\nsns.set_palette('viridis')\nax=sns.barplot(x = list(avg_accuracies.keys()), y = list(avg_accuracies.values()))\nplt.yticks(np.arange(0, 100, 10))\nplt.ylabel('Percentage %', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Average Accuracy Scores Comparison', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x() + 0.3, p.get_height() + 1.02))\nplt.show()","990cfff8":"plt.figure(figsize = (8, 6))\nsns.set_palette('Set1')\nplt.plot(fpr1, tpr1, label = 'Linear Regression')\nplt.plot(fpr2, tpr2, label = 'KNeiihbors Classifier')\nplt.plot(fpr3, tpr3, label = 'SVM')\nplt.plot(fpr4, tpr4, label = 'Decision Tree')\nplt.plot(fpr5, tpr5, label = 'Random Forests')\nplt.plot(fpr6, tpr6, label = 'Gradient Boosting MachineC')\nplt.plot(fpr7, tpr7, label = 'XGBoost')\nplt.plot(fpr8, tpr8, label = 'LightGBM')\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.ylabel('True Positive Rate', labelpad = 10)\nplt.xlabel('False Positive Rate', labelpad = 10)\nplt.title('Receiver Operating Characteristic (ROC) Curves', pad = 20)\nplt.legend()\nplt.show()","a0d66672":"plt.figure(figsize = (15, 8))\nsns.set_palette('magma')\nax = sns.barplot(x = list(roc_auc.keys()), y = list(roc_auc.values()))\n#plt.yticks(np.arange(0,100,10))\nplt.ylabel('Score', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Area under the ROC Curves (AUC)', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 0.01))\nplt.show()","06962658":"plt.figure(figsize = (8, 6))\nsns.set_palette('Set1')\nplt.plot(recall1, precision1, label = 'Linear Regression PRC')\nplt.plot(recall2, precision2, label = 'KNN PRC')\nplt.plot(recall3, precision3, label = 'SVM PRC')\nplt.plot(recall4, precision4, label = 'CART PRC')\nplt.plot(recall5, precision5, label = 'Random Forests PRC')\nplt.plot(recall6, precision6, label = 'GBM PRC')\nplt.plot(recall7, precision7, label = 'XGB PRC')\nplt.plot(recall8, precision8, label = 'LGBM PRC')\nplt.ylabel('Precision', labelpad = 10)\nplt.xlabel('Recall', labelpad = 10)\nplt.title('Precision Recall Curves', pad = 20)\nplt.legend()\nplt.show()","d061ada7":"plt.figure(figsize = (15, 8))\nsns.set_palette('mako')\nax = sns.barplot(x = list(pr_auc.keys()), y = list(pr_auc.values()))\nplt.ylabel('Score', labelpad = 10)\nplt.xlabel('Algorithms', labelpad = 10)\nplt.title('Area under the PR Curves (AUCPR)', pad = 20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()), xytext = (p.get_x() + 0.3, p.get_height() + 0.01))\nplt.show()","6b20ed6d":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of GBM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","997ebb61":"## 3. Support Vector Machine Classifier:\n","4ce34ca7":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of CART Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","1759e21f":"Plotting different metrics scores for the CART Classifier for evaluation.","08a394b5":"Plotting different metrics scores for the XGBM Classifier for evaluation.","f41d9cb9":"Plotting different metrics scores for the KNN Classifier for evaluation.","23198ba5":"## Data Visualization\u00b6\n","96ad7668":"Plotting the AUC values of ROC Curve of the machine learning models for comparison.","e63c870e":"## 5. Random Forests:\n\n\nA Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.","e8fd59a6":"## Feature Importance:","7abacbc2":"* Plotting the average of different metrics scores for further evaluation.","ae905085":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Random Forest Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","daed4f96":"Storing model accuracy to plot for comparison with other Machine Learning models.","2d9711cc":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of LGBM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","4504a36b":"Storing model accuracy to plot for comparison with other Machine Learning models.","621f3e69":"\nPlotting the PR Curve of the machine learning models for comparison.","59aa6d0b":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of KNN Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","267b5852":"1. Plotting Confusion Matrix to describe the performance of XGBM Classifier on a set of test data.","707a918a":"## Feature Importance:","1e3b4c81":"Importing the libraries","ac7efc3b":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","8b1d8d90":"1. Plotting Confusion Matrix to describe the performance of CART Classifier on a set of test data.","9c01e663":"## 8. Light GBM","fbc973dc":"1. Plotting Confusion Matrix to describe the performance of Linear Regression Classifier on a set of test data.","853e8883":"\nPlotting the average accuracy metric score of the machine learning models for comparison.","28ffd9bf":"Plotting different metrics scores for the Linear Regression Classifier for evaluation.","180717bb":"## Performance Comparison\n\nPlotting the accuracy metric score of the machine learning models for comparison.","3f162c51":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of XGBM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","00325883":"## Feature Importance:","5a01227c":"### Defining function to create Confusion Matrix.","c8832222":"* Plotting the average of different metrics scores for further evaluation.","baf41d4b":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","9e929920":"* Plotting the average of different metrics scores for further evaluation.","fdb2dc14":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","6b31b7b5":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Linear Regression Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","2fbeac8b":"1. Plotting Confusion Matrix to describe the performance of SVM Classifier on a set of test data.","c98976bf":"### Standardization","cb7fab53":"## 7. XGBoost:","ec601184":"KNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.","0d592005":"### Our aim in this project was to develop a churn prediction model using machine learning algorithms.\n\n### There were 10000 rows in the data set and there were no missing values.\n\n### The dataset consisted of 13 variables.\n\n### The following conclusions came from the analysis on the features:\n\n* Most customers who using products 3 and 4 stopped working with the bank. In fact, all customers using product number 4 were gone.\n* Customers between the ages of 40 and 65 were more likely to quit the bank.\n* Those who had a credit score below 450 had high abandonment rates.\n* Predictions were made with a total of 8 classification models. The highest head was taken with Random Forests.\n* Accuracy and cross validation scores were calculated for each model and results were displayed.\n","2835d5f8":"# CHURN PREDICTION PROJECT\n\n\n------\n\n\nA bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon.\n\n### Dataset\nhttps:\/\/www.kaggle.com\/mathchi\/churn-for-bank-customers\n\nAbout dataset\n\n**RowNumber** : Corresponds to the record (row) number and has no effect on the output.\n\n**CustomerId** :Contains random values and has no effect on customer leaving the bank.\n\n**Surname** : The surname of a customer has no impact on their decision to leave the bank.\n\n**CreditScore** : Can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n\n**Geography** : A customer\u2019s location can affect their decision to leave the bank.\n\n**Gender** : It\u2019s interesting to explore whether gender plays a role in a customer leaving the bank.\n\n**Age** : This is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n\n**Tenure** : Refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n\n**Balance** : Also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to close with lower balances.\n\n**NumOfProducts** : Refers to the number of products that a customer has purchased through the bank.\n\n**HasCrCard** : Denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n\n**IsActiveMember** : Active customers are less likely to leave the bank.\n\n**EstimatedSalary** : As with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n\n**Exited** : Whether or not the customer left the bank.","0a24bb1c":"Storing model accuracy to plot for comparison with other Machine Learning models.","421737cb":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of SVM Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between churn und nonchurn customers.","04bbfe67":"## Machine Learning:\n\n\nWe will train out data on different machine learning models and use different techniques on each model and then compare our finding at the end to determine which model is working best for out data.\n\n\n----- Model Performance and Comparison -----\n\nTo measure the performance of a model, we need several elements\nConfusion matrix : also known as the error matrix, allows visualization of the performance of an algorithm\n\n- True Positive (TP) : Exited correctly identified as exited\n- True Negative (TN) : Nonexited correctly identified as nonexited\n- False Positive (FP) : Nonexited incorrectly identified as exited\n- False Negative (FN) : Exited incorrectly identified as nonexited\n\n\nMetrics\n\n- Accuracy : (TP + TN) \/ (TP + TN + FP +FN)\n- Precision : TP \/ (TP + FP)\n- Recall : TP \/ (TP + FN)\n- F1 score : 2 x ((Precision x Recall) \/ (Precision + Recall))\n","3ab00571":"## 1. Logistic Regression Classifier:","cfb98fb4":"1. Plotting Confusion Matrix to describe the performance of KNN Classifier on a set of test data.","f7e20196":"Plotting different metrics scores for the GBM Classifier for evaluation.","0910366e":"Storing model accuracy to plot for comparison with other Machine Learning models.","02764b8d":"\nPlotting the ROC Curve of the machine learning models for comparison.","bf1920e5":"Plotting different metrics scores for the LGBM Classifier for evaluation.","8de40266":"* Plotting the average of different metrics scores for further evaluation.","8679052d":"### Checking Correlation\n","98645025":"### Defining function to calculate the Metrics Scores.","5a7c2bc9":"### Defining variables to store the outputs.","b650448c":"### Defining function to calculate the Cross-Validation score.\n","21241638":"Plotting the AUC values of PR Curve of the machine learning models for comparison.","9a91d850":"Storing model accuracy to plot for comparison with other Machine Learning models.","0d178c47":"Plotting different metrics scores for the SVM Classifier for evaluation.","b3cad323":"Storing model accuracy to plot for comparison with other Machine Learning models.","35a70b97":"### Defining function to plot Precision-Recall Curve.","e700cd69":"1. Plotting Confusion Matrix to describe the performance of Random Forest Classifier on a set of test data.","0770edcb":"1. Plotting Confusion Matrix to describe the performance of LGBM Classifier on a set of test data.","c3643200":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","68a929f5":"* Plotting the average of different metrics scores for further evaluation.","48c7118a":"Plotting different metrics scores for the Random Forest Classifier for evaluation.","93369994":"## Feature Importance:","cbb2d84d":"Storing model accuracy to plot for comparison with other Machine Learning models.","815b1af2":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","4e9bbef1":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","5e50fe42":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","0c89c1e5":"1. Plotting Confusion Matrix to describe the performance of GBM Classifier on a set of test data.","fa531da5":"### Dropping Irrelevant Feature\nCustomerId and Surname are irrelivant, so we drop those features.","fc6dbd35":"Storing model accuracy to plot for comparison with other Machine Learning models.","d5a0e6a1":"## Data overview","df372717":"Reading the dataset","13c7214e":"# - - - -  REPORTING  - - - -\n\n\n\n","423302c6":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","0fe6d94c":"## 4. Classification and Regression Tree:\n\n\nDecision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.","61a32901":"## 2. KNNeighbors Classifier:","4f2c2e32":"* Plotting the average of different metrics scores for further evaluation.","60e50eac":"Customer with 3 or 4 products are higher chances to Churn\n\n","17101539":"- 40 to 65 years old customers are higher chances to churn\n- Customer with CreditScore less then 450 are higher chances to churn","d8cb7880":"## 6. Gradient Boosting Machines","a0111468":"* Plotting the average of different metrics scores for further evaluation.","f2e203a8":"### Defining function to plot ROC Curve.","79b105e8":"* Plotting the average of different metrics scores for further evaluation."}}