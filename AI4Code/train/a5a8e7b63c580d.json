{"cell_type":{"4ad88a90":"code","92f8206a":"code","3e25b0c9":"code","10948555":"code","fbd61645":"code","8e9b1d35":"code","e3ab68bb":"code","9f21d987":"code","4990289e":"code","eaec2772":"code","cf252ee2":"code","2692c094":"code","aa889de3":"code","c3444baa":"code","eb81aebc":"code","947a5698":"code","b70142fc":"code","86a30a35":"code","242ca7be":"code","18a31519":"code","d38592bb":"code","50471945":"code","55856665":"code","a89cc4b8":"code","898847e0":"code","f052b025":"code","d1e46a74":"code","cd515e16":"code","a129ce07":"code","76f4d59f":"code","12057bc9":"code","2b37aac3":"code","85364e8b":"code","b2f2b5b1":"code","d115603e":"code","59d6ed7d":"code","edee6fb8":"code","ee94d4ad":"code","4c16eaa9":"code","fa59cf84":"code","7a697f4a":"code","28ece439":"code","6d8ff2b4":"code","a45b84ff":"code","e9e010e5":"code","c7c7b715":"code","df2a5797":"code","3e221b26":"code","a7af3ef6":"code","ecb569c1":"code","db241a90":"code","444df443":"code","3ef595cb":"code","fdabd9ab":"code","9e964780":"code","d7b3cc95":"code","d7c308da":"code","89de3f2b":"code","92161f45":"code","7d1cf8ba":"code","0e597f9f":"code","a9add662":"code","e07e56dd":"code","a9a61f14":"code","979da569":"code","d570b27c":"code","4ab4dd77":"code","0bf4c16b":"code","1e780a06":"code","971c664e":"code","1baf99dd":"code","2c47112a":"code","c92b5452":"code","a7ddabbb":"markdown","6d2ec950":"markdown","85dc2d23":"markdown","494378af":"markdown","6c48b770":"markdown","1ad418e9":"markdown","6a87f79b":"markdown","a23657a6":"markdown","c8a96364":"markdown","e13146ef":"markdown","917170be":"markdown","8d76dfa5":"markdown","7d924240":"markdown","86d6fc7a":"markdown","0afc7ba4":"markdown","fcc8edc9":"markdown","1e2f0827":"markdown","946ebbb5":"markdown","751f356a":"markdown","2c7c80fc":"markdown","89c7b08a":"markdown","70d3dd62":"markdown"},"source":{"4ad88a90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92f8206a":"file = open('..\/input\/ict-assignement-2\/files\/ch03\/adult.data', 'r')","3e25b0c9":"def chr_int(a):\n    if a.isdigit():\n        return int(a)\n    else:\n        return 0\n                \ndata=[]\nfor line in file:\n     data1=line.split(', ')\n     if len(data1)==15:\n        data.append([chr_int(data1[0]),data1[1],chr_int(data1[2]),data1[3],chr_int(data1[4]),data1[5],data1[6],\\\n            data1[7],data1[8],data1[9],chr_int(data1[10]),chr_int(data1[11]),chr_int(data1[12]),data1[13],\\\n            data1[14]])\n","10948555":"print (data[1:2])","fbd61645":"df = pd.DataFrame(data) #  Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes \n\ndf.columns = ['age', 'type_employer', 'fnlwgt', 'education', \n                \"education_num\",\"marital\", \"occupation\", \"relationship\", \"race\",\"sex\",\n                \"capital_gain\", \"capital_loss\", \"hr_per_week\",\"country\",\"income\"]\ndf.head()","8e9b1d35":"df.tail()","e3ab68bb":"df.shape","9f21d987":"counts = df.groupby('country').size()\n\nprint (counts) ","4990289e":"counts = df.groupby('age').size().head(30) # grouping by age\nprint(counts)","eaec2772":"print(\"regroupe dans un tableau tout les hommes et en sort le nombre des lignes et de colonne avec la m\u00e9thode shape\")\nml = df[(df.sex == 'Male')] # grouping by sex\nml.shape","cf252ee2":"print(\"fait de m\u00eame qu'au dessus mais associe une s\u00e9lection pour un salaire sup\u00e9rieur \u00e0 50K\")\nml1 = df[(df.sex == 'Male')&(df.income=='>50K\\n')]\nml1.shape","2692c094":"print(\"regroupe dans un tableau tout les femmes et en sort le nombre des lignes et de colonne avec la m\u00e9thode shape\")\nfm =df[(df.sex == 'Female')]\nfm.shape","aa889de3":"print(\"fait de m\u00eame qu'au dessus mais associe une s\u00e9lection pour un salaire sup\u00e9rieur \u00e0 50K\")\nfm1 =df[(df.sex == 'Female')&(df.income=='>50K\\n')]\nfm1.shape","c3444baa":"print(\"pourcentage de personnes\/hommes\/femmes avec un salaire sup\u00e9rieur \u00e0 50K\\n\")\ndf1=df[(df.income=='>50K\\n')]\n\nprint ('The rate of people with high income is: ', int(len(df1)\/float(len(df))*100), '%.' )\nprint ('The rate of men with high income is: ', int(len(ml1)\/float(len(ml))*100), '%.' )\nprint ('The rate of women with high income is: ', int(len(fm1)\/float(len(fm))*100), '%.' )","eb81aebc":"print ('The average age of men is: ', ml['age'].mean(), '.' )\nprint ('The average age of women is: ', fm['age'].mean(), '.')","947a5698":"print ('The average age of high-income men is: ', ml1['age'].mean(), '.' )\nprint ('The average age of high-income women is: ', fm1['age'].mean(), '.')","b70142fc":"ml_mu = ml['age'].mean()\nfm_mu = fm['age'].mean()\nml_var = ml['age'].var()\nfm_var = fm['age'].var()\nml_std = ml['age'].std()\nfm_std = fm['age'].std()\n\nprint ('Statistics of age for men: \\nmu:', ml_mu, '\\nvar:', ml_var, '\\nstd:', ml_std)\nprint ('Statistics of age for women: \\nmu:', fm_mu, '\\nvar:', fm_var, '\\nstd:', fm_std)","86a30a35":"ml_mu_hr = ml['hr_per_week'].mean()\nfm_mu_hr = fm['hr_per_week'].mean()\nml_var_hr = ml['hr_per_week'].var()\nfm_var_hr = fm['hr_per_week'].var()\nml_std_hr = ml['hr_per_week'].std()\nfm_std_hr = fm['hr_per_week'].std()\n\nprint ('Statistics of hours per week for men: \\nmu:', ml_mu_hr, '\\nvar:', ml_var_hr, '\\nstd:', ml_std_hr)\nprint ('Statistics of hours per week for women: \\nmu:', fm_mu_hr, '\\nvar:', fm_var_hr, '\\nstd:', fm_std_hr)","242ca7be":"ml_median= ml['age'].median()\nfm_median= fm['age'].median()\n\nprint (\"Median age per men and women: \", ml_median, fm_median)","18a31519":"ml_median_age= ml1['age'].median()\nfm_median_age= fm1['age'].median()\n\nprint (\"Median age per men and women with high-income: \", ml_median_age, ' ', fm_median_age)","d38592bb":"ml_median_hr= ml['hr_per_week'].median()\nfm_median_hr= fm['hr_per_week'].median()\nprint (\"Median hours per week per men and women: \", ml_median_hr, fm_median_hr)","50471945":"ml_age=ml['age']\nml_age.hist(density=0, histtype='stepfilled', bins=20)","55856665":"fm_age=fm['age']\nfm_age.hist(density=0, histtype='stepfilled', bins=20)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Female samples',fontsize=15)\nplt.show()","a89cc4b8":"import seaborn as sns\nfm_age.hist(density=0, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\nml_age.hist(density=0, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"blue\", .75), bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Samples',fontsize=15)\nplt.show()","898847e0":"fm_age.hist(density=1, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\nml_age.hist(density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('PMF',fontsize=15)\nplt.show()","f052b025":"ml_age.hist(density=1, histtype='stepfilled', bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","d1e46a74":"fm_age.hist(density=1, histtype='stepfilled', bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","cd515e16":"ml_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","a129ce07":"ml_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5)   # default number of bins = 10\nfm_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","76f4d59f":"ml_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20)\nfm_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20, color=sns.desaturate(\"indianred\", .75))\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","12057bc9":"print (\"The mean sample difference is \", ml_age.mean() - fm_age.mean())","2b37aac3":"df['age'].median()","85364e8b":"len(df[(df.income == '>50K\\n') & (df['age'] < df['age'].median() - 15)])","b2f2b5b1":"len(df[(df.income == '>50K\\n') & (df['age'] > df['age'].median() + 35)])\n","d115603e":"df2 = df.drop(df.index[(df.income=='>50K\\n') & (df['age']>df['age'].median() +35) & (df['age'] > df['age'].median()-15)])\n\ndf2.shape","59d6ed7d":"ml1_age=ml1['age']\nfm1_age=fm1['age']","edee6fb8":"ml2_age = ml1_age.drop(ml1_age.index[(ml1_age >df['age'].median()+35) & (ml1_age>df['age'].median() - 15)])\n\nfm2_age = fm1_age.drop(fm1_age.index[(fm1_age > df['age'].median()+35) & (fm1_age > df['age'].median()- 15)])","ee94d4ad":"mu2ml = ml2_age.mean()\nstd2ml = ml2_age.std()\nmd2ml = ml2_age.median()\n\n# Computing the mean, std, median, min and max for the high-income male population\n\nprint (\"Men statistics: \\nMean:\", mu2ml, \"\\nStd:\", std2ml, \"\\nMedian:\", md2ml, \"\\nMin:\", ml2_age.min(), \"\\nMax:\",ml2_age.max())","4c16eaa9":"mu3ml = fm2_age.mean()\nstd3ml = fm2_age.std()\nmd3ml = fm2_age.median()\n\n# Computing the mean, std, median, min and max for the high-income female population\nprint (\"Women statistics: \\nMean:\", mu3ml, \"\\nStd:\", std3ml, \"\\nMedian:\", md3ml, \"\\nMin:\", fm2_age.min(), \"\\nMax:\",fm2_age.max())","fa59cf84":"print ('The mean difference with outliers is: %4.2f.'% (ml_age.mean() - fm_age.mean()))\nprint (\"The mean difference without outliers is: %4.2f.\"% (ml2_age.mean() - fm2_age.mean()))","7a697f4a":"plt.figure(figsize=(13.4,5))\n\ndf.age[(df.income == '>50K\\n')].plot(alpha=.25, color='blue')\ndf2.age[(df2.income == '>50K\\n')].plot(alpha=.45,color='red')\n\nplt.ylabel('Age')\nplt.xlabel('Samples')","28ece439":"countx,divisionx = np.histogram(ml2_age, density=True)\ncounty,divisiony = np.histogram(fm2_age, density=True)","6d8ff2b4":"val = [(divisionx[i]+divisionx[i+1])\/2 for i in range(len(divisionx)-1)]\n\nplt.plot(val, countx-county,'o-')\nplt.title('Differences in promoting men vs. women')\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Differences',fontsize=15)\nplt.show()","a45b84ff":"print (\"Remember:\\n We have the following mean values for men, women and the difference:\\nOriginally: \", ml_age.mean(), fm_age.mean(),  ml_age.mean()- fm_age.mean()) # The difference between the mean values of male and female populations.)\nprint (\"For high-income: \", ml1_age.mean(), fm1_age.mean(), ml1_age.mean()- fm1_age.mean()) # The difference between the mean values of male and female populations.)\nprint (\"After cleaning: \", ml2_age.mean(), fm2_age.mean(), ml2_age.mean()- fm2_age.mean()) # The difference between the mean values of male and female populations.)\n\nprint (\"\\nThe same for the median:\")\nprint (ml_age.median(), fm_age.median(), ml_age.median()- fm_age.median()) # The difference between the mean values of male and female populations.)\nprint (ml1_age.median(), fm1_age.median(), ml1_age.median()- fm1_age.median()) # The difference between the mean values of male and female populations.)\nprint (ml2_age.median(), fm2_age.median(), ml2_age.median()- fm2_age.median()), # The difference between the mean values of male and female populations.)","e9e010e5":"def skewness(x):\n    res=0\n    m=x.mean()\n    s=x.std()\n    for i in x:\n        res+=(i-m)*(i-m)*(i-m)\n    res\/=(len(x)*s*s*s)\n    return res\n\nprint (\"The skewness of the male population is:\", skewness(ml2_age))\nprint (\"The skewness of the female population is:\", skewness(fm2_age))","c7c7b715":"def pearson(x):\n    return 3*(x.mean()-x.median())\/x.std()\n\nprint (\"The Pearson's coefficient of the male population is:\", pearson(ml2_age))\nprint (\"The Pearson's coefficient of the female population is:\", pearson(fm2_age))","df2a5797":"ml1 = df[(df.sex == 'Male')&(df.income=='>50K\\n')]\n\nml2 = ml1.drop(ml1.index[(ml1['age']>df['age'].median() +35)&(ml1['age']> df['age'].median()- 15)])\n\nfm2 = fm1.drop(fm1.index[(fm1['age']> df['age'].median() + 35)& (fm1['age']> df['age'].median() - 15)])\n\nprint (ml2.shape, fm2.shape)","3e221b26":"print (\"Men grouped in 3 categories:\")\nprint (\"Young:\",int(round(100*len(ml2_age[ml2_age<41])\/float(len(ml2_age.index)))),\"%.\")\nprint (\"Elder:\", int(round(100*len(ml2_age[ml2_age >44])\/float(len(ml2_age.index)))),\"%.\")\nprint (\"Average age:\", int(round(100*len(ml2_age[(ml2_age>40) & (ml2_age< 45)])\/float(len(ml2_age.index)))),\"%.\")","a7af3ef6":"print (\"Women grouped in 3 categories:\")\nprint (\"Young:\",int(round(100*len(fm2_age[fm2_age <41])\/float(len(fm2_age.index)))),\"%.\")\nprint (\"Elder:\", int(round(100*len(fm2_age[fm2_age >44])\/float(len(fm2_age.index)))),\"%.\")\nprint (\"Average age:\", int(round(100*len(fm2_age[(fm2_age>40) & (fm2_age< 45)])\/float(len(fm2_age.index)))),\"%.\")","ecb569c1":"print (\"The male mean:\", ml2_age.mean())\nprint (\"The female mean:\", fm2_age.mean())","db241a90":"ml2_young = len(ml2_age[(ml2_age<41)])\/float(len(ml2_age.index))\nfm2_young  = len(fm2_age[(fm2_age<41)])\/float(len(fm2_age.index))\nprint (\"The relative risk of female early promotion is: \", 100*(1-ml2_young\/fm2_young))","444df443":"ml2_elder = len(ml2_age[(ml2_age>44)])\/float(len(ml2_age.index))\nfm2_elder  = len(fm2_age[(fm2_age>44)])\/float(len(fm2_age.index))\nprint (\"The relative risk of male late promotion is: \", 100*ml2_elder\/fm2_elder)","3ef595cb":"l = 3\nx=np.arange(0,2.5,0.1)\ny= 1- np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential CDF: $\\lambda$ =%.2f'% l ,fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","fdabd9ab":"from __future__ import division\nimport scipy.stats as stats\n\nl = 3\nx=np.arange(0,2.5,0.1)\ny= l * np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential PDF: $\\lambda$ =%.2f'% l, fontsize=15)\nplt.xlabel('x', fontsize=15)\nplt.ylabel('PDF', fontsize=15)\nplt.show()","9e964780":"l = 0.25\n\nx=np.arange(0,25,0.1)\ny= l * np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential: $\\lambda$ =%.2f' %l ,fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('PDF',fontsize=15)\nplt.show()","d7b3cc95":"u=6 # mean\ns=2 # standard deviation\n\nx=np.arange(0,15,0.1)\n\ny=(1\/(np.sqrt(2*np.pi*s*s)))*np.exp(-(((x-u)**2)\/(2*s*s)))\n\nplt.plot(x,y,'-')\nplt.title('Gaussian PDF: $\\mu$=%.1f, $\\sigma$=%.1f'%(u,s),fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('Probability density',fontsize=15)\nplt.show()","d7c308da":"fig, ax = plt.subplots(1, 4, sharey=True, squeeze=True, figsize=(14, 5))\nx = np.linspace(0, 1, 100)\nfor i in range(4):\n    f = np.mean(np.random.random((10000, i+1)), 1)\n    m, s = np.mean(f), np.std(f, ddof=1)\n    fn = (1\/(s*np.sqrt(2*np.pi)))*np.exp(-(x-m)**2\/(2*s**2))  # normal pdf            \n    ax[i].hist(f, 40, density=True, color=[0, 0.2, .8, .6]) \n    ax[i].set_title('n=%d' %(i+1))\n    ax[i].plot(x, fn, color=[1, 0, 0, .6], linewidth=5)\nplt.suptitle('Demonstration of the central limit theorem for a uniform distribution', y=1.05)\nplt.show()","89de3f2b":"from scipy.stats.distributions import norm\n\n# Some random data\ny = np.random.random(15) * 10\nx = np.linspace(0, 10, 100)\n\nx1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\nx2 = np.random.normal(6, 3, 10)\ny = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\nx = np.linspace(min(y), max(y), 100)\n\n# Smoothing parameter\ns = 0.4\n\n# Calculate the kernels\nkernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n\nplt.plot(x, kernels, 'k:')\nplt.plot(x, kernels.sum(1), 'r')\nplt.plot(y, np.zeros(len(y)), 'go', ms=10)","92161f45":"from scipy.stats import kde\n\nx1 = np.random.normal(-1, 0.5, 15)\n\n# parameters: (loc=0.0, scale=1.0, size=None)\n\nx2 = np.random.normal(6, 1, 10)\ny = np.r_[x1, x2]\n\n# r_ Translates slice objects to concatenation along the first axis.\n\nx = np.linspace(min(y), max(y), 100)\ns = 0.4   # Smoothing parameter\n\nkernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n\n# Calculate the kernels\ndensity = kde.gaussian_kde(y)\n\nplt.plot(x, kernels, 'k:')\nplt.plot(x, kernels.sum(1), 'r')\nplt.plot(y, np.zeros(len(y)), 'bo', ms=10)\ny","7d1cf8ba":"xgrid = np.linspace(x.min(), x.max(), 200)\nplt.hist(y, bins=28, density=True)\nplt.plot(xgrid, density(xgrid), 'r-')","0e597f9f":"# Create a bi-modal distribution with a mixture of Normals.\n\nx1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\nx2 = np.random.normal(6, 3, 10)\n\n# Append by row\nx = np.r_[x1, x2]\n\n# r_ Translates slice objects to concatenation along the first axis.\nplt.hist(x, bins=18, density=True)","a9add662":"density = kde.gaussian_kde(x)\nxgrid = np.linspace(x.min(), x.max(), 200)\nplt.hist(x, bins=18, density=True)\nplt.plot(xgrid, density(xgrid), 'r-')","e07e56dd":"x = np.random.normal(0.0, 1.0, 10000)\na = plt.hist(x,50,density='True')","a9a61f14":"print ('The empirical mean of the sample is ', x.mean())","979da569":"NTs=200\nmu=0.0\nvar=1.0\nerr = 0.0\nNPs=1000\nfor i in range(NTs):\n    x = np.random.normal(mu, var, NPs)\n    err += (x.mean()-mu)**2\n\nprint ('MSE: ', err\/NTs)","d570b27c":"def Cov(X, Y):\n    def _get_dvis(V):\n        return [v - np.mean(V) for v in V]\n    dxis = _get_dvis(X)\n    dyis = _get_dvis(Y)\n    return np.sum([x * y for x, y in zip(dxis, dyis)])\/len(X)\n\n\nX = [5, -1, 3.3, 2.7, 12.2]\nX= np.array(X)\nY = [10, 12, 8, 9, 11]\n\nprint (\"Cov(X, X) = %.2f\" % Cov(X, X))\nprint (\"Var(X) = %.2f\" % np.var(X))\n\nprint (\"Cov(X, Y) = %.2f\" % Cov(X, Y))","4ab4dd77":"MAXN=100\nMAXN=40\n\nX=np.array([[1,9],[3, 2], [5,3],[5.5,4],[6,4],[6.5,4],[7,3.5],[7.5,3.8],[8,4],\n[8.5,4],[9,4.5],[9.5,7],[10,9],[10.5,11],[11,11.5],[11.5,12],[12,12],[12.5,12],[13,10]])","0bf4c16b":"plt.subplot(1,2,1)\nplt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\nplt.xlabel('Economic growth(T)',fontsize=15)\nplt.ylabel('Stock market returns(T)',fontsize=15)\nplt.gcf().set_size_inches((20,6))","1e780a06":"X=np.array([[1,8],[2, 7], [3,6],[4,8],[5,8],[6,7],[7,7],[8,5],[9,5],[10,6],[11,4],[12,5],[13,3],[14,2],[15,2],[16,1]])\n\nplt.subplot(1,2,1)\nplt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\nplt.xlabel('World Oil Production(T)',fontsize=15)\nplt.ylabel('Gasoline prices(T)',fontsize=15)\nplt.gcf().set_size_inches((20,6))","971c664e":"def Corr(X, Y):\n    assert len(X) == len(Y)\n    return Cov(X, Y) \/ np.prod([np.std(V) for V in [X, Y]])\n\nprint (\"Corr(X, X) = %.5f\" % Corr(X, X))\n\nY=np.random.random(len(X))\n\nprint (\"Corr(X, Y) = %.5f\" % Corr(X, Y))","1baf99dd":"def list2rank(l):\n    #l is a list of numbers\n    # returns a list of 1-based index; mean when multiple instances\n    return [np.mean([i+1 for i, sorted_el in enumerate(sorted(l)) if sorted_el == el]) for el in l]\n\nl = [7, 1, 2, 5]\nprint (\"ranks: \", list2rank(l))\n\ndef spearmanRank(X, Y):\n    # X and Y are same-length lists\n    print (list2rank(X) )\n    print (list2rank(Y))\n    return Corr(list2rank(X), list2rank(Y))\n\nX = [10, 20, 30, 40, 1000]\nY = [-70, -1000, -50, -10, -20]\nplt.plot(X,'ro')\nplt.plot(Y,'go')\n\nprint (\"Pearson rank coefficient: %.2f\" % Corr(X, Y))\nprint (\"Spearman rank coefficient: %.2f\" % spearmanRank(X, Y))","2c47112a":"X=np.array([[10.0, 8.04,10.0, 9.14, 10.0, 7.46, 8.0, 6.58],\n[8.0,6.95, 8.0, 8.14, 8.0, 6.77, 8.0, 5.76],\n[13.0,7.58,13.0,8.74,13.0,12.74,8.0,7.71],\n[9.0,8.81,9.0,8.77,9.0,7.11,8.0,8.84],\n[11.0,8.33,11.0,9.26,11.0,7.81,8.0,8.47],\n[14.0,9.96,14.0,8.10,14.0,8.84,8.0,7.04],\n[6.0,7.24,6.0,6.13,6.0,6.08,8.0,5.25],\n[4.0,4.26,4.0,3.10,4.0,5.39,19.0,12.50],\n[12.0,10.84,12.0,9.13,12.0,8.15,8.0,5.56],\n[7.0,4.82,7.0,7.26,7.0,6.42,8.0,7.91],\n[5.0,5.68,5.0,4.74,5.0,5.73,8.0,6.89]])","c92b5452":"plt.subplot(2,2,1)\nplt.scatter(X[:,0],X[:,1],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\n\nplt.subplot(2,2,2)\nplt.scatter(X[:,2],X[:,3],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\n\nplt.subplot(2,2,3)\nplt.scatter(X[:,4],X[:,5],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\n\nplt.subplot(2,2,4)\nplt.scatter(X[:,6],X[:,7],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\nplt.gcf().set_size_inches((10,10))\n","a7ddabbb":"**Q3 :**\n\nCette m\u00e9thode ressort uniquement les 5 derni\u00e8res lignes du tableau au lieu des 5 premi\u00e8res pour la m\u00e9thode head().","6d2ec950":"***Exercise: Obtain for the Anscombe's quartet [2] given in the figures bellow, the different estimators (mean, variance, covariance for each pair, Pearson's correlation and Spearman's rank correlation.***","85dc2d23":"**Q20: **\n\nIci on voit la CDF pour les hommes (en bleu) et femmes (en rouge). On peut conclure les m\u00eame chose que ce que l'on a dit plus haut. Il y a un plus grande probabilit\u00e9 de toruver des \u00e9chantillons pour les femmes \u00e0 des \u00e2ges plus faibles que pour les hommes. La preuve en est que la CDF grimpe plus vite pour les femmes que les hommes.","494378af":"**Q12 :**\n\nDe m\u00eame que pr\u00e9c\u00e9demment on peut valider avec cette histogramme la moyenne d'\u00e2ge des femmes \u00e0 36 ans.\n\n> Remarque : on peut noter que sur les donn\u00e9es que nous avons les femmes ne sont que tr\u00e8s peu repr\u00e9sent\u00e9es pour des \u00e2ges  sup\u00e9rieur \u00e0 60 ans.","6c48b770":"**Q8 :**\n\nOn remarque que les femmes sont en moyenne plus jeunes que les hommes d'environ 3 ans mais qu'en moyenne les femmes ayant un haut salaire ont 2 ans et demi de moins","1ad418e9":"**Q16: **\n\nM\u00eame conclusion que pr\u00e9c\u00e9demment, les deux histogrammes se rapproche tr\u00e8s fortement. Ce qui est logique puisque plus on a d'\u00e9chantillons pour un certain \u00e2ge plus on a de chance de tomber dessus al\u00e9atoirement.","6a87f79b":"**Q15: **\n\nOn peut voir ici lla probabilit\u00e9 de trouver des \u00e9l\u00e9ments en fonction de l'\u00e2ge. On voit que cela reste coh\u00e9rent avec le nombre d'\u00e9chantillon affich\u00e9 pr\u00e9c\u00e9demment.","a23657a6":"**Q21 :**\n\nL'asym\u00e9trie pour nos deux bases de donn\u00e9es sont positives. Ainsi on peut conclure que les donn\u00e9es s'\u00e9tendes plus vers la droite que vers la gauche (i.e il y a plus de personnes ag\u00e9es dans notre base de donn\u00e9e)","c8a96364":"**Q14 :**\n\nLes r\u00e9sultat sont identiques \u00e0 ceux de la question pr\u00e9c\u00e9dente \u00e0 la diff\u00e9rence pr\u00e8s que l'histogramme \u00e0 \u00e9t\u00e9 normalis\u00e9 afin de faire appara\u00eetre la PMF","e13146ef":"**Q22 :**\n\nOn peut voir en rouge un repr\u00e9sentation de la densit\u00e9 de probabilit\u00e9 car on note que c'est une fonction continu.\n\nOn peut voit les kernels en pointill\u00e9 dont la somme \u00e0 permis de reproduire la densit\u00e9 de probabilit\u00e9. Les points bleus sont ceux en lesquels les kernels ont \u00e9t\u00e9 estim\u00e9s.","917170be":"**Q4 :**\n\nCette m\u00e9thode ressort les dimensions du tabeau pr\u00e9c\u00e9demment cr\u00e9e. Ainsi on peut voir qu'il contient 32561 lignes et 15 colonnes. Ce qui est coh\u00e9rent car nous avons cr\u00e9er ce tableau de sorte \u00e0 avoir 15 colonnes pour les 15 types de donn\u00e9es du fichier.","8d76dfa5":"**Q1 :**\n\nOn a ouvert le fichier de donn\u00e9e et on l'a mis dans un array. Le r\u00e9sultat est un array contenant de nombreuses donn\u00e9es comme le salaire, le pays ou le sexe de la personne.\n\nLa derni\u00e8re commande (print(data[1:2])) donne la troisi\u00e8me colonne de la secondes lignes car en python le compte des \u00e9l\u00e9ments d'un array commence \u00e0 0.","7d924240":"**Q23 :**\n\nOn obtient une moyenne estim\u00e9 l\u00e9g\u00e9rement diff\u00e9rente de la moyenne empirique. Cela vient du fait que les valeurs aberrantes sont minimis\u00e9 gr\u00e2ce \u00e0 l'estimateur.","86d6fc7a":"**Q10 :**\n\nLa m\u00e9diane est une valeur statistique qui s\u00e9pare un groupe de donn\u00e9e de tel sorte \u00e0 ce qu'il y ait 50% des valeurs qui soient inf\u00e9rieur et 50% qui soient sup\u00e9rieur \u00e0 la m\u00e9diane. Elle a pour propri\u00e9t\u00e9 d'\u00eatre plus robuste que la moyenne et donc permet de valider si des valeurs sont aberrantes ou non\n\n> On peut voir que les valeurs de la moyenne et de la m\u00e9diane pour les diff\u00e9rents sets de donn\u00e9es sont relativement proche ce qui permet de valider le fait qu'il y a maxima tr\u00e8s peu de valeurs aberrantes dans nos donn\u00e9es","0afc7ba4":"**Q17: **\n\nVoici une autre mani\u00e8re de r\u00e9p\u00e9senter la probabilit\u00e9 de pr\u00e9sence d'un \u00e9chantillon. En effet il permet de voir la probabilit\u00e9 qu'un \u00e9chantillon soit choisis pour une valeur de inf\u00e9rieur ou \u00e9gal \u00e0 celle que l'on cherche.\n\n> Exemple : Il y a 80% de chance de trouver un \u00e9chantillon pour un \u00e2ge inf\u00e9rieur ou \u00e9gal \u00e0 50 ans","fcc8edc9":"**Q9 :**\n\n* Une interpr\u00e9tation des moyennes est plut\u00f4t simple. Ici on peut voir qu'en moyenne les femmes travaillent moins d'heures par semaien que les hommes.\n\n* On peut remarquer que l'\u00e9cart-type (unbiased standart deviation) est la racine carr\u00e9e de la variance et une interpr\u00e9tation possible serait que plus il est \u00e9lev\u00e9 plus l'ensemble de donn\u00e9e est h\u00e9t\u00e9rog\u00e8ne. Ici les deux valeurs sont assez proches donc on peut dire que les deux ensembles de donn\u00e9es sont h\u00e9t\u00e9rog\u00e8ne de la m\u00eame mani\u00e8re.","1e2f0827":"**Q2 :**\n\nLa derni\u00e8re commande met les donn\u00e9es dans un tableau afin de pourvoir les regarder plus ais\u00e9mment. la m\u00e9thode head() ressort donc les 5 prem\u00e8res lignes de ce tableau.","946ebbb5":"**Q7 :**\n\nOn remarque sur ces statistiques que quasiment un quart de la population a un haut revenu. Cependant 10% des femmes contenu dans ces donn\u00e9es en ont un contrairement \u00e0 30% pour les hommes.\n\n> Remarque : On peut \u00e9galement noter gr\u00e2ce aux lignes de codes pr\u00e9c\u00e9dentes qe le nombres d'hommes dans ces donn\u00e9es est bien sup\u00e9rieurs \u00e0 celui des femmes. Cependant tout proportions gard\u00e9es on a quand m\u00eame un pourcentage de femme plus faible.","751f356a":"**Q11 :**\n\nOn peut voir qu'il y a beaucoup de valeurs autour de 35 ans pour les hommes ce qui est coh\u00e9rent avec la valeur de 39 ans trouv\u00e9 gr\u00e2ce \u00e0 la m\u00e9thode mean().\n\n> Remarque : Les valerus qui sont fort \u00e0 droite sur l'histogramme vont d\u00e9caler la valeur de la moyenne l\u00e9g\u00e9rement vers la droit ce qui explique la valeurs de 39 plut\u00f4t que 35 comme annonc\u00e9 pr\u00e9c\u00e9demment.","2c7c80fc":"**Q13 :**\n\nOn peut voir ici le nombre d'\u00e9l\u00e9ments en fonction de l'\u00e2ge. On voit que l'on a une plus d'\u00e9chantillons pour les femmes autour de la vaingtaine la ou il y en a plus grande pour les hommes autour de 40 ans ou 50 ans","89c7b08a":"**Q6 :**\n\nEn utilisant la commande .max() et .head(30) afin d'avoir suffisamment d'\u00e9l\u00e9ments afficher on trouve que l'\u00e2ge le plus repr\u00e9sent\u00e9 est ***36 ans*** avec ***898*** personnes.\n\n> Remarque : juste utiliser df.groupby('age').size() n'affiche pas tout le tableau dans la console ce qui m'a oblig\u00e9 \u00e0 utiliser des m\u00e9thodes d\u00e9tourn\u00e9es","70d3dd62":"**Q5 :**\n\nIl y a 29170 items pour les USA et  and 643 pour Mexico"}}