{"cell_type":{"36e2e3a6":"code","3f05befb":"code","45d3aa97":"code","a5629420":"code","c73a765c":"code","f3f0b47c":"code","8e8408f6":"code","00b190e7":"code","e3bf0c0b":"code","49752b01":"code","e20c41d4":"code","0b6fe9f8":"code","6828f547":"markdown","b54728f8":"markdown","2aa34a69":"markdown","3baab742":"markdown"},"source":{"36e2e3a6":"package_path = '..\/input\/pytorch-image-models\/pytorch-image-models-master' #'..\/input\/efficientnet-pytorch-07\/efficientnet_pytorch-0.7.0'\nimport sys; sys.path.append(package_path)","3f05befb":"from glob import glob\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom  torch.cuda.amp import autocast, GradScaler\n\nimport sklearn\nimport warnings\nimport joblib\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nimport warnings\nimport cv2\nimport pydicom\nimport timm #from efficientnet_pytorch import EfficientNet\nfrom scipy.ndimage.interpolation import zoom\nfrom sklearn.metrics import log_loss\nfrom sklearn import svm\n\nimport pickle","45d3aa97":"CFG = {\n    'fold_num': 5,\n    'seed': 719,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 10,\n    'train_bs': 32,\n    'valid_bs': 32,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'verbose_step': 1,\n    'device': \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    'tta': 1,\n    'used_epochs': [6,7,8,9],\n    'weights': [1,1,1,1]\n}","a5629420":"train = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ntrain.head()","c73a765c":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb\n\nimg = get_img('..\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nplt.imshow(img)\nplt.show()","f3f0b47c":"class CassavaDataset(Dataset):\n    def __init__(\n        self, df, data_root, transforms=None, output_label=True\n    ):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.df.iloc[index]['label']\n          \n        path = \"{}\/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n        \n        img  = get_img(path)\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n            \n        # do label smoothing\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","8e8408f6":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_inference_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","00b190e7":"class CassvaImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    # Forward the pass the model except the classifier    \n    def forward(self, x):\n        x = nn.Sequential(*list(self.model.children())[:-1])(x)\n        return x","e3bf0c0b":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    \n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        \n        image_preds = model(imgs)   #output = model(input)\n        image_preds_all += [image_preds.detach().cpu().numpy()]\n        \n    \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","49752b01":"# check with true, commit with false\ndo_val = False\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train.shape[0]), train.label.values)\n\nclf = pickle.load(open('..\/input\/pytorch-efficientnetb4-svm-top-train\/SVM_model.pkl', 'rb'))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    if do_val:\n        valid_ = train.loc[val_idx,:].reset_index(drop=True)\n        valid_ds = CassavaDataset(valid_, '..\/input\/cassava-leaf-disease-classification\/train_images\/', transforms=get_valid_transforms(), output_label=False)\n\n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_valid_transforms(), output_label=False)\n    \n    if do_val:\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n\n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique()).to(device)\n    val_preds = []\n    tst_preds = []\n\n    #for epoch in range(CFG['epochs']-3):\n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/pytorch-efficientnet-baseline-train-amp-aug\/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch)))\n\n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                if do_val:\n                    val_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, val_loader, device)]\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n    fin_test = clf.predict(tst_preds)\n    \n    if do_val:\n        val_preds = np.mean(val_preds, axis=0) \n        fin_val = clf.predict(val_preds)\n        print('fold {} validation accuracy = {:.5f}'.format(fold, (valid_.label.values==fin_val).mean()))\n\n    del model\n    torch.cuda.empty_cache()","e20c41d4":"test['label'] = fin_test\ntest.head()","0b6fe9f8":"test.to_csv('submission.csv', index=False)","6828f547":"## Inference","b54728f8":"## Dataset Class and augmentations are same as in original.","2aa34a69":"This notebook extends upon the [Kun Hao Yeh's Inference Notebook](https:\/\/www.kaggle.com\/khyeh0719\/pytorch-efficientnet-baseline-inference-tta\/notebook). Please upvote the original notebook as well.\n\nHere a Support Vector Classifier is used to predict final Classes from the features generated from the EfficientnetB4 Backbone.\n\nTraining Notebook - https:\/\/www.kaggle.com\/yerramvarun\/pytorch-efficientnetb4-svm-top-train","3baab742":"## Model"}}