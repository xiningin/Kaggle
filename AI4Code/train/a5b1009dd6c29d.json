{"cell_type":{"83528b0d":"code","00d9be93":"code","99740546":"code","a2f8ab4a":"code","fbc4b1a1":"code","c96f1c0f":"code","57983330":"code","38dbecbe":"code","b64e41b1":"code","dd294d0e":"code","73bb2d5f":"code","2159bf94":"code","1a64f948":"code","1074ec1d":"code","1bd5be6d":"code","e031bc75":"code","0402a3cc":"code","ef2dc369":"code","377dbd4a":"code","9004dd5f":"code","51ce8cf8":"code","7e9b978c":"code","2c0eb4cf":"code","b704f18e":"code","8b69a52c":"code","9f35cc78":"code","a3347ae5":"code","ef3e5e01":"code","6084036c":"code","2f053b28":"code","2446f6d6":"code","daad194e":"code","7647db9f":"code","c6731a0d":"code","b3126272":"code","f6f5f9e9":"code","43235a62":"code","35cfbbe3":"code","17ae9a35":"code","47c03ab6":"code","9cae4599":"code","d0390bcf":"code","b9993f4e":"code","98bee783":"code","92854e00":"code","ee6684cc":"code","155d5050":"code","da0061ec":"code","b877ca55":"code","55bdb4c4":"code","cb7bd400":"code","7b1af534":"code","7659b890":"code","18776261":"code","61339ac8":"code","00d6b6a7":"code","4f67bcc4":"code","d523d5de":"code","0addfb63":"code","c2750021":"code","e26295a3":"code","795f5e9e":"code","d2e1cb3a":"code","89c1250e":"code","e5358b14":"code","64625349":"code","525e3c30":"code","75e0b5a6":"code","49e5df98":"code","13982fe2":"code","f8080898":"code","ad024888":"code","297df032":"code","dab208d9":"code","4f3ca1d7":"code","4707bc8c":"code","834b6e9e":"code","ddc2b636":"code","61d4dbec":"code","6ddd6b90":"code","bfddff6c":"code","ade0a884":"code","94958cb6":"code","e020d516":"code","fec7572d":"markdown","ec7216a1":"markdown","ac295150":"markdown","8d97e096":"markdown","ff62d704":"markdown","107c2d19":"markdown","8a3a3db1":"markdown","c3c1305b":"markdown","10d264c8":"markdown","33f471b8":"markdown","f84e1265":"markdown","96727ea6":"markdown","b3b75493":"markdown","7218e21f":"markdown","3425d015":"markdown","2e4b6b81":"markdown","557a1bd2":"markdown","af64371e":"markdown","66cfc8aa":"markdown","9ac2ac11":"markdown","a69115c7":"markdown","42ac953e":"markdown","01368256":"markdown","cf3e5b56":"markdown","69665919":"markdown","f7b7b484":"markdown","89695dde":"markdown","2f30507e":"markdown","c3c3b85e":"markdown","9123a703":"markdown","ed730d78":"markdown","2d807e7b":"markdown","36c75865":"markdown","191547c4":"markdown","4bea0314":"markdown","9a5fa9d5":"markdown","110de066":"markdown","ada43c41":"markdown","6cd23ff4":"markdown","e07064f7":"markdown","8665a526":"markdown","37b448e1":"markdown","3bbd91a4":"markdown","63fa673e":"markdown","658ca69d":"markdown","4d916c89":"markdown","fe6ed650":"markdown","5d766e50":"markdown","faa0866f":"markdown","a3de02bc":"markdown","50203ae3":"markdown","74fb38c1":"markdown","6faff1db":"markdown","c699034a":"markdown","c980945f":"markdown","d8c08793":"markdown","ccabb37a":"markdown","dfae514f":"markdown","7d3467f9":"markdown","ea0c3db3":"markdown","ddeac048":"markdown","1099b4a4":"markdown","ebf4e60f":"markdown","133dac60":"markdown","eee9ae15":"markdown","d064256d":"markdown","a0c3e576":"markdown","0cf5f5d4":"markdown","faa2a562":"markdown","5d351b4e":"markdown","382e5d30":"markdown","fa37cede":"markdown","d94d74b8":"markdown","c4bda52a":"markdown","18b1422a":"markdown","59e35462":"markdown","e33e2f74":"markdown","3fb39d0f":"markdown"},"source":{"83528b0d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00d9be93":"import sklearn\nimport plotly\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install vaderSentiment","99740546":"# loading dataset\npath = '\/kaggle\/input\/amazon-fine-food-reviews\/'\nreviews = pd.read_csv(path+\"Reviews.csv\")","a2f8ab4a":"reviews.head()","fbc4b1a1":"reviews.shape","c96f1c0f":"reviews.info()","57983330":"reviews.describe()","38dbecbe":"# number of missing data in this dataset\nreviews.isna().sum()","b64e41b1":"# calculating Helpfulness percentage\nreviews[\"Helpfulness\"] = reviews[\"HelpfulnessNumerator\"]\/reviews[\"HelpfulnessDenominator\"] # it will produce some nan\n# filling above nan values with 0\nreviews['Helpfulness'].fillna(0).head()\nreviews[\"Helpfulness\"].mean()","dd294d0e":"# total null counts in Summary Feature\nreviews[\"Summary\"].isnull().sum()","73bb2d5f":"# imputing missing titles with ''-blank\nreviews[\"Summary\"] = reviews[\"Summary\"].fillna('')","2159bf94":"# calculating summary lengths\nreviews[\"Summary_length\"] = reviews[\"Summary\"].map(lambda x: len(x.split()))\n\n# calculating review lengths\nreviews[\"Text_length\"] = reviews[\"Text\"].map(lambda x: len(x.split()))","1a64f948":"reviews[\"Time\"].dtype","1074ec1d":"reviews[\"Time\"] = pd.to_datetime(reviews.Time,  unit='s')\nreviews[\"Time\"].dtype","1bd5be6d":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n# initealize Sentiment analyzer\nanalyser = SentimentIntensityAnalyzer()\n\n# scorer function based on cutoffs\ndef score_sentiment(compound_score):\n    if compound_score >= 0.05:\n        return(\"Positive\")\n    elif compound_score < 0.05 and compound_score >= -0.05:\n        return(\"Neutral\")\n    else:\n        return(\"Negative\")","e031bc75":"reviews[\"Text_sentiment\"] = reviews[\"Text\"].map(lambda x: score_sentiment(analyser.polarity_scores(x)['compound']))\nreviews[\"Summary_sentiment\"] = reviews[\"Summary\"].map(lambda x: score_sentiment(analyser.polarity_scores(x)['compound']))","0402a3cc":"reviews[\"Text_sentiment\"].head()","ef2dc369":"reviews[\"Summary_sentiment\"].head()","377dbd4a":"pd.DatetimeIndex(reviews['Time']).year.value_counts()","9004dd5f":"# plottig number of reviews overtime\nplt.hist(reviews[\"Time\"], bins=50, color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Year')\nplt.title('Number Observations Over Time')\nplt.show()","51ce8cf8":"pd.DatetimeIndex(reviews['Time']).year == '2000'","7e9b978c":"# plotting number of scores \nscore_counts = reviews[\"Score\"].value_counts().to_dict()\nplt.bar(score_counts.keys(),height=score_counts.values(),color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Score')\nplt.title('Review Scores')\nplt.show()","2c0eb4cf":"# Text_sentiment\ntext_sentiment_counts = reviews[\"Text_sentiment\"].value_counts().to_dict()\nplt.bar(text_sentiment_counts.keys(),height=text_sentiment_counts.values(),color='lightblue')\nplt.ylabel('Sentiment')\nplt.xlabel('Score')\nplt.title('Text Review Sentiments')\nplt.show()","b704f18e":"# Summary_sentiment\nsummary_sentiment_counts = reviews[\"Summary_sentiment\"].value_counts().to_dict()\nplt.bar(summary_sentiment_counts.keys(),height=summary_sentiment_counts.values(),color='lightblue')\nplt.ylabel('Sentiment')\nplt.xlabel('Score')\nplt.title('Summary Review Sentiments')\nplt.show()","8b69a52c":"reviews_sentiment_count = reviews.groupby(['Score','Text_sentiment','Summary_sentiment']).count()[[\"Id\"]].reset_index().rename(columns = {\"Id\": \"Count\"})\nreviews_sentiment_count.head()","9f35cc78":"melted_reviews = pd.melt(reviews_sentiment_count,id_vars=['Score','Text_sentiment','Summary_sentiment'],value_vars=['Count'])\nmelted_reviews.head()","a3347ae5":"reviews.groupby(['Score','Text_sentiment','Summary_sentiment']).count()[[\"Id\"]].plot.bar(figsize=(18,4))\nplt.show()","ef3e5e01":"from scipy.stats import spearmanr\n\nspearmanr(reviews[\"Text_sentiment\"], reviews[\"Summary_sentiment\"])","6084036c":"spearmanr(reviews[\"Text_sentiment\"], reviews[\"Score\"])","2f053b28":"spearmanr(reviews[\"Summary_sentiment\"], reviews[\"Score\"])","2446f6d6":"top_500_reviewers_count = reviews[\"UserId\"].value_counts().nlargest(500)\n\nplt.figure(figsize=(18,5))\nplt.hist(top_500_reviewers_count,bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('# Reviews Per User')\nplt.title('Number of Reviews from Top 500 Reviewers')\nplt.show()","daad194e":"top_users = reviews.loc[reviews['UserId'].isin(top_500_reviewers_count.index)]\ntop_users = top_users.sort_values(['UserId', 'Time'])\ntop_users.head(2)","7647db9f":"# creating numbered entry per person based on sorted list of userid above\nreview_times_vector = [[j + 1 for j in range(i)] for i in top_500_reviewers_count[top_500_reviewers_count.index.sort_values()]]\nreview_times_vector_flat = [item for sublist in review_times_vector for item in sublist]\n\n# adding numbered review order\ntop_users[\"Review_times\"] = review_times_vector_flat","c6731a0d":"top_500_reviewers_count[top_500_reviewers_count.index.sort_values()]","b3126272":"plt.figure(figsize=(30,10))\n\nsns.boxplot(y='Text_length',x='Review_times',data=top_users,palette=\"rainbow\")\nplt.show()","f6f5f9e9":"# review < 194\nplt.figure(figsize=(30,10))\nsns.boxplot(y='Text_length',x='Review_times',data=top_users[top_users[\"Review_times\"] < 194],palette=\"colorblind\")\nplt.show()","43235a62":"# review >=1914\nplt.figure(figsize=(30,10))\nsns.boxplot(y='Text_length',x='Review_times',data=top_users[top_users[\"Review_times\"] >= 194],palette=\"colorblind\")\nplt.show()","35cfbbe3":"# text length\ntext_length_df = top_users.groupby(top_users.Review_times)[['Text_length']].median()\ntext_length_df.reset_index(level=0, inplace=True)\ntext_length_df['Review_times'] = pd.to_numeric(text_length_df['Review_times'])\ntext_length_df.head()","17ae9a35":"plt.figure(figsize=(18,4))\nsns.lineplot(y='Text_length',x='Review_times',data=text_length_df)\nplt.show()","47c03ab6":"plt.figure(figsize=(30,10))\nsns.boxplot(y='Summary_length',x='Review_times',data=top_users,palette=\"colorblind\")\nplt.show()","9cae4599":"summary_length_df = top_users.groupby(top_users.Review_times)[['Summary_length']].median()\nsummary_length_df.reset_index(level=0,inplace=True)\nsummary_length_df['Review_times'] = pd.to_numeric(summary_length_df['Review_times'])\nsummary_length_df.head()","d0390bcf":"plt.figure(figsize=(18,4))\nsns.lineplot(y='Summary_length',x='Review_times',data=summary_length_df)\nplt.show()","b9993f4e":"plt.figure(figsize=(30,10))\nsns.boxplot(y='Score',x='Review_times',data=top_users,palette=\"colorblind\")\nplt.show()","98bee783":"plt.figure(figsize=(30,10))\nsns.boxplot(y='Helpfulness',x='Review_times',data=top_users,palette=\"colorblind\")\nplt.show()","92854e00":"top_500_product_count = reviews[\"ProductId\"].value_counts().nlargest(500)\n\nplt.figure(figsize=(18,4))\nplt.hist(top_500_product_count,bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('# Reviews Per Product')\nplt.title('Number of Reviews from Top 500 Reviewed Products')\nplt.show()","ee6684cc":"top_products = reviews.loc[reviews['ProductId'].isin(top_500_product_count.index)]\ntop_products_mean = top_products.groupby('ProductId').mean().filter(['Score','Helpfulness','Text_length','Summary_length'])\ntop_products_mean.head()","155d5050":"plt.figure(figsize=(18,4))\n\nplt.hist(top_products_mean[\"Score\"],bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Mean Review Score')\nplt.title('Mean Score from Top 500 Reviewed Products')\nplt.show()","da0061ec":"plt.figure(figsize=(18,4))\n\nplt.hist(top_products_mean[\"Helpfulness\"],bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Mean Helpfulness')\nplt.title('Mean Helpfulness from Top 500 Reviewed Products')\nplt.show()","b877ca55":"# getting last time per product for date diff\nend_time = top_products.groupby('ProductId')['Time'].max()\n#end_time = end_time.sort_values('ProductId')\n\n# finding date diff per review\ntop_products['Age'] = top_products.apply(lambda d:end_time[d['ProductId']] - d['Time'],axis=1) \/ np.timedelta64(1,'D')","55bdb4c4":"# scatter plot age to helpfulness\nplt.figure(figsize=(20,6))\nsns.scatterplot(x='Age',y='Helpfulness',hue='Score',data=top_products)\nplt.show()","cb7bd400":"# scatter plot histogram age and helpfulness\nplt.figure(figsize=(18,4))\nsns.distplot(top_products[\"Age\"])\nplt.show()","7b1af534":"from sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2,verbose=0,perplexity=40,n_iter=300)\ntsne_results = tsne.fit_transform(top_products[['Age','Helpfulness']].dropna())","7659b890":"df_subset = top_products[['Age','Helpfulness','Score']].dropna()\ndf_subset['tsne-2d-one'] = tsne_results[:,0]\ndf_subset['tsne-2d-two'] = tsne_results[:,1]\n\nplt.figure(figsize=(20,10))\nsns.scatterplot(x='tsne-2d-one',y='tsne-2d-two',hue=\"Score\",data=df_subset,legend=\"full\",alpha=0.3,palette=sns.color_palette(\"hls\",5))\n\nplt.show()","18776261":"top_products.head()","61339ac8":"age_helpfulness_df = top_products.groupby([top_products.Age, top_products.Score])[['Helpfulness']].mean()\nage_helpfulness_df.reset_index(level=0,inplace=True)\nage_helpfulness_df.reset_index(level=0,inplace=True)\n#age_helpfulness_df['Helpfulness'] = pd.to_numeric(age_helpfulness_df['Helpfulness'])\nage_helpfulness_df.head()","00d6b6a7":"plt.figure(figsize=(30,10))\nsns.lineplot(y='Helpfulness',x='Age',hue='Score',data=age_helpfulness_df)\nplt.show()","4f67bcc4":"# Wanting to try to figure how out to do Helpfulness overtime\nend_time = top_products.groupby('ProductId')['Time'].max().reset_index()","d523d5de":"plt.figure(figsize=(18,4))\nplt.hist(top_products_mean['Summary_length'],bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Mean Summary Length')\nplt.title('Mean Summary Length from Top 500 Reviewed Products')\nplt.show()","0addfb63":"plt.figure(figsize=(18,4))\nplt.hist(top_products_mean['Text_length'],bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Mean Review Length')\nplt.title('Mean Review Length from Top 500 Reviewed Products')\nplt.show()","c2750021":"sns.pairplot(top_products_mean)\nplt.show()","e26295a3":"plt.figure(figsize=(18,4))\nplt.hist(reviews['Summary_length'],bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('# Words in Summary')\nplt.title('Number of Reviews of with # Words in Summary')\nplt.show()","795f5e9e":"plt.figure(figsize=(18,4))\nplt.hist(reviews['Text_length'],bins=50,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('# Words in Review')\nplt.title('Number of Reviews of with # Words in Reviews')\nplt.show()","d2e1cb3a":"# scatter plot of summary_length and review_length\nplt.figure(figsize=(18,4))\nplt.scatter(reviews[\"Summary_length\"], reviews[\"Text_length\"])\nplt.show()","89c1250e":"# calculating spearman's correlation\ncoef, p = spearmanr(reviews['Summary_length'], reviews['Text_length'])\nprint('Spearmans correlation coefficient: %.3f' % coef)\n# interpreting significance\nalpha = 0.05\nif p > alpha:\n    print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\nelse:\n    print('Samples are correlated (reject H0) p=%.3f' % p)","e5358b14":"plt.figure(figsize=(18,4))\n\nplt.hist(reviews['Helpfulness'],bins=20,color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Helpfulness Ratio')\nplt.title('Helpfulness of Reviews')\nplt.xlim(0,1)\nplt.show()","64625349":"plt.figure(figsize=(18,4))\n\nplt.hist(reviews[reviews['HelpfulnessDenominator'] != 1]['Helpfulness'].dropna(), bins=20, color='lightblue')\nplt.ylabel('Count')\nplt.xlabel('Helpfulness Ratio')\nplt.title('Helpfulness of Reviews Removing 1 Helpful Scored Reviews')\nplt.xlim(0,1)\nplt.show()","525e3c30":"sns.pairplot(reviews[['Score','Helpfulness','Summary_length','Text_length']])\nplt.show()","75e0b5a6":"# to get a stronger sense of if above numerical variables mean anything\nsns.boxplot(x='Score',y='Helpfulness',data=reviews,fliersize=18)\nplt.show()","49e5df98":"reviews[reviews['Helpfulness'] > 1]","13982fe2":"from sklearn.preprocessing import minmax_scale\n\nsns.boxplot(x=reviews['Score'],y=minmax_scale(reviews['Summary_length']))\nplt.show()","f8080898":"sns.boxplot(x=reviews['Score'], y=minmax_scale(reviews['Text_length'])).set(ylim=(0, 0.1))\nplt.show()","ad024888":"# approx 2.1989466166127776% of reviews \nreviews_sampled = reviews.sample(12500,random_state=108) ","297df032":"import spacy\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\nnlp = spacy.load(\"en_core_web_sm\")","dab208d9":"def simple_tokenizer(corpus,nlp=nlp):\n    \"\"\" \n    Give a sentence and return tokenized string given \n    lemmanization, stop word remove, punctuation removal, and alpha characters only\n    \"\"\"\n    doc = nlp(corpus)\n    return [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.is_alpha]","4f3ca1d7":"#from sklearn.pipeline import Pipeline\n#tfidf_pipe = Pipeline([('tfidf', TfidfVectorizer(tokenizer = simple_tokenizer))])\n#tfidf_pipe.fit_transform(reviews['Summary'][0:10], reviews['Text'][0:10])","4707bc8c":"print('Starting Summary TF-IDF')\ntfidf_s = TfidfVectorizer(tokenizer = simple_tokenizer)\ntfidf_summary = tfidf_s.fit_transform(reviews_sampled['Summary'])\nprint('Starting Review TF-IDF')\ntfidf_r = TfidfVectorizer(tokenizer = simple_tokenizer)\ntfidf_reviews = tfidf_r.fit_transform(reviews_sampled['Text'])","834b6e9e":"features_name = tfidf_r.get_feature_names()\nprint(features_name)","ddc2b636":"# top 40 tf_idf features for reviews\nindices = np.argsort(tfidf_s.idf_)[::-1]\nfeatures = tfidf_s.get_feature_names()\n\ntop_n = 40\ntop_features = [features[i] for i in indices[:top_n]]\nprint(top_features)","61d4dbec":"# top 40 tf idf features for reviews\nindices = np.argsort(tfidf_r.idf_)[::-1]\nfeatures = tfidf_r.get_feature_names()\n\ntop_n = 40\ntop_features = [features[i] for i in indices[:top_n]]\nprint(top_features)","6ddd6b90":"# updating score as binary \nreviews['Score_bc'] = reviews['Score'] >= 4\nreviews['Score_bc'] = reviews['Score_bc'].astype('category')\nreviews.replace({'Score_bc':{True:'High',False:'Low'}},inplace=True)\nreviews['Score_bc'].head()","bfddff6c":"pd.DatetimeIndex(reviews['Time']).year.value_counts()","ade0a884":"#!pip install scattertext\nimport scattertext as st","94958cb6":"nlp = spacy.load('en_core_web_sm')\ndef produce_scattertext(nlp=nlp,year=1999,col='Text'):\n    \"\"\" \n    Create scatter_text based on a given year and text column \n    \"\"\"\n    filtered_reviews = reviews[pd.DatetimeIndex(reviews['Time']).year == year]\n    print(\"Creating corpus for \" + str(year))\n    \n    # turning it into a Scattertext Corpus \n    corpus = st.CorpusFromPandas(filtered_reviews,category_col='Score_bc',text_col=col,nlp=nlp).build()\n    print(\"Creating plot\")\n    \n    # output scattertext html files\n    html = st.produce_scattertext_explorer(corpus,category='High',category_name='High Score',\n                                           not_category_name='Low Score',width_in_pixels=1000,metadata=filtered_reviews[\"Score\"])\n    open(\"link where you want 2 save\/\" + str(year) + \".html\", 'wb').write(html.encode('utf-8'))\n    \n    print(\"Finished Scattertext\")\n    ","e020d516":"# creating plots (1999 all positive)\nproduce_scattertext(year = 2000)\nproduce_scattertext(year = 2001)\nproduce_scattertext(year = 2002)\nproduce_scattertext(year = 2003)\nproduce_scattertext(year = 2004)\nproduce_scattertext(year = 2005)\nproduce_scattertext(year = 2006)\nproduce_scattertext(year = 2007)\nproduce_scattertext(year = 2008)\nproduce_scattertext(year = 2009)\nproduce_scattertext(year = 2010)\nproduce_scattertext(year = 2011)\nproduce_scattertext(year = 2012)","fec7572d":"**`Trying to understand if this Helpfulness has some Time based dependency`** \n* Calculating relative age of a product based on Last_Review date and \n* back calculate Review_Metrics and trying to visualize these trends","ec7216a1":"`Observe`:\n* `score` seems to be between 1 and 5 which is expected \n* most of the reviews are right skewed in it's `helpfulness` with some very strong outliers\n    * `helpfulness` columns will need to be normalized in order to be useful","ac295150":"`Observe` the plot above, from top 500 reviewers number of reviews are right skewed\n* Most of users in this selection have about 30-40 reviews","8d97e096":"It should be checked if the `Summary` and `Reviews` are correlated\n* It's expected but would be interesting to see if they are truely correlated","ff62d704":"### Helpfulness Features\nFirst--performig some minor feature engineering<br>\nTo get percentage of and rescale helpfulness by dividing numerator by denominator","107c2d19":"`Observe` from this plot it looks like most of sentiments that are 5 star are positive in both the reviews and summary\n* same applies for 4 star reviews","8a3a3db1":"`Observ` pair plot is showinf some general trends\n* Relationship between mean score and other features are nonlinear\n* Most interesting relationship is length of reviews and summary which look very strongly correlated","c3c1305b":"`Observe` from above scatter plot\n* see some sort of clustering in Higher_Bounds after around 100 days with Helpfulness based on age and score\n* A lot of High_Scored youngish reviews that are generally 5 star also tend to be positively reviewed\n    * It looks like a lot of reviews for Similar age but lower scores tend to be rated not as helpful\n* We can try clustering to see if we can better visualize these clusters\n    * It still looks incredibly noisy and there doesn't seem like any specfic trend with age and helpfulness but maybe we can get lucky with some clustering\n    \n**`First, we should do Histogram of Age to confirm what it looks like`**","10d264c8":"`Observe` Summary_text shows a similar trend as Review_text\n* Interesting difference is that something is causing this algorithm to give high neutral scores","33f471b8":"### Reviews Over Time (Time Feature)","f84e1265":"`Observe` in above plot there are top_500_reviewed products\n* As expected number of reviews are right skewed\n* Trying to take a summary look and see what mean score for these products are and trying to plotting it","96727ea6":"`Observ` box above shows top features for actual reviews\n* can see some typos and some non-english terms\n* From here, can mostly see that original and some physical ailments are getting higher TF-IDF values","b3b75493":"`Observe` most of reviews are 5 stars\n* In modeling, this will be an issue","7218e21f":"## `Goal of creating Scattertext` \nGoal is to get an understand per year of why people gave ratings of 4-5 and why they gave lukewarm or bad reviews of 1-3\n* Can see several trends when you open up scatter_text\n    * 1999 was not plotted as sample size was very small and it appears that only highly rated reviews were available\n    \n* `Year 2000` was mostly movie reviews\n    * In particular people seem to like beetle juice\n* `Year 2001` was still related to movies\n    * In particular people seem to prefer wide screen movies and disliked dvds\n    * Perhaps this is around the rise of dvds as the Playstation 2 was released in 2000\n* `Year 2002` is more ambiguous as top scored words are mostly stop words, It is still movie reviews and makes reference to beetlejuice as well as probably Tim Burton\n    * It also references what is likely the Matrix 2 as some of actors and actresses are in dataset\n* `Year 2003` is when dataset begins to closer mention gourmet foods, It still has movie mentions and some dirty html tags but seems to have high number of chocolate and coffee related terms\n    * Starbucks is specifically mentioned and in 2003, Starbucks bought out Seattle Coffee Company and expanded about 2000 stores\n    * This is likely a 2nd wave coffee shop trend\n* `Year 2004` is a more interesting year, There is still a large influence from Beetlejuice and Tim burton but two trends here seem to be tea and urinary tract infections and sugar\n    * It seems people are concerned about sugar intake this year\n    * Senseo is also a top characteristic of these reviews and it appears that it started to appear in 2003\n        * Senseo seems like an early Keurig machine designed to simplify coffee using pods\n* `Year 2005` seems to sweets related. We have many interesting terms here including coffee, tea, sweeteners, jarritos, larabar, and kashi\n    * It seems this year is when health fad happened and people began to worry about type of sugars in their products\n    * According to wikipedia, 2006 was when the WHO released a report saying stevia was safe for consumption so maybe it is related\n    * In top scored tokens, chocolate and tea have high scores\n    * Reviews with low score seem to be price and expediated delivery related\n* `Year 2006` seems to be dominated by cat food reviews, Looking in top and low scores, they seem to refer to either cats or dogs and feeding them good food\n    * This might be related to characteristic terms for kibble and canidae which begun appearing in earlier years\n    * The trends for food according to characteristics seem relatively similar to 2005\n    * We see more gum, oreos, larabars, teas, pretzels, noodles, and snacks\n        * This might be Amazon deciding to expand their food selection to more unhealthier snacks.\n* `Year 2007` has more diverse terms. Specifically, characteristics are more desriptive compared to 2006 which was more specific products\n    * The top scores are mostly relatively positive words that you would expect from reviews like delicious\n    * The low scores are lower sentiment values and are works like disappointed or terrible\n    * There seems to be complaints about pumps and that is related to a water pump for a hydroponic gardening kit from AeroGarden\n* `Year 2008` has many descriptive adjectives. There are still brands that are picked up including izze, canidae but it is mostly generic terms now\n    * The interesting thing is that there seemed to have been some issue with menadione and new formula for canidae which is very poorly received\n* `Year 2009` still contained many adjectives. It seems like Canidae formula changing controversy still continued in reviews\n    * Interestingly, there seems to be an issue with Made in China this year\n    * Looking at some of the reviews, it seems to be dog treat related\n* `Year 2010` continued trend as seen in previous years, It seems pasta and snacks became very indicative of high scores\n    * Some of interesting characteristics that have been added are gluten and keurig which are known for their coffee pods\n    * Investigating thought see which has top low score shows that there is someone reposting same negative 1 star review over and over\n* `Year 2011` only has Amazon as only named entity, All of the primary features follow last couple of year in trends in that it is mostly adjectives\n    * We can see in plot of high score frequent tokens that we have specific foods people are interested in\n    * There is also interestingly some holistic references including outlier term uterus\n    * Negative reviews seems to be complaints based on expiration or taste\n* `Year 2012` shows similar trends as before, We can see that people are still complaining about things made in China\n    * It seems matcha and magnesium are very highly rated\n    * In plot, we can see certain products people don't seem to like such as hammer products and potentially turbinado sugar\n    * People also seem to be wory of propylene glycol which is a flavorless additive to food\n    * Looking at some of strange postiive frequent words, we can see that there is review replication such as for causes diarrhea","3425d015":"`Observ` plot shows that Summary_Length is right skewed","2e4b6b81":"`Observ` plot above shows line plot of different Scores and Over_Time in relation to mean Helpfulness\n* In general, it looks like mean Helpfulness fluctuate but mostly become more positive over time until we start getting sparsity issues with anything past ~2100 days\n* It looks like other scores somewhat follow same pattern and mostly trend upwards overtime until it has sparisity issues as well","557a1bd2":"### Sentiment Score (Text,Summary Features)\nMaybee correlating Sentiment of a review against the score will be intrusting\n* Using [Vader Link](https:\/\/github.com\/cjhutto\/vaderSentiment) which is a `rules based approach` to classifying Reviews","af64371e":"`Observe` plot above shows trend observed with box plots \n* Line represents `median text length` over course of a review's lifetime in dataset\n* Reviews do increase until it fluctuates back down to roughly initial levels","66cfc8aa":"\"\"\"# alternate review_times_vector_flat\nfor sublist in review_times_vector:\n    for item in sublist:\n        print(item)","9ac2ac11":"`Observe`:\n* `ProductId`\n    * might be used to either aggregate reviews against a single product or \n    * maybe pulling additional metadata from Amazon on what these products are\n* `UserId` and `ProfileName` both related with reviewer\n    *  how UserId can change overtime as ProfileName can be changed overtime (not that usefull)\nInteresting would be to try to track `evolution of reviews` of frequent reviewers, see we have several columns for other people rating reviews\n* `Score` reviewer rating on a product\n* `Time` in `timestamp string format` and needs to be converted to be able to do longitudinal analysis\n* `Summary` and `Text` tag line and actual summary of text","a69115c7":"`Observe` see pairwise plots in relation to Score\n* none of these features are very clear differentiators to score\n* longer reviews might be a differentiator for higher scores otherwise there is not much signal\n* can do a box_plot to get a stronger sense of if these numerical variables mean anything","42ac953e":"`Observe` above raw values, dataset starts from 1999-2012\n* 2001 and 2000 are likely mislabeled in this case as it doesn't make sense exponential growth wise but \n    * as that time was roughly around dot com bubble bursting, it could be apparently valid and will be left alone","01368256":"`Observ` in above plot , Score in relation to Helpfulness_Ratio shows patterns in median \n* With scores of 4 and 5 median pushed all way to almost 1.0\n* There interestingly are outliers for score 5\n* can examine what they are","cf3e5b56":"`Observe` although interesting looking, there is no clear pattern with TSNE which would suggest that is hard to separate features given how much overlap they have with each other","69665919":"**`Trying to see if over time users write longer posts`**","f7b7b484":"`Observ` in above plot most of Helpful_Ratio is left skewed\n* This could be expected as many reviews might have been rated helpful once which would heavily bias this score\n* It can be checked by filtering out the single rated entries","89695dde":"`Observ`\n* can see from above that correlation is weak but statistically significant in that there is some true relationship between two variables","2f30507e":"`Observe` box plot above shows the ReviewText_length in relation to NumberOfReviews that person has written so far\n* Two general trends here are\n    * In the left half, distribution gets wider over time\n    * In the right half, box plots mostly shrink as number of people who write that much get fewer and fewer","c3c3b85e":"`Observ` getting a more interesting pattern here\n* above plot shows same Helpfulness_Ratio but removing all reviews that were scored once\n* number of entries drops by above half\n    * In addition, still see left skewed tendencies of this plot","9123a703":"**`First, Imputing Score to be Binary_Classifcation using scores of 4-5 as High and everything else as Low`**","ed730d78":"### GroupBy\n**`It would be good to look at Sentiment in relationship to Score`**","2d807e7b":"`Observe` that Summary_sentiment is also weakly but significantly correlated to Score","36c75865":"`Observ` not expected and it is not clear why Denominator is not total\n* It could be a sample collection error","191547c4":"##### Expanding above code line after line","4bea0314":"`Observe` Finally, plot above is Helpfulness of Reviews\n* Expectation here is that like people might be more interested in more prolific reviewers and give them more helpful scores\n* From above box plots, there does not seem to be any specific trend but it would make sense if it were more time dependent rather than based on a specific reviewer","9a5fa9d5":"`Observe` after 195 reviews median begins to drop\n* This could be sample size problems or it could be that people also get lazy after writing so much","110de066":"### Timestamp (Time Feature)\nFixing Time Feature in order to use it","ada43c41":"`Observ` while ploting two lengths against each other, there is no obvious relationship between number_of_words in summary to review","6cd23ff4":"**`Trying to look closer between two and see if there is any meaningful difference`**","e07064f7":"# `Simple Stats`\nFirst, trying to look at distributions of all of variables to get an idea of what this dataset looks like","8665a526":"**`Trying to plot median again as a line plot to try to track trends based on Number_of_Days`**","37b448e1":"`Observ` similar to summary, we see that distribution here is right skewed","3bbd91a4":"`Observ` mean length seems to vary quite a bit\n* It seems bimodal at around 55 words and 80 words and then dropping off","63fa673e":"`Observe` above shows box plots of review by Score\n* A lot of effect of having mostly 5 star reviews in dataset\n* Most of Q3 in box plots are 5 which makes sense \n* Sparseness and varying box plots near end can be seen","658ca69d":"`Observ` box plot of Score vs min-max_Normalized version of text length\n* y-axis limits are modified otherwise box is not distinguishable\n    * can see that medians are all roughly same between different scores\n\n* Using non-text variables, it does not seem like any of Features are strong enough to distinguish itself as primary driver for these review scores\n\n\n**`Trying to investigate reviews and summary to see if there is any interesting observations`**","4d916c89":"`Observ` it looks like mean_summary_length is relatively short\n* It looks more right tailed with maximum at around 4","fe6ed650":"### Review Lengths (Summary Feature)\n* Looking into Review Lengths \n    * This could be a simple metric related to score of reviews\n    * For instance, longer reviews might be more passionate so it could have a higher score and vice versa\n* `First, Imputinh missing `Summary` titles with blanks`","5d766e50":"Use of `melt`<br>\nUnpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n\nThis function is useful to massage a DataFrame into a format where one\nor more columns are identifier variables (`id_vars`), while all other\ncolumns, considered measured variables (`value_vars`), are \"unpivoted\" to\nthe row axis, leaving just two non-identifier columns, 'variable' and\n'value'.","faa0866f":"**`Finally, should also check their relationship to Score in case one want to try to model their relationship`**","a3de02bc":"`Observ` in above plot similar pattern with Helpfulness with top_500_products\n* None of review for these products are truly in concordance with helpfulness in either direction\n* Getting a clear peak at around 0.8 which looks somewhat normal","50203ae3":"### Score count","74fb38c1":"### Sentiment Distribution\nI have sentiment of Text and Summary\n* Trying to see roughly what predicted sentiments are","6faff1db":"`Observe` most of reviews are considered postiive \n* This is somewhat expected as most of reviews have 5 stars so reasonably would assume that it would be overwhelmingly positive as well","c699034a":"`Observe` doing same thing with Summary-Length as with Text-Length\n* Although it does fluctuate, it seems to actually increase overtime","c980945f":"Got General idea of what text_data looks like\n* Now can go one step further\n    * Trying to find top_words given each year of reviews in our dataset\n    * `It would be interesting to see if we can capture trend in gourmet foods over year using reviews`","d8c08793":"`Observe` plot above shows histogram of Mean_Score from top_500_products \n* It looks somewhat left skewed and has a multi-modal distribution\n* Average stops any product from truly being 5 stars which is expected as we would expect to see some variation in reviews","ccabb37a":"`Observe` in scatter plot above\n* most of data is for relatively newer products\n* These values are generated from date difference between date_of_writing and oldest_review so it stays to reason that a lot of these reviews are relatively newer but still relatively old products\n* Next, it can tryied `T-Sne` to see if we can separate out Helpfulness and Age","dfae514f":"## Context\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.","7d3467f9":"Alternative view of data by using summary statistics","ea0c3db3":"`Observe` above plot that number of reviews in this dataset exponentially grew over years up to 2012","ddeac048":"Now `Calculating lengths of text`","1099b4a4":"### Review Length (Summary_Length and Text_Length Feature) ","ebf4e60f":"### Reviews and Summary Overview\nBulk of this dataset lies in Reviews and the Summary tagline of the review\n* There might be something in either of those features which might be interesting for classification\n* Additionally, it would be interesting to understand those features for general data anlysis to understand Reviewers better\n\nFirst, TF-IDF will be calculated high level overview of what these corpus looks like\n* We will only be checking unigram for keyword checks and removing stop words, numeric, lemmatization and removing punctuation\n* As number of documents are relatively large, a portion of it will be sampled prior to anallysis","133dac60":"**`Now creating plots`**","eee9ae15":"### Reviewers Engagement\nBased on `UserId`, trying to understand who the top reviewers are \n* These people are most engaged and would likely have high helpfulness due to honing their writing skills, and experience","d064256d":"**`Interested in seeing if two variables have any relationship between each othe`**\n* can run Spearman_Correlation as both variables are nonparametric","a0c3e576":"`Observe` the median slowly increases overtime","0cf5f5d4":"`Observe` sentiment between `Text_sentiment` and `Summary_sentiment` are weakly but significantly correlated","faa2a562":"`Observ` boxplot above shows Score vs min-max_scaled version of Summary_Length\n* there is not clear pattern between different scores\n* median and box are tighter in score 5 but as there are more samples, it makes sense","5d351b4e":"**`Next, Setup Scattertext plots of every year of this corpus to get a sense of how things changed over time`**\n* To again see which years we have in dataset, following can be done:","382e5d30":"### Product Popularity (ProductId Feature)\nTo get an estimate of how popular an item is\n* Trying to proxy this by number of reviews","fa37cede":"# `EDA`\n### `Feature Engineering`","d94d74b8":"**`Next, looking at similar metrics and visualize mean summary length of top most reviewed products`**","c4bda52a":"`Observ` top 40 tf-idf features from this sample\n* Although some of these tokens are typos, see that the tokens are a mixture of slang for positive things and food related words","18b1422a":"`Observe` that Text_sentiment is also weakly but significantly correlated to Score","59e35462":"**`Finally, trying to see how these compare with our scores`**\n\n### Relationship of Score","e33e2f74":"`Observe`:\nMost of the data is filled in with some exceptions in `ProfileName` and `Summary`","3fb39d0f":"`Observe` plot shows summary text length\n* Summary-Length is relatively consistent for a while in beginning and then begins to flucuate\n* Starts becoming sparse at around 196 reviews as number of people writing more begins to drop off"}}