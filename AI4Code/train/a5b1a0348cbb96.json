{"cell_type":{"f6dddbbf":"code","a6a8d4e3":"code","c3807cb3":"code","0ef38932":"code","61c55dd3":"code","833f7aa2":"code","2480f426":"code","312c0cb4":"code","d3b0e776":"code","74f00dfc":"code","29c5cb1f":"code","efba503f":"code","38f2afa6":"markdown","f82d63ba":"markdown","c1e5cf82":"markdown","1c2aa5b5":"markdown","af078cfb":"markdown","2310a802":"markdown","7a4bfc52":"markdown"},"source":{"f6dddbbf":"import matplotlib.pyplot as plt \nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread\nfrom skimage.transform import pyramid_reduce, resize\nimport os, glob\nimport zipfile\nfrom keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Add, LeakyReLU, UpSampling2D\nfrom keras.models import Model, load_model\nfrom keras.callbacks import ReduceLROnPlateau","a6a8d4e3":"# unzip 2d images of lung CT\npath = '..\/input\/finding-lungs-in-ct-data\/2d_images.zip'\nwith zipfile.ZipFile(path, 'r') as zip_ref:\n    zip_ref.extractall('2d_images')\n    \n# unzip 2d masks of lung CT\npath = '..\/input\/finding-lungs-in-ct-data\/2d_masks.zip'\nwith zipfile.ZipFile(path, 'r') as zip_ref:\n    zip_ref.extractall('2d_masks')","c3807cb3":"# load tiff images\nimg_list = sorted(glob.glob('2d_images\/*.tif'))\nmask_list = sorted(glob.glob('2d_masks\/*.tif'))\n\nprint(len(img_list), len(mask_list))","0ef38932":"# create numpy array placeholder for pixels with 1 channel (grey scale)\nIMG_SIZE = 256\nx_data, y_data = np.empty((2, len(img_list), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n# ^ 1st arg: (# of numpy set(x_data, y_data), length of numpy set, height, width, color channel)","61c55dd3":"# convert images to numpy arrays\nfor i, img_path in enumerate(img_list):\n    # load image\n    img = imread(img_path)\n    # resize image with 1 channel\n    img = resize(img, output_shape=(IMG_SIZE, IMG_SIZE, 1), preserve_range=True)\n    # save to x_data\n    x_data[i] = img\n\n# convert mask images to numpy arrays\nfor i, img_path in enumerate(mask_list):\n    # load image\n    img = imread(img_path)\n    # resize image with 1 channel\n    img = resize(img, output_shape=(IMG_SIZE, IMG_SIZE, 1), preserve_range=True)\n    # save to x_data\n    y_data[i] = img","833f7aa2":"# scale image arrays\n# scaling benefits learning process \nx_data \/= 255\ny_data \/= 255\n\n# display samples of image and mask in gray scale\nfig, ax = plt.subplots(1, 2)\nax[0].imshow(x_data[0].squeeze(), cmap='gray')\nax[1].imshow(y_data[0].squeeze(), cmap='gray')\n# ^ since imshow takes 2d array, 3d array is squeezed down to 2d by removing single dimensional entry","2480f426":"# split dataset into train and validation datasets with 20% test portion\nx_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2)\n\nprint(x_train.shape)\nprint(x_val.shape)","312c0cb4":"inputs = Input(shape=(256, 256, 1))\n\n# encoding\nnet = Conv2D(32, kernel_size=3, activation='relu', padding='same')(inputs)\nnet = MaxPooling2D(pool_size=2, padding='same')(net)\nnet = Conv2D(64, kernel_size=3, activation='relu', padding='same')(net)\nnet = MaxPooling2D(pool_size=2, padding='same')(net)\nnet = Conv2D(128, kernel_size=3, activation='relu', padding='same')(net)\nnet = MaxPooling2D(pool_size=2, padding='same')(net)\n\nnet = Dense(128, activation='relu')(net)\n\n# decoding\nnet = UpSampling2D(size=2)(net)\nnet = Conv2D(128, kernel_size=3, activation='sigmoid', padding='same')(net)\nnet = UpSampling2D(size=2)(net)\nnet = Conv2D(64, kernel_size=3, activation='sigmoid', padding='same')(net)\nnet = UpSampling2D(size=2)(net)\n\n# output with 1 channel for gray scale segmenation\noutputs = Conv2D(1, kernel_size=3, activation='sigmoid', padding='same')(net)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\n# use binary cross entropy with sigmoid function \nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', 'mse'])\n\nmodel.summary()","d3b0e776":"# reduce learning rate when not improving\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, min_lr=1e-05)\n\n# train model\nhistory = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=30, batch_size=32, callbacks=[reduce_lr])","74f00dfc":"# save model\nmodel.save('image_segmentation.model')","29c5cb1f":"fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n\n# loss\nax[0].set_title('model loss')\nax[0].plot(history.history['loss'], 'b')\nax[0].plot(history.history['val_loss'], 'r')\nax[0].legend(['train', 'test'], loc='upper right')\nax[0].set_ylabel('loss')\nax[0].set_xlabel('epoch')\n\n# accuracy \nax[1].set_title('model accuracy')\nax[1].plot(history.history['acc'], 'b')\nax[1].plot(history.history['val_acc'], 'r')\nax[1].legend(['train', 'test'], loc='lower right')\nax[1].set_ylabel('accuracy')\nax[1].set_xlabel('epoch')","efba503f":"# predict segmentation\npreds = model.predict(x_val)\n\n# show results\nfig, ax = plt.subplots(len(x_val), 3, figsize=(10, 100))\nfor i, pred in enumerate(preds):\n    ax[i, 0].imshow(x_val[i].squeeze(), cmap='gray')\n    ax[i, 1].imshow(y_val[i].squeeze(), cmap='gray')\n    ax[i, 2].imshow(pred.squeeze(), cmap='gray')","38f2afa6":"## Preprocess Dataset","f82d63ba":"## Build Model\n","c1e5cf82":"## Evaluation","1c2aa5b5":"## Train Model","af078cfb":"# Convolutional Encoder Decoder model for<br>Image Segmentation for Lung CT\n\nThis notebook implements a simple convolutional encoder decoder model for image segmentation.<br>\nThe model achieved a validation accuracy of 95% with 80:20 train-test setting.<br>\nThe code is reproduced from a youtube video 'CT \uc601\uc0c1\uc5d0\uc11c \ud3d0 \uc601\uc5ed\ub9cc \ubf51\uc544\ubcf4\uc790! - Python, Deep Learning' for learning and sharing purpose.","2310a802":"## Import Libraries","7a4bfc52":"## Import Dataset"}}