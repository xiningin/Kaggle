{"cell_type":{"635cf57c":"code","8d72c1a2":"code","9b698dae":"code","b73da49d":"code","1b200bb4":"code","08813fd7":"code","48be804d":"code","4c25dc00":"code","049f4274":"code","7993f0cf":"code","f2dde445":"code","12048dec":"code","f40f7008":"code","774f8e4e":"code","fa28bbf8":"code","39957507":"code","bb5a0f9f":"code","79ca4738":"code","a36db0f8":"code","bf4572c3":"code","d1c3b48d":"code","36d0b351":"code","e18459a1":"code","11ff664a":"code","ff6c4b9e":"code","dd9dfd93":"code","88109483":"code","956ce517":"code","cb546e53":"code","b586ebec":"code","8f84b640":"code","ef951b45":"code","4173ac7f":"code","d09fd72f":"code","4b00ae5d":"code","3c562ce3":"code","b3d20926":"code","1e9a01e9":"code","70d579c6":"code","4edc6a1e":"code","73bde08a":"code","c5ebb230":"code","9d01de8c":"code","9f3e4398":"code","becb9c94":"code","e80ce440":"code","ba924f53":"code","31f3d218":"code","4581862c":"code","19a844b7":"code","97061eaa":"markdown","d0561d90":"markdown","d8d77d74":"markdown","b230b0ff":"markdown","79607356":"markdown","1a9097d3":"markdown","e38f4b82":"markdown","ba205bfd":"markdown","d3ec2575":"markdown","a7a0dc2a":"markdown","d04e4733":"markdown","2e09937d":"markdown"},"source":{"635cf57c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import auc,roc_curve,roc_auc_score\n\nimport tensorflow as tf\nprint(\"Tensorflow version:\", tf.__version__)\n\n!pip install git+https:\/\/github.com\/tensorflow\/docs\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.modeling\n\nimport tensorflow.keras as keras\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\n\nfrom IPython.display import SVG, Image\n\n!pip install livelossplot\nfrom livelossplot.tf_keras import PlotLossesCallback\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=FutureWarning)","8d72c1a2":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));","9b698dae":"#define path to the data directory\nbase_dir = '\/kaggle\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\/'","b73da49d":"os.listdir(base_dir)","1b200bb4":"#read the entire dataset\ndf = pd.read_csv(base_dir+'icml_face_data.csv')\ndf.columns = ['emotion', 'Usage', 'pixels']\ndf.head()","08813fd7":"df.info()","48be804d":"df['emotion'].value_counts()","4c25dc00":"df['Usage'].value_counts()","049f4274":"#read train data\ntrain = pd.read_csv(base_dir+'train.csv')\ntrain.head()","7993f0cf":"#read test data\ntest = pd.read_csv(base_dir+'test.csv')\ntest.head()","f2dde445":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","12048dec":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(30,8))\n\nsns.countplot(data = df[df['Usage']=='Training'], x='emotion', ax=ax1, palette='Spectral').set_title('Training')\nax1.set_xticklabels(emotions.values())\n\nsns.countplot(data = df[df['Usage']=='PublicTest'], x='emotion', ax=ax2, palette='Spectral').set_title('Testing')\nax2.set_xticklabels(emotions.values())\n\nsns.countplot(data = df[df['Usage']=='PrivateTest'], x='emotion', ax=ax3, palette='Spectral').set_title('Validation')\nax3.set_xticklabels(emotions.values())","f40f7008":"fig = plt.figure(1, (20, 20))\n\nk = 0\nfor label in sorted(df['emotion'].unique()):\n    for j in range(7):\n        px = df[df['emotion']==label].pixels.iloc[k]\n        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n\n        k += 1\n        ax = plt.subplot(7, 7, k)\n        ax.imshow(px, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(emotions[label])\n        plt.tight_layout()","774f8e4e":"train_data = df[df['Usage']=='Training']\ntrain_data.drop(columns='Usage', inplace=True)\ntrain_data.head()","fa28bbf8":"train_data.isnull().sum()","39957507":"train_data.info()","bb5a0f9f":"train_data['pixels'][0]","79ca4738":"def prepare_data(data):\n    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n    image_label = np.array(list(map(int, data['emotion'])))\n\n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48)) \n        image_array[i, :, :, 0] = image \/ 255\n\n    return image_array, image_label","a36db0f8":"X_train, y_train = prepare_data(train_data)\nprint(X_train.shape, y_train.shape)","bf4572c3":"X_train","d1c3b48d":"y_train","36d0b351":"test_data = df[df['Usage']!='Training']\ntest_data.drop(columns='Usage', inplace=True)\ntest_data.head()","e18459a1":"X_test, y_test = prepare_data(test_data)\nprint(X_test.shape, y_test.shape)","11ff664a":"print('X_train', X_train.shape)\nprint('X_test', X_test.shape)\n\nprint('y_train', y_train.shape)\nprint('y_test', y_test.shape)","ff6c4b9e":"#train val split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n                                                  shuffle=True, \n                                                  stratify=y_train,\n                                                  test_size=0.2, \n                                                  random_state=121)","dd9dfd93":"#encode labels\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)\ny_train = keras.utils.to_categorical(y_train)","88109483":"#ecode labels\ny_test = le.transform(y_test)\ny_test = keras.utils.to_categorical(y_test)","956ce517":"#ecode labels\ny_val = le.transform(y_val)\ny_val = keras.utils.to_categorical(y_val)","cb546e53":"print('y_train', y_train.shape)\nprint('y_test', y_test.shape)\nprint('y_val', y_val.shape)","b586ebec":"y_train","8f84b640":"y_test","ef951b45":"img_size = 48\nbatch_size = 32\n\n#use Image Data Generator to perform this task\n#train set\ndatagen = ImageDataGenerator(rotation_range=25, \n                             width_shift_range=0.1,\n                             height_shift_range=0.1, \n                             shear_range=0.2, \n                             zoom_range=0.2,\n                             horizontal_flip=True)\n\ndatagen.fit(X_train)\ndatagen.fit(X_val)","4173ac7f":"model = Sequential()\n\n#1st conv\nmodel.add(Conv2D(128, (3,3), padding='same', input_shape=(48,48,1))) #1 is for grayscale\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd conv\nmodel.add(Conv2D(128, (5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#3rd conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#4th conv\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))","d09fd72f":"#compile\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-5),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","4b00ae5d":"model.summary()","3c562ce3":"from tensorflow.keras.utils import plot_model\n\n#plot\nplot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)","b3d20926":"epochs = 100\n\n#checkpoint to save best weights\ncheckpoint = ModelCheckpoint('model_weights.h5',\n                             monitor='val_accuracy',\n                             save_weights_only=True,\n                             mode='max')\n\n#reduce learning rate if plateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=2,\n                              min_lr=0.00001,\n                              mode='min')\n\n#stop training if accuracy does not improve\nearlystop = EarlyStopping(monitor='val_accuracy',\n                          patience=5,\n                          mode='max')\n\n#define callbacks\ncallbacks = [tfdocs.modeling.EpochDots(), \n             earlystop, \n             checkpoint, \n             reduce_lr]","1e9a01e9":"%%time\n\n#(datagen.flow(X_train, y_train, batch_size=batch_size)\n \nhistory = model.fit(X_train, y_train,\n                    validation_data=(X_val, y_val),\n                    batch_size=batch_size,\n                    steps_per_epoch=len(X_train) \/ batch_size,\n                    epochs=epochs,\n                    callbacks=callbacks,\n                    verbose=0)","70d579c6":"fig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_acc) + 1)\n\nax[0].plot(epochs , train_acc , 'g-o' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'y-o' , label = 'Validation Accuracy')\nax[0].set_title('Model Training & Validation Accuracy')\nax[0].legend(loc = 'lower right')\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'y-o' , label = 'Validation Loss')\nax[1].set_title('Model Training & Validation & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","4edc6a1e":"print('Train accuracy & loss:', model.evaluate(X_train, y_train))\nprint('\\n')\nprint('Test accuracy & loss:', model.evaluate(X_test, y_test))","73bde08a":"#make prediction\nyhat_test = np.argmax(model.predict(X_test), axis=1)\nyhat_test","c5ebb230":"y_test = np.argmax(y_test, axis=1)\ny_test","9d01de8c":"from mlxtend.plotting import plot_confusion_matrix\n\n#get confusion matrix\ncm = confusion_matrix(y_test, yhat_test)\nprint(cm)\n\nfig, ax = plot_confusion_matrix(conf_mat=cm,\n                                show_normed=True,\n                                show_absolute=False,\n                                class_names=emotions.values(),\n                                figsize=(8, 8))\nfig.show()","9f3e4398":"#get classification report\nprint(classification_report(y_test, yhat_test, target_names=emotions.values()))","becb9c94":"model_json = model.to_json()\nwith open('model.json','w') as json_file:\n    json_file.write(model_json)\n    \nmodel.save('final_model.h5')","e80ce440":"plt.figure(figsize=[16,16])\n\nfor i in range(36):\n    img = X_test[i,:,:,0]\n    p_dist = model.predict(img.reshape(1, 48, 48, 1))\n    k = np.argmax(p_dist)\n    p = np.max(p_dist)\n\n    plt.subplot(6, 6, i+1)\n    plt.imshow(img, cmap='binary_r')\n    plt.title(f'{emotions[y_test[i]]} - ({emotions[k]} - {p:.4f})')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","ba924f53":"class GradCAM:\n    def __init__(self, model, classIdx, layerName=None):\n        self.model = model\n        self.classIdx = classIdx\n        self.layerName = layerName\n        if self.layerName is None:\n            self.layerName = self.find_target_layer()\n            \n    def find_target_layer(self):\n        for layer in reversed(self.model.layers):\n            if len(layer.output_shape) == 4:\n                return layer.name\n        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n        \n    def compute_heatmap(self, image, eps=1e-8):\n        gradModel = Model(\n            inputs=[self.model.inputs],\n            outputs=[self.model.get_layer(self.layerName).output,self.model.output]\n       )\n           \n        with tf.GradientTape() as tape:\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = gradModel(inputs)\n            loss = predictions[:, self.classIdx]\n            grads = tape.gradient(loss, convOutputs)\n\n            castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n            castGrads = tf.cast(grads > 0, \"float32\")\n            guidedGrads = castConvOutputs * castGrads * grads\n            convOutputs = convOutputs[0]\n            guidedGrads = guidedGrads[0]\n\n            weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n            cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n            (w, h) = (image.shape[2], image.shape[1])\n            heatmap = cv2.resize(cam.numpy(), (w, h))\n            numer = heatmap - np.min(heatmap)\n            denom = (heatmap.max() - heatmap.min()) + eps\n            heatmap = numer \/ denom\n            heatmap = (heatmap * 255).astype(\"uint8\")\n        return heatmap\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n        colormap = cv2.COLORMAP_VIRIDIS):\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n        return (heatmap, output)","31f3d218":"plt.figure(figsize=[16,16])\nfor i in range(36):\n    img = X_test[i,:,:,0]\n    p_dist = model.predict(img.reshape(1, 48, 48, 1))\n    k = np.argmax(p_dist)\n    p = np.max(p_dist)\n\n    cam = GradCAM(model, k)\n    heatmap = cam.compute_heatmap(img.reshape(1, 48, 48, 1))\n\n    plt.subplot(6, 6, i+1)\n    plt.imshow(img, cmap='binary_r')\n    plt.imshow(heatmap, alpha=0.5, cmap='hsv')\n    plt.title(f'{emotions[y_test[i]]} - ({emotions[k]} - {p:.4f})')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","4581862c":"test_prob = model.predict(X_test)\ntest_pred = np.argmax(test_prob, axis=1)\n\nsel_imgs = [33, 1000, 88, 777, 108, 111, 7000]\n\nfor n in sel_imgs:\n    img = X_test[n,:,:,0]\n    \n    plt.figure(figsize=[10,3])\n    plt.subplot(1, 3, 1)\n    plt.imshow(img, cmap='binary_r')\n    plt.title(f'True Label: {emotions[y_test[n]]}')\n    plt.axis('off')\n    \n    cam = GradCAM(model, test_pred[n])\n    heatmap = cam.compute_heatmap(img.reshape(1,48,48,1))\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(img, cmap='binary_r')\n    plt.imshow(heatmap, alpha=0.5, cmap='hsv')\n    plt.title(f'Predicted Label: {emotions[test_pred[n]]}')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.bar(emotions.values(), test_prob[n, :], color='m', edgecolor='k')\n    plt.xticks(rotation=45)\n    plt.ylim([0,1])\n    plt.title('Distribution of Predictions')\n    plt.show()","19a844b7":"model_json = model.to_json()\n\nwith open('model.json', 'w') as json_file:\n    json_file.write(model_json)","97061eaa":"## Evaluate Model ","d0561d90":"## Represent Model as JSON String","d8d77d74":"## Grad-CAM","b230b0ff":"## Data Loader and Data Augmentation","79607356":"### Test Set","1a9097d3":"### Prepare Labels","e38f4b82":"### Train Test Split","ba205bfd":"## Build Model","d3ec2575":"## Exploratory Data Analysis","a7a0dc2a":"## Prepare Train & Test Set Inputs\n### Train Set","d04e4733":"## Make Prediction","2e09937d":"## Train Model"}}