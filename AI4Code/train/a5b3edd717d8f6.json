{"cell_type":{"2b10aa8d":"code","e923a9df":"code","e5d13820":"code","899c3146":"code","7a11fbac":"code","da0f1e88":"code","3773f5b3":"code","b086ec01":"code","786fdcdd":"code","b186d21b":"code","4c0ed1f1":"code","3288c6dd":"code","1a570474":"code","ef39dd87":"code","ba6a50c2":"code","31a0dc89":"code","1a52bea3":"code","56977643":"code","5046d4d1":"code","9ea9f2ac":"code","90166012":"code","ddd59fdf":"code","4a128517":"code","16d8effc":"code","efb4928a":"code","1952424a":"code","ff4aa41a":"code","02ae41f1":"code","fe88fed7":"code","cdac3854":"code","147925f4":"code","298eaa86":"code","cabd3305":"code","ff550e31":"code","2aeb0059":"code","3dfe2554":"code","f567f77d":"code","758da6a2":"code","b394868d":"code","54fb7734":"code","b79decea":"code","920a6737":"code","afcb326b":"code","06b5ab2b":"code","e38f8e5c":"markdown","0e6cd4c4":"markdown"},"source":{"2b10aa8d":"import pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [20,10]\n#%matplotlib inline","e923a9df":"vaccineTweet_DF = pd.read_csv('\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv')\nvaccineTweet_DF.head()","e5d13820":"vaccineTweet_DF.shape","899c3146":"# Checking null\nvaccineTweet_DF.isnull().sum()","7a11fbac":"# User location and hashtags and descripton NULL values will be replace with unknown and None, and NoDesc respectivetly \nvaccineTweet_DF['user_location'].fillna('Unknown', inplace=True)\nvaccineTweet_DF['hashtags'].fillna('None', inplace=True)\nvaccineTweet_DF['user_description'].fillna('NoDesc', inplace=True)","da0f1e88":"vaccineTweet_DF.isnull().sum()","3773f5b3":"vaccineTweet_DF.head()","b086ec01":"import nltk\nnltk.download('stopwords')","786fdcdd":"# Plan is to analyze text and hashtags columns \nimport string\nstring.punctuation","b186d21b":"# Remove punctuation FUNCTION\ndef remove_punctuation(text):\n    for eachPunct in string.punctuation:\n        text = text.replace(eachPunct, '')\n    return text ","4c0ed1f1":"vaccineTweet_DF['text'] = vaccineTweet_DF['text'].apply(remove_punctuation)\nvaccineTweet_DF.head()","3288c6dd":"vaccineTweet_DF.shape","1a570474":"# Let's check some retweets \nvaccineTweet_DF['retweets'].value_counts().plot(kind='bar', title='No of Retweets Twitter Acounts')","ef39dd87":"vaccineTweet_DF['favorites'].value_counts().plot(kind='bar', color='red',title='No of Favorites Twitter Acounts')","ba6a50c2":"# Let's do some tokenize FUNCTION  \nfrom nltk.tokenize import word_tokenize\ndef tokenize_text(text):\n    text = word_tokenize(text.lower())\n    return text","31a0dc89":"# Apply the tokenize function to the text column\nvaccineTweet_DF['text'] = vaccineTweet_DF['text'].apply(tokenize_text)\nvaccineTweet_DF.head()","1a52bea3":"pip install textblob","56977643":"pip install langdetect ","5046d4d1":"from langdetect import detect\nfrom textblob import TextBlob    \nmyword = detect(\"hello\")\nmyword","9ea9f2ac":"# stop words FUNCTION\nfrom nltk.corpus import stopwords\ndef remove_stopwords(text):\n    #global stopwords\n    stop_words = set(stopwords.words('english'))\n    text = [word for word in text if not word in stop_words]\n    return text","90166012":"vaccineTweet_DF['text'] = vaccineTweet_DF['text'].apply(remove_stopwords)\nvaccineTweet_DF","ddd59fdf":"import nltk\nnltk.download('wordnet')","4a128517":"# Lemmatization FUNCTION\ndef lemmatize_words(text):\n    wn = nltk.WordNetLemmatizer()\n    text = [wn.lemmatize(word) for word in text]\n    return text\n","16d8effc":"#vaccineTweet_DF['text'] = vaccineTweet_DF.apply(lemmatize_words)","efb4928a":"from nltk.stem import PorterStemmer","1952424a":"# Stemming \ndef stemming_word(text):\n    porter = PorterStemmer()\n    text = [porter.stem(t) for t in text]\n    return text","ff4aa41a":"vaccineTweet_DF['text'].apply(stemming_word)\nvaccineTweet_DF.head()","02ae41f1":"from textblob import TextBlob","fe88fed7":"# Polarity and Subjectivity\ndef sentiment_analysis(text):\n    analisys = TextBlob(text).sentiment\n    return analisys\n\nvaccineTweet_DF.head()","cdac3854":"# To String\ndef listToStr(myList):\n    if type(myList) is list:\n        return \";\".join(myList)\n    else:\n        return myList","147925f4":"vaccineTweet_DF['text'].apply(lambda x: [listToStr(i) for i in x])","298eaa86":"vaccineTweet_DF['stringText'] = vaccineTweet_DF['text'].apply(lambda x: x[1:])\nvaccineTweet_DF.head()","cabd3305":"vaccineTweet_DF['text'] = vaccineTweet_DF['text'].astype(str)","ff550e31":"vaccineTweet_DF['senti_score'] = vaccineTweet_DF['text'].apply(sentiment_analysis)","2aeb0059":"vaccineTweet_DF.head()","3dfe2554":"sentiment_series = vaccineTweet_DF['senti_score'].tolist()","f567f77d":"#vaccineTweet_DF['senti_score'].value_counts().plot(kind='pie')\nuser_verify_plot = vaccineTweet_DF.groupby('user_verified').hashtags.count()\nuser_verify_plot.plot(kind='pie', title='User Verify Twitter Account')","758da6a2":"# Check top 20 locations (USER)\nuser_location = vaccineTweet_DF['user_location'].value_counts().index[:20]\nuser_location","b394868d":"sns.countplot(y='user_location', data=vaccineTweet_DF, order=user_location, color='cornflowerblue')\nplt.title('Number of USERS per LOCATION', loc='center')\nplt.xlabel('Number of users', weight='bold')\nplt.ylabel('Location', weight='bold')\nplt.show()","54fb7734":"# Analize Polarity & Subjetivity together\nfig, ax = plt.subplots(figsize=(8,6), sharex=True)\nplt.ylim(0,2)\nvaccineTweet_DF['senti_score'].hist(ax=ax)","b79decea":"# Analizing Polarity and Subjetivity separate\nsentiment_series = vaccineTweet_DF['senti_score'].tolist()\ncols = ['Polarity', 'Subjetivity']\nsentimentDF = pd.DataFrame(sentiment_series, columns=cols, index=vaccineTweet_DF.index)\nsentimentDF.head()","920a6737":"# remove all 0.00 's \nsentimentDF = sentimentDF.loc[(sentimentDF != 0).any(axis=1)].reset_index(drop=True)\nsentimentDF","afcb326b":"# Polarity Distribution\nplt.hist(sentimentDF['Polarity'], color='darkred', edgecolor='black', density=False, bins= int(30))\nplt.title('Polarity Distribution')\nplt.xlabel('Polarity')\nplt.ylabel('Number of Times')","06b5ab2b":"#Subjetivity Distribution\nsns.distplot(sentimentDF['Subjetivity'], hist=True, kde=True, bins=int(30), color='darkred', hist_kws={'edgecolor':\n                                                                                                   'black'}, axlabel='Subjetivity')\nplt.xlabel('Subjetivity')\nplt.ylabel('Number of times')\nplt.title('Subjetivity Distribution')","e38f8e5c":"## How the new Covid-19 vaccine from Pfizer and BioNTech was received by Tweeter Public","0e6cd4c4":"## Analazing data with NLP"}}