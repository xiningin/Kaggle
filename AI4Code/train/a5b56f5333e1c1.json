{"cell_type":{"f9714349":"code","4bda81ca":"code","0b5c5b4a":"code","a9d95172":"code","498e77ff":"code","77b5177b":"code","c30898a2":"code","070e51c7":"code","cf25df00":"code","1155daa2":"markdown","9772d5e1":"markdown","608e6c17":"markdown","a44cd9c0":"markdown","0e68bcaf":"markdown","9aab6838":"markdown","2306d2f0":"markdown","fe39b194":"markdown","0a84348b":"markdown"},"source":{"f9714349":"import numpy as np\nimport pandas as pd\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import cross_validate\n\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.metrics import accuracy_score","4bda81ca":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\nTASTK_TYPE = 'GPU'","0b5c5b4a":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","a9d95172":"def getLabelCount(df,target):\n    return [( labelValue,len(train.loc[df[target] == labelValue]) ) for labelValue in df[target].unique()]\n\nlabelCount = getLabelCount(train,TARGET)\nlabelCount","498e77ff":"# Outlier detection \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n\n# 1.detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n\n# 2.get train row size \ntrain_len = len(train)\n\n# 3.concat train + test \ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n\n# 4. empty data => np.nan\ndataset = dataset.fillna(np.nan)\n\n# 5.column encoding and create new features\n# 5.1.Fare\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n# dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n\n# 5.2.Embarked\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(dataset[\"Fare\"].mode()[0])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\n\n# 5.3.Sex\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n# dataset = pd.get_dummies(dataset, columns = [\"Sex\"])\n\n# 5.4.Age\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].mean()\n    dataset['Age'].iloc[i] = age_med\n#     age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n#     if not np.isnan(age_pred) :\n#         dataset['Age'].iloc[i] = age_pred\n#     else :\n#         dataset['Age'].iloc[i] = age_med\n        \n        \n# 5.5.Name         \n# dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n# dataset[\"Title\"] = pd.Series(dataset_title)\n# dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n# dataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n# dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n# dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)\n# dataset = pd.get_dummies(dataset, columns = [\"Title\"])\n\n# 5.6.SibSp(Number of Siblings\/Spouses Aboard) + Parch(Number of Parents\/Children Aboard) =>Fsize\ndataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['IsSingle'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n# dataset['IsSmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n# dataset['IsMedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# dataset['IsLargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n# #5.7.Cabin\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\n\n# #5.8.Ticket \nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# 5.9.Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# 5.10.PassengerId\ndataset.drop(labels = [\"Name\",\"PassengerId\"], axis = 1, inplace = True)\n\n# 6.devide train test \ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","77b5177b":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test","c30898a2":"model = CatBoostClassifier(task_type=TASTK_TYPE) \nmodel.fit(X, y,verbose=True)","070e51c7":"pred_test = model.predict(X_test)","cf25df00":"submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsubmission[TARGET] = pred_test.astype(int)\nsubmission.to_csv(SUBMISSION_PATH,index=False)\nsubmission.head()","1155daa2":"# import","9772d5e1":"# variables","608e6c17":"# split data (input and label)","a44cd9c0":"# load data","0e68bcaf":"# preprocess","9aab6838":"# check label count","2306d2f0":"# predict test data target","fe39b194":"# training","0a84348b":"# make submission csv"}}