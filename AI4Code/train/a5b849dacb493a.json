{"cell_type":{"9bf61160":"code","e6cd3091":"code","365db0df":"code","6d37df76":"code","56a1341b":"code","8c523a23":"code","6d74e010":"code","c327eaff":"code","5e4dd3d4":"code","96edd146":"code","5675e99f":"code","cf306646":"code","e7550303":"code","3622674f":"code","29867a24":"code","7539b1b3":"code","121e6e33":"code","8367504e":"code","0018b393":"code","e2c3f651":"code","c8dada74":"code","979693a0":"markdown","261668c7":"markdown","64c3f705":"markdown","42e5f9e1":"markdown","22e1496b":"markdown","bb5efefa":"markdown","d5990833":"markdown","a8b10c5e":"markdown","db993267":"markdown","b0406aec":"markdown"},"source":{"9bf61160":"import numpy as np\nimport pandas as pd\nimport subprocess as sp\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport wordcloud","e6cd3091":"# loading data\ndf = pd.read_csv('..\/input\/netflix-shows\/netflix_titles.csv')\nn_samples,n_feats = df.shape\ndf","365db0df":"df.columns\n\nprint(df.shape[0])\ndf.groupby(['type']).count()['show_id']\n\ndf.isnull().sum()","6d37df76":"# movie and series distribution\ndist = df.groupby(df['type']).count()['show_id'].reset_index()\nfig, ax = plt.subplots(facecolor='white',figsize=(10,10))\nax.bar(dist['type'],dist['show_id'])","56a1341b":"# dist of movie or series running in countries\ncountries = []\nfor i in df['country']:\n    if isinstance(i,str):\n        l = i.split(',')\n        for i in range(len(l)):\n            l[i] = l[i].strip()\n        countries = countries + l\ndist = dict(Counter(countries))\ndist20 = {k:v for k,v in sorted(dist.items(),key=lambda x: x[1],reverse=True)[:20]}\nfig, ax = plt.subplots(facecolor='white',figsize=(10,20))\nax.barh(list(dist20.keys()),dist20.values())\nax.grid(True,axis='x')\nax.set_xlabel(\"Number of shows running\")\nplt.title(\"Top 20 Country by Show Available\")\nplt.show()","8c523a23":"# release year distribution, grouped by 10 years\nyears= df['release_year'].values\nmaxyrs = np.max(years)\nminyrs = np.min(years)\ndist = {k:0 for k in np.arange(1920,2021,10)}\nfor i in years:\n    dist[int(str(int(i \/ 10))+'0')] += 1\nxticklabels = [str(i)+'s' for i in dist.keys()]\nfig, ax = plt.subplots(facecolor='white', figsize= (20,10))\nax.bar(dist.keys(),dist.values())\nax.set_xlabel('Release Years')\nax.set_ylabel('Running Shows')\nax.set_xticks(list(dist.keys()))\nax.set_xticklabels(xticklabels)\nplt.show()\n","6d74e010":"# rating distribution\ndist = df.groupby(['rating']).count().reset_index()[['rating','show_id']]\nfig, ax = plt.subplots(facecolor='white',figsize=(10,8))\nax.bar(dist['rating'],dist['show_id'])\nticks = np.arange(len(dist['rating']))\nax.set_xticks(ticks)\nax.set_xticklabels(dist.rating)\nax.set_xlabel('Content Ratings')\nax.set_ylabel('Shows Count')\nplt.show()","c327eaff":"# tags dist\ntmp_tags = []\nfor i in df['listed_in']:\n    tags = [c.strip() for c in i.split(',')]\n    tmp_tags = tmp_tags + tags\n\ndist = {k:v for k,v in sorted(dict(Counter(tmp_tags)).items(),key=lambda x: x[1])}\n\nfig, ax = plt.subplots(facecolor='white',figsize=(10,20))\nyticks = sorted(np.arange(len(dist.keys())))\nax.barh(list(dist.keys()),dist.values())\nax.set_yticks(yticks)\nax.set_yticklabels(dist.keys())\nax.set_frame_on(False)\nax.grid(True,axis='x')\n\nplt.title('Tags Count')\nplt.show()","5e4dd3d4":"# description\nwc = wordcloud.WordCloud(width=2000,height=2000)\ntexts = \" \".join([w for w in df.description])\nwc.generate(texts)\nfig, ax = plt.subplots(figsize=(10,10))\nax.imshow(wc, interpolation='bilinear')\nax.axis(\"off\")\nplt.show()","96edd146":"from nltk.stem.snowball import EnglishStemmer\nfrom nltk.corpus import stopwords\nes = EnglishStemmer(ignore_stopwords=False)\nsw = set(stopwords.words('english'))\ndef clean(sent):\n#     cleaned = [es.stem(w) for w in sent.split() if w not in sw]\n    sent = sent.lower()\n    cleaned = [w for w in sent.split() if w not in sw]\n    return \" \".join(cleaned)\n\nfor i in range(df.shape[0]):\n    df.loc[i,'description'] = clean(df.loc[i,'description'])","5675e99f":"try:\n    import fasttext.util\nexcept:\n    !pip install fasttext\n    import fasttext.util\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import text\nfrom scipy import spatial\n!pip install python-levenshtein\nfrom Levenshtein import ratio\nimport random\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfasttext.util.download_model('en',if_exists='ignore') # english\nft = fasttext.load_model('cc.en.300.bin')\ns1 = ft.get_sentence_vector('I am sad').reshape(1,-1)\ns2 = ft.get_sentence_vector('I am happy').reshape(1,-1)\nprint(cosine_similarity(s1,s2)[0][0])","cf306646":"ITEM = random.randint(0,df.shape[0])\n# ITEM = 5285\ns1 = ft.get_sentence_vector(df.loc[ITEM,'description']).reshape(1,-1)\nprint('==================Target==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(df.loc[ITEM,'title'],df.loc[ITEM,'listed_in'],df.loc[ITEM,'description']))\nsims = []\nfor i in np.random.randint(0,df.shape[0]-1,100):\n    s2 = ft.get_sentence_vector(df.loc[i,'description']).reshape(1,-1)\n    sim = cosine_similarity(s1,s2)\n    sims.append((i,sim[0][0]))\ntop = sorted(sims,key=lambda x: x[1],reverse=True)[:5]\nfor tpl in top[:10]:\n    print('==================%.2f==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(tpl[1],df.loc[tpl[0],'title'],df.loc[tpl[0],'listed_in'],df.loc[tpl[0],'description']))","e7550303":"tfvec = TfidfVectorizer(ngram_range=(1,1))\ntfvec.fit(df['description'])","3622674f":"# this needs to be changed for tfvec\nITEM = random.randint(0,df.shape[0])\n# ITEM = 5285\ns1 = ft.get_sentence_vector(df.loc[ITEM,'description']).reshape(1,-1)\nprint('==================Target==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(df.loc[ITEM,'title'],df.loc[ITEM,'listed_in'],df.loc[ITEM,'description']))\nsims = []\nfor i in np.random.randint(0,df.shape[0]-1,100):\n    s2 = ft.get_sentence_vector(df.loc[i,'description']).reshape(1,-1)\n    sim = cosine_similarity(s1,s2)\n    sims.append((i,sim[0][0]))\ntop = sorted(sims,key=lambda x: x[1],reverse=True)[:5]\nfor tpl in top[:10]:\n    print('==================%.2f==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(tpl[1],df.loc[tpl[0],'title'],df.loc[tpl[0],'listed_in'],df.loc[tpl[0],'description']))","29867a24":"df = df.dropna(subset=['rating'],axis=0).reset_index()\ndf.drop(columns=['index'],inplace=True)","7539b1b3":"from sklearn.preprocessing import OneHotEncoder","121e6e33":"def customOneHotEncoder(X):\n    \"\"\"\n    Custom one hot encoding of 'listed_in' features\n    Parameters\n    ----------\n    X: dataframe like 2d array\n    \n    Returns\n    -------\n    X: Dataframe\n    \"\"\"\n    Nsamples = X.shape[0]\n    tmp_tags = []\n    for i in X['listed_in']:\n        tags = [c.strip() for c in i.split(',')]\n        tmp_tags = tmp_tags + tags\n    unq_tags = ['listed_in_'+t for t in set(tmp_tags)]\n    df = pd.DataFrame(data=np.zeros((Nsamples,len(unq_tags))),columns=unq_tags)\n    \n    for i in range(Nsamples):\n        tags = [c.strip() for c in X.loc[i,'listed_in'].split(',')]\n        for t in tags:\n            df.loc[i,'listed_in_'+t] = 1\n    return pd.DataFrame(df)","8367504e":"X = df[['type','listed_in','rating']]\nX = customOneHotEncoder(X)","0018b393":"import sklearn.cluster as skc\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AffinityPropagation\n\n# KMeans\nkm = KMeans(n_clusters=30)\nkm.fit(X)\nX['cluster'] = km.labels_\ndf['cluster'] = km.labels_","e2c3f651":"def predict(target, scope, n=5):\n    \"\"\"\n    Predicts similar N movies by Cosine similarity with description. If target has attribute **cluster**, function will only match movies in the same cluster.\n    Params\n    ------\n    target: Series. shape: (n_features,)\n    scope: dataframe on which to search (n_samples,n_features)\n    Returns\n    -------\n    Y: dataframe. columns: [rank, similarity] + X.columns\n    \"\"\"\n    # tfvec = TfidfVectorizer(ngram_range=(1,3))\n    \n#     tf_target = tfvec.transform([target['description']])\n    cluster = True if 'cluster' in scope.columns else False\n    sims = []\n\n    if cluster:\n\n        idx = scope[scope['cluster']==target['cluster']].index\n\n        # X = tfvec.fit_transform(scope.loc[idx,'description'])\n        # tf_target = tfvec.transform([target['description']])\n        ft_target = ft.get_sentence_vector(target['description']).reshape(1,-1)\n\n        for i in range(len(idx)):\n            if scope.loc[idx[i],'show_id'] == target['show_id']:\n                continue\n            # tf_text = X[i]\n            # tf_sim = cosine_similarity(tf_text,tf_target)\n            # sims.append((scope.loc[idx[i],'show_id'],tf_sim,scope.loc[idx[i],'cluster']))\n            # print(idx[i])\n            \n            ft_text = ft.get_sentence_vector(scope.loc[idx[i],'description']).reshape(1,-1)\n            ft_sim = cosine_similarity(ft_target,ft_text)\n            sims.append((scope.loc[idx[i],'show_id'],ft_sim,scope.loc[idx[i],'cluster']))\n            \n    else:\n        tfvec.fit_transform(scope.loc[idx,'description'])\n        tf_target = tfvec.transform([target['description']])\n        \n        for i in range(scope.shape[0]):\n            text = scope.loc[i,'description']\n            tf_text = tfvec.transform([text])\n            tf_sim = cosine_similarity(tf_text,tf_target)\n            sims.append((scope.loc[idx[i],'show_id'],tf_sim,scope.loc[idx[i],'cluster']))\n            \n    top = sorted(sims,key=lambda x: x[1],reverse=True)\n    return top[:5]\n\ndef showbyid(df,obj):\n    \"\"\"\n    Returns movies in a dataframe.\n    \"\"\"\n    idx = [i[0] for i in obj]\n    confidence = [i[1][0][0] for i in obj]\n    \n    tmp = pd.DataFrame(columns=df.columns)\n    for i in idx:\n        tmp = tmp.append(df.loc[df['show_id']==i,:])\n    tmp['confidence'] = confidence\n    return tmp.reset_index()","c8dada74":"test = random.randint(0,df.shape[0]-1)\nprint(\"-----Query--\\n\",df.loc[test])\nres = predict(df.loc[test],df)\nsimilar_movies = showbyid(df,res)\nsimilar_movies","979693a0":"# EDA","261668c7":"### TfIdf ","64c3f705":"## Cluster First, Ranking Later","42e5f9e1":"### Using Word Embedding with Cosine Similarity","22e1496b":"### Clustering","bb5efefa":"Dataset from: https:\/\/www.kaggle.com\/shivamb\/netflix-shows\/ \n\nPerforming basic EDA, and planned tasks-\n* Type of content distribution in different countries\n* Clustering movies based on linguistic features","d5990833":"### OneHotEncoding","a8b10c5e":"# Recommender \ninput: a movie name.\n\noutput: N movies similar to that.\n\n---\nways to achieve:\n1. description similarity measure\n2. cluster. find in which cluster the movie is. rank that cluster by similarity measure.\n\n## Preprocessing\n- stopwords\n- stemming","db993267":"## Similarity Measure on Description\n","b0406aec":"remove NaN from 'rating'  attribute"}}