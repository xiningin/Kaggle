{"cell_type":{"210aada4":"code","c15a9c9c":"code","22bd8076":"code","f64dfe2c":"code","30d3b648":"code","b274e953":"code","feffed90":"code","c9135dd3":"code","9b97e52a":"code","b01bcd6b":"code","bdacd665":"code","51f8d684":"code","b0c82fe6":"code","2f53c080":"code","4b5bdc07":"code","f309675c":"code","20b7ee1b":"code","3e83042d":"code","b281ff9c":"code","22850894":"code","bd123992":"code","38dae4d4":"code","02d791d4":"code","0833d8a5":"code","e2256a24":"code","aad5eecf":"markdown","b81f3bd4":"markdown","fe4c545e":"markdown","8882e322":"markdown","beb0fb82":"markdown","7c14c297":"markdown","699d1a7f":"markdown"},"source":{"210aada4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","c15a9c9c":"# loading the dataset\nfashion_mnist=tf.keras.datasets.fashion_mnist","22bd8076":"# splitting into train and test\n(X_train_full,y_train_full),(X_test,y_test)=fashion_mnist.load_data()","f64dfe2c":"print('Shape of original train data:',X_train_full.shape)\nprint('Shape of test set:',X_test.shape)","30d3b648":"# creating a validation set from train set\n# train set-50000 , validation set- 10000\nX_valid,X_train= X_train_full[:10000]\/255.0, X_train_full[:50000]\/255.0\ny_valid,y_train= y_train_full[:10000], y_train_full[:50000]","b274e953":"print('Shape of final train set:',X_train.shape)\nprint('Shape of validation set:',X_valid.shape)\nprint('Shape of test set:',X_test.shape)","feffed90":"# Checking labels count in training set\nfrom collections import Counter\nprint('Label count of y_train :',Counter(y_train))","c9135dd3":"# Plotting first 9 images of train set\nplt.figure(figsize=(6,6))\nfor i in range(9): \n    plt.subplot(330 + 1 + i)\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\nplt.show()","9b97e52a":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten","b01bcd6b":"ann_model= Sequential()\nann_model.add(Flatten(input_shape=[28,28]))\nann_model.add(Dense(200,activation='relu'))\nann_model.add(Dense(100,activation='relu'))\nann_model.add(Dense(10,activation='softmax'))","bdacd665":"## Visualizing neural network structure\nimport pydot\nfrom keras.utils.vis_utils import plot_model\n# Visualizing the neural network\nplot_model(ann_model,show_shapes=True, show_layer_names=True)","51f8d684":"# Summary of neural network\nann_model.summary()","b0c82fe6":"# Compile the model\nann_model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])","2f53c080":"# Training on GPU\nfrom time import time\nstart=time()\nann_history= ann_model.fit(X_train,y_train,epochs=40,batch_size=250,validation_data=(X_valid,y_valid))\nend=time()\nprint('Time taken for training NN on GPU(s):',np.round(end-start,3))","4b5bdc07":"# evaluating the ann model\n_,ann_train_accuracy = ann_model.evaluate(X_train,y_train, verbose=0)\n_,ann_valid_accuracy = ann_model.evaluate(X_valid, y_valid, verbose=0)\n\nprint('Training set accuracy: %.3f, Validation set accuracy: %.3f' % (ann_train_accuracy, ann_valid_accuracy))","f309675c":"# Predictions and classification report of test set\nann_y_pred = np.argmax(ann_model.predict(X_test), axis=-1)\n\nfrom sklearn.metrics import classification_report\nclass_names= ['T-shirt\/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\nprint('Classification report of test set')\nprint('-'*50)\nprint(classification_report(y_test,ann_y_pred,target_names=class_names))","20b7ee1b":"from keras.layers import Dropout\nfrom keras.layers import Conv2D,MaxPooling2D","3e83042d":"print('Original shape of train set:',X_train.shape)\nprint('Original shape of validation set:',X_valid.shape)\nprint('Original shape of test set:',X_test.shape)","b281ff9c":"# Reshape data to include channel\nX_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\nX_valid = X_valid.reshape((X_valid.shape[0], 28, 28, 1))\nX_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n\nprint('Shape of train set:',X_train.shape)\nprint('Shape of validation set:',X_valid.shape)\nprint('Shape of test set:',X_test.shape)","22850894":"cnn_model = Sequential()\ncnn_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',padding='same' ,input_shape=(28, 28, 1)))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',padding='same'))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(Flatten())\ncnn_model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\ncnn_model.add(Dense(10, activation='softmax'))","bd123992":"# Compile the model\ncnn_model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])","38dae4d4":"# Cnn model Summary\ncnn_model.summary()","02d791d4":"#Training on GPU\nstart=time()\ncnn_history= cnn_model.fit(X_train,y_train,epochs=40,batch_size=250,validation_data=(X_valid,y_valid))\nend= time()\nprint('Time taken for training CNN on GPU(s):',np.round(end-start,3))","0833d8a5":"# evaluating the CNN model\n_,cnn_train_accuracy = cnn_model.evaluate(X_train,y_train, verbose=0)\n_,cnn_valid_accuracy = cnn_model.evaluate(X_valid, y_valid, verbose=0)\n\nprint('Training set accuracy: %.3f, Validation set accuracy: %.3f' % (cnn_train_accuracy, cnn_valid_accuracy))","e2256a24":"cnn_y_pred = np.argmax(cnn_model.predict(X_test), axis=-1)\n\nfrom sklearn.metrics import classification_report\nclass_names= ['T-shirt\/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\nprint(classification_report(y_test,cnn_y_pred,target_names=class_names))","aad5eecf":"All labels are present in almost equal proportions.So its a balanced dataset.","b81f3bd4":"## Using CNN for classification","fe4c545e":"**I am an absolute beginner in Computer Vision.This is my first work on image classification where I have compared ANN and CNN performance on a very popular dataset,the Fashion MNIST dataset.The dataset contains 60000 train samples and 10000 test samples. I have further split the train set to generate a validation set so that test set is completely untouched and used only for final classification report. This will serve in determining the model's actual performance level.**\n\n**Dear Kaggle Community,please provide your valuable feedback and help me learn more.**","8882e322":"As training set and validation set accuracy are very close, we can rule out model overfitting.","beb0fb82":"**While ANN achieved accuracy of ~0.83 on test set, CNN achieved an accuracy of ~0.88 on same test set. So CNN does a better job at classifying images compared to ANN.**","7c14c297":"As train and validation accuracy are almost same, we can say that the model isn't overfitting on the training set.","699d1a7f":"## Using traditional ANN for classification"}}