{"cell_type":{"d6ce2303":"code","fd39da95":"code","7e25a252":"code","942b7e21":"code","0aeeb1e4":"code","2b1929c3":"code","26c311b6":"code","0a822e32":"code","9043828d":"code","50773391":"code","e99e7a5d":"code","9c257feb":"code","5889ac7e":"code","b2fdd1b7":"code","eeba05d2":"code","fbf82bcf":"code","b289219d":"code","6b543221":"code","25bc7bec":"code","bf8ae95e":"code","d31d0778":"code","8beac5ae":"code","06d41e3d":"code","5bace366":"code","e637524b":"code","c70d88d4":"code","763f6526":"code","f82955af":"code","0fb2c8a8":"code","02c9ee98":"code","10c52dd5":"code","9477889d":"code","e1f75f1b":"code","c9c0037e":"code","82d76d62":"code","1f5cc2c4":"code","aba60690":"code","5b871c94":"code","712de7bc":"code","fd676b32":"code","dce12c24":"code","c0b36b27":"code","55b75672":"code","55e156a0":"code","2866924b":"code","edc4b960":"code","78517c04":"code","f40318bf":"code","bbae09d4":"code","41205dba":"code","5238b2a9":"code","40f067d9":"code","f0933459":"code","1e2d3c0a":"code","07d9a426":"code","4e1bc64a":"code","a92dbee9":"code","251d90dd":"code","44e56c3d":"code","94ae8342":"code","3a047f6a":"code","5bafab03":"code","c22b85a0":"code","f0d3b694":"code","922a6975":"code","424e4a47":"code","b43912cd":"code","23cb9853":"code","46449c86":"code","6244a166":"code","352361bf":"code","067816c8":"code","03623790":"code","a3ac4ece":"code","ed4e22be":"code","d476af94":"code","3a95c2d9":"code","6986e10b":"code","66c63431":"code","a9cd9683":"code","bab4f12d":"code","b53b88d3":"code","51e5a084":"code","76afee43":"code","cc1924a8":"code","7db49908":"code","cdfe4567":"code","e0a1bf7a":"code","8ff43436":"code","167d3d99":"code","c5ff492c":"code","ab74218d":"code","648a0d9e":"code","48168516":"code","91d84c9f":"code","7a6147ea":"code","81d61995":"code","c71dd7e6":"code","4ab2951b":"code","88baa18b":"code","d89c8c80":"code","67d81141":"code","efc4cc99":"code","284d4942":"code","d506edf8":"code","d97c5008":"code","c0b367ae":"code","68a66f45":"code","28f7092c":"code","b685b15c":"code","7b8917a7":"code","72d98aee":"code","2eb67001":"code","a836a13b":"code","d36f465b":"code","d4db761f":"code","ac5f6e3e":"code","bdd1c411":"code","80a2769d":"code","cca60c7a":"code","876877ce":"code","5ce6970a":"code","ee0c120d":"code","15839b3d":"code","0372ee73":"code","3d38b196":"code","3778466e":"code","8d97a0f9":"code","239eff5a":"code","56236b81":"code","2e0d19f6":"code","9fb78fe4":"code","f929ed27":"code","7e6cc858":"code","3f8ad0ed":"code","6186ebeb":"code","4be1145c":"code","b4e036be":"code","c2d1d09c":"code","80f513c3":"code","547cb95b":"code","37303a8d":"code","f66e2106":"code","1f98ad55":"code","def8ccc4":"code","08f2da08":"code","c27e1a0a":"code","94560b47":"code","08543aa8":"code","dad8a98b":"code","aae368c5":"code","64127340":"code","81718e5c":"code","69e4bbec":"code","a15385a4":"code","a4769236":"code","58a2203d":"code","bfaed035":"code","7ab13e75":"code","87049492":"code","209ea8aa":"code","e4c319e5":"code","38245279":"code","65a5c74a":"code","eaacfa0b":"code","7391c1e2":"code","1ab7bb6d":"code","16aaea75":"code","bea05c45":"code","9b0e0b49":"code","792d67e1":"code","7f296481":"code","a8bbb792":"code","7e2708be":"code","ec65b570":"code","65cd4188":"code","eedf97d9":"code","d5cb240f":"code","c03c7f41":"code","a1eeedfa":"code","f74981a2":"markdown","22b944c8":"markdown","3e2c7c3e":"markdown","78ad75b2":"markdown","e9671afe":"markdown","7a8af8bb":"markdown","60a54e73":"markdown","ef69e6d4":"markdown","b2fef640":"markdown","d7ab4511":"markdown","048863b8":"markdown","9e98008a":"markdown","9f54a7cf":"markdown","c292adb9":"markdown","06d54810":"markdown","ed3cf3f1":"markdown","f3afd511":"markdown","9639491c":"markdown","393599c6":"markdown","789a2aca":"markdown","4d248184":"markdown","2e7fc7ee":"markdown","2d306830":"markdown","6c54cdcf":"markdown","d12b7868":"markdown","45445eec":"markdown","98bc8828":"markdown","6980b421":"markdown","a2f41c48":"markdown","0549271c":"markdown","42931f22":"markdown","65d6cd27":"markdown","7d79c451":"markdown","4b25aaa0":"markdown","c3cf1f64":"markdown","178f82ad":"markdown","c05e5d4a":"markdown","e47c22d5":"markdown","f42b4918":"markdown","54d57407":"markdown","bed9e0a1":"markdown","63f5a4c2":"markdown","11cc9488":"markdown","2940205c":"markdown","efdd3151":"markdown","cb76e40e":"markdown","f58133e7":"markdown","06df8893":"markdown","1490cf63":"markdown","fba5e470":"markdown"},"source":{"d6ce2303":"import pandas as pd\nfrom pandas.tseries.offsets import Hour, Minute, Second # ...\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n\nimport itertools as it\nimport pytz\nimport numpy as np\nimport folium\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom folium.plugins import HeatMap, HeatMapWithTime, MarkerCluster\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.manifold import LocallyLinearEmbedding\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import SpectralClustering #kernel\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import FeatureAgglomeration\nfrom sklearn.cluster import AffinityPropagation\n\nfrom yellowbrick.cluster import KElbowVisualizer\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n%matplotlib inline","fd39da95":"train = pd.read_csv('..\/input\/sf-crime\/train.csv.zip')\ntest = pd.read_csv('..\/input\/sf-crime\/test.csv.zip')","7e25a252":"train.shape, test.shape","942b7e21":"train.head(3).style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","0aeeb1e4":"train.describe().style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","2b1929c3":"train.info()","26c311b6":"train.isnull().sum()","0a822e32":"test.head(3).style.background_gradient(cmap='rocket', text_color_threshold=0.02)","9043828d":"test.describe().style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","50773391":"test.info()","e99e7a5d":"test.isnull().sum()","9c257feb":"train.head(3).style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","5889ac7e":"train['PdDistrict'].unique()","b2fdd1b7":"train['Resolution'].unique()","eeba05d2":"train['Category'].unique() # target","fbf82bcf":"train['DayOfWeek'].unique()","b289219d":"train['Address'].unique(), len(train['Address'].unique())","6b543221":"len(train['Descript'].unique())","25bc7bec":"train.iloc[1]","bf8ae95e":"def visualization_crime(value, tight=False):\n    with plt.style.context('fivethirtyeight'):\n        fig, ax = plt.subplots(1, 1, figsize=(19, 6))\n        sns.histplot(x=value, data=train, kde=True, palette='rocket', ax=ax)\n        ax.tick_params(axis='x', rotation=90)\n        if tight == True:\n            fig.tight_layout()","d31d0778":"visualization_crime('Category', tight=False)","8beac5ae":"visualization_crime('DayOfWeek')","06d41e3d":"visualization_crime('PdDistrict')","5bace366":"visualization_crime('Resolution')","e637524b":"visualization_crime('X')","c70d88d4":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n    sns.scatterplot(data=train.iloc[:250000], x='X', y='Y', alpha=0.6, palette='rocket', hue='Category', size='Category') # 878049 \n    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')","763f6526":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n    sns.scatterplot(data=train.iloc[:50000], x='X', y='Y', alpha=0.6, palette='flare', hue='DayOfWeek',\n                    size='DayOfWeek', sizes=(20, 200), markers=True) # 878049 ","f82955af":"def query_heat_map(query, location=[37.774599, -122.425892]):\n    train_query = train.query(query).loc[:, ['Y', 'X']]\n    if train_query.shape[0] == 0:\n        print('Either the query is failing or there is no data itself.')\n    m = folium.Map(location=location, zoom_start=13, tiles='CartoDB dark_matter') # HeatmapPlot-tiles : cartodbdark_matter\n    train_query_geo_list = train_query.values.tolist()\n    HeatMap(train_query_geo_list, blur=2, radius=3).add_to(m)\n    #m.save('SanFrancisco-Crime-geo.html') # add \n    return m","0fb2c8a8":"query_heat_map(\"Category=='ASSAULT' & Resolution=='ARREST, BOOKED'\")","02c9ee98":"train_timestamp = pd.read_csv('..\/input\/sf-crime\/train.csv.zip', parse_dates=True, index_col='Dates')","10c52dd5":"train_timestamp.loc['2015-05-13'].head(2)","9477889d":"train_timestamp.index","e1f75f1b":"train_timestamp.loc['2015'].mean()","c9c0037e":"train_timestamp.loc['2015'].count()","82d76d62":"train_timestamp.loc['2013'].count()","1f5cc2c4":"mc = train_timestamp.groupby(level=0)","aba60690":"mc.count().head(3)","5b871c94":"train_plot = pd.read_csv('..\/input\/sf-crime\/train.csv.zip', parse_dates=True)","712de7bc":"frequency_c = pd.DataFrame(train_plot['Category'].value_counts(normalize=True))\nfrequency_c.reset_index(inplace=True)\nfrequency_c.rename({'index': 'Category', 'Category': 'Freq'}, axis=1, inplace=True)\nfrequency_c['Cumsum_Freq'] = frequency_c['Freq'].cumsum()","fd676b32":"frequency_c = frequency_c.set_index('Category')","dce12c24":"freq_quantiles = np.percentile(frequency_c['Cumsum_Freq'], [25, 50, 75]) # array([0.84974358, 0.96996523, 0.99674847])","c0b36b27":"qt = freq_quantiles[1] # 0.9699652297309147","55b75672":"sigma = 0.74 * (freq_quantiles[2] - freq_quantiles[0]) # 0.10878362141520569","55e156a0":"query_freq = frequency_c.query(\"(Cumsum_Freq > @qt - 5 * @sigma) & (Cumsum_Freq < @qt + 5 * @sigma)\") # Cumsum_Freq is Data_Columns","2866924b":"query_freq.reset_index(inplace=True)","edc4b960":"query_freq_list = list(query_freq['Category'])","78517c04":"query_freq_list","f40318bf":"train_sigma = train.loc[train['Category'].isin(query_freq_list)]","bbae09d4":"train_sigma.head()","41205dba":"train_sigma['Dates'] = pd.to_datetime(train_sigma['Dates']) # Not Copy is SettingCopyWarning","5238b2a9":"test['Dates'] = pd.to_datetime(test['Dates'])","40f067d9":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n    sns.countplot(y='Category', data=train_sigma, order=train_sigma['Category'].value_counts().index,  palette='rocket')\n    ax.tick_params(axis='x', rotation=45)\n    #ax.set_xticklabels(ax.get_xticklabels(), rotation=60, ha=\"right\")","f0933459":"cross_tab_train = pd.crosstab(train_sigma['Category'], train_sigma['PdDistrict'])","1e2d3c0a":"cross_tab_train.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","07d9a426":"stack_sigma_list = cross_tab_train.stack().reset_index().rename(columns= {0:'value'})","4e1bc64a":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize= (15,10))\n    sns.barplot(x=stack_sigma_list['PdDistrict'], y=stack_sigma_list['value'], hue=stack_sigma_list['Category'],  palette='rocket')\n    ax.set_title('Categories Count per District')\n    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')","a92dbee9":"frequency_c = pd.DataFrame(train_plot['Category'].value_counts(normalize=True))\nfrequency_c.reset_index(inplace=True)\nfrequency_c.rename({'index': 'Category', 'Category': 'Freq'}, axis=1, inplace=True)\nfrequency_c['Cumsum_Freq'] = frequency_c['Freq'].cumsum()\nfrequency_50_list = list(frequency_c.loc[frequency_c['Cumsum_Freq'] < 0.8, 'Category'])","251d90dd":"train_50_list = train.loc[train['Category'].isin(frequency_50_list)]","44e56c3d":"train_50_list['Dates'] = pd.to_datetime(train_50_list['Dates'])","94ae8342":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n    sns.countplot(y='Category', data=train_50_list, order=train_50_list['Category'].value_counts().index,  palette='rocket')\n    ax.tick_params(axis='x', rotation=45)","3a047f6a":"ct_50_list = pd.crosstab(train_50_list['Category'], train_50_list['PdDistrict'])\nct_50_list.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","5bafab03":"stack_50_list = ct_50_list.stack().reset_index().rename(columns= {0:'value'})","c22b85a0":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize= (15,10))\n    sns.barplot(x=stack_50_list['PdDistrict'], y=stack_50_list['value'], hue=stack_50_list['Category'], palette='rocket')\n    ax.set_title('Categories Count per District')","f0d3b694":"train_sigma.shape, train_50_list.shape","922a6975":"def time_group(date):\n    \n    date['Date'] = date['Dates'].dt.date\n    date['Year'] = date['Dates'].dt.year\n    date['Month'] = date['Dates'].dt.month\n    date[\"Day\"] = date[\"Dates\"].dt.day\n    date[\"Hour\"] = date[\"Dates\"].dt.hour\n    date[\"Minute\"] = date[\"Dates\"].dt.minute\n    date[\"Second\"] = date[\"Dates\"].dt.second\n    \n    ca = calendar()\n    holidays = ca.holidays(start=date['Dates'].min(), end=date['Dates'].max())\n    date['Holiday']= date['Dates'].dt.date.astype('datetime64').isin(holidays)\n    # Week_replace\n    week_mapping = {'Saturday': 5, 'Sunday': 6, 'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4}\n    date['Week_Mapping'] = date['DayOfWeek'].map(week_mapping)\n    \n    # https:\/\/www.jma.go.jp\/jma\/kishou\/know\/yougo_hp\/saibun.html Ministry of Land, Infrastructure, Transport and Tourism: Japan Meteorological Agency [Definition classification]. time scale\n    def hour_Segmentation(x):\n        if x >= 3 and x < 9:\n            return 0\n        elif x >= 9 and x < 15:\n            return 1\n        else:\n            return 2\n        \n    def morning_Or_Afternoon(x): # np.where\n        if x >= 0 and x > 12:\n            return 0\n        else:\n            return 1\n        \n    def daytime_Or_Nighttime(x): # np.where\n        if x >= 9 and x > 18:\n            return 0\n        else:\n            return 1\n    \n    def default_Work_Time_Hours(x): # np.where\n        return 8 <= x <= 18\n    \n    def weekday_and_ends(x):\n        return np.where(x < 5, 'Weekday', 'Weekend')\n    \n    # Q1:1 , Q2:2, Q3:3, Q4:4\n    def quarter(x):\n        if x >= 1 and x <= 3:\n            return 1\n        elif x > 3 and x <= 6:\n            return 2\n        elif x > 6 and x <= 9:\n            return 3\n        elif x > 9 and x <= 12:\n            return 4\n    \n    # T1:1, T2:2, T3:3\n    def month_sep(x):\n        if x >= 1 and x < 10:\n            return 1\n        elif x >= 10 and x < 20:\n            return 2\n        elif x >= 20 and x <= 31:\n            return 3\n    \n    def street_type(x):\n        street_list = x.split(' ')\n        for index in range(len(street_list)):\n            fo_list = street_list[index]\n            if len(fo_list) == 2 and fo_list not in ['OF', 'US', 'LA', 'of']:\n                return fo_list\n        \n    date['Street_type'] = date['Address'].apply(street_type)\n   \n    date['HourGroup'] = date[\"Hour\"].apply(hour_Segmentation)\n    date['MAGroup'] = date['Hour'].apply(morning_Or_Afternoon)\n    date['DNGroup'] = date['Hour'].apply(daytime_Or_Nighttime)\n    date['DworkGroup'] = date['Hour'].apply(default_Work_Time_Hours)\n    date['Week_cat'] = date['Week_Mapping'].apply(weekday_and_ends)\n    date['Month_quarter'] = date['Month'].apply(quarter)\n    date['Month_sep'] = date['Day'].apply(month_sep)\n    \n    return date","424e4a47":"train_sigma_1 = train_sigma.copy()","b43912cd":"train_50_list_1 = train_sigma.copy()","23cb9853":"train_group = time_group(train_sigma_1) # Main_train_group","46449c86":"test_group = time_group(test) # Main_Test","6244a166":"train_group.shape, test_group.shape","352361bf":"train_group_1 = time_group(train_50_list_1)","067816c8":"year_data = pd.DataFrame(train_group.groupby('Year')['Category'].count())\nyear_data_1 = pd.DataFrame(train_group_1.groupby('Year')['Category'].count())","03623790":"year_data.reset_index(inplace=True)","a3ac4ece":"year_data.T.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","ed4e22be":"year_data.drop(12, axis=0, inplace=True)","d476af94":"year_data.T.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","3a95c2d9":"hour_vs_cate = train_group.groupby(['Category', 'HourGroup'], as_index=False).count()","6986e10b":"hour_vs_cate.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","66c63431":"hour_vs_cate_pv = hour_vs_cate.pivot(index='HourGroup', columns='Category', values='Dates') #.fillna(0)","a9cd9683":"hour_vs_cate_pv.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","bab4f12d":"fig, ax = plt.subplots(figsize=(50, 5)) \nsns.heatmap(hour_vs_cate_pv.apply(lambda x:x\/sum(x),axis=0), square=True, annot=True)","b53b88d3":"with plt.style.context('fivethirtyeight'):\n    de_time = train_group.groupby([train_group.Week_cat, train_group.Hour])['Category'].count()\n    de_time.plot(figsize=(19, 6))","51e5a084":"with plt.style.context('fivethirtyeight'):\n    de_time = train_group.groupby([train_group.Week_cat, train_group.Hour])['Category'].count()\n    de_time.loc['Weekday'].plot(figsize=(19, 6), label='Week_Day')\n    de_time.loc['Weekend'].plot(figsize=(19, 6), label='Week_End')\n    plt.title('Week, Day or End Crimes')\n    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')","76afee43":"with plt.style.context('fivethirtyeight'):\n    pt = pd.pivot_table(train_group.loc[:, ['Hour', 'Category']], index=\"Hour\", columns=\"Category\", aggfunc=len, fill_value=0)\n    pt.plot(figsize=(30,10))\n    plt.title('Hour Crimes')\n    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n    #plt.tight_layout()","cc1924a8":"with plt.style.context('fivethirtyeight'):\n    pt = pd.pivot_table(train_group.loc[:, ['Year', 'Category']], index='Year', columns='Category', aggfunc=len, fill_value=0)\n    pt.plot(figsize=(30,10))\n    #plt.gca().set_xticklabels(['2010', '2011', '2012', '2013', '2014', '2015'])\n    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')","7db49908":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(figsize=(30, 10))\n    ax = sns.lineplot(x=year_data['Year'], y=year_data['Category'])\n    ax.set_title('Year Crimes')","cdfe4567":"with plt.style.context('fivethirtyeight'):\n    pt = pd.pivot_table(train_group.loc[:, ['Month', 'Category']], index='Month', columns='Category', aggfunc=len, fill_value=0)\n    pt.plot(figsize=(30,10))\n    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')","e0a1bf7a":"test_1 = train_group.loc[:, ['Year', 'Category']].reset_index().merge(train_group.loc[:, ['Y', 'X']].reset_index(), on=['index']).set_index('Year')","8ff43436":"test_g = train_group.groupby([\"Category\", \"Year\"]).count()","167d3d99":"test_g.unstack()['Dates'].style.background_gradient(cmap='mako_r', text_color_threshold=0.02)","c5ff492c":"time_series = list(np.sort(train_group['Year']))","ab74218d":"train_query_move = train_group.query(\"Category=='ASSAULT'\").loc[:, ['Y', 'X', 'Year']]","648a0d9e":"train_query_move = train_query_move.set_index('Year', drop=False)","48168516":"test_11 = np.sort(train_query_move.index.unique())","91d84c9f":"train_move_list = [train_query_move.loc[i].values.tolist() for i in np.sort(train_query_move.index.unique())]","7a6147ea":"train_query = train.query(\"Category=='ASSAULT' & Resolution=='ARREST, BOOKED'\").loc[: ,['Y','X']]","81d61995":"train_query_geo_list = train_query.values.tolist() # default feat map array","c71dd7e6":"index_time = np.sort(train_query_move.index.unique()).tolist()","4ab2951b":"# It is more efficient to use the dict type for the basic list of locations that you have created, although you don't know if you will use it.\n'''\ndown_town = [[37.77493, -122.419416]]\nunion_square = [[37.786163522, -122.404498382]]\nfishermans_wharf = [[37.80499678, -122.409331696]]\nchina_town = [[37.790163506, -122.404331716]]\nsoma = [[37.777311, -122.411083]]\noak_street = [[37.77412, -122.431384]]\ntwin_peaks = [[37.751586275, -122.447721511]]\nsoutheast = [[37.7369444, -122.3941667]]\nbernal_heights = [[37.744385, -122.417046]]\nmission_district = [[37.76, -122.42]]\nnoe_valley = [[37.7502, -122.4337]]\nhaight_ashbury = [[37.770015, -122.446937]]\npresidio = [[37.798085, -122.466538]]\n'''\n\nsanfrancisco_location = {'down_town': [[37.77493, -122.419416]], 'union_square': [[37.786163522, -122.404498382]],\n                         'fishermans_wharf': [[37.80499678, -122.409331696]], 'china_town': [[37.790163506, -122.404331716]],\n                         'soma': [[37.777311, -122.411083]], 'oak_street': [[37.77412, -122.431384]],\n                         'twin_peaks': [[37.751586275, -122.447721511]], 'southeast': [[37.7369444, -122.3941667]],\n                         'bernal_heights': [[37.744385, -122.417046]], 'mission_district': [[37.76, -122.42]],\n                         'noe_valley': [[37.7502, -122.4337]], 'height_ashbury': [[37.770015, -122.446937]], 'presidio': [[37.798085, -122.466538]]}","88baa18b":"def geo_polygon(lat_lon):\n    '''Find geographic quarter(NW, NE, SW, SE) based on lat_lon'''\n    sw, nw, se, ne = [(lat + py * pow(10, -3), lon + px * pow(10, -3)) for px, py in it.product([-1, 1], [-1, 1]) for lat, lon in lat_lon]\n    return [sw, se, ne, nw]","d89c8c80":"def location_point(location):\n    '''Function to display LocationPoint in bulk: variable by dictionary'''\n    for location_name, lat_lon in location.items():\n        lat_lon_locate = geo_polygon(lat_lon)\n        folium.Polygon(locations=lat_lon_locate, color=\"red\", weight=1, fill=True, fill_opacity=0.1, popup=location_name).add_to(m)\n\ndef location_point_1(location):\n    for location_name, lat_lon in location.items():\n        lat_lon_locate = geo_polygon(lat_lon)\n        folium.Polygon(locations=lat_lon_locate, color=\"red\", weight=1, fill=True, fill_opacity=0.1, popup=location_name).add_to(m_1)","67d81141":"m = folium.Map(location=[37.774599, -122.425892], zoom_start=13, tiles='CartoDB dark_matter')","efc4cc99":"location_point(sanfrancisco_location)","284d4942":"#HeatMapWithTime(train_query_geo_list,auto_play=False,radius=40,max_opacity=1,gradient={0.1: 'blue', 0.25: 'lime', 0.5:'yellow',0.75: 'red'}).add_to(m)\nHeatMapWithTime(train_move_list, index=index_time, auto_play=False, radius=1 , max_opacity=1, gradient={0.1: 'blue', 0.25: 'lime', 0.5:'yellow',0.75: 'red'}).add_to(m)","d506edf8":"m","d97c5008":"m_1 = folium.Map(location=[37.774599, -122.425892], zoom_start=13, tiles='CartoDB dark_matter')","c0b367ae":"marker_cluster = MarkerCluster().add_to(m_1)","68a66f45":"location_point_1(sanfrancisco_location)","28f7092c":"for point in range(0, len(train_query_geo_list)):\n    folium.Marker(train_query_geo_list[point], popup='A').add_to(marker_cluster)","b685b15c":"m_1","7b8917a7":"sorted_map = {'Saturday': 0, 'Sunday': 1, 'Monday': 2, 'Tuesday': 3, 'Wednesday': 4, 'Thursday': 5, 'Friday': 6}","72d98aee":"def dayOfWeek_plot(data, string='ASSAULT'):\n    with plt.style.context('fivethirtyeight'):\n        week_data = pd.DataFrame(data[data['Category'] == string].groupby(by=['DayOfWeek'])['Category'].count()).reset_index()\n        week_data['SortedDayOfWeek'] = week_data['DayOfWeek'].map(sorted_map)\n        week_data = week_data.sort_values('SortedDayOfWeek').drop('SortedDayOfWeek', axis=1)\n\n        fig, ax = plt.subplots(1, 1, figsize = (19, 6))\n        ax = sns.lineplot(x=week_data['DayOfWeek'], y=week_data['Category'])\n        ax.set_title('{} Crimes. Week'.format(string))","2eb67001":"dayOfWeek_plot(train_group, 'ASSAULT')","a836a13b":"list(train_group['Category'].unique()); # test code","d36f465b":"# add def dayOfWeel_plot\nfor string in list(train_group['Category'].unique()):\n    dayOfWeek_plot(train_group, string)","d4db761f":"ct_holiday_cat = pd.crosstab(train_group['Category'], train_group['Holiday'])\nct_holiday_cat.T","ac5f6e3e":"stacked = ct_holiday_cat.stack().reset_index().rename(columns={0:'value'})","bdd1c411":"stacked.loc[stacked['Holiday'] == False, 'value'] \/= train_group.loc[train_group['Holiday'] == False, 'Holiday'].count()\nstacked.loc[stacked['Holiday'] == True, 'value'] \/= train_group.loc[train_group['Holiday'] == True, 'Holiday'].count()","80a2769d":"stacked.T","cca60c7a":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize = (19, 6))\n    bar = sns.barplot(x=stacked['Category'], y=stacked['value'], hue=stacked['Holiday'], palette=['#682F2F', '#F3AB60'])\n    bar.set_title('Proportions of crimes during regular days vs holidays')\n    ax.tick_params(axis='x', rotation=90)","876877ce":"ct_business_hrs_cat = pd.crosstab(train_group['Category'], train_group['DworkGroup'])\nct_business_hrs_cat.T","5ce6970a":"stacked = ct_business_hrs_cat.stack().reset_index().rename(columns={0:'value'})\nstacked.loc[stacked['DworkGroup'] == False, 'value'] \/= train_group.loc[train_group['DworkGroup'] == False, 'DworkGroup'].count()\nstacked.loc[stacked['DworkGroup'] == True, 'value'] \/= train_group.loc[train_group['DworkGroup'] == True, 'DworkGroup'].count()\nstacked.T","ee0c120d":"with plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 1, figsize = (19, 6))\n    bar = sns.barplot(x=stacked['Category'], y=stacked['value'], hue=stacked['DworkGroup'], palette=['#682F2F', '#F3AB60'])\n    bar.set_title('Proportions of crimes during regular days vs holidays')\n    ax.tick_params(axis='x', rotation=90)","15839b3d":"train_group.head(2)","0372ee73":"train_group_2 = train_group.copy()","3d38b196":"train_group_2.set_index('Dates', inplace=True)","3778466e":"train_group_2.loc['2014'].head(2)","8d97a0f9":"freq_d = pd.to_datetime(train_group_2.index)","239eff5a":"train_group_freq_d = pd.DataFrame(train_group_2, index=freq_d)","56236b81":"train_group_2.to_period('Q-DEC').head(2)","2e0d19f6":"train_group.head(2)","9fb78fe4":"test_group.head(2)","f929ed27":"train_group.drop(['Dates', 'Descript', 'Resolution', 'Address', 'Date', 'Street_type'], axis=1, inplace=True) # Street_type","7e6cc858":"test_group.drop(['Id','Dates', 'Address', 'Date', 'Street_type'], axis=1, inplace=True) # Street_type","3f8ad0ed":"X = train_group.drop('Category', axis=1)\ny = train_group['Category']","6186ebeb":"data_labels = y.to_numpy()","4be1145c":"data_num = X.drop(['DayOfWeek', 'PdDistrict', 'Week_cat', 'DworkGroup','Holiday'], axis=1) # 'Street_type'","b4e036be":"number_attribs = list(data_num)","c2d1d09c":"category_attribs = ['DayOfWeek', 'PdDistrict', 'Week_cat', 'Holiday','DworkGroup'] # 'Street_type'","80f513c3":"number_pipeline = Pipeline([\n    ('std_scaler', StandardScaler()),\n])\n\nmain_pipeline = ColumnTransformer([\n    (\"number\", number_pipeline, number_attribs),\n    (\"categorie\", OneHotEncoder(), category_attribs),\n])","547cb95b":"X.columns","37303a8d":"test_group.columns","f66e2106":"X.info()","1f98ad55":"X.isnull().sum()","def8ccc4":"main_x = main_pipeline.fit_transform(X)","08f2da08":"main_test = main_pipeline.transform(test_group)","c27e1a0a":"X_train, X_val, y_train, y_val = train_test_split(main_x, data_labels, test_size=0.25, stratify=data_labels, shuffle=True)","94560b47":"X_train.shape, X_val.shape, y_train.shape, y_val.shape","08543aa8":"model = KMeans(init='k-means++', n_init=10)\nvisualizer = KElbowVisualizer(model, k=(1, 20))","dad8a98b":"visualize = visualizer.fit(main_x)","aae368c5":"visualizer.show();","64127340":"main_cluster_data = KMeans(n_clusters=visualizer.elbow_value_).fit_predict(main_x) # 6 or 5","81718e5c":"main_cluster_test = KMeans(n_clusters=visualizer.elbow_value_).fit_predict(main_test)","69e4bbec":"X_cluster = X.copy()","a15385a4":"test_cluster = test_group.copy()","a4769236":"X_cluster['Cluster'] = main_cluster_data","58a2203d":"test_cluster['Cluster'] = main_cluster_test","bfaed035":"#from sklearn.model_selection import StratifiedKFold\n#kfold =StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\u3000","7ab13e75":"X_cluster.shape, X_cluster[:100000].shape","87049492":"X_cluster.sample(10000);","209ea8aa":"#X_cluster_test = X_cluster.drop('Street_type', axis=1)","e4c319e5":"#test_cluster_test = test_cluster.drop('Street_type', axis=1)","38245279":"data_num = X.drop(['DayOfWeek', 'PdDistrict', 'DworkGroup', 'Week_cat', 'Holiday'], axis=1) # 'Street_type'\nnumber_attribs = list(data_num)\ncategory_attribs = ['DayOfWeek', 'PdDistrict', 'DworkGroup', 'Week_cat', 'Holiday']\n\nnumber_pipeline = Pipeline([\n    ('std_scaler', StandardScaler()),\n])\n\nmain_pipeline = ColumnTransformer([\n    (\"number\", number_pipeline, number_attribs),\n    (\"categorie\", OneHotEncoder(), category_attribs),\n])","65a5c74a":"main_x_1 = main_pipeline.fit_transform(X_cluster.sample(50000)) # X_cluster_test","eaacfa0b":"main_test_1 = main_pipeline.transform(test_cluster) # test_cluster_test","7391c1e2":"X_train, X_val, y_train, y_val = train_test_split(main_x_1, data_labels[:50000], test_size=0.25, shuffle=True) # stratify=data_labels","1ab7bb6d":"X_train.shape, X_val.shape, y_train.shape, y_val.shape","16aaea75":"xgb_model = XGBClassifier(use_label_encoder=True, metric='mlogloss')","bea05c45":"%timeit xgb_model.fit(X_train, y_train)","9b0e0b49":"y_pred_xgb = xgb_model.predict(X_val)","792d67e1":"print('Precision : {} \/ Recall : {}'.format(precision_score(y_val, y_pred_xgb, average='micro'), recall_score(y_val, y_pred_xgb, average='micro')))\nprint(classification_report(y_val, y_pred_xgb))","7f296481":"disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_val, y_pred_xgb))\nfig, ax = plt.subplots(1, 1, figsize=(19, 19))\ndisp.plot(ax=ax);","a8bbb792":"#gb_model = GradientBoostingClassifier()","7e2708be":"#gb_model.get_params().keys()","ec65b570":"#gb_param_grid = {'learning_rate':[0.1, 0.01, 0.001], 'max_depth':[5, 10], 'n_estimators':[10, 100, 200, 300]}","65cd4188":"#UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10. : stratify=data_labels\n#gb_s_model = GridSearchCV(gb_model, gb_param_grid, cv=10, scoring='accuracy')\n#gb_s_model.fit(X_train, y_train)","eedf97d9":"gb_model = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=5)\n%timeit gb_model.fit(X_train, y_train)","d5cb240f":"y_pred_gb = gb_model.predict(X_val)","c03c7f41":"print('Precision : {} \/ Recall : {}'.format(precision_score(y_val, y_pred_gb, average='micro'), recall_score(y_val, y_pred_gb, average='micro')))\nprint(classification_report(y_val, y_pred_gb))","a1eeedfa":"disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_val, y_pred_gb))\nfig, ax = plt.subplots(1, 1, figsize=(19, 19))\ndisp.plot(ax=ax);","f74981a2":"**DayOfWeek Visualization**","22b944c8":"--------\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;\">Second EDA<\/h1>\n\n* Using the knowledge obtained in the above and the results of data processing, perform a more detailed EDA, obtain knowledge, and make it one of the EDA materials for presentation to a third party.\n* The explanation details of each visualization are omitted to some extent.","3e2c7c3e":"<p style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:150%;text-align:center;border-radius:10px 10px;\">unique<\/p>","78ad75b2":"## GradientBoostingClassifier","e9671afe":"-----\n- The following is not inherently necessary. This is a syntax to make the model run smoothly, not an inherent best practice. It is a worst-case scenario when used for anything other than running the model.\n- Because Street is categorized, you may be told that you don't have enough categories unless you have the full sample of X_cluster, but this is not a best practice and you can run it a few times to get them all included.\n- In the following, Street is removed.","7a8af8bb":"- Holiday\u3000Plot","60a54e73":"-----\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;\">Folium [2]<\/h1>\n\n* Perform dynamic visualization with Folium.","ef69e6d4":"- Functionalization\n- The pandas query is used to speed up the process (actually, Numexpr) and to display the heatmap of the data according to multiple conditions.\n    - The query shows that the ASSAULT data is concentrated around downtown and Chinatown. The reason why there are so many ASSAULTs in the Bay Area is because they tend to gather in groups.\n    - The following EDA makes it clear that the probability of Crime increases when a group of people get together.","b2fef640":"------\n<h1 style= \"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>Clustering<\/b><\/h1>","d7ab4511":"- Which incidents are most frequently dealt with by each police station?\n    - This can be made clearer by showing the police stations as location points on the map.","048863b8":"**Category Visualization**","9e98008a":"**Resolution Visualization**","9f54a7cf":"----\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;\"><b>Folium [1]<\/b><\/h1>\n\n> In 2, annual data transition and animation display by clustering are implemented in Folium.","c292adb9":"- Data subdivided by DayOfWeek. It is a little difficult to see because of the large number of data, but it has a left-leaning shape over the weekend.\n- All these problems can be solved with folium. This is just a pre-implementation test display.","06d54810":"-----------\n-----------","ed3cf3f1":"<p style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:200%;text-align:center;border-radius:10px 10px;\">Trainset<\/p>","f3afd511":"-------\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:200%;text-align:center;border-radius:10px 10px;\">Latitude and longitude scatter chart<\/h1>\n\n- Since the latitude and longitude information exists, it is visualized as a scatter plot.\n    - In this way, the shape of the scatter plot displays the shape of the city. This will become visually clearer as the number of data increases.\n    - What we can see here is that the Latitude and Longitude of the data clearly show the coordinates and are accurate. Using Latitude and Longitude without visualization is dangerous in my experience.\n    - The following scatter plot shows the location of the crimes. The following scatterplot is based on 250,000\/ALL, to make it clear whether the data is actual latitude and longitude.\n        - It is also possible to specify conditions to display only specific crimes. See Folium below for details.","9639491c":"------","393599c6":"----\n**Visualize what time of the week each Crime is happening.**\n- This will give you a clearer idea of the nature of the case and the background of the case as knowledge.","789a2aca":"<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>First EDA<\/b><\/h1>\n\n* Get a bird's eye view of the data, checking the internal status of the csv (columns,null,mean,std)\n* Here's what you can easily see\n    1. there are timestamps and they are also categorized.\n    2. the day of the week is categorized against the timestamp. \n    3. The timestamp is the date of the crime, so the location is categorized. \n    4. For locations, we can assume that X and Y are latitudes and longitudes. (This is described in the dataset description without guessing, but it is also important to guess what this is. However, it is also important to guess what this is, because you may discover new FEs in the process of guessing). \n    5. If X and Y are not easy to understand as Columns, rename them to Longitude and Latitude. (Lon and Lat are also acceptable).\n        - Depending on the library, the position to pass the latitude and longitude may be reversed, so check the library.\n* Visualization that may be possible\n    1. normal visualization (Visualization) plot\n    2. visualization of a map, which can be used to visualize in which districts crime occurs most often\n    3. different data from SanFrancisco (stores, residential blocks, residential blocks house prices, residential or non-residential by race) can be used to get different views on why crime is high in a given area. \n    4. crime rate and GDP, higher education rate, number of single households in the past, time-stamped increase\/decrease of crime rate in industrial development, growth of price index in San Francisco as a whole, time-stamped urban development, increase\/decrease of residents in San Francisco, etc. This will provide a variety of insights. This could also serve as a base cohort for other states that may themselves be relevant, as it would elucidate the underlying phenomenon that explains why crime increases and decreases (in which case, I would guess that industrial development should be excluded, as it varies by state).\n* Possible transformations\n    1. hierarchical categorization\n    2. create cluster transformation, hierarchical clusters\n    3. If distribution does not follow a normal distribution, use Box-Cox transformation to convert to normal distribution. \n    4. Gaussian mixture clustering analysis using (transformed or untransformed) normal distribution.\n    5. visualize clustering by dimensionality reduction while maintaining variance using PCA.\n* Visualization is used only for gaining knowledge, and methodological interpretations, such as improving the accuracy of FeatureEnginiering by gaining knowledge, are performed through visualization.","4d248184":"----------\n**TimeStamp Conversion**\n- It is also important to infer the data by switching the time series data to the display of business days, quarters, etc., but this is only a conversion and will be omitted.","2e7fc7ee":"--------\n# Other Models Creating","2d306830":"-----\n<p style= \"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>Default Transform<\/b><\/p>\n\n- The original Pipeline Transform.\n- Due to the training time of the model, this is not used in this notebook.\n- Clustering is not included in the transformation.","6c54cdcf":"--------\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;\"><b>Visualization<\/b><\/h1>\n\n* 1. visualization of Category against DayOfWeek, which week has the highest crime rate. 2.\n\n* 2. Histgram of Category\n\n* 3. Histgram of PdDistrict, i.e. which station has the highest number of correspondences.\n\n* 4. increase\/decrease in crime rate against time stamp, visibility of seasonality.\n\n* 5. yearly rate of increase\/decrease in crime for the timestamp and knowledge of socio-dynamic economic dynamics such as human flow, GDP, etc. showing the relationship between the two.","d12b7868":"# XGBC","45445eec":"<p style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:150%;text-align:center;border-radius:10px 10px;\">Overview<\/p>\n\n<p style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:150%;text-align:center;border-radius:10px 10px;\">Data Fields<\/p>\n\n- Data fields\n- Dates - timestamp of the crime incident\n- Category - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\n- Descript - detailed description of the crime incident (only in train.csv)\n- DayOfWeek - the day of the week\n- PdDistrict - name of the Police Department District\n- Resolution - how the crime incident was resolved (only in train.csv)\n- Address - the approximate street address of the crime incident \n- X - Longitude\n- Y - Latitude","98bc8828":"**Which Crime is the most common?**","6980b421":"---------\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;\">Pre-Processing & Feature Enginiering<\/h1>\n\n- Data transformation and feature engineering are performed using the knowledge obtained in the above.\n- For date and time conversion, we refer to the time division table specified by the Ministry of Land, Infrastructure, Transport and Tourism.\n- Features that correspond to the \"Explanation\" will be deleted in subsequent Pipelines. This is because the conversion is very difficult (e.g., using NLP) and because this feature does not exist in the test set, so adding explanations to the test set is not likely to be a best practice. However, if you want to make accurate predictions, removing it completely is a bad idea.","a2f41c48":"----\n- base 0.8","0549271c":"# Thanks for reading all the way through.\n# Please give me an UPVOTE if you can. Your UPVOTE will be a great encouragement to me!","42931f22":"- Strings are not statistically processed. It is an average of each latitude and longitude, and this average can be used as the basis for map-location in Folium.","65d6cd27":"------\n<h1 style= \"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>Main : Pre-Process-Pipeline<\/b><\/h1>\n\n\n- What the next process needs is a process that can accurately categorize.\n    - Address, Resolusion, and Descript do not have unique values correctly. These need to be processed.\n    \n    - Address : Je(street_type)\n        - In addition, it may be possible to add the characteristics of which block the street is located in (not done below).\n       \n- Category : target\n- Delete Columns : Address, Dates\n\n- In the pipeline passed to the model, we use the pipeline with StreetType deleted. This is done to avoid the situation where the category does not match when specifying the number of digits because it takes time to train the model depending on the PC environment.","7d79c451":"**1. read index as Timestamp.**\n- What kind of transformation is possible?\n- We are not actually using this data as Pre-Processing.","4b25aaa0":"------\n**Check the data after conversion.**\n- Obviously, there is not much data for 2015, because the data only exists up to the middle period as described above.","c3cf1f64":"--------\n<h1 style= \"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>Model<\/b><\/h1>\n\n- GridSearchCV, RandomizedSearchCV, CV, etc. are not used due to the low spec environment in which this Notebook was created.\n- As mentioned above, we have not adjusted the hyperparameters of the Model, so the performance is quite low. I also did not visualize the training, so I cannot tell visually what kind of state it is in.\n- For more information on training models, please refer to another Notebook I am working on.\n\n- I have only created a minimum number of Models.\n- Category prediction is being done in y_pred_gb. This means that it predicts what the incident will be, which also means that it is possible to predict what the incident will be and prepare to respond to it in advance if it occurs with the characteristics of a feature. It is also possible to predict the probability of an incident occurring. It's like Minority Report starring Tom Cruise.","178f82ad":"<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>San Francisco Crime<\/b><\/h1>\n\n- Please give me an UPVOTE if you can. Your UPVOTE will be a great encouragement to me!","c05e5d4a":"## Clustering view of ASSULT from 2003 to 2015.\n- You can visualize the clusters either by scrolling the map or by clicking on the target parcel. Because the latitude and longitude are accurately recorded, you can clearly pinpoint where the incident is occurring when you scroll down to the smallest unit. Due to the performance problem of the PC I created it on, the pins are all marked with 'A', but it is possible to display the details of the incident itself, and since there is a popup at the minimum unit marker that can display what it is, the details of the Crime can be displayed there.\n- The details of the crime can be displayed in the popup. To do this, the ID is linked to the lat_lon management, and the details of the crime are extracted from the linked item and displayed in the popup.","e47c22d5":"**PdDistrict Visualization**","f42b4918":"<p style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:200%;text-align:center;border-radius:10px 10px;\">Testset<\/p>","54d57407":"- Assign the cluster you created. This will be transformed again, but it is better to do the Clustering before transforming.","bed9e0a1":"## Scatterplot of ASSAULT from 2003-2015.\n- Dynamically displayed with the play button. fps uses the default of 10, but can be increased by raising the slide bar.\n- The red frame is the location point, and clicking on it will display the location name. The reason for the red frame is just to show that this kind of display is possible. The pin is probably the most effective.","63f5a4c2":"-----\n# Final training and validation sets to be used in this Notebook","11cc9488":"- Number of Crime Occurrences on Weekend,day\n- The probability of a Crime occurring at 12:00 increases. This means that in order to form a group, a situation where such a situation can inevitably occur is created.\n- The second visualization also shows a temporary increase in the occurrence of Crime at 12:00.","2940205c":"---------------\n<p style= \"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:3px;border-color:#000000;\"><b>Second Cluster transform<\/b><\/p>\n\n- First is practically the final transform, but the number of indices is so large that it takes a long time to process in a normal PC environment. To solve this problem, we can reduce some of the indices before transforming. This method is not the best, but rather a bad idea, but it is beneficial in terms of running the model. It is important to understand that the results obtained from this are not exact.\n- The first step is to extract only a part of the data from the dataset with the clusters assigned to it before applying the transformation. I think this can be done with .sample() (since you can extract randomly).\n- The number of datasets before extraction is 500,000, so we need to reduce this number to less than 100,000 (this can be adjusted).","efdd3151":"--------\n**Visualization with new features**","cb76e40e":"----\n<h1 style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:300%;text-align:center;border-radius:10px 10px;\"><b>SigmaClip<\/b><\/h1>\n- SigmaClip is used to remove outliers. This method can be used to remove wrong dates, etc. (32 days, etc.) at once.\n\n- The last line uses a robust estimation of the sample mean, where 0.74 is the value obtained from the quartile range of the Gaussian distribution. The actual syntax is not described here.\n\n- Use query to speed up the process.","f58133e7":"**Latitude Visualization**","06df8893":"---------\n<p style=\"background-color:#000000;font-family:Georgia;color:#FFFFFF;font-size:200%;text-align:center;border-radius:10px 10px;\">Timestamp operations<\/p>\n\n1. when reading index using Dates\n\n2. read Dates as Timestamp, and split and convert the Timestamp data. It is not necessary to convert the data to minutes and seconds, but we can assume that we can perform effective lineplotting by converting the data to hours. This will allow for effective visualization to a third party. For example, what time of the day has the highest crime rate using the .count() statistic.\n\n3. If time series data exists, it is best practice to actively convert it to time series for use.","1490cf63":"- From numerical visualization to visualization with bar plots. It is important to do both, so that we can diversify our knowledge.","fba5e470":"**Holiday**"}}