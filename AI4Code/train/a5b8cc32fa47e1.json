{"cell_type":{"3aedd8cb":"code","716fb0ab":"code","30f981a6":"code","236004ae":"code","feaeefbd":"code","fb51c48a":"code","b5bbd496":"code","496a3267":"code","c08e5c5e":"code","5b90614b":"code","fcf60a82":"markdown","4f5a4fd0":"markdown","b109d2ce":"markdown","9463800d":"markdown","b94aa4f2":"markdown","e9a88beb":"markdown","fea14ed4":"markdown","50046ed0":"markdown","817f7036":"markdown"},"source":{"3aedd8cb":"import os\nimport gc\nimport random\nimport sys\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport skimage.io\nimport cv2\nimport PIL\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip, Resize, \\\nRandomRotate90, OneOf, RandomContrast, RandomGamma, RandomBrightness, ShiftScaleRotate, \\\nEqualize\nimport torch\nfrom skimage.transform import AffineTransform, warp\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.utils.data.dataloader import DataLoader\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix, accuracy_score\nimport seaborn as sn\nfrom functools import partial\n\n# Install pre-trained models\nsys.path.insert(0, '..\/input\/pytorch-pretrained-models\/semi-supervised-ImageNet1K-models-master\/semi-supervised-ImageNet1K-models-master\/')\nfrom hubconf import *\n\n#Define paths\nBASE_PATH = '\/kaggle\/input'\nTRAIN_IMG_DIR = f'{BASE_PATH}\/panda-128x128x20\/kaggle\/train_images\/'\ntrain = pd.read_csv(f'{BASE_PATH}\/prostate-cancer-grade-assessment\/train.csv').set_index('image_id')\n\n# Global variables\nMODEL_NAME = 'resnext50_32x4d_ssl' \n\nLOSS = 'CE' ","716fb0ab":"class CFG:\n    debug=False\n    lr=1e-3\n    batch_size=16\n    epochs=8\n    onecyclepolicy=False\n    seed=35\n    n_fold=4\n    \nclass CFG_MODEL:\n    ntiles = 20\n    sztiles = 128\n    szbag = 2\n    target_size = 6 \n    target_col = 'isup_grade'","30f981a6":"files = sorted(set([p[:32] for p in os.listdir(TRAIN_IMG_DIR)]))\ntrain = train.loc[files]\ntrain = train.reset_index()\nprint(len(train))","236004ae":"def seed_everything(seed=99):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.enabled = True\n    \n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n    \ndef init_logger(log_file='train.log'):\n    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n    \n    log_format = '%(asctime)s %(levelname)s %(message)s'\n    \n    stream_handler = StreamHandler()\n    stream_handler.setLevel(DEBUG)\n    stream_handler.setFormatter(Formatter(log_format))\n    \n    file_handler = FileHandler(log_file)\n    file_handler.setFormatter(Formatter(log_format))\n    \n    logger = getLogger('PANDA')\n    logger.setLevel(DEBUG)\n    logger.addHandler(stream_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n\nLOG_FILE = 'train.log'\nLOGGER = init_logger(LOG_FILE)\n    \n# Fastai layers (https:\/\/github.com\/alecrubin\/pytorch-serverless\/blob\/master\/fastai\/layers.py)\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1, 1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f = f\n    def forward(self, x): return self.f(x)\n\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n    \n    \n# Label smoothing\n# https:\/\/www.kaggle.com\/vladvdv\/pytorch-training-customizable-kernel-with-5-folds\ndef onehot_encoding(label, n_classes):\n    return torch.zeros(label.size(0), n_classes).to(label.device).scatter_(\n        1, label.view(-1, 1), 1)\ndef cross_entropy_loss(input, target, reduction):\n    logp = F.log_softmax(input, dim=1)\n    loss = torch.sum(-logp * target, dim=1)\n    if reduction == 'none':\n        return loss\n    elif reduction == 'mean':\n        return loss.mean()\n    elif reduction == 'sum':\n        return loss.sum()\n    else:\n        raise ValueError(\n            '`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')\n        \ndef label_smoothing_criterion(epsilon=0.1, reduction='mean'):\n    def _label_smoothing_criterion(preds, targets):\n        n_classes = preds.size(1)\n        device = preds.device\n\n        onehot = onehot_encoding(targets, n_classes).float().to(device)\n        targets = onehot * (1 - epsilon) + torch.ones_like(onehot).to(\n            device) * epsilon \/ n_classes\n        loss = cross_entropy_loss(preds, targets, reduction)\n        if reduction == 'none':\n            return loss\n        elif reduction == 'mean':\n            return loss.mean()\n        elif reduction == 'sum':\n            return loss.sum()\n        else:\n            raise ValueError(\n                '`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')\n\n    return _label_smoothing_criterion","feaeefbd":"class PandaDatasetInt:\n    def __init__(self, df, N, sz, transform=None):\n        self.image_ids=df.image_id.values\n        self.isup_grade = df.isup_grade.values\n        self.data_provider = df.data_provider.values\n        self.transform=transform\n        self.df=df\n        self.tile_sz = sz\n        self.tile_nb = N\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, index):\n        fn_base = f'{TRAIN_IMG_DIR}{self.image_ids[index]}'\n        img = PIL.Image.open(f\"{fn_base}.png\").convert('RGB')\n        img = np.array(img)\n        img = img.reshape(img.shape[0] \/\/ self.tile_sz, self.tile_sz, img.shape[1] \/\/ self.tile_sz, self.tile_sz, 3)\n        img = img.transpose(0, 2, 1, 3, 4).reshape(-1, self.tile_sz, self.tile_sz, 3)  # Nxszxszx3\n        img = img.astype(np.single)\n        \n        if self.transform:\n            for i in range(self.tile_nb):\n                aug = self.transform(image=img[i])\n                img[i] = aug['image'].permute(1,2,0)\n                \n        label = self.isup_grade[index]\n        provider = self.data_provider[index]\n        return  torch.tensor(img.transpose(0, 3, 1, 2)), torch.tensor(label), provider","fb51c48a":"# Display batch\ntfm = Compose([\n        ToTensorV2(),\n    ])\n\ndataset = PandaDatasetInt(train, N=CFG_MODEL.ntiles, sz=CFG_MODEL.sztiles, transform=tfm)\nloader = DataLoader(dataset, batch_size=CFG.batch_size, shuffle=False)\n\nimages, label, provider = next(iter(loader))\nfor i in range(8):\n    grid = torchvision.utils.make_grid(images[i].int(), nrow=20)\n    plt.figure(figsize=(30,30))\n    plt.imshow(grid.permute(1,2,0))\n    plt.title(f'isup grade = {label[i].item()} | provider : {provider[i]}')","b5bbd496":"# RESNEXT\ndef _resnext(block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n\n    return model\n\nclass Model(nn.Module):\n    def __init__(self, n=6, N=12, R=2):\n        super().__init__()\n        self.R = R\n        m = _resnext(Bottleneck, [3, 4, 6, 3], False, progress=False, groups=32, width_per_group=4)\n        m.load_state_dict(torch.load('..\/input\/pytorch-pretrained-models\/semi_supervised_resnext50_32x4-ddb3e555.pth'))\n        \n        self.backbone = nn.Sequential(*list(m.children())[:-1]) \n        nc = list(m.children())[-1].in_features\n        self.conv1d = nn.Conv1d(N, N, nc)\n        self.head =  nn.Sequential(\n            Flatten(), \n            nn.Linear(R*2,200), nn.ReLU(), nn.BatchNorm1d(200), nn.Dropout(0.5), \n            nn.Linear(200,100), nn.ReLU(), nn.BatchNorm1d(100), nn.Dropout(0.5),                            \n            nn.Linear(100, n))\n\n    def forward(self, x):\n        shape = x.shape\n        n = shape[1]\n        x = x.view(-1, shape[2],shape[3],shape[4]) #x: bs*N x C x 128 x 128\n        # Backbone\n        x = self.backbone(x) # => x: bs*N x C x 1 x 1\n        x = x.view(-1, n, x.shape[1], x.shape[2], x.shape[3]) # => x: bs x N x C x 1 x 1\n        x = x.view(x.shape[0], x.shape[1], -1) # => x: bs x N x C\n        x = self.conv1d(x)  # => x: bs x N \n        x, _ = torch.sort(x, dim=1, descending=True)\n        x = torch.cat((x[:, :(self.R)], x[:, (n - self.R):]), 1)  # keep min and max\n        x = self.head(x) # => x: bs x 6\n        return x","496a3267":"if CFG.debug:\n    folds = train.sample(n=50, random_state=CFG.seed).reset_index(drop=True).copy()\nelse:\n    folds = train.copy()\n\ntrain_labels = folds[CFG_MODEL.target_col].values\nkf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n    folds.loc[val_index, 'fold'] = int(fold)\nfolds['fold'] = folds['fold'].astype(int)\nfolds.to_csv('folds.csv', index=None)\nfolds.head()","c08e5c5e":"def train_fn(fold):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"### fold: {fold} ###\")\n    \n    lossTrain = []\n    stepTrain = []\n    lossVal = []\n    stepVal = []\n    \n    step = 0\n        \n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n    \n    # Transforms\n    transformTrain = Compose([\n        OneOf([RandomBrightness(limit=0.15), RandomContrast(limit=0.3), RandomGamma()], p=0.25),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.3),\n        Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n        ),\n        ToTensorV2(),\n    ])\n\n    transformValid = Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n                        \n    # Data loaders\n    train_dataset = PandaDatasetInt(folds.loc[trn_idx].reset_index(drop=True), N=20, sz=128, transform=transformTrain)\n    valid_dataset = PandaDatasetInt(folds.loc[val_idx].reset_index(drop=True), N=20, sz=128, transform=transformValid)\n    \n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, num_workers=4)\n    \n    # Model\n    model = Model(n=CFG_MODEL.target_size, N=CFG_MODEL.ntiles, R=CFG_MODEL.szbag)\n    model.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n    if CFG.onecyclepolicy == True:\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG.lr, div_factor=100, pct_start=0.0, steps_per_epoch=len(train_loader), epochs=CFG.epochs)\n    else:\n        scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n    \n    if LOSS == 'CE':\n        criterion = nn.CrossEntropyLoss()\n    elif LOSS == 'LabelSmoothingCE':\n        criterion = label_smoothing_criterion()\n        \n    best_score = -100\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        start_time = time.time()\n\n        model.train()\n        avg_loss = 0.\n\n        optimizer.zero_grad()\n        tk0 = tqdm(enumerate(train_loader), total=len(train_loader))\n\n        for i, (images, labels, _) in tk0:\n\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lossTrain.append(loss.item())\n            stepTrain.append(step)\n            \n            if CFG.onecyclepolicy == True:\n                scheduler.step()\n\n            avg_loss += loss.item() \/ len(train_loader)\n            step += 1\n            \n        model.eval()\n        avg_val_loss = 0.\n        preds = []\n        valid_labels = []\n        tk1 = tqdm(enumerate(valid_loader), total=len(valid_loader))\n\n        for i, (images, labels, _) in tk1:\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            with torch.no_grad():\n                y_preds = model(images)\n            \n            preds.append(y_preds.to('cpu').numpy().argmax(1))\n            valid_labels.append(labels.to('cpu').numpy())\n\n            loss = criterion(y_preds, labels)\n            avg_val_loss += loss.item() \/ len(valid_loader)\n            \n        lossVal.append(avg_val_loss)\n        stepVal.append(step)\n            \n        if CFG.onecyclepolicy == False:\n            scheduler.step(avg_val_loss)\n            \n        preds = np.concatenate(preds)\n        valid_labels = np.concatenate(valid_labels)\n        \n        LOGGER.debug(f'Counter preds: {Counter(preds)}')\n        score = cohen_kappa_score(valid_labels, preds, weights='quadratic')\n        \n        if epoch == (CFG.epochs - 1):\n            print(confusion_matrix(valid_labels, preds))\n\n        elapsed = time.time() - start_time\n        \n        LOGGER.debug(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.debug(f'  Epoch {epoch+1} - QWK: {score}')\n        \n        if score>best_score:\n            best_score = score\n            LOGGER.debug(f'  Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save(model.state_dict(), f'fold{fold}_se_resnext50.pth')\n            \n    # Plot losses \n    plt.figure(figsize=(26,6))\n    plt.subplot(1, 2, 1)\n    plt.plot(stepTrain, lossTrain, label=\"training loss\")\n    plt.plot(stepVal, lossVal, label = \"validation loss\")\n    plt.title('Loss')\n    plt.xlabel('step')\n    plt.legend(loc='center left')\n    plt.tight_layout()\n    plt.show()","5b90614b":"#for fold in range(CFG.n_fold):\ntrain_fn(1)","fcf60a82":"# Libraries","4f5a4fd0":"# Visualize","b109d2ce":"# Dataset","9463800d":"# Config","b94aa4f2":"# Split train\/val","e9a88beb":"# Training","fea14ed4":"# Train ","50046ed0":"# Utils","817f7036":"Incomplete (revisited) implementation of CHOWDER method as described in https:\/\/arxiv.org\/pdf\/1802.02212.pdf\n\n![image.png](attachment:image.png)\n\n**The authors in the paper use far more than 20 tiles**.\nHope it'll provides some ideas for the challenge\n\nI've used a similar training framework that https:\/\/www.kaggle.com\/yasufuminakama\/panda-se-resnext50-classification-baseline + iafoss tiling method https:\/\/www.kaggle.com\/iafoss\/panda-concat-tile-pooling-starter-0-79-lb"}}