{"cell_type":{"04802e5b":"code","42b65592":"code","9cd5632c":"code","e2a9c374":"code","daaf3ff3":"code","95c30442":"code","ada2d60a":"code","62da77ac":"code","98a4065e":"code","8016cdb9":"code","e5219f3e":"code","633324a2":"code","7ec5797d":"code","a70b8243":"markdown","015b0729":"markdown","b11de67c":"markdown","d9cbd284":"markdown","9eaa83a6":"markdown","bb62a146":"markdown","f6b15074":"markdown","23251111":"markdown","7dc1e9ba":"markdown","5dcf3379":"markdown","1334b682":"markdown"},"source":{"04802e5b":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nsns.set_style(\"dark\")\nimport warnings\nwarnings.filterwarnings('ignore')","42b65592":"#Import datset\ndata = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndata.head(10)","9cd5632c":"data.drop(['Unnamed: 32','id'], axis = 1 , inplace=True)","e2a9c374":"data.describe()","daaf3ff3":"data.skew()","95c30442":"#Visualizing Multidimensional Relationships\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.pairplot(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]], hue = 'diagnosis' , size=3)","ada2d60a":"#create the correlation matrix heat map\nplt.figure(figsize=(10,6))\nsns.heatmap(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]].corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);\nplt.suptitle('Correlation Matrix')\n","62da77ac":"# Transform the 'yes' and 'no' values (target variable) to 1 and 0 respectively\ndata['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n\n#Scalling\nscaler =MinMaxScaler(feature_range=(0, 1))\nscaled_data =  pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n# Split the data to train and test sets\nX = scaled_data.loc[:, scaled_data.columns != 'diagnosis']\ny = scaled_data['diagnosis']","98a4065e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","8016cdb9":"#Defining model evaluation function\ndef getModelEvaluationMetrics(classifier, model_name: str, x_test: pd.core.frame.DataFrame,\n                              y_test: pd.core.frame.DataFrame, y_predicted, plot_confusion_matrix=False,\n                              figsize=(10, 8)) -> np.ndarray:\n\n    conf_mat = confusion_matrix(y_true=y_test, y_pred=y_predicted)\n    print('Confusion matrix:\\n\\n {0}'.format(conf_mat))\n\n    if plot_confusion_matrix:\n        labels = ['M', 'B']\n        fig = plt.figure(figsize=figsize)\n        ax = fig.add_subplot(111)\n        cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n        fig.colorbar(cax)\n        ax.set_xticklabels([''] + labels)\n        ax.set_yticklabels([''] + labels)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('Predicted')\n        plt.ylabel('Expected')\n        plt.title(f'Confusion Matrix for {model_name}', fontweight='bold')\n        plt.show()\n\n    # Calculating the precision (tp\/tp+fp)\n    precision = str(np.round((conf_mat[1][1] \/ (conf_mat[1][1] +\n                              conf_mat[0][1])) * 100, 2))\n    print('The precision is: {0} %'.format(precision))\n\n    # Calculating the recall (tp\/tp+fn)\n    recall = str(np.round((conf_mat[1][1] \/ (conf_mat[1][1] +\n                           conf_mat[1][0])) * 100, 2))\n    print('The recall is: {0} %'.format(recall))\n\n    return conf_mat","e5219f3e":"#Defining function for performing a full ROC analysis\ndef createROCAnalysis(classifier, model_name: str, y_test: pd.core.series.Series, pred_probs: np.ndarray,\n                      plot_ROC_Curve=False, figsize=(10, 8)) -> int:\n   \n    if plot_ROC_Curve:\n        plt.figure(figsize=figsize)\n        plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier')\n        fp_rate, tp_rate, _ = roc_curve(y_test, pred_probs[:, 1])\n        plt.plot(fp_rate, tp_rate, marker='.', label=model_name)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve for {model_name}', fontweight='bold')\n        plt.grid(True, alpha=0.1, color='black')\n        plt.legend(loc='lower right')\n        plt.show()\n\n    # Calculate Area Under Curve (AUC) for the Receiver Operating\n    # Characteristics Curve (ROC)\n    auc_score = np.round(roc_auc_score(y_test, pred_probs[:, 1]), 4)\n    print(f'{model_name} - ROC AUC score: {auc_score}')\n\n    return auc_score","633324a2":"# Instantiate the Random Forest model\n#Pre-tuned Hyperparameter of Random Forest Classifier on this dataset\n\nrf_class = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features=10, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=20, min_samples_split=20,\n            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall\/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","7ec5797d":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))","a70b8243":"> Let's load libraries ","015b0729":"> # Exploratory Data Analysis ","b11de67c":"> # Conclusion\n* Random Forest Model Prediction without PCA\n\nThe precision is: 95.24 %\n\nThe recall is: 93.02 %\n\nROC AUC score: 0.9954\n","d9cbd284":"**Transform the 'M' and 'B' values (target variable) to 1 and 0 respectively. Following the encoding of the categorical features, we will continue with the normalization (scalling) of the numerical features. For this we will use the MinMax scalling method.**","9eaa83a6":"Dataset Description\n\nThe Breast Cancer datasets is available UCI machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.\n\nThe first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M=malignant, B=benign), respectively. The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n\n1= Malignant (Cancerous) - Present (M)\n0= Benign (Not Cancerous) -Absent (B)\n\nAttribute Information:\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\n1. radius \n2. texture \n3. perimeter\n4. area\n5. smoothness \n6. compactness\n7. concavity \n8. concave points \n9. symmetry\n10. fractal dimension \n\nClass distribution: 357 benign, 212 malignant\n\n","bb62a146":"> # Data Preprocessing","f6b15074":"**We will drop the unnecessary data(null)**","23251111":"**The skew result show a positive or negative skew. Values closer to zero show less skew. We can see that radius_mean, perimeter_mean, area_mean, concavity_mean and concave_points_mean are useful in predicting cancer type due to the distinct grouping between malignant and benign cancer types in these features. We can also see that area_worst and perimeter_worst are also useful.**","7dc1e9ba":"> # Breast Cancer Prediction","5dcf3379":"# **Breast Cancer Wisconsin Data Set**","1334b682":"> # Model Evaluation Metrics\n\nFor model evaluation and To perform a full ROC analysis let's define two functions"}}