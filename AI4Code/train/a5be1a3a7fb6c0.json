{"cell_type":{"adc9216b":"code","ab45c1d6":"code","e5b1cd0c":"code","423ab78f":"code","6dfee2f2":"code","fe0363b9":"code","3959cbf1":"code","00678707":"code","72f2a075":"code","33d6b05f":"code","7d9b32bc":"code","d9ab7200":"code","97a17198":"code","cf836330":"code","bc62ca6e":"code","7422a309":"code","80b157af":"code","147d4394":"code","f47a20d3":"code","2428b284":"code","f9d1b2a5":"code","5f2d5717":"code","3503841c":"code","53df93b4":"code","452b43be":"code","427b1d04":"code","918bfc2b":"code","747efbc0":"code","a4109de0":"code","eb4e9fb8":"code","6913c51b":"code","b934efea":"code","f55e70a7":"code","e4c5ad04":"code","bc0d5b2e":"code","d7ad8353":"code","90ef6d77":"code","5bdf3c18":"markdown","4e8fcd49":"markdown","5f0eb0e2":"markdown","80acf07f":"markdown","4f8e517c":"markdown","3101ae07":"markdown","4c7fcfb5":"markdown"},"source":{"adc9216b":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Activation, Dropout,LSTM, Input, Bidirectional\nfrom tensorflow.keras.metrics import categorical_accuracy\nimport collections\nimport re\nimport numpy as np\nimport pandas as pd\n\n\n## pattern to remove special chars and digits\np1 = \"[^a-zA-Z]\"\n\n## sequence parameters\nseq_length = 3\nseq_stepcount = 1\n","ab45c1d6":"# ## scrape data from online\n# import requests\n# from bs4 import BeautifulSoup\n\n# url = \"https:\/\/parenting.firstcry.com\/articles\/top-25-animal-stories-for-kids-with-moral-lessons\/\"\n# res = requests.get(url)\n# soup = BeautifulSoup(res.content, 'html5lib')\n\n","e5b1cd0c":"# all_eles = soup.find_all(\"p\")\n# data = \"\"\n# for i in all_eles:\n#     d = i.text\n#     data+=\" \"+d\n    \n# data\ndata = \"\"\nwith open(\"..\/input\/10-animals-stories\/storiesData.txt\") as f:\n    data = f.read()\ndata\n    ","423ab78f":"def readFileData(path):\n    with open(path,\"r\",encoding=\"utf8\") as f:\n        data = f.read().lower()\n    \n    return data\n\ndef makeListOfWords(op=\"r\",data = None):\n    \"\"\" this function get data manually or read from the file depend on input type op\"\"\"\n    if(op==\"r\"):\n        data = readFileData(\"..\/input\/stories\/stories.txt\")\n    \n    data = re.sub(p1,\" \",data).lower()\n    w1 = []\n    for word in data.split():\n        if word not in list(\"\\n\"):\n            w1+=[word]\n    \n    return w1\n    \n    ","6dfee2f2":"words = makeListOfWords(\"m\",data=data)","fe0363b9":"words","3959cbf1":"## generate dictionary that contains each unique words\nwords_count = collections.Counter(words)","00678707":"vocab_inv = [x[0] for x in words_count.most_common()]\nvocab_inv = list(sorted(vocab_inv))\nvocab_inv","72f2a075":"## mapping from word to index \nvocab = {x:i for i,x in enumerate(vocab_inv)}\nvocabSize = len(vocab)","33d6b05f":"vocabSize","7d9b32bc":"def generateSequencesAndNextWords(seq_length,seq_step):\n    seqs = []\n    nextword = []\n    \n    for i in range(0,len(words) - seq_length , seq_step):\n       \n\n        for j in range(i,i+seq_length):\n            seqs.append(words[i:j+1])\n            nextword.append(words[j+1])\n\n    \n    return seqs,nextword\n","d9ab7200":"sequences , nextWords = generateSequencesAndNextWords(seq_length,seq_stepcount)","97a17198":"sequences","cf836330":"nextWords","bc62ca6e":"vocabSize","7422a309":"## let's build training data\nx = np.zeros((len(sequences),seq_length,vocabSize))\ny = np.zeros((len(sequences),vocabSize))\n\nfor i,sentence in enumerate(sequences):\n    for j , word in enumerate(sentence):\n        x[i,j,vocab[word]] = 1\n    \n    y[i,vocab[nextWords[i]]] = 1","80b157af":"def buildLSTMModel(vocab_size):\n    print(\"Building model ...\")\n    model = tf.keras.models.Sequential([\n        \n        Bidirectional(LSTM(300,recurrent_activation=\"tanh\",recurrent_dropout=0.4,return_sequences= True),input_shape=(None,vocab_size)),\n        Dropout(0.4),\n        LSTM(200,recurrent_activation=\"tanh\",recurrent_dropout=0.4),\n        \n        Dense(vocab_size,activation=\"softmax\")\n    ])\n    \n    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[categorical_accuracy])\n    print(\"Model built\")\n    return model","147d4394":"rnnmd = buildLSTMModel(vocabSize)\nrnnmd.summary()","f47a20d3":"history = rnnmd.fit(x,y,validation_split=0.15,shuffle=True,epochs=70)","2428b284":"pd.Series(history.history[\"categorical_accuracy\"]).plot()\npd.Series(history.history[\"val_categorical_accuracy\"]).plot()","f9d1b2a5":"seed_sentences = \"one\" #seed sentence to start the generating.\nwords_demo = seed_sentences.split()\nseq_lengh_Demo = len(seed_sentences.split())\nxDemo = np.zeros((1,seq_lengh_Demo,vocabSize))\nfor t,word in enumerate(words_demo):\n    xDemo[0,t,vocab[word]]=1\n    print(\"marks 1 at \",(0,t,vocab[word]))","5f2d5717":"def sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) \/ temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds \/ np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)","3503841c":"inverse_vocab = {x:i for i,x in vocab.items()}","53df93b4":"import joblib\n","452b43be":"def predictUsingBiLSTM(sentance,target_seq_length ,temp):\n        \n    counter = 0\n    generated = sentance\n    predicted_sentence_length = 15\n    current_sent = sentance\n    \n    \n    for i in range(target_seq_length):\n\n        words_demo = current_sent.split()\n        seq_lengh_Demo = len(current_sent.split())\n        xDemo = np.zeros((1,len(words_demo),vocabSize))\n        \n        for t,word in enumerate(words_demo):\n            xDemo[0,t,vocab[word]]=1\n\n        pred = inverse_vocab[sample(rnnmd.predict(xDemo)[0],temp)]\n        \n        current_sent = pred\n        generated+=\" \"+current_sent\n        \n        print(\"generate text : \",generated)\n        \n    \npredictUsingBiLSTM(\"one day\",7,20)","427b1d04":"predictUsingBiLSTM(\"one day\",10,temp=5)","918bfc2b":"predictUsingBiLSTM(\"animal culture\",10,7)","747efbc0":"predictUsingBiLSTM(\"lion killed children\",15,temp=7)","a4109de0":"predictUsingBiLSTM(\"animals never\",12,temp=4)","eb4e9fb8":"import joblib\njoblib(rnnmd,\"rnn_model.pickle\")","6913c51b":"rnnmd.save(\"rnn_model2.pkl\")","b934efea":"rnnmd.save(\"rnn_model3.hdf5\")","f55e70a7":"import pickle","e4c5ad04":"rnnmd.save(filepath=\".\/\")","bc0d5b2e":"data","d7ad8353":"from tensorflow.keras.models import load_model","90ef6d77":"md3 = load_model(\".\/rnn_model3.hdf5\")","5bdf3c18":"#### 3.1)  Build vocabulary","4e8fcd49":"## 2) Data preprocessing : \nin this phase i am gonna do text processing like remove special characters and convert all text into lower or upper case to minimize the size of vocbulary ","5f0eb0e2":"#### 3.3) convert sequences into set vectors ( x vectors are for input and y vector for output )","80acf07f":"## 1) Data gathering : scrap 10 stories from online site","4f8e517c":"## 3) Data preparation for training : \n    - Build vocabulary \n    - generate input and output sequences\n    - convert it into form of vetors","3101ae07":"Entire project divide into different phases\n1) Data gathering :  get data from the online source , we have perform web scraping to get 10 stories. \n\n2) Data proprocessing and transformation : clean data and remove special chars and unnecessary words from data\n\n3) Data preparation : prepare data for training , prepare input and output data , and build vocubalary\n\n4) model training : prepare RNN and fit it on training data\n\n5) predict next words using model","4c7fcfb5":"#### 3.2) Generate input and output sequences"}}