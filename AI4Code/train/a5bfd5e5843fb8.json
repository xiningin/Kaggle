{"cell_type":{"165fe4f7":"code","0d5f8cd2":"code","aa336306":"code","fba4aa30":"code","ceb1c954":"code","cf45b358":"code","7749bb5f":"code","9630ce28":"code","592e8f61":"code","0f33f5d2":"code","731451de":"code","4c135f11":"code","b6b2f1f7":"markdown","8016f4ae":"markdown","5c9f3844":"markdown","6f038cdb":"markdown","6ab21de8":"markdown","279c9882":"markdown","b481cb98":"markdown","e3ef36f0":"markdown","f3cce00d":"markdown","16898553":"markdown","86ccaaea":"markdown","08d411a8":"markdown","a1348f89":"markdown"},"source":{"165fe4f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings('ignore')\nsns.set_palette('Set2')\nsns.set_style('darkgrid')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d5f8cd2":"df = pd.read_csv(\"\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv\")\nprint (df.shape)\ndf.head()","aa336306":"dict_ = df['user_verified'].value_counts().to_dict()\ndict_['Verified'] = dict_.pop(True)\ndict_['Not-Verified'] = dict_.pop(False)\n\nplt.figure(figsize=(7,7))\nplt.pie(x=dict_.values(), labels=dict_.keys(), autopct='%1.1f%%', shadow=True, startangle=0, explode = [0.1, 0])\nplt.show()","fba4aa30":"from collections import Counter\ndict_ = Counter(df['source'].tolist()).most_common(5)\ntemp = pd.DataFrame(dict_, columns=['Source', 'Count'])\n\nplt.figure(figsize=(7,7))\nplt.pie(x=temp['Count'], labels=temp['Source'], autopct='%1.1f%%', shadow=True, startangle=0)\nplt.show()","ceb1c954":"plt.figure(figsize=(12,10))\nsns.countplot(y='user_name', data=df, order=df['user_name'].value_counts().index[:15])\nplt.xlabel('Number of Tweets', weight='bold')\nplt.ylabel('User Name', weight='bold')\nplt.show()","cf45b358":"plt.figure(figsize=(12,10))\nsns.countplot(y='user_location', data=df, order=df['user_location'].value_counts().index[:15])\nplt.xlabel('Number of User', weight='bold')\nplt.ylabel('Location', weight='bold')\nplt.show()","7749bb5f":"df_temp = df.copy()\ndf_temp['user_verified'] = df_temp['user_verified'].astype('str')\ndf_temp['user_verified'] = df_temp['user_verified'].str.replace('False','No')\ndf_temp['user_verified'] = df_temp['user_verified'].str.replace('True','Yes')\n\nfig, ax = plt.subplots(2,1,figsize=(20,10))\nsns.boxplot(y='user_verified', x='user_followers', data=df_temp, ax=ax[0])\nax[0].set_xscale('log')\nax[0].set_xlabel(\"Number of Followers\", weight='bold')\nax[0].set_ylabel('Verified User?', weight='bold')\n\nsns.boxplot(y='user_verified', x='retweets', data=df_temp, ax=ax[1])\nax[1].set_xscale('log')\nax[1].set_xlabel(\"Number of ReTweets\", weight='bold')\nax[1].set_ylabel('Verified User?', weight='bold')\nplt.show()","9630ce28":"fig, ax = plt.subplots(1,2, figsize=(18, 10))\nsns.distplot(df['hashtags'].dropna().apply(lambda x: len(x.split(','))).tolist(), kde=False, ax=ax[0], color='red')\nax[0].set_xlabel(\"Number of Hashtags\", weight='bold')\nax[0].set_ylabel('Number of Tweets', weight='bold')\n\nsns.distplot(df['text'].str.len().tolist(), kde=False, ax=ax[1], color='green')\nax[1].set_xlabel(\"Length of Tweet\", weight='bold')\nax[1].set_ylabel('Number of Tweets', weight='bold')\nax[1].set_yscale('log')\nplt.show()","592e8f61":"plt.figure(figsize=(8,8))\nsns.heatmap(df.drop(columns=['id','is_retweet']).corr(), square=True, annot=True)\nplt.show()","0f33f5d2":"import itertools\nfrom wordcloud import WordCloud\n\nlist_hashtags = df['hashtags'].dropna().str.lstrip('[').str.rstrip(']').str.replace(\"'\", \"\").str.split(', ').tolist()\nlist_hashtags = list(itertools.chain(*list_hashtags))\n\nplt.figure(figsize=(14,10))\nwordcloud = WordCloud(max_font_size=50, max_words=100,background_color=\"white\").generate(' '.join(list_hashtags))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","731451de":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english') + list(punctuation))\ndf_temp = df[['text', 'hashtags']]\ndf_temp['text'] = df_temp['text'].str.lower()\ndf_temp['text'] = df_temp['text'].apply(word_tokenize)\ndf_temp['text'] = df_temp['text'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_temp['text'] = df_temp['text'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf_temp['text'] = df_temp['text'].apply(lambda x : [word for word in x if len(word) > 1])","4c135f11":"list_text = df_temp['text'].tolist()\nlist_text = list(itertools.chain(*list_text))\n\nplt.figure(figsize=(14,10))\nwordcloud = WordCloud(max_font_size=50, max_words=100,background_color=\"white\").generate(' '.join(list_text))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","b6b2f1f7":"## **WordCloud of text in Tweets**","8016f4ae":"## **Types of Twitter account**","5c9f3844":"## **Heatmap (correlation) among various numerical features**","6f038cdb":"## **Top 15 locations with most number of users**\n\nContains noise or non-location entities as well","6ab21de8":"## **Number of Hashtags and Length of Text per Tweet**","279c9882":"## **Load the data**","b481cb98":"# **EDA**","e3ef36f0":"## **Top 15 users with most number of tweets**","f3cce00d":"## **WordCloud of Hashtags used**","16898553":"## **Top 5 Sources (Platform) of tweets**","86ccaaea":"# **This work is in progress. Feel free to Upvote and give Feedback.**","08d411a8":"# **Pfizer Vaccine Tweets**\n\nThe data iss collected from recent tweets about Pfizer & BioNTech vaccine using tweepy Python package to access Twitter API.","a1348f89":"## **Number of Followers and Retweets for each type of user**"}}