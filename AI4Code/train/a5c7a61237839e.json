{"cell_type":{"5397016f":"code","58673485":"code","bcc82d47":"code","f869ebbb":"code","aa5a8428":"code","0eaf4623":"code","5f74f318":"code","c234916e":"code","3b8e5424":"code","eb836105":"code","3bc79981":"markdown","db682f91":"markdown","a0c4db53":"markdown","e8caac97":"markdown","fb6366b1":"markdown","a83026a8":"markdown","efa8629c":"markdown","646d5041":"markdown"},"source":{"5397016f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import layers\nfrom keras.models import Model\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom imgaug import augmenters as iaa\n\nimport random","58673485":"x_real = np.load('dataset\/x_real.npz')['data']\ny_real = np.load('dataset\/y_real.npy')\nx_easy = np.load('dataset\/x_easy.npz')['data']\ny_easy = np.load('dataset\/y_easy.npy')\nx_medium = np.load('dataset\/x_medium.npz')['data']\ny_medium = np.load('dataset\/y_medium.npy')\nx_hard = np.load('dataset\/x_hard.npz')['data']\ny_hard = np.load('dataset\/y_hard.npy')\n\nprint(x_real.shape, y_real.shape)\n\nplt.figure(figsize=(15, 10))\nplt.subplot(1, 4, 1)\nplt.title(y_real[0])\nplt.imshow(x_real[0].squeeze(), cmap='gray')\nplt.subplot(1, 4, 2)\nplt.title(y_easy[0])\nplt.imshow(x_easy[0].squeeze(), cmap='gray')\nplt.subplot(1, 4, 3)\nplt.title(y_medium[0])\nplt.imshow(x_medium[0].squeeze(), cmap='gray')\nplt.subplot(1, 4, 4)\nplt.title(y_hard[0])\nplt.imshow(x_hard[0].squeeze(), cmap='gray')","bcc82d47":"x_data = np.concatenate([x_easy, x_medium, x_hard], axis=0)\nlabel_data = np.concatenate([y_easy, y_medium, y_hard], axis=0)\n\nx_train, x_val, label_train, label_val = train_test_split(x_data, label_data, test_size=0.1)\n\nprint(x_data.shape, label_data.shape)\nprint(x_train.shape, label_train.shape)\nprint(x_val.shape, label_val.shape)","f869ebbb":"augs = [x_data[40000]] * 9\n\nseq = iaa.Sequential([\n    # blur images with a sigma of 0 to 0.5\n    iaa.GaussianBlur(sigma=(0, 0.5)),\n    iaa.Affine(\n        # scale images to 90-110% of their size, individually per axis\n        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n        # translate by -10 to +10 percent (per axis)\n        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n        # rotate by -30 to +30 degrees\n        rotate=(-30, 30),\n        # use nearest neighbour or bilinear interpolation (fast)\n        order=[0, 1],\n        # if mode is constant, use a cval between 0 and 255\n        cval=255\n    )\n], random_order=True)\n\naugs = seq.augment_images(augs)\n\nplt.figure(figsize=(16, 6))\nplt.subplot(2, 5, 1)\nplt.title('original')\nplt.imshow(x_data[40000].squeeze(), cmap='gray')\nfor i, aug in enumerate(augs):\n    plt.subplot(2, 5, i+2)\n    plt.title('aug %02d' % int(i+1))\n    plt.imshow(aug.squeeze(), cmap='gray')","aa5a8428":"label_real_dict = {}\n\nfor i, y in enumerate(y_real):\n    key = y.astype(str)\n    key = ''.join(key).zfill(6)\n\n    label_real_dict[key] = i","0eaf4623":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, x, label, x_real, label_real_dict, batch_size=32, shuffle=True):\n        'Initialization'\n        self.x = x\n        self.label = label\n        self.x_real = x_real\n        self.label_real_dict = label_real_dict\n        \n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.x) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        x1_batch = self.x[index*self.batch_size:(index+1)*self.batch_size]\n        label_batch = self.label[index*self.batch_size:(index+1)*self.batch_size]\n        \n        x2_batch = np.empty((self.batch_size, 90, 90, 1), dtype=np.float32)\n        y_batch = np.zeros((self.batch_size, 1), dtype=np.float32)\n        \n        # augmentation\n        if self.shuffle:\n            seq = iaa.Sequential([\n                iaa.GaussianBlur(sigma=(0, 0.5)),\n                iaa.Affine(\n                    scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n                    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n                    rotate=(-30, 30),\n                    order=[0, 1],\n                    cval=255\n                )\n            ], random_order=True)\n\n            x1_batch = seq.augment_images(x1_batch)\n        \n        # pick matched images(label 1.0) and unmatched images(label 0.0) and put together in batch\n        # matched images must be all same, [subject_id(3), gender(1), left_right(1), finger(1)], e.g) 034010\n        for i, l in enumerate(label_batch):\n            match_key = l.astype(str)\n            match_key = ''.join(match_key).zfill(6)\n\n            if random.random() > 0.5:\n                # put matched image\n                x2_batch[i] = self.x_real[self.label_real_dict[match_key]]\n                y_batch[i] = 1.\n            else:\n                # put unmatched image\n                while True:\n                    unmatch_key, unmatch_idx = random.choice(list(self.label_real_dict.items()))\n\n                    if unmatch_key != match_key:\n                        break\n\n                x2_batch[i] = self.x_real[unmatch_idx]\n                y_batch[i] = 0.\n\n        return [x1_batch.astype(np.float32) \/ 255., x2_batch.astype(np.float32) \/ 255.], y_batch\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            self.x, self.label = shuffle(self.x, self.label)","5f74f318":"train_gen = DataGenerator(x_train, label_train, x_real, label_real_dict, shuffle=True)\nval_gen = DataGenerator(x_val, label_val, x_real, label_real_dict, shuffle=False)","c234916e":"x1 = layers.Input(shape=(90, 90, 1))\nx2 = layers.Input(shape=(90, 90, 1))\n\n# share weights both inputs\ninputs = layers.Input(shape=(90, 90, 1))\n\nfeature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(inputs)\nfeature = layers.MaxPooling2D(pool_size=2)(feature)\n\nfeature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(feature)\nfeature = layers.MaxPooling2D(pool_size=2)(feature)\n\nfeature_model = Model(inputs=inputs, outputs=feature)\n\n# 2 feature models that sharing weights\nx1_net = feature_model(x1)\nx2_net = feature_model(x2)\n\n# subtract features\nnet = layers.Subtract()([x1_net, x2_net])\n\nnet = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(net)\nnet = layers.MaxPooling2D(pool_size=2)(net)\n\nnet = layers.Flatten()(net)\n\nnet = layers.Dense(64, activation='relu')(net)\n\nnet = layers.Dense(1, activation='sigmoid')(net)\n\nmodel = Model(inputs=[x1, x2], outputs=net)\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","3b8e5424":"history = model.fit_generator(train_gen, epochs=15, validation_data=val_gen)","eb836105":"# new user fingerprint input\nrandom_idx = random.randint(0, len(x_val))\n\nrandom_img = x_val[random_idx]\nrandom_label = label_val[random_idx]\n\nseq = iaa.Sequential([\n    iaa.GaussianBlur(sigma=(0, 0.5)),\n    iaa.Affine(\n        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n        rotate=(-30, 30),\n        order=[0, 1],\n        cval=255\n    )\n], random_order=True)\n\nrandom_img = seq.augment_image(random_img).reshape((1, 90, 90, 1)).astype(np.float32) \/ 255.\n\n# matched image\nmatch_key = random_label.astype(str)\nmatch_key = ''.join(match_key).zfill(6)\n\nrx = x_real[label_real_dict[match_key]].reshape((1, 90, 90, 1)).astype(np.float32) \/ 255.\nry = y_real[label_real_dict[match_key]]\n\npred_rx = model.predict([random_img, rx])\n\n# unmatched image\nunmatch_key, unmatch_idx = random.choice(list(label_real_dict.items()))\n\nux = x_real[unmatch_idx].reshape((1, 90, 90, 1)).astype(np.float32) \/ 255.\nuy = y_real[unmatch_idx]\n\npred_ux = model.predict([random_img, ux])\n\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 3, 1)\nplt.title('Input: %s' %random_label)\nplt.imshow(random_img.squeeze(), cmap='gray')\nplt.subplot(1, 3, 2)\nplt.title('O: %.02f, %s' % (pred_rx, ry))\nplt.imshow(rx.squeeze(), cmap='gray')\nplt.subplot(1, 3, 3)\nplt.title('X: %.02f, %s' % (pred_ux, uy))\nplt.imshow(ux.squeeze(), cmap='gray')","3bc79981":"# Train","db682f91":"# Preview Augmentation","a0c4db53":"# Train Test Split","e8caac97":"# Data Generator","fb6366b1":"# Load Dataset\nYou can download .npz dataset from my Github  \nhttps:\/\/github.com\/kairess\/fingerprint_recognition","a83026a8":"# Evaluation","efa8629c":"# Make Label Dictionary Lookup Table","646d5041":"# Create Model"}}