{"cell_type":{"e46ddc0d":"code","2ffc0d0b":"code","a4b2257b":"code","aaff8bb2":"code","c63132d9":"code","ffc4b55a":"code","b364d0d8":"code","05b8988d":"code","af4ff7ec":"code","cfa9e8b8":"code","a2debed6":"code","7ec959d6":"code","70e29b1c":"code","b89c55ea":"code","bb563596":"code","ae93a3f3":"code","60d138a7":"code","3f3cd2f8":"code","9f3a700f":"code","a34b038f":"code","ad7548de":"code","0b988d24":"code","94ff73ed":"code","e3f2f2a2":"code","31b56482":"code","13cfa789":"code","2b40a108":"code","26f7fd49":"code","efa62217":"code","30ed1ef3":"code","9618ba0d":"code","56367f29":"code","9ca007e6":"code","c27ba65e":"code","9dcb6bd9":"code","092ce780":"code","3bb24d5e":"code","7b215e09":"code","5e8c5f56":"code","8f3a771b":"code","bbea1448":"code","872bac56":"code","4dcf7e28":"code","f1b2624b":"code","b94a5f45":"code","47d398f8":"code","ebc5e10f":"code","7b84bc94":"code","779e01cb":"code","b24d7b5e":"code","1ce9add8":"code","a478f9ea":"code","bd1d7389":"code","55ad1452":"code","777bfa13":"code","c3cee1a6":"code","445f6c60":"code","0ac8082b":"code","737b9a83":"code","d1e1ba2d":"code","b6c902c9":"code","b4275608":"code","9aeb83aa":"code","33645a24":"code","9a619b5a":"code","9e22e8da":"code","6e931824":"code","3a8d1402":"code","5dad81a3":"code","b62e651f":"code","bc9fef98":"code","14aaebc1":"code","307cfe59":"code","3ebb0035":"code","8c00501c":"code","bd9cab06":"code","09eadae0":"code","ebbeffcd":"code","63f666f5":"code","f7ff5893":"code","969e580f":"code","59a64e2e":"code","38445e0a":"code","c480617f":"code","7a31334d":"code","6db49f1e":"code","cf9c45b6":"code","aa25c234":"code","ee6765ba":"code","42fe8079":"code","a625fe2d":"code","7d5d0bcd":"code","9df76718":"code","0c286e54":"code","2f5bfc43":"code","12983063":"code","d384dae7":"code","99857e2e":"code","277d153b":"code","1d079761":"code","a66fb0d6":"markdown","ed6f3a95":"markdown","5efdd429":"markdown","6fd60281":"markdown","daf0b3a6":"markdown","67641410":"markdown","62f47519":"markdown","208184de":"markdown","0c7fe3f6":"markdown","6b575819":"markdown","ebfa1de5":"markdown","e45910a5":"markdown","fbf3005e":"markdown","62e97f0e":"markdown","d6171e89":"markdown","6f8d521b":"markdown","6dcb7108":"markdown","739cc0bc":"markdown","b8996abb":"markdown","4e0578ac":"markdown","71515f61":"markdown","38a7fe2e":"markdown","ebe2c121":"markdown","c6098a5c":"markdown","0cb63c9e":"markdown","46739e5a":"markdown","ca8c3a00":"markdown","015a65e5":"markdown","2044d7d0":"markdown","6885eae9":"markdown","756ed04c":"markdown","4f410ca5":"markdown","e0b22371":"markdown","c14564cb":"markdown","644cc3d2":"markdown","ee04bee9":"markdown","f70e4751":"markdown","77057a47":"markdown","fc41a0a3":"markdown","3d73233c":"markdown","1fbb31c4":"markdown","c13d370a":"markdown","2f550ce5":"markdown","1f77a343":"markdown","01f17ee6":"markdown","725e90b1":"markdown","e687c61b":"markdown","d3648262":"markdown","99af2115":"markdown","2e8b9e35":"markdown","1bae1fe8":"markdown","f8a70d18":"markdown","509d2191":"markdown","02bd36be":"markdown","ca1b785d":"markdown"},"source":{"e46ddc0d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport random\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.metrics import roc_auc_score\nfrom itertools import cycle\nimport os\n \nfrom sklearn import svm, datasets\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix\nprint(\"Load Successful\")","2ffc0d0b":"from os import listdir\nperson_01 = os.listdir(\"..\/input\/signatures\/Real\/person_01\")\nperson_02 = os.listdir(\"..\/input\/signatures\/Real\/person_02\")\nperson_03 = os.listdir(\"..\/input\/signatures\/Real\/person_03\")\nperson_04 = os.listdir(\"..\/input\/signatures\/Real\/person_04\")\nperson_05 = os.listdir(\"..\/input\/signatures\/Real\/person_05\")\nperson_06 = os.listdir(\"..\/input\/signatures\/Real\/person_06\")\nperson_07 = os.listdir(\"..\/input\/signatures\/Real\/person_07\")\nperson_08 = os.listdir(\"..\/input\/signatures\/Real\/person_08\")\nperson_09 = os.listdir(\"..\/input\/signatures\/Real\/person_09\")\nperson_10 = os.listdir(\"..\/input\/signatures\/Real\/person_10\")\nperson_11 = os.listdir(\"..\/input\/signatures\/Real\/person_11\")\nperson_12 = os.listdir(\"..\/input\/signatures\/Real\/person_12\")\nperson_13 = os.listdir(\"..\/input\/signatures\/Real\/person_13\")\nperson_14 = os.listdir(\"..\/input\/signatures\/Real\/person_14\")\nperson_15 = os.listdir(\"..\/input\/signatures\/Real\/person_15\")\nperson_16 = os.listdir(\"..\/input\/signatures\/Real\/person_16\")\nperson_17 = os.listdir(\"..\/input\/signatures\/Real\/person_17\")\nperson_18 = os.listdir(\"..\/input\/signatures\/Real\/person_18\")\nperson_19 = os.listdir(\"..\/input\/signatures\/Real\/person_19\")\nperson_20 = os.listdir(\"..\/input\/signatures\/Real\/person_20\")\nperson_21 = os.listdir(\"..\/input\/signatures\/Real\/person_21\")\nperson_22 = os.listdir(\"..\/input\/signatures\/Real\/person_22\")\nperson_23 = os.listdir(\"..\/input\/signatures\/Real\/person_23\")\nperson_24 = os.listdir(\"..\/input\/signatures\/Real\/person_24\")\nperson_25 = os.listdir(\"..\/input\/signatures\/Real\/person_25\")\nperson_26 = os.listdir(\"..\/input\/signatures\/Real\/person_26\")\nperson_27 = os.listdir(\"..\/input\/signatures\/Real\/person_27\")\nperson_28 = os.listdir(\"..\/input\/signatures\/Real\/person_28\")\nperson_29 = os.listdir(\"..\/input\/signatures\/Real\/person_29\")\nperson_30 = os.listdir(\"..\/input\/signatures\/Real\/person_30\")","a4b2257b":"from tensorflow.keras.preprocessing.image import load_img,img_to_array\ndataset_dir = \"..\/input\/signatures\/preprocessed_data\"\nimage_size=224\nlabels = []\ndataset = []\ndef create_dataset(image_category,label):\n    for img in tqdm(image_category):\n        image_path = os.path.join(dataset_dir,img)\n        try:\n            image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n            image = cv2.resize(image,(image_size,image_size))\n        except:\n            continue\n        \n        dataset.append([np.array(image),np.array(label)])\n    random.shuffle(dataset)\n    return dataset","aaff8bb2":"dataset = create_dataset(person_01,1)\ndataset = create_dataset(person_02,2)\ndataset = create_dataset(person_03,3)\ndataset = create_dataset(person_04,4)\ndataset = create_dataset(person_05,5)\ndataset = create_dataset(person_06,6)\ndataset = create_dataset(person_07,7)\ndataset = create_dataset(person_08,8)\ndataset = create_dataset(person_09,9)\ndataset = create_dataset(person_10,10)\ndataset = create_dataset(person_11,11)\ndataset = create_dataset(person_12,12)\ndataset = create_dataset(person_13,13)\ndataset = create_dataset(person_14,14)\ndataset = create_dataset(person_15,15)\ndataset = create_dataset(person_16,16)\ndataset = create_dataset(person_17,17)\ndataset = create_dataset(person_18,18)\ndataset = create_dataset(person_19,19)\ndataset = create_dataset(person_20,20)\ndataset = create_dataset(person_21,21)\ndataset = create_dataset(person_22,22)\ndataset = create_dataset(person_23,23)\ndataset = create_dataset(person_24,24)\ndataset = create_dataset(person_25,25)\ndataset = create_dataset(person_26,26)\ndataset = create_dataset(person_27,27)\ndataset = create_dataset(person_28,28)\ndataset = create_dataset(person_29,29)\ndataset = create_dataset(person_30,30)","c63132d9":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(dataset)))\n    image = dataset[sample][0]\n    category = dataset[sample][1]\n    if category== 1:\n        label = \"Person 01\"\n    elif category== 2:\n        label = \"Person 02\"\n    elif category== 3:\n        label = \"Person 03\"\n    elif category== 4:\n        label = \"Person 04\"\n    elif category== 5:\n        label = \"Person 05\"\n    elif category== 6:\n        label = \"Person 06\"\n    elif category== 7:\n        label = \"Person 07\"\n    elif category== 8:\n        label = \"Person 08\"\n    elif category== 9:\n        label = \"Person 09\"\n    elif category== 10:\n        label = \"Person 10\"\n    elif category== 11:\n        label = \"Person 11\"\n    elif category== 12:\n        label = \"Person 12\"\n    elif category== 13:\n        label = \"Person 13\"\n    elif category== 14:\n        label = \"Person 14\"\n    elif category== 15:\n        label = \"Person 15\"\n    else:\n        label = \"Uncatagorized\"\n    plt.subplot(2,5,i+1)\n    plt.imshow(image)\n    plt.xlabel(label)\nplt.tight_layout()    ","ffc4b55a":"X = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3)\ny = np.array([i[1] for i in dataset])","b364d0d8":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","05b8988d":"print(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","af4ff7ec":"from tensorflow.keras.utils import to_categorical\ny_train1 = to_categorical(y_train)\ny_test1 = to_categorical(y_test)","cfa9e8b8":"print((X_train.shape,y_train1.shape))\nprint((X_test.shape,y_test1.shape))","a2debed6":"from keras.applications.vgg16 import VGG16, preprocess_input\nvgg16_weight_path = '..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nvgg = VGG16(\n    weights=vgg16_weight_path,\n    include_top=False, \n    input_shape=(224,224,3)\n)","7ec959d6":"for layer in vgg.layers:\n    layer.trainable = False","70e29b1c":"from tensorflow.keras import Sequential\nfrom keras import layers\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel = Sequential()\nmodel.add(vgg)\nmodel.add(Dense(256, activation='relu'))\nmodel.add(layers.Dropout(rate=0.5))\nmodel.add(Dense(128, activation='sigmoid'))\nmodel.add(layers.Dropout(rate=0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(31,activation=\"sigmoid\"))","b89c55ea":"model.summary()","bb563596":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","ae93a3f3":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","60d138a7":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","3f3cd2f8":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['VGG16',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","9f3a700f":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","a34b038f":"from keras.applications.vgg19 import VGG19, preprocess_input\nvgg19_weight_path = '..\/input\/tf-keras-pretrained-model-weights\/No Top\/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\nvgg = VGG19(\n    weights=vgg19_weight_path,\n    include_top=False, \n    input_shape=(224,224,3)\n)","ad7548de":"for layer in vgg.layers:\n    layer.trainable = False","0b988d24":"from tensorflow.keras import Sequential\nfrom keras import layers\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel = Sequential()\nmodel.add(vgg)\nmodel.add(Dense(256, activation='relu'))\nmodel.add(layers.Dropout(rate=0.5))\nmodel.add(Dense(128, activation='sigmoid'))\nmodel.add(layers.Dropout(rate=0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(31,activation=\"sigmoid\"))","94ff73ed":"model.summary()","e3f2f2a2":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","31b56482":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","13cfa789":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","2b40a108":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['VGG19',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","26f7fd49":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","efa62217":"from keras.applications.resnet import ResNet50, preprocess_input\n# ResNet50_weight_path = '..\/input\/keras-pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet = ResNet50(\n    weights=\"imagenet\",\n    include_top=False\n#     input_shape=(256,256,3)\n)","30ed1ef3":"for layer in resnet.layers:\n    layer.trainable = False","9618ba0d":"from tensorflow.keras import Sequential\nfrom keras import layers, Model\nfrom tensorflow.keras.layers import Flatten,Dense\n# model = Sequential()\n# model.add(resnet)\n# model.add(Dense(256, activation='relu'))\n# model.add(layers.Dropout(rate=0.5))\n# model.add(Dense(128, activation='sigmoid'))\n# model.add(layers.Dropout(rate=0.2))\n# model.add(Dense(128, activation='relu'))\n# model.add(layers.Dropout(0.1))\n# model.add(Flatten())\n# model.add(Dense(31,activation=\"sigmoid\"))\nx = resnet.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x) \npredictions = layers.Dense(31, activation='sigmoid')(x)\nmodel = Model(resnet.input, predictions)\n","56367f29":"model.summary()","9ca007e6":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","c27ba65e":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","9dcb6bd9":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","092ce780":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['ResNet50',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","3bb24d5e":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","7b215e09":"from keras.applications.resnet import ResNet101, preprocess_input\n# ResNet50_weight_path = '..\/input\/keras-pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet = ResNet101(\n    weights=\"imagenet\",\n    include_top=False\n#     input_shape=(256,256,3)\n)","5e8c5f56":"for layer in resnet.layers:\n    layer.trainable = False","8f3a771b":"from tensorflow.keras import Sequential\nfrom keras import layers, Model\nfrom tensorflow.keras.layers import Flatten,Dense\n# model = Sequential()\n# model.add(resnet)\n# model.add(Dense(256, activation='relu'))\n# model.add(layers.Dropout(rate=0.5))\n# model.add(Dense(128, activation='sigmoid'))\n# model.add(layers.Dropout(rate=0.2))\n# model.add(Dense(128, activation='relu'))\n# model.add(layers.Dropout(0.1))\n# model.add(Flatten())\n# model.add(Dense(31,activation=\"sigmoid\"))\nx = resnet.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x) \npredictions = layers.Dense(31, activation='sigmoid')(x)\nmodel = Model(resnet.input, predictions)\n","bbea1448":"model.summary()","872bac56":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","4dcf7e28":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","f1b2624b":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","b94a5f45":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['ResNet101',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","47d398f8":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","ebc5e10f":"from keras.applications.resnet import ResNet152, preprocess_input\n# ResNet50_weight_path = '..\/input\/keras-pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet = ResNet152(\n    weights=\"imagenet\",\n    include_top=False\n#     input_shape=(256,256,3)\n)","7b84bc94":"for layer in resnet.layers:\n    layer.trainable = False","779e01cb":"from tensorflow.keras import Sequential\nfrom keras import layers, Model\nfrom tensorflow.keras.layers import Flatten,Dense\n# model = Sequential()\n# model.add(resnet)\n# model.add(Dense(256, activation='relu'))\n# model.add(layers.Dropout(rate=0.5))\n# model.add(Dense(128, activation='sigmoid'))\n# model.add(layers.Dropout(rate=0.2))\n# model.add(Dense(128, activation='relu'))\n# model.add(layers.Dropout(0.1))\n# model.add(Flatten())\n# model.add(Dense(31,activation=\"sigmoid\"))\nx = resnet.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation='relu')(x) \npredictions = layers.Dense(31, activation='sigmoid')(x)\nmodel = Model(resnet.input, predictions)\n","b24d7b5e":"model.summary()","1ce9add8":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","a478f9ea":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","bd1d7389":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","55ad1452":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['ResNet101',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","777bfa13":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","c3cee1a6":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_v3_weight_path = '..\/input\/tf-keras-pretrained-model-weights\/No Top\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\ninception = InceptionV3(\n    weights=\"imagenet\",\n    include_top=False, \n    input_shape=(224,224,3)\n)","445f6c60":"for layer in inception.layers:\n    layer.trainable = False","0ac8082b":"from tensorflow.keras import Sequential\nfrom keras import layers\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel = Sequential()\nmodel.add(inception)\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(layers.Dropout(rate=0.5))\nmodel.add(Dense(1024, activation='sigmoid'))\nmodel.add(layers.Dropout(rate=0.2))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(31,activation=\"sigmoid\"))\n\n# from tensorflow.keras.optimizers import RMSprop\n# from tensorflow.keras import Model,layers\n\n# last_layer = inception.get_layer('mixed7') \n# last_output = last_layer.output\n\n# # Flatten the output layer to 1 dimension\n# x = layers.Flatten()(last_output)\n# # Add a fully connected layer with 1,024 hidden units and ReLU activation\n# x = layers.Dense(1024, activation='relu')(x)\n# # Add a dropout layer to prevent overfitting\n# x = layers.Dropout(0.2)(x)                  \n# # Add a final sigmoid layer for classification\n# x = layers.Dense  (31, activation='softmax')(x)           \n\n# model = Model(inception.input, x)\n# model.compile(optimizer = RMSprop(lr=0.0001), \n#               loss = 'binary_crossentropy', \n#               metrics = ['accuracy'])\n    \n# model.summary()\n\n\n#Adding custom Layers\n\n# from tensorflow.keras.optimizers import SGD\n\n\n# x = inception.output\n# x = GlobalAveragePooling2D()(x)\n# x = Dense(1024, activation=\"relu\")(x)\n# x = Dropout(0.5)(x)\n# x = Dense(512, activation=\"relu\")(x)\n# predictions = Dense(31, activation=\"sigmoid\")(x)\n\n\n# # creating the final model \n# model_ = Model(inputs=inception.input, outputs=predictions)\n\n\n# # compile the model\n# model_.compile(optimizer=SGD(lr=0.0001, momentum=0.9)\n#                     , loss='categorical_crossentropy'\n#                     , metrics=['accuracy'])","737b9a83":"model.summary()\n\n\n# import tensorflow as tf\n# # Define a Callback class that stops training once accuracy reaches 99.9%\n# class myCallback(tf.keras.callbacks.Callback):\n#     def on_epoch_end(self, epoch, logs={}):\n#         if(logs.get('accuracy')>0.999):\n#             print(\"\\nReached 99.9% accuracy so cancelling training!\")\n#             self.model.stop_training = True\n\n","d1e1ba2d":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","b6c902c9":"# callbacks = myCallback()\n\n# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80, validation_data=(X_test,y_test1))","b4275608":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","9aeb83aa":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['InceptionV3',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","33645a24":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","9a619b5a":"# from keras.applications import InceptionResNetV2, preprocess_input\nimport tensorflow as tf\n# from keras import optimizers, applications\ninception_resnet_v2_weight_path = '..\/input\/tf-keras-pretrained-model-weights\/No Top\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel = tf.keras.applications.InceptionResNetV2(\n    weights=\"imagenet\",\n    include_top=False, \n    input_shape=(224,224,3)\n)","9e22e8da":"for layer in model.layers:\n    layer.trainable = False","6e931824":"from keras.models import Sequential, Model\nfrom tensorflow.keras import optimizers, applications\nfrom keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D, Input, BatchNormalization, Conv2D\n#Adding custom layers \n# x = model.output\n# x = Flatten()(x)\n# x = Dense(1024, activation=\"relu\")(x)\n# x = Dropout(0.5)(x)\n# predictions = Dense(31, activation=\"sigmoid\")(x)\n# model = Model(model.input, predictions)\n\n# model.compile(optimizers.RMSprop(lr=0.001, decay=1e-6),loss=focal_loss,metrics=[f2_score])\n\ninput_tensor = Input(shape=(224,224,3))\nbn = BatchNormalization()(input_tensor)\nx = model(bn)\nx = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(31, activation='sigmoid')(x)\nmodel = Model(input_tensor, output)\n","3a8d1402":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","5dad81a3":"# # Callbacks\n\n# checkpoint = ModelCheckpoint(\"model_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n# early = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')","b62e651f":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","bc9fef98":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","14aaebc1":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['InceptionResNetV2',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","307cfe59":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","3ebb0035":"# from keras.applications import InceptionResNetV2, preprocess_input\nimport tensorflow as tf\n# from keras import optimizers, applications\n# inception_resnet_v2_weight_path = '..\/input\/tf-keras-pretrained-model-weights\/No Top\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel = tf.keras.applications.MobileNet(\n    weights=\"imagenet\",\n    include_top=False, \n    input_shape=(224,224,3)\n)","8c00501c":"for layer in model.layers:\n    layer.trainable = False","bd9cab06":"from keras.models import Sequential, Model\nfrom tensorflow.keras import optimizers, applications\nfrom keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D, Input, BatchNormalization, Conv2D\n#Adding custom layers \n# x = model.output\n# x = Flatten()(x)\n# x = Dense(1024, activation=\"relu\")(x)\n# x = Dropout(0.5)(x)\n# predictions = Dense(31, activation=\"sigmoid\")(x)\n# model = Model(model.input, predictions)\n\n# model.compile(optimizers.RMSprop(lr=0.001, decay=1e-6),loss=focal_loss,metrics=[f2_score])\n\n# input_tensor = Input(shape=(224,224,3))\n# bn = BatchNormalization()(input_tensor)\nx = model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx=Dense(1024,activation='relu')(x) #dense layer 2\nx=Dense(512,activation='relu')(x) #dense layer 3\npreds=Dense(31,activation='sigmoid')(x) #final layer with softmax activation\n# x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n# x = Flatten()(x)\n# x = Dropout(0.5)(x)\n# x = Dense(512, activation='relu')(x)\n# x = Dropout(0.5)(x)\n# output = Dense(31, activation='sigmoid')(x)\nmodel=Model(inputs=model.input,outputs=preds)\n# model = Model(input_tensor, output)\n","09eadae0":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","ebbeffcd":"model.summary()","63f666f5":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","f7ff5893":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","969e580f":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['MobileNet',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","59a64e2e":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","38445e0a":"# from keras.applications import InceptionResNetV2, preprocess_input\nimport tensorflow as tf\n# from keras import optimizers, applications\n# inception_resnet_v2_weight_path = '..\/input\/tf-keras-pretrained-model-weights\/No Top\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel = tf.keras.applications.MobileNetV2(\n    weights=\"imagenet\",\n    include_top=False, \n    input_shape=(224,224,3)\n)","c480617f":"for layer in model.layers:\n    layer.trainable = False","7a31334d":"from keras.models import Sequential, Model\nfrom tensorflow.keras import optimizers, applications\nfrom keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D, Input, BatchNormalization, Conv2D\n#Adding custom layers \n# x = model.output\n# x = Flatten()(x)\n# x = Dense(1024, activation=\"relu\")(x)\n# x = Dropout(0.5)(x)\n# predictions = Dense(31, activation=\"sigmoid\")(x)\n# model = Model(model.input, predictions)\n\n# model.compile(optimizers.RMSprop(lr=0.001, decay=1e-6),loss=focal_loss,metrics=[f2_score])\n\n# input_tensor = Input(shape=(224,224,3))\n# bn = BatchNormalization()(input_tensor)\nx = model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx=Dense(1024,activation='relu')(x) #dense layer 2\nx=Dense(512,activation='relu')(x) #dense layer 3\npreds=Dense(31,activation='sigmoid')(x) #final layer with softmax activation\n# x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n# x = Flatten()(x)\n# x = Dropout(0.5)(x)\n# x = Dense(512, activation='relu')(x)\n# x = Dropout(0.5)(x)\n# output = Dense(31, activation='sigmoid')(x)\nmodel=Model(inputs=model.input,outputs=preds)\n# model = Model(input_tensor, output)\n","6db49f1e":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","cf9c45b6":"model.summary()","aa25c234":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","ee6765ba":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","42fe8079":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['MobileNetV2',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","a625fe2d":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","7d5d0bcd":"import tensorflow as tf\nnasnet_weight_path = \"..\/input\/tf-keras-pretrained-model-weights\/No Top\/NASNet-Large-no-top.h5\"\nbase_model = tf.keras.applications.NASNetLarge(input_shape=(224,224,3),include_top=False,weights=nasnet_weight_path)","9df76718":"for layer in base_model.layers:\n    layer.trainable=False","0c286e54":"# from keras.models import Sequential\n# from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n\n# model=Sequential()\n# model.add(base_model)\n# model.add(Dropout(0.5))\n# model.add(Flatten())\n# model.add(BatchNormalization())\n# model.add(Dense(32,kernel_initializer='he_uniform'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(32,kernel_initializer='he_uniform'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(32,kernel_initializer='he_uniform'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(Dense(31,activation='sigmoid'))\n\n\nfrom tensorflow.keras import Sequential\nfrom keras import layers\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Dense(256, activation='relu'))\nmodel.add(layers.Dropout(rate=0.5))\nmodel.add(Dense(128, activation='sigmoid'))\nmodel.add(layers.Dropout(rate=0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(31,activation=\"sigmoid\"))","2f5bfc43":"model.summary()","12983063":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","d384dae7":"# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\nhistory = model.fit(X_train,y_train1,batch_size=32,epochs=80,validation_data=(X_test,y_test1))","99857e2e":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Computing confusion matrix\n    cm = cnf_matrix_train\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n# Visualizing\n    fig, ax = plt.subplots(figsize=(7,7))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n   # Rotating the tick labels and setting their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n    # Looping over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\nnp.set_printoptions(precision=2)","277d153b":"# Model Performance for train Dataset\ny_pred = model.predict(X_train)\ny_pred = np.argmax(y_pred, axis=1)\ny_train = np.argmax(y_train1, axis=1)\n\nacc_train=format(accuracy_score(y_pred, y_train),'.3f')\nprecision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\nrecall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\nf1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n\ncnf_matrix_train = confusion_matrix(y_pred, y_train)\n\n\nFP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \nFN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\nTP = np.diag(cnf_matrix_train)\nTN = cnf_matrix_train.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_train = TNR\n\n# Model Performance for test Dataset\ny_test_pred = model.predict(X_test)\ny_test_pred = np.argmax(y_test_pred, axis=1)\ny_test = np.argmax(y_test1, axis=1)\n\nacc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\nprecision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\nrecall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\nf1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n\ncnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n\nFP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \nFN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\nTP = np.diag(cnf_matrix_test)\nTN = cnf_matrix_test.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP)\nspecificity_test = TNR\n\nn_classes = y_train1.shape[1]-1\nclass_names = []\nfor i in range(n_classes):\n  class_names.append(i)\n\nplot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'NN Confusion Matrix train')\nplot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'NN Confusion Matrix test')\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Specificity(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[],\n                           'Specificity(test)':[],\n                          })\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['NasNetLarge',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\nevaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n","1d079761":"y_score_train = model.predict(X_train)\n\nn_classes = y_train1.shape[1]\n# n_classes = n_classes - 1\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nplt.figure(figsize = (15,12))\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_train1[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Train Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_train = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc train:\", average_auc_train)\n\n\n\n\ny_score_test = model.predict(X_test)\n\nn_classes = y_train1.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = cycle(['blue', 'red', 'green'])\nplt.figure(figsize = (15,12))\nfor i, color in zip(range(n_classes), colors):\n    if i == 0:\n      continue\n    else:\n      plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of person {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k-', lw=1.5)\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve of NN for Test Data')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfor i in (roc_auc):\n  if float('-inf') < roc_auc[i] < float('inf'):\n    roc_auc[i] = roc_auc[i]\n  else:\n    roc_auc[i] = 0\nfiltered_vals = [v for _, v in roc_auc.items() if v != 0]\naverage_auc_test = sum(filtered_vals) \/ len(filtered_vals)\nprint(\"Average auc test:\", average_auc_test)","a66fb0d6":"# Training MobileNet","ed6f3a95":"# ROC Curve VGG19","5efdd429":"# Precision Recall InceptionResNetV2","6fd60281":"# ROC Curve VGG16","daf0b3a6":"# Training VGG19","67641410":"# Plot Confusion Matrix InceptionResNetV2","62f47519":"# Plot Confusion Matrix MobileNetV2","208184de":"# ROC Curve MobileNetV2","0c7fe3f6":"# ROC Curve ResNet101","6b575819":"## **creating model VGG16**","ebfa1de5":"# **InceptionResNetV2**","e45910a5":"**Create Dataset**","fbf3005e":"# Precision Recall F1 Confusion Matrix VGG19","62e97f0e":"# Precision Recall NasNetLarge","d6171e89":"**Import Images**","6f8d521b":"# VGG19","6dcb7108":"# Plot Confusion Matrix VGG19","739cc0bc":"# Precision Recall F1 Confusion Matrix ResNet50","b8996abb":"# ResNet101","4e0578ac":"# Training InceptionResNetV2","71515f61":"# Training ResNet50","38a7fe2e":"## **Plot confision matrix VGG16** ","ebe2c121":"## **Dividing dataset into x(features) & y(target)**","c6098a5c":"# Training MobileNetV2","0cb63c9e":"# Precesion Recall ResNet101","46739e5a":"# Plot Confusion Matrix MobileNet","ca8c3a00":"# Plot Confusion Matrix ResNet50","015a65e5":"# Plot Confusion Matrix NasNetLarge","2044d7d0":"## **Training the model VGG16** ","6885eae9":"# **MobileNet**","756ed04c":"# ROC Curve InceptionV3","4f410ca5":"# Plot Confusion Matrix InceptionV3","e0b22371":"# Precesion Recall ResNet152","c14564cb":"# Precision Recall InceptionV3","644cc3d2":"# **NasNetLarge**","ee04bee9":"# Training ResNet152","f70e4751":"# Precision Recall MobileNetV2","77057a47":"# Training NasNetLarge","fc41a0a3":"# Training ResNet101","3d73233c":"# Plot Confusion Matrix ResNet101","1fbb31c4":"# Precision Recall MobileNet","c13d370a":"# ROC Curve InceptionResNetV2","2f550ce5":"**Import all Libraries**","1f77a343":"# ROC Curve ResNet152","01f17ee6":"# Plot Confusion Matrix ResNet152","725e90b1":"# ROC Curve ResNet50","e687c61b":"# ROC Curve MobileNet","d3648262":"# Inception V3","99af2115":"# Traing InceptionV3","2e8b9e35":"# ResNet50","1bae1fe8":"# ROC Curve NasNetLarge","f8a70d18":"**Plot Data**","509d2191":"# Precision Recall F1 Confusion Matrix VGG16","02bd36be":"# ResNet152","ca1b785d":"# **MobileNetV2**"}}