{"cell_type":{"32d77a0b":"code","fb50b885":"code","6988f0b2":"code","11338c9c":"code","6a8a32e1":"code","5cca72a3":"code","f749ad53":"code","dc96ca8e":"code","a6c34a3a":"code","4c1b715c":"code","5bc42d3d":"code","d2f41483":"code","20b1de9a":"code","2951e8eb":"code","b2639ad4":"code","39885f53":"code","1c4502ce":"code","1bae701a":"code","3ed9ca5e":"code","893b0d52":"code","c69ab2cd":"code","4c4780e2":"code","ad44c79e":"code","609781d5":"code","2b5b8559":"code","c9f14672":"code","d6a8e814":"markdown","8ad441da":"markdown","91b4dc3a":"markdown","2a754444":"markdown","b3fcc513":"markdown","c435a6d9":"markdown","57b620cc":"markdown","16938802":"markdown","6a78a6bf":"markdown"},"source":{"32d77a0b":"from IPython.core.display import display, HTML, Javascript\n\ndef ApplyCustomCSS():\n    return HTML(\"<style>\"+open(\"..\/input\/customcss\/custom_kaggle_forCommit.css\", \"r\").read()+\"<\/style>\")\n\nApplyCustomCSS()","fb50b885":"import numpy as np\nimport pandas as pd\nimport warnings as w\nfrom scipy import spatial\nfrom tqdm.notebook import tqdm\nimport random, math, cv2, os, string, re, gc\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers as L\nimport tensorflow.keras as K\nfrom sklearn.model_selection import train_test_split\nimport cudf, cuml, cupy\nfrom cuml.neighbors import NearestNeighbors\nfrom cuml.feature_extraction.text import TfidfVectorizer\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n\nw.filterwarnings('ignore')\n\nTRAIN_BASE = '..\/input\/shopee-product-matching\/train_images\/'\nTEST_BASE = '..\/input\/shopee-product-matching\/test_images\/'\nSEED = 100\nIMG_SIZE = 444\nEPOCHS = 2\n\nsample_sub = pd.read_csv(\"..\/input\/shopee-product-matching\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/shopee-product-matching\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/shopee-product-matching\/train.csv\")\n\n# train = pd.concat([train, train, train[:2000]], axis = 0)\n# train.reset_index(drop = True, inplace = True)\n# print(\"shape: \", train.shape)\n\ntrain.head()","6988f0b2":"IS_GPU_AVAIL = tf.config.experimental.list_physical_devices('GPU')\nif IS_GPU_AVAIL:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(IS_GPU_AVAIL[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*6.0)])\n        lgpu = tf.config.experimental.list_logical_devices('GPU')\n        \n    except RuntimeError as ex:\n        print(ex)\n        \nprint(f'Tensorflow GPU space 6GB GPU RAM')\nprint('RAPIDS GPU space 10GB GPU RAM')","11338c9c":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \ndef process_data(df):\n    label_to_encoded = {idx:item for idx,item in enumerate(df.label_group.unique())}\n    encoded_to_label = {item:idx for idx,item in enumerate(df.label_group.unique())}\n    classes = df.label_group.nunique()\n    return label_to_encoded, encoded_to_label, classes\n\nseed_everything(SEED)\nlabel_to_encoded, encoded_to_label, NUM_CLASSES = process_data(train)\n\nfor col in train.columns:\n    print(f\"Number of unique {col} entries : \", train[col].nunique(), \" against the dataset of size \", train.shape)","6a8a32e1":"# size = set()\n# for i in train['image'].values:\n#     img = cv2.imread(TRAIN_BASE+i)\n#     sh = tuple(img.shape)\n#     size.add(sh)\n\n# sizel = list(size)\n\n# ## sorting the size array based on width\n# sizel = sorted(sizel, key = lambda x: x[1])\n# IMG_SIZEavg = int(np.average([i for i in sizel]))\n\n# print(\"Taking the average of all the images sizes \", IMG_SIZEavg)\n# sizel[:5], sizel[-5:]\n# gc.collect()","5cca72a3":"for IMG_IDX in [1,2]: \n    temp_img = cv2.imread(TRAIN_BASE+train['image'].values[IMG_IDX])\n    ct = cv2.resize(temp_img, (IMG_SIZE, IMG_SIZE))\n\n    print(temp_img.shape, \" => \", ct.shape)\n\n    plt.subplot(1,2,1)\n    plt.imshow(temp_img)\n    plt.subplot(1,2,2)\n    plt.imshow(ct)\n    plt.show()","f749ad53":"if test.shape[0] == 3:\n    for IMG_IDX in range(3): \n        temp_img = cv2.imread(TEST_BASE+test['image'].values[IMG_IDX])\n        ct = cv2.resize(temp_img, (IMG_SIZE, IMG_SIZE))\n\n        print(temp_img.shape, \" => \", ct.shape)\n        print(\"Title : \", test['title'].values[IMG_IDX])\n        plt.imshow(temp_img)\n        plt.imshow(ct)\n        plt.show()","dc96ca8e":"best10 = train['label_group'].value_counts().index.tolist()[:10]\nbest10_vals = train['label_group'].value_counts().tolist()[:10]\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=best10, y=best10_vals, palette=\"vlag\")\nplt.xticks(rotation=45)\nplt.xlabel(\"Label_Group\")\nplt.ylabel(\"Num of Images\")\nplt.title(\"Top 10 Labels by Images Count\")\nplt.show()","a6c34a3a":"worst10 = train['label_group'].value_counts().index.tolist()[-10:]\nworst10_vals = train['label_group'].value_counts().tolist()[-10:]\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=worst10, y=worst10_vals, palette=\"rocket\")\nplt.xticks(rotation=45)\nplt.xlabel(\"Label_Group\")\nplt.ylabel(\"Num of Images\")\nplt.title(\"10 Worst Labels by Images Count\")\nplt.show()","4c1b715c":"for item in train.label_group.unique()[3001:3004]: \n    df_temp = train[train.label_group == item]\n    \n    cols = df_temp.shape[0]\n    fig = plt.figure(figsize=(10,20))\n    for idx,(index,row) in enumerate(df_temp.iterrows()):\n        temp_img = cv2.imread(TRAIN_BASE+row.image)\n        ct = cv2.resize(temp_img, (IMG_SIZE, IMG_SIZE))\n        plt.subplot(1,cols,idx+1)\n        plt.imshow(temp_img)\n        plt.axis('off')\n    \n    print('\\033[1m' + '\\033[36m'+\"Group Label\"+'\\033[0m', item)\n    print('\\033[1m' + '\\033[32m'+\"Number of items in Group \"+'\\033[0m', cols)\n    print('\\033[1m' + '\\033[33m'+\"The Group Label Titles are \"+'\\033[0m', df_temp.title.to_list())\n    plt.show()","5bc42d3d":"for IMG_IDX in [1,2]: \n    temp_img = cv2.imread(TRAIN_BASE+train['image'].values[IMG_IDX*1000])\n    dims = np.shape(temp_img)\n    ct = np.reshape(temp_img, (dims[0] * dims[1], dims[2]))\n\n    print(dims, \" => \", ct.shape)\n    plt.title(train['label_group'].values[IMG_IDX*1000])\n    sns.distplot(ct[:,0], bins=15)\n    sns.distplot(ct[:,1], bins=15)\n    sns.distplot(ct[:,2], bins=15)\n    plt.show()","d2f41483":"def plot_hist(col, xlabel, ylabel, title):\n    ax = plt.subplots(figsize =(10, 5));\n    ax = sns.distplot(temp_nlp[col], kde=True);\n    ax.set_ylabel(ylabel, size=15)\n    ax.set_xlabel(xlabel, size=15)\n    ax.set_title(title, size=20)\n    plt.show()\n    \ntemp_nlp = train.copy()\ntemp_nlp['title_len'] = temp_nlp['title'].apply(lambda x: len(x))\ntemp_nlp['title_word_count'] =temp_nlp[\"title\"].apply(lambda x: len(str(x).split(\" \")))\ntemp_nlp['title_char_count'] = temp_nlp[\"title\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\ntemp_nlp['title_avg_word_length'] = temp_nlp['title_char_count'] \/ temp_nlp['title_word_count']","20b1de9a":"groups = temp_nlp.label_group.value_counts()\n\nplt.figure(figsize=(20,5))\nplt.plot(np.arange(len(groups)),groups.values)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Index of Unique Item',size=14)\nplt.title('Duplicate Count vs. Unique Item Count',size=16)\nplt.show()","2951e8eb":"wordcloud = WordCloud(background_color='white', stopwords=STOPWORDS, width=2560, height=1440).generate(' '.join(train['title']))\n\nax = plt.subplots(figsize=(15, 15), facecolor='w')\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.tight_layout(pad=0)","b2639ad4":"for col,x,y,title in [('title_len', 'Length Of Title', 'Num Observations', 'Distribution of Title Length'),\n          ('title_word_count', 'Num Words', 'Num Observations', 'Distribution of Word Count for Title'),\n          ('title_char_count', 'Num Characters', 'Num Observations', 'Distribution of Characters for Title'),\n          ('title_avg_word_length', 'Avg Word Length', 'Num Observations', 'Distribution of Avg Word Length for Title')]:\n    plot_hist(col,x,y,title)\ndel temp_nlp","39885f53":"PREDICT_SCORE = True\nTRAINING = True\nif len(test) > 3:\n    TRAIN_BASE = TEST_BASE\n    ## Right now i am creating a dummy label column for test data later on i will predict this column as well\n    dummy_label_group = list(train.label_group.values)*3\n    test['label_group'] = dummy_label_group[:test.shape[0]].copy()\n    train = test\n    PREDICT_SCORE = False\n    TRAINING = False\ndel test","1c4502ce":"class DataGenerator(K.utils.Sequence):\n    def __init__(self, df, batchSize, code_to_labels, filepath = TRAIN_BASE, shuffle = False, \n                 img_size = IMG_SIZE, classes = NUM_CLASSES):\n        self.df = df\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(df))\n        self.path = filepath\n        self.batch = batchSize \n        self.img_size = IMG_SIZE\n        self.label_dict = code_to_labels\n        self.n_classes = classes\n        \n    def __len__(self):\n        '''Total number of steps in a epoch'''\n        return int(np.floor(self.df.shape[0]\/self.batch))\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __getitem__(self, index):\n        '''Generate One batch of files'''\n        indexes = self.indexes[index*self.batch:(index+1)*self.batch]\n        temp_df = self.df.iloc[indexes]\n        X = np.zeros(((len(indexes), self.img_size, self.img_size, 3)))\n        Y = np.zeros((self.batch, 1))\n        for idx,(index, row) in enumerate(temp_df.iterrows()):\n            img = cv2.imread(self.path + row.image)\n            X[idx,] = cv2.resize(img, (self.img_size, self.img_size)) \/ 255\n            Y[idx,] = self.label_dict[row.label_group]\n        return X, tf.keras.utils.to_categorical(Y, num_classes=self.n_classes)\n\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection \/ (len_y_pred + len_y_true)\n    return f1\n\ndef clean(text):\n    text = ''.join([k for k in text if k not in string.punctuation])\n    text = str(text).lower()\n    text = re.sub('[^a-zA-Z]', ' ', text)\n    text = re.sub(' +', ' ', text)\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  \n                               u\"\\U0001F300-\\U0001F5FF\"  \n                               u\"\\U0001F680-\\U0001F6FF\"  \n                               u\"\\U0001F1E0-\\U0001F1FF\"  \n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    return text\n\n\ndef train_test_split_data(df, features, label, test_size = 0.33):\n    train_x, val_x, train_y, val_y = train_test_split(df[features], df[label], test_size = test_size,\n                                                      random_state = SEED, shuffle = True, stratify = df[label])\n    return train_x, val_x, train_y, val_y\n\ndef learning_rate_scheduler():\n    starting_pt_lr   = 0.0001\n    exp_decay = 0.1\n    def lrfn(epoch):\n        if epoch < 5:\n            return starting_pt_lr\n        else:\n            return starting_pt_lr * math.exp(-exp_decay * epoch)\n    lr = K.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr\n\ntqdm.pandas()\ntrain['title'] = train['title'].progress_apply(clean)","1bae701a":"train_x, val_x, train_y, val_y = train_test_split_data(train, ['image'], ['label_group'])\ntrain_x['label_group'] = train_y\ntrain_x.reset_index(inplace = True, drop = True)\nval_x['label_group'] = val_y\nval_x.reset_index(inplace = True, drop = True)\n\nparams = {'batchSize': 5,\n          'code_to_labels': encoded_to_label,\n          'filepath': TRAIN_BASE,\n          'shuffle': False,\n          'img_size' : IMG_SIZE,\n          'classes' : NUM_CLASSES}\n\ntraining_generator = DataGenerator(train_x, **params)\nvalidation_generator = DataGenerator(val_x, **params)\ncomplete_generator = DataGenerator(train[['image', 'label_group']], **params)\n\ngc.collect()","3ed9ca5e":"def get_multi_pretrained_model(pretrained_layer1, \n                               pretrained_layer2, \n                               classes = NUM_CLASSES):\n    \n    inp = L.Input(shape = (IMG_SIZE, IMG_SIZE, 3))\n    \n    ## PretrainedLayer 1\n    a = pretrained_layer1(inp)\n    a = L.GlobalAveragePooling2D()(a)\n    a = L.Dense(750, activation = 'relu')(a)\n    a = L.BatchNormalization()(a)\n    \n    ## PretrainedLayer2\n    b = pretrained_layer2(inp)\n    b = L.GlobalAveragePooling2D()(b)\n    b = L.Dense(750, activation = 'relu')(b)\n    b = L.BatchNormalization()(b)\n    \n    x1 = L.concatenate([a,b])\n    x = L.Dense(2048, activation = 'relu')(x1)\n    out = L.Dense(classes, activation = 'softmax')(x)\n\n    model = K.models.Model(inputs = inp, \n                           outputs = out)\n    image_embeddings = K.models.Model(inputs = inp, \n                           outputs = x1)\n    opt = K.optimizers.Adam(learning_rate = 0.0001)\n\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=opt, \n                  metrics=['accuracy'])\n    return model, image_embeddings\n\npretrained_layer1 = K.applications.EfficientNetB0(include_top=False, \n                                                  weights='imagenet', \n                                                  input_shape=(IMG_SIZE, IMG_SIZE, 3))\npretrained_layer2 = K.applications.InceptionV3(include_top=False, \n                                               weights='imagenet', \n                                               input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\nmodel_pretranied, image_embeddings = get_multi_pretrained_model(pretrained_layer1, \n                                                                pretrained_layer2)\n\nimage_embeddings.summary()","893b0d52":"if TRAINING: \n    checkpt = tf.keras.callbacks.ModelCheckpoint(f'model_weights_{SEED}.h5', \n                                                 monitor='val_loss', \n                                                 verbose=1, \n                                                 save_best_only=True,\n                                                 save_weights_only=True, \n                                                 mode='min')\n    checkpointeffnet = tf.keras.callbacks.ModelCheckpoint('best_model_eff_net.h5', \n                                                          monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n    # Train model on dataset\n    model_pretranied.fit_generator(generator = training_generator, \n                        epochs = EPOCHS,\n                        validation_data=validation_generator,\n                        callbacks = [learning_rate_scheduler(), checkpt])\nelse:\n    model.load_weights(f'competition_data\/model_weights_{SEED}.h5')\n    \nimage_embeddings = image_embeddings.predict(complete_generator, \n                                batch_size=10, \n                                verbose = 0)\n\"Image embedding shape is :- \", image_embeddings.shape","c69ab2cd":"x_tr = train['title']\ny_tr = train['label_group']\ntokenizer = Tokenizer()\n\ntokenizer.fit_on_texts(list(x_tr))\n\nx_tr_seq  = tokenizer.texts_to_sequences(x_tr) \nx_tr_seq  = pad_sequences(x_tr_seq, maxlen=50)\n\nsize_of_vocabulary=len(tokenizer.word_index) + 1 # +1 for padding\nprint(size_of_vocabulary)","4c4780e2":"embeddings_index = {}\nwith open(\"..\/input\/pretrainedfiles\/model.txt\", encoding='utf-8', errors='ignore') as f:\n    for line in f:\n        word, coefs = line.split(maxsplit=1)\n        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n        embeddings_index[word] = coefs\n\nprint(\"Found %s word vectors.\" % len(embeddings_index))","ad44c79e":"embedding_matrix = np.zeros((size_of_vocabulary, 100))\n\nfor word, i in tokenizer.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n        \ndel embeddings_index","609781d5":"def get_text_model():\n    inp = K.layers.Input(shape=(50,))\n    embed = K.layers.Embedding(size_of_vocabulary,100,weights=[embedding_matrix],trainable=True)(inp)\n    lstm = K.layers.LSTM(16,return_sequences=True,dropout=0.2)(embed)\n    pool = K.layers.GlobalMaxPooling1D()(lstm)\n\n    dense1 = K.layers.Dense(512,activation='relu')(pool)\n    out = K.layers.Dense(NUM_CLASSES,activation='sigmoid')(dense1)\n    \n    model = K.models.Model(inputs = inp, outputs = out)\n    embedding_model = K.models.Model(inputs = inp, outputs = pool)\n    #Add loss function, metrics, optimizer\n    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"acc\"]) \n    return model, embedding_model\n\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \ncheckpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)\n\nmodel_text, embedding_model = get_text_model()\n\n# embedding_model.summary()\n# model_text.fit(np.array(x_tr_seq),tf.keras.utils.to_categorical(y_tr),\n#                     batch_size=2,epochs=2,\n# #                     validation_data=(np.array(x_val_seq),np.array(y_val)),\n#                     verbose=1,callbacks=[earlystopping, checkpoint])","2b5b8559":"def get_text_predictions(df, max_features = 25_000):\n    \n    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    preds = []\n    CHUNK = 1024*4\n\n    print('Finding similar titles...')\n    CTS = len(df)\/\/CHUNK\n    if len(df)%CHUNK!=0: CTS += 1\n    for j in range( CTS ):\n\n        a = j*CHUNK\n        b = (j+1)*CHUNK\n        b = min(b,len(df))\n        print('chunk',a,'to',b)\n\n        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n\n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>0.75)[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(\" \".join(o))\n    \n    del model,text_embeddings\n    gc.collect()\n    return preds\n\ndf_cu = cudf.DataFrame(train)\ntext_preds = get_text_predictions(train)","c9f14672":"def combine_preds(x):\n    all_combined = x['image_preds']+\" \"+ x['text_preds']\n    return ' '.join( set(all_combined.split(\" \")) )\n\ndef get_nearest_neighors(df, embeds, n = 50, image = True, predict_score = PREDICT_SCORE):\n    model = NearestNeighbors(n_neighbors = n)\n    model.fit(embeds)\n    dist_arr, idx_arr = model.kneighbors(embeds)\n    if predict_score:\n        scores = []\n        if image:\n            print(\"Predicting for image\")\n            scores = np.arange(0,10.0,0.5)\n        else:\n            print(\"Predicting for text\")\n            scores = np.arange(20,35,0.5)\n            \n        allscores = []\n        for th in scores:\n            preds = []\n            for idx in range(embeds.shape[0]):\n                index_clear_of_th = np.where(dist_arr[idx,] < th)[0]\n                preds.append(' '.join(df.posting_id.iloc[idx_arr[idx,index_clear_of_th]].values))\n            \n            df[\"pred_values\"] = preds\n            df[\"f1_score\"] = f1_score(df['matches'], df['pred_values'])\n            print(f\"f1 Score for the threshold {th} is {df['f1_score'].mean()}\")\n            allscores.append(df['f1_score'].mean())\n        \n        score_df = pd.DataFrame({\"All_Scores\" : allscores, \"Thresholds\" : scores})\n        best_record = score_df[score_df.All_Scores == score_df.All_Scores.max()]\n        print(f\"Best iteration is with score {best_record.All_Scores.values} and threshold {best_record.Thresholds.values}\")\n        \n        preds = []\n        th = best_record.Thresholds.values[0]\n            \n        for idx in range(embeds.shape[0]):\n            index_clear_of_th = np.where(dist_arr[idx,] < th)[0]\n            preds.append(\" \".join(df.posting_id.iloc[idx_arr[idx,index_clear_of_th]].values))\n            \n    else:\n        preds = []\n        th = 0\n        if image:\n            print(\"Predicting for image\")\n            th = 2.4\n        else:\n            print(\"Predicting for text\")\n            th = 24.0\n            \n        for idx in range(embeds.shape[0]):\n            index_clear_of_th = np.where(dist_arr[idx,] < th)[0]\n            preds.append(\" \",join(df.posting_id.iloc[idx_arr[idx,index_clear_of_th]].values))\n            \n    return df, preds\n\nif PREDICT_SCORE:\n    tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n    train['matches'] = train['label_group'].map(tmp)\n    train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n    \ntrain, image_preds = get_nearest_neighors(train, image_embeddings, n = 50, image = True)\n# train, text_preds = get_nearest_neighors(train, text_embeddings, n = 50, image = False)\n\ntrain['image_preds'] = image_preds\ntrain['text_preds'] = text_preds\ntrain['matches'] = train.apply(combine_preds, axis = 1)\ntrain[['posting_id', 'matches']].to_csv('submission.csv', index = False)","d6a8e814":"## Evaluation Criteria\nWe will be using mean F score on the data set. F1-Score :-\n> In statistical analysis of binary classification, the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all positive results, including those not identified correctly, and the recall is the number of true positive results divided by the number of all samples that should have been identified as positive. Precision is also known as positive predictive value, and recall is also known as sensitivity in diagnostic binary classification.\n\n<center><img src = \"https:\/\/miro.medium.com\/max\/1530\/1*wUdjcIb9J9Bq6f2GvX1jSA.png\" width = \"550\" height = \"150\"\/><\/center>\n\n<center><img src = \"https:\/\/miro.medium.com\/max\/1872\/1*pOtBHai4jFd-ujaNXPilRg.png\" width = \"750\" height = \"250\"\/><\/center>\n\n> In pattern recognition, information retrieval and classification (machine learning), precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of relevant instances that were retrieved. Both precision and recall are therefore based on relevance.\n\n> Suppose a computer program for recognizing dogs (the relevant element) in photographs identifies eight dogs in a picture containing ten cats and twelve dogs, and of the eight it identifies as dogs, five actually are dogs (true positives), while the other three are cats (false positives). Seven dogs were missed (false negatives), and seven cats were correctly excluded (true negatives). The program's precision is then 5\/8 (true positives \/ all positives) while its recall is 5\/12 (true positives \/ relevant elements).\n\nwhere :-\n* TP = True Positive\n* FP = False Positive\n* TN = True Negative\n* FN = False Negative","8ad441da":"## Data Set Information\n[train\/test].csv - the training set metadata. Each row contains the data for a single posting. Multiple postings might have the exact same image ID, but with different titles or vice versa.\n\nposting_id - the ID code for the posting.\nimage - the image id\/md5sum.\nimage_phash - a perceptual hash of the image.\ntitle - the product description for the posting.\nlabel_group - ID code for all postings that map to the same product. Not provided for the test set.\n\ntrain\/test images - the images associated with the postings.\n\n### Importing Dependencies","91b4dc3a":"### <center>If you find this notebook useful and resourceful, do leave behind a upvote. I will be updating this notebook on a regular basis, so please check back once new version comes up.\u2620\ufe0f\u2620\ufe0f<\/center>","2a754444":"## Now Lets do some digging\n\nGetting to know the data from the features prespective.\n\n### Label Sorting and Discovery","b3fcc513":"## Lets Just Build the model","c435a6d9":"### Learning through and about NLP\n#### Label Distribution","57b620cc":"If you wanna know more about modifying how a notebook look then please visit the Kaggle topic here [Click Here](https:\/\/www.kaggle.com\/discussion\/230082)","16938802":"## Optimum Image Size\n\nFinding the average of height and width of all the images. As in the dataset the images size vary from 100x100 to something like 5000x5000, which is a vast range so taking the average should suffice because if a particular image is trimmed down too much the pixels start overlapping and is a image expanded to much then one pixel covers a very large portion ","6a78a6bf":"<h1><center>EDA + Submission Code<\/center><\/h1>\n                                                      \n<center><img src = \"https:\/\/miro.medium.com\/max\/576\/1*NzmIA9eUULy-hNyVOF9g5A.png\" width = \"750\" height = \"500\"\/><\/center>"}}