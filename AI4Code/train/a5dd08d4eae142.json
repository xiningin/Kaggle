{"cell_type":{"e7a33618":"code","455578bb":"code","4127da00":"code","e62980df":"code","b5848ab3":"code","69df210d":"code","aeb7ba48":"code","1ee47307":"code","2da5f6ea":"code","03aa304f":"code","2507cc28":"code","8574aeb6":"code","2fdad965":"code","c432179b":"code","c020680a":"code","f01d293e":"code","b902c651":"code","9364e9fb":"code","5eac4790":"code","407b731a":"code","ae051720":"code","94712ed3":"code","65377bf8":"code","9afef844":"code","462dde16":"code","275a31a0":"code","aab30eae":"code","9df90307":"code","2bf82313":"code","05ea8610":"code","e686de2c":"code","dff4a434":"code","546a3901":"code","722f8b42":"code","c59f45bf":"code","c4010b1f":"code","1d784b84":"code","0e099e43":"code","baa24f9f":"code","56f0517a":"code","82862022":"code","fa299bfb":"code","8d6c5bbd":"code","ce478296":"code","87c5a1a2":"code","c3d1450b":"code","9f606cc2":"code","5afba10f":"code","61714980":"code","e4cf09eb":"code","2a61d22f":"code","e003a47d":"code","5aeafb5e":"code","b3f916fd":"code","34a217a3":"code","81694ab7":"markdown","ae633ca9":"markdown","9ad2b094":"markdown","39e274f7":"markdown","5ce63577":"markdown","34413e66":"markdown","142fb518":"markdown","f7f8e930":"markdown","ed78c437":"markdown","9642bfad":"markdown","4f42fb85":"markdown","b59d056a":"markdown","d6f27b40":"markdown","7a6ab99b":"markdown","61d2b44b":"markdown"},"source":{"e7a33618":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","455578bb":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)","4127da00":"df = pd.read_csv('\/kaggle\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv')","e62980df":"df.head()","b5848ab3":"df.shape","69df210d":"#checking area group by area_type\ndf.groupby('area_type')['area_type'].agg('count')","aeb7ba48":"#df1 = df.drop('area_type','availability','location','size','society','total_sqft','bath','balcony')\ndf1 = df.drop(['area_type','availability','society','balcony'],axis='columns')\ndf1.head()","1ee47307":"df1.isnull().sum()","2da5f6ea":"df2 = df1.dropna()\ndf2.isnull().sum()","03aa304f":"df2['size'].unique()","2507cc28":"df2['bhk'] = df2['size'].apply(lambda x: int(x.split(' ')[0]))","8574aeb6":"df2['bhk'].unique()","2fdad965":"df2[df2['bhk']>20]","c432179b":"df.total_sqft.unique()","c020680a":"def is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","f01d293e":"df2[~df2['total_sqft'].apply(is_float)]","b902c651":"def convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return ((float(tokens[0])+float(tokens[1]))\/2)\n    try:\n        return float(x)\n    except:\n        return None","9364e9fb":"convert_sqft_to_num('2830 - 2882')","5eac4790":"df4 = df2.copy()\ndf4['total_sqft'] =df4['total_sqft'].apply(convert_sqft_to_num)\ndf4.head()","407b731a":"print(df4.loc[30])\ndf5 = df4.copy()\ndf5['price_per_sqft'] = df5['price']*100000\/df5['total_sqft']\nprint(df5.head())","ae051720":"len(df.location.unique())","94712ed3":"df5.location = df5.location.apply(lambda x: x.strip())\nlocation_stats = df.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats","65377bf8":"len(location_stats[location_stats <=10])\nlocation_stats_less_than_10 = location_stats[location_stats <=10]","9afef844":"len(df5.location.unique())","462dde16":"df5.location = df5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\nprint(len(df5.location.unique()))\ndf5.head()","275a31a0":"df5[df5.total_sqft\/df5.bhk < 300].head()","aab30eae":"print(df5.shape)\nprint(df5[df5.total_sqft\/df5.bhk < 300].shape)","9df90307":"df6 = df5[~(df5.total_sqft\/df5.bhk < 300)]\ndf6.shape","2bf82313":"df6.price_per_sqft.describe()","05ea8610":"def remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf['price_per_sqft']>(m-st)) & (subdf['price_per_sqft']<=(m+st))]\n        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n    return df_out\n\ndf7 = remove_pps_outliers(df6)\n","e686de2c":"df7.shape","dff4a434":"def plot_scatter_chart(df,location):\n    bhk2 = df[(df.location == location) & (df.bhk ==2)]\n    bhk3 = df[(df.location == location) & (df.bhk ==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 bhk',s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,color='green',label='3 bhk',s=50, marker='+')\n    plt.xlabel('Total Square Feet Area')\n    plt.ylabel('Price')\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df7,\"Hebbal\")","546a3901":"{\n    '1':{\n        'mean':4000,\n        'std':2000,\n        'count':34\n    },\n    '2':{\n        'mean':4300,\n        'std':2300,\n        'count':22\n    }\n}","722f8b42":"def remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    return df.drop(exclude_indices,axis='index')\ndf8 = remove_bhk_outliers(df7)\n# df8 = df7.copy()\ndf8.shape","c59f45bf":"plot_scatter_chart(df8,\"Hebbal\")","c4010b1f":"import matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df8.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","1d784b84":"df8.bath.unique()","0e099e43":"plt.hist(df8.bath,rwidth=0.8)\nplt.xlabel(\"Number of bathrooms\")\nplt.ylabel(\"Count\")","baa24f9f":"df8[df8.bath>10]","56f0517a":"df8[df8.bath>df8.bhk+2]","82862022":"df9 = df8[df8.bath<df8.bhk+2]\ndf9.shape","fa299bfb":"df10 = df9.drop(['size','price_per_sqft'],axis= 'columns')\ndf10.head()","8d6c5bbd":"dummies = pd.get_dummies(df10.location)\ndummies.head(3)","ce478296":"df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\ndf11.head()","87c5a1a2":"df12 = df11.drop('location',axis='columns')\ndf12.head()","c3d1450b":"X = df12.drop('price',axis='columns')\ny = df12.price\nX.head(3)","9f606cc2":"y.head(3)","5afba10f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=10)","61714980":"from sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train,y_train)\nlr_clf.score(X_test,y_test)","e4cf09eb":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state= 0)\ncross_val_score(LinearRegression(),X,y, cv=cv)","2a61d22f":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression' : {\n            'model' : LinearRegression(),\n            'params' : {\n                'normalize': [True,False]\n            }\n        },\n        'lasso' : {\n            'model' : Lasso(),\n            'params' :{\n                'alpha' :[1,2],\n                'selection' : ['random','cyclic']\n            }\n            \n        },\n        'decision_tree' : {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter' : ['best','random']\n            }\n        }\n        \n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs = GridSearchCV(config['model'],config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        }\n        )\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,y)\n    ","e003a47d":"def predict_price(location, sqft,bath,bhk):\n    loc_index = np.where(X.columns==location)[0][0]\n    \n    x= np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0:\n        x[loc_index] = 1\n    return lr_clf.predict([x])[0]","5aeafb5e":"predict_price('1st Phase JP Nagar', 1000,2,2)","b3f916fd":"predict_price('1st Phase JP Nagar', 1000,3,2)","34a217a3":"predict_price('1st Phase JP Nagar', 1020,3,3)","81694ab7":"# ****Removing outliers, outliers are those which could be irrelavent or very unusaul as per business and keeping them and training model with them will impact your prediction model.","ae633ca9":"# Lets put threashold to location, where location less than 10 to be other location. This will reduce locations and we can use onehot encoding","9ad2b094":"# ****Import dataset","39e274f7":"# After this i created pickle file which will store coefficent, x,y inetercet.. etc not data.\n# then i create json file to export all columns\n# ill call flask module for servicing http response\n# Then i created UI which will be fairily simple with one html,css, json file.\n# Then i tested its GET and POST request from UI.\n# Then i created one instance of Ubuntu on Amazon AWS\n# Then i installed one server nginx on Ubuntu\n# Updated configs of nginx to point to my web UI\n# Then i run server.py script which contains flask which will serve http request and generate dynamic result by 2methods i have created in server.py\n# My website live on Amazon AWS\n","5ce63577":"Finding total sqft where is not a number. Then we will clean it","34413e66":"# Cleanup completed completed mostly","142fb518":"# Cannot use one hot encoding or dummy column .. because then there will be too many columns and we will 'dimensionality curse' problem.\n# Lets first clean dataset to remove white space","f7f8e930":"    removing outliers","ed78c437":"Lets visualize data","9642bfad":"# Looking into locations, finding unique locations in dataset","4f42fb85":"Data cleaning","b59d056a":"# Inorder to find outliers we added column price_per_sqft","d6f27b40":"# Lets start modeling","7a6ab99b":"**Cross val Score**","61d2b44b":"**Trying another model**"}}