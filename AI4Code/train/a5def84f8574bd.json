{"cell_type":{"8802de8c":"code","1dd88ec8":"code","fdd3f9a3":"code","1ae0dc68":"code","e7695f54":"code","30401d2d":"code","38212062":"code","4d2347d5":"code","ed9d2a50":"code","29fe7f5f":"code","b637d529":"code","279a0c6c":"code","098d9244":"code","a00e9376":"code","18ee5bf3":"code","9164a079":"code","1894ae6d":"code","b0e55167":"code","31cb8e5a":"code","8dd450ac":"code","bdcad06f":"code","c088204f":"code","dfc91818":"code","cfacd36d":"code","5f03524d":"code","484c1fea":"code","1811254d":"code","c092dbdb":"code","7ae52f15":"code","c182ea08":"markdown","8652945e":"markdown"},"source":{"8802de8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1dd88ec8":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)","fdd3f9a3":"train.head()","1ae0dc68":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)","e7695f54":"y_train = train[\"label\"]\nX_train = train.drop(labels=[\"label\"],axis=1)","30401d2d":"plt.figure(figsize=(15,7))\ng = sns.countplot(y_train, palette=\"icefire\")\nplt.title(\"Number of digit classes\")\nprint(\" \\t # y_train value counts # \\n\",y_train.value_counts())","38212062":"X_train = X_train \/ 255.0\nX_test = test \/ 255.0","4d2347d5":"X_test = X_test.values.reshape(-1,28,28,1)\nX_train = X_train.values.reshape(-1,28,28,1)","ed9d2a50":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(y_train, num_classes = 10)","29fe7f5f":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_val shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_val shape\",Y_val.shape)","b637d529":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(BatchNormalization(input_shape = (28,28,1)))\nmodel.add(Conv2D(64, (5, 5), padding='same', activation='elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(BatchNormalization(input_shape = (28,28,1)))\nmodel.add(Conv2D(128, (5, 5), padding='same', activation='elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(BatchNormalization(input_shape = (28,28,1)))\nmodel.add(Conv2D(256, (5, 5), padding='same', activation='elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"elu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","279a0c6c":"#optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\noptimizer = Adam(lr=1e-3)","098d9244":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=['accuracy'])","a00e9376":"epochs = 100  \nbatch_size = 250","18ee5bf3":"datagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False, \n        rotation_range=5,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=False,  \n        vertical_flip=False)  \n\ndatagen.fit(X_train)","9164a079":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=6)","1894ae6d":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                    epochs = epochs,\n                    validation_data = (X_val,Y_val),\n                    steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                    callbacks=[early_stopping])","b0e55167":"print(\"Accuracy of the model is --> \" , model.evaluate(X_val, Y_val, batch_size=batch_size)[1]*100 , \"%\")\nprint(\"Loss of the model is --> \" , model.evaluate(X_val, Y_val, batch_size=batch_size)[0])","31cb8e5a":"labels = model.predict(X_test)","8dd450ac":"labels.shape","bdcad06f":"labels = np.argmax(labels, axis=1)","c088204f":"labels.shape","dfc91818":"sample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")","cfacd36d":"sample_submission","5f03524d":"test.head()","484c1fea":"index = test.index.values + 1\ndata = {'ImageId' : index, \"Label\" : labels}\ndf = pd.DataFrame(data=data)\ndf.head()","1811254d":"df.to_csv('submission.csv', index=False)","c092dbdb":"submit = pd.DataFrame({'ImageId' : index, \"Label\" : labels.astype(int).ravel()})\nsubmit.to_csv(\"submission.csv\",index = False)","7ae52f15":"submit","c182ea08":"Using a different model, based on [this](https:\/\/github.com\/Doometnick\/Distributed-TPU-Training\/)","8652945e":"Based on [MNIST digit(CNN)](https:\/\/www.kaggle.com\/abhaporwal\/mnist-digit-cnn) by [Abha Porwal](https:\/\/www.kaggle.com\/abhaporwal), with architecture from [here](https:\/\/github.com\/Doometnick\/Distributed-TPU-Training\/)"}}