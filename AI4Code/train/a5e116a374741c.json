{"cell_type":{"d1d8b81f":"code","a19127c6":"code","58fe5e8f":"code","695c26d2":"code","28310a30":"code","2eeb56e8":"code","dc690d43":"code","002fd970":"code","b358b11a":"code","9170886d":"code","7f6b9752":"code","5753d9ee":"code","250c5703":"code","c46bf8eb":"code","b87407b2":"code","9ef03be0":"code","cdc456b8":"code","800ee2a3":"code","1f6ba459":"code","dd30a58e":"code","1abbea06":"code","dc1d4290":"code","5b85be5d":"code","2975d3f8":"code","3c6eb92a":"code","4e4edeae":"code","d2266bdd":"code","58e897fb":"code","f484f70e":"code","cafcc4cf":"code","7d484edf":"markdown","775046eb":"markdown","b72559d4":"markdown","62e79e1e":"markdown","0a751e75":"markdown","af4292ae":"markdown","0db42332":"markdown","6355465e":"markdown","eb0c9e36":"markdown","41540fa2":"markdown","0eca7d52":"markdown","232d96f5":"markdown","fa242f28":"markdown","e5bab918":"markdown","9fba5a91":"markdown","be34777c":"markdown","9f58b2be":"markdown","60ebb974":"markdown","ec68dad4":"markdown","606f6adf":"markdown","4194c4b9":"markdown","9989c4cf":"markdown","49b2a9b8":"markdown","18a4f523":"markdown","a79ebc76":"markdown","420bd7a3":"markdown","491d25cb":"markdown"},"source":{"d1d8b81f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom plotly.offline import plot, iplot, init_notebook_mode\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n%matplotlib inline\n\ndata = pd.read_csv('..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv')\ndata.head()","a19127c6":"data = data.rename({\"Order Number\": \"Order_Number\", \"Order Status\": \"Order_Status\", \"Book Name\":\"Book_Name\",\n                    \"Order Date & Time\": \"Order_Date\", \"City (Billing)\": \"City\", \n                    \"Payment Method\": \"Payment_Method\", \"Total items\": \"Total_Items\", \n                    \"Total weight (grams)\": \"Total_Weight\" }, axis = 1)\ndata.info()","58fe5e8f":"# Checking whether the Order_Numbers are duplicated or not. \n# If duplicates are present, then delete the duplicates\ndata.Order_Number.value_counts()","695c26d2":"# dropping the nan values in the data\ndata = data.dropna()\ndata.info()","28310a30":"print(data.Order_Status.value_counts())\nprint()\n\n# Plotting the Order Status Frequency \npx.histogram(data, x = data.Order_Status, width = 400, height = 400, title='Order Status Frequency')","2eeb56e8":"# Since the book names were separated by \" \/ \" that is why I used split method to get name of all the books separately\nbook_data = data.Book_Name.apply(lambda x: str(x).split('\/'))\n# Storing the list of lists book names in a list 'books' \nbooks = [item for sublist in book_data for item in sublist]\n# creating a new dataframe 'df' for ease in plotting the books sold\ndf = pd.DataFrame(data = books, columns = ['Books_Sold'])\n# Only storing the top 10 most selling books of all times and converting the result into a datafram\nbook_chart = df.Books_Sold.value_counts().nlargest(10).to_frame()\n# Printing the most sold book name and its number of times it was sold\nprint(book_chart.head(1))\nprint()\n# plotting 10 top selling books of all time\npx.bar(book_chart, y = book_chart.Books_Sold, x = book_chart.index, title = 'Most Selling Books')","dc690d43":"# The column 'Order_Date' had both time and date, for ease in data manipulation made new columns for both Time and Date\n# \"Order_Date\" column had date and time separated by empty space, hence splitted the data and stored in respectice columns\ndata['Time'] = data.Order_Date.apply(lambda x: str(x).split(' ')[1])\ndata['Date'] = data.Order_Date.apply(lambda x: str(x).split(' ')[0])\ndata.head()","002fd970":"# Converting time into mins by getting the hours by splitting and multiplying it by 60 \n# and then adding it with the minutes to get the total minutes\nmins = data.Time.apply(lambda x: int(x.split(\":\")[0])*60 + int(x.split(\":\")[1]))\n# cutting the Mins into 4 parts so that the each time can manipulated with a time range of 6 hours\npd.cut(mins, bins = 4)","b358b11a":"# Creating a new column Mins\ndata['Mins'] = mins\n# if the number of mins are lesser than 360 i.e Time is from 00:00 to 05:59 store it as 0\ndata.loc[data['Mins'] < 360, 'Mins'] = 0\n# if the number of mins are lesser than 720 and greater than equal to 360 \n# i.e Time is from 06:00 to 11:59 store it as 1\ndata.loc[(data['Mins'] >= 360) & (data['Mins'] < 720), 'Mins'] = 1 \n# if the number of mins are lesser than 1080 and greater than equal to 720\n# i.e Time is from 12:00 to 17:59 store it as 2\ndata.loc[(data['Mins'] >= 720) & (data['Mins'] < 1080), 'Mins'] = 2 \n# if the number of mins are  greater than equal to 1080\n#i.e Time is from 18:00 to 23:59 store it as 3\ndata.loc[(data['Mins'] >= 1080), 'Mins'] = 3\n# Checking in which time frame most orders are placed\ndata.Mins.value_counts()\n# plotting the number of orders placed within different time frames\npx.histogram(data, x = data.Mins, width = 400, height = 400, title='Order Status Frequency By Time')\n# Most Orders are placed between 6 PM to 12 AM, with number of orders = 7010","9170886d":"a = data.loc[data.Mins == 0].Order_Status.value_counts().to_frame()\nb = data.loc[data.Mins == 1].Order_Status.value_counts().to_frame()\nc = data.loc[data.Mins == 2].Order_Status.value_counts().to_frame()\nd = data.loc[data.Mins == 3].Order_Status.value_counts().to_frame()","7f6b9752":"print('Ratio of Order Status from 12 AM to 6 AM:')\n# Plotting the Order Status for orders placed between 12 AM to 6 AM\n# normalizing the value_counts to see the percentage of each variable\nprint(data.loc[data.Mins == 0].Order_Status.value_counts(normalize = True)*100)\npx.bar(a, y = a.Order_Status, x = a.index, title = 'Order Status from 12 AM to 6 AM', height = 400, width = 400)","5753d9ee":"print('Ratio of Order Status from 6 AM to 12 PM:')\n# Plotting the Order Status for orders placed between 12 AM to 6 AM\n# normalizing the value_counts to see the percentage of each variable\nprint(data.loc[data.Mins == 1].Order_Status.value_counts(normalize = True)*100)\npx.bar(b, y = b.Order_Status, x = b.index, title = 'Order Status from 6 AM to 12 PM', height = 400, width = 400 )","250c5703":"print('Ratio of Order Status from 12 PM to 6 PM:')\nprint(data.loc[data.Mins == 2].Order_Status.value_counts(normalize = True)*100)\npx.bar(c, y = c.Order_Status, x = c.index, title = 'Order Status from 12 PM to 6 PM', height = 400, width = 400 )","c46bf8eb":"print('Ratio of Order Status from 6 PM to 12 AM:')\nprint(data.loc[data.Mins == 1].Order_Status.value_counts(normalize = True)*100)\npx.bar(d, y = d.Order_Status, x = d.index, title = 'Order Status from 6 PM to 12 AM', height = 400, width = 400 )","b87407b2":"# Since the data contained names of cities in different cases, hence converted the all the data to lower case\ndata.City = data.City.apply(lambda x: str(x).lower())\ndata.City = data.City.replace(\"khi\", \"karachi\")\ndata.City = data.City.replace(\"fsd\", \"faisalabad\")\ndata.City = data.City.replace(\"isb\", \"islamabad\")\ndata.City = data.City.replace(\"lhr\", \"lahore\")\ndata.City = data.City.replace('lahire', 'lahore')\n# top 30 cities with most sales\ncities = data.City.value_counts().nlargest(30).to_frame()\n# list of top cities\ntop_cities = list(cities.index)\ncities = cities.rename({'City': 'Sales'}, axis = 1)\n# plotting the top cities by sales\npx.bar(cities, x = cities.index, y = cities.Sales)","9ef03be0":"df = pd.DataFrame()\n# Creating a new dataframe for visualizing the top 30 cities order statuses\ndf['Order_Status'] = data[data.City.isin(top_cities)].Order_Status\ndf['City'] = data[data.City.isin(top_cities)].City\ndf['Time'] = data[data.City.isin(top_cities)].Mins\ndf['Date'] = data[data.City.isin(top_cities)].Date","cdc456b8":"# creating a pivot table with index city, column Order status and populating the table with Time\npt = pd.pivot_table(df, values = 'Time', index = 'City', columns = 'Order_Status', aggfunc = 'count', fill_value=0)\n# creating a column for finding out the ratio of 'Completed' (Order Status) orders \npt['Completion_Rate'] = pt.Completed \/ (pt.Completed + pt.Returned + pt.Cancelled)\npt = pt.sort_values(by = 'Completion_Rate', ascending = False)","800ee2a3":"px.bar(pt, y = pt.Completion_Rate, x = pt.index, title = 'Order Completion of top 30 cities')","1f6ba459":"pt = pd.pivot_table(data, values = 'City', index = 'Mins', columns = 'Order_Status', aggfunc = 'count', fill_value=0)\npt['Completion_Rate'] = pt.Completed \/ (pt.Completed + pt.Returned + pt.Cancelled)\npt = pt.sort_values(by = 'Completion_Rate', ascending = False)\npx.bar(pt, y = pt.Completion_Rate, x = pt.index, title = 'Order Completion for Different Time Ranges')","dd30a58e":"pt = pd.pivot_table(data, values = 'City', index = 'Date', columns = 'Order_Status', aggfunc = 'count', fill_value=0)\npt['Completion_Rate'] = pt.Completed \/ (pt.Completed + pt.Returned + pt.Cancelled)\npt = pt.sort_values(by = 'Completion_Rate', ascending = False)\npx.bar(pt, y = pt.Completion_Rate, x = pt.index, title = 'Order Completion for Different Dates')","1abbea06":"# splitting the Date column for getting the months and days of each date\nmonthly = data.Date.apply(lambda x: x.split(\"\/\")[0])\ndaily = data.Date.apply(lambda x: x.split(\"\/\")[1])\ndata['Month'] = monthly\ndata['Day'] = daily","dc1d4290":"# Visualizing the month with most sales\npt = pd.pivot_table(data, values = 'Order_Number', index = 'Month', aggfunc = 'count')\\\n              .sort_values(by = 'Order_Number', ascending = False)\npx.bar(pt, y = pt.Order_Number, x = pt.index, title = 'Number of Orders Placed in Different Months')\n              ","5b85be5d":"pt = pd.pivot_table(data, values = 'Order_Number', index = 'Day', aggfunc = 'count').sort_values(by = 'Order_Number', ascending = False)\npx.bar(pt, y = pt.Order_Number, x = pt.index, title = 'Number of Orders Placed in Different Days')","2975d3f8":"# Creating a new pred_table\npred_table = data[['Date', 'Order_Number', 'Order_Status']]\n# converting the Date column values to datetime and copying the data in the pred_table.Date\npred_table['Date'] = pd.to_datetime(data.Date.iloc[:])\n# Grouping the pred_table with Date and calculating the number of orders placed within each date\npred_table = pred_table.groupby('Date')['Order_Number'].count().reset_index()\npred_table","3c6eb92a":"from fbprophet import Prophet\nsales_pred = Prophet(interval_width = 0.95)\n# renaming the columns, since fbpropher requires each column to be used to be renamed as ds and y\nsales = pred_table.rename(columns={'Date': 'ds', 'Order_Number': 'y'})\n# fitting the model\nsales_pred.fit(sales)\n\n# forecasting the number of sales for the next 12 Months\nsales_forecast = sales_pred.make_future_dataframe(periods=12, freq='MS')\nsales_forecast = sales_pred.predict(sales_forecast)\n\n# visualizing the predictions\nplt.figure(figsize=(12, 6))\nsales_pred.plot(sales_forecast, xlabel = 'Date', ylabel = 'Sales')\nplt.title('Book Sales')","4e4edeae":"data.head()","d2266bdd":"a = data.Total_Weight.value_counts().nlargest(10).to_frame()\na = a.reset_index()\na = a.rename({'index': 'Weight', 'Total_Weight': 'Count'}, axis = 1)\nfig_dims = (10, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = 'Weight', y = 'Count', data = a, ax = ax, palette = 'Set2')","58e897fb":"data.Payment_Method.value_counts()","f484f70e":"# Since Cash on delivery was repeated\ndata.Payment_Method = data.Payment_Method.replace('Cash on Delivery (COD)', 'Cash on delivery')\npx.histogram(data, x = 'Payment_Method', width = 600, height = 400, title = 'Frequency of Payment Method')","cafcc4cf":"a = sns.countplot(x = 'Order_Status', data = data[data.Payment_Method == 'Cash on delivery'])\na.set_title('Order Status for Cash on Delivery')\nplt.figure()\na = sns.countplot(x = 'Order_Status', data = data[data.Payment_Method == 'EasyPaisa'])\na.set_title('Order Status for EasyPaisa')\nplt.figure()\na = sns.countplot(x = 'Order_Status', data = data[data.Payment_Method == 'JazzCash'])\na.set_title('Order Status for JazzCash')\nplt.figure()\na = sns.countplot(x = 'Order_Status', data = data[data.Payment_Method == 'BankTransfer'])\na.set_title('Order Status for BankTransfer')","7d484edf":"### Order Completion Ratio by Time","775046eb":"## Order Completion Ratio by Different Dates","b72559d4":"### Visualizing Order Completion Ratio for Cities with most sales","62e79e1e":"Converting Time Column into Categorical Variable for ease in manipulation","0a751e75":"The Rate of Completion of Orders are Maximum for orders placed between 12 AM to 6 AM.","af4292ae":"Renaming the columns for ease in accessing the data","0db42332":"### Results: From above demonstration we can conclude that only the Orders from Cash on Delivery are completed most, however the orders confirmed from E-transactions such as Bank Transfers, EasyPaisa and JazzCash are cancelled right away.","6355465e":"# In Depth Analysis of Gufhtugu Dataset","eb0c9e36":"## Time Series Forecasting for predicting the number of orders","41540fa2":"## Most Selling Books","0eca7d52":"Most number of orders are placed on 9th Day of the month and least orders are placed in the 19th day of the month","232d96f5":"## Visualizing Months with most sales","fa242f28":"Most number of orders are placed in January with least orders placed in February","e5bab918":"## Visualizing Orders Status Frequency by Time ","9fba5a91":"Since most of the people rely on getting things delivered first and then pay accordingly, hence the mode which was used most frequently for delivery is Cash on Delivery mode.","be34777c":"## FB Prophet Library for predicting the sales for the next whole year","9f58b2be":"## Identifying Cities with most orders","60ebb974":"## Visualizing Days with most sales","ec68dad4":"Converting each time frame into a separate dataframe for analyzing the order statuses within every time frame","606f6adf":"## Data Preprocessing","4194c4b9":"### Result: The Book Sales are expected to grow within each month, with the number of sales crossing 300 per day after one year\nThe confidence interval upto 12 months remains constant","9989c4cf":"## Order Completion Ratio with Time Ranges","49b2a9b8":"Hence the City with Most Order Completion Rate is Dera Ghazi Khan","18a4f523":"From above graph we can determine the order placed on 19\/11\/2019 had least completion rate with 0.5","a79ebc76":"### If you like the notebook, give this notebook an upvote and let me know in the comments the part you cannot understand and the part where I can improve.\n### Thank you. Happy Coding. ","420bd7a3":"## Importing Libraries","491d25cb":"## Order Status Frequency"}}