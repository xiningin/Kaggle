{"cell_type":{"1e0ecff6":"code","11503e6c":"code","8516cda0":"code","00060479":"code","151af63b":"code","a13188e9":"code","03d699f2":"code","39e3f5fc":"code","28b8b708":"code","f3c580f5":"code","52ecb248":"code","8eb49ece":"code","a45c0e67":"code","7c92f4fa":"code","4edc5784":"code","e43b9a5a":"code","3945e59c":"code","a438c889":"code","7682152b":"code","d14b35c8":"code","327982e8":"code","71fd96dc":"code","6c0067e9":"code","1b9e106a":"code","a904855c":"code","6f435519":"code","4065176a":"code","57547c9a":"code","9a2933af":"code","114bbef3":"code","06e6a381":"code","d34ac783":"code","56811a14":"code","d5386172":"code","ff789f80":"code","1a9be7cb":"code","f94bc0ad":"code","c5b88cb7":"code","2c0b1ad5":"code","e4295b21":"code","a3835052":"code","afc92125":"code","8f90bad9":"code","59a2570a":"code","6ca4aaa1":"code","36ae0ccf":"code","2c297ee2":"code","2d2845e3":"code","d97f2acf":"code","3afbbe36":"code","d779ef7d":"code","db05ba41":"code","fc6d1986":"code","6b4a1a51":"code","b1ca0f36":"code","712797d6":"code","a9667711":"code","d402b6b9":"markdown","1b095313":"markdown","8df1602a":"markdown","982c6f52":"markdown","88bbed85":"markdown","9ed5120d":"markdown","ace543c3":"markdown","11424d0e":"markdown","53f57a1a":"markdown","2691bfaa":"markdown","42422256":"markdown","c3dbdc1a":"markdown","f975ca3e":"markdown","ae3203e1":"markdown","bfe2498b":"markdown","1911c375":"markdown","e075b005":"markdown","11283d30":"markdown","9c3a714b":"markdown","8cdd7edd":"markdown","7e9ea703":"markdown","f34df221":"markdown"},"source":{"1e0ecff6":"from tensorflow import set_random_seed\nset_random_seed(101)\n\nfrom numpy.random import seed\nseed(101)\nimport pandas as pd\nimport numpy as np\n#import keras\n\nimport tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import  Dropout,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint,EarlyStopping\nfrom tensorflow.keras.metrics import categorical_crossentropy\n\nimport os\n\n\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport itertools\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","11503e6c":"os.listdir('..\/input')","8516cda0":"base_dir = 'base_dir'\nos.mkdir(base_dir)\n\nval_dir = os.path.join(base_dir, 'val_dir')# validation dosyas\u0131\nos.mkdir(val_dir)\n\ntrain_dir = os.path.join(base_dir, 'train_dir')# train dosyas\u0131\nos.mkdir(train_dir)\n\n#train dosyas\u0131n\u0131n i\u00e7ine kanser t\u00fcrlerinin foto\u011fraflar\u0131n\u0131 i\u00e7erecek dosyalar\u0131 olu\u015fturuyoruz.\nnv = os.path.join(train_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(train_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(train_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(train_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(train_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(train_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(train_dir, 'df')\nos.mkdir(df)\n\n\n#validation dosyas\u0131n\u0131n i\u00e7ine kanser t\u00fcrlerinin foto\u011fraflar\u0131n\u0131 i\u00e7erecek dosyalar\u0131 olu\u015fturuyoruz.\nnv = os.path.join(val_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(val_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(val_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(val_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(val_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(val_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(val_dir, 'df')\nos.mkdir(df)","00060479":"df_data = pd.read_csv('..\/input\/HAM10000_metadata.csv')\n\ndf_data.head()","151af63b":"fig, ax1 = plt.subplots(1, 1, figsize= (10, 5))\ndf_data['dx'].value_counts().plot(kind='bar', ax=ax1)","a13188e9":"df_data['dx_type'].value_counts().plot(kind='bar')","03d699f2":"df_data['localization'].value_counts().plot(kind='bar')","39e3f5fc":"df_data['age'].hist(bins=40)","28b8b708":"df_data['sex'].value_counts().plot(kind='bar')","f3c580f5":"#Her bir lesion_id ile ka\u00e7 adet resmin ili\u015fkili oldu\u011funu s\u00f6yler.\ndf = df_data.groupby('lesion_id').count()\n\n#\u015eimdi ise tek resime sahip olanlar\u0131 filtreliyoruz.\ndf = df[df['image_id'] == 1]\n\ndf.reset_index(inplace = True)\ndf.head()","52ecb248":"#\u015eimdi ise yinelenmi\u015f ve tek resim i\u00e7eren lesion_id leri s\u0131n\u0131fl\u0131yoruz.\n\ndef yinelenenleri_algila(x):\n    \n    unique_list = list(df['lesion_id'])\n    \n    if x in unique_list:\n        return 'no_duplicates'\n    else:\n        return 'has_duplicates'\n    \n#\u0130\u015flem yapmak i\u00e7in veriyi kopyalad\u0131k.\ndf_data['duplicates'] = df_data['lesion_id']\n# Kopyalad\u0131\u011f\u0131m\u0131z veriyi fonksiyona soktuk\ndf_data['duplicates'] = df_data['duplicates'].apply(yinelenenleri_algila)\n\ndf_data.head()","8eb49ece":"df_data['duplicates'].value_counts()","a45c0e67":"#Yinelenmeyen verileri filtreliyoruz.\ndf = df_data[df_data['duplicates'] == 'no_duplicates']\n\ndf.shape","7c92f4fa":"#\u015eimdi ise verilerin yinelenmedi\u011finden eminiz.\ny = df['dx']\n\n_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=y)\ndf_val.shape","4edc5784":"df_val['dx'].value_counts()","e43b9a5a":"# Validation ve train verilerini alg\u0131lama.\ndef identify_val_rows(x):\n    #Validation dataframe image_idleri bir listeye aktar\u0131yoruz.\n    val_list = list(df_val['image_id'])\n    \n    if str(x) in val_list:\n        return 'val'\n    else:\n        return 'train'\n\n\n# \u00dcstteki i\u015flemin ayn\u0131s\u0131n\u0131 ger\u00e7ekle\u015ftiriyoruz.\ndf_data['train_or_val'] = df_data['image_id']\n\ndf_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n\ndf_train = df_data[df_data['train_or_val'] == 'train']\n\n\nprint(len(df_train))\nprint(len(df_val))","3945e59c":"df_train['dx'].value_counts()","a438c889":"df_val['dx'].value_counts()","7682152b":"#\u0130mage_id yi index haline getirdik.\ndf_data.set_index('image_id', inplace=True)","d14b35c8":"# Datasetteki verileri iki klas\u00f6r halinde tutuyoruz.\nfolder_1 = os.listdir('..\/input\/ham10000_images_part_1')\nfolder_2 = os.listdir('..\/input\/ham10000_images_part_2')\n\n#Validation ve train verilerini listeliyoruz.\ntrain_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\n\n\n\n#Train dosyalar\u0131n\u0131 transfer ediyoruz.\n\nfor image in train_list:\n    \n    fname = image + '.jpg'#file name\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        # Resmin kayna\u011f\u0131\n        src = os.path.join('..\/input\/ham10000_images_part_1', fname)\n        # Var\u0131\u015f noktas\u0131\n        dst = os.path.join(train_dir, label, fname)\n        # Kaynaktan var\u0131\u015f noktas\u0131na kopyalama i\u015flemi.\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # Resmin kayna\u011f\u0131\n        src = os.path.join('..\/input\/ham10000_images_part_2', fname)\n        # Var\u0131\u015f noktas\u0131\n        dst = os.path.join(train_dir, label, fname)\n        # Kaynaktan var\u0131\u015f noktas\u0131na kopyalama i\u015flemi\n        shutil.copyfile(src, dst)\n\n\n# Validation dosyalar\u0131n\u0131 transfer ediyoruz.\n\nfor image in val_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        # Resmin kayna\u011f\u0131\n        src = os.path.join('..\/input\/ham10000_images_part_1', fname)\n        # Var\u0131\u015f noktas\u0131\n        dst = os.path.join(val_dir, label, fname)\n        # Kaynaktan var\u0131\u015f noktas\u0131na kopyalama i\u015flemi\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # Resmin kayna\u011f\u0131\n        src = os.path.join('..\/input\/ham10000_images_part_2', fname)\n        # Var\u0131\u015f noktas\u0131\n        dst = os.path.join(val_dir, label, fname)\n        # Kaynaktan var\u0131\u015f noktas\u0131na kopyalama i\u015flemi\n        shutil.copyfile(src, dst)\n        ","327982e8":"#Kontrol evresi\n\nprint(len(os.listdir('base_dir\/train_dir\/nv')))\nprint(len(os.listdir('base_dir\/train_dir\/mel')))\nprint(len(os.listdir('base_dir\/train_dir\/bkl')))\nprint(len(os.listdir('base_dir\/train_dir\/bcc')))\nprint(len(os.listdir('base_dir\/train_dir\/akiec')))\nprint(len(os.listdir('base_dir\/train_dir\/vasc')))\nprint(len(os.listdir('base_dir\/train_dir\/df')))","71fd96dc":"#Kontrol evresi\n\nprint(len(os.listdir('base_dir\/val_dir\/nv')))\nprint(len(os.listdir('base_dir\/val_dir\/mel')))\nprint(len(os.listdir('base_dir\/val_dir\/bkl')))\nprint(len(os.listdir('base_dir\/val_dir\/bcc')))\nprint(len(os.listdir('base_dir\/val_dir\/akiec')))\nprint(len(os.listdir('base_dir\/val_dir\/vasc')))\nprint(len(os.listdir('base_dir\/val_dir\/df')))","6c0067e9":"# 'nv' s\u0131n\u0131f\u0131n\u0131 \u00e7oklam\u0131yoruz.\nclass_list = ['mel','bkl','bcc','akiec','vasc','df']\n\nfor item in class_list:\n    \n    # aug_dir klas\u00f6r\u00fcn\u00fc olu\u015fturuyoruz.\n    aug_dir = 'aug_dir'\n    os.mkdir(aug_dir)\n    img_dir = os.path.join(aug_dir, 'img_dir')\n    os.mkdir(img_dir)\n\n    # S\u0131n\u0131f se\u00e7iyoruz\n    img_class = item\n    img_list = os.listdir('base_dir\/train_dir\/' + img_class)\n\n    for fname in img_list:\n            # Resmin kayna\u011f\u0131\n            src = os.path.join('base_dir\/train_dir\/' + img_class, fname)\n            # Var\u0131\u015f noktas\u0131\n            dst = os.path.join(img_dir, fname)\n            # Kaynaktan var\u0131\u015f noktas\u0131na kopyalama i\u015flemi\n            shutil.copyfile(src, dst)\n\n    path = aug_dir\n    save_path = 'base_dir\/train_dir\/' + img_class\n\n    # Data Generator olu\u015fturuyoruz\n    datagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        #brightness_range=(0.9,1.1),\n        fill_mode='nearest')\n\n    batch_size = 50\n\n    aug_datagen = datagen.flow_from_directory(path,\n                                           save_to_dir=save_path,\n                                           save_format='jpg',\n                                                    target_size=(224,224),\n                                                    batch_size=batch_size)\n\n\n\n    # \u00c7oklanm\u0131\u015f g\u00f6r\u00fcnt\u00fcleri olu\u015fturup train klas\u00f6r\u00fcne at\u0131yoruz.\n    \n    ###########\n    \n    num_aug_images_wanted = 6000 # \u00c7oklamak iste\u011fimiz say\u0131.\n    \n    ###########\n    \n    num_files = len(os.listdir(img_dir))\n    num_batches = int(np.ceil((num_aug_images_wanted-num_files)\/batch_size))\n\n    # Modeli kullanarak 6000 fotoyu \u00e7okluyoruz.\n    for i in range(0,num_batches):\n\n        imgs, labels = next(aug_datagen)\n        \n    # Ge\u00e7ici klas\u00f6r\u00fc siliyoruz.\n    shutil.rmtree('aug_dir')","1b9e106a":"#Kontrol evresi\nprint(len(os.listdir('base_dir\/train_dir\/nv')))\nprint(len(os.listdir('base_dir\/train_dir\/mel')))\nprint(len(os.listdir('base_dir\/train_dir\/bkl')))\nprint(len(os.listdir('base_dir\/train_dir\/bcc')))\nprint(len(os.listdir('base_dir\/train_dir\/akiec')))\nprint(len(os.listdir('base_dir\/train_dir\/vasc')))\nprint(len(os.listdir('base_dir\/train_dir\/df')))","a904855c":"#Kontrol evresi\nprint(len(os.listdir('base_dir\/val_dir\/nv')))\nprint(len(os.listdir('base_dir\/val_dir\/mel')))\nprint(len(os.listdir('base_dir\/val_dir\/bkl')))\nprint(len(os.listdir('base_dir\/val_dir\/bcc')))\nprint(len(os.listdir('base_dir\/val_dir\/akiec')))\nprint(len(os.listdir('base_dir\/val_dir\/vasc')))\nprint(len(os.listdir('base_dir\/val_dir\/df')))","6f435519":"# Jupyter diz\u00fcst\u00fc bilgisayardaki etiketleri i\u00e7eren g\u00f6r\u00fcnt\u00fcleri \u00e7izer.\n# Kaynak: https:\/\/github.com\/smileservices\/keras_utils\/blob\/master\/utils.py\n\ndef plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)\/\/rows if len(ims) % 2 == 0 else len(ims)\/\/rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n        \nplots(imgs, titles=None) ","4065176a":"train_path = 'base_dir\/train_dir'\nvalid_path = 'base_dir\/val_dir'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\nimage_size = 224\n\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\nval_steps = np.ceil(num_val_samples \/ val_batch_size)\n","57547c9a":"\ndatagen = ImageDataGenerator(\n    preprocessing_function= \\\n    tensorflow.keras.applications.mobilenet.preprocess_input)\n\ntrain_batches = datagen.flow_from_directory(train_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=train_batch_size)\n\nvalid_batches = datagen.flow_from_directory(valid_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=val_batch_size)\n\n# Not: shuffle=False komutu test datas\u0131n\u0131n kar\u0131\u015ft\u0131r\u0131lmamas\u0131na neden olur.\ntest_batches = datagen.flow_from_directory(valid_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=1,\n                                            shuffle=False)","9a2933af":"# Mobile Net Modelini indiriyor ve kopyal\u0131yoruz.\n\nmobile = tensorflow.keras.applications.mobilenet.MobileNet()","114bbef3":"mobile.summary()","06e6a381":"# Modelde ka\u00e7 adet layer oldu\u011funu kontrol ediyoruz.\nlen(mobile.layers)","d34ac783":"# Model yap\u0131s\u0131n\u0131 olu\u015fturma.\n\n# Modelin son 5 katman\u0131n\u0131 d\u0131\u015far\u0131da tutaca\u011f\u0131z.\nx = mobile.layers[-6].output\n\n# Tahmin i\u00e7in yeni bir dense layer olu\u015fturuyoruz.\n# 7 class say\u0131m\u0131z\u0131 ifade ediyor.\nx = Dropout(0.25)(x)\npredictions = Dense(7, activation='softmax')(x)\n\n# inputs=mobile.input input layer\u0131 se\u00e7er, outputs=predictions dense layer\u0131 i\u015faret eder.\n\nmodel = Model(inputs=mobile.input, outputs=predictions)","56811a14":"model.summary()","d5386172":"# Ger\u00e7ekten ka\u00e7 tane katman\u0131 e\u011fitmeye ihtiyac\u0131m\u0131z oldu\u011funu se\u00e7meliyiz.\n\n#Yeni modelimizdeki son 23 katman d\u0131\u015f\u0131nda hepsini donduruyoruz.\n# Modelin son 23 katman\u0131 e\u011fitilecek.\n\nfor layer in model.layers[:-23]:\n    layer.trainable = False","ff789f80":"# Top2 ve Top3 isabetlilik(acc) fonksiyonlar\u0131n\u0131 tan\u0131mlad\u0131k.\n\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n\ndef top_2_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=2)","1a9be7cb":"model.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n\n","f94bc0ad":"######################################3\nprint(valid_batches.class_indices)","c5b88cb7":"# A\u011f\u0131rl\u0131klar\u0131 Melonoma t\u00fcr\u00fcne daha hassas olacak \u015fekilde d\u00fczenleyin.\nclass_weights={\n    0: 1.0, # akiec\n    1: 1.0, # bcc\n    2: 1.0, # bkl\n    3: 1.0, # df\n    4: 3.0, # mel        # Yukar\u0131da bahsetti\u011fimiz ayr\u0131nt\u0131.\n    5: 1.0, # nv\n    6: 1.0, # vasc\n}","2c0b1ad5":"\nfilepath = \"model_kanser.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_batches, steps_per_epoch=train_steps, \n                              class_weight=class_weights,\n                    validation_data=valid_batches,\n                    validation_steps=val_steps,\n                    epochs=15, verbose=1,\n                   callbacks=callbacks_list)\n","e4295b21":"# metrik adlar\u0131 evaulate_generator fonksiyonunda kullanmak i\u00e7in al\u0131yoruz.\nmodel.metrics_names","a3835052":"# Son epoch kullan\u0131lacak.\nval_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)\nprint('val_top_2_acc:', val_top_2_acc)\nprint('val_top_3_acc:', val_top_3_acc)","afc92125":"# En iyi epoch kullan\u0131lacak.\nmodel.load_weights('model_kanser.h5')\n\nval_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)\nprint('val_top_2_acc:', val_top_2_acc)\nprint('val_top_3_acc:', val_top_3_acc)","8f90bad9":"# Loss ve accuracy e\u011frilerini g\u00f6sterelim.\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\ntrain_top2_acc = history.history['top_2_accuracy']\nval_top2_acc = history.history['val_top_2_accuracy']\ntrain_top3_acc = history.history['top_3_accuracy']\nval_top3_acc = history.history['val_top_3_accuracy']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training ve validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training cat acc')\nplt.plot(epochs, val_acc, 'b', label='Validation cat acc')\nplt.title('Training ve validation cat accuracy')\nplt.legend()\nplt.figure()\n\n\nplt.plot(epochs, train_top2_acc, 'bo', label='Training top2 acc')\nplt.plot(epochs, val_top2_acc, 'b', label='Validation top2 acc')\nplt.title('Training ve validation top2 accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, train_top3_acc, 'bo', label='Training top3 acc')\nplt.plot(epochs, val_top3_acc, 'b', label='Validation top3 acc')\nplt.title('Training ve validation top3 accuracy')\nplt.legend()\n\n\nplt.show()","59a2570a":"# Test foto\u011fraflar\u0131n\u0131n labellar\u0131n\u0131 \u00e7ekelim.\ntest_labels = test_batches.classes","6ca4aaa1":"# \u00c7\u00fcnk\u00fc Confusion Matrixde bunlara ihtiyac\u0131m\u0131z olacak.\ntest_labels","36ae0ccf":"# Her s\u0131n\u0131fla ili\u015fkili label\u0131 yazd\u0131r\u0131n.\ntest_batches.class_indices","2c297ee2":"# Tahmin zaman\u0131\npredictions = model.predict_generator(test_batches, steps=len(df_val), verbose=1)","2d2845e3":"predictions.shape","d97f2acf":"# Kaynak: Scikit Learn website\n# http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Bu fonksiyon confusion matrixi \u00e7izdirir.\n    Normalizasyon bu \u015fekilde yap\u0131labilir --> `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalizasyon ile confusion matrix\")\n    else:\n        print('Normalizasyon olmadan Confusion matrix')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('As\u0131l label')\n    plt.xlabel('Tahmini label')\n    plt.tight_layout()\n\n\n","3afbbe36":"test_labels.shape","d779ef7d":"# argmax bir sat\u0131rdaki maksimum de\u011ferin indexini d\u00f6nd\u00fcr\u00fcr.\n\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))","db05ba41":"test_batches.class_indices","fc6d1986":"cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","6b4a1a51":"# En y\u00fcksek olas\u0131l\u0131k skoruna ait indeksi \u00e7ekiyoruz.\ny_pred = np.argmax(predictions, axis=1)\n\n# Test foto\u011fraflar\u0131n\u0131n labellar\u0131.\ny_true = test_batches.classes","b1ca0f36":"from sklearn.metrics import classification_report\n\n# Classification report olu\u015fturuyoruz.\nreport = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n\nprint(report)","712797d6":"#MODEL\u0130M\u0130Z\u0130 B\u0130T\u0130RD\u0130K.\n### ===================================================================================== ###\n# Modeli Keras'dan Tensorflow.js ye d\u00f6n\u00fc\u015ft\u00fcrme zaman\u0131.","a9667711":"# Klas\u00f6rleri Kaggle da hata almamak i\u00e7in temizliyoruz.\nshutil.rmtree('base_dir')","d402b6b9":"# Giri\u015f\n\nBu proje cilt kanseri \u015f\u00fcphesi i\u00e7in \u00f6n tan\u0131 ama\u00e7l\u0131 geli\u015ftirilmi\u015ftir. Bir doktor te\u015fhisi de\u011fildir ve sadece \u00f6neri niteli\u011findedir. ANN algotirmas\u0131 kullan\u0131larak g\u00f6r\u00fcnt\u00fc i\u015fleme y\u00f6ntemi ile veri setlerinden bir \u00e7\u0131kt\u0131 al\u0131nmas\u0131 yoluyla tahminler yap\u0131lm\u0131\u015ft\u0131r. \u0130lerleyen zamanlarda mobil bir uygulamaya entegre edilecektir. Sayg\u0131lar...","1b095313":"\u015eimdi ise cilt kanserine yakalananlar\u0131n ya\u015flar\u0131na g\u00f6z atal\u0131m.","8df1602a":"V\u00fccuttaki yerle\u015fkelerini g\u00f6steren plot.","982c6f52":"### Validation Seti(Create a val set)","88bbed85":"*Recall*= Bir s\u0131n\u0131f verildi\u011finde, s\u0131n\u0131fland\u0131r\u0131c\u0131 bunu alg\u0131layabilecek mi? <br>\n*Precision*= Bir s\u0131n\u0131fland\u0131r\u0131c\u0131dan bir s\u0131n\u0131f tahmini verildi\u011finde, bunun do\u011fru olma olas\u0131l\u0131\u011f\u0131 ne kadar?<br>\n*F1 Score* = Geri \u00e7a\u011f\u0131rma ve hassasiyetin harmonik ortalamas\u0131.","9ed5120d":"### Classification Report Olu\u015fturma(Generate the Classification Report)","ace543c3":"### Validation Seti \u0130le Modeli De\u011ferlendirin.(Evaluate the model using the val set)","11424d0e":"### Visualize 50 augmented images(Visualize 50 augmented images)","53f57a1a":"\nKaynak Veri(Source):<br>\n> The HAM10000 Dataset: A Large Collection of Multi-Source Dermatoscopic Images of Common Pigmented Skin Lesions<br>\nhttps:\/\/arxiv.org\/abs\/1803.10417\n\n\n\n **nv**<br>\n Melanositik neviler, melanositlerin iyi huylu neoplazmalar\u0131d\u0131r ve hepsi serimizde yer alan say\u0131s\u0131z de\u011fi\u015fkende g\u00f6r\u00fcn\u00fcr. Varyantlar dermatoskopik bak\u0131\u015f a\u00e7\u0131s\u0131ndan \u00f6nemli \u00f6l\u00e7\u00fcde farkl\u0131l\u0131k g\u00f6sterebilir<br>\n *[6705 resim]*\n \n **mel**<br>\nMelanom, farkl\u0131 varyantlarda ortaya \u00e7\u0131kabilen melanositlerden t\u00fcretilmi\u015f bir malign neoplazmd\u0131r. Erken a\u015famada eksize edilirse basit cerrahi eksizyon ile tedavi edilebilir. Melanomlar invaziv veya invaziv olmayabilir (in situ). Yerinde melanom dahil t\u00fcm melanom varyantlar\u0131n\u0131 dahil ettik, ancak pigmente olmayan, subungual, ok\u00fcler veya mukozal melanomu hari\u00e7 tuttuk.<br>*[1113 resim]*\n \n \n**bkl**<br>\n \"Benign keratoz\", seboreik kertozlar\u0131 (\"senil si\u011fil\"), g\u00fcne\u015f lentigo - d\u00fcz bir seboreik keratoz varyant\u0131 olarak kabul edilebilir - ve seboreik bir keratoza benzeyen liken-planus (LPLK) i\u00e7eren genel bir s\u0131n\u0131ft\u0131r keratoz veya iltihapl\u0131 solar lentigo\nve gerileme [22]. \u00dc\u00e7 alt grup dermatolojik olarak farkl\u0131 g\u00f6r\u00fcnebilir, ancak onlar\u0131 grupland\u0131rd\u0131k \u00e7\u00fcnk\u00fc biyolojik olarak benzerler ve s\u0131kl\u0131kla ayn\u0131 jenerik terim alt\u0131nda histopatolojik olarak bildiriliyorlar. Dermatoskopik bir bak\u0131\u015f a\u00e7\u0131s\u0131ndan, liken planus benzeri keratozlar \u00f6zellikle zordur \u00e7\u00fcnk\u00fc melanomay\u0131 taklit eden morfolojik \u00f6zellikler g\u00f6sterebilirler [23] ve \u00e7o\u011fu kez biyopsi yaparlar veya tan\u0131 nedenleriyle eksize edilirler.<br>\n*[1099 resim]*\n\n**bcc**<br>\nBazal h\u00fccreli karsinom nadiren metastaz yapan ancak tedavi edilmedi\u011finde y\u0131k\u0131c\u0131 olarak b\u00fcy\u00fcyen epitel cilt kanserinin yayg\u0131n bir \u00e7e\u015fididir. Hepsi bu sete dahil olan farkl\u0131 morfolojik varyantlarda (yass\u0131, nod\u00fcler, pigmentli, kistik vb.) Ortaya \u00e7\u0131kar.*[514 resim]*\n \n**akiec**<br>\nAktinik Keratozlar (Solar Keratozlar) ve intraepitelyal Karsinom (Bowen hastal\u0131\u011f\u0131), ameliyat olmadan lokal olarak tedavi edilebilen yayg\u0131n non-invaziv, skuam\u00f6z h\u00fccreli karsinom varyantlar\u0131d\u0131r. Baz\u0131 yazarlar bunlar\u0131 as\u0131l kanserler olarak de\u011fil, skuam\u00f6z h\u00fccreli karsinomlar\u0131n \u00f6nc\u00fcleri olarak kabul eder. Bununla birlikte, bu lezyonlar\u0131n, genellikle pigmentli olmayan, invazif skuam\u00f6z h\u00fccreli karsinom i\u00e7in ilerleyebilece\u011fi konusunda bir anla\u015fma vard\u0131r. Her iki neoplazma genellikle y\u00fczey \u00f6l\u00e7eklemesi g\u00f6sterir ve genellikle pigmentten yoksundur. Aktinik keratozlar y\u00fczlerde daha s\u0131k g\u00f6r\u00fcl\u00fcr ve Bowen hastal\u0131\u011f\u0131 di\u011fer v\u00fccut b\u00f6lgelerinde daha s\u0131k g\u00f6r\u00fcl\u00fcr. Her iki tip de UV \u0131\u015f\u0131\u011f\u0131ndan etkilendi\u011finden, \u00e7evreleyen cilt genellikle Bowen hastal\u0131\u011f\u0131, UV de\u011fil, insan papilloma vir\u00fcs\u00fc enfeksiyonunun neden oldu\u011fu durumlar hari\u00e7, zarar g\u00f6rm\u00fc\u015f \u015fiddetli g\u00fcne\u015fe maruz kal\u0131r. Pigmentli varyantlar Bowen hastal\u0131\u011f\u0131 [19] ve aktinik keratozlar [20] i\u00e7in mevcuttur. Her ikisi de bu sete dahil edilmi\u015ftir.<br>*[327 resim]*\n\n\n**vasc**<br>\nVeri setindeki vask\u00fcler cilt lezyonlar\u0131 kiraz anjiyomlar\u0131ndan anjiyokeratomlara [25] ve piyojenik gran\u00fclomlara [26] kadar uzan\u0131r. Kanama da bu kategoriye dahil edilmi\u015ftir.<br>\n*[142 resim]*\n\n**df**<br>\n\n204\/5000\nDermatofibroma, iyi huylu bir proliferasyon veya minimal travmaya kar\u015f\u0131 enflamatuar bir reaksiyon olarak g\u00f6r\u00fclen iyi huylu bir cilt lezyonudur. Dermatoskopik olarak s\u0131kl\u0131kla merkezi bir fibrozis zonu g\u00f6steren kahverengidir [24].<br>*[115 resim]*\n\n\n<br>*[Toplam Resim Say\u0131s\u0131 = 10015]*","2691bfaa":"### Confusion Matrix Olu\u015fturma(Create a Confusion Matrix)","42422256":"### EDA","c3dbdc1a":"### Modeli olu\u015fturma.(Creating Model)","f975ca3e":"<a href=\"https:\/\/ibb.co\/KVDPqdf\"><img src=\"https:\/\/i.ibb.co\/8PbC5qf\/cover.png\" alt=\"cover\" border=\"0\"><\/a>","ae3203e1":"\u015eimdi ise cilt kanserine yakalananlar\u0131n cinsiyetlerine g\u00f6z atal\u0131m.","bfe2498b":"### MobileNet Model","1911c375":"### Training E\u011frilerini \u00c7izdiriyoruz(Plot the Training Curves)","e075b005":"G\u00f6r\u00fcn\u00fc\u015fe g\u00f6re Melanositik nevi t\u00fcr\u00fcnde \u00f6rnek say\u0131m\u0131z olduk\u00e7a fazla.\n\n1. Histopathology(Histo): Eksize edilmi\u015f lezyonlar\u0131n histopatolojik tan\u0131lar\u0131 uzman dermatopatologlar taraf\u0131ndan yap\u0131lm\u0131\u015ft\u0131r.\n2. Confocal: Yans\u0131ma konfokal mikroskobu, h\u00fccresel seviyeye yak\u0131n \u00e7\u00f6z\u00fcn\u00fcrl\u00fckte bir in vivo g\u00f6r\u00fcnt\u00fcleme tekni\u011fidir ve Lab-renk alan\u0131nda manuel olarak yap\u0131lan histogram de\u011fi\u015fikliklerinden \u00f6nce ve sonra t\u00fcm antrenman g\u00f6r\u00fcnt\u00fclerinin gri-d\u00fcnya varsay\u0131m\u0131na sahip baz\u0131 y\u00fcz benignleridir. .\n3. Follow-up: Dijital dermatoskopi ile izlenen neviler 3 takip ziyareti s\u0131ras\u0131nda herhangi bir de\u011fi\u015fiklik g\u00f6stermediyse ya da 1.5 y\u0131l biyologlar bunu biyolojik iyi niyetli oldu\u011funun kan\u0131t\u0131 olarak kabul ettiler. Dermatologlar genellikle dermatofibromlar\u0131, seboreik keratozlar\u0131 veya vask\u00fcler lezyonlar\u0131 izlememeleri nedeniyle, sadece nevus, ancak ba\u015fka benign tan\u0131lar\u0131 bu t\u00fcr ger\u00e7eklerle etiketlenmedi.\n4. Consensus: Histopatolojisi veya takip biyologlar\u0131 olmayan tipik iyi huylu vakalar i\u00e7in, yazarlar PT ve HK'nin uzman-konsens\u00fcs derecesini sunar. Konsens\u00fcs etiketini ancak her iki yazar ba\u011f\u0131ms\u0131z olarak ayn\u0131 kesin benign tan\u0131y\u0131 verdi\u011finde uygulad\u0131lar. Bu t\u00fcr temellere sahip lezyonlar genellikle e\u011fitim nedenleriyle foto\u011frafland\u0131 ve onay i\u00e7in daha fazla takip veya biyopsi gerektirmedi.","11283d30":"### Train resimlerini aug_dir'e kopyal\u0131yoruz.(Copy the train images into aug_dir)","9c3a714b":"* **Zaman Ay\u0131rd\u0131\u011f\u0131n\u0131z \u0130\u00e7in Te\u015fekk\u00fcrler:) Destek olmak istiyorsan\u0131z l\u00fctfen puanlamay\u0131 ve yorum b\u0131rak\u0131n**\n* **Thanks for your reading. If you support me please vote up and leave comment**","8cdd7edd":"### Dizin yap\u0131s\u0131 olu\u015fturmak.(Create the directory structure)\n\nBu klas\u00f6rlerde daha sonra Keras modelimizi besleyecek g\u00f6r\u00fcnt\u00fcleri saklayaca\u011f\u0131z.","7e9ea703":"### Modeli E\u011fitme(Train the Model)","f34df221":"### G\u00f6r\u00fcnt\u00fcleri Klas\u00f6rlere Aktar\u0131yoruz.(Transfer the Images into the Folders)"}}