{"cell_type":{"10104368":"code","5a8e05d4":"code","3cbfaf10":"code","0d704885":"code","78bc2b3a":"code","404e261d":"code","9b648038":"code","03f5ba6d":"code","6d153839":"code","75c6cd45":"code","227d983f":"code","3c423acc":"code","7888b3c3":"code","c1b77fd7":"code","6a71a349":"code","5a64a8ff":"markdown","84e6eabd":"markdown","5dffc562":"markdown","6cbc000c":"markdown","0e6aeeff":"markdown","a11446e5":"markdown","caaf11f5":"markdown","364f0118":"markdown","90facbe6":"markdown","001d9054":"markdown"},"source":{"10104368":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, sys","5a8e05d4":"from sklearn.datasets import fetch_20newsgroups\nfrom gensim import corpora\nfrom gensim.parsing import strip_tags, strip_numeric, \\\n    strip_multiple_whitespaces, stem_text, strip_punctuation, \\\n    remove_stopwords, preprocess_string\nimport pprint\nimport re","3cbfaf10":"# get all the news group docs\ndata = fetch_20newsgroups(subset='all')","0d704885":"# collect all text documents as list\ntext_docs = data['data']","78bc2b3a":"# preprocess using gensim.parsing\n# ref: https:\/\/www.kaggle.com\/venkatkrishnan\/gensim-text-mining-techniques\ntransform_to_lower = lambda s: s.lower()\n\nremove_single_char = lambda s: re.sub(r'\\s+\\w{1}\\s+', '', s)\n\n# Filters to be executed in pipeline\nCLEAN_FILTERS = [strip_tags,\n                strip_numeric,\n                strip_punctuation, \n                strip_multiple_whitespaces, \n                transform_to_lower,\n                remove_stopwords,\n                remove_single_char]\n\n# Method does the filtering of all the unrelevant text elements\ndef cleaning_pipe(document):\n    # Invoking gensim.parsing.preprocess_string method with set of filters\n    processed_words = preprocess_string(document, CLEAN_FILTERS)\n    \n    return processed_words\nprint(cleaning_pipe(text_docs[0]))","404e261d":"def create_dictionary(docs):\n    'create dictionary of words in preprocessed corpus'\n    pdocs = [cleaning_pipe(doc) for doc in docs]\n    dictionary = corpora.Dictionary(pdocs)\n    dictionary.save('newsgroup.dict')\n    return dictionary,pdocs","9b648038":"dictionary, pdocs = create_dictionary(text_docs)","03f5ba6d":"len(dictionary)","6d153839":"new_doc = \"Human computer interaction\"\nnew_vec = dictionary.doc2bow(cleaning_pipe(new_doc))\nprint(new_vec)","75c6cd45":"bow_corpus = [dictionary.doc2bow(text) for text in pdocs]","227d983f":"from gensim import models\n\n# train the model\ntfidf = models.TfidfModel(bow_corpus)","3c423acc":"# transform any new document as tfidf vector\nwords = cleaning_pipe(\"want to sell bike\")\nprint(tfidf[dictionary.doc2bow(words)])","7888b3c3":"# index the tfidf vector of corpus as sparse matrix\nfrom gensim import similarities\nindex = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=len(dictionary))","c1b77fd7":"def get_closest_n(query, n):\n    '''get the top matching docs as per cosine similarity\n    between tfidf vector of query and all docs'''\n    query_document = cleaning_pipe(query)\n    query_bow = dictionary.doc2bow(query_document)\n    sims = index[tfidf[query_bow]]\n    top_idx = sims.argsort()[-1*n:][::-1]\n    return [text_docs[i] for i in top_idx]","6a71a349":"for d in get_closest_n(\"how to sell my broken aeroplane\",2):\n    print(d)","5a64a8ff":"### Fit the tfidf model a.k.a tfidf vectorizer","84e6eabd":"### Define corpus dictionary","5dffc562":"### Retrieve top N document for the given query string","6cbc000c":"### Transform any sample document as per the known dictionary","0e6aeeff":"### Get the dataset as text corpus","a11446e5":"## TFIDF based retrial using gensim\n\nThis notebook defines the **gensim-based document retrieval method based on tf-idf similarity score** (between corpus documents and the query string).\n\n1. Cleanup \/ preprocess \n2. Define dictionary\n3. Transform corpus - Bag of Worgs\n4. Learn tfidf vectors for corpus\n5. Sparse matrix indexing for similarity scoring\n6. Retrieve top N document for the given query string","caaf11f5":"## Sparse matrix indexing for similarity scoring","364f0118":"### Transform complete corpus as BoW","90facbe6":"### Preprocess the text corpus","001d9054":"- dictionary is huge in size (177k unique words - 177k dimensions) but gensim will be able to manage it efficiently."}}