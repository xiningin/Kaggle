{"cell_type":{"e604343f":"code","e408216d":"code","524ff17a":"code","275208ba":"code","fef0cb40":"code","76349fe7":"code","abb64989":"code","7e238590":"code","7fb5fbf7":"code","53181034":"code","c619a8ea":"code","8927c47f":"code","52bd9bd4":"code","a3128a21":"code","b0deea54":"code","1dc03f3e":"code","610ef9aa":"code","0c0a4311":"code","10dedf58":"code","5234a330":"markdown","1be8c447":"markdown","d70aaa3c":"markdown","984cae7b":"markdown","50feb1e8":"markdown","6b1258fa":"markdown","d0b0cbed":"markdown","9e5c54f0":"markdown","ca41d3d4":"markdown","435889bf":"markdown","20e1d9ea":"markdown","5bb91769":"markdown","a5d48548":"markdown","39b5f807":"markdown","47ca9d3b":"markdown","f7c61f34":"markdown","a5bd2a3b":"markdown","32dc530e":"markdown","a723aa3f":"markdown","cf06f470":"markdown","62fa8ba1":"markdown"},"source":{"e604343f":"# General Essential Libraries for data analysis:\nimport numpy as np \nimport pandas as pd \n\nimport seaborn as sns \nsns.set(style = \"whitegrid\")\nimport matplotlib.pyplot as plt \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","e408216d":"# Libraries for data visualisation: \nimport plotly.plotly as py\nimport plotly.tools as tls\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n%matplotlib inline\nimport seaborn as sns","524ff17a":"# Libraries for Machine Learning Algroithyms:\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder \n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor","275208ba":"# This creates a pandas dataframe and assigns it to the titanic variable.\ntitanic = pd.read_csv(\"..\/input\/train.csv\")\ntitanic_test = pd.read_csv(\"..\/input\/test.csv\")\n\n# Print the first 5 rows of the dataframe.\ntitanic.head()","fef0cb40":"#shape command will give number of rows\/samples and number of columns\/features\/predictors in dataset\n#(rows,columns)\n#titanic.shape\nprint (\"The shape of the train data is (row, column):\"+ str(titanic.shape))","76349fe7":"#Describe gives statistical information about numerical columns in the dataset\ntitanic.describe()","abb64989":"#Describe gives statistical information about obj\/Categorial columns in the dataset\ntitanic.describe(include =['O','category'])","7e238590":"#info method provides information about dataset like \n#total values in each column, null\/not null, datatype, memory occupied etc\ntitanic.info()\nprint(\"-\"*70)\ntitanic_test.info()","7fb5fbf7":"# Missing values in Train Datasets\n\ntotal = titanic.isnull().sum().sort_values(ascending = False)\npercent = round(titanic.isnull().sum().sort_values(ascending = False)\/len(titanic)*100, 2)\npd.concat([total, percent], axis = 1,keys= ['Total', 'Percent'])","53181034":"#Lets find distinct percentage of Embarked Category in Traing Dataset.\npercent = pd.DataFrame(round(titanic.Embarked.value_counts(dropna=False, normalize=True)*100,2))\ntotal = pd.DataFrame(titanic.Embarked.value_counts(dropna=False))\ntotal.columns = [\"Total\"]\npercent.columns = ['Percent']\npd.concat([total, percent], axis = 1)","c619a8ea":"titanic[titanic.Embarked.isnull()]","8927c47f":"fig, ax = plt.subplots(figsize=(16,12),ncols=3)\nax1 = sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Survived\", data=titanic, ax = ax[0] , palette=\"colorblind\");\nax2 = sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=titanic, ax = ax[1] , palette=\"colorblind\");\nax3 = sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Sex\", data=titanic, ax = ax[2] , palette=\"colorblind\");\n\nax1.set_title(\"Embarked~Fare~Survived\", fontsize = 18)\nax2.set_title(\"Embarked~Fare~Pclass\",  fontsize = 18)\nax3.set_title(\"Embarked~Fare~Sex\",  fontsize = 18)\nfig.show()","52bd9bd4":"# Fill the NAN with C for Embarked column\ntitanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('C')","a3128a21":"[i[0] for i in titanic.Cabin]","b0deea54":"titanic[titanic.Age.isnull()].head(5)","1dc03f3e":"def MissingAge_RandomForest(df):\n    #Feature set\n    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp','Ticket', 'Pclass','Cabin']]\n    # Split sets into train and test\n    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(test.values[:, 1::])\n    # Assign those predictions to the full data set\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df","610ef9aa":"with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"blue\")\n    plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\");","0c0a4311":"MissingAge_RandomForest(titanic)","10dedf58":"#age = titanic.loc[:,\"Age\":] \n#temp = age.loc[age.Age.notnull()] ## df with age values\n#temp_test = age_df.loc[age_df.Age.isnull()] ## df without age values\n#age\n#y = temp_train.Age.values ## setting target variables(age) in y \n#x = temp_train.loc[:, \"Sex\":].values","5234a330":"Age is realy critical factor in this dataset which canot replaced with 0 or medium\/mean value in case of NAN\nSo we are going to use machine learning algo to predict the missing values.  ( Randome Forest , KNN .. etc )","1be8c447":"We are going to use below library in python.\n![image.png](attachment:image.png)","d70aaa3c":"# 2. Importing the dataset","984cae7b":"From above BoxPlot we can find out Embarked = C is Most appropriate to fill in missing value.","50feb1e8":"# 1. Importing the Libraries","6b1258fa":"If you look cabin data we can get distinct data on basis of 1st charecters ( N , C , B , D .... )","d0b0cbed":"**Embarked feature**","9e5c54f0":"Let's see what is the value of Embarked from other rows where Survived = 1 , Pclass = 1 , Sex = Female, Fare =80.0","ca41d3d4":"![image.png](attachment:image.png)","435889bf":"** Dealing with Missing values**","20e1d9ea":"There are two rows which has NAN values for Embarked. Below are the rows.","5bb91769":"Machine Learning is the fastest growing technology sector today. There are plenty of different libraries like Scikit-learn, Tensorflow, Pandas, NumPy, Matplotlib, Keras. We will use Scikit-learn.\n\nMachine Learning problems fall into one of two categories: Supervised and Unsupervised\n\n### Supervised \nSupervised learning is the learning of the model where with input variable ( say, x) and an output variable (say, Y) and an algorithm to map the input to the output.\nThat is, Y = f(X)\nIt is called supervised learning because the process of an learning(from the training dataset) can be thought of as a teacher who is supervising the entire learning process.\n\n### Unsupervised\nUnsupervised learning is where only the input data (say, X) is present and no corresponding output variable is there.\nThe main aim of Unsupervised learning is to model the distribution in the data in order to learn more about the data.\nIt is called so, because there is no correct answer and there is no such teacher(unlike supervised learning).\n\n","a5d48548":"* Age ==>> Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n* Sibsp ==>> The dataset defines family relations in this way...\n               a. Sibling = brother, sister, stepbrother, stepsister\n               b. Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n* Parch ==>> The dataset defines family relations in this way...\n                a. Parent = mother, father\n                b. Child = daughter, son, stepdaughter, stepson\n                c. Some children travelled only with a nanny, therefore parch=0 for them.\n* Pclass ==>> A proxy for socio-economic status (SES)\n                1st = Upper\n                2nd = Middle\n                3rd = Lower\n* Embarked ==>> nominal datatype\n* Name ==>> nominal datatype . It could be used in feature engineering to derive the gender from title\n* Sex ==>> nominal datatype\n* Ticket ==>> that have no impact on the outcome variable. Thus, they will be excluded from analysis\n* Cabin ==>> is a nominal datatype that can be used in feature engineering\n* Fare ==>> Indicating the fare\n* PassengerID ==>> have no impact on the outcome variable. Thus, it will be excluded from analysis\n* Survival is ==>> dependent variable , 0 or 1","39b5f807":"For object data (e.g. strings or timestamps), the result\u2019s index will include count, unique, top, and freq. The top is the most common value.","47ca9d3b":"# Machine Learning","f7c61f34":"For numeric data, the result\u2019s index will include count, mean, std, min, max as well as lower, 50 and upper percentiles. By default the lower percentile is 25 and the upper percentile is 75. The 50 percentile is the same as the median.","a5bd2a3b":"There are many options we could consider when replacing a missing value, for example:\n\n* A constant value that has meaning within the domain, such as 0, distinct from all other values.\n* A value from another randomly selected record.\n* A mean, median or mode value for the column. (  test statistic )\n* A value estimated by another predictive model.\n* Drop the NAN Columns or Row","32dc530e":"**Age feature**","a723aa3f":"# 3. Overview and Cleaning the Data","cf06f470":"**Cabin feature**","62fa8ba1":"**Variables**"}}