{"cell_type":{"5e9ff273":"code","661f62e3":"code","aa0e81de":"code","cb437eab":"code","a017dfce":"code","a6bdfd34":"code","74a84b32":"code","0dfd769b":"code","238de309":"code","45595b5f":"code","ee183734":"code","7b0e61d5":"code","9aec7ebd":"code","e36f13f1":"code","bcaa6ba2":"code","64468e0c":"code","b1cd9293":"code","af5a20a1":"code","b1072b12":"code","f80c68cb":"code","9a330c9d":"code","78b26ce1":"code","a7ddaa67":"code","0f2d3d52":"code","99a844b0":"code","b17f1992":"code","3068dad6":"code","6ca3806e":"code","70edc0aa":"code","4dde136f":"code","37f86172":"code","5ced864b":"code","f7716ab0":"code","ece730e7":"code","245acd34":"code","f97240a3":"code","a3183d37":"code","92299d31":"code","751ba407":"code","37e480a0":"code","2aa63714":"code","f4639446":"code","06559654":"code","0db844dd":"code","0ac4a8a9":"code","5aa7da26":"code","bf10f7c7":"markdown","17a7d70d":"markdown","438117b1":"markdown","d4fad384":"markdown","d358c853":"markdown","68a454a3":"markdown","423d318d":"markdown","f001d2d3":"markdown","300378f6":"markdown","d18bc623":"markdown","046859ac":"markdown","eb654141":"markdown","2c73d029":"markdown","80a5ede1":"markdown","d3dfd81f":"markdown","1506a1c5":"markdown"},"source":{"5e9ff273":"import numpy as np # Linear Algebra\n\nimport pandas as pd # Dataset related Filtering\n\nimport seaborn as sns # Beautiful Graphs\nsns.set_style('dark') # Set graph styles to 'dark'\n\nimport matplotlib.pyplot as plt # Normal ploating graphs\n# show graphs in this notebook only \n%matplotlib inline\n\nimport plotly.express as px # For interactive plots\n\n\n# ignore  the warning\nimport warnings  \nwarnings.filterwarnings('ignore') \n\n","661f62e3":"# Read Train.csv File \ntrainDF = pd.read_csv('.\/..\/input\/titanic\/train.csv')\n\n# show first five rows from training dataset\ntrainDF.head()","aa0e81de":"# Read Test.csv File \ntestDF = pd.read_csv('.\/..\/input\/titanic\/test.csv')\n\n#  show 5 rows\ntestDF.head()","cb437eab":"# Print 5 Rows\ntestDF.head() # train() for last 5 rows","a017dfce":"def show_shape(train, test):\n    \"\"\" \n    display the shape of train and test DF \n    \n    \"\"\"   \n    print(\" Shape of Training DF\", train.shape)\n    print(\"\")\n    print(\" Shape of Testing DF\", test.shape)","a6bdfd34":"#  to know shape of the training and testing data\nshow_shape(trainDF, testDF)","74a84b32":"# Create an function to display the information of our train and test dataset. Function can be called multiple time in this notebook.\ndef show_info(train, test):\n    \"\"\" \n    display the Information of train and test DF \n    \n    \"\"\"\n    \n    print(\"Information of Training DF\"+ \"-\"*10)\n    print(train.info())\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    print(\"Information of Testing DF\"+ \"-\"*10)\n    print(test.info())","0dfd769b":"show_info(trainDF, testDF)","238de309":"removedFeatures = ['Name', 'Ticket', 'Cabin']\n\ntrainDF = trainDF.drop(removedFeatures, axis=1) # remove from train DF\ntestDF = testDF.drop(removedFeatures, axis=1) # remove from test DF\n\ntrainDF.head()","45595b5f":"# Age Feature\n\ntrainDF['Age'] = trainDF['Age'].fillna(trainDF['Age'].mean()) # fill for train DF\ntestDF['Age'] = testDF['Age'].fillna(testDF['Age'].mean()) # fill for test DF","ee183734":"trainDF['Embarked'].value_counts() # Group Wise count records","7b0e61d5":"# Fill to Embarked column NA with S\n \ntrainDF['Embarked'] = trainDF['Embarked'].fillna('S') # for train DF only\n","9aec7ebd":"# show info of train and test data set by calling function\n\nshow_info(trainDF, testDF)","e36f13f1":"# Show servived graph\n \n\n# Plot Counts for Each survived groupby counts\nfig = px.bar(trainDF.Survived.value_counts())\n\nfig.show()","bcaa6ba2":" \n\n# Plot Counts for Each survived groupby counts\nfig = px.bar(trainDF.groupby(['Survived']).count())\n\nfig.show()","64468e0c":"fig = px.histogram(trainDF, x='Survived', y='Pclass', color='Pclass');\nfig.show()","b1cd9293":" \nsns.catplot(x=\"Pclass\", col=\"Survived\", data=trainDF, kind=\"count\");\n\nplt.show()","af5a20a1":"fig = px.histogram(trainDF, x='Pclass', y= 'Survived', color='Pclass', )\nfig.show()","b1072b12":"#  Pclass wise survived graph \n\n\nplt.figure(figsize=(10, 7))\n\nsns.barplot(x= 'Pclass', y='Survived', data=trainDF)\nplt.title(\"Pclass wise survived \")\nplt.show()","f80c68cb":"# Gender wise Survived graph\n\nfig = px.bar(trainDF, x='Sex', y='Survived', color='Sex')\nfig.show()\n ","9a330c9d":"# Parch and Survived Bar graph\n \nplt.figure(figsize=(10, 7))\n\nsns.barplot(x = 'Parch', y= 'Survived', data= trainDF)\nplt.title(\"Parch and Survived Graph\")\n\nplt.show()","78b26ce1":"# Embarked and Survived bar Graph\nplt.figure(figsize=(10, 7))\n\nsns.barplot(x= 'Embarked', y = 'Survived', data= trainDF)\nplt.title(\"Embarked and Survived Graph\")\n\nplt.show()","a7ddaa67":"plt.figure(figsize=(10, 5))\nsns.distplot(trainDF.Fare)\nplt.title('Distribution of Fares')\nplt.show()","0f2d3d52":"# heatmap show\nplt.figure(figsize=(10, 7))\nsns.heatmap(trainDF.corr(), cmap='Greens', linewidths=1, annot=True, fmt='.1f')\n\nfig=plt.gcf()\nplt.show()","99a844b0":"# show the info\nshow_info(trainDF, testDF)","b17f1992":"# Fill na with median for Fare feature\n\ntestDF[\"Fare\"] = testDF[\"Fare\"].fillna(testDF[\"Fare\"].mean()) # for test DF only","3068dad6":"# Convert sex object values to numeric male=1 and female=0, for both train and test DF\n\ntrainDF['Sex'] = trainDF['Sex'].replace({'male': 0, 'female': 1})\ntestDF['Sex'] = testDF['Sex'].replace({'male': 0, 'female': 1})\n ","6ca3806e":"# count values for Embarked\nprint(testDF['Embarked'].value_counts())\nprint(trainDF['Embarked'].value_counts())\n","70edc0aa":"#  Now, Replace with alphabets to Numbers, for both train and test DF\n\ntrainDF['Embarked'] = trainDF['Embarked'].replace({'C': 1, 'S':2, 'Q': 3})\ntestDF['Embarked'] = testDF['Embarked'].replace({'C': 1, 'S': 2, 'Q': 3})","4dde136f":"print(trainDF.head())\nprint(testDF.head())","37f86172":"# Load Accuracy\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.metrics import confusion_matrix","5ced864b":"# Set Prediction value\n\nX_train = trainDF.drop(['PassengerId', 'Survived'], axis=1)\ny_train = trainDF['Survived']\nX_test = testDF.drop(['PassengerId'], axis=1)\n\n","f7716ab0":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\n","ece730e7":"# Load Model\nfrom sklearn.tree import DecisionTreeClassifier\n","245acd34":"\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n","f97240a3":"# To predict our model\n\npred = model.predict(X_test)\npred.shape","a3183d37":"# show prediction\n\naccu = model.score(X_train, y_train) # model accuracy\nprint( \"Model Prediction Score\", (accu * 100).round(2))\n","92299d31":"dict = {\n    'PassengerId' : testDF['PassengerId'],\n    'Survived' : pred\n}\n\nnew_submission = pd.DataFrame(dict, )\nnew_submission.shape","751ba407":"# Import other Models Classes\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.svm import SVC, LinearSVC\n\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier","37e480a0":"def model_wise_predict(models):\n    \"\"\" \n    Model Predictions\n    \n    \"\"\"\n    ans_score = []\n    for mdl, filename in models:\n        m = mdl\n        m.fit(X_train, y_train)\n        pred = m.predict(X_test)\n        m_accuracy = m.score(X_train, y_train)\n        ans_score.append((m_accuracy*100).round(2))\n        \n        dict = {\n            'PassengerId' : testDF['PassengerId'],\n            'Survived' : pred\n        }\n        new_submission = pd.DataFrame(dict, )\n        \n#         Uncomment this line if you want to generate all the csv file for all of the models.\n#         new_submission.to_csv(filename, index=False)\n        \n        \n    return ans_score","2aa63714":"#  Using DecisionTreeClassifier Model\n\n#  make list of Models\nmodels = [\n    (RandomForestClassifier(n_estimators=300, max_depth=20, random_state=5), 'DTC_submission.csv'),\n    (RandomForestClassifier(), 'RFC_submission.csv'),\n    (LogisticRegression(), 'LR_submission.csv'),\n    (LinearSVC(), 'SVC_submission.csv'),\n    (GaussianNB(), 'GNB_submission.csv'),\n    (SGDClassifier(), 'SGD_submission.csv'),\n    (KNeighborsClassifier(), 'KNC_submission.csv')\n]\n\ndata = model_wise_predict(models)\nprint(\"scores are\", data)","f4639446":"\nlist_model_name = [\n    'DecisionTreeClassifier',\n    'RandomForestClassifier',\n    'LogisticRegression', \n    'LinearSVC',\n    'GaussianNB',\n    'SGDClassifier', \n    'KNeighborsClassifier'\n]\n","06559654":"print(X_train, y_train)","0db844dd":"# Customize Model\n# TEST\n\n# HYPER TUNNING -------------------------------------------------------------- Start\n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nrfc_model = RandomForestClassifier(random_state=45)\n\n\nrfc_params_grid = {\n#     'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001],\n    'n_estimators':[100,250,500,750,1000,1250,1500,1750],\n    'max_depth': np.random.randint(1, (len(X_train.columns)*.85),20),\n    'max_features': np.random.randint(1, len(X_train.columns),20),\n    'min_samples_split':[2,4,6,8,10,20,40,60,100], \n    'min_samples_leaf':[1,3,5,7,9],\n    'criterion': [\"gini\", \"entropy\"]\n}\n\n# gscv_random_classifier = GridSearchCV(estimator = rfc_model, param_grid = rfc_params_grid, cv = 5 , n_jobs = -1, verbose = 5)\ngscv_random_classifier = RandomizedSearchCV(rfc_model, rfc_params_grid, cv = 5, n_jobs = -1, verbose = 5)\n\ngscv_random_classifier.fit(X_train, y_train)\n\npred = gscv_random_classifier.predict(X_test)\n\nprint(\"--------------- START ---------------\")\n\n# print(accuracy_score(y_test, pred))\nprint(gscv_random_classifier.best_estimator_)\nprint(gscv_random_classifier.best_score_)\nprint(gscv_random_classifier.best_params_)\nbestEstimator = gscv_random_classifier.best_estimator_\nbestParams = gscv_random_classifier.best_params_\n\nprint(\"--------------- OVER ---------------\")\n\n# HYPER TUNNING -------------------------------------------------------------- END","0ac4a8a9":"#  DOWNLOAD SUBMISSION\n\n# Submission FILE EXPORTING  -------------------------------------------------------------- Start\n# m = RandomForestClassifier(criterion='entropy', max_depth=7, min_samples_split=4,\n#                        n_estimators=750, random_state=42)\n\nm = RandomForestClassifier(criterion='entropy', max_depth=3, max_features=6,\n                       min_samples_split=4, n_estimators=1250, random_state=35)\n\nm.fit(X_train, y_train)\npred = m.predict(X_test)\n\nprint(\"Acc: \", m.score(X_train, y_train))\n\ndict = {\n    'PassengerId' : testDF['PassengerId'],\n    'Survived' : pred\n}\n\nnew_submission = pd.DataFrame(dict, )\nnew_submission.to_csv('Random-Forest-GSCV-Hyper Tunning.csv', index=False)\n\n# Submission FILE EXPORTING  -------------------------------------------------------------- END\n","5aa7da26":"\nmodelDF = pd.DataFrame({\"Model_Name\" : list_model_name, \"Pred_Score\": data})\nmodelDF.sort_values(by='Pred_Score', ascending=False)\nmodelDF","bf10f7c7":"* Remove Object type of feature from train and test datasets.\n\nHere we have some columns to remove from dataset \n","17a7d70d":"# Import Necessary Packages and Models for ML","438117b1":"* Showing Train and test shape of the dataset.","d4fad384":"# 1. Data Collection","d358c853":"* First of all We need to data to train our model to predict better result.\n\nSo, We need the data for train our model","68a454a3":"# 5. Model Submission","423d318d":"* Checking train and test dataset frame with first five rows from both datasets","f001d2d3":"> ###  Dataset Informations:\n\n1. survival - Survival (0 = No; 1 = Yes)\n- class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n- name - Name\n- sex - Sex\n- age - Age\n- sibsp - Number of Siblings\/Spouses Aboard\n- parch - Number of Parents\/Children Aboard\n- ticket - Ticket Number\n- fare - Passenger Fare\n- cabin - Cabin\n- embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","300378f6":"# 2. Feature Engineering","d18bc623":"0.78468\n\n\n97.98\n\n\nAcc:  0.8799102132435466\n\nAcc:  0.8832772166105499\n\n","046859ac":"- \nOther Machine learning scores calculating.","eb654141":"# 4. Model Prediction\n","2c73d029":"--- \n---\n\n<div class=\"text-center\">\n    <h1>That's it Guys,<\/h1>\n    <h1>\ud83d\ude4f<\/h1>\n    \n        \n        I Hope you guys you like and enjoy it, and learn something interesting things from this notebook, \n        \n        Even I learn a lots of  things while I'm creating this notebook\n    \n        Keep Learning,\n        Regards,\n        Vikas Ukani.\n    \n<\/div>\n\n---\n---\n\n<img src=\"https:\/\/static.wixstatic.com\/media\/3592ed_5453a1ea302b4c4588413007ac4fcb93~mv2.gif\" align=\"center\" alt=\"Thank You\" style=\"min-height:20%; max-height:20%\" width=\"90%\" \/>\n\n","80a5ede1":"# 3. Visualization\n\n","d3dfd81f":"# Prediction Dashboard","1506a1c5":"\n\n> OUTPUT\n\n\n```\nUPDATED Tunning\n\n--------------- START ---------------\nRandomForestClassifier(max_depth=7, max_features=5, min_samples_leaf=3,\n                       min_samples_split=4, n_estimators=600, random_state=35)\n0.8361747536250078\n{'criterion': 'gini', 'max_depth': 7, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 600}\n--------------- OVER ---------------\n\n\n--------------- START ---------------\nRandomForestClassifier(criterion='entropy', max_depth=7, max_features=5,\n                       min_samples_leaf=3, min_samples_split=9,\n                       n_estimators=1400, random_state=35)\n0.8339275626137719\n{'criterion': 'entropy', 'max_depth': 7, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 1400}\n--------------- OVER ---------------\n\n\n\n--------------- START ---------------\n\nRandomForestClassifier(max_depth=7, min_samples_split=6, n_estimators=850,\n                       random_state=42)\n0.8271985437197916\n{'criterion': 'gini', 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 850}\n--------------- OVER ---------------\n\n\nNEW --> Using RandomizedSearchCV\n\n--------------- START ---------------\nRandomForestClassifier(criterion='entropy', max_depth=7, min_samples_split=4,\n                       n_estimators=750, random_state=42)\n0.8193396522503296\n{'n_estimators': 750, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 7, 'criterion': 'entropy'}\n--------------- OVER ---------------\n\nOLD --> Using GridSearchCV\n--------------- START ---------------\nRandomForestClassifier(criterion='entropy', max_depth=7, n_estimators=600,\n                       random_state=45)\n0.8249513527085558\n{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'auto', 'n_estimators': 600}\n--------------- OVER ---------------\n```\n\n"}}