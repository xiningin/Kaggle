{"cell_type":{"e7c4a53e":"code","29a4b8fd":"code","9a613d34":"code","4bcab781":"code","fffb7240":"code","f520f1ea":"code","5a98cb9d":"code","6a4ad67d":"code","c778795f":"code","4e353a9f":"code","da163457":"code","7d227614":"code","6692e823":"code","917bbf7c":"code","564d0ef1":"code","b3fd6403":"code","9233eaae":"code","413dc180":"code","4660c868":"code","c3df43fd":"code","5fe9badb":"code","e998a2a4":"code","99bd8d8a":"code","de89fd07":"code","d6ffb874":"code","84db9cf1":"code","e1d41e2f":"code","067e715f":"code","abebf3d0":"code","0d94628f":"code","56354622":"code","adad1649":"code","4144f739":"code","1b315470":"code","74fd1d77":"code","b7fefb1f":"code","ff2b4a3b":"code","cc82328b":"code","5d61391b":"code","c3d18148":"code","ec7ad971":"markdown","dd883a6f":"markdown","3d53e853":"markdown","c17d55db":"markdown","2d57cd94":"markdown","d79ebce3":"markdown","3d188806":"markdown","e4fb53b3":"markdown","bdf69368":"markdown","af2321ef":"markdown","9acd0de3":"markdown","42f57ed6":"markdown","012cf481":"markdown","05caf59a":"markdown","ec252fd3":"markdown","69d73e70":"markdown","3a0f138d":"markdown","dce84504":"markdown","f87c472a":"markdown","06fb63a0":"markdown","b5378094":"markdown","ba24afd9":"markdown","8c5b0858":"markdown","31df7876":"markdown","465e9e90":"markdown","a5489ebc":"markdown","bebdc257":"markdown","fee4a56b":"markdown","49e559a6":"markdown","1f7b29c1":"markdown","0debf677":"markdown","73ede89a":"markdown","399dbbe4":"markdown","583a492f":"markdown","08ec11a6":"markdown","ba13db72":"markdown","c90586b3":"markdown"},"source":{"e7c4a53e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n############################################\n### DATASETS:\n\na= pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\nb= pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\nc=pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\nd=pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ne=pd.read_csv('..\/input\/lish-moa\/train_drug.csv')\nf=a.merge(e, how='left', on='sig_id')\n\nmerged=pd.concat([a,b])\n\n#Datasets for treated and control experiments\ntreated= a[a['cp_type']=='trt_cp']\ncontrol= a[a['cp_type']=='ctl_vehicle']\n\n#Datasets for treated and control: TEST SET\ntreated_t= b[b['cp_type']=='trt_cp']\ncontrol_t= b[b['cp_type']=='ctl_vehicle']\n\n#Treatment time datasets\ncp24= a[a['cp_time']== 24]\ncp48= a[a['cp_time']== 48]\ncp72= a[a['cp_time']== 72]\n\n#Merge scored and nonscored labels\nall_drugs= pd.merge(d, c, on='sig_id', how='inner')\n\n#Treated drugs without control\ntreated_list = treated['sig_id'].to_list()\ndrugs_tr= d[d['sig_id'].isin(treated_list)]\n\n#Select the columns c-\nc_cols3 = [col for col in b.columns if 'c-' in col]\n#Filter the TEST set\ncells3=treated[c_cols3]\n\n#Treated drugs:\nnonscored= c[c['sig_id'].isin(treated_list)]\nscored= d[d['sig_id'].isin(treated_list)]\n\n#adt= All Drugs Treated\nadt= all_drugs[all_drugs['sig_id'].isin(treated_list)]\n\n#Select the columns c-\nc_cols = [col for col in a.columns if 'c-' in col]\n#Filter the columns c-\ncells=treated[c_cols]\n\n#Select the columns g-\ng_cols = [col for col in a.columns if 'g-' in col]\n#Filter the columns g-\ngenes=treated[g_cols]\n\n\n\n#####################################################\n#### HELPER FUNCTIONS\n\ndef plotd(f1):\n    plt.style.use('seaborn')\n    sns.set_style('whitegrid')\n    fig = plt.figure(figsize=(15,5))\n    #1 rows 2 cols\n    #first row, first col\n    ax1 = plt.subplot2grid((1,2),(0,0))\n    plt.hist(control[f1], bins=4, color='mediumpurple',alpha=0.5)\n    plt.title(f'control: {f1}',weight='bold', fontsize=18)\n    #first row sec col\n    ax1 = plt.subplot2grid((1,2),(0,1))\n    plt.hist(treated[f1], bins=4, color='darkcyan',alpha=0.5)\n    plt.title(f'Treated with drugs: {f1}',weight='bold', fontsize=18)\n    plt.show()\n    \ndef plott(f1):\n    plt.style.use('seaborn')\n    sns.set_style('whitegrid')\n    fig = plt.figure(figsize=(15,5))\n    #1 rows 2 cols\n    #first row, first col\n    ax1 = plt.subplot2grid((1,3),(0,0))\n    plt.hist(cp24[f1], bins=3, color='deepskyblue',alpha=0.5)\n    plt.title(f'Treatment duration 24h: {f1}',weight='bold', fontsize=14)\n    #first row sec col\n    ax1 = plt.subplot2grid((1,3),(0,1))\n    plt.hist(cp48[f1], bins=3, color='lightgreen',alpha=0.5)\n    plt.title(f'Treatment duration 48h: {f1}',weight='bold', fontsize=14)\n    #first row 3rd column\n    ax1 = plt.subplot2grid((1,3),(0,2))\n    plt.hist(cp72[f1], bins=3, color='gold',alpha=0.5)\n    plt.title(f'Treatment duration 72h: {f1}',weight='bold', fontsize=14)\n    plt.show()\n\ndef plotf(f1, f2, f3, f4):\n    plt.style.use('seaborn')\n    sns.set_style('whitegrid')\n\n    fig= plt.figure(figsize=(15,10))\n    #2 rows 2 cols\n    #first row, first col\n    ax1 = plt.subplot2grid((2,2),(0,0))\n    sns.distplot(a[f1], color='crimson')\n    plt.title(f1,weight='bold', fontsize=18)\n    plt.yticks(weight='bold')\n    plt.xticks(weight='bold')\n    #first row sec col\n    ax1 = plt.subplot2grid((2,2), (0, 1))\n    sns.distplot(a[f2], color='gainsboro')\n    plt.title(f2,weight='bold', fontsize=18)\n    plt.yticks(weight='bold')\n    plt.xticks(weight='bold')\n    #Second row first column\n    ax1 = plt.subplot2grid((2,2), (1, 0))\n    sns.distplot(a[f3], color='deepskyblue')\n    plt.title(f3,weight='bold', fontsize=18)\n    plt.yticks(weight='bold')\n    plt.xticks(weight='bold')\n    #second row second column\n    ax1 = plt.subplot2grid((2,2), (1, 1))\n    sns.distplot(a[f4], color='black')\n    plt.title(f4,weight='bold', fontsize=18)\n    plt.yticks(weight='bold')\n    plt.xticks(weight='bold')\n\n    return plt.show()\n\ndef ploth(data, w=15, h=9):\n    plt.figure(figsize=(w,h))\n    sns.heatmap(data.corr(), cmap='hot')\n    plt.title('Correlation between targets', fontsize=25, weight='bold')\n    return plt.show()\n\n# corrs function: Show dataframe of high correlation between features\ndef corrs(data, col1='Gene 1', col2='Gene 2',rows=5,thresh=0.8, pos=[1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53]):\n        #Correlation between genes\n        corre= data.corr()\n         #Unstack the dataframe\n        s = corre.unstack()\n        so = s.sort_values(kind=\"quicksort\", ascending=False)\n        #Create new dataframe\n        so2= pd.DataFrame(so).reset_index()\n        so2= so2.rename(columns={0: 'correlation', 'level_0':col1, 'level_1': col2})\n        #Filter out the coef 1 correlation between the same drugs\n        so2= so2[so2['correlation'] != 1]\n        #Drop pair duplicates\n        so2= so2.reset_index()\n        pos = pos\n        so3= so2.drop(so2.index[pos])\n        so3= so3.drop('index', axis=1)\n        #Show the first 10 high correlations\n        cm = sns.light_palette(\"Red\", as_cmap=True)\n        s = so3.head(rows).style.background_gradient(cmap=cm)\n        print(f\"{len(so2[so2['correlation']>thresh])\/2} {col1} pairs have +{thresh} correlation.\")\n        return s\n\ndef plotgene(data):\n    sns.set_style('whitegrid')    \n    data.plot.bar(color=sns.color_palette('Reds',885), edgecolor='black')\n    set_size(13,5)\n    #plt.xticks(rotation=90)\n    plt.tick_params(\n        axis='x',          # changes apply to the x-axis\n        which='both',      # both major and minor ticks are affected\n        bottom=False,      # ticks along the bottom edge are off\n        top=False,         # ticks along the top edge are off\n        labelbottom=False) # labels along the bottom edge are off\n    plt.ylabel('Gene expression values', weight='bold')\n    plt.title('Mean gene expression of the 772 genes', fontsize=15)\n    return plt.show()\n\ndef mean(row):\n    return row.mean()\n\ndef set_size(w,h, ax=None):\n    \"\"\" w, h: width, height in inches \"\"\"\n    if not ax: ax=plt.gca()\n    l = ax.figure.subplotpars.left\n    r = ax.figure.subplotpars.right\n    t = ax.figure.subplotpars.top\n    b = ax.figure.subplotpars.bottom\n    figw = float(w)\/(r-l)\n    figh = float(h)\/(t-b)\n    ax.figure.set_size_inches(figw, figh)\n    \ndef unidrug(data):\n    #Filter out just the treated samples\n    scored= data[data['sig_id'].isin(treated_list)]\n\n    #Count unique values per column\n    cols = data.columns.to_list() # specify the columns whose unique values you want here\n    uniques = {col: data[col].nunique() for col in cols}\n    uniques=pd.DataFrame(uniques, index=[0]).T\n    uniques=uniques.rename(columns={0:'count'})\n    uniques= uniques.drop('sig_id', axis=0)\n    return uniques\n\ndef avgdrug(data):\n    \n    uniques=unidrug(data)\n\n     #Calculate the mean values\n    scored= data[data['sig_id'].isin(treated_list)]\n    average=scored.mean()\n    average=pd.DataFrame(average)\n    average=average.rename(columns={ 0: 'mean'})\n    average['percentage']= average['mean']*100\n    \n    return average\n\ndef avgfiltered(data):\n    \n    average= avgdrug(data)\n    #Filter just the drugs with mean >0.01\n    average_filtered= average[average['mean'] > 0.01]\n    average_filtered= average_filtered.reset_index()\n    average_filtered= average_filtered.rename(columns={'index': 'drug'})\n    return average_filtered\n\ndef plotc(data, column, width=10, height=6, color=('silver', 'gold','lightgreen','skyblue','lightpink'), edgecolor='black'):\n    \n        fig, ax = plt.subplots(figsize=(width,height))\n        title_cnt=data[column].value_counts()[:15].sort_values(ascending=True).reset_index()\n        mn= ax.barh(title_cnt.iloc[:,0], title_cnt.iloc[:,1], color=sns.color_palette('Reds',len(title_cnt)))\n\n        tightout= 0.008*max(title_cnt[column])\n        ax.set_title(f'Count of {column}', fontsize=15, weight='bold' )\n        ax.set_ylabel(f\"{column}\", weight='bold', fontsize=12)\n        ax.set_xlabel('Count', weight='bold')\n        if len(data[column].unique()) < 17:\n            plt.xticks(rotation=65)\n        else:\n            plt.xticks(rotation=90)\n        for i in ax.patches:\n            ax.text(i.get_width()+ tightout, i.get_y()+0.1, str(round((i.get_width()), 2)),\n             fontsize=10, fontweight='bold', color='grey')\n        return\n    \ndef plot_drugid(drug_id):\n    g=d[f['drug_id']==drug_id]\n    average_filtered2=avgfiltered(g)\n\n    plt.figure(figsize=(5,2))\n    average_filtered2.sort_values('percentage', inplace=True) \n    plt.scatter(average_filtered2['percentage'], average_filtered2['drug'], color=sns.color_palette('Reds',len(average_filtered2)))\n    plt.title(f'Targets with higher presence in the drug: {drug_id} ', weight='bold', fontsize=15)\n    plt.xticks(weight='bold')\n    plt.yticks(weight='bold')\n    plt.xlabel('Percentage', fontsize=13)\n    return plt.show()","29a4b8fd":"a.head()","9a613d34":"plt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.countplot(x='cp_type', data=a, palette='rainbow', alpha=0.75)\nplt.title('Train: Control and treated samples', fontsize=15, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.countplot(x='cp_dose', data=a, palette='Purples', alpha=0.75)\nplt.title('Train: Treatment Doses: Low and High',weight='bold', fontsize=18)\nplt.show()","4bcab781":"plt.figure(figsize=(15,5))\nsns.distplot( a['cp_time'], color='red', bins=5)\nplt.title(\"Train: Treatment duration \", fontsize=15, weight='bold')\nplt.show()","fffb7240":"plotf('c-10', 'c-50', 'c-70', 'c-90')","f520f1ea":"plotd(\"c-30\")","5a98cb9d":"plott('c-30')","6a4ad67d":"#Select the columns c-\nc_cols = [col for col in a.columns if 'c-' in col]\n#Filter the columns c-\ncells=treated[c_cols]\n#Plot heatmap\nplt.figure(figsize=(15,6))\nsns.heatmap(cells.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Correlation: Cell viability', fontsize=15, weight='bold')\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.show()","c778795f":"corrs(cells, 'Cell', 'Cell 2', rows=7)","4e353a9f":"plotf('g-10','g-100','g-200','g-400')","da163457":"plotd('g-510')","7d227614":"plott('g-510')","6692e823":"#Select the columns g-\ng_cols = [col for col in a.columns if 'g-' in col]\n#Filter the columns g-\ngenes=treated[g_cols]\n#Plot heatmap\nplt.figure(figsize=(15,7))\nsns.heatmap(genes.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Gene expression: Correlation', fontsize=15, weight='bold')\nplt.show()","917bbf7c":"corrs(genes, 'Gene', 'Gene 2')","564d0ef1":"#Correlation between drugs\ncorre= genes.corr()\n#Unstack the dataframe\ns = corre.unstack()\nso = s.sort_values(kind=\"quicksort\", ascending=False)\n#Create new dataframe\nso2= pd.DataFrame(so).reset_index()\nso2= so2.rename(columns={0: 'correlation', 'level_0':'Drug 1', 'level_1': 'Drug2'})\n#Filter out the coef 1 correlation between the same drugs\nso2= so2[so2['correlation'] != 1]\n#Drop pair duplicates\nso2= so2.reset_index()\nso2= so2.sort_values(by=['correlation'])\npos = [1,3,5,7,9,11,13,15,17,19,21]\nso2= so2.drop(so2.index[pos])\nso2= so2.round(decimals=4)\nso2=so2.drop('index', axis=1)\nso3=so2.head(4)\n#Show the first 10 high correlations\ncm = sns.light_palette(\"Red\", as_cmap=True)\ns = so2.head().style.background_gradient(cmap=cm)\ns","b3fd6403":"#Transpose the dataframe\ngenesT=genes.T\n#Calculate the mean of each g_xxx feature\ngenesT['mean'] = genesT.apply (lambda row: mean(row), axis=1)\n#Plot the mean values\ngenesTm=genesT.reset_index()\ngenesTm=genesTm[['index', 'mean']]\nplotgene(genesTm)","9233eaae":"average= avgdrug(d)\nuniques=unidrug(d)\naverage_filtered=avgfiltered(d)\n\nplt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.countplot(uniques['count'], color='deepskyblue', alpha=0.75)\nplt.title('Unique elements per target [0,1]', fontsize=15, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.distplot(average['percentage'], color='orange', bins=20)\nplt.title(\"The targets mean distribution\", fontsize=15, weight='bold')\nplt.show()","413dc180":"plt.figure(figsize=(7,7))\naverage_filtered.sort_values('percentage', inplace=True) \nplt.scatter(average_filtered['percentage'], average_filtered['drug'], color=sns.color_palette('Reds',len(average_filtered)))\nplt.title('Targets with higher presence in train samples', weight='bold', fontsize=15)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.xlabel('Percentage', fontsize=13)\nplt.show()","4660c868":"inhibitors = [col for col in d.columns if 'inhibitor' in col]\nactivators = [col for col in d.columns if 'activator' in col]\nantagonists = [col for col in d.columns if 'antagonist' in col]\nagonists = [col for col in d.columns if 'agonist' in col]\nmodulators = [col for col in d.columns if 'modulator' in col]\nreceptors = [col for col in d.columns if 'receptor' in col]\nreceptors_ago = [col for col in d.columns if 'receptor_agonist' in col]\nreceptors_anta = [col for col in d.columns if 'receptor_antagonist' in col]\n\n\nlabelss= {'Drugs': ['inhibitors', 'activators', 'antagonists', 'agonists', 'receptors', 'receptors_ago', 'receptors_anta'],\n          'Count':[112,5,32,60, 53, 24, 26]}\n\n\nlabels= pd.DataFrame(labelss)\nlabels=labels.sort_values(by=['Count'])\nplt.figure(figsize=(15,5))\nplt.bar(labels['Drugs'], labels['Count'], color=sns.color_palette('Reds',len(labels)))\nplt.xticks(weight='bold')\nplt.title('Target types', weight='bold', fontsize=15)\nplt.show()","c3df43fd":"ploth(drugs_tr)","5fe9badb":"#Correlation between drugs\ncorre= drugs_tr.corr()\n#Unstack the dataframe\ns = corre.unstack()\nso = s.sort_values(kind=\"quicksort\", ascending=False)\n#Create new dataframe\nso2= pd.DataFrame(so).reset_index()\nso2= so2.rename(columns={0: 'correlation', 'level_0':'Target 1', 'level_1': 'Target 2'})\n#Filter out the coef 1 correlation between the same drugs\nso2= so2[so2['correlation'] != 1]\n#Drop pair duplicates\nso2= so2.reset_index()\npos = [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35]\nso2= so2.drop(so2.index[pos])\nso2= so2.round(decimals=4)\nso2=so2.drop('index', axis=1)\nso3=so2.head(4)\n#Show the first 10 high correlations\ncm = sns.light_palette(\"Red\", as_cmap=True)\ns = so2.head().style.background_gradient(cmap=cm)\ns","e998a2a4":"plt.figure(figsize=(8,10))\nthe_table =plt.table(cellText=so3.values,colWidths = [0.35]*len(so3.columns),\n          rowLabels=so3.index,\n          colLabels=so3.columns\n          ,cellLoc = 'center', rowLoc = 'center',\n          loc='left', edges='closed', bbox=(1,0, 1, 1)\n         ,rowColours=sns.color_palette('Reds',10))\nthe_table.auto_set_font_size(False)\nthe_table.set_fontsize(10.5)\nthe_table.scale(2, 2)\naverage_filtered.sort_values('percentage', inplace=True) \nplt.scatter(average_filtered['percentage'], average_filtered['drug'], color=sns.color_palette('Reds',len(average_filtered)))\nplt.title('Targets with higher presence in train samples', weight='bold', fontsize=15)\nplt.xlabel('Percentage', weight='bold')\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.show()","99bd8d8a":"#Extract unique elements per column\ncols2 = nonscored.columns.to_list() # specify the columns whose unique values you want here\nuniques2 = {col: nonscored[col].nunique() for col in cols2}\nuniques2=pd.DataFrame(uniques2, index=[0]).T\nuniques2=uniques2.rename(columns={0:'count'})\nuniques2= uniques2.drop('sig_id', axis=0)\n\n#############################\n### PLOT\nplt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.countplot(uniques2['count'], palette='Blues', alpha=0.75)\nplt.title('Nonscored: Unique elements per target [0,1]', fontsize=13, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.countplot(uniques['count'], color='cyan', alpha=0.75)\nplt.title('Scored: Unique elements per target [0,1]', fontsize=13, weight='bold')\nplt.show()","de89fd07":"print(f\"{len(uniques2[uniques2['count']==1])} targets without ANY mechanism of action in the nonscored dataset\")","d6ffb874":"#Filter out just the treated samples\n#Calculate the mean values\naverage2=nonscored.mean()\naverage2=pd.DataFrame(average2)\naverage2=average2.rename(columns={ 0: 'mean'})\naverage2['percentage']= average2['mean']*100\n#Filter just the drugs with mean >0.01\naverage_filtered2= average2[average2['mean'] > 0.01]\naverage_filtered2= average_filtered2.reset_index()\naverage_filtered2= average_filtered2.rename(columns={'index': 'drug'})\n\n#####################\n#Plot the percentage of MoAs\nplt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.distplot(average2['percentage'], color='blue', bins=20)\nplt.title('Percentage of the nonscored MoAs in the samples',weight='bold', fontsize=13)\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.distplot(average['percentage'], color='gold', bins=20)\nplt.title('Percentage of the scored MoAs in the samples',weight='bold', fontsize=13)\nplt.show()","84db9cf1":"corrs(adt, 'target', 'target 2', 15, thresh= 0.7)","e1d41e2f":"#Correlation between drugs\ncorre= adt.corr()\n#Unstack the dataframe\ns = corre.unstack()\nso = s.sort_values(kind=\"quicksort\", ascending=False)\n#Create new dataframe\nso2= pd.DataFrame(so).reset_index()\nso2= so2.rename(columns={0: 'correlation', 'level_0':'Drug 1', 'level_1': 'Drug2'})\n#Filter out the coef 1 correlation between the same drugs\nso2= so2[so2['correlation'] != 1]\n#Drop pair duplicates\nso2= so2.reset_index()\npos = [1,3,5,7,9, 11,13,15,17,19,21,23, 25, 27, 29, 31,33,35, 37, 39, 41, 43, 45]\nso2= so2.drop(so2.index[pos])\n#so2= so2.round(decimals=4)\nso3=so2.head()\n#Show the first 10 high correlations\ncm = sns.light_palette(\"Red\", as_cmap=True)\ns = so2.head(16).style.background_gradient(cmap=cm)\ns\n#High correlation adt 22 pairs\nadt15= so2.head(22)\n#Filter the drug names\nadt_1=adt15['Drug 1'].values.tolist()\nadt_2=adt15['Drug2'].values.tolist()\n#Join the 2 lists\nadt3= adt_1 + adt_2\n#Keep unique elements and drop duplicates\nadt4= list(dict.fromkeys(adt3))\n#Filter out the selected drugs from the \"all drugs treated\" adt dataset\nadt5= adt[adt4]","067e715f":"ploth(adt5)","abebf3d0":"plotc(f, 'drug_id')","0d94628f":"print('First observation:')\nprint(f\"Number of rows of the Control vehicle is {len(a[a['cp_type']=='ctl_vehicle'])}\")\nprint(f\"Number of rows of the Drug cacb2b860 is {f.drug_id.value_counts()[0]}\")","56354622":"plot_drugid('87d714366')","adad1649":"plot_drugid('d50f18348')","4144f739":"plt.figure(figsize=(7,7))\naverage_filtered.sort_values('percentage', inplace=True) \nplt.scatter(average_filtered['percentage'], average_filtered['drug'], color=sns.color_palette('Reds',len(average_filtered)))\nplt.title('Targets with higher presence in train samples', weight='bold', fontsize=15)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.xlabel('Percentage', fontsize=13)\n\nplt.axhline(y=21.5, color='deepskyblue', linestyle='-.')\nplt.axhline(y=23.5, color='deepskyblue', linestyle='-.')\nplt.text(1.7,23, 'Drug: 87d714366 ', fontsize=12, color='black', ha='left' ,va='top')\nplt.text(1.7,15.7, 'Drug: 8b87a7a83 ', fontsize=12, color='black', ha='left' ,va='top')\nplt.text(1.7,14.7, 'Drug: 5628cb3ee ', fontsize=12, color='black', ha='left' ,va='top')\nplt.text(1.7,13.7, 'Drug: d08af5d4b ', fontsize=12, color='black', ha='left' ,va='top')\nplt.show()","1b315470":"drug_count=f[['drug_id']].value_counts().to_frame()\ndrug_count=drug_count.rename(columns={0:'drug_count'})\ndrug_count2=drug_count['drug_count'].value_counts().to_frame().reset_index()\ndrug_count2=drug_count2.rename(columns={'index': 'Samples per drug', 'drug_count':'Number of Drugs'})\ndrug_count2[:12]","74fd1d77":"plt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.countplot(x='cp_type', data=b, palette='rainbow', alpha=0.75)\nplt.title('Test: Control and treated samples', fontsize=15, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.countplot(x='cp_dose', data=b, palette='rainbow', alpha=0.75)\nplt.title('Test: Treatment Doses: Low and High',weight='bold', fontsize=18)\nplt.show()","b7fefb1f":"plt.figure(figsize=(13,3))\nsns.distplot( b['cp_time'], color='gold', bins=5)\nplt.title(\"Test: Treatment duration \", fontsize=15, weight='bold')\nplt.show()","ff2b4a3b":"#Filter out just the treated samples\ntreated2= b[b['cp_type']=='trt_cp']\ntreated_list2 = treated2['sig_id'].to_list()\nfull_tr= b[b['sig_id'].isin(treated_list2)]\n\n#Select the columns c-\nc_cols2 = [col for col in full_tr.columns if 'g-' in col]\n#Filter the columns c-\ncells2=treated2[c_cols2]\n\nplt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.heatmap(cells2.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Test: Gene expression correlation', fontsize=15, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.heatmap(genes.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Train: Gene expression: Correlation', fontsize=15, weight='bold')\nplt.show()","cc82328b":"#Correlation between drugs\ncorre= cells2.corr()\n#Unstack the dataframe\ns = corre.unstack()\nso = s.sort_values(kind=\"quicksort\", ascending=False)\n#Create new dataframe\nso2= pd.DataFrame(so).reset_index()\nso2= so2.rename(columns={0: 'correlation', 'level_0':'Gene 1', 'level_1': 'Gene 2'})\n#Filter out the coef 1 correlation between the same drugs\nso2= so2[so2['correlation'] != 1]\n#Drop pair duplicates\nso2= so2.reset_index()\n#so2= so2.sort_values(by=['correlation'])\npos = [1,3,5,7,9,11,13,15,17,19,21]\nso2= so2.drop(so2.index[pos])\nso2= so2.round(decimals=4)\nso2=so2.drop('index', axis=1)\nso4=so2.head(10)\ncm = sns.light_palette(\"Red\", as_cmap=True)\ns = so2.head(10).style.background_gradient(cmap=cm)\ns","5d61391b":"#Select the columns c-\nc_cols3 = [col for col in b.columns if 'c-' in col]\n#Filter the columns c-\ncells3=treated_t[c_cols3]\n\nplt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.heatmap(cells3.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Test: CVB correlation', fontsize=15, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.heatmap(cells.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Train: CVB correlation', fontsize=15, weight='bold')\nplt.show()","c3d18148":"corrs(cells3, 'Cell', 'Cell 2', rows=10)","ec7ad971":"Now, we check the high correlation cells and comapre them to the train test.","dd883a6f":"* **Inhibitor targets** are dominating with 121 targets (out of 206).\n* Agonists, receptors and antagonists come at the second plan.\n***\n> ### 4-1-3 Correlation between targets:","3d53e853":"* **Many high correlations between c- features. This is something to be taken into consideration in feature engineering.**\n***\n\n# 3- `g-` Features are related to gene expression. What is gene expression?\n\nGene expression is the process by which information from a gene is used in the synthesis of a functional gene product. These products are often proteins. You can refer to my notebook [COVID_19: Viral proteins identification](https:\/\/www.kaggle.com\/amiiiney\/covid-19-proteins-identification-with-biopython) to understand more how gene expression works.\n\nIn short, the mechanism of action of the 207 targets in this study will activate some genes, gene expression will take place and byproducts (proteins) will be synthesized.\n> ### 3.1 g-xxx features","c17d55db":"Most of the targets have 0 correlation. It is worth recalling that the presence of active targets in the samples in very low (mainly 1 or 2 targets per sample).\n\nHowever, we notice some yellow dots *(high correlation)* between some targets. Let's have a closer look over these targets.\n\n> ### 4-1-4 Targets with the highest MoA correlation","2d57cd94":"* We have seen in the previous section that the scored targets had [0,1] in all the samples, in other words, **ALL THE TARGETS HAD A MoA IN AT LEAST ONE SAMPLE.**\n\n* Here, we see that the extra nonscored dataset contains **71 targets without ANY mechanism or action MoA.**\n\nNow that we know that 71 targets don't have any mechanism of action, let's compare the targets with MoA in the nonscore dataset with the score one.\n> ### 4-2-1 Percentage of non-scored MoA in the samples:","d79ebce3":"\n***First observation in this EDA:***\n\nAs mentioned in the definition, cell viability should range between the integers 0 and 1. Here, we have values in the range -10 and 6 because the data were z-scored and then normalized using a procedure called [quantile normalization](https:\/\/clue.io\/connectopedia\/glossary#Q).\n\n*A high negative cell viability measure reflects a high fraction of killing [@by the host](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/191487).* In other words:\n* High negative values = High number of dead cells\n* High positive values = High number of living cells.\n\n> ### 2.2 Cell viability:\n\nLet's see the difference between the cell viability in a control and treated sample.","3d188806":"* **We have both negative and positive correlations here between genes. Interesting!** *(The control samples were not included, so the negative correlation between some genes is not related to the control\/treated samples).*\n\nLet's have a closer look at the high correlation genes.","e4fb53b3":"***\n# References:\n\n[1] Viability assay https:\/\/en.wikipedia.org\/wiki\/Viability_assay\n\n[2] COVID-19 viral proteins identification https:\/\/www.kaggle.com\/amiiiney\/covid-19-proteins-identification-with-biopython\n\n[3] Gene expression level https:\/\/www.sciencedirect.com\/topics\/biochemistry-genetics-and-molecular-biology\/gene-expression-level\n\n[4] Image credit: https:\/\/www.labiotech.eu\/cancer\/forx-therapeutics-cancer-treatment\/","bdf69368":"> ### 3.4 Genes correlation:\n\n**let's see the correlation between gene expression features. (in the treated samples, no control)**","af2321ef":"In section 4.1, figure 2, we have seen that we had 2 outliers: **proteasome_inhibitor and nfkb_inhibitor**, I first thought that that there were many drugs with those MoAs in the train set, but apparently most of them belong to one single drug: **87d714366** that was profiled 718 times.\n\nAnother drug: **d50f18348** was profiled 178 times and has 3 MoAs:","9acd0de3":"# 1-Overview: Features\n> ### 1.1 Categorical features:\n***\n**First glimpse: 876 features with:**\n* Features **g-** signify gene expression data.\n* Features **c-** signify cell viability data.\n* **cp_type** indicates samples treated with a compound, **trt_cp** samples treated with the compounds. \n* **cp_vehicle** or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs.\n* **cp_time** and **cp_dose** indicate treatment duration (24, 48, 72 hours) and dose (high or low).","42f57ed6":"So, Drug cacb2b860 is the control vehicle, this explains it's high presence in the train set. The second most frequent drugs is 87d714366 with 718 rows!\n> ### 4-3-2 Examples:","012cf481":"This is just a first impression after checking multiple cell lines *(We need to check all the cell lines to draw conclusions).*\n\n> ### 2.3 Treatment time:\n\n**Next, let's see the impact of the treatment time on the cell viability.**","05caf59a":"> ### Top 10 gene pairs in the test set:","ec252fd3":"We can see several high positive and negative correlations between some genes, same as in the train set. However more investigation is needed to find some patterns and differences in gene expression between the train and test sets.","69d73e70":"> ### 2.4 Cells correlation\n\n**Let's see the correlation between cell viability features (in the treated samples, no control).**","3a0f138d":"> ### 3.3 Treatment time:\n\n**let's check the impact of the treatment time on the gene expression.**","dce84504":"Findings based on the top 10 cell pairs:\n* 4377 cell pairs have +0.8 correlation in comparison with the 4187 in the train set.\n* 3\/10 cell pairs in the test set are not present in the train set.\n* The order of the cells correlation is different in the test set!","f87c472a":"# Mechanisms of Action (MoA) Prediction: EDA\n***\n\n\n### BLOG POST: [DRUG DISCOVERY WITH NEURAL NETWORKS](https:\/\/medium.com\/swlh\/drug-discovery-with-neural-networks-a6a68c76bb53?sk=dc332f724905461ac5a9b5060c62141d)\n\n\n\n![image1](https:\/\/miro.medium.com\/max\/700\/1*AYJLRDxyO6MWGVSaP6Fm2w.png)<div align=\"center\">Image source: Blog Post<\/div>\n\nIn this competition, we are suposed to develop algorithms and train models **to determine the mechanism of action of a new drug based on the gene expression and cell viability information.** In this EDA, we will try to find patterns in the data, interactions between the targets in both scored and nonscored datasets and the relationship between targets and their target genes.\n\n\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">PROJECT CONTENT<\/h3>\n    \n> ####  1- FEATURES OVERVIEW\n> ####  2- CELL VIABILITY FEATURES\n> ####  3. GENE EXPRESSION FEATURES\n> ####  4. TARGETS *(MoA)*\n    >> ##### 4.1 Scored targets\n    >> ##### 4.2 Non-Scored targets\n    >> ##### 4.3 Drug_ID\n\n> ####  5. TEST FEATURES","06fb63a0":"**Strong negative correlation genes**","b5378094":"* **Observations:**\n\n>1. **nfkb_inhibitor and proteasome_inhibitor** have +0.9 correlation and are highly presented in the samples.\n2.  **Kit_inhibtor** is highly correlated with 2 targets: **pdgfr_inhibitor and flt3_inhibitor**.\n\nThe samples having +2 active targets most probably include those 4 target pairs.\n***\n\n> ## 4-2 Nonscored targets:\n\nIn this section, we will have a look over the dataset provided that will not be used in the score. This dataset has 402 MoAs *(more than the 206 MoAs in the targets_scored dataset that will be used in the score).* \n\nThis dataset can be used for transfer learning!","ba24afd9":"**Interesting!** Even though this is just a visual representation of the table above, here we can clearly see that many targets from the `scored_target` dataset have high correlation with several targets from the `nonscored_targets`.\n\n> ### 4.3 Drug IDs: *(UPDATE)*\n\nWe are now provided the drug_id just for the train set, it will be valuable for a more stable CV\/LB, however, I don't think it will be valuable for feature engineering since we don't have the drug_id for the test set, let's dig into this new feature:\n> ### 4-3-1 Most frequent drugs in the train set:","8c5b0858":"* All the targets are present in at least one sample.\n* The presence of the targets is very low in the samples (Mostly less than 0.75%).\n* Some targets *(outliers)* have a higher presence in comparison with the rest of targets with a percentage in the range (3%, 4%).\n\n> ### 4-1-1 **Most frequent targets:**","31df7876":"* The presence of the nonscored targets in the samples is 10 times lower than the scored ones, which will be translated basically to 1 MoA per target in the samples.\n\nWe can deduct from the latest findings that the nonscored targets have less MoA in comparison to the scored ones. However, this doesn't mean that the information in the nonscored dataset can't be useful because if the nonscored targets have just 1 MoA and it happens that this 1 single MoA coincides with the scored targets in the same samples, then we might have interesting correlation between both targets.\n\nTo understand this better, let's first merge both scored and nonscored targets datasets and try to find patterns and relationships between the targets in both datasets. \n> ### 4-2-2 Non-scored targets correlation:","465e9e90":"> The other most frequent drugs have cdk_inhibitor, egfr_inhibitor and tubulin_inhibitor as MoAs.","a5489ebc":"Those are the outlier drugs, the drugs that were profiled more than 18 times! Next, let's check the other drugs, normally 1 drug was profiled 6 times *(2 doses x 3 treatment times)*, if a drug was profiled twice it will have 12 samples per drug_id.","bebdc257":"**Observations:**\n* **5\/10** high correlated genes are the same as in the train set *(see section 3.2).*\n* **5** new gene pairs seem to be highly correlated in the test set then in the train set.\n* This is just a quick look over the TOP10 genes. I will update this section in the future with deeper analysis.\n\nUnderstanding the difference between the genes correlation in the train and test sets will be crucial to determine and prevent the shake-up.\n\n> ## 5-3 Cell viability:","fee4a56b":"Everything seems similar to the train set:\n* The doses are equally applied.\n* Very few control samples.\n* Same treatment duration 24h, 48h and 72h.\n\n**Good news!** It seems that both train and test datasets are similar in terms of *experimental conditions.* The variation would be in the gene expression and cell viability since the samples used in the test set are different than the train set.\n\nLet's see how different are those samples!\n\n> ## 5-2 Gene expression:","49e559a6":"* **2 Target-pairs have +0.9 correlation:** \n\nThose target pairs must be in the few samples that have more than two active targets. The functionality of these targets and their distribution is something to be taken into consideration because in this case, we have **a multi-label classification problem**, where the correlation between the labels is also important and the model selection should be based on the labels correlation. Select a model that finds patterns not just in the train data but also in the **multi-label target data.**\n\nBelow, we will try to connect the dots and try to match the high correlated targets with the targets with the most presence in the samples.","1f7b29c1":"# 2- `c-` Features are related to cell viability. What is cell viability? \n\nA viability assay is an assay that is created to determine the ability of organs, cells or tissues to maintain or recover a state of survival. Viability can be distinguished from the all-or-nothing states of life and death by the use of a quantifiable index that ranges between the integers of 0 and 1 or, if more easily understood, the range of 0% and 100%. Viability can be observed through the physical properties of cells, tissues, and organs. Some of these include mechanical activity, motility, such as with spermatozoa and granulocytes, the contraction of muscle tissue or cells, mitotic activity in cellular functions, and more. Viability assays provide a more precise basis for measurement of an organism's level of vitality.[1]\n\n> ### 2.1 c-xxx features","0debf677":"We have 34 gene pairs with **+0.8** correlation. This information will be useful, we will come back to it in the following sections.\n> ### 3.5 Mean gene expression of g-xxx features","73ede89a":"The mean gene expression of the 772 genes show some strong negative and positive gene expression values. This can be due to many factors:\n* Some drugs **upregulate** and others **downregulate** some genes: For example, drug-A could reduce gene-X expression level while drug-B could elevate gene-Y expression level.\n\n* Some genes have high **negative correlation**, so gene-X has a high positive gene expression value which means gene-Y will have a high negative gene expression value.\n\n* Other factors are related to the drug types and the genes, the information about drugs, genes and cells is not provided!\n\n\n\n# 4-Targets *(MoA)*:\n***\n> ## 4-1 Scored targets:\n\nThis is a multi-label classification, we have 207 MoA and we have to find out the mechanism of action of the 5000 drugs that were treated in the `sig_id` samples. A single sample treated with a drug can have many active targets, in other words, one drug can have more than 1 mechanism of action, so we have to predict the mechanisms of action of each drug.\n\n*We will filter the **train_targets_scored** dataset and keep just the treated rows (we discard the control rows because they are not treated with the drugs).*\n","399dbbe4":"* It seems we have 2 outliers here: **nfkb_inhibitor** and **proteasome_inhibitor.** *(We will come back to this later)*\n\n* We can see many target labels in the plot: inhibitor, agonist, antagonist.\n> ### 4-1-2 Targets: Drug types:","583a492f":"**Observations:**\n* As expected, 2774 drugs out of 3700 drugs have 6 rows that correspond to 2 doses and 3 treatment times. \n* Only 64 drugs have 12 samples, I was expecting more drugs to be profiled twice.\n* Only 3 drugs have 18 sample, the drugs were profiled 3 times.\n* 196 drugs were profiled 7 times, so 1 additional sample with respect to most of the drugs, perhaps a dosage or treatment time experiment was repeated for those drugs!\n\n**My Drug_id conclusion:**\n\nI am not sure why the competition host chose some drugs to be profiled hundreds of times but the data shows that most of the drugs,exactly 2774 drug, were profiled just once (6 samples), my intuition is that those samples will not be present in the test, however, the drugs with + 18 samples were intentionally profiled 100s of times because they have some mechanism of action targets that the test set drugs have.\n\nFor more info, you can check this discussion topic: [Extracting insights from Drug_ID](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/195217).\n\n***\n# 5- Test features:\nAfter understanding the relationship between the features and the labels, we move on to the test set to understand the features and their relationship with the train features.\n> ## 5-1 Features:","08ec11a6":"> ### 3.2 Gene expression:\n\n***How to interpret those values?***\n\nGene expression levels are calculated by the ratio between the expression of the target gene (i.e., the gene of interest) and the expression of one or more reference genes (often household genes). [3]\n\n> To understand this better, let's compare the samples treated with the drugs and the control samples.","ba13db72":"**Great!** This nonscored dataset seems promising. \n\nIf in the `scored_target` dataset we had just 4 target pairs with +0.7 correlation, by merging both datasets we have more than 15 target pairs highly correlated.\n\n> ### 4-2-3 Heatmap of the 31 target with high correlation:","c90586b3":"* **Few control samples.**\n* **The low and high doses were applied equally.**\n* **3 treatment durations: 24h, 48h and 72h.**"}}