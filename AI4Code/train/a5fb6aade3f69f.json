{"cell_type":{"479753af":"code","68e1ecfc":"code","b58ec434":"code","76e07f5c":"code","89d09c8d":"code","f48fff99":"code","f336c2b2":"code","ccdc2e89":"code","37325718":"code","fdf176f6":"code","4a3795c0":"code","c8676c5a":"code","95aee278":"code","8655ec24":"code","5bffe69e":"code","80a3fa03":"code","9a47cea6":"code","f11e8f58":"code","2466fae0":"code","c02b6b7e":"code","1b5cbd90":"code","2877c48d":"code","6fa5201b":"code","f98df5c4":"code","b4c2b84d":"code","3e64fe73":"code","bf392d41":"code","0e87bbd8":"code","ddab0b4f":"code","ce5ec4d2":"code","773b70b3":"code","efc337d0":"code","2af62101":"code","fc9711e3":"code","0879eb3e":"code","11a4ee45":"code","8181befd":"code","822a6822":"code","22eb1932":"code","917c505a":"code","cffc0f6f":"code","72415535":"code","e0c64799":"code","f82663b4":"code","63e9202d":"code","4f1cd0d2":"markdown","e735160b":"markdown","46336f58":"markdown","8f70af9e":"markdown","bcd36300":"markdown","9c3f1bb6":"markdown"},"source":{"479753af":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","68e1ecfc":"# data analysis and wrangling\nimport random as rnd\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#\nfrom sklearn.metrics import mean_squared_log_error","b58ec434":"train_df = pd.read_csv('..\/input\/traintsv\/train.tsv',sep='\\t')\ntest_df = pd.read_csv('..\/input\/testtsv\/test.tsv',sep='\\t')\ncombine = [train_df, test_df]","76e07f5c":"train_df.head()","89d09c8d":"test_df.head()","f48fff99":"train_df.shape","f336c2b2":"test_df.shape","ccdc2e89":"train_df.describe()","37325718":"train_df.info()","fdf176f6":"test_df.info()","4a3795c0":"#\u6b20\u640d\u5024\u306e\u78ba\u8a8d\ntrain_df.isna().sum()","c8676c5a":"#\u6b20\u640d\u5024\u306e\u78ba\u8a8d\ntest_df.isna().sum()","95aee278":"#\u72b6\u614b\u3068\u4fa1\u683c\u306e\u6563\u5e03\u56f3\ntrain_df.plot.scatter(x = 'price',y = 'item_condition_id')\n\n#\u30b3\u30f3\u30c7\u30a3\u30b7\u30e7\u30f35\u3060\u3068\u5024\u6bb5\u4f4e\u3081\u306a\u50be\u5411\u304c\n#\u591a\u5206 1\u304c\u30b3\u30f3\u30c7\u30a3\u30b7\u30e7\u30f3\u826f\u304f\u3066\u30015\u304c\u60aa\u3044","8655ec24":"train_df.plot.scatter(x = 'price',y = 'item_condition_id')","5bffe69e":"#name\u306e\u7a2e\u985e\u3054\u3068\u306e\u8981\u7d20\u6570\n#import collections\n#c = collections.Counter(train_df['name'])\n#print(c)\n\n#bundle\u304c\uff12\uff10\uff10\uff10\u3061\u3087\u3044\n#\u307e\u3068\u3081\u58f2\u308a\u8aac\n\n#reserve\u304c\uff14\uff15\uff10\u3050\u3089\u3044\n#\u3007\u3007\u69d8\u5c02\u7528\u7684\u306a","80a3fa03":"#\u30b3\u30f3\u30c7\u30a3\u30b7\u30e7\u30f3\u3054\u3068\u306e\u4fa1\u683c\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nnew_train=train_df.query('price<200')#query\ng = sns.FacetGrid(train_df, col = 'item_condition_id')\ng.map(plt.hist,'price',bins = 100)\n#\u30b3\u30f3\u30c7\u30a3\u30b7\u30e7\u30f3\u304c\u60aa\u3044\u3068\u51fa\u54c1\u6570\u304c\u5c11\u306a\u3044?\n#\u30b3\u30f3\u30c7\u30a3\u30b7\u30e7\u30f3\u304c\u3044\u3044\u3068\u51fa\u54c1\u6570\u304c\u591a\u3044\uff1f\u304c\u4fa1\u683c\u4f4e\u3044...","9a47cea6":"g=sns.FacetGrid(new_train,col='shipping')\ng.map(plt.hist, 'price',bins=30)\n","f11e8f58":"train_df.head()","2466fae0":"#\u3053\u308c\u3060\u3068\u540c\u3058\u30e1\u30e2\u30ea\u306b\u5225\u306e\u5909\u6570\u540d\u3067\u30a2\u30af\u30bb\u30b9\u3057\u3066\u308b\u3060\u3051\n#train_copy=train_df","c02b6b7e":"#python\u306f\u3061\u3083\u3093\u3068.copy()\u4f7f\u3063\u3066\u30b3\u30d4\u30fc\u3057\u306a\u3044\u3068\u3060\u3081\ntrain_copy = train_df.copy()","1b5cbd90":"#Checking for NULL values in the columns\ntrain_copy.isnull().any()","2877c48d":"brands = train_copy[\"brand_name\"].value_counts()\nprint(\"No. of Unique Brand Names :\", brands.size)\nfig, ax = plt.subplots(1, 2, figsize = (13, 6))\n# we skipped '0' index and started from 1st because 0th index has \"unknown brands\"\nsns.barplot(brands[1:11].values, brands[1:11].index,ax = ax[0], edgecolor='k', linewidth=0.5, palette='rocket') \nax[0].set_title(\"Top 10 Most Frequently Used Brand Names\", fontsize = 13)\nax[0].set_xlabel(\"Counts\", fontsize = 10)\nax[0].set_ylabel(\"Brand Name\", fontsize = 10)\n\nimport pandas as pd\ntop10_brands = train_copy.groupby('brand_name', axis=0).mean()\ndf_expPrice = pd.DataFrame(top10_brands.sort_values('price', ascending = False)['price'][0:10].reset_index())\nax[1].set_title(\"Top 10 Most Costly Brands\", fontsize = 13)\nax[1] = sns.barplot(x=\"brand_name\", y=\"price\", data=df_expPrice, edgecolor='k', linewidth=0.5, palette='PuRd')\nax[1].set_xlabel(\"Brand Name\", fontsize = 10)\nax[1].set_ylabel(\"Sale Price\", fontsize = 10)\nax[1].set_xticklabels(ax[1].get_xticklabels(),rotation=35)\nplt.show()","6fa5201b":"train_copy.query('price > 500 & brand_name == \"Unknown brand\" & category_name == \"Other\/Other\/Other\"')","f98df5c4":"#brand_name\u5217\u306b\u30d6\u30e9\u30f3\u30c9\u540d\u3054\u3068\u306e\u5e73\u5747\u5024\u6bb5\u3092\u304f\u3063\u3064\u3051\u3066\u65b0\u3057\u3044\u30ab\u30e9\u30e0\u3092\u4f5c\u308b\ntrain_copy = train_copy.join(train_copy.groupby('brand_name')['price'].mean().astype(int), on = 'brand_name', rsuffix='_r')\n","b4c2b84d":"# Splitting category name\ndef split_cat(text):\n    try: return text.split(\"\/\")\n    except: return (\"No Label\", \"No Label\", \"No Label\") \n    \n# Splitting category name into: Main Category, SubCategory_1, SubCategory_2\ntrain_copy['main_category'], train_copy['subcat_1'], train_copy['subcat_2'] = zip(*train_copy['category_name'].apply(lambda x: split_cat(x)))","3e64fe73":"# Label Encoding\n# \u6587\u5b57\u30c7\u30fc\u30bf\u3092\u6570\u5024\u30c7\u30fc\u30bf\u306b\u5909\u63db\n# toNumeric\nfrom sklearn import preprocessing\ndef toNumeric(data,to):\n    if train_copy[data].dtype == type(object):\n        le = preprocessing.LabelEncoder()\n        train_copy[to] = le.fit_transform(train_copy[data].astype(str))\ntoNumeric('name','n_name')\ntoNumeric('category_name','n_category_name')\ntoNumeric('brand_name','n_brand_name')\ntoNumeric('main_category','n_main_category')\ntoNumeric('subcat_1','n_subcat_1')\ntoNumeric('subcat_2','n_subcat_2')\ntrain_copy.head()","bf392d41":"train_copy.isnull().any()","0e87bbd8":"#\u6b20\u640d\u5024\u3092\u57cb\u3081\u308b\ndef fill_missing_data(data):\n    data.category_name.fillna(value = \"Other\/Other\/Other\", inplace = True)\n    data.brand_name.fillna(value = \"Unknown brand\", inplace = True)\n    data.item_description.fillna(value = \"No description\", inplace = True)\n    return data\n\ntrain_copy = fill_missing_data(train_copy)\ntrain_copy = train_copy.dropna()\nprint(np.shape(train_copy))\ntrain_copy.head()","ddab0b4f":"train_df = train_copy.drop(['name','category_name','brand_name','item_description','main_category','subcat_1','subcat_2'],axis=1)\ntest_df = test_df.drop(['name','category_name','brand_name','item_description'],axis=1)","ce5ec4d2":"train_df","773b70b3":"train_df['price_r'].astype(int)","efc337d0":"train_data = train_df.sample(frac=0.7)\ntest_data = train_df.drop(train_data.index)","2af62101":"train_data.shape,test_data.shape","fc9711e3":"train_df","0879eb3e":"X_train = train_data.drop('price',axis=1)\nY_train = train_data['price'].astype(int)\nX_train.shape, Y_train.shape ","11a4ee45":"X_train.head()","8181befd":"Y_train.head()","822a6822":"X_test.head()","22eb1932":"#\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\nfrom sklearn.ensemble import RandomForestRegressor\nrandom_forest = RandomForestRegressor(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(test_data.drop('price',axis=1))","917c505a":"print(Y_pred[140:200])","cffc0f6f":"len(Y_pred)","72415535":"Y_pred.shape,Y_train.shape","e0c64799":"print(X_test)","f82663b4":"rmsle = np.sqrt(mean_squared_log_error(test_data['price'],Y_pred))\n\nprint(rmsle)","63e9202d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f1cd0d2":"\u30d6\u30e9\u30f3\u30c9\u540d","e735160b":"\u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316","46336f58":"#\u5909\u6570\u30c9\u30ed\u30c3\u30d7","8f70af9e":"#\u5b66\u7fd2\u3055\u305b\u3066\u307f\u308b","bcd36300":"$500 \u4ee5\u4e0a\u3067\u30d6\u30e9\u30f3\u30c9\u540d","9c3f1bb6":"EDA"}}