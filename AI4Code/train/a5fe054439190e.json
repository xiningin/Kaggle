{"cell_type":{"4b35ea8b":"code","1fe4121a":"code","51e2940f":"code","9c4369c3":"code","eacfd4cd":"code","80582b6b":"code","e62b9f6a":"code","9006adb8":"code","59f1fcf8":"code","8755b2c4":"code","c1de4a37":"code","5d676b9a":"code","536e2da0":"code","21916d9f":"code","34cb7f02":"code","a4854a3a":"code","d40e9f88":"code","a632e53c":"code","582ec1db":"code","ba3ad232":"code","eb0c8ae7":"code","01167fb8":"code","6dd5ae3f":"code","8ab7b66a":"code","a59fc62a":"code","b0830518":"code","13503a40":"code","24667f97":"code","3858d7af":"code","672a1201":"code","4498f610":"code","c6dad636":"code","a2a8b7b9":"code","7ea57f1e":"code","f8b26202":"code","464c43e9":"code","f66e4664":"code","063e66b6":"code","c353f340":"code","400e7eba":"code","220974f7":"code","850c4e62":"code","78d31db3":"code","b115620b":"code","1b9a2109":"code","09619e98":"code","a454c53e":"code","fcd6013d":"markdown","11061a5b":"markdown","3947ea1b":"markdown","7bf465f0":"markdown","776d0dce":"markdown","b1407ae2":"markdown","77ea9ad4":"markdown","a5f4d5d3":"markdown","9c14e2d7":"markdown","d027ef4b":"markdown","1caf197d":"markdown"},"source":{"4b35ea8b":"import subprocess\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nimport cv2\nimport numpy as np\nimport os\nimport pandas as pd\nfrom sklearn import model_selection, metrics, utils\nimport shutil\nimport random","1fe4121a":"cd ..","51e2940f":"train_df = pd.read_csv('input\/hackerearth\/data\/train.csv')","9c4369c3":"new_classes = [train_df['breed'].value_counts().index[i] for i in range(0, len(train_df['breed'].value_counts())) \n               if train_df['breed'].value_counts().values[i] < 200]","eacfd4cd":"final_df = pd.DataFrame()\nfor x in new_classes:\n    datap = train_df[train_df['breed'] == x]\n    final_df = final_df.append(datap)\n\nfinal_df.index = list(range(0, len(final_df)))","80582b6b":"train, valid = model_selection.train_test_split(final_df, test_size=.1, stratify=final_df['breed'])","e62b9f6a":"!rm -r data\/train\n!rm -r data\/valid\n!mkdir data\/train\n!mkdir data\/valid","9006adb8":"for x in final_df['breed'].value_counts().index:\n    subprocess.call(['mkdir', 'data\/train\/' + x])\n    subprocess.call(['mkdir', 'data\/valid\/' + x])","59f1fcf8":"for i in range(0, len(train)):\n    name = train['image_id'].iloc[i]\n    label = train['breed'].iloc[i]\n    shutil.copy('dataset\/train\/'+name+'.jpg', 'data\/train\/'+label+'\/'+name+'.jpg')","8755b2c4":"for i in range(0, len(valid)):\n    name = valid['image_id'].iloc[i]\n    label = valid['breed'].iloc[i]\n    shutil.copy('dataset\/train\/'+name+'.jpg', 'data\/valid\/'+label+'\/'+name+'.jpg')","c1de4a37":"callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='working\/model_dir\/modelfinal.h5', save_best_only=True,\n                                      monitor='val_accuracy'),\n    tf.keras.callbacks.TensorBoard(log_dir='working\/model_dir\/logs'),\n]","5d676b9a":"module_selection = (\"mobilenet_v2_035_160\", 160)\nhandle_base, pixels = module_selection\nMODULE_HANDLE =\"https:\/\/tfhub.dev\/google\/imagenet\/{}\/feature_vector\/4\".format(handle_base)\nIMAGE_SIZE = (pixels, pixels)\nprint(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\nBATCH_SIZE = 32 ","536e2da0":"datagen_kwargs = dict(rescale=1.\/255)\ndataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, interpolation=\"bilinear\")\n\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\nvalid_generator = valid_datagen.flow_from_directory('input\/hackerearth\/data\/valid\/', \n                                                    shuffle=True,  \n                                                    **dataflow_kwargs)\n\ndo_data_augmentation = False \nif do_data_augmentation:\n      train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n          rotation_range=40,\n          horizontal_flip=True,\n          width_shift_range=0.2, height_shift_range=0.2,\n          shear_range=0.2, zoom_range=0.2,\n          **datagen_kwargs)\nelse:\n      train_datagen = valid_datagen\n\ntrain_generator = train_datagen.flow_from_directory('input\/hackerearth\/data\/train\/', \n                                                    shuffle=True, \n                                                    **dataflow_kwargs)","21916d9f":"do_fine_tuning = False\n\nprint(\"Building model with\", MODULE_HANDLE)\nmodel = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)), hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n    tf.keras.layers.BatchNormalization(momentum=0.8, epsilon=0.1),\n    tf.keras.layers.Dropout(rate=0.6),\n    tf.keras.layers.Dense(train_generator.num_classes,\n                          kernel_regularizer=tf.keras.regularizers.l2(0.00001))\n])\nmodel.build((None,)+IMAGE_SIZE+(3,))\nmodel.summary()","34cb7f02":"class_weights = utils.class_weight.compute_class_weight(\n           'balanced',\n            np.unique(train_generator.classes), \n            train_generator.classes)\nclass_weights = dict(enumerate(class_weights))","a4854a3a":"model.compile(\n    optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum=0.9),\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.01),\n    metrics=['accuracy'])","d40e9f88":"steps_per_epoch = train_generator.samples \/\/ train_generator.batch_size\nvalidation_steps = valid_generator.samples \/\/ valid_generator.batch_size\nhist = model.fit(\n    train_generator,\n    epochs=100, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n#     class_weight=class_weights,\n    shuffle=True,\n    validation_steps=validation_steps).history","a632e53c":"plt.figure()\nplt.ylabel(\"Loss (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,5])\nplt.plot(hist[\"loss\"])\nplt.plot(hist[\"val_loss\"])\n\nplt.figure()\nplt.ylabel(\"Accuracy (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,1])\nplt.plot(hist[\"accuracy\"])\nplt.plot(hist[\"val_accuracy\"])","582ec1db":"batch_size = 32\n# training for 10 epochs\nepochs = 30\n# size of each image\nIMAGE_SHAPE = (224, 224, 3)\n\n\nvalid_data_gen = ImageDataGenerator(rescale=1\/255)\ntrain_data_gen = ImageDataGenerator(\n                                    rescale=1.\/255,\n                                    rotation_range=30,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.4,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    channel_shift_range=0.4\n                                   )\n# make the training dataset generator\ntrain_image_generator = train_data_gen.flow_from_directory(directory='input\/hackerearth\/data\/train\/', batch_size=batch_size,\n                                                     target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n                                                        shuffle=True)\n# make the validation dataset generator\nvalid_image_generator = valid_data_gen.flow_from_directory(directory='input\/hackerearth\/data\/valid\/', batch_size=batch_size, \n                                                     target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n                                                     shuffle=True)","ba3ad232":"k_class_weights = utils.class_weight.compute_class_weight(\n           'balanced',\n            np.unique(train_image_generator.classes), train_image_generator.classes)\nk_class_weights = dict(enumerate(k_class_weights))","eb0c8ae7":"help(tf.keras.layers.MaxPool2D())","01167fb8":"c_model = tf.keras.models.Sequential()\nc_model.add(tf.keras.layers.Input(shape=(224, 224, 3)))\nc_model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nc_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nc_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nc_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nc_model.add(tf.keras.layers.GlobalAvgPool2D())\nc_model.add(tf.keras.layers.Flatten())\nc_model.add(tf.keras.layers.Dense(1056, activation='relu'))\nc_model.add(tf.keras.layers.Dense(28, activation='softmax'))\n\nc_model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n                metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.TopKCategoricalAccuracy()])","6dd5ae3f":"c_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='kmodel_dir\/modelfinal.h5', save_best_only=True,\n                                      monitor='val_accuracy'),\n    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4),\n    tf.keras.callbacks.TensorBoard(log_dir='kmodel_dir\/logs')\n]","8ab7b66a":"training_steps_per_epoch = np.ceil(train_image_generator.samples \/ batch_size)\nvalidation_steps_per_epoch = np.ceil(valid_image_generator.samples \/ batch_size)\n# train using the generators\nc_hist = c_model.fit(train_image_generator, \n              steps_per_epoch=training_steps_per_epoch,\n              validation_data=valid_image_generator, \n              validation_steps=validation_steps_per_epoch,\n              epochs=epochs,\n              verbose=1, \n              callbacks=c_callbacks)","a59fc62a":"input_shape = (224, 224, 3)\nconv_base = tf.keras.applications.MobileNetV2(input_shape=input_shape, weights='imagenet')\n\nk_model = tf.keras.models.Sequential()\nk_model.add(conv_base)\nk_model.add(tf.keras.layers.BatchNormalization())\nk_model.add(tf.keras.layers.Dropout(0.2))\nk_model.add(tf.keras.layers.Dense(512, activation='relu'))\nk_model.add(tf.keras.layers.Dropout(0.5))\nk_model.add(tf.keras.layers.Dense(train_image_generator.num_classes))\n\nfor layer in k_model.layers[:-4]:\n    layer.trainable = False\n    \n# print the summary of the model architecture\n# k_model.summary()\nk_model.compile(\n                optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n                metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.TopKCategoricalAccuracy()])","b0830518":"k_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='kmodel_dir\/modelfinal.h5', save_best_only=True,\n                                      monitor='val_accuracy'),\n    tf.keras.callbacks.TensorBoard(log_dir='kmodel_dir\/logs'),\n]","13503a40":"training_steps_per_epoch = np.ceil(train_image_generator.samples \/ batch_size)\nvalidation_steps_per_epoch = np.ceil(valid_image_generator.samples \/ batch_size)\n# train using the generators\nk_hist = k_model.fit(train_image_generator, \n              steps_per_epoch=training_steps_per_epoch,\n              validation_data=valid_image_generator, \n              validation_steps=validation_steps_per_epoch,\n              epochs=epochs,\n              class_weight=k_class_weights,\n              verbose=1, \n              callbacks=k_callbacks)","24667f97":"class Predictions:\n    \n    def __init__(self, image_dir, model, test_df, x, y):\n        self.image_dir = image_dir\n        self.model = model\n        self.test_df = test_df\n        self.x = x\n        self.y = y\n    \n    def predict(self, image_name):\n        self.image_name = image_name\n        test_img = cv2.imread(os.path.join(self.image_dir, self.image_name))\n        test_img = np.resize(test_img, (1, self.x, self.y, 3))\n        tf_model_predictions = self.model.predict(test_img)\n        id_ = np.argmax(tf_model_predictions[0])\n        \n        return tf_model_predictions","3858d7af":"#train_generator.class_indices\ntest_df = pd.read_csv('dataset\/test.csv')\nimage_ids = list(test_df['image_id'])\n\ntest_results = []\nfor x in image_ids:\n    set_f = {}\n    x_name = x + '.jpg'\n    prediction_module = Predictions('dataset\/test\/', model, 'test', 160, 160)\n    predits = Predictions.predict(prediction_module, x_name)\n    pred_label = np.argmax(predits[0])\n    set_f['image_id'] = x\n    set_f['breed'] = pred_label\n    test_results.append(set_f)","672a1201":"test_results_df = pd.DataFrame(test_results)\ntest_results_df['breed'].value_counts()","4498f610":"new_id = {}\nfor id,val in enumerate(train_generator.class_indices): \n    new_id[id] = val \n    \ntest_results_df['breed'] = [new_id[x] for x in test_results_df['breed']]","c6dad636":"# test_results_df.drop(['id-preds'], axis=1, inplace=True)\ntest_results_df.to_csv('results\/vishnu_submit.csv', index=None)","a2a8b7b9":"class Preprocessing:\n    def __init__(self, x, y, batch_size, train_path, valid_path):\n        self.x = x\n        self.y = y\n        self.batch_size = batch_size\n        self.train_path = train_path\n        self.valid_path = valid_path\n    \n    def generator(self):\n        train_datagen = ImageDataGenerator(\n                                            rescale=1.\/255,\n                                            rotation_range=30,\n                                            width_shift_range=0.2,\n                                            height_shift_range=0.4,\n                                            shear_range=0.2,\n                                            zoom_range=0.2,\n                                            channel_shift_range=0.4,\n                                            fill_mode=\"nearest\",\n                                            cval=0.4,\n                                            horizontal_flip=True,\n                                            vertical_flip=True\n                                           )\n        test_datagen = ImageDataGenerator(rescale=1.\/255)\n        \n        train_generator = train_datagen.flow_from_directory(\n                                                            self.train_path,  # this is the target directory\n                                                            target_size=(self.x, self.y),  # all images will be resized to 150x150\n                                                            batch_size=self.batch_size,\n                                                            class_mode='categorical')\n\n        valid_generator = test_datagen.flow_from_directory(\n                                                            self.valid_path,\n                                                            target_size=(self.x, self.y),\n                                                            batch_size=self.batch_size,\n                                                            class_mode='categorical')\n        \n        return train_generator, valid_generator\n    \nclass Model:\n    def __init__(self, train_generator, valid_generator, met, los, model_link, x, y, class_weight, callbacks):\n        self.train_generator = train_generator\n        self.valid_generator = valid_generator\n        self.met = met\n        self.los = los\n        self.model_link = model_link\n        self.x = x\n        self.y = y\n        self.class_weight = class_weight\n        self.callbacks = callbacks\n    \n    def compiler(self, dropout):\n        self.dropout = dropout\n        tl_model = tf.keras.Sequential([\n                    hub.KerasLayer(self.model_link, trainable=True),\n                    tf.keras.layers.Dropout(self.dropout),\n                    tf.keras.layers.Dense(self.train_generator.num_classes,\n                                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n        ])\n        tl_model.build([None, self.x, self.y, 3])\n        optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n        tl_model.compile(optimizer=optimizer, loss=self.los, metrics=self.met)\n        \n        return tl_model\n    \n    def train(self, epochs, model):\n        self.epochs = epochs\n        self.model = model\n        steps_per_epoch = np.ceil(self.train_generator.samples\/self.train_generator.batch_size)\n        val_steps_per_epoch = np.ceil(self.valid_generator.samples\/self.valid_generator.batch_size)\n        hist = self.model.fit(\n                            self.train_generator, \n                            epochs=self.epochs,\n                            verbose=1,\n                            steps_per_epoch=steps_per_epoch,\n                            class_weight=self.class_weight,\n                            callbacks=self.callbacks,\n                            validation_data=self.valid_generator,\n                            validation_steps=val_steps_per_epoch).history\n\n        return self.model, hist\n    \nmet = tf.keras.metrics.Accuracy()\nlos = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\nmodel_weights = 'https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_035_224\/classification\/4'","7ea57f1e":"preprocess = Preprocessing(224, 224, 8, 'data\/train', 'data\/valid')\ntrain_generator, valid_generator = Preprocessing.generator(preprocess)","f8b26202":"image_class_model = Model(train_generator, \n                          valid_generator, \n                          met, los, \n                          model_weights, \n                          224, 224, \n                          class_weights,\n                          callbacks)\ntl_model = Model.compiler(image_class_model, 0.4)\nimg_model, img_hist = Model.train(image_class_model, 40, tl_model)","464c43e9":"class Predictions:\n    \n    def __init__(self, image_dir, model, test_df, x, y):\n        self.image_dir = image_dir\n        self.model = model\n        self.test_df = test_df\n        self.x = x\n        self.y = y\n    \n    def predict(self, image_name):\n        self.image_name = image_name\n        test_img = cv2.imread(os.path.join(self.image_dir, self.image_name))\n        test_img = np.resize(test_img, (1, self.x, self.y, 3))\n        tf_model_predictions = self.model.predict(test_img)\n        id_ = np.argmax(tf_model_predictions[0])\n        \n        return tf_model_predictions","f66e4664":"import matplotlib.pyplot as plt\nimport cv2","063e66b6":"test_img = cv2.imread('dataset\/test\/2006370aad.jpg', cv2.COLOR_BGR2RGB)\nplt.imshow(test_img)","c353f340":"#train_generator.class_indices\ntest_df = pd.read_csv('dataset\/test.csv')\nimage_ids = list(test_df['image_id'])","400e7eba":"test_results = []\nfor x in image_ids:\n    set_f = {}\n    x_name = x + '.jpg'\n    prediction_module = Predictions('dataset\/test\/', img_model, 'test', 224, 224)\n    predits = Predictions.predict(prediction_module, x_name)\n    pred_label = np.argmax(predits[0])\n    set_f['id-preds'] = predits\n    set_f['image_id'] = x\n    set_f['breed'] = pred_label\n    test_results.append(set_f)","220974f7":"test_results_df = pd.DataFrame(test_results)\ntest_results_df['breed'].value_counts()","850c4e62":"test_results_df['id-preds'][6]","78d31db3":"test_results_df['breed'] = [new_id[x] for x in test_results_df['breed']]","b115620b":"test_results_df.to_csv('vishnu_submit.csv', index=None)","1b9a2109":"!zip -r results.zip results","09619e98":"rm -r results\/.ipynb_checkpoints\/","a454c53e":"new_id = {}\nfor id,val in enumerate(train_generator.class_indices): \n    new_id[id] = val ","fcd6013d":"## Modelling","11061a5b":"### Visualizing images","3947ea1b":"## Data preparation","7bf465f0":"### Inferencing","776d0dce":"### Transfer learning","b1407ae2":"The images are retrieved using bing image downloader api and the model is created using tensorflow and tensorflow hub","77ea9ad4":"### Using OOPs","a5f4d5d3":"## Inferencing","9c14e2d7":"from bing_image_downloader import downloader\nquery_string = 'sliding fouls football'\ndownloader.download(query_string, limit=300,  output_dir='dataset', adult_filter_off=True, force_replace=False, timeout=60)","d027ef4b":"# Image classification for classification fouls or not","1caf197d":"### Keras application"}}