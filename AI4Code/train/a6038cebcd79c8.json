{"cell_type":{"dfbedfa9":"code","5cca62d9":"code","59245074":"code","818bdc3e":"code","e2364a36":"code","e0879231":"code","fc95ed91":"code","a71184e0":"code","fc4cc367":"code","581dd411":"code","10ee883b":"code","bc2228f5":"code","4e5b6c24":"code","524e51d9":"code","a68ff02e":"code","5e488030":"code","30d68690":"code","2c4ac8e9":"code","398d0996":"code","b6155bbe":"code","9a63d62f":"code","4632dcac":"code","b7217c52":"code","f6e1988f":"code","08d28c6a":"code","a3d39b06":"code","4c46826c":"code","acc724e6":"code","50a96755":"code","8b065ac4":"code","1d9a0ed9":"code","074e8ab2":"code","e8ffe089":"code","bfd1ceaa":"code","e040633a":"code","a3833a93":"code","ce713377":"code","0df183d4":"code","4ece78db":"code","cf4107cd":"code","3f5aa87e":"code","016e7c39":"code","ec0499e1":"code","f15f7217":"code","e1bd7053":"code","d1715c76":"code","1184a50a":"code","2bde1eaf":"code","ec564c15":"code","60a2da25":"code","b2274efa":"code","26151499":"code","5e516f71":"code","a070710e":"code","f5c00834":"code","f61d00db":"code","44412673":"code","14abd168":"code","4e09102a":"code","a8617f63":"code","02f7c619":"code","f1877d03":"code","31f0d27a":"code","52b4f3fc":"code","bc0fe8f1":"code","2e198e02":"markdown","4a4fa0cb":"markdown","474a62f1":"markdown","2d712bac":"markdown","6da52dbf":"markdown","3c802ff9":"markdown","cdb59b18":"markdown","0afebfc7":"markdown","4613ccd3":"markdown","ae069a88":"markdown","b1bd75b2":"markdown","476508c3":"markdown","e3f6f0f3":"markdown","6b4a676e":"markdown","c715c390":"markdown","86af47eb":"markdown","c303903c":"markdown","85d32301":"markdown","cd738543":"markdown","f63afc4d":"markdown","15a84a1e":"markdown"},"source":{"dfbedfa9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cca62d9":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt","59245074":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest  = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n","818bdc3e":"# printing first 5 rows\ntrain.head()","e2364a36":"# shape of data\ntrain.shape,test.shape","e0879231":"# information about data\ntrain.info()","fc95ed91":"train.isnull().sum()","a71184e0":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() #","fc4cc367":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))\nbar_chart('Sex')","581dd411":"bar_chart('Pclass')","10ee883b":"bar_chart('SibSp')","bc2228f5":"bar_chart('Parch')","4e5b6c24":"bar_chart('Embarked')","524e51d9":"train_test_data = [train, test] # combining train and test dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","a68ff02e":"train['Title'].value_counts()","5e488030":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","30d68690":"train.head()","2c4ac8e9":"bar_chart('Title')","398d0996":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","b6155bbe":"train.head()","9a63d62f":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","4632dcac":"bar_chart('Sex')","b7217c52":"train.head(20)","f6e1988f":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","08d28c6a":"train.head(10)\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","a3d39b06":"train.info()","4c46826c":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show()","acc724e6":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","50a96755":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","8b065ac4":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","1d9a0ed9":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","074e8ab2":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","e8ffe089":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","bfd1ceaa":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","e040633a":"bar_chart('Age')","a3833a93":"train.head()","ce713377":"#filling missing values\nPclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))\n","0df183d4":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\ntrain.head()","4ece78db":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","cf4107cd":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(250)","3f5aa87e":"train.head()","016e7c39":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","ec0499e1":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","f15f7217":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","e1bd7053":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","d1715c76":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","1184a50a":"train.Cabin.value_counts()","2bde1eaf":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","ec564c15":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","60a2da25":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)\n","b2274efa":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","26151499":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n","5e516f71":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","a070710e":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","f5c00834":"train.head()","f61d00db":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","44412673":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","14abd168":"train_data.head(8)","4e09102a":"from sklearn.svm import SVC","a8617f63":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n","02f7c619":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","f1877d03":"round(np.mean(score)*100,2)","31f0d27a":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","52b4f3fc":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","bc0fe8f1":"submission = pd.read_csv('submission.csv')\nsubmission.head(20)","2e198e02":"*Cabin*","4a4fa0cb":"We can see that Age value is missing for many rows.\n\nOut of 891 rows, the Age value is present only in 714 rows.\n\nSimilarly, Cabin values are also missing in many rows. Only 204 out of 891 rows have Cabin values.","474a62f1":"### Step 3-->Exploratory data analysis","2d712bac":"### Step 1 -->Defining the problem statement\nComplete the analysis of what sorts of people were likely to survive.\nIn particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy.","6da52dbf":"### Step 4-->Feature engineering","3c802ff9":"*Age*","cdb59b18":"# Titanic : Machine Learning from Disaster\n\n### Predict survival on the Titanic\n#### step 1 -->Defining the problem statement\n#### step 2 -->Collecting the data\n#### step 3 -->Exploratory data analysis\n#### step 4 -->Feature engineering\n#### step 5 -->Modelling\n#### step 6 -->Testing","0afebfc7":"*Embarked*","4613ccd3":"*Binning*","ae069a88":"The Chart confirms a person aboarded from C slightly more likely survived\n\nThe Chart confirms a person aboarded from Q more likely dead\n\nThe Chart confirms a person aboarded from S more likely dead","b1bd75b2":"The Chart confirms 1st class more likely survivied than other classes\n\nThe Chart confirms 3rd class more likely dead than other classes","476508c3":"*Sex*","e3f6f0f3":"*FamilySize*","6b4a676e":"##### The Chart confirms Women more likely survivied than Men","c715c390":"The Chart confirms a person aboarded with more than 2 parents or children more likely survived\n\nThe Chart confirms a person aboarded alone more likely dead","86af47eb":"#### for visualization","c303903c":"*Name*","85d32301":"The Chart confirms a person aboarded with more than 2 siblings or spouse more likely survived\n\nThe Chart confirms a person aboarded without siblings or spouse more likely dead","cd738543":"*Fare*","f63afc4d":"#### Bar Chart for Categorical Features\n -->Pclass\n \n -->Sex\n \n -->SibSp ( # of siblings and spouse)\n \n -->Parch ( # of parents and children)\n \n -->Embarked\n \n -->Cabin","15a84a1e":"### Step 2-->Collecting the data"}}