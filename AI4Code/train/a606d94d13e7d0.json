{"cell_type":{"84074e4f":"code","cf5535e7":"code","641eccc2":"code","514897b2":"code","5438082c":"code","3d7eba0d":"code","6c20eb26":"code","c5133e64":"code","8765f85d":"code","db0571f5":"code","c1036b8d":"code","028b925d":"code","71b8c505":"code","02677c6b":"code","bae420ed":"code","45a74372":"code","b45ad3a2":"code","71e504ef":"code","45dba3de":"code","d96b2411":"code","eafb7c1a":"code","63557239":"code","80d53a26":"code","a6fdca0e":"code","3b8f479b":"code","364886c9":"code","42f4fdab":"code","e0f707d7":"code","49fedfbf":"code","bdd17953":"code","63e2e1cd":"code","bef0943b":"code","4d4e1da4":"code","ee32b44a":"code","089f17e0":"code","a5e0421f":"code","d10fd9d1":"code","820d9cc8":"code","a5d7bdfd":"code","a414fb40":"code","34b5e186":"code","4d2a7413":"code","17dbd528":"code","1d913246":"code","346fa294":"code","3e48c043":"code","f2ebbb75":"code","e585fe2d":"code","9d439d97":"code","b9c1b3c5":"code","6e5d126f":"code","5264e94e":"code","a7f4ae6e":"code","8c2e7785":"code","247547d9":"code","7546fa31":"code","f924614c":"code","4213092e":"code","585d15b1":"code","eebb4b95":"code","12967e37":"code","69361aeb":"code","3a354ac8":"code","750bf608":"code","3ce635d1":"code","fdd01610":"code","0d1fcfc2":"code","5694f7cc":"code","d728cbd1":"code","bab4130f":"code","69802bbb":"code","2f6d1731":"code","391a4287":"code","c9ca8a2d":"code","b5dc8f07":"code","4b673ab2":"code","22db7614":"markdown","f8799c6f":"markdown","7d358e36":"markdown","782e0960":"markdown","e2e3de66":"markdown","a7906381":"markdown","cc820e81":"markdown","880246cd":"markdown","b81f26d7":"markdown","b45eba8a":"markdown","377d9432":"markdown","44fd2aa7":"markdown","0f783fc1":"markdown","217a89dd":"markdown","a8182d75":"markdown"},"source":{"84074e4f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf5535e7":"!pip install plotly","641eccc2":"!pip install cufflinks","514897b2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import iplot\nimport plotly as py\nimport plotly.tools as tls\nimport cufflinks as cf","5438082c":"train = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv',na_values=['unknown'])\nsubmission = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\ntest = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\ntrain.head()","3d7eba0d":"train.isnull().sum()","6c20eb26":"train.info()","c5133e64":"py.offline.init_notebook_mode(connected = True)\ncf.go_offline()","8765f85d":"type(train.columns)","db0571f5":"lists = ['anatom_site_general_challenge']","c1036b8d":"# cf.set_config_file(theme = 'solar')\nfrom bokeh.models.widgets import DataTable, TableColumn\nfrom bokeh.models import ColumnDataSource\n\ndata_table = DataTable(\n    columns=[TableColumn(field=Ci, title=Ci) for Ci in lists],\n    source=ColumnDataSource(train),\n    height=300,\n)\n\n\ncount_anatom = train['anatom_site_general_challenge'].value_counts().plot_bokeh(kind = 'barh',color='green',title=\"count of location of imaged site\", \n    alpha=0.6,show_figure=False)\n\npandas_bokeh.plot_grid([[data_table, count_anatom]], plot_width=400, plot_height=350)\n","028b925d":"train['benign_malignant'].value_counts().plot_bokeh(kind='bar',alpha=0.6,color= 'red',title=\"count of benign and malignant\",ylabel='count',xlabel='benign_malignant')","71b8c505":"train['diagnosis'].value_counts().plot_bokeh(kind='bar',color ='magenta',alpha=0.6,vertical_xlabel=True,title=\"count of diagnosis\",ylabel='count',xlabel='diagnosis')","02677c6b":"train['age_approx'].value_counts().plot_bokeh(kind='bar',color = 'blue',title=\"count of age_approx\",vertical_xlabel=True,ylabel='count',xlabel='age_approx',alpha=0.6)","bae420ed":"train['sex'].value_counts().plot_bokeh(kind='bar',alpha=0.6,colormap=[\"#009933\"],title=\"count of sex\",ylabel='count',xlabel='sex')","45a74372":"p_vs_img = train.groupby('patient_id').image_name.count().to_frame().reset_index()","b45ad3a2":"p_vs_img_plot = p_vs_img.sort_values(by=['image_name'],ascending=False).iloc[0:50]\np_vs_img_plot.plot_bokeh(kind='bar',alpha=0.6,color=\"brown\",title=\"count of top 50 patient_id\",ylabel='count',xlabel='patient_id',vertical_xlabel=True)","71e504ef":"\n# patient_id\ntrain['patient_id'].value_counts().plot_bokeh(kind='bar',alpha=0.6,color=\"blue\",title=\"count of full patient_id\",ylabel='count',xlabel='patient_id',vertical_xlabel=True,figsize=(1000, 600))","45dba3de":"(train.groupby('patient_id').image_name.count()).max()","d96b2411":"train.head()","eafb7c1a":"train.groupby(['target','sex']).count()","63557239":"train.groupby(['target','anatom_site_general_challenge'])['benign_malignant'].count().iplot(kind = 'bar')","80d53a26":"train.groupby(['target','sex'])['benign_malignant'].count().iplot(kind = 'bar',color='red')","a6fdca0e":"train.groupby(['target','age_approx'])['benign_malignant'].count().iplot(kind = 'bar',color='green')","3b8f479b":"train.groupby(['sex','anatom_site_general_challenge'])['benign_malignant'].count().iplot(kind = 'bar',color = 'blue')","364886c9":"train.groupby(['target','diagnosis'])['benign_malignant'].count().iplot(kind = 'bar')","42f4fdab":"train.groupby(['sex','diagnosis'])['benign_malignant'].count().iplot(kind = 'bar',color ='magenta')","e0f707d7":"amount = train.groupby('anatom_site_general_challenge')['anatom_site_general_challenge'].transform('count')","49fedfbf":"import plotly.graph_objs as go\nlabels = set(train['anatom_site_general_challenge'])\nlabels_list = list(labels)\ntrace = go.Pie(values=amount,labels = labels_list,hole=0.3,pull=[0, 0, 0.2, 0])\niplot([trace])","bdd17953":"train['diagnosis'].value_counts()","63e2e1cd":"train['diagnosis'].value_counts().iplot(kind='bar',color='yellow')","bef0943b":"train.head()","4d4e1da4":"numerical_features = [i for i in train.columns if train[i].dtypes != 'O']\nnumerical_features","ee32b44a":"categorical_features = [i for i in train.columns if train[i].dtypes == 'O']\ncategorical_features","089f17e0":"discreat_features = [i for i in numerical_features if len(train[i].unique())<25 ]\ndiscreat_features","a5e0421f":"import gc\ngc.collect()","d10fd9d1":"train.head()","820d9cc8":"train.isnull().sum()","a5d7bdfd":"nan_features = [i for i in train.columns if train[i].isnull().sum()>=1]\nnan_features","a414fb40":"# pd.pandas.set_option('display.max_columns',None)\n# pd.pandas.set_option('display.max_rows',None)\n\ntrain['age_approx'] = train['age_approx'].fillna(train['age_approx'].median())\ntrain['age_approx'].isnull().sum()","34b5e186":"train['anatom_site_general_challenge'].mode()","4d2a7413":"train['anatom_site_general_challenge']=train['anatom_site_general_challenge'].fillna('torso') \ntrain['anatom_site_general_challenge'].isnull().sum()","17dbd528":"train['sex'] = train['sex'].fillna(str(train['sex'].mode()))\ntrain['diagnosis'] = train['diagnosis'].fillna(str(train['diagnosis'].mode()))\ntrain['sex'].isnull().sum()\ntrain['diagnosis'].isnull().sum()","1d913246":"train.isnull().sum()","346fa294":"from sklearn.preprocessing import LabelEncoder\nlabel_encod = LabelEncoder()\n\nfor i in categorical_features:\n    train[i]=label_encod.fit_transform(train[i])","3e48c043":"train.head()","f2ebbb75":"data = train.copy()\ndata = data.drop(['image_name','patient_id','diagnosis','benign_malignant'],axis = 1)\ndata.head()","e585fe2d":"Y = data['target']\nX = data.drop(['target'],axis = 1)\n","9d439d97":"SEED = 42\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_val,y_train,y_val = train_test_split(X,Y,test_size = 0.2,random_state = SEED)","b9c1b3c5":"random_grid = {'bootstrap': [True, False],\n               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n               'max_features': ['auto', 'sqrt'],\n               'min_samples_leaf': [1, 2, 4],\n               'min_samples_split': [2, 5, 10],\n               'n_estimators': [130, 180, 230]}","6e5d126f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n\nclassifier_rf = RandomForestClassifier(random_state=SEED)\nrf_random = RandomizedSearchCV(estimator = classifier_rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(x_train,y_train)","5264e94e":"rf_random.best_estimator_","a7f4ae6e":"classifier_rf1 = RandomForestClassifier(max_depth=70, min_samples_leaf=4, min_samples_split=5,\n                       n_estimators=180, random_state=42)\nclassifier_rf1.fit(x_train,y_train)","8c2e7785":"y_pred = classifier_rf1.predict_proba(x_val)\ntype(y_pred)","247547d9":"test.isnull().sum()","7546fa31":"test['anatom_site_general_challenge'] = test['anatom_site_general_challenge'].fillna(str(test['anatom_site_general_challenge'].mode())) ","f924614c":"test.isnull().sum()","4213092e":"categorical_fea_test = [i for i in test.columns if test[i].dtypes == 'O']\nfor i in categorical_fea_test:\n    test[i] = label_encod.fit_transform(test[i])\n    \ntest.head()","585d15b1":"test = test.drop(['image_name','patient_id'],axis = 1)\ntest.head()","eebb4b95":"from sklearn.metrics import roc_curve, roc_auc_score,auc\nprint(roc_auc_score(y_val, y_pred[:,1]))\n\nfpr, tpr, _ = roc_curve(y_val, y_pred[:,1])\n\nplt.clf()\nplt.plot(fpr, tpr)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC curve')\nplt.show()","12967e37":"y_pred","69361aeb":"auc_rf = auc(fpr,tpr)\nprint(auc_rf)","3a354ac8":"y_pred_test_rf = classifier_rf1.predict_proba(test)\ny_pred_test_rf[:,1].","750bf608":"submission_main = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","3ce635d1":"img_sub = pd.read_csv('..\/input\/1st-featuredcom-submission-baseline-keras-vgg16\/submission.csv')\nimg_sub.head()","fdd01610":"import xgboost as xgb\nfrom scipy import stats\nfrom scipy.stats import randint\n\nxgb_clf = xgb.XGBClassifier()\n\n\nparam_dist = {'n_estimators': stats.randint(150, 1000),\n              'learning_rate': stats.uniform(0.01, 0.6),\n              'subsample': stats.uniform(0.3, 0.9),\n              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n              'colsample_bytree': stats.uniform(0.5, 0.9),\n              'min_child_weight': [1, 2, 3, 4]\n             }\nclf_xgb = RandomizedSearchCV(xgb_clf, param_distributions = param_dist, n_iter = 25, scoring = 'roc_auc', error_score = 0, verbose = 3, n_jobs = -1)\nclf_xgb.fit(x_train,y_train)","0d1fcfc2":"clf_xgb.best_estimator_\n","5694f7cc":"xgbo = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5791848525626986, gamma=0,\n              gpu_id=-1, importance_type='gain', interaction_constraints='',\n              learning_rate=0.47840118037023044, max_delta_step=0, max_depth=4,\n              min_child_weight=4, monotone_constraints='()',\n              n_estimators=585, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n              subsample=0.792826572247452, tree_method='exact',\n              validate_parameters=1, verbosity=None)\n","d728cbd1":"xgbo.fit(x_train,y_train)\ny_pred_xgb = xgbo.predict_proba(x_val)","bab4130f":"print(roc_auc_score(y_val, y_pred_xgb[:,1]))\n","69802bbb":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import (AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier)\nfrom sklearn.tree import DecisionTreeClassifier\n\nbase_learners = [\n                 ('rf_1', RandomForestClassifier(n_estimators=100, random_state=SEED)),\n                 ('adb',AdaBoostClassifier(n_estimators=100, random_state=SEED)),\n                 ('ext',ExtraTreesClassifier(n_estimators=100, random_state=SEED)),\n                 ('gbc',GradientBoostingClassifier(n_estimators=100,random_state=SEED)),\n                 ('svc', SVC())\n    \n    \n                ]\n\n# Initialize Stacking Classifier with the Meta Learner\nstk_clf = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())\n\nstk_clf.fit(x_train, y_train)","2f6d1731":"y_pred_stk = stk_clf.predict_proba(x_val)","391a4287":"print(roc_auc_score(y_val, y_pred_stk[:,1]))\n","c9ca8a2d":"!pip install -U pandas_bokeh","b5dc8f07":"import pandas_bokeh\npd.set_option('plotting.backend', 'pandas_bokeh')\npandas_bokeh.output_notebook()\n","4b673ab2":"train['anatom_site_general_challenge'].value_counts().plot_bokeh(kind='barh')","22db7614":"### Label Encoding","f8799c6f":"### Model Building:(RF)","7d358e36":"## Pandas-Bokeh is use full and quite handy. I previously tried to use Bokeh but because of its complexcity i gave up and started learning plotly.In this notebook i used both bokeh and plotly for comparison. Except that i have implimented stacking on the tabular data which is giving score of 0.685.","782e0960":"# Feature Engineering:","e2e3de66":"### Image prediction file: ","a7906381":"### Droping some columns:","cc820e81":"### Evaluation:","880246cd":"#### So random Forest is giving me more better results than Xgboost, though the difference is slightly large.","b81f26d7":"So, we got some features which are neumerical and categorical. And from above cell it is clear that the neumerical features are discontinious.so there is no continious features.","b45eba8a":"### Train test split:","377d9432":"### Test data:","44fd2aa7":"### Feature Engineering:","0f783fc1":"### Model Building:(XGB)","217a89dd":"#### So stacking is producing far more better result than, normal xgboost or random forest. And it is found that we are getting same score with and without SVC.","a8182d75":"### Stacking:"}}