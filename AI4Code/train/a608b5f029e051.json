{"cell_type":{"748fba46":"code","e2fa65b9":"code","52560f95":"code","e3e0fc59":"code","36d184f2":"code","e1b0175d":"code","7354da7e":"code","e75a49a6":"code","1418faeb":"code","6e591ebc":"code","b8a61fc6":"code","59ef3676":"code","7ad0fe9e":"code","f7a7d2fc":"code","e5797e56":"code","64ae92a6":"markdown","07e9b816":"markdown","2476a137":"markdown","fbd8bdce":"markdown","0837ac59":"markdown"},"source":{"748fba46":"import gc\nimport os,h5py\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\n\nimport torch\nfrom torch import nn,optim\nimport matplotlib.pyplot as plt\n\nimport os, glob\nfrom scipy.ndimage import map_coordinates\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nfrom skimage import io\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize","e2fa65b9":"DATA_ROOT_FOLDER = '\/kaggle\/input\/textiledefectdetection'","52560f95":"class TextureDataset(Dataset):\n    filenames = {64: dict(train=('train64.csv', 'train64.h5'), test=('test64.csv', 'test64.h5')),\n                 32: dict(train=('train32.csv', 'train32.h5'), test=('test32.csv','test32.h5'))}\n    indication_classes = ['index', 'angle', 'indication_type', 'indication_value', 'split']\n    def __init__(self,root_folder, train=True, patch_size=64, classification=True, task='defect',keep_angles=True,keep_defects=False, transformation=None, test_sub_sample=200):\n        if os.path.exists(root_folder):\n            self.root_folder = root_folder\n        else:\n            raise IOError('The path of the directory is incorrect or doesn\\'t exist')\n        \n        self.patch_size = patch_size if patch_size in self.filenames.keys() else 32\n        self.infos, self.data = self.load_data(train)\n        if train:\n            if classification:\n                #print('Classification Task:', end=' ')\n                if task=='defect' and not keep_angles:    \n                    self.infos = self.infos.loc[self.infos['angle']==0]\n                    #print('Drop all angles others than 0')\n                elif task=='angle' and not keep_defects:\n                    self.infos = self.infos.loc[self.infos['indication_type']=='good']\n                    print('Drop all defect (all other than good)')\n                else:\n                    print('Keep\u00edng all the data')\n                    pass\n            else:\n                print('By default only keep healthy')\n                self.infos = self.infos.loc[(self.infos['indication_type']=='good') & (self.infos['angle']==0)]\n            self.data = self.data[self.infos.index]\n        self.transformation = transforms.Compose([transforms.ToTensor()]) if transformation is None  else  transformation\n        \n        \n        if not train and test_sub_sample:\n            X = []\n            newinfo = pd.DataFrame()\n            for (a,t), df in self.infos.groupby(['angle','indication_type']):\n                index = df.index\n                subi = np.random.choice(index, test_sub_sample, replace=False)\n                X.append(self.data[subi])\n                newinfo = newinfo.append(self.infos.iloc[subi],ignore_index=True)\n            self.infos = newinfo\n            self.data = np.concatenate(X)\n    \n    def __len__(self):\n        return self.infos.shape[0]\n        \n    def __getitem__(self,index):\n        info = self.infos.iloc[index]\n        angle, indication_value = int(info['angle'])\/\/20, int(info['indication_value'])\n        img = self.data[index]\n        \n        return self.transformation(img),angle, indication_value\n            \n    \n    def load_data(self,train):\n        files = self.filenames[self.patch_size]\n        infos_filename, data_filename = files['train'] if train else files['test']\n        \n        infos = pd.read_csv(os.path.join(self.root_folder,infos_filename))\n        data = None\n        with h5py.File(os.path.join(self.root_folder,data_filename),mode='r') as h5file:\n            data = h5file['images'][:]\n        return infos, data        \n    \n    @staticmethod\n    def get_angles_classes():\n        return np.arange(8)* 20\n    @staticmethod\n    def get_indication_classes():\n        return ['good', 'color', 'cut',  'hole', 'thread', 'metal_contamination']\n    @staticmethod\n    def compute_normalization_parameters(root):\n        print('#### Compute Mean and Std of image for image scaling')\n        dataset = TextureDataset(root_folder=root, classification=True,task='angle',keep_defects=False)\n        loader = DataLoader(dataset,batch_size=15, num_workers=4, shuffle=True)\n        mean = 0.\n        std = 0.\n        for images, _,_ in loader:\n            batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n            images = images.view(batch_samples, images.size(1), -1)\n            mean += images.mean(2).sum(0)\n            std += images.std(2).sum(0)\n\n        mean \/= len(loader.dataset)\n        std \/= len(loader.dataset)\n        print(f\"\"\" Normalize the data as following:\n        transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize({mean}, {std} )])\n        this function return the object Normalize the new mean and std: transforms.Normalize({mean}, {std} )\n        \"\"\")\n        return transforms.Normalize(mean, std )","e3e0fc59":"from torch import nn\nimport torch\n\n\nfor i in range(torch.cuda.device_count()):\n    print(\"Found device {}:\".format(i), torch.cuda.get_device_name(i))\n\nif torch.cuda.device_count() == 0:\n    print(\"No GPU device found\")\nelse:\n    print(\"Current cuda device is\", torch.cuda.get_device_name(torch.cuda.current_device()))\n\nclass Cudafy(object):\n    \n    def __init__(self, device=None):\n        if torch.cuda.is_available() and device:\n            self.device = device\n        else:\n            self.device = 0\n    \n    def name(self):\n        if torch.cuda.is_available():\n            return torch.cuda.get_device_name(self.device)\n        return 'Cuda is not available.'\n    \n    def put(self, x):\n        \"\"\"Put x on the default cuda device.\"\"\"\n        if torch.cuda.is_available():\n            return x.to(device=self.device)\n        return x\n\n    def __call__(self, x):\n        return self.put(x)\n    \n    def get(self,x):\n        \"\"\"Get from cpu.\"\"\"\n        if x.is_cuda:\n            return x.to(device='cpu')\n        return x\n    \ndef cpu(x):\n    if x.is_cuda:\n        return x.to(device='cpu')\n    return x","36d184f2":"class Encoder(nn.Module):\n    def __init__(self, args):\n        super(Encoder, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.main = nn.Sequential(\n            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 2),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 8),\n            nn.ReLU(True),\n        )\n        self.fc = nn.Linear(self.dim_h * (2 ** 5), self.n_z)\n\n    def forward(self, x):\n        x = self.main(x)\n             \n        \n        x=x.view(-1,self.dim_h * (2 ** 5))\n        #x = x.squeeze()\n        #print('x before fc',x.shape)\n        x = self.fc(x)\n        return x\nclass Decoder(nn.Module):\n    def __init__(self, args):\n        super(Decoder, self).__init__()\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.proj = nn.Sequential(\n            nn.Linear(self.n_z, self.dim_h * 8 * 2 * 2),\n            nn.ReLU()\n        )\n        self.main = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear'),\n            nn.Conv2d(self.dim_h * 8, self.dim_h * 4, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Upsample(scale_factor=2, mode='bilinear'),\n            nn.Conv2d(self.dim_h * 4, self.dim_h * 2, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 2),\n            nn.ReLU(True),\n            nn.Upsample(scale_factor=2, mode='bilinear'),\n            nn.Conv2d(self.dim_h * 2, self.dim_h , 3, 1, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h),\n            nn.ReLU(True),\n            nn.Upsample(scale_factor=2, mode='bilinear'),\n            nn.Conv2d(self.dim_h, self.n_channel , 3, 1, 1, bias=False),\n            nn.BatchNorm2d(self.n_channel),\n            nn.Sigmoid(),\n        )\n    def forward(self, x):\n        x = self.proj(x)\n        x = x.view(-1, self.dim_h * 8, 2, 2)\n        x = self.main(x)\n        return x\nclass AE(nn.Module):\n\n    def __init__(self,args):\n        super(AE, self).__init__()\n        self.encoder = Encoder(args)\n        self.decoder = Decoder(args)\n    \n    def forward(self,x):\n        x = self.encoder(x)\n        return self.decoder(x)","e1b0175d":"class cEncoder(nn.Module):\n    def __init__(self, args):\n        super(cEncoder, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n        self.edoor=args.edoor\n        self.eBias=args.dBias\n\n\n        self.main = nn.Sequential(\n            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=self.eBias),\n            self.edoor,\n            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=self.eBias),\n            nn.BatchNorm2d(self.dim_h * 2),\n            self.edoor,\n            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=self.eBias),\n            nn.BatchNorm2d(self.dim_h * 4),\n            self.edoor,\n            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=self.eBias),\n            nn.BatchNorm2d(self.dim_h * 8),\n            self.edoor,\n        )\n        self.fc = nn.Linear(self.dim_h * (2 ** 5), self.n_z)\n\n    def forward(self, x):\n        x = self.main(x)\n             \n        \n        x=x.view(-1,self.dim_h * (2 ** 5))\n        #x = x.squeeze()\n        #print('x before fc',x.shape)\n        x = self.fc(x)\n        return x\nclass cDecoder(nn.Module):\n    def __init__(self, args):\n        super(cDecoder, self).__init__()\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n        self.finalLayer=args.fl\n        self.ddoor=args.ddoor\n        self.dBias=args.eBias\n\n        self.proj = nn.Sequential(\n            nn.Linear(self.n_z, self.dim_h * 8 * 2 * 2),\n            nn.ReLU()\n        )\n        self.main = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False),\n            nn.Conv2d(self.dim_h * 8, self.dim_h * 4, 3, 1, 1, bias=self.dBias),\n            nn.BatchNorm2d(self.dim_h * 4),\n            self.ddoor,\n            nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False),\n            nn.Conv2d(self.dim_h * 4, self.dim_h * 2, 3, 1, 1, bias=self.dBias),\n            nn.BatchNorm2d(self.dim_h * 2),\n            self.ddoor,\n            nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False),\n            nn.Conv2d(self.dim_h * 2, self.dim_h , 3, 1, 1, bias=self.dBias),\n            nn.BatchNorm2d(self.dim_h),\n            self.ddoor,\n            nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False),\n            nn.Conv2d(self.dim_h, self.n_channel , 3, 1, 1, bias=self.dBias),\n            nn.BatchNorm2d(self.n_channel),\n            self.finalLayer,\n        )\n    def forward(self, x):\n        x = self.proj(x)\n        x = x.view(-1, self.dim_h * 8, 2, 2)\n        x = self.main(x)\n        return x\nclass cAE(nn.Module):\n\n    def __init__(self,args):\n        super(cAE, self).__init__()\n        self.encoder = cEncoder(args)\n        self.decoder = cDecoder(args)\n    \n    def forward(self,x):\n        x = self.encoder(x)\n        return self.decoder(x)","7354da7e":"def make_model(dim_h,n_z,n_channel):\n    class Arg():\n        def __init__(self):\n            pass\n            \n    args = Arg()\n    args.dim_h = dim_h\n    args.n_z = n_z\n    args.n_channel = n_channel    \n    model = AE(args=args)\n\n    return model","e75a49a6":"\ndef make_custom_model(dim_h,n_z,n_channel):\n    class Arg():\n        def __init__(self):\n            pass\n            \n    args = Arg()\n    args.dim_h = dim_h\n    args.n_z = n_z\n    args.n_channel = n_channel\n    args.eBias = True\n    args.dBias = False\n    args.edoor = nn.ReLU(True) #Encoder door\n    args.ddoor = nn.ReLU(True) #Decoder door\n    args.fl    = nn.Sigmoid()\n    \n    model = cAE(args=args)\n\n    return model","1418faeb":"from torchvision import transforms,utils\n\ndef getdataloader(root, patch_size=32, task='defect',batch_size=32,keep_angles=False,test_sub_sample=False,num_workers=5, *args,**kwargs):\n    \n    transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.3541], [0.1352]), transforms.RandomErasing(0.3, value=0)])\n    \n    dataset = TextureDataset(root,train=True,patch_size=patch_size, classification=True, task=task, transformation=transformation,keep_angles=keep_angles)\n    train_loader = DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True,num_workers=num_workers, pin_memory=True)\n    \n    transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.3541], [0.1352])])\n    \n    dataset = TextureDataset(root,train=False,patch_size=patch_size, classification=True, task=task, transformation=transformation,test_sub_sample=test_sub_sample)\n    val_loader = DataLoader(dataset=dataset,batch_size=int(batch_size*2),shuffle=False,num_workers=num_workers)\n    \n    return train_loader, val_loader","6e591ebc":"def run_train(model, batch_size, patch_shape, epochs, lr, test_sub_sample, optim, crit, display):\n\n    \n    gpu = Cudafy(device=0)\n    model = gpu(model)\n    \n    funcdict = {\n        'Adam': torch.optim.Adam,\n        'SGD': torch.optim.SGD,\n        'Adadelta': torch.optim.Adadelta,\n        'RMSprop': torch.optim.RMSprop,\n    }\n\n    optim = funcdict[optim](model.parameters(), lr = lr)\n    \n    #optim = optim(model.parameters(), lr = lr)\n    criterion = crit\n    \n    \n     #Load Data\n    \n    train_loader,valid_loader=getdataloader(root='\/kaggle\/input\/textiledefectdetection', patch_size=patch_shape, batch_size=batch_size, task='defect',test_sub_sample=test_sub_sample, nclasses = len(TextureDataset.get_indication_classes()))\n\n    metric = dict(l2_train=[],l2_valid=[])\n    if(display):\n        print(f'total iterations: {len(train_loader)}')\n    for epoch in range(epochs):\n        if(display):\n            print(f'Epoch: {epoch}')\n        b = []\n        model.train()\n        for it,data  in enumerate(train_loader):\n            img, _, _ = data\n            img = gpu(img)\n            output = model(img)\n            loss = criterion(output, img)\n            optim.zero_grad() # Backward & update weights\n            loss.backward()\n            b.append( cpu(loss).item())\n            if display and (it%50==0 or it==len(train_loader)):\n                print(f'it: {it}, loss: {b[-1]}')\n            optim.step()\n        metric['l2_train'].append(np.mean(b))\n        model.eval()\n        b = []\n        with torch.no_grad():\n            if(display):\n                print('computing loss in validation set')\n            for itval, data  in enumerate(valid_loader):\n                if display and (itval%50==0 or itval==len(valid_loader)):\n                    print(f'it:{itval}\/{len(valid_loader)}')\n                img, _, _ = data\n                img = gpu(img)\n                output = model(img)\n                loss = criterion(output, img)\n                b.append( cpu(loss).numpy()) \n        metric['l2_valid'].append( np.mean(b))  \n\n    ret=loss\n    if(display):\n        plt.figure()\n        metric = pd.DataFrame(metric)\n        metric['epochs'] = np.arange(epochs)\n        metric = pd.melt(metric,id_vars='epochs', value_vars=['l2_train','l2_valid'])\n        sns.lineplot(x='epochs', y='value',hue='variable',data=metric)  \n    # test on a dataset\n    model.eval()\n    print('',end='\\r')\n\n    with torch.no_grad():\n\n        for data in valid_loader:\n            img, _, _ = data\n            img = gpu(img)\n            output = model(img)\n            loss = criterion(output, img)\n                                                    \n            if(display):\n                fig, axes = plt.subplots(1, 2, figsize=(20,10))\n                axes = axes.ravel()\n                for ax,i in zip(axes,[img, output]):\n                    grid_img = utils.make_grid(cpu(i),nrow=8).permute(1, 2, 0)\n                    ax.imshow(grid_img)\n                plt.axis('off')\n            break#only show one, the whole validset is too big to visualize\n            \n    return ret","b8a61fc6":"#@title Parameters\n\np_batch_size = 32 #@param {type:\"slider\", min:0, max:128, step:16}\np_patch_size = 32\np_test_sub_sample=100\np_epochs =  5#@param {type:\"integer\"}\np_lr = 1e-3 #@param {type:\"number\"}\np_dim_h = 128 #@param {type:\"integer\"}\np_n_z = 32 #@param {type:\"integer\"}\np_n_channel = 1 #@param {type:\"integer\"}\ncrit = nn.MSELoss()     #I want to test the nn.NNL() in this case3.0\noptim='Adam'\n\n\nclass Arg():\n    def __init__(self):\n        pass\n\nargs = Arg()\nargs.dim_h = p_dim_h\nargs.n_z = p_n_z\nargs.n_channel = p_n_channel\nargs.eBias = True\nargs.dBias = False\nargs.edoor = nn.ReLU(True) #Encoder door\nargs.ddoor = nn.ReLU(True) #Decoder door\nargs.fl    = nn.Sigmoid()\n\nmodel = cAE(args=args)\n\n#run_train(model=model, batch_size = p_batch_size, patch_shape=p_patch_size, epochs = p_epochs, lr = p_lr,test_sub_sample=p_test_sub_sample, optim=optim, crit = crit,display=False)","59ef3676":"def make_model(p_dim_h, p_n_z, p_n_channel):\n    class Arg():\n        def __init__(self):\n            pass\n\n    args = Arg()\n    args.dim_h = p_dim_h\n    args.n_z = p_n_z\n    args.n_channel = p_n_channel\n    args.eBias = True\n    args.dBias = False\n    args.edoor = nn.ReLU(True) #Encoder door\n    args.ddoor = nn.ReLU(True) #Decoder door\n    args.fl    = nn.Sigmoid()\n    \n    model = cAE(args=args)\n    \n    return model","7ad0fe9e":"from statistics import variance \n\ndef ultimateExperiments():\n    #@title Parameters\n\n    p_batch_size = [32, 64] #@param {type:\"slider\", min:0, max:128, step:16}\n    p_patch_size = 32\n    p_test_sub_sample=100\n    p_epochs = 5 #[1, 50, 150, 300] #@param {type:\"integer\"}\n    p_lr = [1e-3, 1e-2, 1e-1] #@param {type:\"number\"}\n    p_dim_h = [64, 128] #@param {type:\"integer\"}\n    p_n_z = [32, 64, 128] #@param {type:\"integer\"}\n    p_n_channel = 1 #@param {type:\"integer\"}\n    crit = [nn.MSELoss(), nn.NLLLoss]  #I want to test the nn.NNL() in this case3.0\n    optim=['Adam', 'SGD', 'RMSprop']\n    repet=2\n    \n    count=1\n    \n    model = make_model(p_dim_h[1], p_n_z[1], p_n_channel)\n    #run_train(model=model, batch_size = p_batch_size[0], patch_shape=p_patch_size[0], epochs = p_epochs[0], lr = p_lr[0], test_sub_sample=p_test_sub_sample[0], optim=optim[0], crit = crit[0], display=False)\n    #metric=run_train(model=model, batch_size = batch, patch_shape=p_patch_size[0], epochs = epoch, lr = l, test_sub_sample=sample, optim=optim[0], crit = crit[0], display=False)\n    min_var=10\n    list_s=[]\n    run_list=[]\n    idx=0\n    \n    for batch in p_batch_size :\n        for opt in optim :\n            for l in p_lr :\n\n                var=[]\n                run=[count, batch, p_test_sub_sample, p_epochs, l, opt]\n                run_list.append(run)\n                run_name='Run n\u00b0'+str(count)+', batch_size='+str(batch)+', sample=' + str(p_test_sub_sample)+ ', epochs='+str(p_epochs)+', lr='+str(l)+', optim='+opt\n                print(run_name)\n\n                list_s.append(run_name)\n                \n\n                for i in np.arange(repet):\n\n                    p=run_train(model=model, batch_size = batch, patch_shape=p_patch_size, epochs = p_epochs, lr = l, test_sub_sample=p_test_sub_sample, optim=opt, crit = crit[0], display=False)\n                    p=p.detach().cpu().numpy()\n\n                    var.append(p)\n                var=list(map(float,var))\n\n                var=variance(var)\n\n                if var<min_var:\n                    min_var=var\n                    idx=count-1\n\n                print('Loss Variance = '+ str(var))\n                \n                count=count+1\n            \n    print('BEST PARAMETERS : '+list_s[idx])\n\n    run_train(model=model, batch_size = run_list[idx][1], patch_shape=p_patch_size, epochs = run_list[idx][3], lr = run_list[idx][4], test_sub_sample=run_list[idx][2], optim=run_list[idx][5], crit = crit[0], display=True)","f7a7d2fc":"ultimateExperiments()","e5797e56":"#run_train(model=model, batch_size = p_batch_size, patch_shape=p_patch_size, epochs = p_epochs, lr = p_lr,dim_h = p_dim_h,n_z = p_n_z,n_channel = p_n_channel,test_sub_sample=p_test_sub_sample, optim=optim, crit = crit,dispay=True)","64ae92a6":"run train on the dataset","07e9b816":"Custom AE","2476a137":"Parameters","fbd8bdce":"AutoEncoder Model","0837ac59":"Loading Library"}}