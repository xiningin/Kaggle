{"cell_type":{"162c39ab":"code","31fa0ed1":"code","d619009f":"code","8e0012a6":"code","0bc0c64d":"code","830e5e2e":"code","17e9212b":"code","b6e925a1":"code","e4e421d0":"code","e09b4906":"code","07e491cc":"code","563d5673":"code","d82ad70e":"code","e38290f6":"code","778b5352":"code","cf83b789":"code","6eeb93e3":"code","1f8d6375":"code","b1cb02ce":"code","a4aed4a7":"code","89cd4e54":"code","5337b3a4":"code","d759ad8e":"code","10428479":"code","8b5c4538":"code","8a271c0e":"code","34ee95cc":"code","1ad327f6":"code","cde35d8e":"code","59c49a42":"code","b0752bd3":"code","d943f5b2":"code","778c2954":"code","e4739e58":"code","3a00bb62":"markdown","43b935db":"markdown","a543ee9d":"markdown","e6fc448c":"markdown","2dcf3122":"markdown","c7dd8545":"markdown","cb87a876":"markdown","647a3e0f":"markdown","e7ab2294":"markdown","089b5201":"markdown","08dbb09e":"markdown","b7b66cfa":"markdown","aff3c458":"markdown","be6ea51b":"markdown","2dc69c2d":"markdown","b46fdb9d":"markdown","6c1ae83c":"markdown","326f2e6f":"markdown","251ea6ab":"markdown","b748224e":"markdown","8f5f2e5d":"markdown","a774f8c7":"markdown","c06ce00f":"markdown","7e5d74cf":"markdown","e6085a52":"markdown","de7aa27d":"markdown"},"source":{"162c39ab":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')","31fa0ed1":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\nprint(f\"train set : {train.shape[1]} columns and {train.shape[0]} rows\")\nprint(f\"test set : {test.shape[1]} columns and {test.shape[0]} rows\")","d619009f":"train.head()","8e0012a6":"test_id = test.PassengerId.tolist()\ntest.insert(1, \"Survived\", np.nan)\n\ndataset = [train, test]","0bc0c64d":"features = ['Pclass', 'Name', 'Sex', 'Age', 'SibSp','Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\ntarget = \"Survived\"","830e5e2e":"def plot_missing(train, test):\n    fig, axes = plt.subplots(1,2, figsize=(20,6))\n    \n    m1 = train[features].isna()\n    m2 = test[features].isna()\n    \n    sns.heatmap(m1, cmap='viridis', cbar=False, yticklabels=[], ax=axes[0])\n    sns.heatmap(m2, cmap='viridis', cbar=False, yticklabels=[], ax=axes[1])\n    \n    axes[0].set_title(f\"Missing values in train\", fontsize=14)\n    axes[1].set_title(f\"Missing values in test\", fontsize=14)\n        \nplt.show()","17e9212b":"plot_missing(train, test)","b6e925a1":"train[features].isna().mean().to_frame('% of missing values')*100","e4e421d0":"plt.figure(figsize=(10,5))\n\ndf=train.groupby(['Sex',\"Pclass\"])['Age'].median().to_frame().reset_index()\n\nplot = sns.boxplot(x='Sex', y='Age', hue='Pclass', data=train)\nplot.set_xlabel(\"Sex\", fontsize=14, fontweight=\"bold\")\nplot.set_ylabel(\"Age\",fontsize=14, fontweight=\"bold\")\n\nplt.show()","e09b4906":"# Calaculate median ages\n\nmedian_ages = np.zeros((2,3))\n\nfor i, sex in enumerate([\"male\", \"female\"]):\n    for j in range(0,3):\n        median_ages[i,j] = train[((train['Sex'] == sex) &\n                                 (train['Pclass'] == j+1))]['Age'].median()","07e491cc":"# Put our estimates into NaN rows of new column AgeFill.\n\ntrain['AgeFill'] = train['Age']\ntest[\"AgeFill\"] = test[\"Age\"]\n\nfor data in dataset:\n    for i, sex in enumerate([\"male\", \"female\"]):\n        for j in range(0, 3):\n            data.loc[((data.Age.isnull()) &\n                      (data.Sex == sex) &\n                      (data.Pclass == j+1)), 'AgeFill'] = median_ages[i,j]\n\n\n    # Create a feature that records whether the Age was originally missing\n    data['AgeIsNull'] = pd.isnull(data['Age']).astype(int)\n\n    # Drop original age column\n    data.drop(\"Age\", axis=1, inplace=True)","563d5673":"medfare = data['Fare'].dropna().median()\n\nfor data in dataset:\n    data['Fare'].fillna(medfare, inplace=True)","d82ad70e":"# Feature that tells whether a passenger had a cabin on the Titanic\nfor data in dataset:\n    \n    data['Has_cabin'] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n    #Drop column\n    data.drop('Cabin', axis=1, inplace=True)","e38290f6":"mf = data.Embarked.mode()[0]\n\nfor data in dataset:\n    data.Embarked.fillna(value=mf, inplace=True)","778b5352":"continuous = ['Fare', 'AgeFill']\ndiscrete = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', \"Has_cabin\"]","cf83b789":"fig, ax = plt.subplots(figsize=(12, 5))\n\ndf = train[target].value_counts(normalize=True)\n\ndf.plot.bar(width=0.2, color=('red','green'), ax=ax, fontsize=14)\nax.set_title(\"Target distribution\", fontweight='bold', fontsize=15)\nplt.show()","6eeb93e3":"fig, axes = plt.subplots(3, 2, figsize=(10,12))\naxes = [ax for axes_row in axes for ax in axes_row]\n\nfor i,c in enumerate(discrete):\n    df = train[c].value_counts()\n    df.plot(kind='pie', ax=axes[i], title=c, autopct=\"%.2f\", fontsize=14)\n    axes[i].set_ylabel('')\n    axes[i].set_title(c, fontsize=14, fontweight='bold')\n    \nplt.show()","1f8d6375":"fig, axes = plt.subplots(ncols=2,figsize=(20, 6))\n\nfor i, c in enumerate(continuous):\n    \n    hist = train[c].plot(kind = 'hist',\n                         ax=axes[i], \n                         color='blue',\n                         bins=30)\n    axes[i].set_title(c, fontsize=14, fontweight='bold')\n    \nplt.show()","b1cb02ce":"for data in dataset:\n    data['Ticket_type'] = data['Ticket'].apply(lambda x: x[0:3])\n    data['Ticket_type'] = data['Ticket_type'].astype('category')\n    data['Ticket_type'] = data['Ticket_type'].cat.codes\n\n    # Remove ticket column\n    data.drop(\"Ticket\", axis=1, inplace=True)","a4aed4a7":"# Title from name\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor data in dataset:\n    \n    data.loc[:, 'Name_length'] = data.Name.apply(len)\n    data.loc[:, 'Word_count'] = data.Name.apply(lambda x: len(x.split()))\n\n    data.loc[:, 'Title'] = data['Name'].apply(get_title)\n    rare = ['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n\n    data['Title'] = data['Title'].replace(rare, 'Rare')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n\n    # Remove Name column\n    data.drop('Name', axis=1, inplace=True)","89cd4e54":"for data in dataset:\n    \n    # Mapping Sex\n    data['Sex'] = data['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    data['Title'] = data['Title'].map(title_mapping)\n    data['Title'] = data['Title'].fillna(0)\n\n    # Mapping Embarked\n    data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","5337b3a4":"# Mapping Fare\nfor data in dataset:\n    \n    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n\n    data.loc[((data['Fare'] > 7.91) & \n                 (data['Fare'] <= 14.454)), 'Fare'] = 1\n\n    data.loc[((data['Fare'] > 14.454) &\n                 (data['Fare'] <= 31)), 'Fare'] = 2\n\n    data.loc[ data['Fare'] > 31, 'Fare'] = 3\n\n    data['Fare'] = data['Fare'].astype(int)","d759ad8e":"# Mapping Age\nfor data in dataset:\n    \n    data.loc[ data['AgeFill'] <= 16, 'AgeFill'] = 0\n\n    data.loc[((data['AgeFill'] > 16) &\n                 (data['AgeFill'] <= 32)), 'AgeFill'] = 1\n\n    data.loc[((data['AgeFill'] > 32) &\n              (data['AgeFill'] <= 48)), 'AgeFill'] = 2\n\n    data.loc[((data['AgeFill'] > 48) & \n              (data['AgeFill'] <= 64)), 'AgeFill'] = 3\n\n    data.loc[data['AgeFill'] > 64, 'AgeFill'] = 4","10428479":"for data in dataset:\n    \n    # Create new feature FamilySize as a combination of SibSp and Parch\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n\n    # Create new feature IsAlone from FamilySize\n    data['IsAlone'] = 0\n    data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1","8b5c4538":"train.head()","8a271c0e":"final_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare','Embarked',\n                  'AgeFill', 'AgeIsNull', 'Has_cabin', 'Ticket_type',\n                  'Name_length', 'Word_count', 'Title', 'FamilySize', 'IsAlone']\n\ntrain = train[final_features+[target]]\ntest = test[final_features]\n\nX_train, X_test, y_train, y_test = train_test_split(train[final_features],\n                                                    train[target].astype(int),\n                                                    test_size=0.25,\n                                                    random_state=1,\n                                                    stratify=train[target]\n                                                   )\n\n\n# Make a copy of the test test\ntest_copy = test.copy()","34ee95cc":"plt.figure(figsize=(18,8))\n\ndf = train.corr()\n\nmask = np.triu(np.ones_like(df))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(df, annot=True, cbar=False, cmap=\"Blues\",mask=mask)\nplt.show()","1ad327f6":"from h2o.automl import H2OAutoML\nimport h2o\n# initiate h2o instance\nh2o.init()","cde35d8e":"hf_train = h2o.H2OFrame(train)\naml = H2OAutoML(max_models = 10, seed = 10, exclude_algos = [\"DeepLearning\"], verbosity=\"info\", nfolds=0)\naml.train(x = final_features, y = target, training_frame = hf_train)","59c49a42":"lb = aml.leaderboard\nlb.head(rows=lb.nrows)","b0752bd3":"preds = aml.predict(h2o.H2OFrame(test))","d943f5b2":"predictions = preds.as_data_frame().predict.apply(lambda x : 1 if x>0.5 else 0).values","778c2954":"df = pd.DataFrame({ 'PassengerId': test_id, 'Survived': predictions })\ndf.to_csv(\"predictions.csv\", index=False)","e4739e58":"df.head(5)","3a00bb62":"### Combine train and test","43b935db":"### Binning : Converting continuous features into discrete features","a543ee9d":"### Correlation between variables","e6fc448c":"### Hand picked features","2dcf3122":"<h1 align=\"center\"> Titanic Survival prediction<\/h1>\n\n<img src=\"https:\/\/images.pexels.com\/photos\/813011\/pexels-photo-813011.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940\" width=\"60%\">\n<center>\n<a href=\"https:\/\/www.pexels.com\/photo\/white-cruise-ship-813011\/\">Photo by Matthew Barra from Pexels<\/a>\n<\/center>\n\n# Plan of Action\n\n[1. Data pre-processing](#1)\n\n[2. Plots and Charts](#2)\n\n[3. Feature engineering](#3)\n\n[4. Modeling](#h20)\n\n[5. Evaluation](#4)\n\n[6. Submission & References](#5)","c7dd8545":"### Sample data","cb87a876":"<a id=\"3\"><\/a>\n# Feature Engineering","647a3e0f":"### Pie charts","e7ab2294":"### Fare\n#### Filling missing values of fare with the median fare","089b5201":"### Importing python libraries","08dbb09e":"<a id=\"2\"><\/a>\n# Plots and charts","b7b66cfa":"### Load the data into memory","aff3c458":"#### Extracting new features `Name_length`, `Word_count` and `Title` from `Name`","be6ea51b":"### Cabin\n\n#### Create a new feature `Has_cabin` and Drop Cabin feature since it has 77% of missing values","2dc69c2d":"### Variable separation","b46fdb9d":"### Label encoding the categorical features","6c1ae83c":"### Continuous columns distribution","326f2e6f":"#### Extracting a new feature `Ticket_type` from `Ticket`","251ea6ab":"### Age\n#### Filling missing values in age using the median age for each gender within each passenger class as a proxy.","b748224e":"## Handling Missing values","8f5f2e5d":"<a id=\"h20\"><\/a>\n# Modeling\n","a774f8c7":"### Target distribution","c06ce00f":"<a id=\"1\"><\/a>\n# Data pre-processing\n\n### Columns\n<table align=\"left\" style=\"font-size:15px;\">\n<tbody>\n<tr><th><b>Variable<\/b><\/th><th><b>Definition<\/b><\/th><th><b>Key<\/b><\/th><\/tr>\n<tr>\n<td>PassengerId<\/td>\n<td>Unique Id of passenger<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>Survived<\/td>\n<td>Survival<\/td>\n<td>0 = No, 1 = Yes<\/td>\n<\/tr>\n<tr>\n<td>pclass<\/td>\n<td>Ticket class<\/td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd<\/td>\n<\/tr>\n<tr>\n<td>Name<\/td>\n<td>Name of passenger<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>sex<\/td>\n<td>Sex<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>Age<\/td>\n<td>Age in years<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>sibsp<\/td>\n<td># of siblings \/ spouses aboard the Titanic<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>parch<\/td>\n<td># of parents \/ children aboard the Titanic<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>ticket<\/td>\n<td>Ticket number<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>fare<\/td>\n<td>Passenger fare<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>cabin<\/td>\n<td>Cabin number<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>embarked<\/td>\n<td>Port of Embarkation<\/td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton<\/td>\n<\/tr>\n<\/tbody>\n<\/table>","7e5d74cf":"<a id=\"5\"><\/a>\n# References\nFeature engineering :  https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions <br>\nModeling :  https:\/\/thecleverprogrammer.com\/2020\/08\/01\/automate-machine-learning-with-h2o-automl\/","e6085a52":"### Embarked\n#### Filling missing values of Embarked column with the most frequent label","de7aa27d":"## Submission"}}