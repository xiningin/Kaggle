{"cell_type":{"c5f4d30a":"code","105ac69b":"code","4659d8a2":"code","f37f7f18":"code","796ae421":"code","bd14a1d5":"code","7555ffcf":"code","f274ca0a":"code","99e9e671":"code","f377f9a0":"code","f631aa59":"code","db61cd63":"code","4eea820c":"code","c6ae5459":"code","de0f2238":"code","ea594433":"code","1ef752b8":"code","20a4aed1":"code","701c2ea4":"code","9008d75d":"code","5bbdcbab":"code","5b6e7fe4":"code","1e393956":"code","25f4bace":"code","a64f9636":"markdown","ab6a5144":"markdown","cda277f8":"markdown","6823b305":"markdown","ecb8efce":"markdown","21ab43b4":"markdown","ad05b93d":"markdown","41021d72":"markdown","23d0dba8":"markdown","8c6b40e2":"markdown","8246cf22":"markdown","581f25d4":"markdown","077fe5d5":"markdown","ba897969":"markdown","16a1e7b5":"markdown","1765dde9":"markdown","753a6519":"markdown","c24be0d6":"markdown","b577ac59":"markdown","3205c7e8":"markdown","887d06b9":"markdown","0f77b822":"markdown"},"source":{"c5f4d30a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, AvgPool2D, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom sklearn.model_selection import train_test_split","105ac69b":"!pip install split-folders","4659d8a2":"import os\nimport shutil\nimport splitfolders\nfrom distutils.file_util import copy_file\n\n\nshutil.os.mkdir('.\/train')\nshutil.os.mkdir('.\/train\/Tuberculosis')\nshutil.os.mkdir('.\/train\/False')\nshutil.os.mkdir('.\/test')\nshutil.os.mkdir('.\/test\/Tuberculosis')\nshutil.os.mkdir('.\/test\/False')\n\ndf = pd.read_csv('..\/input\/chest-xrays-tuberculosis-from-india\/jaypee_metadata.csv')\ntuberculosis_true = df[df['findings'] == 'Tuberculosis']\ntuberculosis_false = df[df['findings'] == 'False']\n\nsrc_directory = '..\/input\/chest-xrays-tuberculosis-from-india\/images\/images\/'\ndst_directory_train_true = '.\/train\/Tuberculosis'\ndst_directory_train_false = '.\/train\/False'\ndst_directory_test_true = '.\/test\/Tuberculosis'\ndst_directory_test_false = '.\/test\/False'\n\nfor image in tuberculosis_true['study_id'].to_list():\n    if 'TRAIN' in image:\n        copy_file(src_directory + image, dst_directory_train_true)\n    elif 'TEST' in image:\n        copy_file(src_directory + image, dst_directory_test_true)\n        \nfor image in tuberculosis_false['study_id'].to_list():\n    if 'TRAIN' in image:\n        copy_file(src_directory + image, dst_directory_train_false)\n    elif 'TEST' in image:\n        copy_file(src_directory + image, dst_directory_test_false)\n        \n\nsplitfolders.ratio(\".\/train\", output = \".\/train_and_val\", seed = 823, ratio = (.8, .2))\n\ntrain_path = '.\/train_and_val\/train'\nval_path = '.\/train_and_val\/val'\ntest_path = '.\/test'","f37f7f18":"datagen_train = ImageDataGenerator(rescale = 1.\/255, #1\/255 to scale\/normalize the pixel values\n                                   shear_range = 0.2, #shear intensity\n                                   rotation_range = 5, #random rotation (0 to 100 degrees)\n                                   zoom_range = 0.2, #random zooming\n                                   width_shift_range=0.1,  #random horizontal shifting\n                                   height_shift_range=0.1)  #random vertical shifting \n                                   #horizontal_flip=True  #random horizontal flipping\n                                   #vertical_flip=True)  #random vertical flipping)\n\ntraining_set = datagen_train.flow_from_directory(train_path,\n                                                 target_size = (256, 256),\n                                                 batch_size = 32,\n                                                 shuffle = True,\n                                                 seed = 823,\n                                                 color_mode = 'grayscale',\n                                                 class_mode = 'binary')","796ae421":"datagen_val = ImageDataGenerator(rescale = 1.\/255)\nval_set = datagen_val.flow_from_directory(val_path,\n                                            target_size = (256, 256),\n                                            batch_size = 32,\n                                            shuffle = True,\n                                            seed = 823,\n                                            color_mode = 'grayscale',\n                                            class_mode = 'binary')","bd14a1d5":"datagen_test = ImageDataGenerator(rescale = 1.\/255)\ntest_set = datagen_test.flow_from_directory(test_path,\n                                            target_size = (256, 256),\n                                            batch_size = 1,\n                                            shuffle = False,\n                                            seed = 823,\n                                            color_mode = 'grayscale',\n                                            class_mode = 'binary')","7555ffcf":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(30, 10))\nimg_tb1 = load_img(train_path + '\/Tuberculosis\/TRAIN_px52.jpg')\nimg_tb2 = load_img(train_path + '\/Tuberculosis\/TRAIN_px6.jpg')\nimg_tb3 = load_img(train_path + '\/Tuberculosis\/TRAIN_px7.jpg')\nimg_tb4 = load_img(train_path + '\/Tuberculosis\/TRAIN_px8.jpg')\nimg_tb5 = load_img(train_path + '\/Tuberculosis\/TRAIN_px9.jpg')\n\nax1.imshow(img_tb1)\nax2.imshow(img_tb2)\nax3.imshow(img_tb3)\nax4.imshow(img_tb4)\nax5.imshow(img_tb5)\n\nprint(\"Chest X-Rays diagnosed with Tuberculosis\")\nplt.show()","f274ca0a":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(30, 10))\nimg_ntb1 = load_img(train_path + '\/False\/TRAIN_nx51.jpg')\nimg_ntb2 = load_img(train_path + '\/False\/TRAIN_nx6.jpg')\nimg_ntb3 = load_img(train_path + '\/False\/TRAIN_nx7.jpg')\nimg_ntb4 = load_img(train_path + '\/False\/TRAIN_nx8.jpg')\nimg_ntb5 = load_img(train_path + '\/False\/TRAIN_nx9.jpg')\n\nax1.imshow(img_ntb1)\nax2.imshow(img_ntb2)\nax3.imshow(img_ntb3)\nax4.imshow(img_ntb4)\nax5.imshow(img_ntb5)\n\nprint(\"Normal Chest X-Rays\")\nplt.show()","99e9e671":"np.random.seed(823)\ntf.random.set_seed(188)\n\n#Initialize\ncnn = tf.keras.models.Sequential()\n\n#Convolutional Layers\ncnn.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[256,256,1]))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Conv2D(filters = 32, kernel_size=3, activation='relu'))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Conv2D(filters = 64, kernel_size=3, activation='relu'))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Conv2D(filters = 64, kernel_size=3, activation='relu'))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Conv2D(filters = 128, kernel_size=3, activation='relu'))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(Conv2D(filters = 128, kernel_size=3, activation='relu'))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\n\n#Flatten Layer\ncnn.add(Flatten())\n\n#Full Connection\ncnn.add(Dense(units = 256, activation='relu'))\ncnn.add(Dropout(0.15))\n\n#Output Layer\ncnn.add(Dense(units=1, activation='sigmoid'))\n\n#Compile\ncnn.compile(optimizer = 'adam', \n            loss = 'binary_crossentropy', \n            metrics = ['accuracy'])\n\n#Callback\nlrreduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience = 10, \n                                            verbose = 1, \n                                            factor = 0.5, \n                                            min_lr = 0.0001)\n\nearlystop = EarlyStopping(monitor='accuracy', \n                          patience = 10,\n                          min_delta = 0.0002,\n                          verbose = 1,\n                          restore_best_weights = False)\n\n#Summary\ncnn.summary()","f377f9a0":"cnn.fit(x = training_set, \n        validation_data = val_set, \n        epochs = 200,\n        callbacks = [earlystop],\n        shuffle = False)","f631aa59":"cnn_lossacc = pd.DataFrame(cnn.history.history)\nplt.rcParams['figure.figsize'] = (12, 8)\nsns.set_style('whitegrid')\ncnn_lossacc.plot()","db61cd63":"test_set.reset()\npredictions_test = (cnn.predict(test_set,verbose=True) > 0.5).astype(\"int32\")","4eea820c":"print('Testing Accuracy: ',(cnn.evaluate(test_set))[1]*100, '%')","c6ae5459":"labels = (training_set.class_indices)\nlabels = dict((i,j) for j,i in labels.items())\nprint(labels)","de0f2238":"from sklearn.metrics import classification_report,confusion_matrix\ny_true = np.array([0] * 26 + [1] * 26) #26 Normal, #26 TB\ndata = confusion_matrix(y_true, predictions_test)\ndf_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\ndf_cm.index.name = 'Predicted'\ndf_cm.columns.name = 'Actual'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.5)\nax = sns.heatmap(df_cm,cmap = 'Purples', annot=True,fmt = '.5g',annot_kws={\"size\": 16})# font size\nax.set_title('Confusion Matrix')\nax.xaxis.set_ticklabels(['False', 'Tuberculosis']); ax.yaxis.set_ticklabels(['False', 'Tuberculosis']);\n#For cmaps:\n#https:\/\/matplotlib.org\/3.1.1\/gallery\/color\/colormap_reference.html\nprint(\"Classification Report: \")\nprint(classification_report(y_true,predictions_test))","ea594433":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input","1ef752b8":"train_datagen = ImageDataGenerator(shear_range = 0.2,\n                                   rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n                                   zoom_range = 0.1, # Randomly zoom image \n                                   width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                                   height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n                                   preprocessing_function = preprocess_input) #to be consistent to how the resnet model was created. This is why there is no need to specify 1.\/255\ntraining_set = train_datagen.flow_from_directory(train_path,\n                                                 target_size = (300, 300),\n                                                 batch_size = 32,\n                                                 shuffle = True,\n                                                 seed = 823,\n                                                 color_mode = 'rgb',\n                                                 class_mode = 'binary')","20a4aed1":"datagen_val = ImageDataGenerator(preprocessing_function = preprocess_input)\nval_set = datagen_val.flow_from_directory(val_path,\n                                            target_size = (300, 300),\n                                            batch_size = 32,\n                                            shuffle = True,\n                                            seed = 823,\n                                            color_mode = 'rgb',\n                                            class_mode = 'binary')","701c2ea4":"datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\ntest_set = datagen_test.flow_from_directory(test_path,\n                                            target_size = (300, 300),\n                                            batch_size = 1,\n                                            shuffle = False,\n                                            seed = 823,\n                                            color_mode = 'rgb',\n                                            class_mode = 'binary')","9008d75d":"pretrainedlayer = ResNet50(weights = 'imagenet', \n                           include_top = False, #To exclude the last layer\n                           pooling = 'avg',  #Global average pooling\n                           input_shape = (300, 300, 3))\n\n# Freeze all the layers\nfor layer in pretrainedlayer.layers[:]:\n    layer.trainable = False\n# Check the trainable status of the individual layers\nfor layer in pretrainedlayer.layers:\n    print(layer, layer.trainable)","5bbdcbab":"new_cnn = Sequential()\nnew_cnn.add(pretrainedlayer) #Add the resnet50\nnew_cnn.add(Flatten())\nnew_cnn.add(Dense(1024, activation='relu'))\nnew_cnn.add(Dropout(0.2))\nnew_cnn.add(Dense(1, activation = 'sigmoid')) #1 neuron, sigmoid activation for binary classification\nnew_cnn.summary()\n\nlrreduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=10, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\nearlystop = EarlyStopping(monitor='accuracy', \n                          patience = 5,\n                          min_delta = 0.002,\n                          verbose = 1,\n                          restore_best_weights = False)","5b6e7fe4":"#Compile Model\nnew_cnn.compile(optimizer='adam', \n                     loss='binary_crossentropy', \n                     metrics=['accuracy'])\n\nnew_cnn.fit(\n      training_set,\n      epochs = 50,\n      validation_data = val_set,\n      callbacks = [lrreduction,earlystop],\n      verbose=1)","1e393956":"new_cnn_lossacc = pd.DataFrame(new_cnn.history.history)\nplt.rcParams['figure.figsize'] = (12, 8)\nsns.set_style('whitegrid')\nnew_cnn_lossacc.plot()","25f4bace":"print('Testing Accuracy: ',(new_cnn.evaluate(test_set))[1]*100, '%')","a64f9636":"##### See the Labels","ab6a5144":"### Validation Set Processing","cda277f8":"### Model Loss & Accuracy Plot","6823b305":"## CNN from Scratch","ecb8efce":"### Validation Set","21ab43b4":"### Training Proper","ad05b93d":"## Image Data Preprocessing","41021d72":"### Test Set Processing","23d0dba8":"## Importing Libraries","8c6b40e2":"### Training Set Processing","8246cf22":"##### Data Augmentation with preprocessing input of the specified keras application. We then specify the training set, validation set and test set once again.","581f25d4":"### Model Evaluation","077fe5d5":"##### *We arrange the folders first in a manner that can be understood in our chosen method (flow_from_directory of ImageDataGenerator Class from tf.keras)*","ba897969":"### Classification Report and Confusion Matrix","16a1e7b5":"### Test Set","1765dde9":"### Training Set","753a6519":"##### Train the CNN and evaluate using the Validation Set","c24be0d6":"##### Quick Peek at Accuracy on Test Set","b577ac59":"### Some X-Ray Images","3205c7e8":"## Transfer Learning","887d06b9":"##### Create the new model by adding the Keras Application Object as the first layer and the replacement output layers","0f77b822":"### Model Summary"}}