{"cell_type":{"a0545219":"code","dccfaa3e":"code","8cdce6eb":"code","b18939f4":"code","02e37e76":"code","4ac1c53e":"code","c3b7511d":"code","97b1dc2d":"code","92a7edc9":"code","fe9561f2":"code","670822e9":"code","97cbcff3":"code","d89cb7f8":"code","4f577e3b":"code","9e80e1a2":"code","0e75582f":"code","3e8abbc7":"code","a51e7e6b":"code","29106143":"code","7879903b":"code","acdd1fdc":"code","96c60b69":"code","9fc9ce05":"code","7aef1fdc":"code","a25dec1e":"code","b4c1733d":"code","a76530e9":"code","fef40658":"code","80735fa7":"code","9f66110b":"code","c1e23bda":"code","137c7e1c":"code","865c1847":"code","b775e09d":"code","2e455870":"code","4c1373e5":"code","7e3ea2b9":"code","96be85f4":"code","5c2b0155":"code","060fd2f2":"code","88e5fdfd":"code","ba11525e":"code","cf1c60b9":"code","60a967db":"code","236c0471":"code","a3ffc7ea":"code","cf8a1e57":"code","cf0a5542":"code","67282ac1":"code","23c6e11a":"code","037d2b2d":"code","f7d6f94f":"code","93551c21":"code","4363f9bd":"code","cd7cb28e":"code","568f2b0c":"code","ccc513d4":"code","5bdd2811":"code","d571399a":"code","40e1470e":"code","614eb26f":"code","04521912":"code","1d5afc8b":"code","40759bc7":"code","3c8a16ad":"code","f0dc5243":"code","f92f34a6":"code","05e86895":"code","d9553f51":"code","44db3910":"code","d9444cc9":"code","a5d62761":"code","3efdf2d7":"code","1c611d57":"code","0772e762":"code","38b8188e":"code","595a71ee":"markdown","8c5064e9":"markdown","a86aa496":"markdown","2ca84d85":"markdown","c2dd6def":"markdown","cfc756f5":"markdown"},"source":{"a0545219":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import OrderedDict\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","dccfaa3e":"data = pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")","8cdce6eb":"'''EDA'''\n#check top 5 rows\ndata.head()","b18939f4":"data.info()","02e37e76":"#first removing features which are irrelevant for our prediction\ndata.drop(['imdb_id','poster_path'],axis=1,inplace=True)\ntest.drop(['imdb_id','poster_path'],axis=1,inplace=True)","4ac1c53e":"#we have a lot of null values for homepage\n#Converting homepage as binary\ndata['has_homepage'] = 0\ndata.loc[data['homepage'].isnull() == False, 'has_homepage'] = 1\ntest['has_homepage'] = 0\ntest.loc[test['homepage'].isnull() == False, 'has_homepage'] = 1\n\n#Homepage v\/s Revenue\nsns.catplot(x='has_homepage', y='revenue', data=data);\nplt.title('Revenue for film with and without homepage');\n","c3b7511d":"data=data.drop(['homepage'],axis =1)\ntest=test.drop(['homepage'],axis =1)","97b1dc2d":"\n#Converting collections as binary\ndata['collection'] = 0\ndata.loc[data['belongs_to_collection'].isnull() == False, 'collection'] = 1\ntest['collection'] = 0\ntest.loc[test['belongs_to_collection'].isnull() == False, 'collection'] = 1\n\n#collections v\/s Revenue\nsns.catplot(x='collection', y='revenue', data=data);\nplt.title('Revenue for film with and without collection');\n","92a7edc9":"#Collection too increaes the revenue\ndata=data.drop(['belongs_to_collection'],axis =1)\ntest=test.drop(['belongs_to_collection'],axis =1)","fe9561f2":"#Exploring Genres\ngenres = {}\nfor i in data['genres']:\n    if(not(pd.isnull(i))):\n        if (eval(i)[0]['name']) not in genres:\n            genres[eval(i)[0]['name']]=1\n        else:\n                genres[eval(i)[0]['name']]+=1\n                \nplt.figure(figsize = (12, 8))\n#text = ' '.join([i for j in genres for i in j])\nwordcloud = WordCloud(background_color=\"white\",width=1000,height=1000, max_words=10,relative_scaling=0.5,normalize_plurals=False).generate_from_frequencies(genres)\n\nplt.imshow(wordcloud)\nplt.title('Top genres')\nplt.axis(\"off\")\nplt.show()\ngenres = OrderedDict(genres)\n#Drama, Comedy and Thriller are popular genres\nOrderedDict(sorted(genres.items(), key=lambda t: t[1]))","670822e9":"#adding number of genres for each movie\ngenres_count=[]\nfor i in data['genres']:\n    if(not(pd.isnull(i))):\n        \n        genres_count.append(len(eval(i)))\n        \n    else:\n        genres_count.append(0)\ndata['num_genres'] = genres_count","97cbcff3":"#Genres v\/s revenue\nsns.catplot(x='num_genres', y='revenue', data=data);\nplt.title('Revenue for different number of genres in the film');","d89cb7f8":"#Adding genres count for test data\ngenres_count_test=[]\nfor i in test['genres']:\n    if(not(pd.isnull(i))):\n        \n        genres_count_test.append(len(eval(i)))\n        \n    else:\n        genres_count_test.append(0)\ntest['num_genres'] = genres_count_test","4f577e3b":"#Dropping genres\ndata.drop(['genres'],axis=1, inplace = True)\ntest.drop(['genres'],axis=1, inplace = True)","9e80e1a2":"#Production companies\n#Adding production_companies count for  data\nprod_comp_count=[]\nfor i in data['production_companies']:\n    if(not(pd.isnull(i))):\n        \n        prod_comp_count.append(len(eval(i)))\n        \n    else:\n        prod_comp_count.append(0)\ndata['num_prod_companies'] = prod_comp_count","0e75582f":"#number of prod companies vs revenue\nsns.catplot(x='num_prod_companies', y='revenue', data=data);\nplt.title('Revenue for different number of production companies in the film');","3e8abbc7":"#Adding production_companies count for  test data\nprod_comp_count_test=[]\nfor i in test['production_companies']:\n    if(not(pd.isnull(i))):\n        \n        prod_comp_count_test.append(len(eval(i)))\n        \n    else:\n        prod_comp_count_test.append(0)\ntest['num_prod_companies'] = prod_comp_count_test","a51e7e6b":"#number of prod companies vs revenue\nsns.catplot(x='num_prod_companies', y='revenue', data=data);\nplt.title('Revenue for different number of production companies in the film');","29106143":"#Dropping production_companies\ndata.drop(['production_companies'],axis=1, inplace = True)\ntest.drop(['production_companies'],axis=1, inplace = True)","7879903b":"#production_countries\n#Adding production_countries count for  data\nprod_coun_count=[]\nfor i in data['production_countries']:\n    if(not(pd.isnull(i))):\n        \n        prod_coun_count.append(len(eval(i)))\n        \n    else:\n        prod_coun_count.append(0)\ndata['num_prod_countries'] = prod_coun_count","acdd1fdc":"#number of prod countries vs revenue\nsns.catplot(x='num_prod_countries', y='revenue', data=data);\nplt.title('Revenue for different number of production countries in the film');","96c60b69":"#Adding production_countries count for  test data\nprod_coun_count_test=[]\nfor i in test['production_countries']:\n    if(not(pd.isnull(i))):\n        \n        prod_coun_count_test.append(len(eval(i)))\n        \n    else:\n        prod_coun_count_test.append(0)\ntest['num_prod_countries'] = prod_coun_count_test","9fc9ce05":"#Dropping production_countries\ndata.drop(['production_countries'],axis=1, inplace = True)\ntest.drop(['production_countries'],axis=1, inplace = True)","7aef1fdc":"#handling overview\n#mapping overview present to 1 and nulls to 0\ndata['overview']=data['overview'].apply(lambda x: 0 if pd.isnull(x) else 1)\ntest['overview']=test['overview'].apply(lambda x: 0 if pd.isnull(x) else 1)\nsns.catplot(x='overview', y='revenue', data=data);\nplt.title('Revenue for film with and without overview');","a25dec1e":"data= data.drop(['overview'],axis=1)\ntest= test.drop(['overview'],axis=1)","b4c1733d":"#cast\n#Adding cast count for  data\ntotal_cast=[]\nfor i in data['cast']:\n    if(not(pd.isnull(i))):\n        \n        total_cast.append(len(eval(i)))\n        \n    else:\n        total_cast.append(0)\ndata['cast_count'] = total_cast","a76530e9":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(data['cast_count'], data['revenue'])\nplt.title('Number of cast members vs revenue');","fef40658":"#cast\n#Adding cast count for  test data\ntotal_cast=[]\nfor i in test['cast']:\n    if(not(pd.isnull(i))):\n        \n        total_cast.append(len(eval(i)))\n        \n    else:\n        total_cast.append(0)\ntest['cast_count'] = total_cast","80735fa7":"#Dropping cast\ndata= data.drop(['cast'],axis=1)\ntest= test.drop(['cast'],axis=1)","9f66110b":"#crew\ntotal_crew=[]\nfor i in data['crew']:\n    if(not(pd.isnull(i))):\n        \n        total_crew.append(len(eval(i)))\n        \n    else:\n        total_crew.append(0)\ndata['crew_count'] = total_crew","c1e23bda":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(data['crew_count'], data['revenue'])\nplt.title('Number of crew members vs revenue');","137c7e1c":"#Adding crew count for  test data\ntotal_crew=[]\nfor i in test['crew']:\n    if(not(pd.isnull(i))):\n        \n        total_crew.append(len(eval(i)))\n        \n    else:\n        total_crew.append(0)\ntest['crew_count'] = total_crew","865c1847":"#Dropping crew\ndata= data.drop(['crew'],axis=1)\ntest= test.drop(['crew'],axis=1)","b775e09d":"#Dropping original_title\ndata= data.drop(['original_title'],axis=1)\ntest= test.drop(['original_title'],axis=1)","2e455870":"#How language contributes to revenue\nplt.figure(figsize=(15,11)) #figure size\n\n#It's another way to plot our data. using a variable that contains the plot parameters\ng1 = sns.boxenplot(x='original_language', y='revenue', \n                   data=data[(data['original_language'].isin((data['original_language'].sort_values().value_counts()[:10].index.values)))])\ng1.set_title(\"Revenue by language\", fontsize=20) # title and fontsize\ng1.set_xticklabels(g1.get_xticklabels(),rotation=45) # It's the way to rotate the xticks when we use variable to our graphs\ng1.set_xlabel('Language', fontsize=18) # Xlabel\ng1.set_ylabel('Revenue', fontsize=18) #Ylabel\n\nplt.show()","4c1373e5":"#Taking only en and zh into consideration as they are the highest grossing\ndata['original_language'] =data['original_language'].apply(lambda x: 1 if x=='en' else(2 if x=='zh' else 0))\ntest['original_language'] =test['original_language'].apply(lambda x: 1 if x=='en' else(2 if x=='zh' else 0))","7e3ea2b9":"#check correlation between variables\ncol = ['revenue','budget','popularity','runtime']\n\nplt.subplots(figsize=(10, 8))\n\ncorr = data[col].corr()\n\nsns.heatmap(corr, xticklabels=col,yticklabels=col, linewidths=.5, cmap=\"Reds\")","96be85f4":"#budget and revenue are highly correlated\nsns.regplot(x=\"budget\", y=\"revenue\", data=data)","5c2b0155":"#Check how revenue depends of day\ndata['release_date']=pd.to_datetime(data['release_date'])\ntest['release_date']=pd.to_datetime(data['release_date'])\n","060fd2f2":"release_day = data['release_date'].value_counts().sort_index()\nrelease_day_revenue= data.groupby(['release_date'])['revenue'].sum()\nrelease_day_revenue.index=release_day_revenue.index.dayofweek\nsns.barplot(release_day_revenue.index,release_day_revenue, data = data,ci=None)\nplt.show()","88e5fdfd":"#adding day feature to the data\n\ndata['release_day']=data['release_date'].dt.dayofweek \ntest['release_day']=test['release_date'].dt.dayofweek ","ba11525e":"#filling nulls in test\ntest['release_day']=test['release_day'].fillna(0)","cf1c60b9":"data.drop(['release_date'],axis=1,inplace=True)\ntest.drop(['release_date'],axis=1,inplace=True)","60a967db":"#status\nprint(\"train data\")\nprint(data['status'].value_counts())\nprint(\"test data\")\ntest['status'].value_counts()\n","236c0471":"#Feature is irrelevant hence dropping\ndata.drop(['status'],axis=1,inplace =True)\ntest.drop(['status'],axis=1,inplace =True)","a3ffc7ea":"#keywords\nKeywords_count=[]\nfor i in data['Keywords']:\n    if(not(pd.isnull(i))):\n        \n        Keywords_count.append(len(eval(i)))\n        \n    else:\n        Keywords_count.append(0)\ndata['Keywords_count'] = Keywords_count","cf8a1e57":"#number of prod countries vs revenue\nsns.catplot(x='Keywords_count', y='revenue', data=data);\nplt.title('Revenue for different number of Keywords in the film');","cf0a5542":"Keywords_count=[]\nfor i in test['Keywords']:\n    if(not(pd.isnull(i))):\n        \n        Keywords_count.append(len(eval(i)))\n        \n    else:\n        Keywords_count.append(0)\ntest['Keywords_count'] = Keywords_count","67282ac1":"#Dropping title and keywords\ndata=data.drop(['Keywords'],axis=1)\ndata=data.drop(['title'],axis=1)\ntest=test.drop(['Keywords'],axis=1)\ntest=test.drop(['title'],axis=1)","23c6e11a":"#tagline\ndata['isTaglineNA'] = 0\ndata.loc[data['tagline'].isnull() == False, 'isTaglineNA'] = 1\ntest['isTaglineNA'] = 0\ntest.loc[test['tagline'].isnull() == False, 'isTaglineNA'] = 1\n\n#Homepage v\/s Revenue\nsns.catplot(x='isTaglineNA', y='revenue', data=data);\nplt.title('Revenue for film with and without tagline');\n","037d2b2d":"data.drop(['tagline'],axis=1,inplace =True)\ntest.drop(['tagline'],axis=1,inplace =True)","f7d6f94f":"#runtime has 2 nulls; setting it to the mean\n#filling nulls in test\ndata['runtime']=data['runtime'].fillna(data['runtime'].mean())\ntest['runtime']=test['runtime'].fillna(test['runtime'].mean())","93551c21":"#spoken languages\n#adding number of spoken languages for each movie\nspoken_count=[]\nfor i in data['spoken_languages']:\n    if(not(pd.isnull(i))):\n        \n        spoken_count.append(len(eval(i)))\n        \n    else:\n        spoken_count.append(0)\ndata['spoken_count'] = spoken_count\n\n\nspoken_count_test=[]\nfor i in test['spoken_languages']:\n    if(not(pd.isnull(i))):\n        \n        spoken_count_test.append(len(eval(i)))\n        \n    else:\n        spoken_count_test.append(0)\ntest['spoken_count'] = spoken_count_test","4363f9bd":"#dropping spoken_languages\ndata.drop(['spoken_languages'],axis=1,inplace=True)\ntest.drop(['spoken_languages'],axis=1,inplace=True)","cd7cb28e":"data.info()","568f2b0c":"data.head()","ccc513d4":"data['budget'] = np.log1p(data['budget'])\ntest['budget'] = np.log1p(test['budget'])","5bdd2811":"#normalizing budget\n#a, b = 1, 100\n#m, n = data.budget.min(), data.budget.max()\n#data['budget'] = (data.budget - m) \/ (n - m) * (b - a) + a","d571399a":"y= data['revenue'].values\ncols = [col for col in data.columns if col not in ['revenue', 'id']]\nX= data[cols].values\ny = np.log1p(y)","40e1470e":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()\nscores = cross_val_score(clf, X, y, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores.mean())","614eb26f":"from sklearn.ensemble import RandomForestRegressor\nregr = RandomForestRegressor(max_depth=10, min_samples_split=5, random_state=0,\n                             n_estimators=500)\nscores = cross_val_score(regr, X, y, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores.mean())","04521912":"cols = [col for col in test.columns if col not in ['id']]\nX_test= test[cols].values\n","1d5afc8b":"regr.fit(X,y)\ny_pred = regr.predict(X_test)\n","40759bc7":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_RF.csv', index=False)","3c8a16ad":"import xgboost as xgb\nimport lightgbm as lgb","f0dc5243":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","f92f34a6":"params = {'num_leaves': 30,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\n\nlgb_model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\nlgb_model.fit(X_train, y_train, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)\n\n","05e86895":"data.head()","d9553f51":"lgb_model.fit(X, y, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)\ny_pred=lgb_model.predict(X_test)\n","44db3910":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_LGB.csv', index=False)","d9444cc9":"\nxgb_params = {'eta': 0.01,\n              'objective': 'reg:linear',\n              'max_depth': 7,\n              'subsample': 0.8,\n              'colsample_bytree': 0.8,\n              'eval_metric': 'rmse',\n              'seed': 11,\n              'silent': True}\nxgb_model = xgb.XGBRegressor(**xgb_params, n_estimators = 20000, \n                             nthread = 4, n_jobs = -1)\n","a5d62761":"\nxgb_model.fit(X, y, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)","3efdf2d7":"y_pred = xgb_model.predict(X_test)","1c611d57":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_XGB.csv', index=False)","0772e762":"from sklearn.ensemble import GradientBoostingRegressor\n\nmodel_gboost = GradientBoostingRegressor()\n\nmodel_gboost.fit(X_train, y_train)\ny_pred = model_gboost.predict(X_test)","38b8188e":"y_pred=np.expm1(y_pred)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission_GradientBoosting.csv', index=False)","595a71ee":"Model 2 - Random forest regression","8c5064e9":"Testing the model","a86aa496":"XGB ","2ca84d85":"model 1 - linear Regression","c2dd6def":"Traning the model\n","cfc756f5":"Traing with XGboost and LGB"}}