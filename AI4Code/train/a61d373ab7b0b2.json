{"cell_type":{"ec8d3d1c":"code","ce2f22ee":"code","bbc48720":"code","7ba1f598":"code","e4902a7e":"code","1c39e168":"code","f6533399":"code","2c6599c8":"code","45ad4041":"code","11b45a63":"code","4f6ac3f6":"code","6e5e2d37":"code","7ce3bd47":"code","88d8dec8":"code","45888fc5":"code","1539565f":"code","c65cb5a6":"code","7ae15634":"code","290cb5e9":"markdown","bff6056d":"markdown","f21b15e3":"markdown","286ad271":"markdown","a51ebce1":"markdown","d06543bf":"markdown","8b6e0688":"markdown","09dd7714":"markdown","2d33e3f4":"markdown","2592e999":"markdown","03beb2d6":"markdown","5a85503e":"markdown","117caeb0":"markdown","044a4509":"markdown","aee4d5c1":"markdown"},"source":{"ec8d3d1c":"from time import time\n\nnotebook_start_time = time()\n\n#Only Uncomment When Committing","ce2f22ee":"tr_dir_base = \"\/kaggle\/input\/labeled-chest-xray-images\/chest_xray\/train\/\"\nts_dir_base = \"\/kaggle\/input\/labeled-chest-xray-images\/chest_xray\/test\/\"\n\ntr_dir_normal = tr_dir_base + \"NORMAL\/\"\nts_dir_normal = ts_dir_base + \"NORMAL\/\"\n\ntr_dir_pnemon = tr_dir_base + \"PNEUMONIA\/\"\nts_dir_pnemon = ts_dir_base + \"PNEUMONIA\/\"","bbc48720":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport matplotlib.image as img\nfrom PIL import Image\nimport cv2\n\nimport torch\nfrom torch import optim, nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader as DL\nfrom torch.nn.utils import weight_norm as WN\nimport torch.optim.lr_scheduler as LR\nimport torch.nn.functional as F\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score, log_loss, f1_score\nfrom sklearn.model_selection import KFold\n\nimport random as r\nimport os\nfrom time import time\n\nMAX_VALUE = 255","7ba1f598":"def breaker():\n    print(\"\\n\" + 30*\"-\" + \"\\n\")\n    \ndef head(x, no_of_ele=5):\n    breaker()\n    print(x[:no_of_ele])\n    breaker()\n\ndef getFileNames(root_dir=None):\n    f_name = []\n    for dirname, _, filenames in os.walk(root_dir):\n        for filename in filenames:\n            f_name.append(filename)\n    return f_name\n\ndef removeChannelInfo(file_path=None, file_names=None, size=None):\n    sizes = []\n    images = []\n    for name in file_names:\n        image = cv2.imread(file_path+name)\n        if len(image.shape) > 2:\n            image = image[:, :, -1]\n        sizes.append(image.shape)\n        images.append(cv2.resize(image, dsize=(size, size), interpolation=cv2.INTER_LANCZOS4))\n    return images, sizes","e4902a7e":"tr_normal_file_names = getFileNames(tr_dir_normal)\ntr_pnemon_file_names = getFileNames(tr_dir_pnemon)\nts_normal_file_names = getFileNames(ts_dir_normal)\nts_pnemon_file_names = getFileNames(ts_dir_pnemon)","1c39e168":"breaker()\nprint(\"Total Training Set Size        :\", repr(len(tr_normal_file_names) + len(tr_pnemon_file_names)))\nbreaker()\nprint(\"Total Test Set Size            :\", repr(len(ts_normal_file_names) + len(ts_pnemon_file_names)))\nbreaker()","f6533399":"start_time = time()\n\nn_size = 127\ntrn_images, trn_sizes = removeChannelInfo(tr_dir_normal, tr_normal_file_names, n_size)\ntrp_images, trp_sizes = removeChannelInfo(tr_dir_pnemon, tr_pnemon_file_names, n_size)\n\ntsn_images, tsn_sizes = removeChannelInfo(ts_dir_normal, ts_normal_file_names, n_size)\ntsp_images, tsp_sizes = removeChannelInfo(ts_dir_pnemon, ts_pnemon_file_names, n_size)\n\nprint(\"Time Taken to process data : {:.2f} minutes\".format((time()-start_time)\/60))","2c6599c8":"tr_images = np.concatenate((trn_images, trp_images), axis=0)\ntr_images = np.divide(tr_images, MAX_VALUE)\ntr_labels = np.concatenate((np.zeros((len(trn_images))), np.ones((len(trp_images)))), axis=0)\n\nprint(tr_images.shape)\nprint(tr_labels.shape)","45ad4041":"ts_images = np.concatenate((tsn_images, tsp_images), axis=0)\nts_images = np.divide(ts_images, MAX_VALUE)\nts_labels = np.concatenate((np.zeros((len(tsn_images))), np.ones((len(tsp_images)))), axis=0)\n\nprint(ts_images.shape)\nprint(ts_labels.shape)\n\nnum_obs_test = ts_labels.shape[0]","11b45a63":"class DS(Dataset):\n    def __init__(this, X=None, y=None, mode=\"train\"):\n        this.mode = mode\n        this.X = X\n        if mode == \"train\":\n            this.y = y\n        \n    def __len__(this):\n        return this.X.shape[0]\n    \n    def __getitem__(this, idx):\n        if this.mode == \"train\":\n            return torch.FloatTensor(this.X[idx]), torch.FloatTensor(this.y[idx])\n        else:\n            return torch.FloatTensor(this.X[idx])","4f6ac3f6":"class ANN_CFG():\n    tr_batch_size = 128\n    ts_batch_size = 128\n    \n    epochs = 25\n    \n    HL = [2048, 2048, 2048]\n    OL = 1\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \ncfg = ANN_CFG()\n\ntrds = DS(tr_images, tr_labels.reshape(-1,1))\ntrd  = DL(trds, batch_size=cfg.tr_batch_size, shuffle=True, generator=torch.manual_seed(0))","6e5e2d37":"class ANN(nn.Module):\n    def __init__(this, IL=None, HL=None, OL=None):\n    \n        super(ANN, this).__init__()\n        \n        this.MP  = nn.MaxPool2d(kernel_size=2)\n        this.DP  = nn.Dropout(p=0.3)\n    \n        this.BN1 = nn.BatchNorm2d(1)\n        this.CN1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3)\n        \n        this.BN2 = nn.BatchNorm2d(64)\n        this.CN2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n        \n        this.BN3 = nn.BatchNorm2d(64)\n        this.CN3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n        \n        this.BN4 = nn.BatchNorm2d(128)\n        this.CN4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n        \n        this.BN5 = nn.BatchNorm2d(128)\n        this.CN5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n        \n        this.FC1 = WN(nn.Linear(128*2*2, HL[0]))\n        this.FC2 = WN(nn.Linear(HL[0], HL[1]))\n        this.FC3 = WN(nn.Linear(HL[1], OL))\n        \n    def getOptimizer(this):\n        return optim.Adam(this.parameters(), lr=1e-3, weight_decay=0)\n    \n    def forward(this, x):\n        x = this.BN1(x)\n        x = this.CN1(x)\n        x = F.relu(this.MP(x))\n        \n        x = this.BN2(x)\n        x = this.CN2(x)\n        x = F.relu(this.MP(x))\n        \n        x = this.BN3(x)\n        x = this.CN3(x)\n        x = F.relu(this.MP(x))\n        \n        x = this.BN4(x)\n        x = this.CN4(x)\n        x = F.relu(this.MP(x))\n        \n        x = this.BN5(x)\n        x = this.CN5(x)\n        x = F.relu(this.MP(x))\n        \n        x = x.view(x.shape[0], -1)\n        \n        x = F.relu(this.FC1(x))\n        x = F.relu(this.FC2(x))\n        x = torch.sigmoid(this.FC3(x))\n        return x","7ce3bd47":"#net = ANN(IL=None, HL=cfg.HL, OL=cfg.OL)\n#net.to(cfg.device)\n#net.train()\n\n#trds = DS(tr_images, tr_labels.reshape(-1,1))\n#trd = DL(trds, batch_size=128, shuffle=False)\n\n#xxxx, yyyy = next(iter(trd))\n\n#op = net(xxxx.to(cfg.device).view(xxxx.shape[0], 1, n_size, n_size))\n#print(op.shape)\n\n#del trds, trd, xxxx, yyyy, op, net","88d8dec8":"def train_fn(X=None, y=None):\n    LP = []\n    name_getter = []\n    \n    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n    \n    n_folds = 4\n    fold = 0\n    \n    start_time = time()\n    for tr_idx, va_idx in KFold(n_splits=n_folds, shuffle=True, random_state=0).split(X, y):\n        breaker()\n        print(\"Fold {fold} processing...\".format(fold=fold+1))\n        \n        X_train, X_valid, y_train, y_valid = X[tr_idx], X[va_idx], y[tr_idx], y[va_idx]\n        \n        tr_data_setup = DS(X_train, y_train.reshape(-1,1))\n        va_data_setup = DS(X_valid, y_valid.reshape(-1,1))\n        \n        dataloaders = {\"train\" : DL(tr_data_setup, batch_size=cfg.tr_batch_size, shuffle=True, generator=torch.manual_seed(0)),\n                       \"valid\" : DL(va_data_setup, batch_size=cfg.tr_batch_size, shuffle=False)}\n        \n        model = ANN(IL=None, HL=cfg.HL, OL=cfg.OL)\n        model.to(cfg.device)\n        \n        optimizer = model.getOptimizer()\n        \n        for e in range(cfg.epochs):\n            epochLoss = {\"train\" : 0, \"valid\" : 0}\n            for phase in [\"train\", \"valid\"]:\n                if phase == \"train\":\n                    model.train()\n                else:\n                    model.eval()\n                lossPerPass = 0\n                \n                for feats, label in dataloaders[phase]:\n                    feats, label = feats.to(cfg.device).view(feats.shape[0], 1, n_size, n_size), label.to(cfg.device)\n                    \n                    optimizer.zero_grad()\n                    with torch.set_grad_enabled(phase == \"train\"):\n                        output = model(feats)\n                        loss = nn.BCELoss()(output, label)\n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n                    lossPerPass += (loss.item()\/label.shape[0])\n                epochLoss[phase] = lossPerPass\n            LP.append(epochLoss)\n            \n            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n                bestLoss = epochLoss\n                name = \".\/Model_Fold_{fold}.pt\".format(fold=fold)\n                name_getter.append(name)\n                torch.save(model.state_dict(), name)\n        fold += 1\n    \n    breaker()\n    print(\"Time taken to train {fold} folds for {e} epochs : {:.2f} minutes\".format((time()-start_time)\/60, fold=n_folds, e=cfg.epochs))\n    breaker()\n    print(\"Best Loss :\", repr(bestLoss))\n    breaker()\n    \n    return LP, name_getter, model\n\ndef eval_fn(model=None, names=None, dataloader=None):\n    final_Pred = np.zeros((num_obs_test, 1))\n    \n    for name in names:\n        Pred = torch.zeros(cfg.ts_batch_size, 1).to(cfg.device)\n        model.load_state_dict(torch.load(name))\n        model.eval()\n        for X, y in dataloader:\n            X = X.to(cfg.device).view(X.shape[0], 1, n_size, n_size)\n            with torch.no_grad():\n                Prob = model(X)\n            Pred = torch.cat((Pred, Prob), dim=0)\n        Pred = Pred[cfg.ts_batch_size:]\n        Pred = Pred.cpu().numpy()\n        final_Pred = np.add(final_Pred, Pred)\n        \n    final_Pred = np.divide(final_Pred, len(names))\n    final_Pred[np.argwhere(final_Pred > 0.5)[:, 0]]  = int(1)\n    final_Pred[np.argwhere(final_Pred <= 0.5)[:, 0]] = int(0)\n    return final_Pred.reshape(-1)","45888fc5":"LP, Names, Network = train_fn(X=tr_images, y=tr_labels)","1539565f":"LPV = []\nLPT = []\nfor i in range(len(LP)):\n  LPT.append(LP[i][\"train\"])\n  LPV.append(LP[i][\"valid\"])\n\nxAxis = [i+1 for i in range(cfg.epochs)]\n\nplt.figure(figsize=(25, 25))\nplt.subplot(4, 1, 1)\nplt.plot(xAxis, LPT[:cfg.epochs], \"b\", label=\"Training Loss\")\nplt.plot(xAxis, LPV[:cfg.epochs], \"r--\", label=\"Validation Loss\")\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Fold 1\")\nplt.subplot(4, 1, 2)\nplt.plot(xAxis, LPT[1*cfg.epochs:2*cfg.epochs], \"b\", label=\"Training Loss\")\nplt.plot(xAxis, LPV[1*cfg.epochs:2*cfg.epochs], \"r--\", label=\"Validation Loss\")\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Fold 2\")\nplt.subplot(4, 1, 3)\nplt.plot(xAxis, LPT[2*cfg.epochs:3*cfg.epochs], \"b\", label=\"Training Loss\")\nplt.plot(xAxis, LPV[2*cfg.epochs:3*cfg.epochs], \"r--\", label=\"Validation Loss\")\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Fold 3\")\nplt.subplot(4, 1, 4)\nplt.plot(xAxis, LPT[3*cfg.epochs:4*cfg.epochs], \"b\", label=\"Training Loss\")\nplt.plot(xAxis, LPV[3*cfg.epochs:4*cfg.epochs], \"r--\", label=\"Validation Loss\")\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Fold 4\")\nplt.show()","c65cb5a6":"ts_data_setup = DS(ts_images, ts_labels.reshape(-1,1))\nts_data = DL(ts_data_setup, batch_size=cfg.ts_batch_size, shuffle=False)\n\ny_pred = eval_fn(Network, Names, ts_data)\n\nbreaker()\nprint(\"ANN Model Accuracy  : {:.5f} %\".format(accuracy_score(ts_labels, y_pred) * 100))\nbreaker()","7ae15634":"breaker()\nprint(\"Time taken to run Notebook : {:.2f} minutes\".format((time()-notebook_start_time)\/60))\nbreaker()\n\n#Only Uncomment When Committing","290cb5e9":"# Directory Setup","bff6056d":"**Dataset Template**","f21b15e3":"# Helper Functions","286ad271":"**Consolidating Train Images and creating Labels**","a51ebce1":"**Debugging Sizes**","d06543bf":"**Reading Image Data**","8b6e0688":"# ANN","09dd7714":"**Basic Info (Used to confirm correctness Pre-Dataset Numpy Arrays)**","2d33e3f4":"**Consolidating Test Images and creating Labels**","2592e999":"**Setup**","03beb2d6":"# Data Processing","5a85503e":"# Library Imports","117caeb0":"**Config**","044a4509":"**ANN Helpers**","aee4d5c1":"**File Name Handling**"}}