{"cell_type":{"2d50c6b2":"code","c744bb69":"code","843151a4":"code","97b43dc3":"code","6d762dd3":"code","c0df4035":"code","20a5d7d8":"code","bbc63f7c":"code","d17f363c":"code","6ae594ff":"code","791353f5":"code","d01b5c3a":"code","4521e00f":"code","8a52817a":"code","7d8be086":"code","61800cb1":"code","1d63968d":"code","acc426e5":"code","634cfd2a":"code","24aa0af1":"code","cf671c0d":"code","9133a307":"code","5d4d3c2e":"code","ed5e630e":"code","f4d38339":"code","6c272deb":"code","719684db":"code","3d5873a6":"code","9fb2fef6":"code","54da4788":"code","09be11c2":"code","a963e530":"code","a5645315":"code","f83f1e77":"code","4d7b52bb":"code","8b1d10e6":"code","4ea94f20":"code","a194a5d1":"code","cd0da26b":"code","168614bf":"code","646873a6":"code","831c43b7":"code","052c36c9":"code","94cf6cf0":"code","2a8fa3f3":"code","c6e68639":"code","759045e2":"code","22080994":"code","8bf3c5aa":"code","b7d0ed24":"code","bc0eafc7":"code","cd22c6d6":"code","6d8d11de":"code","016b546c":"code","04f24e98":"code","8074b2d9":"code","eba6b92e":"code","4d996ff3":"code","d9d901ae":"code","3496367a":"code","51fde08e":"code","6562b091":"code","c7e04521":"code","a9ecc3d7":"code","e7ba3c1a":"code","a8499cd1":"code","4280feee":"code","13066275":"code","6a27a9b0":"code","dd0ce095":"code","ef0e58db":"code","59e7f91f":"code","a26606c9":"code","49b7e045":"code","ce36ca07":"code","d2ded618":"code","6b09e2d4":"markdown","69b70ce6":"markdown","6a7ad79a":"markdown","56f13b00":"markdown","48eec6ff":"markdown"},"source":{"2d50c6b2":"import findspark\nfindspark.init()\n\nimport pyspark # only run after findspark.init()\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n","c744bb69":"from pyspark import SparkContext, SparkConf\n\nconf = pyspark.SparkConf().setAppName('covid19 data').setMaster('local')\nsc = pyspark.SparkContext.getOrCreate(conf) #(conf=conf)\n#spark = SparkSession(sc)","843151a4":"#### import data and gain knowledge about data","97b43dc3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","6d762dd3":"# read the global data","c0df4035":"data_path = \"..\/Data\/csse_covid_19_time_series\/\"\nconfirmed_cases = \"..\/input\/covid-data\/time_series_covid19_confirmed_global.csv\"           #data_path + 'time_series_covid19_confirmed_global.csv'\ndeath_cases =\"..\/input\/covid-data\/time_series_covid19_deaths_global.csv\"                   #data_path + 'time_series_covid19_deaths_global.csv'\nrecovery_casese =\"..\/input\/covid-data\/time_series_covid19_recovered_global.csv\"            #data_path + 'time_series_covid19_recovered_global.csv'","20a5d7d8":"confirmed_data = pd.read_csv(confirmed_cases)\ndeaths_data = pd.read_csv(death_cases)\nrecovered_data = pd.read_csv(recovery_casese)","bbc63f7c":"confirmed_data.head()","d17f363c":"confirmed_data.shape","6ae594ff":"len(confirmed_data[\"Country\/Region\"].unique())","791353f5":"confirmed_data.describe()","d01b5c3a":"confirmed_data_spark = spark.read.csv(confirmed_cases,header=True)\ndeaths_data_spark = spark.read.csv(death_cases,header=True)\nrecovered_data_spark = spark.read.csv(recovery_casese,header=True)","4521e00f":"confirmed_data_spark.select([\"Province\/State\",\"Country\/Region\",\"Lat\",\"Long\"]).show(3)","8a52817a":"confirmed_data = confirmed_data.drop([\"Lat\",\"Long\"],axis = 1)","7d8be086":"confirmed_data.head(5)","61800cb1":"drop_col = [\"Lat\",\"Long\"]\ntemp = confirmed_data_spark.select([c for c in confirmed_data_spark.columns if c not in drop_col])","1d63968d":"from functools import reduce\nfrom pyspark.sql import DataFrame\n\nconfirmed_data_spark = reduce(DataFrame.drop, ['Lat','Long'], confirmed_data_spark)","acc426e5":"confirmed_data = confirmed_data.groupby([\"Country\/Region\"]).sum()","634cfd2a":"confirmed_data.head(5)","24aa0af1":"sns.heatmap(confirmed_data.isnull())","cf671c0d":"data_dataype = confirmed_data_spark.dtypes","9133a307":"confirmed_data_spark.groupby().count().show()","5d4d3c2e":"confirmed_data_country_wise = confirmed_data_spark.groupby([\"Country\/Region\"]).sum() ","ed5e630e":"confirmed_data_country_wise.show(5)","f4d38339":"from pyspark.sql.types import IntegerType\n","6c272deb":"string_col = ['Province\/State','Country\/Region']\n\nfor col in confirmed_data_spark.columns :\n    if col not in string_col :\n        confirmed_data_spark = confirmed_data_spark.withColumn(col,confirmed_data_spark[col].cast(IntegerType()))","719684db":"confirmed_data_country_wise_spark = confirmed_data_spark.groupby([\"Country\/Region\"]).sum() ","3d5873a6":"confirmed_data_country_wise_spark.count()","9fb2fef6":"confirmed_data.index","54da4788":"confirmed_data.head(5)","09be11c2":"confirmed_data = confirmed_data.transpose()\nconfirmed_data.head()","a963e530":"confirmed_data_rdd = sc.parallelize(confirmed_data)","a5645315":"#confirmed_data_.createOrReplaceTempView(\"confirmed_data_table\")","f83f1e77":"from pyspark.sql import SQLContext\n\nsqlContext = SQLContext(sc)\n","4d7b52bb":"confirmed_data_with_country_as_col = sqlContext.createDataFrame(confirmed_data)","8b1d10e6":"len(confirmed_data_with_country_as_col.columns)","4ea94f20":"plotCountry = ['China', 'US', 'Italy', 'France', 'Spain', 'Australia']","a194a5d1":"plot_1_datframe = confirmed_data_with_country_as_col.select(plotCountry)","cd0da26b":"plot_1_datframe.show(5)","168614bf":"#confirmed_data_with_country_as_col.columns","646873a6":"date_of_record = confirmed_data.index","831c43b7":"confirmed_data[plotCountry].plot(figsize=(30,15), linewidth=5, colormap='brg', fontsize=25)","052c36c9":"#plot_1_datframe.plot(figsize=(30,15), linewidth=5, colormap='brg', fontsize=25)","94cf6cf0":"confirmed_data[plotCountry].plot(figsize=(30,15), linewidth=3, marker='*', colormap='brg', fontsize=25, logy=True)\nplt.xlabel('Date', fontsize=25);\nplt.ylabel('Confirmed Cases in Logarithmic count', fontsize=25);\nplt.title('Confirmed Cases in Logarithmic Time Series', fontsize=25);","2a8fa3f3":"ax = confirmed_data.plot(figsize=(30,15), linewidth=2, marker='*', fontsize=25)\nax.legend(ncol=10, loc='upper right')\nplt.xlabel('Days', fontsize=20);\nplt.ylabel('Number of Reported Confirmed Casese', fontsize=25);\nplt.title('Total reported coronavirus casese', fontsize=25);","c6e68639":"def max_cases_country_in_give_date(date,data) :\n    \n    max_index = np.argmax(data[data.index == date].iloc[0].values)\n    return data.columns[max_index] \n    \n    ","759045e2":"max_cases_country_in_give_date(\"1\/24\/20\",confirmed_data)","22080994":"confirmed_data.head(5)","8bf3c5aa":"deaths_data_spark.columns","b7d0ed24":"drop_col  = ['Lat','Long','Province\/State']\n\ndeaths_data_spark = deaths_data_spark.select([c for c in deaths_data_spark.columns if c not in drop_col])","bc0eafc7":"len(deaths_data_spark.columns)","cd22c6d6":"deaths_data_spark.count()","6d8d11de":"temp_dfsp = deaths_data_spark.select('Country\/Region','1\/22\/20')","016b546c":"temp_dfsp.show(5)","04f24e98":"deaths_data_spark.createOrReplaceTempView(\"deaths_data_spark_table\")","8074b2d9":"def max_death_on_given_date(date,deaths_data_spark_table):\n    query = \"select Country\/Region, \" + date + \" from deaths_data_spark_table \"","eba6b92e":"date = \"1\/22\/20\"\nquery = \"select Country\/Region, max(\"+ date +\") from ( select Country\/Region, \" + date + \" from deaths_data_spark_table ) \"\nquery","4d996ff3":"query = \" select 1\/22\/20  from deaths_data_spark_table \"\nquery","d9d901ae":"#spark.sql(query).show()","3496367a":"deaths_data.head()","51fde08e":"deaths_data = deaths_data.drop([\"Lat\",\"Long\"],axis = 1)","6562b091":"deaths_data.head()","c7e04521":"deaths_data = deaths_data.groupby([\"Country\/Region\"]).sum()","a9ecc3d7":"deaths_data.head()","e7ba3c1a":"deaths_data.info()","a8499cd1":"deaths_datacopy = deaths_data.copy()","4280feee":"deaths_datacopy.head()","13066275":"deaths_datacopy = deaths_datacopy.transpose()","6a27a9b0":"ax = deaths_datacopy.plot(figsize=(30,15), linewidth=2, marker='*', fontsize=25)\nax.legend(ncol=10, loc='upper right')\nplt.xlabel('Days', fontsize=20);\nplt.ylabel('Number of Reported death Casese', fontsize=25);\nplt.title('Total reported coronavirus death casese', fontsize=25);","dd0ce095":"deaths_datacopy.head(5)","ef0e58db":"deaths_datacopy2 = deaths_datacopy.copy()","59e7f91f":"def death_more_than30_fun(dataframe) :\n    newdf = pd.DataFrame()\n\n    for (val,country) in zip(deaths_datacopy2.iloc[-1],deaths_datacopy2) :\n        if(val >= 30) :\n            newdf[country] = dataframe[country]\n    return newdf  ","a26606c9":"newdatafram  = death_more_than30_fun(deaths_datacopy2)","49b7e045":"newdatafram.head()","ce36ca07":"newdatafram.shape","d2ded618":"ax = newdatafram.plot(figsize=(30,15), linewidth=2, marker='*', fontsize=25)\nax.legend(ncol=10, loc='upper right')\nplt.xlabel('Days', fontsize=20);\nplt.ylabel('Number of Reported death Casese', fontsize=25);\nplt.title('Total reported coronavirus death casese more than 30 in last date', fontsize=25);","6b09e2d4":"### COVID-19 Exploratory Data Analysis","69b70ce6":"### Death Data","6a7ad79a":"### plot data","56f13b00":"##### with spark","48eec6ff":"#### plot in logerithemic time series"}}