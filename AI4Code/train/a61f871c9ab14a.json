{"cell_type":{"b415070e":"code","22cce052":"code","769948ad":"code","dec592e3":"code","4619c92f":"code","67df30e5":"code","f2c18ed2":"code","c717a085":"code","91a0b804":"code","03ebe8e0":"code","470c1ae7":"code","650bd811":"code","75f813e4":"code","24066a54":"code","bcfa7f77":"code","2be88d82":"code","1bfdd239":"code","099cdc74":"code","63c6a66b":"code","a15e4640":"code","f127fa1c":"code","07cc1e4c":"code","77c3b163":"code","e604e475":"code","dd0dd551":"code","5314da15":"code","d21ca21c":"code","e01ce513":"code","050af28b":"code","52fe0d88":"markdown","d46d682d":"markdown","219d4a6b":"markdown"},"source":{"b415070e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","22cce052":"%matplotlib inline\n#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n#machine learning\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier","769948ad":"#load the data\ntrain_df = pd.read_csv('..\/input\/train.csv', index_col=0)\ntest_df = pd.read_csv('..\/input\/test.csv', index_col=0)\nprint(train_df.shape)\nprint(test_df.shape)","dec592e3":"train_df.columns","4619c92f":"train_df.info()","67df30e5":"train_df.describe()","f2c18ed2":"train_df.head()","c717a085":"train_df.loc[:, ['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","91a0b804":"train_df.loc[:, ['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()","03ebe8e0":"#Create new feature\ndef age_feature(age):\n    if age < 30:\n        return 1\n    elif age < 55:\n        return 2\n    elif age >=55:\n        return 3\n    \ntrain_df['Age feature'] = train_df['Age'].apply(age_feature)\n","470c1ae7":"pd.crosstab(train_df['Survived'], train_df['Age feature'])","650bd811":"train_df[train_df['Survived'] == 1]['Age'].hist(color=\"green\", \n                                         label='Survived', alpha=.5\n                                       )\ntrain_df[train_df['Survived'] == 0]['Age'].hist(color=\"red\", \n                                         label='Died', alpha=.5,\n                                       )\nplt.title('Age for survived and died')\nplt.xlabel('Years')\nplt.ylabel('Frequency')\nplt.legend();","75f813e4":"sns.countplot(x=train_df['Age feature'], hue=train_df['Survived'])","24066a54":"train_df.drop(['Name', 'Ticket', 'Cabin', 'Age feature'], axis=1, inplace=True)\ntest_df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","bcfa7f77":"X_train = train_df.drop('Survived', axis=1)\ny_train = train_df['Survived']\nX_test = test_df\nX_train.shape, y_train.shape, X_test.shape","2be88d82":"class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        if not isinstance(X, pd.DataFrame):\n            X = pd.DataFrame(X)\n        return X[self.columns].values\n","1bfdd239":"sex_encoder = Pipeline([('cst', ColumnSelectTransformer(['Sex'])),\n                        ('encoder', OneHotEncoder(sparse=False))])\nembarked_encoder = Pipeline([('cst', ColumnSelectTransformer(['Embarked'])),\n                        ('encoder', OneHotEncoder(sparse=False))])\nage_imputer = Pipeline([('cst', ColumnSelectTransformer(['Age'])),\n                        ('imputer', Imputer(strategy='median'))])","099cdc74":"X_train['Age'] = age_imputer.fit_transform(X_train)\nX_test['Age'] = age_imputer.fit_transform(X_test)","63c6a66b":"X_train['Embarked'] = X_train['Embarked'].fillna(method='ffill')","a15e4640":"X_train['Sex'] = sex_encoder.fit_transform(X_train)\nX_train['Embarked'] = embarked_encoder.fit_transform(X_train)\nX_test['Sex'] = sex_encoder.fit_transform(X_test)\nX_test['Embarked'] = embarked_encoder.fit_transform(X_test)","f127fa1c":"param_grid = {'penalty':['l1', 'l2'],\n              'tol' : np.linspace(1e-9, 1e-4, 10),\n              }\nlg_grid = GridSearchCV(LogisticRegression(), param_grid, n_jobs=2, cv=5, verbose=1)\nlg_grid.fit(X_train, y_train)\nlog_reg = lg_grid.best_estimator_\nprint('LogisticRegression score: {}'.format(log_reg.score(X_train, y_train)))","07cc1e4c":"param_grid = {'C':np.logspace(-3, 2, 25),}\nsvc_grid = GridSearchCV(SVC(kernel='sigmoid', probability=True), param_grid, n_jobs=2, cv=5)\nsvc_grid.fit(X_train, y_train)\nsvc = svc_grid.best_estimator_\nprint(svc)\nprint('SupportVectorClassifier score: {}'.format(log_reg.score(X_train, y_train)))","77c3b163":"param_grid = {'min_samples_split': range(2, 15), 'min_samples_leaf': range(1, 15)}\ntree_grid =  GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=2, cv=5)\ntree_grid.fit(X_train, y_train)\ntree = tree_grid.best_estimator_\nprint(tree)\nprint('DecisionTree score: {}'.format(log_reg.score(X_train, y_train)))","e604e475":"forest = RandomForestClassifier(n_estimators=100, n_jobs=2)\nforest.fit(X_train, y_train)\nprint('RandomForest score: {}'.format(log_reg.score(X_train, y_train)))","dd0dd551":"param_grid = {'learning_rate':np.linspace(1e-3, 1e1, 20) }\n\nadboost = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10),\n                             n_estimators=100),\n                        param_grid, n_jobs=2, cv=5)\nadboost.fit(X_train, y_train)\nprint('Adaboost score: {}'.format(log_reg.score(X_train, y_train)))","5314da15":"voting = VotingClassifier([('log_reg',log_reg), ('decisiontree',tree),\n                           ('randomforest',forest), ('adaboost',adboost)],\n                          voting='soft') \nvoting.fit(X_train, y_train)\nvoting.score(X_train, y_train)","d21ca21c":"X_test['Fare'] = X_test['Fare'].fillna(value=X_test['Fare'].mean())","e01ce513":"X_test['Survived'] = forest.predict(X_test)\nsubmission = X_test['Survived']","050af28b":"\n\n# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"forest.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\n# create a link to download the dataframe\ncreate_download_link(submission)\n\n# \u2193 \u2193 \u2193  Yay, download link! \u2193 \u2193 \u2193 \n\n","52fe0d88":"# Exploratory data analysis","d46d682d":"## Model, predict and solve\nWe will try several classifiers and aggregates the results with a VotingClassifier","219d4a6b":"People in the 1st class and female have the highest survival rate"}}