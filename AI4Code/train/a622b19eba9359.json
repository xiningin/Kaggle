{"cell_type":{"4f9d88bb":"code","0610f67c":"code","07cdc884":"code","d1bebad5":"code","918be892":"code","01242b5c":"code","138beafa":"code","e781e4f6":"code","dff18ba1":"code","5c1e09c8":"code","8cadf082":"code","86bf9527":"code","3929f579":"code","01ff6920":"code","0dc59c85":"code","b7e46cc8":"code","591b786f":"code","a1fa91ef":"code","6df619f1":"code","c20acdfb":"code","6c0711e6":"code","edf4fcbe":"code","09c2e25b":"code","9e464fde":"code","879253be":"code","f0202cb2":"markdown","2119c3a5":"markdown","f00900e8":"markdown","2f630859":"markdown","fc139ec6":"markdown","52223d58":"markdown","8587ce01":"markdown","f0719938":"markdown","e1cb639f":"markdown","2af66062":"markdown","552b69c5":"markdown","c7677019":"markdown","29febba5":"markdown","8acdf736":"markdown","8283f65d":"markdown","9e6fcc60":"markdown"},"source":{"4f9d88bb":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras.utils import to_categorical, Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import ResNet50","0610f67c":"path = '\/kaggle\/input\/hpa-single-cell-image-classification\/'\nos.listdir(path)","07cdc884":"train_data = pd.read_csv(path+'train.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","d1bebad5":"img_size = 64\nimg_channel = 3\nnum_classes = 19\nbatch_size = 64","918be892":"print('Number train samples:', len(train_data.index))\nprint('Number train images:', len(os.listdir(path+'train')))\nprint('Number submission samples:', len(samp_subm.index))\nprint('Number submission images:', len(os.listdir(path+'test')))","01242b5c":"train_data.head()","138beafa":"colors_dict = {'red': 'microtubule', 'blue': 'nuclei', 'yellow': 'Endoplasmic Reticulum', 'green': 'protein'}","e781e4f6":"image_id = train_data.loc[0, 'ID']\nimage_file = cv2.imread(path+'train\/'+image_id+'_blue.png')\nimage_file.shape","dff18ba1":"image_id = train_data.loc[0, 'ID']\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\nfig.subplots_adjust(hspace = .2, wspace=.1)\naxs = axs.ravel()\ncolors = list(colors_dict.keys())\nfor i in range(len(colors)):\n    filename = ''.join([image_id, '_', colors[i], '.png'])\n    image_file = cv2.imread(path+'train\/'+filename)\n    axs[i].imshow(image_file)\n    axs[i].set_title(colors_dict[colors[i]])\n    axs[i].set_xticklabels([])\n    axs[i].set_yticklabels([])","5c1e09c8":"# original label\nprint('input :', train_data.loc[0, 'Label'])\n# label as list\nprint('step 1:', train_data.loc[0, 'Label'].split('|'))\n# label as list on integers\nprint('step 2:', list(map(int, train_data.loc[0, 'Label'].split('|'))))\n# label to binary class matrix\nlabel = to_categorical(list(map(int, train_data.loc[0, 'Label'].split('|'))), num_classes=19)\nprint('step 3:', label)\n# sum the labels\nlabel = label.sum(axis=0)\nprint('step 4:', label)","8cadf082":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, labels, batch_size, img_size, img_channel):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_channel = img_channel\n        self.indexes = np.arange(len(self.list_IDs))\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)\/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, self.img_size, self.img_size, self.img_channel))\n        y = np.zeros((self.batch_size, num_classes), dtype=int)\n        for i, ID in enumerate(list_IDs_temp):\n            data_file = cv2.imread(self.path+ID+'_blue.png')\n            img = cv2.resize(data_file, (self.img_size, self.img_size))\n            X[i, ] = img\/255.\n            # Prepare label\n            label = self.labels[i]\n            label = label.split('|')\n            label = list(map(int, label))\n            label = to_categorical(label, num_classes=num_classes)\n            label = label.sum(axis=0)\n            y[i, ] = label\n        return X, y","86bf9527":"weights='..\/input\/models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","3929f579":"metrics = [tf.keras.metrics.AUC(name='auc', multi_label=True)]\nlearning_rate = 1e-3","01ff6920":"conv_base = ResNet50(include_top=False,\n                     weights=weights,\n                     input_shape=(img_size, img_size, img_channel))\nconv_base.trainable = True","0dc59c85":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(num_classes, activation='sigmoid'))","b7e46cc8":"model.compile(optimizer=Adam(lr=learning_rate), loss=\"binary_crossentropy\", metrics=metrics)","591b786f":"model.summary()","a1fa91ef":"epochs = 3","6df619f1":"train_IDs, val_IDs, y_train, y_val = train_test_split(train_data['ID'], train_data['Label'], test_size=0.33, random_state=2021)\ntrain_IDs.index=range(len(train_IDs))\ny_train.index=range(len(train_IDs))\nval_IDs.index=range(len(val_IDs))\ny_val.index=range(len(val_IDs))","c20acdfb":"train_generator = DataGenerator(path+'train\/', train_IDs, y_train, batch_size, img_size, img_channel)\nval_generator = DataGenerator(path+'train\/', val_IDs, y_val, batch_size, img_size, img_channel)","6c0711e6":"history = model.fit_generator(generator=train_generator,\n                              validation_data=val_generator,\n                              epochs = epochs)","edf4fcbe":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['auc']\nacc_val = history.history['val_auc']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","09c2e25b":"output = samp_subm.copy()","9e464fde":"output.to_csv('submission.csv', index=False)","879253be":"output.head()","f0202cb2":"# Libraries","2119c3a5":"# Load Data","f00900e8":"# Data Generator\nWe define a data generator to load the data on demand.","2f630859":"# Parameter","fc139ec6":"# Define Model","52223d58":"# Intro\nWelcome to the [Human Protein Atlas - Single Cell Classification](https:\/\/www.kaggle.com\/c\/hpa-single-cell-image-classification).\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/23823\/logos\/header.png)\n\nFor a TPU tutorial of this compedition we recommend this [notebook](https:\/\/www.kaggle.com\/drcapa\/human-protein-atlas-tpu-tutorial\/).\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span>","8587ce01":"# Overview","f0719938":"# Analyse Training","e1cb639f":"# Path","2af66062":"# Train Model","552b69c5":"# Load Images\nAll samples consist of four files - blue, green, red, and yellow. Colors are \n* red for [microtubule channels](https:\/\/en.wikipedia.org\/wiki\/Microtubule)\n* blue for nuclei channels\n* yellow for [Endoplasmic Reticulum (ER)](https:\/\/en.wikipedia.org\/wiki\/Endoplasmic_reticulum) channels\n* green for protein","c7677019":"# Encoding Labels\nThis is a multilabel classification. The labels are separeted by | in the train dataset.","29febba5":"# Next Steps\n* Extend the data generator for all colors (blue, red, yellow, green). Currently onle blue is used.\n* Predict test data.","8acdf736":"# Write Output","8283f65d":"Load the first image of the train dataset:","9e6fcc60":"Show the 4 images for the first sample of the train dataset:"}}