{"cell_type":{"1f1b8080":"code","08aab6d0":"code","6bbd54d5":"code","0e57dfe0":"code","4bd92aa1":"code","1e7ebd5d":"code","13093928":"code","1d8d2652":"code","a3cee4a2":"code","e5a9d13b":"code","8a83a5ae":"code","e2693c81":"code","3bc578c7":"code","ca58cda7":"code","1f1c08ce":"code","9f3c7dba":"code","9308701d":"code","097723ab":"code","33a1dbbe":"code","fe115936":"code","09389e6a":"code","46d9e8a5":"code","f18aec57":"code","12e597e6":"code","a7e3141b":"code","facf26ee":"code","ad24b7c5":"code","eec6d5c5":"code","b4679fa5":"code","c77ad7d7":"code","c5386416":"code","38a8771c":"code","c49975f3":"code","db617867":"code","080df800":"code","93c5ac6d":"code","f9c875f8":"code","8c627bb3":"code","a56e827e":"code","507ecac6":"code","9032f562":"code","d349872f":"code","5b5051cf":"code","eb848c1f":"code","65b7aba5":"code","8e351304":"code","d44a5e97":"code","7401f6ce":"code","4f12f00d":"code","8c9d2559":"markdown","0e3883bd":"markdown","b2ef8574":"markdown","d257900c":"markdown","23321822":"markdown","ab062a24":"markdown","a2be8a36":"markdown","e0c68e6e":"markdown","4cfe6fd1":"markdown","fdf80d07":"markdown","ba1e10c8":"markdown","216b010d":"markdown","1a679727":"markdown","1854a530":"markdown","1af829fc":"markdown","651c4690":"markdown","8023c42d":"markdown","863cc03d":"markdown","1614d153":"markdown","cb07c0a9":"markdown","142cb65e":"markdown","175a869c":"markdown","27c0d26c":"markdown","c4a61f67":"markdown","3d06a520":"markdown","d919e9e8":"markdown","e3b12758":"markdown","5ab9d951":"markdown","e7094627":"markdown","43ac3d94":"markdown"},"source":{"1f1b8080":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport datetime\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom urllib.request import urlopen\nimport json\nimport ipywidgets as widgets\nfrom IPython.display import clear_output\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\n\n#If needed other libraries will be called during the project ","08aab6d0":"df = pd.read_csv('..\/input\/sales-forecasting\/train.csv')","6bbd54d5":"df.head()","0e57dfe0":"df.info()","4bd92aa1":"#Missing Values \ndf.isnull().sum()","1e7ebd5d":"df[df['Postal Code'].isnull()]['City'].unique()","13093928":"#Ok, lets fill it :D\ndf['Postal Code'] = df['Postal Code'].fillna(5401)","1d8d2652":"#Quick convert of Order Date and Shipe Date into Date form \ndf['Order Date'] = pd.to_datetime(df['Order Date'])\ndf['Ship Date'] = pd.to_datetime(df['Ship Date'])\n\n#Add Order Year column\ndf['Order Year'] = df['Order Date'].apply(lambda x:x.year)\n#Add Order month column\ndf['Order Month'] = df['Order Date'].apply(lambda x:datetime.datetime(x.year,x.month,1))\n\n#Add a column containing : The number of week\/Year ([1,52]\/Year) in which the order was made \ndf['Order Week'] = df['Order Date'].apply(lambda x:f'{x.year}\/{x.isocalendar()[1]}')\n\n#Add a column containing : The number of the day [1,7] the order was made\ndf['Order Day number'] = df['Order Date'].apply(lambda x:x.isocalendar()[2])\n\n#Sort Data by Order date\ndf.sort_values(['Order Date'],inplace=True)","a3cee4a2":"#Unique values (This steps gives little insights about what sub-series we might consider)\nfor c in df.columns :\n    print(f\"Number of {c} unique values : {df[c].nunique()}\")\n","e5a9d13b":"specs = [[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]]\nfig = make_subplots(rows=2,cols=2,specs=specs)\nfig.add_trace(go.Pie(labels=['Standard Class','Second Class', 'First Class' , 'Same Day'],\n                     values=df[df['Order Year']==2015]['Ship Mode'].value_counts(),title='2015'),1,1)\nfig.add_trace(go.Pie(labels=['Standard Class','Second Class', 'First Class' , 'Same Day'],\n                     values=df[df['Order Year']==2016]['Ship Mode'].value_counts(),title='2016'),1,2)\nfig.add_trace(go.Pie(labels=['Standard Class','Second Class', 'First Class' , 'Same Day'],\n                     values=df[df['Order Year']==2017]['Ship Mode'].value_counts(),title='2017'),2,1)\nfig.add_trace(go.Pie(labels=['Standard Class','Second Class', 'First Class' , 'Same Day'],\n                     values=df[df['Order Year']==2018]['Ship Mode'].value_counts(),title='2018'),2,2)\n\nfig.update_layout(title_text='Shipe mode rate per year',title_x=0.5)","8a83a5ae":"#Lead Time distribution per Segment :\ndf['Lead_Time']=(df['Ship Date']-df['Order Date']).apply(lambda x:x.days)\nfig = px.histogram(df[df['Lead_Time']>0], x=\"Lead_Time\", color=\"Segment\",labels={'Lead_Time':'Lead Time in days'})\nfig.show()","e2693c81":"#A Dictionary containing State codes, these codes will be used for the next plot\ncodes = {'Alabama': 'AL','Alaska': 'AK','Arizona': 'AZ','Arkansas': 'AR','California': 'CA','Colorado': 'CO','Connecticut': 'CT','Delaware': 'DE','District of Columbia':'DC','Florida': 'FL','Georgia': 'GA','Hawaii': 'HI','Idaho': 'ID','Illinois': 'IL','Indiana': 'IN','Iowa': 'IA','Kansas': 'KS','Kentucky': 'KY','Louisiana': 'LA','Maine': 'ME','Maryland': 'MD','Massachusetts': 'MA','Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS','Missouri': 'MO','Montana': 'MT','Nebraska': 'NE','Nevada': 'NV','New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM','New York': 'NY','North Carolina': 'NC','North Dakota': 'ND','Ohio': 'OH','Oklahoma': 'OK','Oregon': 'OR','Pennsylvania': 'PA','Rhode Island': 'RI','South Carolina': 'SC','South Dakota': 'SD','Tennessee': 'TN','Texas': 'TX','Utah': 'UT','Vermont': 'VT','Virginia': 'VA','Washington': 'WA','West Virginia': 'WV','Wisconsin': 'WI','Wyoming': 'WY'}\n#Create a widget to vary year [2015,2018], in order to visualize each year plot (It's not working on kaggle)\nc=2015\nint_range = widgets.IntSlider(min=2015,max=2018,description=\"Plot's Year\")\ndisplay(int_range)\n\ndef on_value_change(change):\n    global c \n    c=change['new']\n    clear_output(wait=True)\n    display(int_range)\n    sales_percity = pd.DataFrame(df[df['Order Year']==c].groupby('State')['Sales'].sum())\n    sales_percity.reset_index(inplace=True)\n    sales_percity['state_code'] = sales_percity['State'].apply(lambda x:codes[x])\n\n    data = dict(type = 'choropleth',\n            locations = sales_percity['state_code'],\n            locationmode = 'USA-states',\n            colorscale= 'Portland',\n            text= sales_percity['State'],\n            z=sales_percity['Sales'],\n            colorbar = {'title':'Colorbar Title'})\n    layout = dict(geo = {'scope':'usa'},title=f'Sales per State in {c}',title_x=0.5)\n    choromap = go.Figure(data = [data],layout = layout)\n    iplot(choromap)\n\nint_range.observe(on_value_change, names='value')\non_value_change({'new':2015})","3bc578c7":"sales_percategory = pd.DataFrame(df.groupby(['Category','Order Year'],sort=False)['Sales'].sum()).sort_values('Order Year')\nsales_percategory.sort_values(['Category','Order Year'],inplace=True)\nsales_percategory.reset_index(inplace=True)\nfig = px.bar(sales_percategory,x='Order Year',y='Sales',title='Sales per Year per Category',\n             color='Category',labels={'Order Year':'Year','Sales':'Sales (c)'},barmode='group')\nfig.update_layout(xaxis_tickformat = 'd',autosize=False,width=1100,height=600,title_x=0.5)\n\nfig.show()","ca58cda7":"sales_percategory['Sales n-1']=sales_percategory['Sales'].shift()\nsales_percategory['Growth Rate'] = round(((sales_percategory['Sales']-sales_percategory['Sales n-1'])\/sales_percategory['Sales n-1']),4)\nfig2 = px.bar(sales_percategory[sales_percategory['Order Year']!=2015],x='Order Year',y='Growth Rate',\n              title='Sales Growth Rate per Year per Category',\n             color='Category',labels={'Order Year':'Year','Growth Rate':'GR'},text='Growth Rate',barmode='group')\nfig2.update_traces( texttemplate='%{text:.2%s}', textposition='outside')\nfig2.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',title_x=0.5)\nfig2.show()","1f1c08ce":"#Group sales per week and per categories\nsales_category_month = pd.DataFrame(df.groupby(['Category','Order Month'],sort=False)['Sales'].sum())\nsales_category_month.reset_index(inplace=True)\nsales_category_month.sort_values(['Category','Order Month'],inplace=True)\nfig = px.line(sales_category_month,x='Order Month',y='Sales',color='Category',\n             hover_data={\"Order Month\": \"|%B  %Y\"})\nfig.update_layout(autosize=False,width=1000,height=600,title_x=0.5,title_text='Monthly sales per Category')\nfig.update_xaxes(\n    dtick=\"M1\",\n    tickformat=\"%b \\n\\n\\n\\n\\n\\n\\n %Y\",ticklabelmode=\"period\")\nfig.show()","9f3c7dba":"sales_category_week = pd.DataFrame(df.groupby(['Category','Order Week'],sort=False)['Sales'].sum())\nsales_category_week.reset_index(inplace=True)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=sales_category_week[sales_category_week['Category']=='Office Supplies']['Order Week'],\n                         y=sales_category_week[sales_category_week['Category']=='Furniture']['Sales'],name='Furniture'))\nfig.add_trace(go.Scatter(x=sales_category_week[sales_category_week['Category']=='Office Supplies']['Order Week'],\n                         y=sales_category_week[sales_category_week['Category']=='Office Supplies']['Sales'],name='Office Supplies'))\nfig.add_trace(go.Scatter(x=sales_category_week[sales_category_week['Category']=='Office Supplies']['Order Week'],\n                         y=sales_category_week[sales_category_week['Category']=='Technology']['Sales'],name='Technology'))\nfig.update_layout(autosize=False,width=1200,height=600,title_x=0.5,title_text='Weekly sales per Category',\n                 xaxis_title='Date (Week number\/Year)',yaxis_title='Profit value')","9308701d":"from statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom dateutil.parser import parse\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error","097723ab":"#Creating a data frame containing Monthly sales of furniture\nX_frame = sales_category_month[sales_category_month['Category']=='Furniture'][['Order Month', 'Sales']]\nX_frame.set_index('Order Month',inplace=True)\n#Add a column containing first difference of sales (sales(t)-sales(t-1))\nX_frame['Sales diff 1'] = X_frame['Sales'].diff()\n#Add a column containing logarithmic transformation of sales also its first and second order difference\nX_frame['log Sales'] = np.log(X_frame['Sales'])\nX_frame ['log Sales diff 1'] = X_frame['log Sales'].diff()\nX_frame['log Sales diff 2'] = X_frame ['log Sales diff 1'].diff()\n#Set series to be equal to 2nd order difference of logarithmic transformation\n#At first trial using Raw sales yields a curved trend, after transforming it using logarithmic function the serie becomes non stationary. \n#Differencing it bring it back to stationarity and attenuate the trend effect. \n#Set a training set containing years 2015\/2016\/2017 observations and test set containing year 2018 observations.\nX = np.array(X_frame['log Sales diff 2'].dropna() )\nX_train = X[:-12]\nX_test = X[-12:]","33a1dbbe":"#Plotting X_train\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,167)),y=X_train,name='True values'))\nfig.update_layout(title_text='Time serie plot',title_x=0.5)","fe115936":"from statsmodels.tsa.stattools import adfuller","09389e6a":"adf_resutls = adfuller(X_train,maxlag=10)\nprint(f'ADF test results are :')\nprint('ADF Statistic: %f' % adf_resutls[0])\nprint('p-value: %f' % adf_resutls[1])\nprint('Critical Values:')\nfor key, value in adf_resutls[4].items():\n    print('\\t%s: %.3f' % (key, value))\nif adf_resutls[0]<=-2.9 :\n    print('==> Non-stationarity can be rejected')\nelse :\n    print('==> Non-stationarity cannot be rejected')","46d9e8a5":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","f18aec57":"fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nplot_pacf(X_train,lags=14,ax=axes[0])\nplot_acf(X_train,lags=14,ax=axes[1])\nplt.show()","12e597e6":"#The value of period is justified by the monthly sales per category plots which suspects a saisonality of 12 months for Furniture category and this value has a relative good effect on the trend composant\nadditive_decomposition = seasonal_decompose(X_train,period=12,model='additive')\nplt.rcParams.update({'figure.figsize': (16,12)})\nadditive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\nplt.tight_layout()","a7e3141b":"import statsmodels.api as sm","facf26ee":"#Reset time serie to be the logarithmic transformation of Sales, differentiation is done automatically in SARIMAX function. \nX = np.array(X_frame['log Sales'].dropna() )\nX_train = X[:-12]\nX_test = X[-12:]","ad24b7c5":"#The saisonality term is added after comparison of bic metric and due to the last remark on the decomposition graph\norder= (1,2,1)\nseasonal_order = (1,0,0,12)\ntrend='c'","eec6d5c5":"model1_fit = sm.tsa.statespace.SARIMAX(X_train,order=order,seasonal_order=seasonal_order,trend=trend,enforce_invertibility=False,\n                                      enforce_stationarity=False).fit()\nfitted_values= model1_fit.fittedvalues","b4679fa5":"#Plot true and predicted sales for the training set\nRMSE = np.sqrt(mean_squared_error(X_train[12:],fitted_values[12:]))\nMAE = mean_absolute_error(X_train[12:],fitted_values[12:])\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,167)),y=X_train,name='True values'))\nfig.add_trace(go.Scatter(x=np.array(range(12,167)),y=fitted_values[12:],name='Predicted Values'))\nfig.update_layout(title_text='Time serie plot',title_x=0.5)","c77ad7d7":"#Monthly prediction: This function gives month by month predictions. \n#If next 2 months sales are to be predicted, the function predicts the value for the first month and add it's true value to the training set then predicts for 2nd month\ndef month_prediction(X,Xtest_len=12,order=(0,0,0),seasonal_order=(2,0,1,12),trend='c'):\n    predictions1 =[]\n    for j in range(Xtest_len):\n        X_train = X[0:len(X)-Xtest_len+j]\n        model1 =  sm.tsa.statespace.SARIMAX(X_train,order=order,seasonal_order=seasonal_order,\n                            enforce_invertibility=False,enforce_stationarity=False,trend=trend)\n      \n            \n        model1_fit = model1.fit()\n        prediction_step = model1_fit.predict(start=len(X_train),end=len(X_train))\n        predictions1.append(prediction_step)\n    predictions1 = np.reshape(predictions1,((Xtest_len),))\n    RMSE = np.sqrt(mean_squared_error(X[len(X)-Xtest_len:],predictions1))\n    MAE = mean_absolute_error(X[len(X)-Xtest_len:],predictions1)\n    \n    return predictions1 , RMSE , MAE","c5386416":"#Test set predictions\npredictions1,RMSE,MAE = month_prediction(X,Xtest_len=12,order=order,seasonal_order=seasonal_order,trend=trend)","38a8771c":"#Plot Test results\nRMSE = np.sqrt(mean_squared_error(X_test,predictions1))\nMAE = mean_absolute_error(X_test,predictions1)\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,12)),y=X[-12:],name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(0,12)),y=np.array(predictions1),name='Predicted Values'))","c49975f3":"transformed_predictions = np.exp(np.array(predictions1))\ntransformed_Xtest = np.exp(np.array(X_test))\nRMSE = np.sqrt(mean_squared_error(transformed_Xtest,transformed_predictions))\nMAE = mean_absolute_error(transformed_Xtest,transformed_predictions)\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,12)),y=transformed_Xtest,name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(0,12)),y=transformed_predictions,name='Predicted Values'))","db617867":"#Same transformations as the previous analysis\nX_frame = pd.DataFrame(df.groupby(['Order Week'],sort=False)['Sales'].sum())\nX_frame['Sales diff 1'] = X_frame['Sales'].diff()\nX_frame['log Sales'] = np.log(X_frame['Sales'])\nX_frame ['log Sales diff 1'] = X_frame['log Sales'].diff()\nX_frame['log Sales diff 2'] = X_frame['log Sales diff 1'].diff()\n#Same split as the previous analysis 2015\/2016\/2017 for training and 2018 for test\nX = np.array(X_frame['log Sales diff 2'].dropna() )\nX_train = X[:-52]\nX_test = X[-52:]","080df800":"#Plot time series\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,208)),y=X_train,name='True values'))\nfig.update_layout(title_text='Time series plot',title_x=0.5)","93c5ac6d":"adf_resutls = adfuller(X_train,maxlag=10)\nprint(f'ADF test results are :')\nprint('ADF Statistic: %f' % adf_resutls[0])\nprint('p-value: %f' % adf_resutls[1])\nprint('Critical Values:')\nfor key, value in adf_resutls[4].items():\n    print('\\t%s: %.3f' % (key, value))\nif adf_resutls[0]<=-2.9 :\n    print('==> Non-stationarity can be rejected')\nelse :\n    print('==> Non-stationarity cannot be rejected')","f9c875f8":"fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nplot_pacf(X_train,lags=52,ax=axes[0])\nplot_acf(X_train,lags=52,ax=axes[1])\n\nplt.show()","8c627bb3":"#Decomposition :\nadditive_decomposition = seasonal_decompose(X_train,period=52,model='additive')\nplt.rcParams.update({'figure.figsize': (16,12)})\nadditive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\nplt.tight_layout()","a56e827e":"X = np.array(X_frame['log Sales'].dropna() )\nX_train = X[:-52]\nX_test = X[-52:]","507ecac6":"#Set lag orders\norder = ([1,2,3,4,18,32],2,1)\nseasonal_order=(1,0,0,12)\ntrend='c'","9032f562":"#Fit the model \nmodel2_fit = sm.tsa.statespace.SARIMAX(X_train,order=order,seasonal_order=seasonal_order,trend=trend,enforce_invertibility=False,\n                                      enforce_stationarity=False).fit()\nfitted_values2= model2_fit.fittedvalues","d349872f":"#Plot true and predicted sales for the training set\nRMSE = np.sqrt(mean_squared_error(X_train[52:],fitted_values2[52:]))\nMAE = mean_absolute_error(X_train[52:],fitted_values2[52:])\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,167)),y=X_train,name='True values'))\nfig.add_trace(go.Scatter(x=np.array(range(52,167)),y=fitted_values2[52:],name='Predicted Values'))\nfig.update_layout(title_text='Time serie plot',title_x=0.5)","5b5051cf":"#Weekly prediction : This function plays the same role as monthly prediction function but on a window of a week\ndef week_prediction(X,Xtest_len=12,order=(0,0,0),seasonal_order=(2,0,1,12),trend='c'):\n    predictions1 =[]\n    for j in range(Xtest_len):\n        X_train = X[0:len(X)-Xtest_len+j]\n        \n        model1 =  sm.tsa.statespace.SARIMAX(X_train,order=order,seasonal_order=seasonal_order,\n                            enforce_invertibility=False,enforce_stationarity=False,trend=trend)\n      \n            \n        model1_fit = model1.fit()\n        prediction_step = model1_fit.predict(start=len(X_train),end=len(X_train))\n        predictions1.append(prediction_step)\n    predictions1 = np.reshape(predictions1,((Xtest_len),))\n    RMSE = np.sqrt(mean_squared_error(X[len(X)-Xtest_len:],predictions1))\n    MAE = mean_absolute_error(X[len(X)-Xtest_len:],predictions1)\n    \n    return predictions1 , RMSE , MAE","eb848c1f":"predictions2,RMSE,MAE = month_prediction(X,Xtest_len=52,order=order,seasonal_order=seasonal_order,trend=trend)","65b7aba5":"#Plot test results\nRMSE = np.sqrt(mean_squared_error(X_test,predictions2))\nMAE = mean_absolute_error(X_test,predictions2)\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=X_test,name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=np.array(predictions2),name='Predicted Values'))","8e351304":"#Transform back and plot real values\ntransformed_predictions = np.exp(np.array(predictions2))\ntransformed_Xtest = np.exp(np.array(X_test))\nRMSE = np.sqrt(mean_squared_error(transformed_Xtest,transformed_predictions))\nMAE = mean_absolute_error(transformed_Xtest,transformed_predictions)\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=transformed_Xtest,name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=transformed_predictions,name='Predicted Values'))","d44a5e97":"#Train the model on all data\nmodel2_fit = sm.tsa.statespace.SARIMAX(X,order=order,seasonal_order=seasonal_order,trend=trend,enforce_invertibility=False,\n                                      enforce_stationarity=False).fit()\nfitted_values = model2_fit.fittedvalues","7401f6ce":"#Predict next week sale value\nnext_week_prediction = model2_fit.predict(start=len(X),end=len(X))\nprint(f'Next week sales value prediction is equal to : {round(np.exp(next_week_prediction[0]),2)} (cur)')","4f12f00d":"#Plot results\nfig = go.Figure()\ntransformed_fitted = np.exp(fitted_values)\nfig.add_trace(go.Scatter(x=np.array(range(200,212)),y=X_frame['Sales'].iloc[200:],name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(200,212)),y=transformed_fitted[200:],name='Predicted Values'))\nfig.add_trace(go.Scatter(x=np.array(range(209,211)),y=np.array([transformed_fitted[-1],np.exp(next_week_prediction[0])]),\n                         line = dict(color='red', width=4, dash='dash'),\n                         name='Next week prediction'))\n","8c9d2559":"    1\/ Through all years states of California and New York have the greatest total sales value\n    2\/ Texas has a medium total sales value compared to California and New York\n    3\/ In the last year Washington total sales value increased considerably.","0e3883bd":"### Preprocessing","b2ef8574":"According to the Partial Autocorrelation plot, Arima((2,2,1)*(0,0,0,0)) is a good candidate. Because second spike in Partial Autocorrelation graph is close to the significance treshhold let's remove this order from the model. The model becomes Arima((1,2,1)*(0,0,0,0))","d257900c":"### Sales per Year per Category","23321822":"These results contain predictions of logarithmic transformation of sales. For next, predicted and true sales are plotted","ab062a24":"### PACF and ACF","a2be8a36":"### Sales mapping (Choropleth)","e0c68e6e":"### Monthly sales time series plot shows that each catogory has a different behavior, in next parts we will predict future weekly sales per category...","4cfe6fd1":"### Additive decomposition","fdf80d07":"# Furniture monthly sales analysis","ba1e10c8":"### Ship Mode and Lead Time","216b010d":"# Data exploration","1a679727":"All observations with missing Postal Code are from the city of Burlington, we can either fill it or drop all the column since it wont be used in this analysis.","1854a530":"### Predicting next week sales :","1af829fc":"    1\/ When using Raw Sales Data, we get a curved trend, in order to attenuate it, a logarithmic transformation had been applied but the serie became non statitionary.\n    2\/ the first order difference brought the series back to stationarity.\n","651c4690":"==> All categories sales exhibit an increasing trend, except in 2016 where Technology and Office Supplies sales diminished.\nThis is better remarked through the next growth rate graph.","8023c42d":"==> We can analyze total sales or sales per category\/subcategories or Shipe mode utilization... ","863cc03d":"# Data Visualization","1614d153":"### Stationarity test","cb07c0a9":"## Autocorrelation and partial autocorrelation graphs :","142cb65e":"### Preprocessing","175a869c":"### Monthly sales per Category","27c0d26c":"# Libraries and Data import","c4a61f67":"## Stationarity test :","3d06a520":"There is some anomalies in ship dates, some of them are anterior to the order date. Only those yielding a positive lead time are plotted. Results are confusing, Shipe Date column is not credible...","d919e9e8":"### Weekly sales per category","e3b12758":"# Total weekly sales","5ab9d951":"## ARIMA Model ","e7094627":"## ARIMA Model","43ac3d94":"### Additive decomposition"}}