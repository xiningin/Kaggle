{"cell_type":{"6baab251":"code","86779ea2":"code","22e74e36":"code","fa0ceabe":"code","85236df3":"code","edb05c8e":"code","dc924cc8":"code","fbc661a2":"markdown"},"source":{"6baab251":"!pip install 'kaggle-environments>=0.1.6'","86779ea2":"%%writefile submission.py\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nT = np.zeros((3, 3))\nP = np.zeros((3, 3))\n\n# a1 is the action of the opponent 1 step ago\n# a2 is the action of the opponent 2 steps ago\na1, a2 = None, None\n\ndef transition_agent(observation, configuration):\n    global T, P, a1, a2\n    if observation.step > 1:\n        a1 = observation.lastOpponentAction\n        T[a2, a1] += 1\n        P = np.divide(T, np.maximum(1, T.sum(axis=1)).reshape(-1, 1))\n        a2 = a1\n        if np.sum(P[a1, :]) == 1:\n            return int((np.random.choice(\n                [0, 1, 2],\n                p=P[a1, :]\n            ) + 1) % 3)\n        else:\n            return int(np.random.randint(3))\n    else:\n        if observation.step == 1:\n            a2 = observation.lastOpponentAction\n        return int(np.random.randint(3))","22e74e36":"%%writefile random.py\nimport numpy as np\ndef random_agent(observation, configuration):\n    return int(np.random.randint(3))","fa0ceabe":"%%writefile mysubmission.py\nfrom numpy import random\nimport math\n\nlast_react_action = None\ndef get_score(left_move, right_move):\n    # This method exists in this file so it can be consumed from rps.py and agents.py without a circular dependency\n    delta = (\n        right_move - left_move\n        if (left_move + right_move) % 2 == 0\n        else left_move - right_move\n    )\n    return 0 if delta == 0 else math.copysign(1, delta)\n\ndef random_agent(observation, configuration):\n    global last_react_action\n    if observation.step == 0:\n        my_list = [0] * 34 + [1] * 33 + [2] * 33\n        last_react_action = int(random.choice(my_list))\n    elif get_score(last_react_action, observation.lastOpponentAction) <= 1:\n        last_react_action = (observation.lastOpponentAction + 1) % configuration.signs\n\n    return last_react_action","85236df3":"from kaggle_environments import evaluate, make, utils\nenv = make(\"rps\", debug=True)\nenv.render()","edb05c8e":"# env.reset()\n# # Play as the first agent against default \"random\" agent.\n# env.run([\"submission.py\", \"random.py\"])\n# env.render(mode=\"ipython\", width=500, height=450)","dc924cc8":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"mysubmission.py\", \"submission.py\"])\nenv.render(mode=\"ipython\", width=500, height=450)","fbc661a2":"# Creating a Transition Matrix to predict opponent's next move\n\nWe will create a simple markov chain with 3 states and a 3x3 transition matrix. We initialize it with uniform probabilities but then learn\nthe transition matrix from the data to better predict the next move of the opponent.\n"}}