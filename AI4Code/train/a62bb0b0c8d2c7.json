{"cell_type":{"be35cf60":"code","145a5738":"code","a2204100":"code","5732f8cf":"code","362cd3d4":"code","d9081f5e":"code","b1f2c6f6":"code","0bbb9c81":"code","46009859":"code","106f5782":"code","601285a2":"code","88a37c20":"code","55257a57":"code","8d939491":"code","a8403b62":"code","48863c91":"code","be651d37":"code","a3c3c6ee":"code","6e720188":"code","13bf4c64":"code","b6ccc14a":"code","a541a242":"code","3cc14406":"code","3ff07453":"code","597d811d":"code","d8dc8633":"code","04ef0e89":"code","9a411b6b":"code","b9045ae4":"code","e528860f":"code","161e127b":"code","54c9c4da":"code","025ef0b0":"code","821789cb":"code","6941ef9b":"code","ea727176":"code","292b04c3":"code","247b24d2":"code","b9ad3fdd":"code","529ae8d2":"markdown","9640756f":"markdown","7c81ce44":"markdown","8cabcacb":"markdown","b0b18e62":"markdown","18e7543c":"markdown","ed0e13b7":"markdown","307ae186":"markdown","2d86d9db":"markdown","b861e91c":"markdown","d823b07f":"markdown","5eec5419":"markdown","68943872":"markdown","8bed9262":"markdown","16ca1c90":"markdown","39fbc429":"markdown","08215d54":"markdown","d0da775c":"markdown","eb2f932c":"markdown","a219166d":"markdown","5186687c":"markdown","1d7aa045":"markdown","b60ab8f9":"markdown","cf6d9750":"markdown","2d476c97":"markdown","f6f41d8c":"markdown","afe2ad86":"markdown","6e9fb4cb":"markdown","99fe3291":"markdown"},"source":{"be35cf60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","145a5738":"from sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import log_loss, accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder","a2204100":"def LabelEncoding(all_data,data):\n    le = LabelEncoder()\n    le.fit(all_data)\n    return le.transform(data)","5732f8cf":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndata_all = pd.concat([train, test],axis=0,sort=True).reset_index().drop(['index'],axis=1)\n\ntrain.name = 'Train data'\ntest.name = 'Test data'\ndata_all.name = 'All data'","362cd3d4":"print(train.name)\ntrain.info()","d9081f5e":"print(test.name)\ntest.info()","b1f2c6f6":"train = train.assign(Female=pd.get_dummies(train['Sex'])['female'],\n                     Male=pd.get_dummies(train['Sex'])['male'])\n\ntest = test.assign(Female=pd.get_dummies(test['Sex'])['female'],\n                     Male=pd.get_dummies(test['Sex'])['male'])\n\ntrain[['Male','Female']].sample(5)","0bbb9c81":"#Pclass is transformed  into one-hot\ntrain_pclass = pd.get_dummies(train['Pclass'])\ntest_pclass = pd.get_dummies(test['Pclass'])\n\ntrain = train.assign(Pclass_1 = train_pclass[1],\n                     Pclass_2 = train_pclass[2],\n                     Pclass_3 = train_pclass[3],\n                    )\ntest = test.assign(Pclass_1 = test_pclass[1],\n                   Pclass_2 = test_pclass[2],\n                   Pclass_3 = test_pclass[3],\n                  )\ntrain[['Pclass_1','Pclass_2','Pclass_3']].sample(5)","46009859":"from keras.preprocessing import text \n\ntokenizer = text.Tokenizer()\n\ntrain_texts = train['Name'].values\ntest_texts = test['Name'].values\n\ntokenizer.fit_on_texts(train_texts)\ntrain_list_tokenized = tokenizer.texts_to_sequences(train_texts)\n\ntrain_mstr = np.zeros(train.shape[0]).astype(int)\ntrain_mr = np.zeros(train.shape[0]).astype(int)\ntrain_miss = np.zeros(train.shape[0]).astype(int)\ntrain_mrs = np.zeros(train.shape[0]).astype(int)\n\nfor i,name in enumerate(train_list_tokenized):\n    #Master:6,Mr:1,Miss:2,Mrs:3\n    if 6 in name: \n        train_mstr[i] = 1\n    elif 3 in name:\n        train_mr[i] = 1\n    elif 2 in name:\n        train_miss[i] = 1\n    elif 1 in name:\n        train_mrs[i] = 1\n\ntokenizer.fit_on_texts(test_texts)\ntest_list_tokenized = tokenizer.texts_to_sequences(test_texts)\n\ntest_mstr = np.zeros(test.shape[0]).astype(int)\ntest_mr = np.zeros(test.shape[0]).astype(int)\ntest_miss = np.zeros(test.shape[0]).astype(int)\ntest_mrs = np.zeros(test.shape[0]).astype(int)\nfor i,name in enumerate(test_list_tokenized):\n    #Master:6,Mr:1,Miss:2,Mrs:3\n    if 6 in name: \n        test_mstr[i] = 1\n    elif 3 in name:\n        test_mr[i] = 1\n    elif 2 in name:\n        test_miss[i] = 1\n    elif 1 in name:\n        test_mrs[i] = 1\n        \ntrain = train.assign(Mstr=train_mstr,Mr=train_mr,Miss=train_miss,Mrs=train_mrs)\ntest = test.assign(Mstr=test_mstr,Mr=test_mr,Miss=test_miss,Mrs=test_mrs)\n\ntrain[['Mstr','Mr','Miss','Mrs']].sample(5)","106f5782":"train['Embarked'] = train['Embarked'].fillna('S') # S is the most frequency\ntrain_embarked = pd.get_dummies(train['Embarked'])\ntest_embarked = pd.get_dummies(test['Embarked'])\n\ntrain = train.assign(Embarked_S = train_embarked['S'],\n                     Embarked_C = train_embarked['C'],\n                     Embarked_Q = train_embarked['Q'])\n\ntest = test.assign(Embarked_S = test_embarked['S'],\n                   Embarked_C = test_embarked['C'],\n                   Embarked_Q = test_embarked['Q'])\ntrain[['Embarked_S','Embarked_C','Embarked_Q']].sample(5)","601285a2":"print(data_all.groupby(['Pclass','Embarked'])['Fare'].mean())\ndata_all[data_all['Fare'].isnull()]","88a37c20":"#Null of fare is predicted low cost because of this person is in  Lower_class and Embarke S\ndata_all['Fare'] = data_all['Fare'].fillna(14.43)","55257a57":"fare_categories = pd.qcut(data_all['Fare'], 10,labels=False)\ntrain['Fare'] = fare_categories[:train.shape[0]].values\ntest['Fare'] = fare_categories[train.shape[0]:].values\ntrain[['Fare']].sample(5)","8d939491":"age_categories = pd.qcut(data_all['Age'], 5,labels=False)\ntrain['Age'] = age_categories[:train.shape[0]].fillna(-1).values #null is filled -1\ntest['Age']  = age_categories[train.shape[0]:].fillna(-1).values #null is filled -1\ntest[['Age']].sample(5)","a8403b62":"data_all['Cabin'] = data_all['Cabin'].fillna('Z')\nCabin_all = [i[0] for i in data_all['Cabin']]\n\ntrain_cabin = [i for i in Cabin_all[:train.shape[0]]]\ntest_cabin = [i for i in Cabin_all[train.shape[0]:]]\n\ntrain['Cabin'] = LabelEncoding(Cabin_all,train_cabin)\ntest['Cabin'] = LabelEncoding(Cabin_all,test_cabin)","48863c91":"#Family_sizes\nfamily_size_group1_train = np.zeros(train.shape[0]).astype(int)\nfamily_size_group2_train = np.zeros(train.shape[0]).astype(int)\nfamily_size_group3_train = np.zeros(train.shape[0]).astype(int)\nalone_train = np.zeros(train.shape[0]).astype(int)\n\nfamily_size_group1_test = np.zeros(test.shape[0]).astype(int)\nfamily_size_group2_test = np.zeros(test.shape[0]).astype(int)\nfamily_size_group3_test = np.zeros(test.shape[0]).astype(int)\nalone_test = np.zeros(test.shape[0]).astype(int)\n\nfamily_size_all_train = train['SibSp'] +train['Parch']\nfamily_size_all_test = test['SibSp'] +test['Parch']\n\nfor i,f_size in enumerate(family_size_all_train):\n    if f_size == 1 or f_size == 2:\n        family_size_group1_train[i] = 1\n    elif f_size == 3 or f_size == 4 or f_size == 5:\n        family_size_group2_train[i] = 1\n    elif f_size == 0:\n        alone_train[i] = 1\n    else:\n        family_size_group3_train[i] = 1\n\nfor i,f_size in enumerate(family_size_all_test):\n    if f_size == 1 or f_size == 2:\n        family_size_group1_test[i] = 1\n    elif f_size == 3 or f_size == 4 or f_size == 5:\n        family_size_group2_test[i] = 1\n    elif f_size == 0:\n        alone_test[i] = 1\n    else:\n        family_size_group3_test[i] = 1\n        \ntrain = train.assign(Alone = alone_train,\n                     Family_group_1 = family_size_group1_train,\n                     Family_group_2 = family_size_group2_train,\n                     Family_group_3 = family_size_group3_train)\n\ntest = test.assign(Alone = alone_test,\n                   Family_group_1 = family_size_group1_test,\n                   Family_group_2 = family_size_group1_test,\n                   Family_group_3 = family_size_group1_test)","be651d37":"test['Ticket'] = data_all.groupby('Ticket')['Ticket'].transform('count')[train.shape[0]:].values\ntrain['Ticket'] = data_all.groupby('Ticket')['Ticket'].transform('count')[:train.shape[0]].values","a3c3c6ee":"train = train.drop(['Sex','Name','Embarked','Pclass'],axis=1)\ntest = test.drop(['Sex','Name','Embarked','Pclass'],axis=1)","6e720188":"#predict_age\nfrom sklearn.ensemble import RandomForestClassifier as RFC\n\nnew_data_all = pd.concat([train.drop(['Survived'],axis=1),test],axis=0).reset_index().drop(['index'],axis=1)\nnot_null_age_index = [i for i,flag in enumerate(new_data_all['Age']) if flag != -1]\nnull_age_index = [i for i,flag in enumerate(new_data_all['Age']) if flag == -1]\n\ntrain_null_age_index = null_age_index[:177]\ntest_null_age_index = [i-train.shape[0] for i in null_age_index[177:]]\n\ntrain_age_data_x = new_data_all.iloc[not_null_age_index].drop(['PassengerId','Age'],axis=1)\ntrain_age_data_y = new_data_all.iloc[not_null_age_index]['Age']\n\ntest_age_data = new_data_all.iloc[null_age_index].drop(['PassengerId','Age'],axis=1)","13bf4c64":"accuracy = []\npred_result = np.ones(train_age_data_x.shape[0])\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=71)\nfor tr_idx, va_idx in kf.split(train_age_data_x,train_age_data_y):\n    tr_x,va_x = train_age_data_x.iloc[tr_idx], train_age_data_x.iloc[va_idx]\n    tr_y,va_y = train_age_data_y.iloc[tr_idx], train_age_data_y.iloc[va_idx]\n    model = RFC(criterion='gini',\n                n_estimators=100,\n                max_depth=8,\n                min_samples_split=7,\n                min_samples_leaf=7,\n                max_features='auto',\n                oob_score=True,\n                random_state=71,\n                n_jobs=-1,\n                verbose=0) \n    model.fit(tr_x,tr_y)\n\n    pred=model.predict(va_x)\n    accuracy.append((sum(pred==va_y))\/len(va_y))\nprint('Varidation accuracy:',accuracy)\nprint('Average of accuracy:',np.mean(accuracy))","b6ccc14a":"model.fit(train_age_data_x,train_age_data_y)\n\nage_pred=model.predict(test_age_data)","a541a242":"train['Age'].iloc[train_null_age_index] = age_pred[:177]\ntest['Age'].iloc[test_null_age_index] = age_pred[177:]","3cc14406":"New_data_all = pd.concat([train,test],axis = 0,sort=True).reset_index().drop(['index','PassengerId'],axis=1)\nplt.subplots(figsize=(10, 7)) \n\nsurvived_rate = New_data_all.groupby(['Ticket','Alone','Family_group_1','Family_group_2','Family_group_3'])['Survived'].transform('mean')\nsurvived_rate2 = New_data_all.groupby(['Parch','SibSp','Male','Female'])['Survived'].transform('mean')\n\nNew_data_all = New_data_all.assign(Survived_rate = survived_rate)\nNew_data_all = New_data_all.assign(Survived_rate2 = survived_rate2)\n\nsns.heatmap(New_data_all.corr(), vmax=1, vmin=-1, center=0)","3ff07453":"New_all_data = pd.concat([train,test],axis=0,sort=True).reset_index().drop(['index'],axis=1)\n\nNew_train = train.assign(Survived_rate = New_data_all['Survived_rate'][:train.shape[0]].values)\nNew_train = New_train.assign(Survived_rate2 = New_data_all['Survived_rate2'][:train.shape[0]].values)\n\nNew_test = test.assign(Survived_rate = New_data_all['Survived_rate'][train.shape[0]:].values)\nNew_test = New_test.assign(Survived_rate2 = New_data_all['Survived_rate2'][train.shape[0]:].values)\n\nplt.subplots(figsize=(10, 7)) \nsns.heatmap(New_train.corr(), vmax=1, vmin=-1, center=0)\nNew_test = New_test.fillna(0.5)","597d811d":"train_x = New_train.drop(['PassengerId','Survived'],axis=1)\ntrain_x = train_x.astype('float32')\ntrain_y = New_train['Survived']\n\ntest_x = New_test.drop(['PassengerId'],axis=1)\ntest_x","d8dc8633":"scores_accuracy = []\npred_result = np.ones(train.shape[0])\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=71)\nfor tr_idx, va_idx in kf.split(train_x,train_y):\n    tr_x,va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y,va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    model = RFC(criterion='gini',\n                n_estimators=100,\n                max_depth=12,\n                min_samples_split=10,\n                min_samples_leaf=10,\n                max_features='auto',\n                oob_score=True,\n                random_state=71,\n                n_jobs=-1,\n                verbose=0) \n    model.fit(tr_x,tr_y)\n\n    pred=model.predict(va_x)\n    accuracy = accuracy_score(va_y, pred>0.5)\n    scores_accuracy.append(accuracy)\n    \nprint('Varidation accuracy:',scores_accuracy)\nprint('Average of accuracy:',np.mean(scores_accuracy))","04ef0e89":"model.fit(train_x,train_y)\nRFC_pred=model.predict(test_x)","9a411b6b":"from sklearn.svm import SVC\nscores_accuracy = []\npred_result = np.ones(train.shape[0])\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=71)\nfor tr_idx, va_idx in kf.split(train_x,train_y):\n    tr_x,va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y,va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    model = SVC(kernel='rbf',C = 100,gamma = 0.001, random_state=71)\n    model.fit(tr_x,tr_y)\n\n    pred=model.predict(va_x)\n    accuracy = accuracy_score(va_y, pred>0.5)\n    scores_accuracy.append(accuracy)\n    \nprint('Varidation accuracy:',scores_accuracy)\nprint('Average of accuracy:',np.mean(scores_accuracy))","b9045ae4":"model.fit(train_x,train_y)\nSVC_pred=model.predict(test_x)","e528860f":"from sklearn.linear_model import LogisticRegression\nscores_accuracy = []\npred_result = np.ones(train.shape[0])\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=71)\nfor tr_idx, va_idx in kf.split(train_x,train_y):\n    tr_x,va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y,va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    model = LogisticRegression(random_state=71,n_jobs=-1,verbose=0)\n    model.fit(tr_x,tr_y)\n\n    pred=model.predict(va_x)\n    accuracy = accuracy_score(va_y, pred>0.5)\n    scores_accuracy.append(accuracy)\n    \nprint('Varidation accuracy:',scores_accuracy)\nprint('Average of accuracy:',np.mean(scores_accuracy))","161e127b":"model.fit(train_x,train_y)\nLR_pred=model.predict(test_x)","54c9c4da":"from xgboost import XGBClassifier\n\nscores_accuracy = []\npred_result = np.ones(train.shape[0])\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=71)\nfor tr_idx, va_idx in kf.split(train_x,train_y):\n    tr_x,va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y,va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n#     model = XGBClassifier(n_estimators=20, random_state=71)\n    model = XGBClassifier(criterion='gini',\n                n_estimators=20,\n                max_depth=5,\n                min_samples_split=4,\n                min_samples_leaf=4,\n                max_features='auto',\n                oob_score=True,\n                random_state=71,\n                n_jobs=-1,\n                verbose=0)     \n    model.fit(tr_x,tr_y)\n\n    pred=model.predict(va_x)\n    accuracy = accuracy_score(va_y, pred>0.5)\n\n    scores_accuracy.append(accuracy)\n\nprint('Varidation accuracy:',scores_accuracy)\nprint('Average of accuracy:',np.mean(scores_accuracy))","025ef0b0":"model.fit(train_x,train_y)\nXGboost_pred=model.predict(test_x)","821789cb":"prediction = np.empty(test.shape[0])\nfor i in range(test.shape[0]):\n    prediction[i] = 1 if SVC_pred[i] >0.5 else 0","6941ef9b":"data_to_submit = pd.DataFrame({\n    'PassengerId':test['PassengerId'],\n    'Survived':prediction.astype(int)\n})\ndata_to_submit.to_csv('submission_1.csv', index = False)","ea727176":"prediction = np.empty(test.shape[0])\nfor i in range(test.shape[0]):\n    prediction[i] = 1 if RFC_pred[i] >0.5 else 0","292b04c3":"data_to_submit = pd.DataFrame({\n    'PassengerId':test['PassengerId'],\n    'Survived':prediction.astype(int)\n})\ndata_to_submit.to_csv('submission_2.csv', index = False)","247b24d2":"prediction = np.empty(test.shape[0])\nfor i in range(test.shape[0]):\n    prediction[i] = 1 if (SVC_pred[i]+RFC_pred[i]+XGboost_pred[i]+LR_pred[i])\/4 >0.5 else 0","b9ad3fdd":"data_to_submit = pd.DataFrame({\n    'PassengerId':test['PassengerId'],\n    'Survived':prediction.astype(int)\n})\ndata_to_submit.to_csv('submission_3.csv', index = False)","529ae8d2":"### 1.1.1. Sex","9640756f":"## 3.1. Using best performance model(SVC model)","7c81ce44":"Pclass 1:Upper Class  \nPclass 2:Middle Class  \nPclass 3:Lower Class","8cabcacb":"## 2.3. Logistic Regression","b0b18e62":"Transformed into One-Hot representation.","18e7543c":"## 1.2. Label Encoding","ed0e13b7":"# 1. Make Feature Map","307ae186":"### 1.1.4. Embarked","2d86d9db":"## 2.2. Support Vector Machine","b861e91c":"## 1.4. Ticket Frequency","d823b07f":"## 1.3. Family Size","5eec5419":"We can predict the null of age in this dataset. I utilized Random Forest Classifier(RFC).","68943872":"# 3. Make submissions","8bed9262":"## 1.1.3. Tittle","16ca1c90":"## 2.4. XGboost","39fbc429":"Drop unnecessary features","08215d54":"### 1.1.2. Pclass","d0da775c":"### 1.2.2. Age","eb2f932c":"Tittle is extracted from Name.","a219166d":"### 1.2.3. Cabin","5186687c":"## 1.5. Predict Age","1d7aa045":"## 3.2. Using good performance model(RFC model)","b60ab8f9":"### 1.2.1. Fare","cf6d9750":"The best score is submission_3.(score:0.80382)","2d476c97":"## 3.3. Ensemble good performance model","f6f41d8c":"## 2.1. Random Forest Classifier","afe2ad86":"## 1.1. One-Hot Encoding","6e9fb4cb":"# 2. Model","99fe3291":"## 1.6. Survived Rate"}}