{"cell_type":{"78ab8b46":"code","1660477c":"code","9a9b3413":"code","ae2dabff":"code","8837133f":"code","50b0d3fd":"code","e2d73b8b":"code","9e1cd4d3":"code","708ae1d1":"code","18503962":"code","1c7bb2cc":"code","a0e953e9":"code","10a14806":"code","6f510a1f":"code","9542e9fc":"code","4d797a6d":"code","a4fccd24":"code","afb0d873":"code","cd0e56ab":"code","b0130be9":"code","9346c661":"code","3b27c695":"code","2d72a4cc":"code","68b9a620":"code","d0cc9762":"code","a468504b":"code","2f2bbabf":"code","57844ceb":"code","1ccec12d":"code","77c6989f":"code","6b6a84e8":"code","70e3af58":"code","d7807830":"code","60c3a26d":"code","defe547f":"code","68d854f0":"code","176e1626":"code","744c03f5":"code","f7c0ec17":"code","210223eb":"code","a8107ae3":"code","4b393d38":"code","f454f0cf":"code","9da0b6a6":"code","37c76eb4":"code","ba540b0a":"markdown","442347f1":"markdown","5d50c0e3":"markdown","bc3405ee":"markdown","1f77e19f":"markdown","b261bf1b":"markdown","30d0ba70":"markdown","e26430d3":"markdown","cb3a6877":"markdown","dd697c3e":"markdown","883890e9":"markdown","7946949b":"markdown","64c6ceda":"markdown","bc879e62":"markdown","c16e176e":"markdown","863754da":"markdown","901cdb27":"markdown","ae9a12c4":"markdown","04261dfe":"markdown"},"source":{"78ab8b46":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1660477c":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nfull_data = [df_train, df_test]","9a9b3413":"df_train.head()","ae2dabff":"df_train.info()","8837133f":"print(\"Uniq PassengerId :\",df_train['PassengerId'].nunique())","50b0d3fd":"del df_train['PassengerId']\ndel df_test['PassengerId']","e2d73b8b":"print (df_train[['Pclass', 'Survived']].groupby(['Survived'], as_index=False).count())","9e1cd4d3":"print (df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","708ae1d1":"print(df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\nmapping_sex = {'female': 0, 'male': 1}","18503962":"print(df_train[['Name', 'Survived']].groupby(['Name'], as_index=False).mean())","1c7bb2cc":"# Extracting Title\nimport re\n\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor df in full_data:\n    df['Title'] = df['Name'].apply(get_title)\n    del df['Name']","a0e953e9":"print(df_train[['Title', 'Survived']].groupby(['Title'], as_index=False).count())","10a14806":"print(df_test[['Title', 'Age']].groupby(['Title'], as_index=False).mean())","6f510a1f":"mapping_title = {'Capt':0, 'Col':1, 'Countess':2, 'Don':3, 'Dr':4, 'Jonkheer':5, 'Lady':6,\\\n                            'Major':7, 'Master':8, 'Miss':9, 'Mlle':10, 'Mme':11, 'Mr':12,\\\n                                                    'Mrs':13, 'Ms':14, 'Rev':15, 'Sir':16, 'Dona':17}","9542e9fc":"print (df_train[['Age', 'Survived']].groupby(['Age'], as_index=False).mean().head(20))","4d797a6d":"df_test.info()","a4fccd24":"for df in full_data:\n    avg = df['Age'].mean()\n    df['Age'][np.isnan(df['Age'])] = avg ","afb0d873":"for df in full_data:\n    df['Family_size'] = df['SibSp'] + df['Parch']\n    del df['SibSp']\n    del df['Parch']","cd0e56ab":"df_train['Ticket'].head()","b0130be9":"for df in full_data:\n    del df['Ticket']","9346c661":"for df in full_data:\n    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())","3b27c695":"df_train['Cabin'].head()","2d72a4cc":"for df in full_data:\n    del df['Cabin']","68b9a620":"df_train[['Embarked','Survived']].groupby('Embarked').count()","d0cc9762":"for df in full_data:\n    df['Embarked'] = df['Embarked'].fillna('S')","a468504b":"mapping_embarked = {'C':0, 'Q':1, 'S':2 }","2f2bbabf":"for df in full_data:\n    df.info()\n    print('*'*40)","57844ceb":"for df in full_data:\n    df['Sex'] = df['Sex'].map(mapping_sex).astype(int) \n    df['Embarked'] = df['Embarked'].map(mapping_embarked).astype(int) \n    df['Title'] = df['Title'].map(mapping_title).astype(int) ","1ccec12d":"for df in full_data:\n    df.info()\n    print('*'*40)","77c6989f":"df_train.info()","6b6a84e8":"df_test.info()","70e3af58":"y = df_train['Survived']\ndel df_train['Survived']\nX = df_train","d7807830":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1, stratify=y)","60c3a26d":"from sklearn.linear_model import LogisticRegression\n\n# Cr\u00e9ation\nlr = LogisticRegression(C=100.0, random_state=1)\n\n# Entra\u00eenement\nlr.fit(X_train, y_train)","defe547f":"print(\"Score train :\",lr.score(X_train, y_train))\nprint(\"Score test :\",lr.score(X_test, y_test))","68d854f0":"lr.get_params()","176e1626":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import validation_curve\n\n# balayage du param\u00e8tre C \n# [surr\u00e9gularisation ... sousr\u00e9gularisation]\nparam_range_c = [0.001, 0.01, 0.1, 1, 10.0, 100.0, 150.0, 200.0]\n\n# Construction de la oourbe de validation\ntrain_scores, test_scores = validation_curve(\n    estimator=lr,\n    X=X_train,\n    y=y_train,\n    param_name='C',\n    param_range=param_range_c,\n    cv=10)\n\n# [ibid pr\u00e9c\u00e9dente, avec param_range \u00e0 la place de train_sizes]\n# Pr\u00e9paration des donn\u00e9es des courbes \ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\n# Affichage de la courbe d'entrainement : \n# train_score_moyen = f( param_range )\nplt.plot(param_range_c, train_mean,\n        color='blue', marker='o',\n        markersize=5, label='train accuracy')\n\n# Affichage des \u00e9carts types sur les scores de la CV\n# correspondants\nplt.fill_between(param_range_c,\n                train_mean + train_std,\n                train_mean - train_std,\n                alpha=0.15, color='blue')\n\n# Affichage de la courbe de validation :\n# test_mean = f( param_range )\nplt.plot(param_range_c, test_mean,\n         color='green', linestyle='--',\n         marker='s', markersize=5, \n         label='validation accuracy')\n\n# Affichage des \u00e9carts types sur les scores de la CV\n# correspondants\nplt.fill_between(param_range_c,\n                test_mean + test_std,\n                test_mean - test_std,\n                alpha=0.15, color='green')\n\n# Param\u00e8tres d'affichages g\u00e9n\u00e9raux\nmpl.style.use('seaborn')\nplt.title('Courbes de validation du mod\u00e8le')\n# mise en log de l'axe des X\nplt.xscale('log')\nplt.xlabel('Param\u00e8tre C')\nplt.ylabel('Pr\u00e9cision (Accuracy)')\nplt.legend(loc='lower right')\nplt.ylim(0.6, 0.95)\nplt.tight_layout\n#plt.savefig('images\/06_05.png', dpi=300)\nplt.show()","744c03f5":"lr.get_params()","f7c0ec17":"from sklearn.model_selection import GridSearchCV\n# Sp\u00e9cification du balayage de grille\nparam_range_c = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, \n               100.0, 1000.0, 1500.0, 2000.0]\nparam_range_penalty = ['l2', 'l1', 'elasticnet']\n\n# Sp\u00e9cification des param\u00e8tres de la grille\n# rq : on entre une liste de dictionnaires python\nparam_grid = [{'C' : param_range_c, 'penalty': param_range_penalty}]\n\n# Cr\u00e9ation du GridSearch\ngs = GridSearchCV(estimator=lr,\n                  param_grid=param_grid,\n                  scoring='accuracy',\n                  cv=10,\n                  n_jobs=4) # parall\u00e9lisation\n\n# Application du GridSearch aux donn\u00e9es d'entrainement\ngs = gs.fit(X_train, y_train)\nprint('\\nMeilleur Pr\u00e9cision (Accuracy) : ', gs.best_score_)\nprint('Meilleurs param\u00e8tres : ',gs.best_params_)\n\nclf = gs.best_estimator_\nclf.fit(X_train, y_train)\nprint('Test de pr\u00e9cision (accuracy): %.3f' % \n      clf.score(X_test, y_test))","210223eb":"from sklearn.svm import SVC\n\nsvc = SVC( kernel ='rbf', random_state = 1, gamma = 0.2, C = 1.0)\nsvc.fit(X_train, y_train)","a8107ae3":"print(\"Score train :\",svc.score(X_train, y_train))\nprint(\"Score test :\",svc.score(X_test, y_test))","4b393d38":"svc.get_params()","f454f0cf":"from sklearn.model_selection import GridSearchCV\n# Sp\u00e9cification du balayage de grille\nparam_range_c = [50.0, 60.0]\nparam_range_gamma = [0.001]\nparam_range_kernel = ['linear']\n\n# Sp\u00e9cification des param\u00e8tres de la grille\n# rq : on entre une liste de dictionnaires python\nparam_grid = [{'C' : param_range_c, 'gamma': param_range_gamma, 'kernel': param_range_kernel}]\n\n# Cr\u00e9ation du GridSearch\ngs = GridSearchCV(estimator=svc,\n                  param_grid=param_grid,\n                  scoring='accuracy',\n                  cv=10,\n                  n_jobs=4) # parall\u00e9lisation\n\n# Application du GridSearch aux donn\u00e9es d'entrainement\ngs = gs.fit(X_train, y_train)\nprint('\\nMeilleur Pr\u00e9cision (Accuracy) : ', gs.best_score_)\nprint('Meilleurs param\u00e8tres : ',gs.best_params_)\n\nclf = gs.best_estimator_\nclf.fit(X_train, y_train)\nprint('Test de pr\u00e9cision (accuracy): %.3f' % \n      clf.score(X_test, y_test))","9da0b6a6":"df_test.head()","37c76eb4":"y_pred = clf.predict(df_test)\n\ndf_output = pd.DataFrame()\ndf_output['PassengerId'] = df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')[\"PassengerId\"]\ndf_output['Survived'] = y_pred\ndf_output.to_csv('output.csv', index=False)","ba540b0a":"## SVM","442347f1":"## 1.1 PassengerId : dopping the column","5d50c0e3":"### Learning curve","bc3405ee":"## 1.10 Cabin : dropping","1f77e19f":"## 1.9 Fare : replacing NaNs with mean ","b261bf1b":"## 1.4 Sex","30d0ba70":"## 1.11 Embarked : filling with most occured vaue","e26430d3":"## Logistic Regression","cb3a6877":"# 1. Feature engineering","dd697c3e":"### Grid-search","883890e9":"## 1.5 Name : extracting Title","7946949b":"### Grid-search","64c6ceda":"## 1.3 Pclass","bc879e62":"## 1.7 SibSp & Parch : combining into Family_size","c16e176e":"## 1.8 Ticket","863754da":"## 1.6 Age : replacing NaNs with mean","901cdb27":"# Submiting","ae9a12c4":"# Modeling","04261dfe":"## 1.2 Survived"}}