{"cell_type":{"c0aa2eac":"code","bdf61a0c":"code","9f6c1a46":"code","01ed4267":"code","94e1e158":"code","8dfc6fda":"code","2140dd69":"code","ab740101":"code","2553c34a":"code","6be6cef4":"code","f389f7f1":"code","0cd874d3":"code","6ef6e2c5":"code","3b181f1d":"code","f83fc899":"code","5265b0c3":"code","b84a86a4":"code","25e1da62":"code","2e35e318":"code","78f2255e":"code","5f8c15de":"code","a3577a41":"code","1235e10c":"code","170ad834":"code","3b972534":"code","754afed5":"code","c3da8649":"code","ddb3857f":"code","a40d23df":"code","3d40baca":"code","475e14ea":"code","28c72887":"code","8b00d76f":"code","db5874be":"code","66a691a8":"code","70c81fec":"code","7e895b6b":"code","c9a1f8e5":"code","d8a2b671":"code","bac6398c":"code","a5f715b3":"code","0655c53d":"code","b454be02":"code","893a1ed1":"code","1e8c48e0":"code","cb10b6ab":"code","2a8e16d7":"code","298eb058":"code","5947e743":"code","3800d12a":"code","108a0377":"markdown","37db02dc":"markdown","82899024":"markdown","d5ff0d36":"markdown","85f1f826":"markdown","2bfbb5e2":"markdown","a9e3801e":"markdown","eecb6741":"markdown","2933f987":"markdown","4f47334a":"markdown"},"source":{"c0aa2eac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bdf61a0c":"data_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","9f6c1a46":"data_train.head()","01ed4267":"data_test.head()","94e1e158":"data_train.shape","8dfc6fda":"data_test.shape","2140dd69":"data_test['SalePrice'] = 0","ab740101":"data = pd.concat([data_train, data_test], axis=0)","2553c34a":"data.shape","6be6cef4":"data['SalePrice']","f389f7f1":"data.isnull().sum()","0cd874d3":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6ef6e2c5":"sns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap=\"viridis\")","3b181f1d":"data.info()","f83fc899":"data['LotFrontage']=data['LotFrontage'].fillna(data['LotFrontage'].mean())\ndata['BsmtFinSF1']=data['BsmtFinSF1'].fillna(data['BsmtFinSF1'].mean())\ndata['BsmtFinSF2']=data['BsmtFinSF2'].fillna(data['BsmtFinSF2'].mean())\ndata['BsmtUnfSF']=data['BsmtUnfSF'].fillna(data['BsmtUnfSF'].mean())\ndata['TotalBsmtSF']=data['TotalBsmtSF'].fillna(data['TotalBsmtSF'].mean())\ndata['GarageCars']=data['GarageCars'].fillna(data['GarageCars'].mean())\ndata['GarageArea']=data['GarageArea'].fillna(data['GarageArea'].mean())","5265b0c3":"data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], axis = 1, inplace = True)\ndata.drop(['GarageYrBlt'], axis = 1, inplace = True)","b84a86a4":"data['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])\ndata['MasVnrType'] = data['MasVnrType'].fillna(data['MasVnrType'].mode()[0])\ndata['BsmtQual'] = data['BsmtQual'].fillna(data['BsmtQual'].mode()[0])\ndata['BsmtCond'] = data['BsmtCond'].fillna(data['BsmtCond'].mode()[0])\ndata['BsmtExposure'] = data['BsmtExposure'].fillna(data['BsmtExposure'].mode()[0])\ndata['BsmtFinType1'] = data['BsmtFinType1'].fillna(data['BsmtFinType1'].mode()[0])\ndata['BsmtFinType2'] = data['BsmtFinType2'].fillna(data['BsmtFinType2'].mode()[0])\ndata['FireplaceQu'] = data['FireplaceQu'].fillna(data['FireplaceQu'].mode()[0])\ndata['GarageType'] = data['GarageType'].fillna(data['GarageType'].mode()[0])\ndata['GarageFinish'] = data['GarageFinish'].fillna(data['GarageFinish'].mode()[0])\ndata['GarageQual'] = data['GarageQual'].fillna(data['GarageQual'].mode()[0])\ndata['GarageCond'] = data['GarageCond'].fillna(data['GarageCond'].mode()[0])\ndata['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])\ndata['Utilities'] = data['Utilities'].fillna(data['Utilities'].mode()[0])\ndata['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\ndata['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\ndata['Electrical'] = data['Electrical'].fillna(data['Electrical'].mode()[0])\ndata['Functional'] = data['Functional'].fillna(data['Functional'].mode()[0])\ndata['MasVnrArea']=data['MasVnrArea'].fillna(data['MasVnrArea'].mode()[0])\ndata['BsmtFullBath']=data['BsmtFullBath'].fillna(data['BsmtFullBath'].mode()[0])\ndata['BsmtHalfBath']=data['BsmtHalfBath'].fillna(data['BsmtHalfBath'].mode()[0])\ndata['KitchenQual']=data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])","25e1da62":"data.drop(['Id'], axis = 1, inplace = True)","2e35e318":"data.info()","78f2255e":"data.shape","5f8c15de":"data.isnull().sum()","a3577a41":"sns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap=\"viridis\")","1235e10c":"columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n        'SaleCondition','ExterCond',\n         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n         'CentralAir',\n         'Electrical','KitchenQual','Functional',\n         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']","170ad834":"len(columns)","3b972534":"def category_onehot_multcols(multcolumns):\n    data_final=data\n    i=0\n    for field in multcolumns:\n        \n        df1=pd.get_dummies(data[field],drop_first=True)\n        \n        data.drop([field],axis=1,inplace=True)\n        if i==0:\n            data_final=df1.copy()\n        else:\n            \n            data_final=pd.concat([data_final,df1],axis=1)\n        i=i+1\n       \n        \n    data_final=pd.concat([data,data_final],axis=1)\n        \n    return data_final","754afed5":"data = category_onehot_multcols(columns)","c3da8649":"data.shape","ddb3857f":"data = data.loc[:,~data.columns.duplicated()]","a40d23df":"data.shape","3d40baca":"data_train=data.iloc[:1460,:]\ndata_test=data.iloc[1460:,:]","475e14ea":"X_test = data_test.drop(['SalePrice'],axis=1)","28c72887":"y_train=data_train['SalePrice']\nX_train=data_train.drop(['SalePrice'],axis=1)","8b00d76f":"X_test.shape","db5874be":"X_test","66a691a8":"X_train.shape","70c81fec":"import xgboost\nmodel = xgboost.XGBRegressor()\nmodel.fit(X_train, y_train)","7e895b6b":"y_pred = model.predict(X_test)\ny_train_pred = model.predict(X_train)","c9a1f8e5":"y_pred","d8a2b671":"booster=['gbtree','gblinear']\nbase_score=[0.25,0.5,0.75,1]","bac6398c":"n_estimators = [100]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }","a5f715b3":"regressor = xgboost.XGBRegressor()","0655c53d":"# Set up the random search with 4-fold cross validation\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","b454be02":"# random_cv.fit(X_train, y_train)","893a1ed1":"# random_cv.best_estimator_","1e8c48e0":"regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n       max_depth=2, min_child_weight=1, missing=1, n_estimators=900,\n       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n       silent=True, subsample=1)","cb10b6ab":"regressor.fit(X_train, y_train)","2a8e16d7":"y_pred = regressor.predict(X_test)\ny_train_pred = regressor.predict(X_train)","298eb058":"from sklearn.metrics import mean_squared_error\nmean_squared_error(y_train, y_train_pred, squared=False)","5947e743":"import statsmodels.api as sm\nX_addC = sm.add_constant(X_train)\nresult = sm.OLS(y_train_pred, X_addC).fit()\nprint(result.rsquared, result.rsquared_adj)","3800d12a":"pred=pd.DataFrame(y_pred)\nsub_df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ndatasets=pd.concat([sub_df['Id'],pred],axis=1)\ndatasets.columns=['Id','SalePrice']\ndatasets.to_csv('sample_submission.csv',index=False)\nprint(\"Your submission was successfully saved!\")","108a0377":"## Concatenating both data's","37db02dc":"## Handling Categorical Features","82899024":"## RMSE","d5ff0d36":"## Model with best parameters","85f1f826":"## Handling Missing Values","2bfbb5e2":"## RandomizedSearchCV","a9e3801e":"## R Square\/Adjusted R Square","eecb6741":"## Create Sample Submission file and Submit","2933f987":"## Hyper Parameter Optimization","4f47334a":"## Model Selection"}}