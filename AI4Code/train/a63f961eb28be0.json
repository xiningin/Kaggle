{"cell_type":{"37d048f9":"code","9120f86b":"code","7ebc9eaf":"code","06408a0e":"code","e5883853":"code","b39a49ab":"code","e9e43d25":"code","7e569eb2":"code","3eec8b36":"code","a8f43722":"code","11c5ff75":"code","b235d2de":"code","4ce645d8":"code","d9acf1c2":"code","d1894f72":"code","5ee5cbef":"code","08834bfe":"code","567750e5":"code","6303fa48":"code","9bf19bb6":"code","06cc25c2":"code","754e10b5":"code","d6c96bf1":"code","7c568568":"code","c8a23581":"code","c8b6325a":"code","ec3d9cb6":"code","ee5a7d98":"code","bc8f7c6d":"code","45db538e":"markdown","a006f9bd":"markdown","5b394733":"markdown"},"source":{"37d048f9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","9120f86b":"# Load the data\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","7ebc9eaf":"X_train, x_val, y_train, y_val = train_test_split(\n    train.iloc[:,1:], train.iloc[:,0], test_size=0.1)\n","06408a0e":"X_train.shape,x_val.shape","e5883853":"print(X_train.shape)\nX_train.head()","b39a49ab":"print(test.shape)\ntest.head()","e9e43d25":"y_train.value_counts()","7e569eb2":"\nplt.figure(figsize=(15,7))\ng = sns.countplot(y_train, palette=\"icefire\")\nplt.title(\"Number of digit classes\")\n","3eec8b36":"img = X_train.iloc[1]\nimg = np.asarray(img)\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[3,0])\nplt.axis(\"off\")\nplt.show()","a8f43722":"img = X_train.iloc[3]\nimg = np.asarray(img)\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[3,0])\nplt.axis(\"off\")\nplt.show()","11c5ff75":"X_train = X_train \/ 255.0\nx_val = x_val \/ 255.0\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",x_val.shape)","b235d2de":"# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\nx_val = x_val.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",x_val.shape)","4ce645d8":"# Label Encoding \nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\ny_train = to_categorical(y_train, num_classes = 10)\ny_val = to_categorical(y_val, num_classes = 10)","d9acf1c2":"plt.imshow(X_train[1][:,:,0],cmap='gray')\nplt.show()","d1894f72":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","5ee5cbef":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","08834bfe":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","567750e5":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n","6303fa48":"epochs = 9# for better result increase the epochs\nbatch_size = 90","9bf19bb6":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","06cc25c2":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size,callbacks=[learning_rate_reduction])","754e10b5":"final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","d6c96bf1":"y_hat = model.predict(x_val)\ny_pred = np.argmax(y_hat, axis=1)\ny_true = np.argmax(y_val, axis=1)\ncm = confusion_matrix(y_true, y_pred)\nprint(cm)","7c568568":"test = test.values.reshape(-1, 28, 28, 1)\/255.","c8a23581":"y_hat = model.predict(test, batch_size=90)","c8b6325a":"y_pred = np.argmax(y_hat,axis=1)","ec3d9cb6":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")","ee5a7d98":"submission['Label'] = y_pred\nsubmission.head(10)","bc8f7c6d":"submission.to_csv(\"submission.csv\", index=False, header=True)","45db538e":"# Data Prepration","a006f9bd":"**Lets Look at some image samples**","5b394733":"**visualize number of digits classes**"}}