{"cell_type":{"26003fcc":"code","54a65f17":"code","cfc72ca4":"code","563b424d":"code","ffb1ad14":"code","628762d1":"code","3287bbf6":"code","3b58adb7":"code","8576a0b0":"code","bdc8c0db":"code","77a4fc54":"code","9fc7c588":"markdown"},"source":{"26003fcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54a65f17":"import tensorflow as tf\nfrom keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, Add, AveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom keras.utils import plot_model\nimport matplotlib.pyplot as plt\nfrom keras.layers.merge import concatenate","cfc72ca4":"train = \"..\/input\/digit-recognizer\/train.csv\"\ntest = \"..\/input\/digit-recognizer\/test.csv\"\n\ntrain_df = pd.read_csv(train)\ntest_df = pd.read_csv(test)","563b424d":"train_labels = tf.keras.utils.to_categorical(train_df.pop(\"label\"))\ntrain_df = np.array(train_df.values.reshape(-1, 28, 28, 1))\ntest_df = np.array(test_df.values.reshape(-1, 28, 28, 1))","ffb1ad14":"InputImages = Input(shape=(28, 28, 1))\n\nconv1 = Conv2D(96, (7, 7), activation='relu')(InputImages)\nmaxpool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv1)\nfire2_squeeze = Conv2D(16, (1,1), activation='relu', padding='same')(maxpool1)\nfire2_expand1 = Conv2D(64, (1,1), activation='relu', padding='same')(fire2_squeeze)\nfire2_expand2 = Conv2D(64, (3,3), activation='relu', padding='same')(fire2_squeeze)\nmerge2 = Add()([fire2_expand1,fire2_expand2])\n\nfire3_squeeze = Conv2D(16, (1,1), activation='relu', padding='same')(merge2)\nfire3_expand1 = Conv2D(64, (1,1), activation='relu', padding='same')(fire3_squeeze)\nfire3_expand2 = Conv2D(64, (3,3), activation='relu', padding='same')(fire3_squeeze)\nmerge3 = Add()([fire3_expand1,fire3_expand2])\n\nfire4_squeeze = Conv2D(32, (1,1), activation='relu', padding='same')(merge3)\nfire4_expand1 = Conv2D(128, (1,1), activation='relu', padding='same')(fire4_squeeze)\nfire4_expand2 = Conv2D(128, (3,3), activation='relu', padding='same')(fire4_squeeze)\nmerge4 = Add()([fire4_expand1,fire4_expand2])\n\nmaxpool4 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(merge4)\n\nfire5_squeeze = Conv2D(32, (1,1), activation='relu', padding='same')(maxpool4)\nfire5_expand1 = Conv2D(128, (1,1), activation='relu', padding='same')(fire5_squeeze)\nfire5_expand2 = Conv2D(128, (3,3), activation='relu', padding='same')(fire5_squeeze)\nmerge5 = Add()([fire5_expand1,fire5_expand2])\n\nfire6_squeeze = Conv2D(32, (1,1), activation='relu', padding='same')(merge5)\nfire6_expand1 = Conv2D(128, (1,1), activation='relu', padding='same')(fire6_squeeze)\nfire6_expand2 = Conv2D(128, (3,3), activation='relu', padding='same')(fire6_squeeze)\nmerge6 = Add()([fire6_expand1,fire6_expand2])\n\nfire7_squeeze = Conv2D(48, (1,1), activation='relu', padding='same')(merge6)\nfire7_expand1 = Conv2D(192, (1,1), activation='relu', padding='same')(fire7_squeeze)\nfire7_expand2 = Conv2D(192, (3,3), activation='relu', padding='same')(fire7_squeeze)\nmerge7 = Add()([fire7_expand1,fire7_expand2])\n\nfire8_squeeze = Conv2D(64, (1,1), activation='relu', padding='same')(merge7)\nfire8_expand1 = Conv2D(256, (1,1), activation='relu', padding='same')(fire8_squeeze)\nfire8_expand2 = Conv2D(256, (3,3), activation='relu', padding='same')(fire8_squeeze)\nmerge8 = Add()([fire8_expand1,fire8_expand2])\n\nmaxpool8 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(merge8)\n\nfire9_squeeze = Conv2D(64, (1,1), activation='relu', padding='same')(merge8)\nfire9_expand1 = Conv2D(256, (1,1), activation='relu', padding='same')(fire9_squeeze)\nfire9_expand2 = Conv2D(256, (3,3), activation='relu', padding='same')(fire9_squeeze)\nmerge9 = Add()([fire9_expand1,fire9_expand2])\n\nfire9_dropout = Dropout(0.5)(merge9)\n\nconv10 = Conv2D(10, (1,1), activation='relu', padding='valid')(fire9_dropout)\navg_pooling10 = AveragePooling2D()(conv10)\n\nflatten = Flatten()(avg_pooling10)\n\ndense=Dense(10)(flatten)\n\noutput = Activation(\"softmax\")(dense)\n\nsqueezeNet_model = Model(inputs=InputImages, outputs=output)","628762d1":"squeezeNet_model.summary()","3287bbf6":"plot_model(squeezeNet_model)","3b58adb7":"squeezeNet_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nhistory = squeezeNet_model.fit(train_df, train_labels, epochs=50,  batch_size=64)","8576a0b0":"plt.plot(history.history['accuracy'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","bdc8c0db":"plt.plot(history.history['loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","77a4fc54":"submission = squeezeNet_model.predict(test_df)\nsubmission_labels = np.argmax(submission, axis=1)\nmy_submission = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': submission_labels})\n\nmy_submission.to_csv(\"submission.csv\", index=False)","9fc7c588":"# SquezeeNet Model"}}