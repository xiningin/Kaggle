{"cell_type":{"95e4e1e4":"code","ea7c210d":"code","643c17ab":"code","eb134739":"code","0721384f":"code","1186757e":"code","80670ca8":"code","1e6a01e0":"code","328afd00":"code","9bc52418":"code","8f935629":"code","8d812cee":"code","5dae27bf":"code","6daa37fe":"code","756ee827":"markdown","4ab223fa":"markdown","a74c8b44":"markdown","91386124":"markdown","e73082e0":"markdown","69c87f3a":"markdown","326112f2":"markdown","307607d2":"markdown","7fc0263d":"markdown"},"source":{"95e4e1e4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ea7c210d":"train=pd.read_csv('..\/input\/website-phishing-data-set\/Website Phishing.csv')\ntrain.head(10)","643c17ab":"a=len(train[train.Result==0])\nb=len(train[train.Result==-1])\nc=len(train[train.Result==1])\nprint(a,\"times 0 repeated in Result\")\nprint(b,\"times -1 repeated in Result\")\nprint(c,\"times 1 repeated in Result\")","eb134739":"sns.countplot(train['Result'])","0721384f":"train.info()\ntrain.describe()","1186757e":"X=train.drop('Result',axis=1).values \ny=train['Result'].values","80670ca8":"# transform the labels to 0's , 1's and -1's\nfrom sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()\ny = enc.fit_transform(y)\n\nfor i in range(0, len(X)):\n    X[i] = enc.fit_transform(X[i])","1e6a01e0":"sns.heatmap(train.isnull(),cmap='Blues')","328afd00":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=10)\n\n# Show the results of the split\nprint(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(X_test.shape[0]))","9bc52418":"from sklearn.naive_bayes import MultinomialNB\n\n#create Naive Bayes object\nmodel=MultinomialNB(alpha=1.0)\n\n#Train the model using training data \nmodel.fit(X_train,y_train)","8f935629":"# Split the dataset by class values, returns a dictionary\ndef separate_by_class(dataset):\n    separated = dict()\n    for i in range(len(dataset)):\n        vector = dataset[i]\n        class_value = vector[-1]\n        if (class_value not in separated):\n            separated[class_value] = list()\n            separated[class_value].append(vector)\n    return separated","8d812cee":"#import Evaluation metrics \nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n \n#Test the model using testing data\npredictions = model.predict(X_test)","5dae27bf":"from sklearn.metrics import confusion_matrix,classification_report\ncm=confusion_matrix(y_test,predictions)\nsns.heatmap(cm,annot=True)","6daa37fe":"print(\"f1 score is \",f1_score(y_test,predictions,average='weighted'))\nprint(\"matthews correlation coefficient is \",matthews_corrcoef(y_test,predictions))\n\n#secondary metric,we should not consider accuracy score because the classes are imbalanced.\n\nprint('*****************************************************************')\nprint(\"The accuracy of your Naive bayes on testing data is: \",100.0 *accuracy_score(y_test,predictions))\nprint('*****************************************************')\n","756ee827":"123","4ab223fa":"# STEP #0: Import Libraries","a74c8b44":"# Naive Bayes Algorithm Step 1: Separate By Class","91386124":"# STEP #1: IMPORT DATASET","e73082e0":"# Introduction","69c87f3a":"# STEP #3: Prepare the Data for Training \/ Data Cleaning","326112f2":"# STEP #4: Model Training","307607d2":"# STEP #2: Explore \/Visualze Data set","7fc0263d":"# STEP #5: Model Testing"}}