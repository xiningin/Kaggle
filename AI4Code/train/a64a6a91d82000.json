{"cell_type":{"f500f68d":"code","9776a2c3":"code","e3e0dde7":"code","d842fa42":"code","f0c66c8b":"code","d9aaa623":"code","d0d80395":"code","f27fded4":"code","ff06d1c1":"code","938f1916":"code","02db22bf":"code","2ec16c37":"code","a58b12e8":"code","1457c139":"code","f80d26af":"code","f1c03972":"code","c24e0449":"code","6161af0f":"code","b1fc48d9":"code","af96f9a2":"code","e1a69c92":"code","fb473df3":"code","662f294d":"code","9fda9984":"code","3be4ebf9":"code","25cc17f8":"code","0b5ae191":"markdown","cd627fd9":"markdown"},"source":{"f500f68d":"import pandas as pd\ndf_train=pd.read_csv(\"..\/input\/mercedesbenz-greener-manufacturing\/train.csv\")\ndf_test=pd.read_csv(\"..\/input\/mercedesbenz-greener-manufacturing\/test.csv\")","9776a2c3":"df_train.head()","e3e0dde7":"#getting the target varaible\nimport numpy as np\nnp.setdiff1d(df_train.columns,df_test.columns)","d842fa42":"#joininng training and testing data ,so that cleaning can be done together\ndf=pd.concat([df_train,df_test],keys=['x','y'])\n#df=df.drop(columns=['y'])\ndf.shape","f0c66c8b":"#checking the missing value and the percentage\ndef miss_val(df):\n   miss_col=df[[col for col in df.columns if df[col].isnull().any() == True]].isna().sum()\n   con=miss_col\/df[[col for col in df.columns if df[col].isnull().any() == True]].isna().count()\n   return pd.concat([miss_col,con],keys=['missing_count','percentage'],axis=1).sort_values('percentage',ascending=False)\nmiss_val(df)","d9aaa623":"#checking the datatypes\nprint(df.select_dtypes('object').shape)\nprint('********')\nprint(df.select_dtypes('int64').shape)\nprint('********')\nprint(df.select_dtypes('float').shape)\nprint('********')\nprint(df.select_dtypes('bool').shape)","d0d80395":"#encoding the cateogrical variables\nfrom sklearn import preprocessing\nen_label = preprocessing.LabelEncoder()\n\nfor i in df.select_dtypes('object'):\n    df[i]= en_label.fit_transform(df[i])","f27fded4":"#Remove Features with Zero Variance\nfrom sklearn.feature_selection import VarianceThreshold\n#threshold_n=0.05\nsel = VarianceThreshold(threshold=.001)\nsel_var=sel.fit_transform(df)\ndf1=df[df.columns[sel.get_support(indices=True)]] ","ff06d1c1":"#Removing Features which are Highly Correlated\ndef correlation(dataset, threshold):\n    col_corr = set() # Set of all names of correlated columns\n    corr_matrix = dataset.corr() # Correlation Matrix\n    \n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold:    # we are interested in absolute coeff value\n                    \n                colname = corr_matrix.columns[i] # getting the name of columns\n                col_corr.add(colname)\n    return(col_corr)\n\nfeatures_no_output = df1.drop(columns=['y'])\n\ncorr_features = correlation(features_no_output,0.85) # Setting Threshold as features having correlation above 85%\nprint(\"\\n\")\nprint(\"Correlated Features :\\n \",corr_features)\nprint(\"\\n\")\nprint(\"No. of Features Correlated: \",len(corr_features))","938f1916":"#dropping the highly correlated values\nfor i in [df1]:\n    df1.drop(columns=corr_features,inplace = True)","02db22bf":"df1.shape","2ec16c37":"#seprating the original train and test data \ntrain_new=df1.loc[\"x\"]\ntest_new=df1.loc[\"y\"].drop(columns=['y'])\ntest_new.shape","a58b12e8":"#Getting x and y\nimport numpy as np\nx=train_new.drop(columns=['y'])\ny=np.log(train_new.y)","1457c139":"#trsin_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import mutual_info_regression, mutual_info_classif\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=10)","f80d26af":"#normalising the dataset\nfrom sklearn.preprocessing import StandardScaler\nstdSC=StandardScaler()\nx_train_std=stdSC.fit_transform(x_train)\nx_test_std=stdSC.fit_transform(x_test)\nx_final_std=stdSC.fit_transform(test_new)","f1c03972":"x_train_std.shape","c24e0449":"#Feature engineering\nfrom sklearn.decomposition import PCA\nPCAModel=PCA(210)\nx_train_com=PCAModel.fit_transform(x_train_std)\nx_test_com=PCAModel.transform(x_test_std)\ntest_new_com=PCAModel.transform(x_final_std)\nPCAModel.explained_variance_\nPCAModel.explained_variance_ratio_*100\nimport numpy as np\nnp.cumsum(PCAModel.explained_variance_ratio_*100)","6161af0f":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error,r2_score\nrfr=RandomForestRegressor( max_depth=7, min_samples_leaf=3,n_estimators=100,\n                       min_samples_split=2)\nrfr.fit(x_train,y_train)\ny_predictrfr = rfr.predict(x_train)\n\n#here we can check our model score\nprint(rfr.score(x_train,y_train))\nprint(rfr.score(x_test,y_test))\nprint('RMSE:' + str(np.sqrt(mean_squared_error(y_test,rfr.predict(x_test)))))\n\n#print(classification_report(y_test,prediction))\n","b1fc48d9":"from sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\nmodel.fit(x_train_com,y_train)\nprint('LR train model:' + str( model.score(x_train_com,y_train)))\nprint('LR test model:' + str(model.score(x_test_com,y_test)))","af96f9a2":"from xgboost import XGBRegressor\nXGB=XGBRegressor()\nXGB.fit(x_train_std,y_train)\n\nprint('XGB train model:' + str( XGB.score(x_train_std,y_train)))\nprint('XGB test  model:' + str(XGB.score(x_test_std,y_test)))","e1a69c92":"from sklearn.linear_model import Lasso\n\nlassoModel=Lasso(alpha=.0001)\nlassoModel.fit(x_train_com,y_train)\nprint(\"Train Score (Linear):\",lassoModel.score(x_train_com,y_train))\nprint(\"Test Score (Linear):\",lassoModel.score(x_test_com,y_test))","fb473df3":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error,r2_score\nRModel=Ridge(alpha=.0001)\nRModel.fit(x_train_com,y_train)\nprint(\"Train Score (Linear):\",RModel.score(x_train_com,y_train))\nprint(\"Test Score (Linear):\",RModel.score(x_test_com,y_test))\nprint('RMSE:' + str(np.sqrt(mean_squared_error(y_test,RModel.predict(x_test_com)))))","662f294d":"#ElasticNet\nfrom sklearn.linear_model import ElasticNet\n\nEModel=ElasticNet(alpha=.0001)\nEModel.fit(x_train_com,y_train)\nprint(\"Train Score (Linear):\",EModel.score(x_train_com,y_train))\nprint(\"Test Score (Linear):\",EModel.score(x_test_com,y_test))","9fda9984":"#prediction of the test_data\nrfr.predict(test_new)","3be4ebf9":"\nA=pd.DataFrame({'ID':test_new.ID,'y_test':rfr.predict(test_new)})","25cc17f8":"A['final_y'] = np.exp(A['y_test'])\nA[['ID','final_y']]","0b5ae191":"### Model building","cd627fd9":"### we can take the rfr model as our final model as the accuracy is 64%."}}