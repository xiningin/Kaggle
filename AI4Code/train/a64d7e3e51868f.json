{"cell_type":{"b01a95e3":"code","b1cae91e":"code","52a48ba8":"code","4d3c2e23":"code","5520b884":"code","f94ae116":"code","f1c8a13f":"code","8d76f51d":"code","f510a037":"code","616ef494":"code","f24e7685":"code","73de515f":"code","5565225b":"code","8e6cf629":"code","016cd30c":"code","c2e235ae":"code","d4716f9a":"code","0b901cb8":"code","660cccc8":"code","14832a84":"code","1aa8ef4a":"code","1fa030ee":"code","6772d2f9":"code","80ee6c5d":"code","d42b14bd":"code","37afccbc":"code","a306e3aa":"code","e85fa9a5":"code","ec5cd88d":"code","35b2060e":"code","89bbf8ba":"code","aaa11768":"code","e510a982":"markdown","5a364de8":"markdown","e2d9a402":"markdown"},"source":{"b01a95e3":"%matplotlib inline\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot","b1cae91e":"import os\nprint(os.listdir(\"..\/input\"))","52a48ba8":"import os.path\nimport itertools\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn import cluster, datasets, mixture\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfrom keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Lambda, \\\n    Conv1D, Conv2D, Conv3D, \\\n    Conv2DTranspose, \\\n    AveragePooling1D, AveragePooling2D, \\\n    MaxPooling1D, MaxPooling2D, MaxPooling3D, \\\n    GlobalAveragePooling1D, GlobalAveragePooling2D, \\\n    GlobalMaxPooling1D, GlobalMaxPooling2D, GlobalMaxPooling3D, \\\n    LocallyConnected1D, LocallyConnected2D, \\\n    concatenate, Flatten, Average, Activation, \\\n    RepeatVector, Permute, Reshape, Dot, \\\n    multiply, dot, add, \\\n    PReLU, \\\n    Bidirectional, TimeDistributed, \\\n    SpatialDropout1D, \\\n    BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras import losses\nfrom keras.callbacks import BaseLogger, ProgbarLogger, Callback, History\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras.metrics import categorical_accuracy\nfrom keras.constraints import maxnorm, non_neg\nfrom keras.optimizers import RMSprop\nfrom keras.utils import to_categorical, plot_model\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras","4d3c2e23":"from PIL import Image\nfrom zipfile import ZipFile\nimport h5py\nimport cv2\nfrom tqdm import tqdm","5520b884":"ls -la ..\/input","f94ae116":"src_dir = '..\/input'\ntrain_csv = pd.read_csv(os.path.join(src_dir, 'train.csv'))\nprint(train_csv.shape)\ntrain_csv.head()","f1c8a13f":"x_train0 = train_csv.iloc[:,2:].values\nprint(x_train0.shape)\nx_train0","8d76f51d":"y_train0 = train_csv.target.values\nprint(y_train0.shape)\ny_train0","f510a037":"y_cat_train0 = to_categorical(y_train0)\nprint(y_cat_train0.shape)\ny_cat_train0[:5]","616ef494":"test_csv = pd.read_csv(os.path.join(src_dir, 'test.csv'))\nprint(test_csv.shape)\ntest_csv.head()","f24e7685":"x_test = test_csv.iloc[:,1:].values\nprint(x_test.shape)\nx_test","73de515f":"sample_submission_csv = pd.read_csv(os.path.join(src_dir, 'sample_submission.csv'))\nprint(sample_submission_csv.shape)\nsample_submission_csv.head()","5565225b":"import warnings\nwarnings.filterwarnings('ignore')","8e6cf629":"from sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, validation_curve\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances","016cd30c":"# some heuristic settings\nrfe_min_features = 12\nrfe_step = 15\nrfe_cv = 20\nsss_n_splits = 20\nsss_test_size = 0.35\ngrid_search_cv = 20\nnoise_std = 0.01\nr2_threshold = 0.185\nrandom_seed = 213\n\nnp.random.seed(random_seed)","c2e235ae":"def scoring_roc_auc(y, y_pred):\n    try:\n        return roc_auc_score(y, y_pred)\n    except:\n        return 0.5","d4716f9a":"x = RobustScaler().fit_transform(np.concatenate((x_train0, x_test), axis=0))\nx_train0 = x[:250]\nx_test = x[250:]","0b901cb8":"x_train0 += np.random.normal(0, noise_std, x_train0.shape)","660cccc8":"robust_roc_auc = make_scorer(scoring_roc_auc)\n\n# define model and its parameters\n# model = Lasso(alpha=0.031, tol=0.01, random_state=random_seed, selection='random')\n\nparam_grid = {\n            'alpha' : [0.022, 0.021, 0.02, 0.019, 0.023, 0.024, 0.025, 0.026, 0.027, 0.029, 0.031],\n            'tol'   : [0.0013, 0.0014, 0.001, 0.0015, 0.0011, 0.0012, 0.0016, 0.0017]\n        }\n# param_grid = {\n#             'alpha' : [0.022, 0.021, 0.02, 0.019, 0.023, 0.024, 0.025, 0.026, 0.027, 0.029, 0.031],\n#         }\n\n# define recursive elimination feature selector\n# feature_selector = RFECV(model,\n#                          min_features_to_select=rfe_min_features,\n#                          scoring=robust_roc_auc,\n#                          step=rfe_step,\n#                          verbose=0,\n#                          cv=rfe_cv,\n#                          n_jobs=-1)","14832a84":"class RFECV_wr(RFECV):\n    \n    def __init__(self, alpha=1.0, tol=0.0001, # for lasso\n                       step=1, min_features_to_select=1, cv='warn',\n                       scoring=None, verbose=0, n_jobs=None):\n        estimator = Lasso(alpha=0.031, tol=0.001,\n                          random_state=random_seed, selection='random')\n        super().__init__(estimator, step=step,\n                         min_features_to_select=min_features_to_select,\n                         cv=cv, scoring=scoring, verbose=verbose, n_jobs=n_jobs)\n    \n    def set_params(self, **params):\n        if 'alpha' in params:\n            self.estimator.set_params(alpha=params['alpha'])\n        if 'tol' in params:\n            self.estimator.set_params(tol=params['tol'])\n        return self\n\nfeature_selector2 = RFECV_wr(min_features_to_select=rfe_min_features,\n                             scoring=robust_roc_auc,\n                             step=rfe_step,\n                             verbose=0,\n                             cv=rfe_cv,\n                             n_jobs=-1)","1aa8ef4a":"feature_selector2.get_params()","1fa030ee":"param_range = np.logspace(-1.7, -1.5, 10)\nparam_range","6772d2f9":"scorer = make_scorer(roc_auc_score)\nscorer\ncv_splitter = StratifiedShuffleSplit(n_splits=5, test_size=0.35, random_state=0)\ncv_splitter.get_n_splits(x_train0, y_train0)","80ee6c5d":"train_scores, test_scores = validation_curve(\n    feature_selector2, x_train0, y_train0,\n    param_name=\"alpha\", param_range=param_range,\n    cv=cv_splitter, scoring=scorer, n_jobs=None, verbose=0)","d42b14bd":"train_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\ntrain_scores_mean","37afccbc":"test_scores_mean","a306e3aa":"plt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"Score\")\nplt.ylim(0.0, 1.1)\nlw = 2\nplt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n             color=\"darkorange\", lw=lw)\nplt.fill_between(param_range, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.2,\n                 color=\"darkorange\", lw=lw)\nplt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n             color=\"navy\", lw=lw)\nplt.fill_between(param_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.2,\n                 color=\"navy\", lw=lw)\nplt.legend(loc=\"best\")","e85fa9a5":"print(\"counter | val_mse  |  val_mae  |  val_roc  |  val_r2    |  alpha     | feature_count \")\nprint(\"-------------------------------------------------------------------------------------\")\n\nimportances = np.zeros((300,))\npredictions = pd.DataFrame()\ncounter = 0\nfor train_index, val_index in StratifiedShuffleSplit(n_splits=sss_n_splits, test_size=sss_test_size, random_state=random_seed).split(x_train0, y_train0):\n    X, val_X = x_train0[train_index], x_train0[val_index]\n    y, val_y = y_train0[train_index], y_train0[val_index]\n    \n    # get the best features and the best paramaters at the same time\n    grid_search = GridSearchCV(feature_selector2,\n                               param_grid=param_grid,\n                               verbose=0,\n                               n_jobs=None,\n                               scoring=robust_roc_auc,\n                               cv=grid_search_cv)\n    \n    grid_search.fit(X, y)\n    \n    # score our fitted model on validation data\n    val_y_pred = grid_search.best_estimator_.predict(val_X)\n    val_mse = mean_squared_error(val_y, val_y_pred)\n    val_mae = mean_absolute_error(val_y, val_y_pred)\n    val_roc = roc_auc_score(val_y, val_y_pred)\n    val_cos = cosine_similarity(val_y.reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n    val_dst = euclidean_distances(val_y.reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n    val_r2  = r2_score(val_y, val_y_pred)\n    \n    # if model did well on validation, save its prediction on test data, using only important features\n    # r2_threshold (0.185) is a heuristic threshold for r2 error\n    # you can use any other metric\/metric combination that works for you\n    if val_r2 > r2_threshold:\n        message = '<-- OK'\n        prediction = grid_search.best_estimator_.predict(x_test)\n        predictions = pd.concat([predictions, pd.DataFrame(prediction)], axis=1)\n        importances += grid_search.best_estimator_.support_.astype(int)\n    else:\n        message = '<-- skipping'\n\n    print(\"{0:2}      | {1:.4f}   |  {2:.4f}   |  {3:.4f}   |  {4:.4f}    |  {5:.4f}    |  {6:3}         {7}  \".format(\n        counter,\n        val_mse,\n        val_mae,\n        val_roc,\n        val_r2,\n        grid_search.best_estimator_.estimator_.get_params()['alpha'],\n        grid_search.best_estimator_.n_features_,\n        message))\n    \n    counter += 1","ec5cd88d":"grid_search.best_estimator_.estimator_.get_params()","35b2060e":"mean_pred = pd.DataFrame(predictions.mean(axis=1))\nmean_pred.index += 250\nmean_pred.columns = ['target']\nmean_pred.to_csv('submission.csv', index_label='id', index=True)\nmean_pred.head()","89bbf8ba":"importances","aaa11768":"print(importances.shape)\nsns.distplot(importances)","e510a982":"### Create model","5a364de8":"\nThank you!  \n[Robust, Lasso, Patches with RFE & GS](https:\/\/www.kaggle.com\/featureblind\/robust-lasso-patches-with-rfe-gs)","e2d9a402":"### load data"}}