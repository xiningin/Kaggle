{"cell_type":{"79c3ce04":"code","c63a17cf":"code","fb3c4291":"code","992de249":"code","d7750b23":"code","1ea9c5d1":"code","d95e05e2":"code","1c0a9710":"code","b2b79e0a":"code","d3828bd9":"code","4a2de450":"code","31104e2b":"code","b68ece16":"code","8c0c7f5c":"code","b9106ae5":"code","f3304680":"code","ed4693ff":"code","576ae479":"code","ab3a0781":"markdown"},"source":{"79c3ce04":"import numpy as np\nimport pandas as pd\n%matplotlib inline \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Dropout, Conv1D, MaxPool1D, BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","c63a17cf":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","fb3c4291":"train","992de249":"test","d7750b23":"print(train.isnull().sum())","1ea9c5d1":"print(test.isnull().sum())","d95e05e2":"train['Title'] = train.Name.str.extract(' ([A-Za-z]+).', expand=False) \ntrain['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')\nTitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \ntrain['Title'] = train['Title'].map(Title_mapping) \ntrain['Title'] = train['Title'].fillna(0)\ndel train['Name']\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\ntrain[\"Sex\"] = train[\"Sex\"].map({\"male\" : 0, \"female\" : 1})\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\ntrain[\"Embarked\"] = train[\"Embarked\"].map({\"S\" : 0, \"Q\" : 1, \"C\" : 2})\ntrain['Ticket_Lett'] = train['Ticket'].apply(lambda x: str(x)[0])\ntrain['Ticket_Lett'] = train['Ticket_Lett'].apply(lambda x: str(x)) \ntrain['Ticket_Lett'] = np.where((train['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), train['Ticket_Lett'], np.where((train['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0')) \ntrain['Ticket_Lett']=train['Ticket_Lett'].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3)\ndel train['Ticket'] \ntrain['Cabin_Lett'] = train['Cabin'].apply(lambda x: str(x)[0]) \ntrain['Cabin_Lett'] = train['Cabin_Lett'].apply(lambda x: str(x)) \ntrain['Cabin_Lett'] = np.where((train['Cabin_Lett']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']),train['Cabin_Lett'], np.where((train['Cabin_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0'))\ntrain['Cabin_Lett']=train['Cabin_Lett'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\ndel train['Cabin'] \ntrain[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntrain","1c0a9710":"test['Title'] = test.Name.str.extract(' ([A-Za-z]+).', expand=False) \ntest['Title'] = test['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')\nTitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \ntest['Title'] = test['Title'].map(Title_mapping) \ntest['Title'] = test['Title'].fillna(0)\ndel test['Name']\ntest[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\ntest[\"Sex\"] = test[\"Sex\"].map({\"male\" : 0, \"female\" : 1})\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\ntest[\"Embarked\"] = test[\"Embarked\"].map({\"S\" : 0, \"Q\" : 1, \"C\" : 2})\ntest['Ticket_Lett'] = test['Ticket'].apply(lambda x: str(x)[0])\ntest['Ticket_Lett'] = test['Ticket_Lett'].apply(lambda x: str(x)) \ntest['Ticket_Lett'] = np.where((test['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), test['Ticket_Lett'], np.where((test['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0')) \ntest['Ticket_Lett']=test['Ticket_Lett'].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3)\ndel test['Ticket'] \ntest['Cabin_Lett'] = test['Cabin'].apply(lambda x: str(x)[0]) \ntest['Cabin_Lett'] = test['Cabin_Lett'].apply(lambda x: str(x)) \ntest['Cabin_Lett'] = np.where((test['Cabin_Lett']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']),test['Cabin_Lett'], np.where((test['Cabin_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0'))\ntest['Cabin_Lett']=test['Cabin_Lett'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\ndel test['Cabin'] \ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\n\ntest","b2b79e0a":"train_x = train.drop(['PassengerId'], axis=1)\ntrainx_corr = train_x.corr()\nplt.figure(figsize=(8, 8))\nsns.heatmap(trainx_corr, cmap=\"Reds\", annot=True, fmt=\"1.2f\")\ntrain_x = train_x.drop(['Survived'], axis=1)\ntrain_y = train['Survived']\n\ntest_x= test.drop(['PassengerId'], axis=1)","d3828bd9":"stdsc = StandardScaler()\ntrainx_std = stdsc.fit_transform(train_x)\ntestx_std = stdsc.fit_transform(test_x)\n\nX_train = np.reshape(trainx_std, (-1, 11, 1))\nY_train = to_categorical(train_y, num_classes = 2)\nX_test = np.reshape(testx_std, (-1, 11, 1))","4a2de450":"model = Sequential()\nmodel.add(Conv1D(32, 5, padding='same', input_shape=(11, 1), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Conv1D(32, 5, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(MaxPool1D(2, padding='same'))\nmodel.add(Conv1D(64, 3, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.summary()","31104e2b":"plot_model(model, to_file='model.png', show_layer_names=False, show_shapes=True)","b68ece16":"model.compile(optimizer = \"Adam\" , loss='binary_crossentropy', metrics=[\"accuracy\"])","8c0c7f5c":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","b9106ae5":"history = model.fit(X_train, Y_train, epochs = 30, verbose = 2, validation_split = 0.2, callbacks=[learning_rate_reduction])","f3304680":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","ed4693ff":"pred_proba = model.predict(X_test)[:,1]\npred = np.where(pred_proba > 0.5,1,0)","576ae479":"submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred})\nsubmission.to_csv('submission_titanic.csv', index=False)","ab3a0781":" **Deep Learning to Solve Titanic**"}}