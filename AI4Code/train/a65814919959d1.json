{"cell_type":{"76331999":"code","a1056889":"code","50fe2a7e":"code","f722af55":"code","1c86e1ea":"code","bd25aecf":"code","dd3bf0f7":"code","1450d2ac":"code","f1ca5bdb":"code","2aca4a8a":"code","c5433ca0":"code","ba8d961e":"code","351f392a":"code","f658fe2b":"code","d6333841":"code","26720e60":"code","7af7f842":"code","8c15e8c9":"code","a3c1d2ce":"code","90bcc972":"code","5ed12184":"code","3d08cbc1":"code","4a0ed7a4":"code","a76a2e91":"code","d4f383a4":"code","7f04dc8e":"code","f2510f7d":"code","42c958ff":"code","7ba3b35c":"code","eba78053":"code","1366f2e9":"code","fe322b1a":"code","191bf030":"code","792f6f91":"code","7ecc333a":"code","b9803f79":"code","b223fd81":"code","f2e66cf0":"code","32c46eb6":"code","db66cfc3":"code","4ed02906":"code","62b0aca0":"code","c6c22521":"code","9db0bf38":"code","d9df9a68":"code","dc26ac8c":"code","1d7be92f":"code","eb959e75":"code","4a4a89a6":"code","af9a7d77":"code","92c1c8b5":"code","55d4862f":"code","6892abdc":"code","32ebc0e9":"code","7e98e780":"code","a06c0139":"code","b3473c39":"code","b709c095":"code","29c37363":"code","8a558090":"code","c687d623":"code","fad7aca0":"code","c62b1681":"code","ee6ee9cd":"code","200ff158":"code","42b95346":"code","ebdbde79":"code","ada47c53":"code","f9d2a811":"code","f8f2986e":"code","64effa9c":"code","ae7b9278":"code","99f99088":"code","5643852a":"code","5f2ab3c1":"code","94326966":"code","b731f625":"code","176993e6":"code","abe21723":"code","3dfd274e":"code","4c07563a":"code","673286b9":"code","17280671":"code","0aec354e":"code","d71d65f5":"code","692bb660":"code","9c59f525":"code","1786c6de":"code","d3e6130d":"code","a36ca48d":"code","215eb081":"code","3bfed219":"code","3b724065":"code","873c501a":"code","8e59e264":"code","89b9b6ea":"code","49bb4aad":"code","7d7600f0":"code","bc74fe6d":"code","497fa13f":"code","d8f6795d":"code","10a0d50b":"code","e8d53c1e":"code","a3ddc12f":"code","2ebaf8f2":"code","62b8548f":"code","632c4108":"code","aa3fe619":"code","7a47a6f0":"code","50f71aa4":"code","499248a9":"code","a1ff57b7":"code","ae5dc067":"code","766098fa":"code","6e6fc752":"code","cb3b0fe8":"code","92a1d890":"code","0687198b":"code","502c87a9":"code","57623c7a":"code","e0a8ea6b":"code","971f6446":"markdown","5a64530e":"markdown","4ae629b7":"markdown","9f2efc38":"markdown","a5777d91":"markdown","6715e9e3":"markdown","783a3bff":"markdown","45839597":"markdown","e1f53852":"markdown","8a89f451":"markdown","921e2f1f":"markdown","752f9c71":"markdown","4ae695c6":"markdown","7aa2e3b1":"markdown","4d88aa75":"markdown","328ffbf2":"markdown","47d9b08d":"markdown","4bf41894":"markdown","9da82417":"markdown","78999821":"markdown","520f02e9":"markdown","34fcf83a":"markdown","c1efa2a1":"markdown","ffd0daa9":"markdown","0325da54":"markdown","65661351":"markdown","9c5821b0":"markdown","c3d3d059":"markdown","adec9498":"markdown","c9d7166c":"markdown","626487f1":"markdown","3678b4ed":"markdown","2ec0d841":"markdown","fee2eb09":"markdown","bb35668c":"markdown","260b08e1":"markdown","37656ade":"markdown","ea159c9e":"markdown","e81b0972":"markdown","60a0f4cf":"markdown","5a4fe1b9":"markdown","6d0d3187":"markdown","6aa39b7e":"markdown","9a892df1":"markdown","ae376e1e":"markdown","b2a10414":"markdown","0e88560e":"markdown","5a8784bd":"markdown","2168847e":"markdown","8e42fa66":"markdown","efebf625":"markdown","42180f73":"markdown","581621bf":"markdown","b167c334":"markdown","4e9eadda":"markdown","a40821f4":"markdown","097c1d18":"markdown","55b4bd47":"markdown","3f42e172":"markdown","35b7b72a":"markdown","e2c60d8b":"markdown","afe6e5d7":"markdown","e2f1bc38":"markdown","581492de":"markdown","28ffa28b":"markdown","eab8943e":"markdown","a93cb55b":"markdown","36299302":"markdown"},"source":{"76331999":"import pandas as pd #For Data Analysis\nimport numpy as np # For numerical Computations\nimport matplotlib.pyplot as plt # For Visualization\nimport seaborn as sns # For Visualization\nimport re # For Capturing words\nplt.style.use('fivethirtyeight')","a1056889":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')","50fe2a7e":"# Checking the Datatypes of the columns\ntrain_df.info()","f722af55":"test_df.info()","1c86e1ea":"train_df.head()","bd25aecf":"# Converting the column names to lower_case and replacing some headings\ntrain_df.columns = [x.lower() for x in train_df.columns]\ntrain_df.columns","dd3bf0f7":"# Doing the same for test_df\ntest_df.columns = [x.lower() for x in test_df.columns]","1450d2ac":"train_df.rename(columns={\n            \"passengerid\":\"passenger_id\",\n            \"pclass\":\"passenger_class\",\n            \"sibsp\":\"sibling_spouse\",\n            \"parch\":\"parent_children\"\n        }, inplace=True)","f1ca5bdb":"# Doing the same for train df\ntest_df.rename(columns={\n            \"passengerid\":\"passenger_id\",\n            \"pclass\":\"passenger_class\",\n            \"sibsp\":\"sibling_spouse\",\n            \"parch\":\"parent_children\"\n        }, inplace=True)","2aca4a8a":"train_df.head()","c5433ca0":"train_df.isnull().sum()","ba8d961e":"train_df.isnull().sum().plot(kind='bar')","351f392a":"# Pictorial\nsns.heatmap(train_df.isnull(), cbar=False)\n","f658fe2b":"train_df[[\"passenger_id\"]]","d6333841":"plt.figure(figsize=(12,5))\ng = sns.FacetGrid(train_df, col='survived',size=5)\ng = g.map(sns.distplot, \"passenger_id\")\nplt.show()","26720e60":"train_df.passenger_class.unique()","7af7f842":"train_df.passenger_class.value_counts().plot(kind='pie')","8c15e8c9":"train_df.passenger_class.value_counts().plot(kind='bar')","a3c1d2ce":"plt.figure(figsize=(12,5))\nsns.countplot(\"passenger_class\", data=train_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"P Class\", fontsize=18)\nplt.title(\"P Class Distribution \", fontsize=20)","90bcc972":"train_df.groupby(\"passenger_class\").survived.value_counts(normalize=True).sort_index()","5ed12184":"train_df.name.unique()","3d08cbc1":"# Collecting the salutation words\ntrain_df.name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip())","4a0ed7a4":"# Assign these values to a new column\ntrain_df[\"salutation\"] = train_df.name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip())\n\n# Doing the same for Tst data\ntest_df[\"salutation\"] = test_df.name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip())\n","a76a2e91":"train_df.salutation.value_counts()","d4f383a4":"#plotting countplot for salutations\nplt.figure(figsize=(16,5))\nsns.countplot(x='salutation', data=train_df)\nplt.xlabel(\"Salutation\", fontsize=16) \nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Salutation Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show()","7f04dc8e":"# Creating Categories\nsalutation_dict = {\n\"Capt\": \"0\",\n\"Col\": \"0\",\n\"Major\": \"0\",\n\"Dr\": \"0\",\n\"Rev\": \"0\",\n\"Jonkheer\": \"1\",\n\"Don\": \"1\",\n\"Sir\" :  \"1\",\n\"the Countess\":\"1\",\n\"Dona\": \"1\",\n\"Lady\" : \"1\",\n\"Mme\": \"2\",\n\"Ms\": \"2\",\n\"Mrs\" : \"2\",\n\"Mlle\":  \"3\",\n\"Miss\" : \"3\",\n\"Mr\" :   \"4\",\n\"Master\": \"5\"\n}","f2510f7d":"train_df['salutation'] = train_df.salutation.map(salutation_dict)\n\n# Doing the same for test data\ntest_df['salutation'] = test_df.salutation.map(salutation_dict)\n","42c958ff":"#plotting countplot for salutations\nplt.figure(figsize=(16,5))\nsns.countplot(x='salutation', data=train_df)\nplt.xlabel(\"Salutation\", fontsize=16) \nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Salutation Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show()","7ba3b35c":"train_df.salutation = train_df.salutation.astype('float64')\n\n# Doing the same for Test\ntest_df.salutation = test_df.salutation.astype('float64')","eba78053":"train_df.salutation.value_counts().plot(kind='pie')","1366f2e9":"#plotting countplot for salutations\nplt.figure(figsize=(16,5))\nsns.countplot(x='salutation', data=train_df, hue=\"survived\")\nplt.xlabel(\"Salutation\", fontsize=16) \nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Salutation Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show()","fe322b1a":"train_df.groupby(\"salutation\").survived.value_counts(normalize=True).sort_index()","191bf030":"train_df.groupby(\"salutation\").survived.value_counts(normalize=True).sort_index().unstack()","792f6f91":"sal_sur_index = train_df[(train_df.salutation.isin([1.0, 2.0, 3.0, 5.0]))].index\n\nsal_sur_index_test = test_df[(test_df.salutation.isin([1.0, 2.0, 3.0, 5.0]))].index","7ecc333a":"train_df[\"sal_sur\"] = 0\ntrain_df.loc[sal_sur_index, \"sal_sur\"] = 1\n\n# Doing the same for test data\n\ntest_df[\"sal_sur\"] = 0\ntest_df.loc[sal_sur_index_test, \"sal_sur\"] = 1","b9803f79":"train_df[[\"sal_sur\", \"survived\"]].head()","b223fd81":"#plotting countplot for salutations Survived\nplt.figure(figsize=(16,5))\nsns.countplot(x='sal_sur', data=train_df, hue=\"survived\")\nplt.xlabel(\"Salutation Survived\", fontsize=16) \nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Salutation Survived Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show()","f2e66cf0":"# Unique values of gender\ntrain_df.sex.unique()","32c46eb6":"# Percentage of people\ntrain_df.sex.value_counts(normalize=True)","db66cfc3":"train_df.sex.value_counts().plot(kind='pie')","4ed02906":"train_df.sex.value_counts().plot(kind='bar')","62b0aca0":"plt.figure(figsize=(12,5))\nsns.countplot(\"sex\", data=train_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Sex\", fontsize=18)\nplt.title(\"Sex Distribution \", fontsize=20)","c6c22521":"train_df.groupby(\"sex\").survived.value_counts(normalize=True).sort_index()","9db0bf38":"train_df[['sex', 'survived']].groupby(['sex'], as_index=False).mean().sort_values(by='survived', ascending=False)","d9df9a68":"train_df.age.isnull().sum()","dc26ac8c":"# Creating a Group based on Sex, Passenger, Salutation\nage_group = train_df.groupby([\"sex\",\"passenger_class\",\"salutation\"])[\"age\"]\n\n# Doing the same for test data\nage_group_test = test_df.groupby([\"sex\",\"passenger_class\",\"salutation\"])[\"age\"]\n","1d7be92f":"# Median of each grop\nage_group.median()","eb959e75":"age_group.transform('median')","4a4a89a6":"# Now we can apply the missing values\ntrain_df.loc[train_df.age.isnull(), 'age'] = age_group.transform('median')\n\n# Doing the same for test data\ntest_df.loc[test_df.age.isnull(), 'age'] = age_group_test.transform('median')\n","af9a7d77":"# For Checking purpose\ntrain_df.age.isnull().sum()","92c1c8b5":"plt.figure(figsize=(12,5))\nsns.histplot(x='age', data=train_df)\nplt.title(\"Total Distribuition and density by Age\")\nplt.xlabel(\"Age\")\nplt.show()","55d4862f":"plt.figure(figsize=(12,5))\nsns.histplot(x='age', data=train_df, hue=\"survived\")\nplt.title(\"Distribuition and density by Age and Survival\")\nplt.xlabel(\"Age\")\nplt.show()","6892abdc":"plt.figure(figsize=(12,5))\nsns.distplot(x=train_df.age, bins=25)\nplt.title(\"Distribuition and density by Age\")\nplt.xlabel(\"Age\")\nplt.show()","32ebc0e9":"plt.figure(figsize=(12,5))\ng = sns.FacetGrid(train_df, col='survived',size=5)\ng = g.map(sns.distplot, \"age\")\nplt.show()","7e98e780":"male_df = train_df[train_df.sex=='male']\nplt.figure(figsize=(12,5))\ng = sns.FacetGrid(male_df, col='survived',size=5)\ng = g.map(sns.distplot, \"age\")\nplt.show()","a06c0139":"female_df = train_df[train_df.sex=='female']\nplt.figure(figsize=(12,5))\ng = sns.FacetGrid(female_df, col='survived',size=5)\ng = g.map(sns.distplot, \"age\")\nplt.show()","b3473c39":"age_index = train_df[((train_df.sex=='male') & ( (train_df.age >= 20) & (train_df.age <= 40) )) |\n         ((train_df.sex=='female') & ( (train_df.age >= 18) & (train_df.age <= 40) ))   \n        ].index","b709c095":"train_df[\"age_sur\"] = 0\ntrain_df.loc[age_index, \"age_sur\"] = 1","29c37363":"train_df[[\"age_sur\",\"survived\"]]","8a558090":"train_df.groupby(\"age_sur\").survived.value_counts()","c687d623":"train_df[\"age_sur\"] = 0\ntrain_df.loc[age_index, \"age_sur\"] = 1\nplt.figure(figsize=(12,5))\nsns.countplot(\"age_sur\", data=train_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Dist\", fontsize=18)\nplt.title(\"Age Dist \", fontsize=20)","fad7aca0":"plt.figure(figsize=(12,5))\ng = sns.FacetGrid(train_df, col='survived',size=5)\ng = g.map(sns.distplot, \"age_sur\")\nplt.show()","c62b1681":"print(sorted(train_df.age.unique()))","ee6ee9cd":"# We can try to create categories","200ff158":"interval = (0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 150) \ncats = list(range(len(interval)-1))\n\n# Applying the pd.cut and using the parameters that we created \ntrain_df[\"age_category\"] = pd.cut(train_df.age, interval, labels=cats)\n\n# Printing the new Category\ntrain_df[\"age_category\"].head()\n\n\n# Doing the same for Test Data\n\n# Applying the pd.cut and using the parameters that we created \ntest_df[\"age_category\"] = pd.cut(test_df.age, interval, labels=cats)\n\n# Printing the new Category\ntest_df[\"age_category\"].head()\n\n","42b95346":"train_df.age_category.unique()","ebdbde79":"plt.figure(figsize=(12,5))\nsns.countplot(\"age_category\", data=train_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Dist\", fontsize=18)\nplt.title(\"Age Dist \", fontsize=20)","ada47c53":"male_df = train_df[train_df.sex=='male']\nplt.figure(figsize=(12,5))\nsns.countplot(\"age_category\", data=male_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Dist for Male\", fontsize=18)\nplt.title(\"Age Dist \", fontsize=20)","f9d2a811":"female_df = train_df[train_df.sex=='female']\nplt.figure(figsize=(12,5))\nsns.countplot(\"age_category\", data=female_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Dist for Female\", fontsize=18)\nplt.title(\"Age Dist \", fontsize=20)","f8f2986e":"age_index = train_df[((train_df.sex=='male') & ( train_df.age_category.isin([0]) )) |\n         ((train_df.sex=='female') & ( (train_df.age_category.isin([0,1,2,3,4,5,6])) ))   \n        ].index\n\n# Doing the same for Test Data \n\nage_index_test = test_df[((test_df.sex=='male') & ( test_df.age_category.isin([0]) )) |\n         ((test_df.sex=='female') & ( (test_df.age_category.isin([0,1,2,3,4,5,6])) ))   \n        ].index\n","64effa9c":"age_index","ae7b9278":"train_df[\"age_sur\"] = 0\ntrain_df.loc[age_index, \"age_sur\"] = 1\n\n# Doing the same for Test Data \ntest_df[\"age_sur\"] = 0\ntest_df.loc[age_index_test, \"age_sur\"] = 1\n\nplt.figure(figsize=(12,5))\nsns.countplot(\"age_sur\", data=train_df, hue=\"survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Dist\", fontsize=18)\nplt.title(\"Age Dist \", fontsize=20)","99f99088":"train_df.sibling_spouse.unique()","5643852a":"train_df.groupby(\"sibling_spouse\").survived.value_counts(normalize=True).sort_index()","5f2ab3c1":"plt.figure(figsize=(12,5))\nsns.countplot(\"sibling_spouse\", data=train_df, hue=\"survived\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Sibling Dist\", fontsize=18)\nplt.title(\"Sibling Dist \", fontsize=20)","94326966":"\nmale_df = train_df[train_df.sex=='male']\nplt.figure(figsize=(12,5))\nsns.countplot(\"sibling_spouse\", data=male_df, hue=\"survived\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Male Sibling Dist\", fontsize=18)\nplt.title(\"Male Sibling Dist \", fontsize=20)","b731f625":"\nfemale_df = train_df[train_df.sex=='female']\nplt.figure(figsize=(12,5))\nsns.countplot(\"sibling_spouse\", data=female_df, hue=\"survived\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Female Sibling Dist\", fontsize=18)\nplt.title(\"Female Sibling Dist \", fontsize=20)","176993e6":"train_df.parent_children.unique()","abe21723":"train_df.groupby(\"parent_children\").survived.value_counts(normalize=True).sort_index()","3dfd274e":"plt.figure(figsize=(12,5))\nsns.countplot(\"parent_children\", data=train_df, hue=\"survived\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"parent_children Dist\", fontsize=18)\nplt.title(\"parent_children Dist \", fontsize=20)","4c07563a":"\nmale_df = train_df[train_df.sex=='male']\nplt.figure(figsize=(12,5))\nsns.countplot(\"parent_children\", data=male_df, hue=\"survived\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Male parent_children Dist\", fontsize=18)\nplt.title(\"Male parent_children Dist \", fontsize=20)","673286b9":"train_df[train_df.sex=='male'].groupby(\"parent_children\").survived.value_counts(normalize=True).sort_index()","17280671":"\nfemale_df = train_df[train_df.sex=='female']\nplt.figure(figsize=(12,5))\nsns.countplot(\"parent_children\", data=female_df, hue=\"survived\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Female parent_children Dist\", fontsize=18)\nplt.title(\"Female parent_children Dist \", fontsize=20)","0aec354e":"ps_ss_sur_index = train_df[\n    (train_df[\"sex\"] == 'female') &\n    (\n        (train_df[\"sibling_spouse\"].isin([0, 1, 2, 3])) | \n        (train_df[\"parent_children\"].isin([0, 1, 2, 3]))\n    )\n].index\n\n\n# Doing the same for Test Data\n\nps_ss_sur_index_test = test_df[\n    (test_df[\"sex\"] == 'female') &\n    (\n        (test_df[\"sibling_spouse\"].isin([0, 1, 2, 3])) | \n        (test_df[\"parent_children\"].isin([0, 1, 2, 3]))\n    )\n].index\n\n","d71d65f5":"train_df[\"ps_ss_sur\"] = 0\ntrain_df.loc[ps_ss_sur_index, \"ps_ss_sur\"] = 1","692bb660":"# Doing the same for test data\n\ntest_df[\"ps_ss_sur\"] = 0\ntest_df.loc[ps_ss_sur_index_test, \"ps_ss_sur\"] = 1","9c59f525":"train_df.ps_ss_sur.corr(train_df.survived)","1786c6de":"print(sorted(train_df.fare.unique()))","d3e6130d":"plt.figure(figsize=(12,5))\nsns.set_theme(style=\"whitegrid\")\nsns.boxplot(x=\"survived\", y=\"fare\", data=train_df, palette=\"Set3\")\nplt.title(\"Survived Fare Rate\")","a36ca48d":"train_df.head()","215eb081":"train_df.fare.fillna(train_df.fare.mean(), inplace=True)\n\n# Doing the same for test data\ntest_df.fare.fillna(test_df.fare.mean(), inplace=True)","3bfed219":"train_df.cabin.isnull().sum()","3b724065":"cabin_null_index = train_df[train_df.cabin.isnull()].index\n\n# Doing the same for Cabin\ncabin_null_index_test = test_df[test_df.cabin.isnull()].index\n","873c501a":"train_df[\"is_cabin\"] = 1\ntrain_df.loc[cabin_null_index, \"is_cabin\"] = 0\n\n# Doing the same for test\ntest_df[\"is_cabin\"] = 1\ntest_df.loc[cabin_null_index_test, \"is_cabin\"] = 0","8e59e264":"train_df.is_cabin.corr(train_df.survived)","89b9b6ea":"train_df.embarked.isnull().sum()","49bb4aad":"train_df.embarked.unique()","7d7600f0":"train_df.embarked.value_counts().plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","bc74fe6d":"sns.displot(x=train_df.embarked)\nplt.title(\"Distribuition of embarked values\")\nplt.show()","497fa13f":"train_df.embarked.fillna(\"S\", inplace=True)","d8f6795d":"# Doing the same for test data\ntest_df.embarked.fillna(\"S\", inplace=True)","10a0d50b":"sns.barplot(x='embarked', y='survived', data=train_df)","e8d53c1e":"train_df.head()","a3ddc12f":"train_df.columns","2ebaf8f2":"train_df.sex.replace({\"male\":0, \"female\":1}, inplace=True)","62b8548f":"# Doing the same for test data\ntest_df.sex.replace({\"male\":0, \"female\":1}, inplace=True)","632c4108":"subset = train_df[[\"passenger_class\", \"survived\",\"sal_sur\", \"age_sur\", \"age_category\", \"ps_ss_sur\", \"is_cabin\", \"sex\", \"fare\"]]\nsubset_test = test_df[[\"passenger_class\", \"sal_sur\", \"age_sur\", \"age_category\", \"ps_ss_sur\", \"is_cabin\", \"sex\", \"fare\"]]","aa3fe619":"subset","7a47a6f0":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(subset.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","50f71aa4":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","499248a9":"X = subset.drop(\"survived\", axis=1)\nY = train_df[\"survived\"]","a1ff57b7":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=10)","ae5dc067":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(solver='liblinear')\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nlr_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', lr_training_data_accuracy)\nlr_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', lr_testing_data_accuracy)","766098fa":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(max_depth=2, random_state=0)\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nrf_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', rf_training_data_accuracy)\nrf_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', rf_testing_data_accuracy)","6e6fc752":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nnb_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', nb_training_data_accuracy)\nnb_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', nb_testing_data_accuracy)","cb3b0fe8":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=2, algorithm='ball_tree')\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nknn_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', knn_training_data_accuracy)\nknn_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', knn_testing_data_accuracy)","92a1d890":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nmodel = make_pipeline(StandardScaler(), SGDClassifier(max_iter=9000, tol=1e-3))\n\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nsgd_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', sgd_training_data_accuracy)\nsgd_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', sgd_testing_data_accuracy)","0687198b":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(random_state=10)\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nsgd_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', sgd_training_data_accuracy)\nsgd_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', sgd_testing_data_accuracy)","502c87a9":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(solver='liblinear')\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\nX_test_prediction = model.predict(X_test)\nlr_training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\nprint('Accuracy score of training data : ', lr_training_data_accuracy)\nlr_testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\nprint('Accuracy score of testing data : ', lr_testing_data_accuracy)","57623c7a":"results = model.predict(subset_test)","e0a8ea6b":"sub_df = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsub_df[\"Survived\"] = results\nsub_df.to_csv(\"final_submission_2.csv\", index=False)","971f6446":"## Modelling","5a64530e":"### Types of filling in the data:\n\n1. Filling the missing data with the mean or median value if it\u2019s a numerical variable.\n2. Filling the missing data with mode if it\u2019s a categorical value.\n3. Filling the numerical value with 0 or -999, or some other number that will not occur in the data. This can be done so that the machine can recognize that the data is not real or is different.\n4. Filling the categorical value with a new type for the missing values.\n\n### Process for filling missing values in Age\n1. Since its a continous values, we can use either mean or median - Here we can use <b>Median<\/b>\n2. We already having a gouping in name - like Mr, Master, Don. \n3. So we can group the individual name category and fill the median value to the missing items\n","4ae629b7":"## 1. Renaming columns","9f2efc38":"#### Since the embarked is a categorical values, we can apply mode. So here we will be filling 'S' for all nan","a5777d91":"#### Comparison with survival rate","6715e9e3":"### 5. Age","783a3bff":"#### Comparison with Gender","45839597":"#### Comparison of P Class with survival","e1f53852":"#### Inference (finding missing values): \nFrom the above plots we can see, that Columns Age, Cabin, Embarked are missing some values. Going further we can see how we can rectify them","8a89f451":"From the above graph, we can see that we have more categories in salutation, we can try to reduce it by mapping\n( Since some categories are having only a single value, eg: Lady, Sir, Col)","921e2f1f":"### 8. Fare","752f9c71":"From the above findings, we can see 74% of females are having higher survival rate than males. ","4ae695c6":"From the above plot, we can see Passengers in Class 1 and 2 were having good survival rate than Passenger in class 3","7aa2e3b1":"Our newly created features is not good","4d88aa75":"#### Inference: \n\nWith Male: As usual the survival rate is low for all categories\n\nWith Female : As usual the survival rate is high for all categories.","328ffbf2":"### 3. Name column","47d9b08d":"#### Inference: \nSince passenger_id column is an index column, and it has no relation with survival rate, we can ignore the passenger_id column","4bf41894":"#### Survival rate based on each embarkment","9da82417":"#### Distribution of Age","78999821":"### 2. Passenger Class","520f02e9":"From the above plot we can see that, people in category 1, 2, 3, 5 were having mpre survival rate than other classess.\n\nPeople in Category \n1. Jonkheer, Don, Sir, Countess, Dona, Lady\n2. Mme, Ms, Mrs\n3. Mlle, Miss\n5. Master\n\nFrom this we can see, Ladies and Childrens are having more survival rate. ","34fcf83a":"#### We can see something is interesting right, For both sibling_spouse and parent_children, with gender as female its showing higher survival rate (in categories of 0, 1, 2, 3). \n\nWith this information we can create a new column, like \"pc_ss_sur\"","c1efa2a1":"### 1. Passenger Id","ffd0daa9":"#### Inference (Name):\nFrom the above findings, we can see \"salutations\" plays a good role in survival_rate","0325da54":"#### Male Comparisons","65661351":"#### Distribution of Salutation","9c5821b0":"## 2. Finding Missing Values","c3d3d059":"#### Comparison with Male","adec9498":"So we can try to create an another column \"sal_sur\" based on the above findings","c9d7166c":"By Comparing, we came to know that Logistic Regression is doing good","626487f1":"# Loading Datasets","3678b4ed":"#### Inference(Age):\nFrom this we can know that, age_sur with category 1 is having higher survival rate","2ec0d841":"# I will be updating this notebook in future as well","fee2eb09":"### 9. Cabin","bb35668c":"### 10. Embarked","260b08e1":"Fare, Sex, is_Cabin, Ps_ss_sur, age_sur, sal_sur were having higher correlation with survival ","37656ade":"# Loading Libraries","ea159c9e":"#### Inference:\nfrom the above graph we can know that, people who are boarded in C were survived more","e81b0972":"We can see that cabin is having more of null values. So instead of filling the missing values, we can create a new feature. ","60a0f4cf":"#### Inference (passenger_class):\nFrom the above normalized data, we can understand that people in class 1 had 63 % survival rate and class 2 is having 47 % survival rate. ","5a4fe1b9":"## Submissions","6d0d3187":"From the above we can see that, people in the range of 18 to 40 were having good survival rate. \n\nNow we can see, how gender is affecting this values","6aa39b7e":"#### Inference: \nOn Whole : From the above plot, we can see people with 1, 2 siblings have higher survival rate\n\nWith Male: As usual the survival rate is low for all categories\n\nWith Female : As usual the survival rate is high for all categories.","9a892df1":"As we know before, embarked is having some missing values. We can try to fix that first. ","ae376e1e":"### 6. Sibling Spouse","b2a10414":"As we discussed at the top Age is having some null values. So first we can concentrate on filling the missing values first. ","0e88560e":"#### Comparison with Female","5a8784bd":"#### Distribution of Gender","2168847e":"#### Comparison with Female","8e42fa66":"From the above two graphs, we can see that Males in age category 0 is having higher survival rate. \n\nFor Female, in the range 0-6 is having higher survival rate. \n\nSo now we can update, the new age_survival column based on our findings. ","efebf625":"# Introduction\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\n\n# Data Description\n\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n\n\nVariable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\n\nSibling = brother, sister, stepbrother, stepsister\n\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\n\nParent = mother, father\n\nChild = daughter, son, stepdaughter, stepson\n\nSome children travelled only with a nanny, therefore parch=0 for them.\n\n\nVariable\tDefinition\tKey\nsurvival\tSurvival\t0 = No, 1 = Yes\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\tSex\t\nAge\tAge in years\t\nsibsp\t# of siblings \/ spouses aboard the Titanic\t\nparch\t# of parents \/ children aboard the Titanic\t\nticket\tTicket number\t\nfare\tPassenger fare\t\ncabin\tCabin number\t\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton","42180f73":"#### Female Comparisons","581621bf":"# EDA of training data","b167c334":"#### Distribution of Embarked","4e9eadda":"## Training Testing Set Preparation ","a40821f4":"#### Comparison with Male","097c1d18":"Please <b>upvote<\/b> if you liked it !!!","55b4bd47":"Now we have reduced the categories","3f42e172":"### 7. Parent Children","35b7b72a":"#### Inference (Sex):\nFrom the above we can see females are having more survival rate than men","e2c60d8b":"## Feature Scaling and Feature Selection","afe6e5d7":"### 4. Sex","e2f1bc38":"# Data Information and data types","581492de":"## 3. Checking Each Column values and Feature Engineering","28ffa28b":"For Males: With age range 20 to 40 is having a good survival rate. \n\nFor Females: With age range 18 to 40 is having a goog survival rate.\n\nNow we can try to use this feature to build a new one ","eab8943e":"Now all the missing values are been filled. ","a93cb55b":"Name column is also like Passenger Id column, its just an index for a person.\n\nBut, from this name values, we can see different salutations are given for persons based on their age\/royalty\/officer.\n\nWe can collect these data first (Feature Engineering), and will analyse whether its supporting survival rate","36299302":"#### Distribution of passenger class"}}