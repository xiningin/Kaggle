{"cell_type":{"fd27ac88":"code","d4b910ac":"code","050e1d41":"code","b2cb1f47":"code","a91e08a3":"code","dc57927e":"code","3dcc8d86":"code","9e03ad4c":"code","bf359a51":"code","5a9eb774":"code","a1a6bad8":"markdown"},"source":{"fd27ac88":"from keras import layers\nfrom keras import models\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))","d4b910ac":"model.summary()","050e1d41":"# images are fed in as 28x28x1 tensors\n# the network shrinks the height and width\n# number of filters per layer determine number of channels in tensor","b2cb1f47":"model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))","a91e08a3":"# we flatten the tensor and run it through a softmax layer","dc57927e":"model.summary()","3dcc8d86":"from keras.datasets import mnist\nfrom keras.utils import to_categorical\n\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\ntrain_images = train_images.reshape((60000, 28, 28, 1))\ntrain_images = train_images.astype('float32') \/ 255\n\ntest_images = test_images.reshape((10000, 28, 28, 1))\ntest_images = test_images.astype('float32') \/ 255\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\nmodel.compile(optimizer='rmsprop',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","9e03ad4c":"model.fit(train_images, train_labels, epochs=5, batch_size=64) ","bf359a51":"test_loss, test_acc = model.evaluate(test_images, test_labels)","5a9eb774":"test_acc","a1a6bad8":"# Basic Convolutional Neural Network\nHere is an example of a basic CNN. For images the accuracy of a CNN is better than a Densely connected Neural Network for two reasons.\n1. CNNs are able to learn local features. A fully connected NN can only find features in the whole image. In this example we use a kernel size of 3x3 pixels. The feature window is also called the `receptive field` of a kernel. \n1. CNNs are able to learn a hierarchy of features. With multiple layers, feature detectors for concepts like 'face' or 'wheel' are built up from simpler detectors like 'edge' or 'curve'.\n\nAdapted from Deep Learning with Python 5.1"}}