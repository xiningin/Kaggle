{"cell_type":{"cad7afb0":"code","ce233b68":"code","bbb22b1d":"code","6af0b242":"code","6c6b569b":"code","b994b7e8":"code","03f6c9ad":"code","63fa29bb":"code","17e7b6f6":"code","e24c34c8":"code","3ce3b17f":"code","567a228a":"code","7840f2fc":"code","096fa8bd":"code","e493af0e":"code","98a0a430":"code","41289923":"code","59696a6e":"code","d64c6b30":"code","417c86bd":"code","2aa41890":"code","da506510":"code","d4043d0c":"code","0681dbfb":"code","8a8a228f":"code","36153ff4":"code","9f109593":"code","4629b72e":"code","1c93e1e7":"code","7a5e153d":"code","a83f2c0b":"code","37cd7682":"code","cef202cb":"code","5adf9e8c":"code","c3f524fb":"code","155b304a":"code","e76adc7f":"code","a7d3ad74":"code","c96fc6a5":"code","d8ddc6f2":"code","34f8e1e9":"code","55aa5dd6":"code","b7a680bc":"markdown","8febc79b":"markdown","7622a11f":"markdown","6c33e022":"markdown","7a290aee":"markdown","8556c206":"markdown","c452afd2":"markdown","828cc918":"markdown"},"source":{"cad7afb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom keras.preprocessing import text, sequence\nfrom keras import backend as K\nfrom keras.models import load_model\nimport keras\nimport pickle\nprint(K.tensorflow_backend._get_available_gpus())\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ce233b68":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/sample_submission.csv')","bbb22b1d":"train_data = train[\"comment_text\"]\nlabel_data = train[\"target\"]\ntest_data = test[\"comment_text\"]\ntrain_data.shape, label_data.shape, test_data.shape","6af0b242":"test.head()","6c6b569b":"tokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(list(train_data) + list(test_data))","b994b7e8":"train_data = tokenizer.texts_to_sequences(train_data)\ntest_data = tokenizer.texts_to_sequences(test_data)","03f6c9ad":"MAX_LEN = 200\ntrain_data = sequence.pad_sequences(train_data, maxlen=MAX_LEN)\ntest_data = sequence.pad_sequences(test_data, maxlen=MAX_LEN)","63fa29bb":"max_features = None","17e7b6f6":"max_features = max_features or len(tokenizer.word_index) + 1\nmax_features","e24c34c8":"type(train_data), type(label_data.values), type(test_data)\nlabel_data = label_data.values","3ce3b17f":"#Word cloud of train file\n\nfrom wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train[\"comment_text\"], title=\"Word Cloud of Train Comments\")","567a228a":"#Word cloud of train file of toxic comments\ntrain['target'] = np.where(train['target'] >= 0.5, 1, 0)\ntrain_toxic = train[train.target == 1]\n\n\nfrom wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train_toxic[\"comment_text\"], title=\"Word Cloud of Toxic Comments\")","7840f2fc":"#Word cloud of train file of non-toxic comments\ntrain['target'] = np.where(train['target'] >= 0.5, 1, 0)\ntrain_nontoxic = train[train.target == 0]\nplot_wordcloud(train_nontoxic[\"comment_text\"], title=\"Word Cloud of Non-Toxic Comments\")","096fa8bd":"# Keras Model\n# Model Parameters\nNUM_HIDDEN = 256\nEMB_SIZE = 256\nLABEL_SIZE = 1\nMAX_FEATURES = max_features\nDROP_OUT_RATE = 0.2\nDENSE_ACTIVATION = \"sigmoid\"\nNUM_EPOCH = 1\n\n# Optimization Parameters\nBATCH_SIZE = 1000\nLOSS_FUNC = \"binary_crossentropy\"\nOPTIMIZER_FUNC = \"adam\"\nMETRICS = [\"accuracy\"]\n\nclass LSTMModel:\n    \n    def __init__(self):\n        self.model = self.build_graph()\n        self.compile_model()\n    \n    def build_graph(self):\n        model = keras.models.Sequential([\n            keras.layers.Embedding(MAX_FEATURES, EMB_SIZE),\n            keras.layers.CuDNNLSTM(NUM_HIDDEN),\n            keras.layers.Dropout(rate=DROP_OUT_RATE),\n            keras.layers.Dense(LABEL_SIZE, activation=DENSE_ACTIVATION)])\n        return model\n    \n    def compile_model(self):\n        self.model.compile(\n            loss=LOSS_FUNC,\n            optimizer=OPTIMIZER_FUNC,\n            metrics=METRICS)","e493af0e":"model = LSTMModel().model\nmodel.fit(\n    train_data, \n    label_data, \n    batch_size = BATCH_SIZE, \n    epochs = NUM_EPOCH)","98a0a430":"from sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)","41289923":"plt.xlim(0, 0.2)\nplt.ylim(0.8, 1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve (zoomed in at top left)')\nplt.legend(loc='best')\nplt.show()","59696a6e":"## Loss and accuracy graphs\n\nimport matplotlib.pyplot as plt\n\nhistory = model.fit(\n    train_data, \n    label_data, \n    validation_split=0.25, epochs=5, batch_size=1000, verbose=1)","d64c6b30":"\n# Plot training & validation accuracy values\nplt.xlim(0, 4)\nplt.ylim(0.6, 0.8)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","417c86bd":"#Plot ROC curve\nimport sklearn.metrics as metrics\n# calculate the fpr and tpr for all thresholds of the classification\ny_pred = model.predict(train_data)","2aa41890":"# Tag label_data as binary\n# y_pred=np.where(y_pred>=0.5,1,0)\nlabel_data=np.where(label_data>=0.5,1,0)\nfpr, tpr, threshold = metrics.roc_curve(label_data, y_pred)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b')\n# label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.02, 1])\nplt.ylim([0, 1.05])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","da506510":"#Tag both label and predicted as binary (with margin as 0.5)\n\ny_pred=np.where(y_pred>=0.5,1,0)\nlabel_data=np.where(label_data>=0.5,1,0)\nfpr, tpr, threshold = metrics.roc_curve(label_data, y_pred)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.02, 1])\nplt.ylim([0, 1.05])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","d4043d0c":"#Extract frequency of transactions along with toxicity for different probability buckets","0681dbfb":"submission_in = '..\/input\/sample_submission.csv'\nsubmission_out = 'submission.csv'","8a8a228f":"result = model.predict(test_data)","36153ff4":"submission = pd.read_csv(submission_in, index_col='id')\nsubmission['prediction'] = result\nsubmission.reset_index(drop=False, inplace=True)","9f109593":"submission.to_csv(submission_out, index=False)","4629b72e":"#Get data for train file so that we can evaluate false positives\nsubmission_in = '..\/input\/train.csv'\n#Filter ID and pre\nsubmission_out = 'submission_train.csv'\n","1c93e1e7":"#Make test data as train so that we can check false positives of classification\ntest1_data = train[\"comment_text\"]","7a5e153d":"tokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(list(test1_data))","a83f2c0b":"test1_data = tokenizer.texts_to_sequences(test1_data)","37cd7682":"MAX_LEN = 200\ntest1_data = sequence.pad_sequences(test1_data, maxlen=MAX_LEN)","cef202cb":"result1 = model.predict(test1_data)","5adf9e8c":"submission_train = pd.read_csv(submission_in, index_col='id')\nsubmission_train['prediction'] = result1\nsubmission_train.reset_index(drop=False, inplace=True)","c3f524fb":"#submisson file has a prediction column as well\n\nsubmission_train.head()","155b304a":"#filter only the ID, target value and prediction value\nfiltered_submission=submission_train.filter(items=['id', 'target','prediction'])","e76adc7f":"filtered_submission.head()","a7d3ad74":"filtered_submission['prediction'] = [ 1 if prediction>=0.5 else 0 for prediction in filtered_submission['prediction'] ]\nfiltered_submission['target'] = [ 1 if target>=0.5 else 0 for target in filtered_submission['target'] ]\nfiltered_submission.head(10)","c96fc6a5":"filtered_submission.groupby([\"target\",\"prediction\"]).count()[['id']]","d8ddc6f2":"# FN are more than FPs. Precision 13%, Recall 3%\n\n#Word cloud of train file of false positives and f\nfiltered_submission_toxic = filtered_submission[filtered_submission.target == 1]\n\nplot_wordcloud(train_toxic[\"comment_text\"], title=\"Word Cloud of Toxic Comments\")","34f8e1e9":"def toxicwordcloud(subset=train[train.target>0.7], title = \"Words Frequented\"):\n    stopword=set(STOPWORDS)\n#     toxic_mask=np.array(Image.open(picture))\n#     toxic_mask=toxic_mask[:,:,1]\n    text=subset.comment_text.values\n    wc= WordCloud(background_color=\"black\",max_words=4000,stopwords=stopword)\n    wc.generate(\" \".join(text))\n    plt.figure(figsize=(8,8))\n    plt.xticks([])\n    plt.yticks([])\n    plt.axis('off')\n    plt.title(title, fontsize=20)\n    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244), alpha=0.98)\n    \n","55aa5dd6":"toxicwordcloud(subset=train[train.target>0.7], title = \"Words Frequented\")","b7a680bc":"Exploratory Analysis","8febc79b":"DO PREDICTION ON TRAIN FILE. ANALYSE FALSE POSITIVES","7622a11f":"#### Model","6c33e022":"#### Prediction","7a290aee":"#### Vectorize Data","8556c206":"### Preprocessing Data","c452afd2":"ANALYSE FALSE POSITIVES IN THE PREDICTION","828cc918":"Filter fields which show difference in classification between target and prediction"}}