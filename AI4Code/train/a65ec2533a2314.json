{"cell_type":{"5128e92e":"code","922f0aa9":"code","e5e01056":"code","cc9c249a":"code","199256b1":"code","c1da129e":"code","602b0a56":"code","011fd9d4":"code","b66109a7":"code","9278c81b":"code","1c0e9bfe":"code","3450c752":"code","e4167848":"code","868c6247":"code","88951809":"code","0e6dd427":"code","646d0fd9":"code","8baa44bf":"code","a670fd4f":"code","9e3a07dc":"code","f2ad30ca":"code","84df3073":"code","fbbab647":"code","d86eb2ff":"code","d4c09bff":"code","d5f6e662":"code","0626700d":"code","eb5f96ef":"code","189c77e2":"code","6bcee455":"code","033e37ca":"code","88fd7a03":"code","a1d748af":"code","fb695aef":"code","a6f95496":"markdown","78095a42":"markdown"},"source":{"5128e92e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","922f0aa9":"import numpy as np\nimport pandas as pd\nimport sklearn as sk\nimport matplotlib.pyplot as plt #for creating static, animated and interactive visulization\nimport seaborn as sns #data visulation library used for making statistical graphics\n\nimport warnings","e5e01056":"#readind data\ndf = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","cc9c249a":"#size (rows,columns)\ndf.shape","199256b1":"#viewing data\ndf.head()","c1da129e":"cleaned_df = df.drop(['Sex', 'RestingECG', 'ST_Slope', 'ChestPainType', 'ExerciseAngina'], axis=1)","602b0a56":"cleaned_df.sample(5)","011fd9d4":"cleaned_df.shape","b66109a7":"sns.pairplot(data=df, hue='Sex')","9278c81b":"sns.pairplot(data=df, hue='Sex', diag_kind='hist')","1c0e9bfe":"cor = df.corr()\n\ncor","3450c752":"plt.figure(figsize=(15,8))\nsns.heatmap(cor, vmax=1, square=True, annot=True)\nplt.title('Correlation between features of Heart Dieses')","e4167848":"sns.lmplot(x='Age', y='MaxHR', data=df, hue='Sex', fit_reg=False)","868c6247":"##NORMALIZATION \n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\n#cleaned_df = pd.DataFrame(scaler.fit_transform(cleaned_df), columns=cleaned_df.columns, index= cleaned_df.index)\n","88951809":"cleaned_df.head()","0e6dd427":"\npca = PCA(2)\n\nout_pca = pca.fit_transform(cleaned_df[cleaned_df.columns.tolist()])\n\npca_df= pd.DataFrame(data=out_pca, columns=['Pca1', 'Pca2'])\n\nprint(pca_df)","646d0fd9":"# total_var = pca.explained_variance_ratio_.sum() * 100\nsns.lmplot(x='Pca1', y='Pca2', data=pca_df, fit_reg=False)\n","8baa44bf":"from sklearn.cluster import KMeans\n\ndef kmns_clustring(data, clusters):\n    kmeans = KMeans(n_clusters =clusters,random_state=42 )\n    kmeans.fit(data)\n    \n    kmeans.clusters = kmeans.cluster_centers_\n    \n    kmeans.y_kmn =  kmeans.fit_predict(out_pca)\n    \n    return kmeans\n\n","a670fd4f":"kmeans = kmns_clustring(data=pca_df, clusters=8)","9e3a07dc":"plt.figure(figsize=(15,8))\ndef scatter_plot(kmns, df):\n    for i in np.unique(kmns.y_kmn):\n        plt.scatter(out_pca[kmns.y_kmn == i ,0], out_pca[kmns.y_kmn == i, 1], s=50)\n        plt.scatter(kmns.clusters[i][0] , kmns.clusters[i][1] , s = 80,marker='+', color = 'k')\n    plt.show()\nscatter_plot(kmeans, pca_df)","f2ad30ca":"from sklearn.metrics import silhouette_score\ndef s_score(data):\n    silhouette_coefficient = []\n    for k in range(2,11):\n        kmeans = KMeans(n_clusters = k, init='k-means++', n_init=30, max_iter=500, random_state=42 )\n        kmeans.fit(data)\n        score = silhouette_score(data, kmeans.labels_)\n        silhouette_coefficient.append(score)\n    return silhouette_coefficient\nsscore = s_score(data=pca_df)","84df3073":"plt.style.use('fivethirtyeight')\nplt.plot(range(2,11), sscore)\nplt.xticks(range(2,11))\nplt.xlabel('Number of Clusters')\nplt.ylabel('Error')\nplt.show()","fbbab647":"X=df.iloc[:,[0,2,3,4,5,6,7,8,9,10,11]]","d86eb2ff":"X","d4c09bff":"Y=df.iloc[:,1]\nY","d5f6e662":"from sklearn.preprocessing import LabelEncoder\nlabel_x=LabelEncoder()\nX=X.apply(LabelEncoder().fit_transform)\nX","0626700d":"# split X and y into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)","eb5f96ef":"from sklearn.tree import DecisionTreeClassifier\nregressor=DecisionTreeClassifier(random_state=1)\n# fit the model\nregressor.fit(X_train, y_train)","189c77e2":"# check the shape of X_train and X_test\n\nX_train.shape, X_test.shape","6bcee455":"\ny_pred_gini = regressor.predict(X_test)","033e37ca":"from sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))","88fd7a03":"#plt.figure(figsize=(12,8))\n\n#from sklearn import tree\n\n#tree.plot_tree(regressor.fit(X_train, y_train))","a1d748af":"def naive_bayes_accuracy(x, y):\n    # splitting X and y into training and testing sets\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n\n    # training the model on training set\n    from sklearn.naive_bayes import GaussianNB\n    gnb = GaussianNB()\n    gnb.fit(X_train, y_train)\n\n    # making predictions on the testing set\n    y_pred = gnb.predict(X_test)\n\n    # comparing actual response values (y_test) with predicted response values (y_pred)\n    from sklearn import metrics\n    score = metrics.accuracy_score(y_test, y_pred)*100\n    return score\n","fb695aef":"print(\"K-Mean Accuracy: %.3f\" %  (naive_bayes_accuracy(cleaned_df, kmeans.y_kmn)))","a6f95496":"**Plotting Heart Rate ratio by Age**","78095a42":"# Silhoutte_Score"}}