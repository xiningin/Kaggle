{"cell_type":{"08e4c191":"code","744ae703":"code","cd394670":"code","997b6b0c":"code","d3394f5b":"code","d10ad490":"code","662051eb":"code","2fe0488a":"code","46cdf6d9":"code","c32d0f69":"code","e702e6a7":"code","ff1d3118":"code","d875f3b4":"code","e1aa261c":"code","c91ca8e6":"code","5a4cb581":"code","65cc28b5":"code","a87ecc33":"code","4b75296f":"code","6bd57869":"code","412b7b2b":"code","eba52d66":"code","6d67fbfc":"code","5dc4aef2":"code","f1210149":"code","dbb4b770":"code","faab9ea9":"code","3f772998":"code","acb85f0b":"code","e927cfc0":"code","95a5f689":"code","c0cfe863":"code","23a34836":"code","19ed51bc":"code","8ed9e28d":"code","e0a8c37c":"code","47942610":"code","4267d511":"code","150db721":"code","c9bffb5a":"code","6bfc8042":"code","cb99b2e3":"code","696f59bb":"code","d4a1bd69":"code","516f1701":"code","19255940":"code","fd37f0f2":"code","da5efaa3":"code","371df1da":"code","5595c9fa":"code","42e2b126":"code","a07782bb":"code","20b2e400":"code","bbf66431":"code","9dcb2767":"code","202c193e":"code","246d7b3b":"code","159af4af":"code","0fa428cc":"code","afbafa1c":"code","814b49d7":"code","a19d9174":"code","718bf762":"code","454f19d8":"code","e373dd45":"code","6c238d59":"code","df537e95":"code","28423255":"code","39231f8a":"code","71256fd7":"code","4f46be88":"code","6c11121a":"code","c31e7c42":"code","22872263":"code","0f94dfb5":"code","9fcbe846":"code","49ed13d9":"code","878b44cf":"code","913d6503":"code","087aea93":"code","d439194b":"code","bc3d01af":"markdown","ac98b21d":"markdown","94aaef9c":"markdown","06418320":"markdown","82c52d4d":"markdown","502174db":"markdown","920e52ed":"markdown","fdbd8802":"markdown","cd0dc252":"markdown","39674062":"markdown","435bd75e":"markdown","9f1000c4":"markdown","c81be93b":"markdown","15ebff5b":"markdown","3f5714d6":"markdown","82878c96":"markdown","e17c693a":"markdown","264617dd":"markdown","021212a0":"markdown","965ca015":"markdown","b57d1ba7":"markdown","580505c1":"markdown","0b8a77e1":"markdown","891c4ff8":"markdown","57edb627":"markdown","47f3ed5b":"markdown","93af55a6":"markdown","9f4bf9ff":"markdown","6a0ffa1c":"markdown","af16a784":"markdown","324afc18":"markdown","3d63c5fd":"markdown","7f2ec269":"markdown","364c8e9d":"markdown","1b1d9169":"markdown","fb97b718":"markdown","0efe7d21":"markdown","742961c0":"markdown","36a2d85a":"markdown"},"source":{"08e4c191":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import RandomOverSampler\nsns.set(style='whitegrid')","744ae703":"train=pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntest=pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/test.csv')","cd394670":"test.head()","997b6b0c":"train.head()","d3394f5b":"train.shape","d10ad490":"train.isnull().sum()","662051eb":"numerical_columns=['Age', 'Region_Code','Annual_Premium','Vintage']\ncategorical_columns=['Gender','Driving_License','Previously_Insured','Vehicle_Age','Vehicle_Damage','Response']","2fe0488a":"train[numerical_columns].describe()","46cdf6d9":"train","c32d0f69":"sns.countplot(train.Response)","e702e6a7":"train.Response.value_counts()","ff1d3118":"sns.distplot(train.Age)","d875f3b4":"sns.boxplot(y = 'Age', data = train,palette='Accent')","e1aa261c":"sns.scatterplot(x=train['Age'],y=train['Annual_Premium'])","c91ca8e6":"sns.countplot(train.Gender)","5a4cb581":"df=train.groupby(['Gender','Response'])['id'].count().to_frame().rename(columns={'id':'count'}).reset_index()\n","65cc28b5":"g = sns.catplot(x=\"Gender\", y=\"count\",col=\"Response\",\n                data=df, kind=\"bar\",\n                height=4, aspect=.7);","a87ecc33":"df=train.groupby(['Gender'])['Driving_License'].count().to_frame().reset_index()","4b75296f":"df","6bd57869":"sns.catplot(x=\"Gender\", y=\"Driving_License\",\n                data=df, kind=\"bar\");","412b7b2b":"sns.countplot(train.Previously_Insured)","eba52d66":"sns.countplot(train.Vehicle_Age)","6d67fbfc":"df=train.groupby(['Vehicle_Age','Response'])['id'].count().to_frame().rename(columns={'id':'count'}).reset_index()\ndf","5dc4aef2":"g = sns.catplot(x=\"Vehicle_Age\", y=\"count\",col=\"Response\",\n                data=df, kind=\"bar\",\n                height=4, aspect=.7);","f1210149":"sns.countplot(train.Vehicle_Damage)","dbb4b770":"df=train.groupby(['Vehicle_Damage','Response'])['id'].count().to_frame().rename(columns={'id':'count'}).reset_index()","faab9ea9":"g = sns.catplot(x=\"Vehicle_Damage\", y=\"count\",col=\"Response\",\n                data=df, kind=\"bar\",\n                height=4, aspect=.7);","3f772998":"sns.distplot(train.Annual_Premium)","acb85f0b":"sns.boxplot(y = 'Annual_Premium', data = train,palette='Accent')","e927cfc0":"sns.distplot(train.Vintage)","95a5f689":"num_feat = ['Age','Vintage']\ncat_feat = ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Age_lt_1_Year','Vehicle_Age_gt_2_Years','Vehicle_Damage_Yes','Region_Code','Policy_Sales_Channel']","c0cfe863":"train['Gender'] = train['Gender'].map( {'Female': 0, 'Male': 1} ).astype(int)","23a34836":"train=pd.get_dummies(train,drop_first=True)","19ed51bc":"train=train.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\ntrain['Vehicle_Age_lt_1_Year']=train['Vehicle_Age_lt_1_Year'].astype('int')\ntrain['Vehicle_Age_gt_2_Years']=train['Vehicle_Age_gt_2_Years'].astype('int')\ntrain['Vehicle_Damage_Yes']=train['Vehicle_Damage_Yes'].astype('int')","8ed9e28d":"from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nss = StandardScaler()\ntrain[num_feat] = ss.fit_transform(train[num_feat])\n\n\nmm = MinMaxScaler()\ntrain[['Annual_Premium']] = mm.fit_transform(train[['Annual_Premium']])","e0a8c37c":"train=train.drop('id',axis=1)","47942610":"for column in cat_feat:\n    train[column] = train[column].astype('str')","4267d511":"train","150db721":"test['Gender'] = test['Gender'].map( {'Female': 0, 'Male': 1} ).astype(int)\ntest=pd.get_dummies(test,drop_first=True)\ntest=test.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\ntest['Vehicle_Age_lt_1_Year']=test['Vehicle_Age_lt_1_Year'].astype('int')\ntest['Vehicle_Age_gt_2_Years']=test['Vehicle_Age_gt_2_Years'].astype('int')\ntest['Vehicle_Damage_Yes']=test['Vehicle_Damage_Yes'].astype('int')","c9bffb5a":"from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nss = StandardScaler()\ntest[num_feat] = ss.fit_transform(test[num_feat])\n\n\nmm = MinMaxScaler()\ntest[['Annual_Premium']] = mm.fit_transform(test[['Annual_Premium']])","6bfc8042":"for column in cat_feat:\n    test[column] = test[column].astype('str')","cb99b2e3":"from sklearn.model_selection import train_test_split\n\ntrain_target=train['Response']\ntrain=train.drop(['Response'], axis = 1)\nx_train,x_test,y_train,y_test = train_test_split(train,train_target, random_state = 0)","696f59bb":"id=test.id","d4a1bd69":"test=test.drop('id',axis=1)","516f1701":"x_train.columns","19255940":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom scipy.stats import randint\nimport pickle\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\n# import packages for hyperparameters tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, KFold, GridSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report ","fd37f0f2":"%pylab inline","da5efaa3":"x_train.dtypes","371df1da":"random_search = {'criterion': ['entropy', 'gini'],\n               'max_depth': [2,3,4,5,6,7,10],\n               'min_samples_leaf': [4, 6, 8],\n               'min_samples_split': [5, 7,10],\n               'n_estimators': [300]}\n\nclf = RandomForestClassifier()\nmodel = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 10, \n                               cv = 4, verbose= 1, random_state= 101, n_jobs = -1)\nmodel.fit(x_train,y_train)","5595c9fa":"filename = 'rf_model.sav'\npickle.dump(model, open(filename, 'wb'))","42e2b126":"filename = 'rf_model.sav'","a07782bb":"rf_load = pickle.load(open(filename, 'rb'))","20b2e400":"y_pred=model.predict(x_test)","bbf66431":"print (classification_report(y_test, y_pred))","9dcb2767":"y_score = model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\ntitle('Random Forest ROC curve: CC Fraud')\nxlabel('FPR (Precision)')\nylabel('TPR (Recall)')\n\nplot(fpr,tpr)\nplot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","202c193e":"roc_auc_score(y_test, y_score)","246d7b3b":"for column in cat_feat:\n    x_train[column] = x_train[column].astype('int')\n    x_test[column] = x_test[column].astype('int')","159af4af":"space={ 'max_depth': hp.quniform(\"max_depth\", 3,18,1),\n        'gamma': hp.uniform ('gamma', 1,9),\n        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n        'n_estimators': 300,\n        'seed': 0\n      }","0fa428cc":"def objective(space):\n    clf=xgb.XGBClassifier(\n                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n                    colsample_bytree=int(space['colsample_bytree']))\n    \n    evaluation = [( x_train, y_train), ( x_test, y_test)]\n    \n    clf.fit(x_train, y_train,\n            eval_set=evaluation, eval_metric=\"auc\",\n            early_stopping_rounds=10,verbose=False)\n    \n\n    pred = clf.predict(x_test)\n    y_score = model.predict_proba(x_test)[:,1]\n    accuracy = accuracy_score(y_test, pred>0.5)\n    Roc_Auc_Score = roc_auc_score(y_test, y_score)\n    print (\"ROC-AUC Score:\",Roc_Auc_Score)\n    print (\"SCORE:\", accuracy)\n    return {'loss': -Roc_Auc_Score, 'status': STATUS_OK }\n","afbafa1c":"from hyperopt import STATUS_OK, Trials, fmin, hp, tpe","814b49d7":"trials = Trials()","a19d9174":"\nbest_hyperparams = fmin(fn = objective,\n                        space = space,\n                        algo = tpe.suggest,\n                        max_evals = 100,\n                        trials = trials)","718bf762":"print(\"The best hyperparameters are : \",\"\\n\")\nprint(best_hyperparams)","454f19d8":"xgb_model=xgb.XGBClassifier(n_estimators = space['n_estimators'], max_depth = best, gamma = 4.0388607178326605, reg_lambda = 0.26955899476862166,\n                            reg_alpha = 66.0, min_child_weight=4.0,colsample_bytree = 0.8844758548525424 )\n    ","e373dd45":"xgb_model.fit(x_train,y_train)","6c238d59":"filename = 'xgboost_model.sav'\npickle.dump(xgb_model, open(filename, 'wb'))","df537e95":"y_score = xgb_model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\ntitle('XGBoost ROC curve')\nxlabel('FPR (Precision)')\nylabel('TPR (Recall)')\n\nplot(fpr,tpr)\nplot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","28423255":"random_state=42\nn_iter=50\nnum_folds=2\nkf = KFold(n_splits=num_folds, random_state=random_state,shuffle=True)","39231f8a":"def gb_mse_cv(params, random_state=random_state, cv=kf, X=x_train, y=y_train):\n    # the function gets a set of variable parameters in \"param\"\n    params = {'n_estimators': int(params['n_estimators']), \n              'max_depth': int(params['max_depth']), \n              'learning_rate': params['learning_rate'],\n              'gamma': params['gamma'],\n              'reg_alpha' : params['reg_alpha'],\n              'reg_lambda' : params['reg_lambda'],\n              'colsample_bytree' : params['colsample_bytree'],\n              'min_child_weight' : params['min_child_weight']\n             }\n            \n            \n    \n    # we use this params to create a new LGBM Regressor\n    model = lgb.LGBMClassifier(random_state=42, **params)\n    \n    # and then conduct the cross validation with the same folds as before\n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1).mean()\n\n    return score","71256fd7":"%%time\n\n# possible values of parameters\nspace={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n       'max_depth' : hp.quniform('max_depth', 2, 8, 1),\n       'learning_rate': hp.loguniform(\"learning_rate\",-4,-1),\n        'gamma': hp.quniform('gamma',0.1,0.5,0.1),\n        'reg_alpha' : hp.quniform('reg_alpha',1.1,1.5,0.1),\n        'reg_lambda' : hp.uniform('reg_lambda',1.1,1.5),\n        'colsample_bytree' : hp.uniform('colsample_bytree', 0.1,0.5),\n        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n      }\n\n# trials will contain logging information\ntrials = Trials()\n\nbest=fmin(fn=gb_mse_cv, # function to optimize\n          space=space, \n          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n          max_evals=n_iter, # maximum number of iterations\n          trials=trials, # logging\n          rstate=np.random.RandomState(random_state) # fixing random state for the reproducibility\n         )\n\n# computing the score on the test set\nmodel = lgb.LGBMClassifier(random_state=random_state, n_estimators=int(best['n_estimators']),\n                           max_depth=int(best['max_depth']),learning_rate=best['learning_rate'],gamma=best['gamma'],\n                           reg_alpha=best['reg_alpha'],reg_lambda=best['reg_lambda'],colsample_bytree=best['colsample_bytree'],\n                           min_child_weight=best['min_child_weight'])\nmodel.fit(x_train,y_train)\n\npreds = [pred[1] for pred in model.predict_proba(x_test)]\nscore = roc_auc_score(y_test, preds, average = 'weighted')\n","4f46be88":"best","6c11121a":"print(\"auc-roc score on Test data\",score)","c31e7c42":"y_score = model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\ntitle('LGBM ROC curve')\nxlabel('FPR (Precision)')\nylabel('TPR (Recall)')\n\nplot(fpr,tpr)\nplot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","22872263":"#X_cat_train, X_cat_test, y_cat_train, y_cat_test = train_test_split(X_cat, Y_cat, test_size = 0.22, random_state = 22, stratify = Y_cat, shuffle = True)\n\ncat_model = CatBoostClassifier()\ncat_model = cat_model.fit(x_train, y_train, cat_features = cat_feat, eval_set = (x_test, y_test), early_stopping_rounds = 10, verbose = 100)\n\npredictions = [pred[1] for pred in cat_model.predict_proba(x_test)]\nprint('Validation ROC AUC Score:', roc_auc_score(y_test, predictions, average = 'weighted'))","0f94dfb5":"test","9fcbe846":"Preds = [pred[1] for pred in cat_model.predict_proba(test)]","49ed13d9":"submission = pd.DataFrame(data = {'id': id, 'Response': Preds})\nsubmission.to_csv('vehicle_insurance_catboost.csv', index = False)\nsubmission.head()","878b44cf":"id=test.id\n#test.drop(['id'],axis=1,inplace=True)","913d6503":"test['Gender'] = test['Gender'].map( {'Female': 0, 'Male': 1} ).astype(int)\ntest=pd.get_dummies(test,drop_first=True)\ntest=test.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\ntest=test.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})","087aea93":"Preds = [pred[1] for pred in model.predict_proba(test)]","d439194b":"submission = pd.DataFrame(data = {'id': id, 'Response': Preds})\nsubmission.to_csv('vehicle_insurance.csv', index = False)\nsubmission.head()","bc3d01af":"![image.png](attachment:image.png)","ac98b21d":"* No missing data","94aaef9c":"<font size=\"+3\" color='#540b11'><b> Data Preprocessing <\/b> <\/font>","06418320":"# Response and Vehicle age","82c52d4d":"# XGBoost Classifier ","502174db":"# Customers having damaged vehicle","920e52ed":"# CatBoost ","fdbd8802":"# Import Dataset","cd0dc252":"# Target Variable (Response)","39674062":"<font size=\"+3\" color='#053c96'><b>Bussiness Goal<\/b><\/font>","435bd75e":"## Save model","9f1000c4":"## ROC Curve & AUC of XG boost classifier","c81be93b":"<font size=\"+2\" color=chocolate ><b>Please Upvote my kernel if you like my work.<\/b><\/font>","15ebff5b":"# Vintage\n\nNumber of Days, Customer has been associated with the company","3f5714d6":"# Driving license by Gender","82878c96":"# Evaluating on Test data","e17c693a":"# Check for missing values","264617dd":"# Evaluate Model ","021212a0":"# Import Libraries","965ca015":"# Customers having Vehicle insurance already","b57d1ba7":"## Classification Report ","580505c1":"# Age Distribution of Customers","0b8a77e1":"Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000\/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000\/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.","891c4ff8":"<font size=\"+1\" color='blue'><b> I hope you enjoyed this kernel , Please don't forget to appreciate me with an Upvote.<\/b><\/font>","57edb627":"<font size=\"+3\" color='#053c96'><b>This Notebook will cover - <\/b><\/font>\n### 1. Exploratory Data Analysis\n### 2. Data Modelling and Evaluation","47f3ed5b":"Building a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n\nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.","93af55a6":"# Random Forest Classifier","9f4bf9ff":"<font size=\"+3\" color='#540b11'><b> Data Modelling and Evaluation <\/b> <\/font>","6a0ffa1c":"<font size=\"+3\" color='#053c96'><b> Problem Statement<\/b><\/font>","af16a784":"## ROC Curve & AUC of Random forest classifier","324afc18":"<font size=\"+3\" color='#540b11'><b> Exploratory Data Analysis <\/b><\/font>","3d63c5fd":"# Damage Vehicle and Response","7f2ec269":"# Age Vs Annual premium ","364c8e9d":"<img src=\"https:\/\/i.pinimg.com\/originals\/e2\/d7\/c7\/e2d7c71b09ae9041c310cb6b2e2918da.gif\">","1b1d9169":"# Gender and Response","fb97b718":"# Vehicle Age ","0efe7d21":"## LGBM ","742961c0":"## Catboost","36a2d85a":"# Annual Premium Distribution "}}