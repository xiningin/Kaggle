{"cell_type":{"ffdde8f2":"code","74c41c75":"code","4948aa7a":"code","e7fcd658":"code","fb962adb":"code","df272039":"code","14031db0":"code","d587879d":"code","21465109":"code","fb22c7fb":"code","feb32148":"code","b946da38":"code","d8a3d1e4":"code","9b8cc788":"code","e9fc66ab":"code","64342088":"code","c50c4642":"code","057b2fde":"code","48dc61ef":"code","e56eed9f":"code","2a236289":"code","29646824":"code","54e7cf22":"code","4bb16b0d":"code","0faa156b":"code","79045db8":"code","ba76c9b5":"code","3a85d6ca":"code","90dcbdf6":"code","0643d97c":"code","60d38149":"code","9db4475c":"code","1dbf2d7a":"code","85a1584d":"code","f55a2e89":"code","3e803dd4":"code","bed6a022":"code","944fa1c9":"code","d8779a56":"code","1f11f391":"code","f2530257":"code","5352a36e":"code","668e8ab7":"code","74eb5b71":"code","6ff5cda5":"code","2e4af21b":"code","bb8ed45f":"code","92a77814":"markdown","b756666b":"markdown","fbf4e0a6":"markdown","f772fa73":"markdown","36060643":"markdown","c087924c":"markdown","e380ab3c":"markdown","599315a0":"markdown","509eb292":"markdown","73f86c02":"markdown","b53faf5c":"markdown","ec80d08b":"markdown","d01a49b8":"markdown"},"source":{"ffdde8f2":"# Load Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport nltk\nimport nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.tokenize import RegexpTokenizer\nimport statsmodels.api as sm\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nimport re\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom nltk.stem.porter import PorterStemmer\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, SimpleRNN\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","74c41c75":"df = pd.read_csv(\"..\/input\/Womens Clothing E-Commerce Reviews.csv\", index_col=0)\ndf.head()","4948aa7a":"df.info()","e7fcd658":"df.describe()","fb962adb":"# The age distribution in data\nplt.hist(df['Age'], color=\"green\", label = \"Age\")\nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Age Distribution in Data\")","df272039":"plt.figure(figsize=(10,10))\nsns.boxplot(x = 'Rating', y = 'Age', data = df)","14031db0":"print(df['Division Name'].unique())\nprint(df['Department Name'].unique())\nprint(df['Class Name'].unique())","d587879d":"rd = df[df['Recommended IND'] == 1] # recommended\nnrd = df[df['Recommended IND'] == 0] # not recommended\nrd.head()","21465109":"plt.style.use('ggplot')\n\nfig = plt.figure(figsize=(18, 18))\nax1 = plt.subplot2grid((2, 2), (0, 0))\nax1 = plt.xticks(rotation=45)\nax1 = plt.hist(rd['Division Name'], color = \"red\", alpha = 0.5, label = \"Recommended\")\nax1 = plt.hist(nrd['Division Name'], color = \"blue\", alpha = 0.5, label = \"Not Recommended\")\nax1 = plt.title(\"Recommended Items in each Division\")\nax1 = plt.legend()\n\nax2 = plt.subplot2grid((2, 2), (0, 1))\nax2 = plt.xticks(rotation=45)\nax2 = plt.hist(rd['Department Name'], color=\"green\", alpha = 0.5, label = \"Recommended\")\nax2 = plt.hist(nrd['Department Name'], color=\"yellow\", alpha = 0.5, label = \"Not Recommended\")\nax2 = plt.title(\"Recommended Items in each Department\")\nax2 = plt.legend()\n\nax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax3 = plt.xticks(rotation=45)\nax3 = plt.hist(rd['Class Name'], color=\"blue\", alpha = 0.5, label = \"Recommended\")\nax3 = plt.hist(nrd['Class Name'], color=\"cyan\", alpha = 0.5, label = \"Not Recommended\")\nax3 = plt.title(\"Recommended Items in each Class\")\nax3 = plt.legend()","fb22c7fb":"df['Review Length'] = df['Review Text'].astype(str).apply(len)\ndf.head()","feb32148":"fig = plt.figure(figsize=(10, 5))\n#ax1 = plt.hist(df['Review Length'], color = \"red\", bins = 20)\nax = sns.distplot(df['Review Length'], color=\"blue\")\nax = plt.title(\"Length of Reviews\")","b946da38":"plt.figure(figsize=(20,10))\nsns.boxplot(x = 'Age', y = 'Review Length', data = df)","d8a3d1e4":"plt.style.use('ggplot')\n\nfig = plt.figure(figsize=(18, 18))\nax1 = plt.subplot2grid((2, 2), (0, 0))\nax1 = plt.xticks(rotation=45)\nax1 = sns.boxplot(x = 'Division Name', y = 'Review Length', data = df)\nax1 = plt.title(\"Review Length in each Division\")\n\nax2 = plt.subplot2grid((2, 2), (0, 1))\nax2 = plt.xticks(rotation=45)\nax2 = sns.boxplot(x = 'Department Name', y = 'Review Length', data = df)\nax2 = plt.title(\"Review Length in each Department\")\n\nax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax3 = plt.xticks(rotation=45)\nax3 = sns.boxplot(x = 'Class Name', y = 'Review Length', data = df)\nax3 = plt.title(\"Review Length in each Class\")","9b8cc788":"plt.figure(figsize=(10,10))\nsns.boxplot(x = 'Rating', y = 'Positive Feedback Count', data = df)","e9fc66ab":"ps = PorterStemmer()\nReviews = df['Review Text'].astype(str)\nprint(Reviews.shape)\nReviews[Reviews.isnull()] = \"NULL\"","64342088":"tokenizer = RegexpTokenizer(r'[a-zA-Z]{3,}')\nstop_words = set(stopwords.words('english'))\ndef preprocessing(data):\n    txt = data.str.lower().str.cat(sep=' ') #1\n    words = tokenizer.tokenize(txt) #2\n    words = [w for w in words if not w in stop_words] #3\n    #words = [ps.stem(w) for w in words] #4\n    return words","c50c4642":"df['tokenized'] = df[\"Review Text\"].astype(str).str.lower() # Turn into lower case text\ndf['tokenized'] = df.apply(lambda row: tokenizer.tokenize(row['tokenized']), axis=1) # Apply tokenize to each row\ndf['tokenized'] = df['tokenized'].apply(lambda x: [w for w in x if not w in stop_words]) # Remove stopwords from each row\n","057b2fde":"def string_unlist(strlist):\n    return \" \".join(strlist)\n\ndf[\"tokenized_unlist\"] = df[\"tokenized\"].apply(string_unlist)\ndf.head()\n","48dc61ef":"# Pre-Processing\nSIA = SentimentIntensityAnalyzer()\n\n# Applying Model, Variable Creation\ndf['Polarity Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['compound'])\ndf['Neutral Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['neu'])\ndf['Negative Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['neg'])\ndf['Positive Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['pos'])\n\n# Converting 0 to 1 Decimal Score to a Categorical Variable\ndf['Sentiment']=''\ndf.loc[df['Polarity Score']>0,'Sentiment']='Positive'\ndf.loc[df['Polarity Score']==0,'Sentiment']='Neutral'\ndf.loc[df['Polarity Score']<0,'Sentiment']='Negative'","e56eed9f":"conditions = [\n    df['Sentiment'] == \"Positive\",\n    df['Sentiment'] == \"Negative\",\n    df['Sentiment'] == \"Neutral\"]\nchoices = [1,-1,0]\ndf['label'] = np.select(conditions, choices)\ndf.head()","2a236289":"samples = df[\"tokenized_unlist\"].tolist()\nmaxlen = 100 \nmax_words = 10000\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(samples)\nsequences = tokenizer.texts_to_sequences(samples)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\ndata = pad_sequences(sequences, maxlen=maxlen)","29646824":"labels = np.asarray(df[\"label\"].values)\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)","54e7cf22":"indices = np.arange(df.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]","4bb16b0d":"training_samples = 11743\nvalidation_samples = 17614\nx_train = data[:training_samples]\ny_train = labels[:training_samples]\nx_val = data[training_samples: validation_samples] \ny_val = labels[training_samples: validation_samples]\nx_test = data[validation_samples:]\ny_test = labels[validation_samples:]\nx_train = pad_sequences(x_train, maxlen=maxlen)\nx_val = pad_sequences(x_val, maxlen=maxlen)","0faa156b":"# BASELINE\n# That is, if all the labels are predicted as 1\n(np.sum(df['label'] == 1)\/df.shape[0]) * 100\n\n# we have to make model that performs better than this baseline","79045db8":"def build_model():\n    model = Sequential()\n    model.add(Embedding(max_words, 100, input_length=maxlen))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['acc'])\n    return model","ba76c9b5":"model = build_model()\nmodel.summary()\nhistory = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model1.h5\")","3a85d6ca":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","90dcbdf6":"model.evaluate(x_test, y_test)","0643d97c":"def build_RNN():\n    model = Sequential() \n    model.add(Embedding(max_words, 100, input_length=maxlen)) \n    #model.add(SimpleRNN(32, return_sequences=True))\n    model.add(SimpleRNN(32)) \n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) \n    return model","60d38149":"model = build_RNN()\nmodel.summary()\nhistory_RNN = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model_RNN.h5\")","9db4475c":"acc = history_RNN.history['acc']\nval_acc = history_RNN.history['val_acc']\nloss = history_RNN.history['loss']\nval_loss = history_RNN.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","1dbf2d7a":"model.evaluate(x_test, y_test)","85a1584d":"# BASELINE\n# That is, if all the labels are predicted as 1\n(np.sum(df['Recommended IND'] == 1)\/df.shape[0]) * 100\n\n# we have to make model that performs better than this baseline","f55a2e89":"def create_dict(tokenized_list):\n    my_dict = dict([(word, True) for word in tokenized_list])\n    return my_dict\ndf[\"NBCdata\"] = df[\"tokenized\"].apply(create_dict)\nr_data = df[\"NBCdata\"].values\nreviews_labels = df[\"Recommended IND\"].values\n","3e803dd4":"reviews_data = []\nfor i in range(len(r_data)):\n    reviews_data.append([r_data[i], reviews_labels[i]])","bed6a022":"train_data = reviews_data[:18788]\ntest_data = reviews_data[18788:]","944fa1c9":"classifier = NaiveBayesClassifier.train(train_data)","d8779a56":"classifier.show_most_informative_features()","1f11f391":"accuracy = nltk.classify.util.accuracy(classifier, test_data)\nprint(\"Classification Accuracy for Recommendation is...\")\nprint(accuracy * 100)","f2530257":"# Deep learning models\nlabels = np.asarray(df[\"Recommended IND\"].values)\nlabels = labels[indices]\nx_train = data[:training_samples]\ny_train = labels[:training_samples]\nx_val = data[training_samples: validation_samples] \ny_val = labels[training_samples: validation_samples]\nx_test = data[validation_samples:]\ny_test = labels[validation_samples:]\nx_train = pad_sequences(x_train, maxlen=maxlen)\nx_val = pad_sequences(x_val, maxlen=maxlen)","5352a36e":"model = build_model()\nmodel.summary()\nhistory = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model2.h5\")","668e8ab7":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","74eb5b71":"model.evaluate(x_test, y_test)","6ff5cda5":"model = build_RNN()\nmodel.summary()\nhistory_RNN = model.fit(x_train, y_train,\n                    epochs=2,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model_RNN2.h5\")","2e4af21b":"acc = history_RNN.history['acc']\nval_acc = history_RNN.history['val_acc']\nloss = history_RNN.history['loss']\nval_loss = history_RNN.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","bb8ed45f":"model.evaluate(x_test, y_test)","92a77814":"# Which age group gives what length of comments on what type of clothes?","b756666b":"### Naive Bayes Classifier","fbf4e0a6":"# EDA - What can you Explore?\n- what age gives what type of rating?\n- What are recommended in each Division, Class, department of Clothes?\n- Which age group gives more comments\/ratings on what type of clothes?\n- Rating vs Positive feedback count\n- Lengthy Reviews for what type of cloth?\n- Positive\/Negative Reviews for what type of clothes?\n","f772fa73":"## Prediction of Recommended IND[](http:\/\/)","36060643":"### Sentiment Analysis","c087924c":"##### Baseline for Sentiment Analysis","e380ab3c":"### Deep Neural Network Classifier","599315a0":"### Simple Embedding Deep Neural Network","509eb292":"## What are Recommended Clothes item?","73f86c02":"# Ratings vs. Positive Feedback Count","b53faf5c":"## What age group has given what types of Ratings?","ec80d08b":"### RNN","d01a49b8":"# Review Analysis"}}