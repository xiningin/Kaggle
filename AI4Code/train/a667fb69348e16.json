{"cell_type":{"2328bdd1":"code","d0bf0998":"code","8bc32627":"code","05f80c42":"code","dc9a5bc0":"code","10afbecb":"code","8676b8a5":"code","a2abe560":"code","9d5f0e6b":"code","40481d56":"code","4459eb73":"code","b5e6bf88":"code","8f222bc8":"code","48eeebd5":"code","0213b3c8":"code","3bc561e8":"code","3198d9c7":"code","2b7e6425":"code","a740641c":"code","963f562d":"code","ab0dc112":"code","dfe370b8":"code","ec415e43":"code","51fd75f5":"code","fffe5821":"code","848e5f32":"code","1f1e8486":"code","9ef18d40":"code","54ebcab0":"code","9d569115":"code","6dea737f":"code","2853e976":"code","cec5b56a":"code","7b331117":"markdown","b202f8ac":"markdown","f54904ac":"markdown"},"source":{"2328bdd1":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets, linear_model\nfrom mpl_toolkits.mplot3d import axes3d\nimport seaborn as sns\nimport plotly.plotly as py\nfrom sklearn.preprocessing import scale\nimport sklearn.linear_model as skl_lm\nfrom sklearn.metrics import mean_squared_error, r2_score","d0bf0998":"'''#For LR\nimport statsmodels.api as sm\n#For LR That looks like R\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.mosaicplot import mosaic\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale'''","8bc32627":"#import os\n#print(os.getcwd())\n#os.chdir('D:\\\\DS_Notes\\\\Datasets_new\\\\')\n# Importing the dataset\ndata = pd.read_csv('..\/input\/diabetes2.csv')\n# displaying the data set\nprint(data.head())","05f80c42":"data.info()","dc9a5bc0":"#get_ipython().magic('matplotlib inline')\nsns.boxplot(data.Outcome,data.Glucose)\n#sns.boxplot(data.Outcome,data.BloodPressure)\n#sns.boxplot(data.Outcome,data.SkinThickness)\n#sns.boxplot(data.Outcome,data.Insulin)\n#sns.boxplot(data.Outcome,data.BMI)","10afbecb":"data_n=data[['Glucose','Age','DiabetesPedigreeFunction','BMI','Insulin','SkinThickness','BloodPressure']]\nsns.pairplot(data_n , height=4, kind=\"reg\",markers=\".\")","8676b8a5":"corr = data.corr()\nprint(corr)","a2abe560":"# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr,cmap=cmap, vmax=.3,square=True,linewidths=6, cbar_kws={\"shrink\": .5})\ncolormap = plt.cm.viridis\n","9d5f0e6b":"plt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(data.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white',\nannot=True)","40481d56":"data.describe()\n","4459eb73":"truediabetes= data.loc[data['Outcome']==1]\ntruediabetes.head()","b5e6bf88":"falsediabetes= data.loc[data['Outcome']==0]\nfalsediabetes.head()","8f222bc8":"#len(truediabetes)\nlen(falsediabetes)","48eeebd5":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nsb.pairplot(data.dropna(), hue='Outcome', palette=\"husl\")","0213b3c8":"data.loc[data['Outcome'] == 0, 'Glucose'].hist()","3bc561e8":"data.loc[data['Outcome']==1, 'Glucose'].hist()","3198d9c7":"plt.figure(figsize=(20, 20))\nfor column_index, column in enumerate(falsediabetes.columns):\n    if column == 'Outcome':\n        continue\nplt.subplot(4, 4, column_index + 1)\nsb.violinplot(x='Outcome', y=column, data=falsediabetes)","2b7e6425":"plt.figure(figsize=(20, 20))\nfor column_index, column in enumerate(truediabetes.columns):\n    if column == 'Outcome':\n        continue\nplt.subplot(4, 4, column_index + 1)\nsb.violinplot(x='Outcome', y=column, data=truediabetes)","a740641c":"# class distribution\nplt.figure(figsize=(10, 10))\nprint(\" class distribution \")\nprint(data.groupby('Outcome').size())\n\n'''print(\" == Univariate Plots: box and whisker plots. determine outliers = \")\ndata.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\nplt.show()\nprint(\" Univariate Plots: histograms. determine if the distribution is normal-like\")\ndata.hist()\nplt.show()'''","963f562d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n#import xgboost as xgb\nimport pydot\nfrom IPython.display import Image\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.externals.six import StringIO\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\nfrom sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\npd.set_option('display.notebook_repr_html', False)\nget_ipython().magic('matplotlib inline')\nplt.style.use('seaborn-white')","ab0dc112":"from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor","dfe370b8":"import sklearn\narray = data.values\narray\ntype(array)\n\nX = array[:,0:8] # independent variables for train\nX","ec415e43":"y = array[:,8] # dependant variable\ny[:10]","51fd75f5":"test_size = 0.33\n\nfrom sklearn.model_selection import train_test_split\n#pip install -U scikit-learn\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size)","fffe5821":"regr = skl_lm.LogisticRegression()\n\nregr.fit(X_train, y_train)\n\npred = regr.predict(X_test)\n\nregr.score(X_test,y_test)\n","848e5f32":"cm_df = pd.DataFrame(confusion_matrix(y_test,pred).T, index=regr.classes_,\ncolumns=regr.classes_)\ncm_df","1f1e8486":"cm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)\nprint(classification_report(y_test, pred))\n\nregr.score(X_test,y_test)","9ef18d40":"from sklearn.metrics import roc_curve, auc, roc_auc_score, cohen_kappa_score\nfpr, tpr, _ = roc_curve(y_test, pred)\n# Calculate the AUC\nroc_auc = auc(fpr, tpr)\nprint('ROC AUC: %0.2f' % roc_auc)\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\nregr.score(X_test,y_test)","54ebcab0":"train, test = sklearn.model_selection.train_test_split(data, train_size = 0.7)\nprint(\"For Main Data Set :\",data[\"Outcome\"].count())\nprint(\"For Train Set :\",train[\"Outcome\"].count())\nprint(\"For Test Set :\",test[\"Outcome\"].count())\nx_train=train[['Glucose','Age','DiabetesPedigreeFunction','BMI','Insulin','SkinThickness','BloodPressure','Pregnancies']]\nx_test=test[['Glucose','Age','DiabetesPedigreeFunction','BMI','Insulin','SkinThickness','BloodPressure','Pregnancies']]\ny_train=train[\"Outcome\"]\ny_test=test[\"Outcome\"]","9d569115":"est = smf.Logit(y_train,x_train).fit()\nest.summary()\n\nregr = skl_lm.LogisticRegression()\nregr.fit(x_train, y_train)\npred = regr.predict(x_test)","6dea737f":"cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T, index=regr.classes_,\ncolumns=regr.classes_)\ncm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)\nprint(classification_report(y_test, pred))","2853e976":"from sklearn.metrics import roc_curve, auc, roc_auc_score, cohen_kappa_score\nfpr, tpr, _ = roc_curve(y_test, pred)\n# Calculate the AUC\nroc_auc = auc(fpr, tpr)\nprint('ROC AUC: %0.2f' % roc_auc)\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","cec5b56a":"regr.score(x_test,y_test)","7b331117":"We see that there are no null values. Hence the data is clean.","b202f8ac":"By default, this function will create a grid of Axes such that each variable in data will by shared in the y-axis across a single row and in the x-axis across a single column. The diagonal Axes are treated differently, drawing a plot to show the univariate distribution of the data for the variable in that column.\n\n","f54904ac":"corr() is used to find the pairwise correlation of all columns in the dataframe. Any na values are automatically excluded. For any non-numeric data type columns in the dataframe it is ignored."}}