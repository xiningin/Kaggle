{"cell_type":{"a7e2fef8":"code","7b1c56c4":"code","345314ae":"code","2c31726f":"code","d96de44f":"code","b2fb792a":"code","092e28ec":"markdown","0f07b9ff":"markdown","7fac2414":"markdown","9830b5f9":"markdown","a0ee3093":"markdown","f5872e7f":"markdown","5603f7d6":"markdown","555c9e27":"markdown","454537c0":"markdown","d2d5e28a":"markdown"},"source":{"a7e2fef8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom matplotlib_venn import venn2\nimport seaborn as sns; sns.set()\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))","7b1c56c4":"df_train = pd.read_csv(\"..\/input\/train.csv\", parse_dates=[\"first_active_month\"], engine='c')\ndf_test = pd.read_csv(\"..\/input\/test.csv\", parse_dates=[\"first_active_month\"], engine='c')\nprint(\"{} observations and {} features in train set.\".format(*df_train.shape))\nprint(\"{} observations and {} features in test set.\".format(*df_test.shape))","345314ae":"df_train.target.describe()","2c31726f":"fig, ax = plt.subplots(figsize=(16, 5))\nsns.distplot(df_train.target, ax=ax)","d96de44f":"fig, ax = plt.subplots(figsize=(12, 3))\nsns.boxplot(x='target', data=df_train)","b2fb792a":"fig, axs = plt.subplots(ncols=3, figsize=(15, 10))\nsns.boxplot(x='feature_1', y='target', data=df_train, orient='v',dodge=False, ax=axs[0])\nsns.boxplot(x='feature_2', y='target', data=df_train, orient='v',dodge=False, ax=axs[1])\nsns.boxplot(x='feature_3', y='target', data=df_train, orient='v',dodge=False, ax=axs[2])","092e28ec":"## I start this kernel for discuss how to handle outliers in target values.\n\nThese bellow notebook show my anlysis resutl at current.","0f07b9ff":"## Common Methods for Detecting Outliers\n\nWhen detecting outliers, we are either doing univariate analysis or multivariate analysis. When your linear model has a single predictor, then you can use univariate analysis. However, it can give misleading results if you use it for multiple predictors. One common way of performing outlier detection is **to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed)**. This assumption is discussed in the Z-Score method section below.\n\n### Box-Plot\nThe quickest and easiest way to identify outliers is by visualizing them using plots. If your dataset is not huge (approx. up to 10k observations & 100 features), I would highly recommend you build scatter plots & box-plots of variables. If there aren\u2019t outliers, you\u2019ll definitely gain some other insights like correlations, variability, or external factors like the impact of world war\/recession on economic factors. However, this method is not recommended for high dimensional data where the power of visualization fails.\n\nOne box-plot like above showed.\n\nThe box plot uses inter-quartile range to detect outliers. Here, we first determine the quartiles Q1 and Q3.\n\nInterquartile range is given by, IQR = Q3\u200a\u2014\u200aQ1\n\nUpper limit = Q3+1.5*IQR\n\nLower limit = Q1\u20131.5*IQR\n\nAnything below the lower limit and above the upper limit is considered an outlier","7fac2414":"### Cook\u2019s Distance\nThis is a multivariate approach for finding influential points. These points may or may not be outliers as explained above, but they have the power to influence the regression model. \n\nThis method is used only for linear regression and therefore has a limited application. Cook\u2019s distance measures the effect of deleting a given observation. It\u2019s represents the sum of all the changes in the regression model when observation \u201ci\u201d is removed from it.\n\n![image.png](attachment:image.png)\n\nHere, p is the number of predictors and s\u00b2 is the mean squared error of the regression model. There are different views regarding the cut-off values to use for spotting highly influential points. A rule of thumb is that D(i) > 4\/n, can be good cut off for influential points.","9830b5f9":"Here, we normally define outliers as points whose modulus of z-score is greater than a threshold value. This threshold value is usually greater than 2 (3 is a common value).\n\n![image.png](attachment:image.png)\n\nAll the above methods are good for initial analysis of data, but they don\u2019t have much value in multivariate settings or with high dimensional data. For such datasets, we have to use advanced methods like PCA, LOF (Local Outlier Factor) & HiCS: High Contrast Subspaces for Density-Based Outlier Ranking.","a0ee3093":"#### Impact & Treatment of Outliers\nThe impact of outliers can be seen not only in predictive modeling but also in statistical tests where it reduces the power of tests. Most parametric statistics, like means, standard deviations, and correlations, and every statistic based on these, are highly sensitive to outliers. But in this post, we are focusing only on the impact of outliers in predictive modeling.\n\n#### To Drop or Not to Drop\nI believe dropping data is always a harsh step and should be taken only in extreme conditions when we\u2019re very sure that the outlier is a measurement error, which we generally do not know. The data collection process is rarely provided. When we drop data, we lose information in terms of the variability in data. When we have too many observations and outliers are few, then we can think of dropping these observations.\n\n","f5872e7f":"## Z-Score\nThis method assumes that the variable has a Gaussian distribution. It represents the number of standard deviations an observation is away from the mean:\n![image.png](attachment:image.png)","5603f7d6":"`target` value min = -33.219281, mean = -0.39 75%=0.76 max = 17.96\n\nAs following, I will create some plots to show the target distribution and more","555c9e27":"## Load train and test data.","454537c0":"According to Wikipedia, an outlier is an observation point that is distant from other observations. This definition is vague because it doesn\u2019t quantify the word \u201cdistant\u201d. In this blog, we\u2019ll try to understand the different interpretations of this \u201cdistant\u201d notion. We will also look into the outlier detection and treatment techniques while seeing their impact on different types of machine learning models.\n\nOutliers arise due to changes in system behavior, fraudulent behavior, human error, instrument error, or simply through natural deviations in populations. A sample may have been contaminated with elements from outside the population being examined.\n\nMany machine learning models, like `linear & logistic regression`, are easily impacted by the outliers in the training data. Models like `AdaBoost` increase the weights of misclassified points on every iteration and therefore might put high weights on these outliers as they tend to be often misclassified. This can become an issue if that outlier is an error of some type, or if we want our model to generalize well and not care for extreme values.","d2d5e28a":"Above two plots show that `target` values range is so big, and most value range is [-1, +1], "}}