{"cell_type":{"53e4b6e9":"code","890981bb":"code","ee1c4b2a":"code","c2aa2e16":"code","8429c7e7":"code","e5fa8691":"code","1b3406e3":"code","60b23e4e":"code","c892878b":"markdown"},"source":{"53e4b6e9":"!pip install --upgrade imutils","890981bb":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport os","ee1c4b2a":"INIT_LR = 1e-4\nEPOCHS = 20\nBS = 32","c2aa2e16":"print(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(\"..\/input\/facemask-dataset\/dataset\"))\ndata = []\nlabels = []","8429c7e7":"# loop over the image paths\nfor imagePath in imagePaths:\n\t# extract the class label from the filename\n\tlabel = imagePath.split(os.path.sep)[-2]\n\n\t# load the input image (224x224) and preprocess it\n\timage = load_img(imagePath, target_size=(224, 224))\n\timage = img_to_array(image)\n\timage = preprocess_input(image)\n\n\t# update the data and labels lists, respectively\n\tdata.append(image)\n\tlabels.append(label)","e5fa8691":"# convert the data and labels to NumPy arrays\ndata = np.array(data, dtype=\"float32\")\nlabels = np.array(labels)\n\n# perform one-hot encoding on the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\n\n# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels,\n\ttest_size=0.20, stratify=labels, random_state=42)\n\n# construct the training image generator for data augmentation\naug = ImageDataGenerator(\n\trotation_range=20,\n\tzoom_range=0.15,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.15,\n\thorizontal_flip=True,\n\tfill_mode=\"nearest\")\n\n# load the MobileNetV2 network, ensuring the head FC layer sets are\n# left off\nbaseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))\n\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False\n\n# compile our model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit(\n\taug.flow(trainX, trainY, batch_size=BS),\n\tsteps_per_epoch=len(trainX) \/\/ BS,\n\tvalidation_data=(testX, testY),\n\tvalidation_steps=len(testX) \/\/ BS,\n\tepochs=EPOCHS)\n\n# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs,\n\ttarget_names=lb.classes_))","1b3406e3":"# serialize the model to disk\nprint(\"[INFO] saving mask detector model...\")\nmodel.save(\".\/FaceMaskDetectionModel\", save_format=\"h5\")\n\n# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")\n#plt.savefig(args[\"plot\"])","60b23e4e":"Predictions=model.predict(testX[10:20])\nfor i in range(10,20):\n    X_1=testX[i]\n    Y_1=testY[i]\n    plt.imshow(X_1)\n    plt.show()\n    print(\"Predicted: \")\n    print(np.argmax(Predictions[i-10]))\n    print(\"True:\")\n    print(np.argmax(testY[i]))\n    ","c892878b":"# Beware -> Wear Mask\nThis is the code for training and testing the Face Mask Detection.\n![My project.png](attachment:f391dd52-19cd-4351-b032-0421f9bee0fb.png)\n# Please use the code for your advantage and Please upvote the notebook and dataset if you find them useful \ud83d\udc89\ud83d\udc89\ud83d\udc8a\ud83d\udc8a"}}