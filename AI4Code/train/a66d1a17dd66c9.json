{"cell_type":{"fbcd83e2":"code","5532fe50":"code","e32c9695":"code","586529b5":"code","66ed47af":"code","c008c061":"code","8b2f37a7":"code","c5155f48":"code","cb8c6cba":"code","0d5e8c41":"code","24af0283":"code","3cad6e05":"code","0f3f8016":"code","fac244e1":"markdown"},"source":{"fbcd83e2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport keras\n\nfrom keras.datasets import mnist\n\ndef load_data():\n  (train_samples,train_labels), (test_samples,test_labels) = mnist.load_data()\n  return train_samples, train_labels, test_samples, test_labels\n\ntrain_samples, train_labels, test_samples, test_labels = load_data()\n\nprint(train_samples.shape)\nprint(train_labels.shape)\nprint(test_samples.shape)\nprint(test_labels.shape)\nprint(train_labels[0:8])\nprint(np.amax(train_samples))\nprint(np.amin(train_samples))\nfor i in range(0,3):\n  pixels=train_samples[i]\n  plt.imshow(pixels, cmap = plt.cm.binary)\n  plt.show()\n  print(\"Label of image is\", train_labels[i])","5532fe50":"def convert_dtype(x):\n   \n    \n    x_float=x.astype('float32')\n    return x_float\n\ntrain_samples = convert_dtype(train_samples)\ntest_samples = convert_dtype(test_samples)\ndef normalize(x):\n  y = (x - np.min(x))\/np.ptp(x)   #ptp function is used to find the range\n  return y\n\ntrain_samples = normalize(train_samples)\ntest_samples = normalize(test_samples)\nnp.isclose(np.amax(train_samples), 1)\n\n\n\n","e32c9695":"def reshape(x):\n    \n    \n    x_r=x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n    return x_r\n\ntrain_samples = reshape(train_samples)\ntest_samples = reshape(test_samples)","586529b5":"def oneHot(y, Ny):\n    \n    import tensorflow \n    from keras.utils import to_categorical\n    Ny=len(np.unique(y))\n    y_oh=to_categorical(y,num_classes=Ny)\n    return y_oh\n\n# example\ntrain_labels = oneHot(train_labels, 10)\ntest_labels = oneHot(test_labels, 10)","66ed47af":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten\n\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","c008c061":"results = model.fit(train_samples, train_labels, validation_split = 0.1, epochs=4, batch_size=250)","8b2f37a7":"results.history.keys()\nimport matplotlib.pyplot as plt\nplt.plot(range(len(results.history['val_loss'])), results.history['val_loss'])\nplt.show()","c5155f48":"plot = pd.DataFrame()\nplot['Validation Accuracy'] = model.history.history['val_accuracy']\nplot['Training Accuracy'] = model.history.history['accuracy']\nplot['Validation Loss'] = model.history.history['val_loss']\nplot['Training Loss'] = model.history.history['loss']\nplot['Epoch'] = plot.reset_index()['index']+1\nplot","cb8c6cba":"def predict(x):\n    y = model.predict(x)\n    return y\n\npredicted_labels_train = predict(train_samples)","0d5e8c41":"def oneHot_tolabel(y):\n    \n    y_b=[]\n    from sklearn.preprocessing import LabelEncoder\n    labelencoder = LabelEncoder()\n    y_b[:, 0] = labelencoder.fit_transform(y_b[:, 0])\n    return y_b","24af0283":"def accuracy(x_train, y_train, model):\n    \n    loss,acc = model.evaluate(train_samples, train_labels,verbose=0) \n    return acc\n\nacc = accuracy(train_samples, train_labels, model)\nprint('Train accuracy is, ', acc*100, '%')","3cad6e05":"def create_confusion_matrix(true_labels, predicted_labels):\n    \n    from sklearn.metrics import confusion_matrix\n    cm = confusion_matrix(true_labels.argmax(axis=1), predicted_labels.argmax(axis=1))\n    return cm\n\ncm = create_confusion_matrix((train_labels), (predict(train_samples)))\nprint(cm)","0f3f8016":"def accuracy(x_test, y_test, model):\n    \n    loss,acc = model.evaluate(test_samples, test_labels,verbose=0) \n    return acc\n\nacc = accuracy(test_samples, test_labels, model)\nprint('Test accuracy is, ', acc*100, '%')","fac244e1":"\uf0d8 For this design, the input of the multi-layer network architecture will be a set of binary pixels representing a 28\u00d728 image of handwritten digits. The output should indicate which of the digits (0,....,9) is in the input image. \n\uf0d8 A multilayer perceptron is a class of feedforward artificial neural network. A MLP consists of, at least, three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. \n\uf0d8 The MNIST database (Modified National Institute of Standards and Technology database) of handwritten digits consists of a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. Additionally, the black and white images from NIST were size-normalized and centered to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels. \n\uf0d8 Select a subset of the MNIST database consisting around 300 images of handwritten digits (0,...,9) for training the system, and use another 100 images for testing the system. Create binary or bipolar images of handwritten digits from gray scale images available in MNIST by simple thresholding (indicate the threshold value you used). \n\uf0d8 The images from the data set have the size 28 x 28. They can also be saved in the form of CSV data files mnist_train.csv and mnist_test.csv. \n\uf0d8 Every line of these files consists of an image, i.e. 785 numbers between 0 and 255. Training data is the data our model learns from. \uf0d8 Test data is kept secret from the model until after it has been trained. Test data is used to evaluate our model."}}