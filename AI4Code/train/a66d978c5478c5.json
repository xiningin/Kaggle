{"cell_type":{"9d1d9290":"code","a5474e71":"code","fefae9b6":"code","2c7c3f3f":"code","5d6534f1":"code","7726992c":"code","fb21df04":"code","1e4335af":"code","d2ec1f3b":"code","e30edbed":"code","eaf9fc54":"code","2200dac9":"code","aa53803d":"code","c95cd8ad":"code","28436bd5":"code","46d1221c":"code","9e590211":"markdown"},"source":{"9d1d9290":"# Imports\n# Manipula\u00e7\u00e3o de dados\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n# Gr\u00e1ficos\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#Prepara\u00e7\u00e3o\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n# Cross Validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n# Modelo\nfrom sklearn.decomposition import PCA\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\n# warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a5474e71":"# Carregando os dados\nX_treino = pd.read_csv('..\/input\/competicao-dsa-machine-learning-sep-2019\/X_treino.csv')\nX_teste = pd.read_csv('..\/input\/competicao-dsa-machine-learning-sep-2019\/X_teste.csv')\ny_treino = pd.read_csv('..\/input\/competicao-dsa-machine-learning-sep-2019\/y_treino.csv')","fefae9b6":"# Adicionado a vari\u00e1vel target ao banco de treino\ndata_train = pd.merge(X_treino, y_treino, on = 'series_id')","2c7c3f3f":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n   \n    return summary","5d6534f1":"# Resumo dos dados\nresumetable(data_train)","7726992c":"# Distribui\u00e7\u00e3o das classes\ny_treino.groupby('surface').size()","fb21df04":"# Gr\u00e1fico da vari\u00e1vel target\nplt.figure(figsize = (16,6))\nfreq = len(y_treino)\n\ng = sns.countplot(x = 'surface', data = y_treino, order = y_treino['surface'].value_counts().index)\ng.set_xlabel(\"Surface\", fontsize = 18)\ng.set_ylabel(\"Quantidade\", fontsize = 18)\n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x() + p.get_width()\/2., height + 3,\n          '{:1.2f}%'.format(height\/freq * 100),\n          ha = \"center\", fontsize = 18)","1e4335af":"# Criando uma nova vari\u00e1vel 'surface_cod'\nle = preprocessing.LabelEncoder()\ndata_train['surface_cod'] = le.fit_transform(data_train['surface'])","d2ec1f3b":"data_train.describe()","e30edbed":"# Plot para distirbui\u00e7\u00f5es bi-variadas\ndados = data_train[['orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W', 'angular_velocity_X', 'angular_velocity_Y',\n                  'angular_velocity_Z', 'linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z', 'surface_cod']]\ncolunas = ['orien_X', 'orien_Y', 'orien_Z', 'orient_W', 'ang_velo_X', 'ang_velo_Y',\n                  'ang_velo_Z', 'lin_acc_X', 'lin_acc_Y', 'lin_acc_Z', 'sur_cod']\n\n# Matriz de Correla\u00e7\u00e3o com nomes das vari\u00e1veis\ncorrelations = dados.corr()\n\n# Plot\n#import numpy as np\nfig = plt.figure(figsize = (20,12))\nplt.suptitle('Matriz de Correla\u00e7\u00e3o', fontsize=22)\nax = fig.add_subplot(111)\ncax = ax.matshow(correlations, vmin = -1, vmax = 1)\nfig.colorbar(cax)\nticks = np.arange(0, 11, 1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(colunas)\nax.set_yticklabels(colunas)\nplt.show()","eaf9fc54":"# Distribui\u00e7\u00e3o\nplt.figure(figsize = (20,7))\nplt.suptitle('Distribui\u00e7\u00e3o de valores das vari\u00e1veis preditoras', fontsize=22)\nplt.subplot(241)\ng1 = sns.distplot(data_train['orientation_X'])\ng1.set_xlabel(\"orientation_X\", fontsize = 15)\n\nplt.subplot(242)\ng2 = sns.distplot(data_train['orientation_Y'])\ng2.set_xlabel(\"orientation_Y\", fontsize = 15)\n\nplt.subplot(243)\ng3 = sns.distplot(data_train['orientation_Z'])\ng3.set_xlabel(\"orientation_Z\", fontsize = 15)\n\nplt.subplot(244)\ng4 = sns.distplot(data_train['orientation_W'])\ng4.set_xlabel(\"orientation_W\", fontsize = 15)\n\nplt.figure(figsize = (20,7))\n\nplt.subplot(231)\ng5 = sns.distplot(data_train['angular_velocity_X'])\ng5.set_xlabel(\"angular_velocity_X\", fontsize = 15)\n\nplt.subplot(232)\ng6 = sns.distplot(data_train['angular_velocity_Y'])\ng6.set_xlabel(\"angular_velocity_Y\", fontsize = 15)\n\nplt.subplot(233)\ng7 = sns.distplot(data_train['angular_velocity_Z'])\ng7.set_xlabel(\"angular_velocity_Z\", fontsize = 15)\n\nplt.figure(figsize = (20, 7))\n\nplt.subplot(231)\ng8 = sns.distplot(data_train['linear_acceleration_X'])\ng8.set_xlabel(\"linear_acceleration_X\", fontsize = 15)\n\nplt.subplot(232)\ng9 = sns.distplot(data_train['linear_acceleration_Y'])\ng9.set_xlabel(\"linear_acceleration_Y\", fontsize = 15)\n\nplt.subplot(233)\ng10 = sns.distplot(data_train['linear_acceleration_Z'])\ng10.set_xlabel(\"linear_acceleration_Z\", fontsize = 15)","2200dac9":"# Dados de treino\nX_train = data_train.drop(['row_id', 'series_id', 'measurement_number', 'group_id', 'surface', 'surface_cod'],axis=1)\n\n# Normalizando os dados\nX_train = MinMaxScaler().fit_transform(X_train)\n\n# Padronizando os dados\nX_train = StandardScaler().fit_transform(X_train)","aa53803d":"# Transformando os dados\n# Carregando os dados\n\nY_train = data_train['surface_cod']\n\n# Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 7\n\n# Separando os dados em folds\nkfold = KFold(num_folds, True, random_state = seed)\n\n# Criando o modelo classificador\ncart = DecisionTreeClassifier()\n\n# Definindo o n\u00famero de trees\nnum_trees = 10\n\n# Criando o modelo bagging\nmodelo = BaggingClassifier(base_estimator = cart, n_estimators = num_trees, random_state = seed).fit(X_train, Y_train)\n\n# Cross Validation\nresultado = cross_val_score(modelo, X_train, Y_train, cv = kfold)","c95cd8ad":"# Dados de teste\nX_test = X_teste.drop(['row_id', 'series_id', 'measurement_number'],axis=1)\n\n# Normalizando os dados\nX_test = MinMaxScaler().fit_transform(X_test)\n\n# Padronizando os dados\nX_test = StandardScaler().fit_transform(X_test)\n\n# Previs\u00f5es com os dados de teste\npred = modelo.predict(X_test)","28436bd5":"# Criando o data frame para a subimiss\u00e3o\ndf_pred = pd.DataFrame({\"series_id\": X_teste.series_id, \"surface\": pred})\ndf_pred['surface'] = le.inverse_transform(df_pred['surface'])\ndf_pred_final = df_pred.drop_duplicates('series_id')","46d1221c":"# salvando a previs\u00e3o\ndf_pred_final.to_csv('arq_submission.csv', index=False)","9e590211":"## Treinando o Modelo"}}