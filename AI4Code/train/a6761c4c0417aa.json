{"cell_type":{"d87c8062":"code","3d6f4ed6":"code","25a3d5e9":"code","f411c8f3":"code","c6f2ea77":"code","e9a8d56d":"code","6c60469b":"code","99b08e54":"code","7c22c981":"code","e3866530":"code","7fe9a184":"code","e89e928b":"code","ab9b8485":"code","d500d8fa":"code","62e53462":"code","78ba47ea":"code","0cd419d1":"code","633f2009":"markdown","9d5aa8dc":"markdown","a6ffb3a5":"markdown","698660e1":"markdown","4958982f":"markdown","fff2d70c":"markdown","17158f49":"markdown","d651a9bf":"markdown","1bac9485":"markdown","292772d5":"markdown","959f5386":"markdown","5cdcac50":"markdown","48764a2f":"markdown","e9f1b3af":"markdown"},"source":{"d87c8062":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, ZeroPadding2D\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam","3d6f4ed6":"train = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashion-mnist_test.csv')\n\nprint(train.shape)\nprint(test.shape)","25a3d5e9":"train.head()","f411c8f3":"test.head()","c6f2ea77":"X_train = train.iloc[:, 1:].values.astype('float32') \/ 255\ny_train = train.iloc[:, :1].values.astype('int32')  # 1st column is 'label' for images\nX_test = test.iloc[:, 1:].values.astype('float32') \/ 255\ny_test = test.iloc[:, :1].values.astype('int32')  # 1st column is 'label' for images","e9a8d56d":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","6c60469b":"y_train","99b08e54":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","7c22c981":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","e3866530":"im_rows = 28\nim_cols = 28\nim_shape = (im_rows, im_cols, 1)\n\nX_train = X_train.reshape(X_train.shape[0], *im_shape)\nX_val = X_val.reshape(X_val.shape[0], *im_shape)\nX_test = X_test.reshape(X_test.shape[0], *im_shape)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","7fe9a184":"f, ax = plt.subplots(1,5)\nf.set_size_inches(80, 40)\n\nfor i in range(5):\n    ax[i].imshow(X_train[i].reshape(28, 28))\nplt.show()","e89e928b":"model = Sequential([\n    ZeroPadding2D((1, 1)),\n    Conv2D(32, (3, 3), activation='relu', input_shape=im_shape),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n    \n    ZeroPadding2D((1, 1)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n    \n    ZeroPadding2D((1, 1)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n    \n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(10, activation='softmax')\n])","ab9b8485":"model.compile(optimizer=Adam(lr=0.001),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","d500d8fa":"history = model.fit(X_train, y_train,\n          batch_size=240, epochs=50, verbose=1,\n          validation_data=(X_val, y_val))","62e53462":"model.summary()","78ba47ea":"score = model.evaluate(X_test, y_test, verbose=0)\nprint(score)\n\nprint('Loss :', score[0])\nprint('Accuracy : ' + str(score[1] * 100) + '%')","0cd419d1":"accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","633f2009":"# CNN (Convolutional Neural Networks) with Keras","9d5aa8dc":"## Compiling the model","a6ffb3a5":"## Evaluating the model","698660e1":"## Showing images of data","4958982f":"## Building CNN model","fff2d70c":"## Importing libraries","17158f49":"## Fitting the model","d651a9bf":"## Exploring the data","1bac9485":"## Splitting into features and labels","292772d5":"## Cross-validation","959f5386":"## One-hot encoding of labels","5cdcac50":"### This is my first published kernel :)\n### If you have any questions or feedback about my work, pls leave comments!\n### Thank you \ud83d\ude0a\ud83d\ude4f","48764a2f":"## Loading the data","e9f1b3af":"## Showing the result of model"}}