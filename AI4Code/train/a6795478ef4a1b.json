{"cell_type":{"82640ce2":"code","4bb04713":"code","50c3ca9d":"code","aa0979e1":"code","8ddbbfa5":"code","87cff607":"code","67f0c4bd":"code","4f5b99fe":"code","02fa4aff":"code","d12215ac":"code","56ba5f6b":"code","4c3f51b8":"code","39bc7388":"code","40151cbc":"code","729e1c13":"code","217d79e4":"code","0fe16be4":"code","fe9c3051":"code","b247a0eb":"code","e4bf4a75":"code","4c98e8ae":"code","3d772508":"markdown","a002e2d7":"markdown","a87de65f":"markdown","b9ad2c75":"markdown","611630bd":"markdown","aae4c296":"markdown","3ca25d1a":"markdown","749e892a":"markdown","689f7eef":"markdown","3b3d5ff4":"markdown","aae7d9a6":"markdown","8fa98c42":"markdown","be8ae68a":"markdown","a6f7bde4":"markdown","13bda4ee":"markdown","370563c9":"markdown","b73eec80":"markdown"},"source":{"82640ce2":"# load labels\nimport pandas as pd\ndf = pd.read_csv(\"..\/input\/dlub-summer-school-challenge-2021\/train.csv\")\nlabels = dict(zip(df.filename, df.category_id))\ndf = pd.read_csv(\"..\/input\/dlub-summer-school-challenge-2021\/category.csv\")\ncategories = dict(zip(df.category_id, df.category_name))\ncategories","4bb04713":"import glob\nimport cv2\nfrom tqdm import tqdm\nimport os\n\nIMG_SIZE = 299\n\n!mkdir -p \/kaggle\/working\/train_resized\n!mkdir -p \/kaggle\/working\/test_resized\n\nfor cat_id, cat_name in categories.items():\n  os.mkdir(f\"\/kaggle\/working\/train_resized\/{cat_name}\")\nos.mkdir(\"\/kaggle\/working\/test_resized\/unknown\")\n\n# Training data\nfor file in tqdm(glob.glob('..\/input\/dlub-summer-school-challenge-2021\/train\/train\/*.jpg')):\n    filename = file.split('\/')[-1]\n    subfolder = categories[labels[filename]]\n    image = cv2.imread(file)\n    resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    cv2.imwrite(f'\/kaggle\/working\/train_resized\/{subfolder}\/{filename}', resized)\n\n# Test data\nfor file in tqdm(glob.glob('..\/input\/dlub-summer-school-challenge-2021\/test\/test\/*.jpg')):\n    filename = file.split('\/')[-1]\n    image = cv2.imread(file)\n    resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    cv2.imwrite(f'\/kaggle\/working\/test_resized\/unknown\/{filename}', resized)","50c3ca9d":"import tensorflow as tf\n\nBATCH_SIZE = 32\nTRAIN_DATA_DIR = \"\/kaggle\/working\/train_resized\"\nTEST_DATA_DIR = \"\/kaggle\/working\/test_resized\"\n\ntrain_set = tf.keras.preprocessing.image_dataset_from_directory(\n    TRAIN_DATA_DIR,\n    image_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    validation_split = 0.2,\n    seed = 42,\n    shuffle = True,\n    label_mode = \"categorical\",\n    subset='training') # set as training data\n\nval_set = tf.keras.preprocessing.image_dataset_from_directory(\n    TRAIN_DATA_DIR,\n    image_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    validation_split = 0.2,\n    seed = 42,\n    shuffle = True,\n    label_mode = \"categorical\",\n    subset='validation') # set as validation data\n\ntest_set = tf.keras.preprocessing.image_dataset_from_directory(\n  TEST_DATA_DIR,\n  labels=\"inferred\",\n  shuffle = False,\n  image_size=(IMG_SIZE, IMG_SIZE),\n  batch_size=BATCH_SIZE)","aa0979e1":"import matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_set.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(categories[np.argmax(labels[i])])\n    plt.axis(\"off\")","8ddbbfa5":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.15),\n  tf.keras.layers.experimental.preprocessing.RandomTranslation(0.15, 0.15, fill_mode=\"nearest\"),\n  tf.keras.layers.experimental.preprocessing.RandomZoom(0.15),\n  tf.keras.layers.experimental.preprocessing.RandomContrast(0.2, 0.8)\n])\n\nfor image, _ in train_set.take(1):\n  plt.figure(figsize=(10, 10))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] \/ 255)\n    plt.axis('off')","87cff607":"import tensorflow as tf\n\n# Create the base model from the pre-trained model on ImageNet\nbase_model = tf.keras.applications.Xception(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                                               include_top=False,\n                                               weights='imagenet')\n\npreprocess_input = tf.keras.applications.xception.preprocess_input\n\nimage_batch, label_batch = next(iter(train_set))\nfeature_batch = base_model(image_batch)\nprint(f\"Extracted features shape by base model: {feature_batch.shape}\")\nprint(f\"Number of layers in the base model: {len(base_model.layers)}\")","67f0c4bd":"inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x)                                           # pretrained base model\nx = tf.keras.layers.GlobalAveragePooling2D()(x)             # add a global spatial average pooling layer\nx = tf.keras.layers.Dense(1024, activation='relu')(x)       # fully-connected layer\nx = tf.keras.layers.Dropout(0.6)(x)\noutputs = tf.keras.layers.Dense(len(categories), activation='softmax')(x)               # a logistic layer -- for 25 food classes\n\n# final model\nmodel = tf.keras.Model(inputs, outputs)","4f5b99fe":"# Freeze base model\nbase_model.trainable = False\n\nBASE_LEARNING_RATE = 0.0001\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=BASE_LEARNING_RATE),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\nmodel.summary()","02fa4aff":"EPOCHS = 20\n\nearlystop_callback = tf.keras.callbacks.EarlyStopping(\n  monitor='val_accuracy', patience=3)\n\nhistory = model.fit(train_set,\n                    epochs=EPOCHS,\n                    callbacks = [earlystop_callback],\n                    validation_data=val_set)","d12215ac":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,5.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","56ba5f6b":"# Fine-tune from this layer onwards\nfine_tune_from = 100\n\n# Freeze all the layers after the `fine_tune_from` layer\nbase_model.trainable = True\nfor layer in base_model.layers[:fine_tune_from]:\n  layer.trainable = False","4c3f51b8":"model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n              optimizer = tf.keras.optimizers.RMSprop(learning_rate=BASE_LEARNING_RATE\/10, momentum=0.9),\n              metrics=['accuracy'])\nmodel.summary()\nprint(f\"Number of trainable model variables: {len(model.trainable_variables)}\")","39bc7388":"FINE_TUNE_EPOCHS = 20\nTOTAL_EPOCHS =  EPOCHS + FINE_TUNE_EPOCHS\n\nearlystop_callback = tf.keras.callbacks.EarlyStopping(\n  monitor='val_accuracy', patience=3)\n\nhistory_fine = model.fit(train_set,\n                         epochs=TOTAL_EPOCHS,\n                         callbacks=[earlystop_callback],\n                         initial_epoch=history.epoch[-1],\n                         validation_data=val_set)","40151cbc":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.3, 1])\nplt.plot([EPOCHS-1,EPOCHS-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 5.0])\nplt.plot([EPOCHS-1,EPOCHS-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","729e1c13":"# Save the weights\nmodel.save_weights('\/kaggle\/working\/checkpoints\/checkpoint299')\n!ls -la checkpoints","217d79e4":"# Restore the weights\nmodel.load_weights('\/kaggle\/working\/checkpoints\/checkpoint299')","0fe16be4":"predictions = model.predict(test_set)","fe9c3051":"predictions_label = []\nfor i, pred in enumerate(predictions):\n  predictions_label.append([f\"test_{i+1:04}.jpg\", np.argmax(pred)])","b247a0eb":"submission = pd.DataFrame(data=predictions_label, columns = [\"filename\", \"category_id\"])\nsubmission.head()","e4bf4a75":"submission.to_csv(\"\/kaggle\/working\/submission.csv\", index = False)","4c98e8ae":"!nvidia-smi -L","3d772508":"### Learning curves","a002e2d7":"## Data loading","a87de65f":"# DL UB Summer school 2021 kaggle competition\nhttps:\/\/www.kaggle.com\/c\/dlub-summer-school-challenge-2021\/overview","b9ad2c75":"## Resize images and move them to sub folder according to labels","611630bd":"# Save the model","aae4c296":"# Train the model","3ca25d1a":"## Load labels","749e892a":"# Submission","689f7eef":"# Transfer learning","3b3d5ff4":"## Unfreeze the top layers to learn specific features of our dataset","aae7d9a6":"## Compile the model","8fa98c42":"# Fine tune the model further","be8ae68a":"## Load saved model","a6f7bde4":"## Learning curves after fine-tuning","13bda4ee":"## Data augmentation","370563c9":"## Visualize the data","b73eec80":"## Construct the model"}}