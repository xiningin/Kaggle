{"cell_type":{"444ffaff":"code","73459062":"code","24280918":"code","c5d26169":"code","6adad4d8":"code","a52d67b3":"code","6fb7774e":"code","1a0a25cd":"code","af6fdd1f":"code","07c4e637":"code","8870da23":"code","3df46ce1":"code","be296c68":"code","1676f09b":"code","35daee82":"code","8615e347":"code","d8a695a5":"code","498c28de":"code","18536085":"markdown","b616f1c0":"markdown","a64900ba":"markdown","398aed9b":"markdown","07057c6b":"markdown","44cd5b6b":"markdown","8632962f":"markdown"},"source":{"444ffaff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","73459062":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm, trange\nfrom PIL import Image\nfrom time import sleep\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport ssl\n%matplotlib inline\nssl._create_default_https_context = ssl._create_unverified_context","24280918":"train_pth = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ntest_pth = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\ntrain = pd.read_csv(train_pth)\ntest = pd.read_csv(test_pth)\nprint(\"train: {}\".format(len(train)))\nprint(\"test: {}\".format(len(test)))","c5d26169":"class MNIST(Dataset):\n    def __init__(self, df, phase, transform=None):\n        self.phase = phase\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if self.phase in ['train', 'val']:\n            image = self.df.iloc[idx,1:].values.reshape((28,28)).astype(np.uint8)\n#             X = Image.fromarray(np.concatenate((image,image,image),axis=2))\n            X = Image.fromarray(image)\n            y = np.array(self.df.iloc[idx,0])\n            return self.transform(X), torch.from_numpy(y)\n        else:\n            image = self.df.iloc[idx].values.reshape((28,28)).astype(np.uint8)\n#             X = Image.fromarray(np.concatenate((image,image,image),axis=2))\n            X = Image.fromarray(image)\n            return self.transform(X)","6adad4d8":"transform = transforms.Compose([\n    transforms.RandomRotation(10),\n    transforms.ToTensor()\n])","a52d67b3":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1,16,5,1,2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(16,64,5,1,2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(64,128,5,1,2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128,256,5,1,2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 7 * 7, 32 * 7 * 7, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5, inplace=False),\n            nn.Linear(32 * 7 * 7, 4 * 7 * 7, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5, inplace=False),\n            nn.Linear(4 * 7 * 7, 10, bias=True)\n        )\n        # (input_size + padding*2 - kernel_size) \/ stride + 1 = output_size\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        output = self.classifier(x)\n        return output\n    ","6fb7774e":"EPOCH = 30\nBATCH_SIZE = 64\nLR = 0.001","1a0a25cd":"model = CNN()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\ncriterion = nn.CrossEntropyLoss()\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3,verbose=True)","af6fdd1f":"train = pd.read_csv(train_pth)\ntest = pd.read_csv(test_pth)\n\ntrain, val = train_test_split(train, test_size = 0.1)\n\ntrain_data = MNIST(train, 'train', transform)\ntest_data = MNIST(val, 'val', transform)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)","07c4e637":"valid_loss_min = np.Inf\ntrain_losses, valid_losses = [], []\nhistory_accuracy = []\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","8870da23":"for epoch in range(1, EPOCH+1):\n    running_loss = 0\n    model.train()\n    try:\n        with tqdm(train_loader, desc='Epoch [{}\/{}]'.format(epoch, EPOCH)) as pbar1:\n            for x, y in pbar1:\n                x, y = x.to(device), y.to(device)\n\n                optimizer.zero_grad()\n                output = model(x)\n                loss = criterion(output, y)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n                pbar1.set_postfix(loss=loss.item(), refresh=True)\n            train_losses.append(running_loss \/ len(train_loader))\n            lr_scheduler.step(train_losses[-1])\n            sleep(0.5)\n    except KeyboardInterrupt:\n        pbar1.close()\n        raise\n    pbar1.close()\n        \n    with torch.no_grad():\n        try:\n            with tqdm(test_loader, desc='Testing') as pbar2:\n                model.eval()\n                accuracy = 0\n                valid_loss = 0\n                for x, y in pbar2:\n                    x, y = x.to(device), y.to(device)\n                    test_output = model(x)\n                    batch_loss = criterion(test_output, y)\n                    valid_loss += batch_loss\n                    pred_y = torch.max(test_output, 1)[1].data.squeeze()\n                    batch_correct = pred_y.eq(y.data.view_as(pred_y)).cpu().sum()\n\n                    batch_acc = batch_correct.item() \/ y.size(0)\n                    pbar2.set_postfix(loss=batch_loss.item(), acc=batch_acc, refresh=True)\n                    accuracy += batch_acc\n                valid_losses.append(valid_loss \/ len(test_loader))\n                history_accuracy.append(accuracy \/ len(test_loader))\n\n                if valid_losses[-1] < valid_loss_min:\n                    torch.save(model.state_dict(), \"model.pth\")\n                    valid_loss_min = valid_losses[-1]\n        except KeyboardInterrupt:\n            pbar2.close()\n            raise\n        pbar2.close()\n    \n    print(\"\\tEpoch[{}\/{}]\\ttrain_loss:{:.6f}\\tvalid_loss:{:.6f}\\tvalid_acc:{:.4f}\".format\n          (epoch,EPOCH,train_losses[-1],valid_losses[-1],history_accuracy[-1]))\n    sleep(0.5)","3df46ce1":"plt.plot(train_losses, label='Training Loss')\nplt.plot(valid_losses, label='Validation Loss')\nplt.legend(frameon=False)","be296c68":"plt.plot(history_accuracy, label='Validation Accuracy')\nplt.legend(frameon=False)","1676f09b":"model = CNN()\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()","35daee82":"dataset = MNIST(test, 'test', transform)\ndataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE)\nmodel.to(device)\npred_y = torch.LongTensor()\n\ntry:\n    with tqdm(dataloader) as pbar3:\n        for i, data in enumerate(pbar3):\n            data = data.to(device)\n            output = model(data)\n            pred_y = torch.cat((pred_y, torch.max(output, axis=1)[1].cpu().data),dim=0)\nexcept KeyboardInterrupt:\n    pbar3.close()\n    raise\npbar3.close()","8615e347":"submission = pd.DataFrame(np.c_[np.arange(1, len(dataset)+1)[:,None], pred_y], \n                      columns=['ImageId', 'Label'])","d8a695a5":"submission.head()","498c28de":"submission.to_csv('submission.csv', index=False)","18536085":"# Load data","b616f1c0":"# Visualize","a64900ba":"# Submission","398aed9b":"# Create dataset","07057c6b":"# Test","44cd5b6b":"# CNN Model","8632962f":"# Train"}}