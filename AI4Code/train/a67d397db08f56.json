{"cell_type":{"29ee7296":"code","bdb263f1":"code","877c733e":"code","3a816bf9":"code","7879ab85":"code","11e81594":"code","4f726c81":"code","c56ab9b9":"code","76b44a14":"code","655f73f3":"code","483a3ac8":"code","6f84819a":"code","366c6e88":"code","4a75a170":"code","897b9a76":"code","43d01e16":"code","884e0d20":"code","2f6903c4":"markdown","2e27569c":"markdown","c5798c4f":"markdown","cf37a8e9":"markdown","542c3848":"markdown","27c21501":"markdown","19c2cc94":"markdown","3fc98884":"markdown","e160ae3c":"markdown","bf4a0eb2":"markdown","be4168b2":"markdown","60cc699b":"markdown","8a9bf559":"markdown","f9c12194":"markdown","2a37f8b3":"markdown","ae70be2a":"markdown","3b73971f":"markdown"},"source":{"29ee7296":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bdb263f1":"df_train = pd.read_csv('..\/input\/iris-train.csv')\ndf_test = pd.read_csv('..\/input\/iris-test.csv')\ndf_train.head(5)","877c733e":"def conversion(a):\n    if a== 'Iris-setosa':\n        return 0\n    elif a== 'Iris-versicolor':\n        return 1\n    elif a == 'Iris-virginica':\n        return 2","3a816bf9":"def reverse(b):\n    if b== 0:\n        return 'Iris-setosa'\n    elif b== 1:\n        return 'Iris-versicolor'\n    elif b == 2:\n        return 'Iris-virginica' ","7879ab85":"df_train['tgt'] = list(map(conversion,df_train['Species']))\ndf_train.head(5)","11e81594":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import normalize\nmodelo = LogisticRegression()","4f726c81":"X = df_train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\nY = df_train['tgt']","c56ab9b9":"X_test = df_test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]","76b44a14":"from sklearn.model_selection import KFold","655f73f3":"kf=KFold(n_splits=5, random_state=None, shuffle=True)\nsplit = 1\nsum_score=0\nfor train_index, test_index in kf.split(X,Y):\n    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n    modelo.fit(x_train,y_train)\n    score = modelo.score(x_test,y_test)\n    print('Split: ' + str(split)+' - Score: '+str(score))\n    split+=1\n    sum_score+=score\nprint('M\u00e9dia do Score: '+str(sum_score\/split))","483a3ac8":"from sklearn.neural_network import MLPClassifier\n\nclf = MLPClassifier(activation='logistic',solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(8, 4), random_state=1)\n\nkf=KFold(n_splits=5, random_state=None, shuffle=True)\nsplit = 1\nsum_score=0\nfor train_index, test_index in kf.split(X,Y):\n    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n    clf.fit(x_train,y_train)\n    score = clf.score(x_test,y_test)\n    print('Split: ' + str(split)+' - Score: '+str(score))\n    split+=1\n    sum_score+=score\nprint('M\u00e9dia do Score: '+str(sum_score\/split))","6f84819a":"modelo.fit(X,Y)","366c6e88":"df_test['tgt'] = modelo.predict(X_test)","4a75a170":"df_test['Species'] = list(map(reverse,df_test['tgt']))","897b9a76":"modelo.score(df_test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']],df_test['tgt'])","43d01e16":"df_final = df_test[['Id','Species']]","884e0d20":"import sys\ndf_final.to_csv(sys.stdout)","2f6903c4":"# Cria\u00e7\u00e3o do objeto LogisticRegression","2e27569c":"# Gerando o arquivo final para submeter no Kaggle","c5798c4f":"# O modelo de regress\u00e3o log\u00edstica obteve uma m\u00e9dia de 0.79 nos scores, enquanto que o modelo MLP apresentou uma m\u00e9dia de 0.60, portanto o modelo escolhido para gerar o arquivo final ser\u00e1 o de regress\u00e3o log\u00edstica","cf37a8e9":"# Leitura dos arquivos CSV para o DataFrame","542c3848":"# Criando uma nova coluna 'tgt' para o c\u00f3digo da classe e aplicando a fun\u00e7\u00e3o map para isso","27c21501":"# Sele\u00e7\u00e3o dos atributos de entrada e sa\u00edda do dataframe de treino","19c2cc94":"# Criando uma nova coluna para a descri\u00e7\u00e3o das classes e aplicando o map para reverter os respectivos c\u00f3digos para as descri\u00e7\u00f5es","3fc98884":"# Aplicando o KFold no modelo MLP (Escolhido 5 splits) e calculada a m\u00e9dia dos scores","e160ae3c":"# Gerando o DataFrame final somente com os campos Id e Species para ficar de acordo com o Kaggle","bf4a0eb2":"# Sele\u00e7\u00e3o dos atributos de entrada do dataframe de teste","be4168b2":"# Treinando o modelo final de regress\u00e3o log\u00edstica","60cc699b":"# Criando uma nova coluna 'tgt' para o c\u00f3digo da classe e aplicando a fun\u00e7\u00e3o map para isso","8a9bf559":"# Aplica\u00e7\u00e3o do KFold no modelo de regress\u00e3o log\u00edstica (Escolhido 5 splits) e calculada a m\u00e9dia dos scores.","f9c12194":"# Fun\u00e7\u00e3o para converter a string em um c\u00f3digo de classe","2a37f8b3":"# Importa\u00e7\u00e3o do KFold para fazer a valida\u00e7\u00e3o do treinamento","ae70be2a":"# Calculando o score no dataframe de teste","3b73971f":"# Criando uma coluna nova no dataframe de teste e atribuindo as recpectivas classes que o modelo fez a previs\u00e3o"}}