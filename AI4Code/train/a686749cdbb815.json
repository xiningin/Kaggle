{"cell_type":{"f9681920":"code","8ce92a01":"code","f10ba3af":"code","6448954c":"code","68791d7d":"code","fd567bdc":"code","7ce42d5d":"markdown","307a5606":"markdown"},"source":{"f9681920":"import keras\nfrom keras.datasets import mnist\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Sequential\n\n# Loading the dataset and perform splitting\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n# Peforming reshaping operation\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n\n# Normalization\nx_train = x_train \/ 255\nx_test = x_test \/ 255\n\n# One Hot Encoding\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)\n# Building the Model Architecture\n\nmodel = Sequential()\n# Select 6 feature convolution kernels with a size of 5 * 5 (without offset), and get 66 feature maps. The size of each feature map is 32\u22125 + 1 = 2832\u22125 + 1 = 28.\n# That is, the number of neurons has been reduced from 10241024 to 28 \u2217 28 = 784 28 \u2217 28 = 784.\n# Parameters between input layer and C1 layer: 6 \u2217 (5 \u2217 5 + 1)\nmodel.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n# The input of this layer is the output of the first layer, which is a 28 * 28 * 6 node matrix.\n# The size of the filter used in this layer is 2 * 2, and the step length and width are both 2, so the output matrix size of this layer is 14 * 14 * 6.\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# The input matrix size of this layer is 14 * 14 * 6, the filter size used is 5 * 5, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n# The output matrix size of this layer is 10 * 10 * 16. This layer has 5 * 5 * 6 * 16 + 16 = 2416 parameters\nmodel.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n# The input matrix size of this layer is 10 * 10 * 16. The size of the filter used in this layer is 2 * 2, and the length and width steps are both 2, so the output matrix size of this layer is 5 * 5 * 16.\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\n# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\nmodel.add(Dense(84, activation='relu'))\n# The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()\nmodel.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\nmodel.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test)\nprint('Test Loss:', score[0])\nprint('Test accuracy:', score[1])","8ce92a01":"x_train.shape","f10ba3af":"import pandas as pd\nimport numpy as np","6448954c":"test=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest.head()","68791d7d":"test = test \/ 255.0\ntest=test.values.reshape(len(test),28,28,1)","fd567bdc":"\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nprint(submission)\n\nsubmission.to_csv(\"submission_mnist_datagen_LeNet.csv\",index=False)","7ce42d5d":"Test with ..\/input\/digit-recognizer\/test","307a5606":"# Deep-Learning-Classification\n\n### Digit-Recognizer\n\nTired to solve the Kaggle Compitition of Digit Recognizer with different network and hyperparameters. \n\nCompitition link - https:\/\/www.kaggle.com\/c\/digit-recognizer\/overview\n\n\nWith accuracy of 99.67 after attempting Different Hyperparameters.\n\nFull Source Code using Keras Tuner - https:\/\/github.com\/FGpramodgupta\/Deep-Learning-Classification-using-Keras-Tuner \n\nProfile - https:\/\/github.com\/FGpramodgupta\n"}}