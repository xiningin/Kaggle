{"cell_type":{"04bef6b4":"code","78b3b44a":"code","1507ef6e":"code","41185244":"code","d3ba2145":"code","27c4c62c":"code","500e386b":"markdown","31f55a03":"markdown","441d02a7":"markdown"},"source":{"04bef6b4":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom tqdm import tqdm\nfrom sklearn.svm import SVC\n# from keras.models import Sequential\n# from keras.layers.recurrent import LSTM, GRU\n# from keras.layers.core import Dense, Activation, Dropout\n# from keras.layers.embeddings import Embedding\n# from keras.layers.normalization import BatchNormalization\n# from keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\n# from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n# from keras.preprocessing import sequence, text\n# from keras.callbacks import EarlyStopping\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","78b3b44a":"fake = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")\ntrue = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")\n\nfake[\"fake\"] = 1\ntrue[\"fake\"] = 0\n\nfake.head()","1507ef6e":"true.head()","41185244":"frames = [fake, true]\ncombined = pd.concat(frames)\ndisplay(combined)","d3ba2145":"msk = np.random.randn(len(combined)) <= 0.7\n\ntrain = combined[msk]\ntest = combined[~msk]\n\nlen(train), len(test)","27c4c62c":"train.to_csv(\"train.csv\")\ntest.to_csv(\"test.csv\")","500e386b":"## Splitting into train and test","31f55a03":"## Combining and adding labels","441d02a7":"# Tackling an NLP problem\n\nIn this I am using guidance from this detailed notebook : https:\/\/www.kaggle.com\/abhishek\/approaching-almost-any-nlp-problem-on-kaggle\/data. This notebook is hugely popular but can it tackle this dataset?"}}