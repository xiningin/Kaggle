{"cell_type":{"b8367b1e":"code","ac616ba6":"code","3e1f3994":"code","d0f0140d":"code","24819ade":"code","ac5ef454":"code","0b2fc790":"code","4368fa72":"code","b8924304":"markdown","26dd7051":"markdown","492f3c16":"markdown","ce1c8a76":"markdown","cf9de0f5":"markdown","04a4938d":"markdown"},"source":{"b8367b1e":"from __future__ import print_function\nimport numpy as np \nimport pandas as pd\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Dropout\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam ,RMSprop\nfrom keras import backend as K\nimport matplotlib.pyplot as plt \n%matplotlib inline","ac616ba6":"batch_size = 128 # Modelin ayn\u0131 anda ka\u00e7 veriyi i\u015fleyece\u011fi anlam\u0131na gelmektedir. (Backpropagation & Gradient Descent i\u00e7in)\ndropout = 0.45\nepochs = 20\nhidden_units = 256","3e1f3994":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n","d0f0140d":"# \u00d6rnek 25 mnist digitlerini train datasetten \u00e7ektik.\nindexes = np.random.randint(0, x_train.shape[0], size=25)\nimages = x_train[indexes]\nlabels = y_train[indexes]\n\n# Plot edelim.\nplt.figure(figsize=(5,5))\nfor i in range(len(indexes)):\n    plt.subplot(5, 5, i + 1)\n    image = images[i]\n    plt.imshow(image, cmap='gray')\n    plt.axis('off')\n    \nplt.show()","24819ade":"# Label say\u0131s\u0131n\u0131 yani asl\u0131nda ka\u00e7 tane class'\u0131m\u0131z oldu\u011funu \u00f6\u011frenelim\nnum_labels = len(np.unique(y_train))\nnum_labels ","ac5ef454":"# One-Hot Encoding -> Class vekt\u00f6rlerini binary class matrislerine d\u00f6n\u00fc\u015ft\u00fcrelim.\ny_train = keras.utils.to_categorical(y_train, num_labels)\ny_test = keras.utils.to_categorical(y_test, num_labels)","0b2fc790":"# Verilerin daha iyi i\u015flenmesi i\u00e7in normalize edelim.\nimage_size = x_train.shape[1]\ninput_size = image_size * image_size\ninput_size # boyutunu \u00f6\u011frendik\n\nx_train = np.reshape(x_train, [-1, input_size])\nx_train = x_train.astype('float32') \/ 255\nx_test = np.reshape(x_test, [-1, input_size])\nx_test = x_test.astype('float32') \/ 255","4368fa72":"model = Sequential()\nmodel.add(Dense(hidden_units, input_dim=input_size))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(hidden_units))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n\nloss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc)) ","b8924304":"## Datay\u0131 y\u00fckleme ve Split etme:","26dd7051":"## K\u00fct\u00fcphaneleri Import Etme:","492f3c16":"## Hiperparemetreleri Belirleme:","ce1c8a76":"## Datay\u0131 G\u00f6rselle\u015ftirme:","cf9de0f5":"## MNIST Dataseti:\n\n* MNIST, 0 ile 9 aras\u0131nda de\u011fi\u015fen el yaz\u0131s\u0131 rakamlardan olu\u015fan bir koleksiyondur.\n\n* 60.000 g\u00f6r\u00fcnt\u00fcden olu\u015fan bir e\u011fitim setine ve kar\u015f\u0131l\u0131k gelen kategorilere veya etiketlere g\u00f6re s\u0131n\u0131fland\u0131r\u0131lm\u0131\u015f 10.000 test g\u00f6r\u00fcnt\u00fcs\u00fcne sahiptir.\n\n* MNIST veri k\u00fcmesini Keras'ta kullanmak i\u00e7in, g\u00f6r\u00fcnt\u00fcleri ve etiketleri otomatik olarak indirmek ve ay\u0131klamak i\u00e7in bir API'dan yararlan\u0131l\u0131r.","04a4938d":"## Bu Notebook Neler \u0130\u00e7eriyor:\n\n* Bu notebook'da, MNIST veri k\u00fcmesinin Multilayer Perceptron (MLP) modelini olu\u015fturuyoruz.\n\n* \u00c7ok katmanl\u0131 MLP'lerde genellikle bir katmandaki her bir n\u00f6ron, bir sonraki katmandaki t\u00fcm n\u00f6ronlara ba\u011fl\u0131d\u0131r. Bu a\u011flar\u0131n \"tam ba\u011flant\u0131l\u0131 olmas\u0131\", onlar\u0131 verilere a\u015f\u0131r\u0131 uymaya e\u011filimli hale getirir.\n\n* Bu MLP modelleri, ileri beslemeli derin a\u011flar (deep feedforward networks) veya ileri beslemeli sinir a\u011flar\u0131(feedforward neural networks) olarak da adland\u0131r\u0131l\u0131r. MLP'ler basit lojistik ve do\u011frusal regresyon problemlerinde yayg\u0131nd\u0131r.\n\n* Ama\u00e7, el yaz\u0131s\u0131 rakamlara g\u00f6re say\u0131lar\u0131 tan\u0131mlamak i\u00e7in bir sinir a\u011f\u0131 olu\u015fturmakt\u0131r. \u00d6rne\u011fin, yaz\u0131, 8 numaras\u0131n\u0131n g\u00f6r\u00fcnt\u00fcs\u00fc oldu\u011funda, kar\u015f\u0131l\u0131k gelen tahmin de 8 rakam\u0131 olmal\u0131d\u0131r."}}