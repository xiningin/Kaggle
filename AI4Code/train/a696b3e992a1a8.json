{"cell_type":{"3e27c891":"code","c690c3b8":"code","270a2d01":"code","ca4e3ef2":"code","620f0506":"code","96379108":"code","8f3bc628":"code","aae7ff9c":"code","ce374f6b":"code","efe5454c":"code","3b90e91a":"code","7e6fa716":"code","7e8de815":"code","821c6736":"code","bd39386c":"code","702cfba5":"code","10306803":"code","9cff8999":"code","8c58db5a":"code","27608271":"code","1e65ace2":"code","74ec7086":"markdown","f01aed1c":"markdown","92c15574":"markdown","78e60b9c":"markdown","95cb175e":"markdown","c85f4f5d":"markdown","3785c4b5":"markdown","a3cd1afa":"markdown"},"source":{"3e27c891":"import numpy as np\nfrom scipy import stats \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Activation\n","c690c3b8":"(X_train,Y_train),(X_test,Y_test) = imdb.load_data(path = \"imdb.npz\",\n                                                  num_words= None,\n                                                  skip_top=0,\n                                                  maxlen=None,\n                                                  seed=113,\n                                                  start_char=1,\n                                                  oov_char=2,\n                                                  index_from=3)\n","270a2d01":"print(\"Type: \",type(X_train))\nprint(\"Type: \",type(Y_train))\nprint()\nprint(\"X_train Shape: \",X_train.shape)\nprint(\"X_train Shape: \",Y_train.shape)","ca4e3ef2":"print(\"Y_train Values: \",np.unique(Y_train))\nprint(\"Y_test Values: \",np.unique(Y_test))","620f0506":"unique, counts = np.unique(Y_train,return_counts=True)\nprint(\"Y Train distribution: \",dict(zip(unique,counts)))\n\nunique, counts = np.unique(Y_test,return_counts=True)\nprint(\"Y Test distribution: \",dict(zip(unique,counts)))\n\n","96379108":"plt.figure()\nsns.countplot(Y_train)\nplt.xlabel(\"Classes\")\nplt.ylabel(\"Freq\")\nplt.title(\"Y_train\")","8f3bc628":"plt.figure()\nsns.countplot(Y_test)\nplt.xlabel(\"Classes\")\nplt.ylabel(\"Freq\")\nplt.title(\"Y_test\")","aae7ff9c":"d = X_train[0]\nprint(d)\nprint()\nprint(\"Len X train[0]\",len(d))","ce374f6b":"review_len_train = []\nreview_len_test = []\nfor i, ii in zip(X_train,X_test):\n    review_len_train.append(len(i))\n    review_len_test.append(len(ii))\n#distribution of word counts in comments made by people\nsns.distplot(review_len_train, hist_kws={\"alpha\":0.3})\nsns.distplot(review_len_test, hist_kws={\"alpha\":0.3})","efe5454c":"print(\"Train mean: \",np.mean(review_len_train))\nprint(\"Train mean: \",np.median(review_len_train))\nprint(\"Train mode: \",stats.mode(review_len_train))\n","3b90e91a":"word_index = imdb.get_word_index()\nprint(type(word_index))\nprint(len(word_index))\n\nfor keys, values in word_index.items():\n    if values ==61:\n        print(keys)\n    elif values ==4:\n        print(keys)","7e6fa716":"def whatItSay(index = 61):\n    reverse_index = dict([(value,key) for (key, value) in word_index.items()])\n    decode_review = \" \".join([reverse_index.get(i - 3,\"!\") for i in X_train[index]])\n    print(decode_review)\n    print(Y_train[index])\n    return decode_review\ndecode_review = whatItSay(5)","7e8de815":"num_words = 15000\n\n(X_train,Y_train),(X_test,Y_test) = imdb.load_data(num_words=num_words)","821c6736":"maxlen = 130\nX_train = pad_sequences(X_train,maxlen=maxlen)\nX_test = pad_sequences(X_test,maxlen=maxlen)\n\nprint(X_train[5])","bd39386c":"for i in X_train[0:10]:\n    print(len(i))","702cfba5":"decode_review = whatItSay(5)","10306803":"rnn = Sequential()\nrnn.add(Embedding(num_words, 32, input_length = len(X_train[0])))\nrnn.add(SimpleRNN(16,input_shape = (num_words,  maxlen),return_sequences = False, activation = \"relu\"))\nrnn.add(Dense(1))\nrnn.add(Activation(\"sigmoid\"))\n\nprint(rnn.summary())\nrnn.compile(loss=\"binary_crossentropy\",optimizer = \"rmsprop\", metrics = [\"accuracy\"])\n","9cff8999":"history = rnn.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs = 5, batch_size = 256,verbose=1)\n","8c58db5a":"score = rnn.evaluate(X_test,Y_test)\nprint(\"Accuracy: %\",score[1]*100)","27608271":"plt.figure()\nplt.plot(history.history[\"accuracy\"],label=\"Train\")\nplt.plot(history.history[\"val_accuracy\"],label = \"Test\")\nplt.title(\"Accuracy\")\nplt.ylabel(\"Acc\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.show()","1e65ace2":"plt.figure()\nplt.plot(history.history[\"loss\"],label=\"Train\")\nplt.plot(history.history[\"val_loss\"],label = \"Test\")\nplt.title(\"Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.show()","74ec7086":"# Import Library","f01aed1c":"# IMDB Sentiment Analysis","92c15574":"# Problem Description and Data Import","78e60b9c":"# EDA","95cb175e":"# Process","c85f4f5d":"# Training Neural Network","3785c4b5":"# Construct RNN ","a3cd1afa":"# Evaluate Result"}}