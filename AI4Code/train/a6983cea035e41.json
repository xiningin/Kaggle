{"cell_type":{"87b27391":"code","43abf821":"code","f5552681":"code","a90e8b3d":"code","e1f58d88":"code","2bdc56f3":"code","eded2bcc":"code","e4e63b9f":"code","f890013c":"code","54d51b81":"code","8e01ad20":"code","ce835d64":"code","a7854c7a":"code","8abbfe52":"code","a6f9bd5d":"code","10ff167a":"code","b1422212":"code","32fda62f":"code","33b377e8":"code","9d9249a7":"code","ba95105b":"code","0436c691":"code","93b6f4b5":"code","445a38a9":"code","fa0817a1":"code","21d8ad80":"code","5f53b18c":"code","0198304e":"code","0678d4f8":"code","30e2ab1f":"code","0db17f09":"code","ab8039ab":"code","6a272844":"code","968a902f":"code","81370b2e":"code","a926acc7":"code","6bbd3212":"code","5dcdce7d":"code","1c892543":"code","d89bd4b1":"code","1ec2c025":"code","f82f3e0c":"code","91a1dd1f":"code","7acd315a":"code","5ebba9a2":"code","28525190":"code","65101b47":"markdown","48fade43":"markdown","31fe7287":"markdown","c9b8954c":"markdown","ebead991":"markdown","eaa8062a":"markdown","282fe71e":"markdown","ec0a703f":"markdown","ba6f447a":"markdown","688e425c":"markdown","3f38e26f":"markdown"},"source":{"87b27391":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n%matplotlib inline\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","43abf821":"Boston_housing = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nBoston_housing.head()","f5552681":"Boston_housing.info()","a90e8b3d":"Boston_housing[Boston_housing.isnull().any(axis=1)]","e1f58d88":"Boston_housing.head()","2bdc56f3":"Boston_housing.drop('Id', axis=1,inplace=True)\n","eded2bcc":"Boston_housing.head()","e4e63b9f":"round(Boston_housing.isnull().sum()*100\/Boston_housing.shape[0],2).sort_values(ascending=False).head(20)","f890013c":"Boston_housing.dropna(axis=1, thresh = int(0.70*Boston_housing.shape[0]), inplace=True)","54d51b81":"Boston_housing.head(100)","8e01ad20":"round(Boston_housing.isnull().sum()*100\/Boston_housing.shape[0],2).sort_values(ascending=False).head(20)","ce835d64":"Boston_housing['LotFrontage'].fillna('NaN', inplace=True)\nBoston_housing['GarageType'].fillna('No Garage', inplace=True)\nBoston_housing['GarageYrBlt'].fillna('No Garage', inplace=True)\nBoston_housing['GarageFinish'].fillna('No Garage', inplace=True)\nBoston_housing['GarageQual'].fillna('No Garage', inplace=True)\nBoston_housing['GarageCond'].fillna('No Garage', inplace=True)\nBoston_housing['BsmtFinType2'].fillna('No Basement', inplace=True)\nBoston_housing['BsmtExposure'].fillna('No Basement', inplace=True)\nBoston_housing['BsmtQual'].fillna('No Basement', inplace=True)\nBoston_housing['BsmtCond'].fillna('No Basement', inplace=True)\nBoston_housing['BsmtFinType1'].fillna('No Basement', inplace=True)\nBoston_housing['MasVnrArea'].fillna('NaN', inplace=True)\nBoston_housing['MasVnrType'].fillna('NaN', inplace=True)\nBoston_housing['Electrical'].fillna('NaN', inplace=True)","a7854c7a":"corr = Boston_housing.corr()\ncorr.shape","8abbfe52":"plt.figure(figsize=(20,20))\nsns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')","a6f9bd5d":"categorical = Boston_housing.select_dtypes(include = \"object\").columns\nBoston_housing[categorical].head(20)","10ff167a":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\n\nfor i in categorical:\n    Boston_housing[i] = encoder.fit_transform(Boston_housing[i].astype(str))\n\nprint (Boston_housing.info())","b1422212":"Boston_housing = Boston_housing.astype(np.float64)\nBoston_housing.info()","32fda62f":"X = Boston_housing.drop(['SalePrice'], axis=1)\nY = Boston_housing['SalePrice']","33b377e8":"from sklearn.preprocessing import scale\ncols = X.columns\nX = pd.DataFrame(scale(X))\nX.columns = cols\nX.columns","9d9249a7":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n","ba95105b":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","0436c691":"linerRegression = LinearRegression()\nlinerRegression.fit(X_train, y_train)\nlinerRegression.score(X_test, y_test )","93b6f4b5":"y_pred_linear = linerRegression.predict(X_train)","445a38a9":"R2_score_linear = metrics.r2_score(y_train, y_pred_linear)\nprint(R2_score_linear)","fa0817a1":"plt.scatter(y_train, y_pred_linear)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","21d8ad80":"sgdregression = linear_model.SGDRegressor()\nsgdregression.fit(X_train, y_train,)\nsgdregression.score(X_test, y_test )","5f53b18c":"y_pred_sgd = sgdregression.predict(X_train)","0198304e":"R2_score_sdg = metrics.r2_score(y_train, y_pred_sgd)\nprint(R2_score_sdg)","0678d4f8":"plt.scatter(y_train, y_pred_sgd)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","30e2ab1f":"ridge_regression = Ridge(alpha=0.01)\nridge_regression.fit(X_train, y_train) \nridge_regression.score(X_test, y_test)","0db17f09":"pred_train_ridge_regression= ridge_regression.predict(X_train)\n","ab8039ab":"R2_score_ridge = metrics.r2_score(y_train, pred_train_ridge_regression)\nprint(R2_score_ridge)","6a272844":"plt.scatter(y_train, pred_train_ridge_regression)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()\n","968a902f":"lasso = Lasso(alpha=0.01)\nlasso.fit(X_train, y_train) \nlasso.score(X_train, y_train) \n","81370b2e":"pred_train_lasso= lasso.predict(X_train)","a926acc7":"R2_score_lasso = metrics.r2_score(y_train, pred_train_lasso)\nprint(R2_score_lasso)","6bbd3212":"pred_train_lasso= lasso.predict(X_train)\nplt.scatter(y_train, pred_train_lasso)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","5dcdce7d":"elasticNet = ElasticNet(alpha = 0.01)\nelasticNet.fit(X_train, y_train) \nelasticNet.score(X_train, y_train)","1c892543":"pred_train_enet= elasticNet.predict(X_train)","d89bd4b1":"R2_score_enet = metrics.r2_score(y_train, pred_train_enet)\nprint(R2_score_enet)","1ec2c025":"plt.scatter(y_train, pred_train_enet)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","f82f3e0c":"from sklearn.svm import SVC\nsvm_regression = SVC(C= .1, kernel='linear', gamma= 1)\nsvm_regression.fit(X_train, y_train)\nsvm_regression.score(X_train, y_train)\n","91a1dd1f":"y_pred_svm_regression = svm_regression.predict(X_train)","7acd315a":"R2_score_svm = metrics.r2_score(y_train, y_pred_svm_regression)\nprint(R2_score_svm)","5ebba9a2":"plt.scatter(y_train, y_pred_svm_regression)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","28525190":"m = {'Model': ['Linear Regression', 'SGDRegressor', 'Ridge','Lasso','Elastic','Support Vector Machines'],\n    'R-squared Score': [R2_score_linear*100,R2_score_sdg*100,R2_score_ridge*100,R2_score_lasso*100, R2_score_enet*100, R2_score_svm*100]}\nmodels = pd.DataFrame.from_dict(m, orient='index')\nmodels = models.transpose()\n\nmodels.sort_values(by='R-squared Score', ascending=False)","65101b47":"setting a thresh value to drop the columns with a lot of null values.","48fade43":"from what i understood and read online the data should be all numerical for the model but most of the data here is categorical data so we have to transform it and according to the ... we can use multiple ways to solve this ","31fe7287":"* Lasso ","c9b8954c":"Spilitg the dependet and independent variables","ebead991":"* SGDRegression","eaa8062a":"* Elastic","282fe71e":"* SVM","ec0a703f":"* Linear Regression","ba6f447a":"filling the categorical data by hand","688e425c":"* Ridge Regression","3f38e26f":"from my understanding that we should drop the null columns only if they have a large percentage that will comprise the data otherwise we could just imput them so:\n\n1. checking the percentage\n2. Theoretically, 25 to 30% is the maximum missing values are allowed. so I am droping the columns with percentages higher than that."}}