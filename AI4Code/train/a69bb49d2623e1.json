{"cell_type":{"19226de8":"code","e0320f58":"code","c61cf461":"code","4074931f":"code","b0fcc86f":"code","4452a2cc":"code","c09b6d50":"code","56a576b0":"code","cc9106e7":"code","d50fb93a":"code","6850919e":"code","2ed44492":"code","89340f24":"code","8b98e9fc":"code","3519fa95":"code","9f58e5da":"code","b45b829f":"code","b7df684f":"code","45199070":"code","cbf02cd1":"code","8fc8f42b":"code","1d6e4f42":"code","f79ccc01":"code","58423b88":"code","66ecf7b8":"code","cfc96f2c":"code","dfc3e647":"code","847499ce":"code","f207151d":"code","c6e3f91f":"code","c3430031":"code","fb3b7cc6":"code","6ff63310":"markdown","7a899f7b":"markdown","ccddc711":"markdown","d95a239e":"markdown","71583c48":"markdown","33a0ab56":"markdown","a5b9e6a8":"markdown","46135716":"markdown","982fd8ea":"markdown","eac27678":"markdown","6bd49e9e":"markdown","498720ee":"markdown","598667c6":"markdown","9bdf557a":"markdown","f3c89ec0":"markdown","2e94f996":"markdown","69568c4c":"markdown","edffdf56":"markdown","b4b641b6":"markdown","0a3bc875":"markdown","2e607820":"markdown","d5f55c52":"markdown","eeea6ec1":"markdown","f5f9cfa9":"markdown","603795d0":"markdown","ee26098d":"markdown","37353777":"markdown","dc2807ad":"markdown","a20c3f0d":"markdown","7e1a8907":"markdown"},"source":{"19226de8":"!pip install quadprog","e0320f58":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport subprocess\nimport pickle\nimport torch\nimport os\nfrom torchvision import transforms\nfrom PIL import Image\nimport argparse\nimport os.path\nimport random\nimport torch\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c61cf461":"# mnist_path = \"mnist.npz\"\n\n# if not os.path.exists(mnist_path):\n#     subprocess.call(\"wget https:\/\/s3.amazonaws.com\/img-datasets\/mnist.npz\", shell=True)\n    \nf = np.load('..\/input\/mnist-numpy\/mnist.npz')\nx_tr = torch.from_numpy(f['x_train'])\ny_tr = torch.from_numpy(f['y_train']).long()\nx_te = torch.from_numpy(f['x_test'])\ny_te = torch.from_numpy(f['y_test']).long()\nf.close()\ntorch.save((x_tr, y_tr), 'mnist_train.pt')\ntorch.save((x_te, y_te), 'mnist_test.pt')\nx_tr.size()[0]\nprint('Xtrain size: [%d , %d , %d ]' % (x_tr.size()[0], x_tr.size()[1],x_tr.size()[2]))\nprint('Xtest size: [%d , %d , %d ]' % (x_te.size()[0], x_te.size()[1],x_te.size()[2]))\nprint('Ytrain size: [%d ]' % (y_tr.size()[0]))\nprint('Ytest size: [%d ]' % (y_te.size()[0]))\n","4074931f":"def rotate_dataset(d, rotation):\n    result = torch.FloatTensor(d.size(0), 784)\n    tensor = transforms.ToTensor()\n\n    for i in range(d.size(0)):\n        img = Image.fromarray(d[i].numpy(), mode='L')\n        result[i] = tensor(img.rotate(rotation)).view(784)\n    return result","b0fcc86f":"a_i = '..\/ouput\/kaggle\/working\/'\na_ntasks = 10\na_min_rot = 0\na_max_rot = 90\na_seed = 0\n\ntorch.manual_seed(a_seed)\n\ntasks_tr = []\ntasks_te = []\n\nfor t in range(a_ntasks):\n    min_rot = 1.0 * t \/ a_ntasks * (a_max_rot - a_min_rot) + \\\n        a_min_rot\n    max_rot = 1.0 * (t + 1) \/ a_ntasks * \\\n        (a_max_rot - a_min_rot) + a_min_rot\n    rot = random.random() * (max_rot - min_rot) + min_rot\n\n    tasks_tr.append([rot, rotate_dataset(x_tr, rot), y_tr])\n    tasks_te.append([rot, rotate_dataset(x_te, rot), y_te])\n","4452a2cc":"import numpy as np\nimport matplotlib.pyplot as plt\n\nw=28\nh=28\nfig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 3\nfig.add_subplot(rows, columns, 1)\nplt.imshow(x_tr[0])\nfor i in range(10):\n    x=tasks_tr[i][1][0]\n    img = x.reshape((h, w))\n    fig.add_subplot(rows, columns, i+2)\n    plt.imshow(img, cmap=plt.cm.gray)\n\nprint('Rotation angles are:')\nfor i in range(10):\n    print(tasks_tr[i][0])","c09b6d50":"import math\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import relu, avg_pool2d","56a576b0":"\ndef Xavier(m):\n    if m.__class__.__name__ == 'Linear':\n        fan_in, fan_out = m.weight.data.size(1), m.weight.data.size(0)\n        std = 1.0 * math.sqrt(2.0 \/ (fan_in + fan_out))\n        a = math.sqrt(3.0) * std\n        m.weight.data.uniform_(-a, a)\n        m.bias.data.fill_(0.0)","cc9106e7":"class MLP(nn.Module):\n    def __init__(self, sizes):\n        super(MLP, self).__init__()\n        layers = []\n\n        for i in range(0, len(sizes) - 1):\n            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n            if i < (len(sizes) - 2):\n                layers.append(nn.ReLU())\n\n        self.net = nn.Sequential(*layers)\n        self.net.apply(Xavier)\n\n    def forward(self, x):\n        return self.net(x)","d50fb93a":"\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)","6850919e":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n                          stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = relu(out)\n        return out","2ed44492":"\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes, nf):\n        super(ResNet, self).__init__()\n        self.in_planes = nf\n\n        self.conv1 = conv3x3(3, nf * 1)\n        self.bn1 = nn.BatchNorm2d(nf * 1)\n        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        bsz = x.size(0)\n        out = relu(self.bn1(self.conv1(x.view(bsz, 3, 32, 32))))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18(nclasses, nf=20):\n    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)","89340f24":"from __future__ import print_function\n\nimport torch","8b98e9fc":"def task_changes(result_t):\n    n_tasks = int(result_t.max() + 1)\n    changes = []\n    current = result_t[0]\n    for i, t in enumerate(result_t):\n        if t != current:\n            changes.append(i)\n            current = t\n\n    return n_tasks, changes\n\n\ndef confusion_matrix(result_t, result_a, fname=None):\n    nt, changes = task_changes(result_t)\n\n    baseline = result_a[0]\n    changes = torch.LongTensor(changes + [result_a.size(0)]) - 1\n    result = result_a[changes]\n\n    # acc[t] equals result[t,t]\n    acc = result.diag()\n    fin = result[nt - 1]\n    # bwt[t] equals result[T,t] - acc[t]\n    bwt = result[nt - 1] - acc\n\n    # fwt[t] equals result[t-1,t] - baseline[t]\n    fwt = torch.zeros(nt)\n    for t in range(1, nt):\n        fwt[t] = result[t - 1, t] - baseline[t]\n\n    if fname is not None:\n        f = open(fname, 'w')\n\n        print(' '.join(['%.4f' % r for r in baseline]), file=f)\n        print('|', file=f)\n        for row in range(result.size(0)):\n            print(' '.join(['%.4f' % r for r in result[row]]), file=f)\n        print('', file=f)\n        # print('Diagonal Accuracy: %.4f' % acc.mean(), file=f)\n        print('Final Accuracy: %.4f' % fin.mean(), file=f)\n        print('Backward: %.4f' % bwt.mean(), file=f)\n        print('Forward:  %.4f' % fwt.mean(), file=f)\n        f.close()\n\n    stats = []\n    # stats.append(acc.mean())\n    stats.append(fin.mean())\n    stats.append(bwt.mean())\n    stats.append(fwt.mean())\n\n    return stats","3519fa95":"import torch.nn as nn\nimport torch.optim as optim\nimport quadprog\n# from sklearn.neural_network import MLPClassifier\n# from common import ResNet18","9f58e5da":"def compute_offsets(task, nc_per_task, is_cifar):\n    \"\"\"\n        Compute offsets for cifar to determine which\n        outputs to select for a given task.\n    \"\"\"\n    if is_cifar:\n        offset1 = task * nc_per_task\n        offset2 = (task + 1) * nc_per_task\n    else:\n        offset1 = 0\n        offset2 = nc_per_task\n    return offset1, offset2","b45b829f":"def store_grad(pp, grads, grad_dims, tid):\n    \"\"\"\n        This stores parameter gradients of past tasks.\n        pp: parameters\n        grads: gradients\n        grad_dims: list with number of parameters per layers\n        tid: task id\n    \"\"\"\n    # store the gradients\n    grads[:, tid].fill_(0.0)\n    cnt = 0\n    for param in pp():\n        if param.grad is not None:\n            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n            en = sum(grad_dims[:cnt + 1])\n            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n        cnt += 1","b7df684f":"def overwrite_grad(pp, newgrad, grad_dims):\n    \"\"\"\n        This is used to overwrite the gradients with a new gradient\n        vector, whenever violations occur.\n        pp: parameters\n        newgrad: corrected gradient\n        grad_dims: list storing number of parameters at each layer\n    \"\"\"\n    cnt = 0\n    for param in pp():\n        if param.grad is not None:\n            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n            en = sum(grad_dims[:cnt + 1])\n            this_grad = newgrad[beg: en].contiguous().view(\n                param.grad.data.size())\n            param.grad.data.copy_(this_grad)\n        cnt += 1","45199070":"def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n    \"\"\"\n        Solves the GEM dual QP described in the paper given a proposed\n        gradient \"gradient\", and a memory of task gradients \"memories\".\n        Overwrites \"gradient\" with the final projected update.\n        input:  gradient, p-vector\n        input:  memories, (t * p)-vector\n        output: x, p-vector\n    \"\"\"\n    memories_np = memories.cpu().t().double().numpy()\n    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n    t = memories_np.shape[0]\n    P = np.dot(memories_np, memories_np.transpose())\n    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n    q = np.dot(memories_np, gradient_np) * -1\n    G = np.eye(t)\n    h = np.zeros(t) + margin\n    v = quadprog.solve_qp(P, q, G, h)[0]\n    x = np.dot(v, memories_np) + gradient_np\n    gradient.copy_(torch.Tensor(x).view(-1, 1))","cbf02cd1":"\nclass Net(nn.Module):\n    def __init__(self,\n                 n_inputs,\n                 n_outputs,\n                 n_tasks,\n                 args):\n        super(Net, self).__init__()\n        nl, nh = args['n_layers'], args['n_hiddens']\n        self.margin = args['memory_strength']\n        self.is_cifar = (args['data_file'] == 'cifar100.pt')\n        if self.is_cifar:\n            self.net = ResNet18(n_outputs)\n        else:\n            self.net = MLP([n_inputs] + [nh] * nl + [n_outputs])\n\n        self.ce = nn.CrossEntropyLoss()\n        self.n_outputs = n_outputs\n\n        self.opt = optim.SGD(self.parameters(), args['lr'])\n\n        self.n_memories = args['n_memories']\n        self.gpu = args['cuda']\n\n        # allocate episodic memory\n        self.memory_data = torch.FloatTensor(\n            n_tasks, self.n_memories, n_inputs)\n        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n        if args['cuda']:\n            self.memory_data = self.memory_data.cuda()\n            self.memory_labs = self.memory_labs.cuda()\n\n        # allocate temporary synaptic memory\n        self.grad_dims = []\n        for param in self.parameters():\n            self.grad_dims.append(param.data.numel())\n        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n        if args['cuda']:\n            self.grads = self.grads.cuda()\n\n        # allocate counters\n        self.observed_tasks = []\n        self.old_task = -1\n        self.mem_cnt = 0\n        if self.is_cifar:\n            self.nc_per_task = int(n_outputs \/ n_tasks)\n        else:\n            self.nc_per_task = n_outputs\n\n    def forward(self, x, t):\n        output = self.net(x)\n        if self.is_cifar:\n            # make sure we predict classes within the current task\n            offset1 = int(t * self.nc_per_task)\n            offset2 = int((t + 1) * self.nc_per_task)\n            if offset1 > 0:\n                output[:, :offset1].data.fill_(-10e10)\n            if offset2 < self.n_outputs:\n                output[:, offset2:self.n_outputs].data.fill_(-10e10)\n        return output\n\n    def observe(self, x, t, y):\n        # update memory\n        if t != self.old_task:\n            self.observed_tasks.append(t)\n            self.old_task = t\n\n        # Update ring buffer storing examples from current task\n        bsz = y.data.size(0)\n        endcnt = min(self.mem_cnt + bsz, self.n_memories)\n        effbsz = endcnt - self.mem_cnt\n        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n            x.data[: effbsz])\n        if bsz == 1:\n            self.memory_labs[t, self.mem_cnt] = y.data[0]\n        else:\n            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n                y.data[: effbsz])\n        self.mem_cnt += effbsz\n        if self.mem_cnt == self.n_memories:\n            self.mem_cnt = 0\n\n        # compute gradient on previous tasks\n        if len(self.observed_tasks) > 1:\n            for tt in range(len(self.observed_tasks) - 1):\n                self.zero_grad()\n                # fwd\/bwd on the examples in the memory\n                past_task = self.observed_tasks[tt]\n\n                offset1, offset2 = compute_offsets(past_task, self.nc_per_task,\n                                                   self.is_cifar)\n                ptloss = self.ce(\n                    self.forward(\n                        self.memory_data[past_task],\n                        past_task)[:, offset1: offset2],\n                    self.memory_labs[past_task] - offset1)\n                ptloss.backward()\n                store_grad(self.parameters, self.grads, self.grad_dims,\n                           past_task)\n\n        # now compute the grad on the current minibatch\n        self.zero_grad()\n\n        offset1, offset2 = compute_offsets(t, self.nc_per_task, self.is_cifar)\n        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n        loss.backward()\n\n        # check if gradient violates constraints\n        if len(self.observed_tasks) > 1:\n            # copy gradient\n            store_grad(self.parameters, self.grads, self.grad_dims, t)\n            indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n                else torch.LongTensor(self.observed_tasks[:-1])\n            dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n                            self.grads.index_select(1, indx))\n            if (dotp < 0).sum() != 0:\n                project2cone2(self.grads[:, t].unsqueeze(1),\n                              self.grads.index_select(1, indx), self.margin)\n                # copy gradients back\n                overwrite_grad(self.parameters, self.grads[:, t],\n                               self.grad_dims)\n        self.opt.step()","8fc8f42b":"import importlib\nimport datetime\nimport argparse\nimport random\nimport uuid\nimport time\nimport os\n\n# from metrics.metrics import confusion_matrix","1d6e4f42":"def load_datasets():\n    d_tr, d_te = tasks_tr, tasks_te\n    n_inputs = d_tr[0][1].size(1)\n    n_outputs = 0\n    for i in range(len(d_tr)):\n        n_outputs = max(n_outputs, d_tr[i][2].max().item())\n        n_outputs = max(n_outputs, d_te[i][2].max().item())\n    return d_tr, d_te, n_inputs, n_outputs + 1, len(d_tr)","f79ccc01":"class Continuum:\n\n    def __init__(self, data, args):\n        self.data = data\n        self.batch_size = args['batch_size']\n        n_tasks = len(data)\n        task_permutation = range(n_tasks)\n\n        if args['shuffle_tasks'] == 'yes':\n            task_permutation = torch.randperm(n_tasks).tolist()\n\n        sample_permutations = []\n\n        for t in range(n_tasks):\n            N = data[t][1].size(0)\n            if args['samples_per_task'] <= 0:\n                n = N\n            else:\n                n = min(args['samples_per_task'], N)\n\n            p = torch.randperm(N)[0:n]\n            sample_permutations.append(p)\n\n        self.permutation = []\n\n        for t in range(n_tasks):\n            task_t = task_permutation[t]\n            for _ in range(args['n_epochs']):\n                task_p = [[task_t, i] for i in sample_permutations[task_t]]\n                random.shuffle(task_p)\n                self.permutation += task_p\n\n        self.length = len(self.permutation)\n        self.current = 0\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        return self.__next__()\n\n    def __next__(self):\n        if self.current >= self.length:\n            raise StopIteration\n        else:\n            ti = self.permutation[self.current][0]\n            j = []\n            i = 0\n            while (((self.current + i) < self.length) and\n                   (self.permutation[self.current + i][0] == ti) and\n                   (i < self.batch_size)):\n                j.append(self.permutation[self.current + i][1])\n                i += 1\n            self.current += i\n            j = torch.LongTensor(j)\n            return self.data[ti][1][j], ti, self.data[ti][2][j]\n","58423b88":"def eval_tasks(model, tasks, args):\n    model.eval()\n    result = []\n    for i, task in enumerate(tasks):\n        t = i\n        x = task[1]\n        y = task[2]\n        rt = 0\n        \n        eval_bs = x.size(0)\n\n        for b_from in range(0, x.size(0), eval_bs):\n            b_to = min(b_from + eval_bs, x.size(0) - 1)\n            if b_from == b_to:\n                xb = x[b_from].view(1, -1)\n                yb = torch.LongTensor([y[b_to]]).view(1, -1)\n            else:\n                xb = x[b_from:b_to]\n                yb = y[b_from:b_to]\n            if args['cuda']:\n                xb = xb.cuda()\n            _, pb = torch.max(model(xb, t).data.cpu(), 1, keepdim=False)\n            rt += (pb == yb).float().sum()\n\n        result.append(rt \/ x.size(0))\n\n    return result","66ecf7b8":"def life_experience(model, continuum, x_te, args):\n    result_a = []\n    result_t = []\n\n    current_task = 0\n    time_start = time.time()\n\n    for (i, (x, t, y)) in enumerate(continuum):\n        if(((i % args['log_every']) == 0) or (t != current_task)):\n            result_a.append(eval_tasks(model, x_te, args))\n            result_t.append(current_task)\n            current_task = t\n\n        v_x = x.view(x.size(0), -1)\n        v_y = y.long()\n\n        if args['cuda']:\n            v_x = v_x.cuda()\n            v_y = v_y.cuda()\n\n        model.train()\n        model.observe(v_x, t, v_y)\n\n    result_a.append(eval_tasks(model, x_te, args))\n    result_t.append(current_task)\n\n    time_end = time.time()\n    time_spent = time_end - time_start\n\n    return torch.Tensor(result_t), torch.Tensor(result_a), time_spent\n\n","cfc96f2c":"args = {\n    'model' : 'gem',\n    'lr' : 0.1,\n    'n_memories' : 256,\n    'memory_strength' : 0.5,\n    'seed' : 0,\n    'cuda' : 'no',\n    'finetune' : 'no',\n    'batch_size' : 10,\n    'shuffle_tasks' : 'no',\n    'samples_per_task' : -1,\n    'n_epochs' : 1,\n    'n_layers' : 2,\n    'n_hiddens' : 100,\n    'data_file' : 'mnist_rotations.pt',\n    'log_every' : 100\n}","dfc3e647":"args['cuda'] = True if args['cuda'] == 'yes' else False\nargs['finetune'] = True if args['finetune'] == 'yes' else False\n    \nuid = uuid.uuid4().hex\n\ntorch.backends.cudnn.enabled = False\ntorch.manual_seed(args['seed'])\nnp.random.seed(args['seed'])\nrandom.seed(args['seed'])\nif args['cuda']:\n        torch.cuda.manual_seed_all(args['seed'])\n\nx_train, x_test, n_inputs, n_outputs, n_tasks = load_datasets()\n\ncontinuum = Continuum(x_train, args)\n# print('done')","847499ce":"#load model\n# Model = importlib.import_module('model.' + args.model)\nmodel = Net(n_inputs, n_outputs, n_tasks, args)\nif args['cuda']:\n    model.cuda()\n    \nprint('done')","f207151d":"# run model on continuum\nresult_t, result_a, spent_time = life_experience(\n    model, continuum, x_train, args)\nprint('done')","c6e3f91f":"# save confusion matrix and print one line of stats\nstats = confusion_matrix(result_t, result_a, 'confusion.txt')\nprint('Final Accuracy = %f' % stats[0].numpy())\nprint('Backward Trasnfer = %f' % stats[1].numpy())\nprint('Forward Trasnfer = %f' % stats[2].numpy())","c3430031":"# save all results in binary file\ntorch.save((result_t, result_a, model.state_dict(),stats, args), 'gem_mnist_rotations.pt')\nfor dirname, _, filenames in os.walk('\/kaggle\/output\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fb3b7cc6":"import matplotlib as mpl\nmpl.use('Agg')\nmpl.rcParams[\"font.family\"] = \"Times New Roman\"\nmpl.rcParams[\"font.family\"] = \"DejaVu Serif\"\n\nfrom matplotlib import pyplot as plt\nfrom glob import glob\nimport numpy as np\nimport torch\n\nmodels = ['gem']\ndatasets = ['mnist_rotations']\n\nnames_datasets = {'mnist_rotations': 'MNIST rotations'}\n\nnames_models = {'gem': 'GEM'}\n\ncolors = {'gem': 'C4'}\n\nbarplot = {}\n\nfor dataset in datasets:\n    barplot[dataset] = {}\n    for model in models:\n        barplot[dataset][model] = {}\n        matches = glob(model + '*' + dataset + '*.pt')\n        if len(matches):\n            data = torch.load(matches[0], map_location=lambda storage, loc: storage)\n            acc, bwt, fwt = data[3][:]\n            barplot[dataset][model]['acc'] = acc\n            barplot[dataset][model]['bwt'] = bwt\n            barplot[dataset][model]['fwt'] = fwt\n\nfor dataset in datasets:\n    x_lab = []\n    y_acc = []\n    y_bwt = []\n    y_fwt = []\n\n    for i, model in enumerate(models):\n        if barplot[dataset][model] != {}:\n            x_lab.append(model)\n            y_acc.append(barplot[dataset][model]['acc'])\n            y_bwt.append(barplot[dataset][model]['bwt'])\n            y_fwt.append(barplot[dataset][model]['fwt'])\n\n    x_ind = np.arange(len(y_acc))\n\n    plt.figure(figsize=(7, 3))\n    all_colors = []\n    for xi, yi, li in zip(x_ind, y_acc, x_lab):\n        plt.bar(xi, yi, label=names_models[li], color=colors[li])\n        all_colors.append(colors[li])\n    plt.bar(x_ind + (len(y_acc) + 1) * 1, y_bwt, color=all_colors)\n    plt.bar(x_ind + (len(y_acc) + 1) * 2, y_fwt, color=all_colors)\n    plt.xticks([0.01, 2, 4], ['ACC', 'BWT', 'FWT'], fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlim(-1, len(y_acc) * 3 + 2)\n    plt.ylabel('classification accuracy', fontsize=16)\n    plt.title(names_datasets[dataset], fontsize=16)\n    plt.legend(fontsize=12)\n    plt.tight_layout()\n    plt.savefig('barplot_%s.pdf' % dataset, bbox_inches='tight')\n    plt.show()\n\nevoplot = {}\n\nfor dataset in datasets:\n    evoplot[dataset] = {}\n    for model in models:\n        matches = glob(model + '*' + dataset + '*.pt')\n        if len(matches):\n            data = torch.load(matches[0], map_location=lambda storage, loc: storage)\n            evoplot[dataset][model] = data[1][:, 0].numpy()\n\nfor dataset in datasets:\n\n    plt.figure(figsize=(7, 3))\n    for model in models:\n        if model in evoplot[dataset]:\n            x = np.arange(len(evoplot[dataset][model]))\n            x = (x - x.min()) \/ (x.max() - x.min()) * 10\n            plt.plot(x, evoplot[dataset][model], color=colors[model], lw=3)\n            plt.xticks(range(0, 11, 2))\n\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel('task number', fontsize=16)\n    plt.title(names_datasets[dataset], fontsize=16)\n    plt.tight_layout()\n    plt.savefig('evoplot_%s.pdf' % dataset, bbox_inches='tight')\n    plt.show()","6ff63310":"### Define continuum of data:","7a899f7b":"For a fine grained evaluation, we can build a matrix R where R<sub>i,j<\/sub> is the test classification accuracy on task j after observing the i<sup>th<\/sup> sample in the continuum. Our dataset is huge and we have limited computational resources, so we go ahead with the earlier definition of R.\n\n- Memory - We allocate a limited memory for each task and we store some samples from respective tasks in those memory slots. \n\n- Episodic - We will use these memory slots to calculate accuracy to make sure we are not significantly reducing the accuracy of previous tasks by learning new tasks\n\nThe GEM algorithm is capable of minimizing the negative backward transfer and increasing the forward transfer. To increase the forward transfer, we can utilize the task descriptor which may say rules about how to solve a particular task and use that knowledge also to solve next tasks if they are similar. But in our project, the task descriptors are integers and hence we cannot expect a significant positive forward transfer. Therefore, we focus on minimizing the negative backward transfer (Catastrophic forgetting). \n\nThe memory unit for each task t<sub>i<\/sub> consists of the last m samples seen in that particular task t<sub>i<\/sub> where $\\ m = \\frac{M}{T}$ <br \\>\nM is total allowed memory and T is the number of tasks.\n\n$\\ l(f_{\\theta}, M_{k})$ = $\\frac{1}{T - 1}$$\\sum_{(x_{i},k, y_{i}) \\in M_{k}} l(f_{\\theta}(x_{i}, k), y_{i})$\n\nWe cannot just minimize this loss function because it will result in overfitting to the examples in M<sub>k<\/sub>. So our goal is to minimize the loss function and make sure loss function after the end of each task t has NOT increased compared to loss function at the end of task t - 1 <br \/>\n\n$\\ <g, g_{k}>$ := $\\ <\\frac{\\partial l(f_{\\theta}(x, t), y)}{\\partial \\theta}, \\frac{\\partial l(f_{\\theta}, M_{k})}{\\partial \\theta}>$   $\\ge 0 $ for all k < t <br \/>\n\nIn order for a gradient update to take place, they compute the dot product of the current learning task with all the previous tasks in memory. The update is allowed to take place if the gradient is greater than or equal to 0 for all the episodes. This translates into constraining your update for one task to not conflict with an update for the previous task.\n\nIf the gradient is going the wrong way, we take this gradient update and project it to the closest possible vector that doesn\u2019t go the wrong way","ccddc711":"## Metrics : <br \/>\nWe calculate Average Accuracy on the test data, Backward transfer, Forward transfer. <br \/>\n- Notation : <br \/>\nR \u2208 R<sup>T \u00d7 T<\/sup> where R<sub>i,j<\/sub> is the test classification accuracy on task j after observing the last sample of task i.\n- Average Accuracy : $\\frac{1}{T}$$\\sum_{i=1}^{T} R_{T,i}$","d95a239e":"## Algorithm Explained:\n### TRAIN function:\n- Initialize memory for each task t.\n- Initialize R matrix which is test accuracy after learning tasks.\n- for each task t = 1,....T, and for each continuum data (x, y) in that task t, keep the last m = M \/ T samples\n- g is the gradient of the loss function based on the current sample\n- $\\ g_k$ is the gradient of the loss function on the memory unit $\\ M_k$. g is a list of the gradients.\n- g~ (I used g` notation in previous explanation) \nis the projection of the gradient on current sample g with the gradient vector on all memory units (as explained earlier)\n- $\\ \\theta$ is updated as per Stochastic Descent Algorithm using a hyperparameter $\\ \\alpha$ and gradient g~\n- Update the matrix R using Evaluate function on test data.\n\n### Evaluate function:\n- Initialize r vector to zero\n- for each task t, and for each continuum data (x, y) in that task, add accuracy on current test data sample.\n- After all the samples in current task are added, divide by the size of the samples in that task.\n\n- Return the predictor function $\\ f_{\\theta}$, matrix R\n- Calculate BWT, FWT using the above formulae and plot graphs.\n","71583c48":"### Defining GEM Algorithm:","33a0ab56":"## Why do we need to Upgrade our methodologies?\n- Since the sequence of samples may consist of examples from different tasks, the assumption of \u201cIndependent and Identically distributed\u201d of the ERM doesn\u2019t work. Even if we try to implement ERM over samples from various tasks, we see what is called \u201cCatastrophic Forgetting\u201d i.e. the learning function forgets how to solve past tasks when it is exposed to new tasks. To bridge the gap between the current ERM and human thinking, Facebook Artificial Intelligence Research group has come up with an algorithm called Gradient Episodic Memory. ","a5b9e6a8":"### Plotting a sample from the training dataset. The origial digit with its 10 rotations:","46135716":"### Evaluating the performance of the model:","982fd8ea":"### Extracting mnist dataset (train and test):","eac27678":"**CS-GY 6613, Artificial Intelligence, Spring 2020**<br\/>\n**New York University Tandon School of Engineering**<br\/>\n**Course Project - 1**<br\/>\n**Name - Durga Prasad Reddy Kasireddy**<br\/> \n**Net ID - dpk290**<br\/>\n**Name - Haneen Alsuradi**<br\/> \n**Net ID - hha243**<br\/>\n**Name - Teena Kunsoth**<br\/> \n**Net ID - tk2598**<br\/>","6bd49e9e":"## Continual AI: <br \/>\nIn conventional deep learning, we train a network to do a task (for example object recognition) with a predefined set of classes. Also, once the network is trained, weights are fixed. In continual learning, the idea is to keep updating the weights and learn from new instances faced by the network. This might again lead to Catastrophic Forgetting which means new instances are causing old knowledge to be wiped. In other words, new instances are causing the weights of the network to be modified and thus affecting the performance of the previously trained task. Thus there are 3 suggested methods that can be used to overcome the (catastrophic forgetting): <br \/>\n\n1. **Regularization:** Meaning there is a penalty on changing the weights of the Neural Network. The penalty increases proportionally with the (weight change) of the Neural Network. This helps in retaining the old knowledge. \n\n2. **Dynamic Architecture:** During learning a new task, new resources are allocated to learn new information (meaning, new neurons are created without changing the old weights of the network). This helps in learning new tasks without interfering with the previously gained knowledge.\n\n3. **Complimentary Learning System (CLS):** A mixture of the two methods above. New resources are created (neurons\/layers) and \"some\" old weights are changed\n\nGradient Episodic Memory comes under CLS and we will use it in this project.","498720ee":"### Create the models that will be used for training:","598667c6":"# Algorithm\n![Screen%20Shot%202020-04-05%20at%206.21.26%20PM.png](attachment:Screen%20Shot%202020-04-05%20at%206.21.26%20PM.png)","9bdf557a":"### Plotting Results:","f3c89ec0":"We use MNIST handwritten digit dataset. It consists of 60,000 images for training and 10,000 images for testing. Each image is 28*28 pixels. We rotate these digits by a certain angle and then try to predict the number. In this project we use 10 tasks (10 different rotation angles from 0 to 90 degrees). Which means each of the 10 tasks has 60,000 images for training and 10,000 images for testing. ","2e94f996":"### Saving results:","69568c4c":"Firstly as long as we guarantee that the loss never increases, there is no need to store the predictor function at the end of each task. Secondly, (here is where the Memory we stored helps us!) we can diagnose the increases in loss of previous tasks by computing the angle between their loss gradient vector and proposed update. \n\nIf these two constraints are satisfied, then the proposed update of the parameter g won\u2019t increase loss in previous tasks. \n\nElse, there is at least one previous task that would experience an increase in loss after the parameter update. If violations occur, project the proposed gradient g to the closest gradient g\u02dc (in squared l<sub>2<\/sub> norm) satisfying all the constraints. Which means we need to <br \/>\n$\\ minimize_{g`} \\frac{1}{2} \\lvert\\lvert g - g`\\rvert\\rvert^{2}_{2}$ <br \/>\nsubject to $\\ <g`, g_{k}> \\ge 0$ for all k < t\n\n\nWe can therefore write Dual of the GEM of a Quadratic Program <br \/>\n$\\ minimize_{v} \\frac{1}{2}v^{T}GG^{T}v$ + $\\ g^{T}G^{T}v$ <br \/>\nsubject to $\\ v \\ge 0$\n\n\nThis is a QP on t - 1 variables. Once we solve 11 for v* we can recover the projected update as <br \/>\n$\\ g` = G^{T}v^{*} + g$\n","edffdf56":"## Forward transfer:\nAs the name suggests, we focus on the average accuracy of each task i before each of the previous tasks are completed. <br \/>\n\nFWT = $\\frac{1}{T - 1}$$\\sum_{i=2}^{T} R_{i-1,i} - b_{i}$ <br \/>\nThere won't be any forward transfer for the last task <br \/>\n\nHow to calculate :-\n1. Record accuracy for each task i = b<sub>i<\/sub> upon initialization (Random initialization)\n2. Learn task 1, record accuracy for task i, repeat this until task i - 1. For all tasks\n3. Subtract their respective b<sub>i<\/sub> from the values and divide  by T - 1 to get average accuracy\n","b4b641b6":"### Load Dataset:","0a3bc875":"### Evaluation of metrics:","2e607820":"### Define the metrics that will be used for evaluation:","d5f55c52":"### Defining the arguments for the complete experiment:","eeea6ec1":"# Introduction:\n## Conventional AI: <br \\>\nWe often employ Empirical Risk Minimization whenever we try to model a supervised learning problem. In this scenario, we have a labelled data (X ,Y) where X is a feature vector and Y is a target vector. We try to model a hypothesis function H : X -> Y which maps the feature vector to the respective target vector label by optimizing a loss function (Least squared error OR Cross Entropy) using some algorithm to minimize the loss (SGD, RMSprop, Adam).\n\n- [](http:\/\/)As research in the field of Artificial Intelligence progresses, we look to build more intelligent and robust systems. We look to replicate the type of thinking a human brain does. For example, a human brain memorizes a few pieces of data in an ordered sequence. The sequence may consist of examples from different tasks (say how to drive a car, how to cook, how to eat etc). Human brain is complex enough to solve examples from these tasks in any order possible and it doesn\u2019t affect the accuracy of previous tasks (Unless you haven\u2019t solved that task in a very long time like a year which is not the case we are talking about). \n","f5f9cfa9":"### Creating traing and testing datasets (tasks, rotated set, labels):","603795d0":"GEM can be viewed as a model that learns the subset of correlations common to a set of distributions (tasks). GEM can also be used to predict target vectors associated to previous or new tasks without making use of task descriptors. <br \/>\n\nThe challenges solved by GEM model are :\n1. **Non-iid input data:** the continuum of data is not iid with respect to any fixed probability distribution P(X, T, Y ) since, once tasks switch, a whole sequence of examples from the new task may be observed. \n2. **Catastrophic forgetting:** learning new tasks may hurt the performance of the learner at previously solved tasks. \n3. **Transfer learning:** when the tasks in the continuum are related, there exists an opportunity for transfer learning. This would translate into faster learning of new tasks, as well as performance improvements in old tasks\n","ee26098d":"## Architecture :\n- Fully connected neural networks with two hidden layers of 100 ReLU units. \n- Mini batch size = 10\n- Algorithm to optimize - Stochastic Gradient Descent ","37353777":"## Dataset : <br \/>\nThe model observes the data in a continuum i.e. example by example which consists of <em>(x, t, y)<sub>i<\/sub><\/em>. Where ti is a task descriptor identifying which task the x<sub><em>i<\/em><\/sub>, y<sub><em>i<\/em><\/sub> belong to. We can still say that for one particular task, the examples belonging to that task are Independent and Identically Distributed also called locally i.i.d. The goal is to predict the target vector y for a test pair (x, t) where (x, y) ~ P<sub><em>t<\/em><\/sub> <br \/>\n\nHuman brain also functions in a similar way. Whenever a task driving comes, we think about the rules of how to drive and then start driving. Here, the task descriptor t<sub><em>i<\/em><\/sub> can be the rules of how to drive and similarly for the task of cooking, the task descriptor can be the recipe. Sometimes, the same input vector x<sub><em>i<\/em><\/sub> can be seen in two different tasks, for example the same ingredients can be used to prepare two different dishes which are two different tasks.\nIn this project, our task descriptors are integers.\n","dc2807ad":"## Code:\n### Importing and Installing needed libraries","a20c3f0d":"### Define function for rotating the dataset images:","7e1a8907":"## Backward transfer:\nAs the name suggests, we focus on the average accuracy of each task i after each of the next tasks are completed.\nBWT = $\\frac{1}{T - 1}$$\\sum_{i=1}^{T - 1} R_{T,i} - R_{i,i}$ <br \/>\nThere won't be any backward transfer for first task <br \/>\nHow to calculate :-\n1. Record accuracy of each task i initially.\n2. Learn task i + 1 and then record accuracy of task i\n3. Since we want to know the transfer, subtract each by R<sub>i, i<\/sub> <br \/>\n"}}