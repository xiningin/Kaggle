{"cell_type":{"96448c1d":"code","b503fc4f":"code","8b52d9ce":"code","82210b6b":"code","08bd3480":"code","ebb117c2":"code","2457e008":"code","c403e47a":"code","2d64122c":"code","cb95d0a0":"code","5f20be0f":"code","18a323e4":"code","bbf500db":"code","195b496c":"code","31cc78af":"code","f705c996":"code","d82b8f7a":"code","c26cacac":"code","faa7001b":"code","bc416cfc":"code","de531362":"markdown","84f912a4":"markdown","18310e61":"markdown","064b5976":"markdown","b445e271":"markdown","60c31280":"markdown","0896e8e3":"markdown","a5030d3c":"markdown","f4089e26":"markdown","2cbacf56":"markdown"},"source":{"96448c1d":"import numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0","b503fc4f":"# RESTRICT TENSORFLOW TO 1GB OF GPU RAM\n# SO THAT WE HAVE 15GB RAM FOR RAPIDS\nLIMIT = 1\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","8b52d9ce":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntrain.head()","82210b6b":"def displayTrainData(train, random=False, COLS=6, ROWS=4, path='..\/input\/shopee-product-matching\/train_images\/'):\n    for k in range(ROWS):\n        plt.figure(figsize=(20,5))\n        for j in range(COLS):\n            if random: row = np.random.randint(0,len(train))\n            else: row = COLS*k + j\n            name = train.iloc[row,1]\n            title = train.iloc[row,3]\n            title_with_return = \"\"\n            for i,ch in enumerate(title):\n                title_with_return += ch\n                if (i!=0)&(i%20==0): title_with_return += '\\n'\n            img = cv2.imread(path+name)\n            plt.subplot(1,COLS,j+1)\n            plt.title(title_with_return)\n            plt.axis('off')\n            plt.imshow(img)\n        plt.show()\n        \ndisplayTrainData(train,random=True)","08bd3480":"groups = train.label_group.value_counts()\n\ndef displayTrainDataBLG(groups, COLS=6, ROWS=4, groups_count=3):\n    for k in range(groups_count):\n        print('label_group: ',groups.index[k])\n        \n        top = train.loc[train.label_group==groups.index[k]]\n        displayTrainData(top, random=False, ROWS=ROWS, COLS=COLS)\n\ndisplayTrainDataBLG(groups)","ebb117c2":"plt.figure(figsize=(20,5))\nplt.bar(groups.index.values[:10].astype('str'),groups.values[:10])\nplt.xticks(rotation = 45)\nplt.ylabel('Number of items',size=14)\nplt.xlabel('Label Group',size=14)\nplt.title('Top 10 groups',size=16)\nplt.show()","2457e008":"USE_TRAIN_DATA = True\n\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n# N\u1ebfu submit th\u00ec kh\u00f4ng d\u00f9ng traindata\nif len(test)>3: USE_TRAIN_DATA = False","c403e47a":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n# EXPECT RESULT\ntrain['target'] = train.label_group.map(tmp)\ntrain.head()","2d64122c":"if USE_TRAIN_DATA:\n    test = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    test_gf = cudf.DataFrame(test)\n    print('D\u00f9ng traindata \u0111\u1ec3 test khi ch\u01b0a submit' )\nelse:\n    #     Real test data\n    test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    test_gf = cudf.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    print('SUBMITTED')\ntest_gf.head()","cb95d0a0":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['use_image_phash'] = test.image_phash.map(tmp)\ntest.head()","5f20be0f":"print('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntext_embeddings = model.fit_transform(test_gf.title).toarray()","18a323e4":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(test)\/\/CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel model, text_embeddings\n_ = gc.collect()","bbf500db":"test['use_title'] = preds\ntest.head()","195b496c":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) \/\/ self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size))\n        return X","31cc78af":"BASE = '..\/input\/shopee-product-matching\/test_images\/'\nif USE_TRAIN_DATA: BASE = '..\/input\/shopee-product-matching\/train_images\/'\n\nWGT = '..\/input\/effnetb0\/efficientnetb0_notop.h5'\nmodel = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n\nembeds = []\nCHUNK = 1024*4\n\nprint('Computing image embeddings...')\nCTS = len(test)\/\/CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor i,j in enumerate( range( CTS ) ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    \n    test_gen = DataGenerator(test.iloc[a:b], batch_size=32, path=BASE)\n    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n    embeds.append(image_embeddings)\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)","f705c996":"KNN = 60\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","d82b8f7a":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)\/\/CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    distances, indices = model.kneighbors(image_embeddings[a:b,])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k,]<6.0)[0]\n        IDS = indices[k,IDX]\n        o = test.iloc[IDS].posting_id.values\n        preds.append(o)\n        \ndel model, distances, indices, image_embeddings, embeds\n_ = gc.collect()","c26cacac":"test['use_image'] = preds\ntest.head()","faa7001b":"def combine_for_sub(row):\n    x = np.concatenate([row.use_image,row.use_title, row.use_image_phash])\n    return ' '.join( np.unique(x) )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","bc416cfc":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","de531362":"# Display Train data group by label_group\nShow first 3 groups","84f912a4":"# Display random traindata","18310e61":"# Number of items in the group (descend)\nShow first 10 groups","064b5976":"# Submission CSV\nCreate submission.csv","b445e271":"# Use image\nUse KNN to find similar images.","60c31280":"# Load test\nSince public test data only has 3 posts, we use training data for testing.","0896e8e3":"# Use title\nExtract Text Embeddings with TfidfVectorizer. Finding similar titles, use cosine similarity instead of KNN.","a5030d3c":"# Load traindata","f4089e26":"# Use image_phash\nPosts always self-match. So use image_phash to add self-post.","2cbacf56":"# Load libraries"}}