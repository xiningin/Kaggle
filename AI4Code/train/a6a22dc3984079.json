{"cell_type":{"64e21ef7":"code","81e7eb2e":"code","dfdf766c":"code","7e6757a0":"code","9d2e43a6":"code","aebabc0e":"code","52ba8670":"code","f657b848":"code","79fb2034":"code","dc1b7560":"markdown","5c9e3c04":"markdown","9bc4a6e1":"markdown","e8452ead":"markdown","097ee764":"markdown","c9268a6f":"markdown","0fab4379":"markdown"},"source":{"64e21ef7":"# import necessary modules\nimport pandas as pd\nimport numpy as np","81e7eb2e":"climate = pd.read_csv('..\/input\/climate-sentiment-in-twitter\/Climate_twitter.csv', index_col= 'id')\nclimate.head()","dfdf766c":"pip install tweepy","7e6757a0":"pip install git+https:\/\/github.com\/JustAnotherArchivist\/snscrape.git","9d2e43a6":"import tweepy","aebabc0e":"def get_credentials(json_file):\n    \"\"\"\n    Reads the json file and start the tweeter API.\n    Requires a json file with 'api_key', 'api_secret', \n    'access_token' and 'access_secret'\n    \n    Argument:\n    ---------\n    json_file (str)\n        path to the json file\n        \n    Returns:\n    The tweeter API\n    \"\"\"\n    with open(jsonfile) as fp:\n        log = json.load(fp)\n        auth = tweepy.OAuthHandler(log['api_key'], log['api_secret'])\n        auth.set_access_token(log['access_token'], log['access_secret'])\n    \n    myAPI = tweepy.API(auth, wait_on_rate_limit = True)\n    \n    return( myAPI)","52ba8670":"import snscrape.modules.twitter as sntwitter","f657b848":"\ndef search(search_item, since = '2020-01-01', until = '2020-12-15', count = 100):\n    \"\"\"\n    Searchs the item in tweets and returns a Pandas DataFrame.\n\n    Arguments:\n    ----------\n    search_item (str)\n        \n    Example:\n    search_term = \"#climate+change -filter:retweets\" to avoid retweets\n        \n    \"\"\"\n    mysearch = f'{search_item} -filter:retweets since:{since} until:{until}'\n    # collect tweet ids!!\n    myscraper = sntwitter.TwitterSearchScraper(mysearch).get_items()\n        \n    tweets_id = list()\n    for i, tweet in enumerate(myscraper):\n        if i>count:\n            break\n        tweets_id.append([tweet.id, tweet.date, tweet.content, tweet.username])\n\n    # Status object from the Tweeter API\n    mytweets = list()\n    for myid in np.array(tweets_id)[:,0]:\n        status = myAPI.get_status(myid, tweet_mode=\"extended\")\n        parsed_tweet = dict()\n        # date and time of creation\n        parsed_tweet['date'] = status.created_at\n        # times the tweet is re-tweeted\n        parsed_tweet['retweets'] = st1atus.retweet_count\n        # which platform used to post\n        parsed_tweet['source'] = status.source\n        # location where posted\n        #parsed_tweet['geo'] = tweet.geo\n        # Name of the user posting\n        parsed_tweet['author'] = status.user.name\n        # number of likes\n        parsed_tweet['likes'] = status.favorite_count\n\n        parsed_tweet['id'] = status.user.id\n        # tweet posted (without URLs)\n        parsed_tweet['text'] = remove_url( status.full_text)\n        # Screen name of the USER\n        parsed_tweet['twitter_name'] = status.user.screen_name\n        # \n        parsed_tweet['location'] = status.user.location\n        # if user is verified\n        parsed_tweet['verified'] = status.user.verified\n        # number of followers\n        parsed_tweet['followers'] = status.user.followers_count\n        # number of people the user follows\n        parsed_tweet['friends'] = status.user.friends_count\n\n        mytweets.append(parsed_tweet)\n\n    df_tweet = pd.DataFrame(mytweets)\n    # just in case, remove duplicates\n    df_tweet.drop_duplicates('text', keep='first', inplace=True)\n    df_tweet.set_index('id', inplace=True)\n        \n    return(df_tweet)","79fb2034":"search(search_item = \"#climate+change -filter:retweets', since = '2020-01-01', until = '2020-12-15', count = 1000):","dc1b7560":"<CENTER><H1>A hack to get historical tweets<\/H1><\/CENTER>\n\n\n<BR>\n    \n* This notebook is based on [a previous notebook](https:\/\/www.kaggle.com\/keitazoumana\/get-tweets-about-a-topic-from-twitter-in-5-steps) by @keitazoumana \n* Have a look to this [medium article](https:\/\/medium.com\/@jcldinco\/downloading-historical-tweets-using-tweet-ids-via-snscrape-and-tweepy-5f4ecbf19032) to have an intuition on snscrape\n\n<BR>\n    \nBe aware that the most of the code will not work here, since it requires you API Tweeter credentials. The pourpose of this notebook is merely didactic.","5c9e3c04":"<a id=\"section1\"><\/a>\n# 1. Introduction\n\nThe current tweet API (tweepy) doesn't allow queries longer than one week. It is difficult to get tweets with a certain hashtag (a great amount of tweets) with scrapping techniques, because Tweeter removed **\/i\/search\/timeline'** end of the advanced search window. The [snscrape module](https:\/\/github.com\/JustAnotherArchivist\/snscrape) allows one to scrape tweets without the restrictions of Tweepy, but using it programmatically is poorly documented. That's the reason I digged into the code and ofer a solution to include it in your Python code.","9bc4a6e1":"<a id=\"section2\"><\/a>\n# 2. Load API credentials from a json file\n\nUse this video to get your API developer. Get your credentials with the [help of this video](https:\/\/www.youtube.com\/watch?v=PqqXjwoDQiY) and put in a json file like this:\n\n```json\n{\n    \"_comment\": \"create you account in https:\/\/developer.twitter.com\/\",\n    \"api_key\": \"YOUR_API_KEY\",\n    \"api_secret\": \"YOUR_API_SECRET\",\n    \"access_token\": \"YOUR_ACCESS_TOKEN,\n    \"access_secret\":\"YOUR_ACCESS_SECRET\"\n}\n```\n","e8452ead":"In principe, we can get a DataFrame like the [sentiment analysis on Climate change](https:\/\/www.kaggle.com\/joseguzman\/climate-sentiment-in-twitter)","097ee764":"<a id=\"section3\"><\/a>\n# 3. Perform your query","c9268a6f":"The key now is to use the sntwitter object to obtain tweeter IDs, as follows\n\n```python\nmysearch = f'{search_item} -filter:retweets since:{since} until:{until}'\n# collect tweet ids!!\nmyscraper = sntwitter.TwitterSearchScraper(mysearch).get_items()\n```\n\nNow, you can create a function that returns a Pandas DataFrame object with the results of your query","0fab4379":"# Table of Contents\n\n1. [Introduction](#section1)\n2. [Loading AP credentials from a json file](#section2)\n3. [Perform your query](#section3)"}}