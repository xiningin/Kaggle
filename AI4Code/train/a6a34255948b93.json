{"cell_type":{"8ba1e04b":"code","1eb4e904":"code","e24dc869":"code","0ef610f9":"code","79f1a929":"code","055edbeb":"code","7a33669f":"code","516f96bf":"code","d9cd3aee":"code","8d3bbcfb":"code","cc577263":"code","e47a5ed0":"code","fa1968d1":"code","0edbdcf5":"code","deb0ca05":"code","aec6acbc":"code","5aaf8e12":"markdown","6952f0e3":"markdown","74c3f134":"markdown","92a1e08b":"markdown","3ec3ac9e":"markdown","1f23c516":"markdown","47fe86a4":"markdown","c3ad669c":"markdown","8413ad73":"markdown","a2e4aad6":"markdown","a3b4b0ba":"markdown","2d3e4a82":"markdown"},"source":{"8ba1e04b":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1eb4e904":"iris_data = pd.read_csv('\/kaggle\/input\/iris-dataset\/Iris.csv')\nprint(iris_data.shape)\nprint(iris_data.head())","e24dc869":"iris_data.drop('Id',inplace=True,axis=1)\nprint(iris_data.head())","0ef610f9":"print(iris_data['Species'].value_counts())","79f1a929":"iris_data.isnull().sum()","055edbeb":"iris_data_shuffled = iris_data.sample(frac=1).reset_index(drop=True)\nprint(iris_data_shuffled)","7a33669f":"#drop the Species column. Note that we are not doing it inplace so the original dataframe will not be modified\ntrain_x = iris_data_shuffled.drop('Species',axis=1)\nprint(train_x.head())","516f96bf":"train_y = iris_data_shuffled['Species']\nprint(train_y.head())","d9cd3aee":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabels = le.fit_transform(train_y)\nprint(labels)","8d3bbcfb":"X = train_x.values\ny = labels\nprint(X.shape)\nprint(y.shape)","cc577263":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)\nprint('no. of training samples:',len(X_train))\nprint('no. of testing samples:',len(X_test))","e47a5ed0":"lr_model = LogisticRegression(multi_class='multinomial')\nlr_model.fit(X_train,y_train)","fa1968d1":"y_pred = lr_model.predict(X_test)\nprint(y_pred)","0edbdcf5":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nprint('test accuracy:',accuracy_score(y_test,y_pred))","deb0ca05":"print(classification_report(y_test,y_pred))","aec6acbc":"print(confusion_matrix(y_test,y_pred))","5aaf8e12":"That's great! There are no missing values in the dataset","6952f0e3":"**Let us train the model using logistic regression**","74c3f134":"**We need to shuffle our dataset as the examples are ordered by classes. Training without shuffling the dataset will lead to poor generalization**","92a1e08b":"convert train_x to numpy array","3ec3ac9e":"# Load the dataset","1f23c516":"**Let us see the class distribution in the dataset. We can use the value_counts function to get the count of unique values for a given column**","47fe86a4":"**we will create a new dataframe which consists of the 4 features and another dataframe which consists of the class labels**","c3ad669c":"We remove the Id column as it has no significance on determining the class labels","8413ad73":"**Let us perform logistic regression. First we split the data into training and testing sets**","a2e4aad6":"# Partition the dataset into features and labels","a3b4b0ba":" **Let us convert the labels into numeric values. We use LabelEncoder for the same**","2d3e4a82":"There are 3 classes each with 50 samples(perfectly balanced). Let us check for presence of missing values"}}