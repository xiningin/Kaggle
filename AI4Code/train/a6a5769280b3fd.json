{"cell_type":{"311e72ef":"code","cc237175":"code","f76632ac":"code","2c948000":"code","8df00332":"code","ad6de925":"code","f52717b9":"code","2f15dc10":"code","64090146":"code","d6699931":"code","cd61a091":"code","0870480e":"code","113644ad":"code","df9ec336":"code","ba35b78c":"code","0425fae0":"code","095487cc":"code","1137f4f0":"code","86efd109":"code","26c79131":"code","31aadd20":"code","1b1ef4a1":"code","ee45096e":"code","90b647c9":"code","49ab727c":"code","575dcc74":"code","21ccbfa3":"code","8612f972":"code","cfe2fcfd":"code","6f7988e2":"code","8be6679f":"code","1209c91b":"code","0f4fdd31":"code","c4757e84":"code","4d1e88ae":"code","b6cc473e":"code","16f1049b":"code","a6d2cc0d":"markdown","da3de78b":"markdown","e781bf0f":"markdown","b0a98d0b":"markdown","1f0b8bf7":"markdown","f845dc04":"markdown","017f56f9":"markdown","c8b0c24b":"markdown","81a4925f":"markdown","2831a831":"markdown"},"source":{"311e72ef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scikitplot as skplt\nfrom sklearn.model_selection import GridSearchCV\nimport sklearn.metrics as m\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cc237175":"#Read Data from csv\ndataset = pd.read_csv(\"\/kaggle\/input\/heart-disease-dataset\/heart.csv\")\ndataset","f76632ac":"features = [\"age\",\"sex\",\"thalach\",\"trestbps\"]\nfeatures","2c948000":"pulseratenormal = dataset[dataset[\"target\"]==0]['trestbps']\nnp.average(pulseratenormal)","8df00332":"#Setting X and y\nX = dataset[features]\ny = dataset[\"target\"]\nprint(X)\nprint(y)","ad6de925":"ds = dataset[features+[\"target\"]]\ncorr =d.corr()\ncorr.style.background_gradient(cmap='coolwarm')","f52717b9":"plt.figure(figsize=(6,7))\nplt.bar(dataset['target'].unique(), dataset['target'].value_counts(), color = ['red', 'green'])\nplt.xticks([0, 1])\nplt.xlabel('Target Classes')\nplt.ylabel('Count')\nplt.title('Count of each Target Class')","2f15dc10":"g = sns.catplot(x=\"thalach\", y=\"trestbps\", hue=\"target\", kind=\"swarm\", data=dataset)#, height=50, aspect=100\/20)\n\ng.fig.set_figwidth(20.27)\ng.fig.set_figheight(11.7)","64090146":"X.hist()","d6699931":"df = dataset[features+[\"target\"]]\ndf = df[df[\"target\"]==1]\ndf = df[features]\ndf.hist(color=\"red\");","cd61a091":"df = dataset[features+[\"target\"]]\ndf = df[df[\"target\"]==0]\ndf = df[features]\ndf.hist(color=\"green\");","0870480e":"g = sns.catplot(x=\"thalach\", y=\"trestbps\", hue=\"target\", kind=\"swarm\", data=dataset)#, height=50, aspect=100\/20)\n\n#g.fig.set_figwidth(20.27)\n#g.fig.set_figheight(11.7)\nplt.xticks(np.arange(0, max(dataset['thalach']), 30 ))","113644ad":"sns.catplot(x=\"thalach\", y=\"trestbps\", hue=\"sex\", kind=\"swarm\", data=dataset)\nplt.xticks(np.arange(0, max(dataset['thalach']), 30 ))","df9ec336":"y.value_counts()","ba35b78c":"from sklearn.model_selection import train_test_split\n#Splitting the dataset into training and testing data\ntrainX,testX,trainY,testY = train_test_split(X,y,random_state=1,test_size=0.2)","0425fae0":"from sklearn import preprocessing\nscaler = preprocessing.StandardScaler()\ntrainX = scaler.fit_transform(trainX)\ntrainX =pd.DataFrame(trainX)\ntrainX.columns = X.columns\ntestX = scaler.transform(testX)\ntestX =pd.DataFrame(testX)\ntestX.columns = X.columns\n\nmm_scaler = preprocessing.MinMaxScaler()\ntrainX = mm_scaler.fit_transform(trainX)\ntrainX =pd.DataFrame(trainX)\ntrainX.columns = X.columns\ntestX = mm_scaler.transform(testX)\ntestX =pd.DataFrame(testX)\ntestX.columns = X.columns","095487cc":"#fit the model with knn classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel1 = KNeighborsClassifier(n_neighbors=1)\n\nmodel1.fit(trainX,trainY)","1137f4f0":"from sklearn.model_selection import GridSearchCV\nparameters = {'n_neighbors': np.arange(1, 10)}\ngrid_search = GridSearchCV(estimator = model1, param_grid = parameters, scoring = 'f1', cv = 10, n_jobs = -1)\ngrid_search = grid_search.fit(trainX, trainY)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(best_accuracy)\nprint(best_parameters)","86efd109":"#skplt.estimators.plot_feature_importances(model,feature_names=features)","26c79131":"#prediction\npredictY = pd.Series(model1.predict(testX))","31aadd20":"#getting accuracy\nimport sklearn.metrics as m\naccuracy = m.accuracy_score(predictY,testY)\nconfusion = m.confusion_matrix(predictY,testY)\nprecision = m.precision_score(predictY,testY)\nrecall = m.recall_score(predictY,testY)\nf1 = m.f1_score(predictY,testY)\nprint(\"accuracy = \",accuracy)\nprint(\"confusion matrix : \\n\",confusion)\nprint(\"precision = \",precision)\nprint(\"recall = \",recall)\nprint(\"f1 score = \",f1)","1b1ef4a1":"skplt.metrics.plot_confusion_matrix(testY,predictY,normalize=True)","ee45096e":"from sklearn.svm import SVC\nmodel2 = SVC(kernel = 'rbf',C=10, random_state = 0, gamma=0.18)\nmodel2.fit(trainX,trainY)","90b647c9":"c = [1, 10, 100]\nimport sklearn.metrics as m\naccuracy=0\nf1=0\nfor ci in c:\n    model2 = SVC(kernel = 'linear', random_state = 0, C=ci)\n    model2.fit(trainX,trainY)\n    predictY = pd.Series(model2.predict(testX))\n    pa = accuracy\n    accuracy = m.accuracy_score(predictY,testY)\n    pa = accuracy-pa\n    pf1 = f1\n    f1 = m.f1_score(predictY,testY)\n    pf1 = f1 - pf1\n    print(\"c = \",model2.C,\" f1 = \",f1,\"accuracy = \",accuracy)\n    print(\"pa = \",pa,\" pf1 = \",pf1)","49ab727c":"parameters =[{'C': [1, 10, 100], 'kernel': ['rbf'], 'gamma': [ 0.10,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2]}]\ngrid_search = GridSearchCV(estimator = model2, param_grid = parameters, scoring = 'f1', cv = 10, n_jobs = -1)\ngrid_search = grid_search.fit(X,y)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(best_accuracy)\nprint(best_parameters)","575dcc74":"predictY = pd.Series(model2.predict(testX))","21ccbfa3":"#getting accuracy\naccuracy = m.accuracy_score(predictY,testY)\nconfusion = m.confusion_matrix(predictY,testY)\nprecision = m.precision_score(predictY,testY)\nrecall = m.recall_score(predictY,testY)\nf1 = m.f1_score(predictY,testY)\nprint(\"accuracy = \",accuracy)\nprint(\"confusion matrix : \\n\",confusion)\nprint(\"precision = \",precision)\nprint(\"recall = \",recall)\nprint(\"f1 score = \",f1)","8612f972":"skplt.metrics.plot_confusion_matrix(testY,predictY,normalize=True)","cfe2fcfd":"from sklearn.ensemble import RandomForestClassifier\nmodel3 = RandomForestClassifier(min_samples_leaf=0.1,min_samples_split=0.1,max_depth=24,n_estimators=8)\nmodel3.fit(trainX,trainY)","6f7988e2":"parameters =[{\"n_estimators\" : [4,8,16,32],\n              \"max_depth\":range(1,16),\n              \"min_samples_split\":np.linspace(0.1, 1.0, 10, endpoint=True),\n              \"min_samples_leaf\" : np.linspace(0.1, 0.5, 10, endpoint=True)}]\ngrid_search = GridSearchCV(estimator = model3, param_grid = parameters, scoring = 'f1', cv = 10, n_jobs = -1)\ngrid_search = grid_search.fit(X,y)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(best_accuracy)\nprint(best_parameters)","8be6679f":"predictY = pd.Series(model3.predict(testX))","1209c91b":"#getting accuracy\naccuracy = m.accuracy_score(predictY,testY)\nconfusion = m.confusion_matrix(predictY,testY)\nprecision = m.precision_score(predictY,testY)\nrecall = m.recall_score(predictY,testY)\nf1 = m.f1_score(predictY,testY)\nprint(\"accuracy = \",accuracy)\nprint(\"confusion matrix : \\n\",confusion)\nprint(\"precision = \",precision)\nprint(\"recall = \",recall)\nprint(\"f1 score = \",f1)","0f4fdd31":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(hidden_layer_sizes=(20,20,20), max_iter=500, alpha=0.0001,\n                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\nclf.fit(trainX,trainY)","c4757e84":"parameters = {\n    'hidden_layer_sizes': [(50,50,50), (50,100,50),(20,20,20)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}\ngrid_search = GridSearchCV(estimator = clf, param_grid = parameters, scoring = 'f1', cv = 10, n_jobs = -1)\ngrid_search = grid_search.fit(X,y)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(best_accuracy)\nprint(best_parameters)","4d1e88ae":"predictY = clf.predict(testX)","b6cc473e":"#getting accuracy\naccuracy = m.accuracy_score(predictY,testY)\nconfusion = m.confusion_matrix(predictY,testY)\nprecision = m.precision_score(predictY,testY)\nrecall = m.recall_score(predictY,testY)\nf1 = m.f1_score(predictY,testY)\nprint(\"accuracy = \",accuracy)\nprint(\"confusion matrix : \\n\",confusion)\nprint(\"precision = \",precision)\nprint(\"recall = \",recall)\nprint(\"f1 score = \",f1)","16f1049b":"from sklearn.neural_network import MLPClassifier\nmodel3 = MLPClassifier(hidden_layer_sizes=(20,20,20), max_iter=500, alpha=0.0001,\n                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\nmodel3.fit(trainX,trainY)","a6d2cc0d":"**SVM**","da3de78b":"Training","e781bf0f":"Multi Layer Perceptron","b0a98d0b":"find *recall* and *precision* and *f1 score*","1f0b8bf7":"Multi Layer Perceptron","f845dc04":"**KNN**","017f56f9":"Visualization","c8b0c24b":"to study\n* feature importance\n* class imbalance\n* grid search\n\nalgorithm\nsvm\nrandom forest","81a4925f":"**Random forest**","2831a831":"**links**\n\nhttps:\/\/towardsdatascience.com\/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e"}}