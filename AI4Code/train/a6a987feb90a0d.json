{"cell_type":{"34192619":"code","b306b4cf":"code","8099c0fd":"code","221ea0bb":"code","291bfcdc":"code","8a3c7918":"code","9c2134b9":"code","3b2c3f3b":"code","6a8c1c20":"code","6fcbd7f7":"code","68613fac":"code","dbec2ca3":"code","044d4a70":"code","f1ea5be7":"code","6a6e146e":"code","5d951633":"code","e96bcbe4":"code","ec641c98":"code","5a86ad42":"code","75a7612f":"code","1746ed67":"code","da170589":"code","376d2663":"markdown","b7356bf4":"markdown","c0e02f8a":"markdown"},"source":{"34192619":"from os.path import join as pjoin\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n","b306b4cf":"PATH_TO_DATA = '..\/input\/lab12-classification-problem'","8099c0fd":"data = pd.read_csv(pjoin(PATH_TO_DATA, 'train.csv'))\ndata.shape\n\n\ndataTest = pd.read_csv(pjoin(PATH_TO_DATA, 'test.csv'))\n","221ea0bb":"labels = data['Label']\nwords = data['Word']\n\n\nwordsTest = dataTest['Word']","291bfcdc":"# \u041f\u0435\u0440\u0432\u0430\u044f \u0431\u0443\u043a\u0432\u0430 \u0431\u043e\u043b\u044c\u0448\u0430\u044f\n\nisUpperFirst = words.str.slice(0, 1).str.isupper()\ndata['is_upper_first'] = isUpperFirst\n\nisUpperFirstTest = wordsTest.str.slice(0, 1).str.isupper()\ndataTest['is_upper_first'] = isUpperFirstTest\n\n\npd.crosstab(isUpperFirst, labels).plot(kind='bar')","8a3c7918":"# \u0432\u0441\u0435 \u0431\u0443\u043a\u0432\u044b \u0431\u043e\u043b\u044c\u0448\u0438\u0435\nisAllUpper = words.str.isupper()\ndata['is_all_upper'] = isAllUpper\n\n\n\nisAllUpperTest = wordsTest.str.isupper()\ndataTest['is_all_upper'] = isAllUpperTest\n\n\npd.crosstab(isAllUpper, labels).plot(kind='bar')","9c2134b9":"# \u0432\u0441\u0435 \u0431\u0443\u043a\u0432\u044b \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u0435\nisAllLower = words.str.islower()\ndata['is_all_lower'] = isAllLower\n\n\n\nisAllLowerTest = wordsTest.str.islower()\ndataTest['is_all_lower'] = isAllLowerTest\n\n\npd.crosstab(isAllLower, labels).plot(kind='bar')","3b2c3f3b":"#\u043f\u043e \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0439 \u0431\u0443\u043a\u0432\u0435\nlastLetter = words.str.slice(-1, None).str.lower()\ndata['last_letter'] = lastLetter\n\nlastLetterTest = wordsTest.str.slice(-1, None).str.lower()\ndataTest['last_letter'] = lastLetterTest\n\n\npd.crosstab(lastLetter, labels).plot(kind='bar')","6a8c1c20":"# \u043f\u043e \u043f\u0440\u0435\u0434\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0439 \u0431\u0443\u043a\u0432\u0435\nprelastLetter = words.str.slice(-1, None).str.lower()\ndata['prelast_letter'] = prelastLetter\n\nprelastLetterTest = wordsTest.str.slice(-1, None).str.lower()\ndataTest['prelast_letter'] = prelastLetterTest\n\n\npd.crosstab(prelastLetter, labels).plot(kind='bar')","6fcbd7f7":"# \u043f\u043e \u043f\u0440\u0435\u0434 \u043f\u0440\u0435\u0434\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0439 \u0431\u0443\u043a\u0432\u0435\npreprelastLetter = words.str.slice(-1, None).str.lower()\ndata['preprelast_letter'] = preprelastLetter\n\npreprelastLetterTest = wordsTest.str.slice(-1, None).str.lower()\ndataTest['preprelast_letter'] = preprelastLetterTest\n\n\npd.crosstab(preprelastLetter, labels).plot(kind='bar')","68613fac":"# \u043f\u043e \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u043c \u043e\u043a\u043e\u043d\u0447\u0430\u043d\u0438\u044f\u043c \u0444\u0430\u043c\u0438\u043b\u0438\u0439 \u0440\u0430\u0437\u043d\u044b\u0445 \u043d\u0430\u0440\u043e\u0434\u043d\u043e\u0441\u0442\u0435\u0439\nt = '''\u0410\u0431\u0445\u0430\u0437\u044b: \u0431\u0430 \u0443\u0430 \u0438\u043f\u0430 \n\u0410\u0437\u0435\u0440\u0431\u0430\u0439\u0434\u0436\u0430\u043d\u0446\u044b: \u0437\u0430\u0434\u0435 \u043b\u0438 \u043b\u044b \u043e\u0433\u043b\u0443 \u043a\u044b\u0437\u044b \n\u0410\u0440\u043c\u044f\u043d\u0435: \u044f\u043d \u044f\u043d\u0446 \u0443\u043d\u0438 \n\u0411\u0435\u043b\u043e\u0440\u0443\u0441\u044b: \u0438\u0447 \u0447\u0438\u043a \u043a\u0430 \u043a\u043e \u043e\u043d\u0430\u043a \u0451\u043d\u0430\u043a \u0443\u043a \u0438\u043a \u0441\u043a\u0438\n\u0411\u043e\u043b\u0433\u0430\u0440\u044b: \u0435\u0432 \u043e\u0432 \n\u0413\u0430\u0433\u0430\u0443\u0437\u044b: \u043e\u0433\u043b\u043e \n\u0413\u0440\u0435\u043a\u0438: \u043f\u0443\u043b\u043e\u0441 \u043a\u043e\u0441 \u0438\u0434\u0438 \n\u0413\u0440\u0443\u0437\u0438\u043d\u044b: \u0448\u0432\u0438\u043b\u0438 \u0434\u0437\u0435 \u0443\u0440\u0438 \u0438\u0430 \u0443\u0430 \u0430\u0432\u0430 \u043b\u0438 \u0441\u0438 \u043d\u0438 \u0442\u0435\n\u0418\u0442\u0430\u043b\u044c\u044f\u043d\u0446\u044b: \u0438\u043d\u0438 \u0438\u043d\u043e \u0435\u043b\u043b\u043e \u0438\u043b\u043b\u043e \u0435\u0442\u0442\u0438 \u0435\u0442\u0442\u043e \u0438\u0442\u043e\n\u041b\u0438\u0442\u043e\u0432\u0446\u044b: \u0442\u0435 \u0438\u0441 \u043d\u0435 \u043e\u043d\u0438\u0441 \u0443\u043d\u0430\u0441 \u0443\u0442\u0438\u0441 \u0430\u0439\u0442\u0438\u0441 \u0435\u043d\u0430 \u044e\u0432\u0435\u043d \u0443\u0432\u0435\u043d \u0443\u0442 \u043f\u043e\u043b\u0443\u044e\u0442 \u0430\u0439\u0442\n\u041b\u0430\u0442\u044b\u0448\u0438: \u0438\u0441\n\u041c\u043e\u043b\u0434\u043e\u0432\u0430\u043d\u0435: \u0441\u043a\u0443 \u0443 \u0443\u043b \u0430\u043d\n\u041c\u043e\u0440\u0434\u0432\u0430: \u044b\u043d \u0438\u043d \u0448\u043a\u0438\u043d \u043a\u0438\u043d\n\u041d\u0435\u043c\u0446\u044b: \u043c\u0430\u043d \u0435\u0440\n\u041e\u0441\u0435\u0442\u0438\u043d\u044b: \u0442\u0438\n\u041f\u043e\u043b\u044f\u043a\u0438: \u0441\u043a \u0446\u043a \u0438\u0439 \n\u041f\u043e\u0440\u0442\u0443\u0433\u0430\u043b\u044c\u0446\u044b: \u0435\u0437 \u0435\u0441 \u0430\u0437\n\u0420\u0443\u0441\u0441\u043a\u0438\u0435: \u0430\u043d \u044b\u043d \u0438\u043d \u0441\u043a\u0438\u0445 \u043e\u0432 \u0435\u0432 \u0441\u043a\u043e\u0439 \u0446\u043a\u043e\u0439 \u0438\u0445 \u044b\u0445 \u043e\u0432\u0430 \u0435\u0432\u0430 \u0441\u043a\u0430\u044f \u0438\u043d\u0430 \u0430\u043d\u0430 \u044b\u043d\u0430\n\u0420\u0443\u043c\u044b\u043d\u044b: \u0441\u043a\u0443 \u0443\u043b \u0430\u043d\n\u0422\u0430\u0442\u0430\u0440\u044b: \u043e\u0432 \u0435\u0432 \u0438\u043d\n\u0422\u0443\u0440\u043a\u0438: \u043e\u0433\u043b\u0443 \u0434\u0436\u0438 \u0437\u0430\u0434\u0435\n\u0428\u0432\u0435\u0434\u044b: \u0441\u0441\u043e\u043d \u0431\u0435\u0440\u0433 \u0441\u0442\u0435\u0434 \u0441\u0442\u0440\u043e\u043c'''\n\n\nendings = []\nfor line in t.split('\\n'):\n    endings.extend([end for end in line.split(':')[1].strip().split(' ')])\nendings = set(endings)","dbec2ca3":"endsWithKnownSuffix = np.zeros_like(words.values, dtype=bool)\nendsWithKnownSuffixTest = np.zeros_like(wordsTest.values, dtype=bool)\n\nfor ending in endings:\n    endsWithKnownSuffix  |= words.str.lower().str.endswith(ending)\n    endsWithKnownSuffixTest |= wordsTest.str.lower().str.endswith(ending)\n    \ndata['ends_with_a_known_suffix'] = endsWithKnownSuffix \ndataTest['ends_with_a_known_suffix'] = endsWithKnownSuffixTest\n\npd.crosstab(endsWithKnownSuffix , labels).plot(kind='bar')","044d4a70":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, precision_recall_curve\nfrom catboost import CatBoostClassifier","f1ea5be7":"W = data.drop(columns = ['Word', 'Label'])\nl = data['Label']\nWTest = dataTest.drop(columns = ['Word'])\n","6a6e146e":"WTrain, WTrainTest, lTrain, lTrainTest = train_test_split(W, l, test_size=0.3, random_state=1)\nWTrain = W\nlTrain = l\n\n\n","5d951633":"def getAcuracy(lTrue, predProba, threshold=0.5):\n    pred = np.zeros_like(predProba)\n    pred[predProba > threshold] = 1\n    acuracy = accuracy_score(lTrue, pred)\n    return acuracy","e96bcbe4":"\ngb = CatBoostClassifier(\n    cat_features= WTrain,\n    eval_metric='AUC',\n    random_seed=1,\n    nan_mode='Forbidden',\n    task_type='CPU',\n    verbose=True,\n    n_estimators=150,\n    max_depth=6,\n)\ngb.fit(WTrain, lTrain)","ec641c98":"# Quality on train\npredProbaTrain = gb.predict_proba(WTrain)[:, 1]\nacc = getAcuracy(lTrain, predProbaTrain)\nprint(\"Acuracy = \", acc)\n","5a86ad42":"# Quality on test\npredProbaTest = gb.predict_proba(WTrainTest)[:, 1]\nacc = getAcuracy(lTrainTest, predProbaTest)\nprint(\"Acuracy = \", acc)","75a7612f":"pr, rec, thr = precision_recall_curve(lTrain, predProbaTrain)\nf1 = 2 * (pr * rec) \/ (pr + rec)\n","1746ed67":"best_thr = thr[f1.argmax() - 1]\nbest_thr, f1.max()","da170589":"predTest = gb.predict_proba(WTest)[:, 1]\n\nanswers = np.zeros(len(predTest), dtype=bool)\n\n\nfor i in range(len(predTest)):\n    if predTest[i] >= best_thr :\n        answers[i] = True\n        \n\nres = pd.DataFrame({'Id': WTest.index, 'Prediction': predTest})\nres.to_csv('result.csv', index=False)","376d2663":"## Second Task","b7356bf4":"## First Task","c0e02f8a":"## Load datasets"}}