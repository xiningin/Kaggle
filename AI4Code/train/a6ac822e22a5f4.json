{"cell_type":{"1b389451":"code","4c20396c":"code","ece97bd6":"code","1a3bab60":"code","a44880e3":"code","a7dbee5e":"code","edaf65c7":"code","230a822f":"code","3673af37":"code","23178e65":"code","9bb7de61":"code","c6470517":"code","cd82eff5":"code","9a5511ce":"code","128b0857":"code","4e70d6d6":"code","8c5fe2c0":"code","0fd359c5":"code","c6c1000a":"code","4f65884e":"code","678034de":"code","da759f42":"code","8453bb29":"code","95b4684a":"code","01eccf7f":"code","d46087ac":"code","3faabd7d":"code","3a31a87b":"code","62d44102":"code","dfab4911":"code","cc62b203":"code","fd5626dc":"markdown","2a58de32":"markdown","101b25ef":"markdown","3cced9dc":"markdown","ac35aa2d":"markdown","64d686fc":"markdown","fd51a920":"markdown","c30fea52":"markdown","257b7b6b":"markdown","d06e5e9f":"markdown","999b4f8e":"markdown","adfd4fc5":"markdown","5652d9dc":"markdown"},"source":{"1b389451":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c20396c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ece97bd6":"df=pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndf.head()","1a3bab60":"df.info()","a44880e3":"df.describe()","a7dbee5e":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","edaf65c7":"df.isnull().sum()","230a822f":"sns.histplot(df[\"bmi\"],bins=20)","3673af37":"median=df[\"bmi\"].median()","23178e65":"df_m=df.copy()","9bb7de61":"df_m[\"bmi\"]=df_m[\"bmi\"].fillna(median)","c6470517":"df_m.isnull().sum()","cd82eff5":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf_m['gender'] = le.fit_transform(df_m['gender'])\ndf_m['ever_married'] = le.fit_transform(df_m['ever_married'])\ndf_m['work_type'] = le.fit_transform(df_m['work_type'])\ndf_m['Residence_type'] = le.fit_transform(df_m['Residence_type'])\ndf_m['smoking_status'] = le.fit_transform(df_m['smoking_status'])","9a5511ce":"df_m.head()","128b0857":"g=sns.FacetGrid(df_m, col='stroke')\ng = g.map(sns.kdeplot, 'work_type')","4e70d6d6":"g=sns.FacetGrid(df_m, col='stroke')\ng = g.map(sns.kdeplot, 'smoking_status')","8c5fe2c0":"df_m.drop(\"id\",axis=True)","0fd359c5":"X=df_m.iloc[:,:-1]\ny=df_m.iloc[:,-1]","c6c1000a":"print(X)","4f65884e":"print(y)","678034de":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","da759f42":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(X_train,y_train)","8453bb29":"lr.score(X_test,y_test)","95b4684a":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test,lr.predict(X_test)),annot=True)","01eccf7f":"sns.lineplot(x='age',y='bmi',hue='gender',data=df)","d46087ac":"import matplotlib as mpl\nsns.set_theme(style='ticks')\nf, ax = plt.subplots(figsize=(10, 7))\nsns.despine(f)\n\nsns.histplot(\n    df,\n    x=\"bmi\", hue=\"gender\",\n    multiple=\"stack\",\n    palette=\"light:m_r\",\n    edgecolor=\".3\",\n    linewidth=.5,\n    log_scale=True,\n)\nax.xaxis.set_major_formatter(mpl.ticker.ScalarFormatter())\nax.set_xticks([10,20,30,40,50])","3faabd7d":"data_male=df[df['gender']=='Male']","3a31a87b":"data_male.head()","62d44102":"print('Median BMI of male with age less than 30 : ',data_male[data_male['age']<30]['bmi'].median())\nprint('Median BMI of male with age more than 30 and less than 50 : ',data_male[(data_male['age']>30) & (data_male['age']<50)]['bmi'].median())\nprint('Median BMI of male with age greater than 50 : ',data_male[data_male['age']>50]['bmi'].median())","dfab4911":"data_female=df[df[\"gender\"]==\"Female\"]\nprint('Median BMI of Female with age less than 30 : ',data_female[data_female['age']<30]['bmi'].median())\nprint('Median BMI of Female with age more than 30 and less than 50 : ',data_female[(data_female['age']>30) & (data_female['age']<50)]['bmi'].median())\nprint('Median BMI of Female with age greater than 50 : ',data_female[data_female['age']>50]['bmi'].median())","cc62b203":"data_other = df[df['gender']=='Other']\nprint('Median BMI of Other with age less than 30 : ',data_other[data_other['age']<30]['bmi'].median())\nprint('Median BMI of Other with age more than 30 and less than 50 : ',data_other[(data_other['age']>30) & (data_other['age']<50)]['bmi'].median())\nprint('Median BMI of Other with age greater than 50 : ',data_other[data_other['age']>50]['bmi'].median())","fd5626dc":"Dropping id column as it is of no use to us","2a58de32":"**TAKING CARE OF MISSING DATA**","101b25ef":"As in our dataset we have:\n\n1.Gender\n\n2.ever_married\n\n3.work_type\n\n4.Residence_type\n\n5.smoking_status\n\nThese are our categorical features so we will encode them by label encoder.","3cced9dc":"**EXPLORING BMI WITH RESPECT TO OTHER COLUMNS**","ac35aa2d":"**IMPORTING LIBRARIES**","64d686fc":"**CHECKING FOR MISSING VALUES**","fd51a920":"Now I will calculate BMI based on two factors age and gender , i will find median for 3 different age groups for male and female and other\n\nThree age groups :\n\n1.0-30\n\n2.30-50\n\n3.>50","c30fea52":"**SPLITTING DATASET INTO TRAIN AND TEST SET**","257b7b6b":"**ENCODING CATEGORICAL FEATURES**","d06e5e9f":"**FINDING CORRELATIONS BETWEEN THE FEATURES(IF ANY)**","999b4f8e":"**IMPORTING DATASET**","adfd4fc5":"**MAKING CONFUSION MATRIX**","5652d9dc":"**TRAINING LOGISTIC REGRESSION MODEL ON THE DATASET**"}}