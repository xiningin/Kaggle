{"cell_type":{"3c37ed3b":"code","1b138f77":"code","3951918c":"code","742e554a":"code","9aede891":"code","77d60d15":"code","365d6bb8":"code","bc916980":"code","6d1bda82":"code","1c9b6f6f":"code","7bce83a8":"code","58043041":"code","693854c1":"code","abb46770":"code","b2d47419":"code","6f0064e4":"code","463046d5":"code","ee09afa5":"code","28273624":"code","dc1b6ff9":"code","3dce72a2":"code","d0f4c932":"code","bb4fc1ba":"code","2e87cdf2":"code","f237ef58":"code","e4e976cd":"markdown","21c74e80":"markdown","cc15cff5":"markdown","2d5c52ef":"markdown","11d6354f":"markdown","24fd3097":"markdown","3d453e20":"markdown","206d45e9":"markdown","244ddd63":"markdown","2da6984e":"markdown","2239be93":"markdown","f33072a9":"markdown","5953c38f":"markdown","823c825a":"markdown","2b0ce0d3":"markdown","2d58be2e":"markdown","358627ed":"markdown","e26709d6":"markdown","694da44d":"markdown","5bc7f54f":"markdown","bdfea4b6":"markdown","f7992e39":"markdown"},"source":{"3c37ed3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b138f77":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn\nimport seaborn as sns ","3951918c":"dataset= pd.read_csv('..\/input\/comcast1\/Comcast Telecom Complaints data 1.csv')\nX = dataset.iloc[:, :-1].values\nprint(X)\n\n","742e554a":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncust_comp = le.fit_transform(dataset.iloc[:,1])\nprint(cust_comp)\nrec_via = le.fit_transform(dataset.iloc[:,4])\nprint(rec_via)\ncity = le.fit_transform(dataset.iloc[:,5])\nprint(city)\nstate = le.fit_transform(dataset.iloc[:,6])\nprint(state)\nonbehalf = le.fit_transform(dataset.iloc[:,8])\nprint(onbehalf)","9aede891":"dataset['year'] = pd.DatetimeIndex(dataset['Date']).year\ndataset['month'] = pd.DatetimeIndex(dataset['Date']).month\ndataset['day'] = pd.DatetimeIndex(dataset['Date']).day\ndataset.drop([\"Ticket #\", \"Time\",\"Zip code\",\"Date\"], axis = 1, inplace = True) \n\ndataset.head()\n","77d60d15":"noc_pm = dataset['month'].value_counts()\nprint(noc_pm)","365d6bb8":"noc_pd = dataset['day'].value_counts()\nprint(noc_pd)","bc916980":"sns.lineplot( data = noc_pm)\nplt.title('MONTHLY GRANULARITY LEVELS')\nplt.xlabel('DAY')\nplt.ylabel('NO. OF COMPLAINTS')\nplt.show()","6d1bda82":"sns.lineplot( data = noc_pd)\nplt.title('DAILY GRANULARITY LEVELS')\nplt.xlabel('DAY')\nplt.ylabel('NO. OF COMPLAINTS')\nplt.show()\n","1c9b6f6f":"dataset['Customer Complaint'] = dataset['Customer Complaint'].str.title()\ncomp = dataset['Customer Complaint'].value_counts()\nprint(comp)","7bce83a8":"dataset['Customer Complaint'].value_counts()[:20].plot(kind='bar',figsize=(8,8),stacked=True)","58043041":"print('The most lodged complaint is : ',dataset.iloc[:,0].value_counts().idxmax())\nprint('The city that has lodged most number of complaints is :',dataset.iloc[:,2].value_counts().idxmax())\nprint('The state that has lodged most number of complaints is :',dataset.iloc[:,3].value_counts().idxmax())","693854c1":"dataset[\"finalstatus\"] = [\"Open\" if Status==\"Open\" or Status==\"Pending\" else \"Closed\"  for Status in dataset[\"Status\"]]\ndataset[\"finalstatus\"].unique()\ndataset.head()","abb46770":"dataset['State'] = dataset['State'].str.title() \nstatecomp = dataset.groupby(['State','finalstatus']).size().unstack().fillna(0)\nstatecomp","b2d47419":"a = statecomp.sort_values(\"Closed\",axis = 0,ascending=False)\na.plot(kind=\"bar\", figsize=(16,12), stacked=True)","6f0064e4":"print(a)\nprint('The maximum no of unresolved complaints is:',a.max())","463046d5":"info = dataset.groupby(['Received Via','finalstatus']).size().unstack().fillna(0)\nprint(info)","ee09afa5":"total_comp =info['Closed']+info['Open']\nprint('The total complaints',total_comp)\npercentage = info['Closed']\/total_comp*100\nprint('The percentage of complaints resolved',percentage)","28273624":"year = dataset.iloc[:,6]\nmonth = dataset.iloc[:,7]\nday = dataset.iloc[:,8]\nimport pandas as pd  \nlst = [cust_comp,rec_via,city,state,onbehalf,year,month,day]\ndf_t = pd.DataFrame(lst) \ndf = df_t.T\nprint(df) ","dc1b6ff9":"\ny = dataset.iloc[:,9]\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)\ny = y.reshape(len(y),1)\ny\n","3dce72a2":"from sklearn.model_selection import train_test_split\ndf_train, df_test, y_train, y_test = train_test_split(df, y, test_size = 0.25, random_state = 0)\n\nprint(df_train)\n\nprint(df_test)\n\nprint(y_test)\n\nprint(y_train)","d0f4c932":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf_train = sc.fit_transform(df_train)\ndf_test = sc.fit_transform(df_test)\n\nprint(df_test)\n\nprint(df_train)\n","bb4fc1ba":"from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(df_train, y_train)","2e87cdf2":"y_pred = regressor.predict(df_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","f237ef58":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\na = accuracy_score(y_test,y_pred)\nprint('The accuracy of the model is :',a*100)","e4e976cd":"\nTO PREDICT THE TEST RESULT","21c74e80":"\n5)NEW VARIABLE WITH OPEN AND PENDING AS OPEN,CLOSED AND SOLVED AS CLOSED","cc15cff5":"9)PERCENTAGE OF COMPLAINTS RESOLVED TILL DATE","2d5c52ef":"FEATURE SCALING","11d6354f":"3)FREQUENCY TABLE OF LODGED COMPLAINTS","24fd3097":"ENCODING CATEGORICAL DATA","3d453e20":"\n\nBY VIEWING THE ABOVE OUTPUT IT IS CLEAR THAT JUNE HAS HIGHEST NO OF COMPLAINTS LODGED WITH 1280 COMPLAINTS","206d45e9":"\n\n4,7)TO FIND MAX LODGED COMPLAINT AND THE STATE THAT HAS LODGED MAX COMPLAINT","244ddd63":"ACCURACY OF THE MODEL","2da6984e":"CONSTRUCTING A DATAFRAME WITH ALL ENCODED VARIABLES","2239be93":"\nSETTING STATUS AS Y TO PREDICT IF THE COMPLAINT LODGED WILL BE OPEN OR CLOSED","f33072a9":"LINE PLOT REPRESENTING MONTHLY GRANULARITY LEVELS","5953c38f":"Importing lib","823c825a":"LINE PLOT REPRESENTING DAILY GRANULARITY LEVELS","2b0ce0d3":"GRAPH REPRESENTING THE STATUS OF COMPLAINTS IN STATES","2d58be2e":"Importing dataset","358627ed":"DECISION TREE MODEL","e26709d6":"6)STATE WISE STATUS OF COMPLAINT","694da44d":"\n\n2)TO OBTAIN NO OF COMPLAINTS IN MONTHLY AND DAILY FORMAT","5bc7f54f":"SPLITTING DATA INTO TRAIN AND TEST","bdfea4b6":"8) TO SEE WHICH STATE HAS MORE UNRESOLVED COMPLAINTS","f7992e39":"OBTAINING DATE,MONTH AND YEAR SEPERATELY REMOVING UNNECESSARY DATA(TICKET,ZIPCODE,TIME)"}}