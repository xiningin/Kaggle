{"cell_type":{"4c75ddfe":"code","1fd144e3":"code","7b041d0a":"code","3073080e":"code","b2b557a7":"code","d2339c8b":"code","4455fa83":"code","7007556e":"code","c857c8c9":"code","3fca3502":"code","dd8a80dc":"code","97d84e07":"code","3f62d989":"code","fdb38aae":"code","bedf9202":"code","26038a30":"code","308d0bd8":"code","1a3d97bc":"markdown","1fc4904a":"markdown","d95ee9bd":"markdown","13280680":"markdown","6beeb777":"markdown","237515f6":"markdown"},"source":{"4c75ddfe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fd144e3":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","7b041d0a":"pd.options.display.max_columns = 999","3073080e":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/sample_submission.csv\")","b2b557a7":"sub.head()","d2339c8b":"test.head()","4455fa83":"train.head()","7007556e":"allData = pd.concat([train, test])\nallData","c857c8c9":"categories = [col for col in allData.columns[1:] if allData[col].dtypes == 'object']\nnum_features = [col for col in allData.columns[1:] if allData[col].dtypes != 'object']","3fca3502":"le = LabelEncoder()\nfor col in allData.columns[allData.dtypes == 'object']:\n    allData[col] = le.fit_transform(list(allData[col]))\nallData.head()","dd8a80dc":"allData2 = allData.drop(['id', 'target'],1)\nlabel = train['target']","97d84e07":"train2 = allData2[:len(train)]\ntest2 = allData2[len(train):]\ntrain2.shape, test2.shape","3f62d989":"# models with training\n\ndef model_catboost(X_train, y_train, X_valid, y_valid, test2):\n    cat = CatBoostClassifier(task_type='GPU')\n    cat.fit(X_train, y_train, verbose=200, cat_features = categories)\n    valid_pred = cat.predict_proba(X_valid)[:,1]\n    test_pred = cat.predict_proba(test2)[:,1]\n    score_pred = roc_auc_score(y_valid, valid_pred)\n    return score_pred, test_pred\n\ndef model_lgbm(X_train, y_train, X_valid, y_valid, test2):\n    lgb = LGBMClassifier()\n    lgb.fit(X_train, y_train)\n    valid_pred = lgb.predict_proba(X_valid)[:,1]\n    test_pred = lgb.predict_proba(test2)[:,1]\n    score_pred = roc_auc_score(y_valid, valid_pred)\n    return score_pred, test_pred\n\ndef model_xgb(X_train, y_train, X_valid, y_valid, test2):\n    xgb = XGBClassifier()\n    xgb.fit(X_train, y_train)\n    valid_pred = xgb.predict_proba(X_valid)[:,1]\n    test_pred = xgb.predict_proba(test2)[:,1]\n    score_pred = roc_auc_score(y_valid, valid_pred)\n    return score_pred, test_pred","fdb38aae":"%%time\n# StratifyKFold\n\nn_counts = 5\n\nskf = StratifiedKFold(n_splits = n_counts, shuffle = True, random_state=42)\n\nresult = {}\nscores = {}\n\nmodel_list = ['cat', 'lgb', 'xgb']\nfor m in model_list:\n    result[m] = 0\n    scores[m] = []\n\ni = 1\nfor train_index, valid_index in skf.split(train2, label):\n    X_train, y_train = train2.loc[train_index], label[train_index]\n    X_valid, y_valid = train2.loc[valid_index], label[valid_index]\n    \n    print(f\"\\n skf times # {i}\\n\")\n    for m in model_list:\n        if m == 'cat':\n            score_pred, test_pred = model_catboost(X_train, y_train, X_valid, y_valid, test2)\n        elif m == 'lgb':\n            score_pred, test_pred = model_lgbm(X_train, y_train, X_valid, y_valid, test2)\n        elif m == 'xgb':\n            score_pred, test_pred = model_xgb(X_train, y_train, X_valid, y_valid, test2)\n        scores[m].append(score_pred)\n        result[m] += test_pred\/n_counts \n        print(f\"times # {i} {m} train and inference complete\")\n        \n    i += 1\n    \nprint('\\n####################### DONE ###############################')","bedf9202":"for key, score in scores.items():\n    print(f\"{key} : {np.mean(score)}\")","26038a30":"weights = [0.3, 0.35, 0.35]\nfinal_score = 0\nfor k, w in zip(result.keys(), weights):\n    final_score += result[k] * w\n    print(f\"{k} result : {result[k]}\")\nprint(f\"final_score : {final_score}\")","308d0bd8":"sub['target'] = final_score\nsub.to_csv(\"tabular_sub.csv\", index=0)\nsub","1a3d97bc":"## 3-2. Ensemble","1fc4904a":"## 3-1. StratifyKFold","d95ee9bd":"# 1. Import","13280680":"# 3. Modeling : StratifyKFold and Ensemble","6beeb777":"# 4. Submission","237515f6":"# 2. Preprocessing\n### Score : ROC_CURVE"}}