{"cell_type":{"a605dc25":"code","831b63dc":"code","e0e9e9c0":"code","a4352a36":"code","815170f8":"code","d778d264":"code","92858793":"code","1dd888e3":"code","796fb4bf":"code","7bb176a8":"code","206df575":"code","b0c02cbd":"code","96f8ff52":"code","6b036860":"code","0e094ce6":"code","b216ab67":"code","11a6c5c3":"code","cc4d66ed":"code","1262c44a":"code","5cf7c96c":"code","d1ab428d":"code","9c13b03a":"code","ce612558":"code","eca27f84":"code","539b044f":"code","f5995bab":"code","599c2cd7":"code","90b49a8f":"code","f0a6830b":"code","210fafab":"code","20590294":"code","edb9a547":"code","7a5fa8dd":"code","5d40530e":"code","2ad07cae":"code","fd89fe77":"code","280e59e7":"code","3d03c600":"code","f25a903a":"code","4c5a7d41":"code","e9e0b800":"code","71c79dc1":"markdown","39161507":"markdown","b0db685b":"markdown","75a1fb00":"markdown","ccb171c5":"markdown","4c13ff18":"markdown","e1932168":"markdown","7c78455d":"markdown","02a30020":"markdown","8ec5efd8":"markdown","50fcd241":"markdown","cac6ea60":"markdown"},"source":{"a605dc25":"!pip install textacy\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport os\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nimport string\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom textacy.viz.termite import draw_termite_plot\n# using binary relevance\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.naive_bayes import GaussianNB# initialize binary relevance multi-label classifier\nfrom sklearn.svm import SVC\nimport pickle","831b63dc":"df_train = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv\");","e0e9e9c0":"df_train.head()","a4352a36":"df_train.nunique()","815170f8":"df_train['dataset_title'].unique()","d778d264":"df_train['dataset_label'].unique()","92858793":"df_train[df_train['dataset_title']!=df_train['dataset_label']].loc[:,['pub_title','dataset_title','dataset_label']]","1dd888e3":"def data(filename):\n    df_json = pd.read_json(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train\/\"+str(filename)+\".json\")\n    text = \"\".join(row['text'] for _,row in df_json.iterrows())\n    return text","796fb4bf":"df_train['json_text'] = df_train['Id'].apply(lambda x : data(x))","7bb176a8":"df_train.head()","206df575":"df_train['dataset_title'].value_counts().plot( kind='bar', figsize=(15,10))","b0c02cbd":"df_train['dataset_label'].value_counts().plot( kind='bar', figsize=(20,5))","96f8ff52":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n    ","6b036860":"vectorizer = TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n                    strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n                    ngram_range=(1, 1), use_idf=1,smooth_idf=1,sublinear_tf=1,\n                    stop_words = 'english', preprocessor=clean_text)\nvectorizer.fit(df_train['dataset_title'])","0e094ce6":"def create_tf_matrix(category):\n    return vectorizer.transform(df_train[df_train['dataset_title'] == category].json_text.apply(clean_text))\n\ndef create_term_freq(matrix, cat):\n    category_words = matrix.sum(axis=0)\n    category_words_freq = [(word, category_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n    return pd.DataFrame(list(sorted(category_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms', cat])\n\nfor cat in df_train.dataset_title.unique():\n    print(\"Top 10 terms for: \", cat)\n    df_right = create_term_freq(create_tf_matrix(cat), cat).head(5)\n    print(df_right)\n    print(\"###############\")\n    if cat != 'National Education Longitudinal Study':\n        df_top5_words = df_top5_words.merge(df_right, how='outer')\n    else:\n        df_top5_words = df_right.copy()\n    print(df_top5_words.shape)","b216ab67":"df_top5_words.fillna(0, inplace=True )\ndf_top5_words.set_index('Terms', inplace=True)\ndf_top5_words.shape","11a6c5c3":"df = df_top5_words.copy()\ndf_norm = (df) \/ (df.max() - df.min())","cc4d66ed":"draw_termite_plot(np.array(df_norm.values),df_top5_words.columns,df_top5_words.index, highlight_cols=[0, 4, 12,20,30,36] )","1262c44a":"Y = pd.get_dummies(df_train['dataset_title'])","5cf7c96c":"vectorizer = TfidfVectorizer( min_df =3, max_df=0.2, max_features=10000, \n                    strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n                    ngram_range=(1, 1), use_idf=1,smooth_idf=1,sublinear_tf=1,\n                    stop_words = 'english', preprocessor=clean_text)\nvectorizer.fit(df_train['json_text'])","d1ab428d":"X = vectorizer.transform(df_train.json_text.apply(clean_text))","9c13b03a":"X.shape","ce612558":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)","eca27f84":"\n# with a SVC base classifier\nclassifier = BinaryRelevance(classifier=SVC(), require_dense=[False,True])# train\nclassifier.fit(X_train, y_train)\npredictions = classifier.predict(X_test)\nprint(\"Accuracy = \",accuracy_score(y_test,predictions))\n","539b044f":"Pkl_Filename = \"model.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(classifier, file)","f5995bab":"from sklearn.metrics import multilabel_confusion_matrix","599c2cd7":"multilabel_confusion_matrix(y_test,predictions)","90b49a8f":"df_submission = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\");","f0a6830b":"def datatest(filename):\n    df_json = pd.read_json(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/test\/\"+str(filename)+\".json\")\n    text = \"\".join(row['text'] for _,row in df_json.iterrows())\n    return text","210fafab":"df_submission['json_text'] = df_submission['Id'].apply(lambda x : datatest(x))","20590294":"X_test = vectorizer.transform(df_submission.json_text.apply(clean_text))","edb9a547":"predictions = classifier.predict(X_test)","7a5fa8dd":"print(predictions)","5d40530e":"Pkl_Filename = \"model.pkl\"  \nwith open(Pkl_Filename, 'rb') as file:\n    pickle_model = pickle.load(file)","2ad07cae":"predictions = pickle_model.predict(X_test)","fd89fe77":"df1 = pd.DataFrame(predictions.toarray(),columns=Y.columns)","280e59e7":"def updateSubmission(Id):\n    return df1.loc[:,df1.loc[Id] == 1].columns[0]","3d03c600":"df_submission['PredictionString'] = df_submission.index.map(lambda x: df1.loc[:,df1.loc[x] == 1].columns[0]) ","f25a903a":"df_submission['PredictionString'] = df_submission['PredictionString'].apply(clean_text)","4c5a7d41":"df_submission.drop(columns =['json_text'])","e9e0b800":"df_submission.to_csv('submission.csv', index=False)","71c79dc1":"**Work In progress - please upvote comment if you find anything interesting**","39161507":"# Know your Data","b0db685b":"# Predict Model","75a1fb00":"# Save model","ccb171c5":"# Create Model","4c13ff18":"next from dataset title we need to find matching phrases in the json text to get our final output","e1932168":"# Prepare Dataset","7c78455d":"loading the model from pickle just to avoid re run as working just on below part.","02a30020":"# Bird View of Data","8ec5efd8":"# Loading JSON Files","50fcd241":"**Dataset Label and title which are not unique** ","cac6ea60":"# Analyse Model"}}