{"cell_type":{"608f3f17":"code","1532bb8d":"code","791c21a1":"code","134266af":"code","6ab5fe02":"code","bb7a9994":"code","ba654e74":"code","aaf045f4":"code","554a84e7":"code","95d7f245":"code","477bcaba":"code","8161913d":"code","bd93775c":"code","10163922":"code","52e58eb9":"code","53c4bd7d":"code","b1bf1319":"code","6261b7b6":"code","4e3343f0":"code","cb576642":"code","4bd7f794":"code","0f0eee50":"code","05130dbb":"code","8d940e63":"code","8354e2ea":"code","23041cb3":"code","0df3b0b2":"code","0c8a67a6":"code","47b8e2e4":"code","c3e33f96":"code","5c22ab88":"code","bbebdf04":"code","a5c3fe67":"code","4e18ee64":"code","06a3d903":"code","badb56a4":"code","9356f5f8":"code","154dc1ad":"code","e3704477":"code","df7ac2f9":"code","cb5517a9":"code","e4eefe35":"code","107c4a5c":"code","3b5f6238":"code","dea1cb8b":"code","ce798eef":"code","f25c2b73":"code","b6ea3d9d":"code","3b803ac0":"code","cb62e2ca":"code","a3fe0f53":"code","9ccc348d":"code","52de38d1":"code","ed777fcd":"code","6a92f168":"markdown","f82e0ffb":"markdown","7a57f154":"markdown","019eb7b3":"markdown","404065f2":"markdown","966594bf":"markdown","851f9792":"markdown","74a563ee":"markdown","631bc228":"markdown","d7f731bc":"markdown","423d535f":"markdown","10b32e98":"markdown","4f8184cb":"markdown","2b795bf8":"markdown","7d6f1506":"markdown","b243201e":"markdown","c078f9cf":"markdown","53c7a639":"markdown","ca5d5e13":"markdown","edb54324":"markdown","3a382aef":"markdown","10160a45":"markdown","7fd10642":"markdown","f0b84a43":"markdown","80f87dc0":"markdown","7b36b872":"markdown","af9e38ef":"markdown","380ad392":"markdown","4f56ec71":"markdown","659b3646":"markdown","7ee21878":"markdown","865386fc":"markdown","a5fa7f8f":"markdown","4e6767ee":"markdown","80c60d5a":"markdown","15dcdd67":"markdown"},"source":{"608f3f17":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\nfrom sklearn import set_config\nset_config(display='diagram')\n\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1532bb8d":"# # Import the CSV file as a dataframe:\n\ndf = pd.read_csv('\/kaggle\/input\/san-francisco-airbnb-listings\/listings.csv')","791c21a1":"print('\\nNumber of rows, columns:')\ndf.shape","134266af":"# # first 5 rows of df:\npd.set_option('display.max_columns', None)\ndf.head()","6ab5fe02":"# # Create a new dataframe that omits all the unneeded columns:\n\nmldf = df[['city', 'neighbourhood_cleansed', 'property_type', 'room_type', 'price', 'amenities']].copy(deep=True)","bb7a9994":"# # Show the number of null values in each column:\n\nmldf.isnull().sum()","ba654e74":"# # Drop null values:\nmldf.dropna(inplace = True)","aaf045f4":"# # Check which datatype each column contains:\nmldf.info()","554a84e7":"# # Show summary stats for the dataframe:\nmldf.describe()","95d7f245":"mldf['city'].value_counts()","477bcaba":"# # Check whether the 'San Francisco' class with only 3 records contains a superfluous space ' ':\n\nmldf.loc[mldf['city'].str.contains('San Francisco ')]","8161913d":"# # Correct the 'San Francisco' name variants to read only 'San Francisco':\n\nmldf.loc[mldf['city'] == 'Noe Valley - San Francisco', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == 'San Francisco, Hayes Valley', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == '\u65e7\u91d1\u5c71', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == 'San Francisco ', 'city'] = 'San Francisco'","bd93775c":"# # Confirm the corrections:\n\nmldf['city'].value_counts()","10163922":"# # drop non-SF row indices from dataFrame and confirm their removal:\n\nindex_names = mldf[(mldf['city'] == 'Daly City') | (mldf['city'] == 'San Jose') | (mldf['city'] == 'Brisbane')].index \n\nmldf.drop(index_names, inplace = True)\n\nmldf['city'].value_counts()","52e58eb9":"# # Convert the values in price column to floats:\n\nmldf['price'] = mldf['price'].replace('[\\$,]', '', regex=True).astype(float)","53c4bd7d":"# # Show summary stats for price column:\nmldf['price'].describe()","b1bf1319":"mldf[mldf['price'] < 1]","6261b7b6":"# # Drop the row with price = 0.000, at index 3752, and confirm its removal:\n\nmldf.drop([3752], inplace = True)\nmldf[mldf['price'] <= 1]","4e3343f0":"# # We can now drop the city column from the dataframe:\n\nmldf = mldf[['neighbourhood_cleansed', 'property_type', 'room_type', 'amenities', 'price']]","cb576642":"mldf['room_type'].value_counts(normalize=True)","4bd7f794":"# # Drop 'shared room' and 'hotel room' listings from the data frame:\n\nmldf = mldf[(mldf['room_type'] == 'Entire home\/apt') | (mldf['room_type'] == 'Private room')]\nmldf['room_type'].value_counts(normalize=True)","0f0eee50":"# # Compute the proportion of listings that belong to each property type category:\n\nprint(mldf['property_type'].value_counts(normalize=True))\nprint(mldf['property_type'].describe())","05130dbb":"# # Add a column that shows the proportion of listings represented by each property type:\n\nmldf[\"property_type_freq\"] = 1\nmldf[\"property_type_freq\"] = mldf.groupby('property_type').transform('count').div(len(mldf)).iloc[:, 1]\nmldf.head()","8d940e63":"# # Drop property types with normalized frequencies less than 5% and confirm the change:\n\nmldf = mldf[(mldf['property_type_freq'] >= 0.05)]\n\nprint(mldf['property_type'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['property_type'].describe())","8354e2ea":"# drop property_type_freq from dataframe and confirm its removal:\n\nmldf.drop('property_type_freq', axis=1, inplace=True)\nmldf.dtypes","23041cb3":"# # Compute the normalized frequency of each neighborhood in the dataframe:\n\nprint(mldf['neighbourhood_cleansed'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['neighbourhood_cleansed'].describe())","0df3b0b2":"mldf[\"neigh_freq\"] = 1\nmldf[\"neigh_freq\"] = mldf.groupby('neighbourhood_cleansed').transform('count').div(len(mldf)).iloc[:, 1]\nmldf.head()","0c8a67a6":"mldf = mldf[(mldf['neigh_freq'] >= 0.02)]\n\nprint(mldf['neighbourhood_cleansed'].describe())","47b8e2e4":"# drop neigh_freq from dataframe and confirm its removal:\n\nmldf.drop('neigh_freq', axis=1, inplace=True)\nmldf.dtypes","c3e33f96":"fig = plt.figure(figsize=(11,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(2,1,1)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Entire home prices')\nplt.xticks(rotation=45, size=8, ha='right')\nplt.xlabel(\"\")\n\nplt.subplot(2,1,2)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Private room\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Private room prices')\nplt.xticks(rotation=45, size=8, ha='right')\n\nplt.show()","5c22ab88":"# # Plot the distribution of prices with and without log transformation to examine the skewness:\n\nprice_skew = mldf['price'].skew(axis = 0, skipna = True)\nlogprice_skew = (np.log(mldf.price)).skew(axis = 0, skipna = True)\n\nfig, ax =plt.subplots(1, 2, figsize=(16,4))\nchart1 = sns.distplot(mldf.price, ax=ax[0], color='b')\nchart1.set_xlabel('Price',fontsize=12)\nchart1.annotate(text=f'skew: {price_skew:.2f}', xy=(300, 200), xycoords='axes points')\nchart2 = sns.distplot(np.log(mldf.price), ax=ax[1], color='g')\nchart2.set_xlabel('log Price',fontsize=12)\nchart2.annotate(text=f'log price skew: {logprice_skew:.2f}', xy=(300, 200), xycoords='axes points')\n\nfig.show()","bbebdf04":"# # Display the ranges of the top 2% of price values for each room class:\n\nprint('\\nThe lower intervals show the price range of the top 2% of listings.')\n\nprint('\\nPrivate room:')\nprint(pd.qcut(mldf[mldf[\"room_type\"] == \"Private room\"]['price'], q=[0, .98, 1]).value_counts(normalize=False))\nprint('\\n')\n\nprint('Entire home:')\nprint(pd.qcut(mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['price'], q=[0, .98, 1]).value_counts(normalize=False))","a5c3fe67":"# # Trim away the top 2% of prices to eliminate the high extremes:\n\nmldf = mldf[((mldf['price'] <= 350) & (mldf[\"room_type\"] == \"Private room\")) | ((mldf['price'] <= 1000) & (mldf[\"room_type\"] == \"Entire home\/apt\"))]","4e18ee64":"# # Regenerate the strip plots:\n\nfig = plt.figure(figsize=(11,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(2,1,1)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Entire home prices')\nplt.xticks(rotation=45, size=8, ha='right')\nplt.xlabel(\"\")\n\nplt.subplot(2,1,2)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Private room\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Private room prices')\nplt.xticks(rotation=45, size=8, ha='right')\n\nplt.show()","06a3d903":"price_skew = mldf['price'].skew(axis = 0, skipna = True)\nlogprice_skew = (np.log(mldf.price)).skew(axis = 0, skipna = True)\n\nfig, ax =plt.subplots(1, 2, figsize=(16,4))\nchart1 = sns.distplot(mldf.price, ax=ax[0], color='b')\nchart1.set_xlabel('Price',fontsize=12)\nchart1.annotate(text=f'skew: {price_skew:.2f}', xy=(300, 200), xycoords='axes points')\nchart2 = sns.distplot(np.log(mldf.price), ax=ax[1], color='g')\nchart2.set_xlabel('log Price',fontsize=12)\nchart2.annotate(text=f'log price skew: {logprice_skew:.2f}', xy=(300, 200), xycoords='axes points')\n\nfig.show()","badb56a4":"# # For each room type, generate a dataframe containing median prices for each neighborhood:\ny1 = mldf[mldf[\"room_type\"] == \"Entire home\/apt\"].groupby(['neighbourhood_cleansed']).median(['price'])\ny2 = mldf[mldf[\"room_type\"] == \"Private room\"].groupby(['neighbourhood_cleansed']).median(['price'])\n\n# get the counts as a dataframe\ny_df=pd.concat([y1,y2],axis=1)\ny_df.columns=['Entire Hm','Pvt Rm']\n\ny_df.index.name = 'index'\n\n# # melt the data frame so it has a \"tidy\" data format\ny_df=y_df.reset_index().melt(id_vars=['index'], var_name=\"room_type\",value_name=\"Median Price (US$)\")\ny_df.head()","9356f5f8":"# # Generate the graphs\n\ny_df_rm = y_df[y_df['room_type'] == 'Pvt Rm']\n\nf, ax = plt.subplots(figsize=(12, 3))\nplt.xticks(rotation=50, size=10, ha='right')\n\nplt.bar(height=\"Median Price (US$)\", x=\"index\", data=y_df, label=\"Total\", alpha = 0.5, color=\"darkorange\")\nplt.bar(height=\"Median Price (US$)\", x=\"index\", data=y_df_rm, label=\"Total\", alpha = 0.5, color=\"deepskyblue\")\n\nsns.despine(left=True, bottom=True)\nplt.legend(['Entire Home\/Apt', 'Private Room'], loc=1)\nplt.title(label='Median Listing Price x Neighborhood')\nplt.xlabel(\"Neighborhood\")\nplt.ylabel(\"Median Price in US$\")\nplt.show()","154dc1ad":"# # Log transform the price data to reduce skew:\n\nmldf['price'] = np.log(mldf['price'])","e3704477":"mldf['amenities'] = mldf['amenities'].str.replace(' *', flags=re.I, repl='')","df7ac2f9":"# # Separate features and labels into X and y:\n\nX = mldf.drop('room_type', axis=1)\ny = mldf['room_type']","cb5517a9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","e4eefe35":"categorical_features = ['neighbourhood_cleansed', 'property_type']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('text', TfidfVectorizer(), 'amenities'), \n        ('category', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n remainder='passthrough')","107c4a5c":"tf = TfidfVectorizer(use_idf=True)\npa = mldf['amenities']\ntfidf_matrix = tf.fit_transform(pa)\n\ntfidf_tokens = tf.get_feature_names()\ndf_tfidfvect = pd.DataFrame(data = tfidf_matrix.toarray(),columns = tfidf_tokens)\n\nprint(\"\\nTotal number of rows, columns:\\n\")\nprint(df_tfidfvect.shape)\nprint(\"\\nTfidfVectorizer output - first 8 rows, first 6 columns:\\n\")\nprint(df_tfidfvect.iloc[0:8,0:6])","3b5f6238":"ohe = preprocessing.OneHotEncoder()\n\npt = mldf['property_type']\n\npt = np.array(pt).reshape((len(pt), 1))\n\nohe.fit(pt)\nonehotlabels = ohe.transform(pt).toarray()\n\nprint(f\"\\n Number of rows, columns: {onehotlabels.shape}\")\nprint('\\n Numerical representation of categories in \\'property_type\\': \\n') \nonehotlabels","dea1cb8b":"# # Gradient Boosting Classifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nmodel = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0)\n\npipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)])\n\n\n# # Train the model on training data:\n\npipe.fit(X_train, y_train)","ce798eef":"y_pred = pipe.predict(X_test)\n\nprint('\\nFirst 10 predictions vs first 10 observations - GradientBoostingClassifier:\\n')\n\nPrediction_Vs_Observation = {'pred': y_pred[0:10],\n                            'obs': y_test[0:10]}\n\nPvOdf = pd.DataFrame(Prediction_Vs_Observation).reset_index(drop=True)\ndisplay(PvOdf)","f25c2b73":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","b6ea3d9d":"import scikitplot as skplt\ny_probas=pipe.predict_proba(X_test)\nskplt.metrics.plot_roc(y_test, y_probas, figsize=(10, 8))","3b803ac0":"# # C-Support Vector Classification\n\nfrom sklearn.svm import SVC\n\nmodel = SVC(kernel=\"linear\", C=0.025)\n\npipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=0)\n\npipe.fit(X_train, y_train)","cb62e2ca":"y_pred = pipe.predict(X_test)\n\nprint('\\nFirst 10 predictions vs first 10 observations - SVC:\\n')\n\nPrediction_Vs_Observation = {'pred': y_pred[0:10],\n                            'obs': y_test[0:10]}\n\nPvOdf = pd.DataFrame(Prediction_Vs_Observation).reset_index(drop=True)\ndisplay(PvOdf)","a3fe0f53":"print(classification_report(y_test, y_pred))","9ccc348d":"# # AdaBoostClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nmodel = AdaBoostClassifier()\n\npipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=0)\n\nX_train = X_train\n\npipe.fit(X_train, y_train)","52de38d1":"y_pred = pipe.predict(X_test)\n\nprint('\\nFirst 10 predictions vs first 10 observations - AdaBoostClassifier:\\n')\n\nPrediction_Vs_Observation = {'pred': y_pred[0:10],\n                            'obs': y_test[0:10]}\n\nPvOdf = pd.DataFrame(Prediction_Vs_Observation).reset_index(drop=True)\ndisplay(PvOdf)","ed777fcd":"print(classification_report(y_test, y_pred))","6a92f168":"## 3. ML Classification","f82e0ffb":"#### Next, let's display the OneHotEncoder output for **property_type**:","7a57f154":"#### To understand what the **TfidfVectorizer** does, let's display its output as a standalone item.","019eb7b3":"#### Compare the first 10 predictions the Gradient Boosting Classifier model made to the matching observations from **y_test**","404065f2":"#### We want only listings located in San Francisco. \n\n#### Consolidate the SF name-variant classes into the 'San Francisco' class, and eliminate the non-SF entries:","966594bf":"#### Compare the first 10 predictions the SVC model made to the matching observations from **y_test**","851f9792":"#### There are four room_type classes.\n\n#### Our goal is to predict room type in a binary fashion. \n\n#### To make this a binary prediction task, we will discard the 'shared room' and 'hotel room' records, which together represent less than 6% of the listings.","74a563ee":"#### The min price value is zero. This make no sense.\n#### Check for prices < 1:","631bc228":"#### Compare the first 10 predictions the AdaBoostClassifier made to the matching observations from **y_test**","d7f731bc":"#### There are 8 unique values for ***city***. Let's see what they are.","423d535f":"#### The change leaves us with 4 property types.","10b32e98":"#### We can also consider the *Receiver Operating Characteristic* (ROC) curve.","4f8184cb":"#### With the extreme high prices eliminated, let's graph the median prices by room type and neighborhood.","2b795bf8":"#### The **train_test_split** specifies the percentage of records that will be used to train the model and the percentage that will be set aside as 'test' data.\n\n#### Here, we will reserve 30% of the records as test data (test_size=0.3):","7d6f1506":"#### Finally, we're going to try three classification models and evaluate the performance of each.","b243201e":"#### We could tune the hyperparameters and\/or run other classification models to achieve higher performance scores. \n#### But this notebook is just for demonstration, so we will end the exercise here.\n\n#### Thank you for making it all the way to the end!","c078f9cf":"#### With that done, let's check the proportion of listings that belong to each room type class:","53c7a639":"In each plot, most of the data points are clustered toward the bottom; ***a few extreme values make the overall price range higher than it would otherwise be.*** These rare\/extraordinary prices are of little predictive value and will hinder the performance of our classification model.","ca5d5e13":"#### Each column in the Tfidf matrix corresponds to one of the terms from **amenities**. \n#### Each row corresponds to one of the Airbnb listings.\n#### The numbers represent weightings based on how *rarely* each term occurs (inverse frequency).","edb54324":"**Left panel**: The prices are very positively skewed, with skewness = 12.02. Normally distributed data have skewness = 0.\n\n**Right panel**: Log transformation helps lower the skew value. But it's still considerably greater than 0.","3a382aef":"#### One common approach for eliminating extreme values involves computing the interquartile range. \n\n#### For the sake of simplicity, we're just going to identify the top 2% of price values and eliminate those.","10160a45":"#### As seen above, the change leaves us with 20 neighborhoods.","7fd10642":"## Welcome! This notebook is divided into the following sections:\n\n1. Data importation and cleaning.\n2. Data visualization\/exploratory data analysis.\n3. Binary classification, using different models.\n\n### The goal is to use **mixed data types** (numerical, categorical, text) to train a model that can accurately predict\/classify Airbnb room types.\n\n### This notebook demonstrates how to leverage the advanced preprocessing and transformation capabilities of Scikit-Learn and apply those to heterogeneous data types.","f0b84a43":"The property_type variable specifies 26 unique classes. Most of these are of little business interest or predictive value because they occur so rarely e.g., 'Earth house' and 'Dome house.'\n\nMoreover, all these classes will have to be one-hot encoded for use in our predictive model. One-hot encoding is computationally demanding.\n\nTo simplify our model and improve its predictive utility, we will discard property types with freq < 5%.","80f87dc0":"#### The dataframe contains 106 columns. We're going to drop all but these five:\n* Property type\n* Room type\n* Amenities\n* Neighborhood\n* City","7b36b872":"The data points are now more spread out along the price axis and cover it more evenly.\n\nRe-plot the distributions and re-calculate the skew values:","af9e38ef":"## 2. Data Visualization\n\nGenerate a strip plot representation of the prices for each room type:","380ad392":"#### The OneHot encoder generated a matrix with four columns. Each column corresponds to one of the four **property_type** values.\n#### The location of the '1' in each row signifies the property type associated with that row\/record.","4f56ec71":"#### Display basic dataframe info","659b3646":"#### The predictors must be preprocessed before they can be fed into the ML model:\n* #### The categorical features must be one-hot encoded.\n* #### The amenities text must be vectorized.\n\n#### To accomplish this, we will use two transformers:\n* #### Term-frequency times inverse document-frequency (Tfid) vectorizer\n* #### One-hot encoder\n\n#### The transformers will convert the categorical and text data to **numerical representations** that can be used by the algorithm.","7ee21878":"#### As we would expect, the median listing price for a private room is lower than for an entire home, regardless of neighbhorhood.","865386fc":"### 1. Data Importation and Cleaning","a5fa7f8f":"Eliminating extreme high prices from the data set lowered the skew values considerably. \n\nThe log skew value is below 0.5, so we will apply a log transformation to the prices before running our classification algorithm below.","4e6767ee":"The amenities text must be *tokenized* before being fed into the ML model. Spaces between words might be incorrectly interpreted as token separators by the vectorizer. We must remove these spaces so that groups of words describing individual amenities are counted as single tokens:","80c60d5a":"#### Next, we will evaluate the performance of the classification model.\n#### Some appropriate metrics for this are **precision**, **recall** and **f1-score**.","15dcdd67":"There are 36 unique neighborhoods. This is a categorical variable, so all the values in this column will have to be one-hot encoded for the predictive model. This raises the same issue as was noted for the property type variable. \n\nTo help our model's performance and predictive utility, we will use freq = 2% as a cut-off."}}