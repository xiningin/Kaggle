{"cell_type":{"01a56abb":"code","bc3a4a34":"code","9132dfb5":"code","0d45f7d6":"code","38b9bad5":"code","81d42bc6":"code","8ded8d23":"code","1ff758e9":"code","49637411":"code","1ae07fcd":"code","222805f3":"code","440172b7":"code","5c66af9f":"code","d6dfdc4f":"code","98edcd85":"code","0dc83eb7":"code","b3788829":"code","9df56f72":"markdown"},"source":{"01a56abb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom scipy.sparse import hstack\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss\nfrom tqdm import tqdm_notebook, tqdm\nfrom scipy import stats\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport gc\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bc3a4a34":"def spearman_corr(y_true, y_pred):\n        if np.ndim(y_pred) == 2:\n            corr = np.mean([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])])\n        else:\n            corr = stats.spearmanr(y_true, y_pred)[0]\n        return corr","9132dfb5":"train = pd.read_csv('..\/input\/google-quest-challenge\/train.csv').fillna(' ')\ntest = pd.read_csv('..\/input\/google-quest-challenge\/test.csv').fillna(' ')\ntrain.head()","0d45f7d6":"train.shape","38b9bad5":"test.shape","81d42bc6":"np.unique(train['category'].values)","8ded8d23":"train_text_1 = train['question_body']\ntest_text_1 = test['question_body']\nall_text_1 = pd.concat([train_text_1, test_text_1])\n\ntrain_text_2 = train['answer']\ntest_text_2 = test['answer']\nall_text_2 = pd.concat([train_text_2, test_text_2])\n\ntrain_text_3 = train['question_title']\ntest_text_3 = test['question_title']\nall_text_3 = pd.concat([train_text_3, test_text_3])\n","1ff758e9":"sample_submission = pd.read_csv('..\/input\/google-quest-challenge\/sample_submission.csv').fillna(' ')\nsample_submission.head()","49637411":"class_names = list(sample_submission.columns[1:])\nclass_names","1ae07fcd":"class_names_q = class_names[:21]\nclass_names_a = class_names[21:]\nclass_names_a","222805f3":"class_names_2 = [class_name+'_2' for class_name in class_names]\nfor class_name in class_names:\n    train[class_name+'_2'] = (train[class_name].values >= 0.5)*1","440172b7":"%%time\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 2),\n    max_features=20000)\nword_vectorizer.fit(all_text_1)\ntrain_word_features_1 = word_vectorizer.transform(train_text_1)\ntest_word_features_1 = word_vectorizer.transform(test_text_1)\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 2),\n    max_features=20000)\nword_vectorizer.fit(all_text_2)\ntrain_word_features_2 = word_vectorizer.transform(train_text_2)\ntest_word_features_2 = word_vectorizer.transform(test_text_2)\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 2),\n    max_features=20000)\nword_vectorizer.fit(all_text_3)\ntrain_word_features_3 = word_vectorizer.transform(train_text_3)\ntest_word_features_3 = word_vectorizer.transform(test_text_3)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(1, 4),\n    max_features=50000)\nchar_vectorizer.fit(all_text_1)\ntrain_char_features_1 = char_vectorizer.transform(train_text_1)\ntest_char_features_1 = char_vectorizer.transform(test_text_1)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(1, 4),\n    max_features=50000)\nchar_vectorizer.fit(all_text_2)\ntrain_char_features_2 = char_vectorizer.transform(train_text_2)\ntest_char_features_2 = char_vectorizer.transform(test_text_2)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(1, 4),\n    max_features=50000)\nchar_vectorizer.fit(all_text_3)\ntrain_char_features_3 = char_vectorizer.transform(train_text_3)\ntest_char_features_3 = char_vectorizer.transform(test_text_3)\n\ntrain_features_1 = hstack([train_char_features_1, train_word_features_1, train_char_features_3, train_word_features_3])\ntest_features_1 = hstack([test_char_features_1, test_word_features_1, test_char_features_3, test_word_features_3])\ntrain_features_2 = hstack([train_char_features_2, train_word_features_2])\ntest_features_2 = hstack([test_char_features_2, test_word_features_2])","5c66af9f":"train_features_1= train_features_1.tocsr()\ntrain_features_2= train_features_2.tocsr()","d6dfdc4f":"%%time\nsubmission = pd.DataFrame.from_dict({'qa_id': test['qa_id']})\n\ntrain_preds = []\ntest_preds = []\nscores = []\nspearman_scores = []\n\nfor class_name in tqdm_notebook(class_names_q):\n    print(class_name)\n    Y = train[class_name+'_2']\n    \n    n_splits = 3\n    kf = KFold(n_splits=n_splits, random_state=47)\n\n    train_oof_1 = np.zeros((train_features_1.shape[0], ))\n    test_preds_1 = 0\n    \n    score = 0\n\n    for jj, (train_index, val_index) in enumerate(kf.split(train_features_1)):\n        #print(\"Fitting fold\", jj+1)\n        train_features = train_features_1[train_index]\n        train_target = Y[train_index]\n\n        val_features = train_features_1[val_index]\n        val_target = Y[val_index]\n\n        model = LogisticRegression(C= .3, solver='lbfgs')\n        model.fit(train_features, train_target)\n        val_pred = model.predict_proba(val_features)[:,1]\n        train_oof_1[val_index] = val_pred\n        #print(\"Fold auc:\", roc_auc_score(val_target, val_pred))\n        #spearman_corr\n        #score += roc_auc_score(val_target, val_pred)\/n_splits\n\n        test_preds_1 += model.predict_proba(test_features_1)[:,1]\/n_splits\n        del train_features, train_target, val_features, val_target\n        gc.collect()\n        \n    model = LogisticRegression(C= .3, solver='lbfgs')\n    model.fit(train_features_1, Y)\n    submission[class_name] = model.predict_proba(test_features_1)[:, 1]\n    spearman_score = spearman_corr(train[class_name], train_oof_1)\n    print(\"spearman_corr:\", spearman_score) \n    spearman_scores.append(spearman_score)\n    score = roc_auc_score(Y, train_oof_1)    \n    print(\"auc:\", score, \"\\n\")\n    train_preds.append(train_oof_1)\n    test_preds.append(test_preds_1)\n    scores.append(score)\n    \n    \n","98edcd85":"%%time\n\nfor class_name in tqdm_notebook(class_names_a):\n    print(class_name+'_2')\n    Y = train[class_name+'_2']\n    \n    n_splits = 3\n    kf = KFold(n_splits=n_splits, random_state=47)\n\n    train_oof_2 = np.zeros((train_features_2.shape[0], ))\n    test_preds_2 = 0\n    \n    score = 0\n\n    for jj, (train_index, val_index) in enumerate(kf.split(train_features_1)):\n        #print(\"Fitting fold\", jj+1)\n        train_features = train_features_2[train_index]\n        train_target = Y[train_index]\n\n        val_features = train_features_2[val_index]\n        val_target = Y[val_index]\n\n        model = LogisticRegression(solver='lbfgs')\n        model.fit(train_features, train_target)\n        val_pred = model.predict_proba(val_features)[:,1]\n        train_oof_2[val_index] = val_pred\n        #print(\"Fold auc:\", roc_auc_score(val_target, val_pred))\n        #score += roc_auc_score(val_target, val_pred)\/n_splits\n\n        test_preds_2 += model.predict_proba(test_features_2)[:,1]\/n_splits\n        del train_features, train_target, val_features, val_target\n        gc.collect()\n        \n    model = LogisticRegression(C= .3, solver='lbfgs')\n    model.fit(train_features_2, Y)\n    submission[class_name] = model.predict_proba(test_features_2)[:, 1]\n        \n    score = roc_auc_score(Y, train_oof_2)\n    \n    \n    spearman_score = spearman_corr(train[class_name], train_oof_2)\n    print(\"spearman_corr:\", spearman_score)\n    print(\"auc:\", score, \"\\n\")\n    spearman_scores.append(spearman_score)\n    \n    train_preds.append(train_oof_2)\n    test_preds.append(test_preds_2)\n    scores.append(score)","0dc83eb7":"print(\"Mean auc:\", np.mean(scores))\nprint(\"Mean spearman_scores\", np.mean(spearman_scores))","b3788829":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","9df56f72":"This is a QUEST version of the following Jigsaw Toxic Comments kernel: https:\/\/www.kaggle.com\/tunguz\/logistic-regression-with-words-and-char-n-grams\n\nWhich in turn was forked from the followiong kernel: https:\/\/www.kaggle.com\/thousandvoices\/logistic-regression-with-words-and-char-n-grams"}}