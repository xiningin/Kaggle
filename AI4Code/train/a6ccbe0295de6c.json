{"cell_type":{"618fa4ab":"code","5a60edc1":"code","b2fffbfc":"code","96bd5c46":"code","fae70a27":"code","73977226":"code","ca09a2bb":"code","b6ef691f":"code","1920572f":"code","457187cc":"code","3f1d5d55":"code","69056ed4":"code","35e96556":"markdown"},"source":{"618fa4ab":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.optim as optim\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.preprocessing import StandardScaler  # \ub370\uc774\ud130 \uc815\uaddc\ud654\nimport random\nimport matplotlib.pyplot as plt","5a60edc1":"device = torch.device('cuda') # \ub514\ubc14\uc774\uc2a4 GPU \uc124\uc815\ntorch.manual_seed(777)\nrandom.seed(777)\ntorch.cuda.manual_seed_all(777)\n\nlearning_rate = 1e-4\ntraining_epochs = 1000\nbatch_size = 15\n#drop_prob = 0.3","b2fffbfc":"train = pd.read_csv('train.csv', header=None, skiprows=1)\ntest = pd.read_csv('test.csv', header=None, skiprows=1)","96bd5c46":"train[0] = train[0]%10000\/100\nx_train = train.loc[:,0:9]\ny_train = train.loc[:,[10]]\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\n\nx_train = torch.FloatTensor(x_train).to(device)\ny_train = torch.FloatTensor(y_train).to(device)","fae70a27":"dataset = TensorDataset(x_train, y_train)\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)","73977226":"linear1 = torch.nn.Linear(10,512,bias=True)\nlinear2 = torch.nn.Linear(512,512,bias=True)\nlinear3 = torch.nn.Linear(512,1,bias=True)\nleakyrelu = torch.nn.LeakyReLU()\n\ntorch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)\n\nmodel = torch.nn.Sequential(linear1,leakyrelu,\n                            linear2,leakyrelu,\n                            linear3\n                            ).to(device)","ca09a2bb":"optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\nloss = torch.nn.MSELoss().to(device)\n\nlosses = []\nmodel_history = []\nerr_history = []\n\ntotal_batch = len(data_loader)\n\nfor epoch in range(training_epochs + 1):\n  avg_cost = 0\n  #model.train()\n  \n  for X, Y in data_loader:\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n\n    avg_cost += cost \/ total_batch\n    \n  model_history.append(model)\n  err_history.append(avg_cost)\n  \n  if epoch % 100 == 0:  \n    print('Epoch:', '%d' % (epoch + 1), 'Cost =', '{:.4f}'.format(avg_cost))\n  losses.append(cost.item())\nprint('Learning finished')","b6ef691f":"print(min(err_history))","1920572f":"plt.plot(losses)\nplt.plot(err_history)\nplt.show()","457187cc":"best_model = model_history[np.argmin(err_history)]\nmin(err_history)","3f1d5d55":"test[0] = test[0]%10000\/100\nx_test = test.loc[:,:]\nx_test = np.array(x_test)\nx_test = scaler.transform(x_test)\nx_test = torch.from_numpy(x_test).float().to(device)\n\nwith torch.no_grad():\n    #model.eval()     \n    predict = best_model(x_test)","69056ed4":"submit = pd.read_csv('submit_sample.csv')\nsubmit['Total'] = submit['Total'].astype(float)\nfor i in range(len(predict)):\n  submit['Total'][i] = predict[i]\nsubmit.to_csv('submit.csv', mode = 'w', index = False, header = True)\nsubmit","35e96556":"# \uc774\uc804\uacfc \ubcc0\uacbd\ub41c \uc810\n* \ubc30\uce58 \uc0ac\uc774\uc988 \uc870\uc815\n8 -> 15\n* lr \uc870\uc815 (1e-5 -> 1e-4) xavier \ucd08\uae30\ud654\n(uniform -> normal)\n"}}