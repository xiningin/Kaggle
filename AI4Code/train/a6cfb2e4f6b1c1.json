{"cell_type":{"95ef3a25":"code","e03152f0":"code","377e6919":"code","6caf079e":"code","5c2ab3bc":"code","780044af":"code","50faf112":"code","f0dcefd7":"code","88eee210":"code","c7985953":"code","7ca0616d":"code","dce3addf":"code","1d29515b":"code","e6a9bf4d":"code","b1533c6c":"code","05b65629":"code","977861d1":"markdown","d1d4fa14":"markdown"},"source":{"95ef3a25":"import numpy as np\nimport scipy.stats as ss\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tsfresh as tsf\n\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.feature_selection import mutual_info_classif, f_classif\n\nimport os\nos.listdir('\/kaggle\/input\/lish-moa\/')","e03152f0":"!lscpu | grep -P '^CPU\\(s\\)'","377e6919":"train_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')","6caf079e":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","5c2ab3bc":"def to_str(row):\n    return \"\".join(row[1:].tolist())\n\ndef encode_multilabel(y: pd.DataFrame):\n    return y.astype('str').apply(to_str,1).astype('category').cat.codes\n\ny_enc = encode_multilabel(train_targets_scored)","780044af":"def q_transform(X, q):\n    X_transformed = np.zeros_like(X)\n    for i in range(X.shape[1]):\n        transformer = QuantileTransformer(n_quantiles=q,random_state=0, output_distribution=\"normal\")\n        X_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n    return X_transformed\n\ndef q_transform(X, q, col_idx=[]):\n    \"\"\"\n        col_idx = bool array of size same as columns in X\n    \"\"\"\n    X_transformed = X.copy()\n    \n    if len(col_idx):\n        idx = np.where(col_idx)[0]\n    else:\n        idx = range(X.shape[1])\n        \n    for i in idx:\n        transformer = QuantileTransformer(n_quantiles=q,random_state=0, output_distribution=\"normal\")\n        X_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n    return X_transformed\n\ndef get_mutual_info_classif(X,y,**kwarg):\n    info = mutual_info_classif(X,y,**kwarg)\n#     info = f_classif(X,y,**kwarg)[1] # p-values\n    info[info<0] = 0\n    return info\n\ndef summarize_loss_difference(x):\n    \"\"\"\n    Usage:\n        x = np.array([-1,-2,3,1,2])\n        summarize_loss_difference(x)\n    \"\"\"\n    return {'il_mean' :x.mean(),\n            'il_median' :np.median(x),\n            'il_skew' :np.round(ss.skew(x),4) ,\n            'il_percentage_features':(x>0).mean(), \n            'n_features': len(x),\n            'il_n_features' :(x>0).sum(),\n            'il_quantiles_features':np.quantile(x>0, [0.1,0.2,0.4,0.5,0.6,0.8,0.9]),\n            'il_hist': np.histogram(x, 20),\n           }\n\ndef test_Qs(X, y, qs, skew_thresh=0.8):\n    org_info = get_mutual_info_classif(X, y)\n    skewness = np.abs(ss.skew(X)) > skew_thresh\n    org_info = org_info[skewness]\n    \n    info_losses = []\n    for q in qs:\n        X_transformed = q_transform(X, q, skewness)\n        new_info = get_mutual_info_classif(X_transformed[:,skewness], y)\n        info_loss = org_info - new_info\n        log = {\n                'q':q,\n                'org_info':org_info.mean(),\n                'new_info':new_info.mean(),\n                'info_loss':info_loss.mean(),\n        }\n        print(pd.Series(log))\n        log.update(summarize_loss_difference(info_loss))\n        info_losses.append(log)\n    return info_losses\n","50faf112":"# qs = np.linspace(2200, 4000, 15, dtype=np.int)\nqs = np.logspace(0.5, 4.2, 15, dtype=np.int)\nqs","f0dcefd7":"X = train_features[GENES[:150]].values\n\ninfo_losses = test_Qs(X, y_enc, qs)\n","88eee210":"gene_info_loss = pd.DataFrame(info_losses)\ngene_info_loss.to_pickle('gene_info_loss.pkl')\ngene_info_loss.iloc[:60,:11]","c7985953":"def plot_loss(df):\n    fig, ax = plt.subplots(3,1, figsize=(12,6), sharex=True)\n    ax[0].plot(df['q'], df[['il_mean']], 'o--', label=\"il_mean\")\n    ax[1].plot(df['q'], df['il_skew'], 'o--', label=\"il_skew\");\n    ax[2].plot(df['q'], df['il_percentage_features'], 'o--', label=\"il_percentage_features\");\n    plt.tight_layout()\n    [axi.legend(loc=\"upper left\") for axi in ax]\n    [axi.set_xscale('log') for axi in ax]\n    ax[0].xticks\n    plt.show()\n\nplot_loss(gene_info_loss)","7ca0616d":"X = train_features[CELLS[:]].values\n\ninfo_losses = test_Qs(X, y_enc, qs=qs)\n","dce3addf":"cell_info_loss = pd.DataFrame(info_losses)\ncell_info_loss.to_pickle('cell_info_loss.pkl')\ncell_info_loss.iloc[:60,:11]","1d29515b":"plot_loss(cell_info_loss)","e6a9bf4d":"# dataset_size = 12000\n# nfeatures = 13\n# nclasses = 3\n\n# np.random.seed(1291)\n# X = np.random.random((dataset_size,nfeatures))\n# y = np.random.randint(0,nclasses,(dataset_size,))\n\n# # f_classif(X, y)\n# # mutual_info_classif(X, y)\n\n# X_transformed = np.zeros_like(X)\n# for i in range(X.shape[1]):\n#     transformer = QuantileTransformer(n_quantiles=120,random_state=0, output_distribution=\"normal\")\n#     X_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n\n# # def get_mutual_info_classif(X,y,**kwarg):\n# #     info = mutual_info_classif(X,y,**kwarg)\n# #     info[info<0] = 0\n# #     return info\n\n# org_info = get_mutual_info_classif(X, y)\n# new_info = get_mutual_info_classif(X_transformed, y)\n\n# info_loss = org_info - new_info\n# org_info, new_info, info_loss","b1533c6c":"X = train_features[GENES[:1]].values\n\ni=0\nX_transformed = np.zeros_like(X)\ntransformer = QuantileTransformer(n_quantiles=20,random_state=0, output_distribution=\"normal\")\nX_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n\nplt.plot(X[:,:1], '.', alpha=0.5)\nplt.plot(X_transformed[:,:1], '.', alpha=0.1)\n\nX_transformed[:,:1]","05b65629":"precision = 3\nplt.hist(X_transformed[:,0].round(precision), bins=330)\n# sns.distplot(X_transformed[:,0], bins=2)\nnp.unique(X_transformed[:,:1].round(precision)).shape, X_transformed[:,0].round(precision)","977861d1":"# Check sparsity","d1d4fa14":"# Toy Example"}}