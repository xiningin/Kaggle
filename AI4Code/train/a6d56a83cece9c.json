{"cell_type":{"499c5dfd":"code","3cfa2a88":"code","174b0d0e":"code","a6ce7c57":"code","0a626644":"code","436023a4":"code","275db783":"code","b3b9e2fb":"code","27b2c944":"code","04b78839":"code","0f4d8c13":"code","920d3548":"markdown","f927de5c":"markdown"},"source":{"499c5dfd":"#Load libraries\nimport os\nimport numpy as np\nimport torch\nimport glob\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport pathlib\n\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\n","3cfa2a88":"#Transforms\ntransformer=transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)\/std\n                        [0.5,0.5,0.5])\n])\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","174b0d0e":"#Dataloader\n\n#Path for training and testing directory\ntrain_path='..\/input\/car-damage-detection\/data1a\/training'\ntest_path='..\/input\/car-damage-detection\/data1a\/validation'\n\nbatch_size = 20\n\ntrain_loader=DataLoader(\n    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n    batch_size=batch_size, shuffle=True\n)\ntest_loader=DataLoader(\n    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n    batch_size=batch_size, shuffle=True\n)","a6ce7c57":"root=pathlib.Path(train_path)\nclasses=sorted([j.name.split('\/')[-1] for j in root.iterdir()])\nprint(classes)","0a626644":"\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n    \n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(batch_size):\n    ax = fig.add_subplot(2, batch_size\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(images[idx].permute(1,2,0), cmap='gray')\n    ax.set_title(classes[labels[idx]])","436023a4":"class ConvNet(nn.Module):\n    def __init__(self,num_classes=2):\n        super(ConvNet,self).__init__()\n        \n        #Output size after convolution filter\n        #((w-f+2P)\/s) +1\n        \n        #Input shape= (256,3,150,150)\n        \n        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,12,150,150)\n        self.bn1=nn.BatchNorm2d(num_features=12)\n        #Shape= (256,12,150,150)\n        self.relu1=nn.ReLU()\n        #Shape= (256,12,150,150)\n        \n        self.pool1=nn.MaxPool2d(kernel_size=2)\n        #Reduce the image size be factor 2\n        #Shape= (256,12,75,75)\n        \n        \n        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,20,75,75)\n        self.bn2=nn.BatchNorm2d(num_features=20)\n        #Shape= (256,20,75,75)\n        self.relu2=nn.ReLU()\n        #Shape= (256,20,75,75)\n        \n        self.pool2=nn.MaxPool2d(kernel_size=2)\n        #Reduce the image size be factor 2\n        #Shape= (256,20,37,37)\n        \n        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,32,37,37)\n        self.bn3=nn.BatchNorm2d(num_features=32)\n        #Shape= (256,32,37,37)\n        self.relu3=nn.ReLU()\n        #Shape= (256,32,37,37)\n        \n        self.pool3=nn.MaxPool2d(kernel_size=2)\n        #Reduce the image size be factor 2\n        #Shape= (256,32,18,18)\n        \n        self.fc1=nn.Linear(in_features=37*37 * 20,out_features=2738)\n        self.fc1_drop = nn.Dropout(p=0.4)\n        self.fc2=nn.Linear(2738,out_features=num_classes)\n        \n        \n        \n        #Feed forwad function\n        \n    def forward(self,input):\n        output=self.conv1(input)\n        output=self.bn1(output)\n        output=self.relu1(output)\n            \n        output=self.pool1(output)\n            \n        output=self.conv2(output)\n        output=self.bn2(output)\n        output=self.relu2(output)\n        \n        output=self.pool2(output)\n            \n        #output=self.conv3(output)\n        #output=self.bn3(output)\n        #output=self.relu3(output)\n        \n        #output=self.pool3(output)\n            \n            \n            #Above output will be in matrix form, with shape (256,32,75,75)\n            \n        output=output.view(-1,20*37*37)\n        \n        output= F.relu(self.fc1(output))\n        output = self.fc1_drop(output)\n        output = self.fc2(output)\n            \n        return output\n            ","275db783":"model=ConvNet(num_classes=2).to(device)","b3b9e2fb":"import torch.optim as optim\n\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nloss_function=nn.CrossEntropyLoss()\nnum_epochs=10\ntrain_count=len(glob.glob(train_path+'\/**\/*.JPEG')) + len(glob.glob(train_path+'\/**\/*.jpg')) +  len(glob.glob(train_path+'\/**\/*.jpeg'))\ntest_count=len(glob.glob(test_path+'\/**\/*.jpeg')) + len(glob.glob(test_path+'\/**\/*.JPEG')) + len(glob.glob(test_path+'\/**\/*.jpg'))","27b2c944":"print(train_count,test_count)","04b78839":"best_accuracy=0.0\n\nfor epoch in range(num_epochs):\n    \n    #Evaluation and training on training dataset\n    model.train()\n    train_accuracy=0.0\n    train_loss=0.0\n    \n    for i, (images,labels) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        optimizer.zero_grad()\n        \n        outputs=model(images)\n        loss=loss_function(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        \n        \n        train_loss+= loss.cpu().data*images.size(0)\n        _,prediction=torch.max(outputs.data,1)\n        \n        train_accuracy+=int(torch.sum(prediction==labels.data))\n        \n    train_accuracy=train_accuracy\/train_count\n    train_loss=train_loss\/train_count\n    \n    \n    # Evaluation on testing dataset\n    model.eval()\n    \n    test_accuracy=0.0\n    for i, (images,labels) in enumerate(test_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        outputs=model(images)\n        _,prediction=torch.max(outputs.data,1)\n        test_accuracy+=int(torch.sum(prediction==labels.data))\n    \n    test_accuracy=test_accuracy\/test_count\n    \n    \n    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n    \n    #Save the best model\n    if test_accuracy>best_accuracy:\n        torch.save(model.state_dict(),'best_checkpoint.model')\n        best_accuracy=test_accuracy\n    ","0f4d8c13":"test_loss = torch.zeros(1)\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\n# set the module to evaluation mode\nmodel.eval()\n\nfor batch_i, data in enumerate(test_loader):\n    \n    # get the input images and their corresponding labels\n    inputs, labels = data\n    \n    # forward pass to get outputs\n    outputs = model(inputs)\n\n    # calculate the loss\n    loss = loss_function(outputs, labels)\n            \n    # update average test loss \n    test_loss = test_loss + ((torch.ones(1) \/ (batch_i + 1)) * (loss.data - test_loss))\n    \n    # get the predicted class from the maximum value in the output-list of class scores\n    _, predicted = torch.max(outputs.data, 1)\n    \n    # compare predictions to true label\n    correct = np.squeeze(predicted.eq(labels.data.view_as(predicted)))\n    \n    # calculate test accuracy for *each* object class\n    # we get the scalar value of correct items for a class, by calling `correct[i].item()`\n    for i in range(batch_size):\n        label = labels.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\nprint('Test Loss: {:.6f}\\n'.format(test_loss.numpy()[0]))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\n        \nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","920d3548":"# Damaged Car Classifier\n\nHere I have provided a set of 1840 training data with both damaged and undamaged cars and training a CNN model to classify them","f927de5c":"# Visualize the same of input pictures and their lables"}}