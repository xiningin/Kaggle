{"cell_type":{"d176aff5":"code","32469c10":"code","c5baafe9":"code","0c7d7e26":"code","0f569a84":"code","de51073f":"code","c3f4334b":"code","fe551070":"code","b71cd8b7":"code","5e9ffefa":"code","5d17e7a3":"code","e8ae1261":"code","69c32fe6":"code","e826c9a7":"code","48aee71a":"code","7e47366e":"code","7a745aa3":"code","27584f8c":"code","1317547a":"code","6ae8ce16":"code","080bfe40":"code","1ea3e230":"code","3b81c6f6":"code","0cdd72e4":"code","55b7852b":"code","a5a3efc9":"code","335dde0b":"code","a6ce1113":"code","0a0a58da":"code","159096e0":"code","d29dd86b":"code","3f1da625":"code","773e2821":"code","258d887f":"code","9de10ee2":"code","3e79983f":"code","b0cf3caa":"code","9c8b0c0a":"code","c4a7260f":"code","4cddf53d":"code","5c5f33c4":"code","112a3224":"code","2364012c":"code","688ee0f4":"code","eb58bb2a":"code","683431f3":"code","422e1ad2":"code","a67a883d":"code","969e8efa":"code","f758faa2":"code","a5bceef8":"code","34f8f45c":"code","c4e85ee2":"code","e671a02c":"code","da8cbb65":"code","2bf27024":"code","eb6ad89a":"code","b45c90a2":"code","548f1c5d":"code","217f0690":"code","f0a9a54e":"code","efdecbb9":"code","24a69fed":"code","121e8e83":"code","dacdfacd":"code","4da3b35d":"code","bfa9f8d8":"code","57bb17f4":"code","fe1a6588":"code","6143971a":"code","59f37ddc":"code","41df83ba":"code","641ec3f3":"code","9faa5e83":"code","d2da52ac":"code","07c4c6a6":"code","b7cb4b07":"code","c02949ba":"code","c67fb960":"code","d36dbdf0":"code","80feea7f":"code","c1f5e6bb":"code","ef398201":"code","edb22d2b":"code","8286ae47":"code","5ee12f1c":"code","199a6eca":"code","fdf74739":"code","e83e256f":"code","edb6c3c5":"code","847925a6":"code","59fe364a":"code","c9d06724":"code","c611d698":"code","431f361c":"code","87adaf67":"code","5683f2e3":"code","1ef94a4b":"code","23dd1e3d":"code","ac8f1672":"code","670de8f9":"code","30216ac9":"code","29a14ad3":"code","e67d9cb9":"code","3b53a0da":"code","38661849":"code","c7e123f3":"code","728b3787":"code","8123d759":"code","ea5ce45b":"code","a561736d":"code","c6485a5a":"code","25f8d7e0":"code","46f52c7a":"code","c52e2dc4":"code","bff7bb49":"code","1cba21b4":"code","62eceffc":"code","d7edee74":"code","2711db15":"code","cc04f4ee":"code","417b15b3":"code","55ff9625":"code","a5d09f8f":"code","036143f7":"code","b5ecaba8":"code","faa368a6":"code","a04f228a":"code","10a3bf38":"code","d2cf0e21":"code","96e8f1f0":"code","da70a2be":"code","b3544c7c":"code","f3b64a28":"code","589a0171":"code","30c7dbfe":"code","e6a04aec":"code","9a2e16c1":"code","316dcfd4":"code","02d338cd":"code","ef801899":"code","f8f09a46":"code","55c1170e":"code","7d5df21a":"code","72b77701":"code","c42fcc10":"code","305fa4ee":"code","38fba365":"code","018993a4":"code","c8ae9373":"code","a82ce466":"code","27c14892":"code","6fd61217":"code","aa6aaa4e":"code","d37f1de9":"code","630aec22":"code","550c263a":"code","66dc6490":"code","b61097fa":"code","c6b8e839":"code","d9bbc3d6":"code","2942ec0b":"code","c2131d3c":"code","fb7d1d2a":"code","4fa9bd5c":"code","a3372fe6":"code","01467f74":"code","fc66e5c7":"code","c3c508b2":"code","f0e1bdf1":"code","f60b8f81":"code","c2023e74":"code","8bc12ce1":"code","7aec129a":"code","2a027077":"code","4966e3d0":"code","b04df4f8":"code","6d1a94b2":"code","37794cfd":"code","170f089c":"code","12854b14":"code","afcb7f32":"code","fa60673d":"markdown","6ca64aa0":"markdown","e5a7185e":"markdown","da590cc2":"markdown","5496f1d5":"markdown","0411994b":"markdown","ec91e50e":"markdown","beb30690":"markdown","cd4ac655":"markdown","02638b1e":"markdown","f9150db3":"markdown","e3670202":"markdown","3c3fc02e":"markdown","452acd92":"markdown","5a92ac1a":"markdown","7e873157":"markdown","537757d3":"markdown","836bf620":"markdown","a021b6d0":"markdown","a091adca":"markdown","f1043103":"markdown","07cf9f52":"markdown","58d28218":"markdown","69c21662":"markdown","21d20a06":"markdown","dc9f4607":"markdown","99d6e0d6":"markdown","2d140e91":"markdown","c5b86c64":"markdown","2d83b72e":"markdown","9fea4891":"markdown","fa319a63":"markdown","28c5815e":"markdown","31162098":"markdown","49f2831f":"markdown","bf0957f1":"markdown","5b61b293":"markdown","72cea8c2":"markdown","82b431ad":"markdown","10d6d642":"markdown","249578f8":"markdown","64fe1e87":"markdown","07ad820f":"markdown","6606a754":"markdown","0fcab8f0":"markdown","874ed8ac":"markdown","5701931a":"markdown","4a619ecb":"markdown","e4a71093":"markdown","d90b454d":"markdown","977bcf9d":"markdown","b40e75b9":"markdown","ec77ef4d":"markdown","12b50013":"markdown","17b7f31f":"markdown","ae113ba1":"markdown","b8b460c5":"markdown","53277493":"markdown","8a44af3c":"markdown","629aec54":"markdown","81e15843":"markdown","4f0a895a":"markdown","e58c6d30":"markdown","8c02b0b7":"markdown","dea06f25":"markdown","f862fa29":"markdown","520428f4":"markdown","423db593":"markdown","7bda0f1a":"markdown","9e7b4ae6":"markdown","f47e9470":"markdown","0bb1bf4d":"markdown","84d993c2":"markdown","95a71035":"markdown","62391a3a":"markdown","4eb6209d":"markdown","dee41471":"markdown","325e6553":"markdown","13ed9ad6":"markdown","9ff7ee9e":"markdown","49d5f6b2":"markdown","3171227a":"markdown","f1a7fe73":"markdown","3237aa35":"markdown","edf8b4ca":"markdown","c4647748":"markdown","b9ae63ae":"markdown","5eb73656":"markdown","19d6a852":"markdown","70a4d4af":"markdown","2605c85c":"markdown","3790f9d0":"markdown","8c7838af":"markdown","9eb1c12f":"markdown","f4b7eabe":"markdown","4645ee4c":"markdown","cb689e2b":"markdown","160a6d42":"markdown","93d1474e":"markdown","54709461":"markdown","a47d7b0c":"markdown","99be6ed4":"markdown","df8939a6":"markdown","952e6590":"markdown","57b33e69":"markdown","2bfb40be":"markdown","688ff2fc":"markdown","415d7813":"markdown","42ffc6ef":"markdown","013a074f":"markdown","88073a5b":"markdown","a140f643":"markdown","649e2ebe":"markdown","aeac562e":"markdown","dd66f4b8":"markdown","1324f64e":"markdown","7de3fd93":"markdown","b5afe419":"markdown","4beb20f6":"markdown","4b0c2062":"markdown","145cb4d3":"markdown","0b7f3cfa":"markdown","9b4d9fbc":"markdown","957a5c7a":"markdown","516500e5":"markdown","4a05d6b6":"markdown","4f66848a":"markdown","074c1321":"markdown","0ff101b5":"markdown","28aadf1a":"markdown","d732a2af":"markdown","2e41a011":"markdown","0acb8cb5":"markdown","0346b468":"markdown","af9ae5e2":"markdown","cfc9e6c0":"markdown","6b7a7c55":"markdown","23cdda2c":"markdown","7195478c":"markdown","9dd3c491":"markdown","97c8b8ad":"markdown","fdd760e9":"markdown"},"source":{"d176aff5":"# linear algebra\nimport numpy as np\n\n#data processing\nimport pandas as pd\n\n#for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns","32469c10":"df = pd.read_excel(\"..\/input\/superstore-sales-data\/SampleSuperstore .xls\")","c5baafe9":"df.head()","0c7d7e26":"df.describe()","0f569a84":"df.info()","de51073f":"len(df.columns)","c3f4334b":"df.isnull().sum()","fe551070":"df.dtypes","b71cd8b7":"df.columns","5e9ffefa":"df['Order ID'].isnull().sum()","5d17e7a3":"df['Order ID'].unique()","e8ae1261":"df['Order ID'].dtype","69c32fe6":"n = df[\"Order ID\"].isnull().sum() # No of null values in the ORDER ID column\n\nind = df['Order ID'][df['Order ID'].isnull()].index # Index of nullvalues in the Order ID column\n\n# We will loop through the rows that have null values and one by one fill na with a random integer ranging from 1 to 60,000.\n# But at the same time we will make sure that the value that we fill is not already present in the Order ID column\n\na=0\n\nwhile (a != (n)):\n    j =np.random.randint(1, high=60000)\n    \n    if j not in df['Order ID']:\n        df['Order ID'][ind[a]]= j\n        a+=1\n","e826c9a7":"s = df['Order ID'][df['Order ID'].isnull()].index","48aee71a":"df['Order ID'].fillna(0, inplace=True)","7e47366e":"df['Order ID'][s]","7a745aa3":"df['Order ID'].isnull().sum()","27584f8c":"df[df['Order Date'].isnull()]","1317547a":"df['Order Date'].unique().tolist()","6ae8ce16":"df['Order Date']= pd.to_datetime(df['Order Date'], errors='coerce')","080bfe40":"date_null = df['Order Date'][df['Order Date'].isnull()] \ndate_null","1ea3e230":"mode_dat = df['Order Date'].mode().values[0] #finding the mode and selecting the first repeated value\n","3b81c6f6":"df['Order Date'].fillna(mode_dat, inplace=True) #filling date time NaT values with the first most repeated and saving it in the column","0cdd72e4":"#for invoice in df['Order ID'][df['Order Date'].isnull()]:\n    #   print(invoice)\n    #   date = df['Order Date'][df['Order ID']==invoice].mode()\n    #  print(date)","55b7852b":"df['Order Date'].isnull().sum()","a5a3efc9":"df['Order Date'].dtype","335dde0b":"df.isnull().sum()","a6ce1113":"df['Order Priority'].value_counts()","0a0a58da":"df['Order Priority'].isnull().sum()","159096e0":"df['Order Priority'].dtypes     #checking the dtype","d29dd86b":"#Using loop to identify the row with integer\/incorrect value and replacing it with NaN","3f1da625":"ind=0\n\nfor row in df['Order Priority']:\n    try:\n        int(row)\n        df.loc[ind, 'Order Priority']=np.nan   #df['Order ID'].values[ind]\n        \n    except:\n        pass\n    ind+=1\n    ","773e2821":"df['Order Priority'].value_counts()   #incorrect Value removed","258d887f":"df.isnull().sum() #Order Priority will now have 13 null values","9de10ee2":"mode_priority = df['Order Priority'].mode().values[0] #Since mode o\/ps series which cannot be used to fillna, \n                                                      #we need a single value for the purpose therefore filling selecting \n                                                      #the value at 0th index.","3e79983f":"df['Order Priority'].fillna(mode_priority, inplace=True)","b0cf3caa":"df.isnull().sum()","9c8b0c0a":"df['Order Quantity'].value_counts()","c4a7260f":"df['Order Quantity'].isnull().sum()","4cddf53d":"df['Order Quantity'].dtypes","5c5f33c4":"#The Order Quantity column has some incorrect values and a single null value. Converting it into numeric will automatically convert \n#non numeric values to NA","112a3224":"df['Order Quantity'] = pd.to_numeric(df[\"Order Quantity\"], errors='coerce')\n","2364012c":"df['Order Quantity'].unique()","688ee0f4":"df['Order Quantity'].isnull().sum() #Earlier there was only one NA,now 7","eb58bb2a":"df.isnull().sum()","683431f3":"df['Order Quantity'].dtype","422e1ad2":"df['Order Quantity'].fillna(df['Order Quantity'].mean(), inplace=True)","a67a883d":"df['Order Quantity'].isnull().sum()","969e8efa":"df.Sales.unique()","f758faa2":"df.Sales.value_counts()","a5bceef8":"df.Sales.isnull().sum()","34f8f45c":"df.Sales.dtype","c4e85ee2":"# We have 19 null values and some incorrect values as well. Converting the sales column to numeric type will make the incorrect values as NA","e671a02c":"df.Sales = pd.to_numeric(df.Sales, errors='coerce')","da8cbb65":"df.Sales.dtype","2bf27024":"df.isnull().sum()","eb6ad89a":"df['Product Sub-Category'][df.Sales.isnull()] # Checking for Product Sub Categories where Sales has NA Value","b45c90a2":"\nfor cats in df['Product Sub-Category'][df.Sales.isnull()]:\n    \n    x =df.Sales[df['Product Sub-Category']==cats].mean() #Taking the Mean of sales against sub categories\n    \n    #print(x, cats)\n\n    df.Sales =np.where(df['Product Sub-Category']==cats, df.Sales.fillna(x), df.Sales)\n\nprint(df.Sales)\n\n","548f1c5d":"df.isnull().sum()\n    ","217f0690":"df.Sales.isnull().sum()","f0a9a54e":"df.Discount.unique()","efdecbb9":"df.Discount.value_counts()","24a69fed":"df.Discount.isnull().sum()","121e8e83":"df['Ship Mode'].value_counts()","dacdfacd":"df['Ship Mode'].isnull().sum()","4da3b35d":"mode_ship = df['Ship Mode'].mode().values[0]","bfa9f8d8":"df['Ship Mode'].fillna(mode_ship, inplace=True)","57bb17f4":"df['Ship Mode'].isnull().sum()","fe1a6588":"df.Profit.unique()","6143971a":"df.Profit.isnull().sum()","59f37ddc":"df.Profit.dtype","41df83ba":"#There is one incorrect value in the column. Conversion of the column to numeric will automatically make that incorrect value as NA","641ec3f3":"df.Profit =  pd.to_numeric(df.Profit, errors='coerce')","9faa5e83":"df.Profit[df.Profit.isnull()]","d2da52ac":"df[df.Profit.isnull()]","07c4c6a6":"    x= df.Profit[(df['Product Sub-Category']=='Storage & Organization') & (df['Customer Segment']=='Corporate')].mean()\n    \n    df.Profit.fillna(x, inplace=True)","b7cb4b07":"df.Profit.isnull().sum()","c02949ba":"df.Profit.value_counts().index","c67fb960":"df['Unit Price'].dtype","d36dbdf0":"df['Unit Price'].unique()","80feea7f":"df['Unit Price'].isnull().sum()","c1f5e6bb":"#Niether incorrect nor blank values is the Unit price column","ef398201":"df['Shipping Cost'].dtype","edb22d2b":"df['Shipping Cost'].unique()","8286ae47":"df['Shipping Cost'].isnull().sum()","5ee12f1c":"#One incorrect value in the Shipping Cost Column\n\ndf['Shipping Cost'] = pd.to_numeric(df['Shipping Cost'], errors='coerce')","199a6eca":"df['Shipping Cost'].isnull().sum()","fdf74739":"df[df['Shipping Cost'].isnull()]","e83e256f":"mean_shipping =  df['Shipping Cost'][(df['Region']=='Nunavut') & (df['Product Container']=='Wrap Bag')].mean()\nmean_shipping","edb6c3c5":"df['Shipping Cost'].fillna(mean_shipping, inplace = True)","847925a6":"df['Shipping Cost'].isnull().sum()","59fe364a":"df['Customer Name'].unique()","c9d06724":"df['Customer Name'].dtype","c611d698":"ind=0  \n\nfor row in df['Customer Name']:\n    try:\n        int(row)\n        df.loc[ind,'Customer Name']=np.nan\n    except ValueError:                         #for exception handling we use try and except\n        pass\n    \n    ind+=1\n    ","431f361c":"df['Customer Name'].isnull().sum()","87adaf67":"#reg = df.Region[df['Customer Name'].isnull()]\n\nfor region in df.Region[df['Customer Name'].isnull()]:\n    \n    x = df['Customer Name'][df.Region==region].mode().values[0]\n    \n    df['Customer Name'] = np.where(df.Region==region, df['Customer Name'].fillna(x), df['Customer Name'])\n    \ndf['Customer Name']","5683f2e3":"df['Customer Name'].isnull().sum()","1ef94a4b":"df.Province.isnull().sum()","23dd1e3d":"df.Province.unique()","ac8f1672":"df.Region.isnull().sum()","670de8f9":"df.Region.unique()","30216ac9":"Customer = df['Customer Name'][df.Region.isnull()]\n","29a14ad3":"for customer in Customer:\n    \n    region_of_customer = df.Region[df['Customer Name']==customer].mode().values[0]\n    #print(customer)\n    #print(region_of_customer)\n    \n    df.Region =np.where(df['Customer Name']==customer, df.Region.fillna(region_of_customer), df.Region)\n\ndf.Region.isnull().sum()\n","e67d9cb9":"df['Customer Segment'].unique()","3b53a0da":"df['Customer Segment'].isnull().sum()","38661849":"df['Product Category'].unique()","c7e123f3":"df['Product Category'].isnull().sum()","728b3787":"for segment in df['Customer Segment'][df['Product Category'].isnull()]:\n    \n    mode_prod =  df['Product Category'][df['Customer Segment']==segment].mode().values[0]\n    \n\n  \n    df['Product Category'] = np.where(df['Customer Segment']==segment, df['Product Category'].fillna(mode_prod), df['Product Category'])\n\n    ","8123d759":"df['Product Category'].isnull().sum()","ea5ce45b":"df['Product Sub-Category'].unique()","a561736d":"df['Product Sub-Category'].isnull().sum()","c6485a5a":"df['Product Name'].unique()","25f8d7e0":"df['Product Name'].isnull().sum()","46f52c7a":"for x in df['Customer Segment'][df['Product Name'].isnull()]:\n    \n    col = df[['Customer Segment','Product Sub-Category']][df['Product Name'].isnull()]\n    \n    mode_prod = df['Product Name'][df['Customer Segment']==x].mode().values[0]\n    \n    df['Product Name'] = np.where(df['Customer Segment']==x, df['Product Name'].fillna(mode_prod), df['Product Name'])\n    \n    print(mode_prod)\n#df['Product Name'].isnull().sum()\n","c52e2dc4":"df['Product Name'].isnull().sum()","bff7bb49":"df['Product Container'].unique()","1cba21b4":"df['Product Container'].isnull().sum()","62eceffc":"for container in df['Product Name'][df['Product Container'].isnull()]:\n    \n    mode_container =  df['Product Container'][df['Product Name']==container].mode().values[0]\n    \n    df['Product Container'] = np.where(df['Product Name']==container, df['Product Container'].fillna(mode_container), df['Product Container'])\n    \n","d7edee74":"df['Product Container'].isnull().sum()","2711db15":"df['Product Container'][7058] # Checking Xeros 190 usually sold in small box. o\/p should also be small box","cc04f4ee":"# As we can see the blank vlue is filled with small box, thats what we wanted","417b15b3":"df['Ship Date'].unique()","55ff9625":"df['Ship Date'].isnull().sum()","a5d09f8f":"df['Ship Date'] = pd.to_datetime(df['Ship Date'], errors='coerce')","036143f7":"mode_shipdate = df['Order Date'].mode().values[0] #finding the mode and selecting the first repeated value\n\ndf['Ship Date'].fillna(mode_shipdate, inplace=True)","b5ecaba8":"df['Ship Date'].isnull().sum()","faa368a6":"df['Ship Date'].dtype","a04f228a":"diff = df['Ship Date']-df['Order Date'] #checking if shipe date is earleier then order date which would be incorrect\ndiff","10a3bf38":"#Cheking if any shipping date is set earlier than its order date. If its truE then setting the shipping date with +1 day after its order","d2cf0e21":"df['Ship Date'][df['Ship Date']<df['Order Date']] = df['Order Date'][df['Ship Date']<df['Order Date']]+pd.Timedelta('1 day')","96e8f1f0":"df['Ship Date'][df['Ship Date']>=df['Order Date']].value_counts().sum()","da70a2be":"df['Ship Date'].isnull().sum()","b3544c7c":"# Just to see the condition of outliers in the data lets plot some columns using box plot\n\nplt.figure(figsize=(15,5))\nplt.subplot(1,4,1)\nsns.boxplot(df['Order ID'])\nplt.xlabel('Order', fontweight='bold')\n\nplt.subplot(1,4,2)\nsns.boxplot(df['Sales'])\nplt.xlabel('Sales', fontweight='bold')\n\nplt.subplot(1,4,3)\nsns.boxplot(df['Profit'])\nplt.xlabel('Profit', fontweight='bold')\n\nplt.subplot(1,4,4)\nsns.boxplot(df['Shipping Cost'])\nplt.xlabel('Shipping Cost', fontweight='bold')","f3b64a28":"#Defining a function to detect and remove all rows with the outliers and returning a data frame on which we can perform the analysis\n\ndef remove_outliers(df):\n    outliers={}\n    for col in df.columns:\n        if (str(df[col].dtype) != 'object') & (str(df[col].dtype) != 'datetime64[ns]') :\n            df = df[np.abs(df[col]-df[col].mean()) < (3*df[col].std())]\n            olrs = df[~(np.abs(df[col]-df[col].mean()) < (3*df[col].std()))]\n            outliers = pd.DataFrame(olrs)\n    #sns.boxplot(df.Profit)\n    \n    #print(df.info())\n    return df\n","589a0171":"data = remove_outliers(df) # Saving the dataframe free of outliers in a variable 'data'\ndata.info()","30c7dbfe":"plt.figure(figsize=(15,5))\nplt.subplot(1,4,1)\nsns.boxplot(data['Order ID'])\nplt.xlabel('Order')\n\nplt.subplot(1,4,2)\nsns.boxplot(data['Sales'])\nplt.xlabel('Sales')\n\nplt.subplot(1,4,3)\nsns.boxplot(data['Profit'])\nplt.xlabel('Profit')\n\nplt.subplot(1,4,4)\nsns.boxplot(data['Shipping Cost'])\nplt.xlabel('Shipping Cost')","e6a04aec":"\ndef categorical_plots(var, data):\n    \n    \n    #Adjustment of plots, bigger size and space b\/w subplots\n    \n    fig = plt.figure(figsize=(15,5))\n    fig.subplots_adjust(wspace=0.7)\n    \n    #1st Plot:  Bar plot     \n        \n    plt.subplot(1,3,1)\n    sns.countplot(x=var, data= data)\n    plt.xticks(rotation = 45, horizontalalignment='right')\n    plt.xlabel(var.name + ' Distribution')\n\n    #2nd Plot: PIE Chart\n    \n    labels =var.value_counts().index  #Labels that will be written against slices in pie charts\n    \n    #For the slice with highest value to be exploded, explode parameter is passed. Using for loop to make a tuple of \n    # number of slice using len(unique) and exploding the first slice by mentioning 0.1 at first index. Atlast converted list to tuple\n    \n    a=[0.1]\n    for i in range ((len(var.unique()))-1):\n        a.append(0)\n\n    explode1= tuple(a)\n    #if var.name != 'Customer Name':\n    ax1 = plt.subplot(1,3,2)\n    ax1.pie(var.value_counts(), labels=labels,autopct='%1.1f%%', shadow=True,explode= explode1 )\n    ax1.axis('equal')\n    plt.xlabel(var.name + ' Distribution')\n    \n    #3rd Plot: Line Plot\n    \n    plt.subplot(1,3,3)\n    var.value_counts().sort_index().plot.line()\n    plt.xticks(rotation = 45, horizontalalignment='right')\n    plt.xlabel(var.name + ' Distribution')\n    \n    show=plt.show()\n    \n    return(show)\n","9a2e16c1":"# This function is for categorical plots that have too many values\n\n\ndef categorical_plots2(var, data):\n    \n    #Adjustment of plots, bigger size and space b\/w subplots\n    \n    fig = plt.figure(figsize=(15,5))\n        \n    #1st Plot: PIE Chart\n    \n    labels =var.index  #Labels that will be written against slices in pie charts\n    \n    #For the slice with highest value to be exploded, explode parameter is passed. Using for loop to make a tuple of \n    # number of slice using len(unique) and exploding the first slice by mentioning 0.1 at first index. Atlast converted list to tuple\n    \n    a=[0.1]\n    for i in range ((len(var.unique()))-1):\n        a.append(0)\n\n    explode1= tuple(a)\n    #if var.name != 'Customer Name':\n    ax1 = plt.subplot()\n    ax1.pie(var, labels=labels,autopct='%1.1f%%', shadow=True)\n    ax1.axis('equal')\n    plt.xlabel(var.name + ' Distribution')\n    \n    \n    show=plt.show()\n    \n    return(show)\n","316dcfd4":"#FOR NUMERICL PLOTS WE WILL BE USING THE FOLLOWING FUNCTION\n\ndef numerical_plots(var):\n    \n    #Adjustment of plots, bigger size and space b\/w subplots\n    \n    fig = plt.figure(figsize=(15,4))\n    fig.subplots_adjust(wspace=0.3)\n    \n    #1st Plot:  Histogram with KDE plot          \n \n    plt.subplot(1,3,1)\n    sns.distplot(var, color='b')\n    plt.xlabel(var.name + ' Distribution')\n\n    \n    #2nd Plot:  Box plot\n    \n    plt.subplot(1,3,2)\n    sns.boxplot(y=var)\n    plt.xlabel(var.name + ' Distribution')\n\n\n    #3rd Plot:  Histogram without plot     \n\n    plt.subplot(1,3,3)\n    sns.distplot(var, color='b', kde=False)\n    plt.xlabel(var.name + ' Distribution')\n    \n    #plt.subplot(1,3,3)\n    #sns.kdeplot(var, color='b')\n    #plt.xlabel(var.name + ' Distribution')\n    \n    show=plt.show()\n    \n    return(show)\n","02d338cd":"plt.figure(figsize=(8,8))\n\nplt.plot_date(df['Order Date'], df['Order Date'].index)","ef801899":"categorical_plots(df['Order Priority'], df)","f8f09a46":"numerical_plots(df['Order Quantity'])","55c1170e":"numerical_plots(df.Sales)","7d5df21a":"categorical_plots(df.Discount,df)","72b77701":"numerical_plots(df.Discount)","c42fcc10":"categorical_plots(df['Ship Mode'],df)","305fa4ee":"numerical_plots(df.Profit)","38fba365":"numerical_plots(df['Unit Price'])","018993a4":"numerical_plots(df['Shipping Cost'])","c8ae9373":"categorical_plots2(df['Customer Name'].value_counts().head(10),df)","a82ce466":"categorical_plots(df.Province, df)","27c14892":"categorical_plots(df.Region,df)","6fd61217":"categorical_plots(df['Customer Segment'],df)","aa6aaa4e":"categorical_plots(df['Product Category'],df)","d37f1de9":"categorical_plots(df['Product Sub-Category'],df)","630aec22":"categorical_plots2(df['Product Name'].value_counts().head(10),df)","550c263a":"categorical_plots(df['Product Container'],df)","66dc6490":"plt.figure(figsize=(8,5))\n\nplt.plot_date(df['Ship Date'], df['Ship Date'].index)","b61097fa":"fig=plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.6)\n\n\nplt.subplot(1,2,1)\ndf['Customer Name'].value_counts().head().plot.bar()\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.xlabel('Frequent Ordering Customers', fontweight='bold')\nplt.ylabel('No. of times Ordered')\n\n\nplt.subplot(1,2,2)\ntop10profit =df.groupby(['Customer Name'])['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head()\nsns.barplot(x='Customer Name', y='Order Quantity', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.xlabel('Highest Order Quantity Placed',fontweight='bold')\n\n\nplt.show()","c6b8e839":"#plt.figure(figsize=(8,5))\n\nfig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n    \n#1st Plot:  Top 5 Customers by profit     \n        \nplt.subplot(1,2,1)\ntop10profit =df.groupby(['Customer Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head()\nsns.barplot(x='Customer Name', y='Profit', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n#2nd Plot:  Top 5 Customers by Loss    \n\nplt.subplot(1,2,2)\ntop10loss =df.groupby(['Customer Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit').head()\nsns.barplot(x='Customer Name', y='Profit', data=top10loss)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Loss')\n\n\nplt.show()","d9bbc3d6":"#plt.figure(figsize=(8,5))\n\nfig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n    \n#1st Plot:  Top 5 Customers by profit     \n        \nplt.subplot(1,2,1)\ntop10profit =df.groupby(['Customer Name','Province'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head()\nsns.barplot(x='Customer Name', y='Profit',hue='Province', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n#2nd Plot:  Top 5 Customers by Loss    \n\nplt.subplot(1,2,2)\ntop10loss =df.groupby(['Customer Name','Province'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit').head()\nsns.barplot(x='Customer Name', y='Profit', hue='Province', data=top10loss)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Loss')\n\n\nplt.show()\n","2942ec0b":"fig=plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.6)\n\nplt.subplot(1,4,1)\ndf['Customer Name'].value_counts().head().plot.bar()\nplt.xlabel('Frequent Ordering Customers', fontweight='bold')\nplt.xticks(rotation=45, horizontalalignment= 'right')\nplt.ylabel('No. of times Ordered')\n\n\nplt.subplot(1,4,2)\ntop10profit =df.groupby(['Customer Name'])['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head()\nsns.barplot(x='Customer Name', y='Order Quantity', data=top10profit)\nplt.xticks(rotation=45, horizontalalignment= 'right')\nplt.xlabel('Highest Order Quantity Placed',fontweight='bold')\n\nplt.subplot(1,4,3)\ntop10profit =df.groupby(['Customer Name'])['Sales'].aggregate(np.sum).reset_index().sort_values('Sales',ascending=False).head()\nsns.barplot(x='Customer Name', y='Sales', data=top10profit)\nplt.xticks(rotation=45, horizontalalignment= 'right')\nplt.xlabel('Highest Sales',fontweight='bold')\n\nplt.subplot(1,4,4)\ntop10profit =df.groupby(['Customer Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head()\nsns.barplot(x='Customer Name', y='Profit', data=top10profit)\nplt.xticks(rotation=45, horizontalalignment= 'right')\nplt.xlabel('Highest Profit',fontweight='bold')\n\nplt.show()","c2131d3c":"def customer_analysis(x):\n    d = []\n    d.append(x['Order ID'].count())\n    d.append(x['Sales'].sum())\n    d.append(x['Profit'].sum())\n    d.append(pd.to_datetime(x['Order Date']).min())\n    d.append(pd.to_datetime(x['Order Date']).max())\n    d.append(x['Product Name'].unique())\n    d.append(x['Province'].unique())\n    return pd.Series(d, index=['#Purchases','Total Sales','Total Profit','First_Purchase_Date','Latest_Purchase_Date','Products Purchased','Location_Count'])\n\n","fb7d1d2a":"df_customers= df.groupby('Customer Name').apply(customer_analysis)","4fa9bd5c":"best_customer = df_customers.loc[['Emily Phan','Deborah Brumfield','Grant Carroll','Darren Budd','Ed Braxton']]\nbest_customer","a3372fe6":"Loss_giving_customers = df_customers.loc[['Julia West', 'Dave Kipp', 'Laurel Workman', 'Adrian Barton', 'Lauren Leatherbury']]\nLoss_giving_customers ","01467f74":"df.groupby(['Order Date','Customer Name']).sum().reset_index().sort_values('Order Date').head()","fc66e5c7":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n\n#1st Plot:  Top 5 Products by Sales:\n\nplt.subplot(1,2,2)\ntop10profit =df.groupby(['Product Name'])['Sales'].aggregate(np.sum).reset_index().sort_values('Sales',ascending=False).head()\nsns.barplot(x='Product Name', y='Sales',data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n#2nd plot: Top 5 Products by Order Quantity:\n\nplt.subplot(1,2,1)\ntop10loss =df.groupby(['Product Name'])['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head()\nsns.barplot(x='Product Name', y='Order Quantity', data=top10loss)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Order Quantity')\n\nplt.show()","c3c508b2":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n\n#1st Plot:  Top 5 Products by Profit:\n\nplt.subplot(1,2,1)\ntop10profit =df.groupby(['Product Category','Product Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head()\nsns.barplot(x='Product Name', y='Profit',hue='Product Category',data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n#2nd plot: Top 5 Products by Loss:\n\nplt.subplot(1,2,2)\ntop10loss =df.groupby(['Product Category','Product Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit').head()\nsns.barplot(x='Product Name', y='Profit',hue='Product Category', data=top10loss)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Loss')\n\nplt.show()","f0e1bdf1":"#plt.figure(figsize=(8,5))\n\nfig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n    \n#1st Plot:  Top 5 Products by profit     \n        \nplt.subplot(1,2,1)\ntop10profit =df.groupby(['Province','Product Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head(10)\nsns.barplot(x='Product Name', y='Profit',hue='Province', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n#2nd Plot:  Top 5 Products by Loss    \n\nplt.subplot(1,2,2)\ntop10loss =df.groupby(['Province','Product Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit').head(10)\nsns.barplot(x='Product Name', y='Profit', hue='Province', data=top10loss)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Loss')\n\n\nplt.show()\n","f60b8f81":"fig = plt.figure(figsize=(10,5))\n\n\nplt.subplot()\nworst_product = df.groupby([\"Province\",\"Product Name\"])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending = False)\nworst_prod = worst_product[worst_product['Product Name'] == \"Polycom ViewStation\u2122 ISDN Videoconferencing Unit\"].sort_values('Profit',ascending = False).head(20)\nsns.barplot(x = \"Product Name\", hue=\"Province\",y= \"Profit\",  data=worst_prod)\nplt.ylabel('Profit \/ Loss')\n\nplt.show()\n\n","c2023e74":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n\n#1st Plot: best product\n\nplt.subplot(1,2,1)\ntop_product = df.groupby([\"Province\",\"Product Name\"])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending = False)\ntop_prod = top_product[top_product['Product Name'] == \"Global Troy\u2122 Executive Leather Low-Back Tilter\"].sort_values('Profit',ascending = False).head(20)\nsns.barplot(x = \"Product Name\", hue=\"Province\",y= \"Profit\",  data=top_prod)\n\n#2nd plot :worst Product:\n\nplt.subplot(1,2,2)\nworst_product = df.groupby([\"Province\",\"Product Name\"])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending = False)\nworst_prod = worst_product[worst_product['Product Name'] == \"Okidata Pacemark 4410N Wide Format Dot Matrix Printer\"].sort_values('Profit',ascending = False).head(20)\nsns.barplot(x = \"Product Name\", hue=\"Province\",y= \"Profit\",  data=worst_prod)\nplt.ylabel('Profit \/ Loss')\n\nplt.show()\n\n","8bc12ce1":"fig=plt.figure(figsize=(20,5))\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(1,4,1)\ndf['Product Name'].value_counts().head().plot.bar()\nplt.title('Frequently Ordered Products', fontweight='bold')\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('No. of times Ordered')\n\n\nplt.subplot(1,4,2)\ntop10profit =df.groupby(['Product Name'])['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head()\nsns.barplot(x='Product Name', y='Order Quantity', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.title('Highest Order Quantity Placed',fontweight='bold')\n\nplt.subplot(1,4,3)\ntop10profit =df.groupby(['Product Name'])['Sales'].aggregate(np.sum).reset_index().sort_values('Sales',ascending=False).head()\nsns.barplot(x='Product Name', y='Sales', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.title('Highest Sales',fontweight='bold')\n\nplt.subplot(1,4,4)\ntop10profit =df.groupby(['Product Name'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head()\nsns.barplot(x='Product Name', y='Profit', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.title('Highest Profit',fontweight='bold')\n\nplt.show()","7aec129a":"def product_analysis(x):\n    d = []\n    d.append(x['Order ID'].count())\n    d.append(x['Order Quantity'].sum())\n    d.append(x['Profit'].sum())\n    d.append(pd.to_datetime(x['Order Date']).min())\n    d.append(pd.to_datetime(x['Order Date']).max())\n    d.append(x['Product Name'].unique())\n    d.append(x['Province'].unique())\n    return pd.Series(d, index=['#Purchases','Total Orders','Total Profit','First_Purchase_Date','Latest_Purchase_Date','Products Purchased','Location_Count'])\n\ndf_products= df.groupby('Product Name').apply(product_analysis)","2a027077":"df_products.loc[['Global Troy\u2122 Executive Leather Low-Back Tilter','Hewlett Packard LaserJet 3310 Copier','80 Minute CD-R Spindle, 100\/Pack - Staples','Polycom ViewStation\u2122 ISDN Videoconferencing Unit','Okidata Pacemark 4410N Wide Format Dot Matrix Printer']]","4966e3d0":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n\n#1st Plot:  Top 5 Province by Sales:\n\nplt.subplot(1,2,2)\ntop10profit =df.groupby(['Province'])['Sales'].aggregate(np.sum).reset_index().sort_values('Sales',ascending=False).head(20)\nsns.barplot(x='Province', y='Sales',data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n#2nd plot: Top 5 Province by Order Quantity:\n\nplt.subplot(1,2,1)\ntop10loss =df.groupby(['Province'])['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head(20)\nsns.barplot(x='Province', y='Order Quantity', data=top10loss)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Order Quantity')\n\nplt.show()","b04df4f8":"fig=plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.6)\n\n\nplt.subplot(1,2,1)\ndf['Province'].value_counts().head(20).plot.bar()\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.xlabel('Province')\nplt.ylabel('Frequency')\n\nplt.subplot(1,2,2)\ntop10profit =df.groupby('Province')['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head(20)\nsns.barplot(x='Province', y='Profit', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Profit', fontweight='bold')\n\n\nplt.show()","6d1a94b2":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n\nplt.subplot(1,2,1)\nsale_ontario = df.groupby([\"Province\",\"Product Category\",\"Product Name\"])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending = False)\ns_ontario = sale_ontario[sale_ontario['Province'] == \"Ontario\"].sort_values('Profit',ascending = False).head()\nsns.barplot( x=\"Product Name\", y= \"Profit\", hue=\"Product Category\",data=s_ontario)\nplt.xticks(rotation=60, horizontalalignment='right')\n\n\nplt.subplot(1,2,2)\nloss_ontario = df.groupby([\"Province\",\"Product Category\",\"Product Name\"])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending = True)\nl_ontario = loss_ontario[loss_ontario['Province'] == \"Ontario\"].sort_values('Profit',ascending = True).head()\nsns.barplot(hue = \"Product Category\", x=\"Product Name\", y= \"Profit\", data=l_ontario)\nplt.xticks(rotation=60, horizontalalignment='right')\nplt.ylabel('Loss')\n\nplt.show()","37794cfd":"#plt.subplot(1,2,2)\ntop10profit =df.groupby('Region')['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head(20)\nsns.barplot(x='Region', y='Profit', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.ylabel('Profit', fontweight='bold')\nplt.show()","170f089c":"fig=plt.figure(figsize=(20,5))\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(1,4,1)\ndf['Province'].value_counts().head().plot.bar()\nplt.title('Frequently Ordered', fontweight='bold')\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.xlabel('Province')\nplt.ylabel('No. of times Ordered')\n\n\nplt.subplot(1,4,2)\ntop10profit =df.groupby(['Province'])['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head()\nsns.barplot(x='Province', y='Order Quantity', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.title('Highest Order Quantity Placed',fontweight='bold')\n\nplt.subplot(1,4,3)\ntop10profit =df.groupby(['Province'])['Sales'].aggregate(np.sum).reset_index().sort_values('Sales',ascending=False).head()\nsns.barplot(x='Province', y='Sales', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.title('Highest Sales',fontweight='bold')\n\nplt.subplot(1,4,4)\ntop10profit =df.groupby(['Province'])['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head()\nsns.barplot(x='Province', y='Profit', data=top10profit)\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.title('Highest Profit',fontweight='bold')\n\nplt.show()","12854b14":"fig=plt.figure(figsize=(20,5))\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(1,3,1)\ndf['Product Sub-Category'].value_counts().head().plot.bar()\nplt.title('Frequently Ordered', fontweight='bold')\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.xlabel('Province')\nplt.ylabel('No. of times Ordered')\n\nplt.subplot(1,3,2)\nprofit_delivery =df.groupby('Product Sub-Category')['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head(10)\nsns.barplot(x='Product Sub-Category', y='Order Quantity', data=profit_delivery)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n\nplt.subplot(1,3,3)\nprofit_delivery =df.groupby('Product Sub-Category')['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head(10)\nsns.barplot(x='Product Sub-Category', y='Profit', data=profit_delivery)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\nplt.show()","afcb7f32":"fig=plt.figure(figsize=(20,5))\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(1,3,1)\ndf['Ship Mode'].value_counts().head().plot.bar()\n#plt.title('Frequently Ordered', fontweight='bold')\nplt.xticks(rotation=60, horizontalalignment= 'right')\nplt.xlabel('Province')\nplt.ylabel('No. of times Ordered')\n\nplt.subplot(1,3,2)\nprofit_delivery =df.groupby('Ship Mode')['Order Quantity'].aggregate(np.sum).reset_index().sort_values('Order Quantity',ascending=False).head(10)\nsns.barplot(x='Ship Mode', y='Order Quantity', data=profit_delivery)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\n\nplt.subplot(1,3,3)\nprofit_delivery =df.groupby('Ship Mode')['Profit'].aggregate(np.sum).reset_index().sort_values('Profit',ascending=False).head(10)\nsns.barplot(x='Ship Mode', y='Profit', data=profit_delivery)\nplt.xticks(rotation=60, horizontalalignment= 'right')\n\nplt.show()","fa60673d":"<b> Julia West who has only ten purchases damaged the most in terms of loss. Lauren Leatherbuy also damaged a great deal interms of loss despite buying 24 times from the company<\/b>","6ca64aa0":"  \n  \n  \n  \n  .\n  .","e5a7185e":"###### FILL NA: There are some customers in all regions who are regular buyers. Therefore we will check the region where there is an NA value and then check which customer has been the a regular buyer in that region. And we fill the NA value with that customer name","da590cc2":"### <u>Sales Distribution<\/u>","5496f1d5":"### Profit: Finding incorrect values, converting to NA and filling NA\n","0411994b":"<b>As can be seen from all the three plots, Corporate Sector is our largest Customer Segment that has been buying products from our store <\/b>","ec91e50e":"<b>To Visualize this lets draw another chart only for \"Polycom ViewStation\u2122 ISDN Videoconferencing Unit\" product.<\/b>","beb30690":"### Unit Price: Finding incorrect values, converting to NA and filling NA\n","cd4ac655":"<b><\/b>","02638b1e":"<b> Emily Phan purcahsed items only ten times but gave the highest profits. Interestingly Darren Budd who is the most frequent buyer and has the highest purchases did'nt benefit the company in terms of profit as did Emily Phan and others. <\/b>","f9150db3":"We can plot discount using both categorical as well as numerical type plots of our functions","e3670202":"<b> The visualizations shows top 5 most frequent buying customers and the top 5 customers who have placed the highest number of orders. The most frequent buying customers have also placed the highest order quanitites at our store with Darren Budd at top of the list.\n\nLets see the top customers from whom the company\/store benefitted in terms of profits<\/b>","3c3fc02e":"# <center><u> 4. Bi\\Multivariate Analysis<\/u><\/center>","452acd92":"## Loading the Data","5a92ac1a":"# <CENTER><u>SALES DATA ANALYSIS<\/u><\/CENTER>","7e873157":"<b> 75% of the Shipping cost were less than 20 and 25% of the shipping cost were greater than 20. <\/b>","537757d3":"### <u>The Oldest Customer <\/u>","836bf620":"### Ship Mode: Finding incorrect values, converting to NA and filling NA\n","a021b6d0":"### Sales: Finding incorrect values, converting to NA and filling NA\n","a091adca":"Niether null nor incorrect values in the Product Sub-Category column","f1043103":"<b>\n\nLets define three functions that make different types of plots; Two functions for Categorical variable that will make Bar plots, pie chars and line charts all showing distribution of each attribute\/column.\n\nOne function for Numerical Variables that will make KDE, Box plot and Histogram.\n\n<\/b>","07cf9f52":"###### Converting the Order Date Column to date time. This will automatically convert the values to NaT which are not in date format","58d28218":"Shipping cost will depend on the region to be shipped and ofcourse the weight because the packaging depends on the size and weight.\n\nSince we have Product container column that describes the type of packaging, we will be filling the NA value by calculating the\nmean of shipping cost when the parcel was shipped to Nunavut region in Wrap Bag","69c21662":"### <u>Province Distribution<\/u>","21d20a06":"###### The Order Quantity column can be filled with the mean value, therefore using mean\n","dc9f4607":"<b> 0.01 Discounts given to the customers was around 9.6 % and is the highest number of discounts. From the count plot we can see that 0.01 discount was offered 800 times and similarly we can also see for other discounts as well \/b>","99d6e0d6":"<b> Both the plots shows top 5 customers with highest profits and loss at Provincial Level.\n    \nThe first plot shows customers whose purchasing gave largest profits where as the second plot shows customers whose purchasing caused the highest losses AT PROVINCIAL LEVEL.\n\nEmily Phan is again on top of the list in terms of profits to the company. Although he\/she may have purcahsed and ordered for different provinces but his\/her purchasing benefitted the company the greatest when the order was for New Brunswick Province. \n\nOn the other hand we can see the customers whose purchasing gave highest losses at provinical level. Julia west and Laurel Workman who gave the largest losses at country level, also caused losses at provinical level. We can dig deep to understand the possibe reasons later . \n\nOne more interesting thing is that majority of the customers who gave losses are from Alberta<\/b>","2d140e91":"###### Since there are repeated dates for Orders, we can also Fill Date Time values with the most repeated ones","c5b86c64":"<b> Lets also Analyze the Most Profitable and most Loss Giving Product <\/b>","2d83b72e":"### <u> Top 5 Customers at Province Level with greatest Profits\/ Loss:<\/u>","9fea4891":"<b>The graph shows the most frequent buying customers with Darren Budd on top of the list whose orders account for 17.2% of the total orders. <\/b>","fa319a63":"<b> Purchase of products from people of Ontario has given the largest profits to the store <\/b>","28c5815e":"<b>The graphs depict that the Paper subcategroy has been the best seller that accouns for 14.6% of our total Sales<\/b>","31162098":"We can clearly see that Product Category column has 31 null values and no incorrect value","49f2831f":"<b> The graphs show that Regular Air type delivery has been the best in all aspects. <\/b>","bf0957f1":"<b>Lets analyze the type of delivery services that gave the highest profits<\/b>","5b61b293":"### Shipping Cost: Finding incorrect values, converting to NA and filling NA\n","72cea8c2":"### Product Sub-Category: Finding incorrect values, converting to NA and filling NA\n","82b431ad":"<b>Now lets plot the 4 subplots again and observe the visualizations after removal of outliers<\/b>","10d6d642":"<b> We can see the best profits were given by Global Troy Executive Leather in the Onatario province. The visualization also shows that altough Polycom View satation gave very good profit in the New Brunswick Province but the overall profit was the largest in Ontario. <\/b>","249578f8":"### <u> Top 5 Customers at Country Level from whom the Store got the Highest Profits \/ Loss: <u>","64fe1e87":"i=0\nx=[]\nfor cols in df.columns:\n    print(\"\\033[1m\", cols,'\\n \\033[0m', df[cols].value_counts())\n    sns.boxplot(df[cols].value_counts(), data=df)\n    plt.show()\n","07ad820f":"## <center><u> Customer Level Analysis <\/u><\/center>","6606a754":"<b>The graphs show that the orders are for the Ontario province account for 21.7% of the total orders which are the largest. Second most in the list is British Columbia that has the highest number of orders <\/b>","0fcab8f0":"### Discount: Finding incorrect values, converting to NA and filling NA\n","874ed8ac":"To fill na values, we will check the product that was sold and will check against that product name the type of conatainer in which it was sold","5701931a":"<b>From the visualizations above, we can clearly see that data has too many outliers. Before analyzing further lets see what happens after getting rid of the outliers. <b>","4a619ecb":"### <u>Order Quantity Distribution<\/u>","e4a71093":"<b>The above three plots show the distribution of each value\/item in terms of  Order Priority.\n\nWe can clearly see from pie chart that 21.2% orders were of High priority. \nCount plot and line plot also depict that order with high priority were the greatest.<\/b>\n\n","d90b454d":"###### No incorrect values in the column. Just Filling NA values in ship mode with the most repeated value","977bcf9d":"### Order Date: Finding NA & incorrect values, and after correction filling the NA:","b40e75b9":"<b> Most of the products had unit prices ranging from 0 to 1000, but at the same time there were many that had higher unit prices even greter than 6000 <\/b>","ec77ef4d":"<b> The above visualization depicts that Global Troy Executive Leather product overall gave the largest profits. It also shows the largest loss incurred was on the sales of Okidata Pacemark 4410 Dot MatriX Printer. \n    \n   The largest Profit was given by the item that is a part of Furniture category and largest loss by the sale of item belongs to the office supplies category <\/b><\/b>","12b50013":"### Order Quantity: Finding incorrect values, converting to NA and filling NA","17b7f31f":"<center> <b>-------------------------------- End of Data Quality Assessment  --------------------------------------<b><\/center>","ae113ba1":"### <u>Product Name Distribution<\/u>","b8b460c5":"## <center><u>Product Level Analysis:<\/u><\/center>","53277493":"<b><\/b>\n","8a44af3c":"<b> From the visualization above we can see that quanity of each order placed ranges from 1 to 50 (KDE). The box plot is depecting that 75% of the data has an order quantity of 38 or less. Andthe histrogram is depicting the freguency ofof each order quantity. The shape of hisogram depcits a comb type distribution  <\/b>","629aec54":"<b> The graphs depict a very interesting sales, Polycom ViewStation\u2122 ISDN Videoconferencing Unit gave the highest profit province wise and the same product gave the biggest loss as well. Which shows that if this product is not sold in Alberta, the company will be in less loss. And the greater the sales of this product in New Burnwick the greater will be the profit for that province to the company<\/b>","81e15843":"Niether incorrect nor null values in the Customer Segment Column","4f0a895a":"### <u>Product Sub Category Distribution<\/u>","e58c6d30":"### Product Category: Finding incorrect values, converting to NA and filling NA","8c02b0b7":"<b> Lets Further analyze 5 customers 'Emily, Deborah, Grant, Darren and Ed Braxton'. Lets see their purchases and purchase history<\/b>","dea06f25":"# <center><u> 3. UNIVARIATE ANALYSIS <\/u><\/center>","f862fa29":"<b><\/b>","520428f4":".","423db593":"### <u>Order Priority Distribution<\/u>","7bda0f1a":"<b> We can see that why is Global Troy the most profitable. Which ever Province it has been sold, it gave profits. And interestingly it has been sold in 8 provinces. \n    On the other hand the Okidata Pacemark Printer has only been sold in three provinces and all in losses.\n    \n   <\/b>","9e7b4ae6":"<b> The analysis has been performed at three different levels:\n    1. Customer Level\n    2. Product Level\n    3. Province Level.\n    \n   All the three levels are mainly analyzed considering the Sales and Profit that each gave. Every orgaznization will want it's Sales and Proft to rise. We will be analyzing which customers, what products and provinces, delivery types brought the largest sales and profits. <\/b>","f47e9470":"###### The ideal value for Na in region column can be selected using the customer name. The idea is to check the customer against each blank value in the region column. Then check the region where that customer's orders are usually shipped. After finding out the region of the customer we will fill values accordingly","0bb1bf4d":"<b> The graph shows that the store\/company had orders mainly in the year range from 2009 to 2013. We can also see an order placed in the year 2022.<\/b>","84d993c2":"### <u> Ship Date Distribution <\/u>","95a71035":"### <u>Discount Distribution<\/u>","62391a3a":"<b> Lets further analyze the products. Selecting two from the highest giving profit, one from the most frquently bought and two from the greates loss giving<\/b>1","4eb6209d":"### Product Name: Finding incorrect values, converting to NA and filling NA\n","dee41471":"<b> Ontario Province has the highest distribution of data and gave the best profits.\n    \n   British Columbia has greater distrbution than Saskachewan but not high interms of Profit. The comparision of distrbution and profits by province is pretty clear in the graphs.\n   \n   For Ontario, we can imagine there will be a lot of products sold in the province. To find out the products that gave the best profit or the greatest loss in that province lets dig the data a little more <\/b>","325e6553":"<b> Pretty clear from the plots that The largest number of orders\/sales has been of prodcuts that our categorized as Office Supplies<\/b>","13ed9ad6":"### <u>Top 5 Products by Profit \/ Loss (at Country Level):<\/u>","9ff7ee9e":"### Product Container: Finding incorrect values, converting to NA and filling NA\n","49d5f6b2":"<center><b> ***************** End of UniVariate Analysis **********************<\/b><\/center>","3171227a":"The Region column only has null values, no incorrect values found in the column","f1a7fe73":"### <u> Province with Highest Profit <\/u>","3237aa35":"###### The Order Priority column (nominal) can be filled with the most repeated value, therefore using mode","edf8b4ca":"<b> 80 Minute CD-R was the best selling product country wise but was unable to give the largest gain.\n    \n   Global Troy Leather has a decent purchase frequency and has benefitted the company the greatest in terms of profits.\n   \n   Okidata Pacemark Dot Matrix that has been purchased only 6 times has given the greatest of loss. As been depicted previously it has been sold in only three regions and has given no profits at all\n   \n   <\/b>\n","c4647748":"## <u> Distribution of every Feature \/ Attribute \/ Column :<\/u>","b9ae63ae":"## <center><u> Top Product Category by Profits <\/u><\/center>","5eb73656":"<b>The graphs show that most of the orders were from the Western Region(23.7%) and the least from Nunavut region (0.9%)<\/b>","19d6a852":"### <u>Shipping Cost Distribution<\/u>","70a4d4af":"### <u> Frequent Buyers \/ Highest Order Quantity \/ Greatest Sales \/ Highest Profits <\/u>","2605c85c":"From the data we know there are sub categories of products. And every sub category has different sales values\nWe are Selecting every sub category and taking its mean value that will be filled in Sales column\n\nFor e.g a sales value is blank where Envelopes were sold. Now we will take the mean of Sales values where envelope was sold\nand fill NA with that mean\n\nFor this to achieve we will be using a for loop","3790f9d0":"<b> The oldest customers are Jessica and Matt who placed their orders on 1st Jan 2009<\/b>","8c7838af":"### <u>Customer Name Distribution<\/u>","9eb1c12f":"### <u>Customer Segment Distribution<\/u>","f4b7eabe":"<b>Around 4500 (51.8 %) products sold were packaged in small boxes which has been our mostly used packaging for the orders<\/b>","4645ee4c":"### <u>Product Category Distribution<\/u>","cb689e2b":"<b> We can see that Ontario stands out among all, the most frequent orders, highest orders, highest sales value and the highest profits.\n    Saskachewan that doesent have as many orders as British Columbia had, but it still benefitted the company more as compared to British Columbia <\/b>","160a6d42":"### <u> Region Wise Profit<\/u>","93d1474e":"###### For NA values, we will check for each customer segment what is the product that they often buy and fillna accordingly","54709461":"The notebook comprises of three main parts:\n \n   <u>1.  Data Quality Assessment\/ Processing<\/u>: Missing \/incorrect value analysis and filling using MCT.\n   \n   <u>2. Univariate Analysis<\/u>: Analyzing the distribution of all attributes using graphs\/charts.\n   \n   <u>3. Bi\/Multivarite Analysis<\/u>: Customer , Product and Provincial Level Anyalysis interms of Profits.\n \nThe notebook is concluded with the findings of the analysis. ","a47d7b0c":"<center><b> The data provided is regarding the sales of items from a store or a company located in Canada.<\/b><\/center>","99be6ed4":"### Customer Name: Finding incorrect values, converting to NA and filling NA\n","df8939a6":"<b> The Graphs depict that the sales value mainly ranges from 1 to 20,000 for all the orders placed. We do had some orders for which sales value were greater than 80,000 as well <\/b>","952e6590":"### <u>Profit Distribution<\/u>","57b33e69":"### <u> Top 5 Customers that order frequentlyand have Highest Order Quantity <\/u>","2bfb40be":"<b> We now know the best customer at the country level .Lets check who were the customers that gave the largest Profits and Loss at Province level.<\/b>","688ff2fc":"<b> The above visualizations shows that Emily Phan gave the highest profits to the store when analyzing at country level. We can see top 5 customers whose purchasing gave the highest profits to the store\/company. On the other hand we can also see the top 5 customers whose purchasing gave us the highest loss. Julia West among these customers was on top of the list <\/b>","415d7813":"## <center><u> Profit by Delivery <\/u><\/center>","42ffc6ef":"### <u> Order Date Distribution<\/u>","013a074f":"### <u>Order ID: Finding NA & incorrect values, and after correction filling the NA:<\/u>","88073a5b":"A great number of rows have been removed that were identified as outliers","a140f643":"No null or incorrect values in the Province Column","649e2ebe":"# <center> 2. BASIC DATA QUALITY ASSESSMENT <\/center>","aeac562e":"<b>80 Minute CD-R is the best selling product from our store which accounts fo 12.6% of the total sales<\/b>","dd66f4b8":"### Region: Finding incorrect values, converting to NA and filling NA","1324f64e":"<b> We can clearly see the greatest number of orders were placed for Ontario Province <\/b>","7de3fd93":"### <u>Top 5 Products that are Frequently Ordered and have the Highest Sales (at Country Level):<\/u>","b5afe419":"<b>The products shipped to our customers were mainly in the years from 2009 to 2013. However one product was also shipped in the year 2023<\/b>","4beb20f6":"### <u> Most Frequent \/ Largest Orders <\/u> ","4b0c2062":"### Province: Finding incorrect values, converting to NA and filling NA\n","145cb4d3":"# <u>Results:<\/u>","0b7f3cfa":"### <u>Unit Price Distribution<\/u>","9b4d9fbc":"### <u> Frequent Buyers \/ Highest Order Quantity \/ Greatest Sales \/ Highest Profits <\/u>","957a5c7a":"<b><\/b>","516500e5":"### <u>Ship Mode Distribution<\/u>","4a05d6b6":"<b><u>1.\tCustomer Level Analysis<\/u><\/b>\n\nAt Country Level:\n\n       \u2022   Darren Budd has been the most frequent buyer with total 59 purchases but interestingly has not been the one who\u2019s  purchase gave the largest profits.\n       \u2022\tEmily Phan with total of only 10 purchases from our store was the best customer in terms of giving Profit.\n       \u2022\tJulia West who has only 10 purchases damaged the most in terms of loss. Lauren Leatherbuy also damaged a great deal in terms of loss despite buying 24 times from our company\/store.\n\n\n<b><u>Oldest Customer:<\/u><\/b>\n    \n    \u2022\tJessica Myrick and Matt Collister have been our oldest customers who purchased for the first time on 1st Jan 2009.\n\n\n\n<u><b>2.\tProduct Level Analysis<\/b><\/u>\n\n    \u2022\t80 Minute CD-R is the best selling products and was purchased 28 times from our store with a total quantity sold equaling 706. But, wasn\u2019t the one giving the highest profits.\n   \n    \u2022\tGlobal Troy Executive Leather, purchased 17 times (550 Orders) gave the highest profits. \n   \n    \u2022\tOkidata Dot matrix printer, purchased only 6 times gave the highest loss (43,949)\n   \n    \u2022\tPolycom viewstation was among the top products that gave losses. Interestingly it gave loss only in Alberta, if not sold in Alberta there will be no loss on sale of this product.\n\n\n<b><u>3.\tProvince Level Analysis<\/u><\/b>\n   \n    \u2022\tMajority of the orders were from the Ontario province and has given the store the highest profit.\n   \n    \u2022\tGlobal Troy Executive Leather was the best profitable product for the province.\n    \n    \u2022\tEpson DFX printer was the worst product in terms of profits. It gave the highest loss for sale in this province.\n\n\n<b><u>4.\tProduct Sub Category Analysis:<\/u><\/b>\n    \n    \u2022\tPaper categories were the most frequently bought, but it was the Telephones and communications category that gave the largest profits.\n\n\n<u><b>5.\tDelivery Type:<\/b><\/u>\n    \n    \u2022\tRegular Air type delivery was the most used and was the one with highest profits.\n","4f66848a":"### Customer Segment: Finding incorrect values, converting to NA and filling NA","074c1321":"<b> We can see clearly see from the above visualizations that the most frequently bought products have had the highest orders placed at our store but interestingly their purchasing has not given the highest profits.\n    \nPolycom Viewstation is among the highest in terms of sales nut not in terms of profits.\n\n\nGlobal Troy Executive Leather, HP Laserjet and Canon PC 940 are the best products in terms of Sales and Profits.\n    \n<\/b>","0ff101b5":"###### We can clearly see from above that Order priority column has one incorrect value and 12 NaN values.","28aadf1a":"### <u> Top 5 Product by Profit\/Loss (At Provincial Level):<\/u>","d732a2af":"### <u>Region Distribution<\/u>","2e41a011":"##  <center><u> Province Wise Analysis <\/u><\/center>","0acb8cb5":"### <u>Product Container Distribution<\/u>","0346b468":"### Ship Date: Finding incorrect values, converting to NA and filling NA\n","af9ae5e2":"### Order Priority: Finding incorrect values, converting to NA and filling NA","cfc9e6c0":"<b>The graphs show that most of the orders placed wer delivered using Regular Air, followed by Delivery Truck and then Express Air which was used the least among three types<\/b>","6b7a7c55":"## Importing the Libraries","23cdda2c":"<b> The Graphs show that the store had profits as well as losses on the sale of products. Mainly the profits from the product was around 0 to 5000 and loss around 3000. but we can also observe that there were some products that gave lager than 5000 profits and some products that gave greater than 5000 losses<\/b>","7195478c":"### <u> Frequent Buyers \/ Highest Order Quantity \/ Greatest Sales \/ Highest Profits <\/u>","9dd3c491":"<b> We can see clearly see from the above visualizations that the most frequent buyers have had the highest orders placed at our store but interestingly their purchasing has not given the highest profits.\n    \n   Darren Budd who has been the most frequent buyers is among the top 5 with highest sales, but he is not among the top list of customers in terms of highest profits. \n    \n   Emily Phan and Deborah Brum Field are the best customers in terms of Sales and Profits.\n    \n <\/b>","97c8b8ad":"We can still see a great numbers of outliers in the data, but removing again will cause the data to loose more rows\/data. For this type of data every time when we remove the outliers, save a dataframe and then plot it, we will again see outliers. This is probably because the range is pretty large for some of the columns. But that doesent means that we have wrong values in the data. \n\nFor e.g in Profit column the largest value is 27220.69. This was when the largest Unit Price item was sold we had 13 number of orders for that item . The sales was also the highest for this i.e 89061.05. This is by no means an outlier.Similarly for same unit price the profit column also has the minimum value -14140.70. This is probably because the sales was not much for this order and we can assume that the processing may have taken some cost which ultimately incurred the largest lost. \n\nSo in summary after detailed study of the data we dont think the outliers in this data are false values and therefore we will continue our analysis with the original data frame in which the outliers were not removed.\n","fdd760e9":"<b> It's cleat that the Paper sub category has been the most selling but in terms of Profit, Telephones and communications has been the best. <\/b>"}}