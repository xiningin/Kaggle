{"cell_type":{"bdfd6fed":"code","90716ebf":"code","240f6221":"code","87849006":"code","21d67df1":"code","95cf574b":"code","f3671d6d":"code","52daa6e4":"code","e0327af6":"code","102c377b":"code","1c26afab":"code","84eafb3e":"code","5d1dc8ce":"markdown","0c38f7e3":"markdown","ddee5c1f":"markdown","ad9e308f":"markdown","2df47a99":"markdown","8548feeb":"markdown"},"source":{"bdfd6fed":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom kaggle.competitions import twosigmanews","90716ebf":"env = twosigmanews.make_env()\n(market_train, _) = env.get_training_data()","240f6221":"lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n\ndef prep_data(market_data):\n    # add asset code representation as int (as in previous kernels)\n    market_data['assetCodeT'] = market_data['assetCode'].map(lbl)\n    market_col = ['assetCodeT', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1', \n                        'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10', \n                        'returnsOpenPrevMktres10']\n    # select relevant columns, fillna with zeros (where dropped in previous kernels that I saw)\n    # getting rid of time, assetCode (keep int representation assetCodeT), assetName, universe\n    X = market_data[market_col].fillna(0).values\n    if \"returnsOpenNextMktres10\" in list(market_data.columns):#if training data\n        up = (market_data.returnsOpenNextMktres10 >= 0).values\n        r = market_data.returnsOpenNextMktres10.values\n        universe = market_data.universe\n        day = market_data.time.dt.date\n        assert X.shape[0] == up.shape[0] == r.shape[0] == universe.shape[0] == day.shape[0]\n    else:#observation data without labels\n        up = []\n        r = []\n        universe = []\n        day = []\n    return X, up, r, universe, day","87849006":"X, up, r, universe, day = prep_data(market_train)","21d67df1":"# r, u and d are used to calculate the scoring metric on test\nX_train, X_test, up_train, up_test, _, r_test, _, u_test, _, d_test = \\\ntrain_test_split(X, up, r, universe, day, test_size=0.25, random_state=99)","95cf574b":"#from other kernel\nfrom xgboost import XGBClassifier\nxgb_market = XGBClassifier(n_jobs=4, n_estimators=200, max_depth=8, eta=0.1)\n#xgb_market = XGBClassifier(n_jobs=4, n_estimators=100)\nt = time.time()\nprint('Fitting Up')\nxgb_market.fit(X_train,up_train)\nprint(f'Done, time = {time.time() - t}s')","f3671d6d":"# distribution of confidence that will be used as submission\nconfidence_test = xgb_market.predict_proba(X_test)[:,1]*2 -1\nprint(accuracy_score(confidence_test>0,up_test))\nplt.hist(confidence_test, bins='auto')\nplt.title(\"predicted confidence\")\nplt.show()","52daa6e4":"# calculation of actual metric that is used to calculate final score\nr_test = r_test.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = confidence_test * r_test * u_test\ndata = {'day' : d_test, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_test = mean \/ std\nprint(score_test)","e0327af6":"days = env.get_prediction_days()","102c377b":"n_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\npredicted_confidences = np.array([])\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    print(n_days,end=' ')\n    \n    t = time.time()\n    # discard assets that are not scored\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_market_obs = prep_data(market_obs_df)[0]\n    prep_time += time.time() - t\n    \n    t = time.time()\n    market_prediction = xgb_market.predict_proba(X_market_obs)[:,1]*2 -1\n    predicted_confidences = np.concatenate((predicted_confidences, market_prediction))\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':market_prediction})\n    # insert predictions to template\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n\nenv.write_submission_file()\ntotal = prep_time + prediction_time + packaging_time\nprint(f'Preparing Data: {prep_time:.2f}s')\nprint(f'Making Predictions: {prediction_time:.2f}s')\nprint(f'Packing: {packaging_time:.2f}s')\nprint(f'Total: {total:.2f}s')","1c26afab":"# distribution of confidence as a sanity check: they should be distributed as above\nplt.hist(predicted_confidences, bins='auto')\nplt.title(\"predicted confidence\")\nplt.show()","84eafb3e":"market_col = ['assetCodeT', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1', \n                        'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10', \n                        'returnsOpenPrevMktres10']\nplt.figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\nplt.bar(range(len(xgb_market.feature_importances_)), xgb_market.feature_importances_)\nplt.xticks(range(len(xgb_market.feature_importances_)), market_col, rotation='vertical');","5d1dc8ce":"# Fit","0c38f7e3":"# Feature importances","ddee5c1f":"# Prediction","ad9e308f":"# Evaluation of Test","2df47a99":"# Market Data Only Baseline\n\nUsing a lot of ideas from XGBoost Baseline Kernel.\n\nThis is a fit of market data only (no news data used) showing relatively good results. ","8548feeb":"# Data Preparation"}}