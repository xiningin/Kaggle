{"cell_type":{"2fec61bc":"code","86283764":"code","de053e73":"code","bddd0be3":"code","a3b4c7aa":"code","5d725008":"code","6129d0e2":"code","2ecf3233":"code","873726d4":"code","91ab44b4":"code","37a449b9":"code","2ecbad3f":"code","c8223f98":"code","f3286831":"code","59bf4a23":"code","10941312":"code","442ac80e":"code","4f805f1c":"code","e2dc0ca7":"code","db19b06f":"code","7b2ea294":"code","5f2cd55e":"code","644bd393":"code","a850c441":"code","b9055e8e":"markdown","f96cf4a8":"markdown","aabfd66c":"markdown","1a5a3219":"markdown","16b419ac":"markdown","80f4c4e7":"markdown","7817ede0":"markdown","181354c0":"markdown","893e6f62":"markdown","9894b896":"markdown","97b380fc":"markdown","61006581":"markdown","1b459b25":"markdown","cef2c285":"markdown","d168c36a":"markdown","ed1e2cbf":"markdown","f1c9ec12":"markdown","a6968e78":"markdown","b26deb19":"markdown","591161a1":"markdown","91f82e09":"markdown","f890414a":"markdown","38044683":"markdown","0c045813":"markdown"},"source":{"2fec61bc":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder\n\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","86283764":"train_data.head()","de053e73":"len(train_data['Name']) == len(train_data['Name'].unique())","bddd0be3":"train_data.notnull().sum()","a3b4c7aa":"train_data[train_data['Embarked'].isnull()]","5d725008":"sns.barplot(x='Embarked', y='Survived', data=train_data)","6129d0e2":"clean_data = train_data.dropna(subset=['Embarked']).copy()\nclean_data","2ecf3233":"clean_data['Cabin'].fillna('Other', inplace=True)\nclean_data['Age'].fillna(clean_data['Age'].mean(), inplace=True)","873726d4":"sns.barplot(x='Sex', y='Survived', data=train_data)","91ab44b4":"sns.kdeplot(data=train_data, x='Age')","37a449b9":"train_data['Age_group'] = pd.cut(train_data['Age'], bins=[0, 16, 32, 48, 64, 100], labels=['Very young', 'Young', 'Mid-age', 'Old', 'Very old'])\nsns.barplot(x='Age_group', y='Survived', data=train_data)","2ecbad3f":"# apply groups to the cleaned data\nclean_data['Age_group'] = pd.cut(clean_data['Age'], bins=[0, 16, 32, 48, 64, 100], labels=['Very young', 'Young', 'Mid-age', 'Old', 'Very old'])","c8223f98":"clean_data['Ticket'].value_counts()","f3286831":"clean_data[clean_data['Ticket'] == '347082']","59bf4a23":"X = clean_data.drop(['Survived', 'Name', 'Fare', 'Age', 'PassengerId'], axis=1)\ny = clean_data['Survived']","10941312":"X_train, X_valid, y_train, y_valid = train_test_split(X, y)\nX","442ac80e":"def build_model(classifier, X, y):\n    model = make_pipeline(\n        # we rely on many categorical variables that could take on unseen values in the test set\n        OneHotEncoder(handle_unknown='ignore'),\n        classifier()\n    )\n    model.fit(X, y)\n    return model","4f805f1c":"lr = build_model(LinearRegression, X_train, y_train)","e2dc0ca7":"knn = build_model(KNeighborsClassifier, X_train, y_train)","db19b06f":"sgd = build_model(SGDClassifier, X_train, y_train)","7b2ea294":"tree = build_model(DecisionTreeClassifier, X_train, y_train)","5f2cd55e":"models = {\n    'Linear Regression': lr,\n    'KNN': knn,\n    'SGD': sgd,\n    'Decision Tree': tree,\n}","644bd393":"cv = 10\nfor name, model in models.items():\n    train_score_total = 0\n    test_score_total = 0\n    for i in range(1000):\n        train_score_total += cross_val_score(model, X_train, y_train, cv=cv).mean()\n        test_score_total += model.score(X_valid, y_valid)\n        if i % 10 == 0:\n            print(f'{i \/ 10}% complete!')\n    print(f'{name} training score: {train_score_total \/ 1000}')\n    print(f'{name} validation score: {test_score_total \/ 1000}')","a850c441":"# apply our transformations on the testing dataset\ntest_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\ntest_data['Age_group'] = pd.cut(test_data['Age'], bins=[0, 16, 32, 48, 64, 100], labels=['Very young', 'Young', 'Mid-age', 'Old', 'Very old'])\ntest_data['Cabin'].fillna('Other', inplace=True)\nX_test = test_data.drop(['Name', 'Fare', 'Age', 'PassengerId'], axis=1)\n\n# build and predict\nfinal_knn_model = build_model(KNeighborsClassifier, X, y)\npredictions = final_knn_model.predict(X_test)\n\n# dump to file\noutput = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint('Done!')","b9055e8e":"# Model Evaluation","f96cf4a8":"Finally, let's drop all the columns we don't need and split the data into features and the target.","aabfd66c":"As is well known, a \"women and children first\" policy was employed when deciding who to save. Let's examine the survival rates of women compared to men:","1a5a3219":"# Data Loading","16b419ac":"## Unused Features","80f4c4e7":"Passengers 16 and under seem to have survived somewhat better than the average, and those over 64 survived much worse than the average. `Age` appears to be a worthwhile feature.","7817ede0":"# Exploratory Data Analysis","181354c0":"Testing favors the KNN model very slightly, so we'll train that on the entire dataset and make our predictions.","893e6f62":"Most columns appear to be complete, but `Age` and `Cabin` are missing a significant amount of values, while `Embarked` is missing just 2 values.","9894b896":"Let's write a utility function to build our models with the parameters we want.","97b380fc":"The `Sex` feature appears to be an excellent predictor.\n\nLet's examine the `Age` feature more closely. First, we'll take a look at how the age data is distributed.","61006581":"# Generating the Submission Data","1b459b25":"- `Name` wasn't used because they are all unique, and someone's name *shouldn't* directly play a role in their survival.\n- `Fare` was ignored in favor of `Pclass` being the better proxy for socioeconomic class.","cef2c285":"Let's look around...","d168c36a":"Hmm; there could be something here... let's just drop the rows with a missing value.","ed1e2cbf":"Surely where someone embarked from doesn't matter, right? Can we just drop the column?","f1c9ec12":"As for `Cabin` and `Age`, we'll fill the missing values with `'Other'` and the mean `Age`, respectively.","a6968e78":"It seems that the majority of passengers were between 10 and 40 years old. Let's look at survivability across multiple age groups.","b26deb19":"My testing has KNN, decision trees, and SGD all doing similarly well, with KNN pulling slightly ahead. Linear Regression is terrible in comparision.","591161a1":"What about `Ticket`?","91f82e09":"# Building the Models","f890414a":"## \"Women and Children First\"?","38044683":"Hmm, they all died. We should probably keep this feature.","0c045813":"## Missing Values"}}