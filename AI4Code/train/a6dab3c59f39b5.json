{"cell_type":{"0badd4da":"code","3a997995":"code","212951fc":"code","4cbe3e5a":"code","f78c7320":"code","bdd32eb5":"code","731bf953":"code","fdfa44c8":"code","3e019a8d":"code","ce4e1ce6":"code","415c4f5a":"code","b6552c26":"code","22e02300":"code","29a26bf1":"code","33906ddc":"code","093075ce":"code","cabc8e85":"code","35ebab7b":"code","e4c8cc0f":"code","0c7e249c":"code","7f5f65aa":"code","4a77fce8":"code","666443b8":"code","08631384":"code","f0b5702c":"code","01313522":"code","9ce94a58":"code","2b856cc8":"code","c0d1d7d8":"code","1fd83d7a":"code","1d1dcfec":"markdown","5754a11e":"markdown","b2a5c219":"markdown","6f20835a":"markdown","06a234d2":"markdown","d99c0312":"markdown","75b0113e":"markdown","9e40b44b":"markdown"},"source":{"0badd4da":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\npd.set_option('display.max_columns', 100)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import combinations\nfrom imblearn.over_sampling import SMOTE\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier","3a997995":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","212951fc":"df1 = pd.read_csv('..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv')\ndf1.head()","4cbe3e5a":"# so that we can separate out the category and numeric features\nfor i in df1.columns:\n    print(\"Number of unique {} are : {}\".format(i,len(df1[i].unique())))","f78c7320":"# checking null values\ndf1.isnull().sum()\n\n#Imputing giving bad roc so we will just let NaN be another category","bdd32eb5":"#checking outliers in numeric features\nfig,axs = plt.subplots(1,2,figsize=(18,7))\nfig.suptitle('Searching For Outliers..')\n\n\nax1 = sns.boxplot(ax=axs[0],y = df1[\"Age\"])\nax2 = sns.boxplot(ax=axs[1],y = df1['Avg_Account_Balance'])\n\n#age seems fine, but account balance too many rich people\n","731bf953":"# Let`s see how much data we have to sacrifice to remove outliers\n\nQ1 = df1['Avg_Account_Balance'].quantile(0.25)\nQ3 = df1['Avg_Account_Balance'].quantile(0.75)\nIQR = Q3 - Q1\n\nfilter = (df1['Avg_Account_Balance'] >= Q1 - 1.5 * IQR) & (df1['Avg_Account_Balance'] <= Q3 + 1.5 *IQR)\ndf2 = df1.loc[filter]  \nprint(\"data loss percentage {}%\".format(((len(df1) - len(df2))\/len(df1))*100))","fdfa44c8":"# time to check target variable is imbalance or not\nsns.countplot(x='Is_Lead',data=df1)\n\n#Imbalanced","3e019a8d":"pd.crosstab(df1['Credit_Product'],df1.Is_Lead,normalize='index').sort_values(by=[1],ascending=False).head(5)","ce4e1ce6":"# check the effects of all cat features on target\ncolumn = ['Gender', 'Region_Code', 'Occupation', 'Channel_Code', 'Credit_Product', 'Is_Active','Vintage']\nfor i in column:\n    print(pd.crosstab(df1[i],df1.Is_Lead,normalize='index').sort_values(by=[1],ascending=False).head(5))\n    print('--------------------------------------------------------------------------')","415c4f5a":"#Let`s group features and check out their influences\n\ncomb = combinations(column, 2) \nfor i in comb:\n    \n    df1[f'{i[0]}_{i[1]}']=df1[i[0]].astype(str)+'_'+df1[i[1]].astype(str)\n    \n    print(pd.crosstab(df1[i[0]],df1.Is_Lead,normalize='index').sort_values(by=[1],ascending=False).head(5))\n    print('**'*30)\n    print(pd.crosstab(df1[f'{i[0]}_{i[1]}'],df1.Is_Lead,normalize='index').sort_values(by=[1],ascending=False).head(5))\n    print('--'*50)\n","b6552c26":"# effect of Age and Avg_Account_Balance on Target\nsns.scatterplot(data=df1, x=\"Avg_Account_Balance\", y=\"Age\",hue='Is_Lead')","22e02300":"def process_data():\n    \n    train = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")\n    test = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/test.csv\")\n    \n    #Removes train rows which has Region_Code not present in test set\n    test_region_list=test['Region_Code'].tolist()\n    train=train[train['Region_Code'].isin(test_region_list)]\n    \n    \n    #Removing outliers\n    Q1 = train['Avg_Account_Balance'].quantile(0.25)\n    Q3 = train['Avg_Account_Balance'].quantile(0.75)\n    IQR = Q3 - Q1\n    filter = (train['Avg_Account_Balance'] >= Q1 - 1.5 * IQR) & (train['Avg_Account_Balance'] <= Q3 + 1.5 *IQR)\n    train = train.loc[filter]  \n    \n    train['train_or_test']='train'\n    test['train_or_test']='test'\n    df=pd.concat([train,test])\n    \n    \n    \n    le = LabelEncoder()\n    for col in ['Gender', 'Region_Code', 'Occupation', 'Channel_Code', 'Credit_Product', 'Is_Active','Vintage']:\n        df[col]=  df[col].astype('str')\n        df[col]= le.fit_transform(df[col])\n        \n\n    \n    return train,test,df","29a26bf1":"train = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/test.csv\")\n\nprint(len (train))\n#Removes train rows which has Region_Code not present in test set\ntest_region_list=test['Region_Code'].tolist()\ntrain1 = train[train['Region_Code'].isin(test_region_list)]\nprint(len(train1))\n((len(train) - len(train1))\/len(train))*100","33906ddc":"def frequency_encoding(column_name,output_column_name,df):\n    fe_pol = (df.groupby(column_name).size()) \/ len(df)\n    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])","093075ce":"\ndef feature_engineering(df):\n    le = LabelEncoder()\n    \n     #Interaction Feature (Combining 2 categorical features and performing frequency encoding)\n        \n    cat_features=[]\n    le_features=[]\n    columns=['Gender', 'Region_Code', 'Occupation', 'Channel_Code', 'Credit_Product', 'Is_Active','Vintage']\n\n    comb = combinations(columns, 2) \n\n    for i in list(comb):  \n        df[f'{i[0]}_{i[1]}']=df[i[0]].astype(str)+'_'+df[i[1]].astype(str)\n        df[f'{i[0]}_{i[1]}_le']=le.fit_transform(df[f'{i[0]}_{i[1]}'])\n        le_features.append(f'{i[0]}_{i[1]}_le')\n        frequency_encoding(f'{i[0]}_{i[1]}',f'{i[0]}_{i[1]}',df)\n        cat_features.append(f'{i[0]}_{i[1]}')   \n        \n    #Frequency Encoding\n    \n    frequency_encoding('Region_Code','Region_Code_fe',df)\n    \n    #Deriving characteristics of each region by creating aggregate features\n    \n    region_aggregate_features = df.groupby(['Region_Code']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],             \n                                                     })\n\n    region_aggregate_features.columns = ['region_aggregate_features' + '_'.join(c).strip('_') for c in region_aggregate_features.columns]\n    df = pd.merge(df, region_aggregate_features, on = ['Region_Code'], how='left')\n\n \n    region_vintage_aggregate_features = df.groupby(['Region_Code','Vintage']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],             \n                                                     })\n    region_vintage_aggregate_features.columns = ['region_vintage_aggregate_features' + '_'.join(c).strip('_') for c in region_vintage_aggregate_features.columns]\n    df = pd.merge(df, region_vintage_aggregate_features, on = ['Region_Code','Vintage'], how='left')\n\n   \n    for i in cat_features:\n        df[f'region_{i}_max']=df.groupby('Region_Code')[i].transform('max')\n        df[f'region_{i}_min']=df.groupby('Region_Code')[i].transform('min')\n        df[f'region_{i}_mean']=df.groupby('Region_Code')[i].transform('mean')\n        df[f'region_{i}_std']=df.groupby('Region_Code')[i].transform('std')\n\n    \n        df[f'region_vinatge_{i}_max']=df.groupby(['Region_Code','Vintage'])[i].transform('max')\n        df[f'region_vinatge_{i}_min']=df.groupby(['Region_Code','Vintage'])[i].transform('min')\n        df[f'region_vinatge_{i}_mean']=df.groupby(['Region_Code','Vintage'])[i].transform('mean')\n        df[f'region_vinatge_{i}_std']=df.groupby(['Region_Code','Vintage'])[i].transform('std')\n\n\n        \n        \n        \n\n    #Deriving characteristics of Occupation by creating aggregate features\n    \n    Occupation_aggregate_features = df.groupby(['Occupation']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Region_Code': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],             \n                                                     })\n\n    Occupation_aggregate_features.columns = ['Occupation_aggregate_features' + '_'.join(c).strip('_') for c in Occupation_aggregate_features.columns]\n    df = pd.merge(df, Occupation_aggregate_features, on = ['Occupation'], how='left')\n    \n    #Deriving characteristics of Channel_Code by creating aggregate features\n    \n    Channel_Code_aggregate_features = df.groupby(['Channel_Code']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Region_Code': ['nunique','count'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],             \n                                                     })\n\n    Channel_Code_aggregate_features.columns = ['Channel_Code_aggregate_features' + '_'.join(c).strip('_') for c in Channel_Code_aggregate_features.columns]\n    df = pd.merge(df, Channel_Code_aggregate_features, on = ['Channel_Code'], how='left')\n    \n    \n    #Deriving characteristics of Is_Active by creating aggregate features\n    \n    Is_Active_aggregate_features = df.groupby(['Is_Active']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Region_Code': ['nunique','count'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],             \n                                                     })\n\n    Is_Active_aggregate_features.columns = ['Is_Active_aggregate_features' + '_'.join(c).strip('_') for c in Is_Active_aggregate_features.columns]\n    df = pd.merge(df, Is_Active_aggregate_features, on = ['Is_Active'], how='left')\n    \n     #Deriving characteristics of Credit_Product by creating aggregate features\n    \n    Credit_Product_aggregate_features = df.groupby(['Credit_Product']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Region_Code': ['nunique','count'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],             \n                                                     })\n\n    Credit_Product_aggregate_features.columns = ['Credit_Product_aggregate_features' + '_'.join(c).strip('_') for c in Credit_Product_aggregate_features.columns]\n    df = pd.merge(df, Credit_Product_aggregate_features, on = ['Credit_Product'], how='left')\n    \n    \n    #Deriving characteristics of Gender by creating aggregate features\n    \n    Gender_aggregate_features = df.groupby(['Gender']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Region_Code': ['nunique','count'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],             \n                                                     })\n\n    Gender_aggregate_features.columns = ['Gender_aggregate_features' + '_'.join(c).strip('_') for c in Gender_aggregate_features.columns]\n    df = pd.merge(df, Gender_aggregate_features, on = ['Gender'], how='left')\n    \n    #Deriving characteristics of Interaction_features by creating aggregate features (These interaction feature are selected for aggregating based on its feature importance)\n    \n    Region_Code_Occupation_grpd = df.groupby(['Region_Code_Occupation']).agg({ 'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count']\n                                                     })                                                              \n                                                     \n    Region_Code_Occupation_grpd.columns = ['grpd_by_Region_Code_Occupation_' + '_'.join(c).strip('_') for c in Region_Code_Occupation_grpd.columns]\n    df = pd.merge(df, Region_Code_Occupation_grpd, on = ['Region_Code_Occupation'], how='left')\n\n\n    Region_Code_Credit_Product_grpd = df.groupby(['Region_Code_Credit_Product']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Gender': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],             \n                                                     })                                                              \n                                                     \n    Region_Code_Credit_Product_grpd.columns = ['grpd_by_Region_Code_Credit_Product_' + '_'.join(c).strip('_') for c in Region_Code_Credit_Product_grpd.columns]\n    df = pd.merge(df, Region_Code_Credit_Product_grpd, on = ['Region_Code_Credit_Product'], how='left')\n    \n    # Occupation_Credit_Product_grpd = df.groupby(['Occupation_Credit_Product']).agg({'Age': ['mean', 'max', 'min','std'],\n    #                                                  'Vintage': ['nunique','count'],\n    #                                                  'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n    #                                                  'Gender': ['nunique','count'],\n    #                                                  'Channel_Code': ['nunique','count'],\n    #                                                  'Is_Active': ['nunique','count'],\n    #                                                  'Region_Code': ['nunique','count'],             \n    #                                                  })                                                              \n                                                     \n    # Occupation_Credit_Product_grpd.columns = ['grpd_by_Occupation_Credit_Product_' + '_'.join(c).strip('_') for c in Occupation_Credit_Product_grpd.columns]\n    # df = pd.merge(df, Occupation_Credit_Product_grpd, on = ['Occupation_Credit_Product'], how='left')\n    \n    Gender_Vintage_grpd = df.groupby(['Gender_Vintage']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Region_Code': ['nunique','count'],             \n                                                     })                                                              \n                                                     \n    Gender_Vintage_grpd.columns = ['grpd_by_Gender_Vintage_' + '_'.join(c).strip('_') for c in Gender_Vintage_grpd.columns]\n    df = pd.merge(df, Gender_Vintage_grpd, on = ['Gender_Vintage'], how='left')\n    \n    Credit_Product_Is_Active_grpd = df.groupby(['Credit_Product_Is_Active']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Gender': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Region_Code': ['nunique','count'],             \n                                                     })                                                              \n                                                     \n    Credit_Product_Is_Active_grpd.columns = ['grpd_by_Credit_Product_Is_Active_' + '_'.join(c).strip('_') for c in Credit_Product_Is_Active_grpd.columns]\n    df = pd.merge(df, Credit_Product_Is_Active_grpd, on = ['Credit_Product_Is_Active'], how='left')\n    \n    Gender_Credit_Product_grpd = df.groupby(['Gender_Credit_Product']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Occupation': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                      })                                                              \n                                                     \n    Gender_Credit_Product_grpd.columns = ['grpd_by_Gender_Credit_Product_' + '_'.join(c).strip('_') for c in Gender_Credit_Product_grpd.columns]\n    df = pd.merge(df, Gender_Credit_Product_grpd, on = ['Gender_Credit_Product'], how='left')\n    \n    #Creating Age Bins and deriving characteristics of each age group by creating aggregate features\n    \n    Age_Bins = KBinsDiscretizer(n_bins=14, encode='ordinal', strategy='quantile')\n    df['Age_Bins'] = Age_Bins.fit_transform(df['Age'].values.reshape(-1,1)).astype(int)\n    \n    age_aggregate_features = df.groupby(['Age_Bins']).agg({'Age': ['mean', 'max', 'min','std'],\n                                                     'Vintage': ['nunique','count'],\n                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std'],\n                                                     'Region_Code': ['nunique','count'],\n                                                     'Channel_Code': ['nunique','count'],\n                                                     'Is_Active': ['nunique','count'],\n                                                     'Credit_Product': ['nunique','count'],\n                                                     'Gender': ['nunique','count'],\n                                                      'Occupation': ['nunique','count'],      \n                                                     })\n    age_aggregate_features.columns = ['age_aggregate_features' + '_'.join(c).strip('_') for c in age_aggregate_features.columns]\n    df = pd.merge(df, age_aggregate_features, on = ['Age_Bins'], how='left')\n\n    \n    return df,le_features\n","cabc8e85":"def preparedatafortraining(df,train,test):\n    \n    train=df.loc[df.train_or_test.isin(['train'])]\n    test=df.loc[df.train_or_test.isin(['test'])]\n    \n    drop_columns={'ID','Is_Lead','train_or_test'}\n    \n    target=['Is_Lead']\n    \n    x=train.drop(columns=drop_columns,axis=1)\n    y=train[target]\n    x_test=test.drop(columns=drop_columns,axis=1)\n    train_features = [_f for _f in x.columns]\n    \n    print(x.shape)\n    \n    return x,y,x_test,train_features","35ebab7b":"def savedata():\n    \n    train,test,df=process_data()\n    df,cat_features=feature_engineering(df)\n    x_train,y_train,x_test,train_features=preparedatafortraining(df,train,test)\n    \n    #x_train.to_pickle(\"x_train_lgbm.pkl\")\n    #y_train.to_pickle(\"y_train_lgbm.pkl\")\n    #x_test.to_pickle(\"x_test_lgbm.pkl\")\n    \n    return x_train,y_train,x_test,cat_features,train_features","e4c8cc0f":"def catboost_model():\n    \n    x,y,x_test,cat_features,train_features=savedata()\n     \n    err = [] \n\n    oofs = np.zeros(shape=(len(x)))\n    preds = np.zeros(shape=(len(x_test)))\n\n    Folds=8\n\n    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2021)\n    i = 1\n\n    for train_index, test_index in fold.split(x, y):\n        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n        m =  CatBoostClassifier(n_estimators=10000,random_state=2020,eval_metric='AUC')\n    \n        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=100,cat_features=cat_features)\n    \n        pred_y = m.predict_proba(x_val)[:,1]\n        oofs[test_index] = pred_y\n        print(i, \" err_cat: \", roc_auc_score(y_val,pred_y))\n        err.append(roc_auc_score(y_val,pred_y))\n        preds+= m.predict_proba(x_test)[:,1]\n        i = i + 1\n    preds=preds\/Folds\n    \n    print(f\"Average StratifiedKFold Score : {sum(err)\/Folds} \")\n    oof_score = roc_auc_score(y, oofs)\n    print(f'\\nOOF Auc is : {oof_score}')\n    \n    oofs=pd.DataFrame(oofs,columns=['catboostoof'])\n    preds=pd.DataFrame(preds,columns=['catboostpred'])\n    \n    oofs.to_csv('catboostoof.csv',index=False)\n    preds.to_csv('catboostpred.csv',index=False)","0c7e249c":"catboost_model()","7f5f65aa":"\ndef lgbm_model():\n    \n    x,y,x_test,cat_features,train_features=savedata()\n    \n\n    params={'lambda': 2.8849054495567423, \n        'alpha': 0.001054193185317787, \n        'colsample_bytree': 0.5, \n        'subsample': 0.4, \n        'learning_rate': 0.014, \n        'max_depth': 13, \n        'random_state': 24,\n        'min_child_weight': 5}\n    \n    err = [] \n\n    oofs = np.zeros(shape=(len(x)))\n    preds = np.zeros(shape=(len(x_test)))\n\n    Folds=8\n\n    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2020)\n    i = 1\n\n    for train_index, test_index in fold.split(x, y):\n        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n        m = LGBMClassifier(n_estimators=10000,**params,verbose= -1)\n    \n        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=False,eval_metric='auc')\n    \n        pred_y = m.predict_proba(x_val)[:,1]\n        oofs[test_index] = pred_y\n        print(i, \" err_lgm: \", roc_auc_score(y_val,pred_y))\n        err.append(roc_auc_score(y_val,pred_y))\n        preds+= m.predict_proba(x_test)[:,1]\n        i = i + 1\n    preds=preds\/Folds\n\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['importance'] = m.booster_.feature_importance(importance_type='gain')\n    \n    print(f\"Average StratifiedKFold Score : {sum(err)\/Folds} \")\n    oof_score = roc_auc_score(y, oofs)\n    print(f'\\nOOF Auc is : {oof_score}')\n    \n    oofs=pd.DataFrame(oofs,columns=['lgbmoof'])\n    preds=pd.DataFrame(preds,columns=['lgbmpred'])\n    \n    oofs.to_csv('lgbmoof.csv',index=False)\n    preds.to_csv('lgbmpred.csv',index=False)\n\n    return imp_df","4a77fce8":"imp = lgbm_model()","666443b8":"# Function to display feature importance...\ndef display_importances(feature_importance_df_,model):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:30].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(12, 8))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title(model+\" Features (avg over folds)\")\n    plt.tight_layout()\n    plt.savefig(model +\"_importances-01.png\")","08631384":"# Feature importance based on gain...\n\ndisplay_importances(imp,\"LGBM\")","f0b5702c":"def xgb_model():\n    \n    x,y,x_test,cat_features,train_features=savedata()\n    \n    params={'lambda': 1.417495651744778, \n        'alpha': 0.4281901245971981, \n        'colsample_bytree': 0.7, \n        'subsample': 0.8, \n        'learning_rate': 0.016,\n        'max_depth': 9, \n        'random_state': 2020, \n        'min_child_weight': 30}\n    \n    err = [] \n\n    oofs = np.zeros(shape=(len(x)))\n    preds = np.zeros(shape=(len(x_test)))\n\n    Folds=8\n\n    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2020)\n    i = 1\n\n    for train_index, test_index in fold.split(x, y):\n        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n        m = XGBClassifier(n_estimators=10000,**params)\n    \n        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=False,eval_metric='auc')\n    \n        pred_y = m.predict_proba(x_val)[:,1]\n        oofs[test_index] = pred_y\n        print(i, \" err_xgb: \", roc_auc_score(y_val,pred_y))\n        err.append(roc_auc_score(y_val,pred_y))\n        preds+= m.predict_proba(x_test)[:,1]\n        i = i + 1\n    preds=preds\/Folds\n    \n    print(f\"Average StratifiedKFold Score : {sum(err)\/Folds} \")\n    oof_score = roc_auc_score(y, oofs)\n    print(f'\\nOOF Auc is : {oof_score}')\n    \n    oofs=pd.DataFrame(oofs,columns=['xgboof'])\n    preds=pd.DataFrame(preds,columns=['xgbpred'])\n    \n    oofs.to_csv(Data_dir+'xgbmoof.csv',index=False)\n    preds.to_csv(Data_dir+'xgbmpred.csv',index=False)","01313522":"xgb_model()","9ce94a58":"def final_process_data():\n    \n    train = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")\n    test = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/test.csv\")\n    sub= pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/sample_submission.csv\")\n    \n    test_region_list=test['Region_Code'].tolist()\n    train=train[train['Region_Code'].isin(test_region_list)]\n    \n    target=train[['Is_Lead']]\n    \n    lgbmpred = pd.read_csv('..\/input\/mayjobathon-model\/lgbmpred.csv')\n    xgbpred = pd.read_csv('..\/input\/mayjobathon-model\/xgbmpred.csv')\n    catboostpred = pd.read_csv('..\/input\/mayjobathon-model\/catboostpred.csv')\n    \n    total_pred = pd.concat([lgbmpred,xgbpred,catboostpred], axis=1)\n    \n    lgbmoof = pd.read_csv('..\/input\/mayjobathon-model\/lgbmoof.csv')\n    xgboof = pd.read_csv('..\/input\/mayjobathon-model\/xgbmoof.csv')\n    catboostoof = pd.read_csv('..\/input\/mayjobathon-model\/catboostoof.csv')\n    \n    total_oof = pd.concat([lgbmoof,xgboof,catboostoof], axis=1)\n    \n    return train,target,sub,test,total_pred,total_oof","2b856cc8":"def findbestweight(df1,df2,target):\n    max_roc = -1\n    max_weight = 0\n    max_ensemble_oof  = 0\n    weights_list = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n    for weight in weights_list:\n        ensemble_oof = weight*df1 + (1-weight)*df2\n        roc_score = roc_auc_score(target,ensemble_oof)\n        if roc_score > max_roc:\n            max_ensemble_oof = ensemble_oof\n            max_roc = roc_score\n            max_weight = weight\n    print(\"The best weights for blending is {0} with AUC {1}\".format(max_weight, max_roc))\n    return max_weight","c0d1d7d8":"def blend():\n    train,target,sub,test,total_pred,total_oof=final_process_data()\n    weight1=findbestweight(total_oof['lgbmoof'],total_oof['xgboof'],target)\n    lgb_xgb=weight1*total_oof['lgbmoof'] +(1-weight1)*total_oof['xgboof']\n    \n    weight2=findbestweight(lgb_xgb,total_oof['catboostoof'],target)\n    lgb_xgb_cat=weight2*lgb_xgb +(1-weight2)*total_oof['catboostoof']\n    \n    lgb_xgb_cat_pred=(weight1*total_pred['lgbmpred']+(1-weight1)*total_pred['xgbpred'])*weight2+total_pred['catboostpred']*(1-weight2)\n    \n    sub['Is_Lead']=lgb_xgb_cat_pred\n    sub.to_csv('.\/blend.csv',index=False)\n    print(sub)","1fd83d7a":"blend()","1d1dcfec":"# XGBOOST","5754a11e":"# Final Blend","b2a5c219":"# Basic Pre-processing","6f20835a":"# Data preparation for Machine Learning","06a234d2":"### Final Score : 0.8732 AUC_ROC Score in private leaderboard","d99c0312":"# CatBoost","75b0113e":"# Feature Engineering","9e40b44b":"# LightGBM"}}