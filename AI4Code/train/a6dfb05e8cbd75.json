{"cell_type":{"52f2ad8c":"code","e6912691":"code","19c57e90":"code","bae0afac":"code","95cd50b2":"code","fc22bd15":"code","ecd3adf8":"code","2ac7a37b":"code","657feb04":"code","aa417da2":"code","6b445d48":"code","70377dbb":"code","53921c3f":"code","9ca587d0":"code","9b2c3cf6":"code","f7522e71":"code","41b9208c":"code","d84e59ef":"code","dd2df999":"code","e943a9dd":"code","9ae6902f":"markdown","e40675ec":"markdown","f15428f1":"markdown","2c498417":"markdown","0dad3e48":"markdown"},"source":{"52f2ad8c":"import numpy as np \nimport pandas as pd \nimport os\nimport glob\nimport pickle\nfrom sklearn.model_selection import train_test_split \nimport librosa","e6912691":"from keras.models import Model\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Reshape\nfrom keras.layers import Activation\nfrom keras.layers import concatenate\nfrom keras import optimizers\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nimport tensorflow as tf","19c57e90":"INPUT_FOLDER = \"..\/input\/freesound-audio-tagging-2019\/\"\nprint(os.listdir(INPUT_FOLDER))","bae0afac":"TRAIN_CURATED_PATH = INPUT_FOLDER + \"train_curated.csv\"\nTRAIN_NOISY_PATH = INPUT_FOLDER + \"train_noisy.csv\"\nSAMPLE_SUBMISSION_PATH = INPUT_FOLDER + \"sample_submission.csv\"\nTRAIN_CURATED = INPUT_FOLDER + \"train_curated\/\"\nTRAIN_NOISY = INPUT_FOLDER + \"train_noisy\/\"\nTEST = INPUT_FOLDER + \"test\/\"\n\ntrain_curated = pd.read_csv(TRAIN_CURATED_PATH)\ntrain_noisy = pd.read_csv(TRAIN_NOISY_PATH)\nsample = pd.read_csv(SAMPLE_SUBMISSION_PATH)","95cd50b2":"def one_hot(labels, src_dict):\n    ar = np.zeros([len(labels), len(src_dict)])\n    for i, label in enumerate(labels):\n        label_list = label.split(',')\n        for la in label_list:\n            ar[i, src_dict[la]] = 1\n    return ar","fc22bd15":"target_names = sample.columns[1:]\nnum_targets = len(target_names)\n\nsrc_dict = {target_names[i]:i for i in range(num_targets)}\nsrc_dict_inv = {i:target_names[i] for i in range(num_targets)}","ecd3adf8":"# image size, normalized\nnum_freq = 128\nlen_div = 256","2ac7a37b":"# # get normarized images (num_freq, len_div). zero padding for last cut\n# X_proc_ = np.zeros([1, num_freq, len_div]) # dummy of normalized image (templete)\n# y_proc_ = np.zeros([1,80]) # dummy of label (templete)\n# y_proc_tmp = one_hot(train_curated['labels'], src_dict)\n\n# file_name = train_curated['fname'].values\n\n# for i, file in enumerate(file_name):\n#     wavfile = TRAIN_CURATED + file\n#     y_proc, sr = librosa.load(wavfile)\n#     S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n#     log_S = librosa.power_to_db(S, ref=np.max)\n#     X_proc = (log_S + 80) \/ 40 - 1 # fit signal range (-80, 0) -> (-1, 1)\n    \n#     num_div = X_proc.shape[1] \/\/ len_div\n#     num_pad = len_div - X_proc.shape[1] % len_div\n#     redidual_amp = np.zeros([num_freq, num_pad])\n#     dum = np.hstack([X_proc, redidual_amp])\n#     X_proc_ = np.vstack([X_proc_, np.array(np.split(dum, num_div+1,1))])\n#     for _ in range(num_div+1):\n#         y_proc_ = np.vstack([y_proc_, y_proc_tmp[i]])\n\n# X = X_proc_[1:] # del templete\n# y = y_proc_[1:] # del templete\n# X = X.reshape([-1, num_freq, len_div, 1])\n\n# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","657feb04":"with open('..\/input\/preprocessed-train-data-2\/train_arr.pickle', 'rb') as f:\n    X_train = pickle.load(f)\n    y_train = pickle.load(f)","aa417da2":"inputs = Input(shape=(num_freq,len_div,1), name='input')\n\ndense_list = []\n\n## Block 1\nconv1 = Conv2D(4, (19, 19),activation='relu',padding='same',name='conv1')(inputs)\npool1 = MaxPooling2D((19, 19),strides=(1, 1),padding='same',name='pool1')(conv1)\nnorm1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm1')(pool1)\ndrop1 = Dropout(0.05)(norm1)\n\nconv1_1 = Conv2D(4, (11, 11),activation='relu',padding='same',name='conv1_1')(drop1)\npool1_1 = MaxPooling2D((5, 5),strides=(5, 5),padding='same',name='pool1_1')(conv1_1)\nnorm1_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm1_1')(pool1_1)\ndrop1_1 = Dropout(0.05)(norm1_1)\n\nflatten1 = Flatten(name='flatten1')(drop1)\ndense1 = Dense(16, name='dense1')(flatten1)\nact1 = Activation('relu',name='act1')(dense1)\ndense_list.append(act1)\n\n## Block 2\nconv2 = Conv2D(4, (13, 13),activation='relu',padding='same',name='conv2')(inputs)\npool2 = MaxPooling2D((13, 13), strides=(1, 1), padding='same',name='pool2')(conv2)\nnorm2 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm2')(pool2)\ndrop2 = Dropout(rate=0.05)(norm2)\n\nconv2_1 = Conv2D(4, (7, 7),activation='relu',padding='same',name='conv2_1')(drop2)\npool2_1 = MaxPooling2D((7, 7), strides=(5, 5), padding='same',name='pool2_1')(conv2_1)\nnorm2_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm2_1')(pool2_1)\ndrop2_1 = Dropout(rate=0.05)(norm2_1)\n\nflatten2 = Flatten(name='flatten2')(drop2_1)\ndense2 = Dense(16, name='dense2')(flatten2)\nact2 = Activation('relu',name='act2')(dense2)\ndense_list.append(act2)\n\n## Block 3\nconv3 = Conv2D(8, (11, 11), activation='relu',padding='same',name='conv3')(inputs)\npool3 = MaxPooling2D((11, 11), strides=(2, 2), padding='same',name='pool3')(conv3)\nnorm3 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm3')(pool3)\ndrop3 = Dropout(rate=0.05)(norm3)\n\nconv3_1 = Conv2D(8, (5, 5), activation='relu',padding='same',name='conv3_1')(drop3)\npool3_1 = MaxPooling2D((5, 5), strides=(2, 2), padding='same',name='pool3_1')(conv3_1)\nnorm3_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm3_1')(pool3_1)\ndrop3_1 = Dropout(rate=0.05)(norm3_1)\n\nflatten3 = Flatten(name='flatten3')(drop3_1)\ndense3 = Dense(16, name='dense3')(flatten3)\nact3 = Activation('relu',name='act3')(dense3)\ndense_list.append(act3)\n\n## Block 4\nconv4 = Conv2D(8, (9, 9),activation='relu',padding='same',name='conv4')(inputs)\npool4 = MaxPooling2D((9, 9), strides=(2, 2), padding='same',name='pool4')(conv4)\nnorm4 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm4')(pool4)\ndrop4 = Dropout(rate=0.05)(norm4)\n\nconv4_1 = Conv2D(8, (3, 3),activation='relu',padding='same',name='conv4_1')(drop4)\npool4_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',name='pool4_1')(conv4_1)\nnorm4_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm4_1')(pool4_1)\ndrop4_1 = Dropout(rate=0.05)(norm4_1)\n\nflatten4 = Flatten(name='flatten4')(drop4_1)\ndense4 = Dense(16, name='dense4')(flatten4)\nact4 = Activation('relu',name='act4')(dense4)\ndense_list.append(act4)\n\nconcat = concatenate(dense_list, name='concat', axis=1)\n\ndense2 = Dense(80, name='dense_all')(concat)\npred = Activation('softmax',name='pred')(dense2)\n\nadam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel = Model(inputs=inputs, outputs=pred)","6b445d48":"def tf_one_sample_positive_class_precisions(y_true, y_pred) :\n    num_samples, num_classes = y_pred.shape\n    \n    # find true labels\n    pos_class_indices = tf.where(y_true > 0) \n    \n    # put rank on each element\n    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n    sample_range = tf.transpose(sample_range)\n    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n    retrieved_class_map = tf.transpose(retrieved_class_map)\n    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n    \n    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n    \n    class_rankings = tf.scatter_nd(retrieved_class_map,\n                                          class_range,\n                                          tf.shape(y_pred))\n    \n    #pick_up ranks\n    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n\n    # add one for division for \"presicion_at_hits\"\n    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n    \n    # generate tensor [num_sample, predict_rank], \n    # top-N predicted elements have flag, N is the number of positive for each sample.\n    sample_label = pos_class_indices[:, 0]   \n    sample_label = tf.reshape(sample_label, (-1, 1))\n    sample_label = tf.cast(sample_label, tf.int32)\n    \n    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n    retrieved_class_true_position = tf.concat((sample_label, \n                                               num_correct_until_correct), axis=1)\n    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n                                         retrieved_pos, \n                                         tf.shape(y_pred))\n    # cumulate predict_rank\n    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n\n    # find positive position\n    pos_ret_indices = tf.where(retrieved_class_true > 0)\n\n    # find cumulative hits\n    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n    correct_rank = tf.cast(correct_rank, tf.float32)\n\n    # compute presicion\n    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n\n    return pos_class_indices, precision_at_hits\n\ndef tf_lwlrap(y_true, y_pred):\n    num_samples, num_classes = y_pred.shape\n    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n    pos_flgs = tf.cast(y_true > 0, tf.int32)\n    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n    class_label = pos_class_indices[:,1]\n    sum_precisions_by_classes = tf.unsorted_segment_sum(precision_at_hits,\n                                                        class_label,\n                                                       num_classes)\n    labels_per_class = tf.cast(labels_per_class, tf.float32)\n    labels_per_class = tf.add(labels_per_class, 1e-7)\n    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n                                  tf.cast(labels_per_class, tf.float32))\n    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n    return out","70377dbb":"model.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=[tf_lwlrap])","53921c3f":"model.summary()","9ca587d0":"datagen = ImageDataGenerator(\n           rotation_range=0,\n           width_shift_range=16,\n           height_shift_range=0,\n           shear_range=0,\n           zoom_range=0,\n           horizontal_flip=False,\n           vertical_flip=False)","9b2c3cf6":"datagen.fit(X_train)\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n                    steps_per_epoch=len(X_train) \/ 32, epochs=30)","f7522e71":"# X_test_list = []\n\n# filename = glob.glob(TEST + \"*\")\n\n# for file in filename:\n#     wavfile = file\n#     y_proc, sr = librosa.load(wavfile)\n#     S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n#     log_S = librosa.power_to_db(S, ref=np.max)\n#     X_proc = (log_S + 80) \/ 40 - 1\n    \n#     num_div = X_proc.shape[1] \/\/ len_div\n#     num_pad = len_div - X_proc.shape[1] % len_div\n#     redidual_amp = np.zeros([num_freq, num_pad])\n#     dum = np.hstack([X_proc, redidual_amp])\n#     X_test_list.append(np.array(np.split(dum, num_div+1,1)))\n    \n# with open('..\/input\/preprocessed-test-data-2\/test_arr.pickle', 'wb') as f:\n#     pickle.dump(X_test_list, f)\n#     pickle.dump(filename, f)\n    \nwith open('..\/input\/preprocessed-test-data-2\/test_arr.pickle', 'rb') as f:\n    X_test_list = pickle.load(f)\n    filename = pickle.load(f)","41b9208c":"pred_list = []\nfor X_test in X_test_list:\n    pred = model.predict(X_test.reshape([-1, num_freq, len_div,1])).sum(axis=0) \/ len(X_test)\n    pred_list.append(pred)\ny_pred = np.array(pred_list)","d84e59ef":"names = []\nfor f in filename:\n    names.append(f.split(\"\\\\\")[-1])\n    \nse_file = pd.Series(names, name='fname')","dd2df999":"sound_names = sample.columns[1:]\nlabel = pd.DataFrame(y_pred, columns=sound_names)\n\nsub_df = pd.concat([se_file, label], axis=1)","e943a9dd":"sub_df.to_csv('submission.csv', index=False)","9ae6902f":"I guess spectram may have long term feature which means that fine feature is not important. That's why I've tried to obtain more than 10 pixel feature. A kernel with small size such as (3, 3) might be not important, for example. At this moment, I've found below is not bad. Deep and precise such as VGG is not good that predicts the same output for all X_test.","e40675ec":"Each X_test has different length. That means each prediction has several predictions. Here, simply, those are averaged.","f15428f1":"Below is definition of LWLRAP evaluation for Keras(tensorflow). Some outputs of this function are different from output of numpy version definition. To my understanding, ranking order causes the difference. For example, if there are two label (A, B) in one sound, we can count ranking both ways from A and from B.","2c498417":"submission test.\n\nI'd like to generate format for submission. I've struggled to find nice network for learning which does not get the same output for every X.","0dad3e48":"As you know, every data has different length for time dim. I like cut data at the same length (ex. 256 pixels). The last cut might not be bad with being filled with zeros."}}