{"cell_type":{"9fa6aa72":"code","bcca4eca":"code","6af98c8a":"code","bd72e1bf":"code","6632e8c5":"code","da88b797":"code","df8e787c":"code","95de2558":"code","f0921d01":"code","c207235c":"code","d2b9931c":"markdown","9483fdf6":"markdown","1fefd09b":"markdown","61b01dd5":"markdown","0c051427":"markdown","a0d9339a":"markdown","4e0a7c04":"markdown","e972e31d":"markdown","7f48ffd0":"markdown","43bb813e":"markdown"},"source":{"9fa6aa72":"import tensorflow as tf\nfrom tensorflow.keras.models import Model \nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda \nfrom tensorflow.keras.optimizers import RMSprop \nfrom tensorflow.keras.datasets import fashion_mnist \nfrom tensorflow.python.keras.utils.vis_utils import plot_model \nfrom tensorflow.keras import backend as K \n\n\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom PIL import Image, ImageFont, ImageDraw \nimport random","bcca4eca":"from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten, MaxPooling2D, Activation, Dropout\nfrom keras.models import Model, Sequential \nfrom keras.regularizers import l2 \nfrom keras import backend as K \nfrom keras.optimizers import Adam \nfrom skimage.io import imshow \nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport random","6af98c8a":"npz = np.load('..\/input\/package-data\/input_data.npz')\nX_train = npz['X_train']\nY_train = npz['Y_train']\n\ndel npz \n\nprint(f\"We have {Y_train.shape[0] - 1000} examples to work with\")","bd72e1bf":"left_input = Input((75,75,3))\nright_input = Input((75,75,3))\n\n\nconvnet = Sequential([\n  Conv2D(5,3,input_shape = (75,75,3)),\n    Activation('relu'),  \n    MaxPooling2D(),\n    Conv2D(5,3),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(7,2),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(7,2),\n    Activation('relu'),\n    Flatten(),\n    Dense(18),\n    Activation('sigmoid')\n])\n\n\nencoded_l = convnet(left_input)\nencoded_r = convnet(right_input)\n\nL1_layer = Lambda(lambda tensor : K.abs(tensor[0] - tensor[1]))\n\nL1_distance = L1_layer([encoded_l, encoded_r])\n\n\nprediction = Dense(1, activation = 'sigmoid')(L1_distance)\nsiamese_net = Model(inputs = [left_input, right_input], outputs = prediction)\n\noptimizer = Adam(0.001, decay = 2.5e-4)\nsiamese_net.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])","6632e8c5":"plot_model(siamese_net)","da88b797":"image_list = np.split(X_train[:1000], 1000)\nlabel_list = np.split(Y_train[:1000], 1000)\n","df8e787c":"iceimage = X_train[101]\ntest_left = []\ntest_right = []\ntest_targets = []\n\n\nfor i in range(Y_train.shape[0] - 1000):\n    test_left.append(iceimage)\n    test_right.append(X_train[i + 1000])\n    test_targets.append(Y_train[i + 1000])\n    \ntest_left = np.squeeze(np.array(test_left))\ntest_right = np.squeeze(np.array(test_right))\ntest_targets = np.squeeze(np.array(test_targets))","95de2558":"\"\"\"\nTrain Data Creation\n\"\"\"\n\nleft_input = []\nright_input = []\ntargets = []\n\n# define the number of same pairs to be created per image\nsame = 6\n# define the number of different pairs to be created per image\ndiff = 4\n\n\n\nfor i in range(len(image_list)):\n    \n    # obtain the label of the ith image\n    label_i = int(label_list[i])\n    #print(label_i)\n    \n    # get same pairs\n    print(\"-\"* 10 ); print(\"Same\")\n    # randomly select 'same' number of items for the images with the 'same' label as that of ith image.\n    print(random.sample(list(np.where(np.array(label_list) == label_i)[0]), same))\n    \n    for j in random.sample(list(np.where(np.array(label_list) == label_i)[0]), same):\n        left_input.append(image_list[i])\n        right_input.append(image_list[j])\n        targets.append(1.)\n        \n    \n    # get diff pairs\n    print('='*10); print(\"Different\")\n    # randomly select 'same' number of items for the images with the 'same' label as that of ith image.\n    print(random.sample(list(np.where(np.array(label_list) != label_i)[0]), diff))\n    \n    for j in random.sample(list(np.where(np.array(label_list) != label_i)[0]), diff):\n        left_input.append(image_list[i])\n        right_input.append(image_list[j])\n        targets.append(0.)\n    ","f0921d01":"left_input = np.squeeze(np.array(left_input))\nright_input = np.squeeze(np.array(right_input))\ntargets = np.squeeze(np.array(targets))","c207235c":"siamese_net.summary()\n\n\n\nsiamese_net.fit([left_input, right_input], targets, batch_size = 16, epochs = 30, verbose = 1, \n               validation_data = ([test_left, test_right], test_targets))","d2b9931c":"### Developing the Siamese Network Model","9483fdf6":"Preparing the test dataset","1fefd09b":"We're taking 1000 samples into consideration for initial model training.","61b01dd5":"For each image, 10 pairs are created of which 6 are same & 4 are different.","0c051427":"Using a already processed provided [here](https:\/\/www.kaggle.com\/arpandhatt\/package-data), we'll apply the preprocessing needed for training a Siamese Network Model. ","a0d9339a":"#### Preprocessing the Dataset","4e0a7c04":"#### Necessary Imports","e972e31d":"## Begin Model Training","7f48ffd0":"## Summary -> <br>\nIn this notebook, we'll learn how to perform Siamese Classification. <br> \n\nSiamese Classification is a One-Shot Learning primarily used in Facial Recognition, Signature Verfication. <br>\n\nData Preparation for Siamese Network Learning is usually a challenge to deal with. <br>\nApart from that, comes the network architecture, which has two inputs feeding to a common network architecture. <br>\n<br>\nLet's begin step by step.","43bb813e":"## Loading the Dataset"}}