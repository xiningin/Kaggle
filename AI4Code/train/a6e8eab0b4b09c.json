{"cell_type":{"92fd3b99":"code","091a86d7":"code","01fc1398":"code","02e9f380":"code","9ac7bc60":"code","8d4557c4":"code","9395e1a6":"code","7c472581":"code","a45d878e":"code","2ec51554":"code","722e783d":"code","29544564":"code","629abbe7":"code","17f3bbf6":"code","9dcfed76":"code","85ed8a48":"code","53e98cd9":"code","c4173488":"code","f10b7d59":"code","a5617001":"code","94f6cc24":"code","fae2d1f4":"code","760b5c73":"code","972dc7bf":"code","93f2fd63":"code","498b9c1c":"code","19af6ea5":"code","baf64e39":"code","958017f0":"code","67a6ce78":"code","8c227960":"code","9e3cc74b":"code","0c1df96f":"code","19e1bea2":"code","ee453b57":"code","c9e7a442":"code","ab485853":"code","2b048732":"code","6e000a99":"code","4a9a92a9":"code","ac85bd2e":"code","980aa62e":"code","dcb9b792":"code","575cf7f4":"code","2f5c60ac":"code","9dde21fa":"code","4bd4f199":"code","4429bea9":"code","fb80b2db":"code","8398dccc":"code","92e536a1":"code","f994ce26":"code","73b5e2b4":"code","10cb704e":"code","3aca6e99":"code","4293854f":"code","ccbe48ec":"code","d94c9676":"code","3fdd311e":"code","1900653e":"code","63d7fd39":"markdown","c2dd83a4":"markdown","8d7f49aa":"markdown","02a23ed5":"markdown","999e48af":"markdown","3631c32c":"markdown","fff57c24":"markdown","f8f6740b":"markdown","7e10d0d3":"markdown","a1985aff":"markdown","1f250aa0":"markdown","1db90d12":"markdown","eeaa6256":"markdown"},"source":{"92fd3b99":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","091a86d7":"#from google.colab import drive\n#drive.mount('\/content\/gdrive')","01fc1398":"data = pd.read_csv('..\/input\/diabetes.csv')","02e9f380":"data.head(5)","9ac7bc60":"data.describe()","8d4557c4":"data.info()","9395e1a6":"datacorr = data.corr()\nsns.heatmap(data[data.columns[:9]].corr(),annot=True,cmap='RdYlGn')\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","7c472581":"sns.countplot(data.Outcome)","a45d878e":"\ndata.hist(figsize=(10, 15))","2ec51554":"data1 = data[(data['BloodPressure']!=0) & (data['BMI']!=0) & (data['Glucose']!=0)]","722e783d":"data1.count()","29544564":"data1 = data","629abbe7":"\nonlydiabetic = data[(data['Outcome']==1)]\nonlydiabetic.head(5)","17f3bbf6":"onlydiabetic.hist(figsize=(10,15))","9dcfed76":"import sklearn ","85ed8a48":"from sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier","53e98cd9":"from sklearn.model_selection import GridSearchCV\n","c4173488":"x = data[data.columns[:8]]\nx.head(5)","f10b7d59":"y= data['Outcome']\ny.head(5)","a5617001":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3)","94f6cc24":"x_test","fae2d1f4":"model1 = LogisticRegression()\nmodel1.fit(x_train,y_train)\nprediction = model1.predict(x_test)\naccuracy = metrics.accuracy_score(prediction, y_test)\n\nprint(\"Logistic regression provides an accuracy of \", accuracy)","760b5c73":"for param in model1.get_params().keys():\n    print(param)","972dc7bf":"# Create regularization penalty space\npenalty = ['l1', 'l2']\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 10)\n\n# Create hyperparameter options\nhyperparameters = dict(C=C, penalty=penalty)\n\nclf = GridSearchCV(model1, hyperparameters, cv=5, verbose=0)\n\nbest_model = clf.fit(x_train, y_train)\n\nbest_model.best_estimator_\n","93f2fd63":"model_LR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\nmodel_LR.fit(x_train,y_train)\nprediction_LR = model_LR.predict(x_test)\naccuracy_LR = metrics.accuracy_score(prediction_LR, y_test)\n\nprint(\"Logistic regression provides an accuracy of \", accuracy_LR)\n\nLogisticRegression()","498b9c1c":"from yellowbrick.classifier import ConfusionMatrix","19af6ea5":"# The ConfusionMatrix visualizer taxes a model\ncm = ConfusionMatrix(model_LR)\n\n# Fit fits the passed model. This is unnecessary if you pass the visualizer a pre-fitted model\ncm.fit(x_train, y_train)\n\n# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n# and then creates the confusion_matrix from scikit-learn.\ncm.score(x_test, y_test)\n\n# How did we do?\ncm.poof()","baf64e39":"from sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom yellowbrick.classifier import ROCAUC\n","958017f0":"precision_recall_fscore_support(y_test, prediction)","67a6ce78":"precision, recall, fscore, support = score(y_test, prediction,)\n\nprint('precision: {}'.format(precision))\nprint('recall: {}'.format(recall))\nprint('fscore: {}'.format(fscore))\nprint('support: {}'.format(support))","8c227960":"# Instantiate the visualizer with the classification model\nvisualizer = ROCAUC(model1)\n\nvisualizer.fit(x_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(x_test, y_test)  # Evaluate the model on the test data\ng = visualizer.poof()   ","9e3cc74b":"model2_without = svm.SVC()\nmodel2_without.fit(x_train,y_train)\nsvm_prediction = model2_without.predict(x_test)\nsvm_accuracy = metrics.accuracy_score(svm_prediction, y_test)\n\nprint(\"SVC provides an accuracy of \", svm_accuracy)","0c1df96f":"Cs = [0.001, 0.01, 0.1, 1, 10]\ngammas = [0.001, 0.01, 0.1, 1]\nparam_grid = {'C': Cs, 'gamma' : gammas}\ngrid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=5)\ngrid_search.fit(x_train, y_train)\ngrid_search.best_params_\n  \n  ","19e1bea2":"model2 = svm.SVC(C=1,gamma=0.001)\nmodel2.fit(x_train,y_train)\nsvm_prediction = model2.predict(x_test)\nsvm_accuracy = metrics.accuracy_score(svm_prediction, y_test)\n\nprint(\"SVC provides an accuracy of \", svm_accuracy)","ee453b57":"from yellowbrick.classifier import ConfusionMatrix","c9e7a442":"# The ConfusionMatrix visualizer taxes a model\ncm = ConfusionMatrix(model2)\n\n# Fit fits the passed model. This is unnecessary if you pass the visualizer a pre-fitted model\ncm.fit(x_train, y_train)\n\n# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n# and then creates the confusion_matrix from scikit-learn.\ncm.score(x_test, y_test)\n\n# How did we do?\ncm.poof()\n\ncm.confusion_matrix_","ab485853":"from sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom yellowbrick.classifier import ROCAUC\n","2b048732":"precision_recall_fscore_support(y_test, svm_prediction)","6e000a99":"precision, recall, fscore, support = score(y_test, svm_prediction)\n\nprint('precision: {}'.format(precision))\nprint('recall: {}'.format(recall))\nprint('fscore: {}'.format(fscore))\nprint('support: {}'.format(support))","4a9a92a9":"# Instantiate the visualizer with the classification model\nvisualizer = ROCAUC(model2, micro=False, macro=False, per_class=False)\n\nvisualizer.fit(x_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(x_test, y_test)  # Evaluate the model on the test data\ng = visualizer.poof()   ","ac85bd2e":"model3 = RandomForestClassifier()\nmodel3.fit(x_train,y_train)\nrf_prediction = model3.predict(x_test)\nrf_accuracy = metrics.accuracy_score(rf_prediction, y_test)\n\nprint(\"Random Forest provides an accuracy of \", rf_accuracy)","980aa62e":"param_grid = {\n    'n_estimators': [200, 700],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(estimator=model3, param_grid=param_grid, cv= 5)\n\nCV_rfc.fit(x_train,y_train)\n\nCV_rfc.best_estimator_","dcb9b792":"model_RFC = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\nmodel_RFC.fit(x_train,y_train)\nrfc_prediction = model_RFC.predict(x_test)\nrfc_accuracy = metrics.accuracy_score(rfc_prediction, y_test)\n\nprint(\"Random Forest provides an accuracy of \", rfc_accuracy)\n\n","575cf7f4":"print(\"the best score is %s\"%CV_rfc.best_score_)  \nprint(\"the best parameter value that resulted in the best performance is %s\"%CV_rfc.best_estimator_)  \nprint(\"the performance over test dats is %s\"%CV_rfc.score(x_train, y_train) ) \n","2f5c60ac":"from yellowbrick.classifier import ConfusionMatrix","9dde21fa":"# The ConfusionMatrix visualizer taxes a model\ncm = ConfusionMatrix(model_RFC)\n\n# Fit fits the passed model. This is unnecessary if you pass the visualizer a pre-fitted model\ncm.fit(x_train, y_train)\n\n# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n# and then creates the confusion_matrix from scikit-learn.\ncm.score(x_test, y_test)\n\n# How did we do?\ncm.poof()","4bd4f199":"from sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom yellowbrick.classifier import ROCAUC\n","4429bea9":"precision_recall_fscore_support(y_test, svm_prediction)","fb80b2db":"precision, recall, fscore, support = score(y_test, rf_prediction)\n\nprint('precision: {}'.format(precision))\nprint('recall: {}'.format(recall))\nprint('fscore: {}'.format(fscore))\nprint('support: {}'.format(support))","8398dccc":"# Instantiate the visualizer with the classification model\nvisualizer = ROCAUC(model3)\n\nvisualizer.fit(x_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(x_test, y_test)  # Evaluate the model on the test data\ng = visualizer.poof()   ","92e536a1":"results = []\nmodels = np.array([\"Logistic Regression\",\"SVM\",\"Random Forest\"])\naccuracies = np.round(np.array([accuracy_LR, svm_accuracy,rf_accuracy]),3)\n\na=np.append(models.reshape(-1,1),accuracies.reshape(-1,1), axis =1 )\nres = pd.DataFrame(a,columns= (['Models', 'Accuracies']))\nres","f994ce26":"d = {'FP': [14,15,19] , 'TN' : [34,46,35]}\nFP_TN = pd.DataFrame( d)\nFP_TN","73b5e2b4":"result = res.reset_index().merge(FP_TN.reset_index(), how = 'inner', on = 'index')","10cb704e":"result.drop(['index'], axis=1, inplace=True)","3aca6e99":"result","4293854f":"FP_TN.reset_index()","ccbe48ec":"result[\"Accuracies\"] = result.Accuracies.astype(float)\nresult[\"Models\"] = result.Accuracies.astype(str)\n","d94c9676":"\nres.dtypes\n","3fdd311e":"result[['Models','Accuracies']].dtypes","1900653e":" \nplt.bar(result.Models , result.Accuracies)\nplt.xticks(result.Models, ['Logistic Regression','SVM','Random Forest'])\nplt.ylim(ymin=0.6)\nplt.title('Accuracies')\nplt.show()\n\n\nplt.bar(result.Models, result.FP)\nplt.xticks(result.Models, ['Logistic Regression','SVM','Random Forest'])\nplt.ylim(ymin=0)\nplt.title(\"Number of who don't have diabetes but are classified as they do\")\nplt.show()\n\nplt.bar(result.Models, result.TN)\nplt.xticks(result.Models, ['Logistic Regression','SVM','Random Forest'])\nplt.title(\"Number of who have diabetes but are classified as they dont\")\nplt.ylim(ymin=0)\nplt.show()\n","63d7fd39":"#### Confusion matrix, precision, recall, ROC AUC)","c2dd83a4":"## Model Building","8d7f49aa":"#### Confusion matrix, precision, recall, ROC AUC)","02a23ed5":"### Model 2 : SVM","999e48af":"#### GridSearch CV SVM","3631c32c":"## Comparing Model Accuracy ","fff57c24":"#### GridSearch CV Logistic regression\n","f8f6740b":"#### Confusion matrix, precision, recall, ROC AUC)","7e10d0d3":"### Model 3 : Random Forest","a1985aff":"## Importing dataset\n","1f250aa0":"#### GridSearch CV Random Forest","1db90d12":"### Model 1 : Logistic  Regression","eeaa6256":"## Exploratory Data Analysis"}}