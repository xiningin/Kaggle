{"cell_type":{"f2bbe2c4":"code","b2b221fc":"code","d4b60f71":"code","42606b18":"code","0ff0d759":"code","528202e0":"code","47d066b7":"code","9a978022":"code","dda9c1cf":"code","49289386":"code","a0a5c075":"code","552d5eb3":"code","976aed83":"code","b26d1078":"code","e2728f68":"code","5fe615a9":"code","c4199b1f":"code","98b1124e":"markdown","c09e75a5":"markdown","58c1bbb3":"markdown","1156be33":"markdown","d64da2a6":"markdown"},"source":{"f2bbe2c4":"#Importing required Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","b2b221fc":"# Reading the dataset\ndataset = pd.read_csv('..\/input\/reviews\/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)","d4b60f71":"dataset.head()","42606b18":"dataset.shape","0ff0d759":"# Preprocessing\nnltk.download('stopwords')\ncorpus = []\nfor i in range(0, 1000):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","528202e0":"# Creating the Bag of Words model\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, 1].values","47d066b7":"# Splitting the dataset into the Training set and Test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","9a978022":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","dda9c1cf":"#Clasiification\n\n# Naive Bayes\nNB_classifier = GaussianNB()\nNB_classifier.fit(X_train, y_train)\ny_pred_NB = NB_classifier.predict(X_test)\n\n# Random Forest\nrf_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf_classifier.fit(X_train, y_train)\ny_pred_rf = rf_classifier.predict(X_test)\n\n#Support Vector Machine\nSVC_classifier = SVC(kernel = 'rbf')\nSVC_classifier.fit(X_train, y_train)\ny_pred_SVC = SVC_classifier.predict(X_test)","49289386":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","a0a5c075":"accuracy_score(y_test, y_pred_NB)","552d5eb3":"print(classification_report(y_test, y_pred_NB))","976aed83":"accuracy_score(y_test, y_pred_rf)","b26d1078":"print(classification_report(y_test, y_pred_rf))","e2728f68":"accuracy_score(y_test, y_pred_SVC)","5fe615a9":"print(classification_report(y_test, y_pred_SVC))","c4199b1f":"#CAP Analysis\ntotal = len(y_test) \none_count = np.sum(y_test) \nzero_count = total - one_count \nlm_NB = [y for _, y in sorted(zip(y_pred_NB, y_test), reverse = True)] \nlm_SVC = [y for _, y in sorted(zip(y_pred_SVC, y_test), reverse = True)] \nlm_RandFor = [y for _, y in sorted(zip(y_pred_rf, y_test), reverse = True)] \nx = np.arange(0, total + 1) \ny_NB = np.append([0], np.cumsum(lm_NB)) \ny_SVC = np.append([0], np.cumsum(lm_SVC)) \ny_RandFor = np.append([0], np.cumsum(lm_RandFor)) \n\nplt.figure(figsize = (10, 10))\nplt.title('CAP Curve Analysis')\nplt.plot([0, total], [0, one_count], c = 'k', linestyle = '--', label = 'Random Model')\nplt.plot([0, one_count, total], [0, one_count, one_count], c = 'grey', linewidth = 2, label = 'Perfect Model') \nplt.plot(x, y_SVC, c = 'y', label = 'SVC', linewidth = 2)\nplt.plot(x, y_NB, c = 'b', label = 'Naive Bayes', linewidth = 2)\nplt.plot(x, y_RandFor, c = 'r', label = 'Rand Forest', linewidth = 2)\nplt.legend()","98b1124e":"Naive Bayes","c09e75a5":"# Reviews Classification Using SVC, Naive Bayes & Random Forest","58c1bbb3":"Cumulative Accuracy Profile \/ CAP Curve Analysis","1156be33":"Support Vector Machine","d64da2a6":"Random Forest"}}