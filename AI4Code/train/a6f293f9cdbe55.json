{"cell_type":{"882a95b4":"code","41afa581":"code","bb50f2c0":"code","0c2809dc":"code","6f52ea77":"code","357f5a16":"code","b7e96827":"code","00fbaab5":"code","6f01e478":"markdown","ac58329c":"markdown","5565b68f":"markdown","6c3e9720":"markdown","2b2c7df7":"markdown","77af4c18":"markdown","85997da4":"markdown"},"source":{"882a95b4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","41afa581":"data = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\ndata.head()","bb50f2c0":"labels = ['Female', 'Male']\nsize = data['Gender'].value_counts()\ncolors = ['lightgreen', 'orange']\nexplode = [0, 0.1]","0c2809dc":"X = data.iloc[:, [3, 4]].values","6f52ea77":"import scipy.cluster.hierarchy as sch\n\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward')) # Ward method tries to minimize the variance within each cluster.\nplt.title('Dendrogam', fontsize = 15)                        #minimizing the within-cluster variants.That is the variance within each cluster\nplt.xlabel('Customers')\nplt.ylabel('Euclidean Distance')\nplt.show()","357f5a16":"from sklearn.cluster import AgglomerativeClustering \nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage ='ward')","b7e96827":"y_hc=hc.fit_predict(X)","00fbaab5":"plt.scatter(X[y_hc==0, 0], X[y_hc==0, 1], s=80, c='red', label ='Cluster 1')\nplt.scatter(X[y_hc==1, 0], X[y_hc==1, 1], s=80, c='blue', label ='Cluster 2')\nplt.scatter(X[y_hc==2, 0], X[y_hc==2, 1], s=80, c='green', label ='Cluster 3')\nplt.scatter(X[y_hc==3, 0], X[y_hc==3, 1], s=80, c='cyan', label ='Cluster 4')\nplt.scatter(X[y_hc==4, 0], X[y_hc==4, 1], s=80, c='magenta', label ='Cluster 5')\nplt.title('Clusters of Customers (Hierarchical Clustering Model)')\nplt.xlabel('Annual Income(k$)')\nplt.ylabel('Spending Score(1-100')\nplt.show()\n","6f01e478":"Reference:\n* https:\/\/medium.com\/@sametgirgin\/hierarchical-clustering-model-in-5-steps-with-python-6c45087d4318\n* https:\/\/www.youtube.com\/watch?v=7xHsRkOdVwo&t=6s\n##### What does each cluster represent?\n* https:\/\/developer.squareup.com\/blog\/so-you-have-some-clusters-now-what\/","ac58329c":"## Visualization","5565b68f":"# Hierarchical  Clustering\n\nEach point is considered as a cluster. It orders rows and\/or columns based on similarity, which makes it easy to see correlation in data.\nHeatmaps often come with dendohrams.\nFirst is find out which row is most similar to each other.\nConceptually... \n1) Figure out which gene is most similar to gene #1. \n2) Figure out which genes is most similar to gene #2... (and then #3 and then #4). \n3) Of the different combinations, figure out which two genes are the most similar. Merge them into a cluster. \n4) Go back to step 1, but now treat new cluster like it's a single gene. \n\n* Cluster 1 formed first and is most similar. It has shortest branch.\n* Heirarchial clustering is usually accopanied by dendogram.\n* It indicates both similarities and orer that the clusters are formed.\n\nWhat mostsimilar means?\nEuclidean distance btw genes is used a lot.\nEuclidean distance: the distance btw the two pts.\nManhatten Distance can also be used.\nPick one that gicves u better result.\n\nDifferent ways to compare clusters:\nWe can compare the point to:\n1) The average of eacn cluster (this  is called the centroid ) \n2) The closest point in each cluster (this is called \"single-linkage\") \n3) The furthest point in each cluster (this is called \"complete-linkage\")  \n\n**The height of the branches in the \"dendrogram\" shows you what is most similar**\n\n\n\n\n\n","6c3e9720":"How do we determine the optimal number of clusters? \nWe look for the largest distance that we can vertically without crossing any horizontal line.","2b2c7df7":"### Count the number of lines on the diagram and determine the optimal number of clusters","77af4c18":"### What does each cluster represent?","85997da4":"#### Centroid Approach\n\nWe can figure out which seller from each cluster is the closest to the centroid (center point) and mark that seller as the most \u2018representative\u2019 seller for that cluster. We can then study the sellers along known dimensions or signals to come up with our best guess of the cluster profile as with the empirical approach. An alternative approach is to study the hypothetical centroid instead of the most representative element. For both approaches, we are making assumptions about how representation works within our groups, so which is the better approach of the two is strictly situational. Of course, if the variance within clusters are large, then neither the hypothetical nor empirical centroid would feel very representative of the group."}}