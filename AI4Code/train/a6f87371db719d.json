{"cell_type":{"7a2be7c6":"code","e5bad45a":"code","e2aa6e5a":"code","d729f675":"code","aa97eda4":"code","b0b7c4cc":"code","7a1d4743":"code","dc6029e5":"code","63abe2cb":"code","0a8d081f":"code","3d996f52":"code","35cb738b":"code","b51db25e":"code","838fb41b":"code","0f2ce52a":"code","39dfe464":"code","0f113f80":"code","c26bfd6b":"markdown","12097f6a":"markdown","780cb9cc":"markdown","b46a7535":"markdown","cb45b91f":"markdown","905c1e61":"markdown","00281b57":"markdown","78e90bb9":"markdown","356b8b4c":"markdown","ae730486":"markdown","17aab652":"markdown","52cc10cd":"markdown","f40e9f94":"markdown","dd4c4ce8":"markdown","f381b19d":"markdown"},"source":{"7a2be7c6":"import pandas as pd\nimport glob\nimport datetime\nimport json\nimport re\nimport numpy as np\n\n# bokeh\nfrom bokeh.io import output_notebook, push_notebook\nfrom bokeh.io import show, save, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, HoverTool, DatetimeTickFormatter, NumeralTickFormatter\nfrom bokeh.palettes import Set1_9 as palette\nfrom ipywidgets import interact, IntSlider\nimport ipywidgets as widget\noutput_notebook()\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer","e5bad45a":"root_path = '\/kaggle\/input\/CORD-19-research-challenge'\ndf_metadata = pd.read_csv('%s\/metadata.csv' % root_path)","e2aa6e5a":"def publish_time_to_datetime(publish_time):\n    if(str(publish_time) == 'nan'):\n        return_date = None\n        \n    else:\n        list_publish_time = re.split('[ -]',publish_time)\n        if len(list_publish_time) >2 :\n            try:\n                #'2020 Jan 27'\n                #'2017 Apr 7 May-Jun'\n                return_date = datetime.datetime.strptime('-'.join(list_publish_time[:3]), '%Y-%b-%d')\n\n            except :                \n                try :\n                    #'2020 03 16'\n                    return_date = datetime.datetime.strptime('-'.join(list_publish_time[:3]), '%Y-%m-%d')\n                    \n                except:\n                    #'2015 Jul-Aug'\n                    return_date = datetime.datetime.strptime('-'.join(list_publish_time[:2]), '%Y-%b')\n\n        elif len(list_publish_time) == 2:\n            #'2015 Winter' -> 1 fev            \n            if(list_publish_time[1] == 'Winter'):\n                return_date = datetime.datetime(int(list_publish_time[0]), 2, 1)\n\n            #'2015 Spring' -> 1 may            \n            elif(list_publish_time[1] == 'Spring'):\n                return_date = datetime.datetime(int(list_publish_time[0]), 5, 1)\n                \n            #'2015 Autumn' -> 1 nov\n            elif(list_publish_time[1] in ['Autumn','Fall']):\n                return_date = datetime.datetime(int(list_publish_time[0]), 11, 1)            \n            else:\n                #\"2015 Oct\"\n                return_date = datetime.datetime.strptime('-'.join(list_publish_time), '%Y-%b')\n\n        elif len(list_publish_time) == 1:\n            #'2020'\n            return_date = datetime.datetime.strptime('-'.join(list_publish_time), '%Y')\n\n    return return_date","d729f675":"%%time\n# thanks to Frank Mitchell\njson_filenames = glob.glob(f'{root_path}\/**\/*.json', recursive=True)\ndf_data = pd.DataFrame()\n\n# set a break_limit for quick test (-1 for off)\nbreak_limit = -1\nprint_debug = False\n\nfor i,file_name in enumerate(json_filenames):\n    if(print_debug):print(file_name)\n    \n    # get the sha\n    sha = file_name.split('\/')[6][:-5]\n    if(print_debug):print(sha)\n    \n    # get the all_sources information\n    df_metadata_sha = df_metadata[df_metadata['sha'] == sha]\n   \n    if(df_metadata_sha.shape[0] > 0):\n        s_metadata_sha = df_metadata_sha.iloc[0]\n    \n        # treat only if full text\n        if(s_metadata_sha['has_full_text']):\n            dict_to_append = {}\n            dict_to_append['sha'] = sha\n            dict_to_append['dir'] = file_name.split('\/')[4]\n\n            # publish time into datetime format        \n            datetime_publish_time = publish_time_to_datetime(s_metadata_sha['publish_time'])\n\n            if(datetime_publish_time is not None):\n                dict_to_append['publish_time'] = datetime_publish_time\n                dict_to_append['title'] = s_metadata_sha['title']\n\n                # thanks to Frank Mitchell\n                with open(file_name) as json_data:\n                    data = json.load(json_data)\n\n                    # get abstract\n                    abstract_list = [data['abstract'][x]['text'] for x in range(len(data['abstract']))]            \n                    abstract = \"\\n \".join(abstract_list)\n                    dict_to_append['abstract'] = abstract\n\n\n                    # get body\n                    body_list = [data['body_text'][x]['text'] for x in range(len(data['body_text']))]            \n                    body = \"\\n \".join(body_list)\n                    dict_to_append['body'] = body\n\n\n                df_data = df_data.append(dict_to_append, ignore_index=True)\n\n    else:\n        if(print_debug):print('not found')\n                \n    if (break_limit != -1):\n        if (i>break_limit):\n            break","aa97eda4":"# set sha as index\ndf_data.index = df_data['sha']\ndf_data = df_data.drop(['sha'], axis =1)","b0b7c4cc":"df_data","7a1d4743":"df_publish_month = df_data.title.groupby(df_data['publish_time'].dt.to_period(\"M\")).count()\n\nsource = ColumnDataSource(data=dict(\n    month = df_publish_month.index,\n    month_tooltips = df_publish_month.index.strftime('%Y\/%m'),\n    publication_count = df_publish_month.values\n))\n\ntooltips = [('month','@month_tooltips'),('publication_count','@publication_count')]\ntools = ['pan', 'box_zoom', 'wheel_zoom', 'reset', HoverTool(tooltips=tooltips, names=['hover_tool'])]\np = figure(plot_height=600,  plot_width=800,tooltips=tooltips, active_drag=\"pan\", active_scroll='wheel_zoom')\np.line('month','publication_count',source=source)\np.xaxis.formatter=DatetimeTickFormatter(months=[\"%Y\/%m\"])\np.title.text = 'Publication count per Month'\np.xaxis[0].axis_label = 'Months'\np.yaxis[0].axis_label = 'Publication count'\nshow(p)","dc6029e5":"%%time\ntitle_weight = 4\nabstract_weight = 2\nbody_weight = 1\n\ndef concat(s_publication):\n    s_return = ''\n    \n    # title\n    if(str(s_publication['title']) != 'nan'):\n        for i in range(title_weight + 1):\n            s_return = s_return + s_publication['title'] + ' '\n\n    # abstract\n    for i in range(abstract_weight + 1):\n        s_return = s_return + s_publication['abstract'] + ' '\n        \n    # body\n    for i in range(body_weight + 1):\n        s_return = s_return + s_publication['body'] + ' '\n        \n    return s_return\n\ndf_data['publication_processing'] = df_data.apply(concat, axis=1)","63abe2cb":"# to release memory\ndf_data = df_data.drop([['title','abstract','body']], axis = 1)","0a8d081f":"%%time\ndf_data['publication_processing'] = df_data['publication_processing'].str.lower()\ndf_data['publication_processing'] = df_data['publication_processing'].str.replace('\\n',' ')","3d996f52":"%%time\n# keep only alpha\ntokenizer = nltk.RegexpTokenizer('[A-Za-z]+')\n# by step to prevent memory error\nstep = 500\nstop = int(df_data.shape[0]\/step)+1\ns_temp = pd.Series()\nfor i in range(stop):\n    if(i == stop - 1):\n        print('tokenize publication %s to %s' % (i*step,df_data.shape[0]))\n    else:\n        print('tokenize publication %s to %s' % (i*step,(i+1)*step -1))\n    df_data['publication_processing'].iloc[i*step:(i+1)*step] = df_data['publication_processing'].iloc[i*step:(i+1)*step].apply(lambda x:tokenizer.tokenize(x))","35cb738b":"%%time\nlist_stopwords_english = list(nltk.corpus.stopwords.words('english'))\ndf_data['publication_processing'] = df_data['publication_processing'].apply(\n    lambda x:[w for w in x if not w in list_stopwords_english])","b51db25e":"%%time\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize_list(list_word):\n    list_return = []\n    for str_word in list_word:\n        list_return.append(lemmatizer.lemmatize(str_word))\n    return list_return\n    \ndf_data['publication_processing'] = df_data['publication_processing'].apply(\n    lemmatize_list)","838fb41b":"%%time\n# int8 msut be sufficient (0-255) for term frequency\ndtype='int8'\ncv = CountVectorizer(analyzer=lambda x: x, dtype=dtype)\ncounted_values = cv.fit_transform(df_data['publication_processing']).toarray()\ndf_tf = pd.DataFrame(\n    counted_values,\n    columns=cv.get_feature_names(),\n    index=df_data['publication_processing'].index\n)\n# to sparse\ndf_tf = df_tf.astype(pd.SparseDtype(dtype, 0))","0f2ce52a":"df_tf","39dfe464":"%%time\ns_word_use = df_tf[df_tf>0].count().sort_values(ascending = False)\/df_tf.shape[0]","0f113f80":"%%time\nsource = ColumnDataSource(data=dict(\n    word = s_word_use.index,\n    word_x = list(range(s_word_use.shape[0])),\n    use = s_word_use.values,\n    use_tooltips = s_word_use.apply(lambda x: '%i %%' % (100*x)).values\n))\n\ntooltips = [('word','@word'),('use','@use_tooltips')]\ntools = ['pan', 'box_zoom', 'wheel_zoom', 'reset', HoverTool(tooltips=tooltips, names=['hover_tool'])]\np = figure(plot_height=600,  plot_width=800,tooltips=tooltips, active_drag=\"pan\", active_scroll='wheel_zoom')\np.line('word_x','use',source=source)\np.title.text = 'Word use'\n\np.xaxis[0].axis_label = 'Word'\ndict_x_overrides = pd.DataFrame(s_word_use.index)[0].astype('str').to_dict()\np.xaxis.major_label_overrides = dict_x_overrides\np.xaxis.major_label_orientation = \"vertical\"\n\np.yaxis[0].axis_label = 'Use'\np.yaxis.formatter=NumeralTickFormatter(format=\"0 %%\")\nshow(p)","c26bfd6b":"There are two signs which show that the publication dates entered in metadata.csv are sometimes incorrect:\n- there is a publication peak in December each year\n- publications have publication dates in the future","12097f6a":"Load the json","780cb9cc":"publish_time to datetime function","b46a7535":"run before","cb45b91f":"Load all sources metadata","905c1e61":"Remove the stop words","00281b57":"# **Data Extraction**","78e90bb9":"Lemmatize","356b8b4c":"Problem :\n- How to differiante common word such as also, study, etc..  from medical word as virus, pathology, etc..\n- How to manage publication in no english language","ae730486":"**Term Frequency**","17aab652":"# **Publication processing**","52cc10cd":"Cleaning : lower and new line removal","f40e9f94":"Concatenation","dd4c4ce8":"# **Publish date analysis**","f381b19d":"Tokenize"}}