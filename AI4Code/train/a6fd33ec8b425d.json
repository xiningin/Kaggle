{"cell_type":{"f5a7c6ce":"code","79d6d3db":"code","acd9c0ee":"code","6f827f28":"code","6021bea6":"code","c1002184":"code","dc8e107b":"code","bd4200d1":"code","1206a321":"code","f119dc06":"code","5260f78f":"code","c2967558":"code","92e4cb3a":"code","4f92b993":"code","4179ec48":"code","71200843":"code","da9e300b":"code","521c90ee":"code","385d2941":"code","34c24c44":"code","030cccbd":"code","d658cfa4":"markdown","d127b4f7":"markdown","7afef08e":"markdown","e61aa4a3":"markdown","45c5a666":"markdown","3a2ec4f3":"markdown","7e27635e":"markdown","0af0beb3":"markdown","f9ae4aa1":"markdown","c20d5f87":"markdown","8ac503b2":"markdown","4db822c2":"markdown","79b2ec37":"markdown","fd3b83be":"markdown","f26ae2d2":"markdown","338d810e":"markdown","482ef20c":"markdown","79019a62":"markdown","740b4e49":"markdown","a35c1632":"markdown","3877d363":"markdown","5cddea06":"markdown","d94d016b":"markdown","2e3c3359":"markdown","6d7b12dd":"markdown","1dfb8062":"markdown","d32a5664":"markdown","c2025c12":"markdown","70abc3cf":"markdown"},"source":{"f5a7c6ce":"import os\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom collections import Counter, defaultdict\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.preprocessing import image\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D\nfrom keras.layers import BatchNormalization, add, GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import plot_model","79d6d3db":"!pwd\npath = '\/kaggle\/input\/fashion-small\/fashion_small\/'\ntable = 'styles.csv'\nbase = path+'resized_images\/'\n\nprint('\\nDirectory contains:\\n', os.listdir(path))\n\ndata = pd.read_csv(path+table, error_bad_lines=False, warn_bad_lines=False) ;\n\nprint('\\n CSV contains {} entries, with attributes\\n {}'.format(len(data),data.keys().values))","acd9c0ee":"# Check for exsisting images in database\n\nim_path = []  \n\nfor item_id in data['id']:\n    #\n    tmp_path = base + str(item_id) +'.jpg'\n    #\n    if os.path.exists(tmp_path):\n        im_path.append(tmp_path)\n    else:\n        data.drop(data[data.id == item_id].index, inplace=True)\n        print('Item {} Doesn\\'t exists'.format(item_id))\n\ndata['img_path'] = im_path\ndata = data.sample(frac=1, random_state=10)\ndata.dropna(inplace=True)\ndata.reset_index(drop=True, inplace=True)\ndata.tail()","6f827f28":"# > Unique values per column\n\ndata.nunique()","6021bea6":"df = data[data['masterCategory'] == 'Apparel']\n\ndf.drop_duplicates(subset='img_path', inplace=True)\n\ndf.drop(columns=['masterCategory', 'year', 'productDisplayName'], inplace=True)\n\ndf.reset_index(inplace=True, drop=True)\ndf.tail(5)","c1002184":"def disp_category(category, df, min_items=500):\n    '''\n    Display Categorical charts\n    category  :: dtpye=str, Category (attribute\/column name)\n    df        :: DataFrame to be loaded\n    min_items :: dtype=int, minimum rows to qualify as class\n    \n    returns classes to be selected for the analysis\n    '''\n    dff = df.groupby(category)\n    class_ = dff.count().sort_values(by='id')['id'].reset_index()\n    class_.columns=[category,'count']\n    \n    class_= class_[class_['count']>=min_items][category]\n    df = df[df[category].isin(class_)]\n\n    labels = df[category]\n    \n    counts = defaultdict(int)\n    for l in labels:\n         counts[l] += 1\n\n    counts_df = pd.DataFrame.from_dict(counts, orient='index')\n    counts_df.columns = ['count']\n    counts_df.sort_values('count', ascending=False, inplace=True)\n\n    fig, ax = plt.subplots()\n    ax = sns.barplot(x=counts_df.index, y=counts_df['count'], ax=ax)\n    fig.set_size_inches(10,5)\n    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=-90);\n    ax.set_title('Label: '+category.upper())\n    plt.show()\n    return class_\n\n\ndef reduce_df(df, category, class_):\n    '''\n    Remove noise points from dataFrame\n    category  :: dtpye=str, Category (attribute\/column name)\n    df        :: DataFrame to be loaded\n    class_    :: list, classes to be seleted for the analysis\n    \n    returns: clean dataFrame\n    '''\n    print('Analysing {} as feature'.format(category))\n    print('Prior Number of datapoints: {}  ::  Classes: {}'.format(len(df),\n                                                                   set(df[category])))\n    df = df[df[category].isin(class_)]\n    df.reset_index(drop=True, inplace=True)\n    print('Posterior Number of datapoints: {}  ::  Classes: {}\\n'.format(len(df),\n                                                                         set(df[category])))\n    return df","dc8e107b":"for cate in df.keys()[1:-1]:\n    class_ = disp_category(cate, df, min_items=700)\n    df = reduce_df(df, cate, class_)","bd4200d1":"# > Posterior Unique values per column\n\ndf.nunique()","1206a321":"def grid_plot(title, grouped_df, samples=2):\n    samples= len(grouped_df)\n    item_id, img_path = grouped_df['id'].values, grouped_df['img_path'].values\n    plt.figure(figsize=(7,15))\n    \n    for i in range(samples):\n        plt.subplot(len(item_id) \/ samples + 1, 3, i + 1, title=title)\n        plt.axis('off')\n        plt.imshow(mpimg.imread(img_path[i]))\n        \n\nfor cat in df.keys()[1:-1]:\n    tmp_df = df.groupby(cat)\n    for group_objects in tmp_df:\n        title = '{}:\\n  {}'.format(cat,group_objects[0])\n        grouped_df = group_objects[1].sample(n=3)\n        grid_plot(title, grouped_df)","f119dc06":"df.tail()","5260f78f":"analysis_df = df.sample(frac=0.95, random_state=10)\nanalysis_df.reset_index(drop=True, inplace=True)\n\nlabels = analysis_df.keys()[1:-1].values\nN = len(analysis_df)\n\nprint('Total nuber of Data_points {}\\nLabels {}'.format(N, labels))","c2967558":"randm = np.random.randint(0, N)\nimg = mpimg.imread(analysis_df['img_path'][randm])\n\nplt.figure(figsize=(7,7))\nplt.imshow(img)\nplt.title(str(analysis_df[labels].values[randm]))\nplt.xlabel('Product_id :: {} \\n Image shape :: {}'.format(str(analysis_df['id'][randm]), img.shape))\nplt.show()","92e4cb3a":"def load_image(path, shape=(112,112,3)):\n    image_list = np.zeros((len(path), shape[0], shape[1], shape[2]))\n    for i, fig in enumerate(path):\n        img = image.load_img(fig, color_mode='rgb', target_size=shape)\n        x = image.img_to_array(img).astype('float16')\n        x = x \/ 255.0\n        image_list[i] = x\n    return image_list\n\n\ndef load_attr(df, attr, N=None, det=False, one_hot=True):\n    le = LabelEncoder()\n    le.fit(df[attr])\n    target = le.transform(df[attr])\n    if N is None:\n        N = len(set(target))\n    if one_hot:\n        target = to_categorical(target, num_classes=N)\n    if det:\n        print('\\n{}:: \\n{}'.format(attr,le.classes_))\n        print('Target shape', target.shape)\n    return le.classes_, N, target","4f92b993":"%%time\n\nt = int(0.9*N)\n\n#----------------------------------------------------#----------------------------------------------------\n\nx_train = load_image(analysis_df['img_path'][:t])\n\ngen_names, num_gen, gender_tr = load_attr(analysis_df[:t], 'gender', det=True)\nsub_names, num_sub, subCategory_tr = load_attr(analysis_df[:t], 'subCategory', det=True)\nart_names, num_art, articleType_tr = load_attr(analysis_df[:t], 'articleType', det=True)\ncol_names, num_col, baseColour_tr = load_attr(analysis_df[:t], 'baseColour', det=True)\nsea_names, num_sea, season_tr = load_attr(analysis_df[:t], 'season', det=True)\nuse_names, num_use, usage_tr = load_attr(analysis_df[:t], 'usage', det=True)\n\n#----------------------------------------------------#----------------------------------------------------\nx_val = load_image(analysis_df['img_path'][t:-100])\n\n_, _, gender_val = load_attr(analysis_df[t:-100], 'gender', N=num_gen)\n_, _, subCategory_val = load_attr(analysis_df[t:-100], 'subCategory', N=num_sub)\n_, _, articleType_val = load_attr(analysis_df[t:-100], 'articleType', N=num_art)\n_, _, baseColour_val = load_attr(analysis_df[t:-100], 'baseColour', N=num_col)\n_, _, season_val = load_attr(analysis_df[t:-100], 'season', N=num_sea)\n_, _, usage_val = load_attr(analysis_df[t:-100], 'usage', N=num_use)\n\n#----------------------------------------------------#----------------------------------------------------\n# Last 100 images to be testset\n\n#----------------------------------------------------#----------------------------------------------------\n\ndict_ = {'gen_names' : gen_names.tolist(),\n         'sub_names' : sub_names.tolist(),\n         'art_names' : art_names.tolist(),\n         'col_names' : col_names.tolist(),\n         'sea_names' : sea_names.tolist(),\n         'use_names' : use_names.tolist()}\n\njson.dump(dict_, open('label_map.json', 'w'))\n\nprint('\\n Distinct classes (Per label):',num_gen, num_sub, num_art, num_col, num_sea, num_use)\nprint('Shape:: Train: {}, Val: {}'.format(x_train.shape, x_val.shape))","4179ec48":"class Classifier():\n    '''\n    Created on Fri Oct 18 18:02:02 2019\n    Modified on Wed Oct 23 19:46:26 2019\n    \n    @author: Bhartendu\n    \n    Contains Multi-label Multi-class architecture\n    \n    ***Arguments***\n    input_shape    :: Input shape, format : (img_rows, img_cols, channels), type='tuple'\n    pre_model      :: Pretrained model file path, file extension : '.h5', type='str'\n    \n    ***Fuctions***\n    build_model()  :: Define the CNN model (can be modified & tuned as per usecase)\n    train_model()  :: Model Training (optimizers and metrics can be modified)\n    eval_model()   :: Predict classes (in one-hot encoding)\n    '''\n    \n    def __init__(self, input_shape=(112,112,3), pre_model=None):\n        self.img_shape = input_shape\n\n        # Load\/Build Model\n        if pre_model is None:\n            self.cnn_model = self.build_model()\n        else:\n            try:\n                self.cnn_model = load_model(pre_model)\n            except OSError:\n                print('Unable to load {}'.format(pre_model))\n\n        # Compile Model\n        self.cnn_model.compile(loss='categorical_crossentropy',\n                               optimizer='adam',\n                               metrics=['accuracy'])\n        \n        plot_model(self.cnn_model, to_file='consolidated_model.png')\n        self.cnn_model.summary()\n\n\n    def custom_residual_block(self, r, channels):\n        r = BatchNormalization()(r)\n        r = Conv2D(channels, (3, 3), activation='relu')(r)\n        h = Conv2D(channels, (3, 3), padding='same', activation='relu')(r)\n        h = Conv2D(channels, (3, 3), padding='same', activation='relu')(h)\n        h = Conv2D(channels, (3, 3), padding='same', activation='relu')(h)\n        return add([h, r])\n\n\n    def build_model(self):\n        input_layer = Input(shape=self.img_shape)\n        \n        # Conv Layers\n        en_in = Conv2D(16, (5, 5), activation='relu')(input_layer)\n        h = MaxPooling2D((3, 3))(en_in)\n        \n        h = self.custom_residual_block(h, 32)\n        h = self.custom_residual_block(h, 32)\n        \n        h = self.custom_residual_block(h, 48)\n        h = self.custom_residual_block(h, 48)\n\n        h = self.custom_residual_block(h, 48)\n        h = self.custom_residual_block(h, 48)\n        \n        h = self.custom_residual_block(h, 54)\n        h = self.custom_residual_block(h, 54)\n        en_out = self.custom_residual_block(h, 54)\n\n        \n        # Dense gender\n        gen = self.custom_residual_block(en_out, 48)\n        gen = GlobalAveragePooling2D()(gen)\n        gen = Dense(100, activation='relu')(gen)\n        gen = Dropout(0.1)(gen)\n        gen = Dense(50, activation='relu')(gen)\n        gen_out = Dense(num_gen, activation='softmax', name= 'gen_out')(gen)\n\n        # Dense subCategory\n        sub = self.custom_residual_block(en_out, 48)\n        sub = GlobalAveragePooling2D()(sub)\n        sub = Dense(100, activation='relu')(sub)\n        sub = Dropout(0.1)(sub)\n        sub = Dense(50, activation='relu')(sub)\n        sub_out = Dense(num_sub, activation='softmax', name= 'sub_out')(sub)\n        \n        # Dense articleType\n        art = self.custom_residual_block(en_out, 48)\n        art = GlobalAveragePooling2D()(art)\n        art = Dense(100, activation='relu')(art)\n        art = Dropout(0.1)(art)\n        art = Dense(50, activation='relu')(art)\n        art_out = Dense(num_art, activation='softmax', name= 'art_out')(art)\n\n        # Dense baseColour\n        col = self.custom_residual_block(en_out, 48)\n        col = GlobalAveragePooling2D()(col)\n        col = Dense(100, activation='relu')(col)\n        col = Dropout(0.1)(col)\n        col = Dense(50, activation='relu')(col)\n        col_out = Dense(num_col, activation='softmax', name= 'col_out')(col)\n        \n        # Dense season\n        sea = self.custom_residual_block(en_out, 48)\n        sea = GlobalAveragePooling2D()(sea)\n        sea = Dense(100, activation='relu')(sea)\n        sea = Dropout(0.1)(sea)\n        sea = Dense(50, activation='relu')(sea)\n        sea_out = Dense(num_sea, activation='softmax', name= 'sea_out')(sea)\n\n        # Dense usage\n        use = self.custom_residual_block(en_out, 48)\n        use = GlobalAveragePooling2D()(use)\n        use = Dense(100, activation='relu')(use)\n        use = Dropout(0.1)(use)\n        use = Dense(50, activation='relu')(use)\n        use_out = Dense(num_use, activation='softmax', name='use_out')(use)\n\n        return Model(input_layer, [gen_out, sub_out, art_out, col_out, sea_out, use_out])\n    \n    \n    def train_model(self, x_train, y_train, x_val, y_val, save_path, epochs=25, batch_size=16):\n        #\n        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0,\n                                       patience=5, verbose=1,\n                                       mode='auto', restore_best_weights=True)\n        #\n        check_pointer = ModelCheckpoint(save_path, monitor='val_loss',\n                                        verbose=1, save_best_only=True,\n                                        save_weights_only=False,\n                                        mode='auto', period=1)\n        #\n        history = self.cnn_model.fit(x_train, y_train,\n                                    batch_size=batch_size,\n                                    epochs=epochs,\n                                    validation_data=(x_val, y_val),\n                                    callbacks=[early_stopping, check_pointer])\n        return history\n    \n    \n    def eval_model(self, x_test):\n        preds = self.cnn_model.predict(x_test)\n        return preds","71200843":"ce = Classifier(pre_model=None)\n\nhistory  = ce.train_model(x_train, [gender_tr, subCategory_tr, articleType_tr,\n                                    baseColour_tr, season_tr, usage_tr],\n                          x_val, [gender_val, subCategory_val, articleType_val,\n                                  baseColour_val, season_val, usage_val],\n                          save_path='consolidated_model.h5',\n                          epochs=25,\n                          batch_size=30)","da9e300b":" def learning_curves(hist):\n        '''\n        Learing curves included (losses and accuracies per label)\n        '''\n        plt.style.use('ggplot')\n        \n        epochs = range(1,len(hist['loss'])+1)\n        colors = ['b', 'g' ,'r', 'c', 'm', 'y']\n        \n        loss_ = [s for s in hist.keys() if 'loss' in s and 'val' not in s]\n        val_loss_ = [s for s in hist.keys() if 'loss' in s and 'val' in s]\n        acc_ = [s for s in hist.keys() if 'acc' in s and 'val' not in s]\n        val_acc_ = [s for s in hist.keys() if 'acc' in s and 'val' in s]\n        \n        # Loss (per label)\n        plt.figure(1, figsize=(20,10))\n        for tr, val ,c in zip(loss_, val_loss_, colors):\n            plt.plot(epochs, hist[tr], c,\n                     label='train_{} : {}'.format(tr, str(format(hist[tr][-1],'.3f'))))\n            \n            plt.plot(epochs, hist[val], '-.'+c,\n                     label='{} : {}'.format(val, str(format(hist[val][-1],'.3f'))))\n            \n        plt.title('Model Loss (Distinct labels)')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.legend(loc='upper right')\n        plt.show()\n        \n        # Accuracy (per label)\n        plt.figure(2, figsize=(20,10))\n        for tr, val, c in zip(acc_, val_acc_, colors):\n            plt.plot(epochs, hist[tr], c,\n                     label='train_{} : {}'.format(tr, str(format(hist[tr][-1],'.3f'))))\n            \n            plt.plot(epochs, hist[val], '-.'+c,\n                     label='{} : {}'.format(val, str(format(hist[val][-1],'.3f'))))\n            \n        plt.title('Model Accuracy (Distinct labels)')\n        plt.xlabel('Epochs')\n        plt.ylabel('Accuracy')\n        plt.legend(loc='lower right')\n        plt.show()\n        \nlearning_curves(history.history)","521c90ee":"class Recognize_Item(object):\n    '''\n    Created on Wed Oct 23 21:38:51 2019\n\n    @author: Bhartendu\n\n    Summary:\n\n        Ready-to-deploy class file for clothing-item-recogintion \n\n    Required:\n        image_path: path or url of the image file [Required]\n        model file: to be saved\/updated at consolidated_model.h5\n        label_dict: to be saved\/updated at label_map.json\n    '''\n\n    def __init__(self, model_path='consolidated_model.h5'):\n        self.model_path = model_path\n\n\n    def load_model(self):\n        '''\n        Load Consolidated model from utils\n        '''\n        try:\n            item_reco_model = load_model(self.model_path)\n            return item_reco_model\n        except Exception:\n            raise Exception('#-----Failed to load model file-----#')\n\n\n    def process_img(self, image_path):\n        '''\n        image: load & preprocess image file\n        '''\n        img = image.load_img(image_path, color_mode='rgb', target_size=(112,112,3))\n        x = image.img_to_array(img).astype('float32')\n        return x \/ 255.0\n\n\n    def tmp_fn(self, one_hot_labels):\n        '''\n        tmp function to manpulate all one-hot encoded values labels to --\n        -- a vector of predicted categories per labels\n        '''\n        flatten_labels = []\n        for i in range(len(one_hot_labels)):\n            flatten_labels.append(np.argmax(one_hot_labels[i], axis=-1)[0])\n        return self.class_map(flatten_labels)\n\n\n    def class_map(self, e):\n        '''\n        To convert class encoded values to actual label attributes\n        '''\n        label_map = json.load(open('label_map.json'))\n        \n        dict_ = {'gen_names' : gen_names.tolist(),\n         'sub_names' : sub_names.tolist(),\n         'art_names' : art_names.tolist(),\n         'col_names' : col_names.tolist(),\n         'sea_names' : sea_names.tolist(),\n         'use_names' : use_names.tolist()}\n        \n        gender = label_map['gen_names'][e[0]]\n        subCategory = label_map['sub_names'][e[1]]\n        articleType = label_map['art_names'][e[2]]\n        baseColour = label_map['col_names'][e[3]]\n        season = label_map['sea_names'][e[4]]\n        usage = label_map['use_names'][e[5]]\n        #\n        return [gender, subCategory, articleType, baseColour, season, usage]\n\n\n    def predict_all(self, model, image):\n        '''\n        Predict all labels\n        '''\n        x_image = np.expand_dims(image, axis=0)\n        return self.tmp_fn(model.predict(x_image))\n\n\n    def demo_results(self, image_path, ground_truth=None):\n        '''\n        To demo sample predictions\n        '''\n        image = self.process_img(image_path)\n        predicted_labels  = self.predict_all(model, image)\n        #\n        plt.figure(figsize=(5,7))\n        plt.title('Fashion: Clothing Item recognition module')\n        plt.text(0, 133, str('Predictions    : '+' | '.join(predicted_labels)),\n                 fontsize=12, color='teal')\n        #\n        if ground_truth is None:\n            pass\n        else:\n            plt.text(0, 142, str('Ground Truth : '+' | '.join(ground_truth)),\n                     fontsize=12, color='b')\n        # \n        plt.axis('off')\n        plt.imshow(image)\n        plt.show()","385d2941":"reco = Recognize_Item()\n\nglobal model\nmodel = reco.load_model()","34c24c44":"test_id = N-np.random.randint(0, 100)\nreco.demo_results(analysis_df['img_path'][test_id],\n                  ground_truth=analysis_df.ix[test_id,'gender':'usage'],)","030cccbd":"test_id = N-np.random.randint(0, 100)\nreco.demo_results(analysis_df['img_path'][test_id])","d658cfa4":"> Prediction for random image from testset","d127b4f7":"---\n## <font color='teal'> Part 3<\/font>","7afef08e":"---\n## <font color='teal'> Part 1<\/font>","e61aa4a3":"## <font color='Orange'>Training Starts..<\/font>\n\n> Set Epochs & Batch Size","45c5a666":"> Predictions vs ground_truth (from testset)","3a2ec4f3":"##### Data courtesy:\n> [Small-Fashion Dataset](https:\/\/www.kaggle.com\/paramaggarwal\/fashion-product-images-small)\n\n#### Bhartendu ([matrixB](www.linkedin.com\/in\/bhartendu-thakur-56bb6285\/)), Machine Learning & Computing \n---","7e27635e":"# <font color='Teal'> Clothing Item <\/font> <font color='red'>Recognition<\/font>\n> ---","0af0beb3":"> Sample Image description","f9ae4aa1":"### EDA outcome","c20d5f87":"### Script for prediction","8ac503b2":"## <font color='Teal'>Architecture<\/font>","4db822c2":"> Data Partitioning","79b2ec37":"> Clothing Item Recognition Model\n![Clothing Item Recognition Model](consolidated_model.png 'Consolidated Model')","fd3b83be":"> Temp functions\n1. Display Categorical charts\n2. Clean dataFrame as per minimum requirements for modelling","f26ae2d2":"> Selection a fraction of data for further anaysis","338d810e":"> Sample images (distinct labels with all classes)","482ef20c":"### Exploratory Data Analysis","79019a62":"---\n## <font color='teal'> Part 2<\/font>","740b4e49":"> Analysing Apparels from masterCategory\n\n* Removing Duplicate entries\n\n* Removing _'year'_                     :: Can't be learnt visually\n\n* Removing _'productDisplayName'_       :: Can't be learnt visually","a35c1632":"> In this notebook, a multi-label problem has been formulated to identify attributes of clothing items, labels have distinct classes against them. As a whole the model describes attributes of any clothing item within visual and dataset related constraints\n\n---\n#### Part 1\n* Initialization & Data Loading\n* Data Exploration\n\n---\n#### Part 2\n* Centralized CNN Model \n* Training with Callbacks\n\n---\n#### Part 3\n* Prediction Scripts","3877d363":"### Visualize Custom Model","5cddea06":"### <font color='orange'>Modelling (CNN Based)<\/font>","d94d016b":"### Initialization","2e3c3359":"### Final Outcome","6d7b12dd":"### Learning Curves","1dfb8062":"## Analysing labels\n\n> Minmum requirement: set minimum samples per class","d32a5664":"> Functions to --\n\n* Load & preprocess images\n\n* Categorical conversions for labels","c2025c12":"### Loading available data","70abc3cf":"> Ready to use Dataframe"}}