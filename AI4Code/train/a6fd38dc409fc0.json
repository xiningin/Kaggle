{"cell_type":{"7e61f36a":"code","540166ef":"code","af5da635":"code","36a1977a":"code","37918418":"code","5bff0342":"code","449330df":"code","e2eab165":"code","0c13835b":"code","0536d96e":"code","e36edadf":"code","989d4c0e":"code","0ca2543d":"code","303ea7d3":"code","effd25e3":"code","fdb0d23d":"code","6839bbd0":"code","f1982435":"code","cd7c181c":"code","7ee5c0d5":"code","06d9c4cb":"code","3288ddfb":"code","e41ef209":"code","528695cc":"code","d5915b1a":"code","22e69cae":"code","6edb8a20":"code","a8db930a":"code","70c8520f":"code","8e89ae30":"markdown","57550a83":"markdown","fc7e7255":"markdown","b8394893":"markdown","6959bd60":"markdown","fbd16c8f":"markdown","01c54e54":"markdown","88c0836b":"markdown","6592edd5":"markdown","457d051f":"markdown","f120d42c":"markdown","7c4f222c":"markdown","29c11351":"markdown","7d1c62f5":"markdown","98155f7b":"markdown","dd0b810f":"markdown","d21e8f22":"markdown","f728bd3b":"markdown","e954d60d":"markdown"},"source":{"7e61f36a":"import os\nimport glob\nimport re\nimport math\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","540166ef":"data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/'\n\ntrain_df = pd.read_csv(data_directory+\"train_labels.csv\")\ntrain_df['BraTS21ID5'] = [format(x, '05d') for x in train_df.BraTS21ID]\ntrain_df.head()","af5da635":"test = pd.read_csv(\n    data_directory+'sample_submission.csv')\n\ntest['BraTS21ID5'] = [format(x, '05d') for x in test.BraTS21ID]\ntest.head(3)","36a1977a":"IMAGE_SIZE = 240\nSCALE = .8\nNUM_IMAGES = 64\nMRI_TYPE = \"FLAIR\"","37918418":"# Load Single Image\ndef load_dicom_image(\n    path,\n    img_size = IMAGE_SIZE,\n    scale = SCALE):\n    '''\n    This function allows you to load a DCIM type image \n    and apply preprocessing steps such as crop, resize \n    and denoising filter to it.\n    ****************************************************\n    PARAMETERS\n    ****************************************************\n    - path : String\n        Path to the DCIM image file to load.\n    - img_size : Integer\n        Image size desired for resizing.\n    - scale : Float\n        Desired scale for the cropped image\n    - prep : Bool\n        True for a full preprocessing with\n        denoising.\n    '''\n    # Load single image\n    img = dicom.read_file(path).pixel_array\n    # Crop image\n    center_x, center_y = img.shape[1] \/ 2, img.shape[0] \/ 2\n    width_scaled, height_scaled = img.shape[1] * scale, img.shape[0] * scale\n    left_x, right_x = center_x - width_scaled \/ 2, center_x + width_scaled \/ 2\n    top_y, bottom_y = center_y - height_scaled \/ 2, center_y + height_scaled \/ 2\n    img = img[int(top_y):int(bottom_y), int(left_x):int(right_x)]\n    # Resize image\n    img = cv2.resize(img, (img_size, img_size))\n    \n    # Convert in 3D array\n    img = np.repeat(img[..., np.newaxis], 3, -1)\n    \n    return img","5bff0342":"sample_img = dicom.read_file(data_directory+\"train\/00046\/FLAIR\/Image-90.dcm\").pixel_array\n\npreproc_img = load_dicom_image(data_directory+\"train\/00046\/FLAIR\/Image-90.dcm\")\n\nfig = plt.figure(figsize = (12, 8))\nax1 = plt.subplot(1,2,1)\nax1.imshow(sample_img, cmap=\"gray\")\nax1.set_title(f\"Original image shape = {sample_img.shape}\")\nax2 = plt.subplot(1,2,2)\nax2.imshow(preproc_img[:,:,0], cmap=\"gray\")\nax2.set_title(f\"After Preprocessing = {preproc_img.shape}\")\nplt.show()","449330df":"def load_dicom_images_3d(\n    scan_id,\n    num_imgs = NUM_IMAGES,\n    img_size = IMAGE_SIZE,\n    mri_type = MRI_TYPE,\n    split = \"train\"):\n    '''\n    This function allows loading an ordered sequence \n    of x preprocessed images starting from the central \n    image of each folder.\n    ****************************************************\n    PARAMETERS\n    ****************************************************\n    - scan_id : String\n        ID of the patient to load.\n    - num_imgs : Integer\n        Number of desired images of the \n        sequence.\n    - img_size : Integer\n        Image size desired for resizing.\n    - scale : Float\n        Desired scale for the cropped image\n    - mri_type : String\n        Type of scan to load (FLAIR, T1w, \n        T1wCE, T2).\n    - split : String\n        Type of split desired : Train or Test\n    '''\n    files = sorted(glob.glob(f\"{data_directory}{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    middle = len(files) \/\/ 2\n    num_imgs2 = num_imgs \/\/ 2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]])\n    if img3d.shape[0] < num_imgs:\n        n_zero = np.zeros((num_imgs - img3d.shape[0], img_size, img_size, 3))\n        img3d = np.concatenate((img3d, n_zero), axis = 0)\n        \n    return img3d","e2eab165":"sample_seq = load_dicom_images_3d(\"00046\")\nprint(\"Shape of the sequence is :-\", sample_seq.shape)\nprint(\"Dimension of the 15th image in sequence is:-\", sample_seq[15].shape)\nfig = plt.figure(figsize = (5,5))\nplt.imshow(np.squeeze(sample_seq[15][:,:,0]), cmap=\"gray\")\nplt.show()","0c13835b":"base_resnet = keras.applications.ResNet50(\n    weights = None,\n    pooling = \"avg\",\n    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n    include_top = False)","0536d96e":"base_resnet.save_weights(\n    'base_resnet_imagenet.h5')","e36edadf":"base_resnet.load_weights(\n    '.\/base_resnet_imagenet.h5')\n","989d4c0e":"base_resnet.trainable = False","0ca2543d":"# Transfert Learning\n# listMatrix = []\n# for person in persons:\n#     listVectors = []\n#     for image in person.images:\n#         img = preprocess(image)\n#         vector = baseModel.predict(img)\n#         listVectors.append(vector)\n\n#     PatientMatrix = np.stack(listVectors)\n#     listMatrix.append(PatientMatrix)","303ea7d3":"train = train_df[['BraTS21ID5','MGMT_value']]\nX_train = train['BraTS21ID5'].values\ny_train = train['MGMT_value'].values","effd25e3":"listMatrix = []\nfor i, patient in enumerate(tqdm(X_train)):\n    listVectors = []\n    sequence = load_dicom_images_3d(scan_id=str(patient),mri_type=MRI_TYPE)\n    for j in range(len(sequence)):\n        img = sequence[j]\n        img = np.expand_dims(img, axis=0)\n        img = tf.keras.applications.resnet50.preprocess_input(img)\n        img_vector = base_resnet.predict(img)\n        listVectors.append(np.array(img_vector))\n    \n    PatientMatrix = np.stack(listVectors)\n    listMatrix.append(PatientMatrix)","fdb0d23d":"print(f\"Number of Patient matrix: {len(listMatrix)}\")\nprint(f\"Patient matrix shape: {listMatrix[0].shape}\")","6839bbd0":"np.array(listMatrix, dtype = object).shape","f1982435":"model_input_dim = listMatrix[0].shape[2]\nmodel_input_dim","cd7c181c":"# Create a function for lstm model\ndef get_sequence_model():\n    '''Define the LSTM architecture'''\n    model = keras.models.Sequential()\n    model.add(keras.layers.LSTM(100, input_shape=(NUM_IMAGES, model_input_dim), return_sequences=True))\n    model.add(keras.layers.Dropout(0.2))\n    model.add(keras.layers.Dense(100, activation='relu'))\n    model.add(keras.layers.Dense(1, activation='sigmoid'))\n    return model","7ee5c0d5":"from sklearn.model_selection import KFold\n\ninputs = np.array(listMatrix)\ntargets = np.array(y_train).astype('float32').reshape((-1,1))\n\nnum_folds = 5\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nhistory = {}\nfold_no = 1\nfor train_df, valid_df in kfold.split(inputs, targets):\n    \n    train_dataset = tf.data.Dataset.from_tensor_slices((inputs[train_df], targets[train_df]))\n    valid_dataset = tf.data.Dataset.from_tensor_slices((inputs[valid_df], targets[valid_df]))\n    \n    model = get_sequence_model()\n    model.compile(loss='binary_crossentropy', \n                  optimizer='adam', \n                  metrics='accuracy')\n    \n    # Define callbacks.\n    model_save = ModelCheckpoint(f'Brain_lstm_kfold_{fold_no}.h5', \n                                 save_best_only = True, \n                                 monitor = 'val_accuracy', \n                                 mode = 'max', verbose = 1)\n    early_stop = EarlyStopping(monitor = 'val_accuracy', \n                               patience = 25, mode = 'max', verbose = 1,\n                               restore_best_weights = True)\n    \n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n    \n    epochs = 200\n    history[fold_no] = model.fit(\n        train_dataset,\n        validation_data=valid_dataset, \n        epochs=epochs, \n        batch_size=32,\n        callbacks = [model_save, early_stop])\n    \n    # Increase fold number\n    fold_no += 1","06d9c4cb":"fig , ax = plt.subplots(1 , 2, figsize=(20,7))\nax = ax.ravel()\n\nfor fold in history:\n    for i, metric in enumerate([\"accuracy\", \"loss\"]):\n        ax[i].plot(history[fold].history[metric], label=\"train\"+str(fold))\n        ax[i].plot(history[fold].history[\"val_\" + metric], linestyle=\"dotted\", label=\"val\"+str(fold))\n        ax[i].set_title(\"Model {}\".format(metric))\n        ax[i].set_xlabel(\"epochs\")\n        ax[i].set_ylabel(metric)\n        ax[i].legend()","3288ddfb":"kfold_results = pd.DataFrame(columns=[\"Fold\",\"Mean_Loss\",\"Mean_Accuracy\"])\nkey = []\nmean_loss = []\nmean_acc = []\nfor fold in history:\n    key.append(fold), \n    mean_loss.append(np.mean(history[fold].history[\"val_loss\"]))\n    mean_acc.append(np.mean(history[fold].history[\"val_accuracy\"]))\n\nkfold_results[\"Fold\"] = key\nkfold_results[\"Mean_Loss\"] = mean_loss\nkfold_results[\"Mean_Accuracy\"] = mean_acc\nkfold_results[\"Rank_Ratio\"] = (kfold_results[\"Mean_Loss\"] - kfold_results[\"Mean_Accuracy\"])\nkfold_results = kfold_results.sort_values(\"Rank_Ratio\", ascending=True)\nkfold_results","e41ef209":"best_kfold_model = '.\/Brain_lstm_kfold_' + str(kfold_results.Fold.values[0]) + '.h5'\nprint(f\"The best select model is {best_kfold_model}\")","528695cc":"X_test = test['BraTS21ID5'].values\ntest_listMatrix = []\nfor i, patient in enumerate(tqdm(X_test)):\n    test_listVectors = []\n    test_sequence = load_dicom_images_3d(scan_id=str(patient),mri_type=MRI_TYPE,split=\"test\")\n    for j in range(len(test_sequence)):\n        img = test_sequence[j]\n        img = np.expand_dims(img, axis=0)\n        img = tf.keras.applications.resnet50.preprocess_input(img)\n        img_vector = base_resnet.predict(img)\n        test_listVectors.append(np.array(img_vector))\n    \n    test_PatientMatrix = np.stack(test_listVectors)\n    test_listMatrix.append(test_PatientMatrix)","d5915b1a":"print(f\"Number of test patient matrix: {len(test_listMatrix)}\")\nprint(f\"Test patient matrix shape: {test_listMatrix[0].shape}\")","22e69cae":"test_dataset = tf.data.Dataset.from_tensor_slices(test_listMatrix)\nlen(test_dataset)","6edb8a20":"final_model = keras.models.load_model(best_kfold_model)\npredict = final_model.predict(test_dataset)\nprint(predict.shape)","a8db930a":"predict = predict[:,0,0]\nfinal_predict = []\nfor i in range(len(test_listMatrix)):\n    i+=1\n    final_predict.append(round(predict[((i-1)*NUM_IMAGES):(NUM_IMAGES*i)].mean(),3))\nsubmission = test[[\"BraTS21ID\",\"MGMT_value\"]]\nsubmission[\"MGMT_value\"] = final_predict\nsubmission.to_csv('submission.csv',index=False)\nsubmission.head(5)","70c8520f":"plt.figure(figsize=(8, 8))\nplt.hist(submission[\"MGMT_value\"])\nplt.title(\"Predicted probabilites distribution on test set\", \n          fontsize=18, color=\"#0b0a2d\")\nplt.show()","8e89ae30":"We will now train this LSTM model on the matrices compiled for each patient using the Transfer Learning ResNet50.\n\nAn EarlyStopping is set up and the best model will be saved","57550a83":"# IMAGE PREPROCESSING\nFor each patient, we will carry out a pre-processing of the images by applying these different modifications:\n\n- Load an ordered sequence of 64 MRI scan\n- Crop images to reduce black borders\n- Resize image for pre-train model\n- Apply denoising filter\n- Convert each image in 3D array","fc7e7255":"## Load the Data","b8394893":"We can check the result of these different preprocessing steps on a random patient:","6959bd60":"## APPLY LSTM FOR CLASSIFICATION\nRecurrent neural networks (RNNs) are widely used in artificial intelligence when a temporal notion is involved in the data.\n\nLSTM is a complex and very powerful algorithm which will allow in our case to take into account the past elements of our sequence of images.","fbd16c8f":"## DATA\nEach independent case has a dedicated folder identified by a five-digit number. Within each of these \u201ccase\u201d folders, there are four sub-folders, each of them corresponding to each of the structural multi-parametric MRI (mpMRI) scans, in DICOM format. The exact mpMRI scans included are:\n\n- Fluid Attenuated Inversion Recovery (FLAIR)\n- T1-weighted pre-contrast (T1w)\n- T1-weighted post-contrast (T1Gd)\n- T2-weighted (T2)\n","01c54e54":"### Import Dependencies","88c0836b":"### LOAD SEQUENCE OF 64 PREPROCESSED IMAGES","6592edd5":"## PREDICT ON TEST SET WITH BEST MODEL\nWe will now create the ResNet50 matrices for the test set and make the predictions on the test patients.","457d051f":"## LOAD PRE-TRAINED RESNET50 MODEL\nTo carry out the Transfer Learning on each image of the sequence, we will load a pre-trained model thanks to Keras.applications with the pre-trained weights on ImageNet.\nAs the notebook must be without Internet for the competition, the weights are loaded separately and imported from a specially created Dataset (..\/input\/resnet-imagenet-weights).\n\nHere we will chrger the ResNet50 model, knowing that other models have been tested such as ResNet50 and Xception.\n\n","f120d42c":"We will apply this process for just one type of MRI scans (here is T1w type) for each patient. Each patient will therefore have 24 images for treatment.","7c4f222c":"Test data:-","29c11351":"Now let's look at the results of this training:","7d1c62f5":"Let us now look at the shapes of the matrices obtained following the application of this Learning Transfer:","98155f7b":"![image.png](attachment:6471aeb2-d6d0-4dfd-a35d-ff48f5695402.png)","dd0b810f":"We are also going to fix all the layers of the model so that they are not re-trained for the detection of features. The classification layer is also not loaded (include_top = False).","d21e8f22":"## CONTEXT\nThe goal of this competition, initiated by the Radiological Society of North America (RSNA) in partnership with the Medical Image Computing and Computer Assisted Intervention Society (the MICCAI Society) is to predict the methylation of the MGMT promoter, which is an important gene biomarker for treatment of brain tumors.\n\nThese predictions will be based on a database of MRI (magnetic resonance imaging) scans of several hundred patients.\n\n","f728bd3b":"## CREATE A MATRIX OF VECTORS BASE ON RESNET50 FOR EACH PATIENT SEQUENCE\nFor this part of Transfer Learning, we will not train the ResNet50 model but only perform the prediction for each image of the sequence of each patient.\nWe will thus obtain, for each image, a matrix of the model weights that we will integrate into a list to recreate the patient sequence.\nFinally, we are going to create a global matrix which will group together the sequences of x ResNet50.predict matrices for all the patients.\n\nLet's look at the pseudo-code:","e954d60d":"Here again we can test the loading of a sequence of preprocessed images for a patient:"}}