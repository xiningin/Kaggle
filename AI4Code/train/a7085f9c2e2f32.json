{"cell_type":{"2c14bd08":"code","a1d656ba":"code","d4241312":"code","c6f3c78f":"code","867ac062":"code","705d4e41":"code","e06a42df":"code","cce1d6b5":"code","3e31a85d":"code","b11c0c46":"code","14155dcb":"code","012dc179":"code","a5df8cb1":"code","3008ec91":"code","a90dad77":"code","6e2e6b0c":"code","b2f4bba0":"code","8cf4aecf":"code","34b54563":"code","d1c23dda":"code","041fda82":"code","fb8b1706":"code","2270a71d":"markdown","584128e4":"markdown","b1809fd7":"markdown","451f2404":"markdown","365ea9a5":"markdown","29b7f8ba":"markdown","6e97837f":"markdown","e3f80e6b":"markdown","c3b6a005":"markdown","27bb0d5f":"markdown","15bf4635":"markdown","6c13024c":"markdown","2e5c456d":"markdown","99f6a22b":"markdown"},"source":{"2c14bd08":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport tensorflow as tf","a1d656ba":"dataframe = pd.read_csv('\/kaggle\/input\/iba-ml1-final-project\/train.csv')\ndataframe.drop([\"Id\"], axis = 1, inplace = True)\ndataframe","d4241312":"one_hot_Rating = pd.get_dummies(dataframe.Rating,prefix=\"Rating\")\ndataframe = dataframe.drop('Rating',axis = 1)\ndataframe = dataframe.join(one_hot_Rating)\ndataframe","c6f3c78f":"dataframe.drop(dataframe[dataframe.Review_Title.isnull() & dataframe.Review.isnull()].index, inplace = True)\ndataframe = dataframe.reset_index().drop(['index'],axis = 1)\ndataframe","867ac062":"from nltk.corpus import wordnet\n\ndef get_pos(word):\n    tag = nltk.pos_tag([word])[0][1][0]\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n    element = tag_dict.get(tag)\n    if(element == \"J\" or element==\"N\" or element==\"V\" or element==\"R\"):\n        return element\n    return 'n' #it is just like for not getting the error, we pass 'n' if the pos tag couldn't found or is not in the dictionary.","705d4e41":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\n\ndataframe['Review_Title'] = dataframe['Review_Title'].fillna('None')\ndataframe['Review'] = dataframe['Review'].fillna('None')\npd.set_option('mode.chained_assignment', None)\ndataframe.Review = dataframe.Review.str.lower()\ndataframe.Review_Title = dataframe.Review_Title.str.lower()\nfor i in range(0,len(dataframe)):\n    review = re.sub('[^a-zA-z]', ' ', dataframe['Review'][i])\n    review = review.split()\n    wl = WordNetLemmatizer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')    \n    review = [wl.lemmatize(word, pos = get_pos(word)) for word in review if word not in set(all_stopwords)]\n    review = ' '.join(review)\n    dataframe['Review'][i] = review\n    \n    review_title = re.sub('[^a-zA-z]', ' ', dataframe['Review_Title'][i])\n    review_title = review_title.split()\n    review_title = [wl.lemmatize(word, pos = get_pos(word)) for word in review_title if word not in set(all_stopwords)]\n    review_title = ' '.join(review_title)\n    dataframe['Review_Title'][i] = review_title","e06a42df":"dataframe[['Review_Title','Review']]","cce1d6b5":"from sklearn.model_selection import train_test_split\nX_dataframe = dataframe.iloc[:,[1,2]]\ny_dataframe = dataframe.iloc[:,-6:]\n\nX_train, X_test, y_train, y_test = train_test_split(X_dataframe,y_dataframe, stratify = y_dataframe.Recommended)","3e31a85d":"X_train_review_title_input = X_train[['Review_Title']].squeeze()\nX_train_review_input = X_train[['Review']].squeeze()\n\nX_test_review_title_input = X_test[['Review_Title']].squeeze()\nX_test_review_input = X_test[['Review']].squeeze()\n\ny_train_rating_output = y_train[['Rating_1','Rating_2','Rating_3','Rating_4','Rating_5']]\ny_train_recommended_output = y_train[['Recommended']]\n\n\ny_test_rating_output = y_test[['Rating_1','Rating_2','Rating_3','Rating_4','Rating_5']]\ny_test_recommended_output = y_test[['Recommended']]","b11c0c46":"from sklearn.feature_extraction.text import TfidfVectorizer\ntf_converter_review = TfidfVectorizer(max_features=10000)\ntf_converter_review_title = TfidfVectorizer(max_features=10000)\n\ntf_review_title = tf_converter_review_title.fit_transform(X_train_review_title_input).toarray()\ntf_review = tf_converter_review.fit_transform(X_train_review_input).toarray()\n\ntf_review_title_test = tf_converter_review_title.transform(X_test_review_title_input).toarray()\ntf_review_test = tf_converter_review.transform(X_test_review_input).toarray()","14155dcb":"tf_review_title_test.shape","012dc179":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ninput_review_title = keras.Input(shape=(tf_review_title.shape[1],), name=\"review_title\")\ninput_review = keras.Input(shape=(tf_review.shape[1],), name=\"review\")\n\ndense_review_title = layers.Dense(4,name = 'dense_review_title')(input_review_title)\ndense_review = layers.Dense(8,name = 'dense_review')(input_review)\n\nconcat_layer = layers.concatenate([dense_review_title,dense_review])\n\nrating_pred = layers.Dense(5,activation ='softmax',name=\"rating\")(concat_layer)\nrecommended_pred = layers.Dense(1,activation ='sigmoid',name=\"recommended\")(concat_layer)\n\nmodel = keras.Model(\n    inputs=[input_review_title, input_review],\n    outputs=[rating_pred, recommended_pred],\n)","a5df8cb1":"keras.utils.plot_model(model,show_shapes=True)","3008ec91":"model.compile(optimizer='adam', loss = {\"rating\": \"categorical_crossentropy\",\n                                        \"recommended\": \"binary_crossentropy\"},\n                                metrics={'rating': 'accuracy', \n                                         'recommended': 'accuracy'})","a90dad77":"callback_loss = tf.keras.callbacks.EarlyStopping(monitor='loss',patience = 5)\ncallback_accuracy = tf.keras.callbacks.EarlyStopping(monitor='val_rating_accuracy', patience = 3)\nhistory = model.fit({\"review_title\": tf_review_title,\n                     \"review\": tf_review}, \n                    {\"rating\": y_train_rating_output,\n                     \"recommended\":y_train_recommended_output}, \n                    epochs=50,batch_size=4, verbose=1, \n                    validation_data = ({\"review_title\": tf_review_title_test,\n                                        \"review\": tf_review_test},\n                                         {\"rating\": y_test_rating_output,\n                                           \"recommended\":y_test_recommended_output}),\n                   callbacks=[callback_loss, callback_accuracy], shuffle = True)","6e2e6b0c":"import matplotlib.pyplot as plt\nprint(history.history.keys())\n\nfig, axs = plt.subplots(2, 2, figsize = (20,10))\naxs[0, 0].plot(history.history['rating_loss'])\naxs[0, 0].set_title('rating_loss')\naxs[0, 1].plot(history.history['recommended_loss'], 'tab:orange')\naxs[0, 1].set_title('recommended_loss]')\naxs[1, 0].plot(history.history['val_rating_loss'], 'tab:green')\naxs[1, 0].set_title('val_rating_loss')\naxs[1, 1].plot(history.history['val_recommended_loss'], 'tab:red')\naxs[1, 1].set_title('val_recommended_loss')","b2f4bba0":"test_dataframe = pd.read_csv('\/kaggle\/input\/iba-ml1-final-project\/test.csv')\ntest_dataframe_Id = test_dataframe[\"Id\"]\ntest_dataframe.drop([\"Id\"], axis = 1, inplace = True)\ntest_dataframe","8cf4aecf":"test_dataframe['Review_Title'] = test_dataframe['Review_Title'].fillna('None')\ntest_dataframe['Review'] = test_dataframe['Review'].fillna('None')\n#Now\ntest_dataframe.Review = test_dataframe.Review.str.lower()\ntest_dataframe.Review_Title = test_dataframe.Review_Title.str.lower()\nfor i in range(0,len(test_dataframe)):\n    review = re.sub('[^a-zA-z]', ' ', test_dataframe['Review'][i])\n    review = review.split()\n    wl = WordNetLemmatizer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')    \n    review = [wl.lemmatize(word, pos = get_pos(word)) for word in review if word not in set(all_stopwords)]\n    review = ' '.join(review)\n    test_dataframe['Review'][i] = review\n    \n    review_title = re.sub('[^a-zA-z]', ' ', test_dataframe['Review_Title'][i])\n    review_title = review_title.split()\n    review_title = [wl.lemmatize(word, pos = get_pos(word)) for word in review_title if word not in set(all_stopwords)]\n    review_title = ' '.join(review_title)\n    test_dataframe['Review_Title'][i] = review_title","34b54563":"test_df_review_title_input = tf_converter_review_title.transform(test_dataframe[['Review_Title']].squeeze()).toarray()\ntest_df_review_input = tf_converter_review.transform(test_dataframe[['Review']].squeeze()).toarray()","d1c23dda":"test_pred = model.predict({\"review_title\": test_df_review_title_input,\n                           \"review\": test_df_review_input})","041fda82":"rating_answer = np.argmax(np.array(test_pred[0]),axis=1)+1\nrecom_answer = (test_pred[1] > 0.5).astype(int).flatten()","fb8b1706":"df_answer = pd.DataFrame({\"Id\":test_dataframe_Id,\n                          \"Rating\":rating_answer,\n                          \"Recommended\": recom_answer})\ndf_answer","2270a71d":"## Applying to the test set\n","584128e4":"Applying the same NLP techniques\n\n","b1809fd7":"# Model","451f2404":"Seperate columns for input","365ea9a5":"Let's put them to the pandas dataframe with proper columns","29b7f8ba":"Change the probabilities to appropriate numbers.","6e97837f":"This code shows the demonstration of bag of words. (It is just for requirement)","e3f80e6b":"As you can see the bag of words approach is too bad for this task","c3b6a005":"# Interpretation","27bb0d5f":"EDA processes is almost same as the main program","15bf4635":"# EDA","6c13024c":"Now let's create our model. As I said, we will use function api for it.","2e5c456d":"Importing main libraries","99f6a22b":"Now let's predict our model"}}