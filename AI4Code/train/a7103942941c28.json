{"cell_type":{"c90060c8":"code","41adb1c0":"code","d1aa00f6":"code","d64fafd8":"code","061dd211":"code","8098d048":"code","78676d58":"code","acf44337":"code","181bdb28":"code","889a5f87":"code","4c502b63":"code","22dba94a":"code","2ef62bab":"code","f2b8283f":"code","ddd3d1d7":"code","c2520d6b":"code","ea1ed26e":"code","db080747":"code","aad271b8":"code","e52a36f6":"code","b381d945":"code","590870ef":"code","d03080e9":"code","2c506392":"code","b3f91d66":"code","61caf681":"code","98e888bf":"code","5776821d":"code","0ef9422b":"code","6f71ed69":"code","f9f9f4d9":"code","0ed434f8":"code","6747723f":"code","d89d0a2a":"code","c61e51cb":"code","3ba0a79c":"code","68af738b":"code","6e8b9995":"code","6ae9743f":"code","0c2d18b3":"code","7e62a081":"code","2c83ac40":"code","ad2a388f":"code","91ba247e":"code","e57165c2":"code","7b5007de":"code","7e04e79d":"code","6f361b0a":"code","7038476b":"code","395235dc":"code","a720fa5a":"code","68f171e4":"code","8b34d8f8":"code","17e07b93":"code","150b0d52":"code","0ea202b2":"code","fd50decf":"code","1dd82788":"code","eb00c69e":"code","e558deee":"code","308c62f8":"code","d0c2214a":"code","5805e835":"code","d0f01df1":"code","23dc2553":"code","1c681330":"code","6d466251":"code","937820dc":"code","59738576":"code","cc8d4f19":"code","8617e98f":"code","fa8143cc":"code","050cd293":"code","a0bd905e":"code","a4a4623a":"code","670c4e81":"code","bf6fe1b4":"code","a8814a9e":"code","cf335a5d":"code","51a61566":"code","2567c748":"code","f1a699ee":"code","2d63f354":"markdown","f1cc7f9a":"markdown","4852a3e2":"markdown","a3b4801a":"markdown","17dd572d":"markdown","c8a418cc":"markdown","4d03bfb2":"markdown","e413cef0":"markdown","7df60207":"markdown","a55f1583":"markdown","8ce6ed42":"markdown","64e909d1":"markdown","ea55dd0d":"markdown","7b54a766":"markdown","c6dac68d":"markdown","497ac208":"markdown","6841f99f":"markdown","6513aeec":"markdown","37990f19":"markdown","cb652dd2":"markdown","3509eb99":"markdown","29c8472e":"markdown","d53373a2":"markdown","7b65aaa4":"markdown","606cd041":"markdown","375e69a3":"markdown","a6365a42":"markdown","dbd07ee0":"markdown","2945875a":"markdown","9983e8b5":"markdown","61892603":"markdown","44bd27d7":"markdown","3da5b10b":"markdown","93fdf0c2":"markdown","2e221785":"markdown","6c17abe1":"markdown","a7b0b6a1":"markdown","b516d5cb":"markdown","3fb51b08":"markdown","5f67db82":"markdown","07abf4c2":"markdown","3e342e1e":"markdown","152266df":"markdown","589c6d45":"markdown"},"source":{"c90060c8":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns  \n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","41adb1c0":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n\ntrain_data.columns","d1aa00f6":"train_data.head()","d64fafd8":"train_data.info()","061dd211":"train_data.describe()","8098d048":"def outlier_detect(feature, data):\n    outlier_index = []\n\n    for each in feature:\n        Q1 = np.percentile(data[each], 25)\n        Q3 = np.percentile(data[each], 75)\n        IQR = Q3 - Q1\n        min_quartile = Q1 - 1.5*IQR\n        max_quartile = Q3 + 1.5*IQR\n        outlier_list = data[(data[each] < min_quartile) | (data[each] > max_quartile)].index\n        outlier_index.extend(outlier_list)\n        \n    outlier_index = Counter(outlier_index)\n    #If there are three or more outlier data features we must delete them. (n)\n    outlier_data = list(i for i, n in outlier_index.items() if n > 3)\n    return outlier_data","78676d58":"outlier_data = outlier_detect([\"Age\",\"SibSp\",\"Parch\",\"Fare\"], train_data)\ntrain_data.loc[outlier_data]\n","acf44337":"train_data = train_data.drop(outlier_data, axis=0).reset_index(drop=True)","181bdb28":"data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)","889a5f87":"sns.countplot('Survived',data=train_data )\n","4c502b63":"data.describe()","22dba94a":"data.select_dtypes(include=[\"int\", \"float64\"]).columns","2ef62bab":"data[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean()","f2b8283f":"sns.factorplot(x=\"Sex\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","ddd3d1d7":"sns.factorplot(x=\"Pclass\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","c2520d6b":"sns.factorplot(x=\"Embarked\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","ea1ed26e":"sns.factorplot(x=\"SibSp\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","db080747":"sns.factorplot(x=\"Parch\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","aad271b8":"g = sns.FacetGrid(data, row=\"Survived\")\ng.map(sns.distplot, \"Age\", bins=25)\nplt.show()","e52a36f6":"g = sns.FacetGrid(data, row=\"Survived\")\ng.map(sns.distplot, \"Fare\", bins=25)\nplt.show()","b381d945":"#data[\"Sex\"] = [0 if i == \"male\" else 1 for i in data[\"Sex\"]]\ndata['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n# male: 0, famela: 1\nsns.heatmap(data[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Fare\",\"Embarked\", \"Survived\"]].corr(), annot = True)\nplt.show()","590870ef":"data.columns[data.isnull().any()]","d03080e9":"data.isnull().sum()","2c506392":"data[data[\"Fare\"].isnull()]","b3f91d66":"data[\"Fare\"] = data[\"Fare\"].fillna(np.mean(data[((data[\"Pclass\"]==3) & (data[\"Embarked\"]==0))][\"Fare\"]))\ndata[data[\"Fare\"].isnull()]","61caf681":"data[data[\"Embarked\"].isnull()]","98e888bf":"data[\"Embarked\"] = data[\"Embarked\"].fillna(1)\ndata[data[\"Embarked\"].isnull()]","5776821d":"data[data[\"Age\"].isnull()]","0ef9422b":"data_age_nan_index = data[data[\"Age\"].isnull()].index\nfor i in data_age_nan_index:\n    mean_age = data[\"Age\"][(data[\"Pclass\"]==data.iloc[i][\"Pclass\"])].median()\n    data[\"Age\"].iloc[i] = mean_age","6f71ed69":"data[\"Family\"] = data[\"SibSp\"] + data[\"Parch\"]\nsns.factorplot(x=\"Family\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","f9f9f4d9":"data[\"Alone\"] = [1 if i == 0 else 0 for i in data[\"Family\"]]\ndata[\"Family\"].replace([0,1,2,3,4,5,6,7,10], [0,1,1,1,0,2,0,2,2], inplace=True)\ndata.head()","0ed434f8":"data['Title']=data.Name.str.extract('([A-Za-z]+)\\.')","6747723f":"sns.countplot(data[\"Title\"])\nplt.xticks(rotation = 90)\nplt.show()","d89d0a2a":"data['Title'].replace(['Mme','Ms','Mlle','Lady','Countess','Dona','Dr','Major','Sir','Capt','Don','Rev','Col', 'Jonkheer'],['Miss','Miss','Miss','Mrs','Mrs','Mrs','Mr','Mr','Mr','Mr','Mr','Other','Other','Other'], inplace=True)","c61e51cb":"sns.countplot(data[\"Title\"])\nplt.show()","3ba0a79c":"sns.factorplot(x=\"Title\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","68af738b":"data[\"Title\"].replace([\"Mr\",\"Mrs\",\"Miss\",\"Master\",\"Other\"], [1,2,2,3,1], inplace=True)\n","6e8b9995":"data['Age_Limit']=pd.cut(data['Age'], 5)\ndata.groupby(['Age_Limit'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","6ae9743f":"data['Age_Limit'] = LabelEncoder().fit_transform(data['Age_Limit'])\n","0c2d18b3":"data['Fare_Limit']=pd.qcut(data['Fare'],4)\ndata.groupby(['Fare_Limit'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","7e62a081":"data['Fare_Limit'] = LabelEncoder().fit_transform(data['Fare_Limit'])\n","2c83ac40":"sns.factorplot(x=\"Fare_Limit\", y =\"Survived\", data=data, kind=\"bar\", size=3)\nplt.show()","ad2a388f":"sns.heatmap(data[[\"Cabin\",\"Pclass\",\"Embarked\",\"Sex\",\"Age\",\"Age_Limit\",\"Fare_Limit\", \"Title\",\"Family\", \"Survived\"]].corr(), annot = True)\nplt.show()","91ba247e":"data['Age']=data['Age'].astype(int)\n\ndata.drop(labels=[\"SibSp\",\"Parch\",\"Cabin\",\"Fare\",\"Age\", \"Ticket\", \"Name\", \"PassengerId\"], axis=1, inplace = True)\ndata.head()","e57165c2":"data = pd.get_dummies(data,columns=[\"Pclass\"])\ndata = pd.get_dummies(data,columns=[\"Embarked\"])\ndata = pd.get_dummies(data,columns=[\"Family\"])\ndata = pd.get_dummies(data,columns=[\"Age_Limit\"])\ndata = pd.get_dummies(data,columns=[\"Fare_Limit\"])\ndata = pd.get_dummies(data,columns=[\"Title\"])\n\ndata.head()","7b5007de":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","7e04e79d":"if len(data) == (len(train_data) + len(test_data)):\n    print(\"success\")","6f361b0a":"test = data[len(train_data):]\ntest.drop(labels=\"Survived\", axis=1, inplace=True)","7038476b":"train = data[:len(train_data)]\nX_train = train.drop(labels = \"Survived\", axis=1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n","395235dc":"log_reg = LogisticRegression(random_state=42)\nlog_reg.fit(X_train, y_train)\nprint(\"Accuracy: \", log_reg.score(X_test,y_test))","a720fa5a":"rf_reg = RandomForestClassifier(random_state=42)\nrf_reg.fit(X_train, y_train)\nprint(\"Accuracy: \", rf_reg.score(X_test,y_test))","68f171e4":"svm_clsf = SVC()\nsvm_clsf.fit(X_train, y_train)\nprint(\"Accuracy: \", svm_clsf.score(X_test,y_test))","8b34d8f8":"best_knn = []\nfor n in range(1,12):\n    knn = KNeighborsClassifier(n_neighbors=n)\n    knn.fit(X_train, y_train)\n    best_knn.insert(n, knn.score(X_test,y_test))\nbest_knn\n","17e07b93":"knn_clsf = KNeighborsClassifier(n_neighbors=8)\nknn_clsf.fit(X_train, y_train)\nprint(\"Accuracy: \", knn_clsf.score(X_test,y_test))","150b0d52":"voting_classfication = VotingClassifier(estimators = [('knn', knn_clsf),('lg', log_reg), ('rfg', rf_reg), ('svc', svm_clsf)], voting=\"hard\", n_jobs=-1)\nvoting_classfication.fit(X_train, y_train)\nprint(\"Accuracy: \", voting_classfication.score(X_test,y_test))","0ea202b2":"test_result = pd.Series(voting_classfication.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_data[\"PassengerId\"], test_result],axis = 1)\nresults.to_csv(\"titanic_submission2.csv\", index = False)","fd50decf":"from sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","1dd82788":"#I usually use Naive Bayes as a baseline for my classification tasks \ngnb = GaussianNB()\ncv = cross_val_score(gnb,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","eb00c69e":"lr = LogisticRegression(max_iter = 2000)\ncv = cross_val_score(lr,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","e558deee":"lr = LogisticRegression(max_iter = 2000)\ncv = cross_val_score(lr,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","308c62f8":"dt = tree.DecisionTreeClassifier(random_state = 1)\ncv = cross_val_score(dt,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","d0c2214a":"dt = tree.DecisionTreeClassifier(random_state = 1)\ncv = cross_val_score(dt,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","5805e835":"knn = KNeighborsClassifier()\ncv = cross_val_score(knn,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","d0f01df1":"knn = KNeighborsClassifier()\ncv = cross_val_score(knn,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","23dc2553":"rf = RandomForestClassifier(random_state = 1)\ncv = cross_val_score(rf,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","1c681330":"rf = RandomForestClassifier(random_state = 1)\ncv = cross_val_score(rf,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","6d466251":"svc = SVC(probability = True)\ncv = cross_val_score(svc,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","937820dc":"svc_poly = SVC( probability = True, kernel='poly', degree=2, gamma='auto', coef0=1, C=5)\ncv = cross_val_score(svc,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","59738576":"svc_rbf = SVC( probability = True, kernel='rbf', gamma=0.5, C=0.1)\ncv = cross_val_score(svc,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","cc8d4f19":"from xgboost import XGBClassifier\nxgb = XGBClassifier(random_state =1)\ncv = cross_val_score(xgb,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","8617e98f":"#Voting classifier takes all of the inputs and averages the results. \n#For a \"hard\" voting classifier each classifier gets 1 vote \"yes\" or \"no\" and the result is just a popular vote. For this, you generally want odd numbers\n#A \"soft\" classifier averages the confidence of each of the models. If a the average confidence is > 50% that it is a 1 it will be counted as such\nfrom sklearn.ensemble import VotingClassifier\nvoting_clf = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svc',svc),('xgb',xgb),\n                                            ('svc_poly', svc_poly), ('svc_rbf', svc_rbf) ], voting = 'soft') ","fa8143cc":"cv = cross_val_score(voting_clf,X_train,y_train,cv=5)\nprint(cv)\nprint(cv.mean())","050cd293":"svc_poly.fit(X_train,y_train)\ntest_result = pd.Series(svc_poly.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_data[\"PassengerId\"], test_result],axis = 1)\nresults.to_csv(\"titanic_submission.csv\", index = False)","a0bd905e":"from sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import RandomizedSearchCV ","a4a4623a":"#simple performance reporting function\ndef clf_performance(classifier, model_name):\n    print(model_name)\n    print('Best Score: ' + str(classifier.best_score_))\n    print('Best Parameters: ' + str(classifier.best_params_))","670c4e81":"lr = LogisticRegression()\nparam_grid = {'max_iter' : [2000],\n              'penalty' : ['l1', 'l2'],\n              'C' : np.logspace(-4, 4, 20),\n              'solver' : ['liblinear']}\n\nclf_lr = GridSearchCV(lr, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_lr = clf_lr.fit(X_train,y_train)\nclf_performance(best_clf_lr,'Logistic Regression')","bf6fe1b4":"knn = KNeighborsClassifier()\nparam_grid = {'n_neighbors' : [3,5,7,9],\n              'weights' : ['uniform', 'distance'],\n              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n              'p' : [1,2]}\nclf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_knn = clf_knn.fit(X_train,y_train)\nclf_performance(best_clf_knn,'KNN')","a8814a9e":"svc = SVC(probability = True)\nparam_grid = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n                                  'C': [.1, 1, 10, 100, 1000]},\n                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\nclf_svc = GridSearchCV(svc, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_svc = clf_svc.fit(X_train,y_train)\nclf_performance(best_clf_svc,'SVC')","cf335a5d":"rf = RandomForestClassifier(random_state = 1)\nparam_grid =  {'n_estimators': [400,450,500,550],\n               'criterion':['gini','entropy'],\n                                  'bootstrap': [True],\n                                  'max_depth': [15, 20, 25],\n                                  'max_features': ['auto','sqrt', 10],\n                                  'min_samples_leaf': [2,3],\n                                  'min_samples_split': [2,3]}\n                                  \nclf_rf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_rf = clf_rf.fit(X_train,y_train)\nclf_performance(best_clf_rf,'Random Forest')","51a61566":"best_rf = best_clf_rf.best_estimator_.fit(X_train,y_train)\nfeat_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","2567c748":"param_grid = {\n    'n_estimators': [450,500,550],\n    'colsample_bytree': [0.75,0.8,0.85],\n    'max_depth': [10],\n    'reg_alpha': [1],\n    'reg_lambda': [2, 5, 10],\n    'subsample': [0.55, 0.6, .65],\n    'learning_rate':[0.5],\n    'gamma':[.5,1,2],\n    'min_child_weight':[0.01],\n    'sampling_method': ['uniform']\n}\n\nclf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_xgb = clf_xgb.fit(X_train,y_train)\nclf_performance(best_clf_xgb,'XGB')","f1a699ee":"test_result = pd.Series(best_clf_xgb.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_data[\"PassengerId\"], test_result],axis = 1)\nresults.to_csv(\"titanic_submission1.csv\", index = False)\n","2d63f354":"<a id='8'><\/a><br>\n# Chapter-4 Data Engineering\n\n* New Feature\n* Edit Feature\n* Drop Feature\n* Normalization","f1cc7f9a":"<a id='8'><\/a><br>\n# Chapter-3 Missing Value\n\n* Find Missing Value\n* Fill Missing Value\n","4852a3e2":"### Survived","a3b4801a":"<a id='9'><\/a><br>\n## 1-Find Missing Value\n\n* Age, Fare and Cabin have missing value. Therefore we are looking at the correlation matrix.\n\nCorrelation Matrix\n* Pclass is associated with Fare.\n* Embarked is not associated with any feature.\n* Pclass and SibSp are associated with Age.","17dd572d":"# Initial Results","c8a418cc":"###\u00a0Logistic Regression","4d03bfb2":"<a id='1'><\/a><br>\n# Chapter:1 Data Load And Check","e413cef0":"###\u00a0Age Fill Value\n\nPclass and SibSp are associated with Age.","7df60207":"**Outcome**    \n\n* Sex, Pclass, Fare and Embarked are associated with Survived. \n\n\n","a55f1583":"### Parch - Survived","8ce6ed42":"<a id='18'><\/a><br>\n##\u00a02-Classificaiton Methods\n\n\n* Logistic Regression\n* Random Forest Regression\n* Support Vector Machine (SVM)\n* K-Nearest Neighbors (KNN)","64e909d1":"###\u00a0KNN\n\nelbow -> n:8 (the article will be updated)","ea55dd0d":"### Correlation Matrix","7b54a766":"<a id='3'><\/a><br>\n## 2-Combining Train and Test Data\n\n\n* Train_data and test_data are combined so that data is obtained. \n","c6dac68d":"###\u00a0Name - Title","497ac208":"### Pclass - Survived","6841f99f":" <a id='2'><\/a><br>\n## 1-Outlier Detection\n\n\n![oie_384549KoGQkTap.png](attachment:oie_384549KoGQkTap.png)\n\n* Q1 = 1.Quartile 25%\n* Q2 = 2.Quartile 50% (median)\n* Q3 = 3.Quartile 75%\n* IQR = Q3 - Q1\n* Outlier data = (Q1 - 1.5 IQR ) U (Q3 + 1.5 IQR)\n\n","6513aeec":"<a id='16'><\/a><br>\n#\u00a0Chapter:5 Modeling","37990f19":"###\u00a0Random Forest Regression","cb652dd2":"**### Age Limit","3509eb99":"> ### Fare Limit","29c8472e":" ### Fare - Survived","d53373a2":"# Model Tuned Performance","7b65aaa4":"<a id='19'><\/a><br>\n##\u00a03-\u00a0Ensemble Modeling","606cd041":"<a id='7'><\/a><br>\n## 2-Correlation Between Features","375e69a3":"### Sex - Survived\n\nFemale are more likely to survive than male.","a6365a42":"<a id='13'><\/a><br>\n##\u00a02- Drop Features\n* Ticket, Cabin, Name, PassengerId and Age are deleted according to the result of the correlation matrix.","dbd07ee0":"### Support Vector Machine (SVM)","2945875a":"# Building New Models","9983e8b5":"###\u00a0Embarked Fill Value\n\nEmbarked is not associated with any feature.\n\nS = 0,  C = 1 and Q = 2","61892603":"<a id='6'><\/a><br>\n## 1- Feature Analysis\n\n* Sex - Survived\n* Pclass - Survived\n* Embarked - Survived\n* SibSp - Survived\n* Parch - Survived\n* Age - Survived\n* Fare - Survived","44bd27d7":"<a id='4'><\/a><br>\n## 3-Feature Analysis\n\nObject\n1. Name        : \n1. Sex         : male and female\n1. Ticket      : ticket number\n1. Cabin       : cabin category\n1. Embarked    : port C, Q and S\n\nInt64\n1. PassengerId : unique id number\n1. Survived    : 0 -> died ,1-> survived\n1. Pclasss     : 1, 2 and 3 \n1. SibSp       : number of siblings\/spouse\n1. Parch       : number of parent\/children\n\nFloat64\n1. Age         : age of passenger\n1. Fare        : price of the ticket","3da5b10b":"[](http:\/\/) ### Age - Survived","93fdf0c2":"<a id='5'><\/a><br>\n# Chapter:2 Data Analysis\n\n* Feature Analysis\n* Corelation Between Features\n\n","2e221785":"### SibSp - Survived","6c17abe1":"### Embarked - Survived","a7b0b6a1":"<a id='14'><\/a><br>\n##\u00a03 - One Hot Encoding","b516d5cb":"\n\nContent of The Titanic Exploratory Data Analysis\n1. [Chapter-1 Data Load and Check](#1)\n    * [1-Outlier Detection](#2)\n    * [2-Joining Test and Train Data](#3)\n    * [3-Feature Check](#4)\n1. [Chapter-2 Data Analysis](#5)\n    * [1-Feature Analysis](#6)\n    * [2-Correlation Between Feature](#7)\n1. [Chapter-3 Missing Value](#8)\n    * [1-Find Missing Value](#9)\n    * [2-Fill Missing Value](#10)\n1. [Chapter-4 Data Engineering](#11)\n    * [1-New Feature](#12)\n    * [2-Drop Feature](#13)\n    * [3-One Hot Encoding](#14)\n1. [Chapter-5 Modeling](#16)\n    * [1-Train-Test Split](#17)\n    * [2-Classification Methods](#18)\n    * [3-Ensemble Modeling](#19)\n    * [4-Result](#20)\n\n\n   \n    \n    \n    \n    \n\n\n\n    \n    \n    ","3fb51b08":"<a id='12'><\/a><br>\n##\u00a01-New - Feature\n* Alone and Family\n* Title (Name)\n* Age Limit\n* Fare Limit","5f67db82":"# Best Results","07abf4c2":"###\u00a0Fare Fill Value\n\nPclass is associated with Fare.","3e342e1e":"<a id='17'><\/a><br>\n##\u00a01-Train Test Split","152266df":"<a id='10'><\/a><br>\n## 2-Fill Missing Value\n\n*\u00a0Cabin has 1007 missing value\n*\u00a0Age has 256 missing value\n*\u00a0Embarked has 2 missing value\n*\u00a0Fare has 1 missing value\n\nNot: Survived has 418 missing value (only test value)","589c6d45":"###\u00a0Alone and Family \n* SibSp + Parch = family"}}