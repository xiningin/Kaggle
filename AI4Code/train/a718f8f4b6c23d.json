{"cell_type":{"75113c8e":"code","e4a458ff":"code","8feae9a6":"code","a5d7741e":"code","31992ae6":"code","c386dc60":"code","ab51ec09":"code","95470cd5":"code","d0463dc3":"code","1b31eaa1":"code","20af8551":"markdown","9f4dcba7":"markdown","26d3c243":"markdown","95547fc7":"markdown","eb1e1ce3":"markdown","767701b6":"markdown","de62f95c":"markdown","7896b0dd":"markdown","1932839d":"markdown","f3c97d34":"markdown","e6c3ec4b":"markdown","2e813e85":"markdown","2d7f93e8":"markdown","f2da8656":"markdown"},"source":{"75113c8e":"import pandas as pd\nfrom xgboost import XGBRegressor","e4a458ff":"train = pd.read_csv('..\/input\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/test.csv', index_col=0)","8feae9a6":"#These two DataFrames will be used to train the model.\ntrain_X = train.loc[:,:'SaleCondition'] #'SaleCondition' is the second last column before 'SalePrice'\ntrain_y = train.loc[:,'SalePrice']\n\n#This DataFrame will be used for the predictions\n#we will submit.\ntest_X = test.copy()","a5d7741e":"numeric_cols = train_X.dtypes[train_X.dtypes != 'object'].index","31992ae6":"train_X = train_X[numeric_cols]\n\ntest_X = test_X[numeric_cols]","c386dc60":"train_X = train_X.fillna(train_X.mean())\n\ntest_X = test_X.fillna(test_X.mean())","ab51ec09":"model = XGBRegressor()\n\nmodel.fit(train_X, train_y, verbose=False)","95470cd5":"predictions = model.predict(test_X)","d0463dc3":"#Create a DataFrame for our submission\nsubmission = pd.DataFrame({'Id':test_X.index, 'SalePrice':predictions})","1b31eaa1":"#Write the submission to a 'csv' file\nsubmission.to_csv('submission.csv', index=False)","20af8551":"I'm not expecting amazing results with this submission.\nI just thought that it may be a good idea to make one of my very first competitions as simple as possible before I get deeper into 'feature-engineering'.","9f4dcba7":"Now that our DataFrames are fit for processing, we can fit our model.\n\nIn this Notebook, we will use the XBGRegressor model.","26d3c243":"# Overview:\n\nThis is a very quick and simple way to build the prediction model for the housing prices problem.\n\nTo build our model, we will drop every every column holding non-numeric values and fill in the remaining missing values with the means of each column.\n\nFinally, we will use the XGBRegressor (without any parameter tuning) on the entire training set to train our model and use it for our predictions.","95547fc7":"## Preprocess the DataFrames:","eb1e1ce3":"## Make the predictions:","767701b6":"## Load Data:","de62f95c":"We will use this list to build our new `X` DataFrames that will hold only numeric data.","7896b0dd":"### Endnote:","1932839d":"## Submission:","f3c97d34":"## Build the Model:","e6c3ec4b":"## Imports:","2e813e85":"With our model fit and our test data (test_X) in proper processing format, we may now make our predictions.","2d7f93e8":"Next, we create a list holding the names of the numeric columns in the 'train_X' DataFrame:","f2da8656":"Now that our two DataFrames contain only numeric data, we can go on and fill in the remaining missing values for each column using each column's mean."}}