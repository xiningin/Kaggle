{"cell_type":{"a36d2030":"code","97b5ed97":"code","3efcc837":"code","44356b04":"code","69a48f03":"code","79acf7dd":"code","7e7bf215":"code","b47cfa60":"code","ab9e2bae":"code","22d51861":"code","b0153189":"code","687adf94":"code","281e5a6d":"code","44f1e958":"code","1631dd8a":"code","01900454":"code","4877fa9c":"code","03a9b6a4":"code","ef3e4675":"code","569bfa50":"code","299e65fc":"code","d4f805d1":"code","51b5ef9e":"code","5fe6fbb7":"code","3cd0ecba":"code","c68107f8":"code","c7c05344":"code","858eba34":"code","f2d85358":"code","9fcb5338":"code","018eb20a":"code","4668135a":"code","b7dbe9f8":"code","178e9b83":"code","84f625af":"code","6ace0217":"code","347f5f87":"code","dca15052":"code","822fd730":"code","93591c77":"code","be4070f2":"code","665e5e9d":"code","627872b3":"code","355ebdb4":"code","222575bb":"code","613e571e":"code","33458d92":"code","e7773cfb":"code","d11a85c9":"code","d7f00250":"code","98338c93":"code","d9d7626a":"code","fed80349":"code","8e941f4d":"code","715f0b1c":"code","fecccd42":"code","bc89b45c":"code","9dc7d942":"code","a5e29814":"code","91f35032":"code","7239f65e":"code","b4b8e63b":"code","45b0747e":"code","7763404e":"code","43e0becc":"code","6913ec05":"code","a563d76a":"code","3796dcee":"code","aceb15dd":"code","f5c329e6":"code","d347640d":"code","eea38727":"code","7d49ba9e":"code","003dd47c":"code","79764604":"code","4a58e337":"code","7b5a8c05":"code","30c2125e":"code","c1158071":"code","dbbba549":"code","e3559e09":"code","2551dc69":"code","5e63c2c4":"code","d04d9dce":"code","205cc9ee":"code","5c9adddc":"code","360ad2f4":"code","b762d709":"code","dec3e469":"code","9e6ef2e4":"code","387ec269":"code","0b8f5b29":"markdown","b8085ab5":"markdown","983f154a":"markdown","7742f776":"markdown","4f41f285":"markdown","e1eb9dc5":"markdown","aa49ad9f":"markdown","778a2e97":"markdown","d4f29c68":"markdown","daf18161":"markdown","81dc03c2":"markdown","0737e1e5":"markdown","3f869cf1":"markdown","ceb82588":"markdown","d7c94580":"markdown","d858227f":"markdown","b5d4657e":"markdown","56b47431":"markdown","6eea73a1":"markdown","edd2eddb":"markdown","2941ae7a":"markdown","eb8dac0e":"markdown","36e3d653":"markdown","506ec20b":"markdown","426197de":"markdown","99435324":"markdown","77307c7c":"markdown","e63b5fad":"markdown","f35290aa":"markdown","9c069a3f":"markdown","dbf128ac":"markdown","52543a85":"markdown","0b8b6e67":"markdown","12cab160":"markdown","b2fa36a8":"markdown","e5a3e977":"markdown","35aa3380":"markdown","9e596955":"markdown","fce978bf":"markdown","99b83512":"markdown","676f8619":"markdown","a152c33a":"markdown","d31041e9":"markdown","a2228a9e":"markdown","490b79b3":"markdown","315ece4e":"markdown","d3b91054":"markdown","a984d46c":"markdown","0f71d86e":"markdown","f1f272c1":"markdown","5636f178":"markdown"},"source":{"a36d2030":"! pip install pycountry-convert\n# ! pip install calmap\n# ! pip install -Uq watermark","97b5ed97":"import torch\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport matplotlib.colors as mcolors\nfrom matplotlib import ticker \nimport pycountry_convert as pc\nimport folium\nimport branca\nfrom datetime import datetime, timedelta,date\nfrom scipy.interpolate import make_interp_spline, BSpline\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\n\nfrom matplotlib import rc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import register_matplotlib_converters\nfrom torch import nn, optim\n\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.graph_objs as gos\nfrom plotly.subplots import make_subplots\nimport matplotlib.colors as mcolors\nimport json, requests\n# import calmap\nimport operator \nimport folium\n\nfrom keras.layers import Input, Dense, Activation, LeakyReLU\nfrom keras import models\nfrom fbprophet import Prophet\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot\nfrom keras.optimizers import RMSprop, Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 14, 10\nregister_matplotlib_converters()\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","3efcc837":"confirmed_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')\ndeaths_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv')\nrecoveries_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv')\nlastupdate_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_daily_reports\/07-07-2020.csv')\nlatest_data = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/web-data\/data\/cases_time.csv\",parse_dates=['Last_Update'])\nCountry_df = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/web-data\/data\/cases_country.csv\")","44356b04":"# Read Top 2 Rows of latest_data \nlatest_data.head(2)","69a48f03":"# Read Top 2 Rows of deaths_df \ndeaths_df.head(2)","79acf7dd":"# Read Top 2 Rows of deaths_df \nrecoveries_df.head(2)","7e7bf215":"# Read Top 2 Rows of lastupdate_data\nlastupdate_data.head(2)","b47cfa60":"# Read Top 2 Rows of confirmed_df \nconfirmed_df.head(2)","ab9e2bae":"# Read Top 2 Rows of Country_df \nCountry_df.head(2)","22d51861":"confirmed_df = confirmed_df.rename(columns={\"Province\/State\":\"state\",\"Country\/Region\": \"country\"})\ndeaths_df = deaths_df.rename(columns={\"Province\/State\":\"state\",\"Country\/Region\": \"country\"})\nrecoveries_df = recoveries_df.rename(columns={\"Province\/State\":\"state\",\"Country\/Region\": \"country\"})\nCountry_df = Country_df.rename(columns={\"Country_Region\": \"country\"})","b0153189":"# Changing the conuntry names as required by pycountry_convert Lib\nconfirmed_df.loc[confirmed_df['country'] == \"US\", \"country\"] = \"USA\"\ndeaths_df.loc[deaths_df['country'] == \"US\", \"country\"] = \"USA\"\nCountry_df.loc[Country_df['country'] == \"US\", \"country\"] = \"USA\"\nrecoveries_df.loc[recoveries_df['country'] == \"US\", \"country\"] = \"USA\"\nlatest_data.loc[latest_data['Country_Region'] == \"US\", \"Country_Region\"] = \"USA\"","687adf94":"dates1 = confirmed_df.columns[4:]\n\nconfirmed_df1 = confirmed_df.melt(id_vars=['state', 'country', 'Lat', 'Long'], \n                            value_vars=dates1, var_name='Date', value_name='Confirmed')\n\ndeaths_df1 = deaths_df.melt(id_vars=['state', 'country', 'Lat', 'Long'], \n                            value_vars=dates1, var_name='Date', value_name='Deaths')\n\nrecoveries_df1 = recoveries_df.melt(id_vars=['state', 'country', 'Lat', 'Long'], \n                            value_vars=dates1, var_name='Date', value_name='Recovered')","281e5a6d":"# getting all countries\ncountries = np.asarray(confirmed_df[\"country\"])\ncountries1 = np.asarray(Country_df[\"country\"])\n\n# Continent_code to Continent_names\ncontinents = {\n    'NA': 'North America',\n    'SA': 'South America', \n    'AS': 'Asia',\n    'OC': 'Australia',\n    'AF': 'Africa',\n    'EU' : 'Europe',\n    'na' : 'Others'\n}\n\n# Defininng Function for getting continent code for country.\ndef country_to_continent_code(country):\n    try:\n        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(country))\n    except :\n        return 'na'\n\n#Collecting Continent Information\nconfirmed_df.insert(2,\"continent\", [continents[country_to_continent_code(country)] for country in countries[:]])\ndeaths_df.insert(2,\"continent\",  [continents[country_to_continent_code(country)] for country in countries[:]])\nCountry_df.insert(1,\"continent\",  [continents[country_to_continent_code(country)] for country in countries1[:]])\nlatest_data.insert(1,\"continent\",  [continents[country_to_continent_code(country)] for country in latest_data[\"Country_Region\"].values])\n#recoveries_df.insert(2,\"continent\",  [continents[country_to_continent_code(country)] for country in countries[:]] )  ","44f1e958":"# Handaling Missing data\nconfirmed_df = confirmed_df.replace(np.nan, '', regex=True)\ndeaths_df = deaths_df.replace(np.nan, '', regex=True)","1631dd8a":"Full_data = pd.merge(left=confirmed_df1, right=deaths_df1, how='left',\n                      on=['state', 'country', 'Date', 'Lat', 'Long'])\nFull_data = pd.merge(left=Full_data, right=recoveries_df1, how='left',\n                      on=['state', 'country', 'Date', 'Lat', 'Long'])\n# Active Case = confirmed - deaths - recovered\nFull_data['Active'] = Full_data['Confirmed'] - Full_data['Deaths'] - Full_data['Recovered']\nFull_data.head(5)","01900454":"# Handaling Missing data\nFull_data=Full_data.dropna(subset=['Long'])\nFull_data=Full_data.dropna(subset=['Lat'])","4877fa9c":"# latest condensed\n#latest_grouped = lastupdate_data.groupby('Country_Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\nlatest_grouped = Country_df.groupby('country')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n","03a9b6a4":"cols = confirmed_df.keys()\nconfirmed = confirmed_df.loc[:, cols[4]:cols[-1]]\ndeaths = deaths_df.loc[:, cols[4]:cols[-1]]\nrecoveries = recoveries_df.loc[:, cols[4]:cols[-1]]","ef3e4675":"dates = confirmed.keys()\nworld_cases = []\ntotal_deaths = [] \nmortality_rate = []\nrecovery_rate = [] \ntotal_recovered = [] \ntotal_active = [] \nchina_cases = [] \nitaly_cases = []\nusa_cases = [] \nspain_cases = [] \n\nfor i in dates:\n    confirmed_sum = confirmed[i].sum()\n    death_sum = deaths[i].sum()\n    recovered_sum = recoveries[i].sum()\n    \n    # confirmed, deaths, recovered, and active\n    world_cases.append(confirmed_sum)\n    total_deaths.append(death_sum)\n    total_recovered.append(recovered_sum)\n    total_active.append(confirmed_sum-death_sum-recovered_sum)\n    \n    # calculate rates\n    mortality_rate.append(death_sum\/confirmed_sum)\n    recovery_rate.append(recovered_sum\/confirmed_sum)\n\n    # case studies \n    china_cases.append(confirmed_df[confirmed_df['country']=='China'][i].sum())\n    italy_cases.append(confirmed_df[confirmed_df['country']=='Italy'][i].sum())\n    usa_cases.append(confirmed_df[confirmed_df['country']=='USA'][i].sum())\n    spain_cases.append(confirmed_df[confirmed_df['country']=='Spain'][i].sum())","569bfa50":"def daily_increase(data):\n    d = [] \n    for i in range(len(data)):\n        if i == 0:\n            d.append(data[0])\n        else:\n            d.append(data[i]-data[i-1])\n    return d \n\nworld_daily_increase = daily_increase(world_cases)\nchina_daily_increase = daily_increase(china_cases)\nitaly_daily_increase = daily_increase(italy_cases)\nusa_daily_increase = daily_increase(usa_cases)\nspain_daily_increase = daily_increase(spain_cases)","299e65fc":"days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)\nworld_cases = np.array(world_cases).reshape(-1, 1)\ntotal_deaths = np.array(total_deaths).reshape(-1, 1)\ntotal_recovered = np.array(total_recovered).reshape(-1, 1)","d4f805d1":"# Cases over time\ndef scatterPlotCasesOverTime(df, country):\n    plot = make_subplots(rows=2, cols=2, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\", \"Active\"))\n\n    subPlot1 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Confirmed'],\n                    name=\"Confirmed\",\n                    line_color='orange',\n                    opacity=0.8)\n\n    subPlot2 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Deaths'],\n                    name=\"Deaths\",\n                    line_color='red',\n                    opacity=0.8)\n\n    subPlot3 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Recovered'],\n                    name=\"Recovered\",\n                    line_color='green',\n                    opacity=0.8)\n    \n    subPlot4 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Active'],\n                    name=\"Active\",\n                    line_color='blue',\n                    opacity=0.8)\n\n    plot.append_trace(subPlot1, 1, 1)\n    plot.append_trace(subPlot2, 1, 2)\n    plot.append_trace(subPlot3, 2, 1)\n    plot.append_trace(subPlot4, 2, 2)\n    plot.update_layout(template=\"ggplot2\", title_text = country + '<b> - Spread of the nCov Over Time<\/b>')\n\n    plot.show()","51b5ef9e":"# For Future forcasting\ndays_in_future = 10\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-10]","5fe6fbb7":"df_countries_cases = Country_df.copy().drop(['Lat','Long_','continent','Last_Update'],axis =1)\ndf_countries_cases.index = df_countries_cases[\"country\"]\ndf_countries_cases = df_countries_cases.drop(['country'],axis=1)\n\ndf_continents_cases = Country_df.copy().drop(['Lat','Long_','country','Last_Update'],axis =1)\ndf_continents_cases = df_continents_cases.groupby([\"continent\"]).sum()","3cd0ecba":"df_t = pd.DataFrame(pd.to_numeric(df_countries_cases.sum()),dtype=np.float64).transpose()\ndf_t[\"Mortality Rate (per 100)\"] = np.round(100*df_t[\"Deaths\"]\/df_t[\"Confirmed\"],2)\ndf_t.style.background_gradient(cmap='Wistia',axis=1).format(\"{:.0f}\",subset=[\"Confirmed\"])","c68107f8":"# For each single countries\nunique_countries =  list(Country_df['country'].unique())","c7c05344":"country_confirmed_cases = []\ncountry_death_cases = [] \ncountry_recovery_cases = []\ncountry_active_cases = []\ncountry_mortality_rate = [] \n\n\nno_cases = []\nfor i in unique_countries:\n    cases = Country_df[Country_df['country']==i]['Confirmed'].sum()\n    if cases > 0:\n        country_confirmed_cases.append(cases)\n    else:\n        no_cases.append(i)\n        \nfor i in no_cases:\n    unique_countries.remove(i)\n# sort countries by the number of confirmed cases\nunique_countries = [k for k, v in sorted(zip(unique_countries, country_confirmed_cases), key=operator.itemgetter(1), reverse=True)]\nfor i in range(len(unique_countries)):\n    country_confirmed_cases[i] = Country_df[Country_df['country']==unique_countries[i]]['Confirmed'].sum()\n    country_death_cases.append(Country_df[Country_df['country']==unique_countries[i]]['Deaths'].sum())\n    country_recovery_cases.append(Country_df[Country_df['country']==unique_countries[i]]['Recovered'].sum())\n    country_active_cases.append(Country_df[Country_df['country']==unique_countries[i]]['Active'].sum())\n    country_mortality_rate.append((country_death_cases[i]\/country_confirmed_cases[i])*100)","858eba34":"country_df = pd.DataFrame({'Country Name': unique_countries, 'Number of Confirmed Cases': country_confirmed_cases,\n                          'Number of Deaths': country_death_cases, 'Number of Recoveries' : country_recovery_cases,\n                           'Number of Active': country_active_cases, 'Mortality Rate': country_mortality_rate})\n\n# number of cases per country\/region\ncountry_df.style.background_gradient(cmap=\"Wistia\", subset=['Number of Confirmed Cases'])\\\n                .background_gradient(cmap=\"Reds\", subset=['Number of Deaths'])\\\n                .background_gradient(cmap=\"summer\", subset=['Number of Recoveries'])\\\n                .background_gradient(cmap=\"OrRd\", subset=['Number of Active'])","f2d85358":"adjusted_dates = adjusted_dates.reshape(1, -1)[0]\nplt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, world_cases)\nplt.title('No. of Coronavirus Cases Over Time', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","9fcb5338":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, world_daily_increase)\nplt.title('World Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","018eb20a":"plt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, world_cases, color='b')\nplt.plot(adjusted_dates, total_deaths, color='r')\nplt.plot(adjusted_dates, total_recovered, color='green')\nplt.title('No. of Coronavirus Total cases vs Death cases vs Recovered Cases', size=25)\nplt.legend(['Cases','Death','Recoveries' ], loc='best', fontsize=20)\nplt.xlabel('Days Since 1\/22\/2020', size=30)\nplt.ylabel('No. of Cases', size=30)\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","4668135a":"mean_mortality_rate = np.mean(mortality_rate)\nplt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, mortality_rate, color='orange')\nplt.axhline(y = mean_mortality_rate,linestyle='--', color='black')\nplt.title('Mortality Rate of Coronavirus Over Time', size=30)\nplt.legend(['mortality rate', 'y='+str(mean_mortality_rate)], prop={'size': 20})\nplt.xlabel('Days Since 1\/22\/2020', size=30)\nplt.ylabel('Mortality Rate', size=30)\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","b7dbe9f8":"df_countries_cases.groupby('country')['Confirmed'].sum().sort_values(ascending=False)[:10]","178e9b83":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\nout = \"\"\nplt.axes(axisbelow=True)\nplt.barh(df_countries_cases.sort_values('Confirmed')[\"Confirmed\"].index[-10:],df_countries_cases.sort_values('Confirmed')[\"Confirmed\"].values[-10:],color=\"deepskyblue\")\n#color=\"darkcyan\"\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Confirmed Cases\",fontsize=18)\nplt.title(\"Top 10 Countries Under Corona Confirmed Cases\",fontsize=20)\nplt.grid(alpha=0.3)\nplt.savefig(out+'Top 10 Countries (Confirmed Cases).png')","84f625af":"df_countries_cases.groupby('country')['Deaths'].sum().sort_values(ascending=False)[:10]","6ace0217":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_countries_cases.sort_values('Deaths')[\"Deaths\"].index[-10:],df_countries_cases.sort_values('Deaths')[\"Deaths\"].values[-10:],color=\"crimson\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Deaths Cases\",fontsize=18)\nplt.title(\"Top 10 Countries Under Corona Deaths Cases\",fontsize=20)\nplt.grid(alpha=0.3,which='both')\nplt.savefig(out+'Top 10 Countries (Deaths Cases).png')","347f5f87":"df_countries_cases.groupby('country')['Recovered'].sum().sort_values(ascending=False)[:10]","dca15052":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_countries_cases.sort_values('Recovered')[\"Recovered\"].index[-10:],df_countries_cases.sort_values('Recovered')[\"Recovered\"].values[-10:],color=\"yellowgreen\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Recovered Cases\",fontsize=18)\nplt.title(\"Top 10 Countries Under Corona Recovered Cases\",fontsize=20)\nplt.grid(alpha=0.3,which='both')\nplt.savefig(out+'Top 10 Countries (Recovered Cases).png')","822fd730":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, usa_daily_increase)\nplt.title('US Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","93591c77":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, china_daily_increase)\nplt.title('China Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","be4070f2":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, italy_daily_increase)\nplt.title('Italy Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","665e5e9d":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, spain_daily_increase)\nplt.title('Spain Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","627872b3":"plt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, usa_cases)\nplt.plot(adjusted_dates, china_cases)\nplt.plot(adjusted_dates, italy_cases)\nplt.plot(adjusted_dates, spain_cases)\nplt.title('No. of Coronavirus Cases', size=25)\nplt.xlabel('Days Since 1\/22\/2020', size=22)\nplt.ylabel('No. of Cases', size=25)\nplt.legend(['US', 'China', 'Italy', 'Spain'], prop={'size': 20})\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","355ebdb4":"# Confirmed\nfig = px.choropleth(latest_grouped, locations=\"country\", \n                    locationmode='country names', color=np.log(latest_grouped[\"Confirmed\"]), \n                    hover_name=\"country\", hover_data=['Confirmed'],\n                    color_continuous_scale=\"Sunsetdark\", \n                    title='Countries with Confirmed Cases')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","222575bb":"# Deaths\ntemp = latest_grouped[latest_grouped['Deaths']>0]\nfig = px.choropleth(temp, \n                    locations=\"country\", locationmode='country names',\n                    color=np.log(temp[\"Deaths\"]), hover_name=\"country\", \n                    color_continuous_scale=\"Peach\", hover_data=['Deaths'],\n                    title='Countries with Deaths Reported')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","613e571e":"formated_gdf = Full_data.groupby(['Date', 'country'])['Confirmed', 'Deaths'].max().reset_index()\nformated_gdf['size'] = formated_gdf['Confirmed'].pow(0.2)\n\nfig = px.scatter_geo(formated_gdf, locations=\"country\", locationmode='country names', \n                     color=\"Confirmed\", size='size', hover_name=\"country\", \n                     range_color= [0, max(formated_gdf['Confirmed'])+2], animation_frame=\"Date\", \n                     title='Spread over time')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","33458d92":"'''\n# World wide\n\nm = folium.Map(location=[0, 0], tiles='cartodbpositron',\n               min_zoom=1, max_zoom=4, zoom_start=1)\n\nfor i in range(0, len(Full_data)):\n    folium.Circle(\n        location=[Full_data.iloc[i]['Lat'], Full_data.iloc[i]['Long']],\n        color='crimson', \n        tooltip =   '<li><bold>Country : '+str(Full_data.iloc[i]['country'])+\n                    '<li><bold>Province : '+str(Full_data.iloc[i]['state'])+\n                    '<li><bold>Confirmed : '+str(Full_data.iloc[i]['Confirmed'])+\n                    '<li><bold>Deaths : '+str(Full_data.iloc[i]['Deaths']),\n        radius=int(Full_data.iloc[i]['Confirmed'])**1.1).add_to(m)\nm\n'''","e7773cfb":"df_usa = lastupdate_data.loc[lastupdate_data[\"Country_Region\"]== \"US\"]\ndf_usa.head(2)\n#df_usa = df_usa.rename(columns={\"Admin2\":\"County\"})","d11a85c9":"total = df_usa.sum()\ntotal.name = \"Total\"\npd.DataFrame(total).transpose().loc[:,[\"Confirmed\",\"Deaths\"]].style.background_gradient(cmap='Purples',axis=1)","d7f00250":"df_usa.loc[:,[\"Confirmed\",\"Deaths\",\"Province_State\"]].groupby([\"Province_State\"]).sum().sort_values(\"Confirmed\",ascending=False).style.background_gradient(cmap='Blues',subset=[\"Confirmed\"]).background_gradient(cmap='Reds',subset=[\"Deaths\"])","98338c93":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_usa.groupby([\"Province_State\"]).sum().sort_values('Confirmed')[\"Confirmed\"].index[-10:],df_usa.groupby([\"Province_State\"]).sum().sort_values('Confirmed')[\"Confirmed\"].values[-10:],color=\"salmon\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Confirmed Cases\",fontsize=18)\nplt.title(\"Top 10 States: USA (Confirmed Cases)\",fontsize=20)\nplt.grid(alpha=0.3)\nplt.savefig(out+'Top 10 States_USA (Confirmed Cases).png')","d9d7626a":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_usa.groupby([\"Province_State\"]).sum().sort_values('Deaths')[\"Deaths\"].index[-10:],df_usa.groupby([\"Province_State\"]).sum().sort_values('Deaths')[\"Deaths\"].values[-10:],color=\"crimson\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Deaths\",fontsize=18)\nplt.title(\"Top 10 States: USA (Deaths Cases)\",fontsize=20)\nplt.grid(alpha=0.3)\nplt.savefig(out+'Top 10 States_USA (Deaths Cases).png')","fed80349":"Full_data.head()","8e941f4d":"df_usa_data = Full_data.loc[Full_data[\"country\"]== \"USA\"]\n#df_usa_data['Last_Update'] =  pd.to_datetime(df_usa_data['Last_Update'])\n#df_usa_data['Last_Update'] = df_usa_data['Last_Update'].dt.date\n#df_usa_data = df_usa_data.rename(columns={\"Last_Update\":\"Date\"})\ndf1 =  df_usa_data[['Date','Confirmed','Deaths','Recovered','Active']]\ndf1.head()\n","715f0b1c":"# USA - Cases over time\nscatterPlotCasesOverTime(df1, \"<b>USA<\/b>\")","fecccd42":"df_usa = df_usa.rename(columns={\"Admin2\":\"County\"})\ndf_usa = df_usa.replace(np.nan, 0, regex=True)\nusa = folium.Map(location=[37, -102], tiles='cartodbpositron', min_zoom=4, max_zoom=8, zoom_start=4)\nfor i in np.int32(np.asarray(df_usa[df_usa['Confirmed'] > 0].index)):\n    folium.Circle(\n        location=[df_usa.loc[i]['Lat'], df_usa.loc[i]['Long_']],\n        tooltip = \"<h5 style='text-align:center;font-weight: bold'>\"+df_usa.loc[i]['Province_State']+\"<\/h5>\"+\n                    \"<div style='text-align:center;'>\"+str(np.nan_to_num(df_usa.loc[i]['County']))+\"<\/div>\"+\n                    \"<hr style='margin:10px;'>\"+\n                    \"<ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n        \"<li>Confirmed: \"+str(df_usa.loc[i]['Confirmed'])+\n        \"<li>Active:   \"+str(df_usa.loc[i]['Active'])+\n        \"<li>Recovered:   \"+str(df_usa.loc[i]['Recovered'])+     \n        \"<li>Deaths:   \"+str(df_usa.loc[i]['Deaths'])+\n        \"<li>Mortality Rate:   \"+str(np.round(df_usa.loc[i]['Deaths']\/(df_usa.loc[i]['Confirmed']+1)*100,2))\n\n        ,\n        radius=int((np.log2(df_usa.loc[i]['Confirmed']+1))*6000),\n        color='yellowgreen',\n        fill_color='red',\n        fill=True).add_to(usa)\n\nusa\n","bc89b45c":"state_geo = requests.get('https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data\/us-states.json').json()\ncounty_geo = requests.get('https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data\/us_counties_20m_topo.json').json()\n# county_geo","9dc7d942":"# binsurl = 'https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data'\n# county_data = f'{url}\/us_county_data.csv'\n# county_geo = f'{url}\/us_counties_20m_topo.json'\n\ndata_temp = df_usa.groupby([\"FIPS\"]).sum().reset_index().drop([\"Lat\",\"Long_\"],axis=1)\ndata_temp[\"Confirmed_log\"] = np.log10(data_temp[\"Confirmed\"]+1)\n\ndf_usa_series = data_temp.set_index('FIPS')['Confirmed_log']\ncolorscale = branca.colormap.linear.Reds_09.scale(0,data_temp[\"Confirmed_log\"].max()-1)\n# print(df_usa_series.max())\ndef style_function(feature):\n    employed = df_usa_series.get(int(feature['id'][-5:]), 0)\n    return {\n        'fillOpacity': 0.5,\n        'weight': 0,\n        'fillColor': '#black' if employed is None else colorscale(employed)\n    }\n\n\nm = folium.Map(\n    location=[37, -102],\n    tiles='cartodbpositron',\n    zoom_start=4,\n    min_zoom=3,\n    max_zoom=7\n)\n\nfolium.TopoJson(\n    county_geo,\n    'objects.us_counties_20m',\n    style_function=style_function\n).add_to(m)\nm","a5e29814":"df_usa1 = confirmed_df.loc[confirmed_df[\"country\"]== \"USA\"]\ndf_usa1.head(2)","91f35032":"temp = df_usa1.melt(value_vars=dates1, var_name='Date', value_name='Confirmed')\ntemp = temp.groupby('Date')['Confirmed'].sum().reset_index()\n#Full_data[['Date','Confirmed']]\npr_data = pd.DataFrame(temp)\n\npr_data.columns = ['ds','y']\npr_data","7239f65e":"m=Prophet()\nm.fit(temp)\nfuture=m.make_future_dataframe(periods=10)\nforecast=m.predict(future)\nforecast","b4b8e63b":"cnfrm = forecast.loc[:,['ds','trend']]\ncnfrm = cnfrm[cnfrm['trend']>0]\ncnfrm=cnfrm.tail(15)\ncnfrm.columns = ['Date','Confirm']\ncnfrm.head()","45b0747e":"fig = plot_plotly(m, forecast)\npy.iplot(fig) \n\nfig = m.plot(forecast,xlabel='Date',ylabel='Confirmed Count')","7763404e":"figure=m.plot_components(forecast)","43e0becc":"df_usa1.head()","6913ec05":"df_usa1 = df_usa1.iloc[:, 5:]","a563d76a":"df_usa1.head()","3796dcee":"daily_cases = df_usa1.sum(axis=0)\ndaily_cases.index = pd.to_datetime(daily_cases.index)\ndaily_cases.head()","aceb15dd":"plt.plot(daily_cases)\nplt.title(\"Cumulative daily cases\");","f5c329e6":"daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)\ndaily_cases.head()","d347640d":"\nplt.plot(daily_cases)\nplt.title(\"Daily cases\");","eea38727":"daily_cases.shape","7d49ba9e":"train_data=daily_cases.iloc[:int(len(daily_cases)*0.8)] \ntest_data=daily_cases.iloc[int(len(daily_cases)*0.8):]\n\ntrain_data.shape","003dd47c":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(train_data, axis=1))\n\ntrain_data = scaler.transform(np.expand_dims(train_data, axis=1))\n\ntest_data = scaler.transform(np.expand_dims(test_data, axis=1))","79764604":"def train_test_split(daily_cases):\n    size=int(len(daily_cases)*0.8)\n    # for train data will be collected from each country's data which index is from 0-size (80%)\n    x_train =daily_cases.drop(columns=['TargetValue']).iloc[0:size] \n    # for test data will be collected from each country's  data which index is from size to the end (20%)\n    x_test = daily_cases.drop(columns=['TargetValue']).iloc[size:]\n    y_train=daily_cases['TargetValue'].iloc[0:size] \n    y_test=daily_cases['TargetValue'].iloc[size:] \n    return x_train, x_test,y_train,y_test\n# unique countries\ncountry=list(set(daily_cases.country))\n# loop each station and collect train and test data \nX_train=[]\nX_test=[]\nY_train=[]\nY_test=[]\nfor i in range(0,len(country)):\n    df=data[['country']==country[i]]\n    x_train, x_test,y_train,y_test=train_test_split(df)\n    X_train.append(x_train)\n    X_test.append(x_test)\n    Y_train.append(y_train)\n    Y_test.append(y_test)\n# concat each train data from each station \nX_train=pd.concat(X_train)\nY_train=pd.DataFrame(pd.concat(Y_train))\n# concat each test data from each station \nX_test=pd.concat(X_test)\nY_test=pd.DataFrame(pd.concat(Y_test))","4a58e337":"def create_sequences(data, seq_length):\n    xs = []\n    ys = []\n\n    for i in range(len(data)-seq_length-1):\n        x = data[i:(i+seq_length)]\n        y = data[i+seq_length]\n        xs.append(x)\n        ys.append(y)\n\n    return np.array(xs), np.array(ys)","7b5a8c05":"seq_length = 5\nX_train, y_train = create_sequences(train_data, seq_length)\nX_test, y_test = create_sequences(test_data, seq_length)\n\nX_train = torch.from_numpy(X_train).float()\ny_train = torch.from_numpy(y_train).float()\n\nX_test = torch.from_numpy(X_test).float()\ny_test = torch.from_numpy(y_test).float()","30c2125e":"class CoronaVirusPredictor(nn.Module):\n\n  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n    super(CoronaVirusPredictor, self).__init__()\n\n    self.n_hidden = n_hidden\n    self.seq_len = seq_len\n    self.n_layers = n_layers\n\n    self.lstm = nn.LSTM(\n      input_size=n_features,\n      hidden_size=n_hidden,\n      num_layers=n_layers,\n      dropout=0.5\n    )\n\n    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n\n  def reset_hidden_state(self):\n    self.hidden = (\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n    )\n\n  def forward(self, sequences):\n    lstm_out, self.hidden = self.lstm(\n      sequences.view(len(sequences), self.seq_len, -1),\n      self.hidden\n    )\n    last_time_step = \\\n      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n    y_pred = self.linear(last_time_step)\n    return y_pred","c1158071":"def train_model(\n  model, \n  train_data, \n  train_labels, \n  test_data=None, \n  test_labels=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 800   # if its time consuming then set it to 500 or 100\n  train_hist = np.zeros(num_epochs)\n  test_hist = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred = model(X_train)\n\n    loss = loss_fn(y_pred.float(), y_train)\n\n    if test_data is not None:\n      with torch.no_grad():\n        y_test_pred = model(X_test)\n        test_loss = loss_fn(y_test_pred.float(), y_test)\n      test_hist[t] = test_loss.item()\n\n      if t % 1000 == 0:  \n        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n    elif t % 1000 == 0:\n      print(f'Epoch {t} train loss: {loss.item()}')\n\n    train_hist[t] = loss.item()\n    \n    optimiser.zero_grad()\n\n    loss.backward()\n\n    optimiser.step()\n  \n  return model.eval(), train_hist, test_hist","dbbba549":"model = CoronaVirusPredictor(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, train_hist, test_hist = train_model(\n  model, \n  X_train, \n  y_train, \n  X_test, \n  y_test\n)","e3559e09":"plt.plot(train_hist, label=\"Training loss\")\nplt.plot(test_hist, label=\"Test loss\")\nplt.ylim((0, 60))\nplt.legend();","2551dc69":"with torch.no_grad():\n  test_seq = X_test[:1]\n  preds = []\n  for _ in range(len(X_test)):\n    y_test_pred = model(test_seq)\n    pred = torch.flatten(y_test_pred).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()","5e63c2c4":"true_cases = scaler.inverse_transform(\n    np.expand_dims(y_test.flatten().numpy(), axis=0)\n).flatten()\n\npredicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","d04d9dce":"plt.plot(\n  daily_cases.index[:len(train_data)], \n  scaler.inverse_transform(train_data).flatten(),\n  label='Historical Daily Cases'\n)\n\nplt.plot(\n  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n  true_cases,\n  label='Real Daily Cases'\n)\n\nplt.plot(\n  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n  predicted_cases, \n  label='Predicted Daily Cases'\n)\n\nplt.legend();\n","205cc9ee":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(daily_cases, axis=1))\n\nall_data = scaler.transform(np.expand_dims(daily_cases, axis=1))\n\nall_data.shape","5c9adddc":"X_all, y_all = create_sequences(all_data, seq_length)\n\nX_all = torch.from_numpy(X_all).float()\ny_all = torch.from_numpy(y_all).float()\n\nmodel = CoronaVirusPredictor(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, train_hist, _ = train_model(model, X_all, y_all)","360ad2f4":"DAYS_TO_PREDICT = 7\n\nwith torch.no_grad():\n  test_seq = X_all[:1]\n  preds = []\n  for _ in range(DAYS_TO_PREDICT):\n    y_test_pred = model(test_seq)\n    pred = torch.flatten(y_test_pred).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()\n    ","b762d709":"predicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","dec3e469":"daily_cases.index[-1]","9e6ef2e4":"predicted_index = pd.date_range(\n  start=daily_cases.index[-1],\n  periods=DAYS_TO_PREDICT + 1,\n  closed='right'\n)\n\npredicted_cases = pd.Series(\n  data=predicted_cases,\n  index=predicted_index\n)\n\nplt.plot(predicted_cases, label='Predicted Daily Cases')\nplt.legend();","387ec269":"plt.plot(daily_cases, label='Historical Daily Cases')\nplt.plot(predicted_cases, label='Predicted Daily Cases')\nplt.legend();","0b8f5b29":"### Daily cases For USA","b8085ab5":"<font face = \"Verdana\" size =\"6\">Analysis the spreading of COVID-19 in USA. <\/font>\n<br>\n\n<h1 id=\"Corona-Virus\">Corona Virus<\/h1>\n<ul>\n<li>Coronaviruses are <strong>zoonotic<\/strong> viruses (means transmitted between animals and people).  <\/li>\n<li>Symptoms include from fever, cough, respiratory symptoms, and breathing difficulties. <\/li>\n<li>In severe cases, it can cause pneumonia, severe acute respiratory syndrome (SARS), kidney failure and even death.<\/li>\n<li>Coronaviruses are also <strong>asymptomatic<\/strong>, means a person can be a carrier for the infection but experiences no symptoms<\/li>\n<\/ul>","983f154a":"# Analysis of Data","7742f776":"#### Getting daily increases","4f41f285":"To create a cool chart with the historical and predicted cases, we need to extend the date index of our data frame:","e1eb9dc5":"## Top 10 countries (Confirmed Cases and Deaths)","aa49ad9f":"## COVID-19 : USA","778a2e97":"### Provinces where deaths have taken place","d4f29c68":"## Visualization on US Map","daf18161":"#### Rename Columns","81dc03c2":"#### 4. Mortality Rate of Coronavirus Over Time","0737e1e5":"# Predicting daily cases\nUse predicted values as input for predicting the next days:","3f869cf1":"The cases gradually increasing with sparks in USA. This will certainly be a challenge for our model.\n\nLet's check the amount of data we have:","ceb82588":"#### Two things to note here:\n\n* The data contains a province, country, latitude, and longitude. We won't be needing those.\n* The number of cases is cumulative. We'll undo the accumulation.","d7c94580":"### Lets look at the Confirmed status","d858227f":"### Most Affected States: USA","b5d4657e":"## Graphical Analysis \n\n### Graphing the number of confirmed cases, active cases, deaths, recoveries, mortality rate, and recovery rate","56b47431":"## Our CoronaVirusPredictor contains 3 methods:\n* constructor - initialize all helper data and create the layers\n* reset_hidden_state - we'll use a stateless LSTM, so we need to reset the state after each example\n* forward - get the sequences, pass all of them through the LSTM layer, at once. We take the output of the last time step and pass it through our linear layer to get the prediction.","6eea73a1":"### Lets also look at the Recovered status","edd2eddb":"## Predicting future cases","2941ae7a":"Let's look at the results:","eb8dac0e":"We have to reverse the scaling of the test data and the model predictions:","36e3d653":"As expected, our model doesn't perform very well. That said, the predictions seem to be in the right ballpark (probably due to using the last data point as a strong predictor for the next).","506ec20b":"# Imports and Datasets\n<hr> \n* Pandas - for dataset handeling\n* Numpy - Support for Pandas and calculations \n* Matplotlib - for visualization (Platting graphas)\n* pycountry_convert - Library for getting continent (name) to from their country names\n* folium - Library for Map\n* keras - Prediction Models\n* plotly - for interative plots","426197de":"Affected Counties : USA","99435324":"#### 2. World Daily Increases in Confirmed Cases","77307c7c":"# Country Base Case Analysis\n#### 1.United State","e63b5fad":"# Your Valuable Feedback is much APPRECIATED\n\n### Please UPVOTE if you LIKE this NOTEBOOK and COMMENT for any Advice\/Suggestion","f35290aa":"## Use all data for training","9c069a3f":"## Training\nLet's build a helper function for the training of our model (we'll reuse it later):","dbf128ac":"## Building a model\nWe'll encapsulate the complexity of our model into a class that extends from torch.nn.Module:","52543a85":"\n<font face = \"Verdana\" size =\"4\">\n    <br>Data: <a href='https:\/\/github.com\/CSSEGISandData\/COVID-19'>https:\/\/github.com\/CSSEGISandData\/COVID-19<\/a>\n    <br>Learn more from the <a href='https:\/\/www.who.int\/emergencies\/diseases\/novel-coronavirus-2019'>WHO<\/a>\n    <br>Learn more from the <a href='https:\/\/www.cdc.gov\/coronavirus\/2019-ncov'>CDC<\/a>\n    <br>Map Visualizations from  <a href='https:\/\/gisanddata.maps.arcgis.com\/apps\/opsdashboard\/index.html#\/bda7594740fd40299423467b48e9ecf6'>Johns Hopkins<\/a>   \n   <br>\n      Feel free to provide me with feedbacks. \n    <br> Last update: 07\/07\/2020 02:32 PM  \n    <br>\n    <\/font>\n   \n    \n <font face = \"Verdana\" size =\"1\">\n<center><img src='https:\/\/ichef.bbci.co.uk\/images\/ic\/720x405\/p086qbqx.jpg'>\n Source: https:\/\/ichef.bbci.co.uk\/images\/ic\/720x405\/p086qbqx.jpg <\/center> \n    \n","0b8b6e67":"### Coronavirus Cases for above four infected countries ","12cab160":"#### 3. World Daily Increases in Confirmed Cases","b2fa36a8":"# 2.LSTM","e5a3e977":"# Prediction Curve for USA\n# 1. Prophet","35aa3380":"We have to scale the data (values will be between 0 and 1) if we want to increase the training speed and performance of the model. We'll use the MinMaxScaler from scikit-learn:","9e596955":"Function to plot data.","fce978bf":"## Preprocessing\n#### We'll reserve the first 60 days for training and use the rest for testing:","99b83512":"## References\n\n- [Sequence Models PyTorch Tutorial](https:\/\/pytorch.org\/tutorials\/beginner\/nlp\/sequence_models_tutorial.html)\n- [LSTM for time series prediction](https:\/\/towardsdatascience.com\/lstm-for-time-series-prediction-de8aeb26f2ca)\n- [Time Series Prediction using LSTM with PyTorch in Python](https:\/\/stackabuse.com\/time-series-prediction-using-lstm-with-pytorch-in-python\/)\n- [Stateful LSTM in Keras](https:\/\/philipperemy.github.io\/keras-stateful-lstm\/)\n- [Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE](https:\/\/github.com\/CSSEGISandData\/COVID-19)\n- [covid-19-analysis](https:\/\/github.com\/AaronWard\/covid-19-analysis)\n- [Worldometer COVID-19 Coronavirus Outbreak](https:\/\/www.worldometers.info\/coronavirus\/)\n- [Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications](https:\/\/www.researchers.one\/article\/2020-01-21)\n- [Creating the Keras LSTM data generators](https:\/\/adventuresinmachinelearning.com\/keras-lstm-tutorial\/)","676f8619":"## Country Wise Reported Cases\n#### Country Wise reported confirmed cases, recovered cases, deaths, active cases","a152c33a":"#### 1. No. of Coronavirus Cases Over Time","d31041e9":"#### 2. China","a2228a9e":"#### Import Data set","490b79b3":"### Global Reported Cases till Date\nTotal number of confirmed cases, deaths reported, revoveries and active cases all across the world","315ece4e":"#### 3. Italy","d3b91054":"# Visualization on Map","a984d46c":"#### Get all the dates for the outbreak","0f71d86e":"# Preprocessing ","f1f272c1":"#### 4. Spain","5636f178":"Our model thinks that things will level off. Note that the more you go into the future, the more you shouldn't trust your model predictions.\n\n# Conclusion\nWell done! You learned how to use PyTorch to create a Recurrent Neural Network that works with Time Series data. The model performance is not that great, but this is expected, given the small amounts of data."}}