{"cell_type":{"64a20deb":"code","e7cabf74":"code","ff675e16":"code","95c4f730":"code","dd21bb68":"code","1412cd50":"code","0fa00672":"code","d2030270":"code","e703bc82":"code","f79cba29":"code","95e1deb9":"code","737d2b00":"code","d239373f":"code","2a79ecec":"code","91b24cf4":"code","dd971503":"code","e3f72c1e":"code","1b604b2b":"code","12c440c8":"markdown"},"source":{"64a20deb":"# import all of our packages\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.utils import np_utils \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.callbacks import ReduceLROnPlateau","e7cabf74":"# import our dataset using the pandas read_csv option\ntest_import = pd.read_csv(\"..\/input\/Kannada-MNIST\/test.csv\");\ntrain_import = pd.read_csv(\"..\/input\/Kannada-MNIST\/train.csv\");","ff675e16":"# test the data for null values. notice how the functions are stacked. isnull() shows a 1 if its null. Any() checks which ones. \n# Describe shows it in a format thats easier to read (otherwise you would have to check the whole matrix if theres a 1 somewhere)\ntrain_import.isnull().any().describe()","95c4f730":"# do this again for the training set\ntrain_import.isnull().any().describe()","dd21bb68":"# drop the label column from the dataset so we only keep the pixel information. The first column represents\n# the outcome (number between 0 and 10).\nX_train = train_import.drop('label', axis=1)\n# obtain the first column vector from the dataset and use it to label data as this is the outcome. (number between 0 and 10)\ny_train = train_import.iloc[:, 0]","1412cd50":"# check the histogram of distribution from our training set using the built in function hist(). Alternatively you could\n# use a library such as matplotlib.  We want to make sure that the distribution between numbers that we have examples of are\n# the same. Imagine if we had 1000 examples of the number 2 but only a couple for the number 3. Its just a quick check.\ny_train.hist()","0fa00672":"test_import = test_import.drop('id', axis=1)","d2030270":"# normalize the pixel intensity values. Great video on normalization: https:\/\/www.youtube.com\/watch?v=FDCfw-YqWTE\nX_train = X_train \/ 255.0\ntest_import = test_import \/ 255.0\n\n# reshape it from a m * 728 matrix (m is number of examples) to a matrix of m * 28 * 28 where 1 is an additional channel.\n# usually you use this last channel for the RGB values but in this example its not needed\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test_import.values.reshape(-1,28,28,1)\n\n# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n# reason for this is that in a neural network each node in the output layer outputs 0 or 1.\n# more information about one hot encoder\n# https:\/\/hackernoon.com\/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\nY_train =  np_utils.to_categorical(y_train, num_classes = 10)\n\n# split set into training and validation. \nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)","e703bc82":"# creating the model. Guide from Keras: https:\/\/keras.io\/getting-started\/sequential-model-guide\/\n# more information about the activation functions relu vs softmax: https:\/\/github.com\/Kulbear\/deep-learning-nano-foundation\/wiki\/ReLU-and-Softmax-Activation-Functions\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(28,28,1), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])","f79cba29":"# create more sample images using ImageDataGenerator.This ensures we have more data to train on. More info about function here: https:\/\/keras.io\/preprocessing\/image\/\nimagegen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False, \n        featurewise_std_normalization=False, \n        samplewise_std_normalization=False,\n        zca_whitening=False, \n        rotation_range=9, \n        zoom_range = 0.25,\n        width_shift_range=0.25,\n        height_shift_range=0.25, \n        horizontal_flip=False, \n        vertical_flip=False)\n\nimagegen.fit(X_train)","95e1deb9":"# set epochs (1 epoch = 1 run) higher for better result (set lower to save costs)\nepochs = 4\nbatch_size = 64","737d2b00":"# fit the model with generated images. Asign it to fitobj so we can later check on the data\nfitobj = model.fit_generator(imagegen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 1, steps_per_epoch=X_train.shape[0])","d239373f":"score = model.evaluate(X_val, Y_val, batch_size=30)","2a79ecec":"# review the model score\nscore","91b24cf4":"# view history of model. It prints for every epoch so you can graph it out to see if you are actually improving\nfitobj.history\n\n# highly recommend to review your data afterward to see which examples were false positives but let's stick to the bare minimum\n# to get this kernel to run.","dd971503":"# predict results\nresults = model.predict(test)\n","e3f72c1e":"results = np.argmax(results,axis = 1)\nsubmission = pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')\nsubmission['label'] = results\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","1b604b2b":"# check if we have a bias towards a specific example in the results\nsubmission.hist()","12c440c8":"Code of my basic CNN including additional information where needed. Keras website has a great explanation and documentation when you are getting started: https:\/\/keras.io\/getting-started\/sequential-model-guide\/\n\nMost of the top 10 CNN kernels at Kaggle are the same so I tried focussing on additional explanations of the functions that I use and links that explain the functions further.\n\nhighly recommend also checking out Yassine's kernel as he does a great job of interpreting the results at of a CNN. https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6"}}