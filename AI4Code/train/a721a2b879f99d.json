{"cell_type":{"df1331b7":"code","d75cff53":"code","c7fe76d9":"code","43507452":"code","639acf26":"code","ad1c06ca":"code","7703a62b":"code","18407f65":"code","381df213":"code","16178544":"code","8c1fe2bd":"code","4e3bdf31":"code","5bc56c20":"code","4a4983d5":"code","7784699f":"code","f3fe1b27":"markdown"},"source":{"df1331b7":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d75cff53":"from keras.utils import to_categorical\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndata_train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","c7fe76d9":"data_train","43507452":"data_test","639acf26":"img_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nX = np.array(data_train.iloc[:, 1:])\ny = to_categorical(np.array(data_train.iloc[:, 0]))\n#Label is only 10 type of the fashion [0,1,2,3,4,5,6,7,8,9]\nprint(\"X = \\n \",X)\nprint(\"y = \\n \",y)","ad1c06ca":"#Here we split validation data to optimiza classifier during training\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n\n#Test data\nX_test = np.array(data_test.iloc[:, 1:])\ny_test = to_categorical(np.array(data_test.iloc[:, 0]))\nprint(\"X_test= \\n \",X_test)\nprint(\"y_test = \\n \",y_test)","7703a62b":"#reshape \nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\nX_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n#Normalization \nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_val = X_val.astype('float32')\nX_train \/= 255\nX_test \/= 255\nX_val \/= 255","18407f65":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\n\nbatch_size = 256\nnum_classes = 10\nepochs = 50\n\n#input image dimensions\nimg_rows, img_cols = 28, 28\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmodel.summary()","381df213":"history = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_val, y_val))\nscore = model.evaluate(X_test, y_test, verbose=0)","16178544":"print('Test loss:', score[0])\nprint('Test accuracy:', score[1])","8c1fe2bd":"import matplotlib.pyplot as plt\n%matplotlib inline\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","4e3bdf31":"\n#Classification Report\n#We can summarize the performance of our classifier as follows\n#get the predictions for the test data\npredicted_classes = model.predict_classes(X_test)\n\n#get the indices to be plotted\ny_true = data_test.iloc[:, 0]\ncorrect = np.nonzero(predicted_classes==y_true)[0]\nincorrect = np.nonzero(predicted_classes!=y_true)[0]","5bc56c20":"from sklearn.metrics import classification_report\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(y_true, predicted_classes, target_names=target_names))","4a4983d5":"\nfor i, correct in enumerate(correct[:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_true[correct]))\n    plt.tight_layout()","7784699f":"\n#And here is a subset of incorrectly predicted classes.\n\nfor i, incorrect in enumerate(incorrect[0:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_true[incorrect]))\n    plt.tight_layout()","f3fe1b27":"Our strategy will be using 20% of the train data (12000 data rows) as a validation set to optimize the classifier, while keeping test data to finally evaluate the accuracy of the model on the data it has never seen.\n\nDataSet : https:\/\/www.kaggle.com\/zalando-research\/fashionmnist\n"}}