{"cell_type":{"acd9aa30":"code","29eab70c":"code","2aeb5ca8":"code","3faeb5d0":"code","8b7b4d3c":"code","3071d412":"code","f8f0ae76":"code","6e4dcd93":"code","70e73a13":"code","62c86477":"code","509c653e":"code","10941323":"code","32a8813e":"code","83c3b2d6":"code","19339ab1":"code","73cd36a9":"code","62f0938e":"code","89ba7d04":"code","4486c19b":"code","a5de7793":"code","04491485":"code","054863d7":"code","ee97d56a":"code","1eefabfb":"code","c1745742":"code","a14c4942":"code","d23d0c80":"code","5e543248":"markdown","9185f5bc":"markdown","3b2db2b2":"markdown","55612fcf":"markdown","aadcf200":"markdown"},"source":{"acd9aa30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29eab70c":"from pycaret import classification\nfrom pycaret.classification import *\nimport numpy as np\nimport pandas as pd","2aeb5ca8":"os.chdir('\/kaggle\/input\/predicting-energy-rating-from-raw-data')\n\ntrain = pd.read_csv('train_rating_eu.csv')\ntest = pd.read_csv('test_rating_eu.csv')\n\ntest = test.drop(['building_id', 'site_id', 'Unnamed: 0'], axis=1)\ntest.info()","3faeb5d0":"train = train.drop(['building_id', 'site_id', 'Unnamed: 0'], axis=1)\ntrain.info()","8b7b4d3c":"train['rating'].unique()","3071d412":"train['rating'] = train['rating'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G'], [0, 0, 1, 1, 2, 2, 2])","f8f0ae76":"os.chdir('\/kaggle\/working\/')\ncla = classification.setup(data=train, target='rating', train_size=0.7)\nm = compare_models()","6e4dcd93":"cat = classification.create_model('catboost')","70e73a13":"tuned_cat = classification.tune_model(cat)","62c86477":"bagged_cat = classification.ensemble_model(tuned_cat)","509c653e":"predictions = classification.predict_model(cat)","10941323":"predictions = classification.predict_model(tuned_cat)","32a8813e":"predictions = classification.predict_model(bagged_cat)","83c3b2d6":"classification.plot_model(tuned_cat)","19339ab1":"classification.evaluate_model(tuned_cat)","73cd36a9":"classification.finalize_model(tuned_cat)\npredictions_test = classification.predict_model(tuned_cat, data=test)","62f0938e":"labels = predictions_test['Label']\npd.value_counts(labels).plot.bar(figsize=(10,5))","89ba7d04":"y = train['rating']\nX = train.drop(['rating'], axis=1)\nX.info()","4486c19b":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size=0.2)\nprint(Xtrain.shape)\nprint(Xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)","a5de7793":"from catboost import Pool, CatBoostClassifier\n\ntrain_dataset = Pool(data=Xtrain, label=ytrain)\ntest_dataset = Pool(data=Xtest, label=ytest)\n\n\nmodel = CatBoostClassifier(iterations=100,\n                           learning_rate=.01,\n                           depth=2,\n                           loss_function='MultiClass')","04491485":"model.fit(train_dataset)\n# Get predicted classes\npreds_class = model.predict(test_dataset)\n# Get predicted probabilities for each class\npreds_proba = model.predict_proba(test_dataset)","054863d7":"preds_proba","ee97d56a":"def getLetter(prob, cat):\n    letter = [0] * len(cat)\n    i = 0\n    for p in prob:\n        if cat[i] == 0:\n            if p[1] > p[2]:\n                letter[i] = 'A'\n            else:\n                letter[i] = 'B'\n        elif cat[i] == 1:\n            if p[0] > p[2]:\n                letter[i] = 'C'\n            else:\n                letter[i] = 'D'\n        else:\n            if p[0] > p[1]:\n                letter[i] = 'E'\n            else:\n                letter[i] = 'F\/G'\n        i = i + 1\n    return letter","1eefabfb":"letters = pd.DataFrame(getLetter(preds_proba, preds_class))\npd.value_counts(letters[0]).plot.bar(figsize=(10,5))","c1745742":"from sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(preds_class, ytest)\naccuracy","a14c4942":"predictions_test = pd.DataFrame(model.predict(test))\npreds_proba_test = model.predict_proba(test)\npd.value_counts(predictions_test[0]).plot.bar(figsize=(10,5))","d23d0c80":"letters = pd.DataFrame(getLetter(preds_proba_test, predictions_test[0]))\npd.value_counts(letters[0]).plot.bar(figsize=(10,5))","5e543248":"# Normal Catboost Classifier","9185f5bc":"The tuned catboost model without bagging performed the best in terms of test F1 and Accuracy scores.","3b2db2b2":"# Analysis of Different Classification Models","55612fcf":"In order to improve the accuracy of the model, I turned a seven class problem into a three class problem by engineering the following classes:\n1. A and B ratings were assigned to class 0, 'Excellent'\n2. C and D ratings were assigned to class 1, 'Pass'\n3. E, F, and G ratings were assigned to class 2, 'Fail'","aadcf200":"# Focusing on Catboost Classifier"}}