{"cell_type":{"b69c258b":"code","ebdff804":"code","e2b0ad1b":"code","ecb521b2":"code","a9c882d0":"code","03dec4bb":"code","a131fd43":"code","3fb81fc6":"markdown","bda3d547":"markdown","13c436bf":"markdown","c177cc17":"markdown"},"source":{"b69c258b":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport matplotlib.pyplot as plt\n\n# set seed for reproducability \nnp.random.seed(0)\n\n# read in data\ndata = pd.read_csv(\"..\/input\/Admission_Predict.csv\")\n\n# for classificiton, add a column with binary accepted or not judgement\n# data['admitted'] = np.where(data['Chance of Admit ']>=0.8, '1', '0')\n\n# most methods here will not work with na's. You may want\n# to impute instead of dropping.\ndata = data.dropna()\n\n# clean up column names\ndata.columns = data.columns.\\\n    str.strip().\\\n    str.lower().\\\n    str.replace(' ', '_')\n\n# split data into training & testing\ntrain, test = train_test_split(data, shuffle=True)\n\n# peek @ dataframe\ntrain.head()","ebdff804":"# imports for mixed effect libraries\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# model that predicts chance of admission based on GRE & TOEFL score, \n# with university rating as a random effect\nmd = smf.mixedlm(\"chance_of_admit ~ gre_score + toefl_score\", # formula w\/ fixed effects\n                 train, # training data\n                 groups=train[\"university_rating\"]) # random effects\n\n# fit & summerize model\nfitted_model = md.fit()\nprint(fitted_model.summary())","e2b0ad1b":"# predictions & actual values, from test set\npredictions = fitted_model.predict(test)\nactual = test['chance_of_admit']\n\n# plot actual vs. predicted\nplt.scatter(actual, \n            predictions,  \n            color='black')\n\n# report mse & r2\nprint(\"Mean squared error: %.2f\" % mean_squared_error(actual, predictions))\nprint('Variance score: %.2f' % r2_score(actual, predictions))","ecb521b2":"import xgboost as xgb\n\n# split training data into inputs & outputs\nX = train.drop([\"chance_of_admit\"], axis=1)\nY = train[\"chance_of_admit\"]\n\n# specify model (xgboost defaults are generally fine)\nmodel = xgb.XGBRegressor()\n\n# fit our model\nmodel.fit(y=Y, X=X)","a9c882d0":"# split testing data into inputs & output\ntest_X = test.drop([\"chance_of_admit\"], axis=1)\ntest_Y = test[\"chance_of_admit\"]\n\n# predictions & actual values, from test set\npredictions = model.predict(test_X)\nactual = test_Y\n\n# plot actual vs. predicted\nplt.scatter(actual, \n            predictions,  \n            color='black')\n\n# report mse & r2\nprint(\"Mean squared error: %.2f\" % mean_squared_error(actual, predictions))\nprint('Variance score: %.2f' % r2_score(actual, predictions))","03dec4bb":"from sklearn.svm import SVR\n\n# split training data into inputs & outputs\nX = train.drop([\"chance_of_admit\"], axis=1)\nY = train[\"chance_of_admit\"]\n\n# specify model (xgboost defaults are generally fine)\nmodel = SVR(gamma='scale', C=1.0, epsilon=0.2)\n\n# fit our model\nmodel.fit(y=Y, X=X)\n","a131fd43":"# split testing data into inputs & output\ntest_X = test.drop([\"chance_of_admit\"], axis=1)\ntest_Y = test[\"chance_of_admit\"]\n\n# predictions & actual values, from test set\npredictions = model.predict(test_X)\nactual = test_Y\n\n# plot actual vs. predicted\nplt.scatter(actual, \n            predictions,  \n            color='black')\n\n# report mse & r2\nprint(\"Mean squared error: %.2f\" % mean_squared_error(actual, predictions))\nprint('Variance score: %.2f' % r2_score(actual, predictions))","3fb81fc6":"# XGBoost minimal example","bda3d547":"This kernel has some very short parallel working examples of regression using mixed effects models, XGBoost and support vector regression in Python. \n\n# Preprocessing (same for all methods)","13c436bf":"## Mixed effects model minimal example (Linear regression)","c177cc17":"# SVM Regression"}}