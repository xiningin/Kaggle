{"cell_type":{"517eb7a7":"code","f845a164":"code","9db2f4b3":"code","d9697a23":"code","2e809866":"code","87691f8b":"code","bea15e81":"code","3e5dda47":"code","6e45aac2":"code","6e137dee":"code","aa6d3f79":"code","fc81ebd8":"code","a3a2c6cd":"code","cffb7d05":"code","822dd7e3":"code","89faec5b":"code","38644050":"code","777e69fc":"code","1b9dbcfd":"code","c942ac08":"code","83e70c66":"code","ce5ddc03":"code","5046a371":"code","12cd25c0":"code","a5950cf3":"code","871b9df3":"code","a186815e":"code","05727a3c":"code","0f32a0dc":"code","49b56332":"code","4cab65fa":"code","ef077c27":"code","e6e73512":"code","50a97b67":"code","a3a8b6a1":"code","b43edb03":"code","96bc90fe":"code","80f47e2c":"code","c4f88f23":"code","4bb9eee0":"code","6810a7a6":"code","6cd06509":"code","3e6783bc":"code","818a1a47":"code","710f4126":"code","b46a7083":"code","45940985":"code","6a85f026":"code","bba5fdd2":"code","f9bd2f97":"code","4f8c5800":"code","0281a9cc":"code","a77fca63":"code","ae8e95c0":"code","f0e02456":"markdown","98997bdf":"markdown","867473fa":"markdown","9cbd20fc":"markdown","33297ae7":"markdown","77226d9e":"markdown","d99defdd":"markdown","a09d95a0":"markdown","0c0f0249":"markdown","41b11d05":"markdown","38176559":"markdown","c31dc472":"markdown","824cf32e":"markdown","f6e840cd":"markdown","3abb0f18":"markdown","f131e1e7":"markdown","29009085":"markdown"},"source":{"517eb7a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f845a164":"data = pd.read_csv(\"\/kaggle\/input\/diabetes\/diabetes.csv\")","9db2f4b3":"data.head()","d9697a23":"data.info()","2e809866":"data.nunique()   #Unique degerler","87691f8b":"data.describe().T","bea15e81":"print(\"satir ve sutun = \", data.shape)\nprint(\"Boyut sayisi = \",data.ndim)\nprint(\"eleman sayisi = \",data.size)","3e5dda47":"data.corr()","6e45aac2":"# Heatmap correlation cizimi seaborn ile.\ndata.corr()\n\nf,ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(data.corr(), \n            annot=True, \n            linewidths=0.2,\n            linecolor=\"yellow\", \n            fmt= '.2f',\n            ax=ax) #ftm noktadan sonra kac hane olacak onu verir\n\nplt.show()","6e137dee":"# kac adet 1 ve 0 var, Diabet hasta sayisi\nsns.countplot(data.Outcome)\nplt.title(\"Outcome\",color = 'Yellow',fontsize=15)\nplt.show()","aa6d3f79":"#Eksik gozlem var mi ? \n\ndata.isnull().sum() ","fc81ebd8":"# Eksik gozlem gorsellestirme rare kutuphanesi ile\n\nimport missingno as msno\nmsno.matrix(data)\nplt.show()","a3a2c6cd":"x = data.drop([\"Outcome\"], axis=1)  #\"Outcome\" disindaki sutunlar bagimsiz degisken_\nx","cffb7d05":"y = data[\"Outcome\"]                 #\"Outcome\" ise bagimli degiskendir, \ny","822dd7e3":"# # Data normalization = data normalizasyonu - Ben kullanmayacagim. \n\n# x = (x - np.min(x))\/(np.max(x)-np.min(x)).values\n","89faec5b":"# Test Train \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,\n                                                    test_size = 0.2,\n                                                    random_state=42)","38644050":"x_train","777e69fc":"x_test","1b9dbcfd":"from sklearn.linear_model import LogisticRegression","c942ac08":"loj_reg = LogisticRegression().fit(x_train,y_train)\nloj_reg \n\n\n#Not penalty= default olursa skor dusuyor.","83e70c66":"# parametrelerin ne oldgunu gorelim..\n\n? loj_reg","ce5ddc03":" # b0 yani sabit degerimizi aldik. bagimsiz degiskenin hic etkisi olmasaydi, baslangic y degeri\nloj_reg.intercept_","5046a371":"# Bagimsiz degiskenlerin bagimli degiskeni etkileme oranlari\n# coef katsayisi\n\nloj_reg.coef_","12cd25c0":"data","a5950cf3":"y_pred = loj_reg.predict(x_test)     # train seti uzerinden modelemize tahmin etme yaptirdik\ny_pred","871b9df3":"#Proba oranlari > yuzde kac 1 ve 0\n\n#ikili cikti uretir, 0 ve 1 oranlarini verir. \n# sadece 1 ve sifir olarak donmesini degilde, bunlarin olasilik degerlerini ogrenmek istedik.\n\n\nloj_reg.predict_proba(x_train)[0:10]","a186815e":"#Accuracy Score > # modeldeki gercek 0-1 ile tahmindeki 0-1 oranlarini karsilastirip, dogru siniflandirma oranimizdir\n\nfrom sklearn.metrics import accuracy_score\nlog_score = accuracy_score(y_test, y_pred)\n\nprint(\"Logistic_reg_class_SCORE = \",log_score)","05727a3c":"from sklearn.ensemble import RandomForestClassifier","0f32a0dc":"rf_model = RandomForestClassifier(n_estimators=22).fit(x_train, y_train)\nrf_model\n\n#n_estimators=10 defaultur. 22 da daha yuksek skor aldim","49b56332":"# Modelimizin tahminleri (test)\n\ny_pred = rf_model.predict(x_test)","4cab65fa":"# Dogrulama skoru (test)\n# modeldeki gercek 0-1 ile tahmindeki 0-1 oranlarini karsilastirip, dogru siniflandirma oranimizdir\n\nrf_score = accuracy_score(y_test, y_pred)\nrf_score","ef077c27":"# ONEM SIRALAMASI\n# y'yi etklileyen degiskenlerin (x) onem siralamasi\n\nImportance = pd.DataFrame({\"Importance\": rf_model.feature_importances_},\n                         index = x_train.columns)\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"green\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")","e6e73512":"from sklearn.neighbors import KNeighborsClassifier","50a97b67":"knn = KNeighborsClassifier( n_neighbors=4).fit(x_train, y_train)\nknn","a3a8b6a1":"#Modelimizin tahminleri\ny_pred = knn.predict(x_test)","b43edb03":"# Dogrulama skoru\n\nknn_score = accuracy_score(y_test, y_pred)\nknn_score","96bc90fe":"# Default olan 0.50 den buyukse 1 degilse 0 olan tanimlamayi kendi istegimize gore degistirelim\n# 0.75 den buyuk 1 degilse 0 olsun.\n\ny_probs = knn.predict_proba(x_test)     # tekrardan 0 ve 1'in olasilik degerlerini bu degiskene atadik.\ny_probs","80f47e2c":"y_probs = y_probs[:,1] # 1 olma olasiliklarini bu degiskene ayirdik. (1.sutunun tum satirlari)\ny_probs # artik 1 olma olasiliklari bu sekildedir.","c4f88f23":"y_pred = [1 if i > 0.85 else 0 for i in y_probs] \n\n\n# if ve for donguleri ile \"1\" in 0.85'den buyukse 1 diye siniflandirmasini.. , \n# ...degilse \"0\" diye siniflandirmasini istedik. \n# ..ve tekrar y_pred seklinde yeni tahminlerimizi atadik\n","4bb9eee0":"# degistirilen diagnosisden sonraki skorumuz\naccuracy_score(y_test, y_pred)    ","6810a7a6":"from sklearn.svm import SVC","6cd06509":"svm_model = SVC(C=5, degree=7, kernel='linear' ).fit(x_train, y_train)\nsvm_model\n\n# C=5, degree=7, kernel='linear'yaptim. def degil","3e6783bc":"# Modelimizin tahminleri\ny_pred = svm_model.predict(x_test)","818a1a47":"# Dogrulama skoru\nsvm_score = accuracy_score(y_test, y_pred)\nsvm_score\n","710f4126":"from sklearn.naive_bayes import GaussianNB","b46a7083":"nb = GaussianNB()\nnb_model = nb.fit(x_train, y_train)\nnb_model","45940985":"nb_model.predict(x_test)[:10]","6a85f026":"nb_model.predict_proba(x_test)[0:10]  \n\n# ! Tahmini olasilik degerleridir. \n# Ilk sutun \"0\", ikinci sutun \"1\" i ifade eder.","bba5fdd2":"y_pred = nb_model.predict(x_test)","f9bd2f97":"nb_score = accuracy_score(y_test, y_pred)\nnb_score","4f8c5800":"# Cross Validation islemi \n#Dogrulanmis test hatamiz, 20 katmanli cross valide edilmis test hatasi ortalamasidir.\n\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(nb_model, x_test, y_test, cv = 20)","0281a9cc":"# Ortalamasini alalim\n\ncross_val_score(nb_model, x_test, y_test, cv = 20).mean()","a77fca63":"# Model Skorlarinin  Seaborn ile gorsellestirilmesi\n\nindexx = [\"Log\",\"RF\",\"KNN\",\"SVM\",\"NB\"]\nregressions = [log_score,rf_score,knn_score,svm_score,nb_score]\n\nplt.figure(figsize=(8,6))\nsns.barplot(x=indexx,y=regressions)\nplt.xticks()\nplt.title('Model Compare',color = 'orange',fontsize=20)\nplt.show()","ae8e95c0":"conda install -c plotly plotly chart-studio","f0e02456":"> Yorum -1 : Bi insanin diabet hastasi olmasini en fazla glikoz etkliyor yorumunu yapabiliriz. (5.44246395)","98997bdf":"# Tesekkurler...","867473fa":"# STEP-2 : DATAYI GORSELLESTIRME","9cbd20fc":"# 2) Random Forest\n\nTemeli birden cok karar agacinin urettigi tahminlerin bir araya getirilerek degerlendirilmesine dayanir. Gozlemlerde ve degiskenlerde rastsallik saglar,","33297ae7":"# STEP - 5 : MODEL KURULMASI","77226d9e":"# 5) Gaussian Naive Bayes Model\n* Olasilik temelli bir modelleme teknigidir. \n* Amac belirli bir ornegin her bir sinifa ait olma olasiliginin kosullu olasilik temelli hesaplanmasidir. \n* Cok sinifli degiskenlerde bu model daha iyi sonuclar verebilir.\n* Cok daha fazla katogorik degisken varsa kullanilmasi uygun olabilir","d99defdd":"# 4) SVM - Support Vector Model\nAmac, iki sinif arasrindaki ayrimin optimum olmasini saglayacak hiper-duzlemi bulmaktir.\n\nyani 1 ve 0 arasindaki mesafenin maximum tutmaya calisir. ayrimin belirgin olmasini saglamaya calisir.","a09d95a0":"* Pregnancies = Hamilelik durumu\n* Glucose = Glikoz orani\n* BloodPressure = Kan basinci\n* SkinThickness = Deri kalinligi\n* Insulin = Inusilin degeri\n* BMI = V\u00fccut Kitle Endeksi\n* DiabetesPedigreeFunction = Diyabet Soy a\u011fac\u0131 \u0130\u015flevi\n* Age = Yas\n* Outcome = Diabet olma durumu\n","0c0f0249":"# STEP - 3 : DEGISKENLERI HAZIRLAMA","41b11d05":"# STEP - 4 : DATAYI TEST\/TRAIN OLARAK SPLIT ETME","38176559":"# 1) Logistic Regression\n\nBilinen do\u011frusal regresyon analizinde ba\u011f\u0131ml\u0131 \nde\u011fi\u015fken ve ba\u011f\u0131ms\u0131z de\u011fi\u015fken(ler) say\u0131sal\n(\u00f6l\u00e7\u00fcmle belirtilen s\u00fcrekli ya da kesikli say\u0131sal)\nolarak belirtilir.\n\u00d6rne\u011fin, ya\u015f ile kan bas\u0131nc\u0131 aras\u0131nda bir ili\u015fki\naranacaksa; hem ya\u015f, hem de kan bas\u0131nc\u0131\nsay\u0131sal olarak belirtilmelidir.\nNitelik olarak belirtilemezler.Ba\u011f\u0131ml\u0131 de\u011fi\u015fken nitelik olarak\nbelirtilirse,\nba\u011f\u0131ms\u0131z de\u011fi\u015fken ya da de\u011fi\u015fkenlerle\naras\u0131ndaki ili\u015fki lojistik regresyon\ny\u00f6ntemiyle aran\u0131r. \n* Ozetle aradigimiz sey sayisal degilde, kategorik ise lojistik regresyon kullanilir. Diabet hastasi mi, degil mi ? Evet yada hayir. Yani nitelik ariyoruz. ","c31dc472":"* E\u011fitim verisi : Modelimize verip e\u011fitilmesini sa\u011flayaca\u011f\u0131m\u0131z verisetimizdir. Ana verisetinin se\u00e7imize g\u00f6re %80'lik belli bir k\u0131sm\u0131n\u0131 kapsar.\n* Test verisi : Ana veri setinin %20'lik k\u0131sm\u0131n\u0131 kapsar. E\u011fitilen modelimize hedef de\u011fi\u015fkenini kapat\u0131larak verilir, ard\u0131ndan modelin tahminleri al\u0131n\u0131r, modelin tahminleri ile ger\u00e7ek hedef de\u011ferler kar\u015f\u0131la\u015ft\u0131r\u0131larak kurdu\u011fumuz modelin ne kadar do\u011fru tahmin yapt\u0131\u011f\u0131 ortaya \u00e7\u0131kar.","824cf32e":"# **Step -1 : DATAYI KESFETME**","f6e840cd":"# Tum modellerin karsilastirilmasi ","3abb0f18":"* ****Data Normalizasyonu nedir ? \n* Normalle\u015ftirmeye ihtiya\u00e7 duymam\u0131zdaki en b\u00fcy\u00fck sebep farkl\u0131 niteliklerin farkl\u0131 \u00f6l\u00e7\u00fc birimleri ile \u00f6l\u00e7\u00fclmesinden kaynaklanmaktad\u0131r. E\u011fer iki \u00f6l\u00e7\u00fc birimi aras\u0131nda d\u00f6n\u00fc\u015ft\u00fcrme yapabiliyorsak bu \u00e7o\u011fu zaman yeterli olacakt\u0131r. Farkl\u0131 iki veri setinin birinde a\u011f\u0131rl\u0131k bilgisi kg di\u011ferinde lbs ile \u00f6l\u00e7\u00fclm\u00fc\u015f olabilir. Bu durumda d\u00f6n\u00fc\u015f\u00fcm yapmak yeterlidir. Fakat farkl\u0131 nitelikler i\u00e7in birbirilerine d\u00f6n\u00fc\u015ft\u00fcr\u00fclmeyecek birimler kullan\u0131yoruz. Bir ki\u015finin a\u011f\u0131rl\u0131\u011f\u0131n\u0131 kg, boyunu cm, maa\u015f\u0131n\u0131 TL ile \u00f6l\u00e7\u00fcyoruz. De\u011fer aral\u0131klar\u0131 \u00e7ok farkl\u0131 olan \u00f6l\u00e7\u00fcm de\u011ferlerinden bahsetti\u011fimiz i\u00e7in klasik \"elma-armut\" \u00e7\u0131kmaz\u0131ndan dolay\u0131 bunlar\u0131 birbirileri ile i\u015fleme tabi tutamay\u0131z. Makine \u00f6\u011frenmesinde parametrik olmayan y\u00f6ntemlerin \u00e7o\u011fu uzakl\u0131k tabanl\u0131 \u00e7al\u0131\u015fmaktad\u0131r. Yani karar verirken iki niteli\u011fin d\u00fczlemde birbirine g\u00f6re olan uzakl\u0131kl\u0131\u011f\u0131na g\u00f6re karar vermektedirler.","f131e1e7":"* n_estimators=10 >> fit edilecek agac sayisidir, yani 10 adet agac tahmini olusturulacak. \n\n* max_features='auto'> > Bolunme islemlerinde goz onunde bulundurulacak olan maximum degisken sayisini verir.\n\n* min_samples_split=2 > > Bu bir node bolunmeden once minimum gozlem sayisini ifade eder, \n* min_samples_leaf=1 > leaf node ' taki minimum gozlem sayisini ifade eder,","29009085":"# 3)KNN Model\nTahminler gozlem benzerligine gore yapilir\n\nk = komsu sayisini belirler Bilinmeyen noktalar ile diger tum noktalar arasindaki mesafeyi hesaplar belirlenen k ile kendisine en yakin k kadar gozlemi secer."}}