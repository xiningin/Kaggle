{"cell_type":{"36e63939":"code","fb7ed7d7":"code","9637217c":"code","1c9b0f2f":"code","09e8144c":"code","b12066e4":"code","ed35ebd4":"code","4efa211a":"code","509f3935":"code","148ef47d":"code","22353c0f":"code","a505f414":"code","3226e1a3":"code","fab0b703":"code","0417e4b9":"code","e7cc4dcf":"code","f9426a88":"code","150a2f87":"code","a6d50140":"code","000ffcae":"code","d24d0c75":"code","0a55bccb":"code","65c66284":"markdown","ae519853":"markdown"},"source":{"36e63939":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport time\nfrom datetime import datetime\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom keras.layers import SimpleRNN, LSTM, Dense, Dropout, Masking, Embedding, Dense, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input","fb7ed7d7":"df_train = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/train.csv')\ndf_details = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/asset_details.csv')\ndf_extest = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/example_test.csv')\ndf_sup = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/supplemental_train.csv')\ndf_exsamp = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/example_sample_submission.csv')","9637217c":"print(\"\/\/ TRAINING DATA \/\/\")\nprint()\nprint(df_train.head(5))\nprint()\nprint(\"-----------\")\nprint(\"\/\/ SUPLEMENTAL TRAIN \/\/\")\nprint()\nprint(df_sup.head(5))\nprint()\nprint(\"-----------\")\nprint(\"\/\/ ASSET DETAILS \/\/\")\nprint()\nprint(df_details.head(5))\nprint()\nprint(\"-----------\")\nprint(\"\/\/ EXAMPLE TEST \/\/\")\nprint()\nprint(df_extest.head(5))\nprint()\nprint(\"-----------\")\nprint(\"\/\/ EXAMPLE SAMPLE \/\/\")\nprint()\nprint(df_exsamp.head(5))\nprint()\nprint(\"-----------\")","1c9b0f2f":"df_train","09e8144c":"df_train.isnull().sum()","b12066e4":"bnc = df_train[df_train['Asset_ID']==0]\nbtc = df_train[df_train['Asset_ID']==1]\nbcs = df_train[df_train['Asset_ID']==2]\ncrd = df_train[df_train['Asset_ID']==3]\ndog = df_train[df_train['Asset_ID']==4]\neos = df_train[df_train['Asset_ID']==5]\neth = df_train[df_train['Asset_ID']==6]\netc = df_train[df_train['Asset_ID']==7]\niot = df_train[df_train['Asset_ID']==8]\nltc = df_train[df_train['Asset_ID']==9]\nmkr = df_train[df_train['Asset_ID']==10]\nmnr = df_train[df_train['Asset_ID']==11]\nstl = df_train[df_train['Asset_ID']==12]\ntrn = df_train[df_train['Asset_ID']==13]","ed35ebd4":"bnc = bnc.reindex(range(bnc.index[0],bnc.index[-1]+60,60),method='pad')\nbtc = btc.reindex(range(btc.index[0],btc.index[-1]+60,60),method='pad')\nbcs = bcs.reindex(range(bcs.index[0],bcs.index[-1]+60,60),method='pad')\ncrd = crd.reindex(range(crd.index[0],crd.index[-1]+60,60),method='pad')\ndog = dog.reindex(range(dog.index[0],dog.index[-1]+60,60),method='pad')\neos = eos.reindex(range(eos.index[0],eos.index[-1]+60,60),method='pad')\neth = eth.reindex(range(eth.index[0],eth.index[-1]+60,60),method='pad')\netc = etc.reindex(range(etc.index[0],etc.index[-1]+60,60),method='pad')\niot = iot.reindex(range(iot.index[0],iot.index[-1]+60,60),method='pad')\nltc = ltc.reindex(range(ltc.index[0],ltc.index[-1]+60,60),method='pad')\nmkr = mkr.reindex(range(mkr.index[0],mkr.index[-1]+60,60),method='pad')\nmnr = mnr.reindex(range(mnr.index[0],mnr.index[-1]+60,60),method='pad')\nstl = stl.reindex(range(stl.index[0],stl.index[-1]+60,60),method='pad')\ntrn = trn.reindex(range(trn.index[0],trn.index[-1]+60,60),method='pad')\n","4efa211a":"df_train","509f3935":"df_train['Target'] = df_train.groupby(['Asset_ID'], sort=False)['Target'].apply(lambda x: x.fillna(x.mean()))","148ef47d":"df_train","22353c0f":"train = df_train[:100000]\ntrain","a505f414":"y_train = train.Target.copy()\ny_train.shape","3226e1a3":"x_train = train.drop(['Target','Asset_ID','Open','High','Low'],axis = 1)\nprint(x_train.shape)\nprint(x_train.head(5))","fab0b703":"x_train = x_train.to_numpy().reshape(-1,5,1)\nx_train.shape","0417e4b9":"from sklearn.model_selection import train_test_split\ntrain_x, val_x, train_y, val_y = train_test_split(x_train, y_train, test_size = 0.25, random_state=2)","e7cc4dcf":"from keras.layers import Dense, LSTM, Dropout, GRU\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD\n# The GRU architecture\nmodel = Sequential()\n# First GRU layer with Dropout regularisation\nmodel.add(GRU(units=50, return_sequences=True, input_shape=(train_x.shape[1],1), activation='tanh'))\nmodel.add(Dropout(0.2))\n# Second GRU layer\nmodel.add(GRU(units=50, return_sequences=True, input_shape=(train_x.shape[1],1), activation='tanh'))\nmodel.add(Dropout(0.2))\n# Third GRU layer\nmodel.add(GRU(units=50, return_sequences=True, input_shape=(train_x.shape[1],1), activation='tanh'))\nmodel.add(Dropout(0.2))\n# Fourth GRU layer\nmodel.add(GRU(units=50, activation='tanh'))\nmodel.add(Dropout(0.2))\n# The output layer\nmodel.add(Dense(units=1))","f9426a88":"from keras.metrics import accuracy\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer = optimizer, loss='mse', metrics = ['mae'])\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                          mode=\"min\",\n                          patience=5)\nmodel.summary()","150a2f87":"history=model.fit(x_train,y_train, batch_size=64,epochs=5,validation_data=(val_x,val_y), callbacks=[early_stopping], shuffle=True)","a6d50140":"# Diffining Figure\nimport matplotlib.pyplot as plt\nfigure = plt.figure(figsize=(20,7))\n\n#Adding Subplot 1 (For Accuracy)\nfigure.add_subplot(121)\n\nplt.plot(history.epoch,history.history['mae'],label = \"mae\") # Accuracy curve for training set\nplt.plot(history.epoch,history.history['val_mae'],label = \"val_mae\") # Accuracy curve for validation set\n\nplt.title(\"MAE Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"MAE\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n#Adding Subplot 1 (For Loss)\nfigure.add_subplot(122)\n\nplt.plot(history.epoch,history.history['loss'],label=\"loss\") # Loss curve for training set\nplt.plot(history.epoch,history.history['val_loss'],label=\"val_loss\") # Loss curve for validation set\n\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()","000ffcae":"mantap = model.predict(val_x)\nval_y, mantap","d24d0c75":"import gresearch_crypto\nenv = gresearch_crypto.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","0a55bccb":"index = 0\nfor (test_df, sample_prediction_df) in iter_test:\n#     x_train = train.drop(['Target','Asset_ID','Open','High','Low'],axis = 1)\n    test_df = test_df.drop(['Asset_ID','Open','High','Low','row_id'],axis = 1)\n    test_df = test_df.to_numpy().reshape(-1,5,1)\n    test_y = model.predict(test_df)\n    sample_prediction_df['Target'] = 0\n    sample_prediction_df['Target'] = test_y\n#     print(test_df.shape)\n#     print(sample_prediction_df.shape)\n#     print(sample_prediction_df)\n    env.predict(sample_prediction_df)\n\n    index += 1","65c66284":"# EDA & PREPROCESSING","ae519853":"# CREATE THE MODEL"}}