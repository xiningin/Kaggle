{"cell_type":{"8d53387b":"code","74cad088":"code","339709f4":"code","26af1a65":"code","acdd9e63":"code","c25b0ef7":"code","ea500f14":"code","b9396b21":"code","6fcee469":"code","7aff4f3d":"code","3ae9249e":"code","d53ecc1a":"code","2f441c40":"code","d2574c32":"code","4c068049":"code","ddf66c3e":"code","6f6e9bf9":"code","ba965885":"code","59428894":"code","1502557f":"code","7861f01a":"code","894c1fd6":"code","dce61ca3":"markdown","c84332cc":"markdown","01b43a79":"markdown","59d12fcb":"markdown"},"source":{"8d53387b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74cad088":"df = pd.read_csv('\/kaggle\/input\/disaster-tweets\/tweets.csv')","339709f4":"df.head()","26af1a65":"df_1 = df[['text','target']]","acdd9e63":"df_1.head()","c25b0ef7":"y = df_1['target']\ny = np.array(y)\ny","ea500f14":"x = df_1.text.values","b9396b21":"x","6fcee469":"from tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(x)","7aff4f3d":"len(tokenizer.word_index)","3ae9249e":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nvocab_size = len(tokenizer.word_index) + 1\nencoded_docs = tokenizer.texts_to_sequences(x)\npadded_sequence = pad_sequences(encoded_docs, maxlen=200)","d53ecc1a":"x[0]","2f441c40":"encoded_docs[0]","d2574c32":"padded_sequence[0]","4c068049":"padded_sequence.shape","ddf66c3e":"#Building LSTM MODEL\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import SpatialDropout1D\nfrom tensorflow.keras.layers import Embedding\nembedding_vector_length = 32\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_vector_length,     \n                                     input_length=200) )\nmodel.add(SpatialDropout1D(0.25))\nmodel.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(120,return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(40))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', \n                           metrics=['accuracy'])","6f6e9bf9":"model.summary()","ba965885":"history = model.fit(padded_sequence,y,\n                  validation_split=0.2, epochs=7, batch_size=32)\n","59428894":"def predict(tweet):\n    test_word = tweet\n    tw = tokenizer.texts_to_sequences([test_word])\n    tw = pad_sequences(tw,maxlen=200)\n    prediction = int(model.predict(tw).round().item())\n    if(prediction==0):\n        return('No Disaster')\n    else:\n        return('Disaster')\n","1502557f":"predict('Breaking news:Nigeria flag set ablaze in Aba.')","7861f01a":"predict('On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE')","894c1fd6":"predict(\"Evacuation drill at work. The fire doors wouldn't open so i got to smash the emergency release glass #feelingmanly\")","dce61ca3":"#tokenizer.word_index\n\n\nto check whcih word has been assigned what value","c84332cc":"Visualize text preprocessing","01b43a79":"our target and feature columns have been made now some text pre processing","59d12fcb":"We would take only useful columns here that is text and target"}}