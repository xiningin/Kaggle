{"cell_type":{"94b88b5f":"code","bd1b1f2b":"code","2de1aa60":"code","6770b79a":"code","f97abb32":"code","c8def777":"code","e54ac34f":"code","ba235aa6":"code","c4f420d1":"code","7aaee6bf":"code","a0c23d6c":"code","8ffba7d2":"code","d9e1f1d9":"code","a3de401f":"code","46692464":"code","b44d8583":"code","c546750f":"code","308c199f":"code","790033cc":"code","129f7309":"code","2662e4f3":"code","0a0ee05f":"code","d39acc8b":"code","7f0d30e1":"code","c776b942":"code","0d1f9e56":"code","6d8339e5":"code","21fef8e5":"code","4fb4aba5":"code","3433a87d":"code","cc23a52a":"code","8eef5494":"code","e28fe14d":"code","28bdc6c7":"code","15591e8c":"code","40332bd6":"code","cf97eb8a":"code","abe2b0a5":"code","757bc27f":"code","2fbc6139":"code","6f670fde":"code","701fb128":"code","f6d71511":"code","57e118cd":"code","2a9baf8d":"code","6369bd48":"code","27f81a71":"code","41070f4f":"code","05df5b35":"code","5734cea4":"code","1239dcb8":"code","ccf758b8":"code","f1b552bf":"code","26067cc9":"code","59b95429":"code","ba0ee64b":"code","29a83272":"code","4f439abf":"code","e880aab7":"code","b9f2efb6":"code","23a151f9":"code","c62c0acc":"code","67b7c637":"code","702f12a0":"code","7047ca0e":"code","290a3d8d":"code","7e3abad3":"code","d2d240c5":"code","e1c17435":"code","5f18a190":"code","24bc6a6b":"code","aaa802cb":"code","713e4a7c":"code","b172948c":"code","5af0fe4e":"markdown","cb04d7fe":"markdown","68773c94":"markdown","9693a359":"markdown","a8ca81fb":"markdown","f0a5289e":"markdown","bd154e4d":"markdown","f9042b8d":"markdown","6f96ab96":"markdown","f231f511":"markdown","a6abb305":"markdown","1643ae97":"markdown","66c2aa12":"markdown","b69051a1":"markdown","1e1c85d2":"markdown","607a27f1":"markdown","d72d71fa":"markdown","7168b41f":"markdown","133063a5":"markdown","37bd650d":"markdown","b7cfa710":"markdown","d5861cc0":"markdown"},"source":{"94b88b5f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPool2D,Dense,Dropout,Softmax,Input,Flatten\nfrom keras.optimizers import Adam,RMSprop,SGD\nfrom keras.layers.merge import add\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import BatchNormalization\nfrom math import ceil\n\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n#attempt to fix reproducibility issue (hard to get reproducible results even after setting seed)\nfrom tensorflow import set_random_seed\nos.environ['PYTHONHASHSEED'] = \"0\"\nnp.random.seed(1)\nset_random_seed(2)\n\nprint(os.listdir(\"..\/input\/chest_xray\/chest_xray\"))\n\n# Any results you write to the current directory are saved as output.","bd1b1f2b":"auggen = ImageDataGenerator(\n#         rotation_range=40,\n#         width_shift_range=0.1,\n#         height_shift_range=0.1,\n# #         shear_range=0.2,\n# #         zoom_range=0.2,\n#         horizontal_flip=True,\n#         vertical_flip=True,\n        rescale=1.\/255\n        )\nauggen = auggen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/train\",\n                                    target_size=(256, 256), color_mode='rgb',  class_mode='binary', \n         batch_size=32, shuffle=True, seed=1)","2de1aa60":"auggen.class_indices","6770b79a":"i=0\nk=0\nfig,axis1 = plt.subplots(1,10,figsize=(60,60))\n\n#augggen.flow_from_directory returns a DirectoryIterator yielding tuples of (x, y) for each iteration where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels.\n#here we unpack the tuple into the first element, images, which is of dimension (batch_size,length, width, number of color channels)\n#think of the number of iterations that the DirectoryIterator object undergoes as the steps_per_epoch parameter in the fit method\n\n#if we set class_mode= categorical then the labels will be hot encoded, if we set class_mode=binary then it will be a 1d array\n#outer loop is used to iterate ove auggen (generator object)\nfor images,labels in  auggen:\n    print(images.shape)\n    print(labels[0])\n    \n    #iterating over images in the first batch in order to plot\n    for image in images:\n        print(image.shape)\n\n        axis1[k].imshow(image)\n        axis1[k].set_title(labels[k],fontdict={'fontsize':50})\n        k=k+1\n        #I only want to plot the first 10 images but we have all 32 available in images variable after 1st iteration\n        if k==10:\n            break\n    \n    i=i+1\n    if i==1:\n        break\n    ","f97abb32":"print('total number of positive instances (pneumonia) in first batch of 32: {}'.format(sum(labels)))","c8def777":"traingen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        rescale=1.\/255\n        )\ntestgen = ImageDataGenerator(\n        rescale=1.\/255\n        )\n\nvalgen = ImageDataGenerator(\n        rescale=1.\/255\n        )\n","e54ac34f":"\ntraingen = traingen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/train\", \n    target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=32, shuffle=True, seed=1)\n        \n                                   \n\n                                   \n                                                                      \n                                   ","ba235aa6":"testgen = testgen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/test\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=25, shuffle=False)\n                                   ","c4f420d1":"valgen = valgen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/val\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=16, shuffle=False)","7aaee6bf":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\",\n                 input_shape=(256,256,1)))\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n# model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n# model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(rate=0.4))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['binary_accuracy'])","a0c23d6c":"model.summary()","8ffba7d2":"history=model.fit_generator(\n        traingen,\n    \n        steps_per_epoch=5216\/32,\n        validation_data=valgen,\n        validation_steps=4,\n        epochs=3,\n        class_weight = {0:2.94,\n                        1:1}\n)","d9e1f1d9":"len(testgen)","a3de401f":"type(testgen)","46692464":"model.evaluate_generator(testgen, steps = len(testgen))\n","b44d8583":"testgen = ImageDataGenerator(\n        rescale=1.\/255\n        )\ntestgen = testgen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/test\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=25, shuffle=False)","c546750f":"y_pred=model.predict_generator(testgen, steps = len(testgen), verbose=1)","308c199f":"y_pred[0:10]","790033cc":"def map_probs(y_predict, T):   \n    k=0\n    for i in y_predict:\n        if y_predict[k]>=T:\n            y_predict[k]=1\n        else:\n            y_predict[k]=0\n        k=k+1\n    return y_predict\n","129f7309":"y_pred_binary=map_probs(y_pred,.5)    \n","2662e4f3":"y_pred_binary[0:10]","0a0ee05f":"y_true=testgen.classes","d39acc8b":"y_true","7f0d30e1":"from sklearn.metrics import confusion_matrix\n\nconfusion_m=confusion_matrix(y_true, y_pred_binary)","c776b942":"confusion_m","0d1f9e56":"tn=confusion_m[0][0]\nfp=confusion_m[0][1]\nfn=confusion_m[1][0]\ntp=confusion_m[1][1]","6d8339e5":"accuracy=(tp+tn)\/(tp+fp+fn+tn)\nprint(\"the accuracy of the model is {} %\".format(accuracy*100))","21fef8e5":"recall = (tp)\/(tp+fn)\nprint(\"the recall of the model is {} %\".format(recall*100))","4fb4aba5":"#\nlabels = ['normal', 'pneumonia']\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(confusion_m)\nplt.title('Confusion matrix of the classifier', pad =20)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n","3433a87d":"traingen2 = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        rescale=1.\/255\n        )\ntestgen2 = ImageDataGenerator(\n        rescale=1.\/255\n        )\n\nvalgen2 = ImageDataGenerator(\n        rescale=1.\/255\n        )\n","cc23a52a":"\ntraingen2 = traingen2.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/train\", \n    target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=32, shuffle=True, seed=1)\n        \n                                   \n\n                                   \n                                                                      \n                                   ","8eef5494":"testgen2 = testgen2.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/test\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=25, shuffle=False)\n                                   ","e28fe14d":"valgen2 = valgen2.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/val\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=16, shuffle=False)","28bdc6c7":"from keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras.layers.convolutional import SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom math import ceil\nimport matplotlib.pyplot as plt\n\n\n\nchanDim = -1\n\nmodel2 = Sequential()\n\nmodel2.add(SeparableConv2D(32, (3, 3), padding=\"same\",\ninput_shape=(256,256,1)))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n \n# (CONV => RELU => POOL) * 2\nmodel2.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n \n# (CONV => RELU => POOL) * 3\nmodel2.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\nmodel2.add(Activation(\"relu\"))\nmodel2.add(BatchNormalization(axis=chanDim))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\nmodel2.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel2.add(Dense(256, activation ='relu'))\nmodel2.add(BatchNormalization())\n\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(1, activation ='sigmoid'))\n# model.add(Activation('softmax'))\n\n\nmodel2.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['binary_accuracy'])\n\nmodel2.summary()\n","15591e8c":"history2=model2.fit_generator(\n        traingen2,\n    \n        steps_per_epoch=5216\/32,\n        validation_data=valgen,\n        validation_steps=4,\n        epochs=3,\n        class_weight = {0:2.94,\n                        1:1}\n)","40332bd6":"model2.evaluate_generator(testgen2, steps = len(testgen2))\n","cf97eb8a":"testgen = ImageDataGenerator(\n        rescale=1.\/255\n        )\n\ntestgen = testgen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/test\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=100, shuffle=False)\n","abe2b0a5":"#iteration 1\nimages,labels = testgen.next()","757bc27f":"labels","2fbc6139":"#iteration 2\nimages2,labels2 = testgen.next()","6f670fde":"labels2","701fb128":"#iteration 3 \nimages3,labels3 = testgen.next()","f6d71511":"labels3","57e118cd":"images4,labels4 = testgen.next()","2a9baf8d":"labels4","6369bd48":"images5,labels5 = testgen.next()","27f81a71":"labels5","41070f4f":"images6,labels6 = testgen.next()","05df5b35":"labels6","5734cea4":"images7,labels7 = testgen.next()","1239dcb8":"#last batch, 6*100=600 images and labels generated so far, we have a total of 624 total files, therefor our last batch has 24 images and this is what we see\nlabels7","ccf758b8":"\nimages8,labels8 = testgen.next()","f1b552bf":"labels8","26067cc9":"images9,labels9 = testgen.next()","59b95429":"labels9","ba0ee64b":"images10,labels10 = testgen.next()","29a83272":"labels10","4f439abf":"testgen.classes","e880aab7":"images11,labels11 = testgen.next()","b9f2efb6":"labels11","23a151f9":"testgen.classes","c62c0acc":"images12,labels12 = testgen.next()","67b7c637":"labels12","702f12a0":"images13,labels13 = testgen.next()","7047ca0e":"labels13","290a3d8d":"images14,labels14 = testgen.next()","7e3abad3":"labels14","d2d240c5":"testgen = ImageDataGenerator(\n        rescale=1.\/255\n        )\n\ntestgen = testgen.flow_from_directory(directory=\"..\/input\/chest_xray\/chest_xray\/test\", \n                                      target_size=(256, 256), color_mode='grayscale',  class_mode='binary', \n         batch_size=100, shuffle=False)\n","e1c17435":"model.evaluate_generator(testgen, steps = len(testgen))\n","5f18a190":"y_pred=model.predict_generator(testgen, steps = len(testgen))","24bc6a6b":"#run the next iteration yielding 100 images\nimages,labels=testgen.next()","aaa802cb":"labels","713e4a7c":"images2,labels2=testgen.next()","b172948c":"labels2","5af0fe4e":"## Dealing with imbalance strategy #1","cb04d7fe":"Seeing if model predicted values from 0 to 1 or if it's guessing the same class always (naive model) by seeing first 10 values","68773c94":"**Mapping between integers and class[](http:\/\/)**","9693a359":"### Plotting confusion matrix","a8ca81fb":"### Visualizing Data Augmentation (And a look into how the ImageDataGenerator class works)","f0a5289e":"Getting the true classes","bd154e4d":"This shows that we have to reinstantiate the ImageDataGenerator after calling .evaluate_generator() and before calling .predict_generator(). If we evaluate the model by hand without reinstantiating we will get innacurate results","f9042b8d":"* **ALOT OF THE ITERATIONS TRIED NOT SHOWN, THEY MESSED WITH BATCH SIZE, STEPS PER EPOCH, AND CLASS WEIGHT. ONLY ITERATON THAT MADE A SIGNIFICANT DIFFERENCE CAN BE FOUND IN THE UPDATE**\n* **Model biased towards always predicting pneumonia, tried to fix it by providing class weights, it seemed to work and reached 72% on the test set for one iteration but was not able to reproduce the results**\n\n* *I started to look into how to fix reproducibility issue, setting Shuffle=False and provinding constant seed value was not enough for some people*\nhttps:\/\/keras.io\/getting-started\/faq\/#how-can-i-obtain-reproducible-results-using-keras-during-development\n\n* Sometimes, the model seems to begin with a loss of close to 11 and an accuracy of 22%, much lower than normal. I wonder if this is because the initialization of the parameters is randomized and it's getting stuck at a valley in the loss function\n\n* **UPDATE: SEEMS TO PREDICT A LOT BETTER BY ELIMINATING BIASED FOR THE CLASS CONTAINING THE MOST INSTANCES. BIASED WAS FIXED AFTER I TOOK THE RATIO OF THE NUMBER OF INSTANCES IN BOTH CLASSES. (1341\/3875) = .34\/1 and then I cross muliply to find the class weights for the normal class given that I set the class weight for pneumonia =1. (do a ratio\/cross multiply), logical will tell you ( and math) that the class containing the highest instance needs to be penalized more, which is true, but with the way the class_weight argument is implemented it seems we need to give a higher weight to the class that appears less in the dataset... this is how the argument is implemented but it should translate to a heavier penalty in the loss function for the class that appears the most **\n\n* **UPDATE:** reproducibility when using .evaluate_generator and .predict_generator was achieved after realizing that the generator object had to be reinstantiated after running model.evaluate_generator. You can't run model.predict_generator right after model.evaluate_generator is run without running code to re instantiate the test generator. I think this has to do with how generator work and I will investigate in the following blocks. The generator should also be reinstantiated each time model.predict_generator is run... but for some reason there is no need after running model.evaluate_generator","6f96ab96":"Map predicted values to a 1 or 0 based on given Threshold","f231f511":"## Summary of results","a6abb305":"*  **Seed** is an argument used for shuffling and transformations, we set it to a constant, that way we always shuffle the data the same way and end up seeing the same 32 images in our first iteration even if we re-run the code, because the seed for shuffling will be the same\n* **Shuffle** is set to true otherwise the generator starts generating images in order before all images are shuffled.If using .flow_from_dataframe, images are generated in order from top of the dataframe to the bottom, the dataframe contains the filename of the images and we point to the directorys storing the images. with anotehr argument in the method. if .flow_from_directory is used, we only point to the directory containing all images then, images are sorted alphanumerically before we start chooring images in the alphanumeric order. for both methods, the generator will generate batches equal to the batchsize in the order stated above (if shuffle=False) and generate the next batch starting where it left off until it reaches the set number of batch generations (set with steps_epoch parameter)\n* **Note:** seed is set to a constant in here for displaying purposes so we can see how the seed parameter works, in the training we want the seed to be randomly generated (default) to add more randomness and Shuffle=True (so the images arent sorted alphanumerically) \n","1643ae97":"## Trying a new architecture","66c2aa12":"Train set class proportions\n* Pneumonia: 3875\n* Normal: 1341\n* **66% imbalance!!!!!! **","b69051a1":"## Trying a new architecture","1e1c85d2":"Remember, only 10 are plotted but labels has the labels for all 32 images that are generated in the first iteration (the outer loop)","607a27f1":"Seeing if Threshold function worked by seeing first 10 values","d72d71fa":"## EDA","7168b41f":"The following test is done to see that if we call .evaluate and then call .predict right after, the generators internal attribute that specifies what index we are currently at is not reset to the first image. For some reason, the index ends up at the position batch_size+1, additionally, to get the true y labels we run y_true=testgen.classes, this always starts at image[0] and ends at image[size of test data], therefore if we run, .predict after .eval, we wont be comparing the same images to each other.","133063a5":"## Testing running .predict_generator after .evaluate_generator","37bd650d":"### Model Building","b7cfa710":"## A further look into generator (Only if interested)","d5861cc0":"strategy:\n* How: Using **class weights argument** in model.fit_generator() method \n* Why: to **more heavily penalize an incorrect normal prediction** (y_predicted=0) to bias model towards predicting y=0 more often, otherwise model will be biased toward predicting y=1 because there are 66% more y=1 instances."}}