{"cell_type":{"8f563865":"code","d2f38612":"code","928e342c":"code","4ad49094":"code","0efd3325":"code","8bd9956f":"code","880b5507":"code","00bcec5f":"code","8389dc17":"markdown","8c59f0ca":"markdown","c8306df3":"markdown","5479d969":"markdown","a0c67421":"markdown"},"source":{"8f563865":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport glob\nimport pydicom\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/siim-acr-pneumothorax-segmentation\"))\nprint(os.listdir(\"..\/input\/siim-test-train\/siim\"))\nimport sys\nsys.path.insert(0, '..\/input\/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask\n\n# Any results you write to the current directory are saved as output.","d2f38612":"im_height = 1024\nim_width = 1024\nim_chan = 1\n\nprint('reading input images and mask dataset.....') \ndf = pd.read_csv('..\/input\/siim-acr-pneumothorax-segmentation\/sample images\/train-rle-sample.csv', header=None, index_col=0)\n\nX_train = np.zeros((10, im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((10, im_height, im_width, 1), dtype=np.bool)\n\nfor q, file_path in enumerate(glob.glob('..\/input\/siim-acr-pneumothorax-segmentation\/sample images\/*.dcm')):\n    dataset = pydicom.dcmread(file_path)\n    X_train[q] = np.expand_dims(dataset.pixel_array, axis=2)\n    if df.loc[file_path.split('\/')[-1][:-4],1] != '-1':\n        Y_train[q] = np.expand_dims(rle2mask(df.loc[file_path.split('\/')[-1][:-4],1], 1024, 1024).T, axis=2)\n    else:\n        Y_train[q] = np.zeros((1024, 1024, 1))\nprint('done!')      ","928e342c":"from skimage.color import label2rgb\nfig = plt.figure(figsize=(30, 30))\nprint('Preparing for visualization...')\nfor q, file_path in enumerate(glob.glob('..\/input\/siim-acr-pneumothorax-segmentation\/sample images\/*.dcm')):\n    plt.subplot(3,10,q+1)\n    plt.title('Input Images')\n    plt.imshow(X_train[q,:,:,0],cmap='gray')\n    plt.axis('off')\n    \n    plt.subplot(3,10,q+11)    \n    plt.title('mask Images')\n    plt.imshow(Y_train[q,:,:,0])\n    plt.axis('off')\n    \n    plt.subplot(3,10,q+21)\n    plt.title('overlap Images')\n    plt.imshow(label2rgb(Y_train[q,:,:,0], image = X_train[q,:,:,0],alpha = 0.3))\n    plt.axis('off') \nprint('done')    ","4ad49094":"#!pip install tensorflow-gpu==2.0.0-alpha0\nimport tensorflow as tf\ntf.__version__","0efd3325":"import random\nimport warnings\n\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dropout, Lambda\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras import backend as K\n\nimport tensorflow as tf\n\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\nrandom.seed = seed\n#np.random.seed = seed","8bd9956f":"# Build U-Net model\ninputs = Input((im_height, im_width, im_chan))\ns = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (s)\nc1 = BatchNormalization()(c1)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\nc1 = BatchNormalization()(c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = BatchNormalization()(c2)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\nc2 = BatchNormalization()(c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = BatchNormalization()(c3)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\nc3 = BatchNormalization()(c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = BatchNormalization()(c4)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\nc4 = BatchNormalization()(c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = BatchNormalization()(c5)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\nc5 = BatchNormalization()(c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = BatchNormalization()(c6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\nc6 = BatchNormalization()(c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = BatchNormalization()(c7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\nc7 = BatchNormalization()(c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = BatchNormalization()(c8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\nc8 = BatchNormalization()(c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = BatchNormalization()(c9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\nc9 = BatchNormalization()(c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)","880b5507":"model = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","00bcec5f":"tf.keras.utils.plot_model(model,to_file='unet_model.png',show_shapes=True,show_layer_names=True,rankdir='TB')","8389dc17":"#  Primary_Data_Read\n* here the visualization of sample dataset which contain 10 images.\n* read the image dataset & store it in X_train variable","8c59f0ca":"# Unet model\n![image.png](attachment:image.png)","c8306df3":"# Install Tensorflow2.0\n* check the version","5479d969":"# import packages for model","a0c67421":"# Primary_Data_Visualization"}}