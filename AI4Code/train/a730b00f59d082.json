{"cell_type":{"f5fb6cda":"code","075302b0":"code","0e741a4b":"code","0c2894fd":"code","43fe855c":"code","f122c7bd":"code","ad57e1dc":"code","aeef6403":"code","2f3097f7":"code","18147198":"code","8827260e":"code","1a495d50":"code","0fd11640":"code","c4d8007b":"code","9294d6ee":"code","7e82e1b5":"code","94611a8d":"code","cc33ea16":"markdown"},"source":{"f5fb6cda":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import KFold\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nfrom contextlib import contextmanager # timer\nfrom functools import partial\nimport cv2\nimport seaborn as sns\nimport SimpleITK as sitk\nimport matplotlib.pylab as plt\nfrom sklearn.model_selection import KFold\nimport random\nfrom skimage.transform import rescale, resize\nfrom scipy.ndimage import rotate\nimport torch\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader, Dataset\nimport SimpleITK as sitk\nprint(os.listdir(\"..\/input\/\"))\nfrom skimage import data, img_as_float\nfrom skimage import exposure","075302b0":"def batch_generator(batch_size, gen_x): \n    batch_features = np.zeros((batch_size,256,256,3))\n    batch_labels = np.zeros((batch_size,256,256,3)) \n    while True:\n        for i in range(batch_size):\n            batch_features[i] , batch_labels[i] = next(gen_x)\n        yield batch_features, batch_labels","0e741a4b":"def gaussian_noise(img, mean=0, sigma=0.03):\n    img = img.copy()\n    noise = np.random.normal(mean, sigma, img.shape)\n    mask_overflow_upper = img+noise >= 1.0\n    mask_overflow_lower = img+noise < 0\n    noise[mask_overflow_upper] = 1.0\n    noise[mask_overflow_lower] = 0\n    img += noise\n    return img\n\n#https:\/\/towardsdatascience.com\/complete-image-augmentation-in-opencv-31a6b02694f5\ndef brightness(img, low, high):\n    value = random.uniform(low, high)\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    hsv = np.array(hsv, dtype = np.float64)\n    hsv[:,:,1] = hsv[:,:,1]*value\n    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n    hsv[:,:,2] = hsv[:,:,2]*value \n    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n    hsv = np.array(hsv, dtype = np.uint8)\n    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    return img\n\n#https:\/\/towardsdatascience.com\/complete-image-augmentation-in-opencv-31a6b02694f5\ndef fill(img, h, w):\n    img = img.astype('float32')\n    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n    return img\ndef zoom(img, mask, value):\n    if value > 1 or value < 0:\n        print('Value for zoom should be less than 1 and greater than 0')\n        return img, mask\n    value = random.uniform(value, 1)\n    h, w = img.shape[:2]\n    h_taken = int(value*h)\n    w_taken = int(value*w)\n    h_start = random.randint(0, h-h_taken)\n    w_start = random.randint(0, w-w_taken)\n    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n    img = fill(img, h, w)\n    mask = mask[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n    mask = fill(mask, h, w)\n    return img, mask\n\n# https:\/\/towardsdatascience.com\/complete-image-augmentation-in-opencv-31a6b02694f5\ndef vertical_shift(img, mask, ratio=0.0):\n    if ratio > 1 or ratio < 0:\n        print('Value should be less than 1 and greater than 0')\n        return img, mask\n    ratio = random.uniform(-ratio, ratio)\n    h, w = img.shape[:2]\n    to_shift = h*ratio\n    if ratio > 0:\n        img = img[:, :int(w-to_shift), :]\n        mask = mask[:, :int(w-to_shift), :]\n    if ratio < 0:\n        img = img[:, int(-1*to_shift):, :]\n        mask = mask[:, int(-1*to_shift):, :]\n    img = fill(img, h, w)\n    mask = fill(mask, h, w)\n    return img, mask\n\n# https:\/\/towardsdatascience.com\/complete-image-augmentation-in-opencv-31a6b02694f5 \ndef horizontal_shift(img, mask, ratio=0.0):\n    if ratio > 1 or ratio < 0:\n        print('Value should be less than 1 and greater than 0')\n        return img, mask\n    ratio = random.uniform(-ratio, ratio)\n    h, w = img.shape[:2]\n    to_shift = w*ratio\n    if ratio > 0:\n        img = img[:, :int(w-to_shift), :]\n        mask = mask[:, :int(w-to_shift), :]\n    if ratio < 0:\n        img = img[:, int(-1*to_shift):, :]\n        mask = mask[:, int(-1*to_shift):, :]\n    img = fill(img, h, w)\n    mask = fill(mask, h, w)\n    return img,mask","0c2894fd":"def generate_data(filelist, img_path, mask_path, gen_type = \"train\"):\n    while True:\n        for i in filelist:\n            X_train = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n            y_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n            y_mask = cv2.resize(y_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n            y_train = (y_mask\/255).astype(int)\n            if gen_type == \"train\":\n                # returns a random integer used to select augmentataion techniques for a given sample\n                augment_num = np.random.randint(0,9)\n                if augment_num == 0:\n                    # do nothing\n                    X_train = X_train\n                elif augment_num == 1:\n                    #random noise\n                    X_train = X_train + np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])*np.random.randint(-100,100)\n                elif augment_num == 2:\n                    X_train = cv2.GaussianBlur(X_train,(random.randrange(1,50,2),random.randrange(1,50,2)), 0)\n                elif augment_num == 3:\n                    rot = np.random.randint(-45,45)\n                    X_train = rotate(X_train,rot, reshape=False)\n                    y_train = rotate(y_train,rot, reshape=False)\n                elif augment_num == 4:\n                    X_train = brightness(X_train,0.5,3)\n                elif augment_num == 5:\n                    X_train = np.fliplr(X_train)\n                    y_train = np.fliplr(y_train)\n                elif augment_num == 6:\n                    X_train = np.flipud(X_train)\n                    y_train = np.flipud(y_train)\n                elif augment_num == 7:\n                    hshift = round(random.uniform(0.1, 0.3),3)\n                    X_train, y_train = horizontal_shift(X_train, y_train, hshift)\n                elif augment_num == 8:\n                    vshift = round(random.uniform(0.1, 0.3),3)\n                    X_train, y_train = vertical_shift(X_train, y_train, vshift)\n                elif augment_num == 9:\n                    zoom_rate = round(random.uniform(0.8, 0.95),3)\n                    X_train, y_train = zoom(X_train, y_train, zoom_rate)\n                elif augment_num == 10:\n                    #contrast\n                    X_train = exposure.equalize_adapthist(X_train.astype(int), clip_limit=0.03)  \n                elif augment_num == 11:\n                    #contrast\n                    X_train = exposure.equalize_hist(X_train.astype(int))  \n            yield X_train, y_train","43fe855c":"def generate_data_pred(filelist, img_path, mask_path, gen_type = \"train\"):\n    while True:\n        for i in filelist:\n            original_img = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n            X_train = cv2.resize(original_img, (256,256), interpolation= cv2.INTER_LINEAR )\n            if gen_type == \"train\":\n                X_train = X_train * np.random.choice([1,1,1,np.random.rand(256, 256,3)])\n            original_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n            y_mask = cv2.resize(original_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n            y_mask = (y_mask\/255).astype(int)\n            yield original_img, original_mask, X_train, y_mask","f122c7bd":"def dice_score(mask_gt, mask_pred):\n    \"\"\"Computes soerensen-dice coefficient.\n\n    compute the soerensen-dice coefficient between the ground truth mask `mask_gt`\n    and the predicted mask `mask_pred`.\n\n    Args:\n    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n\n    Returns:\n    the dice coeffcient as float. If both masks are empty, the result is NaN.\n    \"\"\"\n    volume_sum = mask_gt.sum() + mask_pred.sum()\n    if volume_sum == 0:\n        return np.NaN\n    volume_intersect = (mask_gt & mask_pred).sum()\n    return 2*volume_intersect \/ volume_sum ","ad57e1dc":"from keras import backend as K\n# From: https:\/\/gist.github.com\/wassname\/7793e2058c5c9dacb5212c0ac0b18a8a\ndef dice_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    Dice = (2*|X & Y|)\/ (|X|+ |Y|)\n         =  2*sum(|A*B|)\/(sum(A^2)+sum(B^2))\n    ref: https:\/\/arxiv.org\/pdf\/1606.04797v1.pdf\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","aeef6403":"def jacard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) \/ (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\n\ndef jacard_coef_loss(y_true, y_pred):\n    return 1-jacard_coef(y_true, y_pred)","2f3097f7":"from tensorflow.keras import layers\nimport tensorflow as tf\n\n\ndef get_model(img_size, num_classes):\n\n    inputs = tf.keras.Input(shape=img_size + (3,))\n    #inputs = tf.keras.Input(shape=(256,256,3))\n    #inputs = tf.keras.Input(shape=img_size + (1,))\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n\n    # Define the model\n    model = tf.keras.Model(inputs, outputs)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n    return model\n\n\n# Free up RAM in case the model definition cells were run multiple times\ntf.keras.backend.clear_session()\n\n# Build model\n#model = get_model(img_size, num_classes)\n\n#model.summary()","18147198":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=3, verbose=0, mode='min',\n    min_delta=0.0001, cooldown=5, min_lr=0\n)","8827260e":"!pip install segmentation-models==1.0.1","1a495d50":"import segmentation_models as sm","0fd11640":"!pip install neptune-client","c4d8007b":"import neptune.new as neptune\nfrom sklearn.metrics import jaccard_score\nimport time\nfrom neptune.new.types import File","9294d6ee":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"my_token\")","7e82e1b5":"import segmentation_models as sm\n\nsm.set_framework('tf.keras')\n\nsm.framework()","94611a8d":"file_list = np.asarray(os.listdir(\"..\/input\/hyperkvasiraugustversion\/Kvasir-SEG\/images\"))\nimage_path = \"..\/input\/hyperkvasiraugustversion\/Kvasir-SEG\/images\/\" \nmask_path = \"..\/input\/hyperkvasiraugustversion\/Kvasir-SEG\/masks\/\"\n\nrun = neptune.init(project='SSCP\/HyperKvasir',\n                   api_token=secret_value_0) # your credentials\n\nall_history= []\nbatchsize = 30\ndata_size = len(file_list)\nnum_epoch = 50\nsplits = 10\nkf = KFold(n_splits=splits)\nvalsize = data_size \/\/ splits\ntrainsize = data_size - valsize\nmy_model = \"efficientnetb1\"\ndata_num = np.arange(data_size)\n\nimg_size = (256, 256)\nnum_classes = 3\n\nrun[\"Dataset\"] = \"Polyp\"\nrun[\"Model\"] = my_model\nrun[\"CV-folds\"] = splits\nrun[\"Epochs\"] = num_epoch\nrun[\"Batch size\"] = batchsize\nrun[\"pretrained\"] = \"Imagenet\"\n##########################################################################################\n# Check what augmentation techniques you use and say \"yes\" or \"no\" in the fields bellow  #\n# You can also add new fields                                                            #\n##########################################################################################\nrun[\"noise\"] = \"yes\"\nrun[\"blurring\"] = \"yes\"\nrun[\"cropping\"] = \"no\"\nrun[\"flipping\"] = \"yes\"\nrun[\"rotation\"] = \"yes\"\nrun[\"zoom\"] = \"yes\"\nrun[\"translation\"] = \"no\"\nrun[\"brightness\"] = \"yes\"\nrun[\"contrast_hist\"] = \"no\"\nrun[\"contrast_adaptive\"] = \"no\"\nrun[\"color augmentation\"] = \"no\"\nrun[\"saturation\"] =\"no\"\nrun[\"horizontal shift\"] = \"yes\"\nrun[\"vertical shift\"] = \"yes\"\n\nvalidation_dice_original = np.zeros([valsize,splits])\nvalidation_dice_resized = np.zeros([valsize,splits])\nvalidation_jaccard_original = np.zeros([valsize,splits])\nvalidation_jaccard_resized = np.zeros([valsize,splits])\n\ncv_count = 0\n\nfor train_index, val_index in kf.split(data_num):\n    #model = get_model(img_size, num_classes)\n    model = sm.Unet(my_model, encoder_weights=\"imagenet\", input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n    model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n    history = model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n                            steps_per_epoch=(trainsize\/batchsize), \n                            validation_steps=(valsize\/batchsize),\n                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \n                            validation_freq=1, \n                            verbose = 0, \n                            callbacks=[reduce_lr],\n                            )\n    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\n    for i in range(valsize):\n        time_start = time.time()\n        original_img, original_mask, X, y_true = next(val_gen)\n        original_shape = original_img.shape\n        y_pred = model.predict(np.expand_dims(X,0))\n        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n        y_pred = (y_pred_thr\/255).astype(int)\n        dice_resized = dice_score(y_true[:,:,0],y_pred)\n        jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"micro\")\n        \n        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n        dice_original = dice_score(original_mask[:,:,0]\/\/255,y_pred_original.astype(int))\n        jaccard_original = jaccard_score(original_mask[:,:,0]\/\/255,y_pred_original.astype(int), average=\"micro\")\n        \n        validation_dice_original[i,cv_count] = dice_original\n        validation_dice_resized[i,cv_count] = dice_resized\n        validation_jaccard_original[i,cv_count] = jaccard_original\n        validation_jaccard_resized[i,cv_count] = jaccard_resized\n        \n        if i < 5:\n            plt.figure(figsize=(20,10))\n            plt.subplot(1,2,1)\n            plt.imshow(original_img[...,::-1], 'gray', interpolation='none')\n            plt.imshow(original_mask\/255.0, 'jet', interpolation='none', alpha=0.4)\n            plt.subplot(1,2,2)\n            plt.imshow(original_img[...,::-1], 'gray', interpolation='none')\n            plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n            plt.show()\n            run['image'].log(File.as_image(original_img[...,::-1]))\n            run['GT_mask'].log(File.as_image(y_true))\n            run['pred_mask'].log(File.as_image(y_pred_original))\n        \n    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\n    dice_original_mean = validation_dice_original[:,cv_count].mean()\n    jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\n    jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\n        \n    print(\"--------------------------------------\")\n    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \n    print(\"Mean validation DICE (on original data):\", dice_original_mean)\n    print(\"--------------------------------------\")\n    print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \n    print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\n    print(\"--------------------------------------\")\n    run[\"Dice Resized\"].log(dice_resized_mean)\n    run[\"Dice Original\"].log(dice_original_mean)\n    run[\"Jaccard Resized\"].log(jaccard_resized_mean)\n    run[\"Jaccard Original\"].log(jaccard_original_mean)\n    runtime = time.time() - time_start \n    print('Runtime: {} sec'.format(runtime))\n    run[\"Runtime\"] = runtime\n    cv_count +=1\n    all_history.append(history.history[\"val_dice_coef\"])\nrun.stop()","cc33ea16":"# <center>Transfer Learning in Polyp and Endoscopic Tool Segmentation from Colonoscopy Images<\/center>\n> Colorectal cancer is one of the deadliest and most widespread types of cancer in the world. Colonoscopy is the procedure used to detect and diagnose polyps from the colon, but today's detection rate shows a significant error rate that affects diagnosis and treatment. An automatic image segmentation algorithm may help doctors to improve the detection rate of pathological polyps in the colon. Furthermore, segmenting endoscopic tools in images taken during colonoscopy may contribute towards robotic assisted surgery. In this study, we trained and validated both pre-trained and not pre-trained segmentation models on two different data sets, containing images of polyps and endoscopic tools. Finally, we applied the models on two separate test sets and the best polyp model got a dice score 0.857 and the test instrument model got a dice score 0.948. Moreover, we found that pre-training of the models increased the performance in segmenting polyps and endoscopic tools.\n\nRead full text here: https:\/\/doi.org\/10.5617\/nmi.9132\n\n\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/www.nora.ai\/Competition\/2dadc75e-8fca-4411-88a0-65a3f1cc92be.jpeg\" alt=\"Polyp\" style=\"height:500px;margin-top:3rem;\"> <\/div>\n<center>Colorectal Polyp. Image is redistributed from: https:\/\/www.nora.ai\/Competition\/image-segmentation.html <\/center>"}}