{"cell_type":{"6484df05":"code","1731eb90":"code","98e5d990":"code","bc5ddb2a":"code","654622c8":"code","3e84a25c":"code","2fceef7c":"code","0e33a9e9":"code","67927a77":"code","f5ce5da3":"code","7da453ca":"code","7a94b3cd":"code","a9a05027":"code","9a32eddb":"code","6a740e56":"code","2da0f1b7":"code","efb4aae1":"code","2f62ff6f":"code","268fa269":"code","bad659c4":"code","f6fee8d4":"code","739cecba":"code","36f1644b":"code","86b1dc4e":"code","812c8cef":"code","12da730f":"code","fb08ab7b":"code","d1190379":"code","ed147a2d":"code","50aa4dd8":"code","51301650":"code","7bc2fdaf":"code","8e309bda":"code","514addc3":"markdown","7c4ab365":"markdown","eff9d356":"markdown","ae0dcb1a":"markdown","b8bd3a6a":"markdown","c58f0dc9":"markdown","a8b3ed58":"markdown","692f67ba":"markdown","d38eeeea":"markdown"},"source":{"6484df05":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nimport tensorflow.keras.layers as Layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image\n\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","1731eb90":"df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')\ndf.head()","98e5d990":"#show sum of nullvalues per feature\ndf.isnull().sum()","bc5ddb2a":"#show datatypes\ndf.info()","654622c8":"#impute unknown to null data points, we don't wanna see those ugly null values\ndf.fillna('unknown', inplace=True)\ndf.isnull().sum()","3e84a25c":"print(df['Label_1_Virus_category'].value_counts())\nprint('='*50)\nprint(df['Label_2_Virus_category'].value_counts())","2fceef7c":"#separate train data and test data\ntrain_data = df[df['Dataset_type']=='TRAIN']\ntest_data = df[df['Dataset_type']=='TEST']\nprint('Train shape: ',train_data.shape)\nprint('Test Shape: ',test_data.shape)","0e33a9e9":"#show a countplot\nplt.figure(figsize=(10,5))\nsns.countplot(train_data['Label_2_Virus_category']);","67927a77":"#get the path of train and test folders\ntrain_img_path = '..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'\ntest_img_path = '..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'","f5ce5da3":"#show sample image\nsamp_img1 = Image.open(os.path.join(train_img_path, train_data['X_ray_image_name'][0]))\nsamp_img2 = Image.open(os.path.join(train_img_path, train_data['X_ray_image_name'][22]))\nfig, ax =plt.subplots(1,2, figsize=(10,5))\nax[0].imshow(samp_img1, cmap='gray');\nax[1].imshow(samp_img2, cmap='gray');","7da453ca":"#sample x-ray image of person with covid-19\nwith_covid = train_data[train_data['Label_2_Virus_category'] == 'COVID-19']\n\n#show sample image\nsamp_img1 = Image.open(os.path.join(train_img_path, with_covid['X_ray_image_name'].iloc[8]))\nsamp_img2 = Image.open(os.path.join(train_img_path, with_covid['X_ray_image_name'].iloc[15]))\nfig, ax =plt.subplots(1,2, figsize=(10,5))\nax[0].imshow(samp_img1);\nax[1].imshow(samp_img2);","7a94b3cd":"#remove Pnuemonia with unknown value\nfinal_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') &\n                               (train_data['Label_2_Virus_category'] == 'COVID-19'))]","a9a05027":"# add a target and class feature\nfinal_train_data['class'] = final_train_data.Label.apply(lambda x: 'negative' if x=='Normal' else 'positive')\ntest_data['class'] = test_data.Label.apply(lambda x: 'negative' if x=='Normal' else 'positive')\n\nfinal_train_data['target'] = final_train_data.Label.apply(lambda x: 0 if x=='Normal' else 1)\ntest_data['target'] = test_data.Label.apply(lambda x: 0 if x=='Normal' else 1)","9a32eddb":"#get the important features\nfinal_train_data = final_train_data[['X_ray_image_name', 'class', 'target', 'Label_2_Virus_category']]\nfinal_test_data = test_data[['X_ray_image_name', 'class', 'target']]","6a740e56":"test_data['Label'].value_counts()","2da0f1b7":"\n\n#create a imagegenerator for for augmentation\ndatagen =  ImageDataGenerator(\n  shear_range=0.2,\n  zoom_range=0.2,\n)\n\n# function to convert image to array\ndef read_img(filename, size, path):\n    img = image.load_img(os.path.join(path, filename), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img) \/ 255\n    return img","efb4aae1":"#read a sample image\nsamp_img = read_img(final_train_data['X_ray_image_name'][0],\n                                 (255,255),\n                                 train_img_path)\n\nplt.figure(figsize=(10,10))\nplt.suptitle('Data Augmentation', fontsize=28)\n\ni = 0\n\n#show augmented images\nfor batch in datagen.flow(tf.expand_dims(samp_img,0), batch_size=6):\n    plt.subplot(3, 3, i+1)\n    plt.grid(False)\n    plt.imshow(batch.reshape(255, 255, 3));\n    \n    if i == 8:\n        break\n    i += 1\n    \nplt.show();","2f62ff6f":"#augment the images labeled with covid-19 to balance the data\n\ncorona_df = final_train_data[final_train_data['Label_2_Virus_category'] == 'COVID-19']\nwith_corona_augmented = []\n\n#create a function for augmentation\ndef augment(name):\n    img = read_img(name, (255,255), train_img_path)\n    i = 0\n    for batch in tqdm(datagen.flow(tf.expand_dims(img, 0), batch_size=32)):\n        with_corona_augmented.append(tf.squeeze(batch).numpy())\n        if i == 20:\n            break\n        i =i+1\n\n#apply the function\ncorona_df['X_ray_image_name'].apply(augment)","268fa269":"# extract the image from traing data and test data, then convert them as array\ntrain_arrays = [] \nfinal_train_data['X_ray_image_name'].apply(lambda x: train_arrays.append(read_img(x, (255,255), train_img_path)))\ntest_arrays = []\nfinal_test_data['X_ray_image_name'].apply(lambda x: test_arrays.append(read_img(x, (255,255), test_img_path)))","bad659c4":"print(len(train_arrays))\nprint(len(test_arrays))","f6fee8d4":"#concatenate the training data labels and the labels for augmented images\ny_train = np.concatenate((np.int64(final_train_data['target'].values), np.ones(len(with_corona_augmented), dtype=np.int64)))","739cecba":"train_tensors = tf.convert_to_tensor(np.concatenate((np.array(train_arrays), np.array(with_corona_augmented))))\ntest_tensors  = tf.convert_to_tensor(np.array(test_arrays))\ny_train_tensor = tf.convert_to_tensor(y_train)\ny_test_tensor = tf.convert_to_tensor(final_test_data['target'].values)","36f1644b":"train_dataset = tf.data.Dataset.from_tensor_slices((train_tensors, y_train_tensor))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_tensors, y_test_tensor))","86b1dc4e":"for i,l in train_dataset.take(1):\n    plt.imshow(i);","812c8cef":"BATCH_SIZE = 16\nBUFFER = 1000\n\ntrain_batches = train_dataset.shuffle(BUFFER).batch(BATCH_SIZE)\ntest_batches = test_dataset.batch(BATCH_SIZE)\n\nfor i,l in train_batches.take(1):\n    print('Train Shape per Batch: ',i.shape);\nfor i,l in test_batches.take(1):\n    print('Test Shape per Batch: ',i.shape);","12da730f":"#define input shape\nINPUT_SHAPE = (255,255,3) \n\n#get the pretrained model\nbase_model = tf.keras.applications.ResNet50(input_shape= INPUT_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\n#set the trainable method of covolution layer as false\n# why set to false?? because we don't want to mess up the pretrained weights of the model!!\nbase_model.trainable = False\nbase_model.summary()","fb08ab7b":"#let's try to pass an image to the model to verify the output shape\nfor i,l in train_batches.take(1):\n    pass\nbase_model(i).shape","d1190379":"model = Sequential()\nmodel.add(base_model)\nmodel.add(Layers.GlobalAveragePooling2D())\nmodel.add(Layers.Dense(128))\nmodel.add(Layers.Dropout(0.2))\nmodel.add(Layers.Dense(1, activation = 'sigmoid'))\nmodel.summary()","ed147a2d":"#add a earlystopping callback to stop the training if the model is not learning anymore\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n\n#let's just choose adam as our optimizer, we all love adam anyway.\nmodel.compile(optimizer='adam',\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])","50aa4dd8":"model.fit(train_batches, epochs=10, validation_data=test_batches, callbacks=[callbacks])","51301650":"#predict the test data\npred = model.predict_classes(np.array(test_arrays))","7bc2fdaf":"#let's print a classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(test_data['target'], pred.flatten()))","8e309bda":"### ohhh not that bad\n### lets plot confusion matrix to make it look professional\n\ncon_mat = confusion_matrix(test_data['target'], pred.flatten())\nplt.figure(figsize = (10,10))\nplt.title('CONFUSION MATRIX')\nsns.heatmap(con_mat, cmap='cividis',\n            yticklabels=['Negative', 'Positive'],\n            xticklabels=['Negative', 'Positive'],\n            annot=True);","514addc3":"### GENERATE BATCHES","7c4ab365":"### OKAY, LET'S ADD A DENSE LAYER FOR IMAGE CLASSIFICATION","eff9d356":"### DATA AUGMENTATION","ae0dcb1a":"### TRANSFER LEARNING RESNET","b8bd3a6a":"### DATA UTILITIES","c58f0dc9":"### CONVERT ALL THE DATA TO TENSORS","a8b3ed58":"### CREATE A TENSOR DATASET","692f67ba":"### WRAP UP!","d38eeeea":"### THE MOMENT OF TRUTH"}}