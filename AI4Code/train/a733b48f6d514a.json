{"cell_type":{"a8eecf90":"code","948a3f39":"code","febeca86":"code","ab95cfeb":"code","536eb1dc":"code","7169d555":"code","77e55d68":"code","28d69c99":"code","e8f6c2d8":"code","7344feab":"code","045f3483":"code","5d698fa9":"code","c5f7c333":"code","9de4a81f":"code","eda0e791":"code","bca889ff":"code","51fcdcc3":"code","febb7997":"code","e855ceae":"code","017a9974":"code","f01a3bc9":"code","2b8144d8":"code","8bd76ef5":"code","2820320b":"code","e4c1d7dc":"code","7dd6eb5b":"code","74a1239f":"code","f1f53212":"code","ae6fe591":"code","5d7f567c":"code","1878e2de":"code","589ee027":"code","176d441d":"code","0427dfdb":"code","39d6d429":"code","30264b1c":"code","4d3e645b":"code","a4ae0648":"code","a88d6583":"code","0b1d55f5":"code","b6bdc8ab":"code","3f8ac900":"code","3eecbb02":"code","b699ebd2":"code","4a6970c2":"code","579b981e":"code","89f88c02":"code","9e0bbcfe":"code","822f8896":"code","aa7e73e6":"code","7bd946aa":"code","07b27b9c":"code","44112f17":"code","6d61ef78":"code","e9d04fd3":"code","fed4816d":"code","7b69a501":"code","e81404af":"code","905a96ab":"code","6dbf2f0b":"code","6c29b2cf":"code","f7d7a36b":"code","0583ee7e":"code","8fcb4f8d":"code","44ce38b6":"code","f2e34c9e":"code","bae350f9":"code","df348db0":"code","f9ca35c2":"code","bbb006b3":"code","99ffece9":"code","4b3c36c5":"code","d6036ba3":"code","f195cfad":"code","ae46a8f0":"code","2655f30b":"code","d6fa814f":"code","0bf909a9":"code","23f62ee4":"code","a37416f4":"code","f2697cbc":"code","b9965f5c":"code","1bec49a3":"code","15ff75c5":"code","5646c7a8":"code","599f18ab":"code","f40f2626":"code","8804629a":"code","3cca8729":"code","fc540a89":"code","72fe7f39":"code","c0eafebf":"code","5802633a":"code","bab575f5":"code","9783d4db":"code","a079fc8f":"code","249fbad3":"code","51e806a8":"code","120be6bb":"code","0abd5cec":"code","6043a6f2":"code","dd2d0f10":"code","f8b959e2":"code","78165baa":"code","5efb41b4":"code","87e8277a":"code","2b89fb28":"code","8fd0a7e9":"code","54e419f3":"code","744f8b08":"code","7589c43e":"code","b4dfaebd":"code","d26b53a3":"code","a6978a93":"code","8f9fe1c4":"code","517eff37":"code","2cf17de3":"code","17fa6578":"code","9309022d":"code","111db87d":"code","8d4fecca":"code","f15cddc7":"code","9ad2c852":"code","018275a5":"code","3625c052":"code","69b328b3":"code","3c3c6f5c":"code","0568c45e":"code","0b727035":"code","98680807":"code","20b47ba2":"code","a8c85eef":"code","b2cb29cf":"code","de6b2f60":"code","8de293e2":"code","9b0316f0":"code","1b4587ec":"code","e3d9408d":"markdown","6bac76b8":"markdown","e4ee9bf0":"markdown","8735f080":"markdown","e07739bb":"markdown","e8740a73":"markdown","202b8f67":"markdown","9fae9421":"markdown","3da2b124":"markdown","a00e32a7":"markdown","faa99455":"markdown"},"source":{"a8eecf90":"## Hi all..I am very new to Kaggle any suggestions would be very helpful\n## In my this version of notebook I am focussed on Exploratory Data Analysis and Feature Engineering\n## The remaining part that deals with  Predictive Modelling will upload in upcoming Versions*","948a3f39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics \nfrom sklearn.metrics import confusion_matrix,roc_auc_score","febeca86":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ab95cfeb":"train_data = pd.read_csv(\"\/kaggle\/input\/train.csv\")\ntest_data  = pd.read_csv(\"\/kaggle\/input\/test.csv\")","536eb1dc":"train_data.shape","7169d555":"test_data.shape","77e55d68":"train_data.columns","28d69c99":"train_data.head()","e8f6c2d8":"train_data.describe(include = 'all')","7344feab":"train_data.info()","045f3483":"## Checking the NA values in the dataset\ntrain_data.isnull().sum()","5d698fa9":"(687\/891) *100 ## So Cabin has 77% of missing values So we can drop it for further analysis as most of the data is missing.","c5f7c333":"## Seaborn Relplot also gives good visualization\n## A Relplot is a Figure-level interface for drawing relational plots","9de4a81f":"sns.relplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=train_data)","eda0e791":"## Rechecking using statistics\nx = train_data.Sex[train_data.Survived == 1]","bca889ff":"x.value_counts()","51fcdcc3":"## We will plot Seaborn FacetGrid which is Multi-plot grid for plotting conditional relationships.\n\n## We will plot it using vars Sex,Embark,Survived and PClass","febb7997":"bins = np.arange(0, 65, 5)\ng = sns.FacetGrid(train_data, row=\"Embarked\")\ng = g.map(sns.pointplot, 'Pclass', 'Survived','Sex', palette=None,  order=None, hue_order=None )\ng.add_legend()","e855ceae":"sns.barplot(x='Pclass', y='Survived', data=train_data)","017a9974":"##Checking the Class Distribution wrt Survived\nx1 = train_data.Survived[train_data.Pclass == 3]\nx2 = train_data.Survived[train_data.Pclass == 2]\nx3 = train_data.Survived[train_data.Pclass == 1]\n","f01a3bc9":"x3.value_counts()","2b8144d8":"x2.value_counts()","8bd76ef5":"x1.value_counts()","2820320b":"## It can be seen from the above statistics that most of the people belonging to Class 3 did not survive\n## It can also be rechecked by plotting FacetGrid as below ->\n\ngrid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","e4c1d7dc":"## It can be seen that Pclass 3 has very less rate of survival","7dd6eb5b":"## Need to check relation between SibSp and Survived and relation between Parch and Survived\n## We will check it by plotting the Seaborn Barplot\nsns.barplot(y = 'Survived', x = 'SibSp',data = train_data, edgecolor = 'w')\nplt.show()\n\nsns.barplot(y = 'Survived', x = 'Parch',data = train_data, edgecolor = 'w')\nplt.show()\n","74a1239f":"grid1 = sns.FacetGrid(train_data, col='Survived', row='SibSp', size=2.2, aspect=1.6)\ngrid1.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid1.add_legend();","f1f53212":"## It can be seen that the Survival is better for Sibsp = 0 whereas Sibsp with value 3,4,5 have least and SibSp with value as 8 no survival","ae6fe591":"sns.relplot(x=\"SibSp\", y=\"Parch\", hue=\"Survived\", data=train_data)","5d7f567c":"grid2 = sns.FacetGrid(train_data, col='Survived', row='Parch', size=2.2, aspect=1.6)\ngrid2.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid2.add_legend();","1878e2de":"train_data.isnull().sum()","589ee027":"## Age,Cabin, Embarked have missing values in train data","176d441d":"test_data.isnull().sum()","0427dfdb":"## Age,Fare,Cabin have missin values","39d6d429":"data = [train_data,test_data]","30264b1c":"train_data.Embarked.value_counts()","4d3e645b":"## Most Commom value is 'S' so fillna with 'S'\ntrain_data['Embarked'] = train_data['Embarked'].fillna('S')","a4ae0648":"train_data.Embarked.value_counts()","a88d6583":"test_data.Fare.describe()","0b1d55f5":"## So we will fill the missing value with the mean\ntest_data['Fare'] = test_data['Fare'].fillna(35.627188)","b6bdc8ab":"test_data.Fare.isnull().sum()","3f8ac900":"train_data.Age.describe()","3eecbb02":"## In both train_data and test_data Age attribute has missing values \n##We will fill na with the mean Age in both the data\nmean_age = train_data.Age.mean()\nmean_age\ntrain_data['Age'] = train_data['Age'].fillna(mean_age)","b699ebd2":"train_data.Age.isnull().sum()","4a6970c2":"test_data.Age.describe()","579b981e":"mean_age1 = test_data.Age.mean()\nmean_age1\ntest_data['Age'] = test_data['Age'].fillna(mean_age1)","89f88c02":"test_data.Age.isnull().sum()","9e0bbcfe":"## Now the attribute Cabin has the maximum nbr of missing values \n## In Cabin the letter refers to the Deck which might be helpful for Survived attr as in it might be the case \n## that people belonging to certain Deck have higher rate of survival","822f8896":"train_data.Cabin.describe()","aa7e73e6":"train_data.Cabin.value_counts()","7bd946aa":"train_data['Cabin'] = train_data['Cabin'].str.extract('(\\w)')\n","07b27b9c":"train_data.Cabin.value_counts()","44112f17":"train_data.Cabin.describe()","6d61ef78":"## Lets plot the relation between Cabin and Survived","e9d04fd3":"grid3 = sns.FacetGrid(train_data, col='Survived', row='Cabin', size=2.2, aspect=1.6)\ngrid3.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid3.add_legend();","fed4816d":"## It can be seen from the above Graph that Passengers with Deck no as A and F have higher rate for survival","7b69a501":"test_data.Cabin.describe()","e81404af":"test_data['Cabin'] = test_data['Cabin'].str.extract('(\\w)')","905a96ab":"test_data.Cabin.value_counts()","6dbf2f0b":"test_data.Cabin.describe()","6c29b2cf":"## Lets fill na for Cabin in both the data with value as 'T'","f7d7a36b":"train_data['Cabin'] = train_data['Cabin'].fillna('T')","0583ee7e":"test_data['Cabin'] = test_data['Cabin'].fillna('T')","8fcb4f8d":"train_data.Cabin.value_counts()","44ce38b6":"test_data.Cabin.value_counts()","f2e34c9e":"train_data.describe(include = 'all')","bae350f9":"## Here the vars Sex,Cabin and Embarked need to be converted to numeric categorical\n## So we will convert them using LabelEncoder object","df348db0":"le = LabelEncoder()\n\ntrain_data.Sex       = le.fit_transform(train_data.Sex)\ntrain_data.Cabin     = le.fit_transform(train_data.Cabin)\ntrain_data.Embarked  = le.fit_transform(train_data.Embarked)\n\ntrain_data.Sex       = train_data.Sex.astype('category')\ntrain_data.Cabin     = train_data.Cabin.astype('category')\ntrain_data.Embarked  = train_data.Embarked.astype('category')","f9ca35c2":"train_data.describe(include = 'all')","bbb006b3":"## Similarly we need to convert attr for test_data","99ffece9":"test_data.Sex       = le.fit_transform(test_data.Sex)\ntest_data.Cabin     = le.fit_transform(test_data.Cabin)\ntest_data.Embarked  = le.fit_transform(test_data.Embarked)\n\ntest_data.Sex       = test_data.Sex.astype('category')\ntest_data.Cabin     = test_data.Cabin.astype('category')\ntest_data.Embarked  = test_data.Embarked.astype('category')","4b3c36c5":"train_data.Pclass.value_counts()","d6036ba3":"train_data.Pclass.describe()","f195cfad":"## Pclass needs to be categorized\ntrain_data.Pclass = train_data.Pclass.astype('category')\ntest_data.Pclass  = test_data.Pclass.astype('category')","ae46a8f0":"test_data.Pclass.describe()","2655f30b":"##SibSp and Parch would make more sense as a combined feature, that shows the total number of relatives, a person has on the Titanic.\n## I will create it below and also a feature that shows if someone is not alone.\ndata = [train_data, test_data]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 1\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 0","d6fa814f":"train_data.columns","0bf909a9":"train_data.relatives.head()","23f62ee4":"train_data.Ticket.describe()\n##Since the Ticket attribute has 681 unique tickets, it will be a bit tricky to convert them into useful categories. So we will drop it from the dataset.","a37416f4":"train_data.drop('Ticket', axis = 1, inplace = True)\ntest_data.drop('Ticket', axis = 1, inplace = True)","f2697cbc":"train_data.columns","b9965f5c":"## Also PassengerID is not significant we can drop it\ntrain_data.drop('PassengerId', axis = 1, inplace = True)\ntest_data.drop('PassengerId', axis = 1, inplace = True)","1bec49a3":"train_data.columns","15ff75c5":"train_data.Name.head()","5646c7a8":"## We will use the Name feature to extract the Titles from the Name..That might be helpful in predicting Survived\n## We will extract it using Series.str.extract ","599f18ab":"train_data['Name'] =  train_data['Name'].str.extract(pat = \"(Mr|Master|Mrs|Miss|Major|Rev|Lady|Dr|Mme|Mlle|Col|Capt)\\\\.\")","f40f2626":"test_data['Name'] =  test_data['Name'].str.extract(pat = \"(Mr|Master|Mrs|Miss|Major|Rev|Lady|Dr|Mme|Mlle|Col|Capt)\\\\.\")","8804629a":"train_data.Name.describe()","3cca8729":"test_data.Name.describe()","fc540a89":"train_data.Name.value_counts()","72fe7f39":"test_data.Name.value_counts()","c0eafebf":"train_data.Name.isnull().sum()","5802633a":"test_data.Name.isnull().sum()","bab575f5":"## As we can see that most of the Name accounts for Miss,Mr,Mrs,Master we can group the others to Rare","9783d4db":"train_data['Name'] = train_data['Name'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr','Mme','Mlle',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')","a079fc8f":"train_data['Name'].replace(['Mr','Mrs','Miss','Master','Rare'],[1,2,3,4,5],inplace=True)","249fbad3":"train_data.Name = train_data.Name.fillna(0)","51e806a8":"train_data.Name.describe()","120be6bb":"train_data.Name = train_data.Name.astype('category')","0abd5cec":"train_data.Name.describe()","6043a6f2":"train_data.Name.value_counts()","dd2d0f10":"test_data['Name'] = test_data['Name'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr','Mme','Mlle',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')","f8b959e2":"test_data['Name'].replace(['Mr','Mrs','Miss','Master','Rare'],[1,2,3,4,5],inplace=True)","78165baa":"test_data.Name = test_data.Name.fillna(0)","5efb41b4":"test_data.Name.describe()","87e8277a":"test_data.Name = test_data.Name.astype('category')","2b89fb28":"test_data.Name.describe()","8fd0a7e9":"test_data.Name.value_counts() ","54e419f3":"## We need to convert the \u2018age\u2019 feature. First we will convert it from float into integer. \n## Then we will create the new \u2018AgeGroup\u201d variable, by categorizing every age into a group using the pandas qcut function for data binning\n## The pandas documentation describes qcut as a \u201cQuantile-based discretization function.\u201d This basically means that qcut tries to divide up the underlying data into equal sized bins. \n## The function defines the bins using percentiles based on the distribution of the data, not the actual numeric edges of the bins.","744f8b08":"train_data.Age.describe()","7589c43e":"train_data.Age = train_data.Age.astype(int) ","b4dfaebd":"test_data.Age = test_data.Age.astype(int) ","d26b53a3":"train_data.Age.describe()","a6978a93":"train_data['Age_new'] = pd.qcut(train_data['Age'], q = 6,duplicates = 'drop')","8f9fe1c4":"train_data.Age_new.value_counts()","517eff37":"train_data.head()","2cf17de3":"## Now we need to convert the Age to category\nle1 = LabelEncoder()\ntrain_data.Age_new = le1.fit_transform(train_data.Age_new)\ntrain_data.Age_new = train_data.Age_new.astype('category')","17fa6578":"train_data.Age_new.value_counts()","9309022d":"test_data['Age_new'] = pd.qcut(test_data['Age'], q = 6, duplicates = 'drop')","111db87d":"test_data.Age_new.value_counts()","8d4fecca":"test_data.Age_new = le1.fit_transform(test_data.Age_new)\ntest_data.Age_new = test_data.Age_new.astype('category')","f15cddc7":"test_data.Age_new.value_counts()","9ad2c852":"## For the \u2018Fare\u2019 feature, we need to do the same as with the \u2018Age\u2019 feature","018275a5":"train_data.Fare.describe()\n## Min value is 0 Max is 512 \n## We need to categorize Fare value with cut","3625c052":"train_data['New_Fare'] = pd.qcut(train_data['Fare'], q = 6)","69b328b3":"train_data.New_Fare.value_counts()","3c3c6f5c":"train_data.New_Fare = le1.fit_transform(train_data.New_Fare)\ntrain_data.New_Fare = train_data.New_Fare.astype('category')","0568c45e":"train_data.New_Fare.value_counts()","0b727035":"test_data['New_Fare'] = pd.qcut(test_data['Fare'], q = 6)","98680807":"test_data.New_Fare.value_counts()","20b47ba2":"test_data.New_Fare = le1.fit_transform(test_data.New_Fare)\ntest_data.New_Fare = test_data.New_Fare.astype('category')","a8c85eef":"test_data.New_Fare.value_counts()","b2cb29cf":"train_data.head()","de6b2f60":"## Drop the columns which are not significant","8de293e2":"train_data.drop('Age', axis = 1, inplace = True)\ntrain_data.drop('Fare', axis = 1, inplace = True)\ntest_data.drop('Age', axis = 1, inplace = True)\ntest_data.drop('Fare', axis = 1, inplace = True)\ntrain_data.drop('not_alone', axis = 1, inplace = True)\ntest_data.drop('not_alone', axis = 1, inplace = True)","9b0316f0":"train_data.columns","1b4587ec":"test_data.columns","e3d9408d":"# Exploratory Data Analysis","6bac76b8":"# Feature Engineering","e4ee9bf0":"* From the above FacetGrid graph it can be seen that for Embarked 'S' and 'Q' females have higher rate of survival , whereas for Port 'C' male have higher rate of survival\nThe relation between PClass and Survived can be seen as","8735f080":"# Getting the Data","e07739bb":"# Lets check the data distribution through plots","e8740a73":"So age has 177 missing values,Cabin has 682 and Embarked has 2 missing values","202b8f67":"1. MISSING VALUE CONSTRAINT","9fae9421":"*  It can be seen that females have higher rate of survival\n*  Also from the above relplot it can be seen that for males the rate of survival is better when the age is between 10-30\n*  In both Male and female infants have good survival rate\n*  For further analysis we need to create the age groups","3da2b124":"# CONVERTING FEATURES INTO CORRECT FORMAT ","a00e32a7":"**It can be seen that our train_data has 891 records with 11 attributes and one target as Survived.\nThe Data Definition of each attribute can be given below as\n\n* PassengerId: Unique Id of a passenger\n* survived:    Survival \n* pclass:    Ticket class     \n* sex:    Sex     \n* Age:    Age in years     \n* sibsp:    # of siblings \/ spouses aboard the Titanic     \n* parch:    # of parents \/ children aboard the Titanic     \n* ticket:    Ticket number     \n* fare:    Passenger fare     \n* cabin:    Cabin number     \n* embarked:    Port of Embarkation\n","faa99455":"Here it can be seen that 2 vars Age and Fare are float,5 vars are integers and other 5 are objects.\nAlso it can be seen that PassengerId,Ticket and Name are not that significant enough in predicting the Dependent var Survived.\nAlso most of the features needs to be converted before modelling"}}