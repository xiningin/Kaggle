{"cell_type":{"659c24af":"code","622aa00f":"code","2f6b2bb9":"code","bef94965":"code","5d8df5e4":"code","2c9a7408":"code","cae377ba":"code","fad669df":"code","aa3e0c41":"code","4d5d51df":"code","d27cf3a1":"code","6931e837":"code","d8d4a426":"code","beba69e4":"markdown","a375cf6f":"markdown","57c9de02":"markdown","32c5ffc8":"markdown","6a7e1b2e":"markdown","0eeae15f":"markdown","a71035a1":"markdown","afd4515a":"markdown","0077ec68":"markdown","f8223238":"markdown","3dbd1515":"markdown","9bedf94c":"markdown","9e5fb7bc":"markdown","1a729e6b":"markdown"},"source":{"659c24af":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.linear_model import LogisticRegression","622aa00f":"tweetsdf = pd.read_table('..\/input\/tweets-of-trump-and-trudeau\/tweets.csv', sep=',', names=('ID', 'Author', 'tweet'))\ntweetsdf=tweetsdf.iloc[1:]\ntweetsdf.head()","2f6b2bb9":"y=tweetsdf['Author']\nx=tweetsdf['tweet']\nx_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.33, random_state=50)\nprint(x_train)","bef94965":"tvec= TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df=0.9, min_df=0.05)\n","5d8df5e4":"t_train=tvec.fit_transform(x_train)\nt_test=tvec.fit_transform(x_test)","2c9a7408":"cvec = CountVectorizer(stop_words=\"english\",ngram_range=(1,2), max_df=0.9, min_df=0.05)\nc_train=cvec.fit_transform(x_train)\nc_test=cvec.fit_transform(x_test)","cae377ba":"svclassifier = SVC(kernel='rbf')\nsvclassifier.fit(t_train, y_train)\nt_predsvc = svclassifier.predict(t_test)","fad669df":"svclassifier = SVC(kernel='rbf')\nsvclassifier.fit(c_train, y_train)\nc_predsvc = svclassifier.predict(c_test)","aa3e0c41":"countsvcacc = accuracy_score(c_predsvc,y_test)\nprint(confusion_matrix(y_test,c_predsvc))\nprint(classification_report(y_test,c_predsvc))\n\ntfidfsvmacc = accuracy_score(t_predsvc,y_test)\nprint(confusion_matrix(y_test,t_predsvc))\nprint(classification_report(y_test,t_predsvc))","4d5d51df":"logclassifier=LogisticRegression(random_state=0, solver='lbfgs') \nlogclassifier.fit(t_train, y_train) \nt_predlog = logclassifier.predict(t_test)","d27cf3a1":"logclassifier=LogisticRegression(random_state=0, solver='lbfgs')\nlogclassifier.fit(c_train, y_train)\nc_predlog = logclassifier.predict(c_test)","6931e837":"countlogacc = accuracy_score(c_predlog,y_test)\nprint(confusion_matrix(y_test,c_predlog))\nprint(classification_report(y_test,c_predlog))\n\ncountlogacc = accuracy_score(t_predlog,y_test)\nprint(confusion_matrix(y_test,t_predlog))\nprint(classification_report(y_test,t_predlog))","d8d4a426":"tlog_confmatrix = confusion_matrix(t_predlog,y_test)\nclog_confmatrix = confusion_matrix(c_predlog,y_test)\n\ntsvc_confmatrix = confusion_matrix(t_predsvc,y_test)\ncsvc_confmatrix = confusion_matrix(c_predsvc,y_test)\nprint(tlog_confmatrix)\nprint(clog_confmatrix)\nprint(tsvc_confmatrix)\nprint(csvc_confmatrix)","beba69e4":"**Importing the libraries**","a375cf6f":"**We will predict the author from the tweet column, splitting the data as training and test**","57c9de02":"**Classification with SVC with RBF kernel on the TF-IDF data**","32c5ffc8":"**Calculation of accuracies of both vectorizers with Logistic Regression**","6a7e1b2e":"**Confusion matrices for both vectorizers**","0eeae15f":"Splitting the data for the comparison of vectorizers.","a71035a1":"**Classification with SVC with RBF kernel on Count Vectorizer data**","afd4515a":"# Who's Tweeting? Trump vs Trudeau \n## is a project I've seen on Datacamp. It asks you to classify a given tweet of either Donald Trump or Justin Trudeau.\nThe dataset consists of three columns, ID, Tweet itself and the authors (being either Donald Trump or Justin Trudeau). I have used support vector classifier and logistic regressor in this code, and also compared two word vectorizers; count vectorizer and TF-IDF vectorizer.","0077ec68":"**TF-IDF vectorizer, vectorizes the words by dividing the frequency of that specific word by how many times that word appears in how many documents, it yields a matrix with values between 0 and 1 so it gives better precision than the count vectorizer** The columns of matrix are the words and the rows are the documents. \nIt removes English stopwords, and n-gram determines the number of words taken in a phrase, and max and min df values get rid of words either used too much or too rare.","f8223238":"**Calculation of accuracies of both vectorizers with SVC**","3dbd1515":"**Count vectorizer basically counts the words that appear and returns a matrix with columns being the words and rows being tweets.** The elements of matrix are integers. Applying the same procedure with TF-IDF. ","9bedf94c":"**Classification with logistic regressor on the Count Vectorizer data**","9e5fb7bc":"**Importing the data, and I've also removed the label row that was given in the dataset**","1a729e6b":"**Classification with logistic regressor on the TF-IDF data**"}}