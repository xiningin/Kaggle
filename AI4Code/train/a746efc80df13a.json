{"cell_type":{"2ae26e7d":"code","4ed1707c":"code","dbbc5531":"code","fab93cbd":"code","785aa776":"code","85d0c50a":"code","2cdda85f":"code","88037747":"code","db2052e8":"code","cc70c130":"code","acbf4a8c":"code","e2bdf0f5":"code","3236f004":"code","de3c4fdc":"code","f9233e51":"code","84bef469":"code","7492bc9b":"markdown","59a23154":"markdown","66f2d885":"markdown","c1ce766d":"markdown"},"source":{"2ae26e7d":"#Importing Libraries\nimport numpy as np\nimport tensorflow as tf","4ed1707c":"#Importing Module for Image Processing\nfrom keras.preprocessing.image import ImageDataGenerator","dbbc5531":"#Loading and Augmentation of Training Set\ntrain_data = ImageDataGenerator(rescale=1.\/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\ntrain_set = train_data.flow_from_directory('..\/input\/cnn-dataset\/CNN_Dataset\/training_set', target_size=(64,64),\n                                                    batch_size=32, class_mode='binary')","fab93cbd":"#Loading and Augmentation Test Set\ntest_data = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_data.flow_from_directory('..\/input\/cnn-dataset\/CNN_Dataset\/test_set', target_size=(64,64), batch_size=32,\n                                         class_mode='binary')","785aa776":"#Initialize CNN\nConvNet = tf.keras.models.Sequential()","85d0c50a":"#Convolution\nConvNet.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))","2cdda85f":"#Max Pooling\nConvNet.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))","88037747":"#Second Convolution Layer\nConvNet.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\nConvNet.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))","db2052e8":"#Flattening\nConvNet.add(tf.keras.layers.Flatten())","cc70c130":"#Fully Connected Layer\nConvNet.add(tf.keras.layers.Dense(units=128,activation='relu'))","acbf4a8c":"#Output Layer\nConvNet.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))","e2bdf0f5":"#Compiling\nConvNet.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","3236f004":"#Training\nConvNet.fit(x = train_set, validation_data = test_set, epochs = 30)","de3c4fdc":"#Importing Module for Processing the Image\nfrom keras.preprocessing import image\n\n#Loading the Image(An Image of a Dog) to be Predicted\ntest_image = image.load_img('..\/input\/cnn-dataset\/CNN_Dataset\/single_prediction\/cat_or_dog_1.jpg', target_size=(64,64))\n\n#Converting to a NumPy array\ntest_image = image.img_to_array(test_image)\n\n#To input it as a batch just like the Training Set\ntest_image = np.expand_dims(test_image, axis=0)\n\n#Prediction\nresult = ConvNet.predict(test_image)","f9233e51":"#To check the class indices of Dogs & Cats \ntrain_set.class_indices","84bef469":"#Since the input of the image is in a batch, 1st index ~ batch index & 2nd index ~ index of the\n#ith index in the batch ([0][0] ~ because in this prediction we have 1 batch and 1 image)\nif result[0][0]==1:\n    Animal = 'Dog'\nelse:\n    Animal = 'Cat'\n\nprint(Animal)","7492bc9b":"# **Dogs vs. Cats Classification using Convolution Neural Networks**","59a23154":"# Prediction","66f2d885":"# Data Processing","c1ce766d":"# Building the CNN"}}