{"cell_type":{"41a01d04":"code","0d471886":"code","e219882c":"code","9065e798":"code","bc463005":"code","84fd2b9b":"code","3914e99c":"code","13bed46a":"code","b7381632":"code","35f24286":"code","43ee96d4":"code","c4343ad7":"code","f4203c7b":"code","505a5a48":"code","5c4a9bee":"code","4d5cf802":"code","44d57783":"code","9d2d5866":"code","5e3c28fa":"markdown","0e133eea":"markdown","ccf7907d":"markdown","7c9aef86":"markdown","163c788a":"markdown","1d0bd255":"markdown","88081ac5":"markdown","9b1cef1e":"markdown","5c21b272":"markdown","09aa7c36":"markdown","2a15b9c8":"markdown","8b6e3a1b":"markdown"},"source":{"41a01d04":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"..\/input\"))","0d471886":"pics = np.load(\"..\/input\/olivetti_faces.npy\")\nlabels = np.load(\"..\/input\/olivetti_faces_target.npy\")","e219882c":"print(\"pics: \", pics.shape)\nprint(\"labels: \", labels.shape)","9065e798":"fig = plt.figure(figsize=(20, 10))\ncolumns = 10\nrows = 4\nfor i in range(1, columns*rows +1):\n    img = pics[10*(i-1),:,:]\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img, cmap = plt.get_cmap('gray'))\n    plt.title(\"person {}\".format(i), fontsize=16)\n    plt.axis('off')\n    \nplt.suptitle(\"There are 40 distinct people in the dataset\", fontsize=22)\nplt.show()\n","bc463005":"Xdata = pics # store images in Xdata\nYdata = labels.reshape(-1,1) # store labels in Ydata","84fd2b9b":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(Xdata, Ydata, test_size = 0.2, random_state=46)\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","3914e99c":"x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","13bed46a":"# Store accuracies of the machine learning methods for comparison at the end\nlist_names = []\nlist_accuracy = []","b7381632":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=1000)\nlr.fit(x_train, y_train)\nLR_accuracy = round(lr.score(x_test, y_test)*100,2)\n\nprint(\"LR_accuracy is %\", LR_accuracy)\n\nlist_names.append(\"Logistic Regression\")\nlist_accuracy.append(LR_accuracy)","35f24286":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier(n_estimators = 400, random_state = 1)\nrf.fit(x_train, y_train)\nRF_accuracy = round(rf.score(x_test, y_test)*100,2)\n\nprint(\"RF_accuracy is %\", RF_accuracy)\n\nlist_names.append(\"Random Forest\")\nlist_accuracy.append(RF_accuracy)","43ee96d4":"from sklearn.neighbors import KNeighborsClassifier\n\nKnn = KNeighborsClassifier(n_neighbors = 1) # n_neighbors=1 gives the best result for this data\nKnn.fit(x_train, y_train)\nKnn_accuracy = round(Knn.score(x_test, y_test)*100,2)\n\nprint(\"Knn_accuracy is %\", Knn_accuracy)\n\nlist_names.append(\"KNN\")\nlist_accuracy.append(Knn_accuracy)","c4343ad7":"x_train = x_train.reshape(-1,64,64,1)\nx_test = x_test.reshape(-1,64,64,1)\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)","f4203c7b":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\ny_train_ = to_categorical(y_train, num_classes = 40) # 40 distinct people\ny_test_ = to_categorical(y_test, num_classes = 40)\n\nprint(\"y_train_ shape: \",y_train_.shape)\nprint(\"y_test_ shape: \",y_test_.shape)","505a5a48":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 20, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 50, kernel_size = (6,6),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 150, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(40, activation = \"softmax\"))\n\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.7, \n                                            min_lr=0.00000000001)\n\nepoch = 37\nbatch_size = 20\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.05, # Randomly zoom image \n        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(x_train)\n\nhistory = model.fit_generator(\n                              datagen.flow(x_train,y_train_, batch_size=batch_size),\n                              epochs = epoch, \n                              validation_data = (x_test,y_test_),\n                              verbose = 2, \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n                              callbacks=[learning_rate_reduction]\n                             )","5c4a9bee":"y_pred = model.predict_classes(x_test)\n\ny_test = y_test.reshape(-1,)\n\ndiff = y_test - y_pred\ndiff = diff.reshape(-1,1)\n\ntrue = 0\nfor i in range(0,len(diff)):\n    if diff[i] == 0:\n        true = true + 1\n\nCnn_accuracy = round(100*true\/len(diff),2)\n\nprint(\"Cnn_accuracy is %\", Cnn_accuracy)\n\nlist_names.append(\"CNN\")\nlist_accuracy.append(Cnn_accuracy)","4d5cf802":"# Plot the loss and accuracy curves for training and validation \nval_accuracy = history.history['val_acc']\n\naccuracy = []\nnum_of_epochs = []\nfor i in range(1,epoch,4):\n    accuracy.append(round(100*val_accuracy[i],3))\n    num_of_epochs.append(i)\n\ntrace1 = go.Scatter(y = accuracy, x = num_of_epochs, mode = \"lines\")\ndata = [trace1]\nlayout = dict(title = 'CNN Accuracy',\n              autosize=False,\n              width=800,\n              height=500,\n              yaxis= dict(title= 'Accuracy (%)',gridwidth=2, gridcolor='#bdbdbd'),\n              xaxis= dict(title= 'Number of Epochs',gridwidth=2, gridcolor='#bdbdbd'),\n              font=dict(size=14)\n             )\nfig = dict(data = data, layout = layout)\npy.iplot(fig)","44d57783":"df = pd.DataFrame({'METHOD': list_names, 'ACCURACY (%)': list_accuracy})\ndf = df.sort_values(by=['ACCURACY (%)'])\ndf = df.reset_index(drop=True)\ndf.head()","9d2d5866":"trace1 = go.Bar(x = df.iloc[:,0].tolist(), y = df.iloc[:,1].tolist())\n\ndata1 = [trace1]\nlayout1 = go.Layout(\n    title='Comparison of the Learning Methods',\n    xaxis=dict(titlefont=dict(size=16)),\n    yaxis=dict(title='ACCURACY (%)',gridwidth=1, gridcolor='#bdbdbd', range=[89, 99]),\n    font=dict(size=16),\n    bargap = 0.7,\n    barmode='group')\n\nfig = go.Figure(data=data1, layout=layout1)\npy.iplot(fig, filename='grouped-bar')","5e3c28fa":"### Reshape","0e133eea":"### Reshape for CNN","ccf7907d":"# Convolutional Neural Network (CNN)","7c9aef86":"# Random Forest","163c788a":"# Logistic Regression","1d0bd255":"## Split data for train and test purposes","88081ac5":"# Import Libraries","9b1cef1e":"# Comparison of the Learning Methods","5c21b272":"# Import Data","09aa7c36":"# K-NN Classifier","2a15b9c8":"## Review Data","8b6e3a1b":"### Label Encoding "}}