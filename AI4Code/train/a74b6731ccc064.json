{"cell_type":{"c55a14aa":"code","50c249b6":"code","8a3ae4a7":"code","388a4f12":"code","b689beaa":"code","b745e625":"code","557094f4":"code","19c36654":"code","d3d164ad":"code","f72607ee":"code","1c8bb601":"code","205cf7eb":"code","b35a75c6":"code","5e9a9c40":"code","959e3bd0":"code","b9219674":"code","eb10d3dd":"code","bef19b41":"code","69ebe815":"code","6cab73c4":"code","eb0e7510":"markdown","ee266700":"markdown","6f4d0fb2":"markdown","652e7eac":"markdown","c2325409":"markdown","3ada2786":"markdown","7f39d995":"markdown","d1c7b512":"markdown","fec6b9db":"markdown","20241aba":"markdown","a826d939":"markdown","b121cabe":"markdown","d567af8e":"markdown","44860f5e":"markdown","cf3a6b0b":"markdown","6d404c56":"markdown"},"source":{"c55a14aa":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm","50c249b6":"all_images_meta = pd.read_csv('..\/input\/landmark-retrieval-2020\/train.csv')","8a3ae4a7":"images_meta_sample = all_images_meta.groupby('landmark_id').head(2).reset_index(drop=True)","388a4f12":"images_meta_sample.head(10)","b689beaa":"images_meta_sample.info()","b745e625":"landmark_groups = all_images_meta.groupby('landmark_id')","557094f4":"landmark_group = landmark_groups.get_group(1)\nlandmark_group","19c36654":"def get_positive(anchor_landmark_id):    \n    landmark_group = landmark_groups.get_group(anchor_landmark_id)\n    indexes = landmark_group.index.values\n    \n    rand_index = np.random.choice(indexes)\n    pos_img_id = landmark_group.loc[rand_index].id\n        \n    return pos_img_id","d3d164ad":"images_meta_sample['positive_id'] = images_meta_sample['landmark_id'].apply(get_positive)","f72607ee":"def get_negative(landmark_id):        \n    indexes = images_meta_sample.index.values\n    \n    for i in range(len(images_meta_sample)):\n        rand_index = np.random.choice(indexes)\n        \n        neg_img_id = images_meta_sample.loc[rand_index].id\n        neg_landmark_id = images_meta_sample.loc[rand_index].landmark_id\n        \n        if neg_landmark_id != landmark_id:\n            return neg_img_id\n    \n    return neg_img_id","1c8bb601":"images_meta_sample['negative_id'] = images_meta_sample['landmark_id'].apply(get_negative)","205cf7eb":"images_meta_sample = images_meta_sample.rename({'id': 'anchor_id'}, axis='columns')","b35a75c6":"images_meta_sample.head()","5e9a9c40":"def _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() \n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))","959e3bd0":"def get_image(img_id):\n    chars = tf.strings.bytes_split(img_id)\n    dir_1, dir_2, dir_3 = chars[0], chars[1], chars[2]\n    \n    path = '..\/input\/landmark-retrieval-2020\/train\/' + dir_1 + '\/' + dir_2 + '\/' + dir_3 + '\/' + img_id + '.jpg'\n    image = tf.io.read_file(path)\n    \n    image = tf.image.decode_jpeg(image)\n    image = tf.image.resize(image, size=(128, 128), method='nearest')\n    image = tf.image.convert_image_dtype(image, tf.uint8)\n    \n    image = tf.image.encode_jpeg(image, quality=94, optimize_size=True)\n    \n    return image","b9219674":"def serialize_example(example):    \n    anchor_img = get_image(example.anchor_id)\n    positive_img = get_image(example.positive_id)\n    negative_img = get_image(example.negative_id)\n    \n    feature = {\n        'anchor_img': _bytes_feature(anchor_img),\n        'positive_img': _bytes_feature(positive_img),\n        'negative_img': _bytes_feature(negative_img),\n    }\n    \n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","eb10d3dd":"image_indexes = images_meta_sample.index.values","bef19b41":"file_size = len(image_indexes) \/\/ 15\nfile_count = len(image_indexes) \/\/ file_size + int(len(image_indexes) % file_size != 0)","69ebe815":"def write_tfrecord_file(file_index, file_size, image_indexes):\n    with tf.io.TFRecordWriter('train%.2i.tfrec'%(file_index)) as writer:\n        start = file_size * file_index\n        end = file_size * (file_index + 1)\n        \n        for i in tqdm(image_indexes[start:end]):\n\n            example = serialize_example(\n                images_meta_sample.loc[i]\n            )\n            \n            writer.write(example)","6cab73c4":"for file_index in range(file_count):\n    print('Writing TFRecord %i of %i...'%(file_index, file_count))\n    write_tfrecord_file(file_index, file_size, image_indexes)","eb0e7510":"Finally group these two helped functions together to form one example containing a triplet of images.","ee266700":"I've been taking part in the [Google Landmark Retrieval 2020](https:\/\/www.kaggle.com\/c\/landmark-retrieval-2020) competition recently which has 1.5 million images in its training dataset. To have any chance of training a good model on even a fraction of these images inside a Kaggle notebook I found that I needed a TPU. As such I have had a look around other notebooks and worked out how to convert images into tfrecords. In this format the images enable TPU training at much faster speeds.\n\nNote that I am using triplet loss in this competition to train a model. As such I have arranged the tfrecords to contain triplets of images. However if you want to create a tfrecord dataset without triplets you can still fork this notebook. I have highlighted at the appropriate code block what you would need to change.\n\nIf you'd like to see how to use this dataset to train a model, you can see how I've used it in this [notebook](https:\/\/www.kaggle.com\/mattbast\/google-landmark-retrieval-triplet-loss).","6f4d0fb2":"## Conclusion\n\nTo use these tfrecrds you will need to turn the output of this notebook into a public dataset. Simply commit the notebook, scroll to the bottom of the published notebook and click create dataset next to the notebook output. Once that is done you can do something like [this](https:\/\/www.kaggle.com\/mattbast\/google-landmark-retrieval-triplet-loss) to use your shiny new tfrecords.\n\nI think it is worth noting here that this is not the perfect solution to the super large dataset that comes with this challenge. If you take one image per unique landmark id you'll be left with 81k images out of the the total 1.5 million. That's a very small sample compared to the total size. This will certainly help you quickly train a model with many images but keep in mind the limitations of the size of this notebooks output vs the total size of the raw data.","652e7eac":"Here's another helper function that takes a subset of the examples indexes, loads the examples and writes them to a file.","c2325409":"## Write to tfrecords\n\nWith the dataset organised it's time to start writing the images to tfrecords. I wanted to quickly explain my understanding of what a tfrecord is before getting into how to create them as it took me a while to work it out.\n\nA tfrecord is a file that contains many examples of a dataset. So for most image related tasks an example would contain one image and probably some sort of label. In this task I have included three images (a triplet) in each example. Each image is also formatted as a byte string rather than an image or numpy array.\n\n![Screenshot%202020-08-05%20at%2012.39.06.png](attachment:Screenshot%202020-08-05%20at%2012.39.06.png)\n\nFormatting the data in this way helps tensorflow to distribute and cache the data. It also reduces the time it takes to transfer images to the google cloud bucket sitting next to a TPU. This is because we are transferring many examples bundled into one file rather than one image example at a time.\n\nSo to start I'll define a function to convert an image into a byte string.","3ada2786":"While I would like to convert all the images into tfrecords I am limited in that Kaggle notebooks only allow for 4.9GB of output (the landmarks dataset before it is converted to tfrecords is around 100GB large). I thus need to take a representative sample of the data. I decided that it would be better to get at least one image of every landmark in the dataset. This would help the model generalise better to various styles of architecture. \n\nA quick way to do this is to group by landmark, get the first two images per group and then reset the index to get the table back to the right shape.","7f39d995":"Now get a list of the example indexes (remember that each example contains three images).","d1c7b512":"And define the size and number of tfrecord files to create. I've heard 15 is a good number to aim for though honestly I'm still working out the best way to decide on the number of files to create. For now them I'll split the examples into 15 files.","fec6b9db":"## Load dataset\n\nFirst thing to do is to arrange the dataset into triplets. I'll start with the table of meta information about the images. It includes the image ids (which also includes the directory location of the image) and the id of the landmark in the image.","20241aba":"Finally bring everything together. Loop through the subsets of indexes and write a file for each subset.","a826d939":"Then get a random positive image. This function randomly picks an image from the group of images that contain the same landmark as the anchor. This may pick the same image as the anchor. However it saves some time as this is a fast way to perform the operation on a large dataset.","b121cabe":"And have a look at one of those groups.","d567af8e":"## Form triplets\n\nFor those new to triplet loss, here's a short description of what it means. Models will use triplet loss when they are trying to produce an embedding for an image. An embedding is an array of numbers that represents what is included in the image. Think of it like a textual description such as \"this image includes landmark x on a sunny day\" except this text is in a number format that the machine understands. These embeddings can then be compared using a clustering algorithm when a machine is trying to work out if two images contain the same monument.\n\nTriplet loss enables this by looking at images in threes. One image is an anchor and can include any landmark in it. The next is the positive image. This image must contain the same landmark as the anchor. Finally there is the negative image that contains a different landmark. The purpose then is to minimise the difference between the anchor and positive embeddings while maximising the distance between the anchor and the negative embeddings.\n\nThe dataset then needs to form these sets of three. Let's begin by organising the images into the groups by their landmark ids.","44860f5e":"We now have a list of anchor images with a positive and negative image next to each one. I've also renamed the id column to anchor_id to remind me that this column contains the id of the anchor image.","cf3a6b0b":"Then get a negative image. This time get a list of all the image indexes and randomly pick one. If this image does not contain the same landmark as the anchor use it as the negative. Otherwise repeat this process until an image not in the same landmark group is found.","6d404c56":"and a function that loads an image from the dataset and encodes it ready for the bytes feature function. Note that the dataset is split into many directories and sub directories. The first three characters of an images id specify the directory path that the image lives in.\n\nIt is also here that I can reduce the size of the tfrecord files. As mentioned before, Kaggle notebooks only allow 4.9GBs of data to be outputted so the images sample needs to be reduced here so to fit as many images as possible into the tfrecord files. I've opted for a size of 128,128 using the nearest neighbour method of resizing."}}