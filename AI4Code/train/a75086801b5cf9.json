{"cell_type":{"fe26a971":"code","8c14bbf7":"code","7db57bc0":"code","77372cba":"code","d82d006b":"code","0ac50f98":"code","5b57f144":"code","d1525ed5":"code","65662d49":"code","abae61b5":"code","67ac6f80":"code","07c6a406":"code","eef2ce8b":"code","72088538":"code","a1e62d2f":"code","77cab218":"code","75144729":"code","5ab31aea":"code","f4cc928f":"code","b1c6249a":"code","b3e4314d":"code","fa039029":"code","17f08eb0":"code","ae827827":"code","47284c09":"code","38033293":"code","50f3d5a1":"code","532cabd6":"code","6bc9061d":"code","71e6935d":"code","a32c4518":"code","fda1dd59":"code","593e722f":"code","2fb87f42":"code","f5981d18":"code","fde4570a":"code","c3525262":"code","55dc9e89":"code","7ff32dcc":"code","25b97a0c":"code","54651f03":"code","2266b286":"code","52bf85bd":"code","fe3e0802":"code","136d1cd0":"code","a1407aae":"code","3c85eeb0":"code","aaca8466":"code","b2ee078b":"code","06b6a397":"code","d7dc7d3f":"code","175048d0":"code","823f935f":"code","457558d3":"code","c0e33743":"code","f6da52a7":"code","bcf92c8c":"code","e197394f":"code","fd5cc463":"code","1e7b0d2b":"code","ebac0a19":"code","bae6d7fe":"code","3b419818":"code","2f61e853":"code","0e6e0f79":"code","869d9566":"code","d5a8472f":"code","a4282e3e":"code","6ea10392":"code","db039aaa":"code","4802d772":"code","1db74143":"code","829c47e5":"code","8c49a228":"code","90e14bc9":"code","7ca75854":"code","09a72639":"code","b9370e2f":"code","3e270938":"code","c5b334d6":"code","121bdbf6":"code","23e47b23":"code","18c7fb09":"markdown","cde84adb":"markdown","6e2970cf":"markdown","70e2c161":"markdown","612b9a9d":"markdown","498e4d49":"markdown","7721cf95":"markdown","90355233":"markdown","ac310658":"markdown","52ba8ee2":"markdown","1a1e8da5":"markdown","c5df8124":"markdown","1592b676":"markdown","b1e61290":"markdown","78c9ec42":"markdown","245cc960":"markdown","54f94261":"markdown","5d2dddff":"markdown","68615dec":"markdown","0af15bf0":"markdown"},"source":{"fe26a971":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c14bbf7":"# !pip install -U textblob\n# !python -m textblob.download_corpora\n\n# Import Textblob Modules\nfrom textblob import TextBlob\nfrom textblob import Word\n#from textblob.wordnet import VERB\nfrom textblob.classifiers import NaiveBayesClassifier\n\nimport nltk \nnltk.download('brown')","7db57bc0":"text = '''                                       \nSentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text \ndata using text analysis techniques. Sentiment analysis allows \nbusinesses to identify customer sentiment toward products, brands or services in online conversations and feedback.\n'''\nprint(text)","77372cba":"# Let\u2019s create our first TextBlob object.\nwiki = TextBlob(text)\nwiki","d82d006b":"type(wiki)","0ac50f98":"wiki.","5b57f144":"wiki.words","d1525ed5":"wiki.words.count('Better') # lowwer case is done","65662d49":"wiki.words.count('Sentiment') # lower case is done","abae61b5":"wiki.words.count('sentiment')","67ac6f80":"wiki.sentences","07c6a406":"wiki.word_counts # gives us the number of times the word has appeared , everything converted to Lower case","eef2ce8b":"type(wiki.word_counts)","72088538":"wiki.word_counts['text']","a1e62d2f":"wiki.words.count('text', case_sensitive=True)","77cab218":"wiki.words.count('Text', case_sensitive=True)","75144729":"sentence = TextBlob(text)","5ab31aea":"sentence.words","f4cc928f":"sentence.words.singularize()","b1c6249a":"sentence.words.pluralize()","b3e4314d":"sentence.words[-4:-1].pluralize()","fa039029":"# Lemmatizers -- will always give the root word, will retain the meaning ---> keeping the Dictionary rules\/words into consideration\n\n# Stemming ---> will Trim the tokens from the end ---- es, ses, ed --> might happen that resultant word do not have any meaning","17f08eb0":"# lemmatization -- takes POS Tags  --- by default - NOUN,  it can be changed --- w.r.t tags , go lemmatization","ae827827":"w = Word(\"stripes\", pos_tag = 'n')\nw","47284c09":"w.lemmatize()","38033293":"w = Word(\"stripes\")\nw.lemmatize('v')","50f3d5a1":"w = Word(\"went\")","532cabd6":"w.lemmatize('v') ","6bc9061d":"zen = TextBlob(\"Beautiful is better than ugly. \"\n               \"Explicit is better than implicit. \"\n               \"Simple is better than complex.\")","71e6935d":"zen.tags","a32c4518":"for word, pos in zen.tags:\n    print(word.lower() + \" => \" + pos)","fda1dd59":"document = (\"In computer science, artificial intelligence (AI), \\\n            sometimes called machine intelligence, is intelligence \\\n            demonstrated by machines, in contrast to the natural intelligence \\\n            displayed by humans and animals. Computer science defines AI \\\n            research as the study of \\\"intelligent agents\\\": any device that \\\n            perceives its environment and takes actions that maximize its\\\n            chance of successfully achieving its goals.[1] Colloquially,\\\n            the term \\\"artificial intelligence\\\" is used to describe machines\\\n            that mimic \\\"cognitive\\\" functions that humans associate with other\\\n            human minds, such as \\\"learning\\\" and \\\"problem solving\\\".[2]\")\nprint(document)","593e722f":"text_blob_object = TextBlob(document)\n\nfor noun_phrase in text_blob_object.noun_phrases:    \n    print(noun_phrase)","2fb87f42":"b = TextBlob(\"I havv written goood speling!. speling corection is based. howw tooo writt a speling corectin module \")\n\nfor i in b.sentences:\n    \n    print(i.correct())","f5981d18":"from textblob import Word\nw = Word('falibility')\n\nw.spellcheck() # 1 is the confidence","fde4570a":"?w.spellcheck","c3525262":"from textblob import Word\nw = Word('apoloclypse')\nw.spellcheck() # 1 is the confidence","55dc9e89":"w = Word('armagedon')\nw.spellcheck() # 1 is the confidence","7ff32dcc":"b = TextBlob(\"I havv goood speling!. speling corection is based. howw tooo writt a speling corect \")\n\nfor i in b.words:    \n    print(i.spellcheck())","25b97a0c":"en_blob = TextBlob(u'Simple is better than complex.')","54651f03":"en_blob.translate(to='es') # ","2266b286":"en_blob.translate(to='hi') # ","52bf85bd":"en_blob.translate(to='mr') # ","fe3e0802":"chinese_blob = TextBlob(u\"\u7f8e\u4e3d\u4f18\u4e8e\u4e11\u964b\")\n\nchinese_blob.translate(from_lang=\"zh-CN\", to='en') # en == english","136d1cd0":"b = TextBlob(u\"\u0628\u0633\u064a\u0637 \u0647\u0648 \u0623\u0641\u0636\u0644 \u0645\u0646 \u0645\u062c\u0645\u0639\")\nb.detect_language()","a1407aae":"b.translate(from_lang=\"ar\", to='en') # en == english","3c85eeb0":"b = TextBlob(\"tumi kemon aachon\")\nb.detect_language()","aaca8466":"b = TextBlob(u\"\u0915\u094d\u092f\u093e \u0939\u093e\u0932 \u0939\u0948\")\nb.detect_language()","b2ee078b":"b.translate(from_lang=\"hi\", to='en')","06b6a397":"st =  [\"\u0915\u094d\u092f\u093e \u0939\u093e\u0932 \u0939\u0948\" ,\"\u062a\u0648\u0647\u0627\u0646 \u06aa\u064a\u0626\u0646 \u0622\u0647\u064a\u0648\" ,\"\u0986\u09aa\u09a8\u09bf \u0995\u09c7\u09ae\u09a8 \u0986\u099b\u09c7\u09a8\" ,\"\u0ba8\u0bc0\u0b99\u0bcd\u0b95\u0bb3\u0bcd \u0b8e\u0baa\u0bcd\u0baa\u0b9f\u0bbf\" ,\"\u0b87\u0bb0\u0bc1\u0b95\u0bcd\u0b95\u0bbf\u0bb1\u0bc0\u0bb0\u0bcd\u0b95\u0bb3\u0bcd\" ,\"\u0924\u093f\u092e\u0940\u0932\u093e\u0908 \u0915\u0938\u094d\u0924\u094b \u091b\" ,\"\u0aa4\u0aae\u0ac7 \u0a95\u0ac7\u0aae \u0a9b\u0acb\" ,\"\u0924\u0942 \u0915\u0938\u093e \u0906\u0939\u0947\u0938 \",\"\u0d28\u0d4d\u0d24\u0d46\u0d3e\u0d15\u0d4d\u0d15\u0d46\u0d2f\u0d41\u0d23\u0d4d\u0d1f\u0d4d\"]","d7dc7d3f":"for i in st:\n    a = TextBlob(i)\n    t = a.detect_language()\n    print(t)\n    print(a.translate(from_lang=t, to='en'))","175048d0":"blob = TextBlob(\"Now is better than never.\")","823f935f":"blob.ngrams(n=3)","457558d3":"# from textblob import Word\nword = Word(\"happy\")\nword.definitions","c0e33743":"word = Word(\"elated\")\nword.definitions","f6da52a7":"word.synsets[:5]","bcf92c8c":"# Synonyms from WordNet\n \nsynonyms = set()\nfor synset in word.synsets:\n    for lemma in synset.lemmas():\n        synonyms.add(lemma.name())\n         \nprint(synonyms)","e197394f":"# Getting Antonyms using TextBlob\nantonyms = set()\nfor synset in word.synsets:\n    for lemma in synset.lemmas():        \n        if lemma.antonyms():\n            antonyms.add(lemma.antonyms()[0].name())       \nprint(antonyms)","fd5cc463":"text = \"I love to watch football, but I have never played it\"\ntext_blob_object = TextBlob(text)\n\nprint(text_blob_object.upper())","1e7b0d2b":"text = \"I LOVE TO WATCH FOOTBALL, BUT I HAVE NEVER PLAYED IT\"\ntext_blob_object = TextBlob(text)\n\nprint(text_blob_object.lower())","ebac0a19":"TextBlob(\"so the two together did the job\").sentiment","bae6d7fe":"testimonial1 = TextBlob(\"I want to applause you on your last year's amazing performance\")\ntestimonial4 = TextBlob(\"Mumbai is a city in India. India is in Asia\")","3b419818":"print('Sentiment 1: ', testimonial1.sentiment)\nprint('Sentiment 2: ', testimonial4.sentiment)","2f61e853":"print('Polarity: ', testimonial1.sentiment.polarity)","0e6e0f79":"print('Polarity: ', testimonial1.sentiment.subjectivity)","869d9566":"from textblob.classifiers import NaiveBayesClassifier","d5a8472f":"# create some training and test data.\n# List of Tuples , first being the data , 2nd is the tag\ntrain = [\n     ('I love this sandwich.', 'pos'),  \n     ('this is an amazing place!', 'pos'),\n     ('I feel very good about these beers.', 'pos'),\n     ('this is my best work.', 'pos'),\n     (\"what an awesome view\", 'pos'),\n     ('I do not like this restaurant', 'neg'),\n     ('I am tired of this stuff.', 'neg'),\n     (\"I can't deal with this\", 'neg'),\n     ('he is my sworn enemy!', 'neg'),\n     ('my boss is horrible.', 'neg')\n ]","a4282e3e":"test = [\n     ('the beer was good.', 'pos'),\n     ('I do not enjoy my job', 'neg'),\n     (\"I ain't feeling dandy today.\", 'neg'),\n     (\"I feel amazing!\", 'pos'),\n     ('Gary is a friend of mine.', 'pos'),\n     (\"I can't believe I'm doing this.\", 'neg')\n ]","6ea10392":"cl = NaiveBayesClassifier(train) # Trained my classifier on Train data","db039aaa":"# Loading Data from Files\n# You can also load data from common file formats including CSV, JSON, and TSV.\n\n# CSV files should be formatted like so:\n\n# I love this sandwich.,pos\n# This is an amazing place!,pos\n# I do not like this restaurant,neg","4802d772":"# Classifying Text\n# Call the classify(text) method to use the classifier.\n\ncl.classify(\"This is the best library!\")","1db74143":"# You can get the label probability distribution with the prob_classify(text) method.","829c47e5":"prob_dist = cl.prob_classify(\"This one's a doozy.\")","8c49a228":"prob_dist.prob('pos')","90e14bc9":"round(prob_dist.prob(\"pos\"), 2)","7ca75854":"round(prob_dist.prob(\"neg\"), 2)","09a72639":"# Evaluating Classifiers\n# To compute the accuracy on our test set, use the accuracy(test_data) method.\ncl.accuracy(test)","b9370e2f":"new_data = [('She is my best friend.', 'pos'),\n             (\"I'm happy to have a new friend.\", 'pos'),\n             (\"Stay thirsty, my friend.\", 'pos'),\n             (\"He ain't from around here.\", 'neg')]","3e270938":"cl.update(new_data)","c5b334d6":"cl.accuracy(test)","121bdbf6":"cl.classify(\"This is an amazing library!\")","23e47b23":"cl.classify(\"I want to get rid of this library!\")","18c7fb09":"The synonyms contained within a synset are called lemmas. You can access the string versions of these synonyms via a Synset's lemma_names property.","cde84adb":"## 10. Sentiment Analysis\n\n* The sentiment property returns a named tuple of the form Sentiment(polarity, subjectivity). \n* The polarity score is a float within the range [-1.0, 1.0]. \n* The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n* Polarity is a float value within the range [-1.0 to 1.0] where \n - 0 indicates neutral, \n - 1 indicates a very positive sentiment and \n - -1 represents a very negative sentiment.\n\n* Subjectivity is a float value within the range [0.0 to 1.0] where \n\n  - 0.0 is very objective and \n  - 1.0 is very subjective. ","6e2970cf":"## 9. Converting to Upper and Lowercase\nTextBlob objects are very similar to strings. You can convert them to upper case or lower case, change their values, and concatenate them together as well. In the following script, we convert the text from the TextBlob object to upper case:","70e2c161":"### Updating Classifiers with New Data","612b9a9d":"Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word, confidence) tuples with spelling suggestions.","498e4d49":"## 8. WordNet Integration\n\nWordNet is a database of English words that are linked together by their semantic relationships. It is like a supercharged dictionary\/thesaurus with a graph structure.\n\nTextBlob 0.7 now integrates __NLTK's WordNet__ interface, making it very simple to interact with WordNet.\n\n### Synsets\nAs you know, synonyms are words that have similar meanings. A synonym set, or synset, is a group of synonyms. A synset, therefore, corresponds to an abstract concept.\n\nIn TextBlob, you can access the synsets that a word belongs to by accessing the synsets property of a Word object.\n\n* What is WordNet? A Conceptual Introduction Using Python - https:\/\/stevenloria.com\/wordnet-tutorial\/https:\/\/stevenloria.com\/wordnet-tutorial\/","7721cf95":"**Polarity score  [- 1, 1 ]** \n\n1. closer to -1 -- negative sentiment\n2. closer to +1 - positive sentiment\n\n\n\n**Subjectivity Score  [0,1 ]** \n \n\n1. close to 1 mean more of personal opinion\n2. closer to 0 mean more of factual information","90355233":"If you access the frequencies this way, the search will not be case sensitive, and words that are not found will have a frequency of 0.\n\nThe second way is to use the count() method.","ac310658":"## 4. Noun Phrase Extraction\n\nnoun phrases are accessed through the noun_phrases property.","52ba8ee2":"## 2. Words Inflection and Lemmatization\n\nEach word in TextBlob.words or Sentence.words is a Word object (a subclass of unicode) with useful methods, e.g. for word inflection.","1a1e8da5":"## 6. Translation and Language Detection\n\nOne of the most powerful capabilities of the TextBlob library is to translate from one language to another. On the backend, the TextBlob language translator uses the __Google Translate API__\n\n\n\nhttps:\/\/cloud.google.com\/translate\/docs\/languages","c5df8124":"You can also attempt to detect a TextBlob\u2019s language using TextBlob.detect_language().","1592b676":"## 11. Text Classification Using Naive Bayes","b1e61290":"Due to the advancement in natural language processing tools, there are several open source tools available for natural language processing. One of them is TextBlob lets have a look at this tool and how easily it can be implemented. Text Blob is a simple python library used to perform NLP task like \n- tokenization, \n- Noun phrase extraction, \n- POS-Tagging, Words inflection and lemmatization, \n- N-grams, \n- Sentiment Analysis. \n<br>\nIt is like NLTK just it has more features like Spelling correction, Creating a short summary of a text, Translation and language detection.","78c9ec42":"## 1. Tokenization","245cc960":"## 7. N-Grams\n\n- N-Grams refer to n combination of words in a sentence. For instance, for a sentence \"I love watching football\", some 2-grams would be (I love), (love watching) and (watching football). \n\n- N-Grams can play a crucial role in text classification.\n\n- The TextBlob.ngrams() method returns a list of tuples of n successive words.","54f94261":"## 5. Spelling Correction\nUse the correct() method to attempt spelling correction.\n\nSpelling correction is based on Peter Norvig\u2019s \u201cHow to Write a Spelling Corrector\u201d as implemented in the pattern library. It is about 70% accurate","5d2dddff":"Words can be lemmatized by calling the lemmatize method.","68615dec":"# <center> Introduction to TextBlob - A tool for Natural Language Processing !","0af15bf0":"## 3. POS Tagging\n\nPart-of-speech tags can be accessed through the tags property."}}