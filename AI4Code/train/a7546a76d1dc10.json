{"cell_type":{"0c5e3d71":"code","50e748fa":"code","285f6199":"code","e5772a7d":"code","a366fdd4":"code","172809ff":"code","f2b4da1a":"code","a7698ab2":"code","782e1459":"code","6cd6a415":"code","725ce18f":"code","8f00cd75":"code","d8dd7936":"code","285c3cc7":"code","256d3b13":"code","20497cd1":"code","64b03638":"code","02793738":"markdown"},"source":{"0c5e3d71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","50e748fa":"#Importing data and libaries","285f6199":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")","e5772a7d":"import re\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport numpy as np","a366fdd4":"\nlemma=WordNetLemmatizer()\n\ntrain.drop(['keyword','location'],inplace=True,axis=1)\ntest.drop(['keyword','location'],inplace=True,axis=1)","172809ff":"#data preprocessing\ntrain_corpus=[]\ntest_corpus=[]\n\nfor  i in range(len(train)):\n    review=re.sub('[^a-zA-Z]',' ',train['text'][i])\n    review=review.lower()\n    review=review.split()\n    review=[lemma.lemmatize(word) for word in review if word not in stopwords.words('english')]\n    review=' '.join(review)\n    train_corpus.append(review)\n    \nfor  j in range(len(test)):\n    review1=re.sub('[^a-zA-Z]',' ',test['text'][j])\n    review1=review1.lower()\n    review1=review1.split()\n    review1=[lemma.lemmatize(word) for word in review1 if word not in stopwords.words('english')]\n    review1=' '.join(review1)\n    test_corpus.append(review1)  ","f2b4da1a":"#Model Building\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n \ntf=TfidfVectorizer(max_features=10000)","a7698ab2":"Xtrain2=tf.fit_transform(train_corpus).toarray()\n \nYtrain2=train['target']","782e1459":"Xtest2=tf.fit_transform(test_corpus).toarray()","6cd6a415":"Xtrain2","725ce18f":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(Xtrain2,Ytrain2,test_size=0.3,random_state=2)","8f00cd75":"from sklearn.naive_bayes import MultinomialNB\n \nmodel=MultinomialNB()","d8dd7936":"model.fit(xtrain,ytrain)\npredict1=model.predict(xtest)\nprint(model.score(xtest,ytest))","285c3cc7":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=150,random_state=2)\nrfc.fit(xtrain,ytrain)\nprint(rfc.score(xtest,ytest))","256d3b13":"#Hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\nparameters={'n_estimators':[50,100,150,200,300]}\ngrid=GridSearchCV(rfc,parameters,cv=None)\ngrid.fit(xtrain,ytrain)","20497cd1":"grid.best_params_\n#Naive_bayes perform well so we select naive bayes model and make predictions","64b03638":"submit3=pd.DataFrame()\nsubmit3['id']=test['id']   \nsubmit3['target']=predictions_log2\n\nsubmit3.to_csv('realornotsubmission555.csv',index=False)","02793738":"This is kaggle real or not problem.I solve this NLP problem in a certains steps:\n1.Importing data and Libaries\n2.Removing stopwords and punctuations i.e Data preprocessing\n3.Data Cleaning (Lemmatization)\n4.Model Buiding\n5.Training the model \n6.Hyperparater tuning\n7.Final predictions\n8.Submissions"}}