{"cell_type":{"640e8412":"code","b3d3a81a":"code","ae95c6b4":"code","9fa79f07":"code","2d8c4c60":"code","80e94a53":"code","a12612a6":"code","0323f624":"code","c2e285d9":"code","8eba4463":"code","e27ab7c0":"code","2e3dfd8d":"code","d630ee55":"code","e7ecb513":"code","bc0eaa15":"code","2e921fc7":"code","96f26ded":"code","172365e2":"code","acde91c8":"code","8fd5f2d9":"code","6cc0e377":"code","64b5c534":"code","484d5158":"code","d751f5c3":"code","36e814c2":"code","87ee8e1b":"code","6f0e2abd":"code","25d4b77e":"code","0c17d0e9":"code","ee242a85":"code","d8edef46":"code","37ce995e":"code","878855c2":"code","932788e3":"code","c0e2d29c":"code","dde856e5":"code","14938656":"code","ba93d71e":"code","9d150fbe":"code","849f937e":"code","f739a6f6":"code","349fb41c":"code","2632f46c":"code","893b1268":"markdown","b80bbe71":"markdown","8df977e7":"markdown","61be10a8":"markdown","879fadab":"markdown"},"source":{"640e8412":"# import relevant python modules for the analysis\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom itertools import combinations\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas.util.testing as tm","b3d3a81a":"#merge 12 months data into 1 data file for analysis and read into jupyter notebooks\n\nfile = '..\/input\/mobile-and-accessories-store\/All Sales Data.csv'\ndf = pd.read_csv(file)\nprint(df.head(2))","ae95c6b4":"# data preview\n\ndf.head(3)","9fa79f07":"# check the shape of the data\n\ndf.shape","2d8c4c60":"# data types\n\ndf.dtypes","80e94a53":"# do we have missing values?\n\ndf.isna().values.any()","a12612a6":"# do we have duplicates?\n\ndf.duplicated().values.any()","0323f624":"# drop missing values\n\ndf.dropna(how='all', inplace= True)","c2e285d9":"# drop all duplicates\n\ndf = df.drop_duplicates()","8eba4463":"# check\n\ndf.isna().values.any()","e27ab7c0":"# check\n\ndf.duplicated().values.any()","2e3dfd8d":"df.shape","d630ee55":"df.head(3)","e7ecb513":"df.drop(index=516, inplace=True)","bc0eaa15":"#let's change relevant columns to the correct data types\n\ndf[['Quantity Ordered', 'Price Each']] = df[['Quantity Ordered', 'Price Each']].apply(pd.to_numeric)","2e921fc7":"# check to see if it worked\ndf.dtypes","96f26ded":"df['Total'] = df['Quantity Ordered'] * df['Price Each']","172365e2":"df.head(2)","acde91c8":"df.reset_index(drop=True, inplace = True)","8fd5f2d9":"df.shape","6cc0e377":"df['Month'] = df['Order Date'].str[0:1].apply(pd.to_numeric)","64b5c534":"df.head(2)","484d5158":"df.dtypes","d751f5c3":"def city(address):\n    return address.split(\",\")[1]\n    \ndef state(address):\n    return address.split(\",\")[2].split(\" \")[1]\n\ndef zipcode(address):\n    return address.split(\",\")[2].split(\" \")[3]\n    \ndf['City'] = df['Purchase Address'].apply(lambda x: city(x) + ', ' + state(x))","36e814c2":"df.head(2)","87ee8e1b":"df.groupby('Product').count()['Quantity Ordered'].sort_values(ascending=False)","6f0e2abd":"# How many unique products are there?\n\ndf['Product'].nunique()","25d4b77e":"df_viz = df.groupby('Product').count()['Quantity Ordered'].sort_values()","0c17d0e9":"# Best selling product by volume\nfig, ax = plt.subplots(figsize=(6,8))\ndf_viz.plot(kind = 'barh',ax= ax)\nax.set(title = 'Sales Count By Product')\nax.title.set(y=1.07)\nax.set_xlabel('Total Sold',size=12)\nax.set_ylabel('Products',size=12)\nplt.show()","ee242a85":"# Best selling product by revenue\n\ndf.groupby('Product').sum()['Total'].sort_values(ascending=False)","d8edef46":"salesByProduct = df.groupby('Product').sum()['Total'].sort_values()","37ce995e":"fig, ax = plt.subplots(figsize=(6,8))\nsalesByProduct.plot(kind = 'barh', ax=ax)\nax.set(title= 'Sales By Product')\nax.title.set(y=1.10)\nax.set_xlabel('Total Sales', size=12)\nax.set_ylabel('Products', size=12)\nax.ticklabel_format(useOffset=False,style='plain',axis='x')\nlabels = ax.get_xticklabels()\n\n# define a function to convert scientific notation to shorter value\ndef totalsales(x, pos):\n    if x >= 1e6:\n        s = '${:1.1f}M'.format(x*1e-6) \n    else:\n        s = '${:1.0f}K'.format(x*1e-3) \n    return s\n\nax.xaxis.set_major_formatter(totalsales)\nplt.setp(labels, rotation =0)\nplt.show()","878855c2":"# City with the highest sales\ndf.groupby('City').sum()['Total'].round()","932788e3":"citysales = df.groupby('City').sum()['Total'].round()\nfig, ax = plt.subplots(figsize=(6,4))\ncitysales.plot(kind='bar', ax=ax)\nax.set(title= 'Sales By City')\nax.title.set(y=1.10)\nax.ticklabel_format(useOffset=False,style='plain',axis='y')\nlabels = ax.get_xticklabels()\nplt.show()","c0e2d29c":"df['Order Date'] = pd.to_datetime(df['Order Date'])","dde856e5":"# Now we have converted the order date column to datetime data type\ndf.dtypes","14938656":"# Let's see the dataframe again\ndf.head(3)","ba93d71e":"# Augment relevant columns to have hours and minutes element\n\ndf['Daytime Hour'] = df['Order Date'].dt.hour\ndf['Daytime Minute'] = df['Order Date'].dt.minute\ndf.head(3)","9d150fbe":"# Let's visualize what times the orders came in on average.\n\nfig, ax = plt.subplots(figsize=(8,5.2))\ndf.groupby('Daytime Hour').count()['Quantity Ordered'].plot()\nax.set(title = 'Timeline of Orders')\nax.title.set(y=1.01)\nax.set_xlabel('Daytime Hour', size=12)\nax.set_ylabel('Quantity Ordered', size=12)\nlabels = df['Daytime Hour'].unique()\nax.set_xticks(labels)\nax.grid(axis='x')\nplt.show()","849f937e":"# Let's then see which products were ordered together most often\n# How do I know that products were ordered together? \n#If you see the dataframe below, you can see that some ORDER ID are repeated for different products. \ndf.head()","f739a6f6":"# What products were bought together most?\n\nrepeated_orders = df[df['Order ID'].duplicated(keep=False)]\nrepeated_orders['Bought Together'] = repeated_orders.groupby('Order ID')['Product'].transform(lambda x: \",\".join(x))\n#repeated_orders = repeated_orders[['Order ID', 'Bought Together']]\nrepeated_orders = repeated_orders[['Order ID', 'Bought Together']].drop_duplicates()\nrepeated_orders.head(10)","349fb41c":"# continuation of the operation from last cell\n\ncount = Counter()\nfor row in repeated_orders['Bought Together']:\n    row_list = row.split(',')\n    count.update(Counter(combinations(row_list, 2)))\n    \nfor most_common, number_sold in count.most_common(10):\n    print(most_common, number_sold)","2632f46c":"count = Counter()\nfor row in repeated_orders['Bought Together']:\n    row_list = row.split(',')\n    count.update(Counter(combinations(row_list, 3)))\n    \nfor most_common, number_sold in count.most_common(10):\n    print(most_common, number_sold)","893b1268":"#### Now we have to clean up the data to remove NAN values & duplicates and convert data types","b80bbe71":"# This project is an analysis of a mobile gadgets and accessories store.\n\n#### It's a practice project I did few months ago, and had to refresh today.\n#### Credit for the data goes to Keith Galli, he's on GitHub.\n\nThe activities are going to work on are as follows;\n\n1. Data cleaning\n2. Data sorting\n3. Find best selling product.\n4. Find city with best sales performance.\n5. Find the peak time for orders.\n6. Find products that were bought together most as a pair of 2 and 3.\n\nLet's start the project.","8df977e7":"#### Next, we have to augment the data by adding relevant extra columns","61be10a8":"#### Now let's perform some simple exploratory data analysis to further understand the data","879fadab":"## Conclusion\n\nWhat can we do with the details of this analysis?\n\n1. We can decide to drop products that are not performing well in volume & revenue.\n2. If the company is struggling with runnig cost, store in Portland, ME can be closed.\n3. Peak time for orders can help in two ways; for focused advertising & also in terms of staff allocation\/rotation.\n4. Products bought together can be offered as one package with discount, to drive sales.\n5. The Mac Book Pro was the most popular product.\n6. While the iPhone & its charger were the pair most frequently purchased.\n7. The outlet in San Francisco, CA was the best performing.\n\n\nThank you for your time. Your comments, and constructive criticisms (if any) are welcome. "}}