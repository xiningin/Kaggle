{"cell_type":{"b3453362":"code","9cdd1680":"code","408835c8":"code","423051de":"code","fc3a6958":"code","a486d8e0":"code","cb59bd07":"code","05133cca":"code","87b5fe3d":"code","8b488868":"code","67b2d0ac":"code","327a5139":"code","62bf7f5b":"code","499e6b40":"code","eebbeef4":"markdown","ad9db518":"markdown"},"source":{"b3453362":"import os\nimport PIL\nimport copy\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nfrom operator import itemgetter\n\n# DataSet Spliting into Train\/Test\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Models\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.densenet import DenseNet201\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\n# Confusion Matrix, Acc Score\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n# Graph Plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.image import imread\nfrom IPython.display import display\nfrom tensorflow.keras.utils import plot_model\n\n# Remove Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","9cdd1680":"train_dir = \"..\/input\/flowers-recognition\/flowers\"","408835c8":"datagen = ImageDataGenerator(validation_split=0.10, \n                             rescale=1.\/255,\n                             rotation_range=30,\n                             zoom_range=0.15,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             shear_range=0.15,\n                             horizontal_flip=True,\n                             fill_mode=\"nearest\")","423051de":"train_generator = datagen.flow_from_directory(\n    train_dir, \n    subset='training',\n    target_size=(256, 256),\n    batch_size=32\n)\n\ntest_generator = datagen.flow_from_directory(\n    train_dir,\n    subset='validation',\n    target_size=(256, 256),\n    batch_size=32\n)","fc3a6958":"len(train_generator.class_indices)","a486d8e0":"len(train_generator), len(test_generator)","cb59bd07":"input_shape = (256, 256, 3)\nnum_class = len(train_generator.class_indices)\nweights='imagenet'\ndense_units = 1024\n\nbasemodel = DenseNet201(weights = weights,\n                         include_top = False,\n                         input_shape = input_shape)\n\nx = basemodel.output\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nx = Dense(dense_units)(x)\nx = BatchNormalization()(x)\nx = Activation(activation='relu')(x)\nx = Dropout(0.5)(x)\n\nif num_class>1:\n    outputs = Dense(num_class, activation=\"softmax\")(x)\nelse:\n    outputs = Dense(1, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=basemodel.input, outputs=outputs)\n\n# Compile the model\nmodel.compile(\n    loss = \"categorical_crossentropy\", optimizer = SGD(lr = 0.005, momentum = 0.9),\n    metrics = [\"accuracy\"]\n)\n","05133cca":"nb_validation_samples = 430\n\n# Unfreeze the weights in the base model, now these weights will be changed during training\nbasemodel.trainable = True\n\nearly_stop = EarlyStopping(monitor='val_loss', \n                           patience=4, \n                           verbose=1, \n                           min_delta=1e-4)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.1, \n                              patience=4, \n                              verbose=1, \n                              min_delta=1e-4)\n\ncallbacks_list = [early_stop, reduce_lr]\n\n\nhistory = model.fit_generator(\n    train_generator,\n    epochs=10,\n    validation_data=test_generator,\n    validation_steps=nb_validation_samples \/\/ 32,\n    callbacks=callbacks_list\n)","87b5fe3d":"label = train_generator.class_indices\nnew_label = dict([(value, key) for key, value in label.items()])\nprint(new_label)","8b488868":"# Loading images and their predictions \n\ndef predict_flower(img_path):\n    img= PIL.Image.open(img_path)\n    img = img.resize((256,256))\n    \n    img = np.asarray(img, dtype= np.float32)\n    img = img \/ 255\n    img = img.reshape(-1,256,256,3)\n    predict = model.predict(img)\n    predict = np.argmax(predict)\n    return new_label[predict]","67b2d0ac":"path = \"..\/input\/flowers-recognition\/flowers\/daisy\/10437754174_22ec990b77_m.jpg\"\npredict_flower(path)","327a5139":"batch_size = 32","62bf7f5b":"test_score = model.evaluate_generator(test_generator, batch_size)\nprint(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100))\nprint(\"[INFO] Loss: \",test_score[0])","499e6b40":"#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(7,7))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    \n#Print the Target names\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools \n\ntarget_names = []\nfor key in train_generator.class_indices:\n    target_names.append(key)\n# print(target_names)\n\n#Confution Matrix\nY_pred = model.predict_generator(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\n\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, title='Confusion Matrix')\n\n#Print Classification Report\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","eebbeef4":"## Making Training and Testing Dataset from Main","ad9db518":"## Thank You"}}