{"cell_type":{"8dce2a68":"code","f93d4181":"code","b81e70d6":"code","0ea6b411":"code","7e2777be":"code","599c2c5d":"code","56350037":"code","9136c40b":"code","7c2117d0":"code","931b221c":"code","3854f63a":"code","abc736b0":"code","9711dd6c":"code","9bbc4235":"code","4958841d":"code","867f4a8f":"code","568b3dcd":"code","7e4ba213":"code","dc545fc4":"code","f7e6716b":"code","69406327":"code","8f65f614":"code","87dc9ac4":"code","6cfdca84":"code","94910e6d":"code","9bc3b213":"code","aa2c668d":"code","1e57f2a0":"code","9a8d1fc1":"code","a19c39e8":"code","6f8fba38":"code","0ea777e7":"code","dfeb8cd3":"code","29093af1":"code","38c91fd4":"code","afb5cf43":"code","113a59e8":"markdown","5685eb00":"markdown","f89ec7b4":"markdown","e46b2bae":"markdown","3f325559":"markdown","175f09a9":"markdown","077583c8":"markdown","9f0dda14":"markdown","fcece33a":"markdown"},"source":{"8dce2a68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f93d4181":"import pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nprint(tf.__version__)","b81e70d6":"#\u5bfc\u5165\u6570\u636e\nx1 = pd.read_csv('..\/input\/mnist-in-csv\/mnist_train.csv')\nx2 = pd.read_csv('..\/input\/mnist-in-csv\/mnist_test.csv')","0ea6b411":"##\u5206\u51fa\u6807\u7b7e\u7c7b\ny_train = x1['label']\ny_test = x2['label']\nprint(y1,y2)","7e2777be":"#\u5206\u51fa\u7279\u5f81\u90e8\u4efd\nx_train = x1.drop(['label'],axis = 1)\nx_test = x2.drop(['label'],axis = 1)\nprint(x_train.shape,x_test.shape)\nprint(y_train.shape,y_test.shape)","599c2c5d":"model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=(784,)),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer=keras.optimizers.Adam(),\n             loss='sparse_categorical_crossentropy',           #keras.losses.SparseCategoricalCrossentropy()  \n             metrics=['accuracy'])\nmodel.summary()","56350037":"##\u8bad\u7ec3\u6a21\u578b\nhistory = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=1)","9136c40b":"##\u753b\u51fa\u66f2\u7ebf!! \ndef plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","7c2117d0":"#\u8bc4\u4f30\u6a21\u578b\nscores = model.evaluate(x_test, y_test)\nscores[1]","931b221c":"model = keras.Sequential([\n    layers.Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(784,)),\n    layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n    layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer=keras.optimizers.Adam(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\nmodel.summary()","3854f63a":"history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=0)","abc736b0":"def plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","9711dd6c":"#\u8bc4\u4f30\u6a21\u578b\nscores = model.evaluate(x_test, y_test)\nscores[1]","9bbc4235":"model = keras.Sequential([\n    layers.Dense(64, activation='sigmoid', input_shape=(784,)),\n    layers.Dense(64, activation='sigmoid'),\n    layers.Dense(64, activation='sigmoid'),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer=keras.optimizers.Adam(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\nmodel.summary()","4958841d":"history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=0)","867f4a8f":"def plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","568b3dcd":"#\u8bc4\u4f30\u6a21\u578b\nscores = model.evaluate(x_test, y_test)\nscores[1]","7e4ba213":"model = keras.Sequential([\n    layers.Dense(64, activation='sigmoid', input_shape=(784,)),\n    layers.Dense(64, activation='sigmoid'),\n    layers.Dense(64, activation='sigmoid'),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer=keras.optimizers.SGD(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\nmodel.summary()","dc545fc4":"history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=0)","f7e6716b":"def plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","69406327":"#\u8bc4\u4f30\u6a21\u578b\nscores = model.evaluate(x_test, y_test)\nscores[1]","8f65f614":"model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=(784,)),\n    layers.BatchNormalization(),\n    layers.Dense(64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer=keras.optimizers.Adam(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\nmodel.summary()","87dc9ac4":"history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=0)","6cfdca84":"def plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","94910e6d":"#\u8bc4\u4f30\u6a21\u578b\nscores = model.evaluate(x_test, y_test)\nscores[1]","9bc3b213":"model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=(784,)),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer=keras.optimizers.Adam(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\nmodel.summary()","aa2c668d":"history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=0)","1e57f2a0":"def plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","9a8d1fc1":"#\u8bc4\u4f30\u6a21\u578b\nscores = model.evaluate(x_test, y_test)\nscores[1]","a19c39e8":"\nimport numpy as np\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef mlp_model():\n    model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=(784,)),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(10, activation='softmax')\n    ])\n    model.compile(optimizer=keras.optimizers.Adam(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\n    return model\nmodel1 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)\nmodel2 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)\nmodel3 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)","6f8fba38":"ensemble_clf = VotingClassifier(estimators=[\n    ('model1', model1), ('model2', model2), ('model3', model3)\n], voting='soft')","0ea777e7":"history = ensemble_clf.fit(x_train, y_train","dfeb8cd3":"y_pred = ensemble_clf.predict(x_test)\nprint('acc: ', accuracy_score(y_pred, y_test))","29093af1":"from tensorflow.keras import layers\n\nimport numpy as np\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef mlp_model():\n    model = keras.Sequential([\n    layers.Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(784,)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(10, activation='softmax')\n    ])\n    model.compile(optimizer=keras.optimizers.SGD(),\n             loss=keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\n    return model\nmodel1 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)\nmodel2 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)\nmodel3 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)\nmodel4 = KerasClassifier(build_fn=mlp_model, epochs=100, verbose=0)\nensemble_clf = VotingClassifier(estimators=[\n    ('model1', model1), ('model2', model2), ('model3', model3),('model4', model4)])","38c91fd4":"ensemble_clf.fit(x_train, y_train)","afb5cf43":"y_predict = ensemble_clf.predict(x_test)\nprint('acc: ', accuracy_scoreecuracy_scorecuracy_score(y_predict, y_test))\n","113a59e8":"# \u6279\u6b63\u5219\u5316 \u52a0\u5165BatchNormalization()\n","5685eb00":"# \u57fa\u672c\u6a21\u578b","f89ec7b4":"# \u6539\u53d8\u4f18\u5316\u5668 (Adam\u3001SGD)","e46b2bae":"# #\u7efc\u5408\u5229\u7528","3f325559":"# \u96c6\u6210\u6a21\u578b\u8bad\u7ec3 (\u6295\u7968\u6cd5\u8bad\u7ec3\u6a21\u578b)\n","175f09a9":"# \u6743\u91cd\u521d\u59cb\u5316 \u4f7f\u7528 He\u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\u5668","077583c8":"\u611f\u8c22 czy36mengfei\u5927\u795e\u7684\u5f00\u6e90\u4ee3\u7801 \n\u5f88\u63a8\u8350\u4ed6\u5728Github\u7684\u4ee3\u7801!!!\n","9f0dda14":"# \u6539\u53d8 \u6fc0\u6d3b\u51fd\u6570(relu vs sigmoid)","fcece33a":"# \u52a0\u5165Dropout"}}