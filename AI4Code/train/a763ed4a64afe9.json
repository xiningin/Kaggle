{"cell_type":{"601c78a8":"code","c7270593":"code","b51aad77":"code","9aa996d4":"code","dca4ed59":"code","abc1ac22":"code","b0b25eac":"code","f5aa2aae":"code","bfd5e927":"code","2b78243e":"code","64e8c8df":"markdown","521b17c8":"markdown","5ee76bc7":"markdown","defdc901":"markdown","c1c6ef24":"markdown","27fe0d0b":"markdown","80606bea":"markdown"},"source":{"601c78a8":"# install dependencies: (use cu100 because colab is on CUDA 10.0)\n!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\nimport torch, torchvision\ntorch.__version__\n!gcc --version\n# opencv is pre-installed on colab","c7270593":"# install detectron2:\n!pip install detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu100\/index.html","b51aad77":"import detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog","9aa996d4":"!wget https:\/\/github.com\/TannerGilbert\/Detectron2-Train-a-Instance-Segmentation-Model\/raw\/master\/microcontroller_segmentation_data.zip\n!unzip microcontroller_segmentation_data.zip\n!ls","dca4ed59":"!ls 'Microcontroller Segmentation'","abc1ac22":"import os\nimport numpy as np\nimport json\nfrom detectron2.structures import BoxMode\n\ndef get_microcontroller_dicts(directory):\n    classes = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\n    dataset_dicts = []\n    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n        json_file = os.path.join(directory, filename)\n        with open(json_file) as f:\n            img_anns = json.load(f)\n\n        record = {}\n        \n        filename = os.path.join(directory, img_anns[\"imagePath\"])\n        \n        record[\"file_name\"] = filename\n        record[\"height\"] = 600\n        record[\"width\"] = 800\n      \n        annos = img_anns[\"shapes\"]\n        objs = []\n        for anno in annos:\n            px = [a[0] for a in anno['points']]\n            py = [a[1] for a in anno['points']]\n            poly = [(x, y) for x, y in zip(px, py)]\n            poly = [p for x in poly for p in x]\n\n            obj = {\n                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n                \"bbox_mode\": BoxMode.XYXY_ABS,\n                \"segmentation\": [poly],\n                \"category_id\": classes.index(anno['label']),\n                \"iscrowd\": 0\n            }\n            objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfor d in [\"train\", \"test\"]:\n    DatasetCatalog.register(\"microcontroller_\" + d, lambda d=d: get_microcontroller_dicts('Microcontroller Segmentation\/' + d))\n    MetadataCatalog.get(\"microcontroller_\" + d).set(thing_classes=['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora'])\nmicrocontroller_metadata = MetadataCatalog.get(\"microcontroller_train\")","b0b25eac":"import random\n\ndataset_dicts = get_microcontroller_dicts(\"Microcontroller Segmentation\/train\")\nfor d in random.sample(dataset_dicts, 3):\n    img = cv2.imread(d[\"file_name\"])\n    v = Visualizer(img[:, :, ::-1], metadata=microcontroller_metadata, scale=0.5)\n    v = v.draw_dataset_dict(d)\n    plt.figure(figsize = (14, 10))\n    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    plt.show()","f5aa2aae":"from detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"microcontroller_train\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025\ncfg.SOLVER.MAX_ITER = 1000\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","bfd5e927":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 \ncfg.DATASETS.TEST = (\"microcontroller_test\", )\npredictor = DefaultPredictor(cfg)","2b78243e":"from detectron2.utils.visualizer import ColorMode\ndataset_dicts = get_microcontroller_dicts('Microcontroller Segmentation\/test')\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=microcontroller_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.figure(figsize = (14, 10))\n    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    plt.show()","64e8c8df":"## Install detectron2\n\n> **Important**: If you're running on a local machine, be sure to follow the [installation instructions](https:\/\/github.com\/facebookresearch\/detectron2\/blob\/master\/INSTALL.md). This notebook includes only what's necessary to run in Colab.","521b17c8":"<table align=\"left\"><td>\n  <a target=\"_blank\"  href=\"https:\/\/colab.research.google.com\/github\/TannerGilbert\/Detectron2-Train-a-Instance-Segmentation-Model\/blob\/master\/Microcontroller_Instance_Segmentation.ipynb\">\n    <img src=\"https:\/\/www.tensorflow.org\/images\/colab_logo_32px.png\" \/>Run in Google Colab\n  <\/a>\n<\/td><td>\n  <a target=\"_blank\"  href=\"https:\/\/github.com\/TannerGilbert\/Detectron2-Train-a-Instance-Segmentation-Model\/blob\/master\/Microcontroller_Instance_Segmentation.ipynb\">\n    <img width=32px src=\"https:\/\/www.tensorflow.org\/images\/GitHub-Mark-32px.png\" \/>View source on GitHub<\/a>\n<\/td><\/table>","5ee76bc7":"# Detectron2: Microcontroller Instance Segmentation\n<img src=\"https:\/\/dl.fbaipublicfiles.com\/detectron2\/Detectron2-Logo-Horz.png\" width=\"500\">","defdc901":"## Register data-set\n\nIn order to use a dataset with Detectron2 we need to register it. For more information check out the official documentation.","c1c6ef24":"## Train model\n\nNow, let's fine-tune a pretrained FasterRCNN instance segmentation model on the microcontroller data-set.","27fe0d0b":"## Use model for inference\n\nNow, we can perform inference on our validation set by creating a predictor object.","80606bea":"## Get data"}}