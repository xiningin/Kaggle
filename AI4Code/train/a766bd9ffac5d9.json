{"cell_type":{"5b674a1a":"code","d5ccc88f":"code","472c8cbb":"code","e2de3602":"code","d28ecc71":"code","0411bbd9":"code","dbaaa4a8":"code","dcfe9455":"code","95ba7d1b":"code","60342441":"code","cbe4cc18":"code","20d962b1":"code","d8268ba4":"code","a0d2b2e6":"code","ee2a50e9":"code","190ee583":"code","c149ac80":"markdown","bae5c064":"markdown","85d018c6":"markdown","4c806acd":"markdown","5ec42308":"markdown","e4a911c7":"markdown","bbaad39b":"markdown","da66e569":"markdown","30c692ac":"markdown","60edca31":"markdown","13699477":"markdown","922d2493":"markdown"},"source":{"5b674a1a":"import os\nimport warnings\nimport gc\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import f1_score\nfrom keras import backend as K\nfrom keras import layers, models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import *\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nwarnings.filterwarnings('ignore')\nK.image_data_format()","d5ccc88f":"BATCH_SIZE = 22\nEPOCHS = 100\nk_folds = 5\nTTA_STEPS = 5\nPATIENCE = 10\nSEED = 523\nBASE_MODEL = Xception\nIMAGE_SIZE = 299","472c8cbb":"DATA_PATH = '..\/input\/3rd-comp-car-img\/'\n\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'cropped_train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'cropped_test')\n\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))","e2de3602":"df_train['class'] = df_train['class'].astype('str')\ndf_train = df_train[['img_file', 'class']]\ndf_test = df_test[['img_file']]","d28ecc71":"def recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","0411bbd9":"def get_callback(model_name, patient):\n    ES = EarlyStopping(\n        monitor='val_f1_m', \n        patience=patient, \n        mode='max', \n        verbose=1)\n    RR = ReduceLROnPlateau(\n        monitor = 'val_f1_m', \n        factor = 0.5, \n        patience = patient \/ 3, \n        min_lr=0.000001, \n        verbose=1, \n        mode='max')\n    MC = ModelCheckpoint(\n        filepath=model_name, \n        monitor='val_f1_m', \n        verbose=1, \n        save_best_only=True, \n        mode='max')\n\n    return [ES, RR, MC]","dbaaa4a8":"def get_model(model_name, iamge_size):\n    base_model = model_name(weights='imagenet', input_shape=(iamge_size,iamge_size,3), include_top=False)\n    #base_model.trainable = False\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(2048, activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.5))\n \n    model.add(layers.Dense(196, activation='softmax', kernel_initializer='lecun_normal'))\n    #model.summary()\n\n    optimizer = optimizers.Nadam(lr=0.0001)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc', f1_m, precision_m, recall_m])\n\n    return model","dcfe9455":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True,  # divide each input by its std\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zoom_range=0.2,\n    shear_range=0.2,\n    brightness_range=[0.5, 1.5],\n    fill_mode='nearest'\n    )\n\nvalid_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True  # divide each input by its std\n    )\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True,  # divide each input by its std\n    )","95ba7d1b":"skf = StratifiedKFold(n_splits=k_folds, random_state=SEED)","60342441":"# %%time\n# j = 1\n# model_names = []\n# for (train_index, valid_index) in skf.split(df_train['img_file'], df_train['class']):\n#     if j<=3:\n#         print(\"skip %d fold\" %(j))\n#         j+=1\n#         gc.collect()\n#         continue\n#     else:\n#         traindf = df_train.iloc[train_index, :].reset_index()\n#         validdf = df_train.iloc[valid_index, :].reset_index()\n# \n#         print(\"==============================================\")\n#         print(\"====== K Fold Validation step => %d\/%d =======\" % (j,k_folds))\n#         print(\"==============================================\")\n# \n#         train_generator = train_datagen.flow_from_dataframe(\n#             dataframe=traindf,\n#             directory=TRAIN_IMG_PATH,\n#             x_col='img_file',\n#             y_col='class',\n#             target_size= (IMAGE_SIZE, IMAGE_SIZE),\n#             color_mode='rgb',\n#             class_mode='categorical',\n#             batch_size=BATCH_SIZE,\n#             seed=SEED,\n#             shuffle=True\n#             )\n# \n#         valid_generator = valid_datagen.flow_from_dataframe(\n#             dataframe=validdf,\n#             directory=TRAIN_IMG_PATH,\n#             x_col='img_file',\n#             y_col='class',\n#             target_size= (IMAGE_SIZE, IMAGE_SIZE),\n#             color_mode='rgb',\n#             class_mode='categorical',\n#             batch_size=BATCH_SIZE,\n#             seed=SEED,\n#             shuffle=True\n#             )\n# \n#         model_name = model_path + str(j) + '_' + 'Xception' + '.hdf5'\n#         model_names.append(model_name)\n# \n#         model = get_model(BASE_MODEL, IMAGE_SIZE)\n# \n#         try:\n#             model.load_weights(model_name)\n#         except:\n#             pass\n# \n#         history = model.fit_generator(\n#             train_generator,\n#             steps_per_epoch=len(traindf.index) \/ BATCH_SIZE,\n#             epochs=EPOCHS,\n#             validation_data=valid_generator,\n#             validation_steps=len(validdf.index) \/ BATCH_SIZE,\n#             verbose=1,\n#             shuffle=False,\n#             callbacks = get_callback(model_name, PATIENCE)\n#             )\n#         j+=1\n#         gc.collect()","cbe4cc18":"train_generator = train_datagen.flow_from_dataframe(\n            dataframe=df_train,\n            directory=TRAIN_IMG_PATH,\n            x_col='img_file',\n            y_col='class',\n            target_size= (IMAGE_SIZE, IMAGE_SIZE),\n            color_mode='rgb',\n            class_mode='categorical',\n            batch_size=BATCH_SIZE,\n            seed=SEED,\n            shuffle=True\n            )\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=df_test,\n    directory=TEST_IMG_PATH,\n    x_col='img_file',\n    y_col=None,\n    target_size= (IMAGE_SIZE, IMAGE_SIZE),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","20d962b1":"tmp_list = os.listdir(\"..\/input\/3rd-comp-car-img\")\ntmp_list.sort()","d8268ba4":"model_names = tmp_list[:5]","a0d2b2e6":"prediction = []\nfor i, name in enumerate(model_names):\n    model = get_model(BASE_MODEL, IMAGE_SIZE)\n    model.load_weights(\"..\/input\/3rd-comp-car-img\/\"+name)\n    \n    preds = []\n    for j in range(TTA_STEPS):\n        test_generator.reset()\n        pred = model.predict_generator(\n            generator=test_generator,\n            steps = len(df_test)\/BATCH_SIZE,\n            verbose=1\n        )\n        preds.append(pred)\n    pred_tta = np.mean(preds, axis=0)\n    prediction.append(pred_tta)\n\ny_pred = np.mean(prediction, axis=0)","ee2a50e9":"y_pred","190ee583":"preds_class_indices=np.argmax(y_pred, axis=1)\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nfinal_pred = [labels[k] for k in preds_class_indices]\nsubmission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\nsubmission[\"class\"] = final_pred\nsubmission.to_csv(\"xception_folds_avg.csv\", index=False)\nsubmission.head()","c149ac80":"## \ubd84\uc11d \ud30c\ub77c\ubbf8\ud130 \uc124\uc815","bae5c064":"## \uce35\ud654 \ud3f4\ub4dc \uc124\uc815","85d018c6":"## \uc774\ubbf8\uc9c0 \uc81c\ub108\ub808\uc774\ud130 \uc0dd\uc131","4c806acd":"## Metric \ud568\uc218 \uc815\uc758","5ec42308":"## \ucf5c\ubc31 \ud568\uc218 \uc815\uc758","e4a911c7":"## \uc608\uce21 \uacb0\uacfc \ud655\uc778 \ubc0f \uc81c\ucd9c \ud30c\uc77c \uc0dd\uc131","bbaad39b":"## \uc804\uc774\ud559\uc2b5\uc744 \uc704\ud55c \ubaa8\ub378 \uc0dd\uc131 \ud568\uc218","da66e569":"## \uc774\ubbf8\uc9c0 \uc81c\ub108\ub808\uc774\ud130 \uc124\uc815(data augmentation)","30c692ac":"    \uace0\uc218\ubd84\ub4e4\uc758 \ucee4\ub110 \uacf5\uc720 \uac10\uc0ac\ud569\ub2c8\ub2e4.\n    3\ucc28 \ub300\ud68c\ub97c \ud1b5\ud574 \ub525\ub7ec\ub2dd\uc744 \ud65c\uc6a9\ud55c \uc774\ubbf8\uc9c0 \ubd84\ub958\uc640 \uad00\ub828\ud55c \ub9ce\uc740 \ubc30\uc6c0\uc744 \uc5bb\uc5b4\uac11\ub2c8\ub2e4.\n    1. \ucf00\ub77c\uc2a4 \ud504\ub808\uc784\uc6cc\ud06c\uc5d0 \ub300\ud55c \uc774\ud574\n    2. \uc774\ubbf8\uc9c0 \uc81c\ub108\ub808\uc774\ud130\n    3. \uae30 \ubaa8\ub378\uc744 \ud65c\uc6a9\ud55c \uc804\uc774\ud559\uc2b5\n    4. \ucf5c\ubc31\ud568\uc218\ub97c \ud65c\uc6a9\ud55c \ud559\uc2b5\n    5. \uc815\ud655\ub3c4\ub97c \uc62c\ub9ac\uae30 \uc704\ud55c \ubc29\ubc95\n        5-1. \uce35\ud654 \ud3f4\ub4dc\n        5-2. \ud3f4\ub4dc \ubaa8\ub378\uc744 \ud1b5\ud55c \uc559\uc0c1\ube14\n        5-2. TTA","60edca31":"## \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30","13699477":"## TTA","922d2493":"## \ubaa8\ub378 \ud6c8\ub828 \uc2dc\uc791\n    1~5\ubc88 \ud3f4\ub4dc\ub85c \ub098\ub204\uc5b4 \ud6c8\ub828\uc744 \uc9c4\ud589\ud558\ub294 \ubd80\ubd84\uc785\ub2c8\u3163\ub2e4.\n    \uce90\uae00\uc774\ub098 \ub85c\uceec\uc5d0\uc11c \uc2e4\ud589\ud574\ub3c4 3\ubc88\uc9f8 \ud3f4\ub4dc\uae4c\uc9c0\ub9cc \ud55c \ubc88\uc5d0 \ub3cc\uc544\uac00\uc11c\n    1~3\ubc88\/4~5\ubc88\uc73c\ub85c \ub098\ub204\uc5b4 \ud6c8\ub828\uc2dc\ud0a8 \ud754\uc801\uc774 \ub0a8\uc544\uc788\uc2b5\ub2c8\ub2e4.\n    \ud574\ub2f9 \ucf54\ub4dc\ub294 4~5\ubc88 \ucf54\ub4dc"}}