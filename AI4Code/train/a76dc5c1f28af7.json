{"cell_type":{"efc9fa49":"code","0fc5e28a":"code","cc56186c":"code","4a8d4e3e":"code","82a574d5":"code","44eb7d9f":"code","99ffce78":"code","64716190":"code","0986f58a":"code","cab66274":"code","e472e010":"code","d521d9b0":"code","e1895c7e":"markdown","5cdd0b34":"markdown","274ab3d6":"markdown","d10aae96":"markdown"},"source":{"efc9fa49":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom catboost import CatBoostRegressor  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom datetime import datetime\n\n%matplotlib inline","0fc5e28a":"data = pd.read_csv('\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv')\ndata.head().T","cc56186c":"def data_stats_table(data, data_example=True, nlargest_num=1, stats_describe=True):\n    data_stats = pd.DataFrame()\n\n    if data_example:  \n        data_stats['data[0]'] = data.loc[0, :].T\n\n    data_stats['dtypes'] = data.dtypes  \n    data_stats.loc['rows_count', 'dtypes'] = len(data.dtypes)\n    data_stats['dupl'] = int(data.duplicated().sum())\n\n    data_stats['NaNs'] = data.isnull().sum()  \n    data_stats.loc['rows_count', 'NaNs'] = (\n        data.isnull().sum(axis=1) != 0).sum()\n    data_stats['NaNs'] = data_stats['NaNs'].astype('int')\n\n    for name in data.columns:\n        data_stats.loc[name, 'unique'] = data[name].nunique()\n        top_freq = round(data[name].value_counts(\n            normalize=True).nlargest(nlargest_num), 2)\n        data_stats.loc[name, 'top_freq'] = json.dumps(list(top_freq))\n        data_stats.loc[name, 'top_freq_value'] = json.dumps(\n            list(top_freq.index))\n\n    if stats_describe:  \n        df_des = round(data.describe().T.drop(columns=['count']), 2)\n        data_stats = pd.concat([data_stats, df_des], axis=1, sort=False)\n    data_stats.fillna(\"\", inplace=True)\n    return data_stats\n\ndata_stats_table(data)","4a8d4e3e":"def weird_division(n, d):\n    return n \/ d if d else 0\n\ndata['CPM'] = data.apply(lambda x: 1000*weird_division(x['total_revenue']*100, x['measurable_impressions']), axis=1)\ndata = data[data['CPM'] >= 0]\n\ndata.drop(columns = ['integration_type_id' , 'revenue_share_percent', 'total_revenue'], inplace=True)\ndata_cols = data.columns\n\ndata['date'] = pd.to_datetime(data['date'])\ndata[\"sample\"] = (data['date'] < pd.to_datetime('22.06.2019')).astype(\"int\")","82a574d5":"sns.set(font_scale=1)\nplt.subplots(figsize=(17, 10))\nsns.heatmap(data.corr(), square=True, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1, center=0, \n           linewidths=1, linecolor='white',  mask = np.tril(data.corr()));","44eb7d9f":"def plot_train_test_hist(data_, col_names, col_number=2, figsize_=(18, 8), bins_=10):\n    fig, axes_ = plt.subplots(-(-len(col_names)\/\/col_number),\n                              col_number, figsize=figsize_)\n\n    for counter_ in range(len(col_names)):\n        pic_row_ = counter_\/\/col_number\n        pic_col_ = counter_ % col_number\n        axes_[pic_row_, pic_col_].hist(data_[col_names[counter_]], rwidth=0.95,\n                                       alpha=0, color='green', bins=bins_, density = True)\n        \n        axes_[pic_row_, pic_col_].hist(data_[data_['sample'] == 1][col_names[counter_]], rwidth=0.95,\n                                       alpha=0.65, label='learn_data', color='red', bins=bins_, density = True)\n\n        axes_[pic_row_, pic_col_].hist(data_[data_['sample'] == 0][col_names[counter_]], rwidth=0.95,\n                                       alpha=0.65, label='predict_data', color='blue', bins=bins_, density = True)\n\n        axes_[pic_row_, pic_col_].set_title(col_names[counter_])\n        axes_[pic_row_, pic_col_].legend(loc=1)\n\nplot_train_test_hist(data, data_cols, col_number=4, figsize_=(16, 16), bins_=20)","99ffce78":"num_logs = [\"total_impressions\", \"viewable_impressions\", \"measurable_impressions\", \"CPM\"]\nfor item in num_logs:\n    data[item] = data[item].apply(lambda x: np.log(x+1))","64716190":"sns.set(font_scale=1)\nplt.subplots(figsize=(17, 10))\nsns.heatmap(data.corr(), square=True, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1, center=0, \n           linewidths=1, linecolor='white',  mask = np.tril(data.corr()));","0986f58a":"plot_train_test_hist(data, data_cols, col_number=4, figsize_=(16, 16), bins_=20)","cab66274":"data_train = data[data['date'] < pd.to_datetime('22.06.2019')]\ndata_train = data_train[data_train[\"CPM\"] < data_train[\"CPM\"].quantile(0.95)]\ndata_train = data_train.drop_duplicates()\n\ndata_test = data[data['date'] >= pd.to_datetime('22.06.2019')]\ndata_test = data_test[data_test[\"CPM\"] < data_test[\"CPM\"].quantile(0.95)]\n\n\ntrain_cols = ['site_id', 'ad_type_id', 'geo_id', 'device_category_id', 'advertiser_id', 'order_id', \n              'line_item_type_id', 'os_id', 'monetization_channel_id', 'ad_unit_id', \n              'total_impressions', 'viewable_impressions', 'measurable_impressions']\n\nX_train = data_train[train_cols]\ny_train = data_train[\"CPM\"]\n\nX_test = data_test[train_cols]\ny_test = data_test[\"CPM\"]","e472e010":"def log_y_mse_metrics(y, y_pred):\n    return metrics.mean_squared_error(np.exp(y) - 1, np.exp(y_pred) - 1)","d521d9b0":"%%time\ncatb_params = {\n    'random_seed': 0, \n    'learning_rate': 0.5,\n    'iterations': 1000, \n    'depth': 6, \n    'l2_leaf_reg': 10, \n    'subsample' : 0.75, \n    'random_strength': 0.06, \n    'od_type': \"Iter\", \n    'od_wait': 100, \n    'verbose': False, \n}\ncat_features = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nctb_model = CatBoostRegressor(**catb_params)\nctb_model.fit(X_train, y_train, cat_features = cat_features) \n\ny_pred_test = ctb_model.predict(X_test)\nprint(log_y_mse_metrics(y_test, y_pred_test))","e1895c7e":"# Data descriptive analysis and Preprocessing","5cdd0b34":"# Taking the logarithm of features and CPM","274ab3d6":"# CatBoostRegressor Model for CPM","d10aae96":"# Train\/test split"}}