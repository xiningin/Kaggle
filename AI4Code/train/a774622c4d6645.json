{"cell_type":{"6aa22b0a":"code","66391316":"code","ac88dee0":"code","9b2c305a":"code","dce54276":"code","03567a6f":"code","dc36dec4":"code","33487be9":"code","a9056401":"code","3b0ee69b":"code","269f9422":"code","f747d012":"code","21c00dc5":"code","8d40276c":"code","2a2e022e":"code","e89e91d5":"code","72c7941c":"code","27de6041":"code","ce743dc8":"code","926a1835":"code","bc083de4":"code","d10f7b9d":"code","a6d4f5cd":"code","a52a363d":"code","ecaaeec3":"code","446f3b51":"code","6c4bf870":"code","b9b4b270":"code","c265df2b":"code","3f657798":"code","8cfa0bd1":"code","7bb47269":"code","3fa36d34":"code","f270ca2a":"code","4918c877":"code","1543fd8a":"code","d43f6f3c":"code","8c99eba3":"code","12b753e2":"code","eccdc934":"code","ab234a0f":"code","804c382c":"code","8dc3a9ff":"code","8708b198":"code","2c53b852":"code","875c5b24":"code","44f9ae45":"code","282b0362":"code","9f6301d5":"code","bf1d8427":"code","4fb6e986":"code","075e0e8a":"code","88e001b4":"code","70756573":"code","73f80f64":"code","796906a3":"code","0f00da40":"code","f5600cdc":"code","ccee8c39":"code","615ed1b7":"code","0e46faf4":"code","17cfaacf":"code","267f9438":"code","5e33dfa0":"code","9a09be68":"code","9994201f":"code","e78652f9":"code","fe99f4c5":"code","3f84d80e":"code","99387345":"code","28c1d323":"code","35356841":"code","61c0fabc":"code","c41880bc":"code","6ee4e687":"code","58191fda":"code","0ee7fd80":"code","8507abfa":"code","c0414cec":"code","1e3967e8":"code","14d1f33b":"code","35ba0b6d":"code","3a63caa9":"code","a7e880de":"code","330d6a3d":"code","ffb7cb66":"code","6e15c679":"code","eacda5f5":"code","ec8dce9a":"code","e48e022a":"code","a3362e57":"code","a5ecf78f":"code","2bcf3323":"code","6b301719":"code","682ab093":"code","96d33177":"code","b4649f6a":"code","c26d2c26":"code","413c829c":"code","750736b3":"code","a1e48b6c":"code","896fc2c2":"code","250ab2ce":"code","0b55b647":"code","28099c64":"code","810b32e7":"code","d7503b06":"code","15ddd84e":"code","b41f8fae":"code","691db193":"code","65ade777":"code","a8872c7b":"code","5c1e401a":"code","0516edfc":"markdown","29b8daec":"markdown","d66f090f":"markdown","617dc120":"markdown","9072cf19":"markdown","74b8fc6e":"markdown","e84dff5c":"markdown","6bea2c2d":"markdown","8371da6d":"markdown","b0ef1641":"markdown","74deab19":"markdown","7cfc37f7":"markdown","19070ade":"markdown","f416c230":"markdown","b1b428de":"markdown","99652e7f":"markdown","35372397":"markdown","1c6b38ad":"markdown","b80c310e":"markdown","4afa12e3":"markdown","113d8081":"markdown","c6f67143":"markdown","c760a9e2":"markdown","051b4bad":"markdown","00d6c439":"markdown","aabc404e":"markdown","8e4c0d3f":"markdown","a6fa5fff":"markdown","3cb7b2c7":"markdown","971f9612":"markdown","cff07c6a":"markdown","766657d4":"markdown","9e4619eb":"markdown","f15e2451":"markdown","bf593696":"markdown","db292bfd":"markdown","bf24ab75":"markdown","9fc66418":"markdown","d4cb997a":"markdown","b4ab0e97":"markdown","e2f8fe85":"markdown","d4a87dd5":"markdown","213fc2de":"markdown","5fbfd6de":"markdown","c7eb5b5b":"markdown","d4c18bf0":"markdown","4440d11d":"markdown","5bee786b":"markdown","59dc382e":"markdown","eedb5c50":"markdown"},"source":{"6aa22b0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport os\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","66391316":"#data = pd.read_csv('\/kaggle\/input\/pokemon.csv')\n#data.head()","ac88dee0":"data = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()","9b2c305a":"data.info()","dce54276":"data.corr()","03567a6f":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","dc36dec4":"data.head(10)","33487be9":"data.columns","a9056401":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","3b0ee69b":"# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defence')\nplt.title('Attack Defense Scatter Plot')            # title = title of plot","269f9422":"# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (12,12))\nplt.show()","f747d012":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","21c00dc5":"#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","8d40276c":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)\n","2a2e022e":"# In order to run all code you need to take comment this line\n#del dictionary         # delete entire dictionary     \nprint(dictionary)       # it gives error because dictionary is deleted","e89e91d5":"data = pd.read_csv('..\/input\/pokemon.csv')\n","72c7941c":"series = data['Defense']        # data['Defense'] = series\nprint(type(series))\ndata_frame = data[['Defense']]  # data[['Defense']] = data frame\nprint(type(data_frame))\n","27de6041":"# Comparison operator\nprint(3 > 2)\nprint(3!=2)\n# Boolean operators\nprint(True and False)\nprint(True or False)","ce743dc8":"# 1 - Filtering Pandas data frame\nx = data['Defense']>200     # There are only 3 pokemons who have higher defense value than 200\ndata[x]","926a1835":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['Defense']>200, data['Attack']>100 )]","bc083de4":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Defense']>200) & (data['Attack']>100)]","d10f7b9d":"# Stay in loop if condition( i is not equal 5) is true\ni = 0\nwhile i != 5 :\n    print('i is: ',i)\n    i +=1\nprint(i,' is equal to 5')","a6d4f5cd":"# Stay in loop if condition( i is not equal 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index,value in data[['Attack']][0:1].iterrows():\n    print(index,\" : \",value)\n\n","a52a363d":"# example of what we learn above\ndef tuple_ex():\n    \"\"\" return defined t tuple\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuple_ex()\nprint(a,b,c)","ecaaeec3":"# guess prints what\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x)      # x = 2 global scope\nprint(f())    # x = 3 local scope","446f3b51":"# What if there is no local scope\nx = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x  \n# First local scope searched, then global scope searched, if two of them cannot be found lastly built in scope searched.","6c4bf870":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","b9b4b270":"#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())    ","c265df2b":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","3f657798":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():               # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456)","8cfa0bd1":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(4))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))","7bb47269":"number_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","3fa36d34":"# iteration example\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(*it)         # print remaining iteration\n","f270ca2a":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)","4918c877":"un_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuple\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))","1543fd8a":"# Example of list comprehension\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)","d43f6f3c":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","8c99eba3":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed)\/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later","12b753e2":"data = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()  # head shows first 5 rows","eccdc934":"# tail shows last 5 rows\ndata.tail()","ab234a0f":"# columns gives column names of features\ndata.columns","804c382c":"# shape gives number of rows and columns in a tuble\ndata.shape","8dc3a9ff":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","8708b198":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","2c53b852":"1,2,3,4,200","875c5b24":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","44f9ae45":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","282b0362":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","9f6301d5":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","bf1d8427":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","4fb6e986":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","075e0e8a":"data1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col","88e001b4":"data.dtypes","70756573":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","73f80f64":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","796906a3":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","0f00da40":"# Lets chech Type 2\ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","f5600cdc":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","ccee8c39":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","615ed1b7":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","0e46faf4":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","17cfaacf":"data[\"Type 2\"].fillna('empty',inplace = True)\n","267f9438":"assert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values","5e33dfa0":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","9a09be68":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","9994201f":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","e78652f9":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","fe99f4c5":"# Plotting all data \ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\n# it is confusing","3f84d80e":"# subplots\ndata1.plot(subplots = True)\nplt.show()","99387345":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","28c1d323":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True)","35356841":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","61c0fabc":"data.describe()","c41880bc":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","6ee4e687":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","58191fda":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","0ee7fd80":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","8507abfa":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","c0414cec":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","1e3967e8":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","14d1f33b":"# read data\ndata = pd.read_csv('..\/input\/pokemon.csv')\ndata= data.set_index(\"#\")\ndata.head()","35ba0b6d":"# indexing using square brackets\ndata[\"HP\"][1]","3a63caa9":"# using column attribute and row label\ndata.HP[1]","a7e880de":"# using loc accessor\ndata.loc[1,[\"HP\"]]","330d6a3d":"# Selecting only some columns\ndata[[\"HP\",\"Attack\"]]","ffb7cb66":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","6e15c679":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive","eacda5f5":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"] ","ec8dce9a":"# From something to end\ndata.loc[1:10,\"Speed\":] ","e48e022a":"# Creating boolean series\nboolean = data.HP > 200\ndata[boolean]","a3362e57":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter]","a5ecf78f":"# Filtering column based others\ndata.HP[data.Speed<15]","2bcf3323":"# Plain python functions\ndef div(n):\n    return n\/2\ndata.HP.apply(div)","6b301719":"# Or we can use lambda function\ndata.HP.apply(lambda n : n\/2)","682ab093":"# Defining column using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","96d33177":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","b4649f6a":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()","c26d2c26":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","413c829c":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","750736b3":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","a1e48b6c":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","896fc2c2":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","250ab2ce":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","0b55b647":"# level determines indexes\ndf1.unstack(level=0)","28099c64":"df1.unstack(level=1)","810b32e7":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","d7503b06":"df","15ddd84e":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","b41f8fae":"# We will use df\ndf","691db193":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","65ade777":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","a8872c7b":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","5c1e401a":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()\n","0516edfc":"<a id=\"28\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","29b8daec":"<a id=\"15\"><\/a> <br>\n### LIST COMPREHENS\u0130ON\n**One of the most important topic of this kernel**\n<br>We use list comprehension for data analysis often. \n<br> list comprehension: collapse for loops for building lists into a single line\n<br>Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is  unnecessarily long. We can make it one line code that is list comprehension.","d66f090f":"<a id=\"14\"><\/a> <br>\n### ITERATORS\n* iterable is an object that can return an iterator\n* iterable: an object with an associated iter() method\n<br> example: list, strings and dictionaries\n* iterator: produces next value with next() method","617dc120":"<a id=\"7\"><\/a> <br>\n# 2. PYTHON DATA SCIENCE TOOLBOX","9072cf19":"<a id=\"41\"><\/a> <br>\n### MELTING DATA FRAMES\n* Reverse of pivoting","74b8fc6e":"**WARNING - UYARI**\n* If you run the code above, if it outputs like in the picture, you need to put the \".csv\" path in pd.read_csv () (as in the picture).\n* Yukar\u0131daki kod blo\u011funu run edince sonu\u00e7 ne veriyorsa read_csv i\u00e7erisine onu yazman\u0131z gerekli.\n* Mesela, e\u011fer yukar\u0131 bulunan kodu \u00e7al\u0131\u015ft\u0131rd\u0131\u011f\u0131n\u0131zda, resimdeki gibi bir output veriyorsa pd.read_csv() i\u00e7erisine resimdeki \".csv\" yolunu koyman\u0131z gerekli (resimde oldu\u011fu gibi). Yukar\u0131da kod blo\u011funu run edince ne \u00e7\u0131k\u0131yorsa onu yazman\u0131z laz\u0131m mesela a\u015fa\u011f\u0131daki gibi.\n<a href=\"https:\/\/ibb.co\/Hg0QX2h\"><img src=\"https:\/\/i.ibb.co\/ZT3CNJ2\/sil.png\" alt=\"sil\" border=\"0\"><\/a>\n* read_csv i\u00e7erisine yukar\u0131da \u00e7\u0131kan .csv dosyalar\u0131 yaz\u0131lmal\u0131.","e84dff5c":"<a id=\"31\"><\/a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html\n","6bea2c2d":"<a id=\"6\"><\/a> <br>\n### WHILE and FOR LOOPS\nWe will learn the most basic while and for loops","8371da6d":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","b0ef1641":"* # DATA SCIENTIST\n**In this tutorial, I only explain you what you need to be a data scientist neither more nor less.**\n\n**Bu yaz\u0131da, size sadece bir veri bilimcisi olmak i\u00e7in neye ihtiyac\u0131n\u0131z oldu\u011funu a\u00e7\u0131klayaca\u011f\u0131m, ne fazla ne de az.**\n\nData scientist need to have these skills:\nVeri bilimcilerinin bu becerilere sahip olmas\u0131 gerekir\n\n1. Basic Tools: Like python, R or SQL. You do not need to know everything. What you only need is to learn how to use **python** \nTemel Ara\u00e7lar: python, R veya SQL gibi. Her \u015feyi bilmenize gerek yok. Tek ihtiyac\u0131n\u0131z olan \u015fey nas\u0131l kullan\u0131laca\u011f\u0131n\u0131 \u00f6\u011frenmek\n1. Basic Statistics: Like mean, median or standart deviation. If you know basic statistics, you can use **python** easily.\nTemel \u0130statistikler: Ortalama, medyan veya standart sapma gibi. Temel istatistikleri biliyorsan\u0131z, ** python ** 'u kolayca kullanabilirsiniz.\n1. Data Munging: Working with messy and difficult data. Like a inconsistent date and string formatting. As you guess, **python** helps us.\nVeri Birle\u015ftirme: Da\u011f\u0131n\u0131k ve zor verilerle \u00e7al\u0131\u015fma. Tutars\u0131z bir tarih ve dize bi\u00e7imlendirmesi gibi. Tahmin edebilece\u011finiz gibi, ** python ** bize yard\u0131mc\u0131 oluyor.\n1. Data Visualization: Title is actually explanatory. We will visualize the data with **python** like matplot and seaborn libraries.\nVeri G\u00f6rselle\u015ftirme: Ba\u015fl\u0131k asl\u0131nda a\u00e7\u0131klay\u0131c\u0131d\u0131r. Verileri matplot ve seaborn kitapl\u0131klar\u0131 gibi ** python ** ile g\u00f6rselle\u015ftirece\u011fiz.\n1. Machine Learning: You do not need to understand math behind the machine learning technique. You only need is understanding basics of machine learning and learning how to implement it while using **python**.\nMakine \u00d6\u011frenimi: Makine \u00f6\u011frenimi tekni\u011finin ard\u0131ndaki matemati\u011fi anlaman\u0131za gerek yoktur. Tek ihtiyac\u0131n\u0131z olan makine \u00f6\u011freniminin temellerini anlamak ve ** python ** kullan\u0131rken bunu nas\u0131l uygulayaca\u011f\u0131n\u0131z\u0131 \u00f6\u011frenmektir.\n\n### As a summary we will learn python to be data scientist !!!\n### \u00d6zet olarak python'u veri bilimci olmak i\u00e7in \u00f6\u011frenece\u011fiz !!!\n\n**Content:**\n1. [Introduction to Python:](#1)(Pythona giri\u015fi)\n    1. [Matplotlib](#2) (Matplotlib)\n    1. [Dictionaries ](#3) (S\u00f6zl\u00fckler)\n    1. [Pandas](#4) (Bildi\u011fimiz Pandas :D = Bu arada pandanlar\u0131 sevelim,koruyal\u0131m)\n    1. [Logic, control flow and filtering](#5) (Mant\u0131k , kontrol ak\u0131\u015f\u0131 ve filtreleme) \n    1. [Loop data structures](#6) (D\u00f6ng\u00fc veri yap\u0131lar\u0131)\n1. [Python Data Science Toolbox:](#7) (Python Veri Bilimi Ara\u00e7 Kutusu)\n    1. [User defined function](#8) (Kullan\u0131c\u0131 tan\u0131ml\u0131 i\u015flev)\n    1. [Scope](#9) (KAPSAM)\n    1. [Nested function](#10) (\u0130\u00e7 i\u00e7e ge\u00e7mi\u015f fonksiyon)\n    1. [Default and flexible arguments](#11) (Varsay\u0131lan ve esnek arg\u00fcmanlar)\n    1. [Lambda function](#12) (Lamda fonksiyonu)\n    1. [Anonymous function](#13) (Anonim fonksiyonu)\n    1. [Iterators](#14) (Yineleyiciler)\n    1. [List comprehension](#15) (Listeyi Anlama)\n1. [Cleaning Data](#16) (Veri Temizleme)\n    1. [Diagnose data for cleaning](#17) (Temizlik i\u00e7in verileri tan\u0131lay\u0131n)\n    1. [Exploratory data analysis](#18) (Ke\u015fif veri analizi)\n    1. [Visual exploratory data analysis](#19) (G\u00f6rsel ke\u015fif veri analizi)\n    1. [Tidy data](#20) (D\u00fczenli veriler)\n    1. [Pivoting data](#21) (\u00d6zet verileri)\n    1. [Concatenating data](#22) (Verileri birle\u015ftirme)\n    1. [Data types](#23) (Veri Tipleri)\n    1. [Missing data and testing with assert](#24) (Eksik veriler ve assert ile test)\n1. [Pandas Foundation](#25) (Pandasa Giri\u015f :D )\n    1. [Review of pandas](#26) (Pandalara g\u00f6z gezdirelim )\n    1. [Building data frames from scratch](#27) (Veri \u00e7er\u00e7evelerini s\u0131f\u0131rdan olu\u015fturma)\n    1. [Visual exploratory data analysis](#28) (G\u00f6rsel ke\u015fif veri analizi)\n    1. [Statistical explatory data analysis](#29) (\u0130statistiksel a\u00e7\u0131klay\u0131c\u0131 veri analizi)\n    1. [Indexing pandas time series](#30) (Pandalar zaman serilerini indeksleme)\n    1. [Resampling pandas time series](#31) ( Pandalar zaman serilerini yeniden \u00f6rnekleme)\n1. [Manipulating Data Frames with Pandas](#32) (Veri \u00c7er\u00e7evelerini Pandalarla D\u00fczenleme)\n    1. [Indexing data frames](#33) (Veri \u00e7er\u00e7evelerini indeksleme)\n    1. [Slicing data frames](#34) (Veri \u00e7er\u00e7evelerini dilimleme)\n    1. [Filtering data frames](#35) (Veri \u00e7er\u00e7evelerini filtreleme)\n    1. [Transforming data frames](#36) (Veri \u00e7er\u00e7evelerini d\u00f6n\u00fc\u015ft\u00fcrme)\n    1. [Index objects and labeled data](#37) (Nesneleri ve etiketli verileri indeksle)\n    1. [Hierarchical indexing](#38) (Hiyerar\u015fik indeksleme)\n    1. [Pivoting data frames](#39) (Veri \u00e7er\u00e7evelerini d\u00f6nd\u00fcrme)\n    1. [Stacking and unstacking data frames](#40) (Veri \u00e7er\u00e7evelerini y\u0131\u011f\u0131nlama ve ay\u0131rma)\n    1. [Melting data frames](#41) (Veri \u00e7er\u00e7evelerini eritme)\n    1. [Categoricals and groupby](#42) (Categoricals and groupby)\n","74deab19":"<a id=\"12\"><\/a> <br>\n### LAMBDA FUNCTION\nFaster way of writing function","7cfc37f7":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","19070ade":"<a id=\"27\"><\/a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","f416c230":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing","b1b428de":"<a id=\"26\"><\/a> <br>\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","99652e7f":"<a id=\"13\"><\/a> <br>\n### ANONYMOUS FUNCT\u0130ON\nLike lambda function but it can take more than one arguments.\n* map(func,seq) : applies a function to all the items in a list\n","35372397":"<a id=\"32\"><\/a> <br>\n# MANIPULATING DATA FRAMES WITH PANDAS","1c6b38ad":"[](http:\/\/)Up to now, you learn \n* User defined function \n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n*  Anonymous function\n*  Iterators\n* List comprehension\n","b80c310e":"<a id=\"39\"><\/a> <br>\n### PIVOTING DATA FRAMES\n* pivoting: reshape tool","4afa12e3":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","113d8081":"<a id=\"8\"><\/a> <br>\n### USER DEFINED FUNCTION\nWhat do we need to know about functions:\n* docstrings: documentation for functions. Example:\n<br>for f():\n    <br>\"\"\"This is docstring for documentation of function f\"\"\"\n* tuple: sequence of immutable python objects. \n<br>cant modify values\n<br>tuple uses paranthesis like tuble = (1,2,3)\n<br>unpack tuple into several variables like a,b,c = tuple\n    ","c6f67143":"<a id=\"9\"><\/a> <br>\n### SCOPE\nWhat we need to know about scope:\n* global: defined main body in script\n* local: defined in a function\n* built in scope: names in predefined built in scope module such as print, len\n<br><br>Lets make some basic examples","c760a9e2":"zip(): zip lists","051b4bad":"<a id=\"22\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe ","00d6c439":"<a id=\"34\"><\/a> <br>\n### SLICING DATA FRAME\n* Difference between selecting columns\n    * Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end","aabc404e":"<a id=\"1\"><\/a> <br>\n# 1. INTRODUCTION TO PYTHON","8e4c0d3f":"<a id=\"40\"><\/a> <br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","a6fa5fff":"<a id=\"5\"><\/a> <br>\nBefore continuing with pandas,   we need to learn **logic, control flow** and **filtering.**\n<br>Comparison operator:  ==, <, >, <=\n<br>Boolean operators: and, or ,not\n<br> Filtering pandas","3cb7b2c7":"In this part, you learn:\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","971f9612":"<a id=\"36\"><\/a> <br>\n### TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","cff07c6a":"<a id=\"21\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","766657d4":"<a id=\"30\"><\/a> <br>\n### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","9e4619eb":"# CONCLUSION\nThank you for your votes and comments\n<br> **MACHINE LEARNING ** https:\/\/www.kaggle.com\/kanncaa1\/machine-learning-tutorial-for-beginners\/\n<br> **DEEP LEARNING** https:\/\/www.kaggle.com\/kanncaa1\/deep-learning-tutorial-for-beginners\n<br> **STATISTICAL LEARNING** https:\/\/www.kaggle.com\/kanncaa1\/statistical-learning-tutorial-for-beginners\n<br>**If you have any question or suggest, I will be happy to hear it.**","f15e2451":"<a id=\"3\"><\/a> <br>\n### DICTIONARY\nWhy do we need dictionary?\n* It has 'key' and 'value'\n* Faster than lists\n<br>\nWhat is key and value. Example:\n* dictionary = {'spain' : 'madrid'}\n* Key is spain.\n* Values is madrid.\n<br>\n<br>**It's that easy.**\n<br>Lets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary.","bf593696":"<a id=\"16\"><\/a> <br>\n# 3.CLEANING DATA","db292bfd":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","bf24ab75":"<a id=\"10\"><\/a> <br>\n### NESTED FUNCTION\n* function inside function.\n* There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively.","9fc66418":"<a id=\"37\"><\/a> <br>\n### INDEX OBJECTS AND LABELED DATA\nindex: sequence of label\n","d4cb997a":"<a id=\"20\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it.\n","b4ab0e97":"<a id=\"2\"><\/a> <br>\n### MATPLOTLIB\nMatplot is a python library that help us to plot data. The easiest and most basic plots are line, scatter and histogram plots.\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle  ","e2f8fe85":"<a id=\"4\"><\/a> <br>\n### PANDAS\nWhat do we need to know about pandas?\n* CSV: comma - separated values\n\n","d4a87dd5":"<a id=\"11\"><\/a> <br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n* Default argument example:\n<br> def f(a, b=1):\n        \"\"\" b = 1 is default argument\"\"\"\n* Flexible argument example:\n<br> def f(*args):\n       \"\"\" *args can be one or more\"\"\"\n<br>def f(** kwargs)\n       \"\"\" **kwargs is a dictionary\"\"\"\n       \n<br><br> lets write some code to practice  ","213fc2de":"[i + 1 for i in num1 ]: list of comprehension\n<br> i +1: list comprehension syntax\n<br> for i in num1: for loop syntax\n<br> i: iterator\n<br> num1: iterable object","5fbfd6de":"<a id=\"29\"><\/a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","c7eb5b5b":"<a id=\"25\"><\/a> <br>\n# 4. PANDAS FOUNDATION ","d4c18bf0":"<a id=\"23\"><\/a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),boolean, integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklearn(we will learn later)","4440d11d":"<a id=\"33\"><\/a> <br>\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","5bee786b":"In this part, you learn:\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always used and main for being data scientist\n* While and for loops","59dc382e":"<a id=\"17\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data\n","eedb5c50":"<a id=\"35\"><\/a> <br>\n### FILTERING DATA FRAMES\nCreating boolean series\nCombining filters\nFiltering column based others"}}