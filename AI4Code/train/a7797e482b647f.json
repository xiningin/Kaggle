{"cell_type":{"1aa5d660":"code","5409f5b4":"code","0e17129b":"code","3e39c28d":"code","62921f1e":"code","834711ba":"code","882694c3":"code","b4113ac6":"code","0ed3415a":"code","9cf9d0b5":"code","e8af57d5":"code","e386d5aa":"code","d54021e6":"code","5cfbb422":"code","51dfcc16":"code","43da3875":"code","7db46c15":"code","f151d1eb":"code","a436208a":"code","18ab2d75":"code","59b48cc0":"code","1365dd65":"code","896ad4c3":"code","1cf28d31":"code","a7d52892":"code","c0cf5d0c":"code","41579bd5":"code","2352ea00":"code","7691db01":"code","c7253ab7":"code","0ba4efa9":"code","27915ad9":"code","631e84b4":"code","b3712919":"code","0c826fba":"code","fd24b14e":"code","f02a472a":"code","e42a83bc":"code","351b5293":"code","eee6d405":"code","3579ae3f":"code","af413bd3":"code","8aa77740":"code","2ea4acd5":"code","dbccee9f":"markdown","96a8c688":"markdown","1ef90f27":"markdown","6b75005a":"markdown","21a3b8b7":"markdown","8dbed40a":"markdown","16c33f77":"markdown","3f331c7c":"markdown","8f82d66f":"markdown","3cdf72f3":"markdown","db259e81":"markdown","027b9d55":"markdown","94f13355":"markdown","b06702cd":"markdown","94e7ed3b":"markdown","576379d7":"markdown","0275636a":"markdown","c632324c":"markdown","d1f0581d":"markdown","4ce2b73d":"markdown","2c5ab9b1":"markdown","9928f97c":"markdown","b524d7f0":"markdown","30ad1b0d":"markdown","7110a4cd":"markdown","1d033120":"markdown","93b4060e":"markdown","ec8014ac":"markdown","5fcfc4ca":"markdown","4eec7d1a":"markdown","51e532a2":"markdown","37bc8c5c":"markdown","2c09a0e0":"markdown","6d0d9d36":"markdown","15e96009":"markdown"},"source":{"1aa5d660":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.linear_model import Ridge,RidgeCV\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.metrics import accuracy_score\nimport scipy\nfrom scipy import stats\nimport plotly\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nfrom sklearn.preprocessing import Binarizer\n\nRawdata = pd.read_csv('..\/input\/league-of-legends\/games.csv')\n\n# Any results you write to the current directory are saved as output.","5409f5b4":"df = pd.DataFrame(Rawdata)\ndf.sample(5)","0e17129b":"data = df[['gameDuration', 'winner', 'firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon'\n         , 'firstRiftHerald', 't1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't1_riftHeraldKills'\n         , 't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills', 't2_riftHeraldKills']]","3e39c28d":"def pltDuration(data):\n    plt.figure(figsize = (15, 10))\n    Duration_plot = plt.hist(data['gameDuration'], bins = 200)\n    my_x_ticks = np.arange(0, 4200, 300)\n    plt.xticks(my_x_ticks)\n    plt.xlabel(\"gameDuration (s)\", fontsize = 13)\n    plt.ylabel('Frequency', fontsize = 13)\n    plt.title('GameDuration Distribution', fontsize = 15)\n    plt.show()\npltDuration(data)","62921f1e":"data.info()","834711ba":"data = data[data['gameDuration'] >= 900]\ndata.info()\ndata.sample(5)","882694c3":"pltDuration(data)","b4113ac6":"n = data.count()\nTeam1_win = data[data['winner'] == 1].count()\nTeam2_win = data[data['winner'] == 2].count()\nTeam1_win_percent = Team1_win\/n * 100\nTeam2_win_percent = Team2_win\/n * 100\nT1 = Team1_win_percent['winner']\nT2 = Team2_win_percent['winner']\nplt.pie((T1,T2), labels = ('Team1 Win', 'Team2 Win'), startangle = 90, autopct='%.2f%%')\nplt.axis('equal')\nplt.title('Winning Rate for 2 Teams')\nplt.show()","0ed3415a":"data['winner'].replace(2,0,inplace=True)\ndata.describe()","9cf9d0b5":"true_mu = 0.5\nt_test = scipy.stats.ttest_1samp(data['winner'], true_mu)\nt_value = t_test[0]\np_value = t_test[1]\nprint(\"t value: \" + str(t_value) + \" ,p value: \"+ str(p_value))","e8af57d5":"scipy.stats.t.interval(0.95, len(data['winner'])-1, loc=np.mean(data['winner']), scale=scipy.stats.sem(data['winner']))","e386d5aa":"p_firstBlood = data[(data['firstBlood'] == 1) & (data['winner'] == 1)].count()\/data[data['firstBlood'] == 1].count()\np_firstTower = data[(data['firstTower'] == 1) & (data['winner'] == 1)].count()\/data[data['firstTower'] == 1].count()\np_firstInhibitor = data[(data['firstInhibitor'] == 1) & (data['winner'] == 1)].count()\/data[data['firstInhibitor'] == 1].count()\np_firstBaron = data[(data['firstBaron'] == 1) & (data['winner'] == 1)].count()\/data[data['firstBaron'] == 1].count()\np_firstDragon = data[(data['firstDragon'] == 1) & (data['winner'] == 1)].count()\/data[data['firstDragon'] == 1].count()\np_firstRiftHerald = data[(data['firstRiftHerald'] == 1) & (data['winner'] == 1)].count()\/data[data['firstRiftHerald'] == 1].count()","d54021e6":"labels = ('firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald')\nprobabilities = [p_firstBlood['gameDuration'], p_firstTower['gameDuration'], p_firstInhibitor['gameDuration'], p_firstBaron['gameDuration']\n                ,p_firstDragon['gameDuration'] ,p_firstRiftHerald['gameDuration']]\nprobabilities = [i * 100 for i in probabilities]\ny_pos = np.arange(len(labels))\nplt.figure(figsize=(25,15))\nplt.bar(y_pos, probabilities, align='center', alpha=1)\nplt.xticks(y_pos, labels, fontsize = 30)\nplt.yticks(fontsize = 30)\nplt.ylabel('Probability(%)', fontsize = 30)\nplt.title('Winning Probability when Team 1 got FirstXXX', fontsize = 40)\nfor a,b in zip(y_pos, probabilities):\n    plt.text(a, b, '%.3f'%b+'%', ha='center', va= 'bottom',fontsize=30)\nplt.show()","5cfbb422":"p_firstBlood1 = data[(data['firstBlood'] == 1) & (data['winner'] == 1)].count()\/data[data['winner'] == 1].count()\np_firstTower1 = data[(data['firstTower'] == 1) & (data['winner'] == 1)].count()\/data[data['winner'] == 1].count()\np_firstInhibitor1 = data[(data['firstInhibitor'] == 1) & (data['winner'] == 1)].count()\/data[data['winner'] == 1].count()\np_firstBaron1 = data[(data['firstBaron'] == 1) & (data['winner'] == 1)].count()\/data[data['winner'] == 1].count()\np_firstDragon1 = data[(data['firstDragon'] == 1) & (data['winner'] == 1)].count()\/data[data['winner'] == 1].count()\np_firstRiftHerald1 = data[(data['firstRiftHerald'] == 1) & (data['winner'] == 1)].count()\/data[data['winner'] == 1].count()","51dfcc16":"labels1 = ('firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald')\nprobabilities1 = [p_firstBlood1['gameDuration'], p_firstTower1['gameDuration'], p_firstInhibitor1['gameDuration'], p_firstBaron1['gameDuration']\n                ,p_firstDragon1['gameDuration'] ,p_firstRiftHerald1['gameDuration']]\nprobabilities1 = [i * 100 for i in probabilities1]\ny_pos1 = np.arange(len(labels1))\nplt.figure(figsize=(25,15))\nplt.bar(y_pos1, probabilities1, align='center', alpha=1)\nplt.xticks(y_pos1, labels1, fontsize = 30)\nplt.yticks(fontsize = 30)\nplt.ylabel('Probability(%)', fontsize = 30)\nplt.title('FirstXXX if Team 1 Win', fontsize = 40)\nfor a,b in zip(y_pos1, probabilities1):\n    plt.text(a, b, '%.3f'%b+'%', ha='center', va= 'bottom',fontsize=30)\nplt.show()","43da3875":"\n\ndummy_data = data.copy()\ndummy_data = pd.concat([dummy_data,pd.get_dummies(data['firstBlood'],prefix = 'firstBlood'),\n                       pd.get_dummies(data['firstTower'],prefix = 'firstTower'),\n                       pd.get_dummies(data['firstInhibitor'],prefix = 'firstInhibitor'),\n                       pd.get_dummies(data['firstBaron'],prefix = 'firstBaron'),\n                       pd.get_dummies(data['firstDragon'],prefix = 'firstDragon'),\n                       pd.get_dummies(data['firstRiftHerald'],prefix = 'firstRiftHerald')], axis = 1)\ndummy_data.info()","7db46c15":"X = dummy_data[['t1_towerKills','t1_inhibitorKills','t1_baronKills','t1_dragonKills','t1_riftHeraldKills',\n                           't2_towerKills','t2_inhibitorKills','t2_baronKills','t2_dragonKills','t2_riftHeraldKills',\n                           'firstBlood_1','firstTower_1','firstTower_2','firstInhibitor_1','firstInhibitor_2',\n                           'firstBaron_1','firstBaron_2','firstDragon_1','firstDragon_2','firstRiftHerald_1','firstRiftHerald_2',\n                           'gameDuration']]\ny = dummy_data['winner']","f151d1eb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,random_state=0)","a436208a":"lr_model= LogisticRegression(C = 1,\n                              penalty = 'l2',solver = 'liblinear')\n\nlr_model.fit(X_train,y_train)\npred_train = lr_model.predict(X_train)\nprint(classification_report(y_train, pred_train > 0.5))\n\npred_test= lr_model.predict(X_test)\nprint(classification_report(y_test, pred_test > 0.5))\nprint(lr_model.coef_)\nprint(lr_model.intercept_)\nscores = cross_val_score(lr_model,X,y,cv=7)\nprint('The cross validation score is {0}'.format(scores.mean()))","18ab2d75":"p = []\nt = []\nX1 = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n      [1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,900],\n     [2,0,0,0,0,3,0,0,1,1,1,1,0,0,0,0,0,0,1,0,1,1200],\n     [5,0,0,1,0,4,0,0,1,1,1,1,0,0,0,0,0,0,1,0,1,1500],\n     [6,1,1,2,0,4,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,1800],\n     [9,2,1,3,0,5,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,2100]]\npre = lr_model.predict_proba(X1)\nprint(pre)\nfor i in pre:\n    p.append(i[1])\nfor j in X1:\n    t.append(j[-1])\nfig = plt.figure(figsize = (10,5))\nplt.plot(t,p)\nplt.xlabel('Time(Seconds)')\nplt.ylabel('Winning Probability')\nplt.title('Team 1 Winning Prediction')\nplt.show()","59b48cc0":"pred= lr_model.predict_proba(X_test)\nresult= pd.DataFrame(pred)\nresult.index= X_test.index\nresult.columns= ['0', 'winning_probability']\nprint(result.head(5))","1365dd65":"y_score = lr_model.decision_function(X_test)\nfpr,tpr,threshold = roc_curve(y_test, y_score)\nroc_auc = auc(fpr,tpr)\nprint(\"AUC: \" + str(roc_auc))","896ad4c3":"plt.figure()\nlw = 2\nplt.figure(figsize=(10,10))\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","1cf28d31":"decile_data = pd.concat([result['winning_probability'],y_test],axis = 1)\ndecile_data['Decile_rank']=pd.qcut(decile_data['winning_probability'],10,labels=False)\nprint(decile_data.head(5))","a7d52892":"decile = pd.DataFrame(columns = ['Decile\/global_mean'])\nglobal_mean = decile_data['winner'].mean()\nfor i in range(9,-1,-1):\n    decile.loc[i] = decile_data[decile_data['Decile_rank'] == i].mean()['winning_probability']\/global_mean\nprint(decile)","c0cf5d0c":"plt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features',y=1.05,size=15)\nsns.heatmap(X.astype(float).corr(),linewidths=0.1,vmax=1.0,\n            square=True,linecolor='white',annot=True)\nplt.xticks(rotation=90)\nplt.yticks(rotation=360)\nplt.show()","41579bd5":"transformer = SelectKBest(chi2, k=10)\ntransformer.fit(X,y)\nX_new = transformer.transform(X)","2352ea00":"transformer.get_support(True)","7691db01":"X.columns","c7253ab7":"def multivariate_pearsonr(X,y):\n    scores,pvalues = [],[]\n    for column in range(X.shape[1]):\n        cur_score,cur_p = pearsonr(X[:,column],y)\n        scores.append(abs(cur_score))\n        pvalues.append(cur_p)\n    return (np.array(scores), np.array(pvalues))","0ba4efa9":"transformer = SelectKBest(score_func=multivariate_pearsonr, k=10) \nXt_pearson = transformer.fit_transform(X, y) \nprint(transformer.scores_)","27915ad9":"transformer.get_support(True)","631e84b4":"X.columns","b3712919":"Xt_pearson","0c826fba":"lr_model= LogisticRegression(C = 1,\n                              penalty = 'l2',solver = 'liblinear')\nscores = cross_val_score(lr_model,Xt_pearson,y,cv=7)\nprint('The cross validation score is {0}'.format(scores.mean()))","fd24b14e":"def sigmoid(inX): \n    res = np.array(inX)\n    res = 1.0\/(1+np.exp(-res))\n    return res","f02a472a":"model = Ridge(alpha=1)\n#model = RidgeCV(alphas=[0.1, 1.0, 10.0])\nmodel.fit(X, y)","e42a83bc":"model.coef_","351b5293":"#model.alpha_","eee6d405":"pred_train_r = model.predict(X_train)\nprint(max(pred_train_r))\nprint(min(pred_train_r))\nprint(classification_report(y_train, pred_train_r > 0.5))\npred_test_r= model.predict(X_test)\nprint(classification_report(y_test, pred_test_r > 0.5))\nscores = cross_val_score(model,X,y,cv=7)\nprint('The cross validation score is {0}'.format(scores.mean()))","3579ae3f":"X1 = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n      [1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,900],\n     [2,0,0,0,0,3,0,0,1,1,1,1,0,0,0,0,0,0,1,0,1,1200],\n     [5,0,0,1,0,4,0,0,1,1,1,1,0,0,0,0,0,0,1,0,1,1500],\n     [6,1,1,2,0,4,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,1800],\n     [9,2,1,3,0,5,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,2100]]\npre_r = model.predict(X1)\nprint(pre_r)\nfig = plt.figure(figsize = (10,5))\nplt.plot(t,pre_r)\nplt.xlabel('Time(Seconds)')\nplt.ylabel('Winning Probability')\nplt.title('Team 1 Winning Prediction')\nplt.show()","af413bd3":"neigh = KNeighborsClassifier(n_neighbors=2, weights = 'uniform')\nneigh.fit(X, y)","8aa77740":"neigh_pred = neigh.predict(X_test)\nprint(classification_report(y_test, neigh_pred > 0.5))","2ea4acd5":"X1 = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n      [1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,900],\n     [2,0,0,0,0,3,0,0,1,1,1,1,0,0,0,0,0,0,1,0,1,1200],\n     [5,0,0,1,0,4,0,0,1,1,1,1,0,0,0,0,0,0,1,0,1,1500],\n     [6,1,1,2,0,4,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,1800],\n     [9,2,1,3,0,5,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,2100]]\nprint(neigh.predict_proba(X1))\np = neigh.predict(X1)\nfig = plt.figure(figsize = (10,5))\nplt.plot(t,p)\nplt.xlabel('Time(Seconds)')\nplt.ylabel('Winning Probability')\nplt.title('Team 1 Winning Prediction')\nplt.show()","dbccee9f":"We seperate our data into training dataset and testing dataset. 30% of all data will be selected as test dataset randomly.","96a8c688":"t1_towerKills  \nt1_inhibitorKills  \nt1_dragonKills  \nt2_towerKills  \nt2_inhibitorKills  \nt2_dragonKills  \nfirstTower_2  \nfirstInhibitor_1  \nfirstInhibitor_2  \nfirstBaron_2","1ef90f27":"|t1_towerKills | t1_inhibitorKills | t1_baronKills | t1_dragonKills | t1_riftHeraldKills | t2_towerKills | t2_inhibitorKills | t2_baronKills | t2_dragonKills | t2_riftHeraldKills | firstBlood_1 | firstTower_1 | firstTower_2 | firstInhibitor_1 | firstInhibitor_2 | firstBaron_1 | firstBaron_2 | firstDragon_1 | firstDragon_2 | firstRiftHerald_1 | firstRiftHerald_2 | gameDuration|  \n|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|\n|1|0|0|0|0|0|0|0|0|0|1|1|0|0|0|0|0|0|0|0|0|900|\n|2|0|0|0|0|3|0|0|1|1|1|1|0|0|0|0|0|0|1|0|1|1200|\n|5|0|0|1|0|4|0|0|1|1|1|1|0|0|0|0|0|0|1|0|1|1500|\n|6|1|1|2|0|4|0|0|1|1|1|1|0|1|0|1|0|0|1|0|1|1800|\n|9|2|1|3|0|5|0|0|1|1|1|1|0|1|0|1|0|0|1|0|1|2100|","6b75005a":"t value | p value\n-|-\n2.638 | 0.00833\n\np << 0.05, Rejict H0.  \nTeam 1 winning rate is significantly different from 50%.","21a3b8b7":"## 2.1.1 Prediction","8dbed40a":"From the result, we can see that for both training and testing dataset, the model can both have 0.97 F1-score. So the performance of the model is pretty well.","16c33f77":"The AUC of the model is very close to 1. So the model can predict very well.","3f331c7c":"## 2.1.2 Model Evaluation ","8f82d66f":"* H0: Winning Rate = 50%\n* H1: Winning Rate != 50%\n* Sig. = 0.05","3cdf72f3":"The Chart above shows the prediction of the winner during the game. One thing we need to be careful is what happened before 15 mins. Because no matter in our trainning dataset or testing dataset, we do not have any data before the begnning 15 mins. So the prediction of our model before 15 mins could be inaccurate.","db259e81":"From the Decile Chart we can easily find a gap between Decile 5 and 4. That is because only a few competitions have a winning probability around 50% at the end of the game. The prediction of the winning probability tends to be 1 or 0.","027b9d55":"## 1.3 Action Analysis","94f13355":"# 2.3 KNN\uff08K Nearest Neighbor)","b06702cd":"# 2.1 Logistic Regression","94e7ed3b":"For Knn Classifier, it can not predict the accurate winning probability of a game.","576379d7":"# 2.2 Ridge Regression","0275636a":"## 1.1 Data Cleaning\n\nLet's visualize the \"GameDuration\" attribute first to have a brife idea about how long a game usually take.","c632324c":"Let's create a new game from beginning. The data during the game is shown below.","d1f0581d":"## 1.4 Conclusion \n* There are some invalide competition data need to be removed from the case\n* The design of the map is not Perfectly fair to both teams. Team 1 has slightly higher chance to win the game. But maybe we can say the difference can be ignored.\n* All those actions can increase the winning rate, but they are NOT equally important.\n* Some actions are important requirements to win the game, while some actions are not necessary.","4ce2b73d":"Before cleaning the dataset, we can see that there are 51490 pieces of data. I plan to remove those competitions that gameDuration is under 900 seconds. Because I believe those are some \"unfair\" or \"invalide\" competition.","2c5ab9b1":"From the chart we can see that, most of the games end at around 1800 seconds or 30 minutes, which also match the description of the game official website.\n\nAlso, the distribution of the GameDuration is very similar to Normal Distribution except the left side where many games end before 300 seconds or 5 minutes. As a LOL player, I know that it's possible that players might fail to enter the game because of personal issue or internet issue. So players have the right to vote to remake the game by the beginning 3 minutes. That can explain why there is a a peak before 300 seconds or we can say the peak is before 180 seconds.\n\nThere are also some games end before 900 seconds(15 minutes). That could caused by the unequal match of 2 teams. 1 team is much stronger than another one, so they end the game pretty fast.\n\nPlayers are allowed to vote to surrender at 15 minutes if they believe there is a high chancee that they will lose in the end. This is why there is a high peak at 900 seconds.","9928f97c":"My next step will be forecasting the winning probability of the game using Logistic Regression and KNN (K Nearest Neighbor).  \nWhile the first step is precessing the data to create dummy variables.","b524d7f0":"From the Histogram we can see, if Team 1 got firstInhibitor, 90.8% times Team 1 finally won the game. This is the most important action that can help a Team to win the game. By the rule of the game, one team must destroy at least one inhibitor before destroy the base of the enemy. That's why the firstInhibitor is so important.  \nSo if your team has the chance to destroy the inhibitor, so it first!\n\nAlso, we can see that if Team 1 got firstBlood, 59% chance Team 1 won the game in the end. But remember, every team has 50% chance to win the game at the beginning. So getting first blood only increase the chance a little.  \nSo if you need to pay a lot to get first blood. It doesn't worth. If your team loses first blood, don't be angry, you still have a high chance to win the game.","30ad1b0d":"After creating dummy variables, we have more columns now. But we don't need all of them. For example, if 'firstBlood_1' is 1, then Team 1 got first blood; if 'firstBlood_2' is 1, then Team 2 got first blood. In our case, at least one team got first blood, so either 'firstBlood_1' or 'firstBlood_2' is 1. So we only need one of them to represent the 'firstBlood'.\n\nAs for 'firstTower', if 'firstTower_0' is 1, it means no one got first Tower; if 'firstTowr_1' is 1, then Team 1 got first Tower; if 'firstTower_2' is 1, then Team 2 got first Tower. Also, only one of them can be 1, so we only need 2 of these 3 columns to represent the 'firstTower'.\n\nX will be the performance of two teams in one game and y will be the result of the competition.","7110a4cd":"# 2. Data Forecasting","1d033120":"The performance of KNN is very similar to Logistic Regression","93b4060e":"From the heatmap we can easily know that there are many correlation among our attributes. This can cause serious multicolinearity problem. We could solve a problem like this by removing some attributes or using Ridge Regression.","ec8014ac":"After removing those invalide data, we have 50181 remains. So 51490-50181 = 1309 pieces of data was removed. We can see the distribution of the gameDuration is much cleaner now.","5fcfc4ca":"## 1.2 Hypothesis Test\n\nI'm going to use One Sample Hypothesis Test to see if Team 1 has 50% chance to win a game.\nLet's first visualize the winning rate.","4eec7d1a":"From the pie chart we can see that Team 1 has 50.59% winning rate while Team 2 has 49.41%. So the winning rate of two teams are not equal. But we need to test if this difference is significant or just by accident. We need to use Hypothesis test.\n\nBefore that, we need to do some conversations first. Currently, if the \"winner\" Column is \"1\", then Team 1 win; if the \"winner\" Column is \"2\". then Team 2 win. We need to replace all \"2\"s by 0, so when the column is 1, then Team 1 win. If the column is 0, then Team 1 didn't win. It will be helpful when we do Calculations.","51e532a2":"The 95% confidence interval is **[0.5015, 0.5103]**.  \nSo I have 95% confidence to say that the True winning rate of Team 1 will be between this range.","37bc8c5c":"The chart of Ridge Regression is quite different from Logistic Regression. That is because Ridge Regression is  biased. But it is useful to solve multicolinearity Problem.","2c09a0e0":"t1_towerKills  \nt1_inhibitorKills  \nt1_baronKills  \nt1_dragonKills  \nt2_towerKills  \nt2_inhibitorKills\nt2_baronKills\nt2_dragonKills  \nfirstInhibitor_1  \nfirstInhibitor_2  ","6d0d9d36":"Let's keep visualizing the winning rate. From the chart above, for those competitions that Team 1 wins, 82.22% of them Team 1 got firstInhibitor. We can conclude the getting firstInhibitor is an important requirement to win the game. While only 35% of winning competitions Team 1 gor firstRiftHerald.  \nCompare with the 69.445% chance in the first chart, we can conclude that even though getting first RiftHerald can increase the winning rate to 69%, it's NOT necessary to get the first RiftHerald because onlt 35% of winning game that Team 1 got first RiftHerald.","15e96009":"# 1.Data Analysis\nIn this dataset, we have too many variables. Many of those variables are not easy for us to analyze and do calculation. For example, \"Champion ID\" \"Champ Sum\" and bans. So we choose spart of all variables below to do our analysis."}}