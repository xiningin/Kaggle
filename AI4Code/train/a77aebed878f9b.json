{"cell_type":{"170b5e78":"code","3d264f9e":"code","2243f55a":"code","9f72d5f2":"code","c7782a80":"code","7ac292a5":"code","ad9e410b":"code","4d7f744b":"code","2dccde35":"code","e4493531":"code","e53ef95d":"code","c8e18703":"code","5586f624":"code","d089ba08":"code","75360b92":"code","a540c4cf":"code","4415e428":"code","6c17a077":"code","1ecfddb2":"code","bc08145a":"code","c9048f5d":"code","a56ad6f0":"code","d261b307":"code","4a51d7db":"code","2144eae9":"code","0f2869c1":"code","c75bba6a":"code","07f6fc9a":"code","8798030f":"code","4fc12e56":"code","c49dba52":"code","f6f76998":"code","d6915885":"markdown","648684d6":"markdown","c0f5e3d7":"markdown","aa288c49":"markdown","5bf7d800":"markdown","aa32f731":"markdown","55d62c4e":"markdown","f42e5a65":"markdown","3be3b96f":"markdown","20832714":"markdown","73059672":"markdown","8c7c4a17":"markdown","1f6e0b75":"markdown","2f55aeec":"markdown"},"source":{"170b5e78":"import warnings \nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom shutil import copyfile\nfrom random import seed\nfrom random import random\n\nfrom tqdm import tqdm_notebook as tqdm\ntqdm().pandas()\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom keras.layers import Dropout\n\nfrom keras.optimizers import SGD\n","3d264f9e":"import zipfile\n\nwith zipfile.ZipFile('..\/input\/dogs-vs-cats\/train.zip', 'r') as zip_ref:\n    zip_ref.extractall('.\/')\n\nwith zipfile.ZipFile('..\/input\/dogs-vs-cats\/test1.zip', 'r') as zip_ref:\n    zip_ref.extractall('.\/')","2243f55a":"os.listdir('.\/train')[:10]","9f72d5f2":"folder = '.\/train\/'\n\nplt.figure(figsize=(15,10))\nfor i in range(9):\n    plt.subplot(330 + 1 + i)\n    \n    filename = folder + 'dog.' + str(i) + '.jpg' \n    image = plt.imread(filename)\n    \n    plt.imshow(image)\n    # show the figure\nplt.show()","c7782a80":"plt.figure(figsize=(15,10))\nfor i in range(9):\n    plt.subplot(330 + 1 + i)\n    \n    filename = folder + 'cat.' + str(i) + '.jpg' \n    image = plt.imread(filename)\n    \n    plt.imshow(image)\n    # show the figure\nplt.show()","7ac292a5":"HOME = '.\/'\nsubdirs = ['training\/', 'testing\/']\n\nfor subdir in subdirs:\n    labeldirs = ['dogs\/', 'cats\/']\n    for labeldir in labeldirs:\n        newdir = HOME + subdir + labeldir\n        os.makedirs(newdir, exist_ok = True)","ad9e410b":"SRC_PATH = '.\/train\/'\n\nseed(1)\nval_ratio = 0.25\n\nfor file in tqdm(os.listdir(SRC_PATH)):\n    src = SRC_PATH + file\n    \n    dest_dir = '.\/training\/'\n    if random() < val_ratio:\n        dest_dir = '.\/testing\/'\n    \n    if file.startswith('cat'):\n        dest = dest_dir + 'cats\/' + file\n        copyfile(src, dest)\n    else:\n        dest = dest_dir + 'dogs\/' + file\n        copyfile(src, dest)      \n    ","4d7f744b":"TRAIN_PATH = '.\/training\/'\nTEST_PATH = '.\/testing'","2dccde35":"datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\n# prepare iterators\ntrain_it = datagen.flow_from_directory(TRAIN_PATH, class_mode='binary', \n                                      batch_size=64, target_size=(200,200))\ntest_it = datagen.flow_from_directory(TEST_PATH, class_mode='binary', \n                                      batch_size=64, target_size=(200,200))","e4493531":"def summarize_diagnostics(history):\n    plt.figure(figsize=(10,5))\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(history.history['loss'], color='blue', label='train') \n    plt.plot(history.history['val_loss'], color='orange', label='test')\n\n        # plot accuracy\n    plt.subplot(212)\n    plt.title('Classification Accuracy') \n    plt.plot(history.history['accuracy'], color='blue', label='train') \n    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n    plt.show()","e53ef95d":"def define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Flatten())\n    \n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    opt=SGD(lr=0.01, momentum=0.9)\n    \n    model.compile(optimizer=opt, metrics=['accuracy'], loss='binary_crossentropy')\n    return model","c8e18703":"model = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it), callbacks=[rlrop],\n         epochs=10, validation_data=test_it, verbose=1)","5586f624":"summarize_diagnostics(history)","d089ba08":"_, accuracy = model.evaluate_generator(test_it,  steps=len(test_it), verbose=1)\nprint(accuracy)","75360b92":"def define_model():\n    model = Sequential()\n    #BLOCK 1\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    \n    #BLOCK 2\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    \n    #BLOCK 3\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Flatten())\n    \n    \n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    opt=SGD(lr=0.01, momentum=0.9)\n    \n    model.compile(optimizer=opt, metrics=['accuracy'], loss='binary_crossentropy')\n    return model","a540c4cf":"model = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it), callbacks=[rlrop],\n         epochs=10, validation_data=test_it, verbose=1)","4415e428":"summarize_diagnostics(history)","6c17a077":"_, accuracy = model.evaluate_generator(test_it,  steps=len(test_it), verbose=1)\nprint(accuracy)","1ecfddb2":"def define_model():\n    model = Sequential()\n    #BLOCK 1\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    \n    #BLOCK 2\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.3))\n    \n    #BLOCK 3\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.4))\n    model.add(Flatten())\n    \n    \n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    opt=SGD(lr=0.01, momentum=0.9)\n    \n    model.compile(optimizer=opt, metrics=['accuracy'], loss='binary_crossentropy')\n    return model","bc08145a":"model = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it), \n                              callbacks=[rlrop], epochs=10, \n                              validation_data=test_it, validation_steps=len(test_it), \n                              verbose=1)","c9048f5d":"summarize_diagnostics(history)","a56ad6f0":"_, accuracy = model.evaluate_generator(test_it,  steps=len(test_it), verbose=1)\nprint(accuracy)","d261b307":"def define_model():\n    model = Sequential()\n    #BLOCK 1\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    \n    #BLOCK 2\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    \n    #BLOCK 3\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform',\n                    padding='same', input_shape=(200,200,3)))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Flatten())\n    \n    \n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    opt=SGD(lr=0.01, momentum=0.9)\n    \n    model.compile(optimizer=opt, metrics=['accuracy'], loss='binary_crossentropy')\n    return model","4a51d7db":"datagen = ImageDataGenerator(rescale=1.0\/255.0, width_shift_range=0.1, \n                             height_shift_range=0.1, horizontal_flip=True)\n\n# prepare iterators\ntrain_it = datagen.flow_from_directory(TRAIN_PATH, class_mode='binary', \n                                      batch_size=64, target_size=(200,200))\ntest_it = datagen.flow_from_directory(TEST_PATH, class_mode='binary', \n                                      batch_size=64, target_size=(200,200))","2144eae9":"model = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it), \n                              callbacks=[rlrop], epochs=10, \n                              validation_data=test_it, validation_steps=len(test_it), \n                              verbose=1)","0f2869c1":"summarize_diagnostics(history)","c75bba6a":"_, accuracy = model.evaluate_generator(test_it,  steps=len(test_it), verbose=1)\nprint(accuracy)","07f6fc9a":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\n\ndef define_model():\n    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n    \n    for layer in model.layers:\n        layer.trainable = False\n    \n    flat = Flatten()(model.layers[-1].output)\n    dense1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat)\n    output = Dense(1, activation='sigmoid')(dense1)\n    \n    model = Model(inputs=model.inputs, outputs=output)\n    \n    \n    # Learning rate has been reduced to 0.001 as the model is already trained\n    opt=SGD(lr=0.001, momentum=0.9)\n    \n    model.compile(optimizer=opt, metrics=['accuracy'], loss='binary_crossentropy')\n    return model","8798030f":"datagen = ImageDataGenerator(featurewise_center=True)\ndatagen.mean = [123.68, 116.779, 103.939]\n\n# prepare iterators\ntrain_it = datagen.flow_from_directory(TRAIN_PATH, class_mode='binary', \n                                      batch_size=64, target_size=(224,224))\ntest_it = datagen.flow_from_directory(TEST_PATH, class_mode='binary', \n                                      batch_size=64, target_size=(224,224))","4fc12e56":"model = define_model()\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=3, \n                              validation_data=test_it, validation_steps=len(test_it), \n                              verbose=1)","c49dba52":"summarize_diagnostics(history)","f6f76998":"_, accuracy = model.evaluate_generator(test_it,  steps=len(test_it), verbose=1)\nprint(accuracy)","d6915885":"<h3><center>5. Develop Model Improvements<\/center><\/h3>\n<h3><center>5.1. VGG3 + Dropout Regularization<\/center><\/h3>","648684d6":"<h3><center>4. Modelling<\/center><\/h3>\n\n<h3><center>4.1. Baseline One block VGG Model<\/center><\/h3>","c0f5e3d7":"<h3><center>1. Explore Dataset<\/center><\/h3>","aa288c49":"<h3><center>6. Transfer Learning using VGG-16<\/center><\/h3>\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nVGG-16 with 16 layers achieved top results on the ImageNet photo classification challenge. The model is comprised of two main parts, the feature extractor part of the model that is made up of VGG blocks, and the classifier part of the model that is made up of fully connected layers and the output layer.<br><br>\nWe can use the feature extraction part of the model and add a new classifier part of the model that is tailored to the dogs and cats dataset.<br><br> Specifically, we can hold the weights of all of the convolutional layers fixed during training, and only train new fully connected layers that will learn to interpret the features extracted from the model and make a binary classification.<br><br> This can be achieved by loading the VGG-16 model, removing the fully connected layers from the output-end of the model, then adding the new fully connected layers to interpret the model output and make a prediction. The classifier part of the model can be removed automatically by setting the include top argument to False, which also requires that the shape of the input also be specified for the model, in this case (224, 224, 3). This means that the loaded model ends at the last max pooling layer, after which we can manually add a Flatten layer and the new classifier layers. \n    <\/div>","5bf7d800":"<h3><center>4.2. Baseline Three Block VGG Model<\/center><\/h3>","aa32f731":"<div style=\"font-family:verdana; word-spacing:1.7px;\">\nThe model also expects images to be centered. That is, to have the mean pixel values from each channel (red, green, and blue) as calculated on the ImageNet training dataset subtracted from the input. Keras provides a function to perform this preparation for individual photos via the preprocess input() function. Nevertheless, we can achieve the same effect with the ImageDataGenerator by setting the featurewise center argument to True and manually specifying the mean pixel values to use when centering as the mean values from the ImageNet training dataset: [123.68, 116.779, 103.939]\n    <\/div>","55d62c4e":"Model couldn't learn and instead overfitting the training examples","f42e5a65":"<h3><center>3. Image DataGenerator<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.9px;\">\nNext, we need to prepare the data. This involves first defining an instance of the\nImageDataGenerator that will scale the pixel values to the range of 0-1\n<br><br>\nNext, iterators need to be prepared for both the train and test datasets. We can use the flow_from_directory() function on the data generator and create one iterator for each of the train\/ and test\/ directories.\n<br><br>\nWe must specify that the problem is a binary classification problem via the class mode argument, and to load the images with the size of 200 \u00d7 200 pixels via the target size argument. We will fix the batch size at 64.\n<\/div>","3be3b96f":"<h3>Load Images<\/h3>","20832714":"<h3><center>2. Preprocess photos into Directories to save RAM<\/center><\/h3>\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nWe can load the images progressively using the Keras ImageDataGenerator class and flow from directory() API. This will be slower to execute but will require less RAM. This API prefers data to be divided into separate train\/ and test\/ directories, and under each directory to have a subdirectory for each class, e.g. a train\/dog\/ and a train\/cat\/.\n<br><br>\nWe will randomly select 25% of the images (or 6,250) to be used in a test dataset.\n    <\/div>\n    \n![image.png](attachment:image.png)","73059672":"<h3><center>5.2. VGG3 Baseline + Augmentation<\/center><\/h3>","8c7c4a17":"<h3>Make Directories<\/h3>","1f6e0b75":"<h3><center>Dogs vs Cats<\/center><\/h3>\n\n![image.png](attachment:image.png)","2f55aeec":"def define_model():\n  model = VGG16(include_top=False, input_shape=(224, 224, 3))\n  for layer in model.layers:\n    layer.trainable = False\nflat1 = Flatten()(model.layers[-1].output)\nclass1 = Dense(128, activation=\u272crelu\u272c, kernel_initializer=\u272che_uniform\u272c)(flat1) output = Dense(1, activation=\u272csigmoid\u272c)(class1)\nmodel = Model(inputs=model.inputs, outputs=output)\nopt = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=opt, loss=\u272cbinary_crossentropy\u272c, metrics=[\u272caccuracy\u272c]) return model"}}