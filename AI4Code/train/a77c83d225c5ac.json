{"cell_type":{"294a1cc8":"code","9a51cf9a":"code","daf98677":"code","7d42b8fb":"code","3313e1ec":"code","476ab800":"code","6c611927":"code","c90efe16":"code","857dae88":"code","5a6ca92c":"code","b46d08f4":"code","38968993":"code","5b89c4d1":"code","c2b96742":"code","0c1a3ebc":"code","022f7e1b":"code","e10e78b2":"code","1f1203ac":"code","9653a0a7":"code","95e90a65":"code","163ff63b":"code","39894e66":"code","3198da4c":"code","8ade038e":"code","7d4e31f6":"code","84dbfa25":"code","c46610ab":"code","7fcfec46":"code","135b887d":"code","44276edb":"code","ac2eb6bc":"code","c62663df":"code","0d7d25bd":"code","bbcc130d":"code","84126986":"code","20780b56":"code","8d603589":"code","63773898":"code","fca22868":"code","5bc9acae":"code","f751757a":"code","d482ef83":"code","46ad1b20":"code","9fdc2db2":"code","33e5d8e3":"code","2b36993c":"code","5fb4ec61":"code","9840cc03":"code","477d4d83":"code","7a4516f9":"code","679bbee6":"code","ad5f638e":"code","b287e752":"code","121af967":"markdown"},"source":{"294a1cc8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9a51cf9a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","daf98677":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ndf_test= pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ndf= pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","7d42b8fb":"df.info()","3313e1ec":"corrmat=df.corr()\nf, ax=plt.subplots(figsize=(15,10))\nsns.heatmap(corrmat, vmax=1, square=True)","476ab800":"total=df.isnull().sum().sort_values(ascending=False)\npercent=(total\/df.isnull().count()).sort_values(ascending=False)\nmissing_data=pd.concat([total,percent], axis=1,keys=['Total','percent']).sort_values(by=['Total'], ascending=False)\nmissing_data","6c611927":"#find outliers\nvar='GrLivArea'\ndata=pd.concat([df['SalePrice'],df[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice')","c90efe16":"#GrLivarea above 4500 has weird low saleprice, delete.\ndf.sort_values(by='GrLivArea', ascending=False)[:2]","857dae88":"df=df.drop(index=df[df['Id']==1299].index)\ndf=df.drop(index=df[df['Id']==524].index)","5a6ca92c":"var='GrLivArea'\ndata=pd.concat([df['SalePrice'],df[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice')","b46d08f4":"#Normality to get homoscedasticity\nprint('skewness: %f'% df['SalePrice'].skew())\nprint('kurtosis: %f' % df['SalePrice'].kurt())","38968993":"from scipy.stats import norm\nsns.distplot(df['SalePrice'], fit=norm)\nimport scipy.stats as stats\nfig = plt.figure() #must open a new figure, otherwise two figures would draw together.\nres = stats.probplot(df['SalePrice'], plot=plt)","5b89c4d1":"#From not normal to normal. when positive skewness, log transformations usually works well.\ndf['SalePrice']=np.log(df['SalePrice'])","c2b96742":"sns.distplot(df['SalePrice'], fit=norm)\nfig=plt.figure()\nres=stats.probplot(df['SalePrice'],plot=plt)","0c1a3ebc":"df['GrLivArea']=np.log(df['GrLivArea'])\nsns.distplot(df['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df['GrLivArea'], plot=plt)","022f7e1b":"plt.scatter(df['GrLivArea'], df['SalePrice']);","e10e78b2":"df['1stFlrSF']=np.log(df['1stFlrSF'])\nsns.distplot(df['1stFlrSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df['1stFlrSF'], plot=plt)","1f1203ac":"#dealing with missing data\n#too much missing data will be deleted\ndf.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage'], axis=1, inplace=True)","9653a0a7":"#delect not important features from analysis of heatmap\ndf.drop(['Id', 'MSSubClass', '1stFlrSF', '2ndFlrSF', 'BsmtFullBath', 'OverallCond', 'BsmtFinSF2', 'BsmtUnfSF', 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'GarageArea', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'LotArea', 'GarageYrBlt'], axis=1, inplace=True)","95e90a65":"df.info()","163ff63b":"#fill missing data\ndf['MasVnrType'].unique()","39894e66":"df['MasVnrType'].fillna('None', inplace=True)","3198da4c":"df['MasVnrType'].unique()","8ade038e":"df['MasVnrArea'].fillna(0, inplace=True)","7d4e31f6":"df['BsmtCond'].fillna('None', inplace=True)\ndf['BsmtQual'].fillna('None', inplace=True)\ndf['BsmtExposure'].fillna('None', inplace=True)\ndf['BsmtFinType1'].fillna('None', inplace=True)\ndf['BsmtFinType2'].fillna('None', inplace=True)\ndf.dropna(subset=['Electrical'], inplace=True)\ndf['GarageType'].fillna('None', inplace=True)\ndf['GarageFinish'].fillna('None', inplace=True)\ndf['GarageQual'].fillna('None', inplace=True)\ndf['GarageCond'].fillna('None', inplace=True)","84dbfa25":"df.info()","c46610ab":"#now we have three data types: categorical(get dummies later), numerical and year. Year will transferred.\ndf['YearBuiltBand']=pd.cut(df['YearBuilt'],13, labels=[1,2,3,4,5,6,7,8,9,10,11,12,13]).astype('int64')\ndf['YearRemodAddBand']=pd.cut(df['YearRemodAdd'],6,labels=[1,2,3,4,5,6]).astype('int64')\ndf.drop(['YearBuilt', 'YearRemodAdd'], axis=1, inplace=True)","7fcfec46":"df.info()","135b887d":"#deal with test dataset\nId=df_test['Id'].values","44276edb":"df_test.head()","ac2eb6bc":"df_test.info()","c62663df":"df_test['GrLivArea']=np.log(df_test['GrLivArea'])\ndf_test['1stFlrSF']=np.log(df_test['1stFlrSF'])","0d7d25bd":"df_test.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage'], axis=1, inplace=True)\ndf_test.drop(['Id', 'MSSubClass', '1stFlrSF', '2ndFlrSF', 'BsmtFullBath', 'OverallCond', 'BsmtFinSF2', 'BsmtUnfSF', 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'GarageArea', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'LotArea', 'GarageYrBlt'], axis=1, inplace=True)","bbcc130d":"df_test.info()","84126986":"df_test['MSZoning'].fillna('None', inplace=True)\ndf_test['Utilities'].fillna('None', inplace=True)\ndf_test['MasVnrType'].fillna('None', inplace=True)\ndf_test['MasVnrArea'].fillna(0, inplace=True)\ndf_test['BsmtCond'].fillna('None', inplace=True)\ndf_test['BsmtQual'].fillna('None', inplace=True)\ndf_test['BsmtExposure'].fillna('None', inplace=True)\ndf_test['BsmtFinType1'].fillna('None', inplace=True)\ndf_test['BsmtFinType2'].fillna('None', inplace=True)\ndf_test['GarageCond'].fillna('None', inplace=True)\ndf_test['GarageType'].fillna('None', inplace=True)\ndf_test['GarageFinish'].fillna('None', inplace=True)\ndf_test['GarageQual'].fillna('None', inplace=True)\ndf_test['Exterior1st'].fillna('None', inplace=True)\ndf_test['Exterior2nd'].fillna('None', inplace=True)","20780b56":"df_test.info()","8d603589":"df_test['BsmtFinSF1'].fillna(0, inplace=True)\ndf_test['TotalBsmtSF'].fillna(0, inplace=True)\ndf_test['GarageCars'].fillna(0, inplace=True)\ndf_test['SaleType'].fillna('Oth', inplace=True)\ndf_test['Functional'].fillna('Typ', inplace=True)\ndf_test['KitchenQual'].fillna('Typ', inplace=True)","63773898":"df_test['YearBuiltBand']=pd.cut(df_test['YearBuilt'],13, labels=[1,2,3,4,5,6,7,8,9,10,11,12,13]).astype('int64')\ndf_test['YearRemodAddBand']=pd.cut(df_test['YearRemodAdd'],6,labels=[1,2,3,4,5,6]).astype('int64')\ndf_test.drop(['YearBuilt', 'YearRemodAdd'], axis=1, inplace=True)","fca22868":"df_test.info()","5bc9acae":"all_data=pd.concat((df, df_test))\nfor column in all_data.select_dtypes(include=[np.object]).columns:\n    print(column, all_data[column].unique())","f751757a":"from pandas.api.types import CategoricalDtype\nall_data=pd.concat((df, df_test))\nfor column in all_data.select_dtypes(include=[np.object]).columns:\n    df[column]=df[column].astype(CategoricalDtype(categories=all_data[column].unique()))\n    df_test[column]=df_test[column].astype(CategoricalDtype(categories=all_data[column].unique()))","d482ef83":"df=pd.get_dummies(df)\ndf_test=pd.get_dummies(df_test)","46ad1b20":"df.shape","9fdc2db2":"df_test.shape","33e5d8e3":"#we use feature importance with random forests\nX=df[df.loc[:,df.columns!='SalePrice'].columns].values\ny=df['SalePrice'].values\nfrom sklearn.ensemble import RandomForestRegressor\nforest=RandomForestRegressor(n_estimators=1000, random_state=0, n_jobs=-1)\nforest.fit(X, y)\nimportances=forest.feature_importances_","2b36993c":"feat_labels=df.loc[:,df.columns!='SalePrice'].columns\nindices=np.argsort(importances)[::-1]\nfor f in range(X.shape[1]):\n    print(\"%d) %-s (%f)\" % (f + 1, feat_labels[indices[f]], importances[indices[f]]))","5fb4ec61":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=1)","9840cc03":"#now we use PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\npipe_lr=Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components=30)), ('clf', LinearRegression())])\npipe_lr.fit(X_train, y_train)\nprint('Test Accuracy: %.3f' %pipe_lr.score(X_test, y_test))","477d4d83":"#model evaluation\nfrom sklearn.model_selection import learning_curve\ntrain_sizes, train_scores, test_scores=learning_curve(estimator=pipe_lr, X=X_train, y=y_train, train_sizes=np.linspace(0.1,1.0,10), cv=10, n_jobs=-1)\ntrain_means=np.mean(train_scores, axis=1)\ntest_means=np.mean(test_scores, axis=1)\nylim=(0, 1.0)\nplt.plot(train_sizes, train_means, color='red')\nplt.plot(train_sizes, test_means, color='blue')","7a4516f9":"#validation curve to see find how many features to use\nfrom sklearn.model_selection import validation_curve\nparam_range=[20, 30, 40,50, 60, 70, 80, 90, 100]\npipe_lr=Pipeline([('scl', StandardScaler()), ('pca', PCA()), ('clf', LinearRegression())])\ntrain_scores, test_scores=validation_curve(estimator=pipe_lr, X=X_train, y=y_train, param_name='pca__n_components', param_range=param_range, cv=10)\ntrain_means=np.mean(train_scores, axis=1)\ntest_means=np.mean(test_scores, axis=1)\nplt.plot(param_range, train_means, color='red')\nplt.plot(param_range, test_means, color='blue')","679bbee6":"pipe_lr=Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components=30)), ('clf', LinearRegression())])\npipe_lr.fit(X, y)\npredictions=pipe_lr.predict(df_test)\npredictions","ad5f638e":"predictions=np.exp(predictions)\npredictions.round(1)","b287e752":"submission=pd.DataFrame({'Id': Id, 'SalePrice': predictions})\nsubmission.to_csv('submission.csv', index=False)","121af967":"10 features are most overallqual,grlivarea,garagecars,garagearea,totalbsmtsf,1stfirst,fullbath, totrmsabvgrd,yearbuilt, yearremodadd however, garagecars and garagearea are multicollinearty. totalbsmtsf and 1stflrsf are multicollineary.totrmsabvgrd and grlivearea are multicollinearty. therefore,garagearea, totrmsavgrd and 1stflrsf should be deleted. at last, 7 features remain."}}