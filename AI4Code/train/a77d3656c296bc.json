{"cell_type":{"538929ed":"code","2d6b7592":"code","90120c64":"code","832eae71":"code","eaab4edc":"code","74be6f06":"code","119f36fc":"code","d68d68ac":"code","b3f4d542":"code","000f8c1d":"code","bb1945af":"code","32ebd5ed":"code","5b94ab14":"code","c58f2702":"code","0d566bcf":"code","d190172c":"code","a6cd0b0b":"code","c8f239a2":"code","41d0d0de":"code","f022cdef":"code","9561e9ea":"markdown","4e168334":"markdown","9c09ce92":"markdown","90ef7a8b":"markdown"},"source":{"538929ed":"import numpy as np\nimport pandas as pd\npd.set_option(\"max_colwidth\", 90)\n\nfrom string import punctuation\nfrom bs4 import BeautifulSoup\nimport re\nimport calendar\nimport textwrap\n\nfrom nltk import word_tokenize, pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","2d6b7592":"def text_preprocessor(text: str, max_len: int = 600) -> str:\n    \"\"\" Cutting and cleaning the text. \"\"\"\n    text = text.strip()\n    text = textwrap.shorten(text, width=max_len, placeholder='')\n    text = text.replace('\\n', ' ')\n    text = text.lower()\n\n    text = re.sub(r'image|file|jpg|jpeg', '', text)\n    text = re.sub(r'\\d{1,4}\\.\\d{1,4}\\.\\d{1,4}\\.\\d{1,4}', '', text)\n    text = re.sub(r'https?:\/\/\\S+|www\\.\\S+', '', text)\n\n    soup = BeautifulSoup(text, 'lxml')\n    text = soup.get_text()\n    \n    text_cleaned = [w.strip(punctuation) for w in text.split() if not w.isdigit()]\n    text = \" \".join(text_cleaned)\n    \n    return text\n\n\ndef toxic_preprocessor(string: str) -> float:\n    \"\"\" Get value of toxic text. \"\"\"\n    \n    sid_score = sid.polarity_scores(string).get('neg')\n    \n    if sid_score:\n        return sid_score\n    else:\n        return 0","90120c64":"validation_data_path = \"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\"\nvalidation_data = pd.read_csv(validation_data_path)\nvalidation_data.shape","832eae71":"sid = SentimentIntensityAnalyzer()","eaab4edc":"sid.polarity_scores(\"this article sucks woo woo wooooooo\")","74be6f06":"sid.polarity_scores(\"what wher is your sexy pic gone from your main page put it back\")","119f36fc":"# shorten data to speed up debugging\nvalidation_data.loc[::100].shape","d68d68ac":"check_data = validation_data.copy()\ncheck_data","b3f4d542":"%%time\nclean_data = check_data.copy()\nclean_data['less_toxic'] = clean_data['less_toxic'].apply(text_preprocessor)\nclean_data['more_toxic'] = clean_data['more_toxic'].apply(text_preprocessor)","000f8c1d":"clean_data","bb1945af":"%%time\ntoxic_data = check_data.copy()  # === without text_preprocessor ===\ntoxic_data['less_toxic'] = toxic_data['less_toxic'].apply(toxic_preprocessor)\ntoxic_data['more_toxic'] = toxic_data['more_toxic'].apply(toxic_preprocessor)","32ebd5ed":"toxic_data","5b94ab14":"toxic_data.eval('less_toxic < more_toxic').mean()","c58f2702":"correct_predict = toxic_data.eval('less_toxic < more_toxic')","0d566bcf":"toxic_data.loc[~correct_predict]","d190172c":"diff_toxic_data = toxic_data.loc[~correct_predict] \\\n                    .assign(diff=lambda x: x.less_toxic - x.more_toxic)\ndiff_toxic_data","a6cd0b0b":"diff_toxic_data['diff'].hist(bins=100, figsize=(12,6));","c8f239a2":"clean_data.loc[~correct_predict]","41d0d0de":"# The indicies of incorrect preditions\nclean_data.loc[~correct_predict].reset_index()['index'].hist(bins=100, figsize=(12,6));","f022cdef":"pd.DataFrame({'all': clean_data.loc[:, 'worker'].value_counts(),\n              'correct': clean_data.loc[correct_predict, 'worker'].value_counts(),\n              'incorrect': clean_data.loc[~correct_predict, 'worker'].value_counts()}) \\\n                    .fillna(0).astype(int).sort_values(by='incorrect', ascending=False) \\\n                    .rename_axis(index='worker', columns='predict')","9561e9ea":"## Sample usage for sentiment\n\n> from nltk.classify import NaiveBayesClassifier  \n> from nltk.corpus import subjectivity  \n> from nltk.sentiment import SentimentAnalyzer  \n> from nltk.sentiment.util import *  \n> \n> OR  \n> \n> from nltk.sentiment.vader import SentimentIntensityAnalyzer  \n\nhttps:\/\/www.nltk.org\/howto\/sentiment.html","4e168334":"# 1. Import & Load","9c09ce92":"# 3. Check result","90ef7a8b":"# 2. Get score"}}