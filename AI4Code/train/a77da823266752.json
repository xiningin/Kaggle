{"cell_type":{"dccf3834":"code","56a54f45":"code","aa4f9dca":"code","dcc9a397":"code","57128379":"code","9d26b45a":"code","408218cb":"code","c1605f19":"code","3b519ecb":"code","81f58a85":"code","41eedd83":"code","2d17ce65":"markdown","8a222279":"markdown","319ccd5b":"markdown","33f4c5ee":"markdown","2cdb7d10":"markdown","bca4dad9":"markdown","5a9d580a":"markdown","51fced3f":"markdown","c87c0447":"markdown","f2914fa4":"markdown","7df260e3":"markdown","9d14cb35":"markdown","1221cd24":"markdown","e27b44ed":"markdown","c0b85255":"markdown","78bf13eb":"markdown","1697c10b":"markdown","2f16cead":"markdown"},"source":{"dccf3834":"import math, time\nfrom typing import List\n\n\nclass DGIM:\n    \n    def __init__(self, stream, windowsize, objective):\n        self.container = {}\n        self.windowsize = windowsize\n        self.wstart = len(stream) - objective\n\n        bucketsnum = int(math.log(windowsize, 2)) + 1\n        # initialize the container\n        for i in range(bucketsnum):\n            bucket = int(math.pow(2, i))\n            self.container[bucket] = []\n\n        self.timestamp = 0\n        for char in stream:\n            if char == '1':\n                self.container[1].append((self.timestamp, self.timestamp))\n                self.UpdateContainer(self.container)\n            self.timestamp += 1\n            \n    def UpdateContainer(self, container: dict) -> None:\n        for bucket in container.keys():\n            l = len(container[bucket])\n            if l > 2:\n                start = container[bucket][0][0]\n                container[bucket].pop(0)\n                end = container[bucket][0][1]\n                container[bucket].pop(0)\n                if bucket != max(container.keys()):\n                    container[bucket * 2].append((start, end))\n            while container[bucket] and container[bucket][0][1] + self.windowsize < self.timestamp:\n                container[bucket].pop(0)\n\n    def OutputResult(self):\n        count = 0\n        wstart = self.wstart\n        for bucket in self.container.keys():\n            if len(self.container[bucket]) == 0:\n                continue\n            # if bucket != 1:\n            bucket_num = len(self.container[bucket])\n            if wstart <= self.container[bucket][0][0]:\n                count += bucket_num * bucket\n            elif wstart > self.container[bucket][0][0] and wstart <= self.container[bucket][0][1]:\n                count += (bucket_num - 0.5) * bucket    \n            elif wstart > self.container[bucket][0][1] and wstart < self.container[bucket][-1][1]:\n                count += (bucket_num - 1.5) * bucket\n        return count\n\n\nwith open(\"..\/input\/stream-data-dgim\/stream_data_dgim.txt\", \"r\") as f:\n    stream = f.read().split()\n\ntime_start = time.time()\nmodel = DGIM(stream, windowsize=1000, objective=1000)\ncnt_1000 = model.OutputResult()\ntime_1000 = time.time() - time_start\nprint(\"Estimation (1000 bits): {}, Time (1000 bits):{}\".format(cnt_1000, time_1000))\n","56a54f45":"# last 500 bits\ntime_start = time.time()\nmodel = DGIM(stream, windowsize=1000, objective=500)\ncnt_500 = model.OutputResult()\ntime_500 = time.time() - time_start\nprint(\"Estimation (500 bits): {}, Time (500 bits):{}\".format(cnt_500, time_500))\n\n# last 200 bits \ntime_start = time.time()\nmodel = DGIM(stream, windowsize=1000, objective=200)\ncnt_200 = model.OutputResult()\ntime_200 = time.time() - time_start\nprint(\"Estimation (200 bits): {}, Time (200 bits):{}\".format(cnt_200, time_200))","aa4f9dca":"import time\n\ndef BruteForce(stream, objective):\n    time_start = time.time()\n    count = 0\n    for index, item in enumerate(stream):\n        if index >= len(stream) - objective:\n            if item == '1':\n                count += 1\n    time_end = time.time()\n    return count, time_end-time_start\n\n# DGIM\ncnt, t = BruteForce(stream, objective=1000)\nprint(\"[1000 bits]  Actual:{}, Estimation:{}, Accuracy:{}, DGIM Time:{}, BF Time:{}\".format(cnt, cnt_1000, 1 - abs(cnt-cnt_1000)\/cnt, time_1000, t))\ncnt, t = BruteForce(stream, objective=500)\nprint(\"[ 500 bits]  Actual:{}, Estimation:{}, Accuracy:{}, DGIM Time:{}, BF Time:{}\".format(cnt, cnt_500, 1 - abs(cnt-cnt_500)\/cnt, time_500, t))\ncnt, t = BruteForce(stream, objective=200)\nprint(\"[ 200 bits]  Actual:{}, Estimation:{}, Accuracy:{}, DGIM Time:{}, BF Time:{}\".format(cnt, cnt_200, 1 - abs(cnt-cnt_200)\/cnt, time_200, t))","dcc9a397":"import nltk\nfrom nltk.corpus import words\nword_list = words.words()","57128379":"from nltk.corpus import movie_reviews\n\nneg_reviews = []\npos_reviews = []\n\nfor fileid in movie_reviews.fileids('neg'):\n  neg_reviews.extend(movie_reviews.words(fileid))\nfor fileid in movie_reviews.fileids('pos'):\n  pos_reviews.extend(movie_reviews.words(fileid))","9d26b45a":"from collections import defaultdict\nimport time\n\n\n      \ndef fast_whether_in(word_list, queries):\n    word_dict = defaultdict(bool)\n    for d in word_list:\n        word_dict[d] = True\n    \n    time_start = time.time()\n    cnt = 0\n    for q in queries:\n        cnt += 1 if word_dict[q] else 0\n    t = time.time() - time_start\n    return cnt, t\n\ncnt_neg, time_neg = fast_whether_in(word_list, neg_reviews)\nprint(\"neg_reviews: {}\/{} are in word_list\".format(cnt_neg, len(neg_reviews)))\n\ncnt_pos, time_pos = fast_whether_in(word_list, pos_reviews)\nprint(\"pos_reviews: {}\/{} are in word_list\".format(cnt_pos, len(pos_reviews)))","408218cb":"class Bloom:\n    def __init__(self, m, k, hash_fun):\n        self.m = m\n        self.k = k\n        self.vector = [False] * m \n        self.hash_fun = hash_fun\n\n    def insert(self, key):\n        for i in range(self.k):\n            self.vector[self.hash_fun(key+str(i))%self.m]=True\n\n    def contains(self, key):\n        for i in range(self.k):\n            if self.vector[self.hash_fun(key+str(i))%self.m]==False:\n                return False\n        return True\n    \n    def list_insert(self, keys):\n        for k in keys:\n            self.insert(k)\n            \n    def list_contains(self, keys):\n        time_start = time.time()\n        cnt = 0\n        for q in keys:\n            cnt += 1 if model.contains(q) else 0\n        t = time.time() - time_start\n        return cnt, t\n    \ndef linear_whether_in(dataset, queries):\n    time_start = time.time()\n    cnt = 0\n    for q in queries:\n        cnt += 1 if q in dataset else 0\n    t = time.time() - time_start\n    return cnt, t\n\nmodel = Bloom(m=1000000, k=10, hash_fun=hash)\nmodel.list_insert(word_list)\n    \ncnt_neg, time_neg_bloom = model.list_contains(neg_reviews[:1000])\n_, time_neg = linear_whether_in(word_list, neg_reviews[:1000])\nprint(\"[neg_reviews[:1000]] BLOOM:{}\/{}, Actual:{}\/{}, BLOOM Time:{}, Linear Time:{}\".format(\n    cnt_neg, len(neg_reviews), cnt_neg, len(neg_reviews), time_neg_bloom, time_neg))\n\ncnt_pos, time_pos_bloom = model.list_contains(pos_reviews[:1000])\n_, time_pos = linear_whether_in(word_list, pos_reviews[:1000])\nprint(\"[pos_reviews[:1000]] BLOOM:{}\/{}, Actual:{}\/{}, BLOOM Time:{}, Linear Time:{}\".format(\n    cnt_pos, len(pos_reviews), cnt_pos, len(pos_reviews), time_pos_bloom, time_pos))","c1605f19":"def false_positive(data, keys, m, k):\n    word_dict = defaultdict(bool)\n    for d in data:\n        word_dict[d] = True\n            \n    model = Bloom(m=m, k=k, hash_fun=hash)\n    model.list_insert(data)\n    false_pos = 0\n    for k in keys:\n        false_pos += 1 if model.contains(k) and not word_dict[k] else 0\n    return false_pos\n\ntrials = [(1000000, 1), (1000000, 10), (1000000, 100), (100000, 10), (10000, 10)]\nfor m,k in trials:\n    fp = false_positive(word_list, neg_reviews[:1000], m=m, k=k)\n    print(\"[neg_reviews] m:{}, k:{}, Total:{}, False-Positive:{}\".format(m, k, len(neg_reviews), fp))\n","3b519ecb":"from collections import Counter\nimport time\n\ndef fast_counts(word_list):\n    C = Counter(word_list)\n    return C\n\nC_neg = fast_counts(neg_reviews)\nprint(\"[neg_reviews] the:{}\".format(C_neg['the']))\n\nC_pos = fast_counts(pos_reviews)\nprint(\"[pos_reviews] the:{}\".format(C_pos['the']))","81f58a85":"class CM:\n    def __init__(self, w, d, hash_fun):\n        self.count = [[0 for _ in range(w)] for _ in range(d)]\n        self.hash = hash_fun\n        self.max = d\n        \n        \n    def update(self, stream):\n        self.max *= len(stream)\n        for s in stream:\n            for i in range(d):\n                self.count[i][self.hash(s+str(i))%w] += 1\n                \n    def check(self, s):\n        ans = self.max\n        for i in range(d):\n            ans = min(ans, self.count[i][self.hash(s+str(i))%w])\n        return ans\n\nexperiments = [(10, 1), (100, 1), (1000, 1), (1000, 10), (1000, 20), (10000, 10)]\nfor w, d in experiments:\n    model = CM(w=w, d=d, hash_fun=hash)\n    model.update(neg_reviews)\n    print(\"[neg_reviews: 'the'] CM:{}, Actual:{}, w:{}, d:{}\".format(model.check('the'), C_neg['the'], w, d))","41eedd83":"def error(C, model):\n    err = 0\n    eps = 1e-9\n    for key in C.keys():\n        err += (model.check(key) - C[key])\/(C[key]+eps)\n    return err\/len(C.keys())\n\nexperiments = [(10000, 1), (10000, 5), (10000, 10), (100000, 10), (1000, 10), (100, 10)]\n\nfor w, d in experiments:\n    model = CM(w=w, d=d, hash_fun=hash)\n    model.update(neg_reviews)\n    print(\"[neg_reviews] Average error:{}, w:{}, d:{}\".format(error(C_neg,model), w, d))\n\nprint()\nfor w, d in experiments:\n    model = CM(w=w, d=d, hash_fun=hash)\n    model.update(pos_reviews)\n    print(\"[pos_reviews] Average error:{}, w:{}, d:{}\".format(error(C_pos,model), w, d))","2d17ce65":"Let's see the influence of different w and d on the error. We calculate the mean error on $K$ queries as follows\n$$\nerror_{mean} = \\frac{1}{K}\\sum_{key} \\frac{CM(key)-Count(key)}{Count(key)}\n$$","8a222279":"## **Task1\uff1aDGIM**\n\nDGIM is an efficient algorithm in processing large streams. When it's infeasible to store the flowing binary stream, DGIM can estimate the number of 1-bits in the window. In this coding, you're given the stream_data_dgim.txt (binary stream), and you need to implement the DGIM algorithm to count the number of 1-bits. Write code below.","319ccd5b":"### Data loading:\n\nFrom the NLTK (Natural Language ToolKit) library, we import a large list of English dictionary words, commonly used by the very first spell-checking programs in Unix-like operating systems.","33f4c5ee":"### 3. Write a function that accurately counts the number of 1-bits in the current window. Caculate the accuracy of your own DGIM algorithm and compare the running time difference.","2cdb7d10":"Then we load another dataset from the NLTK Corpora collection: movie_reviews.\n\nThe movie reviews are categorized between positive and negative, so we construct a list of words (usually called bag of words) for each category.","bca4dad9":"## **Task2: Bloom Filter**\n\nA Bloom filter is a space-efficient probabilistic data structure. Here the task is to implement a bloom filter by yourself. ","5a9d580a":"# EE359-Coursework 4  Streaming Algorithm - Jin Gao","51fced3f":"## **Task3: Count-Min sketch**\n\n","c87c0447":"### 2. Implement the Count-Min sketch by yourself. Set different width w and depth d of the internal data structure of CM-Sketch. Compare the influence of different w and d on the error.","f2914fa4":"### 2. With the window size 1000, count the number of 1-bits in the last 500 and 200 bits of the bitstream.","7df260e3":"### 1. Set the window size to 1000, and count the number of 1-bits in the current window.","9d14cb35":"Here we get a data stream (word_list) and 2 query lists (neg_reviews and pos_reviews).","1221cd24":"### 3. Use different bit array length \u2018m\u2019 and number of hash functions \u2018k\u2019 to implement the bloom filter algorithm. Then compare the impact of different m and k on the false positive rate.","e27b44ed":"In computing, the count\u2013min sketch (CM sketch) is a probabilistic data structure that serves as a frequency table of events in a stream of data. ","c0b85255":"Here we use the query stream (neg_reviews or pos_reviews) from task 2.","78bf13eb":"### 1. Write a function that accurately counts the occurrence times of each word in neg_reviews or pos_reviews.","1697c10b":" ### 2. Implement the bloom filter by yourself and add all words in word_list in your bloom filter. Compare the running time difference between linear search on a list and multiple hash computations in a Bloom filter.","2f16cead":"### 1. Write a function that accurately determines whether each word in neg_reviews and pos_reviews belongs to word_list."}}