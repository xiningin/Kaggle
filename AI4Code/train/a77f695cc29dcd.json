{"cell_type":{"8153c1e4":"code","9548978b":"code","36946a67":"code","d880978e":"code","5c52e8dc":"code","a629e027":"code","e4aa3e87":"code","0d8504c5":"code","71cbc3eb":"code","fb105ca7":"code","4ec70780":"code","06da84a1":"code","28634e05":"code","0b14520b":"code","37c0771b":"markdown","937e97e3":"markdown","ee3c9159":"markdown"},"source":{"8153c1e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9548978b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Input,Conv2D,Dense,BatchNormalization,ReLU,Flatten,Reshape,Conv2DTranspose,Activation\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.utils import plot_model","36946a67":"(train_data,train_label), (test_data,test_label) = keras.datasets.mnist.load_data()\nprint(f\"Shape of train dataset >> {train_data.shape}\")\nprint(f\"Shape of test dataset >> {test_data.shape}\")","d880978e":"train_data = train_data.reshape((-1,28,28,1))\ntest_data = test_data.reshape((-1,28,28,1))\nprint(f\"Shape of train dataset >> {train_data.shape}\")\nprint(f\"Shape of test dataset >> {test_data.shape}\")","5c52e8dc":"print(np.max(train_data))\nprint(np.min(train_data))\ntrain_data = train_data \/255.0\ntest_data = test_data \/ 255.0\nprint(np.max(train_data))","a629e027":"train_label = train_data\ntest_label = test_data","e4aa3e87":"#Encoder (Original data -> latent vector)\n\nencoder_X = Input(shape=(28,28,1))\n\nencoder_H = Conv2D(32,3,strides=1,padding='same')(encoder_X)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = ReLU()(encoder_H)\n\nencoder_H = Conv2D(64,3,strides=2,padding='same')(encoder_H)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = ReLU()(encoder_H)\n\nencoder_H = Conv2D(64,3,strides=2,padding='same')(encoder_H)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = ReLU()(encoder_H)\n\nencoder_H = Conv2D(64,3,strides=1,padding='same')(encoder_H)\nencoder_H = BatchNormalization()(encoder_H)\nencoder_H = ReLU()(encoder_H)\n\nshape_before_flatten = K.int_shape(encoder_H)\nprint(\"Encoder\/ shape before flattening >>\",shape_before_flatten)\nencoder_H = Flatten()(encoder_H)\nshape_after_flatten = K.int_shape(encoder_H)\nprint(\"Encoder\/ shape after flattening >>\",shape_after_flatten)\nencoder_Y = Dense(2)(encoder_H)\n\nencoder = Model(encoder_X,encoder_Y)\n\n\n# decoder\ndecoder_X = Input(shape=(2,))\n\ndecoder_H = Dense(shape_after_flatten[1])(decoder_X)\ndecoder_H = Reshape(shape_before_flatten[1:])(decoder_H)\n\ndecoder_H = Conv2DTranspose(64,3,strides=1,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_H = ReLU()(decoder_H)\n\ndecoder_H = Conv2DTranspose(64,3,strides=2,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_H = ReLU()(decoder_H)\n\ndecoder_H = Conv2DTranspose(32,3,strides=2,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_H = ReLU()(decoder_H)\n\ndecoder_H = Conv2DTranspose(1,3,strides=1,padding='same')(decoder_H)\ndecoder_H = BatchNormalization()(decoder_H)\ndecoder_Y = Activation('sigmoid')(decoder_H)\n\ndecoder = Model(decoder_X,decoder_Y)","0d8504c5":"model_input = encoder_X\nmodel_output = decoder(encoder_Y)\nmodel = Model(model_input,model_output)\n\nmodel.compile(loss='mse',optimizer='adam')\n\nprint(model.summary())\nplot_model(model)","71cbc3eb":"history = model.fit(train_data,train_label,batch_size=128,epochs=1000,shuffle=True)","fb105ca7":"idx= [52,192,1621,2411,8888,4009]\ntrain_samples = train_data[idx]\ntest_samples = test_data[idx]\n\ntrain_results = model.predict(train_samples)\ntest_results = model.predict(test_samples)","4ec70780":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nplt.figure(figsize=(10,10))\nfor i,k in enumerate(idx):\n    plt.subplot(4,3,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_results[i],cmap=plt.cm.binary)\nfor i,k in enumerate(idx):\n    plt.subplot(4,3,i+1+6)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_samples[i],cmap=plt.cm.binary)\nplt.show()","06da84a1":"plt.figure(figsize=(10,10))\nfor i,k in enumerate(idx):\n    plt.subplot(4,3,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_results[i],cmap=plt.cm.binary)\nfor i,k in enumerate(idx):\n    plt.subplot(4,3,i+1+6)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_samples[i],cmap=plt.cm.binary)\nplt.show()","28634e05":"(_,train_label),(_,test_label) = keras.datasets.mnist.load_data()\n\nplt.figure(figsize=(16,16))\n\ncolors=['red','pink','orange','blue','purple','black','brown','green','olive','lavender']\nfor i in range(0,10):\n    mask = train_label==i\n    train_x = train_data[mask]\n    train_x = train_x[0:400]\n    train_z = encoder.predict(train_x)\n    plt.scatter(train_z[:,0],train_z[:,1],c=colors[i],alpha=0.2)\nplt.show()","0b14520b":"plt.figure(figsize=(16,16))\n\ncolors=['red','pink','orange','blue','purple','black','brown','green','olive','lavender']\nfor i in range(0,10):\n    mask = test_label==i\n    test_x = test_data[mask]\n    test_x = test_x[0:400]\n    test_z = encoder.predict(test_x)\n    plt.scatter(test_z[:,0],test_z[:,1],c=colors[i],alpha=0.2)\nplt.show()","37c0771b":"**AE(Auto-Encoder) Model using convolution layers**","937e97e3":"**Visualizing latent space(Train data used)** ","ee3c9159":"**Visualize latent vectors (different colors for different classes)**"}}