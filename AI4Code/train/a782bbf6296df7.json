{"cell_type":{"001e38fe":"code","053c7cf5":"code","0ef69fd1":"code","cd7d5ded":"code","118c67c6":"code","00dacd67":"code","65f8563a":"code","fc314107":"code","d67addd9":"code","db97884c":"code","7556ef6e":"code","8e2c7e9a":"code","b4c642ec":"code","88cc43d4":"code","14443916":"code","82af205b":"code","59d99d95":"code","e92e96f7":"code","24d86375":"code","cc71c8b3":"code","6321d27a":"code","4270fde9":"code","c75cfff2":"code","0e05831f":"code","fdabf272":"markdown","d999bd74":"markdown","8dab44d3":"markdown","77c7cc69":"markdown","53f3405a":"markdown","b60ae0e6":"markdown","158017d2":"markdown","438d9a3d":"markdown","ff405271":"markdown","554228c7":"markdown","ded95c50":"markdown","d021f345":"markdown"},"source":{"001e38fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plot\nfrom scipy.stats import norm\n\nfrom sklearn.preprocessing import StandardScaler as Zscore\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split as DataSplit\nfrom sklearn.multiclass import OneVsRestClassifier\n\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.svm import SVC as SVM\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.naive_bayes import GaussianNB as NB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import shuffle\n\nfrom keras.utils import np_utils\nfrom scipy import stats\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","053c7cf5":"data = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndata.head()","0ef69fd1":"data.columns","cd7d5ded":"data.shape","118c67c6":"data.dtypes","00dacd67":"data[\"Species\"].value_counts()","65f8563a":"# iris = data\nencoder = LabelEncoder()\nY = data.Species\nencoded_Y = encoder.fit_transform(Y)\n\ny = np_utils.to_categorical(encoded_Y)\ny = pd.DataFrame(data=y, columns=['Iris-setosa','Iris-versicolor','Iris-virginica'])\n\ny1 = y.head(3)\ny2 = y.tail(3)\nconc_y = pd.concat([y1, y2],axis = 0, ignore_index=True)\nconc_y","fc314107":"X = data.drop(['Id'], axis=1)\n\nX_train, X_test, y_train, y_test = DataSplit(X,y,test_size=0.33)\nTrainset = pd.concat([X_train, y_train],axis = 1)\nTestset = pd.concat([X_test, y_test],axis = 1)","d67addd9":"iris = Trainset.drop(['Iris-setosa','Iris-versicolor','Iris-virginica'], axis=1)\nX_train = X_train.drop(['Species'], axis=1)\nX_test = X_test.drop(['Species'], axis=1)","db97884c":"iris.head(10) # Training set","7556ef6e":"iris_test = Testset.drop(['Iris-setosa','Iris-versicolor','Iris-virginica'], axis=1)\niris_test.to_csv('testset.csv',index=False)\niris_test.head(10)","8e2c7e9a":"iris[\"SepalLengthCm\"].describe() # Describe a variable ","b4c642ec":"iris.Species.value_counts() # Counts ","88cc43d4":"plot.figure(figsize=(15,10))\n\nplot.subplot(2,2,1)\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-virginica\"].SepalLengthCm, bins=5, fc=(1,0,0,0.3), label=\"Virginica\")\nver = plot.hist(iris[iris[\"Species\"] == \"Iris-versicolor\"].SepalLengthCm, bins=5, fc=(0,1,0,0.3), label=\"Versicolor\")\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-setosa\"].SepalLengthCm, bins=5, fc=(0,0,1,0.3), label=\"Setosa\")\nplot.legend()\nplot.xlabel(\"Sepal Length (cm)\")\nplot.ylabel(\"Frequency\")\n\nplot.subplot(2,2,2)\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-virginica\"].SepalWidthCm, bins=5, fc=(1,0,0,0.3), label=\"Virginica\")\nver = plot.hist(iris[iris[\"Species\"] == \"Iris-versicolor\"].SepalWidthCm, bins=5, fc=(0,1,0,0.3), label=\"Versicolor\")\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-setosa\"].SepalWidthCm, bins=5, fc=(0,0,1,0.3), label=\"Setosa\")\nplot.legend()\nplot.xlabel(\"Sepal Width (cm)\")\nplot.ylabel(\"Frequency\")\n\nplot.subplot(2,2,3)\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-virginica\"].PetalLengthCm, bins=5, fc=(1,0,0,0.3), label=\"Virginica\")\nver = plot.hist(iris[iris[\"Species\"] == \"Iris-versicolor\"].PetalLengthCm, bins=5, fc=(0,1,0,0.3), label=\"Versicolor\")\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-setosa\"].PetalLengthCm, bins=5, fc=(0,0,1,0.3), label=\"Setosa\")\nplot.legend()\nplot.xlabel(\"Petal Length (cm)\")\nplot.ylabel(\"Frequency\")\n\nplot.subplot(2,2,4)\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-virginica\"].PetalWidthCm, bins=5, fc=(1,0,0,0.3), label=\"Virginica\")\nver = plot.hist(iris[iris[\"Species\"] == \"Iris-versicolor\"].PetalWidthCm, bins=5, fc=(0,1,0,0.3), label=\"Versicolor\")\nvir = plot.hist(iris[iris[\"Species\"] == \"Iris-setosa\"].PetalWidthCm, bins=5, fc=(0,0,1,0.3), label=\"Setosa\")\nplot.legend()\nplot.xlabel(\"Petal Width (cm)\")\nplot.ylabel(\"Frequency\")\n\nplot.show()\nplot.savefig('histogram.png')","14443916":"plot.figure(figsize=(15,10))\n\nplot.subplot(2,3,1)\nsns.scatterplot(x = iris.SepalLengthCm, y=iris.SepalWidthCm, hue = \"Species\", data = iris)\nplot.legend()\nplot.xlabel(\"SepalLengthCm\")\nplot.ylabel(\"SepalWidthCm\")\n\nplot.subplot(2,3,2)\nsns.scatterplot(x = iris.SepalLengthCm, y=iris.PetalLengthCm, hue = \"Species\", data = iris)\nplot.legend()\nplot.xlabel(\"SepalLengthCm\")\nplot.ylabel(\"PetalLengthCm\")\n\nplot.subplot(2,3,3)\nsns.scatterplot(x = iris.SepalLengthCm, y=iris.PetalWidthCm, hue = \"Species\", data = iris)\nplot.legend()\nplot.xlabel(\"SepalLengthCm\")\nplot.ylabel(\"PetalWidthCm\")\n\nplot.subplot(2,3,4)\nsns.scatterplot(x = iris.SepalWidthCm, y=iris.PetalLengthCm, hue = \"Species\", data = iris)\nplot.legend()\nplot.xlabel(\"SepalWidthCm\")\nplot.ylabel(\"PetalLengthCm\")\n\nplot.subplot(2,3,5)\nsns.scatterplot(x = iris.SepalWidthCm, y=iris.PetalWidthCm, hue = \"Species\", data = iris)\nplot.legend()\nplot.xlabel(\"SepalWidthCm\")\nplot.ylabel(\"PetalWidthCm\")\n\nplot.subplot(2,3,6)\nsns.scatterplot(x = iris.PetalLengthCm, y=iris.PetalWidthCm, hue = \"Species\", data = iris)\nplot.legend()\nplot.xlabel(\"PetalLengthCm\")\nplot.ylabel(\"PetalWidthCm\")\nplot.show()\nplot.savefig('scatter.png')\n","82af205b":"print(iris)","59d99d95":"plot.figure(figsize=(10,10))\n\nplot.subplot(2,1,1)\nmelted_iris = pd.melt(iris, id_vars = \"Species\", value_vars = list(iris.columns[0:4]))\nsns.boxplot(x = \"variable\", y=\"value\", hue = \"Species\", data = melted_iris)\nplot.grid()\n\nplot.subplot(2,1,2)\nmelted_iris = pd.melt(iris, id_vars = \"Species\", value_vars = list(iris.columns[0:4]))\nsns.violinplot(x = \"variable\", y=\"value\", hue = \"Species\", data = melted_iris)\nplot.grid()\nplot.show()\nplot.savefig('Boxplot.png')","e92e96f7":"# sns.pairplot(iris.drop(\"Id\", axis=1), hue = \"Species\", size = 3) # Simple version\n\nsns.set(style = \"white\")\ndf = iris.loc[:,list(iris.columns[1:6])]\ng = sns.PairGrid(df,diag_sharey = False, hue=\"Species\", data=iris)\ng.map_lower(sns.kdeplot, camp=\"Blues_d\")\ng.map_upper(plot.scatter)\ng.map_diag(sns.kdeplot, lw = 3)\nplot.savefig('Pairplot.png')\nplot.show()","24d86375":"f, ax = plot.subplots(figsize = (5,5))\nsns.heatmap(iris.corr(), annot = True, linewidth = 0.5, fmt = \".1f\", ax = ax)\nplot.xticks(rotation = 90)\nplot.yticks(rotation = 1)\nplot.title('corrleation Map')\nplot.savefig('heatmap_Pearson.png')\nplot.show()","cc71c8b3":"ranked_data = iris.rank()\nf, ax = plot.subplots(figsize = (5,5))\nsns.heatmap(ranked_data.corr(), annot = True, linewidth = 0.5, fmt = \".1f\", ax = ax)\nplot.xticks(rotation = 90)\nplot.yticks(rotation = 1)\nplot.title('corrleation Map')\nplot.savefig('heatmap_Spearman.png')\nplot.show()","6321d27a":"total = iris.isnull().sum().sort_values(ascending=False)\npercent = (iris.isnull().sum()\/iris.isnull().count()).sort_values(ascending=False)\n\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'])\nmissing_data.head()","4270fde9":"# # Dealing with missing data (Not used in this article)\n# df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\n# df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n# df_train.isnull().sum().max() #just checking that there's no missing data missing...","c75cfff2":"def train_and_test(model):\n    model = OneVsRestClassifier(model).fit(X_train,y_train)\n    prediction = model.predict(X_test)\n    accuracy = round(accuracy_score(prediction,y_test)*100, 2) # .2f\n    print(\"Model:\",model,\" Training_accuracy: \", accuracy, \"%\")\n    return accuracy\n\n\n# Logistic regression\nLR_pred = train_and_test(LR())\n\n# SVM\nSVM_pred = train_and_test(SVM())\n\n# KNN\nKNN_pred = train_and_test(KNN(n_neighbors = 4))\n\n# Random forest\nRF_pred = train_and_test(RF(n_estimators=100))\n\n# Naive Bayes\nNB_pred = train_and_test(NB())\n\n","0e05831f":"# Generate the output to *.csv format\nprint('The highest accuracy: ',RF_pred,\" %\")","fdabf272":"# 4. Train the models","d999bd74":"# 2. Data analysis - (5) Pearson's correlation","8dab44d3":"# 2. Data analysis\n\n**This section analyze the training dataset.**  **Testset should be unseen data**","77c7cc69":"# Data split","53f3405a":"# Data Encoding","b60ae0e6":"# 3. Missing data","158017d2":"# 2. Data analysis - (2) Scatter plot","438d9a3d":"# 2. Data analysis - (3) Box plot","ff405271":"# 2. Data analysis - (4) Pairplot","554228c7":"# 2. Data analysis - (6) Spearman's rank correlation","ded95c50":"# 1. Data load","d021f345":"# 2. Data analysis - (1) Histogram"}}