{"cell_type":{"42fd575c":"code","2459087d":"code","fc46ac58":"code","2e4e64e8":"code","908ef65f":"code","6df12b96":"code","d56de754":"code","a671828e":"code","81a4a12f":"code","a1c9b48e":"code","9961b60d":"code","e0d5518f":"code","4c494430":"code","3850d4fc":"code","f0efa753":"code","f66e8259":"code","120315d2":"markdown","aa7ec5d3":"markdown","f9909e44":"markdown","13b3f125":"markdown","7133d5e3":"markdown","1c8a8ed3":"markdown","0b18b597":"markdown","65998fd9":"markdown"},"source":{"42fd575c":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sns\nimport os\nimport shutil\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import Callback, TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Add, Dropout, ReLU, BatchNormalization, Input, Lambda\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.metrics import Recall, Precision, AUC \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nsns.set()\nimport tensorflow as tf\n","2459087d":"PATH = '\/kaggle\/input\/breast-histopathology-images'\nfolders = os.listdir('\/kaggle\/input\/breast-histopathology-images')\nfolders.sort()\nfolders.remove('IDC_regular_ps50_idx5')","fc46ac58":"def get_x_y(string):\n    _, _, x, y, c = string.split('_')\n    return [int(x[1:]), int(y[1:]), int(c[-5])]\n\ndef getImg(Pid):\n    base = os.path.join(PATH, Pid)\n    stringList = []\n    stringList.extend(base + '\/0\/' + s for s in os.listdir(base + '\/0'))\n    stringList.extend(base + '\/1\/' + s for s in os.listdir(base + '\/1'))\n    length = len(stringList)\n    \n    index = np.zeros((length, 3), dtype = np.int32)   \n    smallImg = 255*np.ones((length, 50, 50, 3), dtype = np.int8)\n    \n    for i in range(length):\n        index[i] = get_x_y(stringList[i])\n        tempImg = Image.open(stringList[i])\n        \n        if tempImg.size != (50,50):\n            smallImg[i, :tempImg.size[1], :tempImg.size[0]] = np.array(tempImg)\n        else : \n            smallImg[i] = np.array(tempImg)\n            \n    maxVal = np.max(index, axis = 0)\n    fullImg = 255 * np.ones((maxVal[1] + 50, maxVal[0] + 50, 4), dtype = np.int8)\n    for i in range(length):\n        x, y, c = index[i]\n        fullImg[y : y+50, x : x+50, :3] = smallImg[i]\n        if c == 0:\n            fullImg[y : y+50, x : x+50, 3] = 150\n    return fullImg\n\ndef viewImg():\n    idx = np.random.randint(0,high = len(folders))\n    basePath = os.path.join(PATH, folders[idx])\n    imgs0 = os.listdir(os.path.join(basePath, '0'))\n    imgs1 = os.listdir(os.path.join(basePath, '1'))\n    base0 = os.path.join(basePath,'0')\n    base1 = os.path.join(basePath,'1')\n    idx0 = np.random.choice(np.arange(len(imgs0)), size = 25)\n    idx1 = np.random.choice(np.arange(len(imgs1)), size = 25)\n    \n    print('Few negative image of Pacitent ID ' + str(folders[idx]))\n    plt.figure(figsize = [9,9])\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.imshow(Image.open(os.path.join(base0, imgs0[idx0[i]])))\n    plt.show()\n    \n    print('Few positive image of Pacitent ID ' + str(folders[idx]))\n    plt.figure(figsize = [9,9])\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.imshow(Image.open(os.path.join(base1, imgs1[idx1[i]])))\n    plt.show()\nviewImg()\n    \ndef viewRandom9():\n    idx = np.random.choice(np.arange(len(folders)) ,size = 9)\n    plt.figure(figsize = [16,16])\n    for i in range(9):        \n        plt.subplot(3,3, i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(str(folders[idx[i]]))\n        plt.imshow(getImg(folders[idx[i]]))\n\nviewRandom9()","2e4e64e8":"def splitData(folders, trainingData, testData, valData):\n    \"\"\"\n    folders : list of folders\n    train\/test\/valDataFraction : fraction of train\/test\/valDataFraction\n    \"\"\"\n    PATH = '\/kaggle\/input\/breast-histopathology-images'\n    length = len(folders)\n    \"\"\"os.mkdir('\/kaggle\/temp')\n    OutputPath = '\/kaggle\/temp'\n    \n    os.mkdir(os.path.join(OutputPath, 'train'))\n    os.mkdir(os.path.join(OutputPath, 'test')) \n    os.mkdir(os.path.join(OutputPath, 'val'))\n    \n    trainDir = os.path.join(OutputPath, 'train')\n    testDir = os.path.join(OutputPath, 'test')\n    valDir = os.path.join(OutputPath, 'val')\n    \n    os.mkdir(os.path.join(trainDir, '0'))\n    os.mkdir(os.path.join(trainDir, '1'))\n    trainDir0 = os.path.join(trainDir, '0')\n    trainDir1 = os.path.join(trainDir, '1')\n    \n    os.mkdir(os.path.join(testDir, '0'))\n    os.mkdir(os.path.join(testDir, '1'))\n    testDir0 = os.path.join(testDir, '0')\n    testDir1 = os.path.join(testDir, '1')\n    \n    os.mkdir(os.path.join(valDir, '0'))\n    os.mkdir(os.path.join(valDir, '1'))\n    valDir0 = os.path.join(valDir, '0')\n    valDir1 = os.path.join(valDir, '1')\n\"\"\"\n    trainDF = valDF = testDF = pd.DataFrame(columns = ['img', 'lable'])\n    index = np.arange(length)\n    np.random.shuffle(index)\n    \n    for i in range(int(trainingData * length)):\n        folder = os.path.join(PATH, folders[index[i]])\n        src0 = os.path.join(folder, '0')\n        src1 = os.path.join(folder, '1')\n        \n        lst0 = [os.path.join(src0, f) for f in os.listdir(src0)]\n        lst1 = [os.path.join(src1, f) for f in os.listdir(src1)]\n        df0 = pd.DataFrame(list(zip(lst0, np.zeros(len(lst0), dtype = np.int8))), columns = trainDF.columns)\n        df1 = pd.DataFrame(list(zip(lst1, np.ones(len(lst1), dtype = np.int8))), columns = trainDF.columns)\n        trainDF = trainDF.append(df0, ignore_index = True)\n        trainDF = trainDF.append(df1, ignore_index = True)\n        \n        \n    for i in range(int(trainingData * length), int((testData + trainingData)* length)):\n        folder = os.path.join(PATH, folders[index[i]])\n        src0 = os.path.join(folder, '0')\n        src1 = os.path.join(folder, '1')\n        \n        \n        lst0 = [os.path.join(src0, f) for f in os.listdir(src0)]\n        lst1 = [os.path.join(src1, f) for f in os.listdir(src1)]\n        df0 = pd.DataFrame(list(zip(lst0, np.zeros(len(lst0), dtype = np.int8))), columns = trainDF.columns)\n        df1 = pd.DataFrame(list(zip(lst1, np.ones(len(lst1), dtype = np.int8))), columns = trainDF.columns)\n        valDF = valDF.append(df0, ignore_index = True)\n        valDF = valDF.append(df1, ignore_index = True)\n    \n    for i in range(int((testData + trainingData)* length), length):\n        folder = os.path.join(PATH, folders[index[i]])\n        src0 = os.path.join(folder, '0')\n        src1 = os.path.join(folder, '1')\n        \n        lst0 = [os.path.join(src0, f) for f in os.listdir(src0)]\n        lst1 = [os.path.join(src1, f) for f in os.listdir(src1)]\n        df0 = pd.DataFrame(list(zip(lst0, np.zeros(len(lst0), dtype = np.int8))), columns = trainDF.columns)\n        df1 = pd.DataFrame(list(zip(lst1, np.ones(len(lst1), dtype = np.int8))), columns = trainDF.columns)\n        testDF = testDF.append(df0, ignore_index = True)\n        testDF = testDF.append(df1, ignore_index = True)\n        \n    trainDF['lable'] = trainDF['lable'].astype('str')\n    valDF['lable'] = valDF['lable'].astype('str')\n    testDF['lable'] = testDF['lable'].astype('str')\n    \n    print(trainDF.info())\n    print(valDF.info())\n    print(testDF.info())\n    return trainDF, valDF, testDF\n        \n\ntrainDF, valDF, testDF = splitData(folders, 0.8, 0.1, 0.1)\n","908ef65f":"logdir = 'logs'\n\nclass My_callback(Callback):\n    def on_epoch_end(self, epoch, logs = {}):\n        if (logs['acc'] > 0.93):\n            self.model.stop_training = True    \n\nesCallback = EarlyStopping(monitor = 'acc', patience = 3)\nmcCallback = ModelCheckpoint(filepath = 'modelOn.hdf5', monitor = 'val_loss', save_best_only = True)\nlrCallback = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3)\ntbCallback = TensorBoard(log_dir = logdir)\ncsCallback = My_callback()","6df12b96":"\ntrainDataGen = ImageDataGenerator(rescale = 1.\/255,\n                                 horizontal_flip = True,\n                                 vertical_flip = True)\nvalDataGen = ImageDataGenerator(rescale = 1.\/255)\n\ntrainFlow = trainDataGen.flow_from_dataframe(trainDF, x_col = 'img', y_col = 'lable', \n                                             class_mode = 'binary', \n                                             target_size = (50,50), \n                                             validate_filenames = False)\n\nvalFlow = valDataGen.flow_from_dataframe(valDF, x_col = 'img', y_col = 'lable', \n                                         class_mode = 'binary', \n                                         target_size = (50,50), \n                                         validate_filenames = False)\n\ntestFlow = valDataGen.flow_from_dataframe(testDF, x_col = 'img', y_col = 'lable', \n                                          class_mode = 'binary', \n                                          target_size = (50,50), \n                                          validate_filenames = False)","d56de754":"def resNet(layer, filterIn, filterOut, conv, block, isFirst):\n    \n    if isFirst: \n        x = Conv2D(filterIn, (1,1), (2,2), name = conv + '_' + block + '_1')(layer)\n        x = BatchNormalization(name = conv + '_' + block + '_1_' + 'Norm', trainable = True)(x)\n        x = ReLU(name = conv + '_' + block + '_1_' + 'ReLU')(x)\n        \n        x = Conv2D(filterIn, (3,3), padding='same', name = conv + '_' + block + '_2')(x)\n        x = BatchNormalization(name = conv + '_' + block + '_2_' + 'Norm', trainable = True)(x)\n        x = ReLU(name = conv + '_' + block + '_2_' + 'ReLU')(x)\n        \n        x = Conv2D(filterOut, (1,1), name = conv + '_' + block + '_3')(x)\n        x = BatchNormalization(name = conv + '_' + block + '_3_' + 'Norm', trainable = True)(x)\n        \n        y = Conv2D(filterOut,(1,1), (2,2), name = conv + '_' + block + '_0')(layer)\n        y = BatchNormalization(name = conv + '_' + block + '_0_' + 'Norm', trainable = True)(y)\n        \n    else:\n        x = Conv2D(filterIn, (1,1), name = conv + '_'+ block + '_1')(layer)\n        x = BatchNormalization(name = conv + '_' + block + '_1_' + 'Norm', trainable = True)(x)\n        x = ReLU(name = conv + '_' + block + '_1_' + 'ReLU')(x)\n        \n        x = Conv2D(filterIn, (3,3), name = conv + '_'+ block + '_2', padding='same')(x)\n        x = BatchNormalization(name = conv + '_' + block + '_2_' + 'Norm', trainable = True)(x)\n        x = ReLU(name = conv + '_' + block + '_2_' + 'ReLU')(x)\n        \n        x = Conv2D(filterOut, (1,1), name = conv + '_'+ block + '_3')(x)\n        x = BatchNormalization(name = conv + '_' + block + '_3_' + 'Norm', trainable = True)(x)\n        \n        y = layer\n        \n    out = Add()([x,y])\n    out = ReLU(name = conv + '_' + block + '_final_' + 'ReLU')(out)\n    return out\n\ndef resNetAll(blockFilter, nosOfblock, layer_):\n    x = layer_\n    for i in range(len(blockFilter)-1):\n        for j in range(nosOfblock[i]):\n            if j == 0:\n                x = resNet(x, blockFilter[i], blockFilter[i+1], 'conv' + str(i+1), 'block' + str(j+1), True)\n            else:\n                x = resNet(x, blockFilter[i], blockFilter[i+1], 'conv' + str(i+1), 'block' + str(j+1), False)\n    \n    return x \n            \n\ninputs = (None, None, 3)\ninp = Input(inputs)\nx = Conv2D(16, (3,3), padding= 'same', name = 'InitialInput')(inp)\nx = BatchNormalization(name = 'InitialBatch',trainable = True)(x)\nx = ReLU(name = 'InitialReLU')(x)\nx = resNetAll([32, 32, 64, 64], [3,5,5], x)\nx = Conv2D(512, (7,7))(x)\nx = BatchNormalization(trainable = True)(x)\nx = ReLU()(x)\nx = Conv2D(16, (1,1))(x)\nx = BatchNormalization(trainable = True)(x)\nx = ReLU()(x)\nx = Conv2D(1, (1,1), activation = 'sigmoid')(x)\nx = Lambda(lambda x: K.reshape(x,shape =  [-1, 1]))(x)\nmodel = Model(inp, x)\nmodel.compile('adam','binary_crossentropy' ,['acc','mse', Precision(), Recall(), AUC(),])","a671828e":"totalOnes = np.sum(trainDF['lable'].astype('int'))\ntotalZeros = len(trainDF) - totalOnes\nzeroClass, oneClass = totalOnes\/ (totalOnes + totalZeros), totalZeros \/ (totalOnes + totalZeros)\nweightDist = {0 : zeroClass, 1 : oneClass}","81a4a12f":"\nhistory = model.fit(trainFlow,\n                   epochs = 30,\n                   callbacks = [tbCallback,csCallback, lrCallback, esCallback, mcCallback],\n                   class_weight = weightDist,\n                   steps_per_epoch = 5000,\n                   validation_data = valFlow,\n                )\nmodel.save('\/kaggle\/working\/model.h5')   ","a1c9b48e":"plt.figure()\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","9961b60d":"plt.figure()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","e0d5518f":"plt.figure()\nplt.plot(history.history['mse'])\nplt.plot(history.history['val_mse'])\nplt.title('model MSE')\nplt.ylabel('MSE')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","4c494430":"plt.figure()\nplt.plot(history.history['precision'])\nplt.plot(history.history['val_precision'])\nplt.title('model precision')\nplt.ylabel('precision')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","3850d4fc":"plt.figure()\nplt.plot(history.history['recall'])\nplt.plot(history.history['val_recall'])\nplt.title('model recall')\nplt.ylabel('recall')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","f0efa753":"plt.figure()\nplt.plot(history.history['auc'])\nplt.plot(history.history['val_auc'])\nplt.title('model auc')\nplt.ylabel('auc')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","f66e8259":"res = model.evaluate(testFlow)\nprint(\"Model loss      on testDataset \" + str(res[0]))\nprint(\"Model acc       on testDataset \" + str(res[1]))\nprint(\"Model mse       on testDataset \" + str(res[2]))\nprint(\"Model precision on testDataset \" + str(res[3]))\nprint(\"Model recall    on testDataset \" + str(res[4]))\nprint(\"Model AUC       on testDataset \" + str(res[5]))","120315d2":"Here we can fine tune the Hyper Parameter of this model","aa7ec5d3":"Now lets see what is there in this images datasets.\n\nA random pacient is selected and few of its negative images is vizulize in 1st plot of image\nIn second image few of its positvie images is vizulize in 2nd plot of image\n\nAnd in last plot, 9 random pacient is selected and full image is plot and all the negatives part is slightly transparent","f9909e44":"As the datasets directory is in this type of foramt which is not suitable for loading data.\n\n* Datasets\n    * ID XYZ\n        * 0\n        * 1\n        \n        \nSo moving all the datasets in train\/val\/test format and in this subfolder there will be 0\/1 folder \n* NewDatasets\n    * Train \n        * all negative images\n        * all positive images\n       \n       \nsame type of folders for test and val \nand here all the datasets is divided into 80%-10%-10% in train-val-test datasets","13b3f125":"As the datasets is imbalaced we are adding the weights to these classes so optimizer can do better ","7133d5e3":"Importing all required packages that is needed for this notebook.\nIn this a CNN is used using tensorflow.","1c8a8ed3":"Adding image augmenting for training datasets","0b18b597":"Creating a list of all folders that is present in datasets","65998fd9":"After making these 3 folders, lets how many files are there in all these 3 folders"}}