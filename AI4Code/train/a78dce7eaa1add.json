{"cell_type":{"a6e06720":"code","775add90":"code","8398b752":"code","382c8cda":"code","fc7c7011":"code","75e731ea":"code","f87859f6":"code","6a1b7011":"code","00c6f393":"code","490640ca":"code","4cdb8ad7":"code","60cdb9bb":"code","3c5993a0":"code","6649d266":"markdown"},"source":{"a6e06720":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","775add90":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntrain_df.head()","8398b752":"train_df.describe()","382c8cda":"print('# of features = ', len(train_df.columns), '\\n')\ntrain_df.columns\n\n# 100 features, drop 'id', TV is 'loss'","fc7c7011":"train_df.isnull().sum().max()\n\n# No missing values","75e731ea":"print('# of classes = ', len(train_df['loss'].value_counts()))\ntrain_df['loss'].value_counts()","f87859f6":"sns.set_theme(style=\"whitegrid\")\nsns.boxplot(data=train_df.loss)","6a1b7011":"sns.displot(train_df.loss)","00c6f393":"print(train_df.dtypes.value_counts())\ntrain_df.dtypes","490640ca":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom catboost import CatBoostRegressor, CatBoostClassifier","4cdb8ad7":"features = list(train_df.columns[1:101])\ntrain_cat = np.zeros((250000,))\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train_df[features], train_df['loss'])):\n    X_train, X_valid = train_df.iloc[train_idx], train_df.iloc[valid_idx]\n    y_train = X_train['loss']\n    y_valid = X_valid['loss']\n    X_train = X_train.drop('loss', axis=1)\n    X_valid = X_valid.drop('loss', axis=1)\n    \n    cbr = CatBoostRegressor(random_state=42)\n\n    cbr =  cbr.fit(X_train, y_train, verbose=False)\n    temp_cat = cbr.predict(X_valid)\n    train_cat[valid_idx] = temp_cat\n    print(f'Fold {fold}: RMSE: ', mean_squared_error(y_valid, temp_cat, squared=False))\n    \nprint(f'Cat-boost Accuracy: ', mean_squared_error(train_df['loss'], train_cat, squared=False))","60cdb9bb":"test_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv\")\ntest_cat = np.zeros((len(test_df),))\n\nX_test = test_df\ntemp_cat = cbr.predict(X_test)\ntest_cat= temp_cat\n\ntemp_cat = cbr.predict(X_test)\n","3c5993a0":"samp_sub = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\nsamp_sub['loss'] = test_cat\nsamp_sub.to_csv('cat_boost.csv', index = False)","6649d266":"# **Sample submission**"}}