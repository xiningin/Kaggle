{"cell_type":{"0b89d3bf":"code","14fdc9a4":"code","772a2ef0":"code","3ecd4793":"code","6b37c3bd":"code","88bff1d9":"code","f746f1f5":"code","1956d21d":"code","531ae220":"code","f23798a5":"code","f8f60608":"code","8a865cfe":"code","9f1cc3cc":"code","40d32bdd":"code","b971ed0e":"code","b82d3bde":"code","4bdd4268":"code","2c88fa55":"code","953c6e2e":"code","2a9ed6d7":"code","f95ec6a8":"code","dea33892":"code","c6bea148":"code","487abea0":"code","df8e1693":"markdown","0e967afc":"markdown","da5dabed":"markdown","c8f8a167":"markdown","9009cd93":"markdown","532e8bb2":"markdown","c1fe73d9":"markdown","80f46c71":"markdown"},"source":{"0b89d3bf":"import keras, os\nimport tensorflow as tf\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing.image import load_img\n\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D","14fdc9a4":"#Set some directories\ntrain_zip_path = '\/kaggle\/input\/denoising-dirty-documents\/train.zip'\ntest_zip_path = '\/kaggle\/input\/denoising-dirty-documents\/test.zip'\nsample_zip_path = '\/kaggle\/input\/denoising-dirty-documents\/sampleSubmission.csv.zip'\ntrainclean_zip_path = '\/kaggle\/input\/denoising-dirty-documents\/train_cleaned.zip'\nextracting_path = '\/kaggle\/working'\ntrain_path = extracting_path + '\/train'\ntest_path = extracting_path + '\/test'\ntrain_cleaned_path = extracting_path + '\/train_cleaned'","772a2ef0":"#Extract data files to '\/kaggle\/working' \nimport zipfile\nwith zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extracting_path)\n    \nwith zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extracting_path)\n    \nwith zipfile.ZipFile(sample_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extracting_path)\n    \nwith zipfile.ZipFile(trainclean_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extracting_path)","3ecd4793":"#Figure out images shape.\nimage_names = os.listdir(extracting_path + '\/train')\ndata_size = len(image_names)\n#initailize output arrays.\nX = np.zeros([data_size, 2], dtype=np.uint16)\nfor i in tqdm(range(data_size)):\n    image_name = image_names[i]\n    img_dir = os.path.join(extracting_path + '\/train', image_name)\n    img_pixels = mpimg.imread(img_dir)\n    X[i] = img_pixels.shape\n\nprint('Number of training images:', data_size)\nprint('Differnet image hights: {}'.format(set(X[:,0])))\nprint('Differnet image widths: {}'.format(set(X[:,1])))","6b37c3bd":"def images_to_array(data_dir, label_dir=None, img_size=(420, 560)):\n    '''\n    1- Read image samples from certain directory.\n    2- Resize and Stack them into one big numpy array.\n    -- And if there are labels images ..\n    3- Read sample's label form the labels directory.\n    4- Resize and Stack them into one big numpy array.\n    5- Shuffle Data and label arrays.\n    '''\n    image_names = os.listdir(data_dir)\n    data_size = len(image_names)\n    #initailize data arrays.\n    X = np.zeros([data_size, img_size[0], img_size[1]], dtype=np.uint8)\n    #read data.\n    for i in tqdm(range(data_size)):\n        image_name = image_names[i]\n        img_dir = os.path.join(data_dir, image_name)\n        img_pixels = load_img(img_dir, color_mode='grayscale', target_size=img_size)\n        X[i] = img_pixels\n    #reshape into 4-d array    \n    X = X.reshape(data_size, img_size[0], img_size[1], 1) \n    \n    if label_dir:\n        label_names = os.listdir(label_dir)\n        data_size = len(label_names)\n        #initailize labels arrays.\n        y = np.zeros([data_size, img_size[0], img_size[1]], dtype=np.uint8)\n        #read lables.\n        for i in tqdm(range(data_size)):\n            image_name = label_names[i]\n            img_dir = os.path.join(label_dir, image_name)\n            img_pixels = load_img(img_dir, color_mode='grayscale', target_size=img_size)\n            y[i] = img_pixels\n        #reshape into 4-d array    \n        y = y.reshape(data_size, img_size[0], img_size[1], 1) \n        #shuffle    \n        ind = np.random.permutation(data_size)\n        X = X[ind]\n        y = y[ind]\n        print('Data Array Shape: ', X.shape)\n        print('Label Array Shape: ', y.shape)\n        return X\/255., y\/255.\n    \n    print('Ouptut Data Size: ', X.shape)\n    return X\/255.","88bff1d9":"X, y = images_to_array(extracting_path + '\/train', extracting_path + '\/train_cleaned')","f746f1f5":"#Divide our data to train and validation data.\nval_split = int(.15 * data_size)\nX_val, y_val = X[:val_split], y[:val_split]\nX_train, y_train = X[val_split:], y[val_split:]\nprint('Train data shape: ', X_train.shape)\nprint('Test data shape: ', X_val.shape)","1956d21d":"# First row will be raw data, second row will be the corresponding label images\nsamples = np.concatenate((X_train[:3], y_train[:3]), axis=0) \n\nf, ax = plt.subplots(2, 3, figsize=(20,10))\nf.subplots_adjust(hspace = .05, wspace=.05)\nfor i, img in enumerate(samples):\n    ax[i\/\/3, i%3].imshow(img[:,:,0], cmap='gray')\n    ax[i\/\/3, i%3].axis('off')\nplt.show() ","531ae220":"#Perpare the Autoencoder and compile it.\ndef create_model():\n    input_layer = Input(shape=(None, None, 1))\n    # encoder\n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n\n    # decoder\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n    autoencoder = keras.models.Model(inputs=[input_layer], outputs=[output_layer])\n    autoencoder.compile(optimizer = 'adam' , loss = \"mean_squared_error\")\n    return autoencoder\n\nautoencoder = create_model()","f23798a5":"history = autoencoder.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=200, batch_size=16, verbose=False)","f8f60608":"fig = plt.figure()\nax = plt.subplot(111)\n\nax.plot(history.epoch, history.history['loss'], label='Training Loss')\nax.plot(history.epoch, history.history['val_loss'], label='Validation Loss')\n\nax.legend()\nplt.show()","8a865cfe":"print('Final validation loss: ',autoencoder.evaluate(X_val, y_val))","9f1cc3cc":"#Retrain same model on the whole dataset.\nautoencoder = create_model()\nautoencoder.compile(optimizer = 'adam' , loss = \"mean_squared_error\")\nhistory = autoencoder.fit(X, y, epochs=300, batch_size=16, verbose=True)","40d32bdd":"print('Final loss: ',autoencoder.evaluate(X, y))","b971ed0e":"#Pick sample images from validation dataset.\ntest_samples, test_labels = X_val[:3], y_val[:3]\ntest_pred = autoencoder.predict(X_val[:3])\n\n# First row will be raw data, second row will be the corresponding cleaned images\nsamples = np.concatenate((test_samples, test_labels, test_pred), axis=0) \nmap_dict = {0:'Original Image', 1:'Label Image', 2:'Predicted Image'}\nf, ax = plt.subplots(3, 3, figsize=(18,15))\nf.tight_layout(pad=1.0)\nfor i, img in enumerate(samples):\n    ax[i\/\/3, i%3].imshow(img[:,:,0], cmap='gray')\n    ax[i\/\/3, i%3].title.set_text(map_dict[i\/\/3])\n    ax[i\/\/3, i%3].axis('off')\nplt.show() ","b82d3bde":"#Load and Scale test images into one big list.\nimage_names = sorted(os.listdir(extracting_path + '\/test'))\ndata_size = len(image_names)\n#initailize data arrays.\nX_test = []\n#read data.\nfor i in tqdm(range(data_size)):\n    image_name = image_names[i]\n    img_dir = os.path.join(extracting_path + '\/test', image_name)\n    img_pixels = load_img(img_dir, color_mode='grayscale')\n    w, h = img_pixels.size\n    X_test.append(np.array(img_pixels).reshape(1, h, w, 1) \/ 255.)\n    \nprint('Test sample shape: ', X_test[0].shape)\nprint('Test sample dtype: ', X_test[0].dtype)","4bdd4268":"#Predict test images one by one and store them into a list.\nyh_test = []\nfor img in X_test:\n    yh_test.append(autoencoder.predict(img)[0, :, :, 0])","2c88fa55":"# First column will be raw data, second column will be the corresponding cleaned images.\nf, ax = plt.subplots(2,3, figsize=(20,10))\nf.subplots_adjust(hspace = .1, wspace=.05)\nfor i, (img, lbl) in enumerate(zip(X_test[:3], yh_test[:3])):\n    ax[0, i].imshow(img[0,:,:,0], cmap='gray')\n    ax[0, i].title.set_text('Original Image')\n    ax[0, i].axis('off')\n\n    ax[1, i].imshow(lbl, cmap='gray')\n    ax[1, i].title.set_text('Cleaned Image')\n    ax[1, i].axis('off')\nplt.show() ","953c6e2e":"#Flatten the 'yh_test' list into 1-d list for submission.\nsubmit_vector = []\nfor img in yh_test:\n    h, w = img.shape\n    for i in range(w):\n        for j in range(h):\n            submit_vector.append(img[j,i])\nprint(len(submit_vector))","2a9ed6d7":"#Make sure that we got the proper length.\nc = 0\nfor img in yh_test:\n    hi, wi = img.shape\n    c += (hi * wi)\nprint('Total values :', c)","f95ec6a8":"sample_csv = pd.read_csv(extracting_path + '\/sampleSubmission.csv')\nsample_csv.head(10)","dea33892":"id_col = sample_csv['id']\nvalue_col = pd.Series(submit_vector, name='value')\nsubmission = pd.concat([id_col, value_col], axis=1)\nsubmission.head(10)","c6bea148":"submission.to_csv('Cleared.csv',index = False)","487abea0":"#Always clear the output directory for faster committing.\nimport shutil\nshutil.rmtree(extracting_path + '\/train')\nshutil.rmtree(extracting_path + '\/test')\nshutil.rmtree(extracting_path + '\/train_cleaned')","df8e1693":"* Here's a sample from training set.\n* First row will be raw data, second row will be the corresponding label images.","0e967afc":"* Data images don't have the same shape some have a shape of (285, 540), others have (450, 540).\n* The following script just to extract this information.","da5dabed":"* The result is perfect, actually it's almost identical with label images.\n* As mentioned before, data images aren't the same shape. But in this step we can't resize test images for submitting issues, so we collected all images into list instead of 3d array, note that we left autoencoder's input layer with None values to accept any input shape.","c8f8a167":"* Lets test our model on a small sample of the data.\n* First row will be raw data, second row will be the corresponding label images, and the third one is the prediected cleaned images.","9009cd93":"* Perfect results, isn't it?","532e8bb2":"* Note that we reshaped all small images up to be in shape (420, 560).","c1fe73d9":"* As we see, training process goes well without overfitting. Further we will train our model with same settings on the whole dataset.","80f46c71":"* Lets check how good our model with test images?\n* First column will be raw data, second column will be the corresponding cleaned images."}}