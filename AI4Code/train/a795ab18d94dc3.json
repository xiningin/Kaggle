{"cell_type":{"4000b455":"code","0a444ad0":"code","42d56c0c":"code","605bedea":"code","1b8a22ad":"code","d784ebda":"code","5d0a1860":"code","2d84dd63":"code","2c29d3c7":"code","bc1c6c6d":"code","39a492b3":"code","20be7b62":"code","a0e74aa4":"code","21568952":"code","e13ce458":"code","10b16349":"code","088dcc25":"code","2d66f7d5":"code","786ff354":"code","3bb02032":"code","6aeb44ba":"code","ca762799":"code","fca58132":"code","87a2d46a":"code","bab525c8":"code","1a389e5a":"code","650014b7":"code","528ca614":"code","c1c2e4fd":"code","fdb075f2":"code","2ccf1a97":"code","eb142a2a":"code","01ee61a7":"code","f2397e46":"code","fdcd5e8f":"code","9c48dad2":"code","d4522677":"code","1613de6b":"code","58da999d":"code","c28c6cf6":"code","0a90c407":"code","37459330":"markdown","a0488dec":"markdown","5c3c7202":"markdown","5149b035":"markdown","b1e10cfb":"markdown","667f4455":"markdown","a20215aa":"markdown","129e4d0f":"markdown","4c02745a":"markdown"},"source":{"4000b455":"## This Notebook Uses ReSNet50 (Transfer Learning with PreTrained Weights and Retraining) Model to generate Output Predictions","0a444ad0":"import multiprocessing\nfrom multiprocessing.pool import ThreadPool\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm,tqdm_notebook\nfrom prettytable import PrettyTable\nimport pickle\nimport os\nprint('CWD is ',os.getcwd())\n\n# Vis Libs..\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"axes.grid\"] = False\n\n# Image Libs.\nfrom PIL import Image\nimport cv2\n\n# sklearn libs..\nfrom sklearn.model_selection import train_test_split","42d56c0c":"# Research Kernel Link - https:\/\/github.com\/dimitreOliveira\/APTOS2019BlindnessDetection\/blob\/master\/Model%20backlog\/ResNet50\/4%20-%20ResNet50%20-%20Batch%20size%2022.ipynb\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom prettytable import PrettyTable\nimport pickle\nimport multiprocessing\nfrom multiprocessing.pool import ThreadPool\nprint(multiprocessing.cpu_count(),\" CPU cores\")\n\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.rcParams[\"axes.grid\"] = False\n\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score,accuracy_score\n\nfrom PIL import Image\nimport cv2\n\nimport keras\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers,Model,Sequential\nfrom keras.layers import Input,GlobalAveragePooling2D,Dropout,Dense,Activation\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\n\n# Colab Libs...\n#","605bedea":"import tensorflow as tf\nimport os","1b8a22ad":"df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')","d784ebda":"df.head()","5d0a1860":"df['id_code']+='.png'","2d84dd63":"df['diagnosis']= df['diagnosis'].map(str)","2c29d3c7":"df['diagnosis'].dtype","bc1c6c6d":"df_train_train,df_train_test = df.iloc[:3000], df.iloc[3000:]\nprint(df_train_train.shape,df_train_test.shape,'\\n')\ndf_train_test.head(6)\n","39a492b3":"import matplotlib.pyplot as plt","20be7b62":"IMG_SIZE = 512","a0e74aa4":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef circle_crop(img, sigmaX = 30):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width\/2)\n    y = int(height\/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    cv2.resize(img, (320, 320))\n    return img \n\ndef preprocess_image(file):\n    input_filepath ='..\/input\/aptos2019-blindness-detection\/train_images\/'+file\n    output_filepath = '.\/pre_resized_data\/'+file\n    \n    img = cv2.imread(input_filepath)\n    img = circle_crop(img) \n    \n    #print(img.shape)\n    #plt.imshow(img)\n    cv2.imwrite(output_filepath, cv2.resize(img, (IMG_SIZE,IMG_SIZE)))","21568952":"#preprocess_image('000c1434d8d7.png')","e13ce458":"'''This Function uses Multi processing for faster saving of images into folder'''\n\ndef multiprocess_image_processor(process:int, imgs:list):\n    \"\"\"\n    Inputs:\n        process: (int) number of process to run\n        imgs:(list) list of images\n    \"\"\"\n    print(f'MESSAGE: Running {process} process')\n    results = ThreadPool(process).map(preprocess_image, imgs)\n    return results","10b16349":"multiprocess_image_processor(6, df['id_code'].values) ","088dcc25":"len(os.listdir('.\/pre_resized_data'))","2d66f7d5":"# Use 2 cores (colab)\n# ref - https:\/\/stackoverflow.com\/questions\/1006289\/how-to-find-out-the-number-of-cpus-using-python\n\n#multiprocess_image_processor(2, list(df_train_train.id_code.values))","786ff354":"# Model parameters\nBATCH_SIZE = 8\nEPOCHS = 40\nWARMUP_EPOCHS = 2\nLEARNING_RATE = 1e-4\nWARMUP_LEARNING_RATE = 1e-3\nHEIGHT = 512\nWIDTH = 512\nCANAL = 3\nN_CLASSES = df_train_train['diagnosis'].nunique()\nES_PATIENCE = 5\nRLROP_PATIENCE = 3\nDECAY_DROP = 0.5","3bb02032":"def img_generator(train,test):\n    train_datagen=ImageDataGenerator(rescale=1.\/255, validation_split=0.2,horizontal_flip=True)\n    \n    train_generator=train_datagen.flow_from_dataframe(dataframe=df_train_train,\n                                                      directory=\"..\/input\/project1\/1\",\n                                                      x_col=\"id_code\",\n                                                      y_col=\"diagnosis\",\n                                                      batch_size=BATCH_SIZE,\n                                                      class_mode=\"categorical\",\n                                                      target_size=(HEIGHT, WIDTH),\n                                                      subset='training')\n    \n    valid_generator=train_datagen.flow_from_dataframe(dataframe=df_train_train,\n                                                      directory=\"..\/input\/project1\/1\",\n                                                      x_col=\"id_code\",\n                                                      y_col=\"diagnosis\",\n                                                      batch_size=BATCH_SIZE,\n                                                      class_mode=\"categorical\",    \n                                                      target_size=(HEIGHT, WIDTH),\n                                                      subset='validation')\n    \n    test_datagen = ImageDataGenerator(rescale=1.\/255)\n    test_generator = test_datagen.flow_from_dataframe(dataframe=df_train_test,\n                                                      directory = \"..\/input\/project1\/1\",\n                                                      x_col=\"id_code\",\n                                                      target_size=(HEIGHT, WIDTH),\n                                                      batch_size=1,\n                                                      shuffle=False,\n                                                      class_mode=None)\n    \n    return train_generator,valid_generator,test_generator","6aeb44ba":"gen=ImageDataGenerator(rescale=1.\/255, validation_split=0.2,horizontal_flip=True)","ca762799":"train_generator,valid_generator,test_generator = img_generator(df_train_train,df_train_test)","fca58132":"def create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = applications.ResNet50(weights='imagenet', include_top=False,input_tensor=input_tensor)\n    #base_model.load_weights('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(2048, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n    model = Model(input_tensor, final_output)\n    return model","87a2d46a":"model = create_model(input_shape=(HEIGHT, WIDTH, CANAL), n_out=N_CLASSES)\n\nfor layer in model.layers:\n    layer.trainable = False\n\nfor i in range(-5, 0):\n    model.layers[i].trainable = True\nmodel.summary()","bab525c8":"model.summary()","1a389e5a":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nprint(STEP_SIZE_TRAIN,STEP_SIZE_VALID)","650014b7":"model.compile(optimizer = optimizers.Adam(lr=WARMUP_LEARNING_RATE),loss = 'categorical_crossentropy',metrics = ['accuracy'])\n\nhistory_warmup = model.fit(train_generator,\n                                     steps_per_epoch=STEP_SIZE_TRAIN,\n                                     validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,\n                                     epochs=WARMUP_EPOCHS,\n                                     verbose=1).history","528ca614":"for layer in model.layers:\n    layer.trainable = True\n\nes = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nrlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n#ckpt = tf.keras.callbacks.ModelCheckpoint('res_train.h5')\ncallback_list = [es, rlrop]\noptimizer = optimizers.Adam(lr=LEARNING_RATE)\nmodel.compile(optimizer=optimizer, loss=\"binary_crossentropy\",  metrics=['accuracy'])\n#model.summary()","c1c2e4fd":"history_finetunning = model.fit(train_generator,\n                                steps_per_epoch=STEP_SIZE_TRAIN,\n                                validation_data=valid_generator,\n                                validation_steps=STEP_SIZE_VALID,\n                                epochs=EPOCHS,\n                                callbacks=callback_list,\n                                verbose=1).history","fdb075f2":"LEARNING_RATE =  4.19999873689376e-05\noptimizer = optimizers.Adam(lr=LEARNING_RATE)\nmodel.compile(optimizer=optimizer, loss=\"binary_crossentropy\",  metrics=['accuracy'])","2ccf1a97":"history_finetunning = model.fit(train_generator,\n                                steps_per_epoch=STEP_SIZE_TRAIN,\n                                validation_data=valid_generator,\n                                validation_steps=STEP_SIZE_VALID,\n                                epochs=EPOCHS,\n                                callbacks=callback_list,\n                                verbose=1).history","eb142a2a":"tf.keras.models.save_model(model, filepath = '.\/resnet3.h5')","01ee61a7":"# ref - https:\/\/stackoverflow.com\/questions\/29188757\/matplotlib-specify-format-of-floats-for-tick-lables\nplt.figure(figsize=(8,5))\n\nplt.plot(history_finetunning['accuracy'])\nplt.plot(history_finetunning['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.gca().ticklabel_format(axis='both', style='plain', useOffset=False)\nplt.show()","f2397e46":"complete_datagen = ImageDataGenerator(rescale=1.\/255)\ncomplete_generator = complete_datagen.flow_from_dataframe(dataframe=df_train_train,\n                                                          directory = \"..\/input\/aptos2019-blindness-detection\/train_images\",\n                                                          x_col=\"id_code\",\n                                                          target_size=(HEIGHT, WIDTH),\n                                                          batch_size=1,\n                                                          shuffle=False,\n                                                          class_mode=None)\n\nSTEP_SIZE_COMPLETE = complete_generator.n\/\/complete_generator.batch_size\ntrain_preds = model.predict_generator(complete_generator, steps=STEP_SIZE_COMPLETE,verbose = 1)\ntrain_preds = [np.argmax(pred) for pred in train_preds]","fdcd5e8f":"print(\"Train Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds, df_train_train['diagnosis'].astype('int'), weights='quadratic'))\nprint(\"Train Accuracy score : %.3f\" % accuracy_score(df_train_train['diagnosis'].astype('int'),train_preds))","9c48dad2":"test_generator.reset()\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size\ntest_preds = model.predict_generator(test_generator, steps=STEP_SIZE_TEST,verbose = 1)\ntest_labels = [np.argmax(pred) for pred in test_preds]","d4522677":"def plot_conf_matrix(true,pred,classes):\n    cf = confusion_matrix(true, pred)\n    \n    df_cm = pd.DataFrame(cf, range(len(classes)), range(len(classes)))\n    plt.figure(figsize=(8,5.5))\n    sns.set(font_scale=1.4)\n    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},xticklabels = classes ,yticklabels = classes,fmt='g')\n    #sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n    plt.show()","1613de6b":"labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\nplot_conf_matrix(list(df_train_test['diagnosis'].astype(int)),test_labels,labels)","58da999d":"cnf_matrix = confusion_matrix(df_train_test['diagnosis'].astype('int'), test_labels)\ncnf_matrix_norm = cnf_matrix.astype('float') \/ cnf_matrix.sum(axis=1)[:, np.newaxis]\ndf_cm = pd.DataFrame(cnf_matrix_norm, index=labels, columns=labels)\nplt.figure(figsize=(16, 7))\nsns.heatmap(df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","c28c6cf6":"print(\"Test Cohen Kappa score: %.3f\" % cohen_kappa_score(test_labels, df_train_test['diagnosis'].astype('int'), weights='quadratic'))\nprint(\"Test Accuracy score : %.3f\" % accuracy_score(df_train_test['diagnosis'].astype('int'),test_labels))","0a90c407":"x = PrettyTable()\nx.field_names = [\"S.No.\",\"ResNet50 Model\",\"Image Processing\",\"Data Augmentation\",\"Hyperparameters(BS,Opt,lr,ep)\",\"Train QWK\",\"Test QWK\"]\n\nx.add_row([1,\"R-P-D-p(0.5)-D-p(0.5)-S(5)\",\"--\",\"Hor Flip,Scale 1\/255\",\"(4,'Adam','1e-4',7)\",\"0.912\",\"0.905\"])\nx.add_row([2,\"R-P-D-p(0.5)-D-p(0.5)-S(5)\",\"Circle Crop, Gaussian Blur\",\"Hor Flip,Scale 1\/255\",\"(4,'Adam','1e-4',7)\",\"0.98\",\"0.904\"])\n\nprint(x)","37459330":"### <font color='red'> 9.6 ResNet50 Models Summary <\/font>","a0488dec":"### <font color='red'> 9.2 Image Pre Processing <\/font>","5c3c7202":"### <font color='red'> 9.3 Train Model <\/font>","5149b035":"### <font color='red'> 9.5 Evaluate Model on Test Data <\/font>","b1e10cfb":"### <font color='red'> 9.4 Generate Train Predictions on complete Train Data <\/font>","667f4455":"### <font color='red'> 9.1 Setup Colab Environment <\/font>","a20215aa":"#  <font color='red'>Table of Contents<\/font>\n","129e4d0f":"#  <a id = 'section9'> <font color='red'>  9. ResNet50 Models  <\/font> <\/a>","4c02745a":"[9. ResNet50 Models](#section9)<br>\n"}}