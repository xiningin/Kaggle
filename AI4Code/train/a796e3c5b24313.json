{"cell_type":{"0f4bbfaf":"code","af06ab87":"code","a4bd5764":"code","e305a20d":"code","80e5a28d":"code","41a8805c":"code","0d1ab017":"code","a3aebece":"code","c8560db6":"code","f72fa254":"code","96a6079a":"code","f29271d5":"code","36090011":"code","15af7802":"code","e1b2e397":"code","bd26bfce":"code","5e58084b":"code","1a15cc18":"code","678a23c0":"code","7a6c63b6":"code","e9d2ca06":"markdown","4773452c":"markdown","dd5071a4":"markdown","8d41f17a":"markdown","81eef0dd":"markdown","ac583b6e":"markdown","42bd2eab":"markdown","69898cb7":"markdown","81d712a0":"markdown","9bc51630":"markdown","714122d7":"markdown","5a356944":"markdown","27fce7bc":"markdown","8d01eac9":"markdown","96bd26cf":"markdown","afe89748":"markdown","e720ac41":"markdown","9904f7d4":"markdown","2119a52d":"markdown","9e2e00cb":"markdown","e410a9f2":"markdown","68f30164":"markdown","89ff0c08":"markdown","b47de098":"markdown","19fdd567":"markdown","83431117":"markdown","fe847252":"markdown","4ff889aa":"markdown","3aa8fea8":"markdown","54177b8e":"markdown","ca95838c":"markdown","f495b818":"markdown","7bdf3c31":"markdown","46d6940d":"markdown","48fdf195":"markdown","a30f5d28":"markdown","9438f18c":"markdown","bd78eb94":"markdown","62167edb":"markdown"},"source":{"0f4bbfaf":"# Carregar as bibliotecas necess\u00e1rias: \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score \nimport sklearn.metrics\n\n\n# Carregar a base de dados:\nrout_path = \"..\/input\/data.csv\"\ndados = pd.read_csv(rout_path)","af06ab87":"# Mostrar detalhes dos 5 primeiros registros da base:\n\ndados.head() ","a4bd5764":"# Colocar no vetor Y os valores da classe objetivo\n\nY = dados.diagnosis                         \n\n\n# Fazer a remo\u00e7\u00e3o das colunas desnecess\u00e1rias\n\nlist = ['Unnamed: 32','id','diagnosis']        # lista com as colunas a serem removidas\nX = dados.drop(list,axis = 1 )          \nX.head()\n","e305a20d":"ax = sns.countplot(Y,label=\"Quantidade\")       # M = 212, B = 357\nB, M = Y.value_counts()\nprint('Quantidade de Benignos: ',B)\nprint('Quantidade de Malignos: ',M)","80e5a28d":"# mostra soma, m\u00e9dia , desvio padr\u00e3o, min, max, valor dos 25%, 50%(mediana) e 75%\n\nX.describe() ","41a8805c":"# Mostrar mapa de calor \n\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(X.corr(), annot=True, fmt= '.1f', cmap ='RdYlGn')","0d1ab017":"droplist_se_worst = ['radius_se', \t'texture_se',\t'perimeter_se',\t'area_se',\t'smoothness_se',\t'compactness_se',\t'concavity_se',\t'concave points_se',\t'symmetry_se',\t'fractal_dimension_se', 'radius_worst',\t'texture_worst',\t'perimeter_worst',\t'area_worst',\t'smoothness_worst',\t'compactness_worst',\t'concavity_worst',\t'concave points_worst',\t'symmetry_worst',\t'fractal_dimension_worst']\n\nsomente_mean = X.drop(droplist_se_worst, axis = 1)\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(somente_mean.corr(), annot=True, linewidths=.5, fmt= '.3f', cmap ='RdYlGn')","a3aebece":"droplist_mean_worst = ['radius_mean', 'texture_mean',\t'perimeter_mean',\t'area_mean', \t'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean',\t'symmetry_mean',\t'fractal_dimension_mean', 'radius_worst',\t'texture_worst',\t'perimeter_worst',\t'area_worst',\t'smoothness_worst',\t'compactness_worst',\t'concavity_worst',\t'concave points_worst',\t'symmetry_worst',\t'fractal_dimension_worst']\n\nsomente_se = X.drop(droplist_mean_worst, axis = 1)\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(somente_se.corr(), annot=True, linewidths=.5, fmt= '.3f', cmap ='RdYlGn')","c8560db6":"droplist_mean_se = ['radius_mean', 'texture_mean',\t'perimeter_mean',\t'area_mean', \t'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean',\t'symmetry_mean',\t'fractal_dimension_mean', 'radius_se', \t'texture_se',\t'perimeter_se',\t'area_se',\t'smoothness_se',\t'compactness_se',\t'concavity_se',\t'concave points_se',\t'symmetry_se',\t'fractal_dimension_se']\n\nsomente_worst = X.drop(droplist_mean_se, axis = 1)\nf,ax = plt.subplots(figsize=(10, 10))\n\n\nsns.heatmap(somente_worst.corr(), annot=True, linewidths=.5, fmt= '.3f', cmap ='RdYlGn')","f72fa254":"droplist_final = ['radius_mean', \t'perimeter_mean',\t'concavity_mean',\t'radius_se', \t'perimeter_se',\t'radius_worst',\t'perimeter_worst']\n\n\ndata_dia = Y\ndata = X.drop(droplist_final, axis = 1)                     #retirada de atributos \ndata_n_2 = (data - data.mean()) \/ (data.std())              # normaliza\u00e7\u00e3o\ndata = pd.concat([Y,data_n_2],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"Atributos\",\n                    value_name='Valores')\nplt.figure(figsize=(15,15))\nsns.violinplot(x=\"Atributos\", y=\"Valores\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\nplt.xticks(rotation=90)","96a6079a":"# Mostrar correla\u00e7\u00e3o entre classes e atributos 'mean'\nsns.pairplot(dados, kind=\"scatter\", diag_kind=\"hist\", hue=\"diagnosis\" ,  markers=[\"o\", \"D\"], vars=[\"area_mean\", \"texture_mean\", \"smoothness_mean\", \"compactness_mean\", \"concave points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\"] ) \nplt.show()","f29271d5":"# Mostrar correla\u00e7\u00e3o entre classes e atributos 'se'\nsns.pairplot(dados, kind=\"scatter\", diag_kind=\"hist\", hue=\"diagnosis\" ,  markers=[\"o\", \"D\"], vars=[\"area_se\", \"texture_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\"] ) \nplt.show()\n","36090011":"# Mostrar correla\u00e7\u00e3o entre classes e atributos 'worst'\nsns.pairplot(dados, kind=\"scatter\", diag_kind=\"hist\", hue=\"diagnosis\" ,  markers=[\"o\", \"D\"], vars=[\"area_worst\", \"texture_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\" , \"fractal_dimension_worst\"] ) \nplt.show()\n","15af7802":"# Remo\u00e7\u00e3o dos atributos que tinham alta correla\u00e7\u00e3o\n\ndroplist_final = ['radius_mean', \t'perimeter_mean',\t'concavity_mean',\t'radius_se', \t'perimeter_se',\t'radius_worst',\t'perimeter_worst']\n\ndata = X.drop(droplist_final, axis = 1)                     #retirada de atributos \n\n\n# Separar dados em Treino e Teste \n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=10) # random_state=10 foi mantido para quest\u00e3o de REPRODUCIBILIDADE. (Separar os dados da mesma forma independente da execu\u00e7\u00e3o). \n\nprint('Quantidade de registros para treino: ', x_train.shape[0]) \nprint('Quantidade de registros para teste: ',x_test.shape[0]) #qtd de registros para teste\n","e1b2e397":"# Calcular a acur\u00e1cia para K de 1 a 15 utilizando Cross Validation\ntr_acc = []\nk_set = range(1,15)\n\nfor n_neighbors in k_set:\n  knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n  scores = cross_val_score(knn, x_train, y_train, cv=10) #testa eficacia com cross validation na base de treinamento\n  tr_acc.append(scores.mean())\n  \nbest_k = np.argmax(tr_acc) #retorna o indice do maior\nprint('Melhor k no treinamento com Cross Validation: ', k_set[best_k]) #mostra melhor k do treinamento com cross validation","bd26bfce":"te_acc = []\nk_set = range(1,15)\n\nfor n_neighbors in k_set:\n  knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n  knn.fit(x_train, y_train)\n  y_pred = knn.predict(x_test) #aplica x_test no modelo\n  te_acc.append(sklearn.metrics.accuracy_score(y_test, y_pred)) #compara y_test com y_pred\n    \nmelhor_k =np.argmax(te_acc)\nprint('Melhor k nos testes: ', k_set[melhor_k]) #melhor k do treinamento normal + teste","5e58084b":"import matplotlib.pyplot as plt\n\nplt.plot(k_set,tr_acc, label='Treino')\nplt.plot(k_set,te_acc, label='Teste')\nplt.ylabel('Acur\u00e1cia')\nplt.xlabel('k')\nplt.legend()\n\nplt.show()","1a15cc18":"# Reaplicar o modelo com k=7 , que \u00e9 o melhor k\nclf = KNeighborsClassifier(n_neighbors = 11)\nclf.fit(x_train, y_train)\n\n\n# Mostrar Score\npred_scores = clf.predict_proba(x_test)\nprint(pred_scores)","678a23c0":"# Calcular a acur\u00e1cia do modelo aplicado nos dados de teste\ny_pred = clf.predict(x_test)\nte_acc= (sklearn.metrics.accuracy_score(y_test, y_pred)) \nprint ('Acur\u00e1cia obtida: ', te_acc)","7a6c63b6":"conf_mat = sklearn.metrics.confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(conf_mat, index = [i for i in ['maligno', 'benigno']],\n                  columns = [i for i in ['maligno', 'benigno']])\n\ncmap = sns.light_palette(\"navy\", as_cmap=True)\nplt.figure()\nsns.heatmap(df_cm, annot=True, cmap=cmap)","e9d2ca06":"# Sele\u00e7\u00e3o dos Dados","4773452c":"A seguir, a classe objetivo, no caso a coluna \"diagnosis\", \u00e9 separada dos demais atributos, que s\u00e3o efetivamente os dados que ser\u00e3o analisados\n\nTamb\u00e9m s\u00e3o removidas as colunas com informa\u00e7\u00f5es que n\u00e3o s\u00e3o relevantes: 'id' (n\u00famero de identifica\u00e7\u00e3o do registro) e 'Unnamed: 32' (coluna com valor faltante para todos os registros).\n\nNos par\u00e2metros exibidos a seguir, \u00e9 not\u00f3ria a diferen\u00e7a entre os valores absolutos de alguns atributos, como por exemplo o valor da \u00e1rea e o valor da concavidade. Desse modo, para algumas exibi\u00e7\u00f5es gr\u00e1ficas nas se\u00e7\u00f5es adiante, ser\u00e1 necess\u00e1ria a normaliza\u00e7\u00e3o dos dados.","dd5071a4":"## **Plotagem de Violino**","8d41f17a":"A decis\u00e3o de implementa\u00e7\u00e3o foi de deletar os atributos com correla\u00e7\u00e3o maior ou igual a 0.9.","81eef0dd":"*Data mining* \u00e9 a principal atividade do conhecimento, aplicando, para este fim, algoritmos de descoberta de padr\u00f5es.\nIremos fazer uso do algoritmo KNN (do ingl\u00eas,  *K-nearest neighbor*),  que determina a classe(o r\u00f3tulo de classifica\u00e7\u00e3o)  de uma amostra baseado nas k amostras vizinhas mais pr\u00f3ximas advindas de um conjunto de treinamento.","ac583b6e":"Para uma melhor compreens\u00e3o dos dados podemos observar como eles se comportam. \nAp\u00f3s a execu\u00e7\u00e3o a primeira tabela a seguir mostrar\u00e1 os seguintes dados estat\u00edsticos sobre os dados:\nsoma, m\u00e9dia, desvio padr\u00e3o, valor 25% 50%(mediana) e 75% , m\u00e1ximo e m\u00ednimo .","42bd2eab":"## **Gr\u00e1fico de pares de atributos**","69898cb7":"Recentemente, a quantidade de dados produzidos dentro de empresas, universidades, com\u00e9rcio e no mercado tem ganhado grande relev\u00e2ncia, tanto pela quantidade de dados produzidos devido ao f\u00e1cil compartilhamento, envio e recebimento, quanto pela necessidade de entender esses dados e transform\u00e1-los em informa\u00e7\u00e3o \u00fatil para apoio na tomada de decis\u00e3o dentro dessas entidades. Nesse processo de compreens\u00e3o dos dados, existem t\u00e9ncias denonminadas minera\u00e7\u00e3o de dados, que visam explorar grandes quantidades de dados com o intuito de encontrar padr\u00f5es relevantes e consistentes no relacionamento entre os atributos (basicamente, colunas de tabelas) dessas bases de dados. \n\nUma das primeiras t\u00e9cnicas desenvolvidas nesse sentido foi o  KDD (em ingl\u00eas, *Knowledge Discovery in Database*), desenvolvido durante o final da d\u00e9cada de 1980. A extra\u00e7\u00e3o de conhecimento a partir de uma base de dados \u00e9 dividida em fases: coleta de dados -> tratamento dos dados -> resultado final (transforma\u00e7\u00e3o dos dados em informa\u00e7\u00f5es e posteriormente em conhecimento).\n\nO processo KDD foi constitu\u00eddo visando automatizar o processo de extra\u00e7\u00e3o de conhecimento a partir de uma grande base de dados. \u00c9 um processo iterativo, isto \u00e9, cada etapa pode ser repetida at\u00e9 que se tenham os resultados satisfat\u00f3rios. \n\nAs etapas do KDD, segundo Fayyad et al (1996) s\u00e3o as seguintes:\n\n- Sele\u00e7\u00e3o: \u00e9 a etapa de agrupamento dos dados de modo organizado. \u00c9 uma etapa muito importante, pois \u00e9 nela que ser\u00e3o decididos quais os conjuntos de dados que ser\u00e3o relevantes para que sejam obtidos resultados com informa\u00e7\u00f5es uteis.\n- \tPr\u00e9-processamento: neste momento os dados passam por uma adequa\u00e7\u00e3o. Ao final do processo, devem possuir o formato correto e n\u00e3o apresentar duplicidade, entre outras caracter\u00edsticas. Consiste numa a limpeza dos dados e sele\u00e7\u00e3o de atributos. Nesta etapa, informa\u00e7\u00f5es ausentes, err\u00f4neas ou inconsistentes nas bases de dados devem ser corrigidas de forma a n\u00e3o comprometer a qualidade dos modelos de conhecimento a serem extra\u00eddos ao final do processo de KDD.\n-\tTransforma\u00e7\u00e3o: \u00e9 a etapa de armazenamento dos dados de forma a facilitar o uso das t\u00e9cnicas de Data Mining. Esta etapa analisa os dados obtidos na etapa anterior e os reorganiza de uma forma especifica para que possam ser interpretados na etapa seguinte.\n-\tMinera\u00e7\u00e3o de Dados: \u00e9 a principal atividade do processo de descoberta do conhecimento. Nesta fase  s\u00e3o aplicados algoritmos de descoberta de padr\u00f5es. A minera\u00e7\u00e3o faz com que meros dados sejam transformados em informa\u00e7\u00f5es.\n-\tInterpreta\u00e7\u00e3o e avalia\u00e7\u00e3o: esta fase consiste em interpretar os dados gerados e verificar se possuem alguma validade para o problema proposto. Esta \u00e9 a fase na qual as regras indicadas pelo processo anterior ser\u00e3o interpretadas e avaliadas. Ap\u00f3s a interpreta\u00e7\u00e3o poder\u00e3o surgir padr\u00f5es, relacionamentos e descoberta de novos fatos, que podem ser utilizados para pesquisas, otimiza\u00e7\u00e3o e outros.\n\nNeste trabalho, pode-se entender as fases do KDD para uma base de dados na qual existe uma s\u00e9rie de atributos de an\u00e1lise de imagens de c\u00e9lulas na regi\u00e3o do c\u00e2ncer feitos com ultrassonografia para prever se um c\u00e2ncer de mama \u00e9 benigno ou mal\u00edgno. Basicamente, os tumores benignos s\u00e3o constitu\u00eddos por c\u00e9lulas bem semelhantes \u00e0s que os originaram e n\u00e3o possuem a capacidade de provocar met\u00e1stases. J\u00e1 os malignos s\u00e3o agressivos e possuem a capacidade de infiltrar outros \u00f3rg\u00e3os.\nFonte: https:\/\/www.einstein.br\/noticias\/noticia\/cancer-benigno-maligno\n\nAp\u00f3s a extra\u00e7\u00e3o dos dados da plataforma Kaggle (www.kaggle.com) foi realizado um pr\u00e9-processamento para garantir que os dados lidos e interpretados sejam relevantes para o processo de extra\u00e7\u00e3o de conhecimento. Ap\u00f3s isso, foi implementada a transforma\u00e7\u00e3o dos dados em si, atrav\u00e9s do algoritmo KNN. Por fim, foram feitas as previs\u00f5es a partir de novos dados, isto \u00e9, ap\u00f3s o aprendizado realizado pelo algoritmo KNN sobre a base de dados, novas entradas de dados buscaram classificar se uma nova entrada de fotos de c\u00e9lulas seria um c\u00e2ncer beingno ou maligno, baseado no aprendizado anterior. Foi tra\u00e7ada uma avalia\u00e7\u00e3o para essas previs\u00f5es, de modo a se obter uma acur\u00e1cia e concluir se o modelo contru\u00eddo \u00e9 bom ou ruim nas suas previs\u00f5es.\n\n\nCada classifica\u00e7\u00e3o foi calculada a partir de uma imagens digitalizadas de uma regi\u00e3o de c\u00e9lulas afetadas nas gl\u00e2ndulas mam\u00e1rias. Essas imagens descrevem caracter\u00edsticas dos n\u00facleos celulares presentes e das c\u00e9lulas.\n\nAs seguintes se\u00e7\u00f5es desse trabalho se referem \u00e0s etapas do KDD e a conclus\u00e3o do trabalho:\n- Sele\u00e7\u00e3o dos dados, \n- Pr\u00e9-processamento , \n- Transforma\u00e7\u00e3o, \n- Minera\u00e7\u00e3o de Dados, \n- Avalia\u00e7\u00e3o (do modelo),\n- Conclus\u00e3o\n","81d712a0":"## C\u00e1lculo da acur\u00e1cia","9bc51630":"### N\u00famero total de registros para cada classe \n\n\n","714122d7":"- Os atributos radius_worst, perimeter_worst e  area_worst possuem correla\u00e7\u00e3o acima de 0.9, ent\u00e3o iremos remover os atributos per\u00edmetro e raio (escolha arbitr\u00e1ria)\n\nPortanto, nesse primeiro terceiro, os atributos que continuar\u00e3o ser\u00e3o: area_worst, texture_worst, smoothness_worst, compactness_worst, concavity_worst, concave points_worst, symmetry_worst e fractal_dimension_worst","5a356944":" Depois calculamos a acur\u00e1cia para  cada k de 1 at\u00e9 15 aplicando o modelo nos dados de treinamento e fazendo o teste com os dados de teste. \n","27fce7bc":"## Matriz de confus\u00e3o \n","8d01eac9":"### Explica\u00e7\u00e3o dos atributos\n\nOs atributos s\u00e3o divididos em tr\u00eas grupos: Mean, SE e Worst.\n\n> Mean: m\u00e9dia de todas as c\u00e9lulas;\n\n> SE: *Standard Error* (erro padr\u00e3o de todas as c\u00e9lulas);\n\n> Worst: m\u00e9dia dos tr\u00eas piores valores medidos das c\u00e9lulas. Na verdade, \u00e9 considerado \"pior\" porque s\u00e3o medidas indicativas de c\u00e9lulas n\u00e3o saud\u00e1veis; na realidade o \"pior\" significa os maiores valores medidos para raio, per\u00edmetro, textura etc.\n\nCada grupo tem 10 atributos: \n- radius (raio da c\u00e9lula)\n- texture (textura da c\u00e9lula - medida pelo desvio padr\u00e3o de escalas de cinza, que ajudam a indicar se a c\u00e9lula \u00e9 saud\u00e1vel ou n\u00e3o)\n-\tperimeter (per\u00edmetro)\n-\tarea (\u00e1rea)\n-\tsmoothness (varia\u00e7\u00e3o local em comprimentos de raio)\n- compactness (campactude = perimetro\u00b2\/area - 1)\n- concavity (gravidade das por\u00e7\u00f5es c\u00f4ncavas das c\u00e9lulas)\n- concave points (n\u00famero de por\u00e7\u00f5es c\u00f4ncavas no contorno da c\u00e9lula),\n- symmetry (simetria) \n- fractal_dimension (dimens\u00e3o fractal). \n\n\n\n","96bd26cf":"\nA seguir \u00e9 mostrado um gr\u00e1fico para comparar a acur\u00e1cia de cada valor de K no treino e no teste.","afe89748":"# Minera\u00e7\u00e3o de Dados","e720ac41":"### Ver como os dados se comportam","9904f7d4":"- Os atributos radius_mean, perimeter_mean e\tarea_mean possuem correla\u00e7\u00e3o acima de 0.9, ent\u00e3o iremos remover os atributos radius_mean e perimeter_mean (escolha arbitr\u00e1ria)\n- Os atributos concavity_mean e concave points_mean possuem correla\u00e7\u00e3o acima de 0.9, ent\u00e3o iremos remover o atributo concavity_mean (escolha arbitr\u00e1ria)\n\nPortanto, nesse primeiro grupo, os atributos que continuar\u00e3o ser\u00e3o: area_mean, texture_mean, smoothness_mean, compactness_mean, concave points_mean, symmetry_mean e fractal_dimension_mean\n\n","2119a52d":"Como o pr\u00f3prio nome diz, esta fase consiste em interpretar os dados gerados e verificar se possuem alguma validade para o problema proposto.\n\nIremos apresentar o Score , Acur\u00e1cia e Tabela de Confus\u00e3o  do modelo quando aplicado para K = 7. As observa\u00e7\u00f5es que podemos tirar acerca desses c\u00e1lculos \u00e9:\n\n- Score: podemos perceber que na maioria dos casos o algoritmo possui muita 'certeza' da classifica\u00e7\u00e3o efetuada.\n- Acur\u00e1cia: o modelo apresenta  cerca de 93% de acur\u00e1cia.\n- Matriz de confus\u00e3o: no teste do modelo existem 4  casos de falso positivo, ou seja, que foram preditos como benignos quando na verdade eram malignos. E 5 casos de falso positivo , ou seja, que foram preditos como benignos quando na verdade eram malignos. Al\u00e9m dos restantes 134 casos que foram corretamente preditos.\n","9e2e00cb":"Transforma\u00e7\u00e3o \u00e9 a etapa de armazenamento dos dados de forma a facilitar o uso das t\u00e9cnicas de Data Mining. \n\nNessa etapa nos separamos a base de dados em duas partes: \n- Treino : dados que ser\u00e3o usados para treinar o modelo.\n- Teste : dados que ser\u00e3o usados para calcular a qualidade do modelo gerado.","e410a9f2":"# Conclus\u00e3o","68f30164":"A etapa de pre-processamento \u00e9 crucial no processo, pois a qualidade dos dados vai determinar a efici\u00eancia dos algoritmos de minera\u00e7\u00e3o.\nNesta etapa s\u00e3o realizadas tarefas que eliminam dados redundantes e inconsistentes, recuperem dados incompletos e avaliam poss\u00edveis dados discrepantes ao conjunto (*outliers*). \nNesta etapa tamb\u00e9m s\u00e3o utilizados m\u00e9todos de redu\u00e7\u00e3o ou transforma\u00e7\u00e3o para diminuir o n\u00famero\nde vari\u00e1veis envolvidas no processo, visando com isto melhorar o desempenho do algoritmo que ser\u00e1 usado na an\u00e1lise dos dados.\n\n","89ff0c08":"Assim assumiremos que o melhor K para esse modelo \u00e9 7, pois o treino apresenta sua maior acur\u00e1cia. ","b47de098":"Os gr\u00e1ficos abaixo mostram as correla\u00e7\u00f5es entre os atributos (*mean, se* e *worst*) e as classes. \n\nObservando os gr\u00e1ficos da diagonal principal (histogramas referente \u00e0 distribui\u00e7\u00e3o dos dados de acordo com o atributo em si) podemos inferir que os atributos area_mean ,  concave points_mean , area_se , concave points_worst e area_worst s\u00e3o bons atributos para a separa\u00e7\u00e3o das classes, visto que a distribui\u00e7\u00e3o dos dados das classes \u00e9 bem distinto.\n","19fdd567":"# Pr\u00e9-processamento ","83431117":"A plotagem de violino nos mostra a distribui\u00e7\u00e3o dos dados de acordo com cada classe e cada atributo. Para cada atributo \u00e0 esquerda do eixo \u00e9 apresentada a distribui\u00e7\u00e3o dos dados para a classe Maligno,  e \u00e0 direita a distribui\u00e7\u00e3o para a classe Benigno.\n\nAtrav\u00e9s da observa\u00e7\u00e3o da plotagem de violino podemos inferir que os atributos area_mean , concave points_mean, area_se, area_worst, concavity_worst e concave points_worst s\u00e3o bons atributos para a separa\u00e7\u00e3o das classes, visto que a distribui\u00e7\u00e3o dos dados das classes \u00e9 bem distinto. ","fe847252":"Autores: \n- Adauto Donizetti de Paula\n- Aline Regina de Oliveira\n- Antonio Luciano Lopes Uliana","4ff889aa":"## Visualiza\u00e7\u00e3o\n","3aa8fea8":"A fase de sele\u00e7\u00e3o dos dados \u00e9 a primeira no processo de descoberta do conhecimento nas atividades de *machine learning* e ci\u00eancias dos dados.\nNesta fase \u00e9 escolhido o conjunto de dados contendo todas as poss\u00edveis vari\u00e1veis, tamb\u00e9m chamadas de caracter\u00edsticas ou atributos, que far\u00e3o parte da an\u00e1lise.\nA etapa de sele\u00e7\u00e3o possui impacto significante sobre a qualidade do resultado do processo.\n\nOs dados que iremos utilizar pertencem a uma base de dados sobre diagn\u00f3stico de c\u00e2ncer de mama dispon\u00edvel na plataforma Kaggle . (https:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data)","54177b8e":"Para melhor visualizar o mapa de calor, foram separados os grupos Mean, SE e Worst.\n\nA ideia do heatmap aqui \u00e9 entender como os atributos se relacionam. Caso tenham grande correla\u00e7\u00e3o, \u00e9 um indicativo de multicolinearidade, que pode levar a resultados distorcidos. Existem v\u00e1rias maneiras de lidar com esse problema, como por exemplo o uso de PCA (*Principal Component Analysis*). Contudo, a abordagem utilizada ser\u00e1 mais simples, que \u00e9 a de simplesmente escolher um dos atributos para manter na base e eliminar os outros que tenham alta correla\u00e7\u00e3o com ele. \n\nPS: algoritmos que usam \u00e1vores de decis\u00e3o evitam problemas de multicolinearidade naturalmente em sua implementa\u00e7\u00e3o.","ca95838c":"# Transforma\u00e7\u00e3o","f495b818":"- Os atributos radius_se, perimeter_se e  area_se possuem correla\u00e7\u00e3o acima de 0.9, ent\u00e3o iremos remover os atributos per\u00edmetro e raio (escolha arbitr\u00e1ria)\n\nPortanto, nesse segundo grupo, os atributos que continuar\u00e3o ser\u00e3o: area_se, texture_se, smoothness_se, compactness_se, concavity_se, concave points_se, symmetry_se e fractal_dimension_se","7bdf3c31":"# Introdu\u00e7\u00e3o","46d6940d":"# Avalia\u00e7\u00e3o","48fdf195":"\n## **Mapa de calor para os dados limpos**\n\nNo mapa de calor \u00e9 feita uma regress\u00e3o linear de todos os atributos combinados 2 a 2, e o valor que aparece nas c\u00e9lulas do mapa de calor s\u00e3o os coeficientes angulares de um atributo em rela\u00e7\u00e3o ao outro, resultante da regress\u00e3o linear. \nPara exemplificar, o valor que aparece nas c\u00e9lulas da diagonal principal, \u00e9 o coeficiente angular de um atributo em rela\u00e7\u00e3o a ele mesmo, logo o valor \u00e9 1. Se o coefiente angular \u00e9 positivo, significa que quando o atributo do eixo horizontal cresce, o atributo do eixo vertical tamb\u00e9m cresce com taxa de varia\u00e7\u00e3o igual ao valor do coeficiente angular. Se o coeficiente angular \u00e9 negativo,  significa que quando o atributo do eixo horizontal cresce, o do eixo vertical  decresce com taxa de varia\u00e7\u00e3o igual ao m\u00f3dulo do coeficiente angular. Por fim, caso o coeficiente seja zero, significa que as duas vari\u00e1veis n\u00e3o dependem linearmente uma da outra. Nesses casos pode existir uma depend\u00eancia n\u00e3o-linear, que seria necess\u00e1rio investig\u00e1-la por outros meios. \n\n\n\n","a30f5d28":"Para fazer a escolha do K ideal calculamos a acur\u00e1cia para k de 1 at\u00e9 15 com *cross validation*.\n> ***Cross Validation*** (valida\u00e7\u00e3o cruzada) \u00e9 o particionamento do conjunto de dados em subconjuntos mutualmente exclusivos, e posteriormente, utiliza-se alguns destes subconjuntos para a estima\u00e7\u00e3o dos par\u00e2metros do modelo (dados de treinamento) e o restante dos subconjuntos (dados de valida\u00e7\u00e3o ou de teste) s\u00e3o empregados na valida\u00e7\u00e3o do modelo.","9438f18c":"Realizamos todas as etapas do KDD  (Sele\u00e7\u00e3o dos dados, Pr\u00e9-processamento, Transforma\u00e7\u00e3o, Minera\u00e7\u00e3o de Dados, Avalia\u00e7\u00e3o) na abordagem do algoritmo de aprendizado de m\u00e1quina KNN aplicado na base de dados referente ao diagn\u00f3stico de c\u00e2ncer de mama. \n\n\u00c9 poss\u00edvel concluir que a acur\u00e1cia de 93% obtida pelo modelo  \u00e9 satisfat\u00f3ria. \n\nNuma pr\u00f3xima abordagem poderiam ser definidos quais s\u00e3o os atributos mais relevantes para a separa\u00e7\u00e3o das classes a fim de atribuir um peso maior a esses atributos no momento da classifica\u00e7\u00e3o de um novo dado. Atributos que seriam candidatos a um peso maior s\u00e3o os que foram comentados na se\u00e7\u00e3o da Plotagem de violino (area_mean ,  concave points_mean , area_se , concave points_worst e area_worst )  e na se\u00e7\u00e3o de Gr\u00e1fico de pares de atributos (area_mean ,  concave points_mean , area_se , concave points_worst e area_worst ).\n","bd78eb94":"## C\u00e1lculo de score","62167edb":"Para visualizar os dados ser\u00e1 utilizada a biblioteca seaborn para plotar graficos \u00fateis para compreens\u00e3o das informa\u00e7\u00f5es a respeito dos atributos da base de dados.\n"}}