{"cell_type":{"f31b672a":"code","7d486c3c":"code","8739e2f9":"code","39c633e9":"code","bbe5749d":"code","28e011a4":"code","30f034c9":"code","2ef3a249":"code","edb64d57":"code","ab4b107c":"code","95e0f719":"code","9df5c934":"code","1212ab02":"code","78820b3d":"code","292c03f1":"code","14f5db8a":"code","f8e4c910":"code","12f69f20":"code","05e8b0cc":"code","93dd9821":"code","149271a4":"code","e70f9078":"code","5f362a42":"code","c79e7695":"code","c0e3e9bb":"code","8ffb79e5":"code","36862811":"code","c17de4d7":"code","2e8c037c":"code","cd03606a":"code","23a3b9a3":"markdown","6cc09913":"markdown","5f7a2ecb":"markdown","078b9d87":"markdown","050d9ef4":"markdown","f7bea752":"markdown","e95b5de5":"markdown"},"source":{"f31b672a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt","7d486c3c":"os.listdir('..\/input\/100-bird-species')\nBASE_DIR ='..\/input\/100-bird-species\/'\nTRAIN_DIR = os.path.join(BASE_DIR,'train')\nTEST_DIR = os.path.join(BASE_DIR,'test')\nVALID_DIR = os.path.join(BASE_DIR,'valid')\nCONSOLIDATED = os.path.join(BASE_DIR, 'consolidated')","8739e2f9":"BATCH_SIZE=32\nIMAGE_SIZE=[112,112]\nAUTOTUNE = tf.data.experimental.AUTOTUNE","39c633e9":"TCLASS_NAME = np.array([item for item in os.listdir(TEST_DIR)]) #classnames @train\nVCLASS_NAME = np.array([item for item in os.listdir(VALID_DIR)]) #VLIDATION CLASS NAMES\nCONSO_CLASS_NAME = np.array([item for item in os.listdir(CONSOLIDATED)])\nprint('Total Numbers of Training calsses:',len(TCLASS_NAME))\nprint('Total Number of Valid calsses:',len(VCLASS_NAME))","bbe5749d":"TRAIN_LS_DS = tf.data.Dataset.list_files(str(TRAIN_DIR +'\/*\/*')) #LIST ALL THE TRAINING FILES\nVALID_LS_DS = tf.data.Dataset.list_files(str(VALID_DIR+'\/*\/*')) #LIST OF ALL VLAIDATION FILES\nCONSO_LS_DS = tf.data.Dataset.list_files(str(CONSOLIDATED+'\/*\/*'))\nTEST_LS_DS = tf.data.Dataset.list_files(str(TEST_DIR+'\/*\/*'))","28e011a4":"TOTAL_DS = TRAIN_LS_DS.concatenate(CONSO_LS_DS)\nTOTAL_DS = TOTAL_DS.concatenate(VALID_LS_DS)","30f034c9":"#len(list(TOTAL_DS.as_numpy_iterator()))\nDATASET_SIZE = 58006\n\n#sice our total data size is 58006 and then spliting it into train and valid files\n\ntrain_size = int(0.7 * DATASET_SIZE)\nval_size = int(0.15 * DATASET_SIZE)","2ef3a249":"'''for i in range(1,9):\n    print(TRAIN_DIR + '\/'+ TCLASS_NAME[i] + f'\/00{i}.jpg')'''","edb64d57":"w=10\nh=10\nfig=plt.figure(figsize=(15, 15))\ncolumns = 3\nrows = 3\nfor i in range(1, columns*rows +1):\n    img = TOTAL_DS.take(20)\n    fig.add_subplot(rows, columns, i)\n    k = cv2.imread(TRAIN_DIR + '\/'+ TCLASS_NAME[i] + f'\/00{i}.jpg')\n    plt.imshow(k)\nplt.show()","ab4b107c":"def get_label(file_path):\n    parts =tf.strings.split(file_path, os.path.sep)\n    return parts[-2] == TCLASS_NAME\n\ndef decode_img(img):\n    img = tf.image.decode_jpeg(img,3)\n    img = tf.image.convert_image_dtype(img,tf.float32)\n    return tf.image.resize(img, ([*IMAGE_SIZE]))\ndef augment(img):\n    img = decode_img(img)\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_crop(img ,(*IMAGE_SIZE,3))\n    return img\ndef process_path(file_path):\n    label = get_label(file_path)\n    img =tf.io.read_file(file_path)\n    img = augment(img)\n    return img, label","95e0f719":"DS= TOTAL_DS.map(process_path, num_parallel_calls=AUTOTUNE)","9df5c934":"for image, label in DS.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","1212ab02":"def get_dataset(ds, cache=True):\n    ds = ds.cache()\n    ds = ds.shuffle(1000)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds","78820b3d":"full_train_ds = get_dataset(DS)\n\ntrain_dataset = full_train_ds.take(train_size)\nvalid_dataset = full_train_ds.take(val_size)\n\n","292c03f1":"image_batch, label_batch = next(iter(train_dataset))\ndef show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(TCLASS_NAME[label_batch[n]==1][0].title())\n      plt.axis('off')","14f5db8a":"show_batch(image_batch.numpy(), label_batch.numpy())","f8e4c910":"base_model_2 = tf.keras.applications.DenseNet121(\n    include_top=False, weights='imagenet', input_shape=(112,112,3))","12f69f20":"'''base_model_1 = tf.keras.applications.ResNet101(input_shape=(*IMAGE_SIZE,3),include_top = False,\n                                             weights ='imagenet')\nbase_model_1.trainable = True'''\n\n'''model = tf.keras.Sequential([base_model_1,\n                            tf.keras.layers.GlobalAveragePooling2D(),\n                            tf.keras.layers.Dense(len(TCLASS_NAME), activation='softmax')])\nmodel.summary()'''\n\n'''base_learning_rate = 0.001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n             loss =tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])'''\n\n'''loss0,accuracy0 = model.evaluate(valid_dataset, steps = validation_steps)'''\n\n'''history = model.fit(train_dataset,\n                    epochs=initial_epochs,steps_per_epoch = 20,\n                    validation_data=valid_dataset,validation_steps = 10)'''","05e8b0cc":"initial_epochs = 20\nvalidation_steps=10\nbase_learning_rate = 0.0001","93dd9821":"model_2 = tf.keras.Sequential([base_model_2,\n                            tf.keras.layers.GlobalAveragePooling2D(),\n                            tf.keras.layers.Dense(len(TCLASS_NAME), activation='softmax')])","149271a4":"model_2.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n             loss =['categorical_crossentropy'],metrics=['accuracy'])","e70f9078":"history_1 = model_2.fit(train_dataset,\n                    epochs=initial_epochs,steps_per_epoch = initial_epochs,\n                    validation_data=valid_dataset,validation_steps = validation_steps)","5f362a42":"acc = history_1.history['accuracy']\nval_acc = history_1.history['val_accuracy']\n\nloss = history_1.history['loss']\nval_loss = history_1.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')","c79e7695":"#fine tuning the model","c0e3e9bb":"len(base_model_2.layers)","8ffb79e5":"fine_tune = 201\nbase_model_2.trainable = True\nfor layer in base_model_2.layers[:fine_tune]:\n    layer.trainable = False","36862811":"model_2.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n             loss =['categorical_crossentropy'],\n             metrics=['accuracy'])","c17de4d7":"fine_tune_epochs = 20\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model_2.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch =  history_1.epoch[-1],\n                         validation_data=valid_dataset,\n                        steps_per_epoch=45,\n                    validation_steps=15)","2e8c037c":"def proces_test_path(filename):\n        img = tf.io.read_file(filename)\n        img = tf.image.decode_jpeg(img)\n        return (img)\n    ","cd03606a":"TEST_DS = TEST_LS_DS.map(proces_test_path, num_parallel_calls=AUTOTUNE)","23a3b9a3":"### Lets see some class images","6cc09913":"Since given validation data is quite small So I combined all data except test data and then divided into the train and validaiton split ","5f7a2ecb":"## Beautiful Birds ","078b9d87":"### Datasets need to be:\n* Well shuffled\n* Repeat after some time\n* Divide into batches\n* tensorflow prefetch technique ","050d9ef4":"images augmenatation ","f7bea752":"### Reading Images with their labels *class* names using tensorflow","e95b5de5":"# Will update the Notebook as I deal with the newer problems."}}