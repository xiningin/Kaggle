{"cell_type":{"9b57267e":"code","b92b94aa":"code","fbc0f633":"code","d10385fb":"code","15e3f02a":"code","3f59b894":"markdown"},"source":{"9b57267e":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom multiprocessing import Pool\nimport multiprocessing as mp\n#from dataProcessing import loadImage\nimport matplotlib.pyplot as plt\nimport time","b92b94aa":"BATCH_SIZE = 16\nTEST_BATCH_SIZE = 16\nSEED = 777\nSHAPE = (512, 512, 4)\nCORES = mp.cpu_count() #4\nDIR = '..\/input'\nOUTPUT_DIR = '.'\nDEBUG = True","fbc0f633":"def getTrainDataset():\n    \n    path_to_train = DIR + '\/train\/'\n    data = pd.read_csv(DIR + '\/train.csv')\n\n    paths = []\n    labels = []\n    \n    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n        y = np.zeros(28)\n        for key in lbl:\n            y[int(key)] = 1\n        paths.append(os.path.join(path_to_train, name))\n        labels.append(y)\n\n    return np.array(paths), np.array(labels)\n\n\ndef getTestDataset():\n    \n    path_to_test = DIR + '\/test\/'\n    data = pd.read_csv(DIR + '\/sample_submission.csv')\n\n    paths = []\n    labels = []\n    \n    for name in data['Id']:\n        y = np.ones(28)\n        paths.append(os.path.join(path_to_test, name))\n        labels.append(y)\n\n    return np.array(paths), np.array(labels)\n\n\ndef prepareData(paths, labels, shuffle = True, shape = SHAPE, seed = SEED, batch_size = BATCH_SIZE, debug = False):\n    \n    keys = np.arange(paths.shape[0], dtype=np.int)\n    if(shuffle):\n        np.random.seed(seed)\n        np.random.shuffle(keys)\n\n    if(paths.shape[0] % batch_size != 0):\n        remaining = (paths.shape[0] \/\/ batch_size + 1) * batch_size - paths.shape[0]\n        keys = np.append(keys, np.zeros(remaining, dtype=np.int32))\n        \n    keys = keys.reshape(-1,batch_size)\n    \n    if debug == True:\n        keys = keys[0:8]\n    \n    paths = paths[keys]\n    labels = labels[keys]\n    \n    processImages(paths, labels, shape)\n    \n    return paths, labels\n\n\ndef loadImage(path):\n\n        R = Image.open(path + '_red.png')\n        G = Image.open(path + '_green.png')\n        B = Image.open(path + '_blue.png')\n        Y = Image.open(path + '_yellow.png')\n\n        im = np.stack((\n            np.array(R), \n            np.array(G), \n            np.array(B),\n            np.array(Y)), -1)\n        \n        im = np.divide(im, 255)\n        return im\n\n    \ndef processImages(paths, labels, shape):\n    \n    p = Pool(CORES)\n    \n    for batch in tqdm(range(paths.shape[0])):\n\n        batch_size = paths[batch].shape[0]\n        n_labels = labels[batch].shape[1]\n        \n        batch_labels = np.zeros((batch_size, n_labels))\n        \n        batch_images = np.array(p.map(loadImage, paths[batch]))\n        batch_labels = labels[batch]\n        np.savez(os.path.dirname(paths[batch][0]).replace(DIR, OUTPUT_DIR) + '-memory'+str(batch), images=batch_images, labels=batch_labels)","d10385fb":"paths, labels = getTrainDataset()\npathsTrain, labelsTrain = prepareData(paths, labels, debug = DEBUG)","15e3f02a":"paths, labels = getTestDataset()\npathsTest, labelsTest = prepareData(paths, labels, shuffle=False, batch_size = TEST_BATCH_SIZE, debug = DEBUG)","3f59b894":"The goal of this notebook is to precompute the batches using multiprocessing CPU and store these batches as savez_compressed numpy arrays as described in the discussion https:\/\/www.kaggle.com\/c\/human-protein-atlas-image-classification\/discussion\/68118\n\nDue to the limited storage on Kaggle kernel, we process only part of the training and test set (first 64 batches). The results are stored to the output directory, so that other kernels can use the computation results as input."}}