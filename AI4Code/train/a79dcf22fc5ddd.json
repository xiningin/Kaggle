{"cell_type":{"0d258068":"code","3a6c225b":"code","6e5ad387":"code","0531f901":"code","ae55507a":"code","c6746869":"code","9f2fcb16":"code","d4c3c3dc":"markdown"},"source":{"0d258068":"#impor relevent packages\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds","3a6c225b":"#import the dataset\nmnist_dataset, mnist_info= tfds.load(name='mnist',with_info=True, as_supervised=True)","6e5ad387":"mnist_train, mnist_test= mnist_dataset['train'], mnist_dataset['test']\n\nnum_validation_samples= 0.1 * mnist_info.splits['train'].num_examples\nnum_validation_samples= tf.cast(num_validation_samples,tf.int64)\n\nnum_test_samples= mnist_info.splits['test'].num_examples\nnum_test_samples=tf.cast(num_test_samples,tf.int64)\n\ndef scale(image,label):\n    image=tf.cast(image, tf.float32)\n    image \/= 255.\n    return image, label\n\nscaled_train_and_validation_data= mnist_train.map(scale)\n\ntest_data= mnist_test.map(scale)\n\nBUFFER_SIZE= 10000\n\nshuffled_train_and_validation_data=scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n\nvalidation_data= shuffled_train_and_validation_data.take(num_validation_samples)\ntrain_data=shuffled_train_and_validation_data.skip(num_validation_samples)\n\n\nBATCH_SIZE=100\n\ntrain_data=train_data.batch(BATCH_SIZE)\nvalidation_data=validation_data.batch(num_validation_samples)\n\ntest_data=test_data.batch(num_test_samples)\n\nvalidation_inputs, validation_targets= next(iter(validation_data))","0531f901":"#outline the model\ninput_size= 784\noutput_size= 10\nhidden_layer_size= 200\n\nmodel= tf.keras.Sequential([\n                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(output_size, activation='softmax'),\n                            ])","ae55507a":"# Choose the optimizer and loss function\nmodel.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])","c6746869":"#training the model\nNUM_EPOCHS=8\n\nmodel.fit(train_data, epochs= NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2)","9f2fcb16":"#Testing the model\ntest_loss, test_accuracy= model.evaluate(test_data)\nprint('Test loss:{0:.2f}.Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))","d4c3c3dc":"**Model**"}}