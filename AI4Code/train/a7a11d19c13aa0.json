{"cell_type":{"d8d3ee1c":"code","6bd7c880":"code","c5b1d208":"code","a57d30ca":"code","4409046b":"code","e4542721":"code","7ecccfa0":"code","28b787b1":"code","f6516b89":"code","b11f2588":"code","0ccb2c22":"code","572d7d73":"code","63b7a494":"code","5bbb1be1":"code","d767dcbb":"code","2236c010":"markdown","e8fab653":"markdown"},"source":{"d8d3ee1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6bd7c880":"train = pd.read_csv('..\/input\/learn-together\/train.csv')\ntest = pd.read_csv('..\/input\/learn-together\/test.csv')","c5b1d208":"train.columns","a57d30ca":"test.columns","4409046b":"train = train.iloc[:, :15].join(train.iloc[:,15:-2] \\\n                          .dot(range(1,40)).to_frame('Soil_Type1')) \\\n                          .join(train.iloc[:,-1])\ntrain.columns","e4542721":"train.shape","7ecccfa0":"train = train.iloc[:, :11].join(train.iloc[:,11:-2] \\\n                          .dot(range(1,5)).to_frame('Wilderness_Area1')) \\\n                          .join(train.iloc[:,-2:])\ntrain.columns","28b787b1":"X = train.drop(['Cover_Type'], axis = 1)\ny = train.Cover_Type","f6516b89":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","b11f2588":"from sklearn.ensemble import RandomForestClassifier\n\nforest_model = RandomForestClassifier(n_estimators=10)\nforest_model.fit(X_train,y_train)","0ccb2c22":"from sklearn.metrics import mean_absolute_error\n\nval_predictions = forest_model.predict(X_val)\nval_mae = mean_absolute_error(y_val,val_predictions)\nval_mae","572d7d73":"test = test.iloc[:, :15].join(test.iloc[:,15:-1].dot(range(1,40)).to_frame('Soil_Type1')) \ntest.columns","63b7a494":"test.shape","5bbb1be1":"test = test.iloc[:, :11].join(test.iloc[:,11:-1] \\\n                          .dot(range(1,5)).to_frame('Wilderness_Area1')) \\\n                          .join(test.iloc[:,-1])\ntest.columns","d767dcbb":"test_preds = forest_model.predict(test)\noutput = pd.DataFrame({'Id': test.Id, 'Cover_Type': test_preds.astype(int)})\noutput.to_csv('submission.csv', index=False)","2236c010":"This attempt did slightly better than the previous try. Will cross-validation help let's see.","e8fab653":"## Still think features can be reduced without the ML tools - another try."}}