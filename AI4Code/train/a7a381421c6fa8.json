{"cell_type":{"aa6d8d7c":"code","6a667a48":"code","7fe7ea81":"code","5d68c6f5":"code","6760a5d7":"code","a2d479d2":"code","66d427b2":"code","e5bed969":"code","93f51689":"code","ef333a4f":"code","ca7ccd1f":"code","e0ec7861":"code","8100c602":"code","6c8a7ab3":"code","9a29fd84":"code","8e10bdb0":"code","cbaa7d8c":"markdown","e4346b46":"markdown","206a2dff":"markdown","b076252a":"markdown","595aea44":"markdown","278bbc9e":"markdown","682afa2e":"markdown"},"source":{"aa6d8d7c":"!pip install efficientnet tensorflow_addons > \/dev\/null","6a667a48":"import os\nimport math\nimport random\nimport re\nimport warnings\nfrom pathlib import Path\nfrom typing import Optional, Tuple\n\nimport efficientnet.tfkeras as efn\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import KFold","7fe7ea81":"tf.__version__","5d68c6f5":"NUM_FOLDS = 4\nIMAGE_SIZE = 256\nBATCH_SIZE = 64\nEFFICIENTNET_SIZE = 0\nWEIGHTS = \"imagenet\"\nN_CLASSES = 81313\nFOLDS = [0, 1, 2, 3]\nEPOCHS = 20\nSEED = 1213\n\nSAVEDIR = Path(\".\/\")","6760a5d7":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n\nset_seed(SEED)","a2d479d2":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    return strategy","66d427b2":"strategy = auto_select_accelerator()\nREPLICAS = strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE","e5bed969":"gcs_paths = []\nfor i in range(5):\n    gcs_path = KaggleDatasets().get_gcs_path(f\"landmark-recognition-2021-tfrecords-fold{i}\")\n    print(gcs_path)\n    gcs_paths.append(gcs_path)\n    \nall_files = []\nfor path in gcs_paths:\n    all_files.extend(np.sort(np.array(tf.io.gfile.glob(path + \"\/*.tfrec\"))))\n\nprint(\"train files: \", len(all_files))","93f51689":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.image.resize(image, size=(IMAGE_SIZE, IMAGE_SIZE))\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image\n\n\ndef read_labeled_tfrecord(example):\n    tfrec_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),\n    }\n\n    example = tf.io.parse_single_example(example, tfrec_format)\n    posting_id = example[\"image_name\"]\n    image = decode_image(example[\"image\"])\n    label_group = tf.cast(example[\"target\"], tf.int32)\n    matches = 1\n    return posting_id, image, label_group, matches\n\n\ndef arcface_format(posting_id, image, label_group, matches):\n    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches\n\n\n# This function loads TF Records and parse them into tensors\ndef load_dataset(filenames, batch_size=64, cache=False, repeat=False, shuffle=False):        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n    if cache:\n        dataset = dataset.cache()\n\n    if shuffle:\n        dataset = dataset.shuffle(2048)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        dataset = dataset.with_options(opt)\n\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n    dataset = dataset.map(arcface_format, num_parallel_calls=AUTO)\n    if repeat:\n        dataset = dataset.repeat()\n    dataset = dataset.batch(batch_size * REPLICAS)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n\ndef count_data_items(filenames):\n    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","ef333a4f":"NUM_TRAINING_IMAGES = count_data_items(all_files)\nNUM_TRAINING_IMAGES","ca7ccd1f":"class GeM(tf.keras.layers.Layer):\n    def __init__(self, pool_size, init_norm=3.0, normalize=False, **kwargs):\n        self.pool_size = pool_size\n        self.init_norm = init_norm\n        self.normalize = normalize\n\n        super(GeM, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'pool_size': self.pool_size,\n            'init_norm': self.init_norm,\n            'normalize': self.normalize,\n        })\n        return config\n\n    def build(self, input_shape):\n        feature_size = input_shape[-1]\n        self.p = self.add_weight(name='norms', shape=(feature_size,),\n                                 initializer=tf.keras.initializers.constant(self.init_norm),\n                                 trainable=True)\n        super(GeM, self).build(input_shape)\n\n    def call(self, inputs):\n        x = inputs\n        x = tf.math.maximum(x, 1e-6)\n        x = tf.pow(x, self.p)\n\n        x = tf.nn.avg_pool(x, self.pool_size, self.pool_size, 'VALID')\n        x = tf.pow(x, 1.0 \/ self.p)\n\n        if self.normalize:\n            x = tf.nn.l2_normalize(x, 1)\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, input_shape[-1]])","e0ec7861":"class ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https:\/\/arxiv.org\/pdf\/1801.07698.pdf\n        https:\/\/github.com\/lyakaap\/Landmark2019-1st-and-3rd-Place-Solution\/\n            blob\/master\/src\/modeling\/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps \/ self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","8100c602":"def build_model(size=256, efficientnet_size=0, weights=\"imagenet\", count=0):\n    inp = tf.keras.layers.Input(shape=(size, size, 3), name=\"inp1\")\n    label = tf.keras.layers.Input(shape=(), name=\"inp2\")\n    x = getattr(efn, f\"EfficientNetB{efficientnet_size}\")(\n        weights=weights, include_top=False, input_shape=(size, size, 3))(inp)\n    x = GeM(8)(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, name=\"dense_before_arcface\", kernel_initializer=\"he_normal\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = ArcMarginProduct(\n        n_classes=N_CLASSES,\n        s=30,\n        m=0.5,\n        name=\"head\/arc_margin\",\n        dtype=\"float32\"\n    )([x, label])\n    output = tf.keras.layers.Softmax(dtype=\"float32\")(x)\n    model = tf.keras.Model(inputs=[inp, label], outputs=[output])\n    lr_decayed_fn = tf.keras.experimental.CosineDecay(1e-3, count)\n    opt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate=1e-4)\n    model.compile(\n        optimizer=opt,\n        loss=[tf.keras.losses.SparseCategoricalCrossentropy()],\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n    )\n    return model","6c8a7ab3":"def get_lr_callback(plot=False):\n    lr_start   = 1e-3\n    lr_max     = 0.00003 * BATCH_SIZE  \n    lr_min     = 1e-5\n    lr_ramp_ep = 4\n    lr_sus_ep  = 0\n    lr_decay   = 0.9\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) \/ lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n        \n    if plot:\n        epochs = list(range(EPOCHS))\n        learning_rates = [lrfn(x) for x in epochs]\n        plt.scatter(epochs,learning_rates)\n        plt.show()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\nget_lr_callback(plot=True)","9a29fd84":"kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\nfiles_train_all = np.array(all_files)","8e10bdb0":"for fold, (trn_idx, val_idx) in enumerate(kf.split(files_train_all)):\n    if fold not in FOLDS:\n        continue\n    files_train = files_train_all[trn_idx]\n    files_valid = files_train_all[val_idx]\n\n    print(\"=\" * 120)\n    print(f\"Fold {fold}\")\n    print(\"=\" * 120)\n\n    train_image_count = count_data_items(files_train)\n    valid_image_count = count_data_items(files_valid)\n\n    tf.keras.backend.clear_session()\n    strategy = auto_select_accelerator()\n\n    with strategy.scope():\n        model = build_model(\n            size=IMAGE_SIZE,\n            efficientnet_size=EFFICIENTNET_SIZE,\n            weights=WEIGHTS,\n            count=train_image_count \/\/ BATCH_SIZE \/\/ REPLICAS \/\/ 4\n        )\n\n    model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n        str(SAVEDIR \/ f\"fold{fold}.h5\"), monitor=\"val_loss\", verbose=1, save_best_only=True,\n        save_weights_only=True, mode=\"min\", save_freq=\"epoch\"\n    )\n\n    train_dataset = load_dataset(files_train, batch_size=BATCH_SIZE, shuffle=True, repeat=True)\n    train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n\n    valid_dataset = load_dataset(files_valid, batch_size=BATCH_SIZE * 2, shuffle=False, repeat=False)\n    valid_dataset = valid_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n\n    STEPS_PER_EPOCH = train_image_count \/\/ BATCH_SIZE \/\/ REPLICAS \/\/ 4\n    history = model.fit(\n        train_dataset,\n        epochs=EPOCHS,\n        callbacks=[model_ckpt, get_lr_callback()],\n        steps_per_epoch=STEPS_PER_EPOCH,\n        validation_data=valid_dataset,\n        verbose=1\n    )","cbaa7d8c":"## About\n\nIn this notebook, I'll train a model based on EfficientNetB0, GeM pooling, and ArcFace. \n\nThe whole training pipeline is built with TensorFlow, and the training will be done on TPU.\n\nThis notebook is based on [stratified-tfrecords-training-pipeline](https:\/\/www.kaggle.com\/ks2019\/stratified-tfrecords-training-pipeline).","e4346b46":"## Config","206a2dff":"## Utilities","b076252a":"## Data Loading","595aea44":"## Other training utilities","278bbc9e":"## Training","682afa2e":"## Model"}}