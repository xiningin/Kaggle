{"cell_type":{"dc428ef6":"code","06c4fbe7":"code","828c1402":"code","b43a3b35":"code","7e0c407f":"code","cbc47823":"code","efd5bef2":"code","9f0f135a":"code","7ff4d43c":"code","9831af19":"code","0b17c903":"code","2092eca1":"code","fab7975d":"code","e0ef4317":"code","12b900c2":"code","493a3c6c":"markdown","014e28d7":"markdown","8fa18528":"markdown"},"source":{"dc428ef6":"import  datetime,os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom urllib.request import urlopen\nfrom numpy import asarray\nfrom tensorflow.keras import layers\nimport os.path","06c4fbe7":"data_dir = '..\/input\/stanford-dogs-dataset\/'\nbreed_list = os.listdir(data_dir + 'images\/Images\/')\n\n#data_dir = 'data\/'\n#breed_list = os.listdir(data_dir + 'images\/Images\/')","828c1402":"#Crop function\ndef crop_image(breed, dog, data_dir):\n  img = plt.imread(data_dir + 'images\/Images\/' + breed + '\/' + dog + '.jpg')\n  tree = ET.parse(data_dir + 'annotations\/Annotation\/' + breed + '\/' + dog)\n  xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n  xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n  ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n  ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n  img = img[ymin:ymax, xmin:xmax, :]\n  return img","b43a3b35":"# Create a new folder to store cropped images\nDIR_DATA = 'new_data'\nif DIR_DATA not in os.listdir():\n    os.mkdir(DIR_DATA)\n    \nfor breed in breed_list:\n    try:\n        os.mkdir(DIR_DATA + '\/' + breed)\n    except FileExistsError:\n        pass","7e0c407f":"# Lets crop images!\nfor breed in os.listdir(DIR_DATA):\n    for file in os.listdir(data_dir + 'annotations\/Annotation\/' + breed):\n        if file != '.ipynb_checkpoints':\n            file_name = f\"{DIR_DATA}\/{breed}\/{file}.jpg\"\n            if os.path.isfile(file_name):\n                pass\n            else:\n                img = Image.open(data_dir + 'images\/Images\/' + breed + '\/' + file + '.jpg')\n                tree = ET.parse(data_dir + 'annotations\/Annotation\/' + breed + '\/' + file)\n                xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n                xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n                ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n                ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n                img = img.crop((xmin,ymin,xmax,ymax))\n                img = img.convert('RGB')\n                img.save(file_name)\n\n","cbc47823":"DIR_DATA = '.\/new_data'\nIMG_SIZE = 100\nNUM_CLASES = 120\nBATCH_SIZE = 1024\nEPOCHS = 5","efd5bef2":"train_datagen = ImageDataGenerator(rescale = 1.\/255, \n    shear_range=0.1,\n    horizontal_flip=True,\n    validation_split=0.2)\n\ntrain_set = train_datagen.flow_from_directory(\n    DIR_DATA,\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size= BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\ntraining_samples = train_set.samples\n\n\ntest_set = train_datagen.flow_from_directory(\n    DIR_DATA,\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size= BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)\n\ntest_samples = test_set.samples\n","9f0f135a":"# Base model\nbase_model = keras.applications.DenseNet121(\n    weights = 'imagenet',\n    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    include_top=False)\nbase_model.trainable = False","7ff4d43c":"# Custom Architecture\nx = base_model.output\nx = keras.layers.GlobalAveragePooling2D()(x)\n\n\nx = keras.layers.Dense(256, activation='relu')(x)\nx = keras.layers.Dropout(0.2)(x)\nx = keras.layers.Dense(1024, activation='relu')(x)\noutputs = keras.layers.Dense(NUM_CLASES, activation='softmax')(x)\n\n# Coupling the base model with the custom Architecture\nmodel = keras.Model(base_model.input, outputs)\n\n\n# Freeze layers.\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0.001),\n              metrics=['accuracy'])\n\n# Model summary\nmodel.summary()","9831af19":"# Lets train our model\nbatch_size=BATCH_SIZE\nhistory = model.fit(\n    train_set,\n    epochs=EPOCHS,\n    steps_per_epoch= training_samples\/\/batch_size,\n    workers=12,\n    verbose=1,\n    shuffle=True,\n    validation_data=test_set,\n    validation_steps=test_samples\/\/batch_size\n)","0b17c903":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1])\nplt.show()\n\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 10])\nplt.show()","2092eca1":"model_eval = model.evaluate_generator (\n    test_set,\n    verbose=0\n)\n\nprint('Model accuracy:',model_eval[1])\nprint('Model loss:',model_eval[0])","fab7975d":"image_boxer =  urlopen(\"https:\/\/i.pinimg.com\/originals\/16\/cf\/a8\/16cfa8b6ea2c773a6e6ca0308c0b65ee.jpg\")\nimage_boxer = Image.open(image_boxer)\nimage_boxer = image_boxer.convert('RGB')\nimage_boxer = image_boxer.resize((IMG_SIZE,IMG_SIZE))\nimage_boxer = np.asarray(image_boxer) \/ 255\n\nplt.imshow(image_boxer)\nplt.show()\n\npred = model.predict(np.array([image_boxer]))\ny_class = pred.argmax(axis=-1)\nprint(\"Prediccion:\",labels[y_class[0]])","e0ef4317":"image_beagle =  urlopen(\"https:\/\/www.britannica.com\/explore\/savingearth\/wp-content\/uploads\/sites\/4\/2020\/05\/beagle2-1.jpg\")\nimage_beagle = Image.open(image_beagle)\nimage_beagle = image_beagle.convert('RGB')\nimage_beagle = image_beagle.resize((IMG_SIZE,IMG_SIZE))\nimage_beagle = np.asarray(image_beagle) \/ 255\n\nplt.imshow(image_beagle)\nplt.show()\n\npred = model.predict(np.array([image_beagle]))\ny_class = pred.argmax(axis=-1)\nprint(\"Prediccion:\",labels[y_class[0]])","12b900c2":"image_chihuahua =  urlopen(\"https:\/\/www.purina.es\/sites\/default\/files\/2019-06\/Chihuahua%20%28de%20pelo%20suave%29%20_400x378_0.jpg\")\nimage_chihuahua = Image.open(image_chihuahua)\nimage_chihuahua = image_chihuahua.convert('RGB')\nimage_chihuahua = image_chihuahua.resize((IMG_SIZE,IMG_SIZE))\nimage_chihuahua = np.asarray(image_chihuahua) \/ 255\n\nplt.imshow(image_chihuahua)\nplt.show()\n\npred = model.predict(np.array([image_chihuahua]))\ny_class = pred.argmax(axis=-1)\nprint(\"Prediccion:\",labels[y_class[0]])","493a3c6c":"## TRANSFER LEARNING","014e28d7":"## Image augmentation and sets","8fa18528":"## CREATE IMAGES BASED ON THE ANNOTATIONS"}}