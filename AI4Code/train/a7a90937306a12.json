{"cell_type":{"5a55dea7":"code","db1968e1":"code","6a1e8382":"code","4df52bc5":"code","107c1fb5":"code","20ee30b5":"code","1e7c79b2":"code","77b2204e":"code","d8b61a2b":"code","44075e02":"code","b7d1cecb":"code","81ddabd3":"code","4eada6c7":"code","f79526d4":"code","98bf4c9a":"code","40aa1372":"code","c01b80ba":"code","e8ccc119":"code","cb783858":"code","719294fd":"code","49ace9ac":"code","5c54378f":"markdown","6578ff96":"markdown","7f3b5b19":"markdown","183b6e12":"markdown","28a7278f":"markdown","2a935cb6":"markdown","b3ba02fb":"markdown","3ca76839":"markdown","627211f3":"markdown","6cffb273":"markdown","50943115":"markdown","94689635":"markdown"},"source":{"5a55dea7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","db1968e1":"#Importing packages for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Importing packages for data preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n#Importing packages for machine learning\nfrom sklearn.model_selection import train_test_split","6a1e8382":"pd_data = pd.read_csv(\"..\/input\/train.csv\")","4df52bc5":"pd_data.head(10)","107c1fb5":"pd_data.info()","20ee30b5":"total = pd_data.isnull().sum().sort_values(ascending=False)\npercent = (pd_data.isnull().sum()\/pd_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","1e7c79b2":"pd_data = pd_data.drop([\"Alley\",\"FireplaceQu\",\"PoolQC\",\"Fence\",\"MiscFeature\",\"Id\",\"LotFrontage\"], axis=1)","77b2204e":"pd_data = pd_data.drop([\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageQual\",\"GarageCond\"],axis = 1)\npd_data = pd_data.drop([\"BsmtFinType2\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtCond\",\"BsmtQual\"], axis = 1)\npd_data = pd_data.drop([\"MasVnrType\"], axis = 1)","d8b61a2b":"pd_data['MasVnrArea'].fillna(pd_data['MasVnrArea'].median(), inplace = True)","44075e02":"pd_data = pd_data.fillna(pd_data['Electrical'].value_counts().index[0])","b7d1cecb":"total = pd_data.isnull().sum().sort_values(ascending = False)\npercent = (pd_data.isnull().sum()\/pd_data.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(3)","81ddabd3":"correlations = pd_data.corr()\nplt.figure(figsize=(12,12))\ng = sns.heatmap(correlations,cbar = True, square = True, fmt= '.2f', annot_kws={'size': 12})","4eada6c7":"k = 10 \ncols = correlations.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(pd_data[cols].values.T)\nsns.set(font_scale = 1)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, \n                 yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","f79526d4":"le = LabelEncoder()\n\npd_data['MSZoning']      = le.fit_transform(pd_data['MSZoning'])\npd_data['Exterior1st']   = le.fit_transform(pd_data['Exterior1st'])\npd_data['Exterior2nd']   = le.fit_transform(pd_data['Exterior2nd'])\npd_data['KitchenQual']   = le.fit_transform(pd_data['KitchenQual'])\npd_data['Functional']    = le.fit_transform(pd_data['Functional'])\npd_data['SaleType']      = le.fit_transform(pd_data['SaleType'])\npd_data['Street']        = le.fit_transform(pd_data['Street'])   \npd_data['LotShape']      = le.fit_transform(pd_data['LotShape'])   \npd_data['LandContour']   = le.fit_transform(pd_data['LandContour'])   \npd_data['LotConfig']     = le.fit_transform(pd_data['LotConfig'])   \npd_data['LandSlope']     = le.fit_transform(pd_data['LandSlope'])   \npd_data['Neighborhood']  = le.fit_transform(pd_data['Neighborhood'])   \npd_data['Condition1']    = le.fit_transform(pd_data['Condition1'])   \npd_data['Condition2']    = le.fit_transform(pd_data['Condition2'])   \npd_data['BldgType']      = le.fit_transform(pd_data['BldgType'])   \npd_data['HouseStyle']    = le.fit_transform(pd_data['HouseStyle'])   \npd_data['RoofStyle']     = le.fit_transform(pd_data['RoofStyle'])   \npd_data['RoofMatl']      = le.fit_transform(pd_data['RoofMatl'])      \npd_data['ExterQual']     = le.fit_transform(pd_data['ExterQual'])  \npd_data['ExterCond']     = le.fit_transform(pd_data['ExterCond'])   \npd_data['Foundation']    = le.fit_transform(pd_data['Foundation'])   \npd_data['Heating']       = le.fit_transform(pd_data['Heating'])   \npd_data['HeatingQC']     = le.fit_transform(pd_data['HeatingQC'])   \npd_data['CentralAir']    = le.fit_transform(pd_data['CentralAir'])   \npd_data['Electrical']    = le.fit_transform(pd_data['Electrical'])    \npd_data['PavedDrive']    = le.fit_transform(pd_data['PavedDrive'])  \npd_data['SaleCondition'] = le.fit_transform(pd_data['SaleCondition']) \npd_data['Utilities']     = le.fit_transform(pd_data['Utilities']) ","98bf4c9a":"y = pd_data[['SalePrice']]\nX = pd_data.drop('SalePrice',axis=1)","40aa1372":"Scaler = StandardScaler()\n\nX = pd.DataFrame(Scaler.fit_transform(X))","c01b80ba":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","e8ccc119":"from xgboost import XGBRegressor\nXGB = XGBRegressor(max_depth = 5, learning_rate = 0.05, n_estimators = 1500, reg_alpha = 0.001,\n                reg_lambda = 0.000001, n_jobs = -1, min_child_weight = 3)\nXGB.fit(X_train,y_train)","cb783858":"print (\"Training score:\",XGB.score(X_train,y_train),\"Test Score:\",XGB.score(X_test,y_test))","719294fd":"from sklearn.ensemble import RandomForestRegressor\nRFR = RandomForestRegressor(max_depth = 20, random_state = 0, n_estimators = 100)\nRFR.fit(X_train,y_train)","49ace9ac":"print (\"Training score:\",RFR.score(X_train,y_train),\"Test Score:\",RFR.score(X_test,y_test))","5c54378f":"**Missing Data**","6578ff96":"Just double check whether all the variables are free from missing value.","7f3b5b19":"**XGBoost**","183b6e12":"**Random Forest**","28a7278f":"For \"MasVnrArea\" and \"Electrical\", there is only few misssing values so I just use the median to impute the former and use the most frequent value to impute the latter.","2a935cb6":"**Exploratory Data Analysis**","b3ba02fb":"Firstly, I straightly remove the variables with too many missing values as well as the \"Id\" variable","3ca76839":"**Begin Machine Learning**","627211f3":"Here I try to find the top 10 variables that are most correlated with our response \"SalePrice\"","6cffb273":"Secondly, I find that the number of missing values of the \"Garage...\" variabes and the \"Bsmt...\" variables are respectively the same, so I guess their missing data should be in the same observations. For these variables, I also straightly remove them.","50943115":"**Quick View of The Data**","94689635":"**Dealing with Categorical Variables**"}}