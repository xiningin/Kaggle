{"cell_type":{"72f55899":"code","58a9add1":"code","e570b268":"code","2095cb66":"code","08941161":"code","8045dddd":"code","d556908f":"code","12dc204a":"code","769621c8":"code","8d830466":"code","166edc99":"code","ab9ab9d1":"code","2bf2f14c":"code","0e42efde":"code","0064cd15":"code","ad14879f":"code","0d8c05e3":"code","71bc3934":"code","34d8ce06":"code","3f5660fa":"code","49b027ff":"code","f0d189a5":"code","55710a55":"markdown","dd2d25c7":"markdown"},"source":{"72f55899":"from collections import Counter\nfrom multiprocessing import Pool\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm","58a9add1":"np.random.seed(42)","e570b268":"df = pd.read_csv(\"\/kaggle\/input\/bms-molecular-translation\/train_labels.csv\")\n","2095cb66":"test_df = pd.read_csv(\"\/kaggle\/input\/bms-molecular-translation\/sample_submission.csv\")","08941161":"df.head()","8045dddd":"# let's see shortest and longest strings\ndf_lengths = df.InChI.apply(len)\nprint(df_lengths.max())\nprint(df_lengths.min())","d556908f":"df_lengths.plot(kind=\"hist\")","12dc204a":"positions_freqs = [Counter() for _ in range(df_lengths.max())]\nfor inch in df.InChI:\n    for pos, char in enumerate(inch):\n        positions_freqs[pos][char] += 1","769621c8":"len(positions_freqs)","8d830466":"positions_freqs[0]","166edc99":"positions_freqs[10]","ab9ab9d1":"positions_freqs[20]","2bf2f14c":"cnts = np.array([v for v in positions_freqs[20].values()])\nsum(cnts \/ sum(cnts)","0e42efde":"df_inchi_lens_freqs = df_lengths.value_counts(normalize=True)\ndef sample_length(size=1):\n    return np.random.choice(a=df_inchi_lens_freqs.index.to_list(), p=df_inchi_lens_freqs.values.tolist(), size=size)\nsample_length(4)","0064cd15":"pos2char_proba = []\nfor cnt in positions_freqs:\n    counts = np.array(list(cnt.values()))\n    freqs = counts \/ sum(counts)\n    sampl_chars = list(cnt)\n    pos2char_proba.append((sampl_chars, freqs))","ad14879f":"def sample_characters(leng: int):\n    chars = []\n    for i in range(leng):\n        sampl_chars, freqs = pos2char_proba[i]\n        chars.append(np.random.choice(sampl_chars, p=freqs))\n    return \"\".join(chars)\n\nsample_characters(400)","0d8c05e3":"test_df.shape","71bc3934":"test_df.head()","34d8ce06":"test_lengths = sample_length(test_df.shape[0])","3f5660fa":"result = []\nwith Pool(16) as pool:\n    for res in tqdm(pool.imap(sample_characters, test_lengths, chunksize=60), total=test_lengths.shape[0]):\n        result.append(res)","49b027ff":"test_df[\"InChI\"] = result","f0d189a5":"test_df.to_csv(\"output.csv\", index=False)","55710a55":"In this notebook I'm going to sample characters for positions","dd2d25c7":"This is ridiculous, but okay for baseline"}}