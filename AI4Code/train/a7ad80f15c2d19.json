{"cell_type":{"a7591237":"code","6c7958eb":"code","4c56f5f5":"code","4aa841d7":"code","76c7f2e4":"code","596aa717":"code","80400eca":"code","03e63e4f":"code","be3812a8":"code","788ddd20":"code","d9a4cc4c":"code","28cdf393":"code","e41fa1fa":"code","63461d1f":"code","a1afef85":"code","045a722a":"code","fbffa64b":"code","ba7aef38":"code","782603c0":"code","78a31349":"code","2e7af164":"code","b7777599":"code","878b111a":"code","b6a6d2ab":"code","1d763b97":"code","0ea5f43a":"code","97c857ad":"code","cba78865":"code","0455dac0":"code","afeda5da":"code","39b73462":"code","d7bcea04":"code","51f893a0":"code","3f5ab195":"code","e69f4e75":"code","32d065dd":"code","8d7c4620":"code","2a8cb66f":"code","c18eee90":"code","082699e7":"code","73ba0ffe":"code","1e53f2f6":"code","65009862":"code","34b1606d":"code","eb4b4df0":"code","06971dce":"code","f8e34576":"code","ee965532":"code","619c6cbb":"code","9ba51023":"code","ec2b29d0":"code","7d599ae3":"code","1e9772d6":"code","65a6dd09":"code","1bb1d4e7":"code","471dd38a":"code","cd188931":"code","3b00209f":"code","a9fe7065":"code","7d500734":"code","6cd82b90":"code","3345d13a":"code","a7aeac8e":"code","abd04a31":"code","8e5efe3a":"code","d5581361":"code","62c546cb":"code","ecbad624":"code","bc3f0c18":"code","52645a8d":"code","47095709":"code","31d89422":"code","1bd2fc31":"code","c36fb46b":"code","fc91a219":"code","41da7981":"code","632b859a":"code","fab07182":"code","41f9635a":"code","19e7a1e0":"code","2104ad92":"code","bb11a526":"code","509c0b34":"code","cc0933e6":"code","accd6572":"code","643cfa76":"code","2e888e8c":"code","f640ea4f":"code","3f30bddd":"code","b2004317":"code","c0cc6b20":"code","538f4b60":"code","9357f83c":"code","e98ceac2":"code","a7414a0c":"code","8727bfc1":"code","ebce6111":"code","6905b176":"code","37cd3ec6":"code","eb60ec97":"code","116787f2":"code","e8090150":"code","cc9fab2f":"code","b3ab6b0c":"code","90dfe1a0":"code","4ca83a63":"code","dae17cda":"code","90c7e8c1":"code","48a9c9b2":"code","25a94956":"code","0c853065":"markdown","c324933b":"markdown","0518538f":"markdown","9971e3f5":"markdown","987236f2":"markdown","a8907d51":"markdown","18902956":"markdown","c5f175cc":"markdown","a17c5ae8":"markdown","80cc0ddb":"markdown","0eb873ec":"markdown","0ab1f799":"markdown","dfebfaf5":"markdown","6a64510b":"markdown","16f1af9a":"markdown","cffd2980":"markdown","2f9e3853":"markdown","408e28d5":"markdown","f1a85d23":"markdown","65faac0e":"markdown","9a46094f":"markdown","3851a974":"markdown","96a51388":"markdown","21fa6212":"markdown","187d7c71":"markdown","db00d9ae":"markdown","71023d1b":"markdown","4f8a080d":"markdown","b1c1c5e3":"markdown","214a51c4":"markdown","d249f574":"markdown","8234362e":"markdown","3689e9c5":"markdown","808b3d3a":"markdown","d357ea7c":"markdown","6bf111a4":"markdown"},"source":{"a7591237":"#import libraries \n\n#structures\nimport pandas as pd\nimport numpy as np\n\n#visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set()\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#get model duration\nimport time\nfrom datetime import date\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6c7958eb":"#load train dataset\ntrain_data = '..\/input\/titanic\/train.csv'\ntrain_dataset = pd.read_csv(train_data)\ntrain_dataset.shape","4c56f5f5":"print(\"Total number of passengers in the train dataset: \" + str(len(train_dataset.index)))","4aa841d7":"test_data = '..\/input\/titanic\/test.csv'\ntest_dataset = pd.read_csv(test_data)\ntest_dataset.shape","76c7f2e4":"print(\"Total number of passengers in the test dataset: \" + str(len(test_dataset.index)))","596aa717":"train_dataset.dtypes","80400eca":"test_dataset.dtypes","03e63e4f":"train_dataset.describe()","be3812a8":"test_dataset.describe()","788ddd20":"train_dataset.head(10)","d9a4cc4c":"test_dataset.head(10)","28cdf393":"sns.countplot(x=\"Survived\", data=train_dataset)","e41fa1fa":"sns.countplot(x=\"Survived\", hue=\"Sex\", data=train_dataset)","63461d1f":"sns.countplot(x=\"Survived\", hue=\"Pclass\", data=train_dataset)","a1afef85":"total_dataset = pd.concat([train_dataset, test_dataset])","045a722a":"total_dataset.shape","fbffa64b":"total_dataset.head()","ba7aef38":"total_dataset.tail()","782603c0":"train_dataset[\"Age\"].plot.hist()","78a31349":"test_dataset[\"Age\"].plot.hist()","2e7af164":"total_dataset[\"Age\"].plot.hist()","b7777599":"sns.boxplot(x=\"Survived\", y=\"Age\", data=train_dataset)","878b111a":"train_dataset[\"Pclass\"].plot.hist()","b6a6d2ab":"test_dataset[\"Pclass\"].plot.hist()","1d763b97":"total_dataset[\"Pclass\"].plot.hist()","0ea5f43a":"sns.boxplot(x=\"Pclass\", y=\"Age\", data=train_dataset)","97c857ad":"sns.boxplot(x=\"Pclass\", y=\"Age\", data=test_dataset)","cba78865":"sns.boxplot(x=\"Pclass\", y=\"Age\", data=total_dataset)","0455dac0":"train_dataset[\"Fare\"].plot.hist(figsize=(10,10))","afeda5da":"test_dataset[\"Fare\"].plot.hist(figsize=(10,10))","39b73462":"total_dataset[\"Fare\"].plot.hist(figsize=(10,10))","d7bcea04":"train_dataset.info()","51f893a0":"test_dataset.info()","3f5ab195":"total_dataset.info()","e69f4e75":"sns.countplot(x=\"SibSp\", data=train_dataset)","32d065dd":"sns.countplot(x=\"SibSp\", data=test_dataset)","8d7c4620":"sns.countplot(x=\"SibSp\", data=total_dataset)","2a8cb66f":"sns.countplot(x=\"Parch\", data=train_dataset)","c18eee90":"sns.countplot(x=\"Parch\", data=test_dataset)","082699e7":"sns.countplot(x=\"Parch\", data=total_dataset)","73ba0ffe":"total_dataset.isnull()","1e53f2f6":"train_dataset.isnull().sum()","65009862":"test_dataset.isnull().sum()","34b1606d":"sns.heatmap(train_dataset.isnull(), yticklabels=False, cmap=\"viridis\")","eb4b4df0":"sns.heatmap(test_dataset.isnull(), yticklabels=False, cmap=\"viridis\")","06971dce":"train_dataset.head()","f8e34576":"test_dataset.head()","ee965532":"#dropping 'Cabin' feature\ntrain_dataset.drop(\"Cabin\", axis=1, inplace=True)\ntest_dataset.drop(\"Cabin\", axis=1, inplace=True)","619c6cbb":"#check if the 'Cabin' feature is dropped\ntrain_dataset.head()","9ba51023":"test_dataset.head()","ec2b29d0":"sns.heatmap(train_dataset.isnull(), yticklabels=False, cmap=\"viridis\")","7d599ae3":"sns.heatmap(test_dataset.isnull(), yticklabels=False, cmap=\"viridis\")","1e9772d6":"#dropping rows of data with 'Age' null\ntrain_dataset.dropna(inplace=True)","65a6dd09":"test_dataset.describe()","1bb1d4e7":"#replacing null values with average values\ntest_dataset['Age'].fillna((test_dataset['Age'].mean()), inplace=True)\ntest_dataset['Fare'].fillna((test_dataset['Fare'].mean()), inplace=True)","471dd38a":"sns.heatmap(train_dataset.isnull(), yticklabels=False, cmap=\"viridis\")","cd188931":"sns.heatmap(test_dataset.isnull(), yticklabels=False, cmap=\"viridis\")","3b00209f":"#checking if any more null value in the dataset\ntrain_dataset.isnull().sum()","a9fe7065":"test_dataset.isnull().sum()","7d500734":"train_dataset.shape","6cd82b90":"test_dataset.shape","3345d13a":"train_dataset.head()","a7aeac8e":"test_dataset.head()","abd04a31":"train_dataset.Pclass.unique()","8e5efe3a":"test_dataset.Pclass.unique()","d5581361":"train_dataset.Sex.unique()","62c546cb":"test_dataset.Sex.unique()","ecbad624":"train_dataset.Embarked.unique()","bc3f0c18":"test_dataset.Embarked.unique()","52645a8d":"Pcl_train=pd.get_dummies(train_dataset[\"Pclass\"],drop_first=True)","47095709":"Pcl_test=pd.get_dummies(test_dataset[\"Pclass\"],drop_first=True)","31d89422":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nX1 = train_dataset\na = train_dataset['Sex']\n\nX1['Sex'] = le.fit_transform(X1['Sex'])\n\na = le.transform(a)\ntrain_dataset = X1","1bd2fc31":"X2 = test_dataset\nb = test_dataset['Sex']\n\nX2['Sex'] = le.fit_transform(X2['Sex'])\n\nb = le.transform(b)\ntest_dataset = X2","c36fb46b":"embark_train=pd.get_dummies(train_dataset[\"Embarked\"])","fc91a219":"embark_test=pd.get_dummies(test_dataset[\"Embarked\"])","41da7981":"train_dataset=pd.concat([train_dataset,embark_train,Pcl_train],axis=1)\ntrain_dataset.head()","632b859a":"test_dataset=pd.concat([test_dataset,embark_test,Pcl_test],axis=1)\ntest_dataset.head()","fab07182":"train_dataset.drop(['Pclass', 'Name','Ticket','Embarked'],axis=1, inplace=True)\ntrain_dataset.head()","41f9635a":"test_dataset.drop(['Pclass', 'Name','Ticket','Embarked'],axis=1, inplace=True)\ntest_dataset.head()","19e7a1e0":"#get correlation map\ncorr_mat=train_dataset.corr()","2104ad92":"#visualise data\nplt.figure(figsize=(13,5))\nsns_plot=sns.heatmap(data=corr_mat, annot=True, cmap='GnBu')\nplt.show()","bb11a526":"#to run for model without scaling\ndropped_passengerId = train_dataset.drop(\"PassengerId\", axis=1)\n\nX_train = dropped_passengerId.drop(\"Survived\", axis=1)\ny_train = train_dataset[\"Survived\"]\n\nX_test = test_dataset.drop(\"PassengerId\", axis=1)","509c0b34":"#to run for model with scaling\ndropped_passengerId = train_dataset.drop(\"PassengerId\", axis=1)\n\ndropped_survived = dropped_passengerId.drop(\"Survived\", axis=1)\n\ndropped_survived.head()","cc0933e6":"test_dropped_passengerId = test_dataset.drop(\"PassengerId\", axis=1)\ntest_dropped_passengerId.head()","accd6572":"X_train = dropped_survived.iloc[:,0:10]\ny_train = train_dataset[\"Survived\"]\n\nX_test = test_dropped_passengerId.iloc[:,0:10]","643cfa76":"from sklearn.preprocessing import StandardScaler","2e888e8c":"#stadardize data\nX_train_scaled = StandardScaler().fit_transform(X_train)\nX_test_scaled = StandardScaler().fit_transform(X_test)","f640ea4f":"#get feature names\nX_train_columns = train_dataset.columns[:10]\nX_test_columns = test_dataset.columns[:10]","3f30bddd":"from sklearn.preprocessing import MinMaxScaler","b2004317":"#stadardize data\nX_train_scaled = MinMaxScaler().fit_transform(X_train)\nX_test_scaled = MinMaxScaler().fit_transform(X_test)","c0cc6b20":"#get feature names\nX_train_columns = train_dataset.columns[:10]\nX_test_columns = test_dataset.columns[:10]","538f4b60":"from sklearn.preprocessing import RobustScaler","9357f83c":"#stadardize data\nX_train_scaled = RobustScaler().fit_transform(X_train)\nX_test_scaled = RobustScaler().fit_transform(X_test)","e98ceac2":"#get feature names\nX_train_columns = train_dataset.columns[:10]\nX_test_columns = test_dataset.columns[:10]","a7414a0c":"from sklearn.linear_model import LogisticRegression","8727bfc1":"logmodel=LogisticRegression()","ebce6111":"logmodel.fit(X_train,y_train)","6905b176":"predictions = logmodel.predict(X_test)\nprint(predictions)","37cd3ec6":"output = pd.DataFrame({'PassengerId': test_dataset.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_noscaling.csv', index=False)\nprint(\"Your submission was successfully saved!\")","eb60ec97":"import math\nmath.sqrt(len(X_test))","116787f2":"from sklearn.neighbors import KNeighborsClassifier","e8090150":"knnmodel = KNeighborsClassifier(n_neighbors=21, p=2, metric='euclidean') #p is 2 cuz we are looking for survived or not: 2 results","cc9fab2f":"#Fit Model\nknnmodel.fit(X_train_scaled, y_train)","b3ab6b0c":"#predict the test set results\npredictions = knnmodel.predict(X_test_scaled)\nprint(predictions)","90dfe1a0":"output = pd.DataFrame({'PassengerId': test_dataset.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_standard.csv', index=False)\nprint(\"Your submission was successfully saved!\")","4ca83a63":"from sklearn.tree import DecisionTreeRegressor","dae17cda":"decisionmodel = DecisionTreeRegressor()","90c7e8c1":"#Fit Model\ndecisionmodel.fit(X_train_scaled, y_train)","48a9c9b2":"#predict the test set results\npredictions = decisionmodel.predict(X_test_scaled)\nprint(predictions)","25a94956":"output = pd.DataFrame({'PassengerId': test_dataset.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_robust.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0c853065":"## Min-Max Scaler","c324933b":"Now we need to convert features: \"Pclass\", \"Sex\" & \"Embarked\" into categorical binary data which is 0 & 1 or True or False or something along. We have 2 options: we can use a label encoder or we can use a pandas method as well. <br>\n\nFirst, lets check how many unique values in each of these features.","0518538f":"# Analyzing Data","9971e3f5":"We can convert 'Embarked' feature into 3 columns 'S', 'C', 'Q' with 0 for No & 1 for Yes values.","987236f2":"So we can see most of the passengers on Titanic are 3rd class passengers.","a8907d51":"# Cleaning Data","18902956":"## Robust Scaler","c5f175cc":"We can see that younger people tend to have a slightly higher survival rate than the older counterpart.","a17c5ae8":"So now it is confirmed that both the train & test datasets are clean without any null value.","80cc0ddb":"We have 3 unique values.\nSo we can convert 'Pclass' feature into 2 columns '2' for 2nd Class & '3' for 3rd Class with 0 for No & 1 for Yes values.\n0 in both of these columns will be automatically 1st class.","0eb873ec":"We can't drop null rows of \"Age\" under test dataset because if we do so, the number of predictions will be less. <br>\n\nBut we can't leave these null values as it is as well. That will become a problem during a prediction. <br>\n\nSo we will fill up these null values with average values. Under Description of Data section - we already have average values for the test dataset. Lets call it back.","0ab1f799":"## Decision Tree","dfebfaf5":"**Logistics Regression Model**\n* Without scaling - accuracy score: 0.75598\n* Standard scaler - accuracy score: 0.76076\n* Min-max scaler - accuracy score: 0.74162\n* Robust scaler - accuracy score: 0.53588\n\n**K-NN Model** <br>\n*n_neighbors = 19*\n* Without scaling - accuracy score: 0.62679\n* Standard scaler - accuracy score: 0.75119\n* Min-max scaler - accuracy score: 0.74641\n* Robust scaler - accuracy score: 0.71770\n\n*n_neighbors = 21*\n* Without scaling - accuracy score: 0.62200\n* Standard scaler - accuracy score: 0.74641\n* Min-max scaler - accuracy score: 0.76555\n* Robust scaler - accuracy score: 0.73684","6a64510b":"## Training using Train Dataset","16f1af9a":"From 3 histograms above, we can see both train & test datasets have similar distribution of data in terms of age. <br>\nWe can see average population of passengers on the titanic are young to middle age group.","cffd2980":"## Logistics Regression","2f9e3853":"## Standard Scaler","408e28d5":"Test dataset still have full data points.","f1a85d23":"Lets drop the redundant columns which includes 'Pclass', 'Name', 'Ticket' & 'Embarked'.","65faac0e":"We have 2 unique values only. So we can convert 'Sex' feature values into '0' for female & '1' for male.","9a46094f":"## K-NN","3851a974":"We are left with 712 data points which is plenty.","96a51388":"We can see that older population of passengers are more likely to be in Passenger Class 1 & Class 2 than Class 3.","21fa6212":"Result is 20, so we can use 19 or 21 for K. Hence I will use 21.","187d7c71":"We can see females have a higher survival rate than males in this scenario. ","db00d9ae":"The death rate of 3rd class passengers are much higher than the other 2 passenger classes.","71023d1b":"As we can see, there are many null values under 'Cabin' column. <br>\n\n687 out of 891 data points is a really high amount. Also there are quite a number of null values under age. <br>\n\nThis will surely affect the prediction results if left unhandled. <br>\n\nHandling null values in dataset has two approaches. We can determine the null value at a given point by averaging out the surrounding values under the feature. However, this only works given that the data is an ordinal data and we know that it is in either ascending or descending order or have some sort of pattern. In our case, it is not. And same for the 'Cabin' feature as well which actually looks like a nominal data. <br>\n\nTherefore, I decided to remove 177 lines of data from Age along with the whole column of 'Cabin' from the dataset.","4f8a080d":"# Description of data","b1c1c5e3":"The titanic train data consists of 891 rows and 12 columns. <br>\nMeans we have a total of 891 passengers and 12 features in the train dataset.","214a51c4":"From 3 histograms above, we can see both train & test datasets have similar distribution of data in terms of Passenger Class as well.","d249f574":"# Scores record","8234362e":"# Pearson's Correlation","3689e9c5":"Same can be said for test dataset. Again features \"Age\" & \"Cabin\".","808b3d3a":"**Data Definitions**\n\n\n* PassengerId - Unique Id of each passenger on the ship\n* Survived - '0' for not survived & '1' for survived\n* Pclass - Passenger class: '1' for 1st class, '2' for 2nd class & '3' for 3rd class\n* Name - Passenger name\n* Sex - Passenger gender: 'male' or 'female'\n* Age - Passenger age\n* SibSp - No. of siblings or spouses aborded Titanic together with the passenger\n* Parch - No. of parents or children aborded Titanic together with the passenger\n* Ticket - Passenger ticket number\n* Fare - Passenger ticket fare\n* Cabin - Passenger cabin number\n* Embarked - Encoded name of city passenger embarked","d357ea7c":"# Importing Libraries","6bf111a4":"# Scaling Dataset"}}