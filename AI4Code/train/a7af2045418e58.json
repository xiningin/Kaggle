{"cell_type":{"f0c7fa01":"code","68a3d4de":"code","46641c4e":"code","24e7fb14":"code","aaa78347":"code","5614a398":"code","ae96f23c":"code","8bc6c9dd":"code","0abb0f3b":"code","a7c6f737":"code","5bd10cea":"code","25612f63":"code","aad0d8e2":"code","5c900658":"code","f8bb498a":"code","b0c1467e":"code","d0f284b0":"code","fbace6f8":"code","13a34da6":"code","1dd2a3b4":"code","59018a04":"code","c4f9f633":"code","2a1f82b5":"markdown","df94300c":"markdown","505feb64":"markdown","2c2a6133":"markdown","7ddefc15":"markdown","ef9b5fc2":"markdown","1f97dc6a":"markdown","157530a5":"markdown","6d4be451":"markdown","9cd476b3":"markdown","56b5ed54":"markdown","7cdaf971":"markdown","f2deffe7":"markdown","ee6acbdf":"markdown"},"source":{"f0c7fa01":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.preprocessing import minmax_scaling\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# read train and test set\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col='PassengerId')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', index_col='PassengerId')\n\ntrain.head()","68a3d4de":"# passenger percentage per class\n100 * train.Pclass.value_counts() \/ train.shape[0]","46641c4e":"sns.barplot(x='Pclass', y='Survived', hue='Sex', data=train)\nplt.show()\nplt.figure(figsize=(16, 4))\nsns.swarmplot(x='Pclass', y='Fare', hue='Survived', data=train)","24e7fb14":"sns.histplot(data=train.Age, kde=True)\nplt.show()\nsns.histplot(x='Age', hue='Survived', data=train)\nplt.show()\nsns.barplot(x='Pclass', y='Age', hue='Sex', data=train)\nplt.show()","aaa78347":"# cumulative number of people travelling with passenger\ncumulative = train.SibSp + train.Parch\n\nsns.histplot(data=train.SibSp)\nplt.show()\n\nsns.histplot(data=train.Parch)\nplt.show()\n\nsns.histplot(data=cumulative)\nplt.xlabel('Cumulative')","5614a398":"alone_percent = 100 * cumulative.value_counts()[0] \/ train.shape[0]\nthree_more_percent = 100 * cumulative.value_counts()[3:].sum() \/ train.shape[0]\n[alone_percent, three_more_percent]","ae96f23c":"# copy the dataset to avoid changing original data\nX = train.copy()\nX = X.drop(columns=['Name', 'Ticket'])\n\n# separate the target column from the other data\ny = X.pop('Survived')","8bc6c9dd":"print('Percentage of missing values in:')\nfor col in train.columns:\n    if train[col].isnull().sum() > 0:\n        print(col, (train[col].isnull().sum() \/ train.shape[0])*100)","0abb0f3b":"#drop Cabin and fill Embarked\nX = X.drop(columns='Cabin')\nX['Embarked'] = X['Embarked'].fillna('Unknown')","a7c6f737":"# group passangers by their Pclass and Sex, then evaluates the corresponding mean Age\nmeanAge = X.groupby(['Pclass', 'Sex']).Age.mean().round()\nmeanAge","5bd10cea":"# replace NaN values of Age with proper values from meanAge\ndef age_imputing(cols):\n    Pclass, Sex, Age = cols[0], cols[1], cols[2]\n    \n    if pd.isnull(Age):\n        return meanAge[Pclass][Sex]\n    \n    else:\n        return Age\n\n# apply the function to change the Age column\nX['Age'] = X[['Pclass', 'Sex', 'Age']].apply(age_imputing, axis = 1)","25612f63":"# find the categorical features and create an encoding\nX['Pclass'] = X['Pclass'].astype('object')\ncategorical_features = X.select_dtypes(include=['object']).columns.tolist()\n\nX_new = pd.get_dummies(X, columns=categorical_features)\nX_new.head()","aad0d8e2":"Z = test.copy().drop(columns=['Name', 'Ticket', 'Cabin'])\n\nprint('Percentage of missing values in:')\nfor col in Z.columns:\n    if Z[col].isnull().sum() > 0:\n        print(col, (Z[col].isnull().sum() \/ Z.shape[0]) * 100)","5c900658":"# replace the single NaN value in Fare with the mean\nZ['Fare'] = Z['Fare'].fillna(Z['Fare'].median())\n\n#mean Age per Pclass and Sex types\nmeanAge = Z.groupby(['Pclass', 'Sex']).Age.mean().round()\n\n# replace NaN values of Age with values from meanAge\nZ['Age'] = Z[['Pclass', 'Sex', 'Age']].apply(age_imputing, axis = 1)\n\n#categories encoding\nZ['Pclass'] = Z['Pclass'].astype('object')\nZ_new = pd.get_dummies(Z, columns=categorical_features)\nZ_new['Embarked_Unknown'] = [0] * Z_new.shape[0]\n\nZ_new.head()","f8bb498a":"plt.figure(figsize=(14, 6))\ntriumask = np.triu(X_new.corr())\nsns.heatmap(X_new.corr(), mask=triumask, annot=True)","b0c1467e":"X_new.describe()","d0f284b0":"X_new['Age'] = minmax_scaling(X_new, columns='Age')\nX_new['Fare'] = minmax_scaling(X_new, columns='Fare')\nX_new","fbace6f8":"Z_new['Age'] = minmax_scaling(Z_new, columns='Age')\nZ_new['Fare'] = minmax_scaling(Z_new, columns='Fare') \nZ_new","13a34da6":"knn = KNeighborsClassifier()\nparam_grid = {'n_neighbors': np.arange(1,100)}\n\nknn_opt = GridSearchCV(knn, param_grid, cv=5)\n\n# fit on encoded training data\nknn_opt.fit(X_new, y)\n\n# best choice for number of neighbors\nknn_opt.best_params_","1dd2a3b4":"# corresponding score\nknn_opt.best_score_","59018a04":"# prediction on the encoded test set\npredicted = knn_opt.predict(Z_new)\npredicted","c4f9f633":"#generating submission file\noutput = pd.DataFrame({'PassengerId': test.index, 'Survived': predicted})\noutput.to_csv('my_submission.csv', index=False)","2a1f82b5":"Most passengers travel in third class, probably since it is the cheapest one.","df94300c":"To keep the test data consistent with the training data we apply the same transformations.","505feb64":"To perform a good quality classification we find the optimal number of neighbours for kNN with GridSearchCV.","2c2a6133":"Next we search for missing values in our data.","7ddefc15":"As 'Cabin' has over the 75% of missing values we won't retrieve any relevant information from it: we will just drop it. The 'Embarked' column conversely has less than 1% missing values and therefore we will impute them as 'Unknown'.","ef9b5fc2":"# kNN for classification #\n\nThe next step would be applying kNN to classify the test data in two classes (i.e. whether a specific passenger survived or not). A statistical summary of X clearly shows that the Age and Fare data has to be scaled before we can proceed.","1f97dc6a":"The barplots above underline two interesting facts. The first one is that for each class more women survived than men, probably beacause in case of dangerous situations they must be saved first. The second is that most of the people who survived had payed a higher fare, thus implying that maybe they had some sort of advantage.","157530a5":"Before moving on we encode the categorical features (we consider 'Pclass' as categorical)","6d4be451":"Things get a little different when it comes to the Age column since there is a significant amount of missing data but not enough to make them impossible to predict. A simple solution could be to impute the median value of all passengers' age, though it could be worth to consider the observations made in the previous section and group the passengers by their class and sex.","9cd476b3":"About 60% of the Titanic passengers travel alone and only the 10% is accompanied by three or more people.","56b5ed54":"# Explorative Data Analysis #\n\nWe concentrate first on the 'Pclass' column.","7cdaf971":"# Data cleaning #\n\nBefore starting we observe that the 'Name' column is not relevant to our purpose, since survived passengers have to be identified by their Id. We will drop also the 'Ticket' colmn as it should not contain relevant informations.","f2deffe7":"Correlation plot to better understand the data.","ee6acbdf":"Most people are 16 to 36 years old and there is almost no passenger with more than 70 years; on the other side there is a significant number of kids within the 0 to 4 years old range. The survival rate is much higher for 0 to 8 years old population and for each class men are always older than women.\nLastly we look at family relations."}}