{"cell_type":{"bb0aeb72":"code","931267f1":"code","651c9f63":"code","efe0fc46":"code","44d1564b":"code","a1bd90e8":"code","d0fc189c":"code","70fb2ba2":"code","c08db19f":"code","f5ac3b45":"code","f3f21a3d":"code","1a0fe299":"code","5f348960":"code","8560d681":"code","7765620f":"code","8a67f092":"code","e8169040":"code","be5cf9b3":"code","6c379bd4":"code","a769daf4":"code","99aa4fc3":"code","368db999":"code","165a1e89":"code","f34b5f35":"code","73219859":"code","bc8d00f7":"code","5d2030ec":"code","e6197cb5":"code","f7d0a863":"code","8b08fd22":"code","0f2b597e":"code","852a0d2e":"code","cb85a746":"code","293d1fe6":"code","bd059809":"code","0227080a":"code","1af3d5d6":"code","9c2d6504":"code","27dc3246":"code","ce3e4f46":"code","f36b2606":"code","33fb35a4":"code","b30ead82":"code","39916902":"code","69edc4aa":"code","0bee7866":"code","eac3584f":"code","54ed4068":"code","dbcd539b":"code","0866a873":"code","7ecec3c2":"code","e40111e3":"code","2d75b889":"code","add2de94":"code","99594cf4":"code","0583cdeb":"code","ff32dd82":"code","b4cbb415":"code","44ea7009":"code","5896b326":"code","bcf97892":"code","a3f096a9":"code","2e372e83":"code","f2b10095":"code","bf808d56":"code","293df52e":"code","04f14c2a":"code","aac11a62":"code","45eb5518":"code","1cc68d7f":"code","16f45923":"code","aeae99e4":"code","39a7dd3e":"code","97ec7a5d":"code","22364d66":"code","4d452d0d":"code","7c68ac43":"code","cb287f8c":"code","f3838ee2":"code","274bf027":"code","496dc3c4":"code","988ea1a4":"code","b052ecef":"code","54286821":"code","c2739b5b":"code","25c79d11":"code","52de2db2":"code","c5969730":"markdown","fa9991c6":"markdown","578f473f":"markdown","0cdf1fbe":"markdown","eb74b10e":"markdown","18adac10":"markdown","02d75025":"markdown","b410053e":"markdown","51219952":"markdown","ee8e9aa7":"markdown","846def34":"markdown","d379326d":"markdown","6026076c":"markdown","2f427ec4":"markdown","3a639f82":"markdown","fca5810b":"markdown","a975d31c":"markdown"},"source":{"bb0aeb72":"import torch","931267f1":"torch.cuda.device_count()","651c9f63":"torch.cuda.get_device_name(0)","efe0fc46":"# scp C:\\Users\\gigik\\Downloads\\kaggle.json gigi@147.83.50.73:\\veu4\\usuaris29\\gigi\\.kaggle","44d1564b":"# scp Users\/gigik\/Downloads\/kaggle.json gigi@147.83.50.73:veu4\/usuaris29\/gigi\/.kaggle","a1bd90e8":"# scp \/Users\/gigik\/Downloads gigi@147.83.50.73:veu4\/usuaris29\/gigi\/.kaggle","d0fc189c":"# scp \/Users\/gigik\/Downloads\/kaggle gigi@147.83.50.73:veu4\/usuaris29\/gigi\/.kaggle","70fb2ba2":"# scp \/Users\/gigik\/Desktop\/en-ha.csv gigi@147.83.50.73:\/veu4\/usuaris29\/gigi\/translator","c08db19f":"# !unzip englishhausa-corpus.zip","f5ac3b45":"import numpy as np\nimport pandas as pd\nimport unicodedata\nimport string\nimport re\nimport random\nimport torch","f3f21a3d":"import numpy as np","1a0fe299":"import pandas as pd","5f348960":"data = pd.read_csv('..\/input\/englishhausa-corpus\/en-ha.csv')","8560d681":"data.head(5)","7765620f":"seed = 42","8a67f092":"# drop duplicate translations\ndata = data.drop_duplicates()\n\n# Shuffle the data to remove bias in dev set selection.\ndata = data.sample(frac=1, random_state=seed).reset_index(drop=True)","e8169040":"data.shape","be5cf9b3":"data.rename( columns={'Unnamed: 0':'numbers'}, inplace=True )","6c379bd4":"data.drop('numbers', inplace=True, axis=1) #drop column with floats","a769daf4":"## Create a Language class to store  util functions\n## such as index to word and word to index\nSOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {\"<blank>\":0, \"SOS\":1,\"EOS\":2}\n        self.word2count = {}\n        self.index2word = {0:\"<blank>\", 1: \"SOS\", 2: \"EOS\"}\n        self.n_words = 3  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n      try:\n        for word in sentence.split(' '):\n          self.addWord(word)\n      except:\n        a = 1\n        # Do nothing\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","99aa4fc3":"# Turn a Unicode string to plain ASCII, thanks to\n# https:\/\/stackoverflow.com\/a\/518232\/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = s.strip()\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s.strip()","368db999":"# Remove empty rows\ndata = data.dropna()","165a1e89":"data.tail()","f34b5f35":"## create lang\neng_lang = Lang(\"source_sentence\")\nhau_lang = Lang(\"hau_new\")","73219859":"for index, (source_sentence, target_sentence) in data.iterrows():\n  # print(source_sentence, target_sentence)\n  eng_lang.addSentence(source_sentence)\n  hau_lang.addSentence(target_sentence)","bc8d00f7":"hau_lang.n_words","5d2030ec":"eng_lang.n_words","e6197cb5":"len(list(eng_lang.word2count))","f7d0a863":"## convert word to their index\ndef tokenize(Lang,sentence):\n    return np.array([Lang.word2index.get(word) for word in sentence.split(' ')])\n    #X = [[word2idx.get(token, None) for token in d.split()] for d in desc]","8b08fd22":"data['source_index'] = data['source_sentence'].apply(lambda s: tokenize(eng_lang, s))","0f2b597e":"data['target_index'] = data['target_sentence'].apply(lambda s: tokenize(hau_lang, s))","852a0d2e":"data.head()","cb85a746":"pairs2 = data[['source_index', 'target_index']]","293d1fe6":"pairs2.head()","bd059809":"pairs2.shape","0227080a":"input_token = data['source_index']","1af3d5d6":"input_token.head(5)","9c2d6504":"output_token = data['target_index']","27dc3246":"output_token.head(5)","ce3e4f46":"len(input_token), len(output_token)","f36b2606":"len_arr = map(lambda x: len(x), input_token)\nmax_input_length = np.array(list(len_arr)).max()\nmax_input_length","33fb35a4":"len_arr = map(lambda x: len(x), output_token)\nmax_output_length = np.array(list(len_arr)).max()\nmax_output_length","b30ead82":"MAX_LENGTH = (np.array([max_input_length, max_output_length])).max()\nMAX_LENGTH = min(256, MAX_LENGTH)\nMAX_LENGTH","39916902":"input_tokenPad = np.zeros((len(input_token),MAX_LENGTH))\noutput_tokenPad = np.zeros((len(input_token),MAX_LENGTH))","69edc4aa":"print(np.unique(input_tokenPad[2]))","0bee7866":"input_token[0], output_token[0]","eac3584f":"for i,v in enumerate(input_token):\n    \n    for j, token in enumerate(v[:MAX_LENGTH]):\n        \n        input_tokenPad[i,j] = token","54ed4068":"for i,v in enumerate(output_token):\n    \n    for j, token in enumerate(v[:MAX_LENGTH]):\n        \n        output_tokenPad[i,j] = token","dbcd539b":"print(input_tokenPad[1], output_tokenPad[1])","0866a873":"## we only want up to 20K rows------cause of batching\ninput_tokenPad1 = input_tokenPad[:1000]\noutput_tokenPad1 = output_tokenPad[:1000]","7ecec3c2":"print(input_tokenPad1.shape)","e40111e3":"from sklearn.model_selection import train_test_split","2d75b889":"#split the dataset into train, test and validation\ntrain_eng, valid_eng,train_hau,valid_hau = train_test_split(input_tokenPad1,output_tokenPad1,test_size=0.2,shuffle=True)","add2de94":"print(train_eng[0], train_hau[0])","99594cf4":"from torch.utils.data import TensorDataset, DataLoader\n\ntrain_data = TensorDataset(torch.from_numpy(train_eng).long(),torch.from_numpy(train_hau).long())\nvalid_data = TensorDataset(torch.from_numpy(valid_eng).long(),torch.from_numpy(valid_hau).long())\n\nbatch_size = 8 # 32\n\ntrain_loader= DataLoader(train_data,shuffle=True,batch_size=batch_size,)\nvalid_loader =DataLoader(valid_data,shuffle=True,batch_size=batch_size,)\n\n# print(train_eng[3])","0583cdeb":"(list(train_loader))[0][0]","ff32dd82":"# obtain one batch of training data\ndataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\n\nprint(\"shape of english\", sample_x.device)","b4cbb415":"import torch.nn as nn\nimport torch.nn.functional as F\nimport math, copy, time\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport seaborn\nseaborn.set_context(context=\"talk\")\n%matplotlib inline","44ea7009":"class EncoderDecoder(nn.Module):\n    \"\"\"\n    A standard Encoder-Decoder architecture. Base for this and many \n    other models.\n    \"\"\"\n    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n        super(EncoderDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.generator = generator\n        \n    def forward(self, src, tgt, src_mask, tgt_mask):\n        \"Take in and process masked src and target sequences.\"\n        return self.decode(self.encode(src, src_mask), src_mask,\n                            tgt, tgt_mask)\n    \n    def encode(self, src, src_mask):\n        return self.encoder(self.src_embed(src), src_mask)\n    \n    def decode(self, memory, src_mask, tgt, tgt_mask):\n        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)","5896b326":"class Generator(nn.Module):\n    \"Define standard linear + softmax generation step.\"\n    def __init__(self, d_model, vocab):\n        super(Generator, self).__init__()\n        self.proj = nn.Linear(d_model, vocab)\n\n    def forward(self, x):\n        return F.log_softmax(self.proj(x), dim=-1)","bcf97892":"def clones(module, N):\n    \"Produce N identical layers.\"\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])","a3f096a9":"class Encoder(nn.Module):\n    \"Core encoder is a stack of N layers\"\n    def __init__(self, layer, N):\n        super(Encoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, mask):\n        \"Pass the input (and mask) through each layer in turn.\"\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)","2e372e83":"class LayerNorm(nn.Module):\n    \"Construct a layernorm module (See citation for details).\"\n    def __init__(self, features, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.a_2 = nn.Parameter(torch.ones(features))\n        self.b_2 = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.a_2 * (x - mean) \/ (std + self.eps) + self.b_2","f2b10095":"class SublayerConnection(nn.Module):\n    \"\"\"\n    A residual connection followed by a layer norm.\n    Note for code simplicity the norm is first as opposed to last.\n    \"\"\"\n    def __init__(self, size, dropout):\n        super(SublayerConnection, self).__init__()\n        self.norm = LayerNorm(size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, sublayer):\n        \"Apply residual connection to any sublayer with the same size.\"\n        return x + self.dropout(sublayer(self.norm(x)))","bf808d56":"class EncoderLayer(nn.Module):\n    \"Encoder is made up of self-attn and feed forward (defined below)\"\n    def __init__(self, size, self_attn, feed_forward, dropout):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = self_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n        self.size = size\n\n    def forward(self, x, mask):\n        \"Follow Figure 1 (left) for connections.\"\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n        return self.sublayer[1](x, self.feed_forward)","293df52e":"class Decoder(nn.Module):\n    \"Generic N layer decoder with masking.\"\n    def __init__(self, layer, N):\n        super(Decoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, memory, src_mask, tgt_mask):\n        for layer in self.layers:\n            x = layer(x, memory, src_mask, tgt_mask)\n        return self.norm(x)","04f14c2a":"class DecoderLayer(nn.Module):\n    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n        super(DecoderLayer, self).__init__()\n        self.size = size\n        self.self_attn = self_attn\n        self.src_attn = src_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n \n    def forward(self, x, memory, src_mask, tgt_mask):\n        \"Follow Figure 1 (right) for connections.\"\n        m = memory\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n        return self.sublayer[2](x, self.feed_forward)","aac11a62":"def subsequent_mask(size):\n    \"Mask out subsequent positions.\"\n    attn_shape = (1, size, size)\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n    return torch.from_numpy(subsequent_mask) == 0","45eb5518":"plt.figure(figsize=(5,5))\nplt.imshow(subsequent_mask(20)[0])\nNone","1cc68d7f":"def attention(query, key, value, mask=None, dropout=None):\n    \"Compute 'Scaled Dot Product Attention'\"\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n             \/ math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    p_attn = F.softmax(scores, dim = -1)\n    if dropout is not None:\n        p_attn = dropout(p_attn)\n    return torch.matmul(p_attn, value), p_attn","16f45923":"class MultiHeadedAttention(nn.Module):\n    def __init__(self, h, d_model, dropout=0.1):\n        \"Take in model size and number of heads.\"\n        super(MultiHeadedAttention, self).__init__()\n        assert d_model % h == 0\n        # We assume d_v always equals d_k\n        self.d_k = d_model \/\/ h\n        self.h = h\n        self.linears = clones(nn.Linear(d_model, d_model), 4)\n        self.attn = None\n        self.dropout = nn.Dropout(p=dropout)\n        \n    def forward(self, query, key, value, mask=None):\n        \"Implements Figure 2\"\n        if mask is not None:\n            # Same mask applied to all h heads.\n            mask = mask.unsqueeze(1)\n        nbatches = query.size(0)\n        \n        # 1) Do all the linear projections in batch from d_model => h x d_k \n        query, key, value = \\\n            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n             for l, x in zip(self.linears, (query, key, value))]\n        \n        # 2) Apply attention on all the projected vectors in batch. \n        x, self.attn = attention(query, key, value, mask=mask, \n                                 dropout=self.dropout)\n        \n        # 3) \"Concat\" using a view and apply a final linear. \n        x = x.transpose(1, 2).contiguous() \\\n             .view(nbatches, -1, self.h * self.d_k)\n        return self.linears[-1](x)","aeae99e4":"class PositionwiseFeedForward(nn.Module):\n    \"Implements FFN equation.\"\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.w_2(self.dropout(F.relu(self.w_1(x))))","39a7dd3e":"class Embeddings(nn.Module):\n    def __init__(self, d_model, vocab):\n        super(Embeddings, self).__init__()\n        self.lut = nn.Embedding(vocab, d_model)\n        self.d_model = d_model\n\n    def forward(self, x):\n        return self.lut(x) * math.sqrt(self.d_model)","97ec7a5d":"class PositionalEncoding(nn.Module):\n    \"Implement the PE function.\"\n    def __init__(self, d_model, dropout, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        \n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0., max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0., d_model, 2) *\n                             -(math.log(10000.0) \/ d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n        \n    def forward(self, x):\n        x = x + Variable(self.pe[:, :x.size(1)], \n                         requires_grad=False)\n        return self.dropout(x)","22364d66":"plt.figure(figsize=(15, 5))\npe = PositionalEncoding(20, 0)\ny = pe.forward(Variable(torch.zeros(1, 100, 20)))\nplt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\nplt.legend([\"dim %d\"%p for p in [4,5,6,7]])\nNone","4d452d0d":"def make_model(src_vocab, tgt_vocab, N=6, \n               d_model=512, d_ff=2048, h=8, dropout=0.1):\n    \"Helper: Construct a model from hyperparameters.\"\n    c = copy.deepcopy\n    attn = MultiHeadedAttention(h, d_model)\n    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n    position = PositionalEncoding(d_model, dropout)\n    model = EncoderDecoder(\n        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n                             c(ff), dropout), N),\n        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n        Generator(d_model, tgt_vocab))\n    \n    # This was important from their code. \n    # Initialize parameters with Glorot \/ fan_avg.\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n    return model","7c68ac43":"# Small example model.\ntmp_model = make_model(10, 10, 2)\nNone","cb287f8c":"class Batch:\n    \"Object for holding a batch of data with mask during training.\"\n    def __init__(self, src, trg=None, pad=0):\n        self.src = src\n        self.src_mask = (src != pad).unsqueeze(-2)\n        if trg is not None:\n            self.trg = trg[:, :-1]\n            self.trg_y = trg[:, 1:]\n            self.trg_mask = \\\n                self.make_std_mask(self.trg, pad)\n            self.ntokens = (self.trg_y != pad).data.sum()\n    \n    @staticmethod\n    def make_std_mask(tgt, pad):\n        \"Create a mask to hide padding and future words.\"\n        tgt_mask = (tgt != pad).unsqueeze(-2)\n        tgt_mask = tgt_mask & Variable(\n            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n        return tgt_mask","f3838ee2":"def run_epoch(data_iter, model, loss_compute):\n    \"Standard Training and Logging Function\"\n    start = time.time()\n    total_tokens = 0\n    total_loss = 0\n    tokens = 0\n    for i, data in enumerate(data_iter):\n        \n        src, trg = data\n        batch = Batch(src.cuda(),trg.cuda())\n        out = model.forward(batch.src, batch.trg, \n                            batch.src_mask, batch.trg_mask)\n        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n        total_loss += loss\n        total_tokens += batch.ntokens\n        tokens += batch.ntokens\n        if i % 50 == 1:\n            elapsed = time.time() - start\n            # print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %(i, loss \/ batch.ntokens, tokens \/ elapsed))\n            start = time.time()\n            tokens = 0\n    return (total_loss \/ total_tokens).cpu().item()","274bf027":"class NoamOpt:\n    \"Optim wrapper that implements rate.\"\n    def __init__(self, model_size, factor, warmup, optimizer):\n        self.optimizer = optimizer\n        self._step = 0\n        self.warmup = warmup\n        self.factor = factor\n        self.model_size = model_size\n        self._rate = 0\n        \n    def step(self):\n        \"Update parameters and rate\"\n        self._step += 1\n        rate = self.rate()\n        for p in self.optimizer.param_groups:\n            p['lr'] = rate\n        self._rate = rate\n        self.optimizer.step()\n        \n    def rate(self, step = None):\n        \"Implement `lrate` above\"\n        if step is None:\n            step = self._step\n        return self.factor * \\\n            (self.model_size ** (-0.5) *\n            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n        \ndef get_std_opt(model):\n    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))","496dc3c4":"# Three settings of the lrate hyperparameters.\nopts = [NoamOpt(512, 1, 4000, None), \n        NoamOpt(512, 1, 8000, None),\n        NoamOpt(256, 1, 4000, None)]\nplt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\nplt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\nNone","988ea1a4":"class LabelSmoothing(nn.Module):\n    \"Implement label smoothing.\"\n    def __init__(self, size, padding_idx, smoothing=0.0):\n        super(LabelSmoothing, self).__init__()\n        self.criterion = nn.KLDivLoss(size_average=False)\n        self.padding_idx = padding_idx\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.size = size\n        self.true_dist = None\n        \n    def forward(self, x, target):\n        assert x.size(1) == self.size\n        true_dist = x.data.clone()\n        true_dist.fill_(self.smoothing \/ (self.size - 2))\n        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        true_dist[:, self.padding_idx] = 0\n        mask = torch.nonzero(target.data == self.padding_idx)\n        if mask.dim() > 0:\n            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n        self.true_dist = true_dist\n        return self.criterion(x, Variable(true_dist, requires_grad=False))","b052ecef":"class SimpleLossCompute:\n    \"A simple loss compute and train function.\"\n    def __init__(self, generator, criterion, opt=None):\n        self.generator = generator\n        self.criterion = criterion\n        self.opt = opt\n        \n    def __call__(self, x, y, norm):\n        x = self.generator(x)\n        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n                              y.contiguous().view(-1)) \/ norm\n        loss.backward()\n        if self.opt is not None:\n            self.opt.step()\n            self.opt.optimizer.zero_grad()\n        return loss.item() * norm","54286821":"def greedy_decode(model, src, src_mask, max_len, start_symbol):\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n    for i in range(max_len-1):\n        out = model.decode(memory, src_mask, \n                           Variable(ys), \n                           Variable(subsequent_mask(ys.size(1))\n                                    .type_as(src.data)))\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim = 1)\n        next_word = next_word.data[0]\n        ys = torch.cat([ys, \n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n    return ys","c2739b5b":"pad_idx = hau_lang.word2index[\"<blank>\"]\nprint(eng_lang.n_words, hau_lang.n_words)\nmodel = make_model(eng_lang.n_words,hau_lang.n_words,N=6)\nmodel.cuda()\ncriterion = LabelSmoothing(size=hau_lang.n_words,padding_idx=pad_idx,smoothing=0.1)\ncriterion.cuda()","25c79d11":"model_opt = NoamOpt(model.src_embed[0].d_model, 1, 4000,\n            torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9))\n\nfor epoch in range(250):\n    print(\"Epoch:\", epoch)\n\n    model.train()\n    print(\"train\", run_epoch(train_loader,model, SimpleLossCompute(model.generator,criterion,model_opt)))\n    \n    model.eval()\n    print(\"test\", run_epoch(valid_loader,model, SimpleLossCompute(model.generator,criterion,None)))","52de2db2":"for i, data in enumerate(list(valid_loader)[:5]):\n    # print(\"English\", data[0][0])\n    # print(\"Hausa\", data[0][1])\n    src,trg = data[:10][0], data[:10][1]\n    # src,trg = src.cuda(), trg.cuda()\n    # print(len(src), len(trg))\n    batch = Batch(src.cuda(),trg.cuda())\n    src = batch.src[:1]\n    # print(src.cuda(), trg.cuda())\n    src_mask = (src != eng_lang.word2index[\"<blank>\"]).unsqueeze(-2)\n    # print(len(src), len(src_mask))\n    out = greedy_decode(model.cuda(), src, src_mask, \n                        max_len=60, start_symbol=hau_lang.word2index[\"SOS\"])\n    \n    # print(eng_lang.word2index)\n    # print(eng_lang.index2word[src[0, 0].item()])\n\n    # print(out)\n\n    # print(batch.trg.data)\n\n    # print(src[0, 2].item())\n    for i in range(0, src.size(1)):\n        sym = eng_lang.index2word[src[0, i].item()]\n        if sym == \"<blank>\": break\n        print(sym, end =\" \")\n    print()\n    print(\"Translation:\", end=\"\\t\")\n    for i in range(1, out.size(1)):\n        sym = hau_lang.index2word[out[0, i].item()]\n        if sym == \"EOS\": break\n        print(sym, end =\" \")\n    print()\n    print(\"Target:\", end=\"\\t\")\n    for i in range(1, batch.trg.size(1)):\n        \n        sym = hau_lang.index2word[batch.trg.data[0,i].item()]\n        if sym == \"<blank>\": break\n        print(sym, end =\" \")\n    print()\n    break","c5969730":"training begins","fa9991c6":"encoder and decoder stacks","578f473f":"positional encoding","0cdf1fbe":"Transformer","eb74b10e":"Decoder","18adac10":"Position-wise feedforward","02d75025":"Dataloader is created to make batching easy","b410053e":"loss computation","51219952":"embedding and softmax","ee8e9aa7":"optim","846def34":"Training","d379326d":"Attention","6026076c":"label smoothing","2f427ec4":"Create the input lan english tokenization","3a639f82":"the input and output lang is padded and converted into a numpy array","fca5810b":"Transformer model","a975d31c":"Full model"}}