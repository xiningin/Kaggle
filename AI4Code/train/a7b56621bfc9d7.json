{"cell_type":{"ea95f971":"code","6f54cd21":"code","aecc3733":"code","2e3bb19d":"code","de4cb1e5":"code","50d90c83":"code","7d60bcdd":"code","b29af520":"code","b799106e":"code","d4d24080":"code","a1bd5300":"code","17edfbcc":"code","2641e7e0":"code","50b1dbd9":"code","263fb0db":"code","5cb3b14f":"code","5952fdf8":"code","0e40be22":"code","6d061771":"code","f829bcd6":"code","020c6f73":"code","86acfa1d":"code","16d9ddc3":"code","add444c3":"code","835faa1a":"code","cdebd869":"code","5553dc8b":"code","03998796":"code","9bc95eae":"code","20f5739d":"code","8e424bcb":"code","14a80ea6":"code","f3221213":"code","9e6e37da":"code","618f6ef9":"code","31ed4765":"code","a0997c86":"code","9b17a687":"code","2360e061":"code","f0f681f7":"code","a9c9ee2f":"code","318e8775":"code","0e9749c1":"code","13e56ed0":"code","c5eafa78":"code","2b92d928":"code","1e3dd838":"code","f3bb180d":"code","6b62791c":"code","75783207":"code","652a82bb":"code","6a772ea1":"code","be81622e":"code","35970a65":"code","d7b27529":"code","e82fab6d":"code","21b48439":"code","63f75e8c":"code","a0c6e931":"markdown","4f6dcd2f":"markdown","26955c9b":"markdown","f9d3d0ac":"markdown","e135e397":"markdown","735812db":"markdown","e85ad98c":"markdown","0407d82e":"markdown","bc670316":"markdown","4f7064a4":"markdown","fcbcf823":"markdown"},"source":{"ea95f971":"import riiideducation\n# import dask.dataframe as dd\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nenv = riiideducation.make_env()","6f54cd21":"train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'task_container_id': 'int16',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )","aecc3733":"#reading in question df\nquestions_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv',                         \n                            usecols=[0, 3],\n                            dtype={'question_id': 'int16',\n                              'part': 'int8'}\n                          )","2e3bb19d":"#removing True or 1 for content_type_id\n\ntrain = train[train.content_type_id == False].sort_values('timestamp').reset_index(drop = True)","de4cb1e5":"train[(train.task_container_id == 9999)].tail()","50d90c83":"train[(train.content_type_id == False)].task_container_id.nunique()","7d60bcdd":"#saving value to fillna\nelapsed_mean = train.prior_question_elapsed_time.mean()\n","b29af520":"group1 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['count'])\ngroup1.columns = ['avg_questions']\ngroup2 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['nunique'])\ngroup2.columns = ['avg_questions']\ngroup3 = group1 \/ group2","b799106e":"group3['avg_questions_seen'] = group3.avg_questions.cumsum()","d4d24080":"group3.iloc[0].avg_questions_seen","a1bd5300":"results_u_final = train.loc[train.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_final.columns = ['answered_correctly_user']\n\nresults_u2_final = train.loc[train.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\nresults_u2_final.columns = ['explanation_mean_user']","17edfbcc":"results_u2_final.explanation_mean_user.describe()","2641e7e0":"train = pd.merge(train, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')","50b1dbd9":"results_q_final = train.loc[train.content_type_id == False, ['question_id','answered_correctly']].groupby(['question_id']).agg(['mean'])\nresults_q_final.columns = ['quest_pct']","263fb0db":"results_q2_final = train.loc[train.content_type_id == False, ['question_id','part']].groupby(['question_id']).agg(['count'])\nresults_q2_final.columns = ['count']","5cb3b14f":"question2 = pd.merge(questions_df, results_q_final, left_on = 'question_id', right_on = 'question_id', how = 'left')","5952fdf8":"question2 = pd.merge(question2, results_q2_final, left_on = 'question_id', right_on = 'question_id', how = 'left')","0e40be22":"question2.quest_pct = round(question2.quest_pct,5)","6d061771":"display(question2.head(), question2.tail())","f829bcd6":"train.head()","020c6f73":"len(train)","86acfa1d":"len(train)","16d9ddc3":"train.answered_correctly.mean()","add444c3":"prior_mean_user = results_u2_final.explanation_mean_user.mean()","835faa1a":"train.loc[(train.timestamp == 0)].answered_correctly.mean()","cdebd869":"train.loc[(train.timestamp != 0)].answered_correctly.mean()","5553dc8b":"train.drop(['timestamp', 'content_type_id', 'question_id', 'part'], axis=1, inplace=True)","03998796":"len(train)","9bc95eae":"validation = train.groupby('user_id').tail(5)\ntrain = train[~train.index.isin(validation.index)]\nlen(train) + len(validation)","20f5739d":"validation.answered_correctly.mean()","8e424bcb":"train.answered_correctly.mean()","14a80ea6":"results_u_val = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_val.columns = ['answered_correctly_user']\n\nresults_u2_val = train[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\nresults_u2_val.columns = ['explanation_mean_user']","f3221213":"X = train.groupby('user_id').tail(18)\ntrain = train[~train.index.isin(X.index)]\nlen(X) + len(train) + len(validation)","9e6e37da":"X.answered_correctly.mean()","618f6ef9":"train.answered_correctly.mean()","31ed4765":"results_u_X = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\nresults_u_X.columns = ['answered_correctly_user']\n\nresults_u2_X = train[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\nresults_u2_X.columns = ['explanation_mean_user']","a0997c86":"#clearing memory\ndel(train)","9b17a687":"X = pd.merge(X, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\nX = pd.merge(X, results_u_X, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_u2_X, on=['user_id'], how=\"left\")","2360e061":"validation = pd.merge(validation, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\nvalidation = pd.merge(validation, results_u_val, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_u2_val, on=['user_id'], how=\"left\")","f0f681f7":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\nX.prior_question_had_explanation.fillna(False, inplace = True)\nvalidation.prior_question_had_explanation.fillna(False, inplace = True)\n\nvalidation[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(validation[\"prior_question_had_explanation\"])\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])","a9c9ee2f":"#reading in question df\n#question2 = pd.read_csv('\/kaggle\/input\/question2\/question2.csv)","318e8775":"content_mean = question2.quest_pct.mean()\n\nquestion2.quest_pct.mean()\n#there are a lot of high percentage questions, should use median instead?","0e9749c1":"#filling questions with no info with a new value\nquestion2.quest_pct = question2.quest_pct.mask((question2['count'] < 3), .65)\n\n\n#filling very hard new questions with a more reasonable value\nquestion2.quest_pct = question2.quest_pct.mask((question2.quest_pct < .2) & (question2['count'] < 21), .2)\n\n#filling very easy new questions with a more reasonable value\nquestion2.quest_pct = question2.quest_pct.mask((question2.quest_pct > .95) & (question2['count'] < 21), .95)","13e56ed0":"X = pd.merge(X, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\nvalidation = pd.merge(validation, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\nX.part = X.part - 1\nvalidation.part = validation.part - 1","c5eafa78":"X.head()","2b92d928":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\nX.head()\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","1e3dd838":"X = X[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part']]\nX_val = X_val[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part']]","f3bb180d":"\n# Filling with 0.5 for simplicity; there could likely be a better value\nX['answered_correctly_user'].fillna(0.65,  inplace=True)\nX['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\nX['quest_pct'].fillna(content_mean, inplace=True)\n\nX['part'].fillna(4, inplace = True)\nX['avg_questions_seen'].fillna(1, inplace = True)\nX['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\nX['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n","6b62791c":"X_val['answered_correctly_user'].fillna(0.65,  inplace=True)\nX_val['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\nX_val['quest_pct'].fillna(content_mean,  inplace=True)\n\nX_val['part'].fillna(4, inplace = True)\nX['avg_questions_seen'].fillna(1, inplace = True)\nX_val['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\nX_val['prior_question_had_explanation_enc'].fillna(0, inplace = True)","75783207":"import lightgbm as lgb\n\nparams = {\n    'objective': 'binary',\n    'boosting' : 'gbdt',\n    'max_bin': 800,\n    'learning_rate': 0.0175,\n    'num_leaves': 80\n}\n\nlgb_train = lgb.Dataset(X, y, categorical_feature = ['part', 'prior_question_had_explanation_enc'])\nlgb_eval = lgb.Dataset(X_val, y_val, categorical_feature = ['part', 'prior_question_had_explanation_enc'], reference=lgb_train)","652a82bb":"model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=50,\n    num_boost_round=1300,\n    early_stopping_rounds=8\n)","6a772ea1":"y_pred = model.predict(X_val)\ny_true = np.array(y_val)\nroc_auc_score(y_true, y_pred)","be81622e":"import matplotlib.pyplot as plt\nimport seaborn as sns","35970a65":"#displaying the most important features by split\nlgb.plot_importance(model)\nplt.show()","d7b27529":"#displaying the most important features by gain\nlgb.plot_importance(model, importance_type = 'gain')\nplt.show()","e82fab6d":"iter_test = env.iter_test()","21b48439":"for (test_df, sample_prediction_df) in iter_test:\n    test_df['task_container_id'] = test_df.task_container_id.mask(test_df.task_container_id > 9999, 9999)\n    test_df = pd.merge(test_df, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n    test_df = pd.merge(test_df, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_u2_final, on=['user_id'],  how=\"left\")\n    test_df['answered_correctly_user'].fillna(0.65,  inplace=True)\n    test_df['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\n    test_df['quest_pct'].fillna(content_mean,  inplace=True)\n    test_df['part'] = test_df.part - 1\n\n    test_df['part'].fillna(4, inplace = True)\n    test_df['avg_questions_seen'].fillna(1, inplace = True)\n    test_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    \n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen',\n                                                            'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","63f75e8c":"#students don't appear in every task container ID what can I do about this, can't always follow sequentially?","a0c6e931":"## Merging Data ##","4f6dcd2f":"## Creating Validation Set (Most Recent Answers by User) ##","26955c9b":"## Reading Data and Importing Libraries ##","f9d3d0ac":"## Modeling ##","e135e397":"## Making Predictions for New Data ##","735812db":"## Extracting Training Data ##","e85ad98c":"## Data Exploration ##","0407d82e":"This is a small modification to https:\/\/www.kaggle.com\/dwit392\/lgbm-iii converting the question2 file into python code.","bc670316":"Does it make sense to use last questions as validation? Why is the rate of correct answers so low?\nI am convinced there is a better way to match the test data.","4f7064a4":"Affirmatives (True) for content_type_id are only for those with a different type of content (lectures). These are not real questions.","fcbcf823":"## Examining Feature Importance ##"}}