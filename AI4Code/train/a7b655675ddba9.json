{"cell_type":{"d871cf14":"code","7c7c7f6d":"code","9b951d46":"code","8ae18cb5":"code","973f8e30":"code","b18d9595":"code","036b8f43":"code","f48e875b":"code","96655621":"code","452c2d85":"code","8ec7c065":"code","bd91c900":"code","8ffd3b65":"code","8d3f54c4":"code","f2aef435":"code","b035c0d7":"code","b87ba8f4":"code","5351d9cc":"code","9ff4a2de":"code","09eecfdb":"markdown","c305135b":"markdown","a8f0c8d1":"markdown","2155d9b0":"markdown","b847cb6c":"markdown","eeff3240":"markdown","8277a68d":"markdown","b922eaf7":"markdown","5ba57d7f":"markdown","100cba0f":"markdown","2932bdc8":"markdown","80df85af":"markdown","0f168f31":"markdown","346eb29c":"markdown","ab8e54ac":"markdown","f2923260":"markdown"},"source":{"d871cf14":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport missingno as msno\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nfrom sklearn.model_selection import train_test_split\n\nimport xgboost as xg\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","7c7c7f6d":"df = pd.read_csv(\"..\/input\/california-housing-prices\/housing.csv\")\ndf.head()","9b951d46":"df.info()","8ae18cb5":"msno.matrix(df)","973f8e30":"df.total_bedrooms.fillna(method='pad', inplace=True)","b18d9595":"df.iloc[:,2:].describe()","036b8f43":"label = LabelEncoder()\n\ndf['ocean_proximity'] = label.fit_transform(df['ocean_proximity'])\ndf","f48e875b":"X = np.array(df.loc[:, ~df.columns.isin(['median_house_value'])])\nX.shape","96655621":"y = np.array(df[\"median_house_value\"])\ny.shape","452c2d85":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","8ec7c065":"X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size = 0.25, shuffle=True)","bd91c900":"model = xg.XGBRegressor(n_estimators = 500)\n\nmodel.fit(X_train, y_train)","8ffd3b65":"y_pred = model.predict(X_val)","8d3f54c4":"mean_squared_error(y_val, y_pred)","f2aef435":"mean_absolute_error(y_val, y_pred)","b035c0d7":"r2_score(y_val, y_pred)","b87ba8f4":"fig = px.scatter(x=y_val, y=y_pred).update_traces(marker=dict(color='#FB0A66'))\nfig.update_layout(yaxis=dict(title='y true'),\n                  xaxis=dict(title='y predicted'),\n                title=\"XGboost Performance\")\nfig.show()","5351d9cc":"features = df.loc[:, ~df.columns.isin(['median_house_value'])].columns\nimportances = model.feature_importances_\nindices = np.argsort(importances)","9ff4a2de":"fig = go.Figure(\n    data=[go.Bar(x=importances[indices], orientation='h')],\n    layout_title_text=\"Feature Importances XGboost\").update_traces(marker=dict(color='#FB0A66'))\n\nfig.update_layout(\n    yaxis = dict(\n        \n        tickvals = [i for i in range(len(features))],\n        ticktext = [features[i] for i in indices]\n    ),\n    xaxis=dict(title='Relative Importance')\n)\nfig.show()","09eecfdb":"## Define target y","c305135b":"## MSE and MAE","a8f0c8d1":"## Missing values visualization","2155d9b0":"## Predict validation data ","b847cb6c":"## Define and fit model","eeff3240":"XGBoost is one of the most popular and efficient implementations of the Gradient Boosted Trees algorithm, a supervised learning method that is based on function approximation by optimizing specific loss functions as well as applying several regularization techniques.\n\n## Why use XGBoost ?\n1. Execution Speed\n2. Model Performance.\n\n## XGBoost Resources\n\n* Official GitHub repository for the project : https:\/\/github.com\/dmlc\/xgboost\n* Original paper : https:\/\/arxiv.org\/pdf\/1603.02754.pdf\n* Official documentation : https:\/\/xgboost.readthedocs.io\/en\/latest\/","8277a68d":"## XGboost Performance Visualization","b922eaf7":"## Define Features X","5ba57d7f":"## Feature Importances for XGboost","100cba0f":"## R\u00b2 Score","2932bdc8":"## Standardization","80df85af":"## Split data","0f168f31":"## Replace missing values","346eb29c":"## Label encoding","ab8e54ac":"## Libraries import","f2923260":"# House Prediction : XGboost Preformances"}}