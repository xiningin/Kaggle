{"cell_type":{"1192641c":"code","547b822c":"code","b5602711":"code","092c7002":"code","e534806d":"code","bd3ff0eb":"code","3863ec33":"code","7000c89a":"code","79fcf1b1":"code","e38d8459":"code","922905a5":"code","010b4f26":"code","c13a8020":"code","a4c77f41":"code","b9d5fc79":"code","6847eba0":"code","ea0da6c5":"code","73ceef81":"code","922be1c7":"code","3ec3c641":"code","24772238":"code","30af9924":"code","b1a34a0a":"code","481bd5d8":"code","2fcfdffc":"code","a7a88395":"code","528aab03":"code","8a711def":"code","7d88247d":"code","51e45819":"code","aa6264d5":"code","eb8cc6ef":"code","68fafc53":"code","6378608d":"code","7522e96c":"code","0dff4c24":"code","ec69b88c":"code","e3f17fc6":"code","12ab4b50":"code","4cc93703":"code","2822f98e":"code","a976aef8":"code","c1ec64f5":"code","04fc8bf9":"code","db5e9f41":"code","4514e45a":"code","0bf9a35a":"code","096e5700":"code","cff43f8e":"code","749a6ea3":"code","f60c2e0b":"code","dc29ee11":"code","e6da4b06":"code","6a513a09":"code","0c0c1819":"markdown","9bf307b6":"markdown","35b6c195":"markdown","93facd87":"markdown","71f0a71c":"markdown","806e6f9c":"markdown","a5d77231":"markdown","d03f6183":"markdown","dcbbcf95":"markdown","10a76025":"markdown","5ed341a0":"markdown","ec7cb453":"markdown","4c2d9245":"markdown","88331202":"markdown","ad5c59f1":"markdown","6276e200":"markdown","3e963eed":"markdown","b5b6f8b5":"markdown","eec88d5c":"markdown","b965b211":"markdown","e8a34dc0":"markdown","bb33154a":"markdown","3f7872b7":"markdown","5f697673":"markdown","1de5f481":"markdown","e79bb46e":"markdown","7100f694":"markdown","8c26622f":"markdown","4137bc6a":"markdown","0692e4c8":"markdown","8e2ce79e":"markdown","581ec1e4":"markdown","95c4e6c4":"markdown","3e557a47":"markdown","d8b4e33d":"markdown","6954d321":"markdown","88a9f0b4":"markdown","830e5172":"markdown","4b4ad2e6":"markdown","728048f1":"markdown","d35b6c3f":"markdown","a6c70eb7":"markdown","dc913179":"markdown","3895ce9d":"markdown","20adc97c":"markdown","7c40bfa7":"markdown","7ed4e78c":"markdown","c6980674":"markdown","2c7d6457":"markdown","b5ce0b76":"markdown","6283921d":"markdown","7b69d5bf":"markdown","07c863a5":"markdown","abbf1385":"markdown","22f59f77":"markdown","ba859dc9":"markdown"},"source":{"1192641c":"# We'll start by importing the pandas library\nimport pandas as pd\n# Since we'll be generating numbers, we'll need to import the numpy library\nimport numpy as np","547b822c":"countries = pd.DataFrame({\"Country\":['France', 'Germany', 'Spain', 'Belgium',\n                                  'Russia'], \"GDP(2017)\":[2500, 3600, 1300, 500, 1600],})\ncountries","b5602711":"pd.DataFrame(np.random.normal(2.5, 1, (10,3)), \n             columns= [\"1st column\", \"2nd column\", \"3rd Column\"])","092c7002":"dataset = pd.read_csv(\"..\/input\/fortune1000.csv\")","e534806d":"dataset.head(3)\n# The head and tail methods give us the first and last n elements in our datasets, n=5 by default","bd3ff0eb":"dataset.info()","3863ec33":"dataset.describe()","7000c89a":"# let's for example check the type of this output\ntype(dataset.describe())","79fcf1b1":"dataset.describe()['Profits']","e38d8459":"dataset.describe()['Profits'].count()","922905a5":"dataset['Sector'].unique()","010b4f26":"dataset['Sector'].nunique()","c13a8020":"dataset['Sector'].value_counts().head()","a4c77f41":"dataset.set_index(\"Rank\", inplace = True)\ndataset.head(3)","b9d5fc79":"dataset[\"Revenue\"].head()","6847eba0":"dataset[\"Profits\"].nlargest(3)","ea0da6c5":"dataset[\"Profits\"].nsmallest(4)","73ceef81":"dataset.groupby(\"Sector\").describe().head()","922be1c7":"type(dataset.groupby(\"Sector\").describe())","3ec3c641":"# We can grab the single column we want\ndataset.groupby(\"Sector\").describe()[\"Profits\"].head()","24772238":"dataset.groupby(\"Sector\").agg('mean').head()","30af9924":"dataset.groupby(\"Sector\").agg({\"Profits\":['min','max'],\"Revenue\":['mean','median']}).head()","b1a34a0a":"dataset[\"Location\"].head()","481bd5d8":"dataset[\"Location\"].apply(lambda loc:loc.split(',')[1]).head()","2fcfdffc":"dataset[\"Location\"].str.strip().str.split(',').str.get(1).head()","a7a88395":"dataset[\"State\"] = dataset[\"Location\"].apply(lambda loc:loc.split(',')[1])","528aab03":"dataset.head()","8a711def":"dataset[\"State\"].nunique()","7d88247d":"dataset.groupby(\"State\").agg({'Profits': ['min', 'max', 'mean']}).head()","51e45819":"def rate_profit(profit):\n    if profit <0:\n        return \"Negative\"\n    elif (profit >0) & (profit <=3500):\n        return \"Average\"\n    else:\n        return \"High\"","aa6264d5":"rate_profit(200)","eb8cc6ef":"dataset[\"Rating\"] = dataset[\"Profits\"].apply(rate_profit)","68fafc53":"# Check the output\ndataset.head(3)","6378608d":"dataset.groupby(\"Rating\").agg('count')[\"Company\"]","7522e96c":"dataset[\"Rating\"].map({'High':'AAA', 'Average':'BAA', 'Negative':'BBB'}).head()","0dff4c24":"dataset.head(3)","ec69b88c":"dataset[dataset[\"Rating\"] == \"High\"].head()","e3f17fc6":"dataset[dataset[\"Profits\"].between(1500,3000)].head()","12ab4b50":"dataset[(dataset[\"State\"].str.contains('CA'))& (dataset[\"Rating\"] ==\"High\")].head()","4cc93703":"dataset[(dataset[\"Sector\"] == \"Health Care\") &(dataset[\"Profits\"]>3000)].head()","2822f98e":"import matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = [12,6]","a976aef8":"# Histogram of the Revenues\ndataset[\"Revenue\"].plot(kind = 'hist', bins = 100)","c1ec64f5":"dataset[\"State\"].value_counts().plot(kind = 'bar')","04fc8bf9":"np.log(dataset[dataset[\"Profits\"]>0]['Profits']).plot(kind = 'box')\nplt.title(\"Logarithm of the Profit\")\nplt.ylabel(\"log\")","db5e9f41":"dataset.hist(by = \"Rating\", column= \"Revenue\", bins = 50)\nplt.show()","4514e45a":"dataset.plot.scatter(\"Revenue\", \"Profits\")","0bf9a35a":"model_data = pd.get_dummies(dataset, columns= [\"Rating\"], drop_first= True)\nmodel_data.head(3)","096e5700":"np.sum(model_data.isna())","cff43f8e":"# We can also find the percentage\n(np.sum(model_data.isna())\/len(model_data.index))*100","749a6ea3":"# Locate where are the missing values\nmodel_data[model_data.isna().any(axis = 1)].head()","f60c2e0b":"missing_index = model_data[model_data.isna().any(axis = 1)].index","dc29ee11":"model_data.fillna(method='ffill').head()","e6da4b06":"model_data.interpolate(inplace=True)","6a513a09":"model_data.iloc[list(missing_index),].head()","0c0c1819":"Let me break down this code, and introduce the concept of the `.apply()` method. \n\nI applied a lambda function on the Location column. The loc keyword is just a variable that is defined in the scope of the lambda function : for each row in the Location column, take the row, split it by ',' and take the second element (python indexing starts with 0).","9bf307b6":"We can use the aggregation on different columns","35b6c195":"When we want to use a Machine Learning Algorithm, we need to prepare the dataset to have the required shape for the models. The scikit-learn library comes with lots of preprocessing tools to make the data ready but Pandas also offers excellent ways to prepare your data.","93facd87":"CSV files are one of the most popular dataset format. The Pandas read_csv doesn't only read in csv files but also tabular separated values, we just need to specify it in the sep argument. ","71f0a71c":"Suppose we want to include the Rating colum in our model. Since it's a categorical feature, we need to encode it to make it numeric than create dummy variables from it. But Pandas has an easiest way of doing so with the `pd.get_dummies()`function.","806e6f9c":"The `unique()` and `nunique()` methods give us the unique values and their total number","a5d77231":"Remember this output is itself a Pandas DataFrame.","d03f6183":"What is very interesting with pandas is that sometimes  the outpout it gives are own pandas series or dataframes. We can take advantages of that to further explore the data.","dcbbcf95":"**6. The `map()` method**","10a76025":"We can also select companies which have a profit between 1500 and 3000","5ed341a0":"The city is separated by a comma, so we can use string methods to grab some part of this column.","ec7cb453":"**5. Apply method**","4c2d9245":"In our dataset we have a Rank column, instead of having it as a column, we can define it as the index of the dataset","88331202":"**9. Prepare your data for a Machine Learning Algorithm**","ad5c59f1":"There are several ways of creating a dataset using Pandas. If you want to create from scratch a dataset for analysis because you have the raw data and instead of using a spreadsheet, you want to write it directly in Pandas you can use it.","6276e200":"In result we have the `pandas.core.frame.DataFrame`. What's really interesting is that all the attributes and methods of a dataframe can apply. Keep that in mind whenever you explore a Pandas object.","3e963eed":"Now, let's add a State column to the dataset using the method I just present.","b5b6f8b5":"Now it gives us a pandas Series with statistical moments as index. All pandas Series attributes and methods apply on that Series","eec88d5c":"We can visualize our dataset pandas visualization methods based on matplotlib.","b965b211":"Let's now talk about the `.map()`method\n\nThe `.map()`methods works like the `apply()`but the difference is that for every value within a column it returns a predefined value. \n\nFor example, we can map the Ratings we just created to something else. It wors better in doing","e8a34dc0":"We can also draw a countplot of a categorical column. Just think of it as if instead of outputting a DataFrame or Series, you decide to output a plot.","bb33154a":"**b. Dealing with missing values**","3f7872b7":"**7. Filtering the dataset**","5f697673":"This function automatically adds two dummy columns to our dataset, by specifying **`drop_first = True`**, it deletes one of the column to eliminate multicolinearity in the model. It makes it very easy !","1de5f481":"# Introduction\nWelcome to this kernel. I'm super excited to make this tutorial in which we will walk through the Pandas library, one of my favourites for data analysis. Data exploration gets easy when we know which tools to use and when we know the capabilities the tools offer. \n\nI assume you have some prior knowledge of python such as data types (list, dictionnaries... ).\n\nIn this Kernel I will do a complete data exploration of several datasets. \n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/4\/45\/Pandas_logo.png)\n\nThis notebook is easy to understand and completely beginer friendly. If you already know some Pandas, you can use this kernel as a reference notebook in case you need it.","e79bb46e":"Let's now create a column named Rating","7100f694":"When we select a numerical column we have a Pandas Series; we can then use some methods to analyse it. \nThe `describe()` methods already gives us meaningful information on the numerical colums, so we're going to use some other useful methods to quickly explore the data","8c26622f":"If you are not familiar with the idea of using a lambda function on a text column, you can directly use the python built-in `.split()` string method. In Pandas you need to specify the `str`prefix before using this method on the column. \n\nThe `str`coerces any data type into a Pandas text Series","4137bc6a":"**4. Working with the numerical columns**","0692e4c8":"We can also combine these conditions to filter the data on many columns values.","8e2ce79e":"We have some missing values in this dataset, with Pandas it is easy to impute values","581ec1e4":"# What is Pandas?\n*Python Data Analysis Library*\nPandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.","95c4e6c4":"We can also plot statistical visualisation plot","3e557a47":"We need to specify to set the **inplace** argument to true to commit the change we just do.","d8b4e33d":"If we grab a single Pandas Series we need to use the `.plot(kind)` method. But on a DataFrame, we can directly select the plot we want to use.","6954d321":"**a. Dummy variables**","88a9f0b4":"The `.apply()` method helps us apply a function on every row or column of the dataset.\n\nLet's say we want to grab the State from the **Location** column in order to explore the companies by States","830e5172":"We can fill missing values with the `.fillna()`method. \n\nIf we have an idea of what the missing values can be then we need only to specify value = to the value we guess to be. \n\nElse we can use the `method` arguments. \n\n`ffill`: replaces the the missing value with the previous value in the dataset","4b4ad2e6":"**8. Pandas built-in visualizations**","728048f1":"**2. Read dataset from different file formats**\n\nThe pandas read function lets us read data from a large variety of data. We can read from Excel spreadsheets, CSV ...","d35b6c3f":"How many unique states are represented in the dataset.","a6c70eb7":"Since our dataset has 1000 rows, we may wonder wich unique value occurs the most. To do that we can use the `value_count()` which applies on a Pandas Series, and since it's a Series we can also apply the `head` or `tail`methods to display the first or last n rows.","dc913179":"Let's now say, instead of having the descriptive statistics for all the dataset, we want to summarize the data based on the categories we have in another column of the data.","3895ce9d":"**1. Create our own dataset using pandas**","20adc97c":"**a.  Filter with conditions**","7c40bfa7":"Let's say we want to rate the Profit of each company as follow: \n\n**Negative** is the profit is negative\n\n**Average** it is in the range of 0 to 3500m\n\n**High** if above 3500 m\n","7ed4e78c":"Not only these methods give the n largest\/smallest profits, they also give us the the index which we set to be the rank","c6980674":"One of the best way we can use to impute missing values is the interpolate methods.","2c7d6457":"Let's now say we want to see each unique values are in a column.","b5ce0b76":"**4. Summarizing the data within groups**","6283921d":"Filtering a dataset with conditions is often called masking. The mask is just the condition we pass in the dataset to subset it. \nTo subset with many conditions, it is better to use **&** instead of AND and **|** instead of OR to avoid python logical issues.","7b69d5bf":" **3. Explore that dataset**","07c863a5":"WHat we just did is using a dictionary in which we have a key that is the column name and the values are the row of each columns. \n\nWe can alternatively do this using the `DataFrame` arguments","abbf1385":"Let's aggregate the data by State","22f59f77":"We have a more flexible way to analyse the data using the `agg()`method on a grouped dataset. ","ba859dc9":"Let's use again the `.apply()`method but this time with our own custom function"}}