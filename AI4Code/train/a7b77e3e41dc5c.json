{"cell_type":{"babb177e":"code","15b06935":"code","f55312d5":"code","f6fde225":"code","068c48f9":"code","dc392cb9":"code","9f091d23":"code","c70855a3":"code","c107d141":"code","5830d44d":"code","52c6fbb6":"code","e3020df2":"code","7e579d06":"code","5184bf32":"code","97913645":"code","9af230f0":"code","b675504c":"code","6e321565":"code","dc4fb85b":"code","9a9cbc6b":"code","2d605645":"code","4d7a26b5":"code","27eae936":"code","744c0c61":"code","6b6bbe24":"code","695ffaf2":"code","4467c04b":"code","6217a8ff":"code","fab413b7":"code","e1d97301":"code","827bda03":"code","c7012271":"code","85e4694f":"code","d0a3aaee":"code","8fc4884c":"code","49df8a2b":"code","55cd2fc7":"code","05104a66":"code","ca76fb96":"code","90f4ae40":"code","617e3d09":"code","2ace09bf":"code","e467b59c":"code","8f3a6043":"code","fe364812":"code","893e6951":"code","4982a58f":"code","e30464e7":"code","2ae3591c":"code","e2f5314a":"code","e63e0c31":"code","b2e811be":"code","7c005c7d":"code","c1574ad0":"code","094b7f16":"code","50f5f86a":"code","3951a756":"code","ddaf720a":"code","2fe04cb3":"code","bf5fb19c":"code","2be3470b":"code","57dc5de5":"code","54f2f44b":"code","330ac878":"code","c0d6e707":"code","191ec239":"code","662a4d39":"code","8ba13438":"code","5acbc23c":"code","7b7ecdd6":"code","60d1f45c":"code","24bd38d6":"code","bcaf2dcb":"code","8ffa143c":"code","a43bc893":"code","67e5404f":"code","5eac58c0":"code","a2a98787":"code","907954f6":"code","84f90c10":"code","abc3effc":"code","17ad42ff":"code","953dae37":"code","c6ac9ae4":"code","5ab9858d":"code","1890d444":"code","0186328d":"code","2420fae8":"code","563ebfa8":"code","350ca762":"code","49c1d58b":"markdown","905e6dbc":"markdown","f42c049f":"markdown","e1b8a391":"markdown","96d01874":"markdown","96bb1e70":"markdown","48c86911":"markdown","983cfef0":"markdown","9a655eda":"markdown","70cd49ab":"markdown","16fca6fc":"markdown","396d777b":"markdown","ce056aa3":"markdown","0616c948":"markdown","38209778":"markdown","51db2d18":"markdown","9cf9bcef":"markdown","bca086f1":"markdown","cae88e85":"markdown","a80ac6e8":"markdown","ee5bf1ad":"markdown","2103960e":"markdown","919c8083":"markdown","df69fc89":"markdown","c22c41f8":"markdown","050e6196":"markdown","16010d46":"markdown","14be4030":"markdown","603dd317":"markdown","b62d29e5":"markdown","1acb2260":"markdown","f3437ff7":"markdown","fee24808":"markdown","157fa99e":"markdown","04385380":"markdown","bb286fbc":"markdown","8177f578":"markdown","254cb669":"markdown","f6cec982":"markdown","c53fd9aa":"markdown","decffcd7":"markdown","8d58f067":"markdown","6a27a758":"markdown","0346801c":"markdown","fb400e7f":"markdown","482e09dd":"markdown","7fb28268":"markdown","d254862d":"markdown","2a446744":"markdown","9532d881":"markdown","be3cd44d":"markdown","c6f28d9a":"markdown","4d55603b":"markdown","ac60160f":"markdown","023b907e":"markdown","2c9379ca":"markdown","8dbcc930":"markdown","3d431446":"markdown","5e507b95":"markdown","1e8a462e":"markdown","cf28f68e":"markdown","e98a0848":"markdown","5b66956c":"markdown","d98fdc37":"markdown","f4e76665":"markdown","dc616b5e":"markdown","cddd4d9f":"markdown","000d20f3":"markdown","4b5c386e":"markdown","e74aae2d":"markdown","e3109726":"markdown","30830ae1":"markdown","ebc27bf6":"markdown","f58ac555":"markdown","0ab29ade":"markdown","06b77368":"markdown","a2f318e0":"markdown","0e5085d8":"markdown","6a35bf63":"markdown","768f0ec8":"markdown","f32799fc":"markdown","a9192f63":"markdown","acb5545d":"markdown","4092396b":"markdown","e51b8aa5":"markdown","3fb355fb":"markdown","5a38ade2":"markdown","e2e18692":"markdown","f6a5f5c7":"markdown","c4c6f7f6":"markdown","569b032b":"markdown","1cd04137":"markdown","b537779d":"markdown","e3a22e78":"markdown","d499e983":"markdown","b98b2e04":"markdown","ac63e22f":"markdown","6a9ac0b1":"markdown","dd3cddda":"markdown","44cb2939":"markdown","5bf7423f":"markdown","a47ccf46":"markdown","fe624275":"markdown"},"source":{"babb177e":"import pandas as pd\nimport math\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","15b06935":"pd.set_option(\"display.max_columns\", 100) # set max columns when displaying pandas DataFrame\npd.set_option(\"display.max_rows\", 200) # set max rows when displaying pandas DataFrame\n\nplt.rcParams[\"figure.figsize\"] = (10,6) # define figure size of pyplot","f55312d5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f6fde225":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","068c48f9":"df.shape","dc392cb9":"len(df)","9f091d23":"df","c70855a3":"df.head(5)","c107d141":"df.sort_values(by=['Age'], ascending=False, inplace=False)","5830d44d":"df.describe()","52c6fbb6":"df.info()","e3020df2":"df.index","7e579d06":"df.columns","5184bf32":"df.columns.tolist()","97913645":"df.nunique()","9af230f0":"df['Name']","b675504c":"df['Name'].values[:5]","6e321565":"df[['Name']].head(5)","dc4fb85b":"df[['Name', 'Sex', 'Embarked', 'Survived']].head(5)","9a9cbc6b":"df[1:3]","2d605645":"df.iloc[:5]","4d7a26b5":"df = df.iloc[:, 1:]\ndf","27eae936":"df.iloc[-3:, -4:]","744c0c61":"alist = [4,8,6]\ndf.iloc[alist]","6b6bbe24":"df.loc[[10, 20, 30]]","695ffaf2":"df.loc[:3, ['Name', 'Sex', 'Age']]","4467c04b":"df[:10].loc[:, ['Survived', 'Name', 'Age']].iloc[2:5, 1:].sample(3)","6217a8ff":"df['Age'].isnull() # or .isna()","fab413b7":"df[df['Age'].isnull()].head(3)","e1d97301":"df[~df['Age'].isnull()].head(3) # or simply use .notnull() or notna()","827bda03":"df[df['Name'].str.contains('Master.')].sample(5)","c7012271":"df[(df['Age'].isnull()) & (df['Sex']=='male')].head(3)","85e4694f":"unique_cabin = df['Cabin'].unique()\nunique_cabin","d0a3aaee":"A_cabin = []\nfor cabin in unique_cabin:\n    if isinstance(cabin, float): # Skip Null Value\n        continue\n        \n    if 'A' in cabin:\n        A_cabin.append(cabin)\nA_cabin","8fc4884c":"df[df['Cabin'].isin(A_cabin)]","49df8a2b":"null_age = df[df['Age'].isnull()].copy() # Use copy() to create a copy of DataFrame to prevent modification leakage.","55cd2fc7":"null_age.groupby('Pclass').size()","05104a66":"null_age.groupby('Pclass').size() \/ len(null_age) * 100","ca76fb96":"df.groupby('Pclass')['Fare'].mean()","90f4ae40":"df.groupby('Pclass')['Fare'].mean().reset_index().rename(columns={'Fare':'Mean_Fare'})","617e3d09":"df.groupby('Pclass')['Fare'].mean().to_frame(name='Mean_Fare')","2ace09bf":"df[['SibSp', 'Parch']].sum(axis=0)","e467b59c":"df[['SibSp', 'Parch']].sum(axis=1)","8f3a6043":"df.groupby(['Pclass', 'Sex'])['Survived'].sum().to_frame(name='Survived')","fe364812":"pe_group = df.groupby(['Pclass', 'Embarked'])","893e6951":"class_survivability = pe_group['Survived'].apply(lambda x: x.sum() \/ x.count()*100).reset_index()\nclass_survivability","4982a58f":"sns.barplot(x = \"Pclass\", y=\"Survived\", hue=\"Embarked\", data=class_survivability)","e30464e7":"df.groupby('Embarked')['Fare'].agg(['min', 'max', 'mean', 'median', 'sum', 'count'])","2ae3591c":"df['TEST'] = 1\ndf.head(3)","e2f5314a":"df['TEST'] = df['Age'] ** 2\ndf[['Age', 'TEST']].head(3)","e63e0c31":"df.drop(columns=['TEST'], inplace=True)\ndf.head(3)","b2e811be":"df1 = df[['Survived']].copy()\ndf2 = df[['Pclass', 'Name']].copy()\n\nprint(df1.shape, df2.shape)","7c005c7d":"pd.concat([df1, df2], axis=1)","c1574ad0":"df1 = df.iloc[[1,2,3]].copy()\ndf2 = df.iloc[[11,12,13]].copy()\ndf3 = df.iloc[[23,33,43]].copy()\n\nprint(df1.shape, df2.shape, df3.shape)","094b7f16":"pd.concat([df1, df2, df3], axis=0)","50f5f86a":"avg_fare = df.groupby('Pclass')['Fare'].mean().reset_index().rename(columns={'Fare':'AVG_Fare'})\navg_fare","3951a756":"df = pd.merge(df, avg_fare, how='left', on=['Pclass'])\ndf.head(5)","ddaf720a":"df.isnull().sum()","2fe04cb3":"male_filler_age = df.loc[df['Sex']=='male', 'Age'].median()\nfemale_filler_age = df.loc[df['Sex']=='female', 'Age'].median()\n\nprint('Male Filler Age:', male_filler_age)\nprint('Female Filler Age:', female_filler_age)","bf5fb19c":"df.loc[(df['Age'].isnull()) & (df['Sex']=='male'), 'Age'] = male_filler_age\ndf.loc[(df['Age'].isnull()) & (df['Sex']=='female'), 'Age'] = female_filler_age","2be3470b":"df[df['Age'].isnull()]","57dc5de5":"df['Cabin'].head(5)","54f2f44b":"df['Cabin'].fillna('Unknown', inplace=True)","330ac878":"df['Cabin'].head(5)","c0d6e707":"df[df['Embarked'].isnull()]","191ec239":"# subset, columns or rows that will be considered with default value of None (consider all of them).\ndf.dropna(subset=['Embarked'], inplace=True)","662a4d39":"df.isnull().sum()","8ba13438":"df['Fare'].count()","5acbc23c":"df['Fare'].max()","7b7ecdd6":"df['Fare'].min()","60d1f45c":"df['Name'].max()","24bd38d6":"df['Name'].min()","bcaf2dcb":"df['Ticket'].mode()","8ffa143c":"df['Ticket'].value_counts(dropna=False) # Use dropna=False to count the frequency of NaN value too","a43bc893":"VC_Ticket = df['Ticket'].value_counts()\n\nVC_Ticket[VC_Ticket==VC_Ticket.iloc[0]] ","67e5404f":"df['Age'].mean()","5eac58c0":"df['Age'].median()","a2a98787":"Q1 = df['Age'].quantile(q=0.25)\nQ1","907954f6":"Q2 = df['Age'].quantile(q=0.5) # or usually called as median\nQ2","84f90c10":"Q3 = df['Age'].quantile(q=0.75)\nQ3","abc3effc":"IQR = df.quantile(0.75) - df.quantile(0.25)\nIQR","17ad42ff":"df.var()","953dae37":"df.std()","c6ac9ae4":"df.skew()","5ab9858d":"df['Fare'].plot(kind='hist')","1890d444":"df.kurtosis()","0186328d":"df['SibSp'].plot(kind='hist')","2420fae8":"df.cov()","563ebfa8":"df.corr(method='pearson')","350ca762":"sns.heatmap(df.corr(), annot=True)","49c1d58b":"Now we will use those values to fill the missing values using `.loc` function.","905e6dbc":"We are able to slice the rows, but it's very limited to `[a:b]` range format.","f42c049f":"**pd.merge()**\n\n`pd.merge()` merges DataFrame or Series with a database-style join. The join is done on columns or indexes.\n\n4 basic arguments pd.merge() takes are:\n* `left` : Left DataFrame\n* `right` : Right DataFrame\n* `how` : 'left', 'right', 'outer', 'inner'. Join method. default: 'inner'\n* `on` : column name or list of column names to merge based on.\n\n\nSuppose we want to obtain `Average Fare of Pclass Group` for every passengers and assign it into new column.","e1b8a391":"## Challenge","96d01874":"Selecting or Slicing is useful for retrieving some of the demanded data. In addition using previous method such as `.head()`, `.tail()`, and `.sample()`, we also able to call the values of a column in the same way as `Python Dictionary`. Pandas also provides `.iloc[]` and `.loc[]` commands to slice DataFrame using `position-based` and `label-based` indices.","96bb1e70":"Apart from calling the `DataFrame` directly, we can also use other commands such as:\n```\n1. df           # Shows all the data\n2. df.head(n=5)   # Shows top-n data\n3. df.tail(n=5)   # Shows bottom-n data\n4. df.sample(n=1) # Shows n-random data or using frac=n (0 to 1) to use fraction\n```","48c86911":"Use `.tolist()` to convert it, to a list.\n","983cfef0":"### What we'll cover:\n- Count\n- Max, Min\n- Mode, Mean, Median\n- Quantile, Interquartile\n- Variance, Standard Deviation\n- Skewness, Kurtosis\n- Covariance\n- Correlation","9a655eda":"You can use arithmetic operation into `DataFrame` or `Series` and it will operate per row.\nThe following is an example how to check the `ratio` between each `Classes` in percentage.","70cd49ab":"Using `A_cabin` list, let's get passengers who use `Cabin A`","16fca6fc":"In this part, we will learn how to get basic statistics on our DataFrame.","396d777b":"## Mean and Median\n\n`.mean()` can be used to get the `average` of our data.\n\n`.median()` can be used to get the `median` of our data.","ce056aa3":"When performing operations on data, sometimes we have to combine different `DataFrames` or `Series`.\n\nPandas have 3 methods to combine them, `pd.concat()`, `DataFrame.join()`, and `pd.merge()`, but we will skip `DataFrame.join()` because we are able to do same thing with `pd.merge()`.","0616c948":"We are also able to assign values with another columns.","38209778":"## Covariance\n\nCovariance is a measure of the joint variability of two random variables.\n\nThe Covariance value can be:\n\n**Positive Covariance**: if the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, (i.e., the variables tend to show similar behavior). \n\n**Negative Covariance**: in the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, (i.e., the variables tend to show opposite behavior).\n\nThe sign of the covariance shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation.","51db2d18":"To run complex commands, we can use `.apply()` and `lambda x:` functions.\n\nInstead of `pe_group['Survived'].mean()`,\n\nIt could also be `pe_group['Survived'].apply(lambda x: x.sum () \/ x.count()) ` (for the sake of `apply lambda` tutorial)","9cf9bcef":"Before, suppose we want know list of `Cabin` in Titanic. To do that, we can use `.unique()` function.","bca086f1":"After learned how to use pandas to do Exploratory Data Analysis, let's test our understanding on this challenge!\n\nChallenge Link : https:\/\/www.kaggle.com\/ouwyukha\/day-1-machine-learning\n\nAnd we also have a useful tutorial of Statistical Test on Categorical Data using Chi Squared Test,\n\nTutorial Link : https:\/\/www.kaggle.com\/ouwyukha\/day-1-additional-material-chi-squared-test","cae88e85":"This command will return rows that contains NaN value on `Age` column.","a80ac6e8":"Then, what if we want to select `all of the columns except the first one`?","ee5bf1ad":"## Variance\n\nVariance is the expectation of the squared deviation of a random variable from its mean. Informally, it measures how far a set of numbers is spread out from their average value.","2103960e":"Using `.max()` and `.min()` on `text` will return `top` and `bottom` data `lexicographically`.","919c8083":"## Skewness\n\nSkewness is a measure of the asymmetry of the probability distributions. \n\nThe skewness value can be:\n- Negative (Skewed to the right)\n- Zero (Symmetric)\n- Positive (Skewed to the left)\n- or even undefined (Flat).","df69fc89":"## .iloc\nNext, let's use `.iloc[row position, column position]` method.\n\n`.iloc` is `index-based selection`, selecting data based on its numerical position in the data.","c22c41f8":"<div style='width: 40%; float:left'>\n    <img src=\"https:\/\/i.ibb.co\/QP3dS57\/kurtosis-negative.png\" alt=\"kurtosis_negative\" style=\"width:100%\">\n<\/div>\n<div style='width: 40%; float:left'>\n    <img src=\"https:\/\/i.ibb.co\/84sS58g\/kurtosis-positive.png\" alt=\"kurtosis_positive\" style=\"width:100%\">\n<\/div>\n\nSources : <a href=https:\/\/www.spcforexcel.com\/knowledge\/basic-statistics\/are-skewness-and-kurtosis-useful-statistics>https:\/\/www.spcforexcel.com\/knowledge\/basic-statistics\/are-skewness-and-kurtosis-useful-statistics<\/a>\n","050e6196":"Next, let's try to concatenate these following DataFrames vertically.","16010d46":"`.groupby()` is very powerful tool to compute operation on every groups. For example, to find the `Average Fare` of each `Passenger Class`, we can use the following command:","14be4030":"To select rows with index labeled as `[10, 20, 30]` can be achieved with:","603dd317":"**Standard Deviation**\n\nStandard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range.","b62d29e5":"Missing values are given the value `NaN` (Not a Number) and have `float64 dtype`. Handling those missing data often is necessary because they can cause problems due to incompatibility. On this section, we will learn how to handle them. This process is called `Imputation`.","1acb2260":"Next, let's retrieve the value of columns `Name, Sex, and Age` of `rows from start to row with value of 3`.","f3437ff7":"Then, if you want to get number of unique values in columns, you can use `df.nunique()` function.","fee24808":"# Basic Information","157fa99e":"# Selecting Data","04385380":"# Imputing Missing Values","bb286fbc":"## Max and Min\n\n`.max()` and `.min()` are useful to get information of the `maximum` and `minimum` of our data.","8177f578":"Then check it using `.isnull()`","254cb669":"- `Age` column has 177 missing values.\n- `Cabin` column has 687 missing values.\n- `Embarked` column has 2 missing values.","f6cec982":"<img src=\"https:\/\/i.ibb.co\/LdZ4DP6\/skewness.png\" alt=\"skewness\" style=\"width:90%\">\nSources : <a href=https:\/\/www.spcforexcel.com\/knowledge\/basic-statistics\/are-skewness-and-kurtosis-useful-statistics>https:\/\/www.spcforexcel.com\/knowledge\/basic-statistics\/are-skewness-and-kurtosis-useful-statistics<\/a>","c53fd9aa":"Now if we check with `.isnull().sum()` there will be no missing value anymore.","decffcd7":"What is Null? Null simply means the value of data is missing. Shortly, we will learn about how to deal with it in the next section.","8d58f067":"First, let's check which column has missing values.","6a27a758":"Next, we will examine the meaning of `NaN` in `Embarked` column.","0346801c":"To get the mode only, we can use the following command:","fb400e7f":"So, it's works in the same way as `python list`\n\n`[a:b]` Select item from a until b\n\n`[a:]` Select item from a until the last one\n\n`[:b]` Select item from the first one until b\n\n`[:-b]` Select item from the first one until the b-th last item\n\nFurthermore, we also able to use a list of integers as selected item.","482e09dd":"## Interquartile (Q3 - Q1)\n\nInterquartile is a measure of variability in the middle 50% of data, based on dividing a data set into quartiles.","7fb28268":"More examples, how about select `last 3 rows` and `last 4 columns`?","d254862d":"**.isnull()**\n\nOne of the most used pandas built-in conditional function is `.isnull()`. This function will return a boolean same-sized object indicating if the values are Null or not.","2a446744":"## Count\n\n`.count()` is used to get how many `Non-Null` values in our data.","9532d881":"To select `first 5 rows` in the data can be achieved with:","be3cd44d":"Suppose, we want to see the distribution of `Age=Null` based on `Pclass`. First of all, let's retrieved a copy of DataFrame which `Age=Null`.","c6f28d9a":"Last but not least, we can use all of the aggregation function in single line by using `.agg()` function.","4d55603b":"Next is the example of retrieving rows with `Age=Null` `AND` `Sex=male`.","ac60160f":"If you want a DataFrame, use a `list` of column names instead, `df[['Name']]`. This will force pandas to return a DataFrame.","023b907e":"But `.mode()` doesn't tell us the frequency. In order to anticipate that we can use `.value_counts()` instead.\n\n`.value_counts()` will return the frequencies of every unique values in a `Series`.","2c9379ca":"Use `.reset_index()` to convert back to DataFrame and reset the index.\n\nOr use `.to_frame()` instead if you want to keep the index.","8dbcc930":"Let's plot it out to check if the rules are correct.","3d431446":"Or you can use `len()` function to get the length of almost any object.","5e507b95":"# Assigning Values","1e8a462e":"One of the main steps in getting basic information from numerical columns in our data is to use the `.describe()` function. This function displays summary statistics from numerical columns.","cf28f68e":"The next following command is to find `how many people survived` the event based on their `classes` and `sexes`.","e98a0848":"## .loc\nAfter iloc, let's learn about loc[row label, column label] method.\n\n`.loc` is `label-based selection`, selecting data based on its own label.","5b66956c":"You can treat DataFrame as LEG*!","d98fdc37":"If we plot it out,","f4e76665":"<img src=\"https:\/\/i.ibb.co\/rF5dGqy\/titanic.jpg\" alt=\"Titanic\" width=\"550\"\/>\n\nIn this lesson, will learn to how to Analyze Data using Titanic dataset. This dataset contains basic information of Titanic Passengers that have been masked. We will use data analysis and manipulation tool, `pandas` and `math` for this tutorial. And `matplotlib` and `seaborn` for display a visualisation of our data.","dc616b5e":"## Correlation\n\nCorrelation coefficient is a bivariate analysis that measures the strength of association between two variables and the direction of the relationship.\n\nThere's 3 method provided, pearson, kendall, and spearman.\n\n`.corr(method='pearson')`\n\n`method = 'pearson', 'kendall', 'spearman'`\n\n**Pearson** : measure the degree of the linear relationship.\n\n**Kendall** : measures the strength of dependence between two variables. \n\n**Spearman**: measure the degree of association between two variables. ","cddd4d9f":"To assign a value or creating a new column, can be done with `df[column_name] = values`","000d20f3":"Both of them is `Survived` the event. This give us a hint that they might be didn't get on Titanic. If that's the case, those are `outliers` in our data.\n\nIn statistics, `Outlier` is a data point that differs significantly from other observations and not relevant with others. Outlier may alters the statistics of our data. Therefore, we should drop them out.","4b5c386e":"Use `.values` to get only the values, discard the indices.","e74aae2d":"**AND - OR**\n\nWe also can combine multiple expressions using `&` (AND) and `|` (OR).\n\nPlease don't forget to use `(...)` bracket to emphasize the semantic.","e3109726":"Before view the data, let's check how big the dataset is by using `df.shape` attribute.\n\n`df.shape` will return a tuple (number of `rows`, number of `columns`)","30830ae1":"## Quantile\n\n`.quantile(q=n)` is useful to get the `quantile` of our data on the requested `float point n`. `n` has range between `0 until 1`.","ebc27bf6":"First of all, we need to read the dataset first. Usually the dataset is saved in CSV format. CSV stands for Comma-separated values and stores tabular data (number and text) in plain text. When you open a CSV file you will get something like this:\n```\nColumn A, Column B, Column C\nDog,4,0\nBird,2,2\nOctopus,8,0\n```\n\nTo read CSV file, we can use `pandas` function : `pd.read_csv('file path')`.\n\nIn `pandas`, we called them as `DataFrame`.","f58ac555":"Now we will try to impute the missing values of `Age` column using `median` values based on their `sexes`.","0ab29ade":"# Conditional Selection\nwith Pandas, we can also filter the DataFrame using Conditional Expressions by putting the expression inside a bracket. `df[condition]`","06b77368":"If we look closely, the output is not a DataFrame. This format is called `Series`.\n\nPandas `Series` is one-dimensional ndarray with axis labels.","a2f318e0":"Let's try to concatenate these 2 following DataFrame horizontally.","0e5085d8":"**pd.concat()**\n\nThis function concatenate list of pandas objects along a particular axis. So, it's basically combine data horizontally or vertically.","6a35bf63":"`VC_Ticket==VC_Ticket.iloc[0]` will keep rows with highest frequency and filter others.","768f0ec8":"## Mode\n\n`.mode()` can be used to get `most recurring values` of our data.","f32799fc":"Next we will try to sort the data based on the value of column(s), using the `.sort_values()` function.\n\n3 basic arguments `.sort_values()` takes are:\n\n* `by` : column name or a list of column name data will be sorted. (unnecesary on Pandas `Series`)\n* `ascending` : True or False, smallest to largest or vice versa. default: True.\n* `inplace` : True or False, perform operation in place. default: False.","a9192f63":"<img src=\"https:\/\/i.ibb.co\/jvLT3hx\/std.png\" alt=\"Standard_Deviation\" style=\"width:30%\">\n<figcaption style=\"text-align:center;\">Formula of Standard Deviaton<\/figcaption>","acb5545d":"<img src=\"https:\/\/i.ibb.co\/w4Gwsh7\/variance.png\" alt=\"Variance\" style=\"width:30%\">\n<figcaption style=\"text-align:center;\">Formula of Variance<\/figcaption>","4092396b":"**Numerical vs Categorical**\n\nThere's 2 kind of data, Numerical and Categorical. Numerical is data type which can be measured, while Categorical cannot. The thing that distinguishes Numerical and Categorical is their form, Numerical is in the form of numbers and Categorical usually is in the form of text. But Categorical could be in a form of numbers too (Ordinal), as an example is Ranking 1st - n-th.","e51b8aa5":"To drop columns, we can use `.drop(columns=[list of columns])` function.","3fb355fb":"Then `.groupby()` using `Pclass` and call `.size()` function to get the size of each groups.\n\nIt will returns a `Series` showing the number of `Null Age` of each classes.","5a38ade2":"To drop rows or columns with `Null` values, we can use `.dropna()` function.","e2e18692":"# Grouping\nPandas `.groupby()` function is used to split the data into groups based on some criteria. The abstract definition of grouping is to provide a mapping of labels to group names.\n\nTo understand the concept, it's better to jump right into the example.","f6a5f5c7":"The following is a description of the columns in the Titanic dataset.\n\nDataset description:\n* **PassengerId**: Passenger Identification Number\n* **Survived**: Passenger Survived the Event or Not\n* **Pclass**: Ticket Class (1 = 1st Class, 2 = 2nd Class, 3 = 3rd Class)\n* **Name**: Passengger's Name\n* **Sex**: Gender\n* **Age**: Age in Years\n* **SibSp**: # of Siblings \/ Spouse Aboard the Titanic\n* **Parch**: # of Parents \/ Children Aboard the Titanic\n* **Ticket**: Ticket Number \t\n* **Fare**: Passenger Fare \t\n* **Cabin**: Cabin Number \t\n* **Embarked**: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)","c4c6f7f6":"Next, we will find out the passenger survivability based on their `Classes` and `Port of Embarkation`.\n\nWe can use formula `sum \/ count` or `mean` to get the probability.","569b032b":"Next is `df.info()` function. This function displays general information such as amount of data, column names, number of non-null data in each columns, column data types, and memory usage.","1cd04137":"Pandas also provided `.fillna()` function to impute the NaN values.\n\nNext we will impute `Cabin` column using `.fillna()` function with value `'Unknown'`.\n\nAssigning NaN with values like `Unknown`, `Others`, `-1` is useful to prevent incompatibility issue without dismiss the missing meaning.","b537779d":"In order to show the list of `row index` or `column names` we can use `df.index` and `df.columns` attributes.","e3a22e78":"**NOT**\n\nUse `~` to declares `NOT` Expression.","d499e983":"To view the data, we simply call the `DataFrame`.","b98b2e04":"## Kurtosis\n\nKurtosis is the degree of peakedness of a distribution. Pandas is using `Fisher\u2019s definition` of Kurtosis, which the normal value of Kurtosis is `0`.\n\nThe Kurtosis value can be:\n- Negative (Flatter than Normal Distribution)\n- Zero (Normal Distributed)\n- Positive (More pointed than Normal Distribution)","ac63e22f":"# Reading data files","6a9ac0b1":"# Basic Statistics","dd3cddda":"Next, if we want to get `Cabin` starts with letter `A`.","44cb2939":"We can also use multiple columns for grouping.\n\nAs we know, `Survived` column consists of `1` or `0`, `Survived` or `Not Survived`. To count the number of survivors we can use `.sum()` function. This function return the sum of the values based on axis, `axis=0` sums vertically (per column) and `axis=1` sums horizontally (per row).","5bf7423f":"# Combining Data","a47ccf46":"**.str.contains()**\n\nPandas also provides `str` expression. The most useful one is `.str.contains('text')` to check if the string values contains specific text or not.","fe624275":"**.isin()**\n\nOther useful conditional function is `.isin()`. This function checks if a value is in a list of items or not."}}