{"cell_type":{"eda3a2bf":"code","abef9251":"code","5bc49da9":"code","85622381":"code","0e93fee5":"code","5a966d99":"code","515d26bd":"code","1c010a80":"code","d6b1836a":"code","ce9f62e5":"code","f8ba09ce":"code","d8ef60fd":"code","a4f5c064":"markdown","333fb85a":"markdown","5c4da9e4":"markdown","cf6fc766":"markdown","d8cccaf5":"markdown","f1a8f5cc":"markdown","f1c6fe7a":"markdown","2e172dff":"markdown","85852aac":"markdown","ee876a1f":"markdown","ee5c6edf":"markdown","b5155244":"markdown"},"source":{"eda3a2bf":"import numpy as np \nimport pandas as pd \nimport nltk\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix","abef9251":"df = pd.read_csv(\"..\/input\/Reviews.csv\", nrows = 50000, usecols = [\"Score\", \"Text\"])\ndf[\"Score\"] = np.where(df[\"Score\"] >= 4, \"positive\", \"negative\")","5bc49da9":"df.info()","85622381":"df.head()","0e93fee5":"sns.countplot(data = df, x= df[\"Score\"]).set_title(\"Score distribution\", fontweight = \"bold\")\nplt.show()","5a966d99":"texts = df[\"Text\"]\n\nimport nltk\n\ntexts_transformed = []\nfor review in texts:\n    sentences = nltk.sent_tokenize(review)\n    adjectives = []\n    \n    \n    for sentence in sentences:\n        words = nltk.word_tokenize(sentence) \n        words_tagged = nltk.pos_tag(words)\n        \n        adj_add = [adjectives.append(word_tagged[0]) for word_tagged in words_tagged if word_tagged[1] == \"JJ\"]\n                \n    texts_transformed.append(\" \".join(adjectives)) ","515d26bd":"X = texts_transformed\ny = df[\"Score\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n\ncv = CountVectorizer(max_features = 50)\ncv.fit(X_train)\n\nX_train = cv.transform(X_train)\nX_test = cv.transform(X_test)","1c010a80":"arr = X_train.toarray()\n\nprint(arr.shape)","d6b1836a":"model = MultinomialNB()\nmodel.fit(X_train, y_train)\n\nprint(model.score(X_test, y_test))","ce9f62e5":"y_test_pred = model.predict(X_test)\nprint(confusion_matrix(y_test, y_test_pred))","f8ba09ce":"def classifier(adjective):\n    return model.predict(cv.transform([adjective]))\nprint(classifier('great'))\nprint(classifier('bad'))","d8ef60fd":"adj = list(zip(model.coef_[0], cv.get_feature_names()))\nadj = sorted(adj, reverse = True)\nfor a in adj:\n    print(a)","a4f5c064":"### Structure\n\n* Import libraries\n* Load and prepare the Dataset\n* Data exploration\n* Filter adjectives with NLTK\n* Transform Data for Model (Count Vectorizer)\n* Function to classify adjectives as positive or negative\n* Top 50 most used adjectives\n* Conclusion","333fb85a":"## Using nltk to classifiy adjectives in amazon food reviews as positive or negative","5c4da9e4":"### Transform Data for Model (Count Vectorizer)","cf6fc766":"### Filter adjectives with NLTK\n\n1. Creating a list for each review and split all sentences in a review\n2. Split all words from each sentence and add tags all words \n\n*Review : Sentence 1: [(word 1, tag 1), ... , (word n, tag n)]; Sentence n: [(word 1, tag 1), ... , (word n, tag n)]*\n3. Add all adjectives to a list (without tag, only word)\n\n*Review: ['Adjective 1', Adjective 2, ... , Adjective n]*\n\n4. Transforming the list of adjectives of each review to one string each review, which is needed for the model later on.\n\n*Review: [Adjective1 Adjective2 Adjective3 Adjective 4]*","d8cccaf5":"### Libraries","f1a8f5cc":"### Data exploration\n\n- displaying general informations about the data\n- displaying first 5 rows of the data\n- Visualizing the distribution of positive and negative ratings","f1c6fe7a":"### multinomial Naive Bayes\n\n* fit model with train data\n* calculate r2-score with test data","2e172dff":"### Function to classify adjectives as positive or negative","85852aac":"### Confusion-Matrix\n\nDue to the fact that the already classified data we trained our model with is not very balanced (way more positives than negatives), we don't know if the  R2 score is reliable. The Model could be just labeling almost everything as positive, even if it should be negative. With the Confusion matrix, we can evaluate the accuracy of the classification more clearer and see exactly where our multinomial naive Bayes has its errors.\n\nFormat of Confusion-Matrix:\n\n| True negative | False positiv\n| --- | --- |\n| False negativ | True positive","ee876a1f":"### Load and prepare the Dataset\n\n- loading first 50.000 rows\n- only loading columns (Score, Text) that are necessary for my purpose\n- defining reviews with scores >= 4 as positive reviews and reviews with scores < 4 as negative reviews","ee5c6edf":"### Conclusion\n\nAdjectives with higher coefficients (good, great, delicious, free) are correlated to positive reviews and adjectives with lower coefficients (bad, expensive) reduce the likelihood of an adjective having a positive meaning\/being in a positive review and thus contribute to being classified as negative by the multinomial Naive Bayes. ","b5155244":"### Top 50 most used adjectives"}}