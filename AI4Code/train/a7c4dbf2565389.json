{"cell_type":{"0e5d12fa":"code","6faaae2b":"code","28f4037d":"code","ff13f4bf":"code","528815d0":"code","40107306":"code","c2b8ce58":"code","264c1dbf":"code","8994daf3":"code","da7c64dd":"code","bbfc3ec6":"code","28045c03":"code","1293af2d":"code","34051366":"code","622532c3":"code","d233ab7a":"code","425516d3":"code","d868aa1e":"code","ee4f8416":"code","2f223659":"code","ccbccf0a":"code","e164ee86":"code","944fcbd9":"code","82b96fb1":"code","cf511310":"code","f4b9927a":"code","11ce5fbf":"code","1daff441":"code","1319a02c":"markdown","e9af7304":"markdown","2467d619":"markdown","ae93a778":"markdown","12d9e1b5":"markdown","266e7d5f":"markdown","9788cf77":"markdown","2bc19d2d":"markdown","994d1bee":"markdown","f59f169b":"markdown","f98c6b4c":"markdown","c372cb75":"markdown","e1bf423d":"markdown","9ffbaed3":"markdown","abd6a7ca":"markdown","764ebc21":"markdown","adb56df2":"markdown","a1bb113c":"markdown","0b10ba53":"markdown","276baba8":"markdown","a33ba475":"markdown","665b09c5":"markdown","b37a4166":"markdown","c12840e1":"markdown","b0302856":"markdown","e2c8be5a":"markdown"},"source":{"0e5d12fa":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport gc\nfrom itertools import product\nimport pickle\nimport time\n\nfrom sklearn.preprocessing import LabelEncoder\n\n%matplotlib inline","6faaae2b":"#\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","28f4037d":"import sys\nprint(sys.version)","ff13f4bf":"# source https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage (slightly modified)\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    \n    return df","528815d0":"input_path = \"..\/input\/competitive-data-science-predict-future-sales\/\"\n\nitems = reduce_mem_usage(pd.read_csv(input_path + \"items.csv\"))\nshops = reduce_mem_usage(pd.read_csv(input_path + \"shops.csv\"))\ncats = reduce_mem_usage(pd.read_csv(input_path + \"item_categories.csv\"))\ntrain = reduce_mem_usage(pd.read_csv(input_path + \"sales_train.csv\"))\ntest  = reduce_mem_usage(pd.read_csv(input_path + \"test.csv\").set_index(\"ID\"))","40107306":"pd.to_datetime(train.date).value_counts().sort_index(ascending=False).plot(kind='line')\nfig = plt.gcf()\nfig.set_size_inches(20, 8)\nplt.ylabel(\"transactions\")\n","c2b8ce58":"merged_train = pd.merge(train, items, on='item_id', how='inner')\nmerged_train = pd.merge(merged_train, cats, on='item_category_id', how='inner')\nmerged_train = pd.merge(merged_train, shops, on='shop_id', how='inner')\nmerged_train['revenue'] = merged_train['item_price'] *  merged_train['item_cnt_day']\n\nmerged_train.item_category_name.value_counts().plot(kind='bar')\nfig = plt.gcf()\nfig.set_size_inches(20, 8)\nplt.ylabel(\"transactions\")\nplt.xlabel(\"categories\")\nplt.show()\n\nmerged_train.groupby('shop_name')['revenue'].sum().sort_values(ascending=False).plot(kind='bar')\nfig = plt.gcf()\nfig.set_size_inches(20, 8)\nplt.ylabel(\"revenue\")\nplt.xlabel(\"shops\")\nplt.show()\n\ndel merged_train\ngc.collect()","264c1dbf":"plt.xlim(-100, 3000)\nsns.boxplot(x=train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)","8994daf3":"# measure time it took for feature preprocessing\nstart_time = time.time()","da7c64dd":"train = train[(train.item_price < 100000) & (train.item_price > 0)]\ntrain = train[train.item_cnt_day < 1001]","bbfc3ec6":"train.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","28045c03":"# REVENUE\ntrain['revenue'] = train['item_price'] *  train['item_cnt_day']\n\n\n# CITY NAME text feature\n# city is before each shop\nshops.loc[shops.shop_name == '\u0421\u0435\u0440\u0433\u0438\u0435\u0432 \u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"',\"shop_name\"] = '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"'\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city']).astype(np.int8) # Applying label encoding\n\n# SHOP CATEGORY text feature\nshops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\ncategory = []\nfor cat in shops.category.unique():\n    if len(shops[shops.category == cat]) >= 5:\n        category.append(cat)\nshops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )\nshops['category_code'] = LabelEncoder().fit_transform(shops['category']).astype(np.int8) # Applying label encoding\n\n\n# POPULATION\npopulation = {'\u042f\u043a\u0443\u0442\u0441\u043a': 269601, '\u0410\u0434\u044b\u0433\u0435\u044f':144249, '\u0411\u0430\u043b\u0430\u0448\u0438\u0445\u0430': 215494, '\u0412\u043e\u043b\u0436\u0441\u043a\u0438\u0439': 314255, '\u0412\u043e\u043b\u043e\u0433\u0434\u0430': 301755, '\u0412\u043e\u0440\u043e\u043d\u0435\u0436': 889680,\n       '\u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439': 104736, '\u041a\u0430\u0437\u0430\u043d\u044c': 1143535, '\u041a\u0430\u043b\u0443\u0433\u0430':324698,\n       '\u041a\u043e\u043b\u043e\u043c\u043d\u0430': 144589, '\u041a\u0440\u0430\u0441\u043d\u043e\u044f\u0440\u0441\u043a': 973826, '\u041a\u0443\u0440\u0441\u043a': 415159, '\u041c\u043e\u0441\u043a\u0432\u0430':11503501, '\u041c\u044b\u0442\u0438\u0449\u0438': 173160, '\u041d.\u041d\u043e\u0432\u0433\u043e\u0440\u043e\u0434': 1250619,\n       '\u041d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a': 1473754, '\u041e\u043c\u0441\u043a': 1154116, '\u0420\u043e\u0441\u0442\u043e\u0432\u041d\u0430\u0414\u043e\u043d\u0443': 1089261, '\u0421\u041f\u0431': 4879566, '\u0421\u0430\u043c\u0430\u0440\u0430': 1164685,\n       '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434': 111179, '\u0421\u0443\u0440\u0433\u0443\u0442': 306675, '\u0422\u043e\u043c\u0441\u043a': 524669, '\u0422\u044e\u043c\u0435\u043d\u044c': 581907, '\u0423\u0444\u0430': 1062319, '\u0425\u0438\u043c\u043a\u0438': 207425,\n       '\u0427\u0435\u0445\u043e\u0432': 60720, '\u042f\u0440\u043e\u0441\u043b\u0430\u0432\u043b\u044c': 591486}\n# filling the online store and other non-locations with mean\nmean_population = int(np.mean([v for k, v in population.items()]))\npopulation['\u0412\u044b\u0435\u0437\u0434\u043d\u0430\u044f'] = mean_population\npopulation['\u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d'] = mean_population\npopulation['\u0426\u0438\u0444\u0440\u043e\u0432\u043e\u0439'] = mean_population\nshops['city_population'] = shops['city'].map(lambda x: population[x]).astype(np.int32)\n\n# COORDINATES\n# lattitude and longitude of the cities\ncoords = dict()\ncoords['\u042f\u043a\u0443\u0442\u0441\u043a'] = (62.028098, 129.732555, 4)\ncoords['\u0410\u0434\u044b\u0433\u0435\u044f'] = (44.609764, 40.100516, 3)\ncoords['\u0411\u0430\u043b\u0430\u0448\u0438\u0445\u0430'] = (55.8094500, 37.9580600, 1)\ncoords['\u0412\u043e\u043b\u0436\u0441\u043a\u0438\u0439'] = (53.4305800, 50.1190000, 3)\ncoords['\u0412\u043e\u043b\u043e\u0433\u0434\u0430'] = (59.2239000, 39.8839800, 2)\ncoords['\u0412\u043e\u0440\u043e\u043d\u0435\u0436'] = (51.6720400, 39.1843000, 3)\ncoords['\u0412\u044b\u0435\u0437\u0434\u043d\u0430\u044f'] = (0, 0, 0)\ncoords['\u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439'] = (55.5952800, 38.1202800, 1)\ncoords['\u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d'] = (0, 0, 0)\ncoords['\u041a\u0430\u0437\u0430\u043d\u044c'] = (55.7887400, 49.1221400, 4)\ncoords['\u041a\u0430\u043b\u0443\u0433\u0430'] = (54.5293000, 36.2754200, 4)\ncoords['\u041a\u043e\u043b\u043e\u043c\u043d\u0430'] = (55.0794400, 38.7783300, 4)\ncoords['\u041a\u0440\u0430\u0441\u043d\u043e\u044f\u0440\u0441\u043a'] = (56.0183900, 92.8671700, 4)\ncoords['\u041a\u0443\u0440\u0441\u043a'] = (51.7373300, 36.1873500, 3)\ncoords['\u041c\u043e\u0441\u043a\u0432\u0430'] = (55.7522200, 37.6155600, 1)\ncoords['\u041c\u044b\u0442\u0438\u0449\u0438'] = (55.9116300, 37.7307600, 1)\ncoords['\u041d.\u041d\u043e\u0432\u0433\u043e\u0440\u043e\u0434'] = (56.3286700, 44.0020500, 4)\ncoords['\u041d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a'] = (55.0415000, 82.9346000, 4)\ncoords['\u041e\u043c\u0441\u043a'] = (54.9924400, 73.3685900, 4)\ncoords['\u0420\u043e\u0441\u0442\u043e\u0432\u041d\u0430\u0414\u043e\u043d\u0443'] = (47.2313500, 39.7232800, 3)\ncoords['\u0421\u041f\u0431'] = (59.9386300, 30.3141300, 2)\ncoords['\u0421\u0430\u043c\u0430\u0440\u0430'] = (53.2000700, 50.1500000, 4)\ncoords['\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434'] = (56.3000000, 38.1333300, 4)\ncoords['\u0421\u0443\u0440\u0433\u0443\u0442'] = (61.2500000, 73.4166700, 4)\ncoords['\u0422\u043e\u043c\u0441\u043a'] = (56.4977100, 84.9743700, 4)\ncoords['\u0422\u044e\u043c\u0435\u043d\u044c'] = (57.1522200, 65.5272200, 4)\ncoords['\u0423\u0444\u0430'] = (54.7430600, 55.9677900, 4)\ncoords['\u0425\u0438\u043c\u043a\u0438'] = (55.8970400, 37.4296900, 1)\ncoords['\u0426\u0438\u0444\u0440\u043e\u0432\u043e\u0439'] = (0, 0, 0)\ncoords['\u0427\u0435\u0445\u043e\u0432'] = (55.1477000, 37.4772800, 4)\ncoords['\u042f\u0440\u043e\u0441\u043b\u0430\u0432\u043b\u044c'] = (57.6298700, 39.8736800, 2) \n\nshops['city_coord_1'] = shops['city'].apply(lambda x: coords[x][0]).astype(np.float16)\nshops['city_coord_2'] = shops['city'].apply(lambda x: coords[x][1]).astype(np.float16)\nshops['country_part'] = shops['city'].apply(lambda x: coords[x][2]).astype(np.int8)\n\n\n# SHOP TYPE\ncats['split'] = cats['item_category_name'].str.split('-') # item category name is 'type-subtype'\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\ncats['type_code'] = LabelEncoder().fit_transform(cats['type']).astype(np.int8) # Applying label encoding\n\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype']).astype(np.int8) # Applying label encoding","1293af2d":"# dropping unnecessary columns\ncats = cats[['item_category_id','type_code', 'subtype_code']]\nshops = shops[['shop_id','city_code', 'city_coord_1', 'city_coord_2', 'country_part', 'city_population', 'category_code']]\nitems.drop(['item_name'], axis=1, inplace=True)","34051366":"# https:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost\nmatrix = []\ncols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\nfor i in range(34):\n    sales = train[train.date_block_num == i]\n    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n\nmatrix = pd.DataFrame( np.vstack(matrix), columns = cols )\nmatrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\nmatrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\nmatrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\nmatrix.sort_values( cols, inplace = True )","622532c3":"group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month']\n                                .fillna(0)\n                                .clip(0,20)\n                                .astype(np.float16))","d233ab7a":"# adding the month number to the test data\ntest['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\n\nmatrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True)","425516d3":"# merging the dataframes\nmatrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, items, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')","d868aa1e":"# lagging features\ndef lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df\n\n# lagged feature for item with id one less than current item\ndef lag_feature_adv(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)+'_adv']\n        shifted['date_block_num'] += i\n        shifted['item_id'] -= 1\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n        df[col+'_lag_'+str(i)+'_adv'] = df[col+'_lag_'+str(i)+'_adv'].astype('float16')\n    return df","ee4f8416":"# generating lagged features\nmatrix = lag_feature(matrix, [1, 2, 3, 6, 12], 'item_cnt_month')\nmatrix = lag_feature_adv(matrix, [1, 2, 3, 6, 12], 'item_cnt_month')","2f223659":"def mean_encoded_feature(df, group_by, feature, new_feature, lags=[1]):\n    # mean encoding the feature\n    group = df.groupby(group_by).agg({feature: ['mean']})\n    group.columns = [new_feature]\n    group.reset_index(inplace=True)\n    \n    df = pd.merge(df, group, on=group_by, how='left')\n    df[new_feature] = df[new_feature].astype(np.float16)\n    \n    # Lagging the mean encoded feature\n    df = lag_feature(df, lags, new_feature)\n    \n    # Removing for the current month\n    df.drop([new_feature], axis=1, inplace=True)\n    return df","ccbccf0a":"# mean encoding various features\nmatrix = mean_encoded_feature(matrix, ['date_block_num'], 'item_cnt_month', 'date_target_enc', [1])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'item_id'], 'item_cnt_month', 'date_item_target_enc', [1,2,3,6,12])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'shop_id'], 'item_cnt_month', 'date_shop_target_enc', [1,2,3,6,12])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'item_id', 'shop_id'], 'item_cnt_month', 'date_item_shop_target_enc', [1,2,3])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'item_category_id'], 'item_cnt_month', 'date_cat_target_enc', [1])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'shop_id', 'item_category_id'], 'item_cnt_month', 'date_shop_cat_target_enc', [1])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'shop_id', 'type_code'], 'item_cnt_month', 'date_shop_type_target_enc', [1])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'city_code'], 'item_cnt_month', 'date_city_target_enc', [1,2,3])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'item_id', 'city_code'], 'item_cnt_month', 'date_item_city_target_enc', [1])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'type_code'], 'item_cnt_month', 'date_type_target_enc', [1])\nmatrix = mean_encoded_feature(matrix, ['date_block_num', 'subtype_code'], 'item_cnt_month', 'date_subtype_target_enc', [1])","e164ee86":"# Total monthly revenue for each shop \n\ngroup = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\n# total average revenue for each shop\ngroup = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['shop_id'], how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n\n# Monthly revenue difference from the average divided by the average revenue for scaling\nmatrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) \/ matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n\n# Lagging the feature\nmatrix = lag_feature(matrix, [1], 'delta_revenue')\n\nmatrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","944fcbd9":"import calendar\n\n# month number from 0 to 11\nmatrix['month'] = matrix['date_block_num'] % 12\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n\n# days in each month\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)\n\n# number of weekends each month\ndef weekends(date_block_num):\n    month = date_block_num % 12 + 1\n    year = 2013 + date_block_num \/\/ 12\n    return len([1 for i in calendar.monthcalendar(year, month) if i[6] != 0])\n    \nmatrix['weekends'] = matrix['date_block_num'].apply(lambda x: weekends(x)).astype(np.int8)","82b96fb1":"# item first appeared\nfirst_item_block = matrix.groupby(['item_id'])['date_block_num'].min().reset_index()\nfirst_item_block['item_first_interaction'] = 1\n\n# item first bought\nfirst_shop_item_buy_block = matrix[matrix['date_block_num'] > 0].groupby(['shop_id', 'item_id'])['date_block_num'].min().reset_index()\nfirst_shop_item_buy_block['first_date_block_num'] = first_shop_item_buy_block['date_block_num']\n\nmatrix = pd.merge(matrix, first_item_block[['item_id', 'date_block_num', 'item_first_interaction']], on=['item_id', 'date_block_num'], how='left')\nmatrix = pd.merge(matrix, first_shop_item_buy_block[['item_id', 'shop_id', 'first_date_block_num']], on=['item_id', 'shop_id'], how='left')\n\nmatrix['first_date_block_num'].fillna(100, inplace=True)\nmatrix['shop_item_sold_before'] = (matrix['first_date_block_num'] < matrix['date_block_num']).astype('int8')\nmatrix.drop(['first_date_block_num'], axis=1, inplace=True)\n\nmatrix['item_first_interaction'].fillna(0, inplace=True)\nmatrix['shop_item_sold_before'].fillna(0, inplace=True)\n\n# is it the first time the item appears\nmatrix['item_first_interaction'] = matrix['item_first_interaction'].astype('int8')  \n# has item been sold before\nmatrix['shop_item_sold_before'] = matrix['shop_item_sold_before'].astype('int8') \n\n\n# average category sales for the new item\nitem_id_target_mean = matrix[matrix['item_first_interaction'] == 1].groupby(['date_block_num','subtype_code'])['item_cnt_month'].mean().reset_index().rename(columns={\n    \"item_cnt_month\": \"new_item_cat_avg\"}, errors=\"raise\")\n\nmatrix = pd.merge(matrix, item_id_target_mean, on=['date_block_num','subtype_code'], how='left')\n\nmatrix['new_item_cat_avg'] = (matrix['new_item_cat_avg']\n                                .fillna(0)\n                                .astype(np.float16))\n\nmatrix = lag_feature(matrix, [1, 2, 3], 'new_item_cat_avg')\nmatrix.drop(['new_item_cat_avg'], axis=1, inplace=True)\n\n# average category sales for the new item in each store\nitem_id_target_mean = matrix[matrix['item_first_interaction'] == 1].groupby(['date_block_num','subtype_code', 'shop_id'])['item_cnt_month'].mean().reset_index().rename(columns={\n    \"item_cnt_month\": \"new_item_shop_cat_avg\"}, errors=\"raise\")\n\nmatrix = pd.merge(matrix, item_id_target_mean, on=['date_block_num','subtype_code', 'shop_id'], how='left')\n\nmatrix['new_item_shop_cat_avg'] = (matrix['new_item_shop_cat_avg']\n                                .fillna(0)\n                                .astype(np.float16))\n\nmatrix = lag_feature(matrix, [1, 2, 3], 'new_item_shop_cat_avg')\nmatrix.drop(['new_item_shop_cat_avg'], axis=1, inplace=True)","cf511310":"# months since first sale in the shop\nmatrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n# months since first sale over all shops\nmatrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')","f4b9927a":"# fill the nan's caused by lagging the features\n\ndef fill_na(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isnull().any()):\n            df[col].fillna(0, inplace=True)         \n    return df\n\nmatrix = fill_na(matrix)","11ce5fbf":"# saving all the data\nmatrix.to_pickle('all_data.pkl')\n# data for using 12 month lags (first 12 months already removed)\nmatrix = matrix[matrix.date_block_num > 11]\nmatrix.to_pickle('data.pkl')","1daff441":"# measuring the time the preprocessing and feature engineering took\nend_time = time.time()\nprint(f\"Preprocessing took {end_time - start_time}s\")","1319a02c":"The public-private split seems to be random.","e9af7304":"These notebooks helped with feature engineering:\n* https:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost\n* https:\/\/www.kaggle.com\/uladzimirkapeika\/feature-engineering-lightgbm-top-1\n* https:\/\/www.kaggle.com\/gordotron85\/future-sales-xgboost-top-3","2467d619":"### Data Cleaning\nRemoving the outliers and negative item prices","ae93a778":"Python version","12d9e1b5":"### Item date features (interactions)","266e7d5f":"A method to reduce memory usage of pandas dataframes.","9788cf77":"## Reading in the data","2bc19d2d":"### Mean encoded lagged features\nGenerating mean encoded features","994d1bee":"# Imports","f59f169b":"Finding when item first appeared and when it was first bought.","f98c6b4c":"Selecting only the wanted columns","c372cb75":"### Final Touches","e1bf423d":"Adding the correct block number to the test set","9ffbaed3":"Generate all combinations of items and shops for each month","abd6a7ca":"Saving for quicker loading later","764ebc21":"Calculating monthly items sold (target).\n\nFilling missing values with zeros and clipping targets into [0,20] as suggested [here](https:\/\/www.kaggle.com\/c\/competitive-data-science-predict-future-sales\/overview\/evaluation)","adb56df2":"Some shops are duplicates. Merge them","a1bb113c":"### Revenue features","0b10ba53":"Versions of packages","276baba8":"# Feature engineering","a33ba475":"### Basic Feature Engineering + Extracting text features","665b09c5":"As we can see, there are a couple of outliers and negative item prices","b37a4166":"### Lagging features\nhttps:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost","c12840e1":"# EDA","b0302856":"time since first sale and since first sale at the shop","e2c8be5a":"### Date features"}}