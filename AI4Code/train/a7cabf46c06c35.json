{"cell_type":{"5c1695d4":"code","413fd878":"code","2b2a11bf":"code","11c7c06b":"code","de9d8774":"code","7edfd44f":"code","f191cce4":"code","4edaad1b":"code","ed980016":"code","7423953d":"code","c8abe3f3":"code","901bb882":"code","6104d7b4":"code","d3742959":"code","06c83664":"markdown","4a43988b":"markdown","73b1673d":"markdown","59afd9c9":"markdown","55bc0f60":"markdown","10baeb23":"markdown","8d3d2af3":"markdown","62e8fc30":"markdown"},"source":{"5c1695d4":"import pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nimport re","413fd878":"rcc_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/rcc_train.csv\")\nse_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/se_train.csv\", index_col=\"key_value\")\ncenso_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/censo_train.csv\", index_col=\"key_value\")\ny_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/y_train.csv\", index_col=\"key_value\").target\n\nrcc_test= pd.read_csv(\"\/kaggle\/input\/interbank20\/rcc_test.csv\")\nse_test= pd.read_csv(\"\/kaggle\/input\/interbank20\/se_test.csv\", index_col=\"key_value\")\ncenso_test= pd.read_csv(\"\/kaggle\/input\/interbank20\/censo_test.csv\", index_col=\"key_value\")","2b2a11bf":"bins = [-1, 0, 10, 20, 30, 60, 90, 180, 360, 720, float(\"inf\")]\nrcc_train[\"condicion\"] = pd.cut(rcc_train.condicion, bins)\nrcc_test[\"condicion\"] = pd.cut(rcc_test.condicion, bins)","11c7c06b":"def makeCt(df, c, aggfunc=sum):\n    try:\n        ct = pd.crosstab(df.key_value, df[c].fillna(\"N\/A\"), values=df.saldo, aggfunc=aggfunc)\n    except:\n        ct = pd.crosstab(df.key_value, df[c], values=df.saldo, aggfunc=aggfunc)\n    ct.columns = [f\"{c}_{aggfunc.__name__}_{v}\" for v in ct.columns]\n    return ct","de9d8774":"train = []\ntest = []\naggfuncs = [len, sum, min, max]\nfor c in rcc_train.drop([\"codmes\", \"key_value\", \"saldo\"], axis=1):\n    print(\"haciendo\", c)\n    train.extend([makeCt(rcc_train, c, aggfunc) for aggfunc in aggfuncs])\n    test.extend([makeCt(rcc_test, c, aggfunc) for aggfunc in aggfuncs])","7edfd44f":"import gc\n\ndel rcc_train, rcc_test\ngc.collect()","f191cce4":"train = pd.concat(train, axis=1)\ntest = pd.concat(test, axis=1)","4edaad1b":"train = train.join(censo_train).join(se_train)\ntest = test.join(censo_test).join(se_test)\n\ndel censo_train, se_train, censo_test, se_test\ngc.collect()","ed980016":"keep_cols = list(set(train.columns).intersection(set(test.columns)))\ntrain = train[keep_cols]\ntest = test[keep_cols]\nlen(set(train.columns) - set(test.columns)) , len(set(test.columns) - set(train.columns))","7423953d":"test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_-]+', '', x))\ntrain = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_-]+', '', x))","c8abe3f3":"folds = [train.index[t] for t, v in KFold(5).split(train)]","901bb882":"from sklearn.model_selection import ParameterGrid\n\nparams = ParameterGrid({\"min_child_samples\": [150, 250, 500, 1000], \"boosting_type\": [\"gbdt\", \"goss\"]})","6104d7b4":"best_score = 0\nbest_probs = []\nfor param in params:\n    test_probs = []\n    train_probs = []\n    p  = \"\/\/\/\".join([f\"{k}={v}\" for k, v in param.items()])\n    print(\"*\"*10, p, \"*\"*10)\n    for i, idx in enumerate(folds):\n        Xt = train.loc[idx]\n        yt = y_train.loc[Xt.index]\n\n        Xv = train.drop(Xt.index)\n        yv = y_train.loc[Xv.index]\n\n        learner = LGBMClassifier(n_estimators=1000, **param)\n        learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n                    eval_set=[(Xt, yt), (Xv, yv)], verbose=False)\n        test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n        train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n\n    test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n    train_probs = pd.concat(train_probs)\n    score = roc_auc_score(y_train, train_probs.loc[y_train.index])\n    print(f\"roc auc estimado para {p}: {score}\")\n    if score > best_score:\n        print(\"*\"*10, f\"{p} es el nuevo mejor modelo\", \"*\"*10)\n        best_score = score\n        best_probs = test_probs\n    ","d3742959":"best_probs.name = \"target\"\nbest_probs.to_csv(\"benchmark2.csv\")","06c83664":"### Lectura de las Bases\n\nObservamos los datos que tenemos disponibles en https:\/\/www.kaggle.com\/c\/interbank20\/data\n\nVamos a trabajar ahora con todas las bases disponibles","4a43988b":"### Incorporamos la Informaci\u00f3n adicional existente en las tablas socio econ\u00f3micas y del censo. Es un simple join porque ambas tienen key_value \u00fanicos\n#### Por el momento no incorporamos la informaci\u00f3n tributaria porque requiere un tratamiento m\u00e1s complejo que queda para futuras revisiones","73b1673d":"### Entrenamiento del Modelo\n\nPara entrenar nuestro modelo vamos a usar LightGBM. A diferencia del notebook anterior, esta vez vamos a agregar la optimizaci\u00f3n de hyper-par\u00e1metro. Se usan s\u00f3lo dos con algunos pocos posibles valores, a modo de ejemplo para que los participantes lo puedan ir mejorando. ","59afd9c9":"### Guardado de las predicciones modelo para hacer la presentaci\u00f3n\n\nFinalmente creamos el archivo CSV que podemos subir como nuestra Soluci\u00f3n a la competencia","55bc0f60":"### Importamos las librer\u00edas que vamos a utilizar","10baeb23":"### Vamos a trabajar ahora con la base de **RCC**:\n* Discretizamos los d\u00edas de atraso para poder manipularla mejor\n* Hacemos tablas cruzadas sobre key_value y cada variable de inter\u00e9s, utilizando distintas funciones de agregaci\u00f3n sobre el saldo del producto","8d3d2af3":"# Script para generar la soluci\u00f3n del Primer Benchmark de la Competencia\n\n## Si no presentaste a\u00fan tu primera soluci\u00f3n, tenes la oportunidad de hacerlo en pocos Clicks!\n\n**Hola! **  \n  \nEste Script es un Ejemplo de Procesamiento de los Datos, Modelado y Generaci\u00f3n de una Soluci\u00f3n.\n\nAgregamos una peque\u00f1a explicaci\u00f3n de lo que se hace en cada paso para ayudar a los que est\u00e1n comenzando ahora\n","62e8fc30":"### Por la naturaleza de las variables creadas, nos aseguramos que solo se utilicen variables existentes en ambos conjuntos de datos (train y test)"}}