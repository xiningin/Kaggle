{"cell_type":{"57f1ffd4":"code","21414025":"code","4a335226":"code","bc199321":"code","1f7bfc6c":"code","2d97f3fe":"code","ba6d6444":"code","2223ef60":"code","5af1bd9b":"code","0468fdca":"markdown","5f19bf9a":"markdown","736dd95c":"markdown","926b963c":"markdown","d1bba68f":"markdown","e495122a":"markdown","9d8dbe5b":"markdown","30e816e5":"markdown"},"source":{"57f1ffd4":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage\nfrom pathlib import Path\nfrom IPython.display import Image\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.xception import (Xception,\n                                                        decode_predictions,\n                                                        preprocess_input\n                                                       )","21414025":"img_size = (299, 299, 3)\nmodel = Xception(weights=\"imagenet\")","4a335226":"def get_img_array(img_path, size=(299, 299)):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array","bc199321":"def get_gradients(img_input, top_pred_idx):\n    images = tf.cast(img_input, tf.float32)\n    \n    with tf.GradientTape() as tape:\n        tape.watch(images)\n        preds = model(images)\n        top_class = preds[:, top_pred_idx]\n    \n    grads = tape.gradient(top_class, images)\n    return grads","1f7bfc6c":"def get_integrated_gradients(img_input, top_pred_idx, baseline=None, num_steps=50):\n    if baseline is None:\n        baseline = np.zeros(img_size).astype(np.float32)\n    else:\n        baseline = baseline.astype(np.float32)\n        \n    # 1. Do interpolation\n    img_input = img_input.astype(np.float32)\n    interpolated_image = [baseline + (step \/ num_steps)*(img_input - baseline) for step in range(num_steps + 1)]\n    interpolated_image = np.array(interpolated_image).astype(np.float32)\n    interpolated_image = preprocess_input(interpolated_image)\n    \n    \n    # 2. Get the gradients\n    grads = []\n    \n    for i, img in enumerate(interpolated_image):\n        img = tf.expand_dims(img, axis=0)\n        grad = get_gradients(img, top_pred_idx=top_pred_idx)\n        #print(\"Gradients computed\", grad.shape)\n        grads.append(grad[0])\n        \n    grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n    \n    # 3. Approximate the integral usiing trapezoidal rule\n    grads = (grads[:-1] + grads[1:]) \/ 2.0\n    avg_grads = tf.reduce_mean(grads, axis=0)\n    \n    # 4. calculate integrated gradients and return\n    integrated_grads = (img_input - baseline) * avg_grads\n    \n    return integrated_grads","2d97f3fe":"def random_baseline_integrated_gradients(img_input, top_pred_idx, num_steps=50, num_runs=10):\n    integrated_grads = []\n    \n    for run in range(num_runs):\n        baseline = (np.random.random(img_size) * 255)\n        igrads = get_integrated_gradients(img_input=img_input,\n                                          top_pred_idx=top_pred_idx,\n                                          baseline=baseline,\n                                          num_steps=num_steps,\n                                         )\n        integrated_grads.append(igrads)\n        \n    integrated_grads = tf.convert_to_tensor(integrated_grads)\n    return tf.reduce_mean(integrated_grads, axis=0)","ba6d6444":"class GradVisualizer:\n    \"\"\"Plot gradients of an input.\"\"\"\n\n    def __init__(self, positive_channel=None, negative_channel=None):\n        if positive_channel is None:\n            self.positive_channel = [0, 255, 0]\n        else:\n            self.positive_channel = positive_channel\n        \n        if negative_channel is None:\n            self.negative_channel = [255, 0, 0]\n        else:\n            self.negative_channel = negative_channel\n    \n    def apply_polarity(self, attributions, polarity):\n        if polarity == \"positive\":\n            return np.clip(attributions, 0, 1)\n        else:\n            return np.clip(attributions, -1, 0)\n        \n    def apply_linear_transformation(self,\n                                        attributions,\n                                        clip_above_percentile=99.9,\n                                        clip_below_percentile=70.0,\n                                        lower_end=0.2\n                                    ):\n        # 1. get the thresholds\n        m = self.get_thresholded_attributions(attributions, percentage=100 - clip_above_percentile)\n        e = self.get_thresholded_attributions(attributions, percentage=100 - clip_below_percentile)\n\n        # 2.transform the attributions by a linear function f(x) = a*x + b such that\n        # f(m) = 1.0 and f(e) = lower_end\n        transformed_attributions = (1 - lower_end) * (np.abs(attributions) - e) \/ (m - e) + lower_end\n\n        # 3, Make sure that the sign of transformed attributions is the same as original attributions\n        transformed_attributions *= np.sign(attributions)\n\n        # 4. Only keep values that are bigger than the lower_end\n        transformed_attributions *= (transformed_attributions >= lower_end)\n\n        # 5. Clip values and return \n        transformed_attributions = np.clip(transformed_attributions, 0.0, 1.0)\n        return transformed_attributions\n        \n    def get_thresholded_attributions(self, attributions, percentage):\n        if percentage == 100.0:\n            return np.min(attributions)\n\n        # 1. Flatten the attributions\n        flatten_attr = attributions.flatten()\n\n        # 2. Get the sum of the attributions\n        total = np.sum(flatten_attr)\n\n        # 3. Sort the attributions from largest to smallest.\n        sorted_attributions = np.sort(np.abs(flatten_attr))[::-1]\n\n        # 4. Calculate the percentage of the total sum that each attribution\n        # and the values about it contribute.\n        cum_sum = 100.0 * np.cumsum(sorted_attributions) \/ total\n\n        # 5. threshold the attributions by the percentage\n        indices_to_consider = np.where(cum_sum >= percentage)[0][0]\n\n        # 6. select the desired attributions and return\n        attributions = sorted_attributions[indices_to_consider]\n        return attributions\n    \n    def binarize(self, attributions, threshold=0.001):\n        return attributions > threshold\n    \n    def morphological_cleanup_fn(self, attributions, structure=np.ones((4,4))):\n        closed = ndimage.grey_closing(attributions, structure=structure)\n        opened = ndimage.grey_opening(closed, structure=structure)\n        return opened\n    \n    def draw_outlines(self,\n                    attributions,\n                    percentage=90,\n                    connected_component_structure=np.ones((3,3))\n                    ):\n        # 1. Binarize the attributions.\n        attributions = self.binarize(attributions)\n        \n        # 2. fill the gaps\n        attributions = ndimage.binary_fill_holes(attributions)\n\n        # 3. Compute connected components\n        connected_components, num_comp = ndimage.measurements.label(attributions,\n                                                                    structure=connected_component_structure)\n\n        # 4. Go sum up the attributions for each component\n        total = np.sum(attributions[connected_components > 0])\n        component_sums = []\n        \n        for comp in range(1, num_comp+1):\n            mask = connected_components == comp\n            component_sum = np.sum(attributions[mask])\n            component_sums.append((component_sum, mask))\n\n        # 5. Compute the percentage of top components to keep.\n        sorted_sums_and_masks = sorted(component_sums, key=lambda x: x[0], reverse=True)\n        sorted_sums = list(zip(*sorted_sums_and_masks))[0]\n        cumulative_sorted_sums = np.cumsum(sorted_sums)\n        cutoff_threshold = percentage * total \/ 100\n        cutoff_idx = np.where(cumulative_sorted_sums >= cutoff_threshold)[0][0]\n\n        if cutoff_idx > 2:\n            cutoff_idx = 2\n\n        # 6.Set the values for the kept components.\n        border_mask = np.zeros_like(attributions)\n        for i in range(cutoff_idx + 1):\n            border_mask[sorted_sums_and_masks[i][1]] = 1\n\n\n        # 7. Make the mask hollow and show only border\n        eroded_mask = ndimage.binary_erosion(border_mask, iterations=1)\n        border_mask[eroded_mask] = 0\n        \n        # 8. return the outlined mask\n        return border_mask\n            \n    \n    def process_grads(self,\n                image,\n                attributions,\n                polarity=\"positive\",\n                clip_above_percentile=99.9,\n                clip_below_percentile=0,\n                morphological_cleanup=False,\n                structure=np.ones((3,3)),\n                outlines=False,\n                outlines_component_percentage=90,\n                overlay=True,\n                ):\n        \n        if polarity not in [\"positive\", \"negative\"]:\n            raise ValueError(f\"\"\" Allowed polarity values: 'positive' or 'negatiive'\n                                    but provided {polarity}\"\"\")\n        \n        if clip_above_percentile < 0 or clip_above_percentile > 100:\n            raise ValueError('clip_above_percentile must be in [0, 100]')\n        \n        if clip_below_percentile < 0 or clip_below_percentile > 100:\n            raise ValueError('clip_below_percentile must be in [0, 100]')\n        \n        # 1. apply polarity\n        if polarity == \"positive\":\n            attributions = self.apply_polarity(attributions, polarity=polarity)\n            channel = self.positive_channel\n        else:\n            attributions = self.apply_polarity(attributions, polarity=polarity)\n            attributions = np.abs(attributions)\n            channel = self.negative_channel\n        \n        # 2. Average over the channels\n        attributions = np.average(attributions, axis=2)\n        \n        # 3. Apply linear transformation to the attributions\n        attributions = self.apply_linear_transformation(attributions,\n                                                        clip_above_percentile=clip_above_percentile,\n                                                        clip_below_percentile=clip_below_percentile,\n                                                        lower_end=0.0\n                                                       )\n        \n        \n        # 5. cleanup\n        if morphological_cleanup:\n            attributions = self.morphological_cleanup_fn(attributions, structure=structure)\n        # 5. Draw the outlines\n        if outlines:\n            attributions = self.draw_outlines(attributions, percentage=outlines_component_percentage)\n        \n        # 4. Expand the channel axis and convert to RGB\n        attributions = np.expand_dims(attributions, 2) * channel\n        \n        # 6.. Super impose on the original image\n        if overlay:\n            attributions = np.clip((attributions * 0.8 + image), 0, 255)\n            \n        return attributions\n\n    def visualize(self,\n                image,\n                gradients,\n                integrated_gradients,\n                polarity=\"positive\",\n                clip_above_percentile=99.9,\n                clip_below_percentile=0,\n                morphological_cleanup=False,\n                structure=np.ones((3,3)),\n                outlines=False,\n                outlines_component_percentage=90,\n                overlay=True,\n                figsize=(15, 8),\n                ):\n        \n        # 1. Make two copies of the original image\n        img1 = np.copy(image)\n        img2 = np.copy(image)\n\n        # 2. Process the normal grads\n        grads_attr = self.process_grads(image=img1,\n                                attributions=gradients,\n                                polarity=polarity,\n                                clip_above_percentile=clip_above_percentile,\n                                clip_below_percentile=clip_below_percentile,\n                                morphological_cleanup=morphological_cleanup,\n                                structure=structure,\n                                outlines=outlines,\n                                outlines_component_percentage=outlines_component_percentage,\n                                overlay=overlay\n                            )\n        \n        # 3. Process the integrated gradients\n        igrads_attr = self.process_grads(image=img1,\n                                attributions=integrated_gradients,\n                                polarity=polarity,\n                                clip_above_percentile=clip_above_percentile,\n                                clip_below_percentile=clip_below_percentile,\n                                morphological_cleanup=morphological_cleanup,\n                                structure=structure,\n                                outlines=outlines,\n                                outlines_component_percentage=outlines_component_percentage,\n                                overlay=overlay\n                            )\n        \n        f, ax = plt.subplots(1, 3, figsize=figsize)\n        ax[0].imshow(image)\n        ax[1].imshow(grads_attr.astype(np.uint8))\n        ax[2].imshow(igrads_attr.astype(np.uint8))\n\n        ax[0].set_title(\"Input\")\n        ax[1].set_title(\"Normal gradients\")\n        ax[2].set_title(\"Integrated gradients\")\n        plt.show()","2223ef60":"all_images = list(Path(\"..\/input\/\").glob(\"*.jpg\"))\nprint(\"Number of images found\", len(all_images))","5af1bd9b":"for img_path in all_images:\n    # 1. load image\n    img = get_img_array(img_path)\n    orig_img = np.copy(img[0]).astype(np.uint8)\n    \n    # 2. preprocess the image\n    img_processed = tf.cast(preprocess_input(img), dtype=tf.float32)\n    \n    # 3. get predictions and top predicted label\n    preds = model.predict(img_processed)\n    top_pred_idx = tf.argmax(preds[0])\n    print(\"Predicted:\", top_pred_idx, decode_predictions(preds, top=1)[0])\n    \n    # 4. Compute gradients of last layer for the predicted output\n    grads = get_gradients(img_processed, top_pred_idx=top_pred_idx)\n    \n    # 5. Compute the integrated gradients\n    igrads = random_baseline_integrated_gradients(np.copy(orig_img),\n                                                  top_pred_idx=top_pred_idx,\n                                                  num_steps=50,\n                                                  num_runs=2\n                                                 )\n    # 6. Visualize\n    vis = GradVisualizer()\n    vis.visualize(image=orig_img,\n                    gradients=grads[0].numpy(),\n                    integrated_gradients=igrads.numpy(),\n                    clip_above_percentile=99,\n                    clip_below_percentile=0,\n                    overlay=True\n                 )\n    # 7. visualize with outlines\n    vis.visualize(image=orig_img,\n                    gradients=grads[0].numpy(),\n                    integrated_gradients=igrads.numpy(),\n                    clip_above_percentile=95,\n                    clip_below_percentile=28,\n                    morphological_cleanup=True,\n                    outlines=True,\n                    overlay=True\n                 )","0468fdca":"### helper function to load the images","5f19bf9a":"### method to compute integrated gradients","736dd95c":"### method to compute gradients","926b963c":"#### Import required libraries","d1bba68f":"### load model","e495122a":"### sample examples","9d8dbe5b":"## Integrated Gradients\n[Integrated Gradients](https:\/\/arxiv.org\/abs\/1703.01365) is a technique for\nattributing a classification model's prediction to its input features. It is\none of the interpretibility techniques used to understand why did the model make\nthis prediction on this input.\n[Integrated Gradients](https:\/\/arxiv.org\/abs\/1703.01365) involves following steps:\n1. Construct a sequence of images interpolating from a baseline to the actual image.\n2. Do a forward pass on these interpolated images and get the gradients.\n2. Average the gradients across these images.\n\n\n### Refrences:\nPaper: https:\/\/arxiv.org\/abs\/1703.01365<br>\nOriginal implementation: https:\/\/github.com\/ankurtaly\/Integrated-Gradients","30e816e5":"### Helper class to visualize the gradients"}}