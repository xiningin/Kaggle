{"cell_type":{"222dd03f":"code","ace65fd3":"code","e3364d1a":"code","9fe7b682":"code","eefe9380":"code","4f8016d6":"code","113b5e9e":"code","7e5df1ec":"code","79f1a1bc":"code","aab3f734":"code","9435e8b3":"code","02e406a8":"code","eef1b907":"code","b1000d72":"code","28b416c2":"code","6cfec9c1":"code","a2f106dd":"code","4b2932d0":"code","4c27135e":"code","0a6a1e48":"code","50c9c8df":"code","56048cc7":"code","71026591":"code","7ab82689":"code","b5de594c":"code","187330f5":"code","78fad077":"code","1c110137":"markdown","2d8d28f0":"markdown","4050594d":"markdown","fe8b1798":"markdown","739a2aad":"markdown","0ac65da1":"markdown","f7199c7b":"markdown","5f7e9aa4":"markdown","5b0b252e":"markdown","57167661":"markdown","ee1da1b8":"markdown","9c27a169":"markdown","ed2d5489":"markdown","ca50dbe2":"markdown","03768048":"markdown","32e9f033":"markdown"},"source":{"222dd03f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ace65fd3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns ","e3364d1a":"data = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/hyundi.csv')","9fe7b682":"data.head(10)","eefe9380":"print(data.model.unique())\nprint(data.year.unique())\nprint(data.transmission.unique())\nprint(data.fuelType.unique())","4f8016d6":"plt.figure(figsize=(14,6))\nsns.countplot(x='model',data=data)","113b5e9e":"plt.figure(figsize=(14,6))\nsns.countplot(x='year',data=data)","7e5df1ec":"plt.figure(figsize=(8,6))\nsns.countplot(x='transmission',data=data)","79f1a1bc":"plt.figure(figsize=(8,6))\nsns.countplot(x='fuelType',data=data)","aab3f734":"data.describe()","9435e8b3":"sns.heatmap(data.corr(), annot=True, linewidths=1)","02e406a8":"plt.scatter(data.mileage, data.price)","eef1b907":"plt.scatter(data.year, data.price)","b1000d72":"plt.scatter(data['tax(\u00a3)'], data.price)","28b416c2":"plt.scatter(data.mpg, data.price)","6cfec9c1":"plt.scatter(data.engineSize, data.price)","a2f106dd":"datac=data.copy()\n\ndatac.head()","4b2932d0":"datac_d = pd.get_dummies(datac)\ndatac_d.head()","4c27135e":"datac_d=datac_d.drop([\"tax(\u00a3)\",\"mpg\",\"price\"], axis=1)\n\ndatac_d.head()","0a6a1e48":"price = datac.price\nprice.head()","50c9c8df":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ndata_scaled = scaler.fit_transform(datac_d)\ndata_scaled = pd.DataFrame(data_scaled, columns=datac_d.columns)\n\ndata_scaled.head()","56048cc7":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train, y_test = train_test_split(data_scaled, price, test_size=0.2, random_state=1)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","71026591":"from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(x_train,y_train)\npreds = model.predict(x_test)\nmodel.score(x_test, y_test)","7ab82689":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor()\nreg.fit(x_train,y_train)\nreg.score(x_test, y_test)","b5de594c":"from sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures()\nx_train_poly = poly.fit_transform(x_train)\nx_test_poly = poly.fit_transform(x_test)\n\nprint(x_train.shape)\nprint(x_test.shape)","187330f5":"regp = RandomForestRegressor()\n\nregp.fit(x_train_poly, y_train)\npreds_p = regp.predict(x_test_poly)\nprint(regp.score(x_test_poly, y_test))","78fad077":"predictions = pd.DataFrame({\"price prediction\": preds_p.flatten()})\ny_test = y_test.reset_index()\nresult = y_test.join(predictions)\nresult = result.drop(['index'], axis=1)\nresult.head(10)","1c110137":"load the data from csv file.","2d8d28f0":"split the data","4050594d":"scale the numerical features by using min-max-scaler","fe8b1798":"Categories of Variables","739a2aad":"Visualize and understand the data.","0ac65da1":"now create a data frame to compare the predicted results","f7199c7b":"price column from the data ","5f7e9aa4":"Import the libraries","5b0b252e":"From the visualization and the correlation of the data. tax and mpg are not contributing to predict the price. so, we can drop them.","57167661":"The accuracy is 94%. ","ee1da1b8":"drop tax, mpg, and price from copied data","9c27a169":"One Hot Encode the categorical variables of the data for better performance.","ed2d5489":"features miliage and year had a polynomial relation with price.","ca50dbe2":"Try Linear Regression model","03768048":"The acuuracy is 87% which is pretty less. so lets try Random Forest Regressor because we have categorical columns.","32e9f033":"The accuracy is pretty much same. "}}