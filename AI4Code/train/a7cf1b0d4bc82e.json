{"cell_type":{"8ff27a2a":"code","0fb16ead":"code","03b10152":"code","ff234a2a":"code","86a8314e":"code","68aed2ef":"code","28c70f9f":"markdown","6606c103":"markdown","c70fd190":"markdown","10d14ae7":"markdown","ac86f0c9":"markdown","5cc32f00":"markdown","e41ff9e3":"markdown","28ae0561":"markdown","70e5ddb6":"markdown"},"source":{"8ff27a2a":"# This block imports necessary libraries\n\nimport numpy as np # linear algebra\nimport scipy as sp\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport glob\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\n\nwarnings.filterwarnings('ignore')","0fb16ead":"# Function to read a single job posting\ndef read_job_posting(filename):\n    # read all the files into memory\n    with open(filename, 'r', errors='ignore') as fp:\n        filetext = fp.readlines()\n        filetext = [line.rstrip().replace('\\t+','') for line in filetext if line.rstrip()]\n    # concatenated file text\n    concat_file_text = '\\n'.join(filetext)\n    \n    # Extract Various Fields\n    this_file_data = {'FILE_NAME': os.path.basename(filename),\n                      'FILE_TEXT':concat_file_text,\n                      'JOB_CLASS_TITLE':filetext[0].rstrip(),\n                      'JOB_CLASS_NO': (re.findall(r'\\d+',list(filter(lambda x: 'Class Code:' in x,filetext))[0])[0] \n                                       if len(list(filter(lambda x: 'Class Code:' in x,filetext))) > 0 else np.nan),\n                      'OPEN_DATE': (list(filter(lambda x: 'Open Date:' in x,filetext))[0].split(\"Open Date:\")[1].split(\"(\")[0].strip() \n                                    if len(list(filter(lambda x: 'Open Date:' in x,filetext))) >0 else None),\n                      'JOB_DUTIES': re.split(r'DUTIES\\n*|\\n*REQUIREMENT',concat_file_text)[1],\n                      'ENTRY_SALARY_GEN': (re.split(r'\\n+|;|and|or|The|\\(|\\. |, ',\n                                                   re.split(r'ANNUAL SALARY\\n*',concat_file_text)[1])[0]\n                                                      .strip().replace('to','-').replace('TO','-').replace('flat rated.','(flat rated)') \n                                           if len(re.split(r'ANNUAL SALARY\\n*',concat_file_text)) > 1 else None),\n                      'ENTRY_SALARY_DWP': (re.split(r'\\n+|;|and|or|The|\\(|\\. , ',(list(filter(lambda x: 'salary in the Department of Water and Power is' in x,filetext))[0]\n                                            .split('Power is')[1]))[0]\n                                            .strip().replace('to','-')\n                                            .replace('flat rated.','(flat rated)') \n                                           if len(list(filter(lambda x: 'salary in the Department of Water and Power is' in x,filetext))) > 0 else np.nan),\n                      'REQUIREMENTS': (re.split(r'\\n*WHERE TO APPLY',(re.split(r'REQUIREMENTS?(?:\\s*\/\\s*MINIMUM QUALIFICATIONS?)?\\n*',concat_file_text)[1]))[0]\n                                       if len(re.split(r'REQUIREMENTS?(?:\\s*\/\\s*MINIMUM QUALIFICATIONS?)?',concat_file_text)) > 1 else None),\n                     }\n    # ENTRY_SALARY_GEN\n    if this_file_data['ENTRY_SALARY_GEN'] is not None:\n        if '$' not in this_file_data['ENTRY_SALARY_GEN']:\n            this_file_data['ENTRY_SALARY_GEN'] = None\n    try: \n        this_file_data['ENTRY_SALARY_AVG'] = (np.mean(list(map(float,re.sub('\\$|,|\\(*flat.*rated\\)*|-|\\*','',this_file_data['ENTRY_SALARY_GEN']).split()))))\n    except Exception as e:\n        this_file_data['ENTRY_SALARY_AVG'] = np.nan #if this_file_data['ENTRY_SALARY_GEN'] is not None else np.nan)                              \n\n    \n    if 'driver\\'s license is required' in this_file_data['REQUIREMENTS']:\n        this_file_data['DRIVER_LICENSE_REQ'] = 'R'\n    elif re.compile('driver\\'s license').search(this_file_data['REQUIREMENTS']):\n        this_file_data['DRIVER_LICENSE_REQ'] = 'P'\n    else:\n        this_file_data['DRIVER_LICENSE_REQ'] = ''\n     \n    df = pd.DataFrame(this_file_data, index=[0])\n    df['DRIV_LIC_TYPE'] = df.REQUIREMENTS.str.extract(r'(Class.*)\\s+(driver\\'s)\\s*license?')[0].str.replace('\\s*(driver\\'s)?\\s*license.*|\\s*California\\s*','')\n   \n    return(df)","03b10152":"bulletin_dir = \"..\/input\/cityofla\/CityofLA\/Job Bulletins\"\nprint('Reading: '+ bulletin_dir)\n\nfilenames = glob.glob(bulletin_dir+'\/*')\ndata_list = []\nfor file_ in filenames:\n    df = read_job_posting(file_)\n    data_list.append(df)\n        \ndf_jobs = pd.concat(data_list, sort = False).reset_index(drop = True)\n#df_jobs.head(10)\n#set(df_jobs.DRIV_LIC_TYPE)","ff234a2a":"df_jobs.loc[random.sample(list(df_jobs.index),15),]","86a8314e":"sns.set()\nplt.rcParams['figure.figsize']=(12,6)\nsns.distplot(df_jobs.ENTRY_SALARY_AVG.fillna(axis=0, method='ffill'), bins =30, color = 'red')","68aed2ef":"from wordcloud import WordCloud, STOPWORDS\ntext = df_jobs.REQUIREMENTS.values\nwordcloud = WordCloud(\n    width = 1200,\n    height = 800,\n    background_color = 'black').generate(str(text))\nfig = plt.figure(\n    figsize = (8, 6),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()\n","28c70f9f":"## Word Cloud of the Requirement Column\n\nLet us turn the words from the Job Requirements column in to a word coud to see if any words stand out. ","6606c103":"## Goals & Approach\n\nThe goal of this kernel is to generate some useful insights into job postings by City of Los Angeles, by following the steps below. \n\n* Convert a folder full of plain-text job postings into a single structured CSV file and then to use this data to: \n    * Identify language that can negatively bias the pool of applicants; \n    * Improve the diversity and quality of the applicant pool; and\/or \n    * Make it easier to determine which promotions are available to employees in each job class.\n\n### Approach:\nWe will proeed in this order. \n1. Data Cleaning \/ Dataframe generation\n2. Exploratory Analysis \/ Visualization\n3. Recommendations\n\n\n## Data Cleaning \/ Dataframe generation\n\n**Columns Added So Far: (More to be added)**\n\n**NOTE:** Please refer to the file named \"kaggle_data_dictionary.csv\" for the descriptions of various columns.\n* FILE_NAME\n* JOB_CLASS_TITLE\n* JOB_CLASS_NO\n* JOB_DUTIES\n* REQUIREMENTS (Not sorted into SET_ID \/ SUBSET_ID yet)\n* ENTRY_SALARY_GEN\n* ENTRY_SALARY_DWP\n* OPEN_DATE\n* DRIVER_LICENSE_REQ\n* DRIV_LIC_TYPE","c70fd190":"### Observataions from above\n\n1. Apart from the obvious items such as \"Los Angeles\", text related to traffic citations and driver license requirements show up a lot in the job postings. Given how important these are, it is probably worth it to pust a more structured requirements for the Driver License than a free from text description. ","10d14ae7":"### Let us display 15 randomly selected rows of the dataframe, that we painstakingly built. You can scroll left and right to see all the columns.","ac86f0c9":"### Let us read all the job postings into a dataframe using the function above.","5cc32f00":"### The function below reads a single job posting and generates a single row of a dataframe with relevant fields. ","e41ff9e3":"** It looks the salaries are peaking at around \\$80,000. But there are some jobs with more than \\$250,000 salary !!**","28ae0561":"## Data Analysis \/ Visualization\n\n### Let us start with the distribution of salaries (middle of the range) in the job postings","70e5ddb6":"# Suggestions for Improving the Job Postings\n\n1. Given how frequently Driver License requirements are mentioned in the job postings, it is probably worth it to pust a more structured requirements for the Driver License than a free from text description. It is probably also good to mention clearly if a driver license requirement not there for a job. \n\n2. It is probably more useful to have a section of \"Disqualifying Conditions\", so that it is easier for the candidates to filter out the jobs that have that disqualifying criteria such as \"having 3 citations in the past 3 years etc.\""}}