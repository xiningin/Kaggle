{"cell_type":{"ba69316d":"code","e4aaf5db":"code","fef9fa95":"code","c312d615":"code","3ce9f9be":"code","9f61b95b":"code","2d8e6deb":"code","f09db344":"code","0bfa5ae8":"code","2ae884df":"code","746c5e31":"code","0cf2f499":"code","98c09e10":"code","7398dfb8":"code","15e3883a":"code","465cbd48":"code","3f45ca70":"code","cd003258":"code","7e87b573":"code","9eeaee29":"code","cb88a70b":"code","9c2ada2e":"markdown","f0b9e345":"markdown","0c4e7bbb":"markdown","222df65a":"markdown","f526b03b":"markdown","110dffe7":"markdown","c20ddeac":"markdown","2535e9da":"markdown","a07ee80c":"markdown","4ba2e2a1":"markdown","d844e374":"markdown","372031cb":"markdown","270b2307":"markdown","e9892759":"markdown","24ffe03b":"markdown","d4105ed4":"markdown","c8f8cb88":"markdown","f833b7f0":"markdown","6364d0ab":"markdown","e422f48d":"markdown","2a67f7ee":"markdown","8a844b73":"markdown","f8f27300":"markdown","133a85df":"markdown","7ef58eee":"markdown","f39d6c53":"markdown"},"source":{"ba69316d":"import os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom skimage.feature import canny\nfrom skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\nfrom skimage.segmentation import felzenszwalb, slic, quickshift, watershed\nfrom skimage.segmentation import mark_boundaries\nfrom scipy import signal\n\nimport cv2\nfrom PIL import Image\nimport pdb\nfrom tqdm import tqdm\nimport seaborn as sns\nimport os \nfrom glob import glob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e4aaf5db":"INPUT_PATH = '..\/input'\nDATA_PATH = INPUT_PATH\nTRAIN_DATA = os.path.join(DATA_PATH, \"train\/images\")\nTRAIN_MASKS_DATA = os.path.join(DATA_PATH, \"train\/masks\")\nTEST_DATA = os.path.join(DATA_PATH, \"test\")\ndf = pd.read_csv(DATA_PATH+'\/depths.csv')\npath_train = '..\/input\/train\/'\npath_test = '..\/input\/test\/'\ntrain_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]","fef9fa95":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        data_path = TRAIN_DATA\n    elif \"mask\" in image_type:\n        data_path = TRAIN_MASKS_DATA\n    elif \"Test\" in image_type:\n        data_path = TEST_DATA\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}\".format(image_id))\n\ndef get_image_data(image_id, image_type, **kwargs):\n    img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    img = img.astype('uint8')\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","c312d615":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\n_train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n_train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\nalpha = 0.25\n\nm = int(np.ceil(len(_train_ids) * 1.0 \/ n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        \n        mask = get_image_data(image_id, \"Train_mask\")\n        img_masked =  cv2.addWeighted(img, alpha, mask, 1 - alpha,0)\n#         img_masked = cv2.bitwise_and(img, img, mask=mask)\n\n        img = cv2.resize(img, dsize=tile_size)\n        img_masked = cv2.resize(img_masked, dsize=tile_size)\n        \n        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n        \n        img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n        \n    if counter == len(_train_ids):\n        break    \n        \nm = complete_image.shape[0] \/ (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:])\n    plt.title(\"Training dataset\")\n    \nm = complete_image.shape[0] \/ (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training dataset: Lighter Color depicts salt\")","3ce9f9be":"foo = [val[:-4] for val in train_ids]\ntemp = df.set_index('id')\ndf_train = temp.loc[foo]\nprint('df_train shape:',df_train.shape[0])\ndf_train = df_train.reset_index()\n\nfoo = [val[:-4] for val in test_ids]\ntemp = df.set_index('id')\ndf_test = temp.loc[foo]\ndf_test = df_test.reset_index()\n\nprint('df_test shape:',df_test.shape[0])","9f61b95b":"sns.distplot(df_train['z'],kde_kws={ \"lw\": 3, \"label\": \"Train KDE\"})\nsns.distplot(df_test['z'],kde_kws={ \"lw\": 3, \"label\": \"Test KDE\"})\nplt.title('Comparing Train and Test Set Depth Distributions')","2d8e6deb":"df_train = df_train.set_index('id')\ndf_train['saltPercentage'] = 0\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n\n    # Load Y\n    mask = img_to_array(load_img(path + '\/masks\/' + id_, grayscale=True))\n\n    df_train.loc[id_[:-4],'saltPercentage'] = np.sum(mask[:]>0)\/(mask.shape[0]*mask.shape[1])\n    \ndf_train = df_train.reset_index()","f09db344":"sns.set_style(\"white\")\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.distplot(df_train['saltPercentage'])\nprint(\"There are\",np.sum(df_train['saltPercentage']>0.95),\"images with salt content greater than 95%\")","0bfa5ae8":"df_train['bin'] = pd.cut(df_train.z,3)\n# df_train['bin'] = pd.qcut(df_train.z,3)\ndepth_idx = []\nunique_bins = np.unique(df_train.bin.values)\nfor bin_interval in unique_bins:\n    depth_idx.append(np.ravel(np.where(df_train['bin']==bin_interval)))","2ae884df":"print(df_train.groupby('bin')['saltPercentage'].mean())\n# sns.set_style(\"white\")\n# sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n# sns.regplot(x='z',y='saltPercentage', data=df_train)","746c5e31":"depth1 = df_train.groupby('bin')\ndepth1 = depth1.get_group(unique_bins[0])\ndepth2 = df_train.groupby('bin')\ndepth2 = depth2.get_group(unique_bins[1])\ndepth3 = df_train.groupby('bin')\ndepth3 = depth3.get_group(unique_bins[2])\nprint(\"Depth: {} to {}\\n\".format(unique_bins[0].left,unique_bins[0].right),depth1[['saltPercentage','z']].corr())\nprint(\"Depth: {} to {}\\n\".format(unique_bins[1].left,unique_bins[1].right),depth2[['saltPercentage','z']].corr())\nprint(\"Depth: {} to {}\\n\".format(unique_bins[2].left,unique_bins[2].right),depth3[['saltPercentage','z']].corr())","0cf2f499":"sns.set_style(\"white\")\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.distplot(depth1['saltPercentage'],hist=False,label=\"Depth: {} to {}\".format(unique_bins[0].left,unique_bins[0].right))\nsns.distplot(depth2['saltPercentage'],hist=False,label=\"Depth: {} to {}\".format(unique_bins[1].left,unique_bins[1].right))\nsns.distplot(depth3['saltPercentage'],hist=False,label=\"Depth: {} to {}\".format(unique_bins[2].left,unique_bins[2].right))","98c09e10":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\n_train_ids = list(df_train.loc[depth_idx[0],'id']+'.png')\n# _train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n_train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 \/ n))\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        \n        mask = get_image_data(image_id, \"Train_mask\")\n        img_masked =  cv2.addWeighted(img, alpha, mask, 1 - alpha,0)\n        img_masked = cv2.resize(img_masked, dsize=tile_size)\n        \n        \n        img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n        \n    if counter == len(_train_ids):\n        break    \nm = complete_image_masked.shape[0] \/ (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training Set Depth Range: {} to {}\".format(unique_bins[0].left,unique_bins[0].right))\n#     plt.legend('Lighter Color depicts salt')","7398dfb8":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\n_train_ids = list(df_train.loc[depth_idx[1],'id']+'.png')\n# _train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n_train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 \/ n))\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        \n        mask = get_image_data(image_id, \"Train_mask\")\n        img_masked =  cv2.addWeighted(img, alpha, mask, 1 - alpha,0)\n        img_masked = cv2.resize(img_masked, dsize=tile_size)\n        \n        \n        img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n        \n    if counter == len(_train_ids):\n        break    \n        \nm = complete_image_masked.shape[0] \/ (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training Set Depth Range: {} to {}\".format(unique_bins[1].left,unique_bins[1].right))\n#     plt.legend('Lighter Color depicts salt')","15e3883a":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\n_train_ids = list(df_train.loc[depth_idx[2],'id']+'.png')\n# _train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n_train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 \/ n))\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n#         segments_fz = felzenszwalb(img, scale=100, sigma=0.5, min_size=50)\n# #         segments_slic = slic(img, n_segments=250, compactness=10, sigma=1)\n# #         segments_quick = quickshift(img, kernel_size=3, max_dist=6, ratio=0.5)\n#         img = mark_boundaries(img, segments_fz)\n# #         thresh =  threshold_sauvola(img)\n# #         img = img < thresh\n#         img = (img*255).astype('uint8')\n        img = cv2.resize(img, dsize=tile_size)\n        \n        mask = get_image_data(image_id, \"Train_mask\")\n        mask = cv2.resize(mask, dsize=tile_size)\n        img_masked =  cv2.addWeighted(img, alpha, mask, 1 - alpha,0)\n        img_masked = cv2.resize(img_masked, dsize=tile_size)\n        \n        \n#         img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n        \n    if counter == len(_train_ids):\n        break    \n        \nm = complete_image_masked.shape[0] \/ (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m \/ k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training Set Depth Range: {} to {}\".format(unique_bins[2].left,unique_bins[2].right))\n#     plt.legend('Lighter Color depicts salt')","465cbd48":"_train_ids = list(df_train.loc[depth_idx[0],'id']+'.png')\nmask_depth0 = np.zeros((101, 101,len(_train_ids)), dtype=np.float32)\nfor n, id_ in tqdm(enumerate(_train_ids), total=len(_train_ids)):\n    image_id = _train_ids[n]\n    mask = get_image_data(image_id, \"Train_mask\")\n    mask_depth0[:,:,n] = (mask[:,:,0]>0).astype('uint8')\n\nmean_mask_depth0 = mask_depth0.mean(axis=2)\n\n_train_ids = list(df_train.loc[depth_idx[1],'id']+'.png')\nmask_depth1 = np.zeros((101, 101,len(_train_ids)), dtype=np.float32)\nfor n, id_ in tqdm(enumerate(_train_ids), total=len(_train_ids)):\n    image_id = _train_ids[n]\n    mask = get_image_data(image_id, \"Train_mask\")\n    mask_depth1[:,:,n] = (mask[:,:,0]>0).astype('uint8')\n\nmean_mask_depth1 = mask_depth1.mean(axis=2)\n\n_train_ids = list(df_train.loc[depth_idx[2],'id']+'.png')\nmask_depth2 = np.zeros((101, 101,len(_train_ids)), dtype=np.float32)\nfor n, id_ in tqdm(enumerate(_train_ids), total=len(_train_ids)):\n    image_id = _train_ids[n]\n    mask = get_image_data(image_id, \"Train_mask\")\n    mask_depth2[:,:,n] = (mask[:,:,0]>0).astype('uint8')\n\nmean_mask_depth2 = mask_depth2.mean(axis=2)","3f45ca70":"fig = plt.figure(1,figsize=(30,15))\nax = fig.add_subplot(1,3,1)\nax.imshow(mean_mask_depth0)\nax.set_title(\"Depth Range: {} to {}\".format(unique_bins[0].left,unique_bins[0].right))\n\nax = fig.add_subplot(1,3,2)\nax.imshow(mean_mask_depth1)\nax.set_title(\"Depth Range: {} to {}\".format(unique_bins[1].left,unique_bins[1].right))\n\nax = fig.add_subplot(1,3,3)\nax.imshow(mean_mask_depth2)\nax.set_title(\"Depth Range: {} to {}\".format(unique_bins[2].left,unique_bins[2].right))\n\nplt.suptitle('Mean Masks at different depths',y=0.8)","cd003258":"# defining the kernels\nxder = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\nyder = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\nsmooth = np.array([[1,1,1],[1,5,1],[1,1,1]])\nxder2 = np.array([[-1,2,-1],[-3,6,-3],[-1,2,-1]])\nyder2 = np.array([[-1,-3,-1],[2,6,2],[-1,-3,-1]])","7e87b573":"_train_ids = list(df_train.loc[depth_idx[2],'id']+'.png')\nfig = plt.figure(1,figsize=(15,15))\nfor i in range(9):\n    image_id = _train_ids[i]\n    ax = fig.add_subplot(3,3,i+1)\n    img = get_image_data(image_id, 'Train')\n    img = signal.convolve2d(img[:,:,0],smooth,mode='valid')\n    img = img.astype('uint8')\n    img = cv2.resize(img, dsize=tile_size)\n    mask = get_image_data(image_id, \"Train_mask\")\n    mask = cv2.resize(mask, dsize=tile_size)\n    mask = mask[:,:,0]\n    img_masked =  cv2.addWeighted(img, alpha, mask, 1 - alpha,0)\n    img_masked = cv2.resize(img_masked, dsize=tile_size)\n    ax.imshow(img_masked,cmap='binary')\n    ax.set_title('Smoothed Image')\n    \nplt.show()\nplt.suptitle('Smoothed Image with Mask overlayed')","9eeaee29":"# Plot band_1\n_train_ids = list(df_train.loc[depth_idx[2],'id']+'.png')\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.8, hspace=0.2)  #adjust this to change vertical and horiz. spacings..\nq = 0\nfor i in range(3):\n    q = q+1\n    image_id = _train_ids[i]\n#     ax = fig.add_subplot(3,3,i+1)\n    img = get_image_data(image_id, 'Train')\n    img_orig = img.copy()\n    \n    img_x = signal.convolve2d(img[:,:,0],xder,mode='valid')\n    img_x = img_x.astype('uint8')\n    img_x = cv2.resize(img_x, dsize=tile_size)\n    \n    img_y = signal.convolve2d(img[:,:,0],yder,mode='valid')\n    img_y = img_y.astype('uint8')\n    img_y = cv2.resize(img_y, dsize=tile_size)\n    \n    grad_img = np.hypot(img_x,img_y)\n    grad_img = grad_img.astype('uint8')\n    grad_img = cv2.resize(grad_img, dsize=tile_size)\n    \n    mask = get_image_data(image_id, \"Train_mask\")\n    mask = cv2.resize(mask, dsize=tile_size)\n    mask = mask[:,:,0]\n    \n    plt.subplot(3,6,q*6-5)\n    plt.imshow(img_orig, cmap='binary')\n    plt.title('Original Image')\n    \n    plt.subplot(3,6,q*6-4)\n    plt.imshow(mask, cmap='binary')\n    plt.title('Image Mask')\n    \n    plt.subplot(3,6,q*6-3)    \n    plt.imshow(img_x, cmap='binary')\n    plt.title('X-Derivative')\n    \n    plt.subplot(3,6,q*6-2)    \n    plt.imshow(img_y, cmap='binary')\n    plt.title('Y-Derivative')\n    \n    plt.subplot(3,6,q*6-1)    \n    plt.imshow(grad_img,cmap='binary')\n    plt.title('Gradient Magnitude')\n    \nplt.show()\nplt.suptitle('Visualizing First Derivatives', y=0.75, fontsize=30)","cb88a70b":"# Plot band_1\n_train_ids = list(df_train.loc[depth_idx[2],'id']+'.png')\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.8, hspace=0.2)  #adjust this to change vertical and horiz. spacings..\nq = 0\nfor i in range(3):\n    q = q+1\n    image_id = _train_ids[i]\n#     ax = fig.add_subplot(3,3,i+1)\n    img = get_image_data(image_id, 'Train')\n    img_orig = img.copy()\n    \n    img_x = signal.convolve2d(img[:,:,0],xder2,mode='valid')\n    img_x = img_x.astype('uint8')\n    img_x = cv2.resize(img_x, dsize=tile_size)\n    \n    img_y = signal.convolve2d(img[:,:,0],yder2,mode='valid')\n    img_y = img_y.astype('uint8')\n    img_y = cv2.resize(img_y, dsize=tile_size)\n    \n    laplacian = np.hypot(img_x,img_y)\n    laplacian = laplacian.astype('uint8')\n    laplacian = cv2.resize(laplacian, dsize=tile_size)\n    \n    mask = get_image_data(image_id, \"Train_mask\")\n    mask = cv2.resize(mask, dsize=tile_size)\n    mask = mask[:,:,0]\n    \n    plt.subplot(3,6,q*6-5)\n    plt.imshow(img_orig, cmap='binary')\n    plt.title('Original Image')\n    \n    plt.subplot(3,6,q*6-4)\n    plt.imshow(mask, cmap='binary')\n    plt.title('Image Mask')\n    \n    plt.subplot(3,6,q*6-3)    \n    plt.imshow(img_x, cmap='binary')\n    plt.title('Second X-Derivative')\n    \n    plt.subplot(3,6,q*6-2)    \n    plt.imshow(img_y, cmap='binary')\n    plt.title('Second Y-Derivative')\n    \n    plt.subplot(3,6,q*6-1)    \n    plt.imshow(laplacian,cmap='binary')\n    plt.title('Laplacian')\n    \nplt.show()\nplt.suptitle('Visualizing Second Derivatives')","9c2ada2e":"<h2> Visualizing the masks","f0b9e345":"In this notebook, I try to explore the TGS Salt Segmentation data. My purpose here is not to set up a segmentation model, but rather to try to explore the provided data and get some sense of what types of features may be useful. I hope you find this helpful. Happy Kaggling :-)","0c4e7bbb":"We can see the mean Salt Percentage is highest for the group of images at depth between 353 and 656..\nWe can further notice that correlation of Salt Percentage is high for depths between 50 and 353 which may mean that as we go deeper from 50 to 353, the salt content seems to increase... At deeper depths, the correlation seems to be negligible.","222df65a":"Let's try to transform the images in some way to enhance the contrast between the salt and the background.","f526b03b":"Let's plot some images at different depths and try to see if we are able to glean any differences. This way, we can get some sense of what we're looking at. The images are 101 x 101 pixels each with the mask (in lighter color) overlayed on top of it. ","110dffe7":"This helps to confirm our suspicion that salt is not equally distributed at all depths. ","c20ddeac":"We can also define a simple second-derivative operator. The  second order derivatives should do less smoothing than a first order derivative, so we might see less contrast between the salt and the background.\nThe Laplacian operator is just the sum of second derivatives, or the divergence of the gradient.","2535e9da":"<h2>**Plotting Images**","a07ee80c":"It can be seen that Y-derivative has some interesting pattern. We could perhaps use it in our cnn.","4ba2e2a1":"<h2> Some utility functions","d844e374":"We can see from the above plot that depths between 50 and 353 has a high number of images with no salt contents.\nIt can also be observed that depths 353 to 656 has the highest salt content for Salt Percentage greater than 0.25.","372031cb":"<h3>**Smoothing the Image**","270b2307":"# Salt content and the depth","e9892759":"<h2> Setting the Paths","24ffe03b":"<h3>**Second Derivatives**","d4105ed4":"**<h2>Introduction**","c8f8cb88":"As we might expect, smoothing blurs the features. However, it also enhances the contrast between bright and dark regions, so it may be quite useful if we want to use it to seed some clusters..","f833b7f0":"**<h2>Transforming the Images**","6364d0ab":"Let's try to take X-Derivative and  Y-Derivative of the image. We can also take alook at the magnitude of the gradient which can be calculated by taking  the x and y derivatives as a gradient vector at each position and then taking the magnitude at each point.","e422f48d":"Let's try to see if there is any relationship between the salt content and the depth.","2a67f7ee":"It seems that there is a corrleation of 0.1 between depth and saltPercentage. Let's dig deeper.","8a844b73":"<h2>**Plotting Images: Depthwise**","f8f27300":"We've looked at a number of transformations of the images. Gradient-based methods can be used to get features, and smoothing may help out with images with small regions of salt.","133a85df":"<h3>**First Derivatives**","7ef58eee":"Lets plot some random images from training set and some images with the mask overlayed on top of it.","f39d6c53":"It seems that at depth 0 i.e. 50 to 353 the masks appear to be in the lower part of the image. Similarly at depth 2 i.e. 656 to 959 the masks appear to be in the lower part of the image. Let's try to confirm our suspicions  by plotting the mean location of masks at different depths."}}