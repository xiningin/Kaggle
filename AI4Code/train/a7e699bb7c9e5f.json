{"cell_type":{"f1a3e10e":"code","3dc109ce":"code","0cc5b658":"code","42d609d9":"code","66072c11":"code","98e4ef1e":"code","02b43a7b":"code","75131e9e":"code","e6844363":"code","19186207":"code","c0053c2a":"code","207886a8":"code","7c82fd4a":"code","ce6547c6":"code","05d08237":"code","55498d03":"markdown","69ea2ad8":"markdown","81b83ceb":"markdown","57f60c7e":"markdown","a798a8cc":"markdown","fc20687b":"markdown","20ed91b5":"markdown","4cc22ced":"markdown","573cebe6":"markdown","52e103c1":"markdown","d4931970":"markdown","19df8bd7":"markdown"},"source":{"f1a3e10e":"import numpy as np\nimport pandas as pd\nimport re\n\nall_lines = []\n\nVERSION = 0\ntry:\n    with open('..\/input\/jigsaw-toxic-severity-lightgbm-training\/version.info', 'r') as f:\n        all_lines = f.readlines()\n    print(\"Version file read successfully.\")\nexcept:\n    pass\n\nfinally:\n    print(\"Updating version file...\")\n    with open('version.info', 'w') as f:\n        if len(all_lines) != 0:\n            VERSION = int(re.sub(r'\\D', '', '\\n'.join(all_lines))) + 1\n            \n        f.writelines(f\"Version: {VERSION}\")\n        print(\"current version:\", VERSION)","3dc109ce":"train_1 = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ntrain_1","0cc5b658":"train_1_cleaned = pd.concat(\n    [pd.DataFrame({\"text\":train_1.less_toxic.unique(), \"score\":np.zeros(train_1.less_toxic.nunique())}),\n     pd.DataFrame({\"text\":train_1.more_toxic.unique(), \"score\":np.ones(train_1.more_toxic.nunique())})],\n    axis=0).reset_index(drop=True)\ntrain_1_cleaned","42d609d9":"train_2 = pd.read_csv(\"..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv\")\ntrain_2","66072c11":"train_2_cleaned = pd.DataFrame({'text':train_2.comment_text, 'score':train_2.target})\ntrain_2_cleaned['score'] = train_2_cleaned['score'].apply(lambda x: 0 if x <= 0.05 else 0.5+(x\/2))\ntrain_2_cleaned","98e4ef1e":"train_3 = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip\")\ntrain_3","02b43a7b":"score = np.mean(train_3[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']], axis=1)\ntrain_3_cleaned = pd.DataFrame({'text':train_3.comment_text, 'score':score})\ntrain_3_cleaned['score'] = train_3_cleaned['score'].apply(lambda x: 0 if x <= 0.05 else 0.5+(x\/2))\ntrain_3_cleaned","75131e9e":"train_df = pd.concat(\n    [train_1_cleaned, train_2_cleaned, train_3_cleaned],\n    axis=0\n).reset_index(drop=True)\ntrain_df","e6844363":"printed = []\nfor i in sorted(train_df.score.unique()):\n    n = np.round(i, 2) \n    if n in printed:\n        continue\n    printed.append(n)\n    print(f\"{len(printed):<3}: {i:.5f}\\t{repr(np.random.choice(train_df[train_df.score==i]['text']))[:100]}\")","19186207":"train_df[train_df.score == 0.].shape[0]\/train_df.shape[0]","c0053c2a":"train_df_sel = train_df[train_df.score != 0.]\ntrain_df_zer = train_df[train_df.score == 0.].reset_index(drop=True)\ntrain_df_zer = train_df_zer[:train_df_zer.shape[0]\/\/4]\ntrain_df = pd.concat([train_df_zer, train_df_sel], axis=0).reset_index(drop=True)\nprint(train_df[train_df.score == 0.].shape[0]\/train_df.shape[0])\ntrain_df","207886a8":"from tqdm.notebook import tqdm\ntqdm.pandas()\n\nimport re\n\nW_to_I = {'':0}\nadd_space_before_punc = lambda x: re.sub(r'(\\W|_)', r' \\1 ', x)\nremove_whitespaces = lambda x: re.sub(r'\\s+', ' ', x)\nremove_multiples = lambda x: re.sub(r'(.)\\1{2,}', r'\\1\\1', x) #Remove repeated char multiple times\n\ntrain_df['clean_text'] = train_df.text.progress_apply(\n    lambda x: remove_whitespaces(remove_multiples(add_space_before_punc(x)))\n)\n\n# Average len is 44 with min of 1 word and max of 4948.\ntrain_df['len'] = train_df.clean_text.progress_apply(lambda x: len(x.split()))\n\ndef convert_to_int(word):\n    c = W_to_I.get(word, -1)\n    if c==-1:\n        c = len(W_to_I)\n        W_to_I[word] = c\n    return c\n\ndef convert_text_to_arr(text, max_len=60):\n    words = text.split()[:max_len]\n    n = len(words)\n    if n < max_len:\n        words += ['' for _ in range(max_len - n)]\n    words = [convert_to_int(word) for word in words]\n    return np.array(words)\n\nX = train_df.clean_text.progress_apply(lambda x: convert_text_to_arr(x))\nX = np.concatenate([i.reshape((1, -1)) for i in X.values], axis=0)\ny = train_df['score']\nstratify = ['toxic' if y_v>=0.5 else 'not' for y_v in y]","7c82fd4a":"from lightgbm import LGBMRegressor as method\nfrom sklearn.model_selection import train_test_split as tts\n\ncurrent_seed = np.random.randint(7, 1e6)\nprint(\"Using seed:\", current_seed)\n\nprint(\"Splitting train and validation set...\")\ntrain_x, valid_x, train_y, valid_y = tts(X, y, test_size=0.1,\n                                         shuffle=True, random_state=current_seed,\n                                        stratify=stratify)\nprint(\"Train shapes:\", train_x.shape, train_y.shape,\n      \"\\nTest shapes:\", valid_x.shape, valid_y.shape)\n\ndepth = 1000\nmodel = method(\n    device='cpu',\n    #gpu_platform_id=0,\n    #gpu_device_id=0,\n    boosting_type='goss',\n    objective='mse',\n    is_unbalance=True,\n    n_estimators=depth**2,\n    learning_rate=0.05\/(VERSION+1),\n    max_bin=64,\n    #subsample_freq=10,\n    #subsample=0.75,\n    #max_depth=2,\n    #num_leaves=5,\n    reg_alpha=1.5,\n    reg_lambda=5.75,\n    random_state=current_seed,\n    #force_col_wise=True,\n    silent=True,\n    n_jobs=64,\n)\nprint(\"Model fitting...\")\nmodel.fit(train_x, train_y,\n          eval_set=[[train_x, train_y], [valid_x, valid_y]],\n          early_stopping_rounds=depth\/\/5,\n          verbose=depth\/\/50,\n          init_model=\"..\/input\/jigsaw-toxic-severity-lightgbm-training\/model_booster_weights.txt\",\n         )\nmodel.booster_.save_model(\"model_booster_weights.txt\", num_iteration=model.best_iteration_)\nprint(\"Training end.\")","ce6547c6":"import matplotlib.pyplot as plt\n\npreds =model.predict(valid_x, num_iteration=model.best_iteration_)\n\nplt.title(\"Prediction and True value difference with abs(y - pred):\")\nplt.ylim([0, 1])\nplt.plot(range(len(preds)), np.abs(np.where(valid_y=='toxic', 1, 0) - preds), c='#ff0000', alpha=0.5)\nplt.show()","05d08237":"from scipy.stats import rankdata\n\ntest = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ntest['clean_text'] = test.text.progress_apply(\n    lambda x: remove_whitespaces(remove_multiples(add_space_before_punc(x)))\n)\ntest_X = test.clean_text.progress_apply(lambda x: convert_text_to_arr(x))\ntest_X = np.concatenate([i.reshape((1, -1)) for i in test_X.values], axis=0)\n\npreds = model.predict(test_X, num_iteration=model.best_iteration_)\ndisplay(preds, preds.min(), preds.max())\nsub = pd.DataFrame({'comment_id':test.comment_id.values, 'score':rankdata(preds, method='ordinal')})\nsub.to_csv('submission.csv', index=False)\nsub","55498d03":"# Submission","69ea2ad8":"Now, we will vectorize our train data.","81b83ceb":"# Data Preprocessing\n\nNow that we have a train data, let's focus on preparing the data for our training. The first step is to clean the text input string.","57f60c7e":"Now, we will merge all train data as one.","a798a8cc":"For the data from `jigsaw-toxic-comment-classification-challenge`, we will be scoring them based on the average of the five columns present as targets. Similar to `train_2` we will be using base 50% once more.","fc20687b":"There's over 70% of the data that is not toxic (`score` is `0.0`) so we need to reduce their numbers.","20ed91b5":"Let's check one random comment for each unique score (based from a rounded cutoff or 2 decimal places) printing the first 100 raw chars of the corresponding text.","4cc22ced":"For the main train data, we will simple associate the column `less_toxic` with the score of `0` and the column `more_toxic` with the score of `1`. There are some text that are duplicates so we will filter out the uniques for each level of toxicity.","573cebe6":"We will be using multiple dataset from previous Jigsaw competitions as complementary train data.","52e103c1":"# Begin","d4931970":"For the data from `jigsaw-unintended-bias-in-toxicity-classification` we will only be using the `comment_text` and the `target` columns. We will adjust the score on a 50% base if, and only if, the score is not near zero.","19df8bd7":"# Training"}}