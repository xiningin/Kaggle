{"cell_type":{"82fa40a2":"code","9548f104":"code","732bd692":"code","d1d6328a":"code","2f1ceb11":"code","92fd0ef5":"code","a723f228":"code","61768899":"code","db61a775":"code","6f82eda1":"code","86ac1573":"code","68641bae":"code","531c4b45":"code","be9a1733":"code","a9766557":"code","ff88efa0":"code","6ff17bb4":"code","7d3b4375":"code","74139227":"code","f471a898":"code","5abdf05e":"code","a2df386a":"code","b70fd7ec":"code","a739d3f9":"code","65c6ae53":"code","b68979cd":"code","c997314b":"code","8e6cd956":"code","3c4d3858":"code","d9e44014":"code","651b21af":"code","df3143fb":"code","a8421969":"code","b59598bc":"code","674c0a05":"code","e69ab6a7":"code","ebec5a2f":"code","3d325f15":"markdown","f72d28f8":"markdown","98968d43":"markdown","08f87d7c":"markdown","effa2bd6":"markdown","93cff6cf":"markdown","f7d78d2d":"markdown","d8315863":"markdown","07cd7648":"markdown","ee19706c":"markdown","57728803":"markdown","cee90eab":"markdown","12a7cdc8":"markdown","1c129992":"markdown","2a179ea7":"markdown","69d8de1a":"markdown","ca3ac88d":"markdown","217e61a5":"markdown","ce4ceb7f":"markdown","7808c647":"markdown","9e06c492":"markdown","9bcd3827":"markdown","fd6729bf":"markdown","85a937ac":"markdown","47cbbf8f":"markdown","efabf366":"markdown","a3bef281":"markdown","bc797625":"markdown","164a0f23":"markdown"},"source":{"82fa40a2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\nimport os\nimport pandas as pd\nfrom pandas import Series, DataFrame\n\nimport torch\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\n\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nfrom PIL import Image\n\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport warnings","9548f104":"for dirname, _, filenames in os.walk('\/kaggle\/input\/ropstages-reviewed\/NewROPDataset_Sample_justtotry\/'):\n   for filename in filenames:\n    x=Image.open(os.path.join(dirname, filename))\n    print('File Name',os.path.join(dirname, filename))\n    print('Picture Size', x.size)\n","732bd692":"#Assign the used device to GPU if available\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#Creation of the Dataframe\ntrain_df = pd.DataFrame(columns=[\"img_name\",\"label\"])\n\n#Assign each images from the input folder to a label corresponding to ROP or No ROP\ntrain_df[\"img_name\"] = os.listdir('\/kaggle\/input\/ropstages-reviewed\/NewROPDataset_Sample_justtotry\/')\nfor idx, i in enumerate(os.listdir('\/kaggle\/input\/ropstages-reviewed\/NewROPDataset_Sample_justtotry\/')):\n    '''Here we give a label for ROP\/No ROP to every images depending on the name they have (the stage they correspond to) '''\n    if \"NoROP\" in i:\n        train_df[\"label\"][idx] = 0\n    if \"Stage1\" in i:\n        train_df[\"label\"][idx] = 1\n    if \"Stage2\" in i:\n        train_df[\"label\"][idx] = 1\n    if \"Stage3\" in i:\n        train_df[\"label\"][idx] = 1\n\n#View the dataframe created\nprint(train_df)\n\n#Create a csv file out of our dataframe\ntrain_df.to_csv (r'train_csv.csv', index = False, header=True)","d1d6328a":"#Create a list to make classes label explicite\nclasses=['No ROP','ROP']\n\n\nfor label_number in range(2):\n    print('Label',label_number,'corresponds to',classes[label_number])","2f1ceb11":"#Create a list of labels from our data frame\nListOfLabels=train_df[\"label\"].to_list()\n\n#Here we are gonna count how many images for each stages we have\n#No ROP\nNoROP_Size=ListOfLabels.count(0)\nprint('Number of NoROP images', NoROP_Size)\n\n#ROP\nROP_Size=ListOfLabels.count(1)\nprint('Number of ROP images', ROP_Size)\n\n#Check the images count\n#print(NoROP_Size+Stage1_Size+Stage2_Size+Stage3_Size)\n\nprint('the size of our dataset is',len(train_df[\"label\"]))","92fd0ef5":"# Creation of the dataset we will use for our deep learning model\nclass Stage1NoROP(Dataset):\n    def __init__(self, root_dir, annotation_file, transform=None):\n        self.root_dir = root_dir\n        self.annotations = pd.read_csv(annotation_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        pic_id = self.annotations.iloc[index, 0]\n        pic = Image.open(os.path.join(self.root_dir, pic_id)).convert(\"RGB\")\n        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n\n        if self.transform is not None:\n            pic = self.transform(pic)\n\n        return (pic, y_label)","a723f228":"#Processing function for the sole purpose of images display\ntransform = transforms.Compose([transforms.Resize((1000, 1000)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5,0.5,0.5),\n                                                     (0.5,0.5,0.5))])\n    ","61768899":"#Assign dataset\ndataset = Stage1NoROP('\/kaggle\/input\/ropstages-reviewed\/NewROPDataset_Sample_justtotry\/',\"train_csv.csv\",transform=transform)\n\n#Split data for training, testing and validation\ntrain_set, test_set, validation_set = torch.utils.data.random_split(dataset,[60,15,16])\n","db61a775":"#Unnormalize the object given as input\nclass UnnormalizingPicture(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n        return tensor\n    \nUnnormalized = UnnormalizingPicture(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))","6f82eda1":"#Create a function to display images\ndef imshow(img):\n    img=img\/2+0.5\n    npimg=img.numpy()\n    plt.imshow(np.transpose(npimg,(1,2,0)))","86ac1573":"#Define Parameters and create figure as an empty \"table\"\nClass=len(classes)\ncolumn=3\ncolors = ('red', 'green', 'blue')\nfig=plt.figure(figsize=(20,30))\n\n#Complete the table by displaying pictures \n#and creating their associated histogram\ni=0\nfor i in range(Class):\n    #Loading Train Set\n    dataiter_train=iter(train_set)\n    image_train, idx_train=next(x for x in dataiter_train if (x[1]==i))\n    \n    #Loading Test set\n    dataiter_test=iter(test_set)\n    image_test, idx_test=next(x for x in dataiter_test if (x[1]==i))\n    \n    #Loading Validation set\n    dataiter_test=iter(validation_set)\n    image_validation, idx_validation=next(x for x in dataiter_test if (x[1]==i))\n    \n    #Creating first colum of the grid - One train set picture from each classe\n    ax=fig.add_subplot(Class,column,i*column+1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.title.set_text(str(classes[i]+' from train set'))\n    #Display one picture of each class in each row of first colum\n    imshow(image_train)\n    print(image_train.shape)#verify the shape of the images\n    \n    #Creating third Column of the grid - One test set picture from each classe\n    ax2=fig.add_subplot(Class,column,i*column+3)\n    ax2.set_xticks([])\n    ax2.set_yticks([])\n    ax2.title.set_text(str(classes[i]+' from validation set'))\n    #Display one picture of each class in each row of first colum\n    imshow(image_validation)\n    \n    \n    #Creating third Column of the grid - One test set picture from each classe\n    ax3=fig.add_subplot(Class,column,i*column+2)\n    ax3.set_xticks([])\n    ax3.set_yticks([])\n    ax3.title.set_text(str(classes[i]+' from test set'))\n    #Display one picture of each class in each row of first colum\n    imshow(image_test)\n    ","68641bae":"#Get the list of indexes \ndef GetListofIndexes(Dataset):\n    indexes=[]\n    i=0\n    while len(indexes)!=(len(Dataset)):\n        image,label=Dataset[i]\n        indexes.append(label)\n        i=i+1\n    return(indexes)","531c4b45":"# Get the number of images associated with each label for each subset\n#Repartition in Train set\nClassesTrain,Train_count = np.unique(GetListofIndexes(train_set), return_counts=True)\nprint(ClassesTrain)\nprint(Train_count)\nprint(sum(Train_count))\n\n#Repartition in Test set\nClassesTest,Test_count = np.unique(GetListofIndexes(test_set), return_counts=True)\nprint(ClassesTest)\nprint(Test_count)\nprint(sum(Test_count))\n\n#Repartition in Validation set\nClassesV,V_count = np.unique(GetListofIndexes(validation_set), return_counts=True)\nprint(ClassesV)\nprint(V_count)\nprint(sum(V_count))","be9a1733":"#Creation of the data repartition histogram\nplt.figure(figsize=(10,10))\nplt.title('Our data distribution')\n#Create x axis with each class (10 classes)\nclasses=['NorROP','ROP']\nplt.xticks(range(2), classes) \n# axis labels\nplt.xlabel('Classe label')\nplt.ylabel('Number of samples')\n#Bar creation\nplt.bar(range(len(Train_count)), Train_count, label='Train')\nplt.bar(range(len(Test_count)), Test_count, label='Test', bottom=Train_count)\nplt.bar(range(len(V_count)), V_count, label='Validation', bottom=[i+j for i,j in zip(Train_count, Test_count)])\nplt.legend()\nplt.show()","a9766557":"#Hyperparameters\nlearning_rate = 0.0005\nbatch_size = 4\nshuffle = True\npin_memory = True\nnum_workers = 0","ff88efa0":"# Data Processing (size) and Augmentation\ntransform_augmentation = transforms.Compose([\n    transforms.Resize((1000, 1000)),\n    transforms.RandomHorizontalFlip(),\n    #transforms.RandomVerticalFlip(p=1),\n    transforms.ToTensor(),\n    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n    transforms.Normalize((0.5,0.5,0.5),\n                         (0.5,0.5,0.5))\n])\n","6ff17bb4":"# Loading of the dataset with data-aumentation\ndataset_augmentation = Stage1NoROP('\/kaggle\/input\/ropstages-reviewed\/NewROPDataset_Sample_justtotry\/',\"train_csv.csv\",transform=transform_augmentation)\n#Data Split \ntrain_set_augmentation, test_set_augmentation, validation_set_augmentation = torch.utils.data.random_split(dataset,[60,15,16])","7d3b4375":"#Data loaders\ntrain_loader = torch.utils.data.DataLoader(dataset=train_set_augmentation, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_set_augmentation, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)\ntest_loader = torch.utils.data.DataLoader(dataset=test_set_augmentation, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)","74139227":"# Get the number of images associated with each label for each subset\n#Repartition in Train set\nClassesTrain,Train_count = np.unique(GetListofIndexes(train_set_augmentation), return_counts=True)\nprint(ClassesTrain)\nprint(Train_count)\nprint(sum(Train_count))\n\n#Repartition in test set\nClassesTest,Test_count = np.unique(GetListofIndexes(test_set_augmentation), return_counts=True)\nprint(ClassesTest)\nprint(Test_count)\nprint(sum(Test_count))\n\n#Repartition in valdiation set\nClassesV,V_count = np.unique(GetListofIndexes(validation_set_augmentation), return_counts=True)\nprint(ClassesV)\nprint(V_count)\nprint(sum(V_count))","f471a898":"#Creation of the histogram\nplt.figure(figsize=(10,10))\nplt.title('Our data distribution')\n#Create x axis with each class (10 classes)\nclasses=['NorROP','ROP']\nplt.xticks(range(2), classes) \n# axis labels\nplt.xlabel('Classe label')\nplt.ylabel('Number of samples')\n#Bar creation\nplt.bar(range(len(Train_count)), Train_count, label='Train')\nplt.bar(range(len(Test_count)), Test_count, label='Test', bottom=Train_count)\nplt.bar(range(len(V_count)), V_count, label='Validation', bottom=[i+j for i,j in zip(Train_count, Test_count)])\nplt.legend()\nplt.show()","5abdf05e":"#Parameters\nWeight=32\nHeight=32\nTotalNumberofClasses=2\n\n#Check GPU availability\ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)\n\n\n#Creation of our Model :  Le Net model\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(3,6, kernel_size=5)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.dropout = nn.Dropout(p=0.2) \n        self.fc1 = nn.Linear(976144, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, TotalNumberofClasses)\n        \n\n    def forward(self, x):\n        #print(x.size())\n        x = F.relu(self.conv1(x))\n        #print(x.size())\n        x = F.max_pool2d(x, 2)\n        #print(x.size())\n        x = F.relu(self.conv2(x))\n        #print(x.size())\n        x = F.max_pool2d(x, 2)\n        #print(x.size())\n        x=F.relu(x)\n        #print(x.size())\n        x=self.dropout(x)\n        x = x.view(x.size(0),-1)\n        #print(x.size())\n        x = F.relu(self.fc1(x))\n\n        #print(x.size())\n        x = F.relu(self.fc2(x))\n        #print(x.size())\n        x = self.fc3(x)\n        return x\n    \n\nour_CNN = LeNet()\n\n# If GPU available, move the model to GPU.\nif cuda:\n    our_CNN.cuda()","a2df386a":"#Display our model architecture\nprint(our_CNN)","b70fd7ec":"#Loss function chosen : Mean Squared error loss function\nLoss = nn.MSELoss()\n\n#Optimizer = AdamOptimizer\nOptimizer = torch.optim.Adam(our_CNN.parameters(), learning_rate)","a739d3f9":"# Create the directory to save our epochs\n!mkdir saved_models","65c6ae53":"num_epochs = 40\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nif cuda:\n    print(\"Using GPU\")\nelse:\n    print(\"Not using GPU\")\n\n\nfor epoch in range(num_epochs):\n    train_loss = []\n    validation_loss = []\n    \n    for batch_index, (train_image, train_label) in enumerate(train_loader):\n        # If GPU is available, move the data to the GPU for faster computation.\n        if cuda:\n            #######################################################\n            ####################### Train #########################\n            #######################################################\n            # Set the model to train mode so that the parameters can be updated.\n            our_CNN.train()\n            train_image=train_image.cuda()\n            train_label=train_label.cuda()\n            train_label_predicted = our_CNN(train_image)\n            one_hot_labels_train = torch.nn.functional.one_hot(train_label.long(), num_classes=2).to(torch.float)\n            #one_hot_labels_train = torch.nn.functional.one_hot(train_label, num_classes=3).to(torch.float)\n            #print(train_label_predicted.size())\n            loss = Loss(train_label_predicted, one_hot_labels_train)\n        \n            train_loss.append(loss.cuda().data.item())\n\n            # reset the gradient \n            Optimizer.zero_grad()\n            # backpropagate the loss\n            loss.backward()\n            # update the parameters\n            Optimizer.step()\n\n            #######################################################\n            ###################### Validation #####################\n            #######################################################\n            # Set the model to evaluation mode so that parameters are fixed.\n            our_CNN.eval()\n            \n            #Extract the batch validation images and validation labels from the validation loader\n            (image_validation_torch, label_validation_torch) = next(iter(validation_loader))\n\n            validation_label_predicted = our_CNN(image_validation_torch.cuda())\n            \n            one_hot_label_validation = torch.nn.functional.one_hot(label_validation_torch.cuda().long(), num_classes=2).to(torch.float)\n\n            loss = Loss(validation_label_predicted, one_hot_label_validation) #Custom MSE loss function\n            validation_loss.append(loss.cuda().data.item())\n        \n        # If GPU is not available.\n        else:\n            #######################################################\n            ####################### Train #########################\n            #######################################################\n            # Set the model to train mode so that the parameters can be updated.\n            our_CNN.train()\n\n            train_label_predicted = our_CNN(train_image)\n            \n            one_hot_labels_train = torch.nn.functional.one_hot(train_label.long(), num_classes=2).to(torch.float)\n\n            # compute the loss\n            loss = Loss(train_label_predicted,one_hot_labels_train ) #Custom MSE loss function\n            train_loss.append(loss.cpu().data.item())\n\n            # reset the gradient\n            Optimizer.zero_grad()\n            # backpropagate the loss\n            loss.backward()\n            # update the parameters\n            Optimizer.step()\n\n            #######################################################\n            ###################### Validation #####################\n            #######################################################\n            # Set the model to evaluation mode so that parameters are fixed.\n            our_CNN.eval()\n            \n            #Extract the batch validation images and validation labels from the validation loader\n            (image_validation_torch, label_validation_torch) = next(iter(validation_loader))\n\n            validation_label_predicted = our_CNN(image_validation_torch)\n            \n            one_hot_label_validation = torch.nn.functional.one_hot(label_validation_torch.long(), num_classes=2).to(torch.float)\n\n            loss = Loss(validation_label_predicted, one_hot_label_validation) #Custom MSE loss function\n            validation_loss.append(loss.cpu().data.item())\n\n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n    torch.save(our_CNN.state_dict(), '.\/saved_models\/checkpoint_epoch_%s.pth' % (epoch))\n        \n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))","b68979cd":"# Learning curve creation\nplt.figure(figsize = (12, 8))\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');","c997314b":"#Find the best epoch\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('best epoch: ', best_epoch)","8e6cd956":"#Get the infos from best epochs\nstate_dict = torch.load('.\/saved_models\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nour_CNN.load_state_dict(state_dict)","3c4d3858":"#Definition of the function that predicts the labels for every pictures\ndef predict(Model, Dataloader):\n    Labels = []\n    Predicted_labels = []\n    \n    for batch_index, (input_image, input_label) in enumerate(Dataloader):\n        # If GPU is available, move the data to the GPU for faster computation.\n        if cuda:\n            Model.eval()\n            \n            Labels.append(input_label.detach().cpu().tolist())\n            \n            Predicted_label = Model(input_image.cuda())\n            Predicted_label_probability, Predicted_label_idx = torch.max(Predicted_label.data, 1)\n            \n            for current_prediction in Predicted_label_idx:\n                Predicted_labels.append(current_prediction.detach().cpu().numpy().item())\n                \n        else:\n            Model.eval()\n            \n            Labels.append(input_label.detach().cpu().tolist())\n            \n            Predicted_label = Model(input_image)\n            Predicted_label_probability, Predicted_label_idx = torch.max(Predicted_label.data, 1)\n            \n            for current_prediction in Predicted_label_idx:\n                Predicted_labels.append(current_prediction.detach().cpu().numpy().item())\n                \n    Labels = [item for sublist in Labels for item in sublist]\n    return Predicted_labels, Labels","d9e44014":"(test_predicted_labels, test_labels) = predict(our_CNN, test_loader)","651b21af":"#Accuracy calculation\nAccuracy = accuracy_score(test_labels, test_predicted_labels)\n\nprint(\"The accuracy is :\", Accuracy * 100, \"%\")","df3143fb":"#Creation of the confusion matrix\nConfusion_Matrix = confusion_matrix(test_labels, test_predicted_labels)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(Confusion_Matrix, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 2]);\nplt.ylabel('Labels');\nplt.xlabel('Predicted labels');\nplt.xticks([i+0.5 for i in range(2)], classes)\nplt.yticks([i+0.5 for i in range(2)], classes)\nplt.show()","a8421969":"tn, fp, fn, tp = np.reshape(Confusion_Matrix,4)\nsensitivity = (tp) \/ (tp + fn)\nspecificity = tn \/ (tn + fp)\nsensitivity, specificity","b59598bc":"import torch.nn as nn\nimport torchvision.models as models\nfrom tqdm import tqdm\n\nclass CNN_Transfer(nn.Module):\n    def __init__(self, train_CNN=False, num_classes=2):\n        super(CNN_Transfer, self).__init__()\n        self.train_CNN = train_CNN\n        self.inception = models.inception_v3(pretrained=True, aux_logits=False)\n        self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, images):\n        features = self.inception(images)\n        return self.sigmoid(self.dropout(self.relu(features))).squeeze(1)","674c0a05":"our_CNN_Transfer = CNN_Transfer()\n\n# If GPU available, move the model to GPU.\nif cuda:\n    our_CNN_Transfer.cuda()","e69ab6a7":"#Loss function chosen : Mean Squared error loss function\nLoss_transfer = nn.MSELoss()\n\n#Optimizer = AdamOptimizer\nOptimizer_transfer = torch.optim.Adam(our_CNN_Transfer.parameters(), learning_rate)","ebec5a2f":"num_epochs_transfer = 40\n\ntrain_epoch_loss_transfer = []\nvalidation_epoch_loss_transfer = []\n\nif cuda:\n    print(\"Using GPU\")\nelse:\n    print(\"Not using GPU\")\n\n\nfor epoch in range(num_epochs_transfer):\n    train_loss_transfer = []\n    validation_loss_transfer = []\n    \n    for batch_index_transfer, (train_image_transfer, train_label_transfer) in enumerate(train_loader):\n        # If GPU is available, move the data to the GPU for faster computation.\n        if cuda:\n            #######################################################\n            ####################### Train #########################\n            #######################################################\n            # Set the model to train mode so that the parameters can be updated.\n            our_CNN_Transfer.train()\n            train_image_transfer=train_image_transfer.cuda()\n            train_label_transfer=train_label_transfer.cuda()\n            train_label_predicted_transfer = our_CNN_Transfer(train_image_transfer)\n            one_hot_labels_train_transfer = torch.nn.functional.one_hot(train_label_transfer.long(), num_classes=2).to(torch.float)\n            #one_hot_labels_train = torch.nn.functional.one_hot(train_label, num_classes=3).to(torch.float)\n            #print(train_label_predicted.size())\n            loss_transfer = Loss_transfer(train_label_predicted_transfer, one_hot_labels_train_transfer)\n        \n            train_loss_transfer.append(loss_transfer.cuda().data.item())\n\n            # reset the gradient \n            Optimizer_transfer.zero_grad()\n            # backpropagate the loss\n            loss_transfer.backward()\n            # update the parameters\n            Optimizer_transfer.step()\n\n            #######################################################\n            ###################### Validation #####################\n            #######################################################\n            # Set the model to evaluation mode so that parameters are fixed.\n            our_CNN_Transfer.eval()\n            \n            #Extract the batch validation images and validation labels from the validation loader\n            (image_validation_torch_transfer, label_validation_torch_transfer) = next(iter(validation_loader))\n\n            validation_label_predicted_transfer = our_CNN_Transfer(image_validation_torch_transfer.cuda())\n            \n            one_hot_label_validation_transfer = torch.nn.functional.one_hot(label_validation_torch_transfer.cuda().long(), num_classes=2).to(torch.float)\n\n            loss_transfer = Loss_transfer(validation_label_predicted_transfer, one_hot_label_validation_transfer) #Custom MSE loss function\n            validation_loss_transfer.append(loss_transfer.cuda().data.item())\n        \n        # If GPU is not available.\n        else:\n            #######################################################\n            ####################### Train #########################\n            #######################################################\n            # Set the model to train mode so that the parameters can be updated.\n            our_CNN_Transfer.train()\n\n            train_label_predicted_transfer = our_CNN_Transfer(train_image_transfer)\n            \n            one_hot_labels_train_transfer = torch.nn.functional.one_hot(train_label_transfer.long(), num_classes=2).to(torch.float)\n\n            # compute the loss\n            loss_transfer = Loss_transfer(train_label_predicted_transfer,one_hot_labels_train_transfer ) #Custom MSE loss function\n            train_loss_transfer.append(loss_transfer.cpu().data.item())\n\n            # reset the gradient\n            Optimizer_transfer.zero_grad()\n            # backpropagate the loss\n            loss_transfer.backward()\n            # update the parameters\n            Optimizer_transfer.step()\n\n            #######################################################\n            ###################### Validation #####################\n            #######################################################\n            # Set the model to evaluation mode so that parameters are fixed.\n            our_CNN_Transfer.eval()\n            \n            #Extract the batch validation images and validation labels from the validation loader\n            (image_validation_torch_transfer, label_validation_torch_transfer) = next(iter(validation_loader_transfer))\n\n            validation_label_predicted_transfer = our_CNN_Transfer(image_validation_torch_transfer)\n            \n            one_hot_label_validation_transfer = torch.nn.functional.one_hot(label_validation_torch_transfer.long(), num_classes=2).to(torch.float)\n\n            loss_transfer = Loss_transfer(validation_label_predicted_transfer, one_hot_label_validation_transfer) #Custom MSE loss function\n            validation_loss_transfer.append(loss_transfer.cpu().data.item())\n\n    train_epoch_loss_transfer.append(np.mean(train_loss_transfer))\n    validation_epoch_loss_transfer.append(np.mean(validation_loss_transfer))\n    \n    torch.save(our_CNN_Transfer.state_dict(), '.\/saved_models\/checkpoint_epoch_%s.pth' % (epoch))\n        \n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss_transfer[-1], validation_epoch_loss_transfer[-1]))","3d325f15":"# Our files","f72d28f8":"Our labels for this project correspond to NoROP or ROP. The data is thus split into to different classes","98968d43":"Here we just show the different files of the dataset used. This gives a list of pathways for each image. ","08f87d7c":"Since we changed our repartition from the visualization part, we once again look out for the data repartition between stages in each subset.","effa2bd6":"# Dataset visualization","93cff6cf":"**5. Sources**\n\nFor the creation of the dataset : https:\/\/medium.com\/analytics-vidhya\/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc\n","f7d78d2d":"The function below allows to build a list with the indexes within the set. ","d8315863":"# CNN definition","07cd7648":"2. Data Augmentation","ee19706c":"2. Quantitative visualization of the dataset, repartition of pictures\n","57728803":"Using the function above, we are able to count how much images of a particular label there are and thus display the number of images from each class, for every subset. ","cee90eab":"4. Training and validation","12a7cdc8":"Using the different images in the folder, named with the stage corresponding to the disease, we create a dataframe that will be used as our dataset for training, validation and testing.","1c129992":"We want to know **how many images we have, in total, and for each class (ROP\/NoROP).**","2a179ea7":"1. Hyperparameters","69d8de1a":"We choose a LeNet() model with two convolutional layers, and 3 dense fully connected layer + one dropout.","ca3ac88d":"To visualize this result we create a histogram graph.","217e61a5":"1. Image display for each classes","ce4ceb7f":"The repartition is fairly made here ","7808c647":"# Libraries","9e06c492":"Our dataset is verry small : 91 images. This isn't sufficient to have a good deep leanring algorithm that can have an interesting accuracy. Thus we are going to use data augmentation. \nFirst of all, Retinopathy of prematurity can develop in the left or in the right eye. The way it diagnosed is the same. The only thing changing is the overall structure of the image : th temporal view is either with the optic nerve on the right for right eye or with optic nerve on the left for left eye.  This is why we introduce horizontal flips in our dataaugmentation. Contrast, Luminosity, are also things that vary when pictures are taken. \n\nThe following transform function will be applied to the dataset and images will be modified randomly. ","9bcd3827":"# Creation of the dataset","fd6729bf":"The following commented code can be uncommented to get the name and file path of every images we have. ","85a937ac":"# Introduction\nOur Algorithm here aims at classifying babies'fundus into 2 different classes to determine wether the baby has developped ROP  or not. In this first part, our neural network classifies the pictures into 2 stages : No ROP, ROP. Then, these images are used to train a classifier. Finally we tried to use pre trained model. ","47cbbf8f":"3. Model definition","efabf366":"Here is the list the different libraries we are going to use and we import them.","a3bef281":"6. Testing","bc797625":"Here we are going to show what the dataset looks like with no image processing, data-augmentation. Here the data is split and processed only for vizualization purpose. ","164a0f23":"Here we chooe the MSE loss function : a widely used loss function in image classification. The optimizer is AdamOptimizer "}}