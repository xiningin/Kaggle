{"cell_type":{"bab6281d":"code","365199bb":"code","c124aa55":"code","1a83a950":"code","4cb178b3":"code","1cf4161f":"code","024da130":"code","9c931026":"code","d50df97b":"code","a30384aa":"code","a89d5466":"code","cfe4b167":"code","2879e2f2":"code","72c87dd6":"code","16e8d61d":"code","1ec50f1d":"code","1d597ef6":"code","5ff0d4dc":"code","408e6142":"code","b9a30892":"markdown","de0b2f1d":"markdown","baf3b8c3":"markdown","3c52c28a":"markdown","b1717ca8":"markdown","cd0a1120":"markdown","6cde60a8":"markdown","d6e0a8dc":"markdown"},"source":{"bab6281d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","365199bb":"## Most Important\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras import regularizers\n\n## less Important\nfrom functools import partial\nimport os\nfrom scipy import stats\nimport missingno as msno\nimport joblib\nimport tarfile\nimport shutil\nimport urllib\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\n\n## Sklearn\nfrom sklearn import datasets\n## Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\n\n## tensorflow & Keras\nimport tensorflow as tf    ## i will use tf for every thing and for keras using tf.keras","c124aa55":"train_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()","1a83a950":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","4cb178b3":"print('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\n\nprint()\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)","1cf4161f":"train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(train_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)","024da130":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.15, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","9c931026":"import cv2\nR_90_c = np.array([cv2.rotate(i, cv2.ROTATE_90_CLOCKWISE)  for i in train_full_set])\nR_90_cc= np.array([cv2.rotate(i, cv2.ROTATE_90_COUNTERCLOCKWISE)  for i in train_full_set])\nR_180 = np.array([cv2.rotate(i, cv2.ROTATE_180)  for i in train_full_set])\nh_f = np.array([cv2.flip(i, 1)  for i in train_full_set])\nv_f = np.array([cv2.flip(i, 0)  for i in train_full_set])\nV_f_r_180 = np.array([cv2.rotate(cv2.flip(i, 1), cv2.ROTATE_90_COUNTERCLOCKWISE)  for i in train_full_set])\nh_f_r_180 = np.array([cv2.rotate(cv2.flip(i, 1), cv2.ROTATE_90_CLOCKWISE)  for i in train_full_set])\nimport numpy\ntrain_full_set = numpy.concatenate((\n                train_full_set.reshape(13440, 32, 32, 3),\n                R_90_c,\n                R_90_cc,\n                R_180,\n                h_f,\n                v_f,\n                V_f_r_180,\n                h_f_r_180), \n          axis=0).reshape(107520, 32, 32, 3)\n\n# X_test = X_test.reshape(3360, 32, 32, 3)\n# y_train = np.repeat(y_train, 8 , axis=0)\n\na = [train_full_labels for i in range(8)]\ntrain_full_labels = numpy.concatenate(a)","d50df97b":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n    Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n    Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n    Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Flatten(),\n \n    # FC6 Fully Connected Layer\n    tf.keras.layers.Dense(units = 84, activation = 'relu'),\n    Dropout(0.3),\n    \n   \n    \n    #tf.keras.layers.GlobalAveragePooling2D(),\n    \n    tf.keras.layers.Dense(29, activation='softmax')\n \n])","a30384aa":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nearly_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","a89d5466":"history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=100, batch_size=32, callbacks=[early_stopp])","cfe4b167":"pd.DataFrame(history.history).plot(figsize=(10, 6));","2879e2f2":"loss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint('acc_all_data =>', acc_all_data)","72c87dd6":"test_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()","16e8d61d":"print('Number of Instances in test_set is', len(test_images_paths))","1ec50f1d":"test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)","1d597ef6":"predictions=model.predict(test_full_set)\npred = [np.argmax(i) for i in predictions]\ntest_labels['label']=pred","5ff0d4dc":"test_labels","408e6142":"test_labels[['id', 'label']].to_csv('\/kaggle\/working\/submission_new5.csv', index=False)","b9a30892":"## Evaluation on Testing DataSet","de0b2f1d":"`Only for training here`","baf3b8c3":"## Loading the Data and Look at the Big Picture","3c52c28a":"## Done :D","b1717ca8":"## Split the Data","cd0a1120":"## Explore the Data","6cde60a8":"## Model Training","d6e0a8dc":"## Data Preprocessing"}}