{"cell_type":{"889b5449":"code","06aa8ac2":"code","1de0d621":"code","2c2dd817":"code","eefa9f9d":"code","51d1a658":"code","f55b0b62":"code","853dd589":"code","2ebfc4fd":"code","15172c3c":"code","9b323cff":"code","b09ada01":"code","6f7cd9a1":"code","8ff65894":"code","41361d23":"code","bb7ff766":"code","2dbf72fa":"code","b5baf509":"code","4ab0a9fd":"code","2e546ee2":"code","66fa75b8":"code","27da0775":"code","ec25717d":"code","cd75e5a9":"code","8e6635dd":"code","c96336a3":"code","251b5edf":"code","d762e420":"code","32954d6b":"code","e5a15a28":"code","cfc6b3a2":"code","3d286dcc":"code","244ad512":"code","0e4ab33a":"code","75359f75":"code","12f73e81":"code","c7f306c1":"code","11f75a08":"code","3b54adff":"code","f28cd718":"code","ad34fc09":"code","f66d2e0f":"code","dbb4a404":"code","4bfb7204":"code","084ab43d":"code","2a49d4ee":"code","8fef9cbc":"code","00131298":"code","50f4a2c8":"code","85ab512d":"code","ba1bae6e":"code","ea666a56":"code","d9c338a6":"markdown","47a5bec5":"markdown","7b3ab5d7":"markdown","05b58c1a":"markdown","12c9884d":"markdown","76c62955":"markdown","6bfea234":"markdown","d0f05770":"markdown","d3eceb7d":"markdown","cc3674bb":"markdown","1157fe10":"markdown","45ddb5ec":"markdown","85e0854b":"markdown"},"source":{"889b5449":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06aa8ac2":"import re\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nimport missingno as miss\n\nfrom collections import Counter\n\nfrom nltk.corpus import stopwords #removes and, in, the, a ... etc\n\nimport plotly.express as px\n\nimport matplotlib.pyplot as plt\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","1de0d621":"FILEPATH = '\/kaggle\/input\/newyork-room-rentalads\/room-rental-ads.csv'","2c2dd817":"df = pd.read_csv(FILEPATH)","eefa9f9d":"df.head()","51d1a658":"df.sample(3)","f55b0b62":"df.info()","853dd589":"df.describe()","2ebfc4fd":"miss.matrix(df)","15172c3c":"miss.heatmap(df)","9b323cff":"miss.dendrogram(df)","b09ada01":"miss.bar(df)","6f7cd9a1":"# get the number of missing data points per column\nmissing_values_count = df.isnull().sum()\n\n# missing points in the first 10 \nmissing_values_count[0:10]","8ff65894":"def get_space(pre_content, total_space_count = 30):\n\n    current_space_count = total_space_count - len(pre_content)\n    \n    return pre_content + (\" \" * current_space_count)","41361d23":"def show_missing_percentage(current_df):\n    \n    total_cells = np.product(current_df.shape)\n    total_missing = missing_values_count.sum()\n    \n    total_space_count = 20\n\n    print(get_space(\"Total cells\", total_space_count)+\": {}\".format(total_cells))\n    print(get_space(\"Total missing cells\", total_space_count)+\": {}\".format(total_missing))\n\n    missing_percentage = (total_missing \/ total_cells)\n\n    print(get_space(\"Missing Percentage\", total_space_count)+\": {:.2%}\".format(missing_percentage))","bb7ff766":"show_missing_percentage(df)","2dbf72fa":"df.isnull().sum()","b5baf509":"df = df.dropna(axis = 0)","4ab0a9fd":"df.isnull().sum()","2e546ee2":"df.head()","66fa75b8":"df.isnull().sum()","27da0775":"df = df.rename(columns = {'Vague\/Not' : 'Low_Quality'})","ec25717d":"df.head()","cd75e5a9":"df['Low_Quality'] = df['Low_Quality'].astype('int32')","8e6635dd":"df.head()","c96336a3":"# df['new_col'] = range(1, len(df) + 1)\ndf = df.reset_index()","251b5edf":"df.head()","d762e420":"def show_donut_plot(col):\n    \n    cur_df = df\n    \n#     rating_data = cur_df.groupby(col)[['Complaint ID']].count().head(10)\n    rating_data = cur_df.groupby(col)[['index']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['index']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot - ' + str(col) + '', loc='center')\n    \n    plt.show()","32954d6b":"show_donut_plot('Low_Quality')","e5a15a28":"# Clean the data\ndef clean_text_simple(text):\n    text = text.lower()\n    text = re.sub(r'[^(a-zA-Z)\\s]','', text)\n    text = text.strip()\n    text = re.sub(\"\\n\", \"\", text)\n\n    return text","cfc6b3a2":"df['Description'] = df['Description'].apply(clean_text_simple)","3d286dcc":"df.head()","244ad512":"import spacy\n\nnlp = spacy.load('en_core_web_sm') ","0e4ab33a":"# Here we will remove noise in the string. \n# Sample noise: httpsyoutube, httpswwwyoutube, (string less than 3 characters)\ndef is_noise(content):\n    \n    if('httpsyoutube' in content or 'httpswwwyoutube' in content):\n        return True\n    \n    if(len(content) < 3):\n        return True\n    \n    return False\n    ","75359f75":"def get_NER(sentence):\n  \n    doc = nlp(sentence) \n    \n    ner_set = set()\n    \n    for ent in doc.ents: \n        # print(ent.text, ent.start_char, ent.end_char, ent.label_) \n        # print(ent.text)\n        \n        current_ner = str(ent.text)\n        \n        if(not is_noise(current_ner)):\n            ner_set.add(current_ner)\n    \n    return list(ner_set)","12f73e81":"df['NER'] = df['Description'].apply(get_NER)\ndf['NER_count'] = df['NER'].apply(lambda x: len(x))","c7f306c1":"df_sub = df[['NER', 'NER_count']][0:50]","11f75a08":"def highlight_max_custom(s, color = 'lightblue'):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: '+color if v else '' for v in is_max]","3b54adff":"df_sub.style.apply(highlight_max_custom, color = '#CFFE96',  axis = 0, subset=['NER_count'])","f28cd718":"stopwords1 = stopwords.words('english')\n\nwords_collection = Counter([item for sublist in df['NER'] for item in sublist if not item in stopwords1])\nfreq_word_df = pd.DataFrame(words_collection.most_common(30))\nfreq_word_df.columns = ['frequently_used_word','count']\n\n\nfreq_word_df.style.background_gradient(cmap='OrRd', low=0, high=0, axis=0, subset=None)\n\n# Possible color map values\n# 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds', 'YlOrBr', \n# 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu','GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']","ad34fc09":"# As we need to keep the pie chart clean, we are using only top 15 rows\nfreq_word_df_small = freq_word_df[0:15]","f66d2e0f":"fig = px.pie(freq_word_df_small, values='count', names='frequently_used_word', title='Rental ads - Frequently Used NER')\nfig.show()","dbb4a404":"# Define how much percent data you wanna split\nsplit_count = int(0.23 * len(df))","4bfb7204":"# Shuffles dataframe\ndf = df.sample(frac=1).reset_index(drop=True)\n\n# Training Sets\ntrain = df[split_count:]\ntrainX = train['Description']\ntrainY = train['Low_Quality'].values\n\n# Test Sets\ntest = df[:split_count]\ntestX = test['Description']\ntestY = test['Low_Quality'].values\n\nprint(f\"Training Data Shape: {testX.shape}\\nTest Data Shape: {testX.shape}\")","084ab43d":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Load the vectorizer, fit on training set, transform on test set\nvectorizer = TfidfVectorizer()\ntrainX = vectorizer.fit_transform(trainX)\ntestX = vectorizer.transform(testX)","2a49d4ee":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier()\ndt_model = dt_model.fit(trainX, trainY)","8fef9cbc":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier().fit(trainX, trainY)","00131298":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n\nknn_model = knn.fit(trainX, trainY)","50f4a2c8":"from sklearn.linear_model import LogisticRegression\n\nlor = LogisticRegression(solver = \"liblinear\")\nlor_model = lor.fit(trainX, trainY)","85ab512d":"models = [\n#     svm_model,\n    dt_model,\n    rf_model,\n    knn_model,\n    lor_model\n]","ba1bae6e":"best_model_accuracy = 0\nbest_model = None\n\nfor model in models:\n    \n    model_name = model.__class__.__name__\n    \n    predY = model.predict(testX)\n    accuracy = accuracy_score(testY, predY)\n    \n    print(\"-\" * 43)\n    print(model_name + \": \" )\n    \n    if(accuracy > best_model_accuracy):\n        best_model_accuracy = accuracy\n        best_model = model_name\n    \n    print(\"Accuracy: {:.2%}\".format(accuracy))","ea666a56":"print(\"Best Model : {}\".format(best_model))\nprint(\"Best Model Accuracy : {:.2%}\".format(best_model_accuracy))","d9c338a6":"Let's rename the column `Vague\/Not` to `Low_Quality`","47a5bec5":"## Visual Time","7b3ab5d7":"## Data Cleaning Process","05b58c1a":"Observation:\n\n* `manhattan` NER is used most in the rental ads.\n* `brooklyn` NER comes as a second most word.","12c9884d":"There are 20 null entries in the Dataset. Let's drop them we don't want them at the moment.","76c62955":"**To Do:**\n\n* Need to clean up the code with more feature engineering, etc.\n* Need to add more documentation\n* Need to come up with more visualization","6bfea234":"Let's change the data type of `Low_Quality` column from float to int","d0f05770":"Check for null values","d3eceb7d":"**Final Notes:**\n\nI am adding things still. You can come back and check for more information.\n\nAlso, if you **like my notebook**, <font style=\"color:blue;size:14px;\">please upvote it<\/font> as it will motivate me to come up with better approach in the upcoming notebooks.\n","cc3674bb":"### Visual on Null","1157fe10":"### Named Entity Recognition","45ddb5ec":"Let's introduce various models to the maximum accuracy","85e0854b":"<table style=\"font-family: 'Trebuchet MS', Arial, Helvetica, sans-serif;border-collapse: collapse;width: 100%;\">\n  <tr>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Notebook<\/th>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Tags<\/th>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/sof-questions-eda-and-visual\">SOF Questions - EDA and Visual<\/a> <\/td>\n    <td style=\"text-align: left\">Data Visual, Plotly<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/netflix-visualization-plotly-plots-treemap\">Netflix - Visualization, Plotly, Plots, and Treemap<\/a> <\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, Data Cleaning, Plotly<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/prediction-with-various-algorithms\">Prediction with various Algorithms<\/a> <\/td>\n    <td style=\"text-align: left\">Random Forest, Logistic Regression<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/eda-and-visualization\">EDA and Visualization<\/a> <\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Cleaning, Data Visual<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/job-analysis-eda-visual\">Job Analysis - EDA and Visual<\/a> <\/td>\n    <td style=\"text-align: left\">Data Visual, EDA, Plotly<\/td>\n  <\/tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/estonia-disaster-visualization\">Estonia Disaster - Visualization<\/a> <\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, EDA, Data Cleaning<\/td>\n  <\/tr>\n    \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/pandas-dundas-challenge-100\" >Pandas 100+ exercises collection<\/a><\/td>\n    <td style=\"text-align: left\">Pandas, Data Manipulation<\/td>\n  <\/tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/prediction-with-various-algorithms\">Credit Card Fraud - Prediction with various algorithms<\/a><\/td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Various ML Algorithms<\/td>\n  <\/tr>  \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https:\/\/www.kaggle.com\/rajacsp\/linear-equations-real-time\">Linear Equations - Real Time<\/a> <\/td>\n    <td style=\"text-align: left\">Linear Equation<\/td>\n  <\/tr>  \n<\/table>\n"}}