{"cell_type":{"43b3ed53":"code","557cd1c0":"code","544cfa6e":"code","ab5844a1":"code","0ee86a17":"code","5b68645d":"code","802b3d09":"code","7b18a916":"code","29da4044":"code","a8c6e759":"code","db6e5183":"code","9a86a638":"code","76467a7a":"code","64e4f6cf":"code","b910310f":"code","a5a46f15":"code","ca7afe84":"code","db6e7876":"code","7240abd8":"code","1aa46acf":"code","aca6c3c1":"code","1ef6f35f":"code","4a14d71c":"code","01b8c585":"code","84442ef7":"markdown","7c5f7a0b":"markdown","93861a7f":"markdown","c1955a76":"markdown","027cd276":"markdown","bb814018":"markdown","a17cf446":"markdown","89f5de6f":"markdown","3f930146":"markdown","d5ec5998":"markdown","1a664ffa":"markdown"},"source":{"43b3ed53":"# Import Libraries\nfrom pathlib import Path\nimport numpy as np \nimport pandas as pd\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import ensemble\nfrom sklearn import model_selection\nimport xgboost as xgb\nimport lightgbm as lgb","557cd1c0":"path = Path('\/kaggle\/input\/tabular-playground-series-aug-2021')","544cfa6e":"list(path.iterdir())","ab5844a1":"train = pd.read_csv(f'{path}\/train.csv')\ntest = pd.read_csv(f'{path}\/test.csv')\nsample = pd.read_csv(f'{path}\/sample_submission.csv')","0ee86a17":"def rmse(y, pred): return round(np.sqrt(metrics.mean_squared_error(y, pred)), 6)","5b68645d":"def mfe(model, xtrain, ytrain, xval, yval):\n    model.fit(xtrain, ytrain)\n    preds_train = model.predict(xtrain)\n    preds_val = model.predict(xval)\n    print(f'RMSE Train: {rmse(ytrain, preds_train)} RMSE Valid: {rmse(yval, preds_val)}')","802b3d09":"def submit(model, data, fname=None):\n    preds = model.predict(data.loc[:, feats])\n    df_preds = pd.DataFrame({'id': data.id.values, 'loss': preds})\n    df_preds.to_csv(fname, index=False)\n    return 'Predictions exported to csv'","7b18a916":"train.head(3)","29da4044":"train.info()","a8c6e759":"train.isnull().sum().any()","db6e5183":"# Set up data set for splitting\nkey = ['id']\nfeats = [col for col in train.columns if col.startswith('f')]; len(feats)\ntarget = ['loss']\nX = train.loc[:, feats]\ny = train.loc[:, target].values.flatten()\nprint(X.shape, y.shape)","9a86a638":"# Prepare train and validation dataset\nxtrain, xval, ytrain, yval = model_selection.train_test_split(X, y, test_size=.25, random_state=42, shuffle=True)","76467a7a":"xtrain.shape, xval.shape, ytrain.shape, yval.shape","64e4f6cf":"# Compelete dataset to be used to training before submission.\nx_all =  train.loc[:, feats]\ny_all = train.loc[:, target].values.flatten()","b910310f":"rf = ensemble.RandomForestRegressor(\n    n_estimators=40, \n    max_depth=8, \n    min_samples_split=2, \n    min_samples_leaf=5, \n    max_features='auto', \n    max_leaf_nodes=None, \n    max_samples=None, \n    n_jobs=-1, \n    random_state=42)","a5a46f15":"# %%time\n# mfe(rf, xtrain, ytrain, xval, yval)","ca7afe84":"#submit(rf, test, fname='sub1.csv')","db6e7876":"# Define the train, validation and test Dmatrix objects.\ndtrain = xgb.DMatrix(xtrain, label=ytrain)\ndval = xgb.DMatrix(xval, label=yval)\ndtest = xgb.DMatrix(test[feats])","7240abd8":"# Define the model params.\nparams = {\n    'eta': 0.05,\n    'gamma': 1,\n    'max_depth':6 ,\n    'min_child_weight': 8,\n    'subsample': 1,\n    'colsample_bytree': 0.8,\n    'colsample_bylevel': 0.8,\n    'colsample_bynode': 1, \n    'lambda': 1,\n    'alpha': 1,\n    'tree_method': 'exact',\n    'objective': 'reg:squarederror',\n    'eval_metric':'rmse',\n    'seed': 42\n} ","1aa46acf":"%%time\nm = xgb.train(\n    params, \n    dtrain, \n    num_boost_round = 1000, \n    evals = [(dtrain, 'train'), (dval, 'val')], # List of validation sets for which metrics will evaluated during training\n    early_stopping_rounds = 30,\n    verbose_eval = 50\n)","aca6c3c1":"'''\n%%time\nm2 = xgb.train(\n    params, \n    dtrain, \n    num_boost_round = 345, \n    evals = [(dtrain, 'train'), (dval, 'val')], # List of validation sets for which metrics will evaluated during training\n    early_stopping_rounds = 30,\n    verbose_eval = 50\n)\n'''","1ef6f35f":"# submit predictions\npreds = m.predict(dtest)\ndf_preds = pd.DataFrame({'id': test.id.values, 'loss': preds})\ndf_preds.to_csv('xgb2.csv', index=False)","4a14d71c":"m3 = xgb.XGBRegressor(\n    n_estimators = 100,\n    learning_rate = 0.1,\n    max_depth = 6,\n    gamma = 0,\n    min_child_weight = 7,\n    max_delta_step = 0,\n    subsample = 1,\n    colsample_bytree = 1,\n    colsample_bylevel = 1,\n    reg_alpha = 1,\n    reg_lambda = 1,\n    objective = 'reg:squarederror',\n    n_jobs = -1,\n    random_state = 42)","01b8c585":"'''\nm3.fit(\n    xtrain, ytrain,\n    eval_set = [(xtrain, ytrain), (xval, yval)],\n    eval_metric = 'rmse',\n    early_stopping_rounds = 10,\n    verbose = 10)\n'''","84442ef7":"## Scikit Learn API","7c5f7a0b":"# Data Splitting","93861a7f":"# Read Data","c1955a76":"# EDA","027cd276":"# LightGBM","bb814018":"# Random Forest","a17cf446":"### [Competition Link](https:\/\/www.kaggle.com\/c\/tabular-playground-series-aug-2021)","89f5de6f":"## Native API","3f930146":"# Utility Code","d5ec5998":"# Import Libraries","1a664ffa":"# XGBoost"}}