{"cell_type":{"e0a432fb":"code","331acac4":"code","e06f9dcb":"code","eb37ef69":"code","4116f1f6":"code","8a0329e0":"code","11dd3522":"code","e261e967":"code","e278b18a":"code","44060245":"code","1174f27b":"code","3f5bb4d4":"code","9c0f8acc":"code","c5dbe55c":"code","d7482643":"code","de6ed2c2":"code","a97cc9d9":"code","fdceebbc":"code","b662ff9b":"code","2321454c":"code","4b2a508d":"code","34476405":"code","d842f645":"code","1e50e621":"code","3d22a4a5":"code","c13fe9dc":"code","83b896e6":"code","11b10c91":"code","aa3d1a37":"code","6c4d00e0":"code","6812dc7c":"code","05057966":"code","a03a7b4f":"code","6f636280":"code","f23a655a":"code","fc3126fb":"code","3f635dd2":"code","b0d0e067":"markdown","c9ed273c":"markdown","6dde4097":"markdown","0580742c":"markdown","8f632999":"markdown","421d1798":"markdown","886d61e4":"markdown","eccb37f3":"markdown","786ab479":"markdown","2f1cd356":"markdown","2193dc92":"markdown","383f8a8b":"markdown","9a81f67d":"markdown","92ea86d5":"markdown","61fe1b8c":"markdown","9b23fdfa":"markdown","b60bd0aa":"markdown","3acd668f":"markdown"},"source":{"e0a432fb":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D, Dropout, BatchNormalization","331acac4":"tf.__version__","e06f9dcb":"# Load Fashion MNIST dataset\nfrom tensorflow.keras.datasets import fashion_mnist\n","eb37ef69":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()","4116f1f6":"# Normalizing the input data\ntrain_images = train_images\/255.0\ntest_images = test_images\/255.0","8a0329e0":"# Let's check the shape of the dataset\ntrain_images.shape, test_images.shape, train_labels.shape, test_labels.shape","11dd3522":"train_images[0].shape","e261e967":"# Train validation set split\n\ntotal_len=len(train_images)\ntrain_len=int(0.90*total_len)\ntrain_len","e278b18a":"train_images_new=train_images[:train_len]\ntrain_labels_new=train_labels[:train_len]\nval_images=train_images[train_len:]\nval_labels=train_labels[train_len:]","44060245":"class_names=[\n    'T-shirt\/top',\n    'Trouser',\n    'Pullover',\n    'Dress',\n    'Coat',\n    'Sandal',\n    'Shirt',\n    'Sneaker',\n    'Bag',\n    'Ankle boot'\n]","1174f27b":"# total classes\nlen(class_names)","3f5bb4d4":"# Let's see one random image and it's label\ninx=np.random.choice(train_images.shape[0])\ninx","9c0f8acc":"plt.figure(figsize=(8,4))\nplt.imshow(train_images[inx])\nplt.axis('off')\nplt.show()\n\nprint(f'The class of the above image is {class_names[train_labels[inx]]}')","c5dbe55c":"plt.figure(figsize=(12,6))\nsns.heatmap(train_images[inx], annot=True)","d7482643":"model1=Sequential(\n    [Flatten(input_shape=(28,28), name='flatten'),\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(64, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(10, activation='softmax')])","de6ed2c2":"model1.summary()","a97cc9d9":"train_images_new.shape, train_labels_new.shape, val_images.shape, val_labels.shape","fdceebbc":"model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n","b662ff9b":"history=model1.fit(train_images_new, train_labels_new, validation_data= (val_images, val_labels), epochs=50, batch_size=64, verbose=2) ","2321454c":"model1.evaluate(test_images, test_labels)","4b2a508d":"df1=pd.DataFrame(history.history)","34476405":"# Plotting Accuracy\n\nplt.figure(figsize=(8,5))\ndf1[['accuracy', 'val_accuracy']].plot()\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","d842f645":"plt.figure(figsize=(8,5))\ndf1[['loss', 'val_loss']].plot()\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","1e50e621":"x=train_images[..., np.newaxis]\nx[0].shape","3d22a4a5":"model2=Sequential()\nmodel2.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=(28,28,1), activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\nmodel2.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\nmodel2.add(BatchNormalization())\nmodel2.add(Flatten())\nmodel2.add(Dense(64, activation='relu'))\nmodel2.add(Dropout(0.4))\nmodel2.add(Dense(32, activation='relu'))\nmodel2.add(Dense(10, activation='softmax'))","c13fe9dc":"model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","83b896e6":"history2=model2.fit(train_images_new[..., np.newaxis], train_labels_new, validation_data= (val_images[..., np.newaxis], val_labels), epochs=20, batch_size=64, verbose=2) ","11b10c91":"model2.evaluate(test_images[..., np.newaxis], test_labels, verbose=2)","aa3d1a37":"df2=pd.DataFrame(history2.history)","6c4d00e0":"# Plotting Accuracy\n\nplt.figure(figsize=(8,5))\ndf2[['accuracy', 'val_accuracy']].plot()\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","6812dc7c":"plt.figure(figsize=(8,5))\ndf2[['loss', 'val_loss']].plot()\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","05057966":"# A random number to select the image from the test set\nrandom_inx=np.random.choice(test_images.shape[0])\ntest_image=test_images[random_inx]","a03a7b4f":"plt.imshow(test_image)\nplt.axis('off')\nplt.show()","6f636280":"# Now let's run the prediction on the above image. Note that model expects shape of batchsize*pixel*pixel*dim hence\n# total 4 dimensions but our test image is only of 2 dimensions, hence we need to add a dummy axis both at the beginning and at the end\n\nprediction1= model1.predict(test_image[np.newaxis,...,np.newaxis])\n","f23a655a":"print(f' Predicted class for the above image is -> {class_names[np.argmax(prediction1)]}')\nprint(f' Actual class for the above image is -> {class_names[test_labels[random_inx]]}')","fc3126fb":"prediction2= model2.predict(test_image[np.newaxis,...,np.newaxis])","3f635dd2":"print(f' Predicted class for the above image is -> {class_names[np.argmax(prediction2)]}')\nprint(f' Actual class for the above image is -> {class_names[test_labels[random_inx]]}')","b0d0e067":"Accuracy on the test set is 88.6% as shown above","c9ed273c":"## Model1 prediction:","6dde4097":"## Importing required libraries","0580742c":"## Importing FashionMNIST dataset","8f632999":"### Taking out validation set from the train set","421d1798":"# MODELING WITHOUT CONVOLUTION NEURAL NETWORK","886d61e4":"## Data Preprocessing","eccb37f3":"## As it can be seen above, model with convolution layer gave higher accuracy even with lower Epochs.","786ab479":"## Evaluating model on the test set","2f1cd356":"## Plotting Accuracy & Loss of both train and validation set","2193dc92":"# Predictions on a random image with both model1 and model2","383f8a8b":"# MODELING WITH CONVOLUTION NEURAL NETWORKS","9a81f67d":"## Both the predictions are accurate.","92ea86d5":"# This notebook is to demonstrate working classification model with TF2.0 \/ Keras and benchmarking of the model with and without convolution neural network.","61fe1b8c":"## Evaluating model on the test set","9b23fdfa":"## Visualization a random image with it's class label","b60bd0aa":"## Model2 prediction:","3acd668f":"## Plotting Accuracy & Loss of both train and validation set"}}