{"cell_type":{"c256f930":"code","016c6d8c":"code","4eea4133":"code","bd8b4048":"code","0fd24784":"code","22074a48":"code","9d5dd3d2":"code","7f1439b6":"code","0567247d":"code","991be184":"code","f1ffd1ff":"code","caa1937a":"code","da1e5e78":"code","17d9e9dd":"code","5e1b9ed2":"code","2609f85c":"code","107dbfec":"code","877a5ea9":"code","87f22302":"code","e98eecff":"code","0342a79e":"markdown","2d656ca5":"markdown","d8e0817f":"markdown"},"source":{"c256f930":"# import libs \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# machine learning \nimport sklearn\nfrom sklearn import preprocessing\nfrom scipy.stats import pearsonr\n\n# machine learning  - supervised\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# machine learning  - unsupervised\nfrom sklearn import decomposition\nfrom sklearn.cluster import KMeans \nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import adjusted_rand_score\n\n# visualization and plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","016c6d8c":"df = pd.read_csv('..\/input\/indian_liver_patient.csv')\ndf.shape","4eea4133":"# general information about dataset\ndf.info()","bd8b4048":"# let's look on first entries in the data\ndf.head(3)","0fd24784":"# let's look on target variable - classes imbalanced?\ndf['Dataset'].value_counts()","22074a48":"# what are the missing values? \ndf[df[\"Albumin_and_Globulin_Ratio\"].isnull()]","9d5dd3d2":"# fill with median\/mean\/max\/min or ?\ndf.Albumin_and_Globulin_Ratio.fillna(df['Albumin_and_Globulin_Ratio'].median(), inplace=True)","7f1439b6":"# encode gender\nle = preprocessing.LabelEncoder()\nle.fit(df.Gender.unique())\ndf['Gender_Encoded'] = le.transform(df.Gender)\ndf.drop(['Gender'], axis=1, inplace=True)","0567247d":"# correlation plots\ng = sns.jointplot(\"Total_Bilirubin\", \"Direct_Bilirubin\", data=df, kind=\"reg\")","991be184":"# calculate correlation coefficients for two variables\nprint(pearsonr(df['Total_Bilirubin'], df['Direct_Bilirubin']))","f1ffd1ff":"# calculate correlation coefficients for all dataset\ncorrelations = df.corr()\n\n# and visualize\nplt.figure(figsize=(10, 10))\ng = sns.heatmap(correlations, cbar = True, square = True, annot=True, fmt= '.2f', annot_kws={'size': 10})\n\n# based on correlation, you can exclude some highly correlated features","caa1937a":"# pair grid allows to visualize multi-dimensional datasets\ng = sns.PairGrid(df, hue=\"Dataset\", vars=['Age','Gender_Encoded','Total_Bilirubin','Total_Protiens'])\ng.map(plt.scatter)\nplt.show()","da1e5e78":"# prepare train and test set\nX = df[['Age', 'Total_Bilirubin', 'Direct_Bilirubin', 'Alkaline_Phosphotase',\n        'Alamine_Aminotransferase', 'Aspartate_Aminotransferase', 'Total_Protiens', \n        'Albumin', 'Albumin_and_Globulin_Ratio','Gender_Encoded']]\ny = df[['Dataset']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\nprint (X_train.shape, y_train.shape, X_test.shape, y_test.shape)","17d9e9dd":"# let's try random forest on the data\nrf = RandomForestClassifier(n_estimators=25, random_state=2018)\nrf.fit(X_train, y_train)\nrf_predicted = rf.predict(X_test)\n\nrandom_forest_score      = round(rf.score(X_train, y_train) * 100, 2)\nrandom_forest_score_test = round(rf.score(X_test, y_test) * 100, 2)\n\nprint('Random Forest Score: ', random_forest_score)\nprint('Random Forest Test Score: ', random_forest_score_test)\nprint('Accuracy: ', accuracy_score(y_test,rf_predicted))\nprint('\\nClassification report: \\n', classification_report(y_test,rf_predicted))\n\ng = sns.heatmap(confusion_matrix(y_test,rf_predicted), annot=True, fmt=\"d\")","5e1b9ed2":"# perform PCA for dataset to simplify visualizations\npca = decomposition.PCA(n_components=2)\npca.fit(X)\nX_decomposed = pca.transform(X)","2609f85c":"plt.figure( figsize=(10,5))\nplt.scatter(X_decomposed[:,0], X_decomposed[:,1], c=y.values.ravel(), edgecolor='black', s=100)\nplt.show()","107dbfec":"# predict kmeans\nkmeans = KMeans(n_clusters=2)\npred_kmeans = kmeans.fit_predict(X_decomposed)\n\n# predict gmm\ngmm = GaussianMixture(n_components=2).fit(X_decomposed)\ngmm = gmm.fit(X)\npred_gmm = gmm.predict(X)","877a5ea9":"print('Adjusted Rand Score:', adjusted_rand_score(y.values.ravel(), pred_kmeans))\nplt.figure( figsize=(10,5))\nplt.scatter(X_decomposed[:,0], X_decomposed[:,1], c=pred_kmeans, edgecolor='black', s=100)\nplt.show()\n\nprint('Adjusted Rand Score:', adjusted_rand_score(y.values.ravel(), pred_gmm))\nplt.figure( figsize=(10,5))\nplt.scatter(X_decomposed[:,0], X_decomposed[:,1], c=pred_gmm, edgecolor='black', s=100)\nplt.show()","87f22302":"# use all features now\n\n# predict kmeans\nkmeans = KMeans(n_clusters=2)\npred_kmeans = kmeans.fit_predict(X)\n\n# predict gmm\ngmm = GaussianMixture(n_components=2).fit(X)\ngmm = gmm.fit(X)\npred_gmm = gmm.predict(X)","e98eecff":"print('Adjusted Rand Score', adjusted_rand_score(y.values.ravel(), pred_kmeans))\nprint('Adjusted Rand Score', adjusted_rand_score(y.values.ravel(), pred_gmm))","0342a79e":"## Modeling Unsupervised","2d656ca5":"## Load\/Understand Data","d8e0817f":" ## Modeling Supervised"}}