{"cell_type":{"33ccc09d":"code","1a30eb0c":"code","931d0a77":"code","def413e6":"code","483e3265":"code","bd213135":"code","a62aafef":"code","13ea1027":"code","1e6348eb":"code","e74b747c":"code","7a08ad0c":"code","a5a46ff1":"code","aad1450b":"code","ef509777":"code","8391748a":"code","0473acb9":"code","cd484dd6":"code","904fc110":"code","f5a82bc2":"code","577aadca":"code","ccd6e9d1":"code","56045232":"code","c7287a8f":"markdown","ec02a1ca":"markdown","0850d308":"markdown","95317407":"markdown","95f58be8":"markdown","c9cfc5de":"markdown","8b0369b7":"markdown","c3a6e323":"markdown","1b389fd0":"markdown"},"source":{"33ccc09d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","1a30eb0c":"%tensorflow_version 2.x\nfrom tensorflow import keras","931d0a77":"import tensorflow as tf","def413e6":"tf.__version__","483e3265":"from keras.datasets import cifar10","bd213135":"# load dataset\n(trainX, trainy), (testX, testy) = cifar10.load_data()","a62aafef":"# summarize loaded dataset\nprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\nprint('Test: X=%s, y=%s' % (testX.shape, testy.shape))","13ea1027":"# plot first few images\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(331 + i)\n\t# plot raw pixel data\n\tplt.imshow(trainX[i])","1e6348eb":"trainX[10:20,10:20,10:20]","e74b747c":"trainX[1,1:5,1:5,:]","7a08ad0c":"# convert from integers to floats\n#train_norm = trainX.astype('float32')\n#test_norm = testX.astype('float32')\n# normalize to range 0-1\ntrain_norm = trainX \/ 255.0\ntest_norm = testX \/ 255.0","a5a46ff1":"# one hot encode target values\nfrom keras.utils import to_categorical\ntrainy = to_categorical(trainy)\ntesty = to_categorical(testy)","aad1450b":"testy[1]","ef509777":"trainy[:5]","8391748a":"from keras import models\nfrom keras.models import Sequential\nfrom keras import layers","0473acb9":"from keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","cd484dd6":"import keras","904fc110":"model = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(32, (5, 5), activation='relu', padding='same', input_shape=(32, 32, 3)))  \nmodel.add(keras.layers.MaxPooling2D((2, 2)))                                                            \nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))                           \nmodel.add(keras.layers.MaxPooling2D((2, 2)))                                                            \nmodel.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))  \nmodel.add(keras.layers.MaxPooling2D((2, 2)))     \nmodel.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))  \nmodel.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))  \nmodel.add(keras.layers.Flatten())                                                                   \nmodel.add(keras.layers.Dense(256, activation='relu',kernel_initializer=\"he_normal\"))\nmodel.add(Dropout(0.25))\nmodel.add(keras.layers.Dense(128, activation='relu',kernel_initializer=\"he_normal\")) \nmodel.add(Dropout(0.25))\nmodel.add(keras.layers.Dense(10, activation='softmax')) \n                                                ","f5a82bc2":"model.summary()","577aadca":"model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])","ccd6e9d1":"# fit model\ncallback=keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=3)\nhistory=model.fit(train_norm, trainy, epochs=20, batch_size=512, validation_data=(test_norm, testy),callbacks=[callback])\n","56045232":"# evaluate model\nloss, acc = model.evaluate(test_norm, testy)\nprint('Test Loss : ', loss)\nprint('Test Accuracy:', acc)","c7287a8f":"<p><h3><font color= 'DarkBlue'><b> Visualizing first nine samples in Train dataset <\/b><\/font><\/h3><\/p>\n\nA plot of the first nine images in the dataset is also created. It is clear that the images are indeed very small compared to modern photographs; it can be challenging to see what exactly is represented in some of the images given the extremely low resolution.\n\nThis low resolution is likely the cause of the limited performance that top-of-the-line algorithms are able to achieve on the dataset.","ec02a1ca":"<p><h3><b><font color = 'DarkBlue'> Loading the CIFAR-10 dataset in Keras <\/font><\/b><\/h3><\/p>\n\n# CIFAR-10 Photo Classification Dataset\nCIFAR is an acronym that stands for the Canadian Institute For Advanced Research and the CIFAR-10 dataset was developed along with the CIFAR-100 dataset by researchers at the CIFAR institute.\n\nThe dataset is comprised of 60,000 32\u00d732 pixel color photographs of objects from 10 classes, such as frogs, birds, cats, ships, etc. The class labels and their standard associated integer values are listed below.\n\n0: airplane <br>\n1: automobile <br>\n2: bird <br>\n3: cat <br>\n4: deer <br>\n5: dog <br>\n6: frog <br>\n7: horse <br>\n8: ship <br>\n9: truck <br>\nThese are very small images, much smaller than a typical photograph, and the dataset was intended for computer vision research.\n\nCIFAR-10 is a well-understood dataset and widely used for benchmarking computer vision algorithms in the field of machine learning. The problem is \u201csolved.\u201d It is relatively straightforward to achieve 80% classification accuracy. Top performance on the problem is achieved by deep learning convolutional neural networks with a classification accuracy above 90% on the test dataset.","0850d308":"<p><h3><font color= 'DarkBlue'><b> Preparing Test Data <\/b><\/font><\/h3><\/p>\n\nWe also know that there are 10 classes and that classes are represented as unique integers.\n\nWe can, therefore, use a one hot encoding for the class element of each sample, transforming the integer into a 10 element binary vector with a 1 for the index of the class value. We can achieve this with the to_categorical() utility function.","95317407":"<p><h3><b><font color = 'DarkBlue'> Compile the model <\/font><\/b><\/h3><\/p>\n\n","95f58be8":"<p><h3><b><font color = 'DarkBlue'> Evaluate the model  <\/font><\/b><\/h3><\/p>\n\nOnce the model is fit, we can evaluate it directly on the test dataset.","c9cfc5de":"<p><h3><font color= 'DarkBlue'><b> Preparing Train Data <\/b><\/font><\/h3><\/p>\nWe know that the pixel values for each image in the dataset are unsigned integers in the range between no color and full color, or 0 and 255.\n\nWe do not know the best way to scale the pixel values for modeling, but we know that some scaling will be required.\n\nA good starting point is to normalize the pixel values, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value.","8b0369b7":"We can see that there are 50,000 examples in the training dataset and 10,000 in the test dataset and that images are indeed square with 32\u00d732 pixels and color, with three channels.","c3a6e323":"<p><h3><b><font color = 'DarkBlue'> Building a CNN Architecture <\/font><\/b><\/h3><\/p>\n\n","1b389fd0":"<p><h3><b><font color = 'DarkBlue'> Fit the model with train data  <\/font><\/b><\/h3><\/p>\n\n"}}