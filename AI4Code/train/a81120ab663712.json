{"cell_type":{"d596bb69":"code","e5d8b0a1":"code","917b705b":"code","a7d1d14f":"code","a888c3f6":"code","0ff06f83":"code","bfb1beee":"code","d0cdcd6d":"code","a3a054c2":"code","6bf305d2":"code","6cd1f07f":"code","361fe252":"code","b92d01d4":"code","81890187":"code","558f76a9":"code","8ae76448":"code","6d1ebc6f":"markdown","c62ed94f":"markdown","8e4d73e2":"markdown","6b412a0d":"markdown","3ec4e5cc":"markdown","27cfcf05":"markdown"},"source":{"d596bb69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","e5d8b0a1":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom imblearn.over_sampling import ADASYN\n\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.model_selection import cross_val_predict,cross_validate\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import make_scorer\n\nfrom sklearn.pipeline import make_pipeline\n\n","917b705b":"# Input raw data\ntelcom=pd.read_csv(\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","a7d1d14f":"#checking missing data\ntelcom['TotalCharges']=telcom['TotalCharges'].convert_objects(convert_numeric=True)\ntelcom[\"TotalCharges\"].dtypes\n#drop missing data\ntelcom.dropna(inplace=True)","a888c3f6":"#find features and the values of target variable\nfeature_names=telcom.iloc[:,1:].columns\n#select values of target variable - 2-class categorical data\nlabels=telcom.iloc[:,20]\n\n#encoding target variable\nle=LabelEncoder()\nle.fit(labels)\nlabels=le.transform(labels)\nclass_names=le.classes_\ntelcom=telcom.iloc[:,1:-1]\n","0ff06f83":"#check independent features which data value in categorical type\nobj_features=telcom.select_dtypes(['object']).columns\ncategorical_features=[telcom.columns.get_loc(c) for c in obj_features]","bfb1beee":"#encoding categorical data of those features\ncategorical_names = {}\nfor feature in categorical_features:\n    le = LabelEncoder()\n    le.fit(telcom.iloc[:, feature])\n    telcom.iloc[:, feature] = le.transform(telcom.iloc[:, feature])\n    categorical_names[feature] = le.classes_","d0cdcd6d":"#one-hot-encoding on categorical_features\nencoder = OneHotEncoder(categorical_features=categorical_features)\nencoder.fit(telcom)","a3a054c2":"#set all data type to float\ntelcom=telcom.astype(float)","6bf305d2":"X=telcom\ny=labels\n\n#Split train\/test sets of X and y\nnp.random.seed(1)\nsss=StratifiedShuffleSplit(n_splits=5, test_size=0.2,random_state=0)\nsss.get_n_splits(X,y)\n\n#Training\/Testing sets in 5 folds\nfor train_index, test_index in sss.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)","6cd1f07f":"ada= ADASYN()","361fe252":"accuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor train_index, test_index in sss.split(X, y):\n    X_train,X_test=X.iloc[train_index], X.iloc[test_index]\n    y_train,y_test=y[train_index], y[test_index]\n\n    ### One-hot-encoding training\/testing data\n    encoded_train, encoded_test = encoder.transform(X_train), encoder.transform(X_test)\n    \n    ### Oversampling training sets\n    X_resample,y_resample=ada.fit_sample(encoded_train,y_train)\n    \n    ### Model training\n    lr=LogisticRegression()\n    lr.fit(X_resample, y_resample)\n    \n    ### Make Prediction\n    y_pred = lr.predict(encoded_test)\n    \n    ### Performance evaluation\n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))\n    \nprint(\"----------------- Performance Evaluation -----------------\")\nprint('Accuracy', np.mean(accuracy_scores))\nprint('Precision', np.mean(precision_scores))\nprint('Recall', np.mean(recall_scores))\nprint('F1-measure', np.mean(f1_scores)) ","b92d01d4":"predict_fn = lambda x: lr.predict_proba(encoder.transform(x)).astype(float)","81890187":"import lime\nimport lime.lime_tabular\nfrom __future__ import print_function","558f76a9":"#implement LIME interpretation\nexplainer = lime.lime_tabular.LimeTabularExplainer(\n    X_train.values,feature_names = feature_names,\n    class_names=class_names,categorical_features=categorical_features, \n    categorical_names=categorical_names, kernel_width=3\n)","8ae76448":"#visualise LIME interpretation\nnp.random.seed(1)\ni = int(np.random.randint(0,1407,size=1))\nexp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\nexp.show_in_notebook(show_all=False)","6d1ebc6f":"# Data Preprocessing","c62ed94f":"# Feature Engineering : One-Hot-Encoding","8e4d73e2":"# Model training & Performance evaluation","6b412a0d":"# Oversampling training data","3ec4e5cc":"# Stratified CV - Spliting Traning\/Testing sets","27cfcf05":"# LIME interpretability"}}