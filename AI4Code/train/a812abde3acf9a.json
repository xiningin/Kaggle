{"cell_type":{"be8e8f16":"code","e83f6b75":"code","ec54b0c7":"code","0ab85c18":"code","b2b4ee80":"code","7537c11c":"code","5508d7af":"code","e27f09b8":"code","3f619421":"code","4391b1ee":"code","c9d723a9":"code","13d16940":"code","b2081057":"code","4c40cd08":"code","1b4ce674":"code","135d77ae":"code","414d1db6":"code","ae8eab66":"markdown","c09c8fe9":"markdown"},"source":{"be8e8f16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e83f6b75":"df = pd.read_csv('..\/input\/anime-recommendations-database\/anime.csv')\ndf2 = pd.read_csv('..\/input\/anime-recommendations-database\/rating.csv')\n# Its a snowflake data schemea just to reduce the overhead of analytics part\ndata = pd.merge(df,df2,on='anime_id')\ndata.head()","ec54b0c7":"data.drop(['rating_x','episodes'],axis=1)\n# sns.countplot(y=\"type\",data=data)\ndata=data[data['type'] != 'Music']\ndata1=data[data['type'] != 'ONA']\n# sns.countplot(y=\"type\",data=data1)\ndata_movie = data1[data1['type'] == 'Movie']\ndata_tv = data1[data1['type'] != 'TV']\ndata_special = data1[data1['type'] != 'Special']\ndata_movie.head()","0ab85c18":"# lets make a new columns for the average rating including the imdb and customer rating.\ndata_movie[\"Average_rating\"] = (data_movie['rating_x'] + data_movie['rating_y'])\/\/2\ndata_movie\n# newd=data_movie.['rating_y']\n# (data_movie.groupby(\"name\")['rating_y']+data_movie.groupby(\"name\")['rating_x']).mean().sort_values(ascending=False)","b2b4ee80":"data_movie.groupby(\"name\")['Average_rating'].count().sort_values(ascending=False)\nfinal=pd.DataFrame(data_movie.groupby(\"name\")['Average_rating'].mean().sort_values(ascending=False))\nfinal['no_of_ratings'] = data_movie.groupby(\"name\")['rating_y'].count().sort_values(ascending=False)","7537c11c":"# After combing the rating of the user and the original.. Our Data is more compact and clean now\nfinal.head()\n# most of the ratings lies between the range 4.5-8","5508d7af":"sns.scatterplot(y='no_of_ratings',x='Average_rating',data=final)","e27f09b8":"final['no_of_ratings'].hist(bins=14)","3f619421":"final['Average_rating'].hist(bins=14)\n# Data is not normally distributed, but we are getting what we needed. ","4391b1ee":"final.no_of_ratings.sort_values(ascending=False)","c9d723a9":"final.head()","13d16940":"# making a pivot table to get the matrix form\n# of our data on the basis of mv name,user id and their rating\nmov_pivot = data_movie.pivot_table(index='user_id',columns='name',values='Average_rating')\nmov_pivot","b2081057":"final.sort_values('Average_rating',ascending = False).head()","4c40cd08":"Kimi = mov_pivot['Kimi no Na wa.']\n# Nan_Value=73515 - Kimi.isnull().sum()\nsecond = mov_pivot['Ookami Kodomo no Ame to Yuki']\n# second.isnull().sum()","1b4ce674":"SimilarToKimi=mov_pivot.corrwith(Kimi)\ncorr_kimi = pd.DataFrame(SimilarToKimi,columns=['correlation'])\n# corr_kimi.iloc[:,0].values\ncorr_kimi['correlation']=corr_kimi['correlation'].fillna(0)\ncorr_kimi = corr_kimi[corr_kimi['correlation']!=0.000000]\n# corr_kimi.sort_values('correlation',ascending=False).head(5)","135d77ae":"# what if its all one user ratings\ncorr_kimi = corr_kimi.join(final['no_of_ratings'])\ncorr_kimi","414d1db6":"# getiing genuine results by filtering on the basis of no of ratings\ncorr_kimi=corr_kimi[corr_kimi['no_of_ratings'] > 1000]\ncorr_kimi.sort_values('correlation',ascending=False).head(5)","ae8eab66":"Recommendation System","c09c8fe9":"Note: All the series are verifed by me and trust me, They are really correlated. Wynkk"}}