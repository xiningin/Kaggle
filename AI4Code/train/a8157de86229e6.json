{"cell_type":{"e421cbe2":"code","de5ce89a":"code","503ccce2":"code","6ffd0e8c":"code","0ead8ed3":"code","bf0bb12f":"code","4dd6c035":"code","8b68cbb2":"code","e152ce60":"markdown","e6ae99b4":"markdown","745a5368":"markdown","331dbb22":"markdown","b6f6b763":"markdown","a1505781":"markdown","452c5ffa":"markdown","f2713072":"markdown","a4bacf71":"markdown","dae338bb":"markdown","5fc7751c":"markdown","5f7b8a6e":"markdown","ae94d445":"markdown","b4ce9f44":"markdown","3e2dec34":"markdown","684d98d1":"markdown","54780183":"markdown"},"source":{"e421cbe2":"# Replace 'kaggle-competitions-project' with YOUR OWN project id here --  \nPROJECT_ID = 'kaggle-competitions-project'\n\nfrom google.cloud import bigquery\nclient = bigquery.Client(project=PROJECT_ID, location=\"US\")\ndataset = client.create_dataset('bqml_example', exists_ok=True)\n\nfrom google.cloud.bigquery import magics\nfrom kaggle.gcp import KaggleKernelCredentials\nmagics.context.credentials = KaggleKernelCredentials()\nmagics.context.project = PROJECT_ID\n\n# create a reference to our table\ntable = client.get_table(\"kaggle-competition-datasets.geotab_intersection_congestion.train\")\n\n# look at five rows from our dataset\nclient.list_rows(table, max_results=5).to_dataframe()","de5ce89a":"%load_ext google.cloud.bigquery","503ccce2":"%%bigquery\nCREATE MODEL IF NOT EXISTS `bqml_example.model1`\nOPTIONS(model_type='linear_reg') AS\nSELECT\n    TotalTimeStopped_p20 as label,\n    Weekend,\n    Hour,\n    EntryHeading,\n    ExitHeading,\n    City\nFROM\n  `kaggle-competition-datasets.geotab_intersection_congestion.train`\nWHERE\n    RowId < 2600000","6ffd0e8c":"%%bigquery\nSELECT\n  *\nFROM\n  ML.TRAINING_INFO(MODEL `bqml_example.model1`)\nORDER BY iteration ","0ead8ed3":"%%bigquery\nSELECT\n  *\nFROM ML.EVALUATE(MODEL `bqml_example.model1`, (\n  SELECT\n    TotalTimeStopped_p20 as label,\n    Weekend,\n    Hour,\n    EntryHeading,\n    ExitHeading,\n    City\n  FROM\n    `kaggle-competition-datasets.geotab_intersection_congestion.train`\n  WHERE\n    RowId > 2600000))","bf0bb12f":"%%bigquery df\nSELECT\n  RowId,\n  predicted_label as TotalTimeStopped_p20\nFROM\n  ML.PREDICT(MODEL `bqml_example.model1`,\n    (\n    SELECT\n        RowId,\n        Weekend,\n        Hour,\n        EntryHeading,\n        ExitHeading,\n        City\n    FROM\n      `kaggle-competition-datasets.geotab_intersection_congestion.test`))\n    ORDER BY RowId ASC","4dd6c035":"df['RowId'] = df['RowId'].apply(str) + '_0'\ndf.rename(columns={'RowId': 'TargetId', 'TotalTimeStopped_p20': 'Target'}, inplace=True)\ndf","8b68cbb2":"df.to_csv(r'submission.csv')","e152ce60":"## What is BigQuery ML and when should you use it?\n\nBigQuery Machine Learning (BQML) is a toolset that allows you to train and serve machine learning models directly in BigQuery. This has several advantages: \n\n* **You don't have to read your data into local memory.** One question I get a lot is \"how can I train my ML model if my dataset is just too big to fit on my computer?\". You can subsample your dataset, of course, but you can also use tools like BQML that train your model directly in your database.\n* **You don't have to use multiple languages.** Particularly if you're working in a team where most of your teammates don't know  Python or R or your preferred language for modelling, working in SQL can make it easier for you to collaborate.\n* **You can serve your model immediately after it's trained.** Because your model is already in the same place as your data, you can make predictions directly from your database. This lets you get around the hassle of cleaning up your code and either putting it intro production or passing it off to your engineering colleagues.\n\nBQML probably won't replace all your modelling tools, but it's a nice quick way to train and serve a model without spending a lot of time moving code or data around. \n\n### Models supported by BQML\n\nOne limitation of BQML is that a limited number of model types are supported. As of September 10, 2019, [BQML supports the following types of models](https:\/\/cloud.google.com\/bigquery-ml\/docs\/reference\/standard-sql\/bigqueryml-syntax-create#model_type). More model types are being built out, though, so check the documentation for the most up-to-date information.\n\n* Linear regression (LINEAR_REG). This is the OG modelling technique, used to predict the value of a continuous variable. This is what you'd use for questions like \"how many units can we expect a custom to buy?\". \n* Logistic regression (LOGISTIC_REG). This regression technique lets you classify which category an observation fits in to. For example, \"will this person buy the blue one or the red one?\". \n* K-means (KMEANS). This is an unsupervised clustering algorithm. It lets you identify categories. For example, \"given all of the customers in our database, how could we identify five distinct groups?\".\n* Tensorflow (TENSORFLOW). If you've already got a trained TensorFlow model, you can upload it to BQML and serve it directly from there. You can read more about this in [the documentation](https:\/\/cloud.google.com\/bigquery-ml\/docs\/making-predictions-with-imported-tensorflow-models). You can't currently train a TensorFlow model in BQML.","e6ae99b4":"> Note: Typically, it is not a best practice to use a `SELECT *` query. Because the model output is a small table, this query does not process a large amount of data. As a result, the cost is minimal.\n\nThe `loss` column represents the loss metric calculated after the given iteration\n    on the training dataset. \n    The `eval_loss` column is the same loss metric calculated on\n    the holdout dataset (data that is held back from training to validate the model).\n    \nAt this point you'll notice that BQML has taken care of some of the common ML decisions for you:\n\n* Splitting into training & evaluation datasets to help detect overfitting\n* Early stopping (stopping training when additional iterations would not improve performance on the evaluation set)\n* Picking and updating learning rates (starting with a low learning rate and increasing it over time)\n* Picking an optimization strategy (batch gradient descent for large datasets with high cardinality, normal equation for small datasets where it would be faster)\n\nFor more details on the `ML.TRAINING_INFO` function, see the\n    [BQML syntax reference](https:\/\/cloud.google.com\/bigquery\/docs\/reference\/standard-sql\/bigqueryml-syntax-train).\n","745a5368":"## Step zero: Gain access to dataset\n\nTo gain access to this competition's dataset on BigQuery, you must: \n1. Join the open google group provisioned for access to the private dataset. First follow this link: https:\/\/groups.google.com\/d\/forum\/bigquery-geotab \n2. Log in with a Google account. \n3. Click on Join group in the pop-up that appears. \n4. You will now have access to query the dataset kaggle-competition-datasets.geotab_intersection_congestion.train. NOTE: This is NOT an email distribution list. So once you see You cannot view topics in this forum after joining the group, you do not need to take any further action and can proceed to access the dataset. \n5. You can now access the dataset and run this kernel","331dbb22":"The standard SQL query uses a `CREATE MODEL` statement to create and train the model. You can [find the documentation for this fuction here](https:\/\/cloud.google.com\/bigquery-ml\/docs\/reference\/standard-sql\/bigqueryml-syntax-create#model_type). \n\nThe BigQuery Python client library provides a custom magic command so that you don't need to set up the queries yourself. To load the magic commands from the\nclient library, run the following code.","b6f6b763":"Let's break down this command a little bit. \n\nThis line is writing our model to BigQuery. (The fact that BQML requires write permissions is why you needed to set up your GCP account; the default Kaggle connection doesn't allow you write tables, only query them. \n\n    %%bigquery\n    CREATE MODEL IF NOT EXISTS `bqml_example.model1`\n    \nHere we're specifying that our model will be linear regression. Next we need to actually define our model.\n\n    OPTIONS(model_type='linear_reg') AS\n    \nThe code under the SELECT clause is where we define the variable we're trying to predict as well as what variables we want to use to predict it.\n\nThe column we alias as \"label\" will be our dependent variable, the thing we're trying to predict. \n\nThe other five rows say what information we want to use to predict that label. For this example, we're creating a model using information of whether it's the weekend, what hour of the day it is, the entry direction, the exit direction and the city.\n    \n    SELECT\n        TotalTimeStopped_p20 as label,\n        Weekend,\n        Hour,\n        EntryHeading,\n        ExitHeading,\n        City\n      \nThe FROM clause specifies the table (in this case more than one table) that we're going to get our data from.\n\n    FROM\n      `kaggle-competition-datasets.geotab_intersection_congestion.train`\n      \nAnd finally the `WHERE` clause specifies the range of rows we're using to train our model.\n\n    WHERE\n      RowId < 2600000\n      ","a1505781":"> `%load_ext` is one of the many Jupyter built-in magic commands. See the\n[Jupyter documentation](https:\/\/ipython.readthedocs.io\/en\/stable\/interactive\/magics.html) for more\ninformation about `%load_ext` and other magic commands.\n\nThe BigQuery client library provides a cell magic,\n`%%bigquery`, which runs a SQL query and returns the results as a Pandas\nDataFrame. Once you use this command the rest of your cell will be treated as a SQL command. (Note that tab complete won't work for SQL code written in this way.)\n\nHere's the the query that will train our model:","452c5ffa":"The query takes several minutes to complete. After the first iteration is\n    complete, your model (`model1`) appears in the navigation panel of the\n    BigQuery UI. Because the query uses a `CREATE MODEL` statement to create a\n    table, you do not see query results. The output is an empty string.","f2713072":"## Step one: Setup and create your dataset\n\nFirst, you'll need to enable BigQuery in this Kernel. You can do this by toggling BigQuery under settings in the right bar.\n\n![SettingsEnable.png](attachment:SettingsEnable.png)","a4bacf71":"Finally, you'll want to output the results as a CSV. ","dae338bb":"## Step two: Create your model\n\nNext, we will create a linear regression model.","5fc7751c":"## Step four: Evaluate your model\n\nAfter creating your model, you can evaluate the performance of the model using\nthe [`ML.EVALUATE`](\/bigquery\/docs\/reference\/standard-sql\/bigqueryml-syntax-evaluate)\nfunction.","5f7b8a6e":"## Step three: Get training statistics\n\nTo see the results of the model training, you can use the\n[`ML.TRAINING_INFO`](\/bigquery\/docs\/reference\/standard-sql\/bigqueryml-syntax-train)\nfunction, or you can view the statistics in the BigQuery UI.\nIn this tutorial, you use the `ML.TRAINING_INFO` function.\n\nA machine learning algorithm builds a model by examining many examples and\nattempting to find a model that minimizes loss. This process is called empirical\nrisk minimization.\n\nLoss is the penalty for a bad prediction &mdash; a number indicating\nhow bad the model's prediction was on a single example. If the model's\nprediction is perfect, the loss is zero; otherwise, the loss is greater. The\ngoal of training a model is to find a set of weights that have low\nloss, on average, across all examples.\n\nTo see the model training statistics that were generated when you ran the\n`CREATE MODEL` query, run the following:","ae94d445":"In order to create BigQuery ML models, you'll have to link a Google Cloud Platform account.\n\n![Linkacct.png](attachment:Linkacct.png)\n\nAfter you've connected an account, you'll need to [create a project in Google Cloud Platform](https:\/\/cloud.google.com\/resource-manager\/docs\/creating-managing-projects) and replace the placeholder below with your project ID. At which point, you can create a BigQuery dataset to store your ML model. You don't actually have to upload any data; the only table in it will be the one with your trained model.","b4ce9f44":"## Step seven: Repeat\n\nYou'll want to repeat this process for each of the metrics that is evaluated, namely TotalTimeStopped_p50, TotalTimeStopped_p80, DistanceToFirstStop_p20, DistanceToFirstStop_p50 and DistanceToFirstStop_p80.","3e2dec34":"## Step six: Output as CSV\n\nLet's format the results to fit the submission schema. The [format of the submission file](https:\/\/www.kaggle.com\/c\/bigquery-geotab-intersection-congestion\/data) requires that the header be: `TargetId` and `Target` for the predictions column. Since each of the results provided by this model is for TotalTimeStopped_p20, they'll have a TargetId of {RowID}_0 and the Target will be the predicted value for TotalTimeStopped_p20.","684d98d1":"## Step five: Use your model to predict outcomes\n\nNow that you have evaluated your model, the next step is to use it to predict\noutcomes.","54780183":"This kernel is a forked from [BigQuery Machine Learning Tutorial](https:\/\/www.kaggle.com\/rtatman\/bigquery-machine-learning-tutorial) and serves as a starting point for the [BigQuery-Geotab Intersection Congestion](https:\/\/www.kaggle.com\/c\/bigquery-geotab-intersection-congestion\/) competition."}}