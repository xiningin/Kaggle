{"cell_type":{"4d8a9b7f":"code","7bf163fd":"code","2c860929":"code","9ff3c357":"code","396bca27":"code","f969d501":"code","bb2e89c5":"code","ced0acc2":"code","d0dbd051":"code","575cdaae":"code","15eeddc4":"code","c6abfb0a":"code","d269e15f":"code","605c2e6b":"code","abb2c9a5":"code","a7cb03ec":"code","06171d3a":"code","73997384":"code","686d0816":"code","1cca89a5":"code","24acc761":"code","4e6ab90e":"code","9f0649eb":"code","ffdc601d":"code","c47ede15":"code","adac6e4c":"code","30dfef8c":"code","d0ad1787":"code","912d347b":"code","c6ac2aed":"code","2c4e1cd9":"code","0ceeef2b":"code","adc0f3af":"code","a05ddcf2":"code","b28da785":"code","10d90bdd":"code","b4ebcf22":"code","c03a72b5":"code","e4b62cb8":"code","b458a262":"code","c3ecab1f":"code","0984d733":"code","40d15267":"code","aa80bc74":"code","bb476de8":"code","bb4c2941":"code","9f46ffa3":"code","048c905f":"code","4586632e":"code","fa0a3e5a":"code","c00b3291":"code","af5df16b":"code","611896c1":"code","1c876eb6":"code","caef17a9":"code","8796ddab":"code","3ca830d1":"code","46b9d8b2":"code","57fed970":"code","9ce89ff3":"code","1dc6d3af":"markdown","7b704837":"markdown","de870457":"markdown","1e94f2df":"markdown","3f771fa4":"markdown","4bf21cb2":"markdown","2220f91f":"markdown","fc4ed581":"markdown","11f3c886":"markdown","01cee97c":"markdown","a9c1a759":"markdown","e0e61426":"markdown","a178dbaa":"markdown","1a84a845":"markdown","a05f34ef":"markdown"},"source":{"4d8a9b7f":"#Getting the dataset from URL \nfrom urllib.request import urlretrieve\nurlretrieve('https:\/\/raw.githubusercontent.com\/ageron\/handson-ml\/master\/datasets\/housing\/housing.csv', 'housing.csv')","7bf163fd":"#import required libraries\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n","2c860929":"#Import dataset\nd = pd.read_csv('housing.csv')","9ff3c357":"#viewing the dataset\nd.head()","396bca27":"#Dataframe information and description\nd.info()\nd.describe()","f969d501":"#Understanding the features of dataframe by plotting plots.\nd.hist(bins = 60, figsize = (30,20))\nplt.show()","bb2e89c5":"d[\"median_income\"].hist()","ced0acc2":"#creating an attribute ranging from 0-6 og median_income\nd[\"income_cat\"] = pd.cut(d[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n                               labels=[1, 2, 3, 4, 5])","d0dbd051":"d[\"income_cat\"].value_counts()","575cdaae":"d[\"income_cat\"].hist()","15eeddc4":"#Splitting the train and test data\n#Stratified Sampling\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(d, d[\"income_cat\"]):\n    strat_train_set = d.loc[train_index]\n    strat_test_set = d.loc[test_index]","c6abfb0a":"strat_test_set[\"income_cat\"].value_counts() \/ len(strat_test_set)","d269e15f":"d[\"income_cat\"].value_counts() \/ len(d)","605c2e6b":"#Comparing the randomly choosen test set and stratified test set\ndef income_cat_proportions(data):\n    return data[\"income_cat\"].value_counts() \/ len(data)\n\ntrain_set, test_set = train_test_split(d, test_size=0.2, random_state=42)\n\ncompare_props = pd.DataFrame({\n    \"Overall\": income_cat_proportions(d),\n    \"Stratified\": income_cat_proportions(strat_test_set),\n    \"Random\": income_cat_proportions(test_set)}).sort_index()\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] \/ compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] \/ compare_props[\"Overall\"] - 100\n\ncompare_props","abb2c9a5":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)","a7cb03ec":"df = strat_train_set.copy()","06171d3a":"#Visualizing the distribution of location\nplt.scatter(df.longitude, df.latitude, alpha = 0.1) #alpha parameter to highlight high-density places\nplt.title('Geographical distribution of Districts')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()","73997384":"#Visualizing the distribution of location\n#Same graph with more details\ndf.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n s=df.population\/100, label=\"population\", c=\"median_house_value\", cmap=\"jet\", colorbar=True)\nplt.legend()","686d0816":"#Compute standard corelation coefficient between 'median_house_value' and all other attributes\nstd_corr = df.corr()\nstd_corr['median_house_value'].sort_values(ascending = False)","1cca89a5":"#Analyze the relation between median_house_value and median_income\ndf.plot(kind = 'scatter', x = 'median_income', y = 'median_house_value', alpha = 0.1)\nplt.axis([0, 16, 0, 550000])\nplt.show()","24acc761":"#Combining Different attributes to observe correlation\ndf['rooms_per_household'] = df.total_rooms\/df.households\ndf['population_per_household'] = df.population\/df.households\ndf['bedrooms_per_rooms'] = df.total_bedrooms\/df.total_rooms","4e6ab90e":"std_corr = df.corr()\nstd_corr['median_house_value'].sort_values(ascending = False)","9f0649eb":"df.head()","ffdc601d":"df.describe()","c47ede15":"df = strat_train_set.drop(\"median_house_value\", axis=1) # drop house value for training set\ndf_house_value = strat_train_set[\"median_house_value\"].copy()","adac6e4c":"#Importing Impute class from sklearn to handle missing values, as we want to replace all missing values with median of that attribute\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'median') #creating the instance of the class and specify what has to be done\n\n#create a dataframe that contains only numerical values\ndf_num = df.drop('ocean_proximity', axis = 1)\nimputer.fit(df_num)","30dfef8c":"#imputer stores the strategy values in 'imputer.statistics_' variable\nimputer.statistics_","d0ad1787":"df_num.median().values","912d347b":"#transform the fitted imputer to the dataset\nX = imputer.transform(df_num)\nprint(type(X))","c6ac2aed":"#Convert the numpy array to pandas dataframe\ndf_df = pd.DataFrame(X, columns = df_num.columns)\ndf_df.head()","2c4e1cd9":"df_cat = df[[\"ocean_proximity\"]]\ndf_cat","0ceeef2b":"#Transforming the 'string' datatype attribute into integer using one-hot-encoder.\nfrom sklearn.preprocessing import OrdinalEncoder\nencoder = OrdinalEncoder( )\ndf_cat_encoder = encoder.fit_transform(df_cat)\ndf_cat_encoder","adc0f3af":"encoder.categories_","a05ddcf2":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder(sparse = False)\ndf_cat_1hot = cat_encoder.fit_transform(df_cat)\ndf_cat_1hot","b28da785":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# get the right column indices: safer than hard-coding indices 3, 4, 5, 6\nrooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, household_ix]\n        population_per_household = X[:, population_ix] \/ X[:, household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\ndf_extra_attribs = attr_adder.transform(df.values)","10d90bdd":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n ('imputer', SimpleImputer(strategy=\"median\")),\n ('attribs_adder', CombinedAttributesAdder()),\n ('std_scaler', StandardScaler()),\n ])\ndf_num_tr = num_pipeline.fit_transform(df_num)\n","b4ebcf22":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(df_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\nfull_pipeline\ndf_prepared = full_pipeline.fit_transform(df)\ndf_prepared","c03a72b5":"df_prepared.shape","e4b62cb8":"df_house_value","b458a262":"#Linear regression Model\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(df_prepared, df_house_value)","c3ecab1f":"print(\"Prediction :\\n\", np.round(lin_reg.predict(df_prepared[:10]), 2))\nprint(\"Actual_result :\\n\", list(df_house_value[:10]))","0984d733":"from sklearn.metrics import mean_absolute_error\npredict_house_value = lin_reg.predict(df_prepared)\nlin_rmae = mean_absolute_error(df_house_value, predict_house_value)\nlin_rmae","40d15267":"#Decision tree regression Model\nfrom sklearn.tree import DecisionTreeRegressor\ndecision_tree_reg = DecisionTreeRegressor()\ndecision_tree_reg.fit(df_prepared, df_house_value)","aa80bc74":"predict_house_value = decision_tree_reg.predict(df_prepared)\ntree_rmae = mean_absolute_error(df_house_value, predict_house_value)\ntree_rmae","bb476de8":"#Cross-Validation with Decision Tree Regression\nfrom sklearn.model_selection import cross_val_score\ntree_scores = cross_val_score(decision_tree_reg, df_prepared, df_house_value, scoring = 'neg_mean_squared_error', cv=10)\ntree_rmse_scores = np.sqrt(-tree_scores)\ntree_rmse_scores","bb4c2941":"def show_scores(scores):\n    print('Scores :', scores)\n    print('Mean :', scores.mean())\n    print('Standard Deviation :', scores.std())\n    ","9f46ffa3":"show_scores(tree_rmse_scores)","048c905f":"#Cross-Validation with Linear Regression Model\nlin_scores = cross_val_score(lin_reg, df_prepared, df_house_value, scoring = 'neg_mean_squared_error', cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\nlin_rmse_scores","4586632e":"show_scores(lin_rmse_scores)","fa0a3e5a":"#Random Forest regression Model\nfrom sklearn.ensemble import RandomForestRegressor\nrand_reg = RandomForestRegressor()\nrand_reg.fit(df_prepared, df_house_value)","c00b3291":"predict_house_value = rand_reg.predict(df_prepared)\nrand_rmae = mean_absolute_error(df_house_value, predict_house_value)\nrand_rmae","af5df16b":"#Cross-Validation with Random Forest Regression Model\nrand_scores = cross_val_score(rand_reg, df_prepared, df_house_value, scoring = 'neg_mean_squared_error', cv=10)\nrand_rmse_scores = np.sqrt(-rand_scores)\nrand_rmse_scores\nshow_scores(rand_rmse_scores)","611896c1":"#Support Vector Machine regression Model\nfrom sklearn.svm import SVR\nsvr_reg = SVR()\nsvr_reg.fit(df_prepared, df_house_value)\npredict_house_value = svr_reg.predict(df_prepared)\nsvr_rmae = mean_absolute_error(df_house_value, predict_house_value)\nsvr_rmae","1c876eb6":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [{'n_estimators' : [3,10,30], 'max_features' : [2,4,6,8]},\n             {'bootstrap' : [False], 'n_estimators' : [3,10], 'max_features' : [2,3,4]}]\ngrid_search = GridSearchCV(rand_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error')\ngrid_search.fit(df_prepared, df_house_value)","caef17a9":"grid_search.best_params_","8796ddab":"grid_search.best_estimator_","3ca830d1":"cv_res = grid_search.cv_results_","46b9d8b2":"for mean_score,params in zip(cv_res['mean_test_score'], cv_res['params']):\n    print(np.sqrt(-mean_score),params)","57fed970":"from sklearn.metrics import mean_squared_error\nfinal_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1) # drop house value for training set\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_prediction = final_model.predict(X_test_prepared)\n\nfinal_mae = mean_squared_error(y_test, final_prediction)\nfinal_rmae = np.sqrt(final_mae)","9ce89ff3":"final_rmae","1dc6d3af":"Zero error means that every 'df_house_value = predict_house_value', when we test the model then there will be errors-as the test dataset is unknown to the model. In simple, this decision tree regression overfits the training dataset.","7b704837":"12,031 rmae is better than 49,439 and 71,398 rmae","de870457":"## Better Evaluation using Cross-Validation ","1e94f2df":"## Training the model","3f771fa4":"rooms_per_household ia an important attribute as it describes the no of rooms requires depending on the no of people in the house.","4bf21cb2":"$49,439 prediction error, states that the linear model is underfitted on training dataset.\nEither we can add more features to training set and run the model or choose a better model.","2220f91f":"SVM not a good option for this training set.","fc4ed581":"## Fine-Tune the model\n\nGrid Search","11f3c886":"From the above output observe that: as the correlation coefficient value reaches 1, the correlation of median_house_value and that attribute becomes strong positive.\nAnd as the correlation coefficient value reaches -1, the correlation of median_house_value and that attribute becomes strong negative.\n\nWe can also state that, the most promising attribute to predict the median_house_value is the median_income.","01cee97c":"## Data Cleaning\n\nThree ways to fix the missing values:\n\n\u2022 Get rid of the whole attribute.\n\u2022 Get rid of the corresponding districts.\n\u2022 Set the values to some value (zero, the mean, the median, etc.).","a9c1a759":"If we try to impute the whole dataframe, that contains differernt datatypes it throws an error :\n\n#### imputer.fit(df)\n\nValueError: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'NEAR BAY'\n","e0e61426":" 71,398(Decision tree error with cross-validation) >> 49,439(linear regression error)","a178dbaa":"Soo many variations in the actual and predicted value. Let's compute the cost function(root mean absolute error) of the training set.","1a84a845":"Attributes of Dataset\n\n1. longitude: A measure of how far west a house is; a higher value is farther west\n\n2. latitude: A measure of how far north a house is; a higher value is farther north\n\n3. housingMedianAge: Median age of a house within a block; a lower number is a newer building\n\n4. totalRooms: Total number of rooms within a block\n\n5. totalBedrooms: Total number of bedrooms within a block\n\n6. population: Total number of people residing within a block\n\n7. households: Total number of households, a group of people residing within a home unit, for a block\n\n8. medianIncome: Median income for households within a block of houses (measured in tens of thousands of US Dollars)\n\n9. medianHouseValue: Median house value for households within a block (measured in US Dollars)\n\n10. oceanProximity: Location of the house w.r.t ocean\/sea\n","a05f34ef":"## Evaluating the model on Test set"}}