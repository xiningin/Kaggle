{"cell_type":{"1147350c":"code","def2d375":"code","e08abada":"code","19a5eded":"code","a797e4e1":"code","1a22ac5e":"code","ed10dda6":"code","722d2f2f":"code","6e217feb":"code","a35a6661":"code","6f3f517d":"code","1b89d56f":"code","0457f989":"code","cf5fecfd":"code","1da90ecd":"code","39d86508":"code","30caba0c":"code","39f523eb":"code","fcedc701":"code","5e433187":"code","0e4a4af9":"code","d43d8873":"code","01221a62":"code","2779fc16":"code","b9cf39ff":"code","7ec37c5b":"code","8e57ca12":"code","b5dc738f":"markdown","815ed059":"markdown","0207795c":"markdown","86e0c789":"markdown","3cd7e774":"markdown","62bcdfaa":"markdown","7ce48703":"markdown","342fa65b":"markdown","48a031d9":"markdown","0077162a":"markdown","0420ed7d":"markdown","e8fe7322":"markdown","b6c177c7":"markdown","377a0216":"markdown","2525b604":"markdown","96f9aedf":"markdown","782cb707":"markdown","b055b62d":"markdown","9b9cda82":"markdown","1eef70de":"markdown","d7f44f67":"markdown","134bbe51":"markdown","d18b40da":"markdown","32f57056":"markdown"},"source":{"1147350c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","def2d375":"import sys\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch import optim\n\nimport torchvision.transforms as transforms\nimport torchvision\n\nfrom fastprogress import master_bar, progress_bar\n\nfrom PIL import Image","e08abada":"data = pd.read_csv(\"..\/input\/vietai-advanced-final-project-00\/train.csv\")\ndata.head()","19a5eded":"LABELS = data.columns[5:]\nLABELS","a797e4e1":"train_data, val_data = train_test_split(data, test_size=0.1, random_state=2019)","1a22ac5e":"IMAGE_SIZE = 224                              # Image size (224x224)\nIMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\nIMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\nBATCH_SIZE = 96                              \nLEARNING_RATE = 0.001\nLEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\nLEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\nMAX_EPOCHS = 100                              # Maximum number of training epochs","ed10dda6":"class ChestXrayDataset(Dataset):\n    \n    def __init__(self, folder_dir, dataframe, image_size, normalization):\n        \"\"\"\n        Init Dataset\n        \n        Parameters\n        ----------\n        folder_dir: str\n            folder contains all images\n        dataframe: pandas.DataFrame\n            dataframe contains all information of images\n        image_size: int\n            image size to rescale\n        normalization: bool\n            whether applying normalization with mean and std from ImageNet or not\n        \"\"\"\n        self.image_paths = [] # List of image paths\n        self.image_labels = [] # List of image labels\n        \n        # Define list of image transformations\n        image_transformation = [\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor()\n        ]\n        \n        if normalization:\n            # Normalization with mean and std from ImageNet\n            image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n        \n        self.image_transformation = transforms.Compose(image_transformation)\n        \n        # Get all image paths and image labels from dataframe\n        for index, row in dataframe.iterrows():\n            image_path = os.path.join(folder_dir, row.Path)\n            self.image_paths.append(image_path)\n            if len(row) < 14:\n                labels = [0] * 14\n            else:\n                labels = []\n                for col in row[5:]:\n                    if col == 1:\n                        labels.append(1)\n                    else:\n                        labels.append(0)\n            self.image_labels.append(labels)\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Read image at index and convert to torch Tensor\n        \"\"\"\n        \n        # Read image\n        image_path = self.image_paths[index]\n        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n        \n        # TODO: Image augmentation code would be placed here\n        \n        # Resize and convert image to torch tensor \n        image_data = self.image_transformation(image_data)\n        \n        return image_data, torch.FloatTensor(self.image_labels[index])","722d2f2f":"train_dataset = ChestXrayDataset(\"..\/input\/vietai-advanced-final-project-00\/train\/train\", train_data, IMAGE_SIZE, True)","6e217feb":"train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)","a35a6661":"for data, label in train_dataloader:\n    print(data.size())\n    print(label.size())\n    break","6f3f517d":"val_dataset = ChestXrayDataset(\"..\/input\/vietai-advanced-final-project-00\/train\/train\", val_data, IMAGE_SIZE, True)\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)","1b89d56f":"class DenseNet121(nn.Module):\n    def __init__(self, num_classes, is_trained=True):\n        \"\"\"\n        Init model architecture\n        \n        Parameters\n        ----------\n        num_classes: int\n            number of classes\n        is_trained: bool\n            whether using pretrained model from ImageNet or not\n        \"\"\"\n        super().__init__()\n        \n        # Load the DenseNet121 from ImageNet\n        self.net = torchvision.models.densenet121(pretrained=is_trained)\n        \n        # Get the input dimension of last layer\n        kernel_count = self.net.classifier.in_features\n        \n        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n        self.net.classifier = nn.Sequential(nn.Linear(kernel_count, num_classes), nn.Sigmoid())\n        \n    def forward(self, inputs):\n        \"\"\"\n        Forward the netword with the inputs\n        \"\"\"\n        return self.net(inputs)","0457f989":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","cf5fecfd":"model = DenseNet121(num_classes=len(LABELS)).to(device)\nmodel","1da90ecd":"sum(p.numel() for p in model.parameters() if p.requires_grad)","39d86508":"# Loss function\nloss_criteria = nn.BCELoss()\n\n# Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n\n# Learning rate will be reduced automatically during training\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)","30caba0c":"def multi_label_auroc(y_gt, y_pred):\n    \"\"\" Calculate AUROC for each class\n\n    Parameters\n    ----------\n    y_gt: torch.Tensor\n        groundtruth\n    y_pred: torch.Tensor\n        prediction\n\n    Returns\n    -------\n    list\n        F1 of each class\n    \"\"\"\n    auroc = []\n    gt_np = y_gt.to(\"cpu\").numpy()\n    pred_np = y_pred.to(\"cpu\").numpy()\n    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n    for i in range(gt_np.shape[1]):\n        auroc.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return auroc","39f523eb":"def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n    \"\"\"\n    Epoch training\n\n    Paramteters\n    -----------\n    epoch: int\n      epoch number\n    model: torch Module\n      model to train\n    train_dataloader: Dataset\n      data loader for training\n    device: str\n      \"cpu\" or \"cuda\"\n    loss_criteria: loss function\n      loss function used for training\n    optimizer: torch optimizer\n      optimizer used for training\n    mb: master bar of fastprogress\n      progress to log\n\n    Returns\n    -------\n    float\n      training loss\n    \"\"\"\n    # Switch model to training mode\n    model.train()\n    training_loss = 0 # Storing sum of training losses\n   \n    # For each batch\n    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n        \n        # Move X, Y  to device (GPU)\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Clear previous gradient\n        optimizer.zero_grad()\n\n        # Feed forward the model\n        pred = model(images)\n        loss = loss_criteria(pred, labels)\n\n        # Back propagation\n        loss.backward()\n\n        # Update parameters\n        optimizer.step()\n\n        # Update training loss after each batch\n        training_loss += loss.item()\n\n        mb.child.comment = f'Training loss {training_loss\/(batch+1)}'\n\n    del images, labels, loss\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n\n    # return training loss\n    return training_loss\/len(train_dataloader)","fcedc701":"def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n    \"\"\"\n    Validate model on validation dataset\n    \n    Parameters\n    ----------\n    epoch: int\n        epoch number\n    model: torch Module\n        model used for validation\n    val_loader: Dataset\n        data loader of validation set\n    device: str\n        \"cuda\" or \"cpu\"\n    loss_criteria: loss function\n      loss function used for training\n    mb: master bar of fastprogress\n      progress to log\n  \n    Returns\n    -------\n    float\n        loss on validation set\n    float\n        metric score on validation set\n    \"\"\"\n\n    # Switch model to evaluation mode\n    model.eval()\n\n    val_loss = 0                                   # Total loss of model on validation set\n    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n\n    with torch.no_grad(): # Turn off gradient\n        # For each batch\n        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n            # Move images, labels to device (GPU)\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Update groundtruth values\n            out_gt = torch.cat((out_gt,  labels), 0)\n\n            # Feed forward the model\n            ps = model(images)\n            loss = loss_criteria(ps, labels)\n\n            # Update prediction values\n            out_pred = torch.cat((out_pred, ps), 0)\n\n            # Update validation loss after each batch\n            val_loss += loss\n            mb.child.comment = f'Validation loss {val_loss\/(step+1)}'\n\n    # Clear memory\n    del images, labels, loss\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n    # return validation loss, and metric score\n    return val_loss\/len(val_loader), np.array(multi_label_auroc(out_gt, out_pred)).mean()","5e433187":"import time","0e4a4af9":"# Best AUROC value during training\nbest_score = 0\nmodel_path = \"densenet.pth\"\ntraining_losses = []\nvalidation_losses = []\nvalidation_score = []\n\n\n# Config progress bar\nmb = master_bar(range(MAX_EPOCHS))\nmb.names = ['Training loss', 'Validation loss', 'Validation AUROC']\nx = []\n\nnonimproved_epoch = 0\nstart_time = time.time()\n\n# Training each epoch\nfor epoch in mb:\n    mb.first_bar.comment = f'Best AUROC score: {best_score}'\n    x.append(epoch)\n\n    # Training\n    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n    mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n    training_losses.append(train_loss)\n\n    # Evaluating\n    val_loss, new_score = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n    mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n    validation_losses.append(val_loss)\n    validation_score.append(new_score)\n\n    # Update learning rate\n    lr_scheduler.step(new_score)\n\n    # Update training chart\n    mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score]], [0,epoch+1], [0,1])\n\n    # Save model\n    if best_score < new_score:\n        mb.write(f\"Improve AUROC from {best_score} to {new_score}\")\n        best_score = new_score\n        nonimproved_epoch = 0\n        torch.save({\"model\": model.state_dict(), \n                    \"optimizer\": optimizer.state_dict(), \n                    \"best_score\": best_score, \n                    \"epoch\": epoch, \n                    \"lr_scheduler\": lr_scheduler.state_dict()}, model_path)\n    else: \n        nonimproved_epoch += 1\n    if nonimproved_epoch > 10:\n        break\n        print(\"Early stopping\")\n    if time.time() - start_time > 3600*8:\n        break\n        print(\"Out of time\")","d43d8873":"test_df = pd.read_csv(\"..\/input\/vietai-advanced-final-project-00\/sample_submission.csv\")\ntest_df.head()","01221a62":"test_dataset = ChestXrayDataset(\"..\/input\/vietai-advanced-final-project-00\/test\/test\", test_df, IMAGE_SIZE, True)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=700, shuffle=False, num_workers=2, pin_memory=True)","2779fc16":"state = torch.load(model_path, map_location=device)\nmodel.load_state_dict(state[\"model\"])\nmodel.eval()","b9cf39ff":"from tqdm import tqdm\n\nout_pred = torch.FloatTensor().to(device)\nwith torch.no_grad(): # Turn off gradient\n    # For each batch\n    for step, (images, _) in tqdm(enumerate(test_dataloader)):\n        # Move images, labels to device (GPU)\n        images = images.to(device)\n\n        # Feed forward the model\n        ps = model(images)\n        out_pred = torch.cat((out_pred, ps), dim=0)","7ec37c5b":"label_list = list(LABELS)\nfor col in test_df.columns[1:]:\n    test_df[col] = out_pred[:, label_list.index(col)].cpu().numpy()","8e57ca12":"test_df.to_csv(\"submission.csv\", index=False)\ntest_df.head()","b5dc738f":"Let's check the size of data and label for each iteration","815ed059":"In this notebook, we will use Pytorch library to implement and train ResNet50 as a baseline model. With initial weights from ImageNet, we will retrain all layers for this problem.","0207795c":"# Predict","86e0c789":"Number of trainable parameters","3cd7e774":"# Read dataset","62bcdfaa":"## Create model and get number of trainable parameters","7ce48703":"Besides, `DataLoader` also need to be created. For the training data loader, we need to shuffle the dataset.","342fa65b":"## Fully training\nFully training the model ","48a031d9":"## Define model\nIn the baseline, we use DenseNet121 pretrained on ImageNet dataset. The classifier of model would be replaced with a new dense layer to make the output suit the problem.","0077162a":"Import libraries","0420ed7d":"## Compute AUROC-score \nBecause we have multi labels, we need to calculate AUROC-score for each class.","e8fe7322":"Create model and check model architecture","b6c177c7":"## Training each epoch\nThis function will be called to train on one epoch\n","377a0216":"## Define loss function, optimizer, and learning rate scheduler","2525b604":"## Implement Dataset loader\nIn Pytorch, you need to subclass the `Dataset` of Pytorch to custom the data loading process. The **Image Augmentation** would be executed in this subclass","96f9aedf":"**To simplify the baseline model, the dataset is splited randomly. However, to improve the model, cross-validation techniques can be applied here**","782cb707":"We also need to create validation dataloader. Different from training dataloader, we don't shuffle the validation set","b055b62d":"We need to train about 7 millions parameters","9b9cda82":"Create training dataset","1eef70de":"For the data provided, we will split the dataset to 90% for training and 10% for validation","d7f44f67":"# Build and train baseline model","134bbe51":"# Split the dataset","d18b40da":"## Check GPU available","32f57056":"## Evaluate model\nThis function is used to validate the model on the validation dataset"}}