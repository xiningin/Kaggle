{"cell_type":{"a4ea8d36":"code","7e51ee5f":"code","6d09bf83":"code","64e370fe":"code","35e0e1e6":"code","77ee3a05":"code","cbb27e07":"code","88abf08e":"code","5e8b2401":"code","31b9183a":"code","756cd1a2":"code","f540b7c8":"code","5d3f0065":"code","e8a07ec3":"code","c7f98875":"code","674b8af5":"code","629abc70":"code","b39a8e8e":"code","2ebd2425":"code","24a6693b":"code","a05536d1":"code","7150a0fb":"code","b20104fe":"code","6cb76e86":"code","1b47ba06":"code","b67b7e01":"code","67bac170":"code","4953393e":"code","ea14b308":"markdown","90eecbd2":"markdown"},"source":{"a4ea8d36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7e51ee5f":"PATH_WEEK3 = '\/kaggle\/input\/covid19-global-forecasting-week-3'\n\ndf_Train = pd.read_csv(f'{PATH_WEEK3}\/train.csv', parse_dates=[\"Date\"], engine='python')\ndf_Test = pd.read_csv(f'{PATH_WEEK3}\/test.csv')","6d09bf83":"#df_Covid19 = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')","64e370fe":"def fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state","35e0e1e6":"df_Train.rename(columns={'Country_Region':'Country'}, inplace=True)\ndf_Test.rename(columns={'Country_Region':'Country'}, inplace=True)\n#df_Covid19.rename(columns={'Country\/Region':'Country', 'ObservationDate': 'Date'}, inplace=True)\n#df_Covid19.replace({'Country': 'Mainland China'}, 'China', inplace=True)\n#df_Covid19.replace({'Country': 'Taiwan'}, 'Taiwan*', inplace=True)\n\nEMPTY_VAL = \"EMPTY_VAL\"\n\ndf_Train.rename(columns={'Province_State':'State'}, inplace=True)\ndf_Train['State'].fillna(EMPTY_VAL, inplace=True)\ndf_Train['State'] = df_Train.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\ndf_Test.rename(columns={'Province_State':'State'}, inplace=True)\ndf_Test['State'].fillna(EMPTY_VAL, inplace=True)\ndf_Test['State'] = df_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\n#df_Covid19.rename(columns={'Province\/State':'State'}, inplace=True)\n#df_Covid19['State'].fillna(EMPTY_VAL, inplace=True)\n#df_Covid19['State'] = df_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n#df_Covid19.replace({'State': 'Taiwan*'}, 'Taiwan*', inplace=True)\n\n#df_Train['Date'] = pd.to_datetime(df_Train['Date'], infer_datetime_format=True) # as pd.read_csv does parsed 'Date' as dates\ndf_Test['Date'] = pd.to_datetime(df_Test['Date'], infer_datetime_format=True) # dtype('Date') would be object, adnd we need to explicitly convert object to date as we did not use parse_dates\n#df_Covid19['Date'] = pd.to_datetime(df_Covid19['Date'], infer_datetime_format=True)","77ee3a05":"df_groupByCountry = df_Train.loc[:, ['Country', 'State', 'ConfirmedCases', 'Fatalities']].groupby(['Country', 'State']).max().reset_index().groupby('Country').sum().sort_values(by='ConfirmedCases', ascending=False).reset_index()\ndf_groupByCountry[:15].style.background_gradient(cmap='viridis_r')","cbb27e07":"import plotly.express as px\n\ncountries = df_groupByCountry.Country.unique().tolist()\ndf_plot = df_Train.loc[(df_Train.Country.isin(countries[:10])) & (df_Train.Date >= '2020-03-01'), ['Date', 'Country', 'State', 'ConfirmedCases', 'Fatalities']].groupby(['Date', 'Country', 'State']).max().reset_index().groupby(['Date', 'Country']).sum().sort_values(by='ConfirmedCases', ascending=False).reset_index()\n\nfig = px.bar(df_plot, x=\"Date\", y=\"ConfirmedCases\", color=\"Country\", barmode=\"stack\")\nfig.update_layout(title='Rise of Confirmed Cases around top 10 countries', annotations=[dict(x='2020-03-21', y=150, xref=\"x\", yref=\"y\", text=\"Coronas Rise exponentially from here\", showarrow=True, arrowhead=1, ax=-150, ay=-150)])\nfig.show()","88abf08e":"df_Train.loc[: , ['Country', 'State', 'ConfirmedCases', 'Fatalities']].groupby(['Country', 'State']).max().reset_index().nlargest(15, \"ConfirmedCases\").style.background_gradient(cmap='nipy_spectral')","5e8b2401":"import plotly.express as px\n\ndf_plot = df_Train.loc[: , ['Date', 'Country', 'ConfirmedCases', 'Fatalities']].groupby(['Date', 'Country']).max().reset_index()\n\ndf_plot.loc[:, 'Date'] = df_plot.Date.dt.strftime(\"%Y-%m-%d\")\ndf_plot.loc[:, 'Size'] = np.power(df_plot[\"ConfirmedCases\"]+1,0.3)-1 #np.where(df_plot['Country'].isin(['China', 'Italy']), df_plot['ConfirmedCases'], df_plot['ConfirmedCases']*300)\n\nfig = px.scatter_geo(df_plot,\n                     locations=\"Country\",\n                     locationmode = \"country names\",\n                     hover_name=\"Country\",\n                     color=\"ConfirmedCases\",\n                     animation_frame=\"Date\", \n                     size='Size',\n                     #projection=\"natural earth\",\n                     title=\"Rise of Coronavirus Confirmed Cases\")\nfig.show()","31b9183a":"import plotly.express as px\n\ncountries = df_groupByCountry.Country.unique().tolist()\ndf_plot = df_Train.loc[df_Train.Country.isin(countries[:10]), ['Date', 'Country', 'ConfirmedCases']].groupby(['Date', 'Country']).max().reset_index()\n\nfig = px.line(df_plot, x=\"Date\", y=\"ConfirmedCases\", color='Country')\nfig.update_layout(title='No.of Confirmed Cases per Day for Top 10 Countries',\n                   xaxis_title='Date',\n                   yaxis_title='No.of Confirmed Cases')\nfig.show()","756cd1a2":"import plotly.express as px\n\ncountries = df_groupByCountry.Country.unique().tolist()\ndf_plot = df_Train.loc[df_Train.Country.isin(countries[:10]), ['Date', 'Country', 'Fatalities']].groupby(['Date', 'Country']).max().reset_index()\n\nfig = px.scatter(df_plot, x=\"Date\", y=\"Fatalities\", color='Country')\nfig.update_layout(title='No.of Fatalities per Day for Top 10 Countries',\n                   xaxis_title='Date',\n                   yaxis_title='No.of Fatalities')\nfig.show()","f540b7c8":"MIN_TEST_DATE = df_Test.Date.min()\n\ndf_train = df_Train.loc[df_Train.Date < MIN_TEST_DATE, :]\ny1_Train = df_train.iloc[:, -2]\ny2_Train = df_train.iloc[:, -1]","5d3f0065":"def extractDate(df, colName = 'Date'):\n    \"\"\"\n    This function does extract the date feature in to multiple features\n    - week, day, month, year, dayofweek\n    \"\"\"\n    assert colName in df.columns\n    df = df.assign(week = df.loc[:, colName].dt.week,\n                   day = df.loc[:, colName].dt.day,\n                   month = df.loc[:, colName].dt.month,\n                   #year = df.loc[:, colName].dt.year,\n                   dayofweek = df.loc[:, colName].dt.dayofweek)\n    return df","e8a07ec3":"def createNewDataset(df):\n    \"\"\"\n    This function does create a new dataset for modelling.\n    \"\"\"\n    df_New = df.copy()\n    \n    df_New = extractDate(df_New)\n    #df_New.loc[:, 'Date_Int'] = (df_New.loc[:, 'Date'].dt.strftime(\"%m%d\")).astype('int16')\n    df_New.drop(columns=['Date'], axis=1, inplace=True)\n    \n    #df_New.loc[:, 'Country_State'] = df_New.loc[:, 'Country'] + '_' + df_New.loc[:, 'State']\n    #df_New.loc[:, 'Country_State'] = df_New[[\"State\", \"Country\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n    #df_New.drop(columns=['Country', 'State'], axis=1, inplace=True)\n    \n    return df_New","c7f98875":"X_Train = createNewDataset(df_train)\nX_Test = createNewDataset(df_Test)","674b8af5":"X_Train[X_Train.Country == 'Afghanistan'].tail()","629abc70":"X_Test.head()","b39a8e8e":"from warnings import filterwarnings\nfilterwarnings('ignore')","2ebd2425":"from xgboost import XGBRegressor\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\nLEncoder = preprocessing.LabelEncoder()\nskfold = ShuffleSplit(random_state=7)\n\ncountries = X_Train.Country.unique().tolist()\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = X_Train.loc[X_Train.Country == country, :].State.unique().tolist()\n    for state in states:\n        categoricalFeatures = ['Country', 'State']\n        \n        # Train\n        X_Train_CS = X_Train.loc[(X_Train.Country == country) & (X_Train.State == state), :]\n        #X_Train_CS.loc[:, 'Country_State'] = X_Train_CS.loc[:, [\"State\", \"Country\"]].apply(lambda row: row[0] + \"_\" + row[1],axis=1)\n        \n        y1_Train_CS = X_Train_CS.loc[:, 'ConfirmedCases']\n        y2_Train_CS = X_Train_CS.loc[:, 'Fatalities']\n        X_Train_CS.drop(columns=['Id', 'ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n        #X_Train_CS.drop(columns=categoricalFeatures, axis=1, inplace=True)\n        \n        X_Train_CS.loc[:, 'Country'] = LEncoder.fit_transform(X_Train_CS.loc[:, 'Country'])\n        X_Train_CS.loc[:, 'State'] = LEncoder.fit_transform(X_Train_CS.loc[:, 'State'])\n        #X_Train_CS.loc[:, 'Country_State'] = LEncoder.fit_transform(X_Train_CS.loc[:, 'Country_State'])\n        \n        # Test\n        X_Test_CS = X_Test.loc[(X_Test.Country == country) & (X_Test.State == state), :]\n        #X_Test_CS.loc[:, 'Country_State'] = X_Test_CS.loc[:, [\"State\", \"Country\"]].apply(lambda row: row[0] + \"_\" + row[1],axis=1)\n\n        X_Test_CS_Id = X_Test_CS.loc[:, 'ForecastId']\n        X_Test_CS.drop(columns=['ForecastId'], axis=1, inplace=True)\n        #X_Test_CS.drop(columns=categoricalFeatures, axis=1, inplace=True)\n\n        X_Test_CS.loc[:, 'Country'] = LEncoder.fit_transform(X_Test_CS.loc[:, 'Country'])\n        X_Test_CS.loc[:, 'State'] = LEncoder.fit_transform(X_Test_CS.loc[:, 'State'])\n        #X_Test_CS.loc[:, 'Country_State'] = LEncoder.fit_transform(X_Test_CS.loc[:, 'Country_State'])\n\n        # Model fit & predict\n        model1 = XGBRegressor(n_estimators=1250)\n        results = cross_val_score(model1, X_Train_CS, y1_Train_CS, cv=skfold)\n        #print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n        \n        model1.fit(X_Train_CS, y1_Train_CS)\n        y1_pred = model1.predict(X_Test_CS)\n\n        model2 = XGBRegressor(n_estimators=1000)\n        results = cross_val_score(model2, X_Train_CS, y2_Train_CS, cv=skfold)\n        \n        model2.fit(X_Train_CS, y2_Train_CS)\n        y2_pred = model2.predict(X_Test_CS)\n        \n        # Output Dataset\n        df = pd.DataFrame({'ForecastId': X_Test_CS_Id, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n        df_out = pd.concat([df_out, df], axis=0)\n    # Done for state loop\n# Done for country Loop","24a6693b":"df_out.ForecastId = df_out.ForecastId.astype('int')","a05536d1":"#df_out.iloc[np.r_[85:97, 1203:1215, 172:177, 258:269, 1935:1946, 5934:5945, 6708:6719, 12384:12395, 10535:10545, 9030:9041, 8299:8311], :]\ndf_out.iloc[np.r_[42, 45, 97, 143, 175, 267, 327, 350, 420, 450, 540, 590, 680, 730, 2880, 2900, 2960, 3000, 3050, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000], :]","7150a0fb":"df_out.to_csv('submission.csv', index=False)","b20104fe":"noOfDaysOverlap = int((df_Test.Date.min() - df_Train.Date.max()) \/ np.timedelta64(1, 'D'))","6cb76e86":"df_merge = df_Test.merge(df_out, on='ForecastId')\ncountry = 'US'\nstate = 'New York'\ndf_country = df_merge[(df_merge['Country'] == country) & (df_merge['State'] == state)].groupby(['Date','Country', 'State']).sum().reset_index()\ndf_country_Actual = df_Train[(df_Train['Country'] == country) & (df_Train['State'] == state)].groupby(['Date','Country', 'State']).sum().reset_index()\n","1b47ba06":"fig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases\", title='Total Cases of ' + country + ' ' + state + ' (Actual (Red) vs Predicted (Blue))')\n\nfig.add_scatter(x=df_country_Actual['Date'][noOfDaysOverlap:], y=df_country_Actual['ConfirmedCases'][noOfDaysOverlap:], mode='lines', name=\"Actual\")\n\nfig.show()","b67b7e01":"df_Train_Temp = df_Train[df_Train.Date >= df_Test.Date.min()]\ndf_Train_Out = df_Train_Temp.merge(df_out, left_on='Id', right_on='ForecastId')\ndf_Train_Out.tail()","67bac170":"from sklearn.metrics import mean_squared_error\n\nrmsle_cc = np.sqrt(mean_squared_error(np.log1p(df_Train_Out.ConfirmedCases_x), np.log1p(df_Train_Out.ConfirmedCases_y)))\nrmsle_f = np.sqrt(mean_squared_error(np.log1p(df_Train_Out.Fatalities_x), np.log1p(df_Train_Out.Fatalities_y)))","4953393e":"print(f'RMSLE of ConfirmedCases is {round(rmsle_cc, 4)}')\nprint(f'RMSLE of Fatalties is {round(rmsle_f, 4)}')","ea14b308":"X_Group = X_Train.groupby(['Country', 'State'])\nfor lag in range(1, 31):\n    X_Train[f'Lag_CC_{lag}'] = X_Group['ConfirmedCases'].shift(lag)\n    X_Train[f'Lag_F_{lag}'] = X_Group['Fatalities'].shift(lag)","90eecbd2":"To avoid data leak between the Train and Test, lets separate the Test Rows that exists in Train"}}