{"cell_type":{"fbea2184":"code","f1bd6f3a":"code","683c6aa9":"code","555084ce":"code","bb98edf6":"code","1317cf85":"code","065ca8a7":"code","49a54a4f":"code","a95c89fd":"code","2cb0b1f2":"code","91fb31b6":"code","4b78af1e":"code","c5eccc93":"code","9f86f77a":"code","3d77838b":"code","84f54719":"markdown","8e8f4476":"markdown","4bffc013":"markdown","e5a067f4":"markdown","c3474b4c":"markdown","1f99001d":"markdown","f48ebf16":"markdown","914e1fc0":"markdown","92ef9fb1":"markdown","69a92b8c":"markdown","8c616cbe":"markdown","67c35a3d":"markdown","65971fdb":"markdown","550e50a4":"markdown","b869c57f":"markdown","13583a42":"markdown","73fc6227":"markdown","feaec4ec":"markdown","e500d606":"markdown","4370f595":"markdown","5529882b":"markdown","908de3c4":"markdown"},"source":{"fbea2184":"import pandas as pd # Datensets\nimport numpy as np # Data Manipulation","f1bd6f3a":"# Read in all data\ndata = pd.read_csv(\"..\/input\/avocado.csv\")","683c6aa9":"# Create Sample Dataset\n\ntestcolumns = [\"Date\", \"Price\", \"Name\", \"Volume\", \"42\"]\n\ntestdata = [\n    [\"01-01-2019\", 100, \"Redhat\", 20, 42],\n    [\"02-01-2019\", 200, \"Pop\", 10, 42],\n    [\"03-01-2019\", 300, \"Mint\", 5, 42],\n    [\"04-01-2019\", 400, \"Arch\", 2.5, 42],\n    [\"05-01-2019\", 500, \"Suse\", 1.25, ]\n]\n\ntestdata = pd.DataFrame(columns = testcolumns, data = testdata)","555084ce":"# ToDo: Read out schema of the Dataset","bb98edf6":"# This is how the testdata looks:\nprint(testdata.columns.values)\ntestdata.head()","1317cf85":"# ToDo: print column names of data\n\n# ToDo: print last column name\n\n# ToDo: print first 10 rows of data","065ca8a7":"# Example\ntestdata = testdata.drop([\"Name\"], axis = 1)\nprint(\"missing data\\n\", testdata.isnull().sum())\ntestdata = testdata.dropna(how = \"any\")\ntestdata.head()","49a54a4f":"# ToDo: delete \"Unnamed: 0\"\n\n# ToDo: Read out missing data\n\n# ToDo: delete rows with missing Data","a95c89fd":"print(\"before transformation\\n\", testdata[\"Date\"].head())\ntestdata[\"Date\"] = pd.to_datetime(testdata[\"Date\"])\nprint(\"after transformation\\n\", testdata[\"Date\"].head())","2cb0b1f2":"# Overview of Date Data\n","91fb31b6":"# Convert Date to Datetime\n","4b78af1e":"# New Overview of Data\n","c5eccc93":"# example\ntestdata[\"meaningless\"] = testdata[\"Price\"] + testdata[\"Volume\"]\ntestdata[\"just dividing by 5\"] = testdata[\"Volume\"] \/ 5\ntestdata.head()","9f86f77a":"# ToDo: Add \"Total Sales\" to Dataset(Price * Volume)\n\n# ToDo: Add \"real Price\" to Dataset (Price corrected by inflation)\n\n","3d77838b":"# 42 zu ersetzen:\na1 = [1, 42] #Ergebnis 1\na2 = [2, 42] #Ergebnis 2\na3 = [3, \"42\"] #Ergebnis 3\na4 = [4, 42] #Ergebnis ...\na5 = [5, \"42\"]\na6 = [6, 42]\na7 = [7, \"42\"]\na8 = [8, 42]\nantworten = [a1,a2,a3,a4,a5,a6, a7, a8]\nmeine_antworten = pd.DataFrame(antworten, columns = [\"Id\", \"Category\"])\nmeine_antworten.to_csv(\"meine_loesung_Aufgaben1.csv\", index = False)","84f54719":"## Aufgabe 5: Features extrahieren","8e8f4476":"## Beispielsdatensatz\n\nUm euch ein besseres Bild zu vermitteln, wie Funktionen angewandet werden, werde ich Beispiele anhand eines kleinen Datensatzes vor jeder Aufgabe geben.\nDieser Datensatz hat keine wirkliche Bedeutung und dient nur als Beispiel.","4bffc013":"Um sp\u00e4ter ordentlich mit den Daten arbeiten zu k\u00f6nnen, m\u00fcssen Sie erst aufbereitet werden.\nEin Datum, das h\u00e4ufig Schwierigkeiten bereitet ist das kalendarische Datum. Das wird je nach Region anders geschrieben und als Text gespeichert.\nGl\u00fccklicherweise bringt Pandas ein Tool mit, dass Datumsangaben problemlos aufbereitet und interpretiert, solange das Format nicht absolut kaputt ist.\nDaf\u00fcr gibt es die pandas Datetime Funktionen. https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.to_datetime.html \n\nHole dir mit \n```\n\"data.Date.describe()\" \n```\neine \u00dcbersicht \u00fcber die aktuellen Datumsangaben\n\nWandel die Datumsangaben in der Spalte \"Date\" in echte Datumsangaben um verwende daf\u00fcr pd.to_Datetime(~Daten).\n\n```\ndatensatz[\"Datumspalte\"] = pd.to_Datetime(datensatz[\"Datumspalte\"])\n```\n\nSchaue dir danach nochmal die \u00dcbersicht mit \"data.Date.describe()\" an.\nIhr k\u00f6nnt jetzt viel mehr \u00fcber die Daten ablesen, da der Dataframe und die Datumsangaben als solche Interpretieren kann.\n\nGib die komplette Angabe von \"last\" in der \u00dcbersicht als String in Ergebnis 7 an.\n","e5a067f4":"# Aufgaben\nIn diesem Notebook werdet Ihr die Grundlagen der Daten-Exploration \u00fcben.\nDazu werden wir vor Allem auf die Bibliotheken numpy und pandas setzen.\n\nBereitet alle Aufgaben bis zur n\u00e4chsten Worksession vor.\nSchreibt euch alle Fragen auf, damit wir diese in der Session beantworten k\u00f6nnen.\nEs ist nicht schlimm, wenn nicht alle L\u00f6sungen auf Anhieb funktionieren.\nAm Ende des Notebooks gibt es ein Skript mit dem Ihr eure L\u00f6sungen zusammentragen und auf der Kaggle Seite pr\u00fcfen k\u00f6nnt.","c3474b4c":"--------------------------","1f99001d":"## Aufgabe 2: Daten betrachten\nBevor man gro\u00df Daten analysiert, macht es Sinn sich ersteinmal die Daten mit blo\u00dfem Auge und unver\u00e4ndert anzuschauen. Wenn man versteht, was in den Daten steht, l\u00e4sst sich viel einfacher damit arbeiten. Schaut euch die Daten genauer an. Was steht in den Spalten drin? \n\nLese zuerst die Namen aller Spalten aus. \n\nLass dir dann die ersten zehn Eintr\u00e4ge im Datensatz anzeigen.\n\n### Trage den Namen der letzten Spalte (als String) als Ergebnis drei am Ende des Notebooks ein.\n\n### Trage die Summe von AveragePrice der ersten zehn Eintr\u00e4ge als Ergebnis 4 ein. (gerundet auf zwei Nachkommstellen)\n\n### Trage das Datum des h\u00f6chsten Preises (als String) als Ergebnis 5 ein.\n\nTipp:","f48ebf16":"Eine fortgeschrittene Technik der Datenmodelierung ist Feature Extraction. Das umfasst alle Aktivit\u00e4ten, die neue Daten aus der Verarbeitung, Kombination oder Anreicherung von Daten in Datens\u00e4tzen beinhalten. Feature Extraction bindet das Wissen des Analysten in die Daten mit ein und generiert dadurch reichere Datens\u00e4tze. Weil die Informationen oftmals bereits vorhanden sind, spricht man hier von der Extraktion.\n\nIn unserem Avocado Datensatz k\u00f6nnen wir noch einige interessante Informationen herausholen.\nZum einen den Gesamtumsatz am angegebenen Tag und den inflationsbereinigten Preis. \n\nGl\u00fccklicherweise wissen wir, dass die Inflation seit 2015 im Durchschnitt 2.015% betrug. Der Einfachhalt halber rechnen wir alle Durchschnittspreise auf das Jahr 2018 hoch.\n\nTrage den bereinigten Preis am 29.11.2015 in Albany als Ergebnis 8 ein (drei Nachkommastellen).\n\nTipp:","914e1fc0":"Verwende die pandas Attribute\/Funktionen\n```\n.columns # shows list columns\n\n.head(<Count>) # Shows first <Count> rows in Dataset\n\n```\n.colums gibt eine Liste aus. Mithilfe von eckigen Klammern kann man das gew\u00fcnschte Element w\u00e4hlen.","92ef9fb1":"## Aufgabe 3: Datensatz bereinigen","69a92b8c":"----------------------------","8c616cbe":"## Aufgabe 1: Schema betrachten\n\nAls erstes wollen wir Wissen, womit wir es zu tun haben.\nBearbeiten wir hier einen riesigen Datensatz oder nur einen kleinen Auszug?\n\nJe nach Gr\u00f6\u00dfe muss man anders mit Daten umgehen.\n\nUntersuche die Datens\u00e4tze auf ihr Schema.\nWie viele Spalten und Zeilen haben die Daten?\nNotiere deine Ergebnisse in einer Markdown Zeile.\n\nTrage die Anzahl an Zeilen in Ergebnis 1 am Ende des Notebooks ein.\nTrage die Anzahl der Spalten als Ergebnis 2 ein.\n\nTipp:","67c35a3d":"## Aufgabe 4: Daten transformieren","65971fdb":"---------------------------------","550e50a4":"Mit:\n\n```\ndatensatz[\"neuer Spaltenname\"] = xyz\n```\n\nK\u00f6nnen wir neue Spalten hinzuf\u00fcgen.\n\nEine neue Spalte kann auch die Kombination anderer Saplten sein:\n```\ndatensatz[\"summe\"] = datensatz[\"A\"] + datensatz[\"B\"] # Addiert Spalten A und B zur Spalte Summe\ndatensatz[\"halbiert\"] = datensatz[\"A\"] \/ 2 # Halbiert alle Daten in Spalte A und speichert sie in einer neuen Spalte \"halbiert\"\n```\n\n\n\n","b869c57f":"# Ergebnisse \u00dcberpr\u00fcfen\nTrage hier deine Ergebnisse ein.\nDas kleine Script unten spuckt eine CSV Datei aus, die Ihr als \"prediction\" hochladen k\u00f6nnt.","13583a42":"---------------------------------","73fc6227":"Verwenden die pandas .shape funktion https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.shape.html","feaec4ec":"Mit .drop() k\u00f6nnt ihr Zeilen oder Spalten l\u00f6schen.\nmit axis bestimmt ihr, ob ihr Zeilen oder Spalten l\u00f6scht.\nUm eine Spalte mit dem Namen \"Spalte\" zu l\u00f6schen, w\u00fcrde das wie folgt aussehen:\n```\ndatensatz.drop([\"Spaltenname\"], axis = 1)\n```\n\nUm leere Spalten zu l\u00f6schen k\u00f6nnt Ihr .dropna (steht f\u00fcr drop not available) verwenden.\nmit dem attribute \"how\" bestimmt ihr was gel\u00f6scht werden soll.\n```\ndatensatz.dropna(how = \"any\") # L\u00f6scht alle Zeilen die fehlende Daten enthalten\ndatensatz.dropna(how=\"all\") # L\u00f6scht Zeilen in denen ALLE Spalten leer sind.\n```\n\nMehr Infos zum l\u00f6schen von Zeilen: https:\/\/www.kaggle.com\/aliendev\/example-of-pandas-dropna","e500d606":"Eine der Hauptaufgaben bei der Datenaufbereitung (engl. \"Data Wrangling\") ist das Bereinigen der Daten. Datens\u00e4tze aus der Wirtschaft sind nur in den seltensten F\u00e4llen sauber und sch\u00f6n aufbereitet wie dieser hier. Oftmals fehlen signifikante Mengen der Daten, die Spaltennamen sind kryptisch und ein Gro\u00dfteil der Daten ist redundant oder einfach falsch. Das ist aktuell vermutlich die gr\u00f6\u00dfte Herausforderung im Bereich von Data Analytics, Data Science und Machine Learning. \nWenn wir uns nicht auf die Daten verlassen k\u00f6nnen, k\u00f6nnen wir auf deren Basis auch keine Entscheidungen treffen.\n\nMit der Funktion \n```\ndatensatz.isnull().sum() \n```\n\nk\u00f6nnen wir herausfinden, wie viele Daten in der Tabelle fehlen.\nDiese sollten wir m\u00f6glichst entfernen, damit die Analyseergebnisse sp\u00e4ter nicht verf\u00e4lscht werden.\nAu\u00dferdem haben wir noch eine Spalte mit dem Namen \"Unnamed: 0\". Diese ist wohl ein \u00dcberbleibsel aus einem alten Speichervorgang. Die steht nur im Weg und liefert uns keine Informationen.\n\nL\u00f6sche zuerst die unn\u00f6tige Zeile aus dem Datensatz.\nSchaue dir dann die Anzahl fehlender Daten an.\nL\u00f6sche anschlie\u00dfend alle Zeilen mit fehlenden Daten.\n\n### Geben Sie die neue Anzahl an Zeilen als Ergebnis 6 an.\n\nTipp:","4370f595":"## Vorbereitung\nImportieren wir als erstes unsere Bibliotheken und den Trainingsdatensatz.\nDer Datensatz beinhaltet die Verkaufszahlen von Avocados der Sorte Hass aus den Jahren 2015 bis 2018. \n\nDiese Daten k\u00f6nnen aus verschiedenen Gr\u00fcnden interessant sein. Beispielsweise f\u00fcr Anleger, die auf Lebensmittelpreise spekulieren (Kein Fan). Aber auch f\u00fcr Restaurants oder Supermarktketten, die daran die Beliebtheit von Avocados ablesen und ihr Sortiment auf schwankende Preise anpassen k\u00f6nnen.","5529882b":"---------------------------------","908de3c4":"Jetzt seid Ihr an der Reihe!"}}