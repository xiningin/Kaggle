{"cell_type":{"972389ce":"code","ac8fd277":"code","7821fdc0":"code","7f8e66d1":"code","a3475d08":"code","e62fad64":"code","87cc510c":"code","f32dbbb4":"code","98689159":"code","943672cd":"code","28581e14":"code","48826c6a":"code","ce1ba581":"code","b6c3a046":"code","cd58b683":"code","3c09ba91":"code","20345c09":"code","c46b3d27":"code","91037c88":"code","676e7592":"code","a90bf3ce":"code","3226d209":"code","2ddbb9f5":"code","273f0dd8":"code","3055c28a":"code","726d4627":"code","8f5d565e":"code","0ec913ca":"code","32251456":"code","cbdbde13":"code","2fd94c0a":"code","e25758e4":"code","16485b77":"code","b95f9ff5":"code","28d20cca":"code","868fb441":"code","9ab7985e":"code","dcdfc2e8":"code","7e65e82b":"code","5e7459f2":"code","3004b429":"code","d3649d14":"code","6cc5607c":"code","a4831b3c":"code","1cbbd2a2":"code","8f0ceb34":"code","a55f0400":"markdown","02561fc4":"markdown","90036cfe":"markdown","01ca5497":"markdown","f7b246c9":"markdown","22339923":"markdown","8b89cd0e":"markdown","47d98b55":"markdown","ec00a7e7":"markdown","1803b6b0":"markdown","e7c0f2ce":"markdown","f14c0edb":"markdown","52fb1447":"markdown","eae89a57":"markdown","6cbcf3b6":"markdown","c9225ede":"markdown","f1937c3d":"markdown","4ba6ed80":"markdown","6e60ac1d":"markdown","6ab6daa8":"markdown","73cdcf9b":"markdown","52e68332":"markdown","978499db":"markdown","5930f20e":"markdown","73e32974":"markdown","58870448":"markdown","99485aa1":"markdown","1bdcc18a":"markdown"},"source":{"972389ce":"!pip install lofo-importance","ac8fd277":"import numpy as np\nimport pandas as pd\nimport os, gc\nfrom tqdm import tqdm\n\n\nROOT_DIR = \"\/kaggle\/input\/mlb-player-digital-engagement-forecasting\"\n\ndf = pd.read_csv(f\"{ROOT_DIR}\/train_updated.csv\")\nprint(df.shape)\ndf.head()","7821fdc0":"target_df = [eval(x) for x in tqdm(df[\"nextDayPlayerEngagement\"].values)]\n\nflatten = lambda t: [item for sublist in t for item in sublist]\n\n\ntarget_df = pd.DataFrame(flatten(target_df))\n\nprint(target_df.shape)\ntarget_df.head()","7f8e66d1":"roster_df = [eval(x) for x in tqdm(df[\"rosters\"].values) if str(x) != \"nan\"]\n\nroster_df = pd.DataFrame(flatten(roster_df)).drop([\"statusCode\"], axis=1).rename(columns={\"gameDate\": \"date\"})\n\nprint(roster_df.shape)\nroster_df.head()","a3475d08":"standings_df = [eval(x.replace(\":false\", \":False\").replace(\":true\", \":True\").replace(\":null\", \":None\")) for x in tqdm(df[\"standings\"].values) if str(x) != \"nan\"]\n\nstandings_df = pd.DataFrame(flatten(standings_df)).rename(columns={\"gameDate\": \"date\"})[[\"date\", \"teamId\", \"leagueRank\", \"lastTenWins\"]]\n\nprint(standings_df.shape)\nstandings_df.head()","e62fad64":"transaction_df = []\n\nfor x in tqdm(df[\"transactions\"].values):\n    if str(x) != \"nan\":\n        transaction_df.extend(eval(x.replace(\":null\", ':\"\"')))\n\ntransaction_df = pd.DataFrame(transaction_df)\n\nprint(transaction_df.shape)\ntransaction_df.head()","87cc510c":"scores_df = []\n\nfor x in tqdm(df[\"playerBoxScores\"].values):\n    if str(x) != \"nan\":\n        scores_df.extend(eval(x.replace(\":null\", ':\"\"')))\n\nscores_df = pd.DataFrame(scores_df)\n\nprint(scores_df.shape)\nscores_df.head()","f32dbbb4":"awards_df = [eval(x.replace(\":null\", ':\"\"')) for x in df[\"awards\"].values if str(x) != \"nan\"]\nawards_df = pd.DataFrame(flatten(awards_df))\nawards_df.shape","98689159":"twitter_df = []\n\nfor x in tqdm(df[\"playerTwitterFollowers\"].values):\n    if str(x) != \"nan\":\n        twitter_df.extend(eval(x.replace(\":null\", ':\"\"')))\n\ntwitter_df = pd.DataFrame(twitter_df)[[\"date\", \"playerId\", \"numberOfFollowers\"]]\ntwitter_df[\"date\"] = pd.to_datetime(twitter_df[\"date\"])\n\nprint(twitter_df.shape)\ntwitter_df.head()","943672cd":"players_df = pd.read_csv(f\"{ROOT_DIR}\/players.csv\")\n\navailable_players = players_df[players_df[\"playerForTestSetAndFuturePreds\"] == True][\"playerId\"].values\nlen(available_players)","28581e14":"target_df = target_df[target_df[\"playerId\"].isin(available_players)].reset_index(drop=True)\ntarget_df.shape","48826c6a":"targets = [\"target1\", \"target2\", \"target3\", \"target4\"]\n\n\ntarget_df[\"target_date\"] = pd.to_datetime(target_df[\"engagementMetricsDate\"])\ntarget_df['date'] = target_df['target_date'] -  pd.to_timedelta(1, unit='d')\n\ntarget_df[\"dom\"] = target_df[\"target_date\"].dt.day\ntarget_df[\"dow\"] = target_df[\"target_date\"].dt.dayofweek\ntarget_df[\"month\"] = target_df[\"target_date\"].dt.month - 1\ntarget_df[\"year\"] = target_df[\"target_date\"].dt.year\n\ntarget_df[\"time\"] = target_df[\"year\"]*12 + target_df[\"month\"]","ce1ba581":"target_df = target_df.merge(players_df[[\"playerId\", \"DOB\", \"mlbDebutDate\", \"birthCountry\", \"playerName\"]],\n                            on=\"playerId\", how=\"left\") ","b6c3a046":"target_df[\"age\"] = (target_df[\"date\"] - pd.to_datetime(target_df[\"DOB\"])).dt.days\ntarget_df[\"US_person\"] = 1*(target_df[\"birthCountry\"] == \"USA\")\ntarget_df[\"time_since_debut\"] = (target_df[\"date\"] - pd.to_datetime(target_df[\"mlbDebutDate\"])).dt.days\ntarget_df[\"jr\"] = target_df[\"playerName\"].apply(lambda x: \"Jr.\" in x)\ntarget_df[\"jr\"].mean()","cd58b683":"twitter_df[\"twitter_trend\"] = ((twitter_df[\"numberOfFollowers\"] + 1 - twitter_df.groupby(\"playerId\")[\"numberOfFollowers\"].shift())\n                               \/ (twitter_df[\"numberOfFollowers\"] + 1))\ntwitter_df[\"twitter_trend\"].clip(-0.2, 0.2).hist(bins=50)","3c09ba91":"target_df = target_df.merge(twitter_df, on=[\"date\", \"playerId\"], how=\"left\")\n\ntarget_df[\"numberOfFollowers\"] = target_df.groupby(\"playerId\")[\"numberOfFollowers\"].fillna(method=\"ffill\")\ntarget_df[\"twitter_trend\"] = target_df.groupby(\"playerId\")[\"twitter_trend\"].fillna(method=\"ffill\")","20345c09":"awards_df.loc[awards_df.groupby(\"awardId\")[\"awardDate\"].transform(\"count\") < 3, \"awardName\"] = \"Other\"\nawards_df[\"awardName\"].value_counts()","c46b3d27":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nawards_df[\"awardType\"] = le.fit_transform(awards_df[\"awardName\"])","91037c88":"awards_df = awards_df.groupby([\"awardDate\", \"playerId\"])[\"awardType\"].first().reset_index().rename(columns={\"awardDate\": \"date\"})\nawards_df[\"date\"] = pd.to_datetime(awards_df[\"date\"])\nawards_df[\"award_date\"] = awards_df[\"date\"].values\nawards_df.head()","676e7592":"target_df = target_df.merge(awards_df, how=\"left\", on=[\"date\", \"playerId\"])\ntarget_df[\"award_date\"].isnull().mean()","a90bf3ce":"target_df[\"award_date\"] = target_df.groupby(\"playerId\")[\"award_date\"].fillna(method=\"ffill\")\ntarget_df[\"awardType\"] = target_df.groupby(\"playerId\")[\"awardType\"].fillna(method=\"ffill\")","3226d209":"target_df[\"time_since_award\"] = (target_df[\"date\"] - target_df[\"award_date\"]).dt.days\ntarget_df[\"time_since_award\"].hist()","2ddbb9f5":"roster_df.loc[roster_df.groupby(\"status\")[\"date\"].transform(\"count\") < 20, \"status\"] = \"Other\"\nroster_df[\"status\"].value_counts()","273f0dd8":"le = LabelEncoder()\nroster_df[\"status\"] = le.fit_transform(roster_df[\"status\"])","3055c28a":"roster_df[\"date\"] = pd.to_datetime(roster_df[\"date\"])\n\ntarget_df = target_df.merge(roster_df, how=\"left\", on=[\"date\", \"playerId\"])\ntarget_df[\"status\"].isnull().mean(), target_df[\"teamId\"].isnull().mean()","726d4627":"transaction_df[\"date\"] = pd.to_datetime(transaction_df[\"date\"])\ntransaction_df[\"effectiveDate\"] = pd.to_datetime(transaction_df[\"effectiveDate\"])\n\n\nle = LabelEncoder()\ntransaction_df[\"transfer_type\"] = le.fit_transform(transaction_df[\"typeCode\"])","8f5d565e":"target_df = target_df.merge(transaction_df[[\"playerId\", \"date\", \"effectiveDate\", \"transfer_type\"]], \n                            how=\"left\", on=[\"date\", \"playerId\"])","0ec913ca":"target_df[\"effectiveDate\"] = target_df.groupby(\"playerId\")[\"effectiveDate\"].fillna(method=\"ffill\")\ntarget_df[\"transfer_type\"] = target_df.groupby(\"playerId\")[\"transfer_type\"].fillna(method=\"ffill\")\n\ntarget_df[\"time_since_transfer\"] = (target_df[\"date\"] - target_df[\"effectiveDate\"]).dt.days\ntarget_df[\"time_since_transfer\"].hist()","32251456":"scores_df.rename(columns={\"gameDate\": \"date\"}, inplace=True)\nscores_df[\"date\"] = pd.to_datetime(scores_df[\"date\"])\n\nscores_features = ['totalBases', 'strikeOutsPitching', 'plateAppearances', \n                   'homeRuns', 'inningsPitched', 'saves', 'rbi']\ntarget_df = target_df.merge(scores_df[[\"playerId\", \"date\"] + scores_features], on=[\"playerId\", \"date\"], how=\"left\")\n\ntarget_df[scores_features].isnull().mean()","cbdbde13":"def f(x):\n    y = np.zeros(len(x))\n    \n    for i, el in enumerate(x):\n        if el or (i == 0):\n            y[i] = 0\n        else:\n            y[i] = y[i-1] + 1\n    return y\n            \n\ntarget_df[\"no_game_since\"] = target_df[\"rbi\"].notnull()\ntarget_df[\"no_game_since\"] = target_df.groupby(\"playerId\")[\"no_game_since\"].transform(f)\ntarget_df[\"no_game_since\"].hist()","2fd94c0a":"for col in tqdm(scores_features):\n    target_df[col] = target_df.groupby(\"playerId\")[col].fillna(method=\"ffill\")","e25758e4":"def to_float(x):\n    try:\n        return float(x)\n    except:\n        pass\n    return None\n\n\nfor col in scores_features:\n    target_df[col] = target_df[col].apply(to_float)\n    \ntarget_df[\"playerId\"] = target_df[\"playerId\"].astype(int)","16485b77":"standings_df[\"date\"] = pd.to_datetime(standings_df[\"date\"])\n\ntarget_df = target_df.merge(standings_df, on=[\"teamId\", \"date\"], how=\"left\")\nstanding_features = [\"leagueRank\", \"lastTenWins\"]\n\nfor col in standing_features:\n    target_df[col] = target_df.groupby(\"playerId\")[col].fillna(method=\"ffill\")","b95f9ff5":"FUTURE = 20\n\nlags = np.array([21, 28, 35])\nassert np.all(lags > FUTURE)\n\n\n\nfor lag in lags:\n    for t in tqdm(targets):\n        fname = f\"lag{lag}_{t}\"\n        target_df[fname] = target_df.groupby(\"playerId\")[t].shift(lag)\n        \n        if lag == 28:\n            for period in [4*7, 52*7]:\n                fname = f\"std{period}_{lag}_{t}\"\n                target_df[fname] = target_df.groupby(\"playerId\")[t].rolling(period).std().reset_index().sort_values(\"level_1\")[t].values\n                target_df[fname] = target_df.groupby(\"playerId\")[fname].shift(lag)\n                fname = f\"mean{period}_{lag}_{t}\"\n                target_df[fname] = target_df.groupby(\"playerId\")[t].rolling(period).mean().reset_index().sort_values(\"level_1\")[t].values\n                target_df[fname] = target_df.groupby(\"playerId\")[fname].shift(lag)","28d20cca":"for t in targets:\n    target_df[f\"dif_{t}\"] = target_df[f\"lag21_{t}\"] - target_df[f\"lag28_{t}\"]\n    target_df[f\"diff_{t}\"] = target_df[f\"dif_{t}\"] - (target_df[f\"lag28_{t}\"] - target_df[f\"lag35_{t}\"])","868fb441":"VAL_MONTHS = {12*2019 + 7, 12*2019 + 8, 12*2020 + 7, 12*2020 + 8, 12*2021 + 4}\n# 2019 August, September, 2020 August, September, 2021 May\nVAL_MONTHS = target_df[(target_df[\"year\"]*12 + target_df[\"month\"]).isin(VAL_MONTHS)][\"time\"].drop_duplicates().values\n\ncv_scheme = []\n\nfor valm in VAL_MONTHS:\n    train_ind = np.where(target_df[\"time\"].values < valm)[0]\n    val_ind = np.where(target_df[\"time\"].values == valm)[0]\n    cv_scheme.append((train_ind, val_ind))\nVAL_MONTHS","9ab7985e":"categoricals = [\"year\", \"dow\", \"awardType\", \"transfer_type\", \"status\", \"playerId\", \"teamId\", \"month\"]\nnumericals = [\"time_since_award\", \"time_since_transfer\", \"no_game_since\",\n              \"age\", \"time_since_debut\", \"US_person\", \"jr\", \"twitter_trend\", \"numberOfFollowers\"]\nfeatures = list(categoricals) + list(numericals)","dcdfc2e8":"target_features = {f\"{t}_features\": target_df[[f\"lag21_{t}\", f\"dif_{t}\", f\"diff_{t}\",\n                                               f\"std28_28_{t}\", f\"mean28_28_{t}\",\n                                               f\"std364_28_{t}\", f\"mean364_28_{t}\"]].values for t in targets}\n\ntarget_features[\"scores_features\"] = target_df[scores_features].values\ntarget_features[\"standing_features\"] = target_df[standing_features].values\n\ntarget_features.keys()","7e65e82b":"from lofo import Dataset, LOFOImportance, plot_importance\nfrom lightgbm import LGBMClassifier, LGBMRegressor\n\n\ndef get_importance(target_name):\n    model = LGBMRegressor(min_child_samples=20, n_jobs=-1, objective=\"huber\", alpha=0.1,\n                          n_estimators=100)\n    dataset = Dataset(df=target_df, target=target_name, features=features, feature_groups=target_features)\n    lofo_imp = LOFOImportance(dataset, cv=cv_scheme, scoring=\"neg_mean_absolute_error\", model=model,\n                              fit_params={\"categorical_feature\": categoricals})\n    return lofo_imp.get_importance()\n\n\nimportance_df = get_importance(\"target1\")\nplot_importance(importance_df, figsize=(8, 8), kind=\"default\")","5e7459f2":"model = LGBMRegressor(min_child_samples=20, n_jobs=-1, objective=\"huber\", alpha=0.1,\n                      n_estimators=100)\ndataset = Dataset(df=target_df, target=\"target1\", \n                  features=[\"no_game_since\", \"teamId\", \"status\", \"month\"], \n                  feature_groups={\"target1_features\": target_features[\"target1_features\"],\n                                  \"scores_features\": target_features[\"scores_features\"]})\nlofo_imp = LOFOImportance(dataset, cv=cv_scheme, scoring=\"neg_mean_absolute_error\", model=model,\n                          fit_params={\"categorical_feature\": [\"teamId\", \"status\", \"month\"]})\n\nplot_importance(lofo_imp.get_importance(), figsize=(8, 4), kind=\"box\")","3004b429":"importance_df = get_importance(\"target2\")\nplot_importance(importance_df, figsize=(8, 8), kind=\"default\")","d3649d14":"model = LGBMRegressor(min_child_samples=20, n_jobs=-1, objective=\"huber\", alpha=0.1,\n                      n_estimators=100)\ndataset = Dataset(df=target_df, target=\"target2\", \n                  features=[\"no_game_since\", \"teamId\", \"status\", \"month\"], \n                  feature_groups={\"target2_features\": target_features[\"target2_features\"],\n                                  \"scores_features\": target_features[\"scores_features\"]})\nlofo_imp = LOFOImportance(dataset, cv=cv_scheme, scoring=\"neg_mean_absolute_error\", model=model,\n                          fit_params={\"categorical_feature\": [\"teamId\", \"status\", \"month\"]})\n\nplot_importance(lofo_imp.get_importance(), figsize=(8, 4), kind=\"box\")","6cc5607c":"importance_df = get_importance(\"target3\")\nplot_importance(importance_df, figsize=(8, 8), kind=\"default\")","a4831b3c":"model = LGBMRegressor(min_child_samples=20, n_jobs=-1, objective=\"huber\", alpha=0.1,\n                      n_estimators=100)\ndataset = Dataset(df=target_df, target=\"target3\", \n                  features=[\"no_game_since\", \"time_since_transfer\", \"status\", \"month\"], \n                  feature_groups={\"target3_features\": target_features[\"target3_features\"],\n                                  \"scores_features\": target_features[\"scores_features\"]})\nlofo_imp = LOFOImportance(dataset, cv=cv_scheme, scoring=\"neg_mean_absolute_error\", model=model,\n                          fit_params={\"categorical_feature\": [\"status\", \"month\"]})\n\nplot_importance(lofo_imp.get_importance(), figsize=(8, 4), kind=\"box\")","1cbbd2a2":"importance_df = get_importance(\"target4\")\nplot_importance(importance_df, figsize=(8, 8), kind=\"default\")","8f0ceb34":"model = LGBMRegressor(min_child_samples=20, n_jobs=-1, objective=\"huber\", alpha=0.1,\n                      n_estimators=100)\ndataset = Dataset(df=target_df, target=\"target4\", \n                  features=[\"no_game_since\", \"playerId\", \"status\", \"month\"], \n                  feature_groups={\"target4_features\": target_features[\"target4_features\"],\n                                  \"scores_features\": target_features[\"scores_features\"]})\nlofo_imp = LOFOImportance(dataset, cv=cv_scheme, scoring=\"neg_mean_absolute_error\", model=model,\n                          fit_params={\"categorical_feature\": [\"playerId\", \"status\", \"month\"]})\n\nplot_importance(lofo_imp.get_importance(), figsize=(8, 4), kind=\"box\")","a55f0400":"# Twitter Feature Extraction\n* Number of followers\n* Twitter trend: Percentage increase\/decrease in followers compared to last month","02561fc4":"# Player Feature Extraction\n* Age of player\n* If the player is from US or not\n* Time since his debut date\n* Is he a jr (son of a previous well-known MLB player) ?","90036cfe":"**no_game_since** and **scores_features** are important but not as much as they were for **target1**. And **month** feature has high std meaning that it is probably not consistently improtant across the all validation sets. The most important features are **target2** lag features and **status** feature.","01ca5497":"**scores_features** and **no_games_since** are the only significantly important features. teamId, target1_features, status, month also look important but not significant enough. **playerId** seems to be a harmful feature for target1, meaning that it causes overfitting and we can benefit from removing this feature. Most of the features seem to be either redundant or not useful. One would expect lag features of **target1** to have the highest importance but LOFO Importance is the importance of a feature given that you have the other features. So it is about how much it can make a difference. Having target2, target3, target4 lag features and playerId, target1 lag features seem to be redundant.\n\nLet's repeat the experiment with less features:\n","f7b246c9":"# Target Lag Features\n\n**Since the competition task is to predict the digital engagement for 45 days, we need to be careful with lag features. We won't have yesterday's target values for day 10 for example. In order to simplify the problem for feature importance, we can assume that we want to predict for the 20th day. So all lag features should be calculated before the 20th day. Mean and std for the last available month and year are calculated.**","22339923":"**target1** lag features now have larger importance but still less than **scores_features** and **no_games_since**. We can say that the target values for previous month and year is not very important for **target1**. **target1** mainly depends on **Player Box Scores** data.","8b89cd0e":"### LOFO allows us to group features. This prevents highly correlated features to have underestimated importance.","47d98b55":"**status**, **target2_features**, **scores_features**, **no_game_since** and **month** seem to be the important features. Let's repeat the experiment with less features.","ec00a7e7":"# Transaction Feature Extraction\n* Transfer type\n* Time since transfer","1803b6b0":"# Validation Scheme: Time-based Cross-validation\n\n**We need to split the data by time, because our model gets applied on future data. But one time split is not enough, therefore we can pick 5 months as validation sets and the other months before them as training set. The competition will run on August-September, therefore these 2 months are good choices to be included in validation and at least one month from 2021 would be nice.**\n* August 2019\n* September 2019\n* August 2020\n* September 2020\n* May 2021\n\n![](https:\/\/miro.medium.com\/max\/558\/1*AXRu72CV1hdjLfODFGbMWQ.png)","e7c0f2ce":"# target3","f14c0edb":"**target3** lag features are the most important ones. One interesting thing is that while **scores_features** are important, **no_game_since** feature is harmful. For some reason, **Player Box Scores** data is useful for **target3** but only the recent scores without knowing how many days old they are. But there is very small signal overall for **target**, it is difficult to make strong conclusions.","52fb1447":"### Only the evaluated players will be used for this analysis","eae89a57":"**no_game_since** is a harmful feature. It probably means that behavior of **no_game_since** changes over time. Learning its behavior in interaction with other features has more harm than its benefits for **target4**.","6cbcf3b6":"# Awards Feature Extraction\n* Award type\n* Time since award","c9225ede":"**target4** lag features, **playerId** and **status** are important features but they have small mean\/std ratios. So they are not robust across different validation sets. **time_since_debut** is a consistently harmful feature but its performance degradation is not significant.","f1937c3d":"# Read the data","4ba6ed80":"# Summary\n* **target1** mostly depends on the player's individual game performances.\n* Previous target2 values are very predictive for **target2** and status is also very important.\n* There is very little signal for **target3** and **target4**. Target lag features are useful and robust compared to other features. And **no_games_since** is a harmful feature for these targets.","6e60ac1d":"# target1","6ab6daa8":"# Applying LOFO\n* Model: LGBMRegressor with Huber loss\n* Metric: Mean Absolute Error\n* CV: 5 time splits\n\n**Green bars represent useful, red bars represent harmful features. We can also see the standard deviation of importance. This helps us understand if the feature is really important or it is a noisy estimation.**","73cdcf9b":"### Individual features including categoricals","52e68332":"# Scores Feature Extraction\n* Total Bases\n* Strike outs Pitching\n* Plate Appearances\n* Home Runs\n* Innings Pitched\n* Saves\n* rbi\n* No game since","978499db":"# Roster Feature Extraction\n* Status","5930f20e":"**scores_features** and **all target lag features** seem to be important and **no_game_since** is a harmful feature. We can repeat the experiment with less features:","73e32974":"# target4","58870448":"# MLB Feature Importance with LOFO\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/tr\/4\/48\/MLB_Belirtke.png)\n![](https:\/\/raw.githubusercontent.com\/aerdem4\/lofo-importance\/master\/docs\/lofo_logo.png)\n\n**LOFO** (Leave One Feature Out) Importance calculates the importances of a set of features based on **a metric of choice**, for **a model of choice**, by **iteratively removing each feature from the set**, and **evaluating the performance** of the model, with **a validation scheme of choice**, based on the chosen metric.\n\nLOFO first evaluates the performance of the model with all the input features included, then iteratively removes one feature at a time, retrains the model, and evaluates its performance on a validation set. The mean and standard deviation (across the folds) of the importance of each feature is then reported.\n\nWhile other feature importance methods usually calculate how much a feature is used by the model, LOFO estimates how much a feature can make a difference by itself given that we have the other features. Here are some advantages of LOFO:\n* It generalises well to unseen test sets since it uses a validation scheme.\n* It is model agnostic.\n* It gives negative importance to features that hurt performance upon inclusion.\n* It can group the features. Especially useful for high dimensional features like TFIDF or OHE features. It is also good practice to group very correlated features to avoid misleading results.\n\nhttps:\/\/github.com\/aerdem4\/lofo-importance","99485aa1":"# Standing Features\n* League Rank\n* Last Ten Wins","1bdcc18a":"# target2"}}