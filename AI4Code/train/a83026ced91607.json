{"cell_type":{"a54562eb":"code","7cd7398b":"code","75c46400":"code","535040e7":"code","93cad2c7":"code","21f362cc":"code","3d6b5613":"code","ea591d03":"code","3d3f5738":"code","87c67848":"code","2531d442":"code","0181bfc0":"code","b911c924":"code","cb8dea5b":"code","dddf4b5f":"code","a0fa84fd":"code","b540cbc2":"code","97030dbe":"code","fc2f2c5e":"code","0c53cce6":"code","0f9d2567":"code","5f9d55a3":"code","267a2134":"code","b808f2bb":"code","4baaf048":"code","3d0cd7e1":"code","eede07fd":"code","8477cc8e":"code","1535cd4c":"code","82350e5a":"code","7ce67868":"code","65af5fea":"code","767d81ee":"code","40d98955":"code","6cba44cf":"code","1a452b22":"code","fd14b519":"code","27196976":"markdown","8451861c":"markdown","a13649e9":"markdown","faa40831":"markdown","69188940":"markdown","02840e9c":"markdown","c2543e90":"markdown","0e1e8c01":"markdown","25673840":"markdown","c5e2a2dc":"markdown","b3883af0":"markdown","03e9084d":"markdown","0cccfbdc":"markdown","47555973":"markdown","72583046":"markdown","6c5f0507":"markdown","854293c3":"markdown","5cbee2dd":"markdown","df14fb20":"markdown","7fd07d7d":"markdown","a7f95b3b":"markdown","7e0d0124":"markdown","f7e3bfbd":"markdown","7ed42bdf":"markdown","2a93882e":"markdown","e1b4faf7":"markdown","e6862e1c":"markdown","c297f920":"markdown","2d4c3647":"markdown","4e6f381a":"markdown","45361528":"markdown","c9360c0c":"markdown","11580be1":"markdown","ce9a2945":"markdown","0b25720d":"markdown","49b9971b":"markdown","ea8fe9ef":"markdown","e7bb4fab":"markdown","acc38d6d":"markdown","e6bebe36":"markdown","3f521f18":"markdown","ff459475":"markdown","a16be606":"markdown"},"source":{"a54562eb":"# Importa\u00e7\u00e3o dos pacotes\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.patches as mpatches\n\n# Seed para reprodu\u00e7\u00e3o de resultados\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)","7cd7398b":"data = pd.read_csv(r'..\/input\/inadimplncia-de-clientes-de-carto-de-crdito\/default of credit card clients - Data (1).csv')\ndata.head()","75c46400":"# Alterando nome de default payment next month para defaulted para poder fazer as:\n\ndata = data.rename(columns = {'default payment next month': 'defaulted'})\n\nlen(data)","535040e7":"# Distribui\u00e7\u00e3o por Sexo\n\nsexo = data.SEX\nsexo = sexo.replace(to_replace = 1,value='Homem')\nsexo = sexo.replace(to_replace = 2,value='Mulher')\nsexo = sexo.to_frame()\n\ngraph = sns.countplot(data=sexo, x='SEX',palette=\"muted\", order = sexo['SEX'].value_counts().index)\nplt.title('Distribui\u00e7\u00e3o por Sexo')\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(sexo[\"SEX\"].value_counts(normalize=True)[idx]), \n               ha=\"center\")\n    \ngraph.set(xlabel=None)\nplt.xlabel('Sexo')\nplt.ylabel('Quantidade')\nplt.ylim(0,30000)\nplt.show()","93cad2c7":"# Distribui\u00e7\u00e3o por Educa\u00e7\u00e3o\n\nedu = data.EDUCATION\nedu = edu.replace(to_replace = 0,value='N\u00e3o Especificado')\nedu = edu.replace(to_replace = 1,value='P\u00f3s-Gradua\u00e7\u00e3o')\nedu = edu.replace(to_replace = 2,value='Universidade')\nedu = edu.replace(to_replace = 3, value = 'Ensino M\u00e9dio')\nedu = edu.replace(to_replace = 4, value = 'Outros')\nedu = edu.replace(to_replace = 5,value='N\u00e3o Especificado')\nedu = edu.replace(to_replace = 6,value='N\u00e3o Especificado')\nedu = edu.to_frame()\n\nplt.subplots(1,figsize=(10,5))\ngraph = sns.countplot(data=edu, x='EDUCATION',  palette=\"muted\", order = edu['EDUCATION'].value_counts().index)\n\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(edu[\"EDUCATION\"].value_counts(normalize=True)[idx]), \n               ha=\"center\")\n\nplt.title('Distribui\u00e7\u00e3o por Nivel Forma\u00e7\u00e3o')\nplt.xlabel('Nivel Escolaridade')\nplt.ylabel('Quantidade')\nplt.xticks(rotation=45)\n    \ngraph.set(xlabel=None)\nplt.ylim(0,30000)\nplt.show()  ","21f362cc":"# Distribui\u00e7\u00e3o por Estado Civil\n\nmarriage = data.MARRIAGE\nmarriage = marriage.replace(to_replace = 1,value='Casado')\nmarriage = marriage.replace(to_replace = 2,value='Solteiro')\nmarriage = marriage.replace(to_replace = 3,value='Outros')\nmarriage = marriage.replace(to_replace = 0, value ='N\u00e3o Especificado')\nmarriage = marriage.to_frame()\n\nplt.subplots(1,figsize=(10,5))\ngraph = sns.countplot(data=marriage, x='MARRIAGE', palette=\"muted\", order = marriage['MARRIAGE'].value_counts().index)\n\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(marriage[\"MARRIAGE\"].value_counts(normalize=True)[idx]), \n               ha=\"center\")\n    \n\nplt.title('Distribui\u00e7\u00e3o por Estado Civil')\nplt.xlabel('Nivel Escolaridade')\nplt.ylabel('Quantidade')\n \ngraph.set(xlabel=None)\nplt.ylim(0,30000)\nplt.show()","3d6b5613":"age = data[['AGE', 'defaulted']]\n\nplt.hist(age['AGE'], bins=20, rwidth=0.9)\nplt.title('Distribui\u00e7\u00e3o por Faixa Et\u00e1ria')\nplt.plot()\n\n# create a list of our conditions\nconditions = [\n    (age['AGE'] < 30),\n    (age['AGE'] >= 30) & (age['AGE'] < 40),\n    (age['AGE'] >= 40) & (age['AGE'] < 50),\n    (age['AGE'] >= 50) & (age['AGE'] < 60),\n    (age['AGE'] >= 60) & (age['AGE'] < 70),\n    (age['AGE'] >= 70) & (age['AGE'] < 80),\n    (age['AGE'] >= 80),\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['20s', '30s', '40s', '50s', '60s', '70s', 'maior ou igual a 80']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\nage['new_Age'] = np.select(conditions, values)\n\n# display updated DataFrame\nage.head()\n\nage['new_Age'].value_counts()","ea591d03":"# Distribui\u00e7\u00e3o por Faixa Et\u00e1ria\n\nplt.subplots(1,figsize=(10,5))\ngraph = sns.countplot(data=age, x='new_Age', palette=\"muted\", order = age['new_Age'].value_counts().index)\n\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(age[\"new_Age\"].value_counts(normalize=True)[idx]), \n               ha=\"center\")\n    \n\nplt.title('Distribui\u00e7\u00e3o por faixa et\u00e1ria')\nplt.xlabel('Faixa et\u00e1ria')\nplt.ylabel('Quantidade')\n \ngraph.set(xlabel=None)\nplt.ylim(0,30000)\nplt.show()","3d3f5738":"# set the figure size\nplt.figure(figsize=(8, 6))\n\nsexo = data[[\"SEX\",\"defaulted\"]]\nsexo = sexo.replace({\"SEX\" : {1:'Homem', 2:'Mulher'}})\n\n# from raw value to percentage\ntotal = sexo.groupby('SEX')['defaulted'].count().reset_index()\npay = sexo[sexo.defaulted==1].groupby('SEX').count().reset_index()\npay['defaulted'] = [i \/ j * 100 for i,j in zip(pay['defaulted'], total['defaulted'])]\ntotal['defaulted'] = [i \/ j * 100 for i,j in zip(total['defaulted'], total['defaulted'])]\n\n# bar chart 1 -> top bars (group of 'defaulted = 0')\nbar1 = sns.barplot(x=\"SEX\",  y=\"defaulted\", data=total, color='lightgray')\n\n\n# bar chart 2 -> bottom bars (group of 'defaulted = 1')\nbar2 = sns.barplot(x=\"SEX\", y=\"defaulted\", data=pay, color='green')\n\n# add legend\ntop_bar = mpatches.Patch(color='lightgray', label='N\u00e3o Pagou')\nbottom_bar = mpatches.Patch(color='green', label='Pagou')\nplt.legend(handles=[top_bar, bottom_bar])\nplt.xlabel('Sexo')\nplt.ylabel('100% da An\u00e1lise')\n# show the graph\nplt.show()","87c67848":"# set the figure size\nplt.figure(figsize=(18, 6))\n\nedu = data[[\"EDUCATION\",\"defaulted\"]]\nedu = edu.replace({\"EDUCATION\" : {0:'5-NE',1:'3-P\u00f3s Gradua\u00e7\u00e3o', 2:'2-Universidade', 3:'1-Ensino M\u00e9dio',4:'4-Outros',5:'5-NE',6:'5-NE'}})\n\n# from raw value to percentage\ntotal = edu.groupby('EDUCATION')['defaulted'].count().reset_index()\npay = edu[edu.defaulted==1].groupby('EDUCATION').count().reset_index()\npay['defaulted'] = [i \/ j * 100 for i,j in zip(pay['defaulted'], total['defaulted'])]\ntotal['defaulted'] = [i \/ j * 100 for i,j in zip(total['defaulted'], total['defaulted'])]\n\n# bar chart 1 -> top bars (group of 'defaulted = 0')\nbar1 = sns.barplot(x=\"EDUCATION\",  y=\"defaulted\", data=total, color='lightgray')\n\n# bar chart 2 -> bottom bars (group of 'defaulted = 1')\nbar2 = sns.barplot(x=\"EDUCATION\", y=\"defaulted\", data=pay, color='green')\n\n# add legend\ntop_bar = mpatches.Patch(color='lightgray', label='N\u00e3o Pagou')\nbottom_bar = mpatches.Patch(color='green', label='Pagou')\nplt.legend(handles=[top_bar, bottom_bar])\n\n# show the graph\nplt.title('Pagantes e n\u00e3o pagantes por N\u00edvel de Forma\u00e7\u00e3o')\nplt.xlabel('Nivel de Forma\u00e7\u00e3o')\nplt.ylabel('100% da An\u00e1lise')\n           \nplt.show()","2531d442":"# set the figure size\nplt.figure(figsize=(18, 6))\n\nmarriage = data[[\"MARRIAGE\",\"defaulted\"]]\nmarriage = marriage.replace({\"MARRIAGE\" : {0:'NE',1:'2-Casado', 2:'1-Solteiro', 3:'3-Outros'}})\n\n# from raw value to percentage\ntotal = marriage.groupby('MARRIAGE')['defaulted'].count().reset_index()\npay = marriage[marriage.defaulted==1].groupby('MARRIAGE').count().reset_index()\npay['defaulted'] = [i \/ j * 100 for i,j in zip(pay['defaulted'], total['defaulted'])]\ntotal['defaulted'] = [i \/ j * 100 for i,j in zip(total['defaulted'], total['defaulted'])]\n\n# bar chart 1 -> top bars (group of 'defaulted = 0')\nbar1 = sns.barplot(x=\"MARRIAGE\",  y=\"defaulted\", data=total, color='lightgray')\n\n# bar chart 2 -> bottom bars (group of 'defaulted = 1')\nbar2 = sns.barplot(x=\"MARRIAGE\", y=\"defaulted\", data=pay, color='green')\n\n# add legend\ntop_bar = mpatches.Patch(color='lightgray', label='N\u00e3o Pagou')\nbottom_bar = mpatches.Patch(color='green', label='Pagou')\nplt.legend(handles=[top_bar, bottom_bar])\n\n# show the graph\nplt.title('Pagantes e n\u00e3o pagantes por estado civil')\nplt.ylabel('100% da An\u00e1lise')\n           \nplt.show()","0181bfc0":"# set the figure size\nplt.figure(figsize=(18, 6))\n\n# from raw value to percentage\ntotal = age.groupby('new_Age')['defaulted'].count().reset_index()\npay = age[marriage.defaulted==1].groupby('new_Age').count().reset_index()\npay['defaulted'] = [i \/ j * 100 for i,j in zip(pay['defaulted'], total['defaulted'])]\ntotal['defaulted'] = [i \/ j * 100 for i,j in zip(total['defaulted'], total['defaulted'])]\n\n# bar chart 1 -> top bars (group of 'defaulted = 0')\nbar1 = sns.barplot(x=\"new_Age\",  y=\"defaulted\", data=total, color='lightgray')\n\n# bar chart 2 -> bottom bars (group of 'defaulted = 1')\nbar2 = sns.barplot(x=\"new_Age\", y=\"defaulted\", data=pay, color='green')\n\n# add legend\ntop_bar = mpatches.Patch(color='lightgray', label='N\u00e3o Pagou')\nbottom_bar = mpatches.Patch(color='green', label='Pagou')\nplt.legend(handles=[top_bar, bottom_bar])\n\n# show the graph\nplt.title('Pagantes e n\u00e3o pagantes por faixa et\u00e1ria')\nplt.ylabel('100% da An\u00e1lise')\nplt.xlabel('Idade')\nplt.show()","b911c924":"data = pd.read_csv(r'..\/input\/inadimplncia-de-clientes-de-carto-de-crdito\/default of credit card clients - Data (1).csv')\n\n\ndata.head()","cb8dea5b":"data.rename({'SEX':'Sexo',\n             'EDUCATION':'Escolaridade',\n             'MARRIAGE':'Estado_Civil',\n             'AGE': 'Idade',\n             'PAY_6': 'Status_Pg_Apr', \n           'PAY_5': 'Status_Pg_May', \n           'PAY_4': 'Status_Pg_Jun', \n           'PAY_3': 'Status_Pg_Jul', \n           'PAY_2': 'Status_Pg_Aug', \n           'PAY_0': 'Status_Pg_Sep',\n           'BILL_AMT6': 'Tot_Apr', \n           'BILL_AMT5': 'Tot_May', \n           'BILL_AMT4': 'Tot_Jun',\n           'BILL_AMT3': 'Tot_Jul', \n           'BILL_AMT2': 'Tot_Aug', \n           'BILL_AMT1': 'Tot_Sep',\n           'PAY_AMT6': 'Pg_Apr', \n           'PAY_AMT5': 'Pg_May', \n           'PAY_AMT4': 'Pg_Jun',\n           'PAY_AMT3': 'Pg_Jul', \n           'PAY_AMT2': 'Pg_Aug', \n           'PAY_AMT1': 'Pg_Sep',\n           'default payment next month': 'defaulted'}, \n           axis=1, inplace=True)\n\n# Retirando coluna de ID e Agrupando valores para Forma\u00e7\u00e3o e Estado Civil:\ndata = data.drop(['ID'], axis=1)\ndata['Escolaridade'] = data['Escolaridade'].replace([0,5,6],[4,4,4])\ndata['Estado_Civil'] =  data['Estado_Civil'].replace([0],[3])\n\nlen(data)","dddf4b5f":"default = data.defaulted\ndefault = default.replace(to_replace = 0,value='N\u00e3o Pagou')\ndefault = default.replace(to_replace = 1,value='Pagou')\ndefault = default.to_frame()\nplt.subplots(figsize=(5,5))\ngraph = sns.countplot(data=default, x='defaulted')\nplt.title('Pagamentos do pr\u00f3ximo m\u00eas')\nplt.xlabel('Status Pagamento ')\nplt.ylabel('Quantidade')\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(default[\"defaulted\"].value_counts(normalize=True).sort_values()[idx]), \n               ha=\"center\")\n\ngraph.set(xlabel=None)\nplt.ylim(0,30000)\nplt.show()","a0fa84fd":"import missingno\nmissingno.matrix(data)\nplt.show()","b540cbc2":"mask = np.triu(np.ones_like(data.corr(),dtype = bool))\nplt.subplots(figsize=(18,10))\nsns.heatmap(data.corr(), linewidths=0.5,annot=True, cmap='Blues',mask = mask)\nplt.title('Correla\u00e7\u00e3o entre vari\u00e1veis do dataset')\n\nplt.show()","97030dbe":"sns.set(style=\"whitegrid\", color_codes=True, rc = {'figure.figsize':(15,10)})\n\n\nsns.boxplot(data = data.drop(['Sexo','Escolaridade','Estado_Civil','Idade','Status_Pg_Sep','Status_Pg_Aug','Status_Pg_Jul','Status_Pg_Jun','Status_Pg_May','Status_Pg_Apr','defaulted'],axis=1))\nplt.show()","fc2f2c5e":"from sklearn.model_selection import train_test_split \n\nX = data.loc[:,data.columns != 'defaulted']  # Entrada\ny = data['defaulted']    # Sa\u00edda\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)             \n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","0c53cce6":"X_train_df = pd.DataFrame(X_train)\n\nfrom scipy import stats\nimport numpy as np\nz_scores = stats.zscore(X_train_df)\n\nabs_z_scores = np.abs(z_scores)\nfiltered_entries = (abs_z_scores < 3).all(axis=1)\nX_train_out = X_train_df[filtered_entries]\n\nX_train_out\n\ny_train_out = y_train[y_train.index.isin(X_train_out.index)]\ny_train_out = pd.DataFrame(y_train_out)\n\ny_train_out","0f9d2567":"# Boxplot ap\u00f3s retirada de outliers\n\nsns.set(style=\"whitegrid\", color_codes=True, rc = {'figure.figsize':(15,10)})\n\n\nsns.boxplot(data = X_train_out.drop(['Sexo','Escolaridade','Estado_Civil','Idade','Status_Pg_Sep','Status_Pg_Aug','Status_Pg_Jul','Status_Pg_Jun','Status_Pg_May','Status_Pg_Apr'],axis=1))\nplt.show()","5f9d55a3":"#Normalizando os valores das vari\u00e1veis independentes\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X_train_out)\nX_train_normalized = scaler.transform(X_train_out)\nX_test_normalized = scaler.transform(X_test)\n\ny_train_normalized = y_train_out\nX_train_normalized","267a2134":"default = y_train_normalized.defaulted\ndefault = default.replace(to_replace = 0,value='N\u00e3o Pagou')\ndefault = default.replace(to_replace = 1,value='Pagou')\ndefault = default.to_frame()\nplt.subplots(figsize=(5,5))\ngraph = sns.countplot(data=default, x='defaulted')\nplt.title('Pagamentos do pr\u00f3ximo m\u00eas')\nplt.xlabel('Status Pagamento ')\nplt.ylabel('Quantidade')\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(default[\"defaulted\"].value_counts(normalize=True).sort_values()[idx]), \n               ha=\"center\")\n\ngraph.set(xlabel=None)\nplt.ylim(0,30000)\nplt.show()\n\nfrom imblearn.under_sampling import RandomUnderSampler\nsampler = RandomUnderSampler(random_state=seed);\nX_train_balance, y_train_balance = sampler.fit_resample(X_train_normalized, y_train_normalized)\n\nX_train_balance = pd.DataFrame(X_train_balance)\ny_train_balance = pd.DataFrame(y_train_balance) \ny_train_balance.columns = ['defaulted']\n\ndefault = y_train_balance.defaulted\ndefault = default.replace(to_replace = 0,value='N\u00e3o Pagou')\ndefault = default.replace(to_replace = 1,value='Pagou')\ndefault = default.to_frame()\nplt.subplots(figsize=(5,5))\ngraph = sns.countplot(data=default, x='defaulted')\nplt.title('Pagamentos do pr\u00f3ximo m\u00eas')\nplt.xlabel('Status Pagamento ')\nplt.ylabel('Quantidade')\n\nfor idx, bar in enumerate(graph.patches):\n    height = bar.get_height()\n    graph.text(x=bar.get_x() + bar.get_width()\/2., \n               y=height + 500, \n               s=\"{:.2%}\".format(default[\"defaulted\"].value_counts(normalize=True).sort_values()[idx]), \n               ha=\"center\")\n\ngraph.set(xlabel=None)\nplt.ylim(0,20000)\nplt.show()","b808f2bb":"X_train_clean = X_train_balance\ny_train_clean = y_train_balance\nX_test_clean = pd.DataFrame(X_test_normalized)\ny_test_clean = pd.DataFrame(y_test)","4baaf048":"X_train_zero = X_train\ny_train_zero = pd.DataFrame(y_train)\nX_test_zero = X_test\ny_test_zero = pd.DataFrame(y_test)","3d0cd7e1":"#Normalizando os valores das vari\u00e1veis independentes\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X_train_zero)\nX_train_normalized_zero = scaler.transform(X_train_zero)\nX_test_normalized_zero = scaler.transform(X_test_zero)\n\ny_train_normalized_zero = y_train\nX_train_normalized_zero","eede07fd":"def predict_and_evaluate(X_test, y_test, model):\n\n  y_pred = model.predict(X_test)\n\n  # ROC\n  from sklearn.metrics import roc_auc_score\n  roc = roc_auc_score(y_test, y_pred)\n  print('ROC: ', roc)\n\n  # Acur\u00e1cia\n  from sklearn.metrics import accuracy_score\n  accuracy = accuracy_score(y_test, y_pred)\n  print('Acur\u00e1cia: ', accuracy)\n\n   # Kappa\n  from sklearn.metrics import cohen_kappa_score\n  kappa = cohen_kappa_score(y_test, y_pred)\n  print('Kappa: ', kappa)\n\n  # Recall\n  from sklearn.metrics import recall_score\n  recall = recall_score(y_test, y_pred, zero_division=0)\n  print('Recall: ', recall)\n\n  # Precision\n  from sklearn.metrics import precision_score\n  precision = precision_score(y_test, y_pred,zero_division=0)\n  print('Precision: ', precision)\n\n  # F1\n  from sklearn.metrics import f1_score\n  f1 = f1_score(y_test, y_pred)\n  print('F1: ', f1)\n\n  # Matriz de confus\u00e3o\n  from sklearn.metrics import confusion_matrix\n  confMatrix = confusion_matrix(y_pred, y_test)\n\n  ax = plt.subplot()\n  sns.heatmap(confMatrix, annot=True, fmt=\".0f\")\n  plt.xlabel('Real')\n  plt.ylabel('Previsto')\n  plt.title('Matriz de Confus\u00e3o')\n\n  # Colocar os nomes\n  ax.xaxis.set_ticklabels(['N\u00e3o Pagou (0)', 'Pagou (1)']) \n  ax.yaxis.set_ticklabels(['N\u00e3o Pagou (0)', 'Pagou (1)'])\n  plt.show()","8477cc8e":"from sklearn.svm import SVC\n\ndef train_SVM(X_train, y_train, seed):\n  model_SVM = SVC(kernel='rbf', random_state = 1)\n  model_SVM.fit(X_train,y_train)\n  return model_SVM\n\n#### base com pr\u00e9-processamento\n\nmodel_SVM = train_SVM(X_train_clean, y_train_clean, seed)\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_clean, y_test_clean, model_SVM)","1535cd4c":"model_SVM_normalized_zero = train_SVM(X_train_normalized_zero, y_train_normalized_zero, seed)\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_normalized_zero, y_test_zero, model_SVM_normalized_zero)","82350e5a":"# GridSearch para SVM\n\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n# Set the parameters by cross-validation\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-1],\n                     'C': [1, 10, 100, 1000]}]\n\nmodel = GridSearchCV(SVC(), tuned_parameters, scoring='f1')\nmodel_SVM_CV = model.fit(X_train_clean, y_train_clean.values.ravel())\n\n#Rodando o modelo com os novos par\u00e2metros, p\u00f3s GridSearch\npredict_and_evaluate(X_test_clean, y_test_clean, model_SVM_CV)","7ce67868":"from sklearn.linear_model import LogisticRegression\n\ndef train_LR(X_train, y_train, seed):\n  model_LR = LogisticRegression(random_state=1, max_iter= 500)\n  model_LR.fit(X_train,y_train)\n  return model_LR\n\n#### base com pr\u00e9-processamento\n\nmodel_LR = train_LR(X_train_clean, y_train_clean, seed)\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_clean, y_test_clean, model_LR)","65af5fea":"model_LR_normalized_zero = train_LR(X_train_normalized_zero, y_train_normalized_zero, seed)\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_normalized_zero, y_test_zero, model_LR_normalized_zero)","767d81ee":"# GridSerach para Logistic Regression\n\nfrom sklearn.model_selection import GridSearchCV\nclf = LogisticRegression()\ngrid_values = {'penalty': ['l2'],'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\ngrid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'precision')\nmodel_LR_CV = grid_clf_acc.fit(X_train_clean, y_train_clean)\n\n#Rodando o modelo com os novos par\u00e2metros, p\u00f3s GridSearch\npredict_and_evaluate(X_test_clean, y_test_clean, model_LR_CV)","40d98955":"from sklearn.ensemble import RandomForestClassifier\n\ndef train_RF(X_train, y_train, seed):\n  model_RF = RandomForestClassifier(min_samples_leaf=5, random_state=seed) # tente mudar par\u00e2metro para evitar overfitting\n  model_RF.fit(X_train, y_train);\n  return model_RF","6cba44cf":"model_RF = train_RF(X_train_clean, y_train_clean, seed)\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_clean, y_test_clean, model_RF)","1a452b22":"model_RF = train_RF(X_train_zero, y_train_zero, seed)\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_zero, y_test_zero, model_RF)","fd14b519":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ntuned_parameters = {'n_estimators': [20, 50, 100, 150, 200, 300, 400, 500],\n                      'min_samples_split': [2, 4, 6, 10],\n                     'min_samples_leaf': [1,2,4,6,8],\n                     'max_features': [3,4,8,9,10,11]}\n\nprint(\"# Tuning hyper-parameters for F1 score\")\n#print()\n\nmodel = GridSearchCV(RandomForestClassifier(n_jobs=-1, verbose=0), tuned_parameters, scoring='f1')\nmodel.fit(X_test_clean, y_test_clean.values.ravel())\n\ny_pred = model.predict(X_test_clean)\nprint(classification_report(y_test_clean,y_pred))\n#print()\n\nplt.subplots(figsize=(5,5))\npredict_and_evaluate(X_test_clean, y_test_clean,model)\n\nprint('Melhor n\u00famero de \u00e1rvores: {}'.format(model.best_params_['n_estimators']))\nprint('Melhor n\u00famero n\u00famero m\u00ednimo de amostras necess\u00e1rias para dividir um n\u00f3 interno: {}'.format(model.best_params_['min_samples_split']))\nprint('Melhor n\u00famero m\u00ednimo de amostras necess\u00e1rias para estar em um n\u00f3 da folha: {}'.format(model.best_params_['min_samples_leaf']))\nprint('Melhor n\u00famero de vari\u00e1veis a serem considerados ao procurar a melhor divis\u00e3o: {}'.format(model.best_params_['max_features']))","27196976":"#### Estado civil","8451861c":"#### Download da base de dados","a13649e9":"#### base com pr\u00e9-processamento","faa40831":"#### Educa\u00e7\u00e3o","69188940":"#### Identificando Outliers:","02840e9c":"### Distribui\u00e7\u00e3o","c2543e90":"### Normaliza\u00e7\u00e3o","0e1e8c01":"#### Estado Civil","25673840":"###  Modelo: Machine Learning - Support Vector Machine:","c5e2a2dc":"#### base com normaliza\u00e7\u00e3o apenas","b3883af0":"#### Sexo","03e9084d":"#### base de treino com pr\u00e9-processamento","0cccfbdc":"###  Modelo: Machine Learning - Random Forest","47555973":"#### F\u00f3rmula","72583046":"### Distribui\u00e7\u00e3o Vs Vari\u00e1vel resposta","6c5f0507":"#### Balanceamento de vari\u00e1vel resposta","854293c3":"#### f\u00f3rmula para previs\u00e3o e avalia\u00e7\u00e3o dos modelos","5cbee2dd":"#### Sexo","df14fb20":"### Balanceamento na base de Treino: ","7fd07d7d":"# Trabalho Data Mining - Parte 1: An\u00e1lise Preliminar da Dase de Dados:","a7f95b3b":"## Entendendo a base","7e0d0124":"### Importa\u00e7\u00e3o das bibliotecas e random seed","f7e3bfbd":"#### f\u00f3rmula","7ed42bdf":"###  Modelo: Machine Learning - Regress\u00e3o Log\u00edstica:","2a93882e":"## Pr\u00e9-Processamento dos Dados","e1b4faf7":"## Separa\u00e7\u00e3o em Base de Treino e Base de Teste:","e6862e1c":"#### F\u00f3rmula","c297f920":"#### base de dados SEM pr\u00e9-processamento","2d4c3647":"#### GridSearch para Random Forest","4e6f381a":"#### base de dados com normaliza\u00e7\u00e3o","45361528":"### Preparando base de dados","c9360c0c":"#### Educa\u00e7\u00e3o","11580be1":"#### Verificando valores nulos","ce9a2945":"#### Faixa et\u00e1ria","0b25720d":"#### Alterando o nome das Colunas e retirando valores que n\u00e3o est\u00e3o na descri\u00e7\u00e3o da base de dados","49b9971b":"#### Matriz de Correla\u00e7\u00e3o da Base para verificar as vari\u00e1veis mais correlacionadas com defaulted","ea8fe9ef":"### Retirando Outliers","e7bb4fab":"#### base com normaliza\u00e7\u00e3o apenas","acc38d6d":"### Importa\u00e7\u00e3o da base de dados","e6bebe36":"# PARTE 2 - APLICANDO MODELOS DE MACHINE LEARNING","3f521f18":"## Modelos","ff459475":"#### base SEM pr\u00e9-processamento","a16be606":"#### Faixa et\u00e1ria"}}