{"cell_type":{"2ab8f080":"code","065cd796":"code","f858257e":"markdown","09d2c002":"markdown","3d643728":"markdown","f85ffb23":"markdown"},"source":{"2ab8f080":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\nds = pd.read_csv(\"..\/input\/sample-data.csv\")\n\ntf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(ds['description'])\n\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n\nresults = {}\n\nfor idx, row in ds.iterrows():\n    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n    similar_items = [(cosine_similarities[idx][i], ds['id'][i]) for i in similar_indices]\n\n    # First item is the item itself, so remove it.\n    # Each dictionary entry is like: [(1,2), (3,4)], with each tuple being (score, item_id)\n    results[row['id']] = similar_items[1:]\n    \nprint('done!')","065cd796":"# hacky little function to get a friendly item name from the description field, given an item ID\ndef item(id):\n    return ds.loc[ds['id'] == id]['description'].tolist()[0].split(' - ')[0]\n\n# Just reads the results out of the dictionary. No real logic here.\ndef recommend(item_id, num):\n    print(\"Recommending \" + str(num) + \" products similar to \" + item(item_id) + \"...\")\n    print(\"-------\")\n    recs = results[item_id][:num]\n    for rec in recs:\n        print(\"Recommended: \" + item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")\n\n# Just plug in any item id here (1-500), and the number of recommendations you want (1-99)\n# You can get a list of valid item IDs by evaluating the variable 'ds', or a few are listed below\n\nrecommend(item_id=7, num=5)","f858257e":"## Step 1 - Train the engine.\nCreate a TF-IDF matrix of unigrams, bigrams, and trigrams for each product. The 'stop_words' param tells the TF-IDF module to ignore common english words like 'the', etc.\n\nThen we compute similarity between all products using SciKit Leanr's linear_kernel (which in this case is equivalent to cosine similarity).\n\nIterate through each item's similar items and store the 100 most-similar. Stops at 100 because well...how many similar products do you really need to show?\n\nSimilarities and their scores are stored in a dictionary as a list of Tuples, indexed to their item id.\n","09d2c002":"# Try it yourself!\n\nHere are some product IDs to try. Just call:\n\n    recommend(<id>)\n\n1 - Active classic boxers\n\n2 - Active sport boxer briefs\n\n3 - Active sport briefs\n\n4 - Alpine guide pants\n\n5 - Alpine wind jkt\n\n6 - Ascensionist jkt\n\n8 - Print banded betina btm\n\n9 - Baby micro d-luxe cardigan\n\n10 - Baby sun bucket hat\n\n11 - Baby sunshade top","3d643728":"# Description\n\nHere's  simple content-based recommendation engine. An in-depth explanation is here (and the code is ported from the same place):\n\nhttp:\/\/blog.untrod.com\/2016\/06\/simple-similar-products-recommendation-engine-in-python.html","f85ffb23":"## Step 2: Predict!"}}