{"cell_type":{"8861962d":"code","de0e473e":"code","28dbd70d":"code","2da850ea":"code","1231c669":"code","9936dab2":"code","6045fc82":"code","22af6950":"code","74d8b36c":"code","a967d616":"code","e02acda0":"code","4f29c188":"code","9b004ad8":"code","a118d497":"code","36c7f4fb":"code","039f5732":"code","dc7e8523":"code","7472215b":"code","e44d8fa8":"code","6c91b94a":"code","a60224fc":"code","1cfedcad":"code","cc80c3a7":"code","26d4c72f":"code","b812b808":"code","abfe8c3a":"code","31067327":"code","2ce44215":"code","51c2390a":"code","4f601add":"code","f60f19a4":"code","8b8cdc33":"code","3ac972f4":"code","894d3141":"code","4939ce88":"code","983b8ded":"code","8cb9a42b":"code","03bbe2ac":"code","f57e4d5e":"code","45d4edf1":"code","6aa42581":"markdown","464561c1":"markdown","09b8d3f4":"markdown","2586458b":"markdown","d0c07e24":"markdown","20f7c20c":"markdown"},"source":{"8861962d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","de0e473e":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","28dbd70d":"df_train.head()","2da850ea":"df_test.head()","1231c669":"print(df_train.shape)\nprint(df_test.shape)","9936dab2":"# Correlation between different features and Survived\ndf_train.corr()","6045fc82":"# Heatmap of the correlation\nsns.heatmap(df_train.corr())\nplt.show()","22af6950":"# Count of Survived people\nsns.set_style('dark')\nsns.set_palette('RdBu')\nsns.set_context('poster')\nsns.catplot(x = 'Survived',data=df_train, kind='count')\nplt.show()","74d8b36c":"# Count of Survived people belonging to different Pclass\nsns.set_palette(['Red','Green'])\nsns.catplot(x = 'Pclass',data=df_train, kind='count',hue='Survived')\nplt.show()","a967d616":"# Count of Survived people of each Sex\nsns.set_palette(['Red','Green'])\nsns.catplot(x = 'Sex', data = df_train, kind='count', hue='Survived')\nplt.show()","e02acda0":"# Distribution of Age among the Survived people\nsns.set_context('notebook')\nsns.catplot(x = 'Survived', y='Age', data=df_train,kind='box')\nplt.show()","4f29c188":"# Relation between the survived people and their fare\nsns.catplot(x = 'Survived', y='Fare', data=df_train, kind='bar')\nplt.show()","9b004ad8":"# Count of Survived people from each Embarking\nsns.catplot(x = 'Embarked', data = df_train, kind='count', hue='Survived')\nplt.show()","a118d497":"df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\ndf_test['Age'] = df_test['Age'].fillna(df_test['Age'].mean())\ndf_train['Cabin'] = df_train['Cabin'].fillna('Missing')\ndf_test['Cabin'] = df_test['Cabin'].fillna('Missing')\ndf_train = df_train.dropna()\ndf_test['Fare'] = df_test['Fare'].fillna(df_test['Fare'].mean())","36c7f4fb":"df_train.isnull().sum()","039f5732":"df_test.isnull().sum()","dc7e8523":"df_train = df_train.drop(columns=['Name'],axis=1)\ndf_test = df_test.drop(columns=['Name'],axis=1)\ndf_train = df_train.drop(columns=['Ticket'],axis=1)\ndf_test = df_test.drop(columns=['Ticket'],axis=1)\ndf_train = df_train.drop(columns=['Cabin'], axis=1)\ndf_test = df_test.drop(columns=['Cabin'], axis=1)","7472215b":"sex_map = {\n        'male':0,\n    'female':1\n}\ndf_train.loc[: ,'Sex'] = df_train['Sex'].map(sex_map)\ndf_test.loc[: , 'Sex'] = df_test['Sex'].map(sex_map)","e44d8fa8":"df_train = pd.get_dummies(df_train, prefix_sep='_',columns=['Embarked'])\ndf_test = pd.get_dummies(df_test, prefix_sep='_',columns=['Embarked'])","6c91b94a":"df_train.head()","a60224fc":"df_test.head()","1cfedcad":"print(df_train.shape)\nprint(df_test.shape)","cc80c3a7":"# Base Models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\n\n# Ensembling Techniques\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost as xgb\n\n# Metrics \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score","26d4c72f":"X = df_train.drop('Survived',axis=1)\ny = df_train['Survived'].values","b812b808":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)","abfe8c3a":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","31067327":"# Base Classifiers\nlr = LogisticRegression(max_iter=10000)\nknn=KNN()\ndt = DecisionTreeClassifier()\nclassifiers = [('LogisticRegression',lr),\n              ('KNeighborsClassifier',knn),\n              ('ClassificationTree',dt)]\nfor clf_name, clf in classifiers:\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(clf_name, 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","2ce44215":"# Voting Classifier\nvc = VotingClassifier(estimators = classifiers)\nvc.fit(X_train, y_train)\ny_pred = vc.predict(X_test)\nprint('Voting Classifier', 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","51c2390a":"# AdaBoost Classifier\nadb_clf = AdaBoostClassifier(base_estimator = dt, n_estimators = 100)\nadb_clf.fit(X_train, y_train)\ny_pred = adb_clf.predict(X_test)\nprint('AdaBoostClassifier', 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","4f601add":"# GradientBoosting Classifier\ngbt = GradientBoostingClassifier()\ngbt.fit(X_train, y_train)\ny_pred = gbt.predict(X_test)\nprint('GradientBoostingClassifier', 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","f60f19a4":"# Stochastic GradientBoostingClassifier\nsgbt = GradientBoostingClassifier(max_depth=1,subsample=0.8,max_features=0.2,n_estimators=300,random_state=21)\nsgbt.fit(X_train, y_train)\ny_pred = sgbt.predict(X_test)\nprint('Stochastic GradientBoostingClassifier', 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","8b8cdc33":"# XGBoost\nxg_cl = xgb.XGBClassifier(objective='binary:logistic',\n                         seed=123)\nxg_cl.fit(X_train, y_train)\ny_pred = xg_cl.predict(X_test)\nprint('XGBoost', 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","3ac972f4":"## The highest ROC AUC Score and Accuracy is given by GradientBoostingClassifier\n# GradientBoostingClassifier\nsgbt = GradientBoostingClassifier(max_depth=1,subsample=0.8,max_features=0.2,n_estimators=300,random_state=21)\nsgbt.fit(X_train, y_train)\ny_pred = sgbt.predict(X_test)\nprint('Stochastic GradientBoostingClassifier', 'Accuracy Score' , accuracy_score(y_test,y_pred) , \" \" , 'ROC AUC Score' , roc_auc_score(y_test, y_pred))","894d3141":"y_pred = sgbt.predict(df_test)","4939ce88":"df_test['Survived'] = y_pred","983b8ded":"df_test","8cb9a42b":"df_submission = df_test.drop([\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked_C\", \"Embarked_Q\", \"Embarked_S\"],axis=1)","03bbe2ac":"df_submission.head()","f57e4d5e":"gender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ngender_submission.head()","45d4edf1":"df_submission.to_csv('results.csv',index=False)","6aa42581":"## 3. Imputing missing data and handling categorical variables <a id=3><\/a>","464561c1":"### If you like it, please drop an upvote.\nCheck out my other notebooks\n1. https:\/\/www.kaggle.com\/namanmanchanda\/cat-vs-dog-classifier-10-lines-of-code-fast-ai\n2. https:\/\/www.kaggle.com\/namanmanchanda\/star-wars-classifier\n\n[back to top](#100)","09b8d3f4":"## 2. Visual EDA and feature engineering <a id=2><\/a>","2586458b":"## 1. Adding basic libraries & importing the dataset <a id=1><\/a>","d0c07e24":"## 4. Model Development <a id=4><\/a>","20f7c20c":"<h1><center>Titanic EDA + Prediction<\/center><\/h1>\n\nTable of Contents: <a id=100><\/a>\n\n1. [Adding basic libraries & importing the dataset](#1)\n2. [Visual EDA and feature engineering](#2)\n3. [Imputing missing data and handling categorical variables](#3)\n4. [Model Development](#4)"}}