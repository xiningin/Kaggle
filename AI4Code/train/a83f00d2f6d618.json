{"cell_type":{"0ec5f815":"code","79043be0":"code","5f875054":"code","5d6e2c98":"code","91d697d1":"code","0c5b779c":"code","264d90ed":"code","6c3ed8c7":"code","2e7da4ca":"code","88aa2a1c":"code","a9aad817":"code","3da0c52a":"code","77b3572b":"code","9c3a4353":"code","75ea04cc":"code","31afb227":"code","40c7ad58":"code","53543025":"code","89d258e5":"code","5df9cc24":"code","4a9f714e":"code","cd54c882":"code","aa3c053d":"code","3a902d8d":"code","35215d66":"code","93748d8e":"code","3cfd2221":"code","352f170e":"code","27d347f9":"code","7cb4272c":"code","3af01ea6":"code","7b0cac61":"code","f4cfb862":"code","aede52ee":"code","ea47782b":"code","b29347cf":"code","47492ea2":"markdown","f87f9149":"markdown","df9894cc":"markdown","4b8fee7d":"markdown","e184f26e":"markdown","9f317e3d":"markdown","3f82cccd":"markdown","b2f57889":"markdown","70c3f8f3":"markdown","57afd9e3":"markdown"},"source":{"0ec5f815":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n# import matplotlib.image as Image\nimport os\nimport albumentations as A\nimport sys\nimport random\nimport cv2\nimport gc\n\nimport tensorflow as tf\nfrom tensorflow import keras","79043be0":"direcory_train = '..\/input\/petfinder-pawpularity-score\/train\/'\ndirectory_test = '..\/input\/petfinder-pawpularity-score\/test\/'\n\ncsv_train = '..\/input\/petfinder-pawpularity-score\/train.csv'\ncsv_test = '..\/input\/petfinder-pawpularity-score\/test.csv'","5f875054":"data = pd.read_csv(csv_train)\ndata.head()","5d6e2c98":"data.info()","91d697d1":"data.describe()","0c5b779c":"fig = plt.figure(figsize=(20,5))\narr, bins, patches = plt.hist(data.Pawpularity, bins = 199)\nplt.xticks(range(1,101), rotation=90)\nplt.show()","264d90ed":"dataPawpularity = np.array(data.Pawpularity, dtype=np.float32)\n\n# Frequency for the first half is huge. So we used more slicing than the later half\nfor i in range(5, 51, 5):\n    dataPawpularity[(dataPawpularity>(i-5)) & (dataPawpularity<=i)] = (2*i - 5)\/2.0\n\nfor i in range(55, 101, 5):\n    dataPawpularity[(dataPawpularity>(i-5)) & (dataPawpularity<=i)] = i\n    \nprint(np.unique(dataPawpularity))","6c3ed8c7":"# Let's check if it still follows the trend\n\nfig = plt.figure(figsize=(20,5))\narr, bins, patches = plt.hist(dataPawpularity, bins = 41)\nplt.xticks(range(1,101), rotation=90)\nplt.show()","2e7da4ca":"data.Pawpularity = dataPawpularity\ndel dataPawpularity","88aa2a1c":"pawpularity_0 = data[data.Pawpularity <= 5]\npawpularity_30 = data[(data.Pawpularity >= 25) & (data.Pawpularity <= 35)]\npawpularity_100 = data[data.Pawpularity >= 95]","a9aad817":"def show_images(paws):\n    fig = plt.figure(figsize=(10,10), constrained_layout=True)\n    grids = fig.add_gridspec(3,3)\n    \n    for i in range(3):\n        for j in range(3):\n            img = Image.open(direcory_train + paws.Id.iloc[i*3 + j] + '.jpg')\n            ax = fig.add_subplot(grids[i,j])\n            ax.imshow(img)\n    \n    plt.show()","3da0c52a":"print('Pawpularity <= 5')\nshow_images(pawpularity_0)","77b3572b":"print('Pawpularity >= 25 and <=35')\nshow_images(pawpularity_30)","9c3a4353":"print('Pawpularity >= 95')\nshow_images(pawpularity_100)","75ea04cc":"data_np = []\ntarget = data.Pawpularity\n\nimg_shape = (224,224,3)","31afb227":"def make_nparray(data, directory):\n    im_array = np.zeros((data.shape[0], img_shape[0], img_shape[1], 3), dtype=np.uint8)\n    \n    for i in range(data.shape[0]):\n        img = Image.open(directory + data.Id.iloc[i] + '.jpg')\n        img = img.resize((img_shape[0], img_shape[1]))\n        im_array[i] = np.array(img, dtype=np.uint8)\n    \n    return im_array","40c7ad58":"# Run this on kaggle notebook\n# data_np = make_nparray(data, direcory_train)","53543025":"# No need to run this on local machine. simply save and load from local machine!\n\ndef load_data():\n    global data_np\n    \n    import pickle\n\n    # data_file = open('data_file.pkl', 'wb')\n    # pickle.dump(data_np, data_file)\n    # data_file.close()\n\n    data_file = open('..\/input\/petfinder-numpy300300\/data_file.pkl', 'rb')\n    data_np = pickle.load(data_file)\n    data_file.close()\n\nload_data()","89d258e5":"class Paws:\n    \n    def __init__(self, data_np):\n        assert type(data_np) == np.ndarray\n        assert len(data_np.shape) == 4\n        self.data = data_np.copy()\n    \n    def getAugmented(self, raw = 0, p = 0.3):\n        global img_shape\n        \n        if raw == 0:\n            return self.data\n        else:\n            print('Augmenting!')\n            \n            augmented = np.zeros((self.data.shape[0], img_shape[0], img_shape[1], img_shape[2]), dtype=np.uint8)\n            cut = random.randint(img_shape[0]-30,img_shape[0])\n\n            transformer = A.Compose([\n                A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0, rotate_limit=0,p=p,border_mode=cv2.INTER_NEAREST),\n                A.RandomCrop(cut,cut,p=p),\n                A.HorizontalFlip(p=p),\n                A.Rotate(limit=15, p=p),\n#                 A.VerticalFlip(p=p),\n                #     A.GridDropout(ratio=0.3,random_offset=True,holes_number_x=1, holes_number_y=1,always_apply=True),\n                #     A.Cutout(num_holes=1, max_h_size=100, max_w_size=100,fill_value=0, always_apply=True ),\n                A.CoarseDropout(max_holes=1, max_height=50, max_width=50,fill_value=0, p=0.3),\n                A.Resize(height=img_shape[0],width=img_shape[1], always_apply=True)\n            ])\n            \n            for i in range(self.data.shape[0]):\n                transformed = transformer(image=data_np[i])\n                augmented[i] = transformed['image']\n            \n        return augmented\n    \n    def getOriginalData(self):\n        return self.data;","5df9cc24":"es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)","4a9f714e":"start_lr = 0.000625\nmin_lr = 0.00001\nmax_lr = 0.001\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n\ncurrent_epoch = 0\n\ndef lrfn(epoch):\n    global current_epoch\n#     print('current epoch:', current_epoch)\n    \n#     if current_epoch < rampup_epochs:\n#         lr = (max_lr - start_lr)\/rampup_epochs * current_epoch + start_lr\n#         current_epoch += 1\n#         return lr\n#     elif current_epoch < rampup_epochs + sustain_epochs:\n#         current_epoch += 1\n#         return max_lr\n#     else:\n#         lr = (max_lr - min_lr) * exp_decay**(current_epoch-rampup_epochs-sustain_epochs) + min_lr\n#         current_epoch += 1\n#         return lr\n    \n    if epoch < rampup_epochs:\n        lr = (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n        return lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n        return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\nrang = np.arange(50)\ny = [lrfn(x) for x in rang]\nplt.plot(rang, y)\nprint('Learning rate per epoch:')\ncurrent_epoch = 0","cd54c882":"file_it = 1\n\ndef getFilename():\n    return 'it-'+str(file_it)+'vl-{val_loss:.2f}-ep-{epoch:02d}.hdf5'\n\ncp_callback = keras.callbacks.ModelCheckpoint(filepath='best.hdf5',\n                                              monitor='val_loss',\n                                              verbose=1,\n                                              mode='min', \n                                              save_weights_only=True, \n                                              save_best_only=True)","aa3c053d":"# custom train\n\nclass Trainer:\n    \n    def __init__(self, model ,data, meta_data):\n        if type(model) == str:\n            self.model = self.loadModel(model)\n        else:\n            self.model = model\n        self.meta_data = meta_data\n        self.paws = Paws(data)\n    \n    def train(self,epochs:int, iterations:int, batch_size:int, validation_split:np.float32 = 0.15 ):\n        global file_it\n        file_it = 1\n        \n        for it in range(iterations):\n            print('Iteration:{0}\/{1}'.format(it+1,iterations))\n            file_it = it + 1\n            \n            meta_model.fit(x=[self.paws.getAugmented(0), self.meta_data],\n                           y=target, batch_size=batch_size,\n                           epochs=epochs,\n                           validation_split=validation_split,\n                           callbacks=[lr_callback, es_callback, cp_callback ])\n            gc.collect()\n            \n    def loadModel(self, file_name):\n        self.model = keras.models.load_model(file_name)\n","3a902d8d":"def make_model_with_metadata(lr):\n    \n    mobileNet = keras.applications.MobileNetV2(include_top=False,\n                                               weights='..\/input\/mobilenetv2weights\/pre-trained.hdf5'\n                                              )\n    for l in mobileNet.layers:\n        l.trainable = False\n    \n    meta_in = keras.layers.Input((12,))\n    X = keras.layers.GlobalAveragePooling2D()(mobileNet.output)\n    X = keras.layers.BatchNormalization()(X)\n    X = keras.layers.Flatten()(X)\n    X = keras.layers.Concatenate()([X, meta_in])\n    X = keras.layers.Dense(100)(X)\n    X = keras.layers.BatchNormalization()(X)\n    X = keras.layers.Dense(1)(X)\n    \n    opt = keras.optimizers.Adam(lr)\n    model = keras.models.Model(inputs = [mobileNet.input, meta_in], outputs = X)\n    \n    model.compile(optimizer=opt, loss='mean_squared_error', metrics= ['mean_squared_error'])\n    \n    return model","35215d66":"meta_model = make_model_with_metadata(0.0001)","93748d8e":"# print(len(meta_model.layers))\n","3cfd2221":"meta_data = data.loc[:, 'Subject Focus':'Blur']\nmeta_data_np = np.array(meta_data)\n# meta_model.summary()","352f170e":"# meta_model.fit(x=[data_np, meta_data_np],\n#                y=target, batch_size=4,\n#                epochs=10,\n#                validation_split=0.15,\n#                workers=6,\n#                callbacks=[lr_callback, es_callback, cp_callback ])\n\ntrainer = Trainer(meta_model, data_np, meta_data_np)","27d347f9":"trainer.train(epochs=20, iterations= 3, batch_size=16)","7cb4272c":"test = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest_meta = test.loc[:, 'Subject Focus':]\ntest_meta = np.array(test_meta)","3af01ea6":"test_np = make_nparray(test, directory_test)","7b0cac61":"meta_model.load_weights('.\/best.hdf5')","f4cfb862":"predictions = meta_model.predict([test_np, test_meta])","aede52ee":"submission = pd.DataFrame(predictions, columns=['Pawpularity'])\nsubmission['Id'] = test.Id\nsubmission.head()","ea47782b":"submission.to_csv('submission.csv', index=False)","b29347cf":"# from tensorflow.python.client import device_lib\n# print(device_lib.list_local_devices())","47492ea2":"## Test","f87f9149":"## Callbacks","df9894cc":"## Convert images to nparray","4b8fee7d":"## Train","e184f26e":"### View some images with low and high pawpularity","9f317e3d":"## Import","3f82cccd":"## EDA","b2f57889":"## Data augmentation","70c3f8f3":"### Manipulate dataset labels\nManipulating dataset labels is necessary. Because 99, 98, 97 and 100 scored images are very similar. And also other images. So it's very hard for the model to predict accurately. Trying to manipulate the images, and trying out the accuracy, in case it helps!","57afd9e3":"### Output"}}