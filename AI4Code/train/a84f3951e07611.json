{"cell_type":{"fde4d142":"code","bf572038":"code","373459bd":"code","2ec4373b":"code","185928de":"code","5b82c6f4":"code","778788f3":"code","0b9f5f55":"code","dddccded":"code","792dc1df":"code","412fb66f":"code","bf6f7c19":"code","5018b5c9":"code","43389ed2":"code","bfc3c4d4":"code","faf6faba":"code","12aa0683":"code","90f8c691":"code","2c593215":"code","0470f973":"markdown"},"source":{"fde4d142":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","bf572038":"from fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai.callbacks import SaveModelCallback\nimport os","373459bd":"bs = 64","2ec4373b":"path = Path('..\/input\/chest_xray\/chest_xray')\npath.ls()","185928de":"img = open_image(path\/'val'\/'NORMAL'\/'NORMAL2-IM-1440-0001.jpeg')\nprint(img.data.shape)\nimg.show()","5b82c6f4":"tfms = get_transforms()","778788f3":"np.random.seed(7)\ndata = ImageDataBunch.from_folder(path, \n                                  valid='val',\n                                  valid_pct=0.2,\n                                  size=256, bs=bs,\n                                  ds_tfms=tfms).normalize(imagenet_stats)","0b9f5f55":"data.show_batch(3, figsize=(6,6))","dddccded":"data.classes, data.c, len(data.train_ds), len(data.valid_ds)","792dc1df":"learn = cnn_learner(data, models.squeezenet1_0, metrics=error_rate, model_dir=\"\/tmp\/model\/\")","412fb66f":"epochs=5\nlrs=1e-7\nsave_name='test'\ncallbacks = [SaveModelCallback(learn, every='improvement', monitor='val_loss', name=save_name)]\nlearn.fit_one_cycle(epochs, lrs, callbacks=callbacks)","bf6f7c19":"learn.save('stage-1')","5018b5c9":"learn.unfreeze()","43389ed2":"learn.lr_find()","bfc3c4d4":"learn.recorder.plot()","faf6faba":"learn.fit_one_cycle(3, max_lr=slice(3e-5, 3e-4))","12aa0683":"learn.save('stage-2')","90f8c691":"interp = ClassificationInterpretation.from_learner(learn)","2c593215":"interp.plot_confusion_matrix()","0470f973":"> - we have a very small validation set so some augmentation is needed"}}