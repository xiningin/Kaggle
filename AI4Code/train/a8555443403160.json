{"cell_type":{"5d1c4d36":"code","91b9a704":"code","8ec79fe0":"code","66e03e51":"code","e7c6a06d":"code","f35b8c4d":"code","c250e6ad":"code","89d2af74":"code","64f44d68":"code","d56ef9f2":"code","b6b70573":"markdown","af4225f0":"markdown","8a5510a2":"markdown","ea561f98":"markdown","c5eebac3":"markdown","2e0b6ab9":"markdown","f1886159":"markdown","5a3bd03d":"markdown","ba02a423":"markdown","5ab95a68":"markdown","222f1b5c":"markdown"},"source":{"5d1c4d36":"import pandas as pd\nimport os\nrootdir = '\/kaggle\/input\/3d-kinect-total-body-database-for-back-stretches\/Data\/'\ndata_real = pd.DataFrame()\nfor subdir, dirs, files in sorted(os.walk(rootdir)):\n    data = pd.DataFrame()\n    for file in sorted(files,reverse=True):\n        if file == 'label.csv':\n            label = pd.read_csv(subdir+'\/'+file,header=None)\n            label = label.loc[0,0]\n        else:\n            single_joint = pd.read_csv(subdir+'\/'+file,header=None,usecols=range(0,3))\n            data = pd.concat([data,single_joint],axis=1,ignore_index=True)\n    data['classs'] = [label for i in range(0,len(data))]\n    data_real = data_real.append(data)","91b9a704":"data_real.head()\ndata.shape","8ec79fe0":"data_real.classs = pd.factorize(data_real.classs)[0]","66e03e51":"x = data_real.drop([\"classs\"],axis=1)\ny = data_real.classs.values","e7c6a06d":"from sklearn.model_selection import train_test_split\nx_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,shuffle=True)","f35b8c4d":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100,random_state=1)\nprint('RF Fitting .............')\nrf.fit(x_train,y_train)\nprint('RF Scoring ...........')\nprint('Train Set accuracy of Random Forest is : ',rf.score(x_train,y_train))\nprint('Test Set accuracy of Random Forest is : ',rf.score(x_test,y_test))","c250e6ad":"from sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(x_train,y_train)\nprint('nn timee................')\nnn = MLPClassifier(solver='lbfgs',max_iter=20000)\nnn.fit(x_train,y_train)\nprint('BATCH SZE : ',nn.batch_size)\nprint('gaus...............')\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint('Knn:............')\nknn = KNeighborsClassifier(n_neighbors = 3) #n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\n\nprint('Svm..............')\nsvm = SVC(random_state = 1)\nsvm.fit(x_train,y_train)\n\n\nprint(\"SVM accuracu is :\",svm.score(x_test,y_test))\nprint(\"k={} nn score:{}\".format(3,knn.score(x_test,y_test)))\nprint('accuracy of bayes in test data is :', nb.score(x_test,y_test))\nprint('acc_nn = ',nn.score(x_test,y_test))\nprint('acc_of_sgd is: ', sgd.score(x_test,y_test))","89d2af74":"!pip install --upgrade sklearn","64f44d68":"from matplotlib import pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\nclass_names=['mermaid','seated','sumo','towel','wall','Y']\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix of Bayes\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(nb, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","d56ef9f2":"from sklearn.model_selection import cross_val_score\nimport numpy as np\naccuracy_map = cross_val_score(estimator = rf, X = x_train, y =y_train, cv = 10)\nprint(accuracy_map)\nprint(\"avg acc: \",np.mean(accuracy_map))\nprint(\"acg std: \",np.std(accuracy_map))","b6b70573":"**We split data as train and test.I choose 25% test data and %75 train data.You can change it.The shuffle parameters provide us to take the data randomly.**","af4225f0":"**Let's try 10 fold cross-validation on RandomForest Classifier.**","8a5510a2":"**Let's make some practice on data.\n![stretches.PNG](attachment:stretches.PNG)\nThe data folder format is like below.**\n\n> \/data\n\n> -- Subject0_Move_0\/\n\n> ------ ElbowRight_position.csv\n\n> ------ ElbowLeft_position.csv\n\n> ------ labels.csv\n\n> ------ .....\n\n> -- Subject0_Move_1\/ \n\n> ------ ElbowRight_position.csv \n\n> ------ ElbowLeft_position.csv\n\n> ------ labels.csv \n\n> ------ ......\n\n**First, we take x,y,z position data for all joints and actions, we also take the label of folder in 'label.csv'.**\n**As you see below, 'data_real' is pandas dataframe which contaion 75 rows of xyz joint data and 1 row of class label.**\n","ea561f98":"**In this step we split the label and the coordinate data as x,y.**","c5eebac3":"**The labels are in string format which is not appropriate for classify, lets make them categorical integers.**","2e0b6ab9":"**Let's try this data on diffrent kind of classifiers.**","f1886159":"**As you see, the dataframe has 75 rows of x,y,z coordinat of joints and 1 row of label, with 120 000 frames(columns).**","5a3bd03d":"**As you see above, the classifier accuracies are very high which means the stretch moves in data is pretty easy.**","ba02a423":"**So, the mean of the accuracies are almost 1 and the standart deviation is almost 0 which mean the results are pretty close and stable.**","5ab95a68":"**First, I wonder how RandomClassifier works.I build a RFClassifier with 100 decision tree.The results are well.**","222f1b5c":"**I want to show you confusion matrix but I couldn't update the scikit-learn framework.'plot_confusion_matrix' function is only available starting at 0.22 version of sklearn.**"}}