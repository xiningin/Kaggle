{"cell_type":{"7cd63979":"code","8c91cdb8":"code","0ec9d188":"code","26efb4ea":"code","4a16bf00":"code","be98184a":"code","436ff93c":"code","94462dcc":"code","93eb8eb6":"code","facbfc76":"code","b529f03b":"code","fef19dba":"code","030bf4f8":"code","1aa0cd50":"code","b588b10c":"code","52b32bd1":"code","27bef2d6":"code","5baf8425":"code","d7a9ed58":"code","24e34a31":"code","0b180c32":"code","7b19ac08":"markdown","5c66b911":"markdown","839867b1":"markdown","4eecc65d":"markdown","1e6a2720":"markdown","95b522ba":"markdown"},"source":{"7cd63979":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom mlxtend.frequent_patterns import apriori, association_rules","8c91cdb8":"# Load the dataset\nORD = pd.read_excel(\"..\/input\/online-retail-ii-dataset\/online_retail_II.xlsx\")","0ec9d188":"# Display first 5 rows\/transactions\nORD.head()","26efb4ea":"# Summary stats\nORD.info()","4a16bf00":"# checking for duplicate transactions\nORD.duplicated().sum()","be98184a":"print(\"Number of transactions before duplicates removal : %d \" % ORD.shape[0])\n# Dropping the duplicated transactions\nORD = ORD.drop(index=ORD[ORD.duplicated()].index)\nprint(\"Number of transactions after duplicates removal  : %d \" % ORD.shape[0])","436ff93c":"# Checking for cancelled transactions\nORD[ORD['Invoice'].astype(str).str[0] == 'C'].tail()","94462dcc":"print(\"Number of transactions before dropping the cancelled transactions : %d \" % ORD.shape[0])\n# Dropping the cancelled transactions\nORD = ORD.drop(index=ORD[ORD['Invoice'].astype(str).str[0] == 'C'].index)\nprint(\"Number of transactions after dropping the cancelled transactions  : %d \" % ORD.shape[0])","93eb8eb6":"# Checking for missing values\nORD.isnull().sum()","facbfc76":"# Remove transactions with missing product description\nORD = ORD.drop(index=ORD[ORD['Description'].isnull()].index)\n# still any missing product descriptions ?\nORD.isnull().sum()","b529f03b":"# Dropping transactions with negative quantity \nORD = ORD.drop(index = ORD[ORD['Quantity'] <= 0].index)","fef19dba":"# Summary stats for feature 'Country'\nORD['Country'].describe()","030bf4f8":"# transactions count by country\nORD['Country'].value_counts()","1aa0cd50":"country = 'Germany'\nord_country = ORD[ORD['Country'] == country]","b588b10c":"print(\"Number of unique invoices : %d \" % len(ord_country['Invoice'].value_counts()))\nprint(\"Number of unique products : %d \" % len(ord_country['Description'].value_counts()))","52b32bd1":"# Product sold quantity per invoice\nfreq = ord_country.groupby(['Invoice', 'Description'])['Quantity'].sum()","27bef2d6":"prod_freq = freq.unstack().fillna(0).reset_index().set_index('Invoice')\nprod_freq.head()","5baf8425":"# Set value to 1 for postivie quantity. Anything else set to 0\nproduct_set = prod_freq.applymap(lambda x : 1 if x > 0 else 0 )\nproduct_set.head()","d7a9ed58":"# return the products and productsets with at least 10% support\nfrequent_products = apriori(product_set, min_support=0.1, use_colnames=True)\nfrequent_products['length'] = frequent_products['itemsets'].apply(lambda x : len(x))\n# productset of length 2 \nfrequent_products[frequent_products.length > 1]","24e34a31":"# Identiy frequent productsets with the level of confidence above the 70 percent threshold\nrules = association_rules(frequent_products, metric=\"confidence\", min_threshold=0.7)\nrules","0b180c32":"# Identify productsets with lift socre of >= 2\nrules[rules['lift'] >= 2]","7b19ac08":"![image.png](attachment:image.png)","5c66b911":"![image.png](attachment:image.png)","839867b1":"# Frequent Productsets via Apriori Algorithm","4eecc65d":"![image.png](attachment:image.png)","1e6a2720":"# Association Rules generation from Frequent Productsets\n","95b522ba":"# We will analyse transactions from 'Germany' "}}