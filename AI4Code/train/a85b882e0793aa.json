{"cell_type":{"8e251297":"code","6de07d61":"code","eaf2fb05":"code","4e791c8c":"code","e0c4cc2d":"code","88d3f997":"code","a7f83e6e":"code","fce4b22d":"code","e382e508":"code","aa14b096":"code","86dfe0fd":"code","3bb965e6":"code","f143be48":"code","b385508d":"code","4acf32b0":"code","a1091bfe":"code","cc5973ac":"code","57fc9dda":"code","606859f5":"code","a3d3fbe4":"code","898f94d2":"code","82260f24":"code","707b3635":"code","953ba8f4":"code","5238ac42":"code","147137cf":"code","1b5c2f30":"code","766a4494":"code","14d3a36f":"code","4e1aab27":"code","f64ce04d":"code","567b3731":"code","5efcf5ef":"code","d658af2d":"code","eced0259":"code","5434a613":"code","49ac9261":"code","2f7e60d1":"code","e6fee0be":"code","0d4ad03f":"code","2bfe3daa":"code","71207755":"code","86af2dc1":"code","fa676a67":"code","f72710f1":"code","cd957174":"code","126627e9":"code","ab83dd45":"code","73aba75d":"code","2869d973":"code","da6f3418":"code","2827965d":"code","230e7479":"code","f916e68f":"code","87e9472b":"code","d148463f":"code","3d22a9d8":"code","edf1ce9e":"code","7456290a":"code","cc1fa0ba":"code","6de52293":"code","89d94fce":"code","779b149a":"code","0861c2e3":"code","cf8ed44c":"code","07825297":"code","d7cde4ab":"code","2168b52c":"code","d346f4e4":"code","df48562e":"code","1ea8b343":"code","1f782424":"code","da9a1c1c":"code","a2feb064":"code","d587aa21":"code","271671a1":"code","d9a56289":"code","b5e7a0a3":"code","d88e5686":"code","b18b527d":"code","b3cf7906":"code","133e6d00":"code","3e24cefd":"code","41ee8f98":"code","e174fd28":"code","1482a505":"code","1ada1ed5":"code","45816a16":"code","8cf29ea2":"code","1a748eac":"code","c52e7eac":"markdown","cb78083b":"markdown","78eab68e":"markdown","ef531049":"markdown","0c19f2a8":"markdown","f45b65b2":"markdown","98e4ec93":"markdown","9609de2b":"markdown","8d2de827":"markdown","edc8fc1b":"markdown","5c920229":"markdown","0b668c43":"markdown","b10f4a7e":"markdown","e87a4015":"markdown","a217d723":"markdown","a2a7dc13":"markdown","1db93407":"markdown","d18ac874":"markdown","61ff1e3e":"markdown","88489cb7":"markdown","7aa42dc5":"markdown","5c5cb566":"markdown","32d0af9f":"markdown","2b062d2d":"markdown","c6807489":"markdown","73c833da":"markdown","6350a4e3":"markdown","d44bfa10":"markdown","c9101153":"markdown","8ec3f015":"markdown","bc98f85e":"markdown","4c568afd":"markdown","04ff4eb8":"markdown","ac3f2a70":"markdown","8b4da0fd":"markdown","9a61cbfa":"markdown","61ff3d07":"markdown","5df2fed4":"markdown","53fcea76":"markdown","c18cbc72":"markdown","4f3b6372":"markdown","03e42bff":"markdown"},"source":{"8e251297":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6de07d61":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_df.head()","eaf2fb05":"train_df.sample(10)","4e791c8c":"test_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_df.head()","e0c4cc2d":"passenger_id = test_df['PassengerId']\npassenger_id","88d3f997":"features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']\n\ntrain_df = train_df[features + ['Survived']]\ntrain_df.head()","a7f83e6e":"test_df = test_df[features]\ntest_df.head()","fce4b22d":"all_df = pd.concat((train_df, test_df), axis=0)","e382e508":"all_df.head()","aa14b096":"train_df = all_df.iloc[:891].copy()\ntest_df = all_df.iloc[891:].copy()","86dfe0fd":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3bb965e6":"train_df.info()","f143be48":"train_df.describe()","b385508d":"print(train_df['Survived'].value_counts())\nprint(train_df['Survived'].value_counts(normalize=True))","4acf32b0":"sns.countplot(x=train_df['Survived'])\nplt.show()","a1091bfe":"women = train_df.loc[train_df.Sex == 'female']['Survived']\nrate_women = sum(women)\/len(women)\n\nprint('% of women who survived: {:.3f}'.format(rate_women))","cc5973ac":"men = train_df.loc[train_df.Sex == 'male']['Survived']\nrate_men = sum(men)\/len(men)\n\nprint('% of men who survived: {:.3f}'.format(rate_men))","57fc9dda":"sns.countplot(x='Survived', data=train_df, hue='Sex' )\nplt.show()","606859f5":"print('Before encoding:\\n{}\\n'.format(all_df['Sex'].value_counts()))\nall_df['Sex'].replace({'male':0, 'female':1}, inplace=True)\nprint('After encoding:\\n{}'.format(all_df['Sex'].value_counts()))","a3d3fbe4":"train_df = all_df.iloc[:891].copy()\ntest_df = all_df.iloc[891:].copy()","898f94d2":"print(train_df['Pclass'].value_counts())\nprint(train_df['Pclass'].value_counts(normalize=True))","82260f24":"sns.countplot(x='Survived', data=train_df, hue='Pclass')\nplt.show()","707b3635":"sns.catplot(x='Pclass', data=train_df, hue='Sex',\n            col='Survived', kind='count')\nplt.show()","953ba8f4":"train_df['Embarked'].value_counts()","5238ac42":"print('Percentage of null values in Embarked column: {:.3g}%'.format(train_df['Embarked'].isnull().sum() \/ len(train_df) * 100))\nprint('Percentage of null values in Embarked column: {:.3g}%'.format(test_df['Embarked'].isnull().sum() \/ len(test_df) * 100))","147137cf":"all_df['Embarked'].fillna('S', inplace=True)\nall_df['Embarked'].isnull().any()","1b5c2f30":"sns.countplot(x='Embarked', data=train_df, hue='Survived')\nplt.show()","766a4494":"\"\"\"\n# We will encode `Embarked` with 'S' to 0, 'Q' to 1 and 'C' to 2\nprint('Before encoding:\\n{}\\n'.format(train_df['Embarked'].value_counts()))\ntrain_df['Embarked'].replace({'S':0, 'Q':1, 'C':2}, inplace=True)\nprint('After encoding:\\n{}'.format(train_df['Embarked'].value_counts()))\n\"\"\";","14d3a36f":"embark_dummies = pd.get_dummies(data=all_df['Embarked'], prefix='Embarked')\nembark_dummies.head()","4e1aab27":"all_df = pd.concat([all_df, embark_dummies], axis=1)\nall_df.drop(columns='Embarked', inplace=True)\nall_df.head()","f64ce04d":"train_df = all_df.iloc[:891].copy()\ntest_df = all_df.iloc[891:].copy()","567b3731":"print('Percentage of null values in Cabin column: {:.3g}%'.format(train_df['Cabin'].isnull().sum() \/ len(train_df) * 100))\nprint('Percentage of null values in Cabin column: {:.3g}%'.format(test_df['Cabin'].isnull().sum() \/ len(test_df) * 100))","5efcf5ef":"all_df['Cabin'].fillna('U', inplace=True)\nall_df['Cabin'].isnull().any()","d658af2d":"all_df['Cabin'] = all_df['Cabin'].apply(lambda x: x[0])\nall_df['Cabin'].value_counts()","eced0259":"all_df['Cabin'].unique()","5434a613":"sns.countplot(x='Cabin', data=all_df.iloc[:891], hue='Survived')\nplt.show()","49ac9261":"cabin_dummies = pd.get_dummies(data=all_df['Cabin'], prefix='Cabin')\ncabin_dummies.head()","2f7e60d1":"all_df = pd.concat([all_df, cabin_dummies], axis=1)\nall_df.drop(columns='Cabin', inplace=True)\nall_df.head()","e6fee0be":"train_df = all_df.iloc[:891].copy()\ntest_df = all_df.iloc[891:].copy()","0d4ad03f":"plt.figure(figsize=(15, 4))\nplt.subplot(121)\nsns.histplot(x='Age', data=train_df, hue='Survived', multiple='stack')\nplt.subplot(122)\nsns.histplot(x='Age', data=train_df, hue='Survived', element='poly')\n#sns.histplot(x='Age', data=train_df, ax=ax2, color='g')\nplt.show()","2bfe3daa":"temp_df = train_df[train_df.Age.isnull()]\nprint(\"The number of null values in Age column is {}\".format(len(temp_df)))","71207755":"plt.figure(figsize=(18, 10))\nplt.subplot(231)\nsns.countplot(x='Pclass', data=temp_df)\nplt.subplot(232)\nsns.countplot(x='Sex', data=temp_df)\nplt.subplot(233)\nsns.countplot(x='SibSp', data=temp_df)\nplt.subplot(234)\nsns.countplot(x='Parch', data=temp_df)\nplt.subplot(235)\nsns.histplot(x='Fare', data=temp_df)\nplt.show()","86af2dc1":"\"\"\"\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.histplot(data=train_df.groupby(by=['Pclass', 'Parch', 'SibSp'])['Age'].transform('median'), ax=ax1, bins=20, kde=True, color='b')\nsns.histplot(data=train_df.Age, ax=ax1, kde=True, color='r')\n\nsns.histplot(data=train_df.groupby(by=['Pclass', 'Parch', 'Sex'])['Age'].transform('median'), ax=ax2, bins=20, kde=True, color='b')\nsns.histplot(data=train_df.Age, ax=ax2, kde=True, color='r')\n\nplt.show()\n\"\"\";","fa676a67":"\"\"\"\n# Choosing to impute with mean.\ntrain_df.groupby(by=['Pclass', 'Parch'])['Age'].transform('mean').isnull().sum()\ntrain_df['Age'].fillna(train_df.groupby(by=['Pclass', 'Sex', 'Parch'])['Age'].transform('mean'), inplace=True)\n\"\"\";","f72710f1":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import KNNImputer","cd957174":"train_df.head()","126627e9":"scaler = MinMaxScaler()\nscaled_df = scaler.fit_transform(train_df)\nscaled_df = pd.DataFrame(data=scaled_df, columns=train_df.columns)\nscaled_df.head()","ab83dd45":"imputer = KNNImputer(n_neighbors=3)\nimputed_df = imputer.fit_transform(scaled_df)\n#imputer_df = pd.DataFrame(data=imputed_df, columns=features)\nimputed_df = scaler.inverse_transform(imputed_df)\nimputed_df = pd.DataFrame(data=imputed_df, columns=train_df.columns)","73aba75d":"imputed_df.isnull().sum()","2869d973":"train_df['Age'] = imputed_df['Age']","da6f3418":"scaled_df = scaler.transform(test_df)\nscaled_df = pd.DataFrame(data=scaled_df, columns=test_df.columns)\nscaled_df.head()","2827965d":"imputed_df = imputer.transform(scaled_df)\n#imputer_df = pd.DataFrame(data=imputed_df, columns=all_df[891:].columns)\nimputed_df = scaler.inverse_transform(imputed_df)\nimputed_df = pd.DataFrame(data=imputed_df, columns=all_df.iloc[891:].columns)\nimputed_df.head()","230e7479":"test_df['Age'] = imputed_df['Age']","f916e68f":"all_df.iloc[:891] = train_df.copy()\nall_df.iloc[891:] = test_df.copy()","87e9472b":"all_df['Age_band'] = all_df['Age'].apply(lambda x: math.ceil(x \/ 5))\nall_df.sample(10)","d148463f":"train_df = all_df.iloc[:891].copy()\ntest_df = all_df.iloc[891:].copy()","3d22a9d8":"train_df[train_df.Fare==0]","edf1ce9e":"plt.figure(figsize=(18, 12))\nplt.subplot(211)\nsns.histplot(x='Fare', data=train_df, bins=50, hue='Survived', multiple='stack')\nplt.subplot(212)\nsns.histplot(x='Fare', data=train_df, bins=50, hue='Survived', element='poly')\nplt.show()","7456290a":"plt.figure(figsize=(18, 6))\nsns.scatterplot(x='Age', y='Fare', data=train_df, hue='Survived', size='Fare', sizes=(20, 150))\nplt.show()","cc1fa0ba":"plt.figure(figsize=(18, 6))\nax = plt.subplot()\n\nax.scatter(train_df[train_df.Survived==1]['Age'], train_df[train_df.Survived==1]['Fare'],\n           c='g', s=train_df[train_df.Survived==1]['Fare'])\nax.scatter(train_df[train_df.Survived==0]['Age'], train_df[train_df.Survived==0]['Fare'],\n           c='r', s=train_df[train_df.Survived==0]['Fare'])\nplt.show()","6de52293":"all_df['Fare'].fillna(train_df.Fare.mean(), inplace=True)","89d94fce":"def create_fare_class(x):\n    if x >= 100:\n        fare_class = 1\n    elif x >= 80 and x < 100:\n        fare_class = 2\n    elif x >= 60 and x < 80:\n        fare_class = 3\n    elif x >= 40 and x < 60:\n        fare_class = 4\n    elif x >= 20 and x < 40:\n        fare_class = 5\n    else:\n        fare_class = 6\n\n    return fare_class","779b149a":"all_df['Fare_class'] = all_df['Fare'].apply(create_fare_class)\nall_df.head()","0861c2e3":"train_df = all_df.iloc[:891].copy()\ntest_df = all_df.iloc[891:].copy()","cf8ed44c":"sns.countplot(x='Fare_class', data=all_df, hue='Survived')\nplt.show()","07825297":"sns.countplot(x='SibSp', data=train_df, hue='Survived')\nplt.show()","d7cde4ab":"all_df.columns","2168b52c":"sns.countplot(x='Parch', data=train_df, hue='Survived')\nplt.show()","d346f4e4":"train_df.head()","df48562e":"X_train = train_df.drop(columns=['Age', 'Fare', 'Survived'])\nX_train.head()","1ea8b343":"y_train = train_df['Survived'].astype('int')\ny_train.head()","1f782424":"test_df.head()","da9a1c1c":"X_test = test_df.drop(columns=['Age', 'Fare', 'Survived'])\nX_test.head()","a2feb064":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost as xgb\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nrandom_state=2","d587aa21":"cv_score_columns = ['logreg', 'rforest', 'adaboost', 'gboost', 'xg']\n# cv_score_columns = ['logreg', 'rforest', 'adaboost', 'gboost']\ncv_score_df = pd.DataFrame(columns=cv_score_columns)\ncv_score_df","271671a1":"logreg = LogisticRegression(solver='liblinear', random_state=random_state)\nrforest = RandomForestClassifier(random_state=random_state)\nadaboost = AdaBoostClassifier(random_state=random_state)\ngboost = GradientBoostingClassifier(random_state=random_state)\nxg = xgb.XGBClassifier(use_label_encoder=False, random_state=random_state)","d9a56289":"models = [logreg, rforest, adaboost, gboost, xg]\ncv_scores = []\nfor model in models:\n    cvs_mean = (cross_val_score(model, X_train, y_train, cv=5)).mean()\n    cv_scores.append(cvs_mean)","b5e7a0a3":"cv_score_df.loc['base'] = cv_scores\ncv_score_df","d88e5686":"logreg = LogisticRegression(solver='liblinear', random_state=random_state)\nrforest = RandomForestClassifier(random_state=random_state)\nadaboost = AdaBoostClassifier(random_state=random_state)\ngboost = GradientBoostingClassifier(random_state=random_state)\nxg = xgb.XGBClassifier(use_label_encoder=False, random_state=random_state)","b18b527d":"gridsearch_dict = {'model_list':models,\n                   'param_list':[{'penalty':('l1', 'l2'), 'C':(.001, .01, .1)},\n                                 {'n_estimators':(100, 200, 300),'criterion':('gini', 'entropy'), 'max_depth':(2, 3, 4, 5)},\n                                 {'n_estimators':(50, 100, 200, 300), 'learning_rate':(.001, .01, .1)},\n                                 {'loss':('deviance', 'exponential'), 'learning_rate':(.001, .01), 'n_estimators':(100, 200, 300)},\n                                 {'n_estimators':(100, 200, 300), 'learning_rate':(.001, .01, .1)}\n                                ]\n                   }","b3cf7906":"best_model_df = pd.DataFrame(columns=cv_score_columns)\nbest_model_list = []\ncv_scores = []","133e6d00":"%%time\nfor m, p in tqdm(zip(gridsearch_dict['model_list'], gridsearch_dict['param_list'])):\n    clf = GridSearchCV(m, p)\n    clf.fit(X_train, y_train)\n    best_model_list.append({'best_model':clf.best_estimator_, 'best_param':clf.best_params_})\n    cv_scores.append(clf.best_score_)","3e24cefd":"best_model_list","41ee8f98":"cv_scores","e174fd28":"best_model_df.loc['best'] = best_model_list\ncv_score_df.loc['best'] = cv_scores","1482a505":"cv_score_df","1ada1ed5":"model_best = best_model_df.iloc[0]['rforest']['best_model']","45816a16":"model_best.fit(X_train, y_train)","8cf29ea2":"predictions = model_best.predict(X_test)","1a748eac":"output = pd.DataFrame({'PassengerId': passenger_id, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","c52e7eac":"<a id=\"target\"><\/a>\n<h3>Target Variable<\/h3>","cb78083b":"<a href=\"#toc\"><b>back to top<\/b><\/a>\n<hr>","78eab68e":"<a id='reference'><\/a>\n<h2>References<\/h2>\n<ol>\n    <li><a href='https:\/\/bit.ly\/3pjmRIp'>Imputing Numerical Data: Top 5 Techniques Every Data Scientist Must Know<\/a><\/li>\n    <li><a href='https:\/\/bit.ly\/3oaTpoM'>Kaggle Titanic: Machine Learning model (top 7%)<\/a><\/li>\n    <li><a href='https:\/\/bit.ly\/3D9TxsR'>Stacked and Percent Stacked Barplot using Seaborn<\/a><\/li>\n<\/ol>","ef531049":"Feature engineering the `Age` into `Age_band` of 5 years each.","0c19f2a8":"<a href=\"#toc\"><b>back to top<\/b><\/a>\n<hr>","f45b65b2":"<a id=\"sex\"><\/a>\n<h3>Survival based on sex<\/h3>","98e4ec93":"Seems like passengers who paid nothing for `Fare` have very low survival rate","9609de2b":"There appears to be some correlation between age and survival. The very young have better odds of survival. The relatively older passengers also seem to have higher survival rate except for those above 64\/65. We can probably drop the passengers into age bands of 5 years each. But first we have to handle the missing data.","8d2de827":"The columns `Age`, `Cabin` and `Embarked` contain null values. We will clean these data later. ","edc8fc1b":"Most of the column values seem reasonable in the dataset seem reasonable. `Fare` has minimum value of 0 so it might be worth exploring further","5c920229":"<a id=\"fare\"><\/a>\n<h3>Survival based on Fare<\/h3>","0b668c43":"<a id='version'><\/a>\n<h2>Versions<\/h2>\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                                                          |\n| ----------------- | ------- | ---------- | ------------------------------------------------------------------------------------------- |\n|                   | 1.0     |            | Implemented Alexis Cook's Tutorial                                                          |\n|                   | 1.1     |            | NIL                                                                                         |\n|                   | 2.0     |            | Used KNN Imputation for null values in Age                                                  |\n|                   | 2.11    |            | Implemented one-hot-encoding for Embarked and Cabin, fixed target variable to int           |\n|                   | 3.0     |            | Implemented logreg, rforest, adaboost, gboost, xgb and gridsearchCV to tune hyperparameters |\n","b10f4a7e":"<a id=\"pclass\"><\/a>\n<h3>Survival based on Pclass<\/h3>","e87a4015":"We can just fill null values of `Embarked` column with 'S', since there are only 2, which is about .2% of the dataset","a217d723":"<a id='data'><\/a>\n<h2>Loading data<\/h2>","a2a7dc13":"We will compare a few models: Logistic Regression, Random Forest Classifier, AdaBoost Classifier, Gradient Boosting Classifier and of course Extreme Gradient Boosting Classifer. XG Boost has highly rated in kaggle competitions of recent years and we should definitely include this. ","1db93407":"Cabins beginning with B, C, D, E, F and G seem to have better odds of survival.","d18ac874":"<a id='eda'><\/a>\n<h2>Exploratory Data Analysis<\/h2>","61ff1e3e":"<a href=\"#toc\"><b>back to top<\/b><\/a>\n<hr>","88489cb7":"<a id=\"fare\"><\/a>\n<h3>Survival based on SibSp<\/h3>","7aa42dc5":"We will create a dataframe to keep track of mean CV scores of the models. ","5c5cb566":"Performing one hot encoding on `Embarked` ","32d0af9f":"Females show a higher likelihood of survival\n\nEncode `Sex` to 0 for Male and 1 for Female","2b062d2d":"We can feature engineer `Fare` into `Fare_class` in steps of 20","c6807489":"<h2>Summary<\/h2>\nThis is my very first attempt and putting up a public notebook on Kaggle and joining a competition. \n\nThere are a few things that I am trying to achieve here. \n1. Definitely to get familiar with building up a portfolio on Kaggle.\n2. To put up a well-documented notebook with clearly defined sections and links to move within sections easily. A version summary is also available at the end of the notebook for version control","73c833da":"<b>Observation<\/b>: The bulk of people without age documented seem to be coming from lower `Pclass`, without `SibSp`, `Parch` (no siblings\/spouses, no parents\/children) and with very low `Fare`. We might try imputing data using `sklean.impute` with `KNNImputer`. ","6350a4e3":"<div class=\"alert alert-block alert-info\">\n<a id=\"toc\"><\/a>\n<h2>Table of Contents<\/h2>\n<ol>\n    <li><a href=\"#data\">Loading Data<\/a><\/li>\n    <li><a href=\"#eda\">EDA<\/a><\/li>\n    <ol>\n        <li><a href=\"#target\">Target Variable<\/a><\/li>\n        <li><a href=\"#sex\">Survival based on sex<\/a><\/li>\n        <li><a href=\"#pclass\">Survival based on Pclass<\/a><\/li>     \n        <li><a href=\"#embarked\">Data wrangling on Embarked<\/a><\/li>\n        <li><a href=\"#cabin\">Data wrangling on Cabin<\/a><\/li>\n        <li><a href=\"#age\">Survival based on age<\/a><\/li>     \n        <li><a href=\"#fare\">Survival based on fare<\/a><\/li>\n    <\/ol>\n    <li><a href=\"#ml\">Machine Learning<\/a><\/li>\n    <ol>\n        <li><a href=\"#test\">Preparing testing data<\/a><\/li>\n        <li><a href=\"#model\">Modeling<\/a><\/li>\n    <\/ol>\n    <li><a href=\"#submission\">Submission<\/a><\/li>\n    <li><a href=\"#version\">Version<\/a><\/li>    \n    <li><a href=\"#reference\">References<\/a><\/li>\n\n<\/ol>\n<\/div>","d44bfa10":"<a href=\"#toc\"><b>back to top<\/b><\/a>\n<hr>","c9101153":"<h1>Titanic competition<\/h1>","8ec3f015":"Passenger class seem to determine chances of survival","bc98f85e":"<a id=\"fare\"><\/a>\n<h3>Survival based on Parch<\/h3>","4c568afd":"<a id=\"age\"><\/a>\n<h3>Survival based on age<\/h3>","04ff4eb8":"We impute the null value in the test data of Fare to the mean in the training dataset","ac3f2a70":"<a id='test'><\/a>\n<h3>Prepare testing data<\/h3>","8b4da0fd":"<a id=\"cabin\"><\/a>\n<h3>Data wrangling on Cabin<\/h3>","9a61cbfa":"<a id='model'><\/a><h3>Modeling<\/h3>","61ff3d07":"We wil use GridSearch CV to tune hyper parameters ","5df2fed4":"<a href=\"#toc\"><b>back to top<\/b><\/a>\n<hr>","53fcea76":"<a id=\"submission\"><\/a>\n<h2>Submission<\/h2>","c18cbc72":"<a id=\"embarked\"><\/a>\n<h3>Data wrangling on Embarked<\/h3>","4f3b6372":"This is an imbalanced dataset with 38% of passengers surviving and 61% not surviving","03e42bff":"<a id=\"ml\"><\/a>\n<h2>Machine Learning<\/h2>"}}