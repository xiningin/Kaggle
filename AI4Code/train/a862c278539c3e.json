{"cell_type":{"61e512f0":"code","3be5e31f":"code","7acc670a":"code","522c6dd2":"code","be0c33bb":"code","109482da":"code","4a03495e":"code","eef1c904":"code","ce2751c5":"code","d386ec65":"code","e98d6d37":"code","0d8baa85":"code","33e523e3":"code","f386a7f9":"code","12d5269c":"code","6a2ae805":"code","94bd744f":"code","92473d60":"code","634ab6b8":"code","7f909526":"code","337e2d68":"code","2558dd51":"code","88a2dcc0":"code","fe3f8ecc":"code","76c63163":"code","5b2001be":"code","f834c779":"code","b9e495a8":"code","0de24751":"code","4702f7e5":"code","4686bbcb":"code","21bc4c89":"code","ead8cede":"code","f6515718":"code","e72fc3d5":"code","69e42ec2":"code","8c7448b5":"code","b2607da3":"code","64595693":"code","944f9034":"code","6254d6b3":"code","8c95b6c9":"code","6f00665d":"code","d632a955":"code","809783b1":"code","f327fa22":"code","8f5b8189":"code","e39ced2e":"code","9dd1e989":"code","65aa6cf4":"code","04baab06":"code","6c9a1799":"code","bd7db9fe":"code","ccccb9d0":"code","a46b2c4a":"code","f2a91686":"code","37033ec4":"code","238e201d":"code","14f150f8":"code","fc594391":"code","c430b5be":"code","387125e8":"code","4ca93a7a":"code","30494070":"code","34c4ea2a":"code","1071635f":"code","026800c7":"code","cdae513b":"code","6fe193ce":"code","0b9baa6f":"code","d1f54e50":"code","487e2a7e":"code","fa8689ef":"code","1939f4af":"code","eb430839":"code","041297cf":"code","2411a614":"code","110f0fd4":"code","669a8a4d":"code","7de9e7e0":"markdown","2f73902d":"markdown","dd2487ca":"markdown","153d6bec":"markdown","710ee098":"markdown","6012d098":"markdown","dde944a3":"markdown","e29e9934":"markdown","71fcdd48":"markdown","98c76586":"markdown","19062477":"markdown","63e0ad12":"markdown","b1809be6":"markdown","1ffcacab":"markdown","4b6d3eb5":"markdown"},"source":{"61e512f0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","3be5e31f":"dataset=pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\", encoding='latin-1')\ndataset.dropna(how=\"any\", inplace=True, axis=1)\ndataset.columns = ['label', 'sms']\n# labels=dataset['labels']\n# message=dataset['sms']","7acc670a":"dataset.head()","522c6dd2":"dataset['label'].value_counts()","be0c33bb":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()","109482da":"y_data=dataset['label'].values","4a03495e":"y_data=le.fit_transform(y_data)","eef1c904":"print(y_data)","ce2751c5":"print(dataset['sms'])","d386ec65":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","e98d6d37":"sw=set(stopwords.words('english'))\nps=PorterStemmer()","0d8baa85":"def cleantext(sample):\n    sample=sample.lower()\n    sample=sample.replace(\"<br \/><br \/>\",\" \")\n    sample=re.sub(\"[^a-zA-Z]+\",\" \",sample)\n    \n    sample=sample.split(\" \")\n    sample=[ps.stem(s) for s in sample if s not in sw] # stemming and removing stopwords\n    \n    sample=\" \".join(sample)\n    \n    return sample","33e523e3":"cleantext(dataset['sms'][0])","f386a7f9":"dataset['sms'][0]","12d5269c":"# Apply clean text function to each sms\n\ndataset['cleanedmessage']=dataset['sms'].apply(cleantext)","6a2ae805":"corpus=dataset['cleanedmessage'].values","94bd744f":"from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer","92473d60":"#CountVectorizer transformer from the sklearn.feature_extraction model has its own internal tokenization\n#and normalization methods\n\ncv=CountVectorizer(max_df=0.5,max_features=50000)","634ab6b8":"x_data=cv.fit_transform(corpus)","7f909526":"x_data.shape","337e2d68":"print(x_data[0])","2558dd51":"# Assign weights to every word in the vocab using tf-idf\ntfidf=TfidfTransformer()","88a2dcc0":"x_data=tfidf.fit_transform(x_data)","fe3f8ecc":"print(x_data[0])","76c63163":"x_data.shape","5b2001be":"y_data.shape","f834c779":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.3,random_state=42)","b9e495a8":"#Function for plotting confusion matrix\n\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    #plt.figure(figsize=[10,10])\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 verticalalignment=\"center\",\n                 color=\"blue\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","0de24751":"# FUNCTION TO CALCULATE TRUE POSITIVE, TRUE NEGATIVE ,FALSE POSITIVE AND FALSE NEGATIVE \n\ndef perf_measure(y_actual, y_hat):\n    y_actual=np.array(y_actual)\n    y_hat=np.array(y_hat)\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(y_hat)): \n        if y_actual[i]==y_hat[i] and y_hat[i]==1:\n           TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n           FP += 1\n        if y_actual[i]==y_hat[i]==0:\n           TN += 1\n        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)","4702f7e5":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score","4686bbcb":"clf_lr= LogisticRegression(solver='liblinear', penalty='l1')\nclf_lr.fit(X_train, y_train)\npred_lr=clf_lr.predict(X_test)","21bc4c89":"clf_lr.score(X_test,y_test)","ead8cede":"print(classification_report(y_test,pred_lr))","f6515718":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_lr=confusion_matrix(y_test,pred_lr)\n#print(cnf_matrix_lr)\nplot_confusion_matrix(cnf_matrix_lr,[0,1],normalize=False,title=\"Confusion Matrix\")","e72fc3d5":"# PLOTTING AUC-ROC CURVE\n\nprobs_lr= clf_lr.predict_proba(X_test)\nprobs_lr=probs_lr[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_lr)\nplt.title(\"AUC-ROC curve--LR\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","69e42ec2":"clf_mnb=MultinomialNB(alpha=0.2)\n\nclf_mnb.fit(X_train,y_train)\npred_mnb=clf_mnb.predict(X_test)\nacc_mnb=clf_mnb.score(X_test,y_test)\n\n#acc=accuracy_score(y_test,pred)\nprint(\"Accuracy : \",acc_mnb)","8c7448b5":"print(classification_report(y_test,pred_mnb))","b2607da3":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_mnb=confusion_matrix(y_test,pred_mnb)\n#print(cnf_matrix_mnb)\nplot_confusion_matrix(cnf_matrix_mnb,[0,1],normalize=False,title=\"Confusion Matrix\")","64595693":"# PLOTTING AUC-ROC CURVE\n\nprobs_mnb= clf_mnb.predict_proba(X_test)\nprobs_mnb=probs_mnb[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_mnb)\nplt.title(\"AUC-ROC curve--MNB\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","944f9034":"clf_knn= KNeighborsClassifier(n_neighbors=49)\nclf_knn.fit(X_train,y_train)\n\npred_knn=clf_knn.predict(X_test)\nacc_knn=clf_knn.score(X_test,y_test)\n\nprint(\"Accuracy : \",acc_knn)","6254d6b3":"print(classification_report(y_test,pred_knn))","8c95b6c9":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_knn=confusion_matrix(y_test,pred_knn)\n#print(cnf_matrix_knn)\nplot_confusion_matrix(cnf_matrix_knn,[0,1],normalize=False,title=\"Confusion Matrix\")","6f00665d":"# PLOTTING AUC-ROC CURVE\n\nprobs_knn= clf_knn.predict_proba(X_test)\nprobs_knn=probs_knn[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_knn)\nplt.title(\"AUC-ROC curve--KNN\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","d632a955":"clf_svm = svm.SVC(kernel='sigmoid', gamma=1.0,probability=True)\n\nclf_svm.fit(X_train,y_train)\npred_svm=clf_svm.predict(X_test)\nacc_svm=clf_svm.score(X_test,y_test)\n\nprint(\"Accuracy : \",acc_svm)","809783b1":"print(classification_report(y_test,pred_svm))","f327fa22":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_svm=confusion_matrix(y_test,pred_svm)\n#print(cnf_matrix_svm)\nplot_confusion_matrix(cnf_matrix_svm,[0,1],normalize=False,title=\"Confusion Matrix\")","8f5b8189":"# PLOTTING AUC-ROC CURVE\n\nprobs_svm= clf_svm.predict_proba(X_test)\nprobs_svm=probs_svm[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_svm)\nplt.title(\"AUC-ROC curve--SVM\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","e39ced2e":"clf_dtc=DecisionTreeClassifier(random_state=0)\n\nclf_dtc.fit(X_train,y_train)\npred_dtc=clf_dtc.predict(X_test)\nacc_dtc=clf_dtc.score(X_test,y_test)\n\nprint(\"Accuracy : \",acc_dtc)","9dd1e989":"print(classification_report(y_test,pred_dtc))","65aa6cf4":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_dtc=confusion_matrix(y_test,pred_dtc)\n#print(cnf_matrix_dtc)\nplot_confusion_matrix(cnf_matrix_dtc,[0,1],normalize=False,title=\"Confusion Matrix\")","04baab06":"# PLOTTING AUC-ROC CURVE\n\nprobs_dtc= clf_dtc.predict_proba(X_test)\nprobs_dtc=probs_dtc[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_dtc)\nplt.title(\"AUC-ROC curve--DTC\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","6c9a1799":"clf_rf= RandomForestClassifier(n_estimators=31, random_state=111)\n\nclf_rf.fit(X_train,y_train)\npred_rf=clf_rf.predict(X_test)\nacc_rf=clf_rf.score(X_test,y_test)\n\nprint(\"Accuracy : \",acc_rf)","bd7db9fe":"print(classification_report(y_test,pred_rf))","ccccb9d0":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_rf=confusion_matrix(y_test,pred_rf)\n#print(cnf_matrix_rf)\nplot_confusion_matrix(cnf_matrix_rf,[0,1],normalize=False,title=\"Confusion Matrix\")","a46b2c4a":"# PLOTTING AUC-ROC CURVE\n\nprobs_rf= clf_rf.predict_proba(X_test)\nprobs_rf=probs_rf[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_rf)\n\nplt.title(\"AUC-ROC curve--RandomForest\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","f2a91686":"clf_adb=AdaBoostClassifier(n_estimators=62, random_state=111)\n\nclf_adb.fit(X_train,y_train)\npred_adb=clf_adb.predict(X_test)\nacc_adb=clf_adb.score(X_test,y_test)\n\nprint(\"Accuracy : \",acc_adb)","37033ec4":"print(classification_report(y_test,pred_adb))","238e201d":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_adb=confusion_matrix(y_test,pred_adb)\n#print(cnf_matrix_adb)\nplot_confusion_matrix(cnf_matrix_adb,[0,1],normalize=False,title=\"Confusion Matrix\")","14f150f8":"# PLOTTING AUC-ROC CURVE\n\nprobs_adb= clf_adb.predict_proba(X_test)\nprobs_adb=probs_adb[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_adb)\n\nplt.title(\"AUC-ROC curve--AdaBoost\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","fc594391":"from keras import models\nfrom keras.layers import Dense","c430b5be":"model=models.Sequential()\nmodel.add(Dense(16,activation='relu',input_shape=(X_train.shape[1],)))\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))","387125e8":"model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=['accuracy'])","4ca93a7a":"hist=model.fit(X_train,y_train,batch_size=128,epochs=100)","30494070":"pred_mlp=model.predict(X_test)\npred_mlp[pred_mlp>=0.5]=1\npred_mlp[pred_mlp<0.5]=0\nprint(pred_mlp)","34c4ea2a":"acc_mlp=accuracy_score(pred_mlp,y_test)\nprint(acc_mlp)","1071635f":"print(classification_report(y_test,pred_mlp))","026800c7":"# VISUALIZNG CONFUSION MATRIX\n\ncnf_matrix_mlp=confusion_matrix(y_test,pred_mlp)\n#print(cnf_matrix_mlp)\nplot_confusion_matrix(cnf_matrix_mlp,[0,1],normalize=False,title=\"Confusion Matrix\")","cdae513b":"# PLOTTING AUC-ROC CURVE\n\nprobs_mlp= model.predict_proba(X_test)\nfpr, tpr, thresholds = metrics.roc_curve(y_test,probs_mlp)\nplt.title(\"AUC-ROC curve--MLP\",color=\"green\",fontsize=20)\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(fpr,tpr,linewidth=2, markersize=12)\nplt.show()","6fe193ce":"classifiers=[]\n\nclassifiers.append(('LogisticRegression',clf_lr))\nclassifiers.append(('MNB',clf_mnb))\nclassifiers.append(('KNN',clf_knn))\nclassifiers.append(('SVM',clf_svm))\nclassifiers.append(('Desicion Tree',clf_dtc))\nclassifiers.append(('Random Forest',clf_rf))\nclassifiers.append(('AdaBoost',clf_adb))\nclassifiers.append(('MLP',model))","0b9baa6f":"result=[]\ncnf_matric_parameter=[]\nfor i,v in classifiers:\n    if i=='MLP':\n        pred=v.predict(X_test)\n        pred[pred>=0.5]=1\n        pred[pred<0.5]=0\n        print(pred)\n        acc=accuracy_score(y_test,pred)\n        precision = precision_score(y_test,pred)\n        recall=recall_score(y_test, pred)\n        f_measure=f1_score(y_test,pred)\n        result.append((i,acc,precision,recall,f_measure))\n        \n        TP,FP,TN,FN=perf_measure(y_test,pred)\n        cnf_matric_parameter.append((i,TP,FP,TN,FN))\n        continue\n        \n    \n    pred=v.predict(X_test)\n    acc=accuracy_score(y_test,pred)\n    precision = precision_score(y_test,pred)\n    recall=recall_score(y_test, pred)\n    #print(precision)\n    f_measure=f1_score(y_test,pred)\n    result.append((i,acc,precision,recall,f_measure))\n    \n    TP,FP,TN,FN=perf_measure(y_test,pred)\n    cnf_matric_parameter.append((i,TP,FP,TN,FN))","d1f54e50":"column_names=['Algorithm','Accuracy','Precision','Recall','F-measure']\ndf1=pd.DataFrame(result,columns=column_names)\nprint(df1)","487e2a7e":"df1.plot(kind='bar', ylim=(0.65,1.0), figsize=(15,6), align='center', colormap=\"Accent\")\nplt.xticks(np.arange(8), df1['Algorithm'],fontsize=15)\nplt.ylabel('Score',fontsize=20)\nplt.title('Distribution by Classifier',fontsize=20)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,fontsize=20)","fa8689ef":"column_names=['Algorithm','True_Pos','False_Pos','True_Neg','False_Neg']\ndf2=pd.DataFrame(cnf_matric_parameter,columns=column_names)\nprint(df2)","1939f4af":"## save the result as a csv file to the disk\n\ndf1.to_csv(\"result_spam_sms_det.csv\",index=True)\ndf2.to_csv(\"cnf_matrix_parameter.csv\",index=True)","eb430839":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.metrics import mean_squared_error\nimport math","041297cf":"EPSILON = 1e-10\ndef rae(actual: np.ndarray, predicted: np.ndarray):\n    \"\"\" Relative Absolute Error (aka Approximation Error) \"\"\"\n    return np.sum(np.abs(actual - predicted)) \/ (np.sum(np.abs(actual - np.mean(actual))) + EPSILON)\n\ndef rrse(actual: np.ndarray, predicted: np.ndarray):\n    \"\"\" Root Relative Squared Error \"\"\"\n    return np.sqrt(np.sum(np.square(actual - predicted)) \/ np.sum(np.square(actual - np.mean(actual))))","2411a614":"performance_metrics=[]\nfor i,v in classifiers:\n    if i=='MLP':\n        pred=v.predict(X_test)\n        pred[pred>=0.5]=1\n        pred[pred<0.5]=0\n        pred=pred.reshape(-1)\n        #print(y_test.shape,pred.shape)\n        \n        mae=mean_absolute_error(y_test,pred)\n        mcc=matthews_corrcoef(y_test,pred)\n        mse=mean_squared_error(y_test,pred)\n        rmse = math.sqrt(mse)\n        rrsError=rrse(y_test,pred)\n        raError=rae(y_test,pred)\n        performance_metrics.append((i,mcc,mae,rmse,rrsError,raError))\n        continue\n        \n    \n    pred=v.predict(X_test)\n    #print(y_test.shape,pred.shape)\n    mae=mean_absolute_error(y_test,pred)\n    mcc=matthews_corrcoef(y_test, pred)\n    mse=mean_squared_error(y_test,pred)\n    rmse = math.sqrt(mse)\n    rrsError=rrse(y_test,pred)\n    raError=rae(y_test,pred)\n    performance_metrics.append((i,mcc,mae,rmse,rrsError,raError))","110f0fd4":"# corr_coef == Matthews correlation coefficient\n\ncolumn_names=['Algorithm','corr_coef','MAE','RMSE','RRSE','RAE']\ndf3=pd.DataFrame(performance_metrics,columns=column_names)\nprint(df3)","669a8a4d":"# saving the performance merics to the disk\n\ndf2.to_csv(\"performance_metrics.csv\",index=True)","7de9e7e0":"## DTC","2f73902d":"## Preprocessing of data","dd2487ca":"## SVM","153d6bec":"#### removing stopwords and stemming","710ee098":"## KNN","6012d098":"## MLP","dde944a3":"## Logistic Regression","e29e9934":"## vectorization \/ Feature extraction","71fcdd48":"### splitting of dataset","98c76586":"## Random Forest","19062477":"## AdaBoost","63e0ad12":"## PERFORMANCE METRICS\/ ERROR MEASURES","b1809be6":"### Importing classifiers using sklearn","1ffcacab":"## comparision between diffeternt algorithms ","4b6d3eb5":"## MNB"}}