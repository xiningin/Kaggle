{"cell_type":{"fe7a295b":"code","98b99ad9":"code","74ca608b":"code","93755799":"code","dcd17b17":"code","9f5a4202":"code","c923c413":"code","568cba78":"code","129a77d5":"code","07f13c25":"code","48622906":"code","39ea231e":"code","6c34f1f9":"code","ecc00054":"code","7fde5ce3":"code","8cdb50b1":"code","be07abaf":"code","4089589a":"code","97450951":"code","fc93a515":"code","91e20e0d":"code","9c0545fd":"code","59a723f1":"code","465168df":"code","13beda57":"code","f58784df":"code","df44b5b5":"code","eeb3e889":"code","afcf091a":"code","5e304510":"markdown","230a0907":"markdown","f9f94f31":"markdown","b28932a7":"markdown","7366f7ad":"markdown","c3f976f3":"markdown","0ce39a7e":"markdown","4a606e4e":"markdown","f72c436d":"markdown","b5231a39":"markdown"},"source":{"fe7a295b":"from sklearn.metrics import mean_squared_log_error\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nfrom sklearn import preprocessing\nimport numpy as np\nfrom scipy import integrate, optimize\nimport math\n\npredictions_total = []\nactual_total = []\nval_loss_dict = {}\n\nval_info_dict = {}\npredictions_dict = {}\nactuals_dict = {}\ncolors_dict = {}\nloss_dict = {}\ntrain_start = 0\ntrain_end = 0\nval_start = 0\nval_end = 0\ntest_start = 0\ntest_end = 0\nmodes = [\"Confirmed Cases\", \"Fatalities\"]\nmethod = \"SIR\"\ndynamic_start_day = False","98b99ad9":"test = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/test.csv\", parse_dates=[\"Date\"])\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/train.csv\")\nsubmission = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/submission.csv\")\nall_data = train.copy()\n# Create date columns\nall_data['Date'] = pd.to_datetime(all_data['Date'])\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year","74ca608b":"# Load countries data file\nworld_population = pd.read_csv(\"..\/input\/population-by-country-2020\/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P\/Km\u00b2)', 'Land Area (Km\u00b2)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\n\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country (or dependency)', how='left')\nall_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\n\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country (or dependency)', inplace=True, axis=1)\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\n\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) ","93755799":"class SIR:\n    def __init__(self, beta=0, gamma=0, fix_gamma=False):\n        self.beta = beta\n        self.gamma = gamma\n        self.infected_t0 = 0\n        self.fitted_on = np.array([])\n        self.fix_gamma = fix_gamma\n        self.fitted = False\n        \n    def ode(self, y, x, beta, gamma):\n        '''Defines the ODE that governs the SIRs behaviour'''\n        dSdt = -beta * y[0] * y[1]\n        dRdt = gamma * y[1]\n        dIdt = -(dSdt + dRdt)\n        return dSdt, dIdt, dRdt\n    \n    def solve_ode(self, x, beta, gamma):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(beta, gamma))[:,1])\n    \n    def solve_ode_fixed(self, x, beta):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(beta, self.gamma))[:,1])\n    \n    def describe(self):\n        assert self.fitted, \"You need to fit the model before describing it!\"\n        print(\"Beta: \", self.beta)\n        print(\"Gamma: \", self.gamma)\n        print(\"At t=0: \", self.infected_t0)\n        \n        plt.plot(range(1,len(self.fitted_on)+1), self.fitted_on, \"x\", label='Actual')\n        plt.plot(range(1,len(self.fitted_on)+1), self.predict(len(self.fitted_on)), label='Prediction')\n        plt.title(\"Fit of SIR model to actual\")\n        plt.ylabel(\"% of Population\")\n        plt.xlabel(\"Days\")\n        plt.legend()\n        plt.show()\n    \n    def evaluate(self, y_test):\n        assert self.fitted, \"You need to fit the model before evaluating it!\"\n        print(\"Beta: \", self.beta)\n        print(\"Gamma: \", self.gamma)\n        print(\"At t=0: \", self.infected_t0)\n        \n        y_train = self.fitted_on\n        l_train = len(self.fitted_on)\n        l_test = len(y_test)\n        l_all = l_train + l_test\n        \n        plt.plot(range(1, l_train + 1), y_train, \"x\", label='Actual Train')\n        plt.plot(range(1 + l_train, l_all + 1), y_test, \"x\", label='Actual Test')\n        plt.plot(range(1, l_all + 1), self.predict(l_all), label='Prediction')\n        plt.title(\"Fit of SIR model to actual\")\n        plt.ylabel(\"% of Population\")\n        plt.xlabel(\"Days\")\n        plt.legend()\n        plt.show()\n    \n    def fit(self, y):\n        '''Fits the parameters to the data, assuming the first data point is the start of the outbreak'''\n        if len(y) == 1: y = np.array([0, y[0]]) # SIR needs at least 2 datapoints to fit\n        self.infected_t0 = y[0]\n        x = np.array(range(1,len(y)+1), dtype=float)\n        self.fitted_on = y\n        if(self.fix_gamma):\n            popt, _ = optimize.curve_fit(self.solve_ode_fixed, x, y)\n            self.beta = popt[0]\n        else:\n            popt, _ = optimize.curve_fit(self.solve_ode, x, y, maxfev=1000)\n            self.beta = popt[0]\n            self.gamma = popt[1]\n        self.fitted = True\n        \n    def predict(self ,length):\n        '''Returns the predicted cumulated cases at each time step, assuming outbreak starts at t=0'''\n        #assert self.fitted, \"You need to fit the model before predicting!\"\n        return self.solve_ode(range(1, length+1), self.beta, self.gamma)","dcd17b17":"unknown_countries = []\nhardcoded_countries = {\n    \"Korea, South\": 51269000,\n    \"Diamond Princess\": 3711,\n    \"Taiwan*\": 23800000,\n    \"Saint Vincent and the Grenadines\": 109897,\n    \"Congo (Brazzaville)\":5261000,\n    \"Congo (Kinshasa)\":81340000,\n    \"Cote d'Ivoire\":24300000,\n    \"Czechia\": 10650000,\n    \"Saint Kitts and Nevis\": 55345,\n    \"Burma\": 53370000,\n    \"Kosovo\": 1831000,\n    \"MS Zaandam\": 1432, # cruise ship\n    \"West Bank and Gaza\": 4685,\n    \"Sao Tome and Principe\": 204327,\n}\nhardcoded_province = {\n    \"Saint Pierre and Miquelon\": 5888,\n    \"Bonaire, Sint Eustatius and Saba\": 25157,\n    \"Falkland Islands (Malvinas)\": 2840,\n}\nstate_populations= pd.read_csv(\"..\/input\/covid19-forecasting-metadata\/region_metadata.csv\")\n\ndef get_population(country_name, province_name=None):\n    if province_name:\n        pop = state_populations[state_populations['Province_State']==province_name]['population']\n        if len(pop)==0:\n            if province_name in hardcoded_province:\n                return hardcoded_province[province_name]\n            else:\n                print(f\"Warning: We have no province population data at the moment. Instead of data for {province_name}, using data for {country_name}\")\n        else:\n            return pop.iloc[0]\n    \n    if country_name in hardcoded_countries:\n        return hardcoded_countries[country_name]\n    \n    pop = all_data[all_data[\"Country_Region\"] == country_dict[country_name]].iloc[0][\"Population (2020)\"]\n    if not pop:\n        print(f\"population of {country_name} unknown\")\n        pop = 100\n        unknown_countries.append(country_name)\n    \n    return pop","9f5a4202":"country_name = 'China'\nall_data[all_data[\"Country_Region\"] == country_dict[country_name]].iloc[0][\"Population (2020)\"]","c923c413":"country_name = 'Hubei'\nall_data[all_data[\"Province_State\"] == province_dict[country_name]].iloc[0][\"Population (2020)\"]","568cba78":"def get_country_data(country_name, province_name=None, train_split_factor=1.0):\n  if province_name:\n    confirmed_total_date_country = train[(train['Country_Region']==country_name) & (train['Province_State']==province_name)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_total_date_country = train[(train['Country_Region']==country_name) & (train['Province_State']==province_name)].groupby(['Date']).agg({'Fatalities':['sum']})\n    total_date_country = confirmed_total_date_country.join(fatalities_total_date_country)\n\n    cases = total_date_country.ConfirmedCases['sum'].values\n    cases_normalized = total_date_country.ConfirmedCases['sum'].values \/ get_population(country_name, province_name)\n    fatalities_normalized = total_date_country.Fatalities['sum'].values \/ get_population(country_name, province_name)\n\n    cases_final = cases_normalized[np.argmax(cases>0):]\n    fatalities_final = fatalities_normalized[np.argmax(fatalities_normalized>0):]\n\n    cases_length = len(cases_final)\n    fat_length = len(fatalities_final)\n    cases_split = math.floor(cases_length * train_split_factor)\n    fat_split = math.floor(fat_length * train_split_factor)\n  else:\n    confirmed_total_date_country = train[train['Country_Region']==country_name].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_total_date_country = train[train['Country_Region']==country_name].groupby(['Date']).agg({'Fatalities':['sum']})\n    total_date_country = confirmed_total_date_country.join(fatalities_total_date_country)\n\n    cases = total_date_country.ConfirmedCases['sum'].values\n    cases_normalized = cases \/ get_population(country_name, province_name)\n    fatalities_normalized = total_date_country.Fatalities['sum'].values \/ get_population(country_name, province_name)\n\n    cases_final = cases_normalized[np.argmax(cases>0):]\n    fatalities_final = fatalities_normalized[np.argmax(fatalities_normalized>0):]\n\n    cases_length = len(cases_final)\n    fat_length = len(fatalities_final)\n    cases_split = math.floor(cases_length * train_split_factor)\n    fat_split = math.floor(fat_length * train_split_factor)\n    \n  return cases_final, fatalities_final, cases_split, fat_split, cases_length, fat_length","129a77d5":"import matplotlib.pyplot as plt\ndef visualize(val_loss_dict, val_info_dict, start=0, end=150):\n  fig = plt.figure(figsize=(10,2))\n  ax = fig.add_axes([0,0,1,1])\n\n  loss_sorted = sorted(val_loss_dict.items(), key=lambda x: x[1], reverse=True)\n  print(loss_sorted[10:20])\n  losses = [x[1] for x in loss_sorted[start:end]]\n  countries = [x[0] for x in loss_sorted[start:end]]\n  colors = [val_info_dict[x][\"Color\"] for x in countries]\n  ax.bar(countries, losses, color=colors)","07f13c25":"def visualize_country(country_name, val_info_dict=val_info_dict):\n  info = val_info_dict[country_name]\n  cases_actual = info[\"Cases Actual\"]\n  cases_predicted = info[\"Cases Predicted\"]\n  cases_split = info[\"Case Split\"]\n  fat_actual = info[\"Fatalities Actual\"]\n  fat_predicted = info[\"Fatalities Predicted\"]\n  fat_split = info[\"Fatality Split\"]\n  \n  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30,15))\n\n  ax1.plot(cases_actual, 'o')\n  ax1.plot(cases_predicted)\n  ax1.axvline(x=cases_split, color='gray', linestyle='--')\n  ax1.set_title(\"Fit of SIR model to global infected cases\")\n    \n  ax2.plot(fat_actual, 'o')\n  ax2.plot(fat_predicted)\n  ax2.axvline(x=fat_split, color='gray', linestyle='--')\n  ax2.set_title(\"Fit of SIR model to global fatalities\")\n  \n  plt.show()","48622906":"def train_val_country(country_name, train_split_factor=1.0):\n    cases, fatalities, case_split, fat_split, case_length, fat_length = get_country_data(country_name, train_split_factor=train_split_factor)\n    cases_train = cases[0:case_split]\n    cases_test = cases[case_split:]\n    fat_train = fatalities[0:fat_split]\n    fat_test = fatalities[fat_split:]\n    \n    case_model = SIR()\n    case_model.fit(cases_train)\n    fat_model = SIR()\n    fat_model.fit(fat_train)\n    \n    cases_pred_all = case_model.predict(len(cases_train) + len(cases_test))\n    cases_pred_train = cases_pred_all[:case_split]\n    cases_pred_test = cases_pred_all[case_split:]\n    fat_pred_all = fat_model.predict(len(fat_train) + len(fat_test))\n    fat_pred_train = fat_pred_all[:fat_split]\n    fat_pred_test = fat_pred_all[fat_split:]\n    \n    if(sum(cases_test) > sum(cases_pred_test)):\n      color = \"red\"\n    else:\n      color = \"blue\"\n    \n    cases_train_val_loss = np.sqrt(mean_squared_log_error(cases_train, cases_pred_train)) if (len(cases_train) > 0) else 0\n    fat_train_val_loss = np.sqrt(mean_squared_log_error(fat_train, fat_pred_train)) if (len(fat_train) > 0) else 0\n    cases_test_val_loss = np.sqrt(mean_squared_log_error(cases_test, cases_pred_test)) if (len(cases_test) > 0) else 0\n    fat_test_val_loss = np.sqrt(mean_squared_log_error(fat_test, fat_pred_test)) if (len(fat_test) > 0) else 0\n    #print(f\"Val Loss for {country_name}: {val_loss}\")\n    #print(f\"Sum actual: {sum(cases_test)} Sum predicted: {sum(cases_pred_val)}\")\n    val_loss_dict[country_name] = cases_test_val_loss\n    results_dict =  {\n        \"Country\": country_name,\n        \"Province\": float('nan'),\n        \"Case Model\": case_model,\n        \"Fatality Model\": fat_model,\n        \"Color\": color,\n        \"Cases Predicted\": cases_pred_all,\n        \"Cases Actual\": cases,\n        \"Fatalities Predicted\": fat_pred_all,\n        \"Fatalities Actual\": fatalities,\n        \"Cases Loss Train\": cases_train_val_loss,\n        \"Fatality Loss Train\": fat_train_val_loss,\n        \"Cases Loss Test\": cases_test_val_loss,\n        \"Fatality Loss Test\": fat_test_val_loss,\n        \"Case Split\": case_split,\n        \"Fatality Split\": fat_split,\n        \"Case length\": case_length,\n        \"Fatality length\": fat_length\n    }\n    return results_dict\n\ndef train_val_province(country_name, province_name, train_split_factor=1.0):\n    cases, fatalities, case_split, fat_split, case_length, fat_length = get_country_data(country_name, province_name, train_split_factor=train_split_factor)\n    cases_train = cases[0:case_split]\n    cases_test = cases[case_split:]\n    fat_train = fatalities[0:fat_split]\n    fat_test = fatalities[fat_split:]\n    \n    case_model = SIR()\n    case_model.fit(cases_train)\n    fat_model = SIR()\n    fat_model.fit(fat_train)\n      \n    cases_pred_all = case_model.predict(len(cases_train) + len(cases_test))\n    cases_pred_train = cases_pred_all[:case_split]\n    cases_pred_test = cases_pred_all[case_split:]\n    fat_pred_all = fat_model.predict(len(fat_train) + len(fat_test))\n    fat_pred_train = fat_pred_all[:fat_split]\n    fat_pred_test = fat_pred_all[fat_split:]\n    \n    if(sum(cases_test) > sum(cases_pred_test)):\n      color = \"red\"\n    else:\n      color = \"blue\"\n\n    cases_train_val_loss = np.sqrt(mean_squared_log_error(cases_train, cases_pred_train)) if (len(cases_train) > 0) else 0\n    fat_train_val_loss = np.sqrt(mean_squared_log_error(fat_train, fat_pred_train)) if (len(fat_train) > 0) else 0\n    cases_test_val_loss = np.sqrt(mean_squared_log_error(cases_test, cases_pred_test)) if (len(cases_test) > 0) else 0\n    fat_test_val_loss = np.sqrt(mean_squared_log_error(fat_test, fat_pred_test)) if (len(fat_test) > 0) else 0\n    #print(f\"Val Loss for {country_name}: {val_loss}\")\n    #print(f\"Sum actual: {sum(cases_test)} Sum predicted: {sum(cases_pred_val)}\")\n    val_loss_dict[province_name] = cases_test_val_loss\n    results_dict = {\n        \"Country\": country_name,\n        \"Province\": province_name,\n        \"Case Model\": case_model,\n        \"Fatality Model\": fat_model,\n        \"Color\": color,\n        \"Cases Predicted\": cases_pred_all,\n        \"Cases Actual\": cases,\n        \"Fatalities Predicted\": fat_pred_all,\n        \"Fatalities Actual\": fatalities,\n        \"Cases Loss Train\": cases_train_val_loss,\n        \"Fatality Loss Train\": fat_train_val_loss,\n        \"Cases Loss Test\": cases_test_val_loss,\n        \"Fatality Loss Test\": fat_test_val_loss,\n        \"Case Split\": case_split,\n        \"Fatality Split\": fat_split,\n        \"Case length\": case_length,\n        \"Fatality length\": fat_length\n    }\n    return results_dict","39ea231e":"country_and_provinces = {}\nonly_provinces = {}\nonly_country = []\nfor country in test['Country_Region'].unique():\n  provinces = test[test['Country_Region']==country]['Province_State'].unique()\n  \n  if len(provinces)>1:\n    contains_nan = False\n    for province in provinces:\n      if type(province) == float:\n        contains_nan = True\n    if contains_nan:\n      country_and_provinces[country] = provinces\n    else:\n      only_provinces[country] = provinces\n  else:\n    only_country.append(country)\n","6c34f1f9":"from tqdm import tqdm\n\ntrain_split_factor = 0.9\n\nfor country in tqdm(train['Country_Region'].unique()):\n    #If we only need to predict for the provinces, not for the whole country\n    if country in only_provinces:\n        for province in only_provinces[country]:\n            val_info_dict[province] = train_val_province(country, province, train_split_factor=train_split_factor)\n    \n    #If we need to predict for the provinces and for the whole country\n    elif country in country_and_provinces:\n        for province in country_and_provinces[country]:\n            #For the 'nan' province value: Make predictions for the whole country\n            if type(province) == float:\n                val_info_dict[country] = train_val_country(country, train_split_factor=train_split_factor)\n            else:\n                val_info_dict[province] = train_val_province(country, province, train_split_factor=train_split_factor)\n    \n    #If we don't have any provinces for this country\n    elif country in only_country:\n        val_info_dict[country] = train_val_country(country, train_split_factor=train_split_factor)","ecc00054":"val_loss_dict","7fde5ce3":"# losses\nvisualize(val_loss_dict, val_info_dict, end=20)","8cdb50b1":"def evaluate(name, val_info_dict=val_info_dict):\n    info = val_info_dict[name]\n    \n    case_split = info[\"Case Split\"]\n    fat_split = info[\"Fatality Split\"]\n    cases_test = info[\"Cases Actual\"][case_split:]\n    fat_test = info[\"Fatalities Actual\"][fat_split:]\n    \n    case_model = info[\"Case Model\"]\n    fat_model = info[\"Fatality Model\"]\n    \n    print(name)\n    print(\"Confirmed Cases:\")\n    print(\"  Loss Train: \", info[\"Cases Loss Train\"])\n    print(\"  Loss Test: \", info[\"Cases Loss Test\"])\n    display(case_model.evaluate(cases_test))\n    print(\"Fatalities:\")\n    print(\"  Loss Train: \", info[\"Fatality Loss Train\"])\n    print(\"  Loss Test: \", info[\"Fatality Loss Test\"])\n    display(fat_model.evaluate(fat_test))","be07abaf":"evaluate(\"Germany\")","4089589a":"evaluate(\"Spain\")","97450951":"evaluate(\"Hubei\")","fc93a515":"evaluate(\"Italy\")","91e20e0d":"evaluate(\"New York\")","9c0545fd":"evaluate(\"India\")","59a723f1":"evaluate(\"France\")","465168df":"# submission date range: 02Apr20-14May20\npd_daterange_submission = pd.date_range(\"02Apr20\", \"14May20\") #TODO get from test dataset: min\/max of Date\nlength_submission = len(pd_daterange_submission)\n\ndef make_submission(val_info_dict=val_info_dict, name=\"submission\"):\n  # generate submission frames for all items in val_info_dict\n  frames = []\n  for attr, item in val_info_dict.items():\n    country = item[\"Country\"]\n    province = item[\"Province\"]\n    case_length = item[\"Case length\"]\n    fat_length = item[\"Fatality length\"]\n    case_model = item[\"Case Model\"]\n    fat_model = item[\"Fatality Model\"]\n\n    if(type(province)==float):\n        pop = get_population(country)\n    else:\n        pop = get_population(country, province)\n        \n    case_preds = pop * case_model.predict(case_length + length_submission)[case_length:]\n    fat_preds = pop * fat_model.predict(fat_length + length_submission)[fat_length:]\n\n    frames.append(pd.DataFrame({\n        \"Country_Region\": country,\n        \"Province_State\": province,\n        \"Date\": pd_daterange_submission,\n        \"ConfirmedCases\": case_preds,\n        \"Fatalities\": fat_preds\n        })\n    )\n  \n  # concat sub frames and prepare for mergeing with test to get ForecastId\n  submission_data = pd.concat(frames)\n  submission = test.copy()\n\n  index = [\"id\", \"Date\"]\n  submission[\"id\"] = submission[\"Country_Region\"].astype(str) + \"_\" + submission[\"Province_State\"].astype(str)\n  submission = submission[[\"id\", \"Date\", \"ForecastId\"]].set_index(index)\n\n  submission_data[\"id\"] = submission_data[\"Country_Region\"].astype(str) + \"_\" + submission_data[\"Province_State\"].astype(str)\n  submission_data = submission_data[[\"id\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]].set_index(index)\n\n  # merge w\/ ForecastId and extract submission columns\n  submission = submission.join(submission_data)\n  submission = submission[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]]\n\n  # fillna (China)\n  submission = submission.fillna(1)\n    \n  # write to csv\n  submission.to_csv(name + \".csv\", index=False)\n\n  print(\"submission saved to csv.\")\n  \nmake_submission()","13beda57":"class SIRT:\n    def __init__(self, gamma=0, a=0, b=0, c=0, d=0, fix_gamma=False):\n        self.gamma = gamma\n        self.a = a\n        self.b = b\n        self.c = c\n        self.d = d\n        self.infected_t0 = 0\n        self.fitted_on = np.array([])\n        self.fix_gamma = fix_gamma\n        self.fitted = False\n        \n    def ode(self, y, timestep, c, d, gamma):\n        '''Defines the ODE that governs the SIRs behaviour'''\n        beta = c * timestep + d\n        \n        dSdt = -beta * y[0] * y[1]\n        dRdt = gamma * y[1]\n        dIdt = -(dSdt + dRdt)\n        return dSdt, dIdt, dRdt\n    \n    def solve_ode(self, x, c, d, gamma):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(c, d, gamma))[:,1])\n    \n    def solve_ode_fixed(self, x, beta):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(beta, self.gamma))[:,1])\n    \n    def describe(self):\n        assert self.fitted, \"You need to fit the model before describing it!\"\n        print(\"c: \", self.c)\n        print(\"d: \", self.d)\n        print(\"Gamma: \", self.gamma)\n        print(\"Infected at t=0: \", self.infected_t0)\n        \n        plt.plot(range(1,len(self.fitted_on)+1), self.fitted_on, \"x\", label='Actual')\n        plt.plot(range(1,len(self.fitted_on)+1), self.predict(len(self.fitted_on)), label='Prediction')\n        plt.title(\"Fit of SIR model to global infected cases\")\n        plt.ylabel(\"Population infected\")\n        plt.xlabel(\"Days\")\n        plt.legend()\n        plt.show()\n    \n    def fit(self, y):\n        '''Fits the parameters to the data, assuming the first data point is the start of the outbreak'''\n        self.infected_t0 = y[0]\n        x = np.array(range(1,len(y)+1), dtype=float)\n        self.fitted_on = y\n        if(self.fix_gamma):\n            popt, _ = optimize.curve_fit(self.solve_ode_fixed, x, y)\n            self.beta = popt[0]\n        else:\n            popt, _ = optimize.curve_fit(self.solve_ode, x, y)\n            self.c = popt[0]\n            self.d = popt[1]\n            self.gamma = popt[2]\n        self.fitted = True\n        \n    def predict(self ,length):\n        '''Returns the predicted cumulated cases at each time step, assuming outbreak starts at t=0'''\n        #assert self.fitted, \"You need to fit the model before predicting!\"\n        return self.solve_ode(range(1, length+1), self.c, self.d, self.gamma)","f58784df":"measures = pd.read_csv(\"..\/input\/covid19-containment-and-mitigation-measures\/COVID 19 Containment measures data.csv\")\nmeasures[\"Keywords\"].fillna(value=\"-\", inplace=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('South Korea', 'Korea, South', regex=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('US:Georgia', 'US', regex=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('US: Illinois', 'US', regex=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('US:Maryland', 'US', regex=True)\n\nmeasures = measures[measures[\"Country\"] != \"Vatican City\"]\nmeasures = measures[measures[\"Country\"] != \"Hong Kong\"]\n\ndef get_measures(measure_name):\n    \n    took_measure = measures[measures[\"Keywords\"].str.contains(\"distancing\")]\n    output = pd.DataFrame(data=0,\n                          columns=train['Country_Region'].unique(),\n                          index=pd.date_range(\"02.01.2020\", \"03.01.2020\"))\n    \n    print(took_measure)\n    \n    for index, row in took_measure.iterrows():\n        output[row[\"Country\"]][pd.to_datetime(row[\"Date Start\"]):] = 1\n    return output\n                               \n#get_measures(\"distancing\")[\"Italy\"]","df44b5b5":"model = SIRT()\nc, _, case_split, _, case_length, _ = get_country_data(\"Spain\")\nmodel.fit(c[:case_split])\nmodel.describe()","eeb3e889":"get_country_data(\"Spain\")","afcf091a":"for attr, item in val_info_dict.items():\n    country = item[\"Country\"]\n    province = item[\"Province\"]\n    case_length = item[\"Case length\"]\n    fat_length = item[\"Fatality length\"]\n    case_model = item[\"Case Model\"]\n    fat_model = item[\"Fatality Model\"]","5e304510":"# [WIP] Temporal SIR-Model\nAdd temporal variability to SIR-Model's parameters","230a0907":"## Data Prep","f9f94f31":"# COVID19 week4 SIR-Model (LeoCorona)\nhttps:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-4","b28932a7":"## Visualization Helpers","7366f7ad":"# [WIP] Modeling SIR Parameters\nPredicting SIR parameters from Country\/Province Metadata","c3f976f3":"## Submission","0ce39a7e":"## Results","4a606e4e":"## SIR Model","f72c436d":"## Training","b5231a39":"### Evaluate Country\/Province by Example"}}