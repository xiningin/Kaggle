{"cell_type":{"f3cb9429":"code","49e550a0":"code","07be48f6":"code","11976bcc":"code","b8e5c0d4":"code","29a3267a":"code","41b58f43":"code","c8476053":"code","8035d835":"code","d68d8856":"code","99953818":"code","d2be1514":"code","148b73b0":"code","62ccfe12":"code","50a7d1dc":"code","82beca64":"code","8cd0e1ab":"code","fb77289f":"code","5dd0ef53":"code","6ca82524":"code","827c2280":"code","9075c3cf":"code","db819949":"code","a4a6fc33":"code","a255e765":"code","12080b7c":"code","487dedab":"code","e1738b40":"code","0cdc830c":"code","65f37731":"code","ae078923":"code","565f5363":"markdown","444c0839":"markdown","23f20eca":"markdown","4a6f3d9e":"markdown","e9e9081a":"markdown","6abd6c9f":"markdown","a52c8338":"markdown","6a4c356c":"markdown","385f4eec":"markdown","6d0f7f86":"markdown","b9cbacbf":"markdown","4a665a62":"markdown","a80a6234":"markdown","d5c6ec63":"markdown"},"source":{"f3cb9429":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, BatchNormalization,LSTM,Bidirectional,MaxPooling2D,GlobalMaxPooling2D,TimeDistributed\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import confusion_matrix","49e550a0":"data = pd.read_csv('..\/input\/confused-eeg\/EEG_data.csv')\ndata.head()","07be48f6":"demographic_data = pd.read_csv('..\/input\/confused-eeg\/demographic_info.csv')\ndemographic_data = demographic_data.rename(columns = {'subject ID':'SubjectID'})\ndemographic_data\n#data = data.merge(demographic_data,how = 'inner',on = 'SubjectID')\n#data.head()","11976bcc":"unique_data = pd.DataFrame([data[c].value_counts().size for c in data.columns], index=data.columns, columns = ['count of unique values'])\nunique_data","b8e5c0d4":"#identifying missing values\ndata.isnull().sum()","29a3267a":"data.describe()","41b58f43":"dataset = data.copy()\ndataset = dataset[dataset['Attention'] > 0.0]\ndataset = dataset[dataset['Mediation'] > 0.0]\ndataset_all = dataset.copy()\ndataset.drop(columns = ['SubjectID','VideoID','predefinedlabel'],inplace=True)\n","c8476053":"print(\"After cleaning, the data has {} rows and {} columns.\".format(dataset.shape[0],dataset.shape[1]))","8035d835":"dataset.hist(figsize = (15,15), grid = False, color = \"green\", edgecolor = 'black',linewidth = 1.5 )\nplt.suptitle('Histogram of different features in the dataset',fontsize = 20,y= 0.92)\nplt.show()","d68d8856":"#Applying non-linear normalization for spreading the data\nX_n = dataset.iloc[:,:-1].copy() #data that will be normalized\nX_n.iloc[:,3:11] = np.log2(X_n.iloc[:,3:11] + 0.0001) #spreading the amount data using log normalization technique\nX_n.iloc[:,3:11].hist(figsize = (15,15), grid = False, color = \"green\", edgecolor = 'black',linewidth = 1.5 )","99953818":"m = np.mean(X_n, axis=0) # array([16.25, 26.25])\nstd = np.std(X_n, axis=0) # array([17.45530005, 22.18529919])\nmd = np.median(X_n,axis = 0)\np75 = np.percentile(X_n,75,axis = 0)\np25 = np.percentile(X_n,25,axis = 0)","d2be1514":"X_n = np.tanh((X_n - md) \/ (p75 - p25)) #normalization and feature scaling for train set","148b73b0":"X_n.hist(figsize = (15,15), grid = False, color = \"green\", edgecolor = 'black',linewidth = 1.5 )\nplt.suptitle('Histogram of different features in the dataset after normalization',fontsize = 20,y= 0.92)\nplt.show()","62ccfe12":"plt.figure(figsize = (15,15))\ncor_matrix = pd.concat((X_n,dataset_all['user-definedlabeln']),axis = 1).corr()\nsns.heatmap(cor_matrix,annot=True)","50a7d1dc":"X = X_n #features\nY = dataset.iloc[:,-1] #targets","82beca64":"#identify the minimum and maximum length of time-series data in the dataset\nVideoID = list(set(data.iloc[:,1]))\nSubjectID = list(set(data.iloc[:,0])) \nAmin=150 # length of signal\nAmax = 0\nfor i in range(len(SubjectID)):\n    for j in range(len(VideoID)):\n        Xtemp=data[(data.iloc[:,0]==SubjectID[i]) & (data.iloc[:,1]==VideoID[j])]\n        Amin = min(len(Xtemp.iloc[:,14]),Amin)\n        Amax = max(len(Xtemp.iloc[:,14]),Amax)\nprint(\"The minimum length of the time series data is {}.\".format(Amin))\nprint(\"The maximum length of the time series data is {}.\".format(Amax))","8cd0e1ab":"X = np.asarray(X)\nY = np.asarray(Y)\nS = np.asarray(dataset_all.iloc[:,0])\nV = np.asarray(dataset_all.iloc[:,1])\nX1 = {}\nY1 = {}\nfor i in range(X.shape[0]): #for each row of features\n    s = int(S[i]*10 + V[i])\n    if s not in X1.keys():\n        X1[s] = X[i]\n    elif X1[s].shape[0]<Amin*11: # 112*11\n        X1[s] = np.concatenate((X1[s],X[i]),axis =0)\n    Y1[s]= Y[i]","fb77289f":"length_dict = {key: len(value) for key, value in X1.items()}\nlen(set(length_dict.values())) <= 1 #all values are equal","5dd0ef53":"X2 = {}\nY2 = {}\nfor i in range(X.shape[0]): #for each row of features\n    s = int(S[i]*10 + V[i])\n    if s not in X2.keys():\n        X2[s] = X[i]\n    else:\n        X2[s] = np.concatenate((X2[s],X[i]),axis =0)\n    Y2[s]= Y[i]\n    \nfor key in X2.keys():\n    z = np.zeros(Amax*11 - len(X2[key])) #144X11\n    X2[key] = np.concatenate((X2[key],z),axis = 0) #zero padding at the end","6ca82524":"length_dict = {key: len(value) for key, value in X2.items()}\nlen(set(length_dict.values())) <= 1 #all values are equal","827c2280":"D1 = np.zeros((100,Amin*11),dtype = float)\nT = np.zeros((100,1),dtype = int)\nD2 = np.zeros((100,Amax*11),dtype = float)\nfor i in X1.keys():\n    D1[i,:] = X1[i]\n    D2[i,:] = X2[i]\n    T[i] = Y1[i]","9075c3cf":"D1 = D1.reshape(-1,1,Amin,11,1)\nD2 = D2.reshape(-1,1,Amax,11,1)","db819949":"def plotLearningCurve(history,epochs,text):\n  epochRange = range(1,epochs+1)\n  plt.figure(figsize = (5,5))\n  plt.plot(epochRange,history.history['accuracy'])\n  plt.plot(epochRange,history.history['val_accuracy'])\n  plt.title('Model Accuracy for ' + text)\n  plt.xlabel('Epoch', fontsize = 20)\n  plt.ylabel('Accuracy', fontsize = 20)\n  plt.legend(['Training set','Validation set'])\n  plt.show()\n  \n  plt.figure(figsize = (5,5))\n  plt.plot(epochRange,history.history['loss'])\n  plt.plot(epochRange,history.history['val_loss'])\n  plt.title('Model Loss for ' + text)\n  plt.xlabel('Epoch', fontsize = 20)\n  plt.ylabel('Loss', fontsize = 20)\n  plt.legend(['Training set','Validation set'])\n  plt.show()","a4a6fc33":"def lstm_model(Xtrain,Xtest,ytrain,ytest,maxlen,featlen,epochs):\n    i = Input(shape=(None,maxlen,featlen,1)) #maxlen gives us the number of temporal slices per data point\n    x = TimeDistributed(Conv2D(16,(3,3),activation = 'tanh'))(i)\n    x = Dropout(0.05)(x)\n    x = TimeDistributed(Conv2D(32,(5,5),activation = 'tanh'))(x)\n    x = Dropout(0.05)(x)\n    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x)\n    x = TimeDistributed(Flatten())(x)\n    x = Bidirectional(LSTM(75, return_sequences=True),merge_mode = 'ave')(x)\n    x = Dense(1, activation='sigmoid')(x)\n    model = Model(i, x)\n    model.summary()\n    #Training the LSTM\n    model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n    r = model.fit(Xtrain,ytrain, \n                  validation_data = (Xtest,ytest), \n                  epochs = epochs, \n                  verbose = 2,\n                  batch_size = 32,\n                 shuffle = True)\n    print(\"Train score:\", model.evaluate(Xtrain,ytrain))\n    print(\"Test score:\", model.evaluate(Xtest,ytest))\n    return r,model","a255e765":"#For dataset D1\nXtrain, Xtest, ytrain, ytest = train_test_split(D1, T, test_size=0.2, random_state=0)\nr,model = lstm_model(Xtrain,Xtest,ytrain,ytest,Amin,11,epochs = 100)","12080b7c":"plot_model(model)","487dedab":" plotLearningCurve(r,100,text = 'Dataset 1')","e1738b40":"#Generate predictions for the test dataset\nypred = model.predict(Xtest,batch_size = 32).flatten()\nypred = ypred>0.5\n#Get the confusion matrix\ncf_matrix = confusion_matrix(ytest, ypred)\nsns.heatmap(cf_matrix,annot = True,fmt ='g', cmap='Blues')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix for Dataset 1')\nplt.show()","0cdc830c":"#For dataset D2\nXtrain, Xtest, ytrain, ytest = train_test_split(D2, T, test_size=0.2,random_state = 0)\nr,model = lstm_model(Xtrain,Xtest,ytrain,ytest,Amax,11,epochs = 100)","65f37731":" plotLearningCurve(r,100,text = 'Dataset 2')","ae078923":"#Generate predictions for the test dataset\nypred = model.predict(Xtest,batch_size = 32).flatten()\nypred = ypred>0.5\n#Get the confusion matrix\ncf_matrix = confusion_matrix(ytest, ypred)\nsns.heatmap(cf_matrix,annot = True,fmt ='g', cmap='Blues')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix for Dataset 2')\nplt.show()","565f5363":"\n# **4.Predictive modelling using CNN + Bi-Directional LSTM**\n\nUsing CNN along with LSTM networks helps extracting useful signal features from the sequences.","444c0839":"# **2. Loading and Preprocessing the data**","23f20eca":"**Comments**:<br>\nSo we managed to spread some of the features in the dataset. Let us now use a combination of tanh normalization and robust scaleing for transforming the data i.e. spreading the data and scaling it in the range [-1,1]","4a6f3d9e":"**Comments**:<br>\nThere are no missing values in the dataset.","e9e9081a":"### Cleaning the data","6abd6c9f":"#### Creating dataset with minimum length of the time series.","a52c8338":"**Comments**:<br>\nThe above histograms shows that most of the features have their distributions skewed. The histogram of target user-definedlabeln shows that the dataset is fairly balanced. The skewness in the distribution has to be be removed.Some of the features are not spread across the entire range. Also, feature scales are very different. So appropriate normalization needs to be applied to spread the data over the normalized range and yield maximum information from the given data.","6a4c356c":"## Motivation\nPoor performance in the learning process mainly stems from confusion. Detecting confusion in a human\u2019s mind in real time is essential for online education to improve the experience. Massive Open  Online Courses  (MOOC) serve  millions  of  students  at  the  same  time,  but  has several shortcomings as compared to in-class education. In the current scenario, efforts have been made to improve the communication between the instructors and the students by offering interactive forums, feedback forms, quiz etc. But there are still some problems that seperate online courses from in-class education. One of the main problems is detecting students confusion  level.  Unlike  in-class education,  where  a  teacher  can  judge  if  the  students  understand  the  materials  by  verbal  inquiries  or  their  body  language,  immediate feedback  from  the  student  is  less accessible  in  long  distance  education.  \n\n\n\n## Dataset Information \n\nThe dataset consists of EEG signal data collected from 10 college students while they watched MOOC video clips. The EEG signal can help detecting students mental states by acquiring signals from the brain.These 10 students were assigned to watch 20 videos, 10 of which were pre-labeled as \u201ceasy\u201d and 10 as \u201cdifficult\u201d. First, several online education videos were selected that were assumed not to be confusing for the students. Each video was about 2 minutes long. For \u201cdifficult\u201d videos, the two-minute clip was taken abruptly from the middle of a topic to make the videos more confusing. The dataset was prepared by randomly selecting 5 videos from each category for each student. The dataset has a total of 12811 samples. On an average there are 120 samples for each data points. There are 100 datapoints, 10 coming from each student. \n\n\n| Feature | Description | Sampling Rate | Statistic |             \n| :- | :- | :- | :- |\n|Attention|Proprietary measure of mental focus|1 Hz|Mean|      \n|Meditation|Proprietary measure of calmness|1 Hz|Mean|              \n|Raw|Raw EEG signal|512 Hz|Mean|              \n|Delta|1\u20133 Hz of power spectrum|8 Hz|Mean|\n|Theta|4\u20137 Hz of power spectrum|8 Hz|Mean|\n|Alpha1|Lower 8\u201311 Hz of power spectrum|8 Hz|Mean\n|Alpha2|Higher 8\u201311 Hz of power spectrum|8 Hz|Mean|\n|Beta1|Lower 12\u201329 Hz of power spectrum|8 Hz|Mean|\n|Beta2|Higher 12\u201329 Hz of power spectrum|8 Hz|Mean|\n|Gamma1|Lower 30\u2013100 Hz of power spectrum|8 Hz|Mean|\n|Gamma2|Higher 30\u2013100 Hz of power spectrum|8 Hz|Mean|\n\nThere are two label columns \u2014 user-defined label (self-labeled by the students based on their experience) and predefined label (where they are expected to be confused).\n\n \n## Project Overview\nThe project deals with using the convolutional bidirectional LSTM networks to correctly identify confusion among students.\n\n## References\n1. Wang, H., Li, Y., Hu, X., Yang, Y., Meng, Z., & Chang, K. M. (2013, June). Using EEG to Improve Massive Open Online Courses Feedback Interaction. In AIED Workshops.\n2. Ni, Z., Yuksel, A. C., Ni, X., Mandel, M. I., & Xie, L. (2017). Confused or not Confused?: Disentangling Brain Activity from EEG Data Using Bidirectional LSTM Recurrent Neural Networks. ACM-BCB ... ... : the ... ACM Conference on Bioinformatics, Computational Biology and Biomedicine. ACM Conference on Bioinformatics, Computational Biology and Biomedicine, 2017, 241\u2013246. https:\/\/doi.org\/10.1145\/3107411.3107513\n3. Wang, H., Wu, Z., & Xing, E. P. (2018). Removing confounding factors associated weights in deep neural networks improves the prediction accuracy for healthcare applications. In BIOCOMPUTING 2019: Proceedings of the Pacific Symposium (pp. 54-65).\n\n**Please upvote if you like my work.**","385f4eec":"**Comment**: <br>\nAll the features have been spread and scaled in the range [-1,1].","6d0f7f86":"**Comments**:<br>\nMeditation and attention have some values as zero which doesn't make sense at all. As specified by the author of the dataset, these values may be due to problems during data collection .i.e. incorrect position of the device on the head by the student. \n\nThe dataset may have some features that might profoundly confound the results. These features are SubjectID and VideoID. The SubjectID and VideoID indicate details which are not related to the EGG brainwave. These features will overfit the model since we have have 10 clips in all for each of the 10 students and these 60 sec clips are divided into parts of 0.5 sec samples. There is a chance that the model may end up learning these IDs and the resultant prediction might be dominated by these features. The 'predefinedlabel' label indicates which confusion state was supposed to be detected by the experiment conductor prior to the test. We donot need this feature. Our target is the 'user-definedlabel' since it is the label that indicates if a signal is correlated to a confusion state.","b9cbacbf":"### Normalization and standarization","4a665a62":"# **3. Creating datasets**","a80a6234":"# **1. Importing Libraries**","d5c6ec63":"#### Creating dataset with maximum length of the time series."}}