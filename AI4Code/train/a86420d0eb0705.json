{"cell_type":{"3af5116d":"code","f74dc4e5":"code","af32d373":"code","a4ca5766":"code","87e52d0c":"code","f4ca7334":"code","16ac883f":"code","690da157":"code","1b7a15b7":"code","d28201f0":"code","d64bb172":"code","2548059e":"code","668b6951":"code","b25b35e4":"code","bd44ed6c":"markdown","11405d01":"markdown","5d9a94d5":"markdown","013a3ac1":"markdown","c38a3208":"markdown","a64587d2":"markdown","62efe8fc":"markdown","2872f2e5":"markdown","ab9f9b38":"markdown","aa711e30":"markdown","5cad9567":"markdown","08727924":"markdown","f089da5a":"markdown"},"source":{"3af5116d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nimport tensorflow.keras \nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\nfrom keras import optimizers\nimport tensorflow as tf\nimport cv2 \nimport numpy as np \nimport matplotlib.pyplot as plt \nprint(\"tensorflow version is : \", tf.__version__)","f74dc4e5":"path_train=os.path.join(\"\/kaggle\/input\/fashionmnist\",\"fashion-mnist_train.csv\")\npath_test=os.path.join(\"\/kaggle\/input\/fashionmnist\",\"fashion-mnist_test.csv\")\nprint(path_train),print(path_test)\ntrain=pd.read_csv(path_train)\ntest=pd.read_csv(path_test)\n\nprint(\"train shape: \",train.shape)\nprint(\"test shape: \",test.shape)","af32d373":"train.tail(3)\ntest.head(3)","a4ca5766":"y_train=train.iloc[:,:1]\nx_train = train.iloc[:,1:]\ny_test = test.iloc[:,:1]\nx_test = test.iloc[:,1:]\n\nprint(\"x_train shape: \", x_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"x_test shape: \", x_test.shape)\nprint(\"y_test shape: \", y_test.shape)\n","87e52d0c":"#normalize\n\nx_train = x_train\/255.\nx_test  = x_test\/255.\n\n#reshape images\nx_train = x_train.values.reshape(-1,28,28,1)\nx_test = x_test.values.reshape(-1,28,28,1)\n#one-hot encoding\nnum_classes=10\ny_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\ny_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n\nprint(\"x_train shape: \", x_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"x_test shape: \", x_test.shape)\nprint(\"y_test shape: \", y_test.shape)\n","f4ca7334":"fig = plt.figure(figsize = (11, 12))\n\nfor i in range(16):  \n    plt.subplot(4,4,1 + i)\n    plt.title(np.argmax(y_train[i]),fontname=\"Times New Roman\",fontweight=\"bold\")\n    plt.imshow(x_train[i,:,:,0], cmap=plt.get_cmap('gray'))\nplt.show()","16ac883f":"\nimg_rows = 28\nimg_cols = 28\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n    \nprint (input_shape)","690da157":"#Hyper Parameters\nbatch_size = 128\nnum_classes = 10\nepochs = 20\nlearning_rate=0.001\n","1b7a15b7":"modela = Sequential()\nmodela.add(Flatten(input_shape=input_shape))\n\nmodela.add(Dense(8, activation='sigmoid'))\n\nmodela.add(Dense(16, activation='sigmoid'))\n\nmodela.add(Dense(num_classes, activation='softmax'))\n\n\nadam=tensorflow.keras.optimizers.Adam(lr=learning_rate)\nmodela.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nmodela.summary()\n\nhistory=modela.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \\\nvalidation_data=(x_test, y_test), shuffle=True)\nval_loss, val_acc=modela.evaluate(x_test, y_test )\nprint(\"validation loss: \", val_loss),print( \"<3 \")\nprint(\"validation accuracy: \", val_acc)\n","d28201f0":"print(\"learn rate: \",learning_rate, \",epochs: \", epochs)\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=input_shape))\nmodel.add(Dense(512, activation='tanh'))\nmodel.add(Dense(1024, activation='tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024, activation='tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\nadam=tensorflow.keras.optimizers.Adam(lr=learning_rate)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\nmodel.summary()","d64bb172":"history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \\\nvalidation_data=(x_test, y_test), shuffle=True)\nval_loss, val_acc=model.evaluate(x_test, y_test )\nprint(\"validation loss: \", val_loss),print( \"<3 \")\nprint(\"validation accuracy: \", val_acc)\n","2548059e":"print(\"learn rate: \",learning_rate, \",epochs: \", epochs)\n\nmodel2 = Sequential()\nmodel2.add(Flatten(input_shape=input_shape))\nmodel2.add(Dense(512, activation='relu'))\nmodel2.add(Dense(1024, activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(1024, activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(num_classes, activation='softmax'))\n\n\nadam=tensorflow.keras.optimizers.Adam(lr=learning_rate)\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nmodel2.summary()\nhistory=model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \\\nvalidation_data=(x_test, y_test), shuffle=True)\nval_loss, val_acc=model2.evaluate(x_test, y_test )\nprint(\"validation loss: \", val_loss),print( \"<3 \")\nprint(\"validation accuracy: \", val_acc)\n","668b6951":"model3 = Sequential()\nmodel3.add(Flatten(input_shape=input_shape))\nmodel3.add(Dense(512, activation='relu'))\nmodel3.add(Dense(1024, activation='relu'))\nmodel3.add(Dropout(0.2))\nmodel3.add(Dense(1024, activation='relu'))\nmodel3.add(Dropout(0.2))\nmodel3.add(Dense(num_classes, activation='softmax'))\n\n\nRMS=tensorflow.keras.optimizers.RMSprop(lr=learning_rate)\nmodel3.compile(loss='categorical_crossentropy', optimizer=RMS,metrics=['accuracy'])\n\nmodel3.summary()\nhistory=model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \\\nvalidation_data=(x_test, y_test), shuffle=True)\nval_loss, val_acc=model3.evaluate(x_test, y_test )\nprint(\"validation loss: \", val_loss),print( \"<3 \")\nprint(\"validation accuracy: \", val_acc)\n","b25b35e4":"model4 = Sequential()\nmodel4.add(Flatten(input_shape=input_shape))\nmodel4.add(Dense(1024, activation='relu'))\n\nmodel4.add(Dense(2048, activation='relu'))\nmodel4.add(Dropout(0.2))\nmodel4.add(Dense(1024, activation='relu'))\nmodel4.add(Dropout(0.2))\nmodel4.add(Dense(512, activation='relu'))\nmodel4.add(Dense(num_classes, activation='softmax'))\n\nadam=tensorflow.keras.optimizers.Adam(lr=learning_rate)\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nmodel4.compile(loss='categorical_crossentropy', optimizer=adam,metrics=['accuracy'])\n\nmodel4.summary()\nhistory=model4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \\\nvalidation_data=(x_test, y_test), shuffle=True)\nval_loss, val_acc=model4.evaluate(x_test, y_test )\nprint(\"validation loss: \", val_loss),print( \"<3 \")\nprint(\"validation accuracy: \", val_acc)\n","bd44ed6c":"A\u015fa\u011f\u0131da ilk 16 g\u00f6rseli ve ait olduklar\u0131 s\u0131n\u0131flar\u0131 \u00e7izdiren bir matplotlib kodu bulunmaktad\u0131r.","11405d01":"* input --> 512-> relu -> 1024 ->relu -> 1024 -> relu -> Softmax, optimizer = adam\n\nBa\u015far\u0131m:   0.898 ( Val Acc.)","5d9a94d5":"\u015eimdi bu kod \u00e7ok \u00f6nemli de\u011fil, bu olmasa da \u00e7al\u0131\u015f\u0131r kodumuz ama temel olarak imgelerin farkl\u0131 formatlar\u0131 olabiliyor. Bu formatlardan baz\u0131lar\u0131 kanal say\u0131s\u0131n\u0131 ilk ba\u015fta ifade ediyor, b\u00f6yle bir imge var ise hizalamak i\u00e7in b\u00f6yle bir kod yaz\u0131lmakta. Sonu\u00e7 olarak yapay sinir a\u011f\u0131na giri\u015fimiz i\u00e7in imgelerin hepsi 28x28x1 boyutunda. E\u011fer konvolasyonel sinir a\u011f\u0131 (CNN) kullanmayacak isek bu array'i yukarda bahsetti\u011fim gibi vekt\u00f6re \u00e7evirece\u011fiz. CNN'ler \"MNIST Turkce Aciklamali Derin Ogrenmeye Giris - 2\" \u00e7al\u0131\u015fmas\u0131n\u0131n konusu olacakt\u0131r.","013a3ac1":"\u0130lk s\u00fctunu y train ve y test'e aktar\u0131yoruz. Son durumda x_train piksel de\u011ferleri ve x_test ground truth(do\u011fru etiket) ile modelimizi e\u011fitece\u011fiz. E\u011fitilmi\u015f modele x_test girdisini vererek e\u011fitilen yapay sinir a\u011f\u0131n\u0131n sonu\u00e7 vermesini sa\u011flayaca\u011f\u0131z. Daha sonra y_test'de bulunan do\u011fru etiketler ile validation accuracy yani do\u011frulama ad\u0131m\u0131 ba\u015far\u0131m\u0131n\u0131 hesaplayarak modelin g\u00f6rmedi\u011fi data \u00fcst\u00fcndeki ba\u015far\u0131m\u0131n\u0131 sorgulayaca\u011f\u0131z. Burada en \u00f6nemli olan konu test verisinin train verisine s\u0131zmamas\u0131d\u0131r. Bundan dolay\u0131 \u00f6ncesinde standartla\u015ft\u0131rma kullan\u0131lmas\u0131 durumunda fit, fit_transform komutlar\u0131na dikkat etmek gerekir. Biz bu \u00e7al\u0131\u015fmam\u0131zda kullanm\u0131yoruz.","c38a3208":"* input -> 512 -> tanh ->1024 -> tanh -> 1024 -> tanh -> softmax\n\nBa\u015far\u0131m:   0.894 ( Val Acc.)","a64587d2":"\n# **$\\color{purple}{\\text{Derin \u00d6\u011frenmeye Giri\u015f 1 - MNIST FASHION Veri Seti ile \u0130leri Beslemeli A\u011flar  }}$**\n\n*Hi folks, this notebook dedicated to Turkish researchers & deep leaners. Hence, the language is completely Turkish.*\n\nHerkese merhaba, kaggle setlerine ve e\u011fitimlerine devam ediyoruz. Bu notebook ile yapay sinir a\u011flar\u0131na bir giri\u015f yapaca\u011f\u0131z. Sonras\u0131nda Mnist fashion data setini inceleyerek \u00fczerinde basit \"ileri beslemeli yapay sinir a\u011flar\u0131n\u0131\" e\u011fitece\u011fiz ve haz\u0131r modeller kullanmaktan \u00e7ok kendimizin **Keras** k\u00fct\u00fcphanesi ile kuraca\u011f\u0131 modeller \u00fczerinde hiperparemetreler \u00fczerinden de\u011ferlendirmeler yapaca\u011f\u0131z. Derin \u00f6\u011frenmeye ba\u015flamak isteyen veya yeni ba\u015flam\u0131\u015f ara\u015ft\u0131rmac\u0131lar i\u00e7in i\u015fin temelinden ba\u015flanmas\u0131n\u0131 \u00f6neririm. Bu notebook tam olarak temele yani matemati\u011fine inmese de o temele inmek i\u00e7in bir kap\u0131 olabilir.\n\n\u0130lk olarak, e\u011fitmenli \u00f6\u011fretme (supervised learning) yapay sinir a\u011flar\u0131n\u0131n temelini neyin olu\u015fturu\u011funu bilmekte fayda var. Hedef de\u011fere g\u00f6re hedef fonksiyonu minimize veya maksimize etme problemi bizi optimizasyon teorisine kadar g\u00f6t\u00fcrmektedir. En k\u00fc\u00e7\u00fck kareler kural\u0131 (least squares method) [1]  hedef de\u011fere ula\u015fmak i\u00e7in hedef fonksiyon katsay\u0131lar\u0131n\u0131 optimize eden ilk algoritmalardan birisidir. Bana g\u00f6re bu i\u015fin de ilk \u00e7\u0131k\u0131\u015f noktas\u0131 bu olmu\u015ftur. Tabi optimizasyon teorisi derin \u00f6\u011frenmenin bir par\u00e7as\u0131 olsa da kimse onu anmamaktad\u0131r :\/ Oysa geri yay\u0131l\u0131mda(backprop) kulland\u0131\u011f\u0131m\u0131z gradient descent algoritmas\u0131 ve L2, Adam, RMSprop, Madam gibi momentum algoritmalar\u0131n\u0131n temeli bu matematikten gelmektedir. Es ge\u00e7memek gerekir.\n\n![leastsquares](https:\/\/www.i2tutorials.com\/wp-content\/media\/2019\/11\/ordinary-Least-square-method-in-Machine-Learning-i2tutorials.jpg)\n\n\nDaha sonras\u0131nda ise bilinen en eski yapay sinir a\u011f\u0131 olan perceptron 1958 y\u0131l\u0131nda Frank Rosenblatt'\u0131n  Cornell Aeronautical Laboratuvarlar\u0131ndaki \u00e7al\u0131\u015fmalar\u0131nda ortaya koydu\u011fu tek n\u00f6ron yap\u0131l\u0131 modeldir.\u00d6\u011frenme kural\u0131 olarak delta kural\u0131 (delta rule) kullanan ileri beslemeli (feedforward) sinir a\u011f\u0131 her \u015feyin ba\u015flang\u0131c\u0131 olmu\u015ftur. Tabi ilk eksikli\u011fi XOR problemini \u00e7\u00f6zememesiyle ortaya konulunca \u00e7e\u015fitli yenilikler de birbirini takip etti. \u0130lk olarak perceptron aktivizasyon fonksiyonu olarak ad\u0131m fonksiyonu (step function) kullanmaktayd\u0131. Bu da delta kural\u0131 ile \u00f6\u011frenme a\u015famas\u0131nda bir tak\u0131m s\u0131n\u0131rlar olu\u015fturmaktayd\u0131. G\u00fcn\u00fcm\u00fczde dahi tercih edilen (?) sigmoid fonksiyonu eklendi\u011finde ise art\u0131k XOR problemini \u00e7\u00f6zebilen bir sinir a\u011f\u0131m\u0131z bulunmaktayd\u0131. \u0130simleri zaman i\u00e7inde de\u011fi\u015fti: Adaline, Madaline gibi. \u015eirin perceptron a\u015fa\u011f\u0131daki gibidir. \u00c7oklu giri\u015fi bulunmakta, n\u00f6rona ba\u011flayan kollardaki w a\u011f\u0131rl\u0131klar\u0131 ile \u00e7arp\u0131lmakta ve toplama (sum) fonksiyonuna girmektedir. Sonras\u0131nda do\u011frusal olmayan aktivizasyon fonksiyonu (non-linear activation function) ile \u00e7\u0131k\u0131\u015f katman\u0131na ba\u011flanmaktad\u0131r. Burada do\u011frusal olmayan aktivizasyon fonksiyonu se\u00e7ilmesinin ana nedeni, geri yay\u0131l\u0131m algoritmas\u0131nda a\u011f\u0131rl\u0131klar\u0131m\u0131z\u0131 loss fonksiyonumuzun sonucuna ba\u011fl\u0131 olarak g\u00fcncelleyebilmek i\u00e7indir. Gayet tabi do\u011frusal bir aktivizasyon fonksiyonu da kullan\u0131labilir ( Ne zamaan? Mesela ba\u011flan\u0131m-regression problemlerinde.).\n\n![perceptron](https:\/\/www.cc.gatech.edu\/~san37\/img\/dl\/perceptron.jpg)\n\nGel zaman git zaman, basit perceptron yap\u0131s\u0131na ilave n\u00f6ronlar eklenerek ileri beslemeli sinir a\u011flar\u0131 \"multilayer perceptron (MLP)\" olarak kar\u015f\u0131m\u0131za \u00e7\u0131k\u0131yor. Bu yap\u0131larda giri\u015f ve \u00e7\u0131k\u0131\u015f katmanlar\u0131 d\u0131\u015f\u0131nda kalan katmanlara gizli katman (hidden layer) ad\u0131n\u0131 veriyoruz. Problemin b\u00fcy\u00fckl\u00fc\u011f\u00fc ve hesaplama maliyetine g\u00f6re gizli katman say\u0131s\u0131 ve her bir gizli katmanda bulunan noron say\u0131s\u0131 art\u0131\u015f g\u00f6sterebilmektedir. \u00c7al\u0131\u015fmalar g\u00f6stermektedir ki probleme \u00f6zg\u00fc olarak az say\u0131da noron ve gizli katman kullanmak ezberleme(over fit - high variance) problemine yol a\u00e7maktad\u0131r, noron say\u0131s\u0131 ve gizli katman say\u0131s\u0131 artt\u0131k\u00e7a ba\u015far\u0131m\u0131n bir yere kadar artt\u0131\u011f\u0131 ve lokal minimum'lara tak\u0131lamdan \u00f6\u011frenme ger\u00e7ekle\u015ftirebildi\u011fi g\u00f6r\u00fcnmektedir. Bu \u00e7al\u0131\u015fmada da bunu bir miktar g\u00f6sterece\u011fiz. Alt yap\u0131s\u0131n\u0131 anlamak isteyen arkada\u015flar i\u00e7in \u00f6nerim matemati\u011fine inmek olacakt\u0131r, bunun i\u00e7in \u015fu kaynaklar\u0131 \u00f6neririm:\n\n1. Introduction to Machine Learning, Fourth Edition, Ethem Alpaydin\n2. Yapay Sinir A\u011flar\u0131 Kitap, Prof.Dr.Ercan \u00d6ztemel\n3. Derin \u00d6\u011frenme, Ian Goodfellow\n4. Python ile Derin \u00d6\u011frenme, Fran\u00e7ois Chollet\n\n\n![MLP](https:\/\/missinglink.ai\/wp-content\/uploads\/2018\/11\/multilayer-perceptron.png)\n\n\nMNIST data setleri temel yapay sinir a\u011flar\u0131 (ANN, CNN etc.) g\u00fczel bir ba\u015flang\u0131\u00e7t\u0131r. Hand written digits ( el yaz\u0131s\u0131 karakterleri) ve fashion olmak \u00fczere en temel 2 veri seti bulunmaktad\u0131r. \u0130lk \u00e7al\u0131\u015fmam\u0131zda MNIST Fashion'\u0131 inceleyece\u011fiz, 2. \u00e7al\u0131\u015fmam\u0131zda ise Convolutional Neural Networks (CNN) ile beraber MNIST El yaz\u0131s\u0131 karakterlerini inceleyece\u011fiz.\n\nPeki nedir MNSIT Fasion? 10 tane k\u0131yafet s\u0131n\u0131f\u0131 i\u00e7in toplamda 70000 28x28x1'lik foto\u011fraflar i\u00e7eren bir veri setidir. A\u015fa\u011f\u0131da ait olunan s\u0131n\u0131flar\u0131 g\u00f6rebilirsiniz. Amac\u0131m\u0131z 60000 e\u011fitim seti ile do\u011fru s\u0131n\u0131fland\u0131rma yapmay\u0131 \u00f6\u011frenecek bir yapay sinir a\u011f\u0131 geli\u015ftirmek ve m\u00fcmk\u00fcn oldu\u011funca y\u00fcksek bir ba\u015far\u0131m yakalayabilmek.Sonu\u00e7 olarak bu k\u0131lavuz, 10 kategoride 70.000 gri tonlamal\u0131 g\u00f6r\u00fcnt\u00fc i\u00e7eren Fashion MNIST veri k\u00fcmesini kullan\u0131r. G\u00f6r\u00fcnt\u00fcler, a\u015fa\u011f\u0131da g\u00f6r\u00fcld\u00fc\u011f\u00fc gibi d\u00fc\u015f\u00fck \u00e7\u00f6z\u00fcn\u00fcrl\u00fckte (28 x 28 piksel) ayr\u0131 giyim e\u015fyalar\u0131n\u0131 g\u00f6stermektedir. Data seti kaggle i\u00e7erisinde 60000 Training, 10000 Test olarak ayr\u0131lm\u0131\u015f bulunmaktad\u0131r.\n\n\n![nnsr](https:\/\/cdn-images-1.medium.com\/max\/888\/1*-kpgaee9X9Gm-SrQKdk_og.png)\n\n\n\n[1] https:\/\/en.wikipedia.org\/wiki\/Least_squares\n","62efe8fc":"* input --> 512 --> relu --> 1024 --> relu --> 1024 --> softmax, oprimizer= RMSprop\n\nBa\u015far\u0131m:  0.889 ( Val Acc.)","2872f2e5":"\u0130htiyac\u0131m\u0131z olan k\u00fct\u00fcphaneleri y\u00fckl\u00fcyoruz. Temel olarak Tensorflow ve Keras'tan yard\u0131m alaca\u011f\u0131z.","ab9f9b38":"ilk modelimiz olduk\u00e7a k\u00fc\u00e7\u00fck bir sinir a\u011f\u0131. 2 Gizli katman\u0131m\u0131z bulunuyor. \u0130lki 8 n\u00f6ronlu ve aktivizasyon olarak sigmoid fonksiyonu kulland\u0131k. Buradan sonra bir \u00e7ok model deneyerek, hiper parametrelerle oynayarak sonu\u00e7lar\u0131 g\u00f6zlemleyece\u011fiz.\n\n* input -> 8 -> sigmoid ->16 -> sigmoid -> softmax\n\nBa\u015far\u0131m:   0.849 ( Val Acc.) --> Y\u00fcksek g\u00f6r\u00fcnse de en y\u00fcksek skorlar\u0131n 0.99-1.00 aras\u0131nda de\u011fi\u015fti\u011fini d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcm\u00fczde b\u00fcy\u00fck fark oldu\u011fu g\u00f6r\u00fcnmektedir.","aa711e30":"Normalizasyon \u00f6zellikle farkl\u0131 boyutlardaki datalar\u0131 0 ile 1 aras\u0131nda da\u011f\u0131l\u0131m g\u00f6sterecek \u015fekilde yeniden d\u00fczenleme anlam\u0131na gelmektedir. Bir \u00e7ok farkl\u0131 y\u00f6ntemi oldu\u011fu gibi, biz en b\u00fcy\u00fck de\u011fere yani bir pikselin alabilece\u011fi en y\u00fcksek de\u011fer olan 255'e b\u00f6lerek devam edece\u011fiz. \n\nDaha sonras\u0131nda bir s\u0131ra halinde ( 784 ) olan de\u011ferleri yeniden \u015fekillendirerek (reshape) 28x28x1'lik foto\u011fraflar\u0131 tekrar olu\u015fturaca\u011f\u0131z. Bu ad\u0131m\u0131n amac\u0131 sadece foto\u011fraflar\u0131 g\u00f6rselle\u015ftirmektir. Yoksa bu \u015fekilde devam ederek sinir a\u011f\u0131 kurabiliriz. Burada reshape yapt\u0131\u011f\u0131m\u0131zdan dolay\u0131 g\u00f6receksiniz yapay sinir a\u011flar\u0131na \"flatten\" yani 28x28'lik datay\u0131 784'l\u00fck bir giri\u015f vekt\u00f6r\u00fcne d\u00f6n\u00fc\u015ft\u00fcrme katman\u0131 ekleyece\u011fiz.\n\nBir di\u011fer konu ise hedef de\u011ferin durumuna karar vermektir. Ne konu\u015fmu\u015ftuk, y de\u011ferleri 0'dan 9'a kadar de\u011fi\u015fiyor ve \u015fu anda y_train.shape[0]=60k, y_test.shape[0]=10k olmak \u00fczere birer vekt\u00f6r halinde. B\u00f6yle de devam edebiliriz ama o zaman sinir a\u011f\u0131 son katman\u0131m\u0131z\u0131n (\u00e7\u0131k\u0131\u015f katman\u0131) nas\u0131l bir yap\u0131da olaca\u011f\u0131n\u0131 iyi d\u00fc\u015f\u00fcnmemiz gerekir. Tek bir norondan olu\u015fup 0 ile 9 aras\u0131nda de\u011fer veren bir yap\u0131 da in\u015fa edebiliriz, ona g\u00f6re aktivasyon fonksiyonu ve loss fonksiyonu se\u00e7eriz. Ama bunu d\u00fc\u015f\u00fcnmeye gerek yok kategorik yap\u0131lar i\u00e7in \u00e7ok ama \u00e7ok iyi \u00e7al\u0131\u015fan softmax aktivasyonu ve categorical_crossentropy loss fonskiyonu bu tarz 2'den fazla s\u0131n\u0131f bulunan s\u0131n\u0131fland\u0131rma problemleri i\u00e7in \u00e7ok g\u00fczel \u00e7al\u0131\u015fmaktad\u0131r. Ama softmax'i kullanmak i\u00e7in vekt\u00f6r halinde olan \u00e7\u0131kt\u0131m\u0131z\u0131 bir array'e d\u00f6n\u00fc\u015ft\u00fcrmemiz gerekiyor. Bu d\u00f6n\u00fc\u015f\u00fcmlere encoding demekteyiz. Kullanaca\u011f\u0131m\u0131z yap\u0131 bir array oalca\u011f\u0131ndan one hot encoding yap\u0131s\u0131n\u0131 kullanaca\u011f\u0131z. Peki bu one hot encoding ne yap\u0131yor? A\u015fa\u011f\u0131daki resimde de g\u00f6r\u00fcnd\u00fc\u011f\u00fc \u00fczere kategorik s\u0131n\u0131fland\u0131rmay\u0131 (bu string de olabilir number da) bir vekt\u00f6rden matrixe d\u00f6n\u00fc\u015ft\u00fcr\u00fcyor. Bu sayede sonucu makineler daha rahat ifade edebiliyor. Yapay sinir a\u011flar\u0131 i\u00e7in de tek n\u00f6ron \u00fcst\u00fcnden tahminlemek yerine, s\u0131n\u0131f adeti kadar n\u00f6ron koyarak tahminlemek daha b\u00fcy\u00fck ba\u015far\u0131 getiriyor.\n\n![ohe](https:\/\/i.imgur.com\/mtimFxh.png)","5cad9567":"Dosyalar\u0131 okuyoruz, ben tercihen os k\u00fct\u00fcphanesini kullan\u0131yorum. Train 60000,785 ve Test 10000,785 boyutlar\u0131nda. Bu \u015fu anlama gelmektedir 60000 train datas\u0131 var ve bu data 785 boyutlu. 785 boyutun 1 tanenesi label yani do\u011fru etiket, 784 tanesi ise 28x28'lik foto\u011fraf\u0131n piksel de\u011ferleri. Gri bir imge oldu\u011fundan dolay\u0131 her bir pikselin de\u011feri de 0 ila 255 aras\u0131nda de\u011fi\u015fmektedir.","08727924":" Ba\u015far\u0131m: 0.893","f089da5a":"Hiper parametreler deneme yan\u0131lma ile probleme \u00f6zg\u00fc bulmam\u0131z gereken parametrelerdir. Bunlar i\u00e7in temel de\u011ferler tan\u0131mlad\u0131m. \u0130leride her birisini tek tek a\u00e7\u0131klar\u0131m belki :)"}}