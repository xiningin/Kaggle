{"cell_type":{"aecb8ca9":"code","0fbae4f6":"code","95f64f0d":"code","229e4438":"code","2281bdb4":"code","94329d8e":"code","fa8c8f2b":"code","3302d583":"code","a7396011":"code","19c4dd96":"code","1eba0ffe":"code","971f0d69":"code","ceaaf971":"code","cf566646":"code","2b8458ff":"code","23c37a1d":"code","37147176":"code","a7942e85":"code","bf42f6f1":"code","42453073":"markdown","1ee0aebc":"markdown","72ef197f":"markdown","dcd32c65":"markdown","b9773ed1":"markdown","b61acde3":"markdown","e7f1670c":"markdown","3662d182":"markdown","e560f12e":"markdown","36a48479":"markdown","b740e514":"markdown","2feaaa5f":"markdown","f04840e3":"markdown","295368e8":"markdown","17cddf78":"markdown","d769d07a":"markdown","3f7a1009":"markdown","deaa213a":"markdown","a57db272":"markdown","1472ac71":"markdown","ce4d7831":"markdown","e9053279":"markdown","fc7279fd":"markdown","60bec18c":"markdown","3ec0c6c2":"markdown","6d9cf4fa":"markdown","3f0ee6f4":"markdown","4bf7eb0c":"markdown","95160b53":"markdown","f6b63c49":"markdown"},"source":{"aecb8ca9":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport cv2\nimport random\nfrom random import randint\nimport time\n\n\nimport torch\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nfrom PIL import Image\nfrom scipy import ndimage\n\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import f1_score\n","0fbae4f6":"DATA_DIR = '..\/input\/dog-breed-identification'\n\n\nTRAIN_DIR = DATA_DIR + '\/train'                           \nTEST_DIR = DATA_DIR + '\/test'                             \n\nTRAIN_CSV = DATA_DIR + '\/labels.csv'                     \nTEST_CSV = DATA_DIR + '\/submission.csv' ","95f64f0d":"data_df = pd.read_csv(TRAIN_CSV)\ndata_df.head(10)","229e4438":"labels_names=data_df[\"breed\"].unique()\nlabels_sorted=labels_names.sort()\n\nlabels = dict(zip(range(len(labels_names)),labels_names))\nlabels ","2281bdb4":"\nlbl=[]\nfor i in range(len(data_df[\"breed\"])):\n    temp=list(labels.values()).index(data_df.breed[i])\n    lbl.append(temp)\n\n    \ndata_df['lbl'] = lbl\n#data_df['lbl'] = data_df['lbl'].astype(str)\ndata_df.head()","94329d8e":"path_img=[]\nfor i in range(len(data_df[\"id\"])):\n    temp=TRAIN_DIR + \"\/\" + str(data_df.id[i]) + \".jpg\"\n    path_img.append(temp)\n\ndata_df['path_img'] =path_img\ndata_df.head()","fa8c8f2b":"num_images = len(data_df[\"id\"])\nprint('Number of images in Training file:', num_images)\nno_labels=len(labels_names)\nprint('Number of dog breeds in Training file:', no_labels)","3302d583":"bar = data_df[\"breed\"].value_counts(ascending=True).plot.barh(figsize = (30,120))\nplt.title(\"Distribution of the Dog Breeds\", fontsize = 20)\nbar.tick_params(labelsize=16)\nplt.show()","a7396011":"data_df[\"breed\"].value_counts(ascending=False)","19c4dd96":"fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(data_df.path_img[i]))\n    ax.set_title(data_df.breed[i])\nplt.tight_layout()\nplt.show()","1eba0ffe":"random_img=randint(0,len(data_df.path_img))\nimg_path=data_df.path_img[random_img]\nimg= plt.imread(img_path)\n\nplt.imshow(img)\nplt.title(\"Original image\")\nplt.show()\n\nplt.imshow(cv2.resize(img, (150,150)))\nplt.title(\"After resizing\")\nplt.show()","971f0d69":"random_img=randint(0,len(data_df.path_img))\nimg_path=data_df.path_img[random_img]\nimg= plt.imread(img_path)\n\nplt.imshow(img)\nplt.title(\"Original image\")\nplt.show()\n\n\n#rotation angle in degree\n\nrotated1 = ndimage.rotate(img, 90)\nplt.imshow(rotated1)\nplt.title(\"Image rotated 90 degrees\")\nplt.show()","ceaaf971":"random_img=randint(0,len(data_df.path_img))\nimg_path=data_df.path_img[random_img]\nimg= plt.imread(img_path)\n\nplt.imshow(img)\nplt.title(\"Original image\")\nplt.show()\n\n\nimg=cv2.resize(img, (150,150))\nturn =90\n\nfig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 4),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(ndimage.rotate(img, i*90))\n    ax.set_title(\"After resizing rotated \"+ str(i*90) +\" degrees\")\nplt.tight_layout()\nplt.show()","cf566646":"#imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n#this will resize the image \n    T.Resize(256),   \n   \n#Randomly change the brightness, contrast and saturation of an image\n#    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),    \n\n#this will remove parts (crop) the Image at a random location.   \n#    T.RandomCrop(32, padding=4, padding_mode='reflect'),   \n\n#Horizontally flip (rotate by 180 degree) the given image randomly; default is 50% of images\n    T.RandomHorizontalFlip(), \n    \n#Rotate the image by angle -here by 10%\n    T.RandomRotation(10),\n    \n#convert it to a tensor   \n    T.ToTensor()\n\n#Normalize a tensor image with mean and standard deviation - here with the Imagenet stats\n#    T.Normalize(*imagenet_stats,inplace=True), \n    \n#Randomly selects a rectangle region in an image and erases its pixels.    \n#    T.RandomErasing(inplace=True)\n])\n","2b8458ff":"class DogDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['id'], row['lbl']\n        img_fname = self.root_dir + \"\/\" + str(img_id) + \".jpg\"\n        img = Image.open(img_fname)\n        if self.transform:\n            img = self.transform(img)\n        return img, img_label","23c37a1d":"data_ds = DogDataset(data_df, TRAIN_DIR, transform=train_tfms)","37147176":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', labels[target])","a7942e85":"show_sample(*data_ds[241])","bf42f6f1":"show_sample(*data_ds[149])","42453073":"Any other field you would like to add? Please make a note in comments. Thanks!","1ee0aebc":"# Beginner's Guide to Image Augmentation & Transforms\n","72ef197f":"I like to use numbers instead of names for labels. Lets add the numbers as labels to the dataframe","dcd32c65":"# Image Analysis","b9773ed1":"# Exlporatory Data Analysis (EDA)","b61acde3":"We observe that the distribution is not equal. Scottish deerhound has 126 images\nwhile eskimo dog and briard breeds have 66 images","e7f1670c":"# Image transforms using PyTorch","3662d182":"# Add more Data Fields","e560f12e":"Let us look at the data and make some initial conclusions","36a48479":"What are the benefits?\nDeep Learning and Neural Networks need a lot of images\nby rotating images we are adding multiple extra images from one image\n\nNote that I have rotated by 90 degrees  but one may rotate by any random degree that that wants to rotate the image\n\nSimilarly, by blocking parts of images, cropping (removing part of images) and adding jitters, we can both augument images (add to the number of images) and transform them to make it more helpful for the neural network to classify","b740e514":"Lets also add the path of each image to the file. ","2feaaa5f":"Here I focus only on the train transform. Please make sure you make the same transforms in the validation set as well\n\nNote some of the commands are not running as they are as coments due to the # symbol\nremove the # symbol and see how the images below change. \n\nThis will help you visualise the impact of each transform\n\n[Read more about transforms here (click here)](https:\/\/pytorch.org\/docs\/stable\/torchvision\/transforms.html)","f04840e3":"In the start always import the libraries that you feel you may use or need. Over time, build a list of libraries that you use and use it in all the notebooks you are working. You will naturally strat using some of the libraries that you are comfortable with and this will help.","295368e8":"I will not dwelve into modeling here and focus on image transfors\n\nAs a result I will look at only the train file\n\nI will read and add some data fields that I find useful","17cddf78":"Lets try to rotate the images...","d769d07a":"What do you observe?\n\nAll images are of differnt sizes\n\nThe backgrounsd vary- some have humans, and other items in the backgrounds\n\nAlso some images are not vertical - e.g., the lakeland terrier in the lower night","3f7a1009":"Do you notice that the transforms are most likely differnt for both images?\nThis is because the transforms are added randomly. In most liklihood each image will have some differnt rotation and.or flip and other transforms","deaa213a":"Hello! If you are a beginner and learning to handle image data, then Image Augmentation & Transforms is often confusing. Some may wonder why it is needed and what is the use.\n\nWhat are the changes that occur and why is it necessary. We discuss these in brief in the notebook\n\nI will be using the Dog Breed database, as we are intuitively more familiar with dogs than human protiens :)\n\nWe use both Python as well as PyTorch in this notebook!\n\nHope this helps...","a57db272":"# Import Libraries","1472ac71":"Let us work on some image transforms using Python\nand later we will use Pytorch to do the same\n\nLets start with resizing images","ce4d7831":"Ok! we have over 10,000 images for 120 dog breeds.\n\nAre images equally distributed between all dog breeds?\n\nLet's plot a graph and see!","e9053279":"# View Sample Images after Transform","fc7279fd":"What do you observe? a list of image names and breed. Lets add more details to the dataframe\n\nWe create a dictionary of all the breeds","60bec18c":"# Thank you! Hope you like it!","3ec0c6c2":"***Try this out!***\n\nand try with using differnt transforms from the link and by removing the # in the code\n\n**Please share your comments and feedback.**","6d9cf4fa":"# Read the data","3f0ee6f4":"Let us display 20 picture of the dataset with their labels","4bf7eb0c":"As you can observe the originalt height of the image is retained while the width changes\nthis creates an issue of differnt sizes and lenghts of images\n\nLet us do both resize and rotation\n","95160b53":"# Image Transforms using Python ","f6b63c49":"Now that we have a understanding of the transforms using Python, lets do the same using PyTorch"}}