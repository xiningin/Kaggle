{"cell_type":{"912aa63f":"code","593fc8e3":"code","05d05bf2":"code","87712e8a":"code","ec503125":"code","f3c14fc3":"code","03b48a72":"code","7ebe90df":"code","bb09c432":"code","79ad34dd":"code","a35b2852":"code","f390e6b0":"code","edc8e6dd":"code","f20fbb31":"code","34346696":"code","5fc8ddd5":"code","110616ac":"code","3e027919":"code","e046fc27":"code","c00a1822":"code","e1c9f94e":"code","c35f4f20":"code","8efcf9af":"code","b3db9392":"code","43fcdcde":"code","56319fcf":"code","7307b157":"code","6f47ebba":"code","a397cf56":"code","2c028b63":"code","56db7f21":"code","0dc5938b":"code","8efdd70c":"code","a82b9bd8":"code","4dbc72b0":"code","2920b98b":"code","3cdb5784":"code","15b32ff1":"code","4e7dc50a":"code","4d4040e6":"code","d6aa28ca":"code","06b503af":"code","e692bfd7":"code","4a13cd2e":"code","e13e21d2":"code","07fb665b":"code","c6baed0b":"code","9eeb5d4b":"code","dbc43e37":"code","2e47bf2b":"code","1ca1df02":"code","2d58e066":"code","8874c8c6":"code","4484050a":"code","94a1fc4d":"code","5fff9473":"code","6f408c48":"markdown","66efe450":"markdown","dadb272f":"markdown","24acc283":"markdown","6d5a18ed":"markdown","3f0a3834":"markdown","1ddec04b":"markdown","52340ed6":"markdown","bb839874":"markdown","409f7c36":"markdown","d3a21fa1":"markdown","7a8c50c7":"markdown","edf2d766":"markdown","ff29602d":"markdown","82e65552":"markdown","397a7f25":"markdown","9f08e408":"markdown","2aa89c0c":"markdown","292508e2":"markdown","decc9acf":"markdown","886e7f87":"markdown","ac9cd1b4":"markdown","0004cfc1":"markdown","96392789":"markdown","27cdfb30":"markdown","5e24ec5c":"markdown","a1f881a3":"markdown","c03b32e6":"markdown","bcf2a005":"markdown","4df613b9":"markdown","2a25a8f9":"markdown","bef22a19":"markdown","487642c0":"markdown","67b81245":"markdown","25105b66":"markdown","fffbab77":"markdown","04182c48":"markdown","5cb14419":"markdown","21136039":"markdown","469ec6df":"markdown","9fec2d13":"markdown","90778db6":"markdown","952cf85e":"markdown","5d104b4b":"markdown","7b0c72ea":"markdown","da3a9a9a":"markdown","55817dfe":"markdown","f5c39dff":"markdown","e7b59f40":"markdown","8ebacf98":"markdown","3d86d95e":"markdown","4c079f52":"markdown","c96c8642":"markdown","241aae6a":"markdown","704000b6":"markdown","b630c328":"markdown","885a1753":"markdown","ddd8e33a":"markdown","e064d894":"markdown","a37d03dc":"markdown","742e88d0":"markdown","f297ff53":"markdown","7ca42984":"markdown","136676e8":"markdown","c584c064":"markdown","34fbb68a":"markdown","c1a0c0cc":"markdown","291565f7":"markdown","38d86445":"markdown","58de7819":"markdown","f417aa16":"markdown","8749aba3":"markdown","e5cb1019":"markdown"},"source":{"912aa63f":"#Load the Librarys\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nimport plotly.tools as tls\nimport plotly\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\nimport warnings\nfrom collections import Counter","593fc8e3":"#loading the data with encode \ndf_kick = pd.read_csv(\"..\/input\/ks-projects-201801.csv\")\ndf_kick = df_kick.sample(10000, random_state=42).reset_index().drop('index', axis=1)","05d05bf2":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary\n\ndef chi2_test(col, prob=.95):\n    stat, p, dof, expected = stats.chi2_contingency((pd.crosstab(df_kick[col[0]], \n                                                                 df_kick[col[1]]\n                                                                )))\n    print(\"CHI-SQUARED TEST: \")\n    # calculating the value to compare with chi2 statistic\n    critical = stats.chi2.ppf(prob, dof)\n    print(f'dof={dof}, probability={round(prob,3)}, critical={round(critical,5)}, stat={round(stat,5)}')\n    print(\"Accept or Reject H0: \")\n    # interpret test statistic\n    if abs(stat) >= critical:\n        print('Dependent (reject H0)')\n    else:\n        print('Independent (fail to reject H0)')\n\ndef ttest_onesided(cols, alpha = 0.05):\n    \"\"\"\n    \n    cols: list with the , we will test the mean of the population and the sample mean\n    \n    H0:\n    The null Hypothesis is that the both distributions are the same\n    H1:\n    The alternative hypothesis is that the distributions are different\n    \n    \"\"\"\n    pop_mean = cols[0].mean()\n    sample = cols[1]\n    \n    print(f\"Mean of Population: {pop_mean} \\nMean of Sample: {sample.mean()}\")\n    ttest_val, pval = stats.ttest_1samp(sample, pop_mean)\n\n    print(f\"t-test value: {ttest_val}\")\n    print(\"Comparing p_value by...\\n\")\n    print(f'p-value result: {pval}')\n    if pval < alpha:    # alpha value is 0.05 or 5%\n       print(\" we are rejecting null hypothesis\")\n    else:\n      print(\"we are accepting null hypothesis\")\n\ndef ttest_twosided(cols, alpha = 0.05):\n    sample1 = cols[0]\n    sample2 = cols[1]\n    print(f\"Mean of Sample 1: {sample1.mean()} \\nMean of Sample 2: {sample2.mean()}\")    \n    ttest_val, pval = stats.ttest_ind(sample1, sample2)\n\n    print(f\"t-test value: {ttest_val}\")\n    # print(\"Comparing p_value by...\\n\")\n    print(f'p-value result: {pval}')\n    if pval < alpha:    # alpha value is 0.05 or 5%\n       print(\" we are rejecting null hypothesis\")\n    else:\n      print(\"we are accepting null hypothesis\")","87712e8a":"#knowning the main informations of our data\nresumetable(df_kick)","ec503125":"#Looking the data\ndf_kick.head()","f3c14fc3":"state = round(df_kick[\"state\"].value_counts() \/ len(df_kick[\"state\"]) * 100,2)\n\nlabels = list(state.index)\nvalues = list(state.values)\n\ntrace1 = go.Pie(labels=labels, values=values, marker=dict(colors=['red']))\n\nlayout = go.Layout(title='Distribuition of States', legend=dict(orientation=\"h\"));\n\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","03b48a72":"df_kick.head()","7ebe90df":"# df_kick.loc[df_kick.state.isin(['suspended', 'canceled']), 'state'] = 'failed'\ndf_kick = df_kick.loc[df_kick['state'].isin(['failed','successful'])]","bb09c432":"df_failed = df_kick[df_kick[\"state\"] == \"failed\"].sample(10000, replace=True)\ndf_sucess = df_kick[df_kick[\"state\"] == \"successful\"].sample(10000, replace=True)\n\n#First plot\ntrace0 = go.Histogram(\n    x= np.log(df_kick.usd_goal_real + 1),\n    histnorm='probability', showlegend=False,\n    xbins=dict(\n        start=-5.0,\n        end=19.0,\n        size=1),\n    autobiny=True)\n\n#Second plot\ntrace1 = go.Histogram(\n    x = np.log(df_kick.usd_pledged_real + 1),\n    histnorm='probability', showlegend=False,\n    xbins=dict(\n        start=-1.0,\n        end=17.0,\n        size=1))\n\n# Add histogram data\nfailed = np.log(df_failed['usd_goal_real']+1)\nsuccess = np.log(df_sucess[\"usd_goal_real\"]+1)\n\ntrace3 = go.Histogram(\n    x=failed,\n    opacity=0.60, nbinsx=30, name='Goals Failed', histnorm='probability'\n)\ntrace4 = go.Histogram(\n    x=success,\n    opacity=0.60, nbinsx=30, name='Goals Sucessful', histnorm='probability'\n)\n\n\ndata = [trace0, trace1, trace3, trace4]\nlayout = go.Layout(barmode='overlay')\n\n#Creating the grid\nfig = plotly.tools.make_subplots(rows=2, cols=2, specs=[ [{'colspan': 2}, None], [{}, {}]],\n                          subplot_titles=('Failed and Sucessful Projects',\n                                          'Goal','Pledged'))\n\n#setting the figs\nfig.append_trace(trace0, 2, 1)\nfig.append_trace(trace1, 2, 2)\nfig.append_trace(trace3, 1, 1)\nfig.append_trace(trace4, 1, 1)\n\nfig['layout'].update(title=\"Distribuitions\",\n                     height=500, width=900, barmode='overlay')\niplot(fig)","79ad34dd":"# Import shapiro from scipy.stats\nstat, p = stats.shapiro(np.log(df_kick['usd_goal_real']+1).sample(500, random_state=42))\n\nprint(\"Shapiro stat:\", stat)\nprint(\"P-value: \", p)\nif p >= .01:\n    print('Normal Distribution')\nelse:\n    print(\"Non-Normal Distribution\")","a35b2852":"ttest_onesided([np.log(df_kick['usd_goal_real']+1), success])","f390e6b0":"ttest_twosided([failed, success], alpha=.01)","edc8e6dd":"df_kick['pledged_log'] = np.log(df_kick['usd_pledged_real'] + 1)\ndf_kick['goal_log'] = np.log(df_kick['usd_goal_real'] + 1)\n\ndf_kick['diff_pledged_goal'] = round((df_kick['usd_pledged_real'] \/df_kick['usd_goal_real']) * 100, 2)\ndf_kick['diff_pledged_goal'] = df_kick['diff_pledged_goal'].astype(float)","f20fbb31":"print(\"Min Goal and Pledged values\")\nprint(df_kick[[\"goal\", \"pledged\"]].min())\nprint(\"\")\nprint(\"Mean Goal and Pledged values\")\nprint(round(df_kick[[\"goal\", \"pledged\"]].mean(),2))\nprint(\"\")\nprint(\"Median Goal and Pledged values\")\nprint(df_kick[[\"goal\", \"pledged\"]].median())\nprint(\"\")\nprint(\"Max Goal and Pledged values\")\nprint(\"goal       100000000.0\") #If i put the both together give me back log values, \nprint(\"pledged     20338986.27\") # so i decide to just show this values\nprint(\"dtype: float64\")\nprint(\"\")\nprint(\"Std Goal and Pledged values\")\nprint(round(df_kick[[\"goal\", \"pledged\"]].std(),2))","34346696":"#First plot\ntrace0 = go.Box(\n    x=df_kick['state'],\n    y=df_kick['goal_log'],\n    name=\"Goal Log\", showlegend=False\n)\n#Second plot\ntrace1 = go.Box(\n    x=df_kick['state'],\n    y=df_kick['pledged_log'],\n    name=\"Pledged Log\", showlegend=False\n)\n#Third plot\ntrace2 = go.Scatter(\n    x=df_kick['goal_log'], y=df_kick['pledged_log'],\n    name=\"Goal x Pledged Distribuition\", \n    showlegend=False,\n    mode = 'markers'\n)\n\n#Creating the grid\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Goal','Pledged',\n                                          \"Goal x Pledged (Both Log)\"))\n\n#setting the figs\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\n\nfig['layout'].update(showlegend=True, \n                     title=\"Goal Log and Pledged Log by State of Projects\",\n                     xaxis=dict(\n                         title='State', ticklen=5, zeroline=False, gridwidth=2\n                     ),\n                     yaxis=dict(\n                         title='Goal(Log)', ticklen=5, gridwidth=2\n                     ),\n                     xaxis1=dict(title='State', ticklen=5, zeroline=False, gridwidth=2),\n                     yaxis1=dict(title='Goal(Log)', ticklen=5, gridwidth=2),\n                     xaxis2=dict(title='State', ticklen=5, zeroline=False, gridwidth=2),\n                     yaxis2=dict(title='Pledged(Log)', ticklen=5, gridwidth=2))\niplot(fig)","5fc8ddd5":"main_cats = df_kick[\"main_category\"].value_counts()\nmain_cats_failed = df_kick[df_kick[\"state\"] == \"failed\"][\"main_category\"].value_counts()\nmain_cats_sucess = df_kick[df_kick[\"state\"] == \"successful\"][\"main_category\"].value_counts()","110616ac":"#First plot\ntrace0 = go.Bar(\n    x=main_cats_failed.index,\n    y=main_cats_failed.values,\n    name=\"Failed Categories\"\n)\n#Second plot\ntrace1 = go.Bar(\n    x=main_cats_sucess.index,\n    y=main_cats_sucess.values,\n    name=\"Success Categories\"\n)\n#Third plot\ntrace2 = go.Bar(\n    x=main_cats.index,\n    y=main_cats.values,\n    name=\"Categories Distribuition\"\n)\n\n#Creating the grid\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Failed','Sucessful', \"General Category's\"))\n\n#setting the figs\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\n\nfig['layout'].update(showlegend=True,\n                     title=\"Main Category's Distribuition\",\n                     bargap=0.05)\niplot(fig)","3e027919":"       \nchi2_test(['state','main_category'])","e046fc27":"print(\"Looking Goal and Pledged Mean by state \")\nprint(round(df_kick.groupby([\"state\"])[\"goal\", \"usd_pledged_real\"].mean(),2))","c00a1822":"categorys_failed = df_kick[df_kick[\"state\"] == \"failed\"][\"category\"].value_counts()[:25]\ncategorys_sucessful = df_kick[df_kick[\"state\"] == \"successful\"][\"category\"].value_counts()[:25]\ncategorys_general = df_kick[\"category\"].value_counts()[:25]\n\n#First plot\ntrace0 = go.Histogram(\n    x=df_kick[(df_kick.category.isin(categorys_failed.index.values)) & \n              (df_kick[\"state\"] == \"failed\")]['category'].head(100000),\n    histnorm='percent', name=\"Top 15 Failed\", showlegend=False\n)\n#Second plot\ntrace1 = go.Histogram(\n    x=df_kick[(df_kick.category.isin(categorys_sucessful.index.values)) & \n              (df_kick[\"state\"] == \"successful\")]['category'].head(100000),\n    histnorm='percent', name=\"Top 15 Sucessful\", showlegend=False\n)\n\n#Third plot\ntrace2 = go.Histogram(\n    x=df_kick[(df_kick.category.isin(categorys_general.index.values))]['category'].head(100000),\n    histnorm='percent', name=\"Top 25 All Category's\", showlegend=False\n)\n\n#Creating the grid\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Top 15 Failed','Top 15 Sucessful', \"Top 25 All Category's\"))\n\n#setting the figs\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\n\nfig['layout'].update(showlegend=True, title=\"Top Frequency Category's\")\niplot(fig)","e1c9f94e":"#First plot\ntrace0 = go.Box(\n    x=df_kick[(df_kick.category.isin(categorys_failed.index.values)) & \n              (df_kick[\"state\"] == \"failed\")]['category'],\n    y=df_kick[(df_kick.category.isin(categorys_failed.index.values)) & \n              (df_kick[\"state\"] == \"failed\")]['pledged_log'].head(100000),\n    name=\"Failed Category's\", showlegend=False\n)\n\n#Second plot\ntrace1 = go.Box(\n    x=df_kick[(df_kick.category.isin(categorys_sucessful.index.values)) & \n              (df_kick[\"state\"] == \"successful\")]['category'],\n    y=df_kick[(df_kick.category.isin(categorys_sucessful.index.values)) & \n              (df_kick[\"state\"] == \"successful\")]['pledged_log'].head(100000),\n    name=\"Sucessful Category's\", showlegend=False\n)\n\n#Third plot\ntrace2 = go.Box(\n    x=df_kick[(df_kick.category.isin(categorys_general.index.values))]['category'],\n    y=df_kick[(df_kick.category.isin(categorys_general.index.values))]['pledged_log'].head(100000),\n    name=\"All Category's Distribuition\", showlegend=False\n)\n\n#Creating the grid\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Failed','Sucessful', \"General Category's\", ))\n\n#setting the figs\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\n\nfig['layout'].update(showlegend=True, title=\"Main Category's Distribuition\")\niplot(fig)","c35f4f20":"cat_fill = df_kick[df_kick.category.isin(categorys_failed[:10].index.values)]\n\n#First plot\ntrace0 = go.Box(\n    x=cat_fill['category'],\n    y=cat_fill['goal_log'].head(100000),\n    name=\"Failed Category's\", showlegend=False\n)\n\n#Second plot\ntrace1 = go.Box(\n    x=cat_fill['category'],\n    y=cat_fill['pledged_log'].head(100000),\n    name=\"Sucessful Category's\", showlegend=False\n)\n\n#Third plot\ntrace2 = go.Box(\n    x=cat_fill['category'],\n    y=np.log(cat_fill['diff_pledged_goal'] + 1).head(100000),\n    name=\"Pledged\", showlegend=False\n)\n\n#Creating the grid\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Goal Log','Pledged Log', \"Diff of Pledged and Goal\", ))\n\n#setting the figs\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\n\nfig['layout'].update(showlegend=True, \n                     title=\"Distribuition of Values by Top 10 Categorys\")\niplot(fig)\n\n","8efcf9af":"sucess_music = df_kick[(df_kick['main_category'] == 'Music') & \n                      (df_kick['state'] == 'successful')]\nsucess_filme_video = df_kick[(df_kick['main_category'] == 'Film & Video') & \n                      (df_kick['state'] == 'successful')]\nsucess_games = df_kick[(df_kick['main_category'] == 'Games') & \n                      (df_kick['state'] == 'successful')]\n\nplt.figure(figsize=(14,16))\ntotal = len(df_kick)\nplt.subplot(311)\nax0 = sns.countplot(x='category', data=sucess_music,\n                    color='coral')\nax0.set_xticklabels(ax0.get_xticklabels(),rotation=45)\nax0.set_title(\"Categorys of Music with Sucess\", fontsize=22)\nax0.set_xlabel(\"Music categories\", fontsize=15)\nax0.set_ylabel(\"Counts\", fontsize=15)\nsizes=[]\nfor p in ax0.patches:\n    height = p.get_height()\n    sizes.append(height)\n    ax0.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/len(sucess_music)*100),\n            ha=\"center\", fontsize=12) \nax0.set_ylim(0, max(sizes) * 1.15)\n\n\nplt.subplot(312)\nax1 = sns.countplot(x='category', data=sucess_filme_video,\n                    color='coral')\nax1.set_xticklabels(ax1.get_xticklabels(),rotation=45)\nax1.set_title(\"Categorys of Film & Video with Sucess\", fontsize=22)\nax1.set_xlabel(\"Film and Video Categorys\", fontsize=15)\nax1.set_ylabel(\"Counts\", fontsize=15)\nsizes=[]\nfor p in ax1.patches:\n    height = p.get_height()\n    sizes.append(height)\n    ax1.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/len(sucess_filme_video)*100),\n            ha=\"center\", fontsize=12) \nax1.set_ylim(0, max(sizes) * 1.15)\n\nplt.subplot(313)\nax2 = sns.countplot(x='category', data=sucess_games,\n                    color='coral')\nax2.set_xticklabels(ax2.get_xticklabels(),rotation=45)\nax2.set_title(\"Category Games with Sucess\", fontsize=22)\nax2.set_xlabel(\"Categorys of Games with Sucess\", fontsize=15)\nax2.set_ylabel(\"Counts\", fontsize=15)\nsizes=[]\nfor p in ax2.patches:\n    height = p.get_height()\n    sizes.append(height)\n    ax2.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/len(sucess_games)*100),\n            ha=\"center\", fontsize=12) \nax2.set_ylim(0, max(sizes) * 1.15)\n\nplt.subplots_adjust(wspace = 0.3, hspace = 0.6,top = 0.9)\n\nplt.show()","b3db9392":"failed_film = df_kick[(df_kick['main_category'] == 'Film & Video') & \n                      (df_kick['state'] == 'failed')]\nfailed_publishing = df_kick[(df_kick['main_category'] == 'Publishing') & \n                      (df_kick['state'] == 'failed')]\nfailed_music = df_kick[(df_kick['main_category'] == 'Music') & \n                      (df_kick['state'] == 'failed')]\n\nplt.figure(figsize=(14,16))\n\nplt.subplot(3,1,1)\nax0 = sns.countplot(x='category', data=failed_film, color='coral')\nax0.set_xticklabels(ax0.get_xticklabels(),rotation=90)\nax0.set_title(\"Film & Video Most Fail Category's \", fontsize=22)\nax0.set_xlabel(\"\", fontsize=15)\nax0.set_ylabel(\"Counts\", fontsize=15)\nsizes=[]\nfor p in ax0.patches:\n    height = p.get_height()\n    sizes.append(height)\n    ax0.text(p.get_x()+p.get_width()\/2.,\n            height + 2,\n            '{:1.2f}%'.format(height\/len(failed_film)*100),\n            ha=\"center\", fontsize=10) \nax0.set_ylim(0, max(sizes) * 1.15)\n\nplt.subplot(3,1,2)\nax1 = sns.countplot(x='category', data=failed_publishing, color='coral')\nax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\nax1.set_title(\"Publishing Most Fail Category's\", fontsize=22)\nax1.set_xlabel(\"\", fontsize=17)\nax1.set_ylabel(\"Counts\", fontsize=17)\nsizes=[]\nfor p in ax1.patches:\n    height = p.get_height()\n    sizes.append(height)\n    ax1.text(p.get_x()+p.get_width()\/2.,\n            height + 2,\n            '{:1.2f}%'.format(height\/len(failed_publishing)*100),\n            ha=\"center\", fontsize=10) \nax1.set_ylim(0, max(sizes) * 1.15)\n\nplt.subplot(3,1,3)\nax2 = sns.countplot(x='category', data=failed_music, \n                    color='coral')\nax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\nax2.set_title(\"Music Most Fail Category's\", fontsize=22)\nax2.set_xlabel(\"Category Names\", fontsize=17)\nax2.set_ylabel(\"Counts\", fontsize=17)\nsizes=[]\nfor p in ax2.patches:\n    height = p.get_height()\n    sizes.append(height)\n    ax2.text(p.get_x()+p.get_width()\/2.,\n            height + 2,\n            '{:1.2f}%'.format(height\/len(failed_music)*100),\n            ha=\"center\", fontsize=10) \nax2.set_ylim(0, max(sizes) * 1.15)\n\nplt.subplots_adjust(wspace = 0.5, hspace = 0.6,top = 0.9)\n\nplt.show()","43fcdcde":"df_kick['launched'] = pd.to_datetime(df_kick['launched'])\ndf_kick['launched_date'] = df_kick['launched'].dt.date\n\ndf_kick['deadline'] = pd.to_datetime(df_kick['deadline'])\ndf_kick['deadline_date'] = df_kick['deadline'].dt.date\n","56319fcf":"#Creating a new columns with Campaign total months\ndf_kick['time_campaign_d'] = (df_kick['deadline_date'] - df_kick['launched_date']).dt.days\ndf_kick['time_campaign_d'] = df_kick['time_campaign_d'].astype(int)\n\n#removing outlier value\ndf_kick = df_kick[df_kick['time_campaign_d'] != 14867]\n\ndf_kick['time_campaign'] = round(df_kick['time_campaign_d'] \/ 30 )","7307b157":"plt.figure(figsize = (14,6))\n\nax = sns.countplot(x='time_campaign', hue='state', \n                   data=df_kick[(df_kick['time_campaign'] > .7) & \n                                (df_kick['time_campaign'] < 2.1)])\nax.set_title(\"Distribuition of Campaign Time by State\", fontsize=30)\nax.set_xlabel(\"Campaign Total Months\", fontsize=20)\nax.set_ylabel(\"Count\", fontsize=20)\nplt.show()","6f47ebba":"df_kick['laun_month_year'] = df_kick.launched.dt.month\ndf_kick['laun_year'] = df_kick.launched.dt.year\n","a397cf56":"year = df_kick.laun_year.value_counts()\nmonth = df_kick.laun_month_year.value_counts()\n\nfig, ax = plt.subplots(2,1, figsize=(12,10))\n\nplt.subplot(211)\nax1 = sns.boxplot(x=\"laun_year\", y='pledged_log', \n                  data=df_kick, color='coral')\nax1.set_title(\"Project Pledged by Year\", fontsize=22)\nax1.set_xlabel(\"Years\", fontsize=17)\nax1.set_ylabel(\"Pledged(log)\", fontsize=17)\n\nplt.subplot(212)\nax2 = sns.countplot(x=\"laun_year\", hue='state', \n                    data=df_kick )\nax2.set_title(\"Projects count by Year\", fontsize=22)\nax2.set_xlabel(\"State columns by Year\", fontsize=17)\nax2.set_ylabel(\"Count\", fontsize=17)\nax2.legend(loc='upper left')\n\nplt.subplots_adjust(hspace = 0.6)\n\nplt.show()\n","2c028b63":"fig, ax = plt.subplots(2,1, figsize=(12,10))\n\nplt.subplot(211)\nax1 = sns.boxplot(x=\"laun_month_year\", y='pledged_log', \n                  data=df_kick, color='coral')\nax1.set_title(\"Project Pledged by Month\", fontsize=22)\nax1.set_xlabel(\"Months of Year\", fontsize=17)\nax1.set_ylabel(\"Pledged(log)\", fontsize=17)\n\nplt.subplot(212)\nax2 = sns.countplot(x=\"laun_month_year\", hue='state', \n                    data=df_kick )\nax2.set_title(\"Projects count by Month\", fontsize=22)\nax2.set_xlabel(\"Months of Year\", fontsize=17)\nax2.set_ylabel(\"Count\", fontsize=17)\nax2.legend(loc='upper right')\n\nplt.subplots_adjust(hspace = 0.4)\n\nplt.show()\n","56db7f21":"plt.figure(figsize = (12,6))\nsns.distplot(df_kick[(df_kick['diff_pledged_goal'] < 200) & \n                     (df_kick['state'] == 'failed')]['diff_pledged_goal'], color='r')\nsns.distplot(df_kick[(df_kick['diff_pledged_goal'] < 200) & \n                     (df_kick['state'] == 'successful')]['diff_pledged_goal'],color='g')\nplt.show()","0dc5938b":"df_kick['laun_month_year'] = df_kick['launched'].dt.to_period('M').astype(str)","8efdd70c":"plt.figure(figsize = (18,15))\n\nplt.subplots_adjust(hspace = 0.35, top = 0.8)\n\ng1 = plt.subplot(211)\ng1 = sns.countplot(x=\"laun_month_year\", data=df_kick, color='coral',\n                   order=df_kick['laun_month_year'].value_counts().index.sort_values()[19:] )\ng1.set_xticklabels(g1.get_xticklabels(),rotation=90)\ng1.set_title(\"Value Distribuition by Date Distribuition\", fontsize=30)\ng1.set_xlabel(\"Date Distribuition\", fontsize=20)\ng1.set_ylabel(\"Count\", fontsize=20)\n\ng2 = plt.subplot(212)\ng2 = sns.boxplot(x=\"laun_year\", y=\"diff_pledged_goal\",\n                 data=df_kick[df_kick['diff_pledged_goal'] < 200], \n                 hue=\"state\")\ng2.set_xticklabels(g2.get_xticklabels(),rotation=90)\ng2.set_title(\"Value Distribuition by Date Distribuition\", fontsize=22)\ng2.set_xlabel(\"Date Distribuition\", fontsize=17)\ng2.set_ylabel(\"Goal x Pledged (%)\", fontsize=17)\n\nplt.show()","a82b9bd8":"plt.figure(figsize = (14,17))\n\nplt.subplots_adjust(hspace = 0.50, top = 0.8)\n\nplt.subplot(311)\ng =sns.boxplot(x='state', y='goal_log', \n            data=df_kick, \n            hue='time_campaign')\ng.set_title(\"State Goal's by Campaign Time\", fontsize=22)\ng.set_xlabel(\"\", fontsize=17)\ng.set_ylabel(\"Goal(log)\", fontsize=17)\ng.legend(loc='upper right')\n\nplt.subplot(312, sharex=g)\ng1 = sns.boxplot(x='state', y='pledged_log', \n            data=df_kick[df_kick['time_campaign'] < 10], \n            hue='time_campaign')\ng1.set_title(\"State Pledged's by Campaign Time\", fontsize=22)\ng1.set_xlabel(\"\", fontsize=17)\ng1.set_ylabel(\"Pledged(log)\", fontsize=17)\n\nplt.subplot(313)\ng2 = sns.boxplot(x='state', y='diff_pledged_goal', color='coral',\n                 data=df_kick[df_kick['diff_pledged_goal'] < 300])\ng2.set_title(\"State % of Goal reached by Campaign Time\", fontsize=22)\ng2.set_xlabel(\"State\", fontsize=17)\ng2.set_ylabel(\"Percentual Goal\", fontsize=17)\n\n\nplt.show()","4dbc72b0":"df_kick.groupby(['state'])['diff_pledged_goal'].median()","2920b98b":"df_kick['backers_log'] = np.log(df_kick['backers'] + 1 ) \n#The + 1 is to normalize the zero or negative values\n\nplt.figure(figsize = (12,6))\ng = sns.distplot(df_kick['backers_log'])\ng.set_xlabel(\"Distribution\", fontsize=17)\ng.set_ylabel(\"Frequency\", fontsize=17)\ng.set_title(\"Backers Log Distribution\", fontsize=22)\n\nplt.show()","3cdb5784":"plt.figure(figsize = (14,12))\n\nplt.subplots_adjust(hspace = 0.50, top = 0.8)\n\nplt.subplot(211)\ng = sns.violinplot(x='state',y='backers_log',\n                   color='coral', data=df_kick)\ng.set_title(\"Backers Log by STATE\", fontsize=22)\ng.set_xlabel(\"State\", fontsize=17)\ng.set_ylabel(\"Backers Log\", fontsize=17)\n\nplt.subplot(212)\ng1 = sns.violinplot(x='main_category',y='backers_log', \n                   color='coral', data=df_kick)\ng1.set_xticklabels(g1.get_xticklabels(),rotation=45)\ng1.set_title(\"Backers Log by Main Categories \", fontsize=22)\ng1.set_xlabel(\"Main Categories\", fontsize=17)\ng1.set_ylabel(\"Backers Log\", fontsize=17)\n\nplt.show()","15b32ff1":"plt.figure(figsize = (12,8))\n\nplt.subplot(211)\ng = sns.boxplot(x='laun_year',y='backers_log', \n                color='coral',\n               data=df_kick, \n                order=df_kick['laun_year'].value_counts().index.sort_values().values)\ng.set_title(\"Backers by YEAR\", fontsize=18)\n\nplt.show()","4e7dc50a":"from wordcloud import WordCloud, STOPWORDS\nimport nltk.tokenize as word_tokenize\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nimport re\nfrom nltk.stem.porter import *\nfrom nltk.tokenize import sent_tokenize\nfrom sklearn.feature_extraction import stop_words\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n    background_color='white',\n    stopwords=stopwords,\n    max_words=500,\n    max_font_size=200, \n    width=1000, height=800,\n    random_state=42,\n).generate(\" \".join(df_kick['name'].dropna().astype(str)))\n\nprint(wordcloud)\nfig = plt.figure(figsize = (12,14))\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - REGION DESCRIPTION\",fontsize=25)\nplt.axis('off')\n\nplt.show()","4d4040e6":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import minmax_scale\n\n#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding","d6aa28ca":"df_kick = pd.read_csv(\"..\/input\/ks-projects-201801.csv\")","06b503af":"df_kick = df_kick.loc[df_kick['state'].isin(['failed','successful'])]","e692bfd7":"targ_dict = {'failed': 0,\n             'successful': 1 \n            }\n\ndf_kick['state'] = df_kick['state'].map(targ_dict)","4a13cd2e":"df_kick['launched'] = pd.to_datetime(df_kick['launched'])\ndf_kick['launched_date'] = df_kick['launched'].dt.date\n\ndf_kick['deadline'] = pd.to_datetime(df_kick['deadline'])\ndf_kick['deadline_date'] = df_kick['deadline'].dt.date\n\n#Creating a new columns with Campaign total months\ndf_kick['time_campaign_d'] = (df_kick['deadline_date'] - df_kick['launched_date']).dt.days\ndf_kick['time_campaign_d'] = df_kick['time_campaign_d'].astype(int)\n\n#removing outlier value\ndf_kick = df_kick[df_kick['time_campaign_d'] != 14867]","e13e21d2":"to_drop = ['ID', 'name', 'deadline', 'pledged', 'backers', 'goal',\n            'usd pledged', 'usd_pledged_real','launched_date', 'deadline_date']","07fb665b":"df_kick.drop(to_drop, axis=1, inplace=True)","c6baed0b":"df_kick.head()","9eeb5d4b":"df_kick = df_kick.assign(hour=df_kick.launched.dt.hour,\n                         day=df_kick.launched.dt.day,          \n                         month=df_kick.launched.dt.month,\n                         year=df_kick.launched.dt.year).drop('launched', axis=1)","dbc43e37":"print(f'Shape before dummy transformation: {df_kick.shape}')\ndf_kick = pd.get_dummies(df_kick, columns=['category', 'main_category', 'currency', 'country'],\\\n                          prefix=['cat', 'main_cat', 'currency', 'country'], drop_first=True)\n\nprint(f'Shape after dummy transformation: {df_kick.shape}')","2e47bf2b":"num_cols = ['usd_goal_real', 'time_campaign_d']\n\nfor col in num_cols:\n    df_kick[col] = (minmax_scale(df_kick[col], feature_range=(0,1)))","1ca1df02":"X_train, X_test, y_train, y_test = train_test_split(df_kick.drop('state', axis=1), df_kick['state'], \n                                                    test_size=.20, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.15, random_state=42)","2d58e066":"print(f'Shape train: {X_train.shape}')\nprint(f'Shape valid: {X_val.shape}')\nprint(f'Shape test: {X_test.shape}')","8874c8c6":"clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression(n_jobs=-1, random_state=42))])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier(n_jobs=-1, random_state=42))]))) \n#clfs.append((\"KNN\", \n#             Pipeline([(\"Scaler\", StandardScaler()),\n#                       (\"KNN\", KNeighborsClassifier(n_jobs=-1))]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier(random_state=42))]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier(n_estimators=200, n_jobs=-1, \n                                                               random_state=42))]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(n_estimators=200,\n                                                                       random_state=42))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier(random_state=42))])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier(n_jobs=-1, random_state=42))])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier(n_jobs=-1, random_state=42))])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'roc_auc'\nn_folds = 5\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, \n                                 cv= n_folds, scoring=scoring,\n                                 n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+\/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n\nplt.show()","4484050a":"from sklearn.metrics import roc_auc_score\ndef get_models_score(model, X, y, X_val, y_val):\n    # Using the model in X_train and y_train desired\n    model.fit(X, y)\n    \n    # Predicting our validation test\n    y_pred = model.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    \n    return score, y_pred","94a1fc4d":"gb_clf = GradientBoostingClassifier(n_estimators=500, random_state=42) \n\nscore, pred = get_models_score(gb_clf, X_train, y_train,\n                                X_test, y_test)\n\nprint(f'Score of: {score} \\n')\n#print(\"Confusion Matrix: \")\n#print(confusion_matrix(y_test, pred))","5fff9473":"lr_clf = LogisticRegression(n_jobs=-1) \n\nscore, pred = get_models_score(lr_clf, X_train, y_train, \n                               X_test, y_test)\n\nprint(f'Score of: {score} \\n')\n#print(\"Confusion Matrix: \")\n#print(confusion_matrix(y_test, pred))","6f408c48":"<h2> Knowing our data<\/h2>","66efe450":"# Head of data after droping","dadb272f":"Very interesting distribution ! <br>\nwe can see that only 35,38% of all projects got sucess.<br>\nMore than 60% have failed or canceled; <br>\n\nI think that the most important category's here is failed and canceled;\n\nMaybe we can build an model to predict if a project would obtain the money or not;\n<br>\n<br>\n\n# Let's start looking our Project values\n- I will start exploring the distribuition logarithmn of these values","24acc283":"<h1>Kickstarter: Exploratory Data Analysis with Python<\/h1>\n\nI'm improving this kernel and adding some statistical plots","6d5a18ed":"## Taking a look athe the distribuition of Diff Pledged sucessful and failed Projects","3f0a3834":"# MinMax Scaler","1ddec04b":"# Modeling \nI will reimport the dataset, but now I use it FULL","52340ed6":"# Scaling and engineering some features","bb839874":"# Word Cloud - Project Names","409f7c36":"# Two-sampled t-test\n- The Independent Samples t Test or 2-sample t-test compares the means of two independent groups in order to determine whether there is statistical evidence that the associated population means are significantly different. The Independent Samples t Test is a parametric test. This test is also known as: Independent t Test.\n","d3a21fa1":"## encoding our target","7a8c50c7":"Cool. We can note that ","edf2d766":"# NOTE: This kernel isn't finished ","ff29602d":"# Backers by State","82e65552":"# State Feature\n- I will start looking the state column distribuition that might will be our key to understand this dataset<\/h2>","397a7f25":"# Logistic Regression","9f08e408":"## Backers by Years","2aa89c0c":"## GradientBoostClassifier","292508e2":"# Launched distributions\n- Lets see months, years and other interesting informations","decc9acf":"# T- Test :\n- A t-test is a type of inferential statistic which is used to determine if there is a significant difference between the means of two groups which may be related in certain features. It is mostly used when the data sets, like the set of data recorded as outcome from flipping a coin a 100 times, would follow a normal distribution and may have unknown variances. T test is used as a hypothesis testing tool, which allows testing of an assumption applicable to a population.\n\nT-test has 2 types : 1. one sampled t-test 2. two-sampled t-test.\n\nLet's start by the more simple one.\n_______________________________\n# One sampled t-test\n\n- One sample t-test : The One Sample t Test determines whether the sample mean is statistically different from a known or hypothesised population mean. The One Sample t Test is a parametric test.\n","886e7f87":"<h2>Analysing further the Categorys: <\/h2>\n- Sucessful category's frequency\n- failed category's frequency\n- General Goal Distribuition by Category","ac9cd1b4":"<h2>Main Category<\/h2>","0004cfc1":"# Goals ","96392789":"## Launched Year Distributions","27cdfb30":"Cool!!! <br>\n\nChi Squared return to us ChiSquared Statistic, Degree of Freedom, p-value and the contingecy table;<br>\n\nWe used the significance level and the dof to calcute the critical value and see if we need to accept or reject the H0 hypothesis.\n\nNow, we can be sure that exists significantly difference between the categories of successful and failed projects.\n","5e24ec5c":"# Month Launched projects","a1f881a3":"Interesting difference between Pledged and Goal distribuition! <br>\n\nGoal seems a normal distribution, so it would be good if we test the normality of it and also, if exists some statistical difference between failed and success projects. <br>\n\nLet start with the normality test of goal","c03b32e6":"# Dealing with date features","bcf2a005":"We have a high mean and standard deviation... Interesting values. <br>\nLet's known better the distribuition of this values using log scale","4df613b9":"# Get Dummies","2a25a8f9":"<b>Kickstarter<\/b>\nIs an American public-benefit corporation based in Brooklyn, New York, that maintains a global crowdfunding platform focused on creativity The company's stated mission is to \"help bring creative projects to life\". Kickstarter has reportedly received more than $1.9 billion in pledges from 9.4 million backers to fund 257,000 creative projects, such as films, music, stage shows, comics, journalism, video games, technology and food-related projects.\n\nPeople who back Kickstarter projects are offered tangible rewards or experiences in exchange for their pledges. This model traces its roots to subscription model of arts patronage, where artists would go directly to their audiences to fund their work.\n","bef22a19":"<h1>Understanding Kickstarter: <\/h1>","487642c0":"# Goal Distribution\n- Let's plot and analyze the distribution of goal that failed and successful projects.","67b81245":"Cool Gradient Boosting, XGB have the best results so I will select them. <br>\nAlso, I will seelect the Logistic Regression too. \n<br>\nThe Decision tree and Extra trees are the models with the lowest roc_auc scores.","25105b66":"# Models Pipeline","fffbab77":"<h2>We have a very interesting distribuition in goal values.<\/h2>","04182c48":"<h1> Looking the time and another features  <\/h1>\n","5cb14419":"<i>English is not my native language, so sorry for any mistake<\/i>\n\n <i>First version on: 2018-02-12 <\/i> \n","21136039":"# Normality Test\n- Although our data seems normal distributed, its good to do a test and be sure that it is true\n- So, before we go further, lets test if the distribution of or goal is normal distributed","469ec6df":"Cool. Now we have a sparse table;","9fec2d13":"Humm... Its an very interesting information.<br>\nOn the first chart, we can clearly see that projects with more than 30 to 60 days have highest vales pledged, what make many sense. <br>\nAlso, we can see that the median of goal reached is like to 120;  Let's s","90778db6":"# Spliting our data in train, validation and test sets","952cf85e":"# Months to Campaign","5d104b4b":"Cool. Now that we know what we have in the dataset, let's star the exploration. ","7b0c72ea":"We can see that almost all categorys in sucessful have the same distribuition of values but some video games projects have the highest values in % difference of Pledged by Goal ","da3a9a9a":"We can note that all months are very similar. ","55817dfe":"# Predicting the X_test with best models","f5c39dff":"<h2>Description of the continous variables<\/h2>","e7b59f40":"#### function to get different models score","8ebacf98":"# Shape of data after spliting the data","3d86d95e":"## Chi-Squared test\n>Chi-square is a great tool to compare results involving categorical data. We can see how a sample deviates from the expected distribution. Python\u2019s SciPy library provides great tools for running chi-square tests.\n\nWe will do a test of two categorical features Main Category and State; \nI have two hypothesis:\nH0: The main categories are the same in the both states. \nH1(or alternative): The main categories of the both states are different. \n\nLet's run the chi2_test:<br>\n(To see the function go to the functions section or fork this kernel)","4c079f52":"<h2>Looking the State variable<\/h2>\n- pledge log by state\n- goal log by state\n- goal log x pledged log","c96c8642":"## I will take a further look at top 10 sucessful and failed categorys.\nI will look at:\n- Goal\n- Pledged\n- diff_pleded_goal ","241aae6a":"## Util functions","704000b6":"Nice. <br>\nBased on the result, we can see that the data isn't normal distributed;","b630c328":"Cool!!! <br>\nNow, let's see if the Logreg will be better or worst. It would be interesting if we use hyperopt to optimze the parameters, but I will start by a benchmark. ","885a1753":"## ML needed Libraries ","ddd8e33a":"<h2>Now I will start to Investigating the 3 top sucess and fail projects<\/h2>\n","e064d894":"Cool. As we saw in your stastical test, the difference between ","a37d03dc":"# Filtering by successful and failed projects","742e88d0":"Cool. As we are rejecting the null hypothesis, the success projects have a diferent distribution than total population","f297ff53":"In the musics with sucess the most frequent is Indie, and fails is Rock and Hip Hop! \n\nAnother interesting thing, is that Documentary is a significant value in both states... ","7ca42984":"<h2>Looking the Goal and Pledged Means by State<\/h2>","136676e8":"## Launched Months Distributions","c584c064":"# Distribution of Backers","34fbb68a":"Nice!!! <br>\n\nThe table above ","c1a0c0cc":"Cool. We can see that in august 2018 was the peak of projects launched. \nLooking the difference pledged x goal between failed and sucessful ","291565f7":"## Now I will take a look at top 10 failed categorys","38d86445":"Cool! The null hypothesis is that the both data are equal, and as it was rejected, so we can be sure that the goal value of sucessful and failed projects are different. <br>\nBased on the distribution of histogram above, the failed project seems to have a higher value. <br>\nBefore we go deep in it, let's see the other features that we have at disposal. ","58de7819":"The most part of projects have 1 month of campaign. We can see that the ratio of successful one month campaigns is better than projects with 1.5 or 2 months of campaign","f417aa16":"## Some fonts that I used to the statistical tests: \nhttps:\/\/machinelearningmastery.com\/chi-squared-test-for-machine-learning\/ <br>\nhttp:\/\/math.hws.edu\/javamath\/ryan\/ChiSquare.html<br>\nhttps:\/\/towardsdatascience.com\/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce <br>\nhttp:\/\/faculty.marshall.usc.edu\/gareth-james\/ISL\/ISLR%20Seventh%20Printing.pdf <br>","8749aba3":"I Will group some categories and after it, filter by Failed or successful projects. <br>\nAlthough suspended and canceled project are caused by different situations, I will replace this categories by 'failed'","e5cb1019":"Nice!!!<br>\nWe can note that failed and succesful projects have different frequencies;\n\nOne important test that we can use is the Chi-squared test to compare the two categories and be sure if they are statistically different"}}