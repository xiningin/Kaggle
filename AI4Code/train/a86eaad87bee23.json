{"cell_type":{"28fe9391":"code","d523ef34":"code","d1867099":"code","2922286b":"code","30c4f3dd":"code","6bbc96be":"code","84e7977e":"code","fb3e7934":"code","e8d119d8":"code","a38cbf92":"code","694f394e":"code","ba6bdea7":"code","34433a4e":"code","4a41510b":"code","7ea547dd":"code","834d100c":"code","7400734f":"code","d9822f03":"code","f1cc0b84":"code","94fc548b":"code","3b1f0c31":"code","63554241":"code","ba717222":"code","a5475d0c":"code","885b1894":"code","3270e1ac":"code","50a29c36":"code","b2383bda":"code","ef6c1871":"code","b8070e84":"code","e403aef9":"code","223907c8":"code","e114ab8c":"code","1e6cfd5e":"code","dd666d55":"markdown","4c59a724":"markdown","1d516fa7":"markdown","68bf01c1":"markdown","a7d713ba":"markdown","494fd77f":"markdown","1a8d0b94":"markdown","5cf1ca34":"markdown","c660e8c1":"markdown","af006ee8":"markdown","d2b960ea":"markdown"},"source":{"28fe9391":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\nimport os\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d523ef34":"df_raw = pd.read_csv(r\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf_raw.head()","d1867099":"df_raw.shape","2922286b":"df_raw.info()","30c4f3dd":"df_raw[\"TotalCharges\"] = pd.to_numeric(df_raw[\"TotalCharges\"], errors='coerce')","6bbc96be":"df_raw.head()","84e7977e":"sns.countplot(x='Churn', data=df_raw)","fb3e7934":"df_raw.isnull().sum().sort_index()\/len(df_raw)","e8d119d8":"#Code taken from fast ai library. Code can be found at github.\n#https:\/\/github.com\/fastai\/fastai\/blob\/master\/old\/fastai\/structured.py\ndef train_cats(df):\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()","a38cbf92":"train_cats(df_raw)","694f394e":"df_raw.PhoneService.cat.categories","ba6bdea7":"df_raw.PaperlessBilling.cat.categories","34433a4e":"#The below functions are taken from fast ai library, code for which can be found at github.\n#https:\/\/github.com\/fastai\/fastai\/blob\/master\/old\/fastai\/structured.py\ndef fix_missing(df, col, name, na_dict):\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+'_na'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n        df[name] = col.cat.codes+1\n        \ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    else: df = df.copy()\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    else: na_dict = na_dict.copy()\n    na_dict_initial = na_dict.copy()\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if len(na_dict_initial.keys()) > 0:\n        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res","4a41510b":"df, y, nas = proc_df(df_raw, 'Churn', skip_flds=['customerID'], max_n_cat=8)","7ea547dd":"df.head().T","834d100c":"def split_vals(a,n): return a[:n], a[n:]","7400734f":"n_valid = int(7043 * 0.1)\nn_trn = len(df)-n_valid\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)","d9822f03":"from sklearn import metrics","f1cc0b84":"def print_score(m):\n    res = [metrics.accuracy_score(m.predict(X_train), y_train), \n           metrics.accuracy_score(m.predict(X_valid), y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","94fc548b":"m = RandomForestClassifier(n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","3b1f0c31":"#The below functions are taken from fast ai library, code for which can be found at github.\n#https:\/\/github.com\/fastai\/fastai\/blob\/master\/old\/fastai\/structured.py\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","63554241":"fi = rf_feat_importance(m, df) \nfi[:10]","ba717222":"def plot_fi(fi): \n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","a5475d0c":"plot_fi(fi[:30])","885b1894":"plt.figure(figsize=(9, 4))\nplt.title(\"KDE for Total Charges\")\nax0 = sns.kdeplot(df_raw[df_raw['Churn'] == 'No'][\"TotalCharges\"].dropna(), color= 'green', label= 'Churn: No')\nax1 = sns.kdeplot(df_raw[df_raw['Churn'] == 'Yes'][\"TotalCharges\"].dropna(), color= 'red', label= 'Churn: Yes')","3270e1ac":"plt.figure(figsize=(9, 4))\nplt.title(\"KDE for Monthly Charges\")\nax0 = sns.kdeplot(df_raw[df_raw['Churn'] == 'No'][\"MonthlyCharges\"].dropna(), color= 'green', label= 'Churn: No')\nax1 = sns.kdeplot(df_raw[df_raw['Churn'] == 'Yes'][\"MonthlyCharges\"].dropna(), color= 'red', label= 'Churn: Yes')","50a29c36":"plt.figure(figsize=(9, 4))\nplt.title(\"KDE for Tenure\")\nax0 = sns.kdeplot(df_raw[df_raw['Churn'] == 'No'][\"tenure\"].dropna(), color= 'green', label= 'Churn: No')\nax1 = sns.kdeplot(df_raw[df_raw['Churn'] == 'Yes'][\"tenure\"].dropna(), color= 'red', label= 'Churn: Yes')","b2383bda":"#Increase the number of estimator's i.e. the number of decision trees to to 40.\nm = RandomForestClassifier(n_estimators=40, n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","ef6c1871":"fi","b8070e84":"to_keep = fi[fi.imp>0.01].cols\nlen(to_keep)","e403aef9":"df_keep = df[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, n_trn)","223907c8":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","e114ab8c":"fi = rf_feat_importance(m, df_keep)\nplot_fi(fi);","1e6cfd5e":"m = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","dd666d55":"Let's only keep the features in the model that have a feature importance of more than 0.01","4c59a724":"Let's see if we have null values in any of our columns","1d516fa7":"Total Charges columns has float values but the data type of the column is object so lets try to  convert it to float column","68bf01c1":"As you can see the top most features for the Random Forest are Total Charges, Monthly Charges and Tenure. Let's try to analyze these features in detail.","a7d713ba":"Let's try to tune some hyperparameters and see if we can increase the accuracy of the model","494fd77f":"As you can see from the above plots, for higher monthly charges the churn is more. Also higher tenured customers are less likely to leave the telco.","1a8d0b94":"## Introduction\nThis is my first Kaggle kernel which will help in building a predictive model which will identify the churn in Telecom industry. I have recently started with Fast ai ML course hence I will extensively make use of the code and my understandings from the course.  \nI was not sure how to install Fast ai library in Kaggle so I have copy pasted the necessatry code from the Fast ai library since the functions are independent and dont have any dependencies. Full Fast ai ML code can be found at [github](https:\/\/github.com\/fastai\/fastai)","5cf1ca34":"Split the data into Train and Test set. I will set aside 10% of the data as a test set.","c660e8c1":"The categorical variables are currently stored as strings, which is inefficient, and doesn't provide the numeric coding required for a random forest. Therefore we call train_cats to convert strings to pandas categories.","af006ee8":"Let's bump the number of estimators to 100 and see if our model performance improves","d2b960ea":"Jeremy Howard mentions that once you have trained a Random Forest, the next thing you should do is Feature Importance. This will help you in identifying the features that played a prominent role in the predictive model."}}