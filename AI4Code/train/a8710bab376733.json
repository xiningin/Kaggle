{"cell_type":{"6dcbb475":"code","2e37fe28":"code","9d18c2cb":"code","35c85df6":"code","42aba44d":"code","561b0a8c":"code","64ca630c":"code","53a3a1a5":"code","ed0fcbe3":"code","80eadf46":"code","5464edf3":"code","2497ce3a":"code","0b8f6ec6":"code","c26d0683":"code","729bc06d":"code","d8725956":"code","af590325":"code","f1d51db9":"code","35bef589":"code","a037c53e":"code","f19a4c81":"code","04a1d49c":"code","6b79e841":"code","4e1fe154":"code","a8203ca9":"code","5a6e7652":"markdown","6f930e58":"markdown"},"source":{"6dcbb475":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2e37fe28":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('..\/input\/bank-marketing-data-set\/bank_marketing_dataset.csv')\ndata","9d18c2cb":"cols = list(data.columns)\n\nfor col in cols:\n    for i in range(data.shape[0]):\n        if col == \"job\" and data[col][i] == \"unknown\":\n            data[col][i] = \"unemployed\"  #Assuming unemployed status\n        if col == \"marital\" and data[col][i] == \"unknown\":\n            data[col][i] = \"single\" #Assuming 'Single' status\n        if col == \"education\" and data[col][i] == \"unknown\":\n            data[col][i] = \"illiterate\" #Assuming uneducated status    \n        # Default, Housing, loan need to be binary type and cannot contain Missing info as a third option. \n        # Thus, setting it to None so that these records can be dropped.\n        if col in [\"default\", \"housing\", \"loan\"] and data[col][i] == \"unknown\":\n            data[col][i] = None\n        # Similarly, pdays = 999 indicates the client was not contacted and deemed not interested so can be dropped.\n        if col == \"pdays\" and data[col][i] == 999:\n            data[col][i] = None\n        # poutcome can either be success or failure. Thus, nonexistant =  missing data and, can be dropped.\n        if col == \"poutcome\" and data[col][i] == \"nonexistent\":\n            data[col][i] = None","35c85df6":"data.isna().sum()","42aba44d":"\"\"\"\nGoing by the above data, we can observe that most of the clients were not previously contacted i.e they are potential new clients maybe. \nTherefore, it would be inappropriate to drop the respective records from analyis.\nWe could rather drop the feature.\n\"\"\"\n# pdays, previous and poutcome columns can be dropped since most of the clients seem to be new.\n# Further, these columns do not provide any significant information for the predictive analysis as most are new clients.\ndata.drop(['pdays', 'poutcome', 'previous'], axis=1, inplace=True)","561b0a8c":"# Now we can drop the records with missing data\ndata.dropna(axis=0, how='any', inplace=True)","64ca630c":"data.shape","53a3a1a5":"# Lets check for correlated data\ncorrelated_data = data.corr()\nplt.figure(figsize= (12,8))\nsns.heatmap(correlated_data, cmap=\"Blues\", annot=True)","ed0fcbe3":"# From the above data, we can observe that emp.var.rate, nr.employed & euribor3m are highly correlated.\n# So, lets drop the above mentioned columns from the data.\n# Further, the benchmark data, duration also can be dropped for the purpose of predictive analysis.\ndata.drop(['emp.var.rate', 'euribor3m', 'nr.employed', 'duration'], axis=1, inplace=True)","80eadf46":"# Converting categorical and binary type columns to numerical type for easy computation. \nbinary_cols = ['default', 'housing', 'loan', 'subscribed']\ndummy_list = []\nfor c in binary_cols:\n    for text in data[c].values:\n        if text == 'yes':\n            dummy_list.append(1)\n        else:\n            dummy_list.append(0)\n    data[c] = dummy_list\n    dummy_list = []\n\njob_types = {'admin.':1,'blue-collar':2,'entrepreneur':3,'housemaid':4,'management':5,'retired':6,'self-employed':7,\n             'services':8,'student':9,'technician':10,'unemployed':11}\nmarital_status = {'divorced':1,'married':2,'single':3}\nedu = {'basic.4y':1,'basic.6y':2,'basic.9y':3,'high.school':4,'illiterate':5,'professional.course':6,'university.degree':7}\ncontact_type = {'cellular':1,'telephone':2}\nmonths = {'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12}\ndays = {'mon':1,'tue':2,'wed':3,'thu':4,'fri':5}\n\ncpy = []\nfor txt in data['job'].values:\n    cpy.append(job_types[txt])\ndata['job'] = cpy\ncpy = []\nfor txt in data['marital'].values:\n    cpy.append(marital_status[txt])\ndata['marital'] = cpy\ncpy = []\nfor txt in data['education'].values:\n    cpy.append(edu[txt])\ndata['education'] = cpy\ncpy = []\nfor txt in data['contact'].values:\n    cpy.append(contact_type[txt])\ndata['contact'] = cpy\ncpy = []\nfor txt in data['month'].values:\n    cpy.append(months[txt])\ndata['month'] = cpy\ncpy = []\nfor txt in data['day_of_week'].values:\n    cpy.append(days[txt])\ndata['day_of_week'] = cpy\ncpy = []","5464edf3":"data","2497ce3a":"target = data['subscribed']\nfeature_set = data.drop(['subscribed'], axis=1)\n\nX_train, X_test, Y_train, Y_test = train_test_split(feature_set,target, random_state=0)\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score, confusion_matrix, plot_roc_curve\n\nclassifiers = [DecisionTreeClassifier(random_state = 0),\n               GaussianNB(), \n               SGDClassifier(loss='modified_huber', shuffle=True, random_state = 0),\n               RandomForestClassifier(n_estimators=20, random_state = 0),\n               AdaBoostClassifier(),\n               KNeighborsClassifier()\n              ]\n\nfor classifier in classifiers:\n    score = 0\n    \n    classifier = classifier.fit(X_train, Y_train)\n    \n    predicted_target = classifier.predict(X_test)\n    \n    score = accuracy_score(Y_test,predicted_target)\n    print(f\"Accuracy of classifier model: {classifier} is :{round(score, 2)}\")\n    cf_matrix = confusion_matrix(Y_test, predicted_target)\n    print(f\"Confusion Matrix of classifier {classifier} is as follows : \\n{cf_matrix}\")\n    print(f\"ROC Curve of classifier model: {classifier} is as below\")\n    plot_roc_curve(classifier, X_test, Y_test)\n    plt.show()","0b8f6ec6":"df1 = data.loc[data.subscribed == 1]\ndf0 = data.loc[data.subscribed == 0]\nprint(df1.shape)\nprint(df0.shape)","c26d0683":"ed_subs1 = list(df1.education.value_counts().values)\nticks1 = ['University Degree','High School','Professional Course','Basic 9yr','Basic 4yr','Illiterate','Basic 6yr']\nplt.pie(ed_subs1,labels=ticks1, autopct='%.2f%%')\nplt.title(\"Subscribed % by Education\")\nplt.show()","729bc06d":"ed_subs0 = list(df0.education.value_counts().values)\nticks0 = ['University Degree','High School','Basic 9yr','Professional Course','Basic 4yr','Basic 6yr','Illiterate']\nplt.pie(ed_subs0,labels=ticks0, autopct='%.2f%%')\nplt.title(\"Unsubscribed % by Education\")\nplt.show()","d8725956":"marital_subs1 = list(df1.marital.value_counts().values)\nmtick1 = [\"Married\",\"Single\",\"Divorced\"]\nplt.pie(marital_subs1,labels=mtick1, autopct='%.2f%%')\nplt.title(\"Subscribed % by Marital Status\")\nplt.show()","af590325":"marital_subs0 = list(df0.marital.value_counts().values)\nmtick0 = [\"Married\",\"Single\",\"Divorced\"]\nplt.pie(marital_subs0,labels=mtick0, autopct='%.2f%%')\nplt.title(\"Unsubscribed % by Marital Status\")\nplt.show()","f1d51db9":"monthly_subs1 = list(df1.month.value_counts().values)\nmon_tick1 = ['May','August','July','April','June','November','October','March','September','December']\nplt.pie(monthly_subs1,labels=mon_tick1, autopct='%.2f%%')\nplt.title(\"Subscribed % by Month\")\nplt.show()","35bef589":"monthly_subs0 = list(df0.month.value_counts().values)\nmon_tick0 = ['May','July','August','June','November','April','October','September','March','December']\nplt.pie(monthly_subs0,labels=mon_tick0, autopct='%.2f%%')\nplt.title(\"Unsubscribed % by Month\")\nplt.show()","a037c53e":"dow_subs1 = list(df1.day_of_week.value_counts().values)\ndow_tick1 = ['Thursday','Wednesday','Tuesday','Monday','Friday']\nplt.pie(dow_subs1,labels=dow_tick1, autopct='%.2f%%')\nplt.title(\"Subscribed % by Weekday\")\nplt.show()","f19a4c81":"dow_subs0 =list(df0.day_of_week.value_counts().values)\ndow_tick0 = ['Monday','Thursday','Wednesday','Tuesday','Friday']\nplt.pie(dow_subs0,labels=dow_tick0, autopct='%.2f%%')\nplt.title(\"Unsubscribed % by Weekday\")\nplt.show()","04a1d49c":"job_subs1 =list(df1.job.value_counts().values)\njob_tick1 = ['Admin','Technician','Blue-Collar','Retired','Management','Services','Student','Unemployed','Self-Employed',\n             'Entrepreneur','House-maid']\nplt.pie(job_subs1,labels=job_tick1, autopct='%.2f%%')\nplt.title(\"Subscribed % by Job Type\")\nplt.show()","6b79e841":"job_subs0 = list(df0.job.value_counts().values)\njob_tick0 = ['Admin','Blue-Collar','Technician','Services','Management','Entrepreneur','Self-Employed','Retired','Unemployed',\n             'House-maid','Student']\nplt.pie(job_subs0,labels=job_tick0, autopct='%.2f%%')\nplt.title(\"Unsubscribed % by Job Type\")\nplt.show()","4e1fe154":"con_subs1 = list(df1.contact.value_counts().values)\ncon_tick1 = ['Cellular','Telephone']\nplt.pie(con_subs1,labels=con_tick1, autopct='%.2f%%')\nplt.title(\"Subscribed % by Contact Type\")\nplt.show()","a8203ca9":"con_subs0 = list(df0.contact.value_counts().values)\ncon_tick0 = ['Cellular','Telephone']\nplt.pie(con_subs0,labels=con_tick0, autopct='%.2f%%')\nplt.title(\"Unsubscribed % by Contact Type\")\nplt.show()","5a6e7652":"From the above observations, AdaBoostClassifier seems to be the best classifier with following performance metrics:\n\n    Classification Accuracy: 87%\n    Confusion Matrix: [[6763 190] [823  181]]\n    Precision: 181\/(181 + 190) = 0.48787 ~ 0.49\n    Recall: 181\/(181 + 823) = 0.18027 ~ 0.18\n    F1 score: 2*(Precision * Recall)\/(Precision + Recall) = 0.26328 ~ 0.26 \n    Sensitivity (TPR): 181\/(181 + 823) = 0.18\n    Specificity (FPR): 190\/(190 + 6763) = 0.0273 ~ 0.027\n    AUC Score: 0.78","6f930e58":"INSIGHTS:<br>\nAdaBoost Classifier works best with the available data to classify whether a client would subscribe or not.<br>\n4101 clients of 31828 have subscribed as a result of the marketing campaign i.e only 12.88% have subscribed. <br>\nMajority of the 12.88% that have subscribed, have the following characteristics:<br>\n            &emsp;- University Degree or High School level of Education<br>\n            &emsp;- Are Married or Single<br>\n            &emsp;- May, July & August seem to be the Months they mostly subscribe<br>\n            &emsp;- Prefer to attend calls on any weekday via cellphone<br>\n            &emsp;- Have jobs as either Admin, Blue-Collar or Technician<br>\nSimilar characterisctics are observed on the clients who haven't subscribed [ Unsubscribed - 87.12% ]<br>"}}