{"cell_type":{"be1582ae":"code","852286b3":"code","904416dd":"code","09b4ea9d":"code","ce373b3c":"code","a02b8fad":"code","f810f82f":"code","9c277725":"code","a03bcca9":"code","0456c8f5":"code","04efaa49":"code","43f4d8ca":"code","3ad932d5":"code","0b24f73a":"code","529f3498":"code","3fac8cba":"code","75bf8138":"code","5fc39170":"code","8723ae5e":"code","8289e735":"markdown","6d6980cf":"markdown","b11fbcd1":"markdown","3fb21bf6":"markdown","5bb5f4bb":"markdown","66553c2e":"markdown","7f9ccd2b":"markdown"},"source":{"be1582ae":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')","852286b3":"# necessary imports\nimport os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport timm\n\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nDATA_DIR = \"..\/input\/ranzcr-clip-catheter-line-classification\"\n\nplt.style.use('bmh')\nplt.rcParams['figure.figsize'] = [20, 13]\nSEED = 421","904416dd":"IMAGE_SIZE = 600\nBATCH_SIZE = 2\nMODEL_NAME = \"efficientnet_b7\"\nMODEL_PATH_effnetb7 = \"..\/input\/ranzcr-final-timm-efficientnetb7\/timm-effnet-b7-res600-final.pt\"\nTTA = True","09b4ea9d":"input_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\nprint (input_df.info())","ce373b3c":"def plot_input_images(imgs: torch.Tensor, title_string: str, nrow: int = 4) -> None:\n    image_grid = make_grid(imgs, nrow=nrow, padding=10, pad_value=1)\n    \n    # transform from CHW -> HWC\n    plt.imshow(image_grid.permute(1, 2, 0), cmap=plt.cm.bone)\n    plt.title(title_string)","a02b8fad":"CLASSES = [col for col in input_df.columns if col not in ['StudyInstanceUID']]\n\n\nclass RanczrDataset(Dataset):\n    def __init__(self, df, data_dir, transform=None, is_test=False, is_rgb=False):\n        super().__init__()\n        self.df = df\n        self.data_dir = data_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.is_rgb = is_rgb\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        data = {}\n        \n        img_name = self.df['StudyInstanceUID'][index]\n        \n        if not self.is_test:\n            targets = self.df.loc[index, CLASSES].values.astype(np.uint8)\n        \n            targets = torch.from_numpy(targets)\n            \n            data['targets'] = targets\n            \n        img_path = os.path.join(self.data_dir, img_name+\".jpg\")\n        \n        \n        if self.is_rgb:\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        else:\n            image = Image.open(img_path)\n            \n        if self.transform:\n            image = self.transform(image)\n        \n        data['image'] = image\n        \n        return data","f810f82f":"test_effnet_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485], std=[0.229])\n])\n\n# test_resnet200d_transforms = transforms.Compose([\n#     transforms.ToPILImage(),\n#     transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n# ])\n","9c277725":"# creating the dataset object\ntest_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_effnet_transforms, is_test=True)\n\n# creating the test dataloader\ntest_loader1 = DataLoader(dataset=test_dataset, batch_size=8, num_workers=0, shuffle=False)\n\nbatch = next(iter(test_loader1))\n\nplot_input_images(batch['image'], title_string='batch images', nrow=8)\n\ndel batch\ndel test_dataset\ndel test_loader1\ngc.collect()","a03bcca9":"# # creating the dataset object\n# test_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_resnet200d_transforms, is_test=True, is_rgb=True)\n\n# # creating the test dataloader\n# test_loader2 = DataLoader(dataset=test_dataset, batch_size=8, num_workers=0, shuffle=False)\n\n# batch = next(iter(test_loader2))\n\n# plot_input_images(batch['image'], title_string='batch images', nrow=8)\n\n# del batch\n# del test_dataset\n# del test_loader2\n# gc.collect()","0456c8f5":"class Effnetb7(nn.Module):\n    def __init__(self, model_name='efficientnet_b7'):\n        super(Effnetb7, self).__init__()\n        \n        self.effnet = timm.create_model(model_name, pretrained=False, in_chans=1).as_sequential()[:-2]\n        \n        self.dropout = nn.Dropout(p=0.5)\n        self.dense = nn.Linear(2560, len(CLASSES))\n        \n        \n    def forward(self, images):\n        pooled_features= self.effnet(images)\n        \n        outputs = self.dense(self.dropout(pooled_features))\n        \n        return outputs\n    \n# class RANZCRResNet200D(nn.Module):\n#     def __init__(self, model_name='resnet200d', out_dim=11, pretrained=False):\n#         super().__init__()\n#         self.model = timm.create_model(model_name, pretrained=False)\n#         n_features = self.model.fc.in_features\n#         self.model.global_pool = nn.Identity()\n#         self.model.fc = nn.Identity()\n#         self.pooling = nn.AdaptiveAvgPool2d(1)\n#         self.fc = nn.Linear(n_features, out_dim)\n\n#     def forward(self, x):\n#         bs = x.size(0)\n#         features = self.model(x)\n#         pooled_features = self.pooling(features).view(bs, -1)\n#         output = self.fc(pooled_features)\n#         return output","04efaa49":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\neffnetb7 = Effnetb7()\neffnetb7.load_state_dict(torch.load(MODEL_PATH_effnetb7, map_location='cuda:0'))\neffnetb7 = effnetb7.to(device)\n# resnet200d = RANZCRResNet200D()\n# resnet200d.load_state_dict(torch.load(MODEL_PATH_resnet200d, map_location='cuda:0'))","43f4d8ca":"# Adapted from https:\/\/www.kaggle.com\/underwearfitting\/resnet200d-public-benchmark-2xtta-lb0-965#Utils\n\ndef inference_func(model, test_loader, device):\n    model.eval()\n    bar = tqdm(test_loader)\n    LOGITS = []\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, data in enumerate(bar):\n            x = data['image'].to(device)\n            logits = model(x)\n            LOGITS.append(logits.cpu())\n            PREDS += [logits.sigmoid().detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        LOGITS = torch.cat(LOGITS).cpu().numpy()\n    return PREDS\n\ndef tta_inference_func(model, test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    PREDS = []\n    LOGITS = []\n\n    with torch.no_grad():\n        for batch_idx, data in enumerate(bar):\n            x = data['image'].to(device)\n            x = torch.stack([x,x.flip(2),x.flip(3)],0) # TTA: vflip and hflip\n            x = x.view(-1, 1, IMAGE_SIZE, IMAGE_SIZE)\n            logits = model(x)\n            logits = logits.view(BATCH_SIZE, 3, -1).mean(1)\n            PREDS += [logits.sigmoid().detach().cpu()]\n            LOGITS.append(logits.cpu())\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        \n    return PREDS","3ad932d5":"# creating the dataset object\ntest_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_effnet_transforms, is_test=True)\n\n# creating the test dataloader\ntest_loader_effnet = DataLoader(dataset=test_dataset, batch_size=2, num_workers=0, shuffle=False)\n\ntest_preds = None\nif TTA:\n    print ('Using TTA')\n    test_preds = tta_inference_func(effnetb7, test_loader_effnet)\nelse:\n    test_preds = inference_func(effnetb7, test_loader_effnet)","0b24f73a":"test_preds","529f3498":"submission = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')\n\nfor i in range(test_preds.shape[1]):\n    submission.loc[:, CLASSES[i]] = test_preds[:, i]","3fac8cba":"submission","75bf8138":"submission.to_csv('submission.csv', index=False)","5fc39170":"# # creating the dataset object\n# test_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_resnet200d_transforms, is_test=True, is_rgb=True)\n\n# # creating the test dataloader\n# test_loader_resnet200d = DataLoader(dataset=test_dataset, batch_size=2, num_workers=0, shuffle=False)\n\n# predictions_resnet200d = inference_func(resnet200d.to(device), test_loader_resnet200d, device)","8723ae5e":"# predictions = (2 * predictions_resnet200d + predictions_effnetb7) \/ 3.0","8289e735":"### Transforms","6d6980cf":"### Model","b11fbcd1":"### Utilities","3fb21bf6":"### Predictions for Efficientnet-b7","5bb5f4bb":"### Test datasets for both models","66553c2e":"### Visualising test dataset samples for both models","7f9ccd2b":"### Utility function"}}