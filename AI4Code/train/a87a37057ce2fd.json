{"cell_type":{"67459a73":"code","f8915fd7":"code","370c7a7e":"code","fd8c7fc7":"code","52743db0":"code","b2477021":"code","13228cc0":"code","19a47426":"code","d82def8e":"code","e34af4ea":"code","ccdb0c35":"code","200d163d":"code","316296a6":"code","aab48efa":"code","d2a1745e":"code","4622aa28":"code","2f649a41":"code","0fcf6790":"code","84f2c0fd":"code","de863f93":"code","c10553ff":"code","cb492944":"code","6a6dedc4":"code","8182f984":"code","5543f812":"code","e5aa0559":"code","9a59d8dd":"code","6011c7d8":"code","1310e16f":"code","c566f004":"code","6bf70059":"code","a55097b1":"code","f8b46671":"code","25be591e":"code","9317d421":"code","3a69dd46":"code","c1c3c707":"code","9865f604":"code","044a2cf1":"code","72055e44":"code","52384e39":"code","f3b2eb45":"code","1b832f6e":"code","e7d62b83":"code","bc5e5e2f":"code","658656ab":"code","2212d540":"code","9b07871e":"code","cb6d5fa4":"code","142548d9":"code","b0009c53":"code","bc378828":"code","2c63eaa9":"code","96fff2a1":"code","e894591a":"code","fe16dc40":"code","65a24dd4":"code","72b892a1":"code","e5c1a007":"code","c1d3ea6d":"code","7968f6d2":"code","d49fc2ea":"code","3d329d57":"code","ad38bc81":"markdown","6d2cb4d8":"markdown","a3c26c76":"markdown","0427091a":"markdown","c6b5bae1":"markdown","2144f6dd":"markdown","82069ad0":"markdown","b6e2e57d":"markdown","616d205e":"markdown","280aecd9":"markdown","b72c3271":"markdown","2e00e66a":"markdown","f2cddece":"markdown","c74f41f0":"markdown","5352f407":"markdown","956970c6":"markdown","5553d7bb":"markdown","1aebab01":"markdown","4e0b99e1":"markdown","94abc6ed":"markdown","3d899294":"markdown","6a0552c1":"markdown","2ab678e9":"markdown","142a1384":"markdown","3464316d":"markdown","bba2d4fe":"markdown","3c5531f3":"markdown","27f7aacb":"markdown"},"source":{"67459a73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8915fd7":"import matplotlib.pylab as plt\nimport seaborn as sns\nimport plotly.express as px\nimport gc\n","370c7a7e":"train = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')","fd8c7fc7":"train.head()","52743db0":"train.shape","b2477021":"print(train[\"timestamp\"].min() , train[\"timestamp\"].max(),sep =\"\\n\")\n","13228cc0":"train['meter_reading'].describe()","19a47426":"zeros = train[train['meter_reading']== 0].shape[0] \/ train.shape[0]\nprint('Zero reading percentile : {}'.format(round(zeros,3)))","d82def8e":"# Converting meter to what they stand for\n\ntrain['meter'].replace({0:\"electricity\",1:\"chilledwater\",2:\"steam\",3:\"hotwater\"},inplace=True)","e34af4ea":"meter_dict = {}\nfor i in train[\"meter\"].unique():\n    percent = round(train[train['meter_reading']== 0][\"meter\"].value_counts()[i] \/train[\"meter\"].value_counts()[i],2)\n    meter_dict[i] = percent\nzero_meter = pd.Series(meter_dict)\nsns.barplot(x=zero_meter.index, y= zero_meter,palette =\"Set2\")\nplt.title(\"Meters percentage having zero readings\")\n","ccdb0c35":"train[\"timestamp2\"] = pd.to_datetime(train[\"timestamp\"])\ntrain[\"month\"] = train.timestamp2.dt.month","200d163d":"fig, axs = plt.subplots(2,2, sharey=True, tight_layout=True,figsize=(10,6))\n\naxs[0][0].hist(x =\"month\",data =train[(train.meter_reading == 0) & (train.meter==\"electricity\")],bins =12,color = \"navajowhite\")\naxs[0][0].set_title(\"For electricity\")\n\naxs[0][1].hist(x =\"month\",data =train[(train.meter_reading == 0) & (train.meter==\"chilledwater\")],bins =12,color = \"skyblue\")\naxs[0][1].set_title(\"For chilled water\")\n\naxs[1][0].hist(x =\"month\",data =train[(train.meter_reading == 0) & (train.meter==\"steam\")],bins =12,color = \"slategrey\")\naxs[1][0].set_title(\"For steam\")\n\naxs[1][1].hist(x =\"month\",data =train[(train.meter_reading == 0) & (train.meter==\"hotwater\")],bins =12,color = \"lightcoral\")\naxs[1][1].set_title(\"For hot water\")","316296a6":"train.drop(\"timestamp2\",axis = 1 ,inplace = True)","aab48efa":"# Function for remove Outlier\n\ndef removeOutliers(data, outlierConstant = 1.5):\n    values = np.array(data)\n    upper_quartile = np.percentile(values, 75)\n    lower_quartile = np.percentile(values, 25)\n    IQR = (upper_quartile - lower_quartile) * outlierConstant\n    quartile = (lower_quartile - IQR, upper_quartile + IQR)\n    results = []\n    for i in values.tolist():\n        if i >= quartile[0] and i <= quartile[1]:\n            results.append(i)\n    return results","d2a1745e":"target_noOutlier = removeOutliers(train.meter_reading)","4622aa28":"fig, axes = plt.subplots(1, 3,figsize=(12,5))\n\nsns.distplot(train.meter_reading,hist = False,ax = axes[0])\naxes[0].set_title(\"Target distribution\")\n\nsns.distplot(target_noOutlier,ax=axes[1])\naxes[1].set_title(\"Target distribution without outlier\")\n\nsns.distplot(np.log1p(train.meter_reading),ax = axes[2])\naxes[2].set_title(\"Target with Log Transform\") ","2f649a41":"train['meter_reading_log'] = np.log1p(train['meter_reading'])","0fcf6790":"sns.countplot(x= \"meter\",data = train,color = 'b')","84f2c0fd":"sns.kdeplot(train.loc[(train['meter']=='electricity'), \n            \"meter_reading_log\"], color='yellow', shade=False, Label='electricity')\n\nsns.kdeplot(train.loc[(train['meter']=='chilledwater'), \n            \"meter_reading_log\"], color='b', shade=False, Label='chilledwater')\n\nsns.kdeplot(train.loc[(train['meter']=='steam'), \n            \"meter_reading_log\"], color='gray', shade=False, Label='steam')\n\nsns.kdeplot(train.loc[(train['meter']=='hotwater'), \n            \"meter_reading_log\"], color='r', shade=False, Label='hotwater')\n\nplt.xlabel('meter_reading_log') \nplt.ylabel('Probability Density') ","de863f93":"weather_train =pd.read_csv(\"..\/input\/ashrae-energy-prediction\/weather_train.csv\")","c10553ff":"weather_train.shape","cb492944":"weather_train.info()","6a6dedc4":"weather_train.head()","8182f984":"weather_train.describe()","5543f812":"fig, axes = plt.subplots(7,1,figsize=(10,30)) \ncolumns = weather_train.drop([\"site_id\",\"timestamp\"],axis=1).columns\nfor i,col in enumerate(list(columns)):\n\n    plot = weather_train.boxplot(col, by=\"site_id\", ax=axes.flatten()[i])\n\nplt.tight_layout() \n\nplt.show()","e5aa0559":"sns.heatmap(weather_train.corr(),linewidths=.5,cmap=\"YlGnBu\")","9a59d8dd":"build = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/building_metadata.csv\")","6011c7d8":"build.info()","1310e16f":"build.tail()","c566f004":"build.primary_use.unique()","6bf70059":"build.groupby('site_id').agg({\"building_id\":[min,max]})","a55097b1":"fig, axes = plt.subplots(1, 2,figsize=(16,5))\nsite_build = build.groupby('site_id').building_id.size()\nsns.barplot(x=site_build.index , y= site_build,color=\"salmon\",ax=axes[0])\naxes[0].set_ylabel(\"Number of building\")\nsns.countplot(y=\"primary_use\",data=build ,ax=axes[1],color=\"salmon\")\nfig.subplots_adjust(wspace=0.5)\nplt.ylabel(\"\")\ndel site_build\n","f8b46671":"sns.heatmap(build.corr(),linewidths=.5,annot =True)","25be591e":"fig, axes = plt.subplots(3,1,figsize=(10,10)) \ncolumns = build.drop([\"primary_use\",\"site_id\",\"building_id\"],axis=1).columns\nfor i,col in enumerate(list(columns)):\n    plot = build.boxplot(col, by=\"site_id\", ax=axes.flatten()[i])\n\nplt.tight_layout() \n\nplt.show()","9317d421":"build.hist(column =\"year_built\",bins=50)","3a69dd46":"gc.collect()","c1c3c707":"# Reduce memory size func \n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","9865f604":"train = reduce_mem_usage(train)\n\nweather_train = reduce_mem_usage(weather_train)\n\nbuild = reduce_mem_usage(build)","044a2cf1":"print(\"Train merge on : \")\nprint(\"build : \",set(train.columns).intersection(set(build.columns)))\nprint(\"weather :\",set(build.columns).intersection(set(weather_train.columns)),end =\"\")\nprint(set(train.columns).intersection(set(weather_train.columns)))      ","72055e44":"# Merge dataset\n\ntrain = train.merge(build, on='building_id', how='left')\nalltrain = train.merge(weather_train, on=['site_id','timestamp'], how='left')\n\ndel build,weather_train,train\ngc.collect()","52384e39":"alltrain[\"timestamp\"] = pd.to_datetime(alltrain[\"timestamp\"])","f3b2eb45":"#alltrain.info()\n\nnumeric_col = alltrain.select_dtypes(np.number).columns.tolist()\ncategoric_col =alltrain.select_dtypes(\"object\").columns.tolist()\ndate =alltrain.select_dtypes(\"datetime\").columns.tolist()\nprint(\"numeric columns : {} \".format(numeric_col))\nprint(\"categorical columns : {} \".format(categoric_col))\nprint(\"datetime columns : {} \".format(date))","1b832f6e":"alltrain.drop(['building_id','site_id'],axis =1).describe() ","e7d62b83":"use = alltrain.groupby(\"primary_use\").meter_reading.mean()\nsns.barplot(y=use.index,x=use)\ndel use","bc5e5e2f":"feet_range = pd.cut(alltrain.square_feet, bins=np.arange(0, 1000000, 100000))\nsquare_meter_read = pd.concat([feet_range,alltrain.meter_reading],axis =1)\ns = square_meter_read.groupby(\"square_feet\").meter_reading.mean()\nsns.barplot(y=s.index,x=s)\ndel feet_range,square_meter_read,s","658656ab":"gc.collect()","2212d540":"#  expanded on over time\nalltrain.rename(columns = {\"timestamp\":\"date\"},inplace= True)\nalltrain[\"month\"] = np.uint8(alltrain[\"date\"].dt.month)\nalltrain[\"week\"] =alltrain[\"date\"].dt.weekofyear\nalltrain[\"weekday\"] = np.uint8(alltrain[\"date\"].dt.weekday)\nalltrain[\"day\"] = np.uint8(alltrain[\"date\"].dt.day)\nalltrain[\"hour\"] = np.uint8(alltrain[\"date\"].dt.hour)\nalltrain[\"weekend\"] = [1 if x in [5,6] else 0 for x in alltrain.day]","9b07871e":"alltrain['part_of_day'] = (alltrain['date'].dt.hour % 24 + 4) \/\/ 4\nalltrain['part_of_day'].replace({1: 'Late Night',\n                      2: 'Early Morning',\n                      3: 'Morning',\n                      4: 'Noon',\n                      5: 'Evening',\n                      6: 'Night'}, inplace=True)","cb6d5fa4":"reduce_mem_usage(alltrain)","142548d9":"columns = [\"date\",\"hour\"]\nfor col in columns:\n    time = alltrain.groupby([col,\"meter\"]).meter_reading_log.mean().reset_index()\n    fig = px.line(time, x=col, y=\"meter_reading_log\",color='meter')\n    fig.show()","b0009c53":"for x in [\"weekend\",\"part_of_day\",\"weekday\"]:\n    sns.boxplot(x = x, y= \"meter_reading_log\",data = alltrain,palette = \"pastel\")\n    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    plt.show()","bc378828":"def findnull(data):\n    nullseries = data.isnull().sum()\n    onlynull= nullseries[nullseries > 0]\n    print(onlynull)\n    sns.barplot(x=onlynull.index , y=onlynull*100\/len(data))\n    plt.ylabel(\"PERCENTAGE NULL DATA\")\n    plt.xlabel(\"COLUMN NAME\")\n    plt.xticks(rotation=90)\n    plt.figure(figsize=(20,6))","2c63eaa9":"findnull(alltrain)","96fff2a1":"alltrain.columns","e894591a":"def impute_weather(df):\n    columns = ['air_temperature', 'cloud_coverage', 'dew_temperature','precip_depth_1_hr',\n'sea_level_pressure', 'wind_direction','wind_speed'] \n    for col in columns:\n    \n        imputaion = df.groupby(['site_id','part_of_day','month'])[col].transform('mean')\n        df[col].fillna(imputaion,inplace = True)","fe16dc40":"impute_weather(alltrain)","65a24dd4":"findnull(alltrain)","72b892a1":"alltrain.floor_count.fillna(0,inplace = True)  ","e5c1a007":"alltrain[alltrain.meter_reading==0].groupby(\"site_id\").size().sort_values()[-5:]","c1d3ea6d":"sites =[0,13,14,2,9]\nfor s in sites:\n    site = alltrain[alltrain.site_id==s].groupby([\"date\",\"meter\"]).meter_reading_log.mean().reset_index()\n    fig = px.line(site, x=\"date\", y=\"meter_reading_log\",color='meter',title='Site{}'.format(s))\n    fig.show()","7968f6d2":"alltrain.groupby([\"site_id\",\"building_id\"]).meter_reading.sum().sort_values()[:-6:-1]","d49fc2ea":"import plotly.express as px \nfig = px.histogram(np.log1p(alltrain[alltrain['site_id']==13].meter_reading),nbins =10, width=800, height=400)\nfig.show()","3d329d57":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfig = make_subplots(rows=4, cols=1,subplot_titles=(\"Plot electricity\", \"Plot chilled water\", \"Plot steam\", \"Plot hot water\"))\nmax_cons1 = alltrain[(alltrain['building_id']==1099) & (alltrain.meter == \"electricity\")]\nmax_cons2 = alltrain[(alltrain['building_id']==1099) & (alltrain.meter == \"chilledwater\")]\nmax_cons3 = alltrain[(alltrain['building_id']==1099) & (alltrain.meter == \"steam\")]\nmax_cons4 = alltrain[(alltrain['building_id']==1099) & (alltrain.meter == \"hotwater\")]\nfig.add_trace(\n    go.Scatter(x=max_cons1.date,y=max_cons1.meter_reading),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(x=max_cons2.date,y=max_cons2.meter_reading),\n    row=2, col=1\n)\nfig.add_trace(\n    go.Scatter(x=max_cons3.date,y=max_cons3.meter_reading),\n    row=3, col=1\n)\nfig.add_trace(\n    go.Scatter(x=max_cons4.date,y=max_cons4.meter_reading),\n    row=4, col=1\n)\nfig.update_layout(height=600, width=800, title_text=\"Side By Side Subplots\")\nfig.show()","ad38bc81":"All electricity meter is 0 until May 20 for site_id == 0. I will remove these data from training data.","6d2cb4d8":"9% of the reading value is zero.We have the information that some buildings have more than one meter type and we can consider as usage of seasonal energy meters may cause zeros.To be more spesific,we don't need to use chilled water at cold days.Likewise,hotwater usage can be change time to time.However,those data can be missing because no energy consumption doesn't make sense at all !","a3c26c76":"##  <a id='2-1'>2.1. Analysis of train dataset<\/a>","0427091a":"\nThe evaluation metric for this competition is Root Mean Squared Logarithmic Error.\n![rmsle.png](attachment:rmsle.png)","c6b5bae1":"As seen in graphs zero readings change from time to time and meter type. Electricity meter zeros have seen the first 5 months of the year. With the beginning of the sixth month, zero readings scale down. Chilled water and hot water zeros have seasonal changes. Steam and hot water zeros distribution look very similar.","2144f6dd":"# <a id='1'>1. Introduction<\/a>","82069ad0":"We have strong correlation between air_temp and dew_temp.","b6e2e57d":"In this competition, we are tasked with developing accurate predictions of metered building energy usage in the following areas: chilled water, electric, hot water, and steam meters. The data comes from over 1,000 buildings over a three-year timeframe.\n\nThe aim is that with better estimates of these energy-saving investments, large scale investors and financial institutions will be more inclined to invest in this area to enable progress in building efficiencies.","616d205e":"## <a id='1-1'>1.1 Data<\/a>","280aecd9":"Seems like we have outliers.Lets check with a box plot for each site.Also values range quite different from each other. Before ploting scale them to get clear results. ","b72c3271":"![Ashrae.jpg](attachment:Ashrae.jpg)\n\n# ASHRAE - Great Energy Predictor III\n\n  **How much energy will a building consume?**\n\n- <a href='#1'>1. Introduction<\/a>\n    - <a href='#1-1'>1.1. Data<\/a>\n    - <a href='#1-2'>1.2. Evaluation Metric<\/a>\n      \n- <a href='#2'>2. Exploratory Data Analysis<\/a>\n   - <a href='#2-1'>2.1. Analysis of train dataset<\/a>\n   - <a href='#2-2'>2.2. Analysis of weather dataset<\/a>\n   - <a href='#2-3'>2.3. Analysis of building dataset<\/a>\n   - <a href='#2-4'>2.4. More exploration<\/a>\n       - <a href='#2-4.1'>2.4.1 Expand Timestamp<\/a>\n       - <a href='#2-4.2'>2.4.2 Exploration with time<\/a>\n    \n- <a href='#3'>3. Missing Data<\/a>\n- <a href='#4'>4. Outliers<\/a>\n- <a href='#5'>5. Models<\/a>\n\n","2e00e66a":"##  <a id='2-3'>2.3. Analysis of building dataset<\/a>","f2cddece":"##  <a id='2-4'>2.4. More exploration<\/a>","c74f41f0":"##  <a id='2-4.1'>2.4.1 Expand Timestamp<\/a>","5352f407":"- We are trying to predict energy consuption for 1449 buildings. The value we are trying to predict is the `meter_reading`\n- Each building can have multiple meters - The meter id code. Read as `{0: electricity, 1: chilledwater, 2: steam, 3: hotwater}`. Not every building has all meter types.\n- We are given:\n    1. Historic meter reading data by timestamp for the building (`train.csv`)\n    2. Building metadata including the building use, square ft area, year build(`building_meta.csv`). This data does not change between the training and test set.\n    3. Weather data with predicpitation, cloud_coverage, `air_temperature` and more (`weather_[train\/test].csv`)\n- We are also provied csvs to be used for submission:\n    1. `test.csv` which contains the meter, building id and timestamp we will be predicting for\n    2. `sample_submission.csv` which contains all the future data we would like to predict\n","956970c6":"Go [Ashrae2](https:\/\/www.kaggle.com\/zeynepkurban\/ashrae-2) for model.","5553d7bb":"Graphs shows distribution meter_reading in each meter category","1aebab01":"##  <a id='2-2'>2.2. Analysis of weather dataset<\/a>","4e0b99e1":"floor_count and year_built have lots of missing values.We can take primary_use as categorical value. \n","94abc6ed":"##  <a id='2-4.2'>2.4.2 Exploration with time<\/a>","3d899294":"# <a id='2'>2. Exploratory Data Analysis<\/a>","6a0552c1":"# <a id='3'>3. Missing Data<\/a>","2ab678e9":"# <a id='4'>4. Outliers<\/a>","142a1384":"\n## <a id='1-2'>1.2 Evaluation Metric<\/a>","3464316d":"Meter reading variable is heavily right skewed and there are lots of zeros in meter reading.Applying logarithmic transformation turns to skewed distribution into a more normalized dataset.Besides zeros reading we also have outliers !","bba2d4fe":"8 features are numeric ,only timestamp not numeric we will convert to datetime for more exploration.\ncloud_coverage, precip_depth_1_hr, sea_level_pressure and wind_direction have missing values.\n","3c5531f3":"Apart from outliers we dont have any data or less data for cloud_coverage,precip_depth,sea_level_pressure at some sites.Precip_depth have significantly outliers.","27f7aacb":"# <a id='5'>5. Models<\/a>"}}