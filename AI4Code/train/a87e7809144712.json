{"cell_type":{"e8280554":"code","67882bd3":"code","32fc7809":"code","2850a63b":"code","bb7f723f":"code","14f1f59e":"code","bad6e6b7":"code","b40055c6":"code","b1f7d0a9":"code","5744c632":"code","35c9791c":"code","8f7bae24":"code","77776436":"code","6a0d26ed":"code","6ec16758":"code","0d17c085":"code","c4767a0e":"code","04fc7b6f":"code","5f5b0765":"code","9a7e1b63":"code","827432be":"code","6e44e1cf":"code","23bcdb27":"code","945d9f5e":"code","9f9f5a0b":"code","9efb0b55":"code","94a0eaa3":"code","a162452a":"code","cf73bcbc":"markdown","e72d339e":"markdown","2623e0e9":"markdown","7b718998":"markdown","bb5a117f":"markdown","29709f13":"markdown","c50947aa":"markdown","2922cb24":"markdown","030f0496":"markdown","5c24c1b6":"markdown","fc335a70":"markdown","49115907":"markdown","541ca06b":"markdown","cda63fef":"markdown","78facc14":"markdown","836ff0b6":"markdown","4708ae0b":"markdown","f0f5ce70":"markdown","a386864b":"markdown","8afbd70d":"markdown","a239ed0d":"markdown","1216034b":"markdown","7116c9f0":"markdown","c26b1afe":"markdown","525be9ae":"markdown","e29914c4":"markdown","298d1ed2":"markdown","f9377690":"markdown","c386f5b8":"markdown","cc7e05b3":"markdown","126ca24c":"markdown","311c087d":"markdown","60321c79":"markdown","e355b148":"markdown","bdf4893d":"markdown","87c1213a":"markdown","bd18c887":"markdown","523a2d4c":"markdown","e6ed88dd":"markdown","ee014563":"markdown","567018c0":"markdown","b7b4e287":"markdown","e0fb8d56":"markdown","042eab91":"markdown","dd3a3baa":"markdown"},"source":{"e8280554":"#Importing necessary libraries\nfrom __future__ import division\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport math\n\n#turn of data table rendering\npd.set_option('display.notebook_repr_html', False)\nsns.set_palette(['#00A99D','#B61298','#76620C','#095C57'])\nnp.version.full_version\n","67882bd3":"# loading and reading data\ndata=\"..\/input\/fuel-consumption\/test_fuel.csv\"\ndf= pd.read_csv(data,names=['fuel'])\ndf.head()","32fc7809":"plt.hist(df[\"fuel\"])","2850a63b":" # Get the mean of each column\nx_bar=df[\"fuel\"].mean()\nx_bar         ","bb7f723f":"# Get the median of each column\nx_median=df[\"fuel\"].median()          \nx_median","14f1f59e":"sns.distplot(df.fuel)\n\n# Plot black line at mean\nplt.vlines(df.mean(),    \n           ymin=0, \n           ymax=0.3,\n           linewidth=5.0);\n# Plot red line at median\nplt.vlines(df.median(),   \n           ymin=0, \n           ymax=0.3, \n           linewidth=2.0,\n           color=\"red\");","bad6e6b7":"# Get the mode of each column\nx_mode= df[\"fuel\"].mode()         \nx_mode","b40055c6":"max(df[\"fuel\"]) - min(df[\"fuel\"])","b1f7d0a9":"five_num = [df[\"fuel\"].quantile(0),   \n            df[\"fuel\"].quantile(0.25),\n            df[\"fuel\"].quantile(0.50),\n            df[\"fuel\"].quantile(0.75),\n            df[\"fuel\"].quantile(1)]\n\nfive_num","5744c632":"df[\"fuel\"].describe()","35c9791c":"df[\"fuel\"].quantile(0.75) - df[\"fuel\"].quantile(0.25)","8f7bae24":"df.boxplot(column=\"fuel\",\n               return_type='axes',\n               figsize=(8,8))\n\nplt.text(x=0.74, y=7.34, s=\"3rd Quartile\")\nplt.text(x=0.8, y=6.3, s=\"Median\")\nplt.text(x=0.75, y=5.1, s=\"1st Quartile\")\nplt.text(x=0.9, y=0, s=\"Min\")\nplt.text(x=0.9, y=12, s=\"Max\")\nplt.text(x=0.68, y=6.3, s=\"IQR\", rotation=90, size=25);","77776436":"df[\"fuel\"].var()","6a0d26ed":"df[\"fuel\"].std()","6ec16758":"abs_median_devs = abs(df[\"fuel\"] - df[\"fuel\"].median())\n\nabs_median_devs.median() * 1.4826","0d17c085":"# Check skewness\ndf[\"fuel\"].skew()  ","c4767a0e":"# Check kurtosis\ndf[\"fuel\"].kurt()  ","04fc7b6f":"from statsmodels.graphics.gofplots import qqplot\nqqplot(df[\"fuel\"], line='s');","5f5b0765":"stat, p = stats.shapiro(df)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","9a7e1b63":"stat, p = stats.normaltest(df[\"fuel\"])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","827432be":"result = stats.anderson(df[\"fuel\"])\nprint('Statistic: %.3f' % result.statistic)\np = 0\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic < result.critical_values[i]:\n        print('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n    else:\n        print('%.3f: %.3f, data does not look normal (reject H0)' % (sl, cv))","6e44e1cf":"# Get the z-critical value*\nz_critical = stats.norm.ppf(q = 0.975)  \n# Check the z-critical value\nprint(\"z-critical value:\")             \nprint(z_critical)                        \n# Get the population standard deviation\npop_stdev = df.fuel.std()  \nn=len(df)\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(n))\n\nconfidence_interval = (x_bar - margin_of_error,\n                       x_bar + margin_of_error)  \n\nprint(\"Confidence interval:\")\nprint(confidence_interval)","23bcdb27":"#loading data\ndb=\"..\/input\/factors\/data.xlsx\"\ndata=pd.read_excel(db)\n#display the first 5 rows\ndata.head()\n","945d9f5e":"columns=['Max_Speed','Mileage','rapport']\nlabel= data['Fuel'].values\nvariables= data[list(columns)].values","9f9f5a0b":"plt.figure(figsize = (15,10))\nsns.jointplot(data.Max_Speed,data.Fuel,kind=\"regg\")\nplt.show()","9efb0b55":"plt.figure(figsize = (15,10))\nsns.jointplot(data.Mileage,data.Fuel,kind=\"regg\")\nplt.show()","94a0eaa3":"plt.figure(figsize = (15,10))\nsns.jointplot(data.rapport,data.Fuel,kind=\"regg\")\nplt.show()","a162452a":"f,ax=plt.subplots(figsize = (18,18))\nsns.heatmap(data.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title('Correlation Map')\nplt.savefig('graph.png')\nplt.show()","cf73bcbc":"In the plot above the mean and median are both so close to zero that the red median line lies on top of the thicker black line drawn at the mean.\n\nIn skewed distributions, the mean tends to get pulled in the direction of the skew, while the median tends to resist the effects of skew","e72d339e":"![mean-median-mode.png](attachment:mean-median-mode.png)","2623e0e9":"Interquartile (IQR) range is another common measure of spread. IQR is the distance between the 3rd quartile and the 1st quartile:","7b718998":"The data is likely drawn from a Gaussian distribution.","bb5a117f":"Let's calculate a 95% confidence for our mean point estimate:","29709f13":"The boxplots are visual representations of the five number summary and IQR:","c50947aa":"### Note:\nAlthough the mean and median both give us some sense of the center of a distribution, they aren't always the same. The median always gives us a value that splits the data into two halves while the mean is a numeric average so extreme values can have a significant impact on the mean. In a symmetric distribution, the mean and median will be the same. Let's investigate with a density plot:","2922cb24":"The mean is simply an average: the sum of the values divided by the total number of records. We can use df.mean() to get the mean of each column in a data frame:\n","030f0496":"### Note: More details and interpretations are specified in our report.","5c24c1b6":"### The D\u2019Agostino\u2019s K^2\nThe D\u2019Agostino\u2019s K^2 test calculates summary statistics from the data, namely kurtosis and skewness, to determine if the data distribution departs from the normal distribution.\n\nSkew is a quantification of how much a distribution is pushed left or right, a measure of asymmetry in the distribution. Kurtosis quantifies how much of the distribution is in the tail. It is a simple and commonly used statistical test for normality.","fc335a70":"![IC.jpg](attachment:IC.jpg)","49115907":"We can say that two variables are related with each other, if one of them gives information about others\nFor example, price and distance. If you go long distance with taxi you will pay more. There fore we can say that price and distance are positively related with each other.\n- Scatter Plot\nSimplest way to check relationship between two variables\nLets look at relationship between radius mean and area mean\nIn scatter plot you can see that when radius mean increases, area mean also increases. Therefore, they are positively correlated with each other.\nThere is no correlation between area mean and fractal dimension se. Because when area mean changes, fractal dimension se is not affected by chance of area mean","541ca06b":"## Hypothesis Testing\nPoint estimates and confidence intervals are basic inference tools that act as the foundation for another inference technique: statistical hypothesis testing. Statistical hypothesis testing is a framework for determining whether observed data deviates from what is expected. Python's scipy.stats library contains an array of functions that make it easy to carry out hypothesis tests.\n\n### Hypothesis Testing Basics\nStatistical hypothesis tests are based a statement called the null hypothesis that assumes nothing interesting is going on between whatever variables you are testing. The exact form of the null hypothesis varies from one type test to another: if you are testing whether groups differ, the null hypothesis states that the groups are the same. For instance, if you wanted to test whether the average age of voters in your home state differs from the national average, the null hypothesis would be that there is no difference between the average ages.\n\nThe purpose of a hypothesis test is to determine whether the null hypothesis is likely to be true given sample data. If there is little evidence against the null hypothesis given the data, you accept the null hypothesis. If the null hypothesis is unlikely given the data, you might reject the null in favor of the alternative hypothesis: that something interesting is going on. The exact form of the alternative hypothesis will depend on the specific test you are carrying out. Continuing with the example above, the alternative hypothesis would be that the average age of voters in your state does in fact differ from the national average.\n\nOnce you have the null and alternative hypothesis in hand, you choose a significance level (often denoted by the Greek letter \u03b1.). The significance level is a probability threshold that determines when you reject the null hypothesis. After carrying out a test, if the probability of getting a result as extreme as the one you observe due to chance is lower than the significance level, you reject the null hypothesis in favor of the alternative. This probability of seeing a result as extreme or more extreme than the one observed is known as the p-value.","cda63fef":"### Anderson-Darling Test\nAnderson-Darling Test (Theodore Anderson and Donald Darling) is a statistical test that can be used to evaluate whether a data sample comes from one of among many known data samples.\n\nIt can be used to check whether a data sample is normal. The test is a modified version of a more sophisticated nonparametric goodness-of-fit statistical test called the Kolmogorov-Smirnov test.\n\nA feature of the Anderson-Darling test is that it returns a list of critical values rather than a single p-value. This can provide the basis for a more thorough interpretation of the result.\n\nThe anderson() SciPy function implements the Anderson-Darling test. It takes as parameters the data sample and the name of the distribution to test it against. By default, the test will check against the Gaussian distribution (dist=\u2019norm\u2019).\n\nWe can interpret the results by failing to reject the null hypothesis that the data is normal if the calculated test statistic is less than the critical value at a chosen significance level.","78facc14":"Since the median tends to resist the effects of skewness and outliers, it is known a \"robust\" statistic. The median generally gives a better sense of the typical value in a distribution with significant skew or outliers.\n\nThe mode of a variable is simply the value that appears most frequently. Unlike mean and median, you can take the mode of a categorical variable and it is possible to have multiple modes. Find the mode with df.mode():","836ff0b6":"## Measures of Spread\nMeasures of spread (dispersion) are statistics that describe how data varies. While measures of center give us an idea of the typical value, measures of spread give us a sense of how much the data tends to diverge from the typical value.\n\nOne of the simplest measures of spread is the range. Range is the distance between the maximum and minimum observations:","4708ae0b":" <center>\"Ask questions,the data will confess\"<\/center>","f0f5ce70":"Where \u03c3 (sigma) is the population standard deviation, n is sample size, and z is a number known as the z-critical value. The z-critical value is the number of standard deviations you'd have to go from the mean of the normal distribution to capture the proportion of the data associated with the desired confidence level. For instance, we know that roughly 95% of the data in a normal distribution lies within 2 standard deviations of the mean, so we could use 2 as the z-critical value for a 95% confidence interval (although it is more exact to get z-critical values with stats.norm.ppf().).\n\n","a386864b":"Running the example creates the QQ plot showing the scatter plot of points in a diagonal line, closely fitting the expected diagonal pattern for a sample from a Gaussian distribution","8afbd70d":"We used df.var() to check variance:","a239ed0d":"As noted earlier, the median represents the 50th percentile of a data set. A summary of several percentiles can be used to describe a variable's spread. We can extract the minimum value (0th percentile), first quartile (25th percentile), median, third quartile(75th percentile) and maximum value (100th percentile) using the quantile() function:","1216034b":"## Histogram\nHow many times each value appears in dataset. This description is called the distribution of variable\nMost common way to represent distribution of varible is histogram that is graph which shows frequency of each value.\nFrequency = number of times each value appears","7116c9f0":"## Descriptive Statistics\n\nDescriptive statistics are measures that summarize important features of data, often with a single number. Producing descriptive statistics is a common first step to take after cleaning and preparing a data set for analysis. \n","c26b1afe":"### The Shapiro-Wilk\nThe Shapiro-Wilk test evaluates a data sample and quantifies how likely it is that the data was drawn from a Gaussian distribution.\n\nIn practice, the Shapiro-Wilk test is believed to be a reliable test of normality, although there is some suggestion that the test may be suitable for smaller samples of data, e.g. thousands of observations or fewer.","525be9ae":"* A large positive value (near to 1.0) indicates a strong positive correlation, i.e., if the value of one of the variables increases, the value of the other variable increases as well.\n* A large negative value (near to -1.0) indicates a strong negative correlation, i.e., the value of one variable decreases with the other\u2019s increasing and vice-versa.\n* A value near to 0 (both positive or negative) indicates the absence of any correlation between the two variables, and hence those variables are independent of each other.\n","e29914c4":"For unimodal continuous distributions, a skewness value > 0 means that there is more weight in the right tail of the distribution and < 0 means that there is more weight in the left tail of the distribution.","298d1ed2":"The data is likely drawn from a Gaussian distribution.","f9377690":"The kernel focuses on Exploratory Data Anaysis using classical statistical techniques. I have used quantitative techniques as well as graphical techniques to perform various tests.","c386f5b8":"The median of a distribution is the value where 50% of the data lies below it and 50% lies above it. In essence, the median splits the data in half. The median is also known as the 50% percentile since 50% of the observations are found below it. We can get the median using the df.median() function:","cc7e05b3":"![Negative_and_positive_skew_diagrams_%28English%29.svg.png](attachment:Negative_and_positive_skew_diagrams_%28English%29.svg.png)","126ca24c":"Variance and standard deviation are two other common measures of spread. The variance of a distribution is the average of the squared deviations (differences) from the mean. ","311c087d":"### QQ plot\nIn a QQ plot, a perfect match for the normal distribution will be shown by a line of dots on a 45-degree angle from the bottom left of the plot to the top right. It can be used to check if a distribution is normal or not.","60321c79":"![Webp.net-resizeimage%20%283%29.jpg](attachment:Webp.net-resizeimage%20%283%29.jpg)","e355b148":"![variance%20and%20st.png](attachment:variance%20and%20st.png)","bdf4893d":"Since these values are so commonly used to describe data, they are known as the \"five number summary\". They are the same percentile values returned by df.describe():","87c1213a":"###  Measures of center\nMeasures of center are statistics that give us a sense of the \"middle\" of a numeric variable. In other words, centrality measures give you a sense of a typical value you'd expect to see. Common measures of center include the mean, median and mode.\n\n","bd18c887":"The standard deviation is the square root of the variance. Standard deviation can be more interpretable than variance, since the standard deviation is expressed in terms of the same units as the variable in question while variance is expressed in terms of units squared. we used df.std() to check the standard deviation:","523a2d4c":"![quantiles.png](attachment:quantiles.png)","e6ed88dd":"# <center>  Vehicle's fuel consumption-Statistical Analysis<\/center>\n\n","ee014563":"## Skewness and Kurtosis\nBeyond measures of center and spread, descriptive statistics include measures that give you a sense of the shape of a distribution. Skewness measures the skew or asymmetry of a distribution while kurtosis measures how much data is in the tails of a distribution v.s. the center. We won't go into the exact calculations behind skewness and kurtosis, but they are essentially just statistics that take the idea of variance a step further: while variance involves squaring deviations from the mean, skewness involves cubing deviations from the mean and kurtosis involves raising deviations from the mean to the 4th power.\n\nPandas has built in functions for checking skewness and kurtosis, df.skew() and df.kurt() respectively:","567018c0":"## Confidence Intervals\nA point estimate can give you a rough idea of a population parameter like the mean, but estimates are prone to error and taking multiple samples to get improved estimates may not be feasible. A confidence interval is a range of values above and below a point estimate that captures the true population parameter at some predetermined confidence level. For example, if you want to have a 95% chance of capturing the true population parameter with a point estimate and a corresponding confidence interval, you'd set your confidence level to 95%. Higher confidence levels result in a wider confidence intervals.\n\nCalculate a confidence interval by taking a point estimate and then adding and subtracting a margin of error to create a range. Margin of error is based on your desired confidence level, the spread of the data and the size of your sample. The way you calculate the margin of error depends on whether you know the standard deviation of the population or not.\nIf you know the standard deviation of the population, the margin of error is equal to:\n\n                                                        z*\u03c3\/\u221an\n \n","b7b4e287":"![data%20analysis.png](attachment:data%20analysis.png)","e0fb8d56":"## Relationship Between Variables\nWe can say that two variables are related with each other, if one of them gives information about others\nFor example, price and distance. If you go long distance with taxi you will pay more. There fore we can say that price and distance are positively related with each other.\nScatter Plot\nSimplest way to check relationship between two variables\nLets look at relationship between radius mean and area mean\nIn scatter plot you can see that when radius mean increases, area mean also increases. Therefore, they are positively correlated with each other.\nThere is no correlation between area mean and fractal dimension se. Because when area mean changes, fractal dimension se is not affected by chance of area mean","042eab91":"Since variance and standard deviation are both derived from the mean, they are susceptible to the influence of data skew and outliers. Median absolute deviation is an alternative measure of spread based on the median, which inherits the median's robustness against the influence of skew and outliers. It is the median of the absolute value of the deviations from the median:\n\n","dd3a3baa":"# Conformity to Normale distribution\n"}}