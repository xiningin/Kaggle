{"cell_type":{"713713cc":"code","e03defe2":"code","6bb8999a":"code","9f7c023f":"code","4f2ee34d":"code","d084ddcb":"code","8700947c":"code","614cf416":"code","48790356":"code","e8027497":"code","d275f7b7":"code","682eb9da":"code","91cc8708":"code","3c81f27a":"code","e60efd8d":"code","db247f36":"code","d362db6a":"code","71f6d2c6":"code","75cfe91a":"markdown","52291daa":"markdown","3162e266":"markdown","14338dcf":"markdown","6a643f19":"markdown","b73aa2cb":"markdown","72c338e6":"markdown","f13de455":"markdown"},"source":{"713713cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e03defe2":"\nimport pandas as pd\ndf_items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\ndf_items.head(5)","6bb8999a":"df_test= pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ndf_test.head(5)","9f7c023f":"df_train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndf_train.head(5)","4f2ee34d":"df_item_categories = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ndf_item_categories.head(5)","d084ddcb":"df = df_train\ndf = df.groupby(['date_block_num','shop_id','item_id']).agg(\n    {'item_price':'mean',\n     'item_cnt_day':'sum'}).reset_index()\ndf.head(5)","8700947c":"df_test['date_block_num']=34\nitem_price = dict(df.groupby('item_id')['item_price'].last().reset_index().values)\ndf_test['item_price'] = df_test['item_id'].map(item_price)\ndf_test['item_price'] = df_test['item_price'].fillna(df_test['item_price'].median())\ndf_test.head(5)","614cf416":"# df.head(5)\ndf =  df.sample(frac = 1)","48790356":"np.array(df.drop(['item_cnt_day'],1)) #.values","e8027497":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nx = np.array(df.drop(['item_cnt_day'],1))\ny = np.array(df.iloc[:,4])\nSC = MinMaxScaler()\nSC.fit(x)\nX = SC.transform(x)\nxtrain, xtest, ytrain, ytest = train_test_split(X,y,\n                                               test_size = 0.25, random_state = 33)\nprint(xtrain.shape, xtest.shape, ytrain.shape, ytest.shape)","d275f7b7":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\n\n","682eb9da":"def rmse(ytrain, train_pred, ytest, test_pred):\n    print('RMSE Train data', mean_squared_error(ytrain, train_pred))\n    print('RMSE Test data', mean_squared_error(ytest, test_pred))","91cc8708":"X_submission = SC.fit_transform(df_test.values)","3c81f27a":"# rf = RandomForestRegressor()\n# rf.fit(xtrain, ytrain)\n# rf_tr_pred = rf.predict(xtrain)\n# rf_te_pred = rf.predict(xtest)\n\n# rmse(ytrain,rf_tr_pred, ytest,rf_te_pred)\n","e60efd8d":"kn = KNeighborsRegressor()\nkn.fit(xtrain, ytrain)\nkn_tr_pred = kn.predict(xtrain)\nkn_te_pred = kn.predict(xtest)\n# kn.predict(X_submission)\nrmse(ytrain,kn_tr_pred, ytest,kn_te_pred)","db247f36":"lr = LinearRegression()\nlr.fit(xtrain, ytrain)\nlr_tr_pred = lr.predict(xtrain)\nlr_te_pred = lr.predict(xtest)\n# lr.predict(X_submission)\nrmse(ytrain,lr_tr_pred, ytest,lr_te_pred)","d362db6a":"# from sklearn.preprocessing import PolynomialFeatures  \n# poly_regs= PolynomialFeatures(degree= 4)  \n# x_poly= poly_regs.fit_transform(X)  \n# # kn.fit(x_poly, y)\n# clf = LinearRegression()\n# clf.fit(x_poly, y)\n# poly_pred = clf.predict()  \n# print(poly_pred) ","71f6d2c6":"df1 = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\ndf2 = pd.DataFrame()\nN = kn_te_pred.shape[0]\ndf2['ID'] = df1['ID'].loc(axis=0)[:N]\ndf2['item_cnt_month'] = kn_te_pred[214200]\n# df2['item_cnt_month'] = df2.item_cnt_month.abs().iloc[214200:]\ndf2.to_csv('.\/result.csv', index= False)","75cfe91a":"*LinearRegression*","52291daa":"# Hey Kagglers, Please upvote my notebook if you found it useful. It will help me be motivated and create many more simple notebooks in Kaggle competitions.","3162e266":"## Peak into the dataset files ","14338dcf":"*RandomForestRegressor*","6a643f19":"## RMSE root mean squared error\n\nRMSE is a standard way to measure the error of a model in predicting quantitative data.","b73aa2cb":"*KNeighborsRegressor*","72c338e6":"# Model training","f13de455":"## Feature engineering"}}