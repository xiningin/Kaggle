{"cell_type":{"a0a1cd6e":"code","b8c11eb0":"code","0750d972":"code","5b843042":"code","e17da9d5":"code","60d5bc8a":"code","9d9574bf":"code","c1f49721":"code","d24d99f7":"code","6be1cd7c":"code","bf307a6f":"code","16413d41":"code","2e39664d":"code","abc8facf":"code","ad4f2cbe":"code","f97182d2":"code","ef525f11":"code","b15b8504":"code","868bc552":"code","a7def44b":"code","44ef27b7":"code","973fecb4":"code","fd2453ea":"code","a37e7e70":"code","d3baf28c":"code","8dc06cf6":"code","ed712abb":"code","86f8d1b7":"code","ae712974":"code","c152e74f":"code","c4d1b2ea":"code","7d74c964":"code","3c067a7b":"code","4b088e1b":"code","c5673d69":"code","cdfc8829":"code","52ca1bd5":"code","863430c1":"code","2ae8a555":"code","5b718aaf":"code","a144acb6":"markdown"},"source":{"a0a1cd6e":"# initiating gpu using tensorflow.\nimport tensorflow as tf\nfrom keras.backend.tensorflow_backend import set_session\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsess = tf.Session(config=config)\nset_session(sess)","b8c11eb0":"#importing libraries for the data processing and model.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport random\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import misc\nfrom keras.models import load_model\n%matplotlib inline","0750d972":"# defining the path and classes.\ndirectory = '..\/input\/state-farm-distracted-driver-detection\/train'\ntest_directory = '..\/input\/state-farm-distracted-driver-detection\/test\/'\nrandom_test = '..\/input\/driver\/'\nclasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']","5b843042":"# defining a shape to be used for our models.\nimg_size1 = 240\nimg_size2 = 240","e17da9d5":"# Train class image for display.\nfor i in classes:\n    path = os.path.join(directory,i)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n        plt.imshow(img_array, cmap='gray')\n        plt.show()\n        break\n    break","60d5bc8a":"# Test class image for display.\ntest_array = []\nfor img in os.listdir(test_directory):\n    img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n    test_array = img_array\n    plt.imshow(img_array, cmap='gray')\n    plt.show()\n    break","9d9574bf":"r_img_array = cv2.imread(os.path.join(random_test,'dd.jpg'),cv2.IMREAD_GRAYSCALE)\nnew_img = cv2.resize(r_img_array,(img_size2,img_size1))\nplt.imshow(r_img_array, cmap='gray')\nplt.show()","c1f49721":"# checkking image size using shape.\nprint(img_array.shape)","d24d99f7":"# trying out the resize image functionality\nnew_img = cv2.resize(test_array,(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","6be1cd7c":"# creating a training dataset.\ntraining_data = []\ni = 0\ndef create_training_data():\n    for category in classes:\n        path = os.path.join(directory,category)\n        class_num = classes.index(category)\n        \n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_img = cv2.resize(img_array,(img_size2,img_size1))\n            training_data.append([\n                new_img,class_num])","bf307a6f":"# Creating a test dataset.\ntesting_data = []\ni = 0\ndef create_testing_data():        \n    for img in os.listdir(test_directory):\n        img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n        new_img = cv2.resize(img_array,(img_size2,img_size1))\n        testing_data.append([img,\n            new_img])","16413d41":"create_training_data()","2e39664d":"create_testing_data()","abc8facf":"print(len(training_data))\nprint(len(testing_data))","ad4f2cbe":"random.shuffle(training_data)","f97182d2":"x = []\ny = []","ef525f11":"for features, label in training_data:\n    x.append(features)\n    y.append(label)","b15b8504":"x[0].shape","868bc552":"len(x)","a7def44b":"#X  = np.array(x[1]).reshape(-1,img_size2,img_size1,1)\n#i = 1\n#for i in range(len(x)):\nX = np.array(x).reshape(-1,img_size2,img_size1,1)\n#    X = np.append(X,Y,axis = 0)\nX[0].shape","44ef27b7":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=50)","973fecb4":"Y_train = np_utils.to_categorical(y_train,num_classes=10)\nY_test = np_utils.to_categorical(y_test,num_classes=10)","fd2453ea":"model = Sequential()","a37e7e70":"model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(240,240,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.3))","d3baf28c":"model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.3))","8dc06cf6":"model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.5))","ed712abb":"model.add(Flatten())\nmodel.add(Dense(units = 512,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 128,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10,activation='softmax'))","86f8d1b7":"model.summary()","ae712974":"model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","c152e74f":"callbacks = [EarlyStopping(monitor='val_acc',patience=5)]","c4d1b2ea":"batch_size = 50\nn_epochs = 20","7d74c964":"results = model.fit(x_train,Y_train,batch_size=batch_size,epochs=n_epochs,verbose=1,validation_data=(x_test,Y_test),callbacks=callbacks)","3c067a7b":"# Plot training & validation accuracy values\nplt.plot(results.history['acc'])\nplt.plot(results.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","4b088e1b":"preds = model.predict(np.array(testing_data[0][1]).reshape(-1,img_size2,img_size1,1))","c5673d69":"model.save_weights('.\/driverdistraction_lr_weights.h5', overwrite=True)","cdfc8829":"model.save('.\/driverdistraction_lr_weights.h5')","52ca1bd5":"loaded_model = load_model('..\/input\/driver-distraction\/driverdistraction_lr_weights.h5')","863430c1":"test_data = np.array(testing_data[3000][1]).reshape(-1,img_size2,img_size1,1)","2ae8a555":"preds = loaded_model.predict(test_data)\npreds","5b718aaf":"print('Predicted: {}'.format(np.argmax(preds)))\nnew_img = cv2.resize(testing_data[3000][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","a144acb6":"\n    c0: safe driving\n    c1: texting - right\n    c2: talking on the phone - right\n    c3: texting - left\n    c4: talking on the phone - left\n    c5: operating the radio\n    c6: drinking\n    c7: reaching behind\n    c8: hair and makeup\n    c9: talking to passenger\n"}}