{"cell_type":{"dd1f3d7c":"code","de367312":"code","21b16226":"code","38494ad3":"code","55f4e7c4":"code","3b83feb2":"code","6397b3cb":"code","757e019f":"code","5500348a":"code","2d2b6401":"code","58c968c7":"code","99978bc7":"code","2d7dd0f4":"code","67638235":"code","3ddd3c8f":"code","c676dada":"code","d628bb2d":"code","0c1b3738":"code","a17f29ed":"markdown","47ce333f":"markdown","ed4cedf6":"markdown","d5428b19":"markdown","177f4e44":"markdown","2c731d5e":"markdown","55b75140":"markdown","e08202ca":"markdown","44e64d68":"markdown"},"source":{"dd1f3d7c":"import PIL.Image\nfrom IPython.display import Image\nImage('\/kaggle\/input\/private-dataset\/img.jpg',width=500, height=300)","de367312":"import numpy as np\nimport pandas as pd\nimport string\nimport re\nimport nltk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","21b16226":"file = open('\/kaggle\/input\/private-dataset\/hp1.txt')\ntext = file.read()\nre.findall('Page\\s.\\s\\d*\\s.*Rowling',text)[:2]","38494ad3":"# removing page number pattern (Page | 2 Harry Potter and the Philosophers Stone - J.K. Rowling)\ntext = re.sub('Page\\s.\\s\\d*\\s.*Rowling','',text)\ntext = re.sub('\\n','',text)","55f4e7c4":"# using regex tokenizer\nfrom nltk.tokenize import RegexpTokenizer\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\ntext = \"\".join([word for word in text if word not in string.punctuation])\ntokenizer=RegexpTokenizer(\"['\\w]+\")\ntokens = tokenizer.tokenize(text)\nwords = [word.lower() for word in tokens if word.lower() not in stop_words]","3b83feb2":"#Printing vocabulary size\nvocabulary = set(words)\nprint('The vocabulary size is: ',len(vocabulary))","6397b3cb":"# The number of words that has been deleted after removing stop words + percentage\nprint('The number of words that have been removed is {} which is {:.2f}% of total words'.format\n      (len(tokens)-len(words),len(words)\/len(tokens)*100))","757e019f":"from nltk.util import ngrams\nfrom collections import Counter\nfrom wordcloud import WordCloud,ImageColorGenerator\n\nunigrams = list(ngrams(words, 1))\nfreq = Counter(unigrams)\ntopN= freq.most_common(100)\n\nwordscount = {w[0]:f for w, f in topN}   \nwordcloud = WordCloud(max_font_size=40,background_color=\"white\")\nwordcloud.fit_words(wordscount)\nplt.figure(figsize=(7,7))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","5500348a":"Image('\/kaggle\/input\/private-dataset\/image.jpg',width=400, height=300)","2d2b6401":"# Generate a word cloud image\nmask = np.array(PIL.Image.open(\"\/kaggle\/input\/private-dataset\/image.jpg\"))\nwordcloud = WordCloud(background_color=\"white\", max_words=400, mask=mask).generate(text)\n\n# create coloring from image\nimage_colors = ImageColorGenerator(mask)\nplt.figure(figsize=[10,10])\nplt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","58c968c7":"count = Counter(words)\ndf = pd.DataFrame(count.most_common(10),columns=['Words','Frequency'])","99978bc7":"import plotly.express as px\nfig = px.bar(x=df['Words'],y=df['Frequency'])\nfig.update_layout( title={\n        'text': \"Top 10 most frequent word\",\n        'y':0.95,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n    xaxis_title=\"Words\",\n    yaxis_title=\"Frequency\")\n\nfig.show(renderer='kaggle')","2d7dd0f4":"nltk.pos_tag(tokens[:10])","67638235":"tagged_words= nltk.pos_tag(tokens)\n#print (\"Tagged Words: \", tagged_words)","3ddd3c8f":"chunkGram='''CHUNK1: {<DT><NNS>}\n            CHUNK2: {<CD><JJ><NN>}\n            CHUNK3: {<CD><JJ><JJ><NN>}'''\n#Creat chunk parser\nfind = nltk.RegexpParser(chunkGram)\n#Test chunk parser on our example\nchunkTree=find.parse(tagged_words)\n\n\nprint(\"Extracting three different chunks\")\nfor subtree in chunkTree.subtrees():\n    if subtree.label() == 'CHUNK1':\n        finalChunk=\"\"\n        for (w,tag) in subtree.leaves():\n            finalChunk=finalChunk + \" \" + w\n        \n    elif subtree.label() == 'CHUNK2':\n        finalChunk2=\"\"\n        for (w,tag) in subtree.leaves():\n            finalChunk2=finalChunk2 + \" \" + w\n    elif subtree.label() == 'CHUNK3':\n        finalChunk3=\"\"\n        for (w,tag) in subtree.leaves():\n            finalChunk3=finalChunk3 + \" \" + w\nprint (finalChunk+\"\\n\"+finalChunk2+\"\\n\"+finalChunk3)","c676dada":"bigrams = ngrams(tokens,2)\n\n# using Counter function to count the most common bigrams from words (vocabulary after removing stop words)\nfreq_bigrams=Counter(bigrams)\nprint (\"Top 5 most common bigrams from tokens:\\n\", freq_bigrams.most_common(5))","d628bb2d":"from nltk.metrics import TrigramAssocMeasures\n\ntrigrams= nltk.TrigramCollocationFinder.from_words(tokens)\nprint (\"Top tri-grams\")\ntrigrams.nbest(TrigramAssocMeasures.raw_freq, 5)","0c1b3738":"from gensim.summarization import keywords\nprint ('Keywords:')\n#Get 0.01 key words\nkeyWords=keywords(text, ratio=0.01, lemmatize=True)\nprint (keyWords)","a17f29ed":"## Harry Potter and the Philosopher's Stone NLP analysis","47ce333f":"## WordCloud of Harry Potter and the Philosopher's Stone","ed4cedf6":"## Generate a word cloud based on an image","d5428b19":"## Text cleaning and removing stop words","177f4e44":"## POS tagging","2c731d5e":"## Generating tri-grams","55b75140":"## Design a chunker using chunk grammar","e08202ca":"## Generating bi-grams from tokens","44e64d68":"## Finding the keywords"}}