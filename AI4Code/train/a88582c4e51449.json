{"cell_type":{"534b6e93":"code","be0c0466":"code","674a3fcb":"code","98ded404":"code","3efc3646":"code","14bf477f":"code","72fd094e":"code","3055b483":"code","d0cdb515":"code","eff5c7fa":"code","b68784be":"code","5a773401":"code","5e09ec49":"code","a586e167":"code","b058195e":"code","6abffe7e":"code","e0821057":"code","f9c3636c":"code","c4ad87cf":"code","3c46790d":"code","062bcd0f":"markdown","214dd81a":"markdown","4eb3f6c3":"markdown","bbc0b20f":"markdown","c2a585f2":"markdown"},"source":{"534b6e93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be0c0466":"data = pd.read_csv(\"\/kaggle\/input\/international-airline-passengers\/international-airline-passengers.csv\",skipfooter = 5)\ndata.head()","674a3fcb":"dataset = data.iloc[:,1].values \nplt.plot(dataset)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Passengers\")\nplt.title(\"International Airline Passengers\")\nplt.show()","98ded404":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","3efc3646":"type(dataset[0])","14bf477f":"scaler = MinMaxScaler(feature_range = (0,1))\ndataset = scaler.fit_transform(dataset)","72fd094e":"train_size = int(len(dataset) * 0.5)\ntest_size = int(len(dataset) - train_size)\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(f\"Train Size: {len(train)}, test_size: {len(test)}\")","3055b483":"time_stemp = 10\ndatax = []\ndatay = []\nfor i in range(len(train) - time_stemp - 1):\n    a = train[i: (i + time_stemp),0]\n    datax.append(a)\n    datay.append(train[i + time_stemp,0])\ntrainx = np.array(datax)\ntrainy = np.array(datay)","d0cdb515":"time_stemp = 10\ndatax = []\ndatay = []\nfor i in range(len(test) - time_stemp - 1):\n    a = train[i: (i + time_stemp),0]\n    datax.append(a)\n    datay.append(test[i + time_stemp,0])\ntestx = np.array(datax)\ntesty = np.array(datay)","eff5c7fa":"testx.shape","b68784be":"trainx = np.reshape(trainx,(trainx.shape[0],1,trainx.shape[1]))\ntestx = np.reshape(testx,(testx.shape[0],1,testx.shape[1]))","5a773401":"trainx.shape","5e09ec49":"trainy.shape","a586e167":"# Model\nmodel = Sequential()\nmodel.add(LSTM(10,input_shape = (1,time_stemp))) # 10 LSTM Nurom(Block)\nmodel.add(Dense(1))\nmodel.add(Dense(2))\nmodel.add(Dense(4))\nmodel.add(Dense(8))\nmodel.add(Dense(12))\nmodel.compile(loss = \"mean_squared_error\",optimizer = \"adam\")\nmodel.fit(trainx,trainy,epochs = 300,batch_size = 1)","b058195e":"trainpredict = model.predict(trainx)\ntestpredict = model.predict(testx)\n# Invert Predictions\ntrainpredict = scaler.inverse_transform(trainpredict)\ntrainy = scaler.inverse_transform([trainy])\ntestpredict = scaler.inverse_transform(testpredict)\ntesty = scaler.inverse_transform([testy])\n# Calculate Root Mean Squared Error\ntrainscore = math.sqrt(mean_squared_error(trainy[0],trainpredict[:,0]))\nprint(\"Train Score: %.2f RMSE\" % (trainscore))\n\ntestscore = math.sqrt(mean_squared_error(testy[0],testpredict[:,0]))\nprint(\"Test Score: %.2f RMSE\" % (testscore))","6abffe7e":"trainplot = np.empty_like(dataset)\ntrainplot[:, :] = np.nan\ntrainplot[time_stemp: len(trainpredict) + time_stemp, :] = trainpredict\n# Shifting test predictions for plotting\ntestpredplot = np.empty_like(dataset)\ntestpredplot[:, :] = np.nan\ntestpredplot[len(trainpredict) + (time_stemp * 2) + 1:len(dataset) - 1,: ] = testpredict\n# Plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainplot)\nplt.plot(testpredplot)\nplt.show()","e0821057":"trainx = np.reshape(trainx,(trainx.shape[0],trainx.shape[2],1))\ntrainy = trainy.T\n#testx = np.reshape(testx,(testx.shape[0],1,testx.shape[1]))","f9c3636c":"from keras.layers import SimpleRNN\nfrom keras.layers import Dropout # Overfitting'i engeller\n\n# Initializing the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularization\nregressor.add(SimpleRNN(units = 50,activation = \"tanh\",return_sequences=True,input_shape = (trainx.shape[1],1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularization\nregressor.add(SimpleRNN(units = 50,activation = \"tanh\",return_sequences= True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularization\nregressor.add(SimpleRNN(units = 50,activation = \"tanh\",return_sequences= True))\nregressor.add(Dropout(0.2))\n\n# Adding a forth RNN layer and some Dropout regularization\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units= 1))\n\n\n# Compiling the KNN\nregressor.compile(optimizer = \"adam\",loss = \"mean_squared_error\")\n\n# Fitting the RNN to the Training set\nregressor.fit(trainx,trainy,epochs = 300,batch_size = 1)","c4ad87cf":"trainx.shape","3c46790d":"trainy.shape","062bcd0f":"# LETS TRY TO USE RNN ","214dd81a":"# Preprocesssing Data\n* Reshape\n* Change Type\n* Scaling\n* Train Test Split\n* Crate Dataset","4eb3f6c3":"# Create LSTM Model","bbc0b20f":"### Seasonal Data","c2a585f2":"# Prediction and Visualization"}}