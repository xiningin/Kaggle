{"cell_type":{"878b6646":"code","aa01bd1e":"code","4cb9e12d":"code","e8067cfa":"code","b6bc9271":"code","4f5f838f":"code","c0ec4a5c":"code","cb6ec17d":"code","9c0ef1a5":"code","6342b89c":"code","856e56a5":"code","864cfe69":"code","ce72f2a7":"code","4c206bdd":"code","3aa2f19e":"code","c4b1604a":"code","5140935c":"code","0b7b9cbe":"markdown","89429503":"markdown","68bc8b35":"markdown","60075529":"markdown"},"source":{"878b6646":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","aa01bd1e":"# Check if GPU is avialable\n\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","4cb9e12d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense , Dropout , Lambda, Flatten, Conv2D\nfrom tensorflow.python.keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras import backend as K\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n","e8067cfa":"train = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()","b6bc9271":"test= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()","4f5f838f":"X = train.iloc[:,1:].values.astype('float32') # all pixel values\ny = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","c0ec4a5c":"# apply one hot encoding for label\n\nfrom keras.utils.np_utils import to_categorical\ny = to_categorical(y)\nnum_classes = y.shape[1]\nnum_classes","cb6ec17d":"#Convert train datset to (num_images, img_rows, img_cols, colour channel) format \nX = X.reshape(X.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","9c0ef1a5":"# split initial to train and validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)","6342b89c":"#Fit the model using Data Augemnetation, will improve accuracy of the model\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\ndata_generator_with_aug = ImageDataGenerator(rotation_range=8,\n                                             width_shift_range = 0.08,\n                                             height_shift_range = 0.08)\n            \ndata_generator_no_aug = ImageDataGenerator()","856e56a5":"# apply data augementation to train and validation datasete\n\ntrain_generator = data_generator_with_aug.flow(X_train, y_train,batch_size=64)\n\nvalidation_generator = data_generator_no_aug.flow(X_val, y_val, batch_size=64)\n","864cfe69":"# Strides as an option to MaxPooling\n# Dropout to combat overfitting\n\ndigit_model = Sequential()\ndigit_model.add(Conv2D(24, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\ndigit_model.add(Dropout(0.5))\ndigit_model.add(Conv2D(24, kernel_size=(3, 3), strides=2, activation='relu'))\ndigit_model.add(Dropout(0.5))\ndigit_model.add(Conv2D(24, kernel_size=(3, 3), strides=2, activation='relu'))\ndigit_model.add(Dropout(0.5))\ndigit_model.add(Flatten())\ndigit_model.add(Dense(128, activation='relu'))\ndigit_model.add(Dense(num_classes, activation='softmax'))\nprint(\"input shape \",digit_model.input_shape)\nprint(\"output shape \",digit_model.output_shape)","ce72f2a7":"# Your code to compile the model in this cell\ndigit_model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","4c206bdd":"# Your code to fit the model here\nwith tf.device(\"\/device:GPU:0\"):\n    history = digit_model.fit_generator(\n        train_generator,\n        epochs=3,\n        validation_data=validation_generator,\n        validation_steps=1)","3aa2f19e":"import matplotlib.pylab as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","c4b1604a":"gen = ImageDataGenerator(rotation_range=8,\n                        width_shift_range = 0.08,\n                        height_shift_range = 0.08)\nbatches = gen.flow(X, y, batch_size=64)\nwith tf.device(\"\/device:GPU:0\"):\n    history_subm=digit_model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","5140935c":"predictions = digit_model.predict_classes(X_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"DigitRecognizer.csv\", index=False, header=True)","0b7b9cbe":"#### Fit Model\n\nRun the command fashion_model.fit. The arguments you will use are\n\nThe first two are arguments are the data used to fit the model, which are x and y respectively.\nbatch_size = 100\nepochs = 4\nvalidation_split = 0.2\nWhen you run this command, you can watch your model start improving. You will see validation accuracies after each epoch.","89429503":"Specify the Model\n\nCreate a Sequential model. \nAdd 3 Conv2D layers to fashion_model. Make each layer have 12 filters, a kernel_size of 3 and a relu activation. You will need to specify the input_shape for the first Conv2D layer. The input shape in this case is (img_rows, img_cols, 1).\nAdd a Flatten layer to model after the last Conv2D layer.\nAdd a Dense layer with 100 neurons to model after the Flatten layer.\nAdd your prediction layer to model. This is a Dense layer. We alrady have a variable called num_classes. Use this variable when specifying the number of nodes in this layer. The activation should be softmax (or you will have problems later).","68bc8b35":"#### Submission to Kaggle with full dataset","60075529":"#### Compile Model"}}