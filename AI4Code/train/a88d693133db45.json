{"cell_type":{"be3aba25":"code","78628c30":"code","976d7b36":"code","7c76309f":"code","f68a1560":"code","a3582ec1":"code","0e294ea1":"code","3cccb406":"code","1b736525":"code","ae559ddd":"code","8ce94149":"code","09660bd7":"code","f15ee850":"code","f18dc4df":"code","c284a54d":"code","3f33a764":"code","ba0e934a":"code","93251cee":"code","e9104334":"code","50e9ee5b":"code","c6c68f40":"code","5dd5426a":"code","f4d07910":"code","f4287edf":"code","543f43dc":"code","db64770e":"code","ecb043c1":"code","7ea57924":"code","31ee77f9":"code","2596e463":"code","d3c41bf0":"code","a4dc0904":"code","2d532930":"code","eaa9934d":"code","495a75bd":"code","ac693af8":"code","72f128e1":"code","d1d3dcbe":"code","0db8c31f":"code","cc4705c7":"code","f141f61d":"code","803e0897":"code","29b5720f":"code","58bb8743":"code","6edc040e":"code","ac1f23b6":"code","6c8c0340":"code","6eba39d7":"code","ca9cd101":"code","6edf40de":"code","b04081c2":"code","e21394de":"code","30ca947f":"code","0a6e3a42":"code","b416e875":"code","908f041d":"code","900f6949":"code","e8b77389":"code","ef672e6c":"code","554f744c":"markdown","4bada353":"markdown","6bb93300":"markdown","7a9915c2":"markdown","ea1aac21":"markdown","19658d57":"markdown","189784d3":"markdown","d148a1d1":"markdown","7bf47333":"markdown","b2254af2":"markdown","4d547aff":"markdown"},"source":{"be3aba25":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","78628c30":"Main_Sand_Path = Path(\"..\/input\/nasa-curiosity-images\/nasa_curiosity_images\/training_set\")","976d7b36":"JPG_Path = list(Main_Sand_Path.glob(r\"*\/*.jpg\"))","7c76309f":"JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],JPG_Path))","f68a1560":"JPG_Path_Series = pd.Series(JPG_Path,name=\"JPG\").astype(str)\nJPG_Labels_Series = pd.Series(JPG_Labels,name=\"CATEGORY\")","a3582ec1":"Main_Train_Data = pd.concat([JPG_Path_Series,JPG_Labels_Series],axis=1)","0e294ea1":"print(Main_Train_Data.head(-1))","3cccb406":"Mars_Sand_Land = Main_Train_Data[Main_Train_Data[\"CATEGORY\"] == \"sand\"]","1b736525":"print(Mars_Sand_Land.head(-1))","ae559ddd":"Mars_Sand_Land = Mars_Sand_Land.reset_index()","8ce94149":"print(Mars_Sand_Land.head(-1))","09660bd7":"Example_Image = Mars_Sand_Land[\"JPG\"][44]\nRead_Image = cv2.imread(Example_Image)\nRead_Image = cv2.cvtColor(Read_Image,cv2.COLOR_BGR2RGB)\nplt.xlabel(Read_Image.shape)\nplt.ylabel(Read_Image.size)\nplt.imshow(Read_Image)","f15ee850":"Example_Image = Mars_Sand_Land[\"JPG\"][3611]\nRead_Image = cv2.imread(Example_Image)\nRead_Image = cv2.cvtColor(Read_Image,cv2.COLOR_BGR2RGB)\nplt.xlabel(Read_Image.shape)\nplt.ylabel(Read_Image.size)\nplt.imshow(Read_Image)","f18dc4df":"Example_Image = Mars_Sand_Land[\"JPG\"][788]\nRead_Image = cv2.imread(Example_Image)\nRead_Image = cv2.cvtColor(Read_Image,cv2.COLOR_BGR2RGB)\nplt.xlabel(Read_Image.shape)\nplt.ylabel(Read_Image.size)\nplt.imshow(Read_Image)","c284a54d":"figure,axis = plt.subplots(ncols=5,nrows=5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    IMG_E = Mars_Sand_Land[\"JPG\"][i]\n    R_IMG = cv2.imread(IMG_E)\n    R_IMG = cv2.cvtColor(R_IMG,cv2.COLOR_BGR2RGB)\n    ax.set_xlabel(R_IMG.shape)\n    ax.set_ylabel(R_IMG.size)\n    ax.set_title(Mars_Sand_Land[\"CATEGORY\"][i])\n    ax.imshow(R_IMG)\nplt.tight_layout()\nplt.show()","3f33a764":"Transformation_List = []\n\nfor image in Mars_Sand_Land[\"JPG\"]:\n    x_IMG = cv2.imread(image)\n    x_IMG = cv2.resize(x_IMG,(180,180))\n    x_IMG = x_IMG \/ 255.\n    Transformation_List.append(x_IMG)\nprint(\"IT'S DONE!\")","ba0e934a":"print(Transformation_List[3].shape)","93251cee":"figure = plt.figure(figsize=(10,10))\nplt.imshow(Transformation_List[3])","e9104334":"figure = plt.figure(figsize=(10,10))\nplt.imshow(Transformation_List[300])","50e9ee5b":"figure = plt.figure(figsize=(10,10))\nplt.imshow(Transformation_List[210])","c6c68f40":"X_Set = np.asarray(Transformation_List)\nX_Set = X_Set.reshape(-1,180,180,3)","5dd5426a":"print(X_Set.shape)\nprint(X_Set.size)","f4d07910":"Generator_Input = keras.Input(shape=(180,))\nx = layers.Dense(128*90*90)(Generator_Input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((90,90,128))(x)\n\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2DTranspose(256,4,padding=\"same\",strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(3,7,padding=\"same\",activation=\"tanh\")(x)","f4287edf":"Generator = keras.models.Model(Generator_Input,x)","543f43dc":"print(Generator.summary())","db64770e":"R_Noise = tf.random.normal(shape=[1,180])\nG_T_Noise = Generator(R_Noise,training=False)","ecb043c1":"G_T_Noise_S = np.squeeze(G_T_Noise,axis=0)","7ea57924":"plt.imshow(R_Noise)","31ee77f9":"plt.imshow(G_T_Noise_S,cmap=\"binary\")","2596e463":"Discriminator_Input = layers.Input(shape=(180,180,3))\nx = layers.Conv2D(128,3)(Discriminator_Input)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,3,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Flatten()(x)\nx = layers.Dense(1,activation=\"sigmoid\")(x)\n\nDiscriminator = keras.models.Model(Discriminator_Input,x)","d3c41bf0":"print(Discriminator.summary())","a4dc0904":"Decision_IMG = Discriminator(G_T_Noise)","2d532930":"print(Decision_IMG)","eaa9934d":"Discriminator.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","495a75bd":"Discriminator.trainable = False","ac693af8":"GAN_Input = keras.Input(shape=(180,))\nGAN_Output = Discriminator(Generator(GAN_Input))","72f128e1":"GAN_Model = keras.models.Model(GAN_Input,GAN_Output)","d1d3dcbe":"GAN_Model.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","0db8c31f":"print(GAN_Model.summary())","cc4705c7":"os.mkdir(\"new_sand_land_14\")","f141f61d":"start_period = 0\nbatch_size = 32\ndim_shape = 180\niterations = 1000","803e0897":"for step in range(iterations):\n    random_noise_vector = np.random.normal(size=(batch_size,dim_shape))\n    Generator_Images = Generator.predict(random_noise_vector)\n    \n    stop = start_period + batch_size\n    \n    Real_Images = X_Set[start_period:stop]\n    \n    Combination_Images = np.concatenate([Generator_Images,Real_Images])\n    \n    labels = np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))])\n    labels = labels + 0.005 * np.random.random(labels.shape)\n    \n    D_Loss = Discriminator.train_on_batch(Combination_Images,labels)\n    \n    random_noise_vector = np.random.normal(size=(batch_size,dim_shape))\n    \n    Misleading_Target = np.zeros((batch_size,1))\n    \n    Adver_Loss = GAN_Model.train_on_batch(random_noise_vector,Misleading_Target)\n    \n    start_period = start_period + batch_size\n    \n    if start_period > len(X_Set) - batch_size:\n        start_period = 0\n        \n    if step % 10 == 0:\n        GAN_Model.save_weights(\"DCGAN_Model_Weights.h5\")\n        \n        print(\"DISCRIMINATOR LOSS: \", D_Loss)\n        print(\"ADVERSARIAL LOSS: \", Adver_Loss)\n        \n        Img_X_X = image.array_to_img(Generator_Images[0] * 255., scale=False)\n        Img_X_X.save(os.path.join(\".\/new_sand_land_14\",\"FAKE\" + str(step)+\".png\"))\n        \n        Img_X_X = image.array_to_img(Real_Images[0] * 255.,scale=False)\n        Img_X_X.save(os.path.join(\".\/new_sand_land_14\",\"REAL\"+str(step)+\".png\"))","29b5720f":"Export_Out = Path(\".\/new_sand_land_14\")\nList_Output = list(Export_Out.glob(r\"*.png\"))\nList_Output_Series = pd.Series(List_Output,name=\"PNG\").astype(str)","58bb8743":"Predict_Noise = tf.random.normal(shape=[30,dim_shape])","6edc040e":"plt.imshow(Predict_Noise,cmap=\"binary\")\n","ac1f23b6":"Gen_Predict_N = Generator(Predict_Noise)","6c8c0340":"figure, axes = plt.subplots(nrows=5,ncols=6,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Random = Gen_Predict_N[i]\n    ax.imshow(IMG_Random)\n    ax.set_xlabel(Gen_Predict_N[i].shape)\nplt.tight_layout()\nplt.show()","6eba39d7":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Gen_Predict_N[7])\nplt.show()","ca9cd101":"figure = plt.figure(figsize=(10,10))\nplt.imshow(Gen_Predict_N[1])","6edf40de":"figure, axes = plt.subplots(nrows=5,ncols=5,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    List_Gen_Image = cv2.imread(List_Output_Series[i])\n    ax.imshow(List_Gen_Image,cmap=\"binary\")\n    ax.set_xlabel(List_Gen_Image.shape)\n    ax.set_ylabel(List_Gen_Image.size)\nplt.tight_layout()\nplt.show()","b04081c2":"Random_Fake_IMG = cv2.imread(List_Output_Series[3])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","e21394de":"Random_Fake_IMG = cv2.imread(List_Output_Series[5])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","30ca947f":"Random_Fake_IMG = cv2.imread(List_Output_Series[8])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","0a6e3a42":"Random_Fake_IMG = cv2.imread(List_Output_Series[9])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","b416e875":"Random_Fake_IMG = cv2.imread(List_Output_Series[14])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","908f041d":"Random_Fake_IMG = cv2.imread(List_Output_Series[23])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","900f6949":"Random_Fake_IMG = cv2.imread(List_Output_Series[22])\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","e8b77389":"Random_Fake_IMG = cv2.imread(List_Output_Series[1])\nRandom_Fake_IMG = cv2.cvtColor(Random_Fake_IMG,cv2.COLOR_RGB2BGR)\n\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","ef672e6c":"Random_Fake_IMG = cv2.imread(List_Output_Series[3])\nRandom_Fake_IMG = cv2.cvtColor(Random_Fake_IMG,cv2.COLOR_RGB2BGR)\nfigure = plt.figure(figsize=(10,10))\nplt.imshow(Random_Fake_IMG)","554f744c":"#### GENERAL STRUCTURE","4bada353":"# PACKAGES AND LIBRARIES","6bb93300":"# PATH & LABEL PROCESS","7a9915c2":"# DATA PROCESS","ea1aac21":"#### INFORMATION\n\n* Dataset contains images from the Planetary Data System (PDS) Atlas.\n* The website contains a Beta option on the left tab to filter images from the MSL Images based on their content such as \"Drill Hole\" or \"Float Rocks\".\n* The data is already divided in training and test set (80% and 20% respectively) and contains images from sand, rocks, drill holes and distant landscapes.","19658d57":"# HISTORY","189784d3":"#### DISCRIMINATOR","d148a1d1":"#### GENERATOR","7bf47333":"# DC-GAN","b2254af2":"# VISUALIZATION","4d547aff":"#### TRAINING"}}