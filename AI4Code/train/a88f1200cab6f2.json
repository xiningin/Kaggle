{"cell_type":{"3e4cc038":"code","0ed05a5d":"code","7c9d4e8e":"code","a965a7a3":"code","422582dd":"code","44c51e63":"code","00d5f459":"code","a953283d":"code","5f1a5dbd":"code","5febea8e":"code","f256f74c":"code","40cc7884":"code","977ae572":"code","10f360e4":"markdown","1c68b18f":"markdown","32a8c64a":"markdown","5065e3f9":"markdown"},"source":{"3e4cc038":"import sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nwarnings.filterwarnings(\"ignore\")\n","0ed05a5d":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","7c9d4e8e":"pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv\")\ntrain['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])","a965a7a3":"train.head()","422582dd":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n#for country in ['Vietnam']:\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        #The number of day forcast\n        #pred_data[pred_data['Date'] > max_train_date].shape[0]\n        #model = SimpleExpSmoothing(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True, damped=True).fit()\n        model = ExponentialSmoothing(adjusted_y_train_confirmed, trend = 'additive').fit()\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        #model = Holt(adjusted_y_train_fatalities).fit()\n        model = ExponentialSmoothing(adjusted_y_train_fatalities, trend = 'additive').fit()\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_1 = df_val.copy()","44c51e63":"country = \"Netherlands\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","00d5f459":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","a953283d":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima_model import ARIMA\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0), \n                        #seasonal_order=(1,1,0,12),\n                        measurement_error=True).fit(disp=False)\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0), \n                        #seasonal_order=(1,1,0,12),\n                        measurement_error=True).fit(disp=False)\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_2 = df_val.copy()","5f1a5dbd":"country = \"US\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","5febea8e":"country = \"India\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","f256f74c":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","40cc7884":"method_list = ['Exponential Smoothing','SARIMA']\nmethod_val = [df_val_1,df_val_2]\nfor i in range(0,2):\n    df_val = method_val[i]\n    method_score = [method_list[i]] + [RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)] + [RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)]\n    print (method_score)","977ae572":"df_val = df_val_2\nsubmission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","10f360e4":"# Holt and Exponential Smoothening","1c68b18f":"This notebook is in continuation with my earlier [EDA](https:\/\/github.com\/girish208\/Machine_Learning-Projects\/blob\/master\/Covid-19\/covid-19-eda-and-deep-analysis-using-visualization.ipynb). Please check it. This is further addition to analyse data with time series forecasting using HOLT and SARIMA.","32a8c64a":"# SARIMA Model","5065e3f9":"# Submission"}}