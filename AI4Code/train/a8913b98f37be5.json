{"cell_type":{"eb81c8f5":"code","c2fcd34e":"code","0ca97648":"code","8584b6e6":"code","ab82a9af":"code","67cd85eb":"code","ffd7e166":"code","b1cd1130":"code","df77a774":"markdown","bd129644":"markdown","fb82b3cd":"markdown","7bc10911":"markdown","fd0cd320":"markdown","2815b6f3":"markdown"},"source":{"eb81c8f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2fcd34e":"from sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n\ntrain_data = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv', index_col='id')\nX = train_data.iloc[:,:75]\n# One-Hot encode the labels\ny = pd.DataFrame(OH_encoder.fit_transform(pd.DataFrame(train_data.target)))\ny = y.rename(columns={i:f'Class_{i+1}' for i in range(9)})\ntrain_data.head()","0ca97648":"test_data = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv', index_col='id')\nX_test = test_data.iloc[:,:]\ntest_data.head()","8584b6e6":"def my_model():\n    model = keras.Sequential([\n        layers.InputLayer([75]),\n        layers.BatchNormalization(),\n        layers.Dense(16, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(32, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(64, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(128, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(9, activation='softmax')\n    ])\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","ab82a9af":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)","67cd85eb":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=8,\n    min_delta=0.001,\n    restore_best_weights=True,\n    verbose=1\n)\n\nmodel_val = my_model()\nhistory = model_val.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=100,\n    epochs=50,\n    callbacks=[early_stopping]\n)","ffd7e166":"early_stopping_final = keras.callbacks.EarlyStopping(\n    patience=8,\n    min_delta=0.001,\n    restore_best_weights=True,\n    verbose=1\n)\n\nmodel = my_model()\nhistory = model.fit(\n    X, y,\n    batch_size=100,\n    epochs=50,\n    callbacks=[early_stopping_final]\n)","b1cd1130":"predictions = model.predict(X_test)\noutput = pd.DataFrame(predictions)\noutput = output.rename(columns={i:f'Class_{i+1}' for i in range(9)})\noutput = output.rename_axis(\"id\", axis='rows')\nidcol = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nidcol = idcol.iloc[:,0]\noutput = pd.concat([idcol, output], axis=1)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","df77a774":"## Final Training and Submission","bd129644":"## Training and Validation\nNow, we'll set up the training and validation data.","fb82b3cd":"# Tabular Playground June 2021 Submission\nWe'll start with the basic imports. For the submission, I plan on using a deep learning model with TensorFlow.","7bc10911":"## The Model\nHere, we'll use a keras deep learning model with the following architecture:\n1. InputLayer\n2. BatchNormalization\n3. Dense(16, activation='relu')\n4. BatchNormalization\n5. Dense(32, activation='relu')\n6. BatchNormalization\n7. Dense(64, activation='relu')\n8. BatchNormalization\n9. Dense(128, activation='relu')\n10. BatchNormalization\n11. Dense(9, activation='softmax')\n\nWe'll then compile the model with the Adam optimizer, the categorical_crossentropy loss, and the accuracy metric.","fd0cd320":"Then, we'll train the model on the training data and check with validations. We'll use an early stopping metric as well, training on many epochs.","2815b6f3":"## Setting up the Data\nNow, we'll load and take a look at the data."}}