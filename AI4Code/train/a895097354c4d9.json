{"cell_type":{"a5e8c8eb":"code","0fc54a6d":"code","0f4bc884":"code","112c0276":"code","2209ce60":"code","cab7e9fd":"code","cdbf1f71":"code","7f92008d":"code","44915f56":"code","17513699":"code","bb9e85d3":"markdown","3c280a11":"markdown","9fa2e094":"markdown","6b9dc175":"markdown","417a9ce8":"markdown"},"source":{"a5e8c8eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fc54a6d":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\n%matplotlib inline","0f4bc884":"train_dir = '\/kaggle\/input\/digit-recognizer\/train.csv'\ntest_dir = '\/kaggle\/input\/digit-recognizer\/test.csv'\n\ntrain_data = pd.read_csv(train_dir)\ntest_data = pd.read_csv(test_dir)\n\nprint('Train Data Shape: ', train_data.shape)\nprint('Test Data Shape: ', test_data.shape)","112c0276":"# define train size\ntrain_ratio = 0.75\ntrain_size = int(train_data.shape[0]*train_ratio)\n\nprint(\"Num of training images: \", train_size)\nprint(\"Num of validation images: \", train_data.shape[0]-train_size)\n\nX_train = train_data.iloc[:train_size, 1:].values # as np.array()\nX_valid = train_data.iloc[train_size:, 1:].values\nX_test = test_data.values\n\ny_train = train_data.iloc[:train_size, 1].values\ny_valid = train_data.iloc[train_size:, 1].values\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1) # reshaping in image size\nX_valid = X_valid.reshape(X_valid.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\ny_train = to_categorical(y_train) # making one-hot vector\ny_valid = to_categorical(y_valid)","2209ce60":"for i in range(16):\n    sp = plt.subplot(4,4, i+1)\n    sp.axis('off')\n    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.get_cmap('binary'))\nplt.show()","cab7e9fd":"X_train = X_train\/255.0\nX_valid = X_valid\/255.0\nX_test = X_test\/255.0","cdbf1f71":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n    \n])\n\nmodel.summary()","7f92008d":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nhistory = model.fit(X_train, y_train,\n          epochs=5,\n          steps_per_epoch=512,\n          validation_data=(X_valid, y_valid))","44915f56":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","17513699":"predictions = model.predict_classes(X_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"DR_sub.csv\", index=False, header=True)","bb9e85d3":"# Create Submission file","3c280a11":"# Visualize loss and accuracy plot","9fa2e094":"# view image ","6b9dc175":"# Defining Directories","417a9ce8":"# Import Libraries"}}