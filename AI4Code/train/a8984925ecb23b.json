{"cell_type":{"80bcad52":"code","f39946f8":"code","27b31d33":"code","312749b1":"code","cfc84089":"code","7736ae93":"code","deaa2a5e":"code","a3c7e433":"code","cb597c21":"code","443cb905":"code","b3d12bfd":"code","cc7b0694":"code","8e755435":"code","30585025":"code","34a904a8":"code","4b59199e":"code","908d5b58":"markdown","37d3af15":"markdown","b15cc64e":"markdown","f387e26e":"markdown"},"source":{"80bcad52":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.pipeline import Pipeline\nimport gc\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Embedding,  Activation, Flatten, Conv1D\nfrom tensorflow.keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import RMSprop\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.preprocessing import QuantileTransformer,  KBinsDiscretizer\nfrom tensorflow import keras\nfrom sklearn import metrics\nfrom sklearn.impute import SimpleImputer\n\nimport math\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_selection import mutual_info_classif\n\nimport keras_tuner as kt\nfrom tensorflow import keras","f39946f8":"%%time\ntrain = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest  = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')","27b31d33":"validation = train.sample(frac = 0.3)\ntrain = train.drop(validation.index)","312749b1":"print(train.shape)\nprint(train.claim.value_counts())\nprint(validation.shape)\nprint(validation.claim.value_counts())","cfc84089":"train['missing'] = train.isna().sum(axis=1)\nvalidation['missing'] = validation.isna().sum(axis=1)\ntest['missing'] = test.isna().sum(axis=1)\n\nfeatures = [col for col in train.columns if col not in ['claim', 'id']]","7736ae93":"def preprocessor():\n    pipe = Pipeline([\n        ('imputer', SimpleImputer(strategy='median', missing_values=np.nan)),\n        (\"scaler\", QuantileTransformer(n_quantiles=128,output_distribution='uniform')),\n        ('bin', KBinsDiscretizer(n_bins=128, encode='ordinal',strategy='uniform'))\n        ])\n    \n    train[features] = pipe.fit_transform(train[features])\n    test[features] = pipe.transform(test[features])\n    validation[features] = pipe.transform(validation[features])","deaa2a5e":"def model(hp):\n    input = Input(train[features].shape[1:])\n    \n    e = Embedding(input_dim=128, output_dim=4)(input)\n    f2 = Flatten()(e)\n    \n    for i in range(hp.Int('num_layers', 1, 10)):\n        d1 = Dense(hp.Choice('units_' + str(i), [16, 32, 64]),activation='relu')(f2)\n        do1 = Dropout(hp.Float('drop_' + str(i), min_value=0.2, max_value=0.5, step=0.1))(d1)\n    \n    \n    output = Dense(1, activation='sigmoid')(do1)\n\n    model = Model(inputs=input, outputs=output)\n\n    auc = tf.keras.metrics.AUC(name='aucroc')\n    #optimizer = RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])), metrics=[auc])\n    \n    return model\n","a3c7e433":"preprocessor()","cb597c21":"x=train[features]\ny=train['claim']\n\nxval=validation[features]\nyval=validation['claim']\n\ngc.collect()","443cb905":"tuner = kt.RandomSearch(model,objective='val_loss',max_trials=5)\ntuner.search(x, y, epochs=5, validation_data=(xval, yval))\nbest_model = tuner.get_best_models()[0]","b3d12bfd":"best_model.summary()","cc7b0694":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_aucroc', mode='max', patience=5, restore_best_weights=True)","8e755435":"history = best_model.fit(x = x, y = y, batch_size = 1024, shuffle = True, validation_data=(xval, yval), epochs=30, callbacks=[callback])","30585025":"# plot training history\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.plot(history.history['aucroc'], label='aucroc')\nplt.plot(history.history['val_aucroc'], label='val_aucroc')\nplt.legend()\nplt.show()\n","34a904a8":"sub=pd.DataFrame()\nsub['id'] = test['id']\nsub['claim'] = best_model.predict(test[features])\nsub=sub.set_index('id')\nsub.to_csv('submission.csv')","4b59199e":"sub.head()","908d5b58":"# Modeling","37d3af15":"# Analyse Dataset","b15cc64e":"# Load Dataset","f387e26e":"# Preprocessing"}}