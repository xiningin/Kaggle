{"cell_type":{"2eafb450":"code","ff03a092":"code","4da89807":"code","8131c66b":"code","a2fc11b0":"code","d7a81506":"code","f0a98a2a":"code","a7f9ac12":"code","0a7199a3":"code","6a94990b":"code","17871bba":"code","ecd90d07":"code","346e22f4":"code","13dcc7ad":"code","6c81d848":"code","2cf30887":"code","65be8e1d":"code","dea2e09c":"code","1f5613fd":"code","2ff6999b":"code","195335d6":"code","b623c6ed":"code","183d7f89":"code","7b4e865a":"code","867110e1":"code","cbba8d95":"code","d5aaba83":"code","2edf5f76":"code","3b6cccec":"code","efb0b04b":"code","7b7ca0de":"code","d1669552":"code","23cd85fa":"code","236a4424":"code","fb6cf37c":"code","66d6b465":"code","405675e5":"code","00e2c192":"code","7ce66d7f":"code","8c590735":"code","3c1bbce8":"code","c8da5213":"code","22ed1ac5":"code","9fa147be":"code","5683367b":"code","db2b703d":"markdown"},"source":{"2eafb450":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\nimport seaborn as sns\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\nfrom scipy import stats as st\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.metrics import accuracy_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import RFE, f_regression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\n# Any results you write to the current directory are saved as output.","ff03a092":"loans = pd.read_csv(\"..\/input\/LoanStats3a.csv\", encoding=\"utf-8\", skiprows=1)\nloans.head()","4da89807":"loans.info()","8131c66b":"total = loans.isnull().sum().sort_values(ascending=False)\ntotal[total>0]","a2fc11b0":"percent = (loans.isnull().sum()\/loans.isnull().count()).sort_values(ascending = False)\npd1 = pd.concat([total,percent],axis =1 ,keys=['Total','Percent'])\npd2 = pd1[pd1['Total']>0]\nprint(pd2)","d7a81506":"loans.dropna(subset=['purpose','total_acc','last_pymnt_d','tax_liens','revol_util','title','last_credit_pull_d','pub_rec_bankruptcies','emp_title'], inplace=True)","f0a98a2a":"loans = loans.loc[:, percent < 0.3]","a7f9ac12":"loans.shape","0a7199a3":"unique = loans.nunique()\nunique = unique[unique.values == 1]","6a94990b":"loans.drop(labels = list(unique.index), axis =1, inplace=True)\nloans.shape","17871bba":"print(loans.emp_length.unique())\nloans.emp_length.fillna('0',inplace=True)\nloans.emp_length.replace(['n\/a'],'Self-Employed',inplace=True)\nprint(loans.emp_length.unique())","ecd90d07":"loans.drop(labels = 'zip_code', axis =1, inplace=True)","346e22f4":"loans.info()","13dcc7ad":"loans['int_rate'] = loans['int_rate'].str.replace('%', '')\nloans['int_rate'] = loans['int_rate'].astype(float)","6c81d848":"\nloans['revol_util'] = loans['revol_util'].str.replace('%', '')\nloans['revol_util'] = loans['revol_util'].astype(float)","2cf30887":"(loans.purpose.value_counts()*100)\/len(loans)","65be8e1d":"del_loan_purpose = (loans.purpose.value_counts()*100)\/len(loans)\ndel_loan_purpose = del_loan_purpose[(del_loan_purpose < 0.75) | (del_loan_purpose.index == 'other')]\n\nloans.drop(labels = loans[loans.purpose.isin(del_loan_purpose.index)].index, inplace=True)\n\nprint(loans.purpose.unique())","dea2e09c":"(loans.loan_status.value_counts()*100)\/len(loans)","1f5613fd":"loans.info()","2ff6999b":"loans['issue_month'],loans['issue_year'] = loans['issue_d'].str.split('-', 1).str\nloans[['issue_d','issue_month','issue_year']].head()","195335d6":"q = loans[\"annual_inc\"].quantile(0.995)\nloans = loans[loans[\"annual_inc\"] < q]\nloans[\"annual_inc\"].describe()","b623c6ed":"loan_correlation = loans.corr()\nloan_correlation","183d7f89":"loans['issue_month'] = loans['issue_month'].astype(str)\nloans['issue_year'] = loans['issue_year'].astype(str)\ndel loans['issue_d']","7b4e865a":"loans['earliest_month'],loans['earliest_year'] = loans['earliest_cr_line'].str.split('-', 1).str\nloans['earliest_month'] = loans['earliest_month'].astype(str)\nloans['earliest_year'] = loans['earliest_year'].astype(str)\ndel loans['earliest_cr_line']","867110e1":"loans['last_pymnt_d_month'],loans['last_pymnt_d_year'] = loans['last_pymnt_d'].str.split('-', 1).str\nloans['last_pymnt_d_month'] = loans['last_pymnt_d_month'].astype(str)\nloans['last_pymnt_d_year'] = loans['last_pymnt_d_year'].astype(str)\ndel loans['last_pymnt_d']","cbba8d95":"int_cols = [key for key in dict(loans.dtypes) if dict(loans.dtypes)[key] in ['object']]\nint_cols","d5aaba83":"#encoding categorical variables\nfrom sklearn.preprocessing import LabelEncoder\ncols =('grade',\n 'sub_grade',\n 'emp_title',\n 'home_ownership',\n 'verification_status',\n 'loan_status',\n 'purpose',\n 'title',\n 'addr_state',\n 'debt_settlement_flag')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(loans[c].values)) \n    loans[c] = lbl.transform(list(loans[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(loans.shape))","2edf5f76":"loans[int_cols].corr(method='spearman')>0.7","3b6cccec":"#removing columns with high autocorrelation\ndel loans['funded_amnt']\ndel loans['funded_amnt_inv']\ndel loans['loan_amnt']\ndel loans['total_pymnt_inv']\ndel loans['total_rec_prncp']\ndel loans['total_rec_int']\ndel loans['collection_recovery_fee']","efb0b04b":"loans.info()","7b7ca0de":"from sklearn.cross_validation import train_test_split\n\ntrain,test = train_test_split(loans, train_size=0.8 , random_state=100)","d1669552":"df1 = train.copy()\n# First extract the target variable which is our House prices\nY = df1.loan_status.values\n# Drop price from the house dataframe and create a matrix out of the house data\nX = df1.drop(['loan_status'], axis=1)\n\n# Store the column\/feature names into a list \"colnames\"\nint_cols = [key for key in dict(X.dtypes) if dict(X.dtypes)[key] in ['float64', 'int64','uint8','int32']]\nlen(int_cols)","23cd85fa":"X_train = train[int_cols]\ny_train = train['loan_status']\nX_test = test[int_cols]\ny_test = test['loan_status']","236a4424":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","fb6cf37c":"scaler = StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)","66d6b465":"#LogisticRegression\n\n#params = {'C':[1, 10, 50, 100, 500, 1000, 2000], 'tol': [0.001, 0.0001, 0.005]}\nlog_reg = LogisticRegression(solver='newton-cg',max_iter=300, multi_class='multinomial',n_jobs=-1)\n#clf = GridSearchCV(log_reg, params, scoring='log_loss', refit='True', n_jobs=-1, cv=5)\nfit = log_reg.fit(X_train, y_train)","405675e5":"scaler = StandardScaler().fit(X_test)\nX_test = scaler.transform(X_test)","00e2c192":"print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(log_reg.score(X_test, y_test)))","7ce66d7f":"import matplotlib.pyplot as plt\ny_pred = log_reg.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nlabels = ['Fully paid','Charged off','Fully paid(CP not meet)','Charged off(CP not meet)']\nprint(labels)\ncm = confusion_matrix(y_test,y_pred)\n\nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix of the classifier')\nfig.colorbar(cax)\nax.set_xticklabels( labels)\nax.set_yticklabels( labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","8c590735":"#LightGBM Model\n\nimport lightgbm as lgb\nimport gc\n\nlgb_params1 = {}\nlgb_params1['learning_rate'] = 0.1\nlgb_params1['n_estimators'] = 300\nlgb_params1['max_bin'] = 10\nlgb_params1['subsample'] = 0.7\nlgb_params1['subsample_freq'] = 12\nlgb_params1['colsample_bytree'] = 0.7   \nlgb_params1['min_child_samples'] = 600\nlgb_params1['seed'] = 1974\n\n#watchlist = [X_test]\nclf = lgb.LGBMClassifier(**lgb_params1)","3c1bbce8":"lgb_fit = clf.fit(X_train,y_train)","c8da5213":"y_pred = lgb_fit.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nlabels = ['Fully paid','Charged off','Fully paid(CP not meet)','Charged off(CP not meet)']\nprint(labels)\ncm = confusion_matrix(y_test,y_pred)\n\nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix of the classifier')\nfig.colorbar(cax)\nax.set_xticklabels( labels)\nax.set_yticklabels( labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","22ed1ac5":"print(\"Accuracy:\", accuracy_score(y_test,y_pred)) ","9fa147be":"#Random Forest Classifier\n\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.ensemble import RandomForestClassifier \n\nclf = RandomForestClassifier() \nprint(clf) \n\n# fit the model on training data and predict on unseen test data\nclf.fit(X_train, y_train) \npreds = clf.predict(X_test) \n\n# check the accuracy of the predictive model\nprint(\"Accuracy:\", accuracy_score(y_test,preds)) ","5683367b":"y_pred = clf.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nlabels = ['Fully paid','Charged off','Fully paid(CP not meet)','Charged off(CP not meet)']\nprint(labels)\ncm = confusion_matrix(y_test,y_pred)\n\nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix of the classifier')\nfig.colorbar(cax)\nax.set_xticklabels( labels)\nax.set_yticklabels( labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","db2b703d":"Converting int_rate and revol_util into float\n"}}