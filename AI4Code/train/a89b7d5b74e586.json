{"cell_type":{"7993d521":"code","2809c10e":"code","7d88e8c7":"code","2968628b":"code","c4f3dd6a":"code","67b9723a":"code","479a00ec":"code","5c25949c":"code","fa3c91aa":"markdown"},"source":{"7993d521":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom category_encoders.cat_boost import CatBoostEncoder\n\n# Any results you write to the current directory are saved as output.","2809c10e":"class Processor:\n    X = pd.DataFrame()\n    y = pd.DataFrame()\n    filename = ''\n    target_column = None\n    cat_encoders = {}\n    \n    def __init__(self, filename, target_column = None):\n        self.filename = filename\n        self.target_column = target_column\n        self.read()\n    \n    def read(self):\n        self.X = pd.read_csv(self.filename)\n        if self.target_column != None:\n            self.y = self.X[self.target_column].copy()\n            self.X.drop([self.target_column], axis=1, inplace=True)\n        print(self.X.shape)\n       \n    def plot_heatmap(self):\n        f,ax = plt.subplots(figsize=(32, 28))\n        sns.heatmap(self.X.corr(), annot=True, linewidths=.8, fmt= '.1f',ax=ax)\n        plt.plot()        \n    \n    \n    def clean(self):\n        self.drop_nan_and_nocorr_columns()\n        self.set_median_for_numeric_nan()\n        self.X.dropna(axis=1, inplace=True)\n        self.encode_label_columns()\n        print(self.X.shape)\n\n    def drop_nan_and_nocorr_columns(self):\n        columns_to_drop = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature', 'Id','EnclosedPorch','3SsnPorch',\n                           'ScreenPorch','MiscVal','MoSold','YrSold','MasVnrArea', 'BsmtFinSF2','LowQualFinSF',\n                           'OverallCond','BsmtHalfBath', 'Utilities','Street','PoolArea','MasVnrType','Heating',\n                           'Condition2','Functional',\n                           # small number of nans\n                           'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual',\n                          'Electrical', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd',\n                          'GarageCond',  'GarageFinish', 'GarageQual', 'GarageType',\n                          # does not work for test set\n                          'KitchenQual', 'MSZoning','SaleType']\n        self.X.drop(columns_to_drop, axis=1, inplace=True)     \n        \n    def set_median_for_numeric_nan(self):\n        for column in self.X.columns:\n            if np.issubdtype(self.X[column].dtype, np.number):\n                mask = self.X.loc[self.X[column].isna()]\n                df = self.X.iloc[mask.index]\n                df[column] = self.X[column].median()\n                self.X.iloc[mask.index] = df\n                \n    def encode_label_columns(self):\n        columns_to_encode = ['MSSubClass','LotFrontage','LotArea','Neighborhood','OverallQual','YearBuilt','YearRemodAdd','BsmtFinSF1',\n                             'BsmtUnfSF','TotalBsmtSF', '1stFlrSF','2ndFlrSF','GrLivArea','GarageYrBlt','GarageArea','WoodDeckSF',\n                             'OpenPorchSF','BldgType', \n                             'CentralAir', 'Condition1',  \n                             'Foundation',  \n                             'HeatingQC', 'HouseStyle', 'LandContour', 'LandSlope', 'LotConfig','LotShape', \n                             'PavedDrive', 'RoofMatl', 'RoofStyle', 'SaleCondition']\n        for column in columns_to_encode:\n            y = None\n            encoder = CatBoostEncoder()\n            if self.target_column != None:\n                self.X[column] = encoder.fit_transform(self.X[column].values, self.y.values)\n                self.cat_encoders[column] = encoder\n            else:\n                self.X[column] = self.cat_encoders[column].transform(self.X[column].values)\n","7d88e8c7":"processor = Processor('..\/input\/train.csv', 'SalePrice')\nprocessor.clean()\nprocessor.X.head()","2968628b":"processor.plot_heatmap()","c4f3dd6a":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX = processor.X.copy()\ny = processor.y.copy()\n\n\nX_train1, X_valid1, y_train1, y_valid1 = train_test_split( X, y, test_size=0.25, random_state=42)\n    \n# LightGBM dataset formatting \nlgtrain = lgb.Dataset(X_train1, y_train1)\nlgvalid = lgb.Dataset(X_valid1, y_valid1)\n\nparams = {\n    'objective' : 'regression',\n    'num_iterations' : 10000,\n    'metric' : 'rmse',\n    'num_leaves' : 500,\n    'max_bin' : 500,\n    'max_depth': 15,\n    'bagging_fraction' : 0.6,\n    'bagging_freq' : 15,\n    'learning_rate' : 0.007,\n    'feature_fraction' : 0.4,\n    'verbosity' : 0\n}\n\nevals_result = {}  # to record eval results for plotting\n\ngbm = lgb.train(\n    params,\n    lgtrain,\n    valid_sets=[lgtrain, lgvalid],\n    valid_names=[\"train\", \"valid\"],\n    early_stopping_rounds=1000,\n    verbose_eval=500,\n    evals_result=evals_result\n)\n\n#print(\"RMSE of the validation set:\", np.sqrt(mean_squared_error(y_valid1, gbm.predict(X_valid1))))","67b9723a":"print('Plotting metrics recorded during training...')\nax = lgb.plot_metric(evals_result, metric='rmse')\nplt.show()\n\nprint('Plotting feature importances...')\nax = lgb.plot_importance(gbm, max_num_features=20)\nplt.show()","479a00ec":"processor_test = Processor('..\/input\/test.csv')\nid_values = processor_test.X['Id'].copy()\nprocessor_test.clean()\npredictions = gbm.predict(processor_test.X)\nprint(predictions.shape)\nprint(id_values.shape)","5c25949c":"output = pd.DataFrame({'Id': id_values, 'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)","fa3c91aa":"## LightGBM regressor"}}