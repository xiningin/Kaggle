{"cell_type":{"57ee77f9":"code","e014f1fb":"code","8a105da7":"code","4b1fe807":"code","63d1c873":"code","00206bf8":"code","fe23eb71":"code","d94eaf6f":"code","b230e100":"code","b0a68777":"code","74d09150":"code","4a528310":"code","a77323e8":"code","de650d86":"code","04af3436":"code","6d6498bb":"code","cdd1faad":"code","7df21f24":"code","987fb30f":"markdown","cead0ce2":"markdown","00debd49":"markdown","0bf70f08":"markdown","d68c5f99":"markdown","c45d639b":"markdown","41304abc":"markdown","2a5b165e":"markdown","16c863ce":"markdown","34e1a476":"markdown","97dbe3ac":"markdown","d03135d9":"markdown","5c79b117":"markdown","263f17be":"markdown","aa679511":"markdown","80dbcdff":"markdown","7dc09b99":"markdown","f312d1e8":"markdown"},"source":{"57ee77f9":"# ---\n# importing required libraries\nimport random\nimport csv\nimport math\nimport statistics\nimport copy\n\n# set random seed\nrandom.seed('iris dataset')","e014f1fb":"def _load_csv(filename):\n\twith open(filename, 'r') as file:\n\t\tcsv_reader = csv.reader(file)\n\t\treturn [row for row in csv_reader if row]\n","8a105da7":"csv.reader??","4b1fe807":"def _clean_features(dataset):\n    num_columns = len(dataset[0])\n\n    for row in dataset:\n        for column in range(num_columns-1):\n            row[column] = float(row[column].strip())\n","63d1c873":"def _map_classes(dataset):\n    class_mappings = {}\n    for row in dataset:\n        _specie = row[-1]\n        if _specie not in class_mappings.keys():\n            class_mappings[_specie] = len(class_mappings)\n        row[-1] = class_mappings[_specie]\n\n    return class_mappings\n","00206bf8":"def _normalize_data(dataset):\n    num_features = len(dataset[0])-1\n    for i in range(num_features):\n        column_values = [row[i] for row in dataset]\n        column_min = min(column_values)\n        column_max = max(column_values)\n        \n        for row in dataset:\n            row[i] = (row[i] - column_min) \/ (column_max - column_min)\n","fe23eb71":"def DataLoader(filename):\n    dataset = _load_csv(filename)\n    _clean_features(dataset)\n    class_mappings = _map_classes(dataset)\n    _normalize_data(dataset)\n\n    return dataset, class_mappings\n","d94eaf6f":"def _euclidean_distance(row1, row2):\n    distance = 0.0\n    num_features = len(row1)-1\n\n    for i in range(num_features):\n        distance += (row1[i] - row2[i])**2\n    return math.sqrt(distance)\n","b230e100":"def _get_k_neighbours(test_row, train_data, num_neighbours):\n    test_train_distances = []\n    for train_row in train_data:\n        _test_train_distance = _euclidean_distance(test_row, train_row)\n        test_train_distances.append([train_row, _test_train_distance])\n\n    test_train_distances.sort(key=lambda idx: idx[1])\n    return [test_train_distances[i][0] for i in range(num_neighbours)]\n","b0a68777":"def _predict_classification(test_row, train_data, num_neighbours):\n    nearest_neighbours =  _get_k_neighbours(test_row, train_data, num_neighbours)\n    nearest_classes = [neighbour[-1] for neighbour in nearest_neighbours]\n    predicted_class = max(set(nearest_classes), key=nearest_classes.count)\n\n    return predicted_class\n","74d09150":"def kNN_Algorithm(test_data, train_data, num_neighbours):\n    return [_predict_classification(test_row, train_data, num_neighbours) for test_row in test_data]\n","4a528310":"def _test_train_split(dataset, test_ratio):\n    _dataset = copy.deepcopy(dataset)\n    random.shuffle(_dataset)\n\n    split_index = int(len(dataset) * test_ratio)\n    # Training data\n    test_sample = _dataset[0:split_index]\n    #Testing data\n    train_sample = _dataset[split_index:]\n\n    return test_sample, train_sample\n","a77323e8":"def _cross_validation_split(dataset, num_groups):\n    dataset_groups = []\n    _dataset = copy.deepcopy(dataset)\n    group_size = int(len(_dataset) \/ num_groups)\n\n    for i in range(num_groups):\n        group = []\n        while len(group) < group_size:\n            idx = random.randrange(len(_dataset))\n            group.append(_dataset.pop(idx))\n        dataset_groups.append(group)\n\n    return dataset_groups\n","de650d86":"def _get_accuracy(test_sample, algorithm_predictions, class_mappings):\n    test_classes = [row[-1] for row in test_sample]\n    num_test_classes = len(test_classes)\n    test_labels = list(class_mappings.keys())\n\n    if len(test_classes) != len(algorithm_predictions):\n        raise IndexError(\"The count of test classes is not equal to the count of algorithm predictions!\")\n\n    num_correct_predictions = sum([actual == predicted for actual, predicted \n                                                        in zip(test_classes, algorithm_predictions)])\n\n    wrong_predictions = [f'A:{test_labels[actual]} | P:{test_labels[predicted]}'\n                                                            for actual, predicted \n                                                            in zip(test_classes, algorithm_predictions)\n                                                            if actual != predicted]\n                        \n    accuracy = (num_correct_predictions \/ num_test_classes) * 100\n    return accuracy, wrong_predictions\n","04af3436":"def tts_Evaluate_kNN_Algorithm(dataset, class_mappings, test_ratio=0.25, \n                                                                num_neighbours=3, num_iterations=100):\n    \n    ACCURACY_HISTORY = []\n    WRONG_PREDICTION_HISTORY = []\n\n    for _iter in range(num_iterations):\n        _dataset = copy.deepcopy(dataset)\n        test_sample, train_sample = _test_train_split(_dataset, test_ratio)\n\n        algorithm_predictions = kNN_Algorithm(test_sample, train_sample, num_neighbours)\n        accuracy, wrong_predictions = _get_accuracy(test_sample, algorithm_predictions, class_mappings)\n        ACCURACY_HISTORY.append(accuracy)\n        WRONG_PREDICTION_HISTORY.extend(wrong_predictions)\n\n    random.shuffle(WRONG_PREDICTION_HISTORY)\n    print('kNN algorithm evaluation using the Test\/Train Split method:', '\\n\\t', \n                'Average Accuracy:', round(statistics.mean(ACCURACY_HISTORY), ndigits=4), '\\n\\t', \n                'Maximum Accuracy:', max(ACCURACY_HISTORY), '\\n')\n\n    print('A: Actual | P: Predicted')\n    print('\\n'.join(WRONG_PREDICTION_HISTORY[:20]))\n","6d6498bb":"def cvs_Evaluate_kNN_Algorithm(dataset, class_mappings, num_groups=5, \n                                                                num_neighbours=3, num_iterations=100):\n    \n    ACCURACY_HISTORY = []\n    WRONG_PREDICTION_HISTORY = []\n\n    for _iter in range(num_iterations):\n        _dataset = copy.deepcopy(dataset)\n        dataset_groups = _cross_validation_split(_dataset, num_groups)\n\n        for idx, group in enumerate(dataset_groups):\n            test_sample = group\n            _train_sample = copy.deepcopy(dataset_groups)\n            del _train_sample[idx]\n            \n            train_sample = []\n            for train_group in _train_sample:\n                train_sample.extend(train_group)\n\n            algorithm_predictions = kNN_Algorithm(test_sample, train_sample, num_neighbours)\n            accuracy, wrong_predictions = _get_accuracy(test_sample, algorithm_predictions, class_mappings)\n            ACCURACY_HISTORY.append(accuracy)\n            WRONG_PREDICTION_HISTORY.extend(wrong_predictions)\n\n    random.shuffle(WRONG_PREDICTION_HISTORY)\n    print('kNN algorithm evaluation using the Cross Validation Split method:', '\\n\\t', \n                'Average Accuracy:', round(statistics.mean(ACCURACY_HISTORY), ndigits=4), '\\n\\t', \n                'Maximum Accuracy:', max(ACCURACY_HISTORY), '\\n')\n\n    print('A: Actual | P: Predicted')\n    print('\\n'.join(WRONG_PREDICTION_HISTORY[:20]))\n","cdd1faad":"dataset, class_mappings = DataLoader(\"..\/input\/iris-dataset\/iris.data.csv\")\ntts_Evaluate_kNN_Algorithm(dataset, class_mappings)\n","7df21f24":"dataset, class_mappings = DataLoader(\"..\/input\/iris-dataset\/iris.data.csv\")\ncvs_Evaluate_kNN_Algorithm(dataset, class_mappings)\n","987fb30f":"<style>\n  .custom-images-style {\n    display: flex;\n    justify-content: center;\n    align-content: stretch;\n    flex-wrap: wrap;\n    flex-direction: row;\n    text-decoration: none !important;\n  }\n  .custom-images-style img {\n    margin-right: 5px;\n    margin-left: 5px;\n    margin-bottom: 10px;\n  }\n<\/style>","cead0ce2":"## Resources & References","00debd49":"### Evaluate kNN Algorithm: Using Cross-Validation Split Method ","0bf70f08":"## kNN Algorithm\n\nNext, we implement the algorithm itself in a main function `kNN_Algorithm` that calls several child functions.  ","d68c5f99":"The flowchart for implementing the kNN algorithm is shown below. Each step in the implementation will be wrapped in its own function for clarity.\n\n![kNN Flowchart](https:\/\/raw.githubusercontent.com\/Outsiders17711\/Mein.Platz\/main\/images\/ipynb\/knn_flowchart.png)","c45d639b":"---","41304abc":"---","2a5b165e":"## DataLoader\n\nThe dataset is contained in a .csv file. We will implement a function `DataLoader` that calls several child functions to load and cleanup the data.","16c863ce":"---","34e1a476":"## Evaluate kNN Algorithm\n\nNow, we can go ahead and evaluate the performance of the algorithm against the dataset. The evaluation will be implemented using the function `Evaluate_kNN_Algorithm` which calls several child functions to split the dataset into test\/train samples and calculate accuracies.  ","97dbe3ac":"---","d03135d9":"---","5c79b117":"# k-Nearest Neighbours From Scratch","263f17be":"---","aa679511":"-  [Develop k-Nearest Neighbors in Python From Scratch - Machine Learning Mastery](https:\/\/machinelearningmastery.com\/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch\/)\n\n-  [K Nearest Neighbors Algorithm using Python From Absolute Scratch - The Nerdy Dev](https:\/\/www.youtube.com\/watch?v=uclqpQe8TMQ)","80dbcdff":"---","7dc09b99":"### Evaluate kNN Algorithm: Using Test-Train Split Method ","f312d1e8":"# kNN From Scratch: Iris Dataset\n> A step-by-step implementation of the k-Nearest Neighbours and Linear Regression algorithms using the standard Python libaries.\n\n\nThe detailed breakdown and explanation of the code and concepts in this notebook can be found in this [post](https:\/\/outsiders17711.github.io\/Mein.Platz\/kNN-Linear-Regression-Iris_Dataset\/) at my personal [blog](https:\/\/outsiders17711.github.io\/Mein.Platz\/).\n\nI hope you find it useful."}}