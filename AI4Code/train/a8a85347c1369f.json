{"cell_type":{"b7f71627":"code","b6e860de":"code","4fe9c511":"code","cf49f564":"code","adf06a12":"code","efeef7ff":"code","ee29f68b":"code","f9e48407":"code","77bcf84a":"code","9155f7c1":"code","2039b473":"code","3f115328":"code","e129905a":"code","12e615e9":"code","88ed064b":"code","4baf03d8":"code","91d02c0f":"code","36f99ba1":"code","e88fee21":"code","853845b3":"code","9c985b84":"code","e4de2bad":"code","6e5f5099":"markdown","aaf1d204":"markdown"},"source":{"b7f71627":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom lightgbm import LGBMClassifier\nimport seaborn as sns","b6e860de":"# \u4e00\u89a7\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\norigin_path = \"..\/input\/data-science-spring-osaka-2021\/\"\nbase_path = \"..\/input\/makedatayaw\/\"\ntrain_path = 'train.csv'\ntest_path = 'test.csv'\naction_path = 'actions.csv'\ntest_train_path = \"..\/input\/make-data-fork-of-fork-of-proba-model\/submission_confidence.csv\"\ndf_train = pd.read_csv(origin_path+train_path)\ndf_test = pd.read_csv(origin_path+test_path)\ndf_action = pd.read_csv(origin_path+action_path)\ndf_train_test = pd.read_csv(test_train_path)","4fe9c511":"df_train_test = df_train_test[df_train_test[\"conf\"] > 0.999 ]\nlen(df_train_test)","cf49f564":"df_train = pd.concat([df_train,df_train_test]).reset_index(drop=True)\ndf_train","adf06a12":"action_ = df_action[\"action_seq\"].unique()\ntrain_action = df_train[\"action_seq\"].unique()\nunseen_label = set(train_action) ^ set(action_)\n(unseen_label) # unseen label ","efeef7ff":"sns.countplot(y=\"action_seq\", data=df_train)","ee29f68b":"def add_describe_as_features(row):\n    file_path = row['file_path']\n    df = pd.read_csv(base_path + file_path)\n    df = df[df[\"Time\"] >=1000]    \n    s = df.describe().unstack(1)\n    return s.tolist()","f9e48407":"# \u30ab\u30e9\u30e0\u540d\u306e\u30ea\u30b9\u30c8\u3092\u6e96\u5099\u3001\u6700\u521d\u306e\u6700\u5f8c\u3092\u307f\u308b\ndf = pd.read_csv(base_path + 'test\/test_0000.csv')\nlist_columns = ['_'.join(idx).strip() for idx in df.describe().unstack(1).index]\nlist_columns[:5]+list_columns[-5:]","77bcf84a":"# \u4e0a\u8a18\u51e6\u7406\u3092\u9069\u7528\u3057\u307e\u3059\ndf_train[list_columns] = df_train.apply(add_describe_as_features, axis=1, result_type='expand')\ndf_test[list_columns] = df_test.apply(add_describe_as_features, axis=1, result_type='expand')","9155f7c1":"# \u7279\u5fb4\u91cf\uff08=\u8aac\u660e\u5909\u6570\uff09\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\uff08\u88ab\u8aac\u660e\u5909\u6570\uff09\u306b\u5206\u5272\u3057\u3066\u304a\u304d\u307e\u3059\ny_train = df_train.action_seq\nX_train = df_train.drop(['file_path', 'action_seq','conf'], axis=1)\nX_test = df_test.drop(['file_path'], axis=1)","2039b473":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\u3057\u3066\u304a\u304d\u307e\u3059\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)","3f115328":"def incorrect(y_val, y_pred,y_pred_prob):\n    y_val = le.inverse_transform(y_val)\n    y_pred = le.inverse_transform(y_pred)\n    for (val,pred,prob) in zip(y_val, y_pred,y_pred_prob):\n        if val == pred:\n            pass\n        else:\n            print(val,pred,prob)","e129905a":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u3092\u691c\u5b9a\uff08\u7cbe\u5ea6\u8a55\u4fa1\uff09\u7528\u306b\u5207\u308a\u51fa\u3057\u307e\u3059\n# \u30db\u30fc\u30eb\u30c9\u30a2\u30a6\u30c8\u306b\u3088\u308b\u691c\u8a3c\u3092\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3078\u5909\u66f4\n# -----------------------------------\n# \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\n# -----------------------------------\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import KFold\n\n# \u5404fold\u306e\u30b9\u30b3\u30a2\u3092\u4fdd\u5b58\u3059\u308b\u30ea\u30b9\u30c8\nscores_accuracy = []\n\n# \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u30924\u3064\u306b\u5206\u5272\u3057\u3001\u3046\u30611\u3064\u3092\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3068\u3059\u308b\u3053\u3068\u3092\u3001\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3092\u5909\u3048\u3066\u7e70\u308a\u8fd4\u3059\nkf = KFold(n_splits=4, shuffle=True, random_state=71)\nfor tr_idx, va_idx in kf.split(X_train):\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\n    X_train_, X_val = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n    y_train_, y_val = y_train[tr_idx], y_train[va_idx]\n    \n    # \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u884c\u3046\n    model = LGBMClassifier(learning_rate=0.03, n_estimators=50000)\n    model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], eval_metric='logloss', early_stopping_rounds=50,verbose=False)\n    # \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u5024\u3092\u78ba\u7387\u3067\u51fa\u529b\u3059\u308b\n    y_pred = model.predict(X_val)\n    y_pred_prob = model.predict_proba(X_val)\n    # \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3067\u306e\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\n    incorrect(y_val, y_pred,np.max(y_pred_prob, axis=1))\n    accuracy = accuracy_score(y_val, y_pred)\n    print(f'accuracy: {accuracy:.4f}')\n    # \u305d\u306efold\u306e\u30b9\u30b3\u30a2\u3092\u4fdd\u5b58\u3059\u308b\n    scores_accuracy.append(accuracy)\n\n# \u5404fold\u306e\u30b9\u30b3\u30a2\u306e\u5e73\u5747\u3092\u51fa\u529b\u3059\u308b\naccuracy = np.mean(scores_accuracy)\nprint(f'CV mean accuracy: {accuracy:.4f}')","12e615e9":"# \u5168\u30c7\u30fc\u30bf\u3067\u518d\u5b66\u7fd2\u3057\u3066\u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\nbest_iter = model.best_iteration_\nmodel = LGBMClassifier(learning_rate=0.03, n_estimators=best_iter)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","88ed064b":"y_pred_prob = model.predict_proba(X_test)\ntemp = []\nfor i,pred in enumerate(y_pred_prob):\n    temp.append(np.max(pred))\nplt.hist(temp, bins=20)","4baf03d8":"df_sub = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/sample_submission.csv')\ndf_sub['action_seq'] = le.inverse_transform(y_pred)","91d02c0f":"sns.countplot(y=\"action_seq\", data=df_sub)","36f99ba1":"df_sub[\"conf\"] = temp","e88fee21":"# \u51fa\u529b\u3057\u3066\u63d0\u51fa\u3057\u307e\u3059\ndf_sub.to_csv('submission_conf.csv', index=False)","853845b3":"df_sub = df_sub.drop(['conf'], axis=1)\ndf_sub.to_csv('submission.csv', index=False)","9c985b84":"importances = DataFrame(model.feature_importances_, index=X_train.columns, columns=['importance'])\nimportances.sort_values(['importance'], ascending=False, inplace=True)","e4de2bad":"# \u5f71\u97ff\u304c\u3042\u308b\u7279\u5fb4\u91cf\nplt.figure(figsize=[6,10])\nplt.title('Feature Importance')\nplt.barh(importances.index[:10], importances.importance[:10])\nplt.xlabel('importance')\nplt.show()","6e5f5099":"### 3rd ","aaf1d204":"sub\u306e\u4e2d\u304b\u3089\u78ba\u5b9f\u306bunseenlabel\u3067\u3042\u308b\u3082\u306e\u3060\u3051\u53d6\u308a\u51fa\u3059"}}