{"cell_type":{"b6570411":"code","187b1b3e":"code","56cc2491":"code","1b87c273":"code","12c525a5":"code","9f07cde4":"code","1136b42b":"code","75d96e00":"code","27c32ed3":"code","252adf99":"code","9699a5e2":"code","cb1911c6":"code","b8ad9c26":"code","21d5fcf3":"code","5ab06b89":"code","2b1cdd5f":"code","fbd609cf":"code","0ebddd81":"code","2fb5f6c4":"code","4acc47bc":"code","20d970c7":"code","8af886eb":"code","728f3f62":"code","8cddd7f6":"code","e0bea036":"code","f0b4233b":"code","0f219f77":"markdown","d8b09c40":"markdown","5b7929ea":"markdown","ba5a18e8":"markdown","127b2e11":"markdown","6f8f71ab":"markdown","cea7120e":"markdown","37b39f7d":"markdown","89e01d75":"markdown","5a3aace5":"markdown","5ad31385":"markdown","f55402d9":"markdown"},"source":{"b6570411":"#import basic libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","187b1b3e":"#read the file\ndf = pd.read_csv(\"..\/input\/south-german-credit-updated\/german_credit.csv\")\ndf.head()","56cc2491":"#check dataset's size\ndf.shape","1b87c273":"df[\"credit_risk\"].value_counts()","12c525a5":"#Is there any duplicate value in the dataset?\ndf.duplicated().value_counts()","9f07cde4":"#Is there any null value in the dataset?\ndf.isna().sum()","1136b42b":"#How many columns does this dataset have?\ndf.columns","75d96e00":"df.info()","27c32ed3":"dataset = df.drop([\"duration\",\"amount\",\"age\"],1)\ndataset.columns","252adf99":"from sklearn.preprocessing import LabelEncoder\n\nfor x in dataset.columns:\n    dataset[x] = LabelEncoder().fit_transform(dataset[x])\n\ndataset.head()","9699a5e2":"feature_x = dataset[['status', 'credit_history', 'purpose', 'savings',\n       'employment_duration', 'installment_rate', 'personal_status_sex',\n       'other_debtors', 'present_residence', 'property',\n       'other_installment_plans', 'housing', 'number_credits', 'job', 'people_liable',\n       'telephone', 'foreign_worker']]\nfeature_y = dataset[[\"credit_risk\"]]","cb1911c6":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\ndef best_features(X_train,y_train,X_test):\n    fs = SelectKBest(score_func = f_classif, k=\"all\")\n    fs.fit(X_train,y_train)\n    X_train_fs = fs.transform(X_train)\n    X_test_fs = fs.transform(X_test)\n    return X_train_fs,X_test_fs,fs","b8ad9c26":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(feature_x,feature_y,test_size=0.33,random_state=21)\nX_train_fs,X_test_fs,fs = best_features(X_train,np.ravel(y_train),X_test)","21d5fcf3":"# what are scores for the features\nfor i in range(len(fs.scores_)):\n\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\nplt.bar([i for i in range(len(fs.scores_))], fs.scores_)\nplt.show()","5ab06b89":"train_x = dataset[['status', 'credit_history', 'purpose', 'savings','personal_status_sex',\n              'property','other_installment_plans', 'housing','job','foreign_worker']]\ntrain_y = dataset[[\"credit_risk\"]]","2b1cdd5f":"X_train_lr,X_test_lr,y_train_lr,y_test_lr = train_test_split(train_x,train_y,test_size=0.33,random_state=21)","fbd609cf":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver='liblinear')\nfit = lr.fit(X_train_lr,np.ravel(y_train_lr))\nfit","0ebddd81":"yhat = fit.predict(X_test_lr)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test_lr, yhat)\nprint(confusion_matrix)","2fb5f6c4":"from sklearn.metrics import classification_report\nprint(classification_report(y_test_lr, yhat))","4acc47bc":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE()","20d970c7":"X_train_smote,y_train_smote = smote.fit_sample(train_x,train_y)","8af886eb":"print(\"Before SMOTE: \", train_y[\"credit_risk\"].value_counts())","728f3f62":"print(\"After SMOTE: \", y_train_smote[\"credit_risk\"].value_counts())","8cddd7f6":"lr.fit(X_train_smote,np.ravel(y_train_smote))\ny_pred2 = lr.predict(X_test_lr)\nprint(classification_report(y_test_lr, y_pred2))","e0bea036":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel=\"poly\",degree=10)\nsvclassifier.fit(X_train_smote,np.ravel(y_train_smote))","f0b4233b":"yhat_svm = svclassifier.predict(X_test_lr)\nprint(classification_report(y_test_lr, yhat_svm))","0f219f77":"### Classification - Logistic Regression","d8b09c40":"## Data Cleaning and Preparation","5b7929ea":"There is not any null value in the dataset.","ba5a18e8":"Although I applied SMOTE() and reapplied the train sets, the regression model didn't perform well enough. Therefore, I will try another classification model","127b2e11":"Dataset is imbalanced due to that it has more \"good\" values (for credit_risk column) than \"bad\" values. This imbalance may cause us to make weak predictions.","6f8f71ab":"There is not any duplicate value in the dataset.","cea7120e":"Majority of this dataset consists of categorical values and I plan to use some classification models to predict the credit risk. Therefore, I will need to drop some of the variables that aren't categorical and then, I will convert them to numerical labels with **LabelEncoder()**: ","37b39f7d":"As we mentioned earlier, due to that the dataset is imbalanced, our prediction model may not perform well. In order to solve this, we will oversample our data with SMOTE method","89e01d75":"## Classification ","5a3aace5":"### Logistic Regression with SMOTE","5ad31385":"### Feature Selection","f55402d9":"### Support Vector Machine"}}