{"cell_type":{"1ad12aef":"code","fc42decd":"code","41f99b11":"code","d72c9ef2":"code","a2f38850":"code","60f5ad82":"code","0d0cb43c":"code","09f83bcd":"code","a19597af":"code","4eec5d22":"code","d244f6fd":"code","8e9e8b5b":"code","2a7ec1d8":"code","489d5452":"code","6e165a69":"code","3d47444c":"code","e9b55381":"code","d7124455":"code","627e00c6":"code","4b00fd1a":"code","bf3571c9":"code","6682041a":"code","0b5a4382":"code","e89ab48f":"code","111e903d":"code","7b16e22e":"code","c56efd98":"code","373178c6":"code","d1f8a719":"code","c9a347f0":"code","a6d1204f":"code","1b077bf3":"code","754ed263":"code","0c88258e":"code","b263b017":"code","23a78d5f":"code","545fe0b6":"code","5f9dc50f":"code","ef1bced4":"code","09837bbf":"code","17b7f1b5":"code","5313f9bb":"code","10a492bd":"code","10008b04":"code","8ed905fb":"markdown","c50dfe1f":"markdown","42ae75bb":"markdown","9ebf899b":"markdown","b3040c63":"markdown","1a2625e0":"markdown","bd862ff4":"markdown","25074c2d":"markdown","758f091d":"markdown","e4fb80d9":"markdown","62f1d6f2":"markdown","b95c2ee4":"markdown","f5b62d5a":"markdown","dd8a654f":"markdown","d9cda6e9":"markdown","9f0b9ea1":"markdown","7d62fb2b":"markdown","a3b6db2f":"markdown","79ee07d6":"markdown","250ec432":"markdown","6cdfb4bd":"markdown","19a53dee":"markdown","d54323e8":"markdown","0fe2b0ed":"markdown","97a938cf":"markdown","d1fe9025":"markdown","79b30878":"markdown","128d90ef":"markdown","ea0e4beb":"markdown","bb2c454e":"markdown","dc3f21e3":"markdown","141808e7":"markdown","517a4d88":"markdown","484eba0f":"markdown","99f1837a":"markdown","10c9dd79":"markdown","0819f8cc":"markdown","2d5756d4":"markdown","7ede22bd":"markdown","ba2e45a4":"markdown","235acdfa":"markdown","ab5976b0":"markdown","ca57b6f9":"markdown","b8179494":"markdown","b813bf7d":"markdown","f61590f8":"markdown","d87636b9":"markdown","ddf68455":"markdown","3105985c":"markdown","ea0b2865":"markdown","8b65cd48":"markdown","9eb596c9":"markdown","5f10aeaf":"markdown","333ee846":"markdown","c304187c":"markdown","2e2887de":"markdown","0d4ccaeb":"markdown","e26be8c8":"markdown","cd381872":"markdown","6e745462":"markdown","10c04694":"markdown","cda8acad":"markdown","d9f3f240":"markdown","133c8b74":"markdown"},"source":{"1ad12aef":"# bibliotecas de an\u00e1lise dos dados\nimport numpy as np\nimport pandas as pd\n\n# bibliotecas de visualiza\u00e7\u00e3o\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\n# ignorar warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n","fc42decd":"treino = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nteste = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","41f99b11":"treino.info()\n","d72c9ef2":"# Descri\u00e7\u00e3o breve do nosso dataset\ntreino.describe(include = 'all')","a2f38850":"# Passageiros que sobreviveram separados pelo sexo\nsns.barplot(x='Sex', y='Survived', data=treino)\nprint(\"Porcentagem de mulheres que sobreviveram: {}\".format( treino[\"Survived\"][treino[\"Sex\"] == 'female'].value_counts(normalize=True)[1]*100))\nprint(\"Porcentagem de homens que sobreviveram: {}\".format( treino[\"Survived\"][treino[\"Sex\"] == 'male'].value_counts(normalize=True)[1]*100))","60f5ad82":"# gr\u00e1fico de barras para o N\u00famero de SibSp vs Survival\nsns.barplot(x='SibSp', y='Survived', data=treino)\n\nprint(\"porcentagem de SibSp = 0 que sobreviveram: {}\".format(treino[\"Survived\"][treino[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100))\nprint(\"porcentagem de SibSp = 1 que sobreviveram: {}\".format(treino[\"Survived\"][treino[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100))\nprint(\"porcentagem de SibSp = 2 que sobreviveram: {}\".format(treino[\"Survived\"][treino[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100))\nprint(\"porcentagem de SibSp = 3 que sobreviveram: {}\".format(treino[\"Survived\"][treino[\"SibSp\"] == 3].value_counts(normalize = True)[1]*100))\nprint(\"porcentagem de SibSp = 4 que sobreviveram: {}\".format(treino[\"Survived\"][treino[\"SibSp\"] == 4].value_counts(normalize = True)[1]*100))","0d0cb43c":"sns.barplot(x=\"Parch\", y=\"Survived\", data=treino)","09f83bcd":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=treino)\nprint(\"Porcentagem de pessoas da 1\u00aa classe que sobreviveram: {}\".format(treino['Survived'][treino['Pclass'] == 1].value_counts(normalize=True)[1]*100))\nprint(\"Porcentagem de pessoas da 2\u00aa classe que sobreviveram: {}\".format(treino['Survived'][treino['Pclass'] == 2].value_counts(normalize=True)[1]*100))\nprint(\"Porcentagem de pessoas da 3\u00aa classe que sobreviveram: {}\".format(treino['Survived'][treino['Pclass'] == 3].value_counts(normalize=True)[1]*100))\n      ","a19597af":"treino['Title'] = treino.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\nteste['Title'] = teste.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","4eec5d22":"titulos_dict = {\n    'Capt': 'Officer',\n    'Col': 'Officer',\n    'Major': 'Officer',\n    'Jonkheer': 'Royalty',\n    'Don': 'Royalty',\n    'Sir': 'Royalty',\n    'Dr': 'Officer',\n    'Rev': 'Officer',\n    'the Countess': 'Royalty',\n    'Mme': 'Mrs',\n    'Mile': 'Miss',\n    'Ms': 'Mrs',\n    'Mr': 'Mr',\n    'Mrs': 'Mrs',\n    'Miss': 'Miss',\n    'Master': 'Master',\n    'Lady': 'Royalty'\n}\n\ntreino['Title'] = treino['Title'].map(titulos_dict)\nteste['Title'] = teste['Title'].map(titulos_dict)\n","d244f6fd":"sns.barplot(x='Title', y='Survived', data=treino)","8e9e8b5b":"faixas_idade = [0, 5, 12, 18, 24, 60, np.inf]\nrotulos = ['Beb\u00ea', 'Crian\u00e7a', 'Adolescente', 'Jovem Adulto', 'Adulto', 'Idoso']\ntreino['AgeGroup'] = pd.cut(treino[\"Age\"], faixas_idade, labels = rotulos)\nteste['AgeGroup'] = pd.cut(teste[\"Age\"], faixas_idade, labels = rotulos)\nax = sns.barplot(x=\"AgeGroup\", y=\"Survived\", data=treino)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n\nplt.show()","2a7ec1d8":"treino['HasCabin'] = treino['Cabin'].notnull().astype('int')\nteste['HasCabin'] = teste['Cabin'].notnull().astype('int')\n\n#gr\u00e1fico de barras dos passageiros que tinham ou n\u00e3o cabine e sobreviveram\nsns.barplot(x='HasCabin', y=\"Survived\", data=treino)\n\nprint(\"Porcentagem de pessoas com cabine que sobreviveram: {}\".format(treino['Survived'][treino['HasCabin'] == 1].value_counts(normalize=True)[1]*100))\nprint(\"Porcentagem de pessoas sem cabine que sobreviveram: {}\".format(treino['Survived'][treino['HasCabin'] == 0].value_counts(normalize=True)[1]*100))","489d5452":"teste.describe(include=\"all\")","6e165a69":"treino = treino.drop(['Cabin'], axis = 1)\nteste = teste.drop(['Cabin'], axis = 1)","3d47444c":"treino = treino.drop(['Ticket'], axis = 1)\nteste = teste.drop(['Ticket'], axis = 1)","e9b55381":"print(\"Pessoas que embarcaram em Southampton:\")\nS = treino[treino[\"Embarked\"] == \"S\"].shape[0]\nprint(S)\n\nprint(\"Pessoas que embarcaram em Cherbourg:\")\nC = treino[treino[\"Embarked\"] == \"C\"].shape[0]\nprint(C)\n\nprint(\"Pessoas que embarcaram em Queenstown:\")\nQ = treino[treino[\"Embarked\"] == \"Q\"].shape[0]\nprint(Q)","d7124455":"treino = treino.fillna({\"Embarked\": \"S\"})\ntreino[\"Embarked\"].value_counts()","627e00c6":"embarked_map_dict = {\n    \"S\": 1,\n    \"C\": 2,\n    \"Q\": 3\n}\n\ntreino[\"Embarked\"] = treino[\"Embarked\"].map(embarked_map_dict)\nteste['Embarked'] = teste['Embarked'].map(embarked_map_dict)\n\ntreino.head()","4b00fd1a":"treino_agrupado = treino.groupby(['Sex','Pclass','Title']).median()\ntreino_agrupado = treino_agrupado.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]","bf3571c9":"treino_agrupado.head()","6682041a":"def preencher_idade(linha):\n    condicao = (\n        (treino_agrupado['Sex'] == linha['Sex']) &\n        (treino_agrupado['Title'] == linha['Title']) &\n        (treino_agrupado['Pclass'] == linha['Pclass'])\n    )\n\n    if np.isnan(treino_agrupado[condicao]['Age'].values[0]):\n        condicao = (\n            (treino_agrupado['Sex'] == linha['Sex']) &\n            (treino_agrupado['Pclass'] == linha['Pclass'])\n        )\n    \n    return treino_agrupado[condicao]['Age'].values[0]\n\n\ntreino['Age'] = treino.apply(lambda linha: preencher_idade(linha) if np.isnan(linha['Age']) else linha['Age'], axis=1)\nteste['Age'] = teste.apply(lambda linha: preencher_idade(linha) if np.isnan(linha['Age']) else linha['Age'], axis=1)","0b5a4382":"treino['AgeGroup'] = pd.cut(treino[\"Age\"], faixas_idade, labels = rotulos)\nteste['AgeGroup'] = pd.cut(teste[\"Age\"], faixas_idade, labels = rotulos)","e89ab48f":"agegroup_map_dict = {\n    'Adulto': 1,\n    'Jovem Adulto': 2,\n    'Adolescente': 3,\n    'Beb\u00ea': 4,\n    'Crian\u00e7a': 5,\n    'Idoso': 6\n}\n\ntreino['AgeGroup'] = treino['AgeGroup'].map(agegroup_map_dict)\nteste['AgeGroup'] = teste['AgeGroup'].map(agegroup_map_dict)\n\ntreino.drop('Age', axis = 1, inplace=True)\nteste.drop('Age', axis = 1, inplace=True)","111e903d":"titulos_map_dict = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Officer': 5, 'Royalty': 6}\ntreino['Title'] = treino['Title'].map(titulos_map_dict)\nteste['Title'] = teste['Title'].map(titulos_map_dict)\n\ntreino['Title'] = treino['Title'].fillna(0)\nteste['Title'] = teste['Title'].fillna(0)","7b16e22e":"treino.drop('Name', axis=1, inplace=True)\nteste.drop('Name', axis=1, inplace=True)","c56efd98":"sexo_map_dict = {'female': 0, 'male': 1}\ntreino['Sex'] = treino['Sex'].map(sexo_map_dict)\nteste['Sex'] = teste['Sex'].map(sexo_map_dict)","373178c6":"treino.head()","d1f8a719":"treino['Fare'] = pd.Series.round(treino['Fare'], 4)\nteste['Fare'] = pd.Series.round(teste['Fare'], 4)\n        \ntreino['FareGroup'] = pd.qcut(treino['Fare'], 4, labels = [1, 2, 3, 4])\nteste['FareGroup'] = pd.qcut(teste['Fare'], 4, labels = [1, 2, 3, 4])\nteste['FareGroup'] = teste['FareGroup'].fillna(1)\n\ntreino.drop('Fare', axis = 1, inplace = True)\nteste.drop('Fare', axis = 1, inplace = True)","c9a347f0":"treino.head()\n","a6d1204f":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n","1b077bf3":"from sklearn.model_selection import train_test_split\n\npredictors = treino.drop(['Survived', 'PassengerId'], axis=1)\ntarget = treino[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","754ed263":"gaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred = gaussian.predict(x_val)\nacc_gaussian = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gaussian)","0c88258e":"logreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_logreg)","b263b017":"svc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc)","23a78d5f":"linear_svc = LinearSVC()\nlinear_svc.fit(x_train, y_train)\ny_pred = linear_svc.predict(x_val)\nacc_linear_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_linear_svc)","545fe0b6":"perceptron = Perceptron()\nperceptron.fit(x_train, y_train)\ny_pred = perceptron.predict(x_val)\nacc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_perceptron)","5f9dc50f":"decisiontree = DecisionTreeClassifier()\ndecisiontree.fit(x_train, y_train)\ny_pred = decisiontree.predict(x_val)\nacc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_decisiontree)","ef1bced4":"randomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_val)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_randomforest)","09837bbf":"knn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_val)\nacc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_knn)","17b7f1b5":"sgd = SGDClassifier()\nsgd.fit(x_train, y_train)\ny_pred = sgd.predict(x_val)\nacc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_sgd)","5313f9bb":"gbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_val)\nacc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gbk)","10a492bd":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n    'Score': [acc_svc, acc_knn, acc_logreg, \n              acc_randomforest, acc_gaussian, acc_perceptron,acc_linear_svc, acc_decisiontree,\n              acc_sgd, acc_gbk]})\nmodels.sort_values(by='Score', ascending=False)","10008b04":"ids = teste['PassengerId']\npredictions = knn.predict(teste.drop('PassengerId', axis=1))\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","8ed905fb":"Passageiros viajando na primeira classe tem chances maiores de sobreviver do que os que viajam nas classes inferiores.","c50dfe1f":"### Definindo o conjunto de treino e de teste","42ae75bb":"Antes de realizar o tratamento dos dados faltantes, n\u00f3s podemos retirar do nosso dataset as features que n\u00e3o nos trazem de fato alguma informa\u00e7\u00e3o relevante.","9ebf899b":"### Name Feature","b3040c63":"## 1. Importa\u00e7\u00e3o das bibliotecas do python \n\nAntes de tudo, \u00e9 necess\u00e1rio importar as bibliotecas do python que utilizaremos para an\u00e1lisar e predizer o conjunto de dados do titanic.\n","1a2625e0":"Uma informa\u00e7\u00e3o de valor que pode ser retirada dos nomes dos passageiros s\u00e3o seus t\u00edtulos, como senhor (Mr.), senhora (Mrs.), entre outros. Faremos isso no c\u00f3digo a seguir","bd862ff4":"Agora que retiramos as features que n\u00e3o vamos usar. Podemos preencher os dados faltantes.","25074c2d":"Podemos tamb\u00e9m utilizar algumas func\u00f5es do pandas para entender melhor nosso conjunto de dados, como `describe()` e `info()`","758f091d":"### Gaussian Naive Bayes","e4fb80d9":"# Predi\u00e7\u00e3o dos Sobreviventes do Titanic \n\n#### Conte\u00fado:\n\n 1. Importa\u00e7\u00e3o das bibliotecas do python\n 2. Leitura e An\u00e1lise dos Dados\n 3. Visualiza\u00e7\u00e3o dos Dados\n 4. Limpeza dos Dados\n 5. Escolhendo o Melhor Modelo\n \n ","62f1d6f2":"Com isso podemos assumir que os passageiros que tem suas cabines registradas no conjunto de dados tem mais probabilidade de sobreviver do que os que n\u00e3o tem\n","b95c2ee4":"### Age Feature","f5b62d5a":"### Cabin Feature\n","dd8a654f":"Preenchida a idade, podemos atualizar a feature AgeGroup, que criamos para visualizar os grupos de idades e, posteriormente, mapear seus valores para num\u00e9ricos. Feito isso, deletaremos nossa feature idade e poderemos usar apenas o AgeGroup","d9cda6e9":"### Stochastic Gradient Descent","9f0b9ea1":"Assim como fizemos com as idades, precisamos definir faixas de valores para a taxa paga pelos passageiros para criar grupos. Antes, vamos arredondar todos os valores existentes na nossa feature baseado na sua classe.","7d62fb2b":"### Cabin Feature\n","a3b6db2f":"Vamos ver como estam nossos dados de teste:\n    ","79ee07d6":"### Support Vector Machines","250ec432":"\u00c9 possivel perceber que a maioria dos passageiros embarcou em Southampton. Sendo assim, podemos usar o valor desse porto nos dados faltantes, sendo que \u00e9 o mais comum.","6cdfb4bd":"### Logistic Regression","19a53dee":"### Ticket Feature","d54323e8":"Agora, com os valores agrupados, n\u00f3s podemos substituir as idades dos passageiros que faltam baseados no seu sexo, t\u00edtulo e classe.","0fe2b0ed":"Observamos que a maior probabilidade de sobreviv\u00eancia est\u00e1 entre as mulheres (Mrs, Miss), seguido pelos mestres e a realeza. Oficiais e os homens s\u00e3o os que possuem a taxa de sobrevivencia mais baixa\n","97a938cf":"### KNN or k-Nearest Neighbors","d1fe9025":"Podemos ver que os bebes foram os passageiros que mais tem probabilidade de sobreviver, seguido pelos adolescentes. Jovens adultos, adultos e crian\u00e7as tiveram uma taxa de sobreviv\u00eancia parecida. J\u00e1 os idosos foram os que menos sobreviveram.","79b30878":"### Name Feature\n","128d90ef":"### Random Forest","ea0e4beb":"### Perceptron","bb2c454e":"Agora que preenchemos todos os valores, vamos transforma-los em valores num\u00e9ricos.","dc3f21e3":"Levando em considera\u00e7\u00e3o que a idade possui muitos valores omissos, substitu\u00ed-los pela m\u00e9dia ou mediana de todas as idades talvez n\u00e3o seja a melhor abordagem. Para tratar essa feature, n\u00f3s vamos agrupar as m\u00e9dias de idade por sexo, t\u00edtulo e classe\n","141808e7":"### Decision Tree","517a4d88":"## 2. Leitura e An\u00e1lise Explorat\u00f3ria\n\nPara iniciar a nossa an\u00e1lise, precisamos realizar a leitura dos datasets de treino e teste usando a fun\u00e7\u00e3o `pd.read_csv()` do pandas, anteriormente importado.\n","484eba0f":"## 5. Escolhendo o Melhor Modelo","99f1837a":"### Refer\u00eancias:\n* [Titanic Survival Predictions](https:\/\/www.kaggle.com\/gabrielvcampos\/titanic-survival-predictions-beginner\/edit)\n* [Kaggle Titanic: Machine Learning model (top 7%)](https:\/\/towardsdatascience.com\/kaggle-titanic-machine-learning-model-top-7-fa4523b7c40)\n\nFeedbacks s\u00e3o bem-vindos ! ","10c9dd79":"Podemos perceber claramente com o gr\u00e1fico acima que mulheres s\u00e3o mais provaveis de sobreviver do que homens","0819f8cc":"   ### Importando as bibliotecas necess\u00e1rias ","2d5756d4":"Ap\u00f3s reduzir o n\u00famero de t\u00edtulos de 17 para 6, vamos agora criar um gr\u00e1fico que demonstre a porcentagem de sobreviventes de cada um desses t\u00edtulos.","7ede22bd":"### Sex Feature","ba2e45a4":"Com esse gr\u00e1fico, tamb\u00e9m podemos observar que o n\u00famero de pessoas com menos de 5 irm\u00e3os ou conjulgues tem uma probabilidade maior de sobreviver\ndo que passageiros com mais de 4 irm\u00e3os ou conjulgues.\n","235acdfa":"### Parch Feature","ab5976b0":"* Temos um total de 418 passageiros nos nossos dados de teste\n* 1 dos valores de tarifa (Fare) est\u00e3o faltando \n* 86 dados sobre a idade tamb\u00e9m est\u00e3o omissos (Cerca de 20.5%). N\u00f3s vamos precisar preencher esses valores.\n","ca57b6f9":"### Gradient Boosting Classifier","b8179494":"### SibSp Feature\n\n","b813bf7d":"### Linear SVC","f61590f8":"Para ter uma vis\u00e3o melhor da idade dos passageiros, vamos dividi-los em grupos de idade para saber qual foi a porcentagem de sobreviventes em cada um. ","d87636b9":" - **Features Num\u00e9ricas:** Age(Cont\u00ednua), Fare(Cont\u00ednua), SibSp(Discreta), Parch(Discreta)\n - **Features Categ\u00f3ricas:** Survived, Sex, Embarked, Pclass, Ticket, Cabin\n \nBreve descri\u00e7\u00e3o e tipo de dados das features:\n \n \n * **Survival (Int):** Informa 1 se o passageiro sobreviveu e 0 caso n\u00e3o.\n * **Pclass (Int):** Classe do passageiro (1 = 1\u00aa classe; 2 = 2\u00aa classe; 3 = 3\u00aa classe)\n * **Name (string):** Nome do passageiro\n * **Sex (string):** Sexo do passageiro\n * **Age (float):** Idade do passageiro\n * **SibSp (int):** sigla para \"Siblings\/Spouses\", ou seja, o n\u00famero de irm\u00e3os e parceiros conjulgais que o passageiro tinha consigo a bordo do navio. Contam-se tamb\u00e9m a quantidade de meio-irm\u00e3os e meio-irm\u00e3s.\n * **Parch (int):** sigla para \"Parents\/Child\", ou seja, o n\u00famero de filhos, filhas pais e m\u00e3es que o passageiro levava consigo a bordo do navio. Contam-se tamb\u00e9m  a quantidade de padrastos e madrastas. \n * **Ticket (string):** N\u00famero do ticket da viagem.\n * **Fare (float):** valor da tarifa paga pelo passageiro na \u00e9poca em libras esterlinas.\n * **Cabin (string):** n\u00famero da cabine onde o passageiro ficou hospedado. \n * **Embarked (string):** Porto de embarque do passageiro (C = Cherbourg; Q = Queenstown; S = Southampton)\n \n \n Agora que sabemos exatamente o significado de cada uma das nossas features, podemos ver o quanto de informa\u00e7\u00e3o cada uma delas tem para nos dar.\n","ddf68455":"N\u00f3s vamos utilizar os seguintes modelos nos nossos dados de treino:\n\n* Gaussian Naive Bayes\n* Logistic Regression\n* Support Vector Machines\n* Perceptron\n* Decision Tree Classifier\n* Random Forest Classifier\n* KNN or k-Nearest Neighbors\n* Stochastic Gradient Descent\n* Gradient Boosting Classifier\n\nPara cada um dos modelos, iremos treina-lo com nosso dataset de treino, e testar seu desempenho com nosso dataset de teste.","3105985c":"### Embarked Feature","ea0b2865":"### Pclass Feature\n","8b65cd48":"### Fare Feature","9eb596c9":"Esse \u00e9 o momento de tratar os dados faltantes e informa\u00e7\u00f5es que podem atrapalhar nosso modelo de realizar alguma predi\u00e7\u00e3o no futuro. Tamb\u00e9m precisamos normalizar os dados para facilitar o entendimento do algoritmo do nosso modelo. Para isso, transformaremos todos os dados em variaveis numericas discretas.","5f10aeaf":"## 3. Visualiza\u00e7\u00e3o dos dados\n\nChegou o momento de usarmos alguns gr\u00e1ficos para entendermos melhor como nossas features est\u00e3o distribuidas e relacionadas.\n\n","333ee846":"Visualizando novamente o resultado do comando `treino.info()` executado acima, podemos fazer algumas observa\u00e7\u00f5es:\n\n* Existem 891 passageiros no nosso conjunto de treino\n* Est\u00e3o faltando 177 valores sobre a idade dos passageiros. (Cerca de 19,8%)\n* Est\u00e3o faltando 687 valores sobre a cabine dos passageiros. (cerca de 77.1%)\n* Est\u00e3o faltando 2 valores sobre o porto de embarque dos passageiros. (Cerca de 0.22%)","c304187c":"Assim como fizemos com as outras features, vamos transformar os valores de t\u00edtulos em n\u00fameros, mapeando-os.","2e2887de":"### Age Feature ","0d4ccaeb":"Agora que j\u00e1 extra\u00edmos o t\u00edtulo dos nomes, podemos deletar essa feature ","e26be8c8":"### Comparando a acur\u00e1cia de cada modelo","cd381872":"Passageiros com menos de 4 pais ou filhos a bordo tem mais chances de sobreviver. Al\u00e9m disso, quem est\u00e1 viajando sozinho tem menos chances de sobreviver do que os acompanhados. ","6e745462":"### Title Feature","10c04694":"### Sex Feature\n","cda8acad":"### Limpeza dos Dados\n","d9f3f240":"Como existem muitos dados de cabines faltantes, n\u00f3s podemos alterar essa feature e transforma-la em booleana. Isso significa que saber\u00edamos apenas se um passageiro possuia ou n\u00e3o cabine.","133c8b74":"### Criando um arquivo de submiss\u00e3o"}}