{"cell_type":{"7ed7e5c3":"code","ca67fb70":"code","d3bbd33d":"code","a97fbf77":"code","a9bdba3b":"code","26741905":"code","e22c7503":"code","ef02810c":"code","52489c43":"code","4fd9b1b8":"code","ab5a5624":"code","9543d641":"code","c6be0009":"code","9ddd88d7":"code","9956c577":"code","8c9819bf":"code","01eacc28":"code","feb7587f":"code","122bea93":"markdown","1be4e51e":"markdown","7b256007":"markdown","6a88ecba":"markdown","c30b2170":"markdown","4a18079a":"markdown","177e9988":"markdown","d9db6293":"markdown","7cf42f13":"markdown","c9b6dfaf":"markdown","28b93cd4":"markdown","2b77dd83":"markdown","a2ea7174":"markdown","fbeea434":"markdown","fd1688df":"markdown","aae0fbaa":"markdown"},"source":{"7ed7e5c3":"import collections\nimport os\nimport random\nimport time\nfrom tqdm import tqdm\nimport torch\nfrom torch import nn\nimport torchtext.vocab as Vocab\nimport torch.utils.data as Data\nimport torch.nn.functional as F\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","ca67fb70":"def read_imdb(folder='train', data_root=\"Datasets\/aclImdb\"):\n    data = []\n    for label in ['pos', 'neg']:\n        folder_name = os.path.join(data_root, folder, label)\n        for file in tqdm(os.listdir(folder_name)):\n            with open(os.path.join(folder_name, file), 'rb') as f:\n                review = f.read().decode('utf-8').replace('\\n', '').lower()\n                data.append([review, 1 if label == 'pos' else 0])\n    random.shuffle(data)\n    return data\n\nDATA_ROOT = \"..\/input\/imdbdatacorpus\/aclImdb_v1\"\ndata_root = os.path.join(DATA_ROOT, \"aclImdb\")\ntrain_data, test_data = read_imdb('train', data_root), read_imdb('test', data_root)\n\n# \u6253\u5370\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u524d\u4e94\u4e2asample\nfor sample in train_data[:5]:\n    print(sample[1], '\\t', sample[0][:50])","d3bbd33d":"def get_tokenized_imdb(data):\n    '''\n    @params:\n        data: \u6570\u636e\u7684\u5217\u8868\uff0c\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u4e3a [\u6587\u672c\u5b57\u7b26\u4e32\uff0c0\/1\u6807\u7b7e] \u4e8c\u5143\u7ec4\n    @return: \u5207\u5206\u8bcd\u540e\u7684\u6587\u672c\u7684\u5217\u8868\uff0c\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u4e3a\u5207\u5206\u540e\u7684\u8bcd\u5e8f\u5217\n    '''\n    def tokenizer(text):\n        return [tok.lower() for tok in text.split(' ')]\n    \n    return [tokenizer(review) for review, _ in data]\n\ndef get_vocab_imdb(data):\n    tokenized_data = get_tokenized_imdb(data)\n    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n    return Vocab.Vocab(counter, min_freq=5)\n\nvocab = get_vocab_imdb(train_data)\nprint('# words in vocab:', len(vocab))","a97fbf77":"def preprocess_imdb(data, vocab):\n    max_l = 500  # \u5c06\u6bcf\u6761\u8bc4\u8bba\u901a\u8fc7\u622a\u65ad\u6216\u8005\u88650\uff0c\u4f7f\u5f97\u957f\u5ea6\u53d8\u6210500\n\n    def pad(x):\n        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\n\n    tokenized_data = get_tokenized_imdb(data)\n    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n    labels = torch.tensor([score for _, score in data])\n    return features, labels","a9bdba3b":"train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\ntest_set = Data.TensorDataset(*preprocess_imdb(test_data, vocab))\n\n# \u4e0a\u9762\u7684\u4ee3\u7801\u7b49\u4ef7\u4e8e\u4e0b\u9762\u7684\u6ce8\u91ca\u4ee3\u7801\n# train_features, train_labels = preprocess_imdb(train_data, vocab)\n# test_features, test_labels = preprocess_imdb(test_data, vocab)\n# train_set = Data.TensorDataset(train_features, train_labels)\n# test_set = Data.TensorDataset(test_features, test_labels)\n\nbatch_size = 64\ntrain_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\ntest_iter = Data.DataLoader(test_set, batch_size)\n\nfor X, y in train_iter:\n    print('X', X.shape, 'y', y.shape)\n    break\nprint('#batches:', len(train_iter))","26741905":"class BiRNN(nn.Module):\n    def __init__(self, vocab, embed_size, num_hiddens, num_layers):\n        '''\n        @params:\n            vocab: \u5728\u6570\u636e\u96c6\u4e0a\u521b\u5efa\u7684\u8bcd\u5178\uff0c\u7528\u4e8e\u83b7\u53d6\u8bcd\u5178\u5927\u5c0f\n            embed_size: \u5d4c\u5165\u7ef4\u5ea6\u5927\u5c0f\n            num_hiddens: \u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u5927\u5c0f\n            num_layers: \u9690\u85cf\u5c42\u4e2a\u6570\n        '''\n        super(BiRNN, self).__init__()\n        self.embedding = nn.Embedding(len(vocab), embed_size)\n        \n        # bidirectional\u8bbe\u4e3aTrue\u5373\u5f97\u5230\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\n        self.encoder = nn.LSTM(input_size=embed_size, \n                                hidden_size=num_hiddens, \n                                num_layers=num_layers,\n                                bidirectional=True)\n        self.decoder = nn.Linear(4*num_hiddens, 2) # \u521d\u59cb\u65f6\u95f4\u6b65\u548c\u6700\u7ec8\u65f6\u95f4\u6b65\u7684\u9690\u85cf\u72b6\u6001\u4f5c\u4e3a\u5168\u8fde\u63a5\u5c42\u8f93\u5165\n\n    def forward(self, inputs):\n        '''\n        @params:\n            inputs: \u8bcd\u8bed\u4e0b\u6807\u5e8f\u5217\uff0c\u5f62\u72b6\u4e3a (batch_size, seq_len) \u7684\u6574\u6570\u5f20\u91cf\n        @return:\n            outs: \u5bf9\u6587\u672c\u60c5\u611f\u7684\u9884\u6d4b\uff0c\u5f62\u72b6\u4e3a (batch_size, 2) \u7684\u5f20\u91cf\n        '''\n        # \u56e0\u4e3aLSTM\u9700\u8981\u5c06\u5e8f\u5217\u957f\u5ea6(seq_len)\u4f5c\u4e3a\u7b2c\u4e00\u7ef4\uff0c\u6240\u4ee5\u9700\u8981\u5c06\u8f93\u5165\u8f6c\u7f6e\n        embeddings = self.embedding(inputs.permute(1, 0)) # (seq_len, batch_size, d)\n        # rnn.LSTM \u8fd4\u56de\u8f93\u51fa\u3001\u9690\u85cf\u72b6\u6001\u548c\u8bb0\u5fc6\u5355\u5143\uff0c\u683c\u5f0f\u5982 outputs, (h, c)\n        outputs, _ = self.encoder(embeddings) # (seq_len, batch_size, 2*h)\n        encoding = torch.cat((outputs[0], outputs[-1]), -1) # (batch_size, 4*h)\n        outs = self.decoder(encoding) # (batch_size, 2)\n        return outs\n\nembed_size, num_hiddens, num_layers = 100, 100, 2\nnet = BiRNN(vocab, embed_size, num_hiddens, num_layers)","e22c7503":"glove_vocab = Vocab.GloVe(name='6B', dim=100)\n\ndef load_pretrained_embedding(words, pretrained_vocab):\n    '''\n    @params:\n        words: \u9700\u8981\u52a0\u8f7d\u8bcd\u5411\u91cf\u7684\u8bcd\u8bed\u5217\u8868\uff0c\u4ee5 itos (index to string) \u7684\u8bcd\u5178\u5f62\u5f0f\u7ed9\u51fa\n        pretrained_vocab: \u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\n    @return:\n        embed: \u52a0\u8f7d\u5230\u7684\u8bcd\u5411\u91cf\n    '''\n    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # \u521d\u59cb\u5316\u4e3a0\n    oov_count = 0 # out of vocabulary\n    for i, word in enumerate(words):\n        try:\n            idx = pretrained_vocab.stoi[word]\n            embed[i, :] = pretrained_vocab.vectors[idx]\n        except KeyError:\n            oov_count += 1\n    if oov_count > 0:\n        print(\"There are %d oov words.\" % oov_count)\n    return embed\n\nnet.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\nnet.embedding.weight.requires_grad = False # \u76f4\u63a5\u52a0\u8f7d\u9884\u8bad\u7ec3\u597d\u7684, \u6240\u4ee5\u4e0d\u9700\u8981\u66f4\u65b0\u5b83","ef02810c":"def evaluate_accuracy(data_iter, net, device=None):\n    if device is None and isinstance(net, torch.nn.Module):\n        device = list(net.parameters())[0].device \n    acc_sum, n = 0.0, 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            if isinstance(net, torch.nn.Module):\n                net.eval()\n                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n                net.train()\n            else:\n                if('is_training' in net.__code__.co_varnames):\n                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n                else:\n                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n            n += y.shape[0]\n    return acc_sum \/ n\n\ndef train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n    net = net.to(device)\n    print(\"training on \", device)\n    batch_count = 0\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n        for X, y in train_iter:\n            X = X.to(device)\n            y = y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y) \n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.cpu().item()\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n            n += y.shape[0]\n            batch_count += 1\n        test_acc = evaluate_accuracy(test_iter, net)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n              % (epoch + 1, train_l_sum \/ batch_count, train_acc_sum \/ n, test_acc, time.time() - start))","52489c43":"lr, num_epochs = 0.01, 5\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\nloss = nn.CrossEntropyLoss()\n\ntrain(train_iter, test_iter, net, loss, optimizer, device, num_epochs)","4fd9b1b8":"def predict_sentiment(net, vocab, sentence):\n    '''\n    @params\uff1a\n        net: \u8bad\u7ec3\u597d\u7684\u6a21\u578b\n        vocab: \u5728\u8be5\u6570\u636e\u96c6\u4e0a\u521b\u5efa\u7684\u8bcd\u5178\uff0c\u7528\u4e8e\u5c06\u7ed9\u5b9a\u7684\u5355\u8bcd\u5e8f\u8f6c\u6362\u4e3a\u5355\u8bcd\u4e0b\u6807\u7684\u5e8f\u5217\uff0c\u4ece\u800c\u8f93\u5165\u6a21\u578b\n        sentence: \u9700\u8981\u5206\u6790\u60c5\u611f\u7684\u6587\u672c\uff0c\u4ee5\u5355\u8bcd\u5e8f\u5217\u7684\u5f62\u5f0f\u7ed9\u51fa\n    @return: \u9884\u6d4b\u7684\u7ed3\u679c\uff0cpositive \u4e3a\u6b63\u9762\u60c5\u7eea\u6587\u672c\uff0cnegative \u4e3a\u8d1f\u9762\u60c5\u7eea\u6587\u672c\n    '''\n    device = list(net.parameters())[0].device # \u8bfb\u53d6\u6a21\u578b\u6240\u5728\u7684\u73af\u5883\n    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n    return 'positive' if label.item() == 1 else 'negative'\n\npredict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])","ab5a5624":"predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'bad'])","9543d641":"def corr1d(X, K):\n    '''\n    @params:\n        X: \u8f93\u5165\uff0c\u5f62\u72b6\u4e3a (seq_len,) \u7684\u5f20\u91cf\n        K: \u5377\u79ef\u6838\uff0c\u5f62\u72b6\u4e3a (w,) \u7684\u5f20\u91cf\n    @return:\n        Y: \u8f93\u51fa\uff0c\u5f62\u72b6\u4e3a (seq_len - w + 1,) \u7684\u5f20\u91cf\n    '''\n    w = K.shape[0] # \u5377\u79ef\u7a97\u53e3\u5bbd\u5ea6\n    Y = torch.zeros((X.shape[0] - w + 1))\n    for i in range(Y.shape[0]): # \u6ed1\u52a8\u7a97\u53e3\n        Y[i] = (X[i: i + w] * K).sum()\n    return Y\n\nX, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\nprint(corr1d(X, K))","c6be0009":"def corr1d_multi_in(X, K):\n    # \u9996\u5148\u6cbf\u7740X\u548cK\u7684\u901a\u9053\u7ef4\u904d\u5386\u5e76\u8ba1\u7b97\u4e00\u7ef4\u4e92\u76f8\u5173\u7ed3\u679c\u3002\u7136\u540e\u5c06\u6240\u6709\u7ed3\u679c\u5806\u53e0\u8d77\u6765\u6cbf\u7b2c0\u7ef4\u7d2f\u52a0\n    return torch.stack([corr1d(x, k) for x, k in zip(X, K)]).sum(dim=0)\n    # [corr1d(X[i], K[i]) for i in range(X.shape[0])]\n\nX = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n              [1, 2, 3, 4, 5, 6, 7],\n              [2, 3, 4, 5, 6, 7, 8]])\nK = torch.tensor([[1, 2], [3, 4], [-1, -3]])\nprint(corr1d_multi_in(X, K))","9ddd88d7":"class GlobalMaxPool1d(nn.Module):\n    def __init__(self):\n        super(GlobalMaxPool1d, self).__init__()\n    def forward(self, x):\n        '''\n        @params:\n            x: \u8f93\u5165\uff0c\u5f62\u72b6\u4e3a (batch_size, n_channels, seq_len) \u7684\u5f20\u91cf\n        @return: \u65f6\u5e8f\u6700\u5927\u6c60\u5316\u540e\u7684\u7ed3\u679c\uff0c\u5f62\u72b6\u4e3a (batch_size, n_channels, 1) \u7684\u5f20\u91cf\n        '''\n        return F.max_pool1d(x, kernel_size=x.shape[2]) # kenerl_size=seq_len","9956c577":"class TextCNN(nn.Module):\n    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n        '''\n        @params:\n            vocab: \u5728\u6570\u636e\u96c6\u4e0a\u521b\u5efa\u7684\u8bcd\u5178\uff0c\u7528\u4e8e\u83b7\u53d6\u8bcd\u5178\u5927\u5c0f\n            embed_size: \u5d4c\u5165\u7ef4\u5ea6\u5927\u5c0f\n            kernel_sizes: \u5377\u79ef\u6838\u5927\u5c0f\u5217\u8868\n            num_channels: \u5377\u79ef\u901a\u9053\u6570\u5217\u8868\n        '''\n        super(TextCNN, self).__init__()\n        self.embedding = nn.Embedding(len(vocab), embed_size) # \u53c2\u4e0e\u8bad\u7ec3\u7684\u5d4c\u5165\u5c42\n        self.constant_embedding = nn.Embedding(len(vocab), embed_size) # \u4e0d\u53c2\u4e0e\u8bad\u7ec3\u7684\u5d4c\u5165\u5c42\n        \n        self.pool = GlobalMaxPool1d() # \u65f6\u5e8f\u6700\u5927\u6c60\u5316\u5c42\u6ca1\u6709\u6743\u91cd\uff0c\u6240\u4ee5\u53ef\u4ee5\u5171\u7528\u4e00\u4e2a\u5b9e\u4f8b\n        self.convs = nn.ModuleList()  # \u521b\u5efa\u591a\u4e2a\u4e00\u7ef4\u5377\u79ef\u5c42\n        for c, k in zip(num_channels, kernel_sizes):\n            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, \n                                        out_channels = c, \n                                        kernel_size = k))\n            \n        self.decoder = nn.Linear(sum(num_channels), 2)\n        self.dropout = nn.Dropout(0.5) # \u4e22\u5f03\u5c42\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\n\n    def forward(self, inputs):\n        '''\n        @params:\n            inputs: \u8bcd\u8bed\u4e0b\u6807\u5e8f\u5217\uff0c\u5f62\u72b6\u4e3a (batch_size, seq_len) \u7684\u6574\u6570\u5f20\u91cf\n        @return:\n            outputs: \u5bf9\u6587\u672c\u60c5\u611f\u7684\u9884\u6d4b\uff0c\u5f62\u72b6\u4e3a (batch_size, 2) \u7684\u5f20\u91cf\n        '''\n        embeddings = torch.cat((\n            self.embedding(inputs), \n            self.constant_embedding(inputs)), dim=2) # (batch_size, seq_len, 2*embed_size)\n        # \u6839\u636e\u4e00\u7ef4\u5377\u79ef\u5c42\u8981\u6c42\u7684\u8f93\u5165\u683c\u5f0f\uff0c\u9700\u8981\u5c06\u5f20\u91cf\u8fdb\u884c\u8f6c\u7f6e\n        embeddings = embeddings.permute(0, 2, 1) # (batch_size, 2*embed_size, seq_len)\n        \n        encoding = torch.cat([\n            self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n        # encoding = []\n        # for conv in self.convs:\n        #     out = conv(embeddings) # (batch_size, out_channels, seq_len-kernel_size+1)\n        #     out = self.pool(F.relu(out)) # (batch_size, out_channels, 1)\n        #     encoding.append(out.squeeze(-1)) # (batch_size, out_channels)\n        # encoding = torch.cat(encoding) # (batch_size, out_channels_sum)\n        \n        # \u5e94\u7528\u4e22\u5f03\u6cd5\u540e\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\u5f97\u5230\u8f93\u51fa\n        outputs = self.decoder(self.dropout(encoding))\n        return outputs\n\nembed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\nnet = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)","8c9819bf":"lr, num_epochs = 0.001, 5\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\nloss = nn.CrossEntropyLoss()\ntrain(train_iter, test_iter, net, loss, optimizer, device, num_epochs)","01eacc28":"predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])","feb7587f":"predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'bad'])","122bea93":"### \u8bad\u7ec3\u5e76\u8bc4\u4ef7\u6a21\u578b","1be4e51e":"## \u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\n### \u4e00\u7ef4\u5377\u79ef\u5c42\n\n\u5728\u4ecb\u7ecd\u6a21\u578b\u524d\u6211\u4eec\u5148\u6765\u89e3\u91ca\u4e00\u7ef4\u5377\u79ef\u5c42\u7684\u5de5\u4f5c\u539f\u7406\u3002\u4e0e\u4e8c\u7ef4\u5377\u79ef\u5c42\u4e00\u6837\uff0c\u4e00\u7ef4\u5377\u79ef\u5c42\u4f7f\u7528\u4e00\u7ef4\u7684\u4e92\u76f8\u5173\u8fd0\u7b97\u3002\u5728\u4e00\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u4e2d\uff0c\u5377\u79ef\u7a97\u53e3\u4ece\u8f93\u5165\u6570\u7ec4\u7684\u6700\u5de6\u65b9\u5f00\u59cb\uff0c\u6309\u4ece\u5de6\u5f80\u53f3\u7684\u987a\u5e8f\uff0c\u4f9d\u6b21\u5728\u8f93\u5165\u6570\u7ec4\u4e0a\u6ed1\u52a8\u3002\u5f53\u5377\u79ef\u7a97\u53e3\u6ed1\u52a8\u5230\u67d0\u4e00\u4f4d\u7f6e\u65f6\uff0c\u7a97\u53e3\u4e2d\u7684\u8f93\u5165\u5b50\u6570\u7ec4\u4e0e\u6838\u6570\u7ec4\u6309\u5143\u7d20\u76f8\u4e58\u5e76\u6c42\u548c\uff0c\u5f97\u5230\u8f93\u51fa\u6570\u7ec4\u4e2d\u76f8\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\u3002\u5982\u56fe\u6240\u793a\uff0c\u8f93\u5165\u662f\u4e00\u4e2a\u5bbd\u4e3a 7 \u7684\u4e00\u7ef4\u6570\u7ec4\uff0c\u6838\u6570\u7ec4\u7684\u5bbd\u4e3a 2\u3002\u53ef\u4ee5\u770b\u5230\u8f93\u51fa\u7684\u5bbd\u5ea6\u4e3a 7\u22122+1=6\uff0c\u4e14\u7b2c\u4e00\u4e2a\u5143\u7d20\u662f\u7531\u8f93\u5165\u7684\u6700\u5de6\u8fb9\u7684\u5bbd\u4e3a 2 \u7684\u5b50\u6570\u7ec4\u4e0e\u6838\u6570\u7ec4\u6309\u5143\u7d20\u76f8\u4e58\u540e\u518d\u76f8\u52a0\u5f97\u5230\u7684\uff1a0\u00d71+1\u00d72=2\u3002\n\n![\u4e00\u7ef4\u5377\u79ef\u5c42](https:\/\/zh.d2l.ai\/_images\/conv1d.svg)","7b256007":"### \u9884\u5904\u7406\u6570\u636e\n\n\u8bfb\u53d6\u6570\u636e\u540e\uff0c\u6211\u4eec\u5148\u6839\u636e\u6587\u672c\u7684\u683c\u5f0f\u8fdb\u884c\u5355\u8bcd\u7684\u5207\u5206\uff0c\u518d\u5229\u7528 [`torchtext.vocab.Vocab`](https:\/\/torchtext.readthedocs.io\/en\/latest\/vocab.html#vocab) \u521b\u5efa\u8bcd\u5178\u3002","6a88ecba":"### \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\n\n\u7531\u4e8e\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u7684\u8bcd\u5178\u53ca\u8bcd\u8bed\u7d22\u5f15\u4e0e\u6211\u4eec\u4f7f\u7528\u7684\u6570\u636e\u96c6\u5e76\u4e0d\u76f8\u540c\uff0c\u6240\u4ee5\u9700\u8981\u6839\u636e\u76ee\u524d\u7684\u8bcd\u5178\u53ca\u7d22\u5f15\u7684\u987a\u5e8f\u6765\u52a0\u8f7d\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u3002","c30b2170":"## \u6587\u672c\u60c5\u611f\u5206\u7c7b\u6570\u636e\n\n\u6211\u4eec\u4f7f\u7528[\u65af\u5766\u798f\u7684IMDb\u6570\u636e\u96c6\uff08Stanford\u2019s Large Movie Review Dataset\uff09](http:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/)\u4f5c\u4e3a\u6587\u672c\u60c5\u611f\u5206\u7c7b\u7684\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u5206\u4e3a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7528\u7684\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u5206\u522b\u5305\u542b 25,000 \u6761\u4eceIMDb\u4e0b\u8f7d\u7684\u5173\u4e8e\u7535\u5f71\u7684\u8bc4\u8bba\u3002\u5728\u6bcf\u4e2a\u6570\u636e\u96c6\u4e2d\uff0c\u6807\u7b7e\u4e3a\u201c\u6b63\u9762\u201d\u548c\u201c\u8d1f\u9762\u201d\u7684\u8bc4\u8bba\u6570\u91cf\u76f8\u7b49\u3002\n\n### \u8bfb\u53d6\u6570\u636e","4a18079a":"### \u521b\u5efa\u6570\u636e\u8fed\u4ee3\u5668\n\n\u5229\u7528 [`torch.utils.data.TensorDataset`](https:\/\/pytorch.org\/docs\/stable\/data.html?highlight=tensor%20dataset#torch.utils.data.TensorDataset)\uff0c\u53ef\u4ee5\u521b\u5efa PyTorch \u683c\u5f0f\u7684\u6570\u636e\u96c6\uff0c\u4ece\u800c\u521b\u5efa\u6570\u636e\u8fed\u4ee3\u5668\u3002","177e9988":"\u7531\u4e8c\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u7684\u5b9a\u4e49\u53ef\u77e5\uff0c\u591a\u8f93\u5165\u901a\u9053\u7684\u4e00\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u53ef\u4ee5\u770b\u4f5c\u5355\u8f93\u5165\u901a\u9053\u7684\u4e8c\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u3002\u5982\u56fe\u6240\u793a\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5c06\u56fe\u4e2d\u591a\u8f93\u5165\u901a\u9053\u7684\u4e00\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u4ee5\u7b49\u4ef7\u7684\u5355\u8f93\u5165\u901a\u9053\u7684\u4e8c\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u5448\u73b0\u3002\u8fd9\u91cc\u6838\u7684\u9ad8\u7b49\u4e8e\u8f93\u5165\u7684\u9ad8\u3002\u56fe\u4e2d\u7684\u9634\u5f71\u90e8\u5206\u4e3a\u7b2c\u4e00\u4e2a\u8f93\u51fa\u5143\u7d20\u53ca\u5176\u8ba1\u7b97\u6240\u4f7f\u7528\u7684\u8f93\u5165\u548c\u6838\u6570\u7ec4\u5143\u7d20\uff1a2\u00d7(\u22121)+3\u00d7(\u22123)+1\u00d73+2\u00d74+0\u00d71+1\u00d72=2\u3002\n\n![\u5355\u8f93\u5165\u901a\u9053\u7684\u4e8c\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97](https:\/\/zh.d2l.ai\/_images\/conv1d-2d.svg)\n\n*\u6ce8\uff1a\u53cd\u4e4b\u4ec5\u5f53\u4e8c\u7ef4\u5377\u79ef\u6838\u7684\u9ad8\u5ea6\u7b49\u4e8e\u8f93\u5165\u7684\u9ad8\u5ea6\u65f6\u624d\u6210\u7acb\u3002*\n\n\u4e4b\u524d\u7684\u4f8b\u5b50\u4e2d\u8f93\u51fa\u90fd\u53ea\u6709\u4e00\u4e2a\u901a\u9053\u3002\u6211\u4eec\u5728[\u201c\u591a\u8f93\u5165\u901a\u9053\u548c\u591a\u8f93\u51fa\u901a\u9053\u201d](https:\/\/zh.d2l.ai\/chapter_convolutional-neural-networks\/channels.html)\u4e00\u8282\u4e2d\u4ecb\u7ecd\u4e86\u5982\u4f55\u5728\u4e8c\u7ef4\u5377\u79ef\u5c42\u4e2d\u6307\u5b9a\u591a\u4e2a\u8f93\u51fa\u901a\u9053\u3002\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5728\u4e00\u7ef4\u5377\u79ef\u5c42\u6307\u5b9a\u591a\u4e2a\u8f93\u51fa\u901a\u9053\uff0c\u4ece\u800c\u62d3\u5c55\u5377\u79ef\u5c42\u4e2d\u7684\u6a21\u578b\u53c2\u6570\u3002","d9db6293":"### \u8bc4\u4ef7\u6a21\u578b","7cf42f13":"\u8bcd\u5178\u548c\u8bcd\u8bed\u7684\u7d22\u5f15\u521b\u5efa\u597d\u540e\uff0c\u5c31\u53ef\u4ee5\u5c06\u6570\u636e\u96c6\u7684\u6587\u672c\u4ece\u5b57\u7b26\u4e32\u7684\u5f62\u5f0f\u8f6c\u6362\u4e3a\u5355\u8bcd\u4e0b\u6807\u5e8f\u5217\u7684\u5f62\u72b6\uff0c\u4ee5\u5f85\u540e\u7528\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u6279\u5904\u7406\u7684\u65b9\u4fbf\uff0c\u8fd8\u9700\u8981\u5bf9\u6587\u672c\u8fdb\u884c\u622a\u65ad\u6216\u8865\u9f50\uff0c\u4f7f\u6587\u672c\u957f\u5ea6\u6052\u5b9a\u3002","c9b6dfaf":"### \u65f6\u5e8f\u6700\u5927\u6c60\u5316\u5c42\n\n\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u6709\u4e00\u7ef4\u6c60\u5316\u5c42\u3002TextCNN \u4e2d\u4f7f\u7528\u7684\u65f6\u5e8f\u6700\u5927\u6c60\u5316\uff08max-over-time pooling\uff09\u5c42\u5b9e\u9645\u4e0a\u5bf9\u5e94\u4e00\u7ef4\u5168\u5c40\u6700\u5927\u6c60\u5316\u5c42\uff1a\u5047\u8bbe\u8f93\u5165\u5305\u542b\u591a\u4e2a\u901a\u9053\uff0c\u5404\u901a\u9053\u7531\u4e0d\u540c\u65f6\u95f4\u6b65\u4e0a\u7684\u6570\u503c\u7ec4\u6210\uff0c\u5404\u901a\u9053\u7684\u8f93\u51fa\u5373\u8be5\u901a\u9053\u6240\u6709\u65f6\u95f4\u6b65\u4e2d\u6700\u5927\u7684\u6570\u503c\u3002\u56e0\u6b64\uff0c\u65f6\u5e8f\u6700\u5927\u6c60\u5316\u5c42\u7684\u8f93\u5165\u5728\u5404\u4e2a\u901a\u9053\u4e0a\u7684\u65f6\u95f4\u6b65\u6570\u53ef\u4ee5\u4e0d\u540c\u3002\n\n![image.png](attachment:image.png)\n\n*\u6ce8\uff1a\u81ea\u7136\u8bed\u8a00\u4e2d\u8fd8\u6709\u4e00\u4e9b\u5176\u4ed6\u7684\u6c60\u5316\u64cd\u4f5c\uff0c\u53ef\u53c2\u8003\u8fd9\u7bc7[\u535a\u6587](https:\/\/blog.csdn.net\/malefactor\/article\/details\/51078135)\u3002*\n\n\u4e3a\u63d0\u5347\u8ba1\u7b97\u6027\u80fd\uff0c\u6211\u4eec\u5e38\u5e38\u5c06\u4e0d\u540c\u957f\u5ea6\u7684\u65f6\u5e8f\u6837\u672c\u7ec4\u6210\u4e00\u4e2a\u5c0f\u6279\u91cf\uff0c\u5e76\u901a\u8fc7\u5728\u8f83\u77ed\u5e8f\u5217\u540e\u9644\u52a0\u7279\u6b8a\u5b57\u7b26\uff08\u59820\uff09\u4ee4\u6279\u91cf\u4e2d\u5404\u65f6\u5e8f\u6837\u672c\u957f\u5ea6\u76f8\u540c\u3002\u8fd9\u4e9b\u4eba\u4e3a\u6dfb\u52a0\u7684\u7279\u6b8a\u5b57\u7b26\u5f53\u7136\u662f\u65e0\u610f\u4e49\u7684\u3002\u7531\u4e8e\u65f6\u5e8f\u6700\u5927\u6c60\u5316\u7684\u4e3b\u8981\u76ee\u7684\u662f\u6293\u53d6\u65f6\u5e8f\u4e2d\u6700\u91cd\u8981\u7684\u7279\u5f81\uff0c\u5b83\u901a\u5e38\u80fd\u4f7f\u6a21\u578b\u4e0d\u53d7\u4eba\u4e3a\u6dfb\u52a0\u5b57\u7b26\u7684\u5f71\u54cd\u3002","28b93cd4":"\u7531\u4e8e\u5d4c\u5165\u5c42\u7684\u53c2\u6570\u662f\u4e0d\u9700\u8981\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u88ab\u66f4\u65b0\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u5229\u7528 `filter` \u51fd\u6570\u548c `lambda` \u8868\u8fbe\u5f0f\u6765\u8fc7\u6ee4\u6389\u6a21\u578b\u4e2d\u4e0d\u9700\u8981\u66f4\u65b0\u53c2\u6570\u7684\u90e8\u5206\u3002","2b77dd83":"### TextCNN \u6a21\u578b\n\nTextCNN \u6a21\u578b\u4e3b\u8981\u4f7f\u7528\u4e86\u4e00\u7ef4\u5377\u79ef\u5c42\u548c\u65f6\u5e8f\u6700\u5927\u6c60\u5316\u5c42\u3002\u5047\u8bbe\u8f93\u5165\u7684\u6587\u672c\u5e8f\u5217\u7531 $n$ \u4e2a\u8bcd\u7ec4\u6210\uff0c\u6bcf\u4e2a\u8bcd\u7528 $d$ \u7ef4\u7684\u8bcd\u5411\u91cf\u8868\u793a\u3002\u90a3\u4e48\u8f93\u5165\u6837\u672c\u7684\u5bbd\u4e3a $n$\uff0c\u8f93\u5165\u901a\u9053\u6570\u4e3a $d$\u3002TextCNN \u7684\u8ba1\u7b97\u4e3b\u8981\u5206\u4e3a\u4ee5\u4e0b\u51e0\u6b65\u3002\n\n1. \u5b9a\u4e49\u591a\u4e2a\u4e00\u7ef4\u5377\u79ef\u6838\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u5377\u79ef\u6838\u5bf9\u8f93\u5165\u5206\u522b\u505a\u5377\u79ef\u8ba1\u7b97\u3002\u5bbd\u5ea6\u4e0d\u540c\u7684\u5377\u79ef\u6838\u53ef\u80fd\u4f1a\u6355\u6349\u5230\u4e0d\u540c\u4e2a\u6570\u7684\u76f8\u90bb\u8bcd\u7684\u76f8\u5173\u6027\u3002\n2. \u5bf9\u8f93\u51fa\u7684\u6240\u6709\u901a\u9053\u5206\u522b\u505a\u65f6\u5e8f\u6700\u5927\u6c60\u5316\uff0c\u518d\u5c06\u8fd9\u4e9b\u901a\u9053\u7684\u6c60\u5316\u8f93\u51fa\u503c\u8fde\u7ed3\u4e3a\u5411\u91cf\u3002\n3. \u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u5c06\u8fde\u7ed3\u540e\u7684\u5411\u91cf\u53d8\u6362\u4e3a\u6709\u5173\u5404\u7c7b\u522b\u7684\u8f93\u51fa\u3002\u8fd9\u4e00\u6b65\u53ef\u4ee5\u4f7f\u7528\u4e22\u5f03\u5c42\u5e94\u5bf9\u8fc7\u62df\u5408\u3002\n\n\u4e0b\u56fe\u7528\u4e00\u4e2a\u4f8b\u5b50\u89e3\u91ca\u4e86 TextCNN \u7684\u8bbe\u8ba1\u3002\u8fd9\u91cc\u7684\u8f93\u5165\u662f\u4e00\u4e2a\u6709 11 \u4e2a\u8bcd\u7684\u53e5\u5b50\uff0c\u6bcf\u4e2a\u8bcd\u7528 6 \u7ef4\u8bcd\u5411\u91cf\u8868\u793a\u3002\u56e0\u6b64\u8f93\u5165\u5e8f\u5217\u7684\u5bbd\u4e3a 11\uff0c\u8f93\u5165\u901a\u9053\u6570\u4e3a 6\u3002\u7ed9\u5b9a 2 \u4e2a\u4e00\u7ef4\u5377\u79ef\u6838\uff0c\u6838\u5bbd\u5206\u522b\u4e3a 2 \u548c 4\uff0c\u8f93\u51fa\u901a\u9053\u6570\u5206\u522b\u8bbe\u4e3a 4 \u548c 5\u3002\u56e0\u6b64\uff0c\u4e00\u7ef4\u5377\u79ef\u8ba1\u7b97\u540e\uff0c4 \u4e2a\u8f93\u51fa\u901a\u9053\u7684\u5bbd\u4e3a 11\u22122+1=10\uff0c\u800c\u5176\u4ed6 5 \u4e2a\u901a\u9053\u7684\u5bbd\u4e3a 11\u22124+1=8\u3002\u5c3d\u7ba1\u6bcf\u4e2a\u901a\u9053\u7684\u5bbd\u4e0d\u540c\uff0c\u6211\u4eec\u4f9d\u7136\u53ef\u4ee5\u5bf9\u5404\u4e2a\u901a\u9053\u505a\u65f6\u5e8f\u6700\u5927\u6c60\u5316\uff0c\u5e76\u5c06 9 \u4e2a\u901a\u9053\u7684\u6c60\u5316\u8f93\u51fa\u8fde\u7ed3\u6210\u4e00\u4e2a 9 \u7ef4\u5411\u91cf\u3002\u6700\u7ec8\uff0c\u4f7f\u7528\u5168\u8fde\u63a5\u5c06 9 \u7ef4\u5411\u91cf\u53d8\u6362\u4e3a 2 \u7ef4\u8f93\u51fa\uff0c\u5373\u6b63\u9762\u60c5\u611f\u548c\u8d1f\u9762\u60c5\u611f\u7684\u9884\u6d4b\u3002\n\n![TextCNN \u6a21\u578b](https:\/\/zh.d2l.ai\/_images\/textcnn.svg)\n\n\u4e0b\u9762\u6211\u4eec\u6765\u5b9e\u73b0 TextCNN \u6a21\u578b\u3002\u4e0e\u4e0a\u4e00\u8282\u76f8\u6bd4\uff0c\u9664\u4e86\u7528\u4e00\u7ef4\u5377\u79ef\u5c42\u66ff\u6362\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5916\uff0c\u8fd9\u91cc\u6211\u4eec\u8fd8\u4f7f\u7528\u4e86\u4e24\u4e2a\u5d4c\u5165\u5c42\uff0c\u4e00\u4e2a\u7684\u6743\u91cd\u56fa\u5b9a\uff0c\u53e6\u4e00\u4e2a\u5219\u53c2\u4e0e\u8bad\u7ec3\u3002","a2ea7174":"## \u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\n\n### \u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\n\n\u5728[\u201c\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u201d](https:\/\/zh.d2l.ai\/chapter_recurrent-neural-networks\/bi-rnn.html)\u4e00\u8282\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u5176\u6a21\u578b\u4e0e\u524d\u5411\u8ba1\u7b97\u7684\u516c\u5f0f\uff0c\u8fd9\u91cc\u7b80\u5355\u56de\u987e\u4e00\u4e0b\uff1a\n\n![\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc](https:\/\/zh.d2l.ai\/_images\/birnn.svg)\n\n\u7ed9\u5b9a\u65f6\u95f4\u6b65 $t$ \u7684\u5c0f\u6279\u91cf\u8f93\u5165 $X_t\\in\\mathbb{R}^{n\\times d}$ \uff08\u6837\u672c\u6570\u4e3a $n$\uff0c\u8f93\u5165\u7ef4\u5ea6\u4e3a $d$\uff09\u548c\u9690\u85cf\u5c42\u6fc0\u6d3b\u51fd\u6570\u4e3a $\\phi$\u3002\u5728\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u67b6\u6784\u4e2d\uff0c\u8bbe\u8be5\u65f6\u95f4\u6b65\u6b63\u5411\u9690\u85cf\u72b6\u6001\u4e3a $\\overrightarrow{\\boldsymbol{H}}_{t} \\in \\mathbb{R}^{n \\times h}$ \uff08\u6b63\u5411\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u4e3a $h$\uff09\uff0c\u53cd\u5411\u9690\u85cf\u72b6\u6001\u4e3a $\\overleftarrow{\\boldsymbol{H}}_{t} \\in \\mathbb{R}^{n \\times h}$ \uff08\u53cd\u5411\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u4e3a $h$\uff09\u3002\u6211\u4eec\u53ef\u4ee5\u5206\u522b\u8ba1\u7b97\u6b63\u5411\u9690\u85cf\u72b6\u6001\u548c\u53cd\u5411\u9690\u85cf\u72b6\u6001\uff1a\n\n$$\n\\begin{aligned}\n&\\overrightarrow{\\boldsymbol{H}}_{t}=\\phi\\left(\\boldsymbol{X}_{t} \\boldsymbol{W}_{x h}^{(f)}+\\overrightarrow{\\boldsymbol{H}}_{t-1} \\boldsymbol{W}_{h h}^{(f)}+\\boldsymbol{b}_{h}^{(f)}\\right)\\\\\n&\\overleftarrow{\\boldsymbol{H}}_{t}=\\phi\\left(\\boldsymbol{X}_{t} \\boldsymbol{W}_{x h}^{(b)}+\\overleftarrow{\\boldsymbol{H}}_{t+1} \\boldsymbol{W}_{h h}^{(b)}+\\boldsymbol{b}_{h}^{(b)}\\right)\n\\end{aligned}\n$$\n\n\u5176\u4e2d\u6743\u91cd $\\boldsymbol{W}_{x h}^{(f)} \\in \\mathbb{R}^{d \\times h}, \\boldsymbol{W}_{h h}^{(f)} \\in \\mathbb{R}^{h \\times h}, \\boldsymbol{W}_{x h}^{(b)} \\in \\mathbb{R}^{d \\times h}, \\boldsymbol{W}_{h h}^{(b)} \\in \\mathbb{R}^{h \\times h}$ \u548c\u504f\u5dee $\\boldsymbol{b}_{h}^{(f)} \\in \\mathbb{R}^{1 \\times h}, \\boldsymbol{b}_{h}^{(b)} \\in \\mathbb{R}^{1 \\times h}$ \u5747\u4e3a\u6a21\u578b\u53c2\u6570\u3002\n\n\u7136\u540e\u6211\u4eec\u8fde\u7ed3\u4e24\u4e2a\u65b9\u5411\u7684\u9690\u85cf\u72b6\u6001 $\\overrightarrow{\\boldsymbol{H}}_{t}$ \u548c $\\overleftarrow{\\boldsymbol{H}}_{t}$ \u6765\u5f97\u5230\u9690\u85cf\u72b6\u6001 $\\boldsymbol{H}_{t} \\in \\mathbb{R}^{n \\times 2 h}$\uff0c\u5e76\u5c06\u5176\u8f93\u5165\u5230\u8f93\u51fa\u5c42\u3002\u8f93\u51fa\u5c42\u8ba1\u7b97\u8f93\u51fa $\\boldsymbol{O}_{t} \\in \\mathbb{R}^{n \\times q}$\uff08\u8f93\u51fa\u7ef4\u5ea6\u4e3a $q$\uff09\uff1a\n\n$$\n\\boldsymbol{O}_{t}=\\boldsymbol{H}_{t} \\boldsymbol{W}_{h q}+\\boldsymbol{b}_{q}\n$$\n\n\u5176\u4e2d\u6743\u91cd $\\boldsymbol{W}_{h q} \\in \\mathbb{R}^{2 h \\times q}$ \u548c\u504f\u5dee $\\boldsymbol{b}_{q} \\in \\mathbb{R}^{1 \\times q}$ \u4e3a\u8f93\u51fa\u5c42\u7684\u6a21\u578b\u53c2\u6570\u3002\u4e0d\u540c\u65b9\u5411\u4e0a\u7684\u9690\u85cf\u5355\u5143\u7ef4\u5ea6\u4e5f\u53ef\u4ee5\u4e0d\u540c\u3002\n\n\u5229\u7528 [`torch.nn.RNN`](https:\/\/pytorch.org\/docs\/stable\/nn.html?highlight=rnn#torch.nn.RNN) \u6216 [`torch.nn.LSTM`](https:\/\/pytorch.org\/docs\/stable\/nn.html?highlight=lstm#torch.nn.LSTM) \u6a21\u7ec4\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u65b9\u4fbf\u5730\u5b9e\u73b0\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u4e0b\u9762\u662f\u4ee5 LSTM \u4e3a\u4f8b\u7684\u4ee3\u7801\u3002","fbeea434":"\u591a\u8f93\u5165\u901a\u9053\u7684\u4e00\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u4e5f\u4e0e\u591a\u8f93\u5165\u901a\u9053\u7684\u4e8c\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\u7c7b\u4f3c\uff1a\u5728\u6bcf\u4e2a\u901a\u9053\u4e0a\uff0c\u5c06\u6838\u4e0e\u76f8\u5e94\u7684\u8f93\u5165\u505a\u4e00\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\uff0c\u5e76\u5c06\u901a\u9053\u4e4b\u95f4\u7684\u7ed3\u679c\u76f8\u52a0\u5f97\u5230\u8f93\u51fa\u7ed3\u679c\u3002\u4e0b\u56fe\u5c55\u793a\u4e86\u542b 3 \u4e2a\u8f93\u5165\u901a\u9053\u7684\u4e00\u7ef4\u4e92\u76f8\u5173\u8fd0\u7b97\uff0c\u5176\u4e2d\u9634\u5f71\u90e8\u5206\u4e3a\u7b2c\u4e00\u4e2a\u8f93\u51fa\u5143\u7d20\u53ca\u5176\u8ba1\u7b97\u6240\u4f7f\u7528\u7684\u8f93\u5165\u548c\u6838\u6570\u7ec4\u5143\u7d20\uff1a0\u00d71+1\u00d72+1\u00d73+2\u00d74+2\u00d7(\u22121)+3\u00d7(\u22123)=2\u3002\n\n![\u591a\u8f93\u5165\u901a\u9053\u7684\u4e00\u7ef4\u5377\u79ef\u5c42](https:\/\/zh.d2l.ai\/_images\/conv1d-channel.svg)","fd1688df":"# \u6587\u672c\u60c5\u611f\u5206\u7c7b\n\n\u6587\u672c\u5206\u7c7b\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u4e00\u4e2a\u5e38\u89c1\u4efb\u52a1\uff0c\u5b83\u628a\u4e00\u6bb5\u4e0d\u5b9a\u957f\u7684\u6587\u672c\u5e8f\u5217\u53d8\u6362\u4e3a\u6587\u672c\u7684\u7c7b\u522b\u3002\u672c\u8282\u5173\u6ce8\u5b83\u7684\u4e00\u4e2a\u5b50\u95ee\u9898\uff1a\u4f7f\u7528\u6587\u672c\u60c5\u611f\u5206\u7c7b\u6765\u5206\u6790\u6587\u672c\u4f5c\u8005\u7684\u60c5\u7eea\u3002\u8fd9\u4e2a\u95ee\u9898\u4e5f\u53eb\u60c5\u611f\u5206\u6790\uff0c\u5e76\u6709\u7740\u5e7f\u6cdb\u7684\u5e94\u7528\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5206\u6790\u7528\u6237\u5bf9\u4ea7\u54c1\u7684\u8bc4\u8bba\u5e76\u7edf\u8ba1\u7528\u6237\u7684\u6ee1\u610f\u5ea6\uff0c\u6216\u8005\u5206\u6790\u7528\u6237\u5bf9\u5e02\u573a\u884c\u60c5\u7684\u60c5\u7eea\u5e76\u7528\u4ee5\u9884\u6d4b\u63a5\u4e0b\u6765\u7684\u884c\u60c5\u3002\n\n\u540c\u641c\u7d22\u8fd1\u4e49\u8bcd\u548c\u7c7b\u6bd4\u8bcd\u4e00\u6837\uff0c\u6587\u672c\u5206\u7c7b\u4e5f\u5c5e\u4e8e\u8bcd\u5d4c\u5165\u7684\u4e0b\u6e38\u5e94\u7528\u3002\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u5e94\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u548c\u542b\u591a\u4e2a\u9690\u85cf\u5c42\u7684\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e0e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u6765\u5224\u65ad\u4e00\u6bb5\u4e0d\u5b9a\u957f\u7684\u6587\u672c\u5e8f\u5217\u4e2d\u5305\u542b\u7684\u662f\u6b63\u9762\u8fd8\u662f\u8d1f\u9762\u7684\u60c5\u7eea\u3002\u540e\u7eed\u5185\u5bb9\u5c06\u4ece\u4ee5\u4e0b\u51e0\u4e2a\u65b9\u9762\u5c55\u5f00\uff1a\n\n1. \u6587\u672c\u60c5\u611f\u5206\u7c7b\u6570\u636e\u96c6\n2. \u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\n3. \u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u60c5\u611f\u5206\u7c7b","aae0fbaa":"### \u8bad\u7ec3\u6a21\u578b\n\n\u8bad\u7ec3\u65f6\u53ef\u4ee5\u8c03\u7528\u4e4b\u524d\u7f16\u5199\u7684 `train` \u53ca `evaluate_accuracy` \u51fd\u6570\u3002"}}