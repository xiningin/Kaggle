{"cell_type":{"0e35c226":"code","d89a8cfd":"code","cf7a9a60":"code","8cce001c":"code","2ed1395d":"code","7e47a976":"code","4b6f7c32":"code","497eca43":"code","e851561d":"code","8ffa310e":"code","84e9155a":"markdown","ebed95a7":"markdown","39d473ab":"markdown","bc9a4516":"markdown"},"source":{"0e35c226":"!pip install pyyaml==5.1\nimport torch, torchvision\nassert torch.__version__.startswith(\"1.7\")\n!python -m pip install detectron2 -f \\\n  https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cpu\/torch1.7\/index.html\n# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime","d89a8cfd":"# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport pickle\nimport numpy as np\nimport os, json, cv2, random\n# from google.colab.patches import cv2_imshow\nfrom IPython import display\nimport PIL\nfrom PIL import Image\n\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\n\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.structures import BoxMode\nfrom detectron2.modeling import build_model\nfrom detectron2.checkpoint import DetectionCheckpointer\n\n\ndef cv2_imshow(a):\n    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n    Args:\n    a : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n      (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n      image.\n    \"\"\"\n    a = a.clip(0, 255).astype('uint8')\n    # cv2 stores colors as BGR; convert to RGB\n    if a.ndim == 3:\n        if a.shape[2] == 4:\n            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n        else:\n            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n    display.display(PIL.Image.fromarray(a))\n    \n\ndef get_image(a):\n    a = a.clip(0, 255).astype('uint8')\n    # cv2 stores colors as BGR; convert to RGB\n    if a.ndim == 3:\n        if a.shape[2] == 4:\n            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n        else:\n            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n    return PIL.Image.fromarray(a)","cf7a9a60":"!wget \"https:\/\/mipt.one\/mediafiles\/models\/model_final.pth\" -O \"model_final.pth\"\n!wget \"https:\/\/mipt.one\/mediafiles\/models\/cfg.pkl\" -O \"cfg.pkl\"\n!wget \"https:\/\/mipt.one\/mediafiles\/models\/demo.jpg\" -O \"demo.jpg\"\n!wget \"https:\/\/mipt.one\/mediafiles\/models\/demo2.jpg\" -O \"demo2.jpg\"\n!wget \"https:\/\/mipt.one\/mediafiles\/models\/demo3.jpg\" -O \"demo3.jpg\"\n!wget \"https:\/\/mipt.one\/mediafiles\/models\/demo4.jpg\" -O \"demo4.jpg\"\n!wget \"https:\/\/mipt.one\/mediafiles\/models\/cat.jpg\" -O \"cat.jpg\"","8cce001c":"with open(\"cfg.pkl\", \"rb\") as f:\n    cfg = pickle.load(f)\n\ncfg.MODEL.DEVICE = \"cpu\"\ncfg.MODEL.WEIGHTS = os.path.join(\"\/kaggle\/working\/model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n\n# model = build_model(cfg)\n# DetectionCheckpointer(model).load(\"model_final.pth\")","2ed1395d":"def resize(img, basewidth):\n    width, height = img.size\n    if (width <= basewidth) or (height <= basewidth):\n        return img\n    else:\n        wpercent = (basewidth\/float(img.size[0]))\n        hsize = int((float(img.size[1])*float(wpercent)))\n        img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n        return img\n\n\ndef pil_to_cv(pil_image):\n    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)","7e47a976":"predictor = DefaultPredictor(cfg)\n# im = cv2.imread(\"demo2.jpg\")\nim = Image.open('demo.jpg')\norig = im\n\n# resize initial image to reduce inference time on cpu\n# im = resize(im, 1000)\nim = pil_to_cv(im)\n\noutputs = predictor(im)  # format is documented at https:\/\/detectron2.readthedocs.io\/tutorials\/models.html#model-output-format\nv = Visualizer(im[:, :, ::-1],\n#                metadata=my_dataset_test_metadata, \n               scale=1, \n)\nout = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))","4b6f7c32":"img_det = get_image(out.get_image()[:, :, ::-1])\n\nimg_det.save('img_det.jpg')\ndisplay.display(img_det)","497eca43":"from math import ceil\n\n\nboxes_tensor = outputs[\"instances\"].pred_boxes.tensor\nn_boxes = boxes_tensor.shape[0]\n\nif n_boxes == 0:\n    detected = False\nelse:\n    detected = True\n\n    boxes = [tuple(boxes_tensor[i].numpy()) for i in range(n_boxes)]\n\n    best_box = (5000, 5000, 5000, 5000)\n    for box in boxes:\n        if box[1] < best_box[1]:\n            best_box = box\n\n\n    x1, y1, x2, y2 = best_box\n    area = (ceil(x1), ceil(y1), ceil(x2), ceil(y2))\n    region = orig.crop(area)\n\n    region.save(\"region.jpg\")\n    display.display(region)","e851561d":"# !tesseract region.jpg out\nexit_code = os.system(\"tesseract region.jpg out\")\nassert exit_code == 0","8ffa310e":"import re\n\nwith open(\"out.txt\", \"r\") as f:\n    string = f.read().strip()\n\nocr_failed = False\n\n\n# checks\nif len(string) == 0:\n    ocr_failed = True\nelse:\n    if \".\" in string:\n        some = re.search(r\"\\d+\\.\\d+\", string)\n        if some is not None:\n            task_number = some.group(0)\n        else:\n            ocr_failed = True\n    else:\n        some = re.search(r\"\\d*\", string).group(0)\n        if len(some) in [2, 3]:\n            task_number = \".\".join((some[0], some[1:]))\n        elif len(some) in [4, 5]:\n            task_number = \".\".join((some[:2], some[2:]))\n        else:\n            ocr_failed = True\n            \n\nif ocr_failed == True:\n    task_number = \"\"\n\n\nocr_failed, task_number","84e9155a":"## Crop detected regions","ebed95a7":"## Run the detector","39d473ab":"## Install dependances","bc9a4516":"## OCR"}}