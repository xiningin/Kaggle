{"cell_type":{"005c7b49":"code","9dc2d9b6":"code","9bf292e5":"code","b7816905":"code","15742c75":"code","d9da9e69":"code","f68f1fb4":"code","66415c66":"code","2c84f8b0":"code","911d65e3":"code","3d074d37":"code","01a4bd88":"code","706adc56":"code","1e6c686c":"code","bd79945e":"code","c92d4ecb":"code","93789acb":"code","2a02e91c":"code","c1f4b720":"code","d334a762":"code","6ae69c2d":"code","b27358ec":"code","23db474f":"markdown","a0df61e8":"markdown","a27f6ee5":"markdown","12a5ce69":"markdown","d89d9439":"markdown","b36502a1":"markdown","f1abd971":"markdown","da668276":"markdown","9e3ab504":"markdown"},"source":{"005c7b49":"import numpy as np \nimport pandas as pd \nimport os\n       \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold","9dc2d9b6":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \n\nimport transformers\nimport random\n\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nscaler = torch.cuda.amp.GradScaler() # GPU\u3067\u306e\u9ad8\u901f\u5316\u3002\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cpu\u304cgpu\u304b\u3092\u81ea\u52d5\u5224\u65ad\ndevice","9bf292e5":"result_path = \"..\/input\/pytorchbiginnersroommodel-v2\"","b7816905":"SEED = 508\n\ndef random_seed(SEED):\n    \n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n\nrandom_seed(SEED)","15742c75":"tokenizer = transformers.BertTokenizer.from_pretrained(\"..\/input\/bert-base-uncased\")","d9da9e69":"test = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\")\ntest.head(3)","f68f1fb4":"class BERTDataSet(Dataset):\n    \n    def __init__(self,sentences):\n        \n        self.sentences = sentences\n       \n        \n    def __len__(self):\n        \n        return len(self.sentences)\n    \n    def __getitem__(self,idx):\n        \n        sentence = self.sentences[idx]\n        sentence = str(sentence)\n        sentence = \" \".join(sentence.split())\n        \n        \n        bert_sens = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True, # [CLS],[SEP]\n                                max_length = 314,\n                                pad_to_max_length = True, # add padding to blank\n                                truncation=True)\n\n        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n     \n        \n    \n        \n        return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n                \n            }\n        ","66415c66":"test_dataset = BERTDataSet(test[\"excerpt\"])","2c84f8b0":"test_batch = 32","911d65e3":"test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)","3d074d37":"model = transformers.BertForSequenceClassification.from_pretrained('..\/input\/bert-base-uncased',num_labels=1)","01a4bd88":"pthes = [os.path.join(result_path,s) for s in os.listdir(result_path) if \".pth\" in s]\npthes","706adc56":"states = [torch.load(s) for s in pthes]","1e6c686c":"def predicting(\n    test_dataloader,\n    model,\n    states\n    \n):\n\n    allpreds = []\n    \n    for state in states:\n        model.load_state_dict(state[\"state_dict\"])\n        model.to(device)\n        model.eval()\n    \n    \n        preds = []\n        allvalloss=0\n\n        with torch.no_grad():\n\n\n            for a in test_dataloader:\n\n\n\n                ids = a[\"ids\"].to(device)\n                mask = a[\"mask\"].to(device)\n                tokentype = a[\"token_type_ids\"].to(device)\n\n                output = model(ids,mask,tokentype)\n                output = output[\"logits\"].squeeze(-1)\n\n\n                preds.append(output.cpu().numpy())\n\n            preds = np.concatenate(preds)\n            \n            allpreds.append(preds)\n\n    return allpreds\n","bd79945e":"allpreds = predicting(test_dataloader,model,states)","c92d4ecb":"findf = pd.DataFrame(allpreds)\nfindf = findf.T","93789acb":"findf","2a02e91c":"finpred = findf.mean(axis=1)\nfinpred","c1f4b720":"sample = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")\nsample","d334a762":"sample[\"target\"] = finpred","6ae69c2d":"sample","b27358ec":"sample.to_csv(\"submission.csv\",index = False)","23db474f":"# 0. Please enter the model path\n\n(Those created by Copy and edit may want to include their own output)\n\n## 0. model\u30d1\u30b9\u306b\u4f5c\u6210\u3057\u305f\u30e2\u30c7\u30eb\u306e\u30d5\u30a9\u30eb\u30c0\u30d1\u30b9\u3092\u5165\u308c\u3066\u304f\u3060\u3055\u3044\u3002\n\n\nCopy and edit\u3067\u4f5c\u6210\u3055\u308c\u305f\u65b9\u306f\u3001\u3054\u81ea\u5206\u306e\u7d50\u679c\u3092\u5165\u308c\u308b\u3068\u3044\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093)","a0df61e8":"# 2. model load","a27f6ee5":"# 3. prediction function","12a5ce69":"# Inference for Pytorch BERT beginner's room\n\n\n#### This page is the inference notebook on the following pages.\n * English\n     https:\/\/www.kaggle.com\/chumajin\/pytorch-bert-beginner-s-room\n \n \n \n * Japanese\n     https:\/\/www.kaggle.com\/chumajin\/pytorch-bert-beginner-s-room-version\n\n#### The model created by Random Seed 508 is uploaded to dataset.\n\n\n#### If you created it by Copy and edit, please add it to input and change the model path.","d89d9439":"# 4. Avarage the 5 model and making submission.\n## 5\u500b\u306e\u30e2\u30c7\u30eb\u3092\u5e73\u5747\u5316\u3057\u3066\u30b5\u30d6\u30df\u30c3\u30b7\u30e7\u30f3\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002","b36502a1":"# 1.Creating a Dataset (Since it is an inference, there is no target, so I omitted it)\n## If you have changed the max length with tokenizer, change it.","f1abd971":"## 1.\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210\u3002\u30a4\u30f3\u30d5\u30a1\u30ec\u30f3\u30b9\u306a\u306e\u3067\u3001target\u306f\u9664\u53bb\u3057\u3066\u3044\u307e\u3059\u3002\n### \u3082\u3057\u3001tokenizer\u306emax length\u3092\u5909\u3048\u3066\u3044\u308b\u5834\u5408\u306f\u3001314\u3068\u3044\u3046\u3068\u3053\u308d\u3092\u5909\u3048\u3066\u304f\u3060\u3055\u3044\u3002","da668276":"# Thank you so much !","9e3ab504":"\n------------------\u65e5\u672c\u8a9e-------------------------------------------------------------------\n\n\n\n#### \u3053\u306e\u30da\u30fc\u30b8\u306f\u4ee5\u4e0b\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306einference\u306e\u30da\u30fc\u30b8\u3067\u3059\u3002\n * English\n     https:\/\/www.kaggle.com\/chumajin\/pytorch-bert-beginner-s-room\n \n \n \n * Japanese\n     https:\/\/www.kaggle.com\/chumajin\/pytorch-bert-beginner-s-room-version\n\n#### \u30e2\u30c7\u30eb\u306f\u5225\u9014\u30e9\u30f3\u30c0\u30e0\u30b7\u30fc\u30c9508\u3067\u4f5c\u6210\u3055\u308c\u305f\u3082\u306e\u3092up\u3057\u307e\u3057\u305f\u3002(\u30b3\u30fc\u30c9\u306f\u540c\u3058\u3067\u3059)\n\n\n#### Copy and edit\u3055\u308c\u305f\u65b9\u306f\u3001\u305d\u306e\u7d50\u679c\u3092\u30a4\u30f3\u30d7\u30c3\u30c8\u304b\u3089\u767b\u9332\u3057\u3066model path\u306b\u5165\u308c\u3066\u3054\u4f7f\u7528\u304f\u3060\u3055\u3044"}}