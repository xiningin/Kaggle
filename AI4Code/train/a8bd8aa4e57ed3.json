{"cell_type":{"ce170bb5":"code","68550aa8":"code","b191b2e9":"code","ccaa2973":"code","3e0360e6":"code","f0064f15":"code","2ed1686e":"code","ede5d38a":"code","872c4fb4":"code","ac5e6923":"code","23d079f9":"code","3175be3f":"code","a443c7ae":"code","34d3f9b8":"code","3742b77a":"code","29b2ae1e":"code","03c01347":"code","2cd6abed":"code","1c116f21":"code","4cc5bc4a":"code","9295d59d":"code","815c4535":"code","4a0ee922":"code","f5134432":"code","7d830981":"code","50ffce75":"code","6eefcd04":"code","4f8c67cc":"markdown","989d59d1":"markdown","29e2a34f":"markdown","ea4f1548":"markdown","82e44f51":"markdown","6adcd163":"markdown","7a65bc29":"markdown","e1c060a0":"markdown","7c8b3e6d":"markdown","bc126807":"markdown","7fe027d7":"markdown","644d1b2f":"markdown","c2357fc8":"markdown","93e0df93":"markdown","2351e9a4":"markdown","0689f0ca":"markdown","9b520218":"markdown","70c5c603":"markdown","37699e3c":"markdown","173f8e65":"markdown","7e7afc3e":"markdown"},"source":{"ce170bb5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression","68550aa8":"city=pd.read_csv(\"..\/input\/supervised-learning-regression\/bigcity(3).csv\")\nprint(city.head())\ncity.head()\ncity.drop(\"Unnamed: 0\",axis=1,inplace=True)","b191b2e9":"city.info()","ccaa2973":"city.describe()","3e0360e6":"figure,ax=plt.subplots(1,2,figsize=(10,5))\nsns.boxplot(city.u,ax=ax[0],color='r')\nsns.boxplot(city.x,ax=ax[1])","f0064f15":"fig,ax= plt.subplots()\nfig.set_size_inches(11.7, 8.27)\nbox_plot_data=[city.u,city.x]\nox=plt.boxplot(box_plot_data,vert=1,patch_artist=True,labels=[\"u The 1920 population\",\"x The 1930 population\"],showmeans=True)","2ed1686e":"figure,ax=plt.subplots(1,2)\nfigure.set_size_inches(10,10)\nsns.distplot(city.u,ax=ax[0],kde=False)\nsns.distplot(city.x,ax=ax[1],kde=False)","ede5d38a":"figure,ax=plt.subplots(1,2)\nfigure.set_size_inches(10,10)\nsns.distplot(city.u,ax=ax[0],kde=True)\nsns.distplot(city.x,ax=ax[1],kde=True)","872c4fb4":"\nprint(\"u The 1920 population variance:\",city.u.var())\nprint(\"u The 1920 population standard deviation:\",city.u.std())","ac5e6923":"\nprint(\"x The 1930 population variance:\",city.x.var())\nprint(\"x The 1930 population standard deviation:\",city.x.std())","23d079f9":"pd.crosstab(city.u,city.x)","3175be3f":"figure,ax=plt.subplots()\nfigure.set_size_inches(10,10)\nsns.scatterplot(city.u,city.x,sizes=\"size\",legend=\"full\")","a443c7ae":"# figure,ax=plt.subplots()\n# figure.set_size_inches(10,10)\n# sns.regplot(city.u,city.x,scatter_kws={'alpha':'0.7'})","34d3f9b8":"city.shape\nprint(\"number of rows:\",city.shape[0])\nprint(\"number of columns:\",city.shape[1])","3742b77a":"city.isna().sum()","29b2ae1e":"city.corr()","03c01347":"sns.heatmap(city.corr())","2cd6abed":"y=city.x\nX=city.u\nXc=sm.add_constant(X)\nX_train, X_test, y_train, y_test = train_test_split(Xc, y, test_size=0.2, random_state=42)\n\nprint (\"Test shape x\",X_test.shape)\nprint (\"Test shape y\",y_test.shape)\nprint (\"Train shape x\",X_train.shape)\nprint(\"Train shape y\",y_train.shape)","1c116f21":"lin_reg=LinearRegression()\nlin_reg.fit(Xc,y)\nprint(\"coeffiecent\",lin_reg.coef_)\nprint(\"intercept\",lin_reg.intercept_)\nprint(\"R2 score\",lin_reg.score(Xc,y))","4cc5bc4a":"reg_line=[(1.1577337*x)+lin_reg.intercept_ for x in X]\nreg_line","9295d59d":"plt.scatter(city.u,city.x)\nplt.plot(city.u,reg_line)\nplt.ylabel(\"depedent variable\")\nplt.xlabel(\"independent variable\")","815c4535":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score,mean_squared_error\nlr=LinearRegression()\n\nlr.fit(X_train,y_train)\ny_pred_train=lr.predict(X_train)\n\nprint(\"R2 of the train:\",r2_score(y_train,y_pred_train))\nprint(\"RMSE of the train:\",np.sqrt(mean_squared_error(y_train,y_pred_train)))","4a0ee922":"y_pred_test=lr.predict(X_test)\n\nprint(\"R2 of the test:\",r2_score(y_test,y_pred_test))\nprint(\"RMSE of the test:\",np.sqrt(mean_squared_error(y_test,y_pred_test)))","f5134432":"from sklearn.linear_model import Ridge\nfrom yellowbrick.regressor import ResidualsPlot\nfrom sklearn import linear_model\nfrom sklearn.linear_model import Lasso,Ridge,LassoCV,RidgeCV\nfrom sklearn.linear_model import LinearRegression","7d830981":"# Instantiate the linear model and visualizer\nmodel = LinearRegression()\nvisualizer = ResidualsPlot(model)\n\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show()                 # Finalize and render the figure","50ffce75":"lr.score(X_train,y_train)","6eefcd04":"lr.score(X_test,y_test)","4f8c67cc":"# Format","989d59d1":"# 7. Split data into train, test sets\nDivide the data into training and test sets with 80-20 split using scikit-learn. Print the shapes of training and test feature \nsets.*\nCheck: train_test_split function","29e2a34f":"# 2. Collect and load data","ea4f1548":"# 3a. Visualize numeric variables in boxplot and histograms\n# 3b. Measure spread \u2013 variance and standard deviation","82e44f51":"# 1. Load required Libraries","6adcd163":"Population of U.S. Cities","7a65bc29":"This data frame contains the following columns:\n\nu The 1920 population.\n\nx The 1930 population.\n\nSource:\n\nThe data were obtained from\n\nCochran, W.G. (1977) Sampling Techniques. Third edition. John Wiley\n\nReferences:\n\nDavison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application. Cambridge University Press","e1c060a0":"# 6. Check the dataset for any missing values and also print out the correlation matrix\nYou can use .isna() and .corr() functions to check NA's and correlation in the dataframe respectively","7c8b3e6d":"# 4. Explore relationships between variables using scatterplots and two-way cross tabulations","bc126807":"# 11. Calculate the accuracy of the model for both training and test data set\n\nHint: .score() function","7fe027d7":"# Exploring and Understanding Data (EDA)","644d1b2f":"# Description","c2357fc8":"# 8. Find coefficients & intercept\nEstimate the coefficients b0 and b1 using scikit-learn.\nCheck: coef_ and intercept_ functions can help you get coefficients & intercept","93e0df93":"The bigcity data frame has 49 rows and 2 columns.\nThe measurements are the population (in 1000's) of 49 U.S. cities in 1920 and 1930. The 49 cities are a random sample taken\nfrom the 196 largest cities in 1920.","2351e9a4":"# Simple Linear Regression","0689f0ca":"# Dataset","9b520218":"# 9.  Linear Relationship between feature and target\nPlot the line with b1 and b0 as slope and y-intercept.","70c5c603":"# 3. Explore numeric variables - five number summary","37699e3c":"The high correlation betwwen u and x indicates that the variable u is a good predictor of variable x","173f8e65":"# 10. Evaluation of model with scikit-learn\nValidate the model with Root Mean Squares error and R^2 score using scikit-learn. RMSE and R2 for test data and prediction\n\nHint: You can import mean_squared_error function & r2 (R square) from sklearn.metrics. Performing root operation over mean \nsquare error over mean square error gives you root mean square error","7e7afc3e":"# 5. Transform the dataset\nFind the number of rows in given dataset and separate the input and target variables into X and Y. Hint: You can shape function \nto get the size of the dataframe"}}