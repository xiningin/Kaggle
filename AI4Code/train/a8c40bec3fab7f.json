{"cell_type":{"2431c7e7":"code","48deaa43":"code","1175de8d":"code","c96e9626":"code","73623f94":"code","177c8591":"code","ae6dc356":"code","f820d7c9":"code","633a59a0":"code","9ee80f81":"code","f5321324":"code","f3e65b31":"code","8e77f8d4":"code","f3bcdea4":"code","8bba2409":"code","79229fd0":"code","656edca2":"code","1716f929":"code","5fd1cea1":"code","3aeb1231":"markdown","8371afcf":"markdown","311a32ae":"markdown","a9277c50":"markdown","78f96a37":"markdown","fb3516ae":"markdown","2d5acda5":"markdown","5ad81011":"markdown","e15cdaa4":"markdown","fe6a3df0":"markdown","2fb5d5f7":"markdown","9a038b2f":"markdown","311a120b":"markdown","5477756a":"markdown","540193e1":"markdown","6264ea56":"markdown","2b2013b7":"markdown","da213725":"markdown","b52d9ebb":"markdown","8edfe351":"markdown"},"source":{"2431c7e7":"import numpy as np\nimport pandas as pd\nimport os\n\nimport seaborn as sns\nimport matplotlib as plot\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings(action = 'ignore', category = DeprecationWarning)\nwarnings.filterwarnings(action = 'ignore', category = FutureWarning)","48deaa43":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1175de8d":"white = pd.read_csv('\/kaggle\/input\/white-wine-quality\/winequality-white.csv', sep = ';')","c96e9626":"white.head()","73623f94":"white.describe(include='all')","177c8591":"white.isna().sum()","ae6dc356":"white.info()","f820d7c9":"plt.figure(figsize=(15,10))\n\nsns.heatmap(white.corr(), annot=True, robust=True)","633a59a0":"white.drop('residual sugar', axis = 1, inplace = True)","9ee80f81":"X = white.drop('quality', axis=1)\ny = white['quality'].astype('category')","f5321324":"cols = X.columns\n","f3e65b31":"fig = plt.figure(figsize=(20,90))\n\nfor i in range(1, len(cols)):\n    ax = fig.add_subplot(20, 2, i)\n    g = sns.distplot(X[cols[i]], bins=80)\n    plt.title(cols[i])\n    \n    ","8e77f8d4":"plt.figure(figsize=(10,7))\n\nsns.countplot(x = y)","f3bcdea4":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, \n                                                    stratify = y, random_state = 1234)","8bba2409":"print(X_train.shape)\nprint(y_train.shape)","79229fd0":"print(X_valid.shape)\nprint(y_valid.shape)","656edca2":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\ndef model_building(model, parameters = None, cv = 10, scale = False):\n    if parameters == None:\n        model.fit(X_train, y_train)\n        actual_train = y_train\n        prediction_train = model.predict(X_train)\n        actual_valid = y_valid\n        prediction_valid = model.predict(X_valid)\n        \n        ####### Model Evaluation #######\n        print(\"---------\",model,\"-----------\")\n        print(\"----TRAINING REPORT------\\n\")\n        print(classification_report(actual_train, prediction_train, digits=4))\n        print(\"----VALIDATION REPORT------\\n\")\n        print(classification_report(actual_valid, prediction_valid, digits=4))\n        print(\"\\n\")\n        return(model, prediction_train, prediction_valid)\n    else:\n        model_cv = GridSearchCV(estimator = model, param_grid = parameters, cv = cv)\n        model_cv.fit(X_train, y_train)\n        actual_train = y_train\n        prediction_train = model.predict(X_train)\n        actual_valid = y_valid\n        prediction_valid = model.predict(X_valid)\n        \n        ####### Model Evaluation #######\n        print(\"---------\",model,\"-----------\")\n        print(\"----TRAINING REPORT------\\n\")\n        print(classification_report(actual_train, prediction_train, digits=4))\n        print(\"----VALIDATION REPORT------\\n\")\n        print(classification_report(actual_valid, prediction_valid, digits=4))\n        print(\"\\n\")\n        model = model_cv.best_estimator_\n    \n\n        return(model_cv, prediction_train, prediction_valid)\n","1716f929":"from sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","5fd1cea1":"models = [KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(), AdaBoostClassifier()]\nfor model in models :\n    \n    model, pred_train, pred_valid = model_building(model)","3aeb1231":"We can see that all the featues are numeric.","8371afcf":"## Conclusion\n\nSince the best performance is given by Random Forest Classifier, I would build the model using the same.\n\n\n## Caveat\n\nWhile choosing the metrics, it is important to understand what the business case is expecting. In our case, we did not have any clear indication about any evaluation metric, so we picked up *Weighted Average F1-Score*. If the business case said \"We are concerned about the FALSE POSITIVES\", then we would have picked *Weighted Average Precision*. If the business case said \"We are serious about the FALSE NEGATIVES\", then we would have picked *Weighted Average Recall*. \n\nHence, make sure you understand the business case before choosing the metric(s) for your model.","311a32ae":"`density` and `residual sugar` have 84% correlation. Hence, we can drop either of the columns. \n\nIn this case, *residual sugar* has very low correlations with our target variable, *quality*. Hence, we would drop this.","a9277c50":"# <center>End Of The Notebook<\/center>","78f96a37":"Separating the dependent and independent variables","fb3516ae":"The target variable `quality` is normally distributed\n","2d5acda5":"_______\n## NOTE\nI would highly recommend to go through the blogs below to get a better understanding about the model evaluation metrics. It is a 2-part series. Do read it throughly.\n\nLink: https:\/\/towardsdatascience.com\/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2\n\n_______\n","5ad81011":"### Visualization","e15cdaa4":"___","fe6a3df0":"### Train-Validation Split","2fb5d5f7":"### Standardization","9a038b2f":"There are no missing values. Hence, there is no need of imputation.","311a120b":"## Pre-processing ","5477756a":"## Observations\n1. If you check the training report of *Decision Tree Classifier* and *Random Forest Classifier*, both of them have **1.000** everywhere. Those are true values, because both these models tend to *learn* the data completely and hence encounter a \"seeming\" problem of *overfitting*. Although, the validation report suggests a different story!\n2. Out of all, Random Forest Classifier gives the best weighted average F1-Score of about 65%.\n3. AdaBoost Classifier performs the worst in terms of the evaluation metrics (about 37%).\n","540193e1":"___","6264ea56":"![istockphoto-157583102-612x612.jpg](attachment:a042fdb0-9059-408c-a817-d0f63c3df933.jpg)","2b2013b7":"# Model Building and Model Evaluation","da213725":"# <center>White Wine Quality<\/center>\n","b52d9ebb":"<div class=\"alert alert-block alert-info\"><b>\n    \nThe models that we would be implementing are:\n - KNearest Neighbour Classifier\n - Decision Tree Classifier\n - XGBoost Classifier\n - Gradient Boost Classifier\n - Random Forest Classifier\n \n<\/b> <\/div>","8edfe351":"## Evaluation Metrics\n\nThere is not \"best\" or \"right\" evaluation metric for any classification problem (or for any ML model, per se). It completely depends on thee *USE-CASE*.\n\nIn this case, since it is a multi-class classification problem, we will be using **Weighted Average** values to compare the model.\n\n**NOTE**: Why \"Weighted Average\"? Since we are dealing with a multi-class classification problem, Weighted Average is a better metric to compare the models. It assigns *class-wise weights* to each class and calculates each class's metrics accordingly."}}