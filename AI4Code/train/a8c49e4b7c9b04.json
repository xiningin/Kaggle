{"cell_type":{"cd780641":"code","4f36d4f7":"code","464018db":"code","a915ee78":"code","9c21cc26":"code","2e15e4ca":"code","039a0937":"code","acd5026a":"code","2acae887":"code","5c591f4c":"code","9d2869a0":"code","d4328762":"code","1a03be33":"code","2e939e18":"code","f8003321":"code","1ee6ad27":"code","c9fa376b":"code","16e4361e":"code","e1c0028b":"code","2f0190ea":"code","3d82d4d2":"code","1101796f":"code","eafa71e0":"code","cfa689ba":"code","ae6b072c":"code","31af4513":"code","27f5fa52":"code","14dc7fc1":"code","117a2b0d":"code","3d220780":"code","1e81c66b":"code","8242be8e":"code","3c5cd0cb":"code","c2d4fa6c":"code","9602a4a2":"code","186a1c4a":"code","e231a128":"code","425ed8a2":"code","c7386ca4":"code","60e7d3c6":"code","6a06f623":"code","e7ea1ee3":"markdown","379abc30":"markdown","c5388dda":"markdown","5689f826":"markdown","0bce4816":"markdown","3ce6e9af":"markdown"},"source":{"cd780641":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f36d4f7":"import os\nimport glob\nimport wandb\nimport json\nimport warnings\nimport imageio\nimport datetime\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML, Javascript\nimport IPython.display as py_display\nimport plotly.express as px\nfrom pandas_profiling import ProfileReport \nfrom IPython.display import Image\nimport missingno as msno\nfrom wordcloud import WordCloud, STOPWORDS\nfrom IPython.display import Markdown, display, Image, display_html\nfrom geopy.geocoders import Nominatim\nfrom geopy.geocoders import Nominatim\n#from geopy.distance import vincenty\n# Environment check\nwarnings.filterwarnings(\"ignore\")","464018db":"# Import data\n\ndistricts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\nproducts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")","a915ee78":"districts_info.head()\n","9c21cc26":"products_info","2e15e4ca":"districts_info.shape, products_info.shape","039a0937":"#number of missing values\ndistricts_info.isnull().sum().sum()","acd5026a":"#code from https:\/\/www.kaggle.com\/dmitryuarov\/eda-covid-19-impact-on-digital-learning\n\neng_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\neng_files = glob.glob(eng_path + \"\/*.csv\")\n\nfiles = []\n\nfor file in eng_files:\n    df = pd.read_csv(file, index_col = None, header = 0)\n    districts_id = file.split('\/')[4].split('.')[0]\n    df['district_id'] = districts_id\n    files.append(df)\n    \nengagement = pd.concat(files)\nengagement = engagement.reset_index(drop = True)\nengagement['time'] = pd.to_datetime(engagement['time'])","2acae887":"engagement.head()","5c591f4c":"#dropping null values in district_info\ndistricts_info.dropna(inplace = True)","9d2869a0":"#no more null values\ndistricts_info.isnull().sum().sum()","d4328762":"#null values in products_info\nproducts_info.isnull().sum().sum()","1a03be33":"#dropping null values in products_info\nproducts_info.dropna(inplace = True)","2e939e18":"products_info.isnull().sum().sum()","f8003321":"engagement.shape","1ee6ad27":"engagement.isnull().sum()","c9fa376b":"engagement.dropna( inplace = True)","16e4361e":"engagement.isnull().sum()","e1c0028b":"#plotting functions\ndef plot_hist(df: pd.DataFrame, column: str, color: str) -> None:\n    plt.figure(figsize=(9, 7))\n    sns.displot(data=df, x=column, color=color, kde=True, height=7, aspect=2)\n    plt.title(f'Distribution of {column}', size=20, fontweight='bold')\n    plt.show()\n\n\ndef plot_dist(df: pd.DataFrame, column: str):\n    plt.figure(figsize=(9, 7))\n    sns.distplot(df).set_title(f'Distribution of {column}')\n    plt.show()\n\n\ndef plot_count(df: pd.DataFrame, column: str) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.countplot(data=df, x=column)\n    plt.title(f'Plot count of {column}', size=20, fontweight='bold')\n    plt.show()\n\n\ndef plot_bar(df, x_col, y_col, title=''):\n    plt.figure(figsize=(20, 7))\n    sns.barplot(data = df, x=x_col, y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks( fontsize=14)\n    plt.xlabel(x_col, fontsize=16)\n    plt.ylabel(y_col, fontsize=16)\n    plt.show()\n\n\ndef plot_heatmap(df: pd.DataFrame, title: str, cbar=False) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.heatmap(df, annot=True, cmap='viridis', vmin=0,\n                vmax=1, fmt='.2f', linewidths=.7, cbar=cbar)\n    plt.title(title, size=18, fontweight='bold')\n    plt.show()\n\n\ndef plot_box(df: pd.DataFrame, x_col: str, title: str) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.boxplot(data=df, x=x_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.show()\n\n\ndef plot_box_multi(df: pd.DataFrame, x_col: str, y_col: str, title: str) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.boxplot(data=df, x=x_col, y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n\n\ndef plot_scatter(df: pd.DataFrame, x_col: str, y_col: str, title: str, hue: str, style: str) -> None:\n    plt.figure(figsize=(10, 8))\n    sns.scatterplot(data=df, x=x_col, y=y_col, hue=hue, style=style)\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n    \ndef time_plot(df, x_col, y_col, title=''):\n    plt.figure(figsize=(20, 7))\n    sns.lineplot(data=df, x=x_col, y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks( fontsize=14)\n    plt.xlabel(x_col, fontsize=16)\n    plt.ylabel(y_col, fontsize=16)\n    plt.show()\n    \n","2f0190ea":"plot_count(districts_info, 'locale')","3d82d4d2":"plot_count(districts_info, 'pct_black\/hispanic')","1101796f":"def plot_count_hor(df, col, title, hue=None):\n    plt.figure(figsize=(20, 7))\n    sns.countplot(data = df, y=col, hue=hue, order=df[col].value_counts().index)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks( fontsize=14)\n    plt.xlabel(col, fontsize=16)\n    plt.ylabel(\"Count\", fontsize=16)\n    plt.show()","eafa71e0":"plot_count_hor(districts_info,'state','plot count of state')","cfa689ba":"plot_hist(districts_info, 'pp_total_raw','orange')","ae6b072c":"plot_count_hor(districts_info,'pp_total_raw','plot count of state')","31af4513":"profile = ProfileReport( districts_info, title='Pandas profiling report for districts_info ' , html={'style':{'full_width':True}})\nprofile.to_notebook_iframe()","27f5fa52":"profile = ProfileReport( products_info, title='Pandas profiling report for products_info ' , html={'style':{'full_width':True}})\nprofile.to_notebook_iframe()","14dc7fc1":"profile = ProfileReport( engagement, title='Pandas profiling report ' , html={'style':{'full_width':True}})\nprofile.to_notebook_iframe()","117a2b0d":"fig, ax = plt.subplots(1, 1, figsize=(8,4))\n\nsns.histplot(engagement.groupby('district_id').time.nunique(), bins=30)\nax.set_title('Days of Engagement Data per District')\nplt.show()","3d220780":"graph1 = engagement.groupby('time').agg({'engagement_index': 'mean', 'pct_access': 'mean', 'lp_id': 'count'}).\\\n            reset_index()\n\ntime_plot(graph1, \"time\", \"engagement_index\", title='Engagement Over Time')","1e81c66b":"time_plot(graph1, \"time\", \"pct_access\", title='Percentage of Access Over Time')","8242be8e":"product_engagement_df = pd.merge(engagement, products_info, left_on='lp_id', right_on='LP ID' )","3c5cd0cb":"#changing the data type of district_id to int for merging\nproduct_engagement_df[[\"district_id\"]] = product_engagement_df[[\"district_id\"]].apply(pd.to_numeric)","c2d4fa6c":"product_engagement_df= pd.merge(product_engagement_df, districts_info, left_on='district_id', right_on='district_id' )","9602a4a2":"graph2 = product_engagement_df.groupby(['locale', 'Product Name']).agg({'time': 'count'})\ngraph2 = graph2.reset_index()\n\ndef per_local(locale):\n    local  =  graph2[graph2['locale'] == locale]\n    \n    new_df = pd.DataFrame({\"Product Name\": local['Product Name'], \"time\": local['time']})\n    top_10 = new_df.sort_values(by='time', ascending=False).head(10)\n    plot_bar(top_10, \"Product Name\", \"time\", title=f'Top Used application In {locale}')\n#     plot_bar(top_10, \"Product Name\", 'time', title=f'Top Used application In {locale}', None, None) \n\nfor local in graph2.locale.unique():\n    per_local(local)","186a1c4a":"#credit for this code https:\/\/www.kaggle.com\/iamleonie\/how-to-approach-analytics-challenges\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_info['state_abbrev'] = districts_info['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_info['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    geo_scope='usa',\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations=districts_info_by_state.state_abbrev,\n        zmax=1,\n        z = districts_info_by_state.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='white',\n        geo='geo',\n        colorscale=px.colors.sequential.Teal, \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","e231a128":"districts_info.pp_total_raw.unique()\ntemp = districts_info.groupby('locale').pp_total_raw.value_counts().to_frame()\ntemp.columns = ['amount']\n\ntemp = temp.reset_index(drop=False)\n\ntemp = temp.pivot(index='locale', columns='pp_total_raw')['amount']\ntemp = temp[['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[',  '[22000, 24000[' ]]\n\n\nfig, ax = plt.subplots(1, 2, figsize=(24,4))\n\nsns.countplot(data=districts_info, x='locale', ax=ax[0], palette='GnBu')\n\nsns.heatmap(temp, annot=True,  cmap='GnBu', ax=ax[1])\nax[1].set_title('Heatmap of Districts According To locale and pp_total_raw')\nplt.show()","425ed8a2":"\ndef replace_ranges_pct(range_str):\n    if range_str == '[0, 0.2[':\n        return 0.1\n    elif range_str == '[0.2, 0.4[':\n        return 0.3\n    elif range_str == '[0.4, 0.6[':\n        return 0.5\n    elif range_str == '[0.6, 0.8[':\n        return 0.7\n    elif range_str == '[0.8, 1[':\n        return 0.9\n    else:\n        return np.nan\n    \ndef replace_ranges_raw(range_str):\n    if range_str == '[4000, 6000[':\n        return 5000\n    elif range_str == '[6000, 8000[':\n        return 7000\n    elif range_str == '[8000, 10000[':\n        return 9000\n    elif range_str == '[10000, 12000[':\n        return 11000\n    elif range_str ==  '[12000, 14000[':\n        return 13000\n    elif range_str ==  '[14000, 16000[':\n        return 15000\n    elif range_str == '[16000, 18000[':\n        return 17000\n    elif range_str ==  '[18000, 20000[':\n        return 19000\n    elif range_str ==  '[20000, 22000[':\n        return 21000\n    elif range_str ==  '[22000, 24000[':\n        return 21000\n    else: \n        return np.nan\n    \ndistricts_info['pct_black_hispanic_num'] = districts_info['pct_black\/hispanic'].apply(lambda x: replace_ranges_pct(x))\ndistricts_info['pct_free_reduced_num'] = districts_info['pct_free\/reduced'].apply(lambda x: replace_ranges_pct(x))\ndistricts_info['pp_total_raw_num'] = districts_info['pp_total_raw'].apply(lambda x: replace_ranges_raw(x))\n\ndef plot_state_mean_for_var(col):\n    temp = districts_info.groupby('state_abbrev')[col].mean().to_frame().reset_index(drop=False)\n\n    fig = go.Figure()\n    layout = dict(\n        title_text = f\"Mean {col} per State\",\n        geo_scope='usa',\n    )\n\n    fig.add_trace(\n        go.Choropleth(\n            locations=temp.state_abbrev,\n            zmax=1,\n            z = temp[col],\n            locationmode = 'USA-states', # set of locations match entries in `locations`\n            marker_line_color='white',\n            geo='geo',\n            colorscale=px.colors.sequential.Teal, \n        )\n    )\n\n    fig.update_layout(layout)   \n    fig.show()\n\nplot_state_mean_for_var('pct_black_hispanic_num')\nplot_state_mean_for_var('pct_free_reduced_num')\nplot_state_mean_for_var('pp_total_raw_num')","c7386ca4":"cloud = WordCloud(width=1440, height=1080,stopwords={'nan'}).generate(\" \".join(products_info['Provider\/Company Name'].astype(str)))\nplt.figure(figsize=(15, 10))\nplt.imshow(cloud)\nplt.axis('off')","60e7d3c6":"cloud = WordCloud(width=1440, height=1080,stopwords={'nan'}).generate(\" \".join(districts_info['state'].astype(str)))\nplt.figure(figsize=(15, 10))\nplt.imshow(cloud)\nplt.axis('off')","6a06f623":"cloud = WordCloud(width=1440, height=1080,stopwords={'nan'}).generate(\" \".join(products_info['Product Name'].astype(str)))\nplt.figure(figsize=(15, 10))\nplt.imshow(cloud)\nplt.axis('off')","e7ea1ee3":"The engagement data are aggregated at school district level, and each file in the folder engagement_data represents data from one school district. The 4-digit file name represents district_id which can be used to link to district information in district_info.csv. The lp_id can be used to link to product information in product_info.csv.Loading the engagemnt data is a little bit tricky, we want to reserve the file names(since they are district ids) and load all the data in one data frame.","379abc30":"What is an Engagement Index?\nTotal page-load events per one thousand students of a given product and on a given day. For example, if district A has an engagement index of 26666.66 for product X on 2021-08-10, that means there were 26666.66 page-load events per 1000 students for product X on 2021-08-10","c5388dda":"We've seen how engagement relates to various factors.\nThis is still in progress,in the future using covid data sets as additional data will allow us to answer what is the effect of covid-19 pandemic on learning ","5689f826":"**Problem Statement**\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States.\nIn the Spring of 2020, most states and local governments across the U.S. closed educational institutions\nto stop the spread of the virus. In response, schools and teachers have attempted to reach students \nremotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting\ndigital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.\n\n**Challenge**\n\n(1) the state of digital learning in 2020 \n(2) how the engagement of digital learning relates to factors such as district demographics, broadband access,\n    and state\/national level policies and events.\n\n**DATA Description**\n\nThe data is a set of daily edtech engagement data from over 200 school districts in 2020.\n\nThe engagement_ data folder is based on LearnPlatform\u2019s Student Chrome Extension. The extension collects page load events of over 10K education technology products in our product library, including websites, apps, web apps, software programs, extensions, ebooks, hardwares, and services used in educational institutions. The districts_info.csv file includes information about the characteristics of school districts, including data from NCES and FCC.\nThe districts file includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab:\n\ndistrist_id\nstate\nlocale\npct_black\/hispanic - percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data.\npct_free\/reduced - percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data.\ncounty_connections_ratio - ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version).\npp_total_raw - per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project.\n\n\n\n","0bce4816":"districts_info data set \n\nName                                   Description\ndistrict_id         =    The unique identifier of the school district\nstate               =    The state where the district resides in\nlocale              =    NCES locale classification that categorizes U.S. territory into four types of areas: City,                          Suburban, Town,and Rural. See Locale Boundaries User's Manual for more information\npct_black\/hispanic  =    Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES                     data\npct_free\/reduced    =    Percentage of students in the districts eligible for free or reduced-price lunch based on                          2018-19 NCES data\ncountyconnectionsratio = ratio (residential fixed high-speed connections over 200 kbps in at least one                                      direction\/households) based on the county level data from FCC From 477 (December 2018                              version). See FCC data for more information.\npptotalraw           =   Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's                            National Education Resource Database on Schools (NERD$) project. The expenditure data are                          school-by-school, and we use the median value to represent the expenditure of a given                              school district.","3ce6e9af":"Products_info data set\nName                                    Description\nLP ID                        =  The unique identifier of the product\nURL                          =  Web Link to the specific product\nProduct Name                 =  Name of the specific product\nProvider\/Company Name        =  Name of the product provider\nSector(s)                    =  Sector of education where the product is used\nPrimary Essential Function : =  The basic function of the product. There are two layers of labels here. Products                                   are first labeled as one of these three categories: LC = Learning & Curriculum, CM                                 = Classroom Management, and SDO = School & District Operations. Each of these                                       categories have multiple sub-categories with which the products were labeled\n"}}