{"cell_type":{"231954c0":"code","958e2bdb":"code","724761db":"code","2d871a7c":"code","73184744":"code","499b9632":"code","e156914c":"code","a3aabe5c":"code","4f9ffdc6":"code","70d3a7ce":"code","72a31efb":"code","95b22bd8":"code","be8ff89b":"code","4e01eacf":"code","90a05283":"code","54a13c10":"code","833a23eb":"code","019fab3e":"code","82caead8":"code","a4e856db":"code","4ed33128":"code","be1ff345":"code","923f35ee":"code","eb081b2e":"code","fc54b7bf":"code","494594cb":"code","37ae23cf":"code","1b954faf":"code","fea6c411":"code","c3d48b3d":"code","b9f552aa":"code","024e8899":"code","2f79da7e":"code","32d23cda":"code","43a51d40":"code","d8565c4b":"code","2ae64ee0":"code","3ee88186":"code","cdd65a9f":"markdown","ed145285":"markdown","e77c8716":"markdown","15d4aa0f":"markdown","fc0688fe":"markdown","bb43a0c9":"markdown","da8dff34":"markdown","2c89ad94":"markdown","87e0d57c":"markdown","2d4af995":"markdown","0a53253c":"markdown","90ec6a6c":"markdown"},"source":{"231954c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom matplotlib.patches import Rectangle\nimport seaborn as sns\nimport pydicom as dcm\n%matplotlib inline \nIS_LOCAL = True\nimport os\nif(IS_LOCAL):\n    PATH=\"..\/input\/rsna-pneumonia-detection-challenge\"\nelse:\n    PATH=\"..\/input\/\"\nprint(os.listdir(PATH))\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","958e2bdb":"import matplotlib\nimport matplotlib.pyplot as plt\n#from tqdm import tqdm_notebook\nfrom matplotlib.patches import Rectangle\nimport seaborn as sns\nimport pydicom as dcm\n%matplotlib inline","724761db":"train_labels_df = pd.read_csv('\/kaggle\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_labels.csv')\nclass_info_df = pd.read_csv('\/kaggle\/input\/rsna-pneumonia-detection-challenge\/stage_2_detailed_class_info.csv')","2d871a7c":"class_info_df.sample(5)","73184744":"TRAIN_PATH = \"..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_images\"\nTEST_PATH = \"..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_images\"","499b9632":"len(TRAIN_PATH)","e156914c":"len(TEST_PATH)","a3aabe5c":"print(os.listdir(TRAIN_PATH))","4f9ffdc6":"def count_missing_data(data_df):\n    total = data_df.isnull().sum().sort_values(ascending = False)\n    percent = (data_df.isnull().sum()\/data_df.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","70d3a7ce":"count_missing_data(train_labels_df)","72a31efb":"count_missing_data(class_info_df)","95b22bd8":"class_info=class_info_df[\"class\"].value_counts()\n\nlabels = (np.array(class_info.index))\nsizes = (np.array((class_info \/ class_info.sum())*100))\ncolors = ['violet', 'yellow','red']\nplt.pie(sizes, labels=labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title(\"Class percentage\")\nplt.show()","be8ff89b":"train_class_df = train_labels_df.merge(class_info_df, left_on='patientId', right_on='patientId', how='inner')\ntrain_class_df.sample(5)","4e01eacf":"# Let's plot the number of examinations for each class detected, grouped by Target value.\nfig, ax = plt.subplots(nrows=1,figsize=(6,6))\ntmp = train_class_df.groupby('Target')['class'].value_counts()\ndf = pd.DataFrame(data={'Exams': tmp.values}, index=tmp.index).reset_index()\nsns.barplot(ax=ax,x = 'Target', y='Exams',hue='class',data=df, palette='Set3')\nplt.title(\"Chest exams class and Target\")\nplt.show()","90a05283":"#Locating the penumonia location\n\ntrain_class_df['x_center']=train_class_df['x'] + train_class_df['width']\/2\ntrain_class_df['y_center']=train_class_df['y'] + train_class_df['height']\/2\n# Plot x and y centers\nsns.jointplot(\"x_center\", \"y_center\",kind=\"kde\", data=train_class_df, height=9, alpha=0.5)\nplt.suptitle('Pneumonia location')","54a13c10":"## Aspect ratio of bounding boxes in the sample\ntrain_class_df['aspect_ratio'] = train_class_df['width']\/train_class_df['height']\nsns.distplot(train_class_df['aspect_ratio'].dropna(), norm_hist=True)\nplt.title('Distribution plot: Aspect ratio of bounding boxes of images in the sample')\nplt.show()\n\n# Area of bounding boxes in the sample\ntrain_class_df['area'] = train_class_df['width']* train_class_df['height']\nsns.distplot(train_class_df['area'].dropna(), norm_hist=True)\nplt.title('Distribution plot: Area of bounding boxes of images in the sample')\nplt.show()\n\n# Relationship between aspect ratio and area of bounding boxes of images in the sample\nsns.relplot(x='area', y='aspect_ratio', data=train_class_df, height=5, alpha=0.7, aspect=1.4)\nplt.title('Aspect ratio and area of bounding boxes of images in the sample')\nplt.show()","833a23eb":"# For the class Lung Opacity, corresponding to values of Target = 1, we plot the density of x, y, width and height.\ntarget1 = train_class_df[train_class_df['Target']==1]\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(2,2,figsize=(12,12))\nsns.distplot(target1['x'],kde=True,bins=50, color=\"violet\", ax=ax[0,0])\nsns.distplot(target1['y'],kde=True,bins=50, color=\"red\", ax=ax[0,1])\nsns.distplot(target1['width'],kde=True,bins=50, color=\"green\", ax=ax[1,0])\nsns.distplot(target1['height'],kde=True,bins=50, color=\"yellow\", ax=ax[1,1])\nlocs, labels = plt.xticks()\nplt.tick_params(axis='both', which='major', labelsize=12)\nplt.show()","019fab3e":"image_sample_path = os.listdir(PATH+'\/stage_2_train_images')[:5]\nprint(image_sample_path)","82caead8":"# Read the 'train' and 'test' image data\nimage_train_path = os.listdir(PATH+'\/stage_2_train_images')\nimage_test_path = os.listdir(PATH+'\/stage_2_test_images')\nprint(\"Number of images in train set:\", len(image_train_path),\"\\nNumber of images in test set:\", len(image_test_path))","a4e856db":"# check for duplicate reconrds in training set\nprint(\"Unique patientId in  train_class_df: \", train_class_df['patientId'].nunique()) ","4ed33128":"train_class_df.shape","be1ff345":"tmp = train_class_df.groupby(['patientId','Target', 'class'])['patientId'].count()\ndf = pd.DataFrame(data={'Exams': tmp.values}, index=tmp.index).reset_index()\ntmp = df.groupby(['Exams','Target','class']).count()\ndf2 = pd.DataFrame(data=tmp.values, index=tmp.index).reset_index()\ndf2.columns = ['Exams', 'Target','Class', 'Entries']\ndf2","923f35ee":"samplePatientID = list(train_class_df[:3].T.to_dict().values())[0]['patientId']\nsamplePatientID = samplePatientID+'.dcm'\ndicom_file_path = os.path.join(PATH,\"stage_2_train_images\/\",samplePatientID)\ndicom_file_dataset = dcm.read_file(dicom_file_path)\ndicom_file_dataset","eb081b2e":"def show_dicom_images(data):\n    img_data = list(data.T.to_dict().values())\n    f, ax = plt.subplots(3,3, figsize=(16,18))\n    for i,data_row in enumerate(img_data):\n        patientImage = data_row['patientId']+'.dcm'\n        imagePath = os.path.join(PATH,\"stage_2_train_images\/\",patientImage)\n        data_row_img_data = dcm.read_file(imagePath)\n        modality = data_row_img_data.Modality\n        age = data_row_img_data.PatientAge\n        sex = data_row_img_data.PatientSex\n        data_row_img = dcm.dcmread(imagePath)\n        ax[i\/\/3, i%3].imshow(data_row_img.pixel_array, cmap=plt.cm.bone) \n        ax[i\/\/3, i%3].axis('off')\n        ax[i\/\/3, i%3].set_title('ID: {}\\nModality: {} Age: {} Sex: {} Target: {}\\nClass: {}\\nWindow: {}:{}:{}:{}'.format(\n                data_row['patientId'],\n                modality, age, sex, data_row['Target'], data_row['class'], \n                data_row['x'],data_row['y'],data_row['width'],data_row['height']))\n    plt.show()","fc54b7bf":"show_dicom_images(train_class_df[train_class_df['Target']==1].sample(9))","494594cb":"def show_dicom_images_with_boxes(data):\n    img_data = list(data.T.to_dict().values())\n    f, ax = plt.subplots(3,3, figsize=(16,18))\n    for i,data_row in enumerate(img_data):\n        patientImage = data_row['patientId']+'.dcm'\n        imagePath = os.path.join(PATH,\"stage_2_train_images\/\",patientImage)\n        data_row_img_data = dcm.read_file(imagePath)\n        modality = data_row_img_data.Modality\n        age = data_row_img_data.PatientAge\n        sex = data_row_img_data.PatientSex\n        data_row_img = dcm.dcmread(imagePath)\n        ax[i\/\/3, i%3].imshow(data_row_img.pixel_array, cmap=plt.cm.bone) \n        ax[i\/\/3, i%3].axis('off')\n        ax[i\/\/3, i%3].set_title('ID: {}\\nModality: {} Age: {} Sex: {} Target: {}\\nClass: {}'.format(\n                data_row['patientId'],modality, age, sex, data_row['Target'], data_row['class']))\n        rows = train_class_df[train_class_df['patientId']==data_row['patientId']]\n        box_data = list(rows.T.to_dict().values())\n        for j, row in enumerate(box_data):\n            ax[i\/\/3, i%3].add_patch(Rectangle(xy=(row['x'], row['y']),\n                        width=row['width'],height=row['height'], \n                        color=\"blue\",alpha = 0.1))   \n    plt.show()","37ae23cf":"show_dicom_images_with_boxes(train_class_df[train_class_df['Target']==1].sample(9))","1b954faf":"show_dicom_images(train_class_df[train_class_df['Target']==0].sample(9))","fea6c411":"import os\nimport csv\nimport random\nimport pydicom\nimport numpy as np\nimport pandas as pd\nfrom skimage import io\nfrom skimage import measure\nfrom skimage.transform import resize\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.patches as patches","c3d48b3d":"# empty dictionary\npneumonia_locations = {}\n# load table\nwith open(os.path.join(PATH+'\/stage_2_train_labels.csv'), mode='r') as infile:\n    # open reader\n    reader = csv.reader(infile)\n    # skip header\n    next(reader, None)\n    # loop through rows\n    for rows in reader:\n        # retrieve information\n        filename = rows[0]\n        location = rows[1:5]\n        pneumonia = rows[5]\n        # if row contains pneumonia add label to dictionary\n        # which contains a list of pneumonia locations per filename\n        if pneumonia == '1':\n            # convert string to float to int\n            location = [int(float(i)) for i in location]\n            # save pneumonia location in dictionary\n            if filename in pneumonia_locations:\n                pneumonia_locations[filename].append(location)\n            else:\n                pneumonia_locations[filename] = [location]","b9f552aa":"# load and shuffle filenames\nfolder = PATH+'\/stage_2_train_images'\nfilenames = os.listdir(folder)\nrandom.shuffle(filenames)\n# split into train and validation filenames\nn_valid_samples = 2560\ntrain_filenames = filenames[n_valid_samples:]\nvalid_filenames = filenames[:n_valid_samples]\nprint('n train samples', len(train_filenames))\nprint('n valid samples', len(valid_filenames))\nn_train_samples = len(filenames) - n_valid_samples\nprint('Total train images:',len(filenames))\nprint('Images with pneumonia:', len(pneumonia_locations))","024e8899":"class generator(keras.utils.Sequence):\n    \n    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=256, shuffle=True, augment=False, predict=False):\n        self.folder = folder\n        self.filenames = filenames\n        self.pneumonia_locations = pneumonia_locations\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.predict = predict\n        self.on_epoch_end()\n        \n    def __load__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n        # create empty mask\n        msk = np.zeros(img.shape)\n        # get filename without extension\n        filename = filename.split('.')[0]\n        # if image contains pneumonia\n\n        if filename in pneumonia_locations:\n            # loop through pneumonia\n            for location in pneumonia_locations[filename]:\n                # add 1's at the location of the pneumonia\n                x, y, w, h = location\n                msk[y:y+h, x:x+w] = 1\n        # if augment then horizontal flip half the time\n        if self.augment and random.random() > 0.5:\n            img = np.fliplr(img)\n            msk = np.fliplr(msk)\n        # resize both image and mask\n        img = resize(img, (self.image_size, self.image_size), mode='symmetric')\n        msk = resize(msk, (self.image_size, self.image_size), mode='symmetric') > 0.5\n        \n        \n\n        # add trailing channel dimension\n        img = np.expand_dims(img, -1)\n        msk = np.expand_dims(msk, -1)\n        return img, msk\n    \n    def __loadpredict__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n        # resize image\n        img = resize(img, (self.image_size, self.image_size), mode='symmetric')\n        # add trailing channel dimension\n        img = np.expand_dims(img, -1)\n        return img\n        \n    def __getitem__(self, index):\n        # select batch\n        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n        # predict mode: return images and filenames\n        if self.predict:\n            # load files\n            imgs = [self.__loadpredict__(filename) for filename in filenames]\n            # create numpy batch\n            imgs = np.array(imgs)\n            return imgs, filenames\n        # train mode: return images and masks\n        else:\n            # load files\n            items = [self.__load__(filename) for filename in filenames]\n            # unzip images and masks\n            imgs, msks = zip(*items)\n            # create numpy batch\n            imgs = np.array(imgs)\n            msks = np.array(msks)\n            return imgs, msks\n        \n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n        \n    def __len__(self):\n        if self.predict:\n            # return everything\n            return int(np.ceil(len(self.filenames) \/ self.batch_size))\n        else:\n            # return full batches only\n            return int(len(self.filenames) \/ self.batch_size)","2f79da7e":"def create_downsample(channels, inputs):\n    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n    x = keras.layers.MaxPool2D(2)(x)\n    # Added start\n    #x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n    #x = keras.layers.MaxPool2D(2)(x)\n    # Added End\n    return x\n\n\ndef create_resblock(channels, inputs):\n    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n\n    #Added Start\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n    #Added End\n    \n    addInput = x;\n    print(\"Add input shape:\", addInput.shape)\n    print(\"Resnet block input shape:\", inputs.shape)\n    resBlockOut = keras.layers.add([addInput, inputs])\n    print(\"Resnet block out shape:\", resBlockOut.shape)\n    out = keras.layers.concatenate([resBlockOut, addInput], axis=3)\n    print(\"concat block out shape:\", out.shape)\n    out = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(out)\n    print(\"mixed block out shape:\", out.shape)\n    return out\n\ndef create_network(input_size, channels, n_blocks=2, depth=4):\n    # input\n    inputs = keras.Input(shape=(input_size, input_size, 1))\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n    # residual blocks\n    for d in range(depth):\n        channels = channels * 2\n        x = create_downsample(channels, x)\n        for b in range(n_blocks):\n            x = create_resblock(channels, x)\n    # output\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n    outputs = keras.layers.UpSampling2D(2**depth)(x)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model\n\n","32d23cda":"# define iou or jaccard loss function\ndef iou_loss(y_true, y_pred):\n    y_true = tf.reshape(y_true, [-1])\n    y_pred = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true * y_pred)\n    score = (intersection + 1.) \/ (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n    return 1 - score\n\n# combine bce loss and iou loss\ndef iou_bce_loss(y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n\n# mean iou as a metric\ndef mean_iou(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n    smooth = tf.ones(tf.shape(intersect))\n    return tf.reduce_mean((intersect + smooth) \/ (union - intersect + smooth))\n\n\n","43a51d40":"# create network and compiler\nmodel = create_network(input_size=128, channels=16, n_blocks=2, depth=3)\nmodel.compile(optimizer='adam',\n              loss=iou_bce_loss,\n              metrics=['accuracy', mean_iou])\nprint(\"model summary:\", model.summary())\n# cosine learning rate annealing\ndef cosine_annealing(x):\n    lr = 0.001\n    epochs = 25\n    return lr*(np.cos(np.pi*x\/epochs)+1.)\/2\nlearning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)","d8565c4b":"# create train and validation generators\nfolder = PATH+'\/stage_2_train_images'\n\n\ntrain_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=16, image_size=128, shuffle=False, augment=True, predict=False)\nvalid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=16, image_size=128, shuffle=False, predict=False)\n\nhistory = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=10, shuffle=True, verbose=2)\n\n\n","2ae64ee0":"plt.figure(figsize=(12,4))\nplt.subplot(131)\nplt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nplt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\nplt.legend()\nplt.subplot(132)\nplt.plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\nplt.plot(history.epoch, history.history[\"val_accuracy\"], label=\"Valid accuracy\")\nplt.legend()\nplt.subplot(133)\nplt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\nplt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\nplt.legend()\nplt.show()","3ee88186":"for imgs, msks in valid_gen:\n    # predict batch of images\n    preds = model.predict(imgs)\n    # create figure\n    f, axarr = plt.subplots(4, 8, figsize=(20,15))\n    axarr = axarr.ravel()\n    axidx = 0\n    # loop through batch\n    for img, msk, pred in zip(imgs, msks, preds):\n        # plot image\n        axarr[axidx].imshow(img[:, :, 0])\n        # threshold true mask\n        comp = msk[:, :, 0] > 0.5\n        # apply connected components\n        comp = measure.label(comp)\n        # apply bounding boxes\n        predictionString = ''\n        for region in measure.regionprops(comp):\n            # retrieve x, y, height and width\n            y, x, y2, x2 = region.bbox\n            height = y2 - y\n            width = x2 - x\n            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='b',facecolor='none'))\n        # threshold predicted mask\n        comp = pred[:, :, 0] > 0.5\n        # apply connected components\n        comp = measure.label(comp)\n        # apply bounding boxes\n        predictionString = ''\n        for region in measure.regionprops(comp):\n            # retrieve x, y, height and width\n            y, x, y2, x2 = region.bbox\n            height = y2 - y\n            width = x2 - x\n            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='r',facecolor='none'))\n        axidx += 1\n    plt.show()\n    # only plot one batch\n    break\n\n","cdd65a9f":"## Check the class Distribution ","ed145285":"But the total number of records are 37629. So we have to find out which all records are duplicates","e77c8716":"Refrences :- \n\nhttps:\/\/www.kaggle.com\/jonnedtc\/cnn-segmentation-connected-components\n","15d4aa0f":"### Extract one image and process the DICOM information.","fc0688fe":"## Plot DICOM images with Target = 1, with bounding boxes","bb43a0c9":"## Merge both the Dataset","da8dff34":"# Build the Model","2c89ad94":"# Data Exploration","87e0d57c":"## DICOM DATA","2d4af995":"# Load the Dataset","0a53253c":"# Import Necessary Packages ","90ec6a6c":"All chest examinations withTarget = 1 (pathology detected) associated with class: Lung Opacity.\nThe chest examinations with Target = 0 (no pathology detected) are either of class: Normal or class: No Lung Opacity \/ Not Normal."}}