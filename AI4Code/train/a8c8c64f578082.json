{"cell_type":{"49b5fbf5":"code","18587505":"code","16546121":"code","77d4a34e":"code","c546ddf6":"code","a6588e5b":"code","63e48806":"code","3bef842d":"code","1f49aec6":"code","110744c0":"code","31b23344":"code","05e50cdc":"code","e3cbbae6":"code","580c958f":"code","0009dec2":"code","ced9f953":"code","8b9d7be6":"code","2dd7b3c8":"code","17affd36":"code","fc8b77e0":"code","9a59de80":"code","e4968f00":"code","3be90862":"code","ca199ae0":"code","feb1e99b":"code","96f98a5e":"markdown"},"source":{"49b5fbf5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18587505":"\n!pip install -U textblob\n!pip install googletrans\n#Import libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom googletrans import Translator # translate cities name into english \nfrom textblob import TextBlob\n\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n","16546121":"#Read Dataset\ndf = pd.read_csv(\"..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv\",encoding=\"utf-8\", delimiter=',')\ndf.sample(20)\n","77d4a34e":"#shape of the data (row, and column)\nRow, Col = df.shape\nprint(f'There are {Row} Rows and {Col} columns')","c546ddf6":"#need to rename columns, as they contain spaces in between which causes error\ndf = df.rename(columns={'Order Number': 'Order_Number',\"Order Status\":\"Order_Status\", \"Book Name\":\"Book_Name\",\"Order Date & Time\":\"Order_Date\",\"City\":\"City\",\"Payment Method\":\"Payment_Method\", \"Total items\":\"Total_items\",\"Total weight (grams)\":\"grams\" })\n","a6588e5b":"#Check Null values in data set\ndf.isnull().sum().sort_values(ascending = False).to_frame('counts')","63e48806":"#display rows with missing data to understand it \n\ndf[(df.apply(lambda x: sum(x.isnull().values), axis = 1)>0)]","3bef842d":"#completed, returned, cancelled orders (by customers)\ndf.Order_Status.value_counts().to_frame('count')","1f49aec6":"# Preprocess the date\n# Thanks to  @asim zahid\n\ndf[\"Order_Date\"] = pd.DatetimeIndex(df[\"Order_Date\"])\ndf['date'] = df['Order_Date'].dt.date\ndf['time'] = df['Order_Date'].dt.time\ndf[\"Day_Name\"] = df[\"Order_Date\"].dt.day_name()\ndf[\"Week_Day\"] = df[\"Order_Date\"].dt.dayofweek\ndf[\"DayofYear\"] = df[\"Order_Date\"].dt.dayofyear\ndf[\"Month_Number\"] = df[\"Order_Date\"].dt.month\ndf[\"Month_Name\"] = df[\"Order_Date\"].dt.month_name()\ndf['year'] = df[\"Order_Date\"].dt.year\ndf.sample(10)","110744c0":"#payment methods used by customers in Pakistan\ndf['Payment_Method'] = df['Payment_Method'].replace({\"Cash on Delivery (COD)\": \"Cash on delivery\"})\ndf.Payment_Method.value_counts().to_frame('counts')","31b23344":"#display graphically the payment methods:\n# Set the width and height of the figure\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(10,4))\n\ndf.Payment_Method.value_counts().plot(kind='bar')\n\n# Rotate the x-labels by 30 degrees, and keep the text aligned horizontally\nplt.xticks(rotation=30, horizontalalignment=\"center\")\nplt.title(\"Payment Methods opted by customers in Pakistan\")\nplt.xlabel(\"Payment Modes\")\nplt.ylabel(\"Frequency (orders delivered to customers)\")\nplt.show()","05e50cdc":"#Check NaN in Book_Name\ndf[df['Book_Name'].isna()]\n\n","e3cbbae6":"#Delete all NaN from dataframe\ndf.dropna(inplace=True)\ndf.isnull().sum()\n","580c958f":"#Split the Book_Name column with '\/'and make a new row (Data Cleaning)\nsplit_col = df['Book_Name'].str.split('\/', expand=True).stack()\n\n# Melting dataframe so that we have one book in each row\nsplit_col.index = split_col.index.droplevel(-1) # to line up with df's index\nsplit_col.name = 'Book_Name' # needs a name to join\n\ndf = df.drop(columns='Book_Name').join(split_col)\ndf.head(15)","0009dec2":"#Convert Book_Name and City to lowercase\ndf['Book_Name'] = df['Book_Name'].str.lower()\ndf['City'] = df['City'].str.lower()\ndf['City'].head(8)\n","ced9f953":"\n\n# Source: https:\/\/simplemaps.com\/data\/pk-cities\n\npakistan_major_cities = ['karachi', 'lahore', 'sialkot', 'faisalabad', 'rawalpindi',\n       'peshawar', 'saidu sharif', 'multan', 'gujranwala', 'islamabad',\n       'quetta', 'bahawalpur', 'sargodha', 'new mirpur', 'chiniot',\n       'sukkur', 'larkana', 'shekhupura', 'jhang', 'rahimyar khan',\n       'gujrat', 'kasur', 'mardan', 'mingaora', 'dera ghazi khan',\"dgk\"\n       'nawabshah', 'sahiwal', 'mirpur khas', 'okara', 'burewala',\n       'jacobabad', 'saddiqabad', 'kohat', 'muridke', 'muzaffargarh',\n       'khanpur', 'gojra', 'bahauddin', 'abbottabad', 'dadu',\n       'khuzdar', 'pakpattan', 'tando allahyar', 'vihari', 'jaranwala',\n       'kamalia', 'kot addu', 'nowshera', 'swabi', 'dera ismail khan',\n       'chaman', 'charsadda', 'kandhkot', 'hasilpur', 'muzaffarabad',\n       'mianwali', 'jalalpur\",\"jattan', 'bhakkar', 'zhob', 'kharian',\n       'mian channun', 'jamshoro', 'pattoki', 'harunabad',\n       'toba tek singh', 'shakargarh', 'hujra\", \"shah\", \"muqim', 'kabirwala',\n       'mansehra', 'lala musa', 'nankana sahib', 'bannu', 'timargara',\n       'parachinar', 'gwadar', 'abdul hakim', 'hassan\", \"abdal', 'tank',\n       'hangu', 'risalpur cantonment', 'karak', 'kundian', 'umarkot',\n       'chitral', 'dainyor', 'kulachi', 'kotli', 'gilgit',\n       'hyderabad', 'narowal', 'khairpur', \"mir\u2019s\", 'khanewal', 'jhelum',\n       'haripur', 'shikarpur', 'rawala kot', 'hafizabad', 'lodhran',\n       'malakand', 'attock', 'batgram', 'matiari', 'ghotki',\n       'firoz','naushahro', 'alpurai', 'bagh', 'daggar', 'bahawalnagar',\n       'leiah', 'tando muhammad khan', 'chakwal', 'khushab', 'badin',\n       'lakki', 'rajanpur', 'dera allahyar', 'shahdad kot', 'pishin',\n       'sanghar', 'upper dir', 'thatta', 'dera murad jamali', 'kohlu',\n       'mastung', 'dasu', 'athmuqam', 'loralai', 'barkhan',\n       'musa khel bazar', 'ziarat', 'gandava', 'sibi', 'dera bugti',\n       'eidgah', 'turbat', 'uthal', 'chilas', 'kalat', 'panjgur', 'gakuch',\n       'qila', 'saifullah', 'kharan', 'aliabad', 'awaran', 'dalbandin']","8b9d7be6":"#clean the City col:\nsingle_word_cities = df[df[\"City\"].str.split().apply(len) == 2][\"City\"].unique()\nsingle_word_cities[:20]","2dd7b3c8":"import nltk\n#function to clean City data\ndef clean_city(row):\n    address = row.City.split()\n    add = set()\n    for a in address:\n        a = a.strip()\n        if a:\n            add.add(a)\n    for city in pakistan_major_cities:\n        if row.City.__contains__(city):\n            return city\n        \n    for a in add:\n        for c in pakistan_major_cities:\n            if nltk.edit_distance(a, c) <= 5: # considering spelling mistakes upto 5 letters\n                return c\n    return row.City\n","17affd36":"#apply the function made above to clean cities\ndf[\"City\"] = df.apply(clean_city, axis=1)\ndf['City'].head()","fc8b77e0":"#Convert the 'day' column to day_name\n\ndf['order_date']= pd.to_datetime(df['Order_Date'])\n \n#Extracting year,month and day\ndf['year'] = df['order_date'].apply(lambda x : x.year)\ndf['month'] = df['order_date'].apply(lambda x : x.month)\ndf['day'] = df['order_date'].apply(lambda x : x.day_name())\ndf['weekday'] = df['order_date'].apply(lambda x : x.weekday())\n\n#Rearranging the columns\ndf_new=df[['Order_Number', 'Order_Status', 'Book_Name', 'Order_Date', 'City', 'year', 'month', 'day','weekday']]\ndf_new.head()","9a59de80":"# Find Daily sales\ndaily_sales = df.groupby([\"day\"])[\"Book_Name\"].agg([\"count\"]).reset_index()\ndaily_sales.sort_values(\"day\",ascending = True)","e4968f00":"# Monthly sales\nmonth_sales = df.groupby([\"month\"])[\"Book_Name\"].agg([\"count\"]).reset_index()\nmonth_sales.sort_values(\"month\",ascending = True)","3be90862":"#Finding Top 10 book sale\n#\nimport seaborn as sns\n\n#Setting plot style\nplt.figure(figsize = (30, 15))\nplt.style.use('seaborn-white')\n\n#Top 10 fast moving products\nplt.subplot(1,2,1)\nax=sns.countplot(y=\"Book_Name\", hue=\"year\", data=df_new, palette=\"pastel\",\n              order=df_new.Book_Name.value_counts().iloc[:10].index)\n\nax.set_xticklabels(ax.get_xticklabels(),fontsize=11,rotation=40, ha=\"right\")\nax.set_title('Top 10 books',fontsize= 30)\nax.set_xlabel('Frequency (of purchase)',fontsize = 15) \nax.set_ylabel('Top 10 Books', fontsize = 15)\nplt.tight_layout()","ca199ae0":"#Top 10 cities\ncity_sales1 = df_new['City'].value_counts()[:10].index.tolist()\ncity_sales2 = df_new['City'].value_counts().unique()\ncity_sales = list(zip(city_sales1, city_sales2)) \ncity_sales = pd.DataFrame(city_sales, \n                  columns = ['City', 'counts']) \ncity_sales","feb1e99b":"plt.figure(figsize = (15,8))\nsns.barplot(x =city_sales[\"City\"], y =city_sales[\"counts\"],color = \"Orange\",label = \"count\")\nplt.xlabel(\"City\")\nplt.ylabel(\"Sale\")\nplt.title(\"City wise Sale\")\nplt.xticks(rotation = 50)\nplt.legend()\nplt.show()","96f98a5e":"# **Gufhtugu Publisher is interested to know about the following questions:**\n\n\n1. What is the best-selling book?\n2. Visualize order status frequency\n3. Find a correlation between date and time with order status\n4. Find a correlation between city and order status\n5. Find any hidden patterns that are counter-intuitive for a layman\n6. Can we predict number of orders, or book names in advance?\n\nHave answered first two question here:\n"}}