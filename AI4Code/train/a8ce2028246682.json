{"cell_type":{"5c47a65c":"code","aab96936":"code","4e66bd90":"code","4ad1f3e6":"code","126664e3":"code","e1182798":"code","50129b51":"code","85927852":"code","d2f9cdf4":"code","71ce5b3a":"code","93e6144a":"code","70a12ddf":"code","d4caa115":"code","8ce20c51":"code","dd5724a9":"code","6017dbb9":"code","3643c051":"code","300f631e":"code","184354c0":"code","0bb68bce":"code","4ee05394":"code","b39252d1":"code","f73b4c18":"code","c7b7ee3c":"code","60df5844":"code","f2c77a2d":"code","55c56516":"markdown","2d05101b":"markdown"},"source":{"5c47a65c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aab96936":"#Import \ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4e66bd90":"#Check train\ntrain.isnull().sum()","4ad1f3e6":"#Check test\ntest.isnull().sum()","126664e3":"from sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import cross_val_score","e1182798":"full_data = [train, test]","50129b51":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \n# Create new feature IsAlone from FamilySize\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \n# Remove all NULLS in the Embarked column\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","85927852":"import re","d2f9cdf4":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n# Create a new feature Title, containing the titles of passenger names\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)","71ce5b3a":"for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\ndataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')","93e6144a":"for dataset in full_data:\n    dataset['Cabin'] = dataset['Cabin'].astype(str).str[0]","70a12ddf":"train.head()","d4caa115":"y = train['Survived']\nX = train.drop(['Survived','Name','Ticket'], axis = 1)","8ce20c51":"numerical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind in ['i','f'] and c !='PassengerId']\ncategorical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind not in ['i','f']]","dd5724a9":"numerical_features","6017dbb9":"categorical_features","3643c051":"#import train_test_split library\nfrom sklearn.model_selection import train_test_split\n\n# create train test split\nX_train, X_val, y_train, y_val = train_test_split( X,  y, test_size=0.3, random_state=0, stratify = y)","300f631e":"preprocessor = make_column_transformer(\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'median')\n        #,KBinsDiscretizer(n_bins=3)\n    ), numerical_features),\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'constant', fill_value = 'missing'),\n    OneHotEncoder(categories = 'auto', handle_unknown = 'ignore')), categorical_features),\n)","184354c0":"#from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","0bb68bce":"model_pipeline = make_pipeline(preprocessor,RandomForestClassifier(n_estimators = 200) )","4ee05394":"model_pipeline.fit(X_train, y_train)","b39252d1":"X_prediction = model_pipeline.predict(X_train)","f73b4c18":"print(f'Train : {model_pipeline.score(X_train, y_train):.3f}')","c7b7ee3c":"print(f'Test : {model_pipeline.score(X_val, y_val):.3f}')","60df5844":"submission_prediction = model_pipeline.predict(test.drop(['Name','Ticket'], axis = 1)).astype(int)\n#","f2c77a2d":"AllSub = pd.DataFrame({ 'PassengerId': test['PassengerId'],\n                       'Survived' : submission_prediction\n    \n})\n\nAllSub.to_csv(\"Solution_Pipeline_RF_IMproved.csv\", index = False)","55c56516":"New version","2d05101b":"# Feature Engineering"}}