{"cell_type":{"4e01c52e":"code","a5b4e2be":"code","fc6b8e29":"code","e82eee36":"code","ec21b8a2":"code","61711755":"code","42862d07":"code","39777a51":"code","15b98fe1":"code","ddf1707b":"code","14eda9f9":"code","ac4a806a":"code","6340933b":"code","bd4c13ec":"code","4c41ad36":"code","53b5f28b":"code","ae50ff35":"code","0ef8dc93":"code","0aa63ae4":"code","08f08a36":"code","04326afe":"code","f62b5731":"code","17a233e6":"code","01efb7a5":"code","63236340":"code","9297a9d4":"code","a32a8ed6":"code","9213b016":"code","8903773b":"code","ab5f1878":"markdown","4dafbfbc":"markdown","57c15e09":"markdown","985429f3":"markdown","b861ce80":"markdown","53c8b7b4":"markdown","be44327d":"markdown","0256b768":"markdown","d53a928a":"markdown"},"source":{"4e01c52e":"!pip install ktrain","a5b4e2be":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport ktrain\nfrom ktrain import text\nimport tensorflow as tf\nimport seaborn as sns","fc6b8e29":"tf.__version__","e82eee36":"## loading  dataset\n\ndata = pd.read_csv('\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\ndata.head()","ec21b8a2":"sns.countplot(data[\"sentiment\"])","61711755":"TRAIN_SIZE = 40000\nTEST_SIZE = 10000\n\ndata_train = data[:TRAIN_SIZE]\ndata_test = data[TRAIN_SIZE:].reset_index(drop=True)","42862d07":"data_train.head()","39777a51":"data_test.head()","15b98fe1":"sns.countplot(data_train[\"sentiment\"])","ddf1707b":"sns.countplot(data_test[\"sentiment\"])","14eda9f9":"#dimension of the dataset\n\nprint(\"Size of train dataset: \",data_train.shape)\nprint(\"Size of test dataset: \",data_test.shape)","ac4a806a":"# maxlen means it is considering that much words and rest are getting trucated\n# preprocess_mode means tokenizing, embedding and transformation of text corpus(here it is considering BERT model)\n\n\n(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df=data_train,\n                                                                   text_column = 'review',\n                                                                   label_columns = 'sentiment',\n                                                                   val_df = data_test,\n                                                                   maxlen = 500,\n                                                                   ngram_range=2,\n                                                                   preprocess_mode = 'bert') # ngram_range = 2","6340933b":"len(X_train[1])","bd4c13ec":"X_train[0].shape","4c41ad36":"# name = \"bert\" means, here we are using BERT model.\n\nmodel = text.text_classifier(name = 'bert',\n                             train_data = (X_train, y_train),\n                             preproc = preproc)","53b5f28b":"#here we have taken batch size as 6 as from the documentation it is recommend to use this with maxlen as 500\n\nlearner = ktrain.get_learner(model=model, train_data=(X_train, y_train),\n                   val_data = (X_test, y_test),\n                   batch_size = 6)","ae50ff35":"# To find the best lr, use below code, takes a day to train\n# learner.lr_find()\n# learner.lr_plot()","0ef8dc93":"#Essentially fit is a very basic training loop, whereas fit one cycle uses the one cycle policy callback\n\nlearner.fit_onecycle(lr = 2e-5, epochs = 1)","0aa63ae4":"predictor = ktrain.get_predictor(learner.model, preproc)\npredictor.save(\".\/models\/sentiment_analysis\")","08f08a36":"#sample dataset to test on\n\ndata = ['this movie was horrible, the plot was really boring. acting was okay',\n        'the fild is really sucked. there is not plot and acting was bad',\n        'what a beautiful movie. great plot. acting was good. will see it again']","04326afe":"predictor.predict(data)","f62b5731":"#return_proba = True means it will give the prediction probabilty for each class\n\npredictor.predict(data, return_proba=True)","17a233e6":"#classes available\n\npredictor.get_classes()","01efb7a5":"#loading the model\n\npredictor_load = ktrain.load_predictor(\".\/models\/sentiment_analysis\")","63236340":"#predicting the data\n\npredictor_load.predict(data)","9297a9d4":"new_data = [\"this movie is shit, feels like i have wasted my time\", \"best movie i have seen\", \"you are a good man\"]\nnew_prediction = predictor_load.predict(new_data, return_proba=True)\n\nfor i, pred in enumerate(new_prediction):\n    if np.argmax(pred) == 0:\n        print(f\"{new_data[i]} => {pred} => negative\")\n    else:\n        print(f\"{new_data[i]} => {pred}=> positive\")","a32a8ed6":"import os\nos.chdir(r'.\/models\/sentiment_analysis')","9213b016":"os.listdir()","8903773b":"for file in os.listdir():\n    print(f\"{file}: {round(os.path.getsize(file)\/1e+6,2)} MB\")","ab5f1878":"### Load the model","4dafbfbc":"### Model File Size","57c15e09":"## Model Building","985429f3":"### Saving Model","b861ce80":"## Prediction From Model","53c8b7b4":"#### Links to download model files\n<a href=\".\/models\/sentiment_analysis\/tf_model.h5\"> Download h5 Model <\/a><br>\n<a href=\".\/models\/sentiment_analysis\/tf_model.preproc\"> Download preproc Model <\/a>","be44327d":"### Splitting into train and test set","0256b768":"### Fitting The Model","d53a928a":"### Download Model"}}