{"cell_type":{"e308d6c4":"code","1d30434f":"code","c2293c23":"code","4201190c":"code","4fce5fde":"code","41952549":"code","a0ac7a89":"code","2fddeef9":"code","98415942":"code","85dea110":"code","8a8ccd27":"code","3d2209d8":"code","002fc69d":"code","13d5963e":"code","fbdeb123":"code","d6292a2f":"code","f1335267":"code","0b85eca3":"code","9e2d1dca":"code","2fb6ce2e":"code","2bbb77da":"code","d1abbfe4":"code","a3ec360d":"code","9080b5a5":"code","9d7fbd52":"code","b9f51f02":"code","0d94acc5":"code","d25bf26d":"code","e7908f5b":"code","f3052866":"code","2f6db888":"code","011490f0":"markdown","b0c0ef1b":"markdown","c558ef0c":"markdown","b778f414":"markdown","28ef59d2":"markdown","bb5ed4ef":"markdown","5a7d80ac":"markdown","3dca7b78":"markdown","4a046d94":"markdown","baacd9a3":"markdown","de8d5640":"markdown","f340de5e":"markdown","e36bf2c9":"markdown","52d4e14f":"markdown","92448a88":"markdown","2b2f1744":"markdown"},"source":{"e308d6c4":"import pandas as pd\nimport numpy as np\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nplt.style.use('seaborn')\n\nfrom scipy import ndimage\nimport cv2\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, load_model\nfrom keras.applications import VGG19, VGG16, ResNet50\n\nfrom sklearn.metrics import accuracy_score\n\nimport random","1d30434f":"ac = pd.read_csv(\"..\/input\/doom-crossing\/animal_crossing_dataset.csv\")\ndoom = pd.read_csv(\"..\/input\/doom-crossing\/doom_crossing_dataset.csv\")\n\nac_filePath = \"..\/input\/doom-crossing\/animal_crossing\/\"\ndoom_filePath = \"..\/input\/doom-crossing\/doom\/\"","c2293c23":"ac.head()","4201190c":"doom.head()","4fce5fde":"ac_fileNames = list(ac.filename.values)\ndoom_fileNames = list(doom.filename.values)","41952549":"random.seed(123)\nac_subset = random.sample(ac_fileNames, 25)\ndoom_subset = random.sample(doom_fileNames, 25)\n\ndef plot_images(file_subset, ac_flag):\n    plt.figure(figsize=(15,15))\n    for i in range(25):\n        if ac_flag:\n            load_img = mpimg.imread(os.path.join(ac_filePath,file_subset[i]))\n        else:             \n            load_img = mpimg.imread(os.path.join(doom_filePath,file_subset[i]))\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(load_img)\n    plt.show()","a0ac7a89":"plot_images(ac_subset, True)","2fddeef9":"plot_images(doom_subset, False)","98415942":"IMG_HEIGHT = 128\nIMG_WIDTH = 128\nCOLOURS = 3\n\nN_CLASS = 2\nCLASS_NAMES = [\"animal_crossing\", \"doom\"]\nBATCH_SIZE = 32","85dea110":"img_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                                horizontal_flip = True,\n                                                                validation_split=0.2)\n\n\ntest_ds = img_generator.flow_from_directory(directory = \"..\/input\/ac-doom-testing\/test2\/test\",\n                                            shuffle = False,\n                                            target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                            classes = CLASS_NAMES)\n\ntrain_ds = img_generator.flow_from_directory(batch_size = BATCH_SIZE,\n                                              directory = \"..\/input\/doom-crossing\",\n                                              shuffle=True,\n                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                              classes= CLASS_NAMES,\n                                              subset='training')\n\nvalid_ds = img_generator.flow_from_directory(batch_size = BATCH_SIZE,\n                                              directory = \"..\/input\/doom-crossing\",\n                                              shuffle=True,\n                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                              classes= CLASS_NAMES,\n                                              subset='validation')","8a8ccd27":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \nsample_training_images, _ = next(train_ds)\nplotImages(sample_training_images[:5])","3d2209d8":"def plot_fit(hist, metric):\n    train_met = hist.history[metric]\n    valid_met = hist.history['val_' + metric]\n    \n    plt.figure(figsize=(12,6))\n    plt.plot(train_met)\n    plt.plot(valid_met)\n    plt.xlabel(\"Epoch Num\")\n    plt.legend([\"train\", \"valid\"])\n    plt.show()","002fc69d":"NUM_EPOCHS = 15\nSTEPS_PER_EPOCH = np.ceil(train_ds.samples \/\/ BATCH_SIZE)\nVALID_STEPS = np.ceil(valid_ds.samples \/\/ BATCH_SIZE)","13d5963e":"callbacks0 = [EarlyStopping(patience = 5),\n             ReduceLROnPlateau(monitor = 'val_loss', patience = 5),\n             ModelCheckpoint('..\/working\/model.best.hdf5', save_best_only=True)]","fbdeb123":"model0 = Sequential([\n    Conv2D(128, 3, padding='same',\n                  activation='relu',\n                  input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n    MaxPooling2D(),\n    Conv2D(128, 3, padding='same', activation='relu'),\n    BatchNormalization(),\n    Dropout(0.2),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu', dilation_rate = (2,2)),\n    MaxPooling2D(),\n    BatchNormalization(),\n    Flatten(),\n    Dense(128, activation = 'relu'),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    Dense(2, activation='softmax')\n])\n\nmodel0.summary()","d6292a2f":"model0.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\nhistory0 = model0.fit(\n    train_ds,\n    steps_per_epoch= STEPS_PER_EPOCH,\n    epochs= NUM_EPOCHS,\n    validation_data = valid_ds,\n    validation_steps = VALID_STEPS,\n    callbacks = callbacks0\n)","f1335267":"plot_fit(history0, 'accuracy')","0b85eca3":"plot_fit(history0, 'loss')","9e2d1dca":"model0 = load_model('..\/working\/model.best.hdf5')\npredictions = model0.predict(test_ds)\nprob_doom = [x[1] for x in predictions]\nprob_ac = [x[0] for x in predictions]\npredictions = [np.argmax(x) for x in predictions]","2fb6ce2e":"pred_df = pd.DataFrame({\"file\": test_ds.filenames,\n                        \"class\": test_ds.classes,\n                        \"label\": predictions,\n                        \"ac_prob\": prob_ac,\n                        \"doom_prob\": prob_doom})","2bbb77da":"pred_df","d1abbfe4":"accuracy_score(pred_df.iloc[:,1], pred_df.iloc[:,2])","a3ec360d":"plt.figure(figsize = (15, 15))\nfor i in range(32):\n    path = os.path.join(\"..\/input\/ac-doom-testing\/test2\/test\",pred_df.iloc[i,0])\n    load_img = mpimg.imread(path)\n    plt.subplot(8,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(load_img)\n    prob = round(pred_df.iloc[i,3] if pred_df.iloc[i,2] == 0 else pred_df.iloc[i, 4], 5)\n    if pred_df.iloc[i,2] == pred_df.iloc[i,1]: # correct classification\n        plt.xlabel(CLASS_NAMES[pred_df.iloc[i,2]] + \" prob: \" + str(prob), color = 'blue')\n    else:\n        plt.xlabel(CLASS_NAMES[pred_df.iloc[i,2]] + \" prob: \" + str(prob), color = 'red')\nplt.show()","9080b5a5":"callbacks1 = [EarlyStopping(patience = 4),\n             ReduceLROnPlateau(monitor = 'val_loss', patience = 5),\n             ModelCheckpoint('..\/working\/restnet50model.best.hdf5', save_best_only=True)]\n\nmodel1 = Sequential([\n    ResNet50(include_top = False, pooling = 'avg', weights='imagenet'),\n    Flatten(),\n    Dense(256,activation=('relu')),\n    Dropout(0.3),\n    Dense(128,activation=('relu')),\n    BatchNormalization(),\n    Dense(2, activation = \"softmax\")\n])\n\nmodel1.summary()","9d7fbd52":"model1.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","b9f51f02":"history1 = model1.fit(train_ds,\n    steps_per_epoch= STEPS_PER_EPOCH,\n    epochs= NUM_EPOCHS,\n    validation_data = valid_ds,\n    validation_steps = VALID_STEPS,\n    callbacks = callbacks1\n)","0d94acc5":"predictions1 = model1.predict(test_ds)\nprob_doom1 = [x[1] for x in predictions1]\nprob_ac1 = [x[0] for x in predictions1]\npredictions1 = [np.argmax(x) for x in predictions1]","d25bf26d":"pred_df1 = pd.DataFrame({\"file\": test_ds.filenames,\n                        \"class\": test_ds.classes,\n                        \"label\": predictions1,\n                        \"ac_prob\": prob_ac1,\n                        \"doom_prob\": prob_doom1})","e7908f5b":"pred_df1","f3052866":"accuracy_score(pred_df1.iloc[:,1], pred_df1.iloc[:,2])","2f6db888":"plt.figure(figsize = (15, 15))\nfor i in range(32):\n    path = os.path.join(\"..\/input\/ac-doom-testing\/test2\/test\",pred_df1.iloc[i,0])\n    load_img = mpimg.imread(path)\n    plt.subplot(8,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(load_img)\n    prob = round(pred_df1.iloc[i,3] if pred_df1.iloc[i,2] == 0 else pred_df1.iloc[i, 4], 5)\n    if pred_df1.iloc[i,2] == pred_df1.iloc[i,1]:    \n        plt.xlabel(CLASS_NAMES[pred_df1.iloc[i,2]] + \" prob: \" + str(prob), color = 'blue')\n    else:\n        plt.xlabel(CLASS_NAMES[pred_df1.iloc[i,2]] + \" prob: \" + str(prob), color = 'red')\nplt.show()","011490f0":"Huge thanks to:\n* The creator of this dataset; https:\/\/www.kaggle.com\/andrewmvd\/doom-crossing\n* For the structured code reference for CNN models and on how to implement callbacks for Tensorflow.; https:\/\/www.kaggle.com\/jedrzejdudzicz\/mnist-dataset-100-top-10","b0c0ef1b":"It does have a (somewhat) relative good accuracy rate for the test images.\n\nThe misclassified images include meme templates (which are expected) and ... Celeste?\n\nTo further clean out the excess noise in the dataset, image augmentation such as random cropping would potentially be useful in improving the accuracy rate.","c558ef0c":"# Preparing data","b778f414":"Ah yes, the two most hardcore and violent games in modern day, Doom: Eternal and Animal Crossing.","28ef59d2":"## ResNet50\nNext, let's use a pretrained ResNet50 layer to see if it helps improve the accuracy","bb5ed4ef":"Are they different in such a way that image classification could be easily facilitated? Or is the cute, wholesome Animal Crossing much more similar to the hardcore, violent Doom: Eternal than we thought it was?","5a7d80ac":"Here, we can see the following difficulties in differentiating between the 2 games:\n* Since memes are prevalent in most online communities, common meme templates are often used and substituted with their relevant references. \n* There are text-only images, which is difficult to classify with.\n* There are some cross-over references in both subreddits, which adds noise to the dataset.","3dca7b78":"## Preview","4a046d94":"# Setup","baacd9a3":"# Libraries","de8d5640":"# References","f340de5e":"# Introduction","e36bf2c9":"![](https:\/\/i.kym-cdn.com\/photos\/images\/original\/001\/751\/678\/208.jpg)","52d4e14f":"# Training the model","92448a88":"The testing data (n=32) used were pictures I downloaded off the hot page of the respective subreddits the data was scrapped off from. (If anyone wants to test out the test data for their own model feel free to comment :-) )","2b2f1744":"## CNN"}}