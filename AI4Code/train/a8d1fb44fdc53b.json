{"cell_type":{"dfadf9eb":"code","1587faac":"code","bcc2b5c8":"code","e9bc1e1b":"code","3e05f644":"code","5daf0aab":"code","91c50c02":"code","f876ded0":"code","c7b13762":"code","c23d3eb9":"code","53c6ea25":"code","62b620e8":"code","18406ac3":"code","a3705008":"code","75547dc1":"code","72701421":"code","f82b02b3":"markdown","52d9e86f":"markdown"},"source":{"dfadf9eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1587faac":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\nsample = pd.read_csv('..\/input\/sample_submission.csv')","bcc2b5c8":"sample.columns","e9bc1e1b":"import nltk\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))","3e05f644":"from sklearn.naive_bayes import MultinomialNB \nimport matplotlib.pyplot as plt\nimport string","5daf0aab":"#FROM https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-qiqc\n\n## Number of unique words in the text ##\ndf_train[\"num_words\"] = df_train[\"question_text\"].apply(lambda x: len(str(x).split()))\ndf_test[\"num_words\"] = df_test[\"question_text\"].apply(lambda x: len(str(x).split()))\n                                                                    \n## Number of characters in the text ##\ndf_train[\"num_chars\"] = df_train[\"question_text\"].apply(lambda x: len(str(x)))\ndf_test[\"num_chars\"] = df_test[\"question_text\"].apply(lambda x: len(str(x)))\n                                                                    \n## Number of stopwords in the text ##\ndf_train[\"num_stopwords\"] = df_train[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\ndf_test[\"num_stopwords\"] = df_test[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n                                                                    \n## Number of punctuations in the text ##\ndf_train[\"num_punctuations\"] =df_train['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\ndf_test[\"num_punctuations\"] =df_test['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n                  \n## Number of title case words in the text ##\ndf_train[\"num_words_title\"] = df_train[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ndf_test[\"num_words_title\"] = df_test[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n          \n## Average length of the words in the text ##\ndf_train[\"mean_word_len\"] = df_train[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ndf_test[\"mean_word_len\"] = df_test[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))         ","91c50c02":"# countVector\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport scipy as sp\ncount_vectorizer = CountVectorizer(decode_error='ignore')\nY = df_train['target'].values\n\nX = sp.sparse.hstack((count_vectorizer.fit_transform(df_train.question_text),df_train[['num_words', 'num_chars', 'num_stopwords', 'num_punctuations', 'num_words_title', 'mean_word_len']].values),format='csr')\nX_columns=count_vectorizer.get_feature_names()+df_train[['num_words', 'num_chars', 'num_stopwords', 'num_punctuations', 'num_words_title', 'mean_word_len']].columns.tolist()","f876ded0":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2)","c7b13762":"model = MultinomialNB()\nmodel.fit(Xtrain, Ytrain)\nprint('Classification rate for NB: ', model.score(Xtrain, Ytrain))\nprint('Classification rate for NB: ', model.score(Xtest, Ytest))","c23d3eb9":"from sklearn.metrics import confusion_matrix\ntest_prediction = model.predict(Xtest)\nprint(confusion_matrix(Ytest, test_prediction))","53c6ea25":"# To understand overall, how well the model predicts. \nfrom sklearn.metrics import classification_report\nprint(classification_report(Ytest, test_prediction))","62b620e8":"# https:\/\/machinelearningmastery.com\/roc-curves-and-precision-recall-curves-for-classification-in-python\/\n# roc curve and auc\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\n\n# predict probabilities\nprobs = model.predict_proba(Xtest)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# calculate AUC\nauc = roc_auc_score(Ytest, probs)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(Ytest, probs)\n# plot no skill\npyplot.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\npyplot.plot(fpr, tpr, marker='.')\n# show the plot\npyplot.show()","18406ac3":"# https:\/\/machinelearningmastery.com\/roc-curves-and-precision-recall-curves-for-classification-in-python\/\n# precision-recall curve and f1\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\nfrom matplotlib import pyplot\n\nprobs = model.predict_proba(Xtest)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# predict class values\nyhat = model.predict(Xtest)\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(Ytest, probs)\n# calculate F1 score\nf1 = f1_score(Ytest, yhat)\n# calculate precision-recall AUC\nauc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(Ytest, probs)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n# plot no skill\npyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\npyplot.plot(recall, precision, marker='.')\n# show the plot\npyplot.show()","a3705008":"final = sp.sparse.hstack((count_vectorizer.transform(df_test.question_text),df_test[['num_words', 'num_chars', 'num_stopwords', 'num_punctuations', 'num_words_title', 'mean_word_len']].values),format='csr')\ndf_test['prediction'] = model.predict(final)","75547dc1":"print(df_test.columns)","72701421":"df_test = df_test[['qid', 'prediction']]\ndf_test.to_csv('submission.csv', index=False)","f82b02b3":"This is my try to do a benchmark prediction :) ","52d9e86f":"Obviously, it's really bad. F-score is super low for insincere questions *sadface*"}}