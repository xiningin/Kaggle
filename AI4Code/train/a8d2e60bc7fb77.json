{"cell_type":{"e009a692":"code","6e0f805d":"code","3d798031":"code","6916ceba":"code","bcb7cfd4":"code","d39a064d":"code","b4ca0620":"code","a8e94c3a":"code","92b8d388":"code","b45dfc7d":"code","06f486ad":"code","c9d43261":"code","3d4061a2":"code","c8052843":"code","cedf685d":"code","4018167a":"code","97710a3a":"code","a51d9b84":"code","46a1cd73":"markdown","e48ab46b":"markdown","54741304":"markdown","f16d9cdd":"markdown","5c84e942":"markdown","87859de4":"markdown","e438abcb":"markdown","57a512be":"markdown","b880c117":"markdown","a9cb0d70":"markdown","19b60e1b":"markdown"},"source":{"e009a692":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport glob\nlistBigCSV = glob.glob(\"..\/input\/NGS*csv\")\nlistBigCSV\n# Any results you write to the current directory are saved as output.","6e0f805d":"def memory(df):\n    if isinstance(df,pd.DataFrame):\n        value = df.memory_usage(deep=True).sum() \/ 1024 ** 2\n    else: # we assume if not a df it's a series\n        value = df.memory_usage(deep=True) \/ 1024 ** 2\n    return value, \"{:03.2f} MB\".format(value)","3d798031":"df = pd.read_csv(listBigCSV[2], engine='c')","6916ceba":"df.describe()","bcb7cfd4":"df.dtypes","d39a064d":"dfIntSelection = df.select_dtypes(include=['int'])\ndfConverted2int = dfIntSelection.apply(pd.to_numeric,downcast='unsigned')\nmemInt, memIntTxt=  memory(dfIntSelection)\nmemIntDownCast, memIntDownCastTxt = memory(dfConverted2int)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt\/memIntDownCast *100.0)","b4ca0620":"dfConverted2int.describe()","a8e94c3a":"dfIntSelection = df.select_dtypes(include=['int'])\ndfConverted2int = dfIntSelection.astype('category')\nmemInt, memIntTxt=  memory(dfIntSelection)\nmemIntDownCast, memIntDownCastTxt = memory(dfConverted2int)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt\/memIntDownCast *100.0)\n","92b8d388":"dfFloatSelection = df.select_dtypes(include=['float'])\ndfConverted2float = dfFloatSelection.apply(pd.to_numeric,downcast='float')\nmemInt, memIntTxt=  memory(dfFloatSelection)\nmemIntDownCast, memIntDownCastTxt = memory(dfConverted2float)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt\/memIntDownCast *100.0)","b45dfc7d":"dfTime = df.Time \ndate_format = '%Y-%m-%d %H:%M:%S.%f'\ndfTimeConvert = pd.to_datetime(dfTimeConvert,format=date_format)\n\nmem, memTxt = memory(dfTime)\nmemConv, memConvTxt = memory(dfTimeConvert)\n\nprint(memTxt)\nprint(memConvTxt)\nprint('Gain: ', mem\/memConv *100.0)","06f486ad":"dtypes = df.drop('Time',axis=1).dtypes\n\ndtypes_col = dtypes.index\ndtypes_type = [i.name for i in dtypes.values]\n\ncolumn_types = dict(zip(dtypes_col, dtypes_type))\npreview = first2pairs = {key:value for key,value in list(column_types.items())[:10]}\nimport pprint\npp = pp = pprint.PrettyPrinter(indent=4)\npp.pprint(preview)\ndfDownCast =pd.read_csv(listBigCSV[2],dtype=column_types,parse_dates=['Time'], infer_datetime_format=True)\n","c9d43261":"dfDownCast","3d4061a2":"memInt, memIntTxt=  memory(df)\nmemIntDownCast, memIntDownCastTxt = memory(dfDownCast)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt\/memIntDownCast *100.0)","c8052843":"dfDownCast.info()","cedf685d":"def downCast(df):\n    date_format = '%Y-%m-%d %H:%M:%S.%f'\n    converted_obj = df.select_dtypes(include=['int']).astype('category')\n    df[converted_obj.columns] = converted_obj\n    converted_obj = df.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='float')\n    df[converted_obj.columns] = converted_obj\n    if 'Time' in df:\n        df.Time = pd.to_datetime(df.Time,format=date_format)\n    return df","4018167a":"dfDown = df.copy()\ndfDown = downCast(dfDown)\n\nmemInt, memIntTxt=  memory(df)\nmemIntDownCast, memIntDownCastTxt = memory(dfDown)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt\/memIntDownCast *100.0)","97710a3a":"for csvFile in listBigCSV:\n    dataframe = pd.read_csv(csvFile, engine='c')\n    dataframe = downCast(dataframe)\n    dataframe.to_pickle(os.path.basename(csvFile[:-4]+'.pkl'))\n    del dataframe","a51d9b84":"os.path.basename('..\/input\/NGS-2016-reg-wk7-12.pkl')","46a1cd73":"What kind of types do we have ?","e48ab46b":"# Do we need to do a special function for this ?\nPandas provides a way to give data types upfront while reading csv file. So we can use it. ","54741304":"270% of space gain is really important. Now we can save it as pkl for the next time. And do that for every big dataset.","f16d9cdd":"There is two types left: Time and Event.\nFirst can be converted to date time. The second might be a category. ","5c84e942":"We can select int64 and make them matching both uint8 which takes 1 byte or uint16 (2 bytes).\nSelecting them and applying a smaller types gives:","87859de4":"We gain more than 1000% converting it.","e438abcb":"Again, the gain is about 200% !","57a512be":"# This notebook is made to expolain how to reduce size of big CSV data and make processing faster","b880c117":"We gain 600%  ! We can apply this methods on float too and downcast them to float.","a9cb0d70":"## Downcasting for smaller dataset\nLet's load the first dataset.\nWe can us C engine to load faster those big files and take pandas function memory_usage to see what we gain. \nA conversion from bytes to megabytes is needed. So a division by 1024 ** 2 is need.","19b60e1b":"A gain of 400% is observed. Wich really good !\nInteger might also be seen as category. It may be intersting if a convertion to a category is a better choice."}}