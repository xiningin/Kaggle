{"cell_type":{"641f3d96":"code","0fbeec70":"code","86fb3a7e":"code","cd182134":"code","00a36e9a":"code","c20b64ca":"code","c594a4b6":"code","5e3b8a4d":"code","43035a3a":"code","764de86c":"code","57123645":"code","bc5498eb":"code","0369c7d5":"code","eb21975a":"code","c230e066":"code","08cdb8aa":"code","fcaa16d7":"markdown","d9beeaa7":"markdown","4ee5eed9":"markdown","a85d894c":"markdown","da804e36":"markdown","8fe7d7dc":"markdown","3190f0f9":"markdown","7706a577":"markdown","5bc8eeaa":"markdown","8265864a":"markdown"},"source":{"641f3d96":"%%capture\n\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import PoissonRegressor\n\nimport joblib\n\nimport tensorflow as tf\nmae = tf.keras.losses.MeanAbsoluteError()\n_ = mae([1], [2]) \n\nimport os\n\nINPUT_DIR = '\/kaggle\/input\/morebikes2021'\n\nFEATURE_SET = 'all'            ## Change features here\nSHUFFLE_SAMPLES = False                    ## To shuffle the data\nTRAIN_SIZE = 0.95                          ## To adjust train size","0fbeec70":"def get_peters_features():\n    short = ['bikes_3h_ago', 'short_profile_3h_diff_bikes', 'short_profile_bikes']\n    short_temp = short + ['temperature.C']\n    full = ['bikes_3h_ago', 'full_profile_3h_diff_bikes', 'full_profile_bikes']\n    full_temp = full + ['temperature.C']\n    short_full = ['bikes_3h_ago', 'short_profile_3h_diff_bikes', 'short_profile_bikes', 'full_profile_3h_diff_bikes', 'full_profile_bikes']\n    short_full_temp = short_full + ['temperature.C']\n    \n    if FEATURE_SET=='short':\n        return short\n    elif FEATURE_SET=='short_temp':\n        return short_temp\n    elif FEATURE_SET=='full':\n        return full\n    elif FEATURE_SET=='full_temp':\n        return full_temp\n    elif FEATURE_SET=='short_full':\n        return short_full\n    elif FEATURE_SET=='short_full_temp':\n        return short_full_temp\n    else:\n        return 'all'\n\ndef get_train_path(station_id):\n    return INPUT_DIR+'\/Train\/Train\/station_'+str(station_id)+'_deploy.csv'\n\ndef preprocess(df):\n    df = df.drop(['weekday', 'latitude', 'longitude','year', 'month'], axis=1)\n#     df = df.drop(['numDocks'], axis=1)\n    df = df.drop(['station'], axis=1)\n    df['timestamp'] = (df['timestamp'] - 1412114400) \/ 3600\n    return df\n\ndef select_peters_features(df):\n    features_to_use = get_peters_features()\n        \n    if features_to_use == 'all':\n        return df.dropna()\n    else:\n#         features_to_use += ['numDocks']         #### Remember to remove this !\n        if 'bikes' in list(df.columns):\n            features_to_use += ['bikes']\n        return df[features_to_use].dropna()\n    \ndef make_learning_data(station_id):\n    df = pd.read_csv(get_train_path(station_id))\n    \n    df = preprocess(df)\n#     df = df.sample(frac=1, random_state=12)\n\n    df = select_peters_features(df)\n\n    df_y = df['bikes']\n    df_X = df.drop(['bikes'], axis=1)\n\n    return np.array(df_X), np.array(df_y)\n\n# df = make_learning_data(201)\n# df","86fb3a7e":"def train_bikes_models(X_train, X_val, y_train, y_val, station_id=0):\n    \"\"\"\n    @station_id: id of the station we want to train\n    returns the best model for this station\n    \"\"\"\n\n    \"\"\" All models that will be trained and their scores \"\"\"\n    potential_models = []\n\n    \"\"\"### Linear Regression\"\"\"\n    \n#     degrees = [1, 2, 3]\n#     degrees = [1]\n#     for i in range(len(degrees)):\n#         scaled_features = StandardScaler()\n#         polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n#         linear_regression = Ridge()\n#         pipeline = Pipeline(\n#             [\n#                 (\"scaled_features\", scaled_features),\n#                 (\"polynomial_features\", polynomial_features),\n#                 (\"linear_regression\", linear_regression),\n#             ]\n#         )\n#         pipeline.fit(X_train, y_train)\n#         y_pred = np.rint(pipeline.predict(X_val))\n#         potential_models.append(('linear_reg_'+str(degrees[i]), pipeline, mae(y_val, y_pred).numpy()))\n\n    \"\"\"### K-Nearest Neighbors\"\"\"\n\n#     KNN = KNeighborsClassifier(n_neighbors=2)\n#     KNN.fit(X_train, y_train)\n#     y_pred = KNN.predict(X_val)\n#     potential_models.append(('knn', KNN, mae(y_val, y_pred).numpy()))\n\n    \"\"\"### Decision Tree\"\"\"\n\n#     DcTree = Pipeline([(\"minmax_scaler\", MinMaxScaler()), (\"decision_tree\", DecisionTreeClassifier(random_state=12))])\n#     DcTree.fit(X_train, y_train)\n#     y_pred = DcTree.predict(X_val)\n#     potential_models.append(('decision_tree', DcTree, mae(y_val, y_pred).numpy()))\n\n    \"\"\"### Random Forest\"\"\"\n\n#     RdFor = Pipeline([(\"minmax_scaler\", MinMaxScaler()), (\"random_forest\", RandomForestClassifier(n_estimators=1000, max_leaf_nodes=None, n_jobs=-1, random_state=12))])\n#     RdFor.fit(X_train, y_train)\n#     y_pred = RdFor.predict(X_val)\n#     potential_models.append(('random_forest', RdFor, mae(y_val, y_pred).numpy()))\n\n    \"\"\"### Gradient Boosting\"\"\"\n    GdBoost = Pipeline([(\"minmax_scaler\", MinMaxScaler()), (\"grad_boost\", GradientBoostingClassifier(n_estimators=100, random_state=12))])\n    GdBoost.fit(X_train, y_train)\n    y_pred = GdBoost.predict(X_val)\n    potential_models.append(('grad_boost', GdBoost, mae(y_val, y_pred).numpy()))\n\n    \"\"\"### SVM - One vs. Rest\"\"\"\n\n#     SVM1 = Pipeline([(\"minmax_scaler\", MinMaxScaler()), (\"svm_ovr\", OneVsRestClassifier(LinearSVC(random_state=12)))])\n#     SVM1.fit(X_train, y_train)\n#     y_pred = SVM1.predict(X_val)\n#     potential_models.append(('svm_ovr', SVM1, mae(y_val, y_pred).numpy()))\n\n    \"\"\"### SVM - One vs. One\"\"\"\n\n#     SVM2 = Pipeline([(\"minmax_scaler\", MinMaxScaler()), (\"svm_ovo\", OneVsOneClassifier(SVC(random_state=12)))])\n#     SVM2.fit(X_train, y_train)\n#     y_pred = SVM2.predict(X_val)\n#     potential_models.append(('svm_ovo', SVM2, mae(y_val, y_pred).numpy()))\n    \n    \"\"\"### Poisson Regression \"\"\"\n\n#     Poisreg = Pipeline([(\"minmax_scaler\", MinMaxScaler()), (\"pois_reg\", PoissonRegressor())])\n#     Poisreg.fit(X_train, y_train)\n#     y_pred = Poisreg.predict(X_val)\n#     potential_models.append(('pois_reg', Poisreg, mae(y_val, y_pred).numpy()))\n\n    \"\"\"## Sort the models and pick the best\"\"\"\n    potential_models = sorted(potential_models, key=lambda el:el[2])\n   \n    return potential_models[0]","cd182134":"## All our models will be stored in this dictionnary\n# per_station_models = {}\n\n# for station_id in range(201, 276):\n#     X, y = make_learning_data(station_id)\n#     X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=SHUFFLE_SAMPLES, train_size=TRAIN_SIZE)\n#     per_station_models[station_id] = train_bikes_models(X_train, X_val, y_train, y_val)[1]\n    \n# per_station_models","00a36e9a":"## Collect learning data (and the stations they comme from)\n\nX, y = make_learning_data(201) \nX_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=SHUFFLE_SAMPLES, train_size=TRAIN_SIZE)\nstations = [201]*len(y_val)\n \nfor station_id in range(202, 276):\n    X_, y_ = make_learning_data(station_id) \n    X_train_, X_val_, y_train_, y_val_ = train_test_split(X_, y_, shuffle=SHUFFLE_SAMPLES, train_size=TRAIN_SIZE)\n    \n    X_train = np.vstack([X_train, X_train_])\n    X_val = np.vstack([X_val, X_val_])    \n    y_train = np.concatenate([y_train, y_train_])    \n    y_val = np.concatenate([y_val, y_val_])\n    \n    stations += [station_id]*len(y_val_)","c20b64ca":"## Save this data for later testing in Phases 2 and 3\nnp.save('X_val.npy', X_val)\nnp.save('y_val.npy', y_val)\nnp.save('stations_val.npy', np.array(stations))","c594a4b6":"## Shapes\nprint(\"Shape of the data for all stations together:\")\nprint(\" - train:\", X_train.shape, y_train.shape)\nprint(\" - val:  \", X_val.shape, y_val.shape)\n\nprint(\" - stations for each example:\", len(stations))","5e3b8a4d":"model_name, all_stations_model = train_bikes_models(X_train, X_val, y_train, y_val)[:2]\nall_stations_model","43035a3a":"y_pred_all = np.rint(all_stations_model.predict(X_val))\n\ndef plot_results(y_pred, title):\n    fig, ax = plt.subplots(1, 1, figsize=(18, 5))\n\n    plt.plot(y_val[:600], \"o\", label=\"True values\")\n    ax.plot(y_pred[:600], \".\", label=\"Predictions\")\n    ax.set_xlabel(\"instances\")\n    ax.set_ylabel(\"# bikes\")\n    ax.legend(loc=\"best\")\n    ax.set_title(\n        title+\"\\nMAE = {:.2f}\".format(\n            mae(y_val, y_pred).numpy()\n        )\n    );\n\nplot_results(y_pred_all, title=\"One model (\"+model_name+\") for all stations\");","764de86c":"## Save the model\njoblib.dump(all_stations_model, 'all_stations_model.pkl')","57123645":"# y_pred_per = np.zeros_like(y_val)\n\n# for i in range(len(y_val)):\n#     station_id = stations[i]\n#     y_pred_per[i] = np.rint(per_station_models[station_id].predict([X_val[i]]))\n    \n# plot_results(y_pred_per, title=\"One different model per-station\");","bc5498eb":"## Save the models\n# joblib.dump(per_station_models, 'per_station_models.pkl')","0369c7d5":"def make_test_data():\n    df = pd.read_csv(INPUT_DIR+'\/test.csv')\n    \n    station_ids = df['station']\n    \n    df = preprocess(df)\n    \n    ids = df['Id']\n    df = df.drop(['Id'], axis=1)\n    \n    df = select_peters_features(df)\n    \n    return np.array(df), np.array(ids), np.array(station_ids)\n    \nX_test, ids, station_ids = make_test_data()\nX_test.shape","eb21975a":"## Save this data for later testing in Phases 2 and 3\nnp.save('X_test.npy', X_test)\nnp.save('ids_test.npy', ids)\nnp.save('stations_test.npy', station_ids)","c230e066":"\"\"\" If we chose to all stations at once \"\"\"\ny_pred = all_stations_model.predict(X_test)\n\n\"\"\" If we chose one model per-station \"\"\"\n# y_pred = np.zeros((len(X_test)))\n# for i in range(len(X_test)):\n#     station_id = station_ids[i]\n#     y_pred[i] = per_station_models[station_id].predict([X_test[i]])\n\n# np.unique(y_pred)\nresults = pd.DataFrame({'Id':ids, 'bikes':np.rint(y_pred)})\nresults","08cdb8aa":"results.to_csv('\/kaggle\/working\/roussel_subin_submission.csv', index=False)\n\n## View all assets that will be needed for phases 2 and 3\nos.listdir('\/kaggle\/working\/')","fcaa16d7":"## Linear Regression models with Peter's Features\nOne of the best algorithms for this task is clearly the classic version of linear regression (`Linear Regression - 1` where the features are *not* raised to a power before fitting the algorithm). We've only used the `short_full_temp` feature set so far, and the table below shows that the choice of feature set hardly changes the results.\n\n| Features      | All-stations | Per-station |\n| :---        |    :----:   |          :---: |\n| short      |   2.57     |2.46|\n| short_temp   |    2.57     |2.47|\n| full   |    2.57     |2.46|\n| full_temp   |   2.57      |2.47|\n| short_full   |   2.57      |2.45|\n| short_full_temp   |   2.57     | 2.47 |","d9beeaa7":"%reset -f","4ee5eed9":"# Objective\n\nThis notebook deals with Phase 1 of the Kaggle competition. First, we will build 75 different models for each station (a), then we will build one model for all stations at once (b). After that,  we will compare these two approaches and discus some variables that affect the learning process in both cases. Unless otherwise specified, the models will be trained using the `short_full_temp` feature set, and the training set will contain 95% of the available data. ","a85d894c":"# Predictions for the competition\n\nNow, we will generate and save predictions for the Kaggle competition. As we have stated over the course of this notebook, other quantities have been saved and will be needed to run the final phases of the competition in the next notebook.","da804e36":"# Train and predict for all stations together\n\nNow, we will train a single model for all the stations together. The data for this learning task is collected such that 5% of each station's data is left for validation. If the data is not shuffle before splitting, then this 5% corresponds to the last 2 days of the month. We will see below that shuffling the data (or not) has a huge effect on the results.","8fe7d7dc":"## Should we shuffle the data ?\nFor this first comparison, we will restrict the models to a single category, and for each category (or learning algorithm), we will study the effect of shuffling the data. To better illustrate the rift between these two strategies, we used 80% of the available data for training, and the remaining 20% for validating: \n\n- **Without shuffling the data**: models are trained on the 25 first days of the month, and validated on the remaining 6 days:\n\n| Algorithm      | All-stations | Per-station |\n| :---        |    :----:   |          :---: |\n| Linear Regression - 1      | 2.66       |2.63|\n| Linear Regression - 2   |    2.61     |2.54|\n| Linear Regression - 3   |    2.54     |2.70|\n| K-Nearest Neighbors   |    3.21     |3.20|\n| Decision Tree   |    3.38     |3.40|\n| Random Forest   |    3.05    |3.17|\n| SVM - One vs. Rest   |   4.05      |3.48|\n| SVM - One vs. One   |    2.90     |3.12|\n| Poisson Regression   |    4.40     |3.56|\n\n- **When shuffling the data**: the training data contains some hours of every day of the month, and the same goes for the validation data:\n\n| Algorithm      | All-stations | Per-station |\n| :---        |    :----:   |          :---: |\n| Linear Regression - 1      | 2.70       |2.53|\n| Linear Regression - 2   |    2.61     |2.36|\n| Linear Regression - 3   |    2.60     |2.25|\n| K-Nearest Neighbors   |    3.26     |1.58|\n| Decision Tree   |    3.35     |0.57|\n| Random Forest   |    3.12    |0.50|\n| SVM - One vs. Rest   |   3.91      |3.02|\n| SVM - One vs. One   |    2.86     |2.43|\n| Poisson Regression   |    4.44     |3.31|\n\nThe conclusion we draw after these comparisons is that training multiple models (one for each station) is almost always better than training a single model for all stations. This is especially true when the training data is representative of the whole dataset (with shuffling). When this is not the case (without shuffling), we observe exceptions with some models (Decision Trees, Random Forest, etc.) that perform better when trained on all stations together. Considering that those are also the most computationally costly models, we opted in the next Phases to use the per-stations models trained on unshuffled data. ","3190f0f9":"# Predictions with per-station models\n\nUsing the per-station models we've learned so far, let's make predictions (on the same validation set) and compare the results to the only model for all stations above.","7706a577":"## With a wide range of different models\n\nEach station is now trained on all 9 possible learning algorithms, and only the best model is kept for that station. The same goes for the model for all stations together. As we see in the table below, shuffling produces better results. However, as we have discussed in the previous notebook, not shuffling the data prepares our models for the competition by taking **data drifting** into account. This is why we did not shuffle the data for our submissions for the competition.\n\n|       | **All-stations** | **Per-station**  |\n| :---        |    :----:   |          :---: |\n|    Without shuffling   |   2.54     |2.45|\n|   When shuffling |    2.53    |1.55|","5bc8eeaa":"# Build all per-station models\n\nWe laid out the justification for each envisioned machine learning algorithm in our previous notebook `MoreBikes - Analysis & Per-Station Training`.","8265864a":"# Comparing the two approaches"}}