{"cell_type":{"9b542470":"code","81537fac":"code","8a1199f6":"code","169b2597":"code","3cc64460":"code","4406a215":"code","4160547e":"code","ff4c5b97":"code","60bd6927":"code","2338946e":"code","ec2866fa":"code","74f98a76":"code","f15f87ea":"code","2db43b1f":"code","d2f1ec10":"code","c37bb931":"code","d22cccd3":"code","8dffe013":"code","ed66d4ad":"code","19e3c339":"code","80ac3e8b":"code","9413ae93":"code","5f70b68d":"code","245153f3":"code","f913cd22":"code","25ed4bf1":"code","a24e596f":"code","5956f716":"code","e339d7fe":"code","9dcf8455":"code","1c057625":"code","28242405":"code","dbdc89ca":"code","f93a4537":"code","fee3bb97":"code","72c04611":"markdown","aa928133":"markdown","98d4c9f5":"markdown","91910cf6":"markdown","416a4abd":"markdown","d3c7ac1f":"markdown","6f310c03":"markdown","3b7cdc41":"markdown","3a6e379f":"markdown","e5a45513":"markdown","68dad9e1":"markdown","c4ba79e9":"markdown","ce9039b6":"markdown","58912bd9":"markdown","96a52270":"markdown","e32b0595":"markdown","19477256":"markdown","dddc4421":"markdown","9912e622":"markdown","b7b97237":"markdown"},"source":{"9b542470":"from IPython.core.display import HTML\n\nimport warnings\nwarnings.filterwarnings('ignore')","81537fac":"HTML(\"\"\"\n<style>\n.preprocessing{\n    background-color:#87ceeb;\n    font-size: 20px;\n    height: 50px;\n    padding-top: 15px;\n}\n.model{\n    background-color:#87ceeb;\n    font-size: 20px;\n    height: 50px;\n    padding-top: 15px;\n}\n.main_head{\n    font-family:courier;\n}\n.submission{\n    background-color:#8CC739;\n    font-size: 20px;\n    height: 50px;\n    padding-top: 15px;\n}\n.center {\n  display: block;\n  margin-left: auto;\n  margin-right: auto;\n  width: 50%;\n}\n<\/style>\n\"\"\")","8a1199f6":"# Importing Libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport time","169b2597":"# Read the dataset\ntrain = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\n\ntrain.head()","3cc64460":"test = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\n\ntest.head()","4406a215":"print('Train Shape : {}'.format(train.shape))\n\nprint('Test Shape : {}'.format(test.shape))","4160547e":"train.dtypes","ff4c5b97":"train['song_popularity'].value_counts()","60bd6927":"train.describe()","2338946e":"train['song_duration_ms']","ec2866fa":"class Missing:\n    \n    def addlabels(self, x, y):\n    \n        for i in range(len(x)):\n        \n            plt.text(i, y[i]\/\/2, y[i], ha = 'center')\n    \n    def missing_features(self, num_features_missing_train, num_features_missing_val):\n    \n        \"\"\"\n        Function to find features with missing values along with\n        count of missing values for each feature\n        \"\"\"\n        for feature in train.columns:\n    \n            if train[feature].isna().sum() != 0:\n        \n                num_features_missing_train.append(feature)\n        \n                num_features_missing_val.append(train[feature].isna().sum())\n     \n        fig = plt.figure(figsize=(25,8))\n            \n        plt.bar(num_features_missing_train, num_features_missing_val, width = 0.4)\n    \n        plt.title('Features with missing values in training dataset')\n    \n        plt.xlabel('Features')\n    \n        plt.ylabel('Missing Count')\n    \n        plt.legend(['NaN'], loc=\"upper right\")\n        \n        self.addlabels(num_features_missing_train, num_features_missing_val)\n\nmissing = Missing()\n\nnum_features_missing_train = []\n\nnum_features_missing_val = []\n\nmissing.missing_features(num_features_missing_train, num_features_missing_val)","74f98a76":"print(\"Feature {0} has {1} missing value in dataset which in maximum among all features.\".format(\n                                num_features_missing_train[num_features_missing_val.index(max(num_features_missing_val))],\n                                max(num_features_missing_val)))","f15f87ea":"# Check for target missing values\ntrain['song_popularity'].isna().sum()","2db43b1f":"train['song_popularity'].unique()","d2f1ec10":"class Song_Popularity:\n    \n    def __init__(self):\n        \n        self.fig = plt.figure(figsize=(15,8))\n        \n        self.color = ['#DB4C77', '#10559A']\n        \n        self.width = 0.3\n        \n    def addlabels(self, x, y):\n    \n        for i in range(len(x)):\n        \n            plt.text(i, y[i]\/\/2, y[i], ha = 'center')\n        \n    def bar_graph(self, feature):\n    \n        train[feature].value_counts().plot(kind='bar', color = self.color, width = self.width)\n        \n        plt.title(\"Target : Song Popularity\")\n        \n        plt.xlabel('song_popularity')\n        \n        plt.ylabel('Count')","c37bb931":"unique_val = train['song_popularity'].unique()\n\nheight = train['song_popularity'].value_counts()\n\nsong_pop = Song_Popularity()\n\nsong_pop.bar_graph('song_popularity')\n\nsong_pop.addlabels(unique_val, height)","d22cccd3":"fig = plt.figure(figsize=(35,30))\n\nfig.tight_layout()\n\nfor feature in enumerate(num_features_missing_train):\n    \n    plt.subplot(4, 2, feature[0] + 1)\n    \n    sns.distplot(train[feature[1]], color='green')\n    \n    plt.axvline(x = train[feature[1]].mean(), color = 'red', ls='--', label = \"Mean\")   \n    \n    plt.axvline(x = train[feature[1]].median(), color = 'blue', ls=':', label = \"Median\") \n    \n    plt.title(feature[1])\n    \n    plt.legend(loc=\"upper right\")\n","8dffe013":"# Fill Missing values accoring to details gathered dist plot\n\nclass Fill_Missing:\n    \n    def fill_with_mean_val(self, fill_with_mean):\n        \n        \"\"\"\n        Fill missing values of features with normal distribution\n        \"\"\"\n        for feature in fill_with_mean:\n            \n            print(\"Mean of feature {0} is : {1}\".format(feature, train[feature].mean()))\n  \n            train[feature].fillna(train[feature].mean() , inplace=True)\n            \n            test[feature].fillna(test[feature].mean(), inplace=True)\n    \n    def fill_with_median_val(self, fill_with_median):\n        \n        \"\"\"\n        Fill missing values of features with skewness\n        \"\"\"\n\n        for feature in fill_with_median:\n            \n            print(\"Median of feature {0} is : {1}\".format(feature, train[feature].median()))\n            \n            train[feature].fillna(train[feature].median(), inplace=True)\n            \n            test[feature].fillna(test[feature].median(), inplace=True)\n        \n    \nfill_miss = Fill_Missing()\n    \nfill_with_mean = ['song_duration_ms', 'danceability', 'key']\n\nfill_with_median = ['acousticness','energy', 'instrumentalness', 'liveness', 'loudness']\n\nfill_miss.fill_with_mean_val(fill_with_mean)\n\nfill_miss.fill_with_median_val(fill_with_median)","ed66d4ad":"for feature in train.columns:\n    \n    if train[feature].isna().sum() != 0:\n        \n        print(feature, train[feature].isna().sum())","19e3c339":"fig = plt.figure(figsize = (15, 15))\n\ndf = train \n\ndf = df[[col for col in df if df[col].nunique() > 1]]\n\ncorr_ = df.corr()\n\nmask = np.zeros_like(corr_)\n\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr_, mask = mask, annot=True)\n\nplt.show()","80ac3e8b":"correlations = {}\n\nfor feature in train.columns:\n    \n    if feature != 'song_popularity':\n    \n        correlations[feature] =  train[feature].corr(train['song_popularity'])\n    \nprint(\"Feature {0} has highest correlation with Song Popularity of {1}\".format(\n                                                        list(correlations.keys())[list(correlations.values()).index(max(correlations.values()))],\n                                                        max(correlations.values()))\n                                                        )","9413ae93":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","5f70b68d":"# Train-Test Split\n\ntrain_id = train['id']\n\nX = train.drop(['song_popularity', 'id'], axis = 1)\n\nY = train['song_popularity']","245153f3":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.30, random_state = 0)","f913cd22":"model_1 = XGBClassifier()\n\nmodel_1.fit(X_train, Y_train, eval_metric='rmse')\n\nmodel_1_pred = model_1.predict(X_val)\n\nmean_abs_error_m1 = mean_absolute_error(model_1_pred, Y_val)\n\nroc_m1 = roc_auc_score(model_1_pred, Y_val)\n\nprint(\"Mean Absolute Error of Model 1 : \", mean_abs_error_m1)\n\nprint(\"ROC of Model 1 : \", roc_m1)","25ed4bf1":"# Model Development \n\n# Hyperparameter Optimization (Taken some parameters from Version 2)\n\nxgb_parms = {\n                \"max_depth\"          :    [8],\n                \"min_child_weight\"   :    [3],\n                \"learning_rate\"      :    [0.05],\n                \"gamma\"              :    [0.4],\n                \"colsample_bytree\"   :    [0.6],\n                'tree_method'        :    [\"gpu_hist\"],\n                \"objective\"          :    [\"binary:logistic\"],\n                \"n_jobs\"             :    [1, 2, 3, 4],\n                \"n_estimators\"       :    list([i for i in range(5000, 40000, 5000)]),\n                \"predictor\"          :    [\"gpu_predictor\"],\n                \"eval_metric\"        :    [\"auc\"],           # Receiver Operating Characteristic Area under the Curve\n            }","a24e596f":"randomized_search = RandomizedSearchCV(model_1, param_distributions = xgb_parms, n_iter = 5, scoring = 'roc_auc', n_jobs=-1, \n                                   cv = 5, verbose = 3)","5956f716":"start_time = time.time()\n\nrandomized_search.fit(X_train, Y_train, eval_metric = 'rmse')\n\nend_time = time.time()\n\nprint(\"Time taken : {0}\".format(end_time - start_time))","e339d7fe":"randomized_search.best_estimator_","9dcf8455":"randomized_search.best_params_","1c057625":"model_2 = XGBClassifier(**randomized_search.best_params_, use_label_encoder=False)\n\nmodel_2.fit(X_train, Y_train, eval_metric='rmse')\n\nmodel_2_pred = model_2.predict(X_val)\n\nmean_abs_error_m2 = mean_absolute_error(model_2_pred, Y_val)\n\nroc_m2 = roc_auc_score(model_2_pred, Y_val)\n\nprint(\"Mean Absolute Error of Model 2 : \", mean_abs_error_m2)\n\nprint(\"ROC of Model 2 : \", roc_m2)","28242405":"# Using Stratified K-fold Cross Validation\n\nfrom sklearn.model_selection import StratifiedKFold","dbdc89ca":"targets = train['song_popularity'].values\n\ncolumns = [col for col in train.columns if col not in ['id', 'song_popularity'] ]","f93a4537":"n_splits_val = 10\n\nauc_score = []\n\nsk_fold = StratifiedKFold(n_splits = n_splits_val, shuffle=True, random_state=1)\n\nmodel_3_pred = np.zeros((train.shape[0],))\n\nfor fold, (train_index, val_index) in enumerate(sk_fold.split(X = train, y=targets)):\n    \n    df_train, df_val = train.iloc[train_index][columns], train.iloc[val_index][columns]\n    \n    train_target, val_target = targets[train_index], targets[val_index]\n    \n    model_3 = XGBClassifier(**randomized_search.best_params_,use_label_encoder=False)\n    \n    model_3.fit(df_train[columns],\n                train_target, \n                eval_metric='rmse', \n                eval_set=[(df_val[columns], val_target)],\n                early_stopping_rounds=3000,\n                verbose=500)\n\n    model_3_val_pred = model_3.predict_proba(df_val[columns])[:,1]\n\n    model_3_test_pred = model_3.predict_proba(test[columns])[:,1]\n    \n    model_3_pred[val_index] = model_3_val_pred\n    \n    model_3_test_pred += model_3_test_pred\/n_splits_val\n    \n    auc = roc_auc_score(val_target, model_3_val_pred)\n    \n    auc_score.append(auc)\n    \n    print(\"FOLD IS {0} AUC IS {1} AND MEAN AUC IS {2}\".format(fold, auc, np.mean(auc_score)))\n    \n    ","fee3bb97":"submission = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")\n\nsubmission['song_popularity'] = model_3_test_pred\n\nsubmission.to_csv('submission.csv', index = False)","72c04611":"Data Correlation","aa928133":"From 'count' property it seems like we have Null values in some features eg. song_duration_ms, acousticness , danceability etc.\nWe will figure out something for these Null values.","98d4c9f5":"So we have done something good but Stuart and Bob(Hope you remeber them:)) are not satisfied yet, seems we need to find more accurate ways to predict their playlist. Let's try one more method to build another model","91910cf6":"No missing values now!","416a4abd":"Looking at the correlation table, we can note a few observations on what attributes make a song more popular.\n\n* Energy and loudness seems highly proportional with each other.\n* Acousticness is highest correlated feature with song_popularity in our dataset it seems our dataset contains songs which do not contain electric instruments(may be classic old songs) as they do not contains electric instruments or some remix influence in them.","d3c7ac1f":"<h3 align=\"center\" class=\"submission\"> 3. SUBMISSION \ud83c\udf89\u270c\ufe0f <\/h3>","6f310c03":"<h3 align=\"center\" class=\"model\"> 2.3  PREDICTIVE MODEL 2(Extreme Gradient Boosting with Hyperparameter Optimization) <\/h3>","3b7cdc41":"<h3 align=\"center\" class=\"model\"> 2.4  PREDICTIVE MODEL 3(XGB with Hyperparameter Optimization using Stratified K-fold Cross Validation) <\/h3>","3a6e379f":"Let me know if I can improve anywhere or if I had done something wrong , any feedback will be much appreciated !\nI will try to improve this notebook in the next version","e5a45513":"<h1 align=\"center\" class=\"main_head\">\ud83c\udfb6 HEY! MINIONS, WHAT SONG IS POPULAR AMONG YOU GUYS? \ud83c\udfb6<\/h1>\n\n<div style=\"width:100%;text-align: center;\"> \n<img src=\"https:\/\/thumbs.gfycat.com\/NeedyDisgustingConey-size_restricted.gif\" class=\"center\" alt=\"Minions GIF\">\n<\/div>\nHello Everyone!\n\nWelcome to the world of minions, it's Kevin(a popular minion) birthday & Stuart and Bob (Kevin's friend) have to decide a music playlist that they will use in Kevin's birthday party , let's do some help of Stuart & Bob and find out songs popular among minions\ud83d\ude09\n\nHope we will rock in the Birthday Party\ud83c\udf89\ud83c\udf89\n\nIn this competition we are supposed to predict popularity of a song given features like acousticness, danceability, key, loudness, etc.\n\nIt is a binary classification problem , we have to predict whether song is popular or not?\n\nEvaluation Metric - Area Under the ROC Curve(AUC)<br>\n<a>https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic<\/a>\n\n### Let's have some insight about data\ud83d\udd0d","68dad9e1":"Hope our model predict correct \"song_popularity\" for test songs and further new songs for minions and hope Kevin, Stuart and Bob friendship will be more stronger\n\nAnd finally we did it, ready for submission","c4ba79e9":"<h3 align=\"center\" class=\"model\"> 2.2  PREDICTIVE MODEL 1(Extreme Gradient Boosting) <\/h3>","ce9039b6":"<h2 align=\"center\" class=\"preprocessing\">1. Data Preprocessing\ud83d\udee0<\/h2>\n<h3 align=\"center\" class=\"preprocessing\">1.1 Importing necessary libraries\ud83d\udcda","58912bd9":"<h3 align=\"center\" class=\"model\"> 2. Build A Predictive Model \ud83c\udfd7\ufe0f<\/h3>","96a52270":"<h3 align=\"center\" class=\"preprocessing\"> 1.2 Importing the data \ud83d\udcd1<\/h3>","e32b0595":"Using median value for features which are left or right skewed to replace missing values","19477256":"<h3 align=\"center\" class=\"model\"> 2.1  Importing necessary libraries \ud83d\udcda<\/h3>","dddc4421":"So our target column \"song_popularity\" contains two kind of values:\n\n* 0 means song is not popular\n* 1 means song is popular","9912e622":"<div class=\"alert alert-block alert-info\">\n\ud83d\udcccSo we got our next model and with some more accuracy. Let's try one more with Stratified k-fold cross-validation. It is same as just k-fold cross-validation, but in Stratified k-fold cross-validation, it does stratified sampling instead of random sampling.\n\nYou can learn more from: https:\/\/www.geeksforgeeks.org\/stratified-k-fold-cross-validation\/\n<\/div>","b7b97237":"<h3 align=\"center\" class=\"preprocessing\"> 1.3 Examine Missing Values \ud83e\uddf9<\/h3>"}}