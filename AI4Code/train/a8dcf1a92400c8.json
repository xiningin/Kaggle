{"cell_type":{"40d33953":"code","813588dd":"code","d13e696c":"code","09c4eb20":"code","5c3a4aa5":"code","f304c3d4":"code","5c8ed2b4":"code","f15df8b9":"code","9dbdafea":"code","66ce654a":"code","90284316":"code","4b83c00b":"code","9522c9e5":"code","b932a4e8":"code","252faeb1":"code","aaf61b7d":"code","4afaa348":"code","c5e32226":"markdown","ebbae1b5":"markdown","bad5ec5c":"markdown","5d2f4970":"markdown","1f79fa03":"markdown","af671f21":"markdown","22594b90":"markdown","b46be379":"markdown","2cd586cb":"markdown","5545065d":"markdown","2218aa1b":"markdown","b163fb8d":"markdown","602a7356":"markdown","a0ac2d49":"markdown","8c73c92f":"markdown"},"source":{"40d33953":"import warnings\nwarnings.filterwarnings(\"ignore\") ","813588dd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport missingno as msno \nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE\nimport sklearn.metrics as metrics\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","d13e696c":"base = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\n","09c4eb20":"msno.bar(base) ","5c3a4aa5":"columns = ['Patient age quantile', 'SARS-Cov-2 exam result','Patient addmited to regular ward (1=yes, 0=no)',\n           'Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)',\n           'Hematocrit', 'Hemoglobin', 'Platelets', 'Mean platelet volume ', 'Red blood Cells', 'Lymphocytes', 'Mean corpuscular hemoglobin concentration\u00a0(MCHC)',\n           'Leukocytes', 'Basophils', 'Mean corpuscular hemoglobin (MCH)', 'Eosinophils', 'Mean corpuscular volume (MCV)',\n           'Monocytes', 'Red blood cell distribution width (RDW)', 'Serum Glucose', 'Respiratory Syncytial Virus', 'Influenza A', 'Influenza B', 'Parainfluenza 1', \n           'CoronavirusNL63', 'Rhinovirus\/Enterovirus','Coronavirus HKU1', 'Parainfluenza 3', 'Chlamydophila pneumoniae', 'Adenovirus', 'Parainfluenza 4', 'Coronavirus229E', 'CoronavirusOC43' ,\n           'Inf A H1N1 2009', 'Bordetella pertussis', 'Metapneumovirus', 'Parainfluenza 2' ]\n\nbase = base[columns]","f304c3d4":"base_new = base.dropna(subset=['Hematocrit'])\nbase_new = base_new.fillna(-9)","5c8ed2b4":"from sklearn.preprocessing import LabelEncoder\nfor col in base_new.columns:\n    if base_new[col].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(base_new[col].values))\n        base_new[col] = lbl.transform(list(base_new[col].values))","f15df8b9":"msno.bar(base_new)","9dbdafea":"matrix = np.triu(base_new.corr())\nplt.figure(figsize=(15,15))\nsns.heatmap(base_new.corr(), mask=matrix)","66ce654a":"print('Negative:', round(\n        base_new['SARS-Cov-2 exam result'].value_counts()[0]\/len(base_new)*100, 2), '% of the dataset')\nprint('Positive:', round(\n        base_new['SARS-Cov-2 exam result'].value_counts()[1]\/len(base_new)*100, 2), '% of the dataset')\nsns.countplot('SARS-Cov-2 exam result',data=base_new)","90284316":"#oversampling of the data. The number of Fraud was twiced\nfrom imblearn.over_sampling import SMOTE\nk = 6\nsm = SMOTE(k_neighbors=5, random_state=12, n_jobs=8, sampling_strategy={1:int(83*k), 0:int(520)})\n\n\n#A propor\u00e7\u00e3o de classes da vari\u00e1vel pre_approved na base de treino e de teste deve ser a mesma da base original\nX = base_new.drop(['SARS-Cov-2 exam result'], axis=1)\ny = base_new['SARS-Cov-2 exam result']\nX, y = sm.fit_resample(X, y)\nbase_balanced = pd.concat([X, y], axis=1)\nsns.countplot('SARS-Cov-2 exam result',data=base_balanced)","4b83c00b":"sss = StratifiedShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\nsss.get_n_splits(X, y)\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.values[train_index], X.values[test_index]\n    y_train, y_test = y.values[train_index], y.values[test_index]\n\nweight = base_new['SARS-Cov-2 exam result'].value_counts()[0]\/(6*base_new['SARS-Cov-2 exam result'].value_counts()[1])  \nxgboost = xgb.XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=weight, seed=0, silent=True, subsample=1)","9522c9e5":"xgb_calibrated = CalibratedClassifierCV(xgboost, cv=5, method='isotonic')\nxgb_calibrated.fit(X_train, y_train)\ny_hat = xgb_calibrated.predict_proba(X_test)[:,1]","b932a4e8":"import sklearn.metrics as metrics\n# calculate the fpr and tpr for all thresholds of the classification\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_hat)\nroc_auc = metrics.auc(fpr, tpr)\nprint('The area under the curve ROC is %0.4f:' %roc_auc)\n\nplt.title('Receiver Operating Characteristic (curva ROC)')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.4f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.show()","252faeb1":"scores_xgb=[] \ntresholds = np.linspace(0 , 1 , 200)\nfor treshold in tresholds:\n    y_hat_xgb = (y_hat > treshold).astype(int)\n    scores_xgb.append([metrics.recall_score(y_pred=y_hat_xgb, y_true=y_test),\n                 metrics.precision_score(y_pred=y_hat_xgb, y_true=y_test),\n                 metrics.fbeta_score(y_pred=y_hat_xgb, y_true=y_test, beta=2),\n                 metrics.accuracy_score(y_pred=y_hat_xgb, y_true=y_test)])\nscores_xgb = np.array(scores_xgb)\nfinal_tresh = tresholds[scores_xgb[:, 3].argmax()]\ny_hat_xgb = (y_hat > final_tresh).astype(int)\nbest_score = scores_xgb[scores_xgb[:, 3].argmax(),:]\nrecall_score = best_score[0]\nprecision_score = best_score[1]\nfbeta_score = best_score[2]\nacuraccy = best_score[3]\n\nprint('The recall score is: %.3f' % recall_score)\nprint('The precision score is: %.3f' % precision_score)\nprint('The f2 score is: %.3f' % fbeta_score)\nprint('The accuracy score is: %.3f' % acuraccy)","aaf61b7d":"cm = pd.crosstab(y_test, y_hat_xgb, rownames=['Real'], colnames=['Predict'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Negative', 'Positive'],\n            yticklabels=['Negative', 'Positive'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\", fmt=\"d\")\nplt.title('Confusion Matrix for XGBoost', fontsize=14)\nplt.show()","4afaa348":"perm = PermutationImportance(xgb_calibrated).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = base_new.drop(['SARS-Cov-2 exam result'], axis=1).columns.tolist())","c5e32226":"### Handling missing data and selecting variables\n","ebbae1b5":"### Base Oversampling with SMOTe\n\nSince the amount of positive data in the database is small, we will create synthetic data using the SMOTe technique. This technique creates synthetic data from linear combinations of the original data.","bad5ec5c":"The XGBoost algorithm is a model based on decision trees that uses gradient boosting for learning. Boosting is a set technique in which new models (in this case, decision trees) are added to correct the mistakes made by the existing models. Templates are added sequentially until no further improvements are made. Gradient Boosting is an approach in which new models that predict residuals or errors from previous models are created and then added together to make the final forecast. It is called Gradient Boosting because it uses a gradient drop algorithm to minimize loss when adding new models.\n\nThis algorithm was chosen for several reasons: It is fast, it has excellent performance and it supports the predict_proba method, which allows predicting a categorical independent variable in a probabilistic way. The XGBoost has many hyperparameters, and it was necessary to use Random Search to find the best values \u200b\u200bfor hipeparameters.","5d2f4970":"### Evaluation metrics - Area under the ROC curve\n\nThe ROC Curve is an alternative to evaluate a classifier algorithm, which consists of using a two-dimensional graph, where the vertical axis represents the rate of true positives and the horizontal axis represents the rate of false positives obtained by the classifier. The closer to the point $(0,1)$ (top left) the better the model. Models at point $(0, 0)$ do not classify any observation as positive, and models near point $(1,1)$ classify everything as positive.","1f79fa03":"### Other important metrics <a id=\"2.5\"> <\/a>\n\u00a0 In addition to the area under the ROC curve, the evaluation of other variables becomes important:\n<ul>\n\u00a0\u00a0 <li> <b> Precision: <\/b> Measures the percentage of correct answers among observations classified as positive (or negative); <\/li>\n\u00a0\u00a0 <li> <b> Recall or sensitivity: <\/b> Also called the true positive rate, it measures the percentage of positive observations that were correctly classified; <\/li>\n\u00a0\u00a0 <li> <b> F2: <\/b> This measure seeks a balance between sensitivity and precision, using the harmonic average of these metrics, givin weight 2 to the Recall:\n\u00a0 $$(1+\\beta^2)\\times\\frac{precision\\times recall}{\\beta^2\\times precision+recall}$$ <\/li>\n\u00a0\u00a0 <li> <b> Accuracy: <\/b> Also called the true positive rate, it measures the percentage of positive observations that were correctly classified; <\/li>\n<\/ul>","af671f21":"### Confusion Matrix","22594b90":"### Transformation of categorical variables","b46be379":"### Importance via permutation of features <a id=\"2.6\"> <\/a>\n\nThe Permutation Importance algorithm measures the importance of a feature by calculating the increase in the model's forecast error after exchanging it. A resource is \"important\" if the shuffling of its values increases the model's error, because in this case the model had the resource for the forecast. A feature is \"unimportant\" if the shuffling of its values leaves the model error unchanged, as in this case the model ignored the feature for the forecast.","2cd586cb":"### Calibration of probabilities <a id=\"2.3\"> <\/a>\n\nSome models can predict the probabilities with values very close to the 0 and 1 extremes of the range. For example, the values 0,0,1,1 can be transformed into the probabilities 0,01, 0,05, 0,99, 0,98. The probability calibration aims to mitigate this effect, rescheduling the proportion so that the probability is better distributed between intervals 0 and 1.","5545065d":"### Importing the required libraries","2218aa1b":"\n### Applying the XGBoost model to predict the probability of a positive outcome <a id=\"2.2\"> <\/a>\n\nFirst, we will separate the base between training and testing. The training base must be selected in a stratified manner (maintaining the same proportion of classes as the independent variable in the training base with the original base). Regarding the test base, we must predict all instances, since we must concatenate this column in the training base for the second stage of modeling.","b163fb8d":"<center><h1>COVID 19 Exam Result Prediction - Albert Einstein Task 1 <\/h1><\/center>\n\nIn this notebook we will predict the probability of having positive cases of covid19, and as an evaluation method we will use the F2 metric, which gives more weight to the recall (less false negatives).\n\n<li><b>Dataset<\/b><\/li>\nThis dataset contains anonymized data from patients seen at the Hospital Israelita Albert Einstein, at S\u00e3o Paulo, Brazil, and who had samples collected to perform the SARS-CoV-2 RT-PCR and additional laboratory tests during a visit to the hospital. All data were anonymized following the best international practices and recommendations. All clinical data were standardized to have a mean of zero and a unit standard deviation.\n\n\n<li><b>Task Details - TASK 1<\/b><\/li>\nPredict confirmed COVID-19 cases among suspected cases.\nBased on the results of laboratory tests commonly collected for a suspected COVID-19 case during a visit to the emergency room, would it be possible to predict the test result for SARS-Cov-2 (positive\/negative)?","602a7356":"The database contains a lot of missing data. We will choose features that have an acceptable amount of data only.","a0ac2d49":"### Correlation Map","8c73c92f":"### Conclusion\n\nFrom the results of the metrics F2 and AUC-ROC, we obtained a good performance. For this, it was necessary to increase the number of positive cases, which significantly increased the performance."}}