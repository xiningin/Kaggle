{"cell_type":{"75be23a7":"code","28752ccd":"code","074d9793":"code","af1bfab7":"code","8d226063":"code","87468c3d":"code","a2abb02f":"code","1e86443a":"code","db5b024e":"code","d40b7c9c":"code","b5f349fc":"code","16b55cee":"code","5b44e03d":"code","a5fe346e":"code","0d03273d":"code","dab1e4cf":"code","56b48b4b":"code","aef1f112":"code","43702647":"code","56971369":"code","07a63bca":"code","b53cfe22":"code","071f7a92":"markdown","49318e64":"markdown","353eeab4":"markdown","bf28eec1":"markdown","bd89e4f4":"markdown","e703f01d":"markdown","1f10a58b":"markdown","3810ea04":"markdown","74345e8c":"markdown","3eea79f4":"markdown","cecef6c0":"markdown","1aad8d89":"markdown","7ccdb8e5":"markdown","44530371":"markdown","120bee6f":"markdown","c7d8484b":"markdown","fa1ddcda":"markdown","1cfc6078":"markdown"},"source":{"75be23a7":"import os\nimport random\n\nimport numpy as np \nimport pandas as pd \nimport lightgbm as lgb\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout, Input, Concatenate, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\n\nimport seaborn as sns\nfrom pathlib import Path","28752ccd":"#source path (where the Pawpularity contest data resides)\npath = '..\/input\/petfinder-pawpularity-score-clean\/'\npath_test = '..\/input\/petfinder-pawpularity-score\/'\n#Get the metadata (the .csv data) and put it into DataFrames\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\n#Get the image data (the .jpg data) and put it into lists of filenames\ntrain_jpg = glob(path + \"train\/*.jpg\")\ntest_jpg = glob(path + \"test\/*.jpg\")","074d9793":"#show the dimensions of the train metadata.\nprint('train_df dimensions: ', train_df.shape)\nprint('train_df column names: ', train_df.columns.values.tolist())\n\n#print an extra row could use '\\n' as well in a print statement\nprint('')\n\n#show the dimensions of the test metadata\nprint('test_df dimensions: ',test_df.shape)\nprint('test_df column names: ', test_df.columns.values.tolist())","af1bfab7":"#show the type of train_jpg and test_jpg as well as length of the list.\nprint('train_jpg is of type ',type(train_jpg), ' and length ', len(train_jpg))\n#Also show the first 3 elements\nprint('train_jpg list 1st 3 elements: ', train_jpg[0:3], '\\n')\n\nprint('test_jpg is of type ',type(test_jpg), ' and length ', len(test_jpg))\n#Also show the first 3 elements\nprint('test_jpg list 1st 3 elements: ', test_jpg[0:3])","8d226063":"\nsns.set(rc={'figure.figsize':(15,5)})\nfig = plt.figure()\nsns.histplot(data=train_df, x='Pawpularity', bins=100)\nplt.axvline(train_df['Pawpularity'].mean(), c='red', ls='-', lw=3, label='Mean Pawpularity')\nplt.axvline(train_df['Pawpularity'].median(),c='blue',ls='-',lw=3, label='Median Pawpularity')\nplt.title('Distribution of Pawpularity Scores', fontsize=20, fontweight='bold')\nplt.legend()\nplt.show()","87468c3d":"#Let's start with just one variable to demonstrate\nfig, ax = plt.subplots(1,2)\nsns.boxplot(data=train_df, x='Eyes', y='Pawpularity', ax=ax[0])\nsns.histplot(train_df, x=\"Pawpularity\", hue=\"Eyes\", kde=True, ax=ax[1])\nplt.suptitle(\"Eyes\", fontsize=20, fontweight='bold')\nfig.show()","a2abb02f":"#Let's start with just one variable to demonstrate\nfig, ax = plt.subplots(1,2)\nsns.boxplot(data=train_df, x='Face', y='Pawpularity', ax=ax[0])\nsns.histplot(train_df, x=\"Pawpularity\", hue=\"Eyes\", kde=True, ax=ax[1])\nplt.suptitle(\"Eyes\", fontsize=20, fontweight='bold')\nfig.show()","1e86443a":"#Let's start with just one variable to demonstrate\nfig, ax = plt.subplots(1,2)\nsns.boxplot(data=train_df, x='Near', y='Pawpularity', ax=ax[0])\nsns.histplot(train_df, x=\"Pawpularity\", hue=\"Near\", kde=True, ax=ax[1])\nplt.suptitle(\"Eyes\", fontsize=20, fontweight='bold')\nfig.show()","db5b024e":"#Let's start with just one variable to demonstrate\nfig, ax = plt.subplots(1,2)\nsns.boxplot(data=train_df, x='Action', y='Pawpularity', ax=ax[0])\nsns.histplot(train_df, x=\"Pawpularity\", hue=\"Action\", kde=True, ax=ax[1])\nplt.suptitle(\"Eyes\", fontsize=20, fontweight='bold')\nfig.show()","d40b7c9c":"#first let's try printing out the first 3 images with a loop\n\n#The for loop goes for 3 loops \nfor x in range(3):\n    #this loop goes through index of the train_jpg list of filenames: 0,1,2\n    image_path = train_jpg[x]\n    #use plt.imread() to read in that image file as an array of numbers between 0-255\n    image_array = plt.imread(image_path) \n    #Let's check the image dimensions\n    print(\"image {}'s dimensions are: {}\".format(x,image_array.shape))\n    #then plt.imshow() can display it for you\n    plt.imshow(image_array)\n    #title is the index of train_jpg\n    plt.title(x) \n    #turn off gridlines\n    plt.axis('off')\n    #show the image\n    plt.show()","b5f349fc":"#first let's try printing out the first 3 images with a loop\n\n#The for loop goes for 3 loops \nfor x in range(8):\n    #this loop goes through index of the train_jpg list of filenames: 0,1,2\n    image_path = test_jpg[x]\n    #use plt.imread() to read in that image file as an array of numbers between 0-255\n    image_array = plt.imread(image_path) \n    #Let's check the image dimensions\n    print(\"image {}'s dimensions are: {}\".format(x,image_array.shape))\n    #then plt.imshow() can display it for you\n    plt.imshow(image_array)\n    #title is the index of train_jpg\n    plt.title(x) \n    #turn off gridlines\n    plt.axis('off')\n    #show the image\n    plt.show()","16b55cee":"\nAUTOTUNE = tf.data.experimental.AUTOTUNE  \nimg_size = 224\nchannels = 3\nBatch_size = 128\n\n\n\ndef seed_everything():\n    np.random.seed(123)\n    random.seed(123)\n    tf.random.set_seed(123)\n    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n    os.environ['PYTHONHASHSEED'] = str(123)\n\nseed_everything()","5b44e03d":"### reading the data\ndf = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score-clean\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\")\nId = df_test[\"Id\"].copy()\n\n\ndf[\"Id\"] = df[\"Id\"].apply(lambda x : \"\/kaggle\/input\/petfinder-pawpularity-score-clean\/train\/\" + x + \".jpg\")\ndf_test[\"Id\"] = df_test[\"Id\"].apply(lambda x : \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\" + x + \".jpg\")","a5fe346e":"### doing data augmentation in images\ndef image_preprocess(is_labelled):  \n    def augment(image):\n        image = tf.image.random_flip_left_right(image)\n\n        image = tf.image.random_saturation(image, 0.95, 1.05)\n        image = tf.image.random_contrast(image, 0.95, 1.05)\n        return image\n    \n    def can_be_augmented(img, label):\n        return augment(img), label\n    \n\n    return can_be_augmented if is_labelled else augment\n\n\n\n\ndef image_read(is_labelled):\n    def decode(path):\n        image = tf.io.read_file(path)\n        image = tf.image.decode_jpeg(image, channels=channels)\n        image = tf.cast(image, tf.float32)\n        image = tf.image.resize(image, (img_size, img_size))\n        image = tf.keras.applications.efficientnet.preprocess_input(image) \n        return image\n    \n    def can_be_decoded(path, label):\n        return decode(path), label\n    \n#   If record has label both image and lable will be returned\n\n    return can_be_decoded if is_labelled else decode\n\n\n\ndef create_dataset(df, batch_size, is_labelled = False, augment = False, shuffle = False):\n    image_read_fn = image_read(is_labelled)\n    image_preprocess_fn = image_preprocess(is_labelled)\n    \n    if is_labelled:\n        dataset = tf.data.Dataset.from_tensor_slices((df[\"Id\"].values, df[\"Pawpularity\"].values))\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices((df[\"Id\"].values))\n    \n    dataset = dataset.map(image_read_fn, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(image_preprocess_fn, num_parallel_calls=AUTOTUNE) if augment else dataset\n    dataset = dataset.shuffle(1024, reshuffle_each_iteration=True) if shuffle else dataset\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n","0d03273d":"df","dab1e4cf":"trn = df.iloc[:9000]\nval = df.iloc[9001:]\n\n\n\ntrain = create_dataset(trn, Batch_size, is_labelled = True, augment = True, shuffle = True)\nvalidation = create_dataset(val, Batch_size, is_labelled = True, augment = False, shuffle = False)\ntest = create_dataset(df_test, Batch_size, is_labelled = False, augment = False, shuffle=False)","56b48b4b":"print(trn.shape)\nprint(val.shape)\nprint(df_test.shape)","aef1f112":"img_mod = \"\/kaggle\/input\/keras-applications-models\/EfficientNetB0.h5\"\nefnet = tf.keras.models.load_model(img_mod)\n\nefnet.trainable = False","43702647":"model = Sequential([\n    Input(shape=(img_size, img_size, channels)),\n    efnet,\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(units = 128, activation=\"relu\"),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(units = 64, activation=\"relu\"),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(units = 1, activation=\"relu\")\n])\n","56971369":"early_stopping = EarlyStopping(patience = 5,restore_best_weights=True)\n\n\nlr_schedule = ExponentialDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=100, decay_rate=0.96,\n    staircase=True)","07a63bca":"model.compile(loss=\"mse\", \n              optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule), \n              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\npredictor = model.fit(train,\n                      epochs=50, \n                      validation_data = validation,\n                      callbacks=[early_stopping])","b53cfe22":"pred = model.predict(test)\nfinal=pd.DataFrame()\nfinal['Id']=Id\nfinal['Pawpularity']=pred\nfinal.to_csv('submission.csv',index=False)","071f7a92":"### Sample Training Images","49318e64":"This notebook is for newbies from a newbie, it will help you to get started with the problem\n1. First I will describe about initial EDA.\n2. Then we will make simple model using pretrained weights from EfficientNet network\n\nHope you like the efforts.\nPLease upvote if this notebook helped you in any way","353eeab4":"### Getting the dimensions for our data","bf28eec1":"### Adding additional Layers for prediction","bd89e4f4":"### Lets MAKE OUR FIRST MODEL USING PRETRAINED WEIGHTS","e703f01d":"### Importing the Libraries ","1f10a58b":"### Distribution of Target Variable\n\n","3810ea04":"### addding early stoping and other hyperparameters","74345e8c":"### Now we will perform EDA on Image data","3eea79f4":"### Setting up the hyper parameters","cecef6c0":"### Reading the Path\nNote here we are taking a new dataset in which all the duplicate and bad noisy images has been removed","1aad8d89":"### Making Final Prediction","7ccdb8e5":"### lets visualize the distribution of Pawpularity scores across each feature variable\n","44530371":"### Creating train test validation set","120bee6f":"### Sample Testing Images\n\n\n**NOTE** the test images are just random noices, so nothing to worry final scoring will be done on actual images, thats why in this competition we need to submit notebook also.","c7d8484b":"### Compiling the Model","fa1ddcda":"### Extracting Pretrained efficientNet Weights","1cfc6078":"### Unable to find anything sigficant from individual features"}}