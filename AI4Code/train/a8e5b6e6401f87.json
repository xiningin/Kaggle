{"cell_type":{"2369e52d":"code","fd318f1d":"code","d5a1c396":"code","44038e4c":"code","b7b3bba6":"code","c46c5294":"code","5ee95990":"code","33e77a44":"code","3786f7fd":"code","d460df4e":"code","06ce4f22":"code","0f39b048":"code","c999daf8":"code","7f065c99":"code","e15e35a0":"code","73825125":"code","824e80ba":"code","9145e9cd":"code","fac53911":"code","5b716007":"code","cac95289":"code","1f246a8d":"code","532784d8":"code","7556cc61":"code","d138dd22":"code","b0ba8142":"code","77b2150c":"code","008cdfaf":"code","a14a2c4c":"code","db95a03d":"code","d4b2b923":"code","2966c3af":"code","766d9c04":"code","0dfd95d4":"code","46395a66":"code","d2dff3fc":"code","e73f8f69":"code","93910bae":"code","acf52fc9":"code","f14d1ab7":"code","1a83e373":"code","28547b06":"code","2fcf3c0c":"code","0a9ed178":"code","cb5ae483":"code","cb145b65":"code","2a72ad04":"code","8306ec10":"code","f2d3f4dd":"code","da86f809":"code","2bd5d210":"code","caa6e91a":"code","66ff7256":"code","a988d8d3":"code","fd25024a":"code","e5d1a166":"code","f517f676":"code","27f7abae":"code","31d7aa86":"code","cad79f70":"code","8e11523c":"code","3ec83ebb":"code","f773b4dc":"code","9833114e":"code","2ec3b0a2":"code","020e96a1":"code","511e1e17":"code","10d9654a":"code","4689e372":"code","6a2ce159":"code","88fec958":"code","f6e12124":"code","27381392":"code","337b7d4c":"code","5af24a40":"code","1ea26d23":"code","d723a41c":"code","091bfe6b":"code","231be661":"code","fee4934d":"code","8a9c4319":"code","99cfd00b":"code","8f700b09":"code","2d89410a":"code","bc555c1b":"code","cff44aca":"code","4b58888a":"code","9feb44aa":"code","e2e9caeb":"code","5e640f8c":"code","7377996c":"code","d9c51a71":"code","d1660464":"code","a439e08c":"code","9b591552":"code","32d93ab6":"code","559c524d":"code","13005d20":"code","26ab9a5c":"code","0f0d4a91":"code","a95cc0e1":"code","ce13046e":"code","4fc4a066":"code","02b462fb":"markdown","6fa1d4c9":"markdown","6cb5772f":"markdown","e9d4e605":"markdown","3fc50958":"markdown","762611a8":"markdown","a3e615ac":"markdown","1a11940c":"markdown","55185268":"markdown","9c054829":"markdown","8724f818":"markdown","ed2e96ce":"markdown","4c090740":"markdown","50c2d82b":"markdown","0fd13e95":"markdown","fd3876ea":"markdown","b8c5c632":"markdown","a1f45b36":"markdown","8ab4b467":"markdown","a53a6cec":"markdown"},"source":{"2369e52d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix,roc_curve,accuracy_score,auc,log_loss,roc_auc_score,f1_score\n%matplotlib notebook\n%matplotlib inline","fd318f1d":"data=pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata.iloc[:6]","d5a1c396":"data.describe().T","44038e4c":"data['TotalCharges']=data['TotalCharges'].apply(lambda i:np.NaN if i==' ' else float(i))","b7b3bba6":"data=data.dropna()\ndata.info()  ","c46c5294":"data.describe().T","5ee95990":"data.columns","33e77a44":"sns.countplot(x=data['Churn'])","3786f7fd":"df=pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\nkerugian=df.groupby(by='Churn').sum()['MonthlyCharges']\nprint(kerugian)\nsns.barplot(x=data['Churn'],y=data['MonthlyCharges'],estimator=sum)","d460df4e":"sns.boxplot(x='tenure',data=data)","06ce4f22":"sns.boxplot(x='MonthlyCharges',data=data)","0f39b048":"sns.boxplot(x='TotalCharges',data=data)","c999daf8":"columnCat=['gender', 'SeniorCitizen', 'Partner', 'Dependents','PhoneService', 'MultipleLines', 'InternetService','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling','PaymentMethod']\nplt.figure(figsize=(30,30))\nfor item in range(len(columnCat)):\n    plt.subplot(4,4,item+1)\n    plt.title(columnCat[item])\n    sns.countplot(x=data[columnCat[item]],hue=data['Churn'])\n    if columnCat[item]=='PaymentMethod':\n        plt.xticks(rotation=90)\nplt.show()","7f065c99":"label= preprocessing.LabelEncoder()\ndata['Churn']=label.fit_transform(data['Churn'])\ndata['Churn'].head()","e15e35a0":"plt.figure(figsize=(10,10))\nsns.heatmap(data.corr(),annot=True)","73825125":"columnNum=['tenure','MonthlyCharges','TotalCharges']\nplt.figure(figsize=(20,10))\nfor item in range(0,len(columnNum)):\n    plt.title(columnNum[item-1])\n    plt.subplot(1,3,item+1)\n    sns.distplot(data[data['Churn']==0][columnNum[item]],kde=True,color='blue',bins=20)\n    sns.distplot(data[data['Churn']==1][columnNum[item]],kde=True,color='red',bins=20)","824e80ba":"plt.scatter(data['TotalCharges'],data['tenure'],c=data['Churn'])\nplt.xlabel('TotalCharges')\nplt.ylabel('Tenure')","9145e9cd":"plt.scatter(data['tenure'],data['MonthlyCharges'],c=data['Churn'])\nplt.xlabel('tenure')\nplt.ylabel('MonthlyCharges')","fac53911":"plt.scatter(data['TotalCharges'],data['MonthlyCharges'],c=data['Churn'])\nplt.xlabel('TotalCharges')\nplt.ylabel('MonthlyCharges')","5b716007":"sns.FacetGrid(data,col='Contract',hue='Churn').map(plt.scatter,'MonthlyCharges','tenure').fig.set_size_inches(15,10)","cac95289":"sns.FacetGrid(data,col='Contract',row='PaymentMethod',hue='Churn').map(plt.scatter,'MonthlyCharges','tenure').fig.set_size_inches(15,10)","1f246a8d":"sns.FacetGrid(data,col='StreamingMovies',row='StreamingTV',hue='Churn').map(plt.scatter,'MonthlyCharges','tenure').fig.set_size_inches(15,10)","532784d8":"print('Mean Monthly charges internet DSL with streaming movies and TV',data[(data['InternetService']=='DSL')&(data['OnlineBackup']=='No')&(data['DeviceProtection']=='No')&(data['OnlineSecurity']=='No')&(data['TechSupport']=='No')&(data['StreamingMovies']=='Yes')&(data['StreamingTV']=='Yes')]['MonthlyCharges'].mean())\nprint('Mean Monthly charges internet  with streaming movies and TV',data[(data['InternetService']=='Fiber optic')&(data['OnlineBackup']=='No')&(data['DeviceProtection']=='No')&(data['OnlineSecurity']=='No')&(data['TechSupport']=='No')&(data['StreamingMovies']=='Yes')&(data['StreamingTV']=='Yes')]['MonthlyCharges'].mean())\nprint(data.groupby(by=['InternetService','OnlineBackup','OnlineSecurity','TechSupport','StreamingMovies','StreamingTV','DeviceProtection'])['MonthlyCharges'].mean())\nprint(data[(data['InternetService']=='Fiber optic')&(data['OnlineBackup']=='No')&(data['DeviceProtection']=='No')&(data['OnlineSecurity']=='No')&(data['TechSupport']=='No')&(data['StreamingMovies']=='Yes')&(data['StreamingTV']=='No')]['MonthlyCharges'].mean())","7556cc61":"sns.FacetGrid(data,col='InternetService',row='TechSupport',hue='Churn').map(plt.scatter,'MonthlyCharges','tenure').fig.set_size_inches(15,10)","d138dd22":"sns.FacetGrid(data,col='OnlineBackup',row='OnlineSecurity',hue='Churn').map(plt.scatter,'MonthlyCharges','tenure').fig.set_size_inches(15,10)","b0ba8142":"for item in columnCat:\n    data[item]=label.fit_transform(data[item])","77b2150c":"data=data.drop('customerID',axis=1)\ndata.iloc[:6]","008cdfaf":"xtrain,xtes,ytrain,ytes=train_test_split(data.drop('Churn',axis=1),data['Churn'],test_size=0.30,random_state=101)","a14a2c4c":"from sklearn.ensemble import RandomForestClassifier","db95a03d":"rfc=RandomForestClassifier(n_estimators=100,random_state=50)\nrfc.fit(xtrain,ytrain)","d4b2b923":"coef1=pd.Series(rfc.feature_importances_,xtrain.columns).sort_values(ascending=False)\ncoef1.plot(kind='bar',title='Feature Importances')","2966c3af":"predictTesRFC=rfc.predict(xtes)\npredictProbRFC=rfc.predict_proba(xtes)","766d9c04":"conRFC=pd.DataFrame(data=confusion_matrix(ytes,predictTesRFC),columns=['P No','P Yes'],index=['A No','A Yes']);\nconRFC","0dfd95d4":"print(classification_report(ytes,predictTesRFC))","46395a66":"preds=predictProbRFC[:,1]\nfpr,tpr,threshold=roc_curve(ytes,preds)\nroc_auc=auc(fpr,tpr)\n\nplt.title('Reveiver Operating Charateristic')\nplt.plot(fpr,tpr,'b',label='AUC={}'.format(round(roc_auc,2)))\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\n# plt.xlim([0,1])\n# plt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","d2dff3fc":"print('log_loss=',roc_auc_score(ytes,predictProbRFC[:,1]))","e73f8f69":"from sklearn import tree","93910bae":"DCT=tree.DecisionTreeClassifier()\nDCT.fit(xtrain,ytrain)","acf52fc9":"coef1=pd.Series(DCT.feature_importances_,xtrain.columns).sort_values(ascending=False)\ncoef1.plot(kind='bar',title='Feature Importances')","f14d1ab7":"predictTesDCT=rfc.predict(xtes)\npredictProbDCT=rfc.predict_proba(xtes)","1a83e373":"conDCT=pd.DataFrame(data=confusion_matrix(ytes,predictTesDCT),columns=['P No','P Yes'],index=['A No','A Yes']);\nconDCT","28547b06":"print(classification_report(ytes,predictTesDCT))","2fcf3c0c":"preds=predictProbDCT[:,1]\nfpr,tpr,threshold=roc_curve(ytes,preds)\nroc_auc=auc(fpr,tpr)\n\nplt.title('Reveiver Operating Charateristic')\nplt.plot(fpr,tpr,'b',label='AUC={}'.format(round(roc_auc,2)))\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\n# plt.xlim([0,1])\n# plt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","0a9ed178":"print('log_loss=',log_loss(ytes,predictProbDCT[:,1]))","cb5ae483":"import xgboost as xgb","cb145b65":"xgb=xgb.XGBClassifier()\nxgb.fit(xtrain,ytrain)","2a72ad04":"coef1=pd.Series(xgb.feature_importances_,xtrain.columns).sort_values(ascending=False)\ncoef1.plot(kind='bar',title='Feature Importances')","8306ec10":"predictTesXGB=xgb.predict(xtes)\npredictProbXGB=xgb.predict_proba(xtes)","f2d3f4dd":"conXG=pd.DataFrame(data=confusion_matrix(ytes,predictTesXGB),columns=['P No','P Yes'],index=['A No','A Yes']);\nconXG","da86f809":"print(classification_report(ytes,predictTesXGB))","2bd5d210":"preds=predictProbXGB[:,1]\nfpr,tpr,threshold=roc_curve(ytes,preds)\nroc_auc=auc(fpr,tpr)\n\nplt.title('Reveiver Operating Charateristic')\nplt.plot(fpr,tpr,'b',label='AUC={}'.format(round(roc_auc,2)))\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\n# plt.xlim([0,1])\n# plt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","caa6e91a":"print('log_loss=',roc_auc_score(ytes,predictProbXGB[:,1]))","66ff7256":"from sklearn.linear_model import LogisticRegression","a988d8d3":"logmodel = LogisticRegression(solver='lbfgs',max_iter=1000)\nlogmodel.fit(xtrain,ytrain)","fd25024a":"predictTesLR=logmodel.predict(xtes)\npredictProbLR=logmodel.predict_proba(xtes)","e5d1a166":"con=pd.DataFrame(data=confusion_matrix(ytes,predictTesLR),columns=['P No','P Yes'],index=['A No','A Yes']);\ncon","f517f676":"print(classification_report(ytes,predictTesLR))","27f7abae":"preds=predictProbLR[:,1]\nfpr,tpr,threshold=roc_curve(ytes,preds)\nroc_auc=auc(fpr,tpr)\n\nplt.title('Reveiver Operating Charateristic')\nplt.plot(fpr,tpr,'b',label='AUC={}'.format(round(roc_auc,2)))\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\n# plt.xlim([0,1])\n# plt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","31d7aa86":"from sklearn.model_selection import KFold\n\nK=10\nkf=KFold(n_splits=K,shuffle=True,random_state=42)\ntarget=data['Churn']\ndata=data.drop('Churn',axis=1)","cad79f70":"def calc_train_error(xtrain,ytrain,model):\n    predictions=model.predict(xtrain)\n    predictProba=model.predict_proba(xtrain)\n    accuracy=accuracy_score(ytrain,predictions)\n    f1=f1_score(ytrain,predictions,average='macro')\n    roc_auc=roc_auc_score(ytrain,predictProba[:,1])\n    logloss=log_loss(ytrain,predictProba[:,1])\n    report=classification_report(ytrain,predictions)\n    return {\n        'report':report,\n        'f1':f1,\n        'roc':roc_auc,\n        'accuracy':accuracy,\n        'logloss':logloss\n    }\ndef calc_validation_error(xtes,ytes,model):\n    predictions=model.predict(xtes)\n    predictProba=model.predict_proba(xtes)\n    accuracy=accuracy_score(ytes,predictions)\n    f1=f1_score(ytes,predictions,average='macro')\n    roc_auc=roc_auc_score(ytes,predictProba[:,1])\n    logloss=log_loss(ytes,predictProba[:,1])\n    report=classification_report(ytes,predictions)\n    return {\n        'report':report,\n        'f1':f1,\n        'roc':roc_auc,\n        'accuracy':accuracy,\n        'logloss':logloss\n    }\ndef calc_metrics(xtrain,ytrain,xtes,ytes,model):\n    model.fit(xtrain,ytrain)\n    train_error=calc_train_error(xtrain,ytrain,model)\n    validation_error=calc_validation_error(xtes,ytes,model)\n    return train_error,validation_error\n","8e11523c":"train_errors=[]\nvalidation_errors=[]\nfor train_index,val_index in kf.split(data,target):\n    #Split Data\n    xtrain,x_val=data.iloc[train_index],data.iloc[val_index]\n    ytrain,y_val=target.iloc[train_index],target.iloc[val_index]\n    \n    #calculate errors\n    train_error,val_error=calc_metrics(xtrain,ytrain,x_val,y_val,logmodel)\n    \n    #append to appropiate list\n    train_errors.append(train_error)\n    validation_errors.append(val_error)\ndfLR = []\nfor tr,val in zip(train_errors, validation_errors):\n    dfLR.append([tr['f1'], val['f1'], tr['roc'], val['roc'],\n                  tr['logloss'], val['logloss'],tr['accuracy'], val['accuracy']])\ndfLR = pd.DataFrame(dfLR, columns=['f1 train','f1 test','Train ROC AUC','Test ROC AUC',\n                                       'Train log_loss','Test log_loss','Train accuracy',\n                                       'Test accuracy'])\ndfLR","3ec83ebb":"print('log_loss=',roc_auc_score(ytes,predictProbLR[:,1]))","f773b4dc":"from sklearn.model_selection import GridSearchCV\n\nparameters={'class_weight':({0:1,1:3},{0:1,1:5},{0:1,1:7}),\n            'min_samples_leaf':(15,20,25,30)}\nrfc=RandomForestClassifier(n_estimators=100,random_state=101)\ndt=GridSearchCV(rfc,parameters,\n               scoring='roc_auc',cv=5)\ndt.fit(xtrain,ytrain)\nrfc=dt.best_estimator_\ndt.best_estimator_","9833114e":"train_errors=[]\nvalidation_errors=[]\nfor train_index,val_index in kf.split(data,target):\n    #Split Data\n    xtrain,x_val=data.iloc[train_index],data.iloc[val_index]\n    ytrain,y_val=target.iloc[train_index],target.iloc[val_index]\n    \n    #calculate errors\n    train_error,val_error=calc_metrics(xtrain,ytrain,x_val,y_val,rfc)\n    \n    #append to appropiate list\n    train_errors.append(train_error)\n    validation_errors.append(val_error)\ndfRFC = []\nfor tr,val in zip(train_errors, validation_errors):\n    dfRFC.append([tr['f1'], val['f1'], tr['roc'], val['roc'],\n                  tr['logloss'], val['logloss'],tr['accuracy'], val['accuracy']])\ndfRFC = pd.DataFrame(dfRFC, columns=['f1 train','f1 test','Train ROC AUC','Test ROC AUC',\n                                       'Train log_loss','Test log_loss','Train accuracy',\n                                       'Test accuracy'])\ndfRFC","2ec3b0a2":"DCT","020e96a1":"parameters={'class_weight':({0:1,1:3},{0:1,1:5},{0:1,1:7},{0:1,1:10}),\n            'min_samples_leaf':(90,100,110)}\ndt=GridSearchCV(DCT,parameters,\n               scoring='roc_auc',\n               cv=5)\ndt.fit(xtrain,ytrain)\nDCT=dt.best_estimator_\ndt.best_estimator_","511e1e17":"train_errors=[]\nvalidation_errors=[]\nfor train_index,val_index in kf.split(data,target):\n    #Split Data\n    xtrain,x_val=data.iloc[train_index],data.iloc[val_index]\n    ytrain,y_val=target.iloc[train_index],target.iloc[val_index]\n    \n    print(len(x_val),len(xtrain)+len(x_val))\n    \n    \n    #calculate errors\n    train_error,val_error=calc_metrics(xtrain,ytrain,x_val,y_val,DCT)\n    \n    #append to appropiate list\n    train_errors.append(train_error)\n    validation_errors.append(val_error)\ndfDCT = []\nfor tr,val in zip(train_errors, validation_errors):\n    dfDCT.append([tr['f1'], val['f1'], tr['roc'], val['roc'],\n                  tr['logloss'], val['logloss'],tr['accuracy'], val['accuracy']])\ndfDCT = pd.DataFrame(dfDCT, columns=['f1 train','f1 test','Train ROC AUC','Test ROC AUC',\n                                       'Train log_loss','Test log_loss','Train accuracy',\n                                       'Test accuracy'])\ndfDCT","10d9654a":"from sklearn.model_selection import GridSearchCV\n\nparameters={'max_depth':(1,2,3),\n            'min_child_weight':(13,15,17,20)}\ndt=GridSearchCV(xgb,parameters,\n               scoring='roc_auc',\n               cv=5)\ndt.fit(xtrain,ytrain)\nxgb=dt.best_estimator_\ndt.best_estimator_","4689e372":"train_errors=[]\nvalidation_errors=[]\nfor train_index,val_index in kf.split(data,target):\n    #Split Data\n    xtrain,x_val=data.iloc[train_index],data.iloc[val_index]\n    ytrain,y_val=target.iloc[train_index],target.iloc[val_index]\n    \n    print(len(x_val),len(xtrain)+len(x_val))\n    \n    \n    #calculate errors\n    train_error,val_error=calc_metrics(xtrain,ytrain,x_val,y_val,xgb)\n    \n    #append to appropiate list\n    train_errors.append(train_error)\n    validation_errors.append(val_error)\ndfXGB = []\nfor tr,val in zip(train_errors, validation_errors):\n    dfXGB.append([tr['f1'], val['f1'], tr['roc'], val['roc'],\n                  tr['logloss'], val['logloss'],tr['accuracy'], val['accuracy']])\ndfXGB = pd.DataFrame(dfXGB, columns=['f1 train','f1 test','Train ROC AUC','Test ROC AUC',\n                                       'Train log_loss','Test log_loss','Train accuracy',\n                                       'Test accuracy'])\ndfXGB","6a2ce159":"outside = ['f1', 'f1', 'f1','f1', 'f1',\n          'f1','f1','f1','f1','f1','f1','f1', 'ROC_AUC','ROC_AUC', 'ROC_AUC',\n          'ROC_AUC','ROC_AUC','ROC_AUC', 'ROC_AUC','ROC_AUC','ROC_AUC','ROC_AUC','ROC_AUC','ROC_AUC','logloss',\n          'logloss','logloss',\n          'logloss','logloss','logloss','logloss','logloss','logloss','logloss','logloss','logloss','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy','accuracy']\ninside = [1,2,3,4,5,6,7,8,9,10,'Avg','Std', 1,2,3,4,5,6,7,8,9,10,'Avg','Std', 1,2,3,4,5,6,7,8,9,10,'Avg','Std', 1,2,3,4,5,6,7,8,9,10,'Avg','Std']\nhier_index = list(zip(outside, inside))\nhier_index = pd.MultiIndex.from_tuples(hier_index)\nhier_index","88fec958":"f1=[]\nroc=[]\nlogloss=[]\naccuracy=[]\nkol = {\n    'f1' : 'f1 test',\n    'ROC_AUC' : 'Test ROC AUC',\n    'logloss' : 'Test log_loss',\n    'accuracy' : 'Test accuracy'\n}\nfor item1,item2,item3,item4 in zip(dfRFC.values,dfXGB.values,dfDCT.values,dfLR.values):\n    f1.append([item1[1],item2[1],item3[1],item4[1]])\n    roc.append([item1[3],item2[3],item3[3],item4[3]])\n    logloss.append([item1[5],item2[5],item3[5],item4[5]])\n    accuracy.append([item1[7],item2[7],item3[7],item4[7]])\n\nfor i,j in zip([f1,roc,logloss,accuracy], ['f1','ROC_AUC','logloss','accuracy']):\n    i.append([dfRFC[kol[j]].mean(), dfXGB[kol[j]].mean(),dfDCT[kol[j]].mean(),dfLR[kol[j]].mean()])\n    i.append([dfRFC[kol[j]].std(), dfXGB[kol[j]].std(),dfDCT[kol[j]].std(),dfLR[kol[j]].std()])\n    \ndfEval = pd.concat([pd.DataFrame(f1),pd.DataFrame(roc),pd.DataFrame(logloss),pd.DataFrame(accuracy)], axis=0)\ndfEval.columns = ['RFC','XGB','DCT','LR']\ndfEval.index = hier_index\ndfEval","f6e12124":"for item in ['ROC_AUC', 'accuracy', 'f1', 'logloss']:\n    print('Average of {}'.format(item))\n    print(dfEval.loc[item].loc['Avg'])","27381392":"xgb.fit(xtrain,ytrain)","337b7d4c":"coef1=pd.Series(xgb.feature_importances_,xtrain.columns).sort_values(ascending=False)\ncoef1.plot(kind='bar',title='Feature Importances')","5af24a40":"predictTesXGB=xgb.predict(xtes)\npredictProbXGB=xgb.predict_proba(xtes)","1ea26d23":"conXG=pd.DataFrame(data=confusion_matrix(ytes,predictTesXGB),columns=['P No','P Yes'],index=['A No','A Yes']);\nconXG","d723a41c":"print(classification_report(ytes,predictTesXGB))","091bfe6b":"preds=predictProbXGB[:,1]\nfpr,tpr,threshold=roc_curve(ytes,preds)\nroc_auc=auc(fpr,tpr)\n\nplt.title('Reveiver Operating Charateristic')\nplt.plot(fpr,tpr,'b',label='AUC={}'.format(round(roc_auc,2)))\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\n# plt.xlim([0,1])\n# plt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","231be661":"print('log_loss=',roc_auc_score(ytes,predictProbXGB[:,1]))","fee4934d":"from sklearn.model_selection import learning_curve\n\ntrain_sizes,train_scores,test_scores=learning_curve(estimator=xgb,\n                                                   X=data,\n                                                   y=target,\n                                                   train_sizes=np.linspace(0.3,1.0,5),\n                                                   cv=10,\n                                                   scoring='roc_auc')\nprint('\\nTrain Scores:')\nprint(train_scores)\n#Mean value of accuracy against training data\ntrain_mean=np.mean(train_scores,axis=1)\nprint('\\ntrain Mean: ')\nprint(train_mean)\nprint('\\nTrain Size: ')\nprint(train_sizes)\n#Standard deviation of training accuracy per number of training samples\ntrain_std=np.std(train_scores,axis=1)\nprint('\\nTrain Std: ')\nprint(train_std)\n\n#Same as data above for test data\ntest_mean=np.mean(test_scores,axis=1)\ntest_std=np.std(test_scores,axis=1)\nprint('\\nTest Scores:')\nprint(test_scores)\nprint('\\nTest Mean: ')\nprint(test_mean)\nprint('\\nTest Std: ')\nprint(test_std)\n\n#Plot training accuracies\nplt.plot(train_sizes,train_mean,color='red',marker='o',label='Training Accuracy')\n#Plot the variances of training accuracies\nplt.fill_between(train_sizes,\n                train_mean+train_std,\n                train_mean-train_std,\n                alpha=0.15,color='red')\n#Plot for test data as training data\nplt.plot(train_sizes,test_mean,color='blue',linestyle='--',marker='s',\n        label='Test Accuracy')\nplt.fill_between(train_sizes,\n                test_mean+test_std,\n                test_mean-test_std,\n                alpha=0.15,color='blue')\nplt.xlabel('Number of training samples')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","8a9c4319":"listItem=[]\nfor item1,item2,item3 in zip(tpr,fpr,threshold):\n    listItem.append([item1,item2,item3])\ndftpr=pd.DataFrame(columns=['TPR','FPR','Threshold'],data=listItem)\n# dftpr[dftpr['Threshold']<0.0382987]\ndftpr","99cfd00b":"predictTreshold=[]\nfor item in predictProbXGB:\n    if item[1]>=0.038299:\n        predictTreshold.append(1)\n    else:\n        predictTreshold.append(0)\npredictTreshold[:5]","8f700b09":"conXG=pd.DataFrame(data=confusion_matrix(ytes,predictTreshold),columns=['P No','P Yes'],index=['A No','A Yes']);\nconXG","2d89410a":"print(classification_report(ytes,predictTreshold))","bc555c1b":"datatest=xtes\ndatatest['Churn']=ytes\nkerugian=datatest.groupby(by='Churn').sum()['MonthlyCharges']\nprint(kerugian)\nsns.barplot(x=target,y=xtes['MonthlyCharges'],estimator=sum)","cff44aca":"listItem=[]\nfor item in zip(predictTreshold,ytes,data['TotalCharges'],data['MonthlyCharges']):\n    listItem.append([item[0],item[1],item[2],item[3]])\ndfDesc=pd.DataFrame(columns=['Predict','Actual','Total Charges','Monthly Charges'],data=listItem)\ndfDesc.head()","4b58888a":"dfDesc.groupby(by=['Predict','Actual']).sum()","9feb44aa":"# Budget=(kerugian[1]\/sum(predictTreshold))\nBudget=50000\/sum(predictTreshold)\nprint('Budget Promotion Per Customer: ',Budget)","e2e9caeb":"sns.countplot(x=dfDesc['Predict'],hue=dfDesc['Actual'])","5e640f8c":"sns.barplot(x=dfDesc['Predict'],y=dfDesc['Monthly Charges'],estimator=sum,hue=dfDesc['Actual'])","7377996c":"sns.barplot(x=dfDesc['Predict'],y=dfDesc['Monthly Charges'],estimator=sum)","d9c51a71":"sns.barplot(x=dfDesc['Actual'],y=dfDesc['Monthly Charges'],estimator=sum)","d1660464":"dftpr[dftpr['FPR']<0.4]","a439e08c":"predictTreshold=[]\nfor item in predictProbXGB:\n    if item[1]>=0.54:\n        predictTreshold.append(1)\n    else:\n        predictTreshold.append(0)\npredictTreshold[:5]","9b591552":"conXG=pd.DataFrame(data=confusion_matrix(ytes,predictTreshold),columns=['P No','P Yes'],index=['A No','A Yes']);\nconXG","32d93ab6":"print(classification_report(ytes,predictTreshold))","559c524d":"listItem=[]\nfor item in zip(predictTreshold,ytes,data['TotalCharges'],data['MonthlyCharges']):\n    listItem.append([item[0],item[1],item[2],item[3]])\ndfDesc=pd.DataFrame(columns=['Predict','Actual','Total Charges','Monthly Charges'],data=listItem)\ndfDesc.head()","13005d20":"dfDesc.groupby(by=['Predict','Actual']).sum()","26ab9a5c":"# Budget=(kerugian[1]\/sum(predictTreshold))\nBudget=50000\/sum(predictTreshold)\nprint('Budget Promotion per Customer: ',Budget)","0f0d4a91":"sns.countplot(x=dfDesc['Predict'],hue=dfDesc['Actual'])","a95cc0e1":"sns.barplot(x=dfDesc['Predict'],y=dfDesc['Monthly Charges'],estimator=sum,hue=dfDesc['Actual'])","ce13046e":"sns.barplot(x=dfDesc['Predict'],y=dfDesc['Monthly Charges'],estimator=sum)","4fc4a066":"sns.barplot(x=dfDesc['Actual'],y=dfDesc['Monthly Charges'],estimator=sum)","02b462fb":"# Distplot Summary\n#### Tenure=New user will likely to churn\n#### Monthly Charges= High monthly charges means higher churn rate\n#### Total Charge=higher total charges of custommer smaller the chance of them to churn","6fa1d4c9":"#### Customer that has contract month to month tend to be churn but the highest number of churn customer is if they use electronic check as payment method","6cb5772f":"# Random Forest","e9d4e605":"# Data Treatment","3fc50958":"# Machine Learning","762611a8":"# Business Solution 1\n#### Let's say that our company want to know best recall from Churned Client because the cost for promotion is near zero or zero we assume budget=50000","a3e615ac":"# Business Solution 2\n#### The cost for Churned Client is so high so we need precision for Churned Client","1a11940c":"# Decision Tree","55185268":"# Logistic Regression","9c054829":"# Countplot Summary\n#### Gender=feature gender doesnt have correlation with Churn\n#### Senior Citizen= Senior Citizen has imbalance data and almost half of senior citizen churned\n#### Partner= Customer that doesnt have partner likely will churn although the correlation will be really small\n#### Dependent=Customer that not dependent has higher chance to churn\n## Telco Service\n#### Phone Service=Imbalance data between customer that has phone service and not\n#### multiple line=No Correlation with Churn\n#### Internet service=Customer that use fiber optic has higher chance to churn\n#### online security=Customer that doesnt have online security service tend to have high Churn rate\n#### online backup=Customer that doesnt have online backup service tend to have high Churn rate\n#### device protection=Customer that doesnt have device protection service tend to have high Churn rate\n#### tech support=Customer that doesnt have tech support service tend to have high Churn rate\n#### Streaming TV=No Correlation with Churn\n#### streaming movies=No Correlation with Churn\n#### contract=The longer the contract the churn rate tend to be decreased\n#### paperless billing=customer that use paperless billing has higher churn rate\n#### payment method=Customer that use electronic check has the highest churn rate than other payment method\n\n\n\n## Feature that might have strong correlation with target(Churn):\n#### payment method\n#### Contract\n#### online security\n#### internet service\n#### tech support \n#### Online Backup","8724f818":"# Conclusion From EDA\n### payment method : telco need to reduce payment method using electronic check\n### Contract : telco need to reduce customer with month to month contract\n## Telco Feature\n#### Fiber Optic really expensive,either decrease the cost or focus on DSL Service\n#### Telco need to increase the number of customer that using services below:\n#### online security\n#### internet service\n#### tech support\n#### Online Backup\n","ed2e96ce":"# GridSearch and evaluate the model","4c090740":"# Test Evaluation XGBOOST with GridSearch","50c2d82b":"# Train Test Split","0fd13e95":"#### Customer that has contract month to month and high monthly charges tend will be churn","fd3876ea":"# EDA","b8c5c632":"#### From this chart we can see that Telco loss $13900 revenue from Churned Customer","a1f45b36":"#### From The Table we can see XGB perform better than RFC and DT and slightly better than Logistic Regression","8ab4b467":"#### Tenure and Monthly charges dont have any correlation\n#### The longer Customer use telco service, total charges will increased\n#### Client that has high monthly charge tend to have high total charges too","a53a6cec":"# XG Boost"}}