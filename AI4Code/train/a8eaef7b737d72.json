{"cell_type":{"7140b1fe":"code","804e54fb":"code","0f8109ba":"code","42deff20":"code","71881aee":"code","7570022c":"code","0d290150":"code","22bc1b54":"code","76547369":"code","318c7ea2":"code","0a115f22":"code","f1993e8f":"code","faca3d73":"code","184c4b7d":"code","1a4263c7":"code","98721daa":"code","c23ab93b":"code","cce703d3":"code","c2f5b742":"code","299ecb95":"code","f4dda062":"code","140700c4":"code","a9347a22":"code","d0a810ca":"code","43e08dc4":"code","d88d7582":"code","23687263":"code","6dddfdf3":"code","254489b2":"markdown","01fe9678":"markdown","ba677220":"markdown","3b2e1a96":"markdown","f4c394ef":"markdown","d25e444d":"markdown","d7054a67":"markdown","16b0affd":"markdown","8848d9c1":"markdown","28feaea8":"markdown","feac4b4b":"markdown","be6bb554":"markdown","7f405592":"markdown","87af7a66":"markdown","15c14431":"markdown","a03e4d93":"markdown","09c79dc7":"markdown","32a20985":"markdown","4e55c812":"markdown","6593762e":"markdown","c2869066":"markdown","66160d74":"markdown","8136c59d":"markdown","dc0cd11b":"markdown","8937ae79":"markdown"},"source":{"7140b1fe":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","804e54fb":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport folium\nfrom folium.plugins import HeatMap\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","0f8109ba":"data = pd.read_csv(\"..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv\")","42deff20":"data.head()","71881aee":"print('Number of features: {}'.format(data.shape[1]))\nprint('Number of entries: {}'.format(data.shape[0]))","7570022c":"plt.figure(figsize=(17, 5))\nsns.heatmap(data.isnull(), cbar=True, cmap='Set3')\nplt.xlabel(\"Column_Name\", size=14, weight=\"bold\")\nplt.title(\"Places of missing values in column\",fontweight=\"bold\",size=14)\nplt.show()","0d290150":"#make a list of the variables that contain missing values\nvars_with_na=[var for var in data.columns if data[var].isnull().sum()>1]\n\n#print the variable name and the percentage of missing values \nfor var in vars_with_na:\n    print(var,np.round(data[var].isnull().mean(),3),'% missing values')","22bc1b54":"plt.figure(figsize=(14, 6))\nsns.barplot(data.neighbourhood_group, data.price, hue=data.room_type, ci=None)","76547369":"plt.figure(figsize=(15, 6))\nsns.scatterplot(x=data.longitude,y=data.latitude,hue=data.neighbourhood_group)","318c7ea2":"m=folium.Map([40.7128,-74.0060],zoom_start=11)\nHeatMap(data[['latitude','longitude']].dropna(),radius=8,gradient={0.2:'blue',0.4:'purple',0.6:'orange',1.0:'red'}).add_to(m)\ndisplay(m)","0a115f22":"sns.distplot(data[(data['minimum_nights'] <= 30) & (data['minimum_nights'] > 0)]['minimum_nights'], bins=31)\nplt.ioff()","f1993e8f":"data.describe(include='all')","faca3d73":"### Lets plot histogram for prices less than $1000\nhist_price1=data[\"price\"][data[\"price\"]<1000].hist()","184c4b7d":"data = data[data[\"price\"]<1000]\ndata.head()","1a4263c7":"##Data cleaning\n#remove duplicates if any\ndata.duplicated().sum()\ndata.drop_duplicates(inplace=True)","98721daa":"#Drop unneceassry columns\ndata.drop(['name','id', 'host_id','last_review'], axis = 1, inplace = True)","c23ab93b":"#Drop NaN values\n#Since reviews_per_month column has many NaN values so lets replace them with 0 instead of removing\ndata.fillna({'reviews_per_month' : 0}, inplace = True)\n#remove Nan from rest of the column\ndata.isnull().sum() #to check for null values in each column\ndata.dropna(how = 'any', inplace = True)","cce703d3":"#Get correlation between different features\ncorr = data.corr(method='kendall')\nplt.figure(figsize=(12,7))\nsns.heatmap(corr, annot=True)\ndata.columns","c2f5b742":"#Regression analysis to predict the price\n#drop unneceassy columns\ndata.drop(['host_name','latitude','longitude','neighbourhood','number_of_reviews','reviews_per_month'], axis = 1, inplace = True)\nX = data.iloc[:,[0,1,3,4,5]]\ny = data['price']","299ecb95":"#Label encoding\nX = pd.get_dummies(X, prefix=['neighbourhood_group', 'room_type'], drop_first=True)","f4dda062":"#splitting the dataset into test and training data\nX_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 0)","140700c4":"print('Dimensions of the training feature matrix: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the test feature matrix: {}'.format(X_test.shape))\nprint('Dimensions of the test target vector: {}'.format(y_test.shape))","a9347a22":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","d0a810ca":"#Prepare a Linear Regression Model\n\nreg=LinearRegression()\nreg.fit(X_train,y_train)\ny_pred=reg.predict(X_test)\n#R2 score\nfrom sklearn.metrics import r2_score, mean_squared_error\nprint(\"R2 score: \",r2_score(y_test,y_pred)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': y_pred.flatten()})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","43e08dc4":"#Lasso regression\nregL1 = Lasso(alpha=0.01)\nregL1.fit(X_train, y_train) \n\ny_pred=regL1.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"R2 score: \",r2_score(y_test,y_pred)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': y_pred.flatten()})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","d88d7582":"#Prepairng a Decision Tree Regression\n\nDTree=DecisionTreeRegressor(min_samples_leaf=.0001)\nDTree.fit(X_train,y_train)\ny_pred=DTree.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"R2 score: \",r2_score(y_test,y_pred)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': y_pred.flatten()})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","23687263":"#Random forest regression \nregrRM2 = RandomForestRegressor(n_estimators=200, max_depth = 50, min_samples_split = 5,min_samples_leaf =4)\nregrRM2.fit(X_train, y_train)\n\ny_pred=regrRM2.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"R2 score: \",r2_score(y_test,y_pred)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': y_pred.flatten()})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","6dddfdf3":"#Gradient Boosting Regressor\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.01)\nGBoost.fit(X_train,y_train)\n\ny_pred=GBoost.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"R2 score: \",r2_score(y_test,y_pred)*100)\nprint(\"RMSE: \",np.sqrt(mean_squared_error(y_test,y_pred)))\n\n#Error\nerror_diff = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': y_pred.flatten()})\nprint(error_diff.head(5))\n\n#Visualize the error\ndf1 = error_diff.head(25)\ndf1.plot(kind='bar',figsize=(10,7))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","254489b2":"# Airbnb price prediction","01fe9678":"### Label encoding","ba677220":"### Drop unnecessary columns","3b2e1a96":"### Percentage of missing values in each column","f4c394ef":"Handling outliers by removing entries having price > 1000","d25e444d":"Its clearly visible that **reviews_per_month** has maximum number of missing values.","d7054a67":"### Remove duplicates","16b0affd":"The above bar plot demonstrates:\n\n1. Manhattan is the most expensive neighbourhood_group\n2. The price of entire home\/apt is more than any other room type.\n3. Bronx is the cheapest.","8848d9c1":"We see that the average price is 152. Price varies between 0 to 10K","28feaea8":"columns \"name\" and \"host_name\" are irrelevant and insignificant to our data analysis, columns \"last_review\" and \"review_per_month\" need very simple handling. To elaborate, \"last_review\" is date; if there were no reviews for the listing - date simply will not exist. In our case, this column is irrelevant and insignificant therefore appending those values is not needed. For \"review_per_month\" column we can simply append it with 0.0 for missing values; we can see that in \"number_of_review\" that column will have a 0, therefore following this logic with 0 total reviews there will be 0.0 rate of reviews per month. Therefore, let's proceed with removing columns that are not important and handling of missing data.","feac4b4b":"This dataset has around 49,000 observations in it with 16 columns and it is a mix between categorical and numeric values.","be6bb554":"### Feature scaling","7f405592":"### Distribution of Airbnb hotels in a Heat Map","87af7a66":"### Correlation between different features","15c14431":"### Plotting heatmap of missing values\n","a03e4d93":"### Model building","09c79dc7":"The above plot just decibes the demogrphic view of the entries in the data and also provides a clear view of the neighbourhood_groups.","32a20985":"The objective of the notebook is to predict the price of Airbnb hotels in New york city.","4e55c812":"### Nights Booked","6593762e":"### Check statics of the dataset","c2869066":"### Split datset","66160d74":"### Load all the required libraries","8136c59d":"### Load the dataset","dc0cd11b":"![airbnb-insights-705x439.jpg](attachment:airbnb-insights-705x439.jpg)","8937ae79":"Our features are not coorelated."}}