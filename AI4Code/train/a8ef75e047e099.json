{"cell_type":{"267b1eca":"code","1036b77a":"code","f97ee848":"code","8f514023":"code","5cbeedd0":"code","b8cd6517":"code","81837695":"code","1960bab4":"code","39953fcc":"code","89bbdc7d":"code","5a30cd14":"code","959bb8e2":"code","046c0529":"code","6a1a8e90":"code","55bc54ed":"code","7ccb60c3":"code","c85a3dad":"code","83377fa7":"markdown","f1c7cde2":"markdown","e8e3ce1b":"markdown","677ebb0f":"markdown","b08549d1":"markdown","4d8e2bd7":"markdown","dde18df7":"markdown","edd985ff":"markdown","80093ed4":"markdown"},"source":{"267b1eca":"!pip3 install ktrain==0.2.2","1036b77a":"from sklearn.model_selection import train_test_split","f97ee848":"import pandas as pd\ntrain_df = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")","8f514023":"train_df.head()","5cbeedd0":"random_seed = 12342\nx_train, x_val, y_train, y_val = train_test_split(train_df['text'], train_df['target'], shuffle=True, test_size = 0.2, random_state=random_seed, stratify=train_df['target'])","b8cd6517":"import ktrain\nfrom ktrain import text","81837695":"(x_train_bert,  y_train_bert), (x_val_bert, y_val_bert), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n                                                                                         x_test = x_val, y_test=y_val,\n                                                                                          class_names= [\"0\", \"1\"],\n                                                                                          preprocess_mode='bert',\n                                                                                          \n                                                                                          maxlen=65, \n                                                                                          max_features=35000)","1960bab4":"model = text.text_classifier('bert', train_data=(x_train_bert, y_train_bert), preproc=preproc)\nlearner = ktrain.get_learner(model, train_data=(x_train_bert, y_train_bert), val_data=(x_val_bert, y_val_bert), batch_size=16)","39953fcc":"learner.lr_find()             # briefly simulate training to find good learning rate\n   ","89bbdc7d":"learner.lr_plot()","5a30cd14":"learner.autofit(1e-5)","959bb8e2":"learner.validate(val_data=(x_val_bert, y_val_bert), class_names=['No Disaster', 'Disaster'])","046c0529":"# getting predictor variable\npredictor = ktrain.get_predictor(learner.model, preproc)","6a1a8e90":"learner.print_layers()","55bc54ed":"test_df = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\ntest_df[\"target\"] = predictor.predict(test_df[\"text\"].tolist())\n\ntest_df = test_df[[\"id\", \"target\"]]\n","7ccb60c3":"test_df.head()","c85a3dad":"test_df.to_csv(\"submisssions.csv\", index=False)","83377fa7":"**Multiclass Text Classification Using BERT and Keras****\nwe will use ktrain (a lightweight wrapper around Keras) to build a model using the dataset employed in the scikit-learn tutorial: Working with Text Data.The objective is to accurately classify each text into one of these 2 classes. This will provide us an opportunity to see BERT in action on a relatively smaller training set.","f1c7cde2":"### Splitting training data in to training and validation data","e8e3ce1b":"### Reading training file","677ebb0f":"**Convert data to features for BERT**\n# **Load and Preprocess the Data**\nPreprocess the data using the texts_from_array function (since the data resides in an array). If your documents are stored in folders or a CSV file you can use the texts_from_folder or texts_from_csv functions, respectively.","b08549d1":"### Getting predictor variable","4d8e2bd7":"### Getting predictions on test data","dde18df7":"# STEP 2: Load the BERT Model and Instantiate a Learner object\n**Create Model Instance and train it for 6 epochs\n**\n# STEP 3: Train the Model\nWe train using one of the three learning rates recommended in the BERT paper: 5e-5, 3e-5, or 2e-5. Alternatively, the ktrain Learning Rate Finder can be used to find a good learning rate by invoking learner.lr_find() and learner.lr_plot(), prior to training. The learner.fit_onecycle method employs a 1cycle learning rate policy.\n\n","edd985ff":"# **Supervised Learning code for Disaster Tweet Classification**\n\n\u2714\u2714\u2714\n\nInstalling the libraries\n","80093ed4":"### Importing Libraries\n"}}