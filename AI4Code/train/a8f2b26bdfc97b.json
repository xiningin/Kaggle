{"cell_type":{"3832d73f":"code","57dbbb05":"code","8cc7499c":"code","38cdf0b5":"code","53bb4eac":"code","791240a8":"code","4eaec5c2":"code","5ed9ee19":"code","39e3d7fc":"code","4aac849b":"code","41e8f1d8":"code","584ae16a":"code","ba4b862c":"code","e090b624":"code","be1dfac0":"code","01bf2f13":"code","94325c01":"code","bb275063":"code","b2974ab8":"code","5cb3d363":"code","582d0e0b":"code","365b3cba":"code","bbc9b2d3":"code","a4de699b":"code","2f8b2f9a":"code","5e96d5df":"code","2db01d84":"code","e8e718f9":"code","20e7ef2d":"code","74a4b8e7":"code","13e417d7":"code","a395c7b9":"code","bc44ef17":"code","85f04bac":"code","2d01036a":"code","f913af35":"code","0b088ab7":"code","40eafc65":"code","53cfcf42":"code","21f658e5":"code","9f241f0d":"markdown","c54c9f48":"markdown","49344136":"markdown","2b26949e":"markdown","7cecc4c1":"markdown","2af49575":"markdown","3e3fad47":"markdown","2e48c6ce":"markdown","ff297e4f":"markdown","70c8b3f5":"markdown","60d80e53":"markdown","9293198e":"markdown","66a52f53":"markdown","b39f061b":"markdown","b4c6a4c2":"markdown","c227d072":"markdown","d2e36895":"markdown","26f11bfe":"markdown","2cc442fd":"markdown","a43629b2":"markdown","41a69974":"markdown"},"source":{"3832d73f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom PIL import Image\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom scipy.special import boxcox\nimport os\nfrom os import path\nprint(os.listdir(\"..\/input\"))\nimport sklearn \nfrom sklearn.model_selection import train_test_split\n\n\n\n%matplotlib inline\nimport plotly\nimport plotly.plotly as py\nimport plotly.offline as offline\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nfrom plotly.graph_objs import Scatter, Figure, Layout\nfrom plotly import tools\n# Any results you write to the current directory are saved as output.","57dbbb05":"df = pd.read_csv(\"..\/input\/olist_classified_public_dataset.csv\")\ndf2 = pd.read_csv(\"..\/input\/geolocation_olist_public_dataset.csv\")","8cc7499c":"df.head(10)","38cdf0b5":"translate_df = pd.read_csv(\"..\/input\/product_category_name_translation.csv\")\ntranslate_df.head()","53bb4eac":"### all of product categories names are translated into english\nfor i in range(0,len(translate_df)):\n    df.product_category_name[df.product_category_name==translate_df.iloc[i,0]] = translate_df.iloc[i,1]","791240a8":"plt.figure(figsize=(50,60))\nsns.countplot(y=df.product_category_name,orient=\"v\")\nplt.yticks(fontsize=35)\nplt.xticks(fontsize=30)\nplt.ylabel(\"Product Category Name\", fontsize=40)\nplt.xlabel(\"Product Count\",fontsize=40)\nplt.title(\"Product Category Count\",fontsize=80)\nplt.show()","4eaec5c2":"soup = ' '.join(df.product_category_name)\n#wordcloud = WordCloud().generate()\n\nwordcloud = WordCloud(width=5000, height=2500,max_words=300)\nwordcloud.generate(soup)\nplt.figure(figsize=(20,10),facecolor='k')\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","5ed9ee19":"soup = ' '.join(df.review_comment_message)\n#wordcloud = WordCloud().generate()\n\nwordcloud = WordCloud(width=5000, height=2500,max_words=300)\nwordcloud.generate(soup)\nplt.figure(figsize=(20,10),facecolor='k')\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","39e3d7fc":"df.head()","4aac849b":"### convert data types of date columns into pd.datetime\ntime_columns = ['order_purchase_timestamp','order_aproved_at','order_estimated_delivery_date','order_delivered_customer_date']\nfor x in time_columns:\n    df[x] = pd.to_datetime(df[x])","41e8f1d8":"### calculate time delay between approving purchase\n### calculate time gap between estimated delivery date and actual ordered date\n\ndf['approved_delay'] = df['order_aproved_at']-df['order_purchase_timestamp']\ndf['delivery_gap_btw_est_act'] = df['order_delivered_customer_date']-df['order_estimated_delivery_date']","584ae16a":"### convert time delay between approving purchase into minutes data\n\napproved_time = pd.DatetimeIndex(df['approved_delay'])\napproved_minutes = approved_time.hour*60 + approved_time.minute","ba4b862c":"### Approved minutes into histogram\n\nplt.figure(figsize=(15,8))\nax = plt.subplot(1,1,1)\nsns.distplot(list(approved_minutes),bins=50,color='c')\nax.set_xticks(range(0,1800,60))\nplt.title(\"Approval Time Delay Histogram\",fontsize=20)\nplt.xlabel(\"Approval Delay in minutes\", fontsize=10)\nplt.show()","e090b624":"### convert time delay between approving purchase into minutes data\nDeliver_gap = pd.DatetimeIndex(df['delivery_gap_btw_est_act'])\nDeliver_gap = Deliver_gap.day-1\nCleanedList = [x for x in Deliver_gap if str(x) != 'nan']","be1dfac0":"### Approved minutes into histogram\n\nplt.figure(figsize=(15,8))\nax = plt.subplot(1,1,1)\nsns.distplot(CleanedList,bins=50,color='orange')\n#ax.set_xticks(range(0,1800,60))\nplt.title(\"Time gap between Estimated Delivery Date and Actual Date\"+\"\\n (Days Faster than estimated)\",fontsize=20)\nplt.xlabel(\"Dates\", fontsize=12)\nplt.show()","01bf2f13":"df2 = pd.read_csv(\"..\/input\/geolocation_olist_public_dataset.csv\").sample(n=50000)\n\nmapbox_access_token = 'pk.eyJ1IjoibGVlZG9oeXVuIiwiYSI6ImNqbjl1Y2hmcTB6dTQzcnBiNDZ2cXcwbGEifQ.hcPVtUhnyzXDXZbQQH0nMw'\ndata = [go.Scattermapbox(\n    lon = df2['lng'],\n    lat = df2['lat'],\n    marker = dict(\n        size = 3,\n        \n    ))]\n\nlayout = dict(\n        title = 'Geo Locations based on Zip code',\n        mapbox = dict(\n            accesstoken = mapbox_access_token,\n            center= dict(lat=-20,lon=-60),\n            bearing=5,\n            pitch=5,\n            zoom=2.3,\n        )\n    )\nfig = dict( data=data, layout=layout )\niplot( fig, validate=False)","94325c01":"### longitude and latitude are recored into new columns in df\n\ndf['customer_latitude'] = pd.Series([df2.loc[df2.zip_code_prefix==df.customer_zip_code_prefix[x],:].lat.mean() for x in range(0,len(df)-1)])\ndf['customer_longitude'] = pd.Series([df2.loc[df2.zip_code_prefix==df.customer_zip_code_prefix[x],:].lng.mean() for x in range(0,len(df)-1)])","bb275063":"\nmapbox_access_token = 'pk.eyJ1IjoibGVlZG9oeXVuIiwiYSI6ImNqbjl1Y2hmcTB6dTQzcnBiNDZ2cXcwbGEifQ.hcPVtUhnyzXDXZbQQH0nMw'\ndata = [go.Scattermapbox(\n    lon = df['customer_longitude'],\n    lat = df['customer_latitude'],\n    marker = dict(\n        size = 5,\n        color = 'red'\n    ))]\n\nlayout = dict(\n        title = 'Customer Locations',\n        mapbox = dict(\n            accesstoken = mapbox_access_token,\n            center= dict(lat=-20,lon=-60),\n            bearing=5,\n            pitch=5,\n            zoom=2.3,\n        )\n    )\nfig = dict( data=data, layout=layout )\niplot( fig, validate=False)","b2974ab8":"plt.figure(figsize=(10,10))\ncorr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","5cb3d363":"heavy_freights = df[df.order_freight_value > df.order_freight_value.quantile(q=0.9)]","582d0e0b":"\nmapbox_access_token = 'pk.eyJ1IjoibGVlZG9oeXVuIiwiYSI6ImNqbjl1Y2hmcTB6dTQzcnBiNDZ2cXcwbGEifQ.hcPVtUhnyzXDXZbQQH0nMw'\ndata = [go.Scattermapbox(\n    lon = heavy_freights['customer_longitude'],\n    lat = heavy_freights['customer_latitude'],\n    marker = dict(\n        size = heavy_freights['order_items_qty']*3,\n        color = 'blue'\n    ))]\n\nlayout = dict(\n        title = 'High Freight order Customer Locations',\n        mapbox = dict(\n            accesstoken = mapbox_access_token,\n            center= dict(lat=-20,lon=-60),\n            bearing=5,\n            pitch=5,\n            zoom=2.3,\n        )\n    )\nfig = dict( data=data, layout=layout )\niplot( fig, validate=False)","365b3cba":"### import olist public dataset which is including the data for customer_id\n\ndf3 = pd.read_csv(\"..\/input\/olist_public_dataset_v2.csv\")","bbc9b2d3":"df3.head()","a4de699b":"### making DataFrame based on df3.customer_id.value_counts()\n### first, making index list\n### second, making counts value list\n### zipping into dictionary and make new df 'purchase_df'\n\nvalue = df3.customer_id.value_counts().index.tolist()\ncounts= df3.customer_id.value_counts().tolist()\npurchase_df = pd.DataFrame({'customer_id':value,'purchase_counts':counts})","2f8b2f9a":"### purchase counts number df is concated into df3 as new column\n### pd.merge is very effective\n\ndf3 = pd.merge(df3,purchase_df)\ndf3.head()","5e96d5df":"def normalize(x):\n    return(x-x.mean())\/(x.max()-x.min())","2db01d84":"df3['normalized_opv']=normalize(df3.order_products_value)\ndf3['normalized_ofv']=normalize(df3.order_freight_value)","e8e718f9":"from sklearn.cluster import KMeans","20e7ef2d":"feature = df3[['normalized_opv','normalized_ofv']]\nmodel = KMeans(n_clusters=3,algorithm='auto')\nmodel.fit(feature)\npredict = pd.DataFrame(model.predict(feature))\npredict.columns=['predict']\nr = pd.concat([feature,predict],axis=1)","74a4b8e7":"ks = range(1,10)\ninertias = []\n\n\nfor k in ks:\n    model = KMeans(n_clusters=k)\n    model.fit(feature)\n    inertias.append(model.inertia_)\n    \n# Plot ks vs inertias\nplt.plot(ks, inertias, '-o')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.title(\"Intertias Tilting Graph\")\nplt.xticks(ks)\nplt.show()","13e417d7":"model = KMeans(n_clusters=3,algorithm='auto')\nmodel.fit(feature)\npredict = pd.DataFrame(model.predict(feature))\npredict.columns=['predict']\n\nplt.figure(figsize=(8,7))\nplt.scatter(r['normalized_opv'],r['normalized_ofv'],c=r['predict'],alpha=0.5)\nplt.xlim(xmax=0.4)\nplt.ylim(ymax=0.4)\nplt.xlabel(\"Order Product Values\",fontsize=15)\nplt.ylabel(\"Order Freight Values\",fontsize=15)\nplt.title(\"Clustering from Product Value & Freight Value\",fontsize=20)\ncenters = pd.DataFrame(model.cluster_centers_,columns=['normalized_opv','normalized_ofv'])\ncenter_x = centers['normalized_opv']\ncenter_y = centers['normalized_ofv']\nplt.scatter(center_x,center_y,s=50,marker='D',c='r')\nplt.show()","a395c7b9":"df['time gap btw purchase and deliver'] = df.order_delivered_customer_date - df.order_purchase_timestamp","bc44ef17":"deliver_gap = pd.DatetimeIndex(df['time gap btw purchase and deliver'])\ndf['days taken for deliver'] = deliver_gap.day\ndf['times taken for deliver'] = deliver_gap.day*24 + deliver_gap.hour\ndf = df.dropna(subset=['days taken for deliver','customer_latitude','customer_longitude'])","85f04bac":"y = df['times taken for deliver']\nX = df[['customer_latitude','customer_longitude']]\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)\nmodel = sklearn.svm.SVC()\nmodel.fit(y=y_train,X=X_train)\nmodel.predict(X=X_train)","2d01036a":"model.score(y=y_train,X=X_train)","f913af35":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport numpy as np\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)\n\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(13, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model\n\nseed = 10\nnp.random.seed(seed)\n# evaluate model with standardized dataset\nestimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\nestimator.fit(X_train, y_train)","0b088ab7":"estimator.predict(X_test)","40eafc65":"estimator.predict(X_test)","53cfcf42":"plt.figure(figsize=(10,10))\nsns.scatterplot(list(range(1,len(estimator.predict(X_test))+1)),estimator.predict(X_test))\nsns.scatterplot(list(range(1,len(estimator.predict(X_test))+1)),y_test)","21f658e5":"plt.figure(figsize=(10,5))\nsns.distplot(estimator.predict(X_test),color='b')\nsns.distplot(y_test,color='c')","9f241f0d":"# Normalize is needed before conducting Clustering","c54c9f48":"# Convert 4 columns into pd.Datetime data types","49344136":"# Olist Data Analysis : Geospatial and Correlations\n### Olist E-commerce Data is used to trace customer location based on zip code using latitude and longitude\n#### (1) [What kinds of products are sold frequently? and which words are appeared mainly in review comments](#1)\n#### (2) [Showing Delivery Dates Time Histogram: Estimated Dates vs Actual Dates](#2)\n#### (3) [Geospatial scatterplot using latitudes and longitudes data, linking Zip code for customers](#3)\n#### (4) [Interesting Correlation between features & Freight payments by locations](#4)\n#### (5) [Clustering can seperate customers?](#5)\n#### (6) [ To be improved ](#6)","2b26949e":"# Product Category WordCloud","7cecc4c1":"# <a id='5'><\/a><br> Data merge from value_counts()","2af49575":"## KMeans Clustering using only 2 dimensions\n### Clustering method is not seem to efficient","3e3fad47":"### Actual delivery occurs on average 15 days earlier than the estimated delivery date\n#### This result implies that Company's estimation for delivery date is too loose that their estimation is needed to be improved","2e48c6ce":"# WordCloud using Review Comment data & Products Categories","ff297e4f":"# In every case of delivery, actual delivery dates never exceed the estimated Delivery Dates","70c8b3f5":"# <a id='6'><\/a><br> To be improved...\n#### only a few customers are recorded as using this e-commerce platform more than once.\n#### in order to get insight or motivate more customers use this platform, further data will be helpful","60d80e53":"# <a id=\"1\"><\/a><br> Product Category Count Plot","9293198e":"# <a id='2'><\/a><br> Showing Histogram for approval time delay data","66a52f53":"# <a id='3'><\/a><br> Showing Geo Locations based on Zip code","b39f061b":"# Let's look at who is paying for higher freight payment\n## This is related to the number of order items quantity and addresses","b4c6a4c2":"## Linear Regression between Customer Location and Hours taken for deliver","c227d072":"# KMeans Clustering ","d2e36895":"# Using Keras Regression...","26f11bfe":"## Checking optimal number of Clusters","2cc442fd":"# Estimate Customer address' Longitude and Latitude based on their zip code","a43629b2":"# In above graph, size of circle means the number of orders.\n### Therefore, we need to focus on the smaller circles' location, these locations are needed to pay further fees.","41a69974":"# <a id='4'><\/a><br> Let's look at Intersting Correlations\n### (1) Votes_parital_delivery & order_sellers_qty are stronly correlated : Obvious\n### (2) Votes_satisfied & review_score are stronly correlated : Obvious \n### (3) Votes_before_estimate & review_score stronly correlated : Obvious\n### (4) product_description_length & order_products_value : Interesting ..Right?\n### (5) Customer Latitude and Longitude(Location of Customer) is correlated with order_freight_value "}}