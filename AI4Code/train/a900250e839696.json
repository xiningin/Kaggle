{"cell_type":{"fafde86b":"code","683a79dc":"code","0b3e097c":"code","d5f1a076":"code","cabb999c":"code","2306ed5f":"code","f2bd978c":"code","f75da21f":"code","9fc0ab20":"code","990ec7ec":"code","0ed5853a":"code","ad14fff8":"code","f94ed860":"code","775cd637":"code","5759355c":"code","5765637c":"code","eea7b95c":"code","74b71301":"code","697377d4":"markdown","84705b35":"markdown","5196f778":"markdown","609c4012":"markdown","ecb65c37":"markdown","5dc92890":"markdown","1f2798d8":"markdown","f137649b":"markdown","6f661ffe":"markdown","6ee66610":"markdown","21ee372f":"markdown","9fb0fec2":"markdown","5f27332d":"markdown","abc85e49":"markdown","a53675f3":"markdown","0fff7346":"markdown","a5168ffb":"markdown","382564e2":"markdown","eb6a2248":"markdown","b3c76694":"markdown","3f7be552":"markdown","37a51480":"markdown","de317b96":"markdown"},"source":{"fafde86b":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential, layers\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","683a79dc":"mnist = keras.datasets.mnist.load_data()\n(x1, y1), (x2, y2) = mnist\nx = np.concatenate((x1,x2))\ny = np.concatenate((y1,y2))\nx.shape, y.shape\nprint('\\nDataset loaded succesfully..')\nprint('Total number of samples in the Dataset :',x.shape[0])\nprint('Shape of images in the Dataset :',x.shape[1:])\nprint('\\nLabels and number of samples per labels :')\npd.DataFrame({'Labels':np.unique(y,return_counts=True)[0],'Counts':np.unique(y,return_counts=True)[1]})","0b3e097c":"x = x.reshape(x.shape[0],28*28)\nx,y = RandomOverSampler().fit_resample(x,y)\nx = x.reshape(x.shape[0],28,28,1)\nprint('\\nData is balanced now.')\nprint('Total number of samples in the Dataset now :',x.shape[0])\nprint('\\nLabels and number of samples per labels now :')\npd.DataFrame({'Labels':np.unique(y,return_counts=True)[0],'Counts':np.unique(y,return_counts=True)[1]})","d5f1a076":"xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,stratify=y,random_state=28)\nprint('\\nTotal number of samples in the Train Dataset now :',xtrain.shape[0])\nprint('Total number of samples in the Test Dataset now :',xtest.shape[0])\nprint('\\nLabels and number of samples per labels in train dataset now :')\npd.DataFrame({'Labels':np.unique(ytrain,return_counts=True)[0],'Counts':np.unique(ytrain,return_counts=True)[1]})","cabb999c":"print('\\nLabels and number of samples per labels in test dataset now :')\npd.DataFrame({'Labels':np.unique(ytest,return_counts=True)[0],'Counts':np.unique(ytest,return_counts=True)[1]})","2306ed5f":"plt.figure(figsize=(25,15))\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    plt.imshow(xtrain[i])\n    label = \"This is : \" + str(ytrain[i])\n    plt.xlabel(label,fontdict={'fontsize':14})","f2bd978c":"plt.figure(figsize=(25,15))\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    plt.imshow(xtest[i])\n    label = \"This is : \" + str(ytest[i])\n    plt.xlabel(label,fontdict={'fontsize':14})","f75da21f":"digits = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nytrain = keras.utils.to_categorical(ytrain)\nytest = keras.utils.to_categorical(ytest)","9fc0ab20":"xtrain = xtrain \/ 255\nxtest = xtest \/ 255","990ec7ec":"model = Sequential(\n                        [\n                            # CNN Layers\n                            layers.Conv2D(25,(3,3),padding='same',activation='relu',input_shape=(28,28,1)),\n                            layers.MaxPooling2D((2,2)),\n                            layers.Conv2D(50,(3,3),padding='same',activation='relu'),\n                            layers.MaxPooling2D((2,2)),\n                            layers.Conv2D(75,(3,3),padding='same',activation='relu'),\n                            layers.MaxPooling2D((2,2)),                            \n                            layers.Conv2D(100,(3,3),padding='same',activation='relu'),\n                            layers.MaxPooling2D((2,2)),\n                            \n                            # Flattening Data\n                            layers.Flatten(),\n                            \n                            # Dense Layers\n                            layers.Dense(50,activation='relu'),\n                            layers.Dropout(0.1),\n                            layers.Dense(25,activation='relu'),\n                            layers.Dropout(0.05),\n                            layers.Dense(10,activation='softmax')\n                        ]\n                  )\nmodel.summary()","0ed5853a":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\ntraining = model.fit(xtrain,ytrain,batch_size=20,validation_data=(xtest,ytest),epochs=10)","ad14fff8":"training_history = training.history\ntraining_history['epochs'] = range(1,11)\ntraining_history = pd.DataFrame(training_history)\nprint('\\nLoss and Accuracy History per Epochs :')\ntraining_history","f94ed860":"plt.figure(figsize=(15,5))\nplt.plot(training_history['epochs'],training_history['loss'])\nplt.plot(training_history['epochs'],training_history['val_loss'])\nplt.legend(['loss','validation loss'])\nplt.title('Loss Per Epochs')\nplt.xlabel('Epochs -->')\nplt.ylabel('Loss -->')\nplt.show()\n\nplt.figure(figsize=(15,5))\nplt.plot(training_history['epochs'],training_history['accuracy'])\nplt.plot(training_history['epochs'],training_history['val_accuracy'])\nplt.legend(['accuracy','validation accuracy'])\nplt.title('Accuracy Per Epochs')\nplt.xlabel('Epochs -->')\nplt.ylabel('Accuracy -->')\nplt.show()","775cd637":"ytrue = np.array([np.argmax(i) for i in ytest])\nypred = np.array([np.argmax(i) for i in model.predict(xtest)])\nprint('\\nConfusion Matrics : ')\nconfusion_matrix(ytrue,ypred)","5759355c":"plt.figure(figsize=(20,10))\nsns.heatmap(confusion_matrix(ytrue,ypred),annot=True,cmap='YlGnBu')\nplt.title('Confusion Metrics Visualization')\nplt.show()","5765637c":"print('\\nClassification Report : \\n')\nprint(classification_report(ytrue,ypred))","eea7b95c":"plt.figure(figsize=(25,15))\nprint('\\nPredictions on few Samples :\\n')\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    plt.imshow(xtest[i])\n    prediction = np.argmax(model.predict(np.array([xtest[i]])))\n    label = \"This is : \" + str(ytrue[i]) + '\\n' + 'Model Predicted : ' + str(prediction)\n    plt.title(label,fontdict={'fontsize':14})","74b71301":"model.save('mnist_handwritten_classifier.h5')","697377d4":"#### Normalization","84705b35":"# <center>**Thank You**","5196f778":"#### Some Examples of Testing Data","609c4012":"#### Some Examples of Training Data","ecb65c37":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/2\/27\/MnistExamples.png\/320px-MnistExamples.png\" alt=\"Heat beating\" style=\"height:300px;margin-top:3rem;\"> <\/div>","5dc92890":"#### Visualizing Confusion Metrics","1f2798d8":"#### Saving Model","f137649b":"***","6f661ffe":"#### Categorical Encoding","6ee66610":"#### Visualization of Training History","21ee372f":"#### Handling Imbalanced Data","9fb0fec2":"# <center>**Handwritten Digit Classification**","5f27332d":"#### Spliting Data for Training and Testing","abc85e49":"### **AIM : Developing a Neural Network Model that can Read and Classify Handwritten Digits.**","a53675f3":"#### Analysis of Training History","0fff7346":">","a5168ffb":"#### Model Compilation and Training","382564e2":"#### Model Performence Analysis - Classification Report","eb6a2248":"#### Model Performence Analysis - Confusion Metrics","b3c76694":"#### Load Dataset","3f7be552":"#### Importing All Necessary Packages","37a51480":"#### Developing Convolutional Neural Network Model","de317b96":"#### Predictions on few Samples"}}