{"cell_type":{"c63dfcbb":"code","e27bc9bc":"code","ca678727":"code","a7a7ccdf":"code","c67d7cc3":"code","9ee65f4c":"code","05d10ab4":"code","dacc2888":"code","ee7c4238":"code","81217ebd":"code","0a2b62e3":"code","d2b473c8":"code","b8cdf687":"code","675b042e":"code","e2b0d1c5":"code","053b8ba8":"code","aa5e5f38":"code","ece28c41":"code","10acf91a":"code","6d4d9e46":"code","5a4d2ae1":"code","8f44ad15":"code","96788d5d":"code","92523ac0":"code","da51c7fa":"code","40a20a7b":"code","4b89d83a":"code","30b6d33f":"code","f33f12ef":"code","f4ab6681":"code","96937737":"code","caa72972":"code","50523696":"code","11d30188":"code","8b0e745b":"markdown","40717f8d":"markdown","f06d9b27":"markdown","56a65ce4":"markdown","5e4725eb":"markdown","b74601e0":"markdown","84dbdc4f":"markdown","dbc2351a":"markdown","f6f40007":"markdown","00f41a9c":"markdown","40737094":"markdown","8993bdfd":"markdown","a86a539f":"markdown","eec72fca":"markdown","71b85720":"markdown","46e8fd6a":"markdown","4d2a9b8e":"markdown","6f950363":"markdown","86f3298c":"markdown","01e6e537":"markdown","45e05a8f":"markdown","319015bd":"markdown","1200a99c":"markdown","e16404a0":"markdown"},"source":{"c63dfcbb":"import numpy as np \nimport pandas as pd \nimport re\nimport nltk \n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import csr_matrix\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\nfrom sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import uniform\nfrom wordcloud import WordCloud","e27bc9bc":"raw_data = pd.read_csv('..\/input\/penyisihan-datavidia-7-0\/train.csv')\nraw_data.head()","ca678727":"raw_data.info()","a7a7ccdf":"raw_data['review_id'].value_counts()","c67d7cc3":"raw_data['review_text'].value_counts()","9ee65f4c":"raw_data['category'].value_counts()","05d10ab4":"X = raw_data['review_text']","dacc2888":"unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\nunigram_vectorizer.fit(X)\nX_train_unigram = unigram_vectorizer.transform(X)\n\nunigram_tf_idf_transformer = TfidfTransformer()\nunigram_tf_idf_transformer.fit(X_train_unigram)\nX_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)","ee7c4238":"print(X_train_unigram)","81217ebd":"print(X_train_unigram_tf_idf)","0a2b62e3":"bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\nbigram_vectorizer.fit(X)\nX_train_bigram = bigram_vectorizer.transform(X)\n\nbigram_tf_idf_transformer = TfidfTransformer()\nbigram_tf_idf_transformer.fit(X_train_bigram)\nX_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)","d2b473c8":"print(X_train_bigram)","b8cdf687":"print(X_train_bigram_tf_idf)","675b042e":"def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n    X_train, X_valid, y_train, y_valid = train_test_split(\n        X, y, train_size=0.8, stratify=y, random_state = 42\n    )\n\n    clf = SGDClassifier()\n    clf.fit(X_train, y_train)\n    train_score = clf.score(X_train, y_train)\n    valid_score = clf.score(X_valid, y_valid)\n    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')","e2b0d1c5":"y_train = raw_data[\"category\"].values","053b8ba8":"train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\ntrain_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\ntrain_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\ntrain_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')","aa5e5f38":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nmpl.style.use('ggplot')","ece28c41":"fig, ax = plt.subplots(figsize = (6, 6))\nsizes = [count for count in raw_data['category'].value_counts()]\nlabels = list(raw_data['category'].value_counts().index)\nexplode = (0.1, 0)\nax.pie(x = sizes, labels = labels, autopct = '%1.1f%%', explode = explode, textprops={'fontsize': 14})\nax.set_title('Category Percentage on Reviews Data', fontsize = 16, pad = 20)\nplt.show()","10acf91a":"sns.histplot(raw_data['review_text'].str.len())\nplt.show()","6d4d9e46":"sns.histplot(raw_data[raw_data['category'] == 1]['review_text'].str.len())\nplt.show()","5a4d2ae1":"sns.histplot(raw_data[raw_data['category'] == 0]['review_text'].str.len())\nplt.show()","8f44ad15":"sns.kdeplot(raw_data[raw_data['category'] == 1]['review_text'].str.len())\nsns.kdeplot(raw_data[raw_data['category'] == 0]['review_text'].str.len())\nplt.show()","96788d5d":"tmp = []\nfor i in raw_data[\"review_text\"]:\n#     t = []\n    for j in i.lower().split():\n        tmp.append(j)\n    \n\ndf = pd.DataFrame(tmp, columns = ['Words']) ","92523ac0":"from collections import Counter\n\ntop = Counter([item for item in df['Words']])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","da51c7fa":"string = ' '.join(temp['Common_words'])\n\nwordcloud = WordCloud(width = 600, height = 400, background_color = 'black', min_font_size = 10).generate(string)\nfig, ax = plt.subplots(figsize = (8, 6))\nax.set_title('Word Cloud of Reviews Data', fontsize = 18)\nax.grid(False)\nax.imshow((wordcloud))\nfig.tight_layout(pad=0)\nax.axis('off')\nplt.show()","40a20a7b":"distributions = dict(\n    penalty=['l1', 'l2', 'elasticnet'],\n    alpha=uniform(loc=1e-6, scale=1e-5),\n    loss=['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n    learning_rate=['optimal', 'invscaling', 'adaptive'],\n    eta0=uniform(loc=1e-7, scale=1e-3),\n    max_iter=[1e6]\n)","4b89d83a":"clf = SGDClassifier()\n\nrandomized_search_cv =  RandomizedSearchCV(\n    estimator=clf,\n    param_distributions=distributions,\n    cv=10,\n    n_iter=100,\n    verbose=2,\n    scoring='f1_macro',\n    random_state=42,\n    return_train_score=True\n)","30b6d33f":"X_train = X_train_bigram_tf_idf\nrandomized_search_cv.fit(X_train, y_train)","f33f12ef":"print(f'Best estimator: \\n{randomized_search_cv.best_estimator_}\\n')\nprint(f'Best params: \\n{randomized_search_cv.best_params_}\\n')\nprint(f'Best score: \\n{randomized_search_cv.best_score_}\\n')","f4ab6681":"sgd_classifier = randomized_search_cv.best_estimator_","96937737":"test = pd.read_csv('..\/input\/penyisihan-datavidia-7-0\/test.csv')\ntest","caa72972":"X_test = bigram_vectorizer.transform(test[\"review_text\"].values)\n\nX_test = bigram_tf_idf_transformer.transform(X_test)","50523696":"del test[\"review_text\"]\ntest['category'] = sgd_classifier.predict(X_test)","11d30188":"test.to_csv(\"submission.csv\", index=False)","8b0e745b":"**Fit Grid Seach**","40717f8d":"**Create Model With Best Estimator**","f06d9b27":"**Write Prediction Result To CSV**","56a65ce4":"Dari hasil visualisasi distribusi panjang kalimat diatas, kita dapat menyimpulkan bahwa:\n\n* Keseluruhan review cenderung memiliki panjang kalimat yang rendah\n* Kalimat dengan panjang diatas 100 sangat sedikit dan,\n* Mayoritas kalimat dengan panjang diatas 100 berasal dari review negative","5e4725eb":"**Build A Grid Search Space**","b74601e0":"[1] Joachims T. (1998) Text categorization with Support Vector Machines: Learning with many relevant features. In: N\u00e9dellec C., Rouveirol C. (eds) Machine Learning: ECML-98. ECML 1998. Lecture Notes in Computer Science (Lecture Notes in Artificial Intelligence), vol 1398. Springer, Berlin, Heidelberg.\n\n[2] Zhang, D., Wang, J. and Zhao, X., 2015, September. Estimating the uncertainty of average F1 scores. In Proceedings of the 2015 International Conference on The Theory of Information Retrieval (pp. 317-320).","84dbdc4f":"**SVM Hyperparameters**","dbc2351a":"Dari hasil yang kita dapatkan, berikut adalah beberapa hal yang bisa kita simpulkan:\n* Problem Type: Sentiment Analysis (Binary Classification)\n* Target Variabel: Category\n* Tidak ada column yang memiliki null value","f6f40007":"# 2. Data Wrangling\n\nDalam tahap ini kita akan mengubah review_text menjadi vector alu diubah menjadi unigram vector dan bigram vector. Setelah itu, data diubah menjadi bentuk vector TF-IDF (term frequency\u2013inverse document frequency) sehingga data menjadi bentuk unigram tf-idf dam bigram tf-idf. Berikut adalah contohnya:\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*iPsBH19N9_DW4u_QXc8wFA.png)\n\nDari kedua kalimat di atas, kita dapat membuat sebuah kumpulan kata yang unik dari kalimat tersebut.\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*K8af6OLksqCzpjj5JYFbdA.png)\n\nBerikut adalah representasi unigram dari kedua kalimat di atas:\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*MJ6908hSSTAgoVZIbRbjdA.png)\n\nBerikut adalah representasi bigram dari kedua kalimat di atas:\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*RLY811uwYEX_tF_nM6IcBQ.png)\n\nReferensi:\n* Building a Sentiment Classifier using Scikit-Learn (https:\/\/towardsdatascience.com\/building-a-sentiment-classifier-using-scikit-learn-54c8e7c5d2f0)\n\n* Maas, A., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y. and Potts, C., 2011, June. Learning word vectors for sentiment analysis. In Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies (pp. 142-150).","00f41a9c":"# **5. Modeling and Validation**\nDalam bagian ini kami melakukan modeling menggunakan SGDClassifier, kami melakukan hyperparameter tuning dengan menggunakan GridSearchCV agar dapat menghasilkan model dengan hyperparameter yang optimal dengan mengikuti penilaian dari validasi f1 metric.\n\nText sering kali memiliki pembagian yang linear, selain itu text classification memiliki sedikit feature yang tidak relevant[[1]](https:\/\/doi.org\/10.1007\/BFb0026683). Sehingga SVM (Support Vector Machine) sangat cocok untuk menyelesaikan masalah ini.\n\nDalam mengevaluasi model dalam GridSearchCV kami menggunakan metric F1-macro karena metric tersebut adalah metric yang paling sering digunakan untuk menilai text classifier, F1 Score didefinisikan sebagai rata-rata harmonic recall dan precision. Kami menggunakan F1-Macro karena macro averaging memberikan weight yang sama kepada kedua kelas[[2]](https:\/\/dl.acm.org\/doi\/10.1145\/2808194.2809488).","40737094":"Notebook ini akan membahas pendekatan tim kami untuk membuat model yang dapat melakukan *sentiment analysis* dengan menggunakan *machine learning*. Berikut adalah tahapan-tahapannya:\n\n1. **Problem Definition**: memahami masalah yang sedang dihadapi agar dapat mencari solusi yang tepat serta membantu menentukan teknik yang akan digunakan.\n2. **Data Wrangling**: membersihkan dan menstrukturkan data dengan tujuan untuk mempersiapkan data agar siap untuk digunakan dalam proses pembelajaran machine learning.\n3. **Exploratory Data Analysis (EDA)**: mengidentifikasi pola, mendeteksi anomali, dan melakukan analisa menggunakan statistik terhadap data agar kita lebih mengerti mengenai data tersebut.\n4. **Data Modelling**: membuat sebuah model dengan mencoba berbagai macam teknik, algoritma, dan juga melakukan hyperparameter tuning untuk mendapatkan model yang efisien dan teroptimisasi untuk data yang kita olah.\n5. **Prediction**: mengetes model dengan data yang belum pernah dilihat sebelumnya untuk mengecek akurasi dari model tersebut.\n\nPerlu diingat bahwa tahapan-tahapan di atas tidak kaku. Setelah melakukan prediksi, kita bisa balik ke tahap *EDA* maupun *Data Wrangling* untuk kembali mengolah data atau mengganti parameter saat *modelling*.\n","8993bdfd":"# **7. References**","a86a539f":"Pertama-tama, kita dapat mengimport terlebih dahulu data yang sudah diberikan. Setelah itu, kita mencoba untuk memahami struktur dari data yang diberikan dengan melihat 5 baris pertama dari dataset. Kemudian dilanjuti oleh memahami tiap kolum yang ada di dataset serta mengecek masing-masing kolum.","eec72fca":"# **6. Prediction**\n\nDalam bagian ini kami melakukan prediksi terhadap dataset test","71b85720":"**Predict The Text Classification**","46e8fd6a":"**View Best Estimator, Parameters, and Score**","4d2a9b8e":"Sekarang kita akan menentukan tipe data yang mana yang paling optimal untuk data kita. ","6f950363":"# Daftar Isi\n1. Problem Definition\n","86f3298c":"# Datavidia 7.0: Sentiment Analysis\n**By Tim Penangkap Serangga**\n\n**1. Roland (Ketua)**\n\n**2. Elvan Selvano**\n\n**3. Cornelius Tantius**","01e6e537":"# 1. Problem Definition\n> Mas William merupakan manager perusahaan jaringan operator mitra hotel ternama di Indonesia. Dalam pekerjaan sehari - harinya, mas William sering kali perlu menangani masalah - masalah yang ada pada jasa perhotelan yang diberikan perusahaan. Namun, belakangan ini aplikasinya sangat sering dipakai sehingga mas William kewalahan untuk menemukan mana review buruk yang perlu penanganan segera. Akibatnya, mas William dimarahi oleh bos Jopan. Mas William pun pergi menemui mas Yoga, seorang data scientist handal di perusahaan tersebut untuk menemukan solusinya. Mas Yoga menawarkan untuk membantu mas William dapat bekerja dengan lebih efisien. Bantulah Mas Yoga untuk melakukan prediksi apakah suatu review termasuk review positif atau negatif.\n\nDi dalam kompetisi ini, kita diberikan sebuah dataset mengenai ulasan hotel. Kita diminta untuk membuat sebuah model menggunakan machine learning yang bisa menentukan apakah sebuah ulasan dikategorikan sebagai ulasan positif atau ulasan negatif. \n\nDalam hal ini, kita mendapatkan sebuah problem yaitu sentiment analysis untuk menganalisa sentimen dari sebuah review. Kita akan menggunakan beberapa packages untuk melakukan analisa dan modelling.","45e05a8f":"**Prepare Feature in Test**","319015bd":"# Most Common Words and Word Cloud\nPada bagian ini, kita akan memvisualisasikan kata - kata yang sering muncul secara kesuluruha, sering muncul di review positive dan sering muncul di review negative. Sumber kalimat yang kita gunakan adalah kalimat yang sudah di preprocess dan dijadikan token untuk menghindari prefix ato suffix pada sebuah kata.","1200a99c":"**Import And View Test Dataset**","e16404a0":"# 3. Exploratory Data Analysis (EDA)"}}