{"cell_type":{"3b2ebb87":"code","7072d22d":"code","6a0e0efd":"code","35a4542a":"code","91cd9c58":"code","5185ac70":"code","cff99943":"code","dbf213f1":"code","9f3dbe45":"code","c6b3ec3b":"code","a4ae7fe2":"code","3eb48ff9":"code","a79b5b39":"code","68306253":"code","d31eb043":"code","9ec7e695":"code","93b57736":"code","b6fed7ee":"code","f3ea725c":"code","69f72f89":"code","acf78ce6":"code","bce56428":"code","2e34d5d3":"markdown","b29342d6":"markdown","a92dc84e":"markdown","20a07f37":"markdown","c5530aa3":"markdown","4c08c452":"markdown","a7f99bb0":"markdown","95efe706":"markdown","6d79a297":"markdown","c4fe27ed":"markdown","84c5b29e":"markdown","2d9fdc8e":"markdown","f2243036":"markdown","26cf9db6":"markdown"},"source":{"3b2ebb87":"from __future__ import print_function\n\nfrom collections import defaultdict, deque\nimport datetime\nimport pickle\nimport time\nimport torch.distributed as dist\nimport errno\nfrom fastai import metrics\n\nimport cv2\nimport collections\nimport os\nimport numpy as np\nimport torch\nimport torch.utils.data\nfrom PIL import Image, ImageFile\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torchvision import transforms\nimport torchvision\nimport random\n\nImageFile.LOAD_TRUNCATED_IMAGES = True","7072d22d":"import platform\nprint(f'Python version: {platform.python_version()}')\nprint(f'PyTorch version: {torch.__version__}')","6a0e0efd":"def seed_everything(seed=73):\n    '''\n      Make PyTorch deterministic.\n    '''    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.deterministic = True","35a4542a":"seed_everything()","91cd9c58":"IS_DEBUG = False","5185ac70":"def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n\n    def f(x):\n        if x >= warmup_iters:\n            return 1\n        alpha = float(x) \/ warmup_iters\n        return warmup_factor * (1 - alpha) + alpha\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)","cff99943":"class DiceLoss(torch.nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n \n    def forward(self, logits, targets):\n        ''' fastai.metrics.dice uses argmax() which is not differentiable, so it \n          can NOT be used in training, however it can be used in prediction.\n          see https:\/\/github.com\/fastai\/fastai\/blob\/master\/fastai\/metrics.py#L53\n        '''\n        N = targets.size(0)\n        preds = torch.sigmoid(logits)\n        #preds = logits.argmax(dim=1) # do NOT use argmax in training, because it is NOT differentiable\n        # https:\/\/github.com\/tensorflow\/tensorflow\/blob\/r1.12\/tensorflow\/python\/keras\/backend.py#L96\n        EPSILON = 1e-7\n \n        preds_flat = preds.view(N, -1)\n        targets_flat = targets.view(N, -1)\n \n        intersection = (preds_flat * targets_flat).sum()#.float()\n        union = (preds_flat + targets_flat).sum()#.float()\n        \n        loss = (2.0 * intersection + EPSILON) \/ (union + EPSILON)\n        loss = 1 - loss \/ N\n        return loss","dbf213f1":"import torch.nn.functional as F\n\ndef train_one_epoch(model, optimizer, data_loader, device, epoch):\n    model.train()\n    loss_func = DiceLoss()\n\n    lr_scheduler = None\n    if epoch == 0:\n        warmup_factor = 1. \/ 1000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    lossf=None\n    inner_tq = tqdm(data_loader, total=len(data_loader), leave=False, desc= f'Iteration {epoch}')\n    for images, masks in inner_tq:\n        y_preds = model(images.to(device))\n        y_preds = y_preds['out'][:, 1, :, :] #\n\n        loss = loss_func(y_preds, masks.to(device))\n\n        if torch.cuda.device_count() > 1:\n            loss = loss.mean() # mean() to average on multi-gpu.\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()\n        else:\n            lossf = loss.item()\n        inner_tq.set_postfix(loss = lossf)","9f3dbe45":"def rle2mask(rle, width, height):\n    mask= np.zeros(width * height, dtype=np.uint8)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 1\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","c6b3ec3b":"class SIIMDataset(torch.utils.data.Dataset):\n    def __init__(self, df_path, img_dir):\n        self.df = pd.read_csv(df_path)\n        self.df = self.df[self.df[' EncodedPixels'] != ' -1']\n        if IS_DEBUG:\n            self.df = self.df.sample(frac=0.01, random_state=73)\n        self.height = 1024\n        self.width = 1024\n        self.image_dir = img_dir\n        self.image_info = collections.defaultdict(dict)\n\n        counter = 0\n        for index, row in tqdm(self.df.iterrows(), total=len(self.df)):\n            image_id = row['ImageId']\n            image_path = os.path.join(self.image_dir, image_id)\n            if os.path.exists(image_path + '.png') and row[\" EncodedPixels\"].strip() != \"-1\":\n                self.image_info[counter][\"image_id\"] = image_id\n                self.image_info[counter][\"image_path\"] = image_path\n                self.image_info[counter][\"annotations\"] = row[\" EncodedPixels\"].strip()\n                counter += 1\n\n    def __getitem__(self, idx):\n        img_path = self.image_info[idx][\"image_path\"]\n        img = Image.open(img_path + '.png').convert(\"RGB\")\n        width, height = img.size\n        info = self.image_info[idx]\n\n        mask = rle2mask(info['annotations'], width, height)\n        mask = mask.T\n#         mask = np.expand_dims(mask, axis=0)\n        mask = torch.as_tensor(mask, dtype=torch.float)\n\n        img = transforms.ToTensor()(img)\n        \n        return img, mask\n\n    def __len__(self):\n        return len(self.image_info)","a4ae7fe2":"dataset_train = SIIMDataset(\"..\/input\/siim-dicom-images\/train-rle.csv\", \"..\/input\/siim-png-images\/input\/train_png\")","3eb48ff9":"len(dataset_train)","a79b5b39":"model_ft = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False, num_classes=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft.to(device)\nNUM_GPUS = torch.cuda.device_count()\nif NUM_GPUS > 1:\n    model_ft = torch.nn.DataParallel(model_ft)\n_ = model_ft.to(device)","68306253":"data_loader = torch.utils.data.DataLoader(\n    dataset_train, batch_size=2*NUM_GPUS, shuffle=True, num_workers=NUM_GPUS,drop_last=True\n)","d31eb043":"# construct an optimizer\nparams = [p for p in model_ft.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)","9ec7e695":"# and a learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                               step_size=5,\n                                               gamma=0.1)","93b57736":"num_epochs = 5\nfor epoch in range(num_epochs):\n    train_one_epoch(model_ft, optimizer, data_loader, device, epoch)\n    lr_scheduler.step()","b6fed7ee":"def mask_to_rle(img, width, height):\n    rle = []\n    lastColor = 0\n    currentPixel = 0\n    runStart = -1\n    runLength = 0\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 1:\n                    runStart = currentPixel\n                    runLength = 1\n                else:\n                    rle.append(str(runStart))\n                    rle.append(str(runLength))\n                    runStart = -1\n                    runLength = 0\n                    currentPixel = 0\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor\n            currentPixel+=1\n    # https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/discussion\/98317\n    if lastColor == 255:\n        rle.append(runStart)\n        rle.append(runLength)\n    return \" \" + \" \".join(rle)","f3ea725c":"model_ft.eval()\nfor param in model_ft.parameters():\n    param.requires_grad = False\nmodel_ft.to(torch.device('cuda'))\nassert model_ft.training == False","69f72f89":"torch.save(model_ft.state_dict(), 'deeplabv3.pth')\ntorch.cuda.empty_cache()","acf78ce6":"sample_df = pd.read_csv(\"..\/input\/siim-acr-pneumothorax-segmentation\/sample_submission.csv\")\n\n# this part was taken from @raddar's kernel: https:\/\/www.kaggle.com\/raddar\/better-sample-submission\nmasks_ = sample_df.groupby('ImageId')['ImageId'].count().reset_index(name='N')\nmasks_ = masks_.loc[masks_.N > 1].ImageId.values\n###\nsample_df = sample_df.drop_duplicates('ImageId', keep='last').reset_index(drop=True)","bce56428":"tt = transforms.ToTensor()\nsublist = []\ncounter = 0\nthreshold = 0.5\nfor index, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n    image_id = row['ImageId']\n    if image_id in masks_:\n        img_path = os.path.join('..\/input\/siim-png-images\/input\/test_png', image_id + '.png')\n\n        img = Image.open(img_path).convert(\"RGB\")\n        width, height = img.size\n        img = img.resize((1024, 1024), resample=Image.BILINEAR)\n        img = tt(img)\n        img = img.reshape((1, *img.numpy().shape))\n        logits = model_ft(img.to(device))['out'][:, 1, :, :]\n        preds = torch.sigmoid(logits)[0].cpu().numpy()\n        mask = (preds > 0.5).astype(np.uint8).T\n        if np.count_nonzero(mask) == 0:\n            rle = \" -1\"\n        else:\n            rle = mask_to_rle(mask, width, height)\n    else:\n        rle = \" -1\"\n    sublist.append([image_id, rle])\n\nsubmission_df = pd.DataFrame(sublist, columns=sample_df.columns.values)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(counter)","2e34d5d3":"# RLE to Mask","b29342d6":"# SIIM Dataset Class","a92dc84e":"# Create Dataset","20a07f37":"# Create Data Loader","c5530aa3":"# Get Test Data","4c08c452":"# Train Model","a7f99bb0":"# Mask to RLE helper","95efe706":"# Create DeepLabV3 Model","6d79a297":"This kernel is forked from [mask-rcnn with augmentation and multiple masks](https:\/\/www.kaggle.com\/abhishek\/mask-rcnn-with-augmentation-and-multiple-masks)\n\n# Import Cool Stuff","c4fe27ed":"# Convert Model to Evaluation Mode","84c5b29e":"# Training Function","2d9fdc8e":"## Dice Loss","f2243036":"# Define Training Parameters","26cf9db6":"# Utility Functions (hidden)"}}