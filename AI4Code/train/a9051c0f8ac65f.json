{"cell_type":{"974b8050":"code","d1eccecd":"code","646e425d":"code","7c608b7e":"code","3f81e9e6":"code","cf7ba014":"code","1ea25eec":"code","fb6a6f45":"code","cfe44d85":"code","a479b4c3":"code","eeaf68a8":"code","33923347":"code","0beb1e43":"code","b7a2bd7d":"code","78d898e1":"code","f0d4b57a":"code","8afba9fd":"code","8af40d10":"markdown","fabdc772":"markdown","16857c78":"markdown","e66a1c68":"markdown","1ef8d109":"markdown","a1e8ae51":"markdown","4fb7b5fe":"markdown","6f2e129d":"markdown","d4777351":"markdown","041194b5":"markdown","ac374f11":"markdown","de315000":"markdown","8f1e8d1f":"markdown"},"source":{"974b8050":"! python -m pip -q install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","d1eccecd":"def polygonFromMask(maskedArr): # https:\/\/github.com\/hazirbas\/coco-json-converter\/blob\/master\/generate_coco_json.py\n\n    contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    segmentation = []\n    for contour in contours:\n        # Valid polygons have >= 6 coordinates (3 points)\n        if contour.size >= 6:\n            segmentation.append(contour.flatten().tolist())\n    RLEs = mask_util.frPyObjects(segmentation, maskedArr.shape[0], maskedArr.shape[1])\n    RLE = mask_util.merge(RLEs)\n    # RLE = mask.encode(np.asfortranarray(maskedArr))\n    area = mask_util.area(RLE)\n    [x, y, w, h] = cv2.boundingRect(maskedArr)\n\n    return segmentation[0] #, [x, y, w, h], area","646e425d":"from detectron2.structures import polygons_to_bitmask\ndef polygon_to_rle(polygon: list, shape=(520, 704)):\n    '''\n    polygon: a list of [x1, y1, x2, y2,....]\n    shape: shape of bitmask\n    Return: RLE type of mask\n    '''\n    mask = polygons_to_bitmask([np.asarray(polygon) + 0.25], shape[0], shape[1]) # add 0.25 can keep the pixels before and after the conversion unchanged\n    rle = mask_util.encode(np.asfortranarray(mask))\n    return rle","7c608b7e":"import detectron2\nfrom pathlib import Path\nimport random, cv2, os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pycocotools.mask as mask_util\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, default_setup, hooks, launch\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.modeling import GeneralizedRCNNWithTTA\nsetup_logger()","3f81e9e6":"dataDir=Path('\/kaggle\/input\/sartorius-cell-instance-segmentation\/')\ntrain_json_file = \"\/kaggle\/input\/sartorius-cell-instance-segmentation-coco\/annotations_train.json\"\nval_json_file = \"\/kaggle\/input\/sartorius-cell-instance-segmentation-coco\/annotations_val.json\"\nregister_coco_instances(\"sar_train\", {}, train_json_file, dataDir)\nregister_coco_instances(\"sar_val\", {}, val_json_file, dataDir)","cf7ba014":"metadata = MetadataCatalog.get('sar_train')\ntrain_ds = DatasetCatalog.get('sar_train')","1ea25eec":"sample = train_ds[35]\nsample_seg = sample[\"annotations\"][0][\"segmentation\"]\nsample_seg","fb6a6f45":"sample_mask = mask_util.decode(sample_seg)\nsample_polygon = polygonFromMask(sample_mask)","cfe44d85":"restored_rle = polygon_to_rle(sample_polygon)\nrestored_rle","a479b4c3":"poly = polygonFromMask(mask_util.decode(restored_rle))\nnp.array(poly),np.array(sample_polygon)","eeaf68a8":"poly_mask = mask_util.decode(restored_rle)\n_, ax = plt.subplots(1, 2, figsize=(40, 16))\nax[0].imshow(poly_mask, cmap=\"gray\")\nax[1].imshow(sample_mask, cmap=\"gray\")\nax[0].set_title(\"restored\")\nax[1].set_title(\"ori\")","33923347":"import json\n\ndef polygons_format_json(json_file, save_dir):\n    with open(json_file) as f:\n        imgs_anns = json.load(f)\n\n    for idx, v in enumerate(imgs_anns[\"annotations\"]):\n        rle = v[\"segmentation\"]\n        compressed_rle = mask_util.frPyObjects(rle, rle.get('size')[0], rle.get('size')[1])\n        mymask = mask_util.decode(compressed_rle)\n        polygons = polygonFromMask(mymask)\n        v[\"segmentation\"] = [polygons]\n    \n    json_str = json.dumps(imgs_anns, indent=4, separators=(',', ':'))\n    with open(save_dir, 'w') as json_file:\n        json_file.write(json_str)","0beb1e43":"os.mkdir(\"\/kaggle\/working\/annotations\")\nfor d in [\"train\", \"val\"]:\n    json_file = f\"\/kaggle\/input\/sartorius-cell-instance-segmentation-coco\/annotations_{d}.json\"\n    save_dir = f\"\/kaggle\/working\/annotations_{d}_polygon.json\"\n    polygons_format_json(json_file, save_dir)","b7a2bd7d":"train_json_file = \"..\/input\/cellis\/annotations\/annotations_train_polygon.json\"\nval_json_file = \"..\/input\/cellis\/annotations\/annotations_val_polygon.json\"\nregister_coco_instances(\"sar_train_polygon\", {}, train_json_file, dataDir)\nregister_coco_instances(\"sar_val_polygon\", {}, val_json_file, dataDir)","78d898e1":"def ann_visualization(data, metadata, index):\n    data = data[index]\n    img = cv2.imread(data[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata)\n    out = visualizer.draw_dataset_dict(data)\n    return out","f0d4b57a":"before = DatasetCatalog.get('sar_train')\nafter = DatasetCatalog.get('sar_train_polygon')\nmb, ma = MetadataCatalog.get('sar_train'), MetadataCatalog.get('sar_train_polygon')","8afba9fd":"index = 32\noutb = ann_visualization(before, mb, index)\nouta = ann_visualization(after, ma, index)\n_, ax = plt.subplots(1, 2, figsize=(40, 30))\nax[0].imshow(outb.get_image()[:, :, ::-1])\nax[1].imshow(outa.get_image()[:, :, ::-1])","8af40d10":"It seems that the convertion is successful!","fabdc772":"# Experiment","16857c78":"I tested several different masks, and the results are roughly the same. The converted mask will lose a few pixels.\nNoticed that in `polygon_to_rle`:\n```python\nmask = polygons_to_bitmask([np.asarray(polygon) + 0.25], shape[0], shape[1])\n```\n*0.25* is tried out through experimentation. When I set it to 0, I find that the x coordinate will differ by 1, and when it is set to 0.5, the y coordinate will differ by 1. So I took their average to alleviate this problem.","e66a1c68":"# The information loss due to convertion\nWe will compare the mask before and after conversion in polygon format","1ef8d109":"# Polygon to RLE\nUsing the opposite method, we can also convert polygons to RLE. Through this inverse process, we can observe whether there is information loss during the conversion process.","a1e8ae51":"## Save annotation in polygon format\nI saved the converted result as a new file and placed it in the **cellis** dataset","4fb7b5fe":"Although there are differences in data, they seem to be similar. So information loss will not affect training.","6f2e129d":"# RLE to Polygon\nThe basic idea is to first convert RLE into bitmask, and then obtain the corresponding polygons by looking for contours on the bitmask.","d4777351":"You can see that the restored RLE(**b'YW[52P`08N1N3N2M5L3N000002M<E\\\\Ud5'**) is different from the one(**b'YW[53o?8N1N3N2M5L3N000000O3N;DTec5'**) in the original data. We can visualize it and observe it more intuitively","041194b5":"When i try to use the [centermask2](https:\/\/github.com\/youngwanLEE\/centermask2\/blob\/master\/configs\/centermask\/centermask_V_39_eSE_FPN_ms_3x.yaml) to train my model, an error occur \"AttributeError: 'BitMasks' object has no attribute 'polygons'\". So there is a need of converting original RLE mask to polygons to run the code.\n\nFirst we need to install detectron2 for subsequent use","ac374f11":"## Visualization","de315000":"## Load Data","8f1e8d1f":"## Display a sample file to check the convertion"}}