{"cell_type":{"868102ec":"code","6aceba22":"code","91d67693":"code","a52ff773":"code","dcb21c0a":"code","0252e536":"code","299fb342":"code","1e8e8a61":"code","e387a4f4":"code","17eac945":"code","7608755b":"code","22710114":"code","8a2c34a3":"code","a009e16b":"code","3f5560a5":"code","7760781e":"code","1f582e12":"code","0a573f47":"code","36738164":"code","e6a409dc":"code","025181e4":"code","fb6a7285":"markdown","34113038":"markdown","9f45f13d":"markdown","19b77878":"markdown","2829acbb":"markdown","634d73be":"markdown"},"source":{"868102ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6aceba22":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb","91d67693":"dt = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndt.head()","a52ff773":"plt.figure(figsize=(20,15))\nsns.set_theme(style='dark')\nplt.subplot(2,3,1)\nsns.countplot(data=dt,x='fbs',hue='target')\nplt.subplot(2,3,2)\nsns.countplot(data=dt,x='restecg',hue='target')\nplt.subplot(2,3,3)\nsns.countplot(data=dt,x='slope',hue='target')\nplt.subplot(2,3,4)\nsns.countplot(data=dt,x='ca',hue='target')\nplt.subplot(2,3,5)\nsns.countplot(data=dt,x='exang',hue='target')\nplt.subplot(2,3,6)\nsns.countplot(data=dt,x='thal',hue='target')\nplt.show()","dcb21c0a":"plt.figure(figsize=(13,13))\n\nsns.set_theme(style='darkgrid')\nplt.subplot(2,3,1)\nsns.boxplot(x='thal',data=dt)\nplt.subplot(2,3,2)\nsns.boxplot(x='oldpeak',data=dt)\nplt.subplot(2,3,3)\nsns.boxplot(x='thalach',data=dt)\nplt.subplot(2,3,4)\nsns.boxplot(x='chol',data=dt)\nplt.subplot(2,3,5)\nsns.boxplot(x='trestbps',data=dt)\nplt.subplot(2,3,6)\nsns.boxplot(x='age',data=dt)\nplt.show()","0252e536":"dt.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']","299fb342":"dt.describe()","1e8e8a61":"ranges = [0, 120, 140, np.inf]\nlabels = [0, 1, 2]\n\ndt['resting_blood_pressure'] = pd.cut(dt.resting_blood_pressure, bins=ranges, labels=labels)","e387a4f4":"ranges = [0, 200, 270, np.inf]\nlabels = [0, 1, 2]\n\ndt['cholesterol'] = pd.cut(dt.cholesterol, bins=ranges, labels=labels)","17eac945":"ranges = [0, 130, 160, np.inf]\nlabels = [0, 1, 2]\n\ndt['max_heart_rate_achieved'] = pd.cut(dt.max_heart_rate_achieved, bins=ranges, labels=labels)","7608755b":"ranges = [0, 0.8, 1.6, np.inf]\nlabels = [0, 1, 2]\n\ndt['st_depression'] = pd.cut(dt.st_depression, bins=ranges, labels=labels)","22710114":"dt['resting_blood_pressure'] = pd.to_numeric(dt.resting_blood_pressure)\ndt['cholesterol'] = pd.to_numeric(dt.cholesterol)\ndt['max_heart_rate_achieved'] = pd.to_numeric(dt.max_heart_rate_achieved)\ndt['st_depression'] = pd.to_numeric(dt.st_depression)","8a2c34a3":"for i in dt.columns:\n    dt[i].fillna(dt[i].mean(), inplace=True)","a009e16b":"dt.head()","3f5560a5":"X_train, X_test, y_train, y_test = train_test_split(dt.drop('target', 1), dt['target'], test_size = 0.3, random_state=10) #split the data","7760781e":"dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=6, min_samples_leaf=6)\ndt_model.fit(X_train, y_train)\ndt_model.score(X_test, y_test)","1f582e12":"rf = RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth= 3, min_samples_leaf= 5)\nrf.fit(X_train, y_train)\nrf.score(X_test, y_test)","0a573f47":"y_pred = rf.predict(X_test)","36738164":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","e6a409dc":"X, y = dt.iloc[:,:-1], dt.iloc[:,-1]\n\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","025181e4":"clf = xgb.XGBClassifier(subsample=0.7, n_estimators= 500, learning_rate=1.0, num_boost_round=10)\nclf.fit(X_train, y_train)\nprint('Score: ',clf.score(X_test, y_test))","fb6a7285":"dmatrix = xgb.DMatrix(data=X,label=y)\ngbm_param_grid = {'learning_rate': np.arange(0.05,1.05,.05),\n                  'n_estimators': [100, 200, 500],\n                  'subsample': np.arange(0.05,1.05,.05)}\n\ngbm = xgb.XGBRFClassifier()\n\nrandomized_mse = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid, \n                                    n_iter=25, cv=5, verbose=1)\n\nrandomized_mse.fit(X, y)","34113038":"## Boosting","9f45f13d":"rf = RandomForestClassifier()\n\npara_rf = {'criterion':['gini','entropy'],'max_depth':np.arange(1, 50), 'min_samples_leaf':[1,2,4,5,10,20,30,40,80,100]}\n\ngrid = GridSearchCV(dtree, para_dt, cv=5)\n\ngrid.fit(X_train, y_train)\n\ngrid.best_params_\n","19b77878":"## Decision Tree","2829acbb":"dtree = DecisionTreeClassifier()\n\npara_dt = {'criterion':['gini','entropy'],'max_depth':np.arange(1, 50), 'min_samples_leaf':[1,2,4,5,10,20,30,40,80,100]}\n\ngrid = GridSearchCV(dtree, para_dt, cv=5)\n\ngrid.fit(X_train, y_train)\n\ngrid.best_params_\n\ngrid.best_score_","634d73be":"## Random Forest"}}