{"cell_type":{"c542fc6a":"code","73923f2b":"code","6062cc03":"code","be0a0614":"code","5fa38420":"code","fdf185df":"code","c2b9cb04":"code","b98f79ec":"code","6331e5ec":"code","ef3b3d40":"code","99db584c":"code","bb47400b":"code","4d88f81b":"code","aee55b1e":"code","533efe03":"code","3c5c8580":"code","f6387d32":"markdown","c13fc922":"markdown","273b4df9":"markdown","93db1eb4":"markdown","a57c36c2":"markdown","ad4351a1":"markdown","1dee696b":"markdown","0c99d6fe":"markdown","a18339a4":"markdown","4575e929":"markdown","a0e49388":"markdown","c5f7944c":"markdown","c5157dfa":"markdown","5306ac49":"markdown"},"source":{"c542fc6a":"# Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# import utilities\nimport os\nimport time\n\n# import data visualization\nimport matplotlib.pyplot as plt\n\n# import pytorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD,Adam,lr_scheduler\nfrom torch.utils.data import random_split\nimport torchvision\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader","73923f2b":"# define transformations for train\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=.40),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\n# define transformations for test\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\n# define training dataloader\ndef get_training_dataloader(train_transform, batch_size=128, num_workers=0, shuffle=True):\n    \"\"\" return training dataloader\n    Args:\n        train_transform: transfroms for train dataset\n        path: path to cifar100 training python dataset\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n        shuffle: whether to shuffle \n    Returns: train_data_loader:torch dataloader object\n    \"\"\"\n\n    transform_train = train_transform\n    cifar10_training = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transform_train)\n    cifar10_training_loader = DataLoader(\n        cifar10_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n\n    return cifar10_training_loader\n\n# define test dataloader\ndef get_testing_dataloader(test_transform, batch_size=128, num_workers=0, shuffle=True):\n    \"\"\" return training dataloader\n    Args:\n        test_transform: transforms for test dataset\n        path: path to cifar100 test python dataset\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n        shuffle: whether to shuffle \n    Returns: cifar100_test_loader:torch dataloader object\n    \"\"\"\n\n    transform_test = test_transform\n    cifar10_test = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transform_test)\n    cifar10_test_loader = DataLoader(cifar10_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n\n    return cifar10_test_loader","6062cc03":"# get dataloaders for training and testing datasets\n# don't forget to turn on internet in kernel's settings\ntrainloader = get_training_dataloader(train_transform)\ntestloader = get_testing_dataloader(test_transform)","be0a0614":"# specify the names of the classes\nclasses_dict = {0 : 'airplane', 1 : 'automobile', 2: 'bird', 3 : 'cat', 4 : 'deer', 5: 'dog', 6:'frog', 7 : 'horse', 8 : 'ship', 9 : 'truck'}","5fa38420":"# plot 25 random images from training dataset\nfig, axs = plt.subplots(5, 5, figsize=(10,10))\n    \nfor batch_idx, (inputs, labels) in enumerate(trainloader):\n    for im in range(25):\n        image = inputs[im].permute(1, 2, 0)\n        i = im \/\/ 5\n        j = im % 5\n        axs[i,j].imshow(image.numpy()) #plot the data\n        axs[i,j].axis('off')\n        axs[i,j].set_title(classes_dict[int(labels[im].numpy())])\n        \n    break;\n\n# set suptitle\nplt.suptitle('CIFAR-10 Images')\nplt.show()","fdf185df":"#\"\"\"Bottleneck layers. Although each layer only produces k\n#output feature-maps, it typically has many more inputs. It\n#has been noted in [37, 11] that a 1\u00d71 convolution can be in-\n#troduced as bottleneck layer before each 3\u00d73 convolution\n#to reduce the number of input feature-maps, and thus to\n#improve computational efficiency.\"\"\"\nclass Bottleneck(nn.Module):\n    def __init__(self, in_channels, growth_rate):\n        super().__init__()\n        #\"\"\"In  our experiments, we let each 1\u00d71 convolution \n        #produce 4k feature-maps.\"\"\"\n        inner_channel = 4 * growth_rate\n\n        #\"\"\"We find this design especially effective for DenseNet and \n        #we refer to our network with such a bottleneck layer, i.e., \n        #to the BN-ReLU-Conv(1\u00d71)-BN-ReLU-Conv(3\u00d73) version of H ` , \n        #as DenseNet-B.\"\"\"\n        self.bottle_neck = nn.Sequential(\n            nn.BatchNorm2d(in_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels, inner_channel, kernel_size=1, bias=False),\n            nn.BatchNorm2d(inner_channel),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(inner_channel, growth_rate, kernel_size=3, padding=1, bias=False)\n        )\n\n    def forward(self, x):\n        return torch.cat([x, self.bottle_neck(x)], 1)\n\n#\"\"\"We refer to layers between blocks as transition\n#layers, which do convolution and pooling.\"\"\"\nclass Transition(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        #\"\"\"The transition layers used in our experiments \n        #consist of a batch normalization layer and an 1\u00d71 \n        #convolutional layer followed by a 2\u00d72 average pooling \n        #layer\"\"\".\n        self.down_sample = nn.Sequential(\n            nn.BatchNorm2d(in_channels),\n            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            nn.AvgPool2d(2, stride=2)\n        )\n\n    def forward(self, x):\n        return self.down_sample(x)\n\n#DesneNet-BC\n#B stands for bottleneck layer(BN-RELU-CONV(1x1)-BN-RELU-CONV(3x3))\n#C stands for compression factor(0<=theta<=1)\nclass DenseNet(nn.Module):\n    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_class=10):\n        super().__init__()\n        self.growth_rate = growth_rate\n\n        #\"\"\"Before entering the first dense block, a convolution \n        #with 16 (or twice the growth rate for DenseNet-BC) \n        #output channels is performed on the input images.\"\"\"\n        inner_channels = 2 * growth_rate\n\n        #For convolutional layers with kernel size 3\u00d73, each \n        #side of the inputs is zero-padded by one pixel to keep \n        #the feature-map size fixed.\n        self.conv1 = nn.Conv2d(3, inner_channels, kernel_size=3, padding=1, bias=False) \n\n        self.features = nn.Sequential()\n\n        for index in range(len(nblocks) - 1):\n            self.features.add_module(\"dense_block_layer_{}\".format(index), self._make_dense_layers(block, inner_channels, nblocks[index]))\n            inner_channels += growth_rate * nblocks[index]\n\n            #\"\"\"If a dense block contains m feature-maps, we let the \n            #following transition layer generate \u03b8m output feature-\n            #maps, where 0 < \u03b8 \u2264 1 is referred to as the compression \n            #fac-tor.\n            out_channels = int(reduction * inner_channels) # int() will automatic floor the value\n            self.features.add_module(\"transition_layer_{}\".format(index), Transition(inner_channels, out_channels))\n            inner_channels = out_channels\n\n        self.features.add_module(\"dense_block{}\".format(len(nblocks) - 1), self._make_dense_layers(block, inner_channels, nblocks[len(nblocks)-1]))\n        inner_channels += growth_rate * nblocks[len(nblocks) - 1]\n        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n        self.features.add_module('activation', nn.ReLU(inplace=True))\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        self.linear = nn.Linear(inner_channels, num_class)\n\n    def forward(self, x):\n        output = self.conv1(x)\n        output = self.features(output)\n        output = self.avgpool(output)\n        output = output.view(output.size()[0], -1)\n        output = self.linear(output)\n        return output\n\n    def _make_dense_layers(self, block, in_channels, nblocks):\n        dense_block = nn.Sequential()\n        for index in range(nblocks):\n            dense_block.add_module('bottle_neck_layer_{}'.format(index), block(in_channels, self.growth_rate))\n            in_channels += self.growth_rate\n        return dense_block\n\ndef densenet121(activation = 'relu'):\n    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n\ndef densenet169(activation = 'relu'):\n    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32)\n\ndef densenet201(activation = 'relu'):\n    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\n\ndef densenet161(activation = 'relu'):\n    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48)","c2b9cb04":"# number of epochs\nepochs = 50\n# learning rate\nlearning_rate = 0.001\n# device to use\n# don't forget to turn on GPU on kernel's settings\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\ndevice","b98f79ec":"model = densenet121()","6331e5ec":"# set loss function\ncriterion = nn.CrossEntropyLoss()\n\n# set optimizer, only train the classifier parameters, feature parameters are frozen\noptimizer = Adam(model.parameters(), lr=learning_rate)","ef3b3d40":"train_stats = pd.DataFrame(columns = ['Epoch', 'Time per epoch', 'Avg time per step', 'Train loss', 'Train accuracy', 'Train top-3 accuracy','Test loss', 'Test accuracy', 'Test top-3 accuracy']) ","99db584c":"#train the model\nmodel.to(device)\n\nsteps = 0\nrunning_loss = 0\nfor epoch in range(epochs):\n    \n    since = time.time()\n    \n    train_accuracy = 0\n    top3_train_accuracy = 0 \n    for inputs, labels in trainloader:\n        steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        \n        # calculate train top-1 accuracy\n        ps = torch.exp(logps)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == labels.view(*top_class.shape)\n        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n        \n        # Calculate train top-3 accuracy\n        np_top3_class = ps.topk(3, dim=1)[1].cpu().numpy()\n        target_numpy = labels.cpu().numpy()\n        top3_train_accuracy += np.mean([1 if target_numpy[i] in np_top3_class[i] else 0 for i in range(0, len(target_numpy))])\n        \n    time_elapsed = time.time() - since\n    \n    test_loss = 0\n    test_accuracy = 0\n    top3_test_accuracy = 0\n    model.eval()\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            logps = model.forward(inputs)\n            batch_loss = criterion(logps, labels)\n\n            test_loss += batch_loss.item()\n\n            # Calculate test top-1 accuracy\n            ps = torch.exp(logps)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(*top_class.shape)\n            test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            \n            # Calculate test top-3 accuracy\n            np_top3_class = ps.topk(3, dim=1)[1].cpu().numpy()\n            target_numpy = labels.cpu().numpy()\n            top3_test_accuracy += np.mean([1 if target_numpy[i] in np_top3_class[i] else 0 for i in range(0, len(target_numpy))])\n\n    print(f\"Epoch {epoch+1}\/{epochs}.. \"\n          f\"Time per epoch: {time_elapsed:.4f}.. \"\n          f\"Average time per step: {time_elapsed\/len(trainloader):.4f}.. \"\n          f\"Train loss: {running_loss\/len(trainloader):.4f}.. \"\n          f\"Train accuracy: {train_accuracy\/len(trainloader):.4f}.. \"\n          f\"Top-3 train accuracy: {top3_train_accuracy\/len(trainloader):.4f}.. \"\n          f\"Test loss: {test_loss\/len(testloader):.4f}.. \"\n          f\"Test accuracy: {test_accuracy\/len(testloader):.4f}.. \"\n          f\"Top-3 test accuracy: {top3_test_accuracy\/len(testloader):.4f}\")\n\n    train_stats = train_stats.append({'Epoch': epoch, 'Time per epoch':time_elapsed, 'Avg time per step': time_elapsed\/len(trainloader), 'Train loss' : running_loss\/len(trainloader), 'Train accuracy': train_accuracy\/len(trainloader), 'Train top-3 accuracy':top3_train_accuracy\/len(trainloader),'Test loss' : test_loss\/len(testloader), 'Test accuracy': test_accuracy\/len(testloader), 'Test top-3 accuracy':top3_test_accuracy\/len(testloader)}, ignore_index=True)\n\n    running_loss = 0\n    model.train()","bb47400b":"train_stats.to_csv('train_log_DenseNet121.csv')","4d88f81b":"fig = plt.figure(figsize=(10,7))\nax = plt.axes()\n\nplt.title(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\");\n\nx = range(1, len(train_stats['Train loss'].values) + 1)\nax.plot(x, train_stats['Train loss'].values, '-g', label='train loss');\nax.plot(x, train_stats['Test loss'].values, '-b', label='test loss');\n\nplt.legend()","aee55b1e":"fig = plt.figure(figsize=(10,7))\nax = plt.axes()\n\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\");\n\nx = range(1, len(train_stats['Train accuracy'].values) + 1)\nax.plot(x, train_stats['Train accuracy'].values, '-g', label='train accuracy');\nax.plot(x, train_stats['Test accuracy'].values, '-b', label='test accuracy');\n\nplt.legend()","533efe03":"def view_classify(img, ps, title):\n    \"\"\"\n    Function for viewing an image and it's predicted classes\n    with matplotlib.\n\n    INPUT:\n        img - (tensor) image file\n        ps - (tensor) predicted probabilities for each class\n        title - (str) string with true label\n    \"\"\"\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    image = img.permute(1, 2, 0)\n    ax1.imshow(image.numpy())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(list(classes_dict.values()), size='small');\n    ax2.set_title(title)\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    plt.show()","3c5c8580":"for batch_idx, (inputs, labels) in enumerate(testloader):\n    inputs, labels = inputs.to(device), labels.to(device)\n    img = inputs[0]\n    label_true = labels[0]\n    ps = model(inputs)\n    view_classify(img.cpu(), torch.softmax(ps[0].cpu(), dim=0), classes_dict[int(label_true.cpu().numpy())])\n    \n    break;","f6387d32":"## Load Data\n\nFor loading the dataset I will use Torchvision CIFAR-10 dataset and PyTorch dataloaders. I will also define train and test transformations using PyTorch transforms.","c13fc922":"## Analyze Training Log\nPlot test and train accuracy and test and train loss:","273b4df9":"Run this code to train the model:","93db1eb4":"## Credits\n1. [GitHub repo](https:\/\/github.com\/weiaicunzai\/pytorch-cifar100) with DenseNet implementation for PyTorch.","a57c36c2":"## Train Model\nSetup training parameters:","ad4351a1":"View some random images from the training dataset:","1dee696b":"## Conclusion\nUsing DenseNet I managed to achive about 90% accuracy on test dataset.","0c99d6fe":"# Classifying CIFAR-10 Images with DenseNet and PyTorch\n\n## Introduction\nThe [CIFAR-10 dataset](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n\nThe dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n\nIn this kernel I will try to classify images from this dataset using [DenseNet](https:\/\/arxiv.org\/abs\/1608.06993) neural networks architecture implemented with PyTorch. I used code for DenseNet implementation from this [GitHub repo](https:\/\/github.com\/weiaicunzai\/pytorch-cifar100).\n\nI will download CIFAR-10 dataset directly from Torchvision.","a18339a4":"I will use DenseNet model implemented [in this repository](https:\/\/github.com\/weiaicunzai\/pytorch-cifar100):","4575e929":"## Build Model","a0e49388":"Initialize loss function and optimizer:","c5f7944c":"## Use Model to Classify Images\nUse the model to classify the images from the training set and visualize prediction:","c5157dfa":"Initialize the model:","5306ac49":"Save training log to a csv file:"}}