{"cell_type":{"2eb404bf":"code","4c4d8d90":"code","f5acfb1c":"code","fc38cfcf":"code","afcc44e0":"code","b53955c7":"code","d1e41403":"code","799defef":"code","08fd3994":"code","9d9dbdfc":"code","0770943f":"code","0d4e4cae":"code","6278b45e":"code","47d65be1":"code","587dc3f2":"code","d5d203a7":"code","d2928e11":"markdown","a9f52bca":"markdown","29c4a421":"markdown","6ca1008f":"markdown","cb28ea10":"markdown","beba0240":"markdown","5ec421e8":"markdown","9876e1d1":"markdown","0baac369":"markdown","f7e1a4ee":"markdown","51047e65":"markdown"},"source":{"2eb404bf":"!pip install -U lightautoml","4c4d8d90":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task","f5acfb1c":"N_THREADS = 4\nN_FOLDS = 5\nRANDOM_STATE = 42\nTIMEOUT = 72000\nTARGET_NAME = 'pressure'","fc38cfcf":"# for reproducibility\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","afcc44e0":"train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsample_sub = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","b53955c7":"print(train.shape)\ntrain.head()","d1e41403":"print(test.shape)\ntest.head()","799defef":"!cp -r ..\/input\/googlebrainbilstm\/bilstm_test.csv .\/","08fd3994":"train_bilstm = pd.read_csv('..\/input\/googlebrainbilstm\/bilstm_train.csv')\ntest_bilstm = pd.read_csv('..\/input\/googlebrainbilstm\/bilstm_test.csv')\n\ntrain['bilstm_pred'] = train_bilstm['pressure']\ntest['bilstm_pred'] = test_bilstm['pressure']","9d9dbdfc":"del train_bilstm, test_bilstm","0770943f":"task = Task('reg', loss='mae', metric='mae')","0d4e4cae":"roles = {\n    'drop': 'id',\n    'group': 'breath_id', # for group k-fold\n    'category': ['R', 'C'],\n    'target': TARGET_NAME\n}","6278b45e":"%%time\nautoml = TabularAutoML(task=task, \n                       timeout=TIMEOUT,\n                       cpu_limit=N_THREADS,\n                       reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                       general_params={'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       tuning_params={'max_tuning_time': 1800}\n                      )\noof_pred = automl.fit_predict(train, roles=roles)","47d65be1":"# Prediction\ntest_pred = automl.predict(test)\nsample_sub[TARGET_NAME] = test_pred.data[:, 0]","587dc3f2":"sample_sub.head()","d5d203a7":"sample_sub.to_csv('submission.csv', index=False)","d2928e11":"Here we setup the constants to use in the kernel:\n\n- `N_THREADS` - number of vCPUs for LightAutoML model creation\n- `N_FOLDS` - number of folds in LightAutoML inner CV\n- `RANDOM_STATE` - random seed for better reproducibility\n- `TIMEOUT` - limit in seconds for model to train\n- `TARGET_NAME` - target column name in dataset","a9f52bca":"## LightAutoML installation","29c4a421":"## Import libraries","6ca1008f":"### Feature roles setup\n\nTo solve the task, we need to setup columns roles. The only role you must setup is target role, everything else (drop, numeric, categorical, group, weights etc.) is up to user - LightAutoML models have automatic columns typization inside:","cb28ea10":"### Task setup\n\nOn the cell below we create Task object - the class to setup what task LightAutoML model should solve with specific loss and metric if necessary (more info can be found [here](https:\/\/lightautoml.readthedocs.io\/en\/latest\/generated\/lightautoml.tasks.base.Task.html#lightautoml.tasks.base.Task) in our documentation):","beba0240":"### LightAutoML model creation - TabularAutoML preset\n\nIn next the cell we are going to create LightAutoML model with `TabularAutoML` class - preset with default model structure like in the image below:\n\n![LightAutoML model](https:\/\/raw.githubusercontent.com\/sberbank-ai-lab\/LightAutoML\/master\/imgs\/tutorial_blackbox_pipeline.png \"LightAutoML model\")\n\nin just several lines. Let's discuss the params we can setup:\n\n- `task` - the type of the ML task (the only must have parameter)\n- `timeout` - time limit in seconds for model to train\n- `cpu_limit` - vCPU count for model to use\n- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc. For example, we setup `n_jobs` threads for typization algo, `cv` folds and `random_state` as inside CV seed.\n- `general_params` - we use `use_algos` key to setup the model structure to work with (Linear and LGBM model on the first level and their weighted composition creation on the second). This setup is only to speedup the kernel, you can remove this `general_params` setup if you want the whole LightAutoML model to run.","5ec421e8":"## Add a bidirectional LSTM feature\n\nI copied [Improvement base on Tensor Bidirect LSTM (0.173)](https:\/\/www.kaggle.com\/kensit\/improvement-base-on-tensor-bidirect-lstm-0-173) and created a bidirectional LSTM feature. My copy (score: 0.161) is [here](https:\/\/www.kaggle.com\/tsano430\/improvement-base-on-tensor-bidirect-lstm-0-173\/data).","9876e1d1":"## Create submission file","0baac369":"## Data loading","f7e1a4ee":"## LightAutoML model building","51047e65":"## References\n\n- https:\/\/www.kaggle.com\/alexryzhkov\/lightautoml-continuer\n- https:\/\/lightautoml.readthedocs.io\/en\/latest\/\n- https:\/\/www.kaggle.com\/kensit\/improvement-base-on-tensor-bidirect-lstm-0-173"}}