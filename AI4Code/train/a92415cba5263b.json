{"cell_type":{"35af6abb":"code","dfa6123f":"code","56304013":"code","3426a3d9":"code","31d5e2ef":"code","af667b78":"code","02aa2914":"code","998a60b4":"code","1e660616":"code","ccef3a79":"code","e656d991":"code","800f2bd1":"code","58edd1c9":"code","0d8216ba":"code","ff7f2760":"code","a6eaf5de":"code","37550d04":"markdown","9a9902d6":"markdown","f3a5f685":"markdown","e0e97018":"markdown","51546aae":"markdown","83ac81b3":"markdown","13392e62":"markdown","d781c0a2":"markdown","2059826a":"markdown","0acbde9f":"markdown","67378b1d":"markdown","97b1eae9":"markdown","bef26929":"markdown","aa79deb9":"markdown","64fd2ec3":"markdown","04082169":"markdown","ed46e26d":"markdown"},"source":{"35af6abb":"#Importing Library\nimport torch\nimport numpy as np","dfa6123f":"#tuples\nlst = ([1,2],[2,3])\nprint(lst)\nprint(type(lst))","56304013":"#tuples --> tensor\nl = torch.tensor(lst)\nprint(l)\nprint(type(l))","3426a3d9":"#Numpy --> tensor\nl1 = torch.tensor(np.array([1,2,3,4,5]))\nprint(l1)\nprint(type(l1))","31d5e2ef":"#Tensor to Numpy\nl2 = l1.numpy()\nprint(l2)\nprint(type(l2))","af667b78":"#Other Tensor Formates\nprint(\"Empty Tensor    :\",torch.tensor([]))\nprint(\"Float Tensor    :\",torch.tensor([1,2,3],dtype=torch.float))","02aa2914":"print(\"Torch of Ones  :\\n\",torch.ones(3,3))\nprint(\"\\nTorch of Zeros :\\n\",torch.zeros(3,2))\nprint(\"\\nTorch of Randomn Number :\\n\",torch.rand(2,3))\nprint(\"\\nTorch with Range of Number :\\n\",torch.arange(1,5))\nprint(\"\\nTorch with Linespace of Number :\\n\",torch.linspace(1,10,6))\nprint(\"\\nTorch with Identity Matrix :\\n\",torch.eye(3))\nprint(\"\\nTorch with complete Matrix :\\n\",torch.full((2,3),3))","998a60b4":"l = torch.arange(8)\nv = l.view(2,4)\nr = l.reshape(4,2)\nprint(\"A tensor of range 7 : \", l)\nprint(\"\\nWhen we use view    \\n\",v)\nprint(\"\\nWhen we use Reshape \\n\",r)\nprint(\"\\nFind value in tensor using index of value  :  \",v[1,3].item())\nprint(\"\\nFind value in tensor using index of value  :  \",r[2,0].item())","1e660616":"# slicing\nprint(\"slicing the tensor  :\",l[2:6])\nprint(\"slicing the tensor  :\",l[:4])","ccef3a79":"x = torch.ones(3,2)\ny = torch.full((3,2),3)\nprint(\"Tensors of Ones   ,x :\\n\",x)\nprint(\"\\nTensors of Full ,y :\\n\",y)","e656d991":"print(\"Addition of Tensors      , x+y :\\n\",x+y)\nprint(\"\\nSubtraction of Tensors   , x-y :\\n\",x-y)\nprint(\"\\nMultiplication of Tensors, x*y :\\n\",x*y)\nprint(\"\\nDivition of Tensors      , x\/y :\\n\",x\/y)","800f2bd1":"# IS cuda available in your Device\nprint(\"IS cuda available in your Device  ?  : \",torch.cuda.is_available())\nprint(\"Count of Available CUDA Device       : \",torch.cuda.device_count())\nprint(\"Available Device Name                : \",torch.cuda.get_device_name())","58edd1c9":"#object for cuda device\ncuda0 = torch.device('cuda:0')\nprint(\"Device used in this  :  \",type(cuda0))\nprint(\"\\nSample torch with GPU device  :\\n\",torch.ones(2,2,device =cuda0))","0d8216ba":"%%time\nfor i in range(1000):\n  x = np.random.randn(100,100)\n  y = np.random.randn(100,100)\n  z = x*y","ff7f2760":"%%time\nfor i in range(1000):\n  x = torch.randn(100,100)\n  y = torch.randn(100,100)\n  z = x*y","a6eaf5de":"%%time\nfor i in range(100):\n  x = torch.randn(1000,1000,device = cuda0)\n  y = torch.randn(1000,1000,device =cuda0)\n  z = x*y","37550d04":"#### Numpy","9a9902d6":"### In this, we are going to use Pytorch as Numpy.","f3a5f685":"## Reshape & Slicing\n\nIt is almost similar to reshape & slice in List","e0e97018":"#### CPU Tensor","51546aae":"# PyTorch Tutorials\n\n\nPyTorch is the premier open-source deep learning framework developed and maintained by Facebook.\n\nAt its core, PyTorch is a mathematical library that allows you to perform efficient computation and automatic differentiation on graph-based models. Achieving this directly is challenging, although thankfully, the modern PyTorch API provides classes and idioms that allow you to easily develop a suite of deep learning models.\n\n1. [PyTorch Tutorial - 1 (Basic)](https:\/\/www.kaggle.com\/anandsubbu007\/pytorch-basics-tutorial-1)\n2. [PyTorch Tutorial - 2 (Autograd)](https:\/\/www.kaggle.com\/anandsubbu007\/pytorch-autograd-tutorial-2)\n3. [PyTorch Tutorial - 3 (Deep Neural Network)](https:\/\/www.kaggle.com\/anandsubbu007\/deep-nn-pytorch-tutorial-3)\n4. [PyTorch Tutorial - 3 (CNN-CIFAR10)](https:\/\/www.kaggle.com\/anandsubbu007\/cnn-cifar10-pytorch-tutorial-4)","83ac81b3":"## Performance -  Numpy Vs CPU Tensors Vs GPU Tensors\n\nComputation Time","13392e62":"#### GPU Tensor","d781c0a2":"## Ways of creaing Tensor array","2059826a":"#### Reshape tensor (matrix)\n\nThere are two way to reshape the tensor using .view & .reshape\n\n* Tensor.view() works only on contiguous tensors and will never copy memory. It will raise an error on a non-contiguous tensor.\n* Tensor.reshape() will work on any tensor and can make a clone if it is needed.\n","0acbde9f":"<a href=\"https:\/\/colab.research.google.com\/github\/anandsubbu007\/Pytorch-Tutorial-Beginner\/blob\/master\/Pytorch_Basics_1.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","67378b1d":"# Scope of this Notebook","97b1eae9":"# Pytorch","bef26929":"# Pytorch Vs Numpy","aa79deb9":"Torch is around 4 times faster than numpy","64fd2ec3":"It\u2019s a Python based scientific computing package targeted at two sets of audiences:\n\n* Tensorial library that uses the power of GPUs\n* A deep learning research platform that provides maximum flexibility and speed","04082169":"## Mathematical Operation on Tensor","ed46e26d":"# CUDA\n\nCUDA is a parallel computing platform and application programming interface model created by Nvidia."}}