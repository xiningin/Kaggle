{"cell_type":{"ba7c1088":"code","1b7d631f":"code","fec0904f":"code","1ff4afab":"code","e1ac4fcd":"code","1988d837":"code","3c67ab96":"code","0ad7cf83":"code","1aa3bf38":"code","719afbea":"code","a082c3f6":"code","76eddf60":"code","19fd6d0e":"code","aaf0d4ee":"code","c1ee1e9c":"code","c6daee83":"code","003a3649":"code","092f1f3c":"code","13a59107":"code","b45a40d9":"code","70396802":"code","ffea227d":"code","ada68934":"code","858c2d7a":"code","d3f094b6":"code","3f176056":"code","80467dd8":"code","a9ba47c6":"code","dc7fe5e8":"code","19b85d09":"code","43879b29":"code","6fcda883":"code","a03f078a":"code","4729fff5":"code","9547d36f":"code","fe419c32":"code","a14d6e24":"code","6b547aef":"code","9ebd6f0d":"code","33031fc3":"code","9d0f4838":"code","a8e1b426":"code","6b9e0e64":"code","89842656":"code","5410041d":"code","e901f3b4":"code","ec9d4227":"code","c177a9c2":"code","e5d7da6d":"code","d0f5d12b":"code","7b736c5c":"code","6eeac056":"code","0bb353c9":"code","e3c3574c":"code","8d726853":"code","a15538f7":"code","0ef7b3b7":"code","df9c0f8e":"code","d637b56e":"code","b2ab2adb":"code","b30ff345":"code","4464455f":"code","0617e745":"code","324fdeb9":"code","1887483c":"code","ebdacab2":"code","2719702d":"code","a084b3ef":"code","57c77387":"code","716063b2":"code","a003626d":"code","5defe1f6":"code","2522eb60":"code","4b12a694":"code","4a227e42":"code","4a907f04":"code","c662aae2":"code","d06be542":"code","8516fe95":"code","780b31c4":"code","5b3c38f7":"code","6f6bd480":"code","be3af1b0":"code","57b1de48":"markdown","92f1c9ce":"markdown","cf8b792c":"markdown","bf3009e3":"markdown","830f9617":"markdown","b4d3356a":"markdown","8894c1fc":"markdown","566b38e1":"markdown","3153b161":"markdown","724f93dc":"markdown","467beb95":"markdown","5366533e":"markdown","b0f0c133":"markdown","9ca2a034":"markdown","31c7ce3f":"markdown","d2e3cbd2":"markdown","89c7adea":"markdown","84ae718e":"markdown","7249cd7a":"markdown","e64693a3":"markdown","ea498fd5":"markdown","6879fa50":"markdown","4caae814":"markdown","0b176fc3":"markdown","a498135f":"markdown","8db85121":"markdown","7ffbaa15":"markdown","3c5e16cb":"markdown","e978a923":"markdown","036dbbad":"markdown","451c9f09":"markdown","fab45c7a":"markdown","0dff18a8":"markdown","5f081fde":"markdown","33c5d967":"markdown","c913cec6":"markdown","ca7ce7f4":"markdown","97b3cf9a":"markdown","7e3adb8e":"markdown","52a7dfdf":"markdown","40dac385":"markdown","ec8e7261":"markdown","ce3275a2":"markdown","71834c40":"markdown","f99a91fc":"markdown","c08b2747":"markdown","43af8c7b":"markdown","1f3f7951":"markdown","1bff1f07":"markdown","a75582c9":"markdown","0b7bff75":"markdown","fb84200e":"markdown"},"source":{"ba7c1088":"# Setting Up\n\nimport os\nimport random\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\n\nfrom lightgbm import LGBMClassifier\n\nfrom mlxtend.classifier import StackingCVClassifier\n\nfrom matplotlib import pyplot as plt\n\nfrom plotly import express as px\n\nfrom sklearn.ensemble import AdaBoostClassifier, IsolationForest, RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\n\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\nrandom_state = 1\nrandom.seed(random_state)\nnp.random.seed(random_state)","1b7d631f":"# Loading Data\n\ntrain = pd.read_csv('..\/input\/learn-together\/train.csv', index_col='Id')\ntest = pd.read_csv('..\/input\/learn-together\/test.csv', index_col='Id')\n\nX_train = train.drop('Cover_Type', axis='columns')\ny_train = train['Cover_Type']\n\nX_test = test.copy()","fec0904f":"numericals = sorted(col for col in X_train.columns if 'Soil_Type' not in col and 'Wilderness_Area' not in col)\n\nX_train['Soil_Type'] = sum(i * X_train['Soil_Type{}'.format(i)] for i in range(1, 41))\nX_train['Wilderness_Area'] = sum(i * X_train['Wilderness_Area{}'.format(i)] for i in range(1, 5))","1ff4afab":"plot_features = ['Horizontal_Distance_To_Hydrology', \n                 'Horizontal_Distance_To_Roadways', \n                 'Horizontal_Distance_To_Fire_Points']\n\ncolors = sns.color_palette('deep')\nsample = train.copy()\n\nfor cover in [1,2,3,4,5,6,7]:\n    rest = list(set([1,2,3,4,5,6,7]) - set([cover]))\n    \n    sample['Cover_Type'] = train['Cover_Type'].copy()\n    sample['Cover_Type'] = sample['Cover_Type'].replace(rest, 0)\n    \n    fig = plt.figure(figsize=(16, 12))\n    palette = ['lavender', colors[cover]]\n    \n    for i in range(3):\n        fig.add_subplot(3, 3, i+1)\n        ax = sns.scatterplot(x='Elevation', \n                             y=plot_features[i], \n                             data=sample, \n                             hue='Cover_Type',\n                             marker='+',\n                             palette=palette)\n\n    plt.tight_layout()\n    plt.show()","e1ac4fcd":"plot_features = ['Horizontal_Distance_To_Hydrology', \n                 'Horizontal_Distance_To_Roadways', \n                 'Horizontal_Distance_To_Fire_Points']\n\ncolors = sns.color_palette('deep')\nclass_pairs = [(a, b) for a in range(1, 8) for b in range(a+1, 8)]\n\nfor a, b in class_pairs:\n    sample = train[(train['Cover_Type'] == a) | (train['Cover_Type'] == b)]\n    \n    fig = plt.figure(figsize=(16, 12))\n    palette = list(colors[i] for i in [a, b])\n    \n    for i in range(3):\n        fig.add_subplot(3, 3, i+1)\n        ax = sns.scatterplot(x='Elevation', \n                             y=plot_features[i],\n                             data=sample, \n                             hue='Cover_Type', \n                             marker='+',\n                             palette=palette)\n\n    plt.tight_layout()\n    plt.show()","1988d837":"# Get data for a Wilderness_Area\n\ndef get_wa_data(wa, X, y=None):\n    X_wa = X[X['Wilderness_Area{}'.format(wa)] == 1]\n    \n    if y is not None:\n        y_wa = y.loc[X_wa.index]\n        return X_wa, y_wa\n    \n    return X_wa, _","3c67ab96":"fig = plt.figure(figsize=(16, 20))\n\nfor wa in range(1, 5):\n    X_wa, y_wa = get_wa_data(wa, X_train, y_train)\n    \n    soil_covers = pd.crosstab(X_wa['Soil_Type'], y_wa)\n    \n    missing_soils = set(range(1, 41)) - set(soil_covers.index)\n          \n    for soil in missing_soils:\n        soil_covers.loc[soil] = 0\n    \n    soil_covers = soil_covers.sort_index()\n    \n    fig.add_subplot(1, 4, wa)\n    ax = sns.heatmap(soil_covers, annot=True, cmap='BuPu', fmt='d',\n                     xticklabels=soil_covers.columns, yticklabels=soil_covers.index, \n                     cbar_kws={'fraction':0.03}) \n    ax.set(xlabel='Cover Type', ylabel='Soil Type', title='Wilderness Area {}'.format(wa))\n    ax.xaxis.tick_top()\n    ax.xaxis.set_label_position('top')\n\nplt.tight_layout()\nplt.show()","0ad7cf83":"for feature in numericals:\n    fig = plt.figure(figsize=(16, 4))\n    ax = sns.boxplot(x='Soil_Type', y=feature, data=X_train)\n    plt.tight_layout()\n    plt.show()","1aa3bf38":"def plot_correlations(X, y=None, label=False):\n    numericals = [col for col in X.columns if \n                  'Soil_Type' not in col and \n                  'Wilderness_Area' not in col]\n\n    numericals = sorted(numericals)\n    \n    if y is None:\n        corr = X[numericals].corr()\n        \n    else:\n        # Optional target correlations\n        X_cl = X[numericals].copy()\n        classes = sorted(y.unique().tolist())\n        \n        for cl in classes:\n            y_cl = (y==cl).astype(np.uint8).rename('Cover_Type' + str(cl))\n            X_cl = pd.concat([X_cl, y_cl], axis='columns')\n            \n        corr = X_cl.corr()\n        \n    corr = np.around(corr, 1)\n    \n    # Place correlations in four bins\n    corr_bin = corr.abs()\n    corr_bin = corr_bin.where(corr_bin > 0.30, 0.0)\n\n    corr_bin = corr_bin.where((corr_bin <= 0.30) | \n                              (corr_bin > 0.50), 0.50)\n\n    corr_bin = corr_bin.where((corr_bin <= 0.50) | \n                              (corr_bin > 0.70), 0.70)\n\n    corr_bin = corr_bin.where(corr_bin <= 0.70, 1.0)\n    \n    # Show binned correlation plot\n    annot = corr if label else False\n        \n    fig = plt.figure(figsize=(12, 12))\n    ax = sns.heatmap(corr_bin, annot=annot, linewidths=1, square=True,\n                     cmap='BuPu', cbar_kws={'shrink':0.5})\n    plt.show()","719afbea":"plot_correlations(X_train, y_train, label=True)","a082c3f6":"fig = plt.figure(figsize=(14, 12))\n\nfig.add_subplot(331)\nsns.regplot(x='Hillshade_9am', y='Hillshade_3pm', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(332)\nsns.regplot(x='Hillshade_9am', y='Aspect', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(333)\nsns.regplot(x='Hillshade_Noon', y='Slope', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(334)\nsns.regplot(x='Hillshade_Noon', y='Hillshade_3pm', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(335)\nsns.regplot(x='Aspect', y='Hillshade_3pm', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(336)\nsns.regplot(x='Elevation', y='Horizontal_Distance_To_Roadways', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(337)\nsns.regplot(x='Horizontal_Distance_To_Fire_Points', y='Horizontal_Distance_To_Roadways', data=X_train, scatter_kws={'alpha':0.05})\n\nfig.add_subplot(338)\nsns.regplot(x='Horizontal_Distance_To_Hydrology', y='Vertical_Distance_To_Hydrology', data=X_train, scatter_kws={'alpha':0.05})\n\nplt.tight_layout()\nplt.show()","76eddf60":"area_covers = pd.crosstab(y_train, X_train['Wilderness_Area'])\n\n\nfig = plt.figure(figsize=(8, 7))\nax = sns.heatmap(area_covers, annot=True, cmap='BuPu', fmt='d', square=True,\n                 xticklabels=area_covers.columns, yticklabels=area_covers.index,\n                 cbar_kws={'fraction':0.05})\nax.set(ylabel='Cover Type', xlabel='Wilderness Area')\nax.xaxis.tick_top()\nax.xaxis.set_label_position('top')\nplt.show()","19fd6d0e":"# Plot feature distribution by Wilderness_Area\n\ndef plot_distribution_wa(X, feature):\n    fig = plt.figure(figsize=(16, 3))\n    \n    for wa in range(1, 5):\n        fig.add_subplot(1, 4, wa)\n        \n        wilderness_area = 'Wilderness_Area{}'.format(wa)\n        feature_wa = X[feature][X[wilderness_area] == 1]\n        ax = sns.distplot(feature_wa)\n        ax.set(title=wilderness_area)\n\n    plt.tight_layout()\n    plt.show()\n    \n    \n# Plot feature distribution by Wilderness_Area and Cover_Type\n\ndef plot_distribution_wa_ct(X, y, feature):\n    fig = plt.figure(figsize=(16, 3))\n    colors = sns.color_palette('deep')\n    \n    for wa in range(1, 5):\n        fig.add_subplot(1, 4, wa)\n        \n        wilderness_area = 'Wilderness_Area{}'.format(wa)\n        cover_type_wa = y[X[wilderness_area] == 1]\n\n        ctypes = sorted(cover_type_wa.unique().tolist())\n        \n        for ct in ctypes:\n            feature_wa_ct = X[feature][(X[wilderness_area] == 1) & (y == ct)]\n            ax = sns.kdeplot(feature_wa_ct, color=colors[ct-1], shade=False, label=ct)\n        ax.legend()\n        ax.set(title=wilderness_area)\n\n    plt.tight_layout()\n    plt.show()\n  \n    \n# Plot feature boxplots by Wilderness_Area and Cover_Type\n\ndef boxplot_wa_ct(X, y, feature):\n    fig = plt.figure(figsize=(16, 4))\n    colors = sns.color_palette('deep')\n    palette = dict((ct, colors[ct-1]) for ct in range(1, 8))\n    \n    ax_min = X[feature].min() - 5\n    ax_max = X[feature].max() + 5\n    \n    for wa in range(1, 5):\n        fig.add_subplot(1, 4, wa)\n        \n        wilderness_area = 'Wilderness_Area{}'.format(wa)\n        feature_wa = X[feature][X[wilderness_area] == 1]\n        cover_type_wa = y[X[wilderness_area] == 1]\n\n        ax = sns.boxplot(x=cover_type_wa, y=feature_wa, palette=palette)\n        ax.set(ylim=(ax_min, ax_max), title=wilderness_area)\n\n    plt.tight_layout()\n    plt.show()\n\n    \n# Plot feature distributions, violinplots and boxplots\n\ndef plot_wa_graphs(X, y, feature):\n    plot_distribution_wa(X, feature)\n#     plot_distribution_wa_ct(X, y, feature)\n    boxplot_wa_ct(X, y, feature)","aaf0d4ee":"plot_wa_graphs(X_train, y_train, 'Elevation')","c1ee1e9c":"plot_wa_graphs(X_train, y_train, 'Aspect')","c6daee83":"plot_wa_graphs(X_train, y_train, 'Slope')","003a3649":"plot_wa_graphs(X_train, y_train, 'Horizontal_Distance_To_Hydrology')","092f1f3c":"plot_wa_graphs(X_train, y_train, 'Vertical_Distance_To_Hydrology')","13a59107":"plot_wa_graphs(X_train, y_train, 'Horizontal_Distance_To_Roadways')","b45a40d9":"plot_wa_graphs(X_train, y_train, 'Hillshade_9am')","70396802":"plot_wa_graphs(X_train, y_train, 'Hillshade_Noon')","ffea227d":"plot_wa_graphs(X_train, y_train, 'Hillshade_3pm')","ada68934":"plot_wa_graphs(X_train, y_train, 'Horizontal_Distance_To_Fire_Points')","858c2d7a":"clf = RandomForestClassifier(n_estimators=100,\n                             random_state=random_state,\n                             n_jobs=-1)","d3f094b6":"# Plot feature importances by Wilderness_Area\n\ndef plot_importances_wa(clf, X, y):\n    importances = pd.DataFrame()\n    for wa in range(1, 5):\n        X_wa, y_wa = get_wa_data(wa, X, y)\n        \n        if wa == 1:\n            importances = pd.DataFrame(columns=X_wa.columns)\n            \n        clf = clf.fit(X_wa, y_wa)\n        importances.loc[wa] = clf.feature_importances_\n    \n    fig = plt.figure(figsize=(16, 40))\n    ax_max = max(importances.max()) + 0.01\n    \n    for i, col in enumerate(importances.columns):\n        fig.add_subplot(15, 4, i+1)\n        ax = sns.barplot(x=[1,2,3,4], y=col, data=importances)\n        ax.set(xlabel='Wilderness Area', ylabel='Importance', title=col)\n        ax.set(ylim=(0, ax_max))\n    \n    plt.tight_layout()\n    plt.show()\n    \n    X_train = train.drop('Cover_Type', axis='columns')","3f176056":"X_train = train.drop('Cover_Type', axis='columns')\nplot_importances_wa(clf, X_train, y_train)","80467dd8":"def feature_importances(clf, X, y):\n    clf = clf.fit(X, y)\n    \n    importances = pd.DataFrame({'Features': X.columns, \n                                'Importances': clf.feature_importances_})\n    \n    importances.sort_values(by=['Importances'], axis='index', ascending=False, inplace=True)\n\n    fig = plt.figure(figsize=(14, 4))\n    sns.barplot(x='Features', y='Importances', data=importances)\n    plt.xticks(rotation='vertical')\n    plt.show()","a9ba47c6":"def cv_performance(clf, X, y):\n    # Get cross-validation scores\n    scores = []\n    predictions = pd.Series(dtype=y.dtype)\n\n    splits = StratifiedKFold(n_splits=5).split(X, y)\n\n    for trn_index, val_index in splits:\n        X_trn = X.iloc[trn_index, :]\n        y_trn = y.iloc[trn_index]\n\n        X_val = X.iloc[val_index, :]\n        y_val = y.iloc[val_index]\n\n        clf = clf.fit(X_trn, y_trn)\n        pred = clf.predict(X_val)\n        \n        pred = pd.Series(pred, index=y_val.index)\n        predictions = pd.concat([predictions, pred])\n\n        score = accuracy_score(y_val, pred)\n        scores.append(score)\n\n    predictions = predictions.sort_index()\n\n    print('Cross-validation accuracy: {:.3f} {}'.format(np.mean(scores), \n                                                        np.around(scores, 3)))\n    \n    # Plot confusion matrix\n    classes = sorted(y.unique().tolist())\n\n    conf_mat = confusion_matrix(y, predictions)\n    norm_conf_mat = np.around(conf_mat \/ conf_mat.sum(axis=1), 2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    fig.add_subplot(1, 2, 1)\n    ax = sns.heatmap(norm_conf_mat, annot=True, cmap='OrRd', \n                     xticklabels=classes, yticklabels=classes)\n    ax.set(xlabel='Predicted Class', ylabel='True Class', title='Normalized')\n\n\n    fig.add_subplot(1, 2, 2)\n    ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='OrRd', \n                     xticklabels=classes, yticklabels=classes)\n    ax.set(xlabel='Predicted Class', ylabel='True Class', title ='Counts')\n\n    plt.tight_layout()\n    plt.show()","dc7fe5e8":"cv_performance(clf, X_train, y_train)","19b85d09":"# https:\/\/www.kaggle.com\/jakelj\/basic-ensemble-model  (Some useful features)\n# https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/108575  (Feat Eng techniques)\n\ndef add_features(X_trn_, X_tst_):\n    X_trn = X_trn_.copy()\n    X_tst = X_tst_.copy()\n    \n    X = pd.concat([X_trn, X_tst])\n        \n    X['Aspect'] = X['Aspect'] % 360\n    X['Aspect_120'] = (X['Aspect'] + 120) % 360\n\n\n    X['Hydro_Elevation_sum'] = X[['Elevation',\n                                  'Vertical_Distance_To_Hydrology']\n                                 ].sum(axis='columns')\n    \n    X['Hydro_Elevation_diff'] = X[['Elevation',\n                                   'Vertical_Distance_To_Hydrology']\n                                  ].diff(axis='columns').iloc[:, [1]]\n\n    X['Hydro_Euclidean'] = np.sqrt(X['Horizontal_Distance_To_Hydrology']**2 +\n                                   X['Vertical_Distance_To_Hydrology']**2)\n\n    X['Hydro_Manhattan'] = (X['Horizontal_Distance_To_Hydrology'] +\n                            X['Vertical_Distance_To_Hydrology'].abs())\n    \n    \n    X['Hydro_Distance_sum'] = X[['Horizontal_Distance_To_Hydrology',\n                                 'Vertical_Distance_To_Hydrology']\n                                ].sum(axis='columns')\n\n    X['Hydro_Distance_diff'] = X[['Horizontal_Distance_To_Hydrology',\n                                  'Vertical_Distance_To_Hydrology']\n                                 ].diff(axis='columns').iloc[:, [1]]\n    \n    X['Hydro_Fire_sum'] = X[['Horizontal_Distance_To_Hydrology',\n                             'Horizontal_Distance_To_Fire_Points']\n                            ].sum(axis='columns')\n\n    X['Hydro_Fire_diff'] = X[['Horizontal_Distance_To_Hydrology',\n                              'Horizontal_Distance_To_Fire_Points']\n                             ].diff(axis='columns').iloc[:, [1]].abs()\n\n    X['Hydro_Fire_mean'] = X[['Horizontal_Distance_To_Hydrology',\n                              'Horizontal_Distance_To_Fire_Points']\n                             ].mean(axis='columns')\n\n    X['Hydro_Fire_median'] = X[['Horizontal_Distance_To_Hydrology',\n                                'Horizontal_Distance_To_Fire_Points']\n                               ].median(axis='columns')\n                               \n    X['Hydro_Road_sum'] = X[['Horizontal_Distance_To_Hydrology',\n                             'Horizontal_Distance_To_Roadways']\n                            ].sum(axis='columns')\n\n    X['Hydro_Road_diff'] = X[['Horizontal_Distance_To_Hydrology',\n                              'Horizontal_Distance_To_Roadways']\n                             ].diff(axis='columns').iloc[:, [1]].abs()\n\n    X['Hydro_Road_mean'] = X[['Horizontal_Distance_To_Hydrology',\n                              'Horizontal_Distance_To_Roadways']\n                             ].mean(axis='columns')\n\n    X['Hydro_Road_median'] = X[['Horizontal_Distance_To_Hydrology',\n                                'Horizontal_Distance_To_Roadways']\n                               ].median(axis='columns')\n    \n    X['Road_Fire_sum'] = X[['Horizontal_Distance_To_Roadways',\n                            'Horizontal_Distance_To_Fire_Points']\n                           ].sum(axis='columns')\n\n    X['Road_Fire_diff'] = X[['Horizontal_Distance_To_Roadways',\n                             'Horizontal_Distance_To_Fire_Points']\n                            ].diff(axis='columns').iloc[:, [1]].abs()\n\n    X['Road_Fire_mean'] = X[['Horizontal_Distance_To_Roadways',\n                             'Horizontal_Distance_To_Fire_Points']\n                            ].mean(axis='columns')\n\n    X['Road_Fire_median'] = X[['Horizontal_Distance_To_Roadways',\n                               'Horizontal_Distance_To_Fire_Points']\n                              ].median(axis='columns')\n    \n    X['Hydro_Road_Fire_mean'] = X[['Horizontal_Distance_To_Hydrology',\n                                   'Horizontal_Distance_To_Roadways',\n                                   'Horizontal_Distance_To_Fire_Points']\n                                  ].mean(axis='columns')\n\n    X['Hydro_Road_Fire_median'] = X[['Horizontal_Distance_To_Hydrology',\n                                     'Horizontal_Distance_To_Roadways',\n                                     'Horizontal_Distance_To_Fire_Points']\n                                    ].median(axis='columns')\n\n    \n    # Compute Soil_Type number from Soil_Type binary columns\n    X['Soil_Type'] = sum(i * X['Soil_Type{}'.format(i)] for i in range(1, 41))\n    \n    # For all 40 Soil_Types, 1=rubbly, 2=stony, 3=very stony, 4=extremely stony, 0=?\n    stoneyness = [4, 3, 1, 1, 1, 2, 0, 0, 3, 1, \n                  1, 2, 1, 0, 0, 0, 0, 3, 0, 0, \n                  0, 4, 0, 4, 4, 3, 4, 4, 4, 4, \n                  4, 4, 4, 4, 1, 4, 4, 4, 4, 4]\n    \n    # Replace Soil_Type number with \"stoneyness\" value\n    X['Stoneyness'] = X['Soil_Type'].replace(range(1, 41), stoneyness)\n    \n    rocks = [1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n             1, 1, 1, 0, 0, 0, 0, 0, 0, 0, \n             0, 1, 0, 0, 0, 0, 1, 1, 0, 1, \n             0, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n    \n    X['Rocks'] = X['Soil_Type'].replace(range(1, 41), rocks)\n    \n    soil_count = X['Soil_Type'].value_counts().to_dict()\n    X['Soil_count'] = X['Soil_Type'].map(soil_count)\n    \n    soil_elevations = X.groupby('Soil_Type')['Elevation'].median().to_dict()\n    X['Soil_Elevation'] = X['Soil_Type'].map(soil_elevations)\n    \n    soil_aspects = X.groupby('Soil_Type')['Aspect'].median().to_dict()\n    X['Soil_Aspect'] = X['Soil_Type'].map(soil_aspects)\n    \n    soil_slopes = X.groupby('Soil_Type')['Slope'].median().to_dict()\n    X['Soil_Slope'] = X['Soil_Type'].map(soil_slopes)\n    \n    soil_hhydros = X.groupby('Soil_Type')['Horizontal_Distance_To_Hydrology'].median().to_dict()\n    X['Soil_H_Hydro'] = X['Soil_Type'].map(soil_hhydros)\n    \n    soil_vhydros = X.groupby('Soil_Type')['Vertical_Distance_To_Hydrology'].median().to_dict()\n    X['Soil_V_Hydro'] = X['Soil_Type'].map(soil_vhydros)\n    \n    soil_roads = X.groupby('Soil_Type')['Horizontal_Distance_To_Roadways'].median().to_dict()\n    X['Soil_Road'] = X['Soil_Type'].map(soil_roads)\n    \n    soil_fires = X.groupby('Soil_Type')['Horizontal_Distance_To_Fire_Points'].median().to_dict()\n    X['Soil_Fire'] = X['Soil_Type'].map(soil_fires)\n    \n    \n    X = X.drop(['Soil_Type'], axis='columns')\n            \n    X_trn = X.loc[X_trn.index, :]\n    X_tst = X.loc[X_tst.index, :]\n        \n    return X_trn, X_tst","43879b29":"X_train = train.drop('Cover_Type', axis='columns')\nX_test = test.copy()\n\nX_train, X_test = add_features(X_train, X_test)","6fcda883":"feature_importances(clf, X_train, y_train)","a03f078a":"cv_performance(clf, X_train, y_train)","4729fff5":"# Plotting mode frequencies as % of data size\nn_rows = X_train.shape[0]\nmode_frequencies = [X_train[col].value_counts().iat[0]for col in X_train.columns]\nmode_frequencies = 100.0 * np.asarray(mode_frequencies) \/ n_rows\n\nmode_df = pd.DataFrame({'Feature': X_train.columns, \n                        'Mode_Frequency': mode_frequencies})\n\nmode_df.sort_values(by=['Mode_Frequency'], axis='index', ascending=True, inplace=True)\n\nfig = plt.figure(figsize=(14, 4))\nax = sns.barplot(x='Feature', y='Mode_Frequency', data=mode_df, color='b')   \nplt.ylabel('Mode Frequency %')\nplt.xticks(rotation='vertical')\nplt.show()","9547d36f":"# Drop features with high mode frequencies\n\ndef drop_unimportant(X_):\n    X = X_.copy()\n    \n    n_rows = X.shape[0]\n    hi_freq_cols = []\n    \n    for col in X.columns:\n        mode_frequency = X[col].value_counts().iat[0] \n        \n        if mode_frequency > (n_rows - 10):\n            hi_freq_cols.append(col)\n            \n    X = X.drop(hi_freq_cols, axis='columns')\n    \n    return X","fe419c32":"X_train = drop_unimportant(X_train)","a14d6e24":"cv_performance(clf, X_train, y_train)","6b547aef":"plot_correlations(X_train)","9ebd6f0d":"def drop_correlated(X_):\n    X = X_.copy()\n    \n    drop_cols = ['Hillshade_max', 'Hillshade_mean', 'Hillshade_median', \n                 'Hillshade_min', 'Hillshade_sum', 'Hydro_Elevation_sum',\n                 'Hydro_Distance_sum', 'Hydro_Distance_diff', 'Hydro_Fire_mean', \n                 'Hydro_Fire_median', 'Hydro_Manhattan', 'Hydro_Road_Fire_mean', \n                 'Hydro_Road_Fire_median', 'Hydro_Road_mean', 'Hydro_Road_median', \n                 'Road_Fire_mean', 'Road_Fire_median', 'Soil_Aspect', 'Soil_Slope', \n                 'Soil_H_Hydro', 'Soil_V_Hydro', 'Soil_Road', 'Soil_Fire',\n                 'Stoneyness', 'Rocks', 'Aspect_120','Aspect', 'Slope']\n    \n    drop_cols += ['Soil_Type{}'.format(i) for i in range(1, 41)]\n        \n    drop_cols = [col for col in drop_cols if col in X.columns]\n    \n    X = X.drop(drop_cols, axis='columns')\n    \n    return X","33031fc3":"X_train = drop_correlated(X_train)","9d0f4838":"plot_correlations(X_train, y_train)","a8e1b426":"feature_importances(clf, X_train, y_train)","6b9e0e64":"cv_performance(clf, X_train, y_train)","89842656":"# Reload data\nX_train = train.drop('Cover_Type', axis='columns')\nX_test = test.copy()","5410041d":"X_train_wa, y_train_wa = get_wa_data(1, X_train, y_train)\nX_test_wa, _ = get_wa_data(1, X_test)","e901f3b4":"feature_importances(clf, X_train_wa, y_train_wa)","ec9d4227":"cv_performance(clf, X_train_wa, y_train_wa)","c177a9c2":"X_train_wa, X_test_wa = add_features(X_train_wa, X_test_wa)","e5d7da6d":"feature_importances(clf, X_train_wa, y_train_wa)","d0f5d12b":"cv_performance(clf, X_train_wa, y_train_wa)","7b736c5c":"def drop_features(X_):\n    X = X_.copy()\n    \n    X = drop_unimportant(X)\n    X = drop_correlated(X)\n    \n    return X","6eeac056":"X_train_wa = drop_features(X_train_wa)","0bb353c9":"feature_importances(clf, X_train_wa, y_train_wa)","e3c3574c":"cv_performance(clf, X_train_wa, y_train_wa)","8d726853":"def plot_class_counts(y):\n    fig = plt.figure(figsize=(8, 4))\n    sns.countplot(y)\n    plt.show()","a15538f7":"plot_class_counts(y_train_wa)","0ef7b3b7":"# https:\/\/www.kaggle.com\/shahules\/tackling-class-imbalance\n\n# Up-sample minority classes\n\ndef upsample(X_, y_):\n    X = X_.copy()\n    y = y_.copy()\n    \n    max_samples = y.value_counts().iat[0]\n    classes = y.unique().tolist()\n    sampling_strategy = dict((clas, max_samples) for clas in classes)\n\n    sampler = SMOTE(sampling_strategy=sampling_strategy,\n                    random_state=random_state)\n\n    x_columns = X.columns.tolist()\n    X, y = sampler.fit_resample(X, y)\n    X = pd.DataFrame(X, columns=x_columns)\n    y = pd.Series(y)\n    \n    return X, y","df9c0f8e":"X_train_wa, y_train_wa = upsample(X_train_wa, y_train_wa)","d637b56e":"plot_class_counts(y_train_wa)","b2ab2adb":"# Modify cv_performance() to include upsampling\n\ndef cv_performance(clf, X, y, resample=False):\n    # Get cross-validation scores\n    scores = []\n    predictions = pd.Series(dtype=y.dtype)\n\n    splits = StratifiedKFold(n_splits=5).split(X, y)\n\n    for trn_index, val_index in splits:\n        X_trn = X.iloc[trn_index, :]\n        y_trn = y.iloc[trn_index]\n\n        X_val = X.iloc[val_index, :]\n        y_val = y.iloc[val_index]\n        \n        if resample:\n            X_trn, y_trn = upsample(X_trn, y_trn)\n\n        clf = clf.fit(X_trn, y_trn)\n        pred = clf.predict(X_val)\n        \n        if resample:\n            # Calculate scores on original samples only\n            pred = pred[:len(y_val)]\n            \n        pred = pd.Series(pred, index=y_val.index)\n        predictions = pd.concat([predictions, pred])\n\n        score = accuracy_score(y_val, pred)\n        scores.append(score)\n\n    predictions = predictions.sort_index()\n\n    print('Cross-validation accuracy: {:.3f} {}'.format(np.mean(scores), \n                                                        np.around(scores, 3)))\n    \n    # Plot confusion matrix\n    classes = sorted(y.unique().tolist())\n\n    conf_mat = confusion_matrix(y, predictions)\n    norm_conf_mat = np.around(conf_mat \/ conf_mat.sum(axis=1), 2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    fig.add_subplot(1, 2, 1)\n    ax = sns.heatmap(norm_conf_mat, annot=True, cmap='OrRd', \n                     xticklabels=classes, yticklabels=classes)\n    ax.set(xlabel='Predicted Class', ylabel='True Class', title='Normalized')\n\n\n    fig.add_subplot(1, 2, 2)\n    ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='OrRd', \n                     xticklabels=classes, yticklabels=classes)\n    ax.set(xlabel='Predicted Class', ylabel='True Class', title ='Counts')\n\n    plt.tight_layout()\n    plt.show()","b30ff345":"# Reload Wilderness_Area1 data\nX_train_wa, y_train_wa = get_wa_data(1, X_train, y_train)\nX_test_wa, _ = get_wa_data(1, X_test)\n\nX_train_wa, X_test_wa = add_features(X_train_wa, X_test_wa)\n\nX_train_wa = drop_features(X_train_wa)","4464455f":"cv_performance(clf, X_train_wa, y_train_wa, resample=True)","0617e745":"X_train_wa, y_train_wa = get_wa_data(2, X_train, y_train)\nX_test_wa, _ = get_wa_data(2, X_test)","324fdeb9":"plot_class_counts(y_train_wa)","1887483c":"feature_importances(clf, X_train_wa, y_train_wa)","ebdacab2":"cv_performance(clf, X_train_wa, y_train_wa)","2719702d":"X_train_wa, X_test_wa = add_features(X_train_wa, X_test_wa)\n\nX_train_wa = drop_features(X_train_wa)","a084b3ef":"feature_importances(clf, X_train_wa, y_train_wa)","57c77387":"cv_performance(clf, X_train_wa, y_train_wa, resample=True)","716063b2":"X_train_wa, y_train_wa = get_wa_data(3, X_train, y_train)\nX_test_wa, _ = get_wa_data(3, X_test)","a003626d":"plot_class_counts(y_train_wa)","5defe1f6":"feature_importances(clf, X_train_wa, y_train_wa)","2522eb60":"cv_performance(clf, X_train_wa, y_train_wa)","4b12a694":"X_train_wa, X_test_wa = add_features(X_train_wa, X_test_wa)\n\nX_train_wa = drop_features(X_train_wa)","4a227e42":"feature_importances(clf, X_train_wa, y_train_wa)","4a907f04":"cv_performance(clf, X_train_wa, y_train_wa, resample=True)","c662aae2":"X_train_wa, y_train_wa = get_wa_data(4, X_train, y_train)\nX_test_wa, _ = get_wa_data(4, X_test)","d06be542":"plot_class_counts(y_train_wa)","8516fe95":"feature_importances(clf, X_train_wa, y_train_wa)","780b31c4":"cv_performance(clf, X_train_wa, y_train_wa)","5b3c38f7":"X_train_wa, X_test_wa = add_features(X_train_wa, X_test_wa)\n\nX_train_wa = drop_features(X_train_wa)","6f6bd480":"feature_importances(clf, X_train_wa, y_train_wa)","be3af1b0":"cv_performance(clf, X_train_wa, y_train_wa, resample=True)","57b1de48":"# Numerical correlations","92f1c9ce":"## Initial cross-validation accuracy and confusion matrix","cf8b792c":"Manual feature elimination - iteratively eliminate some features that have high inter-correlations with other features, ensuring that cv score does not get worse in the process.","bf3009e3":"# Horizontal_Distance_To_Hydrology","830f9617":"Classes are imbalanced in Wilderness_Area1","b4d3356a":"# Horizontal_Distance_To_Roadways","8894c1fc":"## Notes\n* Class 2 has a very low count compared to the others and is the hardest to predict.\n* Confusion between classes 3 and 6 is noticeable.\n* Unlike other Wilderness Areas, importances of Elevation & Hydro_Elevation_diff do not dwarf all other feature importances.","566b38e1":"# Feature importances by Wilderness_Area","3153b161":"# Helpful notebooks\n \n https:\/\/www.kaggle.com\/jakelj\/basic-ensemble-model\n \n https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/108575\n \n https:\/\/www.kaggle.com\/arthurtok\/introduction-to-ensembling-stacking-in-python\n \n https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n \n https:\/\/www.kaggle.com\/shahules\/tackling-class-imbalance\n","724f93dc":"# Removing low importance features","467beb95":"# Slope","5366533e":"## [Wilderness_Area1] :: Performance after adding features","b0f0c133":"## [Wilderness_Area1] :: Data Preparation","9ca2a034":"## [Wilderness_Area2] :: Performance after processing","31c7ce3f":"# Horizontal_Distance_To_Fire_Points","d2e3cbd2":"# Cover_Type one vs rest","89c7adea":"# Focusing on Wilderness_Area2","84ae718e":"## [Wilderness_Area1] :: Performance after feature removal","7249cd7a":"# Correlation plots","e64693a3":"# Adding new features","ea498fd5":"Low importance Soil_Type features all have low variance, being almost entirely made up of zeros (or ones). The frequency of the mode is close to 100% of data size, whether the mode is 0 or 1.","6879fa50":"## New feature correlations","4caae814":"## [Wilderness_Area2] :: Initial performance","0b176fc3":"# Hillshade_3pm","a498135f":"# Vertical_Distance_To_Hydrology","8db85121":"# Aspect","7ffbaa15":"# Focusing on Wilderness_Area3","3c5e16cb":"# Hillshade_9am","e978a923":"## [Wilderness_Area1] :: Up-sampling to balance classes","036dbbad":"# Focusing on Wilderness_Area1","451c9f09":"# Soil_Type associations","fab45c7a":"# Cover_Type by Wilderness Area","0dff18a8":"# Soil_Type boxplots","5f081fde":"## [Wilderness_Area4] :: Performance after processing","33c5d967":"## Backward feature elimination","c913cec6":"# Elevation","ca7ce7f4":"## [Wilderness_Area4] :: Initial performance","97b3cf9a":"# Cover_Type pairs","7e3adb8e":"## [Wilderness_Area3] :: Initial performance","52a7dfdf":"## [Wilderness_Area1] :: Performance after up-sampling","40dac385":"## [Wilderness_Area1] :: Initial performance","ec8e7261":"## Notes\n* Cross-validation accuracy for Wilderness Area 2 improved.\n* Confusion between classes 1 and 2 is high.\n* Class 2 has a lower count than class 1 and is harder to predict.","ce3275a2":"## Notes\n* Cross-validation accuracy improved from 78.0% to 81.8% (3.8% up).\n*  Confusion between classes 1 and 2 is high (initially 0.24 \/ 0.25).\n*  Adding new features has not improved the confusion by much.","71834c40":"Classes become equally balanced after up-sampling","f99a91fc":"* Confusion between classes 1 and 2 > 0.2\n* Confusion between classes 3 and 6 > 0.1\n* Confusion between all other classes < 0.1","c08b2747":"## Cross-validation performance with added features","43af8c7b":"# Hillshade_Noon","1f3f7951":"## Notes\n* Cross-validation accuracy for Wilderness Area 3 improved.\n* Confusion between classes 1 and 2 is high.","1bff1f07":"## [Wilderness_Area3] :: Performance after processing","a75582c9":"# Focusing on Wilderness_Area4","0b7bff75":"## Feature importances with added features","fb84200e":"## Notes\n * Cross-validation accuracy for Wilderness Area 1 improved from 74.7% to 78.8% (4.1% up).\n * Confusion between classes 1 and 2 is high (0.22 \/ 0.23)\n * Top 5 important Soil Types: 30, 38, 29, 12, 23"}}