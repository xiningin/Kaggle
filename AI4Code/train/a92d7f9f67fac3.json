{"cell_type":{"e9066af2":"code","5d7b112e":"code","c2a6e7e5":"code","3176d6ef":"code","cef1fd1f":"code","7aba3f20":"code","211cb331":"code","2a9fffd8":"code","edffdaa6":"code","da1156af":"code","71c6dcca":"code","96218000":"code","c002e60d":"code","265b504d":"code","b967fdb5":"markdown","4838c7be":"markdown","fe0fb158":"markdown","6cf0bcc0":"markdown","f1b75df7":"markdown","09f80d50":"markdown","2cdbb7a7":"markdown","82ecf15d":"markdown","fab57ea3":"markdown","cf69cfed":"markdown","6bf3d08f":"markdown","5019c9db":"markdown","f1f8b794":"markdown"},"source":{"e9066af2":"zabt = \"Papers on Diagnostics and Surveillance\"\nznam = \"Papers_on_Diagnostics_and_Surveillance\"","5d7b112e":"zwds = \"able academic accelerator accessibility accuracy advanced aid analytics antibodies approach approaches area assay associated asymptomatic barriers bats bed-side bioinformatics biological capabilities capacity clinical coalition collecting communications companion convalescent coordination coupling covid-19 crispr cytokines demographic demographics denominators detection development devices diagnostic diagnostics disease distinguishing domestic drift efficacy efforts elisas entity environment environmental epidemic ethical evolution evolutionary execution experiments expertise exposure factors farmed food forces funding genetic genome genomics guidelines health hoc holistic host humans immediate impact important improve inclusive influenza information instruments intentional interventions issues laboratories latency legal leverage local locking longitudinal markers market mass measures mechanism migrate mitigate mitigation model mutations national naturally-occurring neutralizing non-profit occupational officials ongoing operational opportunities organism outcomes particular pathogen pathogens pcr people perspective platforms point-of-care policy potential practice predict preparedness private progression protocols public published purposes reagents recognizing recommendations recorded recruitment regions regulatory response risk roadmap samples sampling scale scaling schemes screening sector separation sequencing serosurveys sources species specific specificity spillover states streamlined sufficient supplies support surveillance swabs systematic tap target technology test testers testing therapeutic times track tradeoffs trafficked transmission understanding universities unknown variant viral virus widespread wildlife\"","c2a6e7e5":"import os\nimport pandas as pd\nimport json\nfrom IPython.core.display import display, HTML\n# !pip uninstall spacy # Uncomment this if installed version of spacy fails.\n# !pip install spacy # Uncomment this if spacy package is not installed.\nimport spacy\n# !python -m spacy download en # Uncomment this if en language is not loaded in spacy package. \nnlp = spacy.load('en')","3176d6ef":"zchk = nlp(zwds)","cef1fd1f":"ztop = '\/kaggle\/input\/CORD-19-research-challenge'","7aba3f20":"zdf0 = pd.DataFrame(columns=['Folder', 'File', 'Match'])","211cb331":"%%capture\n\nfor zsub, zdir, zfis in os.walk(ztop):\n\n    for zfil in zfis:\n        if zfil.endswith(\".json\"):\n            \n            with open(zsub + os.sep + zfil) as f:\n                zout = json.load(f)\n            f.close()\n            \n            zout = \" \".join([part['text'] for part in zout['abstract']])\n            zout = zchk.similarity(nlp(zout))\n            \n            zdf0 = zdf0.append({'Folder': zsub.replace(ztop, \"\"), 'File': zfil, 'Match': zout}, ignore_index=True)\n            \nprint(zdf0.head(4))","2a9fffd8":"zdf0.to_csv(znam + '_Check.csv', index = False)","edffdaa6":"zdf6 = zdf0[zdf0.Match > 0.6].sort_values(by=['Match'], axis=0, ascending=False, inplace=False)\nprint(zdf6.head(4))","da1156af":"zdf6.to_csv(znam + '_Relevant.csv', index = False)","71c6dcca":"%%capture\n\nzht0 = \"<html>\\n<head>\\n\"\nzht0 = zht0 + \"<title>Relevant Papers for Vaccines and Therapeutics<\/title>\\n\"\nzht0 = zht0 + \"<script>\\nfunction openPop(x) {\\nei = document.getElementById('pop_' + x);\\n\"\nzht0 = zht0 + \"ei.style.display='block';\\nec = document.getElementsByClassName('pip');\\nvar i;\\n\"\nzht0 = zht0 + \"for (i = 0; i < ec.length; i++) {\\nif ( ec[i] != ei) { ec[i].style.display='none'; }; }; }\\n\"\nzht0 = zht0 + \"function shutPop(x) { document.getElementById('pop_' + x).style.display='none'; }\\n<\/script>\\n\"\nzht0 = zht0 + \"<style>table, th, td { border: 1px solid black; }<\/style>\\n\"\nzht0 = zht0 + \"<\/head>\\n<body>\\n\"\nzht0 = zht0 + \"<h1>\" + zabt + \"<\/h1>\\n\"\nzht0 = zht0 + \"<p>The following is a list of relevant papers.<\/p><br \/>\\n\"\nzht0 = zht0 + \"<p>Click on a Title to pop up its Abstract.<\/p><br \/>\\n\"\nzht0 = zht0 + \"<table>\\n<tbody>\\n<tr><th>Title<\/th>\\n<th>Abstract<\/th><\/tr>\\n\"","96218000":"zht6 = zht0 # zht6 is to be saved later as a file.\nzhtd = zht0 # zhtd is a smaller version of zht6, for displaying in this notebook.\n\nfor indx, cont in zdf6.iterrows():\n    \n    with open(ztop + os.sep + cont['Folder'] + os.sep + cont['File']) as f:\n        ztxt = json.load(f)\n        f.close()\n        \n    ztxt = \" \".join([part['text'] for part in ztxt['abstract']])\n    \n    zhta = \"<tr><td><div onClick=openPop(\" + str(indx) + \")>\" + str(cont['File']) + \"<\/div><\/td>\\n\"    \n    zhta = zhta + \"<td><div onClick=shutPop(\" + str(indx) + \") class='pip' id='pop_\" + str(indx) + \"' style='display:none;'>\" + ztxt + \"<\/div><\/td><\/tr>\\n\"\n    \n    zht6 = zht6 + zhta\n    if indx < 10:\n        zhtd = zhtd + zhta\n\nzht6 = zht6 + \"<\/body>\\n<\/html>\"\nzhtd = zhtd + \"<\/body>\\n<\/html>\"","c002e60d":"%%capture\n\nzout = open(znam + \"_Relevant_10.html\",\"a\")\nzout.write(zht6)\nzout.close()","265b504d":"display(HTML(zhtd))","b967fdb5":"Display the smaller html as a webpage here.","4838c7be":"This notebook aims to:\n- Prepare a list of papers and their relevance to the task under consideration.\n- Prepare a list and a webpage of most relevant papers and their abstracts.\n- Display top 10 most relevant papers and their abstracts.","fe0fb158":"Outside this notebook: take the task's specification; make a unique list of words; remove common words; and optionally sort them.","6cf0bcc0":"Save the webpage html as a file.","f1b75df7":"Make a subset dataframe of records with more than 60% relevance.","09f80d50":"Import python packages: os, pandas, json, IPython, and spacy.","2cdbb7a7":"Specify the location of files of papers provided by this challenge.","82ecf15d":"Make an empty dataframe, to populate later.","fab57ea3":"Export this dataframe as a csv file.","cf69cfed":"Make a webapage html of list and abstracts of papers with more than 60% relevance.","6bf3d08f":"\n\nApply spacy's nlp tool to the set of selected words.","5019c9db":"Go through each file, review the Abstract text contained in it, compute its relevance to the task, and add it to the dataframe.","f1f8b794":"Export this subset dataframe as another csv file."}}