{"cell_type":{"0e81e6eb":"code","510072dc":"code","50838dfa":"code","8c179a3d":"code","c8e074db":"code","d262fd1d":"code","5a8c7ff0":"code","dea658e8":"code","3e7d9d19":"code","8c1c8e57":"code","e977da07":"code","2e72c5aa":"code","3def86cd":"code","b45c36f6":"code","bdcc836a":"code","f824cf94":"code","754b9090":"code","c7fde1c8":"code","77338a90":"code","a01b1466":"code","b66f6f90":"code","20eb3f33":"code","1941257e":"code","996b379a":"code","cc31c3bc":"code","d6377ee0":"code","63ac4be8":"code","dd332548":"code","75109dd2":"code","8a04e9c9":"code","9a7bcedf":"code","be3f219a":"code","55ca5f27":"code","985ce220":"code","704c3949":"code","53124218":"code","f86d025e":"code","64109f95":"code","10e52260":"code","3e7f3c46":"code","2403b3d5":"code","f228e924":"code","073bd94d":"code","02bc3f22":"code","aba2a60c":"code","de82826f":"code","45566598":"code","50e8b861":"code","257a742f":"code","042063a6":"code","1009317c":"markdown","12a248dd":"markdown","02c8e437":"markdown","ae9d9ee5":"markdown","d9e64774":"markdown","6d9b0a4f":"markdown","fb6939bd":"markdown","c741a2cc":"markdown","b7a81f08":"markdown","0668c5f6":"markdown","3873514c":"markdown","b5e1b8f7":"markdown","775aeb1f":"markdown","7cc25021":"markdown","6db3f50f":"markdown","57243322":"markdown","78517594":"markdown","d37c32fd":"markdown"},"source":{"0e81e6eb":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.naive_bayes import GaussianNB","510072dc":"df1=pd.read_csv('..\/input\/world-university-rankings\/cwurData.csv')\ndf1.head(2)","50838dfa":"df1.describe()","8c179a3d":"df1.isnull().sum()","c8e074db":"df1['broad_impact']=df1['broad_impact'].fillna(df1.groupby(['institution'])['broad_impact'].transform('mean'))\ndf1['broad_impact']=df1['broad_impact'].fillna(0)","d262fd1d":"df1.isnull().sum()","5a8c7ff0":"df1.shape","dea658e8":"from scipy.stats.stats import pearsonr\nfeatures = ['quality_of_education','alumni_employment','quality_of_faculty','publications','influence','citations','broad_impact','patents']\ntarget = 'score'\nfor feature in features:\n    coeff = pearsonr(df1[feature], df1[target])[0]\n    print('Pearson correlation for ' + feature + ' coeff: ' + str(coeff))","3e7d9d19":"df_top100 = df1.iloc[:100,:]","8c1c8e57":"import plotly.graph_objs as go","e977da07":"citation= go.Scatter(x = df_top100.world_rank,y = df_top100.citations,mode = \"lines\",name = \"citations\",marker = dict(color = 'rgba(16, 112, 2, 0.8)'),text= df_top100.institution)\nteaching= go.Scatter(x = df_top100.world_rank, y = df_top100.quality_of_faculty, mode = \"lines+markers\", name = \"teaching\",marker = dict(color = 'rgba(80, 26, 80, 0.8)'),text= df_top100.institution)","2e72c5aa":"from plotly.offline import init_notebook_mode, iplot\nfrom plotly.graph_objs import *\ninit_notebook_mode(connected=True)  \n# Create a list to add traces\ndata = [citation, teaching]\nlayout = dict(title = 'Citation and Teaching vs World Rank of Top 100 Universities',xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= False))\nfig1 = dict(data = data, layout = layout)\niplot(fig1)","3def86cd":"# Plot evolution of each criteria of the ranking\ndf2 = df1[['year', 'quality_of_faculty', 'alumni_employment', 'patents', 'citations']].head(20)\nax = df2.plot.bar( stacked=True, x='year')\nax.legend(loc=7, bbox_to_anchor=(1.4, 0.5))","b45c36f6":"df1['world_rank'] = df1['world_rank'].astype('int64')\ndf1['national_rank'] = df1['national_rank'].astype('float64')\ndf1['broad_impact'] = df1['broad_impact'].astype('float64')\ndf1['score'] = df1['score'].astype('float64')\n# Plot evolution of ranking\nax = df1.plot(kind='line',  x='year',  y='world_rank', xlim=(2011, 2016),  ylim=(1, 60),  xticks=range(2011, 2017))\n# Have ints for the labels\nax.ticklabel_format(useOffset=False, style='plain')","bdcc836a":"sns.lmplot(x = 'broad_impact',y= 'world_rank',data = df1)\nplt.title('world rank vs broad impact')\nplt.show()","f824cf94":"# Prepare Data\ndff=df1.head(100)\ndf= dff.groupby('country').size()\n# Make the plot with pandas\ndf.plot(kind='pie', subplots=True, figsize=(8, 8))\nplt.title(\"Pie Chart of Various Category\")\nplt.ylabel(\"\")\nplt.show()","754b9090":"f,ax=plt.subplots(1,1,figsize=(20,4))\ndf1['country'].value_counts().plot(kind='bar')","c7fde1c8":"f,ax=plt.subplots(1,1,figsize=(8,4))\nsns.countplot(x=\"year\",data=df1,palette=\"muted\")","77338a90":"import matplotlib.pyplot as plt\nnew=df1.head(20)\nplt.scatter(new.country,new.institution,) #scatter plot example\nplt.xlabel('countries')\nplt.ylabel('universities')\nplt.title('rank')\nplt.show()","a01b1466":"f,ax=plt.subplots(1,3,figsize=(25,5))\nbox1=sns.boxplot(data=df1[\"quality_of_education\"],ax=ax[0],color='c')\nax[0].set_xlabel('quality_of_education')\nbox1=sns.boxplot(data=df1[\"alumni_employment\"],ax=ax[1],color='c')\nax[1].set_xlabel('alumni_employment')\nbox1=sns.boxplot(data=df1[\"quality_of_faculty\"],ax=ax[2],color='c')\nax[2].set_xlabel('quality_of_faculty')","b66f6f90":"f,ax=plt.subplots(1,3,figsize=(25,5))\nbox1=sns.boxplot(data=df1[\"publications\"],ax=ax[0],color='c')\nax[0].set_xlabel('publications')\nbox1=sns.boxplot(data=df1[\"influence\"],ax=ax[1],color='c')\nax[1].set_xlabel('influence')\nbox1=sns.boxplot(data=df1[\"citations\"],ax=ax[2],color='c')\nax[2].set_xlabel('citations')","20eb3f33":"corr = (df1.corr())\nplt.subplots(figsize=(9, 9))\nsns.heatmap(corr, vmax=.8,annot=True,cmap=\"viridis\", square=True);","1941257e":"df1['country'].replace([0], 'USA', inplace=True) \ndf1['country'].replace([1], 'United Kingdom', inplace=True) \ndf1['country'].replace([2], 'China', inplace=True)   \ndf1['country'].replace([2], 'Japan', inplace=True)   \ndf1['country'].replace([2], 'Germany', inplace=True)   \n\nf,ax=plt.subplots(1,1,figsize=(25,10))\nsns.kdeplot(df1.loc[(df1['country']=='USA'), 'quality_of_faculty'], color='b', shade=True, Label='USA')\nsns.kdeplot(df1.loc[(df1['country']=='United Kingdom'), 'quality_of_faculty'], color='g', shade=True, Label='United Kingdom')\nsns.kdeplot(df1.loc[(df1['country']=='China'), 'quality_of_faculty'], color='r', shade=True, Label='China')\nsns.kdeplot(df1.loc[(df1['country']=='Japan'), 'quality_of_faculty'], color='m', shade=True, Label='Japan')\nsns.kdeplot(df1.loc[(df1['country']=='Germany'), 'quality_of_faculty'], color='c', shade=True, Label='Germany')\nplt.xlabel('quality of faculty') \nplt.ylabel('Probability Density')","996b379a":"sns.pairplot(df1,vars = ['quality_of_education','alumni_employment','quality_of_faculty','publications', 'influence','citations'] )","cc31c3bc":"f,axes=plt.subplots (1,1,figsize=(15,4))\nsns.distplot(df1['score'],kde=True,hist=True,color=\"r\")","d6377ee0":"df_h=df1.drop(['world_rank','institution','country','national_rank','year'],axis=1)","63ac4be8":"hist_mean=df_h.hist(bins=10, figsize=(15, 15),grid=False,)","dd332548":"df2014 = df1[df1.year == 2014].iloc[:100,:]\ndf2015 = df1[df1.year == 2015].iloc[:100,:]\ndf2012 = df1[df1.year == 2012].iloc[:100,:]","75109dd2":"# creating trace for year 2014\ntrace_2014 = go.Scatter(x = df2014.world_rank, y = df2014.citations, mode = \"markers\", name = \"2014\", marker = dict(color = 'rgba(255, 128, 255, 0.8)'), text= df2014.institution)\n# creating trace for year 2015\ntrace_2015 = go.Scatter(x = df2015.world_rank,y = df2015.citations,mode = \"markers\",name = \"2015\",marker = dict(color = 'rgba(255, 128, 2, 0.8)'),\n                        text= df2015.institution)\n# creating trace for year 2016\ntrace_2012 = go.Scatter(x = df2012.world_rank,y = df2012.citations, mode = \"markers\", name = \"2016\", marker = dict(color = 'rgba(0, 255, 200, 0.8)'),text= df2012.institution)","8a04e9c9":"# Create a list to add traces\ndata = [trace_2014, trace_2015, trace_2012]\n\nlayout = dict(title = 'Citation vs world rank of top 100 universities in year 2014, 2015 and 2012',\n              xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Citation',ticklen= 5,zeroline= False))\nfig2 = dict(data = data, layout = layout)\niplot(fig2)","9a7bcedf":"from wordcloud import WordCloud \ndf2=df1['country'].to_string()\n# Start with one review:\ntext = df2\n# Create and generate a word cloud image:\nwordcloud = WordCloud().generate(text)\n# Display the generated image:\nf,ax=plt.subplots(1,1,figsize=(25,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","be3f219a":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf1['country']=le.fit_transform(df1['country'])","55ca5f27":"X = df1.drop(['score','institution','year'],axis=1)\nY = df1['score']\nx_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=7)","985ce220":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nlm = LinearRegression()\nmodel = lm.fit(X,Y)\nprint(f'alpha = {model.intercept_}')\nprint(f'betas = {model.coef_}')","704c3949":"Y_Pred = lm.predict(x_test)\nprint('Linear Regression R squared: %.2f' % lm.score(x_test, y_test))","53124218":"mse = mean_squared_error(Y_Pred, y_test)\nrmse = np.sqrt(mse)\nprint('Linear Regression RMSE: %.2f' % rmse)","f86d025e":"model.predict(X)","64109f95":"new_X = [[100,50,8,8,8,9,9,0,8,7,6]]\nprint(model.predict(new_X))","10e52260":"model = LinearRegression()\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\nsns.distplot(y_test - predictions, axlabel=\"Test - Prediction\")\nplt.show()","3e7f3c46":"df1.insert(14,\"chances\",0,True)\ndf1.head(1)","2403b3d5":"df1.loc[df1['score']> 50, ['chances']] = '1'\ndf1.loc[df1['score']< 50, ['chances']] = '0'","f228e924":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf1['country']=le.fit_transform(df1['country'])","073bd94d":"X=X.fillna(0)","02bc3f22":"X = df1.drop(['score','institution','year','chances','broad_impact'],axis=1)\nY=df1['chances'].astype(int)\nx_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=7)","aba2a60c":"models = []\nmodels.append((\"LR\",LogisticRegression()))\nmodels.append((\"GNB\",GaussianNB()))\nmodels.append((\"KNN\",KNeighborsClassifier()))\nmodels.append((\"DecisionTree\",DecisionTreeClassifier()))\nmodels.append((\"LDA\",  LinearDiscriminantAnalysis()))\nmodels.append((\"QDA\",  QuadraticDiscriminantAnalysis()))\nmodels.append((\"AdaBoost\", AdaBoostClassifier()))\nmodels.append((\"SVM Linear\",SVC(kernel=\"linear\")))\nmodels.append((\"SVM RBF\",SVC(kernel=\"rbf\")))\nmodels.append((\"Random Forest\",  RandomForestClassifier()))\nmodels.append((\"Bagging\",BaggingClassifier()))\nmodels.append((\"Calibrated\",CalibratedClassifierCV()))\nmodels.append((\"GradientBoosting\",GradientBoostingClassifier()))\nmodels.append((\"LinearSVC\",LinearSVC()))\nmodels.append((\"Ridge\",RidgeClassifier()))","de82826f":"results = []\nfor name,model in models:\n    kfold = KFold(n_splits=10, random_state=0)\n    cv_result = cross_val_score(model,x_train,y_train, cv = kfold,scoring = \"accuracy\")\n# It gives you an unbiased estimate of the actual performance you will get at runtime\n    results.append(tuple([name,cv_result.mean(), cv_result.std()]))\n    results.sort(key=lambda x: x[1], reverse = True)    \nfor i in range(len(results)):\n    print('{:20s} {:2.2f} (+\/-) {:2.2f} '.format(results[i][0] , results[i][1] * 100, results[i][2] * 100))","45566598":"ran_class=RandomForestClassifier()\nran_class.fit(x_train,y_train)\nran_predict=ran_class.predict(x_test)\nprint(classification_report(y_test,ran_predict))\naccuracy=ran_class.score(x_test,y_test)\nprint(accuracy*100,'%')\ncm = confusion_matrix(y_test, ran_predict)\nsns.heatmap(cm, annot= True)","50e8b861":"false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, ran_predict)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nplt.figure(figsize = (10,6))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, color = 'red', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","257a742f":"train_score = ran_class.score(x_train,y_train)\ntest_score = ran_class.score(x_test,y_test)\nprint(f'Training Accuracy of our model is: {train_score}')\nprint(f'Test Accuracy of our model is: {test_score}')","042063a6":"prediction = ran_class.predict(x_train.iloc[15].values.reshape(1,-1))\nactual_value = y_train.iloc[15]\nprint(f'Predicted Value \\t: {prediction[0]}')\nprint(f'Actual Value\\t\\t: {actual_value}')","1009317c":"**Piechart**","12a248dd":"**Random Forest Classifier**","02c8e437":"**Heatmap**","ae9d9ee5":"**2.Using Classification**","d9e64774":"**Pairplot**","6d9b0a4f":"**Importing Dataset**","fb6939bd":"**Boxplot**","c741a2cc":"**1.Linear Regression**","b7a81f08":"**Histogram**","0668c5f6":"**KDE plot**","3873514c":"**Quality of faculty**","b5e1b8f7":"**Countplot**","775aeb1f":"**Distplot**","7cc25021":"**Wordcloud**","6db3f50f":"**Importing Dataset**","57243322":"**Pearson Coefficient**","78517594":"**ROC curve**","d37c32fd":"**K-Fold cross Validation**"}}