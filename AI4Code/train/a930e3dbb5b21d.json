{"cell_type":{"31543ffb":"code","500ddc2d":"code","c89e7738":"code","d76b68c4":"code","e77ee4a8":"code","a0a10b2c":"code","a3e031a7":"code","379da1a8":"code","3bcafa57":"code","a0830910":"code","913bcb1f":"code","cf77e791":"code","f10fe46c":"code","c40e55d3":"code","c0ed393d":"code","70e6a5a7":"code","89795508":"code","c0f17e36":"code","07be41f8":"code","cd32b3a1":"code","d48a469f":"code","8bcc637f":"code","2010eb88":"code","22b0380a":"code","1ece3e5a":"code","1972df89":"code","f16084b7":"code","7f40de35":"code","4e78ec80":"code","7e4028b2":"code","cc6baf0c":"code","b6f8eefe":"code","0fa39a11":"code","02d5fe10":"code","874b6a94":"code","9ded8fdf":"code","abb63599":"code","fd62c52f":"markdown","e556c9f3":"markdown","d5658417":"markdown","5b59ff48":"markdown","b01b3da3":"markdown","2d82c339":"markdown","4028f07f":"markdown","fc624985":"markdown","19530637":"markdown","bee1e288":"markdown","da7e00d3":"markdown","903521ea":"markdown","d501570d":"markdown","0eeb80ff":"markdown","4a18b0cf":"markdown","60ff1a80":"markdown","b94faa38":"markdown","05a44987":"markdown","c036276d":"markdown","222f3a3d":"markdown","6ad51d16":"markdown","3dfd1dcd":"markdown","e7e1f722":"markdown","14311d60":"markdown","bce483a8":"markdown","6bed7387":"markdown","40d88afd":"markdown","adbee7c0":"markdown","73dc65c8":"markdown","7b2c9520":"markdown","64bb8975":"markdown"},"source":{"31543ffb":"# REQUIREMENTS: these are usually installed in any decent ML environment.\n#\n#!pip install -U matplotlib numpy pandas tqdm xgboost","500ddc2d":"import os\n\nin_path = \"..\/input\/competitive-data-science-predict-future-sales\/\"\nif os.path.exists(in_path):\n    print(\"Running inside Kaggle\")\n    tree_method = \"hist\" # Kaggle GPU VM runs out of RAM\n\nelse:\n    try:\n        from google.colab import drive\n        drive.mount(\"\/content\/drive\")\n\n        os.chdir(\"\/content\/drive\/My Drive\/Colab Notebooks\")\n        print(\"Running inside Colab\")\n\n        in_path = \".\/competitive-data-science-predict-future-sales\/\"\n        tree_method = \"gpu_hist\" # Colab Pro with High-RAM GPU VM\n\n    except:\n        in_path = \".\/\"\n        tree_method = \"gpu_hist\"\n\nprint(\"Work dir:\", os.getcwd())","c89e7738":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom difflib import SequenceMatcher\nfrom itertools import combinations\nfrom tqdm import tqdm\nfrom xgboost import plot_importance, XGBRegressor\n\npd.options.display.max_rows = 50\nplt.style.use(\"seaborn\")","d76b68c4":"def compact_types(df):\n    for col in df.columns:\n        if df[col].dtype == np.float64:\n            df[col] = df[col].astype(np.float32)\n\n        elif df[col].dtype == np.int64:\n            df[col] = df[col].astype(np.int32)","e77ee4a8":"shops = pd.read_csv(in_path + \"shops.csv\", header=0, names=[\"name\", \"shop\"], index_col=\"shop\")\ncats  = pd.read_csv(in_path + \"item_categories.csv\", header=0, names=[\"name\", \"cat\"], index_col=\"cat\")\nitems = pd.read_csv(in_path + \"items.csv\", header=0, names=[\"name\", \"item\", \"cat\"], index_col=\"item\")\n\ntrain = pd.read_csv(in_path + \"sales_train.csv\", header=0,\n    names=[\"date\", \"block\", \"shop\", \"item\", \"price\", \"count\"],\n    usecols=[1, 2, 3, 4, 5]\n)\n\ntest = pd.read_csv(in_path + \"test.csv\", header=0, names=[\"ID\", \"shop\", \"item\"])","a0a10b2c":"def get_name(shop): return shops.loc[shop, \"name\"]\ndef get_label(shop): return str(shop) + \": \" + get_name(shop)\n\ndef get_sales(shop):\n    sales = train[ train[\"shop\"] == shop ].groupby(\"block\").agg(count=(\"count\", \"sum\"))\n    \n    all_blocks = sorted(train[\"block\"].unique())\n    sales = sales.reindex(index=all_blocks, fill_value=0)\n\n    return sales.index, sales[\"count\"]\n\nfor shop1, shop2 in combinations(shops.index, 2):\n    match = SequenceMatcher(a=get_name(shop1), b=get_name(shop2))\n\n    if match.ratio() > .8:\n        plt.figure(figsize=(12, 2))\n\n        x1, h1 = get_sales(shop1)\n        plt.bar(x=x1, height=h1, width=.5, label=get_label(shop1))\n        plt.yticks([])\n        plt.legend(loc=\"upper left\")\n\n        x2, h2 = get_sales(shop2)\n        plt.bar(x=x2, height=h2, width=.5, label=get_label(shop2), bottom=h1)\n        plt.yticks([])\n        plt.legend(loc=\"upper left\")","a3e031a7":"shops_to_replace = { 0: 57, 1: 58, 11: 10, 23: 24, 40: 39 }\n\ntrain[\"shop\"].replace(shops_to_replace, inplace=True)\ntest [\"shop\"].replace(shops_to_replace, inplace=True)\n\nshops.drop(index=shops_to_replace.keys(), inplace=True)","379da1a8":"test_shops = test[\"shop\"].unique()\n\nshops_to_delete = []\nfor shop in shops.index:\n    blocks = train[ train[\"shop\"] == shop ][\"block\"].nunique()\n\n    if blocks < 6:\n        plt.figure(figsize=(12, 2))\n        x, h = get_sales(shop)\n\n        if shop in test_shops:\n            plt.bar(x=x, height=h, width=.5, label=get_label(shop), color=\"red\")\n        else:\n            plt.bar(x=x, height=h, width=.5, label=get_label(shop))\n            shops_to_delete.append(shop)\n\n        plt.yticks([])\n        plt.legend(loc=\"upper left\")","3bcafa57":"print(\"Deleting shops:\", shops_to_delete)\n\ntrain = train[ ~train[\"shop\"].isin(shops_to_delete) ]\nshops.drop(index=shops_to_delete, inplace=True)","a0830910":"cities = shops[\"name\"].str.extract(\"^([^ ]+)\")[0]\nshops[\"city\"], cities = cities.factorize()\n\ncities = cities.to_frame(index=False, name=\"name\")\ncities.index.name = \"city\"\n\nprint(\"Extracted\", len(cities), \"cities\")","913bcb1f":"cats[\"is_digital\"] = cats[\"name\"].str.contains(\"\u0426\u0438\u0444\u0440\u0430\")\n\nnames = cats[\"name\"].str.replace(\" (\u0426\u0438\u0444\u0440\u0430)\", \"\", regex=False)\nsubcats = names.str.extract(\"^([^-]+)-?(.*)$\")\n\nmajors = subcats[0].str.strip()\nminors = subcats[1].str.strip()\ndel subcats\n\n# replace empty minors with majors\nminors[ minors == \"\" ] = majors[ minors == \"\" ]\n\ncats[\"major\"], majors = majors.factorize()\ncats[\"minor\"], minors = minors.factorize()\n\nmajors = majors.to_frame(index=False, name=\"name\")\nmajors.index.name = \"major\"\n\nminors = minors.to_frame(index=False, name=\"name\")\nminors.index.name = \"minor\"\n\nprint(\"Extracted\", len(majors), \"major and\", len(minors), \"minor categories\")","cf77e791":"plt.figure(figsize=(18, 4))\nplt.hist(train[\"price\"], log=True, bins=100, color=\"seagreen\", ec=\"green\");","f10fe46c":"outlier_index = (train[\"price\"] <= 0) | (train[\"price\"] > 49000)\ntrain[outlier_index]","c40e55d3":"train = train[~outlier_index]\n\nplt.figure(figsize=(18, 4))\nplt.hist(train[\"price\"], log=True, bins=100, color=\"seagreen\", ec=\"green\");","c0ed393d":"plt.figure(figsize=(18, 4))\nplt.hist(train[\"count\"], log=True, bins=100, color=\"teal\", ec=\"darkgreen\");","70e6a5a7":"train = train[ (train[\"count\"] > 0) & (train[\"count\"] <= 20) ]\n\nplt.figure(figsize=(18, 4))\nplt.hist(train[\"count\"], log=True, bins=100, color=\"teal\", ec=\"darkgreen\")\nplt.xticks(range(1, 21));","89795508":"index_names = [\"block\", \"shop\", \"item\"]\ntrain.set_index(index_names, inplace=True)\n\ntrain = train.join(shops[[\"city\"]])\ntrain = train.join(items[[\"cat\" ]])\ntrain = train.join(cats [[\"is_digital\", \"major\", \"minor\"]], on=\"cat\")\ncompact_types(train)\n\ntrain.sort_index(inplace=True)\ntrain","c0f17e36":"def get_sales(col):\n    sales = train.groupby(col).agg(\n        count=(\"count\", \"sum\"),\n        count_mean=(\"count\", \"mean\"),\n        price=(\"price\", \"mean\"),\n    )\n    sales = sales.add_prefix(col + \"_\")\n\n    compact_types(sales)\n    return sales\n\nblocks = get_sales(\"block\")\nshops  =  shops.join(get_sales(\"shop\" ))\ncities = cities.join(get_sales(\"city\" )) \nitems  =  items.join(get_sales(\"item\" ))\ncats   =   cats.join(get_sales(\"cat\"  ))\n#majors= majors.join(get_sales(\"major\"))\n#minors= minors.join(get_sales(\"minor\"))\n\ncompact_types(train)","07be41f8":"index_names = [\"block\", \"shop\", \"item\"]\n\nsales_block = train.groupby(index_names).agg(\n    block_shop_item_count=(\"count\", \"sum\"),\n    block_shop_item_count_mean=(\"count\", \"mean\"),\n    block_shop_item_price=(\"price\", \"mean\"),\n)\n\nsales_block[\"block_shop_item_count\"] = sales_block[\"block_shop_item_count\"].clip(0, 20)","cd32b3a1":"block_slices = []\nfor block in tqdm(sales_block.index.unique(0)):\n    block_slice = sales_block.loc[block : block]\n\n    shop = block_slice.index.unique(1)\n    item = block_slice.index.unique(2)\n\n    block_index = pd.DataFrame(\n        index=pd.MultiIndex.from_product([[block], shop, item], names=index_names),\n    )\n    block_slice = block_index.join(block_slice)\n\n    block_slices.append(block_slice)","d48a469f":"test_slice = test[[\"shop\", \"item\"]]\ntest_slice[\"block\"] = block + 1\ntest_slice.set_index(index_names, inplace=True)\n\nblock_slices.append(test_slice)\n\nsales_block = pd.concat(block_slices)\ndel block_slice, block_index, test_slice, block_slices\n\ncompact_types(sales_block)\nsales_block.info()","8bcc637f":"sales_block = (sales_block.join(blocks)\n    .join( shops.drop(columns=\"name\"))\n    .join(cities.drop(columns=\"name\"), on=\"city\")\n    .join( items.drop(columns=\"name\"))\n    .join(  cats.drop(columns=\"name\"), on=\"cat\")\n#   .join(majors.drop(columns=\"name\"), on=\"major\")\n#   .join(minors.drop(columns=\"name\"), on=\"minor\")\n)\n\ndel blocks, shops, cities, items, cats, majors, minors","2010eb88":"feat_names = [\"shop\", \"item\", \"city\", \"cat\"] #, \"major\", \"minor\"]\nfor feat in tqdm(feat_names):\n\n    sales_feat = train.groupby([\"block\", feat]).agg(\n        count=(\"count\", \"sum\"),\n        count_mean=(\"count\", \"mean\"),\n        price=(\"price\", \"mean\"),\n    )\n    sales_feat = sales_feat.add_prefix(\"block_\" + feat + \"_\")\n\n    sales_block = sales_block.join(sales_feat, on=[\"block\", feat])\n\n    # compute price change\n    metric = feat + \"_price\"\n    block_price = sales_block[\"block_\" + metric]\n    price = sales_block[metric]\n    sales_block[\"block_\" + metric + \"_change\"] = (block_price - price) \/ price\n\ndel sales_feat, block_price, price\ndel train\n\ncompact_types(sales_block)\nsales_block.info()","22b0380a":"lags = [1, 2, 3, 6, 12]\nlag_names = [ name for name in sales_block.columns if name.startswith(\"block_\") ]\n\nfor lag in tqdm(lags):\n\n    feat_slice = sales_block[ lag_names ].copy()\n    feat_slice.reset_index(inplace=True)\n\n    feat_slice[\"block\"] += lag\n        \n    # joining on index is much faster\n    feat_slice.set_index(index_names, inplace=True)\n    feat_slice.rename(columns=lambda name: name + \"_lag\" + str(lag), inplace=True)\n\n    sales_block = sales_block.loc[ lag : ] # discard \"pre-lag\" months\n    sales_block = sales_block.join(feat_slice)\n\ndel feat_slice\n\ncompact_types(sales_block)\nsales_block.info()","1ece3e5a":"sales_block.drop(columns=[\n    name for name in sales_block.columns\n        if \"block_\" in name and \"_lag\" not in name and name != \"block_shop_item_count\"\n], inplace=True)\n\nsales_block.reset_index(inplace=True)","1972df89":"sales_block[\"year\"] = (sales_block[\"block\"] \/\/ 12 + 2013)\nsales_block[\"month\"] = (sales_block[\"block\"] % 12 + 1)\n\ndates = sales_block[[\"year\", \"month\"]].copy()\ndates[\"day\"] = 1\nsales_block[\"days\"] = pd.to_datetime(dates).dt.daysinmonth\n\ncompact_types(sales_block)","f16084b7":"sales_block.fillna(0, inplace=True)\n\nfor name in tqdm(sales_block.columns):\n    if \"count\" in name and \"mean\" not in name and \"change\" not in name:\n        if sales_block[name].dtype != np.int32:\n            sales_block[name] = sales_block[name].astype(np.int32)\n\nsales_block.to_pickle(\"sales.pickle\")\nsales_block.info()","7f40de35":"sales_block = pd.read_pickle(\"sales.pickle\")\ntest = pd.read_csv(in_path + \"test.csv\", header=0, names=[\"ID\", \"shop\", \"item\"])\n\nsales_block = sales_block[[\n    \"block\",\n    \"shop\",\n    \"item\",\n    \"block_shop_item_count\",\n    \"city\",\n    \"cat\",\n    \"is_digital\",\n    \"major\",\n    \"minor\",\n    #\"year\",\n    \"month\",\n    \"days\",\n\n    #\"shop_count\",\n    #\"shop_count_mean\",\n    #\"shop_price\",\n    #\n    #\"city_count\",\n    #\"city_count_mean\",\n    #\"city_price\",\n    #\n    #\"item_count\",\n    #\"item_count_mean\",\n    #\"item_price\",\n    #\n    #\"cat_count\",\n    #\"cat_count_mean\",\n    #\"cat_price\",\n    #\n    \"block_shop_item_count_lag1\",\n    #\"block_shop_item_count_mean_lag1\",\n    \"block_shop_item_price_lag1\",\n    #\n    #\"block_count_lag1\",\n    \"block_count_mean_lag1\",\n    #\"block_price_lag1\",\n    #\n    #\"block_shop_count_lag1\",\n    \"block_shop_count_mean_lag1\",\n    #\"block_shop_price_lag1\",\n    \"block_shop_price_change_lag1\",\n    #\n    #\"block_item_count_lag1\",\n    \"block_item_count_mean_lag1\",\n    #\"block_item_price_lag1\",\n    \"block_item_price_change_lag1\",\n    #\n    #\"block_city_count_lag1\",\n    \"block_city_count_mean_lag1\",\n    #\"block_city_price_lag1\",\n    #\"block_city_price_change_lag1\",\n    #\n    #\"block_cat_count_lag1\",\n    \"block_cat_count_mean_lag1\",\n    #\"block_cat_price_lag1\",\n    #\"block_cat_price_change_lag1\",\n    #\n    \"block_shop_item_count_lag2\",\n    #\"block_shop_item_count_mean_lag2\",\n    #\"block_shop_item_price_lag2\",\n    #\n    #\"block_count_lag2\",\n    #\"block_count_mean_lag2\",\n    #\"block_price_lag2\",\n    #\n    #\"block_shop_count_lag2\",\n    \"block_shop_count_mean_lag2\",\n    #\"block_shop_price_lag2\",\n    #\"block_shop_price_change_lag2\",\n    #\n    #\"block_item_count_lag2\",\n    \"block_item_count_mean_lag2\",\n    #\"block_item_price_lag2\",\n    #\"block_item_price_change_lag2\",\n    #\n    #\"block_city_count_lag2\",\n    #\"block_city_count_mean_lag2\",\n    #\"block_city_price_lag2\",\n    #\"block_city_price_change_lag2\",\n    #\n    #\"block_cat_count_lag2\",\n    #\"block_cat_count_mean_lag2\",\n    #\"block_cat_price_lag2\",\n    #\"block_cat_price_change_lag2\",\n    #\n    \"block_shop_item_count_lag3\",\n    #\"block_shop_item_count_mean_lag3\",\n    #\"block_shop_item_price_lag3\",\n    #\n    #\"block_count_lag3\",\n    #\"block_count_mean_lag3\",\n    #\"block_price_lag3\",\n    #\n    #\"block_shop_count_lag3\",\n    \"block_shop_count_mean_lag3\",\n    #\"block_shop_price_lag3\",\n    #\"block_shop_price_change_lag3\",\n    #\n    #\"block_item_count_lag3\",\n    \"block_item_count_mean_lag3\",\n    #\"block_item_price_lag3\",\n    #\"block_item_price_change_lag3\",\n    #\n    #\"block_city_count_lag3\",\n    #\"block_city_count_mean_lag3\",\n    #\"block_city_price_lag3\",\n    #\"block_city_price_change_lag3\",\n    #\n    #\"block_cat_count_lag3\",\n    #\"block_cat_count_mean_lag3\",\n    #\"block_cat_price_lag3\",\n    #\"block_cat_price_change_lag3\",\n    #\n    \"block_shop_item_count_lag6\",\n    #\"block_shop_item_count_mean_lag6\",\n    #\"block_shop_item_price_lag6\",\n    #\n    #\"block_count_lag6\",\n    #\"block_count_mean_lag6\",\n    #\"block_price_lag6\",\n    #\n    #\"block_shop_count_lag6\",\n    \"block_shop_count_mean_lag6\",\n    #\"block_shop_price_lag6\",\n    #\"block_shop_price_change_lag6\",\n    #\n    #\"block_item_count_lag6\",\n    \"block_item_count_mean_lag6\",\n    #\"block_item_price_lag6\",\n    #\"block_item_price_change_lag6\",\n    #\n    #\"block_city_count_lag6\",\n    #\"block_city_count_mean_lag6\",\n    #\"block_city_price_lag6\",\n    #\"block_city_price_change_lag6\",\n    #\n    #\"block_cat_count_lag6\",\n    #\"block_cat_count_mean_lag6\",\n    #\"block_cat_price_lag6\",\n    #\"block_cat_price_change_lag6\",\n    #\n    \"block_shop_item_count_lag12\",\n    #\"block_shop_item_count_mean_lag12\",\n    #\"block_shop_item_price_lag12\",\n    #\n    #\"block_count_lag12\",\n    #\"block_count_mean_lag12\",\n    #\"block_price_lag12\",\n    #\n    #\"block_shop_count_lag12\",\n    \"block_shop_count_mean_lag12\",\n    #\"block_shop_price_lag12\",\n    #\"block_shop_price_change_lag12\",\n    #\n    #\"block_item_count_lag12\",\n    \"block_item_count_mean_lag12\",\n    #\"block_item_price_lag12\",\n    #\"block_item_price_change_lag12\",\n    #\n    #\"block_city_count_lag12\",\n    #\"block_city_count_mean_lag12\",\n    #\"block_city_price_lag12\",\n    #\"block_city_price_change_lag12\",\n    #\n    #\"block_cat_count_lag12\",\n    #\"block_cat_count_mean_lag12\",\n    #\"block_cat_price_lag12\",\n    #\"block_cat_price_change_lag12\",\n]]\nsales_block.info()","4e78ec80":"test_block = sales_block[\"block\"].max()\nvalid_block = test_block - 1\n\nX_train = sales_block[ sales_block[\"block\"] <  valid_block ].drop(columns=\"block_shop_item_count\")\ny_train = sales_block[ sales_block[\"block\"] <  valid_block ][\"block_shop_item_count\"]\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n\nX_valid = sales_block[ sales_block[\"block\"] == valid_block ].drop(columns=\"block_shop_item_count\")\ny_valid = sales_block[ sales_block[\"block\"] == valid_block ][\"block_shop_item_count\"]\nprint(\"X_valid:\", X_valid.shape, \"y_valid:\", y_valid.shape)\n\nX_test = sales_block[ sales_block[\"block\"] == test_block ].drop(columns=\"block_shop_item_count\")\nprint(\"X_test :\", X_test.shape)\n\ndel sales_block","7e4028b2":"def print_rmse(which, y_true, y_pred):\n    print(\"RMSE\", which, np.sqrt( np.square(y_true - y_pred).mean() ))","cc6baf0c":"model_xgb = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42,\n    tree_method=tree_method,\n    n_jobs=-1,\n)\nmodel_xgb.fit(\n    X_train, y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_valid, y_valid)], \n    verbose=True, \n    early_stopping_rounds=10\n)","b6f8eefe":"print_rmse(\"train\", y_train, model_xgb.predict(X_train))\nvalid_xgb = model_xgb.predict(X_valid)\nprint_rmse(\"valid\", y_valid, valid_xgb)\n\ntest_xgb = model_xgb.predict(X_test)","0fa39a11":"plt.figure(figsize=(10, 16))\nplot_importance(model_xgb, ax=plt.gca())","02d5fe10":"submission = X_test[[\"shop\", \"item\"]].copy()\nsubmission[\"item_cnt_month\"] = test_xgb.clip(0, 20)\n\nsubmission = submission.merge(test, on=[\"shop\", \"item\"])\nsubmission = submission[[\"ID\", \"item_cnt_month\"]]\n\nsubmission.sort_values(\"ID\", inplace=True)","874b6a94":"plt.figure(figsize=(12, 4))\nplt.hist(submission[\"item_cnt_month\"], bins=105)\nsubmission","9ded8fdf":"submission.to_csv(\"submission.csv\", index=False)","abb63599":"model_xgb.save_model(\"model_xgb.json\")\nX_test.to_pickle(\"X_test.pickle\")","fd62c52f":"Examine price outliers.","e556c9f3":"# Save the Model\n\nSave pre-processed `X_test` data as well, so that they can be used to reproduce the results.","d5658417":"## XGBoostRegressor","5b59ff48":"# Model Training","b01b3da3":"## Add year, month & days","2d82c339":"## Item categories\n\nExtract and encode major and minor subcategory from categories. They are separated by the dash. Additionally, some of the categories contain the word \"\u0426\u0438\u0444\u0440\u0430\", which as far as I understand means \"digital\".","4028f07f":"# EDA","fc624985":"Remove \"transient\" shops that are not in the test set.","19530637":"Extract and encode cities from shop names. First word in the shop name is the city where it is located.","bee1e288":"# Read original data","da7e00d3":"Split training set into monthly slices and create a grid with all combinations of shops and items for that month.\n\nThe reason we want to create all shop-item combinations for each month is that the training set doesn't contain any \"0 sales\" data and if we don't provide them, our model will not be able to predict zeros.\n\nIdeally we would take *all* items and *all* shops in both the training and the test sets and create *all* shop-item combinations for each month. However, this will make our dataset huge and it will most likely not fit in RAM.","903521ea":"Combine with test set.","d501570d":"There are a few sales with price > 49000 and one sale with negative price. Remove them from the training set.","0eeb80ff":"## Shops\n\nFind and examine shops with similar names.","4a18b0cf":"## Add features\n\nAdd city, category, major and minor subcategories, and is_digital to the training set.","60ff1a80":"## Sales price & count\n\nExamine training set price distribution.","b94faa38":"Find and examine \"transient\" shops that have operated for less than 6 months. Note if any of them are in the test set.","05a44987":"## Select useful features\n\nThis is probably the most daunting task.","c036276d":"Since the competition objective mandates target values to be in [0, 20] range, we'll remove all sales outside of this range.","222f3a3d":"Shops (0, 57), (1, 58), and (10, 11) are most likely the same shop, since their monthly sales distributions complement each other.\n\nWe will also go ahead and combine shops (23, 24) and (39, 40).","6ad51d16":"## Training, validation and test split","3dfd1dcd":"# Feature Encoding","e7e1f722":"Compute means and totals by block.","14311d60":"## Add time lag features\n\nAs we append lagging features, discard \"pre-lag\" months to manage memory usage.","bce483a8":"# Submission","6bed7387":"## Fill NaNs and convert counts to int","40d88afd":"## Compute totals and means\n\nCompute total & mean count, mean price and total amount for each shop, item and category.","adbee7c0":"## Remove features\n\nRemove features related to current block (since we won't have them during prediction) except for `block_shop_item_count`, which will be used as the \"y\" label.","73dc65c8":"## Compute monthly sales\n\nGroup training set into monthly shop & item combinations and compute total and mean count, mean price and total amount.\n\nClip the total count to [0, 20] range mandated by the competition objective. ","7b2c9520":"Examine training set count distribution.","64bb8975":"## Add features\n\nAdd block, shop and item totals and means."}}