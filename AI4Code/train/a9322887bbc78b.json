{"cell_type":{"17eb86ae":"code","03f7276a":"code","65d61cac":"code","7641c9a7":"code","d04fcb28":"code","f6886fc5":"code","8ea51d44":"code","ab9f3096":"code","d2369215":"code","0db40644":"code","2ad214e3":"code","0c43283d":"code","17207739":"code","ac379acf":"code","c5d9e428":"code","9f61c732":"markdown"},"source":{"17eb86ae":"#IMPORTING REQUIRED LIBRARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nfrom lightgbm.sklearn import LGBMRegressor\nfrom lightgbm.sklearn import LGBMClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.metrics import roc_auc_score,accuracy_score\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport gc\ngc.enable()\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","03f7276a":"#All functions\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n    display(df_fa.head())   \n    return(df.fillna('-'))\n\n","65d61cac":"#DATASET VIEW\npath='..\/input\/'\ndata_files=list(os.listdir(path))\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(path+x).st_size\/(1024*1024),2))\ndf_files","7641c9a7":"%%time\n#READING ONLY TRAINING SET SAMPLE\nprint('reading train dataset...')\ndf_train=pd.read_csv(path+'train.csv',nrows=100000)\n# print('reading test dataset...')\n# df_test=pd.read_csv(path+'test.csv',nrows=100000)\n# print('submission file')\n# df_submission=pd.read_csv(path+'sample_submission.csv')","d04fcb28":"#CREATING AND STORING FEATURE SUMMARY\nfs_train=feature_summary(df_train)\nwith pd.option_context('display.max_rows', 999):\n    display(fs_train)","f6886fc5":"feature_list=list(fs_train.index)\nfeature_list.remove('MachineIdentifier')\nfeature_list.remove('HasDetections')\nfeature_list.remove('AvSigVersion')\nfeature_list.remove('OsBuildLab')\nfeature_list.remove('Census_OSVersion')","8ea51d44":"%%time\nfs_train['score']=0\nmodel=LGBMClassifier(learning_rate=0.05,n_estimators=100,n_jobs=-1,reg_alpha=0.1,min_split_gain=.1,verbose=-1)\nfor feature in feature_list:\n    df=pd.read_csv(path+'train.csv',usecols=['HasDetections',feature])\n    X=df[feature]\n    y=df['HasDetections']\n    if fs_train.loc[feature,'Data_type']!='object':\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        model.fit(np.array(X_train).reshape(-1,1),y_train)\n        score=roc_auc_score(y_test,(model.predict_proba(np.array(X_test).reshape(-1,1))[:,1]))\n        \n    else:\n        X=pd.get_dummies(df[feature],prefix=feature).values\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        model.fit(X_train,y_train)\n        score=roc_auc_score(y_test,(model.predict_proba(X_test)[:,1]))\n        \n    fs_train.at[feature,'score']=score\n    print('feature:',feature,'\\tscore:\\t',score,'\\tDatatype:\\t',fs_train.loc[feature,'Data_type'])\n    gc.collect()\n    \n    ","ab9f3096":"#WRITING FS_TRAIN FILE \nfs_train.to_csv('feature_score.csv',index=False)","d2369215":"# print(X.shape,y.shape,test.shape)","0db40644":"# %%time\n# #CREATING FINAL MODEL WITH STRATIFIED KFOLDS\n# #FOLD COUNT 10\n# #TRIED XGBClassifier, LGBMClassifier, CatBoostClassifier\n# #BEST SCORE ACHIEVED BY CatBoostClassifier\n\n# model=CatBoostClassifier(iterations=1000,\n#                               learning_rate=0.05,\n#                               depth=7,\n#                               l2_leaf_reg=40,\n#                               bootstrap_type='Bernoulli',\n#                               subsample=0.7,\n#                               scale_pos_weight=5,\n#                               eval_metric='AUC',\n#                               metric_period=50,\n#                               od_type='Iter',\n#                               od_wait=45,\n#                               random_seed=17,\n#                               allow_writing_files=False)\n\n# # model= XGBClassifier(\n# #  learning_rate =0.1,\n# #  n_estimators=1000,\n# #  max_depth=5,\n# #  min_child_weight=1,\n# #  gamma=0,\n# #  subsample=0.8,\n# #  colsample_bytree=0.8,\n# #  objective= 'binary:logistic',\n# #  nthread=8,\n# #  scale_pos_weight=1,\n# #  seed=27,\n# #  n_jobs=-1)\n\n# # model=LGBMClassifier(\n# #             nthread=4,\n# #             n_estimators=1000,\n# #             learning_rate=0.02,\n# #             num_leaves=34,\n# #             colsample_bytree=0.9497036,\n# #             subsample=0.8715623,\n# #             max_depth=8,\n# #             reg_alpha=0.041545473,\n# #             reg_lambda=0.0735294,\n# #             min_split_gain=0.0222415,\n# #             min_child_weight=39.3259775,\n# #             silent=-1,\n# #             verbose=-1)\n\n# #DATAFRAMES FOR STORING PREDICTIONS ON TRAIN DATA AS WELL AS TEST DATA\n# #CAN BE USED FOR ENSEMBLE \n# df_preds=pd.DataFrame()\n# df_preds_x=pd.DataFrame()\n# k=1\n# splits=10\n# avg_score=0\n\n# #CREATING STRATIFIED FOLDS\n# skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\n# print('\\nStarting KFold iterations...')\n# for train_index,test_index in skf.split(X,y):\n#     df_X=X.iloc[train_index,:]\n#     df_y=y.iloc[train_index]\n#     val_X=X.iloc[test_index,:]\n#     val_y=y.iloc[test_index]\n\n# #FITTING MODEL\n#     model.fit(df_X,df_y)\n\n# #PREDICTING ON VALIDATION DATA\n#     col_name='cat_predsx_'+str(k)\n#     preds_x=pd.Series(model.predict_proba(val_X)[:,1])\n#     df_preds_x[col_name]=pd.Series(model.predict_proba(X)[:,1])\n\n# #CALCULATING ACCURACY\n#     acc=roc_auc_score(val_y,preds_x)\n#     print('Iteration:',k,'  roc_auc_score:',acc)\n#     if k==1:\n#         score=acc\n#         model1=model\n#         preds=pd.Series(model.predict_proba(test)[:,1])\n#         col_name='cat_preds_'+str(k)\n#         df_preds[col_name]=preds\n#     else:\n#         preds1=pd.Series(model.predict_proba(test)[:,1])\n#         preds=preds+preds1\n#         col_name='cat_preds_'+str(k)\n#         df_preds[col_name]=preds1\n#         if score<acc:\n#             score=acc\n#             model1=model\n#     avg_score=avg_score+acc        \n#     k=k+1\n# print('\\n Best score:',score,' Avg Score:',avg_score\/splits)\n# #TAKING AVERAGE OF PREDICTIONS\n# preds=preds\/splits","2ad214e3":"#PREPARING SUBMISSION\n# df_submission['target']=preds\n# df_submission","0c43283d":"#CREATING SUMBISSION FILE\n# df_submission.to_csv('submission.csv',index=False)","17207739":"# svc = svm.SVC(kernel='linear', C=1,probability=True).fit(df_preds_x,y)","ac379acf":"# df_submission2=df_submission.copy()\n# df_submission2['target']=svc.predict_proba(df_preds)[:,1]\n\n# df_submission2","c5d9e428":"# df_submission2.to_csv('submission2.csv',index=False)","9f61c732":"\n<h2>Problem Statement<\/h2>\n\nIn this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted.\n\n<br><br>\nSubmissions are scored on the <b>area under the ROC curve<\/b>. :\n\n![area under the ROC curve](https:\/\/developers.google.com\/machine-learning\/crash-course\/images\/AUC.svg)"}}