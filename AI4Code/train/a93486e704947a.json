{"cell_type":{"92e1d60f":"code","ef67c824":"code","dc10721f":"code","93d4b782":"code","7b45b3d2":"code","c750a4ff":"code","6e75424a":"code","b3ad6151":"code","f3453cae":"code","2ec0df60":"code","56b0fa40":"code","31dc6504":"markdown","d8922dd9":"markdown","792d9dd4":"markdown"},"source":{"92e1d60f":"import os\nimport sys\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom joblib import Parallel, delayed","ef67c824":"ROOT = Path.cwd().parent\nINPUT = ROOT \/ \"input\"\nDATA = INPUT \/ \"nfl-impact-detection\"\nTRAIN_VIDEOS = DATA \/ \"train\"\n\nWORK = ROOT \/ \"working\"\n\n# # save frames out of \/kaggle\/working\/ because of the HDD limitation\nTMP = ROOT \/ \"tmp\"\nTRAIN_EXTRACTED_FRAMES = TMP \/ \"nfl-impact-detection-train-frames\"\nTRAIN_EXTRACTED_FRAMES.mkdir(parents=True)","dc10721f":"TRAIN_EXTRACTED_FRAMES","93d4b782":"for video_path in sorted(TRAIN_VIDEOS.iterdir()):\n    print(video_path.name)","7b45b3d2":"def extract_frames_from_video(video_path: Path, out_root: Path):\n    \"\"\"Extract frames from one video\"\"\"\n    cap = cv2.VideoCapture(str(video_path))\n    if not cap.isOpened():\n        return\n    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    digit = len(str(int(n_frames)))\n    \n    base_name = video_path.stem\n    out_dir_path = out_root \/ base_name\n    out_dir_path.mkdir(exist_ok=True)  # make directory for video\n    print(f\"[video id: {base_name}] n_frames {n_frames}\")\n\n    ret, frame = cap.read()\n    frame_id = 1  # frame index starts from 1.\n    while ret:\n        frame_path = out_dir_path \/ \"{}_{}.png\".format(base_name, str(frame_id).zfill(digit))\n        _ = cv2.imwrite(str(frame_path), frame)\n        ret, frame = cap.read()\n        frame_id += 1","c750a4ff":"video_paths = sorted(TRAIN_VIDEOS.iterdir())\n_ = Parallel(n_jobs=4, verbose=10)(  # We can use 4 CPU cores in CPU Notebooks.\n    [delayed(extract_frames_from_video)(v_path, TRAIN_EXTRACTED_FRAMES) for v_path in video_paths])","6e75424a":"for video_dir in sorted(TRAIN_EXTRACTED_FRAMES.iterdir()):\n    print(\"video: {}.mp4,\\tn_frames: {}\".format(video_dir.name, len(list(video_dir.iterdir()))))","b3ad6151":"meta_info_list = []\nfor v_dir in sorted(TRAIN_EXTRACTED_FRAMES.iterdir()):\n    v_id = v_dir.name\n    for f_path in sorted(v_dir.iterdir()):\n        f_name = f_path.name\n        frame_id = int(f_path.stem.split(\"_\")[-1])\n        meta_info_list.append([v_id + \".mp4\", frame_id, v_id, f_name])\n        \nmeta_info_df = pd.DataFrame(\n    meta_info_list,\n    columns=[\"video\", \"frame\", \"video_id\", \"frame_name\"])\ndel meta_info_list","f3453cae":"meta_info_df.head()","2ec0df60":"meta_info_df.to_csv(TRAIN_EXTRACTED_FRAMES \/ \"train_frames.csv\", index=False)","56b0fa40":"meta_info_df.to_csv(WORK \/ \"train_frames.csv\", index=False)  # for checking","31dc6504":"## Extract frames","d8922dd9":"## create meta data csv","792d9dd4":"## About\nThis is a notebook for explanation of how I extracted frames from train videos (see: https:\/\/www.kaggle.com\/c\/nfl-impact-detection\/discussion\/201502)\n\nActualy I extracted frames in my local enviroment and uploaded them because of the limitation of Kaggle Notebooks outputs (20GB)."}}