{"cell_type":{"9b5f62cc":"code","387b33d1":"code","22db39b1":"code","90153697":"code","6e3c6b88":"code","7278d6fd":"code","3dadfdad":"code","8b935c2e":"code","3bc53cbf":"code","967e4f17":"code","1b3912b8":"code","47d93deb":"markdown","7b9706bd":"markdown","ff3c157f":"markdown","5e7908d9":"markdown","1e7a8256":"markdown","5d1bb696":"markdown","ef332f6e":"markdown","8579234f":"markdown","cac60441":"markdown"},"source":{"9b5f62cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","387b33d1":"import os\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\ntf.config.list_physical_devices('GPU') \nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'","22db39b1":"# set the matplotlib backend so figures can be saved in the background\nimport matplotlib\nmatplotlib.use(\"Agg\")\n%matplotlib inline\n\n# Import necessary modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns;\nimport pandas as pd\nimport cv2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","90153697":"# Import data from CIFAR 10 dataset\n((x_train, y_train), (x_test, y_test)) = cifar10.load_data()\n\n# Change our image type to float32 data type\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n# Normalize our data by changing the range from (0 to 255) to (0 to 1)\nx_train \/= 255\nx_test \/= 255\n\n# Reshape the labels to be 2 Dimension\ny_train = y_train.reshape(y_train.shape[0], 1)\ny_test = y_test.reshape(y_test.shape[0], 1)\n\n# Convert the labels from integers to vectors [7] --> [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\nlb = LabelBinarizer()\ny_train = lb.fit_transform(y_train)\ny_test = lb.transform(y_test)\n\n# The number of classes to predict\nclasses = y_train.shape[1]\n\n# Initialize the label names for the CIFAR-10 dataset\nlabelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n\n# The channel Dimension\nchanDim = -1\n\n# Get the input shape\nheight, width, depth = x_train[0].shape\ninputShape = (height, width, depth)\n\nprint(\"[DATA INFO]\")\nprint(\"Total Input Rows : \", x_test.shape[0])\nprint(\"Input Shape : \", inputShape)\nprint(\"Total Classes to predict : \", classes)\nprint(\"Label Names : \", labelNames)","6e3c6b88":"# Creating our data generator for our training data\ntrain_datagen = ImageDataGenerator(\n      rotation_range = 30,           # randomly applies rotations\n      width_shift_range = 0.1,       # randomly applies width shifting\n      height_shift_range = 0.2,      # randomly applies height shifting\n      shear_range = 0.2,             # randomly applies shearing\n      zoom_range=0.2,                # Zoomed by uniformly sampling in the range [0.8, 1.2]\n      horizontal_flip = True,        # randonly flips the image\n      fill_mode = 'nearest')         # uses the fill mode nearest to fill gaps created by the above","7278d6fd":"# Build LittleVGGNet\nmodel = Sequential()\n\n# First CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Second CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# First (and only) set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Softmax classifier\nmodel.add(Dense(classes))\nmodel.add(Activation(\"softmax\"))\n\nmodel.summary()","3dadfdad":"# Parameter to fit\nEPOCHS = 40\nVERBOSE = 1\nBATCH_SIZE = 64\n\ndef step_decay(epoch):\n    # Initialize the base initial learning rate, drop factor, and epochs to drop every\n    initAlpha = 0.01\n    factor = 0.25\n    dropEvery = 5\n    # Compute learning rate for the current epoch\n    alpha = initAlpha * (factor ** np.floor((1 + epoch) \/ dropEvery))\n    # Return the learning rate\n    return float(alpha)\n\n# Construct the callback to save only the *best* model to disk based on the validation loss\ncheckpoint = ModelCheckpoint(\".\/MNIST_Checkpoint.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1)\n\n# Construct the callback to stop early when model does not improve\nearlystop = EarlyStopping(monitor = 'val_loss', # value being monitored for improvement\n                          min_delta = 0, #Abs value and is the min change required before we stop\n                          patience = 6, #Number of epochs we wait before stopping \n                          verbose = 1,\n                          restore_best_weights = True)\n\ncallbacks = [checkpoint, LearningRateScheduler(step_decay)]\n\n# Compiling our model\nopt = SGD(lr=0.01, momentum=0.9, nesterov=True)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\n# Train the network\nH = model.fit(x_train, y_train, batch_size=BATCH_SIZE, validation_data=(x_test, y_test), epochs=EPOCHS, callbacks=callbacks, verbose=VERBOSE)\n\n# Use data augmentation when your model is underfitting\n# H = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE), steps_per_eopch=len(x_train) \/\/ 64, validation_data=(x_test, y_test), epochs=EPOCHS, callbacks=callbacks, verbose=VERBOSE)","8b935c2e":"# Plot the training loss and accuracy\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(8, 5))\nplt.plot(np.arange(0, 40), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, 40), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, 40), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, 40), H.history[\"val_accuracy\"], label=\"val_acc\")\n\nplt.title(\"Training Loss and Accuracy on CIFAR-10\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()\nplt.show()\n# plt.savefig(args[\"output\"])","3bc53cbf":"# Print Classification Report\npredictions = model.predict(x_test, batch_size=32).argmax(axis=1)\nprint(classification_report(y_test.argmax(axis=1),predictions))","967e4f17":"# Plot the Confusion Matrix\ncm = confusion_matrix(predictions, y_test.argmax(axis=1))\ndf_cm = pd.DataFrame(cm, index = [i for i in labelNames],\n                  columns = [i for i in labelNames])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\");","1b3912b8":"import matplotlib.pyplot as plt\nimport math\n\npreds = model.predict(x_test, batch_size=32).argmax(axis=1)\nfig = plt.figure(figsize=(13, 13))\n\nnumberToDisplay = 5\ncolumns = 3\nrows = math.ceil(numberToDisplay\/columns)\n\n# loop over the sample images\nfor i in range(numberToDisplay):\n    # load the example image, draw the prediction, and display it to our screen\n    image = x_test[i] \n    image = cv2.cvtColor(np.float32(image), cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n    cv2.putText(image, \"Label: {}\".format(labelNames[preds[i]]), (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n    fig.add_subplot(rows, columns, i+1)\n    plt.grid(b=None)\n    plt.imshow(image)","47d93deb":"<h2> Build LittleVGGNet Model","7b9706bd":"<h2> Plot the training","ff3c157f":"<h2> Create Data Augmentation","5e7908d9":"<h2> Examine The Result","1e7a8256":"<h2> Fit Our Model","5d1bb696":"<h1> <b>How to make your LittleVGGNet<\/b>","ef332f6e":"LittleVGGNet consists of two sets of **CONV => RELU => CONV => RELU => POOL**\nlayers, followed by a set of **FC => RELU => FC => SOFTMAX** layers. The first two CONV layers\nwill learn 32 filters, each of size 3\u00d73. The second two CONV layers will learn 64 filters, again, each\nof size 3\u00d73. Our POOL layers will perform max pooling over a 2\u00d72 window with a 2\u00d72 stride.\nWe\u2019ll also be inserting batch normalization layers after the activations along with dropout layers\n(DO) after the POOL and FC layers.","8579234f":"## Preprocess the Data","cac60441":"<h2>Import Modules"}}