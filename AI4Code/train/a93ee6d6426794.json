{"cell_type":{"41de53e6":"code","41e07cb8":"code","1db61f60":"code","9ae692c8":"code","d3a869a4":"code","0d1dce7c":"code","b37147a8":"code","4d4b5c64":"code","78da731e":"code","57459b77":"code","6d4d56bb":"code","6767f8d2":"code","72ccfdbe":"code","acde8ec7":"code","c8e7c663":"code","a21a862f":"code","ffb756eb":"code","8a40e6d4":"code","beb462a7":"code","d4b4a9ec":"code","7a21fd76":"code","c5550a2c":"markdown","d8aab5e4":"markdown","9ab2bcb4":"markdown","b09dc8bd":"markdown"},"source":{"41de53e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41e07cb8":"data = pd.read_csv('..\/input\/spam-classification-for-basic-nlp\/Spam Email raw text for NLP.csv', encoding='ISO-8859-2')","1db61f60":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport matplotlib.pyplot as plt\nimport re\nimport os\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","9ae692c8":"#data.dropna(inplace=True)  There is NO missing values\nchange_labels = lambda x: 1 if x==0 else 0\ndata['CATEGORY'] = data['CATEGORY'].apply(change_labels)\ndata.head()","d3a869a4":"remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)","0d1dce7c":"tokenize = lambda x: word_tokenize(x)","b37147a8":"ps = PorterStemmer()\nstem = lambda w: [ ps.stem(x) for x in w ]","4d4b5c64":"lemmatizer = WordNetLemmatizer()\nleammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]","78da731e":"print('Processing : [=', end='')\ndata['MESSAGE'] = data['MESSAGE'].apply(remove_non_alphabets)\nprint('=', end='')\ndata['MESSAGE'] = data['MESSAGE'].apply(tokenize) # [ word_tokenize(row) for row in data['MESSAGE']]\nprint('=', end='')\ndata['MESSAGE'] = data['MESSAGE'].apply(stem)\nprint('=', end='')\ndata['MESSAGE'] = data['MESSAGE'].apply(leammtizer)\nprint('=', end='')\ndata['MESSAGE'] = data['MESSAGE'].apply(lambda x: ' '.join(x))\nprint('] : Completed', end='')\ndata.head()","57459b77":"max_words = 10000\ncv = CountVectorizer(max_features=max_words, stop_words='english')\nsparse_matrix = cv.fit_transform(data['MESSAGE']).toarray()","6d4d56bb":"sparse_matrix.shape","6767f8d2":"x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(data['CATEGORY']))","72ccfdbe":"class LogisticRegression(nn.Module):\n    def __init__(self):\n        super(LogisticRegression, self).__init__()\n        self.linear1 = nn.Linear(10000, 100)\n        self.linear2 = nn.Linear(100, 10)\n        self.linear3 = nn.Linear(10, 2)\n        \n    def forward(self, x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","acde8ec7":"model = LogisticRegression()","c8e7c663":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)","a21a862f":"x_train = Variable(torch.from_numpy(x_train)).float()\ny_train = Variable(torch.from_numpy(y_train)).long()","ffb756eb":"epochs = 20\nmodel.train()\nloss_values = []\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    y_pred = model(x_train)\n    loss = criterion(y_pred, y_train)\n    loss_values.append(loss.item())\n    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n    acc = pred * 100.0 \/ len(x_train)\n    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n    loss.backward()\n    optimizer.step()","8a40e6d4":"plt.plot(loss_values)\nplt.title('Loss Value vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Loss'])\nplt.show()","beb462a7":"x_test = Variable(torch.from_numpy(x_test)).float()\ny_test = Variable(torch.from_numpy(y_test)).long()","d4b4a9ec":"model.eval()\nwith torch.no_grad():\n    y_pred = model(x_test)\n    loss = criterion(y_pred, y_test)\n    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n    print (\"Accuracy : {}%\".format(100*pred\/len(x_test)))","7a21fd76":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks to Shivam Mehta, all code by Shivam.')","c5550a2c":"#Preprocess text data\n\nRemove non words, lower it, then Tokenize, Lemmatize and Vectorize and Remove Stopwords from the data.","d8aab5e4":"#https:\/\/www.kaggle.com\/shivammehta007\/spam-not-spam-classifier-with-pytorch","9ab2bcb4":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTWlcbWivk1cRetlEM7JjvOiUSg7uYfmRe8hQ&usqp=CAU)marketbusinessnews.com","b09dc8bd":"#All script by Shivam Mehta https:\/\/www.kaggle.com\/shivammehta007\/spam-not-spam-classifier-with-pytorch"}}