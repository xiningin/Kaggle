{"cell_type":{"98a60d0a":"code","6aeaabd4":"code","4379c903":"code","97c1e706":"code","e87e0e88":"code","b9978eb3":"code","bbad046c":"code","0639a28a":"code","e92f8362":"code","debf9c23":"code","34309064":"code","e79095b2":"code","db331517":"code","ff155b13":"code","5540dd35":"code","120bd3b5":"code","971dee01":"code","c3a48a7a":"code","9b2bae9d":"code","d6aa9605":"code","88a7d924":"code","2010f7b6":"code","18f6d279":"code","e92d2ff9":"code","2e97a22e":"code","77fcd6bc":"code","471ea4c5":"code","31512ff9":"code","f46a0206":"code","cd879c51":"code","d156f346":"markdown","fe6cf7a1":"markdown","8272b62f":"markdown","239bfc1b":"markdown","1c2b1a7c":"markdown","000ff72b":"markdown","5afb68d6":"markdown","08b0d88c":"markdown","3f9a67e6":"markdown","eaa0c78b":"markdown","2554a6da":"markdown","734db2e9":"markdown","60f58102":"markdown","7e22f55b":"markdown","7c0de976":"markdown","6db36ffb":"markdown","ad4298a3":"markdown","9032bff7":"markdown","f30b4cf4":"markdown","77a7cb6a":"markdown","5d8c4e85":"markdown","8a2cea7f":"markdown","97523812":"markdown","86ec6a48":"markdown","b2b2ac8b":"markdown","097d649d":"markdown","e2b16aa5":"markdown","57d704f3":"markdown","2123009c":"markdown"},"source":{"98a60d0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6aeaabd4":"import numpy as np\nimport pandas as pd\nimport os\nfrom datetime import datetime\n\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom plotly.subplots import make_subplots\nfrom plotly.graph_objs import Line\n\nfrom scipy import stats\nimport seaborn as sns","4379c903":"# Data Paths\ndaily_eurusd_df = pd.read_csv(\"..\/input\/xauusdxaueureurusd-daily\/data\/EUR_USD Historical Data.csv\")\nxau_eur_df = pd.read_csv(\"..\/input\/xauusdxaueureurusd-daily\/data\/XAU_EUR Historical Data (2).csv\")\nxau_usd_df = pd.read_csv(\"..\/input\/xauusdxaueureurusd-daily\/data\/XAU_USD Historical Data (1).csv\")\noil_df = pd.read_csv(\"..\/input\/crude-oil-prices\/Oil_Prices.csv\")\nusd_index_df = pd.read_csv(\"..\/input\/us-dollar-index\/US Dollar Index Futures Historical Data.csv\")\nus_interest_rates = pd.read_csv(\"..\/input\/historical-fed-funds\/fed-funds-rate-historical-chart_Mar2021.csv\")\ngold_prices_df = pd.read_csv(\"..\/input\/gold-and-silver-prices-dataset\/gold_price.csv\")\ndaily_usdjpy_df = pd.read_csv(\"..\/input\/usdjpy-historical-data-2014-2021\/USD_JPY Historical Data.csv\")\nvix_df = pd.read_csv(\"..\/input\/cboe-vix-historical-data-2014-2021\/CBOE Volatility Index Historical Data.csv\")\nsnp_500_df = pd.read_csv(\"..\/input\/sp-500-historical-data-2014-2021\/SP 500 Historical Data.csv\")","97c1e706":"# Renaming Columns For Merging Later on\n\ndaily_eurusd_df.rename(columns = {'Price' : 'EURUSD_Price', 'Open' : 'EURUSD_Open', \"High\":\"EURUSD_High\", \"Low\":\"EURUSD_Low\", \"Change %\":\"EURUSD_Change%\"}, inplace = True)\nxau_usd_df.rename(columns = {'Price' : 'XAUUSD_Price', 'Open' : 'XAUUSD_Open', \"High\":\"XAUUSD_High\", \"Low\":\"XAUUSD_Low\", \"Change %\":\"XAUUSD_Change%\"}, inplace = True)\nxau_eur_df.rename(columns = {'Price' : 'XAUEUR_Price', 'Open' : 'XAUEUR_Open', \"High\":\"XAUEUR_High\", \"Low\":\"XAUEUR_Low\", \"Change %\":\"XAUEUR_Change%\"}, inplace = True)","e87e0e88":"def modify_datetime(df_column):\n    \"\"\"\n    Changes Date Format from Feb 08, 2020 --> 08\/02\/2020 [dd\/mm\/YYYY]\n    \"\"\"\n    df_column[\"Date\"] = df_column[\"Date\"].apply(lambda x:datetime.strptime(x.lower().replace(\",\", \"\"), \"%b %d %Y\").strftime(\"%d\/%m\/%Y\"))\n    return df_column[\"Date\"]\n\n\ndef remove_comma(df_column, column_name):\n    \"\"\"\n    Removes Comma from Prices E.g [1,234,234 --> 1234234]\n    \"\"\"\n    try:\n        df_column[column_name] = df_column[column_name].apply(lambda x: x.replace(\",\", \"\"))\n        return df_column[column_name]\n    except:\n        return df_column[column_name]\n\n\ndaily_eurusd_df[\"Date\"] = modify_datetime(daily_eurusd_df)\nprint(\"No. of Data Points (EURUSD) :\", len(daily_eurusd_df))\n\nxau_usd_df[\"Date\"] = modify_datetime(xau_usd_df)\nprint(\"No. of Data Points (XAUUSD) :\", len(xau_usd_df))\n\nxau_eur_df[\"Date\"] = modify_datetime(xau_eur_df)\nprint(\"No. of Data Points (XAUEUR) :\", len(xau_eur_df))","b9978eb3":"# Merging all the Dataframes together \nmerge_df = pd.merge(daily_eurusd_df, xau_usd_df, how=\"outer\", on=\"Date\")\nmerge_df = pd.merge(merge_df, xau_eur_df, how=\"outer\", on=\"Date\")\n# Re-Fromatting Dataframe\nmerge_df.dropna(inplace=True)\nmerge_df = merge_df[::-1].reset_index()\ndel merge_df[\"index\"]\n# Removes Commas from Columns we need\nmerge_df[\"XAUUSD_Price\"] = remove_comma(merge_df, \"XAUUSD_Price\")\nmerge_df[\"XAUEUR_Price\"] = remove_comma(merge_df, \"XAUEUR_Price\")\n# Make an archive\/copyy of the original dataframe\n_merge_df = merge_df.copy()","bbad046c":"\"\"\"Mean Price\"\"\"\n\nmean_eurusd = merge_df[\"EURUSD_Price\"].mean()\nmean_xauusd = merge_df[\"XAUUSD_Price\"].astype(np.float).mean()\nmean_xaueur = merge_df[\"XAUEUR_Price\"].astype(np.float).mean()\n\n\n\"\"\"Mode Price\"\"\"\n\nmode_eurusd = merge_df[\"EURUSD_Price\"].mode().tolist()\nmode_xauusd = merge_df[\"XAUUSD_Price\"].mode().astype(float).tolist()\nmode_xaueur = merge_df[\"XAUEUR_Price\"].mode().astype(float).tolist()\n\n\n\"\"\"Plotting Candlestick Graphs with Mean and Mode Values\"\"\"\n\nfig = go.Figure(data=[go.Candlestick(x=merge_df['Date'],\n                open=merge_df['EURUSD_Open'],\n                high=merge_df['EURUSD_High'],\n                low=merge_df['EURUSD_Low'],\n                close=merge_df['EURUSD_Price'],\n                name=\"Candlestick Graph\")])\n\nfor i in mode_eurusd:\n    x = np.array([\"02\/01\/2014\", \"08\/02\/2021\"])\n    y = np.array([i, i])\n    fig.add_trace(go.Scatter(x=x, y=y, name=\"Mode Value(s)\",mode='lines'))\n\nx = np.array([\"02\/01\/2014\", \"08\/02\/2021\"])\ny = np.array([mean_eurusd, mean_eurusd])\nfig.add_trace(go.Scatter(x=x, y=y, name=\"Mean Value\",line=dict(color='red', width=1.5, dash='dot')))\n\nfig.update_layout(showlegend=True)\nfig.update_layout(xaxis_rangeslider_visible=False)\nfig.update_layout(height=600, width=1000, title_text=\"EURUSD Chart\")\n\nfig.show()\nprint(\"Mean EURUSD Price (Jan 2014 - Feb 2021) :\", round(mean_eurusd, 4))\nprint(\"Mode EURUSD Price(s) (Jan 2014 - Feb 2021) :\", mode_eurusd)","0639a28a":"# Overview of Data\nsns.displot(merge_df['EURUSD_Price'])\n\n\"\"\"\nSkewness is a measure of the symmetrical nature of data. \n\nKurtosis is a measure of how heavy-tailed or light-tailed the data is relative to a normal distribution.\n\"\"\"\nprint(\"Skewness: %f\" % merge_df['EURUSD_Price'].skew())\nprint(\"Kurtosis: %f\" % merge_df['EURUSD_Price'].kurt())","e92f8362":"fig = go.Figure(data=[go.Candlestick(x=merge_df['Date'],\n                open=merge_df['XAUUSD_Open'],\n                high=merge_df['XAUUSD_High'],\n                low=merge_df['XAUUSD_Low'],\n                close=merge_df['XAUUSD_Price'],\n                name=\"Candlestick Graph\")])\n\nfor i in mode_xauusd:\n    x = np.array([\"02\/01\/2014\", \"08\/02\/2021\"])\n    y = np.array([i, i])\n    fig.add_trace(go.Scatter(x=x, y=y, name=\"Mode Value(s)\",mode='lines'))\n\nx = np.array([\"02\/01\/2014\", \"08\/02\/2021\"])\ny = np.array([mean_xauusd, mean_xauusd])\nfig.add_trace(go.Scatter(x=x, y=y, name=\"Mean Value\",line=dict(color='red', width=1.5, dash='dot')))\n\nfig.update_layout(showlegend=True)  \nfig.update_layout(xaxis_rangeslider_visible=False)\nfig.update_layout(height=600, width=1000, title_text=\"XAUUSD Chart\")\n\nfig.show()\nprint(\"Mean XAUUSD Price (Jan 2014 - Feb 2021) :\", round(mean_xauusd, 2))\nprint(\"Mode XAUUSD Price(s) (Jan 2014 - Feb 2021) :\", mode_xauusd)\n\n\n\nfig = go.Figure(data=[go.Candlestick(x=merge_df['Date'],\n                open=merge_df['XAUEUR_Open'],\n                high=merge_df['XAUEUR_High'],\n                low=merge_df['XAUEUR_Low'],\n                close=merge_df['XAUEUR_Price'],\n                name=\"Candlestick Graph\")])\n\nfor i in mode_xaueur:\n    x = np.array([\"02\/01\/2014\", \"08\/02\/2021\"])\n    y = np.array([i, i])\n    fig.add_trace(go.Scatter(x=x, y=y, name=\"Mode Value(s)\",mode='lines'))\n\nx = np.array([\"02\/01\/2014\", \"08\/02\/2021\"])\ny = np.array([mean_xaueur, mean_xaueur])\nfig.add_trace(go.Scatter(x=x, y=y, name=\"Mean Value\",line=dict(color='red', width=1.5, dash='dot')))\n\nfig.update_layout(showlegend=True)  \nfig.update_layout(xaxis_rangeslider_visible=False)\nfig.update_layout(height=600, width=1000, title_text=\"XAUEUR Chart\")\n\nfig.show()\nprint(\"Mean XAUEUR Price (Jan 2014 - Feb 2021) :\", round(mean_xaueur, 2))\nprint(\"Mode XAUEUR Price(s) (Jan 2014 - Feb 2021) :\", mode_xaueur)","debf9c23":"# Finding the Difference Between XAUUSD and XAUEUR\nmerge_df[\"XAUUSD_XAUEUR_Diff_Price\"] = (merge_df[\"XAUUSD_Price\"].astype(float) - merge_df[\"XAUEUR_Price\"].astype(float))\nmerge_df[\"XAUEUR \/ XAUUSD Price\"] = (merge_df[\"XAUUSD_Price\"].astype(float) \/ merge_df[\"XAUEUR_Price\"].astype(float))","34309064":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.XAUUSD_XAUEUR_Diff_Price, name=\"EUR and USD Currency Strength\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.EURUSD_Price, name=\"EUR\/USD\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"EUR\/USD Versus EUR and USD Currency Strength\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>EUR and USD Currency Strength<\/b>\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>EUR\/USD<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\nprint(\"Correlation Between Currency Strength of EUR and USD (XAUEUR - XAUUSD) and EUR\/USD :\", round(stats.pearsonr(merge_df.XAUUSD_XAUEUR_Diff_Price, merge_df.EURUSD_Price)[0],4))","e79095b2":"# Oil Dataframe\noil_df = pd.read_csv(\"..\/input\/crude-oil-prices\/Oil_Prices.csv\")\noil_df.rename(columns = {'Close\/Last' : 'Oil_Price', 'Volume' : 'Oil_Volume', \"Open\": \"Oil_Open\", \"High\":\"Oil_High\", \"Low\":\"Oil_Low\"}, inplace=True)\noil_df = oil_df[::-1].reset_index()\ndel oil_df[\"index\"]\noil_df = oil_df[712:]\noil_df[\"Date\"] = oil_df[\"Date\"].apply(lambda x:datetime.strptime(x, \"%m\/%d\/%Y\").strftime(\"%d\/%m\/%Y\"))\noil_df.reset_index()\n\n# Gold Dataframe\ngold_prices_df = pd.read_csv(\"..\/input\/gold-and-silver-prices-dataset\/gold_price.csv\")\ngold_prices_df.rename(columns={\"date\":\"Date\", \"price\": \"Gold_Price\"}, inplace=True)\ngold_prices_df[\"Date\"] = gold_prices_df[\"Date\"].apply(lambda x:datetime.strptime(x, \"%Y-%m-%d\").strftime(\"%d\/%m\/%Y\"))\ngold_prices_df = gold_prices_df.dropna()\n# us_interest_rates = us_interest_rates[us_interest_rates['Date'].between(\"02\/01\/2014\", \"08\/02\/2021\")]\nstart_date = \"02\/01\/2014\"\nend_date = \"08\/02\/2021\"\ngold_prices_df = gold_prices_df[gold_prices_df[gold_prices_df.Date==(start_date)].index[0] : gold_prices_df[gold_prices_df.Date==(end_date)].index[0]+1].reset_index().drop(\"index\", axis=1)\n\n# USDX Dataframe\nusd_index_df = pd.read_csv(\"..\/input\/us-dollar-index\/US Dollar Index Futures Historical Data.csv\")\nmodify_datetime(usd_index_df)\nusd_index_df.rename(columns = {'Price' : 'USDX_Price', \"Open\": \"USDX_Open\", \"High\":\"USDX_High\", \"Low\":\"USDX_Low\", \"Vol.\":\"USDX_Vol\", \"Change %\":\"USDX_Change%\"}, inplace=True)\n\n# US Interest Rates\nus_interest_rates = pd.read_csv(\"..\/input\/historical-fed-funds\/fed-funds-rate-historical-chart_Mar2021.csv\")\nus_interest_rates.rename(columns={\"date\":\"Date\", \" value\": \"US_Interest_Rates_Value\"}, inplace=True)\nus_interest_rates[\"Date\"] = us_interest_rates[\"Date\"].apply(lambda x:datetime.strptime(x, \"%m\/%d\/%Y\").strftime(\"%d\/%m\/%Y\"))\nus_interest_rates = us_interest_rates.dropna()\n# us_interest_rates = us_interest_rates[us_interest_rates['Date'].between(\"02\/01\/2014\", \"08\/02\/2021\")]\nstart_date = \"02\/01\/2014\"\nend_date = \"08\/02\/2021\"\nus_interest_rates = us_interest_rates[us_interest_rates[us_interest_rates.Date==(start_date)].index[0] : us_interest_rates[us_interest_rates.Date==(end_date)].index[0]+1].reset_index().drop(\"index\", axis=1)\n\n# Merging Dataframe\nmerge_df = pd.merge(merge_df, oil_df, how=\"left\", on=\"Date\")\nmerge_df = pd.merge(merge_df, gold_prices_df, how=\"left\", on=\"Date\")\nmerge_df = pd.merge(merge_df, usd_index_df, how=\"left\", on=\"Date\")\nmerge_df = pd.merge(merge_df, us_interest_rates, how=\"left\", on=\"Date\")\nmerge_df[\"Gold\/Oil\"] = merge_df[\"Gold_Price\"] \/ merge_df[\"Oil_Price\"]","db331517":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Gold_Price, name=\"Gold Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.EURUSD_Price, name=\"EURUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold Prices Versus EURUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>EURUSD<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Gold_Price, name=\"Gold Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.XAUUSD_XAUEUR_Diff_Price, name=\"XAUEUR - XAUUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold Prices Versus XAUEUR - XAUUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>XAUUSD_XAUEUR_Diff<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Gold_Price, name=\"Gold Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"XAUEUR \/ XAUUSD Price\"], name=\"XAUEUR \/ XAUUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold Prices Versus XAUEUR\/XAUUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>XAUEUR\/XAUUSD<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Gold_Price, name=\"Gold Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.USDX_Price, name=\"USDX Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold Prices Versus USDX Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>USDX<\/b> Prices\", secondary_y=True)\n\nfig.show()","ff155b13":"merge_df.corr(method='pearson')\ncorr_df = merge_df[[\"Gold_Price\", \"USDX_Price\", \"EURUSD_Price\", \"XAUEUR \/ XAUUSD Price\", \"XAUUSD_XAUEUR_Diff_Price\"]]\n\n# Correlation Heatmap\ncorrmat = corr_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nax.set_title(\"Correlation Heatmap\")\nsns.heatmap(corrmat, square=True, annot=True)","5540dd35":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Oil_Price, name=\"Oil Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.EURUSD_Price, name=\"EURUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Oil Prices Versus EURUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>EURUSD<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Oil_Price, name=\"Oil Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.XAUUSD_XAUEUR_Diff_Price, name=\"XAUEUR - XAUUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Oil Prices Versus XAUEUR - XAUUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>XAUUSD_XAUEUR_Diff<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Oil_Price, name=\"Oil Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"XAUEUR \/ XAUUSD Price\"], name=\"XAUEUR \/ XAUUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Oil Prices Versus XAUEUR\/XAUUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>XAUEUR\/XAUUSD<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Oil_Price, name=\"Oil Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.USDX_Price, name=\"USDX Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Oil Prices Versus USDX Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>USDX<\/b> Prices\", secondary_y=True)\n\nfig.show()","120bd3b5":"merge_df.corr(method='pearson')\ncorr_df = merge_df[[\"Oil_Price\", \"USDX_Price\", \"EURUSD_Price\", \"XAUEUR \/ XAUUSD Price\", \"XAUUSD_XAUEUR_Diff_Price\"]]\n\n# Correlation Heatmap\ncorrmat = corr_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nax.set_title(\"Correlation Heatmap\")\n\nsns.heatmap(corrmat, square=True, annot=True)","971dee01":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Gold_Price, name=\"Gold Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Oil_Price, name=\"Oil Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold Prices Versus Oil Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>Oil<\/b> Prices\", secondary_y=True)\n\nfig.show()","c3a48a7a":"merge_df.corr(method='pearson')\n\n\n# Adjust Correlation Dataframe\ncorr_df = merge_df[[\"Gold_Price\", \"Oil_Price\"]]\n\n# Correlation Heatmap\ncorrmat = corr_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nax.set_title(\"Gold and Oil Prices Correlation Heatmap\")\n\nsns.heatmap(corrmat, square=True, annot=True)","9b2bae9d":"# Overview of Data\nsns.displot(merge_df['Gold\/Oil'])\n\nprint(\"Skewness: %f\" % merge_df['Gold\/Oil'].skew())\nprint(\"Kurtosis: %f\" % merge_df['Gold\/Oil'].kurt())\nprint(merge_df['Gold\/Oil'].describe())","d6aa9605":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"Gold\/Oil\"], name=\"Gold\/Oil\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.US_Interest_Rates_Value, name=\"US Interest Rate\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold\/Oil Prices Versus US Interest Rates\"\n)\n\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold\/Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>US Interest Rates<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"Gold\/Oil\"], name=\"Gold\/Oil\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.EURUSD_Price, name=\"EURUSD Price\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold\/Oil Prices Versus EURUSD Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold\/Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>EURUSD<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"Gold\/Oil\"], name=\"Gold\/Oil\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Gold_Price, name=\"Gold Price\"),\n    secondary_y=True,\n)\n\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold\/Oil Prices Versus Gold Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold\/Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"Gold\/Oil\"], name=\"Gold\/Oil\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.Oil_Price, name=\"Oil Price\"),\n    secondary_y=True,\n)\n\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold\/Oil Prices Versus Oil Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold\/Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>Gold<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"Gold\/Oil\"], name=\"Gold\/Oil\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.USDX_Price, name=\"USDX Price\"),\n    secondary_y=True,\n)\n\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Gold\/Oil Prices Versus USDX Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Gold\/Oil<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>USDX<\/b> Prices\", secondary_y=True)\n\nfig.show()","88a7d924":"merge_df.corr(method='pearson')\n\n\n# Adjust Correlation Dataframe\ncorr_df = merge_df[[\"Gold\/Oil\", \"US_Interest_Rates_Value\", \"EURUSD_Price\", \"USDX_Price\", \"Gold_Price\", \"Oil_Price\"]]\n\n\n# Correlation Heatmap\ncorrmat = corr_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, square=True, annot=True)","2010f7b6":"daily_usdjpy_df[\"Date\"] = modify_datetime(daily_usdjpy_df)\nvix_df[\"Date\"] = modify_datetime(vix_df)\nsnp_500_df[\"Date\"] = modify_datetime(snp_500_df)\n\ndaily_usdjpy_df.rename(columns = {'Price' : 'USDJPY_Price', \"Open\": \"USDJPY_Open\", \"High\":\"USDJPY_High\", \"Low\":\"USDJPY_Low\", \"Change %\":\"USDJPY_Change %\"}, inplace=True)\nvix_df.rename(columns = {'Price' : 'VIX_Price', \"Open\": \"VIX_Open\", \"High\":\"VIX_High\", \"Low\":\"VIX_Low\", \"Change %\":\"VIX_Change %\"}, inplace=True)\nsnp_500_df.rename(columns = {'Price' : 'S&P500_Price', \"Open\": \"S&P500_Open\", \"High\":\"S&P500_High\", \"Low\":\"S&P500_Low\", \"Change %\":\"S&P500_Change %\"}, inplace=True)\n\nmerge_df = pd.merge(merge_df, daily_usdjpy_df, how=\"left\", on=\"Date\")\nmerge_df = pd.merge(merge_df, vix_df, how=\"left\", on=\"Date\")\nmerge_df = pd.merge(merge_df, snp_500_df, how=\"left\", on=\"Date\")","18f6d279":"merge_df[\"S&P500_Price\"] = merge_df[\"S&P500_Price\"].astype(str)\nmerge_df[\"S&P500_Price\"] = remove_comma(merge_df, \"S&P500_Price\")\nmerge_df[\"S&P500_Price\"] = merge_df[\"S&P500_Price\"].astype(float)","e92d2ff9":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"S&P500_Price\"], name=\"S&P500 Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.USDJPY_Price, name=\"USDJPY Price\"),\n    secondary_y=True,\n)\n\n\n# Add figure title\nfig.update_layout(\n    title_text=\"S&P500 Prices Versus USDJPY Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>S&P500<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>USDJPY<\/b> Prices\", secondary_y=True)\n\nfig.show()\n\n\n\n\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df[\"S&P500_Price\"], name=\"S&P500 Price\"),\n    secondary_y=False,\n)\nfig.add_trace(\n    go.Scatter(x=merge_df.Date, y=merge_df.VIX_Price, name=\"VIX Price\"),\n    secondary_y=True,\n)\n\n\n# Add figure title\nfig.update_layout(\n    title_text=\"S&P500 Prices Versus VIX Prices\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>S&P500<\/b> Prices\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>VIX<\/b> Prices\", secondary_y=True)\n\nfig.show()","2e97a22e":"merge_df.corr(method='pearson')\n\n\n# Adjust Correlation Dataframe\ncorr_df = merge_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\"]]\n\n# Correlation Heatmap\ncorrmat = corr_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nax.set_title(\"S&P500 \/ VIX \/ USDJPY Prices Correlation Heatmap\")\n\nsns.heatmap(corrmat, square=True, annot=True)","77fcd6bc":"from sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom mpl_toolkits.mplot3d import Axes3D\nimport datetime as dt\nimport matplotlib.dates as mdates\n\n\nclf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.05),\n                        max_features=1.0, n_jobs=-1, random_state=42)\nanomaly_df = merge_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\", \"Date\"]].dropna()\n\n\nclf.fit(anomaly_df[[\"USDJPY_Price\", \"VIX_Price\"]])\npred = clf.predict(anomaly_df[[\"USDJPY_Price\", \"VIX_Price\"]])\n\nanomaly_df['anomaly'] = pred\nanomaly_df = anomaly_df.reset_index()\noutliers = anomaly_df.loc[anomaly_df['anomaly']==-1]\nout_test_index = list(outliers.index)\noutlier_index = list(outliers[\"index\"].index)\nse = anomaly_df['anomaly'].value_counts()\n_se_list = [\"Normal Points\", \"Anomalies\"]\nse.index = _se_list\nse = se.rename(\"Number of Anomalies\")\nprint(se)\n\n\nX = anomaly_df[[\"USDJPY_Price\", \"VIX_Price\", \"Date\"]]\nb1 = plt.scatter(X[\"Date\"], X[\"USDJPY_Price\"], c='green',\n                 s=3, label=\"Normal Points\")\n\nb2 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"USDJPY_Price\"], c='green',s=6, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"USDJPY Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()\n\nb3 = plt.scatter(X[\"Date\"], X[\"VIX_Price\"], c='green',\n                 s=5,label=\"Normal Points\")\n\nb4 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"VIX_Price\"], c='green',s=10, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"VIX Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()","471ea4c5":"from sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nclf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.1),\n                        max_features=1.0, n_jobs=-1, random_state=42)\nanomaly_df = merge_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\", \"Date\"]].dropna()\n\n\nclf.fit(anomaly_df[[\"USDJPY_Price\", \"VIX_Price\"]])\npred = clf.predict(anomaly_df[[\"USDJPY_Price\", \"VIX_Price\"]])\n\nanomaly_df['anomaly'] = pred\nanomaly_df = anomaly_df.reset_index()\noutliers = anomaly_df.loc[anomaly_df['anomaly']==-1]\nout_test_index = list(outliers.index)\noutlier_index = list(outliers[\"index\"].index)\nse = anomaly_df['anomaly'].value_counts()\n_se_list = [\"Normal Points\", \"Anomalies\"]\nse.index = _se_list\nse = se.rename(\"Number of Anomalies\")\nprint(se)\n\n\nX = anomaly_df[[\"USDJPY_Price\", \"VIX_Price\", \"Date\"]]\nb1 = plt.scatter(X[\"Date\"], X[\"USDJPY_Price\"], c='green',\n                 s=3,label=\"Normal Points\")\n\nb2 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"USDJPY_Price\"], c='green',s=6, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"USDJPY Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()\n\nb3 = plt.scatter(X[\"Date\"], X[\"VIX_Price\"], c='green',\n                 s=5,label=\"Normal Points\")\n\nb4 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"VIX_Price\"], c='green',s=10, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"VIX Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()","31512ff9":"from sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nclf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.05),\n                        max_features=1.0, n_jobs=-1, random_state=42)\nanomaly_df = merge_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\", \"Date\"]].dropna()\n\n\nclf.fit(anomaly_df[[\"S&P500_Price\", \"VIX_Price\"]])\npred = clf.predict(anomaly_df[[\"S&P500_Price\", \"VIX_Price\"]])\n\nanomaly_df['anomaly'] = pred\nanomaly_df = anomaly_df.reset_index()\noutliers = anomaly_df.loc[anomaly_df['anomaly']==-1]\nout_test_index = list(outliers.index)\noutlier_index = list(outliers[\"index\"].index)\nse = anomaly_df['anomaly'].value_counts()\n_se_list = [\"Normal Points\", \"Anomalies\"]\nse.index = _se_list\nse = se.rename(\"Number of Anomalies\")\nprint(se)\n\nX = anomaly_df[[\"S&P500_Price\", \"VIX_Price\", \"Date\"]]\nb1 = plt.scatter(X[\"Date\"], X[\"S&P500_Price\"], c='green',\n                 s=3,label=\"Normal Points\")\n\nb2 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"S&P500_Price\"], c='green',s=6, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"S&P 500 Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()\n\nb3 = plt.scatter(X[\"Date\"], X[\"VIX_Price\"], c='green',\n                 s=5,label=\"Normal Points\")\n\nb4 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"VIX_Price\"], c='green',s=10, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"VIX Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()","f46a0206":"from sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nclf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.1),\n                        max_features=1.0, n_jobs=-1, random_state=42)\nanomaly_df = merge_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\", \"Date\"]].dropna()\n\n\nclf.fit(anomaly_df[[\"S&P500_Price\", \"VIX_Price\"]])\npred = clf.predict(anomaly_df[[\"S&P500_Price\", \"VIX_Price\"]])\n\nanomaly_df['anomaly'] = pred\nanomaly_df = anomaly_df.reset_index()\noutliers = anomaly_df.loc[anomaly_df['anomaly']==-1]\nout_test_index = list(outliers.index)\noutlier_index = list(outliers[\"index\"].index)\nse = anomaly_df['anomaly'].value_counts()\n_se_list = [\"Normal Points\", \"Anomalies\"]\nse.index = _se_list\nse = se.rename(\"Number of Anomalies\")\nprint(se)\n\n\nX = anomaly_df[[\"S&P500_Price\", \"VIX_Price\", \"Date\"]]\nb1 = plt.scatter(X[\"Date\"], X[\"S&P500_Price\"], c='green',\n                 s=3,label=\"Normal Points\")\n\nb2 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"S&P500_Price\"], c='green',s=6, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"S&P500 Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()\n\nb3 = plt.scatter(X[\"Date\"], X[\"VIX_Price\"], c='green',\n                 s=5,label=\"Normal Points\")\n\nb4 = plt.scatter(X.loc[outlier_index,\"Date\"], X.loc[outlier_index,\"VIX_Price\"], c='green',s=10, edgecolor=\"red\", label=\"Predicted Outlieres\")\n\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"VIX Price\")\nplt.xticks(rotation=90)\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))\nplt.gca().xaxis.set_minor_locator(mdates.DayLocator(30))\n\nplt.show()","cd879c51":"from sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nclf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.05), \\\n                        max_features=1.0, n_jobs=-1, random_state=42)\nanomaly_df = merge_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\", \"Date\"]].dropna()\n\nclf.fit(anomaly_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\"]])\npred = clf.predict(anomaly_df[[\"S&P500_Price\", \"VIX_Price\", \"USDJPY_Price\"]])\n\nanomaly_df['anomaly'] = pred\nanomaly_df = anomaly_df.reset_index()\noutliers = anomaly_df.loc[anomaly_df['anomaly']==-1]\noutlier_index = list(outliers[\"index\"].index)\nse = anomaly_df['anomaly'].value_counts()\n_se_list = [\"Normal Points\", \"Anomalies\"]\nse.index = _se_list\nse = se.rename(\"Number of Anomalies\")\nprint(se)\n\n\nX = anomaly_df.to_numpy()\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.set_xlabel(\"S&P500_Price\")\nax.set_ylabel(\"VIX_Price\")\nax.set_zlabel(\"USDJPY_Price\")\n\nax.scatter(X[:, 0], X[:, 1], X[:, 2], s=4, lw=1, label=\"Inliers\",c=\"green\")\nax.scatter(X[outlier_index,0],X[outlier_index,1], X[outlier_index,2],\n           lw=2, s=60, marker=\"x\", c=\"red\", label=\"outliers\")\nax.legend()\nplt.show()","d156f346":"### Data Paths <a name=\"data_paths\"><\/a> \n","fe6cf7a1":"**Isolation Forest [VIX, S&P500, USD\/JPY] (0.05 Contamination)**","8272b62f":"It seems like Gold correlation with our Data is rather weak, now us let us look at **Oil's Correlation with out Data**","239bfc1b":"**Isolation Forest [VIX, S&P500] (0.05 Contamination)**","1c2b1a7c":"Let us first look at **Gold's Correlation with out Data**","000ff72b":"#### *Anomaly Detection in Market Risk Appetite* <a name=\"anomaly_detection\"><\/a>","5afb68d6":"Although there doesn't seem to be many close correlations with Gold\/Oil Prices with the rest of our data, the Gold\/Oil Price is nevertheless an important factor to look at. \n\nGold and Oil are generally thought to be inverse to the Dollar. Gold acts as a \"safe haven\" investment in crises while Oil's inverse relationship with the dollar stems from it being priced in USD, where when the dollar rises, fewer US Dollars are required to purchase a barrel of oil.\n\nNoting the obvious difference for their inverse relationship with the Dollar, the Gold\/Oil Ratio allows us to pinpoint a specific reason\/event for the price movement of the Dollar. ","08b0d88c":"### Libraries <a name=\"libraries\"><\/a>","3f9a67e6":"<img src= \"https:\/\/www.hedgethink.com\/wp-content\/uploads\/2020\/09\/e4367cfd7833fa17a680a30b7c32cd9f-1024x576.jpg\" alt =\"Forex\" style='width: 200px;'>\n<sub>Source : https:\/\/www.hedgethink.com\/wp-content\/uploads\/2020\/09\/e4367cfd7833fa17a680a30b7c32cd9f-1024x576.jpg<\/sub>","eaa0c78b":"## **Data Analysis** <a name=\"data_analysis\"><\/a>\nIn this section we will do a simple analysis of our data that may help us later on in our **Data Exploration**","2554a6da":"### Currency Strength in relation to Gold <a name=\"curr_strength\"><\/a>\n\nCurrency Strength is often used as an indicator to aid in trading. However, there are many ways to define a currency's strength. Some open source currency strength meters available measure the strength of each currency in relation to USD then ranks the major currency pairs accordingly. This presents a more biased view of currency strength due to the heavy influence of USD involved and thus a greater influence of events occurring in USA. Take for example a rise in AUDUSD does not necessarily suggest an improving AUD but could instead be a negtive fundamental change that is occurring in USA. Thus, it is essential that we avoid using other currencies as a standard to measure currency strength.\n\nPerhaps looking at the currencies in terms of Gold provides a less biased outlook of currency strength. In this section, we look at how closely correlated EUR\/USD is against their currency strengths in relation to Gold\n","734db2e9":"### Statistics <a name=\"statistics\"><\/a>","60f58102":"Above are just some of the ways that one can make sense of given market data to draw conclusions and make better trading decision. There will be more in depth to discuss each section in future notebooks","7e22f55b":"### Gold \/ Oil Ratio <a name=\"gold_oil_ratio\"><\/a>\n\n","7c0de976":"EUR and USD Currency Strength is taken as (XAUEUR - XAUUSD) in this case","6db36ffb":"I think its natural that we expect a positive correlation between the S&P500 Price and USD\/JPY Price as JPY often act as a safe haven asset during times of increasing risk. This is however not the case in the period of 2015 - 2021 that we are analysing. On the contrary, our analysis suggests a negative correlation between the 2 which does come as a surprise. Upon further inspection, there are 2 major areas which contribute to this clear deviation.\n\n1. 2014 Oct - 2016 July \n    - During this period of time, it seems like USD\/JPY took off by itself, leaving the S&P 500 price behind.\n    - An explanantion for this activity could be the Bank of Japan announcing Quantitative Easing during this period of time. This causes the money supply of Japanese Yen to increase and thus a fall in purchasing power compared to USD and also a fall in interest rates.\n2. 2020 Mar - 2021 Jan\n    - During this period of time, USD\/JPY and S&P 500 Prices exhibited a negative correlation\n    - The Fed's Quantitative Easing during the COVID recovery could have contributed to the negative correlation. However, this time the Fed cut interest rates to close to 0 which may have caused a more serious deviation in the correlation between S&P500 Prices and USD\/JPY Prices\n","ad4298a3":"**Isolation Forest [VIX, USD\/JPY] (0.1 Contamination)**","9032bff7":"As for S&P's correlation with VIX, we can expect a clear negative correlation between the 2 when there is a huge change in the S&P's price as VIX acts as a gauge for fear in the markets *[During Periods of Increased Fear, a fall in the S&P500 Prices will often result in a huge rise in VIX]*.\n\nPerhaps a good way of making use of this information would be an attempt to do Anomaly Detection in VIX Prices to catch favourable points in the market.","f30b4cf4":"### Risk Appetite <a name=\"risk_appetite\"><\/a>\n\nRisk Management is essential when participating in the markets. Many participants seek to increase earnings while simultaneously attempting to reduce \/ limit the increase in downside that usually brings about. This usually comes in the form of diversification and selecting securities which are \"safe\" and less volatile.\n\nWhile risk management is essential in protecting one's assets, the global risk appetite does have significant impacts on the Forex Markets, whether directly, or indirectly. In this section, we will look at ways to gauge investor's risk appetite and analyse its impacts on the Forex Markets****","77a7cb6a":"**Isolation Forest [VIX, S&P500] (0.1 Contamination)**","5d8c4e85":"# Table of contents\n1. [Introduction](#introduction)\n2. [Data Analysis](#data_analysis)\n    1. [Libraries](#libraries)\n    2. [Data Paths](#data_paths)\n    3. [Data Cleaning and Engineering](#data_cleaning_and_engineering)\n    4. [Statistics](#statistics)\n3. [Data Exploration](#data_exploration)\n    1. [Currency Strength in relation to Gold](#curr_strength)\n    2. [Intermarket Relations [Commodities]](#intermarket_relations)\n    3. [Gold \/ Oil Ratio](#gold_oil_ratio)\n    4. [Risk Appetite](#risk_appetite)\n        1. [Volatility Index, Equity Index and USD\/JPY](#VIX_S&P_USDJPY) \n        2. [Anomaly Detection in Market Risk Appetite](#anomaly_detection)\n    \n\n## **Introduction** <a name=\"introduction\"><\/a>\nForex is a large global market that allows one to trade currencies against each other. As the largest market in the world, it boasts a trading volume of almost $7 trillion in a single day. With the increase in popularity of AI and Machine Learning, many have attempted to predict future currency prices, however, many had little success.\n\nPredicting the Financial Markets is akin to predicting the future. With so many unknown and unpredictable factors, building a machine learning model to predict occurrence of future events is just too unlikely (for now). Therefore, instead of trying to predict future prices, this notebook provides a simple analysis of the currency market (only some currency pairs are analysed), its correlations with the wider market and perhaps some recent trends that we have been observing","8a2cea7f":"<ins>**Insights and Findings**<\/ins>\n\nCompared to Gold, there aren't many anomalies in the relationship between Oil and the Euro or Dollar at first glance that have yet to be discussed.\n\nOil is generally negatively correlated with the Dollar and moves alongside EUR\/USD. With Oil priced in USD and USA being a net importer of Oil, it is easy see how this negative correlation between the 2 is established.\n\nOf Course Oil has interesting correlations between other currencies as well. However this will be discussed in further EDA's which goes in depth into specific commodities\/markets\/assets that affect the Forex markets.","97523812":"**Isolation Forest [VIX, USD\/JPY] (0.05 Contamination)**","86ec6a48":"### Data Cleaning and Engineering <a name=\"data_cleaning_and_engineering\"><\/a>","b2b2ac8b":"## **Data Exploration** <a name=\"data_exploration\"><\/a>","097d649d":"We can see currency strength of EUR and USD is closely correlated to EUR\/USD Prices. From 2015, it even seems that they move in sync with each other.  ","e2b16aa5":"### Intermarket Relations [Commodities] <a name=\"intermarket_relations\"><\/a>\n\nCommodities such as Gold and Oil have been a measure for currencies for a long while, whether through direct means of affecting currency prices or through its correlations with interest rates, it seems that commodities have played an essential role in gauging future movements in the Forex market. Let us look at Gold and Oil Correlations against some of our the Data we have at hand","57d704f3":"#### *Volatility Index, Equity Index and USD\/JPY* <a name=\"VIX_S&P_USDJPY\"><\/a>","2123009c":"<ins>**Anomalies**<\/ins>\n\nIt's interesting here how Gold has only around a 0.15 correlation with EURUSD and XAUUSD \/ XAUEUR but a 0.58 correlation with XAUEUR - XAUUSD. From the graphs we can clearly see differences between XAUEUR - XAUUSD and (EURUSD and XAUUSD \/ XAUEUR) during the following periods :\n\n- 2016 Jun - 2016 Dec\n- 2020 Mar - 2021 Feb\n\nIts generally understood that an effect on XAUEUR - XAUUSD is amplified as compared to XAUEUR \/ XAUUSD or EUR\/USD as the impact of a subtraction of 2 values is generally greater than performing division on the 2 values (Gold and EUR\/USD for example). Considering some of the global events that occurred during these 2 periods of time, it is easy to understand why our correlation sees such great differences between 2 very similar values.\n\n**Global Events During these Periods**\n\n- 2016 Jun - 2016 Dec\n    - Brexit did not create as much of an issue as expected and as such the financial markets did not take a big hit. The stock market rally during this period may have contributed greatly to the fall in prices of Gold\n    \n- 2020 Mar - 2021 Feb\n    - COVID 19's initial toll on the stock market and the ensuing stock market rally\n\n\n\n<ins>**Insights and Findings**<\/ins>\n\nGold's low correlation to the Euro and Dollar is largely expected as Gold's price is mostly determined by its underlying demand and supply.\n\nAlthough Gold historically acts as a hedge to inflation and the dollar (Gold usually rises dramatically as the dollar falls), its low correlation to the dollar may suggest a general positive outlook in the US economy over this time period. This is especially so from late 2018 to the early 2020's where Gold moved almost in tandem with USDX prices.\n\n"}}