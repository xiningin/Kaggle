{"cell_type":{"e013da7d":"code","f96199fa":"code","edd6d4b4":"code","3169ac7d":"code","9b3dd979":"code","fc36962d":"code","e5e902b6":"code","236ba568":"code","dbde8b9e":"code","494387d9":"code","fe764175":"code","641b2579":"code","f9bc2867":"code","2679cfe0":"code","98932ee1":"code","60800497":"code","752ef064":"code","1384a6e5":"code","99e471b5":"code","095e96f4":"code","1706a517":"code","78677d8e":"code","1a1a2e4a":"code","c11fc433":"code","23be1983":"code","e1421660":"code","49d52154":"code","bdb5b746":"code","409b9745":"code","f7d09885":"code","13e13bbe":"code","72151e7b":"code","a7e8f62d":"code","8eeda8d1":"code","696ff567":"code","d5061421":"code","86b168e6":"code","f6572f60":"code","a370c09a":"code","7d493388":"code","cdbde110":"code","6d0c7b35":"code","34aada1d":"code","816ae706":"code","8d7495f5":"markdown","1d603cb4":"markdown","56b32c67":"markdown","28f69fb0":"markdown","b167f97f":"markdown","a8261781":"markdown"},"source":{"e013da7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f96199fa":"data = pd.read_csv('\/kaggle\/input\/titanic\/train_and_test2.csv')\ndata.head()","edd6d4b4":"data.shape","3169ac7d":"data.describe()","9b3dd979":"data.info()","fc36962d":"data.isnull().sum()","e5e902b6":"data = data.rename(columns = {'2urvived': 'survived'}, inplace = False)\ndata.head()","236ba568":"data = data.fillna(0)","dbde8b9e":"data.isnull().sum()","494387d9":"import seaborn as sns","fe764175":"data.corr()","641b2579":"sns.heatmap(data.corr())","f9bc2867":"sns.jointplot('Fare', 'sibsp', data=data, kind = 'hex')","2679cfe0":"sns.countplot(data.Sex)","98932ee1":"sns.jointplot('Fare', 'sibsp', data=data, kind = 'reg')","60800497":"sns.distplot(data['Age'])","752ef064":"sns.countplot('survived', data=data)","1384a6e5":"sns.barplot('survived', 'Fare', data=data)","99e471b5":"sns.boxplot('survived', 'Age', data=data)","095e96f4":"X = data.drop('survived', axis='columns')\ny = data.survived","1706a517":"X.shape","78677d8e":"y.shape","1a1a2e4a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","c11fc433":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predlr = model.predict(X_test)\ncm = confusion_matrix(y_predlr, y_test)\ncm","23be1983":"cr = classification_report(y_predlr, y_test)\nprint(cr)","e1421660":"acc_lr = accuracy_score(y_predlr, y_test)\nacc_lr","49d52154":"from sklearn.metrics import matthews_corrcoef\nmc = matthews_corrcoef(y_predlr, y_test)\nmc","bdb5b746":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nimport matplotlib.pyplot as plt","409b9745":"model = Sequential()\n# add first hidden layer with input diamension\nmodel.add(Dense(units = 32, activation='relu', kernel_initializer = 'he_uniform', input_dim = 27))\n# add second hidden layer\nmodel.add(Dense(units = 16, activation='relu', kernel_initializer = 'he_uniform'))\n# add output layer\nmodel.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer = 'glorot_uniform'))","f7d09885":"# now we compile the model\nmodel.compile(optimizer = 'adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n# train the model\nmodel.fit(X_train, y_train, batch_size = 128, epochs = 50, verbose = 1)","13e13bbe":"acc = model.evaluate(X_test, y_test)","72151e7b":"model.summary()","a7e8f62d":"y_ann = model.predict(X_test)\ny_ann = y_ann > 0.5","8eeda8d1":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_ann, y_test)\ncm","696ff567":"from sklearn.metrics import matthews_corrcoef\nmc_ann = matthews_corrcoef(y_ann, y_test)\nmc_ann","d5061421":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nmodel_svm = SVC()\nmodel_svm.fit(X_train, y_train)\ny_svm = model_svm.predict(X_test)\nacc_svm = accuracy_score(y_svm, y_test)\ncm_svm = confusion_matrix(y_svm, y_test)\nacc_svm","86b168e6":"cm_svm","f6572f60":"from sklearn.metrics import classification_report\nprint(classification_report(y_svm, y_test))","a370c09a":"mc_svm = matthews_corrcoef(y_svm, y_test)\nmc_svm","7d493388":"from sklearn.ensemble import RandomForestClassifier\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X_train, y_train)\ny_rf = model_rf.predict(X_test)\nacc_rf = accuracy_score(y_rf, y_test)\ncm_rf = confusion_matrix(y_rf, y_test)\nacc_rf","cdbde110":"cm_rf","6d0c7b35":"from sklearn.metrics import classification_report\nprint(classification_report(y_rf, y_test))","34aada1d":"mc_rf = matthews_corrcoef(y_rf, y_test)\nmc_rf","816ae706":"print(\"Logistic Regression Accuracy : \", acc_lr)\nprint(\"Artificial Neural Network Accuracy : \", acc)\nprint(\"Support Vector Machine Accuracy : \", acc_svm)\nprint(\"Random Forest Accuracy : \", acc_rf)","8d7495f5":"## ANN with Keras","1d603cb4":"## Score of all models","56b32c67":"## This is the original data from Titanic competition plus some changes that I applied to it to be better suited for binary logistic regression:\n\n* Merged the train and test data.\n\n* Removed the 'ticket' and 'cabin' attributes.\n\n* Moved the 'Survived' attribute to the last column.\n\n* Added extra zero columns for categorical inputs to be better suited for One-Hot-Encoding.\n\n* Substituted the values of 'Sex' and 'Embarked' attributes with binary and categorical values respectively.\n\n* Filled the missing values in 'Age' and 'Fare' attributes with the median of the data.","28f69fb0":"## Logistic Regression y = (1 \/ 1 + e^-z)","b167f97f":"## Support Vector Machine (SVM)","a8261781":"## Random Forest"}}