{"cell_type":{"6237ca06":"code","9bf874cf":"code","0aa1ac0f":"code","955705fa":"code","033e58e1":"code","37eefca6":"code","21a21601":"code","4de4818b":"code","43ac554d":"code","be7d4aaf":"code","f3b2ea5e":"code","acd17730":"code","1dbd9095":"code","d289d004":"code","52629419":"markdown","45dd32c5":"markdown","15c3b34b":"markdown","2d236247":"markdown","eee30a23":"markdown","5a1ee0ab":"markdown","2f16d3ca":"markdown","3628ed83":"markdown","1bd0054c":"markdown","89cd5833":"markdown","db06370e":"markdown","c3dbbc8b":"markdown","54298fb9":"markdown","024c0484":"markdown","163341bf":"markdown","6ce3d2ec":"markdown","d5fd1eff":"markdown"},"source":{"6237ca06":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport sys\nimport warnings\nfrom sklearn import datasets, linear_model\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom math import sqrt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nspeedData = pd.read_csv('\/kaggle\/input\/traffic-speed-data\/traffic_speed_data.csv', delimiter=\";\");\nprint(speedData.head())","9bf874cf":"\n    speedData['date'] = pd.to_datetime(speedData['date'], format='%Y-%m-%d %H:%M:%S', utc=True)\n    \n    print(speedData.head())","0aa1ac0f":"speedData5min = speedData.set_index('date').resample('5min').mean().ffill().reset_index()\nspeedData5min.head()\n","955705fa":"targetDate = dt.datetime(2018, 5, 12)\npastWeekCount = 1;\n\nindexList = np.array(range(1, 289)).reshape(-1, 1)\nfig, axs = plt.subplots(3)\nfig.set_figheight(10)\nfig.set_figwidth(10)\ncolor =['yellow', 'orange', 'green']\ncurrentDate = targetDate;\n\nfor i in range(1, 4):\n    dateInfoStatus = [y.day == currentDate.day and \n                      y.month == currentDate.month and\n                      y.year == currentDate.year for y in speedData['date']]\n    \n    targetSpeedData = speedData[dateInfoStatus]\n    targetSpeedData = targetSpeedData.set_index('date').resample('5min').mean().ffill().reset_index()\n    speedList = targetSpeedData['Speed']\n    axs[i-1].plot(indexList, speedList, color=color[i-1])\n    axs[i-1].set(title=currentDate.strftime('%d\/%m\/%Y'));\n    axs[i-1].set_xlim([0, 300])\n    axs[i-1].set_ylim([0, 150])\n\n    currentDate = targetDate - dt.timedelta(days=7 * pastWeekCount)\n    pastWeekCount = pastWeekCount + 1\n    \nfig.text(0.5, 0, 'Each 5 minute', ha='center')\nfig.text(0.04, 0.4, 'Speed', va='center', rotation='vertical')\nfig.tight_layout()\nplt.show()","033e58e1":"# for 11\/06\/2018\ndayOfMonth = 11 \nmonthInfo = 6\nyearInfo = 2018\n\npreviousWeekCount = 7\nmustBeDataCount = 1100","37eefca6":"# Data set filtered by date\ndateInfoStatus = [y.day == dayOfMonth and y.month == monthInfo and y.year == yearInfo for y in speedData['date']]\ntargetDateInfoDF = speedData[dateInfoStatus]","21a21601":"if targetDateInfoDF.shape[0] < mustBeDataCount:\n    print(targetDateInfoDF.shape[0])\n    sys.exit()","4de4818b":"def fillBoundsOfDataForResample(fillDF, columnName):\n    # sort day speed data by date\n    fillDF.sort_values(by=['date'], inplace=True, ascending=True)\n    \n    # last available data of the day is in 23:59?\n    lastRowDate = fillDF[columnName].iloc[-1]\n    if lastRowDate.minute != 59 or lastRowDate.hour != 23:\n        fillDF.iloc[-1, fillDF.columns.get_loc(columnName)] = lastRowDate.replace(hour=23, minute=59)\n    \n    # first available data of the day is in 00:00?\n    firstRowDate = fillDF[columnName].iloc[0]\n    if firstRowDate.minute != 0 or firstRowDate.hour != 0:\n        fillDF.iloc[0, fillDF.columns.get_loc(columnName)] = lastRowDate.replace(hour=00, minute=00)\n    return fillDF","43ac554d":"targetDateInfoDF = fillBoundsOfDataForResample(targetDateInfoDF, 'date')","be7d4aaf":"def fill_missing_value(df):\n    return df.set_index('date').resample('5min').mean().ffill().reset_index()","f3b2ea5e":"# Average value was taken at 5 minute intervals, missing data filled\ntargetDateInfoDF = fill_missing_value(targetDateInfoDF)","acd17730":"def lineerRegression(mArray, sList):\n    regr = linear_model.LinearRegression()\n    regr.fit(np.array(mArray).reshape(-1, 1), np.array(sList))\n    y_pred = regr.predict(np.array(sList).reshape(-1, 1))\n    return y_pred\n\ndef polinomialRegression(indexList, mArray, spdList):\n    poly_reg = PolynomialFeatures(degree=5)\n    X_poly = poly_reg.fit_transform(indexList)\n    pol_reg = linear_model.LinearRegression()\n    pol_reg.fit(X_poly, mArray)\n    predResult = pol_reg.predict(poly_reg.fit_transform(indexList))\n    return predResult","1dbd9095":"\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    y_pred = y_pred.reshape(-1, 1)\n    dvdList = []\n    for i in range(0, y_true.size):\n        if y_true[i] != 0:\n            diff = y_true[i] - y_pred[i]\n            dvd = diff \/ y_true[i]\n            dvdList.append(dvd)\n\n    return np.mean(np.abs(dvdList)) * 100","d289d004":"#speed data of selected day\nspeedList = targetDateInfoDF['Speed']\n\n# used for saved as excel\nlstForExcel = []\n\n#row for excel, initialized with standard deviation of selected day speed data\nrowList = [targetDate.strftime(\"%d\/%m\/%Y\"), \"{0:.2f}\".format(speedList.std())]\n\n#excel columns initialized\ncols = ['Date', 'STD_Of_Speed']\n\n# past k week speed stored in allSpeeds\nallSpeeds = []\n\n# past week counter\npastWeekCount = 1\n\n# used dates stored in allCurrentDate\nallCurrentDate = targetDate.strftime(\"%d\/%m\/%Y\")\n\n\nfor weekCount in range(1, previousWeekCount):\n    previousDateInfoDF = pd.DataFrame()\n    \n    # Go back 1 week until you find the day with include more than 1100 speed data\n    while previousDateInfoDF.shape[0] < mustBeDataCount:\n        currentDate = targetDate - dt.timedelta(days=7 * pastWeekCount)\n        \n        print('Current Date in while: %s' % currentDate)\n        \n        currentDayInfo = currentDate.day;\n        currentMonthInfo = currentDate.month;\n        currentYearInfo = currentDate.year;\n        \n        # get past week day speed data\n        dateInfoStatus = [y.day == currentDayInfo and\n                          y.month == currentMonthInfo and \n                          y.year == currentYearInfo for y in speedData['date']]\n        \n        previousDateInfoDF = speedData[dateInfoStatus]\n        \n        pastWeekCount = pastWeekCount + 1\n    \n    # store date info of back weeks\n    allCurrentDate = allCurrentDate + ',' + currentDate.strftime(\"%d\/%m\/%Y\")\n    \n    # fill missing value and resample for back week day speed data\n    previousDateInfoDF = fillBoundsOfDataForResample(previousDateInfoDF, 'date')\n    previousDateInfoDF = fill_missing_value(previousDateInfoDF)\n\n    previousSpeedList = previousDateInfoDF['Speed']\n    \n    # store back week day data for evaluation\n    allSpeeds.append(np.array(previousSpeedList, float))\n\n    # get mean speed value of all week day speeds\n    meanArray = np.array(allSpeeds, float)[:(weekCount), :].mean(axis=0)\n    \n    # difference speed between all back k week's mean speed value and target speed list\n    diffSpeed = abs(meanArray - np.array(speedList, float))\n\n    mse = mean_squared_error(speedList, meanArray, multioutput='raw_values')\n    rmse = sqrt(mse)\n    mae = mean_absolute_error(speedList, meanArray, multioutput='raw_values')\n    mape = mean_absolute_percentage_error(speedList, meanArray)\n\n    print(\"Mean squared error: %.6f\" % mse)\n    print(\"Root Mean squared error: %.6f\" % rmse)\n    print(\"Mean absolute error: %.6f\" % mae)\n    print(\"Mean absolute percentage error: %.6f\" % mape)\n    \n    \n    # Linear Regression\n    linearRegPred = lineerRegression(meanArray, speedList)\n    \n    linearRegMse = mean_squared_error(speedList, linearRegPred)\n    linearRegMape = mean_absolute_percentage_error(speedList, linearRegPred)\n    linearRegMae = mean_absolute_error(speedList, linearRegPred)\n    \n    print(\"Linear Regression Mean squared error: %.6f\" % linearRegMse)\n    print(\"Linear Regression Mean absolute error: %.6f\" % linearRegMape)\n    print(\"Linear Regression Mean absolute percentage error: %.6f\" % linearRegMae)\n    \n    \n    # Polinomial Regression\n    xList = np.array(range(1, 289)).reshape(-1, 1)\n    predResult = polinomialRegression(xList, meanArray, speedList)\n    \n    polRegMse = mean_squared_error(speedList, predResult)\n    polyRegMape = mean_absolute_percentage_error(speedList, predResult)\n    polyRegMae = mean_absolute_error(speedList, predResult)\n    \n    print(\"Polinomial Regression Mean squared error: %.6f\" % polRegMse)\n    print(\"Polinomial Regression Mean absolute error: %.6f\" % polyRegMape)\n    print(\"Polinomial Regression Mean absolute percentage error: %.6f\" % polyRegMae)\n\n\n    # Prepare result excel\n    rowList.extend([ \"{0:.2f}\".format(diffSpeed.std()),\n         \"{0:.2f}\".format(diffSpeed.min()),\n         \"{0:.2f}\".format(diffSpeed.max()), \n         \"{0:.2f}\".format(float(polRegMse)), \n         \"{0:.2f}\".format(float(polyRegMape)), \n         \"{0:.2f}\".format(float(polyRegMae)),\n         \"{0:.2f}\".format(float(linearRegMse)), \n         \"{0:.2f}\".format(float(linearRegMape)), \n         \"{0:.2f}\".format(float(linearRegMae)),\n         \"{0:.2f}\".format(float(mse)), \n         \"{0:.2f}\".format(float(rmse)), \n         \"{0:.2f}\".format(float(mae)),\n         \"{0:.2f}\".format(float(mape))])\n\n    cols.extend(['STD_of_Diff_Speed_'+str(weekCount),\n                 'Minimum_Value_'+str(weekCount), \n                 'Maximum_Value_'+str(weekCount), \n                 'PolReg_MSE_'+str(weekCount),\n                 'PolReg_MAPE_'+str(weekCount),\n                 'PolReg_MAE_'+str(weekCount), \n                 'LinearReg_MSE_'+str(weekCount),\n                 'LinearReg_MAPE_'+str(weekCount),\n                 'LinearReg_MAE_'+str(weekCount), \n                 'MSE_'+str(weekCount), \n                 'RMSE_'+str(weekCount), \n                 'MAE_'+str(weekCount), \n                 'MAPE_'+str(weekCount)])\n\n# add all used dates column\ncols.append('UsedDates')\nrowList.append(allCurrentDate)\n\n# create dataframe for excel view\nlstForExcel.append(rowList)\ndfForExcel = pd.DataFrame(lstForExcel, columns=cols)\n\npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\ndfForExcel.T\n","52629419":"# ***Preparation of the Data Set by Going Back k Week***\n \nIn the studies that make short-term speed estimation, speed data mostly used on the same day. It is not sufficient to use the speed data on the same day for long term speed estimation. In this study, the effect of using days with similar characteristics in the past for long-term speed estimation was investigated. Here k shows how many weeks to go back, in our study k; It takes the values 1, 2, 3, 4, 5, 6.\n\n\n**Lets Look Dataset's a day speed with going back 2 week using 12\/05\/2018 speed data**\n\nWhen we run the code, it is seen that the speed data of the same days of past 2 week are in a similar speed structure.","45dd32c5":"We went back k (previousWeekCount) weeks to get speed data on the same day of the week.\n\nCalculate Linear and Polinomial regression's error rates.","15c3b34b":"The data set contains missing data. In python code ffill() help us for missing data, resampling was performed in such a way that the speed value nearest to the data (eg, speed data after 5 minutes) was accepted. \n\n**fill_missing_value()** function used for this.","2d236247":"In below initialization parameres;\n\n***monthInfo:*** selected day for prediction\n\n***monthInfo:*** selected month for prediction\n\n***yearInfo:*** selected year info in data\n\n***previousWeekCount:*** how many weeks to go back\n\n***mustBeDataCount:*** Days with less than 1100 speed data (approximately 70% of data) were not included in the calculation.\n","eee30a23":"**Lets Understand Dataset**\n\nDataset contains speed data for each minute of year 2018 collected from a sample sensor in Istanbul, Turkey.  Dataset include 5 feature.\n\n* sensorId  -> sensor id\n* sensorDir -> road direction for sensor\n* date -> date information for speed data\n* dayOfWeek -> week day info of speed data (monday, tuesday.. etc)\n* Speed -> km\/h type speed info for date","5a1ee0ab":"# 1. Data Exploration & Visualization","2f16d3ca":"# Long-term Traffic Speed Estimation via Regression \n\nTraffic has become one of the most important problems of urbanized settlements. In order to reduce the time spent in traffic, various applications have been developed which show people the fastest and most comfortable route from one point to another. However, although these applications are suitable for short-term speed prediction, they cannot predict long-term traffic density. \n\nIn this study, Linear and Polynomial Regression Model were used to predict up to 7 days using the patterns of speed data of the past week.\n\n1. Data Exploration & Visualization\n2. Long-Term Traffic Speed Estimation Model","3628ed83":"Data set filtered by date","1bd0054c":"Days with less than 1100 speed data (approximately 70% of data) were not included in the calculation.","89cd5833":"# 2. Long-Term Traffic Speed Estimation Model","db06370e":"Dataset contains missing values. The first and last data were changed for samples that did not start at 00:00 or end at 23:59 with daily speed data. The initial speed data was set to 00:00, while the last speed data was set to 23:59.\n\n**fillBoundsOfDataForResample** function used for this type missing values.","c3dbbc8b":"The data obtained are speed data measured from the sensor every minute. Since the data set is 1440 minutes in 24 hours in an unprocessed state, it contains 1440 speed data in 1 day. Days with less than 1100 speed data (approximately 70% of data) were not included in the calculation. \n\nIn previous studies, it was observed that the speed flow data was evaluated at intervals of 5 minutes and the data set was arranged by taking the average speed value for every 5 minutes in the study.\n\n![5_minutes_mean.png](attachment:5_minutes_mean.png)\n\nWe can see 5 minutes sampling progress in below python code.\n\nThe data set contains missing data. In python code ffill() help us for missing data, resampling was performed in such a way that the speed value nearest to the data (eg, speed data after 5 minutes) was accepted.  ","54298fb9":"If the first and last values of the data do not represent the day limit, the date has been changed for match the resample","024c0484":"Mean Absolute Percentage Error Calculate Function","163341bf":"Transform csv data to pandas dataframe and change date attribute type to datetime.","6ce3d2ec":"In this section, the preparation phase of the data set will be mentioned to estimate the long-term traffic density. In the preparation of the data set, the same characteristic of the same days of the week was used as a hypothesis.","d5fd1eff":"Linear and Polinomial Regression Function"}}