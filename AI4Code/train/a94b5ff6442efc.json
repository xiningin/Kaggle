{"cell_type":{"9be9824a":"code","ca91c5c9":"code","08cd3d65":"code","6eb280d1":"code","cacb174f":"code","f3509aa6":"code","c33f4ba7":"code","2fc5d9a9":"code","b7df6a66":"code","d583103c":"code","befbf9c1":"code","d4b6e86a":"code","18444f97":"code","9fe50141":"code","3dceb56c":"code","8e7c034a":"code","1a320c6e":"code","93b10999":"code","20aeaa01":"code","8e762025":"code","a0c8aa25":"code","b8d42576":"code","19d668fe":"code","327b53c4":"code","32b69f3a":"code","8ef40eb5":"code","10ac3c80":"code","fd1cf198":"code","378c07e9":"code","252fb073":"code","a2005484":"code","3eba7cb0":"markdown","e36bc840":"markdown","ba820749":"markdown"},"source":{"9be9824a":"import os\nimport numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score\nfrom tqdm import tqdm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom joblib import dump, load\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport enum\nimport math\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","ca91c5c9":"def random_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)","08cd3d65":"PATH = '..\/input\/song-popularity-prediction'\ntrain = pd.read_csv(os.path.join(PATH, 'train.csv'))\ntest = pd.read_csv(os.path.join(PATH, 'test.csv'))\nsub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))","6eb280d1":"train.head(5)","cacb174f":"#overview: structure and data content\n#find the null values\ntrain.isnull().sum()","f3509aa6":"train.isna().sum().reset_index(name=\"NaN\").plot.bar(x='index', y='NaN', rot=45)","c33f4ba7":"test.isna().sum().reset_index(name=\"NaN\").plot.bar(x='index', y='NaN', rot=45)","2fc5d9a9":"plt.hist(train.song_duration_ms.dropna())","b7df6a66":"plt.hist(train.\tacousticness.dropna())\n# this is right skewed\n# you can convert this into a categorical feature","d583103c":"plt.hist(train.\tdanceability.dropna())","befbf9c1":"plt.hist(train.energy.dropna())","d4b6e86a":" plt.hist(np.log(train.instrumentalness.dropna()))","18444f97":"plt.hist(train.key.dropna())","9fe50141":"plt.hist(train.liveness.dropna())","3dceb56c":"plt.hist(train.loudness.dropna(), bins=100)\nplt.show()","8e7c034a":"plt.hist(train.audio_mode.dropna(), bins=10)\nplt.show()\n#this is a binary feature","1a320c6e":"plt.hist(train.speechiness.dropna(), bins=100)\nplt.show()\n","93b10999":"plt.hist(train.song_duration_ms.dropna(), bins=100)\nplt.show()","20aeaa01":"plt.hist(train.song_popularity.dropna(), bins=3)\nplt.show()\n# the output variable is not balanced so do some preprocessing","8e762025":"train.song_popularity.value_counts(normalize=True)","a0c8aa25":"plt.rcParams[\"figure.figsize\"] = (15,6)\ndataplot = sns.heatmap(train.corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","b8d42576":"test.shape\n","19d668fe":"sub.shape\n","327b53c4":"train.describe()","32b69f3a":"test.describe()","8ef40eb5":"columns = [col for col in train.columns if col not in ['id', 'song_popularity'] ]","10ac3c80":"xgb_params= {\n        \"n_estimators\": 30000,\n        \"max_depth\": 11,\n        \"objective\":\"binary:logistic\",\n        \"n_jobs\": 4,\n        \"seed\": 42,\n        'tree_method': \"gpu_hist\",\n        \"gpu_id\": 0,\n        \"eval_metric\": \"auc\", \n        \"subsample\": 0.7,\n        \"colsample_bytree\": 0.7,\n        \"learning_rate\": 0.01\n    }","fd1cf198":"class Config(enum.Enum):\n    SEED = 2001\n    N_FOLDS = 10\n    EARLY_STOP = 300","378c07e9":"random_seed(Config.SEED.value)\n\nauc_score = []\n\ntargets = train['song_popularity'].values\n\nkf = StratifiedKFold(n_splits = Config.N_FOLDS.value, shuffle=True, random_state=Config.SEED.value)    \n        \noof = np.zeros((train.shape[0],))\ntest_preds = 0\n\nfor f, (train_idx, val_idx) in tqdm(enumerate(kf.split(X=train, y=targets))):\n        df_train, df_val = train.iloc[train_idx][columns], train.iloc[val_idx][columns]\n        train_target, val_target = targets[train_idx], targets[val_idx]\n        \n        model = xgb.XGBClassifier(**xgb_params)\n        \n        model.fit(\n            df_train[columns], \n            train_target,\n            eval_set=[(df_val[columns], val_target)],\n            early_stopping_rounds=Config.EARLY_STOP.value,\n            verbose=500\n        )\n        \n        oof_tmp = model.predict_proba(df_val[columns])[:,1]\n        test_tmp = model.predict_proba(test[columns])[:,1]\n        oof[val_idx] = oof_tmp\n        test_preds += test_tmp\/Config.N_FOLDS.value\n        auc = roc_auc_score(val_target, oof_tmp)\n        auc_score.append(auc)\n        print(f'FOLD: {f} AUC: {auc} Mean AUC: {np.mean(auc_score)}')","252fb073":"sub['song_popularity'] = test_preds\nsub.to_csv('submission.csv', index=False)","a2005484":"sub.head()","3eba7cb0":"# Feature interactions","e36bc840":"#  feature target interactions","ba820749":"# visualize individual features\n"}}