{"cell_type":{"2a219b96":"code","a6da285f":"code","940da6a4":"code","4c550f03":"code","4ce11aa7":"code","903342f4":"code","257900ce":"code","6a9c827a":"code","f9834f47":"code","d20f7b36":"code","9e56c3f5":"code","3c863021":"code","e213a838":"code","a069cf6f":"code","b6600f19":"code","aa770713":"code","a4319527":"code","56b85cf0":"code","edef4046":"code","0375bd35":"markdown","2f38627c":"markdown","e8c62429":"markdown","8d554816":"markdown","4e845e30":"markdown"},"source":{"2a219b96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6da285f":"import numpy as np\nimport pandas as pd\nimport math\nimport sklearn\nimport sklearn.preprocessing\nimport datetime\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras","940da6a4":"from tensorflow.keras.utils import plot_model","4c550f03":"df=pd.read_csv('\/kaggle\/input\/nyse\/prices-split-adjusted.csv')\ndf.info()","4ce11aa7":"df.head()","903342f4":"# number of different stocks\nprint('number of different stocks: ', len(list(set(df.symbol))))\nprint(list(set(df.symbol)))","257900ce":"df.isnull().sum()","6a9c827a":"df.describe()","f9834f47":"df_eqix=df[df.symbol=='EQIX']\ndf_eqix=df_eqix.set_index('date')\ndf_eqix.head()","d20f7b36":"# visualizing 'EQIX' stock price and volume as time\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\n\nplt.plot(df[df.symbol == 'EQIX'].open.values, color='red', label='open')\nplt.plot(df[df.symbol == 'EQIX'].close.values, color='green', label='close')\nplt.plot(df[df.symbol == 'EQIX'].low.values, color='blue', label='low')\nplt.plot(df[df.symbol == 'EQIX'].high.values, color='black', label='high')\nplt.title('stock price')\nplt.xlabel('time [days]')\nplt.ylabel('price')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2);\nplt.plot(df[df.symbol == 'EQIX'].volume.values, color='black', label='volume')\nplt.title('stock volume')\nplt.xlabel('time [days]')\nplt.ylabel('volume')\nplt.legend(loc='best')\nplt.show()","9e56c3f5":"# standardization for data\ndef normalize_data(df):\n    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n    df['close'] = min_max_scaler.fit_transform(df.close.values.reshape(-1,1))\n    return df\n\n# function to create train, validation, test data given stock data and sequence length\n\n# split data in 80%\/10%\/10% train\/validation\/test sets\nvalid_set_size_percentage = 10 \ntest_set_size_percentage = 10 \n\ndef load_data(stock, seq_len):\n    data_raw=stock.values #convert to numpy array\n    data=[]\n    \n    # create all possible sequences of length seq_len\n    for index in range(len(data_raw)-seq_len):\n        data.append(data_raw[index: index+seq_len])\n        \n    data=np.array(data)\n    valid_set_size=int(np.round(valid_set_size_percentage\/100 * data.shape[0]));\n    test_set_size=int(np.round(test_set_size_percentage\/100 * data.shape[0]));\n    train_set_size=data.shape[0]-(valid_set_size + test_set_size);\n    \n    x_train= data[:train_set_size, :-1, :]\n    y_train= data[:train_set_size, -1, :]\n    \n    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:]\n    \n    x_test = data[train_set_size+valid_set_size:,:-1,:]\n    y_test = data[train_set_size+valid_set_size:,-1,:]\n    \n    return [x_train, y_train, x_valid, y_valid, x_test, y_test]","3c863021":"# choose one stock\ndf_stock=df[df.symbol== 'EQIX'].copy()\ndf_stock.drop(['symbol'],1,inplace=True) # df_stock\uc740 EQIX symbol\ub9cc \uc0ac\uc6a9\ndf_stock.drop(['volume'],1,inplace=True)\ndf_stock.drop(['date'],1,inplace=True)\n\ncols=list(df_stock.columns.values)\nprint('df_stock.columns.values = ', cols)\n","e213a838":"# normalize stock\ndf_stock_norm= df_stock.copy()\ndf_stock_norm=normalize_data(df_stock_norm)\n\n# create train, test data\nseq_len=20 # choose sequence length\nx_train, y_train, x_valid, y_valid, x_test, y_test = load_data(df_stock_norm, seq_len)\nprint('x_train.shape = ',x_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('x_valid.shape = ',x_valid.shape)\nprint('y_valid.shape = ', y_valid.shape)\nprint('x_test.shape = ', x_test.shape)\nprint('y_test.shape = ',y_test.shape)","a069cf6f":"plt.figure(figsize=(15, 5));\nplt.plot(df_stock_norm.open.values, color='red', label='open')\nplt.plot(df_stock_norm.close.values, color='green', label='low')\nplt.plot(df_stock_norm.low.values, color='blue', label='low')\nplt.plot(df_stock_norm.high.values, color='black', label='high')\n#plt.plot(df_stock_norm.volume.values, color='gray', label='volume')\nplt.title('stock')\nplt.xlabel('time [days]')\nplt.ylabel('normalized price\/volume')\nplt.legend(loc='best')\nplt.show()","b6600f19":"from keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt","aa770713":"lstm_model=Sequential()\n\nlstm_model.add(LSTM(input_shape=(19,4), units=50, return_sequences=True)) # adding LSTM layer\nlstm_model.add(Dropout(0.2)) #adding Dropout\n\nlstm_model.add(LSTM(100, return_sequences = False))                            #Adding LSTM layer\nlstm_model.add(Dropout(0.2))                                                   #Adding Dropout\n\nlstm_model.add(Dense(units=4))                                                 #Adding Dense layer with activation = \"linear\"\nlstm_model.add(Activation('linear'))\n\n'''Compiling the model'''\n\nlstm_model.compile(loss='mse', optimizer='rmsprop')","a4319527":"'''Fitting the dataset into the model'''\n\nlstm_model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_valid, y_valid))\n","56b85cf0":"'''Predicted values of train\/val\/test dataset'''\n\ntrain_y_pred = lstm_model.predict(x_train)\nprint('prediction of train data is ',train_y_pred)\nval_y_pred = lstm_model.predict(x_valid)\nprint('prediction of validation data is ', val_y_pred)\ntest_y_pred = lstm_model.predict(x_test)\nprint('prediction of test data is ', test_y_pred)","edef4046":"# visualizing the trained\/predicted\/test dataset\nc = 0 # 0 = open, 1 = close, 2 = high, 3 = low\n\nplt.figure(figsize=(15, 5));\nplt.subplot(1,2,1);\n\nplt.plot(np.arange(y_train.shape[0]), y_train[:, c], color='blue', label='Train target')\n\nplt.plot(np.arange(y_train.shape[0], y_train.shape[0] + y_valid.shape[0]), y_valid[:, c], \n         color='gray', label='Validation target')\n\nplt.plot(np.arange(y_train.shape[0]+ y_valid.shape[0], y_train.shape[0]+y_test.shape[0]+y_test.shape[0]), \n         y_test[:, c], color='black', label='Test target')\n\nplt.plot(np.arange(train_y_pred.shape[0]),train_y_pred[:, c], color='red', label='Train Prediction')\n\nplt.plot(np.arange(train_y_pred.shape[0], train_y_pred.shape[0]+val_y_pred.shape[0]), \n         val_y_pred[:, c], color='orange', label='Validation Prediction')\n\nplt.plot(np.arange(train_y_pred.shape[0]+val_y_pred.shape[0], \n                   train_y_pred.shape[0]+val_y_pred.shape[0]+test_y_pred.shape[0]), \n         test_y_pred[:, c], color='green', label='Test Prediction')\n\n\nplt.title('Past and Future Stock Prices')\nplt.xlabel('Time [days]')\nplt.ylabel('Normalized Price')\nplt.legend(loc='best');\n\nplt.subplot(1,2,2);\nplt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]), y_test[:, c], color='black', label='Test target')\n\nplt.plot(np.arange(train_y_pred.shape[0], train_y_pred.shape[0]+test_y_pred.shape[0]), test_y_pred[:, c], \n         color='green', label='Test Prediction')\n\nplt.title('Future Stock Prices')\nplt.xlabel('Time [days]')\nplt.ylabel('Normalized Price')\nplt.legend(loc='best');\n\ntrain_acc = np.sum(np.equal(np.sign(y_train[:,1]-y_train[:,0]), \n                            np.sign(train_y_pred[:,1]-train_y_pred[:,0])).astype(int)) \/ y_train.shape[0]\nval_acc = np.sum(np.equal(np.sign(y_valid[:,1]-y_valid[:,0]), \n                          np.sign(val_y_pred[:,1]-val_y_pred[:,0])).astype(int)) \/ y_valid.shape[0]\ntest_acc = np.sum(np.equal(np.sign(y_test[:,1]-y_test[:,0]), \n                           np.sign(test_y_pred[:,1]-test_y_pred[:,0])).astype(int)) \/ y_test.shape[0]\n\nprint('Accuracy for Close - Open price for Train\/Validation\/Test Set: %.2f\/%.2f\/%.2f'%(train_acc, val_acc, test_acc))","0375bd35":"# Model and Validate data\nwith RNN, LSTM, GRU cells","2f38627c":"# \uba38\uc2e0\ub7ec\ub2dd \uae30\ubc18 \ub370\uc774\ud130 \ubd84\uc11d_\ud669\uc720\uc815","e8c62429":"# Analyze Data\n- load stock prices from prices-split-adjusted.csv \n- analyze data","8d554816":"# Prediction and Accuracy","4e845e30":"# Maniqulate data\n- choose a specific stock\n- drop feature: volume\n- normalize stock data\n- create train, validation and test data sets"}}