{"cell_type":{"b3a61fe1":"code","4b61ce86":"code","54c729cf":"code","c75c8624":"code","5a5e78c2":"code","61cbed26":"code","ecf52523":"code","191ca1ab":"code","1438ab70":"code","c8e81dc6":"code","f4382ce6":"code","9e5f331e":"code","29e081a3":"code","1e28f1b9":"code","6e0118d1":"code","99cc8e82":"code","0bb28ed2":"code","ef80c18b":"code","f0e92991":"markdown","8168ebf4":"markdown","48386310":"markdown","22eeff12":"markdown","8eb84451":"markdown","a8202ad5":"markdown","d486a15f":"markdown","ecaf6555":"markdown","4b409b6c":"markdown","2e1cd6e3":"markdown","8733b39e":"markdown","53928c12":"markdown"},"source":{"b3a61fe1":"import numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport math\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict as cvp\nfrom sklearn import metrics, pipeline\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom time import time\n# models\nfrom sklearn.linear_model import LogisticRegression, LogisticRegression, Perceptron, RidgeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC, SVR\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4b61ce86":"iris=pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\niris.head(10)","54c729cf":"iris.info() #The info() command here is used to check if there is any inconsistency with the data .\n#As we can see there is nothing weird about the data we can process the data.","c75c8624":"pp.ProfileReport(iris)","5a5e78c2":"plt.figure(figsize=(15,8))\nsns.scatterplot(data=iris,x='SepalLengthCm',y='SepalWidthCm',hue='Species')\nplt.title('Sepal Length VS Sepal Width')","61cbed26":"plt.figure(figsize=(15,8))\nsns.scatterplot(data=iris,x='PetalLengthCm',y='PetalWidthCm',hue='Species')\nplt.title('Petal Length VS Petal Width')","ecf52523":"iris['Species'].value_counts().plot.pie(explode=[.1,.1,.1],autopct='%1.1f%%',shadow=True)","191ca1ab":"iris.drop(['Id'],axis=1,inplace=True)","1438ab70":"iris.head()","c8e81dc6":"iris.hist(edgecolor='black',linewidth=1.2)\nplt.gcf().set_size_inches(12,6)","f4382ce6":"sns.pairplot(iris,hue='Species')","9e5f331e":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species',y='PetalLengthCm',data=iris)\nplt.subplot(2,2,2)\nsns.violinplot(x='Species',y='PetalWidthCm',data=iris)\nplt.subplot(2,2,3)\nsns.violinplot(x='Species',y='SepalLengthCm',data=iris)\nplt.subplot(2,2,4)\nsns.violinplot(x='Species',y='SepalWidthCm',data=iris)","29e081a3":"sns.heatmap(iris.corr(),annot=True,cmap='cubehelix_r')","1e28f1b9":"def acc_summary(pipeline, X_train, y_train, X_val, y_val):\n    t0 = time()\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    y_pred = sentiment_fit.predict(X_val)\n    train_test_time = time() - t0\n    accuracy = accuracy_score(y_val, y_pred)*100\n    print(\"accuracy : {0:.2f}%\".format(accuracy))\n    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n    print(\"-\"*80)\n    return accuracy, train_test_time","6e0118d1":"names = [ \n        'Logistic Regression',\n        'Perceptron',\n        'Ridge Classifier',\n        'SGD Classifier',\n        'SVC',\n        'Gradient Boosting Classifier', \n        'Extra Trees Classifier', \n        \"Bagging Classifier\",\n        \"AdaBoost Classifier\", \n        \"K Nearest Neighbour Classifier\",\n         \"Decison Tree Classifier\",\n         \"Random Forest Classifier\",\n         'GaussianNB',\n        \"Gaussian Process Classifier\",\n        \"MLP Classifier\",\n        \"XGB Classifier\",\n        \"LGBM Classifier\"\n         ]\nclassifiers = [\n    LogisticRegression(),\n    Perceptron(),\n    RidgeClassifier(),\n    SGDClassifier(),\n    SVC(),\n    GradientBoostingClassifier(),\n    ExtraTreesClassifier(), \n    BaggingClassifier(),\n    AdaBoostClassifier(),\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GaussianNB(),\n    GaussianProcessClassifier(),\n    MLPClassifier(),\n    XGBClassifier(),\n    LGBMClassifier()\n        ]\n\nzipped_clf = zip(names,classifiers)","99cc8e82":"def classifier_comparator(X_train,y_train,X_val,y_val,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([\n            ('classifier', c)\n        ])\n        print(\"Validation result for {}\".format(n))\n        #print(c)\n        clf_acc,tt_time = acc_summary(checker_pipeline,X_train, y_train, X_val, y_val)\n        result.append((n,clf_acc,tt_time))\n    return result","0bb28ed2":"X_train,X_val,y_train,y_val=train_test_split(iris.iloc[:,:-1],iris.iloc[:,-1],test_size=0.1)","ef80c18b":"classifier_comparator(X_train,y_train,X_val,y_val)\n","f0e92991":"As we can see that the Petal Features are giving a better cluster division compared to the Sepal features. This is an indication that the Petals can help in better and accurate Predictions over the Sepal. ","8168ebf4":"We now read the dataset and check the first few lines of the dataset.","48386310":"# Some Data Analysis with iris","22eeff12":"The Sepal Width and Length are not correlated The Petal Width and Length are highly correlated.\n\n# Now the given problem is a classification problem. Thus we will be using the classification algorithms to build a model.\n\n","8eb84451":"**Creating a function to compare accuracies**","a8202ad5":"The above graph show the relationship between the SepalLengthCm and the SepalWidthCm.","d486a15f":"**Hello Kagglers!!**\n\nThis is a tutorial to Machine Learning for using the Iris Dataset. I will try to show how to implement a machine learning to a given dataset by following this notebook. I have explained everything related to the implementation in detail . Hope you find it useful.\n\n\nIf this notebook to be useful,\n\n**Please Upvote!!!**","ecaf6555":"The violinplot shows density of the length and width in the species. The thinner part denotes that there is less density whereas the fatter part conveys higher density","4b409b6c":"**I hope the notebook was useful to you to get started with Machine Learning.**\n\n**If find this notebook, Please Upvote.**\n\n**Thank You!!**","2e1cd6e3":"We drop the Id column as it is unique for each row and hence seems to be useless.","8733b39e":"# Now let us see how the length and width vary according to the species\n","53928c12":"# Splitting the data"}}