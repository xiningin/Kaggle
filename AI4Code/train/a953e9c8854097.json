{"cell_type":{"a44cece5":"code","af673963":"code","7c1bd933":"code","fe621ef0":"code","3bb3d4c5":"code","5b37bda2":"code","41520d03":"code","b605a2f3":"code","93d52501":"code","c82f61a0":"code","ae60fb2f":"code","38578793":"code","625159ab":"code","51d77d39":"code","c08452be":"code","951a6fbf":"code","6eafdf40":"code","03202d2a":"code","6dd6311b":"code","d45179b5":"code","42c6ac0f":"code","82e6e083":"code","c24b6ebe":"code","1953da19":"code","eecc797b":"code","07f8d476":"code","270c2287":"code","9a24622d":"code","517ae46d":"code","18968239":"code","5dc2928f":"code","07043adc":"code","c462848e":"code","f4e792b2":"markdown","21111b68":"markdown","51896f40":"markdown","47eb3c01":"markdown","5aa84d4f":"markdown","f4c5e550":"markdown","e09b9901":"markdown","2aa29c6c":"markdown","7b8a0fd0":"markdown","df401375":"markdown","f803bf1e":"markdown","e924dbd3":"markdown","b2781260":"markdown","7a4aaaf1":"markdown","31cf0831":"markdown","59962044":"markdown"},"source":{"a44cece5":"import os \nprint(os.listdir(\"\/kaggle\/input\/skin-cancer-mnist-ham10000\"))","af673963":"dataPath = \"\/kaggle\/input\/skin-cancer-mnist-ham10000\/\"","7c1bd933":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(dataPath+'HAM10000_metadata.csv')\ndf.head()","fe621ef0":"dx = df['dx'].value_counts().sort_index()\nprint(dx)","3bb3d4c5":"categories = dx.index.values\nprint(categories)\n\ncounts = dx.values\nprint(counts)","5b37bda2":"#labels = ['\u5149\u5316\u89d2\u5316\u75c5', '\u57fa\u5e95\u7d30\u80de\u764c', '\u826f\u6027\u89d2\u5316\u75c5', '\u76ae\u819a\u7e96\u7dad\u7624', '\u60e1\u6027\u9ed1\u8272\u7d20\u7624', '\u9ed1\u7d20\u7d30\u80de\u75e3', '\u8840\u7ba1\u75c5\u8b8a']\nlabels = ['Actinic Keratoses', 'Basal Cell Carcinoma', 'Benign Keratosis', 'Dermatofibroma', 'Malignant Melanoma', 'Melanocytic Nevi', 'Vascular Lesions']\n\nnum_classes = len(labels) # = len(categories)","41520d03":"import matplotlib.pyplot as plt\nimport seaborn as sns\n#sns.set_style(\"whitegrid\")\n\ndef plot_equilibre(categories, counts):\n\n    plt.figure(figsize=(12, 8))\n\n    sns_bar = sns.barplot(x=categories, y=counts)\n    sns_bar.set_xticklabels(categories, rotation=45)\n    plt.title('Equilibre of Training Dataset')\n    plt.show()","b605a2f3":"plot_equilibre(categories, counts)","93d52501":"# create local data directory \ndata_dir = 'data'\nos.mkdir(data_dir)\ntrain_dir = os.path.join(data_dir, 'train')\nos.mkdir(train_dir)\nval_dir = os.path.join(data_dir, 'val')\nos.mkdir(val_dir)\ntest_dir = os.path.join(data_dir, 'test')\nos.mkdir(test_dir)","c82f61a0":"# create directory for each category in train\/val\/test directory\nfor category in categories:\n    os.mkdir(os.path.join(train_dir, category))\n    os.mkdir(os.path.join(val_dir,   category))\n    os.mkdir(os.path.join(test_dir,  category))","ae60fb2f":"!ls data\/train\n!ls data\/val\n!ls data\/test","38578793":"from sklearn.model_selection import train_test_split\n# Split to train and validation set\ndf_train, df_tmp = train_test_split(df, test_size=0.2, random_state=101, stratify=df['dx'])\ndf_val, df_test = train_test_split(df_tmp, test_size=0.5, random_state=101)\nprint(df_train.shape)\nprint(df_val.shape)\nprint(df_test.shape)","625159ab":"# image_id as df index\ndf_train = df_train.set_index('image_id') \ndf_val   = df_val.set_index('image_id') \ndf_test  = df_test.set_index('image_id')","51d77d39":"import shutil\nfolder_1 = os.listdir(dataPath +'ham10000_images_part_1')\nfolder_2 = os.listdir(dataPath +'ham10000_images_part_2')\n\ndef copy_files(df, data_dir):\n    fileList = df.index.values\n    \n    for file in fileList:\n        fname = file + '.jpg'\n        label = df.loc[file, 'dx'] \n\n        if fname in folder_1:\n            src = os.path.join(dataPath+'ham10000_images_part_1', fname)\n            dst = os.path.join(data_dir, label, fname)\n            shutil.copyfile(src, dst)\n            \n        if fname in folder_2:\n            src = os.path.join(dataPath+'ham10000_images_part_2', fname)\n            dst = os.path.join(data_dir, label, fname)\n            shutil.copyfile(src, dst)","c08452be":"copy_files(df_train, train_dir)\ncopy_files(df_val, val_dir)\ncopy_files(df_test, test_dir)","951a6fbf":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntarget_size = (224,224)\nbatch_size = 16\n\n# Data Generator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    'data\/train',\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',    \n    shuffle=True,\n    seed=42,\n    class_mode='categorical')","6eafdf40":"valid_datagen = ImageDataGenerator(rescale=1.\/255)\n\nvalid_generator = valid_datagen.flow_from_directory(\n    'data\/val',\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')","03202d2a":"test_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    'data\/test',\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')","6dd6311b":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense","d45179b5":"#base_model=keras.applications.MobileNetV2(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.InceptionV3(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.ResNet50V2(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.ResNet101V2(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.ResNet152V2(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.DenseNet121(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.DenseNet169(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.DenseNet201(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.NASNetMobile(input_shape=(224,224,3), weights='imagenet',include_top=False)\n#base_model=keras.applications.NASNetLarge(input_shape=(331,331,3), weights='imagenet',include_top=False)","42c6ac0f":"!pip install -q efficientnet","82e6e083":"import efficientnet.tfkeras as efn\nbase_model = efn.EfficientNetB7(input_shape=(224,224,3), weights='imagenet', include_top=False)","c24b6ebe":"## Add Extra Layers to Model\nx=base_model.output\nx=GlobalAveragePooling2D()(x)      \nx=Dense(1024,activation='relu')(x) \nx=Dense(64,activation='relu')(x)\nout=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n\nmodel=Model(inputs=base_model.input,outputs=out)","1953da19":"## for transfer learning\nbase_model.trainable = False \n\nmodel.summary()","eecc797b":"# Compile Model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","07f8d476":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST =test_generator.n\/\/test_generator.batch_size\n\nnum_epochs = 30","270c2287":"# Add weights to make the model more sensitive to melanoma due to data equilibre\nclass_weights={\n    0: 1.0,  # akiec\n    1: 1.0,  # bcc\n    2: 1.0,  # bkl\n    3: 1.0,  # df\n    4: 3.0,  # mel\n    5: 1.0,  # nv\n    6: 1.0,  # vasc\n}","9a24622d":"model.fit_generator(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, class_weight=class_weights, validation_data=valid_generator, validation_steps=STEP_SIZE_VALID)","517ae46d":"# Save Model\nmodel.save('tl_skinlesion.h5')","18968239":"# Evaluate Model\nloss, acc = model.evaluate_generator(test_generator, steps=STEP_SIZE_TEST)\nprint(\"The accuracy of the model is {:.3f}\\nThe Loss in the model is {:.3f}\".format(acc,loss))","5dc2928f":"from sklearn.metrics import classification_report, confusion_matrix\n\npredY=model.predict_generator(test_generator)\ny_pred = np.argmax(predY,axis=1)\n#y_label= [labels[k] for k in y_pred]\ny_actual = test_generator.classes\ncm = confusion_matrix(y_actual, y_pred)\nprint(cm)","07043adc":"print(classification_report(y_actual, y_pred, target_names=labels))","c462848e":"fig, ax = plt.subplots()\nax.matshow(cm, cmap='Blues')\n\nfor (i, j), z in np.ndenumerate(cm):\n    ax.text(j, i, '{:d}'.format(z), ha='center', va='center')\nplt.show()","f4e792b2":"## EfficientNet-B7 transfer learning","21111b68":"## Plot confusion matrix","51896f40":"### read metadata","47eb3c01":"## Data Augmentation","5aa84d4f":"## Train Model ","f4c5e550":"## Data Equilibre ","e09b9901":"# Skin Lesion Classification","2aa29c6c":"## classification report","7b8a0fd0":"## Evaluate Model","df401375":"## Build Model","f803bf1e":"### *can not split folers in local disk, because kaggle disk space limit = 5GB*\n","e924dbd3":"![image.png](attachment:image.png)","b2781260":"## Confusion Matrix","7a4aaaf1":"### add extra layers","31cf0831":"## Copy files from input dataset to local directory","59962044":"## Save Model"}}