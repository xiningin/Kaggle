{"cell_type":{"24463e26":"code","2d0dc61e":"code","be96d3fb":"code","8e55b36c":"code","a2a5c715":"code","fd34f6f2":"code","aa988d1e":"code","8095b181":"code","31c979c7":"code","9c5652c4":"markdown"},"source":{"24463e26":"!pip install tensorflow_addons\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nimport pandas as pd\nimport numpy as np\nimport random\nfrom tensorflow.keras.callbacks import Callback, LearningRateScheduler\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import losses, models, optimizers\nimport tensorflow_addons as tfa\nimport gc\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import f1_score\n\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2d0dc61e":"# configurations and main hyperparammeters\nEPOCHS = 180\nNNBATCHSIZE = 16\nGROUP_BATCH_SIZE = 4000\nSEED = 321\nLR = 0.0015\nSPLITS = 6\n\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)","be96d3fb":"# read data\ndef read_data():\n    train = pd.read_csv('\/kaggle\/input\/data-without-drift\/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n    test  = pd.read_csv('\/kaggle\/input\/data-without-drift\/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\n    sub  = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/sample_submission.csv', dtype={'time': np.float32})\n    \n    Y_train_proba = np.load(\"\/kaggle\/input\/ion-shifted-rfc-proba\/Y_train_proba.npy\")\n    Y_test_proba = np.load(\"\/kaggle\/input\/ion-shifted-rfc-proba\/Y_test_proba.npy\")\n    \n    for i in range(11):\n        train[f\"proba_{i}\"] = Y_train_proba[:, i]\n        test[f\"proba_{i}\"] = Y_test_proba[:, i]\n\n    return train, test, sub\n\n# create batches of 4000 observations\ndef batching(df, batch_size):\n    df['group'] = df.groupby(df.index\/\/batch_size, sort=False)['signal'].agg(['ngroup']).values\n    df['group'] = df['group'].astype(np.uint16)\n    return df\n\n# normalize the data (standard scaler). We can also try other scalers for a better score!\ndef normalize(train, test):\n    train_input_mean = train.signal.mean()\n    train_input_sigma = train.signal.std()\n    train['signal'] = (train.signal - train_input_mean) \/ train_input_sigma\n    test['signal'] = (test.signal - train_input_mean) \/ train_input_sigma\n    return train, test\n\n# get lead and lags features\ndef lag_with_pct_change(df, windows):\n    for window in windows:    \n        df['signal_shift_pos_' + str(window)] = df.groupby('group')['signal'].shift(window).fillna(0)\n        df['signal_shift_neg_' + str(window)] = df.groupby('group')['signal'].shift(-1 * window).fillna(0)\n    return df\n\n# main module to run feature engineering. Here you may want to try and add other features and check if your score imporves :).\ndef run_feat_engineering(df, batch_size):\n    # create batches\n    df = batching(df, batch_size = batch_size)\n    # create leads and lags (1, 2, 3 making them 6 features)\n    df = lag_with_pct_change(df, [1, 2, 3])\n    # create signal ** 2 (this is the new feature)\n    df['signal_2'] = df['signal'] ** 2\n    return df\n\n# fillna with the mean and select features for training\ndef feature_selection(train, test):\n    features = [col for col in train.columns if col not in ['index', 'group', 'open_channels', 'time']]\n    train = train.replace([np.inf, -np.inf], np.nan)\n    test = test.replace([np.inf, -np.inf], np.nan)\n    for feature in features:\n        feature_mean = pd.concat([train[feature], test[feature]], axis = 0).mean()\n        train[feature] = train[feature].fillna(feature_mean)\n        test[feature] = test[feature].fillna(feature_mean)\n    return train, test, features","8e55b36c":"train, test, sample_submission = read_data()\ntrain, test = normalize(train, test)","a2a5c715":"train = run_feat_engineering(train, batch_size = GROUP_BATCH_SIZE)\ntest = run_feat_engineering(test, batch_size = GROUP_BATCH_SIZE)\ntrain, test, features = feature_selection(train, test)","fd34f6f2":"#\ntrain['signal_rolling_mean_1h'] = train['signal'].rolling(window = 100).mean().fillna(0)\ntest['signal_rolling_mean_1h'] = test['signal'].rolling(window = 100).mean().fillna(0)\n\ntrain['signal_rolling_std_1h'] = train['signal'].rolling(window = 100).std().fillna(0)\ntest['signal_rolling_std_1h'] = test['signal'].rolling(window = 100).std().fillna(0)\n\ntrain['signal_rolling_median_1h'] = train['signal'].rolling(window = 100).median().fillna(0)\ntest['signal_rolling_median_1h'] = test['signal'].rolling(window = 100).median().fillna(0)\n\n#\ntrain['signal_rolling_mean_1t'] = train['signal'].rolling(window = 1000).mean().fillna(0)\ntest['signal_rolling_mean_1t'] = test['signal'].rolling(window = 1000).mean().fillna(0)\n\ntrain['signal_rolling_std_1t'] = train['signal'].rolling(window = 1000).std().fillna(0)\ntest['signal_rolling_std_1t'] = test['signal'].rolling(window = 1000).std().fillna(0)\n\ntrain['signal_rolling_median_1t'] = train['signal'].rolling(window = 1000).median().fillna(0)\ntest['signal_rolling_median_1t'] = test['signal'].rolling(window = 1000).median().fillna(0)\n\n# #\n# train['signal_rolling_mean_3h'] = train['signal'].rolling(window = 333).mean().fillna(0)\n# test['signal_rolling_mean_3h'] = test['signal'].rolling(window = 333).mean().fillna(0)\n\n# train['signal_rolling_std_3h'] = train['signal'].rolling(window = 333).std().fillna(0)\n# test['signal_rolling_std_3h'] = test['signal'].rolling(window = 333).std().fillna(0)\n\n# train['signal_rolling_median_3h'] = train['signal'].rolling(window = 333).median().fillna(0)\n# test['signal_rolling_median_3h'] = test['signal'].rolling(window = 333).median().fillna(0)\n\ntrain['shift_100'] = train['signal'].shift(100)\ntrain['shift_1000'] = train['signal'].shift(1000)\n\ntest['shift_100'] = test['signal'].shift(100)\ntest['shift_1000'] = test['signal'].shift(1000)","aa988d1e":"train.head()","8095b181":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nX = train.drop(['time', 'open_channels'], axis = 1)\ny = train['open_channels']\nX_test = test.drop(['time'], axis = 1)\n\n# \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5206\u5272\u3059\u308b\nX_train, X_val, y_train, y_val = train_test_split(X, y)\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u751f\u6210\u3059\u308b\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n# LightGBM \u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\nlgbm_params = {\n    'objective': 'multiclass',\n    'num_class': 11}\n\n# \u4e0a\u8a18\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3059\u308b\nmodel = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval)\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e88\u6e2c\u3059\u308b\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\ny_pred_max = np.argmax(y_pred, axis=1)","31c979c7":"sample_submission['open_channels'] = y_pred_max\n# sample_submission['open_channels'].value_counts()\n\nsample_submission.to_csv('submission_wavenet_lgbm.csv', index=False, float_format='%.4f')","9c5652c4":"Many thanks to https:\/\/www.kaggle.com\/nxrprime\/wavenet-with-shifted-rfc-proba-and-cbr"}}