{"cell_type":{"8ad8f82e":"code","351bcd3c":"code","5a95d2c8":"code","3bc50ffb":"code","deece140":"code","37684eb0":"code","5894b9db":"code","a111813c":"code","af30bb94":"code","c49672ef":"code","f51f7d67":"code","dcad76ad":"code","2605fc7d":"code","887aa4e9":"code","67bf7a3c":"code","ab5a89e5":"code","ddc6d0f8":"code","3a5ac6da":"code","96a3e905":"code","a0f1c6db":"code","3fe80574":"code","b9507d45":"code","213a3b29":"code","6a0316e2":"code","e80a8751":"code","426f018a":"code","1d572d04":"code","f2e924b7":"code","c3f7c0e6":"markdown","b86fba9b":"markdown","29c6f3a6":"markdown","ad4d8ef7":"markdown","d383cc0d":"markdown","7a0d322f":"markdown","049e5545":"markdown","4001e3e0":"markdown","060bdf37":"markdown","33892387":"markdown","a33e5bf9":"markdown","53a4d5a9":"markdown","2c491f53":"markdown","6cbebfba":"markdown","0c86e2ef":"markdown","2a4ffd75":"markdown","0f5500ea":"markdown","4b8b1815":"markdown","155bacf6":"markdown","60262992":"markdown","f2b0b1bd":"markdown","194c5cae":"markdown","77edf617":"markdown","7bc949aa":"markdown","6535bc3c":"markdown","243cdd08":"markdown","03c15409":"markdown","0c3643ef":"markdown","c8b52da9":"markdown","3201ce6b":"markdown","0c67660c":"markdown","aa23d7c5":"markdown","f6c2555a":"markdown","157f2f2a":"markdown","293fa491":"markdown","bd77e42c":"markdown","bad1f2d0":"markdown","b32afca5":"markdown","7e9b1ece":"markdown","07d15423":"markdown","5f215610":"markdown","9c119308":"markdown","606a5783":"markdown","d309d0cc":"markdown","d76a9e9c":"markdown","a0bccc0c":"markdown"},"source":{"8ad8f82e":"import sys\n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")","351bcd3c":"import tensorflow as tf\n\nprint(tf.__version__)","5a95d2c8":"import matplotlib.pyplot as plt\nimport os\nimport cv2\n#pip install opencv-python\nfrom tqdm import tqdm\nimport numpy as np","3bc50ffb":"DATADIR = \"..\/input\/images\"\n\nCATEGORIES = [\"Dog\/Dog\", \"Cat\/Cat\"]\n\nfor category in CATEGORIES: \n    path = os.path.join(DATADIR,category) \n    for img in os.listdir(path): \n        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE) \n        plt.imshow(img_array, cmap='gray') \n        plt.show()  \n\n        break \n    break  ","deece140":"print(img_array.shape)","37684eb0":"IMG_SIZE = 40\n\nnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\nplt.imshow(new_array, cmap='gray')\nplt.show()\n","5894b9db":"for i in np.arange(10,200,35):\n\n    IMG_SIZE = i\n\n    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    plt.imshow(new_array, cmap='gray')\n    plt.show()","a111813c":"IMG_SIZE = 50\n\nnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\nplt.imshow(new_array, cmap='gray')\nplt.show()\n","af30bb94":"training_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:  # do dogs and cats\n\n        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n\n        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n            try:\n                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n                training_data.append([new_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass\n            #except OSError as e:\n            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n            #except Exception as e:\n            #    print(\"general exception\", e, os.path.join(path,img))\n\ncreate_training_data()\n\nprint(len(training_data))","c49672ef":"import random\n\nrandom.shuffle(training_data)","f51f7d67":"for sample in training_data[:10]:\n    print(sample[1])","dcad76ad":"IMG_SIZE = 50\n\n\n\nX = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\ny = np.array(y)\n\nprint(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)","2605fc7d":"import pickle\n\npickle_out = open(\"X.pickle\",\"wb\")\npickle.dump(X, pickle_out)\npickle_out.close()\n\npickle_out = open(\"y.pickle\",\"wb\")\npickle.dump(y, pickle_out)\npickle_out.close()","887aa4e9":"pickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)","67bf7a3c":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nimport pickle\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\n\nX = X\/255.0 #VERY IMPORTANT STEPS\n\nmodel = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n\nmodel.add(Dense(64))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.fit(X, y, batch_size=32, epochs=3, verbose = 2, validation_split=0.3)","ab5a89e5":"from tensorflow.keras.callbacks import TensorBoard","ddc6d0f8":"model.fit(X, y,\n          batch_size=32,\n          epochs=3,\n          validation_split=0.3,\n           verbose = 2,\n          callbacks = [tf.keras.callbacks.TensorBoard(log_dir=\"logs\/{}\".format(NAME), histogram_freq=1, profile_batch = 100000000)])","3a5ac6da":"tensorboard = TensorBoard(log_dir=\"logs\/{}\".format(NAME))\ncallbacks = [tensorboard])","96a3e905":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n# more info on callbakcs: https:\/\/keras.io\/callbacks\/ model saver is cool too.\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nimport time\n\nNAME = \"Cats_vs_dogs-CNN\" #you need to create this repository before running or you will encounter an error\n\n#logdir = \"logs\\\\model\"\n\n#https:\/\/github.com\/tensorflow\/tensorboard\/issues\/2819    help for directory\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\n\nX = X\/255.0\n\nmodel = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n#tensorboard = TensorBoard(log_dir=\"logs\/{}\".format(NAME))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'],\n              )\n\n\nimport tensorflow as tf\n#call = keras.callbacks.TensorBoard(log_dir=logdir)\n\nmodel.fit(X, y,\n          batch_size=32,\n          epochs=3,\n          validation_split=0.3,\n           verbose = 2,\n          #callbacks = [tensorboard])\n          \n          \n          callbacks = [tf.keras.callbacks.TensorBoard(log_dir=\"logs\/{}\".format(NAME), histogram_freq=1, profile_batch = 100000000)])","a0f1c6db":"model.save('firstmodel.model')","3fe80574":"model = tf.keras.models.load_model(\"firstmodel.model\")","b9507d45":"import time\n\ndense_layers = [0,1]\nlayer_sizes = [16,32]\nconv_layers = [1,2]\n\nfor dense_layer in dense_layers:\n    for layer_size in layer_sizes:\n        for conv_layer in conv_layers:\n            NAME = \"{}-conv-{}-node-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n            print(NAME)","213a3b29":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n# more info on callbakcs: https:\/\/keras.io\/callbacks\/ model saver is cool too.\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nimport time\n\n\n#https:\/\/github.com\/ibab\/tensorflow-wavenet\/issues\/255  solve directory problem\n\nNAME = \"Cats_vs_dogs-CNN\"\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\n\nX = X\/255.0\n\ndense_layers = [0,1]\nlayer_sizes = [16,32]\nconv_layers = [1,2]\n\nfor dense_layer in dense_layers:\n    for layer_size in layer_sizes:\n        for conv_layer in conv_layers:\n            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n            print(NAME)\n\n            model = Sequential()\n\n            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n            model.add(Activation('relu'))\n            model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            for l in range(conv_layer-1):\n                model.add(Conv2D(layer_size, (3, 3)))\n                model.add(Activation('relu'))\n                model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            model.add(Flatten())\n\n            for _ in range(dense_layer):\n                model.add(Dense(layer_size))\n                model.add(Activation('relu'))\n\n            model.add(Dense(1))\n            model.add(Activation('sigmoid'))\n\n            #tensorboard = TensorBoard(log_dir=\"logs\/{}\".format(NAME))\n\n            model.compile(loss='binary_crossentropy',\n                          optimizer='adam',\n                          metrics=['accuracy'],\n                          )\n\n            model.fit(X, y,\n                      batch_size=32,\n                      epochs=10,\n                      validation_split=0.3,\n                      verbose = 2,\n                      callbacks = [tf.keras.callbacks.TensorBoard(log_dir=\"logs\\{}\".format(NAME), histogram_freq=1, profile_batch = 100000000)])","6a0316e2":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n# more info on callbakcs: https:\/\/keras.io\/callbacks\/ model saver is cool too.\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nimport time\n\n\n#https:\/\/github.com\/ibab\/tensorflow-wavenet\/issues\/255  solve directory problem\n\nNAME = \"CNNopti\"\n\npickle_in = open(\"X.pickle\",\"rb\")\nX = pickle.load(pickle_in)\n\npickle_in = open(\"y.pickle\",\"rb\")\ny = pickle.load(pickle_in)\n\nX = X\/255.0\n\ndense_layers = [1]\nlayer_sizes = [32]\nconv_layers = [2]\n\nfor dense_layer in dense_layers:\n    for layer_size in layer_sizes:\n        for conv_layer in conv_layers:\n\n\n            model = Sequential()\n\n            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n            model.add(Activation('relu'))\n            model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            for l in range(conv_layer-1):\n                model.add(Conv2D(layer_size, (3, 3)))\n                model.add(Activation('relu'))\n                model.add(MaxPooling2D(pool_size=(2, 2)))\n\n            model.add(Flatten())\n\n            for _ in range(dense_layer):\n                model.add(Dense(layer_size))\n                model.add(Activation('relu'))\n\n            model.add(Dense(1))\n            model.add(Activation('sigmoid'))\n\n            #tensorboard = TensorBoard(log_dir=\"logs\/{}\".format(NAME))\n\n            model.compile(loss='binary_crossentropy',\n                          optimizer='adam',\n                          metrics=['accuracy'],\n                          )\n\n            model.fit(X, y,\n                      batch_size=32,\n                      epochs=10,\n                      validation_split=0.3,\n                      verbose = 2,\n                      callbacks = [tf.keras.callbacks.TensorBoard(log_dir=\"logs\\{}\".format(NAME), histogram_freq=1, profile_batch = 100000000)])","e80a8751":"model.save('CNNopti.model')","426f018a":"import tensorflow as tf\n\nCATEGORIES = [\"Dog\", \"Cat\"]  # will use this to convert prediction num to string value\n\n\ndef prepare(filepath):\n    IMG_SIZE = 50\n    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n    img_array = img_array\/255.0\n    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)","1d572d04":"model = tf.keras.models.load_model(\"CNNopti.model\")","f2e924b7":"prediction = model.predict([prepare('..\/input\/prediction\/dog.jpg')])  \nprint(CATEGORIES[int(prediction[0][0])])","c3f7c0e6":"First, we need a dataset,  let's grab the Dogs vs Cats dataset from Microsoft. I : https:\/\/www.microsoft.com\/en-us\/download\/confirmation.aspx?id=54765","b86fba9b":"Let's save this data, so that we don't need to keep calculating it every time we want to play with the neural network model. For this, we can use pickle, if you don't know it : https:\/\/docs.python.org\/3\/library\/pickle.html","29c6f3a6":"First things first, let's import it.","ad4d8ef7":"To begin, let's think of a few things we could do to this model that we'd like to know.\n\nThe most basic things for us to modify are layers and nodes per layer, as well as 0, 1, or 2 dense layers. Let's test those things.","d383cc0d":"We definitely don't want the images that big, but also various images are different shapes, and this is also a problem. Let's modify that.","7a0d322f":"There you have how to use your model to predict new samples.\n\nSo this is the end of my little tutorial on how to use TensorBoard, I hope you found it useful and learn some nice things.\n\nI would thanks Sentdex for those beautiful videos on TensorFlow and TensorBoard. If this tutorial was established, thanks to him.\n\nI would highly recommend to anyone who's into Data Science with Python to check out his youtube channel, he's awesome and wholesome. \n\nhttps:\/\/www.youtube.com\/channel\/UCfzlCWGWYyIQ0aLC5w48gBQ\n\nHave a nice day.","049e5545":"Even just toying with these parameters will take some significant time. We haven't even begun to touch other concepts like varying layer sizes, activation functions, learning rates, dropouts, and much much more.","4001e3e0":"Next, we want to load our model :","060bdf37":"Yes it is ! ","33892387":"So, previously we introduce TensorBoard, which is an application that we can use to visualize our model's training stats over time. In this tutorial, we're going to continue on that to exemplify how you might build a workflow to optimize your model's architecture.","a33e5bf9":"It's too much, let's search for the perfect IMG_SIZE.","53a4d5a9":"Let's see the shape. ","2c491f53":"If you want to load it :","6cbebfba":"Next let's shuffle our data for good measure.","0c86e2ef":"After having run this, you should have a new directory called logs. We can visualize the initial results from this directory using tensorboard now. Open a console, change to your working directory, and type: tensorboard --logdir=logs\/. You should see a notice like: TensorBoard 1.10.0 at http:\/\/H-PC:6006 (Press CTRL+C to quit) where \"h-pc\" probably is whatever your machine's name is. Open a browser and head to this address. You should see something like:","2a4ffd75":"For me, this method doesn't work but maybe for you it will work. ","0f5500ea":"So let's put this all together now !","4b8b1815":"<a id=\"6\"><\/a> <br>\n## 6. Make predictions with our model","155bacf6":"The way that we use TensorBoard with Keras is via a Keras callback. If you want to check out all the Keras callbacks, here it is : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/TensorBoard\n\nLet's focus on TensorBoard, we want to make our TensorBoard callback object.\n\nThis will save the model's training data to logs\/NAME, which can then be read by TensorBoard.\n\nWe can add it into our model by adding it to the .fit method, with callbacks, like :","60262992":"Now we can see how our model did over time. We can also save it for later if we want to rerun it directly.","f2b0b1bd":"![](https:\/\/i.ytimg.com\/vi\/pJt6erSOnm0\/maxresdefault.jpg)","194c5cae":"<a id=\"2\"><\/a> <br>\n## 2. Loading your own data","77edf617":"Now, we can make our prediction !","7bc949aa":"You could also use : ","6535bc3c":"First, we some images. I am going to use a couple of images that I know to be unique.\nYou can also go to google images and grab some there too. That said, there's a high chance the images from google images are contained in the dataset we used, so, if you have some unique ones, use those.\n\nWhat were the things we did to our training images? We grayscaled, resized, and reshaped. Let's create a function that does all of that.","243cdd08":"Now let's build our training data :","03c15409":"<a id=\"4\"><\/a> <br>\n## 4. Analysing model with TensorBoard","0c3643ef":"<a id=\"1\"><\/a> <br>\n## 1. Import packages","c8b52da9":"We can load it whatever and whenever we want, we just need the files in our folder !","3201ce6b":"For me, the best model is : \n- **dense_layers** = *1*\n- **layer_sizes** = *32*\n- **conv_layers** = *2*\n\nSo let's try that.","0c67660c":"Nice result for a first try ! Now let's talk about **TensorBoard** :)","aa23d7c5":"<a id=\"5\"><\/a> <br>\n## 5. Optimising model with TensorBoard","f6c2555a":"Again, if you want to see which model perform better, go to your TensorBoard. First Open a console, change to your working directory, and type: tensorboard --logdir=logs\/.\n\nYou should have something like this :\n\n![](https:\/\/pythonprogramming.net\/static\/images\/machine-learning\/optimizing-models.png)\n\nIf you have a lot of model, you can filter or zoom to see which one perform the most eficiently.","157f2f2a":"50 seems good.","293fa491":"So now, let's see how our model predict well !","bd77e42c":"You could make more parameters, more variables, if fou wish, if you have the right computer, go for it but my computer isn't quite strong enough at the moment so those parameters will do the job for me :)","bad1f2d0":"As usual, we save our best model with pickle.","b32afca5":"Hello there, I would like to show you a nice little thing Tensorflow has in this pocket : TensorBoard.\n\nFor those who don't know, this is tool that show you in real time how your Deep Learning model, or models, perform in your browser. I found that very useful, you can have some nice dashboard. Moreover il you need to explain your model to your co_worker, non familiar with Deep Learnig or even Data Science, this is the perfect tool to explain quickly and efficiently. \n\nBut before that, I will import some database and build my model, and after I will explain how to setup and use TensorBoard.\n\nFor now, I give you the link to TensorBoard : https:\/\/www.tensorflow.org\/tensorboard\/","7e9b1ece":"So let's build our model now.","07d15423":"Time to make our Neural Network ! Let's import the packages needed.","5f215610":"<a id=\"7\"><\/a> <br>\n## 7. Conclusion","9c119308":"It's time to make our model, if you don't know anything about Neural Network and Deep Learning, I strongly recommand this wonderful playlist by 3blue1brown : https:\/\/www.youtube.com\/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\n\nIt's really awesome how he can explain stuff so easily and yet so hard.","606a5783":"Let's verify if it's nicely shuffled !","d309d0cc":"<a id=\"3\"><\/a> <br>\n## 3. First Deep Learning model","d76a9e9c":"![](https:\/\/pythonprogramming.net\/static\/images\/machine-learning\/tensorboard-basic.png)","a0bccc0c":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">&nbsp;Table of Contents:<\/h1>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#1\" role=\"tab\" aria-controls=\"profile\">Import packages<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2\" role=\"tab\" aria-controls=\"messages\">Loading your own data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#3\" role=\"tab\" aria-controls=\"settings\">First Deep Learning model<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#4\" role=\"tab\" aria-controls=\"settings\"> Analysing model with TensorBoard<span class=\"badge badge-primary badge-pill\">4<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#5\" role=\"tab\" aria-controls=\"settings\">Optimising model with TensorBoard<span class=\"badge badge-primary badge-pill\">5<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6\" role=\"tab\" aria-controls=\"settings\"> Make predictions with our model<span class=\"badge badge-primary badge-pill\">6<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#7\" role=\"tab\" aria-controls=\"settings\">Conclusion<span class=\"badge badge-primary badge-pill\">5<\/span><\/a> \n<\/div>"}}