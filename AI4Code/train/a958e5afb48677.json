{"cell_type":{"3243cab7":"code","c372a008":"code","4ccc717f":"code","ec8d7f65":"code","1be243c4":"code","03847d3b":"code","38acc278":"code","beca5768":"code","3b99ce89":"code","de627c9e":"code","f854b949":"code","353ff63a":"code","7df678f7":"code","91ac7705":"code","25016ea9":"code","1238447f":"code","6a4b6265":"code","c90fd083":"code","70e7b527":"code","42917808":"code","b53a7313":"code","667ae3a0":"code","641dbddf":"code","cd374508":"code","501955c0":"code","58ac170a":"code","a78d15a5":"markdown","ec8bf619":"markdown","d8f2b931":"markdown","a60acb30":"markdown","3d0872c0":"markdown","6aedcf71":"markdown","08850f51":"markdown","6d625bcb":"markdown","18bf72ae":"markdown","ef4b50ae":"markdown","b441f5be":"markdown"},"source":{"3243cab7":"from IPython.display import Image\nImage(\"..\/input\/inception\/pokemons.png\")","c372a008":"import numpy as np\nimport pandas as pd\nimport math\n\nfrom sklearn.model_selection import train_test_split","4ccc717f":"import tensorflow as tf\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Conv2D, Activation, MaxPool2D, BatchNormalization, Flatten, Dense, Dropout, concatenate, AveragePooling2D\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import LearningRateScheduler","ec8d7f65":"import cv2\nimport glob\nimport os","1be243c4":"labels = np.array(list(os.walk('..\/input\/pokemon-generation-one\/dataset\/'))[0][1])\nnp.random.shuffle(labels)","03847d3b":"# Selecting only 10 pokemons to train\nlabels = labels[:10]","38acc278":"idx_to_name = {i:x for (i,x) in enumerate(labels)}\nname_to_idx = {x:i for (i,x) in enumerate(labels)}","beca5768":"# Selected pokemons to train\nidx_to_name","3b99ce89":"data = []\nlabels_one_hot = []\n\nfor label in labels:\n    path = '..\/input\/pokemon-generation-one\/dataset\/' + label + '\/'\n    imgs = np.array([cv2.resize(cv2.imread(img), (224,224), interpolation = cv2.INTER_AREA) for img in glob.glob(path + '*.jpg')])\n    if(len(imgs) > 0):\n        for i in imgs:\n            labels_one_hot.append(name_to_idx[label])\n        data.append(imgs)\n    \ndata = np.array(data)\ndata = np.concatenate(data)\n\ndata = data \/ 255.0\ndata = data.astype('float32')\nlabels_one_hot = np.eye(len(list(idx_to_name.keys())))[labels_one_hot]","de627c9e":"X_train, X_test, y_train, y_test = train_test_split(data, labels_one_hot, test_size=0.3, random_state=42)","f854b949":"kernel_init = tf.keras.initializers.glorot_uniform()\nbias_init = tf.keras.initializers.Constant(value=0.2)","353ff63a":"def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce,\nfilters_5x5, filters_pool_proj, name=None):\n    # create the 1x1 convolution layer that takes its input directly from the previous layer\n    conv_1x1 = Conv2D(filters_1x1, kernel_size=(1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n\n    # 3x3 route = 1x1 conv + 3x3 conv\n    pre_conv_3x3 = Conv2D(filters_3x3_reduce, kernel_size=(1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    conv_3x3 = Conv2D(filters_3x3, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pre_conv_3x3)\n\n    # 5x5 route = 1x1 conv + 5x5 conv\n    pre_conv_5x5 = Conv2D(filters_5x5_reduce, kernel_size=(1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    conv_5x5 = Conv2D(filters_5x5, kernel_size=(5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pre_conv_5x5)\n\n    # pool route = pool layer + 1x1 conv\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n\n    # concatenate the depth of the 3 filters together\n    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n\n    return output","7df678f7":"Image(\"..\/input\/inception\/inception.png\")","91ac7705":"# input layer with size = 24x24x3\ninput_layer = Input(shape=(224, 224, 3))\n \nx = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7\/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n \nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3\/2')(x)\n \nx = BatchNormalization()(x)\n \nx = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu')(x)\nx = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu')(x)\n \nx = BatchNormalization()(x)\n \nx = MaxPool2D((3, 3), padding='same', strides=(2, 2))(x)","25016ea9":"x = inception_module(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool_proj=32, name='inception_3a')\n \nx = inception_module(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool_proj=64, name='inception_3b')\n \nx = MaxPool2D((3, 3), padding='same', strides=(2, 2))(x)","1238447f":"x = inception_module(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool_proj=64, name='inception_4a')\n \nx = inception_module(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64, name='inception_4b')\n \nx = inception_module(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64, name='inception_4c')\n \nx = inception_module(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool_proj=64, name='inception_4d')\n \nx = inception_module(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128, name='inception_4e')\n \nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3\/2')(x)","6a4b6265":"x = inception_module(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128, name='inception_5a')\n \nx = inception_module(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool_proj=128, name='inception_5b')","c90fd083":"x = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(x)\nx = Dropout(0.4)(x)\nx = Flatten()(x)\nx = Dense(10, activation='softmax', name='output')(x)","70e7b527":"epochs = 500\ninitial_lrate = 0.01\n \n# implement the learning rate decay function\ndef decay(epoch, steps=100):\n    initial_lrate = 0.01\n    drop = 0.96\n    epochs_drop = 8\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)\/epochs_drop))\n    return lrate","42917808":"lr_schedule = LearningRateScheduler(decay, verbose=0)\n \nsgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)","b53a7313":"model = Model(input_layer, [x], name='googlenet')\n\nmodel.compile(loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'], loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=['accuracy'])","667ae3a0":"history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=16, callbacks=[lr_schedule], verbose=0)","641dbddf":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","cd374508":"print('Trying to predict ', labels[0])","501955c0":"img = cv2.imread('..\/input\/pokemon-generation-one\/dataset\/' + labels[0] + '\/' + list(os.walk('..\/input\/pokemon-generation-one\/dataset\/' + labels[0] + '\/'))[0][2][0])\nimg = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\nimg = img \/ 255.0\nimg = img.astype('float32')\nimg = np.array(img)\nimg = img.reshape(1, 224, 224, 3)","58ac170a":"predicted = idx_to_name[np.argmax(model.predict(img))]\nprint('Predicted ', predicted)","a78d15a5":"<a id='partb'><\/a>\n# Part B","ec8bf619":"# CNN Pokemon using Tensorflow and Inception Architecture","d8f2b931":"## Inception CNN\n\nInceptionv3 is a convolutional neural network for assisting in image analysis and object detection, and got its start as a module for Googlenet. It is the third edition of Google's Inception Convolutional Neural Network, originally introduced during the ImageNet Recognition Challenge. Just as ImageNet can be thought of as a database of classified visual objects, Inception helps classification of objects in the world of computer vision. One such use is in life sciences, where it aids in the research of Leukemia.<br>\nIt was \"codenamed 'Inception' after the film of the same name.","a60acb30":"<a id='parta'><\/a>\n# Part A","3d0872c0":"## Content\n* [Prepare Data to Train](#prepare)\n* [Architecture](#architecture)\n* [Implementation](#implementation)\n    * [Part A](#parta)\n    * [Part B](#partb)\n    * [Part D](#partd)\n* [Training](#training)\n* [Predict](#predict)","6aedcf71":"<a id='prepare'><\/a>\n# Prepare Data to Train","08850f51":"<a id='predict'><\/a>\n# Predict","6d625bcb":"<a id='implementation'><\/a>\n# Implementation","18bf72ae":"<a id='training'><\/a>\n# Training","ef4b50ae":"<a id='architecture'><\/a>\n# Architecture","b441f5be":"<a id='partd'><\/a>\n# Part D"}}