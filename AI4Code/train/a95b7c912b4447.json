{"cell_type":{"f6eb7119":"code","47093dd2":"code","dd1c442a":"code","dca42ff1":"code","5fb2b243":"code","d8eac3e9":"code","4d43989f":"code","63994096":"code","30a8a239":"code","c4b82681":"code","e1a8ac56":"code","06de0f13":"code","ccc1dbc1":"code","b6f06dab":"code","a608ca82":"code","0a86b839":"code","17719a94":"code","6d4df4c2":"code","928ada38":"code","05466853":"code","016b9e2b":"code","44d468fe":"code","bd4dafec":"code","82fead03":"code","864689e6":"code","f9fcacd9":"code","63ace35e":"code","a077a22a":"code","43a847d5":"code","3cb9dbb6":"code","e7f47113":"markdown","66df74d1":"markdown","af5e9777":"markdown","663cb837":"markdown","320c207a":"markdown"},"source":{"f6eb7119":"# \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435\nimport math, os, re, warnings, random \n# \u043d\u0430\u0448\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0430\u044f \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430\nimport tensorflow as tf \n# \u043d\u0430\u043c\u043f\u0438 \u0431\u0435\u0437 \u043d\u0435\u0433\u043e \u043d\u0438\u043a\u0430\u043a\nimport numpy as np \n# \u043f\u0430\u043d\u0434\u0430\u0441 \u043a\u0430\u043a \u0438 \u043d\u0430\u043c\u043f\u0438 \nimport pandas as pd \n# \u044d\u0442\u043e \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0437\u0432\u0443\u043a\u043e\u0432\nimport librosa\n# \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0432\u0432\u043e\u0434\u0430-\u0432\u044b\u0432\u043e\u0434\u0430 \u0442\u0435\u043d\u0437\u043e\u0440\u0444\u043b\u043e\u0443\nimport tensorflow.io \n# \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u041a\u0430\u0433\u0433\u043b\u0430, \u043e\u043d\u0430 \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u0430 \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043f\u0443\u0442\u0438 \u0434\u043e \u0434\u0430\u043d\u043d\u044b\u0445\nfrom kaggle_datasets import KaggleDatasets  \n# \u0440\u0438\u0441\u0443\u043d\u043a\u0438 \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0438 \u043a\u0440\u0430\u0441\u043e\u0442\u0430\nimport matplotlib.pyplot as plt \n# \u0435\u0449\u0451 \u0440\u0438\u0441\u0443\u043d\u043a\u0438 \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0438 \u043a\u0440\u0430\u0441\u043e\u0442\u0430 \u0434\u043b\u044f \u0437\u0432\u0443\u043a\u043e\u0432\nfrom IPython.display import Audio \n# \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043a\u0435\u0440\u0430\u0441\nfrom tensorflow.keras import Model, layers \n# \u0431\u0443\u0434\u0435\u043c \u0440\u0430\u0437\u0431\u0438\u0432\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0444\u043e\u043b\u0434\u044b\nfrom sklearn.model_selection import KFold \n#\nimport tensorflow.keras.backend as K # \n# \u043a\u043e\u043b\u0431\u044d\u043a\u0438 \u0434\u043b\u044f \u0440\u0430\u043d\u043d\u0435\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438, \u043f\u0440\u043e\u043c\u0435\u0436\u0443\u0442\u043e\u0447\u043d\u044b\u0445 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0439 \u0438 \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044f lr\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler \n# \u0443\u0440\u043e\u0432\u043d\u0438 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c \u0438\u0437 \u043a\u0435\u0440\u0430\u0441\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0430\u043c \u043f\u043e\u043d\u0430\u0434\u043e\u0431\u044f\u0442\u0441\u044f, \u043a\u0430\u043a \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0441\u043a\u043e\u0440\u0435\u0435, \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Dropout, GaussianNoise\n# ResNet50 \u043e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c,\n# \u043e\u043d\u0430 \u0445\u043e\u0440\u043e\u0448\u0430 \u0437\u0430\u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u043e\u0432\u0430\u043b\u0430 \u0441\u0435\u0431\u044f \u0434\u043b\u044f \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u043e\u0432\u0430\u043d\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n# \u0443 \u043d\u0435\u0451 \u0445\u043e\u0440\u043e\u0448\u0430\u044f \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u044c \u0446\u0435\u043d\u0430\/\u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e\n# \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0435\u0451 \u0434\u043b\u044f \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f \u0437\u0432\u0443\u043a\u043e\u0432\n# \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043a\u0440\u043e\u0441\u0441-\u044d\u043d\u0435\u0442\u0440\u043e\u043f\u0438\u044e\n# \u0432\u043e\u043e\u0431\u0449\u0435 \u043c\u044b \u043c\u043e\u0433\u043b\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0441\u043e\u0437\u0434\u0430\u0432\u0430\u0442\u044c \u0438 \u0441\u0432\u043e\u0438 \u043c\u043e\u0434\u0435\u043b\u0438\n# c \u0443\u0447\u0451\u0442\u043e\u043c \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0435\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043d\u0430\u0448\u0438\u0445 \u0442\u0440\u0435\u0431\u043e\u0432\u0430\u043d\u0438\u0439, \u043d\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043d\u0435\u0442 \u043d\u0430 \u044d\u0442\u043e\nfrom tensorflow.keras.applications import ResNet50\n# \u0432\u043e \u043c\u043d\u043e\u0433\u0438\u0445 \u0440\u0435\u0448\u0435\u043d\u043d\u044b\u0445 \u043d\u043e\u0442\u0430\u0445 \u043d\u0430 \u043a\u0430\u0433\u0433\u043b\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442\u0441\u044f efficientnet \u043c\u043e\u0434\u0435\u043b\u0438\n# \u043d\u043e \u044f \u043d\u0435 \u043d\u0430\u0441\u0442\u043e\u043b\u044c\u043a\u043e \u0445\u043e\u0440\u043e\u0448\u043e \u0438\u0445 \u0437\u043d\u0430\u044e, \u0447\u0442\u043e\u0431\u044b \u0441\u0435\u0439\u0447\u0430\u0441 \u0440\u0430\u0437\u0431\u0438\u0440\u0430\u0442\u044c\u0441\u044f \u0441 \u043d\u0435\u0439 \u0435\u0449\u0451\n# import efficientnet.keras as efn\nimport seaborn as sns # \u044d\u0442\u043e \u0437\u043d\u0430\u043c\u0435\u043d\u0438\u0442\u0430\u044f \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0434\u043b\u044f \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432, \u0442\u0435\u043f\u043b\u043e\u0432\u044b\u0445 \u043a\u0430\u0440\u0442 \u0438 \u0442.\u0434.","47093dd2":"# \u0432\u044b\u0432\u043e\u0434\u0438\u043c \u0432\u0435\u0440\u0441\u0438\u044e \u0442\u0435\u043a\u0443\u0449\u0435\u0439 \u0441\u0431\u043e\u0440\u043a\u0438 TF\n# \u044d\u0442\u043e \u0441\u043a\u043e\u0440\u0435\u0435 \u043f\u0435\u0440\u0435\u0441\u0442\u0440\u0430\u0445\u043e\u0432\u043a\u0430, \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435\nprint(tf.__version__)","dd1c442a":"# \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0438\u0441\u0442\u0438\u043d\u043d\u043e \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u043e\u0439 \u0442\u0440\u0435\u043d\u0438\u043d\u0433\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n# \u0435\u0441\u0442\u044c \u0435\u0449\u0451 \u0438 \u043b\u043e\u0436\u043d\u043e-\u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u0430\u044f, \u043d\u043e \u044f \u0435\u0451 \u043d\u0435 \u0442\u0440\u043e\u0433\u0430\u043b\u0430, \u0442.\u043a. \u043d\u0435 \u0437\u043d\u0430\u044e \u0447\u0442\u043e \u0441 \u043d\u0435\u0439 \u0434\u0435\u043b\u0430\u0442\u044c. \n#\u0418\u0437 \u043e\u043f\u044b\u0442\u0430 \u043c\u0443\u0437\u044b\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u0434\u0438\u0441\u043a\u0442\u0430\u043d\u0442\u043e\u0432 \u0438 \u0438\u0437\u0443\u0447\u0435\u043d\u0438\u044f \u0438\u043d. \u044f\u0437\u044b\u043a\u043e\u0432, \u044f \u043c\u043e\u0433\u0443 \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u044c, \u0447\u0442\u043e \u043e\u043d\u0430 \u043d\u0443\u0436\u043d\u0430 \n#\u0434\u043b\u044f \u043b\u0443\u0447\u0448\u0435\u0433\u043e \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f \u0441\u0445\u043e\u0436\u0438\u0445 \u0437\u0432\u0443\u043a\u043e\u0432, \u043d\u043e \u043d\u0435 \u0437\u043d\u0430\u044e, \u043a\u0430\u043a \u044d\u0442\u043e \u0434\u0435\u043b\u0430\u0442\u044c\ntraindf = pd.read_csv(r'..\/input\/rfcx-species-audio-detection\/train_tp.csv')\ntraindf.head()","dca42ff1":"# \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0444\u0438\u0447 \u0444\u043e\u0440\u043c\u0430\u0442\u0430 tfrecords \u0438\u0437 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\n# \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0439 \u043a\u043e\u0434\n# \u043e\u043d \u0432\u0440\u043e\u0434\u0435 \u0431\u044b \u0440\u043e\u0434\u043e\u043c \u0438\u0437 \u043e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u043c\u0430\u043d\u0443\u0430\u043b\u0430 \u0434\u0430\u0436\u0435\n\n# \u0432 \u044d\u0442\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0444\u0438\u0447\u0443 \u0441 \u0442\u0438\u043f\u043e\u043c BytesList\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n# \u0432 \u044d\u0442\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0444\u0438\u0447\u0443 \u0441 \u0442\u0438\u043f\u043e\u043c FloatList\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n# \u0432 \u044d\u0442\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043c\u044b \u0441\u0435\u0440\u0438\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u044e\n# \u0432 \u0441\u0442\u0440\u043e\u0447\u043a\u0443 \u0434\u043b\u044f \u0431\u0443\u0434\u0443\u0449\u0435\u0439 \u0437\u0430\u043f\u0438\u0441\u0438 \u0432 \u0444\u0430\u0439\u043b \u0444\u043e\u0440\u043c\u0430\u0442\u0430 tfrecords\n# \u043a\u0430\u0436\u0434\u0430\u044f \u0441\u0442\u0440\u043e\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0442\u0430\u043c \u0438\u043c\u043c\u0435\u0442 \u0442\u0438\u043f tf.train.Example \u0442\u0430\u043a \u0447\u0442\u043e \u0434\u0435\u043b\u0430\u0435\u043c \u0447\u0435\u0440\u0435\u0437 \u043d\u0435\u0451\ndef serialize_example(wav, recording_id, target, song_id, tmin,fmin, tmax, fmax):\n    feature = {\n      'wav': _bytes_feature(wav),\n      'recording_id': _bytes_feature(recording_id),\n      'target': _float_feature(target),\n      'song_id': _float_feature(song_id),\n      'tmin': _float_feature(tmin),\n      'fmin' : _float_feature(fmin),\n      'tmax': _float_feature(tmax),\n      'fmax' : _float_feature(fmax),\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    \n    return example_proto.SerializeToString() \n","5fb2b243":"from sklearn.model_selection import StratifiedKFold\n# \u0437\u0434\u0435\u0441\u044c \u043c\u044b \u0434\u043e\u043b\u0436\u043d\u044b \u0431\u044b\u043b\u0438 \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u043d\u043e\u0432\u044b\u0435 \u0444\u0430\u0439\u043b\u0438\u043a\u0438 tfrecords\n# \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438, \u043d\u043e \u043d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c\n# \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430 \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e TPU \u043c\u043e\u0436\u0435\u0442 \u0447\u0438\u0442\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0438\u0437 input\n# \u0430 \u043f\u0440\u044f\u043c\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043a input \u043d\u0435\u0442\n# \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0444\u0430\u0439\u043b\u0438\u043a\u0438 \u0441\u043e\u0437\u0434\u0430\u044e\u0442\u0441\u044f \u0432 \u043f\u0430\u043f\u043a\u0435 output\n# \u043f\u043e \u044d\u0442\u043e\u043c\u0443 \u044f \u0441\u0434\u0435\u043b\u0430\u043b\u0430 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u043d\u043e\u0442\u0435, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0441\u043e\u0437\u0434\u0430\u043b \u0444\u0430\u0439\u043b\u0438\u043a\u0438 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438\n# \u0438 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0438\u043b\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0435\u0433\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f, \u043a\u0430\u043a \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0435(input) \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u043e\u0442\u0435\n# \u0438 \u0442\u0430\u043a \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u043e :)\n\n\n# tfrec_num = 0\n# kfold = StratifiedKFold(n_splits=10, shuffle=False)\n# for fold, (train_idx, test_idx) in enumerate(kfold.split(traindf['recording_id'], traindf['species_id'])):\n#     x_train , y_train = traindf['recording_id'][test_idx] , traindf['species_id'][test_idx]\n   \n#     with tf.io.TFRecordWriter('tp%.2i-%.2i.tfrec'%(tfrec_num, len(test_idx))) as writer:\n#         print('Writing_tfrecords ',fold)\n#         for recording_id , true_value in zip(x_train, y_train): \n#             wav, _ = librosa.load(f'..\/input\/rfcx-species-audio-detection\/train\/{recording_id}.flac', sr = None)\n#             label_info = traindf.loc[traindf['recording_id'] == str(recording_id)].values[0]\n#             wav = tf.audio.encode_wav(tf.reshape(wav,(wav.shape[0], 1)) ,sample_rate = 48000)\n#             recording_id = label_info[0].encode()\n#             target = label_info[1]\n#             song_id = label_info[2]\n#             tmin = label_info[3]\n#             fmin = label_info[4]\n#             tmax = label_info[5]\n#             fmax = label_info[6]\n#             example = serialize_example(wav, recording_id, target, song_id, tmin,fmin, tmax, fmax)\n#             writer.write(example)\n#     tfrec_num += 1\n","d8eac3e9":"# \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0439 \u043a\u043e\u0434 \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0431\u043b\u043e\u043a\u043d\u043e\u0442\u043e\u0432 \u043d\u0430 \u041a\u0430\u0433\u0433\u043b\u0435\n# \u043c\u044b \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0430\u0435\u043c TPU \u0438\u043b\u0438 distribute \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e\u0441\u0442\u0438\n# distribute \u043c\u043e\u0436\u0435\u0442 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u043a\u0430\u043a \u0441 GPU \u0442\u0430\u043a \u0438 \u0441 CPU \n\n# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","4d43989f":"# \u0437\u0434\u0435\u0441\u044c \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432 \u0441 \u043f\u0443\u0442\u044f\u043c\u0438 \u0434\u043b\u044f \u043d\u0443\u0436\u043d\u044b\u0445 \u043d\u0430\u043c \u0434\u0430\u043d\u043d\u044b\u0445\n# \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 frog-song-data - \u044d\u0442\u043e \u0442\u043e \u0447\u0442\u043e \u043c\u044b \u0440\u0430\u0441\u0447\u0438\u0442\u0430\u043b\u0438\n# \u0432 \u0434\u0440\u0443\u0433\u043e\u043c \u0431\u043b\u043e\u043a\u043d\u043e\u0442\u0435 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u043d\u0433\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nTRAIN_DATA_DIR = 'frog-song-data'\nTRAIN_GCS_PATH =  KaggleDatasets().get_gcs_path(TRAIN_DATA_DIR)\nFILENAMES = tf.io.gfile.glob(TRAIN_GCS_PATH + '\/tp*.tfrec')","63994096":"#\u0430 \u044d\u0442\u043e \u043d\u0430\u0448\u0438 \u0442\u0435\u0442\u0441\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u043e\u043d\u0438 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u044e\u0442\u0441\u044f \u043a\u0430\u043a \u0438 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0435\nTEST_DATA_DIR = 'rfcx-species-audio-detection'\nTEST_GCS_PATH =  KaggleDatasets().get_gcs_path(TEST_DATA_DIR)\nTEST_FILES = tf.io.gfile.glob(TEST_GCS_PATH + '\/tfrecords\/test\/*.tfrec')","30a8a239":"# \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u043d\u043e\u043c\u0435\u0440 \u0432 \u0438\u043c\u0435\u043d\u0438 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0444\u0430\u0439\u043b\u0430 \u043e\u0437\u043d\u0430\u0447\u0430\u0435\u0442 \u043d\u043e\u043c\u0435\u0440 \u0441\u0435\u043c\u043f\u043b\u0430\n# \u043c\u044b \u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0447\u0438\u0441\u043b\u043e \u0441\u0435\u043c\u043f\u043b\u043e\u0432 \u0447\u0435\u0440\u0435\u0437 \u0447\u0438\u0441\u043b\u043e \u0444\u0430\u0439\u043b\u043e\u0432\n# \u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u0445\u043e\u0434... \u043d\u043e \u0440\u0430\u0431\u043e\u0447\u0438\u0439\nn = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in FILENAMES]\nprint(f\"Total number of rows :{np.sum(n)}\")\nno_of_training_samples=np.sum(n)","c4b82681":"# \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043f\u0430\u0440\u043c\u0435\u0442\u0440\u044b \u043d\u0430\u0448\u0438\u0445 \u0441\u043a\u0440\u0438\u043f\u0442\u043e\u0432\nCUT = 10\n# \u043e\u043a\u043d\u043e \u0432 \u0441\u0435\u043a. \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0434\u043e\u0440\u043e\u0436\u0435\u043a\nTIME = 10\n# \u0447\u0438\u0441\u043b\u043e \u044d\u043f\u043e\u0445\nEPOCHS = 25\n# \u0440\u0430\u0437\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430\nGLOBAL_BATCH_SIZE = 4 * REPLICAS\n# \u0448\u0430\u0433 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u0430 \u0431\u0430\u0437\u043e\u0432\u044b\u0439(\u043e\u043d \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u043d\u044f\u0442\u044c\u0441\u044f)\nLEARNING_RATE = 0.0015\n# \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u043e\u0442\u0436\u0438\u0433\u0430(\u043f\u0435\u0440\u0435\u0433\u0440\u0435\u0432\u0430) \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043a\u043e\u043b\u0431\u044d\u043a, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u043d\u044f\u0442\u044c \u043d\u0430 lr \nWARMUP_LEARNING_RATE = 1e-5\n# \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u043e\u0442\u0436\u0438\u0433\u0430(\u043f\u0435\u0440\u0435\u0433\u0440\u0435\u0432\u0430) \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043a\u043e\u043b\u0431\u044d\u043a, \u0447\u0438\u0441\u043b\u043e \u044d\u043f\u043e\u0445 \u0433\u0434\u0435 lr \u043c\u043e\u0436\u0435\u0442 \u0440\u0430\u0441\u0442\u0438\nWARMUP_EPOCHS = int(EPOCHS*0.1)\nPATIENCE = 8\n# \u0437\u0430 \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0448\u0430\u0433\u043e\u0432 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 TPU\nSTEPS_PER_EPOCH = 64\n#\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u043e\u043b\u0434\u043e\u0432, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u044b\u043c \u0431\u0443\u0434\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u0442\u044c\nN_FOLDS = 5\nNUM_TRAINING_SAMPLES = no_of_training_samples","e1a8ac56":"# \u0435\u0449\u0451 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n# \u044d\u0442\u043e \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441\u043f\u0435\u043a\u0442\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b, \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0432\u044b\u0442\u0430\u0441\u043a\u0438\u0432\u0430\u0442\u044c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e\n# \u0438\u0437 \u0437\u0432\u0443\u043a\u0430 \u0434\u043b\u044f \u0435\u0433\u043e \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u043e\u0432\u0430\u043d\u0438\u044f \u0438 \u044d\u0442\u043e \u043a\u0430\u043a \u0431\u044b \u043e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0437\u0430\u0434\u0430\u0447\u0430 \u0438 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430\n# \u0438\u043c\u0435\u043d\u043d\u043e \u0437\u0434\u0435\u0441\u044c \u0431\u0443\u0434\u0443\u0442 \u0437\u0430\u043f\u0440\u044f\u0442\u0430\u043d\u044b \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0435 \u043e\u0434\u043d\u043e\u0437\u043d\u0430\u0447\u043d\u043e\u0441\u0442\u0438 \u0438 \u043d\u0435\u043f\u043e\u043d\u044f\u0442\u043d\u043e\u0441\u0442\u0438\nclass params:\n    # \u044d\u0442\u043e \u0447\u0438\u0441\u043b\u043e \u0431\u0430\u0439\u0442 \u0432 \u0441\u0435\u043a\u0443\u043d\u0434\u0443 \u0434\u043b\u044f \u043d\u0430\u0448\u0435\u0439 \u0430\u0443\u0434\u0438\u043e \u0437\u0430\u043f\u0438\u0441\u0438\n    sample_rate = 48000\n    # \u044d\u0442\u043e \u0440\u0430\u0437\u043c\u0435\u0440 \u043e\u043a\u043d\u0430 \u0440\u0430\u0441\u043a\u043b\u0430\u0434\u044b\u0432\u0430\u0435\u043c\u043e\u0435 \u0432 \u0424\u0443\u0440\u044c\u0435 \u0432 \u0441\u0435\u043a\u0443\u043d\u0434\u0430\u0445\n    stft_window_seconds: float = 0.025\n    stft_hop_seconds: float = 0.005\n    # \u0434\u043b\u0438\u043d\u043d\u0430 \u043e\u043a\u043d\u0430 \u0432 \u0431\u0430\u0439\u0442\u0430\u0445 = sample_rate * stft_window_seconds\n    frame_length: int =  1200    \n    # \u043c\u0435\u043b\u044b - \u043a\u0430\u043a \u0445\u043e\u0440\u043e\u0448\u043e, \u0447\u0442\u043e \u044f \u0445\u043e\u0434\u0438\u043b\u0430 \u0432 \u043c\u0443\u0437\u044b\u043a\u0430\u043b\u043a\u0443 \u0432 \u0434\u0435\u0442\u0441\u0442\u0432\u0435\n    # \u043d\u043e \u0434\u0430\u0436\u0435 \u044d\u0442\u043e \u043d\u0435 \u0432\u0441\u0435\u0433\u0434\u0430 \u0441\u043f\u0430\u0441\u0430\u0435\u0442 :)\n    # \u043c\u0435\u043b\u044b - \u044d\u0442\u043e \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430 \u0432 \u043c\u0443\u0437\u044b\u043a\u0438, \u043e\u043d\u0430 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0447\u0435\u0441\u043a\u0438 \u0441\u0432\u044f\u0437\u0430\u043d\u0430 \u0441 \u0447\u0430\u0441\u0442\u043e\u0442\u043e\u0439\n    mel_bands: int = 512\n    mel_min_hz: float = 50.0\n    mel_max_hz: float = 24000.0\n    log_offset: float = 0.001\n    patch_window_seconds: float = 0.96\n    patch_hop_seconds: float = 0.48\n\n  \n    patch_frames =  int(round(patch_window_seconds \/ stft_hop_seconds))\n\n  \n    patch_bands = mel_bands\n    height = mel_bands\n    width = 2000\n    # \u0447\u0438\u0441\u043b\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\n    num_classes: int = 24\n    # \u0437\u0430\u0449\u0438\u0442\u0430 \u043e\u0442 \u043e\u0432\u0435\u0440\u0438\u0444\u0438\u0442\u0438\u043d\u0433\u0430, \u043d\u043e \u044d\u0442\u043e \u043d\u0435 \u0441\u0430\u043c\u044b\u0435 \u0433\u043b\u0430\u0432\u043d\u044b\u0439 \u0441\u043f\u043e\u0441\u043e\u0431 \u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435\n    # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0443\u0440\u043e\u0432\u043d\u044f dropout \u0434\u043b\u044f \"\u0437\u0430\u0431\u044b\u0432\u0430\u043d\u0438\u044f\" \u0441\u0442\u0430\u0440\u044b\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0432\u044f\u0437\u0435\u0439\n    # \u044d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e\n    # \u043d\u043e \u0433\u043b\u0430\u0432\u043d\u043e\u0435, \u044d\u0442\u043e \u0441\u043b\u043e\u0439 GaussianNoise\n    # \u043e\u043d \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u0442 \u0448\u0443\u043c \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043a \u0434\u0430\u043d\u043d\u044b\u043c input\n    # \u044d\u0442\u043e \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043d\u0430\u043c \u041d\u0415 \u043e\u0431\u0443\u0447\u0430\u0442\u044c \u043d\u0430\u0448\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0448\u0443\u043c\u0435\n    # \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u044b \u0438\u043d\u0430\u0447\u0435 \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u043b\u0441\u044f \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0435\n    dropout = 0.35\n    #\u0432\u043e\u043e\u0431\u0449\u0435 \u0434\u043e\u043b\u0436\u0435\u043d \u0431\u044b\u0442\u044c softmax, \u043d\u043e \u043f\u043e\u0447\u0435\u043c\u0443-\u0442\u043e sigmoid \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0435, \u043f\u043e\u043a\u0430 \u043d\u0435 \u043f\u043e\u043d\u0438\u043c\u0430\u044e\n    classifier_activation: str = 'sigmoid'","06de0f13":"# \u043e\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0444\u0438\u0447\u0438 \u0432 \u044d\u043a\u0437\u0430\u043c\u043f\u043b\u0430\u0445(\u0441\u0442\u0440\u0447\u043e\u043a\u0430\u0445) \u044d\u0442\u043e \u043d\u0443\u0436\u043d\u043e, \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u0437\u0436\u0435 \u0441 \u043d\u0438\u043c\u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c\nclassifier_activation: str = 'sigmoid'\nfeature_description = {\n    'wav': tf.io.FixedLenFeature([], tf.string),\n    'recording_id': tf.io.FixedLenFeature([], tf.string ),\n    'target' : tf.io.FixedLenFeature([], tf.float32),\n    'song_id': tf.io.FixedLenFeature([], tf.float32),\n     'tmin' : tf.io.FixedLenFeature([], tf.float32),\n     'fmin' : tf.io.FixedLenFeature([], tf.float32),\n     'tmax' : tf.io.FixedLenFeature([], tf.float32),\n     'fmax' : tf.io.FixedLenFeature([], tf.float32),\n}\nfeature_dtype = {\n    'wav': tf.float32,\n    'recording_id': tf.string,\n    'target': tf.float32,\n    'song_id': tf.float32,\n    't_min': tf.float32,\n    'f_min': tf.float32,\n    't_max': tf.float32,\n    'f_max':tf.float32,\n}","ccc1dbc1":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u044b\u0440\u043e\u0433\u043e \u0437\u0432\u0443\u043a\u0430 \u0432 \u0441\u043f\u0435\u043a\u0442\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443\n# \u043d\u043e \u043d\u0430\u0448\u0430 \u0441\u043f\u0435\u043a\u0442\u043e\u0440\u0433\u0440\u0430\u043c\u043c\u0430 \u0431\u0443\u0434\u0435\u0442 \u043d\u0435 \u043f\u043e \u0413\u0446, \u0430 \u043f\u043e \u043c\u0435\u043b\u0430\u043c\ndef waveform_to_log_mel_spectrogram(waveform,target_or_rec_id):\n    \"\"\"Compute log mel spectrogram patches of a 1-D waveform.\"\"\"\n    # \u044f \u0440\u0435\u0448\u0438\u043b\u0430 \u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0435 \u043a\u043e\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438\n    # waveform has shape [<# samples>]\n\n    # Convert waveform into spectrogram using a Short-Time Fourier Transform.\n    # Note that tf.signal.stft() uses a periodic Hann window by default.\n    \n    # \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043e\u043a\u043d\u0430 \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u0434\u0430\u0447\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 tf.signal.stft\n    # \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u043c\u043e\u0449\u043d\u043e\u0441\u0442\u0438 \u0437\u0432\u0443\u043a\u0430 \u043e\u0442 \u0413\u0446 \u043f\u043e\u043a\u0430 \u0432 \u0413\u0435\u0440\u0446\u0430\u0445\n    window_length_samples = int(round(params.sample_rate * params.stft_window_seconds))\n    hop_length_samples = int(round(params.sample_rate * params.stft_hop_seconds))\n    fft_length = 2 ** int(np.ceil(np.log(window_length_samples) \/ np.log(2.0)))\n    num_spectrogram_bins = fft_length \/\/ 2 + 1\n    # \u043f\u0435\u0440\u0435\u0434\u0430\u0451\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0438 \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043f\u0435\u043a\u0442\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443 (\u0413\u0435\u0440\u0446\u044b)\n    spectogram=tf.signal.stft(signals=waveform,frame_length=params.frame_length,frame_step=hop_length_samples,fft_length= fft_length)\n    magnitude_spectrogram = tf.abs(spectogram)\n    # magnitude_spectrogram has shape [<# STFT frames>, num_spectrogram_bins]\n\n    # Convert spectrogram into log mel spectrogram\n    # \u0442\u0435\u043f\u0435\u0440\u044c \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u0443 \u0438\u0437 \u0413\u0435\u0440\u0446 \u0432 \u043c\u0435\u043b\u044b\n    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n        num_mel_bins=params.mel_bands,\n        num_spectrogram_bins=num_spectrogram_bins,\n        sample_rate=params.sample_rate,\n        lower_edge_hertz=params.mel_min_hz,\n        upper_edge_hertz=params.mel_max_hz)\n    \n    mel_spectrogram = tf.matmul(magnitude_spectrogram, linear_to_mel_weight_matrix)\n    \n    log_mel = tf.math.log(mel_spectrogram + params.log_offset)\n    log_mel = tf.transpose(log_mel)\n    log_mel_spectrogram = tf.reshape(log_mel , [tf.shape(log_mel)[0] ,tf.shape(log_mel)[1],1])  \n    # \u0443\u0440\u0430, \u0442\u0435\u043f\u0435\u0440\u044c \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0432 \u043c\u0435\u043b\u0430\u0445\n    # \u0432\u0430\u0436\u043d\u043e \u0437\u0430\u043c\u0435\u0442\u0438\u0442\u044c, \u0447\u0442\u043e \u0432\u0441\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u043f\u043e \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0430\u0446\u0438\u0438 \u043c\u044b \u0434\u0435\u043b\u0430\u043b\u0438 \u043f\u0440\u0438 \u043f\u043e\u043c\u043e\u0449\u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u0439 TF\n    # \u0430 \u044d\u0442\u043e \u0437\u043d\u0430\u0447\u0438\u0442, \u0447\u0442\u043e \u043f\u0440\u0438 \u043a\u043e\u043c\u043f\u0438\u043b\u043b\u044f\u0446\u0438\u0438 \u0431\u0443\u0434\u0435\u0442 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d \u0433\u0440\u0430\u0444 \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u0438 \u044d\u0442\u0438\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u0439 \u043d\u0430\u0442\u0438\u0432\u043d\u043e\n    # \u0442.\u0435. \u0432\u0441\u0435 \u044d\u0442\u0438 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u0431\u0443\u0434\u0443\u0442 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u044b \u0432 \u0442\u0435\u043d\u0437\u043e\u0440\u043d\u044b\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f TF\n    # \u0447\u0442\u043e \u043e\u0447\u0435\u043d\u044c \u0432\u0430\u0436\u043d\u043e, \u0442.\u043a. \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u0442\u0435\u043d\u0437\u043e\u0440\u043d\u044b\u0445 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439 \u0431\u0443\u0434\u0443\u0442 \u043d\u0435\u0440\u0430\u0437\u0440\u044b\u0432\u043d\u044b \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0442\u044c\u0441\u044f \u0432 TPU\\GPU\n    # \u0441\u0435\u0439\u0447\u0430\u0441 \u0434\u043b\u044f \u043d\u0430\u0441 \u044d\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u0438 \u043d\u0435 \u0438\u043c\u0435\u0442\u044c \u043a\u0430\u043a\u043e\u0433\u043e-\u0442\u043e \u0434\u0438\u043a\u043e\u0433\u043e \u044d\u0444\u0444\u0435\u043a\u0442\u0430, \u043d\u043e \u043f\u0440\u0438 \u0440\u0430\u0431\u043e\u0442\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432 \u043f\u0440\u043e\u0434\u0435\n    # \u044d\u0442\u043e \u0441\u043a\u0430\u0436\u0435\u0442\u0441\u044f \u043e\u0447\u0435\u043d\u044c \u0441\u0438\u043b\u044c\u043d\u043e \u0432 \u0442.\u0447.\u0438 \u043d\u0430 \u043d\u0435\u043e\u0447\u0435\u0432\u0438\u0434\u043d\u043e\u043c \u0435\u0451 \u043f\u043e\u0432\u0435\u0434\u0435\u043d\u0438\u0438\n    # \u043d\u0430\u0434\u043e \u0441\u0442\u0430\u0440\u0430\u0442\u044c\u0441\u044f \u043d\u0435 \u0432\u044b\u0445\u043e\u0434\u0438\u0442\u044c \u0437\u0430 \u043f\u0440\u0435\u0434\u0435\u043b\u044b \u0444\u0443\u043d\u043a\u0446\u0438\u0439 TF\n    # \u0434\u0430\u0436\u0435 \u0432 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 =)\n    \n    # Frame spectrogram (shape [<# STFT frames>, params.mel_bands]) into patches\n    # (the input examples). Only complete frames are emitted, so if there is\n    # less than params.patch_window_seconds of waveform then nothing is emitted\n    # (to avoid this, zero-pad before processing).\n    spectrogram_hop_length_samples = int(round(params.sample_rate * params.stft_hop_seconds))\n    spectrogram_sample_rate = params.sample_rate \/ spectrogram_hop_length_samples\n    patch_window_length_samples = int(round(spectrogram_sample_rate * params.patch_window_seconds))\n    patch_hop_length_samples = int(round(spectrogram_sample_rate * params.patch_hop_seconds))\n    features = tf.signal.frame(signal=log_mel_spectrogram,frame_length=patch_window_length_samples,frame_step=patch_hop_length_samples,axis=0)\n    # features has shape [<# patches>, <# STFT frames in an patch>, params.mel_bands]\n    return log_mel_spectrogram, target_or_rec_id","b6f06dab":"# \u042d\u0442\u043e \u0432\u0441\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u043d\u0430\u0448\u0443 \u0432\u044b\u0431\u043e\u043a\u0443, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0430\u043d\u043d\u044b\u0445\n# \u0447\u0442\u043e\u0431\u044b \u043c\u043e\u0434\u0435\u043b\u044c \u043b\u0443\u0447\u0448\u0435 \u043e\u0431\u0443\u0447\u0430\u043b\u0430\u0441\u044c, \u043b\u0443\u0447\u0448\u0435 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u044f \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u044b\n\ndef frequency_masking(mel_spectrogram):\n    \n    frequency_masking_para = 80, \n    frequency_mask_num = 2\n    \n    fbank_size = tf.shape(mel_spectrogram)\n#     print(fbank_size)\n    n, v = fbank_size[0], fbank_size[1]\n\n    for i in range(frequency_mask_num):\n        f = tf.random.uniform([], minval=0, maxval= tf.squeeze(frequency_masking_para), dtype=tf.int32)\n        v = tf.cast(v, dtype=tf.int32)\n        f0 = tf.random.uniform([], minval=0, maxval= tf.squeeze(v-f), dtype=tf.int32)\n\n        # warped_mel_spectrogram[f0:f0 + f, :] = 0\n        mask = tf.concat((tf.ones(shape=(n, v - f0 - f,1)),\n                          tf.zeros(shape=(n, f,1)),\n                          tf.ones(shape=(n, f0,1)),\n                          ),1)\n        mel_spectrogram = mel_spectrogram * mask\n    return tf.cast(mel_spectrogram, dtype=tf.float32)\n\n\ndef time_masking(mel_spectrogram):\n    time_masking_para = 40, \n    time_mask_num = 1\n    \n    fbank_size = tf.shape(mel_spectrogram)\n    n, v = fbank_size[0], fbank_size[1]\n\n   \n    for i in range(time_mask_num):\n        t = tf.random.uniform([], minval=0, maxval=tf.squeeze(time_masking_para), dtype=tf.int32)\n        t0 = tf.random.uniform([], minval=0, maxval= n-t, dtype=tf.int32)\n\n        # mel_spectrogram[:, t0:t0 + t] = 0\n        mask = tf.concat((tf.ones(shape=(n-t0-t, v,1)),\n                          tf.zeros(shape=(t, v,1)),\n                          tf.ones(shape=(t0, v,1)),\n                          ), 0)\n        \n        mel_spectrogram = mel_spectrogram * mask\n    return tf.cast(mel_spectrogram, dtype=tf.float32)\n\n\n\ndef random_brightness(image):\n    return tf.image.random_brightness(image, 0.2)\n\ndef random_gamma(image):\n    return tf.image.random_contrast(image, lower = 0.1, upper = 0.3)\n\ndef random_flip_right(image):\n    return tf.image.random_flip_left_right(image)\n\ndef random_flip_up_down(image):\n    return tf.image.random_flip_left_right(image)\n\navailable_ops = [\n          frequency_masking ,\n          time_masking, \n          random_brightness, \n          random_flip_up_down,\n          random_flip_right \n         ]\n\n#\u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043e\u0442 \u043d\u0443\u043b\u044f \u0434\u043e \u0442\u0440\u0435\u0445 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439\ndef apply_augmentation(image, target):\n    num_layers = int(np.random.uniform(low = 0, high = 3))\n    \n    for layer_num in range(num_layers):\n        op_to_select = tf.random.uniform([], maxval=len(available_ops), dtype=tf.int32, seed = seed)\n        for (i, op_name) in enumerate(available_ops):\n            image = tf.cond(\n            tf.equal(i, op_to_select),\n            lambda selected_func=op_name,: selected_func(\n                image),\n            lambda: image)\n    return image, target","a608ca82":"# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0432 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0443 \u0434\u043b\u044f \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f\ndef preprocess(image, target_or_rec_id):\n    \n    image = tf.image.grayscale_to_rgb(image)\n    image = tf.image.resize(image, [params.height,params.width])\n    image = tf.image.per_image_standardization(image)\n    return image , target_or_rec_id\n\n# \u043c\u044b \u043e\u0431\u0440\u0435\u0437\u0430\u0435\u043c \u043d\u0430\u0448\u0438 wav (\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0437\u0430\u043f\u0438\u0441\u0438) \u043f\u043e \u043d\u0430\u0448\u0438\u043c \u0434\u043e\u043f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 tmin max, fmin max \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \n# \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0435, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0435 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 wav  \u0438 target\ndef read_labeled_tfrecord(example_proto):\n    # \u041e\u0431\u0440\u0430\u0442\u043d\u043e \u0440\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u043c \u0441\u0442\u0440\u043e\u0447\u043a\u0438 \u043d\u0430 \u0441\u0442\u043e\u043b\u0431\u0446\u044b\n    sample = tf.io.parse_single_example(example_proto, feature_description)\n    wav, _ = tf.audio.decode_wav(sample['wav'], desired_channels=1) # mono\n    # \u043a\u0430\u0441\u0442 \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u0440\u0443\u0435\u0442, \u0447\u0442\u043e \u0431\u0443\u0434\u0435\u0442 \u0442\u0438\u043f float\n    target = tf.cast(sample['target'],tf.float32)\n    #\u0434\u0435\u043b\u0430\u0435\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043a\u043b\u0430\u0441\u0441\u043e\u0432, \u043a\u0430\u043a \u043f\u0440\u043e\u0446\u0435\u0434\u0443\u0440\u0430 \u0434\u0430\u043c\u043c\u0438 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445, \u0442\u043e\u043b\u044c\u043a\u043e \u0441 \u0442\u0435\u043d\u0437\u043e\u0440\u043d\u044b\u043c\u0438 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u044f\u043c\u0438\n    target = tf.squeeze(tf.one_hot([target,], depth = params.num_classes), axis = 0)\n    \n    tmin = tf.cast(sample['tmin'], tf.float32)\n    fmin = tf.cast(sample['fmin'], tf.float32)\n    tmax = tf.cast(sample['tmax'], tf.float32)\n    fmax = tf.cast(sample['fmax'], tf.float32)\n    # \u041c\u0430\u043a\u0441 \u0438 \u043c\u0438\u043d \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0432 \u0431\u0430\u0439\u0442\u0430\u0445\n    tmax_s = tmax * tf.cast(params.sample_rate, tf.float32)\n    tmin_s = tmin * tf.cast(params.sample_rate, tf.float32)\n    # \u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0431\u0430\u0439\u0442\u044b\n    cut_s = tf.cast(CUT * params.sample_rate, tf.float32)\n    all_s = tf.cast(60 * params.sample_rate, tf.float32)\n    tsize_s = tmax_s - tmin_s\n    #\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043d\u0430\u0434\u043e \u043e\u0442\u0440\u0435\u0437\u0430\u0442\u044c \u0441\u043b\u0435\u0432\u0430\n    cut_min = tf.cast(\n    tf.maximum(0.0, \n        tf.minimum(tmin_s - (cut_s - tsize_s) \/ 2,\n                   tf.minimum(tmax_s + (cut_s - tsize_s) \/ 2, all_s) - cut_s)\n    ), tf.int32\n      )\n    #\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043d\u0430\u0434\u043e \u043e\u0442\u0440\u0435\u0437\u0430\u0442\u044c \u0441\u043f\u0440\u0430\u0432\u0430\n    cut_max = cut_min + CUT * params.sample_rate\n    wav = tf.squeeze(wav[cut_min : cut_max] )\n    \n    return wav, target\n\n# \u042d\u0442\u043e \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\ndef read_unlabeled_tfrecord(example):\n    feature_description = {\n    'recording_id': tf.io.FixedLenFeature([], tf.string),\n    'audio_wav': tf.io.FixedLenFeature([], tf.string),\n    }\n    sample = tf.io.parse_single_example(example, feature_description)\n    wav, _ = tf.audio.decode_wav(sample['audio_wav'], desired_channels=1) # mono\n    recording_id = tf.reshape(tf.cast(sample['recording_id'] , tf.string), [1])\n#     wav = tf.squeeze(wav)\n\n# \u041e\u0431\u0440\u0435\u0437\u0430\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0435 \u0430\u0443\u0434\u0438\u043e\n    def _cut_audio(i):\n        _sample = {\n            'audio_wav': tf.reshape(wav[i*params.sample_rate*TIME:(i+1)*params.sample_rate*TIME], [params.sample_rate*TIME]),\n            'recording_id': sample['recording_id']\n        }\n        return _sample\n\n    return tf.map_fn(_cut_audio, tf.range(60\/\/TIME), dtype={\n        'audio_wav': tf.float32,\n        'recording_id': tf.string\n    })","0a86b839":"# \u044d\u0442\u043e \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0443 \u0444\u0430\u0439\u043b\u043e\u0432 \u0438\u0437 tfrecords\ndef load_dataset(filenames, labeled = True, ordered = False , training = True):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # Diregarding data order. Order does not matter since we will be shuffling the data anyway\n    ignore_order = tf.data.Options()\n    if not ordered:\n        # disable order, increase speed\n        ignore_order.experimental_deterministic = False\n        \n#     GCS_PATH = KaggleDatasets().get_gcs_path('audio-note-generated')\n#     print(\"GCS_PATH: \"+GCS_PATH)\n    # automatically interleaves reads from multiple files\n    \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO )\n    # use data as soon as it streams in, rather than in its original order\n    # \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0447\u0435\u0440\u0435\u043c map \u043a\u043e \u0432\u0441\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f\n    # \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0432\u0435\u0442\u0441\u044f wav \u0438 target\n    dataset = dataset.map(read_labeled_tfrecord , num_parallel_calls = AUTO )\n    #\u043f\u0440\u0435\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0432 \u043c\u0435\u043b \u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u0443\n    dataset = dataset.map(waveform_to_log_mel_spectrogram , num_parallel_calls = AUTO)   \n    if training:\n        # \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u043e\u0440\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e (\u043f\u043e\u0440\u0442\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435) \u0434\u043b\u044f \u043b\u0443\u0432\u0447\u0448\u0435\u0433\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\n        dataset = dataset.map(apply_augmentation, num_parallel_calls = AUTO)\n        # \u0434\u0435\u043b\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0443\n    dataset = dataset.map(preprocess, num_parallel_calls = AUTO)\n    return dataset\n","17719a94":"# \u043e\u0431\u0435\u0440\u0442\u043a\u0430 \u0434\u043b\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0432\u044b\u0448\u0435 \u0441 \u0440\u0430\u0437\u0431\u0438\u0442\u0438\u0435\u043c \u043d\u0430 \u0431\u0430\u0442\u0447\u0438, \u0447\u0442\u043e\u0431\u044b \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0432 TPU\ndef get_dataset(filenames, training = True):\n    if training:\n        dataset = load_dataset(filenames , training = True)\n        dataset = dataset.shuffle(256).repeat()\n        dataset = dataset.batch(GLOBAL_BATCH_SIZE, drop_remainder = True)\n    else:\n        dataset = load_dataset(filenames , training = False)\n        dataset = dataset.batch(GLOBAL_BATCH_SIZE).cache()\n    \n    dataset = dataset.prefetch(AUTO)\n    return dataset\n","6d4df4c2":"# \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u044f\u0434\u0435\u0440 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0432\u0435\u043b\u0438\u0447\u0438\u043d, \u0447\u0442\u043e\u0431\u044b \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b \u0432\u0441\u0435\u0433\u0434\u044b \u0431\u044b\u043b\u0438 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u043c\u0438\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 42\nseed_everything(seed)\nwarnings.filterwarnings('ignore')\n","928ada38":"# \u044d\u0442\u043e \u044f \u0447\u0438\u0441\u0442\u043e \u0442\u0435\u0441\u0442\u0438\u043b\u0430, \u0443 \u043c\u0435\u043d\u044f \u044d\u0442\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0437\u0430\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0430 \u043d\u0435 \u0441\u0440\u0430\u0437\u0443, \u043c\u044f\u0433\u043a\u043e \u0433\u043e\u0432\u043e\u0440\u044f\ntrain_dataset = get_dataset(FILENAMES, training = True)\n","05466853":"# \u0437\u0434\u0435\u0441\u044c \u043c\u044b \u0441\u043e\u0437\u0434\u0430\u0451\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0443 \u0434\u043b\u044f \u043d\u0430\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438(\u043d\u0435 \u043e\u0448\u0438\u0431\u043a\u0443), \u043f\u0440\u043e\u0441\u0442\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0443\n# \u043e\u043d\u0430 \u0441\u0434\u0435\u043b\u0430\u043d\u0430 \u043f\u043e \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u044e \u043a\u043e\u043c\u043f\u0435\u0442\u0438\u0448\u0438\u043d\u0430, \u0442\u0430\u043a\u043e\u0439 \u043e\u043d\u0430 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043f\u0440\u0438 \u0432\u044b\u0431\u043e\u0440\u0435 \u043c\u0435\u0441\u0442\u0430 \u0443\u0447\u0430\u0441\u0442\u043d\u0438\u043a\u0430\n# \u0447\u0435\u043c \u044d\u0442\u0430 \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \u0432\u044b\u0448\u0435, \u0442\u0435\u043c \u043b\u0443\u0447\u0448\u0435 \u043c\u0435\u0441\u0442\u043e, \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c = 1 \u0438 \u043c\u0438\u043d\u0438\u043c\u0443\u043c = 0\n# \u043e\u0434\u043d\u0430\u043a\u043e \u0435\u0451 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043d\u0435 \u043e\u0431\u044b\u0447\u0435\u043d \u0434\u043b\u044f \u043c\u0435\u043d\u044f, \u044f \u043d\u0435 \u0443\u0432\u0435\u0440\u0435\u043d\u0430, \u0447\u0442\u043e \u043e\u043d\u0430 \u043f\u0440\u044f\u043c\u043e \u0443\u0434\u043e\u0432\u043b\u0435\u0442\u0432\u043e\u0440\u044f\u0435\u0442\n# \u0443\u0441\u043b\u043e\u0432\u0438\u044f\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \ndef _one_sample_positive_class_precisions(example):\n    y_true, y_pred = example\n    y_true = tf.reshape(y_true, tf.shape(y_pred))\n    retrieved_classes = tf.argsort(y_pred, direction='DESCENDING')\n#     shape = tf.shape(retrieved_classes)\n    class_rankings = tf.argsort(retrieved_classes)\n    retrieved_class_true = tf.gather(y_true, retrieved_classes)\n    retrieved_cumulative_hits = tf.math.cumsum(tf.cast(retrieved_class_true, tf.float32))\n\n    idx = tf.where(y_true)[:, 0]\n    i = tf.boolean_mask(class_rankings, y_true)\n    r = tf.gather(retrieved_cumulative_hits, i)\n    c = 1 + tf.cast(i, tf.float32)\n    precisions = r \/ c\n\n    dense = tf.scatter_nd(idx[:, None], precisions, [y_pred.shape[0]])\n    return dense\n\n# @tf.function\nclass LWLRAP(tf.keras.metrics.Metric):\n    def __init__(self, num_classes, name='lwlrap'):\n        super().__init__(name=name)\n\n        self._precisions = self.add_weight(\n            name='per_class_cumulative_precision',\n            shape=[num_classes],\n            initializer='zeros',\n        )\n\n        self._counts = self.add_weight(\n            name='per_class_cumulative_count',\n            shape=[num_classes],\n            initializer='zeros',\n        )\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        precisions = tf.map_fn(\n            fn=_one_sample_positive_class_precisions,\n            elems=(y_true, y_pred),\n            dtype=(tf.float32),\n        )\n\n        increments = tf.cast(precisions > 0, tf.float32)\n        total_increments = tf.reduce_sum(increments, axis=0)\n        total_precisions = tf.reduce_sum(precisions, axis=0)\n\n        self._precisions.assign_add(total_precisions)\n        self._counts.assign_add(total_increments)        \n\n    def result(self):\n        per_class_lwlrap = self._precisions \/ tf.maximum(self._counts, 1.0)\n        per_class_weight = self._counts \/ tf.reduce_sum(self._counts)\n        overall_lwlrap = tf.reduce_sum(per_class_lwlrap * per_class_weight)\n        return overall_lwlrap\n\n    def reset_states(self):\n        self._precisions.assign(self._precisions * 0)\n        self._counts.assign(self._counts * 0)\n","016b9e2b":"# \u044d\u0442\u043e \u0445\u0430\u043a \u0438\u0437 Keras_Bag_of_Tricks \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442 \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c lr\n# \u0432\u0440\u043e\u0434\u0435 \u0431\u044b \u044d\u0442\u043e \u0434\u043e\u043b\u0436\u043d\u043e \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442\u044c \u043a \u043b\u0443\u0447\u0448\u0435\u0439 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\n# \u0432 \u043d\u0430\u0447\u0430\u043b\u0435 \u043c\u044b \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u043c lr \u0440\u043e\u0441\u0442\u0435 \u0434\u043e warmup_steps\n# \u0430 \u043f\u043e\u0441\u043b\u0435 lr \u043f\u0430\u0434\u0430\u0435\u0442 \u043f\u0440\u0438\u0447\u0451\u043c \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0438 \u0441 \u043a\u0443\u0441\u043a\u043e\u043c \u0441\u0438\u043d\u0443\u0441\u043e\u0438\u0434\u044b\n# \u043d\u0438\u0436\u0435 \u0431\u0443\u0434\u0435\u0442 \u0433\u0440\u0430\u0444\u0438\u043a \u0441 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u043c\ndef cosine_decay_with_warmup(global_step,\n                             learning_rate_base,\n                             total_steps,\n                             warmup_learning_rate=0.0,\n                             warmup_steps= 0,\n                             hold_base_rate_steps=0):\n \n    if total_steps < warmup_steps:\n        raise ValueError('total_steps must be larger or equal to '\n                     'warmup_steps.')\n    learning_rate = 0.5 * learning_rate_base * (1 + tf.cos(\n        np.pi *\n        (tf.cast(global_step, tf.float32) - warmup_steps - hold_base_rate_steps\n        ) \/ float(total_steps - warmup_steps - hold_base_rate_steps)))\n    if hold_base_rate_steps > 0:\n        learning_rate = tf.where(\n          global_step > warmup_steps + hold_base_rate_steps,\n          learning_rate, learning_rate_base)\n    if warmup_steps > 0:\n        if learning_rate_base < warmup_learning_rate:\n            raise ValueError('learning_rate_base must be larger or equal to '\n                         'warmup_learning_rate.')\n        slope = (learning_rate_base - warmup_learning_rate) \/ warmup_steps\n        warmup_rate = slope * tf.cast(global_step,\n                                    tf.float32) + warmup_learning_rate\n        learning_rate = tf.where(global_step < warmup_steps, warmup_rate,\n                               learning_rate)\n    return tf.where(global_step > total_steps, 0.0, learning_rate,\n                    name='learning_rate')\n\n\n#dummy example\nrng = [i for i in range(int(EPOCHS * STEPS_PER_EPOCH))]\nWARMUP_STEPS =  int(WARMUP_EPOCHS * STEPS_PER_EPOCH)\ny = [cosine_decay_with_warmup(x , LEARNING_RATE, len(rng), 1e-5, WARMUP_STEPS) for x in rng]\n\nsns.set(style='whitegrid')\nfig, ax = plt.subplots(figsize=(20, 6))\nplt.plot(rng, y)\n","44d468fe":"# to apply learning rate schedule stepwise we need to subclass keras callback\n# if we would have applied lr schedule epoch wise then it is not needed we can only call class learningrateschedule \n# \u044d\u0442\u043e callback \u043e\u0431\u0435\u0440\u0442\u043a\u0430 \u043d\u0430\u0434 \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439 \u0432\u044b\u0448\u0435, \u043e\u043d\u0430 \u043d\u0443\u0436\u043d\u0430, \u0447\u0442\u043e\u0431\u044b \u043a\u0435\u0440\u0430\u0441 \u0441\u044a\u0435\u043b \u044d\u0442\u043e \u043a\u0430\u043a callback\nclass WarmUpCosineDecayScheduler(tf.keras.callbacks.Callback):\n\n    def __init__(self,\n                 learning_rate_base,\n                 total_steps,\n                 global_step_init=0,\n                 warmup_learning_rate=0.0,\n                 warmup_steps=0,\n                 hold_base_rate_steps=0,\n                 verbose=0):\n\n        super(WarmUpCosineDecayScheduler, self).__init__()\n        self.learning_rate_base = learning_rate_base\n        self.total_steps = total_steps\n        self.global_step = global_step_init\n        self.warmup_learning_rate = warmup_learning_rate\n        self.warmup_steps = warmup_steps\n        self.hold_base_rate_steps = hold_base_rate_steps\n        self.verbose = verbose\n        self.learning_rates = []\n\n    def on_batch_end(self, batch, logs=None):\n        self.global_step = self.global_step + 1\n        lr = K.get_value(self.model.optimizer.lr)\n        self.learning_rates.append(lr)\n\n    def on_batch_begin(self, batch, logs=None):\n        lr = cosine_decay_with_warmup(global_step=self.global_step,\n                                      learning_rate_base=self.learning_rate_base,\n                                      total_steps=self.total_steps,\n                                      warmup_learning_rate=self.warmup_learning_rate,\n                                      warmup_steps=self.warmup_steps,\n                                      hold_base_rate_steps=self.hold_base_rate_steps)\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print('\\nBatch %05d: setting learning '\n                  'rate to %s.' % (self.global_step + 1, lr.numpy()))\n            \n\ntotal_steps = int(EPOCHS * STEPS_PER_EPOCH)\n# Compute the number of warmup batches or steps.\nwarmup_steps = int(WARMUP_EPOCHS * STEPS_PER_EPOCH)\nwarmup_learning_rate = WARMUP_LEARNING_RATE\n","bd4dafec":"#\u0410 \u044d\u0442\u043e \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u043d\u0430\u0448\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \ndef ResNet50_MODEL():\n    waveform = Input(shape=(None,None,3), dtype=tf.float32)\n    noisy_waveform = GaussianNoise(0.2)(waveform)\n    model = ResNet50(include_top=False, weights='imagenet',) \n    model_output = model(noisy_waveform)\n    model_output = GlobalAveragePooling2D()(model_output)\n    dense = Dropout(params.dropout)(model_output)\n    predictions = Dense(params.num_classes, activation = params.classifier_activation )(dense)\n    model = Model(\n      name='ResNet50', inputs=waveform,\n      outputs=[predictions])\n    return model\n","82fead03":"# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0438 \u043a\u043e\u043c\u043f\u0438\u043b\u0438\u0440\u0443\u0435\u043c \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u043c\n# \u0431\u0438\u043d\u0430\u0440\u043d\u043e\u0439 \u043a\u0440\u043e\u0441\u044d\u043d\u0442\u0440\u043e\u043f\u0438\u0435\u0439 \u043a\u0430\u043a \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439 \u043f\u043e\u0442\u0435\u0440\u044c\n# \u0431\u0438\u043d\u0430\u0440\u043d\u0430\u044f \u043a\u0440\u043e\u0441\u044d\u0442\u0440\u043e\u043f\u0438\u044f \u0432\u044b\u0431\u0440\u0430\u043d\u0430 \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u0443 \u043d\u0430\u0441 \u043f\u0440\u043e\u0441\u0442\u0430\u044f \u043a\u043b\u0430\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f\n# \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0438\u0437 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0435\u0441\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u0432\u0430 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0445 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430\n# \u043b\u0438\u0431\u043e \u0437\u0432\u0443\u043a \u043f\u0440\u0438\u043d\u0430\u0434\u043b\u0435\u0436\u0438\u0442 \u044d\u0442\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443, \u043b\u0438\u0431\u043e \u043d\u0435\u0442\n# \u0438 \u043c\u0435\u0442\u0440\u0438\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0435\u0442\u0438\u0448\u0435\u043d\u0430 LWLRAP\ndef get_model():\n    with strategy.scope():\n        model = ResNet50_MODEL()\n        model.summary()\n        model.compile(optimizer = 'adam',\n                                loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.1),\n                                metrics = [LWLRAP(num_classes = params.num_classes),\n                                ])\n    return model","864689e6":"\nskf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\noof_pred = []; oof_labels = []; history_list = []\n\nfor fold,(idxT, idxV) in enumerate(skf.split(np.arange(10))):\n    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    print(f'\\nFOLD: {fold+1}')\n    print(f'TRAIN: {idxT} VALID: {idxV}')\n\n    # Create train and validation sets\n    TRAIN_FILENAMES = [FILENAMES[x] for x in idxT]\n    VALID_FILENAMES = [FILENAMES[x] for x in idxV]\n    np.random.shuffle(TRAIN_FILENAMES)\n    \n    train_dataset =  get_dataset(TRAIN_FILENAMES, training=True,)\n    validation_data= get_dataset(VALID_FILENAMES, training=False) \n    model = get_model()\n\n    model_path = f'RFCX_model_fold {fold}.h5'\n    early_stopping = EarlyStopping(monitor = 'val_lwlrap', mode = 'max', \n                       patience = PATIENCE, restore_best_weights=True, verbose=1)\n\n    # Create the Learning rate scheduler.\n    cosine_warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base= LEARNING_RATE,\n                                    total_steps= total_steps,\n                                    warmup_learning_rate= warmup_learning_rate,\n                                    warmup_steps= warmup_steps,\n                                    hold_base_rate_steps=0)\n\n    ## TRAIN\n    history = model.fit(train_dataset, \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        callbacks=[early_stopping, cosine_warm_up_lr], \n                        epochs=EPOCHS,  \n                        validation_data = validation_data,\n                        verbose = 2).history\n\n    history_list.append(history)\n    # Save last model weights\n    model.save_weights(model_path)\n\n# OOF predictions\n#     ds_valid = get_dataset(VALID_FILENAMES, training = False)\n#     oof_labels.append([target.numpy() for frame, target in iter(ds_valid.unbatch())])\n#     x_oof = ds_valid.map(lambda frames, target: frames)\n#     oof_pred.append(np.argmax(model.predict(x_oof), axis=-1))\n\n    ## RESULTS\n#     print(f\"#### FOLD {fold+1} OOF Accuracy = {np.max(history['val_lwlrap']):.3f}\")\n","f9fcacd9":"# def plot_history(history):\n#     plt.figure(figsize=(8,3))\n#     plt.subplot(1,2,1)\n#     plt.plot(history[\"loss\"])\n#     plt.plot(history[\"val_loss\"])\n#     plt.legend(['Train', 'Test'], loc='upper left')\n#     plt.title(\"loss\")\n\n#     plt.subplot(1,2,2)\n#     plt.plot(history[\"lwlrap\"])\n#     plt.plot(history[\"val_lwlrap\"])\n#     plt.legend(['Train', 'Test'], loc='upper left')\n#     plt.title(\"lwlrap\")\n    \n# for hist in history_list:\n#     plot_history(hist)\n","63ace35e":"def get_test_dataset(filenames, training = False):\n    \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO )  \n    dataset = dataset.map(read_unlabeled_tfrecord , num_parallel_calls = AUTO ).unbatch()\n    dataset = dataset.map(lambda spec : waveform_to_log_mel_spectrogram(spec['audio_wav'], spec['recording_id']) , num_parallel_calls = AUTO)\n    dataset = dataset.map(preprocess, num_parallel_calls = AUTO)\n    return dataset.batch(GLOBAL_BATCH_SIZE*4).cache()\n","a077a22a":"test_predict = []\n\ntest_data = get_test_dataset(TEST_FILES, training = False)\ntest_audio = test_data.map(lambda frames, recording_id: frames)\n\nfor fold in range(N_FOLDS):\n    model.load_weights(f'.\/RFCX_model_fold {fold}.h5')\n    test_predict.append(model.predict(test_audio, verbose = 1 ))\n","43a847d5":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c sample submission, \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u0442\u043e\u043c \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c \u043d\u0430 \u043d\u0430\u0448\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f, \u0447\u0442\u043e\u0431\u044b \u0431\u044b\u043b\u0438 \u0432 \u043d\u0443\u0436\u043d\u043e\u043c \u0444\u043e\u0440\u043c\u0430\u0442\u0435 \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0448\u0435\u043d\u0430\nSUB = pd.read_csv('..\/input\/rfcx-species-audio-detection\/sample_submission.csv')\n\npredict = np.array(test_predict).reshape(N_FOLDS, len(SUB), 60 \/\/ TIME, params.num_classes)\npredict = np.mean(np.max(predict ,axis = 2) , axis = 0)\n# predict = np.mean(predict, axis =  0)\n\nrecording_id = test_data.map(lambda frames, recording_id: recording_id).unbatch()\n# # all in one batch\ntest_ids = next(iter(recording_id.batch(len(SUB) * 60 \/\/ TIME))).numpy().astype('U').reshape(len(SUB), 60 \/\/ TIME)\n\npred_df = pd.DataFrame({ 'recording_id' : test_ids[:, 0],\n             **{f's{i}' : predict[:, i] for i in range(params.num_classes)} })\n","3cb9dbb6":"pred_df.sort_values('recording_id', inplace = True) \npred_df.to_csv('submission.csv', index = False)  ","e7f47113":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430\n> \u0418\u043c\u043f\u043e\u0440\u0442 \u0432\u0441\u0435\u0433\u043e \u0447\u0442\u043e \u043d\u0443\u0436\u043d\u043e \u0438 \u043d\u0435 \u043e\u0447\u0435\u043d\u044c. \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438","66df74d1":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0438 \u043a\u043e\u043b\u0431\u044d\u043a\u0430 \u0434\u043b\u044f \u0432\u0441\u0435\u0433\u043e","af5e9777":"# \u0421\u0440\u0430\u0437\u0443 \u043e\u0433\u043e\u0432\u043e\u0440\u044e\u0441\u044c\n> \u0412 \u044d\u0442\u043e\u043c \u043a\u043e\u043c\u043f\u0435\u0442\u0438\u0448\u0435\u043d\u0435 \u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430 \u0434\u0440\u0443\u0433\u0438\u0435 \u043d\u043e\u0442\u044b, \u0433\u0438\u0442\u0445\u0430\u0431, \u0433\u0443\u0433\u043b, \u044f\u043d\u0434\u0435\u043a\u0441 \u0438 arxiv.org\n","663cb837":"https:\/\/github.com\/Tony607\/Keras_Bag_of_Tricks\/blob\/master\/warmup_cosine_decay_scheduler.py\n\nhttps:\/\/arxiv.org\/abs\/1608.03983","320c207a":"# \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0438 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n> \u041f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u0438\u0437 \u0437\u0432\u0443\u043a\u0430 (\u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u044b, \u043c\u0435\u043b\u043e\u0433\u0440\u0430\u043c\u043c\u044b). \u0421\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445(\u0441\u043f\u0435\u043a\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u044b, \u043c\u0435\u043b\u043e\u0433\u0440\u0430\u043c\u043c\u044b) \u0432 \u043f\u0440\u044f\u043c\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u044b\u0435 \u0442\u0435\u043d\u0437\u043e\u0440\u044b \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u043a \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a"}}