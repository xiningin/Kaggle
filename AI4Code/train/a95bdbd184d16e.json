{"cell_type":{"535213be":"code","0f1215bd":"code","61721f56":"code","760f625d":"code","dc1071ca":"code","dc993196":"code","5f90dfc9":"code","6202f39a":"code","3323a5dc":"code","fcad8f7a":"code","cf825447":"code","bc340e8e":"code","68b51745":"code","50e153bf":"code","5aa40b05":"code","c39955d0":"code","adde6034":"code","2c82bf4c":"code","f23641d1":"code","13d963f0":"code","c3d325a0":"code","5e1f67af":"code","586b2a99":"code","4c2304e9":"code","4554d7d3":"code","4e91e045":"code","8b830ee6":"code","852d5571":"markdown","add2ebae":"markdown","9dd948b7":"markdown","30d8fc5d":"markdown","ae8c5f38":"markdown","40c066c1":"markdown"},"source":{"535213be":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D , MaxPooling2D , Dense, Flatten, Dropout, Input\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nimport tensorflow_hub as hub\nfrom tensorflow.keras.utils import to_categorical\n\nimport gc\nfrom tqdm import tqdm","0f1215bd":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()","61721f56":"X = np.concatenate((x_train,x_test)).reshape((-1,28,28,1))\ny = np.concatenate((y_train,y_test))","760f625d":"y = to_categorical(y)\ny[0]","dc1071ca":"BATCH_SIZE = 16","dc993196":"datagen = ImageDataGenerator(\n    rotation_range=10, \n    width_shift_range=2.0,\n    height_shift_range=0.5, \n    shear_range=1.0, \n    validation_split = 0.1\n)","5f90dfc9":"trainGen = datagen.flow(X,\n                   y,\n                   subset = 'training',\n                    shuffle=True,\n                    \n    batch_size = BATCH_SIZE,\n)\n\nvalGen = datagen.flow(X,\n                   y,\n                   subset = 'validation'\n)","6202f39a":"model = Sequential()\n\n# NET1\n# model.add(Conv2D(32,(4,4),activation = tf.nn.leaky_relu, input_shape=(28,28,1)))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(32,(4,4),activation = tf.nn.leaky_relu))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n# model.add(Conv2D(64,(3,3),activation = tf.nn.leaky_relu))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64,(3,3),activation = tf.nn.leaky_relu))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n# model.add(Conv2D(128,(2,2),activation = tf.nn.leaky_relu))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(256,(2,2),activation = tf.nn.leaky_relu))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n\n# NET2\nmodel.add(Conv2D(32,(2,2),activation = tf.nn.leaky_relu, input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32,(2,2),activation = tf.nn.leaky_relu))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(2,2),activation = tf.nn.leaky_relu))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64,(2,2),activation = tf.nn.leaky_relu))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(128,(2,2),activation = tf.nn.leaky_relu))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation= tf.nn.leaky_relu))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64,activation= tf.nn.leaky_relu))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(10,activation = 'softmax'))\nmodel.summary()","3323a5dc":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])","fcad8f7a":"hist = model.fit(\n    trainGen,\n    validation_data = valGen,\n    epochs = 50,\n    batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5 ,patience = 3)]\n)","cf825447":"gc.collect()","bc340e8e":"with open('model.json','w') as f:\n    f.write(model.to_json())\nmodel.save_weights('weights.h5')","68b51745":"mod2 = model","50e153bf":"!pip install kaggle","5aa40b05":"from google.colab import files\nfiles.upload()","c39955d0":"! mkdir ~\/.kaggle\n! cp kaggle.json ~\/.kaggle\/\n! chmod 600 ~\/.kaggle\/kaggle.json","adde6034":"! kaggle competitions download -c digit-recognizer ","2c82bf4c":"import zipfile\nwith zipfile.ZipFile(\"\/content\/test.csv.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"\/content\/\")","f23641d1":"test = pd.read_csv('\/content\/test.csv')\nsample = pd.read_csv('\/content\/sample_submission.csv')","13d963f0":"test_data = test.to_numpy().reshape((-1,28,28,1))","c3d325a0":"preds = np.zeros(test.shape[0])\ni = 0\nfor x in tqdm(test_data):\n    img = x.reshape((1,28,28,1))\n    pred = (model.predict(img) + mod2.predict(img))\/2\n    preds[i] = np.argmax(pred)\n    i+=1","5e1f67af":"gc.collect()","586b2a99":"results = pd.DataFrame()","4c2304e9":"results['ImageId'] = sample['ImageId']\nresults['Label'] = preds.astype(int)","4554d7d3":"results.head()","4e91e045":"results.to_csv('res.csv',index=False)","8b830ee6":"! kaggle competitions submit -c digit-recognizer -f \"res.csv\" -m \"TF v2.2\"","852d5571":"# Kaggle Testing","add2ebae":"# MNIST with Bagging\n\n<img src = \"https:\/\/miro.medium.com\/max\/800\/1*LyRlX__08q40UJohhJG9Ow.png\" width=400><br>\n\nThe idea behind this notebook is to use the entire MNIST Dataset and training 2 separate Neural Networks with different architectures. Finally the results from both will be averaged out to give us results. I managed to score 99.79% on Kaggle using this technique, hope this helps. ","9dd948b7":"## Neural Net","30d8fc5d":"# Instructions:\n- Train using NET1 once\n- save the model\n- Train using NET2\n- Predict using average of both network predictions","ae8c5f38":"## Image Augmentation","40c066c1":"## One Hot Encoding numbers"}}