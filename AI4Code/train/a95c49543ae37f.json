{"cell_type":{"af78b4d9":"code","6730b770":"code","7376a8eb":"code","53b340d0":"code","ac19ad6e":"code","6fe49d72":"code","84ace1cd":"code","9a3183e8":"code","4f81cdb5":"markdown","8f46236d":"markdown","b9e138a5":"markdown","4110748b":"markdown","bd77fe34":"markdown"},"source":{"af78b4d9":"import numpy as np\nfrom typing import *\n\nfiles = {\n    'jmp': '\/kaggle\/input\/tube-guitar-amplifiers-v1\/jmp.wav',\n    'jmp2': '\/kaggle\/input\/tube-guitar-amplifiers-v1\/jmp2.wav',\n    'od120': '\/kaggle\/input\/tube-guitar-amplifiers-v1\/od120.wav',\n    'twin': '\/kaggle\/input\/tube-guitar-amplifiers-v1\/twin.wav',\n    'clean': '\/kaggle\/input\/tube-guitar-amplifiers-v1\/clean.wav'\n}\n\namplifier = 'jmp'","6730b770":"#Credits: https:\/\/medium.com\/analytics-vidhya\/how-to-filter-noise-with-a-low-pass-filter-python-885223e5e9b7\n\nfrom scipy.signal import butter,filtfilt\n\ndef butter_lowpass_filter(data: np.ndarray, cutoff: float, fs: float, order: int) -> np.ndarray:\n    nyq = fs\/2\n    normal_cutoff = cutoff \/ nyq\n    # Get the filter coefficients \n    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n    y = filtfilt(b, a, data)\n    return y\n\ndef butter_highpass_filter(data: np.ndarray, cutoff: float, fs: float, order: int) -> np.ndarray:\n    nyq = fs\/2\n    normal_cutoff = cutoff \/ nyq\n    # Get the filter coefficients \n    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n    y = filtfilt(b, a, data)\n    return y\n\ndef treble_boost(data: np.ndarray, freq: float, gain: float, fs: float) -> np.ndarray:\n    order = 10\n    low = butter_lowpass_filter(data, freq, fs, order)\n    high = butter_highpass_filter(data, freq, fs, order)\n    return low\/(gain\/2) + high*(gain\/2)\n    \ndef treble_unboost(data: np.ndarray, freq: float, gain: float, fs: float) -> np.ndarray:\n    order = 10\n    low = butter_lowpass_filter(data, freq, fs, order)\n    high = butter_highpass_filter(data, freq, fs, order)\n    return low*(gain\/2) + high\/(gain\/2)","7376a8eb":"def split_wave(data: np.ndarray, samples_per_slice: int) -> List[np.ndarray]:\n    '''\n    Split wave data to slices.\n    Params:\n        data (np.ndarray): NumPy array containing audio signal.\n        samples_per_slice (int): Quantity of audio samples in each slice.\n    \n    Returns (List[np.ndarray]): List of slices.\n    '''\n    assert len(data.shape) == 1 #data shape must be (length,)\n\n    n_samples = data.shape[0] #Quantity of samples in data\n    n_slices = n_samples \/\/ samples_per_slice #Quantity of slices \n\n    l = [] #List where the slices will be inserted\n    for i in range(n_slices):\n        slc = data[i*samples_per_slice : (i+1)*samples_per_slice] #Slice\n        l.append(slc)\n    \n    return l","53b340d0":"import scipy.io.wavfile as wave\n\ndef load_dataset(x_filename: str, y_filename: str, samples_per_input: int, treble_boost_y=False) -> Tuple[np.ndarray, np.ndarray]:\n    '''\n    Load wave files as a dataset for keras.\n    Params:\n        x_filename (str): Name of the wave file with input data.\n        y_filename (str): Name of the wave file with target data.\n        samples_per_slice (int): Quantity of samples in each NN input.\n        treble_boost_y (bool): Boost (gain=2) the high frequencies (1KHz-20Khz) of Y audio. \n    '''\n    x_data = wave.read(x_filename)[1] #read data from the wav file\n    x_data = x_data \/ (2**16) #normalize data\n    \n    y_data = wave.read(y_filename)[1] #read data from the wav file\n    y_data = y_data \/ (2**16) #normalize data\n    \n    if treble_boost_y == True:\n        y_data = treble_boost(y_data, 1000, 4, 44100)\n    \n    y_data = butter_lowpass_filter(y_data, 10000, 44100, 10) #Cut frequencies above 10KHz\n    \n    # --- Split entire audio to chuncks ---\n    x_slices = split_wave(x_data, samples_per_input) \n    y_slices = split_wave(y_data, samples_per_input)\n    \n    x_dataset = np.vstack(x_slices)\n    y_dataset = np.vstack(y_slices)\n    \n    return (x_dataset, y_dataset)\n\nchunck_len = 1024\n\nx, y = load_dataset(files['clean'], files[amplifier], chunck_len, treble_boost_y=True)","ac19ad6e":"#Building model\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef build_model(input_len: int) -> keras.Sequential:\n    '''\n    Generate the Keras RNN model.\n    Params:\n        input_len (int) - Length of the input audio chunck.\n        \n    Returns (keras.Sequential): The keras model.\n    '''\n    model = keras.Sequential([\n        keras.Input(shape=(input_len,)),\n        layers.Reshape((input_len,1)),\n        layers.LSTM(12, return_sequences=True),\n        layers.Dropout(0.3),\n        layers.LSTM(12, return_sequences=True),\n        layers.Dropout(0.3),\n        layers.Flatten(),\n        layers.Dense(input_len*20, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(input_len*15, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(input_len*5, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(input_len, activation='linear'),\n    ])\n\n    model.compile(loss='mse', optimizer='rmsprop')\n\n    return model\n\nmodel = build_model(chunck_len)\n\nmodel.summary()","6fe49d72":"#Training\n\nes = keras.callbacks.EarlyStopping(patience=20)\n\nhist = model.fit(x, y, batch_size=150, epochs=1000, validation_split=0.25, callbacks=[es])\n\nmodel.save(f'{amplifier}_lstm_model.h5')","84ace1cd":"#Plotting training history\n\nimport matplotlib.pyplot as plt\n\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","9a3183e8":"# Testing the model and saving result to a wav file\n\nx_test = x[:x.shape[0]\/\/2]\ny_test = model.predict(x_test)\n\ny_test = y_test.reshape((1,y_test.shape[0]*y_test.shape[1]))[0] #Join chuncks to a single audio signal\ny_test = treble_unboost(y_test, 1000, 4, 44100) #Unboost treble (1KHz-20KHz)\ny_test = butter_lowpass_filter(y_test, 10000, 44100, 10) #Cut frequencies above 10KHz\n\nwave.write(f'{amplifier}_lstm_predict.wav', 44100, y_test)","4f81cdb5":"## Dataset preprocessing\n\nThe RNN's input is a audio chunck of 1024 normalized samples. Dataset's preprocessing must turn audio to sequences of chuncks and normalize it by dividing samples by $2^{16}$.","8f46236d":"## Model building and training","b9e138a5":"## Signal processing functions\n\nThe target audio (y dataset) goes through a treble boost for the training of the neural network so that the training fits it better for the amplifier's treble. Therefore, the neural network predictor must be proceeded by an \"unboost 'of treble.","4110748b":"## Final results\n\nThe final results consist of a graph showing the training history and an audio processed by the model.","bd77fe34":"# Marshall JMP's modeling using a recurrent neural network.\n\nThis notebook ran on Kaggle with GPU. The dataset used was **tube-guitar-amplifiers-v1** (https:\/\/www.kaggle.com\/filipechagas\/tube-guitar-amplifiers-v1)."}}