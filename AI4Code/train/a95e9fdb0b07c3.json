{"cell_type":{"43917dde":"code","febfa05c":"code","52c9d943":"code","308d8a88":"code","0ca539d5":"code","7b049721":"code","e604f7b9":"code","cc1afd32":"code","1ee3d3b3":"code","2059d687":"code","38c248f9":"code","2f63335e":"code","6e2da62c":"code","5d865b2f":"code","d6e34040":"code","53c8dff2":"code","bc89437a":"code","dbf7fc20":"code","dc9d52a3":"code","a6030cce":"code","e99e43ed":"code","9251b9ab":"code","0bd6b95a":"code","a0320398":"code","db6e756e":"code","2eda0ad4":"code","6e2f37ae":"code","4e260622":"code","b2f0cff7":"code","70c2033b":"code","775c3749":"code","14ecb6b4":"code","d47b51b5":"code","4aef7dd2":"code","dfab8423":"code","2f659f5f":"markdown","d39e57da":"markdown","984ab5db":"markdown","156b649c":"markdown","24a0ebc6":"markdown","c11bb4e9":"markdown","5f5196ad":"markdown","dfab373b":"markdown","306938f4":"markdown","15680fe4":"markdown","d59d7c72":"markdown"},"source":{"43917dde":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","febfa05c":"# Importando os dados\ndf = pd.read_csv('\/kaggle\/input\/bank-marketing\/bank-additional-full.csv', sep=';')\n\ndf.shape","52c9d943":"# Verificando quantidades e tipos\ndf.info()","308d8a88":"# Visualizando os dados\ndf.head().T","0ca539d5":"# N\u00e3o temos valores nulos mas temos dados como 'unknown'\n# Para facilitar vamos considerar esses dados como um tipo espec\u00edfico\ndf['job'].value_counts()","7b049721":"# Verificando tamb\u00e9m a coluna 'loan'\ndf['loan'].value_counts()","e604f7b9":"# O problema da vari\u00e1vel 'duration' - data leak - vazamento de dados\ndf.drop(columns=['duration'], axis=1, inplace=True)","cc1afd32":"# Convertendo as colunas object para colunas categ\u00f3ricas\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col] = df[col].astype('category').cat.codes\n        \ndf.info()","1ee3d3b3":"# Separando o dataframe\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df, test_size=0.20, random_state=42)\n\ntrain.shape, test.shape","2059d687":"# Lista das colunas a serem usadas para treino\nfeats = [c for c in df.columns if c not in ['y']]","38c248f9":"# Importando o RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Instanciando um objeto RandomForest\nrf = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n\n# Treinando o modelo\nrf.fit(train[feats], train['y'])","2f63335e":"# Fazer previs\u00f5es usando o modelo treinado\npreds = rf.predict(test[feats])\n\n# Importando a m\u00e9trica\nfrom sklearn.metrics import accuracy_score\n\n# Avaliando o modelo com rela\u00e7\u00e3o aos dados de teste\naccuracy_score(test['y'], preds)","6e2da62c":"# Verificando a distribui\u00e7\u00e3o da vari\u00e1vel target\ndf['y'].value_counts()","5d865b2f":"# Verificando a distribui\u00e7\u00e3o da vari\u00e1vel target (%)\ndf['y'].value_counts(normalize=True)","d6e34040":"# Verificando a distribui\u00e7\u00e3o da vari\u00e1vel target (%) - Base de treino\ntrain['y'].value_counts(normalize=True)","53c8dff2":"# Verificando a distribui\u00e7\u00e3o da vari\u00e1vel target (%) - Base de teste\ntest['y'].value_counts(normalize=True)","bc89437a":"# Importando uma biblioteca espec\u00edfica para plotar gr\u00e1ficos relacionada\n# com o scikitlearn\nimport scikitplot as skplt\n\n# Matriz de Confus\u00e3o - Dados de teste\nskplt.metrics.plot_confusion_matrix(test['y'], preds)","dbf7fc20":"# Importando a biblioteca\nfrom sklearn.utils import resample\n\n# Separando os dados de acordo com a classifica\u00e7\u00e3o\ndf_no = df[df['y'] == 0]\ndf_yes = df[df['y'] == 1]\n\ndf_no.shape, df_yes.shape","dc9d52a3":"# Over-Sampling\ndf_yes_over = resample(df_yes, # vamos aumentar a classe menor\n                       replace=True, # sample com replacement\n                       n_samples=len(df_no), # igualando a maior classe\n                       random_state=42)\n\n# juntando os dados\ndf_over= pd.concat([df_no, df_yes_over])\n\n# check new class counts\ndf_over['y'].value_counts()","a6030cce":"# Executando o modelo com df_over\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_over, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['y'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['y'], preds_test)","e99e43ed":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['y'], preds_test)","9251b9ab":"# Under-Sampling\ndf_no_under = resample(df_no, # vamos diminuir a classe maior\n                       replace=False, # sample sem replacement\n                       n_samples=len(df_yes), # igualando a menor classe\n                       random_state=42)\n\n# juntando os dados\ndf_under= pd.concat([df_no_under, df_yes])\n\n# check new class counts\ndf_under['y'].value_counts()","0bd6b95a":"# Executando o modelo com df_under\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_under, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['y'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['y'], preds_test)","a0320398":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['y'], preds_test)","db6e756e":"# Importando a biblioteca\nimport imblearn","2eda0ad4":"# Separando os dados de entrada e o target\nX, y = df[feats], df[['y']]","6e2f37ae":"# Importando a biblioteca\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Fazendo o over-sampling\nros = RandomOverSampler(random_state=42)\nX_ros,y_ros= ros.fit_resample(X,y)\n\n# Verificando os dados\ny_ros['y'].value_counts()","4e260622":"# Executando o modelo com imblearn over-sampling\n\n# Juntando os dados\ndf_over = pd.concat([X_ros, y_ros], axis=1)\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_over, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['y'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['y'], preds_test)","b2f0cff7":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['y'], preds_test)","70c2033b":"# Importando a biblioteca\nfrom imblearn.under_sampling import TomekLinks\n\n# Fazendo o under-sampling\ntl = TomekLinks()\nX_tl, y_tl = tl.fit_resample(X,y)\n\n# Verificando os dados\ny_tl['y'].value_counts()","775c3749":"# Executando o modelo com Tomek-links\n\n# Juntando os dados\ndf_under = pd.concat([X_tl, y_tl], axis=1)\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_under, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['y'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['y'], preds_test)","14ecb6b4":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['y'], preds_test)","d47b51b5":"# Importando a biblioteca\nfrom imblearn.over_sampling import SMOTE\n\n# Fazendo o under-sampling\nsm = SMOTE()\nX_sm, y_sm = sm.fit_resample(X,y)\n\n# Verificando os dados\ny_sm['y'].value_counts()","4aef7dd2":"# Executando o modelo com SMOTE\n\n# Juntando os dados\ndf_over = pd.concat([X_sm, y_sm], axis=1)\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_over, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['y'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['y'], preds_test)","dfab8423":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['y'], preds_test)","2f659f5f":"### Random Over-Sampling ","d39e57da":"# Parte 2\n## Tratando classes desbalanceadas","984ab5db":"## Confusion Matrix","156b649c":"### Random Under-Sampling","24a0ebc6":"### Imblearn Random Over-Sampling","c11bb4e9":"## Usando a bilioteca imbalanced-learn\nEssa biblioteca implementa diversos modelos diferentes para tratar classes desabalanceadas","5f5196ad":"## Fazendo Random Under-Sampling e Random Over-Sampling\nVamos usar o pr\u00f3pio sklearn para realizar under e over sampling de forma aleat\u00f3ria","dfab373b":"# IESB - CIA035 - Aula 04 - Classes desbalanceadas","306938f4":"### Imblearn SMOTE (over-sampling)","15680fe4":"# Parte 1\n## Tratamento de dados e execu\u00e7\u00e3o do modelo","d59d7c72":"### Imblearn Tomek-links (under-sampling)"}}