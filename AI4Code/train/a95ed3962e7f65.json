{"cell_type":{"daf725f3":"code","debdcdfe":"code","b585cfb1":"code","ed3ef55c":"code","3093930b":"code","3ea84c71":"code","784f6d8b":"code","99d0b3f7":"code","52413757":"code","5193a5d5":"code","16fcd708":"code","5ce9edcc":"code","976c2353":"code","2e22a1f8":"code","5a7a6c99":"code","2d198810":"code","c87cfc94":"code","da49dd7f":"code","c4569c9c":"code","a1dcc8fb":"code","d7876cfc":"code","019fb359":"code","dd8e40c6":"code","af665f9d":"code","e3c9ffe1":"code","9ba4212e":"code","d3db89e4":"code","d5928bbd":"code","4adfa615":"code","ee9e1862":"code","cd4c6e41":"code","aa919520":"code","04e719ee":"code","07d01d28":"markdown","6205b1bd":"markdown","8c4ebc49":"markdown","d6628899":"markdown","04dfe4eb":"markdown","73f0268a":"markdown","3e1886b7":"markdown","5def4fe0":"markdown","e67038b3":"markdown","80f077a0":"markdown","6cfbff3b":"markdown","1f506ad7":"markdown","887f476b":"markdown","f5f8f1ae":"markdown","397fd194":"markdown","05a13fce":"markdown","5a7cb216":"markdown"},"source":{"daf725f3":"import pandas as pd\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n%config Completer.use_jedi = False\nimport warnings\nwarnings.simplefilter(action='ignore')\nfrom sklearn import preprocessing\nsns.set(style=\"darkgrid\", color_codes=True)","debdcdfe":"df=pd.read_csv('..\/input\/titanic\/train.csv')\ndf","b585cfb1":"df.drop(columns=['Ticket',],inplace=True)\ndf.columns=['passengerid','survived','pclass','name','sex','age','sibsp','parch','fare','cabin','embarked']","ed3ef55c":"null=df.isnull().sum()# entire\npercent=null\/len(df)*100\nprint(percent)\npercent=percent[percent>0]\nsns.barplot(x=percent.index,y=percent)\nplt.show()","3093930b":"print(df['embarked'].nunique())\nprint(df['embarked'].unique())\n","3ea84c71":"df['embarked-s']=np.zeros(len(df))\ndf['embarked-c']=np.zeros(len(df))\ndf['embarked-q']=np.zeros(len(df))\nsns.countplot(df['embarked'])\nplt.show()\n","784f6d8b":"# from the graph its fair assume the missing values to embarked=S\ndf['embarked'].fillna('S',inplace=True)\ndf.loc[df['embarked']=='S','embarked-s']=1\ndf.loc[df['embarked']=='C','embarked-c']=1\ndf.loc[df['embarked']=='Q','embarked-q']=1\n\n","99d0b3f7":"df.loc[df['sex']=='male','sex']=1\ndf.loc[df['sex']=='female','sex']=0\ndf['age'].fillna(df['age'].mean(),inplace=True)","52413757":"df['cabin'].nunique()\n# df['cabin'].unique()","5193a5d5":"df['owned_cabin']=df['cabin'].isnull().astype(int)\ndf['is_minor']=np.zeros(len(df))\ndf.loc[df['age']<18,'is_minor']=1\n\ndf['pclass_1']=np.zeros(len(df))\ndf['pclass_2']=np.zeros(len(df))\ndf['pclass_3']=np.zeros(len(df))\ndf.loc[df['pclass']==1,'pclass_1']=1\ndf.loc[df['pclass']==2,'pclass_2']=1\ndf.loc[df['pclass']==3,'pclass_3']=1\n\n\n# df.drop('cabin',axis=1,inplace=True)\n# df.drop('name',axis=1,inplace=True)","16fcd708":"df.describe()","5ce9edcc":"sns.countplot(data=df,x='survived',hue='sex')\nplt.show()\n\n#oh my god i did't know that","976c2353":"sns.set(style='darkgrid')\nsns.countplot(df['pclass'],hue=df['survived'])\nsns.jointplot(df['pclass'],df['sex'],kind='hex',color='pink')\nsns.jointplot(df['pclass'],df['age'],hue=df['survived'])\nsns.jointplot(df['pclass'],df['age'],hue=df['sex'])\nsns.jointplot(df['pclass'],df['age'],hue=df['embarked'],kind='kde')\nsns.jointplot(df['survived'],df['sex'],hue=df['embarked'],kind='kde')\nplt.show()\n# sns.distplot(df['age'],ax=ax[0][1],kde=True,)","2e22a1f8":"sns.jointplot(df['pclass'],df['sibsp'],kind='hex',color='green')\nsns.jointplot(df['pclass'],df['parch'],kind='hex',color='yellow')\nplt.show()","5a7a6c99":"sns.jointplot(df['pclass'],df['fare'],hue=df['survived'],palette='rocket')\nsns.jointplot(df['sex'],df['fare'],hue=df['survived'],kind='kde',palette ='rocket')","2d198810":"# sns.pairplot(df,hue='survived',palette='rocket',kind='kde')\n","c87cfc94":"corr_matrix=df.corr()\nfigure=plt.figure(figsize=(15,10))\nsns.heatmap(corr_matrix,annot=True,cmap='Blues')\nplt.show()","da49dd7f":"from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn","c4569c9c":"df.drop(columns={'pclass','name','cabin','embarked'},inplace=True)\ndf.head()","a1dcc8fb":"X=df.drop(columns={'survived','is_minor'}, axis=1)\nY=df['survived']\ntrain_x,validation_x,train_y,validation_y=train_test_split(X,Y.to_numpy(),test_size=0.2,random_state=10)\n ","d7876cfc":"clf=LinearSVC(C=0.1,random_state=0)\nclf.fit(train_x,train_y)\ny_preds=clf.predict(validation_x)\naccuracy=accuracy_score(validation_y,y_preds)\nprint(accuracy)","019fb359":"confusion_matrix(validation_y,y_preds)\n","dd8e40c6":"param_grid = {'C': 10. ** np.arange(-10, 4)}\ngrid_search = GridSearchCV(clf, param_grid=param_grid, cv=6,)\ngrid_search.fit(train_x,train_y)\n","af665f9d":"print(grid_search.best_params_)\nprint(grid_search.best_score_)\n","e3c9ffe1":"res_data=pd.DataFrame(grid_search.cv_results_)\nres_data","9ba4212e":"plt.figure(figsize=(8,5))\nplt.plot(res_data['param_C'],res_data['mean_test_score'])\nplt.xticks([0,100,1000],rotation=90)\nplt.show()","d3db89e4":"y_preds = grid_search.predict(validation_x)\nprint('Accuracy: %.10f' % accuracy_score(validation_y, y_preds))","d5928bbd":"#zero mean and unit variance\nsc=StandardScaler()\ntrain_x=sc.fit_transform(train_x)\nvalidation_x=sc.transform(validation_x)","4adfa615":"\nlr_clf = LogisticRegression(solver='liblinear')\nlr_clf.fit(train_x, train_y)\npred = lr_clf.predict(train_x)\nclf_report = pd.DataFrame(classification_report(train_y, pred, output_dict=True))\nprint(clf_report)\nprint(accuracy_score(train_y, pred) )\n    ","ee9e1862":"pred = lr_clf.predict(validation_x)\nclf_report = pd.DataFrame(classification_report(validation_y, pred, output_dict=True))\nprint(accuracy_score(validation_y, pred) )","cd4c6e41":"#preparing test_data \n\ntest_data=pd.read_csv('..\/input\/titanic\/test.csv')\n\ntest_data['pclass_1']=np.zeros(len(test_data))\ntest_data['pclass_2']=np.zeros(len(test_data))\ntest_data['pclass_3']=np.zeros(len(test_data))\ntest_data.loc[test_data['Pclass']==1,'pclass_1']=1\ntest_data.loc[test_data['Pclass']==2,'pclass_2']=1\ntest_data.loc[test_data['Pclass']==3,'pclass_3']=1\n\ntest_data['embarked-s']=np.zeros(len(test_data))\ntest_data['embarked-c']=np.zeros(len(test_data))\ntest_data['embarked-q']=np.zeros(len(test_data))\n\ntest_data['Embarked'].fillna('S',inplace=True)\ntest_data.loc[test_data['Embarked']=='S','embarked-s']=1\ntest_data.loc[test_data['Embarked']=='C','embarked-c']=1\ntest_data.loc[test_data['Embarked']=='Q','embarked-q']=1\n\ntest_data['owned_cabin']=test_data['Cabin'].isnull().astype(int)\ntest_data['is_minor']=np.zeros(len(test_data))\ntest_data.loc[test_data['Age']<18,'is_minor']=1\n\ntest_data.loc[test_data['Sex']=='male','Sex']=1\ntest_data.loc[test_data['Sex']=='female','Sex']=0\n\ntest_data['Age'].fillna(test_data['Age'].mean(),inplace=True)\ntest_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)\n\ntest_data.drop(columns={'Name','Ticket','Cabin','Embarked','Pclass','is_minor'},inplace=True)\n\n","aa919520":"Survived=lr_clf.predict(test_data)\nfile=pd.DataFrame(test_data['PassengerId'])\nfile['Survived']=Survived","04e719ee":"file.to_csv('submission.csv', header=True, index=False)","07d01d28":"* loading the data...","6205b1bd":"Here is  a parameter search with gridsearch, from sklearn.modelselection. As mensioned earlier the parameter c is really vital here since it controlls the distance from the descision to the margin boundary. What the grid search doea is, we can give it an array of different c values,the algorithm takes the values and cross valuidate through the entire data set and outputs the accuracies for each of the cross validated piece of data, then the avarage of the accuracies is taken as the representing accuracy for the perticular value of the parameter. ","8c4ebc49":"importing bunch of things  for different algorithms","d6628899":" # Model building and testing","04dfe4eb":"Lets try applying a Linear classifier","73f0268a":"* nan values of age replaced by the mean value","3e1886b7":"* Need to know howmany null values are there in each columns of the data, so that we can replace it by apropriate values \n\n* What i think is i'll just see the percent of null values in all of the column , if any of e'm has a very high percent of null values we'll drop and maybe explore a bit later! ,rest of e'm we'll fill with the mean value\n\n\n","5def4fe0":"**Lets try applying logistic regression**","e67038b3":"* just need to get rid of all the upper case latters for ease in the headers","80f077a0":"# # EDA\nLets see what insights can we get from the graph ..\n","6cfbff3b":"0.8324 seems the maximum accuracy logi regression can output given the feature representations","1f506ad7":"* All the string values to be changed to int if its that sort of a parameter\n* Here embarked has 3 values we'll change it to 1,2,3 correspondingly\n* Sex to 1 & 0, the same way\n* The missing values in both categories can be changed to its avarage or what the most of the data tend towards","887f476b":"the data is already prepared, and we need separate sets of them for training and validation\n","f5f8f1ae":"* We can makes separate columns for different embarked values","397fd194":"The confusion matrix shows how have the model really made the predictions, where all the currect classification represented along the diagonal, and all the misclassified, and how they have been misclssified is given as the other elements of the matrix.(if a positive sample is classified -ve or all the other combinations of potential errors.)","05a13fce":"now using the best parameter from grid search to train the data and check on the validation set","5a7cb216":"* most of the survivers were sex=0, also the death rate for sex=0 is very low compared to the other one\n"}}