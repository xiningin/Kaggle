{"cell_type":{"c33d6a0b":"code","8fddbebd":"code","465627ee":"markdown"},"source":{"c33d6a0b":"import numpy as np\nimport matplotlib.pyplot as plt","8fddbebd":"sec = 52   # Number of seconds to produce, delete first two seconds as they are bursts\ndt = 1 \/ 10000  # seconds\n# samples needs to be enough to be generating long enough strips\n# but it's length is stochastic!\nsamples = 100000    # 150000 for 50 secs\nsamplesout = int(sec \/ dt)\nmaxchannels = 3\nmaxrecords = 5  # how many results do we need?\ntime = np.linspace(0, samples - 1, samples)  # test this!!\n# filename = 'states3n.xlsx'\n# this scheme is the fast open scheme (used for 1, 3, 5 channels and 10 channels)\n# fiona (fast open)\nscheme = np.array([[0, 4799, 109, 0, 0, 0],\n                   [3368, 0, 0, 0, 353, 0],\n                   [262, 0, 0, 24, 0, 0],\n                   [0, 0, 638, 0, 0, 0],\n                   [0, 218, 0, 0, 0, 11.5],\n                   [0, 0, 0, 0, 31, 0]])\nisopen = [0, 1, 0, 0, 1, 1]\n\n# this scheme is not evaluated yet (maybe same behavior, maybe slow opening?)\n# lowery\nscheme2 = np.array([[0, 0.37, 0, 0, 0],\n                    [286, 0, 1856, 811, 0],\n                    [0, 37, 0, 0, 2395],\n                    [0, 148, 0, 0, 0],\n                    [0, 0, 5144, 0, 0]])\nisopen2 = [0, 0, 0, 1, 1]  # is maybe wrong in the github? (could be [0, 1, 1, 0, 0])\n\n# outcomment if lowery should not be used\n# scheme = scheme2\n# isopen = isopen2\n# samples = samples \/\/ 10\n\nmaxstates = len(scheme)\nstate = 1\n\n\ndef getalldists(maxstates, scheme, samples):\n    alldist = [0] * (maxstates)\n    for lstate in range(maxstates):\n        trans = []\n        for j in range(-maxstates, maxstates):\n            if (0 <= (lstate + j)) and ((lstate + j) < maxstates):\n                if scheme[lstate, lstate + j] > 0:\n                    # sort out the preallocation for speed\n                    row = lstate\n                    col = lstate + j\n                    val = scheme[row, col]\n                    trans.append([lstate, val])\n        f = np.random.exponential((1 \/ np.array(trans)[:, 1].sum()), size=[samples, 1])\n        # f(randperm(length(f))); unecessary\n        alldist[lstate] = f\n    highest = 0\n    for ii in range(len(alldist)):\n        if alldist[ii].mean() > highest:\n            commonest = ii\n            highest = alldist[ii].mean()\n    # str1=[\"commonest=\",num2str(commonest)];\n    # print(str1);\n    return alldist, commonest\n\n\ndef neigbours(lstate, maxstates, scheme):\n    trans = []\n    for j in range(-maxstates, maxstates):\n        if (0 <= (lstate + j)) and ((lstate + j) < maxstates):\n            if scheme[lstate, lstate + j] > 0:\n                # sort out the preallocation for speed\n                row = lstate\n                col = lstate + j\n                val = scheme[row, col]\n                trans.append([col, val])\n                if trans[0][1] == 0:\n                    print(\"bug down here should never be no possible transitisions\")\n    # print(trans)\n    return np.array(trans)\n\n\ndef nextstate(state, maxstates, scheme):\n    # This was my original idea, but a similar one is here:\n    # http:\/\/www.scholarpedia.org\/article\/Stochastic_models_of_ion_channel_gating\n    trans = neigbours(state, maxstates, scheme)\n    # Now MLG from the above site for massive speed improvement.\n    if len(trans) == 1:\n        state = trans[0, 0]\n    else:\n        psum = trans[:, 1].sum()\n        ran = np.random.rand(1) * psum\n        for row in range(len(trans[:, 0])):\n            smmer = trans[:row + 1, 1].sum()\n            if (smmer >= ran[0]):\n                state = trans[row, 0]\n                # print(int(state))\n                return int(state)\n    # print(int(state))\n    return int(state)\n\n\ndef getlifetime(nth, dists, state):\n    # print(nth);\n    thislife = dists[state][nth][0]\n    return thislife\n\n\ndef maketimeseries(lifetimes, dt):\n    lifetimes = np.array(lifetimes)\n    # output = np.zeros([2000000, 2])  # Needs to be more than samples in length\n    output = np.array([[0], [0]])\n    # cur = 0\n    # tlen = 0\n    for lifetime in lifetimes:\n        thislen = lifetime[0]\n        thisstate = lifetime[1]\n        num = int(round(thislen \/ dt))\n        # tlen = num + tlen\n        t1 = output[0].max() + dt\n        t2 = t1 + thislen\n        a = np.linspace(t1, t2, num)\n        values = (np.ones_like(a) * thisstate).astype(int)\n        output = np.concatenate([output, [a, values]], axis=1)\n        # output[cur:cur + num, 0] = a\n        # output[cur:cur + num, 1] = int(thisstate)\n        # cur = cur + num\n    # output=output(1:tlen,:)\n    return output.T\n\n\ndef fstatesn(scheme, isopen, dt, samples, time, state, maxstates):\n    # C-O-O\n    # READ FROM A TABLE!!\n    # State 1 = colA\n    # state 2\n    # startstate=1+int64(rand(1,1)*(maxstates-1))\n    disters, commonest = getalldists(maxstates, scheme, samples)\n    # THESE NEXT LINES MUST CHANGE IF MAXSTATES INCREASE FROM 5\n    open_state = np.zeros(maxstates)\n    for event in range(maxstates):\n        if isopen[event] == 1:\n            open_state[event] = event\n    open_state = open_state[open_state > 0]\n    lifetimes = []\n    # states=[];\n    for ii in range(samples):\n        # look up the correct range of kf and kb on the basis of the current state\n        tl = getlifetime(ii, disters, state)\n        state = nextstate(state, maxstates, scheme)\n        # states=[states;state];\n        # print(state);\n        if state in open_state:\n            lifetimes.append([tl, 1])\n        else:\n            lifetimes.append([tl, 0])\n    out = maketimeseries(lifetimes, dt)\n    state = commonest\n    return out, state\n\n\nfor record in range(maxrecords):\n    print(\"Record =\", record)\n    # Multichannels\n    out = np.zeros([samplesout, 2])\n    channels = 0\n    shorty = 0\n    while channels < maxchannels:\n        channels = channels + 1\n        print(\"Channel =\", channels)\n        temp, state = fstatesn(scheme, isopen, dt, samples, time, state, maxstates)\n        if len(temp) > samplesout:\n            shorty = 0  # reset the time saver variable shorty.\n            if channels == 1:\n                out[:samplesout, :] = temp[:samplesout, :]\n            else:\n                out[:samplesout, 1] = out[:samplesout, 1] + temp[:samplesout, 1]\n            samples = int(0.9 * samples)    # may be wasting time to go with shorter search\n            print(\"too long?\", samples)\n        else:\n            shorty = shorty + 1\n            if shorty > 2:\n                shorty = 0\n                samples = int(1.5 * samples)  # we didn't get enough samples so increase and go again.\n                # now do this channel number again ignore warning!\n            print(\"too short\", samples)\n            channels = channels - 1\n    filename = 'astr' + str(record) + '_' + str(maxchannels) + 'c_fast_open.npy'\n    np.save(filename, out)\n\n    # Crops of the first 2 seconds because of the bug I cannot trace...\n    # that always starts the channel in a burst.\n    # csvwrite(['astr' num2str(record) '.csv'],out(:,2));\n\n    plt.plot(out[:, 0], out[:, 1])\n    plt.ylim([0, maxchannels + 1])\n    plt.show()","465627ee":"### This script is a Python-ported version of https:\/\/github.com\/RichardBJ\/Deep-Channel\/tree\/master\/annotated_data\/fiona\/multichannelMLG002_fiona.m\n\n- It will output sequences of open_channel data that match the ones used for this competition. \n- It was presumably used for all batches with 1, 3, 5 and 10 channels and a high opening probability.  \n- Most interestingly, we have 6 states (3 open states, 3 closed states) for each channel Markov Model and we are just adding up a number of channels (1, 3, 5 or 10) to form the final sequence.  \n- The lifetime at each state is drawn from an exponential distribution here: `f = np.random.exponential((1 \/ np.array(trans)[:, 1].sum()), size=[samples, 1])` after that, a state must change"}}