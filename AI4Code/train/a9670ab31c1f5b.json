{"cell_type":{"676bcc2b":"code","02b8a222":"code","44323608":"code","8b48c84f":"code","356b7d20":"code","e566f7d7":"code","18115dc8":"code","4dba6e2f":"code","fb5c1b19":"code","ffce5813":"code","867bb741":"code","ed5a7aea":"code","0cbb578e":"code","04400dd2":"code","48d82a72":"code","e7eb6a33":"code","ecd32057":"code","6a8fcbf2":"code","030eac48":"code","fab13c8b":"code","f574ce40":"code","70aafb6a":"code","74e05ed7":"code","42417ef8":"code","06fd4fe8":"code","a2cb0b7c":"code","a8da2ef0":"code","632ed6c2":"code","c93e5082":"code","8210f53e":"code","bf5a1c60":"code","dfcdbe7d":"code","1d41c00e":"code","8c956f34":"code","0252760c":"code","987194aa":"code","8dff551c":"code","c0e159a3":"code","909e9853":"code","3d05a870":"code","be3d2b44":"code","717a373c":"code","aa6e641a":"code","702b488f":"code","9c9c7580":"code","46a62e88":"code","e2326be5":"code","1b214947":"code","cdfa43b6":"code","04a35789":"code","8dc1cfc0":"code","094f40d5":"code","992d2b50":"code","4eecddd6":"code","67520ccf":"code","e1b4d149":"code","09b56d47":"code","32db235e":"code","15541b5c":"code","94699682":"markdown","feefcb03":"markdown","7239e734":"markdown","25b75dad":"markdown","44ccea35":"markdown","f85d3f58":"markdown","debab60f":"markdown","79d028e0":"markdown","bfcffcba":"markdown","ee9aab5e":"markdown","d9dfbd69":"markdown","88028342":"markdown","02e1142b":"markdown","8eedac70":"markdown","a294a4fe":"markdown","645d8c42":"markdown","6b9797fb":"markdown","f5e46fde":"markdown","98e66374":"markdown","57490f87":"markdown","9ee1a67e":"markdown","358d6de6":"markdown","06fd6b0b":"markdown","ea8e0efa":"markdown","c6157890":"markdown","3f4b8094":"markdown","66825428":"markdown","b32b74ab":"markdown","a430fff2":"markdown","1d351261":"markdown","5341ae69":"markdown","d4dc9de8":"markdown"},"source":{"676bcc2b":"import pandas as pd\npd.options.display.max_columns = None\nimport dataset_utilities as du\nimport plotly.graph_objects as go\nfrom ipywidgets import interact","02b8a222":"bbc = pd.read_csv('\/kaggle\/input\/news-sitemaps\/bbc_sitemaps.csv',\n                  parse_dates=['lastmod'], index_col='lastmod', usecols=['lastmod', 'loc'])\nbbc.sample(5)","44323608":"du.value_counts_plus(bbc['loc'].rename('language').str.split('\/').str[3], show_top=50)","8b48c84f":"bbc['loc'].str.contains('https:\/\/www.bbc.com\/').all()","356b7d20":"bbc['slug'] = bbc['loc'].str.replace('https:\/\/www.bbc.com\/', '')\nbbc['slug'] = bbc['slug'].str.replace('^news|^sport|^newsround', 'english\/\\g<0>')\nbbc.sample(5)","e566f7d7":"bbc['lang'] = bbc['slug'].str.split('\/').str[0].replace('mundo', 'spanish')\nbbc.sample(5)","18115dc8":"du.value_counts_plus(bbc['lang'], show_top=50)","4dba6e2f":"bbc['slug_split_length'] = bbc['slug'].str.split('\/').str.len()\nbbc.sample(7)","fb5c1b19":"du.value_counts_plus(bbc['slug_split_length']).hide_index()","ffce5813":"format(bbc[bbc['slug_split_length']==2]['slug'].str.split('\/').str[1].nunique(), ',')","867bb741":"bbc[bbc['slug_split_length']==3]['slug'].sample(15)","ed5a7aea":"bbc[bbc['slug_split_length']==3]['slug'].str.split('\/').str[1].value_counts()[:20]","0cbb578e":"format(bbc[bbc['slug_split_length']==3]['slug'].str.split('\/').str[2].nunique(), ',')","04400dd2":"bbc[bbc['slug_split_length']==4]['slug'].sample(10)","48d82a72":"bbc[bbc['slug_split_length']==4]['slug'].str.contains('english\/sport\/|english\/news').mean()","e7eb6a33":"bbc[bbc['slug_split_length']==4]['slug'].str.split('\/').str[0].value_counts(dropna=False)","ecd32057":"bbc[bbc['slug_split_length']==4]['slug'].str.split('\/').str[1].value_counts(dropna=False)","6a8fcbf2":"len_4_index_1_2 = (bbc[bbc['slug_split_length']==4]\n                   ['slug'].str.split('\/').str[1:3]\n                   .str.join('\/')\n                  )","030eac48":"len_4_index_1_2.value_counts()[:7]","fab13c8b":"non_sports = {\n    'live', 'scotland', 'northern-ireland', 'get-inspired', 'wales', 'live', 'av',\n    'sports-personality', 'supermovers', 'africa', 'england', 'audiovideo', 'england',\n    'video_and_audio', 'features', 'live', 'live', 'special-reports', 'in-depth',\n    'in-depth', 'business', 'world', 'ultimate-performers', 'scotland',\n    'move-like-never-before', 'made-more-of-their-world', 'wales', 'syndication',\n    'west-bank-hitchhiking', 'headlines', 'stadium', 'trump-kim-meeting',\n    'deadcities', 'wedding-mixed-race', 'northern_ireland', 'wedding-dress', 'system',\n    'the-vetting-files', 'brodsky', 'syndication', 'wedding-designers', 'education',\n    'world-cup-russia-hopefuls', 'wedding-guests', 'uk-scotland', 'tianshu',\n    'yorkshire-and-humberside', 'west',  'west-midlands', 'uk-scotland','students_diary',\n    'students_experience', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n    '12', '2015', '2016', 'articles', 'asia', 'chart_uk', 'east',  'east-mids-and-lincs',\n    'election', 'europe', 'globalnews', 'in_depth', 'london-and-south-east',\n    'north-east-and-cumbria', 'north-west', 'on_britain', 'south', 'south-west',\n    'special_reports','politics', 'qa', 'tenglong', 'technology'\n}","f574ce40":"bbc[bbc['slug_split_length']==5]['slug'].str.split('\/').str[1].value_counts()[:10]","70aafb6a":"bbc[bbc['slug_split_length']==5]['slug'].str.split('\/').str[2].value_counts()[:20]","74e05ed7":"bbc[bbc['slug_split_length']==5]['slug'].str.split('\/').str[3].value_counts()[:20]","42417ef8":"format(bbc[bbc['slug_split_length']==5]['slug'].str.split('\/').str[4].nunique(), ',')","06fd4fe8":"bbc[bbc['slug_split_length']==6]['slug'].str.split('\/').str[1].value_counts()[:10]","a2cb0b7c":"bbc[bbc['slug_split_length']==6]['slug'].str.split('\/').str[2].value_counts()[:15]","a8da2ef0":"bbc[bbc['slug_split_length']==6]['slug'].str.split('\/').str[1:3].str.join('\/').value_counts()[:20]","632ed6c2":"bbc[bbc['slug_split_length']==6]['slug'].str.split('\/').str[3].value_counts()[:15]","c93e5082":"bbc[bbc['slug_split_length']==6]['slug'].str.split('\/').str[4].value_counts()[:15]","8210f53e":"format(bbc[bbc['slug_split_length']==6]['slug'].str.split('\/').str[5].nunique(), ',')","bf5a1c60":"bbc[bbc['slug_split_length']==7]['slug'].str.split('\/').str[0].value_counts()","dfcdbe7d":"bbc[bbc['slug_split_length']==7]['slug'].str.split('\/').str[1].value_counts()[:15]","1d41c00e":"bbc[bbc['slug_split_length']==7]['slug'].str.split('\/').str[2].value_counts()[:15]","8c956f34":"bbc[bbc['slug_split_length']==7]['slug'].str.split('\/').str[3].value_counts()[:15]","0252760c":"bbc[bbc['slug_split_length']==7]['slug'].str.split('\/').str[4].value_counts()[:15]","987194aa":"bbc[bbc['slug_split_length']==7]['slug'].str.split('\/').str[5].value_counts()[:15]","8dff551c":"bbc['year_month'] = bbc['loc'].str.extract('\/(\\d{4}\/\\d{2})\/')[0].values","c0e159a3":"bbc.dropna(subset=['year_month']).sample(7)","909e9853":"sport_names_4 = set(bbc[bbc['slug_split_length']==4]['slug'].str.split('\/').str[2].unique())\nsport_names_5 = set(bbc[bbc['slug_split_length']==5]['slug'].str.split('\/').str[3].unique())","3d05a870":"sport_names_all = sport_names_4.union(sport_names_5).difference(non_sports)\nsport_regex = '\/(' + '|'.join(sport_names_all) + ')\/'\nsport_regex","be3d2b44":"bbc['sport'] = bbc['loc'].str.extract(sport_regex)[0].values","717a373c":"bbc.dropna(subset=['sport', 'year_month']).sample(7)","aa6e641a":"bbc['sport'].value_counts()[:10]","702b488f":"import numpy as np\nextracted_pub_date = (bbc['slug']\n                      .str.extract('\/([012][0-9][01][0-9][0123][0-9])_')[0]\n                      .replace('00000[01]', np.nan, regex=True))\nextracted_pub_date","9c9c7580":"bbc['pub_date'] = pd.to_datetime(extracted_pub_date, format='%y%m%d', errors='coerce', utc=True)\nbbc.dropna(subset=['sport', 'pub_date']).sample(7)","46a62e88":"bbc['pub_date'].notna().mean()","e2326be5":"du.value_counts_plus(bbc['pub_date'].sub(bbc.index).dt.days, dropna=True)","1b214947":"category_indexes = [(3, 1), (5, 1), (6, 2), (7, 3)]\ncategory_indexes","cdfa43b6":"categories = set()\nfor length, index in category_indexes:\n    temp_categories = set(bbc[bbc['slug_split_length']==length]['slug'].str.split('\/').str[index].unique())\n    categories = categories.union(temp_categories)","04a35789":"categories_regex = '\/(' + '|'.join(categories) + ')\/'\ncategories_regex","8dc1cfc0":"bbc['category'] = bbc['loc'].str.extract(categories_regex)[0].values","094f40d5":"bbc.dropna(subset=['category', 'sport', 'pub_date']).sample(7)","992d2b50":"bbc['title'] = (bbc['slug']\n                .str.split('\/')\n                .str[-1]\n                .str.replace('^\\d{6}_|-\\d+$|^\\d+$', '')\n                .str.replace('_|-', ' '))","4eecddd6":"bbc.dropna(subset=['title']).sample(7)","67520ccf":"timeframe_key = dict(A='Year', M='Month', W='Week')\ndef compare_langs(lang1=None, lang2=None, lang3=None, timeframe='A', y_scale='linear'):\n    title_lang = []\n    fig = go.Figure()\n    for lang in [lang1, lang2, lang3]:\n        if lang is not None:\n            df = bbc[bbc['lang']==lang].resample(timeframe)['loc'].count()\n            fig.add_scatter(x=df.index, y=df.values, name=lang.title(),\n                            mode='markers+lines')\n            title_lang.append(lang.title())\n    fig.layout.title = 'Articles per ' + timeframe_key[timeframe] + ': ' + ', '.join(title_lang)\n    fig.layout.yaxis.type = y_scale\n    fig.layout.paper_bgcolor = '#E5ECF6'\n    return fig\n        ","e1b4d149":"compare_langs('english', 'russian', 'portuguese')","09b56d47":"compare_langs('english', 'russian', 'portuguese', y_scale='log')","32db235e":"languages = [None] +  sorted(bbc['lang'].unique())","15541b5c":"interact(compare_langs, lang1=languages, lang2=languages, lang3=languages,\n         timeframe=dict(Year='A', Month='M', Week='W'), y_scale=['linear', 'log']);","94699682":"Length six, index three, again, years, followed by months: ","feefcb03":"After exploring all the lengths, I summarized the information in this table.  \nAs you can see, all slugs start with \"language\", and all end with \"title\", which is the title of the article (separated by dashes and\/or underscores). The other elements that are found are year, month, category, sport name, and a few others.  \nThe following code cells go through every length, and explore the elements resulting from splitting the slugs, to come up with this table. You can skip to the section where we start to [add URLs](#add_urls) if you want","7239e734":"   Slug length when split | Number of articles | 0 | 1 | 2 | 3 | 4 | 5 | 6 | \n--------------------------------:|--------------------------:|---|---|---|---|---|---|---|\n                   1 |     38          | language | NA | NA | NA | NA | NA | NA \n                   2 | 725,691     | language | **title** |  NA | NA | NA | NA | NA \n                   3 |  1,177,736 | language | **category** | **title** | NA | NA | NA | NA \n                   4 | 419,816     | language | **\"sport\"** or **\"news\"** | **sport_name** | **title** | NA | NA | NA \n                   5 |  1,562,777 | language | **category** | **year** or **\"av\"** or **\"live\"**| **month** or **sport_name** | **title** | NA | NA\n                   6 |  96,574      | language | **general category** | **category** | **year** | **month** | **title** | NA\n                   7 |  13,180      | language |**\"simp\"** or **\"trad\"** | **general_category** | **category** | **year** | **month** | **title**\n","25b75dad":"The same process again for slugs of length seven: ","44ccea35":"Length six, index two:","f85d3f58":"Now that we know that they are all \"bbc.com\", we can safely take the part that follows that, and create a `slug` colum. I'm also prepending \"english\" to the other words mentioned above. ","debab60f":"We can now get an idea on the number of URLs for each length.","79d028e0":"We can now start to look at annual, monthly, or weekly publishing trends for the languages that we are interested in. The following function takes up to three languages and plots the trend by the specified time frame. ","bfcffcba":"# Analyzing BBC.com's XML Sitemaps' Four Million URLs\nXML sitemaps are boring. Really boring...  \nBut if they come with the `lastmod` tag, and the site provides rich URLs, then they might be really interesting in understanding trends in publishing and content across time and across different languages, or cateogires (depending on what information is available in the URLs).  \nThis is an exploration of almost four million URLs included in all of BBC.com's sitemaps. ","ee9aab5e":"#### Slugs of length four:","d9dfbd69":"So the overwhelming majority of the updated articles get updated within a day or two. Probably immediate corrections, typos, or simple mistakes. Which means that it seems that `lastmod` is a good proxy for publishing date.\n\n\nNow in order to extract the categories from the URLs, we need to identify where they are located, which we have already done.  The following list of tuples are for (length, index) of each URL. For slugs of length three, index one is where the category occurs, for length five, it is index one, and so on:","88028342":"The slugs are separated by forward-slashes, and this is the main way in which we are going to extract information. They also come in different lengths (number of times a URL contains \"\/\" + 1). So to add some structure to the process I'm adding a column that shows the length of the slug after splitting by \"\/\" `slug_split_length`.","02e1142b":"We can now explore the slugs of length five: ","8eedac70":"Now that we have \"english\" in the slugs, we can split by \"\/\" and get the first element and put it in the `lang` column. I also replaced \"mundo\" with \"spanish\".","a294a4fe":"It seems 38.7% of the articles contain a date, so now we can compare them to the index, by a simple subtraction, and counting the occurrences of the diffrent time differences.\n\nHere we are subtracting the index from the `pub_date` column and counting the days.","645d8c42":"This is an interactive version of the function, and you will be able to run it if you fork the notebook, because it needs a runningn Python process to work: ","6b9797fb":"These slugs with length four seem start with \"english\/sport\" and \"english\/news\", so let's quickly check for what percentage this is true.","f5e46fde":"#### Slugs of length three:","98e66374":"Now we can go through those and count the values that are available. You will see that the majority will contain sports names, and that there are many other occurrences of other categories of news and articles.  \nI manually went through them, and created a set `non_sports`, based on which I was able to come up with a list of the sports in the URLs. This will help in createing a regular expression to extract sports names; football, basketball, etc. ","57490f87":"# [Add new columns](#add_urls)\n\nAs a summary here is the table showing the different elements of URLs and where they fall for different slugh lengths (it's the same as the one above)\n\n   Slug length when split | Number of articles | 0 | 1 | 2 | 3 | 4 | 5 | 6 | \n--------------------------------:|--------------------------:|---|---|---|---|---|---|---|\n                   1 |     38          | language | NA | NA | NA | NA | NA | NA \n                   2 | 725,691     | language | **title** |  NA | NA | NA | NA | NA \n                   3 |  1,177,736 | language | **category** | **title** | NA | NA | NA | NA \n                   4 | 419,816     | language | **\"sport\"** or **\"news\"** | **sport_name** | **title** | NA | NA | NA \n                   5 |  1,562,777 | language | **category** | **year** or **\"av\"** or **\"live\"**| **month** or **sport_name** | **title** | NA | NA\n                   6 |  96,574      | language | **general category** | **category** | **year** | **month** | **title** | NA\n                   7 |  13,180      | language |**\"simp\"** or **\"trad\"** | **general_category** | **category** | **year** | **month** | **title**    ","9ee1a67e":"After this the options are endless for what you can do. This was a basic preparation and categorization of the data, so the following steps are hopefully easier to do. ","358d6de6":"Finally, the last part of the URLs is where the most important content is. The title of the article. We will split the slugs by \"\/\", take the last element, replace leading six digits with the empty character, and do the same for articles ending with a dash and a bunch of numbers, and titles that are only numbers. Then we replace dashes and underscores with spaces, and we get a better easier to read article title. ","06fd6b0b":"Length six index one:","ea8e0efa":"All of them are languages indeed, with the exception of \"news\", \"sport\", \"newsround\", and \"mundo\". Before going further and starting to extract data, let's first check if all the URLs are for the same domain and if there are any other sub-domains for example. ","c6157890":"Months, following the year ...\/YYYY\/MM\/... ","3f4b8094":"We know that there are many slugs containing the pattern `\/YYYY\/MM\/` so we can easily extract them:","66825428":"The year the article was published ....\/YYYY\/... ","b32b74ab":"Pretty much all of them. We can also quickly check the distribution of \"sport\" and \"english\" because the overwhelming majority fall under these categories. ","a430fff2":"We know that sports names occur in slugs of length four and five, on index two and three respectively. So we can easily extract those elements, get their unique values, and remove the elements from `non_sports`. With this we can create our `sport_regex`.","1d351261":"Getting the number of unique elements after splitting a slug, is a quick way to make sure they are indeed article titles and not something else. In this case 725k is almost the same as the one you see in the table above for length two. ","5341ae69":"The URLs have been imported using the [`sitemap_to_df`](https:\/\/advertools.readthedocs.io\/en\/master\/advertools.sitemaps.html) function from [advertools](https:\/\/github.com\/eliasdabbas\/advertools).  \nThe function can take a sitemap URL or a sitemap index, and goes through all of them, retreiving all URLs and any other tags available in the sitemap(s). \n\n`value_counts_plus` is a simple function that I wrote to give richer information to the pandas `value_counts` function, so I'll be using it when counting values, starting with the first thing after \"https:\/\/www.bbc.com\/\", which seems to be the language of the page. ","d4dc9de8":"There is a good portion of URLs that seem to have six digits right after the `\/YYYY\/MM\/` pattern. Looking closely at them, and comparing them to the `lastmod` tag (which is the index of the DataFrame), you'll see that they are almost identical. It seems to me that these are the actual publishing dates of the articles.  \n\nIf we can extract these and compare them to the `lastmod` tag, we can get a view on how often the BBC update their content. "}}