{"cell_type":{"5ab0afe1":"code","9eac24d9":"code","180525be":"code","3b641199":"code","646c8af1":"code","7e6ec61d":"code","8f9e1d31":"code","d83d9659":"code","00151b7d":"code","2f76b09b":"code","d6b66f7f":"code","6d3d77c0":"code","c7aecd5c":"code","e6a4bbf6":"code","b0062c3c":"code","bb6a7953":"code","54af6277":"code","fdb1a2c6":"code","f1b65f03":"code","24fb9e22":"code","ecfa848b":"code","46d25dff":"code","90d64e86":"code","4c494630":"code","4a6dcdbe":"code","d1671f28":"code","1bd8ffc7":"code","546a7f19":"markdown","16744415":"markdown","7fce0b40":"markdown","8e17d558":"markdown","055bfd5e":"markdown","d8bf168c":"markdown","773002aa":"markdown","883d5f49":"markdown","53b70e05":"markdown","a342e3a4":"markdown","f25ceb45":"markdown","a3e41d4d":"markdown","e717c7d8":"markdown","66b06cef":"markdown","9ff956a2":"markdown","5aecce89":"markdown","bd2b7439":"markdown","18015f4e":"markdown","28415cdf":"markdown","20ae4c7a":"markdown","77fa7aea":"markdown","f6944629":"markdown","9a64ed73":"markdown","8e2367b6":"markdown","65184f00":"markdown","d3d8f73f":"markdown","4716d900":"markdown","6a194078":"markdown","5d14ffce":"markdown","bd4f6f26":"markdown","14ce8161":"markdown","cc9f4029":"markdown","2832e55f":"markdown","79aac8e5":"markdown","74a4be52":"markdown","4d2f6c51":"markdown","2d8210a3":"markdown","27e14b66":"markdown","0b0c8d30":"markdown","a89a4933":"markdown"},"source":{"5ab0afe1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #commenting this to save space\n        #print(os.path.join(dirname, filename))\n        pass","9eac24d9":"import matplotlib.pyplot as plt\nimage = plt.imread('\/kaggle\/input\/natural-images\/natural_images\/fruit\/fruit_0618.jpg')","180525be":"image.shape","3b641199":"plt.imshow(image); #adding ; helps suppress printed material","646c8af1":"import PIL\nfrom PIL import Image\nimport numpy as np\n\n#read image from directory using Image\nimg = Image.open('\/kaggle\/input\/natural-images\/natural_images\/fruit\/fruit_0618.jpg')\n\n#reshape the image to (128, 128). This maintains the aspect ratio (images may be squished\/stretched)\nimg = img.resize((128,128), Image.ANTIALIAS)\n\n#we can convert to an array directly using np.array(PIL image)\nimg = np.array(img)\n\n#display the image with matplotlib\nplt.imshow(img);","7e6ec61d":"X, y = [], []","8f9e1d31":"import numpy as np #import numpy\nfrom tqdm import tqdm #import tqdm for progress bar\n\n#collect names of directories we will be pulling from\n#this is necessary because there are other duplicate subdirectories we do not want to go over twice\ndirs = ['\/kaggle\/input\/natural-images\/natural_images\/fruit',\n        '\/kaggle\/input\/natural-images\/natural_images\/flower',\n        '\/kaggle\/input\/natural-images\/natural_images\/person',\n        '\/kaggle\/input\/natural-images\/natural_images\/car',\n        '\/kaggle\/input\/natural-images\/natural_images\/motorbike',\n        '\/kaggle\/input\/natural-images\/natural_images\/airplane',\n        '\/kaggle\/input\/natural-images\/natural_images\/dog',\n        '\/kaggle\/input\/natural-images\/natural_images\/cat']\n\n#we will switch the y label when we finish with a directory\ncurrent_y_label = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    \n    #if the directory name is not valid, begin the next iteration\n    if dirname not in dirs: continue\n        \n    #for each file (image.png) in the filenames\n    for filename in tqdm(filenames): #use tqdm around an iterator to display progress bar\n        \n        #combine paths to form complete directory\n        directory = os.path.join(dirname, filename)\n        \n        #read image from directory using Image\n        img = Image.open(directory)\n\n        #reshape the image to (128, 128). This maintains the aspect ratio (images may be squished\/stretched)\n        img = img.resize((128,128), Image.ANTIALIAS)\n\n        #we can convert to an array directly using np.array(PIL image)\n        img = np.array(img)\n        \n        #append the array to X (after dividing it by 255)\n        X.append(img\/255)\n        \n        #append the y label as the y label\n        y.append(current_y_label)\n        \n    #we're finished with the directory. time to change the y label\n    current_y_label += 1","d83d9659":"from keras.utils import to_categorical\nX, y = np.array(X), to_categorical(np.array(y))","00151b7d":"X.shape","2f76b09b":"y.shape","d6b66f7f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","6d3d77c0":"shapes = {'X train': X_train.shape, 'X test': X_test.shape,\n          'y train': y_train.shape, 'y test': y_test.shape}\nfor key in shapes:\n    print(f\"{key}: {shapes[key]}\")","c7aecd5c":"X_train.shape","e6a4bbf6":"y_train.shape","b0062c3c":"import keras\nfrom keras.models import Sequential #our model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense #import layers","bb6a7953":"model = Sequential() #initiate model\nmodel.add(Conv2D(64, kernel_size=(5,5), input_shape=(128,128,3)))\nmodel.add(MaxPooling2D(pool_size=(5,5)))\nmodel.add(Conv2D(64, kernel_size=(3,3)))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(8, activation='softmax'))","54af6277":"model.summary()","fdb1a2c6":"model.compile(metrics=['accuracy'], \n              loss='categorical_crossentropy',\n              optimizer='adam')","f1b65f03":"history = model.fit(X_train, y_train, epochs=15)","24fb9e22":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(10, 4))\nsns.set_style('whitegrid')\nsns.lineplot(x=range(1,16), y=history.history['accuracy'], marker='o', color='#EA4335', label='Accuracy')\nsns.lineplot(x=range(1,16), y=history.history['loss'], marker='X', color='#4285F4', label='Loss')\nplt.title(\"Performance with Standard CNN\")\nplt.xlabel('Epochs');\nplt.ylabel('Accuracy | Loss');","ecfa848b":"model.evaluate(X_test, y_test)","46d25dff":"from keras.preprocessing.image import ImageDataGenerator\ndata_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.25,\n                        horizontal_flip=True)","90d64e86":"#this will yield an error but we'll still get to see an example augmented image\nplt.imshow(data_generator.flow(X,y)[0][0][0]);\nplt.show()\nplt.imshow(data_generator.flow(X,y)[0][0][1]);\nplt.show()\nplt.imshow(data_generator.flow(X,y)[0][0][2]);\nplt.show()","4c494630":"model1 = Sequential() #initiate model\nmodel1.add(Conv2D(64, kernel_size=(5,5), input_shape=(128,128,3)))\nmodel1.add(MaxPooling2D(pool_size=(5,5)))\nmodel1.add(Conv2D(64, kernel_size=(3,3)))\nmodel1.add(MaxPooling2D(pool_size=(3,3)))\nmodel1.add(Flatten())\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(Dense(8, activation='softmax'))\nmodel1.compile(metrics=['accuracy'], \n              loss='categorical_crossentropy',\n              optimizer='adam')","4a6dcdbe":"history1 = model1.fit_generator(data_generator.flow(X_train, y_train), epochs=25)","d1671f28":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(10, 4))\nsns.set_style('whitegrid')\nsns.lineplot(x=range(1,26), y=history1.history['accuracy'], marker='o', color='#EA4335', label='Accuracy')\nsns.lineplot(x=range(1,26), y=history1.history['loss'], marker='X', color='#4285F4', label='Loss')\nplt.title(\"Performance with Augmented Data\")\nplt.xlabel('Epochs');\nplt.ylabel('Accuracy | Loss');","1bd8ffc7":"model1.evaluate(X_test, y_test)","546a7f19":"Let's create x and y lists to store arrays and labels.","16744415":"Let's import the Sequential model-building object as well as relevant layers.","7fce0b40":"Let's fit the model with the data generator. Since it will take some more time to learn, let's train it for 20 epochs.","8e17d558":"Let's construct the following Image Data Generator, which simply passes training data through random filters (e.g. random shifting or tilting) before training the network on it.","055bfd5e":"It looks like there are eight distinct subdirectories that lie in \/kaggle\/input\/natural-images\/natural-images\/class\/name.\n\nNext, we need to convert these images into an array. Let's first explore how to do it with one image.","d8bf168c":"Data augmentation is where images are zoomed, cropped, rotated, etc. to help promote more generalization and understanding. While convolutional neural networks are not by design invariant to these changes, it's a step in the right direction.\n\n![image.png](attachment:image.png)\nSource: https:\/\/www.pyimagesearch.com\/2019\/07\/08\/keras-imagedatagenerator-and-data-augmentation\/","773002aa":"Let's see how it performs on our test data.","883d5f49":"# 3 | Basic CNN w\/ Data Augmentation","53b70e05":"Then, for each valid file path, we will follow our image processing pipeline and add it to the array.","a342e3a4":"A convolutional neural network is simply a neural network that has convolutional (and often pooling) layers. Since the Inception architecture was released, modular designs have been popular.\n\nA standard CNN architecture consists of iterations of modules, followed by several standard layers.\n- Convolutional layer (input, operating on 2-d data)\n- Max pooling layer (operating on 2-d data)\n- Convolutional layer (operating on 2-d data)\n- Max pooling layer (operating on 2-d data)\n- Flatten layer (converted 2-d data to 1-d data)\n- Dense layer (operating on 1-d data)\n- Dense layer (output, operating on 1-d data)","f25ceb45":"We can display it using .imshow():","a3e41d4d":"We can create our model as such:","e717c7d8":"Even though the training accuracy is significantly lower, the test accuracy is > 91%, an improvement from previously.","66b06cef":"Luckily, matplotlib's .imread function takes in an image path and converts it into a NumPy array for us.","9ff956a2":"Finally, let's train it for 15 epochs.","5aecce89":"It would also be a wise idea to divide the array by 255 to yield numbers from 0 to 1. \n\nSo, our image processing pipeline is as following:\n1. Obtain file path directory\n2. Use PIL to read file path\n3. Reshape to 128 by 128 pixels\n4. Convert to numpy array\n5. Divide array by 255 to scale","bd2b7439":"# 2 | Basic Convolutional NN","18015f4e":"Let's see how it performs on the test set.","28415cdf":"Thus, the shapes of our training data will be (128, 128, 3) for the input and 8 neurons in the output.","20ae4c7a":"Let's compile the model with metrics and an optimizer.","77fa7aea":"Plotting the results:","f6944629":"Not bad! We have an accuracy of almost 90%. The network may be overfitting, though. Let's use data augmentation.","9a64ed73":"Let's view the parameters of our model.","8e2367b6":"It's always good to look at the shapes of our data just to be sure:","65184f00":"-------------------\n### This is a work in progress!\nCheck back later for updates. Would be great to have some collaborators as well.","d3d8f73f":"```data_generator.flow(X,y)``` is used to load the augmented data into memory. It's a NumPy iterator, so we can access the first few augmented images through ```data_generator.flow(X,y)[0][0][0]``` (array is segmented as iterator > batches > individual images).","4716d900":"Next, let's convert the X and y into a numpy array while one-hot encoding it (since it is categorical).","6a194078":"The shape of y:","5d14ffce":"# 4 | Transfer Learning","bd4f6f26":"Some images in our dataset are not the standard ```256x256x3``` size. Additionally, we should store our images as ```128x128x3``` simply to save space (we're working with limited resources here). \n\nWe can reshape images with PIL (Python Imaging Library).","14ce8161":"Perfect! There are 6899 images and 8 classes.","cc9f4029":"It seems that it reaches (near) 100% accuracy after about 15 epochs. Let's plot out its training history.","2832e55f":"Let's check the shape of X:","79aac8e5":"# A Deep Dive into Image Recognition - Tutorial\n\nIn this notebook we'll dive through a few common techniques and methods used in image recognition.\n\n1. Loading & Organizing the Data\n\n    - Image filepath to image\n    - Scaling & resizing images\n    - Automating image processing pipline\n    - Creating data\n    \n    \n2. Basic Convolutional NN\n\n    - Construct basic convolutional NN\n    - Compile & fit\n    - Plot performance\n    \n    \n3. Basic Convolutional NN w\/ Data Augmentation\n\n    - Construct basic convolutional NN\n    - Create & demonstrate data augmentation\n    - Compile & fit\n    - Plot performance & compare without data augmentation\n    \n    \n4. Convolutional NN w\/ Callbacks (Reduce LR)\n\n\n5. Transfer Learning","74a4be52":"We're good to go! On towards constructing the neural network.","4d2f6c51":"We will need to split the data into training and testing sets.","2d8210a3":"Let's just get an idea of our input and output shapes again.","27e14b66":"# 3 | Using Callbacks (Reducing LR)","0b0c8d30":"We need to use ```fit_generator``` instead of simply ```fit```.","a89a4933":"## 1 | Loading & Organizing the Data\n\nLoading image data can be very difficult. Let's take a look at Kaggle's default cell, which can help us get an idea of what the directories and paths look like. You can also get a lot of information from the dataset explorer."}}