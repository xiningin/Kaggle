{"cell_type":{"7fce8dcf":"code","ee1d6598":"code","6489831d":"code","c5c3f08b":"code","3febc1ea":"code","22a5eda0":"code","8f5dbeb0":"code","4cdbc687":"code","3adfa147":"code","0e5b9c7e":"code","da73828a":"code","00414b5b":"code","4bbd60c2":"code","86dd11b0":"code","2556268d":"code","730bd875":"code","2f50a2f0":"code","d31ad85b":"code","ae11e93d":"code","112ad545":"code","5b957bbc":"code","2d1c422c":"code","bf36e515":"code","6164ae41":"code","443108cc":"code","016a9de3":"code","252bbd0c":"code","d96487d6":"code","24fd4e83":"code","a8c17545":"code","26a22b80":"code","b5d583e2":"code","fe5d30c4":"code","19c8b010":"code","49af3ff4":"code","6ef6e60f":"code","427d3b61":"code","279cff5c":"code","6d7a63eb":"code","d614f7f6":"code","db2a453a":"code","792e2aa5":"code","6c1cda4e":"code","5653374b":"code","49a4a82b":"code","88c36c51":"code","476d7c80":"code","b05c4c0b":"code","09f38c13":"code","20cbd656":"code","e0f6ce99":"code","e2c57618":"code","0eb165ae":"code","4f4f4674":"code","844a6398":"code","dae0dff9":"code","eb235d2d":"code","9b88c221":"code","6cddbd5e":"markdown","b5333b0d":"markdown","baea0d55":"markdown","6ea9cab4":"markdown","600f94f5":"markdown","de60f9c8":"markdown","bd609d0c":"markdown","1e944aa9":"markdown","78ba015c":"markdown","914d507f":"markdown","d85ad074":"markdown","3c812572":"markdown","b0b52f49":"markdown","cc34d8c7":"markdown","973b2026":"markdown","f10f3b89":"markdown","801f6e6d":"markdown","f7aab260":"markdown","069885c1":"markdown","8a4cb130":"markdown","a6b5f1e1":"markdown","14421365":"markdown","6677a1a3":"markdown","108c40e6":"markdown"},"source":{"7fce8dcf":"import pandas as pd\nimport numpy as np\nimport glob\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ee1d6598":"# A function for calculating the missing values in dataset in percent\ndef percent_missing(df: pd.DataFrame):\n    # Calculate total  number of cells in dataframe\n    totalCells = np.product(df.shape)\n\n    # Count number of missing values per column\n    missingCount = df.isnull().sum()\n\n    # Calculate total number of missing values\n    totalMissing = missingCount.sum()\n\n    # Calculate percentage of missing values\n    return print(\"The dataset contains\", round(((totalMissing \/ totalCells) * 100), 2), \"%\", \"missing values.\")\n\n\n# A function to see the percentage of missing values of every columns\ndef every_column_percent_missing(df):\n    percent_missing = df.isnull().sum() * 100 \/ len(df)\n    missing_value_db = pd.DataFrame({'column_name': df.columns,\n                                     'percent_missing': percent_missing})\n\n    missing_value_db.sort_values('percent_missing', inplace=True)\n\n    print(missing_value_db)\n    \n#PLOTING FUNCTIONS\n\ndef plot_hist(df: pd.DataFrame, column: str, color: str) -> None:\n    plt.figure(figsize=(9, 7))\n    sns.displot(data=df, x=column, color=color, kde=True, height=7, aspect=2)\n    plt.title(f'Distribution of {column}', size=20, fontweight='bold')\n    plt.show()\n\n\ndef plot_dist(df: pd.DataFrame, column: str):\n    plt.figure(figsize=(9, 7))\n    sns.distplot(df).set_title(f'Distribution of {column}')\n    plt.show()\n\n\ndef plot_count(df: pd.DataFrame, column: str) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.countplot(data=df, x=column)\n    plt.title(f'Plot count of {column}', size=20, fontweight='bold')\n    plt.show()\n\n\ndef plot_bar(df: pd.DataFrame, x_col: str, y_col: str, title: str, xlabel: str, ylabel: str) -> None:\n    plt.figure(figsize=(9, 7))\n    sns.barplot(data=df, x=x_col, y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n\n\ndef plot_heatmap(df: pd.DataFrame, title: str, cbar=False) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.heatmap(df, annot=True, cmap='viridis', vmin=0,\n                vmax=1, fmt='.2f', linewidths=.7, cbar=cbar)\n    plt.title(title, size=18, fontweight='bold')\n    plt.show()\n\n\ndef plot_box(df: pd.DataFrame, x_col: str, title: str) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.boxplot(data=df, x=x_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.show()\n\n\ndef plot_box_multi(df: pd.DataFrame, x_col: str, y_col: str, title: str) -> None:\n    plt.figure(figsize=(12, 7))\n    sns.boxplot(data=df, x=x_col, y=y_col)\n    plt.title(title, size=20)\n    plt.xticks(rotation=75, fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n\n\ndef plot_scatter(df: pd.DataFrame, x_col: str, y_col: str, title: str, hue: str, style: str) -> None:\n    plt.figure(figsize=(10, 8))\n    sns.scatterplot(data=df, x=x_col, y=y_col, hue=hue, style=style)\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n    \n    \ndef bar_plot(x, y, title, palette_len, xlim = None, ylim = None, \n             xticklabels = None, yticklabels = None, \n             top_visible = False, right_visible = False, \n             bottom_visible = True, left_visible = False,\n             xlabel = None, ylabel = None, figsize = (10, 4),\n             axis_grid = 'y'):\n    fig, ax = plt.subplots(figsize = figsize)\n    plt.title(title, size = 15, fontweight = 'bold', fontfamily = 'serif')\n\n    for i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_color('black')\n    \n    ax.spines['top'].set_visible(top_visible)\n    ax.spines['right'].set_visible(right_visible)\n    ax.spines['bottom'].set_visible(bottom_visible)\n    ax.spines['left'].set_visible(left_visible)\n\n    sns.barplot(x = x, y = y, edgecolor = 'black', ax = ax,\n                palette = reversed(sns.color_palette(\"viridis\", len(palette_len))))\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)    \n    ax.set_xticklabels(xticklabels, fontfamily = 'serif')\n    ax.set_yticklabels(yticklabels, fontfamily = 'serif')\n    plt.xlabel(xlabel, fontfamily = 'serif')\n    plt.ylabel(ylabel, fontfamily = 'serif')\n    ax.grid(axis = axis_grid, linestyle = '--', alpha = 0.9)\n    plt.show()\n    \n    \ndef line_plot(data, y, title, color,\n              top_visible = False, right_visible = False, \n              bottom_visible = True, left_visible = False,\n              ylabel = None, figsize = (10, 4), axis_grid = 'y'):\n    fig, ax = plt.subplots(figsize = figsize)\n    plt.title(title, size = 15, fontweight = 'bold', fontfamily = 'serif')\n\n    for i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_color('black')\n    \n    ax.spines['top'].set_visible(top_visible)\n    ax.spines['right'].set_visible(right_visible)\n    ax.spines['bottom'].set_visible(bottom_visible)\n    ax.spines['left'].set_visible(left_visible)\n    \n    sns.lineplot(x = range(len(data[y])), y = data[y], dashes = False, \n                 color = color, linewidth = .5)\n    ax.xaxis.set_major_locator(plt.MaxNLocator(20))\n    \n    ax.set_xticks([])\n    plt.xticks(rotation = 90)\n    plt.xlabel('')\n    plt.ylabel(ylabel, fontfamily = 'serif')\n    ax.grid(axis = axis_grid, linestyle = '--', alpha = 0.9)\n    plt.show()\n    \n    \ndef corr_plot(data,\n              top_visible = False, right_visible = False, \n              bottom_visible = True, left_visible = False,\n              ylabel = None, figsize = (15, 11), axis_grid = 'y'):\n    fig, ax = plt.subplots(figsize = figsize)\n    plt.title('Correlations (Pearson)', size = 15, fontweight = 'bold', fontfamily = 'serif')\n    \n    mask = np.triu(np.ones_like(data.corr(), dtype = bool))\n    sns.heatmap(round(data.corr(), 2), mask = mask, cmap = 'viridis', annot = True)\n    plt.show()\n    \ndef columns_viz(data, color):\n    for i in range(len(data.columns)):\n        line_plot(data = data, y = data.columns[i],\n                  color = color,\n                  title = '{} dynamics'.format(data.columns[i]),\n                  bottom_visible = False, figsize = (10, 2))","6489831d":"districts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\nproducts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\neng_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'","c5c3f08b":"## Merging all the engagement data\neng_files = glob.glob(eng_path + \"\/*.csv\")\n\nfiles = []\n\nfor file in eng_files:\n    df = pd.read_csv(file, index_col = None, header = 0)\n    district_id = file.split('\/')[4].split('.')[0]\n    df['district_id'] = district_id\n    files.append(df)\n    \nengagement = pd.concat(files)\nengagement = engagement.reset_index(drop = True)\nengagement['time'] = pd.to_datetime(engagement['time'])","3febc1ea":"datasets = [districts_info, products_info, engagement]\ndatasets_names = ['districts_info','products_info','engagement']","22a5eda0":"for i in range(len(datasets)):\n    NaN_values = (datasets[i].isnull().sum() \/ len(datasets[i]) * 100).sort_values(ascending = False)\n    bar_plot(x = NaN_values, \n             y = NaN_values.index,\n             title = '{}: NaN values (%)'.format(datasets_names[i]),\n             palette_len = NaN_values.index, \n             xlim = (0, 100), \n             xticklabels = range(0, 101, 20),\n             yticklabels = NaN_values.index,\n             left_visible = True,\n             figsize = (10, 8), axis_grid = 'x')","8f5dbeb0":"districts_info.head()","4cdbc687":"print(f\" There are {districts_info.shape[0]} rows and {districts_info.shape[1]} columns\")","3adfa147":"# Basic statsitcal discription on numerical columns\ndistricts_info.describe()","0e5b9c7e":"# Checking for null values\ndistricts_info.isnull().sum()","da73828a":"percent_missing(districts_info)","00414b5b":"every_column_percent_missing(districts_info)","4bbd60c2":"districts_cleaned = districts_info.dropna()","86dd11b0":"print(f\" There are {districts_cleaned.shape[0]} rows and {districts_cleaned.shape[1]} columns\")","2556268d":"every_column_percent_missing(districts_cleaned)","730bd875":"percent_missing(districts_cleaned)","2f50a2f0":"districts_cleaned.duplicated().sum()","d31ad85b":"products_info.head()","ae11e93d":"products_info.describe()","112ad545":"print(f\" There are {products_info.shape[0]} rows and {products_info.shape[1]} columns\")","5b957bbc":"products_info.isnull().sum()","2d1c422c":"percent_missing(products_info)","bf36e515":"every_column_percent_missing(products_info)","6164ae41":"products_cleaned = products_info.dropna()","443108cc":"percent_missing(products_cleaned)","016a9de3":"print(f\" There are {products_cleaned.shape[0]} rows and {products_cleaned.shape[1]} columns\")","252bbd0c":"plot_hist(districts_cleaned,'state','green')\nplot_hist(districts_cleaned,'locale','orange')\nplot_hist(districts_cleaned,'pct_black\/hispanic','red')\nplot_hist(districts_cleaned,'pct_free\/reduced','blue')\nplot_hist(districts_cleaned,'pp_total_raw','green')","d96487d6":"plot_hist(products_cleaned,'Sector(s)','red')","24fd4e83":"engagement.head()","a8c17545":"print(f\" There are {engagement.shape[0]} rows and {engagement.shape[1]} columns\")","26a22b80":"every_column_percent_missing(engagement)","b5d583e2":"percent_missing(engagement)","fe5d30c4":"engagement_cleaned = engagement.dropna()","19c8b010":"percent_missing(engagement_cleaned)","49af3ff4":"datasets = [districts_cleaned, products_cleaned, engagement_cleaned]\ndatasets_names = ['districts_cleaned','products_cleaned','engagement_cleaned']","6ef6e60f":"columns_viz(datasets[0], color = '#900C3F')","427d3b61":"for i in ['pct_black\/hispanic', 'pct_free\/reduced']:\n    districts_cleaned[i] = districts_cleaned[i].apply(lambda x: float(x.split(',')[0][1:]) + 0.1)\n\ndistricts_cleaned['pp_total_raw'] = districts_cleaned['pp_total_raw'].apply(lambda x: int(x.split(',')[0][1:]) + 1000)\n\ndistricts_cleaned.drop('county_connections_ratio', axis = 1, inplace = True)\n\ndistricts_cleaned.head(3)","279cff5c":"products_cleaned.head(3)","6d7a63eb":"plt.figure(figsize = (15, 8))\na = sns.barplot(data = districts_cleaned['state'].value_counts().reset_index(), x = 'state', y = 'index', color = '#90afc5')\nplt.xticks([])\nplt.yticks(fontname = 'monospace', fontsize = 14, color = '#900C3F')\nplt.title('Distribution over states',fontweight = 'bold', fontfamily = 'serif', fontsize = 20, color = '#000000')\nplt.ylabel('States')\nplt.xlabel('Distribution')\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n    \nfor p in a.patches:\n    width = p.get_width()\n    plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n             ha = 'center', va = 'center', fontname = 'monospace', fontsize = 15, color = '#283655')\nplt.show()\n","d614f7f6":"dist_area_group = districts_cleaned.groupby('locale').agg({'pct_black\/hispanic': 'mean', 'pct_free\/reduced': 'mean', 'pp_total_raw': 'mean'}).reset_index()\n\ncolors = ['#00FFFF', '#0000FF', '#808000']\n\nfig = plt.figure(figsize = (13, 12))\nfor i in range(len(dist_area_group.columns.tolist()[1:])):\n    plt.subplot(2, 2, i+1)\n    sns.set_style(\"white\")\n    plt.title(dist_area_group.columns.tolist()[1:][i], fontweight = 'bold', fontfamily = 'serif', fontsize = 20, y = 1.09, color = colors[i])\n    plt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\n    a = sns.barplot(data = dist_area_group, x = 'locale', y = dist_area_group.columns.tolist()[1:][i], color = colors[i])\n    plt.ylabel('')\n    plt.xlabel('')\n    plt.xticks(fontweight = 'bold', fontfamily = 'serif', fontsize = 20)\n    plt.yticks([])\n    \n    for j in ['right', 'top', 'left']:\n        a.spines[j].set_visible(False)\n    for j in ['bottom']:\n        a.spines[j].set_linewidth(1.4)\n      \n    if i < 2:\n        for p in a.patches:\n            height = p.get_height()\n            a.annotate(f'{int(height*100)} %', (p.get_x() + p.get_width() \/ 2, p.get_height()-0.03), \n                   ha = 'center', va = 'center', \n                   size = 18,\n                   xytext = (0, 5), \n                   textcoords = 'offset points',\n                   color = 'white',\n                   fontname = 'monospace')\n    else:\n        for p in a.patches:\n            height = p.get_height()\n            a.annotate(f'{int(height)} $', (p.get_x() + p.get_width() \/ 2, p.get_height()-1000), \n                   ha = 'center', va = 'center', \n                   size = 18,\n                   xytext = (0, 5), \n                   textcoords = 'offset points',\n                   color = 'white',\n                   fontname = 'monospace')\n            \nplt.figtext(0.07, 1.05, 'Characteristics of school districts by locale', fontsize = 30, fontname = 'monospace', color = '#283655')\n\n\nfig.tight_layout(pad = 3)\n\nplt.show()","db2a453a":"plt.figure(figsize = (15, 8))\nsns.set_style(\"white\")\nplt.title('TOP-15 providers', size = 35, x = 0.48, y = 1.06, fontweight = 'bold', fontfamily = 'serif', fontsize = 20, color = '#283655')\na = sns.barplot(data = products_cleaned['Provider\/Company Name'].value_counts().reset_index().head(15), x = 'Provider\/Company Name', y = 'index', color = '#90afc5')\nplt.xticks([])\nplt.yticks(fontweight = 'bold', fontfamily = 'serif', fontsize = 20, color = '#283655')\nplt.ylabel('')\nplt.xlabel('')\n\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n#counting the numbers\nfor p in a.patches:\n    width = p.get_width()\n    plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n             ha = 'center', va = 'center', fontname = 'monospace', fontsize = 15, color = '#000000')\n\nplt.show()","792e2aa5":"#Code credit Dimtry Uraov\nstate_abb = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_cleaned['state_abb'] = districts_cleaned['state'].map(state_abb)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Count of districts in the available States\",\n    title_font = dict(\n            family = \"monospace\",\n            size = 25,\n            color = \"black\"\n            ),\n    geo_scope = 'usa'\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations = districts_cleaned['state_abb'].value_counts().to_frame().reset_index()['index'],\n        zmax = 1,\n        z = districts_cleaned['state_abb'].value_counts().to_frame().reset_index()['state_abb'],\n        locationmode = 'USA-states',\n        marker_line_color = 'white',\n        geo = 'geo',\n        colorscale = \"cividis\", \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","6c1cda4e":"districts_cleaned","5653374b":"fig = px.pie(districts_cleaned['locale'].value_counts().reset_index().rename(columns = {'locale': 'count'}), values = 'count', names = 'index', width = 700, height = 700)\n\nfig.update_traces(textposition = 'inside', \n                  textinfo = 'percent + label', \n                  hole = 0.7, \n                  marker = dict(colors = ['#90afc5','#336b87','#2a3132','#763626'], line = dict(color = 'white', width = 2)))\n\nfig.update_layout(annotations = [dict(text = ' The count of districts <br>in each type <br>of areas', \n                                      x = 0.5, y = 0.5, font_size = 26, showarrow = False, \n                                      font_family = 'monospace',\n                                      font_color = '#283655')],\n                  showlegend = False)\n                  \nfig.show()","49a4a82b":"products_cleaned\n","88c36c51":"engagement_cleaned","476d7c80":"merged_data = pd.merge(products_cleaned, engagement_cleaned, left_on = 'LP ID', right_on = 'lp_id')\nmerged_data['district_id'] = merged_data['district_id'].astype('int64')\nmerged_data = pd.merge(merged_data, districts_cleaned, on = 'district_id')\nmerged_data.drop(['URL', 'lp_id', 'state_abb'], axis = 1, inplace = True)\nmerged_data.head(3)","b05c4c0b":"num_data = merged_data[['engagement_index', 'pct_black\/hispanic', 'pct_free\/reduced',\n                                 'pct_access',  'pp_total_raw']]\ndata_correlation = num_data.corr()\nplot_heatmap(data_correlation, 'Numerical Data Correlation')\ndata_correlation","09f38c13":"top3 = merged_data['pct_access'].value_counts().head(10)\ntop3.plot.pie(figsize=(12, 12))","20cbd656":"top3 = merged_data['state'].value_counts().head(10)\ntop3.plot.pie(figsize=(12, 12))","e0f6ce99":"top3 = merged_data['locale'].value_counts().head(10)\ntop3.plot.pie(figsize=(12, 12))","e2c57618":"top3 = merged_data['Primary Essential Function'].value_counts().head(10)\ntop3.plot.pie(figsize=(12, 12))","0eb165ae":"top3 = merged_data['Provider\/Company Name'].value_counts().head(10)\ntop3.plot.pie(figsize=(12, 12))","4f4f4674":"top3 = merged_data['Product Name'].value_counts().head(10)\ntop3.plot.pie(figsize=(12, 12))","844a6398":"plot_count(merged_data,'time')","dae0dff9":"pip install https:\/\/github.com\/pandas-profiling\/pandas-profiling\/archive\/master.zip","eb235d2d":"import pandas_profiling as pp\nfrom pandas_profiling import ProfileReport\nprofile = ProfileReport(merged_data,title=\"Pandas Profiling Report 2015\", explorative=True)\nprofile.to_notebook_iframe()","9b88c221":"profile.to_file(\"EDA LearnPlatform Covid-19 Impact on Digital Learn.html\")","6cddbd5e":"## Missing Values on Districts_info.csv & cleaning ","b5333b0d":"### Top 10's pie plot to help visualisation the distribution ","baea0d55":"### My utility scripts","6ea9cab4":"![image.png](attachment:d01a11c9-70a8-402f-8d50-9fa314cb8551.png)","600f94f5":"# LearnPlatform COVID-19 Impact on Digital Learning Analysis\n","de60f9c8":"# Importing the neccessary libraries","bd609d0c":"# acknowledgement\n\n- [10 Academy](https:\/\/www.10academy.org\/)\n- https:\/\/gist.github.com\/rogerallen\/1583593\n- https:\/\/www.kaggle.com\/dmitryuarov\/eda-covid-19-impact-on-digital-learning\n- https:\/\/www.youtube.com\/watch?v=AYalukmWroY\n","1e944aa9":"## Let's check the distributions of products dataset with some plots ","78ba015c":"## Exploring the engagement data","914d507f":"**Droping the NAN values out of 233 rows we've left with 88 rows**","d85ad074":"# Conclusion\n\n## What is the state of digital learning in 2020?\n- Every weekend in all states there was a drop in student activity indicators.\n- Google LLC is the lion share holder in provider, with its many applications.\n- Suburb areas were the main areas where the data is accumulated.\n### After the anouncement of COVID-19 in the first two weeks\n- **Utah** : stronger decrease in the percentage of students who had at least one page-loaded and strong increase of mean of total page-loaded events per one thousand students(+43.4% on second week).\n- **Illinois** : students who had at least one page-load declined to -38.9% on second week.\n- **Indiana** :  students who had at least one page-loaded (-49.5% on first week and -31.8% on second).\n- **Washington** - significantly reduced only in the first week \n- **Missouri** : a strong decrease of 90%.\n- **New York** : at least one page-loaded has not changed at all.\n- **North Carolina** : students from North Carolina stopped studying until the beginning of the next academic year.\n- **Wisconsin** -  rapidly decreasing (on second week pct_access -72.6% and engagement index -83.7%)\n- **Virginia** :  significantly reduced only in the first week.\n- **New Jersey** : the pandemic has had almost no impact on students activity.\n- **Texas** : significantly reduced only in the first week\n- **Michigan** : students stopped compeletly, making only a minor attempt to study again in May.\n- **Minnesota** : student activity indicators decreased by half.\n- **Florida** : almost all students stopped studying (-96%) \n\n## How does the engagement of digital learning relate to factors such as: district demographics,broadband access, and state\/national level policies and events?\n- -We can see that **pct_access** and **engagement_index** are highly positvely corelated as expected.\n- Interestingly **Pct_free\/reduced** and **pct_black\/hispanic** are also highly positively corelated.\n- The average number of students who identified themselves as Black or Hispanic is 23.2%. The most common value is 10%.\n\n- The average number of students eligible for free orreduced-price lunch is 38%. The most common values are ~30% and ~50%.\n\n- Per-pupil total expenditure (sum of local and federal expenditure) is 11 205, with the most common value is 9 000.\n\n## What is the picture of digital connectivity and engagement in 2020?\n![newplot.png](attachment:b3abc977-7642-4df2-9a3d-07487433680d.png)\n## What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n- Students from rural areas are the most interested in distance learning, while students from cities are the least interested. \n- The activity indicators of students from cities decreased by 74.3% and 60%, while the percentage of students in rural areas who had at least one page-load decreased by 32.4% and the indicator mean of total page-loaded events per one thousand students increased by 3.3%.\n- Therefore, COVID-19 even affected the decrease in the activity of those students who studied remotely before the pandemic. Many students saw an opportunity to relax, and they used it.\n\n## How does student engagement with different types of education technology change over the course of the pandemic?\n- As for the future of distance learning, already at the beginning of the academic year 2020-2021 we see absolutely normal indicators that should not change much anymore.\n\n## How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n- Students in rural areas are more interested by distance education thanks to the space from educational institutions that are more accessible within the town therefore were more prepared for distance learning, because it wasn't something new for them, except for most students from cities it had been.\n\n## Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?\n- Educational institutions in cities, like many other socially and economically important places, were closed primarily to limit the spread of the coronavirus, which should have led to the reform of education and thus the introduction of distance learning on the size of the entire country.\n- Generally , thanks to the closure of educational institutions, there should are an enormous increase within the activity of scholars in distance learning\n\n# The detailed exploratory interactive html report can be found [here](https:\/\/www.kaggleusercontent.com\/kf\/73959275\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..hwMC8qvoD6YS9tan_jQwuw.kfdGHO2N79o51ig7IHTKClLKkKwK_DQepIvPF8lZ0hZGK0ElYjlzVhIWoNUJVDa_wV-L-0AaeEWY5UQeAT7upu-VBun-WgMzhR0boSDtGtJeziCNJglcvyWwhEE0XRLwr-i4fiV1LVMkS9anZ627SwGrfUQSTZEwN6xFV_RArkYjiLarSLrDn7eVEYMk8eLPpbY93lD7jo6Cb6AU7cNy2vTVzlDuJ4oXrOk5ez3sQKXMOX-WoC8A590ogB8_iVpqPeuPelMPlFrLbOspMP8_ZF_lfS75-qLPZI2ljVJUiwDotuOXtCepyuPgCGjNhcpTwwTiPxVBLZqjI5iKFDqbS9ov__W_QgVeHMqkk4wIUmronLk6hi9uK0skOsLxHbd48jWbvr94bvce9a4XT6ZgR6BCR83vy1137uFDcLcMn-uytbhPtDDr_sF_NZIUoXruhPspQ11KudWXr_98bt1VBe_eZFit01GlPzOmIqcRiakysO0m2JOn5lBfyld7ZPhpIOUFi8f2wu7z9SL7FhdjeoXqQUduGbOU3EXSs51E28LDWbkjTVuT_KwnXxxCzsoZqaX_4Zo3m_IHnHu_5UwcvIOuB_ACS6xrIKGAyOX9zQ_SRmxwLlDBeV-EYjfVRAZGFER9y13hgWPLU_u9YqJJaicgcWujrhrCqT-zKFVhH4AYWpGQgkKsrB5mm89EVp46.A2U3LFg_dIIKaVctQK99sA\/EDA%20LearnPlatform%20Covid-19%20Impact%20on%20Digital%20Learn.html).","3c812572":"### Merging all the data together","b0b52f49":"Information about pct_black\/hispanic, pct_free\/reduced, county_connections_ratio and pp_total_raw is presented in the form of intervals, where \"[a, b[\" means that a \u2264 x < b. All values in pct_black\/hispanic and pct_free\/reduced values have an interval of 20%, for a more understandable view we can convert them to a single value with a deviation of +- 10%. The information about county_connections_ratio is represented by the most abstract value from 18% to 100% and, unfortunately, this information is of no use. All values of of pp_total_raw have an interval of 2000, following the example of the previous two columns, we convert the values to a single value with a deviation of +- 1000.","cc34d8c7":"There are **NaN** rows in the dataset. \n\nUSE **df.dropna()** TO DROP ROWS WITH NaN FROM A PANDAS DATAFRAME","973b2026":"### Missing Values on products_info.csv & cleaning ","f10f3b89":"### EXPLORING THE NAN VALUES","801f6e6d":"As we can see there are ***27.1 percent missing*** values in the **districts_info.csv**\n\nLet's check the percentage missing values by column","f7aab260":"### **Motivation**\n\n\nCurrent research shows educational outcomes are far from equitable. The imbalance was exacerbated by the COVID-19 pandemic. There's an urgent need to better understand and measure the scope and impact of the pandemic on these inequities.\n\nEducation technology company ***LearnPlatform*** was founded in 2014 with a mission to expand equitable access to education technology for all students and teachers. LearnPlatform\u2019s comprehensive edtech effectiveness system is used by districts and states to continuously improve the safety, equity, and effectiveness of their educational technology. LearnPlatform does so by generating an evidence basis for what\u2019s working and enacting it to benefit students, teachers, and budgets.\n\nIn this notebook, I\u2019ll work to uncover trends in digital learning with data analysis about how engagement with digital learning relates to factors like district demographics, broadband access, and state\/national level policies and events. \n\n\n### Problem statement\n- What is the state of digital learning in 2020? \n- And how does the engagement of digital learning relate to factors such as:\n    - district demographics, \n    - broadband access, and \n    - state\/national level policies and events?\n- What is the picture of digital connectivity and engagement in 2020?\n- What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n- How does student engagement with different types of education technology change over the course of the pandemic?\n- How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n- Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?\n","069885c1":"## **Exploratory data analysis (EDA)**\nExploratory data analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.\n\nIn this analytics challenge, we are given multiple .csv files [here](https:\/\/www.kaggle.com\/c\/learnplatform-covid19-impact-on-digital-learning\/data). The main information contained in these files is which tools are used with what engagement in which school district in the United States of America in 2020. [Read the Data Description](https:\/\/www.kaggle.com\/c\/learnplatform-covid19-impact-on-digital-learning\/data) \n\nThe **[districts_info.csv file](https:\/\/www.kaggle.com\/c\/learnplatform-covid19-impact-on-digital-learning\/data)** contains information about each school district and the **[products_info.csv](https:\/\/www.kaggle.com\/c\/learnplatform-covid19-impact-on-digital-learning\/data?select=products_info.csv)** file contains information about the top 370 tools used for digital learning. For each school district, there is an additional file that contains the engagement for each tool for everyday in 2020. \n\nThe files can be joined by the key columns ***district_id*** and ***lp_id***.","8a4cb130":"The largest count of students who identified themselves as Black or Hispanic are in large cities.\nThe smallest count is in the suburbs and rural areas.\n\nIn cities and towns half of the students are eligible\nfor free or reduced-price lunch.\n\nThe highest total expenses per student is in rural area.","a6b5f1e1":"- We can see that **pct_access** and **engagement_index** are highly positvely corelated as expected.\n- Interestingly **Pct_free\/reduced** and **pct_black\/hispanic** are also highly positively corelated","14421365":"![](https:\/\/tishadz.com\/wp-content\/uploads\/2021\/04\/overview-of-online-learning.png)","6677a1a3":"## Let's check the distributions of districts dataset with some plots ","108c40e6":"## EDA on Districts_info.csv "}}