{"cell_type":{"8f8c5f3c":"code","859a4f62":"code","72ffc2f9":"code","cd1174b2":"code","707bb5a9":"code","3419cb65":"code","a342f6a2":"code","f9a402a8":"code","de587915":"code","8661909b":"code","212385f5":"code","69871bf2":"code","1b36d010":"code","323ab28d":"code","98bdf3ce":"code","fdb8d982":"code","9f759deb":"code","557b5fbf":"code","672de047":"code","dd534bb3":"code","0be5fa40":"code","97582757":"code","efacfd95":"code","b82250e9":"code","c40ce462":"code","0f4f2b3f":"code","930822ae":"code","dc971cd2":"code","e539b659":"code","42c3fc02":"code","78a6ec01":"code","65216123":"code","35a12ab7":"markdown","cb1115eb":"markdown","5f3e2fb2":"markdown","73154684":"markdown","4f26e936":"markdown","060ede84":"markdown","00dc032a":"markdown","2bebcc41":"markdown","08341c98":"markdown","e8474633":"markdown","d4dad93d":"markdown","0a6d6148":"markdown","80d7f94f":"markdown","cd503097":"markdown","a634339a":"markdown"},"source":{"8f8c5f3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","859a4f62":"import math #for mathematical operations\nimport time \nimport os\nfrom skimage import io, transform #for augmentation purposes\nimport PIL #for image processing\nworkers=2\nworking_dir = '.\/'#for loading saved files to this location , will be used at the end","72ffc2f9":"main_dir = '..\/input\/petfinder-pawpularity-score' \nbatch_size = 32\nnp.random.seed(100)","cd1174b2":"import matplotlib.pyplot as plt # used for plotting\nimport torch #pytorch\nfrom torchvision import datasets,transforms, models \nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts #scheduler used for finding global minima\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler","707bb5a9":"train_df= pd.read_csv(f'{main_dir}\/train.csv')  \ntrain_df.head(4)","3419cb65":"train_df.info()","a342f6a2":"plt.hist(train_df.iloc[:,13],bins=50,facecolor ='r',alpha= 0.5)\nplt.xlabel('pawpularity_score')\nplt.ylabel('frequency')\nplt.title('PAWPULARITY DISTRIBUTION')\nplt.grid(True)","f9a402a8":"class Pawpularity_Data(Dataset):\n    def __init__(self,csv_file,img_dir,transform = transforms.ToTensor()):\n        self.annotations_csv = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform =transform\n        \n    def __len__(self):\n        return len(self.annotations_csv)\n    \n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_name = os.path.join(self.img_dir,self.annotations_csv.iloc[idx,0])\n        image = PIL.Image.open(img_name + '.jpg')\n        # Columns 1 to 12 contain the annotations\n        annotations = np.array(self.annotations_csv.iloc[idx, 1:13])\n        annotations = annotations.astype('float')\n        # Column 13 has the scores\n        score = np.array(self.annotations_csv.iloc[idx, 13])\n        score = torch.tensor(score.astype('float')).view(1).to(torch.float32)\n        # Apply the transforms\n        image = self.transform(image)\n        sample = [image, annotations, score]\n        return sample","de587915":"# Test out the transforms on an image (images need to be made the same size for the dataset to work)\nimg_transforms = transforms.Compose([transforms.Resize(255),\n                                     transforms.CenterCrop(224),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.RandomRotation(20),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                          std=[0.229, 0.224, 0.225])])\n\nimg_transforms_valid = transforms.Compose([transforms.Resize(255),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                std=[0.229, 0.224, 0.225])])","8661909b":"train_data = Pawpularity_Data(f'{main_dir}\/train.csv',f'{main_dir}\/train',transform =img_transforms)\ntrain_data.img_dir","212385f5":"dataloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)","69871bf2":"images, annotations, scores = next(iter(dataloader))\nprint(images.shape)\nprint(scores.shape)\nprint(annotations.shape)","1b36d010":"def de_norm(tensor):\n    image = tensor.to('cpu').clone().detach()\n    image = image.numpy().squeeze()\n    image = image * np.array((0.229, 0.224, 0.225)).reshape(3, 1, 1) + np.array((0.485, 0.456, 0.406)).reshape(3, 1, 1)\n    img = (image * 255).astype(np.uint8) # unnormalize\n    return plt.imshow(np.transpose(img, (1, 2, 0)))","323ab28d":"im_numpy = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(20, 10))\n# display 20 images\nfor idx in np.arange(8):\n    ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\n    de_norm(images[idx])\n    ax.set_title(scores[idx].item())\n","98bdf3ce":"import torch.nn as nn\nimport torch.nn.functional as func\nimport torch.optim as optim","fdb8d982":"# Calculate the dense layer input size\n# Padding of 1 and of 3 means no change in the image dimensions apart from pooling\n\nsdim = 224\/2\/2\/2\/2\/2 #maxpoolin layers reduce xy dimensions by 2\nprint(sdim)\nprint(sdim*sdim*256+12) # add in the annotations","9f759deb":"model = torch.load('..\/input\/resnet-pretrained\/resnet_pretrained.pt')\n","557b5fbf":"# Disable gradients on all model parameters to freeze the weights\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Sequential(nn.Linear(2048, 1024),\n                         nn.ReLU(),\n                         nn.Linear(1024, 512),\n                         nn.ReLU(),\n                         nn.Linear(512, 256),\n                         nn.ReLU(),\n                         nn.Linear(256, 128),\n                         nn.ReLU(),\n                         nn.Linear(128, 1),\n                         nn.Sigmoid())\n\nfor param in model.fc.parameters():\n    param.requires_grad = True","672de047":"print(model)","dd534bb3":"torch.manual_seed(40)\n\ncriterion = nn.MSELoss(reduction='sum')\n\n\n#Adam with L2 regularization\noptimizer = optim.AdamW(model.parameters(), lr=0.0008, weight_decay=0.2)\n\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,10,\n    T_mult=1,\n    eta_min=0,\n    last_epoch=-1,\n    verbose=False,\n)","0be5fa40":"# Load a small batch to test out the forward pass\n\ntrain_dataset = Pawpularity_Data(f'{main_dir}\/train.csv', f'{main_dir}\/train', transform=img_transforms)\ndataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\nimages, annotations, scores = next(iter(dataloader))","97582757":"# Test out the forward pass on a single batch\n# RMSE before any training (with random parameters): \nwith torch.no_grad():\n    train_loss = 0.0\n    output = model(images)*100\n    loss = criterion(output, scores)\n    math.sqrt(loss.item()\/64)","efacfd95":"print(scores.dtype)\nprint(output.dtype)\nprint(torch.mean(output))\nprint(torch.std(output))","b82250e9":"## Load and set up the final training and validation dataset (use different transforms)\n\ntrain_data = Pawpularity_Data(f'{main_dir}\/train.csv', f'{main_dir}\/train', transform=img_transforms)\nvalid_data = Pawpularity_Data(f'{main_dir}\/train.csv', f'{main_dir}\/train', transform=img_transforms_valid)\n\nnp.random.seed(100)\n\n# obtain random indices that will be used for traingin\/validation split\nvalid_size = 0.2\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           sampler=train_sampler, num_workers=workers,\n                                           pin_memory=True) \nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,\n                                           sampler=valid_sampler, num_workers=workers,\n                                           pin_memory=True) \n\nprint(len(train_loader)*batch_size)\nprint(len(valid_loader)*batch_size)","c40ce462":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\ndevice = torch.cuda.get_device_name()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print(f'CUDA is available!  Training on GPU {device}...')","0f4f2b3f":"# number of epochs to train the model\n# Use 40 epochs\n\nif train_on_gpu:\n    model.cuda()\n\nn_epochs = 70\n\nvalid_loss_min = np.Inf # track change in validation loss\n\ntrain_losses, valid_losses = [], []\n\nfor epoch in range(1, n_epochs+1):\n    \n    start = time.time()\n    current_lr = scheduler.get_last_lr()[0]\n    \n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    # put in training mode (enable dropout)\n    model.train()\n    for images, annotations, scores in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        # the annotations get added in the dense layers\n        output = model(images)*100\n        # print(output.dtype)\n        # print(scores.dtype)\n        # calculate the batch loss\n        loss = criterion(output, scores)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()\n        \n    ######################    \n    # validate the model #\n    ######################\n    # eval mode (no dropout)\n    model.eval()\n    with torch.no_grad():\n        for images, annotations, scores in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(images)*100\n            # calculate the batch loss\n            loss = criterion(output, scores)\n            # update average validation loss \n            valid_loss += loss.item()\n    \n    # calculate RMSE\n    train_loss = math.sqrt(train_loss\/len(train_loader.sampler))\n    valid_loss = math.sqrt(valid_loss\/len(valid_loader.sampler))\n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # increment learning rate decay\n    scheduler.step()\n    \n    # print training\/validation statistics \n    # print(f'Epoch: {e}, {float(time.time() - start):.3f} seconds, lr={optimizer.lr}')\n    print('Epoch: {}, time: {:.3f}s, lr: {:.6f} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, float(time.time() - start), current_lr, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), f'{working_dir}pawpularity_best_model.pt')\n        valid_loss_min = valid_loss    ","930822ae":"# Load the best performing model on the validation set\nmodel.load_state_dict(torch.load(f'{working_dir}pawpularity_best_model.pt'))","dc971cd2":"class PawpularityTestDataset(Dataset):\n    \"\"\"Dataset connecting dog images to the score and annotations\"\"\"\n\n    def __init__(self, csv_file, img_dir, transform=transforms.ToTensor()):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            img_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n\n        self.annotations_csv = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations_csv)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.img_dir,\n                                self.annotations_csv.iloc[idx, 0])\n\n        # load each image in PIL format for compatibility with transforms\n        image = PIL.Image.open(img_name + '.jpg')\n\n        annotations = np.array(self.annotations_csv.iloc[idx, 1:13])\n        annotations = annotations.astype('float')\n\n        # Apply the transforms\n        image = self.transform(image)\n\n        sample = [image, annotations]\n        return sample","e539b659":"## Load the test dataset\nimg_transforms = transforms.Compose([transforms.Resize(255),\n                                       transforms.CenterCrop(224),\n                                       transforms.ToTensor()])\n\ntest_data = PawpularityTestDataset(f'{main_dir}\/test.csv', f'{main_dir}\/test', transform=img_transforms_valid)\n\nbatch_size = min(len(test_data), 32)\n\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=workers) ","42c3fc02":"test_df = pd.read_csv(f'{main_dir}\/test.csv')\ntest_df.head(10)","78a6ec01":"# Step through with a reasonable batch size and build up the output dataset\n\nmodel.eval()\noutputs = []\nfor images, annotations in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        images, annotations = images.cuda(), annotations.cuda()\n    test_output = model(images)*100\n    outputs.extend(list(test_output.cpu().detach().numpy().reshape(len(test_output),)))\n    \nimg_names = list( test_df.iloc[:, 0].values)\noutputs = [round(x, 2) for x in outputs]\n\noutput_df = pd.DataFrame({'Id': img_names, 'Pawpularity': outputs})\noutput_df.head(10)","65216123":"# Write the output in the required format\noutput_df.to_csv('submission.csv', index=False)","35a12ab7":"BASIC IMPORTS","cb1115eb":"# Data preprocessing","5f3e2fb2":"# Classifier Head \nYou can use any classifier but I have gone with ANN with 5 dense layers..","73154684":"# Basic Imports","4f26e936":"# Image Augmentations","060ede84":"Hello every-one , I am sharing the basic approach to tackle this competition. This code is for beginners who are new to kaggle , pytorch and data-science. I have tried to explain each and every code cell in a layman terms so that many beginners who get confused to understand the code of high scoring notebooks can easily get what I have done here.\n**This notebook scored 18.50 on public leaderboad(pb) and 17.87 during validation**","00dc032a":"No need to get confused, I am just using names instead of copying the link of the directory","2bebcc41":"Calling the class that we created earlier ","08341c98":"# CNN MODEL ARCHITECTURE","e8474633":"# CONFIG","d4dad93d":"# Important!!! dont skip this\nSince this competition needs , kaggle internet to be switched off before submitting the predictions, common issue may arise when importing a pretrained model like..... this .... model = models.resnet50(pretrained=True)....this approach is not wrong but it will require internet to download imagenet weights... which will throw an error during submission since internet is off.\n\nTo deal with this .... open a separate notebook and load a model like mentioned above and then save the model in .pt file and download it and upload in your working notebook.","0a6d6148":"* Now comes the tricky part( not that tricky though!!). I have used basic OOPs , this way code looks clean and its easy to track the info.\n* The code below , gives outthe pawpularity score , transformed image and annotations. This class so formed will be called in further code cells... and it consits of 3 methods __init__, __len__,__getitem__\n* Basically this compitition deals with images and tabular data, so we have to merge both type of data .... in __get_item__ method, the path of the images have been added into the table of annotations according to image ids. In this manner Pawpularity score act as a label\/ answers(supervised learning) for the image.\n\n","80d7f94f":"* Image augmentation is done to deliberately increase the size of the dataset so that model gets trained on a large dataset, this makes models's prediction more robust\n* Augmentations can be of many types but according to my testings..... this for this competition , flipping and rotation gave better results \n* Whereas augmentations like blurring, changing contrast and vertical flipping hampered the prediction","cd503097":"# LOOKING AT IMAGES FROM DATA","a634339a":"# TRAINING THE MODEL"}}