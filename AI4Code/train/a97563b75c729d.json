{"cell_type":{"49aa7ea6":"code","a6827672":"code","b31ea624":"code","8168ace5":"code","1b9bfbb1":"code","2b49a50b":"code","2f6fdce3":"code","687c9c7d":"code","ddc67288":"code","ec7321f7":"code","53534825":"code","2f10d9b4":"code","e871939e":"code","f690c197":"code","02b7a58d":"code","b715c879":"code","0041401d":"code","5d79e0cc":"code","476ceade":"code","beac1c0d":"code","52a433d0":"code","5e84b0be":"code","f614e99c":"code","429c938e":"code","92f46fea":"code","43957e6d":"markdown","2beb4918":"markdown","4b6eb328":"markdown","75922826":"markdown","ecac9f4c":"markdown"},"source":{"49aa7ea6":"import numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier,XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.cluster import KMeans","a6827672":"df = pd.read_csv(\"\/kaggle\/input\/california-housing-prices\/housing.csv\")\ndf.head()","b31ea624":"#shape of the data\ndf.shape","8168ace5":"#checking the null values\ndf.isnull().sum()","1b9bfbb1":"#checking number of rows containing zero value\nfor i in df.columns:\n    print(\"The number of rows containing zero value for\",i,\"=\",(df[i] == 0).sum())","2b49a50b":"#chceking number of unique values in each feature\ndf.nunique()","2f6fdce3":"#to keep the default size for all the plotting\nplt.rcParams['figure.figsize']=(20,10)","687c9c7d":"#checking the colinearity between all features\nsns.heatmap(df.corr(),annot=True)","ddc67288":"#checking distribution of different feature\ndf.hist(bins=50)\nplt.show()","ec7321f7":"#Chceking the distribution of different feature with transformed data\npt=PowerTransformer()\npd.DataFrame(pt.fit_transform(df.iloc[:,:9])).hist(bins=50)\nplt.show()","53534825":"df.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",s=df[\"population\"]\/100)\nplt.show()","2f10d9b4":"population_densiy = df[[\"longitude\",\"latitude\"]]\n\nkm = KMeans(n_clusters=3,random_state=0)\nkm.fit(population_densiy)\n\ndf[\"cluster\"] = km.labels_\ndf[\"cluster\"] = df[\"cluster\"].astype(\"object\")\n\nplt.subplot(1,2,1)\nsns.boxplot(x=\"cluster\",y=\"median_house_value\", data = df)\nplt.subplot(1,2,2)\nsns.scatterplot(x=\"longitude\",y = \"latitude\", hue=\"cluster\", data = df)\n\nplt.show()","e871939e":"#Dropping the nan values\ndf = df.dropna()","f690c197":"df.isna().sum()","02b7a58d":"#One hot encoding\ndf = pd.get_dummies(df)","b715c879":"#creating new attribute so that we can have better model with better features\n\ndf[\"rooms_per_household\"] = df[\"total_rooms\"]\/df[\"households\"]\ndf[\"bedrooms_per_room\"] = df[\"total_bedrooms\"]\/df[\"total_rooms\"]\ndf[\"population_per_household\"] = df[\"population\"]\/df[\"households\"]","0041401d":"#Heatmap showing colinearity with new features\n\nsns.heatmap(df.corr(),annot=True)","5d79e0cc":"#dropping the features with high colearnity \ndf = df.drop([\"households\",\"total_bedrooms\",\"population\"],axis=1)","476ceade":"#train test split\nX = df.drop(\"median_house_value\",axis=1)\ny = df[\"median_house_value\"]\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.20)","beac1c0d":"#Linear Regression\n\npipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"py\",PolynomialFeatures(2)),\n(\"sc\",StandardScaler()),\n(\"lr\",LinearRegression()),\n))\n\npipe.fit(Xtrain,ytrain)\n\nprint(\"Train accuracy\" ,pipe.score(Xtrain,ytrain))\nprint(\"Test accuracy\" ,pipe.score(Xtest,ytest))\n\nLR_Trainscore = pipe.score(Xtrain,ytrain)\nLR_Testscore = pipe.score(Xtest,ytest)","52a433d0":"#Gradient Boosting Regressor without any hyperparameter tuning\n\npipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"py\",PolynomialFeatures(2)),\n(\"sc\",StandardScaler()),\n(\"gb\",GradientBoostingRegressor()),\n))\n\npipe.fit(Xtrain,ytrain)\nprint(\"Train accuracy\" ,pipe.score(Xtrain,ytrain))\nprint(\"Test accuracy\" ,pipe.score(Xtest,ytest))\n\nGB_WHT_Trainscore = pipe.score(Xtrain,ytrain)\nGB_WHT_Testscore = pipe.score(Xtest,ytest)","5e84b0be":"#Gradient Boosting Regressor with hyperparameter tuning\n\npipe = Pipeline((\n(\"py\",PolynomialFeatures(2)),\n(\"sc\",StandardScaler()),\n(\"gb\",GradientBoostingRegressor(learning_rate=0.1,n_estimators=300,min_samples_split=20, min_samples_leaf=10, max_depth=6)),\n))\n\npipe.fit(Xtrain,ytrain)\nprint(\"Train accuracy\" ,pipe.score(Xtrain,ytrain))\nprint(\"Test accuracy\" ,pipe.score(Xtest,ytest))\n\nGB_HT_Trainscore = pipe.score(Xtrain,ytrain)\nGB_HT_Testscore = pipe.score(Xtest,ytest)","f614e99c":"pipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"py\",PolynomialFeatures(2)),\n(\"sc\",StandardScaler()),\n(\"xgb\",XGBRegressor()),\n))\n\npipe.fit(Xtrain,ytrain)\nprint(\"Train accuracy\" ,pipe.score(Xtrain,ytrain))\nprint(\"Test accuracy\" ,pipe.score(Xtest,ytest))\n\nXGB_Trainscore = pipe.score(Xtrain,ytrain)\nXGB_Testscore = pipe.score(Xtest,ytest)","429c938e":"score_comparision = pd.DataFrame([[LR_Trainscore,GB_WHT_Trainscore,GB_HT_Trainscore,XGB_Trainscore,],\n                                 [LR_Testscore,GB_WHT_Testscore,GB_HT_Testscore,XGB_Testscore]],\n                                 columns = [\"Linear Regression\",\n                                            \"Gradient Boosting without Hyper Tuning\",\n                                            \"Gradient Boosting with Hyper Tuning\",\n                                            \"XGB\"])\nscore_comparision.index.names = ['score']\nscore_comparision.index = [\"Train\", \"Test\"]\nscore_comparision = score_comparision.T\n\nscore_comparision.head()","92f46fea":"plt.figure(figsize=(20,5))\n\nplt.plot( 'Train', data=score_comparision, marker='o', markerfacecolor='black', markersize=8, color='skyblue', linewidth=2)\nplt.plot( 'Test', data=score_comparision, marker='o', markerfacecolor='black',markersize=8, color='orange', linewidth=2)\nplt.legend()","43957e6d":"## Model Building","2beb4918":"## Exploratory Data Analysis","4b6eb328":"## Splitting of the data","75922826":"## Importing Library","ecac9f4c":"## Reading Data"}}