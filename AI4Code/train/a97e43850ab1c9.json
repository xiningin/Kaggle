{"cell_type":{"cea89653":"code","387bdb5c":"code","93b94785":"code","c40b4ad8":"code","ef382b21":"code","c2068690":"code","d7c1ae4c":"code","95f5188a":"code","bbeb8d75":"code","3eb524c5":"code","e1f5d575":"code","9f913d1a":"code","c09c4c76":"code","033b8c90":"code","615a6808":"code","aa7a687b":"code","22af36a4":"code","ca419b2a":"code","b0be36b0":"code","d98e1d5e":"code","9c861601":"code","908bcba9":"code","71a83375":"code","c1cfcd33":"code","8a8a9e5a":"code","c28c2777":"code","f0cad3c0":"code","bc1fd475":"code","97323463":"code","c8455713":"code","c889b006":"code","3aa10bbd":"code","207f85f7":"code","07cbb068":"code","fe1f65f0":"code","cb6fabe1":"code","efa1dbf2":"code","732515a4":"code","9b00a54f":"code","ba8bba2b":"markdown","09ca5c60":"markdown","ec7c396a":"markdown","6d8c8c40":"markdown","610a54df":"markdown","d2c9a843":"markdown","a6c5f38f":"markdown","5c2b88c0":"markdown","07364390":"markdown"},"source":{"cea89653":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nfrom scipy import stats\n\nimport os, sys, datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\n\nfrom catboost import CatBoostClassifier\nimport category_encoders as ce","387bdb5c":"Kaggle = True\n\nif Kaggle:\n    DIR = '..\/input\/data-science-bowl-2019'\n    task_type = 'CPU'\nelse:\n    DIR = '.\/data-science-bowl-2019'\n    task_type = 'GPU'","93b94785":"train = pd.read_csv(os.path.join(DIR,'train.csv'))\ntrain_labels = pd.read_csv(os.path.join(DIR,'train_labels.csv'))\nspecs = pd.read_csv(os.path.join(DIR,'specs.csv'))\ntest = pd.read_csv(os.path.join(DIR,'test.csv'))","c40b4ad8":"print('train:\\t\\t',train.shape)\nprint('train_labels:\\t',train_labels.shape)\nprint('specs:\\t\\t',specs.shape)\nprint('test:\\t\\t',test.shape)","ef382b21":"train.head()","c2068690":"train[['event_id','game_session','installation_id',\n       'title','type','world']].describe()","d7c1ae4c":"event_code_n = train['event_code'].nunique()\nprint(\"num of unique 'event_code':\", event_code_n)\nprint(\"'event_code': \",\n      train['event_code'].min(), \"-\", train['event_code'].max())","95f5188a":"# 'event_data' exsample\nprint(train['event_data'][40])\nprint(train['event_data'][41])\nprint(train['event_data'][43])","bbeb8d75":"train_labels.head()","3eb524c5":"train_labels[['game_session','installation_id', 'title']].describe()","e1f5d575":"# unique 'title' list\ntrain_labels['title'].unique()","9f913d1a":"specs.head()","c09c4c76":"specs.describe()","033b8c90":"# 'info' exsample\nprint(specs['info'][0])\nprint(specs['info'][6])\nprint(specs['info'][7])","615a6808":"# 'args' exsample\nprint(specs['args'][0])\nprint(specs['args'][1])","aa7a687b":"test.head(8)","22af36a4":"test[['event_id','game_session','installation_id',\n       'title','type','world']].describe()","ca419b2a":"# make 'title' and 'event_code' list\ntitle_list = list(set(train['title'].value_counts().index) \\\n                   .union(set(test['title'].value_counts().index)))\nevent_code_list = list(set(train['event_code'].value_counts().index) \\\n                   .union(set(test['event_code'].value_counts().index)))","b0be36b0":"# makes dict 'title to number(integer)'\ntitle2num = dict(zip(title_list, np.arange(len(title_list))))\n# makes dict 'number to title'\nnum2title = dict(zip(np.arange(len(title_list)), title_list))\n# makes dict 'title to win event_code' \n# (4100 except 'Bird Measurer' and 4110 for 'Bird Measurer'))\ntitle2win_code = dict(zip(title2num.values() \\\n                    ,(np.ones(len(title2num))).astype('int') * 4100))\ntitle2win_code[title2num['Bird Measurer (Assessment)']] = 4110","d98e1d5e":"# Convert 'title' to the number\ntrain['title'] = train['title'].map(title2num)\ntest['title'] = test['title'].map(title2num)\ntrain_labels['title'] = train_labels['title'].map(title2num)\n\n# Convert 'timestamp' to datetime\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","9c861601":"# Convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    user_sample : DataFrame from train\/test group by 'installation_id'\n    test_set    : related with the labels processing\n    '''\n    # Constants and parameters declaration\n    user_assessments = []\n    last_type = 0\n    types_count = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    time_spent_each_title = {title:0 for title in title_list}\n    event_code_count = {code:0 for code in event_code_list}\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    \n    accumu_accuracy_group = 0\n    accumu_accuracy=0\n    accumu_win_n = 0 \n    accumu_loss_n = 0 \n    accumu_actions = 0\n    counter = 0\n    durations = []\n    \n    # group by 'game_session'\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i      : game_session_id\n        # session: DataFrame from user_sample group by 'game_session'\n        session_type = session['type'].iloc[0]  # Game\/Assessment\/Activity\/Clip\n        session_title = session['title'].iloc[0]\n        \n        if session_type != 'Assessment':\n            time_spent = int(session['game_time'].iloc[-1] \/ 1000)   # [sec]\n            time_spent_each_title[num2title[session_title]] += time_spent\n        \n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100(4110)\n            all_4100 = session.query(f'event_code == \\\n                                         {title2win_code[session_title]}')\n            # numbers of wins and losses\n            win_n = all_4100['event_data'].str.contains('true').sum()\n            loss_n = all_4100['event_data'].str.contains('false').sum()\n\n            # init features and then update\n            features = types_count.copy()\n            features.update(time_spent_each_title.copy())\n            features.update(event_code_count.copy())\n            features['session_title'] = session_title\n            features['accumu_win_n'] = accumu_win_n\n            features['accumu_loss_n'] = accumu_loss_n\n            accumu_win_n += win_n\n            accumu_loss_n += loss_n\n            \n            features['day_of_the_week'] = (session['timestamp'].iloc[-1]). \\\n                                            strftime('%A')    # Mod 2019-11-17\n\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n\n            # average of the all accuracy of this player\n            features['accuracy_ave'] = accumu_accuracy \/ counter \\\n                                                if counter > 0 else 0\n            accuracy = win_n \/ (win_n + loss_n) \\\n                                   if (win_n + loss_n) > 0 else 0\n            accumu_accuracy += accuracy\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # average of accuracy_groups of this player\n            features['accuracy_group_ave'] = \\\n                    accumu_accuracy_group \/ counter if counter > 0 else 0\n            accumu_accuracy_group += features['accuracy_group']\n            \n            # how many actions the player has done in this game_session\n            features['accumu_actions'] = accumu_actions\n            \n            # if test_set, all sessions belong to the final dataset\n            # elif train, needs to be passed throught this clausule\n            if test_set or (win_n + loss_n) > 0:\n                user_assessments.append(features)\n                \n            counter += 1\n        \n        # how many actions was made in each event_code\n        event_codes = Counter(session['event_code'])\n        for key in event_codes.keys():\n            event_code_count[key] += event_codes[key]\n\n        # how many actions the player has done\n        accumu_actions += len(session)\n        if last_type != session_type:\n            types_count[session_type] += 1\n            last_type = session_type\n            \n    # if test_set, only the last assessment must be predicted,\n    # the previous are scraped\n    if test_set:\n        return user_assessments[-1]\n    return user_assessments","908bcba9":"# get_data function is applyed to each installation_id\ncompiled_data = []\ninstallation_n = train['installation_id'].nunique()\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby( \\\n                                     'installation_id', sort=False)),\n                                     total=installation_n):\n    # user_sample : DataFrame group by 'installation_id'\n    compiled_data += get_data(user_sample)","71a83375":"# the compiled_data is converted to DataFrame and deleted to save memmory\nnew_train = pd.DataFrame(compiled_data)\ndel compiled_data","c1cfcd33":"new_train.head(10)","8a8a9e5a":"# process test set, the same that was done with the train set\nnew_test = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id',sort=False),\n                                total=1000):\n    new_test.append(get_data(user_sample, test_set=True))\n    \nnew_test = pd.DataFrame(new_test)","c28c2777":"new_test.head(10)","f0cad3c0":"# all_features but 'accuracy_group', that is the label y\nall_features = [x for x in new_train.columns if x not in ['accuracy_group']]\n# categorical feature\ncategorical_features = ['session_title','day_of_the_week']","bc1fd475":"# Encode categorical_features to integer(for use with LightGB,XGBoost,etc)\n\n# concatnate train and test data\ntemp_df = pd.concat([new_train[all_features], new_test[all_features]])\n# encode\nencoder = ce.ordinal.OrdinalEncoder(cols = categorical_features)\ntemp_df = encoder.fit_transform(temp_df)\n# dataset\nX, y = temp_df.iloc[:len(new_train),:], new_train['accuracy_group']\nX_test = temp_df.iloc[len(new_train):,:]","97323463":"X.head()","c8455713":"y.head()","c889b006":"X_test.head()","3aa10bbd":"# makes the model and set the parameters\ndef make_classifier():\n    model = CatBoostClassifier(\n        loss_function='MultiClass',\n        eval_metric=\"WKappa\",\n        task_type=task_type,\n        thread_count=-1,\n        od_type=\"Iter\",\n        early_stopping_rounds=500,\n        random_seed=42,\n        \n        border_count=110,\n        l2_leaf_reg=7,\n        iterations=1800,\n        learning_rate=0.2,\n        depth=5\n    )\n    return model","207f85f7":"# Train and make 5 models\nstart_time = time()\n\nNFOLDS = 5\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\nmodels = []\nscores = []\nfor fold, (train_ids, test_ids) in enumerate(folds.split(X, y)):\n    print('\u25cf Fold :', fold+1)\n    model = make_classifier()\n    model.fit(X.loc[train_ids, all_features], y.loc[train_ids], \n              eval_set=(X.loc[test_ids, all_features], y.loc[test_ids]),\n              use_best_model=False,     # The meaning of this parameter does not fall into the trap\n              verbose=500,\n              cat_features=categorical_features)    \n    models.append(model)\n    scores.append(model.get_best_score()['validation']['WKappa'])\n    print('\\n')\n    \nprint('-' * 50)\nprint(\"Average 'WKappa' Score =\", np.mean(scores))\nprint('-' * 50)\nprint('finished in {}'.format( \n    str(datetime.timedelta(seconds=time() - start_time))))","07cbb068":"# Check the effect of 'voting'\npredictions = []\nfor model in models:\n    predictions.append(model.predict(X).astype(int))\npredictions = np.concatenate(predictions, axis=1)\ndf = pd.DataFrame(predictions)\n\nvote = stats.mode(predictions, axis=1)[0].reshape(-1)\ndf['vote'] = vote\ndf['y'] = y\ndf.head(10)","fe1f65f0":"kappa_score = []\nfor col in df.columns[:NFOLDS+1]:\n    kappa_score.append(cohen_kappa_score(df['y'], df[col]))\nprint('kappa_score:\\n',kappa_score)\nprint('average score:',np.mean(kappa_score[:NFOLDS]))\nprint('voting score :',kappa_score[-1],'\\n')\nprint('Improved from',np.mean(kappa_score[:NFOLDS]),'to',\n      kappa_score[-1],\"by 'voting'\")","cb6fabe1":"predictions = []\nfor model in models:\n    predictions.append(model.predict(X_test))\npredictions = np.concatenate(predictions, axis=1)\n# Voting\npredictions = stats.mode(predictions, axis=1)[0].reshape(-1)\nprint(predictions.shape)","efa1dbf2":"submission = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\nsubmission['accuracy_group'] = np.round(predictions).astype('int')\nsubmission.head(10)","732515a4":"submission['accuracy_group'].plot(kind='hist')","9b00a54f":"submission.to_csv('submission.csv', index=None)","ba8bba2b":"### 3. specs","09ca5c60":"### 4. test","ec7c396a":"## CatBoost with Voting\n- Create several types of train_data with kFold, and then create a model for each dataset.\n- Estimate the final result by 'voting method' of the prediction result of each model.","6d8c8c40":"## Make submission","610a54df":"## Observe the data","d2c9a843":"### 1. train","a6c5f38f":"## Model (CatBoostClassifier)","5c2b88c0":"## Compile data\nBased on several kernels\n- Hosseinali: https:\/\/www.kaggle.com\/mhviraf\/a-new-baseline-for-dsb-2019-catboost-model\n- Bruno Aquino: https:\/\/www.kaggle.com\/braquino\/catboost-some-more-features","07364390":"### 2. train_labels"}}