{"cell_type":{"78fa323e":"code","29758cfd":"code","a315d4d7":"code","c6a2847e":"code","bbd9ff8c":"code","cf58e6f1":"code","208f45fd":"code","1e931052":"code","40a51ebe":"code","b26533f6":"code","eabc7171":"code","20e662c9":"code","ef05f772":"code","97650d68":"code","e435ebfa":"code","655c2e52":"code","af662e9e":"code","aa7d0f13":"code","28477fd6":"code","59651567":"code","03b9cf19":"code","d465f317":"code","64881b9c":"code","1d471f7b":"code","f4500ce0":"code","07d071de":"code","2a02014f":"code","1146877b":"code","b8bce4f3":"code","a8dad6ab":"code","072a79c0":"code","6a49938a":"code","813f35ec":"code","1d292c71":"code","5fff1ced":"code","29f96139":"markdown","7828371b":"markdown","c9b7e720":"markdown","a90864ee":"markdown","fdf680a3":"markdown","aa34b3d6":"markdown","2b330f32":"markdown","7b4f3ceb":"markdown","0fffb22c":"markdown","7983118d":"markdown","73ba8467":"markdown","8ddc11a5":"markdown","94b8c1f1":"markdown","356168db":"markdown","8cf10cbb":"markdown","bc2b7e8d":"markdown","1c977011":"markdown","c2e0eefc":"markdown","0774f65c":"markdown","66c3f0d1":"markdown","e06ab408":"markdown","00ac468a":"markdown","2453bb5c":"markdown","92b9ffbb":"markdown","095f7490":"markdown"},"source":{"78fa323e":"#Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score,roc_auc_score,plot_confusion_matrix\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_validate\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","29758cfd":"# Loading Dataset\n\ndf = pd.read_csv(r\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndf.head(10)","a315d4d7":"#Data shape and column names.\n\nprint(\n    f'Dataset has {df.shape[1]} features, {df.shape[0]} observations.\\nDataset features are:\\n{df.columns.tolist()}\\n'\n)","c6a2847e":"df.info()","bbd9ff8c":"#Information about numerical features.\n\ndf.describe()","cf58e6f1":"#Checking missing values.\n\ndf.isnull().sum()\n","208f45fd":"#Unique values in each columns.\n\ndf.nunique()\n","1e931052":"df[\"gender\"].value_counts()","40a51ebe":"# Replacing other value with female\ndf[\"gender\"] = df[\"gender\"].replace(['Other'],'Female')\n","b26533f6":"#Filling missing values with mean of BMI\n\ndf['bmi'].fillna(int(df['bmi'].mean()), inplace=True)","eabc7171":"df[\"work_type\"].value_counts()\n","20e662c9":"df[df[\"work_type\"] == \"Never_worked\"]","ef05f772":"# Replacing never_worked value with children\ndf[\"work_type\"] = df[\"work_type\"].replace(['Never_worked'],'children')","97650d68":"categorical = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\",\"stroke\"]\nnumerical = [\"age\",\"avg_glucose_level\",\"bmi\"]","e435ebfa":"\nplt.figure(figsize=(15,30))\nfor i in enumerate(categorical):\n    plt.subplot(4,2,i[0]+1)\n    sns.countplot(x = i[1],\n                  data = df ,\n                  order = df[i[1]].value_counts().index,\n                  palette=\"muted\")\n    \n    plt.title(i[1] +' distribution')\n    \n    ","655c2e52":"f, axes = plt.subplots(3, 2, figsize=(14,8))\nsns.histplot( x=df.age , ax=axes[0,0])\naxes[0,0].set_title(\"Age Distribution\")\nsns.boxplot( x=df.age , ax=axes[0,1])\naxes[0,1].set_title(\"Boxplot of Age\")\nsns.histplot(x=df.avg_glucose_level , ax=axes[1,0])\naxes[1,0].set_title(\"Average Glucose Level Distribution\")\nsns.boxplot(x=df.avg_glucose_level, ax= axes[1,1])\naxes[1,1].set_title(\"Boxplot of Average Glucose Level\")\nsns.histplot(x=df.bmi,ax=axes[2,0])\naxes[2,0].set_title(\"BMI Distribution\")\nsns.boxplot(x=df.bmi, ax = axes[2,1])\naxes[2,1].set_title(\"Boxplot of BMI\")\nplt.tight_layout()","af662e9e":"\nplt.figure(figsize=(15,30))\n\nfor i in enumerate(categorical[:-1]):\n    plt.subplot(4,2,i[0]+1)\n    sns.countplot(x = i[1],\n                  data = df ,\n                  hue = \"stroke\",\n                  order = df[i[1]].value_counts().index,\n                  palette=\"muted\")\n    \n    plt.title(i[1] +' distribution')\n    \n   ","aa7d0f13":"def drop_outliers(df, field_name):\n    iqr = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n    df.drop(df[df[field_name] > (iqr + np.percentile(df[field_name], 75))].index, inplace=True)\n    df.drop(df[df[field_name] < (np.percentile(df[field_name], 25) - iqr)].index, inplace=True)","28477fd6":"drop_outliers(df,\"avg_glucose_level\")","59651567":"drop_outliers(df,\"bmi\")","03b9cf19":"df['gender'] = df['gender'].replace({'Male':1,'Female':0})\n\ndf['Residence_type'] = df['Residence_type'].replace({'Rural':0,'Urban':1})\n\ndf['work_type'] = df['work_type'].replace({'Private':0,'Self-employed':1,'Govt_job':2,'children':3})\n\ndf['ever_married'] = df['ever_married'].replace({'Yes':1,'No':0})\n\ndf['Residence_type'] = df['Residence_type'].replace({'Urban':1,'Rural':0})\n\ndf['smoking_status'] = df['smoking_status'].replace({'never smoked':0,'Unknown':1,'formerly smoked':2,'smokes':3})","d465f317":"df.drop(\"id\",axis=1,inplace=True)","64881b9c":"df[\"stroke\"].value_counts()","1d471f7b":"X = df.drop('stroke', axis=1)\ny = df['stroke']","f4500ce0":"from imblearn.over_sampling import SMOTE\n","07d071de":"oversample = SMOTE()\nX_os, y_os = oversample.fit_resample(X, y.ravel())\n","2a02014f":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_os[numerical] = scaler.fit_transform(X_os[numerical])","1146877b":"cv = KFold(10, shuffle=True,random_state=42)","b8bce4f3":"LReg = cross_validate(\n            LogisticRegression(),\n            X_os,\n            y_os,\n            cv=cv,\n            scoring=('accuracy','f1','roc_auc'),\n            return_train_score=True\n            )","a8dad6ab":"DTC = cross_validate(\n            DecisionTreeClassifier(),\n            X_os,\n            y_os,\n            cv=cv,\n            scoring=('accuracy','f1','roc_auc'),\n            return_train_score=True\n            )","072a79c0":"RFC = cross_validate(\n            RandomForestClassifier(),\n            X_os,\n            y_os,\n            cv=cv,\n            scoring=('accuracy','f1','roc_auc'),\n            return_train_score=True\n            )","6a49938a":"SVC = cross_validate(\n            SVC(),\n            X_os,\n            y_os,\n            cv=cv,\n            scoring=('accuracy','f1','roc_auc'),\n            return_train_score=True\n            )","813f35ec":"XGB = cross_validate(\n            XGBClassifier(use_label_encoder =False),\n            X_os,\n            y_os,\n            cv=cv,\n            scoring=('accuracy','f1','roc_auc'),\n            return_train_score=True\n            )","1d292c71":"modelstats =  {'Model':['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier', 'SVC','XGB Classifier'],\n        'Train Accuracy Mean': [LReg['train_accuracy'].mean(),DTC['train_accuracy'].mean(),RFC['train_accuracy'].mean(),SVC['train_accuracy'].mean(),XGB['train_accuracy'].mean()],\n        'Test Accuracy Mean':[LReg['test_accuracy'].mean(),DTC['test_accuracy'].mean(),RFC['test_accuracy'].mean(),SVC['test_accuracy'].mean(),XGB['test_accuracy'].mean()],\n        'Train f1':[LReg['train_f1'].mean(),DTC['train_f1'].mean(),RFC['train_f1'].mean(),SVC['train_f1'].mean(),XGB['train_f1'].mean()],\n        'Test f1' :[LReg['test_f1'].mean(),DTC['test_f1'].mean(),RFC['test_f1'].mean(),SVC['test_f1'].mean(),XGB['test_f1'].mean()],\n        'Train ROC-AUC':[LReg['train_roc_auc'].mean(),DTC['train_roc_auc'].mean(),RFC['train_roc_auc'].mean(),SVC['train_roc_auc'].mean(),XGB['train_roc_auc'].mean()],\n        'Test ROC-AUC':[LReg['test_roc_auc'].mean(),DTC['test_roc_auc'].mean(),RFC['test_roc_auc'].mean(),SVC['test_roc_auc'].mean(),XGB['test_roc_auc'].mean()]      \n     }  ","5fff1ced":"modeltable = pd.DataFrame(modelstats) \nmodeltable","29f96139":"* Hard to interpret the graphs because of imbalanced dataset.","7828371b":"Thank you for checking my work. I' m  trying to learn .Thanks for all the recommendations. Have a wonderful day.","c9b7e720":"<a id='id'><\/a>\n# <p style=\"background-color:white; font-family:newtimeroman; font-size:100%; text-align:center; border-radius: 10px 35px;\">Feature Distributions \ud83d\udcca <\/p>","a90864ee":"Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).","fdf680a3":"**We can see that, there are many outliers in column of Average Glucose Level and BMI. We have to deal with them in modelling phase.**","aa34b3d6":"  Decision Tree algorithm belongs to the family of supervised learning algorithms. Unlike other supervised learning algorithms, the decision tree algorithm can be used for solving regression and classification problems too.","2b330f32":"**By looking age column we can add this to children.**","7b4f3ceb":" A stroke is a medical condition in which poor blood flow to the brain causes cell death. There are two main types of stroke: ischemic, due to lack of blood flow, and hemorrhagic, due to bleeding. Both cause parts of the brain to stop functioning properly.","0fffb22c":"**We remove the outliers in columns of avg_glucose_level and bmi**","7983118d":"* Decision tree based models overfitted.\n\n* I should try hyperparameter tuning for models.\n\n","73ba8467":"<a id='id'><\/a>\n# <p style=\"background-color:white; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 10px 35px;\">Modelling \ud83d\udccf<\/p>","8ddc11a5":"Support-vector machines are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.\n","94b8c1f1":"* We have 3 values for gender. We 'll replace Other value with the value with most repetative one which is female.","356168db":"<a id='begin'><\/a>\n# <p style=\"background-color:white; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\"> Stroke Prediction \ud83d\udc8a <\/p>","8cf10cbb":" The main risk factor for stroke is **high blood pressure.** Other risk factors include **tobacco smoking**, **obesity**, **high blood cholesterol**, **diabetes mellitus**, **a previous TIA**, **end-stage kidney disease**, **and atrial fibrillation**.","bc2b7e8d":"* Dataset contains more female.\n* Residence type distribution is balanced.\n* Target feature is stroke which is imbalanced.\n","1c977011":"XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) ","c2e0eefc":"<a id='id'><\/a>\n# <p style=\"background-color:white; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 10px 35px;\">Feature Engineering \u2702\ufe0f<\/p>","0774f65c":"<a id='loaddata'><\/a>\n# <p style=\"background-color:white; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">Loading data \ud83d\udcc2 <\/p>","66c3f0d1":"**We have 201 missing value in BMI column.  We have to fill the missing values.**","e06ab408":"![image.png](attachment:image.png)","00ac468a":"**SMOTE (Synthetic Minority Oversampling Technique) \u2013 Oversampling**\n\nSMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem.\nIt aims to balance class distribution by randomly increasing minority class examples by replicating them.","2453bb5c":"<a id='begin'><\/a>\n# <p style=\"background-color:white; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\"> Explotorary Data Analysis \ud83d\udcc8 <\/p>","92b9ffbb":"**Lets check the people who never worked**","095f7490":"Random forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance."}}