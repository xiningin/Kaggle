{"cell_type":{"57b19641":"code","56de9a2b":"code","42a03261":"code","842bf892":"code","95574157":"code","1c074b04":"code","706f9840":"code","de47523b":"code","826b5d94":"code","a5280fee":"code","1de04bc3":"code","8aba9564":"code","2738d535":"code","0d2950ae":"code","b20a18a2":"code","08f26f2d":"code","8e2685b1":"code","ea0c0e76":"code","80730217":"markdown","b58f3755":"markdown","44adb61c":"markdown","633e3f07":"markdown"},"source":{"57b19641":"# Load the extension and start TensorBoard\n\n%load_ext tensorboard\n%tensorboard --logdir logs","56de9a2b":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,Dataset\nfrom tqdm import tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter","42a03261":"class CNN(nn.Module):\n    def __init__(self, input_channels=1, num_size=10):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d( in_channels=in_channels, out_channels=8, kernel_size=(3,3), padding=(1,1), stride=(1,1))\n        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n        self.fc1 = nn.Linear(16 * 7 * 7, num_size)\n    \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc1(x)\n        return x","842bf892":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nin_channels =1\nnum_classes = 10\nnum_epochs = 3\nlearning_rate = 0.001\nbatch_size = 64","95574157":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf.head()","1c074b04":"df['label'].values","706f9840":" df.iloc[:,1:].values","de47523b":"class getTrainDataset(Dataset):\n    def __init__(self,csv_path='..\/input\/digit-recognizer\/train.csv'):\n        \n        df = pd.read_csv(csv_path)\n        \n        self.y = torch.from_numpy(df.iloc[:,0].values)\n        self.x = torch.from_numpy(df.iloc[:, 1:].values)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]","826b5d94":"train_dataset = getTrainDataset()","a5280fee":"x, y = train_dataset[100]\n\ny, x.shape","1de04bc3":"x = x.reshape(1, 28, 28)\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(x.permute(1,2,0))","8aba9564":"train_dataset.__len__()","2738d535":"train_dataloader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)","0d2950ae":"model = CNN().to(device=device)","b20a18a2":"optimizer = optim.Adam(model.parameters(), lr=learning_rate)\nloss_criterion = nn.CrossEntropyLoss()\n\nwriter = SummaryWriter(f'runs\/MNIST\/trying_out_tensorboard')\n","08f26f2d":"step = 0\nfor epoch in range(num_epochs):\n    total_correct = 0\n    for data, target in tqdm(train_dataloader):\n        data = data.reshape(data.shape[0],1,28,28).float()\n        target = target.long()\n        data = data.to(device=device)\n        target = target.to(device=device)\n        \n        scores = model(data)\n        loss = loss_criterion(scores, target)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        _, predictions = scores.max(1)\n        total_correct += (target==predictions).sum()\n        accuracy = float(total_correct\/target.shape[0])\n        \n        writer.add_scalar('training loss', loss, global_step=step)\n        writer.add_scalar('training accuracy',accuracy, global_step=step )\n        step += 1","8e2685b1":"def check_accuracy(model, loader):\n    \n    model.eval()\n    \n    total_correct = 0\n    total_cases = 0\n    \n    for x,y in tqdm(loader):\n        x = x.reshape(x.shape[0],1,28,28).float()\n        y = y.long()\n        x = x.to(device=device)\n        y = y.to(device=device)\n        \n        scores = model(x)\n        \n        _, predictions = scores.max(1)\n        total_correct += (y==predictions).sum()\n        total_cases += y.shape[0]\n        \n    model.train()\n    \n    print(f\"total correct: {total_correct} out of {total_cases} with an accuracy of {float(total_correct\/total_cases)}\")","ea0c0e76":"check_accuracy(model, train_dataloader)","80730217":"### Imports","b58f3755":"### Hyperparameters","44adb61c":"### Getting the dataset","633e3f07":"### Defining the model"}}