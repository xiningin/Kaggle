{"cell_type":{"a81e9a25":"code","7d0c1cf6":"code","c8095233":"code","615c82d5":"code","1840bee0":"code","9347f526":"code","5bc63aa9":"code","0173edd3":"code","9c74e074":"code","d481d8e7":"code","cdf19be5":"code","21488fee":"code","82b92029":"code","da83c0aa":"code","18a038b0":"code","55bf8694":"code","057571ba":"code","d8c7d677":"code","f48b76da":"code","98f0d31b":"code","be64a7d2":"code","ad0e57d5":"code","4343f7fc":"code","87566299":"markdown","d2edbd1e":"markdown","deb0c109":"markdown","4c06e8b3":"markdown","f5b4f540":"markdown","48bd0dfd":"markdown","622ae63a":"markdown","2ab71f39":"markdown"},"source":{"a81e9a25":"#setting up sparknlp \n!wget http:\/\/setup.johnsnowlabs.com\/kaggle.sh -O - | bash","7d0c1cf6":"#Importing Useful Packages\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score\n\nimport sparknlp\nfrom sparknlp.annotator import *\nfrom sparknlp.base import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import col\nfrom pyspark.ml import Pipeline\nfrom sparknlp.pretrained import PretrainedPipeline","c8095233":"#Starting Sparknlp\nspark= sparknlp.start()","615c82d5":"print(\"SparkNLP version: {}\".format(sparknlp.version()))\nprint(\"Pyspark version: {}\".format(spark.version))","1840bee0":"# Loading train and test datasets\ndf_train= spark.read\\\n    .option(\"header\", True)\\\n    .csv(\"..\/input\/nlp-getting-started\/train.csv\")\ndf_test= spark.read\\\n    .option(\"header\", True)\\\n    .csv(\"..\/input\/nlp-getting-started\/test.csv\")\nsubmission= spark.read\\\n        .option(\"header\", True)\\\n        .csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")","9347f526":"df_train.show(5, truncate=False)  ","5bc63aa9":"df_train.groupby(\"target\")\\\n    .count()\\\n    .orderBy(col(\"count\")).show()","0173edd3":"drop_col= [\"keyword\", \"location\"]\ndf_train= df_train.drop(*drop_col)\ndf_train.show()","9c74e074":"#Dropping the values which is null in the target column.\ndf_train= df_train.na.drop(how=\"any\")\ndf_train.groupby(\"target\")\\\n    .count()\\\n    .orderBy(col(\"count\")).show()","d481d8e7":"document = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nuse = UniversalSentenceEncoder.pretrained()\\\n .setInputCols([\"document\"])\\\n .setOutputCol(\"sentence_embeddings\")\n\nclasssifierdl = ClassifierDLApproach()\\\n    .setInputCols([\"sentence_embeddings\"])\\\n    .setOutputCol(\"class\")\\\n    .setLabelColumn(\"target\")\\\n    .setMaxEpochs(10)\\\n    .setEnableOutputLogs(True)\\\n    .setLr(0.004)\\\n\nnlpPipeline = Pipeline(\n    stages = [\n        document,\n        use,\n        classsifierdl\n    ])","cdf19be5":"#splitting the data into train set and test set\n(train_set, test_set)= df_train.randomSplit([0.8, 0.2], seed=100)\nprint(\"Train set shape: {}\".format((train_set.count(), len(train_set.columns))))\nprint(\"Test set shape: {}\".format((test_set.count(), len(test_set.columns))))","21488fee":"#fitting with train_set\nuse_model = nlpPipeline.fit(train_set)","82b92029":"!cd ~\/annotator_logs && ls -l","da83c0aa":"!cat ~\/annotator_logs\/ClassifierDLApproach_e0b7218e9b57.log","18a038b0":"preds= use_model.transform(test_set)\npreds.select(\"target\", \"text\", \"class.result\").show(5, truncate=False)","55bf8694":"df= use_model.transform(test_set).select(\"target\", \"document\", \"class.result\").toPandas()\ndf[\"result\"]= df[\"result\"].apply(lambda x: x[0])\nprint(classification_report(df[\"target\"], df[\"result\"]))\nprint(accuracy_score(df[\"target\"], df[\"result\"]))","057571ba":"df_test.show(5, truncate=False)  #this is the test data","d8c7d677":"submission.show(5, truncate=False) #this is the submission format","f48b76da":"preds= use_model.transform(df_test)\npreds.select(\"id\",\"text\", \"class.result\").show(5, truncate=False)","98f0d31b":"final = use_model.transform(df_test).select(\"id\", \"class.result\")","be64a7d2":"# This is the final step\nfinal= final.withColumnRenamed(\"result\" ,\"target\")\nfinal.show(5)","ad0e57d5":"final= final.toPandas()","4343f7fc":"final.to_csv(index=False, path_or_buf=\"final_submission.csv\")","87566299":"**id:** This column consist ids per each tweets <br\/>\n**keyword:** A keyword from that tweet (although this may be blank) <br\/>\n**location:** The location the tweet was sent from (may also be blank) <br\/>\n**text:** The text of a tweet <br\/>\n**target:** In train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0) <br\/>","d2edbd1e":"For check the result of our model:","deb0c109":"Now, there aren't any null values. <br\/>\nFirstly I will apply SparkNLP DocumentAssembler. DocumentAssembler is a entry point to SparkNLP pipeline. <br\/>\nAfter thar, I will apply Universal Sentence Encoder and then create ClassifierDL. <br\/>\nFinally I will put into the pipeline and fit with the train_set.","4c06e8b3":"When we fit pipeline, Spark NLP will write the training logs to \"annotator_logs\" folder in our home directory. <br\/>\nHere is how you can read the logs:","f5b4f540":"We achieved %88 accuracy score on train_set. <br\/>\nLet's check the model with test_set by using sklearn metrics.","48bd0dfd":"We achieved %80 accuracy score on test_set as well. <\/br>\n####  Applying the model on the test.csv data for submission.","622ae63a":"# Disaster Tweets Classification By Using SparkNLP\nIn this project, I built a classification model that predicts which Tweets are about real disasters and which one\u2019s aren\u2019t by using Universal Sentence Encoder. <br\/>\nI have accessed to a dataset that contains 10,000 tweets. ","2ab71f39":"Data include some null values. I will drop them. Also, firstly I will drop keyword and location columns."}}