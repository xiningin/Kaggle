{"cell_type":{"daa87b62":"code","773e604e":"code","28b18875":"code","b5c7fcf6":"code","0d39a133":"code","77264a42":"code","3c14ddb6":"code","4fd60ba5":"code","bf721ddd":"code","f8c678cf":"code","00c9bed6":"code","62501dec":"code","d5ac4a03":"code","dbb86424":"code","da34c969":"code","44a78e32":"code","ac424ced":"code","d731a99d":"code","3a208ba0":"code","45605e70":"code","577cf71e":"code","83b26be5":"code","d95ccec3":"code","ff567300":"markdown","d7cbd60e":"markdown","d23029fe":"markdown","bd2fd128":"markdown","a8fa6f0d":"markdown","2ca77df7":"markdown","9c372c66":"markdown","ab589a97":"markdown","d7fc621d":"markdown","8c3bd0bf":"markdown"},"source":{"daa87b62":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport collections\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","773e604e":"#Import the data as a dataframe\ndf = pd.read_csv('\/kaggle\/input\/wuzzuf-jobs\/Wuzzuf_Jobs.csv')\n\n# Take a look at the data\ndf","28b18875":"# Check data types and missing values\ndf.info()","b5c7fcf6":"# Checking for null values\ndf.isnull().any().sum()","0d39a133":"# Checking for duplicates\ndf.duplicated().sum()","77264a42":"#Check country column\ndf.Country.value_counts()","3c14ddb6":"#Further checking\ndf[df.Country == 'Egypt'].Location.value_counts()","4fd60ba5":"#Check location column\ndf.Location.value_counts()","bf721ddd":"#Check company column\ndf.Company.value_counts()","f8c678cf":"#Check title column\ndf.Title.value_counts()","00c9bed6":"# Create a copy to preserve data\ndf_clean = df.copy()","62501dec":"# Delete duplicates\ndf_clean.drop_duplicates(inplace=True)\n# Test\ndf_clean.duplicated().sum()","d5ac4a03":"# Replace Egypt with corresponding city values\ndf_clean.Country.mask(df_clean.Country == 'Egypt', df_clean.Location, axis=0, inplace=True)\n#Eliminate excess spaces\ndf_clean.Country = df_clean.Country.str.replace(' ', '')","dbb86424":"#Drop countries that aren't Egypt\n\ncountries_list = ['SaudiArabia', 'UnitedArabEmirates', 'Oman', 'ElSalvador', 'Brazil',  'India', 'UnitedStates',\n                  'Qatar', 'Kuwait', 'Tunisia', 'China', 'Bahrain', 'Philippines', 'Austria', 'Pakistan',\n                  'Indonesia', 'Ukraine', 'SriLanka', 'Iraq']\n\nfor country in countries_list:\n    df_clean = df_clean.drop(df_clean[df_clean.Country == country].index)","da34c969":"#Rename the country column to city\ndf_clean.rename(columns = {'Country':'City', 'Location':'District'}, inplace = True)","44a78e32":"#Convert skills cells to a list of each skill\ndf_clean.Skills = df_clean.Skills.str.split(\",\")\n\n#Test\ndf_clean.head()","ac424ced":"#Create a dataframe counting needed skills\nlist_df=list(df['Skills'])\nmapdic={}\nlist_str =','.join(list_df).split(',')\nskills_counter = collections.Counter(list_str)\nskill_df = pd.DataFrame.from_dict(skills_counter, orient='index', columns=['skill_count'])\n#Sort values descendingly from the most important skills to the least important\nskill_df.sort_values(by='skill_count', ascending=False, inplace=True)\n\n#Test\nskill_df","d731a99d":"#Clean the title column from excess words\ndf_clean.Title = df_clean.Title.str.replace(r'[\\W][ \\W].*' , '')","3a208ba0":"# Pie plot of jobs types\nsorted_counts = df_clean.Type.value_counts()\nlabels = sorted_counts.index\n\nplt.figure(figsize=[14,14])\nplt.pie(sorted_counts, labels=labels, rotatelabels =True, startangle=170, radius=2,\n        counterclock=False, autopct='%1.00f%%', labeldistance=1.02)\nplt.axis('square')\nplt.title('Egyptian Wuzzuf Jobs Types 2020', pad=2, fontsize=15);","45605e70":"# Bar plot top 10 skills\nplt.figure(figsize=[15,6])\ntop_skills = skill_df.index[:10]\ncount = skill_df.skill_count.head(10)\n\nplt.barh(top_skills, count)\n\nplt.title('Top 10 Wanted Skills in Wuzzuf Egypt 2020', fontsize= 15)\nplt.xticks(fontsize= 11)\nplt.yticks(fontsize= 12)\nplt.xlabel('Number of Times the Skill Was Requested', fontsize=12);","577cf71e":"# Bar plot top 10 jobs\nplt.figure(figsize=[15,6])\ntop_jobs = df_clean.Title.value_counts().head(10).index\ncount = df_clean.Title.value_counts().head(10)\n\nplt.barh(top_jobs, count)\n\nplt.title('Top 10 Wuzzuf Jobs Needed in Egypt 2020', fontsize= 15)\nplt.xticks(fontsize= 11)\nplt.yticks(fontsize= 12)\nplt.xlabel('Number of Times the Job Was Requested', fontsize=12);","83b26be5":"# Bar plot top 10 districts\nplt.figure(figsize=[15,6])\ntop_districts = df_clean.District.value_counts().head(10).index\ncount = df_clean.District.value_counts().head(10)\n\nplt.barh(top_districts, count)\n\nplt.title('Top 10 Job Locations at Wuzzuf Egypt 2020', fontsize= 15)\nplt.xticks(fontsize= 11)\nplt.yticks(fontsize= 12)\nplt.xlabel('Number of Jobs in the Location', fontsize=12);","d95ccec3":"import matplotlib.gridspec as gridspec\n\ndef create_figure(plot1, plot2, plot3):\n    with plt.style.context((\"seaborn\",\"ggplot\")):\n        fig = plt.figure(constrained_layout=True, figsize=(10,15))\n        specs = gridspec.GridSpec(ncols=1, nrows=3, figure=fig) ## Declaring 2x2 figure.\n\n        ax1 = fig.add_subplot(specs[0, 0]) ## First Row\n        ax2 = fig.add_subplot(specs[1, 0]) ## Second Row First Column\n        ax3 = fig.add_subplot(specs[2, 0]) ## Second Row Second Colums\n\n        #1 Bar plot top 10 skills\n        top_skills = skill_df.index[:10]\n        count = skill_df.skill_count.head(10)\n        ax1.barh(top_skills, count, color='#421244')\n        ax1.set_title(plot1, fontsize= 15)\n        ax1.set_xlabel('Number of Times the Skill Was Requested', fontsize=12);\n\n        #2 Bar plot top 10 jobs\n        top_jobs = df_clean.Title.value_counts().head(10).index\n        count = df_clean.Title.value_counts().head(10)\n        ax2.barh(top_jobs, count, color='#446664')\n        ax2.set_title(plot2, fontsize= 15)\n        ax2.set_xlabel('Number of Times the Job Was Requested', fontsize=12);\n\n        #3 Bar plot top 10 districts\n        top_districts = df_clean.District.value_counts().head(10).index\n        count = df_clean.District.value_counts().head(10)\n        ax3.barh(top_districts, count, color='#448844')\n        ax3.set_title(plot3, fontsize= 15)\n        ax3.set_xlabel('Number of Jobs in the Location', fontsize=12);\n\n        plt.close(fig)\n        return fig\n\ncreate_figure('Top 10 Wanted Skills in Wuzzuf Egypt 2020', 'Top 10 Wuzzuf Jobs Needed in Egypt 2020', 'Top 10 Job Locations at Wuzzuf Egypt 2020')","ff567300":"<a id='conclusions'><\/a>\n## Conclusions\n\nThis dashboard includes the ***top 10 skills, job titles and job locations*** needed by employers on Wuzzuf in Egypt 2020.","d7cbd60e":"It shows that there're some inaccurate values such as *Maadi* listed as a skill while it's in fact a district. Changing these values isn't significant for the purposes of our analysis.","d23029fe":"# Wuzzuf Egypt Jobs Postings EDA\n## Fatimah Ehab Farouk\n\n\n## Contents\n\n<ul>\n<li><a href=\"#intro\">1. Introduction<\/a><\/li>\n<li><a href=\"#wrangling\">2. Data Wrangling<\/a><\/li>\n<li><a href=\"#eda\">3. Exploratory Data Analysis<\/a><\/li>\n<li><a href=\"#conclusions\">4. Conclusion<\/a><\/li>\n<\/ul>","bd2fd128":"So we need to delete duplicates.\n\nNow let's dive deeper into the data. I want to check these for a start:\n- All of these job postings are located in Egypt, so having Egypt as the value in the country column is meaningless. Having the country column itself is debatable.\n- Will keeping confidential companies be of benefit?\n- Clean these columns: `Title` and `Company`.\n\nAnd of course adding on more items to explore and clean goes on iteratively as we move forward.","a8fa6f0d":"### To-clean list:\n- Eliminate duplicates.\n- Replace the value *Egypt* in ` Country` column with its corresponding values from `Location` column.\n- Rename `Country` column to `City`.\n- Rename `Location` column to `District` so it makes more sense.\n- Wrangle `Skill` column so that each cell contains a list of the skills.\n- Clean unnecessary characters from the `Title` column.\n","2ca77df7":"<a id='wrangling'><\/a>\n\n## 2. Data Wrangling","9c372c66":"<a id='intro'><\/a>\n## 1. Introduction\n\nThis dataset includes 4380 Jobs with attributes such as Title, Company, Location, etc.\n\nThis is an exploratory data analysis project to discover hidden trends in the Egyptian job postings on Wuzzuf.","ab589a97":"<a id='eda'><\/a>\n## 2. Exploratory Data Analysis\n\nThis is the part where data visualization is done to explore data and discover insightful patterns in it.","d7fc621d":"So, there're a few postings outside of Egypt, so these need to be cleaned. And renaming the country column to **city** will make more sense, because it's all in Egypt anyway. And for that to be successfully done, we need to replace Egypt with the correct corresponding cities values in `Location` column.","8c3bd0bf":"This is excellent! Now let's summarize the most important discovered insights in the conclusions part."}}