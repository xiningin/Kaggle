{"cell_type":{"33dab860":"code","9b4ad492":"code","72198214":"code","9ed93d79":"code","162ce28c":"code","da92a3c8":"code","de8f0a0b":"code","2b435de5":"code","66fb0a6d":"code","1c253dd3":"code","eaaddfa0":"code","314c5e67":"code","2aa829fa":"code","166af345":"code","b7182de2":"code","aea6e316":"code","3dcfb417":"code","6242ae36":"code","c3981cd3":"code","585440d8":"code","6e18ce7e":"code","649dfa29":"code","875ef1fe":"code","b043bc10":"code","c1c3092c":"code","52973ba8":"code","416bd594":"code","4d3057a3":"code","5a5866de":"code","cfc8acc4":"code","23051cd5":"code","9a1df86a":"code","04f7a984":"code","9b10457c":"code","1f6c25f8":"code","ef4e5b68":"markdown","465b61d1":"markdown","844b989f":"markdown","47927a25":"markdown","e7c666de":"markdown"},"source":{"33dab860":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom re import search\nfrom tqdm  import tqdm\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import layers\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport PIL\nimport pathlib\n\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex5 import *\n\n# Imports\nimport glob\nimport shutil\nimport os, warnings\nfrom matplotlib import gridspec\n\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n\nimport cv2\nfrom random import shuffle\nplt.style.use('fivethirtyeight')\n\nprint(\"setup completed\")","9b4ad492":"#run this cell only if the directories exist\nshutil.rmtree(\".\/train_images\")\nshutil.rmtree(\".\/validation_images\")\nshutil.rmtree(\".\/test_images\")","72198214":"IMAGE_SIZE = 128\nCLASSES = ['0', '1', '2', '3']\nLR = 1e-3\nDIR = '..\/input\/plant-pathology-2020-fgvc7\/images'\nTRAIN_DATASET_SIZE = 1100","9ed93d79":"train_dataset = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/train.csv')\nprint(train_dataset)\ntest_dataset = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/test.csv')\nprint(test_dataset)\n\n# Convert the first image into an array\nimage = Image.open('..\/input\/plant-pathology-2020-fgvc7\/images\/Test_0.jpg');\nprint(np.asarray(image))\nimg = plt.imshow(image)","162ce28c":"print(train_dataset.head())","da92a3c8":"train_dataset['image_id'] = train_dataset['image_id'] + '.jpg'\nprint(train_dataset.shape)\nprint(train_dataset)\n#define the class names\nclass_names = train_dataset.loc[:, 'healthy':].columns\nprint(class_names)","de8f0a0b":"counter = 0\ntrain_dataset['label'] = 0\nfor name in class_names:\n    train_dataset['label'] = train_dataset['label'] + train_dataset[name] * counter\n    counter = counter + 1\n    \nprint(train_dataset)","2b435de5":"# sort the images based on label\ntrain_dataset_healthy = train_dataset[train_dataset.label == 0]\ntrain_dataset_multiple_diseases = train_dataset[train_dataset.label == 1]\ntrain_dataset_rust = train_dataset[train_dataset.label == 2]\ntrain_dataset_scab = train_dataset[train_dataset.label == 3]","66fb0a6d":"print(train_dataset_healthy)\nprint(train_dataset_multiple_diseases)\nprint(train_dataset_rust)\nprint(train_dataset_scab)","1c253dd3":"image_h = Image.open('..\/input\/plant-pathology-2020-fgvc7\/images\/Train_4.jpg');\n#print(np.asarray(image))\nimg_h = plt.imshow(image_h)","eaaddfa0":"image_md = Image.open('..\/input\/plant-pathology-2020-fgvc7\/images\/Train_1.jpg');\n#print(np.asarray(image))\nimg_md = plt.imshow(image_md)","314c5e67":"image_r = Image.open('..\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg');\n#print(np.asarray(image))\nimg_r = plt.imshow(image_r)","2aa829fa":"image_s = Image.open('..\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg');\n#print(np.asarray(image))\nimg_s = plt.imshow(image_s)","166af345":"def get_label_img(img):\n    if search(\"Train\", img):\n        label = train_dataset.loc[train_dataset[\"image_id\"] == img]['label']\n        return label","b7182de2":"def create_train_data():\n    count = 0\n    for img in tqdm(os.listdir(DIR)):\n        label = get_label_img(img)\n        path = os.path.join(DIR, img)\n        #image_name = img\n        #img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMAGE_SIZE, IMAGE_SIZE))\n        \n        if search(\"Train\", img):\n            if count < TRAIN_DATASET_SIZE and label.item() == 0:\n                shutil.copy(path, '.\/train_images\/healthy')\n            elif count < TRAIN_DATASET_SIZE and label.item() == 1:\n                shutil.copy(path, '.\/train_images\/multiple_diseases')\n            elif count < TRAIN_DATASET_SIZE and label.item() == 2:\n                shutil.copy(path, '.\/train_images\/scab')\n            elif count < TRAIN_DATASET_SIZE and label.item() == 3:\n                shutil.copy(path, '.\/train_images\/rust')\n            elif count >= TRAIN_DATASET_SIZE and label.item() == 0:\n                shutil.copy(path, '.\/validation_images\/healthy')\n            elif count >= TRAIN_DATASET_SIZE and label.item() == 1:\n                shutil.copy(path, '.\/validation_images\/multiple_diseases')\n            elif count >= TRAIN_DATASET_SIZE and label.item() == 2:\n                shutil.copy(path, '.\/validation_images\/scab')\n            elif count >= TRAIN_DATASET_SIZE and label.item() == 3:\n                shutil.copy(path, '.\/validation_images\/rust')\n            count = count + 1\n        elif search(\"Test\", img):\n            shutil.copy(path, '.\/test_images\/images') ","aea6e316":"shutil.os.mkdir('.\/train_images')\nshutil.os.mkdir('.\/test_images')\nshutil.os.mkdir('.\/test_images\/images')\nshutil.os.mkdir('.\/validation_images')\nshutil.os.mkdir('.\/train_images\/healthy')\nshutil.os.mkdir('.\/train_images\/multiple_diseases')\nshutil.os.mkdir('.\/train_images\/scab')\nshutil.os.mkdir('.\/train_images\/rust')\nshutil.os.mkdir('.\/validation_images\/healthy')\nshutil.os.mkdir('.\/validation_images\/multiple_diseases')\nshutil.os.mkdir('.\/validation_images\/scab')\nshutil.os.mkdir('.\/validation_images\/rust')\ntrain_data = create_train_data()\n","3dcfb417":"filenames = glob.glob(\".\/validation_images\/rust\/*.jpg\")\nfilenames.sort()\nfilenames = glob.glob(\".\/validation_images\/healthy\/*.jpg\")\nfilenames.sort()\nfilenames = glob.glob(\".\/validation_images\/scab\/*.jpg\")\nfilenames.sort()\nfilenames = glob.glob(\".\/validation_images\/multiple_diseases\/*.jpg\")\nfilenames.sort()\n","6242ae36":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.4),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])\n","c3981cd3":"def set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n#set_seed()","585440d8":"# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '.\/train_images',\n    labels='inferred',\n    label_mode='int',\n    image_size=[IMAGE_SIZE, IMAGE_SIZE],\n    interpolation='nearest',\n    batch_size=64,\n)\nds_valid_ = image_dataset_from_directory(\n    '.\/validation_images',\n    labels='inferred',\n    label_mode='int',\n    image_size=[IMAGE_SIZE, IMAGE_SIZE],\n    interpolation='nearest',\n    batch_size=64,\n)\n\nds_test_ = image_dataset_from_directory(\n    '.\/test_images',\n    image_size=[IMAGE_SIZE, IMAGE_SIZE],\n    label_mode=None\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\ndef convert_to_float_test(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n","6e18ce7e":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_test = (\n    ds_test_\n    .map(convert_to_float_test)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nprint(type(ds_test))\nprint(type(ds_train))","649dfa29":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01, learning_rate=LR),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","875ef1fe":"\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50\n)","b043bc10":"model.summary()","c1c3092c":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();","52973ba8":"probabilities = model.predict(ds_valid)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","416bd594":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","4d3057a3":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","5a5866de":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)","cfc8acc4":"from sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\nauc = multiclass_roc_auc_score(train_dataset.iloc[TRAIN_DATASET_SIZE:,[5]], predictions)\nprint('AUC: %.2f' % auc)\n","23051cd5":"from sklearn.metrics import confusion_matrix","9a1df86a":"conf_matrix = confusion_matrix(train_dataset.iloc[TRAIN_DATASET_SIZE:,[5]], predictions, labels=[0, 1, 2, 3])\n","04f7a984":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","9b10457c":"# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(conf_matrix, classes=[0, 1, 2, 3],\n                      title='Confusion matrix')","1f6c25f8":"print((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_frame['val_loss'].min(), \n              history_frame['val_accuracy'].max()))","ef4e5b68":"New model","465b61d1":"Old model accuracy: 66%","844b989f":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.3),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.5),\n\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])","47927a25":"# Get to work","e7c666de":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(2, 2),\n    layers.Dropout(0.1),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(2, 2),\n    layers.Dropout(0.3),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    #layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(2, 2),\n    layers.Dropout(0.3),\n\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])\n"}}