{"cell_type":{"231db4cc":"code","a2182086":"code","9ac72961":"code","c9149122":"code","cb95358b":"code","d4b8a0c9":"code","101c90a4":"code","92410650":"code","563b4a2f":"code","ab4e9f5b":"code","c4a0cda7":"code","6eac520e":"code","ac8646be":"code","477c1d8d":"code","ca9d08d5":"code","30c549e4":"code","9f0d1b1f":"code","8baac5cb":"code","667384dd":"code","7e8af6dd":"code","b3a58636":"code","48eb2f9f":"code","c33c6c04":"markdown","e4b3435b":"markdown","36f3a0b4":"markdown","a1dd1a75":"markdown","49c0b3e4":"markdown","33d2af64":"markdown","13d8c85c":"markdown","7c19dfba":"markdown"},"source":{"231db4cc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model.logistic import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import  AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a2182086":"data = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndata = data.loc[:,[\"date_block_num\", \"shop_id\", \"item_id\", \"item_cnt_day\" ]]\ndata","9ac72961":"test = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ntest = test.drop(\"ID\", axis=1)\npd.set_option('float_format', '{:.2f}'.format)\ntest","c9149122":"items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitems.describe()","cb95358b":"shops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nshops.describe()","d4b8a0c9":"data[\"date_block_num\"]=((data[\"date_block_num\"]-data[\"date_block_num\"].min())\/((data[\"date_block_num\"].max()+1)-data[\"date_block_num\"].min()))\ndata[\"shop_id\"]=((data[\"shop_id\"]-0)\/(59-0))\ndata[\"item_id\"]=((data[\"item_id\"]-0)\/(22169-0))\ndata","101c90a4":"test[\"shop_id\"]=((test[\"shop_id\"]-0)\/(59-0))\ntest[\"item_id\"]=((test[\"item_id\"]-0)\/(22169-0))\ntest","92410650":"## normalizasyon sonucu data_block_num 34 olaca\u011f\u0131, \n## yani normalizasyonda direkt 1 olaca\u011f\u0131 i\u00e7in\n## 1'lik dataframe olu\u015fturuyoruz.\nsatistest = np.ones(214200)\nsatistest = pd.DataFrame(satistest)\nsatistest","563b4a2f":"#join ile bu dataframeleri birle\u015ftiriyoruz\ntest = satistest.join(test)\ntest","ab4e9f5b":"#Bu \u015fekilde datasetimizi azaltabiliriz.\n#Mevcut durumda bilgisayar\u0131n ekran kart\u0131 yetersizli\u011finden ve ram \u015fi\u015fmesinden dolay\u0131 3 milyon olan k\u00fcmeyi 1.6 milyon al\u0131yorum\ndata = data.sample(n=1600000, random_state=1)","c4a0cda7":"egitimverisi, validationverisi = train_test_split(data, test_size=0.2)","6eac520e":"egitimgirdi = egitimverisi.drop([\"item_cnt_day\"], axis=1)\negitimcikti = egitimverisi.item_cnt_day\negitimgirdi","ac8646be":"egitimcikti","477c1d8d":"valgirdi = validationverisi.drop([\"item_cnt_day\"], axis=1)\nvalcikti = validationverisi.item_cnt_day\nvalgirdi","ca9d08d5":"valcikti","30c549e4":"test = test.rename(columns = {0: \"date_block_num\"})\ntest2 = test.sample(n=214200, random_state=1)\ntest2 = test2.to_numpy()","9f0d1b1f":"sales = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\",index_col='date',parse_dates=['date'])\nsales[\"item_cnt_day\"][:\"2014-01-01\"].plot(figsize=(16,10), legend= True, color = 'g')\nsales[\"item_cnt_day\"]['2014-01-01':'2015-01-01'].plot(figsize=(16,10), legend=True, color= 'b')\nsales[\"item_cnt_day\"]['2015-01-01':].plot(figsize=(16,10), legend = True, color = 'r')\nplt.xlabel('Dates')\nplt.ylabel('Number of Products Sold')\nplt.title('Date vs Sold')","8baac5cb":"models = []\nmodels.append((\"LR\",LogisticRegression()))\n## models.append((\"LDA\",LinearDiscriminantAnalysis())) LR ile benzer oldu\u011fu i\u00e7in kald\u0131r\u0131ld\u0131.\nmodels.append((\"KNN\",KNeighborsClassifier()))\nmodels.append((\"DCT\",DecisionTreeClassifier()))\nmodels.append((\"GNB\",GaussianNB()))\n#models.append((\"SVC\",SVC()))  A\u015eIRI ZAMAN ALDI\u011eI \u0130\u00c7\u0130N KALDIRILDI (YAKLA\u015eIK 10 SAAT) \n##### Your notebook tried to allocate more memory than is available. It has restarted.\n#models.append((\"GPC\",GaussianProcessClassifier(1.0*RBF(1.0)))) A\u015eIRI ZAMAN ALDI\u011eI \u0130\u00c7\u0130N KALDIRILDI (YAKLA\u015eIK 15 SAAT)\n#models.append((\"MLP\",MLPClassifier()))                         A\u015eIRI ZAMAN ALDI\u011eI \u0130\u00c7\u0130N KALDIRILDI\n#models.append((\"ADB\",AdaBoostClassifier()))                    A\u015eIRI ZAMAN ALDI\u011eI \u0130\u00c7\u0130N KALDIRILDI","667384dd":"m=0\nmodelCohorenceTrain = np.arange(4)\nmodelCohorenceValidation = np.arange(4)\nfor name, model in models:\n    liste = np.arange(214200)\n    i=0\n    egitilmismodel = model.fit(egitimgirdi,egitimcikti)\n    egitimsonuc = egitilmismodel.score(egitimgirdi,egitimcikti)\n    valsonuc = egitilmismodel.score(valgirdi,valcikti)\n    if name == \"LR\":\n        print(\"Sonuclar:  %s Egitim Verilerindeki Coherence Oran\u0131:     %f \" %(name, egitimsonuc))\n        print(\"Sonuclar:  %s Validation Verilerindeki Coherence Oran\u0131: %f \" %(name,valsonuc))\n    else:\n        print(\"Sonuclar:  %s Egitim Verilerindeki Coherence Oran\u0131:     %f \" %(name, egitimsonuc))\n        print(\"Sonuclar:  %s Validation Verilerindeki Coherence Oran\u0131: %f \" %(name,valsonuc))\n    modelCohorenceTrain[m] = egitimsonuc*100\n    modelCohorenceValidation[m] = valsonuc*100\n    for x in test2:\n        liste[i]=(egitilmismodel.predict([[x[0],x[1],x[2]]]))\n        i=i+1\n        if m == 0 and i == 214200:\n            df = pd.DataFrame(liste)\n            df.to_csv('LR.csv', header=False, index=False)\n            print(\"LR file saved\")\n        elif m == 1 and i == 214200:\n            df = pd.DataFrame(liste)\n            df.to_csv('KNN.csv', header=False, index=False)\n            print(\"KNN file saved\")\n        elif m == 2 and i == 214200:\n            df = pd.DataFrame(liste)\n            df.to_csv('DCT.csv', header=False, index=False)\n            print(\"DCT file saved\")\n        elif m == 3 and i == 214200:\n            df = pd.DataFrame(liste)\n            df.to_csv('GNB.csv', header=False, index=False) \n            print(\"GNB file saved\")\n    m = m+1","7e8af6dd":"#modelCohorenceTrain = np.arange(9)\n#modelCohorenceValidation = np.arange(9)\n%matplotlib inline\nModelName = ['LogisticRegression','KNeighborsClassifier','DecisionTreeClassifier','GaussianNB']","b3a58636":"fig = plt.figure(figsize = (10,10))\nplt.plot(modelCohorenceTrain, color=\"red\", ls=\"-.\", marker=\"^\", ms=10, label=\"Train Verilerinin Y\u00fczdelik Coherence Oran\u0131\")\nplt.plot(modelCohorenceValidation, color=\"green\", ls=\"-.\", marker=\"*\", ms=10, label=\"Validation Verilerinin Y\u00fczdelik Coherence Oran\u0131\")\nplt.legend(loc = 'upper left', bbox_to_anchor=(1,1))\nplt.xticks(list(range(4)), ModelName, rotation=\"horizontal\")\nplt.yticks( rotation= 0)\nplt.show()","48eb2f9f":"pd.set_option('float_format', '{:.0f}'.format)\nlr = pd.read_csv(\"\/kaggle\/working\/LR.csv\", header = None)\nlr.rename(columns={0:\"satis_miktari\"}, \n                 inplace=True)\ntestLR = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ntestLR = testLR.join(lr)\ntestLR\nfig = plt.figure(figsize = (15,15))\ntestLR.plot(x='shop_id',  y='satis_miktari',color=\"orange\", style='^')\nplt.title('SHOPS &  number of products sold LR')  \nplt.xlabel('SHOPS')  \nplt.legend(loc = 'upper left', bbox_to_anchor=(1,1)) #to show the labels at proper location\nplt.ylabel(' number of products sold')  \nplt.show()\n\n\nknn = pd.read_csv(\"\/kaggle\/working\/KNN.csv\", header = None)\nknn.rename(columns={0:\"satis_miktari\"}, \n                 inplace=True)\ntestKNN = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ntestKNN = testKNN.join(knn)\ntestKNN\nfig = plt.figure(figsize = (15,15))\ntestKNN.plot(x='shop_id', y='satis_miktari',color=\"navy\", style='*')\nplt.title('SHOPS &  number of products sold KNN')  \nplt.xlabel('SHOPS')  \nplt.legend(loc = 'upper left', bbox_to_anchor=(1,1)) #to show the labels at proper location\nplt.ylabel(' number of products sold')  \nplt.show()\n\ndct = pd.read_csv(\"\/kaggle\/working\/DCT.csv\", header = None)\ndct.rename(columns={0:\"satis_miktari\"}, \n                 inplace=True)\ntestDCT = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ntestDCT = testDCT.join(dct)\ntestDCT\nfig = plt.figure(figsize = (15,15))\ntestDCT.plot(x='shop_id', y='satis_miktari',color=\"blueviolet\", style='+')\nplt.title('SHOPS &  number of products sold DCT')  \nplt.xlabel('SHOPS')  \nplt.legend(loc = 'upper left', bbox_to_anchor=(1,1)) #to show the labels at proper location\nplt.ylabel(' number of products sold')  \nplt.show()\n\ngnb = pd.read_csv(\"\/kaggle\/working\/GNB.csv\", header = None)\ngnb.rename(columns={0:\"satis_miktari\"}, \n                 inplace=True)\ntestGNB = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ntestGNB = testGNB.join(gnb)\ntestGNB\nfig = plt.figure(figsize = (15,15))\ntestGNB.plot(x='shop_id', y='satis_miktari',color=\"deepskyblue\", style='+')\nplt.title('SHOPS &  number of products sold GNB')  \nplt.xlabel('SHOPS')  \nplt.legend(loc = 'upper left', bbox_to_anchor=(1,1)) #to show the labels at proper location\nplt.ylabel(' number of products sold')  \nplt.show()\n\n","c33c6c04":"## Bu k\u0131s\u0131mda hem modellerimizin uygulanmas\u0131 i\u015flemi yap\u0131l\u0131yor hem de sonu\u00e7 de\u011ferleri csv'lere aktar\u0131l\u0131yor. \n#### Bu k\u0131s\u0131mda datasetimizden ay\u0131rd\u0131\u011f\u0131m\u0131z bilgisayar\u0131n hi\u00e7 g\u00f6rmedi\u011fi validation verileri ile cohorence hesaplan\u0131yor. \n#### Bu \u015fekilde beklenen ve olu\u015fan tahmin de\u011ferlerinin do\u011frulu\u011funu saptayabiliyoruz.","e4b3435b":"### imports","36f3a0b4":"### datam\u0131z ve sonu\u00e7lar\u0131m\u0131z i\u00e7in column i\u015flemleri yapal\u0131m","a1dd1a75":"####\u00a0normalizasyon i\u015flemimizi burada yap\u0131yoruz","49c0b3e4":"#### BLM442 Final S\u0131nav\u0131 Projesi KISIM-2\n#### \u0130sim\/Soyisim: Berkay \u00c7APAR\n#### \u00d6\u011frenci Numaras\u0131: 160201085\n#### E-mail: berkaycapar@gmail.com\n#### Kullan\u0131lan dataset ad\u0131:  Earthquakes in 1910-2017, Turkey\n\n### SUNULAN \u00c7\u00d6Z\u00dcMDE TEST VER\u0130S\u0130 \u00dcZER\u0130NDE 6 FARKLI MAK\u0130NE \u00d6\u011eRENMES\u0130 K\u00dcT\u00dcPHANES\u0130 KULLANILARAK COHERENCE SKORLAR ELDE ED\u0130LM\u0130\u015e,HER B\u0130R MODEL SONUCU OLARAK TEST VER\u0130S\u0130 \u00dcZER\u0130NDE SATI\u015e M\u0130KTARLARI G\u00d6STER\u0130LEREK AYRI B\u0130R .CSV'YE ATILMI\u015eTIR. SONRASINDA BU CSVLER \u00c7EK\u0130LEREK G\u00d6RSELLE\u015eT\u0130R\u0130LM\u0130\u015eT\u0130R.","33d2af64":"#### csv'ye aktar\u0131lan veriler \u00e7ekilip shop_id'lerde ka\u00e7 tane \u00fcr\u00fcn sat\u0131ld\u0131\u011f\u0131n\u0131 g\u00f6rebiliriz.","13d8c85c":"####\u00a0shop id ka\u00e7 tane item id ka\u00e7 tane onlara da bak\u0131p ona g\u00f6re normalizasyon i\u015flemi uygulayaca\u011f\u0131z.","7c19dfba":"### E\u011fitim verilerimizi kullanabilmemiz i\u00e7in sales_train.csv dosyam\u0131z\u0131 okuyoruz ve date_block_num, shop_id, item_id, item_cnt_day kolonlar\u0131n\u0131 al\u0131yoruz."}}