{"cell_type":{"949aa857":"code","f25412ae":"code","b0b826f6":"code","4d73f69f":"code","75ef7924":"code","01e03007":"code","efe92b7e":"code","c796eae6":"code","1cc4e6d0":"code","1a220755":"code","eaa1a079":"code","b8a6adc0":"code","a6b86e5a":"code","45f65610":"code","e600fe99":"code","452c626c":"code","5c51f8a0":"code","ed07feb4":"code","08057f29":"code","57b91983":"markdown","1908ede1":"markdown","7b91bcbd":"markdown","f70239c1":"markdown"},"source":{"949aa857":"try:\n    import resnest\nexcept ModuleNotFoundError:\n    !pip install -q \"..\/input\/resnest50-fast-package\/resnest-0.0.6b20200701\/resnest\"","f25412ae":"import numpy as np\nimport librosa as lb\nimport soundfile as sf\nimport pandas as pd\nimport cv2\nfrom pathlib import Path\nimport re\n\nimport torch\nfrom torch import nn\nfrom  torch.utils.data import Dataset, DataLoader\n\nfrom tqdm.notebook import tqdm\n\nimport time\nfrom resnest.torch import resnest50","b0b826f6":"NUM_CLASSES = 397\nSR = 32_000\nDURATION = 5\nTHRESH = 0.11\n\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"DEVICE:\", DEVICE)\n\nTEST_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/test_soundscapes\")\nSAMPLE_SUB_PATH = \"..\/input\/birdclef-2021\/sample_submission.csv\"\nTARGET_PATH = None\n    \nif not len(list(TEST_AUDIO_ROOT.glob(\"*.ogg\"))):\n    TEST_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/train_soundscapes\")\n    SAMPLE_SUB_PATH = None\n    # SAMPLE_SUB_PATH = \"..\/input\/birdclef-2021\/sample_submission.csv\"\n    TARGET_PATH = Path(\"..\/input\/birdclef-2021\/train_soundscape_labels.csv\")","4d73f69f":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr\/\/10)\n        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr\/\/(10*4))\n        self.kwargs = kwargs\n\n    def __call__(self, y):\n\n        melspec = lb.feature.melspectrogram(\n            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n        )\n\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","75ef7924":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) \/ (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) \/ (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\ndef crop_or_pad(y, length):\n    if len(y) < length:\n        y = np.concatenate([y, length - np.zeros(len(y))])\n    elif len(y) > length:\n        y = y[:length]\n    return y","01e03007":"class BirdCLEFDataset(Dataset):\n    def __init__(self, data, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n        \n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n                                                 fmax=self.fmax)\n    def __len__(self):\n        return len(self.data)\n    \n    @staticmethod\n    def normalize(image):\n        image = image.astype(\"float32\", copy=False) \/ 255.0\n        image = np.stack([image, image, image])\n        return image\n    \n    def audio_to_image(self, audio):\n        melspec = self.mel_spec_computer(audio) \n        image = mono_to_color(melspec)\n        image = self.normalize(image)\n        return image\n\n    def read_file(self, filepath):\n        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n\n        if self.resample and orig_sr != self.sr:\n            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n          \n        audios = []\n        for i in range(self.audio_length, len(audio) + self.step, self.step):\n            start = max(0, i - self.audio_length)\n            end = start + self.audio_length\n            audios.append(audio[start:end])\n            \n        if len(audios[-1]) < self.audio_length:\n            audios = audios[:-1]\n            \n        images = [self.audio_to_image(audio) for audio in audios]\n        images = np.stack(images)\n        \n        return images\n    \n        \n    def __getitem__(self, idx):\n        return self.read_file(self.data.loc[idx, \"filepath\"])","efe92b7e":"data = pd.DataFrame(\n     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(TEST_AUDIO_ROOT).glob(\"*.ogg\")],\n    columns = [\"filename\", \"id\", \"site\", \"date\", \"filepath\"]\n)\nprint(data.shape)\ndata.head()","c796eae6":"df_train = pd.read_csv(\"..\/input\/birdclef-2021\/train_metadata.csv\")\n\nLABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df_train[\"primary_label\"].unique()))}\nINV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}","1cc4e6d0":"test_data = BirdCLEFDataset(data=data)\nlen(test_data), test_data[0].shape","1a220755":"def load_net(checkpoint_path, num_classes=NUM_CLASSES):\n    net = resnest50(pretrained=False)\n    net.fc = nn.Linear(net.fc.in_features, num_classes)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n    for key in list(d.keys()):\n        d[key.replace(\"model.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net","eaa1a079":"\ncheckpoint_paths = [\n#     Path('..\/input\/bridclef-resnest50-weight\/birdclef_resnest50_fold4_epoch_29_f1_val_07694_20210513205331.pth'),\n#     Path('..\/input\/bridclef-resnest50-weight\/birdclef_resnest50_fold1_epoch_18_f1_val_07636_20210512152028.pth'),\n#     Path('..\/input\/bridclef-resnest50-weight\/birdclef_resnest50_fold2_epoch_24_f1_val_07728_20210512202556.pth'),\n#     Path('..\/input\/bridclef-resnest50-weight\/birdclef_resnest50_fold3_epoch_28_f1_val_07609_20210513105835.pth'),\n    Path('..\/input\/kkiller-birdclef-models-public\/birdclef_resnest50_fold0_epoch_10_f1_val_06471_20210417161101.pth')\n]\n\n\nnets = [\n        load_net(checkpoint_path.as_posix()) for checkpoint_path in checkpoint_paths\n]","b8a6adc0":"@torch.no_grad()\ndef get_thresh_preds(out, thresh=None):\n    thresh = thresh or THRESH\n    o = (-out).argsort(1)\n    npreds = (out > thresh).sum(1)\n    preds = []\n    for oo, npred in zip(o, npreds):\n        preds.append(oo[:npred].cpu().numpy().tolist())\n    return preds","a6b86e5a":"def get_bird_names(preds):\n    bird_names = []\n    for pred in preds:\n        if not pred:\n            bird_names.append(\"nocall\")\n        else:\n            bird_names.append(\" \".join([INV_LABEL_IDS[bird_id] for bird_id in pred]))\n    return bird_names","45f65610":"def predict(nets, test_data, names=True):\n    preds = []\n    with torch.no_grad():\n        for idx in  tqdm(list(range(len(test_data)))):\n            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n            pred = 0.\n            for net in nets:\n                o = net(xb)\n                o = torch.sigmoid(o)\n\n                pred += o\n\n            pred \/= len(nets)\n            \n            if names:\n                pred = get_bird_names(get_thresh_preds(pred))\n\n            preds.append(pred)\n    return preds","e600fe99":"pred_probas = predict(nets, test_data, names=False)\nprint(len(pred_probas))","452c626c":"preds = [get_bird_names(get_thresh_preds(pred, thresh=THRESH)) for pred in pred_probas]\n# preds[:2]","5c51f8a0":"def preds_as_df(data, preds):\n    sub = {\n        \"row_id\": [],\n        \"birds\": [],\n    }\n    \n    for row, pred in zip(data.itertuples(False), preds):\n        row_id = [f\"{row.id}_{row.site}_{5*i}\" for i in range(1, len(pred)+1)]\n        sub[\"birds\"] += pred\n        sub[\"row_id\"] += row_id\n        \n    sub = pd.DataFrame(sub)\n    \n    if SAMPLE_SUB_PATH:\n        sample_sub = pd.read_csv(SAMPLE_SUB_PATH, usecols=[\"row_id\"])\n        sub = sample_sub.merge(sub, on=\"row_id\", how=\"left\")\n        sub[\"birds\"] = sub[\"birds\"].fillna(\"nocall\")\n    return sub","ed07feb4":"sub = preds_as_df(data, preds)\nprint(sub.shape)\nsub","08057f29":"sub.to_csv(\"submission.csv\", index=False)","57b91983":"This inference notebook is the same as @kkiller's [one](https:\/\/www.kaggle.com\/kneroma\/clean-fast-simple-bird-identifier-inference). Please upvote the original notebook.\n\nIn this Notebook, I just lower the threshold. And it seems that LB will increase with smaller thresh, maybe which overfitting the public leaderboard.","1908ede1":"# Data","7b91bcbd":"# Configs","f70239c1":"# Inference"}}