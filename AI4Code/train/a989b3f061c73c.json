{"cell_type":{"6923c6b8":"code","b4e7136d":"code","455d4d35":"code","3ea72ff2":"code","77bb9079":"code","0950608c":"code","389b6124":"code","f1c89e2b":"code","eea17efb":"code","1cb244fb":"code","38faced6":"code","31a911d1":"code","a0af54e8":"code","a426da9d":"code","31e98a80":"code","c5c81266":"code","f465bc98":"code","9fad2818":"code","a1a8129f":"code","791a70b9":"code","4bc10877":"code","210279bf":"code","e978fcee":"markdown","44c1e4d5":"markdown","c2230010":"markdown","07c258e1":"markdown","030d3128":"markdown","baef8970":"markdown","aab18dd9":"markdown","10749bd8":"markdown","02cfa6a9":"markdown","8051f086":"markdown","8a6f81d4":"markdown","41461179":"markdown","f15f31bf":"markdown","987a105a":"markdown","52458ffc":"markdown","5c48af59":"markdown","e070deec":"markdown","ba46178a":"markdown","80000738":"markdown"},"source":{"6923c6b8":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import MobileNet, MobileNetV2, VGG16\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dropout, Dense, BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle","b4e7136d":"path = \"..\/input\/brain-tumor-classification-mri\"","455d4d35":"list(os.listdir(path))","3ea72ff2":"list(os.listdir(path + \"\/Training\"))","77bb9079":"list(os.listdir(path + \"\/Testing\"))","0950608c":"labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']\n\nclass_map = {\n    'no_tumor': 0,\n    'glioma_tumor': 1,\n    'meningioma_tumor': 2,\n    'pituitary_tumor': 3\n}\n\ninverse_class_map = {\n    0: 'no_tumor',\n    1: 'glioma_tumor',\n    2: 'meningioma_tumor',\n    3: 'pituitary_tumor'\n}","389b6124":"h, w = 224, 224\nbatch_size = 32\nepochs = 100","f1c89e2b":"IMAGE = []\nLABELS = []\n\nfor label in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri\/Training', label)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath, j))\n        img = cv2.resize(img,(h, w))\n        IMAGE.append(img)\n        LABELS.append(class_map[label])\n            \n        \nfor label in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri\/Testing', label)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(h, w))\n        IMAGE.append(img)\n        LABELS.append(class_map[label])\n        \nX = np.array(IMAGE)\ny = np.array(LABELS)","eea17efb":"plt.figure(figsize=(16, 12))\n\npath = '..\/input\/brain-tumor-classification-mri\/Training\/'\nfileNames = ['glioma_tumor\/gg (10).jpg', 'meningioma_tumor\/m (108).jpg', 'no_tumor\/image (16).jpg', 'pituitary_tumor\/p (12).jpg']\nfileLabels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n\nfor i in range(4):\n    ax = plt.subplot(4, 4, i + 1)\n    img = mpimg.imread(path + fileNames[i])\n    img = cv2.resize(img, (h, w))\n    plt.imshow(img)\n    plt.title(fileLabels[i])\n    plt.axis(\"off\")","1cb244fb":"X, y = shuffle(X, y, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, to_categorical(y), test_size=0.1, random_state=42)","38faced6":"# base_model = MobileNet(\n#     input_shape=(h, w, 3), \n#     weights='imagenet',\n#     include_top=False, \n#     pooling='avg'\n# )\n\nbase_model = VGG16(\n    input_shape=(h, w, 3), \n    weights='imagenet',\n    include_top=False, \n    pooling='max'\n)\n\nbase_model.summary()","31a911d1":"base_model.trainable = False\n\noutput_class = 4\n\nmodel = Sequential([\n    base_model,\n    Dropout(rate=0.5),\n    Dense(output_class, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","a0af54e8":"earlystop = EarlyStopping(monitor='val_loss', patience=5)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]","a426da9d":"datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)","31e98a80":"history = model.fit(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n                    steps_per_epoch = len(X_train) \/ batch_size, epochs = epochs, callbacks = callbacks)","c5c81266":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(history.history['accuracy']))\n\nplt.figure(figsize=(18, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(len(history.history['accuracy'])), acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","f465bc98":"predicted_labels = model.predict(X_test)\nprint(predicted_labels[:5])","9fad2818":"predicted_labels = [np.argmax(i) for i in predicted_labels]\nprint(predicted_labels[:5])","a1a8129f":"original_labels =[np.argmax(i) for i in y_test]\nprint(original_labels[:5])","791a70b9":"from sklearn.metrics import classification_report,confusion_matrix\n\nconf_mat = confusion_matrix(original_labels, predicted_labels)\nreport = classification_report(original_labels, predicted_labels)\n\nprint('Confusion Matrix ==>')\nprint(conf_mat)\nprint('----------------------------------------------------------------------------------------')\nprint('Classification Report ==>')\nprint(report)","4bc10877":"predicted_labels = [inverse_class_map[x] for x in predicted_labels]\nprint(predicted_labels[:5])","210279bf":"# model.save(\"tumorModel.h5\")","e978fcee":"# Reading the image & saving as np.array, along with their respective labels","44c1e4d5":"# Checking model performance","c2230010":"# Saving our model","07c258e1":"# Defining Callbacks","030d3128":"# Set Hyperparameters","baef8970":"# Checking prediction accuracy with confusion matrix","aab18dd9":"# Converting labels to their respective class names","10749bd8":"# Training our model","02cfa6a9":"# **DETECTING BRAIN TUMOR WITH CNN**\n\n![](https:\/\/www.researchgate.net\/profile\/Tamije-Selvy-Perumal\/publication\/265477512\/figure\/fig1\/AS:462790839279619@1487349342768\/a-Original-MRI-brain-tumor-image-b-Colored-MRI-image.png)\n\n\n*My aim is to predict whether a patient has any kind of tumor or not based on a MRI scan of brain.*","8051f086":"# Define CNN model","8a6f81d4":"# Define labels of the output classes","41461179":"# Predicting with our model","f15f31bf":"# Checking available files\/folders","987a105a":"# Image Augmentation","52458ffc":"# Create Train & Test sets","5c48af59":"# Looking at different types of tumor","e070deec":"# Steps Involved\n\n* Import all the necessary modules & load the data.\n* Observe the data and determine the number of output classes (4 in this case).\n* Define labels for each of the output class. \n* Read & save the images along with their respective labels.\n* Create Train and Test set.\n* Define the CNN model & set the number of output classes.\n* Train & observe the model, then tune hyperparams accordingly.\n* Predict & save our model.","ba46178a":"# Set the no. of output class of the model","80000738":"# Imports"}}