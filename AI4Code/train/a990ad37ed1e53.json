{"cell_type":{"ad8cfd49":"code","b8f32597":"code","28af9adc":"code","d62aae6c":"code","fc025e93":"code","f788e03a":"code","dedb78c0":"code","0bb9268e":"code","19585178":"code","1b17ae51":"code","0fa937ce":"code","c9eb4c77":"code","0ce2affa":"code","158a37ec":"code","6fcd0b06":"code","34ce8199":"code","c2a84a1c":"code","2bbdc761":"code","0f02e9b9":"code","47612a23":"code","71d75757":"code","307d574e":"code","bdc2745b":"code","15f1545a":"code","0f92c754":"code","4da2aae8":"code","050060ae":"markdown","cdfdc4b9":"markdown","7a2bc286":"markdown","6323915a":"markdown"},"source":{"ad8cfd49":"!pip install mtcnn","b8f32597":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom mtcnn import MTCNN\nfrom tqdm import tqdm\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore',category=FutureWarning)","28af9adc":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","d62aae6c":"detector = MTCNN()","fc025e93":"img0=cv2.imread('..\/input\/famous-iconic-women\/output\/train\/Serena Williams\/000008.jpg')\nimg1= cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\nplt.imshow(img1,cmap=\"gray\")\nplt.axis(\"off\")  \nplt.show()","f788e03a":"def mtcnn_box(image,BOX) : \n    result = detector.detect_faces(image)\n    return result","dedb78c0":"# prepare empty box\nBOX1=[]\nmtcnn_box(img1,BOX1)","0bb9268e":"names=os.listdir('..\/input\/famous-iconic-women\/output\/train')\nprint(names)\nprint(len(names))","19585178":"paths=[]\nfor dirname, _, filenames in os.walk('..\/input\/famous-iconic-women\/output\/train'):    \n    t=0\n    for filename in filenames:\n        if t<8:\n            paths+=[os.path.join(dirname,filename)]\n            t+=1\nprint(len(paths))","1b17ae51":"paths0=[]\nfor item in paths:\n    if item.split('\/')[-2] in names:\n        paths0+=[item]   \nprint(len(paths0))        ","0fa937ce":"BOX=[]\nfor path in tqdm(paths0):\n    img=cv2.imread(path)\n    if type(img)==np.ndarray:\n        BOX+=mtcnn_box(img,BOX)","c9eb4c77":"annotation=pd.DataFrame(columns=['ids','b1','b2','b3','b4','conf','le1','le2','re1','re2','ns1','ns2','lm1','lm2','rm1','rm2','class'],index=range(len(BOX)))\nannotation","0ce2affa":"i=0\nfor path1 in paths0:\n    BOX2=[]\n    img=cv2.imread(path1)\n    BOX2+=mtcnn_box(img,BOX2)\n    for item2 in BOX2:\n        box=item2['box']\n        confidence=item2['confidence']\n        left_eye=item2['keypoints']['left_eye']\n        right_eye=item2['keypoints']['right_eye']\n        nose=item2['keypoints']['nose']\n        mouth_left=item2['keypoints']['mouth_left']\n        mouth_right=item2['keypoints']['mouth_right']\n        annotation.iloc[i,0:1]=path1.split('\/')[-1]\n        annotation.iloc[i,1:5]=box\n        annotation.iloc[i,5:6]=confidence\n        annotation.iloc[i,6:8]=left_eye\n        annotation.iloc[i,8:10]=right_eye\n        annotation.iloc[i,10:12]=nose\n        annotation.iloc[i,12:14]=mouth_left\n        annotation.iloc[i,14:16]=mouth_right      \n        annotation.iloc[i,16:17]=path1.split('\/')[-2]      \n        i+=1\n        \nannotation","158a37ec":"from matplotlib import animation,rc\nrc('animation',html='jshtml')","6fcd0b06":"def create_animation(ims):\n    fig=plt.figure(figsize=(6,6))\n    plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[0],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig,animate_func,frames=len(ims),interval=1000\/\/2)","34ce8199":"images0=[]\nfor i in tqdm(range(0,len(paths0),1)):\n    images0+=[cv2.imread(paths0[i])]\n    \nprint(len(images0))","c2a84a1c":"create_animation(images0)","2bbdc761":"anno2=annotation\nanno2['le-re']=((anno2['le1']-anno2['re1'])**2+(anno2['le2']-anno2['re2'])**2)**0.5\nanno2['ce1']=(anno2['le1']+anno2['re1'])\/2\nanno2['ce2']=(anno2['le2']+anno2['re2'])\/2\nanno2['cm1']=(anno2['lm1']+anno2['rm1'])\/2\nanno2['cm2']=(anno2['lm2']+anno2['rm2'])\/2\nanno2['ce-ns']=((anno2['ce1']-anno2['ns1'])**2+(anno2['ce2']-anno2['ns2'])**2)**0.5\nanno2['ns-cm']=((anno2['ns1']-anno2['cm1'])**2+(anno2['ns2']-anno2['cm2'])**2)**0.5\nanno2['ce-ns-ratio']=anno2['ce-ns']\/anno2['le-re']\nanno2['ns-cm-ratio']=anno2['ns-cm']\/anno2['le-re']\nanno2","0f02e9b9":"anno3=anno2[['ce-ns-ratio','ns-cm-ratio']]\nanno3['class']=anno2['class']\nanno3","47612a23":"anno4=anno3.iloc[0:195]\nanno4","71d75757":"g=sns.jointplot(data=anno4,x='ce-ns-ratio',y='ns-cm-ratio',hue=\"class\",kind=\"kde\")\ng.fig.set_size_inches(13,13)","307d574e":"g2=sns.relplot(data=anno4,x='ce-ns-ratio',y='ns-cm-ratio',hue=\"class\")\ng2.fig.set_size_inches(13,13)","bdc2745b":"anno3['ce-ns-ratio']=anno3['ce-ns-ratio'].astype(float)\nanno3['ns-cm-ratio']=anno3['ns-cm-ratio'].astype(float)","15f1545a":"anno3.info()","0f92c754":"anno5=anno3.groupby('class',as_index=False).mean()\nanno5","4da2aae8":"g3=sns.relplot(data=anno5,x='ce-ns-ratio',y='ns-cm-ratio',hue=\"class\")\ng3.fig.set_size_inches(13,13)","050060ae":"https:\/\/github.com\/ipazc\/mtcnn","cdfdc4b9":"# Slide Show","7a2bc286":"# Create new parameters\n### 'eye center - nose distance ratio' and 'nose - mouth center distance ratio' to 'left eye - right eye distance'","6323915a":"# detector = MTCNN()"}}