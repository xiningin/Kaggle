{"cell_type":{"0bcb27cb":"code","e9db80df":"code","a352152c":"code","e20170cf":"code","1cf9c295":"code","918a33d0":"code","8edbb287":"code","0f61935a":"markdown","6ed3548c":"markdown","7cb3193a":"markdown","0482de27":"markdown","222456f7":"markdown","3d3ebc3f":"markdown","607a859b":"markdown","e5084b94":"markdown","bcc051ef":"markdown","98dd9286":"markdown","68c3ba20":"markdown"},"source":{"0bcb27cb":"import pandas as pd\n\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","e9db80df":"x_train = train.drop('label',axis = 1)\ny_train = train['label']\nx_test = test\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\nx_train = x_train.values.reshape(-1,28,28,1)\nx_val =  x_val.values.reshape(-1,28,28,1)\nx_test = x_test.values.reshape(-1,28,28,1)","a352152c":"from keras.preprocessing.image import ImageDataGenerator\n\naug = ImageDataGenerator(rotation_range=5, width_shift_range=0.05, height_shift_range=0.05, zoom_range = 0.05)\naug.fit(x_train)","e20170cf":"from keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\n\nmodel = Sequential()\n\nmodel.add(Conv2D(6, 5, padding=\"same\",\n                 activation=\"relu\", input_shape=[28, 28, 1]))\nmodel.add(MaxPool2D())\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(16, 5, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(120, 5, padding=\"same\", activation=\"relu\"))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(84, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation=\"softmax\"))\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer=\"sgd\", metrics=[\"accuracy\"])\nmodel.summary()","1cf9c295":"early_stop = EarlyStopping(\n    patience=6, restore_best_weights=True,monitor = 'val_acc') #avoid overfitting\n\nmodel.fit(aug.flow(x_train, y_train,batch_size = 64),steps_per_epoch=len(x_train) \/ 64, epochs=100,validation_data = (x_val,y_val),callbacks=[early_stop],use_multiprocessing = True, verbose = 0)","918a33d0":"import numpy as np\ny_pred = np.argmax(model.predict(x_test),axis = 1) #choose max probability as prediction label\n\nsubmission = pd.DataFrame({\"imageId\": np.arange(1, len(y_pred)+1),\"Label\":y_pred})\n","8edbb287":"submission.to_csv(\"lenet_sub.csv\",index=False)","0f61935a":"## train model","6ed3548c":"# Simple LeNet-5 with Data Augmentation","7cb3193a":"## load data","0482de27":"This dataset has been widely cheked, so we directly skip the EDA part.  ","222456f7":"![Lenet](https:\/\/miro.medium.com\/max\/3600\/0*H9_eGAtkQXJXtkoK)","3d3ebc3f":"I made some customization to the original lenet-5, including: changed activate function to ReLu, added a dropout layer, added BatchNormalization layers, changed padding strategy in convolutional layers (which makes number of parameters increase by 10 times.)\n\nOriginal architecture of LeNet-5 could be found on [this website](http:\/\/yann.lecun.com\/exdb\/lenet\/)","607a859b":"If you find this notebook helpful, please upvote. Your support will be highly appreciated!.","e5084b94":"## cnn model (LeNet-5)\n","bcc051ef":"## data augmentation","98dd9286":"Using keras api to do the data augmentation (to generate extra training data).","68c3ba20":"## predict and export"}}