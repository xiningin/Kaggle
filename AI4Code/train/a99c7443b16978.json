{"cell_type":{"e2fb51e7":"code","b9f67625":"code","53be5a9b":"code","b0c4c4e1":"code","57c8b599":"code","f196034d":"code","15de450d":"code","d0492135":"code","863de3d8":"code","a178beac":"code","b9d8b914":"code","2666f6ff":"code","51582985":"code","339cf301":"code","88fd0e5d":"code","7d41e99c":"code","375f3a68":"code","0dc06415":"code","1c51eb7a":"code","d333909b":"code","4541d257":"code","990b1857":"code","15e2059e":"code","e0714752":"code","aca039b8":"code","ec49f789":"code","322be379":"code","5897d9dc":"code","5338001d":"code","2cf2033b":"code","c3960bfc":"code","8639bf73":"code","2d454e47":"code","e9e36e83":"code","d5e8a369":"code","2df84bbf":"code","2d65b45f":"code","bc2a8dd8":"code","91369dcf":"code","15cbdc23":"code","7945e6fc":"code","c2e8a78f":"code","f15c61e2":"code","523c0ae5":"code","8cb8abb3":"code","25e11e54":"code","1ff2c96f":"code","39b641f9":"markdown","4078968b":"markdown","564a97e1":"markdown","afd72b56":"markdown","91559aa8":"markdown","22817882":"markdown","9ada3368":"markdown","1f69a22d":"markdown","5cb81501":"markdown","57f6d128":"markdown","7936bc35":"markdown","f90180aa":"markdown","bf829e49":"markdown","861ba7a7":"markdown","9d44272a":"markdown","0f3caecb":"markdown","d437b3b6":"markdown","3d4e086f":"markdown","1b7b4343":"markdown","a639b50e":"markdown","5eb3f410":"markdown","c7566645":"markdown","a497ebd8":"markdown","9f19f3d4":"markdown","3a7174f0":"markdown","893486c5":"markdown","58f41023":"markdown","3011402a":"markdown","13cce877":"markdown","4e6bbd12":"markdown","887c3f34":"markdown","5b077428":"markdown","acc1007f":"markdown","6f790202":"markdown","5146ac4d":"markdown","a479b864":"markdown","95f0a99d":"markdown","40ee715e":"markdown","a58c9f52":"markdown","21c315a5":"markdown","1095aee4":"markdown","ce89d3e4":"markdown","7cb6e868":"markdown","ec99cc5e":"markdown"},"source":{"e2fb51e7":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\n# for visualization\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# import holoviews as hv\n\n# Testing\nimport scipy\nimport scipy.stats as st\n\n# Modeling\nimport xgboost\nfrom xgboost import XGBClassifier\n\nimport sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n\nfrom sklearn import model_selection\n# Splitting Dataset\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\n# Scoring\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score\nfrom sklearn.model_selection import KFold\n\n# Class Imbalance\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n# from imblearn import over_sampling\n\n%matplotlib inline","b9f67625":"print('Numpy Version : ' + np.__version__)\nprint('Pandas Version : ' + pd.__version__)\nprint('Matplotlib Version : ' + matplotlib.__version__)\nprint('Seaborn Version : ' + sns.__version__)\nprint('Scipy Version : ' + scipy.__version__)\nprint('Sklearn Version : ' + sklearn.__version__)\nprint('XGBoost Version : ' + xgboost.__version__)","53be5a9b":"train = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntrain.head()","b0c4c4e1":"train.shape","57c8b599":"train.info()","f196034d":"train.describe()","15de450d":"numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndisplay(train.select_dtypes(include=numerics).columns)\nprint(train.select_dtypes(include=numerics).shape)\ndata_num = train.select_dtypes(include=numerics)","d0492135":"#Invalid Value\ndisplay(train.select_dtypes(include=['object']).columns)\nprint(train.select_dtypes(include=object).shape)\ndata_cat = train.select_dtypes(include=['object'])","863de3d8":"train[['id', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured',\n       'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']].describe()","a178beac":"train['Gender'].value_counts()","b9d8b914":"train['Vehicle_Age'].value_counts()","2666f6ff":"train['Vehicle_Damage'].value_counts()","51582985":"train[['Gender', 'Vehicle_Age', 'Vehicle_Damage']].describe()","339cf301":"trainGroup = train.loc[:, train.columns.intersection(['id', 'Response'])]\ntrainGroup['Age-Group'] = train['Age'].apply(lambda x : '> 50' if x > 50 else ('36 - 50' if (x > 35) and (x < 51) else '20-35'))\ntrainGroup['Vintage-Group'] = train['Vintage'].apply(lambda x : '0-100' if x < 100 else ('100 - 200' if (x > 100) and (x < 200) else '200 - 300'))\ntrainGroup['Annual_Premium-Group'] = train['Annual_Premium'].apply(lambda x : '> 450K' if x > 450000 else ('150K - 450K' if (x > 150000) and (x < 450001) else '0 - 150K'))\n\ntrainGroup","88fd0e5d":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\n\n# Count Length Data Vehicle Damage\ndv_len = len(train['Driving_License'])\n\ng = sns.countplot(train['Driving_License'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Driving_License'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Driving License',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\n\nplt.savefig('.\/driving-license.jpg')\nplt.show();","7d41e99c":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\npi_len = len(train['Previously_Insured'])\n\ng = sns.countplot(train['Previously_Insured'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Previously_Insured'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Previously Insured',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\nplt.savefig('.\/previously-insured.jpg')\nplt.show();","375f3a68":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\nag_len = len(trainGroup['Age-Group'])\n\ng = sns.countplot(trainGroup['Age-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nh = sns.countplot(trainGroup['Age-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nax[1].legend(loc=\"upper left\", title=\"Response\",)\n\n    \nk = sns.distplot(train['Age'], ax=ax[2])\nl = sns.boxplot(train['Age'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Age',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/age.jpg')\nplt.show();","0dc06415":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\nvg_len = len(trainGroup['Vintage-Group'])\n\ng = sns.countplot(trainGroup['Vintage-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(trainGroup['Vintage-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \ng = sns.distplot(train['Vintage'], ax=ax[2])\ng = sns.boxplot(train['Vintage'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Vintage',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\t\nfig.tight_layout()\n\nplt.savefig('.\/vintage.jpg')\nplt.show();","1c51eb7a":"fig,ax = plt.subplots(1,4,figsize=(26,8))\n\napg_len = len(trainGroup['Annual_Premium-Group'])\n\ng = sns.countplot(trainGroup['Annual_Premium-Group'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(trainGroup['Annual_Premium-Group'], hue = trainGroup['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \ng = sns.distplot(train['Annual_Premium'], ax=ax[2])\ng = sns.boxplot(train['Annual_Premium'], orient='v', ax=ax[3])\n\nplt.suptitle('Distribution Annual Premium',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\t\nfig.tight_layout()\n\nplt.savefig('.\/annual-premium.jpg')\nplt.show();","d333909b":"fig,ax = plt.subplots(2,figsize=(26,15),\n                     sharey=True)\n\ndata_region_code = train[train.Region_Code.isin(train[['id','Region_Code']].groupby('Region_Code', as_index=False).count().sort_values('id', ascending=False).head(10).Region_Code.to_list())]\n\ng = sns.countplot(data_region_code['Region_Code'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\nax[0].set_title('Distribution Region Code',fontsize=24,color='dodgerblue',fontweight='bold')\n\nh = sns.countplot(data_region_code['Region_Code'],hue= data_region_code['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\nax[1].set_title('Response to Region Code',fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout();","4541d257":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\ng_len = len(train['Gender'])\n\ng = sns.countplot(train['Gender'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Gender'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nplt.suptitle('Response to Gender',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/gender.jpg')\nplt.show();","990b1857":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\nva_len = len(train['Vehicle_Age'])\n\ng = sns.countplot(train['Vehicle_Age'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n    \nh = sns.countplot(train['Vehicle_Age'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\n\nplt.suptitle('Response to Vehicle Age',y=1, fontsize=24,color='dodgerblue',fontweight='bold');\n\nfig.tight_layout()\n\nplt.savefig('.\/vehicle-age.jpg')\nplt.show();","15e2059e":"fig,ax = plt.subplots(1,2,figsize=(15,8),\n                     sharey=True)\n\n# Count Length Data Vehicle Damage\nvd_len = len(train['Vehicle_Damage'])\n\ng = sns.countplot(train['Vehicle_Damage'],palette=sns.color_palette(\"Set2\"), ax=ax[0])\nfor i in g.patches:\n    g.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\n\n\nh = sns.countplot(train['Vehicle_Damage'], hue = train['Response'],palette=sns.color_palette(\"husl\", 8), ax=ax[1])\nfor i in h.patches:\n    h.annotate(format(i.get_height(), ',.0f'), (i.get_x() + i.get_width() \/ 2., i.get_height()), \n                ha = 'center', \n                va = 'center', \n                size=15,\n                xytext = (0, 10), \n                textcoords = 'offset points',\n                color='black',\n                fontsize=\"15\",\n                fontweight=\"bold\")\n\nplt.suptitle('Response to Vehicle Damage',y=1, fontsize=24,color='dodgerblue',fontweight='bold')\n\nfig.tight_layout()\n\nplt.savefig('.\/vehicle-damage.jpg')\nplt.show();","e0714752":"corr_= train.corr().round(3)\nmask = np.zeros_like(corr_)\n    \nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(21, 10))\n    ax = sns.heatmap(corr_, annot=True, cmap = \"BuPu\")\n\nplt.tight_layout;\n# plt.savefig('fig\/matrix correlation.png');","aca039b8":"# Finding Missing Value\ndata_missing_value = train.isnull().sum().reset_index()\ndata_missing_value.columns = ['feature','missing_value']\ndata_missing_value = data_missing_value[data_missing_value['missing_value'] > 0]\n\ndata_missing_value","ec49f789":"train.duplicated().sum()","322be379":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nss = StandardScaler()\n\nss_list = [\n    'Annual_Premium',\n    'Vintage',\n]\n\nfor x in ss_list :\n    train[[x]] = ss.fit_transform(train[[x]])","5897d9dc":"gd = {'Male' : 0, 'Female' : 1}\npi = {0 : 'No', 1 : 'Yes'}\ntrain['Gender'] = train['Gender'].map(gd)\ntrain['Previously_Insured'] = train['Previously_Insured'].map(pi)\ntrain","5338001d":"# sns.boxplot(np.log(train['Annual_Premium']), orient='v')\n# train['Annual_Premium'].describe()","2cf2033b":"train_dummies = pd.get_dummies(train[[\n    'Vehicle_Damage',\n    'Previously_Insured',    \n    'Vehicle_Age'\n]])\n# , drop_first=True\ntrain_d = pd.concat([train, train_dummies], axis=1)\ntrain_d.head()","c3960bfc":"train_d=train_d.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\n\ntrain_d['Vehicle_Age_lt_1_Year']=train_d['Vehicle_Age_lt_1_Year'].astype('int')\ntrain_d['Vehicle_Age_gt_2_Years']=train_d['Vehicle_Age_gt_2_Years'].astype('int')\ntrain_d['Vehicle_Damage_Yes']=train_d['Vehicle_Damage_Yes'].astype('int')","8639bf73":"train_d = train_d.drop([\n    'id', \n    'Vehicle_Age',\n    'Vehicle_Damage',\n    'Previously_Insured',\n    \n    'Vehicle_Damage_No',    \n    'Vehicle_Age_1-2 Year'\n    \n], axis=1)\ntrain_d.head()","2d454e47":"train_pp = train_d\n\ny = train_pp['Response'].values\nX = train_pp.drop(labels = ['Response'], axis = 1)\nprint(\"Shape of X is {} and that of y is {}\".format(X.shape, y.shape))\n\n# Splitting the dataset \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint('Shape of training set ', X_train.shape)\nprint('Shape of test set ', X_test.shape)","e9e36e83":"classifications = [\n    LogisticRegression(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\n]\n\nresult_model = pd.DataFrame(columns = ['Method', 'roc_auc_score'])\nresult_model","d5e8a369":"for model in classifications:\n    model.fit(X_train, y_train)\n    y_score = model.predict_proba(X_test)[:,1]\n    \n    method = str(type(model)).split('.')[-1][:-2]\n    \n    #roc_auc_score\n    roc_auc_score_ = roc_auc_score(y_test, y_score)\n    roc_auc_score_ = roc_auc_score_.item()\n    \n    result_model = result_model.append({\n        'Method': method,\n        'roc_auc_score': roc_auc_score_,\n    },ignore_index=True)\n    \nresult_model","2df84bbf":"rf = XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\nrf.fit(X_train, y_train)\n\nkfold = model_selection.KFold(n_splits=10, random_state=41)\n\n# Get score:\nresults_k = model_selection.cross_val_score(rf, X, y, cv=kfold, scoring='roc_auc')\nresults_k","2d65b45f":"from sklearn.model_selection import StratifiedKFold\n\nroc_auc_list = []\nroc_auc_holdout = []\nroc_auc_train = []\nfolds = []\nmodel = XGBClassifier(max_depth= 2, eta= 1, objective= 'binary:logistic')\nkfold = KFold(n_splits=10, random_state=41)\nfor i, (train_index, test_index) in enumerate(kfold.split(X_train)):\n    X1_train, X1_valid = X.iloc[train_index], X.iloc[test_index]\n    y1_train, y1_valid = y[train_index], y[test_index]\n    model.fit(X1_train, y1_train)\n    train_pred = model.predict_proba(X1_train)[:,1] # 70%\n    #Measure of the fit of your model.\n    pred = model.predict_proba(X1_valid)[:,1] # 10%\n    # DATA WHICH MODEL HAS NOT SEEN\n    pred_holdout = model.predict_proba(X_test)[:,1] # 20%\n    \n    print('Prediction length on validation set, XGBoost Classifier, fold ', i, ': ', len(pred))\n\n    folds.append(i)\n    roc_auc_list.append(roc_auc_score(y1_valid, pred))\n    roc_auc_holdout.append(roc_auc_score(y_test, pred_holdout))\n    roc_auc_train.append(roc_auc_score(y1_train, train_pred))","bc2a8dd8":"roc_auc_train # train","91369dcf":"roc_auc_holdout # test","15cbdc23":"roc_auc_list # val","7945e6fc":"# import matplotlib as mpl\n# matplotlib.rcParams.update(mpl.rcParamsDefault)","c2e8a78f":"rg = np.arange(0.840,0.900,0.005)\n\ntrain_mean = np.mean(roc_auc_train)\ntest_mean = np.mean(roc_auc_holdout)\nval_mean = np.mean(roc_auc_list)\n\ntrain_std = np.std(roc_auc_train)\ntest_std = np.std(roc_auc_holdout)\nval_std = np.std(roc_auc_list)\n\nplt.style.use('tableau-colorblind10')\n\nfig, ax = plt.subplots(figsize=(20,10))\nax.plot(roc_auc_train, label='Train', marker='o', linestyle='-.')\nax.plot(roc_auc_holdout, label='Test', marker='o', linestyle=':')\nax.plot(roc_auc_list, label='Val', marker='o', linestyle='--')\n\ntext_m = '''\n    * Train Mean : ''' + str(format(train_mean, '.5f')) + '''\n    * Test Mean : ''' + str(format(test_mean, '.5f')) + ''' \n    * Val Mean : ''' + str(format(val_mean, '.5f')) + '''     \n'''\n\nax.text(6,0.841,text_m,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n\n\ntext_s = '''\n    * Train Standard Deviation : ''' + str(format(train_std, '.5f')) + '''\n    * Test Standard Deviation : ''' + str(format(test_std, '.5f')) + ''' \n    * Val Standard Deviation : ''' + str(format(val_std, '.5f')) + '''     \n'''\n\nax.text(0.5,0.841,text_s,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n\n\nax.set_xlabel('No of variable at each split', fontsize=18, labelpad=20)\nax.set_ylabel('ROC_AUC Score', fontsize=18, labelpad=10)\n\nax.set_title('XGBoost - Train, Test, Val Error', pad=20, fontsize=30)\n\nax.legend()\nax.set_yticks(rg)\n\nsns.despine()\n\nplt.savefig('.\/xgb-ttv.jpg')\n\nplt.tight_layout()\n\nplt.show();","f15c61e2":"#\nclf = XGBClassifier()\nclf.fit(X_train, y_train)\n\n#\nclf.feature_importances_\n\n#\nfeature_importances = pd.DataFrame(clf.feature_importances_,\n                                   index = X.columns,\n                                   columns=['importance']).sort_values('importance', ascending=False)\nfeature_importances\n\nfig, ax = plt.subplots(1,1, figsize=(10,15))\nsns.barplot(x='importance', y='index', color='#800000',data=feature_importances.reset_index());\n\nplt.title('Feature Importance', fontsize=30, pad=20)\n\n\nplt.savefig('.\/feature-importance.jpg')\nplt.tight_layout()\nplt.show();","523c0ae5":"# from sklearn.model_selection import XGBClassifier\n\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'max_depth': [10,15],\n#     'max_features': [2, 3],\n#     'min_samples_leaf': [3, 4, 5],\n#     'min_samples_split': [3,4,5],\n#     'n_estimators': [100, 200, 300]\n# }\n# # Create a based model\n# rf = RandomForestClassifier()\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1, verbose = 2)\n\n# # Fit the grid search to the data\n# grid_search.fit(X_train,y_train)","8cb8abb3":"# grid_search.best_estimator_","25e11e54":"# rff = RandomForestClassifier(max_depth=10, max_features=2, min_samples_leaf=5,\n#                        min_samples_split=3)\n# rff.fit(X_train, y_train)\n# y_pred = rff.predict_proba(X_test)\n\n# print('Random Forest Classifier ', roc_auc_score_)","1ff2c96f":"# result_model","39b641f9":"### 4.3.1. Numerical Data","4078968b":"### 5.1.6. Rename and Casting Feature","564a97e1":"## 5.2. Splitting Values","afd72b56":"### 5.1.7. Drop Feature","91559aa8":"# 2. Data Collection","22817882":"#### 4.3.1.2. Visualize Previously Insured","9ada3368":"![data-description.png](attachment:data-description.png)","1f69a22d":"## 4.4. Multivariate Analysis","5cb81501":"### 5.1.4. Reformat Label","57f6d128":"## 3.1. General Information","7936bc35":"## 4.2. Grouping Feature","f90180aa":"# 8. Tuning Hyperparameter (One Time Running)","bf829e49":"#### 4.3.1.4. Visualize Vintage","861ba7a7":"Target Output : Feature <strong>RESPONSE<\/strong>","9d44272a":"## 6.3. Cross Validation","0f3caecb":"### 5.1.2. Duplicate Value","d437b3b6":"## 6.5. Visualize Train, Test, Val Score","3d4e086f":"# 1. Data Description","1b7b4343":"## 5.1. Feature Engineering","a639b50e":"## 6.2. Modeling Process","5eb3f410":"# 5. Pre-Processing","c7566645":"### 5.1.5. One Hot Encoding","a497ebd8":"# 7. Feature Importance","9f19f3d4":"# 4. Exploratory Data Analyst","3a7174f0":"### 4.1.1. Numerical Data","893486c5":"## 3.3. Non-Numerical data","58f41023":"# 3. Data Understanding","3011402a":"## 3.2. Numerical Data","13cce877":"#### 4.3.1.6. Visualize Region Code","4e6bbd12":"## 6.4. Train, Test, Val Score","887c3f34":"### 4.1.2. Non-Numerical Data","5b077428":"#### 4.3.1.3. Visualize Age","acc1007f":"#### 4.3.1.1. Visualize Driving License","6f790202":"#### 4.3.1.5. Visualize Annual Premium","5146ac4d":"## 4.1. Statistika Deskriptif","a479b864":"## 4.3. Univariate Analysis","95f0a99d":"#### 4.3.2.2. Visualize Vehicle Age","40ee715e":"## 6.1. Define Model","a58c9f52":"### 5.1.1. Missing Value","21c315a5":"### 4.3.2. Non-Numerical Data","1095aee4":"# 6. Modeling","ce89d3e4":"#### 4.3.2.1. Visualize Gender","7cb6e868":"#### 4.3.2.3. Visualize Vehicle Damage","ec99cc5e":"### 5.1.3. Scaling Use StandarScaler"}}