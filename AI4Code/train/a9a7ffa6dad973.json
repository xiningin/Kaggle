{"cell_type":{"00a63c08":"code","aa6d657b":"code","624e0d0b":"code","cafbda13":"code","2dd16ae9":"code","c3659ed6":"code","c105ed5b":"code","4f151afe":"code","9af8708f":"code","3e2740d7":"code","6441db4f":"code","ad29c0ad":"code","9bb49239":"code","61d4c544":"code","d3193a24":"code","23808778":"code","864a630d":"code","4c96506f":"code","de068717":"code","1325c585":"code","2db95f43":"code","68842fa0":"code","5b15734e":"markdown","da3914eb":"markdown","6019bb81":"markdown","af1cb1e0":"markdown","b34091e2":"markdown","06ef6316":"markdown"},"source":{"00a63c08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa6d657b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nfrom scipy import stats\n\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, GridSearchCV, StratifiedKFold\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsRegressor, KernelDensity, KDTree\nfrom sklearn.metrics import *\n\nfrom imblearn.over_sampling import SMOTENC,SMOTE\n","624e0d0b":"maindf=pd.read_csv(\"..\/input\/imbalanced-data-practice\/aug_train.csv\")\nprint(\"### Head ### \\n\",maindf[0:5],\"\\n\")\nprint(\"### Tail ### \\n\",maindf[len(maindf)-5:len(maindf)])\n","cafbda13":"print(maindf.info())\nprint(maindf.describe())\n","2dd16ae9":"cateogrical_cols = [cols for cols in maindf.columns if maindf[cols].dtypes =='object']\nprint('Categories', cateogrical_cols)\n\nnumeric_cols = [cols for cols in maindf.columns if cols not in cateogrical_cols]\nprint('Numerics', numeric_cols)\n# transform cateogrical cols to lables by label encoder\n\n\n\nfor cols in cateogrical_cols:\n    le=LabelEncoder()\n    le.fit(list(maindf[cols].astype('str')))\n    maindf[cols] = le.transform(list(maindf[cols].astype(str))) \n","c3659ed6":"maindf[0:3]","c105ed5b":"maindf=maindf.drop('id',1)\ntarget=maindf.pop(\"Response\")\n","4f151afe":"plt.figure(figsize=(15, 12))\nsns.heatmap(pd.concat([maindf, target], axis=1).corr(),annot=True , cmap='vlag') ","9af8708f":"maindf","3e2740d7":"target","6441db4f":"X_train, X_test, y_train, y_test = train_test_split(\n    maindf, target, test_size=0.33, random_state=42)\n","ad29c0ad":"clf0=RandomForestClassifier()\nmodel = clf0.fit(X_train,y_train)\npred_y0=model.predict(X_test)\naccuracy_score(y_test, pred_y0)","9bb49239":"from imblearn.ensemble import BalancedRandomForestClassifier\nclf1=BalancedRandomForestClassifier(sampling_strategy=0.2)\nmodel = clf1.fit(X_train,y_train)\npred_y2=model.predict(X_test)\naccuracy_score(y_test, pred_y2)","61d4c544":"X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\nclf2=RandomForestClassifier()\nmodel2=clf2.fit(X_resampled, y_resampled)\nperd_y3=model.predict(X_test)\naccuracy_score(y_test,perd_y3)","d3193a24":"# we will use SMOTE random classifier\n\ntrain=pd.read_csv(\"..\/input\/imbalanced-data-practice\/aug_train.csv\")\ntest=pd.read_csv(\"..\/input\/imbalanced-data-practice\/aug_test.csv\")","23808778":"for c in cateogrical_cols:\n    le=LabelEncoder()\n    le.fit(list(train[c].astype('str')) + list(test[c].astype('str')))\n    train[c] = le.transform(list(train[c].astype(str))) \n    test[c] = le.transform(list(test[c].astype(str))) \ntrain.head()\n","864a630d":"final_y=train.pop(\"Response\")\nfinal_X=train.drop(\"id\",1)\n","4c96506f":"testing=test.drop(\"id\",1)\ntesting","de068717":"final_X_resampled, final_y_resampled = SMOTE().fit_resample(final_X, final_y)\nfinal_clf=RandomForestClassifier()\nfinal_model=final_clf.fit(final_X_resampled, final_y_resampled)\nprediction=model.predict(testing)\n","1325c585":"prediction","2db95f43":"to_submission=pd.DataFrame(list(zip(test['id'],prediction)),columns=[\"id\",\"predict\"])","68842fa0":"to_submission.to_csv(\"submission.csv\",header=True,index=False)","5b15734e":"![vintage user.JPG](attachment:f5dd4f5a-7863-4021-bf8e-5d0a1813c69d.JPG)","da3914eb":"### Creataing Bar graph with %\n1. Create groups for response (target variable),Previously Insured,Driving license,Vechicle age, Vechicle damage,Gender in data the section.(available near the small drop down in each columns )\n2. Now bring response(group) to coloumn section. Make sure that 'aggregate' is turned on in 'analysis' tab available in menu bar\n3. Now bring the number of records in row section. By  default, it create a bar graph. We can also use pie chart\n4. Right click on the bar graph and select 'mark label', and turn on Lables to 'always show'\n5. To show different colors, we can drag and drop 'response group' field to colors section in the 'marks' tab \n![target response.JPG](attachment:1401716b-3c57-4ec2-95c6-572591c15417.JPG)","6019bb81":"Using this, going to implement this as a end to end project wheather to provide or they will take up the loan or not (yes\/no)","af1cb1e0":"Creating a annual preimum and the number of records within the bin\n1. Create bin for annual count\n2. Use number of records and change to COUNT \n3. For top three bars, we will show the count by enabling the mark label to always show\n![anuaal new.JPG](attachment:12a03a0e-d837-4659-ac5f-011d7f5f0909.JPG)\nAnual premium with 28k is the highest","b34091e2":"## visulaising data in Tableau","06ef6316":"# Load the data"}}