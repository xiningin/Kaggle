{"cell_type":{"62d8817e":"code","7b94a3c3":"code","523bd4c7":"code","ea235504":"code","c9f6b559":"code","ceb4437a":"code","ce529981":"code","63d38849":"code","9d53a472":"code","f8533fb2":"code","a689530e":"code","5cecec45":"code","3643d54f":"code","63878329":"code","0365124b":"code","e453996b":"code","a0b8590b":"code","fa08683e":"code","b27ab4b3":"code","7298ff4c":"code","cebd92d2":"markdown","b5f0f28b":"markdown","f481edc3":"markdown","ac664253":"markdown","9fc8ba0b":"markdown","5ab3fd62":"markdown","d1e68ae0":"markdown","09feb59b":"markdown","b12bb688":"markdown","2b74ffd3":"markdown","d4dd3c5c":"markdown","b756ab12":"markdown","340915cf":"markdown","b46d882e":"markdown"},"source":{"62d8817e":"import pandas as pd\nimport numpy as np\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torchvision import transforms\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')","7b94a3c3":"if torch.cuda.is_available():\n    current_device = torch.cuda.current_device()\n    torch.cuda.set_device(current_device)\n    device = torch.device('cuda:{}'.format(current_device))\n    print('Using GPU: {}'.format(torch.cuda.get_device_name(current_device)))\nelse:\n    device = torch.device('cpu')","523bd4c7":"test_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","ea235504":"train_df.head()","c9f6b559":"test_df.head()","ceb4437a":"Y = train_df.label.values\nX = train_df.loc[:, train_df.columns != 'label'].values \/ 255\nX_test = test_df.values \/ 255","ce529981":"train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size = 0.2, random_state = 42) ","63d38849":"trainTorch_x = torch.from_numpy(train_x).type(torch.FloatTensor)\ntrainTorch_y = torch.from_numpy(train_y).type(torch.LongTensor)\n\n\nvalTorch_x = torch.from_numpy(val_x).type(torch.FloatTensor)\nvalTorch_y = torch.from_numpy(val_y).type(torch.LongTensor) \n\ntestTorch_x = torch.from_numpy(np.array(X_test)).type(torch.FloatTensor)","9d53a472":"train = torch.utils.data.TensorDataset(trainTorch_x, trainTorch_y)\nval = torch.utils.data.TensorDataset(valTorch_x, valTorch_y)\ntest = torch.utils.data.TensorDataset(testTorch_x)","f8533fb2":"train_loader = DataLoader(train, batch_size = 100, shuffle = False)\nval_loader = DataLoader(val, batch_size = 100, shuffle = False)\ntest_loader = DataLoader(test, batch_size = 100, shuffle = False)","a689530e":"randomlist = []\nfor i in range(0,9):\n    n = random.randint(0,len(X))\n    randomlist.append(n)\n\nfig = plt.figure(figsize=(15,8))\ngs1 = gridspec.GridSpec(3, 3)\naxs = []\n\nfor num in range(len(randomlist)):\n    axs.append(fig.add_subplot(gs1[num - 1]))\n    axs[-1].imshow(X[randomlist[num]].reshape(28,28))\n    axs[-1].set_title(\"Actual: \" + str(Y[randomlist[num]]))\nfig.subplots_adjust(hspace=0.3)\nplt.show()","5cecec45":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.c1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(5,5), stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size=(2,2))\n        self.dropout1 = nn.Dropout(0.2)\n        self.c2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size=(2,2))\n        self.dropout2 = nn.Dropout(0.2)\n        self.fc1 = nn.Linear(800, 256)\n        self.dropout3 = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(256, 10)\n        \n    def forward(self, x):\n        \n        output = self.c1(x) \n        output = self.relu1(output) \n        output = self.maxpool1(output)\n        output = self.dropout1(output) \n        output = self.c2(output) \n        output = self.relu2(output) \n        output = self.maxpool2(output)\n        output = self.dropout2(output) \n        output = output.view(output.size(0), -1) \n        output = self.fc1(output)\n        output = self.dropout3(output)\n        output = self.fc2(output)\n        return output\n\nmodel = Net()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0.0002)\ncriterion = nn.CrossEntropyLoss()","3643d54f":"if torch.cuda.is_available():\n    print(\"Model will be training on GPU\")\n    model = model.cuda()\n    criterion = criterion.cuda()\nelse:\n    print(\"Model will be training on CPU\")","63878329":"model.train()\nn_iterations = 0\nprint_every = 50\nsteps = 0\ntrain_losses, val_losses = [], []\ntotal_epochs = 50\nfor epoch_number in range(total_epochs):\n    running_loss = 0\n    for i, (images, labels) in enumerate(train_loader):\n        steps += 1\n        data, target = Variable(images.view(100,1,28,28)), Variable(labels)\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        model.zero_grad()\n        loss = criterion(output, target)\n\n        n_iterations += 1\n        \n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        if steps % print_every == 0:\n            val_loss = 0\n            accuracy = 0\n            \n            \n            # Turn off gradients for validation\n            with torch.no_grad():\n                model.eval()\n                for images, labels in val_loader:\n                    data, target = Variable(images.view(100,1,28,28), volatile=True), Variable(labels)\n\n                    if torch.cuda.is_available():\n                        data = data.cuda()\n                        target = target.cuda()\n                    \n                    log_ps = model(data)\n                    loss = criterion(log_ps, target)\n                    val_loss += loss.item()\n\n                    ps = torch.exp(log_ps)\n                    \n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == target.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n            model.train()\n\n            train_losses.append(running_loss\/len(train_loader))\n            val_losses.append(val_loss \/ len(val_loader))\n\n    print(\"Epoch: {}\/{}.. \".format(epoch_number + 1, total_epochs),\n                  \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n                  \"Val Loss: {:.3f}.. \".format(val_losses[-1]),\n                  \"Val Accuracy: {:.3f}\".format(accuracy\/len(val_loader)))\n","0365124b":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(y = np.array(train_losses),\n                    mode='lines+markers',\n                    name='Training loss'))\nfig.add_trace(go.Scatter(y = np.array(val_losses),\n                    mode='lines+markers',\n                    name='Validation loss'))\n\nfig.update_layout(title_text = 'Loss of model', xaxis = dict(tickmode = 'linear', dtick = 1))\nfig.update_xaxes(\n    range=(1, total_epochs),\n    constrain='domain'\n)\n\nfig.show()","e453996b":"model.eval()\nval_pred = torch.LongTensor().cuda()\n\nfig = plt.figure(figsize=(20,8))\ngs1 = gridspec.GridSpec(6, 6)\naxs = []\n\ni_graph = 0\nbatch_tot = 0\n\nfor images, labels in val_loader:\n\n    batch_tot += 100\n    data, target = Variable(images.view(100,1,28,28), volatile=True), Variable(labels)\n    if torch.cuda.is_available():\n        data = data.cuda()\n        target = target.cuda()\n    log_ps = model(data)\n    ps = torch.exp(log_ps)\n    top_p, top_class = ps.topk(1, dim=1)\n    val_pred = torch.cat((val_pred, top_class), dim=0)\n    diff = torch.eq(top_class.flatten(), target)\n    diff_index = (diff == torch.tensor(False)).nonzero().flatten()\n    for ind in diff_index:\n        if i_graph == 36:\n            break\n        image = images[ind]\n        prediction = top_class[ind]\n        actual = target[ind]\n        axs.append(fig.add_subplot(gs1[i_graph - 1]))\n        axs[-1].imshow(image.reshape(28,28))\n        axs[-1].set_title(\"A: \" + str(int(actual.item())) + \" \" + \"P: \" + str(prediction.item()))\n        i_graph += 1\n    \nfig.subplots_adjust(hspace=1)\nplt.show()","a0b8590b":"model.eval()\ntest_pred = torch.LongTensor().cuda()\n\nfig = plt.figure(figsize=(20,8))\ngs1 = gridspec.GridSpec(6, 6)\naxs = []\nrandomlist = []\n\nfor i in range(0,36):\n    n = random.randint(0, len(X_test))\n    randomlist.append(n)\n    \ni_graph = 0\nbatch_tot = 0\nfor images in test_loader:\n    images = images[0]\n    batch_tot += 100\n    data, target = Variable(images.view(100,1,28,28), volatile=True), Variable(labels)\n    if torch.cuda.is_available():\n        data = data.cuda()\n        target = target.cuda()\n    log_ps = model(data)\n    ps = torch.exp(log_ps)\n    \n    top_p, top_class = ps.topk(1, dim=1)\n    test_pred = torch.cat((test_pred, top_class), dim=0)\n    if any(x <= batch_tot for x in randomlist):\n        filtered_list = list(filter(lambda x: (x <= batch_tot), randomlist))\n        \n        for element in range(len(filtered_list)):\n            num = filtered_list[element] if filtered_list[element] < 100 else 99 if filtered_list[element] == batch_tot else batch_tot - filtered_list[element]\n\n            axs.append(fig.add_subplot(gs1[i_graph - 1]))\n            axs[-1].imshow(data.cpu()[num].reshape(28,28))\n            axs[-1].set_title(\"Prediction: \" + str(top_class[num].item()))\n            i_graph += 1\n        randomlist = list(filter(lambda x: (x > batch_tot), randomlist))  \n    \nfig.subplots_adjust(hspace=1)\nplt.show()","fa08683e":"dataset = pd.DataFrame({'ImageId': list(range(1, len(X_test) + 1)), 'Label': torch.flatten(test_pred).tolist()}, columns=['ImageId', 'Label'])","b27ab4b3":"dataset.head()","7298ff4c":"dataset.to_csv(\"submission.csv\", index=False)","cebd92d2":"Let's investigate the errors.","b5f0f28b":"<a id=\"4\"><\/a>\n# Results","f481edc3":"<a id=\"1\"><\/a>\n# Import libraries","ac664253":"<a id=\"2\"><\/a>\n# Preprocess data","9fc8ba0b":"<a id=\"5\"><\/a>\n# Error Analysis","5ab3fd62":"# **Digit Recognizer with Pytorch**\n\n### In this kernel, I will use Pytorch for identifying digits from images. It is first time I'm building a model with Pytorch. So if you have any suggestions, advice or correction please don't hesitate to write them.\n\n    \n<center><img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3004\/logos\/header.png?t=2018-11-14-20-12-43\"><\/center>","d1e68ae0":"# Introduction\n\nThe data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.","09feb59b":"<a id=\"6\"><\/a>\n# Making predictions on test data","b12bb688":"# Table of contents:\n\n* [1. Import libraries](#1)\n* [2. Preprocess data](#2)\n* [3. Modelling](#3)\n* [4. Results](#4)\n* [5. Error analysis](#5)\n* [5. Making predictions on test data](#6)","2b74ffd3":"<a id=\"3\"><\/a>\n# Modelling","d4dd3c5c":"**Thank You!** If you have any suggestion or advice or feedback, I will be very appreciated to hear them.","b756ab12":"I choosed to split the train set in two parts : a small fraction (20%) became the validation set which the model is evaluated and the rest (80%) is used to train the model.","340915cf":"Visualising the image and looking at the label from training dataset for getting better sense","b46d882e":"We perform a grayscale normalization to reduce the effect of illumination's differences."}}