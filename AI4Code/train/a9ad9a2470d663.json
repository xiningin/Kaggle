{"cell_type":{"6dd32d4d":"code","c3e4c322":"code","03a7ba76":"code","de489036":"code","20cb89e4":"code","d3d67f1b":"code","53226a3f":"code","7e0e810d":"code","ef96e41c":"code","70eb6efb":"code","df4e2666":"code","226ce06a":"code","93f81685":"code","a2cba551":"code","ab70eb29":"code","9e588495":"code","225be69e":"code","466a829b":"code","cb0e694d":"code","0320fbf4":"code","acad087e":"code","4b2e54e3":"code","f8f5ac7b":"code","09d68071":"code","407f8c31":"code","4189c7fc":"code","c115ff8e":"code","26c543b0":"code","fa9ddb16":"markdown","363e6523":"markdown"},"source":{"6dd32d4d":"# import pandas and numpy\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom string import ascii_letters\n\n\n# import the os package for Kaggle\nimport os\nprint(os.listdir(\"..\/input\"))","c3e4c322":"# create dataframe\ndf = pd.read_csv(\"..\/input\/BRAZIL_CITIES.csv\", sep=\";\", decimal=\",\")","03a7ba76":"# view dataframe\ndf.sample(25)","de489036":"# get dataframe shape\ndf.shape","20cb89e4":"# create backup copy\ndf_copy = df.copy(True)","d3d67f1b":"''' select the columns you're interested in exploring. These are the one's I chose. \nif a model was being generated for some purpose, feature selection methods should be employed,\nhowever, I will just being doing cleaning, vis and exploration '''\n\ncolumns = ['CITY', 'STATE', 'CAPITAL', 'IBGE_RES_POP', 'IBGE_RES_POP_BRAS','IBGE_RES_POP_ESTR','IBGE_DU','IBGE_DU_URBAN','IBGE_DU_RURAL', 'IBGE_POP','IBGE_1','IBGE_1-4','IBGE_5-9','IBGE_10-14','IBGE_15-59','IBGE_60+','IBGE_PLANTED_AREA','IDHM','LONG','LAT','ALT','ESTIMATED_POP','GDP_CAPITA','Cars','Motorcycles','UBER','MAC','WAL-MART','BEDS']","53226a3f":"# create reduced dataframe and check shape\nr_df = df[columns]\nr_df.shape","7e0e810d":"# create a seaborn pairplot\npp = sns.pairplot(r_df)","ef96e41c":"# the pairplot is still huge and difficult to find individual relationships in, let's try a correlation matrix for narrowing down our search\ncorr = r_df.corr()","70eb6efb":"# I prefer one sided matricies so create a mask\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# set up figure \nf, ax = plt.subplots(figsize=(15, 15))\n\ncmap = sns.diverging_palette(220, 20, as_cmap=True)\n\nsns.heatmap(corr, mask=mask,cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","df4e2666":"# let's look at what's in the uber column\nr_df.UBER","226ce06a":"# there are a lot of nans, possibly in place of zeros, let's check\ndf_copy.UBER.value_counts()","93f81685":"# I was right! let's fix that\nr_df.UBER.replace({np.nan:0}, inplace=True)\nr_df.UBER.value_counts()","a2cba551":"# let's see if that does anything to our matrix\ncorr = r_df.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(15, 15))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask,cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","ab70eb29":"# let's investigate the strongest correlation first\nsns.set_style('dark')\nsns.scatterplot(x=r_df.IDHM, y=r_df.LAT)","9e588495":"# map of lat and long with IDHM detemining size\nf, ax = plt.subplots(figsize=(8, 8))\nsns.scatterplot(x=r_df.LONG, y=r_df.LAT, size=r_df.IDHM)","225be69e":"# it's hard to see any trends here, let's add color to get a better idea\nf, ax = plt.subplots(figsize=(8, 8))\nsns.scatterplot(x=r_df.LONG, y=r_df.LAT, size=r_df.IDHM, hue=r_df.IDHM)","466a829b":"# let's see if we can spot any capitals in there\nf, ax = plt.subplots(figsize=(8, 8))\nmarkers = {0:'o', 1:'s'}\nsns.scatterplot(x=r_df.LONG, y=r_df.LAT, size=r_df.IDHM, hue=r_df.IDHM,style=r_df.CAPITAL, markers=markers)","cb0e694d":"# that's not helpful, let's try an overlay    \nf, ax = plt.subplots(figsize=(8, 8))\nsns.scatterplot(x=r_df.LONG, y=r_df.LAT, size=r_df.IDHM, hue=r_df.IDHM)\nsns.scatterplot(x=r_df[r_df.CAPITAL==1].LONG, y=r_df[r_df.CAPITAL==1].LAT, s=100)","0320fbf4":"# very cool! let's give GDP per capita the same treatment real quick\nf, ax = plt.subplots(figsize=(8, 8))\nsns.scatterplot(x=r_df.LONG, y=r_df.LAT, size=r_df.GDP_CAPITA, hue=r_df.GDP_CAPITA)","acad087e":"# that's not what I expected, let's look at the data directly\nr_df.GDP_CAPITA\n# looks like the color palette binned the values,possibly obscuring some insights","4b2e54e3":"# let's take a look at the distribution, after taking care of nans\nf, ax = plt.subplots(figsize=(12, 8))\ngdp = r_df.GDP_CAPITA.dropna()\nsns.distplot(gdp)","f8f5ac7b":"# it looks like gdp is heavily right skewed with a massive tail. \n# it seems likely that those massive outliers are errors, and could be removed in some cases\ngdp.describe()","09d68071":"# let's look at how UBER is doing\nf, ax = plt.subplots(figsize=(12, 8))\nsns.countplot(r_df['UBER'])\n","407f8c31":"f, ax = plt.subplots(figsize=(8, 8))\nsns.scatterplot(x=r_df[r_df.UBER==0].LONG, y=r_df[r_df.UBER==0].LAT)\nsns.scatterplot(x=r_df[r_df.UBER==1].LONG, y=r_df[r_df.UBER==1].LAT)","4189c7fc":"# let's see how cars in cities with and without uber look\nf, ax = plt.subplots(figsize=(16, 12))\nsns.boxplot(y=r_df['Cars'], x=r_df['UBER'])","c115ff8e":"# can removing some of the really high outlier give us a better picture\nf, ax = plt.subplots(figsize=(16, 12))\nubers, car_vals = r_df[r_df.Cars <100000].UBER, r_df[r_df.Cars <100000].Cars\nsns.boxplot(ubers, car_vals )\n# there are way more cars in cities with uber","26c543b0":"# comparing distributions of cars with and without UBER\nf, ax = plt.subplots(figsize=(16, 12))\nsns.distplot(r_df[(r_df.Cars < 100000) & (r_df.UBER==0)].Cars)\nsns.distplot(r_df[(r_df.Cars < 100000) & (r_df.UBER==1)].Cars, bins=20)","fa9ddb16":"**Exploratory Data Analysis and Visualization**","363e6523":"Future questions\n- Explore population data\n- See how population varies with other supplied categorical values \n- look at how gdp per capita varies with presence of other industries\n- add back in all variables\/subset with different variables and create more correlation matricies to explore additional trends"}}