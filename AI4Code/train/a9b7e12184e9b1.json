{"cell_type":{"5e080088":"code","5c6ebbb6":"code","2c718033":"code","a685cfaa":"code","4bcf5440":"code","0848b183":"code","9f8ce654":"code","909754a9":"code","d1b7b85d":"code","21510630":"code","28b94962":"code","14b66bbf":"markdown","72b578d9":"markdown","aa713465":"markdown","e9286201":"markdown","2ce9e2c4":"markdown","6c1eff17":"markdown","d12e4952":"markdown","85acee6a":"markdown"},"source":{"5e080088":"import numpy as np \nimport pandas as pd\nimport tensorflow\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nimport tensorflow_addons as tfa\nfrom sklearn.metrics import log_loss\nimport tensorflow as tf\n","5c6ebbb6":"data_train = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ndata_train_target_ns = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\ndata_train_target_s = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\nsub = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')","2c718033":"display(data_train.head())\nprint(\"SHAPE of training data--\",data_train.shape)","a685cfaa":"display(data_test.head())\nprint(\"SHAPE of test data--\",data_test.shape)","4bcf5440":"def preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n    del df['sig_id']\n    return df\n\ntrain = preprocess(data_train)\ntest = preprocess(data_test)\n\ndel data_train_target_s['sig_id']","0848b183":"def create_model(num_columns):\n    model = Sequential()\n    model.add(Input(num_columns))\n    model.add(BatchNormalization())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.8))\n    \n    model.add(Dense(2048, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    \n    model.add(Dense(206, activation='sigmoid'))\n    \n    optimizer = tfa.optimizers.Lookahead('adam',sync_period=10)\n    \n    model.compile(optimizer=optimizer,\n                  loss='BinaryCrossentropy', \n                  metrics=['accuracy'])\n    \n    model.summary()\n    return model","9f8ce654":"def metric(y_true, y_pred):\n    metrics = []\n    for _target in data_train_target_s.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)","909754a9":"N_STARTS = 4\ntf.random.set_seed(42)\n\nres = data_train_target_s.copy()\nsub.loc[:, data_train_target_s.columns] = 0\nsub.loc[:, data_train_target_s.columns] = 0\n\nfor seed in range(N_STARTS):\n    for n, (train_idx, test_idx) in enumerate(KFold(n_splits=5, random_state=seed, shuffle=True).split(data_train_target_s, data_train_target_s)):\n        print(f'Fold {n}')\n    \n        model = create_model(875)\n        checkpoint_path = f'repeat:{seed}_Fold:{n}.h5'\n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                     save_weights_only = True, mode = 'min')\n        model.fit(train.values[train_idx],\n                  data_train_target_s.values[train_idx],\n                  validation_data=(train.values[test_idx], data_train_target_s.values[test_idx]),\n                  epochs=25, batch_size=128,\n                  callbacks=[reduce_lr_loss, cb_checkpt], verbose=1\n                 )\n        \n        model.load_weights(checkpoint_path)\n        test_predict = model.predict(test.values)\n        val_predict = model.predict(train.values[test_idx])\n        \n        sub.loc[:, data_train_target_s.columns] += test_predict\n        res.loc[test_idx, data_train_target_s.columns] += val_predict\n        print('')\n    \nsub.loc[:, data_train_target_s.columns] \/= ((n+1) * N_STARTS)\nres.loc[:, data_train_target_s.columns] \/= N_STARTS","d1b7b85d":"print(f'OOF Metric: {metric(data_train_target_s, res)}')","21510630":"sub.loc[test['cp_type']==1, data_train_target_s.columns] = 0","28b94962":"sub.to_csv('submission.csv', index=False)","14b66bbf":"**train_features.csv** - Features for the training set. Features g- signify gene expression data, and c- signify cell viability data. cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs; cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low).<br>\n**train_targets_scored.csv** - The binary MoA targets that are scored.<br>\n**train_targets_nonscored.csv** - Additional (optional) binary MoA responses for the training data. These are not predicted nor scored.<br>\n**test_features.csv** - Features for the test data. You must predict the probability of each scored MoA for each row in the test data.<br>\n**sample_submission.csv** - A submission file in the correct format.","72b578d9":"# Mechanisms of Action (MoA) Prediction","aa713465":"## Step 1: Understanding the Data","e9286201":"## Training Model \nWe will create 4 models and each model will have 5 kfold split. In last we average out the predictions and save it to csv","2ce9e2c4":"## Creating Model ","6c1eff17":"## Loading Data","d12e4952":"## Do upvote, help me reach expert in notebooks :)","85acee6a":"### Encode cp_type, cp_dose, cp_time and remove sig_id"}}