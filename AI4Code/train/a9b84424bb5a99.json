{"cell_type":{"39d5a94f":"code","9ed235f6":"code","ae1725ff":"code","3f72311b":"code","0197f2b4":"code","58ebb49f":"code","d708bf96":"code","6c0b3f45":"markdown","c9f0d683":"markdown","95b1caa1":"markdown","17dbee02":"markdown","8f3d6728":"markdown","e34c9826":"markdown","2b662a30":"markdown","bef3c5a3":"markdown"},"source":{"39d5a94f":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn import metrics\nfrom pathlib import Path","9ed235f6":"#Path \ntrain_dir = Path('..\/input\/10-monkey-species\/training\/training\/')\ntest_dir = Path('..\/input\/10-monkey-species\/validation\/validation\/')\n\n#Images target size\nimg_width = 100\nimg_height = 100\ntarget_size = (img_width, img_height)\nchannels = 3 #RGB","ae1725ff":"#Data augmentation \ntrain_generator = ImageDataGenerator(rescale=1\/255,\n                                    rotation_range=40,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    fill_mode='nearest')\n\nvalid_generator = ImageDataGenerator(rescale = 1\/255)","3f72311b":"epochs = 20\nbatch_size = 64 \n\n#Finds images, transforms them\ntrain_data = train_generator.flow_from_directory(train_dir, target_size=target_size, batch_size=batch_size,\n                                                    class_mode='categorical')\n\ntest_data = valid_generator.flow_from_directory(test_dir, target_size=target_size, batch_size=batch_size,\n                                                    class_mode='categorical', shuffle=False)","0197f2b4":"####################\n# Model creation\n####################\n\ntrain_samples = train_data.samples\nvalid_samples = test_data.samples\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, channels)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(10, activation='softmax'))\n\n#Compile model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","58ebb49f":"#Fit the model\nmodel.fit_generator(generator=train_data,\n                    steps_per_epoch=train_samples\/batch_size,\n                    validation_data=test_data,\n                    validation_steps=valid_samples\/batch_size,\n                    epochs=epochs)","d708bf96":"#Get the true classes and the predictions for each image\ntest_steps_per_epoch = np.math.ceil(test_data.samples\/\/ batch_size+1)\npredictions = model.predict_generator(test_data, steps=test_steps_per_epoch, verbose=1)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = test_data.classes\n\n#Get label names for the final table\ncols = ['Label','Latin Name', 'Common Name','Train Images', 'Validation Images']\nlabels = pd.read_csv(\"..\/input\/10-monkey-species\/monkey_labels.txt\", names=cols, skiprows=1)\nlabels = labels['Common Name']\n\n#Create classification report\nprint(metrics.classification_report(true_classes, predicted_classes,target_names=labels))\n","6c0b3f45":"The following kernel presents the creation of a convolutional neural network (CNN) to classify images of monkeys, found in the \"10 monkeys species\" dataset. Before we begin, make sure to have GPU accelerator on as it drastically improves training speed.\n\nSo first, we import the necessary packages.","c9f0d683":"We then create our generators, which will allow us to do data augmentation and scaling of the images. Be careful to only augment training images, but rescale everything. \nAs a clarification, be mindful that the ImageDataGenerator function does not create new images. Rather, it modifies some of our current training images, so that the model is trained on a bigger variety of images. This helps in avoiding overfitting and it makes the model more apt to predict the class of new monkeys. ","95b1caa1":"Without going into the details of every layer here, a few things could be mentionned. The first convolutional layer requires an input shape, i.e. the shape of the images. Also, the last layer of this CNN uses the softmax activation function, which is appropriate when we have multiple classes, as it allows the model to calculate probabilities an image belongs to each class. Finally, the model.compile function allows us to specify how the model will learn during training. \n\nWe can then generate a fit, and evaluate performance on the validation set. ","17dbee02":"Thanks a lot for reading!","8f3d6728":"We then specify the path where the images can be found, as well as the target size for the images. ","e34c9826":"We can then import the images. The flow_from_directory function finds the images in their specified path and resizes them.","2b662a30":"We see that we have 10 classes, with more than 1000 training images and 272 images for validation of the model. We can then create the model. ","bef3c5a3":"With only 20 epochs, we manage to get an accuracy of about 60% on the validation set.\n\nFinally, we can create a table to view the accuracy of our model depending on the class, using the classification_report function from sklearn. Predictions come as arrays, with, for every image, a probability that the image belongs to a class (so 10 separate predictions). Obviosuly, the class with the highest prediction is the one chosen as the predicted class. Here is the code. "}}