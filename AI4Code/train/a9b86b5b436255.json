{"cell_type":{"f8134b67":"code","53746a5b":"code","2f562f51":"code","6c242abb":"code","ba656e76":"code","00c214de":"code","cd6614b5":"code","65a9ce93":"code","262b1266":"code","70af519b":"code","f25fa7af":"code","a9a030ad":"code","d2cf2136":"code","865f1625":"code","e95ae2c8":"code","724fd9d9":"code","ae84758b":"code","e7f2e1c4":"code","27e7170b":"code","176d7ec6":"code","cfb7dac4":"code","d59a4b96":"code","7e4752c4":"code","67831b3b":"code","65424923":"code","bb83f12c":"code","9394afc3":"code","c80cb7b0":"code","ef0a68cd":"code","0f750c19":"markdown","176dc527":"markdown","cacd7fc1":"markdown","28209045":"markdown","4771f62a":"markdown","7e215f39":"markdown","79aadba0":"markdown","67927601":"markdown","0f3c0ac6":"markdown","738401da":"markdown","62b912b4":"markdown","253f385c":"markdown","c30add36":"markdown","7b7d4aa5":"markdown"},"source":{"f8134b67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53746a5b":"df = pd.read_csv('..\/input\/glass\/glass.csv')\ndf.head()","2f562f51":"print('Number of Null Values: ',df.isnull().sum().sum())","6c242abb":"df['Type'] = df['Type'].astype('category')\nprint(df.dtypes)\ndf.describe()","ba656e76":"df['Type'].value_counts()","00c214de":"features = ['RI','Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']","cd6614b5":"plt.figure(figsize = (20,16))\nn=0\nfor i in features:\n    n+=1\n    plt.subplot(3,3,n)\n    plt.subplots_adjust(hspace = 0.3,wspace = 0.3)\n    plot = sns.barplot(x = \"Type\", y = i,ci = None, data = df)\n    for p in plot.patches:\n        plot.annotate(format(p.get_height(), '.1f'),\n                   (p.get_x() + p.get_width() \/ 2.,p.get_height()), \n                   ha = 'center', va = 'center', \n                   size=15,\n                   xytext = (0, -12), \n                   textcoords = 'offset points')\n    plt.title = ('Plot of {i}')\n    plt.xlabel = ('Type')\n    plt.ylabel = ('{i}')\nplt.show()","65a9ce93":"plt.figure(figsize=(8,8))\nsns.pairplot(df[features],palette='coolwarm')\nplt.show()","262b1266":"corr = df[features].corr()\nplt.figure(figsize=(16,16))\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           xticklabels= features, yticklabels= features, alpha = 0.7,   cmap= 'coolwarm')\nplt.show()","70af519b":"temp = pd.get_dummies(df['Type'],prefix = 'Type')\ndf = pd.concat([df,temp],axis = 1)\ndf.drop(['Type'],axis = 1,inplace = True)\ndf.head()","f25fa7af":"target = ['Type_1', 'Type_2', 'Type_3', 'Type_5', 'Type_6', 'Type_7']","a9a030ad":"# Scaling the features since, PCA is sensitive to scale\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# Separating out the features\nX = df.loc[:, features].values\n# Separating out the target\ny = df.loc[:,target].values\n# Standardizing the features\nX = scaler.fit_transform(X)\n\n# Pricipal Component Analysis\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = 4)\nprincipalComponents = pca.fit_transform(X)\npc_df = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2','pc3','pc4'])\npc_df = pd.concat([pc_df, df[target]], axis = 1)","d2cf2136":"pc_df.head()","865f1625":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report,log_loss,r2_score,accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Input\ntarget_names = target","e95ae2c8":"def eval(y_test, y_pred):\n    print('LOG LOSS: ',log_loss(y_test, y_pred))\n    print('ACCURACY SCORE: ',accuracy_score(y_test, y_pred))\n    print('R2 SCORE: ',r2_score(y_test, y_pred),'\\n')","724fd9d9":"def neigh(X_train,y_train,X_test,y_test):\n    pipe = Pipeline([('scaler', StandardScaler()), ('neigh', KNeighborsClassifier())])\n    pipe.fit(X_train, y_train)\n    y_pred = pipe.predict(X_test)\n    print('KNN_CLASSIFIER: ')\n    print(classification_report(y_test, y_pred, target_names=target_names,zero_division = 1))\n    print('PIPE SCORE: ', pipe.score(X_test, y_test))\n    eval(y_test,y_pred)\n    print(pipe.get_params())","ae84758b":"def tree(X_train,y_train,X_test,y_test):\n    pipe = Pipeline([('scaler', StandardScaler()), ('tree', DecisionTreeClassifier())])\n    pipe.fit(X_train, y_train)\n    y_pred = pipe.predict(X_test)\n    print('DECISION TREE: ')\n    print(classification_report(y_test, y_pred, target_names=target_names,zero_division = 1))\n    print('PIPE SCORE: ', pipe.score(X_test, y_test))\n    eval(y_test,y_pred)\n    print(pipe.get_params())","e7f2e1c4":"def forest(X_train,y_train,X_test,y_test):\n    #Parameter Grid\n    pipe = Pipeline([('scaler', StandardScaler()), ('forest', RandomForestClassifier())])\n    pipe.fit(X_train, y_train)\n    y_pred = pipe.predict(X_test)\n    #Evaluation Phase\n    print('RANDOM FOREST: ')\n    print(classification_report(y_test, y_pred, target_names=target_names,zero_division = 1))\n    eval(y_test,y_pred)\n    print(pipe.get_params())","27e7170b":"from keras.callbacks import EarlyStopping\n\ndef ann(X_train,y_train,X_test,y_test):\n    #Build\n    model = Sequential()\n    model.add(Input(4,))\n    model.add(Dense(units = 500,activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units = 400,activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units = 300,activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units = 200,activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(units = 6,activation = 'softmax'))\n    model.summary()\n    #Train\n    model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['categorical_accuracy'])\n    model.fit(X_train,y_train,epochs = 30, callbacks = [EarlyStopping(monitor='val_acc', patience=2)])\n    Test_Loss,Test_Accuracy = model.evaluate(X_test,y_test)\n    print('\\nTest Accuracy',Test_Accuracy)","176d7ec6":"from keras import regularizers\n\n# Performing L2 regularizer\ndef ann_L2_Reg(X_train,y_train,X_test,y_test):\n    #Build\n    model = Sequential()\n    model.add(Input(4,))\n    model.add(Dense(units = 500,activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(Dense(units = 400,activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(Dense(units = 300,activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(Dense(units = 200,activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(units = 6,activation = 'softmax'))\n    model.summary()\n    #Train\n    model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['categorical_accuracy'])\n    model.fit(X_train,y_train,epochs = 30)\n    Test_Loss,Test_Accuracy = model.evaluate(X_test,y_test)\n    print('\\nTest Accuracy',Test_Accuracy)","cfb7dac4":"# Performing L1 regularizer\ndef ann_L1_Reg(X_train,y_train,X_test,y_test):\n    #Build\n    model = Sequential()\n    model.add(Input(4,))\n    model.add(Dense(units = 500,activation = 'relu', kernel_regularizer=regularizers.l1(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(Dense(units = 400,activation = 'relu', kernel_regularizer=regularizers.l1(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(Dense(units = 300,activation = 'relu', kernel_regularizer=regularizers.l1(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(Dense(units = 200,activation = 'relu', kernel_regularizer=regularizers.l1(0.01)))\n    #model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(units = 6,activation = 'softmax'))\n    model.summary()\n    #Train\n    model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['categorical_accuracy'])\n    model.fit(X_train,y_train,epochs = 30)\n    Test_Loss,Test_Accuracy = model.evaluate(X_test,y_test)\n    print('\\nTest Accuracy',Test_Accuracy)","d59a4b96":"X = pc_df.iloc[:,:4]\ny = pc_df.iloc[:,4:]\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.33,random_state = 7)","7e4752c4":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","67831b3b":"forest(X_train,y_train,X_test,y_test)","65424923":"neigh(X_train,y_train,X_test,y_test)","bb83f12c":"tree(X_train,y_train,X_test,y_test)","9394afc3":"ann(X_train,y_train,X_test,y_test)","c80cb7b0":"ann_L2_Reg(X_train,y_train,X_test,y_test)","ef0a68cd":"ann_L1_Reg(X_train,y_train,X_test,y_test)","0f750c19":" \n # Acknowledgements\n \n* Source:\n    https:\/\/archive.ics.uci.edu\/ml\/datasets\/Glass+Identification\n* Creator:\n     B. German\n     Central Research Establishment\n     Home Office Forensic Science Service\n     Aldermaston, Reading, Berkshire RG7 4PN\n \n* Donor:\n     Vina Spiehler, Ph.D., DABFT\n     Diagnostic Products Corporation\n     (213) 776-0180 (ext 3014)","176dc527":"## Observation\n\n* All Types have the same Refractive Index and Silicon(Si)\nSilicon is a very important element in making of glass and hence it is used for the purpose.\n* Type 5 contains a significantly high amount of Pottasium(K) compared to other types and a higher level of Calcium(Ca)\nAlkali (Na, K) \u2013 lime (Ca,Mg) glass is by far the most common glass type today, and has been the most common ever since glass-blowing began in the \ufb01rst century BC in the Near East.\nAlthough glass can be produced from just two compounds, silica (SiO2) as a glass former andeither soda (Na2CO3) or potash (K2CO3) as a network modi\ufb01er or \ufb02ux, **lime (CaO) is essential as a third compound to stabilize the glass against rapid chemical attack by \ufb02uids.**\nType 5 is container glass and that is the reason why it need extra protection from rapid chemical attack in order to serve its purpose, which explains why it has higher amount of Calcium. Type 5 also contains the lowest amount of sodium, which explains why it has a higher amount of Pottasium(K)\n* Type 1 & 3 have a almost equal amount of Magnesium(Mg) than others\nMg has properties that help stabilise the Na reaction, which explains why type 1 and 3 also have similar amounts of Sodium.\n* Type 7 has a significantly high amount of Barium(Ba) than all others\n**Glass-to-metal seals are a very important element of the construction of vacuum tubes, electric discharge tubes, incandescent light bulbs**, glass encapsulated semiconductor diodes, reed switches, pressure tight glass windows in metal cases, and metal or ceramic packages of electronic components. Alkali Barium glass is bext suited for this purpose.\nType 7 is used in headlamps and hence in contains more Alkali Barium","cacd7fc1":"# Data Analysis","28209045":"Not a very evenly distributed(unfortunately)\n\nThis will look bad on the model's performance. :(","4771f62a":"# Spliting Data","7e215f39":"# Observation\n\nThe Refractive Index is correlated to the Ca Oxide Content quite heavily...\nthe increase in CaO content or R ratio, heat\u2010treated glasses exhibit direct band gap within 5.92\u20106.01 eV range. \nThe Urbach energy lies within the 0.62\u20100.86 eV range for all the heat\u2010treated glass samples.\n\nAnd it has been proved that CaO content has influence on the optical parameters of the glass.","79aadba0":"In order to visually examine correlation between features, use pairplot","67927601":"# Data\n\n**This is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)**\n\n1. Id number: 1 to 214 (removed from CSV file)\n2. RI: refractive index\n3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n4. Mg: Magnesium\n5. Al: Aluminum\n6. Si: Silicon\n7. K: Potassium\n8. Ca: Calcium\n9. Ba: Barium\n10. Fe: Iron\n11. Type of glass: (class attribute)\n       -- 1 buildingwindowsfloatprocessed \n       -- 2 buildingwindowsnonfloatprocessed \n       -- 3 vehiclewindowsfloatprocessed\n       -- 4 vehiclewindowsnonfloatprocessed (none in this database)\n       -- 5 containers\n       -- 6 tableware\n       -- 7 headlamps","0f3c0ac6":"The Dimensions of the dataset has reduced from 9 to 4, this will help our model's performance in many ways","738401da":"![Periodic_Table.png](attachment:Periodic_Table.png)","62b912b4":"# Encoding","253f385c":"From the above Description...\nON AN AVERAGE ALL THESE GLASS TYPES CONTAIN HIGH LEVELS OF SILICON(SI), MODERATE AMOUNTS OF CALCIUM(CaO),SODIUM(Na2O)...etc.\nMost of the above elements are alkali or alkali earth metals. \n\nAlkali metal oxide reduces the working temperature and plays an important role in setting the thermal expansion. If the alkali metal oxides content is above a certain limit, glasses exhibit a high coefficient of thermal expansion (Marques, 2008). \nA higher level of alkali oxide also causes an adverse effect on hydrolytic stability.\n\nLi+ forms strong bonds with the glass network and increases the acid resistance of the glass (Marques, 2008).\n\nPeuchert et al. (2004) also discussed the role of alkali metal oxides on crystallization and suggested using at least two alkali metal oxides, even in small amounts, in order to have a positive effect on resisting unwanted crystallization.\n\n[Refer](http:\/\/https:\/\/www.sciencedirect.com\/topics\/materials-science\/alkali-metal-oxide#:~:text=Properties%20of%20Glass%20Materials&text=Alkali%20metal%20oxide%20reduces%20the,expansion%20(Marques%2C%202008).)","c30add36":"# Defining the Model","7b7d4aa5":"# Principal Component Analysis"}}