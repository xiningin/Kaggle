{"cell_type":{"e8925fde":"code","a58d824a":"code","bb714d81":"code","ab3ee3d3":"code","fd7c3eb6":"code","210039ff":"code","522e02c0":"code","bd2f937d":"code","59ef8e8e":"code","fa5912b5":"code","043d116b":"code","8dc45676":"code","2f8b4ece":"code","5cbe6fe1":"code","f6da57de":"code","89da6e53":"code","38c39b6f":"code","054bb3c5":"code","2fea8e0a":"code","9c5d129a":"code","aae55bcc":"code","e0b56cd6":"code","bef1c303":"code","fa56ccf4":"code","67711953":"code","d235d1aa":"code","3bb547d1":"code","96cacae2":"code","dca6bdee":"code","f5341709":"code","76ced801":"code","78ee04ff":"code","6be02462":"code","2df98b35":"code","9de88f62":"code","39c7b1ea":"code","cd47598b":"code","5c916ac9":"code","f21280e6":"code","355fbbd1":"code","41fcbef8":"code","d7cdfb78":"code","2c148481":"code","a22d8bed":"code","1b00d7c6":"code","7f6504ae":"code","6481dbfb":"code","1139d15d":"code","448eb61c":"code","b8683ada":"code","29d5d150":"code","501f23e8":"code","ff02fd55":"code","bcb79182":"code","5da79af8":"code","1563167d":"code","c115c72b":"code","0f2abd62":"code","58af14a5":"code","86fa1f75":"code","ffbd7419":"code","d7189ca0":"code","fe3ca19b":"code","d7e22855":"code","b32bcd8c":"code","aa68b3cc":"markdown","5197f26b":"markdown","f905a09c":"markdown","0ec23d6d":"markdown","d323a1c5":"markdown","9cd50dbc":"markdown","b6dd1275":"markdown","e1dec4a8":"markdown","f8aa7c3d":"markdown","29e83f67":"markdown","d50d45e7":"markdown","e4d51151":"markdown","9b73e29a":"markdown","171f8d95":"markdown","08a0ebf7":"markdown","60d5b978":"markdown"},"source":{"e8925fde":"# based on the post here: https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/275094\n\nimport sys\nsys.path.append(\"..\/input\/tez-lib\/\")\ntimm_path = \"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\n\nimport tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport random\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport math\nimport os\n\nclass args:\n    batch_size = 16\n    image_size = 384\n    \ndef sigmoid(x):\n    return 1 \/ (1 + math.exp(-x))","a58d824a":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        \nset_seed(42)","bb714d81":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n    \nclass PawpularModel(tez.Model):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x, 0, {}\n    \ntest_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        albumentations.RandomBrightnessContrast(p=0.5),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","ab3ee3d3":"import cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')\n\nLOAD_SVR_FROM_PATH = '..\/input\/svr-models-10-folds\/'\n\ndf = pd.read_csv('..\/input\/same-old-creating-folds\/train_10folds.csv')\nprint('Train shape:', df.shape )\ndf.head()","fd7c3eb6":"import cuml, pickle\nfrom cuml.svm import SVR","210039ff":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n    \n    model = PawpularModel(model_name=\"swin_large_patch4_window12_384\")\n    model.load(f\"..\/input\/paw-models\/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    df_test = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n    test_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/test\/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    df_valid = df[df.kfold == fold_].reset_index(drop=True)#.iloc[:160]\n    valid_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_].reset_index(drop=True)\n        train_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        train_dataset = PawpularDataset(\n            image_paths=train_img_paths,\n            dense_features=df_train[dense_features].values,\n            targets=df_train['Pawpularity'].values\/100.0,\n            augmentations=test_aug,\n        )\n        print('Extracting train embedding...')\n        train_predictions = model.predict(train_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n        \n    \n        embed = np.array([]).reshape((0,128+12))\n        for preds in train_predictions:\n            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n\n        clf.fit(embed.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    test_dataset = PawpularDataset(\n        image_paths=test_img_paths,\n        dense_features=df_test[dense_features].values,\n        targets=np.ones(len(test_img_paths)),\n        augmentations=test_aug,\n    )\n    print('Predicting test...')\n    test_predictions = model.predict(test_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n    #print(test_predictions.shape)\n\n    final_test_predictions = []\n    embed = np.array([]).reshape((0,128+12))\n    for preds in test_predictions: #tqdm\n        final_test_predictions.extend(preds[:,:1].ravel().tolist())\n        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n\n    \n\n    final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embed)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ","522e02c0":"# FORCE SVR WEIGHT TO LOWER VALUE TO HELP PUBLIC LB\nbest_w = 0.5","bd2f937d":"super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ndf_test[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\n","59ef8e8e":"df_test.head()","fa5912b5":"timm_path = \"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\nfrom timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\nimport shutil\nfrom shutil import copyfile\nimport random\nimport PIL\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","043d116b":"test_dir = \"..\/input\/petfinder-pawpularity-score\/test\"\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","8dc45676":"if not os.path.exists('\/kaggle\/working\/yolov5s-master'):\n    shutil.copytree('\/kaggle\/input\/yolov5s-master', '\/kaggle\/working\/yolov5x6')\n\n# Can't figure out how to disable the font download in torchhub, so I manually copy it over to satisfy the check in plot.py\nos.mkdir('\/root\/.config\/Ultralytics\/')\ncopyfile('\/kaggle\/input\/yolov5-model\/Arial.ttf', '\/root\/.config\/Ultralytics\/Arial.ttf')","2f8b4ece":"# Use torch hub to load our model locally\nmodel = torch.hub.load('\/kaggle\/working\/yolov5x6', 'custom', path='\/kaggle\/input\/yolov5-model\/yolov5x6.pt', source='local')\nmodel.max_det = 1\nmodel.classes = [15,16]\nmodel.multi_label = False","5cbe6fe1":"for index, row in test.iterrows():\n    img = Image.open(test_dir + \"\/\" + row['Id'] + \".jpg\")\n    imgs = [img]\n    results = model(imgs, size=1280)\n    results.crop(save=True)\n    results.save()\n    df = results.pandas().xyxy[0]\n    \n    pet_class = \"unknown\"\n    if len(df) > 0:\n        pet_class = df['name'].values[0]\n          \n    test.loc[test['Id'] == row['Id'], 'pet_class'] = pet_class\n    \ntest.head(10)","f6da57de":"test['path'] = [test_dir +'\/' + x + '.jpg' for x in test[\"Id\"].values]","89da6e53":"shutil.rmtree('.\/runs')\nshutil.rmtree('.\/yolov5x6')","38c39b6f":"test.head()","054bb3c5":"cats = test[test.pet_class == 'cat'].reset_index(drop=True)\ndogs_unk = test[test.pet_class != 'cat'].reset_index(drop=True)","2fea8e0a":"class Model1(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model(\"tf_efficientnet_b4_ns\", pretrained=pretrained, num_classes=0, drop_rate=0., drop_path_rate=0.,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1792,12)\n        self.fc3_B = nn.Linear(1792,1)\n    \n    def forward(self,image):\n        image = self.backbone(image)\n        \n        if(len(image.shape) == 4):#for efficientnet models\n            image = self.pool(image)\n            image = image.view(image.shape[0], -1)\n\n        dec2 = self.fc3_B(image)\n        dec1 = self.fc3_A(image)\n        return image , dec2","9c5d129a":"class Model2(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model('swin_base_patch4_window12_384_in22k', pretrained=pretrained, num_classes=0, drop_rate=0., drop_path_rate=0.,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1024,12)\n        self.fc3_B = nn.Linear(1024,1)\n    \n    def forward(self,x):\n        x = self.backbone(x)\n        dec2 = self.fc3_B(x)\n        dec1 = self.fc3_A(x)\n        return x,dec2","aae55bcc":"class Model3(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model(\"swin_large_patch4_window7_224\", pretrained=False, num_classes=0, drop_rate=0.0, drop_path_rate=0.0,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1536,12)\n        self.fc3_B = nn.Linear(1536,1)\n        self.do = nn.Dropout(p=0.3)\n    \n    def forward(self,image):\n        image = self.backbone(image)\n        \n        if(len(image.shape) == 4):#for efficientnet models\n            image = self.pool(image)\n            image = image.view(image.shape[0], -1)\n\n        dec2 = self.fc3_B(image)\n      \n        return image , dec2","e0b56cd6":"class Model4(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=False, num_classes=0, drop_rate=0.0, drop_path_rate=0.0,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1536,12)\n        self.fc3_B = nn.Linear(1536,1)\n        self.do = nn.Dropout(p=0.3)\n    \n    def forward(self,image):\n        image = self.backbone(image)\n        \n        if(len(image.shape) == 4):#for efficientnet models\n            image = self.pool(image)\n            image = image.view(image.shape[0], -1)\n\n        dec2 = self.fc3_B(image)\n      \n        return image , dec2","bef1c303":"val_aug2 = A.Compose(\n    [ \n        A.Resize(320,320,p=1.0),\n        A.CenterCrop(224,224,p=1.0),\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","fa56ccf4":"image_size = 384\nval_aug1 = A.Compose(\n    [ \n        A.Resize(480,480,p=1.0),\n        A.CenterCrop(image_size,image_size,p=1.0),\n\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","67711953":"class Pets(Dataset):\n    def __init__(self , df,augs = None):\n        self.df = df\n        self.augs = augs\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        img_src = self.df.loc[idx,'path']\n        image = cv2.imread(img_src)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        transformed = self.augs(image=image)\n        image = transformed['image']\n       \n        return image","d235d1aa":"def inference_func1(test_loader , path):\n    m = Model1(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            _,output = m(x)\n            output = output.sigmoid()\n            output = output*100\n            PREDS += [output.detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","3bb547d1":"def inference_func2(test_loader , path):\n    m = Model2(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            _,output = m(x)\n            output = output.sigmoid()\n            output = output*100\n            PREDS += [output.detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","96cacae2":"def inference_func3(test_loader , path):\n    m = Model3(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            _,output = m(x)\n            output = output.sigmoid()\n            output = output*100\n            PREDS += [output.detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","dca6bdee":"dogs_unk_dataset1 = Pets(dogs_unk.reset_index(drop=True),augs = val_aug1)\ndogs_unk_loader1 = DataLoader(dogs_unk_dataset1, batch_size=16, shuffle=False,  num_workers=4)","f5341709":"dogs_unk_dataset2 = Pets(dogs_unk.reset_index(drop=True),augs = val_aug2)\ndogs_unk_loader2 = DataLoader(dogs_unk_dataset2, batch_size=16, shuffle=False,  num_workers=4)","76ced801":"if(len(dogs_unk) > 0):\n    yp1  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 0 - val rmse 18.9697.pth')\n    yp2  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 1 - val rmse 19.0007.pth')\n    yp3  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 2 - val rmse 19.5034.pth')\n    yp4  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 3 - val rmse 20.1689.pth')\n    yp5  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 4 - val rmse 19.3915.pth')\n    yp6  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 5 - val rmse 19.9424.pth')\n    yp7  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 6 - val rmse 19.6432.pth')\n    yp8  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 7 - val rmse 20.5341.pth')\n    yp9  = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 8 - val rmse 19.4683.pth')\n    yp10 = inference_func1(dogs_unk_loader1,'..\/input\/pawpularity-models-dog-v2\/tf_efficientnet_b4_ns - dog - Fold 9 - val rmse 19.4951.pth')\n    yp11 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 0 with val_rmse 18.57408182689726.pth')\n    yp12 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 1 with val_rmse 20.93912210908539.pth')\n    yp13 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 2 with val_rmse 19.520618494757.pth')\n    yp14 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 3 with val_rmse 19.780201070324544.pth')\n    yp15 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 4 with val_rmse 19.5155116100269.pth')\n    yp16 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 5 with val_rmse 20.58098075077962.pth')\n    yp17 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 6 with val_rmse 19.79990146746921.pth')\n    yp18 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 7 with val_rmse 19.779097576099065.pth')\n    yp19 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 8 with val_rmse 19.374419857287354.pth')\n    yp20 = inference_func3(dogs_unk_loader2,'..\/input\/exp1-224-dogs\/Fold 9 with val_rmse 19.94593150668674.pth')","78ee04ff":"if(len(dogs_unk) > 0):\n    dogs_unk['Pawpularity'] = (yp1+ yp2+ yp3+yp4+yp5+yp6+yp7+yp8+yp9+yp10+yp11+yp12+yp13+yp14+yp15+yp16+yp17+yp18+yp19+yp20 )\/20.","6be02462":"dogs_unk","2df98b35":"cats_dataset = Pets(cats.reset_index(drop=True),augs = val_aug1)\ncats_loader = DataLoader(cats_dataset, batch_size=16, shuffle=False,  num_workers=4)","9de88f62":"if(len(cats) > 0):\n    y_p1 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 0 - val rmse 15.4214.pth')\n    y_p2 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 1 - val rmse 14.8935.pth')\n    y_p3 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 2 - val rmse 15.8637.pth')\n    y_p4 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 3 - val rmse 15.2904.pth')\n    y_p5 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 4 - val rmse 14.5136.pth')\n    y_p6 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 5 - val rmse 15.7827.pth')\n    y_p7 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 6 - val rmse 16.0911.pth')\n    y_p8 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 7 - val rmse 15.7253.pth')\n    y_p9 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 8 - val rmse 15.3140.pth')\n    y_p10 = inference_func1(cats_loader,'..\/input\/paw-models-cat-v2\/tf_efficientnet_b4_ns - cat - Fold 9 - val rmse 15.4286.pth')\n    y_p11 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 0 - val rmse 14.8155.pth')\n    y_p12 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 1 - val rmse 14.4614.pth')\n    y_p13 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 2 - val rmse 15.0405.pth')\n    y_p14 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 3 - val rmse 14.8688.pth')\n    y_p15 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 4 - val rmse 15.6885.pth')\n    y_p16 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 5 - val rmse 15.0525.pth')\n    y_p17 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 6 - val rmse 14.4531.pth')\n    y_p18 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 7 - val rmse 14.9049.pth')\n    y_p19 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 8 - val rmse 15.0138.pth')\n    y_p20 = inference_func2(cats_loader,'..\/input\/paw-models-swin-cat\/swin_base_patch4_window12_384_in22k - cat - Fold 9 - val rmse 14.6707.pth')\n    ","39c7b1ea":"if(len(cats) > 0):\n    cats['Pawpularity'] = (y_p1+ y_p2+ y_p3+y_p4+y_p5+y_p6+y_p7+y_p8+y_p9+y_p10+y_p11+y_p12+y_p13+y_p14+y_p15+y_p16+y_p17+y_p18+y_p19+y_p20 )\/20.","cd47598b":"cats","5c916ac9":"test['path'] = [test_dir +'\/' + x + '.jpg' for x in test[\"Id\"].values]","f21280e6":"def inference_funcx(oof , path):\n    oof_dataset = Pets(oof.reset_index(drop=True),augs = val_aug1)\n    oof_loader = DataLoader(oof_dataset, batch_size=16, shuffle=False,  num_workers=4)\n    m = Model1(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(oof_loader)\n\n    PREDS1 = []\n    PREDS2 = []\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output1,output2 = m(x)\n            output2 = output2.sigmoid()\n            output2 = output2*100\n            PREDS1 += [output1.detach().cpu()]\n            PREDS2 += [output2.detach().cpu()]\n        PREDS1 = torch.cat(PREDS1).cpu().numpy()\n        PREDS2 = torch.cat(PREDS2).cpu().numpy()  \n    return PREDS1,PREDS2","355fbbd1":"path = []\npath.append(\"..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 0 - val rmse 17.3108.pth\")\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 1 - val rmse 17.4745.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 2 - val rmse 16.9196.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 3 - val rmse 17.4784.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 4 - val rmse 17.0746.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 5 - val rmse 16.9158.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 6 - val rmse 17.7258.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 7 - val rmse 16.9325.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 8 - val rmse 16.7591.pth')\npath.append('..\/input\/paw-pl-models\/tf_efficientnet_b4_ns - all - Fold 9 - val rmse 17.5080.pth')","41fcbef8":"LOAD_SVR_FROM_PATH = '..\/input\/effnet-svm-train\/'","d7cdfb78":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    #model.load(f\"..\/input\/paw-models\/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    #df_test = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n    #df_test['path'] = [f\"..\/input\/petfinder-pawpularity-score\/test\/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    #df_valid = df[df.kfold == fold_]\n    #valid_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"eff_SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_]\n        #train_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        print('Extracting train embedding...')\n        embedx,_ = inference_func(df_train , path[fold_])\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embedx.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n\n    print('Predicting test...')\n    embedt,final_test_predictions = inference_funcx(test , path[fold_])\n\n    #final_test_predictions = []\n   \n\n    #final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embedt)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################","2c148481":"best_w = 0.45\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ntest['x'] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ntest.head()","a22d8bed":"#image_size = 384\nval_augy =A.Compose(\n    [ \n        A.Resize(480,480,p=1.0),\n        A.CenterCrop(384,384,p=1.0),\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","1b00d7c6":"def inference_funcy(oof , path):\n    oof_dataset = Pets(oof.reset_index(drop=True),augs = val_augy)\n    oof_loader = DataLoader(oof_dataset, batch_size=16, shuffle=False,  num_workers=4)\n    m = Model4(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(oof_loader)\n\n    PREDS1 = []\n    PREDS2 = []\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output1,output2 = m(x)\n            output2 = output2.sigmoid()\n            output2 = output2*100\n            PREDS1 += [output1.detach().cpu()]\n            PREDS2 += [output2.detach().cpu()]\n        PREDS1 = torch.cat(PREDS1).cpu().numpy()\n        PREDS2 = torch.cat(PREDS2).cpu().numpy()  \n    return PREDS1,PREDS2","7f6504ae":"pathy= []\npathy.append(\"..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 0 - val rmse 17.2610.pth\")\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 1 - val rmse 17.2024.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 2 - val rmse 16.8636.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 3 - val rmse 17.7805.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 4 - val rmse 16.9883.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 5 - val rmse 16.5446.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 6 - val rmse 16.8143.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 7 - val rmse 16.8518.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 8 - val rmse 16.6582.pth')\npathy.append('..\/input\/paw-models-384-large-all\/swin_large_patch4_window12_384 - all - Fold 9 - val rmse 17.6446.pth')","6481dbfb":"LOAD_SVR_FROM_PATH = '..\/input\/swin-svm-train-384\/'\nfrom sklearn.metrics import mean_squared_error","1139d15d":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    #model.load(f\"..\/input\/paw-models\/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    #df_test = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n    #df_test['path'] = [f\"..\/input\/petfinder-pawpularity-score\/test\/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    #df_valid = df[df.kfold == fold_]\n    #valid_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_]\n        #train_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        print('Extracting train embedding...')\n        embedx,_ = inference_func(df_train , pathy[fold_])\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embedx.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n\n    print('Predicting test...')\n    embedt,final_test_predictions = inference_funcy(test , pathy[fold_])\n\n    #final_test_predictions = []\n   \n\n    #final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embedt)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################","448eb61c":"best_w = 0.45\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ntest['y'] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ntest.head()","b8683ada":"val_augz =  A.Compose(\n    [ \n        A.Resize(329,320,p=1.0),\n        A.CenterCrop(224,224,p=1.0),\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","29d5d150":"def inference_funcz(oof , path):\n    oof_dataset = Pets(oof.reset_index(drop=True),augs = val_augz)\n    oof_loader = DataLoader(oof_dataset, batch_size=16, shuffle=False,  num_workers=4)\n    m = Model3(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(oof_loader)\n\n    PREDS1 = []\n    PREDS2 = []\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output1,output2 = m(x)\n            output2 = output2.sigmoid()\n            output2 = output2*100\n            PREDS1 += [output1.detach().cpu()]\n            PREDS2 += [output2.detach().cpu()]\n        PREDS1 = torch.cat(PREDS1).cpu().numpy()\n        PREDS2 = torch.cat(PREDS2).cpu().numpy()  \n    return PREDS1,PREDS2","501f23e8":"pathz = []\npathz.append(\"..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 0 - val rmse 17.5231.pth\")\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 1 - val rmse 17.8166.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 2 - val rmse 17.4906.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 3 - val rmse 17.5070.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 4 - val rmse 17.4393.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 5 - val rmse 17.2695.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 6 - val rmse 17.9887.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 7 - val rmse 17.2341.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 8 - val rmse 17.0782.pth')\npathz.append('..\/input\/paw-models-all-5-epoch\/swin_large_patch4_window7_224_in22k - all - Fold 9 - val rmse 17.7036.pth')","ff02fd55":"LOAD_SVR_FROM_PATH = '..\/input\/svm-swin-train-224\/'","bcb79182":"test","5da79af8":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    #model.load(f\"..\/input\/paw-models\/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    #df_test = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n    #df_test['path'] = [f\"..\/input\/petfinder-pawpularity-score\/test\/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    #df_valid = df1[df1.kfold == fold_]\n    #valid_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df1[df1.kfold != fold_]\n        #train_img_paths = [f\"..\/input\/petfinder-pawpularity-score\/train\/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        print('Extracting train embedding...')\n        embedx,_ = inference_funcz(df_train , pathz[fold_])\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embedx.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n\n    print('Predicting test...')\n    embedt,final_test_predictions = inference_funcz(test , pathz[fold_])\n\n    #final_test_predictions = []\n   \n\n    #final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embedt)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################","1563167d":"best_w = 0.55\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ntest['z'] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ntest.head()","c115c72b":"test['xx'] = (test.x+test.z+test.y)\/3.","0f2abd62":"test[\"Pawpularity\"] = -1.\ntest[\"Pawpularity\"] = test[\"Pawpularity\"].astype(np.float)\ntest.head()","58af14a5":"if(len(cats) > 0):\n    for index, row in cats.iterrows():\n        test.loc[test['Id'] == row['Id'], 'Pawpularity'] = row['Pawpularity']\n","86fa1f75":"if(len(dogs_unk) > 0):\n    for index, row in dogs_unk.iterrows():\n        test.loc[test['Id'] == row['Id'], 'Pawpularity'] = row['Pawpularity']","ffbd7419":"test[\"Pawpularity\"] =  0.45*test[\"Pawpularity\"] + 0.55*test['xx']","d7189ca0":"sub = test[[\"Id\" , \"Pawpularity\"]]","fe3ca19b":"sub[\"Pawpularity\"] = 0.5*sub[\"Pawpularity\"] + 0.5*df_test[\"Pawpularity\"]","d7e22855":"sub.to_csv(\"submission.csv\", index = False)","b32bcd8c":"sub","aa68b3cc":"# Swin 384","5197f26b":"# Weighted Averaging different models","f905a09c":"# YOLO detection","0ec23d6d":"# Dataset class","d323a1c5":"# Inference functions","9cd50dbc":"# Models\n","b6dd1275":"# Effnet","e1dec4a8":"# Dividing data into cats\/dogs","f8aa7c3d":"# Predicing for \"All\"","29e83f67":"# Predicting for !Cats ","d50d45e7":"# swin 224","e4d51151":"# Our models","9b73e29a":"# Import RAPIDS","171f8d95":"# Augs","08a0ebf7":"# Predicting for images cats","60d5b978":"# Public Notebook\nhttps:\/\/www.kaggle.com\/cdeotte\/rapids-svr-boost-17-8"}}