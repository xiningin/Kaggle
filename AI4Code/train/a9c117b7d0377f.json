{"cell_type":{"4c3556e4":"code","d184a75d":"code","2b5cd5ec":"code","7ce688ad":"code","461c3303":"code","9912abed":"code","bcbd924e":"code","108c96f2":"code","37f7b669":"code","dbe42937":"markdown","1c56fc38":"markdown","1c7567db":"markdown","7977c500":"markdown","b27ec80e":"markdown","3785cd77":"markdown","31c7fe98":"markdown"},"source":{"4c3556e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d184a75d":"import numpy as np\nimport pandas as pd\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\n\npd.pandas.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 170)\n\n\ndef load():\n    data = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\n    return data\n\ndf = load()\ndf.head()\n\n#Let's Check the Features\n\ncat_cols = [col for col in df.columns if df[col].dtypes == \"O\"]\nnum_cols = [col for col in df.columns if df[col].dtypes != \"O\"]\nif len(cat_cols) == 0:\n    print(\"There is not Categorical Column\",\",\",\"Number of Numerical Columns: \", len(num_cols), \"\\n\", num_cols)\nelif len(num_cols) == 0:\n    print(\"There is not Numerical Column\",\",\",\"Number of Categorical Column: \", len(cat_cols), \"\\n\", cat_cols)\nelse:\n    print(\"\")\n\n\nnum_cols = [col for col in df.columns if len(df[col].unique()) > 20\n            and df[col].dtypes != 'O'\n            and col not in \"Outcome\"]\n\n\n###Pregnancies is num but cat column.\n\nzero_columns = [col for col in df.columns if (df[col].min() == 0 and col not in [\"Pregnancies\", \"Outcome\"])]\n\n# Saklanan degiskenlerin her birisine gidip 0 iceren gozlem degerlerini Nan diye kaydettik\nfor col in zero_columns:\n    df[col] = np.where(df[col] == 0, np.nan, df[col])\n\n\n#Inspectation of Features\n\ndf.describe([0.05,0.25,0.50,0.75,0.90,0.95,0.99]).T\ndf.isnull().sum()\n\n#pregnancies hari\u00e7 di\u011fer de\u011fi\u015fkenlerin min de\u011ferinin 0 gelmesi imkans\u0131zd\u0131r.\n#bu sebeple bu de\u011ferleri nan ile doldural\u0131m.\n\nnan_cols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n# for col in nan_cols:\n#     df[col].replace(0,np.NaN,inplace=True)\n#Outlier olarak minimum de\u011ferlerdir, 0 de\u011ferleri medyan ile doldurmak gerekir.\ndf.isnull().sum()\n\n\n","2b5cd5ec":"#NAN DE\u011eERLER\u0130 \u0130NCELEYEL\u0130M\ndef missing_values_table(dataframe):\n    variables_with_na = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[variables_with_na].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[variables_with_na].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    dtypes = dataframe.dtypes\n    dtypesna = dtypes.loc[(np.sum(dataframe.isnull()) != 0)]\n    missing_df = pd.concat([n_miss, np.round(ratio, 2), dtypesna], axis=1, keys=['n_miss', 'ratio', 'type'])\n    if len(missing_df) > 0:\n        print(missing_df)\n    else:\n        print(\"no missing value\")\nmissing_values_table(df)\n\n#Medyan ile doldural\u0131m\n\nfor col in df.columns:\n    df.loc[(df[\"Outcome\"]==0) & (df[col].isnull()),col] = df[df[\"Outcome\"]==0][col].median()\n    df.loc[(df[\"Outcome\"]==1) & (df[col].isnull()),col] = df[df[\"Outcome\"]==1][col].median()\n\nmissing_values_table(df)","7ce688ad":"df['Glucose_Range'] = pd.cut(x=df['Glucose'], bins = [0,140,200], labels = [\"Normal\",\"Prediabetes\"]).astype('O')\ndf['BMI_Range'] = pd.cut(x=df['BMI'], bins=[0,18.5,24.9,29.9,100],labels = [\"Underweight\",\"Healty\",\"Overweight\",\"Obese\"])\ndf['BloodPressure_Range'] = pd.cut(x=df['BloodPressure'], bins=[0,79,89,123],labels = [\"Normal\",\"HS1\",\"HS2\"])\ndf['SkinThickness_Range'] = df['SkinThickness'].apply(lambda x: 1 if x <= 18.0 else 0)\n\ndef set_insulin(row):\n    if row[\"Insulin\"] >= 16 and row[\"Insulin\"] <= 166:\n        return \"Normal\"\n    else:\n        return \"Abnormal\"\ndf[\"Insulin_range\"] = df.apply(set_insulin, axis=1)\n\ndf.loc[df['Pregnancies'] == 0, \"NEW_PREG\"] = \"NoPreg\"\ndf.loc[((df['Pregnancies'] > 0) & (df['Pregnancies'] <= 4)), \"NEW_PREG\"] = \"NormalPreg\"\ndf.loc[(df['Pregnancies'] > 4), \"NEW_PREG\"] = \"OverPreg\"\n\ndf[\"BloodPres\/Glucose\"] = df[\"BloodPressure\"] \/ df[\"Glucose\"]\ndf[\"Pregs*DiabetesPedigree\"] = df[\"Pregnancies\"] \/ df[\"DiabetesPedigreeFunction\"]\ndf[\"Pregs*DiabetesPedigree\"] = df[\"Pregnancies\"] * df[\"DiabetesPedigreeFunction\"]\ndf[\"BMI\/Age\"] = df[\"BMI\"] \/ df[\"Age\"]","461c3303":"df.head()","9912abed":"\n#LABEL ENCODING\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\nbinary_cols = [col for col in df.columns if len(df[col].unique()) ==2 and df[col].dtypes == 'O']\n\nfor col in binary_cols:\n    df = label_encoder(df, col)\n\n#ONE HOT ENCODING\nohe_cols = np.array([col for col in df.columns if 10 >= len(df[col].unique()) > 2])\ndf = one_hot_encoder(df, ohe_cols)\n\n# df.groupby(\"Glucose_Range_Prediabetes\").agg({\"Insulin\":\"mean\"})\n\n#As we can see, if who reached prediabet class, insulin level averagely 135. It has affection cumulatively for diabet.\n\n\nfor col in df.columns:\n    df.loc[(df[\"Outcome\"]==0) & (df[col].isnull()),col] = df[df[\"Outcome\"]==0][col].median()\n    df.loc[(df[\"Outcome\"]==1) & (df[col].isnull()),col] = df[df[\"Outcome\"]==1][col].median()\n####\n# After our feature engineering, there was some infinite and NaN values. We solved with this codes;\n#np.where(df.values >= np.finfo(np.float64).max)\ndf[df==np.inf]=np.nan\ndf.fillna(df.median(), inplace=True)\n####","bcbd924e":"from sklearn.ensemble import RandomForestClassifier\n\ny = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)\n\nrf = RandomForestClassifier(random_state=17).fit(X_train, y_train)","108c96f2":"# base model error\ny_pred = rf.predict(X_test)\naccuracy_score(y_test,y_pred)\nprint(classification_report(y_test, y_pred))\n\n\nrf_prms = {'max_depth': range(1, 11),\n               \"min_samples_split\": [2, 3, 4]}\n\nrf_cv = GridSearchCV(rf, rf_prms, cv=10, n_jobs=-1, verbose=True)\nrf_cv.fit(X_train, y_train)\n\nrf_cv.best_params_\n\nrf_tuned = RandomForestClassifier(**rf_cv.best_params_).fit(X_train, y_train)\n\n\n# test error\ny_pred = rf_tuned.predict(X_test)\ny_prob = rf_tuned.predict_proba(X_test)[:, 1]\nprint(classification_report(y_test, y_pred))\nroc_auc_score(y_test, y_prob)","37f7b669":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndef plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(14, 12))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                     ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n\n\nplot_importance(rf, X_train)","dbe42937":"**0.93 auc score that we reached!! We can predict each person with 93 per cent auc score which is more important than accuracy.**","1c56fc38":"**Feature Importance shows us our feature engineering works very well.. You can check the plot and see what features we can drop or what features we should insist of prediction of diabet.**","1c7567db":"![image](https:\/\/www.niddk.nih.gov\/-\/media\/Images\/Health-Information\/Diabetes\/diabetes-monitor-fruits-vegetables-small_597x347.png)","7977c500":"**Diabetes is one of the most common diseases of our time and a disease that we start to see frequently in every age range. Early diagnosis is really important in terms of preventing diabetes and taking precautions. So, as data scientists, I think we should pay more attention to such health problems.**","b27ec80e":"Glucose : \nThe results can be classified as normal, impaired, or abnormal\n\nNormal Results for Diabetes -> Two-hour glucose level less than 140 mg\/dL\nImpaired Results for Diabetes -> Two-hour glucose level 140 to 200 mg\/dL\nAbnormal (Diagnostic) Results for Diabetes -> Two-hour glucose level greater than 200 mg\/dL\n\nBlood Pressure:\nThis is the time when the heart fills with blood and gets oxygen.\n\nNormal: Systolic below 120 and diastolic below 80\nElevated: Systolic 120\u2013129 and diastolic under 80\nHypertension stage 1: Systolic 130\u2013139 and diastolic 80\u201389\nHypertension stage 2: Systolic 140-plus and diastolic 90 or more\nHypertensive crisis: Systolic higher than 180 and diastolic above 120.\n\nBMI:\n\nBelow 18.5 -> Underweight\n18.5 \u2013 24.9 -> Normal or Healthy Weight\n25.0 \u2013 29.9 -> Overweight\n30.0 and Above -> Obese\n\nTriceps Skinfolds:\nFor adults, the standard normal values for triceps skinfolds ;\n2.5mm (men)\n18.0mm (women)","3785cd77":"**[You can learn more information about Diabet](https:\/\/www.diabetes.co.uk\/diabetes-causes.html)**","31c7fe98":"Let's dive to Feature Engineering. As we can see in the final, our new features almost reached the top levels of importance. "}}