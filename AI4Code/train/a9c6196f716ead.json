{"cell_type":{"b19ffc1f":"code","b74ebeea":"code","33a87535":"code","93619888":"code","30297497":"code","a3563864":"code","10924134":"code","e934a520":"code","12b7b4cb":"code","1a5c1d56":"code","0d563f6e":"code","69f6d656":"code","5ba574c8":"code","5e7bcd3e":"code","ef232049":"code","169ec49e":"code","e654abde":"code","db7ed82e":"code","3123c000":"code","e5e7ba41":"code","6e898785":"code","fca59eca":"code","e38e2024":"code","e53e67ef":"code","d73cd2ee":"code","d00f5027":"code","efa829af":"code","3a1ac764":"code","0731a2e4":"markdown","ddb6120b":"markdown","1016d455":"markdown","8a4b822e":"markdown","d56f9889":"markdown","a7cb7203":"markdown","b792c044":"markdown","2ebe309e":"markdown","dbe55757":"markdown","3e321e84":"markdown","81fb3c2e":"markdown","f86437ee":"markdown","3ce6fa03":"markdown","c3fa71d1":"markdown","8e807997":"markdown","53fe9cc6":"markdown","a90a43bd":"markdown","c424501a":"markdown","2b9c5e31":"markdown"},"source":{"b19ffc1f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom scipy.integrate import solve_ivp\nimport numpy\nimport datetime\nfrom datetime import timedelta\n\n%matplotlib inline","b74ebeea":"# Function code refernece from https:\/\/www.kaggle.com\/anjum48\/seir-model-with-intervention\n\n# Susceptible equation\ndef dS_dt(S, I, R_t, T_inf):\n    return -(R_t \/ T_inf) * I * S\n\n# Exposed equation\ndef dE_dt(S, E, I, R_t, T_inf, T_inc):\n    return (R_t \/ T_inf) * I * S - (T_inc**-1) * E\n\n# Infected equation\ndef dI_dt(I, E, T_inc, T_inf):\n    return (T_inc**-1) * E - (T_inf**-1) * I\n\n# Recovered\/Remove\/deceased equation\ndef dR_dt(I, T_inf):\n    return (T_inf**-1) * I\n\ndef SEIR_model(t, y, R_t, T_inf, T_inc):\n    \n    if callable(R_t):\n        reproduction = R_t(t)\n    else:\n        reproduction = R_t\n        \n    S, E, I, R = y\n    \n    S_out = dS_dt(S, I, reproduction, T_inf)\n    E_out = dE_dt(S, E, I, reproduction, T_inf, T_inc)\n    I_out = dI_dt(I, E, T_inc, T_inf)\n    R_out = dR_dt(I, T_inf)\n    \n    return [S_out, E_out, I_out, R_out]","33a87535":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv')\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv')\ntrain['Date_datetime'] = train['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))","93619888":"pop_info = pd.read_csv('\/kaggle\/input\/covid19-population-data\/population_data.csv')\ncountry_pop = pop_info.query('Type == \"Country\/Region\"')\nprovince_pop = pop_info.query('Type == \"Province\/State\"')\ncountry_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\nprovince_lookup = dict(zip(province_pop['Name'], province_pop['Population']))","30297497":"def plot_model_and_predict(data, pop, solution, title='SEIR model'):\n    sus, exp, inf, rec = solution.y\n    \n    f = plt.figure(figsize=(16,5))\n    ax = f.add_subplot(1,2,1)\n    #ax.plot(sus, 'b', label='Susceptible');\n    ax.plot(exp, 'y', label='Exposed');\n    ax.plot(inf, 'r', label='Infected');\n    ax.plot(rec, 'c', label='Recovered\/deceased');\n    plt.title(title)\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.ylabel(\"Fraction of population\", fontsize=10);\n    plt.legend(loc='best');\n    \n    ax2 = f.add_subplot(1,2,2)\n    preds = np.clip((inf + rec) * pop ,0,np.inf)\n    ax2.plot(range(len(data)),preds[:len(data)],label = 'Predict ConfirmedCases')\n    ax2.plot(range(len(data)),data['ConfirmedCases'])\n    plt.title('Model predict and data')\n    plt.ylabel(\"Population\", fontsize=10);\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.legend(loc='best');","a3563864":"Country = 'Hubei'\nN = pop_info[pop_info['Name']==Country]['Population'].tolist()[0] # Hubei Population \n\n# Load dataset of Hubei\ntrain_loc = train[train['Country_Region']==Country].query('ConfirmedCases > 0')\nif len(train_loc)==0:\n    train_loc = train[train['Province_State']==Country].query('ConfirmedCases > 0')\n\nn_infected = train_loc['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\nmax_days = len(train_loc)# how many days want to predict\n\n# Initial stat for SEIR model\ns = (N - n_infected)\/ N\ne = 0.\ni = n_infected \/ N\nr = 0.\n\n# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9 # average infectious period\nR_0 = 3.954 # reproduction number\n\n## Solve the SEIR model \nsol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(R_0, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\n## Plot result\nplot_model_and_predict(train_loc, N, sol, title = 'SEIR Model (without intervention)')","10924134":"# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9  # average infectious period\n\n# Define the intervention parameters (fit result, latter will show how to fit)\nR_0, cfr, k, L=[ 3.95469597 , 0.04593316 , 3.      ,   15.32328881]\n\ndef time_varying_reproduction(t): \n    return R_0 \/ (1 + (t\/L)**k)\n\nsol2 = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\nplot_model_and_predict(train_loc, N, sol2, title = 'SEIR Model (with intervention)')","e934a520":"from scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error","12b7b4cb":"def cumsum_signal(vec):\n    temp_val = 0\n    vec_new = []\n    for i in vec:\n        if i > temp_val:\n            vec_new.append(i)\n            temp_val = i\n        else:\n            vec_new.append(temp_val)\n    return vec_new","1a5c1d56":"# Use a constant reproduction number\ndef eval_model_const(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # R0 become half after intervention days\n    def time_varying_reproduction(t):\n        if t > 80: # we set intervention days = 80\n            return R_0 * 0.5\n        else:\n            return R_0\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","0d563f6e":"# Use a Hill decayed reproduction number\ndef eval_model_decay(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr, k, L = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions   \n    # Hill decay. Initial values: R_0=2.2, k=2, L=50\n    def time_varying_reproduction(t): \n        return R_0 \/ (1 + (t\/L)**k)\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","69f6d656":"len(train[-7:]),len(train[:-7]),len(train)","5ba574c8":"from matplotlib import dates\nimport plotly.graph_objects as go\n\ndef fit_model_new(data, area_name, initial_guess=[2.2, 0.02, 2, 50], \n              bounds=((1, 20), (0, 0.15), (1, 3), (1, 100)), make_plot=True, decay_mode = None):\n    \n    if area_name in ['France']:# France last data looks weird, remove it\n        train = data.query('ConfirmedCases > 0').copy()[:-1]\n    #elif area_name in ['Virgin Islands']:\n    #    train = data[:-3].query('ConfirmedCases > 0').copy()\n    else:\n        train = data.query('ConfirmedCases > 0').copy()\n    \n    ####### Split Train & Valid #######\n    #valid_data = train[-1:]\n    train_data = train\n    \n    ####### If this country have no ConfirmedCase, return 0 #######\n    if len(train_data) == 0:\n        result_zero = np.zeros((43))\n        return pd.DataFrame({'ConfirmedCases':result_zero,'Fatalities':result_zero}), 0 \n    \n    ####### Load the population of area #######\n    try:\n        #population = province_lookup[area_name]\n        population = pop_info[pop_info['Name']==area_name]['Population'].tolist()[0]\n    except IndexError:\n        print ('country not in population set, '+str(area_name))\n        population = 1000000 \n    \n    \n    if area_name == 'US':\n        population = 327200000\n    if area_name == 'Global':\n        population = 7744240900\n        \n    cases_per_million = train_data['ConfirmedCases'].max() * 10**6 \/ population\n    n_infected = train_data['ConfirmedCases'].iloc[0]\n    \n    ####### Total case\/popuplation below 1, reduce country population #######\n    if cases_per_million < 1:\n        #print ('reduce pop divide by 100')\n        population = population\/100\n        \n    ####### Fit the real data by minimize the MSLE #######\n    res_const = minimize(eval_model_const, [2.2, 0.02], bounds=((1, 20), (0, 0.15)),\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n\n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    ####### Align the date information #######\n    test_end = datetime.datetime.strptime('2020-05-14','%Y-%m-%d')\n    test_start = datetime.datetime.strptime('2020-04-02','%Y-%m-%d')\n    train_test = data[data.Date_datetime>=test_start]\n    test_period = (test_end - test_start).days\n    train_max = train_data.Date_datetime.max()\n    train_min = train_data.Date_datetime.min()\n    add_date = 0\n    delta_days =(test_end - train_max).days\n    train_add_time=[]\n\n    if train_min > test_start:\n        add_date = (train_min-test_start).days\n        last = train_min-timedelta(add_date)\n        train_add_time = np.arange(last, train_min, dtype='datetime64[D]').tolist()\n        train_add_time = pd.to_datetime(train_add_time)\n        dates_all = train_add_time.append(pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]')))\n    else:\n        dates_all = pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]'))\n\n\n    ####### Auto find the best decay function ####### \n    if decay_mode is None:\n        if res_const.fun < res_decay.fun :\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n    else:\n        if decay_mode =='day_decay':\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n\n    ####### Predict the result by using best fit paramater of SEIR model ####### \n    sus, exp, inf, rec = sol.y\n    \n    y_pred = pd.DataFrame({\n        'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n       # 'ConfirmedCases': [inf[0]*population for i in range(add_date)]+(np.clip((inf + rec) * population,0,np.inf)).tolist(),\n       # 'Fatalities': [rec[0]*population for i in range(add_date)]+(np.clip(rec, 0, np.inf) * population * res.x[1]).tolist()\n        'Fatalities': cumsum_signal((np.clip(rec * population * res.x[1], 0, np.inf)).tolist())\n    })\n\n    #y_pred_valid = y_pred.iloc[len(train_data):len(train_data)+len(valid_data)]\n    y_pred_valid = y_pred.iloc[:len(train_data)]\n    y_pred_test = pd.concat([train_test[['ConfirmedCases', 'Fatalities']],y_pred.iloc[-(delta_days):]], ignore_index=True)\n    y_true_valid = train_data[['ConfirmedCases', 'Fatalities']]\n    #y_true_valid = valid_data[['ConfirmedCases', 'Fatalities']]\n    #print (len(y_pred),train_min)\n    \n    ####### Calculate MSLE ####### \n    valid_msle_cases = mean_squared_log_error(y_true_valid['ConfirmedCases'], y_pred_valid['ConfirmedCases'])\n    valid_msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid['Fatalities'])\n    valid_msle = np.mean([valid_msle_cases, valid_msle_fat])\n    \n    ####### Plot the fit result of train data and forecast after 300 days ####### \n    if make_plot:\n        if len(res.x)<=2:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using intervention days decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}')\n        else:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using Hill decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}, K : {res.x[2]:0.5f}, L: {res.x[3]:0.5f}')\n        \n        ####### Plot the fit result of train data dna SEIR model trends #######\n\n        f = plt.figure(figsize=(16,5))\n        ax = f.add_subplot(1,2,1)\n        ax.plot(exp, 'y', label='Exposed');\n        ax.plot(inf, 'r', label='Infected');\n        ax.plot(rec, 'c', label='Recovered\/deceased');\n        plt.title('SEIR Model Trends')\n        plt.xlabel(\"Days\", fontsize=10);\n        plt.ylabel(\"Fraction of population\", fontsize=10);\n        plt.legend(loc='best');\n        #train_date_remove_year = train_data['Date_datetime'].apply(lambda date:'{:%m-%d}'.format(date))\n        ax2 = f.add_subplot(1,2,2)\n        xaxis = train_data['Date_datetime'].tolist()\n        xaxis = dates.date2num(xaxis)\n        hfmt = dates.DateFormatter('%m\\n%d')\n        ax2.xaxis.set_major_formatter(hfmt)\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'),train_data['ConfirmedCases'],label='Confirmed Cases (train)', c='g')\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'), y_pred['ConfirmedCases'][:len(train_data)],label='Cumulative modeled infections', c='r')\n        #ax2.plot(np.array(valid_data['Date_datetime'], dtype='datetime64[D]'), y_true_valid['ConfirmedCases'],label='Confirmed Cases (valid)', c='b')\n        #ax2.plot(np.array(valid_data['Date_datetime'], dtype='datetime64[D]'),y_pred_valid['ConfirmedCases'],label='Cumulative modeled infections (valid)', c='y')\n        plt.title('Real ConfirmedCase and Predict ConfirmedCase')\n        plt.legend(loc='best');\n        plt.show()\n            \n        ####### Forecast 300 days after by using the best paramater of train data #######\n        if len(res.x)>2:\n            msle, sol = eval_model_decay(res.x, train_data, population, True, 300)\n        else:\n            msle, sol = eval_model_const(res.x, train_data, population, True, 300)\n        \n        sus, exp, inf, rec = sol.y\n        \n        y_pred = pd.DataFrame({\n            'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n            'Fatalities': cumsum_signal(np.clip(rec, 0, np.inf) * population * res.x[1])\n        })\n        \n        ####### Plot 300 days after of each country #######\n        start = train_min\n        end = start + timedelta(len(y_pred))\n        time_array = np.arange(start, end, dtype='datetime64[D]')\n\n        max_day = numpy.where(inf == numpy.amax(inf))[0][0]\n        where_time = time_array[max_day]\n        pred_max_day = y_pred['ConfirmedCases'][max_day]\n        xy_show_max_estimation = (where_time, max_day)\n        \n        con = y_pred['ConfirmedCases']\n        fat = y_pred['Fatalities']\n        max_day_con = numpy.where(con == numpy.amax(con))[0][0] # Find the max confimed case of each country\n        max_day_fat = numpy.where(fat == numpy.amax(fat))[0][0]\n        max_con = numpy.amax(con)\n        max_fat = numpy.amax(fat)\n        where_time_con = time_array[len(time_array)-50]\n        xy_show_max_estimation_confirmed = (where_time_con, max_con)\n        \n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['ConfirmedCases'].astype(int),\n                            mode='lines',\n                            line = dict(color='red'),\n                            name='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['Fatalities'].astype(int),\n                            mode='lines',\n                            line = dict(color='yellow'),\n                            name='Estimation Fatalities Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        fig.add_trace(go.Scatter(x=time_array[:len(train)], y=train['ConfirmedCases'],\n                            mode='lines',\n                            name='Confirmed case until '+ str(train_max.date()),line = dict(color='green', width=4)))\n        fig.add_trace(go.Scatter(x=time_array[:len(train)], y=train['Fatalities'],\n                            mode='lines',\n                            name='Fatalities case until '+ str(train_max.date()),line = dict(color='blue', width=4)))\n        fig.add_annotation(\n            x=where_time_con,\n            y=max_con-(max_con\/30),\n            showarrow=False,\n            text=\"Estimate Max Case around:\" +str(int(max_con)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=where_time_con,\n            y=max_fat-(max_fat\/30),\n            showarrow=False,\n            text=\"Estimate Max death around:\" +str(int(max_fat)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=time_array[len(train)-1],\n            y=train['ConfirmedCases'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max ConfirmedCase: \" +str(int(train['ConfirmedCases'].tolist()[-1]))) \n        \n        fig.add_annotation(\n            x=time_array[len(train)-1],\n            y=train['Fatalities'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max Fatalities: \" +str(int(train['Fatalities'].tolist()[-1]))) \n        \n        fig.add_annotation(\n            x=where_time,\n            y=pred_max_day,\n            text='Infect start decrease from: ' + str(where_time))   \n        fig.update_layout(title='Estimate Confirmed Case ,'+area_name+' Total population ='+ str(int(population)), legend_orientation=\"h\")\n        fig.show()\n        \n        #df = pd.DataFrame({'Values': train_data['ConfirmedCases'].tolist()+y_pred['ConfirmedCases'].tolist(),'Date_datatime':time_array[:len(train_data)].tolist()+time_array.tolist(),\n        #           'Real\/Predict': ['ConfirmedCase' for i in range(len(train_data))]+['PredictCase' for i in range(len(y_pred))]})\n        #fig = px.line(df, x=\"Date_datatime\", y=\"Values\",color = 'Real\/Predict')\n        #fig.show()\n        #plt.figure(figsize = (16,7))\n        #plt.plot(time_array[:len(train_data)],train_data['ConfirmedCases'],label='Confirmed case until '+ str(train_max.date()),color='g', linewidth=3.0)\n        #plt.plot(time_array,y_pred['ConfirmedCases'],label='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date()),color='r', linewidth=1.0)\n        #plt.annotate('Infect start decrease from: ' + str(where_time), xy=xy_show_max_estimation, size=15, color=\"black\")\n        #plt.annotate('max Confirmedcase: ' + str(int(max_con)), xy=xy_show_max_estimation_confirmed, size=15, color=\"black\")\n        #plt.title('Estimate Confirmed Case '+area_name+' Total population ='+ str(int(population)))\n        #plt.legend(loc='lower right')\n        #plt.show()\n\n\n    return y_pred_test, valid_msle","5e7bcd3e":"country = 'Taiwan*'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","ef232049":"country = 'Korea, South'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","169ec49e":"country = 'Japan'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","e654abde":"country = 'Italy'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","db7ed82e":"country = 'New York'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","3123c000":"country = 'Afghanistan'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","e5e7ba41":"country = 'US'\ncountry_pd_train = train[train['Country_Region']==country]\ncountry_pd_train2 = country_pd_train.groupby(['Date']).sum().reset_index()\ncountry_pd_train2['Date_datetime'] = country_pd_train2['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\na,b = fit_model_new(country_pd_train2,country,make_plot=True)","6e898785":"country = 'Global'\ncountry_pd_train2 = train.groupby(['Date']).sum().reset_index()\ncountry_pd_train2['Date_datetime'] = country_pd_train2['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\na,b = fit_model_new(country_pd_train2,country,make_plot=True)","fca59eca":"import numpy\nvalidation_scores = []\nvalidation_county = []\nvalidation_country = []\nfor country in tqdm(train['Country_Region'].unique()):\n    country_pd_train = train[train['Country_Region']==country]\n    #if country_pd_train['Province_State'].isna().unique()==True:\n    if len(country_pd_train['Province_State'].unique())<2:\n        predict_test, score = fit_model_new(country_pd_train,country,make_plot=False)\n        if score ==0:\n            print(f'{country} no case')\n        validation_scores.append(score)\n        validation_county.append(country)\n        validation_country.append(country)\n        test.loc[test['Country_Region']==country,'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n        test.loc[test['Country_Region']==country,'Fatalities'] = predict_test['Fatalities'].tolist()\n    else:\n        for state in country_pd_train['Province_State'].unique():\n            if state != state: # check nan\n                state_pd = country_pd_train[country_pd_train['Province_State'].isna()]\n                predict_test, score = fit_model_new(state_pd,state,make_plot=False)\n                if score ==0:\n                    print(f'{country} \/ {state} no case')\n                validation_scores.append(score)\n                validation_county.append(state)\n                validation_country.append(country)\n                test.loc[(test['Country_Region']==country)&(test['Province_State'].isna()),'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n                test.loc[(test['Country_Region']==country)&(test['Province_State'].isna()),'Fatalities'] = predict_test['Fatalities'].tolist()\n            else:\n                state_pd = country_pd_train[country_pd_train['Province_State']==state]\n                predict_test, score = fit_model_new(state_pd,state,make_plot=False)\n                if score ==0:\n                    print(f'{country} \/ {state} no case')\n                validation_scores.append(score)\n                validation_county.append(state)\n                validation_country.append(country)\n                test.loc[(test['Country_Region']==country)&(test['Province_State']==state),'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n                test.loc[(test['Country_Region']==country)&(test['Province_State']==state),'Fatalities'] = predict_test['Fatalities'].tolist()\n         #   print(f'{country} {state} {score:0.5f}')\n            \nprint(f'Mean validation score: {np.average(validation_scores):0.5f}')","e38e2024":"validation_scores = pd.DataFrame({'country\/state':validation_country,'country':validation_county,'MSLE':validation_scores})\nvalidation_scores.sort_values(by=['MSLE'], ascending=False).head(20)","e53e67ef":"large_msle = validation_scores[validation_scores['MSLE']>1]","d73cd2ee":"test_end = datetime.datetime.strptime('2020-05-14','%Y-%m-%d')\ntest_start = datetime.datetime.strptime('2020-04-02','%Y-%m-%d')\ntrain_max = train.Date_datetime.max()\ntrain_min = train.Date_datetime.min()\ndelta_days =(test_end - train_max).days\nall_days =(test_end - train_min).days\ndelta_days,all_days","d00f5027":"from sklearn import linear_model\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n\nfor country in large_msle['country'].unique():\n    if (country!= country)==False: # check None\n        #print ('training model for country ==>'+country)\n        country_pd_train = train[train['Country_Region']==country]\n        country_pd_test = test[test['Country_Region']==country]\n        if len(country_pd_train)==0:\n            country_pd_train = train[train['Province_State']==country]\n            country_pd_test = test[test['Province_State']==country]\n            \n            test_end = datetime.datetime.strptime('2020-05-14','%Y-%m-%d')\n            test_start = datetime.datetime.strptime('2020-04-02','%Y-%m-%d')\n            train_max = train.Date_datetime.max()\n            train_min = train.Date_datetime.min()\n            delta_days =(test_end - train_max).days\n            \n            x = np.array(range(len(country_pd_train))).reshape((-1,1))[:-7]\n            valid_x = np.array(range(len(country_pd_train))).reshape((-1,1))[-7:]\n            y = country_pd_train['ConfirmedCases'][:-7]\n            valid_y = country_pd_train['ConfirmedCases'][-7:]\n            y_fat = country_pd_train['Fatalities'][:-7]\n            valid_y_fat = country_pd_train['Fatalities'][-7:]\n            \n            model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model = model.fit(x, y)\n\n            model_fat = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model_fat = model_fat.fit(x, y_fat)\n            \n            predict_y = model.predict(valid_x)\n            predict_yfat = model_fat.predict(valid_x)\n            score = mean_squared_log_error(np.clip(valid_y,0,np.inf), np.clip(predict_y,0,np.inf))\n            score_fat = mean_squared_log_error(np.clip(valid_y_fat,0,np.inf), np.clip(predict_yfat,0,np.inf))\n            score = (score+score_fat)\/2\n\n            print(f'{country} {score:0.5f}')\n            if score < large_msle[large_msle['country']==country]['MSLE'].tolist()[0]:\n                validation_scores.loc[validation_scores['country']==country,'MSLE'] = score\n                predict_x = (np.array(range(all_days))).reshape((-1,1))\n                predict_result = model.predict(predict_x)\n                predict_fat_result = model_fat.predict(predict_x)\n                test.loc[test['Province_State']==country,'ConfirmedCases'] = country_pd_train[country_pd_train.Date_datetime>=test_start]['ConfirmedCases'].tolist()+predict_result[-(delta_days):].tolist()\n                test.loc[test['Province_State']==country,'Fatalities'] = country_pd_train[country_pd_train.Date_datetime>=test_start]['Fatalities'].tolist()+predict_fat_result[-(delta_days):].tolist()\n        else:\n            x = np.array(range(len(country_pd_train))).reshape((-1,1))[:-7]\n            valid_x = np.array(range(len(country_pd_train))).reshape((-1,1))[-7:]\n            y = country_pd_train['ConfirmedCases'][:-7]\n            valid_y = country_pd_train['ConfirmedCases'][-7:]\n            y_fat = country_pd_train['Fatalities'][:-7]\n            valid_y_fat = country_pd_train['Fatalities'][-7:]\n            \n            model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model = model.fit(x, y)\n\n            model_fat = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model_fat = model_fat.fit(x, y_fat)\n            \n            predict_y = model.predict(valid_x)\n            predict_yfat = model_fat.predict(valid_x)\n            score = mean_squared_log_error(np.clip(valid_y,0,np.inf), np.clip(predict_y,0,np.inf))\n            score_fat = mean_squared_log_error(np.clip(valid_y_fat,0,np.inf), np.clip(predict_yfat,0,np.inf))\n            score = (score+score_fat)\/2\n\n            print(f'{country} {score:0.5f}')\n            if score < large_msle[large_msle['country']==country]['MSLE'].tolist()[0]:\n                validation_scores.loc[validation_scores['country']==country,'MSLE'] = score\n                predict_x = (np.array(range(all_days))).reshape((-1,1))\n                predict_result = model.predict(predict_x)\n                predict_fat_result = model_fat.predict(predict_x)\n                test.loc[test['Country_Region']==country,'ConfirmedCases'] = country_pd_train[country_pd_train.Date_datetime>=test_start]['ConfirmedCases'].tolist()+predict_result[-(delta_days):].tolist()\n                test.loc[test['Country_Region']==country,'Fatalities'] = country_pd_train[country_pd_train.Date_datetime>=test_start]['Fatalities'].tolist()+predict_fat_result[-(delta_days):].tolist()\n                \nMSLE_score = validation_scores['MSLE'].tolist()     \nprint(f'Mean validation score: {np.average(MSLE_score):0.5f}')\n","efa829af":"submit = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/submission.csv')\nsubmit['Fatalities'] = test['Fatalities'].astype('float')\nsubmit['ConfirmedCases'] = test['ConfirmedCases'].astype('float')\nsubmit.to_csv('submission.csv',index=False)","3a1ac764":"submit.head()","0731a2e4":"# Conclusion\n* This SEIR model is for idea Compartmental models in epidemiology, it's rough\n* R0 reduce can be cause by many things (government, Medical system, calture(habit to wear mask), people behavior)\n* We can using real data of recover for each country to define \"T_inf\"\n\n# Hope COVID-19 will be under control soon","ddb6120b":"## Predict all Country\/Region and Province\/States\n* Counting all Country\/Region MSLE & predict\n* If MSLE is lower than 1 , using PR model to retrain and check the performance","1016d455":"## SEIR Model function\n* Function From [SEIR Great APP](http:\/\/gabgoh.github.io\/COVID\/index.html)\n![image.png](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/3\/3d\/SEIR.PNG)\n* S ==> Susceptible : number of susceptible\n* E ==> Expose : number of expose\n* I ==> Infectious : number of infectious\n* R ==> Recovered or Removed : number recovered (or immune) individuals. \n* We have S + E + I + R = N, this is only constant because of the (degenerate) assumption that birth and death rates are equal, N is country population.\n\nSusceptible \u2192 Exposed \u2192 Infected \u2192 Removed, Differential Function as below (from [SEIR Great APP](http:\/\/gabgoh.github.io\/COVID\/index.html)): \n![image.png](attachment:image.png)\nWe need to solve the Differential equation to find the S,E,I,R, but what is **\"R_t\"**, **\"T_inf\"**, **\"T_inc\"** and how can we define those variable?\n* R_0 & R_t ==> [Reproduction number](https:\/\/en.wikipedia.org\/wiki\/Basic_reproduction_number), The definition describes the state where no other individuals are infected or immunized (naturally or through vaccination)\n* T_inf ==> Average duration of the infection, 1\/T_inf can be treat as individual experiences one recovery in D units of time.\n* T_inc ==> Average incubation period, Many paper and article define as 5.1 ([reference](https:\/\/www.ncbi.nlm.nih.gov\/pubmed\/32150748), [reference2](https:\/\/www.worldometers.info\/coronavirus\/coronavirus-incubation-period\/))\n\n### Assume there are some intervention will cause reproduction number (R_0) reduce (such as bed nets and vaccines,government, isolation ....), have an effectiveness which decays over time ","8a4b822e":"## Retrain PR model for MSLE>1 countries\n* If MSLE of PR model lower than SEIR model, than use PR model as predict result","d56f9889":"## Let's fit SEIR model on country\n* Check Taiwan(My country!!), South Korean, Japan, Italy, New York\n* Hope these are not ture... Italy and New York are very terrifying....","a7cb7203":"### Model with intervention\n* There are different way to reduce R_t, [Differnt decay function](https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions) as below, we are using hill function\n![image](https:\/\/raw.githubusercontent.com\/wiki\/SwissTPH\/openmalaria\/img\/graphs\/decay-functions.png)\nThis could be modified to take any function of `R_t(t)` values to model the reproduction number as a time varying variable\n* Result shows the predict value greate fit the current comfirmedcases\n* You can also using different decay function as above to reduce \"R_t\"","b792c044":"### Load populations of each country","2ebe309e":"## Let's try simple SEIR model on Hubei\n* Already defined R0, T_inf, T_inc. \n* Compare invention and non-invention condition on SEIR model.","dbe55757":"### Plot SEIR model and predict","3e321e84":"### Load dataset (Global ComfirmedCase of each country)","81fb3c2e":"### Intervention by Hill function for SEIR model\n* https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions","f86437ee":"### Cumsum signal\n* to prevent fluctuation","3ce6fa03":"## Fit the SEIR model to real data\nFind the best variables of SEIR model to fit the real data\n* T_inf ==> Using average value 2.9 \n* T_inc ==> Using average value 5.2\n* **R_t** ==> find the best reproduction number by fitting the real data (if have decay function, find the paramater of decay function)\n* **cfr** ==> find the best Case fatality rate, this parater is for predict Fatalities","c3fa71d1":"### Intervention by after days for SEIR model\n* after days, start interverntion, R0 = R0 * 0.5","8e807997":"## Submit result","53fe9cc6":"# SEIR & PR Model for COVID19 Global forecast\n\nSEIR MODEL Reference:\n* Many thanks for @datasaurus great Kernel : https:\/\/www.kaggle.com\/anjum48\/seir-model-with-intervention\n* [Compartmental models in epidemiology - SEIR](https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology#The_SEIR_model)\n* [SEIR Great APP](http:\/\/gabgoh.github.io\/COVID\/index.html)\n\nPR model Reference:\n* [My previous kernel](https:\/\/www.kaggle.com\/super13579\/covid19-global-forcast-simple-eda-pr-model)\n","a90a43bd":"### Model without intervention\n* We can see the without intervention, Hubei comfirmedcase will keep increase... this is very terrifying.","c424501a":"### Check the total US trend","2b9c5e31":"### Function of Fit the SEIR model to real data\n* Auto choose the best decay function of R_t (intervention days decay or Hill decay)\n* Total case\/country population is below 1, reduce country population\n* If datset still no case, return 0 \n* Plot the fit result and forecast trends (Infect smooth decrease by what date)\n* Function being hide, there are describe in code."}}