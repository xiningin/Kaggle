{"cell_type":{"4bd47532":"code","0304a9ee":"code","926c9adb":"code","d9c4c818":"code","8a183bf0":"code","140cc368":"code","cd527cdd":"code","9acf460d":"code","06c07508":"code","04e50b68":"code","f1ee70db":"code","2d0c94a1":"code","ea207510":"code","e8d6c3fd":"code","e2275d94":"code","19d4c7e7":"code","8db09dd5":"code","b5ac4293":"code","101e1894":"code","bdb34d36":"code","5a0da58b":"code","2c192729":"code","062006f3":"code","f05602c5":"code","38f9e272":"code","1326a74c":"code","08e36cd4":"code","a9e85714":"markdown","bf977ac8":"markdown","d92f2932":"markdown","879bb6a3":"markdown","faa39c59":"markdown","cbb2dac8":"markdown","ca734d63":"markdown","3cb6adf9":"markdown","a9a36569":"markdown","40dfc04f":"markdown","3a9af539":"markdown","4be26c84":"markdown","2f19a024":"markdown","caa835b9":"markdown","5cf3438c":"markdown","1b3a768a":"markdown","b9e362d8":"markdown","c9305d79":"markdown","3a9f1443":"markdown","39ad895c":"markdown","20e39d0e":"markdown"},"source":{"4bd47532":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom PIL import Image\nfrom glob import glob\nimport tensorflow as tf\nimport cv2\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dense , Dropout, Flatten , Conv2D,MaxPool2D , MaxPooling2D\nfrom keras import regularizers\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","0304a9ee":"def read_images(path,num_img):\n    array=np.zeros((num_img,224,224,3))\n    i=0\n    for img in os.listdir(path):\n        img_path=path + \"\/\" + img\n        img=Image.open(img_path,mode=\"r\")\n        data=np.asarray(img,dtype=\"uint8\")\n        array[i]=data\n        i+=1\n    return array\n#no\nno_dr_path=r\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/No_DR\"\nnum_no_dr=len(glob(\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/No_DR\/*\"))\nno_dr_array=read_images(no_dr_path,num_no_dr)\nno_dr_array=no_dr_array.astype(np.uint8)\n#mild\nmild_path=r\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Mild\"\nnum_mild=len(glob(\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Mild\/*\"))\nmild_array=read_images(mild_path,num_mild)\nmild_array=mild_array.astype(np.uint8)\n#moderate\nmoderate_path=r\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Moderate\"\nnum_moderate=len(glob(\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Moderate\/*\"))\nmoderate_array=read_images(moderate_path,num_moderate)\nmoderate_array=moderate_array.astype(np.uint8)\n#proliferate\nproliferate_dr_path=r\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Proliferate_DR\"\nnum_proliferate_dr=len(glob(\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Proliferate_DR\/*\"))\nproliferate_dr_array=read_images(proliferate_dr_path,num_proliferate_dr)\nproliferate_dr_array=proliferate_dr_array.astype(np.uint8)\n#severe\nsevere_path =r\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Severe\"\nnum_severe=len(glob(\"\/kaggle\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/Severe\/*\"))\nsevere_array=read_images(severe_path,num_severe)\nsevere_array=severe_array.astype(np.uint8)","926c9adb":"print(\"no_dr_array\",no_dr_array.shape)\nprint(\"mild_array\",mild_array.shape)\nprint(\"moderate_array\",moderate_array.shape)\nprint(\"proliferate_dr_array\",proliferate_dr_array.shape)\nprint(\"severe_array\",severe_array.shape)","d9c4c818":"plt.imshow(no_dr_array[1])\nplt.axis(\"off\")\nplt.show()","8a183bf0":"print(\"no_dr_array dtype is\",no_dr_array.dtype)\nprint(\"mild_array dtype is\",mild_array.dtype)\nprint(\"moderate_array dtype is\",moderate_array.dtype)\nprint(\"proliferate_dr_array dtype is\",proliferate_dr_array.dtype)\nprint(\"severe_array dtype is\",severe_array.dtype)","140cc368":"print(\"num_no_dr:\",num_no_dr)\nprint(\"num_mild:\",num_mild)\nprint(\"num_moderate:\",num_moderate)\nprint(\"num_proliferate_dr:\",num_proliferate_dr)\nprint(\"num_severe:\",num_severe)","cd527cdd":"zeros=np.zeros(1805)\nones=np.ones(370)\ntwos=np.full(999,2)\nthrees=np.full(295,3)\nfours=np.full(193,4)\ny = np.concatenate((zeros,ones,twos,threes,fours),axis=0)\nprint(\"y shape\",y.shape)","9acf460d":"sns.countplot(y)\nplt.show()","06c07508":"def resize_images(img):\n    number_of_image=img.shape[0]\n    new_array=np.zeros((number_of_image,64,64,3))\n    for i in range(number_of_image):\n        new_array[i]=cv2.resize(img[i,:,:,:],(64,64))\n    return new_array\nno_dr_array=resize_images(no_dr_array)\nno_dr_array=no_dr_array.astype(np.uint8)\nmild_array=resize_images(mild_array)\nmild_array=mild_array.astype(np.uint8)\nmoderate_array=resize_images(moderate_array)\nmoderate_array=moderate_array.astype(np.uint8)\nproliferate_dr_array=resize_images(proliferate_dr_array)\nproliferate_dr_array=proliferate_dr_array.astype(np.uint8)\nsevere_array=resize_images(severe_array)\nsevere_array=severe_array.astype(np.uint8)","04e50b68":"plt.imshow(no_dr_array[1])\nplt.axis(\"off\")\nplt.show()","f1ee70db":"print(\"new no_dr_array shape\",no_dr_array.shape)\nprint(\"new mild_array shape\",mild_array.shape)\nprint(\"new moderate_array shape\",moderate_array.shape)\nprint(\"new proliferate_dr_array shape\",proliferate_dr_array.shape)\nprint(\"new severe_array shape\",severe_array.shape)","2d0c94a1":"print(\"no_dr_array dtype is\",no_dr_array.dtype)\nprint(\"mild_array dtype is\",mild_array.dtype)\nprint(\"moderate_array dtype is\",moderate_array.dtype)\nprint(\"proliferate_dr_array dtype is\",proliferate_dr_array.dtype)\nprint(\"severe_array dtype is\",severe_array.dtype)","ea207510":"y = to_categorical(y,5)\nprint(\"new y shape\",y.shape)","e8d6c3fd":"x=np.concatenate((no_dr_array,mild_array,moderate_array,proliferate_dr_array,severe_array),axis=0)\nprint(\"x shape\",x.shape)\nprint(\"x dtype is \",x.dtype)","e2275d94":"x=x \/ 255.0","19d4c7e7":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\nprint(\"x_train shape\",x_train.shape)\nprint(\"x_test shape\",x_test.shape)\nprint(\"y_train shape\",y_train.shape)\nprint(\"y_test shape\",y_test.shape)","8db09dd5":"model = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(750,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(240,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(180,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(64,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(5,activation=\"softmax\"))","b5ac4293":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","101e1894":"datagen=ImageDataGenerator(\n                          shear_range=0.3,\n                          horizontal_flip=True,\n                          vertical_flip=True,\n                          zoom_range=0.3,\n                          rotation_range=0.3)\ndatagen.fit(x_train)","bdb34d36":"batch_size=125\nepochs=10","5a0da58b":"hist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=epochs,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] \/\/ batch_size)","2c192729":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.legend()\nplt.show()","062006f3":"model =Sequential([\n        Conv2D(16, 3, padding='same', activation='relu', input_shape=(64, 64, 3)),\n        MaxPooling2D(),\n        Conv2D(32, 3, padding='same', activation='relu'),\n        MaxPooling2D(),\n        Conv2D(64, 5, padding='same', activation='relu'),\n        MaxPooling2D(),\n        Conv2D(64, 5, padding='same', activation='relu'),\n        MaxPooling2D(),\n        \n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.4),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        Dense(8, activation='relu'),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","f05602c5":"hist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=30,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n\nplt.plot(hist.history['loss'], label='train loss')\nplt.plot(hist.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')","38f9e272":"model =Sequential([\n        Conv2D(16, 3, padding='same', activation='relu', input_shape=( 64, 64, 3)),\n        MaxPooling2D(),\n        Conv2D(32, 3, padding='same', activation='relu'),\n        MaxPooling2D(),\n        Conv2D(64, 5, padding='same', activation='relu'),\n        MaxPooling2D(),\n        Conv2D(64, 5, padding='same', activation='relu'),\n        MaxPooling2D(),\n        \n        Flatten(),\n        Dense(128, activation='relu'),\n\n        Dense(64, activation='relu'),\n\n        Dense(8, activation='relu'),\n\n        Dense(1, activation='sigmoid')\n    ])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","1326a74c":"hist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=30,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n\nplt.plot(hist.history['loss'], label='train loss')\nplt.plot(hist.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')","08e36cd4":"model =Sequential([\n        Conv2D(16, 3, padding='same', activation='relu', input_shape=(64, 64, 3)),\n        BatchNormalization(),\n        MaxPooling2D(),\n        Conv2D(32, 3, padding='same', activation='relu'),\n        BatchNormalization(),\n        MaxPooling2D(),\n        Conv2D(64, 5, padding='same', activation='relu'),\n        BatchNormalization(),\n        MaxPooling2D(),\n        Conv2D(64, 5, padding='same', activation='relu'),\n        BatchNormalization(),\n        MaxPooling2D(),\n        \n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.4),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        Dense(8, activation='relu'),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n#datagen=ImageDataGenerator(\n#                          shear_range=0.3,\n#                          horizontal_flip=True,\n#                          vertical_flip=True,\n#                          zoom_range=0.3,\n#                          rotation_range=0.3)\n#datagen.fit(x_train)\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=30,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n\nplt.plot(hist.history['loss'], label='train loss')\nplt.plot(hist.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n#plt.plot(hist.history['accuracy'], label='train acc')\n#plt.plot(hist.history['val_accuracy'], label='val acc')\n#plt.legend()\n#plt.show()\n#plt.savefig('AccVal_acc')","a9e85714":"### I showed the dtypes of arrays for learning arrays' dtypes","bf977ac8":"### I added new images. For example, I wrote horizontal_flip=True. This parameter take an image and it is rotated horizontally and new images are created.","d92f2932":"### I created my model\n* if you increase conv2d number or filters number, your machine learn better\n* if you incerase Dense number or units number, your machine learn better (units=Dense's parameter. Such as 250,125","879bb6a3":"### I categorized the labels for working my model","faa39c59":"### I determined different figures the labels for creating y variable according to keras\n\nno_dr = 0\n\nmild = 1\n\nmoderate = 2\n\nproliferate_dr = 3\n\nsevere = 4","cbb2dac8":"### I normalized the arrays for faster machine operation","ca734d63":"### I compiled my model ","3cb6adf9":"**# \u0647\u0645\u0627\u0646\u200c\u0637\u0648\u0631 \u06a9\u0647 \u0645\u0634\u0627\u0647\u062f\u0647 \u0645\u06cc\u200c\u0634\u062f \u0628\u0627 \u062d\u062f\u0641 \u0644\u0627\u06cc\u0647\u200c\u0647\u0627\u06cc \u062d\u0630\u0641 \u062a\u0635\u0627\u062f\u0641\u06cc \u0627\u0632 \u0645\u062f\u0644\n* \u0627\u062e\u062a\u0644\u0627\u0641 \u062f\u0642\u062a \u0648 \u062a\u0627\u0628\u0639 \u0632\u06cc\u0627\u0646 \u0632\u06cc\u0627\u062f\u062a\u0631 \u0634\u062f\u0647 \u0627\u0633\u062a\n* \u062f\u0631 \u0646\u062a\u06cc\u062c\u0647 \u0645\u062f\u0644 \u062f\u0627\u0631\u0627\u06cc \u0628\u06cc\u0634\u200c\u0628\u0631\u0627\u0632\u0634 \u0645\u06cc\u200c\u0628\u0627\u0634\u062f**","a9a36569":"### I showed an image you","40dfc04f":"### I splitted it into two as training set and test set.","3a9af539":"### I converted from image to array but array's dtype must be uint8 for show the images.\n","4be26c84":"### I resized arrays (64,64,3) because RAM inadequate from me. If you increase size of arrays, the machine learn better but it works slowly","2f19a024":"### I imported the necessary libraries ","caa835b9":"\u0645\u0634\u0627\u0647\u062f\u0647 \u0645\u06cc\u0634\u0648\u062f \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0627\u0632 \u0646\u0631\u0645\u0627\u0644 \u0633\u0627\u0632\u06cc \u062f\u0633\u062a\u0647 \u0627\u06cc \u0628\u0647 \u0647\u0645\u0631\u0627\u0647 \u062d\u0630\u0641 \u062a\u0635\u0627\u062f\u0641\u06cc \u0627\u062e\u062a\u0644\u0627\u0641 \u062f\u0642\u062a \u0648 \u062a\u0627\u0628\u0639 \u0632\u06cc\u0627\u0646 \u06a9\u0645\u062a\u0631\u06cc \u0631\u0627 \u0646\u0633\u0628\u062a \u0628\u0647 \u0645\u062f\u0644 \u067e\u06cc\u0627\u062f\u0647 \u0633\u0627\u0632\u06cc \u0634\u062f\u0647 \u0628\u0647 \u0647\u0645\u0631\u0627\u0647 \u062f\u0627\u0631\u062f","5cf3438c":"### I started to work my model","1b3a768a":"### I showed the shape for learning images' shape","b9e362d8":"### I showed the arrays (64,64,3)","c9305d79":"### I showed the dtypes of arrays for learning arrays' dtypes","3a9f1443":"### I observed the new shape of arrays","39ad895c":"### I showed how many have images the different features","20e39d0e":"### I combined the arrays for creating training set and test set"}}