{"cell_type":{"fb0c18ca":"code","d3db18d6":"code","e829061f":"code","864a5969":"code","0385aad1":"code","2c712ab4":"code","4875d197":"code","55ed3eb4":"code","1f3a4af1":"code","15342a51":"code","c558ad3c":"code","17b47307":"code","88fb72b4":"markdown","78691bb0":"markdown","15602b2e":"markdown","34f270f8":"markdown","674a5cee":"markdown","5c856519":"markdown","3b410295":"markdown","b4dc2e19":"markdown","6edf3bfd":"markdown","f6289530":"markdown","fabd9901":"markdown","36f81da1":"markdown","a1af53ef":"markdown"},"source":{"fb0c18ca":"import tensorflow as tf\nimport os\nimport pandas as pd\nimport cv2\nfrom skimage.transform import rescale, resize\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.utils import class_weight\nimport tensorflow_addons as tfa\nimport pickle\nfrom skimage.io import imread\nfrom sklearn.utils import shuffle\nfrom matplotlib import pyplot as plt","d3db18d6":"#To get the filenames for a task\ndef filenames(part,train=True):\n    root='..\/input\/mura-v11\/'\n    if train:\n        csv_path=\"..\/input\/mura-v11\/MURA-v1.1\/train_image_paths.csv\"\n    else:\n        csv_path=\"..\/input\/mura-v11\/MURA-v1.1\/valid_image_paths.csv\"\n    \n    with open(csv_path, 'rb') as F:\n        d = F.readlines()\n        if part == 'all':\n            imgs = [root + str(x, encoding='utf-8').strip() for x in d]  # \u6240\u6709\u56fe\u7247\u7684\u5b58\u50a8\u8def\u5f84, [:-1]\u76ee\u7684\u662f\u629b\u5f03\u6700\u672b\u5c3e\u7684\\n\n        else:\n            imgs = [root + str(x, encoding='utf-8').strip() for x in d if\n                            str(x, encoding='utf-8').strip().split('\/')[2] == part]\n\n    #imgs= [x.replace(\"\/\", \"\\\\\") for x in imgs]\n    labels= [x.split('_')[-1].split('\/')[0] for x in imgs]\n    return imgs,labels\n\n\n#To icrop a image from center\ndef crop_center(img,cropx,cropy):\n    y,x,_ = img.shape\n    startx = x\/\/2-(cropx\/\/2)\n    starty = y\/\/2-(cropy\/\/2)    \n    return img[starty:starty+cropy,startx:startx+cropx]\n","e829061f":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,\n    ToFloat, ShiftScaleRotate\n)\nfrom albumentations.augmentations.transforms import Resize\nAUGMENTATIONS_TRAIN = Compose([\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=0.5),\n    RandomGamma(gamma_limit=(80, 120), p=0.5),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ToFloat(max_value=255)\n])\nAUGMENTATIONS_TEST = Compose([\n    # CLAHE(p=1.0, clip_limit=2.0),\n    ToFloat(max_value=255)\n])","864a5969":"albumentation_list =  [\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=0.5),\n    RandomGamma(gamma_limit=(80, 120), p=0.5),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ToFloat(max_value=255)\n]\nroot='..\/input\/mura-v11\/'\nchosen_image= imread(root+'MURA-v1.1\/train\/XR_ELBOW\/patient01055\/study1_positive\/image3.png')\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\nimg= resize(chosen_image,(300,300,3))\nimg_matrix_list.append(img)\nimg_matrix_list.append(crop_center(img,224,224))\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"Horizontal Flip\",\"Random Contrast\",\"Random Gamma\",\"RandomBrightness\",\n               \"Shift Scale Rotate\",\"Resizing\", \"Cropping\"]\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"Data Augmentation\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=2, ncols=ncols, squeeze=True)\n    fig.suptitle(main_title, fontsize = 30)\n    #fig.subplots_adjust(wspace=0.3)\n    #fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4)","0385aad1":"class My_Custom_Generator(keras.utils.Sequence) :\n  \n  def __init__(self, image_filenames, labels, batch_size,transform) :\n    self.image_filenames = image_filenames\n    self.labels = labels\n    self.batch_size = batch_size\n    self.t= transform\n    \n  def __len__(self) :\n    return (np.ceil(len(self.image_filenames) \/ float(self.batch_size))).astype(np.int)\n  \n  \n  def __getitem__(self, idx) :\n    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n    x=[]\n    for file in batch_x:\n        img= imread(file)\n        img= self.t(image=img)[\"image\"]\n        img= resize(img,(300,300,3))\n        img= crop_center(img,224,224)\n        x.append(img)\n    x=np.array(x)\/255.0\n    y= np.array(batch_y)\n    return x,y","2c712ab4":"part='XR_WRIST'\nimgs,labels= filenames(part=part)\nvimgs,vlabels= filenames(part=part,train=False)\nprint(labels.count('positive'),labels.count('negative'))\ntraining_data= labels.count('positive')+labels.count('negative')\nprint(\"Training Data: \", training_data)\ny_data= [0 if x=='positive' else 1 for x in labels]\ny_data= keras.utils.to_categorical(y_data)\nprint(vlabels.count('positive'),vlabels.count('negative'))\nvalidation_data= vlabels.count('positive')+vlabels.count('negative')\nprint(\"Validation Data: \", validation_data)\nvy_data= [0 if x=='positive' else 1 for x in vlabels]\nvy_data= keras.utils.to_categorical(vy_data)","4875d197":"from sklearn.utils.class_weight import compute_class_weight\n\ny_integers = np.argmax(y_data, axis=1)\nclass_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\nd_class_weights = dict(enumerate(class_weights))","55ed3eb4":"batch_size = 32\nimgs, y_data = shuffle(imgs, y_data)\n#vimgs, vy_data = shuffle(vimgs, vy_data)\nmy_training_batch_generator = My_Custom_Generator(imgs, y_data, batch_size,AUGMENTATIONS_TRAIN)\nmy_validation_batch_generator = My_Custom_Generator(vimgs, vy_data, batch_size,AUGMENTATIONS_TEST)","1f3a4af1":"part='XR_WRIST'\ncheckpoint_path = root+\"MURA-v1.1\/\"+part+\"\/WRIST.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nmy_callbacks = [\n    keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=0, save_best_only=True,\n                                       save_weights_only=False, mode='auto'),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,patience=3,\n                                         min_delta=0.001, verbose=1, min_lr=0.000000001)]\n","15342a51":"Inception=keras.applications.InceptionResNetV2(include_top=False,input_shape=(224,224,3))\n#for layer in Inception.layers[:4]:\n#  layer.trainable=False\ninput_image=keras.layers.Input((224,224,3))\nx=Inception (input_image)\n\n#x=keras.layers.GlobalAveragePooling2D()(x)\nx=keras.layers.Flatten()(x)\n#x=keras.layers.Dense(1024)(x)\n#x=keras.layers.Activation(activation='relu')(x)\n#x= keras.layers.Dropout(0.5)(x)\nx=keras.layers.Dense(256)(x)\nx=keras.layers.Activation(activation='relu')(x)\nx= keras.layers.Dropout(0.5)(x)\nx=keras.layers.Dense(2)(x)\nout=keras.layers.Activation(activation='softmax')(x)\n\nmodel=keras.Model(inputs=input_image,outputs=out)\nmodel.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\nprint(model.summary())","c558ad3c":"history=model.fit_generator(generator=my_training_batch_generator,\n                   steps_per_epoch = int(training_data \/\/ batch_size),\n                   epochs = 30,\n                   verbose = 1,\n                   class_weight=d_class_weights,\n                   validation_data = my_validation_batch_generator,\n                   validation_steps = int(validation_data \/\/ batch_size),\n                   callbacks=my_callbacks)","17b47307":"m = tfa.metrics.CohenKappa(num_classes=2,sparse_lables=False)\nmodel=tf.keras.models.load_model(checkpoint_path)\ny_pred=  model.predict(my_validation_batch_generator)\n\nyp2 = np.argmax(y_pred,axis = 1)\nya2 = np.argmax(vy_data,axis = 1)\nprint(y_pred.shape,vy_data.shape)\nm.update_state(ya2, yp2)\nprint('Final result: ', m.result().numpy())","88fb72b4":"Data augmentations","78691bb0":"* Calculate class-weight to avoid class-imbalance ","15602b2e":"* Create Training and Test daat generator","34f270f8":"# This notebook is a guide for classification task in MURA dataset. ","674a5cee":"****Some utility functions****","5c856519":"*  *Training*","3b410295":"* Training callbacks","b4dc2e19":"* Evaluate the performance by cohen's kappa score","6edf3bfd":"Creating data generator for training and testiing with augmentation","f6289530":"Getting data using the utility functions","fabd9901":"Plotting the augmentations","36f81da1":"Import the modules","a1af53ef":"* Create a model"}}