{"cell_type":{"58ef00ca":"code","52c876c6":"code","868bbbe6":"code","91e508b2":"code","81892770":"code","a7ff22d0":"code","0867990e":"code","552f5e93":"code","87d636ed":"code","3f58b6f0":"code","a9a8e32b":"code","f974f50d":"code","f901e93c":"code","074a7c1c":"code","bac881b2":"code","d3ed1c20":"code","8b5f8c9e":"code","456a1250":"code","2a40ea9c":"code","3accc110":"code","5d38398d":"code","682c64a5":"code","54ca8f9e":"code","498d311c":"code","96cce436":"code","4a93925f":"code","64a67f1f":"code","582bac62":"code","be2421f7":"code","dd5f794a":"code","f122b1ca":"code","9d113f28":"code","5ff7aa52":"markdown","649624ef":"markdown","c5816413":"markdown"},"source":{"58ef00ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52c876c6":"# Importing Libraries \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport os\nfrom keras.utils import to_categorical","868bbbe6":"# Reading the input images and putting them into a numpy array\ndata=[]\nlabels=[]\n\nheight = 30\nwidth = 30\nchannels = 3\nclasses = 43\nn_inputs = height * width*channels\n\n","91e508b2":"classs = { 0: \"Speed limit (20km\/h)\", \n           1: \"Speed limit (30km\/h)\", \n           2: \"Speed limit (50km\/h)\", \n           3: \"Speed limit (60km\/h)\", \n           4: \"Speed limit (70km\/h)\", \n           5: \"Speed limit (80km\/h)\",\n           6: \"End of Speed limit (80km\/h)\", \n           7: \"Speed limit (100km\/h)\", \n           8: \"Speed limit (120km\/h)\",\n           9: \"No passing\", \n           10: \"No passing veh over 3.5 tons\", \n           11: \"Right-of-way at intersection\",\n           12: \"Priority road\", \n           13: \"Yield\", \n           14: \"Stop\", \n           15: \"No vehicles\", \n           16: \"Veh > 3.5 tons prohibited\",\n           17: \"No entry\", \n           18: \"General caution\", \n           19: \"Dangerous curve left\", \n           20: \"Dangerous curve right\", \n           21: \"Double curve\", \n           22: \"Bumpy road\", \n           23: \"Slippery road\", \n           24: \"Road narrows on the right\",\n           25: \"Road work\", \n           26: \"Traffic signals\", \n           27: \"Pedestrians\", \n           28: \"Children crossing\", \n           29: \"Bicycle crossing\",\n           30: \"Beware of ice\/snow\", \n           31: \"Wild animals crossing\", \n           32: \"End speed + passing limits\", \n           33: \"Turn right ahead\", \n           34: \"Turn left ahead\", \n           35: \"Ahead only\", \n           36: \"Go straight or right\", \n           37: \"Go straight or left\", \n           38: \"Keep right\", \n           39: \"Keep Left\", \n           40: \"Roundabout mandatory\",\n           41: \"End of no passing\", \n           42: \"End of no passing veh > 3.5 tons\"}","81892770":"train_csv = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Train.csv')\ntest_csv = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Test.csv')\n","a7ff22d0":"train_csv.head()","0867990e":"training_images_path = list('\/kaggle\/input\/gtsrb-german-traffic-sign\/' + train_csv['Path'])\ntesting_images_path = list('\/kaggle\/input\/gtsrb-german-traffic-sign\/' + test_csv['Path'])","552f5e93":"train_csv['ClassId'].unique() # all unique classes available in the data ","87d636ed":"# from sklearn.utils import shuffle\n\ntraining_labels = list(train_csv['ClassId'])\ntesting_labels = list(test_csv['ClassId'])\n\ntraining_labels = training_labels\ntesting_labels = testing_labels\n\nprint(len(training_labels))\n# training_images_path,training_labels = shuffle(training_images_path,training_labels)\n\n# training_images_path = training_images_path\n# training_labels = training_labels\n\nunique_classes = pd.unique(training_labels)\nprint('Total Classes = ',format(len(unique_classes)))\nprint('Total Training Examples = ',format(len(training_images_path)))","3f58b6f0":"train_df = pd.DataFrame(data = {'Path':training_images_path,'Labels':training_labels})\ntrain_df= train_df.sample(frac=1).reset_index(drop=True)\n","a9a8e32b":"train_df.head()","f974f50d":"plt.imshow(cv2.imread(train_df[\"Path\"][1]))\nprint(classs[(train_df['Labels'][1])])","f901e93c":"test_df = pd.DataFrame(data = {'Path':testing_images_path,'Labels':testing_labels})\ntest_df= test_df.sample(frac=1).reset_index(drop=True)\n","074a7c1c":"rand_num = np.random.randint(1 , 400,size = 25)\n\nprint(rand_num)\nfor num in range(len(rand_num)):\n    plt.subplot(5,5,num+1)\n    #print(training_images_path[rand_num[num]])\n    img = cv2.imread(training_images_path[rand_num[num]])\n    plt.imshow(img)\n    plt.title(training_labels[rand_num[num]])\n    plt.subplots_adjust(wspace=0.2, hspace=0.8)\n    plt.xticks([])\n    plt.yticks([])","bac881b2":"training_data = []\n#print(training_images_path)\nfor num in range(len(train_df)):\n    #print(num)\n    img = cv2.imread(train_df['Path'][num])\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    img = cv2.equalizeHist(img.astype('uint8'))\n\n    img = img\/255.00\n    img = cv2.resize(img, (33,33),  \n               interpolation = cv2.INTER_NEAREST)\n#     img = img.reshape((33,33,1))\n    training_data.append(img)\n    \ntraining_data = np.array(training_data)","d3ed1c20":"testing_data = []\n#print(training_images_path)\nfor num in range(len(test_df)):\n    #print(num)\n    img = cv2.imread(test_df['Path'][num])\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    img = cv2.equalizeHist(img.astype('uint8'))\n\n    img = img\/255.00\n    img = cv2.resize(img, (33,33),  \n               interpolation = cv2.INTER_NEAREST)\n#     img = img.reshape(33,33,1)\n    testing_data.append(img)\n    \ntesting_data = np.array(testing_data)","8b5f8c9e":"training_data = training_data.reshape(training_data.shape[0],training_data.shape[1],training_data.shape[2],1)","456a1250":"testing_data = testing_data.reshape(testing_data.shape[0],testing_data.shape[1],testing_data.shape[2],1)","2a40ea9c":"from keras.preprocessing.image import ImageDataGenerator","3accc110":"datagen = ImageDataGenerator(width_shift_range = 0.1,\n                            height_shift_range = 0.1,\n                            zoom_range = 0.2,\n                            shear_range = 0.1,\n                            rotation_range = 10,\n                            horizontal_flip=False)","5d38398d":"datagen.fit(training_data)","682c64a5":"y_train = to_categorical(train_df.Labels) # Changing into categorical variable \ny_test = to_categorical(test_df.Labels) # changing into categorical variable ","54ca8f9e":"batch = datagen.flow(training_data,y_train,batch_size = 20)","498d311c":"train_batch, train_label_batch = next(batch)","96cce436":"\nplt.imshow(train_batch[6].reshape(33,33))\nprint(np.argmax(train_label_batch[6]))","4a93925f":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nstop = EarlyStopping(monitor  = 'val_accuracy', patience = 5,restore_best_weights=True) # early stopping callbacks\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(33,33,1)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(43, activation='softmax'))\n\n#Compilation of the model\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)","64a67f1f":"history = model.fit_generator(datagen.flow(training_data,y_train, batch_size = 20) ,validation_data = (testing_data,y_test), epochs = 30, verbose = 1,callbacks=[stop])","582bac62":"pred = model.predict(testing_data)","be2421f7":"result = np.argmax(pred, axis = 1)","dd5f794a":"from sklearn.metrics import accuracy_score\naccuracy_score(test_df.Labels,result)\n","f122b1ca":"model.save('\/kaggle\/working\/model_traffic_data1.h5')","9d113f28":"plt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","5ff7aa52":"DATA AUGMENTATION","649624ef":"## Since the pictures were too small and it was also in large quantity hence we havnt used data augmentation","c5816413":"## Plotting the result and graphs"}}