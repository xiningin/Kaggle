{"cell_type":{"2722b70c":"code","aa7ef57f":"code","46866783":"code","cf46152c":"code","63afd555":"code","c480ee23":"code","f55ed03b":"code","b951a6d3":"code","36f0f8a3":"code","92b88aaf":"code","1107a9cd":"code","4496d473":"code","48d9779b":"code","68f33d34":"code","ac08440b":"code","c85c0829":"markdown","7e17839d":"markdown","708874ac":"markdown","4d3037c2":"markdown","f7c3d007":"markdown","250b71e5":"markdown","04635827":"markdown","8b2cfd30":"markdown","9afaa666":"markdown","68ff4713":"markdown","5d9b5021":"markdown","75dfe290":"markdown","1a6d21b6":"markdown","8a946ee5":"markdown","00593926":"markdown","ab8d23b1":"markdown"},"source":{"2722b70c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","aa7ef57f":"# BeautifulSoup is a Python library for pulling data out of HTML and XML files\nfrom bs4 import BeautifulSoup as bs\n\n# urllib.request for opening and reading URLs\nfrom urllib.request import urlopen","46866783":"# Getting the website page address\nurl = 'https:\/\/wuzzuf.net\/search\/jobs\/?a=navbl%7Cspbl&q=illustrator'","cf46152c":"client = urlopen(url)","63afd555":"html = client.read()\nprint(html)","c480ee23":"client.close()","f55ed03b":"soup = bs(html, \"html.parser\")","b951a6d3":"# Now we have a well-prepared html code\nsoup","36f0f8a3":"containers = soup.find_all(\"div\", {\"class\" : \"css-1gatmva e1v1l3u10\"})","92b88aaf":"len(containers)","1107a9cd":"print(bs.prettify(containers[0]))","4496d473":"# Let's check how to access a specific element in the page (i.e. the job title)\ncontainers[0].div.h2.text","48d9779b":"# Here is the best practice (better way) for accessing the job title\njob_title = containers[0].findAll(\"h2\", {\"class\": \"css-m604qf\"})\njob_title[0].text ","68f33d34":"company_name = containers[0].findAll(\"a\", {\"class\": \"css-17s97q8\"})\ncompany_name[0].text","ac08440b":"# We need to create a file to save our new data to it\n# f = open('data\/wuzzuf.csv','w')\n# headers = \"Job_Ttile, Company_Name\\n\"\n# f.write(headers)\n\n# Now we will get ALL the needed data from the web page\n#for container in containers:\n    #jtitle = container.findAll(\"h2\", {\"class\": \"css-m604qf\"})\n    #job_title = jtitle[0].text.strip()\n    \n    #cname = container.findAll(\"a\", {\"class\": \"css-17s97q8\"})\n    #company_name = cname[0].text.strip()\n    \n    #jtype = container.findAll(\"a\", {\"class\": \"css-n2jc4m\"})\n    #job_type = jtype[0].text.strip()\n    \n#     print(job_title)\n#     print(company_name)\n#     print(job_type)\n#     print()\n    \n    #print(job_title + \", \" + company_name + \", \" + job_type)\n    #f.write(job_title + \", \" + company_name + \", \" + job_type + \"\\n\")\n\n#f.close()","c85c0829":"==========","7e17839d":"### Importing Libraries","708874ac":"==========","4d3037c2":"##### Creating an HTML Parser Using BeautifulSoup","f7c3d007":"##### Getting the HTML Code of the Full Page","250b71e5":"##### Closing the Request","04635827":"##### Creating a Container for the Needed Data","8b2cfd30":"## Case-study: Wuzzuf.com [Web Scraping]","9afaa666":"##### Importing Libraries & Methods","68ff4713":"##### How Do I Scrape Data From A Website?","5d9b5021":"- Find the URL that you want to scrape\n- Inspecting the Page\n- Find the data you want to extract\n- Write the code\n- Run the code and extract the data\n- Store the data in the required format ","75dfe290":"##### Accessing Page Elements","1a6d21b6":"- Wuzzuf.com URL: https:\/\/wuzzuf.net\/search\/jobs\/?a=navbl%7Cspbl&q=illustrator","8a946ee5":"##### Inputting the URL","00593926":"##### Bringing it All Together","ab8d23b1":"##### Create a Client-based Request to Get the URL"}}