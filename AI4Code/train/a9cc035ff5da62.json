{"cell_type":{"e08a7c79":"code","dadcef18":"code","1b994049":"code","df555ad5":"code","77623634":"code","123b0a83":"code","131c54e0":"code","f0240384":"code","fbf846f2":"code","b94c2b03":"code","83fb99e7":"code","a99aee92":"code","20d74568":"code","6098ee7a":"code","b8c70879":"code","48cc9f0a":"code","2bd94d2b":"code","ea03d8cb":"code","87127d17":"code","ef12cd58":"code","b06c10fe":"code","e20a064a":"code","0d8ddb19":"code","32c41be8":"code","8ef8ce25":"code","cf178dbe":"code","34fc6182":"code","29da7d60":"code","805b1918":"code","78d81b72":"code","8c2250d6":"code","fa33519c":"code","615214f0":"code","833505f5":"code","96e7369e":"code","700099bd":"markdown","ce57b2d4":"markdown","915063eb":"markdown","996d71fa":"markdown"},"source":{"e08a7c79":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom time import time\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom IPython.display import Image\nfrom multiprocessing import Pool\nfrom scipy.stats import multivariate_normal\nimport cv2\nimport tensorflow as tf\ntf.__version__\n\nfrom IPython.display import Image\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","dadcef18":"root = \"..\/input\"\nroot_test = root + '\/test\/test'\nroot_train = root + '\/train\/train'\nprint(os.listdir(root))","1b994049":"identify = pd.DataFrame.from_csv(root + '\/train.csv')","df555ad5":"total_test = os.listdir(root_test)\ntotal_train = os.listdir(root_train)\nlen(total_train)","77623634":"identify[identify.index=='6ba575bb5788a9b77a4cef2fb4fdf24d.jpg'].has_cactus.values[0]\n#identify[0:1].has_cactus.values[0]\nidentify[identify.has_cactus==1].index[0]","123b0a83":"total_data = +len(total_test)+len(total_train)","131c54e0":"total_cactus = len(identify[identify.has_cactus.values==1])\ntotal_no_cactus = len(identify[identify.has_cactus.values==0])\ntotal_no_cactus","f0240384":"print('{} Total test'.format(len(total_test)))\nprint('{} Total train'.format(len(total_train)))","fbf846f2":"def sample(y, k):\n    if y == 0:\n        return mpimg.imread(os.path.join(root_train, identify[identify.has_cactus==0].index[k]))\n    elif y == 1:\n        return mpimg.imread(os.path.join(root_train, identify[identify.has_cactus==1].index[k]))\n    else:\n        raise ValueError","b94c2b03":"sample(0, 0).shape","83fb99e7":"f, ax = plt.subplots(4, 2, figsize=(10, 10))\nfor k in range(4):\n    for y in range(2):\n        ax[k][y].imshow(sample(y, k))","a99aee92":"sample(0,1).shape","20d74568":"y_total = []\nx_total = np.zeros((total_no_cactus+total_no_cactus,16,16,3))\nfor i in range(total_no_cactus):\n    x_total[i] = cv2.resize(sample(0,i),(16,16))\n    y_total.append(0)\nfor j in range(total_no_cactus):\n    x_total[j+total_no_cactus] = cv2.resize(sample(1,j),(16,16))\n    y_total.append(1)","6098ee7a":"len(y_total)","b8c70879":"y_total_np=np.array(y_total)\ny_total_np[total_no_cactus-1]","48cc9f0a":"x_train, x_test, y_train, y_test = train_test_split(x_total, y_total_np, test_size=.25)\nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\nprint(\"\\ndistribution of train classes\")\nprint(pd.Series(y_train).value_counts())\nprint(\"\\ndistribution of test classes\")\nprint(pd.Series(y_test).value_counts())","2bd94d2b":"def get_conv_model_A(num_classes, img_size=16, compile=True):\n    tf.reset_default_graph()\n    tf.keras.backend.clear_session()\n    print(\"using\",num_classes,\"classes\")\n    inputs = tf.keras.Input(shape=(img_size,img_size,3), name=\"input_1\")\n    layers = tf.keras.layers.Conv2D(12,(3,3), activation=\"relu\")(inputs)\n    layers = tf.keras.layers.Flatten()(layers)\n    layers = tf.keras.layers.Dense(15, activation=tf.nn.relu)(layers)\n    layers = tf.keras.layers.Dropout(0.2)(layers)\n    predictions = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\")(layers)\n    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n    if compile:\n        model.compile(optimizer='adam',\n                      loss='sparse_categorical_crossentropy',\n                      metrics=['accuracy'])\n    return model","ea03d8cb":"model = get_conv_model_A(2)","87127d17":"weights = model.get_weights()\nfor i in weights:\n    print(i.shape)","ef12cd58":"initial_w0 = model.get_weights()[0].copy()","b06c10fe":"y_test.shape, y_train.shape, x_test.shape, x_train.shape","e20a064a":"num_classes = len(np.unique(y_total_np))\n\ndef train(model, batch_size, epochs, model_name=\"\"):\n    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs\/\"+model_name+\"_\"+\"{}\".format(time()))\n    model.reset_states()\n    model.fit(x_train, y_train, epochs=epochs, callbacks=[tensorboard],\n              batch_size=batch_size,\n              validation_data=(x_test, y_test))\n    metrics = model.evaluate(x_test, y_test)\n    return {k:v for k,v in zip (model.metrics_names, metrics)}","0d8ddb19":"model = get_conv_model_A(num_classes)\nmodel.summary()\ntrain(model, batch_size=32, epochs=20, model_name=\"model_A\")","32c41be8":"def get_conv_model_B(num_classes=2 ,entr=60,convol1=70,convol2=75, img_size=16, compile=True):\n    tf.reset_default_graph()\n    tf.keras.backend.clear_session()\n    print(\"using\",num_classes,\"classes\")\n    model = tf.keras.models.Sequential()\n    \n    model.add(tf.keras.layers.Conv2D(convol1,(3,3), activation=\"relu\",input_shape=(img_size,img_size,3)))\n    model.add(tf.keras.layers.MaxPool2D((2,2)))\n    model.add(tf.keras.layers.Conv2D(convol2,(3,3), activation=\"relu\"))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(entr, activation=tf.nn.relu))\n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\"))\n    \n    if compile:\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0005),\n                      loss='sparse_categorical_crossentropy',\n                      metrics=['accuracy'])\n    return model","8ef8ce25":"model = get_conv_model_B(num_classes, 70, 7, 11)\nmodel.summary()\ntrain(model, batch_size=32, epochs=20, model_name=\"model_B\")","cf178dbe":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\n#entr(60,70,75), convol1(5,7,9), convol2(11,12,15)\n\nmodel2 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=get_conv_model_B,epochs=10)\n\npipe = Pipeline([('model2', model2)])\n\nparam_grid = {'model2__entr': [60,70,], \n              'model2__convol1': [5,7,],}\nsearch = GridSearchCV(pipe, param_grid, scoring=\"accuracy\", n_jobs=1, verbose=1)","34fc6182":"search.fit(x_train, y_train)","29da7d60":"search.best_estimator_.score(x_test, y_test)","805b1918":"search.best_params_","78d81b72":"pd.DataFrame(search.cv_results_).columns","8c2250d6":"pd.DataFrame(search.cv_results_)[['params', 'mean_test_score', 'std_test_score']]","fa33519c":"model3 = get_conv_model_B(2)\nmodel3.summary()\ntrain(model3, batch_size=32, epochs=10, model_name=\"model3\")","615214f0":"from sklearn.metrics import roc_curve\ny_pred_keras = model3.predict(x_test)\ny_pred_list=[]\nfor i in y_pred_keras:\n    y_pred_list.append(np.argmax(i))\ny_pred = np.array(y_pred_list)\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)","833505f5":"from sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\nfrom sklearn.ensemble import RandomForestClassifier\n# Supervised transformation based on random forests\nrf = RandomForestClassifier(max_depth=4, n_estimators=10)\nrf.fit(x_train.reshape(-1,768), y_train)\n\ny_pred_rf = rf.predict_proba(x_test.reshape(-1,768))[:, 1]\nfpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_rf)\nauc_rf = auc(fpr_rf, tpr_rf)","96e7369e":"plt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\nplt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n# Zoom in view of the upper left corner.\nplt.figure(2)\nplt.xlim(0, 0.2)\nplt.ylim(0.8, 1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\nplt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve (zoomed in at top left)')\nplt.legend(loc='best')\nplt.show()","700099bd":"To create the model with keras","ce57b2d4":"Modelo de Random Forest Alternativo a la Red Neuronal","915063eb":"To extract to the name of the files","996d71fa":"To know the total images"}}