{"cell_type":{"e3394fe3":"code","7a0918a2":"code","6f87a902":"code","f60e05be":"code","742537ed":"code","ab26a5cd":"code","a93f461f":"code","15eefcbf":"code","89c095d9":"code","2408c57a":"code","9e9bdf07":"code","08f44a6a":"code","82dc5501":"code","bfd29336":"code","1045113f":"code","e5756625":"code","2ea38032":"code","1b42dfec":"code","080f8ff3":"code","ba4471f3":"code","139ca49a":"code","0a05bde5":"code","3cf47783":"code","d4e3ee08":"code","d7a9e01f":"code","716d75ea":"code","0b2e9300":"code","34c892ea":"code","a84c7a46":"code","e8e9dcb4":"code","3268e453":"code","7441fc9d":"code","982ca05c":"code","80d7c711":"code","9e85ba58":"code","adfc7f27":"code","b08d4d7b":"code","42e714e8":"code","8aba6e84":"code","aba63bf1":"code","b3373a8a":"code","bbfeca23":"code","199ce957":"markdown","35745491":"markdown","dca077f1":"markdown"},"source":{"e3394fe3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nimport tensorflow as tf\nimport math\nfrom sklearn.metrics import mean_squared_error","7a0918a2":"data = pd.read_csv('..\/input\/stock-dataset\/Stock.csv')","6f87a902":"data.head()","f60e05be":"data1 = data.reset_index()['close']","742537ed":"data1","ab26a5cd":"data1.shape","a93f461f":"plt.plot(data1 , color = \"purple\")","15eefcbf":"scaler = MinMaxScaler(feature_range=(0,1))","89c095d9":"data1 = scaler.fit_transform(np.array(data1).reshape(-1,1))","2408c57a":"data1","9e9bdf07":"# splitting the dataset into train and test split : \ntraining_size = int(len(data1)*0.65)","08f44a6a":"test_size = len(data1) - training_size","82dc5501":"train_data,test_data = data1[0:training_size,:],data1[training_size:len(data1),:1]","bfd29336":"len(train_data)","1045113f":"len(test_data)","e5756625":"# converting the array values into a dataset matrix : \ndef create_dataset(dataset, time_step = 1):\n    dataX , dataY = [], []\n    for i in range(len(dataset) - time_step - 1 ):\n        a = dataset[i:(i + time_step), 0]  \n        dataX.append(a)\n        dataY.append(dataset[i + time_step, 0])\n    return np.array(dataX), np.array(dataY)","2ea38032":"time_step = 100","1b42dfec":"X_train, y_train = create_dataset(train_data, time_step)\n\nX_test, y_test = create_dataset(test_data, time_step)","080f8ff3":"X_train.shape","ba4471f3":"y_train.shape","139ca49a":"X_test.shape","0a05bde5":"y_test.shape","3cf47783":"# reshape the input to be in [samples, time steps, features] which is required for LSTM\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)","d4e3ee08":"X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","d7a9e01f":"model=Sequential()","716d75ea":"model.add(LSTM(50,return_sequences = True,input_shape = (100,1)))\nmodel.add(LSTM(50,return_sequences = True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer = 'adam')","0b2e9300":"model.summary()","34c892ea":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 100,batch_size = 64,verbose = 1)","a84c7a46":"# prediction and performance metrics:\ntrain_predict = model.predict(X_train)\ntest_predict = model.predict(X_test)","e8e9dcb4":"# Back to original form : \ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)","3268e453":"# RMSE performance metrics (Training dataset): \nmath.sqrt(mean_squared_error(y_train,train_predict))","7441fc9d":"# RMSE performance metrics (Test dataset): \nmath.sqrt(mean_squared_error(y_test,test_predict))","982ca05c":"# shifting train predictions for plotting\nlook_back=100\ntrainPredictPlot = np.empty_like(data1)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n# shifting test predictions for plotting\ntestPredictPlot = np.empty_like(data1)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(data1)-1, :] = test_predict","80d7c711":"# ploting baseline and predictions\nplt.plot(scaler.inverse_transform(data1) , color = \"yellow\")\nplt.plot(trainPredictPlot , color = \"blue\") # train predict data\nplt.plot(testPredictPlot  , color = \"red\") # test predict data\nplt.show()","9e85ba58":"# previous 100 days:\nx_input = test_data[341:].reshape(1,-1)\nx_input.shape","adfc7f27":"temp_input = list(x_input)","b08d4d7b":"temp_input = temp_input[0].tolist()","42e714e8":"# demonstrate prediction for next 30 days\nlst_output=[]\nn_steps=100\ni=0\nwhile(i<30):\n    \n    if(len(temp_input)>100):\n        #print(temp_input)\n        x_input = np.array(temp_input[1:])\n        print(\"{} day input {}\".format(i,x_input))\n        x_input = x_input.reshape(1,-1)\n        x_input = x_input.reshape((1, n_steps, 1))\n        # print(x_input)\n        yhat = model.predict(x_input, verbose=0)\n        print(\"{} day output {}\".format(i,yhat))\n        temp_input.extend(yhat[0].tolist())\n        temp_input=temp_input[1:]\n        # print(temp_input)\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    else:\n        x_input = x_input.reshape((1, n_steps,1))\n        yhat = model.predict(x_input, verbose=0)\n        print(yhat[0])\n        temp_input.extend(yhat[0].tolist())\n        print(len(temp_input))\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    \n\nprint(lst_output)","8aba6e84":"day_new=np.arange(1,101)","aba63bf1":"day_pred=np.arange(101,131)","b3373a8a":"plt.plot(day_new,scaler.inverse_transform(data1[1158:]) , color=\"green\")\nplt.plot(day_pred,scaler.inverse_transform(lst_output) , color = \"orange\")","bbfeca23":"data3 = data1.tolist()\ndata3.extend(lst_output)\nplt.plot(data3[1200:] , color = \"green\")","199ce957":"# IMPORTING THE DATASET","35745491":"# CREATING THE STACKED LSTM MODEL","dca077f1":"# IMPORTING THE LIBRARIES"}}