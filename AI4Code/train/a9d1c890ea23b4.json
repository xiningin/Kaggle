{"cell_type":{"f4ff492f":"code","dc52dead":"code","3956fdb6":"code","2006de4b":"code","6ed70e36":"code","072e485d":"code","2521ec5e":"code","2783a5cd":"code","fb2ef567":"code","9c26d59a":"code","95e04819":"code","9c9b977b":"code","68ec79b8":"code","438befbd":"code","f4016c30":"code","a1af32ea":"code","22363fe0":"code","0aa6a9b2":"code","24f8f094":"code","26016997":"code","da8f9f01":"code","3f1b000d":"code","984b9701":"code","64cd940e":"code","0631e883":"code","ee3e6dba":"code","90e43141":"code","91d4c64a":"code","eae9b926":"code","6c1a820d":"code","f2d54aee":"code","d45eab9d":"code","f45d1a68":"code","a53663ec":"code","e11f343f":"code","709d2c02":"code","6cd2b395":"code","4aa51250":"code","9747e294":"code","185a3b9b":"code","239e4da8":"code","c1c2515a":"code","fae97d89":"code","bd9a4405":"code","e7d3184f":"code","3df998b2":"code","79b657e1":"code","85279eaa":"code","71b7194f":"code","95177969":"code","eb7902c3":"code","cd3a6a93":"code","85ea8f6f":"code","d9683aa9":"code","69272526":"code","41c51166":"code","d0551048":"code","1aff241b":"code","d87d1d8a":"code","0fc63872":"markdown","c9c54bb2":"markdown","5564df6f":"markdown","99aac989":"markdown","ef435bff":"markdown","f1a8b6fb":"markdown","e05c6260":"markdown","f34b8efc":"markdown","236680ad":"markdown","68daddf7":"markdown","658785b6":"markdown","cc8bcf36":"markdown","b6b5b18f":"markdown","e12414b8":"markdown","133bfee3":"markdown","09b2fe66":"markdown","52402654":"markdown","20f26511":"markdown","2d26b791":"markdown","901e296d":"markdown","8efc9896":"markdown","9a8d2702":"markdown"},"source":{"f4ff492f":"# Supressing the warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","dc52dead":"# Reading the dataset\nimport pandas as pd\nimport numpy as np\nDPricesData=pd.read_csv('..\/input\/diamonddata\/DiamondPricesData.csv', encoding='latin')\nprint('Shape before deleting duplicate values:', DPricesData.shape)\n\n# Removing duplicate rows if any\nDPricesData=DPricesData.drop_duplicates()\nprint('Shape After deleting duplicate values:', DPricesData.shape)\n\n# Printing sample data\n# Start observing the Quantitative\/Categorical\/Qualitative variables\nDPricesData.head(10)","3956fdb6":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\nDPricesData['Price'].hist()","2006de4b":"DPricesData.head()","6ed70e36":"DPricesData.info()","072e485d":"DPricesData.describe(include='all')","2521ec5e":"DPricesData.nunique()","2783a5cd":"def PlotBarCharts(inpData, colsToPlot):\n    %matplotlib inline\n    \n    import matplotlib.pyplot as plt\n    \n    # Generating multiple subplots\n    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n\n    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])","fb2ef567":"PlotBarCharts(inpData=DPricesData, colsToPlot=['cut','color','clarity'])","9c26d59a":"DPricesData.hist(['carat','depth','table','x','y','z'], figsize=(18,10))","95e04819":"DPricesData['x'][DPricesData['x']>2].sort_values(ascending=True)\nDPricesData['x'][DPricesData['x']<3.73] =3.73","9c9b977b":"DPricesData['y'][DPricesData['y']<20].sort_values(ascending=False)\nDPricesData['y'][DPricesData['y']>20] =10.54","68ec79b8":"DPricesData['z'][DPricesData['z']<10].sort_values(ascending=False)\nDPricesData['z'][DPricesData['z']>8] =6.98","438befbd":"DPricesData.hist(['x','y', 'z'], figsize=(18,8))","f4016c30":"DPricesData['y'][DPricesData['y']>2].sort_values(ascending=True)","a1af32ea":"DPricesData['y'][DPricesData['y']<2] =3.68","22363fe0":"DPricesData['z'][DPricesData['z']>2].sort_values(ascending=True)","0aa6a9b2":"DPricesData['z'][DPricesData['z']<2]=2.06","24f8f094":"DPricesData.hist(['x','y', 'z'], figsize=(18,8))","26016997":"DPricesData.isnull().sum()","da8f9f01":"DPricesData['color'].fillna(value=DPricesData['color'].mode()[0], inplace=True)\nDPricesData['depth'].fillna(value=DPricesData['depth'].median(), inplace=True)","3f1b000d":"DPricesData.isnull().sum()","984b9701":"ContinuousCols=['carat','depth','table','x','y','z']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    DPricesData.plot.scatter(x=predictor, y='Price', figsize=(10,5), title=predictor+\" VS \"+ 'Price')","64cd940e":"DataFilter=(DPricesData['z']>2.06) & (DPricesData['z']<6.5)\nDPricesData=DPricesData[DataFilter]","0631e883":"ContinuousCols=['carat', 'depth', 'table', 'x','y','z']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    DPricesData.plot.scatter(x=predictor, y='Price', figsize=(10,5), title=predictor+\" VS \"+ 'Price')","ee3e6dba":"# Calculating correlation matrix\nContinuousCols=['Price','carat','depth','table','x','y','z']\n\n# Creating the correlation matrix\nCorrelationData=DPricesData[ContinuousCols].corr()\nCorrelationData","90e43141":"CorrelationData['Price'][abs(CorrelationData['Price']) > 0.2 ]","91d4c64a":"CategoricalColsList=['cut','color','clarity']\n\nimport matplotlib.pyplot as plt\nfig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))\n\n# Creating box plots for each continuous predictor against the Target Variable \"Price\"\nfor PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):\n    DPricesData.boxplot(column='Price', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])","eae9b926":"def FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):\n    from scipy.stats import f_oneway\n\n    # Creating an empty list of final selected predictors\n    SelectedPredictors=[]\n    \n    print('##### ANOVA Results ##### \\n')\n    for predictor in CategoricalPredictorList:\n        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)\n        AnovaResults = f_oneway(*CategoryGroupLists)\n        \n        # If the ANOVA P-Value is <0.05, that means we reject H0\n        if (AnovaResults[1] < 0.05):\n            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n            SelectedPredictors.append(predictor)\n        else:\n            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n    \n    return(SelectedPredictors)","6c1a820d":"CategoricalPredictorList=['cut','color','clarity']\nFunctionAnova(inpData=DPricesData, \n              TargetVariable='Price', \n              CategoricalPredictorList=CategoricalPredictorList)","f2d54aee":"SelectedColumns=['cut','color','clarity','carat','x','y','z']\n\n# Selecting final columns\nDataForML=DPricesData[SelectedColumns]\nDataForML.head()","d45eab9d":"DataForML.to_pickle('DataForML.pkl')","f45d1a68":"DataForML['cut'].unique()","a53663ec":"# Replacing the ordinal values\nDataForML['cut'].replace({'Good':1, \n                          'Very Good':2,\n                          'Fair':3,\n                          'Ideal':4,\n                          'Premium':5\n                         }, inplace=True)","e11f343f":"DataForML['color'].unique()","709d2c02":"# Replacing the ordinal values\nDataForML['color'].replace({'J':1, \n                          'I':2,\n                          'H':3,\n                          'G':4,\n                          'F':5,\n                          'E':6,\n                          'D':7\n                         }, inplace=True)","6cd2b395":"DataForML['clarity'].unique()","4aa51250":"DataForML['clarity'].replace({'I1':1,\n                          'SI1':2,\n                          'SI2':3,\n                          'VS1':4,\n                          'VS2':5,\n                          'VVS1':6,\n                          'VVS2':7,\n                          'IF':8\n                         }, inplace=True)","9747e294":"DataForML_Numeric=pd.get_dummies(DataForML)\n\n# Adding Target Variable to the data\nDataForML_Numeric['Price']=DPricesData['Price']\n\n# Printing sample rows\nDataForML_Numeric.head()","185a3b9b":"DataForML_Numeric.columns","239e4da8":"# Separate Target Variable and Predictor Variables\nTargetVariable='Price'\nPredictors=['cut', 'color', 'clarity', 'carat', 'x', 'y', 'z']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)","c1c2515a":"### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","fae97d89":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","bd9a4405":"# Multiple Linear Regression\nfrom sklearn.linear_model import LinearRegression\nRegModel = LinearRegression()\n\n# Printing all the parameters of Linear regression\nprint(RegModel)\n\n# Creating the model on Training Data\nLREG=RegModel.fit(X_train,y_train)\nprediction=LREG.predict(X_test)\n\n# Taking the standardized values to original scale\n\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Price']-TestingDataResults['PredictedPrice']))\/TestingDataResults['Price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","e7d3184f":"# Decision Trees (Multiple if-else statements!)\nfrom sklearn.tree import DecisionTreeRegressor\nRegModel = DecisionTreeRegressor(max_depth=10,criterion='mse')\n# Good Range of Max_depth = 2 to 20\n\n# Printing all the parameters of Decision Tree\nprint(RegModel)\n\n# Creating the model on Training Data\nDT=RegModel.fit(X_train,y_train)\nprediction=DT.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DT.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Price']-TestingDataResults['PredictedPrice']))\/TestingDataResults['Price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","3df998b2":"# Random Forest (Bagging of multiple Decision Trees)\nfrom sklearn.ensemble import RandomForestRegressor\nRegModel = RandomForestRegressor(max_depth=5, n_estimators=100,criterion='mse')\n# Good range for max_depth: 2-10 and n_estimators: 100-1000\n\n# Printing all the parameters of Random Forest\nprint(RegModel)\n\n# Creating the model on Training Data\nRF=RegModel.fit(X_train,y_train)\nprediction=RF.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Price']-TestingDataResults['PredictedPrice']))\/TestingDataResults['Price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","79b657e1":"# Adaboost (Boosting of multiple Decision Trees)\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Choosing Decision Tree with 1 level as the weak learner\nDTR=DecisionTreeRegressor(max_depth=10)\nRegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=0.01)\n\n# Printing all the parameters of Adaboost\nprint(RegModel)\n\n# Creating the model on Training Data\nAB=RegModel.fit(X_train,y_train)\nprediction=AB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(AB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Price']-TestingDataResults['PredictedPrice']))\/TestingDataResults['Price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","85279eaa":"# Xtreme Gradient Boosting (XGBoost)\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=2, \n                      learning_rate=0.1, \n                      n_estimators=1000, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Printing all the parameters of XGBoost\nprint(RegModel)\n\n# Creating the model on Training Data\nXGB=RegModel.fit(X_train,y_train)\nprediction=XGB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Price']-TestingDataResults['PredictedPrice']))\/TestingDataResults['Price'])\n\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","71b7194f":"# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=4)\n\n# Printing all the parameters of KNN\nprint(RegModel)\n\n# Creating the model on Training Data\nKNN=RegModel.fit(X_train,y_train)\nprediction=KNN.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The variable importance chart is not available for KNN\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Price']-TestingDataResults['PredictedPrice']))\/TestingDataResults['Price'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","95177969":"# Separate Target Variable and Predictor Variables\nTargetVariable='Price'\n\n# Selecting the final set of predictors for the deployment\n# Based on the variable importance charts of multiple algorithms above\nPredictors=['carat','y', 'color' , 'clarity']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\nprint(X.shape)\nprint(y.shape)","eb7902c3":"# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=4)\n\n# Training the model on 100% Data available\nFinal_KNN_Model=RegModel.fit(X,y)","cd3a6a93":"# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(Final_KNN_Model, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","85ea8f6f":"import pickle\nimport os\n\n# Saving the Python objects as serialized files can be done using pickle library\n# Here let us save the Final model\nwith open('Final_KNN_Model.pkl', 'wb') as fileWriteStream:\n    pickle.dump(Final_KNN_Model, fileWriteStream)\n    # Don't forget to close the filestream!\n    fileWriteStream.close()\n    \nprint('pickle file of Predictive Model is saved at Location:',os.getcwd())","d9683aa9":"# This Function can be called from any from any front end tool\/website\ndef FunctionPredictResult(InputData):\n    import pandas as pd\n    Num_Inputs=InputData.shape[0]\n    \n    # Making sure the input data has same columns as it was used for training the model\n    # Also, if standardization\/normalization was done, then same must be done for new input\n    \n    # Appending the new data with the Training data\n    DataForML=pd.read_pickle('DataForML.pkl')\n    InputData=InputData.append(DataForML)\n    \n    # Treating ordinal variables\n    # Replacing the ordinal values of color\n    InputData['color'].replace({  'J':1, \n                                  'I':2,\n                                  'H':3,\n                                  'G':4,\n                                  'F':5,\n                                  'E':6,\n                                  'D':7\n                                 }, inplace=True)\n    \n    # Replacing the ordinal values for clarity\n    InputData['clarity'].replace({'I1':1,\n                                  'SI1':2,\n                                  'SI2':3,\n                                  'VS1':4,\n                                  'VS2':5,\n                                  'VVS1':6,\n                                  'VVS2':7,\n                                  'IF':8\n                                 }, inplace=True)\n    \n    # Generating dummy variables for rest of the nominal variables\n    InputData=pd.get_dummies(InputData)\n            \n    # Maintaining the same order of columns as it was during the model training\n    Predictors=['carat','y', 'color' , 'clarity']\n    \n    # Generating the input values to the model\n    X=InputData[Predictors].values[0:Num_Inputs]\n    \n    # Generating the standardized values of X since it was done while model training also\n    X=PredictorScalerFit.transform(X)\n    \n    # Loading the Function from pickle file\n    import pickle\n    with open('Final_KNN_Model.pkl', 'rb') as fileReadStream:\n        PredictionModel=pickle.load(fileReadStream)\n        # Don't forget to close the filestream!\n        fileReadStream.close()\n            \n    # Genprice Predictions\n    Prediction=PredictionModel.predict(X)\n    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n    return(PredictionResult)","69272526":"# Calling the function for new sample data\nNewSampleData=pd.DataFrame(\ndata=[[0.23,3.98,'E','SI2'],\n     [0.29, 4.23,'I','VS2']],\ncolumns=['carat','y', 'color' , 'clarity'])\n\nprint(NewSampleData)\n\n# Calling the Function for prediction\nFunctionPredictResult(InputData= NewSampleData)","41c51166":"# Creating the function which can take inputs and return prediction\ndef FunctionGeneratePrediction(inp_carat, inp_y, inp_color, inp_clarity):\n    \n    # Creating a data frame for the model input\n    SampleInputData=pd.DataFrame(\n     data=[[inp_carat , inp_y, inp_color, inp_clarity]],\n     columns=['carat','y', 'color', 'clarity'])\n\n    # Calling the function defined above using the input parameters\n    Predictions=FunctionPredictResult(InputData= SampleInputData)\n\n    # Returning the predicted value\n    return(Predictions.to_json())\n\n# Function call\nFunctionGeneratePrediction(  inp_carat=0.29,\n                             inp_y =4.23,\n                             inp_color='I',\n                             inp_clarity='VS2'\n                             )","d0551048":"from flask import Flask, request, jsonify\nimport pickle\nimport pandas as pd\nimport numpy","1aff241b":"app = Flask(__name__)\n\n@app.route('\/prediction_api', methods=[\"GET\"])\ndef prediction_api():\n    try:\n        # Getting the paramters from API call\n        carat_value = float(request.args.get('carat'))\n        y_value=float(request.args.get('y'))\n        color_value=request.args.get('color')\n        clarity_value=request.args.get('clarity')\n                \n        # Calling the funtion to get predictions\n        prediction_from_api=FunctionGeneratePrediction(\n                                                         inp_carat=carat_value,\n                                                         inp_y =y_value,\n                                                         inp_color=color_value,\n                                                         inp_clarity=clarity_value\n                                                      )\n\n        return (prediction_from_api)\n    \n    except Exception as e:\n        return('Something is not right!:'+str(e))","d87d1d8a":"import os\nif __name__ ==\"__main__\":\n    \n    # Hosting the API in localhost\n    app.run(host='127.0.0.1', port=8080, threaded=True, debug=True, use_reloader=False)\n    # Interrupt kernel to stop the API","0fc63872":"# Copy and paste below URL in the web browser\n# http:\/\/127.0.0.1:8080\/prediction_api?carat=0.5&y=5&color=E&clarity=VS2","c9c54bb2":"# Starting the API engine","5564df6f":"# Basic Data Exploration","99aac989":"# Linear Regression","ef435bff":"# Feature Selection & Outliers","f1a8b6fb":"# Decision Tree","e05c6260":"# Looking at the distribution of Target variable","f34b8efc":"# XGBoost","236680ad":"# Adaboost","68daddf7":"# Outlier treatment","658785b6":"# Deployment of the Model","cc8bcf36":"# Function for predictions API","b6b5b18f":"# Standardization\/Normalization of data","e12414b8":"# Visual Exploratory Data Analysis","133bfee3":"# KNN","09b2fe66":"# Data Pre-processing for Machine Learning","52402654":"I am choosing KNN as the final model since it is very fast for this data!","20f26511":"# Selecting final predictors for Machine Learning","2d26b791":"# Machine Learning: Splitting the data into Training and Testing sample","901e296d":"# Random Forest","8efc9896":"# Creating Flask API","9a8d2702":"# Data description\nThe business meaning of each column in the data is as below\n\nprice: The price of the Diamond\n\ncarat: The carat value of the Diamond\n\ncut: The cut type of the Diamond, it determines the shine\n\ncolor: The color value of the Diamond\n\nclarity: The carat type of the Diamond\n\ndepth: The depth value of the Diamond\n\ntable: Flat facet on its surface \u2014 the large, flat surface facet that you can see when you look at the diamond from above.\n\nx: Width of the diamond\n\ny: Length of the diamond\n\nz: Height of the diamond\n"}}