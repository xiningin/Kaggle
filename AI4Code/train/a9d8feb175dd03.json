{"cell_type":{"b5edc676":"code","126165be":"code","4a7132b7":"code","6c220b79":"code","05a25b4d":"code","9ce22b27":"code","5aae7373":"code","5c1fddc6":"code","894e7b4f":"code","e1552001":"code","db848a36":"code","77bd267a":"code","b913a3ac":"code","6490f6c2":"code","fbd38e4c":"code","3f08189c":"code","dba530f3":"code","fb1cb4c3":"code","dfbe193d":"code","f3592bd1":"code","9da460a3":"code","86bb4444":"code","dc8e00d3":"code","6a5afb17":"code","0574a845":"code","02f9d27e":"code","4914673d":"code","342f9bf8":"code","e5ecd051":"code","a645889a":"code","c642da19":"code","4509c90d":"code","aa04d3e8":"code","98ee541c":"code","a805680c":"code","fd75af45":"code","331c8ef4":"code","80a9255d":"code","780f602c":"code","d628a01d":"code","b6eedfed":"code","0c17ba07":"code","16d7e1fa":"code","fd7987da":"code","f7fe88a7":"code","a1fb1aaf":"code","0beb5882":"code","b64ca2c2":"code","4b5785d9":"code","9cb09744":"code","5be7ca22":"code","31005850":"code","b65ae7a3":"code","ba8a8da4":"code","e64ea216":"code","4b19d993":"code","bbfbd5cb":"code","fbafeb6d":"code","c2a9e61a":"code","5063a63f":"code","89d87584":"code","b46a3cf7":"code","877efb69":"code","8fea1311":"code","5eb6d76b":"code","b84c0a25":"code","8c878011":"code","26ddbfa9":"code","0c3cdec4":"code","468b9666":"code","aa589f97":"code","883abd37":"code","133675cb":"code","f7fb1901":"code","d1284855":"code","9aac0620":"code","dbf3d67c":"code","bf8bb674":"code","d7db1c4b":"code","f8695030":"code","7c860439":"code","3d967d1e":"code","319c3189":"code","37ae0c5c":"code","4ed14eb6":"markdown","7604ad2e":"markdown","c689384a":"markdown","950d4b4d":"markdown","69aa7186":"markdown","91b01305":"markdown","72cb9bff":"markdown","211e1c62":"markdown","9c3b1f70":"markdown","63692d04":"markdown","2aeb65a3":"markdown","6586f4b5":"markdown","c3318d3c":"markdown","9404d6f7":"markdown","5082d3bc":"markdown","35e459a1":"markdown","f3158989":"markdown","6ce04c19":"markdown","31dcf05a":"markdown","1b778382":"markdown","dfd885a3":"markdown","87a013d5":"markdown","fcf8ed47":"markdown","3738021e":"markdown","41a13fd7":"markdown","14d472d8":"markdown","505da86a":"markdown","7bb5b26b":"markdown","5bf5ef0f":"markdown","b902ef31":"markdown","fccf5b59":"markdown","4bf23bf2":"markdown","c4422c74":"markdown","606f8e27":"markdown","9a4655a0":"markdown","745c9f72":"markdown","7530a0f6":"markdown","92895b46":"markdown","9499887b":"markdown","18896c43":"markdown","6efd1592":"markdown","d74033d2":"markdown","b5691503":"markdown","71840e1d":"markdown","bc1ab516":"markdown","acd82d12":"markdown","55b76966":"markdown","c7304003":"markdown","714003c5":"markdown","92cdc98e":"markdown","c8c147e3":"markdown","125f57b7":"markdown","1adfd3b5":"markdown","51c2ed9c":"markdown","802bb1ad":"markdown","98c0bf52":"markdown","4c33d12d":"markdown","7c07615f":"markdown","2ba45615":"markdown","16c77b0c":"markdown","5193a55f":"markdown","0444e96e":"markdown","278983c7":"markdown","33846a40":"markdown","ab89fbf4":"markdown","4c2a38d1":"markdown","30cada61":"markdown","3bfa9c0f":"markdown","7d7c11b5":"markdown","3050b676":"markdown","a03398ad":"markdown","632a4e86":"markdown","c07a8d27":"markdown","f3d3d4cc":"markdown","d3a0f2fc":"markdown","1c963ae2":"markdown","b8a7c044":"markdown","07d78367":"markdown","afe9915a":"markdown","8f2069a1":"markdown","d5e7d0d4":"markdown","5ef776f4":"markdown","f2fec396":"markdown","e62e01d5":"markdown","8634c04f":"markdown","50270c78":"markdown","186c7da0":"markdown","1478c58e":"markdown","796bf887":"markdown","3f882470":"markdown","41a23a56":"markdown","06cad413":"markdown","a9c6d550":"markdown","b3f090d1":"markdown","c3520022":"markdown","157cead5":"markdown","b97ea68c":"markdown","4c50a352":"markdown","9869bc6a":"markdown","149aca05":"markdown","4c64e342":"markdown","b3809511":"markdown","e34c93dd":"markdown","d4ba6768":"markdown","5c0b6ce5":"markdown","f220f5ed":"markdown","2e74a3e5":"markdown","cd3156c9":"markdown","c75bf581":"markdown","63dba0cf":"markdown","0f092f3e":"markdown","2f4d79f8":"markdown","d85b19b8":"markdown","981ab454":"markdown","b23e1d7c":"markdown","1b7f3a27":"markdown","4ce0c12b":"markdown","b00444d0":"markdown","c40f21a5":"markdown","afbc1337":"markdown","e53ed485":"markdown","1e3d0549":"markdown","9f12ed96":"markdown","8d67aa18":"markdown"},"source":{"b5edc676":"!pip install comet_ml","126165be":"import comet_ml\nfrom comet_ml import Experiment\n\n#Setting up the API KEY\nexperiment = Experiment(api_key= 'p0xSNBixchjaLhMutKMYVuJAq',project_name=\"classification_team_1_jhb\",workspace=\"crtshabangu\")","4a7132b7":"#!pip install spacy\n#!pip install wordcloud\n#!pip install nltk","6c220b79":"#standard libraries\nimport numpy as np\nimport pandas as pd\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wordcloud\n\n#modeling libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\nfrom sklearn.utils import resample\n\n#text preprocessing libraries\nimport re\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk import TreebankWordTokenizer, SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport string\n\n#pickling\nimport pickle","05a25b4d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9ce22b27":"train_data = pd.read_csv('\/kaggle\/input\/climate-change-belief-analysis\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/climate-change-belief-analysis\/test.csv')","5aae7373":"train_data.head()","5c1fddc6":"test_data.head()","894e7b4f":"len(train_data), len(test_data)","e1552001":"train_data.set_index('tweetid', inplace=True)\ntest_data.set_index('tweetid', inplace=True)","db848a36":"train_data.isnull().sum()","77bd267a":"test_data.isnull().sum()","b913a3ac":"blanks = []  # start with an empty list\n\nfor i,lb,tw in train_data.itertuples():  # iterate over the DataFrame\n    if type(tw)==str:                    # avoid NaN values\n        if tw.isspace():                 # test 'review' for whitespace\n            blanks.append(i)             # add matching index numbers to the list\n        \nprint(len(blanks), 'blanks in train data: ', blanks)   # Checking for empty strings","6490f6c2":"blanks = []  # start with an empty list\n\nfor i, tw in test_data.iterrows():  # iterate over the DataFrame\n    if type(tw)==str:            # avoid NaN values\n        if tw.isspace():         # test 'review' for whitespace\n            blanks.append(i)     # add matching index numbers to the list\n        \nprint(len(blanks), 'blanks in test data: ', blanks)","fbd38e4c":"#Converting every tweet to be lower case\ntrain_data['message'] = train_data['message'].str.lower()\ntest_data['message'] = test_data['message'].str.lower()","3f08189c":"def cleaning(text):\n    \n    \"\"\"\n    Function takes in a text, and returns it cleaned of all noise \n    (such as  unexpected artifacts, urls, twitter handles and numbers).\n    \n    \"\"\"\n    \n    text = re.sub(r'http\\S+', '', text)\n    text = re.sub(r'@[\\w]*','',text)\n    text = re.sub(r'\u00e2\u20ac\u00a6', '', text)\n    text = re.sub(r'\u2026', '', text)\n    text = re.sub(r'\u00e2\u20ac\u2122', \"'\", text)\n    text = re.sub(r'\u00e2\u20ac\u02dc', \"'\", text)\n    text = re.sub(r'\\$q\\$', \"'\", text)\n    text = re.sub(r'&amp;', \"and\", text)\n    text = re.sub('[0-9]+', '', text)\n    \n    words = text.split()  \n    \n    return( \" \".join(words))\n","dba530f3":"train_data['message'] = train_data['message'].apply(cleaning)\ntest_data['message'] = test_data['message'].apply(cleaning)","fb1cb4c3":"def remove_punctuation(text):\n    \n    \"\"\"custom function to remove the punctuation\"\"\"\n    \n    return text.translate(str.maketrans('', '', string.punctuation))","dfbe193d":"train_data['message'] = train_data['message'].apply(remove_punctuation)\ntest_data['message'] = test_data['message'].apply(remove_punctuation)","f3592bd1":"#Remove Stop words\ndef stop(text):\n    \n    \"\"\"\" \n    Function takes in some text, adds the variants of 'retweets'\n    into the stopwords list, and then removes all stopwords.\n    \n    \"\"\"\n    \n    word = text.split()\n    #Remove stop words\n    stop_additional = ['rt','rts', 'retweet']\n    stop_word = set().union(stopwords.words('english'), stop_additional)\n    remove_stop = [w for w in word if w not in stop_word]\n    free_stop = \" \".join(remove_stop)\n    \n    return free_stop \n","9da460a3":"train_data['message'] = train_data['message'].apply(stop)\ntest_data['message'] = test_data['message'].apply(stop)","86bb4444":"def lemmatizer(text):\n    \n    \"\"\"\" \n    Function takes in some text, and returns the lemmatized text.\n    \n    \"\"\"\n    \n    lemma = WordNetLemmatizer()\n    new_text = \" \".join([lemma.lemmatize(lem) for lem in text.split()])\n    \n    return new_text\n","dc8e00d3":"train_data['message'] = train_data['message'].apply(lemmatizer)\ntest_data['message'] = test_data['message'].apply(lemmatizer)","6a5afb17":"# Separate the classes\nnews = train_data[train_data['sentiment']==2]\npro = train_data[train_data['sentiment']==1]\nneutral = train_data[train_data['sentiment']==0]\nanti = train_data[train_data['sentiment']==-1]","0574a845":"# Get all possible labels\nlabels = train_data['sentiment'].unique()\nheights = [len(pro),len(news),len(neutral),len(anti)]\nplt.bar(labels,heights,color='blue')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.xlabel('sentiments')\nplt.ylabel(\"number of observations\")\nplt.title('Distribution of classes')\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes')\nplt.show()","02f9d27e":"plt.figure(figsize=(7,7))\ntrain_data[\"sentiment\"].value_counts().plot.pie(labels=['Pro', 'News', 'Neutral', 'Anti'], \n                                                autopct='%.1f%%',\n                                                title = 'Pie chart showing percentage of class distribution',\n                                                colors = ['grey','lime','brown','blue'])\nexperiment.log_figure(figure=plt,figure_name='Pie chart showing percentages of class distridution')","4914673d":"\nfig, axs = plt.subplots(2, 2, figsize=(11,7))\n\naxs[0, 0].hist(pro.message.str.len(),bins=50,label='pro',color='grey')\naxs[0, 0].set_title('pro')\n\naxs[1, 0].set_title('news')\naxs[1, 0].hist(news.message.str.len(),bins=50,label='news',color='lime')\n\naxs[0, 1].set_title('neutral')\naxs[0, 1].hist(neutral.message.str.len(),bins=50,label='neutral',color='brown')\n\naxs[1, 1].set_title('anti')\naxs[1, 1].hist(anti.message.str.len(),bins=50,label='anti',color='blue')\n\nfor ax in axs.flat:\n    ax.set(xlabel='length of tweets', ylabel='number of tweets')\n\n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor ax in axs.flat:\n    ax.label_outer()\n\nexperiment.log_figure(figure = plt,figure_name='histograms showing the count of length of tweets')     ","342f9bf8":"all_words = ''.join([label for label in train_data['message']])","e5ecd051":"from wordcloud import WordCloud\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words')\nplt.show()","a645889a":"pro_tweets = train_data[train_data['sentiment'] == 1]\nall_words = ''.join([label for label in pro_tweets['message']])","c642da19":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in Pro Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Pro Tweets')\nplt.show()","4509c90d":"anti_tweets = train_data[train_data['sentiment'] == -1]\nall_words = ''.join([label for label in anti_tweets['message']])","aa04d3e8":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in Anti Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Anti Tweets')\nplt.show()","98ee541c":"neutral_tweets = train_data[train_data['sentiment'] == 0]\nall_words = ''.join([label for label in neutral_tweets['message']])","a805680c":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in Neutral Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Neutral Tweets')\nplt.show()","fd75af45":"news_tweets = train_data[train_data['sentiment'] == 2]\nall_words = ''.join([label for label in news_tweets['message']])","331c8ef4":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in News Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in News Tweets')\nplt.show()","80a9255d":"X = train_data['message']\ny = train_data['sentiment'].values","780f602c":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)","d628a01d":"vectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_train_tfidf.shape","b6eedfed":"def fit_evaluate_model(model, X_train, y_train):\n    \n    \"\"\" \n    Function takes a model to train as input, and returns the performance\n    of said model (in the form of various metrics). \n    \n    \"\"\"\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                         ('clf',model)])\n    \n    # Fit the model to the training set\n    text_clf.fit(X_train, y_train) \n    \n    # Obtain predictions on the training and validation set\n    y_pred = text_clf.predict(X_train)\n    y_pred_test=text_clf.predict(X_test)\n    \n    # Determining the performance of the model\n    accuracy = accuracy_score(y_train,y_pred)\n    precision = precision_score(y_train,y_pred,average='weighted')\n    recall = recall_score(y_train,y_pred,average='weighted')\n    f1 = f1_score(y_train,y_pred,average='weighted')\n    f1_test = f1_score(y_test,y_pred_test,average='weighted')\n    \n    # Creating a dictionary for the metrics\n    performance = {\"accuracy\": accuracy,\"precision\":precision,\n                   \"recall\":recall,\"f1_score\":f1,\"f1_test_score\":f1_test}\n    \n    output = pd.DataFrame([performance])\n\n \n    return output\n    ","0c17ba07":"model1 = LogisticRegression(max_iter=10000)\nlogistic_model = fit_evaluate_model(model1, X_train, y_train)","16d7e1fa":"model2 = LinearSVC()\nlinear_svc = fit_evaluate_model(model2, X_train, y_train)","fd7987da":"model3 = SVC(kernel = 'rbf')\nkernel_svc = fit_evaluate_model(model3, X_train, y_train)","f7fe88a7":"model4 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nk_nn = fit_evaluate_model(model4,X_train, y_train)","a1fb1aaf":"assess = pd.concat([logistic_model, linear_svc, kernel_svc, k_nn])\nassess.index = ['Logistic Regression','Linear SVM Model','Kernel SVM Model', 'K-NN Model']\nassess","0beb5882":"def tuned_model(model, parameters):\n    \n    \"\"\" \n    Function takes a model to train and parameters to optimize as input,\n    and returns the best parameters and best F1-Score of said model.\n    \n    \"\"\"\n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                         ('clf',model)]) \n    \n    grid_search = GridSearchCV(estimator = text_clf,\n                               param_grid = parameters,\n                               scoring = 'f1_weighted',\n                               cv = 10,\n                               n_jobs = -1)\n    grid_search = grid_search.fit(X_train, y_train)\n    best_accuracy = grid_search.best_score_\n    best_parameters = grid_search.best_params_\n    print(\"Best f1-score: {:.2f}\".format(best_accuracy))\n    print(\"Best Parameters:\", best_parameters)","b64ca2c2":"parameters = [{'clf__C': [0.05], 'clf__penalty': ['l1'], 'clf__solver': ['liblinear'], 'clf__verbose':[1]},\n              {'clf__C': np.linspace(1,10,10)}] \n\ntuned_model(model1, parameters)","4b5785d9":"parameters = [{'clf__C': np.linspace(1,10,10), 'clf__penalty': ['l1','l2']}]\n\ntuned_model(model2, parameters)","9cb09744":"parameters = [{'clf__n_neighbors': [5, 6, 7, 8, 9, 10]}]\n\ntuned_model(model4, parameters)","5be7ca22":"data = {'F1-Score after tuning': [0.71, 0.70, 0.73, 0.63]}\nindex=['Logistic Regression Tuned', 'Linear SVC Tuned', 'Kernel SVC Tuned', 'KNN Tuned']\nsummary = pd.DataFrame(data = data, index=index)\nsummary","31005850":"# Separate the classes\nnews = train_data[train_data['sentiment']==2]\npro = train_data[train_data['sentiment']==1]\nneutral = train_data[train_data['sentiment']==0]\nanti = train_data[train_data['sentiment']==-1]","b65ae7a3":"# Get all possible labels\nlabels = train_data['sentiment'].unique()\nheights = [len(pro),len(news),len(neutral),len(anti)]\nplt.bar(labels,heights,color='grey')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"# of observations\")\nplt.show()","ba8a8da4":"# Downsample majority\npro_downsampled = resample(pro,\n                          replace=False, # sample without replacement (no need to duplicate observations)\n                          n_samples=len(news)) # match number in minority class\n\n# Combine downsampled majority class with minority classes\ndownsampled = pd.concat([pro_downsampled, anti, neutral, news])\n\n# Check new class counts\ndownsampled['sentiment'].value_counts()","e64ea216":"downsampled_heights = [len(downsampled[downsampled['sentiment']==1]),len(downsampled[downsampled['sentiment']==2]),\n                       len(downsampled[downsampled['sentiment']==0]),len(downsampled[downsampled['sentiment']==-1])]\n\n# Get all possible labels\nlabels = train_data['sentiment'].unique()\nplt.bar(labels,heights,color='grey')\nplt.bar(labels,downsampled_heights,color='blue')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"number of observations\")\nplt.legend(['original','resampled'])\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after downsampling')   \nplt.show()","4b19d993":"# Upsample minority\nanti_upsampled = resample(anti,\n                          replace=True, # sample with replacement (we need to duplicate observations)\n                          n_samples=len(news)) # match number in minority class\n\n# Combine upsampled anti class with majority classes\nup_sampled = pd.concat([pro_downsampled, anti_upsampled, neutral, news])\n\n# Check new class counts\nup_sampled['sentiment'].value_counts()","bbfbd5cb":"# Upsample minority\nneutral_upsampled = resample(neutral,\n                          replace=True, # sample with replacement (we need to duplicate observations)\n                          n_samples=len(news)) # match number in minority class\n\n# Combine upsampled neutral class with majority class\nfinal = pd.concat([pro_downsampled, anti_upsampled, neutral_upsampled, news])\n\n# Check new class counts\nfinal['sentiment'].value_counts()","fbafeb6d":"upsampled_heights = [len(final[final['sentiment']==1]),len(final[final['sentiment']==2]),\n                     len(final[final['sentiment']==0]),len(final[final['sentiment']==-1])]\n\n# Get all possible labels\nlabels = train_data['sentiment'].unique()\nplt.bar(labels,upsampled_heights,color='green')\nplt.bar(labels,heights,color='grey')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"number of observations\")\nplt.legend(['resampled','original'])\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after upsampling')\nplt.show()","c2a9e61a":"# Get all possible labels\nlabels = train_data['sentiment'].unique()\nheights = [len(final[final['sentiment']==1]),len(final[final['sentiment']==2]),\n           len(final[final['sentiment']==0]),len(final[final['sentiment']==-1])]\nplt.bar(labels,heights,color='grey')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"number of observations\")\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after resampling')\nplt.show()","5063a63f":"X = final['message'] \ny = final['sentiment'].values\n\nX_train_resampled, X_test, y_train_resampled, y_test = train_test_split(X,y,test_size=0.2,random_state=42)","89d87584":"# Logistic Regression\nlogreg = fit_evaluate_model(model1, X_train_resampled, y_train_resampled) \n# Linear SVC model\nl_svc = fit_evaluate_model(model2, X_train_resampled, y_train_resampled)\n# Kernel SVM Model\nk_svc = fit_evaluate_model(model3, X_train_resampled, y_train_resampled)\n# K_Nearest Neighbours\nknn = fit_evaluate_model(model4, X_train_resampled, y_train_resampled)","b46a3cf7":"assess_resampled = pd.concat([logreg,l_svc,k_svc, knn])\nassess_resampled.index = ['Logistic Regression Resampled','Linear SVM Model Resampled',\n                          'Kernel SVM Model Resampled', 'K-NN Model Resampled']\nassess_resampled","877efb69":"def testing(model, filename, X, y):\n    \n    \"\"\"\" \n    Function takes a model, and X and y variables to train as input,\n    and returns a csv file of predictions (named as \"filename\") to \n    submit to Kaggle in order to obtain the true F1-score. \n    \n    \"\"\"\n    test_x = test_data['message']\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                         ('clf',model)])\n    \n    # Fit the model to the training set\n    text_clf.fit(X, y) \n    \n    # Obtain predictions on the testing set\n    y_pred = text_clf.predict(test_x)\n    \n    # Save predictions in a new DataFrame\n    predictions = pd.DataFrame(y_pred, columns=['sentiment'], index = test_data.index)\n    predictions.reset_index(inplace=True)\n    \n    return predictions.to_csv('\/kaggle\/working\/'+filename+'.csv', index=False)","8fea1311":"testing(model1, 'LogReg', X_train, y_train)","5eb6d76b":"testing(model2, 'LinearSVC', X_train, y_train)","b84c0a25":"testing(model3, 'KernelSVC', X_train, y_train)","8c878011":"testing(model4, 'KNN', X_train, y_train)","26ddbfa9":"testing(LogisticRegression(C=6.0, max_iter=10000), 'LogReg_Tuned', X_train, y_train)","0c3cdec4":"testing(SVC(kernel='rbf', C=100, gamma='scale'), 'KernelSVC_Tuned', X_train, y_train)","468b9666":"testing(KNeighborsClassifier(leaf_size=20, n_neighbors=9), 'KNN_Tuned', X_train, y_train)","aa589f97":"testing(model1, 'LogReg_Resampled', X_train_resampled, y_train_resampled)","883abd37":"testing(model2, 'LinearSVC_Resampled', X_train_resampled, y_train_resampled)","133675cb":"testing(model3, 'KernelSVC_Resampled', X_train_resampled, y_train_resampled)","f7fb1901":"testing(model4, 'KNN_Resampled', X_train_resampled, y_train_resampled)","d1284855":"arrays = [['Before Resampling', 'Before Resampling', 'Before Resampling', 'Before Resampling', \n           'Before Resampling Tuned', 'Before Resampling Tuned', 'Before Resampling Tuned',\n           'Before Resampling Tuned', 'After Resampling', 'After Resampling', 'After Resampling',\n           'After Resampling'],\n          ['Logistic Regression', 'Linear SVC', 'Kernel SVC', 'K-Nearest Neighbours',\n           'Logistic Regression', 'Linear SVC', 'Kernel SVC', 'K-Nearest Neighbours',\n           'Logistic Regression', 'Linear SVC', 'Kernel SVC', 'K-Nearest Neighbours']]\n\ntuples = list(zip(*arrays))","9aac0620":"index = pd.MultiIndex.from_tuples(tuples, names=[' ', 'Model'])\n\ndata = {'Train F1-Score': [0.8289, 0.9628, 0.9534, 0.7479, '--', '--', '--', '--',\n                           0.9083, 0.9797, 0.9879, 0.7531],\n        'Validation F1-Score': [0.7114, 0.7172, 0.7068, 0.6416, 0.7100,0.7000, 0.7300,\n                                0.6300, 0.7781, 0.8029, 0.8346, 0.6350],\n        'Test F1-Score': [0.7336, 0.7483, 0.7358, 0.6497, 0.7526, 0.7483, 0.7565, 0.6526,\n                         0.6548, 0.6566, 0.6969, 0.4988]}\n\nsummary = pd.DataFrame(data = data, index = index)","dbf3d67c":"summary","bf8bb674":"def the_fit(model):\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                     ('clf', model)])\n\n    # Feed the training data through the pipeline\n    return text_clf.fit(X_train, y_train) \n    ","d7db1c4b":"# The best model\nbest_model = SVC(kernel='rbf', C=100, gamma='scale')\nkernel_svc = the_fit(best_model)","f8695030":"model = kernel_svc \nmodel_save_path = \"model_1.pkl\"\nwith open(model_save_path,'wb') as file:\n    pickle.dump(model,file)","7c860439":"# Log best model parameters\nbest_model_hyperparams = {'clf__C': 100, 'clf__gamma': 'scale',\n                     'clf__kernel': 'rbf'}\nexperiment.log_parameters(best_model_hyperparams)\n\n# Log best model F1 score\nexperiment.log_metrics({\"Test F1-Score\":0.75651})","3d967d1e":"# Log best model\nexperiment.log_model(\"Kernel SVM Model\", model_save_path)","319c3189":"experiment.end()","37ae0c5c":"experiment.display()","4ed14eb6":"### Obtaining X and y","7604ad2e":"**The following lines of code took hours to load:**\n\n\n\n```\nparameters = [{'clf__C': [1, 10, 100], 'clf__kernel': ['poly', 'rbf'],'clf__gamma': ['scale', 'auto']}] \ntuned_model(model3, parameters)\n```\n**And the output:**\n\n\n```\nBest f1-score: 0.73 \nBest Parameters: {'clf__C': 100, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n```\n\n\n","c689384a":"Th data has no missing values, and no empty tweet strings.","950d4b4d":"<a id='the_libraries'><\/a>\n## Importing the libraries","69aa7186":"#### WordCloud2: Top 50 Words in \"Pro\" Tweets","91b01305":"#### Logistic Regression: F1 Score = 0.65483","72cb9bff":"Another type of textual noise to be removed include multiple representations exhibited by a single word.","211e1c62":"#### Upsampling the minority class","9c3b1f70":"<a id='the_intro'><\/a>\n## Introduction","63692d04":"More that 50% of the tweets belong to the `pro` class. Recall that the `pro` class represent tweets of people who believe in man-made climate change. This could be an indication that people are finally acknowledging this phenomenon, and more people are becoming aware of it. ","2aeb65a3":"#### WordCloud3: Top 50 Words in \"Anti\" Tweets","6586f4b5":"**Models to Fit:**\n\n1. **Logistic Regression**\n   * Logistic Regression models the probability that `Y`(label) belongs to a certain category (or class). It uses the logistic       function to fit the model using the **maximum likelihood** method. It produces an `S-shaped` curve. This model         can be extended to Multi-class classification, where multiple logistic models can be combined using the          `one-vs-rest` approach.\n<br>   \n\n\n2. **Support Vector Machine**\n   *  In classification, an SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall.\n   *  In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n<br> \n\n \n3. **K-Nearest Neighbors (K-NN)**\n   * K-NN is an easy and powerful machine learning algorithm. The algorithm works by assigning the majority class of the N-closest neighbors to the current data point. Hence, no training is required for the algorithm; the only thing that needs to be done is choosing the value of `k` (i.e. the number of neighbors to consider) and choose the Euclidean distance function (`minkowski`) to calculate proximity.<br>\n  ","c3318d3c":" Here, random copies of observations in the `anti` and `neutral` classes are made until we match the size of the `news` class. Using this approach means that there will be more data; however the model will be prone to overfitting. ","9404d6f7":"<a id='the_logging'><\/a>\n## Logging to comet","5082d3bc":"#### Model 2: Linear SVM model","35e459a1":"<a id='the_balancedfit'><\/a>\n## Modelling after resampling","f3158989":"<a id='the_fit'><\/a>\n## Modelling before resampling\n","6ce04c19":"Any piece of information (text) that is not relevant in the data is considered as noise. The following constitutes as noise: stop words, urls, links, social media entities, punctuations or any industry-specific words. Noise is to be removed from our data as it is not required.\n \nPart of noise removal in this instance involves **Object Standardization**. \n\nObject Standardization involves making sense of, or removing words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models. Some examples include acronyms, hashtags with attached words, and colloquial slangs.","31dcf05a":"This visual depicts the 50 most common words among `pro` tweets.\n\nWords like \"change denier\", \"tackle climate\" and \"going die\" are included.","1b778382":"#### Visualizing the new data:","dfd885a3":"<a id='the_conclusion'><\/a>\n## Conclusion","87a013d5":"A hyperparameter is a value that is set before the model is trained. Different models have different algorithms, and hence have different hyperparameters. \n<br>\n\nFirstly, the hyperparameters of the fitted models are inspected: <br>\n\n**Logistic Regression**<br>\n`C`: controls regularization (shrinkage). The smaller value of `C`, the greater the amount of shrinkage that takes place. <br>\n\n**Support Vector Classifier** <br>\n`C`: controls the penalty of the error term.<br>\n`gamma`: kernel coefficient. <br>\n(Support Vector Classifier has tons of hyperparameters, but only these two are focused on, for the sake of efficiency).\n\n**KNN**<br>\n`n_neighbors`: number of nearest neighbors.<br>","fcf8ed47":"For ease, the `tweetid` column is set to be the index. ","3738021e":"#### Pie Chart","41a13fd7":"#### Logistic Regression: F1 Score = 0.73364","14d472d8":"#### Linear SVC: F1 Score = 0.65659","505da86a":"#### Model 4: K-NN","7bb5b26b":"#### Logistic Regression: F1 Score = 0.75225","5bf5ef0f":"### Models with resampled data","b902ef31":"#### Linear SVC: F1 Score = 0.74834","fccf5b59":"#### Kernel SVM: F1 Score = 0.73577","4bf23bf2":"As mentioned before, the classes are imbalanced. The imbalance in the classes are fixed by `resampling`. Resampling consists of three techniques:\n\n\n*   **Upsampling** the minority class - increasing the minority class by resampling from observations to match the number of observations in the majority class.\n\n\n*   **Downsampling** the majority class - reducing the number of observations in the majority class to match those of the minority class.\n\n\n*   **Synthetic data** - another type of upsampling method where the number of observations in the minority class are inflated, but by generating new observations which are very similar to (but not identical to) existing samples in the minority class. \n\nThis notebook uses the upsampling and downsampling methods.\n\n","c4422c74":"In classification, the process of cleaning and standardization of text and making it noise-free is known as [text preprocessing](https:\/\/www.analyticsvidhya.com\/blog\/2017\/01\/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python\/). This entails of:\n* Noise Removal.\n* Object Standardization.\n* Lexicon Normalization.\n","606f8e27":"Python's `string` library is used to remove punctuation.","9a4655a0":"This visual depicts the 50 most common words in the dataset. \n\nWords like \"climate change\", \"global warming\" and \"science\" are included.","745c9f72":"#### Model 1: Logistic Regression ","7530a0f6":"#### Histogram","92895b46":"Many companies are built around lessening one\u2019s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product\/service may be received.\n\n\nProviding an accurate and robust solution to this problem gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n","9499887b":"### Length of tweets per class","18896c43":"Checking for missing data:","6efd1592":"<a id='the_analysis'><\/a>\n## Explanatory Data Analysis","d74033d2":"Many of the tweets are from people who believe in man-made climate change. Unresolved class imbalance can lead to the classifier been good at predicting the class(es) with the majority of the data points in the dataset. Whether class imbalance results in poor performance or not is something that will be tested. \n\nThe exact percentages of these classes are now inspected using a pie chart.","b5691503":"####  Assessing the performance on resampled data","71840e1d":"#### Model 1 : Logistic Regression","bc1ab516":"### Distribution of the classes","acd82d12":"Here, unexpected artifacts, urls, twitter handles and numbers in the tweets are removed. ","55b76966":"#### Assessing the performance after hyperparameter tuning","c7304003":"#### K-NN: F1 Score = 0.64971","714003c5":"1. [Data overview](#the_data)\n \n1. [Connecting to comet](#the_connection)\n \n1. [Importing the libraries](#the_libraries)\n \n1. [Loading the datasets](#the_load)\n\n1. [Inspecting the data](#inspecting)\n \n1. [Text preprocessing](#the_prep)\n\n1. [Exploratory data analysis](#the_analysis)\n \n1. [Feature engineering on text data](#the_features)\n \n1. [Modelling before resampling](#the_fit)\n\n1. [Hyperparameter tuning](#the_tune)\n\n1. [Modelling after resampling](#the_balancedfit)\n\n1. [Submissions to kaggle](#submission)\n\n1. [Evaluating the models](#the_eval)\n \n1. [Saving the best model](#the_saving)\n\n1. [Logging to comet](#the_logging)\n\n1. [Conclusion](#the_conclusion)\n\n1. [References](#the_ref)\n","92cdc98e":"#### Kernel SVM: F1 Score = 0.75651","c8c147e3":"<a id='inspecting'><\/a>\n## Inspecting the data","125f57b7":"####  WordCloud5: Top 50 Words in \"News\" Tweets","1adfd3b5":"A [word cloud](https:\/\/www.geeksforgeeks.org\/generating-word-cloud-python\/) is a technique used in visualization to represent text data in such a way that the size of each word in the text indicate its significance or occurrences. Words that are largely displayed have a high frequency in the text.","51c2ed9c":"### Models with default parameters","802bb1ad":"#### Model 3 : Kernel SVM Model","98c0bf52":"<a id='the_data'><\/a>\n## Data overview","4c33d12d":"This visual depicts the 50 most common words among `anti` tweets.\n\nWords like \"chinese\", \"man made\" and \"trump\" are included.","7c07615f":"This visual depicts the 50 most common words among `news` tweets.\n\nWords like \"paris agreement\", \"scott pruitt\" and \"carbon dioxide\" are included.","2ba45615":"### Modelling with default parameters","16c77b0c":"#### K-Nearest Neighbours: F1 Score = 0.65259","5193a55f":"### Splitting into the training and validation datasets","0444e96e":"#### WordCloud 1: Top 50 Words","278983c7":"### Problem Identification","33846a40":"<a id = 'the_ref'><\/a>\n## References","ab89fbf4":"<a id='the_connection'><\/a>\n## Connecting to comet","4c2a38d1":"<a id='the_features'><\/a>\n## Feature engineering on text data","30cada61":"This visual depicts the 50 most common words among `neutral` tweets.\n\nWords like \"warming\", \"global\" and \"club penguin\" are included.","3bfa9c0f":"<a id='the_saving'><\/a>\n## Saving the best model","7d7c11b5":"### Modelling","3050b676":"#### Model 2: Linear SVC","a03398ad":"### End experiment","632a4e86":"These are now evenly distributed observations that can now be thrown at any classification model.","c07a8d27":"A few observations:\n\n1. The models performed the best on the training set (understandably).\n2. The resampling done (especially upsampling the minority classes) caused our data to overfit; this can be seen by the very high F1-scores on the training set and a drastic decrease of the F1-score on the testing set. \n3. The K-Nearest Neighbors model consistently performed the worst. \n4. The Kernel SVM model consistently performed the best, indicating that the data is not linearly separable.\n5. Tuning the models definitely improved the performance of the model.\n6. The models that were tuned before resampling performed the best; the models built on the resampled data performed the worst.\n7. The highest `Test F1-score` = `0.75651`, indicating that **the best model is the Kernel SVM optimally tuned model before resampling.**","f3d3d4cc":"The imbalance in our data can also be seen in the accuracy being significantly higher than the f1 score across all the models. ","d3a0f2fc":"Now the resampling techniques are applied:","1c963ae2":"Submissions are now made to Kaggle to see the performance of the models on the true testing dataset. These F1-scores are the ones that carry the most weight.","b8a7c044":"### Applying Tfidf","07d78367":"#### Assessing the performance","afe9915a":"The data is now split into labels and features, and the training set is split up into the training and validation datasets.","8f2069a1":"#### WordCloud4: Top 50 Words in \"Neutral\" Tweets","d5e7d0d4":"Now we evaluate the performance of all the models:","5ef776f4":"### Splitting into training and validation sets","f2fec396":"### Resampling","e62e01d5":"#### K-Nearest Neighbours: F1 Score = 0.49881","8634c04f":"\n### Display comet page","50270c78":"<a id='submission'><\/a>\n## Submissions to Kaggle","186c7da0":"<a id='the_prep'><\/a>\n## Text preprocessing","1478c58e":"The models' performance can now be improved through **hyperparametric tuning**.","796bf887":"Since the `pro` class has so many observations, its size can be reduced by taking a small random subset of observations to match the size of the `news` class.","3f882470":"All the models built in this notebook are now evaluated according to the performance metric (The `F1-Score`) on the testing set:","41a23a56":"\n**Resources used**: \n*   More on hyperparameter tuning: https:\/\/www.youtube.com\/watch?v=yBiLCkv96lo&feature=emb_title\n*   Cleaning the data: https:\/\/medium.com\/@edwardcqian\/using-machine-learning-to-measure-user-sentiment-towards-climate-change-d817c21c5887\n\n\n","06cad413":"We now apply scikit-learn's `TfidfVectorizer` which does the following to our text data:\n\n*   It counts all the occurrences of the unique words and transforms the tweets to feature vectors\n*   A refinement on top of counting the words is to downscale the weight for words that occur in many tweets (such as \"the\") and are therefore less informative than those that occur only in a few tweets (such as \"climate\").\n*   This is achieved by simply dividing the number of occurrences of each word in the tweets by the total number of words in the tweets.\n","a9c6d550":"### Models with tuned hyperparameters","b3f090d1":"Remember that only the training set has been vectorized into a full vocabulary. In order to perform an analysis on the test set, it has to be submitted to the same procedures. Hence, the `Pipeline` class is used. \n","c3520022":"### Wordclouds: Visualizing frequently used words in the tweets","157cead5":"### **Noise Removal**","b97ea68c":"Note the shape of `X_train_tfidf`, which indicates the number of features in the feature vector.","4c50a352":"Firstly, the data has to be split into labels and features. ","9869bc6a":"An improvement of the models on the validation set can be seen since the data has been resampled.","149aca05":"### Lexicon Normalization ","4c64e342":"## Table of Contents","b3809511":"Hyperparameter Tuning\/Optimization is the process of selecting a certain combination of hyperparameters that are optimal for our model.\n<br>\n\nThere are many techniques to tune the hyperparameters; this notebook uses the `GridSearch` method.<br>\n\nA **GridSearch** is an optimization process that finds the best hyperparameters. It is a trial-and-error method used to train the model of various combinations of the specified hyperparameters. The hyperparameters chosen are the ones that fully optimize the model.\n","e34c93dd":"<hr>\n<h1><center>Climate Change Belief Analysis Competition<\/center><\/h1>\n<hr>","d4ba6768":"The training set has 15819 tweets.\n\nThe testing set has 10546 tweets. ","5c0b6ce5":"### Problem Statement","f220f5ed":"<a id='the_tune'><\/a>\n## Hyperparameter tuning","2e74a3e5":"Comet is a platform that allows data scientists and developers to easily monitor, compare and optimize their machine learning models. \nMore information about Comet can be found [here](https:\/\/techcrunch.com\/2018\/04\/05\/cometml-wants-to-do-for-machine-learning-what-github-did-for-code\/#:~:text=Comet.ml%20allows%20data%20scientists,optimize%20their%20machine%20learning%20models.&text=The%20service%20provides%20you%20with,ML).  \n\nFirstly, `comet_ml` has to be installed.\n","cd3156c9":"It is noticed that the tweets contain 'rt', implying a retweet.\n\nHence, 'rt', 'rts' and 'retweet' are added as stopwords, and all stopwords are now removed. ","c75bf581":"#### Model 3: Kernel SVM","63dba0cf":"#### Downsampling the majority class","0f092f3e":"<a id='the_load'><\/a>\n## Loading the datasets","2f4d79f8":"The common types of Lexicon Normalization:\n\n\n* **Stemming**:  Stemming is a rudimentary rule-based process of stripping the suffixes (\u201cing\u201d, \u201cly\u201d, \u201ces\u201d, \u201cs\u201d, etc) from a word.\n* **Lemmatization**: Lemmatization, on the other hand, is an organized, and step-by-step procedure of obtaining the root form of the word, by making use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations).\n\nIn this case, lemmatization is chosen. In lemmatization, words like \"loving\", \"lovely\" and \"loved\" are normalized to their root-word \"love\".\nThis process returns words present in our dictionary; unlike stemming which may return words that may not even exist. \n\n\n","d85b19b8":"#### Model 4 : K-NN Model","981ab454":"Before proceeding with importing the usual libraries, there are some natural language processing libraries that need to be installed: \n\n* `spacy`\n* `wordcloud`\n* `nltk`\n\n","b23e1d7c":"The training data is now split up into the training dataset and the validation dataset.","1b7f3a27":"The purpose of this project is to train a classification model to predict the sentiment of tweets related to climate change.\n\nThe Machine Learning model chosen will be the one with the highest `Weighted F1-score `(the performance metric used to evaluate the models). \n\nClick [here](https:\/\/www.kaggle.com\/c\/climate-change-belief-analysis\/overview) to view the competition page.","4ce0c12b":"Checking for empty strings:","b00444d0":"The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected.\n\nThe training and test datasets provided here is a subset of these 43943 tweets.\n\nThe files to be downloaded are:\n* **Train.csv** - the dataset for training our model.\n* **Test.csv** - the dataset for testing our model .\n\nVariable definitions on the train dataset:\n\n`sentiment`: Sentiment of tweet\n\n`message`: Tweet body\n\n`tweetid`: Twitter unique ID\n\nEach tweet is labelled as one of the following sentiment classes:\n\n![image.png](data:image\/png;base64,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)","c40f21a5":"<a id='the_eval'><\/a>\n## Evaluating the models","afbc1337":"A few things noted:\n\n1. It seems like the length for most tweets lie in the `20-120` range in all classes. \n\n2. The length of tweets for each sentiment class are bell-shaped, and hence have a normal distribution. Since they follow a normal distribution, the mean of the length of tweets can be gauged (which is the highest point on the bell curve).\n\n3. `news` tweets have the lowest mean length. This could be explained by the fact that `news` tweets tend to be concise, and contains just a headline or a link to the full article, hence the length is shorter. \n\n4. The mean for `anti` tweets are higher than that of `pro` tweets. This could indicate that people may have to use more words to express how climate change is not man-made. This speaks volumes that the general sentiment is leaning more towards `pro` than `anti`, since a few words suffice to explain how climate change is man-made. ","e53ed485":"The purpose of this notebook was to build a classifier to determine whether a person believes if climate change is man-made or not, based on their novel tweet data.\n\nVarious text preprocessing methods (such as noise removal and object standardisation) were applied to the tweets, so that they could be thrown at any classification model.\n\nExploratory data analysis was done, such as visualising the length of tweets per sentiment class, and the most common words found in each sentiment class.\n\nIt was found that the data was heavily imbalanced; modelling was done before resampling the data and compared to the modelling done after resampling the data. \nModelling done after resampling exhibited the tendency of the models to overfit the resampled data. \n\nHyperparametric tuning was also applied in order to optimize the models. \n\nFrom the various models built, the best model is chosen according to the performance metric. In this case, the best model is the one which exhibits the highest `F1-Score`.\n\nHence, the classifier chosen to predict the sentiment of tweets related to climate change is the **fully optimized Kernel SVM model (before resampling).**","1e3d0549":"#### Kernel SVM: F1 Score = 0.69689","9f12ed96":"[Feature engineering](https:\/\/www.kaggle.com\/shivamb\/extensive-text-data-feature-engineering) on text data simply means extracting features from text using the following techniques:\n\n* **Bag of Words** <br>\nThis extracts features from text and counts the frequency of words in a document (the simplest form). \n<br>\n*  **TF-IDF** <br>\nTfidf combines **Term Frequency (TF)** and **Inverse Document Frequency** (IDF). It computes the term frequency-inverse document value for each word. TF is the raw count of a term in a document. IDF is an algorithm that reduces the weight for most common words and add more weight for words that are rare in a document. We compute these two as follows:\n  * TF(t) = (Number of times term t appears in a document) \/ (Total number of terms in the document)\n  * IDF(t) = log_e(Total number of documents \/ Number of documents with term t in it) \n  <br>\n\n* **Word2Vec** <br>\nThis is a two layer neutral-net that processes text.\n\nThis notebook makes use of the **TF-IDF** method.","8d67aa18":"The model performance can possibly be improved by rebalancing our data. Before this is done, the current distribution of the classes are examined:"}}