{"cell_type":{"5a469967":"code","cb3624a0":"code","e3ea220d":"code","e64f0ac0":"code","873a087d":"code","6d6fe9cf":"code","a0b11504":"code","870a2fa7":"code","cf08ce1c":"code","b60fed93":"code","5227d417":"code","e244b61e":"code","c3b5181b":"code","a7919de9":"code","476083f0":"code","a89c8a94":"code","a6594334":"code","de520b6c":"code","ff29c932":"code","6bc350b1":"code","1aa4740a":"code","e840d8a3":"code","d82b3a1c":"code","a6a2e4b2":"code","d6f0aa55":"code","b79f6a43":"code","6074506b":"code","3a6c1031":"code","9a1443a8":"code","5cef8c62":"code","18ff4c6e":"code","09378040":"code","012294d0":"code","9b8d20ac":"code","52ce8bcf":"code","0d98c623":"code","7262ac66":"code","e247a3ab":"code","53ff0acb":"code","9a5cb7ef":"code","6a5ee5b7":"code","3bb0c736":"code","5959bf96":"code","3c59a693":"code","95ddc2bc":"code","fbb56f3e":"code","64054b49":"code","6618d573":"code","11d29384":"code","d0db0fa0":"code","5910b12e":"code","05597bda":"markdown"},"source":{"5a469967":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import ceil\n","cb3624a0":"## Storing all the files into dataframes\n\nsample = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\ncategories = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nsales_train = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nsales_test = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')","e3ea220d":"sales_test","e64f0ac0":"sales_train.head()","873a087d":"items.head()","6d6fe9cf":"## Joining training data to the different item names\nnew_train = sales_train.join(items.set_index('item_id'),on='item_id')","a0b11504":"## Joining training data to the different item catagories\nnew_train = new_train.join(categories.set_index('item_category_id'),on='item_category_id')","870a2fa7":"new_train = new_train.join(shops.set_index('shop_id'),on='shop_id')","cf08ce1c":"new_train['item_price'].nunique()","b60fed93":"new_train['item_name'].nunique()","5227d417":"## Need to figure out how to extract total sales by date\n\n## This gives us total sales by shop\nnew_train.groupby('shop_name').sum()","e244b61e":"new_train.groupby('date')","c3b5181b":"## Looking to see how many rows we have\nnew_train.shape","a7919de9":"## Looking for outliers \nnew_new = new_train[new_train['item_price']<=5000]","476083f0":"## Looking at the shape of the item prices without \nnew_new['item_price'].hist()","a89c8a94":"outliers = new_train[new_train['item_price']>=5000]","a6594334":"outliers","de520b6c":"33831\/2935849","ff29c932":"train_prepped = new_train[new_train['item_price']<=5000]","6bc350b1":"train_prepped","1aa4740a":"## Attempts at seeing if it clusters\n\nprint(train_prepped['shop_id'].nunique())\nprint('\\b')\nprint(train_prepped['date_block_num'].nunique())\n\nprint(60*34)","e840d8a3":"train_prepped['date_time'] = pd.to_datetime(train_prepped['date'],format='%d.%m.%Y')\ntrain_prepped","d82b3a1c":"df= train_prepped.groupby(['shop_id','date_block_num'],as_index=False)['item_cnt_day'].sum()\ndf\n","a6a2e4b2":"df= train_prepped.groupby(['date_block_num','shop_id'],as_index=False)['item_cnt_day'].sum()\ndf\n","d6f0aa55":"## Graphing Monthly Sales number by company\nplt.figure(figsize=[10,18])\n\nsns.lineplot(data=df,x='date_block_num',y='item_cnt_day',hue='shop_id',palette='dark')\nplt.legend(bbox_to_anchor=(1.2,1))","b79f6a43":"monthly_sales=train_prepped.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date_time\",\"item_price\",\"item_cnt_day\"].agg({\"date_time\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})","6074506b":"df","3a6c1031":"monthly_sales.head()","9a1443a8":"grouped = pd.DataFrame(train_prepped.groupby(['shop_id', 'date_block_num'])['item_cnt_day'].sum().reset_index())\nfig, axes = plt.subplots(nrows=5, ncols=2, sharex=True, sharey=True, figsize=(16,20))\nnum_graph = 10\nid_per_graph = ceil(grouped.shop_id.max() \/ num_graph)\ncount = 0\nfor i in range(5):\n    for j in range(2):\n        sns.pointplot(x='date_block_num', y='item_cnt_day', hue='shop_id', data=grouped[np.logical_and(count*id_per_graph <= grouped['shop_id'], grouped['shop_id'] < (count+1)*id_per_graph)], ax=axes[i][j])\n        count += 1","5cef8c62":"len(train_prepped)","18ff4c6e":"len(sales_test)","09378040":"2902039\/214200","012294d0":"sales_test['item_id'].nunique()","9b8d20ac":"train_prepped['item_id'].nunique()","52ce8bcf":"## Creating minimum date for each item\nmin_date = train_prepped.groupby([\"item_id\"]).agg({\"date_time\":\"min\"})\nmin_date","0d98c623":"\nmin_date['min_date'] = min_date['date_time']\nmin_date = min_date.drop('date_time',axis=1)","7262ac66":"## Joining date to minimum date & adding column to training data\ntrain_prepped = train_prepped.join(min_date,on='item_id')","e247a3ab":"train_prepped.head()","53ff0acb":"train_prepped['first_month'] = train_prepped.apply(first_month,axis=1)","9a5cb7ef":"train_prepped.head()","6a5ee5b7":"## train_prepped['first_month'] = (train_prepped['date_time'] > train_prepped['min_date']) & (train_prepped['date_time'] < (train_prepped['min_date'] + pd.Timedata('30 d'))","3bb0c736":"## Creating minimum date for each item at each shop\nmin_date_per_shop = train_prepped.groupby([\"shop_id\",\"item_id\"]).agg({\"date_time\":\"min\"})\nmin_date_per_shop","5959bf96":"## Creating indicator for first month sale at each shop\ndef first_month(row):\n    if (row['date_time'] > min_date_per_shop.loc[(row['shop_id'],row['item_id']), 'date_time']) & (row['date_time'] < (min_date_per_shop.loc[(row['shop_id'],row['item_id']), 'date_time'] + pd.Timedelta('30 d'))):\n        return 1\n    else:\n        return 0","3c59a693":"min_date_per_shop.loc[(row['shop_id'],row['item_id']), 'date_time']","95ddc2bc":"train_prepped['first_month'] = train_prepped.apply(first_month,axis=1)","fbb56f3e":"aggregated_train = train_prepped.groupby([\"shop_id\",\"item_id\"])[\"date_time\",\"item_cnt_day\",'first_month'].agg({\"date_time\":[\"min\",'max'],\"item_cnt_day\":\"sum\",'first_month':'sum'})\naggregated_train","64054b49":"train_prepped.to_csv('training_prepped.csv')","6618d573":"train_prepped.head()","11d29384":"train_2 = train_prepped.groupby(['shop_id','item_id'])['item_cnt_day','first_month'].sum()","d0db0fa0":"sales_test.head()","5910b12e":"train_2.groupby('shop_id').mean()","05597bda":"## Creating indicator for first month sale\ndef first_month(row):\n    if (row['date_time'] > row['min_date']) & (row['date_time'] < (row['min_date'] + pd.Timedelta('30 d'))):\n        return 1\n    else:\n        return 0\n        \nIncorrect way of going about it, gets the lowest date fore everything"}}