{"cell_type":{"04ff223f":"code","27c86c41":"code","9d7c90c4":"code","901ee459":"code","7a05e313":"code","d893fa7e":"code","fbafab9f":"code","488476e9":"code","cf41e69d":"code","1dcf0735":"markdown","ada34d21":"markdown"},"source":{"04ff223f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time","27c86c41":"def sigmoid(X, weight):\n    z = np.dot(X, weight)\n    return 1 \/ (1 + np.exp(-z))\n\ndef loss(h, y):\n    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n\ndef gradient_descent(X, h, y):\n    return np.dot(X.T, (h - y)) \/ y.shape[0]\n\ndef update_weight_loss(weight, learning_rate, gradient):\n    return weight - learning_rate * gradient\n\ndef log_likelihood(x, y, weights):\n    z = np.dot(x, weights)\n    ll = np.sum( y*z - np.log(1 + np.exp(z)) )\n    return ll\n\ndef gradient_ascent(X, h, y):\n    return np.dot(X.T, y - h)\n\ndef update_weight_mle(weight, learning_rate, gradient):\n    return weight + learning_rate * gradient","9d7c90c4":"data = pd.read_csv(\"..\/input\/titanic\/train_data.csv\")\nprint(\"Dataset size\")\nprint(\"Rows {} Columns {}\".format(data.shape[0], data.shape[1]))","901ee459":"print(\"Columns and data types\")\npd.DataFrame(data.dtypes).rename(columns = {0:'dtype'})","7a05e313":"df = data.copy()","d893fa7e":"df['class'] = df['Survived'].apply(lambda x : 1 if x == \"Yes\" else 0)\n# features will be saved as X and target will be saved as y\nX = df[['Sex','Emb_3']].copy()\nX2 = df[['Sex','Emb_3']].copy()\ny = df['class'].copy()","fbafab9f":"start_time = time.time()\n\nnum_iter = 100000\n\nintercept = np.ones((X.shape[0], 1)) \nX = np.concatenate((intercept, X), axis=1)\ntheta = np.zeros(X.shape[1])\n\nfor i in range(num_iter):\n    h = sigmoid(X, theta)\n    gradient = gradient_descent(X, h, y)\n    theta = update_weight_loss(theta, 0.1, gradient)\n    \nprint(\"Training time (Log Reg using Gradient descent):\" + str(time.time() - start_time) + \" seconds\")\nprint(\"Learning rate: {}\\nIteration: {}\".format(0.1, num_iter))","488476e9":"result = sigmoid(X, theta)\nresult","cf41e69d":"'''from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(fit_intercept=True, max_iter=100000)\nclf.fit(df[['Sex','Emb_3']], y)\nprint(\"Training time (sklearn's LogisticRegression module):\" + str(time.time() - start_time) + \" seconds\")\nprint(\"Learning rate: {}\\nIteration: {}\".format(0.1, num_iter))'''","1dcf0735":"### Pre-requisite functions","ada34d21":"### Running Logistic Regression from scratch"}}