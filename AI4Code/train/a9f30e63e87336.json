{"cell_type":{"a47eec96":"code","370952f8":"code","409fd748":"code","85ac7499":"code","0b7a877e":"code","fc6472fc":"code","ed1e6f99":"code","8073e48b":"code","e4492ffb":"code","1f9f735f":"code","ee59b99a":"code","c10fc42e":"code","fff974fe":"code","1cf6c534":"code","f8ef141a":"code","75c57b5c":"code","8ed77be5":"code","2bcf60f9":"code","3ee87533":"code","6e8c32eb":"code","9428fab3":"code","6c3f7a6c":"code","5588548f":"markdown","15da5440":"markdown","566fb37e":"markdown","10e636ff":"markdown","5b0d057e":"markdown","80265097":"markdown","1d77f4f8":"markdown","b22f6228":"markdown","941c3ad8":"markdown","4cca351a":"markdown","f17e3b8e":"markdown","60d9cc95":"markdown","0cbc0657":"markdown","adb55d6e":"markdown","7c170914":"markdown","a8b8085b":"markdown","35737b3c":"markdown","3f153391":"markdown"},"source":{"a47eec96":"import pandas as pd\n\nd_fake = pd.read_csv('..\/input\/fake-news-data\/fnn_politics_fake.csv')\nheadlines_fake = d_fake.drop(['id', 'news_url', 'tweet_ids'], axis=1).rename(columns={'title': 'headline'})\nheadlines_fake['fake'] = 1\n\nd_real = pd.read_csv('..\/input\/fake-news-data\/fnn_politics_real.csv')\nheadlines_real = d_real.drop(['id', 'news_url', 'tweet_ids'], axis=1).rename(columns={'title': 'headline'})\nheadlines_real['fake'] = 0\n\neval_data = pd.concat([headlines_fake, headlines_real])","370952f8":"import os\n\ndef read_data(d):\n    \"\"\"Each file has a headline as the first line, followed by some white space and then the article content.\n    We need to exract the headline and the content of each file and store them in lists.\"\"\"\n    files = os.listdir(d)\n    headlines, contents = [], []\n    for fname in files:\n        if fname[:5] != 'polit':\n            continue\n        \n        f = open(d + '\/' + fname)\n        text = f.readlines()\n        f.close()\n\n        if len(text) == 2:\n            # One of the lines is missing\n            if len(text[1]) <= 1:\n                # There is no article content or headline\n                continue\n        elif len(text) >= 3:\n            # More than one empty line encountered\n            text[1] = text[-1]\n        else:\n            # Only one or zero lines is file\n            continue\n        \n        headline, content = text[0][:-1].strip().rstrip(), text[1][:-1]\n        headlines.append(headline)\n        contents.append(content)\n    \n    return headlines, contents\n\n\nfake_dir = '..\/input\/fake-news-data\/fnd_news_fake'\nfake_headlines, fake_content = read_data(fake_dir)\nfake_headlines = pd.DataFrame(fake_headlines, columns=['headline'])\nfake_headlines['fake'] = 1\n\nreal_dir = '..\/input\/fake-news-data\/fnd_news_real'\nreal_headlines, real_content = read_data(real_dir)\nreal_headlines = pd.DataFrame(real_headlines, columns=['headline'])\nreal_headlines['fake'] = 0","409fd748":"eval_data = pd.concat([eval_data, fake_headlines, real_headlines])\neval_data['fake'].value_counts()\neval_data.head()","85ac7499":"all_news = pd.read_csv('..\/input\/all-the-news\/articles3.csv', nrows=300000)\nall_news = all_news.rename(columns={'title': 'headline'})\nall_news['fake'] = 0\ndata = all_news[['headline', 'fake']]\n\n# data = pd.concat([data, all_news])\ndata.head()","0b7a877e":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport numpy as np\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef format_data(data, max_features, maxlen, tokenizer=None, shuffle=False):\n    if shuffle:\n        data = data.sample(frac=1).reset_index(drop=True)\n    \n    data['headline'] = data['headline'].apply(lambda x: str(x).lower())\n\n    X = data['headline']\n    Y = data['fake'].values # 0: Real; 1: Fake\n\n    if not tokenizer:\n        filters = \"\\\"#$%&()*+.\/<=>@[\\\\]^_`{|}~\\t\\n\"\n        tokenizer = Tokenizer(num_words=max_features, filters=filters)\n        tokenizer.fit_on_texts(list(X))\n\n    X = tokenizer.texts_to_sequences(X)\n    X = pad_sequences(X, maxlen=maxlen)\n\n    return X, Y, tokenizer","fc6472fc":"max_features, max_len = 5000, 25\nX, Y, tokenizer = format_data(data, max_features, max_len, shuffle=True)\nX_eval, Y_eval, tokenizer = format_data(eval_data, max_features, max_len, tokenizer=tokenizer)","ed1e6f99":"import pickle\npickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))","8073e48b":"from keras.layers import Input, Dense, Bidirectional, GRU, Embedding, Dropout, LSTM\nfrom keras.layers import concatenate, SpatialDropout1D, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras import regularizers\n\nepochs=20\n\n# Input shape\ninp = Input(shape=(max_len,))\n\nencoder = Embedding(max_features, 50)(inp)\nencoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\nencoder = Bidirectional(LSTM(25, return_sequences=True,\n                        activity_regularizer=regularizers.l1(10e-5)))(encoder)\n\ndecoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\ndecoder = GlobalMaxPooling1D()(decoder)\ndecoder = Dense(50, activation='relu')(decoder)\ndecoder = Dense(max_len)(decoder)\n\nmodel = Model(inputs=inp, outputs=decoder)\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, X, epochs=epochs, batch_size=64, verbose=1)\n\nmodel.save_weights('model{}.h5'.format(epochs))","e4492ffb":"model.evaluate(X, X)","1f9f735f":"results = model.predict(X_eval, batch_size=1, verbose=1)","ee59b99a":"mse = np.mean(np.power(X_eval - results, 2), axis=1)\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                         'true_class': Y_eval})\nerror_df.describe()","c10fc42e":"from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support)","fff974fe":"LABELS = ['REAL', 'FAKE']\nbest, threshold = -1, -1\n\n# General Search\nfor t in range(0, 3500000, 10000):\n    y_pred = [1 if e > t else 0 for e in error_df.reconstruction_error.values]\n    score = f1_score(y_pred, error_df.true_class, average='micro', labels=[0, 1])\n    if score > best:\n        best, threshold = score, t\n\n# Specialized Search around general best\nfor t in range(threshold-10000, threshold+10000):\n    y_pred = [1 if e > t else 0 for e in error_df.reconstruction_error.values]\n    score = f1_score(y_pred, error_df.true_class, average='micro', labels=[0, 1])\n    if score > best:\n        best, threshold = score, t\n\nprint(threshold, best)","1cf6c534":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ngroups = error_df.groupby('true_class')\nfig, ax = plt.subplots()\n\nfor name, group in groups:\n    ax.plot(group.index, group.reconstruction_error, marker='o', ms=3.5, linestyle='',\n            label=\"Fake\" if name == 1 else \"Real\")\n\nax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\nax.legend()\nplt.title(\"Reconstruction error for different classes\")\nplt.ylabel(\"Reconstruction error\")\nplt.xlabel(\"Data point index\")\nplt.show();","f8ef141a":"LABELS = ['FAKE', 'REAL']\nerrors = error_df.reconstruction_error.values\ny_pred = [1 if e > threshold else 0 for e in errors] # final predictions\nconf_matrix = confusion_matrix(error_df.true_class, y_pred)\nplt.figure(figsize=(12, 12))\nsns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","75c57b5c":"from sklearn.metrics import f1_score\n\ndef accuracy_f1(preds, correct):\n    \"\"\"Returns F1-Score for predictions\"\"\"\n    return f1_score(preds, correct, average='micro', labels=[0, 1])\n\naccuracy_f1(y_pred, error_df.true_class)","8ed77be5":"from sklearn.preprocessing import MinMaxScaler\nminmax_0_05 = MinMaxScaler(feature_range=(0, 0.5))\nminmax_05_1 = MinMaxScaler(feature_range=(0.5, 1))","2bcf60f9":"errors_below = np.array([i for i, e in enumerate(errors) if e <= threshold])\nerrors_above = np.array([i for i, e in enumerate(errors) if e > threshold])\n\nminmax_0_05.fit(errors[errors_below].reshape(-1, 1))\nminmax_05_1.fit(errors[errors_above].reshape(-1, 1))","3ee87533":"errors_mm = np.array([minmax_0_05.transform(e.reshape(1, -1)) if i in errors_below\n                      else minmax_05_1.transform(e.reshape(1, -1))\n                      for i, e in enumerate(errors)]).flatten()\n\ny_pred2 = [1 if e > 0.5 else 0 for e in errors_mm]","6e8c32eb":"def accuracy_percentile(preds, Y_validate):\n    \"\"\"Return the percentage of correct predictions for each class and in total\"\"\"\n    real_correct, fake_correct, total_correct = 0, 0, 0\n    _, (fake_count, real_count) = np.unique(Y_validate, return_counts=True)\n\n    for i, r in enumerate(preds):\n        if r == Y_validate[i]:\n            total_correct += 1\n            if r == 0:\n                fake_correct += 1\n            else:\n                real_correct += 1\n\n    print('Real Accuracy:', real_correct\/real_count * 100, '%')\n    print('Fake Accuracy:', fake_correct\/fake_count * 100, '%')\n    print('Total Accuracy:', total_correct\/(real_count + fake_count) * 100, '%')\n\n\naccuracy_percentile(y_pred2, error_df.true_class)","9428fab3":"from sklearn.metrics import f1_score\n\ndef accuracy_f1(preds, correct):\n    \"\"\"Returns F1-Score for predictions\"\"\"\n    return f1_score(preds, correct, average='micro', labels=[0, 1])\n\naccuracy_f1(y_pred2, error_df.true_class)","6c3f7a6c":"pd.Series(errors_mm).to_csv('autoencoder.csv', index=False)","5588548f":"## Scaling Error\n\nRight now the errors lie in $[0, \\infty)$. It is useful in some cases (for example, using these predictions in ensembling) to scale the error in $[0, 1]$. We cannot though simply min-max all of the values together, since then the final output wouldn't be a representative probability. Instead, we are going to do the following: Values below the threshold will be scaled to $[0, 0.5]$ and values above the threshold will be scaled to $[0.5, 1]$. The threshold, after scaling, is set to `0.5`.","15da5440":"Finally, we are going to convert our errors array to the scaled outputs.","566fb37e":"## Classification\n\n*(code here is modified from [this blog](https:\/\/medium.com\/@curiousily\/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd))*\n\nNow we need to calculate the reconstruction error of the test set.","10e636ff":"We are going to visualize the data points against the threshold line.","5b0d057e":"Next, we are going to compute the F1 score as well.","80265097":"With the scalers initialized, we need to fit them. We are going to fit `minmax_0_05` to items below the threshold, and `minmax_05_1` to items above the threshold.","1d77f4f8":"## Introduction\n\nIn this kernel we will build an autoencoder to discriminate between real and fake news headlines. The dataset we will use is [A Million News Headlines](https:\/\/www.kaggle.com\/therohk\/million-headlines), which contains real news headlines. For evaluation, we will use [Fake News Net](https:\/\/github.com\/KaiDMML\/FakeNewsNet) and [Fake News Dataset](http:\/\/web.eecs.umich.edu\/~mihalcea\/downloads.html#FakeNews). These datasets contain both real and fake headlines. After performing some basic pre-processing, we will train an autoencoder to represent real headlines. To perform classification, we will reconstruct inputs and calculate the overall reconstruction error. If the error is above a certain threshold, the item will be classified as fake, otherwise as real. To evaluate the network's performance, we will measure percentile and F1-score accuracy metrics.","b22f6228":"Time to compute our results!","941c3ad8":"## Model\n\nThe model we will use is based around a bi-directional RNN (either GRU or LSTM), with max pooling. The encoder is comprised of two RNN layers, while the decoder uses an RNN with a dense layer on top of it. The reconstruction of the original input occurs on a final Dense layer.","4cca351a":"The `max_features` and `max_len` variables denote the length of each vector and the vocabulary length.","f17e3b8e":"We are now going to calculate the percentile accuracy of the scaled predictions, alongside the F1-score (this score may differ slightly for values right around the threshold, but the difference is negligible).","60d9cc95":"Now let's read our training data:","0cbc0657":"We now need to compute the optimal threshold to make our predictions. We will split the process into two:\n\n1. Find the general range where the threshold lies.\n2. In that range, find a more specific threshold value.","adb55d6e":"We will now concatenate these two new datasets into an evaluation dataset.","7c170914":"## Data Processing\n\nWe also need to format the data. We will split the dataset into features `X` and target `Y`. For `Y`, we simply store the label at the target column. For `X`, we are first going to tokenise and pad our text input before storing it.","a8b8085b":"Next we will read fake and real headlines from the Fake News Dataset.","35737b3c":"## Reading Data\n\nFirst we are going to read the evaluation data for real and fake headlines, and then we are going to concatenate the two dataframes.","3f153391":"Finally, we'll store the predictions."}}