{"cell_type":{"17f7d831":"code","caaa6e7a":"code","a82a6e21":"code","3395e7f8":"code","49e8feb5":"code","9e267ad9":"code","8a7a24ba":"code","f02fdf4c":"code","30435d8d":"code","d5e0e8c6":"code","9d269af9":"code","d13a7095":"code","4d7f4910":"code","4a9791d5":"code","54c40a6c":"code","e6d9ccb9":"code","bb5a0362":"code","06bfe1f5":"code","2c75a832":"code","43f63faa":"code","b89823af":"code","c0cb53b6":"code","c96bd59f":"code","b69b72d5":"code","f6bd1773":"code","c4c88966":"code","4dc4b3a0":"code","c47e6809":"code","2ee5c184":"code","2bb80a7b":"code","7a002ca5":"code","5bd43b8f":"code","5edfae3a":"code","0e688053":"code","2b464e81":"code","1c03232f":"code","c39c7449":"code","aa6a2035":"code","6a32bbb0":"code","49efd04e":"code","548dcae3":"code","1a33f828":"code","fafbf65f":"code","375d966a":"code","1a982354":"code","4fbb6955":"code","4bb1b0d4":"code","70e70893":"code","6213d55f":"code","f6d7fda7":"code","88158ed6":"code","a5674895":"code","e02ab8a8":"markdown","d55e8448":"markdown","fb6ded06":"markdown","0d19cefb":"markdown","d3c20efe":"markdown","4a2b89f7":"markdown","b56d0db2":"markdown","55605373":"markdown","e287c4e7":"markdown","0dc52e9e":"markdown","643c323b":"markdown","439715fe":"markdown","bd43f565":"markdown","3dd9ef2d":"markdown","f0e11167":"markdown","988939e9":"markdown","26048170":"markdown","fc8c74f5":"markdown"},"source":{"17f7d831":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","caaa6e7a":"train_df = pd.read_csv('..\/input\/loan-predication\/train_u6lujuX_CVtuZ9i (1).csv')\ntrain_df.info()","a82a6e21":"#Data Shape\ntrain_df.shape","3395e7f8":"dummy_Gender = pd.get_dummies(train_df['Gender'])\ndummy_Gender.head()","49e8feb5":"dummy_Education = pd.get_dummies(train_df['Education'])\ndummy_Education.head()","9e267ad9":"dummy_Married = pd.get_dummies(train_df['Married'])\ndummy_Married.head()","8a7a24ba":"dummy_Property_Area = pd.get_dummies(train_df['Property_Area'])\ndummy_Property_Area.head()","f02fdf4c":"dummy_Loan_Status = pd.get_dummies(train_df['Loan_Status'])\ndummy_Loan_Status.head()","30435d8d":"df2 = pd.concat((dummy_Gender , dummy_Married) , axis=1)\ndf2.head()","d5e0e8c6":"df3=pd.concat((df2 ,dummy_Education ) , axis=1)\ndf3.head()","9d269af9":"df4=pd.concat((df3,dummy_Property_Area) , axis=1)\ndf4.head()","d13a7095":"df5=pd.concat((df4 , dummy_Loan_Status) , axis=1)\ndf5.head()","4d7f4910":"final_con = pd.concat((train_df , df5) , axis=1)\nfinal_con.head()","4a9791d5":"final_Data = final_con.drop(['Loan_ID' , 'Married' , 'Education' , 'Gender' , 'Self_Employed' , 'Loan_Status' , 'Property_Area' , 'Male' , 'Yes' , 'Not Graduate' , 'Y'] , axis=1)","54c40a6c":"final_Data.head()","e6d9ccb9":"final_Data.rename(columns= {\"Female\":\"Gender\" , \"No\":\"Married\" , \"Graduate\":\"Education\" , \"N\":\"Loan_Status\"})","bb5a0362":"final_Data.tail()","06bfe1f5":"#Checking The Missing Values\nfinal_Data.isnull()","2c75a832":"final_Data.isnull().sum()","43f63faa":"final_Data['LoanAmount'] = final_Data['LoanAmount'].fillna(final_Data['LoanAmount'].mean())","b89823af":"final_Data['Credit_History'] = final_Data['Credit_History'].fillna(final_Data['Credit_History'].median())","c0cb53b6":"final_Data.isnull().sum()","c96bd59f":"final_Data.dropna(inplace = True)","b69b72d5":"final_Data.isnull().sum()","f6bd1773":"#Data Set Shape \nfinal_Data.shape","c4c88966":"#Data Visualization Libiraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","4dc4b3a0":"final_Data.info()","c47e6809":"from sklearn.model_selection import train_test_split","2ee5c184":"x=final_Data.iloc[1:586,1:12].values","2bb80a7b":"y=final_Data.iloc[1:586 ,12].values","7a002ca5":"x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.3,random_state=0)","5bd43b8f":"final_Data.dtypes.sample(10)","5edfae3a":"#solver  is liblinear or sag\n#Accuracy with sag could small -- but with liblinear could Good\n#the iteration with l1 is smaller than l2\nfrom sklearn.linear_model import LogisticRegression \nmodel_LR=LogisticRegression(solver='liblinear', C=1.0 , penalty='l1', random_state=33 , max_iter=1000)\nmodel_LR.fit(x_train,y_train)","0e688053":"pred = model_LR.predict(x_test)","2b464e81":"print('Y_Prediction is :: \\n' , pred)\nprint('\\nY_Test is :: \\n' , y_test)","1c03232f":"print('Y_Prediction is :: \\n' , pred[10:15])\nprint('\\nY_Test is :: \\n' , y_test[10:15])","c39c7449":"import sklearn.metrics as metrics","aa6a2035":"#print number of classes\nclasses = model_LR.classes_\nprint('The Number Of Classes Is :: ' ,classes)","6a32bbb0":"#View number of Iterations\nIter = model_LR.n_iter_\nprint('The Number Of Iteration is :: ' ,Iter)","49efd04e":"#import confusion Matrics\nfrom sklearn.metrics import confusion_matrix\nCM = confusion_matrix(y_test , pred)\nprint('The Confuios Matrix is :: \\n' , CM)","548dcae3":"sns.heatmap(CM , center=True)\nplt.show()","1a33f828":"#print Training Accuracy\ntrain_Acc = model_LR.score(x_train , y_train)\nprint('Accuracy of Training Data is :: ' , train_Acc)\n#print Testing Accuracy\ntest_Acc = model_LR.score(x_test , y_test)\nprint('Accuracy of Testing Data is :: ' , test_Acc)","fafbf65f":"score = metrics.accuracy_score(pred , y_test)\nprint('Logistic Regrission Accurrcy is :: ' ,score )","375d966a":"#Accuracy_score ((TP+TN) \/ float(TP + TN + FP + FN))\n#Accuracy with normalize = False -- summition of True_Positive and True_Negative\nAcc_score = metrics.accuracy_score(y_test , pred , normalize = False)\nprint('Accuracy Score is :: \\n' , Acc_score)","1a982354":"#Accuracy_score ((TP+TN) \/ float(TP + TN + FP + FN))\n#Accuracy with normalize = True\nAcc_score = metrics.accuracy_score(y_test , pred , normalize = True)\nprint('Accuracy Score is :: \\n' , Acc_score)","4fbb6955":"#Calculating Recall Score : : (Sensitivity) (TP \/ float(TP + FN) ) 1\/1+2\nfrom sklearn.metrics import recall_score\nRecall_Score = recall_score(y_test , pred , average = 'micro')\nprint('Recall_Score is :: \\n' , Recall_Score)","4bb1b0d4":"#Calculating precision Score :: (Specificity) # (TP \/ float(TP + FP))\nfrom sklearn.metrics import precision_score\nPrecision_Score = precision_score(y_test , pred , average='micro')\nprint('Precision Score is :: \\n' , Precision_Score)","70e70893":"#F1 score =2 * (precision * recall) \/ (precision + recall)\nfrom sklearn.metrics import f1_score\nF1_SCORE = f1_score(y_test , pred, average = 'micro')\nprint('F1 Score is :: \\n' , F1_SCORE)","6213d55f":"#Precision Recall fScore Support\nfrom sklearn.metrics import precision_recall_fscore_support\n","f6d7fda7":"P_R_F_Support = precision_recall_fscore_support(y_test , pred , average= 'micro')\nprint('Precision Recall fScore Support :: \\n' , P_R_F_Support)","88158ed6":"from sklearn.metrics import classification_report","a5674895":"class_report = classification_report(y_test , pred )\nprint('Classification Report is :: \\n ' , class_report)","e02ab8a8":"# Calculate Precision and Recall","d55e8448":"# View Accuracy of Train and Test","fb6ded06":"A housing company that deals in all housing loans. White in all residential, semi-white and rural areas. To obtain a loan to obtain the loan.\nThe company wants to automate the educational process of the loan over the Internet. These details are gender, marital status and education. A problem arose in defining customer segments to serve the service requests provided to customer service. Here they have provided a partial dataset.","0d19cefb":"**Calculation F1 score **","d3c20efe":"# Convert Categorical Values to Binary (0 and 1) ","4a2b89f7":"# Importing Libraries","b56d0db2":"# Print Accuracy","55605373":"# Spliting The DataSet To Train and Test Set","e287c4e7":"# Drawing Confusion Metrix","0dc52e9e":"![image.png](attachment:image.png)","643c323b":"**Dataset Description:**","439715fe":"# Logistic Regrission","bd43f565":"Problem","3dd9ef2d":"# Calculating Confusion Metrics","f0e11167":"# Classification Report","988939e9":"# Loading The DataSet","26048170":"# Loan Prediction using Logistic Regression Modeling","fc8c74f5":"# Data Cleaning"}}