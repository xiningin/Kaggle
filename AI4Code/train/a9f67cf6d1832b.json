{"cell_type":{"48e30f06":"code","a3408913":"code","08a3559d":"code","f2da6ee7":"code","4c8dd501":"code","67d43c72":"code","ecb29665":"code","ef379532":"code","fd7300be":"code","57d59195":"code","d62f11ee":"code","f6743970":"code","a1f2a20b":"code","6d038690":"code","8bced529":"code","7c3ff630":"code","e7ec0d50":"code","d715e1b1":"code","f699d800":"code","7f3a0b05":"code","578f5ef7":"code","48fa6613":"code","e08283b9":"code","900dde30":"code","db5f1c8f":"code","aec297ff":"code","9034794a":"code","18965e9c":"code","0b8aa61b":"code","42df9e49":"code","f68ba6ad":"code","4816c002":"code","e4ef83d3":"code","dc3ad203":"code","1f273477":"code","8e9dd664":"code","0cb77bcc":"code","bce1f05b":"code","330bcbbf":"code","da5e03a1":"code","f443d105":"code","f61bc0ff":"code","67743f15":"code","41176295":"code","319b996a":"code","4ecb48d9":"code","ed6e6643":"code","dea7a569":"code","80cc9856":"code","d1066c49":"code","9be4244b":"code","73201e31":"code","d4fce112":"code","cc6af5f8":"code","ed0e1ae1":"code","3c6b1fe8":"code","96076dfe":"code","1d1616ce":"code","751e354d":"code","4e367291":"code","1eb4e662":"code","abbdc3df":"code","e65bb54d":"code","389fd9c1":"code","b7513cf3":"markdown","a25441ac":"markdown","e463e566":"markdown","379e6e5a":"markdown","b9d8df43":"markdown","398a80d5":"markdown","4921e6c5":"markdown","1f8ccabf":"markdown","dcaf3919":"markdown","20dcdcf1":"markdown","40bbdc25":"markdown","d8230a60":"markdown","02bd43bf":"markdown","11ddcbfc":"markdown","22403b3c":"markdown","4ef798b5":"markdown","2e8e6197":"markdown","851b02b4":"markdown","4168da05":"markdown","6b51ced1":"markdown","e16f6acb":"markdown","43b5487d":"markdown","f082e8b6":"markdown","9020a41a":"markdown","76902b8d":"markdown","c15f8462":"markdown","add3378e":"markdown","cab84ba5":"markdown","bd53ffc0":"markdown"},"source":{"48e30f06":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a3408913":"import warnings\nwarnings.filterwarnings(\"ignore\")","08a3559d":"import pandas as pd\nimport numpy as np\nnp.set_printoptions(suppress=True)","f2da6ee7":"CancerData = pd.read_csv('\/kaggle\/input\/cancer_reg.csv', encoding='latin')\nprint('Shape before removing duplicates', CancerData.shape)\nCancerData = CancerData.drop_duplicates()\nprint('Shape before removing duplicates', CancerData.shape)\nCancerData.head()","4c8dd501":"CancerData.columns","67d43c72":"CancerData = CancerData[['avgAnnCount', 'avgDeathsPerYear', 'incidenceRate',\n       'medIncome', 'popEst2015', 'povertyPercent', 'studyPerCap', 'binnedInc',\n       'MedianAge', 'MedianAgeMale', 'MedianAgeFemale', 'Geography',\n       'AvgHouseholdSize', 'PercentMarried', 'PctNoHS18_24', 'PctHS18_24',\n       'PctSomeCol18_24', 'PctBachDeg18_24', 'PctHS25_Over',\n       'PctBachDeg25_Over', 'PctEmployed16_Over', 'PctUnemployed16_Over',\n       'PctPrivateCoverage', 'PctPrivateCoverageAlone', 'PctEmpPrivCoverage',\n       'PctPublicCoverage', 'PctPublicCoverageAlone', 'PctWhite', 'PctBlack',\n       'PctAsian', 'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate', 'TARGET_deathRate']]","ecb29665":"CancerData.head()","ef379532":"CancerData.describe()","fd7300be":"CancerData.info()","57d59195":"CancerData.isna().sum()","d62f11ee":"CancerData.drop(['PctPrivateCoverageAlone', 'PctSomeCol18_24'], axis=1, inplace=True)","f6743970":"CancerData.isna().sum()","a1f2a20b":"CancerData.iloc[1:10,7:]","6d038690":"CancerData.nunique()","8bced529":"CancerData.drop('Geography', axis=1, inplace=True)","7c3ff630":"CancerData.shape","e7ec0d50":"CancerData.head()","d715e1b1":"%matplotlib inline\nhisto=CancerData.hist(['incidenceRate', 'medIncome',\n       'povertyPercent', 'MedianAgeMale', 'MedianAgeFemale', 'AvgHouseholdSize',\n       'PercentMarried', 'PctNoHS18_24', 'PctHS18_24', 'PctBachDeg18_24'], figsize=(30,30))","f699d800":"histo = CancerData.hist(['PctHS25_Over', 'PctBachDeg25_Over', 'PctEmployed16_Over',\n       'PctUnemployed16_Over', 'PctPrivateCoverage', 'PctEmpPrivCoverage',\n       'PctPublicCoverage', 'PctPublicCoverageAlone', 'PctWhite', 'PctBlack',\n       'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate',\n       'TARGET_deathRate'], figsize=(30,30))","7f3a0b05":"['incidenceRate', 'medIncome', 'povertyPercent', 'MedianAgeMale', 'MedianAgeFemale', 'AvgHouseholdSize',\n'PercentMarried', 'PctNoHS18_24', 'PctHS18_24', 'PctBachDeg18_24', 'PctHS25_Over', 'PctBachDeg25_Over', 'PctEmployed16_Over',\n'PctUnemployed16_Over', 'PctPrivateCoverage', 'PctEmpPrivCoverage',\n'PctPublicCoverage', 'PctPublicCoverageAlone', 'PctWhite', 'PctBlack',\n'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate',\n'TARGET_deathRate']","578f5ef7":"import matplotlib.pyplot as plt\nCancerData.groupby('binnedInc').size().plot.bar()","48fa6613":"scatter = pd.plotting.scatter_matrix(CancerData, figsize=(20,20))","e08283b9":"def ConVSCon(inpData, Cols, Target):\n    fig,subplot = plt.subplots(nrows = len(Cols), ncols = 1, figsize = (5,80))\n    for ColName, PlotNumber in zip(Cols, range(len(Cols))):\n        inpData.plot.scatter(x = ColName, y = Target, ax = subplot[PlotNumber])","900dde30":"ConVSCon(inpData=CancerData, Cols=['incidenceRate', 'medIncome', 'povertyPercent', 'MedianAgeMale', 'MedianAgeFemale', 'AvgHouseholdSize',\n'PercentMarried', 'PctNoHS18_24', 'PctHS18_24', 'PctBachDeg18_24', 'PctHS25_Over', 'PctBachDeg25_Over', 'PctEmployed16_Over',\n'PctUnemployed16_Over', 'PctPrivateCoverage', 'PctEmpPrivCoverage',\n'PctPublicCoverage', 'PctPublicCoverageAlone', 'PctWhite', 'PctBlack',\n'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate'], Target='TARGET_deathRate')","db5f1c8f":"plt.scatter(x=CancerData['incidenceRate'], y=CancerData['TARGET_deathRate'])","aec297ff":"CancerData.plot.scatter(x = 'incidenceRate', y='TARGET_deathRate',marker='o')","9034794a":"CoorData = CancerData.corr()","18965e9c":"np.abs(CoorData['TARGET_deathRate']).sort_values(ascending=False)","0b8aa61b":"['TARGET_deathRate', 'PctBachDeg25_Over', 'incidenceRate',\n       'PctPublicCoverageAlone', 'povertyPercent', 'medIncome',\n       'PctEmployed16_Over', 'PctHS25_Over', 'PctPublicCoverage',\n       'PctPrivateCoverage', 'PctUnemployed16_Over', 'PctMarriedHouseholds',\n       'PctBachDeg18_24', 'PctEmpPrivCoverage', 'PercentMarried', 'PctHS18_24',\n       'PctBlack']","42df9e49":"bar = CancerData.groupby(['binnedInc']).mean()['TARGET_deathRate'].plot.bar(figsize = (5,5))","f68ba6ad":"CancerData.boxplot(by='binnedInc', column='TARGET_deathRate', figsize=(10,10))","4816c002":"from scipy.stats import f_oneway\ncategrpList = CancerData.groupby(['binnedInc'])['TARGET_deathRate'].apply(list)\nANOVA = f_oneway(*categrpList)\nprint(np.round(ANOVA[1],decimals = 10))","e4ef83d3":"CancerData.info()","dc3ad203":"MapResult = {'(61494.5, 125635]':10, '(48021.6, 51046.4]':7, '(42724.4, 45201]':5,\n       '(51046.4, 54545.6]':8, '(37413.8, 40362.7]':3, '(40362.7, 42724.4]':4,\n       '(54545.6, 61494.5]':9, '(34218.1, 37413.8]':2, '[22640, 34218.1]':1,\n       '(45201, 48021.6]':6}","1f273477":"CancerData['binnedInc'] = CancerData['binnedInc'].map(MapResult)","8e9dd664":"CancerData.head()","0cb77bcc":"CancerData['binnedInc'].unique()","bce1f05b":"CancerData.isna().sum()","330bcbbf":"CancerData['PctEmployed16_Over'] = CancerData['PctEmployed16_Over'].fillna(CancerData['PctEmployed16_Over'].median())","da5e03a1":"CancerData['PctEmployed16_Over'].isna().sum()","f443d105":"Predictors = ['PctBachDeg25_Over', 'incidenceRate',\n       'PctPublicCoverageAlone', 'povertyPercent', 'medIncome',\n       'PctEmployed16_Over', 'PctHS25_Over', 'PctPublicCoverage',\n       'PctPrivateCoverage', 'PctUnemployed16_Over', 'PctMarriedHouseholds',\n       'PctBachDeg18_24', 'PctEmpPrivCoverage', 'PercentMarried', 'PctHS18_24',\n       'PctBlack', 'binnedInc']\nTarget = ['TARGET_deathRate']\nX = CancerData[Predictors].values\ny = CancerData[Target].values","f61bc0ff":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)","67743f15":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","41176295":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlrRegModel = lr.fit(X_train, y_train)\nlrPrediction = lrRegModel.predict(X_test)\nfrom sklearn.metrics import r2_score\nprint('R2 value', r2_score(y_train, lrRegModel.predict(X_train)))\nprint('Accuracy', 100-(np.mean((np.abs(y_test-lrPrediction)\/y_test))*100))\n\nTestingData = pd.DataFrame(X_test, columns=Predictors)\nTestingData['Target'] = y_test\nTestingData['PredictedValue'] = lrPrediction\nTestingData['APE'] = (np.abs(y_test-lrPrediction)\/y_test)*100\nTestingData.head()","319b996a":"from sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(max_depth=6, criterion='mse')\ndtRegModel = dt.fit(X_train, y_train)\ndtPrediction = dtRegModel.predict(X_test)\nprint('R2 value', r2_score(y_train, dtRegModel.predict(X_train)))\nprint('Accuracy', 100-(np.mean((np.abs(y_test-dtPrediction)\/y_test))*100))\n\nfeature_importances = pd.Series(dtRegModel.feature_importances_, index=Predictors)\nfeature_importances.nlargest(17).plot.barh()\n\nTestingData = pd.DataFrame(X_test, columns=Predictors)\nTestingData['Target'] = y_test\nTestingData['PredictedValue'] = dtPrediction\n#TestingData['APE'] = (np.abs(y_test-dtPrediction)\/y_test)*100\nTestingData.head()","4ecb48d9":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(max_depth=1, criterion='mse', n_estimators=100)\nrfRegModel = rf.fit(X_train, y_train)\nrfPrediction = rfRegModel.predict(X_test)\nprint('R2 value', r2_score(y_train, rfRegModel.predict(X_train)))\nprint('Accuracy', 100-(np.mean((np.abs(y_test-rfPrediction)\/y_test))*100))\n\nfeature_importances = pd.Series(rfRegModel.feature_importances_, index=Predictors)\nfeature_importances.nlargest(17).plot.barh()\n\nTestingData = pd.DataFrame(X_test, columns=Predictors)\nTestingData['Target'] = y_test\nTestingData['PredictedValue'] = rfPrediction\n#TestingData['APE'] = (np.abs(y_test-rfPrediction)\/y_test)*100\nTestingData.head()","ed6e6643":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(max_depth=1)\nadab = AdaBoostRegressor(n_estimators=100, base_estimator=dt, learning_rate=0.1)\nadabRegModel = adab.fit(X_train, y_train)\nadabPrediction = adabRegModel.predict(X_test)\nprint('R2 value', r2_score(y_train, adabRegModel.predict(X_train)))\nprint('Accuracy', 100-(np.mean((np.abs(y_test-adabPrediction)\/y_test))*100))\n\nfeature_importances = pd.Series(adabRegModel.feature_importances_, index=Predictors)\nfeature_importances.nlargest(17).plot.barh()\n\nTestingData = pd.DataFrame(X_test, columns=Predictors)\nTestingData['Target'] = y_test\nTestingData['PredictedValue'] = adabPrediction\n#TestingData['APE'] = (np.abs(y_test-rfPrediction)\/y_test)*100\nTestingData.head()","dea7a569":"from xgboost import XGBRegressor\nxgb = XGBRegressor(n_estimators=500, max_depth=7, learning_rate=0.2, booster='gbtree')\nxgbRegModel = xgb.fit(X_train, y_train)\nxgbPrediction = xgbRegModel.predict(X_test)\nprint('R2 value', r2_score(y_train, xgbRegModel.predict(X_train)))\nprint('Accuracy', 100-(np.mean((np.abs(y_test-xgbPrediction)\/y_test))*100))\n\nfeature_importances = pd.Series(xgbRegModel.feature_importances_, index=Predictors)\nfeature_importances.nlargest(17).plot.barh()\n\nTestingData = pd.DataFrame(X_test, columns=Predictors)\nTestingData['Target'] = y_test\nTestingData['PredictedValue'] = xgbPrediction\n#TestingData['APE'] = (np.abs(y_test-rfPrediction)\/y_test)*100\nTestingData.head()","80cc9856":"# Linear Regression\ndef LinearRegressionParams(X_train, y_train, X_test, y_test):\n    test_size_list = [0.2,0.25,0.3]\n    random_state_list = [42,775,687]\n    TrialNo = 0\n    for Test_size in test_size_list:\n        for Random_state in random_state_list:\n            TrialNo+=1\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_size, random_state = Random_state)\n            lr = LinearRegression()\n            lrRegModel = lr.fit(X_train, y_train)\n            lrPrediction = lrRegModel.predict(X_test)\n            print(TrialNo, 'Random_state', Random_state, '--> Test_size', Test_size, '--> Accuracy',100-(np.mean((np.abs(y_test-lrPrediction)\/y_test))*100))","d1066c49":"LinearRegressionParams(X_train, y_train, X_test, y_test)","9be4244b":"# AdaBoost\ndef AdaboostParams(X_train, y_train, X_test, y_test):\n    test_size_list = [0.2,0.25,0.3]\n    random_state_list = [42,775,687]\n    N_Estimators_list = [500, 550, 600]\n    TrialNo = 0\n    for Test_size in test_size_list:\n        for Random_state in random_state_list:\n            for N_Estimators in N_Estimators_list:\n                TrialNo+=1\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_size, random_state = Random_state)\n                adab = AdaBoostRegressor(n_estimators=N_Estimators, base_estimator=dt, learning_rate= 0.2)\n                adabRegModel = adab.fit(X_train, y_train)\n                adabPrediction = adabRegModel.predict(X_test)\n                Accuracy = 100-(np.mean((np.abs(y_test-adabPrediction)\/y_test))*100)\n                print(TrialNo, 'Random_state', Random_state,\n                      '--> Test_size', Test_size, 'n_estimators',N_Estimators, '--> Accuracy', Accuracy)","73201e31":"AdaboostParams(X_train, y_train, X_test, y_test)","d4fce112":"# Random Forest\ndef RandomForestParams(X_train, y_train, X_test, y_test):\n    test_size_list = [0.2,0.25,0.3]\n    random_state_list = [42,775,687]\n    N_Estimators_list = [500, 550, 600]\n    TrialNo = 0\n    for Test_size in test_size_list:\n        for Random_state in random_state_list:\n            for N_Estimators in N_Estimators_list:\n                TrialNo+=1\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_size, random_state = Random_state)\n                rf = RandomForestRegressor(max_depth=1, criterion='mse', n_estimators=N_Estimators)\n                rfRegModel = rf.fit(X_train, y_train)\n                rfPrediction = rfRegModel.predict(X_test)\n                Accuracy = 100-(np.mean((np.abs(y_test-rfPrediction)\/y_test))*100)\n                print(TrialNo, 'Random_state', Random_state,\n                      '--> Test_size', Test_size, 'n_estimators',N_Estimators, '--> Accuracy', Accuracy)","cc6af5f8":"RandomForestParams(X_train, y_train, X_test, y_test)","ed0e1ae1":"# Importing Layers and Models\nfrom keras.models import Sequential\nfrom keras.layers import Dense","3c6b1fe8":"model = Sequential()\nmodel.add(Dense(units = 5, input_dim = 17, kernel_initializer = 'normal', activation = 'relu'))\nmodel.add(Dense(units = 20, kernel_initializer = 'normal', activation = 'relu'))\nmodel.add(Dense(units = 1, kernel_initializer = 'normal'))\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')","96076dfe":"model.fit(X_train, y_train, verbose=1, batch_size=10, epochs=20)","1d1616ce":"def ANNBestParams(X_train, y_train, X_test, y_test):\n    test_size_list = [0.2,0.25,0.3]\n    Batch_size_list = [5,10,15]\n    Epochs_list = [10,50,100]\n    TrialNo = 0\n    for test_size in test_size_list:\n        for Batch_size in Batch_size_list:\n            for Epochs in Epochs_list:\n                TrialNo+=1\n                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 42)\n                model = Sequential()\n                model.add(Dense(units = 5, input_dim = 17, kernel_initializer = 'normal', activation = 'relu'))\n                model.add(Dense(units = 20, kernel_initializer = 'normal', activation = 'relu'))\n                model.add(Dense(units = 1, kernel_initializer = 'normal'))\n                model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n                model.fit(X_train, y_train, verbose=0, batch_size=Batch_size, epochs=Epochs)\n                Prediction = model.predict(X_test)\n                print(TrialNo, '--> Test_size', test_size, 'batch_size', Batch_size, 'epochs', Epochs,\n                      '--> Accuracy',100-(np.mean((np.abs(y_test-Prediction)\/y_test))*100))","751e354d":"ANNBestParams(X_train, y_train, X_test, y_test)","4e367291":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)","1eb4e662":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","abbdc3df":"model.fit(X_train, y_train, epochs=50, batch_size=15, verbose=0)","e65bb54d":"ANNPrediction = model.predict(X_test)\nTestingData = pd.DataFrame(X_test, columns=Predictors)\nTestingData['TARGET_deathRate'] = y_test\nTestingData['Predicted_deathRate'] = ANNPrediction\nTestingData.head()","389fd9c1":"100-(np.mean((np.abs(TestingData['TARGET_deathRate']-TestingData['Predicted_deathRate'])\/TestingData['TARGET_deathRate']))*100)","b7513cf3":"## Decision Tree","a25441ac":"## Choosing Predictors based on corr() value","e463e566":"## Finding best set of parameters using grid search","379e6e5a":"## Checking Distributions: Categorical","b9d8df43":"## Selecting Target and Predictor variable","398a80d5":"### Generating the model using best hyperparameters","4921e6c5":"## Splitting the data into training and testing","1f8ccabf":"## Checking The relationship: Continuous vs Categorical (Boxplot)","dcaf3919":"## Arranging the Target Variable","20dcdcf1":"## Mapping the object variable to Numeric: 'binnedInc'","40bbdc25":"### Generating the predictions on Testing Data","d8230a60":"## Checking The relationship: Continuous vs Categorical (Bar plot)","02bd43bf":"## Calculating the Accuracy","11ddcbfc":"## Choosing Continuous Cols depending on distribution","22403b3c":"## Treating Missing values","4ef798b5":"## Checking Distributions: Continuous","2e8e6197":"## Checking The relationship: Continuous vs Categorical (P-Value)","851b02b4":"## Finding best set of parameters using grid search","4168da05":"## Dropping unnecessary columns from the data","6b51ced1":"## Checking The relationship: Continuous vs Continuous","e16f6acb":"## Reading the data and removing duplicate values","43b5487d":"## XGBoost","f082e8b6":"## Linear Regression","9020a41a":"## Artificial Neural Network","76902b8d":"## Random Forest","c15f8462":"## Checking The relationship: Continuous vs Continuous (Scatter plot)","add3378e":"## Data Exploration","cab84ba5":"## Dropping Geography after doing data exploration","bd53ffc0":"## AdaBoost"}}