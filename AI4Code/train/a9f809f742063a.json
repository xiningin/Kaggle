{"cell_type":{"3264d26f":"code","43447c9a":"code","b58d9287":"code","8c1ad104":"code","e83d3ee4":"code","9b2742c8":"code","291ad45b":"code","56d03a7e":"code","67b1d714":"code","bf7cf119":"code","3d6492b4":"code","d953fb6a":"code","6c073dfc":"code","803e9607":"code","db730083":"code","866d67ae":"code","6aeb259c":"markdown","228bb178":"markdown","d849cde5":"markdown","6d8db40b":"markdown","3433338f":"markdown","16e0c4b9":"markdown","9243e2da":"markdown","4fabf249":"markdown","a239c20e":"markdown","0be6aa2a":"markdown","c4c007f9":"markdown","d2e63ec8":"markdown"},"source":{"3264d26f":"import gc\nimport glob\nimport os\nimport cv2\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport imageio as im\nimport keras\nfrom keras import models\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import np_utils\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nimport matplotlib\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.","43447c9a":"# load images dataset\ndef loadImagesData(glob_path):\n    images = []\n    names = []\n    for img_path in glob.glob(glob_path):\n        # load\/resize images with cv2\n        names.append(os.path.basename(img_path))\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        images.append(img) # already 32x32\n    return (images,names)\n# map of training label to list of images\ntrainData = {}\nnamesData = {}\nfor label in os.listdir('..\/input\/train\/'):\n    (images,names) = loadImagesData(f\"..\/input\/train\/{label}\/*.jpg\")\n    print(f\"..\/input\/train\/{label}\/*.jpg\")\n    trainData[label] = images\n    namesData[label] = names\nprint(\"train labels:\", \",\".join(trainData.keys()))\nprint(len(trainData['train']))\n# show some data\nplt.figure(figsize=(4,2))\ncolumns = 4\nfor i in range(0,8):\n    plt.subplot(8 \/ columns + 1, columns, i + 1)\n    plt.imshow(trainData['train'][i])\nplt.show()","b58d9287":"train_meta = pd.read_csv('..\/input\/train.csv')\nprint(train_meta.shape)\nprint(train_meta.has_cactus.value_counts())\n# lookup table of name to has_cactus\nlookupY = {}\nfor i in range(0,len(train_meta)):\n    row = train_meta.iloc[i,:]\n    lookupY[row.id] = row.has_cactus\ntrain_meta.head()","8c1ad104":"# build x\/y dataset\ntrainList = []\nmaxCount = 4364 # number of has_cactus = 0\ncounts = {'0':0,'1':0}\nfor (i,image) in enumerate(trainData['train']):\n    label = lookupY[namesData['train'][i]]\n    counts[str(label)] = 1 + counts[str(label)]\n    if counts[str(label)] < maxCount:\n        trainList.append({\n            'label': label,\n            'data': image\n        })\n# shuffle dataset\nrandom.shuffle(trainList)\n# dataframe and display\ntrain_df = pd.DataFrame(trainList)\ngc.collect()\nprint(train_df.shape)\nprint(train_df.label.value_counts())\ntrain_df.head()","e83d3ee4":"# encode training data\ndata_stack = np.stack(train_df['data'].values)\ndfloats = data_stack.astype(np.float)\nall_x = np.multiply(dfloats, 1.0 \/ 255.0) # np.array(train_df['data'].values, dtype=np.float) \/ 255.0\nprint(all_x.shape)\nprint(type(all_x))\nall_x[0,0,0,0]","9b2742c8":"all_y = np.array(train_df.label).astype(np.float)\nall_y[0:5]","291ad45b":"# split test\/training data\ntrain_x,test_x,train_y,test_y=train_test_split(all_x,all_y,test_size=0.2,random_state=7)\nprint(train_x.shape,test_x.shape)","56d03a7e":"# x,y and rotation data augmentation\ndatagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    rotation_range=60,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range=0.2, # zoom images\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=True)  # randomly flip images\ndatagen.fit(train_x)","67b1d714":"# create the network\nnum_filters = 8\ninput_shape = train_x.shape[1:]\noutput_shape = 1\n# model\nm = Sequential()\ndef tdsNet(m):\n    m.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n    m.add(Conv2D(16, kernel_size=3, activation='relu'))\n    m.add(Flatten())\n    m.add(Dropout(0.5)) # increases val_acc from 0.89 to 0.92, acc from 0.8932 to 0.8987\n#     m.add(BatchNormalization()) # val_acc falling from 0.89 to 0.8322\n    m.add(Dense(units = output_shape, activation='sigmoid'))\ntdsNet(m)\n# compile adam with decay and use binary_crossentropy for single category dataset\nm.compile(optimizer = 'nadam',\n          loss = 'binary_crossentropy', \n          metrics = ['accuracy'])\n# show summary\nm.summary()","bf7cf119":"# train model\nbatch_size = 32\nhistory = m.fit_generator(datagen.flow(train_x, train_y,\n                          batch_size=batch_size),\n                          steps_per_epoch= (train_x.shape[0] \/\/ batch_size),\n                          epochs = 4,\n                          validation_data=(test_x, test_y),\n                          workers=4)","3d6492b4":"# create the network\nnum_filters = 8\ninput_shape = train_x.shape[1:]\noutput_shape = 1\n# model\nm = Sequential()\n\ndef cnnNet(m):\n    # Architecture motivated by: https:\/\/medium.com\/@ksusorokina\/image-classification-with-convolutional-neural-networks-496815db12a8\n    # Old: CONV => RELU => CONV => RELU => POOL => CONV => RELU => CONV => RELU => POOL => FC\n    # New: CONV => RELU => CONV => RELU => CONV => RELU => POOL => CONV => RELU => POOL => FC\n    m.add(Conv2D(32, kernel_size=3, input_shape=input_shape)) # 30 # , activation='relu'\n    m.add(BatchNormalization())\n    m.add(Activation(\"relu\"))\n#     m.add(Dropout(0.25)) # remove 14.04 # add 1.04\n    \n#     m.add(MaxPooling2D(2,2)) # exluded 18.03\n    # Second Conv2D layer\n    m.add(Conv2D(32, kernel_size=3)) # 15 # , activation='relu'\n    m.add(BatchNormalization())\n    m.add(Activation(\"relu\"))\n#     m.add(MaxPooling2D(2,2)) # removed 13.04 # put back 30.03\n    m.add(Dropout(0.25)) # add 30.03\n    \n    # Third Conv2D layer\n    m.add(Conv2D(64, kernel_size=3)) # , activation='relu'\n    m.add(BatchNormalization())\n    m.add(Activation(\"relu\"))\n    m.add(Dropout(0.25)) # add 31.03\n    # m.add(MaxPooling2D(2,2)) # removed from here 30.03 - 00:23\n    \n    # Fourth Conv2D layer\n    m.add(Conv2D(64, kernel_size=3)) # change 6.04 # 128 # change 31.03 # 64 # , activation='relu'\n    m.add(BatchNormalization())\n    m.add(Activation(\"relu\"))\n    m.add(MaxPooling2D(2,2)) # add 13.04\n    m.add(Dropout(0.25)) # added 6.04 - VGG like\n    \n    ## VGG like\n    m.add(Conv2D(128, kernel_size=3)) # , activation='relu'\n    m.add(BatchNormalization())\n    m.add(Activation(\"relu\"))\n    m.add(Dropout(0.25)) # add 31.03\n    # m.add(MaxPooling2D(2,2)) # removed from here 30.03 - 00:23\n    \n    # Fourth Conv2D layer\n    m.add(Conv2D(128, kernel_size=3)) # change 6.04 # 128 # change 31.03 # 64 # , activation='relu'\n    m.add(BatchNormalization())\n    m.add(Activation(\"relu\"))\n    ## VGG like\n    \n    m.add(MaxPooling2D(2,2))\n    m.add(Dropout(0.25)) # add 21.03\n    \n    m.add(Flatten())\n    \n    # add 6.04\n#     m.add(Dense(256, activation='relu'))\n#     m.add(BatchNormalization())\n#     m.add(Dropout(0.5))\n    # add 6.04\n    \n    m.add(Dense(64, activation='relu')) # 128 # 7 # <7 stops working, but higher values do nothing\n    m.add(BatchNormalization())\n#     m.add(Flatten()) # moved two lines up 18.03\n    m.add(Dropout(0.5)) # makes no sense: make acc and val_acc lower # increases val_acc from 0.9404 to .., acc from 0.9226 to ..\n    m.add(Dense(units = output_shape, activation='sigmoid')) #\n\n'''\n# LeNet\ndef cnnNet(m):\n    m.add(Conv2D(20, 5, padding='same', input_shape=input_shape)) # size: 5\n    m.add(Activation('relu'))\n    m.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    \n    m.add(Conv2D(50, 5, padding='same')) # size: 5\n    m.add(Activation('relu'))\n    m.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    \n    m.add(Flatten())\n    m.add(Dense(500)) #\n    m.add(Activation('relu'))\n    \n    m.add(Dense(units = output_shape))\n    m.add(Activation(\"sigmoid\")) # softmax\n'''\n    \ncnnNet(m)\n# compile adam with decay and use binary_crossentropy for single category dataset\nm.compile(optimizer = 'nadam', # 'nadam',\n          loss = 'binary_crossentropy', \n          metrics = ['accuracy'])\n# show summary\nm.summary()","d953fb6a":"### train model\nbatch_size = 64 # 32\nhistory = m.fit_generator(datagen.flow(train_x, train_y,\n                          batch_size=batch_size),\n                          steps_per_epoch= (train_x.shape[0] \/\/ batch_size),\n                          epochs = 95, # 10, # 4,\n                          validation_data=(test_x, test_y),\n                          workers=4)","6c073dfc":"# build complete x\/y dataset\ntrainList = []\nfor (i,image) in enumerate(trainData['train']):\n    label = lookupY[namesData['train'][i]]\n    trainList.append({\n        'label': label,\n        'data': image\n    })\n# shuffle dataset\nrandom.shuffle(trainList)\n# dataframe and display\ntrain_df = pd.DataFrame(trainList)\ngc.collect()\n# encode training data\ndata_stack = np.stack(train_df['data'].values)\ndfloats = data_stack.astype(np.float)\nall_x = np.multiply(dfloats, 1.0 \/ 255.0)\nall_x.shape\nall_y = np.array(train_df.label).astype(np.float)\n# split test\/training data\ntrain_x,test_x,train_y,test_y=train_test_split(all_x,all_y,test_size=0.2,random_state=7)\nprint(train_x.shape,test_x.shape)","803e9607":"###### continue training model\nbatch_size = 128 # 64 # \nhistory = m.fit_generator(datagen.flow(train_x, train_y,\n                          batch_size=batch_size),\n                          steps_per_epoch= (train_x.shape[0] \/\/ batch_size),\n                          epochs = 95, # 10, # 4,\n                          validation_data=(test_x, test_y),\n                          workers=4)","db730083":"# check sample submission format\npd.read_csv('..\/input\/sample_submission.csv').head()","866d67ae":"# output predicted submission csv\n(test_images, test_names) = loadImagesData(f\"..\/input\/test\/test\/*.jpg\")\ndata_stack = np.stack(test_images)\ndfloats = data_stack.astype(np.float32)\nunknown_x = np.multiply(dfloats, 1.0 \/ 255.0)\n# predict\npredicted = np.ravel(m.predict(unknown_x))\nsubmission_df = pd.DataFrame({'id':test_names,'has_cactus':predicted})\nsubmission_df.to_csv('submission.csv', index=False)\nlen(submission_df)","6aeb259c":"Here I write the function for loading and preprocessing the image data. There's only one target category in this dataset so I show the first 8 images. ","228bb178":"I'm basing this kaggle on my previous [Plant Seedling - Simple CNN](https:\/\/www.kaggle.com\/masonblier\/plant-seedling-simple-cnn) kaggle notebook. ","d849cde5":"Encode x data as numpy stack","6d8db40b":"Finish training on the rest of the data","3433338f":"I found I could do slightly better and have fewer trainable parameters if I use max pooling layers and a dense layer at the end.","16e0c4b9":"Build a dataframe of all the x and y data. I then build a more even dataset of 50% 0 and 1 to help the training process.","9243e2da":"Since we use binary_crossentropy, the y category data just needs to be made as floats","4fabf249":"Checking out the train.csv data, use value_counts to check relative number of 0 and 1 has_cactus values","a239c20e":"Output predictions file","0be6aa2a":"Starting with the simple stacked 3x3 conv net from Towards Data Science","c4c007f9":"Here I define the data augmenter. I use x,y and rotation as the images were taken from aerial and thus can vary in these ways.","d2e63ec8":"Make the training\/validation split to measure training accuracy"}}