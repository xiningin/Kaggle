{"cell_type":{"3e3a9ecd":"code","caad6329":"code","8dd328ea":"code","537101ef":"code","dc8e36c9":"code","ccc02cf0":"code","6bc8692a":"code","067f83c0":"code","d99e40f0":"code","e15e74ee":"code","87ec76b8":"code","d961cdb3":"code","28116976":"code","b87e1633":"markdown","a77b59f0":"markdown","99a24188":"markdown","1106d725":"markdown","ebbd0eba":"markdown","b070c09c":"markdown","eb2825cd":"markdown","b7242f29":"markdown","e1cc9b25":"markdown","e4f3b05b":"markdown","9937c43d":"markdown","c37321bd":"markdown","bff68bc0":"markdown","5958c8b1":"markdown","9fe63d84":"markdown","04f9175d":"markdown","cd710a5d":"markdown","ab2bbaf8":"markdown","99e19f35":"markdown","8196894e":"markdown","83bddc99":"markdown"},"source":{"3e3a9ecd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for plots\nimport seaborn as sns\n%matplotlib inline\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","caad6329":"print(os.listdir(\"..\/input\"))\ndata = pd.read_csv('..\/input\/horse.csv')\ndata.head()","8dd328ea":"print(\"Shape of data (samples, features): \",data.shape)","537101ef":"data.dtypes.value_counts()","dc8e36c9":"nan_per=data.isna().sum()\/len(data)*100\nplt.bar(range(len(nan_per)),nan_per)\nplt.xlabel('Features')\nplt.ylabel('% of NAN values')\nplt.plot([0, 25], [40,40], 'r--', lw=1)\nplt.xticks(list(range(len(data.columns))),list(data.columns.values),rotation='vertical')","ccc02cf0":"obj_columns=[]\nnonobj_columns=[]\nfor col in data.columns.values:\n    if data[col].dtype=='object':\n        obj_columns.append(col)\n    else:\n        nonobj_columns.append(col)\nprint(len(obj_columns),\" Object Columns are \\n\",obj_columns,'\\n')\nprint(len(nonobj_columns),\"Non-object columns are \\n\",nonobj_columns)\n\ndata_obj=data[obj_columns]\ndata_nonobj=data[nonobj_columns]","6bc8692a":"print(\"Data Size Before Numerical NAN Column(>40%) Removal :\",data_nonobj.shape)\nfor col in data_nonobj.columns.values:\n    if (pd.isna(data_nonobj[col]).sum())>0:\n        if pd.isna(data_nonobj[col]).sum() > (40\/100*len(data_nonobj)):\n            print(col,\"removed\")\n            data_nonobj=data_nonobj.drop([col], axis=1)\n        else:\n            data_nonobj[col]=data_nonobj[col].fillna(data_nonobj[col].median())\nprint(\"Data Size After Numerical NAN Column(>40%) Removal :\",data_nonobj.shape)","067f83c0":"print(\"Data Size Before Categorical NAN Column(>40%) Removal :\",data_obj.shape)\nfor col in data_obj.columns.values:\n    if (pd.isna(data_obj[col]).sum())>0:\n        if pd.isna(data_obj[col]).sum() > (40\/100*len(data_nonobj)):\n            print(col,\"removed\")\n            data_obj=data_obj.drop([col], axis=1)\n        else:\n            data_obj[col]=data_obj[col].fillna(data_obj[col].mode()[0])\nprint(\"Data Size After Categorical NAN Column(>40%) Removal :\",data_obj.shape)","d99e40f0":"for col in data_obj.columns.values:\n    data_obj[col]=data_obj[col].astype('category').cat.codes\ndata_merge=pd.concat([data_nonobj,data_obj],axis=1)\n\ntarget=data['outcome']\nprint(target.value_counts())\ntarget=data_merge['outcome']\nprint(target.value_counts())","e15e74ee":"train_corr=data_merge.corr()\nsns.heatmap(train_corr, vmax=0.8)\ncorr_values=train_corr['outcome'].sort_values(ascending=False)\ncorr_values=abs(corr_values).sort_values(ascending=False)\nprint(\"Correlation of mentioned features wrt outcome in ascending order\")\nprint(abs(corr_values).sort_values(ascending=False))","87ec76b8":"print(\"Data Size Before Correlated Column Removal :\",data_merge.shape)\n\nfor col in range(len(corr_values)):\n        if abs(corr_values[col]) < 0.1:\n            data_merge=data_merge.drop([corr_values.index[col]], axis=1)\n            print(corr_values.index[col],\"removed\")\nprint(\"Data Size After Correlated Column Removal :\",data_merge.shape)","d961cdb3":"#packed_cell_volume \ncol='packed_cell_volume'\nfig,(ax1,ax2)=plt.subplots(1,2, figsize=[20,10])\n\ny=data_merge[col][target==2]\nx=data_merge['outcome'][target==2]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\n\ny=data_merge[col][target==0]\nx=data_merge['outcome'][target==0]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\n\ny=data_merge[col][target==1]\nx=data_merge['outcome'][target==1]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\n\nplt.title(col)\nax1.legend(['lived','died','euthanized'])\nax2.legend(['lived','died','euthanized'])\nplt.show()","28116976":"#pulse \ncol='pulse'\nfig,(ax1,ax2)=plt.subplots(1,2, figsize=[20,10])\ny=data_merge[col][target==2]\nx=data_merge['outcome'][target==2]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\ny=data_merge[col][target==0]\nx=data_merge['outcome'][target==0]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\ny=data_merge[col][target==1]\nx=data_merge['outcome'][target==1]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\nplt.title(col)\nax1.legend(['lived','died','euthanized'])\nax2.legend(['lived','died','euthanized'])\nplt.show()","b87e1633":"It shall be noted that numeric **0,1,2** are equivalent to **died, euthanized, lived** for outcome.","a77b59f0":"## Inspecting Correlation between various Features and Outcome","99a24188":"## 2. Pulse & Outcome","1106d725":"The graph shows the number of Missing values in each feature, most of the features have less than 40% missing values. ","ebbd0eba":"\nTutorial Level : ***Beginner***\n\nData Cleaning is detection, fillup or removal of incomplete, inaccurate or vague data.\nThe tutorial below discuss the examination of data and performing necessary steps to clean data including \n\n* Dealing with Missing Data \n    *     Removal and Filling of Missing Data for Numerical and Categorical Features\n* Dividing Numerical and Categorical Data and Converting Categorical Data to Numeric Form\n* Inspecting Feature Correlation to study important features\n* Removal of less Corrlated Features\n* Plotting histogram and kde plots to get a butter understanding of data\n","b070c09c":"To better understand, how two features are correlated. Let us plot two most correlated (to outcome) features as histogram and kde plot.","eb2825cd":"## Converting Categorical Data to Numerical and Merging Them","b7242f29":"## Checking missing values for each feature","e1cc9b25":"Importing required libraries","e4f3b05b":"**Inspecting nature of data**, it can be seen that data consists of **17** categorical features and rest numerical out of **28**.","9937c43d":"## Shape and Nature of data","c37321bd":"Reading data from **CSV file** and saving as **Pandas' Dataframe**","bff68bc0":"Removing unwanted very less correlated features","5958c8b1":"## 1. Packed Cell Volume & Outcome","9fe63d84":"# Data Examination and Cleaning","04f9175d":"The plots show that after approx **60**, outcome is likely to be **died** which is then replaced by **euthanized** after **100**.  And after **150** , the probability of **died** being the outcome is highest.","cd710a5d":"Data being used here for data examination is 'Horse Colic Dataset' which predicts whether a horse can survive or not based on past medical conditions.\nData is available via following links.\n1.  [Kaggle](http:\/\/www.kaggle.com\/uciml\/horse-colic)\n2. [UCI Machine Learning Repository](http:\/\/archive.ics.uci.edu\/ml\/datasets\/Horse+Colic)","ab2bbaf8":"Correlation shows how strongly features are related to each other. We will be checking correlation of each column with outcome. \n* If correlation value is positive, fetaure is positively correlated to outcome. \n1. If correlation value is negative, feature is negatively correlated to outcome. \n1. If correlation value is 0, two columns are not correlated. \n\n    *  |value| > 0.7 : Hight correlated    \n    *  0.7 < |value| > 0.3 : Moderately correlated    \n    *  0.3 < |value| > 0 : Weakly correlated    ","99e19f35":"The plots show that after approx **50**, outcome is most likely to be **euthanized**, and after **60**, it is likely to be **died**. ","8196894e":"## Removing and Filling Missing Values in Numerical and Categorical Data \n1.     For columns with more than 40% NAN Value : Remove Columns\n2.     For columns with less than 40% NAN Value \n    *       ***For Numerical Data***: Replace NAN values with median value of that particular column\n    *      ** *For Categorical Data***: Replace NAN values with mode value of that particular column","83bddc99":"## Dividing Categorical and Numerical Data"}}