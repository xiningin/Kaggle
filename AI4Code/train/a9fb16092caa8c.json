{"cell_type":{"de36c613":"code","b3e282dd":"code","6ab255d5":"code","e96c235b":"code","f6fe07e0":"code","6c12044f":"code","ddf9a2ef":"markdown"},"source":{"de36c613":"import os\nfrom scipy.io import wavfile\nimport librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nrandom.seed(111)","b3e282dd":"def spec_augment(spec: np.ndarray, num_mask=2, \n                 freq_masking_max_percentage=0.15, time_masking_max_percentage=0.3):\n\n    spec = spec.copy()\n    for i in range(num_mask):\n        all_frames_num, all_freqs_num = spec.shape\n        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n        \n        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n        f0 = int(f0)\n        spec[:, f0:f0 + num_freqs_to_mask] = 0\n\n        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n        \n        num_frames_to_mask = int(time_percentage * all_frames_num)\n        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n        t0 = int(t0)\n        spec[t0:t0 + num_frames_to_mask, :] = 0\n    \n    return spec\n    ","6ab255d5":"audio_path = os.path.join(\"..\/input\/train_curated\/d7d25898.wav\")\nsr, audio = wavfile.read(audio_path)\n\nx = librosa.feature.melspectrogram(y=audio.astype(float), sr=sr, S=None, n_fft=512, hop_length=256, n_mels=40).T\nx = librosa.power_to_db(x, ref=np.max)","e96c235b":"plt.figure()\nplt.imshow(spec_augment(x),aspect= 'auto')\nplt.show()","f6fe07e0":"plt.figure()\nplt.imshow(spec_augment(x),aspect= 'auto')\nplt.show()","6c12044f":"plt.figure()\nplt.imshow(spec_augment(x),aspect= 'auto')\nplt.show()","ddf9a2ef":"This is my quick implementation of SpecAugment paper [here](https:\/\/arxiv.org\/abs\/1904.08779), without time warping. It works regardless of PyTorch or Tensorflow.\n\nYou set percentage of frames to mask so should work with long and short segments.\n\nLet's test it:"}}