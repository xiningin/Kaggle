{"cell_type":{"2a572c56":"code","33f09304":"code","2204e496":"code","c7633395":"code","e263b816":"code","5e7f0196":"code","85f3ddd1":"code","2d24602d":"code","937d4be3":"code","b9b8de19":"code","1e0cbe1b":"code","6ad6bc86":"code","313613ba":"code","fec67186":"code","4ca0e236":"code","20f5be09":"code","2c8a4a89":"code","433d5e56":"code","e50e5f2c":"code","e0a19f32":"code","34af43ee":"code","65a1c32f":"code","4ca3e121":"code","49a3f3b9":"code","c4c6df5e":"code","b3647cd6":"code","6506f213":"code","71b14142":"code","497a4075":"markdown","6556f9ac":"markdown","699289c7":"markdown","69223ccc":"markdown","72c43034":"markdown","9c1dad89":"markdown","02dc7e3e":"markdown","cd489a14":"markdown","65328399":"markdown","927f9d26":"markdown","142a2572":"markdown","f9813400":"markdown","07ae70a6":"markdown","9330c181":"markdown","d8000f05":"markdown","23abeab1":"markdown","c63428fb":"markdown"},"source":{"2a572c56":"!pip show keras","33f09304":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pickle\nimport csv\nimport os\n\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom keras.callbacks import Callback\nfrom keras.regularizers import l2\nfrom keras import optimizers\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras.applications.xception import Xception\nfrom keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))","2204e496":"# \u0412 \u0441\u0435\u0442\u0430\u043f \u0432\u044b\u043d\u043e\u0448\u0443 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438, \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0439 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c\n\nEPOCHS               = 10\nBATCH_SIZE           = 32\nLR                   = 1e-4\n\nCLASS_NUM            = 10\nIMG_SIZE             = 299 # \u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0434\u043b\u044f \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u0435\u0442\u0435\u0439\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/'\nPATH = \"..\/working\/car\/\"","c7633395":"os.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\n\nfrom tensorflow import set_random_seed\nset_random_seed(RANDOM_SEED)","e263b816":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","5e7f0196":"train_df.info()","85f3ddd1":"train_df.Category.value_counts()","2d24602d":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(DATA_PATH+f'train\/train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","937d4be3":"image = PIL.Image.open(DATA_PATH+'\/train\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","b9b8de19":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0447\u0435\u043d\u044c \u0432\u0430\u0436\u043d\u0430 \u043a\u043e\u0433\u0434\u0430 \u0443 \u043d\u0430\u0441 \u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u043a\u0430\u043a \u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435)\n# \u041f\u043e\u0438\u0433\u0440\u0430\u0439\u0441\u044f \u0442\u0443\u0442 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u044f\u0442\u044c \u0447\u0442\u043e \u043a \u0447\u0435\u043c\u0443. \n# \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0434\u043e\u043a\u0430 https:\/\/keras.io\/preprocessing\/image\/\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    rotation_range = 5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=0.1, # set validation split\n    horizontal_flip=False)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\n# \u0417\u0430\u0434\u0430\u043d\u0438\u0435 \u0434\u043b\u044f \u041f\u0440\u043e - \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0441\u0442\u043e\u0440\u043e\u043d\u043d\u0438\u0435 \u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0430\u0443\u0433\u043c\u0438\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439","1e0cbe1b":"# \"\u0417\u0430\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0435\u043c\" \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 generator\n\ntrain_generator = train_datagen.flow_from_directory(\n    DATA_PATH+'train\/train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    DATA_PATH+'train\/train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe(\n    dataframe=sample_submission,\n    directory=DATA_PATH+'test\/test_upload',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# \u043a\u0441\u0442\u0430\u0442\u0438, \u0442\u044b \u0437\u0430\u043c\u0435\u0442\u0438\u043b, \u0447\u0442\u043e \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0448\u0435\u043d\u0430 \u043c\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u043e\u0439 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 flow_from_dataframe? \n# \u041a\u0430\u043a \u0442\u044b \u0434\u0443\u043c\u0430\u0435\u0448\u044c, \u043f\u043e\u0447\u0435\u043c\u0443?","6ad6bc86":"# \u041a\u0441\u0442\u0430\u0442\u0438 \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0435\u0449\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0435\u0442\u0435\u0439...\nbase_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)","313613ba":"base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = input_shape)","fec67186":"base_model.summary()","4ca0e236":"# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u0443\u044e \"\u0433\u043e\u043b\u043e\u0432\u0443\"\n# \u0422\u0443\u0442 \u0442\u043e\u0436\u0435 \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0438\u0433\u0440\u0430\u0442\u044c\u0441\u044f, \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c Batch Normalization \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440.\n\n#x = base_model.output\n#x = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\n##x = Dense(256, activation='relu')(x)\n#x = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\n#predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\n#model = Model(inputs=base_model.input, outputs=predictions)\n#model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","20f5be09":"# Test 1\n\n#x = base_model.output\n#x = GlobalAveragePooling2D()(x)\n#x = BatchNormalization()(x)  # new\n# let's add a fully-connected layer\n#x = Dense(256, activation='relu')(x)\n#x = Dropout(0.25)(x)\n#x = BatchNormalization()(x)  # new\n# and a logistic layer -- let's say we have 10 classes\n#predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","2c8a4a89":"# Test 2\n\n#x = base_model.output\n#x = GlobalAveragePooling2D()(x)\n#x = BatchNormalization()(x)\n\n#x = Dense(256, activation='relu')(x)\n#x = Dropout(0.2)(x)\n#x = BatchNormalization()(x) \n\n#x = Dense(64, activation='relu')(x) \n#x = Dropout(0.3)(x)  \n#x = BatchNormalization()(x) \n\n#x = Dense(16, activation='relu')(x) \n#x = Dropout(0.4)(x)         \n#x = BatchNormalization()(x)  \n# and a logistic layer -- let's say we have 10 classes\n#predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\n#model = Model(inputs=base_model.input, outputs=predictions)\n#model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","433d5e56":"# Test 3\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\n\nx = Dense(256, activation='elu')(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x) \n\nx = Dense(64, activation='elu')(x) \nx = Dropout(0.3)(x)  \nx = BatchNormalization()(x) \n\nx = Dense(16, activation='elu')(x) \nx = Dropout(0.4)(x)         \nx = BatchNormalization()(x)  \n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","e50e5f2c":"model.summary()","e0a19f32":"# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u044e \u0434\u043e\u0431\u0430\u0432\u0442\u044c \u0435\u0449\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0438\u0437 https:\/\/keras.io\/callbacks\/\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_acc'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\n# \u0414\u043b\u044f \u043f\u0440\u043e - \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate\n# \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440:\n# https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6\n# http:\/\/teleported.in\/posts\/cyclic-learning-rate\/","34af43ee":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\n# \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c transfer learning \u0441 fine-tuning\n# \u0421\u043d\u0430\u0447\u0430\u043b\u0430 \u0437\u0430\u043c\u043e\u0440\u0430\u0436\u0438\u0432\u0430\u0435\u043c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438 \u043a\u0440\u043e\u043c\u0435 \u043d\u043e\u0432\u043e\u0439 \"\u0433\u043e\u043b\u043e\u0432\u044b\"\n# \u041f\u043e\u0442\u043e\u043c, \u043a\u043e\u0433\u0434\u0430 \u043c\u044b \u043d\u0430\u0443\u0447\u0438\u043b\u0438 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 \u0441\u043b\u043e\u0438 (\u0433\u043e\u043b\u043e\u0432\u0443) \u043f\u043e\u0434 \u043d\u043e\u0432\u0443\u044e \u0437\u0430\u0434\u0430\u0447\u0443, \u043c\u043e\u0436\u043d\u043e \u0440\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u0438\u0442\u044c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438 \u0438 \u043f\u0440\u043e\u0439\u0442\u0438\u0441\u044c \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u043c \u043b\u0435\u0440\u043d\u0438\u043d\u0433 \u0440\u0435\u0439\u0442\u043e\u043c","65a1c32f":"model.save('..\/working\/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","4ca3e121":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","49a3f3b9":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","c4c6df5e":"test_sub_generator.samples","b3647cd6":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","6506f213":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# \u0414\u043b\u044f \u041f\u0440\u043e - \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 TTA","71b14142":"submission.head()","497a4075":"# Submission","6556f9ac":"## \u0418\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e, \u043a \u043a\u0430\u043a\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0442\u043d\u0435\u0441\u0435\u0442 \u0432\u043e\u0442 \u044d\u0442\u043e\u0442 \u0430\u0432\u0442\u043e:\n![](http:\/\/kvu.su\/upload\/iblock\/e3a\/e3a32ed064fd71e4ce99b7f57d2de745.jpg)","699289c7":"### \u0423\u0436\u0435 \u0434\u043e\u0433\u0430\u0434\u0430\u043b\u0441\u044f \u0447\u0442\u043e \u043e\u0437\u043d\u0430\u0447\u0430\u044e\u0442 \u043a\u043b\u0430\u0441\u0441\u044b?\n### \u0422\u043e\u0433\u0434\u0430 \u043f\u0435\u0440\u0435\u0439\u0434\u0435\u043c \u043a \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0435 \u0434\u0430\u043d\u043d\u044b\u0445...\n![](http:\/\/admem.ru\/content\/images\/1391000424.jpg)","69223ccc":"# Setup","72c43034":"> \u042d\u0442\u043e \u043f\u0440\u0438\u043c\u0435\u0440 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u043e\u0439 \u0437\u0430\u0434\u0430\u0447\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c Keras. \u0412\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u044d\u0442\u043e\u0442 \u043a\u0435\u0440\u043d\u0430\u043b \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0438\u0445 \u0441\u0432\u043e\u0438\u0445 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0439 \u0438 \u044d\u043a\u0441\u043f\u0435\u0440\u0435\u043c\u0435\u043d\u0442\u043e\u0432.\n# Car classification\n![](http:\/\/img1.joyreactor.cc\/pics\/post\/\u0430\u0432\u0442\u043e\u043f\u0440\u043e\u043c-\u0432\u0430\u0437-\u043b\u0438\u043c\u0443\u0437\u0438\u043d-\u0432\u0430\u0442\u0435\u0440\u043c\u0430\u0440\u043a-351083.jpeg)\n\n### \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f - \u0431\u0435\u0440\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u043d\u0430 imagenet \u0441\u0435\u0442\u044c Xception \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u0434 \u043d\u0430\u0448\u0443 \u0437\u0430\u0434\u0430\u0447\u0443.\n\u041f\u043e \u0445\u043e\u0434\u0443 \u043a\u0435\u0440\u043d\u0435\u043b\u0430 \u044f \u0431\u0443\u0434\u0443 \u0434\u0430\u0432\u0430\u0442\u044c \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438 \u0438 \u043f\u043e\u0434\u0441\u043a\u0430\u0437\u043a\u0438 (\u0433\u0434\u0435 \u0447\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0434\u043a\u0440\u0443\u0442\u0438\u0442\u044c \u0438 \u0447\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0435\u0449\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c, \u0447\u0442\u043e\u0431 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0441\u043a\u043e\u0440).  \n\u041c\u043d\u043e\u0433\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u044b \u043d\u0435 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c ;)\n\n\u0423\u0434\u0430\u0447\u0438 \u0438 \u041f\u043e\u0435\u0445\u0430\u043b\u0438!","9c1dad89":"acc1 = .8432\n\nacc2 = .9027\n\nacc3 = .9111\n\nacc4 = .9169\n\n\n","02dc7e3e":"(H*W*D+1) * N\n\n(3*3*3+1) * 32","cd489a14":"acc1 = .895\n\nacc2 = .9388\n\nacc3 = .9414\n\nacc4 = .9452\n\nacc5 = .9459\n\nacc6 = .9369\n\nacc7 = .9369\n\nacc8 = .9439\n\nacc9 = .9427\n\nacc10 = .9497","65328399":"## Fit","927f9d26":"acc1 = .8963\n\nacc2 = .9169\n\nacc3 = .9143\n\nacc4 = .9079\n\nacc5 = .9246","142a2572":"# Data","f9813400":"\n\nacc1 = .5767\n\nacc2 = .7352\n\nacc3 = .8318\n\nacc4 = .8769\n\nacc5 = .9034\n\nacc6 = .9117\n\nacc7 = .9259\n\nacc8 = .9188\n\nacc9 = .9246\n\nacc10 = .9259","07ae70a6":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","9330c181":"# Model","d8000f05":"### Data augmentation","23abeab1":"### \u043f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u0441\u0435\u0442\u044c Xception","c63428fb":"### datagen"}}