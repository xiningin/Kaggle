{"cell_type":{"552275af":"code","350055ba":"code","74f820ae":"code","73394bdf":"code","aa204d6c":"code","8d0f5775":"code","604a48a8":"code","959982a0":"markdown","5f3368bd":"markdown","bbd9cc1e":"markdown","790deee5":"markdown","bc2c2880":"markdown","5e82b744":"markdown","6b144c2a":"markdown","91a4c334":"markdown","c3996867":"markdown","9c1662b2":"markdown"},"source":{"552275af":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.4 cannot be found (uncomment if needed). \n# !curl -X PURGE https:\/\/pypi.org\/simple\/kaggle-environments\n\n# ConnectX environment was defined in v0.1.4\n!pip install 'kaggle-environments>=0.1.4'","350055ba":"from kaggle_environments import evaluate, make\n\nenv = make(\"connectx\", debug=True)\nenv.render()","74f820ae":"# This agent random chooses a non-empty column.\ndef my_agent(observation, configuration):\n    from random import choice\n    return choice([c for c in range(configuration.columns) if observation.board[c] == 0])","73394bdf":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([my_agent, \"random\"])\nenv.render(mode=\"ipython\", width=500, height=450)","aa204d6c":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","8d0f5775":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) \/ sum(r[0] + r[1] for r in rewards)\n\n# Run multiple episodes to estimate it's performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\nprint(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","604a48a8":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","959982a0":"# ConnectX Getting Started_Submission","5f3368bd":"# Test your Agent","bbd9cc1e":"In this game, your objective is to get a certain number of your checkers in a row horizontally, vertically, or diagonally on the game board before your opponent. \n\nWhen it's your turn, you \u201cdrop\u201d one of your checkers into one of the columns at the top of the board. \n\nThen, let your opponent take their turn. This means each move may be trying to either win for you, or trying to stop your opponent from winning. \n\nThe default number is four-in-a-row, but we\u2019ll have other options to come soon.","790deee5":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https:\/\/kaggle.com\/c\/connectx\/submissions) to view your score and episodes being played.","bc2c2880":"# Write Submission File\n\n","5e82b744":"# Create ConnectX Environment","6b144c2a":"# Debug\/Train your Agent","91a4c334":"# Evaluate your Agent","c3996867":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy (more may be added later). ","9c1662b2":"# Install kaggle-environments"}}