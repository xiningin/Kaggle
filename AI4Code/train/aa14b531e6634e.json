{"cell_type":{"1e0af3e9":"code","1afc8301":"code","e5f88645":"code","f25f48b9":"code","3f38fcd1":"code","049705f7":"code","7d110b2b":"code","25d53e8e":"code","cc12e825":"code","37b95b09":"code","69cb0f7a":"code","3510a666":"code","b5b49fc8":"code","2d4c2c2c":"code","9a87e0fd":"code","5ed02fa5":"code","59c88f43":"code","653f61d3":"code","72570c52":"code","f3c42fe3":"code","2aa645f0":"code","b682b825":"code","d1d62f08":"code","d41d84ec":"code","05b45765":"code","dc9adc9a":"code","4db1d03e":"code","2006e21a":"code","dd63ca31":"code","ee4a5cfc":"code","6f9ed2a5":"code","37f8b8af":"code","dff5c0b0":"code","9888d99b":"code","220220ab":"code","d289dc94":"code","883b7975":"code","62500e5a":"code","749813ee":"code","3ddbf9f8":"code","25f5381d":"code","c918f3a5":"code","5f5b63f1":"markdown","b81bea29":"markdown","0f5bb9ad":"markdown","681b08c7":"markdown","acd70c38":"markdown","45a5c471":"markdown","249cb659":"markdown","097ffce0":"markdown","8d649b30":"markdown","c9126a1e":"markdown","36814192":"markdown","231c0f0f":"markdown","1635deaa":"markdown","5a297500":"markdown","61422544":"markdown","1c449bff":"markdown","8ad5e613":"markdown","daf709b4":"markdown","a6319df0":"markdown","7ee54bb9":"markdown","4da56260":"markdown","ac7e13bb":"markdown","d08f81b2":"markdown","d3d26362":"markdown","ea458b5c":"markdown","ded970f8":"markdown","d7a37986":"markdown","03891eaf":"markdown","55ea6d8f":"markdown","811e81d6":"markdown","b41c5a20":"markdown","ed0729ca":"markdown","761634af":"markdown","1ecf60ad":"markdown","805689fa":"markdown","a582ad57":"markdown","b7758902":"markdown","cd72a45f":"markdown","6e30be3a":"markdown","451f4d8e":"markdown","9af42ed6":"markdown","6356fdbc":"markdown","90e48cc9":"markdown","5f8f3452":"markdown","6b1ca09b":"markdown","a8e25b56":"markdown","611d4e2c":"markdown","37ad5280":"markdown","02a018ce":"markdown"},"source":{"1e0af3e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Ignore warnings\nimport warnings  \nwarnings.filterwarnings('ignore')","1afc8301":"data = pd.read_csv('\/kaggle\/input\/hotel-booking-demand\/hotel_bookings.csv')","e5f88645":"data.head()","f25f48b9":"data.info()","3f38fcd1":"data.describe().T","049705f7":"import matplotlib.pyplot as plt\nimport seaborn as sns","7d110b2b":"perc_missing_data = pd.DataFrame([data.isnull().sum(),data.isnull().sum()*100.0\/data.shape[0]]).T\nperc_missing_data.columns = ['No. of Missing Data', '% Missing Data']\nperc_missing_data","25d53e8e":"data['children'].value_counts()","cc12e825":"data['children'].fillna(0,inplace=True)","37b95b09":"perc_country_data = pd.DataFrame([data['country'].value_counts(),data['country'].value_counts()*100\/data.shape[0]]).T\nperc_country_data.columns = ['Count', '% Distribution']\nperc_country_data","69cb0f7a":"data['country'].fillna('PRT',inplace=True)","3510a666":"data.drop(['agent','company'],axis=1,inplace=True)","b5b49fc8":"perc_missing_data = pd.DataFrame([data.isnull().sum(),data.isnull().sum()*100.0\/data.shape[0]]).T\nperc_missing_data.columns = ['No. of Missing Data', '% Missing Data']\nperc_missing_data","2d4c2c2c":"plt.style.use('fivethirtyeight')","9a87e0fd":"plt.figure(figsize=(14,6))\nsns.countplot(x='hotel',data=data,hue='is_canceled',palette='pastel')\nplt.show()","5ed02fa5":"plt.figure(figsize=(14,6))\nsns.countplot(x='deposit_type',data=data,hue='is_canceled',palette='pastel')\nplt.show()","59c88f43":"data['arrival_date'] = data['arrival_date_year'].astype(str) + '-' + data['arrival_date_month'] + '-' + data['arrival_date_day_of_month'].astype(str)\ndata['arrival_date'] = data['arrival_date'].apply(pd.to_datetime)\ndata['reservation_status_date'] = data['reservation_status_date'].apply(pd.to_datetime)","653f61d3":"cancelled_data = data[data['reservation_status'] == 'Canceled']\ncancelled_data['canc_to_arrival_days'] = cancelled_data['arrival_date'] - cancelled_data['reservation_status_date']\ncancelled_data['canc_to_arrival_days'] = cancelled_data['canc_to_arrival_days'].dt.days","72570c52":"plt.figure(figsize=(14,6))\nsns.distplot(cancelled_data['canc_to_arrival_days'])\nplt.show()","f3c42fe3":"print('Percentage of cancellations that are within a week of arrival: ', \n      (cancelled_data[cancelled_data['canc_to_arrival_days']<=7]['canc_to_arrival_days'].count()*100\/cancelled_data['canc_to_arrival_days'].count()).round(2), '%')","2aa645f0":"month_sorted = ['January','February','March','April','May','June','July','August','September','October','November','December']\nplt.figure(figsize=(14,6))\nsns.countplot(data['arrival_date_month'], palette='pastel', order = month_sorted)\nplt.xticks(rotation = 90)\nplt.show()","b682b825":"perc_monthly_canc = pd.DataFrame(data[data['is_canceled'] == 1]['arrival_date_month'].value_counts() * 100 \/ data['arrival_date_month'].value_counts())\nperc_monthly_canc.reset_index()\nplt.figure(figsize=(14,6))\nsns.barplot(x=perc_monthly_canc.index,y='arrival_date_month',data=perc_monthly_canc, order=month_sorted, palette='pastel')\nplt.xticks(rotation = 90)\nplt.ylabel('% cancellation per month')\nplt.show()","d1d62f08":"plt.figure(figsize=(8,8))\nexplode = [0.005] * len(cancelled_data['market_segment'].unique())\ncolors = ['royalblue','orange','y','darkgreen','gray','purple','red','lightblue']\nplt.pie(cancelled_data['market_segment'].value_counts(),\n       autopct = '%.1f%%',\n       explode = explode,\n       colors = colors)\nplt.legend(cancelled_data['market_segment'].unique(), bbox_to_anchor=(-0.1, 1.),\n           fontsize=14)\nplt.title('Market Segment vs Cancelled Bookings')\nplt.tight_layout()\nplt.show()","d41d84ec":"plt.figure(figsize=(10,8))\ndata.corr()['is_canceled'].sort_values()[:-1].plot(kind='bar')\nplt.show()","05b45765":"plt.figure(figsize=(16,12))\nplt.subplot(221)\nsns.countplot(data['meal'], hue=data['is_canceled'])\nplt.xlabel('Meal Type')\nplt.subplot(222)\nsns.countplot(data['customer_type'], hue=data['is_canceled'])\nplt.xlabel('Customer Type')\nplt.subplot(223)\nsns.countplot(data['reserved_room_type'], hue=data['is_canceled'])\nplt.xlabel('Reserved Room Type')\nplt.subplot(224)\nsns.countplot(data['reservation_status'], hue=data['is_canceled'])\nplt.xlabel('Reservation Status')\nplt.show()","dc9adc9a":"data = data.drop(['meal','country','reserved_room_type','assigned_room_type','deposit_type','reservation_status','reservation_status_date','arrival_date'], axis=1)\ndata = pd.concat([data, \n                 pd.get_dummies(data['hotel'], drop_first=True), \n                 pd.get_dummies(data['arrival_date_month'], drop_first=True), \n                 pd.get_dummies(data['market_segment'], drop_first=True),\n                 pd.get_dummies(data['distribution_channel'], drop_first=True),\n                 pd.get_dummies(data['customer_type'], drop_first=True)\n                 ], axis=1)\ndata = data.drop(['hotel','arrival_date_month','market_segment','distribution_channel','customer_type'], axis=1)","4db1d03e":"data.info()","2006e21a":"plt.figure(figsize=(16,8))\ndata.corr()['is_canceled'].sort_values()[:-1].plot(kind='bar')\nplt.show()","dd63ca31":"X = data.iloc[:, 1:].values\ny = data.iloc[:, 0].values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","ee4a5cfc":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","6f9ed2a5":"# Empty dictionary of model accuracy results\nmodel_accuracy_results = {}\n\n# Function for calculating accuracy from confusion matrix\nfrom sklearn.metrics import confusion_matrix\ndef model_accuracy(y_test, y_pred):\n    cm = confusion_matrix(y_test, y_pred)\n    accuracy = ((cm[0,0] + cm [1,1]) * 100 \/ len(y_test)).round(2)\n    return accuracy","37f8b8af":"# Baseline model\n(unique, counts) = np.unique(y_train, return_counts=True)\nif counts[0]  > counts[1]:\n    idx = 0\nelse:\n    idx = 1\n\n# Applying baseline results to y_pred\nif idx == 0:\n    y_pred = np.zeros(y_test.shape)\nelse:\n    y_pred = np.ones(y_test.shape)\n\n# Computing accuracy\nmodel_accuracy_results['Baseline'] = model_accuracy(y_test, y_pred)","dff5c0b0":"# Fit and train\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0, max_iter=250)\nclassifier.fit(X_train, y_train)\n\n# Predict\ny_pred = classifier.predict(X_test)\n\n# Computing accuracy\nmodel_accuracy_results['LogisticRegression'] = model_accuracy(y_test, y_pred)","9888d99b":"# Fit and train\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 10)\nclassifier.fit(X_train,y_train)\n\n# Predict\ny_pred = classifier.predict(X_test)\n\n# Computing accuracy\nmodel_accuracy_results['KNearestNeighbors'] = model_accuracy(y_test, y_pred)","220220ab":"# Fit and train\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state=0)\nclassifier.fit(X_train,y_train)\n\n# Predict\ny_pred = classifier.predict(X_test)\n\n# Computing accuracy\nmodel_accuracy_results['SVM'] = model_accuracy(y_test, y_pred)","d289dc94":"# Fit and train\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\nclassifier.fit(X_train,y_train)\n\n# Predict\ny_pred = classifier.predict(X_test)\n\n# Computing accuracy\nmodel_accuracy_results['RandomForest'] = model_accuracy(y_test, y_pred)","883b7975":"df_model_accuracies = pd.DataFrame(list(model_accuracy_results.values()), index=model_accuracy_results.keys(), columns=['Accuracy'])\ndf_model_accuracies\n","62500e5a":"# Grid Search\nfrom sklearn.model_selection import GridSearchCV\nparameters = [{'n_estimators': [10,25,50,100,500] , 'criterion': ['entropy', 'gini']}]\nrandomforestclassifier = RandomForestClassifier()\ngrid_search = GridSearchCV(estimator = randomforestclassifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           n_jobs = -1)\ngrid_search.fit(X_train, y_train)","749813ee":"print('Best Score: ', grid_search.best_score_.round(2))\nprint('Best Parameters: ', grid_search.best_params_)","3ddbf9f8":"# Fit and train\noptimized_classifier = RandomForestClassifier(n_estimators=500, criterion='entropy', random_state=0)\noptimized_classifier.fit(X_train,y_train)\n\n# Predict\ny_pred = optimized_classifier.predict(X_test)\n\n# Computing accuracy\nmodel_accuracy_results['OptimizedRandomForest'] = model_accuracy(y_test, y_pred)\n","25f5381d":"df_model_accuracies = pd.DataFrame(list(model_accuracy_results.values()), index=model_accuracy_results.keys(), columns=['Accuracy'])\ndf_model_accuracies","c918f3a5":"orf_cm = confusion_matrix(y_test, optimized_classifier.predict(X_test))\n\nnames = ['True Neg','False Pos','False Neg','True Pos'] # list of descriptions for each group\nvalues = [value for value in orf_cm.flatten()] # list of values for each group\npercentages = [str(perc.round(2))+'%' for perc in orf_cm.flatten()*100\/np.sum(orf_cm)] # list of percentages for each group\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(names,values,percentages)] # zip them into list of strings as labels\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(orf_cm, annot=labels, fmt='', cmap='binary')","5f5b63f1":"## Let's look at missing data","b81bea29":"#### Results of grid search","0f5bb9ad":"#### 40.7% of bookings are from Portugal. Only 0.4% is missing information. We will fill the missing rows of country as Portugal since the distribution will not change by much and we still get to preserve data and discard the row.","681b08c7":"#### Let's visualize the confusion matrix of the OptimizedRandomForest Model","acd70c38":"#### Split into training and test sets","45a5c471":"#### 13% of agent ID and 94% of company ID is missing. It is possible to dive deep into the details of the dataset to find a correlation of missing information in agent ID and company ID vs other other features like market segment, distribution channel etc; For example most direct bookings may not have an agent ID or company ID and the information is probably null. It is therefore possible to fill these missing values based on other features however for simplicity, we will drop both the columns. ","249cb659":"#### 12% of cancellations happen less than a week. There is huge benefits to predicting if a customer will cancel a booking so the hotel can adequately prepare for it. ","097ffce0":"#### We will choose the RandomForest Model as it gives the best accuracy. Now we will tune the hyper parameters on the random forest model using grid search and retrain the model to see if performance improved","8d649b30":"#### Let us again look at the correlation of the target variable with rest of the selected features after dummy variable conversion","c9126a1e":"#### RandomForest with new parameters","36814192":"### Let's visualize distribution of days from cancellation to arrival","231c0f0f":"### Let's look at distribution of hotel bookings and separate them by their cancellation status","1635deaa":"### We've completed predicting cancellations with an accuracy of 86%. Please upvote and leave comments. Thanks for your time.","5a297500":"#### About 25% of resort hotel bookings have been cancelled and about 40% of city hotel bookings have been cancelled. These numbers are high and have potential implications in revenue for the hotels","61422544":"# DATA VISUALIZATION","1c449bff":"#### It's clear that meal type and reserved room type don't have bookings evenly distributed. In both the features, bookings heavily favour one category and hence we will drop both columns. We will drop deposit type(visualized previously) for the same reasons\n\n#### We will keep customer type feature and convert to dummy variables.\n\n#### The reservation status feature is basically the target variable. To avoid data leakage we will drop this column as well.\n\n#### There are too many countries and will add a lot of dimension when converted to dummy variables. We will drop this column as well. (NOTE - we could have dropped this at the filling missing data stage itself)\n\n#### We will also drop all the date features.\n\n#### We will convert the other categorical features which we've visualized in the previous sections based on intuition.","8ad5e613":"#### Create a new dataframe for cancelled bookings called cancelled_data. Add a new column called canc_to_arrival_days that is the difference between cancellation date and arrival date","daf709b4":"#### There is not a significant difference in the percentage cancellations between months however the lowest demand months have the lowest % cancellations and the highest demand months have the highest % cancellations. The hotels will accept this trend as filling in cancelled rooms during peak season becomes easier. ","a6319df0":"### Let's now look at market segment vs cancellation","7ee54bb9":"#### Functions and Variable Assignments","4da56260":"#### So far we've looked at some features and plotted their general distribution and how they behave against cancellation. Now let's look at the entire feature set and see how they correlate with cancellation status. This step is going to help us select features for our model","ac7e13bb":"### Let's look at deposit type vs cancellation status","d08f81b2":"#### Let's see at what times of the year do we have the highest bookings","d3d26362":"#### Most bookings had no children and hence we will fill the missing rows for children with value 0","ea458b5c":"#### It looks like the summer months May-August have the highest demand. The winter months November-February have the lowest demand. Let's now see which months have the highest cancellations as our target is cancellations.","ded970f8":"#### Verifying no categorical variables exist in the dataset","d7a37986":"## CONVERTING CATEGORICAL COLUMNS TO DUMMY VARIABLES AND DROPPING UNNECESSARY COLUMNS","03891eaf":"#### Logistic Regression","55ea6d8f":"#### 0.4% of rows have missing information for country. Let's look at distribution of country to fill missing information","811e81d6":"#### We first need to create a new column called arrival_date that combines arrival date year, month and date. We then compare arrival_date to cancellation date to find out how the cancellation happens. Cancellation date can be identified from reservation_status_date for reservation_status = Cancelled","b41c5a20":"#### About 30k bookings of deposit type 'No Deposit' were cancelled. These numbers are huge if the hotels were not able to replace the cancelled bookings in time. It's a significant loss for the hotel. But in the next section, we will look at date of cancellation vs date of arrival to understand the impact of cancellation and how much time the hotel had to prepare for cancellations.\n\n#### Also it is interesting to note that non-refundable deposits had more cancellation than refundable deposits. Logically one would have assumed that refundable deposits have more cancellation as hotel rates are usually higher for refundable deposit type rooms and customers pay more in anticipation of cancellation","ed0729ca":"### K Nearest Neighbors","761634af":"### Let's visualize other features to have an idea about the dataset ","1ecf60ad":"#### Let's confirm all missing data have been handled","805689fa":"## MODELING","a582ad57":"#### 0.003% of rows have missing information for children. Let's look at distribution of children to fill missing information","b7758902":"#### SVM","cd72a45f":"# This is my first Kaggle project. I will do some EDA on the dataset. I will then do some feature selection, apply different models, tune and select the best one and predict cancellation. I am new to this field and Kaggle so I appreciate if you can leave comments and suggestions. Thanks ","6e30be3a":"#### Feature Scaling","451f4d8e":"#### The correlation happens only with numerical values. Let's look at distribution of some of categorical variables that we've not covered already in the previous sections to decide which ones out of those we want to carry over for the model.","9af42ed6":"#### We will choose the best parameters and re-train the model with the new parameters and compare against the original RandomForest classifier accuracy result","6356fdbc":"#### Assuming the hotel can sufficiently replace the cancelled reservation in a week, we are only interested in cancellations that happen less than a week to arrival date which bear a financial cost to the hotels","90e48cc9":"#### Baseline Model - We will take the class that has most observations in the training set and applying it as the predicted result and compute accuracy","5f8f3452":"We will use all features left to build our model. The following are the steps we will take to build our model.\n\n1. Split into training and test sets\n2. Apply feature scaling\n3. Baseline model\n4. Train and predict multiple models - LogisticRegression, KNearestNeighbors, SVM, RandomForest\n5. Compare against baseline model and choose the best model using accuracy\n6. Use grid search to tune hyperparameters\n7. Retrain model using chosen hyperparameters\n8. Predict ","6b1ca09b":"#### About 65% of the cancelled bookings are by travel agents or tour operators","a8e25b56":"#### RandomForest","611d4e2c":"#### Let's visualize the model accuracy results again with OptimizedRandomForest included","37ad5280":"#### Let's visualize the accuracy results","02a018ce":"### Date of Cancellation vs Date of Arrival"}}