{"cell_type":{"aef14c7b":"code","37050111":"code","13970c78":"code","d8cd2897":"code","df20c87a":"code","d23fb123":"code","81f7d85f":"code","516c58f4":"code","0799614c":"code","c026ea3e":"code","f32bf203":"code","d3f135d1":"code","adc512ee":"code","de7a97c7":"code","6f1143ef":"code","2b8208f2":"code","012f8917":"code","73cf18d0":"code","4c2dc809":"code","da00c1eb":"code","69eb0ad7":"code","5e4dba31":"code","ac9e45ca":"code","e2b57e13":"code","08d40ee2":"code","1b9cd775":"code","4a1d410f":"code","c7e8ad3c":"code","9c8896c7":"code","d739c805":"code","7a003bdb":"code","da604b20":"code","40d20d67":"code","fbb75251":"code","893750a9":"code","c1c30b6b":"code","e7b4324b":"code","212f0b37":"code","30964549":"code","e3b5424f":"code","b24b5501":"markdown","1e4328ed":"markdown","cb51758e":"markdown","c6777534":"markdown","fc08d62c":"markdown","7f377b95":"markdown","155235b5":"markdown","54ff0733":"markdown","b77cf021":"markdown","b85d8d56":"markdown","7618c259":"markdown","b80061b5":"markdown","868c97a4":"markdown"},"source":{"aef14c7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","37050111":"from scipy import stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nimport statsmodels.api as sm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\nfrom datetime import date, datetime, timedelta\nfrom time import time\nfrom random import randint\nfrom dateutil.relativedelta import relativedelta\n\nimport sys\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.float_format = '{:.2f}'.format","13970c78":"item_categories = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nitems = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nshops = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")","d8cd2897":"train.head(3)","df20c87a":"test.head(3)","d23fb123":"msno.matrix(train)","81f7d85f":"train.isna().sum()","516c58f4":"test.isna().sum()","0799614c":"train.dtypes","c026ea3e":"train.date[4]","f32bf203":"def date_formatter(x):\n    year = x[-4:]\n    month = x[3:5]\n    day = x[:2]\n    stf = year + '-' + month + '-' + day\n    return stf\n\ntrain['date'] = train['date'].apply(date_formatter)\ntrain['date'] = pd.to_datetime(train['date'])\ntrain.head(3)","d3f135d1":"train.groupby('date_block_num')['item_cnt_day'].sum().plot(figsize=(16,9), color='royalblue', title=\"Monthly Sales Volume\", linewidth=3)","adc512ee":"train.groupby('shop_id')['item_cnt_day'].sum().plot(kind='bar', figsize=(16,9), color='royalblue', edgecolor='k', title=\"Sales Volume by shops\")","de7a97c7":"train.groupby('date_block_num')['shop_id'].unique().apply(len).plot(figsize=(16,9), color='maroon', title=\"# shops each month\")","6f1143ef":"len(train['item_id'].unique())\n\n# Many items on shelf","2b8208f2":"len(train['shop_id'].unique())","012f8917":"len(train['date_block_num'].unique())","73cf18d0":"monthly = train.groupby('date_block_num')['item_cnt_day'].sum()\n\nres = sm.tsa.seasonal_decompose(monthly, freq=12, model='multiplicative')\nres.plot()\nplt.show()","4c2dc809":"res = sm.tsa.seasonal_decompose(monthly, freq=12, model='additive')\nres.plot()\nplt.show()","da00c1eb":"res = sm.tsa.seasonal_decompose(monthly, freq=12, model='multiplicative')\nres.trend[-12:]","69eb0ad7":"res.seasonal[-12:]","5e4dba31":"res.resid.mean()","ac9e45ca":"trends = res.trend.dropna()\ntrends","e2b57e13":"deltas = [trends[i+1]-trends[i] for i in range(trends.index.min(), trends.index.max())]\ndeltas","08d40ee2":"e_delta = np.array(deltas).mean()\n# 34th date_block_num is our target\ne_trend = trends[trends.index.max()]+e_delta*7\ne_season = res.seasonal[res.seasonal.index.max()-11]\ne_value = e_trend*e_season\ne_value","1b9cd775":"res = sm.tsa.seasonal_decompose(monthly, freq=12, model='additive')\nres.resid.mean()","4a1d410f":"e_delta = np.array(deltas).mean()\n# 34th date_block_num is our target\ne_trend = trends[trends.index.max()]+e_delta*7\ne_season = res.seasonal[res.seasonal.index.max()-11]\ne_value = e_trend + e_season + res.resid.mean()\ne_value","c7e8ad3c":"from fbprophet import Prophet\nmodel = Prophet(yearly_seasonality=True)\ndf = pd.DataFrame(monthly).reset_index().rename(columns={'date_block_num': 'ds', 'item_cnt_day': 'y'})\nfor i in range(df.ds.max()+1):\n    in_date = date(2013, 1, 1) + relativedelta(months=i)\n    df['ds'] = df['ds'].replace(i, in_date)\nmodel.fit(df)\nfuture = model.make_future_dataframe(periods=1, freq='MS')\nforecast = model.predict(future)\nforecast","9c8896c7":"e_value = forecast[forecast['ds']=='2015-11-01']['yhat']\ne_value.values[0]","d739c805":"ct = train[train['shop_id'].isin(test['shop_id'])]\nct = ct[ct['date_block_num']>=22]\nshop_ratio = ct.groupby('shop_id')['item_cnt_day'].sum()\nitem_ratio = ct.groupby(['shop_id', 'item_id'])['item_cnt_day'].sum()","7a003bdb":"agg = shop_ratio.sum()\nshop = pd.DataFrame(shop_ratio)\nshop['agg'] = np.ones(len(shop))*agg\nshop['ratio'] = shop['item_cnt_day'] \/ shop['agg']\nshop.head()","da604b20":"yhat = e_value.values[0]\nshop['yhat'] = np.ones(len(shop))*yhat\nshop['pred'] = shop['yhat']*shop['ratio']\nshop.tail()","40d20d67":"item = pd.DataFrame(item_ratio).reset_index()\nitem = item.merge(shop.reset_index()[['shop_id', 'item_cnt_day']].rename(columns={'item_cnt_day': 'agg'}), how='left', on='shop_id')\nitem.head()\n# item = item.merge(shop.reset_index()[['shop_id', 'pred']], how='left', on='shop_id')","fbb75251":"shop.head(3)","893750a9":"item['rate'] = item['item_cnt_day'] \/ item['agg']\nitem = item.merge(shop.reset_index()[['shop_id', 'pred']], how='left', on='shop_id')\nitem['cnt_pred'] = item['rate']*item['pred']\nitem.head()","c1c30b6b":"sample.head(2)","e7b4324b":"test.head(2)","212f0b37":"sub = test.merge(item[['shop_id', 'item_id', 'cnt_pred']], how='left', on=['shop_id', 'item_id']).rename(columns={'cnt_pred': 'item_cnt_month'})\nsub.head()","30964549":"submission = sub.fillna(0)[['ID', 'item_cnt_month']]\nsubmission.to_csv('submission3.csv', index=False)","e3b5424f":"submission.head(5)","b24b5501":"We can't tell just by looking whether multiplicative model assumption or additive assumption fits better with this dataset. We'll try them both","1e4328ed":"This is our agg forecast assuming the multiplicative model. Let's try the additive","cb51758e":"# Modeling\n## 1. Statistics Approach","c6777534":"## 2. Dtypes and Formatting","fc08d62c":"## 2. Machine Learning Approach","7f377b95":"# 4. Making Predictions for Submission","155235b5":"It's only a slight difference, but it can be significant after all","54ff0733":"This value lies somewhere inbetween the two values we got from multiplicative and additive seasonal decompose. So we could say all these results point at similar directions.","b77cf021":"Findings So far:\n1. Decreasing Trend\n2. 12-month seasonality\n3. Large Variation across shops\n4. Number of shops on business vary time to time","b85d8d56":"# Preprocessing\n\n## 1. Missing Values","7618c259":"# Exploratory Data Analysis\n## 1. Trend, Seasonality","b80061b5":"## 2. Other Fact Checks","868c97a4":"No Missing Values! Lucky us :)"}}