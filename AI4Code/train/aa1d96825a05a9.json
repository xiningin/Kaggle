{"cell_type":{"8fbb1a54":"code","ab75cc5e":"code","d9be92a8":"code","01526056":"code","9ebb54c5":"code","31569297":"code","8ea5f0f3":"code","bf50fc07":"code","7b73dd7b":"code","dde21de7":"code","ab016e78":"code","8d671bca":"code","dbb59e98":"code","4dfbb806":"code","f2549b6e":"code","00665f31":"code","91f0f75c":"code","9838ae8d":"code","fa93681e":"code","52815aaa":"code","56785e83":"code","08690f33":"code","a467a45e":"code","d6a02ee5":"code","0ed32083":"code","f51edabf":"code","4ec887cf":"code","889cfba2":"code","4e11eae0":"code","98eef557":"code","d00d1091":"markdown"},"source":{"8fbb1a54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab75cc5e":"import pandas as pd\nimport numpy as np\n","d9be92a8":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.head()","01526056":"df.info()","9ebb54c5":"df.describe()","31569297":"df.isnull().sum()","8ea5f0f3":"df1 = df.drop(columns = {'Cabin' ,'Name'})\ndf1.head()","bf50fc07":"df1.isnull().sum()","7b73dd7b":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(df1[['Age']])\ndf1['Age'] = imputer.transform(df1[['Age']])","dde21de7":"df1.info()","ab016e78":"df1.dropna(axis=0,inplace=True)\ndf1.info()","8d671bca":"#'Sex' , 'Ticket' , 'Embarked'\ndf1['Ticket'].nunique()       #Ticket need to be dropped as their are too many unique values","dbb59e98":" df1['Sex'].nunique()  ","4dfbb806":"df1['Embarked'].nunique()","f2549b6e":"#OneHot Encode Sex and Embarked columns\ndf2 = pd.get_dummies(df1[['Sex','Embarked']])\ndf2.head()","00665f31":"df1 = df1.join(df2)\ndf1.head()","91f0f75c":"df1.drop(columns={'Sex' , 'Embarked' , 'Ticket'}, axis=1 , inplace=True)\ndf1.info()","9838ae8d":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,8), dpi= 80)\nsns.heatmap(df1.corr(), cmap='RdYlGn', center=0)\n\n# Decorations\nplt.title('Correlogram of mtcars', fontsize=22)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","fa93681e":"y = df1['Survived']\nX = df1.drop(columns={'Survived'}, axis=1)\nX.head()","52815aaa":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test.info()","56785e83":"df_test.drop(columns={'Cabin','Name','Ticket'},axis=1,inplace=True)\ndf_test.info()","08690f33":"df_test2 = pd.get_dummies(df_test[['Sex','Embarked']])\ndf_test2.head()\n\ndf_test = df_test.join(df_test2)\ndf_test.head()","a467a45e":"df_test.drop(columns={'Sex','Embarked'},axis=1,inplace=True)\ndf_test['Age'] = imputer.transform(df_test[['Age']])\ndf_test['Fare'] = imputer.transform(df_test[['Fare']])\n\n\ndf_test.info()","d6a02ee5":"#Submission Dataframe\nsub = pd.DataFrame(columns = ['PassengerId' , 'Survived'])\nsub['PassengerId'] = df_test['PassengerId'].astype(int)","0ed32083":"X.drop(columns = ['PassengerId'],axis=1  , inplace= True)","f51edabf":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(learning_rate=0.1, n_estimators=2000, max_depth=15,\n                        min_child_weight=0, gamma=0, subsample=0.45, colsample_bytree=1,\n                        objective='binary:logistic', nthread=4, scale_pos_weight=1, \n                     reg_alpha=5, reg_lambda=2, booster='gbtree',\n            n_jobs=-1, max_delta_step=0, colsample_bylevel=1, colsample_bynode=1)\n\nmodel = xgb.fit(X, y)\nprint('train accuracy',xgb.score(X, y))","4ec887cf":"df_test.drop(columns=['PassengerId'] , axis=1 , inplace=True)\ny_pred = model.predict(df_test)","889cfba2":"sub['Survived'] = y_pred.astype(int)","4e11eae0":"sub.to_csv('sub.csv', index=False) ","98eef557":"col_sorted_by_importance=xgb.feature_importances_.argsort()\nfeat_imp=pd.DataFrame({\n    'cols':X.columns[col_sorted_by_importance],\n    'imps':xgb.feature_importances_[col_sorted_by_importance]\n})\n\n#!pip install plotly-express\nimport plotly_express as px\npx.bar(feat_imp, x='cols', y='imps')","d00d1091":"**Manipulating Test Data**"}}