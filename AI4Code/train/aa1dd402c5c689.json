{"cell_type":{"cbb5fd84":"code","d964881f":"code","e46baf4b":"code","c10cd562":"code","fea40eb6":"code","088239f8":"code","21ad4485":"code","6163e11f":"code","3f9055a7":"code","7872f00a":"markdown","f8288f18":"markdown","e98b9181":"markdown","ce1da672":"markdown","c5068e2f":"markdown","7a316645":"markdown","cef841ce":"markdown","91f6f8bf":"markdown","339ab534":"markdown"},"source":{"cbb5fd84":"import numpy as np # linear algebras \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import misc\nimport imageio\nimport matplotlib.pyplot as plt\nfrom os import listdir\nimport random\n\n# machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score,accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#creating figures\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#resizing\nimport cv2\n\n#prevent warnings messages\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\ntf.logging.set_verbosity(tf.logging.ERROR)","d964881f":"# resize image and turn pixel values between 0 and 1\nIMG_SHAPE = 50\n\n# cell labels are 1 if infected, 0 if uninfected.\ncell_labels = []\n\n# cells \ncell_images = []\n\n#first six infected and unfected cells for visualization only\ninfected_cells = []\nuninfected_cells = []\n\n#listdir(\"..\/input\/cell_images\/cell_images\/\")\nbase_path = \"..\/input\/cell_images\/cell_images\/\"\n\n#get infected cells\ninfected_path = base_path +'Parasitized\/'\nfor file in listdir(infected_path):\n    if file.endswith('.png'):\n        file_path = infected_path + file\n        image = imageio.imread(file_path)\n        image = cv2.resize(image,(IMG_SHAPE,IMG_SHAPE)).astype('float32')\/255.0\n        infected_cells.append(image)\n        cell_images.append(image)\n        cell_labels.append(1)\n\n            \n#get uninfected cells\nuninfected_path = base_path +'Uninfected\/'\nfor file in listdir(uninfected_path):\n    if file.endswith('.png'):\n        file_path = uninfected_path + file\n        image = imageio.imread(file_path) \n        image = cv2.resize(image,(IMG_SHAPE,IMG_SHAPE)).astype('float32')\/255.0   \n        uninfected_cells.append(image)\n        cell_images.append(image)\n        cell_labels.append(0)","e46baf4b":"# visualize cells\ndef ShowFirstSix(images_arr,title):\n\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.set_title(title,fontsize=20)\n    plt.tight_layout()\n    plt.show()\nShowFirstSix(infected_cells,'Infected')\nShowFirstSix(uninfected_cells,'Uninfected')","c10cd562":"#randomly shuffle cell image list and their labels\ndef reorder(old_list,order):\n    new_list = []\n    for i in order:\n        new_list.append(old_list[i])\n    return new_list\n\nnp.random.seed(seed=42)\nindices = np.arange(len(cell_labels))\nnp.random.shuffle(indices)\nindices = indices.tolist()\ncell_labels = reorder(cell_labels,indices)\ncell_images = reorder(cell_images,indices)\n\n#change to arrays\nimage_array = np.array(cell_images)\nlabel_array = np.array(cell_labels)","fea40eb6":"# 30% of the data goes to the training data set\nX_train, X_test, y_train, y_test = train_test_split(image_array, label_array, train_size=0.70, random_state=100)\n\n# 30% additional data goes to the validation data set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=len(y_test), random_state=100)\n\nprint(\"size of training data set {}\".format((X_train.shape[0])))\nprint(\"size of validating data set {}\".format(X_val.shape[0]))\nprint(\"size of testing data set {}\".format(X_test.shape[0]))","088239f8":"#seeding random seed so I can get consist results\ntf.set_random_seed(10)\n\nmodel =  Sequential([\n    \n    #convolutional layers\n    Conv2D(32, (3,3), activation='relu', input_shape=(50,50, 3),padding='same'),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3,3), activation='relu',padding='same'),\n    MaxPooling2D(2,2),  \n    Conv2D(128, (3,3), activation='relu',padding='same'),\n    MaxPooling2D(2,2),\n    \n    # dense layer\n    Flatten(),\n    Dropout(0.50),\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\n\n# Compile the model\nmodel.compile(optimizer='adam', \n              loss='binary_crossentropy',\n              metrics=[tf.keras.metrics.binary_accuracy])\nmodel.summary()\n","21ad4485":"epochs = 20\nbatch_size =  600\nhistory = model.fit(X_train,y_train,\n    steps_per_epoch=int(np.ceil(len(y_train)\/ float(batch_size))),\n    epochs=epochs,\n    validation_data=(X_val,y_val),\n    validation_steps=int(np.ceil(len(y_val) \/ float(batch_size)))\n)","6163e11f":"#Plot accuracy and loss per epoch\n\n#accuracy\ntrain_accuracy = history.history['binary_accuracy']\nvalidation_accuracy = history.history['val_binary_accuracy']\n\n#loss \ntrain_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n\nepoch_range = range(1,len(train_accuracy)+1)\n\nfig, ax = plt.subplots(1, 2, figsize=(10,5))\n\n#accuracy\nax[0].set_title('Accuracy per Epoch')\nsns.lineplot(x=epoch_range,y=train_accuracy,marker='o',ax=ax[0])\nsns.lineplot(x=epoch_range,y=validation_accuracy,marker='o',ax=ax[0])\nax[0].legend(['training','validation'])\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].set_xticks([2,4,6,8,10,12,14,16,18,20])\nax[0].set_yticks([.6,.7,.8,.9,1.0])\nax[0].set_yticklabels(['60%','70%','80%','90%','100%'])\n#loss\nax[1].set_title('Loss per Epoch')\nsns.lineplot(x=epoch_range,y=train_loss,marker='o',ax=ax[1])\nsns.lineplot(x=epoch_range,y=validation_loss,marker='o',ax=ax[1])\nax[1].legend(['training','validation'])\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].set_xticks([2,4,6,8,10,12,14,16,18,20])\nplt.plot()","3f9055a7":"def GetFalseTruePositiveRate(y_true,y_prob,threshold):\n\n    y_predict = np.fromiter([1 if x > threshold else 0 for x in y_prob ],int)\n    n_positives = y_true.sum()\n    n_negatives = y_true.shape[0] - n_positives\n    \n    # get n true positives\n    n_true_pos = 0\n    n_false_pos = 0\n    for pred_value,true_value in zip(y_predict,y_true):\n        # true positive\n        if true_value == 1 and pred_value == 1:\n            n_true_pos += 1\n        # false positive\n        elif true_value == 0 and pred_value == 1:\n            n_false_pos += 1\n    true_pos_rate = n_true_pos\/n_positives\n    false_pos_rate = n_false_pos\/n_negatives\n    return false_pos_rate,true_pos_rate\n\ndef MakeConfusionMatrix(y_true,y_prob,threshold):\n    confusion_matrix = np.array([[0,0],[0,0]])\n    for pred_value,true_value in zip(y_prob,y_true):\n        if true_value == 1:\n            #true positive\n            if pred_value > threshold:\n                confusion_matrix[0,0] += 1\n            #false negative\n            else:\n                confusion_matrix[1,0] += 1\n        else:\n            #false positive\n            if pred_value > threshold: \n                 confusion_matrix[0,1] += 1\n            #true negative\n            else:\n                confusion_matrix[1,1] += 1       \n    fig = plt.figure(figsize=(5,5))\n    ax =  fig.gca()\n    sns.heatmap(confusion_matrix,ax=ax,cmap='Blues',annot=True,fmt='g',\n               xticklabels = ['Infected','Uninfected'],\n               yticklabels=['Infected','Uninfected'])\n    ax.set_ylabel('Actual',fontsize=20)\n    ax.set_xlabel('Predicted',fontsize=20)\n    plt.title('Confusion Matrix',fontsize=24)\n    plt.show()\n\ny_predict = model.predict(X_test)\nthresholds = np.arange(0.01,1.01,0.01)\nthresholds = np.append(np.array([0,0.00001,0.0001,0.001]),thresholds)\nroc_auc = np.array([GetFalseTruePositiveRate(y_test,y_predict,n) for n in thresholds ]) \nroc_auc = np.sort(roc_auc,axis=0)\nroc_auc_value = roc_auc_score(y_test,y_predict)\nloss,accuracy = model.evaluate(X_test,y_test)\naccuracy = accuracy\nloss = loss\ntext = 'AUC-ROC  score = {:.3f}'.format(roc_auc_value)\ntext += '\\nAccuracy = {:.1f}%'.format(accuracy*100)\ntext += '\\nLoss = {:.3f}'.format(loss)\n\nfig = plt.figure(figsize=(7,7))\nax =  fig.gca()\nax.set_title('Malaria AUC-ROC Curve',fontsize=28)\nax.set_ylabel('True Positive Rate',fontsize=20)\nax.set_xlabel('False Positive Rate',fontsize=20)\nax.plot(roc_auc[:,0],roc_auc[:,1])\nax.text(s=text,x=0.1, y=0.8,fontsize=20)\nplt.show()\n\nMakeConfusionMatrix(y_test,y_predict,0.5)","7872f00a":"# Random shuffling\n\nThe order of cells is randomized. Attention is paid to making sure that 'cell_images', which store the pixels, and 'cell_labels', which store the labels, are ordered the same way. Both 'cell_images' and 'cell_labels' are converted into numpy arrays.","f8288f18":"# Creating model\n\nBelow, the model is created. We used 3 convolutional layers and one dense layer. The convolutional layers provide filters to look for regional patterns. Since the signs of malaria infection are found from discoloration in small areas of the image, the convolutional layers provide a high degree of accuracy on the validation data. The model reaches this degree of accuracy with less epochs with the inclusion of the dense layer. More dense layers do not improve accuracy but it does cause the cross entropy loss function to increase after a certain number of epoche steps. This is a sign of overfitting.","e98b9181":"# Evaluate model on Testing Data\n\nOverall the model does well on the testing data. The AUC-ROC, loss function,accuracy, and confusion matrix are shown below.","ce1da672":"# Epoch Plots.\n\nThe accuracy and loss function for the validation data stable after a certain number of epoch steps. There is not a loss in accuracy or increase in the loss function which is a sign that the model is not overfitted.","c5068e2f":"# Data Split\n\nData is split into training, validation, and testing data. The training data trains the models. The validation data  evaluates the model while the models is being train. The validation data is used to see how the model improves. The testing data test the model once the training is complete.","7a316645":"# Train the model.\n\nThere are 20 epochs sets with a batch size of 600. ","cef841ce":"# Visualizing Images\n\nBelow, images of malaria infected and uninfected cells are shown. Infected cells can be recognized by regions of discoloration alone which is why convolutional layers are so successful.\n","91f6f8bf":"# Reading, resizing, and normalizing data\n\nAll images are read into memory and resized to 50 X 50. The values of each pixel is normalized to a value between 0 to 1. The images of the cells are stored in 'cell_images' and the labels (infected = 1, non-infected = 0) are stored in cell_labels.","339ab534":"# Malaria detection from Cell Images \n\nIn this notebook, a convolutional neural network is created in order to predict whether cells are infected with malaria from images of the cells. Neural networks require the inputs to be the same dimension. The images of the cells were therefore converted into size 50X50 in order to have consistant size. This would also have the impact of reducing the size of the image to a reasonable number for quicker modeling. As typical for an neural network, the\nvalues of pixels were normalized to be between 0 to 1.\n\nThe convolutional neural network had 3 convolutional layers and 1 dense layers. The dense layer had a drop off of 0.50 to prevent overfit. The convolutional layers detect local patterns using filters. The convolutional layers was found to be significantly more important than the dense layer. We get 94% on the validation data with the convolutional layers alone but this required more epoche to reach same degree of accuracy as with the inclusion of the dense layer. Using more dense layers did not affect accuracy but there is a increase in the cross entropy loss function on the validation data after a number of epoche steps. This is sign of overfitting. In the end, the convolutional neural network provided a 95% accuracy on the testing data.\n"}}