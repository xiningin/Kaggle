{"cell_type":{"8ea70614":"code","5af3333a":"code","57664790":"code","b66ef685":"code","cb349bc3":"code","b90d451b":"code","cd888634":"code","dd47ff06":"code","095aa0fc":"code","7c4da0ba":"code","e7f6f92e":"code","226d0851":"code","a0fcf65a":"code","e3566b91":"code","f6763e1f":"code","5b9d4e81":"code","d9e72785":"markdown"},"source":{"8ea70614":"from fastai.vision import *\nimport os\npath = Path('..\/input\/samples\/samples')\nos.listdir(path)[:10]","5af3333a":"files = os.listdir(path)\n\nfig, ax = plt.subplots(nrows=4, figsize=(14,7))\n\nfor a, filename in zip(ax.flatten(), files[:4]):\n    a.imshow(PIL.Image.open(path\/filename))\n    a.axis('off')\n\nplt.show()","57664790":"#convert label\nlabels = [[char for char in code.name[:-4]] for code in (path).glob('*.png')]\nlabels = set([letter for label in labels for letter in label])\nprint(len(labels), 'different labels were found')\n\nencoding_dict = {l:e for e,l in enumerate(labels)}\ndecoding_dict = {e:l for l,e in encoding_dict.items()}\n\ncode_dimension = len(labels)\ncaptcha_dimension = 5\n\ndef to_onehot(filename):\n    code = filename.name[:-4]\n    onehot = np.zeros((code_dimension, captcha_dimension))\n    for column, letter in enumerate(code):\n        onehot[encoding_dict[letter], column] = 1\n    return onehot.reshape(-1)\n\ndef to_idx(filename):\n    code = filename.name[:-4]\n    return np.array([encoding_dict[c] for c in code])#, dtype=torch.long)\n\ndef decode(onehot):\n    onehot = onehot.reshape(code_dimension, captcha_dimension)\n    idx = np.argmax(onehot, axis=0)\n    return [decoding_dict[i.item()] for i in idx]\n\ndef label_accuracy(preds, actuals):\n    pred = torch.unbind(preds)\n    act = torch.unbind(actuals)\n    \n    valid = 0\n    total = 0\n    \n    for left,right in zip(pred,act):\n        total+=1\n        p = decode(left)\n        a = decode(right)\n        if p==a: valid += 1\n\n    return torch.tensor(valid\/total).cuda()\n\ndef char_accuracy(n):\n    def c_acc(preds, actuals):\n        pred = torch.unbind(preds)\n        act = torch.unbind(actuals)\n\n        valid = 0\n        total = 0\n\n        for left,right in zip(pred,act):\n            total+=1\n            p = decode(left)\n            a = decode(right)\n            if p[n]==a[n]: valid += 1\n\n        return torch.tensor(valid\/total).cuda()\n    return c_acc","b66ef685":"data = (ImageList.from_folder(path)\n        .split_by_rand_pct(0.2)\n        .label_from_func(to_onehot, label_cls = FloatList)\n        .transform(get_transforms(do_flip=False))\n        .databunch()\n        .normalize()\n       )","cb349bc3":"learn = cnn_learner(data, models.resnet50, model_dir='\/tmp',\n                    metrics=[label_accuracy, char_accuracy(0),char_accuracy(1),char_accuracy(2),char_accuracy(3),char_accuracy(4)],\n                   ps=0.)","b90d451b":"lr_find(learn)\nlearn.recorder.plot()","cd888634":"learn.fit_one_cycle(5, 5e-2)","dd47ff06":"learn.unfreeze()\n#lr_find(learn)\n#learn.recorder.plot()","095aa0fc":"learn.fit_one_cycle(25, slice(1e-3, 1e-2))","7c4da0ba":"def multi_cross_entropy(inp, target):\n    re_inp = inp.view(-1, 5, 19)\n    re_target = target.view(-1, 5, 19)\n    soft = F.log_softmax(re_inp, dim=0)\n    cross = soft*re_target\n    return -cross.mean()","e7f6f92e":"data = (ImageList.from_folder(path)\n        .split_by_rand_pct(0.2)\n        .label_from_func(to_onehot, label_cls = FloatList)\n        .transform(get_transforms(do_flip=False))\n        .databunch()\n        .normalize()\n       )","226d0851":"learn = cnn_learner(data, models.resnet50, model_dir='\/tmp',\n                    metrics=[label_accuracy, char_accuracy(0),char_accuracy(1),char_accuracy(2),char_accuracy(3),char_accuracy(4)],\n                    loss_func=multi_cross_entropy,\n                   ps=0.)","a0fcf65a":"lr_find(learn)\nlearn.recorder.plot()","e3566b91":"learn.fit_one_cycle(20, 1e-1)","f6763e1f":"learn.unfreeze()\nlr_find(learn)\nlearn.recorder.plot()","5b9d4e81":"learn.fit_one_cycle(25, slice(1e-4, 1e-2))","d9e72785":"This notebook is the groundwork for [this](https:\/\/medium.com\/@oneironaut.oml\/solving-captchas-with-deeplearning-part-3-one-model-to-solve-it-all-d1fbd51f7f9e) blogpost. It's part of a 3-part miniseries, the other posts are [here](https:\/\/medium.com\/@oneironaut.oml\/solving-captchas-with-deeplearning-part-1-multi-label-classification-b9f745c3a599) and [here](https:\/\/medium.com\/@oneironaut.oml\/solving-captchas-with-deeplearning-part-2-single-character-classification-ac0b2d102c96)."}}