{"cell_type":{"360ae755":"code","49c97bdf":"code","0e8cfc7b":"code","306d3848":"code","a1d2a0e0":"code","75366025":"code","5b37bb7f":"code","7b324766":"code","4f98df1c":"code","1de657a2":"code","d98d308c":"code","b70a6f8a":"code","fc6f00aa":"code","78a8ce07":"code","77fa8cc1":"code","cb1e02c1":"code","a2360810":"code","54e02669":"code","5350fde6":"code","467659fc":"code","9a1c98d2":"code","6d637ccb":"code","926fe903":"code","9961e91e":"code","52eaf65c":"code","7ce8d403":"code","1b750473":"code","0f1151da":"code","23d3b372":"code","343ae7f9":"code","b68ab363":"code","2f873f8d":"code","579b8be3":"code","2da1cf04":"code","c2d337c2":"code","c58529d1":"code","410b157c":"code","e78b9dbf":"code","2f27161f":"code","8629762a":"code","7d37ed4f":"code","b161fd84":"code","aac01f09":"code","7fc885fb":"code","d012303a":"code","5fa5332d":"code","87d1d74b":"code","7cb3744c":"code","05e05256":"code","ab4b37f2":"markdown","84a1985a":"markdown","58aee9f5":"markdown","0aa8b1b8":"markdown","f901936c":"markdown","2ac0dc62":"markdown","b29d5c0e":"markdown","f8a5c6fb":"markdown","fdaa5f90":"markdown","53325434":"markdown","a8c2f6c4":"markdown","95e2909a":"markdown","cc7a99c2":"markdown","322adc20":"markdown","673dc5c4":"markdown","03a7c920":"markdown","a7b9f0b3":"markdown","bbdbaeff":"markdown","d41cc6b2":"markdown","f4979de7":"markdown","5e6017ff":"markdown","80e542f3":"markdown","dff6ec46":"markdown","56dab088":"markdown","617fae36":"markdown","62bae1fb":"markdown","0344580a":"markdown","ec8d280d":"markdown","d56d9ff3":"markdown","3b14fb9c":"markdown","3469c07d":"markdown","e9e18613":"markdown"},"source":{"360ae755":"!pip show fastai","49c97bdf":"# Put these at the top of every notebook, to get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","0e8cfc7b":"# This file contains all the main external libs we'll use\nfrom fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *\n\nimport torch.optim as optim\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\nimport seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')\n\nimport gc\nimport datetime as dt","306d3848":"# Start timer\nstart = dt.datetime.now()","a1d2a0e0":"#set the path\nPATH = \"..\/input\"\nos.listdir(PATH)","75366025":"img_size = 28               # Known from dataset description\nbatch_size = 64             # Opting for a default value for now","5b37bb7f":"train_data = pd.read_csv(f'{PATH}\/train.csv', header='infer')\ntest_data  = pd.read_csv(f'{PATH}\/test.csv', header='infer')\n\n# Getting number of training examples from train data shape\nm = train_data.shape[0]\nprint(\"Number of samples in training data is:\", m)","7b324766":"#Pixels\nX_train_data = train_data.iloc[:,1:]\nX_train_data = X_train_data.values\nX_test_data = test_data.values       # this one has no labels to be removed\n\n# Labels\nY_train_data = train_data.iloc[:,0:1]\nY_train_data = Y_train_data.values\n\n# Little clean up\ndel train_data\ndel test_data\ngc.collect()","4f98df1c":"# Converting to the square image\nprint(\"Original train image data shape:\", X_train_data.shape)\nX_train_data = X_train_data.reshape(-1, img_size, img_size)\n\n#Add missing color channels to previously reshaped image\nX_train_data = np.stack((X_train_data,) * 3, axis = -1).astype('uint8') \nX_train_data = X_train_data\/255                                           # Normalizing data as we go, it seems to make a lot of difference\nprint(\"Resulting train image data shape:\", X_train_data.shape)\n\n# Same conversion for test data as well\nX_test = X_test_data.reshape(-1, img_size, img_size)\nX_test = np.stack((X_test,) * 3, axis = -1).astype('uint8')\nX_test = X_test\/255                                                      # Same processing for test as for training","1de657a2":"def print_10_images(X, y):\n    plt.rcParams['figure.figsize'] = (50.0, 50.0) # set default size of plots\n    plt.axis('off')\n    \n    num_images_to_show = 10\n    m = X.shape[0]\n    \n    for i in range(num_images_to_show):\n        sample = np.random.randint(0, m - 1)\n        \n        plt.subplot(2, num_images_to_show, i + 1)\n        plt.imshow(X[sample], interpolation = 'nearest')\n        plt.rcParams['figure.figsize'] = (50.0, 50.0) # set default size of plots\n        \n        plt.title(\"Index: \" + str(sample) + \" \\n Label: \" + str(y[sample]), fontsize=25)\n            \n    plt.axis('on')\n    plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n        \ndef plot_labels_distribution(Y_train, Y_cv, sharey = False):\n    _, axes = plt.subplots(1, 2, figsize = (10, 3), sharey = sharey)\n    sns.countplot(Y_train.flatten(), ax = axes[0])\n    sns.countplot(Y_cv.flatten(), ax = axes[1])","d98d308c":"print_10_images(X_train_data, Y_train_data)","b70a6f8a":"test_size = 0.05      # Proportion of CV set to be extracted from training data\n\nY_train, Y_cv = train_test_split(Y_train_data, test_size = test_size, shuffle = True, stratify = None, random_state = 1974)\nplot_labels_distribution(Y_train, Y_cv)","fc6f00aa":"X_train, X_cv, Y_train, Y_cv = train_test_split(X_train_data, Y_train_data, test_size = test_size, shuffle = True, stratify = Y_train_data, random_state = 1974)\nplot_labels_distribution(Y_train, Y_cv)","78a8ce07":"# Final touches\nY_train = Y_train.flatten()\nY_cv = Y_cv.flatten()\n\ndel X_train_data\ndel Y_train_data\ngc.collect()","77fa8cc1":"# Loading data into the Fast.AI structure\narch = resnet34\ndata = ImageClassifierData.from_arrays('tmp\/', (X_train, Y_train), (X_cv, Y_cv), classes = np.unique(Y_cv), bs = batch_size, tfms = tfms_from_model(arch, img_size))\nlearn = ConvLearner.pretrained(arch, data, precompute = True)","cb1e02c1":"# Find learning rate\nlearn.lr_find()","a2360810":"learn.sched.plot()","54e02669":"learn.fit(lrs = 0.01, n_cycle = 3)","5350fde6":"# This gives prediction for validation set. Predictions are in log scale\nlog_preds = learn.predict()\n\n# From log probabilities to 0 or 1\nprobs = np.exp(log_preds)  \n\n# From probabilities to classes\npreds = np.argmax(probs, axis=1)  ","467659fc":"def print_10_mislabeled_images(X, y, p):\n    \n    plt.rcParams['figure.figsize'] = (50.0, 10.0) # set default size of plots\n    plt.axis('off')\n    \n    num_images_to_show = 10\n    \n    a = p - y\n    mislabeled_indices = np.asarray(np.where(a != 0))\n\n    for i in range(num_images_to_show):\n        sample = np.random.randint(0, mislabeled_indices.shape[1])\n        index = mislabeled_indices[0][sample]\n        \n        plt.subplot(2, num_images_to_show, i + 1)\n        plt.imshow(X[index], interpolation = 'nearest')\n        plt.title(\"Prediction: \" + str(p[index]) + \" \\n Label: \" + str(y[index]), fontsize=25)\n        \n    plt.axis('on')\n    plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n    \ndef print_all_mislabeled_images(X, y, p):\n    \n    plt.rcParams['figure.figsize'] = (50.0, 15.0) # set default size of plots\n    plt.axis('off')\n    \n    num_images_in_row = 10\n    \n    a = p - y\n    mislabeled_indices = np.asarray(np.where(a != 0))\n    num_rows = mislabeled_indices.shape[1] \/\/ num_images_in_row + 1\n    \n    for i in range(mislabeled_indices.shape[1]):\n        index = mislabeled_indices[0][i]\n        \n        plt.subplot(num_rows, num_images_in_row, i + 1)\n        plt.imshow(X[index], interpolation = 'nearest')\n        plt.title(\"Prediction: \" + str(p[index]) + \" \\n Label: \" + str(y[index]), fontsize=25)\n        \n    plt.axis('on')\n    plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots","9a1c98d2":"print_10_mislabeled_images(X_cv, Y_cv, preds)","6d637ccb":"learn.precompute = False\nlearn.fit(lrs = 1e-2, n_cycle = 3, cycle_len = 1)\n\nlearn.sched.plot_lr()","926fe903":"learn.unfreeze()","9961e91e":"lr = 0.01\nlrs = np.array([lr\/9,lr\/3,lr])                # Using bigger LR for early layers as our images are quite different from the ImageNet\n\nlearn.fit(lrs = lr, n_cycle = 3, cycle_len = 1, cycle_mult = 2)","52eaf65c":"learn.sched.plot_lr()","7ce8d403":"learn.sched.plot_loss()","1b750473":"# This gives prediction for validation set. Predictions are in log scale\nlog_preds = learn.predict()\n\n# From log probabilities to 0 or 1\nprobs = np.exp(log_preds)  \n\n# From probabilities to classes\npreds = np.argmax(probs, axis=1)  \n\nprint_all_mislabeled_images(X_cv, Y_cv, preds)","0f1151da":"cm = confusion_matrix(Y_cv, preds)\n\nplt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\nplot_confusion_matrix(cm, data.classes)\nplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots","23d3b372":"def show_img(ims, idx, figsize = (50, 50), ax = None):\n    if ax is None: fig, ax = plt.subplots(figsize = figsize)\n    ims = np.rollaxis(to_np(ims), 1, 4)\n    ax.imshow(np.clip(ims, 0, 1)[idx], interpolation = 'nearest')\n    ax.axis('off')","343ae7f9":"# Loading data into the Fast.AI structure\narch = resnet34\n\naug_tfms = [RandomRotate(30, p = 0.75, mode = cv2.BORDER_REFLECT, tfm_y = TfmType.NO),\n            AddPadding(pad = 2, mode = cv2.BORDER_REPLICATE)]\n\ntfms = tfms_from_model(arch, img_size, aug_tfms = aug_tfms, max_zoom = 1.1)\ndata = ImageClassifierData.from_arrays('tmp\/', (X_train, Y_train), (X_cv, Y_cv), classes = np.unique(Y_cv), bs = batch_size, tfms = tfms)","b68ab363":"batches = [next(iter(data.aug_dl)) for i in range(10)]\n\nfor pos in range(len(batches)):\n    fig, axes = plt.subplots(1, 10, figsize=(25,8))\n    for i,(x,y) in enumerate(batches):\n        show_img(x, pos, ax = axes.flat[i])","2f873f8d":"learn = ConvLearner.pretrained(arch, data, precompute = True)\n\n# Find learning rate\nlearn.lr_find()\n\nlearn.sched.plot()","579b8be3":"lr = 0.02                                \nlearn.fit(lrs = lr, n_cycle = 3)","2da1cf04":"learn.precompute = False\nlearn.fit(lrs = lr, n_cycle = 3, cycle_len = 1)","c2d337c2":"learn.unfreeze()\n\nlearn.lr_find()\nlearn.sched.plot()","c58529d1":"lr = 0.003\nlrs = np.array([lr\/9, lr\/3, lr])\nlearn.fit(lrs = lrs, n_cycle = 3, cycle_len = 1, cycle_mult = 2)\nlearn.sched.plot_loss()","410b157c":"# This gives prediction for validation set. Predictions are in log scale\nlog_preds, y = learn.TTA()\n\n# From log probabilities to 0 or 1\nprobs = np.exp(log_preds) \n\n# From probabilities to classes\npreds = np.argmax(np.mean(probs, axis = 0), axis = 1)\n\nprint_all_mislabeled_images(X_cv, Y_cv, preds)","e78b9dbf":"cm = confusion_matrix(y, preds)\n\nplt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\nplot_confusion_matrix(cm, data.classes)\nplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots","2f27161f":"arch = resnet152\nbatch_size = 64\n\ndef get_data(sz, bs, trn = (X_train, Y_train), val = (X_cv, Y_cv), test = X_test):\n    aug_tfms = [RandomRotate(30, p = 0.75, mode = cv2.BORDER_REFLECT, tfm_y = TfmType.NO),\n                RandomZoom(zoom_max = 0.05),\n                #RandomStretch(max_stretch = 0.05),\n                AddPadding(pad = 2, mode = cv2.BORDER_REPLICATE)]\n    tfms = tfms_from_model(arch, sz, aug_tfms = aug_tfms, max_zoom = 1.1)\n    data = ImageClassifierData.from_arrays('tmp\/', trn, val, classes = np.unique(Y_cv), bs = bs, tfms = tfms, test = test)\n    return data\n\ndata = get_data(img_size, batch_size, (X_train, Y_train), (X_cv, Y_cv), X_test)","8629762a":"# Using Adam optimizer\nlearn = ConvLearner.pretrained(arch, data, opt_fn = optim.Adam, precompute = True)\n\nlearn.lr_find()\nlearn.sched.plot()","7d37ed4f":"lr = 0.001\n\nlearn.fit(lr, n_cycle = 1, cycle_len = 1)\n\nlearn.precompute = False\nlearn.fit(lr, n_cycle = 4, cycle_len = 1, cycle_mult = 2)\nlearn.save('pre_fit')","b161fd84":"learn.load('pre_fit')\nlearn.unfreeze()\n\nlearn.lr_find()\nlearn.sched.plot()","aac01f09":"lr = 0.0003\nwd = 0.0001\n\nlearn.fit(lrs = [lr\/9, lr\/3, lr], n_cycle = 5, wds = [wd\/100, wd\/10, wd], use_wd_sched = True, cycle_len = 1, cycle_mult = 2)","7fc885fb":"learn.sched.plot_loss()","d012303a":"# This gives prediction for validation set. Predictions are in log scale\nlog_preds, y = learn.TTA()\n\n# From log probabilities to 0 or 1\nprobs = np.exp(log_preds) \n\n# From probabilities to classes\npreds = np.argmax(np.mean(probs, axis = 0), axis = 1)\n\nprint_all_mislabeled_images(X_cv, Y_cv, preds)","5fa5332d":"cm = confusion_matrix(Y_cv, preds)\n\nplt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\nplot_confusion_matrix(cm, data.classes)\nplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots","87d1d74b":"# This gives prediction for validation set. Predictions are in log scale\nlog_preds, y = learn.TTA(is_test = True)\n\n# From log probabilities to 0 or 1\nprobs = np.exp(log_preds) \n\n# From probabilities to classes\npreds = np.argmax(np.mean(probs, axis = 0), axis = 1)\n\n# Saving predictions\nresults = pd.Series(preds, name = \"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), results], axis = 1)\nsubmission.to_csv(\"submission.csv\", index = False)","7cb3744c":"# Remove temp files as it seems to help to avoid error on the kernel submission\n!rm -rf '..\/working\/tmp'","05e05256":"# Collect and report execution timings\nend = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","ab4b37f2":"## Improving the Model","84a1985a":"Let's look at samples of augmented images.","58aee9f5":"## Environment","0aa8b1b8":"The distribution of classes looks fine, but it is not perfect. Stratifying should help, so also including image data into split along with the labels.","f901936c":"Since the pre-trained model resnet has 3 channels, we will have to multiply the channels by 3 the test and train data.","2ac0dc62":"All in all, accuracy is not that impressive. After all, the simplest possible model with one output layer (inputs pixels are directly mapped to softmax activations) would give accuracy at around 90%. However, with only the output layer being fitted by default we are very close to that.","b29d5c0e":"## Data Augmentation","f8a5c6fb":"Let's see what we still get wrong? Actually, there are only a bunch of weird images in the validation set that the model couldn't classify correctly.","fdaa5f90":"Learning rate of 0.01 seems to be a good default choice. It is important to notice that by default only the output layer of the model is affected by fitting.","53325434":"## Putting everything together.\n\nI now want to start from scratch and put together all I have learned. The goal is to get to accuracy > 0.999 or better.","a8c2f6c4":"To implement data augmentation, we need to create new learner wish updated transformations structure `tfms`. As we are working with digits, we should be careful selecting augmentations as compared to simple images classification (e.g., we can't flip images). As we work with relatively small images, all augmentation parameters should be fairly subtle.","95e2909a":"Let's first look at the confusion matrix.","cc7a99c2":"Note that's what being plotted above is the learning rate of the final layers. The learning rates of the earlier layers are fixed at the same multiples of the last layer rates as we initially requested.\n\nLoss graph for reference.","322adc20":"By default when we create a learner, it sets all but the last layer to *frozen*. That means that it's still only updating the weights in the last layer when we call `fit`.","673dc5c4":"Apparently, it is hard to manage the environment, I ran into this issue both here on Kaggle and on Google Colab. Although it is possible to change packages versions with `!pip`, it would work only for a particular session. However, having these installation steps in the script is not that practical, as it takes precious kernel runtime.","03a7c920":"It is clear that the model still can benefit from the time invested in further training. But first, let's check out TTA.","a7b9f0b3":"# Fast.AI.MNIST\n\nAfter playing with plain `numpy` neutral network implementation in NNNN - a [Naive Neutral Network iNtroduction](https:\/\/www.kaggle.com\/alukashenkov\/nnnn-a-naive-neutral-network-introduction) kernel I intended to try to implement a similar model using a popular deep learning framework. However, I really got inspired by Fast.AI approach demonstrated in Lesson 1 of the [course](https:\/\/course.fast.ai). Also, it helps a lot in the learning process to take a concept and to extend it to a similar, but still different case.\n\nSo, here is my take on MNIST dataset with the Fast.AI toolbox.\n\nAs always, if you see a bug, please let me know at alukashenkov@gmail.com. If you find this piece of use and interest, please upvote.","bbdbaeff":"We need to split `train_data` into training and cross-validation sets.","d41cc6b2":"Also, looking at `trn_loss` and `val_loss` it is clear that the model starts to overfit. So, I would assume that further training wouldn't yield much better results - we need to implement data augmentation.","f4979de7":"The above training file contains both images and labels. These have to be split. The first column is a label.","5e6017ff":"## Getting Data and Preparing Train\/CV Sets\nImporting libraries.","80e542f3":"I'm also using weight decay parameter (as described in https:\/\/www.fast.ai\/2018\/07\/02\/adam-weight-decay\/)","dff6ec46":"Now that we have a good final layer trained, we can try fine-tuning the other layers. To tell the learner that we want to unfreeze the remaining layers, just call `unfreeze()`.","56dab088":"Generally speaking, the earlier layers (as we've seen) have more general-purpose features. Therefore we would expect them to need less fine-tuning for new datasets. For this reason, we will use different learning rates for different layers. We refer to this as differential learning rates, although there's no standard name for this technique in the literature that we're aware of.","617fae36":"Sanity check - what images the model gets wrong? In my case, most of the pictures I see still easily recognisable.","62bae1fb":"## Testing and Submitting","0344580a":"Load train and test data.","ec8d280d":"Definig some useful constants.","d56d9ff3":"## The Model\n\nNow we are coming to the famous \"three lines of code\" model definition. Let's follow the steps outlined in the course to get it working.","3b14fb9c":"## Acknowledgments\n\nI took initial inspiration from [MNIST Classification using Fast AI V2](https:\/\/www.kaggle.com\/vijaykris\/mnist-classification-using-fast-ai-v2) kernel. \n\n[Practical Deep Learning for Coders](https:\/\/course.fast.ai) course materials were of great help. I guess I'm using inputs from first three lessons in this kernel. There are [incredible notes](https:\/\/medium.com\/@hiromi_suenaga\/deep-learning-2-part-1-lesson-1-602f73869197) for this course created by [Hiromi Suenaga](https:\/\/medium.com\/@hiromi_suenaga) that make the content of video lectures \"searchable.\"\n\n[Data Augmentation Experimentation](https:\/\/towardsdatascience.com\/data-augmentation-experimentation-3e274504f04b) article by [Amrit Virdee](https:\/\/medium.com\/@pillview) helped a lot to understand how to work with data augmentation in Fast.AI.","3469c07d":"Let's see what we've got to work with.","e9e18613":"I observed no material improvements in model accuracy after 4 cycles (15 epochs). So, let's now unfreeze and fit model with all layers, but first, let's see if any changes to the learning rate are needed."}}