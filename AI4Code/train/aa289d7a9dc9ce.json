{"cell_type":{"45217f45":"code","4ecc658c":"code","36754975":"code","5f687e8f":"code","ecab4fa6":"code","2f192412":"code","7f060ee9":"code","ea211a8c":"code","9cc2fc7c":"code","7c5697a7":"code","087ccc56":"code","10147dad":"code","80b9eb6c":"code","7bd3bd57":"code","2b4f5481":"code","024c0d7c":"code","e10f098e":"code","01216916":"code","177f4a71":"code","5be2657d":"code","ff13a9e0":"code","d78cf339":"code","e3fec348":"code","79859a60":"code","9d530a6f":"code","5017f070":"code","45d3b95d":"code","d8f85900":"code","42a1d3e8":"code","1e1f3a7a":"code","00986919":"code","5afc87fb":"code","2da3b6e9":"code","c236ade6":"code","906ff360":"code","3c88f3d3":"code","7c144aa6":"markdown","7c7ceb1e":"markdown","d5eb8856":"markdown","1fb2cbe8":"markdown","a705d25a":"markdown","7643a8b1":"markdown","31cecfee":"markdown","d1c0967c":"markdown","695be4b5":"markdown","a77a8ef7":"markdown","007adf84":"markdown","a65064c0":"markdown","abed2409":"markdown","385e2195":"markdown","dd57e16b":"markdown"},"source":{"45217f45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ecc658c":"import numpy as np\nimport torch\nimport torch.utils.data\nfrom PIL import Image\nimport pandas as pd\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torch.utils.data.sampler import SequentialSampler\nfrom pydicom import dcmread\n\nimport torch\nfrom torchvision import transforms\nfrom torchvision import transforms as T\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils import data\nfrom torch.utils.data import Dataset, DataLoader\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nimport pydicom as pyd\nfrom tqdm import tqdm\n\nimport cv2\nimport re\nimport time\nimport matplotlib\nimport os\n\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom tqdm import tqdm\nimport albumentations as A\n\nfrom albumentations import (\n    Resize,\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n)","36754975":"images_path = '..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_images'\ntrain_labels_df = pd.read_csv('..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_labels.csv')\nlabel_meta_data = pd.read_csv('..\/input\/rsna-pneumonia-detection-challenge\/stage_2_detailed_class_info.csv')","5f687e8f":"train_labels_df","ecab4fa6":"label_meta_data","2f192412":"len(np.unique(label_meta_data['patientId']))","7f060ee9":"label_meta_data.shape","ea211a8c":"unique_patientId = train_labels_df.drop_duplicates(subset = ['patientId'])\nunique_patientId","9cc2fc7c":"target = (\n    unique_patientId['Target']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'Target', 'Target':'Count'})\n    .replace([0,1], ['Normal', 'Lung Opacity']) \n    .groupby('Target')\n    .sum()\n    .reset_index()    \n          )   \n\nfig = go.Figure(data=[go.Pie(labels=target['Target'], \n                             values=target['Count'])])\n\nfig.update_traces(hoverinfo='percent+value', \n                  textinfo='label', \n                  textfont_size=20,\n                  marker=dict(colors=['#8cb074', '#5a7c47'], line=dict(color='white', width=5)))\n\nfig.update_layout(showlegend=False, \n                  title_text=\"Target Distribution\",\n                  title_x=0.5,\n                  font=dict(family=\"Hiragino Kaku Gothic Pro, sans-serif\", size=20, color='#000000'))\n\n\nfig.show()","7c5697a7":"print('Original dataframe shape:', train_labels_df.shape)\n\ntrain_labels_df_pos = pd.DataFrame(columns=['patientId', 'x', 'y', 'width', 'height'])\n\nk = 0\nfor i in range(len(train_labels_df)):\n    if train_labels_df.loc[i]['Target'] == 1:\n        train_labels_df_pos.loc[k] = train_labels_df.loc[i]\n        k += 1\n\nprint('Positive instances dataframe shape:', train_labels_df_pos.shape)\ntrain_paths = [os.path.join(images_path, image[0]) for image in train_labels_df_pos.values]","087ccc56":"train_labels_df_pos.head()","10147dad":"def imshow(num_to_show=9):\n    \n    plt.figure(figsize=(20,20))\n    \n    for i in range(num_to_show):\n        plt.subplot(3, 3, i+1)\n        plt.grid(False)\n        plt.xticks([])\n        plt.yticks([])\n        \n        img_dcm = dcmread(f'{train_paths[i+20]}.dcm')\n        img_np = img_dcm.pixel_array\n        plt.imshow(img_np, cmap='bone')\n\nimshow()","80b9eb6c":"def show_image_with_bboxes(num_to_show=9):\n    plt.figure(figsize=(20,20))\n    \n    for i in range(num_to_show):\n        plt.subplot(3, 3, i+1)\n        plt.grid(False)\n        plt.xticks([])\n        plt.yticks([])\n        \n        id_= np.random.choice(train_labels_df_pos['patientId'].values)\n\n        current_axis = plt.gca()\n        img=pyd.read_file(os.path.join(images_path,id_+'.dcm')).pixel_array\n        plt.imshow(img,cmap='bone')\n\n\n        current_axis = plt.gca()\n        boxes=train_labels_df_pos[['x','y','width','height']][train_labels_df_pos['patientId']==id_].values\n\n        for box in boxes:\n            x=box[0]\n            y=box[1]\n            w=box[2]\n            h=box[3]\n            current_axis.add_patch(plt.Rectangle((x, y), w, h, color='red', fill=False, linewidth=3)) \n        \nshow_image_with_bboxes()","7bd3bd57":"def parse_one_annot(data, patient_id):\n    boxes_array = data[data[\"patientId\"] == patient_id][[\"x\", \"y\", \"width\", \"height\"]].values\n#     print(boxes_array.dtype)\n    return boxes_array","2b4f5481":"def show_one_with_bbox(id_):\n    plt.figure(figsize=(20,20))\n    current_axis = plt.gca()\n    img=pyd.read_file(os.path.join(images_path,id_+'.dcm')).pixel_array\n    plt.imshow(img,cmap='bone')\n\n    current_axis = plt.gca()\n    boxes=train_labels_df_pos[['x','y','width','height']][train_labels_df_pos['patientId']==id_].values\n    for box in boxes:\n        x=box[0]\n        y=box[1]\n        w=box[2]\n        h=box[3]\n        current_axis.add_patch(plt.Rectangle((x, y), w, h, color='red', fill=False, linewidth=3)) ","024c0d7c":"id_= np.random.choice(train_labels_df_pos['patientId'].values)\nprint('Id', id_)\nprint('Bboxes', parse_one_annot(train_labels_df_pos, id_))\nshow_one_with_bbox(id_)","e10f098e":"class PneumoniaDataset(Dataset):\n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n\n        self.image_ids = dataframe['patientId'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n        \n    def __getitem__(self, index):\n        # load images and bounding boxes   \n        image_id = self.image_ids[index]\n        records = self.df[self.df['patientId'] == image_id]\n        \n#         img_path = os.path.join(self.image_dir, image_id)\n#         img=pyd.read_file(os.path.join(img_path+'.dcm')).pixel_array\n        img = cv2.imread(f'{self.image_dir}\/{image_id}.jpg', cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n#         img = img\/255\n        img \/= 255.0\n        \n        boxes = records[['x', 'y', 'width', 'height']].values\n        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype=torch.float32)\n        \n        # there is only one class\n        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n        \n        target = {}    \n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['patientId'] = torch.tensor([index])\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n                      \n        if self.transforms:\n            sample = {\n                'image': img,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            img = sample['image']\n            \n            target['boxes'] = torch.stack(tuple(map(torch.FloatTensor, zip(*sample['bboxes'])))).permute(1, 0)\n            \n        return img, target\n    \n\n    def __len__(self):\n        return self.image_ids.shape[0]","01216916":"# Albumentations\ndef get_train_transform():\n    return A.Compose([\n        Resize(300,  300),\n        A.Flip(0.5),\n        A.RandomRotate90(0.5),\n        MotionBlur(p=0.2),\n        MedianBlur(blur_limit=3, p=0.1),\n        Blur(blur_limit=3, p=0.1),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\ndef get_valid_transform():\n    return A.Compose([\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})","177f4a71":"input_folder = '..\/input\/rsna-pneumonia-detection-2018\/input'\nimages_folder = f\"{input_folder}\/images\/\"\n\nimage_ids = train_labels_df_pos['patientId'].unique()\nvalid_ids = image_ids[-300:]\ntrain_ids = image_ids[:-300]\nprint(f\"Training instance: {len(train_ids)}\")\nprint(f\"Validation instances: {len(valid_ids)}\")\n\nvalid_df = train_labels_df_pos[train_labels_df_pos['patientId'].isin(valid_ids)]\ntrain_df = train_labels_df_pos[train_labels_df_pos['patientId'].isin(train_ids)]\n\nprint('Train dataframe shape:', train_df.shape)\nprint('Valid dataframe shape:', valid_df.shape)\n    \ntrain_dataset = PneumoniaDataset(train_df, images_folder, get_train_transform())\nvalid_dataset = PneumoniaDataset(valid_df, images_folder, get_valid_transform())\nprint('train_dataset and valid_dataset are loaded :)')   \nprint(\"We have: {} training examples and {} validation examples\".format(len(train_dataset), len(valid_dataset)))","5be2657d":"def collate_fn(batch):\n    return tuple(zip(*batch))","ff13a9e0":"train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=2, collate_fn=collate_fn)\nvalid_data_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, num_workers=2, collate_fn=collate_fn)","d78cf339":"def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n    # https:\/\/www.kaggle.com\/sadmanaraf\/wheat-detection-using-faster-rcnn-train\n    \"\"\"Calculates image precision.\n\n    Args:\n        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n               sorted by confidence value (descending)\n        thresholds: (float) Different thresholds\n        form: (str) Format of the coordinates\n\n    Return:\n        (float) Precision\n    \"\"\"\n    n_threshold = len(thresholds)\n    image_precision = 0.0\n    \n    ious = np.ones((len(gts), len(preds))) * -1\n    # ious = None\n\n    for threshold in thresholds:\n        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n                                                     form=form, ious=ious)\n        image_precision += precision_at_threshold \/ n_threshold\n\n    return image_precision\n\n\ndef calculate_iou(gt, pr, form='pascal_voc') -> float:\n    # https:\/\/www.kaggle.com\/sadmanaraf\/wheat-detection-using-faster-rcnn-train\n    \"\"\"Calculates the Intersection over Union.\n\n    Args:\n        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n        form: (str) gt\/pred coordinates format\n            - pascal_voc: [xmin, ymin, xmax, ymax]\n            - coco: [xmin, ymin, w, h]\n    Returns:\n        (float) Intersection over union (0.0 <= iou <= 1.0)\n    \"\"\"\n    if form == 'coco':\n        gt = gt.copy()\n        pr = pr.copy()\n\n        gt[2] = gt[0] + gt[2]\n        gt[3] = gt[1] + gt[3]\n        pr[2] = pr[0] + pr[2]\n        pr[3] = pr[1] + pr[3]\n\n    # Calculate overlap area\n    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n    \n    if dx < 0:\n        return 0.0\n    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n\n    if dy < 0:\n        return 0.0\n\n    overlap_area = dx * dy\n\n    # Calculate union area\n    union_area = (\n            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n            overlap_area\n    )\n\n    return overlap_area \/ union_area\n\n\ndef find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n    # https:\/\/www.kaggle.com\/sadmanaraf\/wheat-detection-using-faster-rcnn-train\n    \"\"\"Returns the index of the 'best match' between the\n    ground-truth boxes and the prediction. The 'best match'\n    is the highest IoU. (0.0 IoUs are ignored).\n\n    Args:\n        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n        pred: (List[Union[int, float]]) Coordinates of the predicted box\n        pred_idx: (int) Index of the current predicted box\n        threshold: (float) Threshold\n        form: (str) Format of the coordinates\n        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n\n    Return:\n        (int) Index of the best match GT box (-1 if no match above threshold)\n    \"\"\"\n    best_match_iou = -np.inf\n    best_match_idx = -1\n    for gt_idx in range(len(gts)):\n        \n        if gts[gt_idx][0] < 0:\n            # Already matched GT-box\n            continue\n        \n        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n\n        if iou < 0:\n            iou = calculate_iou(gts[gt_idx], pred, form=form)\n            \n            if ious is not None:\n                ious[gt_idx][pred_idx] = iou\n\n        if iou < threshold:\n            continue\n\n        if iou > best_match_iou:\n            best_match_iou = iou\n            best_match_idx = gt_idx\n\n    return best_match_idx\n\ndef calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n    # https:\/\/www.kaggle.com\/sadmanaraf\/wheat-detection-using-faster-rcnn-train\n    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n\n    Args:\n        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n               sorted by confidence value (descending)\n        threshold: (float) Threshold\n        form: (str) Format of the coordinates\n        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n\n    Return:\n        (float) Precision\n    \"\"\"\n    n = len(preds)\n    tp = 0\n    fp = 0\n    \n    for pred_idx in range(n):\n\n        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n                                            threshold=threshold, form=form, ious=ious)\n\n        if best_match_gt_idx >= 0:\n            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n            tp += 1\n            # Remove the matched GT box\n            gts[best_match_gt_idx] = -1\n        else:\n            # No match\n            # False positive: indicates a predicted box had no associated gt box.\n            fp += 1\n\n    # False negative: indicates a gt box had no associated predicted box.\n    fn = (gts.sum(axis=1) > 0).sum()\n\n    return tp \/ (tp + fp + fn)\n","e3fec348":"class Averager:\n    def __init__(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total \/ self.iterations\n\n    def reset(self):\n        self.current_total = 0.0\n        self.iterations = 0.0","79859a60":"def train(dataloader, lr_scheduler, model, optimizer, \n          device, epoch, loss_hist, itr):\n    model.train()\n    start = time.time()\n    loss_hist.reset()\n    for images, targets in dataloader:\n        \n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n\n\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n\n        loss_hist.send(loss_value)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if itr % 100 == 0:\n            print(f\"Epoch #{epoch} iteration #{itr} loss: {loss_value}\")\n\n        itr += 1\n    \n    end = time.time()\n    return loss_hist, end, start","9d530a6f":"def validate(dataloader, model, device, iou_thresholds):\n    valid_image_precision = []\n    model.eval()\n    with torch.no_grad():\n        for images, targets in dataloader:\n\n            images = list(image.to(device) for image in images)\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n            outputs = model(images)\n            \n    for i, image in enumerate(images):\n        boxes = outputs[i]['boxes'].data.cpu().numpy()\n        scores = outputs[i]['scores'].data.cpu().numpy()\n        gt_boxes = targets[i]['boxes'].cpu().numpy()\n        preds_sorted_idx = np.argsort(scores)[::-1]\n        preds_sorted = boxes[preds_sorted_idx]\n        image_precision = calculate_image_precision(preds_sorted,\n                                                        gt_boxes,\n                                                        thresholds=iou_thresholds,\n                                                        form='coco')\n        valid_image_precision.append(image_precision)\n\n    valid_prec = np.mean(valid_image_precision)\n    return valid_prec","5017f070":"def get_model():\n    # load an object detection model pre-trained on COCO\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=1024)\n    # one class is pneumonia, and the other is background\n    num_classes = 2\n    # get the number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new on\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n   \n    return model","45d3b95d":"torch.cuda.is_available()","d8f85900":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# learning parameters\nnum_epochs = 30\nlr = 0.001\nbatch_size = 8\n\nmodel = get_model().to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005)\nlr_scheduler = None\n\n# initialize the Averager\nloss_hist = Averager()\niou_thresholds = [x for x in np.arange(0.5, 0.76, 0.05)]","42a1d3e8":"train_loss = []\nprecision = []\nfor epoch in range(num_epochs):\n    itr = 1\n    train_loss_hist, end, start = train(train_data_loader, lr_scheduler,\n                                        model, optimizer, device,\n                                        epoch, loss_hist, itr)\n    valid_prec = validate(valid_data_loader, model, device, iou_thresholds)\n    print(f\"Took {(end-start)\/60:.3f} minutes for epoch# {epoch} to train\")\n    print(f\"Epoch #{epoch} Train loss: {train_loss_hist.value}\")  \n    print(f\"Epoch #{epoch} Validation Precision: {valid_prec}\")  \n    train_loss.append(train_loss_hist.value)\n    precision.append(valid_prec)\n    \n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n","1e1f3a7a":"torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn_pneumonia_detection.pth')","00986919":"# plot the training loss\nplt.figure()\nplt.plot(train_loss, label='Training loss')\nplt.legend()\nplt.show()\n\n# plot the validation precision\nplt.figure()\nplt.plot(precision, label='Validation precision')\nplt.legend()\nplt.show()","5afc87fb":"#uncomment next cells in case of testing\n#commented due to lack of memory","2da3b6e9":"# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# input_folder = '..\/input\/rsna-pneumonia-detection-2018\/input'\n\n# images_test_path = f\"{input_folder}\/samples\"\n# test_images = os.listdir(images_test_path)\n# print(f\"Validation instances: {len(test_images)}\")","c236ade6":"# # load a model; pre-trained on COCO\n# model = get_model()\n\n# # os.makedirs('..\/validation_predictions', exist_ok=True)\n# model.load_state_dict(torch.load('.\/fasterrcnn_resnet50_fpn_pneumonia_detection.pth'))\n# model.to(device)","906ff360":"# def format_prediction_string(boxes, scores):\n#     pred_strings = []\n#     for j in zip(scores, boxes):\n#         pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], \n#                                                              int(j[1][0]), int(j[1][1]), \n#                                                              int(j[1][2]), int(j[1][3])))\n\n#     return \" \".join(pred_strings)","3c88f3d3":"# detection_threshold = 0.8\n# img_num = 0\n# results = []\n# model.eval()\n# with torch.no_grad():\n#     for i, image in tqdm(enumerate(test_images), total=len(test_images)):\n\n#         orig_image = cv2.imread(f\"{images_test_path}\/{test_images[i]}\", cv2.IMREAD_COLOR)\n#         image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n#         image \/= 255.0\n#         image = np.transpose(image, (2, 0, 1)).astype(np.float)\n#         image = torch.tensor(image, dtype=torch.float).cuda()\n#         image = torch.unsqueeze(image, 0)\n\n#         model.eval()\n#         cpu_device = torch.device(\"cpu\")\n\n#         outputs = model(image)\n        \n#         outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n#         if len(outputs[0]['boxes']) != 0:\n#             for counter in range(len(outputs[0]['boxes'])):\n#                 boxes = outputs[0]['boxes'].data.cpu().numpy()\n#                 scores = outputs[0]['scores'].data.cpu().numpy()\n#                 boxes = boxes[scores >= detection_threshold].astype(np.int32)\n#                 draw_boxes = boxes.copy()\n#                 boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n#                 boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n                \n#             for box in draw_boxes:\n#                 cv2.rectangle(orig_image,\n#                             (int(box[0]), int(box[1])),\n#                             (int(box[2]), int(box[3])),\n#                             (0, 0, 255), 3)\n        \n#             plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n#             plt.axis('off')\n#             plt.savefig(f\"{test_images[i]}\")\n#             plt.close()\n                \n#             result = {\n#                 'patientId': test_images[i].split('.')[0],\n#                 'PredictionString': format_prediction_string(boxes, scores)\n#             }\n#             results.append(result)\n#         else:\n#             result = {\n#                 'patientId': test_images[i].split('.')[0],\n#                 'PredictionString': None\n#             }\n#             results.append(result)\n\n# sub_df = pd.DataFrame(results, columns=['patientId', 'PredictionString'])\n# print(sub_df.head())\n# sub_df.to_csv('submission.csv', index=False)","7c144aa6":"# **Helper functions**","7c7ceb1e":"# **Target Distribution**","d5eb8856":"# **Saving**","1fb2cbe8":"# **Preparing data for training. Dataset class. Tranformations**","a705d25a":"# **Plot Loss and Precision**","7643a8b1":"# **Reading the input files**","31cecfee":"# **Test model and make predictions**","d1c0967c":"# **Data Loaders**","695be4b5":"# **Selecting instances with inflammation**","a77a8ef7":"# **Load the model**","007adf84":"# **Train and Validation split**","a65064c0":"# **Importing the required libraries**","abed2409":"# **Visualization of the images and the areas of inflammation**","385e2195":"# **Train and Validate functions**","dd57e16b":"# **Train the model**"}}