{"cell_type":{"46590738":"code","5e81228a":"code","911e1287":"code","b5552963":"code","31f678df":"code","66d32a52":"code","6f47922e":"code","fcc01d2b":"code","b430816d":"code","1680e434":"code","726fa9a3":"code","5dee7243":"code","2919b1e6":"code","7af3781c":"code","2ac48fd8":"code","3706c7c7":"code","b2e41c7a":"code","0671a662":"code","6652ee23":"code","2572b09f":"code","dfb30048":"code","ef841a0d":"code","9c3a61af":"code","7465d504":"code","ce92e3d4":"code","37871c09":"code","0a48b01b":"code","1aea46ce":"code","c871becd":"code","e8cabd65":"code","31f02f05":"code","9810851c":"code","f78de16a":"code","b1be9fc5":"code","fe8192ad":"code","f32ef516":"code","547f3749":"code","09219774":"code","94add02b":"code","9b7fbcfb":"code","d71d5c06":"code","3b65bff1":"code","f27e6900":"code","f315e2fc":"code","cd74f05d":"code","c48bd7d1":"code","96cbae0a":"code","0be7d5ca":"code","7a2b4fd3":"code","d06f591a":"code","e1adb3e5":"code","93c9532f":"code","5dc2ab67":"code","cbb4a045":"code","36465d29":"code","39b5d8eb":"code","88daa9a2":"code","28d845eb":"code","23218c1d":"code","32593ab8":"code","d6193aa7":"code","5866efb8":"code","029bf45e":"code","8d28c6cf":"code","4d3eaea8":"code","615168c0":"code","d396b134":"code","97fa5b60":"code","a6179ecb":"code","b1705139":"code","6c7b400a":"code","8921f99b":"code","b2a6a665":"code","9ace61c2":"code","04546237":"code","0a3668c0":"code","b85ac5f3":"code","8498b34e":"code","4a2bf84e":"code","9aa057b9":"code","16137bad":"code","591dac8a":"code","153da645":"code","f6b37e2c":"code","784c884d":"code","e6bc7f6f":"code","6b014783":"code","70bc2a83":"code","38c41e43":"code","e8e4ec62":"code","0f1d98de":"markdown","101e65dd":"markdown","65de3719":"markdown","23fc3db6":"markdown","49e3e9bc":"markdown","87cb4e8f":"markdown","8b96c31f":"markdown","3609102c":"markdown","62a91be4":"markdown","1dffcc4a":"markdown","fffa492e":"markdown","15fc103d":"markdown"},"source":{"46590738":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","5e81228a":"import warnings\nwarnings.filterwarnings('ignore')","911e1287":"matplotlib.rcParams.update({'font.size': 14})","b5552963":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","31f678df":"train_df = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/train.csv')\ntrain_df.tail()","66d32a52":"train_df.dtypes","6f47922e":"test_df = pd.read_csv(TEST_DATASET_PATH)\ntest_df.tail()","fcc01d2b":"print('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0440\u0435\u0439\u043d\u0435:', train_df.shape[0])\nprint('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0435\u0441\u0442\u0435', test_df.shape[0])","b430816d":"train_df.shape[1] - 1 == test_df.shape[1]","1680e434":"train_df.dtypes","726fa9a3":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","5dee7243":"plt.figure(figsize = (16, 8))\n\ntrain_df['Price'].hist(bins=30)\nplt.ylabel('Count')\nplt.xlabel('Price')\n\nplt.title('Target distribution')\nplt.show()","2919b1e6":"train_df.describe()","7af3781c":"train_df.select_dtypes(include='object').columns.tolist()","2ac48fd8":"train_df['DistrictId'].value_counts()","3706c7c7":"train_df['Ecology_2'].value_counts()","b2e41c7a":"train_df['Ecology_3'].value_counts()","0671a662":"train_df['Shops_2'].value_counts()","6652ee23":"train_df['Rooms'].value_counts()","2572b09f":"train_df['Rooms_outlier'] = 0\ntrain_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1\ntrain_df.head()","dfb30048":"train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1\ntrain_df.loc[train_df['Rooms'] >= 6, 'Rooms'] = train_df['Rooms'].median()","ef841a0d":"train_df['Rooms'].value_counts()","9c3a61af":"train_df['KitchenSquare'].value_counts()","7465d504":"train_df['KitchenSquare'].quantile(.975), train_df['KitchenSquare'].quantile(.025)","ce92e3d4":"condition = (train_df['KitchenSquare'].isna()) \\\n             | (train_df['KitchenSquare'] > train_df['KitchenSquare'].quantile(.975))\n        \ntrain_df.loc[condition, 'KitchenSquare'] = train_df['KitchenSquare'].median()\n\ntrain_df.loc[train_df['KitchenSquare'] < 3, 'KitchenSquare'] = 3","37871c09":"train_df['KitchenSquare'].value_counts()","0a48b01b":"train_df['HouseFloor'].sort_values().unique()","1aea46ce":"train_df['Floor'].sort_values().unique()","c871becd":"(train_df['Floor'] > train_df['HouseFloor']).sum()","e8cabd65":"train_df['HouseFloor_outlier'] = 0\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1\n","31f02f05":"train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor'] = train_df['HouseFloor'].median()","9810851c":"floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\nfloor_outliers","f78de16a":"train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']\\\n                                                .apply(lambda x: random.randint(1, x))","b1be9fc5":"(train_df['Floor'] > train_df['HouseFloor']).sum()","fe8192ad":"train_df['HouseYear'].sort_values(ascending=False)","f32ef516":"train_df.loc[train_df['HouseYear'] > 2020, 'HouseYear'] = 2020","547f3749":"train_df.isna().sum()","09219774":"train_df[['Square', 'LifeSquare', 'KitchenSquare']].head(10)","94add02b":"train_df['LifeSquare_nan'] = train_df['LifeSquare'].isna() * 1\n\ncondition = (train_df['LifeSquare'].isna()) \\\n             & (~train_df['Square'].isna()) \\\n             & (~train_df['KitchenSquare'].isna())\n        \ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","9b7fbcfb":"train_df.drop('Healthcare_1', axis=1, inplace=True)","d71d5c06":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)\n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        # KitchenSquare\n        condition = (X['KitchenSquare'].isna()) \\\n                    | (X['KitchenSquare'] > self.kitchen_square_quantile)\n        \n        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']\n\n        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n                                            .apply(lambda x: random.randint(1, x))\n        \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        condition = (X['LifeSquare'].isna()) & \\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","3b65bff1":"binary_to_numbers = {'A': 0, 'B': 1}\n\ntrain_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)\ntrain_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)\ntrain_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)","f27e6900":"district_size = train_df['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n\ndistrict_size.head()","f315e2fc":"train_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","cd74f05d":"(train_df['DistrictSize'] > 100).value_counts()","c48bd7d1":"train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)","96cbae0a":"med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                            .rename(columns={'Price':'MedPriceByDistrict'})\n\nmed_price_by_district.head()","0be7d5ca":"train_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\ntrain_df.head()","7a2b4fd3":"def floor_to_cat(X):\n\n    X['floor_cat'] = 0\n\n    X.loc[X['Floor'] <= 3, 'floor_cat'] = 1  \n    X.loc[(X['Floor'] > 3) & (X['Floor'] <= 5), 'floor_cat'] = 2\n    X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n    X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n    X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n\n    return X\n\n\ndef floor_to_cat_pandas(X):\n    bins = [0, 3, 5, 9, 15, X['Floor'].max()]\n    X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n    \n    X['floor_cat'].fillna(-1, inplace=True)\n    return X\n\n\ndef year_to_cat(X):\n\n    X['year_cat'] = 0\n\n    X.loc[X['HouseYear'] <= 1941, 'year_cat'] = 1\n    X.loc[(X['HouseYear'] > 1941) & (X['HouseYear'] <= 1945), 'year_cat'] = 2\n    X.loc[(X['HouseYear'] > 1945) & (X['HouseYear'] <= 1980), 'year_cat'] = 3\n    X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4\n    X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5\n    X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6\n\n    return X\n\n\ndef year_to_cat_pandas(X):\n    bins = [0, 1941, 1945, 1980, 2000, 2010, X['HouseYear'].max()]\n    X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n    \n    X['year_cat'].fillna(-1, inplace=True)\n    return X","d06f591a":"bins = [0, 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins, labels=False)","e1adb3e5":"bins = [0, 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins)","93c9532f":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n                \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                                            .rename(columns={'Price':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.house_year_max = df['HouseYear'].max()\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n        \n\n        \n    def transform(self, X):\n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 floor_cat\n        X = self.year_to_cat(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 year_cat\n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X.fillna(self.med_price_by_floor_year_median, inplace=True)\n        \n        return X\n    \n    def floor_to_cat(self, X):\n        bins = [0, 3, 5, 9, 15, self.floor_max]\n        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n\n        X['floor_cat'].fillna(-1, inplace=True) \n        return X\n     \n    def year_to_cat(self, X):\n        bins = [0, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X\n            ","5dc2ab67":"train_df = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/test.csv')\n\npreprocessor = DataPreprocessing()\npreprocessor.fit(train_df)\n\ntrain_df = preprocessor.transform(train_df)\ntest_df = preprocessor.transform(test_df)\ntrain_df.shape, test_df.shape","cbb4a045":"features_gen = FeatureGenetator()\nfeatures_gen.fit(train_df.drop(columns='Price'), train_df['Price'])\n\ntrain_df = features_gen.transform(train_df)\ntest_df = features_gen.transform(test_df)\ntrain_df.shape, test_df.shape","36465d29":"train_df.isna().sum().sum(), test_df.isna().sum().sum()","39b5d8eb":"train_df.columns.tolist()","88daa9a2":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'LifeSquare_nan', 'DistrictSize',\n                     'new_district', 'IsDistrictLarge',  'MedPriceByDistrict', 'MedPriceByFloorYear']\n\ntarget_name = 'Price'","28d845eb":"X = train_df[feature_names + new_feature_names]\ny = train_df[target_name]\n\ntest_df = test_df[feature_names + new_feature_names]","23218c1d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)","32593ab8":"from sklearn import ensemble\nclf = ensemble.GradientBoostingRegressor(n_estimators = 400, max_depth = 4, min_samples_split = 2, learning_rate = 0.1, loss = 'ls')","d6193aa7":"clf.fit(X_train, y_train.values.ravel())","5866efb8":"y_train_preds = clf.predict(X_train)\ny_test_preds = clf.predict(X_test)\n\nevaluate_preds(y_train, y_train_preds, y_test, y_test_preds)","029bf45e":"cv_score = cross_val_score(clf, X, y, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=42))\ncv_score","8d28c6cf":"cv_score.mean()","4d3eaea8":"feature_importances = pd.DataFrame(zip(X_train.columns, clf.feature_importances_), \n                                   columns=['feature_name', 'importance'])\n\nfeature_importances.sort_values(by='importance', ascending=False)","615168c0":"test_df['Rooms_outlier'] = 0\ntest_df.loc[(test_df['Rooms'] == 0) | (test_df['Rooms'] >= 6), 'Rooms_outlier'] = 1\ntest_df.head()","d396b134":"test_df.loc[test_df['Rooms'] == 0, 'Rooms'] = 1\ntest_df.loc[test_df['Rooms'] >= 6, 'Rooms'] = test_df['Rooms'].median()","97fa5b60":"test_df['Rooms'].value_counts()","a6179ecb":"test_df['KitchenSquare'].value_counts()","b1705139":"test_df['KitchenSquare'].quantile(.975), test_df['KitchenSquare'].quantile(.025)","6c7b400a":"condition = (test_df['KitchenSquare'].isna()) \\\n             | (test_df['KitchenSquare'] > test_df['KitchenSquare'].quantile(.975))\n        \ntest_df.loc[condition, 'KitchenSquare'] = test_df['KitchenSquare'].median()\n\ntest_df.loc[train_df['KitchenSquare'] < 3, 'KitchenSquare'] = 3","8921f99b":"test_df['KitchenSquare'].value_counts()","b2a6a665":"test_df['HouseFloor'].sort_values().unique()","9ace61c2":"test_df['Floor'].sort_values().unique()","04546237":"(test_df['Floor'] > test_df['HouseFloor']).sum()","0a3668c0":"test_df['HouseFloor_outlier'] = 0\ntest_df.loc[test_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntest_df.loc[test_df['Floor'] > test_df['HouseFloor'], 'HouseFloor_outlier'] = 1","b85ac5f3":"test_df.loc[test_df['HouseFloor'] == 0, 'HouseFloor'] = test_df['HouseFloor'].median()","8498b34e":"test_df['HouseYear'].sort_values(ascending=False)","4a2bf84e":"test_df.isna().sum()","9aa057b9":"test_df[['Square', 'LifeSquare', 'KitchenSquare']].head(10)","16137bad":"test_df['LifeSquare_nan'] = test_df['LifeSquare'].isna() * 1\n\ncondition = (test_df['LifeSquare'].isna()) \\\n             & (~test_df['Square'].isna()) \\\n             & (~test_df['KitchenSquare'].isna())\n        \ntest_df.loc[condition, 'LifeSquare'] = test_df.loc[condition, 'Square'] \\\n                                            - test_df.loc[condition, 'KitchenSquare'] - 3","591dac8a":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)\n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        # KitchenSquare\n        condition = (X['KitchenSquare'].isna()) \\\n                    | (X['KitchenSquare'] > self.kitchen_square_quantile)\n        \n        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']\n\n        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n                                            .apply(lambda x: random.randint(1, x))\n        \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        condition = (X['LifeSquare'].isna()) & \\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","153da645":"test_df.head()","f6b37e2c":"y_test_preds = clf.predict(X_test)","784c884d":"cv_score = cross_val_score(clf, X, y, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=42))\ncv_score","e6bc7f6f":"cv_score.mean()","6b014783":"submit = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')\nsubmit.head()","70bc2a83":"predictions = clf.predict(test_df)\npredictions","38c41e43":"submit['Price'] = predictions\nsubmit.head()","e8e4ec62":"submit.to_csv('rf_submit.csv', index=False)","0f1d98de":"# 6. \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 train \u0438 test","101e65dd":"**\u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0438 \u0441\u043a\u0440\u0438\u043f\u0442\u043e\u0432**","65de3719":"**\u041f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0442\u0438\u043f\u043e\u0432**","23fc3db6":"# 1. EDA\n\n\n**\u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f**","49e3e9bc":"# 5. \u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","87cb4e8f":"# 7. \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","8b96c31f":"# 4. \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","3609102c":"**\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430**\n\n* Id - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b\n* DistrictId - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0440\u0430\u0439\u043e\u043d\u0430\n* Rooms - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442\n* Square - \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* LifeSquare - \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* KitchenSquare - \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\n* Floor - \u044d\u0442\u0430\u0436\n* HouseFloor - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0434\u043e\u043c\u0435\n* HouseYear - \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043e\u043c\u0430\n* Ecology_1, Ecology_2, Ecology_3 - \u044d\u043a\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* Social_1, Social_2, Social_3 - \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* Healthcare_1, Helthcare_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043e\u0445\u0440\u0430\u043d\u043e\u0439 \u0437\u0434\u043e\u0440\u043e\u0432\u044c\u044f\n* Shops_1, Shops_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043d\u0430\u043b\u0438\u0447\u0438\u0435\u043c \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u043e\u0432, \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u0446\u0435\u043d\u0442\u0440\u043e\u0432\n* Price - \u0446\u0435\u043d\u0430 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b","62a91be4":"# 3. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","1dffcc4a":"# 2. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432","fffa492e":"**\u041d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435**","15fc103d":"**\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435**"}}