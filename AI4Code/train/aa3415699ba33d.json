{"cell_type":{"b489199b":"code","6f799b65":"code","d7719683":"code","5a446108":"code","a32882f6":"code","593926c3":"code","8e12331f":"code","a0726135":"code","990ce4a9":"code","760449e1":"code","94988638":"code","d132c1b5":"code","2de45d7b":"code","4b6625a9":"markdown","98cef79a":"markdown","0f517b7f":"markdown","8fb562b2":"markdown"},"source":{"b489199b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # drawing graphs and images\nimport tensorflow as tf # data processing, modeling\nfrom tensorflow.keras.preprocessing.image import NumpyArrayIterator, ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array\ntf.enable_eager_execution() # will reduce memory footprint when working with numpy arrays\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6f799b65":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","d7719683":"print('Train head: {}'.format(train_df.head()))\nprint('Test head: {}'.format(test_df.head()))\nprint('------')\ntrain_shape = train_df.shape\ntest_shape = test_df.shape\nprint('Train: {}'.format(train_shape))\nprint('Test: {}'.format(test_shape))","5a446108":"num_training_examples = train_shape[0]\nnum_test_examples = test_shape[0]\n\n# Create a train and test dataset\n# Select all rows and columns but first column, which is the label for the given image data\ntraining_examples = tf.convert_to_tensor(train_df.iloc[:, 1:].values)\ntraining_labels = tf.convert_to_tensor(train_df.iloc[:, :1].values)\ntrain_dataset = tf.data.Dataset.from_tensor_slices((training_examples, training_labels))\n\ntesting_examples = tf.convert_to_tensor(test_df.values)\ntest_dataset = tf.data.Dataset.from_tensor_slices(testing_examples)\n\n# Normalize the pixel values between 0 and 1 (smaller values play nice with the model we'll build)\ndef normalize(images, labels):\n    images = tf.cast(images, tf.float32)\n    images \/= 255\n    return images, labels\n\ndef normalize_unlabled(images):\n    images = tf.cast(images, tf.float32)\n    images \/= 255\n    return images\n\ntrain_dataset = train_dataset.map(normalize)\ntest_dataset =  test_dataset.map(normalize_unlabled)","a32882f6":"# We're dealing with square images, so let's calculate the size of each image\nIMG_SIZE = int(np.sqrt(len(training_examples[0])))\n\n# Take a single image and format it\nfor image in test_dataset.take(1):\n    break\nimage = image.numpy().reshape((IMG_SIZE, IMG_SIZE))\n\n# Plot the image\nplt.figure()\nplt.imshow(image, cmap=plt.cm.binary)\nplt.colorbar()\nplt.grid(False)\nplt.show()","593926c3":"# Looks like our test dataset is formatted correctly so\n# take a look at the training data\nplt.figure(figsize=(10,10))\ni = 0\nfor (image, label) in train_dataset.take(20):\n    image = image.numpy().reshape((IMG_SIZE, IMG_SIZE))\n    plt.subplot(5,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(image, cmap=plt.cm.binary)\n    plt.xlabel(label.numpy()[0], fontsize=16)\n    i += 1\nplt.show()","8e12331f":"BATCH_SIZE = 32 # 32 - 512 is a good range\n\n# Last step is creating a validation dataset\n# which we can use to monitor our training progress.\n# We'll use 80% of the data for training\ntrain_split = int(0.8 * num_training_examples)\nvalidation_dataset = train_dataset.skip(train_split).batch(BATCH_SIZE)\ntrain_dataset = train_dataset.take(train_split).repeat().shuffle(train_split).batch(BATCH_SIZE)","a0726135":"flat_model = tf.keras.Sequential([\n    tf.keras.layers.Dense(32, input_shape=(784,)),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n])\n\nflat_model.summary()\n\nflat_model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = flat_model.fit(train_dataset,\n               epochs=6,\n               steps_per_epoch=np.ceil(num_training_examples\/BATCH_SIZE),\n               validation_data=validation_dataset,\n               validation_steps=np.ceil((num_training_examples-train_split)\/BATCH_SIZE))","990ce4a9":"x = test_dataset.batch(num_test_examples)\npredictions = flat_model.predict(x)\n\ndef plot_image(i, predictions_array, images):\n  predictions_array, img = predictions_array[i], images[i].numpy().reshape((IMG_SIZE, IMG_SIZE))\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  color = 'green'\n  \n  plt.xlabel(\"{} {:2.0f}%\".format(predicted_label,\n                                100*np.max(predictions_array),\n                                color=color))\n\nnum_rows = 5\nnum_cols = 5\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, num_cols, i+1)\n  plot_image(i, predictions, testing_examples)","760449e1":"# Get predicted labels\npredicted_labels = [np.argmax(prediction) for prediction in predictions]\n\n# Create submission\nnp.savetxt('submission.csv', \n           np.c_[range(1,num_test_examples+1),predicted_labels], \n           delimiter=',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt='%d')","94988638":"# Leverage TensorFlow (Keras) image pre-processing and data augmentation capabilities\nimage_gen_train = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=10,\n#       width_shift_range=0.15,\n#       height_shift_range=0.15,\n      zoom_range=0.1,\n      fill_mode='nearest',\n      validation_split=0.9\n)\n\ntrain_imgs = np.asarray([img.reshape((IMG_SIZE, IMG_SIZE, 1)) for img in train_df.iloc[:, 1:].values])\ntrain_labels = train_df.iloc[:, :1]\ntrain_img_gen = NumpyArrayIterator(train_imgs, train_labels, shuffle=True, subset='training', batch_size=BATCH_SIZE, image_data_generator=image_gen_train)\nval_img_gen = NumpyArrayIterator(train_imgs, train_labels, subset='validation', batch_size=BATCH_SIZE, image_data_generator=image_gen_train)\n\n# Plot images from an array\ndef plot_images(images_arr):\n    fig, axes = plt.subplots(1, 4, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(array_to_img(img))\n    plt.tight_layout()\n    plt.show()\n\n# Pull sample data from generator to show how same image may be augemented\naugmented_images = [train_img_gen[0][0][0] for i in range(10)]\nplot_images(augmented_images)\n\nconv_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Compile the model\nconv_model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nconv_model.summary()\n\nepochs = 3\nsteps_per_epoch=int(np.ceil(len(train_imgs) \/ float(BATCH_SIZE)))\nvalidation_steps=int(np.ceil(len(train_imgs)*0.8) \/ float(BATCH_SIZE))\n\nhistory = conv_model.fit_generator(\n    train_img_gen,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n    validation_data=val_img_gen,\n    validation_steps=validation_steps\n)","d132c1b5":"z = np.asarray([img.reshape((IMG_SIZE, IMG_SIZE, 1))\/255.0 for img in test_df.values])\nconv_predictions = conv_model.predict(z)\n\ndef plot_conv_image(i, predictions_array, images):\n  predictions_array, img = predictions_array[i], images[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(array_to_img(img), cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  color = 'blue'\n  \n  plt.xlabel(\"{} {:2.0f}%\".format(predicted_label,\n                                100*np.max(predictions_array),\n                                color=color))\n\nnum_rows = 5\nnum_cols = 5\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, num_cols, i+1)\n  plot_conv_image(i, conv_predictions, z)","2de45d7b":"# Get predicted labels\nconv_predicted_labels = [np.argmax(prediction) for prediction in conv_predictions]\n\n# Create submission\nnp.savetxt('conv_submission.csv', \n           np.c_[range(1,len(conv_predicted_labels)+1),predicted_labels], \n           delimiter=',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt='%d')","4b6625a9":"# Looking at the results","98cef79a":"# Get the data, examine it, and shape it","0f517b7f":"# Another Approach: Using a CNN","8fb562b2":"# Create, train, and test the model"}}