{"cell_type":{"c42ce26b":"code","f4479347":"code","d36510be":"code","e640d571":"code","ea44efa3":"code","6ac46c5a":"code","180f11e5":"code","296c17e5":"code","af224004":"code","e347501d":"code","9895ed46":"code","dc5be13c":"code","d8e4e996":"code","38254a2b":"code","bc9f8643":"code","013556f3":"markdown","8179d0de":"markdown","362f7629":"markdown","8a786494":"markdown","0653596e":"markdown","ddc822ab":"markdown","c17d92a7":"markdown","ed2ccb40":"markdown"},"source":{"c42ce26b":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport re\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","f4479347":"data_directory = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\ninput_monaipath = \"\/kaggle\/input\/monai-v060-deep-learning-in-healthcare-imaging\/MONAI-0.7.0\"\nmonaipath = \"\/kaggle\/tmp\/monai\/\"","d36510be":"!mkdir -p {monaipath}\n!cp -r {input_monaipath}\/* {monaipath}","e640d571":"mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\nSIZE = 256\nNUM_IMAGES = 64\nBATCH_SIZE = 4\nN_EPOCHS = 16\nSEED = 12345\nLEARNING_RATE = 0.0005\nLR_DECAY = 0.9\n\nsys.path.append(monaipath)\n\nfrom monai.networks.nets.densenet import DenseNet121","ea44efa3":"def load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if np.min(data)==np.max(data):\n        data = np.zeros((img_size,img_size))\n        return data\n    \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\n\ndef natural_sort(l): \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(l, key=alphanum_key)\n\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n    files = natural_sort(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"))\n    \n    every_nth = len(files) \/ num_imgs\n    indexes = [min(int(round(i*every_nth)), len(files)-1) for i in range(0,num_imgs)]\n    \n    files_to_load = [files[i] for i in indexes]\n    \n    img3d = np.stack([load_dicom_image(f) for f in files_to_load]).T \n    \n    img3d = img3d - np.min(img3d)\n    if np.max(img3d) != 0:\n        img3d = img3d \/ np.max(img3d)\n    \n    return np.expand_dims(img3d,0)\n\n\nload_dicom_images_3d(\"00000\", mri_type=mri_types[0]).shape","6ac46c5a":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(SEED)","180f11e5":"samples_to_exclude = [109, 123, 709]\n\ntrain_df = pd.read_csv(f\"{data_directory}\/train_labels.csv\")\nprint(\"original shape\", train_df.shape)\ntrain_df = train_df[~train_df.BraTS21ID.isin(samples_to_exclude)]\nprint(\"new shape\", train_df.shape)\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=SEED, \n    stratify=train_df[\"MGMT_value\"],\n)\n","296c17e5":"df_train.tail()","af224004":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type, split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type, split=\"train\")\n            \n        if self.targets is None:\n            return {\"X\": data, \"id\": scan_id}\n        else:\n            return {\"X\": data, \"y\": torch.tensor(self.targets[index], dtype=torch.float)}\n","e347501d":"def build_model():\n    model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=1)\n    return model    ","9895ed46":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=LR_DECAY)\n        self.criterion = criterion\n\n        self.best_valid_score = .0\n        self.n_patience = 0\n        self.lastmodel = None\n        \n        self.val_losses = []\n        self.train_losses = []\n        self.val_auc = []\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):      \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n            \n            self.train_losses.append(train_loss)\n            self.val_losses.append(valid_loss)\n            self.val_auc.append(valid_auc)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s\",\n                n_epoch, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_loss, valid_auc, valid_time\n            )\n\n            if self.best_valid_score < valid_auc: \n                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n                self.info_message(\n                     \"auc improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_auc, self.lastmodel\n                )\n                self.best_valid_score = valid_auc\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = torch.tensor(batch[\"X\"]).float().to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            loss = self.criterion(outputs, targets)\n                \n            loss.backward()\n\n            sum_loss += loss.detach().item()\n            \n            self.optimizer.step()\n            \n            message = 'Train Step {}\/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss\/step, end=\"\\r\")\n            \n        self.lr_scheduler.step()\n        \n        return sum_loss\/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                targets = batch[\"y\"].to(self.device)\n\n                output = self.model(torch.tensor(batch[\"X\"]).float().to(self.device)).squeeze(1)\n                loss = self.criterion(output, targets)\n                sum_loss += loss.detach().item()\n                output = torch.sigmoid(output)\n\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(output.tolist())\n\n            message = 'Valid Step {}\/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss\/step, end=\"\\r\")\n            \n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return sum_loss\/len(valid_loader), auc, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss, auc):\n        self.lastmodel = f\"{save_path}-e{n_epoch}-loss{loss:.3f}-auc{auc:.3f}.pth\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n        \n    def display_plots(self, mri_type):\n        plt.figure(figsize=(10,5))\n        plt.title(\"{}: Training and Validation Loss\")\n        plt.plot(self.val_losses,label=\"val\")\n        plt.plot(self.train_losses,label=\"train\")\n        plt.xlabel(\"iterations\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.show()\n        plt.close()\n        \n        plt.figure(figsize=(10,5))\n        plt.title(\"{}: Validation AUC-ROC\")\n        plt.plot(self.val_auc,label=\"val\")\n        plt.xlabel(\"iterations\")\n        plt.ylabel(\"AUC\")\n        plt.legend()\n        plt.show()\n        plt.close()\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","dc5be13c":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_mri_type(df_train, df_valid, mri_type):\n    print(df_train.shape, df_valid.shape)\n    display(df_train.head())\n    display(df_valid.head())\n    \n    train_data_retriever = Dataset(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        mri_type\n    )\n\n    valid_data_retriever = Dataset(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        mri_type\n    )\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=8,\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    model = build_model()\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion\n    )\n\n    history = trainer.fit(\n        N_EPOCHS, \n        train_loader, \n        valid_loader, \n        f\"{mri_type}\", \n        N_EPOCHS,\n    )\n    \n    trainer.display_plots(mri_type)\n    \n    return trainer.lastmodel\n\nmodelfiles = None\n\nif not modelfiles:\n    modelfiles = [train_mri_type(df_train, df_valid, m) for m in mri_types]\n    print(modelfiles)","d8e4e996":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=mri_type,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = build_model()\n    model.to(device)\n    \n    checkpoint = torch.load(modelfile)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(torch.tensor(batch[\"X\"]).float().to(device)).squeeze(1)).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","38254a2b":"df_pred = df_valid.set_index(\"BraTS21ID\")\ndf_pred[\"MGMT_pred\"] = 0\nfor m, mtype in zip(modelfiles,  mri_types):\n    pred = predict(m, df_pred, mtype, \"train\")\n    df_pred[\"MGMT_pred\"] += pred[\"MGMT_value\"]\ndf_pred[\"MGMT_pred\"] \/= len(modelfiles)\nauc = roc_auc_score(df_pred[\"MGMT_value\"], df_pred[\"MGMT_pred\"])\nprint(f\"Validation ensemble AUC: {auc:.4f}\")\nsns.displot(df_pred[\"MGMT_pred\"])","bc9f8643":"submission = pd.read_csv(f\"{data_directory}\/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\nsubmission[\"MGMT_value\"] \/= len(modelfiles)\nsubmission[\"MGMT_value\"].to_csv(\"submission.csv\")","013556f3":"**Submission**","8179d0de":"## Use stacked images (3D) and Densenet121 3D model\n\nAcknowledgements:\n\n- https:\/\/www.kaggle.com\/rluethy\/efficientnet3d-with-one-mri-type\n- https:\/\/www.kaggle.com\/davidbroberts\/determining-dicom-image-order\n- https:\/\/www.kaggle.com\/ihelon\/brain-tumor-eda-with-animations-and-modeling\n- https:\/\/www.kaggle.com\/furcifer\/torch-efficientnet3d-for-mri-no-train\n- https:\/\/github.com\/shijianjian\/EfficientNet-PyTorch-3D\n\nThis notebook is based on the implementation of Densenet121 3D available here:\nhttps:\/\/www.kaggle.com\/mikecho\/monai-v060-deep-learning-in-healthcare-imaging\n\nIt builds 4 models with only one MRI type, then ensembles all of them computing average probabilities\n","362f7629":"## Functions to load images","8a786494":"## train \/ test splits","0653596e":"## train models","ddc822ab":"## Model and training classes","c17d92a7":"# Prediction","ed2ccb40":"**Validation**"}}