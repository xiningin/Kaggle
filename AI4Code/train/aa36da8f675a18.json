{"cell_type":{"75c0e506":"code","5e736b58":"code","965f0599":"code","a131a27f":"code","ac2d0787":"code","4b66c1bb":"code","ebcc1624":"code","91fb65b8":"code","df0edfd9":"markdown","d0bbe70a":"markdown"},"source":{"75c0e506":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n\n\nimport numpy as np\nimport tensorflow as tf\nimport keras\nimport pandas as pd\nimport zipfile\nimport cv2\nimport sklearn.model_selection\nfrom keras import backend as K\nfrom keras.utils import to_categorical\n\n\n#dl libraraies\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n\n# specifically for cnn\nfrom tensorflow.keras.layers import Dropout, Flatten,Activation\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","5e736b58":"data = pd.read_csv('\/kaggle\/input\/game-of-deep-learning-ship-datasets\/train\/train.csv')\ntrain_images = pd.read_csv('\/kaggle\/input\/game-of-deep-learning-ship-datasets\/train\/train.csv')\ntest_images = pd.read_csv('\/kaggle\/input\/game-of-deep-learning-ship-datasets\/test_ApKoW4T.csv')\nlabel = np.array(data['category'])","965f0599":"def resize():\n    res_img =[]\n    train_img = np.array(train_images['image'])\n    \n    for i in train_img:\n        try:\n            images = cv2.imread('\/kaggle\/input\/game-of-deep-learning-ship-datasets\/train\/images\/'+i , 1)\n            res = cv2.resize(images , (200,150))\n            res_img.append(res)\n        except Exception as e:\n            print(str(e))\n    res_img = np.array(res_img)\n    return res_img\n\nz = resize()\n\n\n","a131a27f":"#Train-Test Split \n\nlabel = to_categorical(label)\nx_train , x_test , y_train , y_test = sklearn.model_selection.train_test_split(z , label , test_size=0.1)\nprint(x_train.shape , y_train.shape)\nprint(x_test.shape , y_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n#Normalization\n\nx_train = x_train\/255.0\nx_test = x_test\/255.0","ac2d0787":"\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,200,3))\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- we have 6 classes\npredictions = Dense(6, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all VGG16 convolutional layers\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","4b66c1bb":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally \n        height_shift_range=0.2,  # randomly shift images vertically \n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)\n","ebcc1624":"model.fit(datagen.flow(x_train, y_train, batch_size=32),\n          steps_per_epoch=len(x_train) \/ 32, epochs=50)","91fb65b8":"model.evaluate(x_test,y_test)","df0edfd9":"# Transfer learning from pre-trained model","d0bbe70a":"# DATA AUGMENTATION"}}