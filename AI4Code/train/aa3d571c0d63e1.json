{"cell_type":{"b3099897":"code","b9b3268f":"code","7ca2a84e":"code","40fcb20a":"code","ada327d7":"code","10b4a4fd":"code","25f43b0c":"code","34b78273":"code","f21f1e0c":"code","6d62f480":"code","123cb10c":"code","138d1a26":"code","2056864a":"code","e2f3be17":"code","235670ed":"code","b3f9a262":"code","213fb748":"code","a40ec63c":"code","8d233e9c":"code","6396dbbf":"code","d614fc72":"code","ca97b324":"code","bbfb7e6d":"code","5573c5e1":"code","2cc1f707":"code","8201e0b2":"code","8c4c0a29":"code","b4992897":"code","c5ea8232":"code","364e9134":"code","d490e9f3":"code","6d8ba261":"code","1e80f65f":"code","70daf83b":"code","cc3026dd":"code","560d7077":"code","51638b18":"code","a805898e":"code","61aa346f":"code","0141ea5d":"code","53ffac91":"code","d9d03d1b":"code","c6276ad5":"code","3089ad2f":"code","7090174c":"code","1c2ffe27":"code","dd0cf769":"code","035cb7da":"code","fb428fc6":"code","67820ff9":"code","99cac958":"code","880b27a2":"code","bf31bd0f":"code","bd3356cb":"code","5b026b3c":"code","7634c608":"code","635856cc":"code","e8bebb2c":"code","5726f966":"code","80ec1ce9":"code","1878bfae":"code","5708cbf6":"code","df272c30":"code","89a88768":"code","f66ba329":"code","5942d6ba":"code","3e357dc9":"code","a1acc83f":"code","3c9a495f":"code","eb8029af":"code","d70b3622":"code","b1fe3854":"code","2306261d":"code","e28ae35b":"code","14dd8936":"code","bd23f690":"code","91de1aff":"code","857e40df":"code","2dde75f6":"code","e4bcfd5e":"code","d4d8ee70":"code","a2f4a354":"code","7b72491b":"code","b13ae813":"code","ef17ee04":"code","c263ead7":"code","a6b66ac8":"code","55906f33":"code","d920b254":"code","4b65b5dd":"code","566a3eb0":"code","5f4fd584":"code","459f6136":"code","f19e67f8":"code","4946ba28":"code","c246b8b6":"code","368f6736":"code","6834fea3":"code","1c9dbfa0":"code","85285fdc":"code","ae6f767c":"code","3cf41a2e":"code","f63af2aa":"code","19c915ee":"code","f418f92b":"markdown","20c86ea2":"markdown","7aed2ce7":"markdown","d309122d":"markdown","1f65b9dc":"markdown","47be903d":"markdown","5f916488":"markdown","13596153":"markdown","59b34097":"markdown","501a4ba6":"markdown","1a520bd0":"markdown","b53d25ff":"markdown","e38ba2af":"markdown","ec9ded41":"markdown","1f62fc91":"markdown","5f3ca135":"markdown","6182c8d6":"markdown","fdb53bd0":"markdown","b5c4ea8c":"markdown","1968adaa":"markdown","1ac25244":"markdown","6abbf642":"markdown","b2a1859d":"markdown","22e7699c":"markdown","7a243c77":"markdown","30d41106":"markdown","d9599df4":"markdown","9c90fce4":"markdown","351e587d":"markdown","12835bac":"markdown","be900e7b":"markdown","4a24d79e":"markdown","7b9979e3":"markdown","b55405e9":"markdown","9b1c5759":"markdown","9ab0d4a4":"markdown","f4a283f4":"markdown","5ff29d04":"markdown"},"source":{"b3099897":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9b3268f":"\n\n%matplotlib inline\n\nimport math, time, random, datetime\n\nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\nimport time\ndef timer(self, threshold):\n    if (time.time() - self.lastTime) > threshold:\n        self.lastTime = time.time()\n        return True\n    else:\n        return False\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","7ca2a84e":"df_gender=pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\ndf_test=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndf_train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","40fcb20a":"len(df_gender) #length of gender table\n","ada327d7":"len(df_test)  #lenght of test table","10b4a4fd":"len(df_train) #length of train table","25f43b0c":"df_train.head(11)","34b78273":"df_test.head(11)","f21f1e0c":"df_gender.head(11)","6d62f480":"df_gender.describe().columns\n","123cb10c":"df_train.describe().columns\n","138d1a26":"df_test.describe().columns\n","2056864a":"df_num = df_train[['Age','SibSp','Parch','Fare','Survived']]\ndf_cat = df_train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","e2f3be17":"for i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","235670ed":"\nprint(df_num.corr())\nsns.heatmap(df_num.corr())","b3f9a262":"for i in df_cat.columns:\n    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n    plt.show()","213fb748":"for n in df_num.columns:\n    sns.barplot(df_num[n].value_counts().index,df_num[n].value_counts()).set_title(n)\n    plt.show()","a40ec63c":"missingno.matrix(df_train, figsize = (16,20))","8d233e9c":"df_train.isnull().sum()","6396dbbf":"df_bin=pd.DataFrame()\ndf_con=pd.DataFrame()","d614fc72":"df_train.dtypes\n","ca97b324":"df_train.Survived.isnull().sum()","bbfb7e6d":"df_train.Survived.value_counts()       # count or number of survived passanger\n","5573c5e1":"sns.set(style='dark')\nax=sns.countplot(y='Survived' ,palette='gist_rainbow_r', data=df_train);","2cc1f707":"sns.distplot(df_train.Survived , color = 'g')","8201e0b2":"df_bin['Survived'] = df_train['Survived']\ndf_con['Survived'] = df_train['Survived']   #add data to our subset dataframes","8c4c0a29":"df_train.Pclass.isnull().sum()","b4992897":"sns.set(style='dark')\nax=sns.countplot(y='Pclass' ,palette='gist_rainbow', data=df_train);","c5ea8232":"sns.distplot(df_train.Pclass)","364e9134":"df_bin[\"Pclass\"]=df_train[\"Pclass\"]\ndf_con[\"Pclass\"]=df_train[\"Pclass\"]  # #add data to our subset dataframes","d490e9f3":"df_train.Name.isnull().sum()\n","6d8ba261":"df_train.Sex.isnull().sum()","1e80f65f":"plt.figure(figsize=(20,2))\nsns.countplot(y='Sex' , data=df_train , palette='RdPu_r')\nsns.set(style=\"darkgrid\")","70daf83b":"df_bin['Sex'] = df_train['Sex']\ndf_bin['Sex'] = np.where(df_bin['Sex'] == 'female', 1, 0) # change sex to 0 for male and 1 for female\n\ndf_con['Sex'] = df_train['Sex']","cc3026dd":"df_train.Age.isnull","560d7077":"ax=df_train.Age.isnull().sum() # total of age null value","51638b18":"total=df_train.Age.count()  # ototal of age with null and filled value","a805898e":"filled=total-ax\nfilled                    #diference between total of age - null value","61aa346f":"sns.distplot(df_train.Age)","0141ea5d":"df_train.SibSp.count()","53ffac91":"df_train.SibSp.isnull().sum()","d9d03d1b":"df_train.SibSp.value_counts()","c6276ad5":"plt.figure(figsize=(4,10))\n\nplt.title(\"SibSp  , by Survived\")\n\nsns.barplot(x=df_train.SibSp , y=df_train.Survived)\n\nplt.ylabel(\" Average Children\")","3089ad2f":"df_bin['SibSp'] = df_train['SibSp']\ndf_con['SibSp'] = df_train['SibSp'] #add data to our subset dataframes","7090174c":"\ndef plot_count_dist(data, bin_df, label_column, target_column, figsize=(20, 5), use_bin_df=False):\n    \"\"\"\n    Function to plot counts and distributions of a label variable and \n    target variable side by side.\n    ::param_data:: = target dataframe\n    ::param_bin_df:: = binned dataframe for countplot\n    ::param_label_column:: = binary labelled column\n    ::param_target_column:: = column you want to view counts and distributions\n    ::param_figsize:: = size of figure (width, height)\n    ::param_use_bin_df:: = whether or not to use the bin_df, default False\n    \"\"\"\n    if use_bin_df: \n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=bin_df);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={\"label\": \"Did not survive\"});\n    else:\n        fig = plt.figure(figsize=figsize)\n        plt.subplot(1, 2, 1)\n        sns.countplot(y=target_column, data=data);\n        plt.subplot(1, 2, 2)\n        sns.distplot(data.loc[data[label_column] == 1][target_column], \n                     kde_kws={\"label\": \"Survived\"});\n        sns.distplot(data.loc[data[label_column] == 0][target_column], \n                     kde_kws={\"label\": \"Did not survive\"});","1c2ffe27":"df_train.Parch.isnull().sum()","dd0cf769":"plot_count_dist(df_train, \n                bin_df=df_bin, \n                label_column='Survived', \n                target_column='SibSp', \n                figsize=(20, 10))","035cb7da":"df_bin['Parch'] = df_train['Parch']\ndf_con['Parch'] = df_train['Parch']","fb428fc6":"df_train.Fare.isnull().sum()","67820ff9":"plot_count_dist(df_train, \n                bin_df=df_bin, \n                label_column='Fare', \n                target_column='SibSp', \n                figsize=(10, 5))","99cac958":"df_bin['Fare'] = df_train['Fare']\ndf_con['Fare'] = df_train['Fare']","880b27a2":"df_train.Embarked.isnull().sum()","bf31bd0f":"df_bin['Embarked'] = df_train['Embarked']\n\ndf_con['Embarked'] = df_train['Embarked']","bd3356cb":"print(len(df_con))\ndf_con = df_con.dropna(subset=['Embarked'])\ndf_bin = df_bin.dropna(subset=['Embarked'])\nprint(len(df_con))","5b026b3c":"sns.countplot(y='Embarked', data=df_train);","7634c608":"df_bin.head()","635856cc":"encode = df_bin.columns.tolist()\nencode.remove('Survived')\ndf_binencode = pd.get_dummies(df_bin, columns=encode)\n\ndf_binencode.head()","e8bebb2c":"df_con.head()","5726f966":"df_embarked_one_hot = pd.get_dummies(df_con['Embarked'], \n                                     prefix='embarked')\n\ndf_sex_one_hot = pd.get_dummies(df_con['Sex'], \n                                prefix='sex')\n\ndf_plcass_one_hot = pd.get_dummies(df_con['Pclass'], \n                                   prefix='pclass')","80ec1ce9":"df_con_enc = pd.concat([df_con, \n                        df_embarked_one_hot, \n                        df_sex_one_hot, \n                        df_plcass_one_hot], axis=1)\n\n# Drop the original categorical columns (because now they've been one hot encoded)\ndf_con_enc = df_con_enc.drop(['Pclass', 'Sex', 'Embarked'], axis=1)","1878bfae":"df_con_enc.tail()","5708cbf6":"df_con_enc.describe()","df272c30":"df_con_enc.count()","89a88768":"df_con_enc","f66ba329":"ML = df_con_enc","5942d6ba":"ML.shape","3e357dc9":"ML","a1acc83f":"ML.tail()","3c9a495f":"X_train=ML.drop(\"Survived\" , axis=1)\ny_train=ML.Survived","eb8029af":"X_train.shape  ##ROW AND COLUMBS OF X_train","d70b3622":"y_train.shape  ## ROWS OF y_train\/?","b1fe3854":"def fit_ml_algo(algo, X_train, y_train, cv):\n    \n    # One Pass\n    model = algo.fit(X_train, y_train)\n    acc = round(model.score(X_train, y_train) * 100, 2)\n    \n    # Cross Validation \n    train_pred = model_selection.cross_val_predict(algo, \n                                                  X_train, \n                                                  y_train, \n                                                  cv=cv, \n                                                  n_jobs = -1)\n    # Cross-validation accuracy metric\n    acc_cv = round(metrics.accuracy_score(y_train, train_pred) * 100, 2)\n    \n    return train_pred, acc, acc_cv","2306261d":"start=time.time()\ntrain_pred_log, acc_log, acc_cv_log = fit_ml_algo(LogisticRegression(),X_train,y_train,10)\nlog=(time.time()- start)\nprint(\"Accuracy:%s \"  %acc_log)\nprint(\"Accuracy CV 10-Fold :%s\" %acc_cv_log)\nprint(\"Running time:%s\" %datetime.timedelta(seconds=log))","e28ae35b":"start_time = time.time()\ntrain_pred_svc, acc_linear_svc, acc_cv_linear_svc = fit_ml_algo(LinearSVC(),\n                                                                X_train, \n                                                                y_train, \n                                                                10)\nlinear_svc_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_linear_svc)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_linear_svc)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=linear_svc_time))","14dd8936":"import time","bd23f690":"start_time = time.time()\ntrain_pred_dt, acc_dt, acc_cv_dt = fit_ml_algo(DecisionTreeClassifier(), \n                                                                X_train, \n                                                                y_train,\n                                                                10)\ndt_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_dt)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_dt)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=dt_time))","91de1aff":"X_train.head()","857e40df":"X_train.tail()","2dde75f6":"y_train.describe()","e4bcfd5e":"features=np.where(X_train.dtypes  != np.float)[0]\nfeatures","d4d8ee70":"pool_data=Pool(X_train ,  y_train , features)","a2f4a354":"Model=CatBoostClassifier(iterations=5000,custom_loss=['Accuracy'])","7b72491b":"Model.fit(pool_data,plot=True)","b13ae813":"metrics = ['Precision', 'Recall', 'F1', 'AUC']\n\neval_metrics = Model.eval_metrics(pool_data,metrics=metrics,plot=True)\nfor metric in metrics:\n    print(str(metric)+\": {}\".format(np.mean(eval_metrics[metric])))","ef17ee04":"X_train.head()","c263ead7":"df_test.head()\n","a6b66ac8":"df_test_embarked = pd.get_dummies(df_test['Embarked'], prefix='embarked')\n\ndf_test_sex = pd.get_dummies(df_test['Sex'], prefix='sex')\n\ndf_test_plcass = pd.get_dummies(df_test['Pclass'],prefix='pclass')","55906f33":"final= pd.concat([df_test, \n                  df_test_embarked, \n                  df_test_sex, \n                  df_test_plcass], axis=1)","d920b254":"final.head","4b65b5dd":"final.tail()","566a3eb0":"final.describe()","5f4fd584":"wante = X_train.columns\nwante","459f6136":"predict = Model.predict(final[wante])","f19e67f8":"predict[:2000]","4946ba28":"submit = pd.DataFrame()\nsubmit['PassengerId'] = df_test['PassengerId']\nsubmit['Survived'] = predict # our model predictions on the test dataset\n","c246b8b6":"submit","368f6736":"submit.columns","6834fea3":"submit['Survived'] = submit['Survived'].astype(int)  #convert our submission dataframe 'Survived' column to ints\nprint('DONE')","1c9dbfa0":"if len(submit) == len(df_test):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submit)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","85285fdc":"#Convert submisison dataframe to csv for submission to csv \n# for Kaggle submisison\nsubmit.to_csv('..\/catboost_submission.csv', index=False)\nprint('Submission is ready!')","ae6f767c":"\n# Check the submission csv to make sure it's in the right format\nsubmissions_check = pd.read_csv(\"..\/catboost_submission.csv\")\nsubmissions_check.head()","3cf41a2e":"\nfinal_submit=pd.read_csv(\"..\/catboost_submission.csv\")","f63af2aa":"final_submit","19c915ee":"final_submit.head","f418f92b":"### Name","20c86ea2":"VARIABLE DESCRIPTIONS:\n* survival    :   Survival\n                (0 = No; 1 = Yes)\n                 \n* pclass       :   Passenger Class\n                 (1 = 1st; 2 = 2nd; 3 = 3rd)\n                 \n* name         :  Name\n* sex          :  Sex\n*  age         :   Age\n \n* sibsp        :  Number of Siblings\/Spouses Aboard\n* parch        :  Number of Parents\/Children Aboard\n \n* ticket       :  Ticket Number\n* fare         :  Passenger Fare\n* cabin        :   Cabin\n* embarked     : Port of Embarkation\n                 (C = Cherbourg; Q = Queenstown; S = Southampton)","7aed2ce7":"# CatBoost ","d309122d":"### SibSp or Sibling ","1f65b9dc":"THE BLACK SHOWED FILLED DATA AND  THE WHITE SPACES SHOWS THE FIELDS WITH NULL VALUE , WE CAN SEE THAT AGE AND CABIN HAVE LOTS OF MISSING AND INCONSISTANT DATA\n","47be903d":"## Pclass","5f916488":"# Support Vector Machines (SVC)","13596153":"# END","59b34097":"# Graphic representation of the basic data","501a4ba6":"## HELPS US UNDERSTAND VARIOUS ASPECT OF THE TABLE WITH THE HELP OF GRAPHS","1a520bd0":"#### GRPAH WITH NULL VALUE\n","b53d25ff":"# Data uploading and understanding","e38ba2af":"# Machine Learning Models","ec9ded41":" # UNDERSTANING THE DATASETS\/","1f62fc91":"NOTE:-The ticket class of the passenger.\n\nKey: 1 = 1st,\n     2 = 2nd, \n     3 = 3rd","5f3ca135":"GRAPH","6182c8d6":"## IDENTIFICATION OF NULL VALUES \n","fdb53bd0":"### AGE","b5c4ea8c":"###  Embarked","1968adaa":"# PREWORK","1ac25244":"###  Sex \/ GENDER","6abbf642":"FROM THE ABOVE NUMBERS WE CAN SEE THAT \n\n1. survied = 549\n2. deaseced =342 \n\n\nPlotted below for graphical represent\n\n","b2a1859d":"DATA LOADING","22e7699c":"THE SAME CONCLUSION IS SHOWN BELOW IN NUMERIC FORMS","7a243c77":"# LOGESTIC REGRESSION","30d41106":"# TRAIN DATASETS","d9599df4":"Lenght of my dataset's (the number of rows present )","9c90fce4":"# CONCLUSION","351e587d":"# ANALYSIS OF FEATURES\nWith the help of graphs we get to know the data better and can make better decisions","12835bac":"###  Parch**** ","be900e7b":"# Decision Tree Classifier","4a24d79e":"CREATE DUPLICATE DATAFRAME","7b9979e3":"Precision is higher therefore there's less false positives","b55405e9":"### Survied people","9b1c5759":"#### FARE\n","9ab0d4a4":"NOTE:-  0 = Deseacead, 1 = survived","f4a283f4":"KNOWING THE DATA IN TABLE","5ff29d04":"### CREATE 2nd DUPLICATE DATAFRAME FOR ANALYSIS"}}