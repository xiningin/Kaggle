{"cell_type":{"18311d43":"code","c98347b5":"code","66dcffe9":"code","2f39f8a4":"code","bb812a40":"code","b702411b":"code","956295ef":"code","0ec926be":"code","10e84f9d":"code","d4897772":"code","d228e0f0":"code","76f56f2a":"code","656dee06":"code","1110964a":"code","9cad3ae0":"code","d1cab0c8":"code","f7f3f755":"code","d8a490b3":"code","db4efc19":"code","a9252826":"code","7138bedb":"code","78d9a235":"code","7e6d8590":"code","b947d911":"code","c93f6ef9":"code","a7c409fb":"code","ed99ba80":"code","2e1add01":"code","f1dee28e":"code","05b83d1d":"code","334a9f8b":"code","1b6abbfe":"code","f72b7488":"code","e160051c":"markdown","a2cdf74c":"markdown","4c5a9b0b":"markdown","1b27bf86":"markdown","8a82a554":"markdown","d08c0661":"markdown","1c037ad1":"markdown"},"source":{"18311d43":"!pip install -U sentence-transformers","c98347b5":"import numpy as np \nimport pandas as pd\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score\n\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')","66dcffe9":"# true = pd.read_csv('..\/input\/stancedata\/real_withstance (1).csv')\n# true['label'] = 0\n\n# cleansed_data = []\n# for data in true.text:\n#     if \"@realDonaldTrump : - \" in data:\n#         cleansed_data.append(data.split(\"@realDonaldTrump : - \")[1])\n#     elif \"(Reuters) -\" in data:\n#         cleansed_data.append(data.split(\"(Reuters) - \")[1])\n#     else:\n#         cleansed_data.append(data)\n\n# true[\"text\"] = cleansed_data\n# true.head(5)","2f39f8a4":"# fake = pd.read_csv('..\/input\/stancedata\/fake_withstance (1).csv')\n# fake['label'] = 1\n\n# dataset = pd.concat([true, fake])\n# dataset = dataset.sample(frac = 1, random_state = 13).reset_index(drop = True)\n# dataset['full_text'] = dataset['title'] + ' ' + dataset['text']\n\n# del true, fake\n# gc.collect()\n# # dataset = dataset[:15000]\n# dataset.head()","bb812a40":"dataset = pd.read_csv('..\/input\/real-fake\/news_dataset.csv')\ndataset = dataset.drop(['Unnamed: 0'], 1)\ndataset['label'] = dataset['label'].map({'fake':1,'real':0})\ndataset = dataset.dropna(subset=['title','content'])\ndataset['full_text'] = dataset['title'] + ' ' + dataset['content']\ndataset = dataset.sample(frac = 1, random_state = 13).reset_index(drop = True)\ndataset.head()","b702411b":"sentences = dataset.full_text\nsentence_embeddings = model.encode(sentences)","956295ef":"stance_embeddings = np.hstack([sentence_embeddings,pd.factorize(dataset.stance)[0].reshape((dataset.shape[0],1))])","0ec926be":"from sklearn import cluster\n\n# Training for 2 clusters (Fake and Real)\nkmeans = cluster.KMeans(n_clusters=2, random_state=20, max_iter = 400)\n\n# Fit predict will return labels\nclustered = kmeans.fit_predict(sentence_embeddings)","10e84f9d":"if clustered[0] == 0:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(dataset['label'].values):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, dataset['label'].values)))","d4897772":"dbscan = cluster.DBSCAN(eps=0.5,min_samples=5, metric='euclidean', leaf_size=30)\n\n# Fit predict will return labels\nclustered = dbscan.fit_predict(sentence_embeddings)","d228e0f0":"if clustered[0] == 0:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(dataset['label'].values):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")","76f56f2a":"np.unique(clustered, return_counts=True) ","656dee06":"# Training for 2 clusters (Fake and Real)\nkmeans = cluster.KMeans(n_clusters=2,random_state=20,max_iter=400)\n\n# Fit predict will return labels\nclustered = kmeans.fit_predict(stance_embeddings)","1110964a":"if clustered[0] == 1:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(dataset['label'].values):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, dataset['label'].values)))","9cad3ae0":"def cosine_similarity(a, b):\n    return np.inner(a, b) \/ (np.linalg.norm(a) * np.linalg.norm(b))\n\nprint(cosine_similarity(sentence_embeddings[0],sentence_embeddings[1])) ### label 0 and 1\nprint(cosine_similarity(sentence_embeddings[0],sentence_embeddings[2])) ### label 0 and 0\nprint(cosine_similarity(sentence_embeddings[1],sentence_embeddings[4])) ### label 1 and 1","d1cab0c8":"from sklearn.decomposition import PCA\n\nX = np.array(sentence_embeddings)\n\npca = PCA(n_components=3)\nresult = pca.fit_transform(X)","f7f3f755":"clustered = kmeans.fit_predict(result)\n\nif clustered[0] == 1:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(dataset['label'].values):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, dataset['label'].values)))","d8a490b3":"result_stance = np.hstack([result,pd.factorize(dataset.stance)[0].reshape((dataset.shape[0],1))])\n\nclustered = kmeans.fit_predict(result_stance)\n\nif clustered[0] == 1:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(dataset['label'].values):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, dataset['label'].values)))","db4efc19":"df = pd.DataFrame({\n    'sent': dataset.full_text.values,\n    'cluster': clustered.astype(int),\n    'x': result[:, 0],\n    'y': result[:, 1],\n    'z': result[:, 2]\n})\ndf.head()","a9252826":"from mpl_toolkits import mplot3d\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(12, 9))\nax = mplot3d.Axes3D(fig)\n\nfor grp_name, grp_idx in df.groupby('cluster').groups.items():\n    if grp_name == 0:\n        name = 'real news'\n    else: name = 'fake news'\n    y = df.iloc[grp_idx,3]\n    x = df.iloc[grp_idx,2]\n    z = df.iloc[grp_idx,4]\n    ax.scatter(x,y,z, label=str(name))\n\nax.legend()","7138bedb":"# import nltk\n# nltk.download('vader_lexicon')\n# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# sid = SentimentIntensityAnalyzer()","78d9a235":"# dataset['scores'] = dataset['full_text'].apply(lambda full_text: sid.polarity_scores(full_text))","7e6d8590":"# def keywithmaxval(d): \n#     v=list(d.values())\n#     k=list(d.keys())\n#     return k[v.index(max(v))]\n\n# dataset['sentiment'] = dataset['scores'].apply(lambda x: keywithmaxval(x))\n# dataset['sentiment'].value_counts()","b947d911":"# result_stancesent = np.hstack([result,pd.factorize(dataset.stance)[0].reshape((dataset.shape[0],1)),\n#                               pd.factorize(dataset.sentiment)[0].reshape((dataset.shape[0],1))])\n\n# clustered = kmeans.fit_predict(result_stancesent)\n\n# if clustered[0] == 1:\n#     clustered = 1 - clustered  ### invert the first to match the group\n\n# correct = 0\n# incorrect = 0\n# for index, row in enumerate(dataset['label'].values):\n#     if row == clustered[index]:\n#         correct += 1\n#     else:\n#         incorrect += 1\n        \n# print(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\n# print(\"AUC: \"+str(roc_auc_score(clustered, dataset['label'].values)))","c93f6ef9":"from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short # Preprocesssing\nfrom gensim.models import Word2Vec # Word2vec\nimport re","a7c409fb":"def remove_URL(s):\n    regex = re.compile(r'https?:\/\/\\S+|www\\.\\S+|bit\\.ly\\S+')\n    return regex.sub(r'',s)\n\n# Preprocessing functions to remove lowercase, links, whitespace, tags, numbers, punctuation, strip words\nCUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, remove_URL, strip_punctuation, strip_multiple_whitespaces, \n                  strip_numeric, remove_stopwords, strip_short]\n\n# Here we store the processed sentences and their label\nprocessed_data = []\nprocessed_labels = []\nindices = []\n\nfor index, row in dataset.iterrows():\n    words_broken_up = preprocess_string(row['full_text'], CUSTOM_FILTERS)\n    # This eliminates any fields that may be blank after preprocessing\n    if len(words_broken_up) > 0:\n        processed_data.append(words_broken_up)\n        processed_labels.append(row['label'])\n        indices.append(index)","ed99ba80":"model = Word2Vec(processed_data, min_count=1)\n\ndef ReturnVector(x):\n    try:\n        return model[x]\n    except:\n        return np.zeros(100)\n    \ndef Sentence_Vector(sentence):\n    word_vectors = list(map(lambda x: ReturnVector(x), sentence))\n    return np.average(word_vectors, axis=0).tolist()\n\nX_np = []\nfor data_x in processed_data:\n    X_np.append(Sentence_Vector(data_x))","2e1add01":"X_np = np.array(X_np)\nX_np.shape","f1dee28e":"# Training for 2 clusters (Fake and Real)\nkmeans = cluster.KMeans(n_clusters=2)\n\n# Fit predict will return labels\nclustered = kmeans.fit_predict(X_np)\n\nif clustered[0] == 1:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(processed_labels):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, processed_labels)))","05b83d1d":"shortened_embeddings = np.array([sentence_embeddings[i] for i in indices])\nshortened_embeddings = shortened_embeddings*2","334a9f8b":"clustered = kmeans.fit_predict(np.hstack([X_np, shortened_embeddings]))\n\nif clustered[0] == 0:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(processed_labels):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, processed_labels)))","1b6abbfe":"shortened_embeddings = np.array([stance_embeddings[i] for i in indices])\nshortened_embeddings = shortened_embeddings*0.5","f72b7488":"clustered = kmeans.fit_predict(np.hstack([X_np, shortened_embeddings]))\n\nif clustered[0] == 1:\n    clustered = 1 - clustered  ### invert the first to match the group\n\ncorrect = 0\nincorrect = 0\nfor index, row in enumerate(processed_labels):\n    if row == clustered[index]:\n        correct += 1\n    else:\n        incorrect += 1\n        \nprint(\"Correctly clustered news: \" + str((correct*100)\/(correct+incorrect)) + \"%\")\nprint(\"AUC: \"+str(roc_auc_score(clustered, processed_labels)))","e160051c":"## KMeans on embeddings with stance","a2cdf74c":"With stance","4c5a9b0b":"> PCA to reduce dimension","1b27bf86":"## Concatenation of embeddings with weights","8a82a554":"## Combine with gensim","d08c0661":"## DBSCAN","1c037ad1":"## KMEANS on original embeddings"}}