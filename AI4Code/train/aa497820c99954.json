{"cell_type":{"48c7692b":"code","cd52e9f8":"code","d7478318":"code","894bfb29":"code","809d29b9":"code","1dc29b6e":"code","894ca954":"code","632ccf99":"code","aa75e59b":"code","e09e0e67":"code","dde570b2":"code","26da2488":"code","420085a6":"code","2afca9f1":"code","e6151aec":"code","6d3f311d":"code","f73d8e36":"code","2aa64170":"code","915b1a2c":"code","dfc7576d":"code","334618d1":"code","23e5923b":"code","b5d848b4":"code","bb48f12f":"code","d76f5e6b":"code","6d68148b":"code","50bc4c9d":"code","62cb9f2f":"code","012eb01d":"code","b77f6c16":"code","46c0d5ee":"code","1ad4864d":"code","1f3697c0":"code","89c01ee5":"code","f064aef9":"code","202a3371":"code","30144c5c":"code","bd9112e4":"code","a09ad426":"code","3fed089c":"code","c52903b0":"code","71418cef":"code","a93f49a3":"code","2cbe6488":"code","51cd1707":"code","33903f3e":"code","cad64dd4":"code","b78db9db":"code","2ab4823a":"code","9c41716c":"code","2b463698":"code","ec7a6af3":"code","84f0c911":"code","d3825e82":"code","8946b0f3":"code","3d3205a7":"code","b12fd739":"code","e8dc0358":"code","8505174c":"code","078bc6c0":"markdown","ae559fb3":"markdown","04537c5b":"markdown","2b1f9bea":"markdown","db11f5f0":"markdown","0a25d6bf":"markdown","929b3ae1":"markdown","793eb78f":"markdown","699bcf22":"markdown","f4e332fa":"markdown","7efd0cc8":"markdown","0e83504b":"markdown","553042e7":"markdown","3447d321":"markdown","e9c24fbb":"markdown","898c34a9":"markdown","f3ee69d8":"markdown","2a41388a":"markdown","1eb15b7a":"markdown","17e49c80":"markdown","b2cd3f49":"markdown","cfe594f6":"markdown","5d190467":"markdown","ec2f6373":"markdown","58557a88":"markdown","84e865ea":"markdown","2bd199d2":"markdown","29183bc0":"markdown","46742ba9":"markdown","23642c98":"markdown","4dfb4ec5":"markdown","36feb952":"markdown","82b4921e":"markdown","7e7d87b5":"markdown","fd7d0ad6":"markdown","35722ead":"markdown","ce11a720":"markdown","dbec1d7e":"markdown","566f90a2":"markdown","3e04c1b8":"markdown","6da85ba8":"markdown","e3bfeea8":"markdown","f44d589a":"markdown","e7040fcf":"markdown","5a5a32ab":"markdown","b871a0e1":"markdown","a97d20b2":"markdown","443c6b56":"markdown","13fb40da":"markdown","f0174c82":"markdown","6cb0c4d6":"markdown","eff110f6":"markdown","f740ba64":"markdown","de6165ac":"markdown","3ac996eb":"markdown","a4bc5c58":"markdown","90ba5dd7":"markdown","72996b60":"markdown","7844446a":"markdown"},"source":{"48c7692b":"#Librairies for data treatment\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport collections as col\nfrom collections import Counter\n\n#Libraries for text treatment\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nstopWords = set(stopwords.words('english'))\nfrom textblob import TextBlob\nfrom difflib import SequenceMatcher\n\n#Library for file loading\nimport os\nimport csv\n\n#Library for ML\nfrom sklearn import feature_extraction\n\npd.options.display.max_colwidth = 100","cd52e9f8":"for subfold in os.listdir(\"..\/input\/cityofla\/CityofLA\/\"):\n    print(subfold)","d7478318":"for subfold in os.listdir(\"..\/input\/cityofla\/CityofLA\/Additional data\"):\n    print(subfold)","894bfb29":"for subfold in os.listdir(\"..\/input\/cityofla\/CityofLA\/Additional data\") :\n    if \".csv\" in subfold :\n        file_csv=pd.read_csv(\"..\/input\/cityofla\/CityofLA\/Additional data\/\"+subfold)\n        print(subfold + ', ' + str(file_csv.shape[0]) + ' rows, ' + str(file_csv.shape[1]) + ' columns')\n        display(file_csv.head(5))","809d29b9":"file_txt=os.listdir(\"..\/input\/cityofla\/CityofLA\/Job Bulletins\/\")\nprint('Number of elements in the folder Job Bulletins : ' + str(len(file_txt)))\nexpl=5\nprint('Here the {0} first txt job bulletins : '.format(str(expl)))\nfor name_txt in file_txt[:expl]:\n    print(name_txt)","1dc29b6e":"frequencyBulletin=col.Counter([re.split(\"\\s+[0-9]|\\.+\",x)[0] for x in sorted(file_txt)])\nfrequencyBulletin=pd.DataFrame.from_dict(frequencyBulletin,orient='index',columns=['Count_txt'])\nfrequencyBulletin.index.names = ['Name_txt']\nfrequencyBulletin.reset_index(inplace=True)\nfrequencyBulletin.loc[frequencyBulletin.Count_txt>1]\n","894ca954":"jobTitle=pd.read_csv(\"..\/input\/cityofla\/CityofLA\/Additional data\/job_titles.csv\", names=['Name_csv'])\njobTitle.Name_csv=jobTitle.Name_csv.replace(to_replace=\"'|&\", value='_', regex=True)\ntitleJobBulletin=frequencyBulletin.merge(jobTitle, how='outer', left_on='Name_txt', right_on='Name_csv')\ntitleJobBulletin.loc[(titleJobBulletin.Name_txt.isnull())|(titleJobBulletin.Name_csv.isnull())]","632ccf99":"jobTitle=pd.read_csv(\"..\/input\/cityofla\/CityofLA\/Additional data\/job_titles.csv\", names=['Name_csv'])\njobTitle.Name_csv=jobTitle.Name_csv.replace(to_replace=\"'|&\", value='_', regex=True)\ntitleJobBulletin=frequencyBulletin.merge(jobTitle, how='outer', left_on='Name_txt', right_on='Name_csv')\nprint(\"\"\"Thus we know that \nfor {0} job titles we have a bulletin;\nfor {1} job bulletins we don't have any reference in the job title csv file.\"\"\".format(1+len(titleJobBulletin.loc[(~titleJobBulletin.Name_txt.isnull())&(~titleJobBulletin.Name_csv.isnull()),'Name_txt']),\n                                                                                     len(titleJobBulletin.loc[(~titleJobBulletin.Name_txt.isnull())&(titleJobBulletin.Name_csv.isnull()),'Name_csv'])-1))","aa75e59b":"job=\"SENIOR REAL ESTATE OFFICER 1961 0413018 (2).txt\"\nprint(job)\nfile=open(r\"..\/input\/cityofla\/CityofLA\/Job Bulletins\/\"+job,\"r\")\ntxt_file=file.read()\ntxt_file[:500]","e09e0e67":"def fromTxt2Dataframe (string,job):\n    \"\"\"\n    Input (string) : content of the bulletin txt file\n    Output (dataframe) : \n                        header the title part (capital letter) ; \n                        row the  content between two title parts (list with each item is a line)\n    This function transform the txt file into a semi structure dataframe as first step    \n    \"\"\"\n\n    # we seperate each line\n\n    superList=[]\n    cellList=[]\n    key=''\n    note_flag=0\n    \n    #string=re.sub(re.split(\"\\s+[0-9]|\\.+\",job)[0].replace(' ','[\\n\\s]*'), \"\", string)\n    \n    string=re.sub(\"\\t\", \" \", string)\n    string=re.sub(\" +\", \" \", string)\n    string=re.sub(\"\\s\\.+\", \"\", string)\n    string=re.sub(\"[\\s ]*\\n[\\s ]*\", \"\\n\", string)\n    string=re.sub(\"^\\s+\", \"\", string)\n    string=[x for x in re.split(\"[\\n\\t]\",string) if not (x==''or x==' ')]\n    \n    stringLen=len(string)-1\n    \n    superList.append(('JOB_NAME_TXT',re.sub(\" +\", \" \",re.split(\"\\s+[0-9]|\\.+\",job)[0]).upper()))  \n    \n    if string[0]=='CAMPUS INTERVIEWS ONLY':\n        start=2\n        superList.append((string[0],string[0]))\n        title=string[1]\n        item=string[start]\n        while item.isupper() and re.search(\"[0-9]\", item)==None:\n            title=title + \" \" + item\n            start += 1\n            item=string[start]\n        superList.append(('JOB_TITLE_TXT',title.upper()))\n\n    else :\n        start=1\n        title=string[0]\n        item=string[start]\n        while item.isupper() and re.search(\"[0-9]\", item)==None:\n            title=title + \" \" + item\n            start += 1\n            item=string[start]\n        superList.append(('JOB_TITLE_TXT',title.upper()))\n    \n    key='ADMINISTRATION'\n    \n    for index, item in enumerate(string[start:]):\n        # we keep capital letters as title part\n        if item.isupper() and re.search(\"[0-9]\", item)==None:\n            if cellList:\n                if re.search(r\"^NOTES*\",item):\n                    if note_flag==0:\n                        superList.append((key,cellList))\n                        cellList=[]\n                        key=key + \" \" + item\n                        note_flag=1\n                else :\n                    superList.append((key,cellList))\n                    cellList=[]\n                    key=item\n                    note_flag=0\n            else:\n                key=key+' '+item\n            \n            #print(note_flag, key)\n        # otherwise it's the content of the part\n        else:\n            cellList.append(item)\n            if index==stringLen:\n                superList.append((key,cellList))\n    \n    df_position=pd.DataFrame([dict(superList)],columns=dict(superList).keys())\n    return df_position","dde570b2":"fromTxt2Dataframe(txt_file,job)","26da2488":"def standardize2Aggregate(listOfFile,dictOfStandard=dict(), step='standardize'):\n    \n    list_metaData=[]\n    df1_metaData=pd.DataFrame()\n    \n    for job in listOfFile:\n        file=open(r\"..\/input\/cityofla\/CityofLA\/Job Bulletins\/\"+job,\"r\")\n        try:\n            txt_file=file.read()\n            df=fromTxt2Dataframe(txt_file,job)\n\n            # we map the headers of the document with the standardize header before to aggregate\n            if step=='aggregate':\n                #print(df.columns)\n                df.columns=[ x if ((x==\"JOB_NAME_TXT\") | (x==\"JOB_TITLE_TXT\")) else dictOfStandard[x]\n                        #\" \".join(x.translate(str.maketrans(string.punctuation,' '*len(string.punctuation))).split())\n                        for x in list(df.columns)]\n                df1_metaData = df1_metaData.append(df, sort=False)\n\n            list_metaData.append([x  for x in list(df.columns) if((x!=\"JOB_NAME_TXT\") & (x!=\"JOB_TITLE_TXT\"))])\n\n        except:print(job)\n\n        file.close()\n        \n    if step=='aggregate':\n        return list_metaData,df1_metaData\n    else:\n        return list_metaData","420085a6":"listOfHeaders=standardize2Aggregate(file_txt)","2afca9f1":"def lemmatizeSentence(sentence):\n    sent = sentence\n    tag_dict = {\"J\": 'a', \n                \"N\": 'n', \n                \"V\": 'v', \n                \"R\": 'r'}\n    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n    return lemmatized_list\n\ndef reduceSentence(sentence):\n    sentence=TextBlob(sentence.translate(str.maketrans(string.punctuation,' '*len(string.punctuation))).lower())\n    sentence=sentence.correct()\n    sentence=lemmatizeSentence(sentence)\n    sentenceback=[re.sub(\"MORTIFICATION\",\"CERTIFICATION\",x.upper()) for x in list(sentence) if x not in stopWords]\n    return sentenceback\n\ndef add_or_append(dictionary, key, value):\n    dictionary[key]=value","e6151aec":"mappingHeaders=dict()\nfor value in set(x for l in listOfHeaders for x in l):\n    add_or_append(mappingHeaders,value, \"_\".join(reduceSentence(value)))","6d3f311d":"listOfHeaders, dfStandarized =standardize2Aggregate(file_txt,mappingHeaders,'aggregate')","f73d8e36":"def ratio_sim(row) :\n    return SequenceMatcher(None,row['JOB_NAME_TXT'],row['JOB_TITLE_TXT']).ratio()\ndf=dfStandarized[['JOB_NAME_TXT','JOB_TITLE_TXT']]\ndf['similarity']=df.apply(ratio_sim,axis=1)\ndf.sort_values('similarity').head(5)","2aa64170":"display(dfStandarized.loc[dfStandarized.JOB_NAME_TXT!='VOCATIONAL WORKER DEPARTMENT OF PUBLIC WORKS'].head(5))\ndfStandarized=dfStandarized.loc[dfStandarized.JOB_NAME_TXT!='VOCATIONAL WORKER DEPARTMENT OF PUBLIC WORKS']","915b1a2c":"a=dfStandarized.count().sort_values(ascending=False).reset_index()\na.columns=['HEADERS','Count']\ndisplay(a.head(10))\nlist_ratio=[]\na=a.sort_values('Count',ascending=False)\nlist_name=a['HEADERS']\nlist_valeur=a['Count']\nfor x in range(len(list_name)):\n    for y in range(x,len(list_name)):\n        if not (bool(re.search(\"_NOTE$\",list_name[x])) ^ bool(re.search(\"_NOTE$\",list_name[y]))):\n            correl=dfStandarized.loc[(~dfStandarized[list_name[x]].isnull()) & (~dfStandarized[list_name[y]].isnull()),[list_name[x],list_name[y]]].shape[0]\n            list_ratio.append([list_name[x],list_name[y],round(SequenceMatcher(None,list_name[x], list_name[y]).ratio(),4)*100,\n                                  list_valeur[x],list_valeur[y],correl])\ndf_ratio=pd.DataFrame(list_ratio, columns=['Col1','Col2','Similarity','Num_Col1','Num_Col2','Overlap'])\ndf_ratio.loc[(df_ratio['Col1']!=df_ratio['Col2'])\n             &(df_ratio['Similarity']>0)\n             &(df_ratio['Overlap']==0)\n            ].sort_values(['Similarity'], ascending=False).head(5)","dfc7576d":"listToCorrect=[\"ANNUALSALARY_NOTE\",\"ANNUALSALARY\",\n               \"EXAMINATION_GIVE_INTERDEPARTMENTAL_PROMOTION_BASIS_NAVY\",\n               \"PASS_SCORE_QUALIFY_TEST_NOTE\",\"REQUIREMENT_MIMINUMUM_QUALIFICATION\",\n               \"PASS_SCORE_QUALIFY_TEST\",\"EXAM_GIVE_INTERDEPARTMENTAL_PROMOTION_BASIS\",\n               \"EXAMINATION_GIVE_OPEN_COMPETITIVE_INTERDEPARTMENTAL_PROMOTION_BASIS\",\"SELECTION_PROCEDURE\",\n               \"EQUAL_OPPORTUNITY_EMPLOYER\",\"EQUAL_EMPLOYMENT_OPPORTUNITY_EMPLOYER_EQUAL_EMPLOYMENT_OPPORTUNITY_EMPLOYER\",\n               \"REQUIREMENT\",\"REQUIREMENT_MINIMUM_REQUIREMENT\",\n               \"MINIMUM_REQUIREMENT\",\n               \"REQUIREMENT_NOTE\",\"APPLICATION_DEADLINE_NOTE_EXPERT_REVIEW_COMMITTEE\"]\nlistByCorrect=[\"ANNUAL_SALARY_NOTE\",\"ANNUAL_SALARY\",\n               \"EXAMINATION_GIVE_INTERDEPARTMENTAL_PROMOTION_BASIS\",\n               \"PASS_SCORE_QUALIFYING_TEST_NOTE\",\"REQUIREMENT_MINIMUM_QUALIFICATION\",\n               \"PASS_SCORE_QUALIFYING_TEST\",\"EXAMINATION_GIVE_INTERDEPARTMENTAL_PROMOTION_BASIS\",\n               \"EXAMINATION_GIVE_INTERDEPARTMENTAL_PROMOTION_OPEN_COMPETITIVE_BASIS\",\"SELECTION_PROCESS\",\n               \"EQUAL_EMPLOYMENT_OPPORTUNITY_EMPLOYER\",\"EQUAL_EMPLOYMENT_OPPORTUNITY_EMPLOYER\",\n               \"REQUIREMENT_MINIMUM_QUALIFICATION\",\"REQUIREMENT_MINIMUM_QUALIFICATION\",\n               \"REQUIREMENT_MINIMUM_QUALIFICATION\",\n               \"REQUIREMENT_MINIMUM_QUALIFICATION_NOTE\",\"EXPERT_REVIEW_COMMITTEE\"]\nfor index, item in enumerate(listToCorrect):\n    dfStandarized.loc[~dfStandarized[listToCorrect[index]].isnull(),listByCorrect[index]]=dfStandarized.loc[~dfStandarized[listToCorrect[index]].isnull(),listToCorrect[index]]\n    dfStandarized.drop([listToCorrect[index]], axis=1,inplace=True)\ndfStandarized.reset_index(drop=True,inplace=True)","334618d1":"a=dfStandarized.count().sort_values(ascending=False)\na.columns=['HEADERS','Count']\na.head(30)","23e5923b":"dfStandarized['CLASS_CODE']=dfStandarized['ADMINISTRATION'].apply(lambda x: ' '.join(x)).str.lower()\\\n.apply(lambda x : re.search(\"class code: (\\S+)*\",x).group(1) if re.search(\"class code: (\\S+)*\",x) else np.NaN )\n\ndfStandarized.loc[dfStandarized.CLASS_CODE.isnull(),'CLASS_CODE']=dfStandarized.loc[dfStandarized.CLASS_CODE.isnull(),'JOB_TITLE_TXT'].str.lower()\\\n.apply(lambda x : re.search(\"class code: (\\S+)*\",x).group(1) if re.search(\"class code: (\\S+)*\",x) else np.NaN )\ndfStandarized['JOB_TITLE_TXT']=dfStandarized['JOB_TITLE_TXT'].apply(lambda x : re.sub(\" CLASS CODE: (\\S+)*\",\"\",x))\n\ndfStandarized['OPEN_DATE']=dfStandarized['ADMINISTRATION'].apply(lambda x: ' '.join(x)).str.lower()\\\n.apply(lambda x : re.search(\"open date: (\\S+)*\",x).group(1) if re.search(\"open date: (\\S+)*\",x) else None )\n\ndfStandarized['REVISED_DATE']=dfStandarized['ADMINISTRATION'].apply(lambda x: ' '.join(x)).str.lower()\\\n.apply(lambda x : re.search(\"revised: (\\S+)*\",x).group(1) if re.search(\"revised: (\\S+)*\",x) else None )\n\ndfStandarized['EXAM_OPEN_TO']=dfStandarized['ADMINISTRATION'].apply(lambda x: ' '.join(x)).str.lower()\\\n.apply(lambda x : re.search(\"\\(exam (.+)*\\)\",x).group(1) if re.search(\"\\(exam ([\\w\\s]+)*\",x) else None )","b5d848b4":"dfStandarized[['JOB_TITLE_TXT','ADMINISTRATION','CLASS_CODE','OPEN_DATE','REVISED_DATE','EXAM_OPEN_TO']].head(5)","bb48f12f":"dfStandarized.EXAM_OPEN_TO.value_counts()","d76f5e6b":"dfStandarized.head(10)['ANNUAL_SALARY'].values","6d68148b":"regex_range_salary=\"\\$*\\s*(\\d+\\,*\\s*\\d+)+\\** to \\$*\\s*(\\d+\\,*\\s*\\d+)+\"\nregex_flat=\"(flat\\srate)+\"\nregex_flat_salary=\"\\$*\\s*(\\d+\\,*\\d+)+\"","50bc4c9d":"dfStandarized['ANNUAL_SALARY']=dfStandarized['ANNUAL_SALARY']\\\n.apply(lambda x: list(filter(lambda x: x!='',[' '.join(x[i:i+2]) if bool(re.search(\" (to)$\",x[i])) \n                                              else x[i]  if (i==0)|\n                                              ((bool(re.search(\" (to)$\",x[i-1]))==False) & (i>0)) else '' for i in range(len(x)) ])))\n\ndfStandarized['ANNUAL_SALARY_REDUCED_BIS']=dfStandarized['ANNUAL_SALARY']\\\n.apply(lambda x: [re.sub(regex_range_salary,\"xx\",y.lower()) if re.search(regex_range_salary,y.lower()) else y.lower() for y in x])\\\n.apply(lambda x: [re.sub(regex_flat_salary,\"ff\",y) if re.search(regex_flat,' '.join(reduceSentence(y)).lower()) else y for y in x])\\\n.apply(lambda x :[re.sub('(LOS ANGELES)|(SALARY)|(RANGE)|(DEPARTMENT)|(WORLD)|(POSITION)|\\d', r'',' '.join(reduceSentence(y))) for y in x] )\\\n.apply(lambda x: [re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1',' '.join(reduceSentence(y))) for y in x])\\\n.apply(lambda x: [re.sub(r'\\b([\\w\\s]+)( \\1\\b)+', r'\\1',' '.join(reduceSentence(y))) for y in x])\\\n.apply(lambda x: [re.sub(r'\\b([\\w\\s]+)( \\1\\b)+', r'\\1',' '.join(reduceSentence(y))) for y in x])\\\n.apply(lambda x :[re.sub('\\s+', r' ',y) for y in x] )\\\n.apply(lambda x :[re.sub('^\\s+|\\s+$', r'',y) for y in x])","62cb9f2f":"a=dfStandarized['ANNUAL_SALARY_REDUCED_BIS']\nx=Counter([y for x in a for y in x])\nsorted(x.items(), key=lambda pair: pair[1], reverse=True)[:10]\n","012eb01d":"dfStandarized.head(10)[['ANNUAL_SALARY','ANNUAL_SALARY_REDUCED_BIS']].values","b77f6c16":"dict_salary=dict()\ndict_salary['AIRPORT FLAT RATE FF']='AIRPORT FF FLAT RATE'\ndict_salary['WATER POWER FLAT RATE FF']='WATER POWER FF FLAT RATE'\ndict_salary['XX WATER POWER XX']='WATER POWER XX'\ndict_salary['XX FLAT RATE']='FF FLAT RATE'\ndfStandarized['ANNUAL_SALARY_REDUCED_BIS']=dfStandarized['ANNUAL_SALARY_REDUCED_BIS'].apply(lambda x: [dict_salary[y] if y in dict_salary.keys() else y for y in x])\\\n.apply(lambda x :[re.sub('(WATER POWER FF FLAT RATE XX)|(WATER POWER XX FF FLAT RATE)', r'WATER POWER XX WATER POWER FF FLAT RATE',y) for y in x] )","46c0d5ee":"dict_get_salary={\n    \n    \"WATER_POWER_SALARY_RANGE\" : [\"(WATER POWER XX)\" , regex_range_salary],\n    \"WATER_POWER_SALARY_FLAT\" : [\"(WATER POWER FF FLAT RATE)\", regex_flat_salary],\n    \n    \"AIRPORT_SALARY_RANGE\" : [\"(AIRPORT XX)\" , regex_range_salary],\n    \"AIRPORT_SALARY_FLAT\" : [\"(AIRPORT FF FLAT RATE)\" , regex_flat_salary],\n    \n    \"HARBOR_SALARY_RANGE\" : [\"(HARBOR XX)\" , regex_range_salary],\n    \"HARBOR_SALARY_FLAT\" : [\"(HARBOR FF FLAT RATE)\", regex_flat_salary],\n    \n    \"GENERAL_SALARY_RANGE\" : [\"(XX)\",regex_range_salary],\n    \"GENERAL_SALARY_FLAT\" : [\"(FF FLAT RATE)\", regex_flat_salary]\n}","1ad4864d":"def f(x,y):\n    a=[re.findall(y[1],x['ANNUAL_SALARY_MODIFIED'][i].lower())\n       for i,z in enumerate(x['ANNUAL_SALARY_REDUCED_BIS'])\n       if (re.search(y[0],z)) and (re.search(y[1],x['ANNUAL_SALARY_MODIFIED'][i].lower()))]\n    return [item for sublist in a for item in sublist] if a!=[] else None\n\ndef g(x,y):\n    b=[re.sub(y[1],'Substitute',x['ANNUAL_SALARY_MODIFIED'][i].lower()) \n       if re.search(y[0],z) else x['ANNUAL_SALARY_MODIFIED'][i].lower()\n       for i,z in enumerate(x['ANNUAL_SALARY_REDUCED_BIS'])]\n    return b","1f3697c0":"dfStandarized['ANNUAL_SALARY_MODIFIED']=dfStandarized['ANNUAL_SALARY']\n\nfor new_column in dict_get_salary.keys():\n    print(new_column)\n    dfStandarized[new_column]=dfStandarized[['ANNUAL_SALARY_MODIFIED','ANNUAL_SALARY_REDUCED_BIS']]\\\n    .apply(lambda x : f(x,dict_get_salary[new_column]), axis=1)\n    dfStandarized['ANNUAL_SALARY_MODIFIED']=dfStandarized[['ANNUAL_SALARY_MODIFIED','ANNUAL_SALARY_REDUCED_BIS']]\\\n    .apply(lambda x : g(x,dict_get_salary[new_column]), axis=1)","89c01ee5":"dfStandarized[dfStandarized[['WATER_POWER_SALARY_RANGE','WATER_POWER_SALARY_FLAT',\n                            'AIRPORT_SALARY_RANGE','AIRPORT_SALARY_FLAT',\n                            'HARBOR_SALARY_RANGE','HARBOR_SALARY_FLAT',\n                            'GENERAL_SALARY_RANGE','GENERAL_SALARY_FLAT']].isna().all(1)][['JOB_NAME_TXT','ANNUAL_SALARY_MODIFIED']]","f064aef9":"dfStandarized.head(5)[['ANNUAL_SALARY',\n                       'GENERAL_SALARY_RANGE','WATER_POWER_SALARY_RANGE', 'AIRPORT_SALARY_RANGE', 'HARBOR_SALARY_RANGE',\n                       'GENERAL_SALARY_FLAT','WATER_POWER_SALARY_FLAT', 'AIRPORT_SALARY_FLAT', 'HARBOR_SALARY_FLAT']]","202a3371":"dfSalaryComparaison=dfStandarized[dfStandarized[['WATER_POWER_SALARY_RANGE',\n                                                                     'AIRPORT_SALARY_RANGE',\n                                                                     'HARBOR_SALARY_RANGE',\n                                                                     'GENERAL_SALARY_RANGE']].isnull().sum(axis=1)<3]\ndfSalary=pd.DataFrame()\nfor x in ['WATER_POWER_SALARY_RANGE', 'AIRPORT_SALARY_RANGE', 'HARBOR_SALARY_RANGE','GENERAL_SALARY_RANGE']:\n    a=pd.DataFrame(dfSalaryComparaison.loc[~dfSalaryComparaison[x].isnull(),x].tolist())\n    a['JOB_NAME']=dfSalaryComparaison.loc[~dfSalaryComparaison[x].isnull(),'JOB_NAME_TXT'].values\n    a=a.set_index('JOB_NAME').stack().reset_index(name='new')[['JOB_NAME','new']]\n    b=pd.DataFrame(a['new'].values.tolist(),columns=['LOWER_RANGE','UPPER_RANGE']).applymap(lambda x : re.sub('[^0-9]','',x))\n    b['JOB_NAME']=  a['JOB_NAME']\n    b['DEPARTEMENT_POSITION']=x\n    dfSalary=dfSalary.append(b, ignore_index=True, sort=True)\n\ndfSalary[['LOWER_RANGE','UPPER_RANGE']]=dfSalary[['LOWER_RANGE','UPPER_RANGE']].astype(int)","30144c5c":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.scatterplot(x=\"LOWER_RANGE\", y=\"UPPER_RANGE\",\n                hue=\"DEPARTEMENT_POSITION\",style=\"DEPARTEMENT_POSITION\",\n                data=dfSalary)","bd9112e4":"dfSalaryComparaison=dfStandarized\n\ndfSalary=pd.DataFrame()\nfor x in ['WATER_POWER_SALARY_RANGE', 'AIRPORT_SALARY_RANGE', 'HARBOR_SALARY_RANGE','GENERAL_SALARY_RANGE']:\n    a=pd.DataFrame(dfSalaryComparaison.loc[~dfSalaryComparaison[x].isnull(),x].tolist())\n    a['JOB_NAME']=dfSalaryComparaison.loc[~dfSalaryComparaison[x].isnull(),'JOB_NAME_TXT'].values\n    a=a.set_index('JOB_NAME').stack().reset_index(name='new')[['JOB_NAME','new']]\n    b=pd.DataFrame(a['new'].values.tolist(),columns=['LOWER_RANGE','UPPER_RANGE']).applymap(lambda x : re.sub('[^0-9]','',x))\n    b['JOB_NAME']=  a['JOB_NAME']\n    b['DEPARTEMENT_POSITION']='SALARY_RANGE'#x\n    dfSalary=dfSalary.append(b, ignore_index=True, sort=True)\n\nfor x in ['WATER_POWER_SALARY_FLAT', 'AIRPORT_SALARY_FLAT', 'HARBOR_SALARY_FLAT','GENERAL_SALARY_FLAT']:\n    a=pd.DataFrame(dfSalaryComparaison.loc[~dfSalaryComparaison[x].isnull(),x].tolist())\n    a['JOB_NAME']=dfSalaryComparaison.loc[~dfSalaryComparaison[x].isnull(),'JOB_NAME_TXT'].values\n    a=a.set_index('JOB_NAME').stack().reset_index(name='LOWER_RANGE')[['JOB_NAME','LOWER_RANGE']]\n    b=pd.DataFrame(a['LOWER_RANGE']).applymap(lambda x : re.sub('[^0-9]','',x))\n    b['JOB_NAME']=  a['JOB_NAME']\n    b['DEPARTEMENT_POSITION']='SALARY_FLAT'#x\n    b['UPPER_RANGE']=b['LOWER_RANGE']\n    dfSalary=dfSalary.append(b, ignore_index=True, sort=True)\n\ndfSalary[['LOWER_RANGE','UPPER_RANGE']]=dfSalary[['LOWER_RANGE','UPPER_RANGE']].astype(int)","a09ad426":"import seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nsns.scatterplot(x=\"LOWER_RANGE\", y=\"UPPER_RANGE\",\n                hue=\"DEPARTEMENT_POSITION\",style=\"DEPARTEMENT_POSITION\",\n                data=dfSalary)","3fed089c":"dfStandarized.head(5)[['JOB_NAME_TXT','ANNUAL_SALARY_NOTE']].values","c52903b0":"regex_url='https?:\\\/\\\/.*[\\r\\n]*'\n\ndfStandarized['ANNUAL_SALARY_NOTE_REDUCED_BIS']=dfStandarized['ANNUAL_SALARY_NOTE']\\\n.apply(lambda x : x if type(x) == list else [])\\\n.apply(lambda x: [re.sub(regex_url,\"URLPDF\",y.lower()) if re.search(regex_url,y.lower()) else y.lower() for y in x])\\\n.apply(lambda x: [re.sub('^\\d. ',\"\",y.lower()) if re.search('^\\d. ',y.lower()) else y.lower() for y in x])\\\n.apply(lambda x :[re.sub('(LOS ANGELES)|(SALARY)|(RANGE)|(DEPARTMENT)|(WORLD)|(POSITION)|\\d', r'',' '.join(reduceSentence(y))) for y in x] )\\\n.apply(lambda x: [re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1',' '.join(reduceSentence(y))) for y in x])\\\n.apply(lambda x: [re.sub(r'\\b([\\w\\s]+)( \\1\\b)+', r'\\1',' '.join(reduceSentence(y))) for y in x])\\\n.apply(lambda x: [re.sub(r'\\b([\\w\\s]+)( \\1\\b)+', r'\\1',' '.join(reduceSentence(y))) for y in x])\\\n.apply(lambda x :[re.sub('\\s+', r' ',y) for y in x] )\\\n.apply(lambda x :[re.sub('^\\s+|\\s+$', r'',y) for y in x])","71418cef":"a=dfStandarized['ANNUAL_SALARY_NOTE_REDUCED_BIS']\nx=Counter([y for x in a for y in x])\nsorted(x.items(), key=lambda pair: pair[1], reverse=True)[:10]","a93f49a3":"columns_reduced=['ANNUAL_SALARY_REDUCED_BIS','ANNUAL_SALARY_NOTE_REDUCED_BIS']\n\ndfStandarized['LOWER_PAY_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'LOWER PAY GRADE POSITION' if sum([bool(re.search(\"LOW\",y))for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0 \n                                                                                else None, axis=1)\ndfStandarized['HIGHER_PAY_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'NIGHT WORK' if sum([bool(re.search(\"NIGHT\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                 else('SHIFT WORK'if sum([bool(re.search(\"ASSIGN\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                      else None), axis=1)\ndfStandarized['PART_TIME_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'PART TIME' if sum([bool(re.search(\"PART TIME\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                else None, axis=1)\ndfStandarized['BEGIN_RANGE_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'BEGIN SALARY RANGE' if sum([bool(re.search(\"(START|BEGIN) PAY\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                  else None, axis=1)\ndfStandarized['MULTIPLE_PAY_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'COVER MULTIPLE PAY GRADE' if sum([bool(re.search(\"MULTIPLE\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                   else None, axis=1)\ndfStandarized['CONFIRM_PAY_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'CONFIRM SALARY BEFORE' if sum([bool(re.search(\"ACCEPT\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                  else None, axis=1)\ndfStandarized['CHANGE_PAY_SALARY_CRITERIA']=dfStandarized[columns_reduced].apply(lambda x: 'CURRENT SALARY SUBJECT TO CHANGE' if sum([bool(re.search(\"CHANGE\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                 else None, axis=1)\ndfStandarized['RECIPROCITY_SALARY_INFORMATION']=dfStandarized[columns_reduced].apply(lambda x: 'CITY LA AND LADWP' if sum([bool(re.search(\"URLPDF\",y)) for y in x[columns_reduced[1]]+x[columns_reduced[0]]])>0\n                                                                                 else None, axis=1)","2cbe6488":"dfStandarized.head(5)[['JOB_NAME_TXT',\n                       'LOWER_PAY_SALARY_CRITERIA','HIGHER_PAY_SALARY_CRITERIA', 'PART_TIME_SALARY_CRITERIA', 'BEGIN_RANGE_SALARY_CRITERIA',\n                       'MULTIPLE_PAY_SALARY_CRITERIA','CONFIRM_PAY_SALARY_CRITERIA', 'CHANGE_PAY_SALARY_CRITERIA', 'RECIPROCITY_SALARY_INFORMATION']]","51cd1707":"dfStandarized[dfStandarized[['LOWER_PAY_SALARY_CRITERIA','HIGHER_PAY_SALARY_CRITERIA', 'PART_TIME_SALARY_CRITERIA', 'BEGIN_RANGE_SALARY_CRITERIA',\n                       'MULTIPLE_PAY_SALARY_CRITERIA','CONFIRM_PAY_SALARY_CRITERIA', 'CHANGE_PAY_SALARY_CRITERIA', 'RECIPROCITY_SALARY_INFORMATION']].isna().all(1)][['JOB_NAME_TXT','ANNUAL_SALARY','ANNUAL_SALARY_NOTE']]","33903f3e":"dfStandarized.head(5)[['JOB_NAME_TXT','REQUIREMENT_MINIMUM_QUALIFICATION']].values","cad64dd4":"dfStandarized['REQUIREMENT_MINIMUM_QUALIFICATION_REDUCED_BIS']=dfStandarized['REQUIREMENT_MINIMUM_QUALIFICATION']\\\n.apply(lambda x: [re.sub('^\\d\\. ',\"\",y) if re.search('^\\d\\. ',y) else y for y in x])\\\n.apply(lambda x: [re.sub('^[a-z]{1}\\. ',\"\",y) if re.search('^[a-z]{1}\\. ',y) else y for y in x])\\\n.apply(lambda x :' '.join(x))\\\n.apply(lambda x :' '.join(reduceSentence(x)).lower())","b78db9db":"dfStandarized.loc[np.random.randint(1, 682, size=(1, 3))[0],\n                  ['REQUIREMENT_MINIMUM_QUALIFICATION_REDUCED_BIS']].values","2ab4823a":"def tokenize_only(text):\n    tokens=[word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n    filtered_tokens=[]\n    \n    for token in tokens:\n        if re.search('[a-zA-Z]',token):\n            filtered_tokens.append(token)\n    return filtered_tokens","9c41716c":"totalvocab_tokenized=[]\n\nfor i in dfStandarized['REQUIREMENT_MINIMUM_QUALIFICATION_REDUCED_BIS'].values:\n    allwords_tokenized=tokenize_only(i)\n    totalvocab_tokenized.extend(allwords_tokenized)    \n    ","2b463698":"vocab_frame=pd.DataFrame({'words': totalvocab_tokenized}, index=totalvocab_tokenized)\nprint ('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')","ec7a6af3":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(min_df=0.2,max_df=0.8,\n                                   use_idf=True, tokenizer= tokenize_only, ngram_range=(1,1))\n\ntfidf_matrix = tfidf_vectorizer.fit_transform(dfStandarized['REQUIREMENT_MINIMUM_QUALIFICATION_REDUCED_BIS'].values)\n\nterms=tfidf_vectorizer.get_feature_names()\n\nprint(tfidf_matrix.shape)","84f0c911":"from sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.cluster.hierarchy import ward, dendrogram\ndist = 1 - cosine_similarity(tfidf_matrix)\nlinkage_matrix = ward(dist)","d3825e82":"fig,ax = plt.subplots(figsize=(15, 20))\nax= dendrogram(linkage_matrix, orientation=\"right\",labels=dfStandarized['JOB_NAME_TXT'].values )\n\nplt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n\nplt.tight_layout()","8946b0f3":"k=18","3d3205a7":"fig,ax = plt.subplots(figsize=(15, 20))\nax= dendrogram(\n    linkage_matrix,orientation=\"right\",\n    truncate_mode='lastp',  # show only the last p merged clusters\n    p=k,  # show only the last p merged clusters\n    show_contracted=True  # to get a distribution impression in truncated branches\n)\nplt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n\nplt.tight_layout()","b12fd739":"from scipy.cluster.hierarchy import fcluster\ndfStandarized['REQUIREMENT_MINIMUM_QUALIFICATION_CLUSTER_HIER']=fcluster(linkage_matrix, k, criterion='maxclust')","e8dc0358":"from sklearn.cluster import KMeans\nfrom wordcloud import WordCloud\n\ntfidf_vectorizer_bis = TfidfVectorizer(min_df=0.2,max_df=0.8,\n                                       use_idf=True, ngram_range=(1,1))\n\nfunct = lambda x: ' '.join([vocab_frame.loc[y].values.tolist()[0][0] for y in x.split(' ')])\n\ndictResultCluster=dict()\n\nfor i in range(k):\n    df=dfStandarized.loc[dfStandarized.REQUIREMENT_MINIMUM_QUALIFICATION_CLUSTER_HIER==i+1,\n                          'REQUIREMENT_MINIMUM_QUALIFICATION_REDUCED_BIS']\n    tfidf_matrix_bis = tfidf_vectorizer_bis.fit_transform(df.values)\n    terms_bis=tfidf_vectorizer_bis.get_feature_names()\n\n    km=KMeans(n_clusters=1)\n    km.fit(tfidf_matrix_bis)\n    order_centroids = km.cluster_centers_.argsort()[:,::-1]\n    \n    print('Cluster '+str(i+1) + ' : size '+ str(df.shape[0]))\n    list_cluster=[]\n    for ind in order_centroids[0,:]:\n        try : \n            list_cluster.append(funct(terms_bis[ind])) \n        except : \n            pass\n    \n    comment_words=' '.join([ x \n                            for y in df\n                            for x in tokenize_only(y) if x in list_cluster\n                            ])\n    wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                min_font_size = 10).generate(comment_words) \n    \n    plt.figure(figsize = (4, 4), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n  \n    plt.show()\n\n    dictResultCluster[i+1]   =[df.shape[0],' ,'.join(list_cluster)] \n\n    #df=dfStandarized.loc[dfStandarized.REQUIREMENT_MINIMUM_QUALIFICATION_CLUSTER_HIER==i+1,\n    #                        ['REQUIREMENT_MINIMUM_QUALIFICATION']]\n    #print(df.values[np.random.randint(1, df.shape[0], size=(1, 3))[0]])\n","8505174c":"pd.DataFrame(dictResultCluster, index=['Cluster size','Words embeded'])","078bc6c0":"### 2.3. Standardization of the structure\n\n<a id=\"stand\"><\/a>","ae559fb3":"We are going to have to standardized the verbatim related to the EXAM_OPEN_TO in order to get only the two related designation :\n* *open to all, including current city employees* (as well as *open to all, including city employees* and *open to all including current city employees*\n* *open to current city employees* (as similar with *open to all current city employees*)","04537c5b":"We will ignore the bulletin related to the Police Job Commander position that failed to be read\n\nWe collected the headers of the bulletins that are going to be standardized by lemmatization\n","2b1f9bea":"The puporse of this challenge is to struture, extract and analyse the data of the job descriptions contained in the bulletins.\nOur strategy to achieve thoses challenges both on the form and the content:\n* Standardize the structure of the bulletins - Form\n* Extract the data from the bulletins - Content\n* Analyse how the form and the content influence the applicants","db11f5f0":"### 1.1. Libraries\n\n<a id=\"lib\"><\/a>","0a25d6bf":"Let's have a quick look to how the ANNUAL_SALARY data is presented :","929b3ae1":"## 2. Structure of the bulletin\n\n<a id=\"struct\"><\/a>","793eb78f":"# Coming Soon --  Under construction\n![](https:\/\/scholarblogs.emory.edu\/ranews\/files\/2017\/02\/under-construction-image-850x478.jpeg)","699bcf22":"**Clustering hierarchical**","f4e332fa":"We can notice here that the text of this part is much more unstructured and diversed that the annual salsry data:","7efd0cc8":"**Stemmatization and correction**","0e83504b":"> \nWe will focus on the 668 job positions that we should retrieve in the folder Job Bulletins","553042e7":"We can have a look now to the administration data structured in our dataframe","3447d321":"Maybe some initial conclusions :\n* as general statement, the lowest salary for water and power departement are higher than the lowest salary for unspecified department\n* netherless, the range ratio is higher for unspecified departement than for specific departement","e9c24fbb":"**Vectorization TFIDF**","898c34a9":"We take as example a bulletin to have a first understanding of the structure.","f3ee69d8":"By a visual analysis we can quickly decide to cluster the corpus in 18 groups (this is a first approach)","2a41388a":"### 2.2. Load the structure\n\n<a id=\"load\"><\/a>","1eb15b7a":"#### Quantitative data","17e49c80":"As previously done with the qualitative data, we will reduce the dimentionnality of the sentence in order to regularize the text and find the most common elements","b2cd3f49":"We analyse the bulletin txt file and different elements structure the document :\n* Elements in CAPITAL letters\n* \\n for new line symbol\n* \\t for tab symbol\n* Succesions of dots\n* List of points 1., 2., 3.,... ect","cfe594f6":"The three csv files job_titles, kaggle_data_dictionnary and sample_job_class_export_template.\nLet's explore them to get information about the documents.","5d190467":"So our strategy here wil be a little bit more advanced through the following steps:\n1. Apply first a stemmatization and correction of the texts\n2. Tokenize then the texts\n3. Vectorize the corpus using TFIDF method\n4. Clusterize using hierarchical aggregation algorithm\n5. Visualize the main words behind those clusters","ec2f6373":"The subfolder Aditionnal data contain th following files or folders :","58557a88":"### 1.2. Purpose & strategy\n<a id=\"purp\"><\/a>","84e865ea":"## 1. Introduction\n\n<a id=\"intro\"><\/a>","2bd199d2":"### 3.1. Administration data\n<a id=\"admin\"><\/a>\n* CLASS CODE\n* OPEN DATE\n* REVISED DATE\n* EXAM OPEN TO","29183bc0":"## Help the City of Los Angeles to structure and analyze its job descriptions","46742ba9":"**Visualization**","23642c98":"### **Please do not hesitate to comment, critic and vote so it will help to improve the approach by doing better or differently the things :)** <br>","4dfb4ec5":"## 3. Extraction and analyse of data\n\n<a id=\"extract\"><\/a>","36feb952":"So we can notice than some salary are expressed in term on range **salary1 to salary2** and other in term of flat rate **salary (flat-rated)**<br>\nThus we will focus first to retreive those two kind of information.","82b4921e":"**Tokenization**","7e7d87b5":"Heree also maybe some initial conclusions :\n* as general statement, the flated salaries are lower than the ranged salaries","fd7d0ad6":"We notice here that there is a difference between the number of the job positions specified by the csv file job_titles and the number of job descriptions as txt file.\nLet'sb check the gap between the two list.","35722ead":"## Table of contents\n1. [Introduction](#intro)<br>\n    1.1. [Libraries](#lib)<br>\n    1.2. [Purpose & strategy](#purp)<br>\n    1.3. [Folder content](#Folcont)<br>\n    \n2. [Structure of the bulletins](#struct)<br>\n    2.1. [Example](#expl)<br>\n    2.2. [Load the structure](#load)<br>\n    2.3. [Standardization of the structure](#stand)<br>\n    \n3. [Extraction of data](#extract)<br>\n    3.1. [Administration data : <br>CLASS CODE, OPEN DATE, REVISED DATE, EXAM OPEN TO](#admin)<br>\n    3.2. [Salary data : <br> *QUANTITATIVE* : DEPARTEMENT (WATER POWER, HARBOR, AIRPORT) & GENERAL SALARY, RANGE & FLAT SALARY,<br> *QUALITATIVE* : LOWER & HIGHER PAY REASON](#sala)<br>\n    3.3. [Minimum requirement qualification : ](#minireq)<br>","ce11a720":"### 3.3. Requirement minimum qualification data\n<a id=\"minireq\"><\/a>\n* REQUIREMENT MINIMUM QUALIFICATION\n* NOTE","dbec1d7e":"### 3.2. Salary data\n<a id=\"sala\"><\/a>\n* ANNUAL SALARY\n* NOTE","566f90a2":"Here below some example of verbatim reduction from ANNUAL_SALARY as in the bulletin to ANNUAL_SALARY_REDUCED_BIS which get the pattern of the salary","3e04c1b8":"We note that 3 job bulletins title does not match the file name :\n* ANIMAL CARE TECHNICIAN SUPERVISOR 4313 122118.txt\n* SENIOR EXAMINER OF QUESTIONED DOCUMENTS 3231 072216 REVISED 072716.txt\n* WASTEWATER COLLECTION SUPERVISOR 4113 121616.txt\n\nThe bulletin VOCATIONAL WORKER DEP OF PUBLIC WORKS does not have a common framework shared with the other files. We remove it from our analysis.","6da85ba8":"Thus we get a list of the most common typology of salary as in the bulletin:\n* Some just contain salaries as range (XX), other as flat rated (FF FLAT RATE)\n* Other are related to specific Departements : Water and Power, Airport, Harbor","e3bfeea8":"The last action to perform is to make \"hand\" correction by analysing the similarity between some headers to merge columns to enhance the completion of information.","f44d589a":"We would like to check the matching between the name of the file and the title position they content.\nSo we use the similarity string between JOB_TITLE_TXT and JOB_NALE_TXT","e7040fcf":"We can expect that some job bulettins are not reprensented in the list of job title positions contained in the csv.","5a5a32ab":"Let's have a quick look to how the ANNUAL_SALARY_NOTE data is presented :","b871a0e1":"In addition to quantitative data related to salary, there are qualitative data contained for the mostly contained in the NOTES part attached to the ANNUAL SALARY part.","a97d20b2":"We need to standardize the headers of the dataframe we built :\n* Remove stop words and ponctuation if any\n* Correct wording mistake\n* Singularize words\n* Combine NOTE(S) headers ","443c6b56":"The main folder CityofLA include two subfodlers:","13fb40da":"### 2.1. Example\n\n<a id=\"expl\"><\/a>","f0174c82":"We detect that for one offer, none salary is mentionned : ","6cb0c4d6":"How about to start a small visualization that those data ? <br>\nWe will try to first if we can make any conclusion about how are the range salary for specific departments compare with salary without specification fo departement","eff110f6":"### 1.3. Folder content\n<a id=\"Folcont\"><\/a>","f740ba64":"We can expect that several job descriptions rely to a same job position.","de6165ac":"#### Qualitative","3ac996eb":"Let's compare now the ranged salaries with the flated ones","a4bc5c58":"# DATASCIENCE4GOOD : City of LA","90ba5dd7":"Thus we get a list of the most common typology of informations related to the note salary as in the bulletin:\n* Grade position,\n* Night and shift work bonus,\n* Part time position,\n* Start level salary,\n* Multiple range grade,\n* Salary to confirm,\n* Possible salary change,\n* Confirm hiring salary","72996b60":"We can have a look now to the salary data structured in our dataframe","7844446a":"For some positions no additional information is provided about the salay :"}}