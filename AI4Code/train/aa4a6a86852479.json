{"cell_type":{"e09cc1cd":"code","4b4df32a":"code","ed90b95f":"code","f035054e":"code","ca8d4179":"code","6a33a3ae":"code","8e151473":"code","9a74dd77":"code","a5c100f5":"code","5b463966":"code","600fc81f":"code","6c5ecb3a":"code","73eef996":"code","0e57de83":"code","b3461c8e":"code","05fadab0":"code","b8298101":"code","02641e8c":"code","803edd47":"code","31d353a0":"code","59ccc78c":"code","9f0d9564":"code","f6008fba":"code","dcd93a40":"code","662bc85b":"code","b9dbe54c":"code","2678914c":"code","197003fa":"code","6a00bff8":"code","9611cb76":"code","2ed6d2a9":"code","48921919":"code","22123dbc":"code","7498883b":"code","15990614":"code","da25c699":"code","f0e4ba5b":"code","03d996c2":"code","7a6a7f2c":"code","c9ef9cea":"code","11007ff4":"code","170b1b4c":"code","a94ed90d":"code","ab3649c8":"code","32eb18db":"code","bdcfa727":"code","bc9f5447":"code","6b75626b":"code","e1f7593e":"code","07a36016":"code","f6ca8f05":"code","f9c92661":"code","47f11112":"code","607ae933":"code","bf9ba806":"code","59ee7002":"code","5b5cc173":"code","3f10f045":"code","4b31ee95":"code","85a55ef7":"code","e4cf6869":"code","f2fcceff":"code","c2b3330d":"code","4b229d64":"code","893c9818":"code","50d0a857":"code","a1bda01b":"code","469a2fc3":"code","30496583":"code","68b6a2fe":"code","7695ca04":"code","4a9c9044":"code","ad893a45":"code","194a1ef3":"code","9718de8f":"code","f054801c":"code","6508e826":"code","97e1a379":"code","5d8e9925":"code","20ffd3d6":"code","747444f4":"code","a1e39a80":"code","39f78b67":"code","69c7dc8b":"code","fb6ec0bc":"code","bef0bb87":"code","40186014":"code","a5995acc":"code","74f5fa7f":"code","cac7cf61":"code","73303b0c":"code","fbdb9dcc":"code","6d679825":"code","746a6b63":"code","ca83f565":"code","1075cc8c":"code","f2210be4":"code","edc897ae":"code","8c894031":"code","c942985a":"code","bea86639":"code","d47d99c4":"code","3c6c55ca":"code","bb2ac9fa":"code","81342cf4":"code","2c04213a":"code","0bf89384":"code","580a874d":"code","42e0a647":"code","b693311b":"code","9b17d122":"code","dd9c3dd1":"code","f5a8edf6":"code","4d73060a":"code","52f6b69a":"code","ffe207af":"code","4d48977e":"code","0f3d7cde":"code","58d741da":"code","01790a14":"code","92910ec3":"code","ee180279":"code","3c9bb209":"code","73deb65a":"markdown","e422c875":"markdown","c00bd290":"markdown","552cc851":"markdown","8472e5d4":"markdown","64c5970a":"markdown","6cd566c1":"markdown","60421046":"markdown","68b659c8":"markdown","a8159b90":"markdown","4ef4ad57":"markdown"},"source":{"e09cc1cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingClassifier\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.regularizers import l1_l2\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b4df32a":"dat_train=pd.read_csv(\"\/kaggle\/input\/ipl-2020-player-performance\/Training.csv\")\ndatipl_08_19=pd.read_csv(\"\/kaggle\/input\/ipl-2020-player-performance\/Matches IPL 2008-2019.csv\")","ed90b95f":"dat_train.describe()","f035054e":"#checking if there is any null value or not\ndat_train.isnull().any()","ca8d4179":"summvaluebat=0\nsumvaluebowl=0\nsumvaluetot=0\ndatcop=dat_train","6a33a3ae":"# Checking if the scores are correct according to the given formula if not then correcting it\n\n#part for batting score\n\nfor i in range(len(dat_train)):\n    if(dat_train.iloc[i]['Fifty']==1):\n        sumvaluebat=dat_train.iloc[i]['Runs']+dat_train.iloc[i]['Boundaries']+2*dat_train.iloc[i]['Six']+8\n    elif(dat_train.iloc[i]['Hundred']):\n        sumvaluebat=dat_train.iloc[i]['Runs']+dat_train.iloc[i]['Boundaries']+2*dat_train.iloc[i]['Six']+16\n    elif(dat_train.iloc[i]['Runs']==0):\n        sumvaluebat=-2\n    else:\n        sumvaluebat=dat_train.iloc[i]['Runs']+dat_train.iloc[i]['Boundaries']+2*dat_train.iloc[i]['Six']\n        \n    if(sumvaluebat!=dat_train.iloc[i]['Batting_Points']):\n        datcop.loc[i,'Batting_Points']=sumvaluebat\n    \n    #part for bowling score    \n    if(dat_train.iloc[i]['4W_Haul']==1):\n        sumvaluebowl=25*dat_train.iloc[i]['Wickets']+8+8*dat_train.iloc[i]['Maidens']\n    elif(dat_train.iloc[i]['5W_Haul']==1):\n        sumvaluebowl=25*dat_train.iloc[i]['Wickets']+16+8*dat_train.iloc[i]['Maidens']\n    else:\n        sumvaluebowl=25*dat_train.iloc[i]['Wickets']+8*dat_train.iloc[i]['Maidens']\n        \n    if(sumvaluebowl!=dat_train.iloc[i]['Bowling_Points']):\n        datcop.loc[i,'Bowling_Points']=sumvaluebowl\n        \n    x=sumvaluebat+sumvaluebowl\n\n    \n    if(x!=dat_train.iloc[i]['Total Points']):\n        datcop.loc[i,'Total Points']=x","8e151473":"#corrected data\ndatcop.head()","9a74dd77":"#setting index and finding null values\ndatipl_08_19=datipl_08_19.sort_values(['match_id'])\ndatipl_08_19=datipl_08_19.set_index('match_id')\ndatipl_08_19.isna().any()","a5c100f5":"#nan value at 11413 so will remove this row later from consolidated view as it will create problem while training the model\ndatipl_08_19[datipl_08_19.index==11413]","5b463966":"datipl_08_19.columns","600fc81f":"# combining data set for easing the work later\n\nk=0\nfor i in datipl_08_19.index:\n    for j in range(len(datcop)):\n        \n        if(int(''.join(filter(str.isdigit,datcop['Id'][j])))==datipl_08_19.index[k]):\n            datcop.loc[j,'team1']=datipl_08_19.loc[i,'team1']\n            datcop.loc[j,'team2']=datipl_08_19.loc[i,'team2']\n            datcop.loc[j,'venue']=datipl_08_19.loc[i,'venue']\n            datcop.loc[j,'umpire1']=datipl_08_19.loc[i,'umpire1']\n            datcop.loc[j,'umpire2']=datipl_08_19.loc[i,'umpire2']\n    k=k+1","6c5ecb3a":"datcop.columns","73eef996":"#starting organizing data according to the ipl2020.csv\nx=['Id', 'team1', 'team2', 'venue', 'umpire1','umpire2', 'Total Points']\ndatcop=datcop[x]","0e57de83":"#extracting playername from id\nk=0\nfor i in datcop[\"Id\"]:\n    \n    datcop.loc[k,'playername']=\"\".join(filter(str.isalpha,datcop.loc[k,'Id']))\n    k=k+1","b3461c8e":"#removing all the rows with null values as they may cause an error later\ndatcop=datcop.dropna()","05fadab0":"datcop","b8298101":"#preparing testdata \ntestdata=pd.DataFrame(columns=['Id','playername'])","02641e8c":"sample=pd.read_csv('\/kaggle\/input\/ipl-2020-player-performance\/sample_submission.csv')","803edd47":"#extracting player name from id in samplesubmission.csv\nfor i in range(len(sample)):\n    testdata.loc[i,'playername']=''.join(filter(str.isalpha,sample['Id'][i]))\n    testdata.loc[i,'Id']=int(''.join(filter(str.isnumeric,sample['Id'][i])))","31d353a0":"testdata.head()","59ccc78c":"testdata2=pd.read_csv('\/kaggle\/input\/ipl-2020-player-performance\/Matches IPL 2020.csv')","9f0d9564":"# using sample the data from 2 different csv to make test data\nfor i in range(len(testdata2)):\n    for j in range(len(testdata)):\n        if(testdata[\"Id\"][j]==testdata2['match_id'][i]):\n            testdata.loc[j,'venue']=testdata2.loc[i,'venue']\n            testdata.loc[j,'umpire1']=testdata2.loc[i,'umpire1']\n            testdata.loc[j,'umpire2']=testdata2.loc[i,'umpire2']\n            testdata.loc[j,'team1']=testdata2.loc[i,'team1']\n            testdata.loc[j,'team2']=testdata2.loc[i,'team2']","f6008fba":"#This part was done manually because making the code for it would have taken a lot more time than doing it manuaaly\n\ntestdata=testdata.replace({'Virender Sharma':'Virender Kumar Sharma'})\ntestdata=testdata.replace({'Sheikh Zayed Stadium, Abu Dhabi':'Sheikh Zayed Stadium'})\ntestdata=testdata.replace({'Chettithody Shamshuddin':'C Shamshuddin'})\ntestdata=testdata.replace({'Richard Illingworth':'RK Illingworth'})\ntestdata=testdata.replace({'Pashchim Pathak':'PG Pathak'})\ntestdata=testdata.replace({'Paul Reiffel':'PR Reiffel'})\ntestdata=testdata.replace({'Krishnamachari Srinivasan':'K Srinivasan'})\n\nnamechanger={'MI':'Mumbai Indians','RCB':'Royal Challengers Bangalore','RR':'Rajasthan Royals','SRH':'Sunrisers Hyderabad','KXIP':'Kings XI Punjab','KKR':'Kolkata Knight Riders','DC':'Delhi Capitals','CSK':'Chennai Super Kings'}\ntestdata=testdata.replace(namechanger)","dcd93a40":"testdata","662bc85b":"datcop","b9dbe54c":"#finding unique and then reducing the training set according to the test set\npnamtesdata=testdata.playername.unique()\npnamdcopdata=datcop.playername.unique()\npnamtesdata=set(pnamtesdata)\npnamdcopdata=set(pnamdcopdata)\nnotreqfromdatcop=pnamdcopdata-pnamtesdata\nrequiredindatcop=pnamtesdata-pnamdcopdata\nrequiredindatcop=list(requiredindatcop)\nprint(len(requiredindatcop))\n","2678914c":"notreqfromdatcop=list(notreqfromdatcop)","197003fa":"for i in notreqfromdatcop: \n    index_names = datcop[ datcop['playername'] == i ].index \n    datcop.drop(index_names, inplace = True) ","6a00bff8":"datcop.tail()","9611cb76":"#making a list of rows not in datcop but are in testdata and then adding those datcop which will ease up training after one-hot ecoding \nlis=[]\nfor i in requiredindatcop:\n    rslt_df = testdata[testdata['playername'] ==i]\n    lis.append(rslt_df)\n    \nfor i in range(len(lis)):\n    lis[i]=lis[i][['Id','team1', 'team2', 'venue', 'umpire1', 'umpire2', 'playername']]\n    \nempty=pd.DataFrame(columns=['team1', 'team2', 'venue', 'umpire1', 'umpire2', 'playername'])\n\nfor i in range(len(lis)):\n    empty=empty.append(lis[i])\n    \nind=[]\ncounter=15916\nfor i in range(len(empty)):\n    ind.append(counter)\n    counter=counter+1","2ed6d2a9":"x=empty.index\ncounter=0\nfor i in x:\n    empty.loc[i,'ind']=ind[counter]\n    empty.loc[i,'ind']=int(empty.loc[i,'ind'])\n    counter=counter+1","48921919":"empty.tail()","22123dbc":"data_types_dict = {'ind': int} \nempty = empty.astype(data_types_dict)","7498883b":"empty=empty.set_index('ind')","15990614":"mval=datcop['Total Points'].unique().mean()\nfor i in empty.index:\n    empty.loc[i,'Total Points']=np.round(mval)","da25c699":"empty=empty[['team1', 'team2', 'venue', 'umpire1', 'umpire2', 'playername','Total Points']]","f0e4ba5b":"dtcop2=datcop\ndatcop=datcop.append(empty)\nprint(datcop.columns)","03d996c2":"datcop=datcop[['Id', 'team1', 'team2', 'umpire1', 'umpire2','playername', 'venue','Total Points']]","7a6a7f2c":"#some id's are empty because we appended empty dataset without id's\ndatcop.isna().any()","c9ef9cea":"#doing one hot encoding as almost every feature is actually categorical\ndatcop2=datcop[['team1', 'team2', 'umpire1', 'umpire2','playername','Total Points']]\ndatcop2=pd.get_dummies(data=datcop2, drop_first=True)","11007ff4":"testdata.isna().any()","170b1b4c":"testdatafinal=testdata[['team1', 'team2', 'umpire1', 'umpire2','playername']]\ntestdatafinal.isna().any()\ntestdatafinal=pd.get_dummies(data=testdatafinal, drop_first=True)\ntestdatafinal1=list(testdatafinal.columns)\ntestdatafinal1.append('Total Points')\ndatcop2=datcop2[testdatafinal1]\nprint(len(datcop2.columns))","a94ed90d":"traindata=datcop2[list(testdatafinal)]","ab3649c8":"output=datcop2['Total Points']","32eb18db":"import seaborn as sns\nimport matplotlib.pyplot as plt","bdcfa727":"dat_train.columns","bc9f5447":"continiousval=['Runs', 'Boundaries', 'Six', 'Fifty', 'Hundred', 'Duck','Batting_Points', 'Wickets', '4W_Haul', '5W_Haul', 'Maidens','Bowling_Points', 'Total Points',]","6b75626b":"#heatmap before converting our categorical data\nplt.figure(figsize=(20,20))\nsns.heatmap(dat_train.corr(),annot=True,cmap='spring_r',square=True)\nplt.show()","e1f7593e":"# heatmap after converting our categorical data but it's too large\nplt.figure(figsize=(20,20))\nsns.heatmap(datcop2.corr(),annot=True,cmap='spring_r',square=True)\nplt.show()","07a36016":"#histograms\nfig=plt.figure(figsize=(10,10))\nax=fig.gca()\ndat_train.hist(ax=ax)\nplt.show()","f6ca8f05":"#splitting up data for training and testing(from training data itself)","f9c92661":"X, x_test, Y, y_test = train_test_split(traindata, output, test_size=0.2, random_state = 42)","47f11112":"from sklearn.linear_model import LinearRegression","607ae933":"# Linear Regression Model\nmodel= LinearRegression()\nY=np.ravel(Y)\nmodel.fit(X,Y)\nprediction=model.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","bf9ba806":"from sklearn.metrics import mean_squared_error","59ee7002":"print(mean_squared_error(y_test,prediction))","5b5cc173":"print(model.score(x_test,y_test))","3f10f045":"#lets say we do it using normal training data because of variables bowling points and batting points \n#it would be really easy for model to predict it but these are not actually present in ipl2020.csv\ndat_train.columns","4b31ee95":"trdata=dat_train[['Runs', 'Boundaries', 'Six', 'Fifty', 'Hundred', 'Duck',\n       'Batting_Points', 'Wickets', '4W_Haul', '5W_Haul', 'Maidens',\n       'Bowling_Points']]","85a55ef7":"oudata=dat_train[['Total Points']]","e4cf6869":"X, x_test, Y, y_test = train_test_split(trdata, oudata, test_size=0.2, random_state = 42)","f2fcceff":"model= LinearRegression()\nY=np.ravel(Y)\nmodel.fit(X,Y)\nprediction=model.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","c2b3330d":"print(mean_squared_error(y_test,prediction))\nprint(model.score(x_test,y_test))","4b229d64":"model1=svm.SVC(kernel='linear')\nmodel2=DecisionTreeClassifier()\nmodel3=KNeighborsClassifier(n_neighbors=5)\nmodel4=RandomForestClassifier(n_estimators=100)","893c9818":"X, x_test, Y, y_test = train_test_split(traindata, output, test_size=0.2, random_state = 42)","50d0a857":"# svm\nY=np.ravel(Y)\nmodel1.fit(X,Y)\nprediction=model1.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","a1bda01b":"print(mean_squared_error(y_test,prediction))\nprint(model1.score(x_test,y_test))","469a2fc3":"#decision tree\nmodel2.fit(X,Y)\nprediction=model2.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","30496583":"print(mean_squared_error(y_test,prediction))\nprint(model2.score(x_test,y_test))","68b6a2fe":"#knn\nmodel3.fit(X,Y)\nprediction=model3.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","7695ca04":"print(mean_squared_error(y_test,prediction))\nprint(model3.score(x_test,y_test))","4a9c9044":"# random forest\nmodel4.fit(X,Y)\nprediction=model4.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","ad893a45":"print(mean_squared_error(y_test,prediction))\nprint(model4.score(x_test,y_test))","194a1ef3":"# basic neural network for regression\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=189, activation= \"relu\"))\nmodel.add(Dense(64, activation= \"relu\"))\nmodel.add(Dense(32, activation= \"relu\"))\nmodel.add(Dense(1))\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.01), loss='mse', metrics=['mae'])\nhistory=model.fit(X, Y, epochs=20,batch_size=32)","9718de8f":"from sklearn.metrics import accuracy_score","f054801c":"prediction=model.predict(x_test)\nprediction=np.round(prediction)\nprediction=np.int64(prediction)","6508e826":"score = accuracy_score(y_test, prediction)\nprint(score)","97e1a379":"\n# summarize history for loss(mse) and mae\nplt.plot(history.history['loss'])\nplt.plot(history.history['mae'])\n\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","5d8e9925":"dat_train=pd.read_csv(\"\/kaggle\/input\/ipl-2020-player-performance\/Training.csv\")\ndatipl_08_19=pd.read_csv(\"\/kaggle\/input\/ipl-2020-player-performance\/Matches IPL 2008-2019.csv\")","20ffd3d6":"summvaluebat=0\nsumvaluebowl=0\nsumvaluetot=0\ndatcop=dat_train\n#part for batting score\n\nfor i in range(len(dat_train)):\n    if(dat_train.iloc[i]['Fifty']==1):\n        sumvaluebat=dat_train.iloc[i]['Runs']+dat_train.iloc[i]['Boundaries']+2*dat_train.iloc[i]['Six']+8\n    elif(dat_train.iloc[i]['Hundred']):\n        sumvaluebat=dat_train.iloc[i]['Runs']+dat_train.iloc[i]['Boundaries']+2*dat_train.iloc[i]['Six']+16\n    elif(dat_train.iloc[i]['Runs']==0):\n        sumvaluebat=-2\n    else:\n        sumvaluebat=dat_train.iloc[i]['Runs']+dat_train.iloc[i]['Boundaries']+2*dat_train.iloc[i]['Six']\n        \n    if(sumvaluebat!=dat_train.iloc[i]['Batting_Points']):\n        datcop.loc[i,'Batting_Points']=sumvaluebat\n    \n    #part for bowling score    \n    if(dat_train.iloc[i]['4W_Haul']==1):\n        sumvaluebowl=25*dat_train.iloc[i]['Wickets']+8+8*dat_train.iloc[i]['Maidens']\n    elif(dat_train.iloc[i]['5W_Haul']==1):\n        sumvaluebowl=25*dat_train.iloc[i]['Wickets']+16+8*dat_train.iloc[i]['Maidens']\n    else:\n        sumvaluebowl=25*dat_train.iloc[i]['Wickets']+8*dat_train.iloc[i]['Maidens']\n        \n    if(sumvaluebowl!=dat_train.iloc[i]['Bowling_Points']):\n        datcop.loc[i,'Bowling_Points']=sumvaluebowl\n        \n    x=sumvaluebat+sumvaluebowl\n\n    \n    if(x!=dat_train.iloc[i]['Total Points']):\n        datcop.loc[i,'Total Points']=x","747444f4":"datipl_08_19=datipl_08_19.sort_values(['match_id'])\ndatipl_08_19=datipl_08_19.set_index('match_id')","a1e39a80":"datipl_08_19.isna().any()","39f78b67":"k=0\nfor i in datipl_08_19.index:\n    for j in range(len(datcop)):\n        \n        if(int(''.join(filter(str.isdigit,datcop['Id'][j])))==datipl_08_19.index[k]):\n            datcop.loc[j,'team1']=datipl_08_19.loc[i,'team1']\n            datcop.loc[j,'team2']=datipl_08_19.loc[i,'team2']\n            datcop.loc[j,'venue']=datipl_08_19.loc[i,'venue']\n            datcop.loc[j,'umpire1']=datipl_08_19.loc[i,'umpire1']\n            datcop.loc[j,'umpire2']=datipl_08_19.loc[i,'umpire2']\n    k=k+1","69c7dc8b":"x=['Id', 'team1', 'team2', 'venue', 'umpire1','umpire2', 'Total Points']\ndatcop=datcop[x]","fb6ec0bc":"k=0\nfor i in datcop[\"Id\"]:\n    datcop.loc[k,'playername']=\"\".join(filter(str.isalpha,datcop.loc[k,'Id']))\n    k=k+1","bef0bb87":"datcop=datcop.dropna()","40186014":"testdata=pd.DataFrame(columns=['Id','playername'])\ntestdata","a5995acc":"sample=pd.read_csv('\/kaggle\/input\/ipl-2020-player-performance\/sample_submission.csv')\nfor i in range(len(sample)):\n    testdata.loc[i,'playername']=''.join(filter(str.isalpha,sample['Id'][i]))\n    testdata.loc[i,'Id']=int(''.join(filter(str.isnumeric,sample['Id'][i])))","74f5fa7f":"testdata2=pd.read_csv('\/kaggle\/input\/ipl-2020-player-performance\/Matches IPL 2020.csv')","cac7cf61":"for i in range(len(testdata2)):\n    for j in range(len(testdata)):\n        if(testdata[\"Id\"][j]==testdata2['match_id'][i]):\n            testdata.loc[j,'venue']=testdata2.loc[i,'venue']\n            testdata.loc[j,'umpire1']=testdata2.loc[i,'umpire1']\n            testdata.loc[j,'umpire2']=testdata2.loc[i,'umpire2']\n            testdata.loc[j,'team1']=testdata2.loc[i,'team1']\n            testdata.loc[j,'team2']=testdata2.loc[i,'team2']","73303b0c":"testdata=testdata.replace({'Virender Sharma':'Virender Kumar Sharma'})\ntestdata=testdata.replace({'Sheikh Zayed Stadium, Abu Dhabi':'Sheikh Zayed Stadium'})\ntestdata=testdata.replace({'Chettithody Shamshuddin':'C Shamshuddin'})\ntestdata=testdata.replace({'Richard Illingworth':'RK Illingworth'})\ntestdata=testdata.replace({'Pashchim Pathak':'PG Pathak'})\ntestdata=testdata.replace({'Paul Reiffel':'PR Reiffel'})\ntestdata=testdata.replace({'Krishnamachari Srinivasan':'K Srinivasan'})","fbdb9dcc":"namechanger={'MI':'Mumbai Indians','RCB':'Royal Challengers Bangalore','RR':'Rajasthan Royals','SRH':'Sunrisers Hyderabad','KXIP':'Kings XI Punjab','KKR':'Kolkata Knight Riders','DC':'Delhi Capitals','CSK':'Chennai Super Kings'}","6d679825":"testdata=testdata.replace(namechanger)","746a6b63":"#finding out what i actually require to train\npntedata=testdata.playername.unique()\npndcdata=datcop.playername.unique()\npntedata=set(pntedata)\npndcdata=set(pndcdata)\nnotreqfromdatcop=pndcdata-pntedata\nrequiredindatcop=pntedata-pndcdata\nrequiredindatcop=list(requiredindatcop)\nlen(requiredindatcop)\nnotreqfromdatcop=list(notreqfromdatcop)\nlen(notreqfromdatcop)","ca83f565":"for i in notreqfromdatcop: \n    index_names = datcop[ datcop['playername'] == i ].index \n    datcop.drop(index_names, inplace = True) ","1075cc8c":"lis=[]\nfor i in requiredindatcop:\n    rslt_df = testdata[testdata['playername'] ==i]\n    lis.append(rslt_df)","f2210be4":"for i in range(len(lis)):\n    lis[i]=lis[i][['Id','team1', 'team2', 'venue','umpire1', 'umpire2', 'playername']]","edc897ae":"empty=pd.DataFrame(columns=['Id','team1', 'team2','venue', 'umpire1', 'umpire2', 'playername'])","8c894031":"for i in range(len(lis)):\n    empty=empty.append(lis[i])","c942985a":"ind=[]\ncounter=15916\nfor i in range(len(empty)):\n    ind.append(counter)\n    counter=counter+1","bea86639":"x=empty.index\n\nrot=0\nfor i in x:\n    empty.loc[i,'ind']=ind[rot]\n    empty.loc[i,'ind']=int(empty.loc[i,'ind'])\n    rot=rot+1\n    \ndata_types_dict = {'ind': int} \nempty = empty.astype(data_types_dict)","d47d99c4":"empty=empty.set_index('ind')\nfor i in empty.index:\n    empty.loc[i,'Total Points']=90\n\nempty=empty[['team1', 'team2', 'venue','umpire1', 'umpire2', 'playername','Total Points']]","3c6c55ca":"datcop=datcop.append(empty)","bb2ac9fa":"x= datcop['playername'].unique()\ndict_players={}\nfor i in range(len(x)):\n    dict_players[x[i]]=i","81342cf4":"x=datcop.team1.unique()\ndict_team1={}\nfor i in range(len(x)):\n    dict_team1[x[i]]=i","2c04213a":"x=datcop.venue.unique()\ndict_ven={}\nfor i in range(len(x)):\n    dict_ven[x[i]]=i","0bf89384":"x=datcop.umpire1.unique()\ndict_umpire1={}\nfor i in range(len(x)):\n    dict_umpire1[x[i]]=i\n    \nx=datcop.umpire2.unique()\ndict_umpire2={}\nfor i in range(len(x)):\n    dict_umpire2[x[i]]=i\n    \nreq=set(dict_umpire1)-set(dict_umpire2)\nact=list(dict_umpire2)\n\nfor i in req:\n    act.append(i)\n    \ndict_totumpire={}\nfor i in range(len(act)):\n    dict_totumpire[act[i]]=i","580a874d":"datcop2=datcop\ndatcop.playername=datcop.playername.replace(dict_players)\ndatcop.team1=datcop.team1.replace(dict_team1)\ndatcop.team2=datcop.team2.replace(dict_team1)\ndatcop.umpire1=datcop.umpire1.replace(dict_totumpire)\ndatcop.umpire2=datcop.umpire2.replace(dict_totumpire)\ndatcop.venue=datcop.venue.replace(dict_ven)","42e0a647":"datcop=datcop[['team1','team2','venue','umpire1','umpire2','playername','Total Points']]","b693311b":"train=datcop[['playername']]","9b17d122":"output=datcop[['Total Points']]","dd9c3dd1":"testdata.playername=testdata.playername.replace(dict_players)","f5a8edf6":"testdata.team1=testdata.team1.replace(dict_team1)\ntestdata.team2=testdata.team2.replace(dict_team1)\ntestdata.umpire1=testdata.umpire1.replace(dict_totumpire)\ntestdata.umpire2=testdata.umpire2.replace(dict_totumpire)\ntestdata.venue=testdata.venue.replace(dict_ven)","4d73060a":"testdatafinal=testdata[['playername']]","52f6b69a":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import MultiTaskLasso\nfrom sklearn.linear_model import ARDRegression\nfrom sklearn.linear_model import LassoLars\nfrom sklearn.linear_model import BayesianRidge\n\nfrom sklearn.ensemble import VotingRegressor","ffe207af":"X, x_test, Y, y_test = train_test_split(train, output, test_size=0.1, random_state = 42)","4d48977e":"model1=LinearRegression()\nmodel2=Ridge(alpha=0.1)\nmodel3=Lasso(alpha=0.1)\nmodel4=BayesianRidge()\nmodel5=ARDRegression()","0f3d7cde":"evc=VotingRegressor(estimators=[('model1',model1),('model2',model2),('model3',model3),('model4',model4),('model5',model5)])","58d741da":"Y=np.ravel(Y)","01790a14":"evc.fit(X,Y)","92910ec3":"from sklearn.metrics import accuracy_score\npred=evc.predict(x_test)\npred=np.round(pred)\npred=np.int64(pred)\nscore=accuracy_score(y_test,pred)\nprint(score)","ee180279":"model = Sequential()\nmodel.add(Dense(128, input_dim=1, activation= \"relu\",activity_regularizer=l1_l2(l1=0.1, l2=0.1)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation= \"relu\",activity_regularizer=l1_l2(l1=0.2, l2=0.2)))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(32,  activation= \"relu\",activity_regularizer=l1_l2(l1=0.1, l2=0.1)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(16, activation= \"relu\",activity_regularizer=l1_l2(l1=0.2, l2=0.2)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(8, activation= \"relu\",activity_regularizer=l1_l2(l1=0.1, l2=0.1)))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1))\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['mae'])\nhistory=model.fit(X, Y, validation_data=(x_test, y_test),epochs=300,batch_size=64)","3c9bb209":"# predictionforsubmission=model.predict(testdatafinal)\n# predictionforsubmission=np.round(predictionforsubmission)\n# predictionforsubmission=np.int64(predictionforsubmission)\n# sample=pd.read_csv('....................\\sample_submission.csv')\n\n# for i in range(len(sample)):\n#     sample.loc[i,'Total Points']=predictionforsubmission[i]\n# sample=sample.set_index('Id')\n# sample.to_csv('.........................\\sample_submission_final.csv')","73deb65a":"Even neural networks are not able to infer any thing from this data","e422c875":"Before we move ahead with predictions lets do some EDA","c00bd290":"# Importing necessary libraries","552cc851":"# Preprocessing Data","8472e5d4":"Got The best result with neural network","64c5970a":"# our training testing data is finaly complete","6cd566c1":"# Machine Learning and Neural Network for model","60421046":"Basically one hot encoding is not a good way for regression so we tagged each category with a unique number","68b659c8":"# Making test data using samplesubmission.csv and ipl2020.csv","a8159b90":"Saving the predicted Data","4ef4ad57":"# Approach2"}}