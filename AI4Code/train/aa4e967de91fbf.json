{"cell_type":{"15644056":"code","ce4a0010":"code","7da9cb07":"code","5f5df219":"code","164bc504":"code","d40070a7":"code","0a8d7e6f":"code","f3bcb9d3":"code","13f6f9d9":"code","f0fcb1c1":"code","315d9c2c":"code","49970ca6":"code","086937a7":"code","3b683764":"code","f35f11d9":"code","7a2d2c6d":"code","e513fb04":"code","86095d2c":"code","848b22ef":"code","6ba79a3b":"code","c853d5f1":"code","1d305898":"code","cf37a79f":"code","ac57155f":"code","85775d6c":"code","51bed861":"code","99f51c4f":"code","b2399a13":"code","e218b0a9":"code","05bc864e":"code","3280be6d":"code","a9b2a12b":"code","9559679a":"code","df76d988":"code","1f317469":"code","2b956c3d":"markdown","22982f56":"markdown","3363be38":"markdown","ce9180d5":"markdown","769b9445":"markdown","c7e2e795":"markdown","22bf43e7":"markdown","bb342cce":"markdown","b74e2a31":"markdown","46eee98b":"markdown","d0186667":"markdown","05622532":"markdown","f94f4a70":"markdown","4841318e":"markdown","88dbd75a":"markdown","794d9327":"markdown","8580490c":"markdown","14468c20":"markdown","64aabc7d":"markdown","52455003":"markdown","a54f0c99":"markdown","50024407":"markdown","c2f9b575":"markdown","23a6db4d":"markdown","4fca9156":"markdown","56b6c860":"markdown","fdb64b3c":"markdown","da6936a2":"markdown","0cba3dbe":"markdown","4098df2a":"markdown","b2ae54bc":"markdown","39a9845f":"markdown","42b6999c":"markdown","a51c41d4":"markdown","b7d2796d":"markdown","78bb8b2c":"markdown","7db9c962":"markdown","afb1f9f6":"markdown","ab7ea08c":"markdown","ec0cc2c3":"markdown","785253ab":"markdown","39332374":"markdown","abe8b380":"markdown","18a87f32":"markdown","1fe03fe6":"markdown","aa764564":"markdown"},"source":{"15644056":"# for visualization -------------------\n\nimport matplotlib.pyplot as plt\nimport seaborn as srn\n\n# for data pipeline --------------------\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import*\n\n# for prediction (machine learning models) ------------------------\n\nfrom sklearn.linear_model import*\nfrom sklearn.preprocessing import*\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestRegressor","ce4a0010":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7da9cb07":"df=pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')\nprint(df.head())","5f5df219":"print('shape of the dataset is :',df.shape)","164bc504":"l1=df.isnull()\nfor col in l1.columns:\n    print('leakage in '+col+' is :  ',len(l1[l1[col]==True]))","d40070a7":"for col in df.columns:\n    print(col,end=\" \")","0a8d7e6f":"colm=[]\nfor col in df.columns:\n    print('type of '+col+' is : ',df[col].dtypes)\n    colm.append(col)","f3bcb9d3":"a=df['sex'].value_counts()\nprint('index  count')\nprint(a)\nprint('\\n\\n')\nb=df['smoker'].value_counts()\nprint('index  count')\nprint(b)\nprint('\\n\\n')\nc=df['region'].value_counts()\nprint(' index      count')\nprint(c)","13f6f9d9":"#   'sex' column encoding\nk=0\nfor i in a.index:\n    df['sex'].replace(i,k,inplace=True)\n    k+=1\n\n#   'smoker' column encoding\n\nk=0\nfor i in b.index:\n    df['smoker'].replace(i,k,inplace=True)\n    k+=1\n\n#   'region' column encoding\n\nk=0\nfor i in c.index:\n    df['region'].replace(i,k,inplace=True)\n    k+=1\ndf","f0fcb1c1":"charge=df['charges']\ncharge","315d9c2c":"age=df['age']\nplt.title('age vs. charges')\nplt.xlabel('age')\nplt.ylabel('charges')\nplt.scatter(age,charge,s=5)\nplt.show()","49970ca6":"bmi=df['bmi']\nplt.title('bmi vs. charges')\nplt.xlabel('bmi')\nplt.ylabel('charges')\nplt.scatter(bmi,charge,s=5)\nplt.show()","086937a7":"children=df['children']\nplt.title('children vs. charges')\nplt.xlabel('children')\nplt.ylabel('charges')\nplt.scatter(children,charge,s=5)\nplt.show()","3b683764":"sex=df['sex']\nsmoker=df['smoker']\nconfusion_matrix=pd.crosstab(sex, smoker, rownames=['sex'], colnames=['smoker'])\nsrn.heatmap(confusion_matrix, annot=True)\nplt.show()","f35f11d9":"reg=df['region']\nplt.figure(figsize=(10,5))\nplt.scatter(charge,reg,s=2)\nplt.title('region vs charges')\nplt.xlabel('charges')\nplt.ylabel('region label')\nplt.show()","7a2d2c6d":"xx=np.arange(1,len(df)+1,1)\nplt.scatter(xx,df['age'])","e513fb04":"X_df=df.drop('charges',1)\ny_df=df['charges']","86095d2c":"print('shape of X :',X_df.shape)\nprint('shape of Y :',y_df.shape)","848b22ef":"X_train,X_test,y_train,y_test=train_test_split(X_df,y_df,test_size=0.2)\nprint('shape of X_train :',X_train.shape)\nprint('shape of X_test :',X_test.shape)\nprint('shape of y_train :',y_train.shape)\nprint('shape of y_test :',y_test.shape)","6ba79a3b":"alp=np.arange(0.1,1.1,0.1)\narr=[]\nar1=[]\nfor i in alp:\n    clf=Ridge(alpha=i)\n    clf.fit(X_train,y_train)\n    m=clf.score(X_train,y_train)\n    print('alpha : ',i,'    accuracy : ',m)\n    arr.append(m)\nplt.plot(arr)\nplt.title('                                        training model accuracy with Ridge Regression')\nplt.xlabel('alpha')\nplt.ylabel('accuracy')","c853d5f1":"mm=[]\nfor i in alp:\n    model=Ridge(alpha=i)\n    model.fit(X_train,y_train)\n    y_pr=model.predict(X_test)\n    xx=np.sqrt(mean_squared_error(y_test,y_pr))\n    mm.append(xx)\n    print('RMSE for '+str(i)+' is :',xx)\nplt.plot(mm)\nplt.title('RMSE on Ridge model (testing data)')\nplt.xlabel('alpha')\nplt.ylabel('RMSE')\nplt.show()","1d305898":"arrr=np.arange(1,len(y_test)+1,1)\nplt.scatter(arrr,y_test,label='true',color='b',s=5)\nplt.legend()\nplt.scatter(arrr,y_pr,label='predicted',color='g',s=5)\nplt.legend()\nplt.title('true vs predicted ')\nplt.ylabel('charges')\nplt.show()","cf37a79f":"print(' best accuracy with ridge regression on training data :',max(arr))\nprint(' least RMSE with ridge regression on testing data :',min(mm))","ac57155f":"arr=[]\nar1=[]\nfor i in alp:\n    clf=Lasso(alpha=i)\n    clf.fit(X_train,y_train)\n    m=clf.score(X_train,y_train)\n    print('alpha : ',i,'    accuracy : ',m)\n    arr.append(m)\nplt.plot(arr)\nplt.title('                                        training model accuracy with Lasso Regression')\nplt.xlabel('alpha')\nplt.ylabel('accuracy')","85775d6c":"mm=[]\nfor i in alp:\n    model=Lasso(alpha=i)\n    model.fit(X_train,y_train)\n    y_pr=model.predict(X_test)\n    xx=np.sqrt(mean_squared_error(y_test,y_pr))\n    mm.append(xx)\n    print('RMSE for '+str(i)+' is :',xx)\nplt.plot(mm)\nplt.title('RMSE on Lasso model (testing data)')\nplt.xlabel('alpha')\nplt.ylabel('RMSE')\nplt.show()","51bed861":"arrr=np.arange(1,len(y_test)+1,1)\nplt.scatter(arrr,y_test,label='true',color='b',s=5)\nplt.legend()\nplt.scatter(arrr,y_pr,label='predicted',color='g',s=5)\nplt.legend()\nplt.title('true vs predicted ')\nplt.ylabel('charges')\nplt.show()","99f51c4f":"print(' best accuracy with ridge regression on training data :',max(arr))\nprint(' least RMSE with ridge regression on testing data :',min(mm))","b2399a13":"print('shape of X_train',X_train.shape)","e218b0a9":"tr=[]\nts=[]\nfor i in range(10):\n    model=make_pipeline(PolynomialFeatures(i+1),LinearRegression())\n    model.fit(X_train,y_train)\n    x1=model.score(X_train,y_train)\n    y_pr=model.predict(X_test)\n    x2=np.sqrt(mean_squared_error(y_test,y_pr))\n    tr.append(x1)\n    ts.append(x2)\n    print('tarining accuracy with '+str(i+1)+' degree  :',x1)\n    print('RMSE with '+str(i+1)+' degree  :',x2)","05bc864e":"plt.plot(tr)\nplt.title('accuracy in training model')\nplt.xlabel('degree')\nplt.ylabel('accuracy')\nplt.show()\nplt.plot(ts)\nplt.title('accuracy in testing model')\nplt.xlabel('degree')\nplt.ylabel('RMSE')\nplt.show()","3280be6d":"for i in range(len(tr)):\n    print('degree '+str(i+1)+'  : ',ts[i]\/tr[i])","a9b2a12b":"print('accuracy of the best fitted model by Polynomial Regression :',tr[5])\nprint('RMSE of the best fitted model by Polynomial Regression :',ts[5])","9559679a":"model=RandomForestRegressor(random_state=0)   \nmodel.fit(X_train,y_train)\ny_pr=model.predict(X_test)\nprint('RMSE of randomforest regression model  :',np.sqrt(mean_squared_error(y_test,y_pr)))\nprint('accuracy of the training data with randomforest regression model : ',model.score(X_train,y_train))","df76d988":"id1=np.arange(1,len(y_test)+1,1)\nx=pd.DataFrame({'id': id1,'charges':y_pr})\n","1f317469":"x.to_csv('submission.csv',index=False)","2b956c3d":"**This is an *additional conclusion* of the data**","22982f56":"Now we will see the how the charges change as per features.","3363be38":"# UPVOTE if you like the kernel  :)","ce9180d5":"The increase in alpha may lower the accuracy a bit , but it enhances the test accuracy","769b9445":"![doctors-hospital-design-jumbo.jpg](attachment:doctors-hospital-design-jumbo.jpg)","c7e2e795":"As we have to predict this model and we don't have any test data we are going to split the data into train and test","22bf43e7":"* Polynomial Regression","bb342cce":"* Making output ","b74e2a31":"* Random Forest Regression","46eee98b":"* Ridge Regression","d0186667":"For polynomial regression we we have 6 features to works on. \n\nSo degree of polynomial regression will be better if we do it under 6. Otherwise it will overfit the training data.","05622532":"# Data visualization ( visual prediction )","f94f4a70":"# Creating Output file","4841318e":"Creating X and Y for prediction","88dbd75a":"# Data gathering and basic visualization","794d9327":"It is visible the charges are in 3 ranges ,as well as the charges are incrasing with increasing age.","8580490c":"Generating ***output*** file","14468c20":"This is the **generalized method** how you interpret a **data science prediction-based project**.","64aabc7d":"* Lasso Regression","52455003":"It is clearly visible that non-smokers are bigger in number .\n\nand as well as men are bigger in number being a smoker","a54f0c99":"Conclusion :\n\n   **Model Accuracy** : RandomForestRegressor > Ridge Regressor > Lasso Regressor > PolynomialRegressor\n             ","50024407":"Our hypothesis worked as predicted. The RMSE increased after we overfit the data (degree>6). the **degree = 6** is th best for it.","c2f9b575":"Dataset is medium in size and this size is quite good for predicting","23a6db4d":"We can see increase of the value of alpha decreases the model accuracy over the training data.","4fca9156":"1. **Checking leakages  :**","56b6c860":"Preprocessing is done in some steps ---\n\n                                 1. Checking leakages \n                                 2. Filling leakages (if any)\n                                 3. Searching unnecessary column\/row for deletion\n                                 4. Unnecessary column\/row deletion (if any)\n                                 5. Encoding (if any)","fdb64b3c":"It is great that this data is leakage - free. \n\nSo, we don't have to replace or fill any leakages ","da6936a2":"As the data looks like quite shuffled so we are not doing **random reshuffling**.","0cba3dbe":"Charges are averaging in a lower 15000s , still there are not so few charges crossing 40000 barrier.\n\nThese could be the severe cases.","4098df2a":"5. Encoding :","b2ae54bc":"The data is short in size so we are going to do a 80%-20% train-test split","39a9845f":"* ***prediction with regression models*** ","42b6999c":"# Pipeline","a51c41d4":"People with less children are facing more bills aka they're having severe problems than others.\n\nIt concludes that people are much fit who has more children or should we say that it is vice-cersa ??   XD","b7d2796d":"Moreover it is seen that severs cases are low in number in every region.","78bb8b2c":"Checking the type of the columns :","7db9c962":"As every single column are pairwise unique , so deleting any data would shorten the tarining data and increase loss in prediction","afb1f9f6":"male-0 female-1\n\nnon_smoker-0 smoker-1\n\n","ab7ea08c":"For prediction purposes we have to change the object\/categorical data into numerical data .\nWe need encoding for that.","ec0cc2c3":"3. Searching unnecessary column\/row for deletion :","785253ab":"When it is time to code, it is easier to use library function that help us gain time in short or mid-range time based competitions.\nOtherwise we have to write large codes ","39332374":"The lasso and ridge model showed similar gesture","abe8b380":"# Libraries","18a87f32":"Note :\n\n       This Notebook is for beginners who are new to data science .\n       In here I will try to cover the basics how a project is maintained from start to end.\n       Before starting this I recommend to understand basic in-built functions of Python related to data science.\n       And after all try to analyze every single cell and don't copy the code rather try to fork and edit it as per your usage.\n       \n       \n **Thank You**","1fe03fe6":"# Pre-processing","aa764564":"![the%20end.jpg](attachment:the%20end.jpg)"}}