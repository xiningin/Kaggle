{"cell_type":{"b0637e0c":"code","9fb76a78":"code","db38d52f":"code","e39146a1":"code","5865da7c":"code","90a3a3d4":"code","67f5770c":"code","5ac01350":"code","64e67aab":"code","e129211b":"code","0aa5a86f":"code","49baf736":"code","7ed8e356":"code","8bde7155":"code","25d5e7fc":"code","1010e5fd":"code","4ebcb7e8":"code","fde45b56":"code","d5f8e038":"code","501242ca":"code","924df265":"markdown","08c760a1":"markdown"},"source":{"b0637e0c":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM, CuDNNLSTM\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\nimport pandas as pd","9fb76a78":"train = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()","db38d52f":"class_count = train['label'].value_counts()\nclass_count.plot(kind='bar', title='Check imbalanced data');","e39146a1":"test = pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()","5865da7c":"x_train = train.iloc[:,1:].values.astype('float32')\ny_train = train.iloc[:,0].values.astype('int32')\nx_test = test.values.astype('float32')","90a3a3d4":"x_train = x_train\/255.0\nx_test = x_test\/255.0","67f5770c":"x_train = x_train.reshape(x_train.shape[0], 28, 28)\nx_test = x_test.reshape(x_test.shape[0], 28, 28)\nprint('Input shape: ', x_train.shape[1:])","5ac01350":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)","64e67aab":"model = Sequential()\n\nmodel.add(CuDNNLSTM(128, input_shape=(x_train.shape[1:]), return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(CuDNNLSTM(128))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))","e129211b":"opt = Adam(lr=1e-3, decay=1e-5)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7, verbose=1)","0aa5a86f":"model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","49baf736":"history = model.fit(x_train, y_train, epochs=30, validation_data=(x_val, y_val), callbacks=[reduce_lr])","7ed8e356":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# Get training and test loss histories\ntraining_loss = history.history['loss']\ntest_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.ylim(0, 0.3)\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","8bde7155":"import seaborn as sn\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n\npred = model.predict_classes(x_val)\nplt.figure(figsize = (11,9))\nsn.heatmap(confusion_matrix(y_val, pred), annot=True)\n\nprint(y_val[:25])\nprint(pred[:25])\nprint(\"******************************************\")\nprint(\"Precision: \", precision_score(y_val, pred), average='macro')\nprint(\"Recall: \", recall_score(y_val, pred), average='micro')\nprint(\"f1 score: \", f1_score(y_val, pred), average='micro')\nprint(\"******************************************\")","25d5e7fc":"opt = RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)","1010e5fd":"model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","4ebcb7e8":"history = model.fit(x_train, y_train, epochs=30, validation_data=(x_val, y_val), callbacks=[reduce_lr])","fde45b56":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# Get training and test loss histories\ntraining_loss = history.history['loss']\ntest_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.ylim(0, 0.3)\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","d5f8e038":"prediction = model.predict_classes(x_test)","501242ca":"submissions = pd.DataFrame({\"ImageId\": list(range(1,len(prediction)+1)),\n                         \"Label\": prediction})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","924df265":"Using ADAM optimizer","08c760a1":"Using RMSProp optimizer"}}