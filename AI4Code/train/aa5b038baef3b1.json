{"cell_type":{"0276443c":"code","31402dd9":"code","4accde78":"code","fa39d958":"code","9273954b":"code","767a7b22":"code","a6bd3080":"code","ffb8099d":"code","c5d31085":"code","63f777a1":"code","1c3a67cf":"code","451d2aad":"code","d82ed42f":"code","037cd18f":"code","bb561317":"code","be5eaf76":"code","1f01b2b6":"code","d481ff73":"code","a630ddfa":"code","024f92f1":"code","5e6d278e":"code","8e45589e":"code","df5aebb3":"code","ad1cfb31":"code","724678a8":"code","66f5c946":"code","0c1afc1b":"markdown","03cfa9b9":"markdown","40c73723":"markdown","bad70ec0":"markdown","5ebee479":"markdown","c19229c3":"markdown","135781d7":"markdown"},"source":{"0276443c":"# imports\nimport os\nfrom pathlib import Path\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","31402dd9":"pd.options.display.max_rows = 100\npd.options.display.max_columns = 100\nplt.style.use('ggplot')\nwarnings.filterwarnings('ignore')","4accde78":"path = Path('\/kaggle\/input\/tabular-playground-series-jun-2021\/')\ntrain_df = pd.read_csv(path\/'train.csv')\ntest_df = pd.read_csv(path\/'test.csv')\nsample_submission = pd.read_csv(path\/'sample_submission.csv')","fa39d958":"sample_submission.head()","9273954b":"train_df.shape, test_df.shape","767a7b22":"# remove unnecessary columns like id column\ntrain_ids = train_df.id\ntrain_df.drop('id', axis=1, inplace=True)\ntest_ids = test_df.id\ntest_df.drop('id', axis=1, inplace=True)","a6bd3080":"target = train_df.target\ntrain_df.drop('target', axis=1, inplace=True)","ffb8099d":"# Check for duplicates\ntrain_df = train_df.drop_duplicates(keep='first')\ntarget = target[train_df.index]\n\ntrain_df.shape, target.shape","c5d31085":"# Encode target variable\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_enc = LabelEncoder()\ntarget_labels = pd.Series(label_enc.fit_transform(target), name='target')\ntarget_labels[:5]","63f777a1":"train_df.shape, test_df.shape","1c3a67cf":"# null value check\ntrain_df.isnull().sum().sum(), test_df.isnull().sum().sum()","451d2aad":"# target distribution\ntarget_value_counts = target.value_counts()\ntarget_value_percent = target.value_counts()*100\/len(train_df)\n\nplt.figure(figsize=(10, 4))\nplt.bar(target_value_counts.keys(), target_value_counts.values)\nfor (label, value), percent in zip(target_value_counts.items(), target_value_percent.values):\n    plt.text(label, value+1000, f'{percent:.1f}%', ha='center')\nplt.ylim(0, 60000)\nplt.title('Target class counts')\nplt.xlabel('Target class')\nplt.ylabel('Count')\nplt.grid(False)\nplt.tight_layout()\nplt.show()","d82ed42f":"def get_num_unique(x):\n    return len(x.unique())\n\nfeature_unique_df = train_df.apply(lambda x: get_num_unique(x), axis=0).to_frame('n_unique')\nzero_percent_df = train_df.apply(lambda x: x.value_counts()[0]*100\/len(train_df), axis=0).to_frame('per_zero')\n\ntrain_describe_df = pd.concat([\n    train_df.describe(percentiles=[0.25, 0.5, 0.75, 0.95]).T.drop('count', axis=1),\n    feature_unique_df,\n    zero_percent_df\n], axis=1)\ntrain_describe_df.head()","037cd18f":"train_describe_df.sort_values(by=['std','n_unique']) \\\n                 .style.bar(subset=['mean', 'per_zero']) \\\n                 .background_gradient(subset=['n_unique', 'std'])","bb561317":"drop_the_zero_features = 0\nzero_feature_columns = ['feature_15', 'feature_17', 'feature_22', 'feature_36', 'feature_47', 'feature_49', 'feature_66', 'feature_74']\nif drop_the_zero_features:\n    train_df.drop(zero_feature_columns, axis=1, inplace=True)\n    test_df.drop(zero_feature_columns, axis=1, inplace=True)\n\ntrain_df.shape, test_df.shape","be5eaf76":"from sklearn.model_selection import train_test_split","1f01b2b6":"X_train, X_test, y_train, y_test = train_test_split(train_df, target_labels, test_size=0.15, random_state=13,\n                                                    shuffle=True, stratify=target_labels)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","d481ff73":"import catboost\nimport optuna\nfrom sklearn.metrics import log_loss","a630ddfa":"def objective(trial):\n    param = {\n        \"task_type\": \"GPU\",\n        \"loss_function\": 'MultiClass',\n        \"eval_metric\": 'MultiClass',\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.02, 1),\n        \"leaf_estimation_method\": \"Newton\",\n        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 1e-5, 100),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0, 1),\n        \"random_strength\": trial.suggest_uniform(\"random_strength\", 10, 50),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 30),\n        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n        \"bootstrap_type\": \"Bernoulli\",\n    }\n    gbm = catboost.CatBoostClassifier(**param)\n    gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=25)\n    preds = gbm.predict_proba(X_test)\n    loss = log_loss(y_test, preds)\n    return loss","024f92f1":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50, timeout=600)","5e6d278e":"study.best_params","8e45589e":"study.best_value","df5aebb3":"# Final model build with best_params\ncat_params = study.best_trial.params\ncat_params['loss_function'] = 'MultiClass'\ncat_params['eval_metric'] = 'MultiClass'\ncat_params['bootstrap_type'] = 'Bernoulli'\ncat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = 13\ncat_params['task_type'] = 'GPU'","ad1cfb31":"from sklearn.model_selection import StratifiedKFold\n\ntest_preds = None\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)\nfor fold, (train_index, test_index) in enumerate(skf.split(train_df.values, target.values)):\n    print(f'Fold: {fold+1}')\n    X_train_sub, X_test_sub = train_df.values[train_index], train_df.values[test_index]\n    y_train_sub, y_test_sub = target.values[train_index], target.values[test_index]\n    eval_set = [(X_test_sub, y_test_sub)]\n    model = catboost.CatBoostClassifier(**cat_params)\n    model.fit(X_train_sub, y_train_sub, eval_set=eval_set, verbose=False)\n    print(f'log loss: {log_loss(y_test_sub, model.predict_proba(X_test_sub))}')\n    if test_preds is None:\n        test_preds = model.predict_proba(test_df)\n    else:\n        test_preds = model.predict_proba(test_df)\n\ntest_preds \/= 10","724678a8":"sample_submission['Class_1']=test_preds[:,0]\nsample_submission['Class_2']=test_preds[:,1]\nsample_submission['Class_3']=test_preds[:,2]\nsample_submission['Class_4']=test_preds[:,3]\nsample_submission['Class_5']=test_preds[:,4]\nsample_submission['Class_6']=test_preds[:,5]\nsample_submission['Class_7']=test_preds[:,6]\nsample_submission['Class_8']=test_preds[:,7]\nsample_submission['Class_9']=test_preds[:,8]\nsample_submission.head()","66f5c946":"sample_submission.to_csv('.\/catboost.csv', index=False)","0c1afc1b":"> #### Some of target classes are heavily imbalanced","03cfa9b9":"*Seems no null values*","40c73723":"## Data load","bad70ec0":"## EDA","5ebee479":"## Data prep","c19229c3":"## CATBoost","135781d7":"### In this notebook, I'm trying `CatBoost` extensively by finding right parameters using Optuna\n### Do comment if you find something can be improved, & what else to try next."}}