{"cell_type":{"194ba996":"code","c616973d":"code","cf418d1f":"code","7f707d26":"code","b6203e59":"code","4031764a":"code","cc8a93f9":"code","cca488d9":"code","3b362d48":"markdown","78305a69":"markdown"},"source":{"194ba996":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport lightgbm as lgb\nfrom pathlib import Path\nimport seaborn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom warnings import simplefilter\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c616973d":"!pip install kaggler","cf418d1f":"import kaggler\nfrom kaggler.model import AutoLGB\nprint(kaggler.__version__)\nplt.style.use('fivethirtyeight')\npd.set_option('max_columns', 100)\nsimplefilter('ignore')","7f707d26":"data_dir = Path('..\/input\/tabular-playground-series-jul-2021')\ntrain_file = data_dir \/ 'train.csv'\ntest_file = data_dir \/ 'test.csv'\nsample_file = data_dir \/ 'sample_submission.csv'\nid_col = 'date_time'\ntarget_col = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\n\nn_fold = 5\nseed = 42","b6203e59":"trn = pd.read_csv(train_file, index_col=id_col)\ntst = pd.read_csv(test_file, index_col=id_col)\nsub = pd.read_csv(sample_file, index_col=id_col)\nprint(trn.shape, tst.shape, sub.shape)","4031764a":"n_trn = trn.shape[0]\ndf = pd.concat([trn.drop(target_col, axis=1), tst], axis=0)\nprint(df.shape)","cc8a93f9":"cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\nX = df\ny = pd.Series(np.concatenate([np.zeros(n_trn,), np.ones(df.shape[0] - n_trn,)]))\np = np.zeros_like(y, dtype=float)\nfor i, (i_trn, i_val) in enumerate(cv.split(X, y)):\n    if i == 0:\n        clf = AutoLGB(objective='binary', metric='auc', random_state=seed)\n        clf.tune(X.iloc[i_trn], y[i_trn])\n        features = clf.features\n        params = clf.params\n        n_best = clf.n_best\n        print(f'{n_best}')\n        print(f'{params}')\n        print(f'{features}')\n    \n    trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn])\n    val_data = lgb.Dataset(X.iloc[i_val], y[i_val])\n    clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100)\n    p[i_val] = clf.predict(X.iloc[i_val])\n    print(f'CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}')","cca488d9":"print(f'CV AUC: {roc_auc_score(y, p):.6f}')","3b362d48":"# Reference: https:\/\/www.kaggle.com\/jeongyoonlee\/adversarial-validation-with-lightgbm by Jeong-Yoon Lee","78305a69":"# Adversarial validation AUC score is far away from 50%, which suggests the possibility of overfitting. However, since this is a time series data, and I have removed date_time, the adversarial validation may not be accurate"}}