{"cell_type":{"b5ef2449":"code","7663f184":"code","2fbc7b7a":"code","af07c3c5":"code","0a36beee":"code","3a6329de":"code","01a31ebf":"code","78705242":"code","7b29be01":"code","a5650e5e":"code","ca59a3a1":"code","1b590e83":"code","ea70108c":"code","d5717e11":"code","59f0a6b7":"markdown","18461e94":"markdown","21feecdb":"markdown","f7a4edb1":"markdown","d46e76ae":"markdown","b2419868":"markdown","d644a5ad":"markdown","b64fb9ef":"markdown","e581e86f":"markdown","acac1f2d":"markdown","f96a6899":"markdown","4114f15f":"markdown","fe32a866":"markdown","25148224":"markdown","a745ff42":"markdown","093c692d":"markdown"},"source":{"b5ef2449":"import pandas as pd\nimport numpy as np\n\nBUCKET = 'gs:\/\/<your-bucket-name>' # change this to actual storage bucket where images are stored\n\npickles='\/kaggle\/input\/starter-arthropod-taxonomy-orders-data-exploring\/'\nlabels=pd.read_pickle(pickles+'ArTaxOr_labels.pkl')\ndf=pd.read_pickle(pickles+'ArTaxOr_filelist.pkl')\nanno=pd.read_pickle(pickles+'ArTaxOr_objects.pkl')","7663f184":"df = df.sample(frac=1).reset_index(drop=True) # shuffle dataset (not really required, AutoML will do)\nautoml=pd.DataFrame(columns=['set', 'file', 'label', 'xmin1', 'ymin1', 'xmax2', 'ymin2', 'xmax3', 'ymax3', 'xmin4' , 'ymax4'])\nfor i in range(len(df)):\n    an=anno[anno.id == df.iloc[i].id]\n    for j in range(len(an)):\n        automl=automl.append({'set': 'UNASSIGNED',\n                              'file': BUCKET+an.file.iloc[j].replace('\/kaggle\/input',''),\n                              'label': an.label.iloc[j],\n                              'xmin1': an.left.iloc[j],\n                              'ymin1': an.top.iloc[j],\n                              'xmax2': an.right.iloc[j],\n                              'ymin2': an.top.iloc[j],\n                              'xmax3': an.right.iloc[j],\n                              'ymax3': an.bottom.iloc[j],\n                              'xmin4': an.left.iloc[j],\n                              'ymax4': an.bottom.iloc[j]}, ignore_index=True)\nautoml.to_csv('.\/ArTaxOr.csv', index=False, header=False)\n!head -3 .\/ArTaxOr.csv","2fbc7b7a":"import urllib.request\n\nmodel_url='https:\/\/github.com\/geddy11\/ArTaxOr-models\/raw\/master\/TensorFlow\/AutoML\/tflite_model-ArTaxOr1.0.0_dataset_20191023_model.tflite'\nurllib.request.urlretrieve(model_url, 'automl_trained.tflite')","af07c3c5":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n!pip install python-resize-image\nfrom PIL import Image, ImageFont, ImageDraw\nfrom resizeimage import resizeimage\nimport glob, os.path\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline","0a36beee":"def attribution(file):\n    with Image.open(file) as img:\n        exif_data = img._getexif()\n    s='Photo: unknown'\n    if exif_data is not None:\n        if 37510 in exif_data:\n            if len(exif_data[37510]) > 0:\n                s = exif_data[37510][8:].decode('ascii')\n        if 315 in exif_data:\n            if len(exif_data[315]) > 0:\n                s = 'Photo: ' + exif_data[315]\n    return s\n\ndef resize_image(file, width, height, stretch=False):\n    with Image.open(file) as im:\n        img = im.resize((width, height)) if stretch else resizeimage.resize_contain(im, [width, height])\n    img=img.convert(\"RGB\")    \n    return img, attribution(file)\n\nfontname = '\/usr\/share\/fonts\/truetype\/dejavu\/DejaVuSans.ttf'\nfont = ImageFont.truetype(fontname, 20) if os.path.isfile(fontname) else ImageFont.load_default()\n\ndef bbox(img, xmin, ymin, xmax, ymax, color, width, label, score):\n    draw = ImageDraw.Draw(img)\n    xres, yres = img.size[0], img.size[1]\n    box = np.multiply([xmin, ymin, xmax, ymax], [xres, yres, xres, yres]).astype(int).tolist()\n    txt = \" {}: {}%\" if score >= 0. else \" {}\"\n    txt = txt.format(label, round(score, 1))\n    ts = draw.textsize(txt, font=font)\n    draw.rectangle(box, outline=color, width=width)\n    if len(label) > 0:\n        if box[1] >= ts[1]+3:\n            xsmin, ysmin = box[0], box[1]-ts[1]-3\n            xsmax, ysmax = box[0]+ts[0]+2, box[1]\n        else:\n            xsmin, ysmin = box[0], box[3]\n            xsmax, ysmax = box[0]+ts[0]+2, box[3]+ts[1]+1\n        draw.rectangle([xsmin, ysmin, xsmax, ysmax], fill=color)\n        draw.text((xsmin, ysmin), txt, font=font, fill='white')","3a6329de":"def hex_to_rgb(value):\n    value = value.lstrip('#')\n    lv = len(value)\n    return tuple(int(value[i:i+lv\/\/3], 16) for i in range(0, lv, lv\/\/3))\n\ndef plot_img_pred(img, axes, scores, boxes, classes, title, by=''):\n    for i in range(len(scores)):\n        if scores[i]> 0.5 and classes[i]>0:\n            label = labels.name.iloc[int(classes[i]-1)]\n            color = hex_to_rgb(labels[labels.name == label].color.iloc[0])\n            bbox(img, boxes[i][1], boxes[i][0], boxes[i][3], boxes[i][2], color, 2, label, 100*scores[i])\n    plt.setp(axes, xticks=[], yticks=[])\n    axes.set_title(title) if by == '' else axes.set_title(title+'\\n'+by)\n    plt.imshow(img)\n    \ndef plot_img_gt(img, axes, boxes, stretch, title, by=''):\n    wscale = 1. if stretch else min(1,boxes.xres.iloc[0]\/boxes.yres.iloc[0])\n    hscale = 1. if stretch else min(1,boxes.yres.iloc[0]\/boxes.xres.iloc[0])\n    for i in range(len(boxes)):\n        label = boxes.label.iloc[i]\n        color = hex_to_rgb(labels[labels.name == label].color.iloc[0])\n        xmin = .5+(boxes.xcenter.iloc[i]-.5)*wscale-.5*wscale*boxes.width.iloc[i]\n        ymin = .5+(boxes.ycenter.iloc[i]-.5)*hscale-.5*hscale*boxes.height.iloc[i]\n        xmax = .5+(boxes.xcenter.iloc[i]-.5)*wscale+.5*wscale*boxes.width.iloc[i]\n        ymax = .5+(boxes.ycenter.iloc[i]-.5)*hscale+.5*hscale*boxes.height.iloc[i]\n        bbox(img, xmin, ymin, xmax, ymax, color, 2, label, -1)\n    plt.setp(axes, xticks=[], yticks=[])\n    axes.set_title(title) if by == '' else axes.set_title(title+'\\n'+by)\n    plt.imshow(img)","01a31ebf":"interpreter = tf.lite.Interpreter(model_path='automl_trained.tflite')\ninterpreter.allocate_tensors()\ninput_details, output_details = interpreter.get_input_details(), interpreter.get_output_details()\n\ndef predict(img):\n    input_data = np.expand_dims(img, axis=0)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    num = interpreter.get_tensor(output_details[3]['index'])\n    return scores, classes, boxes, num","78705242":"pickles='\/kaggle\/input\/starter-arthropod-taxonomy-orders-testset\/'\nlabels=pd.read_pickle(pickles+'testset_labels.pkl')\ndf=pd.read_pickle(pickles+'testset_filelist.pkl')\nanno=pd.read_pickle(pickles+'testset_objects.pkl')","7b29be01":"negs='\/kaggle\/input\/arthropod-taxonomy-orders-object-detection-testset\/ArTaxOr_TestSet\/negatives\/*.jpg'\nnlist=glob.glob(negs, recursive=False)\nfig = plt.figure(figsize=(16,24))\nfor i in range(len(nlist)\/\/2):\n    for j in range(2):\n        axes = fig.add_subplot(len(nlist)\/\/2, 2, 1+i*2+j)\n        img, by = resize_image(nlist[i*2+j], 512, 512, stretch=False)\n        scores, classes, boxes,_ = predict(img)\n        plot_img_pred(img, axes, scores.squeeze(), boxes.squeeze(), classes.squeeze(), 'Prediction', by)","a5650e5e":"def pred_batch(idx, stretch):\n    fig = plt.figure(figsize=(16,24))\n    rows = 3\n    for i in range(rows):\n        img, by = resize_image(df.path.iloc[i+idx].replace('F:\/', 'F:\/'), 512, 512, stretch)\n        axes = fig.add_subplot(rows, 2, 1+i*2)\n        boxes = anno[anno.id == df.id.iloc[i+idx]][['label','xres', 'yres', 'xcenter', 'ycenter', 'width', 'height']]\n        plot_img_gt(img, axes, boxes, stretch, 'Ground truth', by)\n        img, by = resize_image(df.path.iloc[i+idx].replace('F:\/', 'F:\/'), 512, 512, stretch)\n        scores, classes, boxes,_ = predict(img)\n        axes = fig.add_subplot(rows, 2, 2+i*2)\n        plot_img_pred(img, axes, scores.squeeze(), boxes.squeeze(), classes.squeeze(), 'Prediction', '') ","ca59a3a1":"pred_batch(0, False)","1b590e83":"pred_batch(3, False)","ea70108c":"pred_batch(6, False)","d5717e11":"pred_batch(12, False)","59f0a6b7":"## Summary\nSo, the model misses quite a few objects, but those it finds are pretty good on IoU. Again, this model training was stopped before it finished, so the result would most likely be better if it ran longer. Considering how easy it is to use AutoML, its definately thumbs up for this product! And in the future we can expect the performance of AutoML to improve dramatically. And no doubt other providers will launch similar services.","18461e94":"Define a few helper functions.","21feecdb":"## The resulting model\nAutoML did spend the 20h I set as maximum, which means it was not finished. It is impossible to know if AutoML was close to finish or just getting started. The ArTaxOr dataset is not an easy one, so I assume AutoML would spend quite a few more hours if allowed. Here is the reported precision:\n![ArTaxOr_dataset%20%E2%80%93%20Vision%20%E2%80%93%20ArTaxOr%20%E2%80%93%20Google%20Cloud%20Platform.png](attachment:ArTaxOr_dataset%20%E2%80%93%20Vision%20%E2%80%93%20ArTaxOr%20%E2%80%93%20Google%20Cloud%20Platform.png)\nNot too bad really for a partly trained model. Now, what kind of neural network is AutoML creating? Let us check by loading the .tflite model into [Netron](https:\/\/github.com\/lutzroeder\/netron):\n![tflite_model.png](attachment:tflite_model.png)","f7a4edb1":"The model detects a few arty butterflies!  \n## Make predictions on true positives","d46e76ae":"All that is needed now is to transfer the ArTaxOr dataset and the ArTaxOr.csv file to a storage bucket. One note about .zip files though: There is no direct way to unzip .zip files in a storage bucket. I found it most convenient to unzip ArTaxOr.zip on a local machine and then transfer the directory to the bucket with:  \n```gsutil -m cp -r ArTaxOr gs:\/\/<bucket name>```  \n`gsutil` is part of the Google Cloud SDK","b2419868":"# Object Detection Using Google Cloud AutoML Vision\nTired of testing different neural network architectures and all that hyperparameter tuning? Why not let a machine do it all and just concentrate on putting together the dataset? Dream or reality? Well, Google AutoML claims to do just that. So I decided to give AutoML a spin with the [ArTaxOr dataset](https:\/\/www.kaggle.com\/mistag\/arthropod-taxonomy-orders-object-detection-dataset).  \nThere is a nice [tutorial](https:\/\/cloud.google.com\/vision\/automl\/object-detection\/docs\/how-to) on using Cloud AutoML Vision Object Detection, and I had no problem to follow it.\n","d644a5ad":"Fetch the testset metadata from the starter kernel:","b64fb9ef":"## Make predictions on true negatives\nLets start with making predictions on images that have no valid objects. Art and sculptures are not regarded as valid objects in the context of ArTaxOr, which is about species identification. Although false positives are not really a big problem.","e581e86f":"TensorFlow Lite inference is quite straight forward using the `tf.lite.Interpreter`:","acac1f2d":"## Step 2: Run AutoML\nThere are no hyperparameters to set, only to choose between a model that will be deployed to the cloud (best accuracy) or to an edge device. I choose the latter, to have a model I can run locally. There is also a tradeoff between latency and accuracy:\n![optimize.png](attachment:2019-10-23%2020_36_49-Train%20new%20model%20%E2%80%93%20Vision%20%E2%80%93%20ArTaxOr%20%E2%80%93%20Google%20Cloud%20Platform.png)\n\nThen there is the matter of setting the maximum number of training hours AutoML can use. AutoML will stop training automatically if it finishes before the quota is reached. At the time of writing, the first 20 hours are free the the price is $18 per hour after that.\n![Train%20new%20model%20%E2%80%93%20Vision%20%E2%80%93%20ArTaxOr%20%E2%80%93%20Google%20Cloud%20Platform.png](attachment:Train%20new%20model%20%E2%80%93%20Vision%20%E2%80%93%20ArTaxOr%20%E2%80%93%20Google%20Cloud%20Platform.png)\nI set it to 20h and let it go...","f96a6899":"The labels in this dataset are systematic names rather than common names, so a quick review of their meaning:\n* Coleoptera: Beetles\n* Diptera: True flies, including mosquitoes, midges, crane flies etc.\n* Hymenoptera: Ants, bees and wasps\n* Lepidoptera: Butterflies and moths","4114f15f":"## Making predictions\nSo, we have a (partly) trained model from AutoML, which I have copied to GitHub. Making predictions with images not part of the ArTaxOr dataset is the last step to check the performance. First, fetch the model file from GitHub:","fe32a866":"Import TensorFlow, PIL and other libraries.","25148224":"The input layers look like this:\n![model_input_stage.png](attachment:model_input_stage.png)\nWhile the output layers look like this:\n![end%20model.png](attachment:end%20model.png)\n> Given that this is an intermediate stage, we would probably get a different architecture if AutoML was allowed to finish.","a745ff42":"AutoML has a nice UI, and after training lets you explore accuracy on the different labels as well as viewing predictions.","093c692d":"## Step one: Prepare the dataset\nAutoML just needs a .csv file with one bounding box per line in addition to the .jpg files. Let us start with createing the .csv file. The ArTaxOr starter kernel outputs pickled objects data, we can simply load that file and export to .csv. The format of each line needs to be:  \n```<set>, <image path>,<label>, x_relative_min, y_relative_min, x_relative_max, y_relative_min, x_relative_max, y_relative_max, x_relative_min, y_relative_max```\nwhere `<set>` is TRAIN, TEST, VALIDATE or UNASSIGNED. The latter means we leave the splitting to AutoML, which wants a 80%-10%-10% split of the dataset. `<image path>` is the path to the image in a Google storage bucket, and the four vertices of the bounding box follow last. Notice that AutoML will discard objects that are too small (less than 8x8pix), and also discard files that have no bounding boxes.\n"}}