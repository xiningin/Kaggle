{"cell_type":{"3e78deae":"code","37f39469":"code","2dbc452a":"code","b31a5f5c":"code","7b65c1da":"code","e19bff15":"code","20db6c9a":"code","9bb7ec48":"code","9315647e":"code","bcaf854b":"code","ad208b7b":"code","159ee4ba":"code","e6f9e556":"code","23220645":"code","baafde49":"code","37ca498d":"code","d76124a4":"code","104d8ea5":"code","248014d0":"code","b07cc901":"code","17b6ebb8":"code","ec8de190":"code","09e1c1df":"markdown","60600a99":"markdown","ee410503":"markdown","62dc9452":"markdown","dbfcd077":"markdown","d6c5e332":"markdown","a4c3ef84":"markdown","af065d03":"markdown","e805b3ca":"markdown","343f96d7":"markdown","cd4d2814":"markdown","00371e55":"markdown","bea9852b":"markdown","353fd8ab":"markdown"},"source":{"3e78deae":"import janestreet\nimport numpy as np\nimport pandas as pd\n\nimport os, sys\nimport gc\nimport math\nimport random\nimport pathlib\nfrom tqdm import tqdm\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model\nimport operator\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom tqdm import tqdm\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\npd.options.display.max_columns = None\n\nimport warnings\nwarnings.filterwarnings('ignore')","37f39469":"SEED = 1225 # Merry Christmas!\n# INPUT_DIR = '..\/input\/jane-street-market-prediction\/'\nINPUT_DIR = '..\/input\/janestreet-save-as-feather\/'\nTRADING_THRESHOLD = 0.5 # 0 ~ 1: The smaller, the more aggressive\nAVERAGE_WEIGHTS = [1, 2, 3, 4, 5] # for resp","2dbc452a":"os.listdir(INPUT_DIR)","b31a5f5c":"%%time\n\ndef load_data(input_dir=INPUT_DIR):\n    train = pd.read_feather(pathlib.Path(input_dir + 'train.feather'))\n    features = pd.read_feather(pathlib.Path(input_dir + 'features.feather'))\n    example_test = pd.read_feather(pathlib.Path(input_dir + 'example_test.feather'))\n    ss = pd.read_feather(pathlib.Path(input_dir + 'example_sample_submission.feather'))\n    return train, features, example_test, ss\n\ntrain, features, example_test, ss = load_data(INPUT_DIR)","7b65c1da":"print(train.shape)\ntrain.head()","e19bff15":"# histograms for non-features\nfor f in ['weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']:\n    train[f].plot.hist(bins=100, title=f)\n    plt.show()","20db6c9a":"# resp...correlated with one another?\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nsns.heatmap(train[['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']].corr(), \n            annot=True, square=True, ax=ax);\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right');\nax.set_title('resp correlations');","9bb7ec48":"fig, ax = plt.subplots(1, 1, figsize=(20, 5))\nfor f in ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']:\n    train.iloc[-10000:].plot(x='ts_id', y=f, alpha=0.4, label=f, ax=ax) # last 10000\nax.legend(frameon=False)\nax.set_ylabel('return')","9315647e":"# target\ntrain['action'] = train['resp'] * train['weight']\ntrain['action'].describe()","bcaf854b":"print(features.shape)\nfeatures.head()","ad208b7b":"fig, ax = plt.subplots(1, 1, figsize=(6, 6))\nsns.heatmap(features[[f for f in features.columns.values.tolist() if f.startswith('tag')]].corr(), \n            square=True, ax=ax);\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right');\nax.set_title('features.csv');","159ee4ba":"print(example_test.shape)\nexample_test.head()","e6f9e556":"print(ss.shape)\nss.head()","23220645":"del features, example_test, ss\ngc.collect()","baafde49":"# remove weight = 0 for saving memory \ntrain = train.query('weight > 0').reset_index(drop=True)\ntrain.shape","37ca498d":"train['action'].describe()","d76124a4":"train['action'].hist(bins=100)","104d8ea5":"# features to use\nfeats = [f for f in train.columns.values.tolist() if f.startswith('feature')]\nprint('There are {:,} features.'.format(len(feats)))","248014d0":"%%time\n\n# same hyperparameters from an numerai example (https:\/\/github.com\/numerai\/example-scripts\/blob\/master\/example_model.py)\nparams = {\n    'colsample_bytree': 0.1,                 \n    'learning_rate': 0.01,\n    'max_depth': 5,\n    'seed': SEED,\n    'n_estimators': 2000,\n    'tree_method': 'gpu_hist' # Let's use GPU for a faster experiment\n}\n\n# params[\"objective\"] = 'reg:squarederror'\n# params[\"eval_metric\"] = 'rmse'\n# model = xgb.XGBRegressor(**params)\n\nparams[\"objective\"] = 'binary:logistic'\nparams[\"eval_metric\"] = 'logloss'\n    \nmodels = []\nfor r in tqdm(['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']):\n    train['action'] = train[r] * train['weight']\n    train['action'] = 1 * (train['action'] > 0)\n    model = xgb.XGBClassifier(**params)\n    model.fit(train[feats], train['action'], verbose=100)\n    models.append(model)","b07cc901":"pd.DataFrame(model.feature_importances_, index=feats, columns=['importance']).sort_values(by='importance', ascending=False).style.background_gradient(cmap='viridis')","17b6ebb8":"env = janestreet.make_env()\ntest = env.iter_test()\n        \nweight_sum = np.sum(np.array(AVERAGE_WEIGHTS))\nfor (t, sub) in test:\n    pred = np.zeros(t.shape[0])\n    for w, model in zip(AVERAGE_WEIGHTS, models):\n        pred += w * model.predict_proba(t[feats])[:, 1] \/ weight_sum\n    sub.action = (pred > TRADING_THRESHOLD).astype('int')\n    env.predict(sub)       ","ec8de190":"# env = janestreet.make_env()\n# test = env.iter_test()\n\n# for (t, sub) in test:\n#     sub.action = (model.predict(t[feats]) > TRADING_THRESHOLD - 0.5).astype('int')\n#     env.predict(sub)","09e1c1df":"## features\n>features.csv - metadata pertaining to the anonymized features\n\n","60600a99":"# Model fitting\nFor now, let's use a simple XGBoost which is also used as an example in the Numerai Tournament.\n\nThere are several columns of returns (resp 1-4 and resp). Let's predict all as our targets and ensemble the results for our final prediction.","ee410503":"# Config\nSome configuration setups.","62dc9452":">In the training set, train.csv, you are provided a resp value, as well as several other resp_{1,2,3,4} values that represent returns over different time horizons.\n\nLet's look at 'resp': how they are correlated with one another.","dbfcd077":">Each trade has an associated weight and resp, which together represents a return on the trade. The date column is an integer which represents the day of the trade\n\nOK, how does the return look like?","d6c5e332":"## Train\n>train.csv - the training set, contains historical data and returns","a4c3ef84":"# Feature importance\nLet's see feature importance given by the model.","af065d03":"<center><h2>Jane Street Market Prediction | Numerai Baseline | katsu1110 <\/h2><\/center><hr>\n\nHere I use an example model (XGBoost) used for the [Numerai tournament](https:\/\/numer.ai\/tournament). This model [performs well](https:\/\/numer.ai\/integration_test) in Numerai, but how about this competition?\n\nThis notebook loads feathered-data from [my another notebook](https:\/\/www.kaggle.com\/code1110\/janestreet-save-as-feather?scriptVersionId=47635784) such that we don't have to spend our time on waiting long for loading csv files.\n\nIn this notebook we treat the task as a binary classification.","e805b3ca":"# Submit\nLet's use ensemble for each target (resp 1-4 & resp) for our final prediction.","343f96d7":"# EDA (Exploratory Data Analysis)\nLet's briefly look at data.","cd4d2814":"Looks beautiful but what does this indicate???","00371e55":"# Load data\nI have already saved the training data in the feather-format in [my another notebook](https:\/\/www.kaggle.com\/code1110\/janestreet-save-as-feather?scriptVersionId=47635784). Loading csv takes time but loading feather is really light:)","bea9852b":"## Test, submission\nNote that this is a code competition...which means, the actual test file is hidden (the example_test is just an example!) ...your score is calculated on the hidden dataset only when you submit.","353fd8ab":"The target 'action' has its median of 0, meaning that we can take this task as a binary classification without label unbalance. \n\nAlternatively we can also take it as a regression problem. "}}