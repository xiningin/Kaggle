{"cell_type":{"23abbd17":"code","e88c703d":"code","f2614556":"code","e645e49a":"code","26c85241":"code","4b2082c3":"code","38353124":"code","27fc34b9":"code","6e61ec74":"code","9e6b05b7":"code","4efbb2d2":"code","1f8270f0":"code","5093b64f":"code","ef329b81":"code","e2420447":"code","523ff0a3":"code","d6b43fb2":"code","d4905932":"code","6ea0b44f":"code","b0eaddb4":"code","fd053eb1":"code","dd6d7e8e":"code","6811f3d0":"code","54c9777c":"code","b5534c5d":"code","650a087a":"code","70579109":"code","ccd74552":"code","b0e23364":"code","afc93dfa":"code","8849c7a2":"code","99ac5831":"code","5e673519":"code","b102eb9b":"code","c355371c":"code","181393f2":"code","f3b7ceda":"code","3aad7de7":"code","a7516995":"code","b9b44d38":"code","8f3b1aa2":"code","1578993c":"code","6464edb2":"code","83ff73d2":"code","0f907c87":"code","1c180c14":"code","838733d1":"code","9e8e64a5":"code","20aa6d74":"code","92e6b79c":"code","35563851":"code","7bf3b6fb":"code","3277630b":"code","5a03df59":"code","7ecd1df0":"code","3900b7fa":"code","b2dbf226":"code","528d7bbb":"code","19d98022":"code","e4a1c28b":"code","d5590c16":"code","a265917f":"code","ad361896":"code","5c45cec7":"code","7f9b63af":"code","269e5fc2":"code","c3ef40a8":"code","3c31ef1a":"code","c97caf69":"code","8bc651bb":"code","97700ed8":"code","c8d3cb9e":"code","92e384e7":"code","18343ffa":"code","e8b602ae":"code","782be602":"code","8ea02fa7":"code","c2598d83":"code","09f25d80":"code","ccaeb156":"code","22e63058":"code","921f91e4":"code","9643da5e":"code","2d53e655":"code","55b096ab":"code","fbc8fa5f":"code","bdb823be":"markdown","43b0f248":"markdown","373c9ff8":"markdown","9725ed7e":"markdown","d20ac861":"markdown","1d69e0f3":"markdown","9deeb4ee":"markdown","62349f18":"markdown","7365a83a":"markdown","d2311243":"markdown","601bea4a":"markdown","f30fa766":"markdown","c6eaf9d1":"markdown","ad8c3e3f":"markdown","e6130299":"markdown","29d8cef0":"markdown","c1c5bc9c":"markdown","feca7cd1":"markdown","e6050e16":"markdown","0895bdf3":"markdown","dc573f95":"markdown","4ea9f20f":"markdown","24039f7c":"markdown","26195972":"markdown","8e10cd27":"markdown","32765eee":"markdown"},"source":{"23abbd17":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\nfrom sklearn.model_selection import train_test_split, GridSearchCV","e88c703d":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\") \ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","f2614556":"train = df_train.copy() \ntest = df_test.copy()","e645e49a":"train.info()","26c85241":"train.head()","4b2082c3":"train.describe().T","38353124":"train[\"Survived\"].value_counts()","27fc34b9":"Survival_Rate = 342\/891*100","6e61ec74":"print(str(Survival_Rate)+'%')","9e6b05b7":"train[\"Sex\"].value_counts()","4efbb2d2":"train[\"Pclass\"].value_counts()","1f8270f0":"train[\"SibSp\"].value_counts()","5093b64f":"train[\"Parch\"].value_counts()","ef329b81":"train[\"Embarked\"].value_counts()","e2420447":"train[\"Cabin\"].value_counts()","523ff0a3":"sns.catplot(x=\"Survived\", kind=\"count\", data=train);","d6b43fb2":"sns.catplot(x=\"Sex\", hue=\"Survived\", kind=\"count\", data=train);","d4905932":"sns.barplot(x = \"Sex\", y = \"Survived\", data = train);","6ea0b44f":"sns.catplot(x=\"Pclass\", hue=\"Survived\", kind=\"count\", data=train);","b0eaddb4":"sns.barplot(x = \"Pclass\", y = \"Survived\", data = train);","fd053eb1":"sns.catplot(x=\"SibSp\", hue=\"Survived\", kind=\"count\", data=train);","dd6d7e8e":"sns.barplot(x = \"SibSp\", y = \"Survived\", data = train);","6811f3d0":"sns.catplot(x=\"Parch\", hue=\"Survived\", kind=\"count\", data=train);","54c9777c":"sns.barplot(x = \"Parch\", y = \"Survived\", data = train);","b5534c5d":"plt.hist(train[\"Age\"])\nplt.show()","650a087a":"sns.boxplot(x=\"Survived\", y=\"Age\", data=train);","70579109":"sns.boxplot(x=\"Survived\", y=\"Fare\", data=train);","ccd74552":"train = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain = train.drop(['Cabin'], axis = 1) \ntest = test.drop(['Cabin'], axis = 1)","b0e23364":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","afc93dfa":"sns.boxplot(y=\"Fare\", data=train);","8849c7a2":"Q1 = train['Fare'].quantile(0.25) \nQ3 = train['Fare'].quantile(0.75) \nIQR = Q3 - Q1","99ac5831":"lower_limit = Q1 - 1.5*IQR \nlower_limit","5e673519":"upper_limit = Q3 + 1.5*IQR\nupper_limit","b102eb9b":"train['Fare'] > (upper_limit)","c355371c":"train.sort_values(\"Fare\", ascending=False).head()","181393f2":"test.sort_values(\"Fare\", ascending=False)","f3b7ceda":"count = 0\nfor i in train[\"Fare\"] : \n    if i > 65.6344 :\n        count = count + 1","3aad7de7":"print(\"The numbers of observations greater than upper limit of 65.6344 : \" + str(count))","a7516995":"count = 0\nfor i in train[\"Fare\"] : \n    if i > 200 :\n        count = count + 1","b9b44d38":"print(\"The numbers of observations greater than 200 : \" + str(count))","8f3b1aa2":"for i in train[\"Fare\"] : \n    if i > 200 :\n        train[\"Fare\"].replace(i, 200, inplace=True)","1578993c":"train.sort_values(\"Fare\", ascending=False).head()","6464edb2":"for i in test[\"Fare\"] : \n    if i > 200 :\n        test[\"Fare\"].replace(i, 200, inplace=True)","83ff73d2":"test.sort_values(\"Fare\", ascending=False).head()","0f907c87":"sns.boxplot(y=\"Fare\", data=train);","1c180c14":"train.describe().T","838733d1":"train.isnull().sum()","9e8e64a5":"test.isnull().sum()","20aa6d74":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\ntest[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())\ntrain.isnull().sum()","92e6b79c":"test.isnull().sum()","35563851":"test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].mean())","7bf3b6fb":"test.isnull().sum()","3277630b":"train[\"Embarked\"].value_counts()","5a03df59":"train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","7ecd1df0":"train[\"Embarked\"].isnull().sum()","3900b7fa":"from sklearn.preprocessing import LabelEncoder\nlbe = LabelEncoder()\nlbe.fit_transform(train[\"Sex\"])\ntrain[\"Gender\"] = lbe.fit_transform(train[\"Sex\"])","b2dbf226":"train.drop([\"Sex\"], inplace = True, axis =1)","528d7bbb":"train.tail()","19d98022":"from sklearn.preprocessing import LabelEncoder\nlbe = LabelEncoder()\nlbe.fit_transform(train[\"Embarked\"])\ntrain[\"Embarked_new\"] = lbe.fit_transform(train[\"Embarked\"])","e4a1c28b":"train.drop([\"Embarked\"], inplace = True, axis =1)","d5590c16":"train.head()","a265917f":"lbe.fit_transform(test[\"Sex\"])\ntest[\"Gender\"] = lbe.fit_transform(test[\"Sex\"])\ntest.drop([\"Sex\"], inplace = True, axis =1)\nlbe.fit_transform(test[\"Embarked\"])\ntest[\"Embarked_new\"] = lbe.fit_transform(test[\"Embarked\"])\ntest.drop([\"Embarked\"], inplace = True, axis =1)\ntest.head()","ad361896":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","5c45cec7":"train.drop([\"SibSp\"], inplace = True, axis = 1)","7f9b63af":"test.drop([\"SibSp\"], inplace = True, axis = 1)","269e5fc2":"train.drop([\"Parch\"], inplace = True, axis = 1)","c3ef40a8":"test.drop([\"Parch\"], inplace = True, axis = 1)","3c31ef1a":"train.head()","c97caf69":"test.head()","8bc651bb":"train = pd.get_dummies(train, columns = [\"Gender\"], prefix =\"Gen\") \ntrain = pd.get_dummies(train, columns = [\"Embarked_new\"], prefix=\"Em\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"], prefix=\"Pclass\")\ntrain = pd.get_dummies(train, columns = [\"FamilySize\"], prefix=\"Famsize\")\n\ntest = pd.get_dummies(test, columns = [\"Gender\"], prefix =\"Gen\") \ntest = pd.get_dummies(test, columns = [\"Embarked_new\"], prefix=\"Em\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"], prefix=\"Pclass\")\ntest = pd.get_dummies(test, columns = [\"FamilySize\"], prefix=\"Famsize\")","97700ed8":"train.head()","c8d3cb9e":"test.head()","92e384e7":"from sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score \npredictors = train.drop(['Survived', 'PassengerId'], axis=1) \ntarget = train[\"Survived\"] \nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 42)","18343ffa":"x_train.shape","e8b602ae":"x_test.shape","782be602":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression() \nlogreg.fit(x_train, y_train) \ny_pred = logreg.predict(x_test) \nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2) \nprint(acc_logreg)","8ea02fa7":"from sklearn.ensemble import RandomForestClassifier\nrandomforest = RandomForestClassifier() \nrandomforest.fit(x_train, y_train) \ny_pred = randomforest.predict(x_test) \nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2) \nprint(acc_randomforest)","c2598d83":"from sklearn.ensemble import GradientBoostingClassifier\ngbk = GradientBoostingClassifier() \ngbk.fit(x_train, y_train) \ny_pred = gbk.predict(x_test) \nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2) \nprint(acc_gbk)","09f25d80":"xgb_params = { 'n_estimators': [200, 500], 'subsample': [0.6, 1.0], 'max_depth': [2,5,8], 'learning_rate': [0.1,0.01,0.02], \"min_samples_split\": [2,5,10]}\nxgb = GradientBoostingClassifier()\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)\nxgb_cv_model.fit(x_train, y_train)\nxgb_cv_model.best_params_","ccaeb156":"xgb = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 2, min_samples_split = 10, n_estimators = 200, subsample = 0.6)\nxgb_tuned = xgb.fit(x_train,y_train)\ny_pred = xgb_tuned.predict(x_test) \nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2) \nprint(acc_gbk)","22e63058":"ids = test['PassengerId'] \npredictions = randomforest.predict(test.drop('PassengerId', axis=1))","921f91e4":"output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions }) \noutput.to_csv('submission.csv', index=False)\noutput.head()","9643da5e":"output.describe().T","2d53e655":"output[\"Survived\"].value_counts()","55b096ab":"Survival_Rate = 152\/418*100","fbc8fa5f":"print(str(Survival_Rate)+'%')","bdb823be":"8.3. Missing Value Treatment","43b0f248":"The number of observations higher than 75% of the median value for the variable of Fare is 116, \n\nIt is too much for replacing with the upper limit of 65.6344.\n\nHowever, the number of outliers higher than 200 (taking into account the boxplot) is just 20.\n\nSo, the Fare values of these observations will be replaced by 200 to make the dataframe less skewed.","373c9ff8":"7. Data Visualization:","9725ed7e":"9.1. Logistic Regression","d20ac861":"6. Exploring Data Features:\n\nWhat are the number of observations per variables?\n\nWhat are the types of variables?","1d69e0f3":"8. Data Preparation\n\n8.1. Deleting Unnecessary Variables\n\nWe are deleting the variable of Ticket and Name, since they are irrelavant for data analysis.\nWe will also delete the variable of Cabin, since the total number of observations for this variable is 204, although total number of observations are 891. This is too low and it may not help us to understand who is survived in the Titanic.","9deeb4ee":"For the variable of Fare in the test set, we will use the mean value for filling the missing values:","62349f18":"8.6. Creating Dummy Variable\n\nIn this section, dummy variables will be created for Pclass, Gender, Embarked_new and Family Size.","7365a83a":"How does the initial observations look like?","d2311243":"For the variable of Embarked, we will use the most frequent value for filling the missing values:","601bea4a":"In this section, we will transform categorical variables into numerical variables to make machine learning workable.","f30fa766":"What are the general characteristics of the numerical variables?","c6eaf9d1":"9.3. Gradient Boosting Classifier","ad8c3e3f":"The categorical variable of Sex is turned into 1 and 0 under a new variable of Gender. Sex is dropped.\n\nThe categorical variable of Embarked is turned into 0,1 and 2 under a new variable of Embarked_new. Embarked is dropped.","e6130299":"5. Loading and Making a Copy of the Data:","29d8cef0":"9.2. Random Forest","c1c5bc9c":"10. Deployment\n\nSince the accuracy rate achieved by the Random Forest Classifier is the highest, we decided to deploy this model for predicting the Survival values. \n\nWe will set ids as PassengerId and predict the survival\nWe will set the output as a dataframe and convert to csv file named submission.csv ","feca7cd1":"9. Modeling, Evaluation and Model Tuning\n\n9.1. Splitting the Train Data","e6050e16":"8.4. Variable Transformation","0895bdf3":"For the variable of Age, we will use the mean value for filling the missing values:","dc573f95":"How is the value breakdown of the categorical variables?","4ea9f20f":"When we look at the number of available observations per variables, we see that there are some missing values.\n\nWhile the variable Age lacks 177 values, the variable Embarked has just 2 missing values. \n\nFor the test data set, Age lacks 86 values and there is one missing value for Fare variable.\n\nWe will fill the missing values with relavant figures to have a complete data set. ","24039f7c":"What is the survival rate in general?","26195972":"8.5. Feature Engineering\n\nA new variable under the name of Family Size will be created by combining the variables of SibSp and Parch. SibSp and Parch will be deleted from the data set.","8e10cd27":"WHO HAS SURVIVED IN TITANIC?\n\n1. Objective: \n\nThe overall objective of this study is to understand better who has survived in Titanic accident. In order to do that a machine learning model will be developed by using the existing data covering several features of the people who were at Titanic during the accident. The model will predict which passengers survived during the accident.\n\n2. Variables and Their Types:\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton\n\n3. Variable Notes:\n\nPclass: A proxy for socio-economic status (SES) 1st = Upper 2nd = Middle 3rd = Lower \n\nAge: Age is frictional if less than 1. If the age is estimated, it is in the form of xx.5\n\nSibSp: The dataset defines family relations in this way.\n\nSibling = brother, sister, stepbrother, stepsister \n\nSpouse = husband, wife\n\nParch: The dataset defines family relations in this way.\n\nParent = mother, father \n\nChild = daughter, son, stepdaughter, stepson \nSome children travelled only with a nanny, therefore parch=0 for them.\n\n4. Importing Libraries:","32765eee":"8.2. Outlier Treatment\n\nIt seems that the standard deviation for the variable Fare is too much. \n\nAccording to the boxplot it is clear that there is a number of outliers for this variable. \n\nIn this regard, we will replace them with an acceptable maximum figure."}}