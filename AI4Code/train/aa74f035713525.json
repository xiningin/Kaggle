{"cell_type":{"743a1c24":"code","41f80414":"code","cb8b6c73":"code","3fd0d723":"code","0b35c65a":"code","d63be85b":"code","d87e97f4":"code","725bb16a":"code","97117320":"code","a7dc60af":"code","296763c8":"code","945cf890":"code","60f959e0":"code","2b64183a":"code","e66aed5e":"code","ada67968":"code","f34029b9":"code","7c442b50":"code","4678f85d":"code","1b71d5b2":"code","eaf2b1d9":"code","903db209":"code","3d654f21":"code","297550ee":"code","d6b21bf5":"code","55ac8be9":"code","190b8134":"code","9e419cce":"markdown","0fb370f5":"markdown","c5f6aa2b":"markdown","db4b5508":"markdown","dc11bbd6":"markdown","13e59575":"markdown"},"source":{"743a1c24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","41f80414":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","cb8b6c73":"# Importing the dataset\ndataset = pd.read_csv(\"..\/input\/Book1.csv\")","3fd0d723":"#checking the dataset\ndataset.head(30) ","0b35c65a":"#Checking the dimensions of dataset....\ndataset.shape","d63be85b":"#Checking the null values in the dataset\ndataset.isnull().sum()","d87e97f4":"dataset=dataset.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','Summary'],axis=1)","725bb16a":"dataset.head()","97117320":"#Counting all unique values of column \"sentiment\" from dataset \n\ndataset[\"Score\"].value_counts()","a7dc60af":"#visualize the \"Score\" of each customer with the help of Bar plot \ndataset[\"Score\"].value_counts().plot.bar(color='black')","296763c8":"dataset[\"Score\"] = dataset[\"Score\"].apply(lambda score: \"1\" if score > 3 else \"0\")","945cf890":"dataset.head()","60f959e0":"dataset = dataset[['Text','Score']]\ndataset.head()","2b64183a":"#Bar plot for Score column\ndataset[\"Score\"].value_counts().plot.bar(color='Pink')","e66aed5e":"# Cleaning the texts\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = [] #Creating an empty list\nfor i in range(0, 1000):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Text'][i])#Remove all special character like('',:,;,%,*,@,$,!,#) \n    #Convert complete sentences into lowercase. \n    review = review.lower() \n    #Spliting each sentences into different words.\n    review = review.split()\n    #Stemming example is love-loving,loved,lovely.etc.\n    ps = PorterStemmer()\n    #Removing unnecessary words like is,of,for,this...and only focusing on main meaning of the sentence. \n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","ada67968":"print(corpus)","f34029b9":"print(review)","7c442b50":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 4199)\nX= cv.fit_transform(corpus).toarray()\nX = X.transpose()#Transposing here just to match the dimensionsns with y-target variable\n\ny = dataset.iloc[:,-1].values","4678f85d":"print(X)","1b71d5b2":"print(y)","eaf2b1d9":"X.shape","903db209":"y.shape","3d654f21":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","297550ee":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","d6b21bf5":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","55ac8be9":"#confusion matrix.....\nimport seaborn as sns\nplt.figure(figsize=(20,10))\nplt.subplot(2,4,3)\nplt.title(\"Multinomial naive bayes_cm\")\nsns.heatmap(cm,annot=True,cmap=\"prism\",fmt=\"d\",cbar=False)","190b8134":"#Check the accuracy\nfrom sklearn.metrics import accuracy_score\nprint(\"The accuracy of naives bayes is:\",accuracy_score(y_pred,y_test))","9e419cce":"**Applying Multinomial Na\u00efve Bayes learning method**","0fb370f5":"The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.\n\nNumber of reviews: 568,454\nNumber of users: 256,059\nNumber of products: 74,258\nTimespan: Oct 1999 - Oct 2012\nNumber of Attributes\/Columns in data: 10\n\nAttribute Information:\n\nId\n\nProductId - unique identifier for the product\n\nUserId - unqiue identifier for the user\n\nProfileName\n\nHelpfulnessNumerator - number of users who found the review helpful\n\nHelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n\nScore - rating between 1 and 5\n\nTime - timestamp for the review\n\nSummary - brief summary of the review\n\nText - text of the review","c5f6aa2b":"# About the dataset","db4b5508":"Hi everyone!!\n\nHope you are doing well!!!\n\nI have tried my best to understand customers feedback(Sentimental analysis)!!\n\nIf you like then **please vote up**!!\n\nHappy learning!!","dc11bbd6":"**Conclusion :-**\nFrom the above analysis we can say that most people are liking amazon fine food and we got our model accuracy -72% ","13e59575":"# Goal\nGiven a review, determine whether the review is positive (rating of 4 or 5) or negative (rating of 1 or 2).\n\n\n[Q] How to determine if a review is positive or negative?\n\n[Ans] We could use Score\/Rating. A rating of 4 or 5 can be cosnidered as a positive review. A rating of 1 or 2 can be considered as negative one. A review of rating 3 is considered nuetral and such reviews are ignored from our analysis. This is an approximate and proxy way of determining the polarity (positivity\/negativity) of a review."}}