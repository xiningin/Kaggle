{"cell_type":{"983fc878":"code","499e7bc4":"code","7ea685bf":"code","ef7db5f9":"code","b3bc795e":"code","6122e5b0":"code","5e6af808":"code","86eccf43":"code","35a1266f":"code","a85266f6":"code","e6da5d40":"markdown","8d7d21d7":"markdown","8b9e2c4e":"markdown","742d71d7":"markdown","be4418e6":"markdown","40a2ea42":"markdown","6304a94b":"markdown","ac3decdb":"markdown","66c5b120":"markdown","e08e6ced":"markdown","65eb7d4e":"markdown","8f186bcb":"markdown","e4759ae1":"markdown","8cbdfb27":"markdown","bc9fb5a6":"markdown","a75fe724":"markdown"},"source":{"983fc878":"import pandas as pd\nimport re","499e7bc4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7ea685bf":"irony_data = pd.read_csv('\/kaggle\/input\/ironic-corpus\/irony-labeled.csv')\nirony_data.head()","ef7db5f9":"irony_data.shape","b3bc795e":"irony_data.label.value_counts()","6122e5b0":"unironic = irony_data['comment_text'][irony_data.label == -1].values\nironic = irony_data['comment_text'][irony_data.label == 1].values","5e6af808":"unironic[:5]","86eccf43":"ironic[:5]","35a1266f":"def count_words(lines,linetype):\n    total_words = 0\n    for line in lines:\n        total_words += len(re.findall(r'\\w+', line))\n    print(f'Number of {linetype} comments: {len(lines)}, Total words: {total_words}, Words per comment: {total_words \/ len(lines)}')","a85266f6":"count_words(unironic, \"Unironic\")\ncount_words(ironic, \"Ironic\")","e6da5d40":"# Ironic Corpus - Understanding the Data","8d7d21d7":"The dataset is imbalanced. There are approximately three times as many \"not ironic\" (-1) comments as \"ironic\" (1) comments. ","8b9e2c4e":"The first five ironic comments:","742d71d7":"Now that we've looked at the data, check out the other notebooks in this section to see different ways of analyzing it.","be4418e6":"Now let's look at the ironic and unironic comments. The comments are spearated based on their label, and by using `values` , only the comments remain.","40a2ea42":"The `shape` of the dataframe tells us how many comments are in the Ironic Corpus. Here we see that there are 1,949 comments in the file instead of 1,950.  ","6304a94b":"Here's the questions we asked before, and the answers our quick descriptive analysis provided. \n- What are examples of ironic and non-ironic comments?\n    - Ironic snippet: \"Insane like a fox.  Ted Cruz is actually very very intelligent.\"\n    - Unironic snippet: \"Also there are bound to be some glitches when rolling out a program of this scope.\"\n    - A superficial difference of the groups of comments is that the Unironic comments contain more words than the Ironic comments. After fining the mean length of comment, the Unironic comments contain almost 20 more words per comment. \n    \n    \n- What is the split of ironic \/ non ironic comments?\n    - The comments are unbalanced, with about 3:1 unironic to ironic comments.\n- How big of a dataset are we looking at?\n    - In total, the dataset contains ~84k words. ","ac3decdb":"# Understanding the Data","66c5b120":"> Harry Potter says, \u201cAnd [the Death Eaters] would love to have me. We\u2019d be best pals if they didn\u2019t keep trying to do me in.\u201d The Death Eaters is actually an evil group bent on killing Harry Potter. \nHarry Potter, \n\nJ.K. Rowling, Harry Potter and the Half-Blood Prince\n\n\nThe data presented in this corpus concerns [_irony_](https:\/\/en.wikipedia.org\/wiki\/Irony#Verbal_irony), which is a statement produced with one meaning, but the intended meaning is the opposite. That is, a literal interpretation of the statement will produce the opposite meaning of what the statement is trying to convey. For example, a person who has burned a meal might serve it and say ironically \"it's a little underdone.\"\n\nAlthought there are [different types of irony](http:\/\/typesofirony.com\/), this dataset concerns _verbal irony_. A feature of verbal irony is that it is used intentionally to mean something other than what is said.\n\nOnline comments are a ripe place for irony. \n\nThis makes irony detection a difficult problem because a surface interpretation of a sentence can produce an opposite meaning that what was intended. In natural language processing, automatic verbal irony detection has been treated as a text classification problem, but with some approaches specific to irony.\n\nThe creators of the dataset used here, claim that context is important in detecting irony. They claim that humans often need context to determine irony, and therefore computers probably also need context. \n\nThe paper was published in 201\n\n### What is the goal?\n\nThe _Ironic Corpus_, [first presented in 2014](http:\/\/www.byronwallace.com\/static\/articles\/wallace-irony-acl-2014.pdf), is set up as a binary classification problem. The dataset contains 1950 comments (taken from [reddit](www.reddit.com), which were rated as (1) containing irony, or (-1) not containing irony.\n\nThis data is relevant, because it was taken from a source known to inspire ironic comments. However, the data set was purposely created to be ambigious.\n\nIn the paper, the authors use an SVM model with five-fold cross-validation to detect irony. They present their results with the F1 score, precision and recall. For preceision and recall, scores close to 1 are best. F1 is the harmoic mean between the two.\n- average [F1 score](https:\/\/en.wikipedia.org\/wiki\/F1_score): 0.383 (range 0.330 - 0.412)\n- average [recall](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall): 0.496 (range 0.446 - 0.548)\n- average [precision](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall): 0.315 (range 0.261 - 0.380)\n\nBefore trying to improve or reporoduce these results, this notebook performs some basic exploratory data analysis to get a feel for the corpus. ","e08e6ced":"The provided csv file contains two columns, containing the text and label. Accorrding to the Kaggle page, -1 indicates a \"not ironic\" label, and a 1 indicates an \"ironic\" label.","65eb7d4e":"## What's next?","8f186bcb":"Based on rough counts, the unironic comments appear to be generally longer than the unironic comments. In addition, the entire dataset is rather small, though, with only ~84k words in total.","e4759ae1":"# Questions Answered","8cbdfb27":"Even with a cursory first glance, these groups of comments seem different in terms of word length. Below is a function to count the words across all of the ironic and unironic comments. ","bc9fb5a6":"The first five unironic comments:","a75fe724":"Let's see what this data looks like, and answer a few questions:\n- What are examples of ironic and non-ironic comments?\n- What is the split of ironic \/ non ironic comments?\n- How big of a dataset are we looking at?"}}