{"cell_type":{"665dc08b":"code","09966be7":"code","41d0ffe2":"code","9875e1bc":"code","e2a9829d":"code","5678bb62":"code","cecb45df":"code","c1e5ba96":"code","f746678c":"code","78a07ba2":"code","3420415b":"code","e421b473":"code","b6c1bc89":"code","39829a88":"code","93a397e3":"code","322b25eb":"code","3ce48d4c":"code","41285a69":"code","1912ce84":"code","717bb2d0":"code","0f65b707":"code","8cb8ff43":"code","91cbbeae":"code","e282b640":"code","7971400f":"code","8c7f146a":"code","78f28872":"code","1828cb1d":"code","69e9291d":"code","d8550dcc":"code","60dfc2e5":"code","ac3fae91":"code","88532239":"code","fe4f82dd":"code","586babc1":"code","da4047ae":"code","e5eaded1":"code","75922668":"code","9f184f6b":"code","623b01e8":"code","f715eae1":"code","bac73558":"markdown","5dc8b0c0":"markdown","24325bcb":"markdown","bfc06151":"markdown","cd7a60c0":"markdown","1c1bda2c":"markdown","dc837a28":"markdown","1bc70cef":"markdown","11654813":"markdown","d1caea74":"markdown","a8ba1f24":"markdown","27b5d935":"markdown","2329dc4b":"markdown","384d5c7e":"markdown","6578d279":"markdown","11061cfa":"markdown","378a7ffa":"markdown","f41e26fe":"markdown","2074a84c":"markdown","79f4b585":"markdown","eb64d182":"markdown","524b382f":"markdown","d20e6e92":"markdown","a1dbd923":"markdown","8364da68":"markdown","020eca2e":"markdown","36edb829":"markdown","9d96455b":"markdown","167165d6":"markdown","c6a5a7b2":"markdown","5811d200":"markdown","04597658":"markdown","2a90be4b":"markdown","331bf9f8":"markdown","8ca53f1a":"markdown"},"source":{"665dc08b":"import pandas as pd\nimport numpy as np \nimport os \nimport warnings\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport gc \nimport time \nfrom glob import glob \nfrom IPython.display import display \nimport plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, plot, iplot\nfrom wordcloud import WordCloud \nfrom typing import Dict \n\nwarnings.simplefilter(\"ignore\")\nplt.style.use(\"dark_background\")\nnp.random.seed(42)\ndebug = True","09966be7":"%%time \n\n\ndistrict = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\ndistrict.drop(\"county_connections_ratio\", axis=1, inplace=True)\nproduct = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\", usecols=[\"LP ID\", \"Product Name\", \"Primary Essential Function\"])\n\nengagement = pd.DataFrame()\nfor i, f in enumerate(glob(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/*.csv\")):\n    df = pd.read_csv(f)\n    district_id = f.split(\"\/\")[-1].split(\".\")[0]\n    df[\"district_id\"] = district_id \n#     df[\"engagement_index\"] = df[\"engagement_index\"].fillna(df[\"engagement_index\"].mean())\n    df[\"pct_access\"] = df[\"pct_access\"].fillna(df[\"pct_access\"].mean())\n    engagement = pd.concat([engagement, df])\n    if debug:\n        if i > 30:\n            break \n    else:\n        if i > 233:\n            break \n        \ndisplay(district.head())\ndisplay(product.head())\ndisplay(engagement.head())\n","41d0ffe2":"display(district.isnull().sum().to_frame())","9875e1bc":"'''\ndistrict table \n'''\n\ndef pct_black(x):\n    if x == \"[0, 0.2[\":\n        return float(0.1)\n    elif x == \"[0.2, 0.4[\":\n        return float(0.3)\n    elif x == \"[0.4, 0.6[\":\n        return float(0.5)\n    elif x == \"[0.8, 1[\":\n        return float(0.9)\n    else:\n        return np.nan\n    \ndef pct_free(x):\n    if x == \"[0, 0.2[\":\n        return float(0.1)\n    elif x == \"[0.2, 0.4[\":\n        return float(0.3)\n    elif x == \"[0.4, 0.6[\":\n        return float(0.5)\n    elif x == \"[0.6, 0.8[\":\n        return float(0.7)\n    elif x == \"[0.8, 1[\":\n        return float(0.9)\n    else:\n        return np.nan \n    \ndef pp_raw(x):\n    if x == \"missing\":\n        return x \n    else:\n        x = str(x)\n        upper_value = int(x.split(\",\")[0].split(\"[\")[1].strip())\n        lower_value = int(x.split(\",\")[1].split(\"[\")[0].strip())\n        return (upper_value+lower_value) \/\/ 2 \n    \n# drppna\ndistrict = district[district.state.notna()].reset_index(drop=True)\n\n# take the median as float \ndistrict[\"pct_black\/hispanic\"] = district[\"pct_black\/hispanic\"].apply(pct_black)\ndistrict[\"pct_free\/reduced\"] = district[\"pct_free\/reduced\"].apply(pct_free)\ndistrict[\"pp_total_raw\"] = district[\"pp_total_raw\"].fillna(\"missing\")\ndistrict[\"pp_total_raw\"] = district[\"pp_total_raw\"].apply(pp_raw)\n\n# fill values \ndistrict[\"pct_black\/hispanic\"] = district[\"pct_black\/hispanic\"].fillna(district[district[\"pct_black\/hispanic\"].notna()].groupby(\"locale\")[\"pct_black\/hispanic\"].mean())\ndistrict[\"pct_black\/hispanic\"] = district[\"pct_black\/hispanic\"].fillna(district[\"pct_black\/hispanic\"].mean())\ndistrict[\"pct_free\/reduced\"] = district[\"pct_free\/reduced\"].fillna(district[district[\"pct_free\/reduced\"].notna()].groupby(\"locale\")[\"pct_free\/reduced\"].mean())\ndistrict[\"pct_free\/reduced\"] = district[\"pct_free\/reduced\"].fillna(district[\"pct_free\/reduced\"].mean())\ndistrict[\"pp_total_raw\"] = district[\"pp_total_raw\"].apply(lambda x: district.loc[district[\"pp_total_raw\"] != \"missing\", \"pp_total_raw\"].mean() if x == \"missing\" else x)\n\ndisplay(district.isnull().sum().to_frame())","e2a9829d":"\n'''\nproduct table \n\n'''\n\ndef get_main(x):\n    if type(x) == list and len(x) > 0 :\n        return x[0] \n    else:\n        return \"missing\"\n    \ndef get_sub(x):\n    if type(x) == list and len(x) > 1:\n        return x[1]\n    else:\n        return \"missing\"\n    \n# split main and sub in Primary Essential Function    \nproduct[\"Primary Essential Function\"] = product[\"Primary Essential Function\"].fillna(\"missing\")\nproduct[\"split\"] = product[\"Primary Essential Function\"].apply(lambda x: x.split(\"-\"))\nproduct[\"main\"] = product[\"split\"].apply(get_main)\nproduct[\"sub\"] = product[\"split\"].apply(get_sub)\nproduct.drop([\"split\", \"Primary Essential Function\"], axis=1, inplace=True)\n\ndisplay(product.isnull().sum().to_frame())","5678bb62":"\n'''\nmerge dataframe \n\n'''\n\ndf = pd.merge(engagement, product, how=\"left\", left_on=\"lp_id\", right_on=\"LP ID\")\ndel engagement, product\n\ndf[\"district_id\"] = df[\"district_id\"].astype(int)\ndistrict[\"district_id\"] = district[\"district_id\"].astype(int)\ndf = pd.merge(df, district, how=\"left\", left_on=\"district_id\", right_on=\"district_id\")\ndel district \ngc.collect()\n\nif debug:\n    df = df.dropna()\n    \ndf = df.rename(columns={\"Product Name\": \"product\", \"pct_black\/hispanic\": \"hispanic\", \"pct_free\/reduced\": \"reduced\", \"pp_total_raw\": \"pp_raw\"})\ndf.drop(\"LP ID\", axis=1, inplace=True)\ndf.head()","cecb45df":"display(df.isnull().sum().to_frame())","c1e5ba96":"def reduce_mem_usage(train_data):\n    start_mem = train_data.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    for col in train_data.columns:\n        col_type = train_data[col].dtype\n\n        if col_type != object:\n            c_min = train_data[col].min()\n            c_max = train_data[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    train_data[col] = train_data[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    train_data[col] = train_data[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    train_data[col] = train_data[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    train_data[col] = train_data[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    train_data[col] = train_data[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    train_data[col] = train_data[col].astype(np.float32)\n                else:\n                    train_data[col] = train_data[col].astype(np.float64)\n        else:\n            train_data[col] = train_data[col].astype('category')\n\n    end_mem = train_data.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return train_data","f746678c":"%%time\n\ndf = reduce_mem_usage(df)\ndf[\"time\"] = pd.to_datetime(df.time)","78a07ba2":"#hispanic \nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\nax = axes.ravel()\n\nhispanic = df.groupby(\"product\").mean().loc[:, [\"hispanic\"]].sort_values(\"hispanic\", ascending=False)\nhispanic.iloc[:10].sort_values(\"hispanic\").plot(kind=\"barh\", cmap=\"Greens\", ax=ax[0])\nax[0].set_title(\"high hispanic x Product\")\nax[0].set_xticks(np.arange(0, 0.6, 0.1))\nhispanic.iloc[-10:].sort_values(\"hispanic\", ascending=False).plot(kind=\"barh\", cmap=\"Greens\", ax=ax[1])\nax[1].set_title(\"low hispanic x Product\")\nax[1].set_xticks(np.arange(0, 0.6, 0.1))\nplt.suptitle(\"hispanic\", fontsize=20)\nplt.tight_layout()\n\n#reduces \nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\nax = axes.ravel()\n\nhispanic = df.groupby(\"product\").mean().loc[:, [\"reduced\"]].sort_values(\"reduced\", ascending=False)\nhispanic.iloc[:10].sort_values(\"reduced\").plot(kind=\"barh\", cmap=\"Greens\", ax=ax[0])\nax[0].set_title(\"high reduced x Product\")\nax[0].set_xticks(np.arange(0, 0.6, 0.1))\nhispanic.iloc[-10:].sort_values(\"reduced\", ascending=False).plot(kind=\"barh\", cmap=\"Greens\", ax=ax[1])\nax[1].set_title(\"low reduced x Product\")\nax[1].set_xticks(np.arange(0, 0.6, 0.1))\nplt.suptitle(\"reduced\", fontsize=20)\nplt.tight_layout()\n\n#pp_total_raw \nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\nax = axes.ravel()\n\nhispanic = df.groupby(\"product\").mean().loc[:, [\"pp_raw\"]].sort_values(\"pp_raw\", ascending=False)\nhispanic.iloc[:10].sort_values(\"pp_raw\").plot(kind=\"barh\", cmap=\"Greens\", ax=ax[0])\nax[0].set_title(\"high pp_total_raw x Product\")\nax[0].set_xticks(np.arange(0, 16000, 2000))\nhispanic.iloc[-10:].sort_values(\"pp_raw\", ascending=False).plot(kind=\"barh\", cmap=\"Greens\", ax=ax[1])\nax[1].set_title(\"low pp_total_raw x Product\")\nax[1].set_xticks(np.arange(0, 16000, 2000))\nplt.suptitle(\"pp_total_raw\", fontsize=20)\nplt.tight_layout()\n\ndel hispanic \ngc.collect()","3420415b":"fig, axes = plt.subplots(1, 3, figsize=(22, 6))\nax = axes.ravel()\n\ngrp = df.groupby(\"locale\").mean().loc[:, [\"hispanic\"]]\ngrp.plot(kind=\"barh\", cmap=\"Greens\", ax=ax[0])\nax[0].set_title(\"hispanic\")\n\ngrp = df.groupby(\"locale\").mean().loc[:, [\"reduced\"]]\ngrp.plot(kind=\"barh\", cmap=\"Greens\", ax=ax[1])\nax[1].set_title(\"reduced\")\n\ngrp = df.groupby(\"locale\").mean().loc[:, [\"pp_raw\"]]\ngrp.plot(kind=\"barh\", cmap=\"Greens\", ax=ax[2])\nax[2].set_title(\"pp_total_raw\")\n\nplt.tight_layout()\n","e421b473":"locale = df.locale.value_counts().index\nfig, axes = plt.subplots(1, 4, figsize=(22, 12))\nax = axes.ravel()\n\n# locale 1\ngrp = df.loc[df.locale == locale[0], [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:10]\ngrp.sort_values(\"pct_access\").plot(kind=\"barh\", ax=ax[0], cmap=\"Greens\")\nax[0].set_title(locale[0])\nax[0].set_xticks(np.arange(0, 20.0, 2.0))\n\n\n# locale 2 \ngrp = df.loc[df.locale == locale[1], [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:10]\ngrp.sort_values(\"pct_access\").plot(kind=\"barh\", ax=ax[1], cmap=\"Greens\")\nax[1].set_title(locale[1])\nax[1].set_xticks(np.arange(0, 20.0, 2.0))\n\n\n# locale 3 \ngrp = df.loc[df.locale == locale[2], [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:10]\ngrp.sort_values(\"pct_access\").plot(kind=\"barh\", ax=ax[2], cmap=\"Greens\")\nax[2].set_title(locale[2])\nax[2].set_xticks(np.arange(0, 20.0, 2.0))\n\n\n# locale 4\ngrp = df.loc[df.locale == locale[3], [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:10]\ngrp.sort_values(\"pct_access\").plot(kind=\"barh\", ax=ax[3], cmap=\"Greens\")\nax[3].set_title(locale[3])\nax[3].set_xticks(np.arange(0, 20.0, 2.0))\n\ndel grp \ngc.collect()\nplt.suptitle(\"most popular Plattform by Locale\", fontsize=18)\nplt.tight_layout()","b6c1bc89":"grp = df.groupby(\"product\").mean().loc[:, [\"pct_access\"]]\n\nfig, axes = plt.subplots(1, 2, figsize=(22, 6))\nax = axes.ravel()\n\ngrp.sort_values(\"pct_access\", ascending=False)[:10].sort_values(\"pct_access\", ascending=True).plot(kind=\"barh\", ax=ax[0])\nax[0].set_title(\"most use product by all.\")\nax[0].set_xticks(np.arange(0, 20.0, 2.0))\n\ngrp.sort_values(\"pct_access\", ascending=True)[:10].sort_values(\"pct_access\", ascending=False).plot(kind=\"barh\", ax=ax[1])\nax[0].set_title(\"most unuse product by all.\")\nax[1].set_xticks(np.arange(0, 0.1, 0.01))\n\nplt.suptitle(\"populer Plattform.\", fontsize=18)\nplt.tight_layout()","39829a88":"df[\"week\"] = df.time.dt.dayofweek \n\nweek_name = {\n    0: \"monday\", \n    1: \"thesday\",\n    2: \"wednesday\", \n    3: \"thursday\", \n    4: \"friday\",\n    5: \"saturday\",\n    6: \"sunday\",\n}\n\nfig, axes = plt.subplots(3, 3, figsize=(22, 18))\nax = axes.ravel()\n\nfor i, week in enumerate(np.argsort(df.week.unique())):\n    x = df.loc[df.week == week, [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:5]\n    x.sort_values(\"pct_access\", ascending=True).plot(kind=\"barh\", cmap=\"Greens\", ax=ax[i])\n    ax[i].set_title(week_name[week])\n    ax[i].set_xticks(np.arange(0, 20.0, 2.0))\n    \nplt.suptitle(\"Weekly popular platform \", fontsize=18)\nplt.tight_layout()","93a397e3":"def viz_transition(high, low):\n    fig, axes = plt.subplots(1, 2, figsize=(22, 12))\n    ax = axes.ravel()\n    color = [\"b\", \"r\", \"g\"]\n    for i, p in enumerate(high):\n        x = df[df[\"product\"] == p]\n        x[[\"time\", \"pct_access\"]].groupby(\"time\").mean().loc[:, \"pct_access\"].plot(cmap=\"Greens\", ax=ax[0], color=color[i])\n    ax[0].set_title(\"most popular plattform top3 trends.\")\n    ax[0].legend(high)\n    \n    for i, p in enumerate(low):\n        x = df[df[\"product\"] == p]\n        x[[\"time\", \"pct_access\"]].groupby(\"time\").mean().loc[:, \"pct_access\"].plot(cmap=\"Greens\", ax=ax[1], color=color[i])\n    ax[1].set_title(\"not most popular plattform under3 trends.\")\n    ax[1].legend(low)\n    plt.suptitle(\"Trends.\", fontsize=16)\n    plt.tight_layout()\n    \n    del x\n    gc.collect()\n    \n\ntop_3_plattform = df[[\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:3].index.values.to_list()\nunder_3_plattform = df[[\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=True)[:3].index.values.to_list()\nviz_transition(top_3_plattform, under_3_plattform)","322b25eb":"top_10_plattform = df[[\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:10].index.values.to_list()\nunder_10_plattform = df[[\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[-10:].index.values.to_list()\n\nfig, axes = plt.subplots(1, 2, figsize=(22, 12))\nax = axes.ravel()\n\ngrp = df.loc[df[\"product\"].isin(top_10_plattform), [\"locale\"]].value_counts().to_frame()\ngrp.plot(kind=\"barh\", cmap=\"Greens\", ax=ax[0])\nax[0].set_title(\"Top10 Plattfrom\")\nax[0].set_xticks(np.arange(0, 40000, 10000))\n\ngrp = df.loc[df[\"product\"].isin(under_10_plattform), [\"locale\"]].value_counts().to_frame()\ngrp.plot(kind=\"barh\", cmap=\"Greens\", ax=ax[1])\nax[1].set_title(\"Under10 Plattfrom\")\nax[1].set_xticks(np.arange(0, 4000, 1000))\n\nplt.suptitle(\"Popular platform migration district \", fontsize=18)\nplt.tight_layout()\n\ndel grp \ngc.collect()","3ce48d4c":"us_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\npd.DataFrame({\"TOP\": top_10_plattform, \"UNDER\": under_10_plattform})","41285a69":"def show_location(plattform):\n    x = df.loc[df[\"product\"].isin(plattform), \"state\"].value_counts().to_frame().sort_values(\"state\", ascending=False)[:20]\n    x = x.rename(columns={\"state\": \"count\"})\n    x[\"state\"] = x.index \n    x[\"state\"] = x.state.map(us_state_abbrev)\n    x = x.reset_index(drop=True)\n    data = dict(\n        type = 'choropleth',\n        colorscale = 'blackbody',\n        locations = x[\"state\"],\n        locationmode = 'USA-states',\n        z = list(x['count']),\n        text = x[\"state\"],\n        colorbar = {'title':'States'},\n      )\n    layout = dict(title = 'States',\n                  geo = dict(projection = {'type':'mercator'})\n                 )\n    layout = dict(title= 'Platform popularity usage count ',\n                  geo = {'scope':'usa'})\n\n    choromap = go.Figure(data = [data],layout = layout)\n    iplot(choromap)\n    del x\n    gc.collect()\n    \n    \ndef show_location_locale(locale, plattform):\n    x = df.loc[(df[\"locale\"] == locale) & (df[\"product\"].isin(plattform)), [\"state\", \"product\"]]\n    x = x.groupby(\"state\").count().loc[:, [\"product\"]]\n    x = x[x[\"product\"] != 0]\n    x = x.rename(columns={\"product\": \"count\"})\n    x[\"state\"] = x.index \n    x[\"state\"] = x[\"state\"].map(us_state_abbrev)\n    x = x.reset_index(drop=True)\n    \n    data = dict(\n        type = 'choropleth',\n        colorscale = 'blackbody',\n        locations = x[\"state\"],\n        locationmode = 'USA-states',\n        z = list(x['count']),\n        text = x[\"state\"],\n        colorbar = {'title':'States'},\n      )\n    layout = dict(title = 'States',\n                  geo = dict(projection = {'type':'mercator'})\n                 )\n    layout = dict(title= f'Platform popularity usage count by {locale}',\n                  geo = {'scope':'usa'})\n    choromap = go.Figure(data = [data],layout = layout)\n    iplot(choromap)\n    del x\n    gc.collect()","1912ce84":"show_location(top_10_plattform)","717bb2d0":"show_location(under_10_plattform)","0f65b707":"show_location_locale(df.locale.unique()[0], top_10_plattform)","8cb8ff43":"show_location_locale(df.locale.unique()[1], top_10_plattform)","91cbbeae":"show_location_locale(df.locale.unique()[2], top_10_plattform)","e282b640":"show_location_locale(df.locale.unique()[3], top_10_plattform)","7971400f":"show_location_locale(df.locale.unique()[0], under_10_plattform)","8c7f146a":"show_location_locale(df.locale.unique()[1], under_10_plattform)","78f28872":"show_location_locale(df.locale.unique()[2], under_10_plattform)","1828cb1d":"show_location_locale(df.locale.unique()[3], under_10_plattform)","69e9291d":"def viz_main(high, low):\n    fig, axes = plt.subplots(1, 2, figsize=(22, 12))\n    ax = axes.ravel()\n    x = df.loc[df[\"product\"].isin(high), [\"main\"]].value_counts()\n    ax[0].pie(x=x.values, labels=x.index, startangle=90, autopct=\"%1.1f%%\", shadow=True, counterclock=False)\n    ax[0].set_title(\"most popular Plattfrom x main.\")\n    \n    x = df.loc[df[\"product\"].isin(low), [\"main\"]].value_counts()\n    ax[1].pie(x=x.values, labels=x.index, startangle=90, autopct=\"%1.1f%%\", shadow=True, counterclock=False)\n    ax[1].set_title(\"not most popular Plattfrom x main.\")\n    \n    plt.tight_layout()\n    del x \n    gc.collect()\n    ","d8550dcc":"viz_main(top_10_plattform, under_10_plattform)","60dfc2e5":"def create_vocab(sub) -> Dict[str, int]:\n    word2count = {}\n    for s in sub:\n        s = s.strip()\n        for ss in s.split():\n            ss = ss.lower()\n            if ss == \"&\": continue \n            if ss not in word2count:\n                word2count[ss] = 1 \n            else:\n                word2count[ss] += 1 \n    return word2count \n\ndef viz_sub(high, low):\n    fig, axes = plt.subplots(1, 2, figsize=(22, 12))\n    ax = axes.ravel()\n    \n    x = df.loc[df[\"product\"].isin(high), \"sub\"].to_list()\n    word2count = create_vocab(x)\n    word = WordCloud(width=1440, height=1100).generate_from_frequencies(word2count)\n    ax[0].imshow(word)\n    ax[0].set_xticks([])\n    ax[0].set_yticks([])\n    ax[0].set_title(\"most popular Plattfrom x sub word\")\n    \n    x = df.loc[df[\"product\"].isin(low), \"sub\"].to_list()\n    word2count = create_vocab(x)\n    word = WordCloud(width=1440, height=1100).generate_from_frequencies(word2count)\n    ax[1].imshow(word)\n    ax[1].set_xticks([])\n    ax[1].set_yticks([])    \n    ax[1].set_title(\"not most popular Plattfrom x sub word\")","ac3fae91":"viz_sub(top_10_plattform, under_10_plattform)","88532239":"df[\"quarter\"] = df.time.dt.quarter \ndisplay(df[\"quarter\"].value_counts().to_frame().sort_index())","fe4f82dd":"before_covid = df[df.quarter == 1]\nbefore_covid = before_covid.pivot_table(values=\"pct_access\", index=\"product\", columns=\"quarter\", aggfunc=\"mean\")\nbefore_covid.columns = [\"pct_access\"]\n\nbefore_covid.sort_values(\"pct_access\", ascending=False)[:10].sort_values(\"pct_access\", ascending=True).plot(kind=\"barh\", figsize=(22, 12))\nplt.title(\"before the pandemic most popular Plattfrom.\", fontsize=18)\nplt.show()","586babc1":"after_covid = df[df.quarter != 1]\nafter_covid = after_covid.groupby(\"product\").mean().loc[:, [\"pct_access\"]]\n\nafter_covid.sort_values(\"pct_access\", ascending=False)[:10].sort_values(\"pct_access\", ascending=True).plot(kind=\"barh\", figsize=(22, 12))\nplt.title(\"after the pandemic most popular Plattfrom.\", fontsize=18)\nplt.show()","da4047ae":"growth = pd.merge(before_covid.rename(columns={\"pct_access\": \"before_access\"}), after_covid.rename(columns={\"pct_access\": \"after_access\"}), how=\"outer\", left_index=True, right_index=True)\ngrowth = growth.fillna(0)\ngrowth[\"growth_access\"] = growth[\"after_access\"] - growth[\"before_access\"]\ngrowth = growth[[\"growth_access\"]].sort_values(\"growth_access\", ascending=False)[:10]\n\ngrowth.sort_values(\"growth_access\", ascending=True).plot(kind=\"barh\", figsize=(22, 12))\nplt.title(\"Access growth potential \", fontsize=18)\nplt.show()\n\ndel before_covid, after_covid, growth \ngc.collect()","e5eaded1":"df[\"google\"] = df[\"product\"].apply(lambda x: x.find(\"Google\") >= 0)\ndf[\"google\"] = df[\"google\"].apply(lambda x: 1 if x is True else 0)\ngoogle = df[\"google\"].value_counts()\n\nplt.figure(figsize=(12, 12))\nplt.pie(x=google.values, labels=google.index, startangle=90, counterclock=False, autopct=\"%1.1f%%\")\nplt.legend([\"not Google\", \"Google\"])\nplt.show()","75922668":"fig, axes = plt.subplots(1, 2, figsize=(22, 12))\nax = axes.ravel()\n\ngoogle_service = df.loc[df[\"google\"] == 1, [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=False)[:10]\ngoogle_service.sort_values(\"pct_access\", ascending=True).plot(kind=\"barh\", ax=ax[0])\nax[0].set_title(\"most popluar Plattfrom with google\")\n\ngoogle_service = df.loc[df[\"google\"] == 1, [\"product\", \"pct_access\"]].groupby(\"product\").mean().sort_values(\"pct_access\", ascending=True)[:10]\ngoogle_service.sort_values(\"pct_access\", ascending=False).plot(kind=\"barh\", ax=ax[1])\nax[1].set_title(\"not most popluar Plattfrom with google\")\n\nplt.suptitle(\"Google Service.\", fontsize=20)\nplt.tight_layout()\n\ndel google_service\ngc.collect()","9f184f6b":"def viz_transition_google():\n    fig, axes = plt.subplots(1, 2, figsize=(22, 12))\n    ax = axes.ravel()\n    \n    x = df.loc[df[\"google\"] == 0, [\"time\", \"pct_access\"]].groupby(\"time\").mean().sort_index()\n    x.plot(ax=ax[0])\n    ax[0].set_title(\"Not google x pct access.\")\n    \n    x = df.loc[df[\"google\"] == 1, [\"time\", \"pct_access\"]].groupby(\"time\").mean().sort_index()\n    x.plot(ax=ax[1])\n    ax[1].set_title(\"is google x pct access.\")\n    \n    plt.tight_layout()\n    del x \n    gc.collect()\n    ","623b01e8":"viz_transition_google()","f715eae1":"df.head()","bac73558":"### Plattform x State","5dc8b0c0":"#### Trends in popular and unpopular platforms ","24325bcb":"### Plattform x State \n\nCount and visualize the states in which each platform ranked in the frame below is used. ","bfc06151":"#### weekly","cd7a60c0":"#### sub ","1c1bda2c":"**Thanks for watching:)**","dc837a28":"# 1. Preprocess ","1bc70cef":"### with google ","11654813":"### Plattform x Primary Essential Function ","d1caea74":"# 0. Read CSV ","a8ba1f24":"### Before the pandemic x Plattfrom ","27b5d935":"## Before and after the covid \n---","2329dc4b":"### Growth rate ","384d5c7e":"#### main ","6578d279":"### Locale x Plattform\nGet popular platforms in each locale","11061cfa":"### Plattform x Locale  \nSame as the combination described above, but with different trials to aggregate from each platform. In other words, the aggregated value is reversed.   \nNote that the width numbers are 10 times different. ","378a7ffa":"### Plattoform x Numerical \nOnly the most used or unused products are counted. ","f41e26fe":"#### Under 10 Plattform groupby locale ","2074a84c":"###   Popular Plattform \n---","79f4b585":"Get the platform with the highest growth rate from the average access value for each season. The front of the corona is divided into quarters, and the rear is divided into 2 and later. ","eb64d182":"The difference between top and bottom is quite large ","524b382f":"#### Obsevation... \n* The google platform shows high frequency of use in every area. \n* Especially in city, the ratio of hispanic is large and the ratio is also high from the total of platforms.   \n* Most consist of city or suburb.   \n* Extreme pp_total_raw platform not included in popularity   \n\nContinue your insights from the three figures above. You will get a better analysis. ","d20e6e92":"### Comparison of transition ","a1dbd923":"### Locale x Numerical ","8364da68":"### Plattform x State x Locale \nVisualize platform counts aggregated by locale by state. ","020eca2e":"#### Observation...\n* There is a big difference in the transition distribution between popular and unpopular platforms, which is reversed before and after the corona.  \n* There is not much change from week to week and google is monopolizing. \n* Platform usage is not sorted by migration type \n\nHowever, keep in mind that the axis widths are different.","36edb829":"## Numerical data \n---","9d96455b":"# 2.EDA ","167165d6":"#### all ","c6a5a7b2":"#### Observation...\n* The google service is conservatively strong. \n* There are also platforms that have increased in demand after the corona. It seems that teleworking by video services is great. ","5811d200":"## Whether google \n---","04597658":"### After the pandemic x Plattfrom ","2a90be4b":"#### Top 10 Plattform groupby locale ","331bf9f8":"Platforms other than google are on the rise after Corona. ","8ca53f1a":"In my opinion, the word used in schools on popular platforms. I think there are many specialized words on unpopular platforms. "}}