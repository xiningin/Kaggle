{"cell_type":{"55288cec":"code","8ad19dec":"code","f3e26ab2":"code","cf845033":"code","bd14cda1":"code","410d86de":"code","af13d345":"code","6685045d":"code","80949005":"code","904c5aff":"code","933a8675":"code","a2a605d4":"code","76eca54e":"code","217fa443":"code","cb7a9f44":"code","ab7e3fbe":"code","c1414c71":"code","4b8f1818":"code","5d56cf73":"code","bc204a44":"code","df1ed0d7":"code","d647e637":"code","3e0c036a":"code","36f7cd19":"code","cfe11262":"markdown","42281de4":"markdown","5c3f14b1":"markdown","ae2bb0c2":"markdown","719d5dd2":"markdown","bd9bfb3e":"markdown"},"source":{"55288cec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8ad19dec":"df_train = pd.read_csv('..\/input\/train.csv')\nX_train = df_train.iloc[:, 1:]\nY_train = df_train.iloc[:, 0]","f3e26ab2":"X_train.head()","cf845033":"Y_train.head()","bd14cda1":"X_train = np.array(X_train)\nY_train = np.array(Y_train)","410d86de":"# Normalize inputs\nX_train = X_train \/ 255.0","af13d345":"def plot_digits(X, Y):\n    for i in range(20):\n        plt.subplot(5, 4, i+1)\n        plt.tight_layout()\n        plt.imshow(X[i].reshape(28, 28), cmap='gray')\n        plt.title('Digit:{}'.format(Y[i]))\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","6685045d":"plot_digits(X_train, Y_train)","80949005":"fig, ax = plt.subplots(figsize=(8,8))\nsns.countplot(Y_train)\nax.set_title('Distribution of Digits', fontsize=14)\nax.set_xlabel('Digits', fontsize=12)\nax.set_ylabel('Count', fontsize=14)\nplt.show()","904c5aff":"#Train-Test Split\nX_dev, X_val, Y_dev, Y_val = train_test_split(X_train, Y_train, test_size=0.03, shuffle=True, random_state=2019)\nT_dev = pd.get_dummies(Y_dev).values\nT_val = pd.get_dummies(Y_val).values","933a8675":"#Reshape the input \nX_dev = X_dev.reshape(X_dev.shape[0], 28, 28, 1)\nX_val = X_val.reshape(X_val.shape[0], 28, 28, 1)","a2a605d4":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPool2D(strides=2))\nmodel.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\nmodel.add(MaxPool2D(strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(84, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","76eca54e":"model.build()\nmodel.summary()","217fa443":"adam = Adam(lr=5e-4)\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)","cb7a9f44":"# Set a learning rate annealer\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', \n                                patience=3, \n                                verbose=1, \n                                factor=0.2, \n                                min_lr=1e-6)","ab7e3fbe":"# Data Augmentation\ndatagen = ImageDataGenerator(\n            rotation_range=10, \n            width_shift_range=0.1, \n            height_shift_range=0.1, \n            zoom_range=0.1)\ndatagen.fit(X_dev)","c1414c71":"model.fit_generator(datagen.flow(X_dev, T_dev, batch_size=100), steps_per_epoch=len(X_dev)\/100, \n                    epochs=30, validation_data=(X_val, T_val), callbacks=[reduce_lr])","4b8f1818":"score = model.evaluate(X_val, T_val, batch_size=32)","5d56cf73":"score","bc204a44":"df_test = pd.read_csv('..\/input\/test.csv')\nX_test = np.array(df_test)\nX_test = X_test\/255.0","df1ed0d7":"X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\nY_test = model.predict(X_test)","d647e637":"Y_test = np.argmax(Y_test, axis=1)\nY_test[:5]","3e0c036a":"df_out = pd.read_csv('..\/input\/sample_submission.csv')\ndf_out['Label'] = Y_test\ndf_out.head()","36f7cd19":"df_out.to_csv('out.csv', index=False)","cfe11262":"# Create submission file","42281de4":"# LeNet-5 CNN with Keras:\n** I am developing a series of kernels for different Deep Learning Models: **\n\n* [L-Layered Neural Network from scratch](https:\/\/www.kaggle.com\/curiousprogrammer\/l-layered-neural-network-from-scratch)\n* [TensorFlow NN with Augmentation](https:\/\/www.kaggle.com\/curiousprogrammer\/digit-recognizer-tensorflow-nn-with-augmentation)\n* [Data Augmentation in Python, TF, Keras, Imgaug](https:\/\/www.kaggle.com\/curiousprogrammer\/data-augmentation-in-python-tf-keras-imgaug)\n* [Deep NN with Keras](https:\/\/www.kaggle.com\/curiousprogrammer\/deep-nn-with-keras-97-5) \n* [CNN with TensorFlow](https:\/\/www.kaggle.com\/curiousprogrammer\/lenet-5-cnn-with-tensorflow-98-5) \n* CNN with Keras - This one\n* AutoEncoders with TensorFlow\n* AutoEncoders with Keras\n* GANs with TensorFlow\n* GANs with Keras","5c3f14b1":"# Plot Digits","ae2bb0c2":"# Let's predict test data","719d5dd2":"# CNN Architecture\n\nWe will LeNet-5 CNN architeture to build our model.\n\n** LeNet - 5 Architecture: **\n\n![LeNet-5 Architecture](https:\/\/engmrk.com\/wp-content\/uploads\/2018\/09\/LeNet_Original_Image.jpg)\n\n** Convolution Operation: **\n\n![Convolution Operation](https:\/\/www.researchgate.net\/profile\/Ihab_S_Mohamed\/publication\/324165524\/figure\/fig3\/AS:611103423860736@1522709818959\/An-example-of-convolution-operation-in-2D-2.png)\n\n### Input : Flattened 784px grayscale images, which can be represented as dimension (n, 28, 28, 1)\n### Output: 0 - 9 \n\n### Let's decode the operations we will be performing in each layer \n** First Layer:  Convolutional Layer (CONV1): **\n* Parameters: Input (N) = 28, Padding (P) = 2, Filter (F) = 5 x 5, Stride (S) = 1\n* Conv Operation: ((N + 2P - F) \/ S) + 1 = ((28 + 4 - 5) \/ 1) + 1 = 28 x 28 \n* We will apply 6 filters \/ kernels so we will get a 28 x 28 x 6 dimensional output\n\n** Second Layer:  Average Pooling Layer (POOL1): **\n* Parameters: Input (N) = 28, Filter (F) = 2 x 2, Stride (S) = 2\n* AVG Pooling Operation: ((N + 2P -F) \/ S) + 1 = ((28 - 2) \/ 2) + 1 = 14 x 14\n* We will have a 14 x 14 x 6 dimensional output at the end of this pooling\n\n** Third Layer:  Convolutional Layer (CONV2): **\n* Parameters: Input (N) = 14, Filter (F) = 5 x 5, Stride (S) = 1\n* Conv Operation: ((N + 2P - F) \/ S) + 1 = ((14 - 5) \/ 1) + 1 = 10 x 10\n* We will apply 16 filters \/ kernels so we will get a 10 x 10 x 16 dimensional output \n\n** Fourth Layer: Average Pooling Layer (POOL2): **\n* Parameters: Input (N) = 10, Filter (F) = 2 x 2, Stride (S) = 2\n* AVG Pooling Operation: ((N + 2P -F) \/ S) + 1 = ((10 - 2) \/ 2) + 1 = 5 x 5\n* We will have a 5 x 5 x 16 dimensional output at the end of this pooling\n\n** Fifth Layer: Fully Connected layer(FC1): **\n* Parameters: W: 400 * 120, b: 120\n* We will have an output of 120 x 1 dimension\n\n** Sixth Layer: Fully Connected layer(FC2): **\n* Parameters: W: 120 * 84, b: 84\n* We will have an output of 84 x 1 dimension\n\n** Seventh Layer: Output layer(Softmax): **\n* Parameters: W: 84 * 10, b: 10\n* We will get an output of 10 x 1 dimension\n\nWe will tweak the pooling layers from average to max and activation functions. With this architecture as per book, I was not able to achieve accuracy > 98.5%. Let's imcrease the filters and check.","bd9bfb3e":"# Load Data"}}