{"cell_type":{"dcaaf4d2":"code","8c34ade7":"code","c6ca4203":"code","2e178a37":"code","cc72fad0":"code","f46135c2":"code","ef16f6af":"code","0d9809a0":"code","ab306118":"code","cd8cd6b7":"code","8214d9fe":"code","0cd57b58":"code","63440096":"code","9de39a0a":"markdown","09309f47":"markdown","34d4561b":"markdown","fa727cde":"markdown","d94405d3":"markdown"},"source":{"dcaaf4d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c34ade7":"data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","c6ca4203":"test_ids = test[\"PassengerId\"]","2e178a37":"data.head()","cc72fad0":"def clean(data):\n    data = data.drop([\"Ticket\", \"PassengerId\", \"Name\", \"Cabin\"], axis=1)\n    \n    cols = [\"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n    for col in cols:\n        data[col].fillna(data[col].median(), inplace=True)\n        \n    data.Embarked.fillna(\"U\", inplace=True)\n    return data\n\ndata = clean(data)\ntest = clean(test)","f46135c2":"data.head()","ef16f6af":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ncolumns = [\"Sex\", \"Embarked\"]\n\nfor col in columns:\n    data[col] = le.fit_transform(data[col])\n    test[col] = le.transform(test[col])\n    print(le.classes_)\n      \ndata.head()","0d9809a0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ny = data[\"Survived\"]\nX = data.drop(\"Survived\", axis=1)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","ab306118":"clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)","cd8cd6b7":"predictions = clf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_val, predictions)","8214d9fe":"submission_preds = clf.predict(test)","0cd57b58":"df = pd.DataFrame({\"PassengerId\": test_ids.values,\n                   \"Survived\": submission_preds,\n                  })","63440096":"df.to_csv(\"submission.csv\", index=False)","9de39a0a":"# Getting sklearn Logistic Regression Model for training and testing","09309f47":"# Select PassengerId in test_ids for submission","34d4561b":"# Removing un-necessary columns from the data. Also replacing missing values in dataset with median. ","fa727cde":"# Get the dataset ","d94405d3":"# Changing the columns of Sex and Embarked from string to int for better model building"}}