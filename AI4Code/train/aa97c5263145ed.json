{"cell_type":{"d3a386c1":"code","4c946b53":"code","749db022":"code","b0c40951":"code","c2fe6307":"code","d680c84a":"code","24e72000":"code","1c7e0b9b":"code","57829820":"code","d29d82c6":"code","49e55666":"code","28b21d1a":"code","2adae8d1":"code","2d100ada":"code","47cd4839":"code","5f96b642":"code","b1bc824b":"code","0ebe4d4b":"code","96cee2c4":"code","f65a8a22":"code","097de071":"code","fa27e6f6":"code","388f6f8e":"code","e571c596":"code","13ab2134":"code","173a53ef":"code","7912388c":"markdown","28f930f4":"markdown","9d920e87":"markdown","32f1d9ff":"markdown","9273da2e":"markdown","27c846f5":"markdown","2af612cb":"markdown","04c3f7f9":"markdown","73f86b77":"markdown","789de0c1":"markdown","48ed6ea3":"markdown"},"source":{"d3a386c1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4c946b53":"training_dataset = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv', header=0)\ntraining_dataset.head()","749db022":"bincount = np.bincount(training_dataset.label)\nprint(dict(zip(np.nonzero(bincount)[0], bincount)))","b0c40951":"y = training_dataset['label'].copy()\nX = training_dataset.drop(['label'], axis='columns')\ndel training_dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)","c2fe6307":"print('X train shape: {}'.format(X_train.shape))\nprint('y train shape: {}'.format(y_train.shape))\nprint('X test shape: {}'.format(X_test.shape))\nprint('y test shape: {}'.format(y_test.shape))","d680c84a":"train_class_counter = dict(zip(np.nonzero(np.bincount(y_train))[0], np.bincount(y_train)))\nprint(train_class_counter)","24e72000":"test_class_counter = dict(zip(np.nonzero(np.bincount(y_test))[0], np.bincount(y_test)))\nprint(test_class_counter)","1c7e0b9b":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\nX_train = X_train.reshape(-1, 28, 28)\nX_test = X_test.reshape(-1, 28, 28)\n\nprint('X train shape: {}'.format(X_train.shape))\nprint('y train shape: {}'.format(y_train.shape))\nprint('X test shape: {}'.format(X_test.shape))\nprint('y test shape: {}'.format(y_test.shape))","57829820":"def show_digits(X=X_train, y=y_train, n=10, figsize=(20,3)):\n    \n    fig, axes = plt.subplots(1, n, figsize=figsize)\n    for i in range(n):\n        ax = axes[i]\n        ax.imshow(X[i], cmap='gray_r')\n        ax.set_title(str(y[i]), fontsize=12, color='white')\n    plt.tight_layout()\n    plt.show()","d29d82c6":"show_digits(n=13, figsize=(26, 2))","49e55666":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.","28b21d1a":"show_digits(n=13, figsize=(26, 2))","2adae8d1":"from tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","2d100ada":"model = Sequential([\n    Flatten(input_shape=(28, 28)),\n    Dense(units=128, activation='relu'),\n    Dropout(0.2),\n    Dense(units=64, activation='relu'),\n    Dropout(0.15),\n    Dense(units=10, activation='softmax')\n])\n\noptim = Adam(learning_rate=0.0001, epsilon=1e-8)\n\nmodel.compile(optimizer=optim, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","47cd4839":"history = model.fit(X_train, y_train, epochs=200, batch_size=1024)","5f96b642":"model.evaluate(X_test, y_test, verbose=2)","b1bc824b":"metrics = pd.DataFrame(history.history)\nmetrics.head()","0ebe4d4b":"epochs = range(1, 201)\nf, axes = plt.subplots(1, 2, figsize=(16, 8))\nsns.set()\nsns.lineplot(x=epochs, y=metrics.loss, ax=axes[0]).set(title='Training loss', xlabel='Epochs', ylabel='Loss value')\nsns.lineplot(x=epochs, y=metrics.accuracy, ax=axes[1], color='orange').set(title='Training accuracy', xlabel='Epochs', ylabel='Accuracy value')\nplt.show()","96cee2c4":"submission_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nsubmission_data.head()","f65a8a22":"submission_data = np.array(submission_data)\nsubmission_data = submission_data.reshape(-1, 28, 28)\nprint(submission_data[0])","097de071":"submission_data = submission_data \/ 255.\nsubmission_classes = model.predict_classes(submission_data)\nprint(submission_classes[0])","fa27e6f6":"submission_classes.shape","388f6f8e":"sub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nsub.head()","e571c596":"sample_sub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsample_sub.head()","13ab2134":"ids = [i for i in range(1, sub.shape[0] + 1)]\nsubmission = pd.DataFrame({'ImageId': ids, 'Label': submission_classes})\nsubmission.head()","173a53ef":"filename = 'Mnist_submission.csv'\nsubmission.to_csv(filename, index=False)","7912388c":"# *BUILDING A NN MODEL IN TENSORFLOW 2.0 AND KERAS*","28f930f4":"Let's see if class proportions in both training and test sets are more or less equal:","9d920e87":"Seems like all sets have correct shape and size. Now, let's turn our data into NumPy arrays, in order to plot some digits along with labels. ","32f1d9ff":"Let's start with importing some libraries and functions:\n- Numpy: linear algebra and math operations, here used mostly for reshaping data\n- Matplotlib: data visualization\n- Pandas: Data manipulation, reading\/saving data\n- train_test_split from sklearn: splitting dataset training and test subsets","9273da2e":"# *EXPLORATORY DATA ANALYSIS*","27c846f5":"Let's plot our train digits again to see if inputs were normalized correctly.","2af612cb":"Next thing that we should do is normalization of our X-es, both train and test.\nThis operation should make our neural network learn much faster.","04c3f7f9":"Let's plot some digits along with labels from the training set.","73f86b77":"Now, I will split original training dataset to train and test subsets - file 'test.csv' does not contain a 'label' column.\nParameter 'stratify' will be used in orde to make sure that our target variable has the same proportions in both train and test sets.","789de0c1":"Let's see proportions of each class in 'label' column:","48ed6ea3":"Let's import some essential functions from tensorflow.keras:"}}