{"cell_type":{"b935301e":"code","51e1fc69":"code","c9b58590":"code","6da10595":"code","c6390dac":"code","ad4c0e69":"code","aaf2b0cc":"code","8be53462":"code","35a31664":"code","9a554367":"code","a201d154":"code","586a91ac":"code","702baa04":"code","33c96133":"code","8e6f66b7":"code","9253061f":"code","81d5e4f8":"code","a23f2022":"code","95fba75c":"code","b487fbb5":"code","86e865c2":"code","7549cd20":"code","37b7a92b":"code","e5b911a8":"markdown","637c5417":"markdown","9fc31d72":"markdown","4e59bf5b":"markdown","25c9d9e1":"markdown","01745998":"markdown","6a3fb12e":"markdown","6503cdbb":"markdown","6b42baa6":"markdown","b59aaec4":"markdown","6e068ab7":"markdown","c5fe603c":"markdown","779b73b5":"markdown"},"source":{"b935301e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","51e1fc69":"print(tf.__version__)","c9b58590":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","6da10595":"print (train_data.shape)\nprint (test_data.shape)","c6390dac":"# Convert from pandas dataframe to numpy\n# .to_numpy() -- not available in the numpy running in Kaggle, use deprecated .values member.\ntrain_data = train_data.values\ntest_data = test_data.values","ad4c0e69":"# Shuffle the training data before separating lables and images\nnp.random.shuffle(train_data)","aaf2b0cc":"## Separate the labels from the pixels in the training data, and reshape images to 28x28 instead of 784x1\ntrain_labels = train_data[:,0]\ntrain_digits = train_data[:,1:].reshape(-1, 28, 28, 1)\n\n## Convert test digits to numpy, and reshape.  \ntest_digits = test_data.reshape(-1, 28, 28, 1)\n\nprint(train_labels.shape, train_digits.shape, test_digits.shape)\n\n## don't need these any longer.\ndel(train_data)\ndel(test_data)","8be53462":"split = len(train_labels)\/\/11\n\nval_labels, train_labels = train_labels[:split], train_labels[split:]\nval_digits, train_digits = train_digits[:split], train_digits[split:]\n\nprint(val_labels.shape, val_digits.shape, train_labels.shape, train_digits.shape)\nplt.bar(range(10), [ np.sum(val_labels == r) for r in range(10) ])","35a31664":"train_digits = train_digits \/ 255.0\nval_digits = val_digits \/ 255.0\ntest_digits = test_digits \/ 255.0","9a554367":"i = 1\nplt.figure()\nplt.imshow(train_digits[i,:,:,0])\nplt.title('Digit: ' + str(train_labels[i]))\nplt.colorbar()\nplt.grid(False)","a201d154":"X0 = Input(shape = (28,28,1))\n\nX = Conv2D(filters = 32, kernel_size = 3, padding = 'Same', activation ='relu')(X0)\nX = Conv2D(filters = 32, kernel_size = 3, padding = 'Same', activation ='relu')(X)\nX = MaxPooling2D(pool_size = 2, strides = 2)(X)\n\nX = Dropout(0.25)(X)\n\nX = Conv2D(filters = 64, kernel_size = 3, padding = 'Same', activation ='relu')(X)\nX = Conv2D(filters = 64, kernel_size = 3, padding = 'Same', activation ='relu')(X)\nX = MaxPooling2D(pool_size = 2, strides = 2)(X)\n\nX = Dropout(0.25)(X)\n\nX = Flatten()(X)\nX = Dense(512, activation = \"relu\")(X)\nX = Dropout(0.50)(X)\n\nOut = Dense(10, activation = \"softmax\")(X)","586a91ac":"model = Model(inputs=X0, outputs=Out)\nmodel.compile(optimizer = 'adam', \n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n## Establish a checkpoint with the model in its initial state.  We can go back to this \n## state later and train the same model differently to see different results. \ninitial_model_weights = model.get_weights()","702baa04":"model.summary()","33c96133":"history = model.fit(train_digits, train_labels, \n                    epochs=10, \n                    verbose=2,\n                    validation_data=(val_digits,val_labels))","8e6f66b7":"def plot_history(hist) :\n    fig, ax = plt.subplots(nrows=2)\n    fig.set_size_inches(8,8)\n\n    ax[0].plot(hist['acc'][:], marker='.', color='red', linewidth=1, alpha=0.5)\n    if ('val_acc' in hist) :\n        ax[0].plot(hist['val_acc'][:], marker='.', color='blue', linewidth=1, alpha=0.5)\n\n    ax[1].plot(hist['loss'][:], marker='.', color='red', linewidth=1, alpha=0.2)\n    if ('val_loss' in hist) :\n        ax[1].plot(hist['val_loss'][:], marker='.', color='blue', linewidth=1, alpha=0.2)\n    ax[0].set_title('Accuracy')\n    ax[0].set_ylabel('accuracy')\n    ax[1].set_title('Loss')\n    ax[1].set_ylabel('loss')\n    ax[1].set_xlabel('epochs')","9253061f":"plot_history(history.history)","81d5e4f8":"## Save off the results for later analysis. \nmodel.save(\"cnn1.h5\")","a23f2022":"predictions = model.predict(test_digits)\npredictions = np.argmax(predictions,axis = 1)\npredictions = pd.Series(predictions,name = 'Label')\nids = pd.Series(range(1,28001),name = 'ImageId')\npredictions = pd.concat([predictions,ids],axis = 1)\npredictions.to_csv('pred1.csv',index = False)\n\ndel(predictions)\ndel(ids)","95fba75c":"## Return the model to its initial state.\nmodel.set_weights(initial_model_weights)","b487fbb5":"datagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n    # randomly shift images horizontally (fraction of total width)\n    width_shift_range=0.1,\n    # randomly shift images vertically (fraction of total height)\n    height_shift_range=0.1,\n    shear_range=0.1,  # set range for random shear\n    zoom_range=0.1,  # set range for random zoom\n    channel_shift_range=0.,  # set range for random channel shifts\n    # set mode for filling points outside the input boundaries\n    fill_mode='nearest',\n    cval=0.,  # value used for fill_mode = \"constant\"\n    horizontal_flip=False,  # randomly flip images\n    vertical_flip=False,  # randomly flip images\n    # set rescaling factor (applied before any other transformation)\n    rescale=None,\n    # set function that will be applied on each input\n    preprocessing_function=None,\n    # image data format, either \"channels_first\" or \"channels_last\"\n    data_format=None,\n    # fraction of images reserved for validation (strictly between 0 and 1)\n    validation_split=0.0)\n\n# Compute quantities required for feature-wise normalization\n# (std, mean, and principal components if ZCA whitening is applied).\ndatagen.fit(train_digits)","86e865c2":"# Fit the model on the batches generated by datagen.flow().\nbatch_size = 64\ngen_history = model.fit_generator(datagen.flow(train_digits, train_labels, batch_size=batch_size),\n                    epochs=10,\n                    verbose=2,\n                    steps_per_epoch=train_digits.shape[0]\/batch_size,\n                    validation_data=(val_digits,val_labels))\nplot_history(gen_history.history)","7549cd20":"predictions = model.predict(val_digits)\npredictions = np.argmax(predictions,axis = 1)\nc = tf.confusion_matrix(labels=val_labels, predictions=predictions, num_classes=10)\nsess = tf.Session()\nr = sess.run(c)\ndel(c)\ndel(sess)\nprint(r)\n\nplt.figure(figsize = (10,8))\nsns.heatmap(r, annot=True, label='small')","37b7a92b":"predictions = model.predict(test_digits)\npredictions = np.argmax(predictions,axis = 1)\npredictions = pd.Series(predictions,name = 'Label')\nids = pd.Series(range(1,28001),name = 'ImageId')\npredictions = pd.concat([predictions,ids],axis = 1)\npredictions.to_csv('pred2.csv',index = False)\ndel(predictions)\ndel(ids)\n\n## Save off the results for later analysis. \nmodel.save(\"cnn2.h5\")","e5b911a8":"An experiment with TensorFlow Keras API \n\nI draw from the original work [here](https:\/\/keras.io\/examples\/cifar10_cnn\/), but sligtly modified for digit recognition.","637c5417":"The data are pandas dataframes.  First separate out the labels from the training data.  For the images, pandas dataframe is a 2D table with columns labeled 'pixel0' to pixel783'.  The original images are 28x28x1.  Convert the image data frame back to the original 28x28.","9fc31d72":"Well, that's enough to get familiar with the Kaggle environment.  No need to beat this digit example to death.  Thanks for reading. ","4e59bf5b":"Hmm, not noticeably better than the model trained without data augmentation.\n\nOne more bit of analysis before wrapping up: Print out the confusion matrix to look at what the model is mispredicting.  ","25c9d9e1":"How else to proceed?\n\nAs the Keras reference manual shows, it's possible to improve performance with a real-time data generator.","01745998":"Looks good.\n\nNormalize the data to be in the range [0,1], the range of sigmoid and ReLU activation functions.","6a3fb12e":"Fit the model for a few epochs, and print the validation performance after each epoch. ","6503cdbb":"Slice off a small amount of training data for validation.  Since the whole of the training data is a uniform distrubution, and that data was randomly shuffled above, the slice taken off should be a uniform distribution.  We'll check it anyway, just to be sure.","6b42baa6":"More epochs won't help that.  It's starting to overtrain as seen in that the validation loss is meandering while the training loss is plateauing.  Three to five epochs was enough. ","b59aaec4":"I'll choose Adam optimizer because it has the benefit of RMSProp, but also momentum.  \n\nIn many kernels here on Kaggle, the Y's (labels) are converted to one-hot form.  This kernel leaves the labels in scalar format and uses the loss function **sparse_**catagorical_crossentropy.  ","6e068ab7":"Surprisingly good, reaching over 99% from the first epoch when I first ran it in the notebook.  But it seems unrealistic, and not likely reproducible.  Re-running from the beginning produces less impressive results, but still training and validation over 99% accuracy by the 10th epoch.  \n\nIs it still converging? Would more epochs help?","c5fe603c":"The data is ready.  Let's build a model.  As noted earlier, this is the model in the Keras documentation applied to the CIFAR-10 small image set.  ","779b73b5":"We can look at the training data like so:"}}