{"cell_type":{"5f4d9c5c":"code","c5070c7f":"code","b99009af":"code","1f32d527":"code","fd537435":"code","8226c5c0":"code","443dc708":"code","f471dd19":"code","f863e5c9":"code","2ac4f300":"code","6497f78d":"code","33f53139":"code","3f3104af":"code","8e56bdc1":"code","4d84b4b2":"code","55003637":"code","bad17204":"code","3fcc7fcd":"code","b6a9ffc3":"code","4553a29a":"code","4ff2eed9":"code","84185d73":"code","179ace63":"code","75f11f40":"code","c0f827d3":"code","9153ec40":"code","fe8fb21e":"code","a53ba4d0":"code","0eb378b6":"code","8c27fd26":"code","1a587ad4":"markdown","277b3c3e":"markdown","c5cc5ed1":"markdown","f7cf65b0":"markdown","143fcc21":"markdown","46be5a35":"markdown","1d0e8ecf":"markdown","b0de52f8":"markdown","36581724":"markdown"},"source":{"5f4d9c5c":"import numpy as np \nimport pandas as pd\nfrom copy import deepcopy\nfrom sklearn.metrics import mean_absolute_error\n%matplotlib inline \nrandom_state=0","c5070c7f":"# The data is provided by the Johns Hopkins University\n# https:\/\/github.com\/CSSEGISandData\/COVID-19\ndf = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')","b99009af":"df.head()","1f32d527":"# only work with a limited amount of data\ndf = df[df.columns[:82]]","fd537435":"# rawData contains the values of confirmed cases in the world\nfirstDateIndex = df.columns.get_loc(\"1\/22\/20\")\nrawData = [0 for i in range(firstDateIndex, df.shape[1])]\nfor i in range(df.shape[1] - firstDateIndex):\n    rawData[i] = sum(df.iloc[:, i+firstDateIndex])","8226c5c0":"import matplotlib.pyplot as plt \nplt.figure(figsize=(10, 5))\nplt.title('Number of confirmed Coronavirus cases in the world', size=20)\nplt.plot(range(len(rawData)), rawData)\nplt.show()","443dc708":"import matplotlib.pyplot as plt \nplt.figure(figsize=(10, 5))\nplt.title('Number of confirmed Coronavirus cases in the world', size=20)\nplt.plot(range(len(rawData[50:])), rawData[50:])\nplt.show()","f471dd19":"originalData = deepcopy(rawData)\nrawData = rawData[50:]","f863e5c9":"numberOfDaysToForcast = 5","2ac4f300":"import datetime\nnumberOfAvailableDays = len(rawData)\nnumberOfDays = numberOfAvailableDays + numberOfDaysToForcast\nday1 = datetime.datetime.strptime('1\/22\/2020', '%m\/%d\/%Y')\nday50 = day1 + datetime.timedelta(days=50)\navailableDateRange = [day50 + datetime.timedelta(days=x) for x in range(numberOfAvailableDays)]\nfutureDateRange = [availableDateRange[-1]  + datetime.timedelta(days=x) for x in range(1, numberOfDaysToForcast + 1)]\nfullAvailableDateRange = [day1 + datetime.timedelta(days=x) for x in range(len(originalData))]\nprint('Dates to be predicted:')\nfutureDateRange","6497f78d":"# This is how I form my dataset from the rawData variable\n\n# rawData = [1 2 3 4 5]:\n# x=[1 2] y=3\n# x=[2 3] y=4\n# x=[3 4] y=5\n# number of training data = 5 - 2\n\n# rawData = [1 2 3 4 5 6]:\n# x=[1 2] y=3\n# x=[2 3] y=4\n# x=[3 4] y=5\n# x=[4 5] y=6\n# number of training data = 6 - 2","33f53139":"numberOfPreviousData = 7","3f3104af":"testFraction = 0.3\nnumberOfTrainingTestRecords = len(rawData) - numberOfPreviousData\nnumberOfUsableData = numberOfTrainingTestRecords - numberOfPreviousData + 2\nnumberOfTestData = int(np.ceil(testFraction * numberOfUsableData))","8e56bdc1":"# Select a good machine learning algorithm for this dataset By picking the one that fits the data well and has the lowest error","4d84b4b2":"y_actual = np.array(rawData[-numberOfTestData:])\ny_predicted = np.array(rawData[-numberOfTestData-1:-1])\nerrors = np.abs(y_actual - y_predicted) \/ np.array(y_predicted)\nbaselineError = errors.mean()\nprint('MAE error: ', baselineError)","55003637":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor","bad17204":"def findBestParameters(model, train_X, train_y):\n    modelName = model.__class__.__name__\n    parameters = {}\n    if modelName == 'SVR':\n        parameters = {\n            'C':[1000, 100, 10, 1],\n            'epsilon': [0.1, 0.01, 0.05, 0.001],\n            'gamma': ['scale', 'auto']}\n        \n    elif modelName == 'RandomForestRegressor':\n        parameters = {\n            'n_estimators': [10, 50, 100, 150, 200, 400, 600]}\n        \n    elif modelName == 'MLPRegressor':\n        parameters = {\n            'hidden_layer_sizes': [(5), (10), (20), \n                        (5, 5), (10, 10), (20, 20), (30, 30),\n                        (5, 5, 5), (10, 10, 10), (20, 20, 20)],\n            'max_iter': [100, 500, 1000, 2000]}\n    \n    clf = GridSearchCV(model, param_grid=parameters, cv=5)\n    clf.fit(train_X, train_y)\n    #print('Best parameters for', modelName, '\\n', clf.best_params_)\n    \n    if modelName == 'SVR':\n        return SVR(C=clf.best_params_['C'], epsilon=clf.best_params_['epsilon'], gamma=clf.best_params_['gamma'])\n    elif modelName == 'RandomForestRegressor':\n        return RandomForestRegressor(n_estimators=clf.best_params_['n_estimators'])\n    elif modelName == 'MLPRegressor':\n        return MLPRegressor(hidden_layer_sizes=clf.best_params_['hidden_layer_sizes'], max_iter= clf.best_params_['max_iter'])\n    return np.nan","3fcc7fcd":"# Build the dataset for training and testing\nX = np.zeros((numberOfTrainingTestRecords, numberOfPreviousData))\ny = np.zeros(numberOfTrainingTestRecords)\nfor i in range(numberOfTrainingTestRecords):\n    for j in range(numberOfPreviousData):\n        X[i, j] = deepcopy(rawData[i + j])\n    y[i] = deepcopy(rawData[i + numberOfPreviousData])","b6a9ffc3":"# Split the dataset into train and test\nX_train = X[0: -numberOfTestData, :]\ny_train = y[0: -numberOfTestData]\nX_test = X[-numberOfTestData:, :]\ny_test = y[-numberOfTestData:]","4553a29a":"# Normalize\nmaxValue = max(rawData)\nX_train = X_train \/maxValue\ny_train = y_train \/maxValue\nX_test = X_test \/maxValue\ny_test = y_test \/maxValue","4ff2eed9":"def recursiveForcast(model):\n    errors = np.zeros(numberOfDaysToForcast)\n    dataUsedToForcast = np.concatenate([y_train[-numberOfPreviousData:], y_test]).copy()\n    for f in range(len(y_test) - numberOfDaysToForcast + 1):\n        movingX = deepcopy(dataUsedToForcast[f: f + numberOfPreviousData])\n        for i in range(numberOfDaysToForcast):\n            newForcast = model.predict(movingX.reshape(1, -1))\n            observedValue = dataUsedToForcast[f + numberOfPreviousData + i]\n            # define the error to be the fraction of observed value\n            currentError = np.abs(newForcast - observedValue)\n            errors[i] = errors[i] + currentError\/newForcast\n            for j in range(movingX.shape[0] - 1): # Shift\n                movingX[j] = movingX[j+1]\n            movingX[-1] = newForcast\n    recursiveMethodError = errors \/ (len(y_test) - numberOfDaysToForcast + 1)\n    print('MAE error for', model.__class__.__name__, recursiveMethodError)\n    return recursiveMethodError","84185d73":"allModels = [SVR(), MLPRegressor(), RandomForestRegressor()]\nrecursiveError = []\nfor m in allModels:\n    m = findBestParameters(m, X_train, y_train)\n    m.fit(X_train, y_train)\n    recursiveMethodError = recursiveForcast(m)\n    if m.__class__.__name__ == 'SVR':\n        recursiveError = recursiveMethodError","179ace63":"# train the SVM model on all available data and then make predictions for the upcoming days","75f11f40":"# Build the dataset for training and testing\nX = np.zeros((numberOfTrainingTestRecords, numberOfPreviousData))\ny = np.zeros(numberOfTrainingTestRecords)\nfor i in range(numberOfTrainingTestRecords):\n    for j in range(numberOfPreviousData):\n        X[i, j] = deepcopy(rawData[i + j])\n    y[i] = deepcopy(rawData[i + numberOfPreviousData])","c0f827d3":"# Split the dataset into train and test\nX_train = X.copy()\ny_train = y.copy()\nX_test = deepcopy(np.array(rawData[-numberOfPreviousData:]))","9153ec40":"# Normalize\nmaxValue = max(rawData)\nX_train = X_train \/maxValue\ny_train = y_train \/maxValue\nX_test = X_test \/maxValue","fe8fb21e":"def recursiveForcast(model):\n    movingX = deepcopy(X_test)\n    predictions = np.zeros(numberOfDaysToForcast)\n    for i in range(numberOfDaysToForcast):\n        newForcast = model.predict(movingX.reshape(1, -1))\n        for j in range(movingX.shape[0] - 1): # Shift\n            movingX[j] = movingX[j+1]\n        movingX[-1] = newForcast\n        predictions[i] = newForcast\n    predictions = predictions * maxValue\n    predictions = [int(np.round(x)) for x in predictions]\n    print('Predictions:', predictions)\n    return predictions","a53ba4d0":"model = SVR()\nmodel = findBestParameters(model, X_train, y_train)\nmodel.fit(X_train, y_train)\nrecursivePredictions = recursiveForcast(model)","0eb378b6":"plt.figure(figsize=(20, 10))\nplt.rcParams['xtick.labelsize'] = 20 \nplt.rcParams['ytick.labelsize'] = 20 \nplt.plot(fullAvailableDateRange, originalData)\nplt.plot(futureDateRange, recursivePredictions, linestyle='dashed', color='red')\nlowerBound = recursivePredictions - recursiveError * recursivePredictions\nupperBound = recursivePredictions + recursiveError * recursivePredictions\nplt.fill_between(futureDateRange, lowerBound, upperBound, color='b', alpha=.1)\nplt.legend(['Real values', 'Predictions'], prop={'size': 20}, loc=2)\nplt.xticks( rotation=90)\nx1,x2,y1,y2 = plt.axis()\nplt.axis((x1,x2,y1,maxValue*2))\nplt.show()","8c27fd26":"print('Number of confirmed cases:')\nfor i, day in enumerate(futureDateRange):\n    print(day.date(), ':', recursivePredictions[i], 'error:', int(round(recursiveError[i]*maxValue)))","1a587ad4":"### Build the datasets needed to do the recursive multi-step predictions and then train the models with them","277b3c3e":"## Baseline: Persistance model","c5cc5ed1":"# Select Model","f7cf65b0":"## SVM, MLP, RF","143fcc21":"### The data can be split in 2 parts: \n1. The linear part made of the first 50 elements \n2. The rest of the data which is non-linear","46be5a35":"## Machine Learning models","1d0e8ecf":"# Prepare the Dataset","b0de52f8":"# Get the data","36581724":"# Forcast using all available data "}}