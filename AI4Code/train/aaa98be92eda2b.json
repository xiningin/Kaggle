{"cell_type":{"ca32bf74":"code","718292e8":"code","67e75fcb":"code","9e799521":"code","3f852a35":"code","dc32668e":"code","a3763eee":"code","543f55a4":"code","62b0825c":"code","ab5380b9":"code","2dbe914e":"code","4a55c01c":"code","542acc53":"code","30b458f0":"code","b8149992":"code","33200b0c":"markdown","23676305":"markdown","aad1994b":"markdown"},"source":{"ca32bf74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","718292e8":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\n\ntrain = pd.read_csv('..\/input\/train.csv', parse_dates=['Dates'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['Dates'], index_col='Id')","67e75fcb":"## \ud2b8\ub808\uc778\uc14b \ub370\uc774\ud130\uc14b \ubd88\ub7ec\uc624\uae30","9e799521":"train.head()","3f852a35":"test.head()","dc32668e":"train.info()","a3763eee":"test.info()","543f55a4":"train.isnull().sum()","62b0825c":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\npd.options.display.max_columns=100\ntrain = pd.read_csv('..\/input\/train.csv', parse_dates=['Dates'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['Dates'], index_col='Id')\n\ndef feature_engineering(data):\n    data['Date'] = pd.to_datetime(data['Dates'].dt.date)\n    data['n_days'] = (data['Date'] - data['Date'].min()).apply(lambda x: x.days)\n    data['Day'] = data['Dates'].dt.day\n    data['DayOfWeek'] = data['Dates'].dt.weekday\n    data['Month'] = data['Dates'].dt.month\n    data['Year'] = data['Dates'].dt.year\n    data['Hour'] = data['Dates'].dt.hour\n    data['Minute'] = data['Dates'].dt.minute\n    data['Block'] = data['Address'].str.contains('block', case=False).apply(lambda x: 1 if x == True else 0)\n    data[\"X_Y\"] = data[\"X\"] - data[\"Y\"]\n    data[\"XY\"] = data[\"X\"] + data[\"Y\"]\n    data.drop(columns=['Dates','Date','Address'], inplace=True)\n    return data\ntrain = feature_engineering(train)\ntest = feature_engineering(test)\ntrain.drop(columns=['Descript','Resolution'], inplace=True)","ab5380b9":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\npd.options.display.max_columns=100\ntrain = pd.read_csv('..\/input\/train.csv', parse_dates=['Dates'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['Dates'], index_col='Id')\n\ndef feature_engineering(data):\n    data['Date'] = pd.to_datetime(data['Dates'].dt.date)\n    data['n_days'] = (data['Date'] - data['Date'].min()).apply(lambda x: x.days)\n    data['Day'] = data['Dates'].dt.day\n    data['DayOfWeek'] = data['Dates'].dt.weekday\n    data['Month'] = data['Dates'].dt.month\n    data['Year'] = data['Dates'].dt.year\n    data['Hour'] = data['Dates'].dt.hour\n    data['Minute'] = data['Dates'].dt.minute\n    data['Block'] = data['Address'].str.contains('block', case=False).apply(lambda x: 1 if x == True else 0)\n    data[\"X_Y\"] = data[\"X\"] - data[\"Y\"]\n    data[\"XY\"] = data[\"X\"] + data[\"Y\"]\n    data.drop(columns=['Dates','Date','Address'], inplace=True)\n    return data\ntrain = feature_engineering(train)\ntest = feature_engineering(test)\ntrain.drop(columns=['Descript','Resolution'], inplace=True)","2dbe914e":"train.head()","4a55c01c":"le1 = LabelEncoder()\ntrain['PdDistrict'] = le1.fit_transform(train['PdDistrict'])\ntest['PdDistrict'] = le1.transform(test['PdDistrict'])\n\nle2 = LabelEncoder()\nX = train.drop(columns=['Category'])\ny= le2.fit_transform(train['Category'])","542acc53":"train.head()","30b458f0":"X.head()","b8149992":"train_data = lgb.Dataset(X, label=y, categorical_feature=['PdDistrict', ])\nparams = {'boosting':'gbdt',\n          'objective':'multiclass',\n          'num_class':39,\n          'max_delta_step':0.9,\n          'min_data_in_leaf': 21,\n          'learning_rate': 0.4,\n          'max_bin': 465,\n          'num_leaves': 41,\n          'verbose' : 1}\n\nbst = lgb.train(params, train_data, 120)\npredictions = bst.predict(test)\n\nsubmission = pd.DataFrame(predictions, columns=le2.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), index=test.index)\nsubmission.to_csv('LGBM_final.csv', index_label='Id')","33200b0c":"\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc0c1\uc704 5\uac1c \ucd9c\ub825****","23676305":"**\ud2b8\ub808\uc778\ub370\uc774\ud130 \uc0c1\uc704 5\uac1c \ucd9c\ub825**","aad1994b":"\uacb0\uce21\uce58 \uc788\ub294\uc9c0 \ud655\uc778\n"}}