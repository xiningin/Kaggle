{"cell_type":{"86733488":"code","c6dbc326":"code","30cd643e":"code","7eb6baf2":"code","7aab0716":"code","a252bc58":"code","9af3cd48":"code","b8b981c7":"code","e25d7be7":"code","aaf0be4b":"code","d157809b":"code","a0ec9046":"code","5322f684":"code","1088d773":"code","9dd6df6f":"code","28c1e1cf":"code","da6a91d1":"code","0dc7ede5":"code","c5a229ca":"code","f18948c5":"code","2e077651":"code","627a4a92":"code","3a979f0e":"code","ca31455d":"code","15902a5e":"code","a05bb511":"code","2887b73c":"code","117f8abc":"code","a96f8c91":"code","fd9a39d2":"code","15578222":"code","a8f07b7a":"code","927613a3":"code","38f556f6":"code","59e05786":"code","eb687c0b":"code","23d750bb":"code","59d5bb15":"code","867f1469":"code","dfcc292b":"code","1b9f930e":"code","2f5d2bb4":"code","9961688c":"code","aa3a3469":"code","a3035ac4":"code","ffb20bd3":"code","3e65bf8d":"code","430858f9":"code","b30ad9eb":"code","84e05ec7":"code","f0d92e65":"code","80ce59ac":"code","d6e9c248":"code","c5d617cd":"code","8170bc88":"code","2ff3f8f4":"code","5553c451":"code","0604cd46":"code","c229884b":"code","c3843418":"code","59a008ad":"code","80e78fa3":"code","b318b46f":"code","8c6aaf08":"code","e413e58d":"code","0ba0a6ad":"code","a53413c8":"code","1ea48528":"code","457e7215":"code","2d33f588":"code","dd95c745":"code","218490bc":"code","8b4b57ba":"code","48fc5cca":"code","9fdcb12e":"code","278c2f13":"code","347673ba":"code","93db0b05":"code","80742d95":"code","452a95fa":"markdown","9be69ab4":"markdown","1e43e1f1":"markdown","4126a6fa":"markdown","0ad869da":"markdown","b02e69eb":"markdown","e649826d":"markdown"},"source":{"86733488":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c6dbc326":"# importing necessary libraries, required for analysis\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport math","30cd643e":"# Importing data file - CSV\n\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\n#combine = [train_df, test_df]","7eb6baf2":"gender_submission.head()","7aab0716":"test_df.head()","a252bc58":"train_df.head()","9af3cd48":"#Since we have 2 different dataset Train and Test, hence both set needs to be checked seperately \n#Check info to know the missing values and data type in both dataset\n\ntrain_df.info() ,test_df.info()\n\n#Age & cabin in both dataset, has some missing values\n#Embarked in train dataset also some missing values\n#Fare in test dataset has some missing values","b8b981c7":"#checking shape - 'In train dataset 'Survived' is an additional'\ntrain_df.shape, test_df.shape","e25d7be7":"train_df.groupby('Survived').count()#['Cabin']#.corr()","aaf0be4b":"# Since the number of people surviving were less than otherwise. While survival rate of female was higher than male. Dataset is imbalanced.\nplt.figure(figsize=(12,4))\nsns.countplot(x='Survived',  data = train_df, hue='Sex')","d157809b":"#pre-analysis checking  correlation of Survived features with other features\ntrain_df.corr()['Survived']","a0ec9046":"print(\"Total Null values in Cabin: \", train_df['Cabin'].isnull().sum(), \". Length of datframe: \", len(train_df), \". Non - Null Values : \", len(train_df) -  train_df['Cabin'].isnull().sum(), \n      \". Null %: \", train_df['Cabin'].isnull().sum()\/len(train_df))","5322f684":"#Verifying Pclass and Cabin details\ntrain_df.groupby('Pclass').count()['Cabin']","1088d773":"# Since the number of people surviving were less than otherwise. While survival rate of female was higher than male. Dataset is imbalanced.\nplt.figure(figsize=(12,4))\nsns.countplot(x='Survived',  data = train_df, hue='Pclass')","9dd6df6f":"#pre-analysis checking  correlation of Pclass features with other features\ntrain_df.corr()['Pclass']","28c1e1cf":"#Understanding Cabin columns\nset(train_df['Cabin'])\n\n# Many Uniquie values and Cabin is more of a bnary (Yes \/ No) than the cabin number ","da6a91d1":"def check(val):\n    if(pd.isnull(val)):\n        return 0\n    else:\n        return 1","0dc7ede5":"# Change Cabin to binary (0 or 1)\ntrain_df['Cabin'] = train_df['Cabin'].apply(check)\ntest_df['Cabin'] = test_df['Cabin'].apply(check)","c5a229ca":"#Post EDA, Checking - Survived columns correlation with other columns \ntrain_df.corr()['Survived']\n\n# WIth following details - EDA has resulted in identifying some positive correlated columns ","f18948c5":"train_df.groupby('Survived').count()#['Cabin']#.corr()","2e077651":"# Passenger with cabin, had a higher chance of survival\nplt.figure(figsize=(12,4))\nsns.countplot(x='Survived',  data = train_df, hue='Cabin')","627a4a92":"# Understanding survival based on price and Class \ntrain_df.groupby(['Pclass', 'Survived']).mean()['Fare']\n\nplt.figure(figsize=(12,4))\nsns.boxenplot(x='Pclass', y='Fare', data=train_df, hue='Survived')","3a979f0e":"# Extract Title from name \ncombine = [train_df, test_df] # combining train and test dataset\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","ca31455d":"# more than 15 title  and majority of the title are in single digit\ntrain_df['Title'].value_counts()","15902a5e":"# Understand % split\ntrain_df['Title'].value_counts() \/ len(train_df)","a05bb511":"# Convert the titile to category columns - 0 for Mr, 1 for Miss, 2 for Mrs and 3 for rest all\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \n                 \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3, \"Ms\": 3, \n                 \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","2887b73c":"# Recheck how, EDA is contributing to overall cleaning process\ntrain_df.corr()['Pclass']#,'Cabin']","117f8abc":"train_df['Title'].value_counts()","a96f8c91":"#Check the dataframe\ntrain_df.head()","fd9a39d2":"# Passenger ID and Name is not contibuting whereas all passenger will have a ticket. passenger Class and cabin details is already present, hence this columns will be dropped \ntrain_df = train_df.drop(['Name', 'PassengerId', 'Ticket'], axis=1)\ntest_df = test_df.drop(['Name', 'Ticket'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","15578222":"#Convert 'Sex' to categorical column 1 for Female and 0 for Male\n\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","a8f07b7a":"train_df['Age'].isnull().sum()","927613a3":"# Age of few person is missing in dataframe, we can either delete the rows or imput via median \/ mean\ntrain_df.groupby(['Survived','Pclass']).mean()['Age'], train_df.groupby(['Survived','Pclass']).median()['Age']","38f556f6":"train_df.groupby(['Survived','Pclass','Sex']).mean()['Age'], train_df.groupby(['Survived','Pclass','Sex']).median()['Age']","59e05786":"# fill missing age with Mean passenger age based on Sex, PClass and survived\nstr_Survived = train_df['Survived'].unique()\nstr_Pclass = train_df['Pclass'].unique()\nstr_Sex = train_df['Sex'].unique()\n\ndef fillage(val):\n    if(pd.isnull(val)):\n        for val_Survived in str_Survived:\n            for val_Pclass in str_Pclass:\n                for val_Sex in str_Sex:\n                    avg_Age = np.round(train_df[(train_df['Survived']==val_Survived) & (train_df['Pclass']==val_Pclass) & (train_df['Sex']==val_Sex)]['Age'].mean())\n    else:\n        avg_Age = val\n    return avg_Age;","eb687c0b":"train_df['Age'] = train_df['Age'].apply(fillage)\ntest_df['Age'] = test_df['Age'].apply(fillage)\n\ncombine = [train_df, test_df]","23d750bb":"train_df.head()","59d5bb15":"# Check Null Values\ntrain_df.isnull().sum(), test_df.isnull().sum()","867f1469":"# Embarked has some missing values and is still a non - numeric columnn. Missing values needs to be either filled with value or dropped\ntrain_df.groupby(\"Embarked\").count()","dfcc292b":"# know values of other column for knowing the Embarked column based on features of other columns\ntrain_df[train_df[\"Embarked\"].isnull()]","1b9f930e":"# Unique columns looks to be Survived=1, Pclass=1, Sex=1 and Cabin=1\ntrain_df[(train_df['Survived']==1) & (train_df['Pclass']==1) & (train_df['Sex']==1) & \n         (train_df['Cabin']==1)].groupby(['Embarked']).mean()['Fare']","2f5d2bb4":"train_df[(train_df['Survived']==1) & (train_df['Pclass']==1) & \n         (train_df['Cabin']==1)].groupby('Embarked')['Fare'].describe().T ","9961688c":"def fixEmbarked(val):\n    if(pd.isnull(val)):\n        return 'S'\n    else:\n        return val","aa3a3469":"# Missing value of Embarked to be filled with 'S'\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].apply(fixEmbarked)\ntest_df[\"Embarked\"] = test_df[\"Embarked\"].apply(fixEmbarked)\n\n# Family Size column is included\ntrain_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntest_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n\n# SibSp, Parch columns is dropped\ntrain_df.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ntest_df.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n","a3035ac4":"# Converting Embarked column to Categorical - numberic\nEmbarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n    \ntrain_df['Embarked'] = train_df['Embarked'].map(Embarked_mapping)\ntest_df['Embarked'] = test_df['Embarked'].map(Embarked_mapping)","ffb20bd3":"train_df.head()","3e65bf8d":"# For understanding, how it is grouped\nmin_age_limit = np.int(np.floor(np.min(train_df['Age'])\/16)*16)\nmax_age_limit = np.int(np.ceil(np.max(train_df['Age'])\/16)*16)\n\npd.cut(train_df['Age'],\n               (range(min_age_limit,max_age_limit + 16, 16)),\n               right=True).value_counts()\/len(train_df)\n","430858f9":"min_age_limit = np.int(np.floor(np.min(train_df['Age'])\/16)*16)\nmax_age_limit = np.int(np.ceil(np.max(train_df['Age'])\/16)*16)\n\ntrain_df['agerange'] = pd.cut(train_df['Age'],\n               (range(min_age_limit,max_age_limit + 16, 16)),\n               right=True)\n\n\ntrain_df['agerange'] = train_df['agerange'].astype('str')\n\nagerange_df = pd.get_dummies(train_df['agerange'])\ntrain_df = pd.concat([train_df, agerange_df],axis=1)\n\n\ntrain_df.drop(['Age','agerange'], axis=1, inplace=True)\ntrain_df.head()\n#agerange_df","b30ad9eb":"test_df['agerange'] = pd.cut(test_df['Age'],\n               (range(min_age_limit,max_age_limit + 16, 16)),\n               right=True)\n\ntest_df['agerange'] = test_df['agerange'].astype('str')\n\nagerange_df = pd.get_dummies(test_df['agerange'])\n\ntest_df = pd.concat([test_df, agerange_df],axis=1)\n\ntest_df.drop(['Age','agerange'], axis=1, inplace=True)\ntest_df.head()","84e05ec7":"train_df.head()","f0d92e65":"test_df.head()","80ce59ac":"# One row in Test Dataset still has missing values, this needs to be either imputed or deleted before modeling\ntest_df[(test_df['Fare'].isnull()==True)]#.apply()","d6e9c248":"test_df[(test_df['Pclass'] == 3) & (test_df['Cabin'] == 0) & \n        (test_df['Embarked'] == 0) & (test_df['FamilySize'] == 1)]['Fare'].mean()","c5d617cd":"# Update the missing value fare with mean of other columns feature\ndef fixFare(val):\n    if(pd.isnull(val)):\n        return test_df[(test_df['Pclass'] == 3) & (test_df['Cabin'] == 0) & \n                    (test_df['Embarked'] == 0) & (test_df['FamilySize'] == 1)]['Fare'].mean()\n    else:\n        return val","8170bc88":"test_df['Fare'] = test_df['Fare'].apply(fixFare)","2ff3f8f4":"train_df.isnull().sum(), '-------', test_df.isnull().sum()","5553c451":"train_df.corr()['Survived']","0604cd46":"sns.pairplot(train_df)","c229884b":"plt.figure(figsize=(24,8))\nsns.heatmap(train_df.corr(), annot = True)","c3843418":"# Importing Classifier Modules\nimport xgboost as xgb\nfrom sklearn import preprocessing\n#from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom imblearn.over_sampling import SMOTE # Oversampling\n\nfrom sklearn.metrics import accuracy_score, f1_score, fbeta_score, make_scorer\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","59a008ad":"'''X = train_df.drop(['Survived'], axis=1)\ny = train_df['Survived']'''","80e78fa3":"train_df.columns, test_df.columns","b318b46f":"# Survived is predicting variable and PassengerID column needs to be dropped\n\nX_train = train_df.drop('Survived', axis=1)\ny_train = train_df['Survived']\n\nX_test = test_df.drop(['PassengerId'], axis=1)\n#y_test = test_df['Survived']\n\nrandom_state= 101\n\nX_train.shape, y_train.shape, X_test.shape\n","8c6aaf08":"#---------------------------------------------------\nX_train.columns","e413e58d":"# Since dataset is inbalanced, we need to apply SMOTE - it will include new dummy rows for analysis. This needs to be done only on train dataset \nrandom_state = random_state\nfeatures = X_train.columns\nsm = SMOTE(random_state=random_state)#, ratio=1.0)\nX_train, y_train = sm.fit_resample(X_train, y_train)\nX_train = pd.DataFrame(X_train, columns=features)","0ba0a6ad":"# Appling MinMaxScaler (fit and transform) on train data and only transform on test data to avoid data leakages \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","a53413c8":"# baselining  \nnaive_predictor_accuracy = accuracy_score(y_train,np.ones(len(y_train)))\nnaive_predictor_f1score = f1_score(y_train, np.ones(len(y_train)))\n\nprint(\"Naive predictor accuracy: %.3f\" % (naive_predictor_accuracy))\nprint(\"Naive predictor f1-score: %.3f\" % (naive_predictor_f1score))","1ea48528":"k_fold = KFold(n_splits=10, shuffle=True, random_state=random_state)","457e7215":"# KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","2d33f588":"# kNN Score\nround(np.mean(score)*100, 2)","dd95c745":"# DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","218490bc":"# decision tree Score\nround(np.mean(score)*100, 2)","8b4b57ba":"# RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","48fc5cca":"# Random Forest Score\nround(np.mean(score)*100, 2)","9fdcb12e":"# GaussianNB\nclf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","278c2f13":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","347673ba":"# SVC\nclf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","93db0b05":"round(np.mean(score)*100,2)","80742d95":"# Working model\n\ngbm = xgb.XGBClassifier(max_depth=3, n_estimators=400, learning_rate=0.05).fit(X_train, y_train)\npredictions = gbm.predict(X_test)\n\n# Kaggle needs the submission to have a certain format;\n# see https:\/\/www.kaggle.com\/c\/titanic-gettingStarted\/download\/gendermodel.csv\n# for an example of what it's supposed to look like.\nsubmission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n                            'Survived': predictions })\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission = pd.read_csv('submission.csv')\nsubmission['Survived'].value_counts()","452a95fa":"familirise with data","9be69ab4":"Embarked columns can be filled with 'S', - Mean of Fare of missing value and Embarked ='S' is very close.","1e43e1f1":"# End","4126a6fa":"## The competition solution is divided following steps: \n\n- Understanding problem statement\n- Importing, exploring, wrangling, cleansing and preparing the data for analysis \n- Analyze and identify patterns\n- create models and predict \n- Visualize, and  submit the results.\n","0ad869da":"Now all columns is numric\n- Categorical\n * Survived, Pclass, Sex, Age, Cabin, Embarked, Title, FamilySize\n- Continous\n * Fare\n\nIt's worth consolidating Age based on group and apply One-hot Encoding, last phase of EDA ","b02e69eb":"# Final model for submission","e649826d":"Final Check before applying ML"}}