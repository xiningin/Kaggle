{"cell_type":{"5bd2459e":"code","61c95dce":"code","037fbd2d":"code","a05e2437":"code","62e7d505":"code","c6be0a56":"code","bac280fc":"code","731c8d21":"code","a0f2243f":"code","16a74310":"code","c8c2fefb":"code","d231867d":"code","61ab0a0e":"code","420958bb":"code","2d5c30d5":"code","c7788c84":"code","1bdbd6b9":"code","672784e8":"code","38bd1aa9":"code","55b2f1f3":"code","a8859a9a":"code","38231911":"code","f85a660c":"code","53d82954":"code","7b16dcd5":"code","1c3898c8":"code","a874a4f9":"code","ce685200":"code","cb453bad":"code","44f2d8ff":"code","c2a000dd":"code","d62576ff":"code","c279363e":"code","604cc451":"code","c3a8e578":"code","b63f285e":"code","e72588d1":"markdown","55f9970d":"markdown","3b70db4b":"markdown","9509473f":"markdown","ff1033e6":"markdown","c3b70a07":"markdown","accd1cbb":"markdown"},"source":{"5bd2459e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61c95dce":"# Birinci yol:\ndef create_user_movie_df():\n    import pandas as pd\n    movie = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/movie.csv')\n    rating = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/rating.csv')\n    df = movie.merge(rating, how=\"left\", on=\"movieId\")\n    comment_counts = pd.DataFrame(df[\"title\"].value_counts())\n    rare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n    common_movies = df[~df[\"title\"].isin(rare_movies)]\n    user_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n    return user_movie_df\n\nuser_movie_df = create_user_movie_df()","037fbd2d":"# \u0130kinci yol:\n# import pickle\n# user_movie_df = pickle.load(open('user_movie_df.pkl', 'rb'))\n\nimport pandas as pd\npd.set_option('display.max_columns', 5)\n","a05e2437":"#rastgele bir kullan\u0131c\u0131 se\u00e7iyorum\nrandom_user = int(pd.Series(user_movie_df.index).sample(1, random_state=45).values)\nrandom_user","62e7d505":"# sinan\u0131n izledi\u011fi filmlere gitece\u011fim.\n# sinan\u0131n izledi\u011fi \u00e7ok film yoksa, item-based  yada content-based yapaca\u011f\u0131z. Trendlerden tavsiye edece\u011fim.\n\n# canl\u0131 sistemlerde dikkat, \n\n#random olarak se\u00e7ti\u011fim ki\u015fiye\nrandom_user_df = user_movie_df[user_movie_df.index == random_user]\n\n# bana sinan\u0131n izledi\u011fi filmler laz\u0131m. Ortak kar\u015f\u0131la\u015ft\u0131rma havuzu laz\u0131m. \n#tolist\nmovies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\n#sinan\u0131n izledi\u011fi filmler\nmovies_watched","c6be0a56":"# var olanlar\u0131 filmelere ka\u00e7 puan vermi\u015f\nuser_movie_df.loc[user_movie_df.index == random_user, user_movie_df.columns == \"Schindler's List (1993)\"]\n","bac280fc":"# ka\u00e7 film izlemi\u015f\nlen(movies_watched)","731c8d21":"# fancy indeks ile de\u011fi\u015fkenleri se\u00e7me\nmovies_watched_df = user_movie_df[movies_watched]\nmovies_watched_df.head()","a0f2243f":"# sat\u0131rlar, sinan ile sinan ile ayn\u0131 ayn\u0131 filmleri izlmi\u015fler\n# en az bir tanesi ayn\u0131 filmi izlmi\u015fler\n# sinan ile ayn\u0131 filmmi izlimi\u015f ki\u015filer, ayn\u0131 sonuca g\u00f6t\u00fcrmez. Bir e\u015fik gerekiyor.\nmovies_watched_df.shape","16a74310":"movies_watched_df.T.head(10)","c8c2fefb":"# her bir kullan\u0131c\u0131 i\u00e7in bo\u015f de\u011filse tru false \u00e7evirme\nuser_movie_count = movies_watched_df.T.notnull().sum()\nuser_movie_count.head(8)","d231867d":"#user id leri de\u011fi\u015fkene de\u011fi\u015ftirdik, indexten kurtard\u0131k\nuser_movie_count = user_movie_count.reset_index()","61ab0a0e":"user_movie_count.columns = [\"userId\", \"movie_count\"]\nuser_movie_count.head(14)","420958bb":"#bana belrili bir say\u0131n\u0131n \u00fczerinden izleyen ki\u015filer laz\u0131m\nuser_movie_count[user_movie_count[\"movie_count\"] > 20].sort_values(\"movie_count\", ascending=False)","2d5c30d5":"#tamamen ayn\u0131 filmi izleyenler ka\u00e7 ki\u015fi var.\nuser_movie_count[user_movie_count[\"movie_count\"] == 33].count()","c7788c84":"# en 20 filmi birlikte be\u011fenleri getir benim kullan\u0131c\u0131mla\nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > 20][\"userId\"]\nusers_same_movies.head()","1bdbd6b9":"users_same_movies.count()","672784e8":"# perc = len(movies_watched) * 60 \/ 100\n# users_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > perc][\"userId\"]\n\n","38bd1aa9":"#sinan ve di\u011ferlerini yan yana getirdim. isin() belirli bir listeyeg\u00f6re se\u00e7me yapar\n\nfinal_df = pd.concat([movies_watched_df[movies_watched_df.index.isin(users_same_movies.index)],\n                      random_user_df[movies_watched]])\n\nfinal_df.head()","55b2f1f3":"#sinan\u0131 da ekledik. \n## 33tane de film var. kullanc\u0131lar\u0131n, izledikleri filmlerin 20den fazlas\u0131 sinan ile ayn\u0131 film izlmi\u015fler.\nfinal_df.shape","a8859a9a":"final_df.T.corr()","38231911":"# unstackten \u00f6t\u00fcr\u00fc dblicate geliyor. onlar\u0131 u\u00e7urmak gerekiyor.\ncorr_df = final_df.T.corr().unstack().sort_values().drop_duplicates()\ncorr_df","f85a660c":"corr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\ncorr_df.head()","53d82954":"corr_df.index.names = ['user_id_1', 'user_id_2']\ncorr_df.head()","7b16dcd5":"corr_df = corr_df.reset_index()\ncorr_df.head()","1c3898c8":"# Sinan ile y\u00fczde 65 ve \u00fczeri korelasyona sahip kullan\u0131c\u0131lar:\ntop_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n    [\"user_id_2\", \"corr\"]].reset_index(drop=True) #iki de\u011fi\u015fkeni se\u00e7tik.\ntop_users.head()\n#sinan ile korelasyonu olan ki\u015filer","a874a4f9":"#sinanla en y\u00fcksek korelasyona sahip ki\u015filer kimler?\ntop_users = top_users.sort_values(by='corr', ascending=False)\ntop_users.head()","ce685200":"# de\u011fi\u015fkenleri tekrardan isimlendiriyorum\ntop_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\ntop_users.head()","cb453bad":"# bu kullan\u0131c\u0131lar, hangi filme ka\u00e7 puan vermi\u015f?\nrating = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/rating.csv')\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\n# skorlama problemini g\u00f6rebildiniz mi? \u00f6l\u00e7\u00fcm problemleri\n# sinan\u0131n bir kullanc\u0131 ile benzer puan verebilme al\u0131\u015fkanl\u0131\u011f\u0131 olabilir. \n# biri y\u00fcksek veriyor, di\u011feri d\u00fc\u015f\u00fck puan veriyor.\n# korelasyonun ve rating a\u011f\u0131rl\u0131\u011f\u0131n\u0131 nas\u0131l ayarlayaca\u011f\u0131z?\n\n#sinanla en y\u00fcksek korelasyona sahip ki\u015filer\ntop_users_ratings.head()","44f2d8ff":"\n\n# weighted_rating'in hesaplanmas\u0131.\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\ntop_users_ratings.head()","c2a000dd":"top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})","d62576ff":"recommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\n\nrecommendation_df = recommendation_df.reset_index()\n\nrecommendation_df[[\"movieId\"]].nunique()","c279363e":"# d\u00f6rten b\u00fcy\u00fck a\u011f\u0131rl\u0131klar\u0131 getir\nrecommendation_df[recommendation_df[\"weighted_rating\"] > 4]","604cc451":"movies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 4]\n\n# idler ile film isimlerini getirir misin?\nmovie = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/movie.csv')\nmovies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]])","c3a8e578":"movies_to_be_recommend","b63f285e":"\n\ndef user_based_recommender():\n    import pickle\n    import pandas as pd\n    user_movie_df = pickle.load(open('user_movie_df.pkl', 'rb'))\n    random_user = int(pd.Series(user_movie_df.index).sample(1, random_state=45).values)\n    random_user_df = user_movie_df[user_movie_df.index == random_user]\n    movies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\n    movies_watched_df = user_movie_df[movies_watched]\n    user_movie_count = movies_watched_df.T.notnull().sum()\n    user_movie_count = user_movie_count.reset_index()\n    user_movie_count.columns = [\"userId\", \"movie_count\"]\n    users_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > 20][\"userId\"]\n\n    final_df = pd.concat([movies_watched_df[movies_watched_df.index.isin(users_same_movies.index)],\n                          random_user_df[movies_watched]])\n\n    corr_df = final_df.T.corr().unstack().sort_values().drop_duplicates()\n    corr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\n    corr_df.index.names = ['user_id_1', 'user_id_2']\n    corr_df = corr_df.reset_index()\n\n    top_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n        [\"user_id_2\", \"corr\"]].reset_index(drop=True)\n\n    top_users = top_users.sort_values(by='corr', ascending=False)\n    top_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\n    rating = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/rating.csv')\n    top_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\n    top_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\n\n    recommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\n    recommendation_df = recommendation_df.reset_index()\n\n    movies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 4]\n    movie = pd.read_csv('\/kaggle\/input\/movielens-20m-dataset\/movie.csv')\n    return movies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]])\n\n\nuser_based_recommender()","e72588d1":"#############################################\n## Ad\u0131m 4: \u00d6neri Yap\u0131lacak Kullan\u0131c\u0131 ile En Benzer Davran\u0131\u015fl\u0131 Kullan\u0131c\u0131lar\u0131n Belirlenmesi\n#############################################\n\n## Bunun i\u00e7in 3 ad\u0131m ger\u00e7ekle\u015ftirece\u011fiz:\n 1. Sinan ve di\u011fer kullan\u0131c\u0131lar\u0131n verilerini bir araya getirece\u011fiz.\n 2. Korelasyon df'ini olu\u015fturaca\u011f\u0131z.\n 3. En benzer bullan\u0131c\u0131lar\u0131 (Top Users) bulaca\u011f\u0131z","55f9970d":"#############################################\n## Ad\u0131m 3: Ayn\u0131 Filmleri \u0130zleyen Di\u011fer Kullan\u0131c\u0131lar\u0131n Verisine ve Id'lerine Eri\u015fmek\n#############################################","3b70db4b":"#############################################\n## Ad\u0131m 2: \u00d6neri Yap\u0131lacak Kullan\u0131c\u0131n\u0131n \u0130zledi\u011fi Filmlerin Belirlenmesi\n#############################################","9509473f":"#############################################\n## Ad\u0131m 1: Veri Setinin Haz\u0131rlanmas\u0131\n#############################################","ff1033e6":"#############################################\n## Ad\u0131m 5: Weighted Average Recommendation Score'un Hesaplanmas\u0131\n#############################################\n\n1.  skorlama problemini g\u00f6rebildiniz mi? \u00f6l\u00e7\u00fcm problemleri\n1.  sinan\u0131n bir kullanc\u0131 ile benzer puan verebilme al\u0131\u015fkanl\u0131\u011f\u0131 olabilir. \n1.  biri y\u00fcksek veriyor, di\u011feri d\u00fc\u015f\u00fck puan veriyor.\n1.  korelasyonun ve rating a\u011f\u0131rl\u0131\u011f\u0131n\u0131 nas\u0131l ayarlayaca\u011f\u0131z?\n\n\u00dcniversite s\u0131nav\u0131nda derslerin katsay\u0131lar\u0131  olur. T\u00fcrk\u00e7e ve mat katsay\u0131lar\u0131 en fazla puan getirir.\n\n**# korelasyonu d\u00fc\u015f\u00fck olanlar daha \u00e7o\u0131k k\u0131rpacakt\u0131r.**\n\n- Her yerde bulanamayanlar serisi","c3b70a07":"############################################\n# User-Based Collaborative Filtering\n#############################################\n\n## Ad\u0131m 1: Veri Setinin Haz\u0131rlanmas\u0131\n## Ad\u0131m 2: \u00d6neri Yap\u0131lacak Kullan\u0131c\u0131n\u0131n \u0130zledi\u011fi Filmlerin Belirlenmesi\n## Ad\u0131m 3: Ayn\u0131 Filmleri \u0130zleyen Di\u011fer Kullan\u0131c\u0131lar\u0131n Verisine ve Id'lerine Eri\u015fmek\n## Ad\u0131m 4: \u00d6neri Yap\u0131lacak Kullan\u0131c\u0131 ile En Benzer Davran\u0131\u015fl\u0131 Kullan\u0131c\u0131lar\u0131n Belirlenmesi\n## Ad\u0131m 5: Weighted Average Recommendation Score'un Hesaplanmas\u0131\n## Ad\u0131m 6: \u00c7al\u0131\u015fman\u0131n Fonksiyonla\u015ft\u0131r\u0131lmas\u0131\n\n","accd1cbb":"#############################################\n## Ad\u0131m 6: \u00c7al\u0131\u015fman\u0131n Fonksiyonla\u015ft\u0131r\u0131lmas\u0131\n#############################################"}}