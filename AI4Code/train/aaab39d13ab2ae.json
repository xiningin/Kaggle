{"cell_type":{"e437d8f5":"code","d8b496c7":"code","3e8a79e1":"code","ad450608":"code","874ca6ea":"code","9822e50b":"code","42dd48ab":"code","f93e7fba":"code","806dc348":"code","5d51f6ab":"code","5db3a16b":"code","0fa04396":"code","5fbcd33c":"code","d8bb7c35":"code","5a34213c":"code","c87eef06":"code","4f09fecb":"code","540be056":"code","eca4665a":"code","bca2dbe6":"code","ca6175a6":"code","6d000a90":"code","b506dc77":"markdown","a11e56b3":"markdown","daee1d55":"markdown","36bf2f92":"markdown","a5125bf1":"markdown","acf82bfc":"markdown","06873506":"markdown","e3339517":"markdown","5674588e":"markdown"},"source":{"e437d8f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8b496c7":"!pip install torchsummary","3e8a79e1":"# Importing necessary libraries \nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchsummary import summary\nimport os\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","ad450608":"train_path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/'\nval_path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/'\ntest_path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/'","874ca6ea":"# MaskDataset for reading the data from source\nclass MaskDataset(Dataset):\n    \n    def __init__(self, path):\n        mask = glob(path+'WithMask\/*.png') # finds all the files matching the pattern , i.e., mask files\n        nomask = glob(path+'WithoutMask\/*.png') # finds all the files matching the pattern , i.e., non-mask files\n        self.fpath = mask+nomask  # combining all the files \n        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) # normalize images to feed into VGG16 architecture\n        from random import shuffle, seed\n        seed(1);\n        self.target = ['WithMask' in fpath.split('\/')[-2] for fpath in self.fpath] # getting labels out of the folder name\n                                                                                   # mask : 1, nomask : 0 \n        \n    def __len__(self):\n        return len(self.fpath) \n    \n    def __getitem__(self, idx):\n        f = self.fpath[idx]\n        target = self.target[idx] \n        im = (cv2.imread(f)[:,:,::-1]) # converting the images to numpy array \n        im = cv2.resize(im, (224,224)) # Resizing the images\n        im = torch.tensor(im\/255)\n        im = im.permute(2,0,1)\n        im = self.normalize(im) \n        return im.float().to(device), torch.tensor([target]).float().to(device)","9822e50b":"# Defining train data, validation data, test data\ntrain_data = MaskDataset(train_path)\nval_data = MaskDataset(val_path)\ntest_data = MaskDataset(test_path)\n\n# Dataloader for train, validation, test with batch size 32\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0) \nval_loader = DataLoader(val_data, batch_size=32, shuffle=True, num_workers=0) \ntest_loader = DataLoader(test_data, batch_size=32, shuffle=True, num_workers=0) ","42dd48ab":"# Looking at one image in training data\nim, label = train_data[400]\nplt.imshow(im.permute(1,2,0).cpu())\nprint(label)","f93e7fba":"# Look at four sample images from the train_dataset\nfig = plt.figure()\n\nfor i in range(1,len(train_data)):\n    imgs, labels = train_data[i]\n    print(labels)\n    ax = plt.subplot(2, 5, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{}'.format(i))\n    ax.axis('off')\n    plt.imshow(imgs.permute(1,2,0).cpu())\n\n    if i == 4:\n        plt.show()\n        break","806dc348":"# let us store the image information and label information from one train batch\nimages, labels = next(iter(train_loader)) \n\nprint(\"Number of elements in this batch\", len(labels))\nprint(\"Image size (batch, channel, height, width):\", images.shape)\nprint(\"Label length:\", labels.shape)","5d51f6ab":"# Check how many mask and nomask are present in one batch\nsns.countplot(np.array(labels.cpu())[:,0]);","5db3a16b":"# Function to train the model with given data and labels, optimizer, loss functions\ndef train_batch(x, y, model, opt, loss_fn):\n    model.train()\n    prediction = model(x) \n    batch_loss = loss_fn(prediction, y)\n    batch_loss.backward() # backpropagation\n    optimizer.step() # optimize\n    optimizer.zero_grad()\n    return batch_loss.item()","0fa04396":"# evaluates the accuracy of model; called in the epoch while training to check train and validation accuracy\n@torch.no_grad()\ndef accuracy(x, y, model):\n    model.eval()\n    prediction = model(x)\n    is_correct = (prediction > 0.5) == y\n    return is_correct.cpu().numpy().tolist()","5fbcd33c":"# Function to return the train and validation dataloaders\ndef get_data():\n    return train_loader, val_loader","d8bb7c35":"@torch.no_grad()\n\n# validation loss calculation\ndef val_loss(x, y, model):\n    prediction = model(x)\n    val_loss = loss_fn(prediction, y)\n    return val_loss.item()","5a34213c":"def get_model():\n    model = models.resnet18(pretrained=True) # loading the model from torhvision.models\n    \n    for param in model.parameters(): # we will not change the trained weights\n        param.requires_grad = False\n        \n    model.avgpool = nn.AdaptiveAvgPool2d(1) # output size changed from 7 to 1\n    \n    # Add two linear layers, one dropout layer and sigmoid activation function in the VGG16 classifier\n    model.fc = nn.Sequential(nn.Flatten(), \n    nn.Linear(512, 128),\n    nn.ReLU(),\n    nn.Dropout(0.2),\n    nn.Linear(128, 1),\n    nn.Sigmoid())\n    \n    loss_fn = nn.BCELoss() # binary cross entropy used to calculate loss in backpropagation\n    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3) # RMSprop algorithm as optimizer \n    return model.to(device), loss_fn, optimizer","c87eef06":"model, criterion, optimizer = get_model() # model instances\nprint(model)","4f09fecb":"summary(model, (3,224,224))","540be056":"# getting the necessary dataloaders and defining model parameters\ntrain_loader, val_loader = get_data() \nmodel, loss_fn, optimizer = get_model()","eca4665a":"train_losses, train_accuracies = [], []\nval_losses, val_accuracies = [], []\nfor epoch in range(5):\n    print(f\" epoch {epoch + 1}\/5\")\n    train_epoch_losses, train_epoch_accuracies = [], []\n    val_epoch_accuracies = []\n\n    for ix, batch in enumerate(iter(train_loader)):\n        x, y = batch\n        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n        train_epoch_losses.append(batch_loss) \n    train_epoch_loss = np.array(train_epoch_losses).mean()\n\n    for ix, batch in enumerate(iter(train_loader)):\n        x, y = batch\n        is_correct = accuracy(x, y, model)\n        train_epoch_accuracies.extend(is_correct)\n    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n\n    for ix, batch in enumerate(iter(val_loader)):\n        x, y = batch\n        val_is_correct = accuracy(x, y, model)\n        val_epoch_accuracies.extend(val_is_correct)\n        validation_loss = val_loss(x, y, model)\n    val_epoch_accuracy = np.mean(val_epoch_accuracies)\n\n    train_losses.append(train_epoch_loss)\n    train_accuracies.append(train_epoch_accuracy)\n    val_losses.append(validation_loss)\n    val_accuracies.append(val_epoch_accuracy)","bca2dbe6":"epochs = np.arange(5)+1\nimport matplotlib.ticker as mtick\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\n%matplotlib inline\nplt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\nplt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\nplt.title('Training and validation accuracy with VGG16 \\nand 1K training data points')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.ylim(0.95,1)\nplt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \nplt.legend()\nplt.grid('off')\nplt.show()","ca6175a6":"import matplotlib.ticker as mtick\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\n%matplotlib inline\nplt.plot(train_losses, label='Training losses')\nplt.plot(epochs, val_losses, label='Validation accuracy')\nplt.title('Training losses with VGG16 \\non training data points')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid('off')\nplt.show()","6d000a90":"# Let us check the model test accuracy\ntest_accuracies = []\nfor epoch in range(5):\n    test_epoch_accuracies = []\n    for img, label in (iter(test_loader)):\n        test_is_correct = accuracy(img, label, model)\n        test_epoch_accuracies.extend(val_is_correct)\n        #validation_loss = val_loss(x, y, model)\n    test_epoch_accuracy = np.mean(val_epoch_accuracies)\n    test_accuracies.append(test_epoch_accuracy)\nprint(\"Model accuarcy:\", max(test_accuracies)*100,\"%\")","b506dc77":"In the following cells we will make functions to train the model batchwise and define an accuracy method that will evaluate our model at different training and validation epochs. The validation loss method is also defined to check validation loss at epoch.","a11e56b3":"These images looks fine and gives the correct labels! Now we are ready to use CNN and feed the data from dataloader. Before that let us again check the one of the batches from one iteration of dataloader and the shape of images and labels","daee1d55":"Importing necessary libraries","36bf2f92":"Now we define a method to use pretrained VGG16 model. We have already normalized the images with mean and standard deviation as required by the model. We will change the average pool layer to give (1,1) output instead of the defined (7,7) in standard VGG16 model. We will also make changes to the classifer in VGG16 model to cater our needs.","a5125bf1":"Now, execute the following block to train the model. ","acf82bfc":"Visulaizing losses and accuracies..","06873506":"In this noteook we will make a **custom Dataset** and **DataLoader** from torch.utils.data to preprocess the data. As such no transformation is made to the image apart from rescaling and resizing the images. The reason of using a custom Dataset is to make use of this notebook as a baseline model. You can make neat changes to it to suit your needs.","e3339517":"Let us look at an image randomly selected data point from our custom dataset.","5674588e":"Let us first define the path to train, validation and test data"}}