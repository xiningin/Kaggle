{"cell_type":{"41b764ea":"code","7c188942":"code","d0fda8eb":"code","89492c39":"code","c3648f8d":"code","fcfa7bd2":"code","89df1399":"code","415c7cc1":"code","d6444553":"markdown","d0bc17fe":"markdown","79ef1233":"markdown","85041510":"markdown","a4e0355e":"markdown","e28a07e5":"markdown","79f1bab5":"markdown","24060453":"markdown"},"source":{"41b764ea":"import os\nimport random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\nCATEGORIES = ['cats', 'dogs']\ntrain_dir = '\/kaggle\/input\/dogs-cats-images\/dog vs cat\/dataset\/training_set'\ntest_dir = '\/kaggle\/input\/dogs-cats-images\/dog vs cat\/dataset\/test_set'","7c188942":"IMG_SIZE = 64\n\n\ndef create_data(directory):\n    a=[]\n    \n    for category in CATEGORIES:                     # CATEGORIES = ['cats', 'dogs']\n        path = os.path.join(directory, category)    # path\n        class_num = CATEGORIES.index(category)      # cats -> 0 | dogs -> 1\n        \n        for img in os.listdir(path):\n            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)     # grayscale\n            new_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))                     # resize to 64*64\n            a.append([new_arr, class_num])          # append image with its class\n    \n    random.shuffle(a)                               # shuffle dogs and cats\n    return a\n    \n    \n# calling function for training and testing data\ntraining_data = create_data(train_dir)\ntesting_data = create_data(test_dir)","d0fda8eb":"print(len(training_data), len(testing_data))","89492c39":"X = []\ny = []\n\nfor features, label in training_data:\n    X.append(features)                 # image features\n    y.append(label)                    # image label\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny = np.array(y)\nX = X\/255.0                            # normalize\n\ntest_sample = []\nactual = []\n\nfor features, label in testing_data:\n    test_sample.append(features)\n    actual.append(label)\n\ntest_sample = np.array(test_sample).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\nactual = np.array(actual)\ntest_sample = test_sample\/255.0","c3648f8d":"datagen = ImageDataGenerator(horizontal_flip = True)\ndatagen.fit(X)","fcfa7bd2":"earlystopping = EarlyStopping(monitor =\"val_accuracy\",\n                              mode = 'auto', patience = 30,\n                              restore_best_weights = True)\n\nopt = keras.optimizers.Adam(learning_rate=0.01)\nmomentum = 0.8\ndp = 0.5\n\nmodel = Sequential()\n\nmodel.add(Conv2D(128, (3, 3), input_shape = X.shape[1:]))\nmodel.add(BatchNormalization(momentum=momentum))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(dp))\n\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(BatchNormalization(momentum=momentum))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(dp))\n\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(BatchNormalization(momentum=momentum))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(dp))\n\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(BatchNormalization(momentum=momentum))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(dp))\n\n# model.add(Conv2D(64, (3, 3)))\n# model.add(BatchNormalization(momentum=momentum))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n# model.add(Dropout(dp))\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n\nEPOCHS = 1000\n\nhistory = model.fit(datagen.flow(X, y), batch_size=16, epochs=EPOCHS,\n                    validation_data=(test_sample, actual),callbacks = [earlystopping])","89df1399":"print(\"Max. Validation Accuracy: {}%\".format(round(100*max(history.history['val_accuracy']), 2)))","415c7cc1":"fig = plt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1,len(loss_val)+1)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nacc_train = history.history['accuracy']\nacc_val = history.history['val_accuracy']\nepochs = range(1,len(acc_val)+1)\nplt.plot(epochs, acc_train, 'g', label='Training accuracy')\nplt.plot(epochs, acc_val, 'b', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","d6444553":"What I do here is merge the data for dogs and cats, and shuffle them for effective training. I also grayscale and resize them.","d0bc17fe":"## Model","79ef1233":"## Visualizing Model Loss and Accuracy","85041510":"### Highest Accuracy Achieved: 92%","a4e0355e":"### Data Augmentation","e28a07e5":"## Preparing Training and Testing Data","79f1bab5":"## Imports","24060453":"### Seperating Features and Label"}}