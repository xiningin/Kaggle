{"cell_type":{"a15e8700":"code","107014b4":"code","ef3845ce":"code","fe29a6af":"code","c2125aa4":"code","6e2782ef":"code","500d419e":"code","f6c78989":"code","c6d64666":"code","af926c61":"markdown","f90130f9":"markdown","c70e3da2":"markdown","c01f2dd3":"markdown"},"source":{"a15e8700":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","107014b4":"from keras.layers import Dense, Activation\nfrom keras.layers.recurrent import SimpleRNN\nfrom keras.models import Sequential\nfrom keras.utils import plot_model","ef3845ce":"data = open(\"\/kaggle\/input\/alice-wonderland-dataset\/alice_in_wonderland.txt\", \"rb\")\nlines = []\nfor line in data:\n    line = line.strip().lower()\n    line = line.decode(\"ascii\", \"ignore\")\n    if len(line) == 0:\n        continue\n    lines.append(line)\ndata.close()\ntext = \" \".join(lines) #.replace(\"\\\\\", \"\").replace(\"\\n\", \"\").replace(\"*\", \"\")","fe29a6af":"text","c2125aa4":"chars = set([c for c in text])\nnb_chars = len(chars)\nchar2index = dict((c, i) for i, c in enumerate(chars))\nindex2char = dict((i, c) for i, c in enumerate(chars))","6e2782ef":"SEQLEN = 10\nSTEP = 1\n\ninput_chars = []\nlabel_chars = []\nfor i in range(0, len(text) - SEQLEN, STEP):\n    input_chars.append(text[i:i + SEQLEN])\n    label_chars.append(text[i + SEQLEN])","500d419e":"X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\ny = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n\nfor i, input_char in enumerate(input_chars):\n    for j, ch in enumerate(input_char):\n        X[i, j, char2index[ch]] = 1\n    y[i, char2index[label_chars[i]]] = 1","f6c78989":"HIDDEN_SIZE = 128\nBATCH_SIZE = 128\nNUM_ITERATIONS = 25\nNUM_EPOCHS_PER_ITERATION = 1\nNUM_PREDS_PER_EPOCH = 100\n\nmodel = Sequential()\nmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False, \n                    input_shape=(SEQLEN, nb_chars), \n                    unroll=True))\nmodel.add(Dense(nb_chars))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")","c6d64666":"for iteration in range(NUM_ITERATIONS):\n    print(\"=\" * 50)\n    print(\"Iteration #: %d\" % (iteration))\n    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n    test_idx = np.random.randint(len(input_chars))\n    test_chars = input_chars[test_idx]\n    print(\"\\nGenerating from seed: %s\" % (test_chars))\n    print(test_chars, end=\"\")\n    for i in range(NUM_PREDS_PER_EPOCH):\n        Xtest = np.zeros((1, SEQLEN, nb_chars))\n        for i, ch in enumerate(test_chars):\n            Xtest[0, i, char2index[ch]] = 1\n        pred = model.predict(Xtest, verbose=0)[0]\n        ypred = index2char[np.argmax(pred)]\n        print(ypred, end=\"\")\n        # move forward with test_chars + ypred\n        test_chars = test_chars[1:] + ypred\nprint()","af926c61":"Vectorizing the input and label texts","f90130f9":"extracting the text in our txt file","c70e3da2":"creating input and label texts","c01f2dd3":"creating the vocabulary lookup tables"}}