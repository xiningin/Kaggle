{"cell_type":{"d5620740":"code","95a1ac1a":"code","e6d766c8":"code","377073e8":"code","c1e73834":"code","c8bfa8dc":"code","41faca6f":"code","cc9207a7":"code","8a1c4d07":"code","417042f5":"code","3eaa8d6d":"code","c2d7337c":"code","8cf15f98":"code","16cd2e74":"code","0b1ced3b":"code","bd62b2a1":"code","99899143":"code","0aa0ed83":"code","e772d865":"code","9fb4c867":"code","45b03459":"code","aac410bb":"code","3a9da063":"code","fd46f17c":"code","c2e0859c":"code","c8e62650":"markdown","ba63d945":"markdown","453ed988":"markdown","3a52ec25":"markdown","49539a59":"markdown","42c0ae25":"markdown","df451466":"markdown"},"source":{"d5620740":"!pip install facenet_pytorch","95a1ac1a":"from facenet_pytorch import MTCNN\n# from PIL import Image\nimport torch\n# from imutils.video import FileVideoStream\n\nfrom numba import cuda \n\nimport time\n# import glob\n# from tqdm.notebook import tqdm\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n\nimport cv2\n\nimport os\nimport tqdm\n\nimport matplotlib.pyplot as plt\n\n# import mtcnn\n\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.utils import plot_model\nfrom keras import callbacks\n\nimport gc","e6d766c8":"def loadImages(fileNames, path):\n    print('form {} extracting face images'.format(path))\n    \n    images = []\n    imagePaths = []    \n    \n    for fileName in fileNames:\n        imagePaths.append(os.path.join(path, fileName))\n        \n        \n    for imagePath in tqdm.tqdm(imagePaths):\n        image = cv2.imread(imagePath, 1)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (256, 256)) \n        image = image\n        images.append(image)           \n    \n    return images","377073e8":"imgs = []\n\npath = '..\/input\/140k-real-and-fake-faces\/real_vs_fake\/real-vs-fake\/train\/real'\nfilenames = os.listdir(path)[0:1500]\nimgs = loadImages(filenames, path)","c1e73834":"imgs_gen = []\n\npath = '..\/input\/140k-real-and-fake-faces\/real_vs_fake\/real-vs-fake\/train\/fake'\nfilenames = os.listdir(path)[0:1500]\nimgs_gen = loadImages(filenames, path)","c8bfa8dc":"def crop_face(images):\n    images = np.array(images)\n    print('Croping Faces!!')\n    fast_mtcnn = MTCNN(\n    device=device\n    ) \n    found, pred = fast_mtcnn.detect(images)\n    i = 0\n    for faces in tqdm.tqdm(found):\n        crop_img = np.zeros((256, 256, 3))\n        if faces is not None:\n            for face in faces:\n                face = np.reshape(face, (2, 2))\n                heiwid = (face [1] - face[0])\n                heiwid = heiwid * 1.3\n                midp = (face[1] + face[0])\/2\n                x1 = int(max(0, (midp[0] - heiwid[0] \/ 2)))\n                y1 = int(max(0, (midp[1] - heiwid[1] \/ 2)))\n                x2 = int(min(256, (midp[0] + heiwid[0] \/ 2)))\n                y2 = int(min(256, (midp[1] + heiwid[1] \/ 2)))\n#                 crop_img[y1:y2, x1: x2] = images[i, y1:y2, x1: x2]\n\n                crop_img = images[i, y1:y2, x1: x2]\n        images[i] = cv2.resize(crop_img, (256, 256))\n#             images[i] = crop_img\n        i = i + 1\n   \n    return images\/255","41faca6f":"imgs = crop_face(imgs)","cc9207a7":"imgs_gen = crop_face(imgs_gen)","8a1c4d07":"plt.figure(figsize=(15, 10))\nfor i in range(8):\n    plt.subplot(2, 4,i+1)\n#     plt.xticks([])\n#     plt.yticks([])\n    plt.imshow(imgs[i])\nplt.subplots_adjust(wspace=0.2, hspace=0)\n\nplt.show()","417042f5":"plt.figure(figsize=(15, 10))\nfor i in range(8):\n    plt.subplot(2, 4,i+1)\n#     plt.xticks([])\n#     plt.yticks([])\n    plt.imshow(imgs_gen[i])\nplt.subplots_adjust(wspace=0.2, hspace=0)\nplt.show()","3eaa8d6d":"imgs_label = np.zeros(imgs.shape[0])\nimgsGen_label = np.ones(imgs_gen.shape[0])\nprint(imgs_label.shape, imgsGen_label.shape)","c2d7337c":"X = np.concatenate((imgs, imgs_gen))\nY = np.concatenate((imgs_label, imgsGen_label))\n\nimgs = None\nimgs_gen = None\nimgs_label = None\nimgsGen_label = None\ndel imgs\ndel imgs_gen\ndel imgs_label\ndel imgsGen_label\n\nprint(X.shape, Y.shape)","8cf15f98":"# X = np.reshape(X, (2000, 256, 256, 1))","16cd2e74":"X.shape","0b1ced3b":"X, X_test, Y, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n","bd62b2a1":"X.shape","99899143":"X[1]","0aa0ed83":"# device = cuda.get_current_device()\n# device\ntorch.cuda.empty_cache()\n\ngc.collect()","e772d865":"layers = [\n    Conv2D(8, kernel_size = (4, 4), input_shape = (256, 256, 3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(3, 3),\n    Conv2D(16, kernel_size = (5, 5), activation = 'relu', padding = 'same'),\n    MaxPooling2D(4, 4),\n    Conv2D(32, kernel_size = (6, 6), activation = 'relu', padding = 'same'),\n    MaxPooling2D(5, 5),\n    Flatten(),\n    Dense(48, activation = 'relu'),\n    Dropout(0.5),\n    Dense(16, activation = 'relu'),\n    Dropout(0.5),\n#     Dense(32, activation = 'relu'),\n#     Dropout(0.5),\n    Dense(2, activation = 'softmax')\n]\nmodel = Sequential(layers)","9fb4c867":"model.summary()","45b03459":"plot_model(model, show_shapes=True)","aac410bb":"model.compile(optimizer ='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","3a9da063":"history = model.fit(X, Y, \n                    batch_size = 50, \n                    epochs = 50, \n                    verbose = 1, \n                    validation_data = (X_test, y_test),\n                    shuffle=True\n                   )","fd46f17c":"plt.plot(history.history[\"accuracy\"])\nplt.plot(history.history[\"val_accuracy\"])\nplt.title(\"Model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Test\"])\nplt.show()","c2e0859c":"plt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Model loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Test\"])\nplt.show()","c8e62650":"# **Visualization**","ba63d945":"**Real Images**","453ed988":"**Generated**","3a52ec25":"**Generated Images**","49539a59":"**Croping Function**","42c0ae25":"**Real**","df451466":"**Load Images**"}}