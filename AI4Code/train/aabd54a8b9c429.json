{"cell_type":{"a7534626":"code","2be3d34c":"code","5eb2fc80":"code","099fbcb1":"code","49f9e002":"code","d2e67933":"code","dc0b4b9b":"code","eb4a6503":"code","bc792432":"code","634fc164":"code","40245385":"code","a1e7cba5":"code","20d9114f":"code","5afd2023":"code","fa5a5b73":"code","d56390a8":"code","625874d3":"code","ea0bdca4":"code","8e78aa5b":"code","a537d177":"markdown"},"source":{"a7534626":"import numpy as np\nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport math\nimport seaborn as sns\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2be3d34c":"df = pd.read_csv(\"..\/input\/Admission_Predict.csv\")\ndf1 = pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")","5eb2fc80":"df = df.merge(df1, how = \"outer\") ## To get a universal single dataframe\ndf = df.rename(columns = {'Chance of Admit ':'Chance of Admit'})\ndf.shape","099fbcb1":"df.head(20).T","49f9e002":"plt.figure(figsize = [10, 5]) ## Plotting the chance of admit to cgpa\nsns.scatterplot(df[\"Chance of Admit\"], df[\"CGPA\"])\nplt.show()","d2e67933":"plt.figure(figsize = [10, 5]) ## Plotting the cgpa to gre scores\nsns.scatterplot(df[\"CGPA\"], df[\"GRE Score\"])\nplt.show()","dc0b4b9b":"## Feature Engineering extra parameters\ndf[\"Ratio_CGPA_GRE\"] = (df[\"CGPA\"] \/ df[\"GRE Score\"]) * 100\ndf[\"Ratio_CGPA_TOEFL\"] = (df[\"CGPA\"] \/ df[\"TOEFL Score\"]) * 100","eb4a6503":"df[\"Ratio_CGPA_GRE\"].head()","bc792432":"df[\"Ratio_CGPA_TOEFL\"].head()","634fc164":"## Dropping the serial number column\ndf.drop(\"Serial No.\", inplace = True, axis = 1)\n\n## Checking the correlation matrix\nplt.figure(figsize = [10, 5])\nsns.heatmap(df.corr(), linewidths = 0.2, annot = True)\nplt.show()","40245385":"y = df[\"Chance of Admit\"] ## Get the dependent variable\ndf.drop(\"Chance of Admit\", axis = 1, inplace = True)","a1e7cba5":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_absolute_error","20d9114f":"## Cross - validate the dataset\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size = 0.2, random_state = 42)","5afd2023":"forest_params = {\n    \"n_estimators\" : [50, 100, 150, 200],\n    \"min_samples_leaf\" : [5, 10, 20, 30],\n    \"max_features\" : [1, 2, 3, 5]\n}","fa5a5b73":"rfr = RandomForestRegressor(oob_score = True)\nopti_rfr = GridSearchCV(rfr, forest_params, cv = 5, n_jobs = -1)","d56390a8":"opti_rfr.fit(X_train, y_train)","625874d3":"print(opti_rfr.best_estimator_)\nprint(opti_rfr.best_score_)","ea0bdca4":"print(\"Test MAE: \", mean_absolute_error(opti_rfr.predict(X_test), y_test))\nprint(\"Train MAE: \", mean_absolute_error(opti_rfr.predict(X_train), y_train))\nprint(\"Test Score: \", opti_rfr.score(X_test, y_test))\nprint(\"Train Score: \", opti_rfr.score(X_train, y_train))","8e78aa5b":"feat_importances = pd.Series(opti_rfr.best_estimator_.feature_importances_, index = df.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","a537d177":"# As it turns do well in your academics people \ud83d\udc4f\ud83c\udffc"}}