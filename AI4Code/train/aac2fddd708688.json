{"cell_type":{"b7f6f1e4":"code","1d2e0cad":"code","f27eada8":"code","cbfcda9e":"code","05262cfc":"code","9e8ee38f":"code","5fdb50ea":"code","f48ac1de":"code","ecbb178d":"code","f5aba7b1":"code","976ea960":"code","6f90c117":"code","3ca89014":"code","367a5e79":"code","ddef730d":"code","66ae10e3":"code","06c9f60c":"code","09abfaad":"code","521d6526":"code","b01a9ee9":"code","84fa607d":"code","40351968":"code","d5129b6f":"code","ab8d41a1":"code","c22d5829":"code","3b4986ec":"code","74651f65":"code","7dba3b9c":"code","0b29a555":"code","b3ed32c6":"code","e40128bb":"code","dd66e197":"code","84ef6f45":"code","9d684700":"code","eada2787":"code","33454e56":"code","e427d93f":"code","5a4b4059":"code","9001d870":"code","edbfa914":"code","bb3b623d":"code","71296f18":"code","3fd1e2f6":"code","3536fb69":"code","7eebdf61":"code","89f1b280":"code","2e23d157":"code","1275225b":"code","32ed8550":"code","19aa7b4d":"code","54ce08a9":"code","e4bbe6a5":"code","57ff9ac7":"code","5f450cad":"code","735abdb0":"markdown"},"source":{"b7f6f1e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1d2e0cad":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","f27eada8":"train_df.head()","cbfcda9e":"test_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_df.head()","05262cfc":"women = train_df[train_df['Sex'] == 'female']['Survived']\nsum(women)\/len(women) * 100","9e8ee38f":"men = train_df[train_df['Sex'] == 'male']['Survived']\nsum(men)\/len(men) * 100","5fdb50ea":"train_df['SibSp'].value_counts()","f48ac1de":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_df['Survived']\n\nfeatures = [\"Sex\", \"Pclass\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_df[features])\nX_test = pd.get_dummies(test_df[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","ecbb178d":"train_df.info()\nprint('_'*40)\ntest_df.info()","f5aba7b1":"train_df['Survived'].value_counts()","976ea960":"train_df.describe()","6f90c117":"train_df['Survived'].describe(percentiles=[.61, .62])","3ca89014":"train_df['Parch'].describe(percentiles=[.75, .8])","367a5e79":"train_df['SibSp'].describe(percentiles=[.68, .69])","ddef730d":"train_df['Age'].describe(percentiles=[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99])","66ae10e3":"train_df['Fare'].describe(percentiles=[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99])","06c9f60c":"train_df.describe(include=['O'])","09abfaad":"train_df.columns","521d6526":"train_df[['Pclass','Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending='False')","b01a9ee9":"train_df[['Sex','Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending='False')","84fa607d":"train_df[['SibSp','Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending='False')","40351968":"train_df[['Parch','Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending='False')","d5129b6f":"train_df[['Embarked','Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending='False')","ab8d41a1":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=10)","c22d5829":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=10)\ngrid.add_legend()","3b4986ec":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","74651f65":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","7dba3b9c":"print(\"Before\", train_df.shape, test_df.shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","0b29a555":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","b3ed32c6":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","e40128bb":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()","dd66e197":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","84ef6f45":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","9d684700":"guess_ages = np.zeros((2,3))\nguess_ages","eada2787":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","33454e56":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","e427d93f":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","5a4b4059":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","9001d870":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","edbfa914":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","bb3b623d":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","71296f18":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","3fd1e2f6":"# Our training dataset has two missing values. We simply fill these with the most common occurance.\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","3536fb69":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","7eebdf61":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","89f1b280":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","2e23d157":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","1275225b":"test_df.head(10)","32ed8550":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","19aa7b4d":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","54ce08a9":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","e4bbe6a5":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","57ff9ac7":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X_train, Y_train)\npredictions = model.predict(X_test)\n\nmodel.score(X_train, Y_train)\nacc_random_forest = round(model.score(X_train, Y_train) * 100, 2)\nacc_random_forest","5f450cad":"output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your second submission was successfully saved!\")","735abdb0":"**Improving model**"}}