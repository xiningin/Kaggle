{"cell_type":{"d75eb76d":"code","2151bb70":"code","7b6b6249":"code","188ad4d9":"code","2b28b9ff":"code","cee83633":"code","a992ca00":"code","db9aeb0c":"code","b137cf6a":"code","783ed39b":"code","7886af62":"code","8f786199":"code","62193436":"code","363e3d51":"code","bcf0751e":"code","3f02026a":"code","c33299a1":"code","30818fc6":"code","3f6d8813":"markdown"},"source":{"d75eb76d":"# Import the required libraries\n\nimport os\nimport random\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","2151bb70":"# Store the base directory path\n\nbase_dir = os.path.join(\"\/kaggle\/input\/kermany2018\/oct2017\/OCT2017 \/\")\nprint('Base directory --> ', os.listdir(base_dir))","7b6b6249":"# Store the train, validation and test directory paths\n\ntrain_dir = os.path.join(base_dir + \"train\/\")\nprint(\"Train Directory --> \", os.listdir(train_dir))\n\nvalidation_dir = os.path.join(base_dir + \"val\/\")\nprint(\"Validation Directory --> \", os.listdir(validation_dir))\n\ntest_dir = os.path.join(base_dir + \"test\/\")\nprint(\"Test Directory --> \", os.listdir(test_dir))","188ad4d9":"# Plot each type of image in the dataset\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 10))\n\ndrusen = random.choice(os.listdir(train_dir + \"DRUSEN\"))\ndrusen_image = load_img(train_dir + \"DRUSEN\/\" + drusen)\nax[0].imshow(drusen_image)\nax[0].set_title(\"DRUSEN\")\nax[0].axis(\"Off\")\n\ndme = random.choice(os.listdir(train_dir + \"DME\"))\ndme_image = load_img(train_dir + \"DME\/\" + dme)\nax[1].imshow(dme_image)\nax[1].set_title(\"DME\")\nax[1].axis(\"Off\")\n\ncnv = random.choice(os.listdir(train_dir + \"CNV\"))\ncnv_image = load_img(train_dir + \"CNV\/\" + cnv)\nax[2].imshow(cnv_image)\nax[2].set_title(\"CNV\")\nax[2].axis(\"Off\")\n\nnormal = random.choice(os.listdir(train_dir + \"NORMAL\"))\nnormal_image = load_img(train_dir + \"NORMAL\/\" + normal)\nax[3].imshow(normal_image)\nax[3].set_title(\"NORMAL\")\nax[3].axis(\"Off\")\n\nplt.show()","2b28b9ff":"INPUT_SHAPE = (150, 150, 3)","cee83633":"inception_resnet_v2 = tf.keras.applications.InceptionResNetV2(\n    include_top = False, \n    weights = 'imagenet', \n    input_tensor = None,\n    input_shape = INPUT_SHAPE, \n    pooling = None, \n    classes = 1000\n)","a992ca00":"inception_resnet_v2.trainable = False","db9aeb0c":"model = tf.keras.models.Sequential([\n    \n    inception_resnet_v2,\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation = 'relu'),\n    tf.keras.layers.Dense(4, activation = 'softmax')\n])","b137cf6a":"model.summary()","783ed39b":"metrics_list = ['accuracy',\n                tf.keras.metrics.AUC(),\n                tfa.metrics.CohenKappa(num_classes = 4),\n                tfa.metrics.F1Score(num_classes = 4)]","7886af62":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = metrics_list)","8f786199":"train_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 100)","62193436":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 16)","363e3d51":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 44)","bcf0751e":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch = (83484\/100),\n    epochs = 10,\n    validation_data = validation_generator,\n    validation_steps = (32\/16),\n    verbose = 1)","3f02026a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(7,7))\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (7,7))\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","c33299a1":"model.predict(test_generator, steps = int(968\/44))","30818fc6":"model.evaluate(test_generator)","3f6d8813":"**This notebook implements InceptionResnetV2 on OCT image dataset to classify the diseases**"}}