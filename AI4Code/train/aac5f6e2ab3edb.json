{"cell_type":{"5b3c474a":"code","29e533cc":"code","0d6d02fe":"code","d47e5371":"code","458f5ea2":"code","a471fda7":"code","55cbd5ab":"code","a16bdb6e":"code","36e5be82":"code","772c34a1":"code","a2e26d8e":"code","d4f4e55f":"code","f960bde4":"code","30205fe8":"code","86252b05":"markdown","cd38bcaa":"markdown","a4cfcf8e":"markdown","505b53e6":"markdown","cf1068db":"markdown","f4f410d2":"markdown","9830fd77":"markdown","e3eb907f":"markdown","8ee52642":"markdown","dd06b95a":"markdown","3617fee7":"markdown","8c1ace4f":"markdown"},"source":{"5b3c474a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/dataset\/dataset\"))\n# Any results you write to the current directory are saved as output.","29e533cc":"import torch\nprint(torch.__version__)\nprint(torch.cuda.device_count())\nprint(torch.cuda.is_available())","0d6d02fe":"import os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\n\nimport numpy as np\nimport pandas as pd\n\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader\nfrom torch.optim.lr_scheduler import MultiStepLR","d47e5371":"dataroot = \"..\/input\/dataset\/dataset\/\"\nckptroot = \".\/\"\n\nlr = 1e-4\nweight_decay = 1e-5\nbatch_size = 32\nnum_workers = 8\ntest_size = 0.8\nshuffle = True\n\nepochs = 80\nstart_epoch = 0\nresume = False","458f5ea2":"def toDevice(datas, device):\n    \"\"\"Enable cuda.\"\"\"\n    imgs, angles = datas\n    return imgs.float().to(device), angles.float().to(device)\n\n\ndef augment(dataroot, imgName, angle):\n    \"\"\"Data augmentation.\"\"\"\n    name = dataroot + 'IMG\/' + imgName.split('\\\\')[-1]\n    current_image = cv2.imread(name)\n\n    if current_image is None:\n        print(name)\n\n    current_image = current_image[65:-25, :, :]\n    if np.random.rand() < 0.5:\n        current_image = cv2.flip(current_image, 1)\n        angle = angle * -1.0\n\n    return current_image, angle","a471fda7":"def load_data(data_dir, test_size):\n    \"\"\"Load training data and train validation split\"\"\"\n    pass\n\n    # reads CSV file into a single dataframe variable\n    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n\n    # Divide the data into training set and validation set\n    train_len = int(test_size * data_df.shape[0])\n    valid_len = data_df.shape[0] - train_len\n    trainset, valset = data.random_split(\n        data_df.values.tolist(), lengths=[train_len, valid_len])\n\n    return trainset, valset\n\ntrainset, valset = load_data(dataroot, test_size)","55cbd5ab":"class TripletDataset(data.Dataset):\n\n    def __init__(self, dataroot, samples, transform=None):\n        self.samples = samples\n        self.dataroot = dataroot\n        self.transform = transform\n\n    def __getitem__(self, index):\n        batch_samples = self.samples[index]\n        steering_angle = float(batch_samples[3])\n\n        center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n        left_img, steering_angle_left     = augment(self.dataroot, batch_samples[1], steering_angle + 0.4)\n        right_img, steering_angle_right   = augment(self.dataroot, batch_samples[2], steering_angle - 0.4)\n\n        center_img = self.transform(center_img)\n        left_img   = self.transform(left_img)\n        right_img  = self.transform(right_img)\n\n        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n\n    def __len__(self):\n        return len(self.samples)","a16bdb6e":"print(\"==> Preparing dataset ...\")\ndef data_loader(dataroot, trainset, valset, batch_size, shuffle, num_workers):\n    \"\"\"Self-Driving vehicles simulator dataset Loader.\n\n    Args:\n        trainset: training set\n        valset: validation set\n        batch_size: training set input batch size\n        shuffle: whether shuffle during training process\n        num_workers: number of workers in DataLoader\n\n    Returns:\n        trainloader (torch.utils.data.DataLoader): DataLoader for training set\n        testloader (torch.utils.data.DataLoader): DataLoader for validation set\n    \"\"\"\n    transformations = transforms.Compose(\n        [transforms.Lambda(lambda x: (x \/ 127.5) - 1.0)])\n\n    # Load training data and validation data\n    training_set = TripletDataset(dataroot, trainset, transformations)\n    trainloader = DataLoader(training_set,\n                             batch_size=batch_size,\n                             shuffle=shuffle,\n                             num_workers=num_workers)\n\n    validation_set = TripletDataset(dataroot, valset, transformations)\n    valloader = DataLoader(validation_set,\n                           batch_size=batch_size,\n                           shuffle=shuffle,\n                           num_workers=num_workers)\n\n    return trainloader, valloader\n\n\ntrainloader, validationloader = data_loader(dataroot,\n                                            trainset, valset,\n                                            batch_size,\n                                            shuffle,\n                                            num_workers)","36e5be82":"class NetworkNvidia(nn.Module):\n    \"\"\"NVIDIA model used in the paper.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize NVIDIA model.\n\n        NVIDIA model used\n            Image normalization to avoid saturation and make gradients work better.\n            Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n            Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n            Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n            Drop out (0.5)\n            Fully connected: neurons: 100, activation: ELU\n            Fully connected: neurons: 50, activation: ELU\n            Fully connected: neurons: 10, activation: ELU\n            Fully connected: neurons: 1 (output)\n\n        the convolution layers are meant to handle feature engineering\n        the fully connected layer for predicting the steering angle.\n        \"\"\"\n        super(NetworkNvidia, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(3, 24, 5, stride=2),\n            nn.ELU(),\n            nn.Conv2d(24, 36, 5, stride=2),\n            nn.ELU(),\n            nn.Conv2d(36, 48, 5, stride=2),\n            nn.ELU(),\n            nn.Conv2d(48, 64, 3),\n            nn.ELU(),\n            nn.Conv2d(64, 64, 3),\n            nn.Dropout(0.5)\n        )\n        self.linear_layers = nn.Sequential(\n            nn.Linear(in_features=64 * 2 * 33, out_features=100),\n            nn.ELU(),\n            nn.Linear(in_features=100, out_features=50),\n            nn.ELU(),\n            nn.Linear(in_features=50, out_features=10),\n            nn.Linear(in_features=10, out_features=1)\n        )\n\n    def forward(self, input):\n        \"\"\"Forward pass.\"\"\"\n        input = input.view(input.size(0), 3, 70, 320)\n        output = self.conv_layers(input)\n        # print(output.shape)\n        output = output.view(output.size(0), -1)\n        output = self.linear_layers(output)\n        return output\n\n\n# Define model\nprint(\"==> Initialize model ...\")\nmodel = NetworkNvidia()\nprint(\"==> Initialize model done ...\")","772c34a1":"# Define optimizer and criterion\noptimizer = optim.Adam(model.parameters(),\n                       lr=lr,\n                       weight_decay=weight_decay)\ncriterion = nn.MSELoss()","a2e26d8e":"# learning rate scheduler\nscheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n\n# transfer to gpu\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","d4f4e55f":"if resume:\n    print(\"==> Loading checkpoint ...\")\n    checkpoint = torch.load(\"..\/input\/pretrainedmodels\/both-nvidia-model-61.h5\",\n                            map_location=lambda storage, loc: storage)\n    start_epoch = checkpoint['epoch']\n    model.load_state_dict(checkpoint['state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    scheduler.load_state_dict(checkpoint['scheduler'])","f960bde4":"class Trainer(object):\n    \"\"\"Trainer.\"\"\"\n\n    def __init__(self,\n                 ckptroot,\n                 model,\n                 device,\n                 epochs,\n                 criterion,\n                 optimizer,\n                 scheduler,\n                 start_epoch,\n                 trainloader,\n                 validationloader):\n        \"\"\"Self-Driving car Trainer.\n\n        Args:\n            model:\n            device:\n            epochs:\n            criterion:\n            optimizer:\n            start_epoch:\n            trainloader:\n            validationloader:\n\n        \"\"\"\n        super(Trainer, self).__init__()\n\n        self.model = model\n        self.device = device\n        self.epochs = epochs\n        self.ckptroot = ckptroot\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.start_epoch = start_epoch\n        self.trainloader = trainloader\n        self.validationloader = validationloader\n\n    def train(self):\n        \"\"\"Training process.\"\"\"\n        self.model.to(self.device)\n        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n            self.scheduler.step()\n            \n            # Training\n            train_loss = 0.0\n            self.model.train()\n\n            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n                # Transfer to GPU\n                centers, lefts, rights = toDevice(centers, self.device), toDevice(\n                    lefts, self.device), toDevice(rights, self.device)\n\n                # Model computations\n                self.optimizer.zero_grad()\n                datas = [centers, lefts, rights]\n                for data in datas:\n                    imgs, angles = data\n                    # print(\"training image: \", imgs.shape)\n                    outputs = self.model(imgs)\n                    loss = self.criterion(outputs, angles.unsqueeze(1))\n                    loss.backward()\n                    self.optimizer.step()\n\n                    train_loss += loss.data.item()\n\n                if local_batch % 100 == 0:\n\n                    print(\"Training Epoch: {} | Loss: {}\".format(epoch, train_loss \/ (local_batch + 1)))\n\n\n            # Validation\n            self.model.eval()\n            valid_loss = 0\n            with torch.set_grad_enabled(False):\n                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n                    # Transfer to GPU\n                    centers, lefts, rights = toDevice(centers, self.device), toDevice(\n                        lefts, self.device), toDevice(rights, self.device)\n\n                    # Model computations\n                    self.optimizer.zero_grad()\n                    datas = [centers, lefts, rights]\n                    for data in datas:\n                        imgs, angles = data\n                        outputs = self.model(imgs)\n                        loss = self.criterion(outputs, angles.unsqueeze(1))\n\n                        valid_loss += loss.data.item()\n\n                    if local_batch % 100 == 0:\n                        print(\"Validation Loss: {}\".format(valid_loss \/ (local_batch + 1)))\n\n\n            print()\n            # Save model\n            if epoch % 5 == 0 or epoch == self.epochs + self.start_epoch - 1:\n\n                state = {\n                    'epoch': epoch + 1,\n                    'state_dict': self.model.state_dict(),\n                    'optimizer': self.optimizer.state_dict(),\n                    'scheduler': self.scheduler.state_dict(),\n                }\n\n                self.save_checkpoint(state)\n\n    def save_checkpoint(self, state):\n        \"\"\"Save checkpoint.\"\"\"\n        print(\"==> Save checkpoint ...\")\n        if not os.path.exists(self.ckptroot):\n            os.makedirs(self.ckptroot)\n\n        torch.save(state, self.ckptroot + 'both-nvidia-model-{}.h5'.format(state['epoch']))\n","30205fe8":"print(\"==> Start training ...\")\ntrainer = Trainer(ckptroot,\n                  model,\n                  device,\n                  epochs,\n                  criterion,\n                  optimizer,\n                  scheduler,\n                  start_epoch,\n                  trainloader,\n                  validationloader)\ntrainer.train()","86252b05":"## Create dataset","cd38bcaa":"## Get data loader","a4cfcf8e":"## Define optimizer and criterion","505b53e6":"## Load data","cf1068db":"## Hyper-parameters","f4f410d2":"## Helper functions","9830fd77":"## Resume training","e3eb907f":"## Install Dependencies","8ee52642":"## Learning rate scheduler","dd06b95a":"## Train","3617fee7":"## Import libraries","8c1ace4f":"## Define model"}}