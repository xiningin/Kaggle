{"cell_type":{"fa13b259":"code","8ea1df2f":"code","cb9fc8b7":"code","e7ef2f5f":"code","0f9e4758":"code","2a2ba6b0":"code","d9695167":"code","1fd30e81":"code","cbabf4c5":"code","f6b9b607":"code","5d957837":"code","d0da3d98":"code","2a8843e2":"code","856aef80":"code","9f5f1bea":"code","6ef3f206":"code","b5986fc9":"code","59a49745":"code","536221c1":"code","571e7571":"code","c8f8d563":"code","7f43cdd5":"code","cc296616":"code","72e689f9":"code","1426119b":"code","9fef84d9":"code","f254522d":"code","6a37da6b":"code","37b97a35":"code","5699cf93":"code","6afe4d88":"code","fc3722b1":"code","c78538c3":"code","7e6db2c1":"code","5316a6f0":"code","cf8ccf04":"code","63ac2255":"code","c8d8aedd":"code","e908ab36":"markdown","c968d5df":"markdown","2ff8f5fd":"markdown","9bfa0ed6":"markdown","23681843":"markdown","00b48bab":"markdown","75a9d11d":"markdown","afe4d156":"markdown","9ca8466d":"markdown"},"source":{"fa13b259":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ea1df2f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nimport string\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV","cb9fc8b7":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","e7ef2f5f":"train.head()","0f9e4758":"test.head()","2a2ba6b0":"train.info()","d9695167":"train.shape","1fd30e81":"train.target.unique()","cbabf4c5":"train.location.nunique()","f6b9b607":"train.keyword.nunique()","5d957837":"test.info()","d0da3d98":"test.shape","2a8843e2":"test.keyword.nunique()","856aef80":"test.location.nunique()","9f5f1bea":"train.isna().sum()","6ef3f206":"test.isna().sum()","b5986fc9":"train.target.value_counts(normalize=True)","59a49745":"plt.figure(figsize=(8,4))\nsns.barplot(train.target.value_counts().index, train.target.value_counts())","536221c1":"#train.location.value_counts().nlargest(10)\nplt.figure(figsize=(10,4))\nsns.barplot(train.location.value_counts().nlargest(10),train.location.value_counts().nlargest(10).index, orient='h')","571e7571":"#https:\/\/stackoverflow.com\/questions\/26540035\/rotate-label-text-in-seaborn-factorplot\n\n#train.keyword.value_counts().nlargest(20)\nplt.figure(figsize=(15,6))\nsns.barplot(train.keyword.value_counts().nlargest(20).index,train.keyword.value_counts().nlargest(20))\nplt.xticks(rotation=45)","c8f8d563":"train['low_text'] =  train['text'].str.lower()\ntest['low_text'] = test['text'].str.lower()","7f43cdd5":"string.punctuation","cc296616":"#https:\/\/stackoverflow.com\/questions\/265960\/best-way-to-strip-punctuation-from-a-string\ntrain['aftr_punct'] = train['low_text'].str.translate(str.maketrans(\"\",\"\",string.punctuation))\ntest['aftr_punct'] = test['low_text'].str.translate(str.maketrans(\"\",\"\",string.punctuation))","72e689f9":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns',None)","1426119b":"stopword = stopwords.words('english')\nstopword","9fef84d9":"stopword = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", \n            'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', \n            'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n            'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', \n            'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n            'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', \n            'into','through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n            'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n            'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own',\n            'same', 'so', 'than', 'too', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm',\n            'o', 're', 've', 'y', 'ma',]","f254522d":"def remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in stopword])\n\ntrain['stp_text'] = train['aftr_punct'].apply(lambda text: remove_stopwords(text))\ntest['stp_text'] = test['aftr_punct'].apply(lambda text: remove_stopwords(text))","6a37da6b":"stemmer = PorterStemmer()\ndef stem_word(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([stemmer.stem(word) for word in text.split()])\n\ntrain['stem_text'] = train['stp_text'].apply(lambda text: stem_word(text))\ntest['stem_text'] = test['stp_text'].apply(lambda text: stem_word(text))","37b97a35":"lemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n\ntrain['lemmatize_text'] = train['stp_text'].apply(lambda text: lemmatize_words(text))\ntest['lemmatize_text'] = test['stp_text'].apply(lambda text: lemmatize_words(text))","5699cf93":"train_df = train[['id','keyword','location','lemmatize_text','target']]\ntrain_df.head()","6afe4d88":"test_df = test[['id','keyword','location','lemmatize_text']]\ntest_df.head()","fc3722b1":"plt.figure(figsize=(12,8))\nwordcloud = WordCloud( background_color='white').generate(\" \".join(train_df['lemmatize_text']))\nplt.imshow(wordcloud)","c78538c3":"bow = CountVectorizer()\ntrain_vector = bow.fit_transform(train_df['lemmatize_text'])\ntest_vector = bow.transform(test_df['lemmatize_text'])","7e6db2c1":"clf = LogisticRegression()\nscore = model_selection.cross_val_score(clf, train_vector, train_df['target'], cv=5, scoring='f1')\nscore","5316a6f0":"clf.fit(train_vector,train_df['target'])","cf8ccf04":"clf_nb = MultinomialNB()\nscore = model_selection.cross_val_score(clf_nb, train_vector, train_df['target'], cv=5, scoring='f1')\nscore","63ac2255":"clf_nb.fit(train_vector, train_df['target'])","c8d8aedd":"sample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = clf_nb.predict(test_vector)\nsample_submission.to_csv(\"submission.csv\", index=False)\n#sample_submission.target.value_counts()","e908ab36":"### Converting text to vector","c968d5df":"### Preprocessing of text data","2ff8f5fd":"We can upload this csv and check our score on LB. \n\n#### End of Notebook!!","9bfa0ed6":"https:\/\/www.kaggle.com\/sudalairajkumar\/getting-started-with-text-preprocessing\n1. Changing text to lower case\n2. Removal of stopwords, punctuation and html tags from data\n3. Stemming\n4. Lemmatization","23681843":"#### https:\/\/www.kaggle.com\/parulpandey\/getting-started-with-nlp-a-general-intro","00b48bab":"#### WordCloud","75a9d11d":"Since Naive Bayes has more accuracy than Logistic Regression, we will use it to predict test dataset target value and for final submission","afe4d156":"#### Observation - Since, value for target variable is almost equal in number, we can apply machine learning algorithm on it.","9ca8466d":"with test.fit_transform, we will get 11,713 features which are not same as train but with test.transform, we will get 21,032 features which are same as train"}}