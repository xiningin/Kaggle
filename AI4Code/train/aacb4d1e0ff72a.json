{"cell_type":{"48ae64e8":"code","9deb53d7":"code","5547866d":"code","9a39524a":"code","193834ff":"code","b222e888":"code","73621356":"code","75d30544":"code","06028b4c":"code","345be788":"code","c24c93b5":"code","8ba32fdd":"code","ab7fad3f":"code","c2bc34fd":"code","fff88d82":"code","6b59b25c":"code","74ec7aec":"code","8d132d6d":"code","ec80319f":"code","8b4aa0f3":"code","27396aa5":"code","34659573":"code","027daaa2":"code","23ab2be1":"code","76a34ee0":"code","1d416faa":"code","55a70113":"code","d15f742e":"code","7714cb02":"code","d51eeddf":"code","55fc5071":"code","4ea89704":"code","ee1a317f":"code","714e11ba":"code","33a8e930":"code","ea4389d0":"code","84be559e":"markdown","b0491cd5":"markdown","c9c200a1":"markdown","ea7dad56":"markdown","21f615ed":"markdown","7f7ecc6b":"markdown","e93b0b19":"markdown","e83023ba":"markdown","40a58b30":"markdown","c0020859":"markdown","194e9d28":"markdown","bec610fd":"markdown","031bbfe0":"markdown","07ff2577":"markdown","e85e64cf":"markdown"},"source":{"48ae64e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sympy\nimport scipy\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport sklearn.metrics as metrics\nimport statsmodels.api as stats\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9deb53d7":"df = pd.read_csv(\"\/kaggle\/input\/Purchase_Likelihood.csv\")\ndf.head()","5547866d":"target = df[\"A\"].astype(\"category\")\npredictor = df[[\"group_size\",\"homeowner\",\"married_couple\"]].astype('category')","9a39524a":"def build_mnlogit (fullX, y, debug = 'N'):\n    # Number of all parameters\n    nFullParam = fullX.shape[1]\n\n    # Number of target categories\n    y_category = y.cat.categories\n    nYCat = len(y_category)\n\n    # Find the non-redundant columns in the design matrix fullX\n    reduced_form, inds = sympy.Matrix(fullX.values).rref()\n\n    # These are the column numbers of the non-redundant columns\n    if (debug == 'Y'):\n        print('Column Numbers of the Non-redundant Columns:')\n        print(inds)\n\n    # Extract only the non-redundant columns for modeling\n    X = fullX.iloc[:, list(inds)]\n\n    # The number of free parameters\n    thisDF = len(inds) * (nYCat - 1)\n\n    # Build a multionomial logistic model\n    logit = stats.MNLogit(y, X)\n    thisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n    thisParameter = thisFit.params\n    thisLLK = logit.loglike(thisParameter.values)\n\n    if (debug == 'Y'):\n        print(thisFit.summary())\n        print(\"Model Parameter Estimates:\\n\", thisParameter)\n        print(\"Model Log-Likelihood Value =\", thisLLK)\n        print(\"Number of Free Parameters =\", thisDF)\n\n    # Recreat the estimates of the full parameters\n    workParams = pd.DataFrame(np.zeros(shape = (nFullParam, (nYCat - 1))))\n    workParams = workParams.set_index(keys = fullX.columns)\n    fullParams = pd.merge(workParams, thisParameter, how = \"left\", left_index = True, right_index = True)\n    fullParams = fullParams.drop(columns = '0_x').fillna(0.0)\n\n    # Return model statistics\n    return (thisLLK, thisDF, fullParams)\n","193834ff":"group_size_dummies = pd.get_dummies(predictor[[\"group_size\"]].astype('category'))\nhomeowner_dummies = pd.get_dummies(predictor[[\"homeowner\"]].astype('category'))\nmarried_couple_dummies = pd.get_dummies(predictor[[\"married_couple\"]].astype('category'))","b222e888":"#Intercept only\n\ndesignX = pd.DataFrame(target.where(target.isnull(), 1))\nLLK0, DF0, fullParams0 = build_mnlogit (designX, target, debug = 'Y')","73621356":"#Intercept + Group Size\ndesignX = stats.add_constant(group_size_dummies, prepend=True)\nLLK_1R, DF_1R, fullParams_1R = build_mnlogit (designX, target, debug = 'N')\ntestDev = 2 * (LLK_1R - LLK0)\ntestDF = DF_1R - DF0\ntestPValue = scipy.stats.chi2.sf(testDev, testDF)\nprint('Deviance Chi=Square Test')\nprint('Chi-Square Statistic = ', testDev)\nprint('  Degreee of Freedom = ', testDF)\nprint('        Significance = ', testPValue)","75d30544":"# Intercept + Group Size + HomeOwner\ndesignX = group_size_dummies\ndesignX = designX.join(homeowner_dummies)\ndesignX = stats.add_constant(designX, prepend=True)\nLLK_1R_1J, DF_1R_1J, fullParams_1R_1J = build_mnlogit (designX, target, debug = 'N')\ntestDev = 2 * (LLK_1R_1J - LLK_1R)\ntestDF = DF_1R_1J - DF_1R\ntestPValue = scipy.stats.chi2.sf(testDev, testDF)\nprint('Deviance Chi=Square Test')\nprint('Chi-Square Statistic = ', testDev)\nprint('  Degreee of Freedom = ', testDF)\nprint('        Significance = ', testPValue)\n","06028b4c":"# Intercept + Group Size + HomeOwner + Married Couple\ndesignX = group_size_dummies\ndesignX = designX.join(homeowner_dummies)\ndesignX = designX.join(married_couple_dummies)\ndesignX = stats.add_constant(designX, prepend=True)\nLLK_1R_1J_M, DF_1R_1J_M, fullParams_1R_1J = build_mnlogit (designX, target, debug = 'N')\ntestDev = 2 * (LLK_1R_1J_M - LLK_1R_1J)\ntestDF = DF_1R_1J_M - DF_1R_1J\ntestPValue = scipy.stats.chi2.sf(testDev, testDF)\nprint('Deviance Chi=Square Test')\nprint('Chi-Square Statistic = ', testDev)\nprint('  Degreee of Freedom = ', testDF)\nprint('        Significance = ', testPValue)","345be788":"def create_interaction (inDF1, inDF2):\n    name1 = inDF1.columns\n    name2 = inDF2.columns\n    outDF = pd.DataFrame()\n    for col1 in name1:\n        for col2 in name2:\n            outName = col1 + \" * \" + col2\n            outDF[outName] = inDF1[col1] * inDF2[col2]\n    return(outDF)","c24c93b5":"# Intercept + Group Size + HomeOwner + Married Couple + GroupSize*Homeowner\ndesignX = group_size_dummies\ndesignX = designX.join(homeowner_dummies)\ndesignX = designX.join(married_couple_dummies)\n\nxRJ = create_interaction(group_size_dummies, homeowner_dummies)\ndesignX = designX.join(xRJ)\n\ndesignX = stats.add_constant(designX, prepend=True)\nLLK_2RJ_m, DF_2RJ_m, fullParams_2RJ = build_mnlogit (designX, target, debug = 'N')\ntestDev = 2 * (LLK_2RJ_m - LLK_1R_1J_M)\ntestDF = DF_2RJ_m - DF_1R_1J_M\ntestPValue = scipy.stats.chi2.sf(testDev, testDF)\nprint('Deviance Chi=Square Test')\nprint('Chi-Square Statistic = ', testDev)\nprint('  Degreee of Freedom = ', testDF)\nprint('        Significance = ', testPValue)","8ba32fdd":"designX = group_size_dummies\ndesignX = designX.join(homeowner_dummies)\ndesignX = designX.join(married_couple_dummies)\nxRJ = create_interaction(group_size_dummies, homeowner_dummies)\ndesignX = designX.join(xRJ)\n\nxHM = create_interaction(homeowner_dummies,married_couple_dummies)\ndesignX = designX.join(xHM)\n\ndesignX = stats.add_constant(designX, prepend=True)","ab7fad3f":"m = [4,6,8,10,12,14,15,16,18,19,20]\n#designX.columns[n]\nprint(\"Aliased parameters in the model\")\nfor i in m:\n    print(designX.columns[i])","c2bc34fd":"# Intercept + Group Size + HomeOwner + Married Couple + GroupSize*Homeowner + Homeowner*MarriedCouple\n\nLLK_2RJ_HM, DF_2RJ_HM, fullParams_2RJ = build_mnlogit (designX, target, debug = 'Y')\ntestDev = 2 * (LLK_2RJ_HM - LLK_2RJ_m)\ntestDF = DF_2RJ_HM - DF_2RJ_m\ntestPValue = scipy.stats.chi2.sf(testDev, testDF)\nprint('Deviance Chi=Square Test')\nprint('Chi-Square Statistic = ', testDev)\nprint('  Degreee of Freedom = ', testDF)\nprint('        Significance = ', testPValue)","fff88d82":"import math\nFeatureImportance = [4.347870389027117e-210,4.306457217534288e-19,5.512105969198056e-52,4.13804354648637e-16 ]\nfor i in FeatureImportance:\n    print(-math.log10(i))","6b59b25c":"logit = stats.MNLogit(target, designX)\nthisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)","74ec7aec":"group = [1,2,3,4]\nhome = [0,1]\nmarried = [0,1]\ncombi = []\n\nfor i in home:\n    for j in group:\n        for k in married:\n            combi.append([i,j,k])\n            \ncombinat = pd.DataFrame(combi,columns=[\"home\",\"group\",\"married\"])\n\ncombi_group_dummies = pd.get_dummies(combinat[[\"group\"]].astype('category'))\ncombi_home_dummies = pd.get_dummies(combinat[[\"home\"]].astype('category'))\ncombi_married_dummies = pd.get_dummies(combinat[[\"married\"]].astype('category'))\n\ngh_combi = create_interaction(combi_group_dummies, combi_home_dummies)\ngh_combi = pd.get_dummies(gh_combi)\n\nhm_combi = create_interaction(combi_home_dummies,combi_married_dummies)\nhm_combi = pd.get_dummies(hm_combi)\n\nfullX = combi_group_dummies\nfullX = fullX.join(combi_home_dummies)\nfullX = fullX.join(combi_married_dummies)\nfullX = fullX.join(gh_combi)\nfullX = fullX.join(hm_combi)\nfullX = stats.add_constant(fullX, prepend=True)","8d132d6d":"combinat","ec80319f":"predicted_probabilities = thisFit.predict(fullX)\npredicted_probabilities = pd.DataFrame.join(combinat,predicted_probabilities)\npredicted_probabilities","8b4aa0f3":"predicted_probabilities[1]\/predicted_probabilities[0]","27396aa5":"combi[9]","34659573":"one,two,three = 0,0,0\nfor i in df.A:\n    if i == 0:\n        one+=1\n    elif i == 1:\n        two+=1\n    else:\n        three+=1\ncounts = [one,two,three]\n\nproabs = []\nfor i in counts:\n    proabs.append(i\/len(df.A))\n\ndata = pd.DataFrame(data = counts , columns = [\"Count\"])\ndata[\"Class Probabilites\"] = proabs\ndata","027daaa2":"pd.crosstab(df.A,df.group_size)","23ab2be1":"pd.crosstab(df.A,df.homeowner)","76a34ee0":"pd.crosstab(df.A,df.married_couple)","1d416faa":"import scipy.stats as ss\ndef cramers_v(confusion_matrix):\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0,(phi2 - ((k-1)*(r-1))\/(n-1)))\n    rcorr = r - ((r-1)**2)\/(n-1)\n    kcorr = k - ((k-1)**2)\/(n-1)\n    print(np.sqrt(phi2corr \/ min( (kcorr-1), (rcorr-1))))","55a70113":"confusion_matrix = pd.crosstab(df.A,df.group_size)\ncramers_v(confusion_matrix)","d15f742e":"confusion_matrix = pd.crosstab(df.A,df.married_couple)\ncramers_v(confusion_matrix)","7714cb02":"confusion_matrix = pd.crosstab(df.A,df.homeowner)\ncramers_v(confusion_matrix)","d51eeddf":"data_count = df.groupby('A').count()['group_size']\ndata_prop = data_count \/ df.shape[0]\ndata_grouped = pd.DataFrame({'A': data_count.index, \n                                    'Count': data_count.values, \n                                    'Class probabilities': data_prop.values})\n\ncrosstab_group_size = pd.crosstab(df.A, df.group_size, margins = False, dropna = False)\n\ncrosstab_homeowner = pd.crosstab(df.A, df.homeowner, margins = False, dropna = False)\n\ncrosstab_married_couple = pd.crosstab(df.A, df.married_couple, margins = False, dropna = False)","55fc5071":"def predict_probabilities(predictors):\n    prob_0 = ((data_grouped['Count'][0] \/ data_grouped['Count'].sum()) * \n                   (crosstab_group_size[predictors[0]][0] \/ crosstab_group_size.loc[[0]].sum(axis=1)[0]) * \n                   (crosstab_homeowner[predictors[1]][0] \/crosstab_homeowner.loc[[0]].sum(axis=1)[0]) * \n                   (crosstab_married_couple[predictors[2]][0] \/ crosstab_married_couple.loc[[0]].sum(axis=1)[0]))\n    prob_1 = ((data_grouped['Count'][1] \/ data_grouped['Count'].sum()) * \n                   (crosstab_group_size[predictors[0]][1] \/ crosstab_group_size.loc[[1]].sum(axis=1)[1]) * \n                   (crosstab_homeowner[predictors[1]][1] \/ crosstab_homeowner.loc[[1]].sum(axis=1)[1]) * \n                   (crosstab_married_couple[predictors[2]][1] \/ crosstab_married_couple.loc[[1]].sum(axis=1)[1]))\n    prob_2 = ((data_grouped['Count'][2] \/ data_grouped['Count'].sum()) * \n                   (crosstab_group_size[predictors[0]][2] \/ crosstab_group_size.loc[[2]].sum(axis=1)[2]) * \n                   (crosstab_homeowner[predictors[1]][2] \/ crosstab_homeowner.loc[[2]].sum(axis=1)[2]) * \n                   (crosstab_married_couple[predictors[2]][2] \/ crosstab_married_couple.loc[[2]].sum(axis=1)[2]))\n    sum_of_probs = prob_0 + prob_1 + prob_2\n    valid_prob_0 = prob_0 \/ sum_of_probs\n    valid_prob_1 = prob_1 \/ sum_of_probs\n    valid_prob_2 = prob_2 \/ sum_of_probs\n\n    return [valid_prob_0, valid_prob_1, valid_prob_2]","4ea89704":"group_sizes = sorted(list(df.group_size.unique()))\nhomeowners = sorted(list(df.homeowner.unique()))\nmarried_couples = sorted(list(df.married_couple.unique()))\nn = pd.DataFrame(combinations,columns = [\"group_size\",\"homeowner\",\"married_couples\"])\n\nimport itertools\ncombinations = list(itertools.product(group_sizes, homeowners, married_couples))\n\n","ee1a317f":"nb_probabilities = []\nfor combination in combinations:\n    temp = [predict_probabilities(combination)]\n    nb_probabilities.extend(temp)\nfinal = pd.DataFrame.join(pd.DataFrame(nb_probabilities,columns = [\"0\",\"1\",\"2\"]),n)\nfinal","714e11ba":"final[\"1\"]\/final[\"0\"]","33a8e930":"max(final[\"1\"]\/final[\"0\"])","ea4389d0":"final.iloc[7]","84be559e":"### Predicted Probabilites for Naive Bayes","b0491cd5":"### Predicted Probabilities\n(e)\t For each of the sixteen possible value combinations of the three features, calculate the predicted probabilities for A = 0, 1, 2 based on the multinomial logistic model.  List your answers in a table with proper labelling.","c9c200a1":"## Machine Learning Assignment 04","ea7dad56":"### Load Dataset","21f615ed":" Show the crosstabulation table of the target variable by the feature homeowner.  The table contains the frequency counts.","7f7ecc6b":"### Aliased parameters found in your model","e93b0b19":"### Odds value\nBased on your model, what values of group_size, homeowner, and married_couple will maximize the odds value Prob(A=1) \/ Prob(A = 0)?  What is that maximum odd value?","e83023ba":"### Feature Importances","40a58b30":"Show the crosstabulation table of the target variable by the feature married_couple.  The table contains the frequency counts.","c0020859":"### Class Probabilities of the target variable.\nShow in a table the frequency counts and the Class Probabilities of the target variable.","194e9d28":"### Cramers V Statistic","bec610fd":"## Question 2","031bbfe0":"### Odds Value","07ff2577":"### Function to build MNL model","e85e64cf":"Show the crosstabulation table of the target variable by the feature group_size.  The table contains the frequency counts."}}