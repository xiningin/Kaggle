{"cell_type":{"308ce985":"code","e8a426a0":"code","ee89e748":"code","bc175210":"code","e95fad33":"code","c0a760e9":"code","996a76a5":"code","9351e112":"code","e8268536":"code","3cd30317":"code","d5f4e431":"code","20616d64":"code","00c6bb6f":"code","a9d4bf82":"code","65ef4956":"code","e18dcda6":"code","49f4ebf3":"code","e820e0d4":"code","e1671cad":"code","c617b0ab":"markdown","b1a47ebd":"markdown","a13e81df":"markdown","0ddab0d8":"markdown","cc68a1f6":"markdown","9f208560":"markdown","5f8a9e1e":"markdown","cb3d6a9f":"markdown","81f5af44":"markdown","1751a47c":"markdown","dd7ba8c0":"markdown","e287d7e4":"markdown"},"source":{"308ce985":"import os\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # To use local CPU instead of local GPU\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as implt\nfrom PIL import Image \nimport time,datetime,keras,cv2,shutil,keras_preprocessing,requests\nimport tensorflow as tf\nfrom keras import layers\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D \nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import shuffle\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom io import BytesIO\nimport seaborn as sns\n%load_ext tensorboard\nshutil.rmtree('.\/logs', ignore_errors=True)","e8a426a0":"%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics)\n    plt.plot(epochs, val_metrics)\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()","ee89e748":"train_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\"\ntest_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"\n\ntrain_horses = train_path + \"\/horses\"\ntest_horses = test_path + \"\/horses\"\n\ntrain_humans = train_path + \"\/humans\"\ntest_humans = test_path + \"\/humans\"","bc175210":"img1 = implt.imread(train_horses + \"\/horse02-8.png\")\nimg2 = implt.imread(train_humans + \"\/human15-07.png\")\n\nplt.subplot(1, 2, 1)\nplt.title('A rendered horse')\nplt.imshow(img1)       \nplt.subplot(1, 2, 2)\nplt.title('A rendered human')\nplt.imshow(img2)\nplt.show()","e95fad33":"img_size = 100\nhumans_train = []\nhorses_train = []\nhumans_test = []\nhorses_test = []\nlabel = []\ny_train = []\ny_test = []\n\nfor i in os.listdir(train_humans):\n    if os.path.isfile(train_path + \"\/humans\/\" + i):\n        humans = Image.open(train_path + \"\/humans\/\" + i).convert(\"L\")\n        humans = humans.resize((img_size,img_size), Image.ANTIALIAS) \n        humans = np.asarray(humans)\/255 \n        humans_train.append(humans)\n        y_train.append(1)\n        \nfor i in os.listdir(train_horses): \n    if os.path.isfile(train_path + \"\/horses\/\" + i): \n        horses = Image.open(train_path + \"\/horses\/\" + i).convert(\"L\") \n        horses = horses.resize((img_size,img_size), Image.ANTIALIAS) \n        horses = np.asarray(horses)\/255 \n        horses_train.append(horses)\n        y_train.append(0)\n\nfor i in os.listdir(test_humans): \n    if os.path.isfile(test_path + \"\/humans\/\" + i): \n        humans = Image.open(test_path + \"\/humans\/\" + i).convert(\"L\") \n        humans = humans.resize((img_size,img_size), Image.ANTIALIAS) \n        humans = np.asarray(humans)\/255 \n        humans_test.append(humans)\n        y_test.append(1)\n        \nfor i in os.listdir(test_horses): \n    if os.path.isfile(test_path + \"\/horses\/\" + i): \n        horses = Image.open(test_path + \"\/horses\/\" + i).convert(\"L\") \n        horses = horses.resize((img_size,img_size), Image.ANTIALIAS) \n        horses = np.asarray(horses)\/255 \n        horses_test.append(horses)\n        y_test.append(0)","c0a760e9":"x_train = np.concatenate((humans_train,horses_train),axis=0)\ny_train = np.asarray(y_train) \ny_train = y_train.reshape(y_train.shape[0],1)\n\nx_test = np.concatenate((humans_test,horses_test),axis=0) \ny_test = np.asarray(y_test) \ny_test = y_test.reshape(y_test.shape[0],1)\n\nx_train, y_train = shuffle(x_train, y_train)\nx_test, y_test = shuffle(x_test, y_test)\nprint(\"humans test:\",np.shape(humans_test) , \"horses test:\",np.shape(horses_test))\nprint(\"test_dataset:\",np.shape(x_test), \"test_values:\",np.shape(y_test))\n\nprint(\"humans train:\",np.shape(humans_train) , \"horses train:\",np.shape(horses_train))\nprint(\"train_dataset:\",np.shape(x_train), \"train_values:\",np.shape(y_train))","996a76a5":"######### BatchNorm and Dropout anywhere made it worse, so I commented them out #########\ninput_shape = (img_size,img_size,1)\nmodel = Sequential([\n    Conv2D(filters = 32, kernel_size = 3, input_shape = input_shape, activation=\"relu\"),\n    # BatchNormalization(),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(filters = 64, kernel_size = 3, activation=\"relu\"),\n    # BatchNormalization(),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(filters = 128, kernel_size = 3, activation=\"relu\"),\n    # BatchNormalization(),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(filters = 256, kernel_size = 3, activation=\"relu\"),\n    # BatchNormalization(),\n    MaxPooling2D(pool_size = (2,2)),\n    Flatten(),\n    Dense(512, activation=\"relu\"),\n    # BatchNormalization(),\n    # Dropout(0.2),\n    Dense(256, activation=\"relu\"),\n    Dense(1, activation=\"sigmoid\"),\n])\nmodel.build(input_shape)\nmodel.summary()","9351e112":"x_trainGen, x_val, y_trainGen, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle=False)\n\nx_train=tf.expand_dims(x_train, -1)\nx_trainGen=tf.expand_dims(x_trainGen, -1)\nx_test=tf.expand_dims(x_test, -1)\nx_val=tf.expand_dims(x_val, -1)\n\ntraining_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range=0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n).flow(x_trainGen,y_trainGen)\n\nvalidating_datagen = ImageDataGenerator().flow(x_val,y_val)","e8268536":"######### Learning Rate #########\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=2e-4,\n    decay_steps=200,\n    decay_rate=0.90)\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\n######### Compile Model #########\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nlog_dir = \"logs\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n######### Early Stopping #########\nearly_stoppage_callback = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.01, patience=100, restore_best_weights = True)\n\nstart = time.time()\n\n######### WITH IMAGEDATAGENERATOR #########\nhistory = model.fit(training_datagen, \n            epochs=200,\n            verbose=1,\n            validation_data=validating_datagen, \n            callbacks=[tensorboard_callback, early_stoppage_callback])\n\n# ######### WITHOUT IMAGEDATAGENERATOR #########\n# history = model.fit(x_train,y_train, \n#             epochs=200,\n#             verbose=1,\n#             validation_split=0.2\n#             callbacks=[tensorboard_callback, early_stoppage_callback])\n\nend = time.time()\nprint(end - start,\"secs\")","3cd30317":"plot_metric(history, \"loss\")\nplot_metric(history, \"accuracy\")","d5f4e431":"# # Works when running locally\n# %tensorboard --logdir logs\/fit","20616d64":"model.evaluate(x_test, y_test)\nclasses = [\"horse\",\"human\"]\ny_pred = np.round(model.predict(x_test),0)\n\nprint(metrics.classification_report(y_test,y_pred,target_names=classes))","00c6bb6f":"ax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, ax = ax,cmap='Blues',fmt='')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels') \nax.set_title('Confusion Matrix') \nax.xaxis.set_ticklabels(['Predicted Horses', 'Predicted Humans']); ax.yaxis.set_ticklabels(['True Horses', 'True Humans'])","a9d4bf82":"url = \"https:\/\/www.kindpng.com\/picc\/m\/154-1542577_full-body-guy-in-suit-png-transparent-png.png\"\nrealhuman = Image.open(BytesIO(requests.get(url).content)).convert(\"L\")\nrealhuman = realhuman.resize((img_size,img_size), Image.ANTIALIAS)\ndisplay(realhuman)\nrealhuman = np.asarray(realhuman)\/255\nrealhuman = realhuman.reshape(1,img_size,img_size,1)","65ef4956":"predictedhuman = model.predict(realhuman)\nprint(\"There's a\",'{0:.2f}'.format(predictedhuman[0][0]*100),\"% chance that this is a human.\")","e18dcda6":"url = \"https:\/\/images.theconversation.com\/files\/250401\/original\/file-20181213-110249-1czg7z.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=1200&h=1200.0&fit=crop\"\nrealhorse = Image.open(BytesIO(requests.get(url).content)).convert(\"L\")\nrealhorse = realhorse.resize((img_size,img_size), Image.ANTIALIAS)\ndisplay(realhorse)\nrealhorse = np.asarray(realhorse)\/255\nrealhorse = realhorse.reshape(1,img_size,img_size,1)","49f4ebf3":"predictedhorse = model.predict(realhorse)\nprint(\"There's a\",'{0:.2f}'.format(100-predictedhorse[0][0]*100),\"% chance that this is a horse.\")","e820e0d4":"url = \"https:\/\/www.winnerscircle-equine.com\/storage\/app\/media\/3j.jpg\"\nrealhorse = Image.open(BytesIO(requests.get(url).content)).convert(\"L\")\nrealhorse = realhorse.resize((img_size,img_size), Image.ANTIALIAS)\ndisplay(realhorse)\nrealhorse = np.asarray(realhorse)\/255\nrealhorse = realhorse.reshape(1,img_size,img_size,1)","e1671cad":"predictedhorse = model.predict(realhorse)\nprint(\"There's a\",'{0:.2f}'.format(100-predictedhorse[0][0]*100),\"% chance that this is a horse.\")","c617b0ab":"## Define a Plotting function","b1a47ebd":"## Model Evaluation","a13e81df":"## Show a couple of samples","0ddab0d8":"## Define ImageDataGenerator","cc68a1f6":"## Go through folders categorizing files into lists","9f208560":"# Load libraries and data\n## Imports","5f8a9e1e":"# Model Analysis\n## Plot Loss and Accuracy","cb3d6a9f":"# Real Human and Horse testing","81f5af44":"## Confusion Matrix","1751a47c":"# Compile and Fit the model","dd7ba8c0":"## Get X and y ready","e287d7e4":"# Define Neural Network\n## Define sequential nn"}}