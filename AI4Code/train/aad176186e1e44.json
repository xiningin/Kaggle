{"cell_type":{"04dc4b49":"code","ff0d8c28":"code","5f1eb9ab":"code","af4d8797":"code","edabed81":"code","2b598d39":"code","d2454539":"code","02de2421":"code","1b354720":"code","2b04593c":"code","a05b3fd4":"code","55e19c26":"code","af29b36a":"code","f7c9f1b8":"code","236323a8":"code","02e6925c":"code","6b811671":"code","75532ca5":"code","0ba1c260":"code","33c64cd7":"code","cd52132f":"markdown","744f0df2":"markdown","b91b4617":"markdown","c0ad1a3b":"markdown","b80b3f89":"markdown"},"source":{"04dc4b49":"import os\nimport cv2\nimport time\nimport torch\nimport random\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom matplotlib import style","ff0d8c28":"os.chdir('\/kaggle\/input\/natural-images\/data\/natural_images')\nprint(os.listdir())","5f1eb9ab":"os.chdir('\/kaggle\/input')\nprint(os.listdir())","af4d8797":"REBUILD_DATA = True\nclass Natural_Images():\n    IMG_SIZE = 50\n    CAT = '\/kaggle\/input\/natural-images\/data\/natural_images\/cat'\n    DOG = '\/kaggle\/input\/natural-images\/data\/natural_images\/dog'\n    AIRPLANE = '\/kaggle\/input\/natural-images\/data\/natural_images\/airplane'\n    FRUIT = '\/kaggle\/input\/natural-images\/data\/natural_images\/fruit'\n    FLOWER = '\/kaggle\/input\/natural-images\/data\/natural_images\/flower'\n    PERSON = '\/kaggle\/input\/natural-images\/data\/natural_images\/person'\n    CAR = '\/kaggle\/input\/natural-images\/data\/natural_images\/car'\n    MOTORBIKE = '\/kaggle\/input\/natural-images\/data\/natural_images\/motorbike'\n    TESTING = '\/kaggle\/input\/natural-images\/data\/natural_images\/testing'\n    LABELS = {CAT: 0, DOG: 1,AIRPLANE: 2,CAR: 3,MOTORBIKE: 4,FRUIT: 5,FLOWER: 6,PERSON: 7}\n    training_data = []\n    catcount = 0\n    dogcount = 0\n    airplanecount = 0\n    fruitcount = 0\n    flowercount = 0\n    personcount = 0\n    carcount = 0\n    motorbikecount = 0\n\n    def make_training_data(self):\n        for label in self.LABELS:  # this return all of the keys (the directory of cats,dogs and so on)\n            for f in os.listdir(label):  # f is the file name,all of the images\n                if 'jpg' in f:\n                        path = os.path.join(label, f)\n                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n                        self.training_data.append([np.array(img), np.eye(8)[self.LABELS[label]]])\n        \n                        if label == self.CAT:\n                            self.catcount = self.catcount + 1\n                        elif label == self.DOG:\n                            self.dogcount += 1\n                        elif label == self.AIRPLANE:\n                            self.airplanecount += 1\n                        elif label == self.FRUIT:\n                            self.fruitcount += 1\n                        elif label == self.FLOWER:\n                            self.flowercount += 1\n                        elif label == self.PERSON:\n                            self.personcount += 1\n                        elif label == self.CAR:\n                            self.carcount += 1\n                        elif label == self.MOTORBIKE:\n                            self.motorbikecount += 1\n\n        np.random.shuffle(self.training_data)\n        np.save(\"\/kaggle\/working\/tra_data2.npy\",self.training_data)\n        print('CATS:',natural_images.catcount)\n        print('DOGS:',natural_images.dogcount)\n        print('AIRPLANE:',natural_images.airplanecount)\n        print('FRUIT:',natural_images.fruitcount)\n        print('FLOWER:',natural_images.flowercount)\n        print('PERSON:',natural_images.personcount)\n        print('CAR:',natural_images.carcount)\n        print('MOTORBIKE:',natural_images.motorbikecount)","edabed81":"if REBUILD_DATA:\n    natural_images = Natural_Images()\n    natural_images.make_training_data()","2b598d39":"training_data = np.load(\"\/kaggle\/working\/tra_data2.npy\", allow_pickle=True)\nprint(len(training_data))","d2454539":"# LABELS = {CAT: 0, DOG: 1,AIRPLANE: 2,CAR: 3,MOTORBIKE: 4,FRUIT: 5,FLOWER: 6,PERSON: 7}\nplt.rcParams['figure.figsize'] = [16, 13]\nplt.figure(33)\nfor i in range(331,340,1):\n    plt.subplot(i)\n    plt.imshow(training_data[i][0])\n    plt.title(training_data[i][1])","02de2421":"# Now we can split our training data into X and y, as well as convert it to a tensor\n# We also need to shape this data (view it, according to Pytorch) in the way Pytorch expects us (-1, IMG_SIZE, IMG_SIZE)\nX = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\nX = X\/255.0\ny = torch.Tensor([i[1] for i in training_data])","1b354720":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__() \n        self.conv1 = nn.Conv2d(1, 32, 5) \n        self.conv2 = nn.Conv2d(32, 64, 5) \n        self.conv3 = nn.Conv2d(64, 128, 5)\n\n        x = torch.randn(50,50).view(-1,1,50,50)\n        \n        self._to_linear = None\n        self.convs(x)\n        \n        self.fc1 = nn.Linear(self._to_linear, 512) \n        self.fc2 = nn.Linear(512, 8) \n        \n    def convs(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2),ceil_mode=True)\n        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2),ceil_mode=True)\n        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2),ceil_mode=True)\n        \n        if self._to_linear is None:\n            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n\n        return x\n    \n    def forward(self, x):\n        x = self.convs(x)\n        x = x.view(-1, self._to_linear)  \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x) \n        return F.softmax(x, dim=1)\n\n    \nnet = Net()\nprint(net)","2b04593c":"optimizer = optim.Adam(net.parameters(), lr=0.001)\nloss_function = nn.MSELoss()\nVAL_PCT = 0.2  # reserve 20% of our data for validation\nval_size = int(len(X)*VAL_PCT)\nprint(val_size)","a05b3fd4":"train_X = X[:-val_size]\ntrain_y = y[:-val_size]\ntest_X = X[-val_size:]\ntest_y = y[-val_size:]\n\nprint(len(train_X), len(test_X))","55e19c26":"BATCH_SIZE = 200\nEPOCHS = 23","af29b36a":"for epoch in range(EPOCHS):\n    for i in range(0, len(train_X), BATCH_SIZE): \n        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n        batch_y = train_y[i:i+BATCH_SIZE]\n\n        net.zero_grad()\n\n        outputs = net(batch_X)\n        loss = loss_function(outputs, batch_y)\n        \n        matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, batch_y)]\n        in_sample_acc = matches.count(True)\/len(matches)\n\n        loss.backward() \n        optimizer.step()\n\n    print(f\"Epoch: {epoch}. Loss: {loss}\")\n    print(\"In-sample acc:\",round(in_sample_acc, 4))","f7c9f1b8":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for i in range(len(test_X)):\n        real_class = torch.argmax(test_y[i])\n        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list\n        predicted_class = torch.argmax(net_out)\n\n        if predicted_class == real_class:\n            correct += 1\n        total += 1\nprint(\"Accuracy: \", round(correct\/total, 4))","236323a8":"def fwd_pass(X, y, train=False):\n\n    if train:\n        net.zero_grad()\n    outputs = net(X)\n    matches  = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n    acc = matches.count(True)\/len(matches)\n    loss = loss_function(outputs, y)\n\n    if train:\n        loss.backward()\n        optimizer.step()\n\n    return acc, loss","02e6925c":"def test(size = 100):\n    random_start = random.randint(0,len(test_X - size))\n    X, y = test_X[random_start:random_start + size], test_y[random_start:random_start + size]\n    with torch.no_grad():\n        val_acc, val_loss = fwd_pass(X.view(-1,1,50,50),y)\n    return val_acc, val_loss\nval_acc, val_loss = test(size = 100)\nprint(val_acc, val_loss)","6b811671":"MODEL_NAME = f\"model-{int(time.time())}\"  \nnet = Net()\noptimizer = optim.Adam(net.parameters(), lr=0.001)\nloss_function = nn.MSELoss()\nprint(MODEL_NAME)","75532ca5":"def train(net):\n    BATCH_SIZE = 200\n    EPOCHS = 23\n    with open(\"\/kaggle\/working\/modeldata.log\", \"a\") as f:\n        for epoch in range(EPOCHS):\n            # iterate over our batches \n            for i in range(0, len(train_X), BATCH_SIZE):\n                # slice our data into batches\n                batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n                batch_y = train_y[i:i+BATCH_SIZE]\n                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n                # calculate in sample acc and loss, each 50 steps\n                if i%50 == 0:\n                    val_acc, val_loss = test(size = 100)\n                    f.write(f\"{MODEL_NAME},{int(time.time())},in_sample,{round(float(acc),2)},{round(float(loss),4)}, out_of_sample,{round(float(val_acc),2)},{round(float(val_loss),4)}\\n\")","0ba1c260":"train(net)","33c64cd7":"style.use(\"ggplot\")\n\nmodel_name = \"MODEL_NAME1\" \n# grab whichever model name you want here.\n\n\ndef create_acc_loss_graph(model_name):\n    # read the file and split by new line\n    times = []\n    accuracies = []\n    losses = []\n    val_accs = []\n    val_losses = []\n    # iterate over our contents \n    with open(\"\/kaggle\/working\/modeldata.log\", \"r\") as rf:\n        contents = rf.read().split(\"\\n\")\n        for c in contents:\n            try:\n                c = c.split(',')\n                del c[2]\n                del c[4]\n                name, timestamp, acc, loss, val_acc, val_loss = c\n\n                times.append(float(timestamp))\n                accuracies.append(float(acc))\n                losses.append(float(loss))\n\n                val_accs.append(float(val_acc))\n                val_losses.append(float(val_loss))\n            except IndexError:\n                    pass\n\n    fig = plt.figure()\n    plt.rcParams['figure.figsize'] = (10.0,5.5)\n    plt.rcParams['savefig.dpi'] = 300\n    plt.rcParams['figure.dpi'] = 300\n\n    ax1 = plt.subplot2grid((2,1), (0,0))\n    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n\n\n    ax1.plot(times, accuracies, label=\"acc\")\n    ax1.plot(times, val_accs, label=\"val_acc\")\n    ax1.legend(loc=2)\n    ax2.plot(times,losses, label=\"loss\")\n    ax2.plot(times,val_losses, label=\"val_loss\")\n    ax2.legend(loc=2)\n    plt.show()\n    \ncreate_acc_loss_graph(model_name)","cd52132f":"# Convolutional Neural Network for Natural Images Classification","744f0df2":"*Hi everyone, this is crazy Allen! I am an enthusiastic learner of machine learning and deep learning. That's my first attempt in Kaggle, which is working on Natural Images Classification using Python. *","b91b4617":"## Evaluation of Model","c0ad1a3b":"## Preparing Data","b80b3f89":"## Training Model"}}