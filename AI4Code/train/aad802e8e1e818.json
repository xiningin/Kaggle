{"cell_type":{"bf475d65":"code","7737a0d2":"code","7a398fee":"code","a9561393":"code","31a5d796":"code","72794129":"code","9ab3774c":"code","9226c2f1":"code","0d2b2b89":"code","a0b34d33":"code","56185379":"code","b641ac0c":"code","b9f0b568":"code","5b5d54a2":"code","82b22c0d":"code","b01dee20":"code","982adc64":"code","fba28fa7":"code","060c1950":"code","1f41c02d":"code","f76f473d":"code","983371e0":"code","e8b29140":"code","1e52a8b4":"code","4a3fbaf8":"code","6055bbe8":"code","a15f9f60":"code","f90ee012":"code","c74f62a8":"code","26f24ea6":"code","fa2bada2":"markdown","e7533e63":"markdown","24d6c35a":"markdown","eaf50f4e":"markdown","d3e2358c":"markdown","c9025885":"markdown","d5ac175b":"markdown","853b11d5":"markdown","6500482b":"markdown","dadd72b0":"markdown","c1bd777e":"markdown","9b61ef2a":"markdown","04f6244b":"markdown","e7b2059f":"markdown","43532752":"markdown","b1f0de87":"markdown","7aefa5df":"markdown","1de25331":"markdown","0dec6010":"markdown","d2782102":"markdown","d73a3dc5":"markdown","4fa93500":"markdown","af7664bf":"markdown","92b34710":"markdown","abe4b260":"markdown","fee34109":"markdown","b02f21f0":"markdown","00b66639":"markdown","b59a63a5":"markdown"},"source":{"bf475d65":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import KFold, StratifiedKFold","7737a0d2":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\nX = df.drop('Class', axis=1)\ny = pd.DataFrame(df['Class'])","7a398fee":"df.info()","a9561393":"print(y.describe().round(decimals=2))\n\nsns.countplot('Class', data=df)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\nplt.show()\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","31a5d796":"X.describe().round(3)","72794129":"fig = plt.figure(figsize=(12,20))\nplt.title('Distribution of Feature Attributes')\nfor i in range(len(X.columns)):\n    fig.add_subplot(8,4,i+1)\n    sns.distplot(X.iloc[:,i].dropna())\n    plt.xlabel(X.columns[i])\n\nplt.tight_layout()\nplt.show()","9ab3774c":"fig = plt.figure(figsize=(12,20))\nplt.title('Numerical Feature (before dropping identified outliers)')\nfor i in range(len(X.columns)):\n    fig.add_subplot(8,4,i+1)\n    sns.scatterplot(X.iloc[:,i], y.iloc[:,0])\n    plt.xlabel(X.columns[i])\n\nplt.tight_layout()\nplt.show()","9226c2f1":"correlation = X.corr()\n\nf, ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation of numerical attributes', size=30)\nsns.heatmap(correlation)\nplt.show()\n","0d2b2b89":"y_corr = pd.DataFrame(X.corrwith(y.Class),columns=[\"Correlation with target variable\"])\ny_corr_sorted= y_corr.sort_values(by=['Correlation with target variable'],ascending=False)\ny_corr_sorted","a0b34d33":"fig = plt.figure(figsize=(6,10))\nplt.title('Correlation with target variable')\na=sns.barplot(y_corr_sorted.index,y_corr_sorted.iloc[:,0],data=y_corr)\na.set_xticklabels(labels=y_corr_sorted.index,rotation=90)\nplt.tight_layout()\nplt.show()","56185379":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)","b641ac0c":"from imblearn.over_sampling import SMOTE\nresampling_method = SMOTE()\n\nX_train_resampled, y_train_resampled = resampling_method.fit_resample(X_train, y_train)","b9f0b568":"sns.countplot('Class', data=y_train_resampled)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\nplt.show()\nprint('No Frauds:', round(y_train_resampled['Class'].value_counts()[0]), 'data points')\n\nprint('Frauds Data points Before SMOTE:', round(df['Class'].value_counts()[1]))\nprint('Frauds Data points After SMOTE:', round(y_train_resampled['Class'].value_counts()[1]), 'data points')\n\nFraud_obs_added = round((y_train_resampled['Class'].value_counts()[1])-df['Class'].value_counts()[1])\nprint('Frauds Data points Added:',Fraud_obs_added , 'data points')\n\n\nprint('No Frauds:', round(y_train_resampled['Class'].value_counts()[0]\/len(y_train_resampled) * 100,2), '% of the dataset')\nprint('Frauds:', round(y_train_resampled['Class'].value_counts()[1]\/len(y_train_resampled) * 100,2), '% of the dataset')\n","5b5d54a2":"y_corr = pd.DataFrame(X_train_resampled.corrwith(y_train_resampled.Class),columns=[\"Correlation with target variable\"])\ny_corr_sorted= y_corr.sort_values(by=['Correlation with target variable'],ascending=False)\ny_corr_sorted","82b22c0d":"fig = plt.figure(figsize=(6,10))\nplt.title('Correlation with target variable')\na=sns.barplot(y_corr_sorted.index,y_corr_sorted.iloc[:,0],data=y_corr)\na.set_xticklabels(labels=y_corr_sorted.index,rotation=90)\nplt.tight_layout()\nplt.show()","b01dee20":"from imblearn.pipeline import Pipeline \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score, make_scorer,roc_curve\n\nresampling = SMOTE(random_state=4)\nroc_auc = make_scorer(roc_auc_score)","982adc64":"training_cv_list={}\ntraining_cv_best_auc={}\n\ntest_best_auc = {}\ntest_best_classification_report={}\ntest_confusion_matrix={}","fba28fa7":"from sklearn.linear_model import LogisticRegression\n\nmodel_name = \"Logistics Regression (Ridge)\"\nmodel=LogisticRegression(max_iter=4000, penalty=\"l2\")\n\nparam_grid = [{model_name+'__C':[0.01,0.1,1,10,100]}]","060c1950":"#LR\npipeline = Pipeline([('SMOTE', resampling), (model_name, model)])\n\n\nclf=GridSearchCV(pipeline,param_grid,cv=5, scoring=roc_auc, n_jobs=-1)\nclf.fit(X_train,y_train.to_numpy())\n\n\n#Record the best grid search paramters into the list.\ntraining_cv_list[model_name]=clf\ntraining_cv_best_auc[model_name]=clf.best_score_\n#print out the best param and best score \nprint('best training param:',clf.best_params_)\nprint('best training score', clf.best_score_)\nprint('\\n')\n\n#make prediction on X_test\npred_prob_y = clf.predict_proba(X_test)\npred_y = clf.predict(X_test)\n\n#compute auc, classification report,confusion matrix \naucroc = roc_auc_score(y_test,pred_prob_y[:,1])\nconfusionmatrix = confusion_matrix(y_test,pred_y)\nclassificationreport = classification_report(y_test,pred_y)\nfpr, tpr, thresholds = roc_curve(y_test, pred_prob_y[:,1])\n\n#store results\ntest_best_auc[model_name]=aucroc\ntest_best_classification_report[model_name]=confusionmatrix\ntest_confusion_matrix[model_name]=classificationreport\n\n#print results\nprint('test auc roc:',aucroc)\nprint('test confusion matrix: \\n',confusionmatrix)\nprint('test classification report \\n', classificationreport)\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC Plot: '+model_name)","1f41c02d":"model_name = \"Logistics Regression (Ridge)\"\nmodel=LogisticRegression(max_iter=4000, penalty=\"l1\",solver='liblinear')\n\nparam_grid = [{model_name+'__C':[0.01,0.1,1,10,100]}]","f76f473d":"pipeline = Pipeline([('SMOTE', resampling), (model_name, model)])\n\n\nclf=GridSearchCV(pipeline,param_grid,cv=5, scoring=roc_auc, n_jobs=-1)\nclf.fit(X_train,y_train.to_numpy())\n\n\n#Record the best grid search paramters into the list.\ntraining_cv_list[model_name]=clf\ntraining_cv_best_auc[model_name]=clf.best_score_\n#print out the best param and best score \nprint('best training param:',clf.best_params_)\nprint('best training score', clf.best_score_)\nprint('\\n')\n\n#make prediction on X_test\npred_prob_y = clf.predict_proba(X_test)\npred_y = clf.predict(X_test)\n\n#compute auc, classification report,confusion matrix \naucroc = roc_auc_score(y_test,pred_prob_y[:,1])\nconfusionmatrix = confusion_matrix(y_test,pred_y)\nclassificationreport = classification_report(y_test,pred_y)\nfpr, tpr, thresholds = roc_curve(y_test, pred_prob_y[:,1])\n\n#store results\ntest_best_auc[model_name]=aucroc\ntest_best_classification_report[model_name]=confusionmatrix\ntest_confusion_matrix[model_name]=classificationreport\n\n#print results\nprint('test auc roc:',aucroc)\nprint('test confusion matrix: \\n',confusionmatrix)\nprint('test classification report \\n', classificationreport)\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC Plot: '+model_name)","983371e0":"from sklearn.tree import DecisionTreeClassifier\n\nmodel=DecisionTreeClassifier()\nmodel_name = 'DecisionTreeClassifier'\nparam_grid = [{model_name+'__'+'splitter':['best','random'],model_name+'__'+'max_depth':[1,2,3,5,10,20]}]","e8b29140":"pipeline = Pipeline([('SMOTE', resampling), (model_name, model)])\n\nclf=GridSearchCV(pipeline,param_grid,cv=5, scoring=roc_auc, n_jobs=-1)\nclf.fit(X_train,y_train.to_numpy())\n\n\n#Record the best grid search paramters into the list.\ntraining_cv_list[model_name]=clf\ntraining_cv_best_auc[model_name]=clf.best_score_\n#print out the best param and best score \nprint('best training param:',clf.best_params_)\nprint('best training score', clf.best_score_)\nprint('\\n')\n\n#make prediction on X_test\npred_prob_y = clf.predict_proba(X_test)\npred_y = clf.predict(X_test)\n\n#compute auc, classification report,confusion matrix \naucroc = roc_auc_score(y_test,pred_prob_y[:,1])\nconfusionmatrix = confusion_matrix(y_test,pred_y)\nclassificationreport = classification_report(y_test,pred_y)\nfpr, tpr, thresholds = roc_curve(y_test, pred_prob_y[:,1])\n\n#store results\ntest_best_auc[model_name]=aucroc\ntest_best_classification_report[model_name]=confusionmatrix\ntest_confusion_matrix[model_name]=classificationreport\n\n#print results\nprint('test auc roc:',aucroc)\nprint('test confusion matrix: \\n',confusionmatrix)\nprint('test classification report \\n', classificationreport)\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC Plot: '+model_name)","1e52a8b4":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_name = 'BaggingDecisionTreeClassifier'\nmodel=BaggingClassifier(DecisionTreeClassifier())\n\nparam_grid = [{model_name+'__'+'base_estimator__splitter': ['best','random'],\n              model_name+'__'+'base_estimator__max_depth':np.arange(1,5)\n              }]","4a3fbaf8":"pipeline = Pipeline([('SMOTE', resampling), (model_name, model)])\n\n\nclf=GridSearchCV(pipeline,param_grid,cv=5, scoring=roc_auc, n_jobs=-1)\nclf.fit(X_train,y_train.to_numpy())\n\n\n#Record the best grid search paramters into the list.\ntraining_cv_list[model_name]=clf\ntraining_cv_best_auc[model_name]=clf.best_score_\n#print out the best param and best score \nprint('best training param:',clf.best_params_)\nprint('best training score', clf.best_score_)\nprint('\\n')\n\n#make prediction on X_test\npred_prob_y = clf.predict_proba(X_test)\npred_y = clf.predict(X_test)\n\n#compute auc, classification report,confusion matrix \naucroc = roc_auc_score(y_test,pred_prob_y[:,1])\nconfusionmatrix = confusion_matrix(y_test,pred_y)\nclassificationreport = classification_report(y_test,pred_y)\nfpr, tpr, thresholds = roc_curve(y_test, pred_prob_y[:,1])\n\n#store results\ntest_best_auc[model_name]=aucroc\ntest_best_classification_report[model_name]=confusionmatrix\ntest_confusion_matrix[model_name]=classificationreport\n\n#print results\nprint('test auc roc:',aucroc)\nprint('test confusion matrix: \\n',confusionmatrix)\nprint('test classification report \\n', classificationreport)\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC Plot: '+model_name)","6055bbe8":"from sklearn.ensemble import RandomForestClassifier\nparam_grid = {\n    model_name+'__'+'max_depth':[1,2,3,5,10,20]}\n\nmodel=RandomForestClassifier()\nmodel_name = 'RandomForestClassifier'\n","a15f9f60":"pipeline = Pipeline([('SMOTE', resampling), (model_name, model)])\n\n\nclf=GridSearchCV(pipeline,param_grid,cv=5, scoring=roc_auc, n_jobs=-1)\nclf.fit(X_train,y_train.to_numpy())\n\n\n#Record the best grid search paramters into the list.\ntraining_cv_list[model_name]=clf\ntraining_cv_best_auc[model_name]=clf.best_score_\n#print out the best param and best score \nprint('best training param:',clf.best_params_)\nprint('best training score', clf.best_score_)\nprint('\\n')\n\n#make prediction on X_test\npred_prob_y = clf.predict_proba(X_test)\npred_y = clf.predict(X_test)\n\n#compute auc, classification report,confusion matrix \naucroc = roc_auc_score(y_test,pred_prob_y[:,1])\nconfusionmatrix = confusion_matrix(y_test,pred_y)\nclassificationreport = classification_report(y_test,pred_y)\nfpr, tpr, thresholds = roc_curve(y_test, pred_prob_y[:,1])\n\n#store results\ntest_best_auc[model_name]=aucroc\ntest_best_classification_report[model_name]=confusionmatrix\ntest_confusion_matrix[model_name]=classificationreport\n\n#print results\nprint('test auc roc:',aucroc)\nprint('test confusion matrix: \\n',confusionmatrix)\nprint('test classification report \\n', classificationreport)\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC Plot: '+model_name)","f90ee012":"# from sklearn.svm import SVC\n\n# model=SVC()\n# model_name = 'SVC'\n\n# param_grid = [\n#   {model_name+'__'+'C': [2**-5,2**-3,2**-1,2**1,2**3,2**5,2**7,2**9,2**11,2**13,2**15], model_name+'__'+'kernel': ['linear','poly','rbf','sigmoid'],\n#    model_name+'__'+'gamma':['scale','auto',2**-5,2**-3,2**-1,2**1,2**3,2**5,2**7,2**9,2**11,2**13,2**15]\n#   }]\n\n","c74f62a8":"# %%time\n# #SVM\n# pipeline = Pipeline([('SMOTE', resampling), (model_name, model)])\n\n\n# clf=GridSearchCV(pipeline,param_grid,cv=5, scoring=roc_auc, n_jobs=-1)\n# clf.fit(X_train,y_train.to_numpy())\n\n\n# #Record the best grid search paramters into the list.\n# training_cv_list[model_name]=clf\n# training_cv_best_auc[model_name]=clf.best_score_\n# #print out the best param and best score \n# print('best training param:',clf.best_params_)\n# print('best training score', clf.best_score_)\n# print('\\n')\n\n# #make prediction on X_test\n# pred_prob_y = clf.predict_proba(X_test)\n# pred_y = clf.predict(X_test)\n\n# #compute auc, classification report,confusion matrix \n# aucroc = roc_auc_score(y_test,pred_prob_y[:,1])\n# confusionmatrix = confusion_matrix(y_test,pred_y)\n# classificationreport = classification_report(y_test,pred_y)\n# fpr, tpr, thresholds = roc_curve(y_test, pred_prob_y[:,1])\n\n# #store results\n# test_best_auc[model_name]=aucroc\n# test_best_classification_report[model_name]=confusionmatrix\n# test_confusion_matrix[model_name]=classificationreport\n\n# #print results\n# print('test auc roc:',aucroc)\n# print('test confusion matrix: \\n',confusionmatrix)\n# print('test classification report \\n', classificationreport)\n# plt.plot(fpr, tpr, marker='.')\n# plt.title('ROC Plot: '+model_name)","26f24ea6":"best_auc_score = pd.DataFrame.from_dict(test_best_auc,orient='index')\nbest_auc_score","fa2bada2":"### 3.2 SMOTE resampling","e7533e63":"### 4.6 Support Vector Classifier","24d6c35a":"### Dataset\nThe following are the features of the dataset.\n- Time\n- V1\n- V2\n- V3\n- V4\n- V5\n- V6\n- V7\n- V8\n- V9\n- V10\n- V11\n- V12\n- V13\n- V14\n- V15\n- V16\n- V17\n- V18\n- V19\n- V20\n- V21\n- V22\n- V23\n- V24\n- V25\n- V26\n- V27\n- V28\n- Amount\n- Class","eaf50f4e":"### 4.2 Logistic Regression Classifier (Lasso)","d3e2358c":"Lets first look at the characteristics of the data.\n\nThere are a total of 30 variables including the target variable (Class). There are 30 numerical features. Only Time and Amount are not the results of PCA. There a total of 284807 samples with no missing values.\n\n","c9025885":"### Correlation between features attributes and target variable\n\nRevisiting the correlation between feature attributes and the target variable, we observed that quite some features have high correlation with the target variable (V4, V11, V2, V7,V3,V17, V9, V16, V12, V14). Perhaps variables that have close to zero correlation can be be dropped. For now, lets just keep these variables.","d5ac175b":"We shall now resample the trainset using SMOTE.","853b11d5":"## 1. Introduction\nThe purpose of the project is to predict credit card fraud cases based on transaction records. Below are some characteristics of the data:\n1. The dataset is greatly imbalanced, as only 0.17% of the data are fraud transaction. \n2. To protect the privacy of customers, most of the 30 input variables are the results of PCA component. The only interpretable input variables are time and amount. \n\nThe issue with imbalanced data is that if the prediction made was simply non-fraud for all observations, we would have a high accuracy score. We are unable to train the model accurately as the model will learn from the non-fraud transactions and we will also be unable to assess the performance of the model accurately. \n\nTo handle the issue of imbalance target variable, we will apply resampling technique to bring the dataset to an equal amount of observations from each target class. The resampling technique we will use will be SMOTE(Synthetic Minority Oversampling Technique). SMOTE over-sample the minority class by taking samples of the target class and make estimation based on feature of its neighbors. \n\nWe will train the model based on Logistic Regression, Decision Trees and SVM. \n\n","6500482b":"### Correlation between feature attributes and target variable\nBy right, we should be able to observe some form of correlation between the feature attributes and target attributes. As the target variable class is highly imbalanced, filled with mostly 0, we will not be able to correlation among them. We shall on check this again after resampling the data.","dadd72b0":"### 3.3 Distribution of the target variables","c1bd777e":"## 4. Modelling","9b61ef2a":"- we created 198996 data points for the minority Fraud classes from its previous small sample size of 492. \n- Important to note that: we are adding a huge amount of \"artificial\" samples from a small size of original observation. This ought to introduce some \"bias\". Unsure about the impact.\n- on the other hand, compared to the other way, which is to undersample the majority class (Non-fraud cases), we have retained 198504 observation points of the majority class. ","04f6244b":"We first split the data into the train and test set before resampling. It is important to note that the test data should not be resampled and resampling done before the splitting the data is the wrong procedure.","e7b2059f":"### 1.2 Importing modules","43532752":"### Correlation among feature attributes\n\nAs expected, there are little correlation between the principal component reduced features. Principcal Component reduce high dimension attributes into lower dimension attributes by creating attributes that are uncorrelated with each other. Looking and Time and Amount, there doesnt seem to have high correlationship with other attributes. There is little processing required.","b1f0de87":"As we can observed, after the resampling, the classes are more balanced.","7aefa5df":"## 2. Exploratory Data Analysis\n","1de25331":"### 1.3 Importing of Data","0dec6010":"### 2.2 Distribution of feature attributes.","d2782102":"## 3. Data Preprocessing\n","d73a3dc5":"### 4.3 Decision Trees","4fa93500":"### 4.4 Decision Tree with Bagging","af7664bf":"### 4.5 Random Forest","92b34710":"### 4.1 Logistic Regression Classifier (Ridge)","abe4b260":"One can compare this graph with the one before and notice the increase in correlations after resampling. Beforehand, the correlations are buried by the imbalanced characteristic of the dataset.\n\nThe correlation result from above means that there are some form of underlying relationships between the feature attributes and target attributes. These should aid the training of the model to fit the data.","fee34109":"The following are the distribution of the feature attributes.","b02f21f0":"### 3.1 Splitting the data into train and test set","00b66639":"We shall now train the model. Gridsearch, together wih K-fold, will be used to find the best hyperparameters that can fit the model to the data. The training data will be trained using the following algorithms:\n\n- Logistic Regression (Lasso)\n- Logistic Regression (Ridge)\n- Decision Tree Classifier\n- Decision Tree Classifier (with bagging)\n- Random Forest Classifier\n- Support Vector Classifier \n\nWe will then test the trained model on the test set to evaluate the best model. ","b59a63a5":"### 2.1 Distribution of target variable\nWe observed that the amount of each class is greatly imbalanced, only 0.17% of the dataset belongs to the other class. We will over-sample the minority class with SMOTE later on."}}