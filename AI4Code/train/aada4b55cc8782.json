{"cell_type":{"1ceba58b":"code","27f98d5b":"code","6f569a8f":"code","49a0e543":"code","cf4e2af9":"code","9007ceb5":"code","aef97efa":"code","554787ef":"code","a328b875":"code","9bdd3b13":"code","78d2c44f":"code","9f88f6d2":"code","d6bb63d1":"code","ecbdbb27":"code","be687123":"code","35dfe273":"code","6f0208a4":"code","3abc5fda":"code","fea17adc":"code","9ce04a27":"code","dc64c722":"code","108df98f":"code","a7b5fcfe":"code","737389a7":"markdown","78ae0c2f":"markdown","7a1509db":"markdown","964bac5e":"markdown","97c7854b":"markdown","cde8956d":"markdown","7f5c5457":"markdown","49fa4d83":"markdown","fafabb76":"markdown","ee0ff61c":"markdown"},"source":{"1ceba58b":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","27f98d5b":"import numpy as np \nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n%matplotlib inline\nimport glob\nimport pydicom\n\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom PIL import Image\n\nimport cv2 as cv\n\nimport random \n\nrandom.seed(42)","6f569a8f":"TARGET_SIZE = 512\n\ndef dicom2array(path, voi_lut = True, fix_monochrome = True):\n    \n    dicom = pydicom.read_file(path)\n    \n    \n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    \n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    \n    data = data * 255\n    \n    data = data.astype(np.uint8)\n    \n    return data\n\ndef img_vizualisation(imgs, nb_samples = 5):\n    \n    fig, axes = plt.subplots(nrows=nb_samples \/\/ 5, ncols=min(5, nb_samples), figsize=(min(5, nb_samples) * 4, 4 * (nb_samples \/\/ 5)))\n    i = 0\n    for img in imgs:\n        axes[i \/\/ 5, i % 5].imshow(np.array(img), cmap=plt.cm.gray, aspect='auto')\n        axes[i \/\/ 5, i % 5].axis('off')\n        i += 1\n    fig.show()    \n","49a0e543":"TRAIN_PATH = \"..\/input\/siim-covid19-detection\/train\/\"\n\npaths = glob.glob(TRAIN_PATH + \"*\/*\/*.dcm\")","cf4e2af9":"sampled_path = random.sample(paths, 10)\n\nsamples = []\nfor path in sampled_path:\n    img = dicom2array(path)\n    samples.append(img)","9007ceb5":"img_vizualisation(samples, 10)","aef97efa":"img_example = samples[4]\nimg_example_hist = cv.equalizeHist(img_example)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\nax1.imshow(img_example, cmap=plt.cm.gray)\nax1.axis('off')\nax1.set_title(\"Original image\")\n\nax2.imshow(img_example_hist, cmap=plt.cm.gray)\nax2.axis('off')\nax2.set_title(\"Histogram Equalization applied on the original image\")\n\nfig.show()","554787ef":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n\nax1.hist(img_example.flatten(), 256, [0, 256])\nax1.set_title(\"Original image\")\n\nax2.hist(img_example_hist.flatten(), 256, [0, 256])\nax2.set_title(\"Histogram Equalization applied on the original image\")\n\nfig.show()","a328b875":"import scipy.misc\n\nequalized_samples = []\nfor sample in samples:\n    img = cv.equalizeHist(sample)\n    equalized_samples.append(img)\n    \nimg_vizualisation(equalized_samples, 10)","9bdd3b13":"clahe = cv.createCLAHE(clipLimit=40.0, tileGridSize=(8,8))\n\nimg_example = samples[9]\nimg_example_clahe = clahe.apply(img_example)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\nax1.imshow(img_example, cmap=plt.cm.gray)\nax1.axis('off')\nax1.set_title(\"Original image\")\n\nax2.imshow(img_example_clahe, cmap=plt.cm.gray)\nax2.axis('off')\nax2.set_title(\"CLAHE applied on the original image\")\n\nfig.show()","78d2c44f":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n\nax1.hist(img_example.flatten(), 256, [0, 256])\nax1.set_title(\"Original image\")\n\nax2.hist(img_example_clahe.flatten(), 256, [0, 256])\nax2.set_title(\"CLAHE applied on the original image\")\n\nfig.show()","9f88f6d2":"clahe_samples = []\n\nclahe = cv.createCLAHE(clipLimit=40.0, tileGridSize=(8,8))\n\nfor sample in samples:\n    img = clahe.apply(sample)\n    clahe_samples.append(img)\n    \nimg_vizualisation(clahe_samples, 10)","d6bb63d1":"clahe_samples_2 = []\n\nclahe = cv.createCLAHE(clipLimit=20.0, tileGridSize=(15, 15))\n\nfor sample in samples:\n    img = clahe.apply(sample)\n    clahe_samples_2.append(img)\n    \nimg_vizualisation(clahe_samples_2, 10)","ecbdbb27":"img_example = equalized_samples[9]\n\nkernel = cv.getStructuringElement(cv.MORPH_RECT, (15, 15)) # MORPH_ELLIPSE\n\ntophat_img = cv.morphologyEx(img_example, cv.MORPH_TOPHAT, kernel)\nbothat_img = cv.morphologyEx(img_example, cv.MORPH_BLACKHAT, kernel) # Black --> Bottom\n\noutput = img_example + tophat_img - bothat_img\n\ncompare = np.concatenate((img_example, output), axis=1)\n\nplt.figure(figsize=(20,10))\nplt.imshow(compare, cmap=plt.cm.gray)\nplt.show()","be687123":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n\nax1.hist(img_example.flatten(), 256, [0, 256])\nax1.set_title(\"Original image\")\n\nax2.hist(output.flatten(), 256, [0, 256])\nax2.set_title(\"This approach on the original image\")\n\nfig.show()","35dfe273":"hat_samples = []\n\nkernel = cv.getStructuringElement(cv.MORPH_RECT, (15, 15)) # MORPH_ELLIPSE\n\nfor sample in equalized_samples:\n\n    tophat = cv.morphologyEx(sample, cv.MORPH_TOPHAT, kernel)\n    bothat = cv.morphologyEx(sample, cv.MORPH_BLACKHAT, kernel)\n    img = sample + tophat - bothat\n\n    hat_samples.append(img)\n    \nimg_vizualisation(hat_samples, 10)","6f0208a4":"img_example = samples[0]\nnoised_samples_example = cv.medianBlur(img_example, 5)\n\ncompare = np.concatenate((img_example, noised_samples_example), axis=1)\n\nplt.figure(figsize=(20,10))\nplt.imshow(compare, cmap=plt.cm.gray)","3abc5fda":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n\nax1.hist(img_example.flatten(), 256, [0, 256])\nax1.set_title(\"Original image\")\n\nax2.hist(noised_samples_example.flatten(), 256, [0, 256])\nax2.set_title(\"Noise reduction on the original image\")\n\nfig.show()","fea17adc":"\nfrom scipy.fftpack import dct, idct\n\ndef dct2(a):\n    return dct(dct(a.T, norm='ortho').T, norm='ortho')\n\ndef idct2(a):\n    return idct(idct(a.T, norm='ortho').T, norm='ortho')  \n\ndef dtc_transform(img):\n    return idct2(dct2(img))\n\nimg_example = samples[0]\nimg_idct = dtc_transform(img_example)\n\nprint(\"Check if the image are similar :\", np.allclose(img_example, img_idct))\n\ncompare = np.concatenate((img_example, img_idct), axis=1)\n\nplt.figure(figsize=(20,10))\nplt.imshow(compare, cmap=plt.cm.gray)","9ce04a27":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n\nax1.hist(img_example.flatten(), 256, [0, 256])\nax1.set_title(\"Original image\")\n\nax2.hist(img_idct.flatten(), 256, [0, 256])\nax2.set_title(\"Noise reduction on the original image\")\n\nfig.show()","dc64c722":"dct_samples = []\n\nfor sample in samples:\n    img = dtc_transform(sample)\n    dct_samples.append(img)\n    \nimg_vizualisation(dct_samples, 10)","108df98f":"channel_1 = samples[9]\nchannel_2 = clahe_samples_2[9]\nchannel_3 = hat_samples[9]\n\n\noutput = np.dstack((channel_1, channel_2, channel_3))\n\nreference = np.dstack((channel_1, channel_1, channel_1))\n\n\ncompare = np.concatenate((reference, output), axis=1)\n\nplt.figure(figsize=(20,10))\nplt.imshow(compare)\nplt.show()","a7b5fcfe":"multi_channel_samples = []\n\nfor i in range(len(samples)):\n    channel_1 = samples[i]\n    channel_2 = clahe_samples_2[i]\n    #\u00a0channel_2 = clahe_samples[i]\n    channel_3 = hat_samples[i]\n    \n    out_img = np.dstack((channel_1, channel_2, channel_3))\n    \n    multi_channel_samples.append(out_img)\n    \nimg_vizualisation(multi_channel_samples, 10)","737389a7":"# Combine the different approaches","78ae0c2f":"# CLAHE (Contrast Limited Adaptive Histogram Equalization) \n\n","7a1509db":"## Contrast Enhancement of Medical X-Ray ImageUsing Morphological Operators with OptimalStructuring Element\n","964bac5e":"### Visualization on the sample data","97c7854b":"### CLAHE with different parameters","cde8956d":"### Visualization on the sample data","7f5c5457":"### Visualization of CLAHE","49fa4d83":"# Noise reduction\n\n## Median filter \n.","fafabb76":"# Histogram equalization\n","ee0ff61c":"## DCT-based filter\n"}}