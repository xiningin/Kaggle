{"cell_type":{"a1173987":"code","b5ad19e2":"code","db173e3b":"code","5b4f23e4":"code","8c98d4e4":"code","5ba28501":"code","f55aff9d":"code","ce9bc71c":"code","9fe565d2":"code","2dfdeaf8":"code","a13003d2":"code","45666bb0":"code","499a643f":"code","6c184820":"code","3a419544":"code","3d03d945":"code","20630e46":"code","9381a081":"code","943509bc":"code","c2e5f31c":"code","b7b9f6cc":"code","a205e780":"code","8dfd60b6":"code","36d3fac7":"code","bbca9352":"code","15365eee":"code","d6b12e40":"code","da5e3f0a":"code","380d92d5":"code","7490df0d":"code","1b5632d3":"code","a04e7ce8":"code","0fde842a":"code","d32acd9e":"code","2f21452c":"code","9aa2cf66":"code","09367615":"code","ae4c7301":"code","54a9dfe7":"code","751e815d":"code","40e3553a":"code","2d3de35f":"code","ccaa4d27":"code","1793c1c8":"code","f5cfdbbc":"code","b5cca906":"code","fde6154a":"code","e277755b":"code","b46d39b9":"code","f472428e":"code","dac7c291":"code","819295d5":"code","3b641357":"code","0f77ec69":"code","27ca7ddc":"markdown","bf8b44a3":"markdown","b37f6589":"markdown","ebb241b1":"markdown","31216cd0":"markdown","c83832fe":"markdown","6af8292c":"markdown","dc7fd69d":"markdown","88af7d07":"markdown","7ad0d497":"markdown","80c9e24a":"markdown","77fd7515":"markdown","76a4210f":"markdown","a86dee8b":"markdown","92657536":"markdown","517a4528":"markdown","8aae8c67":"markdown","91a94bdd":"markdown","61626293":"markdown","5985c408":"markdown","e6b6ce9e":"markdown"},"source":{"a1173987":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5ad19e2":"import seaborn as sns\nimport matplotlib.pyplot as plt","db173e3b":"titanic_df =  pd.read_csv(\"..\/input\/titanic\/train.csv\")","5b4f23e4":"titanic_df.head()\n","8c98d4e4":"titanic_df = titanic_df.drop(labels=['Name','Ticket','Cabin'],axis=1)","5ba28501":"titanic_df.head()","f55aff9d":"titanic_df['Age'].isnull().value_counts()","ce9bc71c":"titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)","9fe565d2":"titanic_df['Age'].isnull().value_counts()","2dfdeaf8":"#checking for null values in any of the columns\ntitanic_df.info()","a13003d2":"sns.countplot(x='Survived',data=titanic_df,hue='Pclass');","45666bb0":"sns.countplot(x='Survived',data=titanic_df,hue='Sex');","499a643f":"sns.heatmap(titanic_df.isnull());","6c184820":"df = pd.concat([titanic_df, pd.get_dummies(titanic_df['Sex'], prefix='Sex')], axis=1); \ndf = df.drop('Sex',axis=1)\ndf","3a419544":"df2 =  pd.concat([df, pd.get_dummies(df['Pclass'],prefix='Pclass')], axis=1,); \ndf2 = df2.drop('Pclass',axis=1)\ndf2","3d03d945":"train =  pd.concat([df2, pd.get_dummies(df['Embarked'],prefix='Embarked')], axis=1,); \ntrain = train.drop('Embarked',axis=1)\ntrain","20630e46":"titanic_test =  pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ntitanic_test = titanic_test.drop(['Name','Ticket','Cabin'],axis=1)\ntitanic_test\n","9381a081":"titanic_test['Age'].isnull().value_counts()","943509bc":"titanic_test['Age'].fillna(titanic_test['Age'].mean(),inplace=True)","c2e5f31c":"titanic_test['Age'].isnull().value_counts()","b7b9f6cc":"#checking for null values in any of the columns\ntitanic_test.info()","a205e780":"sns.heatmap(titanic_test.isnull());","8dfd60b6":"titanic_test['Fare'].isnull().value_counts()","36d3fac7":"titanic_test['Fare'].fillna(titanic_test['Fare'].mean(),inplace=True)","bbca9352":"titanic_test['Fare'].isnull().value_counts()","15365eee":"titanic_test","d6b12e40":"df4 = pd.concat([titanic_test, pd.get_dummies(titanic_test['Sex'], prefix='Sex')], axis=1); \ndf4 = df4.drop('Sex',axis=1)\ndf4","da5e3f0a":"df5 = pd.concat([df4, pd.get_dummies(titanic_test['Pclass'], prefix='Pclass')], axis=1); \ndf5 = df5.drop('Pclass',axis=1)\ndf5","380d92d5":"test = pd.concat([df5, pd.get_dummies(titanic_test['Embarked'], prefix='Embarked')], axis=1);\ntest = test.drop('Embarked',axis=1)\ntest \n","7490df0d":"train","1b5632d3":"train = train.reindex(columns=['PassengerId','Age','SibSp','Parch','Fare','Sex_female','Sex_male','Pclass_1','Pclass_2','Pclass_3','Embarked_C','Embarked_Q','Embarked_S','Survived'])","a04e7ce8":"train","0fde842a":"test","d32acd9e":" from sklearn.preprocessing import MinMaxScaler","2f21452c":"scaler = MinMaxScaler()\n","9aa2cf66":"scaled_train = scaler.fit_transform(train)","09367615":"train[train.columns] = scaled_train","ae4c7301":"train","54a9dfe7":"scaled_test = scaler.fit_transform(test)","751e815d":"test[test.columns] = scaled_test","40e3553a":"test","2d3de35f":"from sklearn.linear_model import LogisticRegression","ccaa4d27":"model = LogisticRegression()\n","1793c1c8":"X = train.drop('Survived',axis=1)\ny = train['Survived']","f5cfdbbc":"model.fit(X,y)","b5cca906":"preds = model.predict(test)\nmodel.score(X,y)","fde6154a":"preds","e277755b":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","b46d39b9":"final = pd.DataFrame(data = preds,columns = [\"Survived\"])","f472428e":"final[\"PassengerId\"] = test[\"PassengerId\"]","dac7c291":"final = final[[\"PassengerId\",\"Survived\"]]","819295d5":"final[\"Survived\"] = final[\"Survived\"].apply(lambda x : np.int32(x))","3b641357":"final_sub = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':preds})\n\n#Visualizing the first 5 rows\nfinal_sub.head()","0f77ec69":"#Converting DataFrame to a csv file that can be uploaded\n\nfilename = 'Titanic Predictions 1.csv'\n\nfinal_sub.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","27ca7ddc":"## As there is lot of variation between different data values. So we need to preprocess the data","bf8b44a3":"### Modifying passenger's ID to original as it was scaled during Preprocessing","b37f6589":"Reordering the train Data\n","ebb241b1":"Preprocessing Test Data","31216cd0":"Preprocessing Train Data","c83832fe":"### Importing Libraries","6af8292c":"Fare is having some null values","dc7fd69d":"## Preparing X and Y data for applying Random Forest Classifier Algorithm","88af7d07":"### As the question asks we have to predict what sort of people will survive the crash ..So lets do some visulaization to check for the same","7ad0d497":"## Creating csv to upload to Kaggle","80c9e24a":"### Since cabin , Ticket and Name Data is of No use for predicting Survival hence dropping these columns","77fd7515":"It can interpreted that most of the passengers died were Male","76a4210f":"Data is now ready for Fitting\n\nContinuing Similar data cleaning process for test data","a86dee8b":"So now we have cleared all the null values from the Age column","92657536":"**Knowing Your Data**\n\n1. survival= 'Survival'  Keys=0-No,1-Yes\n2. pclass =' Ticket class' Keys= 1 = 1st, 2 = 2nd, 3 = 3rd\n3. Sex = 'Sex'\n4. Age = 'Age in years' \n5. sibsp = '# of siblings \/ spouses aboard the Titanic'\n6. parch = '# of parents \/ children aboard the Titanic'\n7. ticket = 'Ticket number'\n8. fare = 'Passenger fare'\n9. cabin = 'Cabin Number'\n10. embarked = 'Port of embarkation' Keys= C = Cherbourg, Q = Queenstown, S = Southampton\n","517a4528":"From the count plot it can seen that most passengers died were from 'Class 3'","8aae8c67":"As it is very clear from the heatmap that none of the values are null so we can proceed further\n\nApplying ***One hot encoding*** for the Pclass, Sex and Embarked  column as these contain categorical values.","91a94bdd":"As we can see that 177 values are null values so replacing these values with the mean value","61626293":"Applying One hot encoding for the Pclass, Sex and Embarked column as these contain categorical values.","5985c408":"The Model is Having 80% prediction score","e6b6ce9e":"### Importing Data"}}