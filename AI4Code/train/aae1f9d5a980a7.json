{"cell_type":{"1b99c95f":"code","9700a8f0":"code","026a01ac":"code","a6065956":"code","2a7628a3":"markdown","dcadbbf8":"markdown","562ec5b2":"markdown","3cf6c543":"markdown","464a358b":"markdown","ea6e5198":"markdown","782968e0":"markdown","bac83ff2":"markdown"},"source":{"1b99c95f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sqlite3 as sql\nimport csv # what is this?\n\nlimitResults = 72\nlimitFormatTypes = True\n\ndbName = \"bookdepo.db\"\nconn = sql.connect(dbName) \ndoesTableExist = \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='books';\"\ndf = pd.read_sql(doesTableExist, conn)\ntableExists = df.values.any()\nif (tableExists != True):\n    print(\"- - table does not exist yet\")\n    print(\"- - read csv\")\n    fileIn = \"\/kaggle\/input\/book-depository-dataset\/dataset.csv\"\n    df = pd.read_csv(fileIn, thousands=None)\n    print(\"- - remove commas from bestsellers col\")\n    # df[\"bestsellers-rank\"] = pd.to_numeric(df[\"bestsellers-rank\"])\n    # df.astype({'bestsellers-rank': 'int32'})\n    df['bestsellers-rank'] = df['bestsellers-rank'].str.replace(',', '')\n    print(\"- - create 'books' table\")\n    df.to_sql('books', conn)\nelse:\n    print(\"- - books table found in \" + dbName)\n\nlimitString = str(limitResults)\ncol1 = '\"authors\", \"bestsellers-rank\", \"categories\", \"description\", \"dimension-x\"'\ncol2 = '\"dimension-y\", \"dimension-z\", \"edition\", \"edition-statement\", \"for-ages\"'\ncol3 = '\"format\", \"id\", \"illustrations-note\", \"imprint\", \"index-date\"'\ncol4 = '\"isbn10\", \"isbn13\", \"lang\", \"publication-date\", \"publication-place\"'\ncol5 = '\"rating-avg\", \"rating-count\", \"title\", \"url\", \"weight\"'\nseperator = ', '\ns = seperator\ncols = col1 + s + col2 + s + col3 + s + col4 + s + col5\nqFormatIn = ' AND format IN (1,2,3,13,15,26)'\nqueryStart = 'SELECT ' + cols + ' FROM books WHERE lang = \"en\" AND description IS NOT NULL'\n# distinct ids\n# queryStart = 'SELECT COUNT(\"id\"), id FROM books WHERE lang = \"en\" AND description IS NOT NULL GROUP BY title'\nif (limitResults > 0):\n    limsql = ' LIMIT '\n    queryEnd = limsql + limitString\nelse:\n    limitString = \"\"\n    queryEnd = \"\"\n\nif (limitFormatTypes == True):\n    query = queryStart + qFormatIn + queryEnd\nelse: \n    query = queryStart + queryEnd\n\nprint(\"- - running query\")\nprint(query)\nprint(\" \")\ndf = pd.read_sql(query, conn)\n\nfileNameStart = \"booksEng\"\nfileNameLimit = limitString\nfileNameExt = \".csv\"\nfileName = fileNameStart + fileNameLimit + fileNameExt\nfileOut = fileName\n\nprint(\"- - writing to file\")\nprint(fileOut)\nprint(\" \")\ndf.to_csv(fileOut,index=False,quoting=csv.QUOTE_ALL,line_terminator='\\r\\n')\nprint (\"- - done\")","9700a8f0":"import pandas as pd\nimport sqlite3 as sql\nconn = sql.connect(\"mydb.db\") \ndoesTableExist = \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='books';\"\ndf = pd.read_sql(doesTableExist, conn)\ndf.values.any()","026a01ac":"#Show Columns\nimport pandas as pd\nimport sqlite3 as sql\nconn = sql.connect(\"mydb.db\")\nq = \"PRAGMA table_info(books)\"\nout = pd.read_sql(q, conn)\nprint(out)","a6065956":"df.dtypes","2a7628a3":"## Thanks to: \n\n* https:\/\/www.kaggle.com\/diamazov\/export-usa-names-into-csv - for showing me how to export files to csv.\n* https:\/\/stackoverflow.com\/questions\/41433269\/pandas-write-csv-file-with-windows-line-ending - solution for busted line endings in windows\n* Panagiotis Simakis and BookDepository for dataset","dcadbbf8":"## Show Columns","562ec5b2":"## Datatypes\n\nthis displays the datatypes of the dataframe (df)","3cf6c543":"Create an in-memory SQLite database.\n\n<pre>\nfrom sqlalchemy import create_engine\nengine = create_engine('sqlite:\/\/', echo=False)\n<\/pre>","464a358b":"The code above is an amateur example of how to run sql queries on a csv dataset.\n\nDespite my best efforts, this code might not do what I intended it to do, which is provide an SQL query tool for convenience in slicing up the (1m x 25) dataset.csv of the Book Depository Dataset *(from bookdepository.com)* provided by Panagiotis Simakis. If you look at the version history you'll notice a bunch of rookie mistakes and clumsiness. Swim at your own risk.","ea6e5198":"## TODO:\n\n* ~~remove thousands comma separator from bestseller-rank and similar~~\n* ~~It tooks like a column called index was added to my db, and then the output adds another unnamed (!) column with the exact same autoincrementing index - so I need to adjust the output to not return the  (two?) index columns~~\n* ~~I need to create the books table if books does not exist...~~","782968e0":"## db\n\nfor better worse I created an actual file, and didn't not use this *(which I believe is a temp db that lives, like, in memory or something like that)*","bac83ff2":"## Probably not the best way to determine if table exists...\n\nbut this is how I determine if table exists"}}