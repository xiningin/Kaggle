{"cell_type":{"bfc0b548":"code","341fa3f3":"code","bbb0887c":"code","75c9806e":"code","5371c038":"code","82f85e94":"code","162cd1df":"code","1ff9bc31":"code","43c9f674":"code","2d83ca0c":"code","c550a8f3":"code","521583b9":"code","651ba7ac":"code","f77df6ac":"code","aa950f6e":"code","65320163":"code","5c29637e":"code","34ff8318":"code","d599e118":"code","9167dd2e":"code","296c65a1":"code","9a70e4e3":"code","a7718012":"code","46a44bdc":"code","55769066":"code","b21fedb7":"code","005940a8":"code","8ccd8e0e":"code","8ac44e1e":"code","48503d37":"code","899be525":"code","c2f17230":"code","dcbc6ffc":"code","e3aaf5a7":"code","9cbd1df0":"code","fa58f2a5":"markdown","94bde795":"markdown","cf7cecc5":"markdown","42d3736d":"markdown","3fbd8f5a":"markdown","aac85f0f":"markdown","64f1c334":"markdown","1a9ad679":"markdown","c0776d50":"markdown","4188138e":"markdown","d9cde6af":"markdown","d92d6a78":"markdown","00284d98":"markdown","3b0f72c2":"markdown","e40624d9":"markdown","7c9f78e8":"markdown","a760b9c2":"markdown","25dadaa9":"markdown","e3266502":"markdown","3594d398":"markdown","3643e81b":"markdown","fabefba3":"markdown","6bbbaa3e":"markdown","7bdfaef5":"markdown","44bbf608":"markdown","a27ded18":"markdown","a862f2b1":"markdown","1d830de8":"markdown","eda20759":"markdown","8d68c78a":"markdown","7ec70d35":"markdown","ea5aa656":"markdown","fe6a2b4a":"markdown","84239034":"markdown","7f89fb6d":"markdown","0c8f58aa":"markdown","fee27520":"markdown","ca5d0c42":"markdown","85395fbb":"markdown","8dd85838":"markdown","f615af9e":"markdown","22b432d5":"markdown","4769fe03":"markdown","6cbafbe5":"markdown","e5b69a67":"markdown","d373f138":"markdown","7797b0cb":"markdown","a5c95cbd":"markdown","8200cdaf":"markdown","5673a684":"markdown","f43cebc9":"markdown","c07cce7c":"markdown","f6f127f5":"markdown","6868348d":"markdown","b18b80e3":"markdown"},"source":{"bfc0b548":"import os\nimport cv2\nimport random\nimport shutil\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom keras.preprocessing.image import ImageDataGenerator,load_img\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D,Flatten,MaxPooling2D,Dense,GlobalAveragePooling2D,Dropout,BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ReduceLROnPlateau","341fa3f3":"import zipfile\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/\"+'train'+\".zip\",\"r\") as z:\n    z.extractall(\".\")","bbb0887c":"Y = []\npath = \".\/train\"\nfilenames = os.listdir(path)\nfor img in os.listdir(path):\n    val = img.split(\".\")[0]\n    if val == \"dog\":\n        Y.append('1')\n    else:\n        Y.append('0')\n\ndf = pd.DataFrame({\n    'filename' : filenames,\n    'category' : Y\n})","75c9806e":"df.head()","5371c038":"df.tail()","82f85e94":"plt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    plt.subplot(4, 3, i+1)\n    sample = random.choice(filenames)\n    filename = path+'\/'+sample\n    image = imread(filename)\n    plt.imshow(image)\nplt.tight_layout()\nplt.show()","162cd1df":"train_df,val_df = train_test_split(df,test_size=0.2,random_state = 42)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","1ff9bc31":"train_df.shape","43c9f674":"val_df.shape","2d83ca0c":"train_df['category'].value_counts().plot.bar()","c550a8f3":"val_df['category'].value_counts().plot.bar()","521583b9":"batch_size = 32\nepochs = 30\ntrain_size = train_df.shape[0]\nval_size = val_df.shape[0]\nimg_hieght = 128\nimg_width = 128\nimg_channels = 3","651ba7ac":"train_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 15,\n    horizontal_flip = True,\n    zoom_range = 0.2,\n    shear_range = 0.1,\n    fill_mode = 'reflect',\n    width_shift_range = 0.1,\n    height_shift_range = 0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    \".\/train\",\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_hieght,img_width),\n    batch_size = batch_size,\n    class_mode = 'binary'\n)","f77df6ac":"example_df = train_df.sample(n=1)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \".\/train\",\n    x_col='filename',\n    y_col='category',\n    target_size=(img_hieght,img_width),\n    class_mode='raw'\n)","aa950f6e":"plt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    plt.subplot(4, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","65320163":"val_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    \".\/train\",\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_hieght,img_width),\n    batch_size = batch_size,\n    class_mode = 'binary'\n)","5c29637e":"model = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape = (img_hieght,img_width,img_channels)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1,activation='sigmoid'))","34ff8318":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n                                            patience=2,\n                                            factor=0.5,\n                                            min_lr = 0.00001,\n                                            verbose = 1)\ncallbacks = [learning_rate_reduction]","d599e118":"model.summary()","9167dd2e":"model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])","296c65a1":"model.fit_generator(\n    train_generator,\n    epochs = epochs,\n    validation_data =  val_generator,\n    steps_per_epoch = train_size\/\/batch_size,\n    validation_steps = val_size\/\/batch_size,\n    callbacks = callbacks\n)","9a70e4e3":"model.save(\"model.h5\")","a7718012":"# model = load_model(\"\/kaggle\/input\/mode-file\/model.h5\")","46a44bdc":"score = model.evaluate_generator(val_generator)\nprint(score[1]*100)","55769066":"score = model.evaluate_generator(train_generator)\nprint(score[1]*100)","b21fedb7":"conf_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n)\n\nconf_generator = conf_datagen.flow_from_dataframe(\n    val_df,\n    \".\/train\",\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_hieght,img_width),\n    batch_size = batch_size,\n    shuffle = False,\n    class_mode = 'binary'\n)","005940a8":"y_predict = model.predict_generator(conf_generator)","8ccd8e0e":"y_predict = np.where(y_predict > 0.5, 1, 0)","8ac44e1e":"p = conf_generator.classes\nq = y_predict\np = np.array(p)\nq = q.flatten()","48503d37":"cfm = confusion_matrix(p, q)\nprint(cfm)\nax= plt.subplot()\nsns.heatmap(cfm, annot=True, ax = ax);\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels');\nax.set_title('Confusion Matrix');\nax.xaxis.set_ticklabels(['cats', 'dogs'])\nax.yaxis.set_ticklabels(['cats', 'dogs'])","899be525":"print(classification_report(p,q))","c2f17230":"path = \"\/kaggle\/input\/test-images\/dog.jpeg\"\nimg = cv2.imread(path)\nplt.imshow(img)\nimg = cv2.resize(img,(128,128))\nimg = np.reshape(img,[1,128,128,3])\nimg = np.divide(img,255)\nresult = model.predict(img)\nif result[0] >= 0.5:\n    print(\"According to our model's prediction below image is of a Dog\")\nelse:\n    print(\"According to our model's prediction below image is of a Cat\")","dcbc6ffc":"shutil.rmtree(\".\/train\")","e3aaf5a7":"# from keras.applications.resnet50 import ResNet50","9cbd1df0":"# base_model = ResNet50(include_top=False,weights=None,input_shape=(128,128,3))\n# res_model = base_model.output\n# res_model = GlobalAveragePooling2D()(res_model)\n# res_model = Dropout(0.5)(res_model)\n# predictions = Dense(1,activation='sigmoid')(res_model)\n# model = Model(inputs = base_model.input,outputs = predictions)","fa58f2a5":"Here we see few last values of our dataframe using df.tail()","94bde795":"**Saving the Model**","cf7cecc5":"We want to draw confusion matrix on validation dataset for our trained model so for that purpose we need to use argument shuffle = \"False\" in our generator because we want predicted and true labels for validation dataset. So for that we made two iterators to validation dataset in which one is used as validation dataset (val_generator) and one (conf_generator) for drawing confusion matrix.","42d3736d":"**Confusion Matrix**","3fbd8f5a":"Transfer learning involves using all or parts of a model trained on a related task.Keras provides a range of pre-trained models that can be loaded and used wholly or partially via the Keras Applications API.\nA useful model for transfer learning is one of the ResNet models, such as ResNet-50 with 50 layers that at the time it was developed, achieved top results. We can use the feature extraction part of the model and add a new classifier part of the model that is tailored to the dogs and cats dataset. Specifically, we can hold the weights of all of the convolutional layers fixed during training, and only train new fully connected layers that will learn to interpret the features extracted from the model and make a binary classification.\nThis can be achieved by loading the ResNet-50 model, removing the fully connected layers from the output-end of the model, then adding the new fully connected layers to interpret the model output and make a prediction. The classifier part of the model can be removed automatically by setting the \u201cinclude_top\u201d argument to \u201cFalse\u201c, which also requires that the shape of the input also be specified for the model, in this case (128, 128, 3).","aac85f0f":"**Fit Model**","64f1c334":"**Training Accuracy**","1a9ad679":"![image.png](attachment:image.png)","c0776d50":"Models often benefit from reducing the learning rate by a factor once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.Basically if learning rate is too low the model requires many updates before reaching minimum point so we need to increase leraning rate but if it gets increaed too much then it causes drastic updates which leads to degradation of performance so at that time we need to reduce the learning rate. We are taking care of this thing in our model with this callback (ReduceLROnPlateau).","4188138e":"Finally we will compile the model .There are 3 things to mention here : Optimizer,Loss, Metrics\n* Optimizer :- To minimize cost function we use different methods For ex :- like gradient descent, stochastic gradient descent. So these are call optimizers. We are using a default one here which is adam.\n* Loss :- To make our model better we either minimize loss or maximize accuracy. Neural Networks always minimize loss. To measure it we can use different formulas like 'categorical_crossentropy' or 'binary_crossentropy'. Here I have used binary_crossentropy.\n* Metrics :- This is to denote the measure of your model. Can be accuracy or some other metric.","d9cde6af":"We are now going to train our compiled model using the train iterator (train_generator) and use the val iterator (val_generator) as a validation dataset during training.The number of steps for the train and validation iterators must be specified. This is the number of batches that will comprise one epoch. This can be specified via the length of each iterator, and will be the total number of images in the train and validation directories divided by the batch size (32).The model will be fit for 30 epochs.","d92d6a78":"**Validation Accuracy**","00284d98":"Here we are going to calculate model's accuracy on training set itself.","3b0f72c2":"A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.So here we are going to draw confusion matrix for our model with use of sklearn.metrics.confusion_matrix inbuilt function. What can we learn from this matrix ?\n* There are two possible predicted classes: 0 and 1. If we were predicting the dog, for example, 1 would mean image represents dog, and 0 would mean that image represents cat.\n* true positives (TP): These are cases in which we predicted 1 (the image is of dog), and the image is of dog.\n* true negatives (TN): We predicted 0, and the image is of cat.\n* false positives (FP): We predicted 1, but the image is of cat. (Also known as a \"Type I error.\")\n* false negatives (FN): We predicted 0, but the image is of dog. (Also known as a \"Type II error.\")","e40624d9":"**Import Library**","7c9f78e8":"Here we will see the prediction of our model on a new image with use of model.predict function","a760b9c2":"**Training Dataframe shape**","25dadaa9":"model.summary() gives the description of the architecture of our model.","e3266502":"**Validation Dataframe shape**","3594d398":"Here we are splitting our dataset into two parts. We are separating 20% of our dataset images for validation purpose and keeping rest for training purpose.This is done because we want to validate our trained model on a new set of images and not on the same set of images on which the model is trained. Therefore we want a different set of images apart from our training set upon which we can test our model and see the performance of the trained model on new unseen images.","3643e81b":"**Resnet**","fabefba3":"In this section, we can develop a convolutional neural network model for the dogs vs. cats dataset.\n\n*Layers needed by CNN*\n\n* ** Conv2D** :- Basic Convolutional layer which is used to extract features from our image.\n* ** MaxPooling ** :- CNN has a concept of max pooling. After every convoulution we get some values in a kernel. However in max pooling we select max kernel value.It helps us to reduce unnecessary noise from our data and keep only useful values for training.\n* **  BatchNormalization** :- This layer helps for normalization of our input values which helps in fast learning of our model.\n* **  Droupout** :- Dropout works by probabilistically removing, or \u201cdropping out,\u201d inputs to a layer, which may be input variables in the data sample or activations from a previous layer. It has the effect of simulating a large number of networks with very different network structures and, in turn, making nodes in the network generally more robust to the inputs.\n* ** Dense** :- Dense layer is needed by every neural network to finally output the result however every once in while using a Dense layer helps in making model learn.\n* **  Flatten**:- Conv2D layer returns doesn't return a flatten data hence we need Flatten layer before feeding it into final Dense layer.\n\nIn the following architecture filter size goes on increasing in each consecutive cnn layer from 32,64,128 to 256. The reason for this is that as we move forward in the layers the patterns gets more complex, hence we have to capture larger combinations of patterns. That's why we increase filter size in the subsequent layers to capture as many combinations as possible.Also here I tested model with both 3 CNN layers and 4 CNN layers and got good accuracy with 4 CNN layers so due to that I took 4 CNN layers in the final model.","6bbbaa3e":"To see our training dataframe shape we are using val_df.shape","7bdfaef5":"To see our training dataframe shape we are using train_df.shape","44bbf608":"Here we see few initial values of our dataframe using df.head()","a27ded18":"Below code can be used to load model weights from save model.h5 file. So that we don't have to go through full trainnig process again.","a862f2b1":"Here by running below code we can see from the plot that images of both dogs and cats are almost equal in both our training and validation dataset. If there is too much difference in number of dogs and cats images then it can cause problem in training of our model","1d830de8":"Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images. Data augmentation can also act as a regularization technique, adding noise to the training data, and encouraging the model to learn the same features, invariant to their position in the input. Small changes to the input photos of dogs and cats might be useful for this problem, such as small shifts and horizontal flips. These augmentations can be specified as arguments to the ImageDataGenerator used for the training dataset. The augmentations should not be used for the validation dataset, as we wish to evaluate the performance of the model on the unmodified photographs.                    \nWe can use the flow_from_dataframe() function on the data generator and create one iterator for each of the train and validation set. With the help of flow_from_dataframe method you can directly pass the Pandas DataFrame which has the mapping between filenames of the images and their labels..We must specify that the problem is a binary classification problem via the \u201cclass_mode\u201d argument, and to load the images with the size of 128\u00d7128\u00d73 pixels via the \u201ctarget_size\u201d argument. We will fix the batch size at 32.","eda20759":"The Dogs & Cats is a foundational problem for a basic CNN(convolutional neural network) model which involves classifying images as a dog or a cat.The dataset can be used for learning how to develop,evaluate and use convolutional deep learning neural networks for classification of images. This includes how to develop a robust test harness for estimating the performance of the model, exploring improvements for the model by changing the paramters of the model, saving and loading the model to make predicitions on new data. In this article, we will discover how to develop a CNN to classify images of dogs and cats.\n\nAfter reading this article, you will know :\n* How to load and prepare the images for training purpose.\n* How to split data for training and validation purpose.\n* How to apply Data Augmentation to the data.\n* How to develop a CNN model using keras and how to choose various parameters for improving performance of the model.\n* How to evaluate performance of our model.\n* How to save and load a model for further predictions.\n* How to draw the confusion matrix for trained model.\n* How to predict a new image from trained model.","8d68c78a":"**Dogs VS Cats Classification Problem**","7ec70d35":"![image.png](attachment:image.png)\nThis image is just an example of cnn model, it not describes our exact model","ea5aa656":"**Prepare Training Data**","fe6a2b4a":"Now our dataset contains only images of dogs and cats with filenames like 'dog.1.png' or 'cat.255.png'. Here we have prepared our label dataset by splitting image name with '.'  eg  if image name is 'dog.1.png' we split it by '.' as delimiter and extract first part of image name ('dog' here ) and if it is dog the we append 1 in list else we append 0 in list.So now basically we have our dataset comprising of images and labels corresponding to each images \n* if label = 1 , image corresponds to dog and \n* label = 0 if image corresponds to cat.\n\nWe have stored filenames and labels using pandas dataframe.","84239034":"Author : Kanish Anand , AI data engineer","7f89fb6d":"**Building the Model**","0c8f58aa":"The photos will have to be reshaped prior to modeling so that all images have the same shape. So we will choose some image height and width constants which will be used later to reshape all images while training process. Here we choose image height and image width as 128,128. That is 25,000 images with 128x128x3 pixels each, or 1,228,800,000 32-bit pixel values.","fee27520":"Once fit, we can save the final model to an .h5 file by calling the save() function on the model and pass in the chosen filename.","ca5d0c42":"Here we will see working of our training image generator by applying augmentation on a single image selected from our training dataframe.","85395fbb":"**Total Count**","8dd85838":"**Selecting Image Size**","f615af9e":"**Plot Random Dataset Image**","22b432d5":"**Prediction**","4769fe03":"We can see by running below code 9 different variations of a single image created by data augmentation techniques. We can see how these 9 images differ only by some properties like horizontal flip, zoom etc from each other.","6cbafbe5":"**Training Generator**","e5b69a67":"Here we are defining constants to be used in our model code. So as to make our code modular we define all constants in a separate cell.\n","d373f138":"The classification report visualizer displays the precision, recall, F1, and support scores for the model.Here we are using sklearn.metrics.classification_reports function to see the measures.","7797b0cb":"Looking at a few random images in the directory, we can see that the images are coloured and have different shapes and sizes. For example, let\u2019s load and plot some random images of dataset in a single figure. Running below code creates a figure showing some random images from the dataset.We can see that some images are landscape format, some are portrait format, and some are square.","a5c95cbd":"**Callbacks**","8200cdaf":"**Validation Generator**","5673a684":"**Working of Image Generator**","f43cebc9":"The dataset can be downloaded for free from the Kaggle website.\nDownload the dataset by visiting the Dogs vs. Cats Data page and click the \u201cDownload All\u201d button.\nDataset Link : https:\/\/www.kaggle.com\/c\/dogs-vs-cats\nThis will download the 850-megabyte file \u201cdogs-vs-cats.zip\u201d to your workstation.\nUnzip the file and you will see train.zip, train1.zip and a .csv file. Unzip the train.zip file, as we will be focusing only on this dataset.\nYou will now have a folder called \u2018train\/\u2018 that contains 25,000 .jpg files of dogs and cats. The photos are labeled by their filename, with the word \u201cdog\u201d or \u201ccat\u201c. ","c07cce7c":"Now we will calculate our model's accuracy on validation set with use of keras  *.evaluate_generator()* function. We have used score[1]*100 because output of evaluate_generator() is a list of which second element represents accuracy of model on passed dataset.","f6f127f5":"**Train Test Split**","6868348d":"**Constants**","b18b80e3":"We will not apply any data augmentation technique like horizontal flip, zoom etc on validation set because we are not going to use this for training purpose."}}