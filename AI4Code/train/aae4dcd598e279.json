{"cell_type":{"1ddd5304":"code","7ff7241c":"code","b27856a9":"code","84ffd6ef":"code","0c80540e":"code","fb6190c4":"code","d3a5f167":"code","58eb90de":"code","d96ef3fe":"code","c71a798d":"code","afbe5bc6":"code","b4dc8f73":"code","43bdb5c9":"code","30a6ffc9":"code","5302f67b":"code","bf917759":"code","de0cb843":"code","53b431d9":"code","7098d9cb":"code","3e0fe81c":"code","f76abec0":"code","4eb52d3b":"code","bddd339c":"code","ffeb41d7":"code","74df6d1a":"code","66abe10f":"code","4eff8582":"code","62f9c1e4":"code","be9b82c2":"code","120a39da":"markdown","190fa40e":"markdown","ebe1a8ff":"markdown","fb4b8cd8":"markdown","7e72595e":"markdown","b34b4b2d":"markdown","28dc3f56":"markdown","ee219b4c":"markdown","e9b84cd4":"markdown","e83f1c86":"markdown","9bab8bed":"markdown","d8006988":"markdown","3990b8c4":"markdown","fd9a2df1":"markdown","57d5e348":"markdown","9707bd9c":"markdown","9db90240":"markdown","6e09ac1b":"markdown","935f5950":"markdown","e4e0d583":"markdown","3f474d51":"markdown","e8a1ee57":"markdown","0927854f":"markdown","60535c1d":"markdown","2d760edf":"markdown","3e00a33c":"markdown","26bac04f":"markdown","8dc45b6e":"markdown"},"source":{"1ddd5304":"import pandas as pd\ndf = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')\ndf.head()","7ff7241c":"df.info()","b27856a9":"y = df['class']\nX = df.drop(columns=['class'],axis=1)\nX.head()","84ffd6ef":"X = pd.get_dummies(X)\nX.head()","0c80540e":"y = y.replace({'e':0,'p':1})","fb6190c4":"y.value_counts()","d3a5f167":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)","58eb90de":"X_train.shape , X_test.shape","d96ef3fe":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression().fit(X_train,y_train)\nlog.score(X_train,y_train)","c71a798d":"y_pred = log.predict(X_test)\nlog.score(X_test,y_test)","afbe5bc6":"from sklearn.metrics import confusion_matrix,classification_report\nprint(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))\n","b4dc8f73":"from sklearn.svm import SVC\n\nsvc = SVC(C=0.005,kernel='linear' ).fit(X_train , y_train)\nsvc.score(X_train,y_train)","43bdb5c9":"y_pred = svc.predict(X_test)\nsvc.score(X_test,y_test)","30a6ffc9":"print(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))","5302f67b":"from sklearn.tree import DecisionTreeClassifier\ndec = DecisionTreeClassifier(max_depth=4 , min_samples_leaf=3).fit(X_train,y_train)\ndec.score(X_train,y_train)","bf917759":"y_pred = dec.predict(X_test)\ndec.score(X_test , y_test)","de0cb843":"print(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))","53b431d9":"from sklearn.ensemble import RandomForestClassifier\n\nrand = RandomForestClassifier(max_depth=8 , n_estimators=100 , min_samples_leaf=3).fit(X_train,y_train)\nrand.score(X_train,y_train)","7098d9cb":"y_pred = rand.predict(X_test)\nrand.score(X_test,y_test)","3e0fe81c":"print(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))","f76abec0":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB().fit(X_train,y_train)\nnb.score(X_train,y_train)","4eb52d3b":"y_pred = nb.predict(X_test)\nnb.score(X_test,y_test)","bddd339c":"print(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))","ffeb41d7":"from sklearn.linear_model import SGDClassifier\nsgd = SGDClassifier(max_iter=100,shuffle=True,random_state=69).fit(X_train, y_train)\nsgd.score(X_train, y_train)","74df6d1a":"y_pred = sgd.predict(X_test) \nsgd.score(X_test, y_test)","66abe10f":"print(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))","4eff8582":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=2,leaf_size=20, algorithm='kd_tree',p=1).fit(X_train,y_train)\nknn.score(X_train, y_train)   ","62f9c1e4":"y_pred = knn.predict(X_test)\nknn.score(X_test, y_test)","be9b82c2":"print(confusion_matrix(y_test, y_pred)) \nprint(classification_report(y_test, y_pred))","120a39da":"# **Random Forest**","190fa40e":"# If you like my work, an upvote would be great!","ebe1a8ff":"**This makes our work simpler!**","fb4b8cd8":"**As the data is quite balanced, we won't be required to assign class weights or upsample or downsample the data. Nice!**","7e72595e":"**Similar to SGD, KNN also gives perfect score for the test and train set!**","b34b4b2d":"# **Hello there, today we will finding out which model is best for classifying mushrooms\ud83c\udf44 as poisionus \u2620!!**","28dc3f56":"# Naive Bayes","ee219b4c":"# Let's split the data!","e9b84cd4":"**As Expected, Random Forest gives almost perfect result! **","e83f1c86":"**Next, as the label is also categorical we will convert it to numerical as well. Although this isn't required as almost all the algorithms do it if we miss it.**","9bab8bed":"**As we can see, this dataset doesn't have  missing values and all the columns are categorical!!**","d8006988":"**SGD gives us perfect score!!**","3990b8c4":"**Logistic Regression gives a very impressive result!! Sometimes less complicated algorithms produces the best results!**","fd9a2df1":"# **K-Nearest Neighbour**","57d5e348":"Decision tree gives accuracy similar to Linear SVC!!","9707bd9c":"# **Logistic Regression**","9db90240":"**Compared to other models, Gaussian Naive Bayes gives decent result without any parameter tuning**","6e09ac1b":"# As per my observation while training all these models, most of them will be able to give 100% accuracy by proper hyperparameter training","935f5950":"# **Linear SVC**","e4e0d583":"# So, final verdict - Because of the simplicity of the dataset almost all the models give perfect score!","3f474d51":"**Lets seperate the label and data**","e8a1ee57":"# **Decision Tree**","0927854f":"# Training","60535c1d":"** Linear SVC also give great results, with higher value for 'C' we can get higher accuracy as well!**","2d760edf":"# **Stochastic Gradient Descent**","3e00a33c":"**So let's first read the dataframe!**","26bac04f":"**That is enough data to build a good model!**","8dc45b6e":"**As all the columns are categorical, let's just one-hot encode them all**"}}