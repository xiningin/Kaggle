{"cell_type":{"df08b1f5":"code","984d0a13":"code","44974809":"code","bd37af9a":"code","0a512c0c":"code","fc0a4613":"code","7c05e219":"code","eb5c9d2c":"code","bff51ac6":"code","a4c5fd6d":"code","a68e772f":"code","81f9dae8":"code","3de54353":"code","4a74672a":"markdown","217a56c7":"markdown","e5759092":"markdown"},"source":{"df08b1f5":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","984d0a13":"data = pd.read_csv('..\/input\/eeg-brainwave-dataset-feeling-emotions\/emotions.csv')","44974809":"data","bd37af9a":"sample = data.loc[0, 'fft_0_b':'fft_749_b']\n\nplt.figure(figsize=(16, 10))\nplt.plot(range(len(sample)), sample)\nplt.title(\"Features fft_0_b through fft_749_b\")\nplt.show()","0a512c0c":"data['label'].value_counts()","fc0a4613":"label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}","7c05e219":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    df['label'] = df['label'].replace(label_mapping)\n    \n    y = df['label'].copy()\n    X = df.drop('label', axis=1).copy()\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    return X_train, X_test, y_train, y_test","eb5c9d2c":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","bff51ac6":"X_train","a4c5fd6d":"def custom(x):\n    return tf.keras.backend.square(tf.keras.backend.max(x)*tf.keras.backend.softmax(x))\n    \nansdict = {\"softmax\":0,\"custom\":0}\nmodel=0\n\nfor af in list(ansdict.keys()) :\n    inputs = tf.keras.Input(shape=(X_train.shape[1],))\n    expand_dims = tf.expand_dims(inputs, axis=2)\n    gru = tf.keras.layers.GRU(256, return_sequences=True)(expand_dims)\n    flatten = tf.keras.layers.Flatten()(gru)\n    if af==\"softmax\":\n        outputs = tf.keras.layers.Dense(3, activation=af)(flatten)\n    else:\n        outputs = tf.keras.layers.Dense(3, activation=custom)(flatten)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    opt=tf.keras.optimizers.SGD(lr=0.00001)\n    model.compile(\n    optimizer=opt,\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n    )\n    history = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=50,\n    callbacks=[\n    tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True\n    )\n    ]\n    )\n    model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n    ansdict[af]=model_acc\n    print(\"Test Accuracy : {:.3f}%\".format(model_acc * 100))","a68e772f":"ansdict=dict(sorted(ansdict.items(), key=lambda item: item[1]))\nansdict","81f9dae8":"fig = plt.figure(figsize = (10, 5))\n \n# creating the bar plot\nplt.bar(list(ansdict.keys()), list(ansdict.values()), \n        width = 0.1)\n \nplt.xlabel(\"Activation Functions in increasing order of accuracy\")\nplt.ylabel(\"Accuracy in %\")\nplt.title(\"Accracy % for different activation functions\")\nplt.show()","3de54353":"y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_test))))\n\ncm = confusion_matrix(y_test, y_pred)\nclr = classification_report(y_test, y_pred, target_names=label_mapping.keys())\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\nplt.xticks(np.arange(3) + 0.5, label_mapping.keys())\nplt.yticks(np.arange(3) + 0.5, label_mapping.keys())\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","4a74672a":"# Preprocessing","217a56c7":"# Results","e5759092":"# Modeling"}}