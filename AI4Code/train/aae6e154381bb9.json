{"cell_type":{"e8f71882":"code","303e5b1d":"code","367bda44":"code","4225e025":"code","c9c74635":"code","a87641e8":"code","277caba8":"code","e349f57d":"code","0accbf53":"code","195a9281":"code","3e1b82d6":"code","d9bfed66":"code","5c25b46f":"code","8180ead4":"code","48ee144b":"code","79bf6233":"code","18187509":"code","833fcebc":"code","88eaaac5":"code","8bf1a1a8":"code","6f46f675":"code","484f4122":"code","dc34742d":"code","8a6a3620":"code","eea7e242":"markdown","ab0f5ee8":"markdown","a43b589d":"markdown"},"source":{"e8f71882":"import numpy  as np\nimport pandas as pd\nimport glob\n\nimport matplotlib.pylab as plt\nimport matplotlib.cm as cm\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","303e5b1d":"from tensorflow.python.client import device_lib \nprint(device_lib.list_local_devices())","367bda44":"from keras.models import Sequential, Model\nfrom keras.optimizers import SGD, RMSprop, Adam, Nadam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\n\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.layers import Activation, Flatten, Input, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D \nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D","4225e025":"housenumbers = glob.glob('..\/input\/svhn-preproccessed-fragments\/housenumbers\/*')\nhousenumbers","c9c74635":"train_images = pd.read_csv('..\/input\/svhn-preproccessed-fragments\/housenumbers\/train_images.csv')\ntrain_labels = pd.read_csv('..\/input\/svhn-preproccessed-fragments\/housenumbers\/train_labels.csv')\n\ntest_images = pd.read_csv('..\/input\/svhn-preproccessed-fragments\/housenumbers\/test_images.csv')\ntest_labels = pd.read_csv('..\/input\/svhn-preproccessed-fragments\/housenumbers\/test_labels.csv')\n\nextra_images = pd.read_csv('..\/input\/svhn-preproccessed-fragments\/housenumbers\/extra_images.csv')\nextra_labels = pd.read_csv('..\/input\/svhn-preproccessed-fragments\/housenumbers\/extra_labels.csv')","a87641e8":"# every row consist of 1024 pixel of an image\ntrain_images.head()","277caba8":"train_labels.head()","e349f57d":"train_images = train_images.iloc[:,1:].as_matrix().astype('float32')","0accbf53":"train_images[100]","195a9281":"train_labels = train_labels.iloc[:,1:].as_matrix().astype('int16')\n\ntest_images = test_images.iloc[:,1:].as_matrix().astype('float32')\ntest_labels = test_labels.iloc[:,1:].as_matrix().astype('int16')\n\nextra_images = extra_images.iloc[:,1:].as_matrix().astype('float32')\nextra_labels = extra_labels.iloc[:,1:].as_matrix().astype('int16')\n","3e1b82d6":"print('Label: ', train_labels[100])\nplt.imshow(train_images[100].reshape(32,32), cmap=plt.cm.bone);\n","d9bfed66":"def digit_to_categorical(data):\n    n = data.shape[1]\n    data_cat = np.empty([len(data), n, 11])    \n    for i in range(n):\n        data_cat[:, i] = to_categorical(data[:, i], num_classes=11)        \n    return data_cat","5c25b46f":"x_train = np.concatenate((train_images.reshape(-1, 32, 32, 1),\n                             test_images.reshape(-1, 32, 32, 1)),\n                            axis=0)\ny_train = np.concatenate((digit_to_categorical(train_labels),\n                             digit_to_categorical(test_labels)),\n                            axis=0)\n\nx_valid = extra_images.reshape(-1, 32, 32, 1)\ny_valid = digit_to_categorical(extra_labels)\n\nn = int(len(x_valid)\/2)\nx_test, y_test = x_valid[:n], y_valid[:n]\nx_valid, y_valid = x_valid[n:], y_valid[n:]\n\nx_train.shape, x_test.shape, x_valid.shape, \\\ny_train.shape, y_test.shape, y_valid.shape\n","8180ead4":"y_test[1]","48ee144b":"y_train_list = [y_train[:, i] for i in range(5)]\ny_test_list = [y_test[:, i] for i in range(5)]\ny_valid_list = [y_valid[:, i] for i in range(5)]","79bf6233":"y_test_list","18187509":"def cnn_model():    \n    model_input = Input(shape=(32, 32, 1))\n    x = BatchNormalization()(model_input)\n        \n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(model_input)\n    x = MaxPooling2D(pool_size=(2, 2))(x) \n    \n    x = Conv2D(32, (3, 3), activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)    \n    x = BatchNormalization()(x)\n    \n    x = Conv2D(64, (3, 3), activation='relu')(x)       \n    x = Conv2D(64, (3, 3), activation='relu')(x)    \n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(128, (3, 3), activation='relu')(x)    \n    x = BatchNormalization()(x)\n              \n    x = Flatten()(x)\n    \n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    y1 = Dense(11, activation='softmax')(x)\n    y2 = Dense(11, activation='softmax')(x)\n    y3 = Dense(11, activation='softmax')(x)\n    y4 = Dense(11, activation='softmax')(x)\n    y5 = Dense(11, activation='softmax')(x)\n    model = Model(input=model_input, output=[y1,y2,y3,y4,y5])\n    \n    opt = Adam(lr=0.001, decay=10e-5)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","833fcebc":"cnn_model = cnn_model()\ncnn_checkpointer = ModelCheckpoint(filepath='weights.best.cnn.hdf5', \n                                   verbose=2, save_best_only=True)","88eaaac5":"cnn_history = cnn_model.fit(x_train, y_train_list, \n                            validation_data=(x_valid, y_valid_list), \n                            epochs=100,batch_size=128, verbose=2, \n                            callbacks=[cnn_checkpointer])","8bf1a1a8":"cnn_model.load_weights('weights.best.cnn.hdf5')\ncnn_scores = cnn_model.evaluate(x_test, y_test_list, verbose=0)\n\nprint(\"CNN Model 1. \\n\")\nprint(\"Scores: \\n\" , (cnn_scores))\nprint(\"First digit. Accuracy: %.2f%%\" % (cnn_scores[6]*100))\nprint(\"Second digit. Accuracy: %.2f%%\" % (cnn_scores[7]*100))\nprint(\"Third digit. Accuracy: %.2f%%\" % (cnn_scores[8]*100))\nprint(\"Fourth digit. Accuracy: %.2f%%\" % (cnn_scores[9]*100))\nprint(\"Fifth digit. Accuracy: %.2f%%\" % (cnn_scores[10]*100))","6f46f675":"# cnn_model.history.history","484f4122":"plt.figure(figsize=(14, 7))\n\nplt.plot(cnn_history.history['val_dense_3_acc'][20:], label = 'First digit')\nplt.plot(cnn_history.history['val_dense_4_acc'][20:], label = 'Second digit')\nplt.plot(cnn_history.history['val_dense_5_acc'][20:], label = 'Third digit')\nplt.plot(cnn_history.history['val_dense_6_acc'][20:], label = 'Fourth digit')\nplt.plot(cnn_history.history['val_dense_7_acc'][20:], label = 'Fifth digit')\n\nplt.legend()\nplt.title('Accuracy');","dc34742d":"plt.figure(figsize=(14, 7))\n\nplt.plot(cnn_history.history['val_dense_3_loss'][20:], label = 'First digit')\nplt.plot(cnn_history.history['val_dense_4_loss'][20:], label = 'Second digit')\nplt.plot(cnn_history.history['val_dense_5_loss'][20:], label = 'Third digit')\nplt.plot(cnn_history.history['val_dense_6_loss'][20:], label = 'Fourth digit')\nplt.plot(cnn_history.history['val_dense_7_loss'][20:], label = 'Fifth digit')\n\nplt.legend()\nplt.title('Loss');","8a6a3620":"avg_accuracy = sum([cnn_scores[i] for i in range(6, 11)])\/5\n\nprint(\"CNN Model. Average Accuracy: %.2f%%\" % (avg_accuracy*100))","eea7e242":"In this version we use keras , if you need the Vanilla version with tenserflow check version 4 with .mat data\nnote: in this version i used  SVHN .csv \n\nthis kernel based on [svhn-digit-recognition](https:\/\/www.kaggle.com\/olgabelitskaya\/svhn-digit-recognition)","ab0f5ee8":"### Load, Explore & Preprocess the Data","a43b589d":"Build the Model"}}