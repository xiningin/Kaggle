{"cell_type":{"75bc4176":"code","24eeeec4":"code","4101a05c":"code","2057e0a8":"code","211b2376":"code","fe87048d":"code","8b2751d5":"code","51744a96":"code","309a2363":"code","d04ee080":"code","3572f91b":"code","83c13b09":"code","1027ac0a":"code","8e94bff3":"code","1ae5b815":"code","38a6c9ad":"code","59224fde":"code","767af73f":"code","ca55f1a0":"code","17cb44b5":"code","c8233707":"code","a83a0e3a":"code","a266449f":"code","f20a33cd":"code","eb4bb0d3":"code","3776c012":"code","7ea9a8bd":"markdown","ed12b691":"markdown","7cf3084d":"markdown","975636b6":"markdown","1d8d684f":"markdown","e56ad9e5":"markdown","f756bcf1":"markdown"},"source":{"75bc4176":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24eeeec4":"import pandas as pd\nimport numpy as np\nimport re\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom tqdm import tqdm","4101a05c":"from sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.dummy import DummyClassifier\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom xgboost import XGBRegressor, XGBRFRegressor\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import ngrams\n\nfrom string import punctuation","2057e0a8":"import warnings\nwarnings.filterwarnings('ignore')","211b2376":"# set plot rc parameters\n\n# jtplot.style(grid=False)\nplt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = '#464646'\n#plt.rcParams['axes.edgecolor'] = '#FFFFFF'\nplt.rcParams['figure.figsize'] = 10, 7\nplt.rcParams['text.color'] = '#666666'\nplt.rcParams['axes.labelcolor'] = '#333333'\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['xtick.color'] = '#666666'\nplt.rcParams['xtick.labelsize'] = 14\nplt.rcParams['ytick.color'] = '#666666'\nplt.rcParams['ytick.labelsize'] = 14\n\n# plt.rcParams['font.size'] = 16\n\nsns.color_palette('dark')\n%matplotlib inline\n\ntqdm.pandas()","fe87048d":"dftrain = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ndftest = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\nsample_submission = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')","8b2751d5":"train_data, validation = train_test_split(dftrain, test_size=0.25, random_state=21)","51744a96":"sample_submission.head()","309a2363":"dftrain.shape, dftest.shape","d04ee080":"dftrain.head()","3572f91b":"wctrain = dftrain['excerpt'].apply(lambda x: len(x.split()))\nwctest = dftest['excerpt'].apply(lambda x: len(x.split()))","83c13b09":"wctrain.max()","1027ac0a":"wctest","8e94bff3":"def clean_text(sentence):\n    # remove numbers\n    pattern = re.compile(r'[0-9]+')\n    sentence = sentence.lower()\n    sentence = pattern.sub(' ', sentence).strip()\n    # remove punctuations\n    newSentence = ''\n    for char in sentence:\n        if char not in punctuation:\n            newSentence += char\n    # Tokenize\n    word_list = word_tokenize(newSentence)\n    # stop words\n    stopwords_list = set(stopwords.words('english'))\n    # remove stop words\n    word_list = [word for word in word_list if word not in stopwords_list]\n    # stemming\n    ps  = PorterStemmer()\n    word_list = [ps.stem(word) for word in word_list]\n    # list to sentence\n    sentence = ' '.join(word_list)\n    \n    return sentence","1ae5b815":"dftrain['clean_text'] = dftrain['excerpt'].progress_apply(clean_text)","38a6c9ad":"dftest['clean_text'] = dftest['excerpt'].apply(clean_text)","59224fde":"tfidf = TfidfVectorizer()\nX = tfidf.fit_transform(dftrain['clean_text'])\nXtest = tfidf.transform(dftest['clean_text'])","767af73f":"Xtrain, Xcv, Ytrain, Ycv = train_test_split(X, dftrain['target'], test_size=0.25, random_state=21)","ca55f1a0":"def print_summary(model, Xtrain, Ytrain, Xcv, Ycv):\n    Ytrain_pred = model.predict(Xtrain)\n    Ycv_pred = model.predict(Xcv)\n    \n    train_rmse = np.sqrt(metrics.mean_squared_error(Ytrain, Ytrain_pred))\n    cv_rmse = np.sqrt(metrics.mean_squared_error(Ycv, Ycv_pred))\n    \n    print('Training RMSE: {}'.format(train_rmse))\n    print('Validation RMSE: {}'.format(cv_rmse))","17cb44b5":"xgb = XGBRegressor()\nxgb.fit(Xtrain, Ytrain)","c8233707":"print_summary(xgb, Xtrain, Ytrain, Xcv, Ycv)","a83a0e3a":"xgbrf = XGBRFRegressor()\nxgbrf.fit(Xtrain, Ytrain)","a266449f":"print_summary(xgbrf, Xtrain, Ytrain, Xcv, Ycv)","f20a33cd":"Ytest = xgb.predict(Xtest)","eb4bb0d3":"submission = pd.DataFrame({'id': dftest['id'], 'target': Ytest})","3776c012":"submission.to_csv('submission.csv', index=False)","7ea9a8bd":"## EDA","ed12b691":"## Vectorize text data","7cf3084d":"## Import Libraries","975636b6":"## Train models","1d8d684f":"## Load Data","e56ad9e5":"### XGBoost","f756bcf1":"## Prediction"}}