{"cell_type":{"a84a0d48":"code","b2560ce1":"code","1095edaf":"code","3620cea9":"code","d1a3d803":"code","66add0b8":"code","8a653a65":"code","b10eaa72":"code","8060fce2":"code","ed4e8b98":"code","e1626de7":"code","43c37de5":"code","8261b283":"code","cb5d3e74":"code","a3e99bc5":"code","56ce090e":"code","49cfcffc":"code","622695fe":"code","e6095049":"code","941190e6":"code","6d629f76":"code","3d97757e":"code","84254e41":"code","513d974c":"code","99f5e441":"code","ad3c7777":"code","cc38821f":"code","b8a9ad2e":"code","0258427d":"code","504f6553":"code","95423488":"code","98b6cde7":"code","20bcf5cd":"code","475ff985":"code","972b2e58":"code","05d058db":"code","5bb9ce45":"code","3bdbf494":"code","2279cb6d":"code","4e4c3043":"code","9697bae3":"code","1a56b32d":"code","445570b2":"code","e5deca40":"code","7b52790b":"code","3d956520":"code","5bd380bf":"code","50add5d0":"code","1f519ebe":"code","009c7fb9":"code","4d0dbe7c":"code","856bd637":"code","d70f8493":"code","e7fd3020":"code","2f07e2ab":"code","3fd207dc":"code","5cd98c17":"code","9c28adc5":"code","46a0273f":"code","38ad1da8":"code","83bdbdb8":"code","a827b85b":"code","dbb0c72d":"code","e9c05396":"code","a6f41194":"code","9516891c":"code","e422080c":"markdown","75554983":"markdown","60a7264c":"markdown","a01aefb5":"markdown","66146b3f":"markdown","e7d573a9":"markdown","b483537e":"markdown","f569b04b":"markdown","5d8e232b":"markdown","e7416d78":"markdown","d6faccdd":"markdown","3674f04c":"markdown","a388f261":"markdown","06b3608e":"markdown","d64c4a4e":"markdown","be857b42":"markdown","9f73e21b":"markdown","d3543b4c":"markdown","481be59a":"markdown","f991a41f":"markdown","9722fd07":"markdown","ac9adf75":"markdown","0bd133bb":"markdown","5df864af":"markdown","183d1153":"markdown","37bd6843":"markdown"},"source":{"a84a0d48":"import cv2\nimport pandas\nimport seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras","b2560ce1":"path1 = '..\/input\/captcha-version-2-images\/samples\/23n88.png'\npath2 = '..\/input\/captcha-version-2-images\/samples\/23mdg.png'","1095edaf":"def plot_ (img1, img2) :\n    plt.figure(figsize = (20,5))\n    \n    plt.subplot(1,2,1)\n    plt.imshow(img1, 'gray')\n    \n    plt.axis('off')\n    \n    plt.subplot(1,2,2)\n    plt.imshow(img2, 'gray')\n    \n    plt.axis('off')","3620cea9":"img1 = cv2.imread(path1, cv2.IMREAD_GRAYSCALE)\nimg2 = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)","d1a3d803":"plot_(img1, img2)","66add0b8":"thresh_img1 = cv2.adaptiveThreshold(img1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\nthresh_img2 = cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)","8a653a65":"plot_(thresh_img1, thresh_img2)","b10eaa72":"close_img1 = cv2.morphologyEx(thresh_img1, cv2.MORPH_CLOSE, np.ones((5,2), np.uint8))\nclose_img2 = cv2.morphologyEx(thresh_img2, cv2.MORPH_CLOSE, np.ones((5,2), np.uint8))","8060fce2":"plot_(close_img1, close_img2)","ed4e8b98":"dilate_img1 = cv2.dilate(close_img1, np.ones((2,2), np.uint8), iterations = 1)\ndilate_img2 = cv2.dilate(close_img2, np.ones((2,2), np.uint8), iterations = 1)","e1626de7":"plot_(dilate_img1, dilate_img2)","43c37de5":"gauss_img1 = cv2.GaussianBlur(dilate_img1, (1,1), 0)\ngauss_img2 = cv2.GaussianBlur(dilate_img2, (1,1), 0)","8261b283":"plot_(gauss_img1, gauss_img2)","cb5d3e74":"cv2.rectangle(gauss_img1, (30,12), (50,49), 0, 1)\ncv2.rectangle(gauss_img1, (50,12), (70,49), 0, 1)\ncv2.rectangle(gauss_img1, (70,12), (90,49), 0, 1)\ncv2.rectangle(gauss_img1, (90,12), (110,49),0, 1)\ncv2.rectangle(gauss_img1, (110,12),(130,49),0, 1)\n\ncv2.rectangle(gauss_img2, (30,12), (50,49), 0, 1)\ncv2.rectangle(gauss_img2, (50,12), (70,49), 0, 1)\ncv2.rectangle(gauss_img2, (70,12), (90,49), 0, 1)\ncv2.rectangle(gauss_img2, (90,12), (110,49),0, 1)\ncv2.rectangle(gauss_img2, (110,12),(130,49),0, 1)","a3e99bc5":"plot_(gauss_img1, gauss_img2)","56ce090e":"path = '..\/input\/captcha-version-2-images\/samples\/'","49cfcffc":"def t_img (img) :\n    return cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n\ndef c_img (img) :\n    return cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5,2), np.uint8))\n\ndef d_img (img) :\n    return cv2.dilate(img, np.ones((2,2), np.uint8), iterations = 1)\n\ndef b_img (img) :\n    return cv2.GaussianBlur(img, (1,1), 0)","622695fe":"import os\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array, ImageDataGenerator","e6095049":"X = []\ny = []\n\nfor image in os.listdir(path) :\n    \n    if image[6:] != 'png' :\n        continue\n    \n    img = cv2.imread(os.path.join(path, image), cv2.IMREAD_GRAYSCALE)\n    \n    img = t_img(img)\n    img = c_img(img)\n    img = d_img(img)\n    img = b_img(img)\n    \n    image_list = [img[10:50, 30:50], img[10:50, 50:70], img[10:50, 70:90], img[10:50, 90:110], img[10:50, 110:130]]\n    \n    for i in range(5) :\n        X.append(img_to_array(Image.fromarray(image_list[i])))\n        y.append(image[i])\nX = np.array(X)\ny = np.array(y)","941190e6":"print(X.shape)\nprint(y.shape)","6d629f76":"X \/= 255.0","3d97757e":"plt.figure(figsize = (20,5))\nfor i in range(5) :\n    plt.subplot(1,5,i+1)\n    plt.imshow(X[i], 'gray')\n    plt.title('Label is ' + str(y[i]))\nplt.plot()","84254e41":"temp = set(y)\nfor t in temp :\n    print('Occurance count of ' + t + ' : ' + str(len(y[y == t])))","513d974c":" temp_df = pandas.DataFrame({'labels' : [t for t in temp], 'Count' : [len(y[y==t]) for t in temp]})","99f5e441":"plt.figure(figsize = (20,7))\nseaborn.barplot(x = 'labels', y = 'Count', data = temp_df, palette = 'Blues_d')\nplt.title('Label distribution in CAPTCHAS', fontsize = 20)","ad3c7777":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\ny_combine = LabelEncoder().fit_transform(y)\ny_one_hot = OneHotEncoder(sparse = False).fit_transform(y_combine.reshape(len(y_combine),1))","cc38821f":"print('letter n : ' + str(y[1]))\nprint('label : ' + str(y_combine[1]))\nprint('Count : ' + str(len(y_combine[y_combine == y_combine[1]])))","b8a9ad2e":"info = {y_combine[i] : y[i] for i in range(len(y))}","0258427d":"print(X.shape)\nprint(y_one_hot.shape)  # one hot encoded form","504f6553":"from sklearn.model_selection import train_test_split","95423488":"X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size = 0.2, random_state = 1)","98b6cde7":"y_temp = np.argmax(y_test, axis = 1)","20bcf5cd":"temp = set(y_temp)\ntemp_df = pandas.DataFrame({'labels' : [info[t] for t in temp], 'Count' : [len(y_temp[y_temp == t]) for t in temp]})","475ff985":"plt.figure(figsize = (20,7))\nseaborn.barplot(x = 'labels', y = 'Count', data = temp_df, palette = 'Blues_d')\nplt.title('Label distribution in test set', fontsize = 20)","972b2e58":"from keras.models import Sequential \nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import Flatten\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import BatchNormalization\n\nfrom keras.layers import Dropout\nfrom keras.layers import Input","05d058db":"print(X_train.shape)\nprint(y_train.shape)","5bb9ce45":"print(X_test.shape)\nprint(y_test.shape)","3bdbf494":"def conv_layer (filterx) :\n    \n    model = Sequential()\n    \n    model.add(Conv2D(filterx, (3,3), padding = 'same', activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n    \n    return model","2279cb6d":"def dens_layer (hiddenx) :\n    \n    model = Sequential()\n    \n    model.add(Dense(hiddenx, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    return model","4e4c3043":"def cnn (filter1, filter2, filter3, hidden1, hidden2) :\n    \n    model = Sequential()\n    model.add(Input((40, 20, 1,)))\n    \n    model.add(conv_layer(filter1))\n    model.add(conv_layer(filter2))\n    model.add(conv_layer(filter3))\n    \n    model.add(Flatten())\n    model.add(dens_layer(hidden1))\n    model.add(dens_layer(hidden2))\n    \n    model.add(Dense(19, activation = 'softmax'))\n    \n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    \n    return model","9697bae3":"X_train = np.reshape(X_train, (4160, 40*20*1))","1a56b32d":"from imblearn.over_sampling import SMOTE\nX_train, y_train = SMOTE(sampling_strategy = 'auto', random_state = 1).fit_resample(X_train, y_train)","445570b2":"print(X_train.shape)\nprint(y_train.shape)","e5deca40":"X_train = np.reshape(X_train, (7866, 40, 20, 1))","7b52790b":"plt.figure(figsize = (20,20))\n\nhi = 7800\nlo = 5000\n\nfor i in range(25) :\n    plt.subplot(5,5,i+1)\n    x = np.random.randint(lo, hi)\n    plt.imshow(X_train[x], 'gray')\n    plt.title('Label is ' + str(info[np.argmax(y_train[x])]))\nplt.show()","3d956520":"traingen = ImageDataGenerator(rotation_range = 5, width_shift_range = [-2,2])\ntraingen.fit(X_train)","5bd380bf":"train_set = traingen.flow(X_train, y_train)","50add5d0":"trainX, trainy = train_set.next()","1f519ebe":"plt.figure(figsize = (20,20))\n\nhi = 32\nlo = 0\n\nfor i in range(25) :\n    plt.subplot(5,5,i+1)\n    x = np.random.randint(lo, hi)\n    plt.imshow(trainX[x], 'gray')\n    plt.title('Label is ' + str(info[np.argmax(trainy[x])]))\nplt.show()","009c7fb9":"model = cnn(128, 32, 16, 32, 32)\nmodel.summary()","4d0dbe7c":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\ncheckp = ModelCheckpoint('.\/result_model.h5', monitor = 'val_loss', verbose = 1, save_best_only = True)","856bd637":"reduce = ReduceLROnPlateau(monitor = 'val_loss', patience = 20, verbose = 1)","d70f8493":"print(X_train.shape)\nprint(y_train.shape)","e7fd3020":"history = model.fit(traingen.flow(X_train, y_train, batch_size = 32), validation_data = (X_test, y_test), epochs = 150, steps_per_epoch = len(X_train)\/32, callbacks = [checkp])","2f07e2ab":"plt.figure(figsize = (20,10))\nplt.subplot(2,1,1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.legend(['train loss','val loss'])\nplt.title('Loss function wrt epochs')\n\nplt.subplot(2,1,2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train acc' , 'val acc'])\nplt.title('Model accuracy wrt Epoch')","3fd207dc":"from keras.models import load_model","5cd98c17":"model = load_model('.\/result_model.h5')","9c28adc5":"pred = model.predict(X_test)","46a0273f":"pred = np.argmax(pred, axis = 1)\nyres = np.argmax(y_test,axis= 1)","38ad1da8":"from sklearn.metrics import accuracy_score, classification_report","83bdbdb8":"target_name = []\nfor i in sorted(info) :\n    target_name.append(info[i])","a827b85b":"target_name","dbb0c72d":"print('Accuracy : ' + str(accuracy_score(yres, pred)))\nprint(classification_report(yres, pred, target_names = target_name))","e9c05396":"def get_demo (img_path) :\n    \n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    \n    plt.imshow(img, 'gray')\n    plt.axis('off')\n    plt.show()\n    \n    img = t_img(img)\n    img = c_img(img)\n    img = d_img(img)\n    img = b_img(img)\n    \n    image_list = [img[10:50, 30:50], img[10:50, 50:70], img[10:50, 70:90], img[10:50, 90:110], img[10:50, 110:130]]\n    \n    plt.imshow(img, 'gray')\n    plt.axis('off')\n    plt.show()\n    Xdemo = []\n    for i in range(5) :\n        Xdemo.append(img_to_array(Image.fromarray(image_list[i])))\n    \n    Xdemo = np.array(Xdemo)\n    Xdemo\/= 255.0\n    \n    ydemo = model.predict(Xdemo)\n    ydemo = np.argmax(ydemo, axis = 1)\n    \n    for res in ydemo :\n        print(info[res])\n    print(img_path[-9:])","a6f41194":"get_demo('..\/input\/captcha-version-2-images\/samples\/2g783.png')\nget_demo('..\/input\/captcha-version-2-images\/samples\/2fxgd.png')\nget_demo('..\/input\/captcha-version-2-images\/samples\/88bgx.png')\nget_demo('..\/input\/captcha-version-2-images\/samples\/4yc85.png')","9516891c":"get_demo('..\/input\/captcha-version-2-images\/samples\/3g2w6.png')\nget_demo('..\/input\/captcha-version-2-images\/samples\/7wnpm.png')\nget_demo('..\/input\/captcha-version-2-images\/samples\/2mpnn.png')\nget_demo('..\/input\/captcha-version-2-images\/samples\/53mn8.png')","e422080c":"# Data augmentation and Oversampling","75554983":"# Testing on samples","60a7264c":"### SMOTE","a01aefb5":"The count of label **n** is almost twice as any other label, so more samples of this letter will be put in the test set.","66146b3f":"Perfromed numpy argmax to obtain the value which has the highest probability of being the truth value.","e7d573a9":"# Converting images to appropriate samples","b483537e":"### ImageDataGenerator","f569b04b":"# Train test split","5d8e232b":"### Dilation\nInvolves a kernel being scanned over the entire image. The maximal pixel value is calculated in the kernel region and the anchor point of the kernel is updated to that value. This causes the white region to expand in the image.","e7416d78":"### Adaptive Thresholding\nAlgorithms determine the threshold for a pixel based on its surrounding regions. So we get different thresholds for different regions of the same image which gives better result for images with varying illumination.","d6faccdd":"# Model Training","3674f04c":"#### Samples where model made errors while identification.","a388f261":"### Scale b\/w 0 and 1","06b3608e":"Oversampled images","d64c4a4e":"### ModelCheckpoint and ReduceLROnPlateau\nUsed ModelCheckpoint to retain the best perfroming model (in terms of loss), and ReduceLROnPlateau to reduce the learning in case the model stops improving.","be857b42":"### Smoothing Images (Blurring)\nInvolves convolving a low-pass filter with an image, to remove high frequency components ie. noises and edges from the image.","9f73e21b":"# Initial Analysis and Data Wrangling","d3543b4c":"#### Samples for which model identified correctly.","481be59a":"### PartitioningBatchNormalization","f991a41f":"### Closing\nDilation followed by Erosion.","9722fd07":"### One hot encoding","ac9adf75":"Augmented images with rotations and shifts.","0bd133bb":"# File description\nThe dataset contains CAPTCHA images. The images are **5 letter** words, and have noise applied (blur and a line). They are of size **200 x 50**. The file name is same as the image letters.\n\n# Aim\nRecognize the captcha letters.\n\n# Approach\nMy approach is to train a **CNN** model for every letter that occurs in the **CAPTCHA** and use this model for evaluation. We will remove all noises (ie. smooth out the images and remove that lines) and then separate out each of the 5 letters in the image and feed each one to the model independently.\n\n# Dataset can be found on [kaggle](https:\/\/www.kaggle.com\/fournierp\/captcha-version-2-images).","5df864af":"# Prediction","183d1153":"# Model Creation","37bd6843":"# Image procesing"}}