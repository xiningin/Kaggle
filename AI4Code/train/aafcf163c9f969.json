{"cell_type":{"ecaf98fc":"code","83fc70ac":"code","803d18b5":"code","69f6d974":"code","42ac7cc5":"code","42036735":"code","844f3301":"markdown","26db441c":"markdown","5573474a":"markdown","355e8050":"markdown","33e5741e":"markdown","998747ec":"markdown"},"source":{"ecaf98fc":"%matplotlib inline\nimport os,cv2,random,glob\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch, os\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport numpy as np\nfrom tqdm import tqdm\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\nfrom timm.models.layers.conv2d_same import Conv2dSame\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings(\"ignore\")","83fc70ac":"device = \"cuda\"\nepochs = 10","803d18b5":"class ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, resize=None, augmentations=None): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n        \n        if self.resize is not None:\n            image = np.transpose(image, (1,2,0))\n            image = cv2.resize(image, dsize=self.resize, interpolation=cv2.INTER_CUBIC)        \n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","69f6d974":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for i,data in enumerate(tqdm(data_loader, position=0, leave=True, desc='Training')):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","42ac7cc5":"train_labels = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntrain_labels['img_path'] = train_labels['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')\n\nimages = train_labels.img_path.values\ntargets = train_labels.target.values\nmodel=timm.create_model('tf_efficientnet_b0_ns',pretrained=False,num_classes=1000)\nmodel.load_state_dict(torch.load('..\/input\/timm-pretrained-efficientnet\/efficientnet\/efficientnet_b0_ra-3dd342df.pth'))\nmodel.classifier=nn.Linear(1280,1)\nconv_stem_wight=model.conv_stem.weight\nconv_stem_bias=model.conv_stem.bias\nmodel.conv_stem = Conv2dSame(6, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\nmodel.conv_stem.weight=torch.nn.Parameter(torch.cat((conv_stem_wight, conv_stem_wight), dim=1))\nmodel.to(device)\n\ntrain_images, valid_images, train_targets, valid_targets = train_test_split(images, targets, stratify=targets, random_state=42)\ntrain_dataset = ClassificationDataset(image_paths=train_images,\n                                     targets=train_targets,\n                                     augmentations=None)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                          batch_size=16,\n                                          shuffle=True,\n                                          num_workers=4)\n\nvalid_dataset = ClassificationDataset(image_paths=valid_images,\n                                     targets=valid_targets,\n                                     augmentations=None)\n\nvalid_loader = torch.utils.data.DataLoader(valid_dataset,\n                                          batch_size=16,\n                                          shuffle=False,\n                                          num_workers=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\nfor epoch in range(epochs):\n    train(train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n    torch.save(model.state_dict(),f'epochs:{epochs},roc_auc{roc_auc}_.pt')","42036735":"submission = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')\ntest_images = submission.img_path.values\ndummy_targets = submission.target.values\ntest_dataset = ClassificationDataset(image_paths=test_images,\n                                     targets=dummy_targets,\n                                     augmentations=None)\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=16,\n                                          shuffle=False,\n                                          num_workers=4)\n\npredictions, valid_targets = evaluate(test_loader, model, device=device)\n# normalize\npredictions = np.array(predictions)\npredictions = (predictions - predictions.min()) \/ (predictions.max() - predictions.min())\nsubmission.target = predictions\nsubmission.drop(['img_path'], axis=1, inplace=True)\nsubmission.to_csv('submission.csv', index=False)","844f3301":"# config","26db441c":"# import","5573474a":"# Dataset","355e8050":"## Inference","33e5741e":"The notebook is simple pytorch efficientnet baseline for six channels input data.I fork @SDSTony notebook,replace resnet18 with efficientnet,and change the first conv layer with pretrained weights,in order to process six channels data.I also delete some useless code compared with original notebook.If the notebook helps you,please upvote this notebook and original notebook,thanks.","998747ec":"## Train"}}