{"cell_type":{"7b4b541d":"code","e39a143a":"code","eb384f02":"code","e9c510e8":"code","1578f5db":"code","0b9a83ca":"code","54f3606c":"code","cff953b8":"code","3f732c5b":"code","aa19bec9":"code","a0fa9494":"code","235a6bce":"code","abca17f0":"code","d6785fd5":"code","4bbc1c80":"code","0a994213":"code","7ace9aa8":"code","06adfff7":"code","c192e048":"code","bc4863fb":"code","2ee12477":"code","ece6a488":"code","6033575d":"code","2a9496cf":"code","15135ff9":"code","d71315a8":"markdown","650b8b3c":"markdown"},"source":{"7b4b541d":"!nvidia-smi","e39a143a":"#from google.colab import drive\n#drive.mount('\/content\/drive')","eb384f02":"#%cd drive\/My\\ Drive\/deep-steg-alexandre\n#%ls","e9c510e8":"##!pip install tensorflow==1.14.0\n#%tensorflow_version 1.x","1578f5db":"import tensorflow\nprint(tensorflow.__version__)","0b9a83ca":"### Imports ###\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n#from keras.engine.topology import Container\nfrom keras.engine.network import Network\nfrom keras.layers import *\nfrom keras import backend\nfrom keras.models import Model\nfrom keras.preprocessing import image\nimport keras.backend as K\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport os\nimport random\nimport scipy.misc\nfrom tqdm import *\n\n%matplotlib inline","54f3606c":"### Constants ###\nDATA_DIR = \"..\/input\/tiny-imagenet\/tiny-imagenet-200\"\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\n\nIMG_SHAPE = (64, 64)\n\ndef load_dataset_small(num_images_per_class_train=10, num_images_test=500):\n    \"\"\"Loads training and test datasets, from Tiny ImageNet Visual Recogition Challenge.\n\n    Arguments:\n        num_images_per_class_train: number of images per class to load into training dataset.\n        num_images_test: total number of images to load into training dataset.\n    \"\"\"\n\n    X_train = []\n    X_test = []\n    \n    # Create training set.\n    for c in os.listdir(\"..\/input\/tiny-imagenet\/tiny-imagenet-200\/train\"):\n        c_dir = os.path.join(\"..\/input\/tiny-imagenet\/tiny-imagenet-200\/train\", c, 'images')\n        c_imgs = os.listdir(c_dir)\n        random.shuffle(c_imgs)\n        for img_name_i in c_imgs[0:num_images_per_class_train]:\n            img_i = image.load_img(os.path.join(c_dir, img_name_i))\n            x = image.img_to_array(img_i)\n            X_train.append(x)\n    random.shuffle(X_train)\n    \n    \"\"\"\n    # Create test set.\n    test_dir = os.path.join(TEST_DIR, 'images')\n    test_imgs = os.listdir(test_dir)\n    random.shuffle(test_imgs)\n    for img_name_i in test_imgs[0:num_images_test]:\n        print(\"2\")\n        img_i = image.load_img(os.path.join(test_dir, img_name_i))\n        x = image.img_to_array(img_i)\n        X_test.append(x)\n    \"\"\"\n    # Return train and test data as numpy arrays.\n    #return np.array(X_train), np.array(X_test)\n    return np.array(X_train)","cff953b8":"# Load dataset.\n#X_train_orig, X_test_orig = load_dataset_small()\nX_train_orig = load_dataset_small()\n\n# Normalize image vectors.\nX_train = X_train_orig\/255.\n#X_test = X_test_orig\/255.\n\n# Print statistics.\nprint (\"Number of training examples = \" + str(X_train.shape[0]))\nprint (\"Number of test examples = \" + str(X_train.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape)) # Should be (train_size, 64, 64, 3).","3f732c5b":"# We split training set into two halfs.\n# First half is used for training as secret images, second half for cover images.\n\n# S1: secret image1\ninput_S1 = X_train[0:X_train.shape[0] \/\/ 4]\n# S2: secret image2\ninput_S2 = X_train[X_train.shape[0] \/\/ 4 : 2*(X_train.shape[0] \/\/ 4)]\n# S3: secret image3\ninput_S3 = X_train[2*(X_train.shape[0] \/\/ 4) : 3*(X_train.shape[0] \/\/ 4)]\n\n\n\n\n# C: cover image\ninput_C = X_train[3*(X_train.shape[0] \/\/ 4):]","aa19bec9":"# Show sample images from the training dataset\nfig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 5\nfor i in range(1, columns*rows +1):\n    # Randomly sample from training dataset\n    img_idx = np.random.choice(X_train.shape[0])\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(X_train[img_idx])\nplt.show()","a0fa9494":"# Variable used to weight the losses of the secret and cover images (See paper for more details)\nbeta = 1.0\n    \n# Loss for reveal network\ndef rev_loss(s_true, s_pred):\n    # Loss for reveal network is: beta * |S-S'|\n    #return s_true-s_pred\n\n    print(s_true.shape, s_pred.shape)\n    return beta * K.sum(K.square(s_true - s_pred))\n\n# Loss for the full model, used for preparation and hidding networks\ndef full_loss(y_true, y_pred):\n    # Loss for the full model is: |C-C'| + beta * |S-S'|\n    print(y_true.shape, y_pred.shape)\n    s1_true, s2_true, s3_true, c_true = y_true[...,0:3], y_true[...,3:6], y_true[...,6:9], y_true[...,9:12]\n    s1_pred, s2_pred, s3_pred, c_pred = y_pred[...,0:3], y_pred[...,3:6], y_pred[...,6:9], y_pred[...,9:12]\n\n    #s_loss = rev_loss(s_true, s_pred)\n    s1_loss = beta * K.sum(K.square(s1_true - s1_pred))\n    s2_loss = beta * K.sum(K.square(s2_true - s2_pred))\n    s3_loss = beta * K.sum(K.square(s3_true - s3_pred))\n    c_loss = K.sum(K.square(c_true - c_pred))\n    \n    return s1_loss + c_loss + s2_loss + s3_loss\n\n\n# Returns the encoder as a Keras model, composed by Preparation and Hiding Networks.\ndef make_encoder(input_size):\n    input_S1 = Input(shape=(input_size))\n    input_S2 = Input(shape=(input_size))\n    input_S3 = Input(shape=(input_size))\n    input_C= Input(shape=(input_size))\n\n    # Preparation Network\n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_3x3_1')(input_S1)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_4x4_1')(input_S1)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_5x5_1')(input_S1)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_3x3_1')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_4x4_1')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_5x5_1')(x)\n    x1 = concatenate([x3, x4, x5])\n\n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_3x3_2')(input_S2)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_4x4_2')(input_S2)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_5x5_2')(input_S2)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_3x3_2')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_4x4_2')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_5x5_2')(x)\n    x2 = concatenate([x3, x4, x5])\n\n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_3x3_3')(input_S3)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_4x4_3')(input_S3)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep0_5x5_3')(input_S3)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_3x3_3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_4x4_3')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_prep1_5x5_3')(x)\n    x3_1 = concatenate([x3, x4, x5])\n    \n    x = concatenate([input_C, x1, x2, x3_1])\n    \n    # Hiding network\n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid0_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid1_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid2_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid3_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_hid4_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_hid5_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    output_Cprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_C')(x)\n    \n    return Model(inputs=[input_S1, input_S2, input_S3, input_C],\n                 outputs=output_Cprime,\n                 name = 'Encoder')\n\n# Returns the decoder as a Keras model, composed by the Reveal Network\ndef make_decoder1(input_size, fixed=False):\n    \n    # Reveal network\n    reveal_input = Input(shape=(input_size))\n    \n    # Adding Gaussian noise with 0.01 standard deviation.\n    input_with_noise = GaussianNoise(0.01, name='output_C_noise1')(reveal_input)\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_3x3_1')(input_with_noise)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_4x4_1')(input_with_noise)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_5x5_1')(input_with_noise)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_3x3_1')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_4x4_1')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_5x5_1')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_3x3_1')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_4x4_1')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_5x5_1')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_3x3_1')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_4x4_1')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_5x5_1')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_3x3_1')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_4x4_1')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev5_5x5_1')(x)\n    x = concatenate([x3, x4, x5])\n    \n    output_S1prime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_S1')(x)\n    \n    if not fixed:\n        return Model(inputs=reveal_input,\n                     outputs=output_S1prime)\n    else:\n        \"\"\"return Container(inputs=reveal_input,\n                         outputs=output_Sprime,\n                         name = 'DecoderFixed')\"\"\"\n        return Network(inputs=reveal_input,\n                         outputs=output_S1prime)\n        \n# Returns the decoder as a Keras model, composed by the Reveal Network\ndef make_decoder2(input_size, fixed=False):\n    \n    # Reveal network\n    reveal_input = Input(shape=(input_size))\n    \n    # Adding Gaussian noise with 0.01 standard deviation.\n    input_with_noise = GaussianNoise(0.01, name='output_C_noise2')(reveal_input)\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_3x3_2')(input_with_noise)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_4x4_2')(input_with_noise)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_5x5_2')(input_with_noise)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_3x3_2')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_4x4_2')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_5x5_2')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_3x3_2')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_4x4_2')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_5x5_2')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_3x3_2')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_4x4_2')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_5x5_2')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_3x3_2')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_4x4_2')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev5_5x5_2')(x)\n    x = concatenate([x3, x4, x5])\n    \n    output_S2prime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_S2')(x)\n    \n    if not fixed:\n        return Model(inputs=reveal_input,\n                     outputs=output_S2prime)\n    else:\n        \"\"\"return Container(inputs=reveal_input,\n                         outputs=output_S2prime,\n                         name = 'DecoderFixed')\"\"\"\n        return Network(inputs=reveal_input,\n                         outputs=output_S2prime)\n\n# Returns the decoder as a Keras model, composed by the Reveal Network\ndef make_decoder3(input_size, fixed=False):\n    \n    # Reveal network\n    reveal_input = Input(shape=(input_size))\n    \n    # Adding Gaussian noise with 0.01 standard deviation.\n    input_with_noise = GaussianNoise(0.01, name='output_C_noise2')(reveal_input)\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_3x3')(input_with_noise)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_4x4')(input_with_noise)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev0_5x5')(input_with_noise)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev1_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev2_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev3_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_3x3')(x)\n    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='relu', name='conv_rev4_4x4')(x)\n    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='relu', name='conv_rev5_5x5')(x)\n    x = concatenate([x3, x4, x5])\n    \n    output_S3prime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='relu', name='output_S3')(x)\n    \n    if not fixed:\n        return Model(inputs=reveal_input,\n                     outputs=output_S3prime)\n    else:\n        \"\"\"return Container(inputs=reveal_input,\n                         outputs=output_S2prime,\n                         name = 'DecoderFixed')\"\"\"\n        return Network(inputs=reveal_input,\n                         outputs=output_S3prime)\n\n# Full model.\ndef make_model(input_size):\n    input_S1 = Input(shape=(input_size))\n    input_S2 = Input(shape=(input_size))\n    input_S3 = Input(shape=(input_size))\n    input_C= Input(shape=(input_size))\n    \n    encoder = make_encoder(input_size)\n    \n    decoder1 = make_decoder1(input_size)\n    decoder1.compile(optimizer='adam', loss=rev_loss)\n    decoder1.trainable = False\n\n    decoder2 = make_decoder2(input_size)\n    decoder2.compile(optimizer='adam', loss=rev_loss)\n    decoder2.trainable = False\n\n    decoder3 = make_decoder3(input_size)\n    decoder3.compile(optimizer='adam', loss=rev_loss)\n    decoder3.trainable = False\n    \n    output_Cprime = encoder([input_S1, input_S2, input_S3, input_C])\n    output_S1prime = decoder1(output_Cprime)\n    output_S2prime = decoder2(output_Cprime)\n    output_S3prime = decoder3(output_Cprime)\n\n    autoencoder1 = Model(inputs=[input_S1, input_S2, input_S3, input_C],\n                        outputs=concatenate([output_S1prime, output_S2prime, output_S3prime, output_Cprime]))\n    autoencoder1.compile(optimizer='adam', loss=full_loss)\n    \n    # autoencoder2 = Model(inputs=[input_S1, input_S2, input_C],\n    #                     outputs=concatenate([output_S2prime, output_Cprime]))\n    # autoencoder2.compile(optimizer='adam', loss=full_loss)\n\n\n    return encoder, decoder1, decoder2, decoder3, autoencoder1","235a6bce":"encoder_model, reveal_model1, reveal_model2, reveal_model3, autoencoder_model = make_model(input_S1.shape[1:])","abca17f0":"def lr_schedule(epoch_idx):\n    if epoch_idx < 200:\n        return 0.001\n    elif epoch_idx < 400:\n        return 0.0003\n    elif epoch_idx < 600:\n        return 0.0001\n    else:\n        return 0.00003","d6785fd5":"NB_EPOCHS = 2\nBATCH_SIZE = 256\n\nm = input_S1.shape[0]\nloss_history = []\n#loss_history2 = []\nfor epoch in range(NB_EPOCHS):\n    np.random.shuffle(input_S1)\n    np.random.shuffle(input_S2)\n    np.random.shuffle(input_S3)\n    np.random.shuffle(input_C)\n    \n    t = tqdm(range(0, input_S1.shape[0], BATCH_SIZE),mininterval=0)\n    ae_loss = []\n    #ae_loss2 = []\n    rev_loss1 = []\n    rev_loss2 = []\n    rev_loss3 = []\n    for idx in t:\n        \n        batch_S1 = input_S1[idx:min(idx + BATCH_SIZE, m)]\n        batch_S2 = input_S2[idx:min(idx + BATCH_SIZE, m)]\n        batch_S3 = input_S3[idx:min(idx + BATCH_SIZE, m)]\n        batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n        \n        C_prime = encoder_model.predict([batch_S1, batch_S2, batch_S3, batch_C])\n        \n        ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S1, batch_S2, batch_S3, batch_C],\n                                                   y=np.concatenate((batch_S1, batch_S2, batch_S3, batch_C),axis=3)))\n        #ae_loss2.append(autoencoder_model2.train_on_batch(x=[batch_S1, batch_S2, batch_C],\n        #                                           y=np.concatenate((batch_S2, batch_C),axis=3)))\n        rev_loss1.append(reveal_model1.train_on_batch(x=C_prime,\n                                              y=batch_S1))\n        rev_loss2.append(reveal_model2.train_on_batch(x=C_prime,\n                                              y=batch_S2))\n        rev_loss3.append(reveal_model3.train_on_batch(x=C_prime,\n                                              y=batch_S3))\n        \n        # Update learning rate\n        K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n        #K.set_value(autoencoder_model2.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model1.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model2.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model3.optimizer.lr, lr_schedule(epoch))\n        \n        t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev1 {:10.2f} | Loss Rev2 {:10.2f} | Loss Rev3 {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss1), np.mean(rev_loss2), np.mean(rev_loss3)))\n    \n    autoencoder_model.save_weights('models\/model3_'+str(epoch))\n    #autoencoder_model2.save_weights('models\/model'+str(epoch))\n    \n    loss_history.append(np.mean(ae_loss))\n    #loss_history2.append(np.mean(ae_loss2))","4bbc1c80":"1# Plot loss through epochs\nplt.plot(loss_history)\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","0a994213":"for epoch in range(5):\n    np.random.shuffle(input_S1)\n    np.random.shuffle(input_S2)\n    np.random.shuffle(input_S3)\n    np.random.shuffle(input_C)\n    \n    t = tqdm(range(0, input_S1.shape[0], BATCH_SIZE),mininterval=0)\n    ae_loss = []\n    rev_loss1 = []\n    rev_loss2 = []\n    rev_loss3 = []\n    for idx in t:\n        \n        batch_S1 = input_S1[idx:min(idx + BATCH_SIZE, m)]\n        batch_S2 = input_S2[idx:min(idx + BATCH_SIZE, m)]\n        batch_S3 = input_S3[idx:min(idx + BATCH_SIZE, m)]\n        batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n        \n        C_prime = encoder_model.predict([batch_S1, batch_S2, batch_S3, batch_C])\n        \n        ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S1, batch_S2, batch_S3, batch_C],\n                                                   y=np.concatenate((batch_S1, batch_S2, batch_S3, batch_C),axis=3)))\n        rev_loss1.append(reveal_model1.train_on_batch(x=C_prime,\n                                              y=batch_S1))\n        rev_loss2.append(reveal_model2.train_on_batch(x=C_prime,\n                                              y=batch_S2))\n        rev_loss3.append(reveal_model3.train_on_batch(x=C_prime,\n                                              y=batch_S3))\n        \n        # Update learning rate\n        K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model1.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model2.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model3.optimizer.lr, lr_schedule(epoch))\n        \n        t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev1 {:10.2f} | Loss Rev2 {:10.2f} | Loss Rev3 {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss1), np.mean(rev_loss2), np.mean(rev_loss3)))\n    \n    autoencoder_model.save_weights('models\/model3_'+str(epoch+6))\n    \n    loss_history.append(np.mean(ae_loss))","7ace9aa8":"for epoch in range(50):\n    np.random.shuffle(input_S1)\n    np.random.shuffle(input_S2)\n    np.random.shuffle(input_S3)\n    np.random.shuffle(input_C)\n    \n    t = tqdm(range(0, input_S1.shape[0], BATCH_SIZE),mininterval=0)\n    ae_loss = []\n    rev_loss1 = []\n    rev_loss2 = []\n    rev_loss3 = []\n    for idx in t:\n        \n        batch_S1 = input_S1[idx:min(idx + BATCH_SIZE, m)]\n        batch_S2 = input_S2[idx:min(idx + BATCH_SIZE, m)]\n        batch_S3 = input_S3[idx:min(idx + BATCH_SIZE, m)]\n        batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n        \n        C_prime = encoder_model.predict([batch_S1, batch_S2, batch_S3, batch_C])\n        \n        ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S1, batch_S2, batch_S3, batch_C],\n                                                   y=np.concatenate((batch_S1, batch_S2, batch_S3, batch_C),axis=3)))\n        rev_loss1.append(reveal_model1.train_on_batch(x=C_prime,\n                                              y=batch_S1))\n        rev_loss2.append(reveal_model2.train_on_batch(x=C_prime,\n                                              y=batch_S2))\n        rev_loss3.append(reveal_model3.train_on_batch(x=C_prime,\n                                              y=batch_S3))\n        \n        # Update learning rate\n        K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model1.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model2.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model3.optimizer.lr, lr_schedule(epoch))\n        \n        t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev1 {:10.2f} | Loss Rev2 {:10.2f} | Loss Rev3 {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss1), np.mean(rev_loss2), np.mean(rev_loss3)))\n    \n    autoencoder_model.save_weights('models\/model3_'+str(epoch+6))\n    \n    loss_history.append(np.mean(ae_loss))","06adfff7":"for epoch in range(700):\n    np.random.shuffle(input_S1)\n    np.random.shuffle(input_S2)\n    np.random.shuffle(input_S3)\n    np.random.shuffle(input_C)\n    \n    t = tqdm(range(0, input_S1.shape[0], BATCH_SIZE),mininterval=0)\n    ae_loss = []\n    rev_loss1 = []\n    rev_loss2 = []\n    rev_loss3 = []\n    for idx in t:\n        \n        batch_S1 = input_S1[idx:min(idx + BATCH_SIZE, m)]\n        batch_S2 = input_S2[idx:min(idx + BATCH_SIZE, m)]\n        batch_S3 = input_S3[idx:min(idx + BATCH_SIZE, m)]\n        batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n        \n        C_prime = encoder_model.predict([batch_S1, batch_S2, batch_S3, batch_C])\n        \n        ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S1, batch_S2, batch_S3, batch_C],\n                                                   y=np.concatenate((batch_S1, batch_S2, batch_S3, batch_C),axis=3)))\n        rev_loss1.append(reveal_model1.train_on_batch(x=C_prime,\n                                              y=batch_S1))\n        rev_loss2.append(reveal_model2.train_on_batch(x=C_prime,\n                                              y=batch_S2))\n        rev_loss3.append(reveal_model3.train_on_batch(x=C_prime,\n                                              y=batch_S3))\n        \n        # Update learning rate\n        K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model1.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model2.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model3.optimizer.lr, lr_schedule(epoch))\n        \n        t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev1 {:10.2f} | Loss Rev2 {:10.2f} | Loss Rev3 {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss1), np.mean(rev_loss2), np.mean(rev_loss3)))\n    \n    autoencoder_model.save_weights('models\/model3_'+str(epoch+6))\n    \n    loss_history.append(np.mean(ae_loss))","c192e048":"BATCH_SIZE = 32\nfor epoch in range(400):\n    np.random.shuffle(input_S1)\n    np.random.shuffle(input_S2)\n    np.random.shuffle(input_S3)\n    np.random.shuffle(input_C)\n    \n    t = tqdm(range(0, input_S1.shape[0], BATCH_SIZE),mininterval=0)\n    ae_loss = []\n    rev_loss1 = []\n    rev_loss2 = []\n    rev_loss3 = []\n    for idx in t:\n        \n        batch_S1 = input_S1[idx:min(idx + BATCH_SIZE, m)]\n        batch_S2 = input_S2[idx:min(idx + BATCH_SIZE, m)]\n        batch_S3 = input_S3[idx:min(idx + BATCH_SIZE, m)]\n        batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n        \n        C_prime = encoder_model.predict([batch_S1, batch_S2, batch_S3, batch_C])\n        \n        ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S1, batch_S2, batch_S3, batch_C],\n                                                   y=np.concatenate((batch_S1, batch_S2, batch_S3, batch_C),axis=3)))\n        rev_loss1.append(reveal_model1.train_on_batch(x=C_prime,\n                                              y=batch_S1))\n        rev_loss2.append(reveal_model2.train_on_batch(x=C_prime,\n                                              y=batch_S2))\n        rev_loss3.append(reveal_model3.train_on_batch(x=C_prime,\n                                              y=batch_S3))\n        \n        # Update learning rate\n        K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model1.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model2.optimizer.lr, lr_schedule(epoch))\n        K.set_value(reveal_model3.optimizer.lr, lr_schedule(epoch))\n        \n        t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev {:10.2f} | Loss Rev2 {:10.2f} | Loss Rev3 {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss1), np.mean(rev_loss2), np.mean(rev_loss3)))\n    \n    autoencoder_model.save_weights('models\/model_A21_'+str(epoch))\n    \n    loss_history.append(np.mean(ae_loss))","bc4863fb":"autoencoder_model.load_weights('models\/model_A21_399')","2ee12477":"# Retrieve decoded predictions.\ndecoded = autoencoder_model.predict([input_S1, input_S2, input_S3, input_C])\ndecoded_S1, decoded_S2, decoded_S3, decoded_C = decoded[...,0:3], decoded[...,3:6], decoded[...,6:9], decoded[...,9:12]\n\n# Get absolute difference between the outputs and the expected values.\ndiff_S1, diff_S2, diff_S3, diff_C = np.abs(decoded_S1 - input_S1), np.abs(decoded_S2 - input_S2), np.abs(decoded_S3 - input_S3), np.abs(decoded_C - input_C) ","ece6a488":"def pixel_errors(input_S1, input_S2, input_S3, input_C, decoded_S1, decoded_S2, decoded_S3, decoded_C):\n    \"\"\"Calculates mean of Sum of Squared Errors per pixel for cover and secret images. \"\"\"\n    see_S1pixel = np.sqrt(np.mean(np.square(255*(input_S1 - decoded_S1))))\n    see_S2pixel = np.sqrt(np.mean(np.square(255*(input_S2 - decoded_S2))))\n    see_S3pixel = np.sqrt(np.mean(np.square(255*(input_S3 - decoded_S3))))\n    see_Cpixel = np.sqrt(np.mean(np.square(255*(input_C - decoded_C))))\n    \n    return see_S1pixel, see_S2pixel, see_S3pixel, see_Cpixel\n\ndef pixel_histogram(diff_S1, diff_S2, diff_S3, diff_C):\n    \"\"\"Calculates histograms of errors for cover and secret image. \"\"\"\n    diff_S1flat = diff_S1.flatten()\n    diff_S2flat = diff_S2.flatten()\n    diff_S3flat = diff_S3.flatten()\n    diff_Cflat = diff_C.flatten()\n    \n    fig = plt.figure(figsize=(15, 5))\n    a=fig.add_subplot(1,2,1)\n        \n    imgplot = plt.hist(255* diff_Cflat, 100, normed=1, alpha=0.75, facecolor='red')\n    a.set_title('Distribution of error in the Cover image.')\n    plt.axis([0, 250, 0, 0.2])\n    \n    a=fig.add_subplot(1,2,2)\n    imgplot = plt.hist(255* diff_S1flat, 100, normed=1, alpha=0.75, facSecolor='red')\n    a.set_title('Distribution of errors in the Secret image1.')\n    plt.axis([0, 250, 0, 0.2])\n\n    a=fig.add_subplot(1,2,3)\n    imgplot = plt.hist(255* diff_S2flat, 100, normed=1, alpha=0.75, facSecolor='red')\n    a.set_title('Distribution of errors in the Secret image2.')\n    plt.axis([0, 250, 0, 0.2])\n\n    a=fig.add_subplot(1,2,4)\n    imgplot = plt.hist(255* diff_S3flat, 100, normed=1, alpha=0.75, facSecolor='red')\n    a.set_title('Distribution of errors in the Secret image3.')\n    plt.axis([0, 250, 0, 0.2])\n    \n    plt.show()","6033575d":"# Print pixel-wise average errors in a 256 scale.\nS1_error, S2_error, S3_error, C_error = pixel_errors(input_S1, input_S2, input_S3, input_C, decoded_S1, decoded_S2, decoded_S3, decoded_C)\n\nprint (\"S1 error per pixel [0, 255]:\", S1_error)\nprint (\"S2 error per pixel [0, 255]:\", S2_error)\nprint (\"S2 error per pixel [0, 255]:\", S3_error)\nprint (\"C error per pixel [0, 255]:\", C_error)","2a9496cf":"# Plot distribution of errors in cover and secret images.\npixel_histogram(diff_S1, diff_S2, diff_S3, diff_C)","15135ff9":"# Configs for results display\n\n# Show images in gray scale\nSHOW_GRAY = False\n# Show difference bettwen predictions and ground truth.\nSHOW_DIFF = True\n\n# Diff enhance magnitude\nENHANCE = 1\n\n# Number of secret and cover pairs to show.\nn = 6\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\ndef show_image(img, n_rows, n_col, idx, gray=False, first_row=False, title=None):\n    ax = plt.subplot(n_rows, n_col, idx)\n    if gray:\n        plt.imshow(rgb2gray(img), cmap = plt.get_cmap('gray'))\n    else:\n        plt.imshow(img)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    if first_row:\n        plt.title(title)\n\nplt.figure(figsize=(14, 15))\nrand_indx = [random.randint(0, 500) for x in range(n)]\n# for i, idx in enumerate(range(0, n)):\nfor i, idx in enumerate(rand_indx):\n    n_col = 12 if SHOW_DIFF else 8\n    \n    show_image(input_C[idx], n, n_col, i * n_col + 1, gray=SHOW_GRAY, first_row=i==0, title='Cover')\n\n    show_image(input_S1[idx], n, n_col, i * n_col + 2, gray=SHOW_GRAY, first_row=i==0, title='Secret1')\n\n    show_image(input_S2[idx], n, n_col, i * n_col + 3, gray=SHOW_GRAY, first_row=i==0, title='Secret2')\n\n    show_image(input_S3[idx], n, n_col, i * n_col + 4, gray=SHOW_GRAY, first_row=i==0, title='Secret3')\n    \n    show_image(decoded_C[idx], n, n_col, i * n_col + 5, gray=SHOW_GRAY, first_row=i==0, title='Encoded')\n    \n    show_image(decoded_S1[idx], n, n_col, i * n_col + 6, gray=SHOW_GRAY, first_row=i==0, title='Decoded1')\n\n    show_image(decoded_S2[idx], n, n_col, i * n_col + 7, gray=SHOW_GRAY, first_row=i==0, title='Decoded2')\n\n    show_image(decoded_S3[idx], n, n_col, i * n_col + 8, gray=SHOW_GRAY, first_row=i==0, title='Decoded3')\n\n    \n    # if SHOW_DIFF:\n    #     show_image(np.multiply(diff_C[idx], ENHANCE), n, n_col, i * n_col + 9, gray=SHOW_GRAY, first_row=i==0, title='Diff Cover')\n        \n    #     show_image(np.multiply(diff_S1[idx], ENHANCE), n, n_col, i * n_col + 10, gray=SHOW_GRAY, first_row=i==0, title='Diff Secret1')\n\n    #     show_image(np.multiply(diff_S2[idx], ENHANCE), n, n_col, i * n_col + 11, gray=SHOW_GRAY, first_row=i==0, title='Diff Secret2')\n\n    #     show_image(np.multiply(diff_S3[idx], ENHANCE), n, n_col, i * n_col + 12, gray=SHOW_GRAY, first_row=i==0, title='Diff Secret3')\n\nplt.show()","d71315a8":"**Model**\n\nThe model is composed of three parts: The Preparation Network, Hiding Network (Encoder) and the Reveal Network. Its goal is to be able to encode information about the secret image S into the cover image C, generating C' that closely resembles C, while still being able to decode information from C' to generate the decoded secret image S', which should resemble S as closely as possible.\n\nThe Preparation Network has the responsibility of preparing data from the secret image to be concatenated with the cover image and fed to the Hiding Network. The Hiding Network than transforms that input into the encoded cover image C'. Finally, the Reveal Network decodes the secret image S' from C'. For stability, we add noise before the Reveal Network, as suggested by the paper. Although the author of the paper didn't originally specify the architecture of the three networks, we discovered aggregated layers showed good results. For both the Hiding and Reveal networks, we use 5 layers of 65 filters (50 3x3 filters, 10 4x4 filters and 5 5x5 filters). For the preparation network, we use only 2 layers with the same structure.\n\nNote that the loss function for the Reveal Network is different from the loss function for the Preparation and Hiding Networks. In order to correctly implement the updates for the weights in the networks, we create stacked Keras models, one for the Preparation and Hiding Network (which share the same loss function) and one for the Reveal Network. To make sure weights are updated only once, we freeze the weights on the layers of the Reveal Network before adding it to the full model.","650b8b3c":"# **Training**\n\n\nAlthough the author of the paper didn't explicitly described the learning rate schedule or the optimizer properties, we used our own schedule with ADAM optimizer. We train for 1000 epochs with a batch size of 32."}}