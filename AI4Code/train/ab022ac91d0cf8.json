{"cell_type":{"4b1fbe36":"code","6f502e61":"code","900320fc":"code","bb363842":"code","9254a933":"code","ae9a0cc0":"code","1c91bb8d":"code","9170ccc9":"code","73cb8146":"code","087aa064":"code","b2b2faef":"code","5931ccdb":"code","5ece5add":"code","2c37dd8c":"code","e6267bb8":"code","9a0fad98":"code","8f2bd531":"code","4c89ca54":"code","b46f338d":"code","783b560f":"code","42bbeceb":"code","c9c1c198":"markdown","7cd11d19":"markdown","5a826c1a":"markdown","1c0bd4e6":"markdown","b8292074":"markdown","72741ee2":"markdown","cc269f71":"markdown","8eb43aaf":"markdown","516304c3":"markdown","e7ef8f1c":"markdown","7500ac33":"markdown","e1e1f7a5":"markdown"},"source":{"4b1fbe36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f502e61":"import os\nos.chdir(\"..\/input\/standard-ocr-dataset\/data\")","900320fc":"\nimport tensorflow as tf\nimport datetime\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import regularizers\nimport matplotlib.pyplot as plt\nimport cv2\n\n","bb363842":"### defining some function to make our work easier\nimport matplotlib.pyplot as plt\n\n# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\ndef plot_images(images_arr, imageWidth, imageHeight):\n    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img.reshape(imageWidth, imageHeight), cmap=\"gray\")\n        ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n","9254a933":"batch_size = 32\nepochs = 50\nIMG_HEIGHT = 28\nIMG_WIDTH = 28","ae9a0cc0":"def preprocessing_fun(img):\n#     print(img.shape)\n#     print(img)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY, CV_8UC1)\n    img = cv2.GaussianBlur(img,(3,3),0)\n    img = img.reshape((28,28,1))\n    thresh = cv2.adaptiveThreshold(img, 255, 1, 1, 11, 2)\n    print(thresh.shape)\n    \n\n#     img = img.reshape((28,28,1))\n\n#     img = np.where(img>140,1,0)\n#     img  = img\/255\n#     return img","1c91bb8d":"augmented_image_gen = ImageDataGenerator(\n        rescale = 1\/255.0,\n    rotation_range=2,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    zoom_range=0.1,\n    shear_range=2,\n    brightness_range=[0.9, 1.1],\n    validation_split=0.2,\n   \n   )\n\nnormal_image_gen = ImageDataGenerator(\n    rescale = 1\/255.0,\n    validation_split=0.2,\n  \n   )\n","9170ccc9":"train_data_gen = augmented_image_gen.flow_from_directory(batch_size=batch_size,\n                                                     directory=\".\/training_data\",\n                                                     color_mode=\"grayscale\",\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     class_mode=\"categorical\",\n                                                     seed=65657867,\n                                                     subset='training')\nval_data_gen = normal_image_gen.flow_from_directory(batch_size=batch_size,\n                                                     directory=\".\/testing_data\",\n                                                     color_mode=\"grayscale\",\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     class_mode=\"categorical\",\n                                                     seed=65657867,\n                                                     subset='validation')\n","73cb8146":"sample_training_images, _ = next(train_data_gen)\nplot_images(sample_training_images[:7], IMG_WIDTH, IMG_HEIGHT)","087aa064":"# model = Sequential([\n#     Conv2D(16, 3, \n#            padding='same',\n#            activation='relu',\n#            kernel_regularizer=regularizers.l2(0.0001),\n#            input_shape=(IMG_HEIGHT, IMG_WIDTH , 1)),\n#     MaxPooling2D(),\n#     Dropout(0.2),\n#     Flatten(),\n#     Dense(\n#         50,\n#         activation='relu',\n#         kernel_regularizer=regularizers.l2(0.0001)\n#     ),\n#     Dropout(0.2),\n#     Dense(36, activation='softmax')\n# ])\n\nfrom tensorflow.keras.optimizers import SGD\n# define cnn model\ndef define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(36, activation='softmax'))\n    return model\n#     # compile model\n# \topt = SGD(lr=0.01, momentum=0.9)\n# \tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n# \treturn model","b2b2faef":"model = define_model()","5931ccdb":"import tensorflow\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n#Prepare call backs\nEarlyStop_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('\/kaggle\/working\/checkpoint',\n                             monitor = 'val_loss',mode = 'min',save_best_only= True)\nlr = ReduceLROnPlateau(monitor = 'val_loss',factor = 0.5,patience = 3,min_lr = 0.00001)\nmy_callback=[EarlyStop_callback,checkpoint]","5ece5add":"model.compile(optimizer=SGD(lr=0.01, momentum=0.9),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['categorical_accuracy'])\n\nhistory = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=train_data_gen.samples \/\/ batch_size,\n    epochs=32,\n    validation_data=val_data_gen,\n    validation_steps=val_data_gen.samples \/\/ batch_size,\n    callbacks = my_callback)","2c37dd8c":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\n\nloss = history.history['loss']\n\n\n\nval_loss = history.history['val_loss']\n\nepochs_range = range(32)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","e6267bb8":"normal_image_gen = ImageDataGenerator(\n    samplewise_center=True,\n    samplewise_std_normalization=True\n)\ntest_data_gen = normal_image_gen.flow_from_directory(batch_size=5193,\n                                                     directory=\".\/testing_data\",\n                                                     color_mode=\"grayscale\",\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     class_mode=\"categorical\")","9a0fad98":"from PIL import Image\ntest_images, test_labels = next(test_data_gen)\nfilenames = test_data_gen.filenames\ntest_pred = model.predict(test_images)","8f2bd531":"\ntrue_labels = tf.argmax(test_labels,1)","4c89ca54":"predicted_labels = tf.argmax(test_pred,1)","b46f338d":"import sklearn\nfrom sklearn.metrics import confusion_matrix,classification_report","783b560f":"confusion_matrix(true_labels, predicted_labels)","42bbeceb":"img = cv2.imread('testing_data\/N\/28333.png',0)\nimg = img\/255\nimg = cv2.resize(img, (28,28))\nimg = img.reshape((1,28,28,1))\n\ntf.argmax(model.predict(img),1)","c9c1c198":"##### Some constants to be defined ","7cd11d19":"#### Using Data Generator generate batches to train our model","5a826c1a":"## Test our Model","1c0bd4e6":"### Importing Necessary Modules ","b8292074":"### Perfect ! ","72741ee2":"### Defining our Sequential model ","cc269f71":"### Image Data Generator \nWe defined two data generators, one that augments the data to make our training more general and one that just scales and centers the data.","8eb43aaf":"**Changing the directory to data2 folder**","516304c3":"#### samples","e7ef8f1c":"### Actual training of our model","7500ac33":"this model works well but somehow 0, O is bit confusing for this model as we know","e1e1f7a5":"### Creating a Function to plot images "}}