{"cell_type":{"0ebd729b":"code","361101b5":"code","f6c791df":"code","c7efcd39":"code","fd2a90b9":"code","3754b36e":"code","44a593a5":"code","07d5ede4":"code","d7eaab5c":"code","8d5fc9ab":"code","65fb1359":"code","402500ac":"code","3264ef14":"code","fc4225e9":"code","758aec09":"code","36b0d48a":"code","1023c30f":"code","6e703d9c":"code","146ba6f0":"code","9b0e40fe":"code","2c944793":"code","252ec1fc":"code","707ce5a4":"code","b7ea0e02":"code","ae018161":"code","1394ac22":"code","1d8d2632":"code","8b029537":"code","04149c6a":"code","353129a0":"code","eea0e838":"markdown","4d4c89a1":"markdown","f601f792":"markdown","18950aa0":"markdown","3521b2bc":"markdown","d3f3cd28":"markdown","1db2c251":"markdown","b317d266":"markdown","e5f955d0":"markdown","2eed8023":"markdown","7906f8f5":"markdown","322d4531":"markdown","11733001":"markdown","957218b6":"markdown"},"source":{"0ebd729b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","361101b5":"import math\nimport tensorflow as tf\nprint(tf.__version__)\n\nnp.random.seed(2019)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","f6c791df":"data_train_file = \"..\/input\/Kannada-MNIST\/train.csv\"\ndata_test_file = \"..\/input\/Kannada-MNIST\/test.csv\"\n\ndf_train = pd.read_csv(data_train_file)\ndf_test = pd.read_csv(data_test_file)","c7efcd39":"df_train.head()","fd2a90b9":"# Notice data is shifted to the left by one column, since the label is missing\ndf_test.head()","3754b36e":"# Note this returns numpy arrays\ndef get_features_labels(df):\n    # The first column is the label.\n    labels = df['label'].values\n    \n    # Select all columns except the first\n    features = df.values[:, 1:]\/255\n    \n    return features, labels","44a593a5":"def get_features_ids(df):\n    # The first column is the id.\n    labels = df['id'].values\n    \n    # Select all columns except the first\n    features = df.values[:, 1:]\/255\n    \n    return features, labels","07d5ede4":"train_features, train_labels = get_features_labels(df_train)\ntest_features, test_labels = get_features_ids(df_test)\n# test_features = df_test.values\/255","d7eaab5c":"print(train_features.shape)\nprint(test_features.shape)\nprint(train_labels.shape)","8d5fc9ab":"# Defaults to showing data from the training set, \n# but we can provide the test data as well, and leave labels as None, to visualize test set\ndef display_by_index(index, features=train_features, labels=train_labels):\n    plt.figure()\n    \n    if labels is not None:\n        plt.title(f'Label: {labels[index]}')\n        \n    _ = plt.imshow(np.reshape(features[index, :], (28,28)), 'gray')","65fb1359":"# Visualize a training sample\ndisplay_by_index(221)","402500ac":"# Visualize a test sample\ndisplay_by_index(221, features=test_features, labels=None)","3264ef14":"df_train['label'].value_counts()","fc4225e9":"print(df_test.shape)","758aec09":"train_labels_1hot = tf.keras.utils.to_categorical(train_labels)","36b0d48a":"print(train_labels_1hot.shape)","1023c30f":"model_arch = {}","6e703d9c":"model_arch['single_layer'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","146ba6f0":"model_arch['dnn'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(200, activation='sigmoid'),\n      tf.keras.layers.Dense(60, activation='sigmoid'),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","9b0e40fe":"model_arch['dnn_relu'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(200, activation='relu'),\n      tf.keras.layers.Dense(60, activation='relu'),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","2c944793":"# lr decay function\ndef lr_decay(epoch):\n    return 0.01 * math.pow(0.6, epoch)\n\n# lr schedule callback\nlr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\n\n# Plot the decay rate\nx = []\ny = []\nfor i in range(1,10):\n    y.append(lr_decay(i))\n    x.append(i)\nplt.plot(y, x)","252ec1fc":"# Add dropout\nmodel_arch['dnn_relu_dropout'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(200, activation='relu'),\n      tf.keras.layers.Dropout(0.25),\n      tf.keras.layers.Dense(60, activation='relu'),\n      tf.keras.layers.Dropout(0.25),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","707ce5a4":"# CNN\nmodel_arch['cnn'] = [\n      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n      tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu', padding='same'),\n      tf.keras.layers.Conv2D(kernel_size=6, filters=24, activation='relu', padding='same', strides=2),\n      tf.keras.layers.Conv2D(kernel_size=6, filters=32, activation='relu', padding='same', strides=2),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(200, activation='relu'),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","b7ea0e02":"model_arch.keys()","ae018161":"model = tf.keras.Sequential(model_arch['dnn_relu_dropout'])\n\noptimizer = 'sgd'\n# optimizer = 'adam'\n# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n\n# We will now compile and print out a summary of our model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n\nmodel.summary()","1394ac22":"BATCH_SIZE=128\nEPOCHS=25","1d8d2632":"history = model.fit(train_features, train_labels_1hot, \n          epochs=EPOCHS, \n          batch_size=BATCH_SIZE, \n          validation_split=0.2,\n          callbacks=[lr_decay_callback])","8b029537":"plt.plot(history.history['acc'], color='b', label=\"Training accuracy\")\nplt.plot(history.history['val_acc'], color='r', label=\"Validation accuracy\")\nplt.legend(loc='lower right', shadow=True)","04149c6a":"predictions = model.predict_classes(test_features)\n\nsubmissions=pd.DataFrame({\"id\": list(range(0,len(predictions))),\n                         \"label\": predictions})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","353129a0":"for i in range(200,210):\n    display_by_index(i, features=test_features, labels=submissions[\"Label\"].values)\n","eea0e838":"Confirm that the shape is what we expect: 42k in train, 28k in test, with 784 pixels per row","4d4c89a1":"### Learning rate decay","f601f792":"## Training the model\nAdjust the hyper params as needed.","18950aa0":"## Preprocess data into numpy","3521b2bc":"## Creating the model \nFor this one we use a deep neural net, expecting \"okay\" results, but nothing spectacular.\n","d3f3cd28":"Turning labels into 1-hot encoding transforms the shape from 1 column to 10 columns","1db2c251":"## Spot-checking some values","b317d266":"I've created a helper function to take care of processing the features into numpy arrays, but there are many options here.","e5f955d0":"## Submission","2eed8023":"Dataset looks fairly balanced. No need to do additional work here.","7906f8f5":"## Imports","322d4531":"### Choose model architecture and compile","11733001":"## Load and explore data","957218b6":"## Visualize the numbers\nA helper function for visualizing a specific row"}}