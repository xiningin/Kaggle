{"cell_type":{"e13d38af":"code","f97a9138":"code","1c504e7d":"code","944f8924":"code","9f980ade":"code","bcf0bbd9":"code","0b5f9dc2":"code","434c11e4":"code","c4eba02a":"code","b70cd6f7":"code","cb7d1ad9":"code","36f2a0d3":"code","6acf31c9":"code","ca4e95c5":"code","cd99ee6c":"code","4ea15ad0":"code","1d660258":"code","71d9cb22":"code","fb13fe71":"code","72c6cc36":"code","0ae88ed5":"code","34eff84f":"code","e7ac5e4d":"code","00b62fd5":"code","d3babaa6":"code","85bb650f":"markdown","169a5b31":"markdown","72f4aca9":"markdown","0cdfee2b":"markdown","64324026":"markdown","6d433a0a":"markdown","699ec56d":"markdown","5618991d":"markdown","03b8a300":"markdown","26c5797e":"markdown","b1f828d9":"markdown","aaf8f9cd":"markdown","91fe4b0d":"markdown","59d87b09":"markdown","37575edf":"markdown","932a7732":"markdown","64ae386c":"markdown","0273c08e":"markdown","b1f59186":"markdown"},"source":{"e13d38af":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt # show graph\nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n\nimport os\nimport email\nfrom bs4 import BeautifulSoup","f97a9138":"path = '\/kaggle\/input\/ham-and-spam-dataset\/'\n\ntopics = []\ncontents = []\nlabels = []\nnum_mails = []\ncontent_types = []\n\ncount = 0\nerror = 0\nwrongContentType = 0\nfor label in ['ham', 'spam']:\n    filenames = os.listdir(path + label + '\/')\n    for filename in filenames:\n        count +=1\n        labels.append(1 if label == 'spam' else 0)\n        with open(os.path.join(path + label + '\/', filename), 'rb') as file:\n            email_file = email.parser.BytesParser(policy=email.policy.default).parse(file)\n            payload = email_file.get_payload()\n            num_mails.append(1 if not isinstance(payload, list) else len(payload))\n            try:\n                if email_file.get_content_type() == 'text\/plain':\n                    contents.append(email_file.get_content())\n                elif email_file.get_content_type() == 'text\/html':\n                    contents.append(BeautifulSoup(email_file.get_content()).body.text)\n                else:\n                    wrongContentType += 1\n                    contents.append('')\n                topics.append(email_file['Subject'])\n                content_types.append(email_file.get_content_type())\n            except LookupError:\n                error +=1\n                topics.append(None)\n                contents.append('')\n                content_types.append('')\n                pass\n        \ninputDF = pd.DataFrame({'topic': topics, 'content': contents, 'label': labels, 'num_mails_in_flow': num_mails, 'content_type': content_types})\nprint('# processed message: %d', count)\nprint('# failed-parsed message: %d', error)\nprint('# non-text message: %d', wrongContentType)","1c504e7d":"inputDF.describe()","944f8924":"inputDF.head(5)","9f980ade":"inputDF.loc[inputDF['content_type'] == 'text\/html'].head(5)","bcf0bbd9":"inputDF.loc[inputDF['content_type'].str.startswith('multipart')].head(5)","0b5f9dc2":"inputDF['topic_content'] = inputDF.topic.astype('U') + \" \" + inputDF.content\ninputDF.topic_content","434c11e4":"y = inputDF.label\nX = inputDF.topic_content\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y, shuffle=True)\nX_train.shape, X_test.shape","c4eba02a":"def reportTest(y_pred, y_test):\n    print(\"Classification report:\")\n    print(classification_report(y_test, y_pred))\n    print(\"Confusion matrix:\")\n    print(confusion_matrix(y_test, y_pred))\n\n    print(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred))) \n    print(\"The precision is {}\".format(precision_score(y_test, y_pred))) \n    print(\"The recall is {}\".format(recall_score(y_test, y_pred))) \n    print(\"The F1-Score is {}\".format(f1_score(y_test, y_pred))) \n    print(\"The AUC is {} \".format(roc_auc_score(y_test, y_pred)))","b70cd6f7":"def get_strategy():\n    try:\n        tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n        print('Running on TPU ', tpu_cluster_resolver.cluster_spec().as_dict()['worker'])\n        tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n        tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)\n    except ValueError as e:\n        print(e)\n        print('No TPU detected')\n        tpu = None\n        strategy = tf.distribute.get_strategy()\n    return strategy\n\nstrategy = get_strategy()","cb7d1ad9":"cv = CountVectorizer(stop_words = {'english'}, ngram_range=(1, 3))\nfeature_word_train = cv.fit_transform(X_train).toarray()\nfeature_word_test = cv.transform(X_test).toarray()","36f2a0d3":"mnb = MultinomialNB()\n\ndef checkTest(clf, X_test, y_test):\n    y_pred = clf.predict(X_test)\n    reportTest(y_pred, y_test)\n\nfor clf, clf_name in [(mnb, 'MultinomialNB')]:\n    print(\"Training for \" + clf_name)\n    clf.fit(feature_word_train, y_train)\n    checkTest(clf, feature_word_test, y_test)\n    print(\"--------------------------------------------------------------\\n\")","6acf31c9":"num_words = 8196\n\ntokenizer = Tokenizer(num_words = num_words - 1, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)\nseq_train_tokenized = tokenizer.texts_to_sequences(X_train)\nseq_test_tokenized = tokenizer.texts_to_sequences(X_test)","ca4e95c5":"max_content_length = 512\n\ntrained_word_embedding = pad_sequences(seq_train_tokenized, max_content_length)\ntest_word_embedding = pad_sequences(seq_test_tokenized, max_content_length)","cd99ee6c":"tf.keras.backend.clear_session()\n\nwith strategy.scope():\n    lstmModel = Sequential([\n        Embedding(num_words, 256, input_length=max_content_length),\n        Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n        Dropout(0.5),\n        Bidirectional(tf.keras.layers.LSTM(64)),\n        Dense(16, activation=\"relu\"),\n        Dropout(0.5),\n        Dense(2, activation='softmax')\n    ])\n\n    lstmModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n                      metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n    # lstmModel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    lstmModel.summary()","4ea15ad0":"X_new = np.array(trained_word_embedding)\ny_new = np.array(y_train)\n\nlstmModel.fit(X_new, y_new, epochs=40, batch_size=128)","1d660258":"y_pred = np.argmax(lstmModel.predict(np.array(test_word_embedding)), axis=-1)\nreportTest(y_pred, np.array(y_test))","71d9cb22":"!pip install -q transformers\n\n# Loading the BERT Classifier and Tokenizer along with Input module\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputFeatures","fb13fe71":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")","72c6cc36":"features_train = tokenizer.batch_encode_plus(X_train, padding='max_length', truncation=True,\n                                             max_length=512,return_tensors='tf',add_special_tokens=True,\n                                             return_token_type_ids=True, return_attention_mask=True)\n\nfeatures_test = tokenizer.batch_encode_plus(X_test, padding='max_length', truncation=True,\n                                            max_length=512,return_tensors='tf',add_special_tokens=True,\n                                            return_token_type_ids=True, return_attention_mask=True)","0ae88ed5":"tf.keras.backend.clear_session()\n\nwith strategy.scope():\n    bertModel = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n    bertModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n                      metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n#     bertModel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    bertModel.summary()","34eff84f":"bertModel.fit(x=features_train.data, y=y_train, epochs=10, batch_size=128, verbose=1)","e7ac5e4d":"bert_outputs = bertModel(features_test.data)\nbert_outputs","00b62fd5":"softmax_outputs = tf.nn.softmax(bert_outputs[0], axis=-1)\nsoftmax_outputs","d3babaa6":"y_pred = np.argmax(softmax_outputs.numpy(), axis=1)\nreportTest(y_pred, np.array(y_test))","85bb650f":"It seems that an email of 'text\/html' is likely to be a spam.","169a5b31":"The label seems to be unbalanced as label 1 is smaller than 25% of the set","72f4aca9":"First 5 examples are not really helpful. \nAll labels are 0, all num_mails_in_flow are 1 and all content_type are 'text\/plain'. \nThey are all dominant types. Let's have a look at minor groups.","0cdfee2b":"Please be careful in processing train\/test data. Any kind of fitting can only be applied training set. Applying fitting into test data will make models learn from test set and directly affect the quality of the models.","64324026":"With the birth of BERT, nearly all state of art solutions are using BERT. Instead of training from scratch, BERT can be used with transfer learning by using pre-trained model. In this section, pretrained Hugging Face's BERT model is used.","6d433a0a":"# BERT solution","699ec56d":"Prepare function to report test results.","5618991d":"It seems that BERT solution is better than LSTM one while using less epoch (with the same configuration). Again, the more compute power wins.","03b8a300":"# Preprocess data\n\nFirst let's start by loading all email files (ham or spam) and playing with the data.","26c5797e":"Also init strategy to run TPU\/GPU or CPU.","b1f828d9":"TFBertForSequenceClassification is a version of BERT for sequence classification problem, which introduces a new dense layer after BERT main layer.","aaf8f9cd":"As our problem does not care about cases, let's use the simplest version of BERT: \"bert-base-uncased\". Let's start by loading WordPiece tokenizer adn tokenize both train & test data.","91fe4b0d":"On the other hand, a 'multipart' email is likely to be a ham. However, if you want to put any conclusion into your model, you should split data for test\/valid & train first. \"Human learning\" can also be used in order to help find spam but it should only work well if all conclusions are learned from training data (not test data).\n\n# Split data & Prepare metrics\n\nIn the scope of this article, only topic & content of the emails is used to identify spam. Let's merge to column into 1 (as many emails seem to have no content - only topic)","59d87b09":"As I do not have enough knowledge about deep learning, I only borrow deep network structure from [this article](https:\/\/www.kaggle.com\/lonnieqin\/spam-filter-using-word-embedding-lstm) and train to compare with MultinominalNB","37575edf":"# MultinominalNB\n\nFirst, let's try out with one of the easiest solution: Multinominal Naive Bayes. This is a stastictical machine learning solution where we calculate the probability of an email to be spam by calculating all related probability of words (or n-gram words) to be in a spam.\n\nThis is naive because it depends on 2 assumptions:\n- An email (document) is just a bag of words. We don't count the order of words in the email.\n- Each feature (word\/ n-gram words) is independent on each other.\n\nEven though these 2 assumptions are wrong, the prediction result is still good. Let's together find out.\n\nFirst, count the number of each word\/n-gram words in each document to calculate the probability of them in spam\/ham.","932a7732":"Deep learning architecture took much more compute power but also provided with great results. Accuracy increases to 0.966 but recall increases dramatically to 0.96. However, precision falls from 0.99 (multinominalNB) to only 0.84. Overall, deep network provides better results than multinominalNB does.","64ae386c":"With only content data, we already have 0.96 at accuracy metric. However, recall is quite low with only 0.76.\n\n# LSTM solution\n\nLet's try with more advanced technology (LSTM) to see whether we can increase the f1-score. \n\nFirst, we need the vocabulary. The easy way to get vocabulary is using Tokenizer. Hyper parameter is borrowed from [this article](https:\/\/www.kaggle.com\/lonnieqin\/spam-filter-using-word-embedding-lstm)","0273c08e":"Again, fitting is only applied to training set.\n\nIn order to make all variable-length sentences fit into our model, we should make them become fixed-length sequences. pad_sequences in default will use the biggest length. However, first we should check distribution of lengths","b1f59186":"Describe our dataset, then view some examples."}}