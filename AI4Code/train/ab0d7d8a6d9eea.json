{"cell_type":{"ab518b82":"code","a9dec4d9":"code","b8e5f70e":"code","badd7a0d":"code","a1119218":"code","c476ad46":"code","d5188fb7":"code","e4391898":"code","5bf913ea":"code","e2370946":"code","a63ff8b4":"code","a39edd0b":"code","05ff1ff6":"code","af5b3d24":"code","6064b05e":"code","5fddac8a":"code","df840478":"code","d95ea952":"code","7776154f":"code","1b3d6917":"code","c5103965":"code","1026dc68":"code","a43fdeed":"code","5240bbaa":"code","a6725645":"code","5dfe1d3c":"code","26518ce4":"code","d9cf27c4":"code","a02094bf":"code","397c0337":"code","a68eb1a8":"code","78ad14fc":"code","dcc44743":"code","a1409182":"code","615c3dc6":"code","1caad9a0":"code","c62cde71":"code","be928f55":"code","193446b9":"code","272b0dd8":"code","8644c462":"code","8f485c7d":"markdown","377125b8":"markdown","9fc81897":"markdown","75b52ae6":"markdown","a75b4d51":"markdown","6382d6b6":"markdown","70b6e427":"markdown","629b4416":"markdown","9721c6f9":"markdown","52d33934":"markdown","9bc4738b":"markdown","d44d82f5":"markdown","305e45ed":"markdown","3ffe872f":"markdown","9d17e438":"markdown","202df585":"markdown","8ab72725":"markdown","80fe69fa":"markdown","50ba402b":"markdown","b376547c":"markdown","366df49a":"markdown","f53e4283":"markdown","b4815723":"markdown","b01e0675":"markdown"},"source":{"ab518b82":"!pip install fastai","a9dec4d9":"!pip install pydicom","b8e5f70e":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","badd7a0d":"import pydicom\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\n\ntry:\n    import cv2\n    cv2.setNumThreads(0)\nexcept: pass\n\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nsns.set_context(\"paper\")","a1119218":"!pip install scikit-image","c476ad46":"pip install kornia===0.2.0","d5188fb7":"#Code by Amrit Virdee  https:\/\/www.kaggle.com\/avirdee\/rsna-miccai-initial-fmi-fastai\/notebook\n\nmri = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\ntrain_files = get_dicom_files(f'{source}\/train')\nlabels = pd.read_csv(f'{source}\/train_labels.csv')\nprint(os.listdir(source))","e4391898":"#get dicom files\nitems = get_dicom_files(mri, recurse=True, folders='train')\nitems","5bf913ea":"Sample_DCM = Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00688\/T2w\/Image-273.dcm')\ndcm = Sample_DCM.dcmread()\ndcm","e2370946":"type(dcm)","a63ff8b4":"dcm.pixels","a39edd0b":"plt.hist(dcm.pixels.flatten().numpy());","05ff1ff6":"plt.hist(dcm.scaled_px.flatten().numpy());","af5b3d24":"t_bin = dcm.pixels.freqhist_bins(n_bins=1)\nt_bin","6064b05e":"plt.hist(t_bin.numpy(), bins=t_bin, color='c')\nplt.plot(t_bin, torch.linspace(0,1,len(t_bin)));","5fddac8a":"t_bin = dcm.pixels.freqhist_bins(n_bins=100)\nt_bin","df840478":"plt.hist(t_bin.numpy(), bins=t_bin, color='c'); plt.plot(t_bin, torch.linspace(0,1,len(t_bin)));","d95ea952":"plt.hist(dcm.pixels.flatten().numpy(), bins=100);","7776154f":"tensor_hists = dcm.pixels.hist_scaled()\nplt.hist(tensor_hists.flatten().numpy(), bins=100);","1b3d6917":"data_scaled = dcm.hist_scaled()\nplt.imshow(data_scaled, cmap=plt.cm.bone);","c5103965":"data_scaled = dcm.hist_scaled(min_px=100, max_px=1000)\nplt.imshow(data_scaled, cmap=plt.cm.bone);","1026dc68":"plt.imshow(dcm.windowed(*dicom_windows.brain), cmap=plt.cm.bone);","a43fdeed":"scales = False, True, dicom_windows.brain, dicom_windows.subdural\ntitles = 'raw','normalized','brain windowed','subdural windowed'\nfor s,a,t in zip(scales, subplots(2,2,imsize=4)[1].flat, titles):\n    dcm.show(scale=s, ax=a, title=t)","5240bbaa":"dcm.show(cmap=plt.cm.gist_ncar, figsize=(6,6))","a6725645":"dcm.show()","5dfe1d3c":"dcm.pct_in_window(*dicom_windows.brain)","26518ce4":"ims = dcm.hist_scaled(), uniform_blur2d(dcm.hist_scaled(), 20), uniform_blur2d(dcm.hist_scaled(), 50)\nshow_images(ims, titles=('original', 'blurred 20', 'blurred 50'))","d9cf27c4":"ims = dcm.hist_scaled(), gauss_blur2d(dcm.hist_scaled(), 20), gauss_blur2d(dcm.hist_scaled(), 50)\nshow_images(ims, titles=('original', 'gauss_blur 20', 'gauss_blur 50'))","a02094bf":"mask = dcm.mask_from_blur(dicom_windows.brain, sigma=0.9, thresh=0.1, remove_max=True)\nwind = dcm.windowed(*dicom_windows.brain)\n\n_,ax = subplots(1,3)\nshow_image(wind, ax=ax[0], title='window')\nshow_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[1], title='mask')\nshow_image(wind, ax=ax[2])\nshow_image(mask, alpha=0.5, cmap=plt.cm.Reds, ax=ax[2], title='window and mask');","397c0337":"bbs = mask2bbox(mask)\nlo,hi = bbs\nshow_image(wind[lo[0]:hi[0],lo[1]:hi[1]]);","a68eb1a8":"px256 = crop_resize(to_device(wind[None]), bbs[...,None], 128)[0]\nshow_image(px256)\npx256.shape","78ad14fc":"_,axs = subplots(1,2)\ndcm.show(ax=axs[0])\nshow_image(px256, ax=axs[1]);","dcc44743":"show_images(dcm.to_nchan([dicom_windows.brain], bins=0))","a1409182":"show_images(dcm.to_nchan([dicom_windows.brain], bins=None))","615c3dc6":"show_images(dcm.to_nchan([dicom_windows.brain,dicom_windows.subdural,dicom_windows.abdomen_soft]))","1caad9a0":"_,axs=subplots(1,2)\nwith tempfile.TemporaryDirectory() as f:\n    f = Path(f)\n    dcm.save_jpg(f\/'test.jpg', [dicom_windows.brain,dicom_windows.subdural])\n    show_image(Image.open(f\/'test.jpg'), ax=axs[0])\n    dcm.save_tif16(f\/'test.tif')\n    show_image(Image.open(str(f\/'test.tif')), ax=axs[1]);","c62cde71":"dcm.pixel_array.shape","be928f55":"dcm.zoom(7.0)\ndcm.show(); dcm.pixel_array.shape","193446b9":"dcm.zoom_to(200); dcm.pixel_array.shape","272b0dd8":"dcm2 = TEST_DCM.dcmread()\ndcm2.zoom_to(90)\ntest_eq(dcm2.shape, (90,90))","8644c462":"dcm2 = TEST_DCM.dcmread()\ndcm2.zoom(0.25)\ndcm2.show()","8f485c7d":"#Dataset.zoom_to\n\nDataset.zoom_to(sz)\n\nChange image size to specified pixel size","377125b8":"#Comparing the original image with the image from using the mask and crop_resize function","9fc81897":"#Tensor.to_nchan\n\nTensor.to_nchan(x:Tensor, wins, bins=None)\n\n#Dataset.to_nchan\n\nDataset.to_nchan(x:Dataset, wins, bins=None)\n\nto_nchan takes a tensor or a dicom as the input and returns multiple one channel images (the first depending on the choosen windows and a normalized image). Setting bins to 0 only returns the windowed image.","75b52ae6":"![](https:\/\/www.wias-berlin.de\/research\/ats\/imaging\/overview.png)wias-berlin.de","a75b4d51":"#Dataset.save_tif16\n\nDataset.save_tif16(x:Dataset'>), path, bins=None, compress=True)\n\nSave tensor or dicom image into tiff format.","6382d6b6":"#Dataset.windowed\n\nDataset.windowed(w, l)","70b6e427":"#Tensor.mask_from_blur\n\nTensor.mask_from_blur(x:Tensor, window, sigma=0.3, thresh=0.05, remove_max=True)\n\nCreate a mask from the blurred image\n\n#Dataset.mask_from_blur\n\nDataset.mask_from_blur(x:Dataset, window, sigma=0.3, thresh=0.05, remove_max=True)\n\nCreate a mask from the blurred image.","629b4416":"#Dataset.set_pixels","9721c6f9":"#Dataset.zoom\n\nDataset.zoom(ratio)\n\nZoom image by specified ratio\n\nCheck to see the current size of the dicom image","52d33934":"Dicom images can contain a high amount of voxel values and windowing can be thought of as a means of manipulating these values in order to change the apperance of the image so particular structures are highlighted. A window has 2 values:\n\nl = window level or center aka brightness\n\nw = window width or range aka contrast","9bc4738b":"#Dataset.pct_in_window\n\nDataset.pct_in_window(dcm:Dataset, w, l)\n\n% of pixels in the window (w,l)","d44d82f5":"#Dataset.show\n\nDataset.show(frames=1, scale=True, cmap=<matplotlib.colors.LinearSegmentedColormap object at 0x7f1cb02ce6a0>, min_px=-1100, max_px=None, **kwargs)\n\nAdds functionality to view dicom images where each file may have more than 1 frame.","305e45ed":"#Tensor.to_3chan\n\nTensor.to_3chan(x:Tensor, win1, win2, bins=None)\n\n#Dataset.to_3chan\n\nDataset.to_3chan(x:Dataset, win1, win2, bins=None)","3ffe872f":"#Tensor.freqhist_bins\n\nA function to split the range of pixel values into groups, such that each group has around the same number of pixels.","9d17e438":"#Tensor.hist_scaled\n\nScales a tensor using freqhist_bins to values between 0 and 1\n\nThe test image has pixel values that range between -1000 and 2500","202df585":"#None\n\nscaled_px uses RescaleSlope and RescaleIntercept values to correctly scale the image so that they represent the correct tissue densities.","8ab72725":"#with n_bins at 100","80fe69fa":"#Dataset.hist_scaled\n\nDataset.hist_scaled(brks=None, min_px=None, max_px=None)\n\nPixels scaled to a min_px and max_px value","50ba402b":"#mask2bbox\n\nmask2bbox(mask)","b376547c":"#All script by Fastai Medical Imaging. Helpers for working with DICOM files\n\nhttps:\/\/docs.fast.ai\/medical.imaging.html#Dataset.set_pixels","366df49a":"#uniform_blur2d\n\nuniform_blur2d(x, s)\n\nUniformly apply blurring","f53e4283":"#crop_resize\n\ncrop_resize(x, crops, new_sz)","b4815723":"#Code by https:\/\/docs.fast.ai\/medical.imaging.html#Dataset.set_pixels","b01e0675":"#gauss_blur2d\n\ngauss_blur2d(x, s)\n\nApply gaussian_blur2d kornia filter"}}