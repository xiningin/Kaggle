{"cell_type":{"c80e581d":"code","b243abe9":"code","1ca7ef24":"code","1314a2aa":"code","d0e75510":"code","6c566d8a":"code","99376b7f":"code","67863120":"code","c36af946":"code","05cd60a7":"code","29a58d56":"code","cd743486":"code","353c1521":"code","4f9201ba":"code","42246e09":"code","eb47875c":"code","5d4ff218":"code","10261a0d":"code","4f0780a9":"code","3e2d3995":"code","5270b5a7":"code","d8c36591":"code","03964e90":"code","5e1ea439":"code","e19bde51":"code","874d5eee":"code","6ebf6a36":"code","f244371a":"code","8c9ac696":"code","8fc3ede2":"code","9d2eacac":"code","2119a638":"code","a1678559":"code","bcbf8fd4":"code","c86d63b3":"code","d28c81d7":"code","b71d07ac":"code","d19571e2":"code","87db45a1":"code","099e999d":"code","7550ad3f":"code","6f1f68d3":"code","f46ff957":"code","1b30d901":"code","f6e59f14":"code","1086c844":"markdown","5798eda1":"markdown","e40aaa00":"markdown","25dc6b25":"markdown","dd1a88dc":"markdown","3fe86a48":"markdown","48c1420a":"markdown","3adc9d33":"markdown","acf63c78":"markdown","d24871e1":"markdown","68ef49c3":"markdown","4809e13c":"markdown","7a900b7e":"markdown","028fcb48":"markdown","f44e3eaf":"markdown","4fc11d65":"markdown","4cee4402":"markdown","37467458":"markdown","1653b28d":"markdown","3761564a":"markdown","f128c3b8":"markdown","fb15b4e6":"markdown","03bfbdba":"markdown","9a8de196":"markdown","796539de":"markdown","a8180ef9":"markdown","dd50b6c7":"markdown","a0030193":"markdown","fe390a69":"markdown","a4f9553c":"markdown","ed6e6d9e":"markdown","51650061":"markdown"},"source":{"c80e581d":"# Uncomment and run the commands below if imports fail\n# !conda install numpy pandas pytorch torchvision cpuonly -c pytorch -y\n# !pip install matplotlib --upgrade --quiet","b243abe9":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline","1ca7ef24":"# Project name used for jovian.commit\nproject_name = '03-cifar10-feedforward'","1314a2aa":"dataset = CIFAR10(root='data\/', download=True, transform=ToTensor())\ntest_dataset = CIFAR10(root='data\/', train=False, transform=ToTensor())","d0e75510":"dataset_size = len(dataset)\ndataset_size","6c566d8a":"test_dataset_size = len(test_dataset)\ntest_dataset_size","99376b7f":"classes = dataset.classes\nclasses","67863120":"num_classes = len(classes)\nnum_classes","c36af946":"img, label = dataset[0]\nimg_shape = img.shape\nimg_shape","05cd60a7":"img, label = dataset[0]\nplt.imshow(img.permute((1, 2, 0)))\nprint('Label (numeric):', label)\nprint('Label (textual):', classes[label])","29a58d56":"num_of_img = np.zeros(10)\nfor img in dataset:\n    value = img[1];\n    num_of_img[value] +=1\nnum_of_img","cd743486":"!pip install jovian --upgrade --quiet","353c1521":"import jovian","4f9201ba":"jovian.commit(project=project_name, environment=None)","42246e09":"torch.manual_seed(43)\nval_size = 5000\ntrain_size = len(dataset) - val_size","eb47875c":"train_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","5d4ff218":"batch_size=128","10261a0d":"train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)","4f0780a9":"for images, _ in train_loader:\n    print('images.shape:', images.shape)\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n    break","3e2d3995":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","5270b5a7":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","d8c36591":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","03964e90":"torch.cuda.is_available()","5e1ea439":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","e19bde51":"device = get_default_device()\ndevice","874d5eee":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","6ebf6a36":"def plot_losses(history):\n    losses = [x['val_loss'] for x in history]\n    plt.plot(losses, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.title('Loss vs. No. of epochs');","f244371a":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","8c9ac696":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","8fc3ede2":"input_size = 3*32*32\noutput_size = 10","9d2eacac":"class CIFAR10Model(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(input_size, 1024)\n        self.linear2 = nn.Linear(1024, 1024)\n        self.linear3 = nn.Linear(1024, 10)\n        \n    def forward(self, xb):\n        # Flatten images into vectors\n        out = xb.view(xb.size(0), -1)\n        # Apply layers & activation functions\n        out = self.linear1(out)\n        out = F.relu(out)\n        out = self.linear2(out)\n        out = F.relu(out)\n        out = self.linear3(out)\n        out = F.relu(out)\n        return out","2119a638":"model = to_device(CIFAR10Model(), device)","a1678559":"history = [evaluate(model, val_loader)]\nhistory","bcbf8fd4":"history += fit(10, 0.1, model, train_loader, val_loader)","c86d63b3":"history += fit(10, 0.01, model, train_loader, val_loader)","d28c81d7":"history += fit(15, 0.1, model, train_loader, val_loader)","b71d07ac":"history += fit(15, 0.01, model, train_loader, val_loader)","d19571e2":"plot_losses(history)","87db45a1":"plot_accuracies(history)","099e999d":"evaluate(model, test_loader)","7550ad3f":"arch = repr(model)\narch","6f1f68d3":"lrs = [0.1,0.01,0.1,0.01]","f46ff957":"epochs = [10,10,15,15]","1b30d901":"result = evaluate(model, val_loader)\ntest_acc = result['val_acc']\ntest_loss = result['val_loss']\nresult","f6e59f14":"torch.save(model.state_dict(), 'cifar10-feedforward.pth')","1086c844":"**(Optional) Q: Can you determine the number of images belonging to each class?**\n\nHint: Loop through the dataset.","5798eda1":"## Recoding your results\n\nAs your perform multiple experiments, it's important to record the results in a systematic fashion, so that you can review them later and identify the best approaches that you might want to reproduce or build upon later. \n\n**Q: Describe the model's architecture with a short summary.**\n\nE.g. `\"3 layers (16,32,10)\"` (16, 32 and 10 represent output sizes of each layer)","e40aaa00":"Note that this dataset consists of 3-channel color images (RGB). Let us look at a sample image from the dataset. `matplotlib` expects channels to be the last dimension of the image tensors (whereas in PyTorch they are the first dimension), so we'll the `.permute` tensor method to shift channels to the last dimension. Let's also print the label for the image.","25dc6b25":"## Training the model\n\nWe will make several attempts at training the model. Each time, try a different architecture and a different set of learning rates. Here are some ideas to try:\n- Increase or decrease the number of hidden layers\n- Increase of decrease the size of each hidden layer\n- Try different activation functions\n- Try training for different number of epochs\n- Try different learning rates in every epoch\n\nWhat's the highest validation accuracy you can get to? **Can you get to 50% accuracy? What about 60%?**","dd1a88dc":"Finally, let's also define some utilities for moving out data & labels to the GPU, if one is available.","3fe86a48":"**Q: What were the final test accuracy & test loss?**","48c1420a":"Let's use the `random_split` method to create the training & validation sets","3adc9d33":"**Q: Provide the list of no. of epochs used while training.**","acf63c78":"## Preparing the data for training\n\nWe'll use a validation set with 5000 images (10% of the dataset). To ensure we get the same validation set each time, we'll set PyTorch's random number generator to a seed value of 43.","d24871e1":"\n**Q: Extend the `ImageClassificationBase` class to complete the model definition.**\n\nHint: Define the `__init__` and `forward` methods.","68ef49c3":"## Base Model class & Training on GPU\n\nLet's create a base model class, which contains everything except the model architecture i.e. it wil not contain the `__init__` and `__forward__` methods. We will later extend this class to try out different architectures. In fact, you can extend this model to solve any image classification problem.","4809e13c":"Are you happy with the accuracy? Record your results by completing the section below, then you can come back and try a different architecture & hyperparameters.","7a900b7e":"**Q: How many images does the training dataset contain?**","028fcb48":"Finally, evaluate the model on the test dataset report its final performance.","f44e3eaf":"**Q: Train the model using the `fit` function to reduce the validation loss & improve accuracy.**\n\nLeverage the interactive nature of Jupyter to train the model in multiple phases, adjusting the no. of epochs & learning rate each time based on the result of the previous training phase.","4fc11d65":"Can you label all the images by looking at them? Trying to label a random sample of the data manually is a good way to estimate the difficulty of the problem, and identify errors in labeling, if any.","4cee4402":"Let's save our work to Jovian, before continuing.","37467458":"Let's move our data loaders to the appropriate device.","1653b28d":"We can also use the exact same training loop as before. I hope you're starting to see the benefits of refactoring our code into reusable functions.","3761564a":"Before you train the model, it's a good idea to check the validation loss & accuracy with the initial set of weights.","f128c3b8":"## Exploring the CIFAR10 dataset","fb15b4e6":"Let us also define a couple of helper functions for plotting the losses & accuracies.","03bfbdba":"# Classifying images of everyday objects using a neural network\n\nThe ability to try many different neural network architectures to address a problem is what makes deep learning really powerful, especially compared to shallow learning techniques like linear regression, logistic regression etc. \n\nIn this assignment, you will:\n\n1. Explore the CIFAR10 dataset: https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\n2. Set up a training pipeline to train a neural network on a GPU\n2. Experiment with different network architectures & hyperparameters\n\nAs you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end. Try to experiment with different network structures and hypeparameters to get the lowest loss.\n\nYou might find these notebooks useful for reference, as you work through this notebook:\n\n- https:\/\/jovian.ml\/aakashns\/04-feedforward-nn\n- https:\/\/jovian.ml\/aakashns\/fashion-feedforward-minimal","9a8de196":"**Q: How many output classes does the dataset contain? Can you list them?**\n\nHint: Use `dataset.classes`","796539de":"Plot the losses and the accuracies to check if you're starting to hit the limits of how well your model can perform on this dataset. You can train some more if you can see the scope for further improvement.","a8180ef9":"**Q: Provide the list of learning rates used while training.**","dd50b6c7":"Let's visualize a batch of data using the `make_grid` helper function from Torchvision.","a0030193":"You can now instantiate the model, and move it the appropriate device.","fe390a69":"Finally, let's save the trained model weights to disk, so we can use this model later.","a4f9553c":"We can now create data loaders to load the data in batches.","ed6e6d9e":"**Q: How many images does the training dataset contain?**","51650061":"**Q: What is the shape of an image tensor from the dataset?**"}}