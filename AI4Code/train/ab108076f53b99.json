{"cell_type":{"6588986d":"code","48b9d768":"code","bda53870":"code","183af0f2":"code","f402f943":"code","43129326":"code","ac0b80b5":"code","19383a9f":"code","c7040da7":"code","2782884b":"code","49fa039d":"code","e09174c9":"code","23f3212a":"code","ef50e836":"code","913611cb":"code","920e8763":"code","2cba9e38":"code","488adc63":"code","e3f5ad65":"code","fe5c5246":"code","f5405c19":"code","109002bb":"code","138fc5a5":"code","2c60dc30":"code","971b4769":"code","805fcbc5":"code","6b5a447c":"code","c2fe4ae5":"code","95320c7d":"code","7f6b950f":"code","6081a056":"code","4e23a9ef":"code","a6657470":"code","0395bf98":"code","d9986f60":"code","b001b381":"code","b2642d95":"code","e0181e03":"code","9cc972e7":"markdown","955baaf0":"markdown","03898fa1":"markdown","963ac281":"markdown","a94a6660":"markdown","b31e2b37":"markdown","85689524":"markdown","5f9694dd":"markdown","cf6b62c0":"markdown","e62cbc04":"markdown","fa415ab7":"markdown","3d3af170":"markdown","be238568":"markdown","133a8cd7":"markdown","e4a696ce":"markdown","fc0fd343":"markdown","541e4762":"markdown","25e749b5":"markdown","d7acb59f":"markdown","35407e53":"markdown","4e4372c3":"markdown","ed4805c1":"markdown","6dea35bb":"markdown","dbe62180":"markdown","7ca997c2":"markdown","bfb1b34f":"markdown","ce9eb107":"markdown","40162c2f":"markdown"},"source":{"6588986d":"from IPython.display import Image\nImage(filename=\"..\/input\/cv-logo\/cv.jpg\")","48b9d768":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom collections import defaultdict\nfrom wordcloud import WordCloud, STOPWORDS\nimport random\n\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n\nimport os\nfor file in os.listdir(\"..\/input\/data-science-for-good-careervillage\"):\n    print(file)","bda53870":"def ngram_extractor(text, n_gram):\n    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\n# Function to generate a dataframe with n_gram and top max_row frequencies\ndef generate_ngrams(df, col, n_gram, max_row):\n    temp_dict = defaultdict(int)\n    for question in df[col].dropna():\n        for word in ngram_extractor(question, n_gram):\n            temp_dict[word] += 1\n    temp_df = pd.DataFrame(sorted(temp_dict.items(), key=lambda x: x[1])[::-1]).head(max_row)\n    temp_df.columns = [\"word\", \"wordcount\"]\n    return temp_df","183af0f2":"from IPython.display import Image\nImage(filename=\"..\/input\/cv-matches\/matches.png\")","f402f943":"professionals = pd.read_csv('..\/input\/data-science-for-good-careervillage\/professionals.csv')\nprint('Professionals data: \\nRows: {}\\nCols: {}\\n'.format(professionals.shape[0],professionals.shape[1]))\n\nemails = pd.read_csv('..\/input\/data-science-for-good-careervillage\/emails.csv')\nprint('E-Mails data: \\nRows: {}\\nCols: {}\\n'.format(emails.shape[0],emails.shape[1]))\n\nmatches = pd.read_csv('..\/input\/data-science-for-good-careervillage\/matches.csv')\nprint('Matches data: \\nRows: {}\\nCols: {}\\n'.format(matches.shape[0],matches.shape[1]))\n\nstudents = pd.read_csv('..\/input\/data-science-for-good-careervillage\/students.csv')\nprint('Students data: \\nRows: {}\\nCols: {}\\n'.format(students.shape[0],students.shape[1]))\n\nquestions = pd.read_csv('..\/input\/data-science-for-good-careervillage\/questions.csv')\nprint('Questions data: \\nRows: {}\\nCols: {}\\n'.format(questions.shape[0],questions.shape[1]))\n\nemails_professionals = pd.merge(emails, \n                                professionals,\n                                how='left',\n                                left_on='emails_recipient_id', \n                                right_on='professionals_id')\n\nmatches_new = pd.merge(matches, \n                       emails_professionals,\n                       how='left',\n                       left_on='matches_email_id',\n                       right_on='emails_id')\n\nquestions_students = pd.merge(questions, \n                              students,\n                              how='left',\n                              left_on='questions_author_id', \n                              right_on='students_id')\n\nmatches_new = pd.merge(matches_new, \n                       questions_students,\n                       how='left',\n                       left_on='matches_question_id',\n                       right_on='questions_id')\n\nmatches_new.drop(columns=['matches_email_id', 'matches_question_id', 'emails_recipient_id','questions_author_id'], inplace=True)\n\nprint('New matches data: \\nRows: {}\\nCols: {}'.format(matches_new.shape[0],matches_new.shape[1]))","43129326":"# Lowercasing\nquestions['questions_title'] = questions['questions_title'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n# Removing punctuations\nquestions['questions_title'] = questions['questions_title'].str.replace('[^\\w\\s]','')\n\n# Removing stop words\nquestions['questions_title'] = questions['questions_title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))","ac0b80b5":"print(\"Missing values in Professionals data\")\nfor x in professionals.columns:\n    if professionals[x].isnull().values.ravel().sum() > 0:\n        print('{} - {}'.format(x,professionals[x].isnull().values.ravel().sum()))","19383a9f":"temp = professionals['professionals_location'].value_counts(normalize=True) * 100\ntemp = temp.reset_index().head(10)\n\nf, ax = plt.subplots(figsize=(10, 4))\nsns.barplot(x=\"professionals_location\", y=\"index\", data=temp, label=\"index\", color=\"palegreen\")\n\nfor p in ax.patches:\n    ax.text(p.get_width()+.15,\n            p.get_y() + (p.get_height()\/2) + .1,\n            '{:1.1f}%'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('% of professionals', size=10, color=\"green\")\nax.set_ylabel('Location', size=10, color=\"green\")\nax.set_title('[Horizontal Bar Plot] % of professionals from top 10 locations', size=12, color=\"green\")\nplt.show()","c7040da7":"temp = professionals['professionals_industry'].value_counts(normalize=True) * 100\ntemp = temp.reset_index().head(10)\n\nf, ax = plt.subplots(figsize=(10, 4))\nsns.barplot(x=\"professionals_industry\", y=\"index\", data=temp, label=\"index\", color=\"palegreen\")\n\nfor p in ax.patches:\n    ax.text(p.get_width()+.4,\n            p.get_y() + (p.get_height()\/2) + .1,\n            '{:1.1f}%'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('% of professionals', size=10, color=\"green\")\nax.set_ylabel('Industry', size=10, color=\"green\")\nax.set_title('[Horizontal Bar Plot] % of professionals from top 10 industries', size=12, color=\"green\")\nplt.show()","2782884b":"professionals[\"professionals_headline\"] = professionals['professionals_headline'].str.replace('[^\\w\\s]','')\n\ndef grey_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n    return \"hsl(0, 0%%, %d%%)\" % random.randint(0, 100)\n\nword_string = professionals[\"professionals_headline\"].str.cat(sep=' ')\n\nwordcloud = WordCloud(\n    stopwords=STOPWORDS,\n    background_color='white',\n    width=3000,\n    height=1000).generate(word_string)\n\nplt.figure(figsize=(20,40))\nplt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3),interpolation=\"bilinear\")\nplt.axis('off')\nfont = {'family': 'sans-serif',\n        'color':  'brown',\n        'weight': 'normal',\n        'size': 32\n        }\nplt.title('Word Cloud - Professionals Headline', fontdict=font)\nplt.show()","49fa039d":"groups = pd.read_csv('..\/input\/data-science-for-good-careervillage\/groups.csv')\n\nprint('Groups data: \\nRows: {}\\nCols: {}'.format(groups.shape[0],groups.shape[1]))\nprint(groups.columns)","e09174c9":"print(\"Missing values in Groups data\")\nfor x in groups.columns:\n    if groups[x].isnull().values.ravel().sum() > 0:\n        print('{} - {}'.format(x,groups[x].isnull().values.ravel().sum()))","23f3212a":"temp = groups['groups_group_type'].value_counts(normalize=True) * 100\ntemp = temp.reset_index()\n\nf, ax = plt.subplots(figsize=(10, 4))\nsns.barplot(x=\"groups_group_type\", y=\"index\", data=temp, label=\"index\", color=\"cyan\")\n\nfor p in ax.patches:\n    ax.text(p.get_width()+2,\n            p.get_y() + (p.get_height()\/2) + .1,\n            '{:1.1f}%'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('% of groups', size=10, color=\"darkcyan\")\nax.set_ylabel('Group Type', size=10, color=\"darkcyan\")\nax.set_title('[Horizontal Bar Plot] % of groups', size=12, color=\"darkcyan\")\nplt.show()","ef50e836":"comments = pd.read_csv('..\/input\/data-science-for-good-careervillage\/comments.csv')\n\ncomments['comments_date'] = pd.to_datetime(comments['comments_date_added'])\ncomments['day'] = comments['comments_date'].dt.day\ncomments['month'] = comments['comments_date'].dt.month\ncomments['year'] = comments['comments_date'].dt.year\ncomments['hour'] = comments['comments_date'].dt.hour\ncomments['minute'] = comments['comments_date'].dt.minute\ncomments['second'] = comments['comments_date'].dt.second\ncomments['day_of_week'] = comments['comments_date'].dt.dayofweek\n\nprint('Comments data: \\nRows: {}\\nCols: {}'.format(comments.shape[0],comments.shape[1]))\nprint(comments.columns)","913611cb":"print(\"Missing values in Comments data\")\nfor x in comments.columns:\n    if comments[x].isnull().values.ravel().sum() > 0:\n        print('{} - {}'.format(x,comments[x].isnull().values.ravel().sum()))","920e8763":"comments[\"comments_body\"] = comments['comments_body'].str.replace('[^\\w\\s]','')\n\ntemp = generate_ngrams(comments,'comments_body',1,10)\n\nf, ax = plt.subplots(figsize=(10, 4))\nsns.barplot(x=\"wordcount\", y=\"word\", data=temp, label=\"wordcount\", color=\"silver\")\n\nfor p in ax.patches:\n    ax.text(p.get_width() + 170,\n            p.get_y() + (p.get_height()\/2) + .1,\n            '{:1.0f}'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('Count of word', size=10, color=\"black\")\nax.set_ylabel('Word in comments', size=10, color=\"black\")\nax.set_title('[Horizontal Bar Plot] Count of words in comments', size=12, color=\"black\")\nplt.show()","2cba9e38":"def grey_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n    return \"hsl(0, 0%%, %d%%)\" % random.randint(0, 100)\n\nword_string = comments[\"comments_body\"].str.cat(sep=' ')\n\nwordcloud = WordCloud(\n    stopwords=STOPWORDS,\n    background_color='white',\n    width=3000,\n    height=1000).generate(word_string)\n\nplt.figure(figsize=(20,40))\nplt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3),interpolation=\"bilinear\")\nplt.axis('off')\nfont = {'family': 'sans-serif',\n        'color':  'brown',\n        'weight': 'normal',\n        'size': 32\n        }\nplt.title('Word Cloud - Comment Body', fontdict=font)\nplt.show()","488adc63":"temp = comments['day'].value_counts()\ntemp = temp.reset_index()\n\nf, ax = plt.subplots(figsize=(12, 4))\nsns.barplot(x=\"index\", y=\"day\", data=temp, label=\"index\", color=\"silver\", orient='v')\n\nfor p in ax.patches:\n    ax.text(p.get_x() + (p.get_width()\/2),\n            p.get_height() + 10,\n            '{:1.0f}'.format(p.get_height()),\n            ha=\"center\")\n\nax.set_xlabel('Day', size=10, color=\"black\")\nax.set_ylabel('Count of Comments', size=10, color=\"black\")\nax.set_title('[Vertical Bar Plot] Count of Comments over each day', size=12, color=\"black\")\nplt.show()","e3f5ad65":"temp = comments['month'].value_counts()\ntemp = temp.reset_index()\n\nf, ax = plt.subplots(figsize=(12, 4))\nsns.barplot(x=\"index\", y=\"month\", data=temp, label=\"index\", color=\"silver\", orient='v')\n\nfor p in ax.patches:\n    ax.text(p.get_x() + (p.get_width()\/2),\n            p.get_height() + 30,\n            '{:1.0f}'.format(p.get_height()),\n            ha=\"center\")\n\nax.set_xlabel('Month', size=10, color=\"black\")\nax.set_ylabel('Count of Comments', size=10, color=\"black\")\nax.set_title('[Vertical Bar Plot] Count of Comments over each month', size=12, color=\"black\")\nplt.show()","fe5c5246":"temp = comments['year'].value_counts()\ntemp = temp.reset_index()\n\nf, ax = plt.subplots(figsize=(12, 3))\nsns.barplot(x=\"year\", y=\"index\", data=temp, label=\"index\", color=\"silver\", orient='h')\n\nfor p in ax.patches:\n    ax.text(p.get_width() + 120,\n            p.get_y() + (p.get_height()\/1.2),\n            '{:1.0f}'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('Count of Comments', size=10, color=\"black\")\nax.set_ylabel('Year', size=10, color=\"black\")\nax.set_title('[Horizontal Bar Plot] Count of Comments over each year', size=12, color=\"black\")\nplt.show()","f5405c19":"temp = comments['day_of_week'].value_counts()\ntemp = temp.reset_index()\n\nf, ax = plt.subplots(figsize=(12, 3))\nsns.barplot(x=\"day_of_week\", y=\"index\", data=temp, label=\"index\", color=\"silver\", orient='h')\n\nfor p in ax.patches:\n    ax.text(p.get_width() + 80,\n            p.get_y() + (p.get_height()\/1.4),\n            '{:1.0f}'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('Count of Comments', size=10, color=\"black\")\nax.set_ylabel('Day of week', size=10, color=\"black\")\nax.set_title('[Horizontal Bar Plot] Count of Comments over the weekday', size=12, color=\"black\")\nplt.show()","109002bb":"temp = comments['hour'].value_counts()\ntemp = temp.reset_index()\n\nf, ax = plt.subplots(figsize=(12, 4))\nsns.barplot(x=\"index\", y=\"hour\", data=temp, label=\"index\", color=\"silver\", orient='v')\n\nfor p in ax.patches:\n    ax.text(p.get_x() + (p.get_width()\/2),\n            p.get_height() + 10,\n            '{:1.0f}'.format(p.get_height()),\n            ha=\"center\")\n\nax.set_xlabel('Hour of the day', size=10, color=\"black\")\nax.set_ylabel('Count of Comments', size=10, color=\"black\")\nax.set_title('[Vertical Bar Plot] Count of Comments over hour of the day', size=12, color=\"black\")\nplt.show()","138fc5a5":"school_memberships = pd.read_csv('..\/input\/data-science-for-good-careervillage\/school_memberships.csv')\n\nprint('School Memberships data: \\nRows: {}\\nCols: {}'.format(school_memberships.shape[0],school_memberships.shape[1]))\nprint(school_memberships.columns)","2c60dc30":"tags = pd.read_csv('..\/input\/data-science-for-good-careervillage\/tags.csv')\n\nprint('Tags data: \\nRows: {}\\nCols: {}'.format(tags.shape[0],tags.shape[1]))\nprint(tags.columns)","971b4769":"group_memberships = pd.read_csv('..\/input\/data-science-for-good-careervillage\/group_memberships.csv')\n\nprint('Group memberships data: \\nRows: {}\\nCols: {}'.format(group_memberships.shape[0],group_memberships.shape[1]))\nprint(group_memberships.columns)","805fcbc5":"answers = pd.read_csv('..\/input\/data-science-for-good-careervillage\/answers.csv')\n\nprint('Answers data: \\nRows: {}\\nCols: {}'.format(answers.shape[0],answers.shape[1]))\nprint(answers.columns)","6b5a447c":"def grey_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n    return \"hsl(0, 0%%, %d%%)\" % random.randint(0, 100)\n\nword_string = answers['answers_body'].str.cat(sep=' ')\n\nwordcloud = WordCloud(\n    stopwords=STOPWORDS,\n    background_color='white',\n    width=3000,\n    height=1000).generate(word_string)\n\nplt.figure(figsize=(20,40))\nplt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3),interpolation=\"bilinear\")\nplt.axis('off')\nfont = {'family': 'sans-serif',\n        'color':  'brown',\n        'weight': 'normal',\n        'size': 32\n        }\nplt.title('Word Cloud - Answers Body', fontdict=font)\nplt.show()","c2fe4ae5":"print(\"Missing values in Students data\")\nfor x in students.columns:\n    if students[x].isnull().values.ravel().sum() > 0:\n        print('{} - {}'.format(x,students[x].isnull().values.ravel().sum()))","95320c7d":"temp = students['students_location'].value_counts()\ntemp = temp.reset_index().head(10)\n\nf, ax = plt.subplots(figsize=(12, 4))\nsns.barplot(x=\"students_location\", y=\"index\", data=temp, label=\"index\", color=\"silver\", orient='h')\n\nfor p in ax.patches:\n    ax.text(p.get_width() + 20,\n            p.get_y() + (p.get_height()\/1.4),\n            '{:1.0f}'.format(p.get_width()),\n            ha=\"center\")\n\nax.set_xlabel('Number of students', size=10, color=\"black\")\nax.set_ylabel('Location', size=10, color=\"black\")\nax.set_title('[Horizontal Bar Plot] Number of students across cities', size=12, color=\"black\")\nplt.show()","7f6b950f":"def grey_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n    return \"hsl(0, 0%%, %d%%)\" % random.randint(0, 100)\n\nword_string = questions['questions_title'].str.cat(sep=' ')\n\nwordcloud = WordCloud(\n    stopwords=STOPWORDS,\n    background_color='white',\n    width=3000,\n    height=1000).generate(word_string)\n\nplt.figure(figsize=(20,40))\nplt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3),interpolation=\"bilinear\")\nplt.axis('off')\nfont = {'family': 'sans-serif',\n        'color':  'brown',\n        'weight': 'normal',\n        'size': 32\n        }\nplt.title('Word Cloud - Questions Title', fontdict=font)\nplt.show()","6081a056":"def grey_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n    return \"hsl(0, 0%%, %d%%)\" % random.randint(0, 100)\n\nword_string = questions['questions_body'].str.cat(sep=' ')\n\nwordcloud = WordCloud(\n    stopwords=STOPWORDS,\n    background_color='white',\n    width=3000,\n    height=1000).generate(word_string)\n\nplt.figure(figsize=(20,40))\nplt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3),interpolation=\"bilinear\")\nplt.axis('off')\nfont = {'family': 'sans-serif',\n        'color':  'brown',\n        'weight': 'normal',\n        'size': 32\n        }\nplt.title('Word Cloud - Questions Body', fontdict=font)\nplt.show()","4e23a9ef":"tag_users = pd.read_csv('..\/input\/data-science-for-good-careervillage\/tag_users.csv')\n\nprint('Tag Users data: \\nRows: {}\\nCols: {}'.format(tag_users.shape[0],tag_users.shape[1]))\nprint(tag_users.columns)","a6657470":"tag_questions = pd.read_csv('..\/input\/data-science-for-good-careervillage\/tag_questions.csv')\n\nprint('Tag Questions data: \\nRows: {}\\nCols: {}'.format(tag_questions.shape[0],tag_questions.shape[1]))\nprint(tag_questions.columns)","0395bf98":"matches_new = pd.merge(matches, \n                       emails, \n                       how='left', \n                       left_on='matches_email_id', \n                       right_on='emails_id')","d9986f60":"matches_new = pd.merge(matches_new, \n                       questions, \n                       how='left', \n                       left_on='matches_question_id', \n                       right_on='questions_id')","b001b381":"matches_new = pd.merge(matches_new, \n                       professionals, \n                       how='left', \n                       left_on='emails_recipient_id', \n                       right_on='professionals_id')","b2642d95":"matches_new = pd.merge(matches_new, \n                       students, \n                       how='left', \n                       left_on='questions_author_id', \n                       right_on='students_id')","e0181e03":"matches_new.head()","9cc972e7":"***More to come!!!***","955baaf0":"Comments (and in turn overall activity) is higher towards the end of the month. It's an expected behaviour. ","03898fa1":"Thank(s), much, will, answer, advice, great, school, work and good are the most present words in the comments. It's pretty obvious though. ","963ac281":"**Dataset: group_memberships**\n\n1038 entries are present.","a94a6660":"**Dataset: tag_users**","b31e2b37":"**Dataset: school_memberships**\n\nThere are 5638 school membership entries","85689524":"Let's analyze the matches first. It contains the data on which professionals receive which question over e-mail. ","5f9694dd":"There are no missing values.","cf6b62c0":"2016 is the year when there was a lot of activity. Is there a specific reason to it? It should be explored.","e62cbc04":"May month, which is the end of the academic year, is when the comments (activity) are higher.","fa415ab7":"**Dataset: Groups**\n\nThere are 49 groups. ","3d3af170":"**Dataset: Students** \n\n30,971 students are on the platform","be238568":"New York, Bengaluru and Los Angeles are the top locations in which the platform has a high student base. ","133a8cd7":"Top headlines used are student and director.","e4a696ce":"**Dataset: Professionals**\n\nThere are 28,152 professionals. We have data related to their location, industry, headline and when they joined. Almost 10% of their data is unknown. ","fc0fd343":"**Join datasets**","541e4762":"**Thanks for viewing my Kernel! If you like my work and find it useful, please leave an upvote! :)**\n\nCareerVillage.org is a nonprofit that crowdsources career advice for underserved youth. The platform uses a Q&A style similar to StackOverflow or Quora to provide students with answers to any question about any career. Underserved youth lack the network to find their career role models, making CareerVillage.org the only option for millions of young people in America and around the globe with nowhere else to turn. \n\nThe objective of this competition is to recommend questions to appropriate volunteers using 5 years of data.","25e749b5":"The comments rise from Monday to peak at Weednesday and then drops off. ","d7acb59f":"**Dataset: Comments**\n\nThere are 14,966 comments in the dataset. ","35407e53":"Comments peak at 17:00. Peak hours are from 15:00 to 19:00. ","4e4372c3":"Telecommunications, Information Technology & Services and Computer Software are the industries with high number of the professionals","ed4805c1":"**Dataset: answers**\n\nThere are 51,123 answers. ","6dea35bb":"**Dataset: tag_questions**","dbe62180":"A quick word cloud on the same data. ","7ca997c2":"**Dataset: questions**\n\nThere are 23,931 questions.","bfb1b34f":"2\/3rd of the groups are youth programs. 1\/6th of the groups are professional networks.","ce9eb107":"New York tops the location of professionals","40162c2f":"**Dataset: tags**\n\nThere are 16,269 tags. "}}