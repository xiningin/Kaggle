{"cell_type":{"581d7238":"code","6798e593":"code","9e4eac9c":"code","7be17d6b":"code","cb4a2008":"code","ad17bdf3":"code","e53122ab":"code","8100ae83":"code","6cbc81bf":"code","3f1c33d2":"code","2a73575d":"code","5b0c1c59":"code","bf9b7626":"code","2a22f5b2":"code","7742cfde":"code","0ede05e2":"code","cacd08a0":"code","3ff95866":"code","3164af96":"code","db3badd0":"code","1840c282":"code","066340ce":"code","25ba5ed3":"code","aabce163":"code","28678381":"code","9e83be17":"code","dd637ebe":"code","5661a101":"code","aaf050ce":"code","401151a7":"code","b3ec7c18":"code","6fcf67cd":"code","047c8dac":"code","70cf4292":"code","2a8600e1":"code","3f04da13":"code","7c8e53c8":"code","9ad35da7":"code","403df7bc":"code","ddeefcd2":"code","d9b2a78b":"code","7b610fd7":"code","59840bcb":"code","c7cccea4":"code","9b01b8b9":"code","1f9433de":"code","f1a78d3c":"code","03fa0657":"code","b77300f6":"code","54698817":"markdown","52dc6de5":"markdown","bb0a7aaf":"markdown","8d224b26":"markdown","2bb87c75":"markdown","c7905869":"markdown"},"source":{"581d7238":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport math\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import precision_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6798e593":"#first we read our data\ntrain_data = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-1\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/cap-4611-2021-fall-assignment-1\/test.csv\")\n","9e4eac9c":"train_data.head()","7be17d6b":"train_data.tail()","cb4a2008":"train_data.describe()","ad17bdf3":"train_data.columns","e53122ab":"train_data.nunique()","8100ae83":"pd.DataFrame(train_data.dtypes)","6cbc81bf":"sns.heatmap(train_data.isnull(),yticklabels=False,cbar=False)","3f1c33d2":"#Clean the data\ntrain_data.isnull().sum()","2a73575d":"#drop features that I think are not needed for RME calculation\ntrain_data = train_data.drop(columns=['Group', 'Total Deaths', 'Week-Ending Date', 'id', 'Footnote', 'Month', 'Year', 'End Date', 'Data As Of'])","5b0c1c59":"train_data = train_data.loc[~(train_data['HHS Region'].isin(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']))]","bf9b7626":"train_data['COVID-19 Deaths'] = train_data['COVID-19 Deaths'].astype('int32')\ntrain_data['MMWR Week'] = train_data['MMWR Week'].astype('Int64')\ntrain_data = train_data.loc[~(train_data['MMWR Week'].isna())]","2a22f5b2":"train_data['Start Date'] = train_data['Start Date'].replace('12\/29\/2019', '1')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/05\/2020', '2')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/12\/2020', '3')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/19\/2020', '4')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/26\/2020', '5')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/02\/2020', '6')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/09\/2020', '7')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/16\/2020', '8')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/23\/2020', '9')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/01\/2020', '10')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/08\/2020', '11')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/15\/2020', '12')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/22\/2020', '13')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/29\/2020', '14')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/05\/2020', '15')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/12\/2020', '16')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/19\/2020', '17')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/26\/2020', '18')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/03\/2020', '19')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/10\/2020', '20')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/17\/2020', '21')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/24\/2020', '22')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/31\/2020', '23')\ntrain_data['Start Date'] = train_data['Start Date'].replace('06\/07\/2020', '24')\ntrain_data['Start Date'] = train_data['Start Date'].replace('06\/14\/2020', '25')\ntrain_data['Start Date'] = train_data['Start Date'].replace('06\/21\/2020', '26')\ntrain_data['Start Date'] = train_data['Start Date'].replace('06\/28\/2020', '27')\ntrain_data['Start Date'] = train_data['Start Date'].replace('07\/05\/2020', '28')\ntrain_data['Start Date'] = train_data['Start Date'].replace('07\/12\/2020', '29')\ntrain_data['Start Date'] = train_data['Start Date'].replace('07\/19\/2020', '30')\ntrain_data['Start Date'] = train_data['Start Date'].replace('07\/26\/2020', '31')\ntrain_data['Start Date'] = train_data['Start Date'].replace('08\/02\/2020', '32')\ntrain_data['Start Date'] = train_data['Start Date'].replace('08\/09\/2020', '33')\ntrain_data['Start Date'] = train_data['Start Date'].replace('08\/16\/2020', '34')\ntrain_data['Start Date'] = train_data['Start Date'].replace('08\/23\/2020', '35')\ntrain_data['Start Date'] = train_data['Start Date'].replace('08\/30\/2020', '36')\ntrain_data['Start Date'] = train_data['Start Date'].replace('09\/06\/2020', '37')\ntrain_data['Start Date'] = train_data['Start Date'].replace('09\/13\/2020', '38')\ntrain_data['Start Date'] = train_data['Start Date'].replace('09\/20\/2020', '39')\ntrain_data['Start Date'] = train_data['Start Date'].replace('09\/27\/2020', '40')\ntrain_data['Start Date'] = train_data['Start Date'].replace('10\/04\/2020', '41')\ntrain_data['Start Date'] = train_data['Start Date'].replace('10\/11\/2020', '42')\ntrain_data['Start Date'] = train_data['Start Date'].replace('10\/18\/2020', '43')\ntrain_data['Start Date'] = train_data['Start Date'].replace('10\/25\/2020', '44')\ntrain_data['Start Date'] = train_data['Start Date'].replace('11\/01\/2020', '45')\ntrain_data['Start Date'] = train_data['Start Date'].replace('11\/08\/2020', '46')\ntrain_data['Start Date'] = train_data['Start Date'].replace('11\/15\/2020', '47')\ntrain_data['Start Date'] = train_data['Start Date'].replace('11\/22\/2020', '48')\ntrain_data['Start Date'] = train_data['Start Date'].replace('11\/29\/2020', '49')\ntrain_data['Start Date'] = train_data['Start Date'].replace('12\/06\/2020', '50')\ntrain_data['Start Date'] = train_data['Start Date'].replace('12\/13\/2020', '51')\ntrain_data['Start Date'] = train_data['Start Date'].replace('12\/20\/2020', '52')\ntrain_data['Start Date'] = train_data['Start Date'].replace('12\/27\/2020', '53')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/03\/2021', '54')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/10\/2021', '55')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/17\/2021', '56')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/24\/2021', '57')\ntrain_data['Start Date'] = train_data['Start Date'].replace('01\/31\/2021', '58')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/07\/2021', '59')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/14\/2021', '60')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/21\/2021', '61')\ntrain_data['Start Date'] = train_data['Start Date'].replace('02\/28\/2021', '62')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/07\/2021', '63')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/14\/2021', '64')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/21\/2021', '65')\ntrain_data['Start Date'] = train_data['Start Date'].replace('03\/28\/2021', '66')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/04\/2021', '67')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/11\/2021', '68')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/18\/2021', '69')\ntrain_data['Start Date'] = train_data['Start Date'].replace('04\/25\/2021', '70')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/02\/2021', '71')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/09\/2021', '72')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/16\/2021', '73')\ntrain_data['Start Date'] = train_data['Start Date'].replace('05\/23\/2021', '74')","7742cfde":"train_data = train_data.loc[~(train_data['Start Date'].isin(['01\/01\/2020', '02\/01\/2020', '04\/01\/2020', '05\/01\/2020', '06\/01\/2020', '07\/01\/2020', '08\/01\/2020', '09\/01\/2020', '10\/01\/2020', '12\/01\/2020', '01\/01\/2021', '02\/01\/2021', '03\/01\/2021', '04\/01\/2021', '05\/01\/2021']))]\n","0ede05e2":"#changing the values inside the columns to be able to graph them in the plots and for comparisons in the fiting of models","cacd08a0":"train_data['Age Group'] = train_data['Age Group'].replace('0-4 years', '1')\ntrain_data['Age Group'] = train_data['Age Group'].replace('5-17 years', '2')\ntrain_data['Age Group'] = train_data['Age Group'].replace('18-29 years', '3')\ntrain_data['Age Group'] = train_data['Age Group'].replace('30-39 years', '4')\ntrain_data['Age Group'] = train_data['Age Group'].replace('40-49 years', '5')\ntrain_data['Age Group'] = train_data['Age Group'].replace('50-64 years', '6')\ntrain_data['Age Group'] = train_data['Age Group'].replace('65-74 years', '7')\ntrain_data['Age Group'] = train_data['Age Group'].replace('75-84 years', '8')\ntrain_data['Age Group'] = train_data['Age Group'].replace('85 years and over', '9')","3ff95866":"train_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Hispanic', '1')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Non-Hispanic American Indian or Alaska Native', '2')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Non-Hispanic Asian', '3')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Non-Hispanic Black', '4')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Non-Hispanic More than one race', '5')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Non-Hispanic Native Hawaiian or Other Pacific Islander', '6')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Non-Hispanic White', '7')\ntrain_data['Race and Hispanic Origin Group'] = train_data['Race and Hispanic Origin Group'].replace('Unknown', '8')","3164af96":"#changing the values type into ants to make sure that they can be compare later on in the models if needed to","db3badd0":"train_data['Start Date'] = pd.to_numeric(train_data['Start Date'], downcast='integer', errors='coerce')\ntrain_data['Race and Hispanic Origin Group'] = pd.to_numeric(train_data['Race and Hispanic Origin Group'], downcast='integer', errors='coerce')\ntrain_data['Age Group'] = pd.to_numeric(train_data['Age Group'], downcast='integer', errors='coerce')","1840c282":"sns.barplot(y = \"COVID-19 Deaths\", x = \"Race and Hispanic Origin Group\", data = train_data)","066340ce":"#Non hispanic people seem to be dying the most from this graph\n#I thought my fellow hispanics would be first since we party a lot","25ba5ed3":"sns.barplot(y = \"COVID-19 Deaths\", x = \"Age Group\", data = train_data)","aabce163":"#The older you are the more you seem to die by Covid-19. Protect your grandparents","28678381":"sns.barplot(y = \"COVID-19 Deaths\", x = \"Start Date\", data = train_data)","9e83be17":"#i know this might seem confusing due to the variables in the bottom all jumbo up\n#but I'm looking at the bars instead and they look great","dd637ebe":"from sklearn.model_selection import train_test_split\ntrain_data = train_data.drop(columns=['HHS Region'])","5661a101":"all_index = list(range(len(train_data)))\nx_train, x, y_train, y,train_index,test_index = train_test_split(train_data['Start Date'].values,train_data[\"COVID-19 Deaths\"].values, all_index,test_size = 0.2161)\nx_train = x_train.reshape(-1,1)\nx = x.reshape(-1,1)\ny_train = y_train.reshape(-1,1)\ny = y.reshape(-1,1)\n\n#normalize = preprocessing.Normalizer()\n#x_train = normalize.fit_transform(x_train)\n#x = normalize.fit_transform(x)\n\n#scaler = StandardScaler()\n#scaler.fit(x_train)\n#x_train = scaler.transform(x_train)\n\n#x = scaler.transform(x)","aaf050ce":"#train_index, test_index = train_test_split(all_index, test_size = 0.3)\n#train = train_data.iloc[train_index, :]\n#test = train_data.iloc[test_index, :]\n#train_proportion = get_class_proportion(train)\n#test_proportion = get_class_proportion(test)","401151a7":"pd.DataFrame(train_data.dtypes)","b3ec7c18":"print(x_train)","6fcf67cd":"#LASSO","047c8dac":"from sklearn.linear_model import Lasso\nlasso_Model = Lasso(alpha=0.3)\nl_model = lasso_Model.fit(x_train,y_train)#x_train.reshape(-1, 1),y_train.reshape(-1, 1)\n#prediction_lasso = r.predict(x)\n","70cf4292":"prediction_lasso  = l_model.predict(x)\nprediction_lasso = prediction_lasso\nmse = mean_squared_error(y, prediction_lasso)\nrmse = np.sqrt(mse)\ncv_r = cross_val_score(l_model, x , y , cv = 10, scoring = None)","2a8600e1":"cv_r_df = pd.DataFrame(cv_r)\ncv_r_df.describe()","3f04da13":"#OLS","7c8e53c8":"import statsmodels.api as sm\nOLS_model = sm.OLS(x_train,y_train)\nOLS_model = OLS_model.fit()","9ad35da7":"prediction_OLS = OLS_model.predict(x)\nmse_OLS = np.square(np.subtract(y,prediction_OLS)).mean()\nrmse_OLS = math.sqrt(mse_OLS)\nprint(rmse_OLS)","403df7bc":"#RIDGE","ddeefcd2":"from sklearn.linear_model import Ridge\nridge_model = Ridge(alpha=1.0)\nridge_model = ridge_model.fit(x_train,y_train)\nprediction_ridge = ridge_model.predict(y_train)","d9b2a78b":"PR = pd.DataFrame(prediction_ridge)\nPR.describe","7b610fd7":"mse_ridge = np.square(np.subtract(y_train,prediction_ridge)).mean()\nrmse_ridge = math.sqrt(mse_ridge)\nprint(rmse_ridge)\ncv_RM = cross_val_score(ridge_model, x , y , cv = 10, scoring = None)\ncv_RM_df = pd.DataFrame(cv_RM)\ncv_RM_df.describe()","59840bcb":"#Elastic","c7cccea4":"from sklearn.linear_model import ElasticNet\nElastic_model = ElasticNet(random_state=0)\nElastic_model = Elastic_model.fit(x_train,y_train)\nprediction_Elastic = Elastic_model.predict(x)","9b01b8b9":"mse_Elastic = np.square(np.subtract(y,prediction_Elastic)).mean()\nrmse_Elastic = math.sqrt(mse_Elastic)\nprint(rmse_Elastic)\ncv_EN = cross_val_score(Elastic_model, x , y , cv = 10, scoring = None)\ncv_EN_df = pd.DataFrame(cv_EN)\ncv_EN_df.describe()\n","1f9433de":"#test_lasso_Model = Lasso(alpha=0.3, normalize=True)\n\n#test_lasso_Model.fit(x.reshape(-1, 1),y.reshape(-1, 1))#x_train.reshape(-1, 1),y_train.reshape(-1, 1)\n#test_prediction_lasso = test_lasso_Model.predict(x.reshape(-1, 1))\n#test_prediction_lasso = test_prediction_lasso","f1a78d3c":"#test_mse_lasso = np.square(np.subtract(x,test_prediction_lasso)).mean()\n#test_rmse_lasso = math.sqrt(test_mse_lasso)\n#print(test_rmse_lasso)","03fa0657":"#now test","b77300f6":"output = pd.DataFrame({\n    \"id\": test_data[\"id\"],\n    \"Covid-19 Deaths\": prediction_lasso\n})\n\noutput.to_csv(\"submission.csv\", index = False)\nprint(\"Your submission was succesfully saved!\")","54698817":"I noticed there was gonna be outliers if I didnt drop the values below in monthly due to the fact im using mmr week","52dc6de5":"switch my start date weekly manually and make them into 1 so im able to switch their type into integers","bb0a7aaf":"change data type to int to be able to plot graphs later on","8d224b26":"I do my calculation of rmse, describe and make the models below","2bb87c75":"Check for missing values above","c7905869":"Now im going to change these columns into ints for the graphs too"}}