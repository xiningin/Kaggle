{"cell_type":{"a7169f6d":"code","298f440a":"code","e4a08dc9":"code","8d903186":"code","029f78a6":"code","a11c2123":"code","6114fecb":"code","9e593048":"code","41d63789":"code","d9f802f2":"code","b7235fa0":"code","3c2cf318":"code","649ac416":"code","9fe75f31":"code","9e1a837a":"code","b155124b":"code","6273d61b":"code","ee1c517a":"code","35645e48":"code","28933471":"code","47d1d275":"code","8788714f":"code","672f4107":"code","4c266633":"code","eb9080e1":"code","7682bc40":"code","0f0b8f8a":"code","e604183f":"markdown","bd7bc78b":"markdown","8d222c61":"markdown","7ae14e2b":"markdown","b877da9e":"markdown"},"source":{"a7169f6d":"from fastai.vision import *","298f440a":"class CustomImageItemList(ImageItemList):\n    def open(self, fn):\n        img = fn.reshape(28, 28)\n        img = np.stack((img,)*3, axis=-1) # convert to 3 channels\n        return Image(pil2tensor(img, dtype=np.float32))\n\n    @classmethod\n    def custom_csv(cls, path:PathOrStr, csv_name:str, imgIdx:int=1, header:str='infer', **kwargs) -> 'ItemList':\n        df = pd.read_csv(Path(path)\/csv_name, header=header)\n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        # convert pixels to an ndarray\n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values \/ 783.0, axis=1).values\n        return res","e4a08dc9":"test = CustomImageItemList.custom_csv(path=Path('..\/input\/'), csv_name='test.csv', imgIdx=0)\ndata = (CustomImageItemList.custom_csv(path=Path('..\/input\/'), csv_name='train.csv')\n                       .random_split_by_pct(.2)\n                       .label_from_df(cols='label')\n                       .add_test(test, label=0)\n                       .databunch(bs=64, num_workers=0)\n                       .normalize(imagenet_stats))","8d903186":"data.show_batch(rows=3, figsize=(12,9))","029f78a6":"learn = create_cnn(data, models.resnet50, metrics=accuracy, model_dir = Path('..\/working\/'))","a11c2123":"learn.lr_find()\nlearn.recorder.plot()","6114fecb":"learn.fit_one_cycle(2, max_lr=slice(1e-2,1e-1))","9e593048":"learn.save('50-stage-1')","41d63789":"learn.lr_find()\nlearn.recorder.plot()","d9f802f2":"learn.unfreeze()","b7235fa0":"learn.fit_one_cycle(2,slice(7e-6,1e-5))","3c2cf318":"learn.save('50-stage-2')","649ac416":"learn.lr_find()\nlearn.recorder.plot()","9fe75f31":"learn.fit_one_cycle(2,slice(2e-5,1e-4))","9e1a837a":"learn.save('50-stage-3')","b155124b":"learn.lr_find()\nlearn.recorder.plot()","6273d61b":"learn.fit_one_cycle(2,slice(1e-4,2e-4))","ee1c517a":"learn.save('50-stage-4')","35645e48":"learn.lr_find()\nlearn.recorder.plot()","28933471":"learn.fit_one_cycle(2,slice(5e-6,2e-5))","47d1d275":"learn.save('50-stage-5')","8788714f":"learn.load('50-stage-5')\npreds, y, losses = learn.get_preds(ds_type=DatasetType.Test, with_loss=True)","672f4107":"y = torch.argmax(preds, dim=1)","4c266633":"preds.shape, len(y)","eb9080e1":"submission_df = pd.DataFrame({'ImageId': range(1, len(y) + 1), 'Label': y}, columns=['ImageId', 'Label'])\nsubmission_df.head()","7682bc40":"submission_df.to_csv('submission.csv', index=False)","0f0b8f8a":"!head submission.csv","e604183f":"## Creating The Predictions and saving it as submissions.csv","bd7bc78b":"## <b>Description<\/b>\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.**\n\n\n### <b>Acknowledgements <\/b>\nMore details about the dataset, including algorithms that have been tried on it and their levels of success, can be found at http:\/\/yann.lecun.com\/exdb\/mnist\/index.html. The dataset is made available under a Creative Commons Attribution-Share Alike 3.0 license.","8d222c61":"## Creating a Custom Class and Function to convert the CSV to ImageItemList","7ae14e2b":"## Importing Fastai for classification","b877da9e":"## Using Resnet50 for Classifying"}}