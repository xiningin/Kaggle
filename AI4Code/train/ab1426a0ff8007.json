{"cell_type":{"4fd17501":"code","9d31409e":"code","95753d69":"code","bac23d17":"code","b1e63c42":"code","6554edb8":"markdown"},"source":{"4fd17501":"import pandas as pd\nimport numpy as np\n\ntest = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntest_text = test[['excerpt']].copy()\ntest_text.rename(columns={'excerpt':'text'}, inplace=True)\ntest_text.to_csv('test_data.csv', index=False)","9d31409e":"from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\ntokenizer = AutoTokenizer.from_pretrained(\"..\/input\/huggingface-roberta\/roberta-base\")\n\ntest_encodes = tokenizer([i for i in test_text.text], max_length=325, truncation=True)","95753d69":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CommonLitDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\ntest_dataset = CommonLitDataset(test_encodes)","bac23d17":"from torch.utils.data import DataLoader\nfrom transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=16, collate_fn=data_collator\n)\n\n# for step, batch in enumerate(test_dataloader):\n#     print(batch[\"input_ids\"].shape)\n#     if step > 5:\n#         break","b1e63c42":"from transformers import Trainer, TrainingArguments\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained('..\/input\/commonlit-run-glue\/output')\nmodel.load_state_dict(torch.load(\"..\/input\/commonlit-run-glue-fit\/model.pt\"))\nmodel.to(device)\npreds = []\nfor batch in test_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n        prediction = outputs.logits\n        preds.extend(np.array(prediction.cpu().squeeze()))\n\nsample = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')\nsample.target = preds\nsample.to_csv('submission.csv',index=False)\nsample","6554edb8":"**Training notebook** [here](https:\/\/www.kaggle.com\/bumjunkoo\/commonlit-run-glue\/edit) will take around 40 minutes to run with GPU enabled   \n**Fitting notebook** [here](https:\/\/www.kaggle.com\/bumjunkoo\/commonlit-run-glue-fit) will take 1 hour and ~40 minutes to run with GPU enabled"}}