{"cell_type":{"c98c9c9a":"code","0492dba0":"code","6a28b132":"code","35b3b62e":"code","2a8e50cc":"code","a2d997b2":"code","82269fa8":"code","4ad26f52":"code","3801ac2d":"code","5f595fc9":"code","f399e297":"code","02f7ffa6":"code","2ad09aaf":"code","1d4d7185":"code","255bb039":"code","f323ac2b":"code","f3223410":"code","07437ca3":"code","3e0e1f18":"code","6aec93c4":"code","2e9a2f5b":"code","68a84f2d":"code","b9b6d8f8":"code","2da0d1df":"code","aa220349":"code","2501c7f6":"code","be309981":"code","65f7a38d":"code","89d8efff":"code","ef2d626d":"code","ded89672":"code","56a48e33":"code","4e33a6a1":"code","7476d727":"code","4e90a0c8":"code","b6f562c5":"code","f585680a":"code","cf017551":"code","ca24b231":"code","73c4f907":"code","1de6305f":"code","afda5d89":"code","f19f7f19":"code","3a0e15c4":"code","3235862f":"code","180f22ce":"code","810e5eaa":"code","698543fa":"code","c36a1495":"code","7b40d897":"code","44131349":"code","c7446892":"code","f1a188fe":"code","18710dce":"code","720c94aa":"code","677b03d4":"code","7dadbef4":"code","5c819a48":"code","50b52584":"code","464add09":"code","3e108818":"code","b3cf73c2":"code","7c4a3551":"markdown","4ccc1761":"markdown","eaf5b036":"markdown","4722ce7c":"markdown","591325c9":"markdown","30864499":"markdown","541320b5":"markdown","e2de26dc":"markdown","bebea86f":"markdown","de48e384":"markdown","5b0d46d4":"markdown","2e94c643":"markdown","2ac9d8bd":"markdown","b860bd62":"markdown","e5752e51":"markdown","feba9bfe":"markdown","9ad6da0e":"markdown","dc6e32bd":"markdown"},"source":{"c98c9c9a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfiles = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n        \nprint(files)","0492dba0":"df = pd.read_csv(files[2])\ndf.head()","6a28b132":"df.shape","35b3b62e":"print(f'{(\"Column Name\").rjust(25)}   {\"#NaNs\": <10} {\"#Unique Values\"}')\nfor column in df.columns:\n    uv = df[column].unique()\n    if len(uv)>10: uv=\"\"\n        \n    print(f'{(column).rjust(25)}   {str(df[column].isnull().sum()): <10} {len(df[column].unique())}\\t\\t{str(uv): <10}')","2a8e50cc":"import matplotlib.pyplot as plt\n\ndef how_many_in_cat_plot(df, variable, color, a, i):\n    ax = plt.subplot(5, 3, (i+1))\n    ax.tick_params(labelrotation=15)\n    #df[variable].hist(ax = ax)\n    plt.hist(df[variable], facecolor = color, alpha=a)\n    plt.title(variable)\n    ","a2d997b2":"df.columns","82269fa8":"colors = ['red', 'blue', 'orange', 'green', 'magenta', 'pink', 'black', 'grey']\nfig = plt.figure(figsize = (30,30))\ntemp_df = df[df.columns].copy(deep=True)\n\nfor i, feature in enumerate(['city', 'city_development_index', 'gender',\n       'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'experience', 'company_size', 'company_type',\n       'last_new_job', 'training_hours', 'target']):\n    \n    # Replace NAN with Missing\n    temp_df[feature] = df[feature].fillna('Missing')\n    how_many_in_cat_plot(temp_df, feature, colors[i%len(colors)], 0.5, i)\n    \nplt.show()","4ad26f52":"for feature in ['city', 'city_development_index', 'gender',\n       'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'experience', 'company_size', 'company_type',\n       'last_new_job', 'training_hours']:\n    \n    print(df.groupby(feature)['target'].value_counts())\n    print(df.groupby(feature)['target'].mean().sort_values(ascending=False))","3801ac2d":"df.head()","5f595fc9":"print(df.groupby('city')['target'].value_counts()['city_171'])","f399e297":"df_final = pd.DataFrame()","02f7ffa6":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stat, pylab\n\nfeature = 'city_development_index'\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df[feature]) #, fit=stat.norm)\nplt.title('Before Scaling')\nplt.subplot(132)\ndf[feature].hist()\nplt.subplot(133)\nstat.probplot(df[feature], dist='norm', plot=pylab)\nplt.show()","2ad09aaf":"temp_df = pd.DataFrame()","1d4d7185":"# Box Cox T\nfeature = 'cdi_boxcox'\ntemp_df[feature], parameter = stat.boxcox(df['city_development_index'])\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(temp_df[feature], fit=stat.norm)\nplt.title('After Transformation')\nplt.subplot(132)\ntemp_df[feature].hist()\nplt.subplot(133)\nstat.probplot(temp_df[feature], dist='norm', plot=pylab)\nplt.show()","255bb039":"print(f'Box Cox Parameter: {parameter}')\ntemp_df.head()","f323ac2b":"# 1\/Log T\nfeature = 'cdi_ExpOfReci'\ntemp_df[feature] = (1\/(df['city_development_index'])**(0.01))\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(temp_df[feature], fit=stat.norm)\nplt.title('After Transformation')\nplt.subplot(132)\ntemp_df[feature].hist()\nplt.subplot(133)\nstat.probplot(temp_df[feature], dist='norm', plot=pylab)\nplt.show()","f3223410":"temp_df.head()","07437ca3":"df_final['city_development_index'] = df['city_development_index']\ndf_final.head()","3e0e1f18":"df_final['relevent_experience'] = np.where(df['relevent_experience']=='Has relevent experience', 1, 0)\ndf_final.head()","6aec93c4":"df['experience'].value_counts().sort_values(ascending=False)\ndf.loc[df['experience']== '>20' , 'experience'] = 21\ndf.loc[df['experience']== '<1' , 'experience'] = 0.5\n\ndf_final['experience'] = df['experience']\ndf_final.head()","2e9a2f5b":"df.loc[df['last_new_job']== '>4' , 'last_new_job'] = 5\ndf.loc[df['last_new_job']== 'never' , 'last_new_job'] = 0\ndf.head(10)","68a84f2d":"df['last_new_job'].fillna(df['last_new_job'].mode()[0],inplace=True)\ndf['last_new_job'] = df['last_new_job'].astype(int)","b9b6d8f8":"df_final['last_new_job'] = df['last_new_job']\ndf_final.head()","2da0d1df":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stat, pylab\n\nfeature = 'training_hours'\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df[feature]) #, fit=stat.norm)\nplt.title('Before Scaling')\nplt.subplot(132)\ndf[feature].hist()\nplt.subplot(133)\nstat.probplot(df[feature], dist='norm', plot=pylab)\nplt.show()","aa220349":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df[['training_hours']])\ndf_scaled = pd.DataFrame(df_scaled, columns=['training_hours_scaled'])\ndf_scaled","2501c7f6":"feature = 'training_hours_scaled'\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df_scaled[feature]) #, fit=stat.norm)\nplt.title('After Scaling')\nplt.subplot(132)\ndf_scaled[feature].hist()\nplt.subplot(133)\nstat.probplot(df_scaled[feature], dist='norm', plot=pylab)\nplt.show()","be309981":"# Logarithmic T\ndf_scaled['training_hours_log'] = np.log(df['training_hours'])\nfeature = 'training_hours_log'\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df_scaled[feature], fit=stat.norm)\nplt.title('After Transformation')\nplt.subplot(132)\ndf_scaled[feature].hist()\nplt.subplot(133)\nstat.probplot(df_scaled[feature], dist='norm', plot=pylab)\nplt.show()","65f7a38d":"# Exponential T\nfeature = 'training_hours_exp'\ndf_scaled[feature] = df['training_hours']**(1\/5)\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df_scaled[feature], fit=stat.norm)\nplt.title('After Transformation')\nplt.subplot(132)\ndf_scaled[feature].hist()\nplt.subplot(133)\nstat.probplot(df_scaled[feature], dist='norm', plot=pylab)\nplt.show()","89d8efff":"# Box Cox T\nfeature = 'training_hours_boxcox'\ndf_scaled[feature], parameter = stat.boxcox(df['training_hours'])\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df_scaled[feature], fit=stat.norm)\nplt.title('After Transformation')\nplt.subplot(132)\ndf_scaled[feature].hist()\nplt.subplot(133)\nstat.probplot(df_scaled[feature], dist='norm', plot=pylab)\nplt.show()","ef2d626d":"print(f'Box Cox Parameter: {parameter}')\ndf_scaled.head()","ded89672":"# Box Cox T on Std Sacled\nfeature = 'train_hrs_scalingOnboxcox'\n\nscaler = StandardScaler()\ntemp_df_scaled = scaler.fit_transform(df_scaled[['training_hours_boxcox']])\ndf_scaled[feature] = pd.DataFrame(temp_df_scaled, columns=[feature])[feature]\n\nfig = plt.figure(figsize=(18,4))\nplt.subplot(131)\nax = sns.distplot(df_scaled[feature], fit=stat.norm)\nplt.title('After Transformation')\nplt.subplot(132)\ndf_scaled[feature].hist()\nplt.subplot(133)\nstat.probplot(df_scaled[feature], dist='norm', plot=pylab)\nplt.show()","56a48e33":"df_scaled.head()","4e33a6a1":"df_final['training_hours'] = df['training_hours'] # df_scaled['train_hrs_scalingOnboxcox']\ndf_final.head()","7476d727":"df['enrolled_university'].value_counts()","4e90a0c8":"df_final['enrolled_university'] = df['enrolled_university'].fillna(df['enrolled_university'].mode()[0])\ndf_final.head()","b6f562c5":"d = {'no_enrollment':0, 'Part time course':1,'Full time course':2}\ndf_final['enrolled_university'] = df_final['enrolled_university'].map(d)\ndf_final.head()","f585680a":"print(df['education_level'].isnull().sum())\ndf['education_level'].value_counts()","cf017551":"d = {'Primary School': 1, 'High School': 2, 'Graduate': 3,'Masters': 4, 'Phd': 5}\ndf_final['education_level'] = df['education_level']\ndf_final['education_level'].fillna(df['education_level'].mode()[0], inplace=True)\ndf_final['education_level'] = df_final['education_level'].map(d)\ndf_final.head()","ca24b231":"df[['city','target']].groupby('city').count().sort_values(['target'], ascending=False).head(10)","73c4f907":"df['major_discipline'].isnull().mean()","1de6305f":"## Replacing the NaN values with 'Missing' label\ndf['major_discipline'].fillna('Missing',inplace=True)\ndf['major_discipline'].value_counts()","afda5d89":"df.groupby(['major_discipline'])['target'].mean()","f19f7f19":"#Target Guided Ordinal Encoding\n\nordinal_labels = df.groupby(['major_discipline'])['target'].mean().sort_values().index\nordinal_labels_dict={k:i for i,k in enumerate(ordinal_labels,0)}\nordinal_labels_dict","3a0e15c4":"df_final['major_discipline'] = df['major_discipline'].map(ordinal_labels_dict)\ndf_final.head()","3235862f":"df['gender'].value_counts().plot(kind='barh')","180f22ce":"df.groupby(['gender'])['target'].value_counts()","810e5eaa":"import random\ndf_final['gender'] = df['gender'].fillna('Missing')\nfor i in range(0,len(df_final['gender'])):\n    if df_final['gender'].iloc[i] == 'Missing': \n        df_final['gender'].iloc[i] = random.choice(['Male','Female','Other'])\n        \ndf_final.head()","698543fa":"df_final['target'] = df['target']\ndf_final.groupby(['gender'])['target'].value_counts()","c36a1495":"df_gender = pd.get_dummies(df_final,drop_first=True)\ndf_final['gender_Male'] = df_gender['gender_Male']\ndf_final['gender_Other'] = df_gender['gender_Other']\ndf_final.drop('gender',inplace=True,axis=1)\ndf_final","7b40d897":"df_final['company_size'] = df['company_size']\ndf_final['company_type'] = df['company_type']","44131349":"df_final['company_type'].value_counts().plot(kind='barh')","c7446892":"df_final['company_size'].value_counts()","f1a188fe":"## Checking how many NaN od company_size and company_type are overlapping\n\ndf_final['company_size'].fillna('Missing',inplace=True)\ndf_final['company_type'].fillna('missing',inplace=True)\ndf_final.groupby(['company_size'])['company_type'].value_counts()","18710dce":"## Checking how the missing company sizes are distributed among the company types\ndf.groupby(['company_type'])['company_size'].value_counts()","720c94aa":"# Replacing that missing value of a company_type with the mode of company_type\n\nfor i in range(0,len(df_final)):\n    if (df_final['company_size'].iloc[i] == 'Missing') and (df_final['company_type'].iloc[i] == 'Early Stage Startup'):\n        df_final['company_size'].iloc[i] = '<10'\n        \n    if (df_final['company_size'].iloc[i] == 'Missing') and (df_final['company_type'].iloc[i] == 'Funded Startup'):\n        df_final['company_size'].iloc[i] = '50-99'\n        \n    if (df_final['company_size'].iloc[i] == 'Missing') and (df_final['company_type'].iloc[i] == 'NGO'):\n        df_final['company_size'].iloc[i] = '100-500'\n    \n    if (df_final['company_size'].iloc[i] == 'Missing') and (df_final['company_type'].iloc[i] == 'Other'):\n        df_final['company_size'].iloc[i] = '100-500'\n    \n    if (df_final['company_size'].iloc[i] == 'Missing') and (df_final['company_type'].iloc[i] == 'Public Sector'):\n        df_final['company_size'].iloc[i] = '1000-4999'\n        \n    if (df_final['company_size'].iloc[i] == 'Missing') and (df_final['company_type'].iloc[i] == 'Pvt Ltd'):\n        df_final['company_size'].iloc[i] = '50-99'    \n        ","677b03d4":"df_final","7dadbef4":"## Checking how many NaN of company_size and company_type are overlapping\n\ndf_final.groupby(['company_size'])['company_type'].value_counts()","5c819a48":"df_final[(df_final['company_type']=='missing') & (df_final['company_size']!='Missing')]","50b52584":"## Checking how many NaN of company_size and company_type are overlapping\n\ndf_final.groupby(['company_size'])['company_type'].value_counts()","464add09":"# Replacing that missing value of a company_type with the mode of company_type\n\nfor i in range(0,len(df_final)):\n    if ((df_final['company_type'].iloc[i] == 'missing') & (df_final['company_size'].iloc[i] != 'Missing')):\n        df_final['company_type'].iloc[i] = 'Pvt Ltd'    \n        ","3e108818":"df_final.groupby(['company_size'])['company_type'].value_counts()","b3cf73c2":"df_final[(df_final['company_type']=='missing') & (df_final['company_size']!='Missing')]","7c4a3551":"### Gender","4ccc1761":"#### Depending on the model, we might need the scaled and transformed data or we might not.","eaf5b036":"### City Development Index","4722ce7c":"#### From the distribution curves and Q-Q plots, it is evident that Box Cox Transformation gives the closest to Normal Distribution, second being the Exponential Transformation with exponent=0.2","591325c9":"### Company Size and Company Type","30864499":"### Creating a Final DataFrame","541320b5":"#### Thus, we notice that on performing Standard Scaling on Box Cox Transformed data, the distribution remains the same while it is linearly shifted so that the mean = 0.","e2de26dc":"Even distribute Male\/Female\/Other wherever Gender is missing.","bebea86f":"### Relevent Experience","de48e384":"#### To add:\n- ~~'city'~~ >> dropped\n- ~~'city_development_index'~~\n- ~~'gender'~~\n- ~~'relevent_experience'~~\n- ~~'enrolled_university'~~\n- ~~'education_level'~~\n- ~~'major_discipline'~~\n- ~~'experience'~~\n- 'company_size'\n- 'company_type'\n- ~~'last_new_job'~~\n- ~~'training_hours'~~ >> scaled, transformed","5b0d46d4":"### Education Level","2e94c643":"### Major Discipline","2ac9d8bd":"### Training Hours","b860bd62":"One-Hot Encoding Gender","e5752e51":"#### Let's see Standard Scaling on Box Cox Transformaed data","feba9bfe":"### Experience","9ad6da0e":"### Last New Job","dc6e32bd":"### Enrolled University"}}