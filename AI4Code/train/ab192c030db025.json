{"cell_type":{"bda330c9":"code","2a6ed054":"code","c69b9ed1":"code","69ad659c":"code","e839dee7":"code","1f1f0cb9":"code","04176198":"code","4c70ca09":"code","f7c9387b":"code","02a46f64":"code","633bd292":"code","f6038b9f":"code","1c367581":"code","eb6f06c6":"code","a188ee26":"code","a7700955":"code","820dafbf":"code","a0810844":"code","e028b2dc":"code","9d34f2bd":"code","6961ba98":"code","f653e9f8":"code","b515f664":"code","240d86b8":"code","9693bc61":"code","f18e304d":"code","8bb45d94":"code","f25f9964":"code","006b16f0":"code","8c2e3a01":"code","5ec428f2":"code","5c29b9a8":"code","533389cc":"code","482c9b12":"markdown","34692948":"markdown","ad1af25d":"markdown","d3542a36":"markdown","40127959":"markdown","20681d1c":"markdown","cd52b406":"markdown","61eda333":"markdown","b3ad447c":"markdown"},"source":{"bda330c9":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score\nfrom sklearn import preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom sklearn import metrics","2a6ed054":"df=pd.read_csv('..\/input\/fetal-health-classification\/fetal_health.csv')","c69b9ed1":"df.T","69ad659c":"df.shape","e839dee7":"columns=df.columns\ncolumns_new=[]\nfor i in columns:\n    columns_new.append(any(df[i].isnull()|df[i].isnull()))\ndf=df.drop(columns[columns_new],axis=1)","1f1f0cb9":"df.shape","04176198":"ax = sns.countplot(df.fetal_health,label=\"Count\")       # M = 212, B = 357\ndf.fetal_health.value_counts()","4c70ca09":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.fetal_health==1])","f7c9387b":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.fetal_health==2])","02a46f64":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.fetal_health==3])","633bd292":"X_train, X_test, y_train, y_test=train_test_split(\n    df.drop(['fetal_health'], axis=1),\n    df[['fetal_health']],\n    stratify=df[['fetal_health']],\n    shuffle=True,\n    test_size=0.3,\n    random_state=41)","f6038b9f":"{'train':X_train.shape,'test':X_test.shape}","1c367581":"corrMatrix = X_train.corr()\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrMatrix, annot=True,ax=ax)\nplt.show()","eb6f06c6":"correlated_features = set()\nfor i in range(len(corrMatrix .columns)):\n    for j in range(i):\n        if abs(corrMatrix.iloc[i, j]) > 0.7:\n            colname = corrMatrix.columns[i]\n            correlated_features.add(colname)\nprint(correlated_features)","a188ee26":"X_train.drop(labels=correlated_features, axis=1, inplace=True)\nX_test.drop(labels=correlated_features, axis=1, inplace=True)","a7700955":"corrMatrix = X_train.corr()\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrMatrix, annot=True,ax=ax)\nplt.show()","820dafbf":"{'train':X_train.shape,'test':X_test.shape}","a0810844":"constant_filter = VarianceThreshold(threshold=0.0)\nconstant_filter.fit(X_train)\nX_train = constant_filter.transform(X_train)\nX_test = constant_filter.transform(X_test)\n\n{'train':X_train.shape,'test':X_test.shape}","e028b2dc":"mm_scaler = preprocessing.StandardScaler()\nX_train = pd.DataFrame(mm_scaler.fit_transform(X_train))\n\nX_test = pd.DataFrame(mm_scaler.transform(X_test))","9d34f2bd":"def conf_matrix(matrix,pred):\n    class_names= [0,1]# name  of classes\n    fig, ax = plt.subplots()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names)\n    plt.yticks(tick_marks, class_names)\n    # create heatmap\n    sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n    ax.xaxis.set_label_position(\"top\")\n    plt.tight_layout()\n    plt.title('Confusion matrix', y=1.1)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.show()","6961ba98":"# Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(class_weight=\"balanced\",n_estimators=200,random_state = 1)\nrf.fit(X_train, y_train.values.ravel())\ny_pred=rf.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\nprint(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))","f653e9f8":"# make class predictions with the model\ny_pred = rf.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test,normalize='true')\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","b515f664":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train.values.ravel())\n\ny_pred=nb.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\n\nprint(\"Accuracy of Naive Bayes: {:.2f}%\".format(acc))","240d86b8":"# make class predictions with the model\ny_pred = nb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test,normalize='true')\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","9693bc61":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(X_train, y_train.values.ravel())\n\ny_pred=svm.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\n\nprint(\"Test Accuracy of SVM Algorithm: {:.2f}%\".format(acc))","f18e304d":"# make class predictions with the model\ny_pred = svm.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test,normalize='true')\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","8bb45d94":"# KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# try ro find best k value\nscore = []\n\nfor i in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn.fit(X_train, y_train.values.ravel())\n    score.append(knn.score(X_test, y_test.values.ravel()))\n    \nplt.plot(range(1,20), score)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K neighbors\")\nplt.ylabel(\"Score\")\nplt.show()\n\nacc = max(score)*100\nprint(\"Maximum KNN Score is {:.2f}%\".format(acc))","f25f9964":"knn = KNeighborsClassifier(n_neighbors =1)  # n_neighbors means k\nknn.fit(X_train, y_train.values.ravel())  ","006b16f0":"# make class predictions with the model\ny_pred = knn.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test,normalize='true')\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","8c2e3a01":"import xgboost as xgb\nxgbo=xgb.XGBClassifier(random_state=42,learning_rate=0.01)\nxgbo.fit(X_train, y_train.values.ravel())","5ec428f2":"# make class predictions with the model\ny_pred = xgbo.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test.values.ravel(),normalize='true')\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test.values.ravel())\nprint(report)","5c29b9a8":"from sklearn.ensemble import VotingClassifier\n\neclf1 = VotingClassifier(estimators=[('knn', knn),('rf', rf),('nb', nb)],\n                         voting='hard')\n\neclf1 = eclf1.fit(X_train, y_train)\nprint(eclf1.predict(X_test))","533389cc":"# make class predictions with the model\ny_pred = eclf1.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test,normalize='true')\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","482c9b12":"The esemble shows a better performance with class 2, which seems to be harder to predict.","34692948":"# Scaling data","ad1af25d":"# Removing correlated features","d3542a36":"# Data exploration","40127959":"# Training models","20681d1c":"# Result","cd52b406":"# Esemble models","61eda333":"# Removing features with 0 variance","b3ad447c":"# Spliting data into train and test sets"}}