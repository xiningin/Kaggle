{"cell_type":{"673ff651":"code","cb68ab3f":"code","f5e1b1f5":"code","2b84c106":"code","d07f6f73":"code","bfd38092":"code","7dbef477":"code","61968ba3":"code","b611b904":"code","9b51bd91":"code","3faf3865":"code","c175d94f":"code","ddecf850":"code","56b559ea":"code","80495959":"code","de0d8bb1":"code","ee031540":"code","1ed9a5f4":"code","8a1fd3de":"code","9898ece2":"code","79e09b23":"code","a2f8871f":"code","774d34a9":"code","1fc4b373":"code","8329f0dd":"code","9183aba8":"code","a4db0988":"code","bfc5bcf6":"markdown","35aedc01":"markdown","9a2c42e2":"markdown","64a9a71d":"markdown","de58a86f":"markdown","c9e56fec":"markdown","db8a250e":"markdown","85b3f418":"markdown","d3373253":"markdown","dcdb6b9a":"markdown"},"source":{"673ff651":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb68ab3f":"\n# basic librareis\nimport zipfile\nimport glob\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n# plotting and visualizations\nimport matplotlib \nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns \nimport missingno as msno\n# preprocessing\nfrom keras.preprocessing.image import (ImageDataGenerator, \n                                       img_to_array, \n                                       array_to_img, \n                                       load_img)\n\nfrom sklearn.model_selection import train_test_split\n# metrics\nfrom sklearn.metrics import (confusion_matrix, \n                             classification_report, \n                             accuracy_score, \n                             f1_score, \n                             roc_auc_score)\n# modeling\nimport tensorflow as tf\nfrom keras.models import Model,Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Dense,Flatten\n\nfrom keras.applications import resnet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping,LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n\n\n\nfrom keras import backend as K\nK.clear_session()\n\n# model plotting\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\n# mesc\nfrom sklearn.utils import shuffle\n\nprint('!Done')","f5e1b1f5":"#extraction of train and test set from zipfiles to data folder\nzip_files = glob.glob('\/kaggle\/input\/dogs-vs-cats\/*.zip')\n\nprint('{} files found in the input directory'.format(str(len(zip_files))) +'\\n')\nfor file in zip_files:\n    with zipfile.ZipFile(file, 'r') as Z:\n        Z.extractall('data')\n    print ('{} is extracted'.format(file.split('\/')[-1]) + '\\n')\n      \nprint('Extraction is completed' + '\\n')\n    \n  \n","2b84c106":"# Total number of images in train and test datasets\ntrain_dir = '\/kaggle\/working\/data\/train\/'\ntest_dir  = '\/kaggle\/working\/data\/test1\/'\nprint('No. of Train Images:' + str(len(os.listdir(train_dir))))\nprint('No. of Test Images:' + str(len(os.listdir(test_dir))))\n","d07f6f73":"# category and filepath extraction helper functions\ndef filename(path):\n    return [file for file in os.listdir(path)]\n\ndef category(path):\n    return [file.split('.')[0] for file in os.listdir(path)]\n\n#image name and labes\nx_train_imgname = filename(train_dir)\nx_test_imgname = filename(test_dir)\ny_train_label = category(train_dir)\n\n#creation of total dataframe and submission dataframe\ntrain_image_df = pd.DataFrame({ 'filename': x_train_imgname, 'category': y_train_label})\nsubmission_image_df = pd.DataFrame({'filename': x_test_imgname})\n\nprint(train_image_df.head(7))\nprint('********************')\nprint(submission_image_df.head(7))\n\n","bfd38092":"# Data split into train data and validation data\ntrain_valid_df, test_df = train_test_split(train_image_df, test_size = 0.04)\ntrain_df, valid_df = train_test_split(train_valid_df, test_size = 0.2)\n#train_valid_df = train_valid_df.reset_index(drop=True)\n#test_df = test_df.reset_index(drop=True)\n\n\n#train_images = train_valid_df.shape[0]\n#valid_images = test_df.shape[0]\ntrain_images = train_df.shape[0]\nvalid_images = valid_df.shape[0]\n#holdon_images = test_df.shape[0]\n#test_images = submission_image_df.shape[0]\n\nprint(train_valid_df.head(7))\nprint('********************')\nprint(test_df.head(7))\nprint('********************')\nprint(train_images)\nprint(valid_images)","7dbef477":"train_valid_df['category'].value_counts().plot.bar()","61968ba3":"test_df['category'].value_counts().plot.bar()","b611b904":"train_df['category'].value_counts().plot.bar()","9b51bd91":"valid_df['category'].value_counts().plot.bar()","3faf3865":"epoch = 50\nlearning_rate = 3e-5 \nlr_start = 0.00000001\nlr_min = 0.000001\nlr_max = 3e-5 \nlr_rampup_epochs = 1\nlr_sustain_epochs = 1\nlr_exp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < lr_rampup_epochs:\n        lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n        lr = lr_max\n    else:\n        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n    return lr","c175d94f":"size  = 224\nbatch_size = 128","ddecf850":"datagen = ImageDataGenerator(\n                             rotation_range=10,\n                             zoom_range=0.1,\n                             horizontal_flip=True,\n                             fill_mode='nearest',\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             preprocessing_function = preprocess_input)\n\nX_train = datagen.flow_from_dataframe(\n    train_df, \n    directory = train_dir, \n    x_col = 'filename',\n    y_col = 'category',\n    target_size= (size,size),\n    class_mode = 'categorical',\n    shuffle = True,\n    batch_size = batch_size)\n","56b559ea":"datagenValidation = ImageDataGenerator(preprocessing_function = preprocess_input)\n\nX_validation = datagenValidation.flow_from_dataframe(\n    valid_df, \n    directory = train_dir, \n    x_col = 'filename',\n    y_col = 'category',\n    target_size= (size,size),\n    class_mode = 'categorical',\n    shuffle = True,\n    batch_size = batch_size)","80495959":"test_df_1 = pd.DataFrame({ 'filename': test_df['filename']})\ntest_df_1.head(10)\n#veo que con esto igual tengo el mismo resultado","de0d8bb1":"X_test = datagenValidation.flow_from_dataframe(\n    test_df_1, \n    directory=train_dir, \n    x_col='filename',\n    y_col=None, #Important\n    class_mode=None,\n    target_size= (size,size),\n    shuffle=False\n)","ee031540":"earlystop = EarlyStopping(patience= 5)\n    \nlr_callback = LearningRateScheduler(lrfn, verbose = True)\n\ncallbacks = [earlystop, lr_callback]","1ed9a5f4":"#loading resent \nresNet = tf.keras.applications.ResNet50(weights = 'imagenet',\n                        include_top = False,\n                        input_shape = (224,224, 3))\n\nresNet.trainable = False # Freeze layers\nresNet_model = Sequential([\n        resNet,\n        Flatten(),\n        Dense(1024, activation = 'relu'),\n        Dropout(0.4),\n        Dense(2, activation = 'softmax')])\n     \n\noptimizer = optimizers.Adam(1e-5)\n\nresNet_model.summary()","8a1fd3de":"resNet_model.compile(optimizer = optimizer,\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])\n\n\n\nresnet_history = resNet_model.fit(X_train, epochs = 15,\n                          validation_data = X_validation,\n                          validation_steps= valid_images\/\/batch_size,\n                          steps_per_epoch= train_images\/\/batch_size,\n                          callbacks = callbacks)\n","9898ece2":"acc = resnet_history.history['accuracy']\nval_acc = resnet_history.history['val_accuracy']\nloss = resnet_history.history['loss']\nval_loss = resnet_history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","79e09b23":"res_pred = resNet_model.predict(X_test)","a2f8871f":"res_pred","774d34a9":"import numpy as np\ntest_df['res_pred'] = np.argmax(res_pred, axis = -1)\nlabels = dict((v,k) for k,v in X_train.class_indices.items())\ntest_df['res_pred'] = test_df['res_pred'].map(labels)","1fc4b373":"res_cf_matrix = confusion_matrix(test_df['category'],test_df['res_pred'])\nres_cf_matrix","8329f0dd":"res_sub_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n\nres_sub_data = res_sub_aug_map.flow_from_dataframe(\n             submission_image_df, test_dir,\n             x_col = 'filename',\n             y_col = None,\n             class_mode = None,\n             target_size = (size, size),\n             shuffle = False)","9183aba8":"res_pred_sub = resNet_model.predict(res_sub_data)\nsubmission_image_df['res_pred_sub'] = np.argmax(res_pred_sub, axis = -1)\nlabels = dict((v,k) for k,v in X_train.class_indices.items())\nsubmission_image_df['res_pred_sub'] = submission_image_df['res_pred_sub'].map(labels)\n\nprint(submission_image_df.head())","a4db0988":"pred_sample = submission_image_df.sample(18)\npred_sample.reset_index(drop = True, inplace = True)\n\nfig = plt.figure(figsize=(12,24))\nfig.patch.set_facecolor('#f5f6f6')\n\nfor index, row in pred_sample.iterrows():\n    filename = row['filename']\n    res_pred = row['res_pred_sub']\n    img = load_img( test_dir + filename, target_size= (size, size))\n    plt.subplot(6,3, index+1)\n    plt.imshow(img)\n    plt.gca().axis('off')\n    #plt.text(130, 175, 'vanila_pred: {}'.format(vani_pred), color='lightgreen',fontsize= 11, bbox=dict(facecolor='black', alpha=0.9))\n    plt.text(130, 200, 'resNet_pred: {}'.format(res_pred), color='red',fontsize= 11, bbox=dict(facecolor='black', alpha=0.9))\n    #plt.title(filename.split('.')[0])\n\nplt.tight_layout()\n#plt.subplots_adjust( wspace=0, hspace= 1)\nfig.text(0,1, 'Hey Siri! is it cat or dog?: Test data labels',{'fontfamily':'serif','size':24,'weight':'bold'})\nfig.show()\n   ","bfc5bcf6":"## Decaying learing rate setting function","35aedc01":"## Image agumentation data preparation with ImageDataGenerator","9a2c42e2":"## Setup Callbacks","64a9a71d":"## Lets train and validate Pre-trained ResNet50 model for top layers...","de58a86f":"## Final predictions on Test Set","c9e56fec":"## Building model for transfer learning on top of pretrained ResNet50 Model...","db8a250e":"## Lets split data into training and validation dataset, and visualize the data distribution...","85b3f418":"## Lets see ResNet predictions with confusion matrix ...","d3373253":"# Classification with ResNet50","dcdb6b9a":"## Import all required libraries"}}