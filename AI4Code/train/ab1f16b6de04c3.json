{"cell_type":{"e23f4576":"code","7c0e3f60":"code","f077cc2c":"code","fd051a64":"code","88685db2":"code","cede8b29":"code","9d6ab133":"code","19491d67":"code","aa548536":"code","91ce5bf5":"code","24aaa91b":"code","30bca697":"code","d81e69d6":"code","4e0a8e02":"code","cd206bb7":"code","35510354":"code","b6bb0b9c":"code","ce112958":"code","cd7d36d7":"code","b00351ee":"code","ba7fcbed":"markdown","75989320":"markdown","4cdf8943":"markdown","b9aa2273":"markdown","73077b7e":"markdown","27d38b6b":"markdown","9a4abf0a":"markdown"},"source":{"e23f4576":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport tensorflow as tf\nimport keras\nimport albumentations as A\nfrom sklearn import model_selection, preprocessing \nimport cv2\nimport tensorflow as tf\nimport numpy as np \nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\nfrom albumentations import (\n    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n    Rotate\n)\nAUTOTUNE = tf.data.experimental.AUTOTUNE","7c0e3f60":"INPUT_PATH = \"..\/input\/cassava-leaf-disease-classification\/\"\ntrain_images_path = INPUT_PATH+\"train_images\/\"\ntest_images_path = INPUT_PATH+\"test_images\/\"\nsample = \"..\/input\/cassava-leaf-disease-classification\/sample_submission.csv\"","f077cc2c":"df = pd.read_csv(INPUT_PATH+\"train.csv\")##..\/input\/cassava-leaf-disease-classification\/train.csv\"\ndf.head(5)","fd051a64":"for img in os.listdir(INPUT_PATH+\"train_images\/\")[:1]:\n    #print(img)\n    img = Image.open(os.path.join(train_images_path+img))\n\n    plt.imshow(img)\n    plt.show()","88685db2":"sample_df = pd.read_csv(sample)\nsample_df.head()","cede8b29":"num_classes = sorted(df[\"label\"].unique())\ndf.info()","9d6ab133":"df.label = df.label.astype(\"str\")\nbatch_size=8\ninput_size = (300, 300)","19491d67":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    validation_split = 0.1, #10 for validation \n    rotation_range=360,\n    #zca_whitening=True,\n    #zca_epsilon=1e-06,\n    width_shift_range=0.2,\n    #brightness_range=[-2, 2],\n    height_shift_range=0.2,\n    shear_range=0.1,\n    zoom_range=[0.5,1.0],\n    channel_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=None,\n    preprocessing_function=None,\n    )\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    #target_size=input_size,\n    class_mode=\"sparse\", \n    subset = \"training\"\n)\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1)\nvalid_generator = valid_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    #target_size=input_size ,\n    class_mode=\"sparse\", \n    subset=\"validation\")","aa548536":"plt.figure(figsize=(12,10))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    batch = train_generator.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(np.array(image[0,:,:,::-1]))\n    plt.axis(\"off\")\n# show the figure\nplt.show()            \n                        ","91ce5bf5":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom keras import Model\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Dense\n\ndef my_model():\n    model_weight_dir = \"..\/input\/tfkerasefficientnetimagenetnotop\/efficientnetb5_notop.h5\"\n    model = Sequential()\n    model.add( tf.keras.applications.EfficientNetB5(\n        include_top=False,\n        weights=model_weight_dir))\n\n\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(len(num_classes), activation=\"softmax\"))\n    model.summary()\n    return model ","24aaa91b":"# accuracy\ndef plot_hist(hist):\n    plt.plot(hist.history['accuracy'])\n    plt.plot(hist.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # loss\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n","30bca697":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    #validation_split = 0.1, #10 for validation \n    rotation_range=360,\n    width_shift_range=0.2,\n    #brightness_range=[-2, 2],\n    height_shift_range=0.2,\n    shear_range=0.1,\n    zoom_range=[0.5,1.0],\n    channel_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=None,\n    preprocessing_function=None,\n    )\n\n\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n","d81e69d6":"from sklearn.model_selection import KFold, StratifiedKFold\nY = df[['label']]\n#kf = KFold(n_splits = 5)                      \nskf = StratifiedKFold(n_splits= 5, random_state = 101, shuffle = True) ","4e0a8e02":"def get_model_name(k):\n    return 'model_'+str(k)+'.h5'","cd206bb7":"model = my_model()\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n             metrics=['accuracy'])","35510354":"\nVALIDATION_ACCURACY = []\nVALIDATION_LOSS = []\nnum_epochs = 20\nsave_dir = '.\/'\nfold_var = 1\n\nn = len(df.image_id.unique())\nfor train_index, val_index in skf.split(np.zeros(n),Y):\n    training_data = df.iloc[train_index]\n    validation_data = df.iloc[val_index]\n\n    print(len(training_data), len(validation_data))\n    \n    train_generator = train_datagen.flow_from_dataframe(\n    dataframe=training_data,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    class_mode=\"sparse\", \n    )\n    \n    valid_generator = valid_datagen.flow_from_dataframe(\n        dataframe=validation_data,\n        directory=train_images_path,\n        x_col=\"image_id\",\n        y_col=\"label\",\n        batch_size=batch_size,\n        class_mode=\"sparse\", \n        )\n    \n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n          filepath= save_dir+get_model_name(fold_var),\n          save_weights_only=False,\n          monitor='val_accuracy',\n          mode='max',\n          save_best_only=True, \n          verbose = 1)\n    \n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n    callbacks_list = [model_checkpoint, early_stopping]\n    \n    history = model.fit(train_generator,\n            epochs=num_epochs,\n            callbacks= callbacks_list,\n            validation_data=valid_generator)\n\n    plot_hist(history)\n\n    # LOAD BEST MODEL to evaluate the performance of the model\n    model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n\n    results = model.evaluate(valid_generator)\n    results = dict(zip(model.metrics_names,results))\n\n    VALIDATION_ACCURACY.append(results['accuracy'])\n    VALIDATION_LOSS.append(results['loss'])\n\n    tf.keras.backend.clear_session()\n\n    fold_var += 1\n","b6bb0b9c":"#model = model.load_weights(\".\/model_3.h5\")","ce112958":"\npredictions = []\nfor  image_id in sample_df.image_id:\n    img = Image.open(os.path.join(test_images_path+image_id))\n    img = np.expand_dims(img, axis=0)\n    predictions.append(np.argmax(model.predict(img)))\n\nsample_df[\"label\"] = predictions\nsample_df","cd7d36d7":"sample_df.head\n","b00351ee":"sample_df.to_csv(\"submission.csv\", index = False)","ba7fcbed":"**Let's Have a look of few data** ","75989320":"# **Prepare Dataset For training**","4cdf8943":"**Data Augmentation**","b9aa2273":"# Prepare Model, Train and Evaluate","73077b7e":"**trying KF**","27d38b6b":"# Loading Paths, Directory and Data-Folders ","9a4abf0a":"**Predict and make Submission**"}}