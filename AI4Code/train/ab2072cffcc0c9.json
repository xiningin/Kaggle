{"cell_type":{"6a59f48b":"code","ae7e65be":"code","ab0ad7b0":"code","8a75d0e5":"code","9b372af1":"code","f87e01aa":"code","a47001a2":"code","2dc42aa3":"code","8c233331":"code","f5b85f4c":"code","2640695a":"code","74601d03":"code","3a08ceb7":"code","f2fb0f83":"code","f17cc329":"code","eb7f0aaf":"code","81a58b37":"markdown","b8597d3a":"markdown","d4653b88":"markdown","4ddeb445":"markdown","5661d8c6":"markdown","d01b851d":"markdown","11b83d70":"markdown","d19740e6":"markdown","6282365c":"markdown","d43c89ff":"markdown","8be8d45e":"markdown","b5d46f59":"markdown","55d49cee":"markdown","c8afe0c1":"markdown","f3f0de66":"markdown","b85843bb":"markdown","f1cb7e95":"markdown"},"source":{"6a59f48b":"import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n### Make prettier the prints ###\nfrom colorama import Fore\nb_ = Fore.BLUE\nr_ = Fore.RED","ae7e65be":"seed = 42\ntf.random.set_seed(seed)\nrandom.seed(seed)\nnp.random.seed(seed)","ab0ad7b0":"BASE_PATH = \"..\/input\/hubmap-256x256\"\ntrain = os.path.join(BASE_PATH, \"train\")\nmasks = os.path.join(BASE_PATH, \"masks\")\n\nprint(f'{b_}Number of training images: {r_}{len(os.listdir(train))}')\nprint(f'{b_}Numner of masks: {r_}{len(os.listdir(masks))}')","8a75d0e5":"sample_filename = os.listdir(train)[6]\nsample_image = plt.imread(os.path.join(train, sample_filename))\nsample_mask = plt.imread(os.path.join(masks, sample_filename))\n\n_, ax = plt.subplots(1, 2)\nax[0].imshow(sample_image)\nax[0].set_title(\"Sample Image\")\nax[1].imshow(sample_mask)\nax[1].set_title(\"Mask\")","9b372af1":"def plot_ori_and_aug(aug):\n    \"\"\"\n    Plot the original sample image with its augmentation\n    \"\"\"\n    plt.figure(figsize=(10, 10))\n    _, ax = plt.subplots(1, 2)\n    ax[0].imshow(sample_image)\n    ax[0].set_title(\"Original\")\n    ax[1].imshow(augmented_image[0])\n    ax[1].set_title(aug);","f87e01aa":"# Add the image to a batch\nimage = tf.expand_dims(sample_image, 0) # I don't fully understand why this line is necesary but i can't replace it\naugmented_image = preprocessing.Resizing(128, 128, interpolation = \"bilinear\")(image)\n\nplot_ori_and_aug(\"Resizing\")","a47001a2":"augmented_image = preprocessing.Rescaling(1.\/5, offset = 0.5)(image)\n\nplot_ori_and_aug(\"Rescaling\")","2dc42aa3":"augmented_image = preprocessing.CenterCrop(height = 64, width = 64)(image)\n\nplot_ori_and_aug(\"CenterCrop\")","8c233331":"augmented_image = preprocessing.RandomCrop(height = 64, width = 64, seed = seed)(image)\n\nplot_ori_and_aug(\"RandomCrop\")","f5b85f4c":"# Here i used \"seed + 1\" because 42 retuns exactly the same image.\naugmented_image = preprocessing.RandomFlip(\"horizontal_and_vertical\", seed = seed + 1)(image)\n\nplot_ori_and_aug(\"RandomFlip\")","2640695a":"augmented_image = preprocessing.RandomTranslation(\n    height_factor = 0.8,\n    width_factor = 0.6,\n    fill_mode = \"reflect\",\n    interpolation = \"bilinear\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomTranslation\")","74601d03":"augmented_image = preprocessing.RandomRotation(\n    factor = 0.8,\n    fill_mode = \"wrap\",\n    interpolation = \"nearest\",\n    seed = seed,\n)(image)\n\nplot_ori_and_aug(\"RandomRotation\")","3a08ceb7":"augmented_image = preprocessing.RandomZoom(\n    height_factor = 0.2,\n    width_factor = -0.3,\n    fill_mode = \"constant\",\n    interpolation = \"bilinear\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomZoom\")","f2fb0f83":"augmented_image = preprocessing.RandomHeight(\n    factor = 0.7,\n    interpolation = \"nearest\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomHeight\")","f17cc329":"augmented_image = preprocessing.RandomWidth(\n    factor = 0.2,\n    interpolation = \"bicubic\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomWidth\")","eb7f0aaf":"data_augmentation = Sequential([\n    preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomZoom(\n        height_factor = 0.2,\n        width_factor = -0.3,\n        fill_mode = \"constant\",\n        interpolation = \"bilinear\",\n    )    \n])\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  augmented_image = data_augmentation(image)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0])\n  plt.axis(\"off\")","81a58b37":"## <font color = \"green\">Combining Layersr<\/font>\n","b8597d3a":"## <font color = \"green\">RandomRotation layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomRotation(\n    factor,\n    fill_mode=\"reflect\",\n    interpolation=\"bilinear\",\n    seed=None,\n    name=None,\n    fill_value=0.0,\n    **kwargs\n)\n```","d4653b88":"\n## <font color = \"green\">Rescaling layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.Rescaling(\n    scale, offset=0.0, name=None, **kwargs\n)\n```","4ddeb445":"# <font color = \"blue\">Data<\/font>","5661d8c6":"## <font color = \"green\">RandomZoom layer<\/font>\n\n\n```\ntf.keras.layers.experimental.preprocessing.RandomZoom(\n    height_factor,\n    width_factor=None,\n    fill_mode=\"reflect\",\n    interpolation=\"bilinear\",\n    seed=None,\n    name=None,\n    fill_value=0.0,\n    **kwargs\n)\n```","d01b851d":"## <font color = \"green\"> Resizing layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.Resizing(\n    height, width, interpolation=\"bilinear\", name=None, **kwargs\n)\n```\n\nYou can prove that it worked seeing the axes of the images.","11b83d70":"# <font color = \"blue\">Image Preprocessing & Augmentation Layers<\/font>","d19740e6":"## <font color = \"green\"> RandomTranslation layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomTranslation(\n    height_factor,\n    width_factor,\n    fill_mode=\"reflect\",\n    interpolation=\"bilinear\",\n    seed=None,\n    name=None,\n    fill_value=0.0,\n    **kwargs\n)\n```","6282365c":"## <font color = \"green\">RandomFlip layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomFlip(\n    mode=\"horizontal_and_vertical\", seed=None, name=None, **kwargs\n)\n```","d43c89ff":"# <font color = \"blue\">References<\/font>\n- [\nImage preprocessing & augmentation layers](https:\/\/keras.io\/api\/layers\/preprocessing_layers\/image_preprocessing\/)\n- [\nData Augmentation in Python: Everything You Need to Know](https:\/\/neptune.ai\/blog\/data-augmentation-in-python)\n- [[Tutorial]Augmentation with mask & Visualization\ud83d\udd25](https:\/\/www.kaggle.com\/piantic\/tutorial-augmentation-with-mask-visualization)\n- [Data augmentation](https:\/\/www.tensorflow.org\/tutorials\/images\/data_augmentation)","8be8d45e":"## <font color = \"green\">RandomCrop layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomCrop(\n    height, width, seed=None, name=None, **kwargs\n)\n```","b5d46f59":"# <font color = \"blue\">Preambule<\/font>\n\nThis notebook was made with the purpose of show to more people that Keras gives ten different layers which could be used to do **data augmentation** of images from this competition. I would to add that it would be nice if you comment why **albumentations** is a better option besides the fact that it provides with more methods, like **Color Jitter**. One advantage of using Keras layers is that it would be faster than algumentation because they can use GPU and TPU processors.","55d49cee":"## <font color = \"green\">RandomWidth layer<\/font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomWidth(\n    factor, interpolation=\"bilinear\", seed=None, name=None, **kwargs\n)\n```","c8afe0c1":"# <font color = \"blue\">Libraries<\/font>","f3f0de66":"# <font color = \"blue\">Reproducibility<\/font>","b85843bb":"## <font color = \"green\">CenterCrop layer<\/font>\n```\ntf.keras.layers.experimental.preprocessing.CenterCrop(\n    height, width, name=None, **kwargs\n)\n```","f1cb7e95":"## <font color = \"green\">RandomHeight layer<\/font>\n\n\n```\ntf.keras.layers.experimental.preprocessing.RandomHeight(\n    factor, interpolation=\"bilinear\", seed=None, name=None, **kwargs\n)\n```"}}