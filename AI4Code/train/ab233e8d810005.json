{"cell_type":{"7bb8ec6e":"code","b8435c1c":"code","31278536":"code","b9c56afa":"code","a4a1e809":"code","55d21376":"code","c95b5ef1":"code","4d20f031":"code","e589e95f":"code","dd6392e2":"markdown","d9f23d27":"markdown","63748561":"markdown","7bf7442b":"markdown","bdb32688":"markdown"},"source":{"7bb8ec6e":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls ","b8435c1c":"import detectron2\nimport torch\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom fastcore.all import *","31278536":"dataDir=Path('..\/input\/sartorius-cell-instance-segmentation')","b9c56afa":"# From https:\/\/www.kaggle.com\/stainsby\/fast-tested-rle\ndef rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef get_masks(fn, predictor):\n    im = cv2.imread(str(fn))\n    pred = predictor(im)\n    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n    take = pred['instances'].scores >= THRESHOLDS[pred_class]\n    pred_masks = pred['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    res = []\n    used = np.zeros(im.shape[:2], dtype=int) \n    for mask in pred_masks:\n        mask = mask * (1-used)\n        if mask.sum() >= MIN_PIXELS[pred_class]: # skip predictions with small area\n            used += mask\n            res.append(rle_encode(mask))\n    return res","a4a1e809":"ids, masks=[],[]\ntest_names = (dataDir\/'test').ls()","55d21376":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \ncfg.MODEL.WEIGHTS = os.path.join('..\/input\/train-model-cell-instance-segmentation', \"model_myfinal.pth\")  \ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\npredictor = DefaultPredictor(cfg)\nTHRESHOLDS = [.15, .35, .55]\nMIN_PIXELS = [75, 150, 75]","c95b5ef1":"encoded_masks = get_masks(test_names[0], predictor)\n\n_, axs = plt.subplots(1,2, figsize=(40,15))\naxs[1].imshow(cv2.imread(str(test_names[0])))\nfor enc in encoded_masks:\n    dec = rle_decode(enc)\n    axs[0].imshow(np.ma.masked_where(dec==0, dec))","4d20f031":"for fn in test_names:\n    encoded_masks = get_masks(fn, predictor)\n    for enc in encoded_masks:\n        ids.append(fn.stem)\n        masks.append(enc)","e589e95f":"pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","dd6392e2":"### Look at the outputs on a sample test file to sanity check\nI'm encoding here in the competition format and decoding back to bit mask just to make sure everything is fine","d9f23d27":"### Initiate a Predictor from our trained model","63748561":"#### Version history\n* V1 - Inference with basic model trained 1000 iterations\n* V2 - Same training procedure but for more iterations. Validation score .267, LB score .286\n* V3 - Same model weights as previously, but score thresholds set for each class individually. LB score .293 *\n* V4 - Another small inference time improvement - throw away predictions with area smaller than a threshold (set per cell type). LB score .294\n\n\\* *Initally that version had score .287 but that was due to a bug in the code*","7bf7442b":"### Looks good, so lets generate masks for all the files and create a submission","bdb32688":"## Inference and submission\nAfter [part one](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-1-3-input-data\/) and [part two](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-2-3-training) we have a trained model. I'm attaching it to this notebook through a dataset. Now all that's left is to run all the test files through it.\n\nThere are two minor details we need to handle:\n- The submission notebooks don't have access to the internet, in order to install detectron2 I needed to download dependecies with `pip download`, put them into a dataset and attach it to the notebook: https:\/\/www.kaggle.com\/slawekbiel\/detectron-05\n- The masks we submit can't overlap, see [the discussion](https:\/\/www.kaggle.com\/c\/sartorius-cell-instance-segmentation\/discussion\/279790#1550666). So I'm manually clipping the output returned from the model) I'm processing the masks ordereded by score, so in the case of conflict the more confident one remaines whole and the other one gets clipped."}}