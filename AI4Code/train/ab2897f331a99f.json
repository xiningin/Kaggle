{"cell_type":{"8fe860e2":"code","e7891b12":"code","d49a97e3":"code","2347f82e":"code","906b7c78":"code","cd99b311":"code","129977a9":"code","1389b8f5":"code","ffacdd17":"code","c3c92dc8":"code","b9a822f5":"code","d9140462":"code","0778ae39":"code","4cf14a63":"code","89c0a316":"code","a505ca43":"code","8202027c":"code","50cc28fb":"code","d853bccb":"code","29123b11":"code","122aa398":"code","55876af6":"code","e53d8332":"code","dff8b978":"code","8522560d":"code","500fdcbe":"markdown","a248ca53":"markdown","d20bcf38":"markdown","9f7b70bf":"markdown","7e224a3c":"markdown","f8b721c3":"markdown","a85d765a":"markdown","e006c4d9":"markdown","e631ea59":"markdown","17c628e5":"markdown","5e9622c6":"markdown","f26c906d":"markdown","c3070564":"markdown"},"source":{"8fe860e2":"!pip install ipython-autotime\n \n%load_ext autotime","e7891b12":"import os\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nfrom PIL import Image\nfrom glob import glob\nfrom skimage.io import imread\nfrom os import listdir\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nimport cv2\nimport copy\nfrom random import shuffle\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom imblearn.metrics import sensitivity_specificity_support\nfrom imgaug import augmenters as iaa\nimport imgaug as ia\n\n\n# import numpy as np\n# import matplotlib.pyplot as plt\nfrom itertools import cycle\n\n# from sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import label_binarize\n# from sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.metrics import roc_auc_score\n\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.utils.vis_utils import plot_model\nfrom keras.optimizers import SGD,Adam\nimport numpy as np\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout,concatenate\nfrom keras.layers import Conv2D, MaxPooling2D, Input, Flatten, BatchNormalization\nfrom keras.layers import Input\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard,CSVLogger\n# import tools\nimport gc\nfrom sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix\nfrom keras.models import Model\nimport keras\n# import channel_attention","d49a97e3":"folder = os.listdir(\"..\/input\/lung-colon-sobel\/trainable_sobel\")\nprint(folder)","2347f82e":"base_path = \"..\/input\/lung-colon-sobel\/trainable_sobel\"\ntotal_images = 0\nimage_class =[]\nfor n in range(len(folder)):\n  image_path = os.path.join(base_path, folder[n]) \n  print(image_path)\n  # class_path = patient_path + \"\/\" + str(c) + \"\/\"\n  subfiles = os.listdir(image_path)\n  print(len(subfiles))\n  image_class.append(len(subfiles))\n  total_images += len(subfiles)\nprint(\"The number of total images are:{}\".format(total_images))  \nprint(image_class)","906b7c78":"data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"path\", \"target\"])\n\nk = 0\nfor n in range(len(folder)):\n    class_id = folder[n]\n    final_path = os.path.join(base_path,class_id) \n    subfiles = os.listdir(final_path)\n    for m in range(len(subfiles)):\n      image_path = subfiles[m]\n      data.iloc[k][\"path\"] = os.path.join(final_path,image_path)\n      data.iloc[k][\"target\"] = class_id\n      k += 1  \n\ndata.head()","cd99b311":"data['target'].unique()","129977a9":"# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ndata['target_label'] = labelencoder.fit_transform(data['target'])\ndata = data.sample(frac=1).reset_index(drop=True)\ndata","1389b8f5":"#data.iloc[1000,:]","ffacdd17":"#data.groupby(\"target_label\").size()","c3c92dc8":"# cancer_perc = data.groupby(\"patient_id\").target.value_counts()\/ data.groupby(\"patient_id\").target.size()\n# cancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(data.groupby(\"target_label\").size(), ax=ax[0], color=\"Orange\", kde=False)\nax[0].set_xlabel(\"Number of images\")\nax[0].set_ylabel(\"Frequency\");\n\nsns.countplot(data.target, palette=\"Set2\", ax=ax[1]);\nax[1].set_xlabel(\"Names of Class\")\nax[1].set_title(\"Data Distribution\");","b9a822f5":"#data.info()","d9140462":"#data.describe()","0778ae39":"#data.target_label","4cf14a63":"X = data.path\ny = data.target_label\nX_train, X_test_sub ,y_train,y_test_sub= train_test_split(X,y, test_size=0.3, random_state=0,shuffle = True)\nprint(X_train.shape)\nprint(X_test_sub.shape)","89c0a316":"X_test,X_valid,y_test,y_valid = train_test_split(X_test_sub, y_test_sub, test_size=0.5, random_state=0 , shuffle =False)\nprint(X_test.shape)\nprint(X_valid.shape)","a505ca43":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(y_train, ax=ax[0], palette=\"Reds\")\nax[0].set_title(\"Train data\")\nsns.countplot(y_valid, ax=ax[1], palette=\"Blues\")\nax[1].set_title(\"Dev data\")\nsns.countplot(y_test, ax=ax[2], palette=\"Greens\");\nax[2].set_title(\"Test data\");","8202027c":"data.path.values","50cc28fb":"target_label_map = {k:v for k,v in zip(data.path.values,data.target_label.values)}","d853bccb":"def chunker(seq, size):\n    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\ndef get_seq():\n    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n    seq = iaa.Sequential(\n        [\n            # apply the following augmenters to most images\n            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n            iaa.Flipud(0.2), # vertically flip 20% of all images\n            sometimes(iaa.Affine(\n                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n                rotate=(-10, 10), # rotate by -45 to +45 degrees\n                shear=(-5, 5), # shear by -16 to +16 degrees\n                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n            )),\n            # execute 0 to 5 of the following (less important) augmenters per image\n            # don't execute all of them, as that would often be way too strong\n            iaa.SomeOf((0, 5),\n                [\n                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n                    iaa.OneOf([\n                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n                    ]),\n                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n                    # search either for all edges or for directed edges,\n                    # blend the result with the original image using a blobby mask\n                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n                    ])),\n                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n                    iaa.OneOf([\n                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n                    ]),\n                    iaa.Invert(0.01, per_channel=True), # invert color channels\n                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n                    # either change the brightness of the whole image (sometimes\n                    # per channel) or change the brightness of subareas\n                    iaa.OneOf([\n                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n                        iaa.FrequencyNoiseAlpha(\n                            exponent=(-1, 0),\n                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n                            second=iaa.ContrastNormalization((0.9, 1.1))\n                        )\n                    ]),\n                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n                ],\n                random_order=True\n            )\n        ],\n        random_order=True\n    )\n    return seq\n\ndef data_gen(list_files, target_label_map, batch_size, augment=False):\n    seq = get_seq()\n    while True:\n        # shuffle(list_files)\n        for batch in chunker(list_files, batch_size):\n            X = [cv2.resize(cv2.imread(x),(224,224),interpolation=cv2.INTER_CUBIC) for x in batch]\n            # for x in X:\n            #   X.append(cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC))\n            # X = [cv2.resize(x,(224,224,3)) for x in X]\n            Y = [target_label_map[x] for x in batch]\n            # print(Y)\n            Y = to_categorical(Y, num_classes = 5)\n            # print(Y)\n            if augment:\n                X = seq.augment_images(X)\n            X = [preprocess_input(x) for x in X]\n                \n            yield np.array(X), np.array(Y)\n    ","29123b11":"from keras.layers import Activation, Reshape, Lambda, dot, add\nfrom keras.layers import Conv1D, Conv2D, Conv3D\nfrom keras.layers import MaxPool1D,GlobalAveragePooling2D,Dense,multiply,Activation,concatenate\nfrom keras import backend as K\n\n\ndef squeeze_excitation_layer(x, out_dim, ratio = 4, concate = True):\n    '''\n    SE module performs inter-channel weighting.\n    '''\n    squeeze = GlobalAveragePooling2D()(x)\n\n    excitation = Dense(units=out_dim \/\/ratio)(squeeze)\n    excitation = Activation('relu')(excitation)\n    excitation = Dense(units=out_dim)(excitation)\n    excitation = Activation('sigmoid')(excitation)\n    print(excitation.shape)\n    excitation = Reshape((1, 1, out_dim))(excitation)\n\n    scale = multiply([x, excitation])\n\n    if concate:\n        scale = concatenate([scale, x],axis=3)\n    return scale","122aa398":"\n\nadam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0009)\nsgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n\ninput_tensor = Input(shape=(224,224, 3))\n#backbone\nbase_model = ResNet50(input_tensor= input_tensor, weights='imagenet', include_top=False)\nbase_output = base_model.output\nprint(base_output.shape)\n# channel-attention\nx = squeeze_excitation_layer(base_output, 2048, ratio=4, concate=False)\nx = BatchNormalization()(x)\n\n# #concat\nx = concatenate([base_output, x], axis=3)\n# spp\n\ngap = GlobalAveragePooling2D()(x)\nx = Flatten()(x)\nx = concatenate([gap,x])\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\npredict = Dense(5, activation='softmax')(x)\nmodel = Model(inputs=input_tensor, outputs=predict)\n\nfor layer in (base_model.layers):\n    layer.trainable = False\n\nmodel.compile(optimizer=adam,\n                      loss='categorical_crossentropy',\n                      metrics=[keras.metrics.categorical_accuracy])    \n\n# for l in model.layers:\n#   print(l.name)","55876af6":"\nmodel.summary()\n","e53d8332":"batch_size=32\nhistory = model.fit_generator(\n    data_gen(X_train, target_label_map, batch_size, augment=True),\n    validation_data=data_gen(X_valid, target_label_map, batch_size),\n    epochs=50, \n    verbose = 1,\n    #callbacks=callbacks,\n    steps_per_epoch=  int(len(X_train)\/\/batch_size),\n    validation_steps= int(len(X_valid)\/\/ batch_size)\n)","dff8b978":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, save_model, load_model\n\nfilepath = '.\/'","8522560d":"tf.keras.models.save_model(\n    model,\n    filepath,\n    overwrite=True,\n    include_optimizer=True,\n    save_format=None,\n    signatures=None,\n    options=None\n)","500fdcbe":"X_test_final,y_test_final = data_gen1(X_test,target_label_map,3750)\nprint(y_test_final.shape) \ny_pred = model.predict(X_test_final)\nprint(y_pred.shape)\nY_pred_classes = np.argmax(y_pred,axis=1) \nprint(Y_pred_classes.shape)\nY_true = np.argmax(y_test_final,axis=1)\nprint(Y_true.shape) ","a248ca53":"p1 ,p2 = data_gen1(X_valid,target_label_map,3750) \nscore = model.evaluate(p1,p2, verbose=0)\nprint('Model Accuracy:', score[1],'\\n')","d20bcf38":"y_test = to_categorical(Y_true, num_classes = 5)\ny_pred = to_categorical(Y_pred_classes ,num_classes =5)\n# print(y_test)\n# print(y_pred)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nnum_classes = 5\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_final[:, i],y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    # print(roc_auc[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\n\n\nn_classes =5\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\nlw = 2\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr \/= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize =(12,10))\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","9f7b70bf":"#print(X_test)\nprint(Y_pred_classes)\nprint(Y_true)","7e224a3c":"cm = confusion_matrix(Y_true, Y_pred_classes)\n\nprint(cm)\n\n\nclssrep = classification_report(Y_true, Y_pred_classes)\n    # CLssrep.append(clssrep)\nprint(clssrep)\n\n\ndf_cm = pd.DataFrame(cm, index = folder, columns= folder )\nfig = plt.figure(figsize = (10,7))\n\nheatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize= 14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize= 14)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nclassification_accuracy = accuracy(cm)\nprint(\"Classification Accuracy:{0:0.6f}\".format(classification_accuracy))\n\n[Precision,Sensitivity,F1_score,_] = precision_recall_fscore_support(Y_true, Y_pred_classes, average='weighted')\n[_, Specificity,_] = sensitivity_specificity_support(Y_true, Y_pred_classes, average='weighted')\n\n\n\n    \nprint('Precision : {0:0.6f}'.format(Precision))\nprint('Sensitivity : {0:0.6f}'.format(Sensitivity))\nprint('Specificity : {0:0.6f}'.format(Specificity))\nprint('F1_score : {0:0.6f}'.format(F1_score))","f8b721c3":"print(y_test_final[:,4])\nprint()","a85d765a":"def accuracy(confusion_matrix):\n    diagonal_sum = confusion_matrix.trace()\n    sum_of_all_elements = confusion_matrix.sum()\n    return diagonal_sum \/ sum_of_all_elements ","e006c4d9":"# def plot_learning_curve(history):\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nplt.plot(history.history['categorical_accuracy'])\nplt.plot(history.history['val_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\n    # plt.savefig('.\/accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\n# plt.savefig('.\/loss_curve.png')","e631ea59":"print(y_test_final)","17c628e5":"print(X_valid.shape)\nprint(y_valid)","5e9622c6":"print(X_valid[768])","f26c906d":"def data_gen1(list_files, target_label_map, batch_size, augment=False):\n    seq = get_seq()\n    while True:\n        # shuffle(list_files)\n        for batch in chunker(list_files, batch_size):\n          X = [cv2.resize(cv2.imread(x),(224,224),interpolation=cv2.INTER_CUBIC) for x in batch]\n            # for x in X:\n            #   X.append(cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC))\n            # X = [cv2.resize(x,(224,224,3)) for x in X]\n          Y = [target_label_map[x] for x in batch]\n            # print(Y)\n          Y = to_categorical(Y, num_classes = 5)\n            # print(Y)\n          if augment:\n            X = seq.augment_images(X)\n          X = [preprocess_input(x) for x in X]\n                \n          return np.array(X), np.array(Y)","c3070564":"print(y_pred)"}}