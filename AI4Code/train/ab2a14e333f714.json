{"cell_type":{"26c2390a":"code","e0f72205":"code","256b3c50":"code","44d8af09":"code","bcd94f82":"code","e91ed9a2":"code","773ba69c":"code","45aed47a":"code","36186634":"code","e00985b8":"code","211c5767":"code","4f497588":"code","84b21db1":"code","bed00c42":"code","9077d748":"code","c48a5993":"code","3bc333ee":"code","80b004fd":"code","fd8f6d29":"code","2422cf2e":"code","96a5c477":"code","30f67112":"code","92efe101":"code","d02dcef4":"code","f9705f8f":"code","6d00f814":"code","04cffd84":"code","2fc98b8e":"code","d4a66901":"code","13f488f6":"code","057b511c":"code","eac0de8c":"code","d99e02ae":"markdown","b281bb54":"markdown","9fe9cc22":"markdown","31b6fbe0":"markdown","5e7a3fb5":"markdown","0168f2d4":"markdown","f453452a":"markdown","d3b5360d":"markdown","5e36b360":"markdown","4276a2a0":"markdown","fc2afdcd":"markdown","fb2213ad":"markdown","97224255":"markdown","cb49f58c":"markdown","bf41ecd5":"markdown","4666604d":"markdown","8e3fb5db":"markdown","0750e414":"markdown","91b1ba0b":"markdown"},"source":{"26c2390a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0f72205":"df = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')\ndf","256b3c50":"df.info()","44d8af09":"categorical_dict = {\n    'Sex': df.Sex.unique(),\n    'ChestPainType': df.ChestPainType.unique(),\n    'RestingECG': df.RestingECG.unique(),\n    'ExerciseAngina': df.ExerciseAngina.unique(),\n    'ST_Slope': df.ST_Slope.unique()\n}\ncategorical_dict","bcd94f82":"import plotly \nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","e91ed9a2":"px.histogram(df, x=\"Sex\", color=\"HeartDisease\", width=500, height=350)","773ba69c":"px.histogram(df, x=\"ExerciseAngina\", color=\"HeartDisease\", width=500, height=350)","45aed47a":"px.histogram(df, x=\"ChestPainType\", color=\"HeartDisease\", width=500, height=350)","36186634":"px.histogram(df, x=\"ST_Slope\", color=\"HeartDisease\", width=500, height=350)","e00985b8":"px.histogram(df, x=\"RestingECG\", color=\"HeartDisease\", width=500, height=350)","211c5767":"plt.figure(figsize=(10,5))\nsns.stripplot(x=\"ST_Slope\", y=\"ExerciseAngina\", hue=\"HeartDisease\", data=df)","4f497588":"plt.figure(figsize=(10,5))\nsns.stripplot(x=\"ST_Slope\", y=\"ChestPainType\", hue=\"HeartDisease\", data=df)","84b21db1":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ExerciseAngina\", y=\"MaxHR\", hue=\"HeartDisease\", data=df)","bed00c42":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ExerciseAngina\", y=\"RestingBP\", hue=\"HeartDisease\", data=df)","9077d748":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ExerciseAngina\", y=\"Cholesterol\", hue=\"HeartDisease\", data=df)","c48a5993":"df.loc[df.Cholesterol == 0]","3bc333ee":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ExerciseAngina\", y=\"Oldpeak\", hue=\"HeartDisease\", data=df)","80b004fd":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ST_Slope\", y=\"MaxHR\", hue=\"HeartDisease\", data=df)","fd8f6d29":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ST_Slope\", y=\"RestingBP\", hue=\"HeartDisease\", data=df)","2422cf2e":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ST_Slope\", y=\"Cholesterol\", hue=\"HeartDisease\", data=df)","96a5c477":"plt.figure(figsize=(10,5))\nsns.boxplot(x=\"ST_Slope\", y=\"Oldpeak\", hue=\"HeartDisease\", data=df)","30f67112":"df = df.drop(df.loc[df.RestingBP == 0].index)\ndf = pd.get_dummies(df, drop_first=True)\ndf","92efe101":"from mlxtend.preprocessing import minmax_scaling\n\ndf = minmax_scaling(df, columns = df.columns)\ndf","d02dcef4":"from sklearn.model_selection import train_test_split\n\nX = df.drop([\"HeartDisease\"], axis=1)\ny = df['HeartDisease']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","f9705f8f":"#step 1\nfrom sklearn.cluster import KMeans\n\nk_means = KMeans(n_clusters=20, random_state=42).fit(X_train)","6d00f814":"#step 2\nk_means.cluster_centers_","04cffd84":"#step 3\nradiuses = []\nfor j in range(len(np.unique(k_means.labels_))):\n    lbl = []\n    lbl = np.array(np.where(k_means.labels_ == j))  \n    radiuses.append(max([np.linalg.norm(k_means.cluster_centers_[j] - X_train[lbl[0,i]]) for i in range(lbl.shape[1])]))\nradiuses","2fc98b8e":"#step 4\ndef h0(x):\n    c = k_means.cluster_centers_[0]\n    r = radiuses[0]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h1(x):\n    c = k_means.cluster_centers_[1]\n    r = radiuses[1]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h2(x):\n    c = k_means.cluster_centers_[2]\n    r = radiuses[2]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h3(x):\n    c = k_means.cluster_centers_[3]\n    r = radiuses[3]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h4(x):\n    c = k_means.cluster_centers_[4]\n    r = radiuses[4]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h5(x):\n    c = k_means.cluster_centers_[5]\n    r = radiuses[5]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h6(x):\n    c = k_means.cluster_centers_[6]\n    r = radiuses[6]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h7(x):\n    c = k_means.cluster_centers_[7]\n    r = radiuses[7]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h8(x):\n    c = k_means.cluster_centers_[8]\n    r = radiuses[8]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h9(x):\n    c = k_means.cluster_centers_[9]\n    r = radiuses[9]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h10(x):\n    c = k_means.cluster_centers_[10]\n    r = radiuses[10]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h11(x):\n    c = k_means.cluster_centers_[11]\n    r = radiuses[11]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h12(x):\n    c = k_means.cluster_centers_[12]\n    r = radiuses[12]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h13(x):\n    c = k_means.cluster_centers_[13]\n    r = radiuses[13]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h14(x):\n    c = k_means.cluster_centers_[14]\n    r = radiuses[14]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h15(x):\n    c = k_means.cluster_centers_[15]\n    r = radiuses[15]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h16(x):\n    c = k_means.cluster_centers_[16]\n    r = radiuses[16]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h17(x):\n    c = k_means.cluster_centers_[17]\n    r = radiuses[17]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h18(x):\n    c = k_means.cluster_centers_[18]\n    r = radiuses[18]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))\n\ndef h19(x):\n    c = k_means.cluster_centers_[19]\n    r = radiuses[19]\n    return np.exp(-1 * np.sqrt(np.sum(np.square((x - c)\/r))))","d4a66901":"#step 5\ntmp = []\nnew_X_train = []\n\nfor i in range(len(X_train)):\n    h0_out = h0(X_train[i])\n    h1_out = h1(X_train[i])\n    h2_out = h2(X_train[i])\n    h3_out = h3(X_train[i])\n    h4_out = h4(X_train[i])\n    h5_out = h5(X_train[i])\n    h6_out = h6(X_train[i])\n    h7_out = h7(X_train[i])\n    h8_out = h8(X_train[i])\n    h9_out = h9(X_train[i])\n    h10_out = h10(X_train[i])\n    h11_out = h11(X_train[i])\n    h12_out = h12(X_train[i])\n    h13_out = h13(X_train[i])\n    h14_out = h14(X_train[i])\n    h15_out = h15(X_train[i])\n    h16_out = h16(X_train[i])\n    h17_out = h17(X_train[i])\n    h18_out = h18(X_train[i])\n    h19_out = h19(X_train[i])\n    tmp = [h0_out, h1_out, h2_out, h3_out, h4_out, h5_out, h6_out, h7_out, h8_out, h9_out, h10_out, h11_out, h12_out, h13_out, h14_out, h15_out, h16_out, h17_out, h18_out, h19_out]\n    new_X_train.append(tmp)\n    \nnew_X_train = np.array(new_X_train)","13f488f6":"#step 5\ntmp = []\nnew_X_test = []\n\nfor i in range(len(X_test)):\n    h0_out = h0(X_test[i])\n    h1_out = h1(X_test[i])\n    h2_out = h2(X_test[i])\n    h3_out = h3(X_test[i])\n    h4_out = h4(X_test[i])\n    h5_out = h5(X_test[i])\n    h6_out = h6(X_test[i])\n    h7_out = h7(X_test[i])\n    h8_out = h8(X_test[i])\n    h9_out = h9(X_test[i])\n    h10_out = h10(X_test[i])\n    h11_out = h11(X_test[i])\n    h12_out = h12(X_test[i])\n    h13_out = h13(X_test[i])\n    h14_out = h14(X_test[i])\n    h15_out = h15(X_test[i])\n    h16_out = h16(X_test[i])\n    h17_out = h17(X_test[i])\n    h18_out = h18(X_test[i])\n    h19_out = h19(X_test[i])\n    tmp = [h0_out, h1_out, h2_out, h3_out, h4_out, h5_out, h6_out, h7_out, h8_out, h9_out, h10_out, h11_out, h12_out, h13_out, h14_out, h15_out, h16_out, h17_out, h18_out, h19_out]\n    new_X_test.append(tmp)\n\nnew_X_test = np.array(new_X_test)","057b511c":"#step 6\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import BinaryAccuracy\n\nmodel = Sequential()\nmodel.add(Input(shape=(20,)))\nmodel.add(Dense(units=1, \n                kernel_initializer='glorot_uniform',\n                activation='sigmoid'))\n\nmodel.compile(optimizer = 'Adam',\n              loss = 'BinaryCrossentropy',\n              metrics = [BinaryAccuracy()])\n          \nmodel.fit(new_X_train, y_train, epochs=20, validation_data = (new_X_test, y_test))","eac0de8c":"model.evaluate(x= new_X_test, y= y_test)","d99e02ae":"According to the plot, the result of cases sex:\n* **Male:** 725 cases(~ 79%), 458 of them have heart disease(63%)\n* **Female:** 193 cases(~ 21%), 50 of them have heart disease(26%) \n\nHowever, the size of data is not big enough, but we can guess men are suffering heart disease more.","b281bb54":"We know pain is the effect side of disease but we can discuss about it;\n* **ATA**: 173 cases (~ 20%), 24 of them have heart disease (~ 14%)\n* **NAP**: 203 cases (~ 22%), 72 of them have heart disease (35%)\n* **TA** : 46  cases (~ 5%), 20 of them have heart disease (43%)\n* **ASY**: 496 cases (~ 53%), 392 of them have heart disease (~ 80%)\n\nThat's a strange result! about 80% of heart disease cases have asymptomatic pain type(ASY) and that means most of them are healthy apparently!","9fe9cc22":"# **Data training**","31b6fbe0":"**2. strip plots**\n\nNow we use strip plot to find relationship between some of categorical variables.","5e7a3fb5":"According to the plot, the result of exercise angina:\n* **No:** 547 cases(~ 60%), 192 of them have heart disease(35%)\n* **Yes:** 371 cases(~ 40%), 316 of them have heart disease(85%) \n\nWe can understand exercise angina is one of important feature for diagnosis heart disease.","0168f2d4":"This is a strange result; because in the reality no one has zero cholesterol but 172 of cases have zero cholesterol. It's true for zero resting blood pressure(restingBP) too. Normally, we should drop these samples from data but in this case we should drop about 19% of datapoints so we dont want do that!\n\nBesides this, all we know is that high cholesterol is not good for heart!","f453452a":"According to the plot we can understand:\n* Cases who their exercise angina test are 'Yes', have lower heart rate\n* Heart patient have lower heart rate compare to healthy persons","d3b5360d":"Let's gather the categorical variables in a dictionary","5e36b360":"**Preprocessing**\n\n* as mention before, zero blood pressure is valueless data so we drop it\n* using get_dummies function for converting categorical data into dummy or indicator variables\n* scaling data using minmax_scaling function\n* split data to train and test sets","4276a2a0":"# Data exploration","fc2afdcd":"As mention before, 80% heart patients have no pain(asymptomatic pain type). We can see this in the plot above too; especially many of patients with ST_slope = 'down' have ASY chest paint.","fb2213ad":"**1. histogram plots**\n\nWe know we have 918 data points and now we want to use histogram plot for some of columns in the data","97224255":"**Training**\n\nA radial basis function(RBF) network is an artificial neural network that uses radial basis functions as transfer functions. The output of the network is a linear combination of radial basis functions of the inputs and neuron parameters. Radial basis function networks have many uses, including function approximation, time series prediction, classification, and system control.\n\nArchitecture of a radial basis function network:\n\n![](http:\/\/miro.medium.com\/max\/639\/1*c6KMMqfhmXdJda9LBGmhJw.png)\n\n\nAlgorithm implementation steps:\n1. Split data between some clusters. Actually, the number of clusters is the number of neurons in the hidden layer; here, we use KMeans clustering algorithm where k=20 clusters (neurons).\n2. Find the center of each cluster (c variable in h(x) formula)\n3. Calculate maximum radius of each cluster (r variable in h(x) formula)\n4. Define transfer functions (here, Gaussian radial function) for each neuron\n5. Pass inputs to the transfer functions (hidden layer)\n6. Training data with sequential model as binary classification","cb49f58c":"According to the result, the data has no any missing values! Is that good news?! We should wait for it :)","bf41ecd5":"According to the plot, the result of resting ECG:\n* **normal**: 552 cases(60%), 285 of them have heart disease(~52%)\n* **ST**: 178 cases(20%), 117 of them have heart disease(~66%)\n* **LVH**: 188 cases(20%), 106 of them have heart disease(~56%)\n\nWe can see about half of each type have heart disease","4666604d":"**3. box plots**\n\nIn the last section of data visualization, we use boxplot for understanding the relationship between some categorical and continuous variables. According to the plots we've seen, we can say 'ExerciseAngina' and 'ST_Slope' are two important features; so we use these columns as one of the axises in the boxplots.","8e3fb5db":"According to the plot, we can understand if the result of exercise angine for somebody is 'yes' and her\/his ST slope is 'flat', she\/he is more in danger of heart disease. It's true for ST slope = 'down' too","0750e414":"According to the plot,the result of ST slope:\n* **up**: 395 cases (43%), 78 of them have heart disease(~20%)\n* **flat**: 460 cases (50%), 381 of them have heart disease(~82%)\n* **Up**: 63 cases (7%), 49 of them have heart disease(~77%)\n\nWe can get cases with 'Flat' and 'Down' ST slop are in high risk of heart disease","91b1ba0b":"# Data visualization"}}