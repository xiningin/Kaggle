{"cell_type":{"a9dc604a":"code","c10c1d2f":"code","443a3806":"code","29cb86ba":"code","a812cf9f":"code","0bc3ac52":"code","4f098472":"code","44e9ce7f":"code","00463c8f":"code","a9864d9d":"code","15ac8319":"code","9fc23234":"code","b8d15026":"code","79e770d6":"code","ac680843":"code","aa9ea947":"code","27c67829":"code","fa8b7710":"code","a17d61b6":"code","3f0230f2":"code","ea3ed656":"code","0d178ad6":"markdown","72cd4f6b":"markdown","0bda5c0a":"markdown","5a70c0e6":"markdown","340a4368":"markdown","00aa8bbd":"markdown","be49e425":"markdown","1b820e60":"markdown"},"source":{"a9dc604a":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nimport lime\nfrom lime import lime_tabular\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler","c10c1d2f":"# Importing the sequences that ends in a ventricular arrhythmia\nabnorm_directory = \"..\/input\/rrintervall\/ventTach\/RRdata1\/\"\nabnorm = []\nabnorm_name = []\nfor i in sorted(os.listdir(abnorm_directory)):\n    try:\n        arr = np.loadtxt(abnorm_directory + i)\n        abnorm.append(arr)\n        abnorm_name.append(abnorm_directory + i)\n    except:\n        print(i)","443a3806":"# Only sing the last 300 beats of the sequence\nsick = np.zeros((len(abnorm),300))\nfor i,j in enumerate(abnorm):\n    sick[i] = j[-300:]\n    ","29cb86ba":"# Importing the baseline sequences \nnorm_directory = \"..\/input\/rrintervall\/mr\/mr\/\"\nnorm = []\nnorm_name = []\nfor i in sorted(os.listdir(norm_directory)):\n    try:\n        arr = np.loadtxt(norm_directory + i)\n        norm.append(arr)\n        norm_name.append(norm_directory + i)\n    except:\n        print(i)","a812cf9f":"# Only sing the last 300 beats of the sequence\nhealthy = np.zeros((len(norm),300))\nfor i,j in enumerate(norm):\n    healthy[i] = j[-300:]","0bc3ac52":"print(f\"Baseline sequnces = {healthy.shape}\")","4f098472":"print(f\"Abnormal sequences = {sick.shape}\")","44e9ce7f":"t = np.arange(0,300)\nfig, ax = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\nfig.suptitle(\"Raw data\")\nfor Vp, Cap in zip(sick, healthy):\n    ax[0].set_title('Tachyarrhythmia')\n    ax[1].set_title('Normal')\n    ax[0].plot(t, Vp, c='darkred', lw=0.4, alpha=0.1)\n    ax[1].plot(t, Cap, c='darkgreen', lw=0.4, alpha=0.1)\n    ax[0].set_xlabel(\"Beats\")\n    ax[1].set_xlabel(\"Beats\")\n    ax[0].set_ylabel(\"Interbeat interval\")\n    ax[1].set_ylabel(\"Interbeat interval\")\n    ax[1].set_xlabel(\"Beats\")\n\nplt.savefig(\"data.png\", bbox_inches='tight')","00463c8f":"# Concatenate data - basline sequence = 0 , abnormal = 1\ny = np.concatenate([np.ones(len(sick)),np.zeros(len(healthy))])\nX = np.concatenate([sick,healthy])\n\nX = np.expand_dims(X,2)","a9864d9d":"# defining a model\ndef FCN():\n    inputlayer = tf.keras.layers.Input(shape=(300,1)) \n\n    conv1 = tf.keras.layers.Conv1D(filters=128, kernel_size=8,input_shape=(300,1), padding='same')(inputlayer)\n    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n    conv1 = tf.keras.layers.Activation(activation='relu')(conv1)\n\n    conv2 = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='same')(conv1)\n    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n    conv2 = tf.keras.layers.Activation('relu')(conv2)\n\n    conv3 = tf.keras.layers.Conv1D(128, kernel_size=3,padding='same', name = \"last_conv\")(conv2)\n    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n    conv3 = tf.keras.layers.Activation('relu')(conv3)\n\n    gap_layer = tf.keras.layers.GlobalAveragePooling1D()(conv3)\n\n\n    outputlayer = tf.keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n\n    model = tf.keras.Model(inputs=inputlayer, outputs=outputlayer)\n\n    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[tf.keras.metrics.BinaryAccuracy()])\n\n    return model","15ac8319":"# Split into development set and test set\nX_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","9fc23234":"# define a learning rate scheduler - decrease lr by a factor of 10 after after each 10th epoch\ndef lr_time_based_decay(epoch, lr):\n    if epoch % 10 == 0:\n        return lr * 0.1\n    else:\n        return lr","b8d15026":"# 5-fold CV on the development set\nkf = KFold(n_splits=5)\nrocscore = []\naccuracy = []\nfor train_index, val_index in kf.split(X_dev):\n    X_train, X_val= X_dev[train_index], X_dev[val_index]\n    y_train, y_val = y_dev[train_index], y_dev[val_index]\n    model = FCN()\n    model.fit(x = X_train, y=y_train,batch_size=20,epochs=40,shuffle=True,validation_data = (X_val,y_val), verbose=0,\n              callbacks = [tf.keras.callbacks.LearningRateScheduler(lr_time_based_decay,verbose=0)])\n    pred = model.predict(X_val)\n    print(classification_report(y_val, pred.round()))\n    print(f\"ROC Score = {roc_auc_score(y_val,pred)}\")\n    rocscore.append(roc_auc_score(y_val,pred))\n    accuracy.append(accuracy_score(y_val, pred.round()))\naccuracy = np.asarray(accuracy)\nrocscore = np.asarray(rocscore)\nprint(f\"Mean acc = {accuracy.mean()}, std = {accuracy.std()}\")\nprint(f\"Mean ROC = {rocscore.mean()}, std = {rocscore.std()}\")","79e770d6":"# Fitting the final model on the whole development set using the same training procedure as in the 5-fold CV\nmodel = FCN()\nmodel.fit(x = X_dev, y=y_dev,batch_size=20,epochs=40,shuffle=True, verbose = 0, callbacks = [tf.keras.callbacks.LearningRateScheduler(lr_time_based_decay,verbose=0)])\npred = model.predict(X_test)","ac680843":"print(classification_report(y_test, pred.round()))\nprint(f\"ROC score = {roc_auc_score(y_test, pred)}\")","aa9ea947":"# A model wrapper - this is necessary to be able to use LIME to explain the predictions \nclass model_wrapper:\n    def __init__(self,model):\n            \n            self.model = model\n \n    def predict(self,input_data):        \n        self.pred = self.model.predict(input_data).ravel()\n        return np.array([[1-self.pred,self.pred]]).T[:,:,0]","27c67829":"# Wrap model\nwrapped_mod = model_wrapper(model)","fa8b7710":"#Initiate lime reccurent explainer (this can be used for 1D CNN also). The surrogate model will be trained on the development set\nexplainer = lime_tabular.RecurrentTabularExplainer(X_dev,training_labels=tf.keras.utils.to_categorical(y_dev), feature_names=[\"Inter beat int\"],\n                                                   discretize_continuous=False, feature_selection='auto', class_names=['Healthy','Sick'])","a17d61b6":"# Explaining the predictions don on the test set. Here we only look at sequences that are classified as abnormal\/sick\nlabel = [\"healthy\", \"sick\"]\ncnt = 0\nfor j in X_test:\n    pred = model.predict(np.expand_dims(j,axis=0))[0][0]\n    if  pred > 0.5: \n        exp = explainer.explain_instance(np.expand_dims(j,axis=0), wrapped_mod.predict, num_features=300)\n        explanations = exp.as_list()\n        heatmap = np.zeros([1,300])\n        for k in explanations:\n            if k[1] > 0:\n                heatmap[0,int(k[0].split(\"-\")[-1])] = k[1]\n        print(f\"Model prediction = sick ({pred}), True label = {label[int(y_test[cnt])]}\")\n        plt.figure(figsize=(30,4))\n        plt.imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,300,j.min(),j.max()], alpha=0.5)\n        plt.plot(j,'k', label=\"V_d\")\n        plt.colorbar()\n        plt.show()\n    cnt +=1","3f0230f2":"# Defining the Grad-CAM algorithm\ndef grad_cam(layer_name, data):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(layer_name).output, model.output]\n    )\n    last_conv_layer_output, preds = grad_model(data)\n    \n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(data)\n        pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n        \n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    \n    pooled_grads = tf.reduce_mean(grads, axis=(0))\n    \n    last_conv_layer_output = last_conv_layer_output[0]\n    \n    heatmap = last_conv_layer_output * pooled_grads\n    heatmap = tf.reduce_mean(heatmap, axis=(1))\n    heatmap = np.expand_dims(heatmap,0)\n    return heatmap","ea3ed656":"# Class activation map from the input layer to the last Conv. layer\nlayer_name = \"last_conv\"\nlabel = [\"healthy\", \"sick\"]\ncnt = 0\nfor i in X_test:\n    data = np.expand_dims(i,0)\n    pred = model.predict(data)[0][0]\n    if  pred > 0.5:\n        heatmap = grad_cam(layer_name,data)\n        print(f\"Model prediction = sick ({pred}), True label = {label[int(y_test[cnt])]}\")\n        plt.figure(figsize=(30,4))\n        plt.imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,300,i.min(),i.max()], alpha=0.5)\n        plt.plot(i,'k')\n        plt.colorbar()\n        plt.show()\n    cnt +=1","0d178ad6":"## <center> LIME <\/center>","72cd4f6b":"### In this Kaggle Notebook I use the [Spontaneous Ventricular Tachyarrhythmia Database](https:\/\/physionet.org\/content\/mvtdb\/1.0\/), which contains interbeat sequences recorded from ICDs. The database contains 270 RR interval time series. 135 of the recordings are baseline recordings without any serious events, while the other 135 recordings ended in severe events such as ventricular fibrillation or ventricular tachycardia. Here I train a classifier to predict whether a sequence of 300 beats are related to a ventricular arrhythmia or not.","0bda5c0a":"## <center> 5-fold cross-validation on development data<\/center>","5a70c0e6":"## <center> Prediction on testdata<\/center>","340a4368":"## <center> Grad-CAM<\/center>","00aa8bbd":"# <center>Classifying ventricular arrhythmia from RR-interval using a Convolutional Neural Network <\/center>\n## <center>And explaining the classification using LIME and Grad-CAM<\/center>","be49e425":"<center><img width=\"500\" height=\"500\" src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/d\/d1\/Blausen_0543_ImplantableCardioverterDefibrillator_InsideLeads.png\/220px-Blausen_0543_ImplantableCardioverterDefibrillator_InsideLeads.png\"\/><\/center>\n\nFigure: Implantable Cardioverter Defibrillator (ICD). Created by: [Blausen.com staff (2014). \"Medical gallery of Blausen Medical 2014\". WikiJournal of Medicine 1 (2)](https:\/\/en.wikipedia.org\/wiki\/Implantable_cardioverter-defibrillator#\/media\/File:Blausen_0543_ImplantableCardioverterDefibrillator_InsideLeads.png). Licensed under [ CC BY 3.0 ](http:\/\/creativecommons.org\/licenses\/by\/3.0\/)\n\n\n","1b820e60":"# <center> Explaining model prediction using LIME and Grad-CAM<\/center>"}}