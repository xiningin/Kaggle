{"cell_type":{"7ec3f91a":"code","642cf7bf":"code","3325d317":"code","5ba1bf52":"code","9cdbdc40":"code","466688f3":"code","d901814f":"code","bb755436":"code","f798fbb2":"code","7d7fe1dd":"code","4b354540":"code","2f7d7695":"code","f78f8a1d":"markdown","341ff2b0":"markdown","fa4a6bfa":"markdown","f8d7a11e":"markdown","99209207":"markdown","1e1236cd":"markdown","633c92a8":"markdown","d38f81e2":"markdown"},"source":{"7ec3f91a":"import torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)\n","642cf7bf":"import pandas as pd\ntrain = pd.read_csv(\"..\/input\/image-depth-estimation\/data\/nyu2_test.csv\", names = ['image', 'label'])\ntest = pd.read_csv(\"..\/input\/image-depth-estimation\/data\/nyu2_test.csv\", names = ['image', 'label'])\n\n\ntrain.label = train.label.map(lambda x: f\"..\/input\/image-depth-estimation\/{x}\")\ntrain.image = train.image.map(lambda x: f\"..\/input\/image-depth-estimation\/{x}\")\nprint(len(train))\ntrain.head()\n\n\n","3325d317":"import torch\nimport os\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\n\n\nclass DepthDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n\n        self.images = list(df['image'].values)\n        self.labels = list(df['label'].values)\n        \n        # load image\n        random_sample_image = random.choice([i for i in range(len(self.images) - 1)])\n        image = Image.open(self.images[random_sample_image])\n        depth = Image.open(self.labels[random_sample_image])\n        \n        plt.imshow(image)\n        plt.title(\"Image\")\n        plt.show()\n        \n        # Denormaling Image\n        plt.imshow(np.asarray(depth) * 256)\n        plt.title(\"Depth\")\n        plt.show()\n\n    def __getitem__(self, index):\n        # load image\n        image = Image.open(self.images[index])\n        depth = Image.open(self.labels[index])\n        \n       \n        # transformation\n        comm_trans = transforms.Compose([\n            transforms.Resize((240, 320)),\n            transforms.CenterCrop((228, 304)),\n            transforms.RandomHorizontalFlip()\n        ])\n        image_trans = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n        depth_trans = transforms.Compose([\n            transforms.Resize((64, 80)),\n            transforms.ToTensor(),\n            transforms.Lambda(lambda x: x.float()),\n            transforms.Lambda(lambda x: torch.div(x, 65535.0)),\n            #transforms.Normalize((0.5, ), (0.5, ))\n        ])\n        image = image_trans(comm_trans(image))\n        depth = depth_trans(comm_trans(depth))\n        return image, depth\n\n    def __len__(self):\n        return len(self.images)\n\n\n\n","5ba1bf52":"\nbatch_size = 32\nlearning_rate = 0.001\ntotal_epoch = 50\nreport_rate = 20","9cdbdc40":"import random\ndataset_train = DepthDataset(train)\n\n\nlengths = [int(math.floor(len(train) * 0.8)), int(math.ceil(len(train) * 0.2))]\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset_train, lengths)","466688f3":"\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                     batch_size=batch_size,\n                                     shuffle=False)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                     batch_size=batch_size,\n                                     shuffle=True)\n","d901814f":"#Cite from: https:\/\/github.com\/simonmeister\/pytorch-mono-depth\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom math import log\n\n\ndef _mask_input(input, mask=None):\n    if mask is not None:\n        input = input * mask\n        count = torch.sum(mask).data[0]\n    else:\n        count = np.prod(input.size(), dtype=np.float32).item()\n    return input, count\n\n\nclass BerHuLoss(nn.Module):\n    def forward(self, input, target, mask=None):\n        x = input - target\n        abs_x = torch.abs(x)\n        c = torch.max(abs_x).item() \/ 5\n        leq = (abs_x <= c).float()\n        l2_losses = (x ** 2 + c ** 2) \/ (2 * c)\n        losses = leq * abs_x + (1 - leq) * l2_losses\n        losses, count = _mask_input(losses, mask)\n        return torch.sum(losses) \/ count\n\n\nclass HuberLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.loss = nn.SmoothL1Loss(size_average=False)\n\n    def forward(self, input, target, mask=None):\n        if mask is not None:\n            loss = self.loss(input * mask, target * mask)\n            count = torch.sum(mask).data[0]\n            return loss \/ count\n\n        count = np.prod(input.size(), dtype=np.float32).item()\n        return self.loss(input, target) \/ count\n\n\nclass DistributionLogLoss(nn.Module):\n    def __init__(self, distribution):\n        super().__init__()\n        self.distribution = distribution\n\n    def forward(self, input, target, mask=None):\n        d = self.distribution(*input)\n        loss = d.log_loss(target)\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) \/ count\n\n\nclass RMSLoss(nn.Module):\n    def forward(self, input, target, mask=None):\n        loss = torch.pow(input - target, 2)\n        loss, count = _mask_input(loss, mask)\n        return torch.sqrt(torch.sum(loss) \/ count)\n\n\nclass RelLoss(nn.Module):\n    def forward(self, input, target, mask=None):\n        loss = torch.abs(input - target) \/ target\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) \/ count\n\nclass MseLoss(nn.Module):  \n    def forward(self, input, target, mask=None):\n        loss = torch.sum((input - target) ** 2)\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) \/ count\n\nclass Log10Loss(nn.Module):\n    def forward(self, input, target, mask=None):\n        loss = torch.abs((torch.log(target) - torch.log(input)) \/ log(10))\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) \/ count\n\n\nclass TestingLosses(nn.Module):\n    def __init__(self, scalar_losses):\n        super().__init__()\n        self.scalar_losses = nn.ModuleList(scalar_losses)\n\n    def forward(self, input, target):\n        scalars = [m(input, target) for m in self.scalar_losses]\n        return torch.cat(scalars)","bb755436":"import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152']\n\n\nmodel_urls = {\n    'resnet18': 'https:\/\/download.pytorch.org\/models\/resnet18-5c106cde.pth',\n    'resnet34': 'https:\/\/download.pytorch.org\/models\/resnet34-333f7ec4.pth',\n    'resnet50': 'https:\/\/download.pytorch.org\/models\/resnet50-19c8e357.pth',\n    'resnet101': 'https:\/\/download.pytorch.org\/models\/resnet101-5d3b4d8f.pth',\n    'resnet152': 'https:\/\/download.pytorch.org\/models\/resnet152-b121ed2d.pth',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model\n\n\n\ndef resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n    return model\n\n\n\ndef resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n    return model\n\n\n\ndef resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n    return model\n\n\n\ndef resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n    return model","f798fbb2":"import torch\nimport torch.nn as nn\nimport torchvision\n\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# 3x3 convolution\ndef conv3x3(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n                     stride=stride, padding=1, bias=False)\n# 5x5 convolution\ndef conv5x5(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=5,\n                     stride=stride, padding=2, bias=False)\n\n# UpSampling Block\nclass UpSamplingBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(UpSamplingBlock, self).__init__()\n        self.unpool = nn.MaxUnpool2d(2, stride=2)\n        self.pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n        self.conv1 = conv5x5(in_channels, out_channels)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(out_channels, out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        # create indices for unpool\n        size = x.size()\n        _, indices = self.pool(torch.empty(size[0], size[1], size[2]*2, size[3]*2))\n        # unpool and assign residual\n        out = self.unpool(x, indices.to(device))\n        residual = self.conv1(out)\n        residual = self.bn1(residual)\n        # forward and projection\n        out = self.conv1(out)\n        out = self.bn1(residual)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(residual)\n        out += residual\n        return out\n\n\n# DepthNet\nclass DepthNet(nn.Module):\n    def __init__(self):\n        super(DepthNet, self).__init__()\n        # Remove FC and AvgPool layer from Resnet50\n        resnet = resnet50(pretrained=True)\n        modules = list(resnet.children())[:-2]\n        self.resnet = nn.Sequential(*modules)\n        self.conv1 = nn.Conv2d(2048, 1024, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(1024)\n        # Add new upsampling layer\n        self.up1 = nn.Sequential(UpSamplingBlock(1024, 512),\n                                 nn.ReLU(),\n                                 UpSamplingBlock(512, 256),\n                                 nn.ReLU(),\n                                 UpSamplingBlock(256, 128),\n                                 nn.ReLU())\n        self.conv2 = conv3x3(128, 1)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, inputs):\n        out = self.resnet(inputs)\n        out = self.conv1(out)\n        out = self.bn(out)\n        out = self.up1(out)\n        out = self.conv2(out)\n        out = self.relu(out)\n        return out\n","7d7fe1dd":"# load model\nmodel = DepthNet().to(device)\n\n# Loss and optimizer\ncriterion  = BerHuLoss()\ncriterion2 = MseLoss()\noptimizer  = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# learning rate decay\ndef update_lr(opt, lr):\n    for param_group in opt.param_groups:\n        param_group['lr'] = lr\n\n# validation\ndef validate(model, test_loader):\n    model.eval()\n    with torch.no_grad():\n        loss2, loss = 0.0, 0.0\n        for t_image, t_depth in test_loader:\n            t_image = t_image.to(device)\n            t_depth = t_depth.to(device)\n            t_outputs = model(t_image)\n            \n            curr_loss = criterion(t_depth, t_outputs)\n            curr_loss2 = criterion2(t_depth, t_outputs)\n            loss += curr_loss.item()\n            loss2 += curr_loss2.item()\n        print(\"Validation BerHuLoss: {:.4f}\"\n              .format(loss\/(len(test_loader) * batch_size)))\n        print(\"Validation MSE LOSS: {:.4f}\"\n              .format(loss2\/(len(test_loader) * batch_size)))\n        \n        \n    model.train()\n\n\n\n","4b354540":"# train\ntotal_step = len(train_dataset)\ncurr_lr = learning_rate\nfor epoch in range(total_epoch):\n    running_loss, running_loss2 = 0.0, 0.0\n    epoch_loss = 0.0\n    for i, (image, depth) in enumerate(train_loader):\n        \n        image = image.to(device)\n        depth = depth.to(device)\n\n        # forward pass\n        outputs = model(image)\n        loss = criterion(outputs, depth)\n        loss2 = criterion2(depth, outputs)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Calculate loss\n        running_loss += loss.item()\n        running_loss2 += loss2.item()\n        \n        epoch_loss += running_loss2\n\n        if (i + 1) % report_rate == 0:\n            print(\"Epoch: [{}\/{}] Step [{}\/{}] Loss: {:.4f} MSE LOSS {:.4f}\"\n                  .format((epoch+1), total_epoch, (i+1), total_step, (running_loss\/batch_size), (running_loss2\/batch_size)))\n            running_loss, running_loss2 = 0.0, 0.0\n\n    #Decay learning rate\n    if (epoch + 1) % 5 == 0:\n        curr_lr \/= 3\n        update_lr(optimizer, curr_lr)\n\n    # Report epoch loss\n    print(\"Epoch: [{}\/{}] Epoch Loss: {:.4f}\\n\"\n          .format((epoch+1), total_epoch, (epoch_loss \/ (len(train_loader) * batch_size))))\n\n    validate(model, test_loader)\n\n# Save the model checkpoint\ntorch.save(model.state_dict(), 'depthnet.ckpt')","2f7d7695":"\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nfor i, (image, depth) in enumerate(test_loader):\n    print(i, end='\\r')\n    image = image.to(device)\n    y_pred = model(image)\n    plt.imshow(y_pred.permute(1,0,2,3).squeeze(axis=0)[1:2,:,:].squeeze(axis=0).cpu().detach().numpy() * 256)\n    plt.show()\n    \n    if i == 2:\n        break\n        \n","f78f8a1d":"## Datasets and loader","341ff2b0":"## hyperparameter","fa4a6bfa":"# Validate Model By Seeing the Predictions Manually","f8d7a11e":"# Resnet 50","99209207":"## LOSS FUCNTIONS (WE CAN USE FOR THE MODEL)","1e1236cd":"## Resnet-50 Model with Up-sampling","633c92a8":"## Reading Dataset","d38f81e2":"## Data Loader"}}