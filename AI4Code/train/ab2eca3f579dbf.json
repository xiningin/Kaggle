{"cell_type":{"d32eda3c":"code","0865ec25":"code","29d9cf35":"code","ffe1352f":"code","e1cec04e":"code","f23a530a":"code","25368056":"code","1a63bd69":"code","d0398ebc":"code","0801c6a8":"markdown"},"source":{"d32eda3c":"import requests\nimport bs4\nimport pandas as pd","0865ec25":"base_url = 'https:\/\/www.flipkart.com\/search?q=iphone+12&sid=tyy%2C4io&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_3_7_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_3_7_na_na_na&as-pos=3&as-type=RECENT&suggestionId=iphone+12%7CMobiles&requestId=ece38464-7707-4d11-85cf-a094fed4b6d0&as-searchtext=iphones&page={}'\n        ","29d9cf35":"result = requests.get(base_url.format('1'))","ffe1352f":"soup = bs4.BeautifulSoup(result.content, 'lxml')","e1cec04e":"data = soup.find_all(\"div\", {'class' : \"_4rR01T\"}) # loop here","f23a530a":"data","25368056":"# loop the base URL = to jump om next page\n    # request, soup\n    # loop the data variable\n        # loop for data elements","1a63bd69":"base_url = 'https:\/\/www.flipkart.com\/search?q=iphone+12&sid=tyy%2C4io&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_3_7_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_3_7_na_na_na&as-pos=3&as-type=RECENT&suggestionId=iphone+12%7CMobiles&requestId=ece38464-7707-4d11-85cf-a094fed4b6d0&as-searchtext=iphones&page={}'\n\n\n# We have to loop for getting through each page.\nfor i in range(0, 10):\n    scrape_url = base_url.format(i)\n    result = requests.get(scrape_url)\n\n    soup = bs4.BeautifulSoup(result.content, 'lxml')\n\n    # Now that we have reached to every page now using loop to jump on each product present to the page.\n    for j in range (0, 24):\n        data = soup.find_all(\"div\", {\"class\": \"_3pLy-c row\"})[j]\n        data1 = soup.find_all(\"div\", {\"class\": \"col col-5-12 nlI3QM\"})[j]\n\n        Products = []\n        Prices = []\n        Ratings = []\n        Details = []\n\n        # Now that we are on the product we have to use loop for getting each required object from the class.\n        for k in data:\n            item = k.find_all(\"div\", attrs = {'class': \"_4rR01T\"})\n            stars = k.find('div', attrs = {'class':'gUuXy-'})\n            info = k.find('div', attrs = {'class':'fMghEO'})\n\n            Products.append(item[0].text)\n            Ratings.append(stars.text)\n            Details.append(info.text)\n            break\n\n        print(Products)\n        print(Ratings)\n        print(Details)\n\n        # I tried doing this in upper loop but couldn't, so created new loop.\n        for l in data1:\n            rates = l.find('div', attrs = {'class': \"_30jeq3 _1_WHN1\"})\n\n            Prices.append(rates.text)\n            break\n\n\n        print(Prices)","d0398ebc":"Products[0].split(' ')[0:4] # we can also save it seperately","0801c6a8":"## Scraping Flipkart for iphones."}}