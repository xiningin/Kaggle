{"cell_type":{"8f1269f6":"code","4b958a22":"code","b0a215e0":"code","0889f0ca":"code","d7fb4df6":"code","16148c0d":"code","8507a5d4":"code","6da7e18c":"code","96686a14":"code","6f86439c":"code","3c090d4c":"code","9905ba28":"code","1cb058ec":"code","a2c73cd9":"code","aee134ac":"code","9e396dd5":"code","4ee4d9ae":"code","d63c2407":"code","78b3d68f":"code","cfab385b":"code","80707600":"code","d2209d39":"code","d060b9d9":"code","e5daf127":"code","29e21eb1":"code","61906c77":"code","7590bf2a":"code","956471f2":"code","1d707ed9":"markdown","7cd2499a":"markdown","d3692e09":"markdown","7544cf4b":"markdown","3c95c870":"markdown","870526ca":"markdown","b613a819":"markdown","9d0742dd":"markdown","aed86a89":"markdown","97a94a10":"markdown","d3865c6c":"markdown","113c314f":"markdown","438174e6":"markdown","3e9d1042":"markdown","2ae4c728":"markdown","2acd3304":"markdown","89928c37":"markdown","f5623644":"markdown","4e17db45":"markdown","21501f0e":"markdown","e7f5ec1d":"markdown","d42bdbc1":"markdown","935a16b6":"markdown","cb28de81":"markdown","d12c4db0":"markdown","98e10f21":"markdown"},"source":{"8f1269f6":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","4b958a22":"df = pd.read_excel('..\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\ndf.sample(10)","b0a215e0":"print('{:,} rows and {:,} cols'.format(*df.shape))\nprint('{:,} unique patients'.format(df.PATIENT_VISIT_IDENTIFIER.nunique()))","0889f0ca":"# source: https:\/\/www.kaggle.com\/leocanela\/getting-to-know-the-data-eda\n\n## Separating features columns like the starter notebook\ncomorb_lst = [i for i in df.columns if \"DISEASE\" in i]\ncomorb_lst.extend([\"HTN\", \"IMMUNOCOMPROMISED\", \"OTHER\"])\n\ndemo_lst = [i for i in df.columns if \"AGE_\" in i]\ndemo_lst.append(\"GENDER\")\n\nvitalSigns_lst = df.iloc[:,193:-2].columns.tolist()\n\nlab_lst = df.iloc[:,13:193].columns.tolist()","d7fb4df6":"# convert age percentile to ordinal\npcts = sorted(df.AGE_PERCENTIL.unique())\nage_percentile_encoding = {k: i for i, k in enumerate(pcts)}\ndf.AGE_PERCENTIL = df.AGE_PERCENTIL.replace(age_percentile_encoding)","16148c0d":"df = df\\\n    .sort_values(by=['PATIENT_VISIT_IDENTIFIER', 'WINDOW'])\\\n    .groupby('PATIENT_VISIT_IDENTIFIER', as_index=False)\\\n    .fillna(method='ffill')\\\n    .fillna(method='bfill')","8507a5d4":"# ICU per window\npd.crosstab(df.WINDOW, df.ICU)","6da7e18c":"# discar unreliable data (admitted 0-2)\nmask_unreliable = (df.WINDOW == '0-2') & (df.ICU == 1)\ntraining_data = df.loc[~mask_unreliable]\n\n# ICU admitted after window 0-2 or not\nicu_above_2 = training_data.groupby('PATIENT_VISIT_IDENTIFIER')\\\n    .agg({'ICU': max})\\\n    .reset_index()\\\n    .rename(columns={'ICU': 'ICU_NEW'})\n    \n# merge back to original df\ntraining_data = training_data.merge(icu_above_2, on=['PATIENT_VISIT_IDENTIFIER'], how='left')","96686a14":"# valid cases per window\npd.crosstab(training_data.WINDOW, training_data.ICU)","6f86439c":"# keep only features from 0-2 hour window\nmask_02 = training_data.WINDOW == '0-2'\ntraining_data = training_data.loc[mask_02]\n\n# valid cases for training\npd.crosstab(training_data.WINDOW, training_data.ICU_NEW)","3c090d4c":"training_data.shape","9905ba28":"from sklearn import (preprocessing, ensemble, model_selection,\n                     metrics, pipeline, base, decomposition)","1cb058ec":"# features\nfeatures = ['AGE_PERCENTIL', 'GENDER'] + comorb_lst + lab_lst + vitalSigns_lst\nX = training_data[features]\ny = training_data['ICU_NEW']\n\n# cross val\nn_splits = 5\nn_repeats = 10\nseed = 2020\ncv = model_selection.RepeatedStratifiedKFold(n_splits, n_repeats, random_state=seed)","a2c73cd9":"def cross_val_score_report(model, X, y, scoring_metrics, cv, n_jobs=-1):\n    mean_scores = dict()\n    for scoring in scoring_metrics:\n        scores = model_selection.cross_val_score(\n            model, X, y, cv=cv, scoring=scoring, n_jobs=n_jobs)\n        mean_scores[scoring] = scores\n        print(f'{scoring} CV Mean: {np.mean(scores):.3f} (Std: {np.std(scores):.3f})')\n    return mean_scores","aee134ac":"rf = ensemble.RandomForestClassifier(\n    n_estimators=1000,\n    max_depth=4,\n    min_weight_fraction_leaf=0.02,\n    random_state=seed,\n    n_jobs=-1,\n    oob_score=True,\n    max_features='sqrt')\n\nmodel1 = rf\n\n# cross val\nscoring_metrics = ['roc_auc', 'precision', 'recall', 'f1', 'accuracy']\nmodel1_scores = cross_val_score_report(\n    model1, X, y, cv=cv, scoring_metrics=scoring_metrics)","9e396dd5":"import shap\nshap.initjs()","4ee4d9ae":"def cross_val_shap(model, X, y, cv, explainer_type='kernel', \n                   random_state=seed, n_jobs=-1, \n                   feature_perturbation='tree_path_dependent',\n                   model_output='raw'):\n    # cross val shap\n    cv_shap = list()\n    expec_values = list()\n    test_ixs = list()\n    # loop folds\n    for train_ix, test_ix in cv.split(X, y):\n        # split train\/test\n        X_train, y_train = X.iloc[train_ix], y.iloc[train_ix]\n        X_test, y_test = X.iloc[test_ix], y.iloc[test_ix]\n        # fit model\n        m = base.clone(model)\n        m.fit(X_train, y_train)\n        # explain\n        if explainer_type == 'tree':\n            if feature_perturbation == 'interventional':\n                data = X_train\n            else:\n                data = None\n            explainer = shap.TreeExplainer(m, \n                                           data=data,\n                                           feature_perturbation=feature_perturbation,\n                                           model_output=model_output)\n            shap_values = explainer.shap_values(X_test, check_additivity=False)\n            cv_shap.append(shap_values)\n            expec_values.append(explainer.expected_value)\n            test_ixs.append(test_ix)\n        elif explainer_type == 'kernel':\n            explainer = shap.KernelExplainer(m.predict_proba, X_train, link='logit')\n            shap_values = explainer.shap_values(X_test)\n            cv_shap.append(shap_values)\n            expec_values.append(explainer.expected_value)\n            test_ixs.append(test_ix)\n        else:\n            raise NotImplementedError\n            \n    # aggregate shap values\n    # source: https:\/\/medium.com\/@lucasramos_34338\/visualizing-variable-importance-using-shap-and-cross-validation-bd5075e9063a\n    test_set = test_ixs[0]\n    cv_shap_agg = np.array(cv_shap[0])\n    expec_values_agg = np.array(expec_values[0])\n    for i in range(len(test_ixs)):\n        test_set = np.concatenate((test_set, test_ixs[i]), axis=0)\n        cv_shap_agg = np.concatenate((cv_shap_agg, np.array(cv_shap[i])), axis=1)\n        expec_values_agg = np.concatenate((expec_values_agg, np.array(expec_values[i])), axis=0)\n    #bringing back variable names    \n    X_test = X.iloc[test_set]\n    \n    return cv_shap_agg, cv_shap, expec_values_agg, X_test","d63c2407":"shap_cv_agg_model1, shap_cv_model1, expec_value_model1, X_test_model1 = cross_val_shap(\n    model1, X, y, cv=cv, explainer_type='tree')","78b3d68f":"# let's plot summary SHAP plots of every 20 features (ordered)\nn_plot = 20\nn_feats = X.shape[1]\n\n# sort features based on sum of abs shap values\nfeature_order = np.argsort(np.sum(np.abs(shap_cv_agg_model1[1]), axis=0))[::-1]\n\n# plot\nshap.summary_plot(shap_cv_agg_model1[1], \n                  X_test_model1,\n                  max_display=n_feats)","cfab385b":"# mean features\nlab_median = [xi for xi in lab_lst if xi.endswith('MEDIAN')]\nvital_median = [xi for xi in vitalSigns_lst if xi.endswith('MEDIAN')]\n\n# feature and target\n# features\nfeatures = ['AGE_PERCENTIL', 'GENDER'] + comorb_lst + lab_median + vital_median\nX = training_data[features]\ny = training_data['ICU_NEW']\n\nX.shape","80707600":"rf = ensemble.RandomForestClassifier(\n    n_estimators=1000,\n    max_depth=4,\n    min_weight_fraction_leaf=0.02,\n    random_state=seed,\n    n_jobs=-1,\n    oob_score=True,\n    max_features='sqrt')\n\nmodel2 = rf\n\n# cross val\nscoring_metrics = ['roc_auc', 'precision', 'recall', 'f1', 'accuracy']\nmodel2_scores = cross_val_score_report(\n    model2, X, y, cv=cv, scoring_metrics=scoring_metrics)","d2209d39":"shap_cv_agg_model2, shap_cv_model2, expec_value_model2, X_test_model2 = cross_val_shap(\n    model2, X, y, cv=cv, explainer_type='tree')","d060b9d9":"# sort features based on sum of abs shap values\nfeature_order = np.argsort(np.sum(np.abs(shap_cv_agg_model2[1]), axis=0))[::-1]\nn_feats = X.shape[1]\n\n# plot\nshap.summary_plot(shap_cv_agg_model2[1], \n                  X_test_model2,\n                  max_display=n_feats)","e5daf127":"# let's check dependence plot for top features\nfig, ax = plt.subplots(4, 4, figsize=(16, 12))\nfor f, axi in zip(X.columns[feature_order[:16]], ax.flatten()):\n    shap.dependence_plot(f, shap_cv_agg_model2[1], X_test_model2, ax=axi, show=False)\n    axi.set_ylabel('SHAP')\n    \nfig.tight_layout()","29e21eb1":"import seaborn as sns\nimport scipy.cluster\n\n# clustering\nD = scipy.spatial.distance.pdist(shap_cv_agg_model2[1], 'sqeuclidean')\nclustOrder = scipy.cluster.hierarchy.leaves_list(scipy.cluster.hierarchy.complete(D))\n\n# clustermap only top10 features\ndata_plot = pd.DataFrame(shap_cv_agg_model2[1], columns=X.columns).iloc[clustOrder]\ntop_10_feat = X.columns[feature_order[:10]]\n\nplt.figure(figsize=(12, 6))\nsns.heatmap(data_plot[top_10_feat].T)\nplt.title('SHAP Values clustering')\nplt.xlabel('Cross-val observation');","61906c77":"import scipy.cluster\n\nclusters = scipy.cluster.hierarchy.fclusterdata(shap_cv_agg_model2[1], \n                                                t=0.7*D.max(),\n                                                criterion='distance',\n                                                metric='sqeuclidean',\n                                                method='complete')\n\nclusters.max()","7590bf2a":"y[X_test_model2.index].groupby(clusters).mean()","956471f2":"X_test_model2.groupby(clusters)[X.columns[feature_order]].mean().T.style.background_gradient(axis=1)","1d707ed9":"This is a model built with only \"0-2 window\", which is clinically relevant as the dataset authors pointed out, with 74% precision.  \n\nMoreover, SHAP values gave us a better understand of underlying factor that affect ICU risk and a way of clustering into groups. It is worth noticing that we can relax the clustering constraint in order to create more or less cluster that are clinically relevant, but this needs expert orientation.\n","7cd2499a":"Feature with zero impact either are really irrelevant or might have not been used in any of the trees ","d3692e09":"## Random Forest","7544cf4b":"## Window  \nAs stated in [data description section](https:\/\/www.kaggle.com\/S%C3%ADrio-Libanes\/covid19), a model with only the \"0-2 window\" is more clincally relevant, so we will follow their suggestion.\n\nMoreover, as warned by the authors as well, we should be aware when the target variable (`ICU`) is 1, since we cannot be sure about the events' order, i.e. we are not sure if lab results were ready before the ICU admission. Therefore, if a patient was admitted at window 0-2, we would discard the data. We will consider a patient ICU adimtted if was happened at any posterior window but we will use only 0-2 window's features.","3c95c870":"The vast majority of the features behave very linearly (globally) and all expanded statistics (MEAN, MIN, MAX, etc.) seem to behave in the same way. With that, let's simplify de model a bit and use only MEDIAN features.","870526ca":"We should end up with 385 - 32 = 353 rows (No. unique patients - admitted 0-2 window)","b613a819":"## Missing data  \nAs suggested by [dataset's authors](https:\/\/www.kaggle.com\/S%C3%ADrio-Libanes\/covid19), patient's missing data can be filled by neighbouring windows. Therefore, we would do an iterative approach by applying a foward fill followed by backward fill.","9d0742dd":"There are some clear clusters:\n* PCR\n* REspiratory\n* Age (both with high SHAP values, in the mid-left, and low SHAP values, in the middle going to the right)\n* Linfocitos (also both high and low SHAP values)\n* Sodium\n\nStill, SHAP values does not give us any insights about original variable values. Let's check it","aed86a89":"Cluster 1 and 2 have more than 70% of ICU admitted patients, while 4th cluster less than 30%.  Let's check the features for more insights.","97a94a10":"# Load data","d3865c6c":"Performance metrics are slightly better, which is good news, since we did not lose predictive information removing those features.  Let's check the SHAP values","113c314f":"# Modelling  \nLet's test some models. We will throw ML algorithms and try to interpret them post hoc, via Shapley values.","438174e6":"## Only MEDIAN features","3e9d1042":"# Conclusion","2ae4c728":"# Interpretation","2acd3304":"## Group of features","89928c37":"# Preprocessing","f5623644":"We will extrapolate the SHAP framework to a cross-validation setting, similar to what has been done [here](https:\/\/medium.com\/@lucasramos_34338\/visualizing-variable-importance-using-shap-and-cross-validation-bd5075e9063a).","4e17db45":"We ended up, as expected, with 353 rows.","21501f0e":"# Cluster and ICU Risk","e7f5ec1d":"Not bad for a first attempt. Let's try to understand and interpret it with SHAP.","d42bdbc1":"Let's use SHAP values for supervised clustering and see if any interesting pattern emerges.","935a16b6":"## Clustering","cb28de81":"Interesting to see the interaction between age and PCR (second subplot): for both there is a positive slope (higher its value, higher the risk of ICU admition), but for older people, higher value of PCR is associated with less risk of ICU admission than with smaller PCR values.","d12c4db0":"Genral summary of clusters:\n* **Cluster 1**: Greater `PCR`, `Age percentile` 60th, smaller `Linfocitos` and higher `Diastolic Blood Pressure`, high `Temperature`, mostly men;\n* **Cluster 2**: Medium `PCR`, `Age percentile` 70-80th, high `Respiratory Rate`;\n* **Cluster 3**: Low `PCR`, `Age percentile` 80-90th, higher incident of `comorbities`, low `Temperature`;\n* **Cluster 4**: Low `PCR`, youngest people 30-40th percentile, low `Temperature`, highest `Calcium`, `Linfocitos`, `Sodium`, `Hemoglobin`, `Oxygen Sautration`.","98e10f21":"No invalid cases (`ICU = 1` and `WINDOW = '0-2'`)"}}