{"cell_type":{"2e1274fa":"code","b46d800f":"code","4b0b3d56":"code","ef263d92":"code","c92a5468":"code","bbc93d41":"code","879661e6":"code","c77bda11":"code","c979121b":"code","37dfe055":"code","0ec40982":"code","491de8b9":"code","2903be0d":"code","16999969":"code","7e0f6b6a":"code","01671cfe":"code","e76c991e":"code","f1bee16b":"code","75ede411":"code","db9658fe":"code","e2aac58a":"code","f52358cd":"code","dcb032c3":"code","e5928151":"code","ad95ffed":"code","a727943e":"code","94891884":"code","6d09bc41":"code","21123cc7":"code","27097251":"code","f505eec9":"code","66c595b8":"code","96bf928b":"code","2ed2413c":"code","84b97ec2":"code","1b3eb173":"code","8e1feebe":"markdown","617917f7":"markdown","bc40cebd":"markdown","5b3d42ee":"markdown","8b2c2d45":"markdown","400b031d":"markdown","308ece52":"markdown","9fe8dcf8":"markdown","55a11b8d":"markdown","f64755f0":"markdown"},"source":{"2e1274fa":"import os\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport shutil\nfrom sklearn.datasets import load_files\n\n#Import required packages\n# import numpy as np\nimport cv2\nimport random\n# import os\nimport sys\n# import shutil\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nimport configparser\nimport secrets\n\nfrom keras.utils import np_utils\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n\nfrom keras.preprocessing import image                  \nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import ImageFile               ","b46d800f":"DATA_AUG = os.path.join(os.getcwd(),\"prepare_augmented_data\")\n\nif not os.path.exists(DATA_AUG):\n    os.makedirs(DATA_AUG)\n    \n","4b0b3d56":"data_train = pd.read_csv(\"..\/input\/identify-the-dance-form\/train.csv\")\ndata_test = pd.read_csv(\"..\/input\/identify-the-dance-form\/test.csv\")\n\ndata_train['Image'] = data_train['Image'].apply(lambda x:os.path.join(\"..\/input\/identify-the-dance-form\/\",\"train\",x))\ndata_test['Image'] = data_test['Image'].apply(lambda x:os.path.join(\"..\/input\/identify-the-dance-form\/\",\"test\",x))\n\nprint(\"The number of training images is \",data_train.shape[0])\nprint(\"The number of testing images is \",data_test.shape[0])","ef263d92":"data_train['target'].value_counts().index\n\ndance_dist = list()\nfor idx,num_files in enumerate(data_train['target'].value_counts()):\n    dance_dist.append({\n        \"DanceName\":data_train['target'].value_counts().index[idx],\n        \"NumFiles\":num_files\n    })\ndance_dist = pd.DataFrame(dance_dist)\n\n\ndance_dist.head(10) # shows the classwise distribution of data","c92a5468":"# putting images belonging to different classes into different folders with corresponding classname\n# Preparing dataset for augmentation\nfor i in range(data_train.shape[0]):\n    if not os.path.exists(os.path.join(DATA_AUG,data_train.iloc[i,1])):\n        os.makedirs(os.path.join(DATA_AUG,data_train.iloc[i,1]))\n    shutil.copy(data_train.iloc[i,0],os.path.join(DATA_AUG,data_train.iloc[i,1],data_train.iloc[i,0].split(\"\/\")[-1]))\n","bbc93d41":"# Setting the data augmentation definition\n\ngen_per_image = 4\ngen_per_class = 300\n#path to the folder containing the data ready for augmentation\npath = DATA_AUG\nrotation_range = 5\nwidth_shift_range = 0.02\nheight_shift_range = 0.02\nshear_range = 0.01\nzoom_range = 0.05\nhorizontal_flip = False\nfill_mode = \"nearest\"\n","879661e6":"def increase_brightness(img, value):\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    h, s, v = cv2.split(hsv)\n\n    lim = 255 - value\n    v[v > lim] = 255\n    v[v <= lim] += value\n\n    final_hsv = cv2.merge((h, s, v))\n    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n    return img\n\ndef change_contrast(img, level):\n    img = Image.fromarray(img.astype('uint8'))\n    factor = (259 * (level + 255)) \/ (255 * (259 - level))\n    def contrast(c):\n        return 128 + factor * (c - 128)\n    return np.array(img.point(contrast))\n\ndef pad_img(img):\n    h, w = img.shape[:2]\n    new_h = int((5 + secrets.randbelow(16)) * h \/ 100) + h\n    new_w = int((5 + secrets.randbelow(16)) * w \/ 100) + w\n\n    full_sheet = np.ones((new_h, new_w, 3)) * 255\n\n    p_X = secrets.randbelow(new_h - img.shape[0])\n    p_Y = secrets.randbelow(new_w - img.shape[1])\n\n    full_sheet[p_X : p_X + img.shape[0], p_Y : p_Y + img.shape[1]] = img\n\n    full_sheet = cv2.resize(full_sheet, (w, h), interpolation = cv2.INTER_AREA)\n\n    return full_sheet.astype(np.uint8)\n\ndef preprocess_img(img):\n    img = np.array(img)\n\n    x = secrets.randbelow(2)\n\n    if x == 0:\n        # img = pad_img(img)\n        img = increase_brightness(img, secrets.randbelow(26))\n        img = change_contrast(img, secrets.randbelow(51))\n    else:\n        # img = pad_img(img)\n        img = change_contrast(img, secrets.randbelow(51))\n        img = increase_brightness(img, secrets.randbelow(26))\n\n    return img\n\ndef copy_org(doc_type):\n    files = os.listdir(os.path.join(path, doc_type))\n\n    for file in files:\n        shutil.copy(os.path.join(path, doc_type, file), os.path.join(os.getcwd(),\"augmented_data\",doc_type, file))\n\n\n#Initialise the parameters for Augmentation.\ndatagen = ImageDataGenerator(\n        rotation_range = rotation_range,\n        width_shift_range = width_shift_range,\n        height_shift_range = height_shift_range,\n        shear_range = shear_range,\n        zoom_range = zoom_range,\n        horizontal_flip = horizontal_flip,\n        fill_mode = fill_mode,\n        preprocessing_function = preprocess_img)\n\ndef generator(doc_type, total):\n    # print(doc_type + \" \" + set_type)\n    print(doc_type)\n    # src_path = os.path.join(path, doc_type, set_type)\n    src_path = os.path.join(path,doc_type)\n    dst_path = os.path.join(os.getcwd(), \"augmented_data\",doc_type)\n    # files = os.listdir(src_path)\n    files = os.listdir(src_path)\n    m = len(files)\n\n    for i in range(total):\n        k = secrets.randbelow(m)\n        img_cv = cv2.resize(cv2.imread(os.path.join(src_path, files[k])), (500, 500), interpolation = cv2.INTER_AREA)\n        cv2.imwrite(\"temp_img.jpg\", img_cv)\n        img = load_img(\"temp_img.jpg\")  # this is a PIL image\n        # img = load_img(os.path.join(src_path, files[k]))  # this is a PIL image\n        imgarr = img_to_array(img)  # this is a Numpy array with shape (?, ?, ?)\n\n        gen_file_name = doc_type + \"_\" + str(i)\n\n        # cv2.imwrite(os.path.join(dst_path, gen_file_name + \".jpg\"), cv2.imread(os.path.join(src_path, files[k])))\n\n        imgarr = imgarr.reshape((1,) + imgarr.shape)  # this is a Numpy array with shape (1, ?, ?, ?)\n\n        n = 1\n        for batch in datagen.flow(imgarr, batch_size=1, save_to_dir=dst_path, save_prefix=gen_file_name, save_format='jpeg'):\n            n += 1\n            if n > gen_per_image:\n                break  # otherwise the generator would loop indefinitely\n\n","c77bda11":"\n#Contains all the labels\ndoc_types = os.listdir(path)\n\nfor doc_type in doc_types:\n    if not os.path.exists(os.path.join(os.getcwd(), \"augmented_data\",doc_type)):\n        os.makedirs(os.path.join(os.getcwd(),\"augmented_data\",doc_type))\n    # generator(doc_type, set_types[0], gen_per_class)\n    generator(doc_type,gen_per_class)\n    copy_org(doc_type)","c979121b":"# creating the new train.csv\nDATA_DIR = os.path.join(os.getcwd(), \"augmented_data\")\ndef create_csv(DATA_DIR,filename):\n    data = list()\n    class_names = os.listdir(DATA_DIR)\n    for class_name in class_names:\n        file_names = os.listdir(os.path.join(DATA_DIR,class_name))\n        for file_name in file_names:\n            data.append({\n                \"FileName\":os.path.join(DATA_DIR,class_name,file_name),\n                \"ClassName\":class_name\n            })\n    data = pd.DataFrame(data)\n    data.to_csv(filename,index=False)\n\ncreate_csv(DATA_DIR,\"train_augmented.csv\")\n\n\ndata = pd.read_csv(os.path.join(os.getcwd(),\"train_augmented.csv\"))\n# data.head()","37dfe055":"TEST_DIR = os.path.join(\"..\/input\/identify-the-dance-form\/\",\"test\")\nTRAIN_DIR = os.path.join(os.getcwd(),\"augmented_data\")\nMODEL_PATH = os.path.join(os.getcwd(),\"model\")","0ec40982":"if not os.path.exists(TEST_DIR):\n    print(\"Testing data does not exists\")\nif not os.path.exists(TRAIN_DIR):\n    print(\"Training data does not exists\")\nif not os.path.exists(MODEL_PATH):\n    print(\"Model path does not exists\")\n    os.makedirs(MODEL_PATH)\n    print(\"Model path created\")\n    ","491de8b9":"data_train = pd.read_csv(os.path.join(os.getcwd(),\"train_augmented.csv\"))\ndata_test = pd.read_csv(os.path.join(\"..\/input\/identify-the-dance-form\/\",\"test.csv\"))","2903be0d":"data_test.head()","16999969":"print(\"The number of training images is \",data_train.shape[0])\nprint(\"The number of testing images is \",data_test.shape[0]) # for submission","7e0f6b6a":"data_train['FileName'] = data_train['FileName'].apply(lambda x:os.path.join(TRAIN_DIR,\"\/\".join(x.split(\"\/\")[-2:])))\ndata_test['Image'] = data_test['Image'].apply(lambda x:os.path.join(\"..\/input\/identify-the-dance-form\/\",\"test\",x))","01671cfe":"data_test.head()","e76c991e":"data_train.info()","f1bee16b":"nf = data_train['ClassName'].value_counts(sort=False)\nlabels = data_train['ClassName'].value_counts(sort=False).index.tolist()\ny = np.array(nf)\nwidth = 1\/1.5\nN = len(y)\nx = range(N)\n\nfig = plt.figure(figsize=(20,15))\nay = fig.add_subplot(211)\n\nplt.xticks(x, labels, size=15)\nplt.yticks(size=15)\n\nay.bar(x, y, width, color=\"blue\")\n\nplt.title('Bar Chart',size=25)\nplt.xlabel('ClassName',size=15)\nplt.ylabel('Count',size=15)\n\nplt.show()","75ede411":"#preparing the dictionary for labels encoding \n\nlabels_list = list(set(data_train['ClassName'].values.tolist()))\nlabels_id = {label_name:id for id,label_name in enumerate(labels_list)}\nprint(labels_id)\ndata_train['ClassName'].replace(labels_id,inplace=True)","db9658fe":"labels = to_categorical(data_train['ClassName'])\nprint(labels.shape)","e2aac58a":"#splitting data into train and test set in 80:20 ratio\n\nxtrain,xtest,ytrain,ytest = train_test_split(data_train.iloc[:,0],labels,test_size = 0.2,random_state=42)\ndef path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(64, 64))\n    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","f52358cd":"           \nImageFile.LOAD_TRUNCATED_IMAGES = True                 \n\n# pre-process the data for Keras\ntrain_tensors = paths_to_tensor(xtrain).astype('float32')\/255 - 0.5\nvalid_tensors = paths_to_tensor(xtest).astype('float32')\/255 - 0.5\ntest_tensors = paths_to_tensor(data_test.iloc[:,0]).astype('float32')\/255 - 0.5","dcb032c3":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(64,64,3), kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(8, activation='softmax', kernel_initializer='glorot_normal'))\n\n\nmodel.summary()","e5928151":"plot_model(model,to_file=\"model_dance_recognition.png\",show_shapes=True,show_layer_names=True)","ad95ffed":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","a727943e":"filepath = os.path.join(MODEL_PATH,\"dance_recognition-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\ncallbacks_list = [checkpoint]","94891884":"model_history = model.fit(train_tensors,ytrain,validation_data = (valid_tensors, ytest),epochs=10, batch_size=40, shuffle=True,callbacks=callbacks_list)","6d09bc41":"def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    fig.savefig(os.path.join(MODEL_PATH,\"confusion_matrix.png\"))\n    return fig","21123cc7":"def print_heatmap(n_labels, n_predictions, class_names):\n    labels = n_labels #sess.run(tf.argmax(n_labels, 1))\n    predictions = n_predictions #sess.run(tf.argmax(n_predictions, 1))\n\n#     confusion_matrix = sess.run(tf.contrib.metrics.confusion_matrix(labels, predictions))\n    matrix = confusion_matrix(labels.argmax(axis=1),predictions.argmax(axis=1))\n    row_sum = np.sum(matrix, axis = 1)\n    w, h = matrix.shape\n\n    c_m = np.zeros((w, h))\n\n    for i in range(h):\n        c_m[i] = matrix[i] * 100 \/ row_sum[i]\n\n    c = c_m.astype(dtype = np.uint8)\n\n    \n    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)","27097251":"class_names = list()\nfor name,idx in labels_id.items():\n    class_names.append(name)\nprint(class_names)","f505eec9":"ypred = model.predict(valid_tensors,verbose=1)","66c595b8":"print_heatmap(ytest,ypred,class_names)","96bf928b":"ypred_class = np.argmax(ypred,axis=1)\n# print(ypred_class[:10])\nytest = np.argmax(ytest,axis=1)","2ed2413c":"accuracy = accuracy_score(ytest,ypred_class)\nprint('Accuracy: %f' % accuracy)\n# precision tp \/ (tp + fp)\nprecision = precision_score(ytest, ypred_class,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp \/ (tp + fn)\nrecall = recall_score(ytest,ypred_class,average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1 = f1_score(ytest,ypred_class,average='weighted')\nprint('F1 score: %f' % f1)","84b97ec2":"test_pred = model.predict(test_tensors,verbose=1)\ntest_pred_class = model.predict_classes(test_tensors)\n# print(test_pred_class)\n# print(test_pred_class.shape)\n# print(test_pred_class.shape)\n\nid_labels = dict()\nfor label,idx in labels_id.items():\n    id_labels[idx]=label\n# print(id_labels)","1b3eb173":"data_submit = list()\nfor i in range(test_pred_class.shape[0]):\n    data_submit.append({\n        \"Image\":data_test.iloc[i,0].split(\"\/\")[-1],\n        \"target\":id_labels[test_pred_class[i]]\n    })\ndata_submit = pd.DataFrame(data_submit)\ndata_submit.to_csv(\"submission.csv\",index=False)","8e1feebe":"# Data Augmentation\n\n* As the dataset size is very less we need to augment the data ","617917f7":"# Precision Recall F1 Score","bc40cebd":"# Data Preprocessing","5b3d42ee":"# Model Architecture","8b2c2d45":"1. The classes are well separated and equally balanced into 8 classes","400b031d":"# Model Training","308ece52":"# Data Preparation","9fe8dcf8":"# Model Analysis\nFinding the Confusion matrix,Precision,Recall and F1 score to analyse the model thus created","55a11b8d":"## Creating the Submission file","f64755f0":"# Importing the Libraries"}}