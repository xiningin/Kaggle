{"cell_type":{"1925436d":"code","e5d4205b":"code","e9a368bb":"code","70bc71a6":"code","bd2f3ad2":"code","422d5ce9":"code","b61027aa":"code","3699cb2e":"code","f37bfbab":"code","45326176":"code","58025c1a":"code","f2afaaa0":"code","2e1dd2b6":"code","e26a5ebe":"code","171368a5":"markdown","3a9513c1":"markdown"},"source":{"1925436d":"import numpy as np\nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n%matplotlib inline\n\nfrom wordcloud import WordCloud\nimport spacy\n\n!pip install spacytextblob==0.1.7\nfrom spacytextblob.spacytextblob import SpacyTextBlob \n\n\n","e5d4205b":"data = pd.read_csv('..\/input\/reddit-vaccine-myths\/reddit_vm.csv')\ndata['timestamp']=pd.to_datetime(data['timestamp'])\ndata=data.set_index(data['timestamp'])\ndata=data.drop('timestamp', axis=1)\ndata.head()","e9a368bb":"data.shape","70bc71a6":"data.drop(['body','created','id','url','comms_num'],axis=1,inplace=True)\ndata.head()","bd2f3ad2":"from nltk.corpus import stopwords","422d5ce9":"data['title'] = data['title'].apply(lambda word: \" \".join(word for word in word.split() if word not in stopwords.words('english')))\ndata['title'] = data['title'].apply(lambda word: \" \".join(word.lower() for word in word.split()))","b61027aa":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()","3699cb2e":"data['title']=[lemmatizer.lemmatize(word) for word in data['title'] ]","f37bfbab":"#Calculating the Polarity and Subjectivity\nspaceit = spacy.load('en_core_web_sm')\nstb = SpacyTextBlob()\nspaceit.add_pipe(stb)\ndata['title_subjectivity'] = data['title'].apply(lambda x: spaceit(x)._.sentiment.subjectivity)\ndata['title_polarity'] = data['title'].apply(lambda x: spaceit(x)._.sentiment.polarity)\n\n","45326176":"data.head()","58025c1a":"tp=pd.DataFrame()\ntp['positive']=data['title_polarity'].apply(lambda x : x if(x > 0.05) else None)\ntp['negative']=data['title_polarity'].apply(lambda x:  x if(x<=-0.05) else None)\ntp['neutral']=data['title_polarity'].apply(lambda x: x if(x>-0.05 and x<=.05) else None)\ntp\n\nfig = plt.figure()\nfig.set_figheight(5)\nfig.set_figwidth(10)\n\nax = fig.add_subplot(111)\n\ncounts = [len((tp['positive']).value_counts()),len(tp['neutral'].value_counts()),len((tp['negative']).value_counts())]\n\npercents = [100*x\/sum(counts) for x in counts]\n\ny_ax = ('Positive','Neutral','Negative')\ny_tick = np.arange(len(y_ax))\n\nax.barh(range(len(counts)), counts, align = \"center\", color = ['red', 'black', 'orange'])\nax.set_yticks(y_tick)\nax.set_yticklabels(y_ax, size = 15)\nax.set_facecolor('xkcd:white')\n\nplt.xlabel('Polarity Of column title ', size=15)\n\n\n\nfor i, y in enumerate(ax.patches):\n    label_per = percents[i]\n    ax.text(y.get_width()+.09, y.get_y()+.3, str(round((y.get_width()), 1)), fontsize=15)\n    \n    ax.text(y.get_width()+.09, y.get_y()+.1, str(f'{round((label_per), 2)}%'), fontsize=15)\n\nsns.despine()\nplt.show()\n","f2afaaa0":"title_positive_polarity_words = ' '\" \".join(x for x in (data[data['title_polarity']>0.05])['title'].astype(str))\ntitle_negative_polarity_words = ' '\" \".join(x for x in (data[data['title_polarity']<-0.05])['title'].astype(str))","2e1dd2b6":"wordcloud=WordCloud(width = 2000, height = 2000, \n                background_color ='black', colormap = 'rainbow',\n                min_font_size = 20).generate(title_positive_polarity_words)\nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n  \nplt.show()","e26a5ebe":"wordcloud=WordCloud(width = 2000, height = 2000, \n                background_color ='black', colormap = 'rainbow',\n                min_font_size = 20).generate(title_negative_polarity_words)\nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n  \nplt.show()","171368a5":"### Title Negative Sentiments","3a9513c1":"### Positive Title Sentiments"}}