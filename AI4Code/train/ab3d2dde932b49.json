{"cell_type":{"34b93e69":"code","dabf4bae":"code","4c761f89":"code","3402c7f4":"code","f11bedc4":"code","d4a6a5eb":"code","602457fe":"code","d64eac47":"code","3ecf91d7":"code","1b351de6":"code","0b539777":"markdown","b18e9017":"markdown","787ba125":"markdown","7671eefd":"markdown","5bb3ad71":"markdown","26cdceb0":"markdown","e3822459":"markdown","51b302af":"markdown","3e808020":"markdown","bc221047":"markdown","c6f951d8":"markdown","718ba946":"markdown"},"source":{"34b93e69":"!git clone --depth 1 --branch \"v1.0-alpha\" https:\/\/github.com\/crunchiness\/lernd.git\n%cd lernd\n!pip install ordered-set==4.0.1","dabf4bae":"import os\n\nimport tensorflow as tf\n\nfrom lernd.classes import GroundAtoms, ILP, LanguageModel, MaybeGroundAtom, ProgramTemplate\nfrom lernd.lernd_loss import Lernd\nfrom lernd.lernd_types import Constant, RuleTemplate\nfrom lernd.main import generate_weight_matrices, extract_definitions, print_valuations\nfrom lernd.util import ground_atom2str, str2ground_atom, str2pred, get_ground_atom_probs\n\nos.environ['CUDA_VISIBLE_DEVICES'] = ''\n\ntarget_pred = str2pred('predecessor\/2')\nzero_pred = str2pred('zero\/1')\nsucc_pred = str2pred('succ\/2')\npreds_ext = [zero_pred, succ_pred]\nconstants = [Constant(str(i)) for i in range(10)]\nlanguage_model = LanguageModel(target_pred, preds_ext, constants)","4c761f89":"preds_aux = []\nrules = {target_pred: (RuleTemplate(0, False), None)}\nforward_chaining_steps = 1\nprogram_template = ProgramTemplate(preds_aux, rules, forward_chaining_steps)","3402c7f4":"ground_zero = str2ground_atom('zero(0)')\nbackground_axioms = [ground_zero] + [str2ground_atom(f'succ({i},{i + 1})') for i in range(9)]\npositive_examples = [str2ground_atom(f'predecessor({i + 1},{i})') for i in range(9)]\nprint('Background axioms:')\nprint('\\n'.join(map(ground_atom2str, background_axioms)))\nprint('\\nPositive examples:')\nprint('\\n'.join(map(ground_atom2str, positive_examples)))","f11bedc4":"ground_atoms = GroundAtoms(language_model, program_template)\nnegative_examples = []\nfor ground_atom, _ in ground_atoms.ground_atom_generator(MaybeGroundAtom.from_pred(target_pred)):\n    if ground_atom not in positive_examples:\n        negative_examples.append(ground_atom)\nprint('Negative examples:')\nprint('\\n'.join(map(ground_atom2str, negative_examples)))","d4a6a5eb":"ilp_problem = ILP(language_model, background_axioms, positive_examples, negative_examples)","602457fe":"lernd_model = Lernd(ilp_problem, program_template)","d64eac47":"weights = generate_weight_matrices(lernd_model.clauses)\nlosses = []\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.5)\n\nim = None\nfor i in range(1, 301):\n    loss_grad, loss, valuation, _ = lernd_model.grad(weights)\n    optimizer.apply_gradients(zip(loss_grad, list(weights.values())))\n    loss_float = float(loss.numpy())\n    losses.append(loss_float)\n    if i % 10 == 0:\n        print(f'Step {i} loss: {loss_float}\\n')","3ecf91d7":"from matplotlib import pyplot as plt\n\nfig, ax = plt.subplots()\nax.plot(losses)\nax.set_title('Loss')\nax.set_xlabel('Step')\nax.set_ylabel('Value')","1b351de6":"extract_definitions(lernd_model.clauses, weights)\nground_atom_probs = get_ground_atom_probs(valuation, lernd_model.ground_atoms)\nprint_valuations(ground_atom_probs)","0b539777":"Now we are ready to start the training. We initialize the weights.\n\nWe are using `RMSProp` optimization as suggested in the paper. All other hyperparameter values are also taken from the\npaper. The only exceptions are the number of steps (100 here instead of 6000) and `clause_prob_threshold` (which is the\nprobability needed for us to extract the clauses). If it does not reach the set 0.1, I extract clauses with max\nprobability.","b18e9017":"All of that together constitutes an ILP problem:","787ba125":"Now we can initialize `Lernd`. On initialization it will perform all the non-differentiable operations, mainly the\ngeneration of $X_c$ tensors (one for each generated clause). These tensors hold indices of ground atoms that satisfy the\nclause, and thus enable forward chaining. For more details, see the paper.","7671eefd":"Finally let's extract the results:","5bb3ad71":"Let's plot the loss to see how it went. Basically, this simple problem is solved in under 10 training steps, and if run\nfor 300 steps, loss converges to exactly 0.","26cdceb0":"In this case, negative examples are all other $predecessor$ substitutions ($\\mathcal{P}$ being a set of positive\nexamples):\n\n$\\mathcal{N} = \\{predecessor(X,Y) \\mid (X,Y) \\in \\{0,\\ldots,9\\}^2\\} - \\mathcal{P}$\n\nHere I take advantage of Lernd's `ground_atom_generator` to define it:","e3822459":"To show how Lernd works, I will walk you through the simple problem of learning the \"predecessor\" relation. Lernd will\nlearn it by using just a few examples and background facts.\n\nFirst the problem needs to expressed in ILP terms. We need to define a language frame and a program template.\n\nFormally, a language frame $\\mathcal{L}$ is a tuple $(target, P_e, arity_e, C)$, where $target$ is an intensional target\npredicate, $P_e$ is a set of extensional predicates, $arity_e$ is an arity map of predicates, $C$ is a set of constants.\n\nIn Lernd `LanguageModel` corresponds to $\\mathcal{L}$. Here we define a language frame for the predecessor problem:\n* The $target$ is an intensional predicate we want to learn.\n* Constants are just natural numbers 0 to 9.\n* We have 2 extensional predicates, a monadic $zero$ predicate, and a successor relation - a dyadic predicate $succ$.\n\nWe don't need to worry about $arity_e$ mapping, since arity is part of the predicate definition in this\nimplementation.","51b302af":"### $\\partial$ILP $-$ Differential Inductive Logic Programming Framework\nBriefly, in $\\partial$ILP all the non-differentiable work is done in advance, producing apparatus for numerical,\ndifferentiable forward chaining. Optimization algorithm is run where loss is evaluation of forward chaining results.\nAutomatic differentiation is used to calculate the gradients. Forward chaining is adjusted by the weight matrices, and,\nin turn, these weights can be adjusted. In the end, results (predicate definitions) are extracted from the weight\nmatrices.\n","3e808020":"Obviously, this is a simple problem with no noise in the data, so the next notebook (`even.ipynb`) will demonstrate how\n**Lernd** solves a more difficult problem.","bc221047":"Program template $\\Pi$ is a tuple $(P_a, arity_a, rules, T)$ where $P_a$ is a set of invented (auxiliary) intensional\npredicates, $rules$ - a map of predicate $p$ to a pair of rule templates $(\\tau_p^1, \\tau_p^2)$.\n\nNote that in cases where an intensional predicate $p$ is fully expressed in just one clause, rule template $\\tau_p^2$\nshould be $null$ (more on this later).\n\nRule template $\\tau$ is a tuple $(v, int)$, which describes the range of clauses that can be generated ($v$ - a number\nof existentially quantified variables allowed in the clause, $int \\in \\{0, 1\\}$ - whether intensional predicates are\nallowed).\n\nProgram template is actually a hyperparameter, since it needs to be given in advance and is problem specific. It is\npossible to use iterative deepening (as per $\\partial$ILP paper), but this increases the amount of computation\nmassively. Iterative deepening is currently not implemented in Lernd.","c6f951d8":"This notebook explains how to use **Lernd** - my implementation of $\\partial$ILP framework.\n\nI will not go into too many details of this implementation here. If interested, I suggest looking at the source code and,\nespecially, unit tests where I used examples straight from the original $\\partial$ILP paper $-$\n[Learning Explanatory Rules from Noisy Data](https:\/\/arxiv.org\/abs\/1711.04574).\n\nPrior to reading this you should be familiar with Inductive Logic Programming (ILP), which is succinctly explained in\nthe original $\\partial$ILP paper.","718ba946":"Background axioms (ground atoms), positive and negative examples are also part of the ILP problem definition.\n\nDefine background axioms - $zero(0)$ and $succ$ examples, as well as positive examples:"}}