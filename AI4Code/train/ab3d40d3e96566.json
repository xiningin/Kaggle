{"cell_type":{"157e78a9":"code","09f919f5":"code","bfb60df0":"code","cb44e7ef":"code","ff3afb3a":"code","fe7cdb5e":"code","a5f4e9c4":"code","2446c15b":"code","21c1afd1":"code","df4f412a":"code","e68be954":"code","841bdecf":"code","0add35fb":"code","db537c8b":"code","d54e4807":"code","eb675c84":"code","93474f30":"code","d12f5401":"code","de7b2b47":"code","1494816d":"code","33cfac81":"code","1874aba0":"code","9eac36bc":"code","44327206":"code","73e1b9c2":"code","536b787d":"code","134b1102":"code","4a5de433":"markdown","a253598a":"markdown","97585902":"markdown","e9358b04":"markdown","d8254e96":"markdown","f2d56993":"markdown","6779f167":"markdown","c9cec999":"markdown","7775434c":"markdown","35277c24":"markdown","2127f2d9":"markdown","816a5742":"markdown","dcdded68":"markdown","c1825015":"markdown","7bfaa81a":"markdown"},"source":{"157e78a9":"import numpy as np\nimport pandas as pd \nimport cv2\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# to unzip\nimport zipfile\n\n# Import PyTorch\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torchvision\nimport torch.optim as optim","09f919f5":"# ref: https:\/\/stackoverflow.com\/questions\/3451111\/unzipping-files-in-python\/3451150\ndef unzip(path):\n    with zipfile.ZipFile(path,\"r\") as z:\n        z.extractall('.')","bfb60df0":"# unzip train folder\ntrain_zip_path = '..\/input\/train.zip'\nunzip(train_zip_path)","cb44e7ef":"test_zip_path = '..\/input\/test.zip'\nunzip(test_zip_path)","ff3afb3a":"train_df = pd.read_csv('..\/input\/train.csv')\ntrain_df.head()","fe7cdb5e":"def draw_pie_chart(labels, sizes, explode=None):        \n    fig, ax = plt.subplots()\n    ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n    plt.show()    ","a5f4e9c4":"number_of_images_contains_cactus = train_df.has_cactus.value_counts().loc[1]\nnumber_of_images_does_not_contain_cactus = train_df.has_cactus.value_counts().loc[0]\n\nprint(number_of_images_contains_cactus)\nprint(number_of_images_does_not_contain_cactus)\n\ndraw_pie_chart([\"has_cactus\", \"no_cactus\"], [number_of_images_contains_cactus, number_of_images_does_not_contain_cactus], (0, 0.1))","2446c15b":"number_of_training_images = len(os.listdir('\/kaggle\/working\/train'))\nnumber_of_test_images = len(os.listdir('\/kaggle\/working\/test'))\n\nprint(f\"Total Train Images: {number_of_training_images}\")\nprint(f\"Total Test Images: {number_of_test_images}\")\n\ndraw_pie_chart([\"Total Training Images\", \"Total Test Images\"], [number_of_training_images, number_of_test_images], (0, 0.1))","21c1afd1":"class Dataset(Dataset):\n    def __init__(self, dataframe, data_dir, transform=None):\n        super().__init__()\n        self.dataframe = dataframe\n        self.data_dir = data_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, index):\n        image_name, label = self.dataframe.iloc[index]\n        image_path = os.path.join(self.data_dir, image_name)\n        image = cv2.imread(image_path)\n        \n        if self.transform != None:\n            image = self.transform(image)\n        \n        return image, label            ","df4f412a":"transforms_train_data = transforms.Compose([transforms.ToPILImage(),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransforms_train_data","e68be954":"train_data = Dataset(train_df, '\/kaggle\/working\/train', transforms_train_data)","841bdecf":"batch_size = 64\n\nvalidation_size = int(np.floor(0.2*number_of_training_images))\n\nindices = list(range(number_of_training_images))\nnp.random.shuffle(indices)\n\ntrain_indices, validation_indices = indices[validation_size:], indices[:validation_size]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalidation_sampler = SubsetRandomSampler(validation_indices)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nvalidation_loader = DataLoader(train_data, batch_size=batch_size, sampler=validation_sampler)","0add35fb":"sample_submission_path = \"..\/input\/sample_submission.csv\"\nsample_submission_df = pd.read_csv(sample_submission_path)\nsample_submission_df.head()","db537c8b":"transform_test_data = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransform_test_data","d54e4807":"test_data = Dataset(sample_submission_df, '\/kaggle\/working\/test', transform_test_data)\n\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","eb675c84":"classes  = ['Cactus', 'No Cactus']","93474f30":"def show_image(image):\n    '''Helper function to un-normalize and display an image'''\n    # unnormalize\n    image = image \/ 2 + 0.5\n    # convert from Tensor image and display\n    plt.imshow(np.transpose(image, (1, 2, 0)))","d12f5401":"data_iter = iter(train_loader)\nimages, labels = data_iter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\n# display 20 images\nfor idx in np.arange(10):\n    ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n    show_image(images[idx])\n    print(images[idx].shape)\n    ax.set_title(classes[labels[idx]])","de7b2b47":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Convolutional Layer (sees 32x32x3 image tensor | outputs 16x16x16 image tensor) \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 16x16x16 image tensor | outputs 8x8x32 image tensor)  \n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 8x8x32 image tensor | outputs 4x4x64 image tensor)  \n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 4x4x64 image tensor | outputs 2x2x128 image tensor)  \n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)        \n        \n        # batch normalization\n        self.bn1 = nn.BatchNorm2d(16)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.bn4 = nn.BatchNorm2d(128)        \n        \n        # MaxPooling Layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # fully connected layers\n        self.fc1 = nn.Linear(2*2*128, 512)        \n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 2)\n        \n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, x):        \n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool(x)\n        \n        x = x.view(-1, 2*2*128)\n        x = self.dropout(x)\n        \n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        \n        x = F.relu(self.fc2(x))                        \n        x = self.dropout(x)\n        \n        x = F.relu(self.fc3(x))\n        \n        return x","1494816d":"class Model:\n    def __init__(self, model, criterion, optimizer, train_on_gpu, train_loader, validation_loader):\n        self.model = model        \n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.train_on_gpu = train_on_gpu                        \n        self.train_loader = train_loader\n        self.validation_loader = validation_loader\n        self.train_losses = []\n        self.validation_losses = []        \n        if self.train_on_gpu:\n            self.model.cuda()\n            \n    def fit(self, epochs=30, show_every=1):\n        self.train_losses = []\n        self.validation_losses = []\n        \n        minimum_validation_loss = np.inf        \n        for epoch in range(epochs):                               \n            train_loss = self.train()\n            self.train_losses.append(train_loss)\n                        \n            validation_loss = self.validate()\n            self.validation_losses.append(validation_loss)   \n            \n            if epoch%show_every == 0:\n                self.print_loss(epoch, train_loss, validation_loss)\n\n            if validation_loss < minimum_validation_loss: \n                self.save_model(minimum_validation_loss, validation_loss)\n                minimum_validation_loss = validation_loss        \n    \n    def train(self):\n        train_loss = 0.0\n\n        self.model.train()\n        for data, target in self.train_loader:\n            if self.train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            self.optimizer.zero_grad()\n\n            output = self.model(data)\n\n            loss = self.criterion(output, target)\n\n            loss.backward()\n\n            self.optimizer.step()\n\n            train_loss += loss.item()*data.size(0)       \n\n\n        train_loss = train_loss\/len(self.train_loader.sampler)\n        return train_loss\n        \n    \n    def validate(self):                \n        validation_loss = 0.0\n        \n        self.model.eval()\n        \n        for data, target in self.validation_loader:\n            if self.train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            output = self.model(data)\n\n            loss = self.criterion(output, target)\n\n            validation_loss += loss.item()*data.size(0)\n            \n        validation_loss = validation_loss\/len(self.validation_loader.sampler)\n        return validation_loss\n    \n    def print_loss(self, epoch, train_loss, validation_loss):        \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1, train_loss, validation_loss))        \n    \n    def save_model(self, minimum_validation_loss, validation_loss):\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(minimum_validation_loss, validation_loss))            \n        torch.save(model.state_dict(), 'best_model.pt')        \n    \n    def load_best_model(self):\n        self.model.load_state_dict(torch.load('best_model.pt'))\n    \n    def predict(self, test_loader):\n        self.load_best_model()        \n        self.model.eval()\n\n        predictions = []\n\n        for data, target in test_loader:\n            if self.train_on_gpu:\n                    data, target = data.cuda(), target.cuda()\n\n            output = self.model(data)\n\n            prediction = output[:,1].detach().cpu().numpy()\n            for pred in prediction:\n                predictions.append(pred)\n                \n        return predictions\n    \n    def show_loss_graph(self):\n        plt.style.use('seaborn')\n        plt.plot(self.validation_losses, label='Validation loss')\n        plt.plot(self.train_losses, label='Train loss')\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.show()        ","33cfac81":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","1874aba0":"model = CNN()\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ncnn_model = Model(model, criterion, optimizer, train_on_gpu, train_loader, validation_loader)","9eac36bc":"cnn_model.fit(50)","44327206":"cnn_model.show_loss_graph()","73e1b9c2":"predictions = cnn_model.predict(test_loader)","536b787d":"sample_submission_df[\"has_cactus\"] = predictions\nsample_submission_df[\"has_cactus\"] = sample_submission_df[\"has_cactus\"].apply(lambda x: 1 if x > 0.75 else 0)\nsample_submission_df.to_csv(\"submission.csv\", index=False)","134b1102":"import shutil\n\n\nshutil.rmtree('\/kaggle\/working\/train')\nshutil.rmtree('\/kaggle\/working\/test')","4a5de433":"## Let's see some images","a253598a":"## Unzipping train and test image dataset","97585902":"### Removing the unzipped Train and Test image folder","e9358b04":"## Method for drawing pie chart","d8254e96":"## Make Predictions on Test Set","f2d56993":"## Number of images for each classes in train set","6779f167":"## Training The CNN Model","c9cec999":"## Preparing Test Data","7775434c":"## Number images in train and test image folder","35277c24":"## References - \n1 - https:\/\/www.kaggle.com\/abhinand05\/in-depth-guide-to-convolutional-neural-networks\n\n2 - https:\/\/www.kaggle.com\/ateplyuk\/pytorch-efficientnet","2127f2d9":"## Define The Network","816a5742":"## Preparing train and validation data","dcdded68":"## Loading csv file for train images","c1825015":"## Import Libraries","7bfaa81a":"## Create submission file"}}