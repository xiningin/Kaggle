{"cell_type":{"d76c0b02":"code","a04d69ee":"code","eaca7b77":"code","d74e7eed":"code","3df40be4":"code","c869727e":"code","6b545ea6":"code","a8c79492":"code","b0c1e2a0":"code","e99017a3":"code","d406add7":"code","40d24d3b":"code","1fe2b783":"code","bef967a7":"code","3b1c719a":"code","5ad5fabb":"code","58debb64":"code","825ab433":"code","597b64d7":"code","3fea224a":"code","72fc68a4":"code","efb325eb":"code","ca545c6c":"code","6fa915a3":"code","61f8f1eb":"code","4c5000cb":"code","2e8ec181":"code","9f64dbe8":"code","e2516c2c":"code","558f6d66":"code","edea9b4f":"code","39ba2bfc":"code","9d0727db":"code","7e029821":"code","e59dec36":"code","f2e0f79a":"code","51799999":"code","13cf86a1":"code","0598e767":"code","7f908d64":"code","23537554":"markdown","48b61616":"markdown","dde1f942":"markdown","3946ac1b":"markdown","831e13d9":"markdown","925753df":"markdown","322f1f58":"markdown","a1790847":"markdown","8620502d":"markdown","cf46ac42":"markdown","a0ef5e77":"markdown","51d15dce":"markdown"},"source":{"d76c0b02":"import sys\nfrom os.path import join\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom numpy import sqrt\nimport itertools\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n\nfrom fbprophet import Prophet\nfrom fbprophet.diagnostics import performance_metrics, cross_validation\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a04d69ee":"# Load data\n\nf = open('\/kaggle\/input\/weather-archive-jena\/jena_climate_2009_2016.csv')\ndata = f.read()\nf.close()\nlines = data.split('\\n')\nheader = lines[0].split(',')\nlines = lines[1:]\nprint(len(lines))\nfor i,j in enumerate(header):\n    print(i,j)","eaca7b77":"# Convert lines list into Numpy array float_data - without the date\n\nfloat_data = np.zeros((len(lines), len(header) - 1))\nfor i, line in enumerate(lines):\n    values = [float(x) for x in line.split(',')[1:]]\n    float_data[i, :] = values\n              \nprint(float_data.shape)","d74e7eed":"temp = float_data[:, 1] \nplt.plot(range(len(temp)), temp)","3df40be4":"plt.plot(range(1000), temp[1000:2000])","c869727e":"# Normalize data\n\nprint(float_data[0])\n\nmean = float_data.mean(axis=0)\nfloat_data -= mean\nstd = float_data.std(axis=0)\nfloat_data \/= std\n\nprint(float_data[0])","6b545ea6":"temp = float_data[:, 1] ","a8c79492":"plt.plot(range(1000), temp[1000:2000])","b0c1e2a0":"prev_val = temp[0]\nsum_mae = 0\nsse = 0\nfor n in range(0, len(temp)-1):\n    err = temp[n] - prev_val\n    sq_err = err ** 2\n    sse = sse + sq_err\n    prev_val = temp[n]\n    sum_mae = sum_mae + np.abs(err)\n    \nmse = sse \/ n\nrmse = np.sqrt(mse)\nmae = sum_mae \/ n\n\nprint('RMSE =',round(rmse,5))\nprint('MAE =',round(mae,5))\nprint('Celsius MAE ', round(mae * std[1],2))\n","e99017a3":"# Naive model prediction on a subset\n\nUlimPred = 200\nLlimPred = 100\n\npredTemp = []\n\nfor n in range(LlimPred, UlimPred):\n    predTemp.append(temp[n-1])\n    \npredTemp = np.array(predTemp)  \npredTemp.shape\n","d406add7":"# Superimposed: model prediction (blue) vs reality (red)\n\nplt.rcParams[\"figure.figsize\"] = [16,9]\n\n# Chart Test\nUlimReal = 200\nLlimReal = 100\nSampleSizeReal = UlimReal - LlimReal\nplt.plot(range(SampleSizeReal), temp[LlimReal:UlimReal], 'r', label=\"Actual\")\n\n# Chart Predicted \nUlimPred = UlimReal - LlimReal\nLlimPred = 0\nSampleSizePred = UlimPred - LlimPred\nplt.legend('Actual', 'Predicted')\nplt.plot(range(SampleSizePred), predTemp[LlimPred:UlimPred], 'b', label=\"Predicted\")\nplt.legend(loc=\"upper left\")\n\nplt.title('Naive model RMSE = 0.03')\nplt.xlabel('Time')\nplt.ylabel('Temp normalized')\n\nplt.show()\n","40d24d3b":"date_rng = pd.date_range(start='1\/1\/2009', end='1\/1\/2017', freq='10T')\ndate_rng[0:420551]","1fe2b783":"temp4Prophet = pd.DataFrame(temp)\ntemp4Prophet.columns=['y']\ntemp4Prophet['ds'] = date_rng[0:420551]\ntemp4Prophet = temp4Prophet[['ds','y']]\ntemp4Prophet","bef967a7":"plt.plot(temp4Prophet['y'])","3b1c719a":"print(temp4Prophet.shape)\ntemp4Prophet = temp4Prophet.iloc[::6, :]\ntemp4Prophet.shape","5ad5fabb":"plt.plot(temp4Prophet['y'])\n","58debb64":"ds4Naive = pd.DataFrame(temp4Prophet['y'])\nds4Naive.reset_index(inplace=True)\nds4Naive.drop('index', axis=1, inplace=True)\nds4Naive","825ab433":"# Baseline naive model on the smaller dataset\n\nprev_val = ds4Naive.iloc[0]['y']\nsum_mae = 0\nsse = 0\n\nfor n in range(0, len(ds4Naive)-1):\n    err = ds4Naive.iloc[n]['y'] - prev_val\n    sq_err = err ** 2\n    sse = sse + sq_err\n    prev_val = ds4Naive.iloc[n]['y']\n    sum_mae = sum_mae + np.abs(err)\n    \nmse = sse \/ n\nrmse = np.sqrt(mse)\nmae = sum_mae \/ n\n\nprint('RMSE =',round(rmse,5))\nprint('MAE =',round(mae,5))\nprint('Celsius MAE ', round(mae * std[1],2))","597b64d7":"#Split into train = 300k\/6 and test = 420551\/6 - 300k\/6\n\ntrainProphet = temp4Prophet.iloc[0:50000]\nprint(trainProphet.shape)\ntrainProphet.head()","3fea224a":"testProphet = temp4Prophet.iloc[50001:]\nprint(testProphet.shape)\ntestProphet.head()","72fc68a4":"%%time\n\n# Train \/ Fit\n\n# prophet REQUIRES a pandas df at the below config ... date column named as DS and the value column as Y\n\nmodel = Prophet(changepoint_prior_scale=0.001,\n               seasonality_prior_scale = 0.01)  \n\n#model = Prophet(seasonality_mode='multiplicative', changepoint_prior_scale=0.5)  \n#model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, seasonality_mode='multiplicative')  \nmodel.fit(trainProphet) # fit the model with the dataframe\nprint('Prophet is trained')","efb325eb":"%%time\n\n# Forecast \/ Predict\n\nfuture = model.make_future_dataframe(periods = testProphet.shape[0], freq = '1H')  \nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]","ca545c6c":"dataList = list(testProphet.y.values)\nprint(len(dataList))\nprint(len(forecast['yhat'][50000:]))\n\nrmse = sqrt(mean_squared_error(dataList,forecast['yhat'][50000:]))\nprint('Prophet RMSE: %.3f' % rmse)\n\nmae = mean_absolute_error(dataList,forecast['yhat'][50000:])\nprint('Prophet MAE: %.3f' % mae)","6fa915a3":"FigFor = model.plot(forecast)\n","61f8f1eb":"figComp = model.plot_components(forecast)\n","4c5000cb":"plt.style.use('seaborn-poster')\nplt.figure()\nplt.plot(dataList[0:20000], label='Original')\nplt.plot(forecast['yhat'][50000:70000].values, ls='--', label=\"Predicted\")\nplt.legend(loc='best')\nplt.title('FB Prophet univariate RMSE = 0.7')\nplt.show()","2e8ec181":"plt.style.use('seaborn-poster')\nplt.figure()\nplt.plot(dataList[0:500], label='Original')\nplt.plot(forecast['yhat'][50000:50500].values, ls='--', label=\"Predicted\")\nplt.legend(loc='best')\nplt.title('FB Prophet model - univariate')\nplt.show()","9f64dbe8":"print(float_data.shape)\nfloat_dataNoTemp = np.delete(float_data, 1, axis=1)\nNoTemp = pd.DataFrame(float_dataNoTemp)\nprint(NoTemp.shape)\nNoTemp.head()","e2516c2c":"temp4Prophet = pd.DataFrame(temp)\ntemp4Prophet.columns=['y']\ntemp4Prophet['ds'] = date_rng[0:420551]\ntemp4Prophet = temp4Prophet[['ds','y']]\nprint(temp4Prophet.shape)\ntemp4Prophet.head()","558f6d66":"MultiVar4Prophet = pd.concat([temp4Prophet, NoTemp], axis=1)\nMultiVar4Prophet.columns = ['ds', 'y', 'v0','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11', 'v12']\nprint(MultiVar4Prophet.shape)\nMultiVar4Prophet","edea9b4f":"# Reduce dataset by a factor of 6 - one row per hour instead of every 10 minutes\n\nprint(MultiVar4Prophet.shape)\nMultiVar4Prophet = MultiVar4Prophet.iloc[::6, :]\nMultiVar4Prophet.shape","39ba2bfc":"#Split into train = 300k\/6 and test = 420551\/6 - 300k\/6\n\ntrainProphet = MultiVar4Prophet.iloc[0:50000]\nprint(trainProphet.shape)\ntrainProphet.head()","9d0727db":"testProphet = MultiVar4Prophet.iloc[50001:]\ntestProphet.reset_index(inplace=True)\ntestProphet.drop('index', axis = 1, inplace=True)\nprint(testProphet.shape)\ntestProphet.head()","7e029821":"%%time\n\n# Train\n\n# Adding the other features \/ cols = Multivariate\n\n\nmodel = Prophet(changepoint_prior_scale=0.001,\n               seasonality_prior_scale = 0.01) \n\nmodel.add_regressor('v0')\nmodel.add_regressor('v1')\nmodel.add_regressor('v2')\nmodel.add_regressor('v3')\nmodel.add_regressor('v4')\nmodel.add_regressor('v5')\nmodel.add_regressor('v6')\nmodel.add_regressor('v7')\nmodel.add_regressor('v8')\nmodel.add_regressor('v9')\nmodel.add_regressor('v10')\nmodel.add_regressor('v11')\nmodel.add_regressor('v12')\n\nmodel.fit(trainProphet) # fit the model with the dataframe\nprint('Prophet is trained')","e59dec36":"testProphet.head()","f2e0f79a":"%%time\n\n# Forecast \/ Predict\n\nfuture = model.make_future_dataframe(periods = testProphet.shape[0], freq = '1H')  \nforecast = model.predict(testProphet)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]","51799999":"dataList = list(testProphet.y.values)\nprint(len(dataList))\nprint(len(forecast['yhat']))","13cf86a1":"rmse = sqrt(mean_squared_error(dataList,forecast['yhat']))\nprint('Prophet RMSE: %.3f' % rmse)\n\nmae = mean_absolute_error(dataList,forecast['yhat'])\nprint('Prophet MAE: %.3f' % mae)","0598e767":"plt.style.use('seaborn-poster')\nplt.figure()\nplt.plot(dataList, label='Original')\nplt.plot(forecast['yhat'].values, ls='--', label=\"Predicted\")\nplt.legend(loc='best')\nplt.title('FB Prophet multivariate RMSE = 0.004')\nplt.show()","7f908d64":"plt.style.use('seaborn-poster')\nplt.figure()\nplt.plot(dataList[0:500], label='Original')\nplt.plot(forecast['yhat'][0:500].values, ls='--', label=\"Predicted\")\nplt.legend(loc='best')\nplt.title('FB Prophet model - multivariate')\nplt.show()","23537554":"### Forecast \/ Predict","48b61616":"# FB Prophet multivariate\n\n* Add additional features \/ cols with add_regressor ... https:\/\/facebook.github.io\/prophet\/docs\/seasonality,_holiday_effects,_and_regressors.html#additional-regressors","dde1f942":"# Multivariate time series forecasting with FB Prophet\n\n* There are 420k rows X 14 cols of meteorological data : temp, humidity, pressure, wind, etc\n* Time steps - one row every 10 minutes\n* The task is to forecast the temperature\n* The metrics : MAE and RMSE\n\n### Naive model (temp at n+1 = temp at n) RMSE = 0.03\n... that translates to a mean error of **0.16 Celsius** ...*This one will be very difficult to beat!*\n\n### Univariate: we look ONLY at temp - disregarding all other info RMSE = 0.7\n### Multivariate: we consider ALL variables when predicting the temp RMSE = 0.004\n\n\n* Excellent explanation on multivariate time series forecasting at https:\/\/github.com\/walesdata\/2Dconv_pub\/blob\/master\/gefcom_multiconv.ipynb","3946ac1b":"# Sanity check - Baseline - Naive model ... temp at n+1 = temp at n","831e13d9":"### Train \/ Fit","925753df":"# Hyper params optimization results\n\n* seasonality_mode='additive' (default)\n\n\n* changepoint_prior_scale=0.5 , seasonality_prior_scale = 10 ... RMSE = 0.772\n* changepoint_prior_scale=0.1 , seasonality_prior_scale = 10 ... RMSE = 0.771\n* changepoint_prior_scale=0.05 , seasonality_prior_scale = 10 ... RMSE =  0.755 (default)\n* changepoint_prior_scale=0.01 , seasonality_prior_scale = 10 ... RMSE = 0.718\n* changepoint_prior_scale=0.001 , seasonality_prior_scale = 10 ... RMSE = 0.707\n\n\n* changepoint_prior_scale=0.001 , seasonality_prior_scale = 1 ... RMSE = 0.758\n* changepoint_prior_scale=0.001 , seasonality_prior_scale = 0.1 ... RMSE = 0.758\n* changepoint_prior_scale=0.001 , seasonality_prior_scale = 0.01 ... **RMSE = 0.705**\n","322f1f58":"# FB Prophet univariate\n\n### prophet REQUIRES a pandas df at the below config ...date column named as DS and the value column as Y\n","a1790847":"# Data","8620502d":"### Baseline naive model RMSE = 0.029 MAE = 0.019\n\n### This naive model will be *very difficult* to beat...","cf46ac42":"## Prophet hyper param optimization\n\n\n### Following got stuck after 2.5 hours...\n\n#Prophet hyper param optimization\n\n\nparam_grid = {  \n    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n}\n\n#Generate all combinations of parameters\nall_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\nrmses = []  # Store the RMSEs for each params here\n\n#Use cross validation to evaluate all parameters\nfor params in all_params:\n    m = Prophet(**params).fit(trainProphet)  # Fit model with given params\n    df_cv = cross_validation(m, horizon='30 days')\n    df_p = performance_metrics(df_cv, rolling_window=1)\n    rmses.append(df_p['rmse'].values[0])\n\n#Find the best parameters\ntuning_results = pd.DataFrame(all_params)\ntuning_results['rmse'] = rmses\nprint(tuning_results)\n\n\nhttps:\/\/facebook.github.io\/prophet\/docs\/diagnostics.html#hyperparameter-tuning\n\n**changepoint_prior_scale**: This is probably the most impactful parameter. It determines the flexibility of the trend, and in particular how much the trend changes at the trend changepoints. As described in this documentation, if it is too small, the trend will be underfit and variance that should have been modeled with trend changes will instead end up being handled with the noise term. If it is too large, the trend will overfit and in the most extreme case you can end up with the trend capturing yearly seasonality. **The default of 0.05** works for many time series, but this could be tuned; a range of [0.001, 0.5] would likely be about right. Parameters like this (regularization penalties; this is effectively a lasso penalty) are often tuned on a log scale.\n\n**seasonality_prior_scale**: This parameter controls the flexibility of the seasonality. Similarly, a large value allows the seasonality to fit large fluctuations, a small value shrinks the magnitude of the seasonality. **The default is 10**., which applies basically no regularization. That is because we very rarely see overfitting here (there\u2019s inherent regularization with the fact that it is being modeled with a truncated Fourier series, so it\u2019s essentially low-pass filtered). A reasonable range for tuning it would probably be [0.01, 10]; when set to 0.01 you should find that the magnitude of seasonality is forced to be very small. This likely also makes sense on a log scale, since it is effectively an L2 penalty like in ridge regression.\n\n**seasonality_mode**: Options are ['additive', 'multiplicative']. **Default is 'additive'**, but many business time series will have multiplicative seasonality. This is best identified just from looking at the time series and seeing if the magnitude of seasonal fluctuations grows with the magnitude of the time series (see the documentation here on multiplicative seasonality), but when that isn\u2019t possible, it could be tuned.\n\n","a0ef5e77":"### We reduce dataset for Prophet to one sample every 6 steps - one sample per hour instead of one every 10 minutes","51d15dce":"### Baseline for the reduced dataset RMSE = 0.121 ... MAE = 0.084"}}