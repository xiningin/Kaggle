{"cell_type":{"67d82ff8":"code","a9bb4d20":"code","1d0a526b":"code","fcf68ee3":"code","f3cee86a":"code","ecac40a4":"code","9d2847ae":"code","92009f2d":"code","6d371b78":"code","3386955f":"code","e93c162e":"code","1becd8c9":"code","9b7198d3":"code","d84c0345":"code","8d2c6665":"code","3d13e2ef":"code","67e8aefc":"code","363aaf47":"code","24647ea4":"code","ebc8f087":"code","61e5a9d2":"code","efa3eb47":"code","72d71ce5":"code","584f70a3":"code","2c5235ba":"code","226b7439":"code","f490ec2a":"code","0ac51011":"code","27592c6f":"code","cdd6f336":"code","4b1545de":"markdown","da265299":"markdown","8d17c65f":"markdown","6a70435f":"markdown","d44624a3":"markdown","ffaa40ba":"markdown","514223a9":"markdown","ae92baae":"markdown","ee4ebbe0":"markdown","8439694c":"markdown","4e8d2bc7":"markdown","bdf06732":"markdown","f77dac9e":"markdown","d886c005":"markdown","9386cfa1":"markdown","ee3108a5":"markdown","105dd579":"markdown","40f3fcb6":"markdown","ed1bb801":"markdown","85805811":"markdown","d8f0e7f6":"markdown","cfaa8ea9":"markdown","c058ffc8":"markdown","9feb832b":"markdown","f3c97637":"markdown","3d674da7":"markdown","a4e333c1":"markdown","343b2511":"markdown","d523197e":"markdown","c1f8c9b4":"markdown","a5e17f23":"markdown","44e301ed":"markdown"},"source":{"67d82ff8":"import tensorflow as tf\n\nfrom keras.applications import VGG16\nfrom keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, BatchNormalization, GaussianNoise\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.applications import ResNet50, DenseNet201, Xception\nfrom tensorflow.python.keras.applications.efficientnet import EfficientNetB6\n\nimport os\nimport json\nimport gc\n\nimport numpy as np\n\n# Local application\nimport miner_a_de_datos_redes_neuronales_utilidad as utils","a9bb4d20":"mult_batch = 32\n\nstrategy, GCS_PATH, AUTO = utils.inicializa_TPU(mult_batch)","1d0a526b":"crear_database = False\n\nif crear_database:\n    USER_ID = 'pablotorrijosarenas'\n    USER_SECRET = '3fd465198d2a3d54103987aaee9d5903'\n\n    utils.create_tfrec_dataset(USER_ID, USER_SECRET)\n\n    KAGGLE_CONFIG_DIR = os.path.join(os.path.expandvars('$HOME'), '.kaggle')\n    os.makedirs(KAGGLE_CONFIG_DIR, exist_ok = True)\n    with open(os.path.join(KAGGLE_CONFIG_DIR, 'kaggle.json'), 'w') as f:\n        json.dump({'username': USER_ID, 'key': USER_SECRET}, f)\n    !chmod 600 {KAGGLE_CONFIG_DIR}\/kaggle.json\n\n    utils.crear_json(USER_ID)\n\n    !kaggle datasets create -p .","fcf68ee3":"FOLDS = 3 #7\nTTA = 3 #10\nEPOCHS = 100\nIMG_DIM = (112, 112)\nCHANNELS = 1\nCLASSES = 10\nBATCH_SIZE = mult_batch * strategy.num_replicas_in_sync","f3cee86a":"indices_cv = utils.train_cv(FOLDS)","ecac40a4":"early_stopping = EarlyStopping(monitor=\"val_accuracy\",\n                               patience=5 #10,\n                               min_delta=0.0002,\n                               restore_best_weights=True)\n\nlr_callback = utils.crea_lrfn_callback(5, 0, .96, EPOCHS, strategy)","9d2847ae":"MASK_PARAMS = {\n    'PORCT_MASK' : 0.5,\n    'd1': 6,\n    'd2': 10,\n    'ratio' : 0.3\n}\n\nROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}","92009f2d":"nombre = \"convolutional_neural_network\"\n\ndef create_model():\n    activation = \"relu\"\n    activation_salida = \"softmax\"\n    with strategy.scope():\n        model = Sequential([GaussianNoise(0.1, input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS)),\n                            Conv2D(32, 3, activation=activation),\n                            Conv2D(32, 3, activation=activation),\n                            BatchNormalization(),\n                            MaxPooling2D(2),\n                            Dropout(0.2),\n                            Conv2D(64, 3, activation=activation),\n                            Conv2D(64, 3, activation=activation),\n                            BatchNormalization(),\n                            MaxPooling2D(2),\n                            Dropout(0.2),\n                            Conv2D(128, 3, activation=activation),\n                            Conv2D(128, 3, activation=activation),\n                            BatchNormalization(),\n                            MaxPooling2D(2),\n                            Dropout(0.2),\n                            Flatten(),\n                            Dense(512, activation=activation),\n                            Dense(128, activation=activation),\n                            Dropout(0.25),\n                            Dense(10, activation=activation_salida)])\n        utils.compile_model(model)\n    \n    return model","6d371b78":"for i in range(FOLDS):\n    print(\"\\n\",\"-\"*20,\"Fold\",i,\"-\"*20,\"\\n\")\n    train_dataset, size_train, val_dataset, size_val = utils.get_fold(i,\n                                                                      MASK_PARAMS, \n                                                                      ROT_PARAMS, \n                                                                      ((IMG_DIM[0], IMG_DIM[1])), \n                                                                      CHANNELS)\n    \n    if i == 0:\n        utils.muestra_imagenes(train_dataset,7,True)\n    \n    STEPS_PER_EPOCH = size_train \/\/ BATCH_SIZE\n\n    model = create_model()\n    \n    if i == 0:\n        model.summary()\n    \n    history = model.fit(train_dataset, \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        epochs=EPOCHS, \n                        validation_data=val_dataset,\n                        callbacks=[early_stopping,lr_callback])\n    \n    model.save(nombre + \"_model_\" + str(i) + \".h5\")\n    \n    utils.plot_history(history)\n    \n    # Liberamos memoria\n    del history\n    if i != (FOLDS-1):\n        del model\n    del train_dataset\n    del val_dataset\n    gc.collect()","3386955f":"MASK_PARAMS = {\n    'PORCT_MASK' : 0,\n    'd1': 0,\n    'd2': 0,\n    'ratio' : 0\n}\n\nROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}\n\ntest_dataset = utils.prepare_dataset(\"test\", MASK_PARAMS, ROT_PARAMS)\n\ntest_dataset = test_dataset.map(utils.reshape, num_parallel_calls = AUTO)\ntest_dataset = test_dataset.map(utils.augment, num_parallel_calls = AUTO)\n\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTO)","e93c162e":"predictions_CNN, predictions_list_CNN, probabilities_list_CNN = utils.predecir_ensemble(FOLDS, CLASSES, TTA, nombre, test_dataset, model)","1becd8c9":"utils.muestra_imagenes(test_dataset,7,False,predictions_CNN)","9b7198d3":"IMG_DIM = (112, 112)\nCHANNELS = 3\n\nMASK_PARAMS = {\n    'PORCT_MASK' : 0.5,\n    'd1': 6,\n    'd2': 10,\n    'ratio' : 0.3\n}\n\nROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}","d84c0345":"nombre = \"pretrained_neural_networkRN50\"\n\ndef create_model():\n    activation = \"relu\"\n    activation_salida = \"softmax\"\n    with strategy.scope():\n        pretrained_model = ResNet50(input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS),\n                                    include_top=False, \n                                    weights='imagenet')\n\n        model = Sequential([GaussianNoise(0.1, input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS)),\n                            pretrained_model,\n                            Flatten(),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(512, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(128, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(10, activation=activation_salida)])\n        utils.compile_model(model)\n    \n    return model","8d2c6665":"for i in range(FOLDS):\n    print(\"\\n\",\"-\"*20,\"Fold\",i,\"-\"*20,\"\\n\")\n    train_dataset, size_train, val_dataset, size_val = utils.get_fold(i,\n                                                                      MASK_PARAMS, \n                                                                      ROT_PARAMS, \n                                                                      ((IMG_DIM[0], IMG_DIM[1])), \n                                                                      CHANNELS)\n\n    STEPS_PER_EPOCH = size_train \/\/ BATCH_SIZE\n\n    model = create_model()\n    \n    if i == 0:\n        model.summary()\n        \n    history = model.fit(train_dataset, \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        epochs=EPOCHS, \n                        validation_data=val_dataset,\n                        callbacks=[early_stopping,lr_callback])\n    \n    model.save(nombre + \"_model_\" + str(i) + \".h5\")\n    \n    utils.plot_history(history)\n    \n    # Liberamos memoria\n    del history\n    if i != (FOLDS-1):\n        del model\n    del train_dataset\n    del val_dataset\n    gc.collect()","3d13e2ef":"TEST_MASK_PARAMS = {\n    'PORCT_MASK' : 0,\n    'd1': 0,\n    'd2': 0,\n    'ratio' : 0\n}\n\nTEST_ROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}\n\ntest_dataset = utils.prepare_dataset(\"test\", TEST_MASK_PARAMS, TEST_ROT_PARAMS)\n\ntest_dataset = test_dataset.map(utils.reshape, num_parallel_calls = AUTO)\ntest_dataset = test_dataset.map(utils.augment, num_parallel_calls = AUTO)\n\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTO)\n\n\npredictions_RN50, predictions_list_RN50, probabilities_list_RN50 = utils.predecir_ensemble(FOLDS, CLASSES, TTA, nombre, test_dataset, model)","67e8aefc":"IMG_DIM = (112, 112)\nCHANNELS = 3\n\nMASK_PARAMS = {\n    'PORCT_MASK' : 0.5,\n    'd1': 6,\n    'd2': 10,\n    'ratio' : 0.3\n}\n\nROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}","363aaf47":"nombre = \"pretrained_neural_networkXception\"\n\ndef create_model():\n    activation = \"relu\"\n    activation_salida = \"softmax\"\n    with strategy.scope():\n        pretrained_model = Xception(input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS),\n                                    include_top=False,\n                                    weights='imagenet')\n        \n        model = Sequential([GaussianNoise(0.1, input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS)),\n                            pretrained_model,\n                            Flatten(),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(512, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(128, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(10, activation=activation_salida)])\n        \n        utils.compile_model(model)\n    \n    return model","24647ea4":"for i in range(FOLDS):\n    print(\"\\n\",\"-\"*20,\"Fold\",i,\"-\"*20,\"\\n\")\n    train_dataset, size_train, val_dataset, size_val = utils.get_fold(i,\n                                                                      MASK_PARAMS, \n                                                                      ROT_PARAMS, \n                                                                      ((IMG_DIM[0], IMG_DIM[1])), \n                                                                      CHANNELS)\n\n    STEPS_PER_EPOCH = size_train \/\/ BATCH_SIZE\n\n    model = create_model()\n    \n    if i == 0:\n        model.summary()\n    \n    history = model.fit(train_dataset, \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        epochs=EPOCHS, \n                        validation_data=val_dataset,\n                        callbacks=[early_stopping,lr_callback])\n    \n    model.save(nombre + \"_model_\" + str(i) + \".h5\")\n    \n    utils.plot_history(history)\n    \n    # Liberamos memoria\n    del history\n    if i != (FOLDS-1):\n        del model\n    del train_dataset\n    del val_dataset\n    gc.collect()","ebc8f087":"MASK_PARAMS = {\n    'PORCT_MASK' : 0,\n    'd1': 0,\n    'd2': 0,\n    'ratio' : 0\n}\n\nTEST_ROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}\n\ntest_dataset = utils.prepare_dataset(\"test\", TEST_MASK_PARAMS, TEST_ROT_PARAMS)\n\ntest_dataset = test_dataset.map(utils.reshape, num_parallel_calls = AUTO)\ntest_dataset = test_dataset.map(utils.augment, num_parallel_calls = AUTO)\n\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTO)\n\n\npredictions_Xception, predictions_list_Xception, probabilities_list_Xception = utils.predecir_ensemble(FOLDS, CLASSES, TTA, nombre, test_dataset, model)","61e5a9d2":"IMG_DIM = (112, 112)\nCHANNELS = 3\n\nMASK_PARAMS = {\n    'PORCT_MASK' : 0.5,\n    'd1': 6,\n    'd2': 10,\n    'ratio' : 0.3\n}\n\nROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}","efa3eb47":"nombre = \"pretrained_neural_networkDN201\"\n\ndef create_model():\n    activation = \"relu\"\n    activation_salida = \"softmax\"\n    with strategy.scope():\n        pretrained_model = Xception(input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS),\n                                    include_top=False,\n                                    weights='imagenet')\n        \n        model = Sequential([GaussianNoise(0.1, input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS)),\n                            pretrained_model,\n                            Flatten(),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(512, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(128, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(10, activation=activation_salida)])\n        \n        utils.compile_model(model)\n    \n    return model","72d71ce5":"for i in range(FOLDS):\n    print(\"\\n\",\"-\"*20,\"Fold\",i,\"-\"*20,\"\\n\")\n    train_dataset, size_train, val_dataset, size_val = utils.get_fold(i,\n                                                                      MASK_PARAMS, \n                                                                      ROT_PARAMS, \n                                                                      ((IMG_DIM[0], IMG_DIM[1])), \n                                                                      CHANNELS)\n\n    STEPS_PER_EPOCH = size_train \/\/ BATCH_SIZE\n\n    model = create_model()\n    \n    if i == 0:\n        model.summary()\n    \n    history = model.fit(train_dataset, \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        epochs=EPOCHS, \n                        validation_data=val_dataset,\n                        callbacks=[early_stopping,lr_callback])\n    \n    model.save(nombre + \"_model_\" + str(i) + \".h5\")\n    \n    utils.plot_history(history)\n    \n    # Liberamos memoria\n    del history\n    if i != (FOLDS-1):\n        del model\n    del train_dataset\n    del val_dataset\n    gc.collect()","584f70a3":"MASK_PARAMS = {\n    'PORCT_MASK' : 0,\n    'd1': 0,\n    'd2': 0,\n    'ratio' : 0\n}\n\nTEST_ROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}\n\ntest_dataset = utils.prepare_dataset(\"test\", TEST_MASK_PARAMS, TEST_ROT_PARAMS)\n\ntest_dataset = test_dataset.map(utils.reshape, num_parallel_calls = AUTO)\ntest_dataset = test_dataset.map(utils.augment, num_parallel_calls = AUTO)\n\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTO)\n\n\npredictions_DN201, predictions_list_DN201, probabilities_list_DN201 = utils.predecir_ensemble(FOLDS, CLASSES, TTA, nombre, test_dataset, model)","2c5235ba":"IMG_DIM = (112, 112)\nCHANNELS = 3\n\nMASK_PARAMS = {\n    'PORCT_MASK' : 0.5,\n    'd1': 6,\n    'd2': 10,\n    'ratio' : 0.3\n}\n\nROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}","226b7439":"nombre = \"pretrained_neural_networkB6\"\n\ndef create_model():\n    activation = \"relu\"\n    activation_salida = \"softmax\"\n    with strategy.scope():\n        pretrained_model = EfficientNetB6(input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS),\n                                          include_top=False,\n                                          weights='imagenet')\n        \n        model = Sequential([GaussianNoise(0.1, input_shape=(IMG_DIM[0], IMG_DIM[1], CHANNELS)),\n                            pretrained_model,\n                            Flatten(),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(512, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(128, activation=activation),\n                            BatchNormalization(),\n                            Dropout(0.25),\n                            Dense(10, activation=activation_salida)])\n        \n        utils.compile_model(model)\n    \n    return model","f490ec2a":"for i in range(FOLDS):\n    print(\"\\n\",\"-\"*20,\"Fold\",i,\"-\"*20,\"\\n\")\n    train_dataset, size_train, val_dataset, size_val = utils.get_fold(i,\n                                                                      MASK_PARAMS, \n                                                                      ROT_PARAMS, \n                                                                      ((IMG_DIM[0], IMG_DIM[1])), \n                                                                      CHANNELS)\n\n    STEPS_PER_EPOCH = size_train \/\/ BATCH_SIZE\n\n    model = create_model()\n    \n    if i == 0:\n        model.summary()\n    \n    history = model.fit(train_dataset, \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        epochs=EPOCHS, \n                        validation_data=val_dataset,\n                        callbacks=[early_stopping,lr_callback])\n    \n    model.save(nombre + \"_model_\" + str(i) + \".h5\")\n    \n    utils.plot_history(history)\n    \n    # Liberamos memoria\n    del history\n    if i != (FOLDS-1):\n        del model\n    del train_dataset\n    del val_dataset\n    gc.collect()","0ac51011":"TEST_MASK_PARAMS = {\n    'PORCT_MASK' : 0,\n    'd1': 0,\n    'd2': 0,\n    'ratio' : 0\n}\n\nTEST_ROT_PARAMS = {\n    'PORCT_ROT' : 1,\n    'ROT_' : 10,\n    'SHR_' : 5,\n    'HZOOM_' : 10.0,\n    'WZOOM_' : 10.0,\n    'HSHIFT_' : 1.2,\n    'WSHIFT_' : 1.2,\n}\n\ntest_dataset = utils.prepare_dataset(\"test\", TEST_MASK_PARAMS, TEST_ROT_PARAMS)\n\ntest_dataset = test_dataset.map(utils.reshape, num_parallel_calls = AUTO)\ntest_dataset = test_dataset.map(utils.augment, num_parallel_calls = AUTO)\n\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTO)\n\n\npredictions_B6, predictions_list_B6, probabilities_list_B6 = utils.predecir_ensemble(FOLDS, CLASSES, TTA, nombre, test_dataset, model)","27592c6f":"PREDICTIONS_All = np.zeros(((5*FOLDS), 28000))\n\nfor i in range (FOLDS):\n    PREDICTIONS_All[i] = predictions_list_CNN[i]\nfor i in range (FOLDS):\n    PREDICTIONS_All[i+FOLDS] = predictions_list_RN50[i]\nfor i in range (FOLDS):\n    PREDICTIONS_All[i+(2*FOLDS)] = predictions_list_Xception[i]\nfor i in range (FOLDS):\n    PREDICTIONS_All[i+(3*FOLDS)] = predictions_list_DN201[i]\nfor i in range (FOLDS):\n    PREDICTIONS_All[i+(4*FOLDS)] = predictions_list_B6[i]\n\nPREDICTIONS_All = PREDICTIONS_All.astype(int)\npredictions_ensemble_total = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=PREDICTIONS_All)\nsubmission = utils.create_submission(predictions_ensemble_total)\nsubmission.to_csv(\"All*FOLDS_submission_ensemble.csv\")  ","cdd6f336":"PREDICTIONS = np.zeros((28000,CLASSES))\n\nfor i in range (FOLDS):\n    PREDICTIONS += probabilities_list_CNN[i]\n    PREDICTIONS += probabilities_list_RN50[i]\n    PREDICTIONS += probabilities_list_Xception[i]\n    PREDICTIONS += probabilities_list_DN201[i]\n    PREDICTIONS += probabilities_list_B6[i]\n\nprediction = np.argmax(PREDICTIONS, axis=-1)\nsubmission = utils.create_submission(prediction)\nsubmission.to_csv(\"PROBS_submission_ensemble.csv\")","4b1545de":"Podemos ver resultados pr\u00e1cticamente iguales que en los casos anteriores. Por \u00faltimo realizamos las predicciones:","da265299":"#\u00a01. Inicializaciones\n\n---\n\nEn primer lugar, vamos a importar las librer\u00edas que necesitaremos m\u00e1s adelante.","8d17c65f":"Ahora, vamos a llamar a la funci\u00f3n de `utils` que inicializa las carpetas de entrenamiento y validaci\u00f3n (5 en este caso) para la validaci\u00f3n cruzada estratificada.","6a70435f":"Por tanto, una vez definido el modelo vamos a pasar a ejecutar la validaci\u00f3n cruzada estratificada para entrenar as\u00ed 5 modelos. Para cada modelo, lo entrenaremos, lo guardaremos, mostaremos la gr\u00e1fica de la evoluci\u00f3n de sus m\u00e9tricas y posteriormente lo eliminaremos para liberar memoria. En esta primera iteraci\u00f3n de la primera red neuronal, adem\u00e1s, vamos a mostrar un ejemplo de las im\u00e1genes de entrenamiento. ","d44624a3":"Podemos ver, otra vez, resultados muy similares a los de los modelos anteriores. Por \u00faltimo, solo nos queda realizar las predicciones:","ffaa40ba":"# 4.4. Red Preentrenada: Dense Net 201\n\n---\n\nAhora vamos a probar a usar la red `DenseNet 201`. En este caso, esta red se caracteriza por que cada capa obtiene sus pesos de todas las anteriores, y los env\u00eda a todas las posteriores (de ah\u00ed su nombre). Adem\u00e1s, tambi\u00e9n seguiremos manteniendo el mismo *data augmentation*, y tampoco congelaremos los pesos de la red preentrenada. Adem\u00e1s, seguimos usando el mismo tama\u00f1o de entrada ya que tambi\u00e9n nos pide 3 canales, y con (112,112) seguimos obteniendo unos tiempos de ejecuci\u00f3n buenos.","514223a9":"Definimos el modelo, que es exactamente igual que el anterior pero cambiando el modelo preentrenado.","ae92baae":"# Ensemble final\n\n---\n\nPara terminar, vamos a intentar conseguir unos mejores *scores* mediante la realizaci\u00f3n de distintos ensembles utilizando varios modelos de redes convolucionales distintas. Vamos a intentar realizar los ensembles desde dos perpectivas distintas.\n\nEn primer lugar, comentar que descartamos hacer el ensemble por votaci\u00f3n directamente sobre los 5 ensembles generados por cada modelo, ya que realizamos pruebas y no daban tan buenos resultados como los otros ensembles que vamos a definir ahora.\n\nPor tanto, nuestra siguiente aproximaci\u00f3n fue hacer un ensemble por votaci\u00f3n, pero en lugar de sobre los 5 ensembles en los que ya se hab\u00eda votado en cada modelo, utilizando la salida del *Test Time Augmention* directamente, por lo que estamos realizando un ensemble por votaci\u00f3n de tama\u00f1o `5 (modelos distintos) x FOLDS`, que en este caso ser\u00e1 `5 x 7 = 35`. Este ser\u00e1 uno de los modelos que usaremos para el *Score Final*, habiendo obtenido un resultado en el *Public Leaderboard* de `0.99585`.","ee4ebbe0":"Por tanto, ahora creamos el modelo, el cual el mismo que en las dem\u00e1s redes neuronales preentrenadas que hemos realizado, pero cambiando el modelo preentrenado por `EfficientNetB6` en este caso.","8439694c":"Por tanto, podemos concluir que los ensembles son un buen m\u00e9todo para lograr buenos resultados. Adem\u00e1s, por todas las pruebas que hemos realizado (de las cuales no todas pueden aparecer en esta libreta, algunas se podr\u00e1n ver en versiones anteriores u observando las subidas de nuestro equipo en la competici\u00f3n), obtenemos las siguientes conclusiones:\n* Un ensemble funciona mejor que una \u00fanica red neuronal individual. Ninguno de los modelos de redes que hemos realizado individualmente, ya sean m\u00e1s o menos complejos, supera a cualquiera de los ensembles que hemos realizado desde el principio.\n* El uso de *Data Augmentation* ayuda ya que hace que nuestro modelo tenga que generalizar, y adem\u00e1s nos permite usar el *Test Time Augmention*, que tambi\u00e9n hemos comprobado como aumenta las puntuaciones obtenidas al reducir la variabilidad en las predicciones.\n* Parece que obtenemos mejores resultados cuanto m\u00e1s elementos tenga el ensemble, ya sea a\u00f1adiendo *folds*, modelos o cada predicci\u00f3n del *Test Time Augmention*.\n\n**Nota:** En el apartado de fichero se pueden ver algunos que no se han generado en la versi\u00f3n actual de esta libreta. Estos han sido pruebas (por ejemplo, realizar el ensemble eliminado alguno de los modelos de red neuronal, a ver c\u00f3mo cambia el *score*; o el ensemble de los 5 modelos que hemos mencionado en primer lugar (`All_submission_ensemble.csv`)), que al final se han descartado.\n\n**Nota 2:** Debido a los problemas que hemos tenido con *Kaggle*, esta versi\u00f3n de la libreta no cuenta con las salidas de las ejecuciones. Se puede ver unas ejecuciones y salidas bastante similares en la versi\u00f3n 16 de la misma, aunque por ejemplo los ensembles finales no son los definitivos en dicha versi\u00f3n. As\u00ed mismo, esperamos que los archivos de salida definitivos se puedan subir en alguna versi\u00f3n entre la 17 y la 21, ya que estamos teniendo un mont\u00f3n de problemas con los mismos.","4e8d2bc7":"# 4.5. Red Preentrenada: EfficientNet B6\n\n---\n\nLa \u00faltima red preentrenada que hemos utilizado es `EfficientNet B6`. Dentro de `EfficientNet`, hemos elegido esta ya que en los datos que proporcionan para `ImageNet`, utiliza casi la mitad de par\u00e1metros que `EfficientNet B7` y obtiene un resultado parecido que \u00e9sta y, a su vez, bastante mejor que `EfficientNet B5`, `EfficientNet B4` y dem\u00e1s versiones m\u00e1s simples.\n\nAs\u00ed, esta ser\u00e1 la red m\u00e1s compleja que entrenaremos, aunque esto no quiera decir que vaya a ser la mejor, sobre todo teniendo en cuenta que est\u00e1 dise\u00f1ada para las im\u00e1genes de `ImageNet` (mucho m\u00e1s complejas, con mayores tama\u00f1os, 1000 clases distintas, en RGB...). Pero a\u00fan as\u00ed, el usar arquitecturas bastante distintas en las redes nos puede ayudar a que en el *ensemble* final que vamos a realizar, obtengamos mejores puntuaciones que si us\u00e1semos solo un modelo de red (aunque fuese con m\u00e1s *epochs*).","bdf06732":"Tambi\u00e9n vamos a definir los *callbacks* que usaremos:\n* Por un lado `EarlyStopping`, el cual parar\u00e1 la ejecuci\u00f3n cuando el *accuracy* de validaci\u00f3n no se mejore en 10 *epochs* seguidas un m\u00ednimo de 0.0002, y adem\u00e1s restaurar\u00e1 al finalizar los pesos del modelo que consiga el mejor, por lo que no nos tenemos que preocupar especialmente por el n\u00famero de *epochs* si los par\u00e1metros de dicho *callbacks* est\u00e1n bien ajustados.\n* Y por otro lado, tenemos el *callback* que ajusta el *learning rate* en cada *epoch* usando `LearningRateScheduler`, el cual crearemos mediante la funci\u00f3n `crea_lrfn_callback` del fichero de utilidades. Esta funci\u00f3n est\u00e1 basada en la proporcionada en el *starter kernel* de la competici\u00f3n `Flower Classification with TPUs`, la cual se cre\u00f3 cuando se a\u00f1adieron las TPU's a `Kaggle`. Est\u00e1 especialmente pensada para realizar *fine tunning* sobre modelos preentrenados sin congelar capas, por lo que al principio cuenta con una rampa ascendente para modificar poco a poco cada vez m\u00e1s los pesos iniciales, y posteriormente volver a ir bajando otra vez. Su primer par\u00e1metro es el n\u00famero de *epochs* en los que asciende la curva, el segundo en los que se mantiene estable, y el tercero el factor de decaimiento.\n","f77dac9e":"En este modelo, en primer lugar tenemos una capa de ruido gaussiano con desviaci\u00f3n est\u00e1ndar de 0.1 (al igual que en la red anterior), seguida de la red `ResNet50` entera, y a la salida de \u00e9sta concatenaremos la capa Flatten, y una repetici\u00f3n en tres ocasiones del patr\u00f3n Batch Normalization, Dropout de un 25% y capa totalmente conectada (\u00e9sta ir\u00e1 de las 512 neuronas de la primera repetici\u00f3n, a 128 en la segunda y a 10 en la capa de salida para as\u00ed ir reduciendo poco a poco el n\u00famero de neuronas hasta la salida).","d886c005":"Por tanto, vamos a realizar las predicciones. En primer lugar crearemos 8 ficheros .csv: Uno con las predicciones de cada uno de los 7 modelos de esta red, y aparte otro con las predicciones de un ensemble formado por dichos modelos usando votaci\u00f3n por mayor\u00eda.","9386cfa1":"Podemos ver c\u00f3mo se nota el ruido en las im\u00e1genes que no existe en las de entrenamiento, adem\u00e1s de que no hay *GridMask*, y tambi\u00e9n podemos apreciar en el borde de algunas im\u00e1genes los efectos de la rotaci\u00f3n, el zoom, el *shear* y el *shift*, cuando \u00e9stos son m\u00e1s pronunciados.\n\n---\n\n## 4.2. Red Preentrenada: ResNet 50\n\n---\n\nAhora, vamos a pasar a usar Redes Neuronal Preentrenadas. Vamos a empezar con `ResNet 50`, la cual se caracteriza por que los pesos de una capa se env\u00edan tanto a la siguiente capa como a la posterior, permitiendo as\u00ed crear redes neuronales m\u00e1s profundas ya que al entrenar se van diluyendo menos los pesos conforme pasamos de una capa a otra.\n\nComo esta red no es excesivamente grande, vamos a dejar el tama\u00f1o de entrada a (112,112). Lo que s\u00ed que tenemos que hacer es cambiar a tres canales, ya que si no no podr\u00edamos usar esta red preentrenada.\n\nNo congelaremos las capas de la parte preentrenada ya que haci\u00e9ndolo logramos tasas de acierto bastante bajas en comparaci\u00f3n, adem\u00e1s de que el tiempo que tarda si no lo hacemos es asumible en esta y en las siguientes redes preentrenadas gracias al uso de la TPU. Por tanto, vamos a entrenar el modelo entero sobre los pesos inicializados de `imagenet`, intentando no modificarlos demasiado al principio mediante el uso del *callback* para modificar el *learning rate* que mencionamos anteriormente.\n\nEl *data augmentation* que vamos a usar en este modelo es el mismo que en el anterior.","ee3108a5":"Y, por \u00faltimo, vamos a realizar un ensemble sumando directamente las probabilidades generadas en cada *Test Time Augmention* para cada iteraci\u00f3n de cada modelo de red neuronal. Por tanto, ser\u00e1 un ensemble de `5 (modelos distintos) x FOLDS x TTA`, que en nuestro caso ser\u00e1 `5 x 7 x 10 = 350` elementos. Este ser\u00e1 el otro modelo que usaremos para el *Score Final*, habiendo obtenido nuestro mejor resultado en el *Public Leaderboard* (`0.99642`).","105dd579":"Y una vez definido, lo entrenamos con la validaci\u00f3n cruzada:","40f3fcb6":"En este caso, volvemos a utilizar otra vez el mismo modelo que en las dos redes anteriores, cambiando la red preentrenada por `Xception`.","ed1bb801":"# 2. Crear database\n\n---\n\nEl primero de los dos mayores problemas que nos encontramos al intentar usar la TPU es que, debido a su r\u00e1pida velocidad de computaci\u00f3n, sufrir\u00eda un cuello de botella al acceder a los datos. Para solventarlo, los lee directamente del `GCS (Google Cloud Storage)`, normalmente en formato `TFRecords`.\n\nPor ello, hemos desarrollado esta funci\u00f3n, complementada en el fichero de utiliades para aligerar esta libreta, que lo que hace es crear autom\u00e1ticamente un nuevo `Dataset` convirtiendo las im\u00e1genes proporcionadas en la competici\u00f3n `recognition-2020` a archivos `TFRecords` que la TPU pueda leer f\u00e1cilmente, y creando una nueva competici\u00f3n llamada `recognition-2020-tfrec`.\n\n**Nota:** Se deja la variable `crear_database` a `False` para no tener que crear la base de datos en cada iteraci\u00f3n.","85805811":"# 3. Inicializaci\u00f3n de los datos y otras variables\n\n---\n\nAhora, vamos a pasar a inicializar los datos y otras variables que utilizaremos posteriormente.\n\nCabe destacar que vamos a realizar una validaci\u00f3n cruzada estratificada con 5 *folds*, para posteriormente hacer un ensemble con los 5 modelos generados para cada arquitectura de red neuronal.\n\nTambi\u00e9n, que usaremos *Test Time Augmention*, el cual consiste b\u00e1sicamente en predecir `n` veces (en este caso hemos elegido 10) cada imagen de test usando `Data Augmentation`, para despu\u00e9s sumar todas las probabilidades de predicciones y quedarnos con la mayor.\n\nPor otro lado, por defecto las im\u00e1genes tienen un tama\u00f1o de 28x28 y solo un canal, pero como incrementar el tama\u00f1o de las im\u00e1genes nos va a proporcionar un mayor rendimiento en la red y nos permitir\u00e1 hacer redes m\u00e1s complejas (a costa de mayor tiempo de ejecuci\u00f3n), vamos a definir inicialmente un tama\u00f1o de 4x(28,28) = (112,112) aunque manteniendo 1 canal (escala de grises).\n\nPor \u00faltimo, destacar tambi\u00e9n que se ha escogido un n\u00famero muy alto de *epochs* (100) ya que es simplemente un n\u00famero m\u00e1ximo, al que no se llegar\u00e1 porque implementaremos el *callback* `EarlyStopping` para que detenga la ejecuci\u00f3n cuando sea neceario.","d8f0e7f6":"Una vez definido el aumento de datos que vamos a utilizar, vamos a definir nuestro primer modelo. En este caso, ser\u00e1 una red neuronal convolucional que contar\u00e1 con una capa de ruido gaussiano con desviaci\u00f3n est\u00e1ndar de 0.1 (para a\u00f1adir m\u00e1s ruido a las im\u00e1genes, evitando el sobreajuste e intentando que se parezcan un poco m\u00e1s a las del conjunto de test), seguida de 3 repeticiones del siguiente patr\u00f3n:\n- 2 x Capa Convolucional: Su n\u00famero de filtros empezar\u00e1 en 32, e ir\u00e1 aumentando al doble en cada repetici\u00f3n; con ventanas de convoluci\u00f3n de tama\u00f1o 3x3, y funci\u00f3n de activaci\u00f3n `relu`).\n- Batch Normalization: Para normalizar las salidas.\n- Max Pooling: Dividir\u00e1 por 2 el tama\u00f1o de la capa anterior mediante la aplicaci\u00f3n de la funci\u00f3n m\u00e1ximo con una ventana de 2x2.\n- Dropout: Fijado a 0.2 para evitar en cierta medida que se produzca sobreajuste a los datos de entrenamiento.\n\nDespu\u00e9s, contar\u00e1 con una capa Flatten para aplanar la salida para trabajar con las capas densamente conectadas, y esttas capas ser\u00e1n una de 512 neuronas, seguida de una de 128 neuronas (ambas con funci\u00f3n de activaci\u00f3n `relu`), una capa de Dropout con un ratio en este caso de 0.25 para evitar sobreajuste, y por \u00faltimo la capa de salida de 10 neuronas con funci\u00f3n de activaci\u00f3n `softmax`.","cfaa8ea9":"Y una vez definido, pasamos a entrenarlo:","c058ffc8":"Podemos ver c\u00f3mo se obtienen unos buenos resultados en el conjunto de validaci\u00f3n, con un *accuracy* en dicho conjunto que es superior al del conjunto de entrenamiento sobre todo en las primeras *epochs* (gracias en gran parte al *data augmentation*). Este *accuracy* alcanzado en el conjunto de validaci\u00f3n var\u00eda para cada *fold*, ya que cada ejecuci\u00f3n de la red neuronal da resultados distintos, y adem\u00e1s cada carpeta puede tener m\u00e1s o menos im\u00e1genes dif\u00edciles en el conjunto de validaci\u00f3n que puedan hacer que dicha tasa de acierto se resienta.\n\nTambi\u00e9n podemos ver c\u00f3mo llega un punto en el que la red empieza a sobreajustar al conjunto de entrenamiento, y normalmente ah\u00ed ya el *score* de la validaci\u00f3n empieza a bajar un poco, por lo que mediante el *callback* `EarlyStopping` se para la ejecuci\u00f3n al no seguir mejorando diahaa puntuaci\u00f3n en 10 iteraciones consecutivas.\n\n---\n\nAhora, vamos realizar nuestras predicciones sobre los datos de test. Para ello, primero vamos a definir los par\u00e1metros de *data augmentation* para el test y a aplicarlos sobre la base de datos de test. Estos par\u00e1metros ser\u00e1n los mismos que en el train, pero sin el GridMask. As\u00ed, con las peque\u00f1as modificaciones en las im\u00e1genes en las distintas predicciones intentaremos reducir la variabilidad en las mismas.","9feb832b":"# Pr\u00e1ctica 3: Redes neuronales (*Deep Learning*)\n\n####\u00a0Miner\u00eda de Datos: Curso acad\u00e9mico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jim\u00e9nez\n* Jos\u00e9 Antonio G\u00e1mez Mart\u00edn\n\nEn esta pr\u00e1ctica trabajaremos con redes neuronales a trav\u00e9s de la *API* (*Advanced Programming Interface*) de `Keras`. Esta se trata de una de las librer\u00edas m\u00e1s populares actualmente debido a su facilidad de uso y versatilidad.","f3c97637":"# 4. Modelos\n\n---\n\n## 4.1. Red neuronal convolucional\n\n---\n\nEn primer lugar, vamos a comentar el otro gran problema que nos hemos encontrado al usar la TPU. Como no podemos usar `ImageDataGenerator`, tenemos que realizar el aumento de datos \"a mano\". Aunque s\u00ed que es verdad que podemos realizar el m\u00f3dulo `tf.image`, \u00e9ste contiene muchas menos caracter\u00edsticas que si utiliz\u00e1semos `ImageDataGenerator`, no pudiendo por ejemplo rotar una imagen, hacer zoom o *shear* (aunque s\u00ed que lo usaremos, por ejemplo, para cambiar el tama\u00f1o de las im\u00e1genes o pasar de escala de grises a RGB).\n\nPor ello, vamos a usar por un lado las funciones que realiz\u00f3 Chris Deotte en [este](https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96) kernel de *Kaggle* para la competici\u00f3n `Flower Classification with TPUs` mencionada anteriormente (`rot_zoom` y `get_mat` en el fichero de utilidades), con las cuales podremos realizar rotaci\u00f3n, *shear*, zoom horizonal y vertical, y *shift* (\"movimiento\") horizontal y vertical aleatorias (introduciendo los par\u00e1metros en `ROT_PARAMS`).\n\nY adem\u00e1s, tambi\u00e9n vamos a utilizar un aumento de datos mediante *GridMask* (funci\u00f3n `grid_mask` en el fichero de utilidades), desarrollado por Xie29 en [este](https:\/\/www.kaggle.com\/xiejialun\/gridmask-data-augmentation-with-tensorflow) kernel de *Kaggle* para la misma competici\u00f3n que hemos mencionado antes. Esto nos servir\u00eda para evitar el sobreajuste, ya que aleatoriamente se crear\u00e1 una cuadr\u00edcula de p\u00edxeles negros tapando la imagen, de tama\u00f1os entre `d1` y `d2` p\u00edxeles, y siendo `ratio` el n\u00famero de cuadrados en relaci\u00f3n con la imagen (con ratio 0 no habr\u00eda ninguno, y con ratio 1 la imagen entera ser\u00eda negra). Estos par\u00e1metros los introducimos en `MASK_PARAMS`.\n\n---\n\nPara esta red, hemos definido unos par\u00e1metros que no son demasiado \"agresivos\", para evitar que la red no sea capaz de reconocer los n\u00fameros en ellos. En el 50% de las im\u00e1genes se aplicar\u00e1 el *GridMask* de tama\u00f1o de cuadrados entre 6 y 10 con un ratio de 0.3, mientras que en todas las im\u00e1genes se aplicar\u00e1 una rotaci\u00f3n de m\u00e1ximo un 10%, *shear* de m\u00e1ximo 5%, zoom tanto horizontal como vertical de m\u00e1ximo 10* cada uno, y un peque\u00f1o *shift* vertical y horizontal de 1,2.","3d674da7":"Ahora vamos a entrenarlo:","a4e333c1":"# 4.3. Red Preentrenada: Xception\n\n---\n\nAhora, vamos a pasar a usar la red preentrenada `Xception`, que tiene como particularidad el uso de m\u00f3dulos con convoluciones separables. Dejaremos el mismo tama\u00f1o de entrada que en la anterior, ya que esta red nos pide un tama\u00f1o m\u00ednimo de (71,71,3).\n\nAl igual que antes, vamos a dejar el mismo aumento de datos y tampoco vamos a congelar las capas preentrenadas.","343b2511":"Y una vez definido el modelo, realizamos la validaci\u00f3n cruzada por \u00faltima vez:","d523197e":"Una vez realizadas las predicciones, por ser la primera red neuronal que ejecutamos, vamos a echar un vistazo a las im\u00e1genes que se est\u00e1n usando como test.","c1f8c9b4":"Obtenemos unos resultados similares a los de la primera Red Neuronal Convolucional que no utilizaba *transfer learning*, ya que al final pr\u00e1cticamente todos los modelos que creamos son suficientemente complejos como para llegar a un buen resultado en este conjunto de datos tan simple (en comparaci\u00f3n con otros como `ImageNet`).\n\nAhora vamos a realizar las predicciones usando *Test Time Augmention*, igual que en la red anterior:","a5e17f23":"No vamos a definir aqu\u00ed ninguna semilla, ya que lo \u00fanico que tenemos que garantizar es que los *folds* de validaci\u00f3n sean siempre los mismos, lo cual se va a cumplir ya que en *utilidades*, al realizar las particiones no se desordenan los datos, sino que ya se desordenaron al crear la nueva base de datos.\n\nVamos a utilizar la TPU (unidad de procesamiento tensorial, *tensor processing unit*) que nos proporciona *Kaggle* para obtener una velocidad mucho mayor que si us\u00e1semos la GPU, sobre todo viendo que en la primera ejecuci\u00f3n que hicimos con la GPU, una red convolucional simple tardaba unos 200 segundos por *epoch* al a\u00f1adir el *Data Augmentation* ya que sobrecargaba la CPU, mientras que con el uso de la TPU hemos podido reducir ese n\u00famero a unos 6 segundos con la misma red.\n\nPor tanto, vamos a llamar a la funci\u00f3n `inicializa_TPU()` de `utilidades`, la cual nos va a inicializar todas las variables necesarias para su uso. Cabe destacar que en ella se inicializa tambi\u00e9n el *batch_size*, utilizando en este caso el [recomendado por *Kaggle*](https:\/\/www.kaggle.com\/docs\/tpu) para maximizar el rendimiento de sus TPU v3-8 (entre 8 y 128 elementos por n\u00facleo, al contar con 8 n\u00facleos la TPU y hardware multiplicador de matrices de tama\u00f1o 128x128). Por tanto, vamos a escoger 32 elementos por n\u00facleo, qued\u00e1ndose el *batch_size* se en `32 x 8 = 256`.","44e301ed":"Como ocurr\u00eda antes, este modelo tambi\u00e9n obtiene valores parecidos a los anteriores. Solo nos queda realizar las predicciones:"}}