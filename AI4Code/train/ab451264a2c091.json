{"cell_type":{"218617fe":"code","69f48580":"code","18421247":"code","b0548adf":"code","9e9c398d":"code","35618616":"code","a51874cc":"code","eea51875":"code","b25291a6":"code","6cec7f2c":"code","13ac7c15":"code","8bd267b0":"code","8576ac69":"markdown","e1a455d8":"markdown"},"source":{"218617fe":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import KFold, cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport lightgbm as lgb\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","69f48580":"boston = load_boston() # \u30dc\u30b9\u30c8\u30f3\u306e\u4f4f\u5b85\u4fa1\u683c\u30c7\u30fc\u30bf\ndf = pd.DataFrame(boston.data, columns = boston.feature_names) # \u8aac\u660e\u5909\u6570\ndf['MEDV'] = boston.target # \u76ee\u7684\u5909\u6570\ndf.shape","18421247":"x, vx, y, vy = train_test_split(df.iloc[:, 0:df.shape[1] - 1], df.iloc[:, df.shape[1] - 1], test_size=0.2, random_state=42)\nx.shape, y.shape, vx.shape, vy.shape","b0548adf":"params = {\n    \"objective\": \"regression\",\n    \"boosting_type\": \"gbdt\",\n    \"seed\": 42,\n    \"n_estimators\": 512,\n    \"n_jobs\": 16,\n    \"learning_rate\": 0.1,\n    \"importance_type\": \"gain\",\n}\nmdl = lgb.LGBMRegressor(**params)\nmdl.fit(x, y,\n        eval_set=[(x, y), (vx, vy)],\n        early_stopping_rounds=params['n_estimators'] \/\/ 10,\n        verbose=64)","9e9c398d":"x = df.iloc[:, 0:df.shape[1] - 1]\ny = df.iloc[:, df.shape[1] - 1]\nx.shape, y.shape","35618616":"def set_fixed_params(params):\n    \"\"\"\u56fa\u5b9a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30bb\u30c3\u30c8\n    \"\"\"\n    params['objective'] = 'regression'\n    params['boosting_type'] = 'gbdt'\n    params['verbosity'] = -1\n    params['n_estimators'] = 512\n    params['importance_type'] = 'gain'\n    params['n_jobs'] = 16\n    params['metric'] = 'r2'\n    \n    params['seed'] = 42\n    params['random_state'] = 42\n    params[\"bagging_fraction_seed\"] = 42\n    params[\"feature_fraction_seed\"] = 42\n    params[\"data_random_seed\"] = 42\n    params[\"extra_seed\"] = 42\n    params[\"drop_seed\"] = 42\n    params[\"objective_seed\"] = 42\n    \n    return params","a51874cc":"def objective(trial):\n    \"\"\"\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u7528\u306e\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\n    \"\"\"\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 10, 100), # trial.suggest_int('num_leaves', 10, 1000),\n        'max_depth': trial.suggest_int('max_depth', 10, 20), # trial.suggest_int('max_depth', 8, 24),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2), # trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 0.5), # trial.suggest_loguniform('reg_alpha', 1e-5, 1.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 0.5), # trial.suggest_loguniform('reg_lambda', 1e-5, 1.0),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0), # trial.suggest_uniform('feature_fraction', 0.3, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0), # trial.suggest_uniform('bagging_fraction', 0.3, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 8),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 80),\n    }\n    params = set_fixed_params(params)\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'r2') # \u898b\u8fbc\u307f\u306e\u306a\u3044 trial \u306e\u5207\u308a\u6368\u3066\n    mdl = lgb.LGBMRegressor(**params) # \u30e2\u30c7\u30eb\u306b\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6e21\u3059\n    kf = KFold(n_splits=3, shuffle=True, random_state=42) # KFold \u5206\u5272\n    scores = cross_validate(mdl, X=x, y=y, scoring='r2', cv=kf) # \u8a55\u4fa1\n    return scores['test_score'].mean()","eea51875":"sampler = optuna.samplers.TPESampler(seed=42)\nstudy = optuna.create_study(sampler=sampler, direction='maximize')\nstudy.optimize(objective, n_trials=50, timeout=300)","b25291a6":"fig = optuna.visualization.plot_optimization_history(study)\nfig.show()","6cec7f2c":"study.best_trials, study.best_params, study.best_value","13ac7c15":"params = set_fixed_params(study.best_params)\nmdl = lgb.LGBMRegressor(**params)\nmdl.fit(x, y)","8bd267b0":"mdl.get_params()","8576ac69":"# Normal Train","e1a455d8":"# Parameter Tuning Train"}}