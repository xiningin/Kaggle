{"cell_type":{"bdd15f61":"code","b2bf776b":"code","fdfc79f6":"code","6a14dfd6":"code","89866c48":"code","b4be1144":"code","b999c827":"code","14915108":"code","5a611c9f":"code","02fb1069":"code","2bf58b41":"code","da8a123c":"code","54f4a4c8":"code","9ca66e41":"code","1a092c05":"code","01d786bc":"code","3a308ae8":"code","a151a44e":"code","01b61118":"code","84319729":"code","3af52abe":"code","d2ec9b4a":"code","0c67dd37":"code","9272a01a":"code","f2158449":"code","ee407e65":"code","d67411be":"code","44a2475f":"code","75d9329d":"code","ff320e77":"markdown","a5d137ed":"markdown","de70b751":"markdown","2177623e":"markdown","f75a9184":"markdown","c2658595":"markdown","a89c2345":"markdown","4100080d":"markdown"},"source":{"bdd15f61":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2bf776b":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\ntrain","fdfc79f6":"# Dropping 'row_id' column from both dataframes\ntrain.drop(['row_id'], axis = 1, inplace = True)\ntest.drop(['row_id'], axis = 1, inplace = True)","6a14dfd6":"# Check missing values\ntrain.info()","89866c48":"train['country'].value_counts()","b4be1144":"train['product'].value_counts()","b999c827":"train['store'].value_counts()","14915108":"print('Train data duration:', train['date'].min(), 'to', train['date'].max())\nprint('Test data duration:', test['date'].min(), 'to', test['date'].max())","5a611c9f":"# Convert 'date' to datetime type for easty handling\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])","02fb1069":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain_monthly = train.set_index('date').groupby([pd.Grouper(freq = 'M')])[['num_sold']].mean()\n\nplt.figure(figsize = (12, 7))\nsns.lineplot(x = 'date', y = 'num_sold', data = train, label = 'daily')\nsns.lineplot(x = 'date', y = 'num_sold', data = train_monthly, label = 'monthly mean', color = 'black')\nplt.title('Monthly Trend')\nplt.grid(alpha = 0.5)\nplt.show()","2bf58b41":"train_monthly_country = train.set_index('date').groupby([pd.Grouper(freq = 'M'), 'country'])[['num_sold']].mean()\n\nplt.figure(figsize = (12, 7))\nsns.lineplot(x = 'date', y = 'num_sold', hue = 'country', data = train_monthly_country)\nplt.title('Monthly Trend by Country')\nplt.grid(alpha = 0.5)\nplt.show()","da8a123c":"# day of week\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntest['dayofweek'] = test['date'].dt.dayofweek","54f4a4c8":"train_dayofweek = train.set_index('date').groupby([pd.Grouper(freq = 'M'), 'dayofweek'])[['num_sold']].mean()\n\nplt.figure(figsize = (12, 7))\nsns.lineplot(x = 'date', y = 'num_sold', hue = 'dayofweek', data = train_dayofweek)\nplt.title('Trend by day of the week')\nplt.grid(alpha = 0.5)\nplt.show()","9ca66e41":"# weekend\ntrain['weekend'] = train['dayofweek'].apply(lambda x : x >= 5)\ntest['weekend'] = train['dayofweek'].apply(lambda x : x >= 5)\ntrain_weekend = train.set_index('date').groupby([pd.Grouper(freq = 'M'), 'weekend'])[['num_sold']].mean()\n\nplt.figure(figsize = (12, 7))\nsns.lineplot(x = 'date', y = 'num_sold', hue = 'weekend', data = train_weekend)\nplt.title('Weekend vs. Weekday Trend Comparison')\nplt.grid(alpha = 0.5)\nplt.show()","1a092c05":"import holidays\n\n# Check if date is a holiday    \ndef isHoliday(country, date):\n    country_holidays = holidays.CountryHoliday(country, years = date.year)\n    return int(date in country_holidays)","01d786bc":"train['isHoliday'] = train.apply(lambda x: isHoliday(x['country'], x['date'].date()), axis = 1)\ntest['isHoliday'] = test.apply(lambda x: isHoliday(x['country'], x['date'].date()), axis = 1)","3a308ae8":"train['isHoliday'].value_counts()","a151a44e":"train['year'] = train['date'].dt.year\ntrain['quarter'] = train['date'].dt.quarter\ntrain['month'] = train['date'].dt.month\ntrain['week'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['day'] = train['date'].dt.day\ntrain['dayofyear'] = train['date'].dt.dayofyear\ntrain['daysinmonth'] = train['date'].dt.days_in_month\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekend'] = ((train['date'].dt.dayofweek) \/\/ 5 == 1).astype(int)","01b61118":"test['year'] = test['date'].dt.year\ntest['quarter'] = test['date'].dt.quarter\ntest['month'] = test['date'].dt.month\ntest['week'] = test['date'].dt.isocalendar().week.astype(int)\ntest['day'] = test['date'].dt.day\ntest['dayofyear'] = test['date'].dt.dayofyear\ntest['daysinmonth'] = test['date'].dt.days_in_month\ntest['dayofweek'] = test['date'].dt.dayofweek\ntest['weekend'] = ((test['date'].dt.dayofweek) \/\/ 5 == 1).astype(int)","84319729":"train","3af52abe":"# Dropping 'date' column from both dataframes\ntrain.drop(['date'], axis = 1, inplace = True)\ntest.drop(['date'], axis = 1, inplace = True)","d2ec9b4a":"train.info()","0c67dd37":"target = ['num_sold']\ncat_features = [col for col in test.columns if train[col].dtype == 'object']\nnum_features = [col for col in test.columns if col not in cat_features]","9272a01a":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nnum_pipeline = Pipeline([\n    ('num_scaler', StandardScaler()), \n])\n\ncat_pipeline = Pipeline([\n    ('cat_encoder', OneHotEncoder(sparse = False, handle_unknown = 'ignore')), \n    ('cat_scaler', StandardScaler()), \n])","f2158449":"from sklearn.compose import ColumnTransformer\n\npreprocess_pipeline = ColumnTransformer([\n    ('num', num_pipeline, num_features), \n    ('cat', cat_pipeline, cat_features), \n])","ee407e65":"X_train = preprocess_pipeline.fit_transform(train[num_features + cat_features])\nX_test = preprocess_pipeline.transform(test[num_features + cat_features])\ny_train = train[target]","d67411be":"from lightgbm import LGBMRegressor\n\nparams = {\n    'boosting_type': 'gbdt', \n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'n_jobs': -1, \n}\n\nlgbm_reg = LGBMRegressor(**params)\nlgbm_reg.fit(X_train, y_train)","44a2475f":"submission","75d9329d":"y_pred = lgbm_reg.predict(X_test)\nsubmission['num_sold'] = y_pred\nsubmission.to_csv('my_submission.csv', index = False)","ff320e77":"# LightGBM Regressor","a5d137ed":"Please visit these notebooks and upvote if you like them:\n\nhttps:\/\/www.kaggle.com\/subinium\/tps-jan-happy-new-year\/notebook\n\nhttps:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\/discussion\/298411\n\nhttps:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\/discussion\/298300","de70b751":"# Data Preprocessing","2177623e":"# Data Visualization","f75a9184":"# Feature Engineering","c2658595":"# Acknowledgements","a89c2345":"# EDA","4100080d":"# Submission"}}