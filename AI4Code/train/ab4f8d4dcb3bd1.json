{"cell_type":{"be547704":"code","bba86e2b":"code","bb326308":"code","0e873366":"code","4adbc128":"code","c1af74a0":"code","2e32b90d":"code","3a8efc38":"code","18d2643f":"code","7bfbf2cb":"code","3a489a07":"code","e8d2f302":"code","ed57e133":"code","318dc19a":"code","16b19c1f":"code","7ad71cd0":"code","e887f4af":"code","766dad46":"code","3cd90cfc":"code","f3207002":"code","355a6021":"code","72fa4a9f":"code","a5496608":"code","c1d725db":"code","5a9af9b8":"code","66bae038":"code","6c28932b":"code","a73ebb6c":"code","09240702":"code","043f3b26":"code","00b41ba8":"code","c152e8db":"code","f4788bde":"code","b386bb24":"code","6c7bf48d":"code","28a8f4cb":"code","4678d9ac":"code","20febc0b":"code","e361708b":"code","aeff5765":"code","d2fc5780":"code","d6135b1e":"code","b4fa753c":"markdown","0a2e6a81":"markdown","308cf3ea":"markdown","732a977b":"markdown","6d4e5428":"markdown","472a2f3d":"markdown","8a78dfc3":"markdown","3d601399":"markdown","5db35006":"markdown","31b5db21":"markdown","4f430111":"markdown","6dd4a1fd":"markdown","90681be1":"markdown","c9d317b5":"markdown","4888df8f":"markdown","e168b91f":"markdown","6811c9d7":"markdown","1eb27be7":"markdown","ceda35d6":"markdown"},"source":{"be547704":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bba86e2b":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings\nnp.random.seed(123)\nwarnings.filterwarnings('ignore')\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV","bb326308":"train_dataset = pd.read_csv(\"\/kaggle\/input\/steam-reviews\/train.csv\", delimiter=\",\")\ntrain_dataset","0e873366":"test_dataset = pd.read_csv(\"\/kaggle\/input\/steam-reviews-test-dataset\/test.csv\", delimiter=\",\")\ntest_dataset['user_suggestion'] = None","4adbc128":"dataset = pd.concat([train_dataset, test_dataset], axis = 0)\ndataset.reset_index(drop = True, inplace = True)\ndataset","c1af74a0":"from matplotlib import pyplot as plt\nimport seaborn as sns","2e32b90d":"# Visualizing the variable - 'year'\nplt.figure(figsize = (10,5))\nplt.xticks(rotation=90)\nsns.countplot(train_dataset['year'])","3a8efc38":"from fastai.text import *","18d2643f":"from pathlib import Path","7bfbf2cb":"path = Path('\/kaggle\/input\/steam-reviews\/')","3a489a07":"%%time\ndata_lm = TextLMDataBunch.from_csv(path,'train.csv', text_cols = 3, label_cols = 4)","e8d2f302":"%%time\ndata_clas = TextClasDataBunch.from_csv(path, 'train.csv', vocab=data_lm.train_ds.vocab, bs=32, text_cols = 3, label_cols = 4)","ed57e133":"data_clas","318dc19a":"bs=16","16b19c1f":"#torch.cuda.set_device(1)\n#torch.cuda.set_device(0)","7ad71cd0":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)","e887f4af":"learn.fit_one_cycle(1, 1e-2)","766dad46":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(1e-4,1e-2))","3cd90cfc":"learn.predict(\"This is a review about\", n_words=10)","f3207002":"learn.predict(\"This game is one of the \", n_words=10)","355a6021":"learn.model_dir = Path('\/kaggle\/working\/')","72fa4a9f":"learn.save(file = Path('language_model'))\nlearn.save_encoder(Path('language_model_encoder'))","a5496608":"learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5).to_fp16()\nlearn.model_dir = Path('\/kaggle\/working\/')\nlearn.load_encoder('language_model_encoder')","c1d725db":"data_clas.show_batch()","5a9af9b8":"learn.fit_one_cycle(1, 5e-2)","66bae038":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(1e-4, 1e-2))","6c28932b":"learn.predict('This game is absolute shit! Dont waste your money!')","a73ebb6c":"learn.predict('This is one of the best games to buy!')","09240702":"learn.predict('The best button of the game is exit button')","043f3b26":"#learn.unfreeze()\n#learn.fit_one_cycle(3, slice(1e-4, 1e-2))","00b41ba8":"data_clas.save('\/kaggle\/working\/data_textlist_class')","c152e8db":"learn.model_dir = Path('\/kaggle\/working\/')\nlearn.save('data_model')","f4788bde":"data_clas = load_data(path, '\/kaggle\/working\/data_textlist_class', bs=bs, num_workers=1)","b386bb24":"data_clas","6c7bf48d":"data_clas = load_data(path, '\/kaggle\/working\/data_textlist_class', bs=bs, num_workers=1)\nlearn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics = [accuracy]).to_fp16()\nlearn_c.model_dir = Path('\/kaggle\/working\/')\nlearn_c.load('data_model', purge=False);","28a8f4cb":"data_clas_bwd = load_data(path, '\/kaggle\/working\/data_textlist_class', bs=bs, num_workers=1, backwards=True)\nlearn_c_bwd = text_classifier_learner(data_clas_bwd, AWD_LSTM, drop_mult=0.5, metrics=[accuracy]).to_fp16()","4678d9ac":"data_clas_bwd.show_batch()","20febc0b":"learn_c_bwd.fit_one_cycle(1, 1e-2)","e361708b":"learn_c_bwd.unfreeze()\nlearn_c_bwd.fit_one_cycle(5, slice(1e-4, 1e-2))","aeff5765":"preds,targs = learn_c.get_preds(ordered=True)\naccuracy(preds,targs)","d2fc5780":"preds_b,targs_b = learn_c_bwd.get_preds(ordered=True)\naccuracy(preds_b,targs_b)","d6135b1e":"preds_avg = (preds+preds_b)\/2\naccuracy(preds_avg,targs_b)","b4fa753c":"## Data Bunch for Classification Task","0a2e6a81":"Though I've not experimented with this here, the idea is pretty simple. In the start we keep the initial layers of model as un-trainable, and then we slowly unfreeze earlier layers, as we keep on training. I'll cover this in detail in next post","308cf3ea":"# ULMFit\n\nThe idea of using Transfer Learning is quite new in NLP Tasks, while it has been quite prominently used in Computer Vision tasks! This new way of looking at NLP was first proposed by Howard Jeremy, and has transformed the way we looked at data proviously!\n\nThe core idea is two-fold - using generative pretrained Language Model + task-specific fine-tuning was first explored in ULMFiT (Howard & Ruder, 2018), directly motivated by the success of using ImageNet pre-training for computer vision tasks. The base model is AWD-LSTM.\n\nA Language Model is exactly like it sounds - the output of this model is to predict the next word of a sentence. The goal is to have a model which can understand the semantics, grammer and unique structure of a language.\n\n**ULMFiT** follows three steps to achieve good transfer learning results on downstream language classification tasks:\n\n1) General Language Model pre-training: on Wikipedia text.\n\n2) Target task Language Model fine-tuning: ULMFiT proposed two training techniques for stabilizing the fine-tuning process.\n\n3) Target task classifier fine-tuning: The pretrained LM is augmented with two standard feed-forward layers and a softmax normalization at the end to predict a target label distribution.","732a977b":"### **Accuracy - 90%**\n\nIt's amazing how little effort we had to put in to get to this point. fast.ai's implementation and ULMFit makes it incredible easy to get started with limited data and get great results, leveraging the power of Transfer Learning. I hope this was helpful for you as well to get started with NLP and Transfer Learning. I'll catch you later in the 4th blog of this series, where we take this up a notch and explore transformers!","6d4e5428":"Let's try to see how well this approach works for our dataset. I would also like to point out that all these ideas and code are available at fast.ai's free official course for NLP - \"\".","472a2f3d":"### Discrimiative Fine-Tuning","8a78dfc3":"# Evolution of NLP - Part 3 - Transfer Learning using ULMFit\n\nThis is the third part of a series of posts showing the improvements in NLP modeling approaches. We have seen the use of traditional techniques like Bag of Words, TF-IDF, then moved on to RNNs and LSTMs. This time we'll look into one of the pivotal shifts in approaching NLP Tasks - Transfer Learning!","3d601399":"### Slated Triangular Learning Rates","5db35006":"Pretty good for the first two! But our model interestingly still can't tell the difference between appreciation and sarcasm! Maybe we can address this ove","31b5db21":"## Data Bunch for Language Model","4f430111":"# Using fast.ai for NLP -\n\n**fast.ai**'s motto - Making Neural Networks Uncool again - tells you a lot about their approach ;) Implementation of these models is remarkably simple and intuitive, and with good documentation, you can easily find a solution if you get stuck anywhere. Along with this, and few other reasons I elaborate below, I decided to try out fast.ai library which is build on top of PyTorch instead of Keras. Despite being used to working in Keras, I didn't find it difficult to navigate fast.ai and the learning curve is quite fast to implement advanced things as well!\n\nIn addition to it's simplicity, there are some advantages of using fast.ai's implementation -\n\n* **Discriminative fine-tuning** is motivated by the fact that different layers of LM capture different types of information (see discussion above). ULMFiT proposed to tune each layer with different learning rates, {\u03b71,\u2026,\u03b7\u2113,\u2026,\u03b7L}, where \u03b7 is the base learning rate for the first layer, \u03b7\u2113 is for the \u2113-th layer and there are L layers in total.\n\n* **Slanted triangular learning rates (STLR)** refer to a special learning rate scheduling that first linearly increases the learning rate and then linearly decays it. The increase stage is short so that the model can converge to a parameter space suitable for the task fast, while the decay period is long allowing for better fine-tuning","6dd4a1fd":"This performs pretty well in predicting the next few words of the review. Time to save this and try it on our classification task.","90681be1":"### Step 1. Training a Language Model","c9d317b5":"Data in fast.ai is taken using TextLMDataBunch. This is very similar to ImageGenerator in Keras, where the path, labels, etc. are provided and the method prepares Train, Test and Validation data depending on the task at hand!","4888df8f":"*learn.unfreeze()* makes all the layers of AWD_LSTM trainable. We can set a training rate using slice() function, which trains the last layer at 1e-02, while groups (of layers) in between would have geometrically reducing learning rates.","e168b91f":"Loading and training on reverse data","6811c9d7":"### Gradual Unfreezing","1eb27be7":"### Step 2. Classification Task using Language Model as encoder","ceda35d6":"This can achieved simply by using fit_one_cycle() method in fast.ai"}}