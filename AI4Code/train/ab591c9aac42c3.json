{"cell_type":{"0bcc7ce6":"code","b2d438d9":"code","d7dbe942":"code","8e0dbafa":"code","c4c74fdd":"code","740bbb7e":"code","2ef11359":"code","9ab9db42":"code","ad19bfd6":"code","8ba3257c":"code","6c7ffa2c":"code","33f6f645":"code","47fb828f":"code","4ccf21b0":"code","671e3075":"code","cd59b217":"code","fe5d58c7":"code","dcca5692":"code","5caf7f80":"code","8cb75741":"code","b898c4ec":"code","b5ec5cb9":"code","09f3f6d9":"code","ac261360":"code","75e719c5":"code","350ab37b":"code","da942733":"code","e31449b5":"code","1399959d":"code","0bb16f2d":"code","d3da8016":"code","187d3ee2":"code","cc0ec6d7":"code","030621c5":"code","df7d06c6":"code","c30c5ce0":"code","5c873018":"code","3f1d7840":"code","f9875fb5":"code","d4f892b9":"code","d1b08b67":"code","3a0f5993":"code","3a0e070f":"code","56dc8f07":"code","9d5cff0c":"code","c6590ddd":"code","b91a1f65":"code","87734939":"code","b840fdb1":"code","b2c07d31":"code","e4d17774":"code","35f30f9d":"code","3f1df16e":"code","17051ec0":"code","af0b11b2":"code","e5a8c023":"code","0aa32d5a":"code","80b728c8":"code","79b735e3":"code","a14c429d":"code","18e73267":"code","6ab3a46a":"code","090f9d88":"code","15040625":"code","a6a1551e":"code","9bc3c14b":"code","ceab007d":"code","2bc4a04b":"code","b8652ad8":"code","acf61b31":"code","5db107a0":"code","be24ab05":"code","72993fad":"code","aa0dc66c":"code","b577d595":"code","41ed6e2c":"code","f7b6a6fc":"code","43fe504e":"code","2cd9550f":"code","c2c53448":"code","1eba8182":"code","cfd5f9b9":"code","1ffcddf8":"code","6d0cc436":"code","4d578fba":"code","03fb4f57":"code","44fe94ea":"code","8b000b1f":"code","594d8a93":"markdown","f8087b1f":"markdown"},"source":{"0bcc7ce6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 \nimport matplotlib.pyplot as plt\nimport math\nimport json\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport time\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2d438d9":"img_path = '\/kaggle\/input\/marks-dataset\/data_easy\/'\n\n# img_names = os.listdir(img_path)\n# img_names.remove('\u041c\u0430\u0440\u043a\u0438_\u0442\u0435\u043a\u0441\u0442\u044b.docx')\n# len(img_names)\nprint(len(os.listdir(img_path)))\nos.listdir(img_path)","d7dbe942":"os.listdir('\/kaggle\/input\/marks-dataset\/data_easy\/')","8e0dbafa":"df = pd.read_json('\/kaggle\/input\/marks-dataset\/data_easy\/info_easy.json')\n\ntrain_df = pd.DataFrame(columns = ['image_id', 'label'])\nfor i in range(len(df)):\n    train_df = train_df.append({'image_id': df.loc[i]['StampsGroups']['CoverPath'], 'label': i}, ignore_index=True)","c4c74fdd":"train_df","740bbb7e":"img_names = list(train_df['image_id'])\nimg_names.remove('')\nimg_names","2ef11359":"photo_path = '\/kaggle\/input\/marks-dataset\/mark_photo\/mark_photo\/'\nimg_photo = os.listdir(photo_path)\nlen(img_photo)","9ab9db42":"import cv2 \nimport matplotlib.pyplot as plt\n\nplt.imshow(cv2.cvtColor(cv2.imread(img_path + img_names[13]), cv2.COLOR_BGR2RGB))\nplt.show()\nplt.imshow(cv2.cvtColor(cv2.imread(photo_path + img_photo[-4]), cv2.COLOR_BGR2RGB))","ad19bfd6":"img_shapes = []\nfor i in range(len(img_names)):\n    img_shapes.append(cv2.imread(img_path + img_names[i]).shape[:2])\nimg_shapes   ","8ba3257c":"import albumentations as A\nimport math\nimport random\n\ndef batch_visualization(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    \n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w)\n    \n    all_names = os.listdir(path)\n    \n    image_names = all_names[:n_images]\n    if is_random:\n        image_names = random.sample(all_names, n_images)\n    \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.axis(\"off\")\n    \n    plt.show()","6c7ffa2c":"batch_visualization(img_path, 1, is_random=True, figsize=(5, 5))","33f6f645":"def color_hist_visualization(image_path, figsize=(16, 4)):\n    plt.figure(figsize=figsize)\n    \n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    plt.subplot(1, 4, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \n    colors = [\"red\", \"green\", \"blue\"]\n    for i in range(len(colors)):\n        plt.subplot(1, 4, i + 2)\n        plt.hist(\n            img[:, :, i].reshape(-1),\n            bins=25,\n            alpha=0.5,\n            color=colors[i],\n            density=True\n        )\n        plt.xlim(0, 255)\n        plt.xticks([])\n        plt.yticks([])\n    \n    \n    plt.show()","47fb828f":"def plot_simple_augmentation(image_path, transform):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    \n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 2, 2)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n\n    plt.show()\n    \ndef plot_multiple_augmentation(image_path, transform):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    \n    plt.figure(figsize=(10, 10))\n    \n    plt.subplot(2, 2, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 2, 2)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 2, 3)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 2, 4)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n\n    plt.show()","4ccf21b0":"# for i in range(len(img_names)):\n\n#     color_hist_visualization(img_path+img_names[i])\n","671e3075":"transform = A.HueSaturationValue(\n                hue_shift_limit=0.5, \n                sat_shift_limit=0.5, \n                val_shift_limit=0.5, \n                p=1)\n\nplot_multiple_augmentation(img_path+img_names[i], transform)","cd59b217":"transform =  A.ColorJitter(brightness=1, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=1) \nplot_multiple_augmentation(img_path+img_names[0], transform)","fe5d58c7":"transform = A.RandomBrightness(limit=0.5, always_apply=False, p=1)\nplot_multiple_augmentation(img_path+img_names[i], transform)","dcca5692":"def prepare_img(img_path, color_low = np.array([60 , 60, 60]), color_high = np.array([255, 255, 255])):\n    img = cv2.imread(img_path, 0)\n\n    hsv_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2HSV)\n\n    curr_mask = cv2.inRange(hsv_img, color_low, color_high)\n    hsv_img[curr_mask > 0] = ([200,200,200])\n    RGB_again = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n    gray = cv2.cvtColor(RGB_again, cv2.COLOR_RGB2GRAY)\n    #90 \u0431\u044b\u043b\u043e \u0440\u0430\u043d\u044c\u0448\u0435\n    ret, threshold = cv2.threshold(gray, np.mean(gray), 255, 0)\n    threshold = threshold[100:-100, 100:-100]\n    x, y = np.where(threshold == 0)\n    img = img[100:-100, 100:-100]\n    return img[min(x):max(x), min(y):max(y)]","5caf7f80":"num = 5\nplt.imshow(cv2.imread(photo_path + img_photo[num]))\nplt.show()\nplt.imshow(prepare_img(photo_path + img_photo[num]))\nplt.show()","8cb75741":"def get_templates(img):\n    input_shape_x = img.shape[0]\n    input_shape_y = img.shape[1]\n    template_images = []\n    shift = 15\n    size_x = int(0.65*input_shape_x)\n    size_y = int(0.65*input_shape_y)\n    template_images.append(img[shift:size_x, -size_y : -shift])\n    template_images.append(img[shift:size_x, shift:size_y])\n    template_images.append(img[-size_x : -shift, -size_y : -shift])\n    template_images.append(img[-size_x : -shift, shift:size_y])\n\n    quarter_x = input_shape_x\/\/4\n    quarter_y = input_shape_y\/\/4\n    template_images.append(img[quarter_x : 3*quarter_x, quarter_y:3*quarter_y])\n\n    template_shape = []\n    for i in range(5):\n        template_shape.append(template_images[i].shape[::-1])\n    return template_images\n\n\ndef prepare_img(img_path, color_low = np.array([60 , 60, 60]), color_high = np.array([255, 255, 255])):\n    img = cv2.imread(img_path, 0)\n\n    hsv_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2HSV)\n\n    curr_mask = cv2.inRange(hsv_img, color_low, color_high)\n    hsv_img[curr_mask > 0] = ([200,200,200])\n    RGB_again = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n    gray = cv2.cvtColor(RGB_again, cv2.COLOR_RGB2GRAY)\n    \n    ret, threshold = cv2.threshold(gray, np.mean(gray), 255, 0)\n    threshold = threshold[100:-100, 100:-100]\n    x, y = np.where(threshold == 0)\n    img = img[100:-100, 100:-100]\n    return img[min(x):max(x), min(y):max(y)]\n\ndef get_templates(img):\n    input_shape_x = img.shape[0]\n    input_shape_y = img.shape[1]\n    template_images = []\n    shift = 15\n    size_x = int(0.8*input_shape_x)\n    size_y = int(0.8*input_shape_y)\n    template_images.append(img[shift:size_x, -size_y : -shift])\n    template_images.append(img[shift:size_x, shift:size_y])\n    template_images.append(img[-size_x : -shift, -size_y : -shift])\n    template_images.append(img[-size_x : -shift, shift:size_y])\n\n    quarter_x = input_shape_x\/\/4\n    quarter_y = input_shape_y\/\/4\n    template_images.append(img[quarter_x : 3*quarter_x, quarter_y:3*quarter_y])\n\n    template_shape = []\n    for i in range(5):\n        template_shape.append(template_images[i].shape[::-1])\n    return template_images\n\ndef finde_img(img_names, photo_img_path, img_dir):\n    photo_img = prepare_img(photo_img_path)\n    photo_img = cv2.resize(photo_img, (224, 224))\n    templates = get_templates(photo_img)\n    threshold = 0.2\n    counts = []\n    for i in range(len(img_names)):\n        img = cv2.resize(cv2.imread(img_dir + img_names[i], 0), (224, 224))\n        method = eval('cv2.TM_CCOEFF_NORMED')\n        count = 0\n        templates = get_templates(img)\n        for template in templates:\n\n            res = cv2.matchTemplate(photo_img, template, method)\n            loc = np.where(res >= threshold)\n            if len(loc[0])>0:\n                count += 1\n        counts.append(count)\n\n\n    return img_dir + img_names[np.argmax(counts)]","b898c4ec":"num = 2\nphoto_img_path = photo_path + img_photo[num]\nimg_dir = img_path\n\nphoto_img = prepare_img(photo_img_path)\nphoto_img = cv2.resize(photo_img, (224, 224))\ntemplates = get_templates(photo_img)\nthreshold = 0.2\ncounts = []\nplt.imshow(photo_img)\nplt.show()\nfor i in range(len(img_names)):\n    img = cv2.resize(cv2.imread(img_dir + img_names[i], 0), (224, 224))\n    method = eval('cv2.TM_CCOEFF_NORMED')\n    count = 0\n    templates = get_templates(img)\n    for template in templates:\n        \n        res = cv2.matchTemplate(photo_img, template, method)\n        loc = np.where(res >= threshold)\n        if len(loc[0])>0:\n            count += 1\n    counts.append(count)\n\n\nplt.imshow(cv2.imread(img_dir + img_names[np.argmax(counts)]))","b5ec5cb9":"\nnum = 2\nprint('\u0418\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 (\u0444\u043e\u0442\u043e)')\nplt.imshow(prepare_img(photo_path + img_photo[num]))\nplt.show()\nstart_time = time.time()\nfinded_img = finde_img(img_names, photo_path + img_photo[num], img_path)\nprint(\"\u0412\u0440\u0435\u043c\u044f \u0437\u0430\u0442\u0440\u0430\u0447\u0435\u043d\u043d\u043e\u0435 \u043d\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \" + str(time.time() - start_time) + str(' \u0441\u0435\u043a\u0443\u043d\u0434\u044b'))\nprint('\u041e\u0442\u0432\u0435\u0442 \u043f\u043e\u0438\u0441\u043a\u0430')\nplt.imshow(cv2.imread(finded_img))\nplt.show()\n","09f3f6d9":"img_names","ac261360":"img_photo","75e719c5":"train_df = pd.DataFrame({'image_id': [img_path + img for img in img_names], 'label': list(range(30))})\nfor i in range(5):\n    train_df = train_df.append({'image_id': 'nothing_'+str(i), 'label': 30}, ignore_index=True)\ntrain_df","350ab37b":"print(train_df['image_id'][30])","da942733":"train_df['image_id'][0].split('\/')[-1]","e31449b5":"# dict_df = pd.DataFrame({'image_id':img_names, 'label': list(range(31))})\n# dict_df.to_csv('dict_new.csv', index = False)","1399959d":"# file1 = open(\"dict.txt\",\"w\")","0bb16f2d":"# for i in range(len(train_df)):\n#     file1.write(train_df['image_id'][i].split('\/')[-1] + ':'+ str(i) + ',')\n\n\n","d3da8016":"test_df = pd.DataFrame({'image_id': [photo_path + img for img in img_photo], 'label': [28, 11, 2, 17, 1, 9, 12, 7, 20, 25]})\nfor i in range(2):\n    test_df = test_df.append({'image_id': 'nothing_'+str(i), 'label': 30}, ignore_index=True)\ntest_df","187d3ee2":"for i in range(len(test_df)):\n    plt.imshow(cv2.imread(test_df['image_id'][i]))\n    plt.show()","cc0ec6d7":"for i in range(len(test_df)):\n    row = train_df.loc[train_df['label'] == test_df['label'][i]]\n    plt.imshow(cv2.imread(row['image_id'].values[0]))\n    plt.show()","030621c5":"def prepare(img):\n    x_range = int(img.shape[0]*0.5)\n    y_range = int(img.shape[1]*0.5)\n    x_add_1 = np.random.choice(list(range(1,x_range)))\n    x_add_2 = np.random.choice(list(range(1,x_range)))\n    y_add_1 = np.random.choice(list(range(1,y_range)))\n    y_add_2 = np.random.choice(list(range(1,y_range)))\n    answ = np.full((img.shape[0] + x_add_1 + x_add_2, img.shape[1] + y_add_1 + y_add_2, 3), 255, dtype = 'uint8')\n    answ[x_add_1: -x_add_2, y_add_1 : -y_add_2, :] = img\n    \n    return cv2.resize(answ, (224, 224))","df7d06c6":"def create_nothing():\n    nums = np.random.choice(np.arange(30), 2)\n    img_1 = cv2.imread(img_path + img_names[nums[0]])\n\n    img_2 = cv2.imread(img_path + img_names[nums[1]])\n\n    white_long = np.random.choice(np.arange(400,600))\n    white_img = np.full((min(img_1.shape[0], img_2.shape[0]), white_long, 3), 255, dtype = 'uint8')\n\n    shape_0 = min(img_1.shape[0], img_2.shape[0])\n    shape_1 = min(img_1.shape[1], img_2.shape[1])\n    if img_1.shape != img_2.shape:\n        img_1 = cv2.resize(img_1, (shape_1, shape_0))\n        img_2 = cv2.resize(img_2, (shape_1, shape_0))\n\n\n    img_1 = img_1[:, np.random.choice(np.arange(shape_1 - 100)):, :]\n    img_2 = img_2[:, :np.random.choice(np.arange(shape_1 - 100)), :]\n\n    result_img = np.concatenate([img_1,white_img, img_2], 1)\n    result_img = cv2.resize(result_img, (224, 224))\n\n\n    return result_img","c30c5ce0":"plt.imshow(create_nothing())","5c873018":"num = 9\nimg = cv2.imread(img_path + img_names[num])\nansw = prepare(img)\nplt.imshow(answ)","3f1d7840":"list(test_df['image_id'])*2","f9875fb5":"class Dataset:\n    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        images_dir (str): path to images folder\n        masks_dir (str): path to segmentation masks folder\n        class_values (list): values of classes to extract from segmentation mask\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    \n    def __init__(\n            self, \n            df,\n            preprocessing=None,\n            augmentation=None,\n            is_test = False\n            \n    ):\n        self.is_test = is_test\n        \n        if is_test:\n            self.ids = list(df['image_id'])*2\n            self.labels = list(df['label'])*2\n        else:\n            self.ids = df['image_id']\n            self.labels = df['label']\n#         self.ids = df['image_id']\n#         self.labels = df['label']\n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n    \n    def __getitem__(self, i):\n        \n        label = np.zeros(31)\n        label[self.labels[i]] = 1\n        \n        if self.labels[i] == 30:\n            image = create_nothing()\n\n        else:\n            # read data\n            image = cv2.imread(self.ids[i])\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            # apply preprocessing\n            if self.preprocessing:\n#                 image = self.preprocessing(image)\n                if self.is_test:\n                    if i > len(self.ids)\/\/2:\n                        image = self.preprocessing(image)\n                    else:\n                        image = cv2.resize(image, (224, 224))\n                else:\n                    image = self.preprocessing(image)\n                    \n\n        # apply augmentations\n        if self.augmentation:\n            image = self.augmentation(image=image)['image']\n        \n        return image, label\n        \n    def __len__(self):\n        return len(self.ids)\n    \n    \nclass Dataloder(keras.utils.Sequence):\n    \"\"\"Load data from dataset and form batches\n    \n    Args:\n        dataset: instance of Dataset class for image loading and preprocessing.\n        batch_size: Integet number of images in batch.\n        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n    \"\"\"\n    \n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n        self.on_epoch_end()\n\n    def __getitem__(self, i):\n        \n        # collect batch data\n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        data = []\n        for j in range(start, stop):\n            data.append(self.dataset[j])\n        \n        # transpose list of lists\n        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n        \n        return batch[0], batch[1]\n    \n    def __len__(self):\n        \"\"\"Denotes the number of batches per epoch\"\"\"\n        return len(self.indexes) \/\/ self.batch_size\n    \n    def on_epoch_end(self):\n        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)","d4f892b9":"AUGMENTATIONS_TRAIN = A.Compose([\n    A.RandomContrast(limit=0.2, p=0.25),\n    A.RandomGamma(gamma_limit=(80, 120), p=0.25),\n    A.RandomBrightness(limit=0.2, p=0.25),\n    A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=20, val_shift_limit=10, p=.25),\n    A.CLAHE(p=0.25, clip_limit=2.0), \n    A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], p = 1.0),\n#     A.\n\n])","d1b08b67":"num = 0\nimg = cv2.cvtColor(cv2.imread(img_path + img_names[num]), cv2.COLOR_BGR2RGB)\nansw = prepare(img)\nplt.imshow(answ)\nplt.show()\nplt.imshow(AUGMENTATIONS_TRAIN(image = answ)['image'])\nplt.show()","3a0f5993":"\ntrain_dataset = Dataset(train_df, prepare, AUGMENTATIONS_TRAIN)\ntrain_dataloader = Dataloder(train_dataset, batch_size=1, shuffle=True)\n\n","3a0e070f":"\nbatch_img = train_dataloader[30][0]\n\n# [12, 16, 22, 19]\nplt.imshow(batch_img[0])","56dc8f07":"batch_label = train_dataloader[0][1]\nbatch_label","9d5cff0c":"AUGMENTATIONS_TEST = A.Compose([\n    A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], p = 1.0),\n\n])\ndef prepare_img(img, color_low = np.array([60 , 60, 60]), color_high = np.array([255, 255, 255])):\n    real_img = img.copy()\n    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n\n    curr_mask = cv2.inRange(hsv_img, color_low, color_high)\n    hsv_img[curr_mask > 0] = ([200,200,200])\n    RGB_again = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n    gray = cv2.cvtColor(RGB_again, cv2.COLOR_RGB2GRAY)\n    \n    ret, threshold = cv2.threshold(gray, np.mean(gray), 255, 0)\n    threshold = threshold[100:-100, 100:-100]\n    x, y = np.where(threshold == 0)\n    img = img[100:-100, 100:-100]\n    real_img =  real_img[100:-100, 100:-100, :]\n    real_img = real_img[min(x):max(x), min(y):max(y), :]\n    real_img = cv2.resize(real_img, (224, 224))\n    \n    return real_img\n\nvalid_dataset = Dataset(test_df, prepare_img, AUGMENTATIONS_TEST, is_test = True)\n# valid_dataset = Dataset(test_df, prepare_img, None)\nvalid_dataloader = Dataloder(valid_dataset, batch_size=1, shuffle=True)\nplt.imshow(valid_dataset[2][0])","c6590ddd":"plt.imshow(valid_dataset[5][0])","b91a1f65":"plt.imshow(valid_dataset[7][0])","87734939":"len(valid_dataloader[5][1][0])","b840fdb1":"import numpy as np\nimport os\nimport cv2\nimport albumentations as A\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt \n\nmobile_net = tf.keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='avg', classes=len(img_names))\nfor layer in mobile_net.layers[:]:\n    layer.trainable = False\n\nmodel = tf.keras.Sequential()\nmodel.add(mobile_net)\nmodel.add(tf.keras.layers.Dense(128, activation= tf.nn.elu, name='first_dense'))\nmodel.add(tf.keras.layers.Dense(31, activation= tf.nn.softmax, name='output'))\n\nmodel.summary()","b2c07d31":"\n# define optomizer\noptim = keras.optimizers.Adam(1e-3)\n\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, loss= 'categorical_crossentropy', metrics = ['accuracy'])","e4d17774":"# define callbacks for learning rate scheduling and best checkpoints saving\ncallbacks = [\n    keras.callbacks.ModelCheckpoint('.\/best_model.h5', save_weights_only=True, save_best_only=True, mode='max', period=1),\n    keras.callbacks.ReduceLROnPlateau(),\n    \n]\n\nclass ModelCheckpoint(tf.keras.callbacks.Callback):\n\n    def __init__(self, freq, directory):\n        super().__init__()\n        self.freq = freq\n        self.directory = directory\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if self.freq > 0 and epoch % self.freq == 0:\n            self.model.save_weights('.\/' + str(epoch)+'.h5')\n\n#     def on_train_end(self, logs=None):\n#         self.model.save(self.directory)\n        \n\n# filepath = \".\/saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(1, '.\/weights')\n# checkpoint = keras.callbacks.ModelCheckpoint(\".\/best_model.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n\nhistory = model.fit_generator(\n    train_dataloader, \n    steps_per_epoch=len(train_dataloader), \n    epochs=60,\n    callbacks=[checkpoint], \n    validation_data=valid_dataloader, \n    validation_steps=len(valid_dataloader),\n)","35f30f9d":"model.load_weights('.\/50.h5')","3f1df16e":"num = 18\npred = model(np.expand_dims(valid_dataset[num][0], axis = 0))\nplt.imshow(valid_dataset[num][0])\nplt.show()\nif np.argmax(pred) == 30:\n    print(30)\nelse:\n    plt.imshow(cv2.imread(train_df['image_id'][np.argmax(pred)]))\n    plt.show()","17051ec0":"# model.load_weights('.\/best_model.h5')\n# model.save('model.h5')\nmodel.save('.\/aaaa')","af0b11b2":"model.save('.\/pizd')","e5a8c023":"model.save('.\/lol')","0aa32d5a":"model = tf.keras.models.load_model('.\/mark_model')","80b728c8":"model.load_weights('.\/18.h5')","79b735e3":"plt.figure(figsize = (18,15))\nfor i,img in enumerate(img_names):\n#     w = int(31 ** .5)\n#     h = math.ceil(31 \/ w)\n    \n    plt.subplot(7, 5, i+1)\n    plt.imshow(cv2.cvtColor(cv2.imread(img_path +img), cv2.COLOR_BGR2RGB))\nplt.show()","a14c429d":"#28,29,30","18e73267":"test_df['image_id'][0]","6ab3a46a":"# img_name = img_path +img_names[30]\nimg_name = test_df['image_id'][5]\nimg = cv2.resize(cv2.cvtColor(cv2.imread(img_name), cv2.COLOR_BGR2RGB), (224, 224))\nimg = AUGMENTATIONS_TEST(image = img)['image']\nplt.imshow(img)","090f9d88":"index = np.argmax(model(np.expand_dims(img, 0))[0])\nplt.imshow(cv2.cvtColor(cv2.imread(train_df.loc[train_df['label']==index]['image_id'].values[0]), cv2.COLOR_BGR2RGB))","15040625":"os.listdir('..\/input\/mark-model')","a6a1551e":"img = cv2.cvtColor(cv2.imread('..\/input\/mark-model\/img_to_rec.jpg'), cv2.COLOR_BGR2RGB)\nimg = prepare_img(img)\nimg = cv2.resize(img, (224, 224))\nimg = img\/255.0\nimg[:2]","9bc3c14b":"\n# img = AUGMENTATIONS_TEST(image = img)['image']\nA.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], p = 1.0),\n\n\n\nplt.imshow(img)","ceab007d":"answ = model.predict(np.expand_dims(img, axis = 0))\nnum = np.argmax(answ[0])\nnum","2bc4a04b":"plt.imshow(cv2.cvtColor(cv2.imread(train_df.loc[ train_df['label'] == num]['image_id'].values[0]), cv2.COLOR_BGR2RGB))","b8652ad8":"tf.keras.models.load_model('..\/input\/mark-model\/mark_model')","acf61b31":"import torch \nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.pytorch import ToTensor\n\n\ndef prepare_train(img):\n    x_range = int(img.shape[0]*0.75)\n    y_range = int(img.shape[1]*0.75)\n    x_add_1 = np.random.choice(list(range(1,x_range)))\n    x_add_2 = np.random.choice(list(range(1,x_range)))\n    y_add_1 = np.random.choice(list(range(1,y_range)))\n    y_add_2 = np.random.choice(list(range(1,y_range)))\n    answ = np.full((img.shape[0] + x_add_1 + x_add_2, img.shape[1] + y_add_1 + y_add_2, 3), 255, dtype = 'uint8')\n    answ[x_add_1: -x_add_2, y_add_1 : -y_add_2, :] = img\n    answ = cv2.resize(answ, (224, 224))\n    return answ\n\ndef prepare_test(img, color_low = np.array([60 , 60, 60]), color_high = np.array([255, 255, 255])):\n    real_img = img.copy()\n    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n\n    curr_mask = cv2.inRange(hsv_img, color_low, color_high)\n    hsv_img[curr_mask > 0] = ([200,200,200])\n    RGB_again = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n    gray = cv2.cvtColor(RGB_again, cv2.COLOR_RGB2GRAY)\n    \n    ret, threshold = cv2.threshold(gray, np.mean(gray), 255, 0)\n    threshold = threshold[100:-100, 100:-100]\n    x, y = np.where(threshold == 0)\n    img = img[100:-100, 100:-100]\n    real_img =  real_img[100:-100, 100:-100, :]\n    real_img = real_img[min(x):max(x), min(y):max(y), :]\n    real_img = cv2.resize(real_img, (224, 224))\n    \n    return real_img\n\n\n\nclass MarkDataset(Dataset):\n    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        images_dir (str): path to images folder\n        masks_dir (str): path to segmentation masks folder\n        class_values (list): values of classes to extract from segmentation mask\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    \n    def __init__(\n            self, \n            df,\n            preprocessing=None,\n            augmentation=None, \n            \n    ):\n        self.ids = df['image_id']\n        self.labels = df['label']\n        \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n    \n    def __getitem__(self, i):\n        \n        # read data\n        image = cv2.imread(self.ids[i])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        label = self.labels[i]\n        \n        \n        # apply preprocessing\n        if self.preprocessing:\n            image = self.preprocessing(image)\n        \n        # apply augmentations\n        if self.augmentation:\n            image = self.augmentation(image=image)['image']\n            \n#         image = cv2.resize(image, (224, 224))\/255.0\n        \n#         image[:,:,0] = (image[:,:,0] - 0.485)\/0.229\n#         image[:,:,1] = (image[:,:,1] - 0.456)\/0.224\n#         image[:,:,2] = (image[:,:,2] - 0.406)\/0.225\n        \n        return image, label\n        \n    def __len__(self):\n        return len(self.ids)\n    \n    \nAUGMENTATIONS_TRAIN = A.Compose([\n    A.RandomContrast(limit=0.2, p=0.5),\n    A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n    A.RandomBrightness(limit=0.2, p=0.5),\n    A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=20,\n                       val_shift_limit=10, p=.9),\n#     A.CLAHE(p=1.0, clip_limit=2.0), \n    A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], p = 1.0),\n#     A.\n    ToTensor()\n\n])\nAUGMENTATIONS_TEST = A.Compose([A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], p = 1.0),ToTensor()])\n\ntrain_dataset = MarkDataset(train_df, prepare_train, AUGMENTATIONS_TRAIN)\ntest_dataset = MarkDataset(test_df, prepare_test, AUGMENTATIONS_TEST)\n\ndataloader_train = DataLoader(train_dataset, batch_size=4,\n                        shuffle=True)\n\ndataloader_test = DataLoader(test_dataset, batch_size=4,\n                        shuffle=True)\n\n","5db107a0":"!pip install timm","be24ab05":"import timm \nfrom pprint import pprint\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nmodel_names = timm.list_models(pretrained=True)\npprint(model_names)","72993fad":"# model = timm.create_model('mobilenetv2_100', pretrained=True)\n# model.classifier = torch.nn.Linear(1280, 31)\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        mobile_net = timm.create_model('mobilenetv2_100', pretrained=True)\n        mobile_net.classifier = nn.Linear(in_features=1280, out_features=128)\n        for i, param in enumerate(mobile_net.parameters()):\n            if i > 157:\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n        self.mobile_net = mobile_net\n        self.elu = nn.ELU()\n        self.classifier_layer = nn.Linear(128, 31)\n        \n    def forward(self, x):\n        x = self.mobile_net.forward(x)\n        x = self.elu(x)\n        x = self.classifier_layer(x)\n        return x\nmodel = MyModel()","aa0dc66c":"model = timm.create_model('mobilenetv2_100', pretrained=True)\nmodel.classifier = nn.Linear(in_features=1280, out_features=31)\nfor i, param in enumerate(mobile_net.parameters()):\n    if i > 157:\n        param.requires_grad = True\n    else:\n        param.requires_grad = False","b577d595":"n = 0\nmobile_net = timm.create_model('mobilenetv2_100', pretrained=True)\nfor i, param in enumerate(mobile_net.parameters()):\n    n+=1\nn","41ed6e2c":"\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9)","f7b6a6fc":"for epoch in range(35):  # loop over the dataset multiple times\n\n    train_loss = 0.0\n    train_acc = 0\n    for i, data in enumerate(dataloader_train, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n#         print(outputs.shape)\n#         print(labels.shape)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        train_loss += loss.item()\n        with torch.no_grad():\n            _, predicted = torch.max(outputs.data, 1)\n            train_acc += (predicted == labels).sum().item()\n    print(train_acc\/31.0)\n            \n    with torch.no_grad():\n        correct = 0\n        total = 0 \n        for data in dataloader_test:\n            images, labels = data\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    if correct\/ total >= 0.9:\n        torch.save(model, 'mobilenet_' + str(epoch) + '_.pt')\n        \n    \n    print('Epoch: ' + str(epoch) + ', ' 'val_acc = ' + str(correct\/ total) + ', train_loss = ' + str(train_loss))\n\nprint('Finished Training')","43fe504e":"!pip install torch.onnx","2cd9550f":"\nimport torch.onnx\n \n# Loading the input PyTorch model and mapping the tensors to CPU\ndevice = torch.device('cpu')\nmodel = torch.load('.\/mobilenet_10_.pt', map_location=device)\n \n# Generate a dummy input that is consistent with the network\u2019s arhitecture\ndummy_input = torch.randn(1, 3, 224, 224)\nin_names = [ 'actual_input_1' ] + [ 'learned_%d' % i for i in range(16) ]\nout_names = [ 'output1' ]\n# Export into an ONNX model using the PyTorch model and the dummy input\ntorch.onnx.export( model, dummy_input, 'pytorch_model.onnx' ,input_names=in_names, \n output_names=out_names ,opset_version=7 , verbose=True)","c2c53448":"# tr = A.Compose([A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n#                              ])\n\n# data_base = []\n# for i in range(len(img_names)):\n#     img = cv2.resize(cv2.imread(img_path + img_names[i]), (224, 224))\n#     img = tr(image = img)\n#     img = np.expand_dims(img['image'], axis = 0)\n#     answ = mobile_net(img)\n#     data_base.append(answ[0])","1eba8182":"# def finde_with_nn(model, data_base, photo_img_path, img_names, img_dir):\n#     photo_img = cv2.resize(cv2.cvtColor(prepare_img(photo_img_path), cv2.COLOR_BGR2RGB), (224, 224))\n    \n# #     img = cv2.resize(cv2.imread(img_dir + df.id[3]), (224, 224))\/255.0\n#     photo_img = tr(image = photo_img)\n#     photo_img = np.expand_dims(photo_img['image'], axis = 0)\n#     features_photo = model(photo_img)[0]\n# #     loss = tf.nn.l2_loss()\n\n#     losses = []\n#     for img_feature in data_base:\n#         losses.append(np.sum((img_feature - features_photo)**2))\n#     return img_dir + img_names[np.argmin(losses)]\n    ","cfd5f9b9":"# num = 0\n# photo_img_path = photo_path + img_photo[num]\n\n# start_time = time.time()\n# finded_img_path = finde_with_nn(mobile_net, data_base, photo_img_path, img_names, img_path)\n# print('\u0412\u0440\u0435\u043c\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 ' + str(time.time() - start_time))\n# plt.imshow(cv2.imread(photo_img_path))\n# plt.show()\n\n# plt.imshow(cv2.imread(finded_img_path))\n# plt.show()","1ffcddf8":"# img = cv2.resize(cv2.cvtColor(cv2.imread(finded_img_path), cv2.COLOR_BGR2RGB), (224, 224))","6d0cc436":"# AUGMENTATIONS_TRAIN = A.Compose([\n#     A.RandomContrast(limit=0.2, p=0.5),\n#     A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n#     A.RandomBrightness(limit=0.2, p=0.5),\n#     A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=20,\n#                        val_shift_limit=10, p=.9),\n#     A.CLAHE(p=1.0, clip_limit=2.0),\n# #     A.ShiftScaleRotate(\n# #         shift_limit=0.0625, scale_limit=0.1, \n# #         rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n#     A.ToFloat(max_value=255)\n# ])\n\n\n# plt.imshow(AUGMENTATIONS_TRAIN(image = img)['image'])","4d578fba":"# num = 5\n\n# def prepare_img(img_path, color_low = np.array([60, 60, 60]), color_high = np.array([255, 255, 255])):\n#     img = cv2.imread(img_path, 0)\n\n#     hsv_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2HSV)\n\n#     curr_mask = cv2.inRange(hsv_img, color_low, color_high)\n#     hsv_img[curr_mask > 0] = ([200,200,200])\n#     RGB_again = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n#     gray = cv2.cvtColor(RGB_again, cv2.COLOR_RGB2GRAY)\n#     #90 \u0431\u044b\u043b\u043e \u0440\u0430\u043d\u044c\u0448\u0435\n#     ret, threshold = cv2.threshold(gray, np.mean(gray), 255, 0)\n#     threshold = threshold[100:-100, 100:-100]\n#     x, y = np.where(threshold < 10)\n#     img = img[100:-100, 100:-100]\n#     return img[min(x):max(x), min(y):max(y)]\n\n# photo_img_path = photo_path + img_photo[num]\n# plt.imshow(cv2.imread(photo_img_path))\n# plt.show()\n# plt.imshow(prepare_img(photo_img_path))\n# plt.show()","03fb4f57":"# img = cv2.imread(finded_img_path)\n# plt.imshow(img)","44fe94ea":"# scale = A.Compose([A.Downscale(scale_min=0.1, scale_max=0.9, interpolation=0, always_apply=True,p = 1.0)])\n# plt.imshow(scale(image = img)['image'])","8b000b1f":"# num = 5\n# img_path = photo_path + img_photo[num]\n# color_low = np.array([127 , 127, 127])\n# color_high = np.array([255, 255, 255])\n# img = cv2.imread(img_path, 0)\n\n# hsv_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2HSV)\n\n# curr_mask = cv2.inRange(hsv_img, color_low, color_high)\n# hsv_img[curr_mask > 0] = ([200,200,200])\n# RGB_again = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n# gray = cv2.cvtColor(RGB_again, cv2.COLOR_RGB2GRAY)\n# #90 \u0431\u044b\u043b\u043e \u0440\u0430\u043d\u044c\u0448\u0435\n# ret, threshold = cv2.threshold(gray, np.mean(gray), 255, 0)\n# threshold = threshold[100:-100, 100:-100]\n# x, y = np.where(threshold < 10)\n\n# x","594d8a93":"# Evaluete","f8087b1f":"# Torch"}}