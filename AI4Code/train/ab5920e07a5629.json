{"cell_type":{"e776d7ba":"code","5004938a":"code","d7a885fe":"code","5b83432e":"code","035e3036":"code","85defc81":"code","7a6e4779":"code","9d740b72":"code","4aa8fe33":"code","a79f7256":"code","16a82024":"code","c4fcd395":"code","57a51eb5":"code","ec797ab8":"code","23417913":"code","24f3b80a":"code","33e2018a":"code","1695ead6":"code","921b6c2a":"code","758d0c6e":"code","3bf42150":"code","ecfe098b":"code","9a936688":"code","197e3d0e":"code","ab3058d1":"markdown","9168c182":"markdown","bedcf4c7":"markdown","4dd0a7d1":"markdown","229a3f5e":"markdown","fb26d67f":"markdown","0493e1ae":"markdown"},"source":{"e776d7ba":"import numpy as np \nimport pandas as pd\n\nimport random\nimport datetime\nimport seaborn as sns\n\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Dense,Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom keras.losses import binary_crossentropy\nfrom keras import regularizers, optimizers\nfrom keras.optimizers import Adam\n\nfrom keras.applications import ResNet50\n#from keras.applications.resnet_v2 import ResNet50V2\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.nasnet import NASNetMobile\n\n\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger,ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndef append_ext(fn):\n    return fn+\".png\"\n\ndef remove_ext(fn):\n    return fn[:-4]","5004938a":"# Set a seed value\nseed_value= 7 \n\n# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\nos.environ['PYTHONHASHSEED']=str(seed_value)\n# 2. Set `python` built-in pseudo-random generator at a fixed value\nrandom.seed(seed_value)\n# 3. Set `numpy` pseudo-random generator at a fixed value\nnp.random.seed(seed_value)\n# 4. Set `tensorflow` pseudo-random generator at a fixed value\ntf.set_random_seed(seed_value)\n# 5 Configure a new global `tensorflow` session\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)","d7a885fe":"train_labels=pd.read_csv('..\/input\/imet-2019-fgvc6\/train.csv', dtype=str)\n#Changing the attribute ids into lists instead of str seperated by a ' ' to be able to count them\ntrain_labels['attribute_ids']=train_labels['attribute_ids'].str.split(' ')\ntrain_labels[\"id\"]=train_labels[\"id\"].apply(append_ext)\n\ntest_labels=pd.read_csv('..\/input\/imet-2019-fgvc6\/sample_submission.csv', dtype=str)\ntest_labels[\"id\"]=test_labels[\"id\"].apply(append_ext)\n\nprint('train : \\n', train_labels.head())\nprint('\\ntest : \\n', test_labels.head())\n\nprint('\\ntrain shape: ', len(train_labels))\nprint('\\ntest shape: ', len(test_labels))","5b83432e":"labels = pd.read_csv('..\/input\/imet-2019-fgvc6\/labels.csv', dtype=str)\nprint('labels : ', '\\n', labels.head())\n\nprint('\\nlabels len :', len(labels))","035e3036":"datagen=ImageDataGenerator(rescale=1.\/255.,validation_split=0.2)","85defc81":"B_size = 128\nTarget_size = (96,96) \n\ntrain_generator=datagen.flow_from_dataframe(\n                                            dataframe=train_labels,\n                                            directory=\"..\/input\/imet-2019-fgvc6\/train\/\",\n                                            x_col=\"id\",\n                                            y_col=\"attribute_ids\",\n                                            subset=\"training\",\n                                            batch_size=B_size,\n                                            seed=seed_value,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n                                            target_size=Target_size\n)\n\nvalid_generator=datagen.flow_from_dataframe(\n                                            dataframe=train_labels,\n                                            directory=\"..\/input\/imet-2019-fgvc6\/train\/\",\n                                            x_col=\"id\",\n                                            y_col=\"attribute_ids\",\n                                            subset=\"validation\",\n                                            batch_size=B_size,\n                                            seed=seed_value,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n                                            target_size=Target_size\n)\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255.)\n\ntest_generator=test_datagen.flow_from_dataframe(\n                                                dataframe=test_labels,\n                                                directory=\"..\/input\/imet-2019-fgvc6\/test\/\",\n                                                x_col=\"id\",\n                                                y_col=None,\n                                                batch_size=B_size,\n                                                seed=seed_value,\n                                                shuffle=False,\n                                                class_mode=None,\n                                                target_size=Target_size\n)","7a6e4779":"train_generator.n\/\/train_generator.batch_size","9d740b72":"gamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","4aa8fe33":"def f2_score(y_true, y_pred):\n    beta = 2\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n    \n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    \n    return K.mean(((1+beta**2)*precision*recall) \/ ((beta**2)*precision+recall+K.epsilon()))","a79f7256":"#Callbacks\n\ncheckpoint = ModelCheckpoint(filepath='weights_test.hdf5',\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          mode='auto')","16a82024":"def make_model(model_choice, model_name, input_tensor, weights_link, nb_epoch):\n    '''Function to create a model\n    Input:\n    - model_choice          for ex: VGG19(include_top=False, input_tensor=input_tensor)\n    - model_name            (str), name that will be given to the model in tensorboard\n    - input_tensor          Input(width_image, height_image, nb_channels)\n    - weights_link          (str) since no internet, link to the dataset with weights\n    - nb_epoch              (int) number of epoch to train on\n    \n    Output:\n    - model made with keras.model.Model'''\n    \n    base_model = model_choice\n    base_model.load_weights(weights_link)\n    base_model.trainable = False\n    x = base_model(input_tensor)\n    out = Flatten()(x)\n    out = Dense(1103, activation=\"softmax\")(out)\n    model = Model(input_tensor, out)\n    \n    model.compile(optimizer=Adam(0.001), loss=focal_loss, metrics=[f2_score])\n    model.summary()\n    \n    history = model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=nb_epoch,\n                    callbacks=[checkpoint, earlystop])\n\n    \n    return model, history","c4fcd395":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size","57a51eb5":"number_epoch = 15\nwidth, height = Target_size\ninput_tensor = Input((width, height, 3))\n\nweights_link = ('..\/input\/inceptionresnetv2\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n\nInceptionResNetV2_model, history = make_model(InceptionResNetV2(weights=None,\n                                                       include_top=False,\n                                                       input_tensor=input_tensor),\n                                              'InceptionResNetV2',\n                                              input_tensor,\n                                              weights_link,\n                                              nb_epoch = number_epoch)","ec797ab8":"model_name = 'InceptionResNetV2'\n\nfig, ax =plt.subplots(1,2, figsize=(15, 8))\n    \nax[0].plot(history.history['f2_score'])\nax[0].plot(history.history['val_f2_score'])\nax[0].set_title(model_name +  ' Model F2 score')\nax[0].legend([model_name +  ' Training',model_name +  ' Validation'])\n#ax[0].ylabel('F2 score')\n#ax[0].xlabel('epoch')\n    \nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title(model_name +  ' Model loss')\nax[1].legend([model_name +  ' Training',model_name +  ' Validation'])\n#ax[1].ylabel('Loss')\n#ax[1].xlabel('epoch')","23417913":"test_generator.reset()\npred=InceptionResNetV2_model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST+1,\nverbose=1)","24f3b80a":"max_of_each_img=[]\nfor i in range(len(pred)):\n    max_of_each_img.append(pred[i].max())\nsns.distplot(max_of_each_img)","33e2018a":"threshold_count = 0.03\n\nnb_label_over_thresh_of_each_img=[]\nfor i in range(len(pred)):\n    nb_labels = 0\n    for prediction in range(len(pred[i])):\n        if pred[i][prediction]>=threshold_count:\n            nb_labels+=1\n    nb_label_over_thresh_of_each_img.append(nb_labels)\nsns.distplot(nb_label_over_thresh_of_each_img)\nprint('threshhold used is: ', threshold_count)\nprint('There are {} images without labels'.format(nb_label_over_thresh_of_each_img.count(nb_label_over_thresh_of_each_img==0)))","1695ead6":"import operator\n\nthreshold = 0.03\n\nlabel_for_test_img = []\nfor i in range(len(pred)):\n    #list to store the label number over the threshold\n    label_number={}\n    for prediction in range(len(pred[i])):\n        if pred[i][prediction]>=threshold:\n            label_number[prediction] = prediction\n    sorted_label_number = sorted(label_number.items(), key=operator.itemgetter(1), reverse=True)\n    label_for_test_img.append([i[0] for i in sorted_label_number[:5]])\n#    print('for image {} labels are: {}'.format(i, label_number))\n\nlabel_for_test_img[:10]","921b6c2a":"valid_generator.reset()\npred_valid=InceptionResNetV2_model.predict_generator(valid_generator,\n                                   steps=STEP_SIZE_VALID+1,\n                                   verbose=1)","758d0c6e":"label_for_valid_img = []\nfor i in range(len(pred_valid)):\n    #list to store the label number over the threshold\n    label_number={}\n    for prediction in range(len(pred_valid[i])):\n        if pred_valid[i][prediction]>=threshold:\n            label_number[prediction] = prediction\n    sorted_label_number = sorted(label_number.items(), key=operator.itemgetter(1), reverse=True)\n    label_for_valid_img.append([i[0] for i in sorted_label_number[:5]])\n#    print('for image {} labels are: {}'.format(i, label_number))\n\nlabel_for_valid_img[:10]","3bf42150":"test_labels[\"id\"]=test_labels[\"id\"].apply(remove_ext)","ecfe098b":"test_list = pd.Series([list(x) for x in label_for_test_img])\ntest_str = test_list.apply(lambda x: [str(i) for n,i in enumerate(x)])\ntest_str = test_str.apply(lambda l: ' '.join(l))","9a936688":"results=pd.DataFrame({\"id\":test_labels[\"id\"],\n                      \"attribute_ids\":test_str})\nresults.to_csv(\"submission.csv\",index=False)","197e3d0e":"results.head()","ab3058d1":"In order to compare the performances of models, it is important to seed everything. This means random and numpy, but also tensorflow and Keras. The following code was taken from [this article](https:\/\/towardsdatascience.com\/properly-setting-the-random-seed-in-machine-learning-experiments-7da298d1320b) from Cecelia Shao. The article is worth a read for a more in depth look of the effects of correctly seeding.","9168c182":"v1: last activation changed to softmax","bedcf4c7":"Updates to do to improve performances:\n- take into account different image sizes\n- perform data augmentation (but not all images can be augmented the same way. Ex: portrait cannot  be flipped vertically. Some abstract objects \/ representations could).","4dd0a7d1":"focal loss taken from [this Kernel from KeepLearning](https:\/\/www.kaggle.com\/mathormad\/resnet50-v2-keras-focal-loss-mix-up)","229a3f5e":"The EDA is done in a [separate Kernel](https:\/\/www.kaggle.com\/maxlenormand\/first-eda-to-get-started)\n\nThis is the first iterations I am doing, simply to have a relevant predicted output. Future work will consist of improving this along multiple aspects.","fb26d67f":"f2_score taken from [this Kernel from Alexander Teplyuk](https:\/\/www.kaggle.com\/ateplyuk\/keras-starter)","0493e1ae":"pred is of shape  7443 x 1103: 7443 test examples, and 1103 different labels.\n\nNext step: apply threshold, if over a certain threshold, then consider it as a label. Otherwise, not."}}