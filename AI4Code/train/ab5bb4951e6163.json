{"cell_type":{"00dc2813":"code","997b1e0b":"code","1c34e6ae":"code","f740568a":"code","b90ea33b":"code","bc735ff1":"code","57b0e48d":"code","e636eb58":"code","a6be0078":"code","5b088d61":"code","58ec67cc":"code","d36c4250":"code","7bcf6bfc":"code","6386e29e":"markdown","b1ddfacc":"markdown","9e3e4d8d":"markdown","14dbe586":"markdown","bb4a3bab":"markdown","21da88ee":"markdown","3a6a13ba":"markdown","26293cca":"markdown","05086cac":"markdown","adfacf9e":"markdown","0a2cbab0":"markdown","12549edb":"markdown"},"source":{"00dc2813":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","997b1e0b":"# importing the vgg16 model from keras\nfrom keras.applications.vgg16 import VGG16\n# loading the model \nmodel = VGG16()\n# summarize the model\nmodel.summary()\n","1c34e6ae":"# Pretrained model as a direct classifier\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.applications.vgg16 import decode_predictions\nimport matplotlib.pyplot as plt\n\n\n\n# load an image from file\nimage = load_img('..\/input\/janata-hack-image-classification\/images\/images\/1001.jpg', target_size = (224,224))\nimg = image\nplt.imshow(img)\n# convert image to numpy array\nimage = img_to_array(image)\n\n# reshape the image\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n\n# preprocess the data for VGG Model (like pixel scaling)\nimage = preprocess_input(image)\n\n# loading the model\nmodel = VGG16()\n\n# predict the probabilities across all output classes\ny_predict = model.predict(image)\n\n# converting probabilities to class labels\ny_predict = decode_predictions(y_predict)\n\n# predicting the class label with highest probability\ny_predict = y_predict[0][0]\n\n# printing the label\nprint('The image is of {} with probability {}%'.format(y_predict[1], y_predict[2]*100))","f740568a":"data = pd.read_csv('..\/input\/janata-hack-image-classification\/train.csv')\ntrain_df = data\ndata.dtypes","b90ea33b":"\n# Preparing the training data and validation data sets\n\ndata = pd.read_csv('..\/input\/janata-hack-image-classification\/train.csv', dtype = str)\ntrain_df = data\n# train_df[\"emergency_or_not\"] = train_df[\"emergency_or_not\"].replace({0: 'not_emergency', 1: 'emergency'})\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip = True,\n    validation_split = 0.2)\ntraining_set = train_datagen.flow_from_dataframe(\n    train_df, \n    \"..\/input\/janata-hack-image-classification\/images\/images\", \n    x_col='image_names',\n    y_col='emergency_or_not',\n    target_size= (224,224),\n    class_mode='categorical',\n    shuffle = True,\n    batch_size = 32,\n    subset = 'training')\n\nvalidation_set = train_datagen.flow_from_dataframe(\n    train_df, \n    \"..\/input\/janata-hack-image-classification\/images\/images\", \n    x_col='image_names',\n    y_col='emergency_or_not',\n    target_size= (224,224),\n    class_mode='categorical',\n    shuffle = True,\n    batch_size = 32,\n    subset = 'validation')","bc735ff1":"\n# Preparing test data\ntest_data = pd.read_csv('..\/input\/janata-hack-image-classification\/test_vc2kHdQ.csv')\ntest_df = test_data\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_set = test_datagen.flow_from_dataframe(\n        test_df,\n        '..\/input\/janata-hack-image-classification\/images\/images',\n        x_col = 'image_names',\n        y_col = None,\n        target_size=(224,224),\n        batch_size=32,\n        shuffle = False,\n        class_mode = None)\n","57b0e48d":"cnn = tf.keras.models.Sequential()\n\ncnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 7, activation = 'relu', input_shape = [224,224,3])) #Convolution\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n\ncnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu', padding = 'same'))  #Convolution\ncnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu', padding = 'same'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))                       \n\ncnn.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu', padding = 'same'))  #Convolution\ncnn.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu', padding = 'same'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))                       \n\ncnn.add(tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu', padding = 'same'))  #Convolution\ncnn.add(tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu', padding = 'same'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)) \n\ncnn.add(tf.keras.layers.Flatten())\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\ncnn.add(tf.keras.layers.Dense(units = 2,   activation = 'softmax'))                                             ","e636eb58":"#Early stopping to get opimal epochs\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\nES = EarlyStopping(monitor = 'val_accuracy', mode = 'max', verbose = 1, patience = 8)\nMC = ModelCheckpoint('best_cnn.h5', monitor = 'val_accuracy')\n\ncnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\ncnn.fit(x = training_set, validation_data = validation_set, epochs = 30, callbacks = [ES, MC])\n","a6be0078":"from keras.models import load_model\nbest_cnn = load_model('best_cnn.h5')\n\npredict_cnn = best_cnn.predict_classes(test_set)\nsubmission_cnn = pd.DataFrame()\nsubmission_cnn['image_names'] = test_df['image_names']\nsubmission_cnn['emergency_or_not'] = predict_cnn\nsubmission_cnn.to_csv('submission_cnn.csv', index = False)","5b088d61":"# Loading the VGG-16, with pre trained weights\n# The fully connected layers are removed \nmodel = VGG16(include_top = False, weights = 'imagenet', input_shape = (224,224,3))\n# Existing layers are not trained\nfor layer in model.layers:\n    layer.trainable = False\n\n# Adding more layers to the model\nflatten = tf.keras.layers.Flatten()(model.output) #flattening  the last layers in the above model\ndense_1 = tf.keras.layers.Dense(units = 200, activation= 'relu')(flatten)\ndense_2 = tf.keras.layers.Dense(units = 200, activation= 'relu')(dense_1)\ndense_3 = tf.keras.layers.Dense(units = 200, activation= 'relu')(dense_2)\n\n# output layer neurons is kept to 1 since it is binary classification problem\noutput = tf.keras.layers.Dense(units = 2, activation = 'softmax')(dense_3) \nmodel  = tf.keras.Model(inputs = model.input, outputs = output)\nmodel.summary()\n","58ec67cc":"#Early stopping to get opimal epochs\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\nES = EarlyStopping(monitor = 'val_accuracy', mode = 'max', verbose = 1, patience = 4)\nMC = ModelCheckpoint('best_model.h5', monitor = 'val_accuracy')\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.fit(x = training_set, validation_data = validation_set, epochs = 15, callbacks = [ES, MC])","d36c4250":"from keras.models import load_model\nbest_model = load_model('best_model.h5')","7bcf6bfc":"predict_prob = best_model.predict(test_set)\npredict_model = np.argmax(predict_prob,axis=1)\npredict_model\n\nsubmission = pd.DataFrame()\nsubmission['image_names'] = test_df['image_names']\nsubmission['emergency_or_not'] = predict_model\nsubmission.to_csv('submission_model.csv', index = False)","6386e29e":"Here, the network predicts that the image is of a limousine with probability 48% which is close to a 'non emergency vehicle'. The displayed image also shows that the image closely resembles a limousine. Hence for a more accurate prediction, we could tailor our own network. ","b1ddfacc":"### Training the CNN","9e3e4d8d":"# VGG-16 Model \n","14dbe586":"### Data Preprocessing\n\nImage augmentation is done to avoid overfitting on the train data. Augmentation includes shearing, zooming, shifting etc. Also, about 20% data is taken as validation set for getting a best fit model. ","bb4a3bab":"# Classification using a normal CNN","21da88ee":"# Using VGG-16 directly as a classifier\nVGG-16 was orginally trained on thousands classes of real life images. That is why, the number of neurons at the output is set as 1000. Now, eventhough our problem is to classify emergency and non emergency vehicles (two classes), we could just pass one of the images in the dataset through the pre trained network to test what the network would predict.  Here I haven't performed any training.\n","3a6a13ba":"# Using VGG 16 as feature extractor\n\nIn this case, I will be using the VGG 16 as a feature extractor. It means that, I will not be using the entire VGG-16 as a classifier as done above. Instead, I kept initial convolutional and max pooling layers as such and removed fully connected output dense layers from the pre trained network. This section can act as a feature extractor. If we pass an image through the network, we get complex abstract features at the output of convolutional layers. Now, these features can be passed through another sequence of dense layers which has been tailored according to our requirements. During training process, only fully connected layer weights are updated and the convolutional layers are kept intact. Otherwise, it would take humongous  amount of time to complete the training. ","26293cca":"Using the above model, it was able to attain 93% testing accuracy. With additional ensemble techniques, it is possible to improve the performance further","05086cac":"# Emergency and Non Emergency Vehicle Classification\n\nThis note book is done as a part of Janatahack hackathon conducted by Analytics Vidhya (late submission). I took this as a learning oppurtunity to study how transfer learning can be applied on computer vision applications like image classification. In transfer learning, a pretrained neural network which was trained for one application has been applied on another application. I learned the transfer learning using keras from the blog post on  [Transfer Learning in Keras with Computer Vision Models by Jason Brownlee.](https:\/\/machinelearningmastery.com\/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models\/) and the Youtube tutorial by [Krish Naik](https:\/\/www.youtube.com\/watch?v=zBOavqh3kWU). \n\nIn the following notebook, I have used:\n\n* VGG 16 as a direct classifier - Here I passed a test image through the already pre trained network to know what the network would predict\n* A normal CNN - Classification using a  normal CNN\n* VGG 16 as a feature extractor on a neural network - Instead of taking the entire network, I kept the convolutional and maxpooling layers and modified the dense layers according to our requirements","adfacf9e":"The above model shows about 81% testing accuracy which can be verified by uploading the test predictions in this [link](https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-computer-vision-hackathon\/True\/#About)","0a2cbab0":"### CNN Modelling","12549edb":"### Prediction on Test data"}}