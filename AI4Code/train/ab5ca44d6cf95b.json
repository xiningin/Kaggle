{"cell_type":{"f163e9ba":"code","998f01b9":"code","541cd582":"code","df97b8b0":"code","ba0da1e4":"code","0220d264":"code","f2b9d5d3":"code","85d93a2f":"code","a4738785":"code","5e1c96b2":"code","70917f83":"code","60f4dca8":"code","a38d9b7b":"code","c50f279c":"code","fa8d4b9a":"code","fe20f8c3":"code","3cfd8919":"code","ad408018":"code","98bb903b":"code","74a68ce6":"code","a151c691":"code","d5036f3c":"code","9a8ac51d":"code","ee89c408":"code","5b6639db":"code","78e391b5":"code","4f9bd3b9":"code","4cc7b3c6":"code","c68f97e2":"code","5473bccd":"code","2aeabbcf":"code","8cee9ef5":"code","9ada86bd":"code","0d79ed78":"code","347dc715":"code","65125702":"code","d524f747":"code","74770cb4":"code","2495f9f5":"code","0ac318e3":"code","21e74c6c":"code","7e59d056":"code","792c8825":"code","0357fc02":"markdown","1f6c7774":"markdown","f3654ef2":"markdown","3f134090":"markdown","0eebfb31":"markdown","18ad9cd1":"markdown","61588c15":"markdown","b11e4f61":"markdown","9728b514":"markdown","4658654a":"markdown","ab3fb136":"markdown","e63c48f2":"markdown","10ab5682":"markdown","9b69809b":"markdown","6ae825bd":"markdown","cf74ab80":"markdown","d4baeed9":"markdown","4855062a":"markdown"},"source":{"f163e9ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","998f01b9":"\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nfrom glob import glob\nimport gc\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image,display\nimport seaborn as sns\nimport matplotlib.image as mpimg\nimport scipy.spatial.distance as dist\nfrom sklearn.model_selection import train_test_split\nfrom skimage.measure import compare_ssim\nimport os\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","541cd582":"tr = pd.read_csv('\/kaggle\/input\/landmark-recognition-2020\/train.csv')\ntr.head()","df97b8b0":"print(tr.landmark_id.nunique())\nprint(np.max(tr.landmark_id))\nprint(np.min(tr.landmark_id))","ba0da1e4":"tab = tr.landmark_id.value_counts()\nprint(tab.head(5))\nprint(tab.tail(5))","0220d264":"tr[tr.landmark_id==197219]","f2b9d5d3":"mainPath = '\/kaggle\/input\/landmark-recognition-2020\/train\/'\nall_img_paths = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0], '*.jpg'))]\nids = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0]))]\nall_filenames = []\nfor filepath in all_img_paths:\n    FileName = os.path.basename(filepath)\n    all_filenames.append(FileName)\npath_dict = dict(zip(all_filenames,all_img_paths))","85d93a2f":"df=pd.DataFrame()\ndf['fname'] = all_filenames\ndf['pname'] = all_img_paths\ndf['id'] = list(map(lambda x: x[:-4], df.fname))\ndf.head()","a4738785":"print(df.shape)\ntrain = pd.merge(tr, df, on = 'id')\ntrain.head()","5e1c96b2":"mainPath = '\/kaggle\/input\/landmark-recognition-2020\/test\/'\nall_img_paths = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0], '*.jpg'))]\nids = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0]))]\nall_filenames = []\nfor filepath in all_img_paths:\n    FileName = os.path.basename(filepath)\n    all_filenames.append(FileName)\npath_dict = dict(zip(all_filenames,all_img_paths))\n\ntest=pd.DataFrame()\ntest['fname'] = all_filenames\ntest['pname'] = all_img_paths\nprint(test.head())\n\ntest['id'] = list(map(lambda x: x[:-4], test.fname))\nprint(test.head())","70917f83":"test.shape","60f4dca8":"from PIL import Image\nimage = Image.open(train.pname[0])\nprint(image.size)\ndisplay(image)","a38d9b7b":"image = Image.open(train.pname[100])\nprint(image.size)\ndisplay(image)","c50f279c":"image = Image.open(test.pname[0])\nprint(image.size)\ndisplay(image)","fa8d4b9a":"image = Image.open(test.pname[100])\nprint(image.size)\ndisplay(image)","fe20f8c3":"#os.listdir('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/')\ndef imtocsv(data):\n    from PIL import Image\n    nrow = []\n    ncol = []\n    pix = []\n    for j in data.pname:\n        image = Image.open(j)\n        nrow.append(image.size[0])\n        ncol.append(image.size[1])\n        pix.append(image.size[0]*image.size[1])\n    out = {'nrow': nrow, 'ncol': ncol, 'pix':pix}\n    df= pd.DataFrame(out)\n    df.insert(0,'id',data.id,True)\n    return df","3cfd8919":"out=imtocsv(train)\ntrain_50 = pd.merge(train, out, on = 'id')\ntrain_50.head()","ad408018":"del out\nout=imtocsv(test)\ntest_50 = pd.merge(test, out, on = 'id')\ntest_50.head()","98bb903b":"train_50.to_csv('train_summary.csv', index=False)\ntest_50.to_csv('test_summary.csv', index=False)","74a68ce6":"import matplotlib.pyplot as plt\n%matplotlib inline","a151c691":"plt.hist(train_50.pix) # add color='green',bins=20\nplt.xlabel('Pixels')\nplt.ylabel('Freq')\nplt.title('Pixel value distribution in train data')\nplt.show()","d5036f3c":"plt.hist(test_50.pix) # add color='green',bins=20\nplt.xlabel('Pixels')\nplt.ylabel('Freq')\nplt.title('Pixel value distribution in test data')\nplt.show()","9a8ac51d":"plt.hist(train_50.pix[train_50.landmark_id == 138982]) # add color='green',bins=20\nplt.xlabel('Pixels')\nplt.ylabel('Freq')\nplt.title('Pixel value distribution in train data with landmark id 138982')\nplt.show()","ee89c408":"print('Maximum number of pixels: ', train_50.pix.max())\nprint('Minimum number of pixels: ', train_50.pix.min())\nprint('Maximum number of pixels: ', test_50.pix.max())\nprint('Minimum number of pixels: ', test_50.pix.min())","5b6639db":"tmp = train_50.loc[train_50.pix == train_50.pix.max()]\ntmp.head()","78e391b5":"pname = list(tmp.pname)\nlen(pname)","4f9bd3b9":"image = Image.open(pname[0])\nprint(image.size)\ndisplay(image)","4cc7b3c6":"image = Image.open(pname[1])\nprint(image.size)\ndisplay(image)","c68f97e2":"image = Image.open(pname[2])\nprint(image.size)\ndisplay(image)","5473bccd":"image = Image.open(pname[7590])\nprint(image.size)\ndisplay(image)","2aeabbcf":"image = Image.open(pname[7591])\nprint(image.size)\ndisplay(image)","8cee9ef5":"fig=plt.figure(figsize=(12, 10))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    img = Image.open(pname[i])\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","9ada86bd":"tmp = train_50.loc[train_50.pix == train_50.pix.min()]\ntmp.head()","0d79ed78":"pname = list(tmp.pname)\nprint(len(pname))\nimage = Image.open(pname[0])\nprint(image.size)\ndisplay(image)","347dc715":"tmp = test_50.loc[test_50.pix == test_50.pix.max()]\nprint(tmp.head())\npname = list(tmp.pname)\nprint('\\n',len(pname))","65125702":"image = Image.open(pname[0])\nprint(image.size)\ndisplay(image)","d524f747":"image = Image.open(pname[1])\nprint(image.size)\ndisplay(image)","74770cb4":"image = Image.open(pname[13])\nprint(image.size)\ndisplay(image)","2495f9f5":"image = Image.open(pname[12])\nprint(image.size)\ndisplay(image)","0ac318e3":"fig=plt.figure(figsize=(12, 10))\ncolumns = 4\nrows = 3\nfor i in range(1, columns*rows +1):\n    img = Image.open(pname[i])\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","21e74c6c":"tmp = test_50.loc[test_50.pix == test_50.pix.min()]\nprint(tmp.head())\npname = list(tmp.pname)\nprint('\\n',len(pname))","7e59d056":"image = Image.open(pname[0])\nprint(image.size)\ndisplay(image)","792c8825":"train_50.to_csv('landmark_train_facts.csv', index = False)\ntest_50.to_csv('landmark_test_facts.csv', index = False)","0357fc02":"### Lets go through some imaages in test data with low resolution","1f6c7774":"7592 Images with high resolution in Train data","f3654ef2":"### High and low resolution images in train and test sets","3f134090":"### Lets go through some imaages in train data with high resolution","0eebfb31":"There are 14 images in test data with high resolution.","18ad9cd1":"### Looks like there might be some relationship between train images with high resolution.\nLet's display multiple images together","61588c15":"### There might be some relationship between test images with high resolution.\nLet's display multiple images together","b11e4f61":"### Lets go through some imaages in test data with high resolution","9728b514":"landmark_id == 138982 has maximum count in train data. Let's have a look at the pixel value distribution for this landmark.","4658654a":"## Hope you will like this notebook.\u00a0\n\n\n# Suggestions please...","ab3fb136":"This is the image in training data with low resolation.","e63c48f2":"Let's have a look of images with high and low resolution.","10ab5682":"Only one image in test data with low resolution.","9b69809b":"Only one image with low resolution. ","6ae825bd":"### Lets go through some imaages in train data with low resolution","cf74ab80":"imd=imtocsv(train.iloc[0:4,:],5)\ntrain_50 = pd.merge(train.iloc[0:4,:], imd, on = 'id')\ntrain_50.head()","d4baeed9":"Have a look of some images from train and test data","4855062a":"This is the image with low resolution in test data."}}