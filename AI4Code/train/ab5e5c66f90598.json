{"cell_type":{"6f589877":"code","fb81314c":"code","b6851f2c":"code","5e692a34":"code","5e01d8d1":"code","91a8e8e0":"code","f488b3ce":"code","d762e164":"code","3131cfff":"code","5dce78d8":"code","892544f4":"code","b4fdcbca":"code","ee109864":"code","65c3e7b2":"code","6c4c76bc":"code","3763e99d":"code","1e12454c":"code","9d0eb346":"code","56629231":"code","0d6a6a6c":"code","cab60dc0":"code","446d1541":"code","a0bb7e2d":"code","1ee4ac98":"code","bbf214be":"code","789b2bf2":"code","a1838315":"code","614dccec":"code","19779e36":"code","a9337a10":"code","950c5941":"code","4b2ec114":"code","dec9a325":"code","5fee27b7":"code","c955861f":"code","e045b2c8":"code","79ad6289":"code","b9911d39":"code","553dae6f":"code","87102d54":"code","0352d8f3":"code","77a03b5c":"code","9d5dc1e8":"code","e55fbe00":"code","cc9548a8":"code","9a8dadf7":"code","c946620c":"code","aef3e9e0":"code","ec23413e":"code","2987dd2c":"code","3aba7691":"code","8159a1b2":"code","2b3e9ad7":"code","2697bd4f":"code","b00c435c":"code","d20203cf":"code","0ed5da8c":"code","285ec378":"code","a50d036c":"code","04e18755":"code","64034a97":"code","9ad22dc5":"code","0795bcab":"code","985c66c7":"code","82ea7cde":"code","5c28b2f0":"code","f361e4e0":"code","630a7eae":"code","e549c0f8":"code","a92f8502":"code","be8e1590":"code","c216b192":"code","17cd3cfd":"code","df90445d":"code","e64025e7":"code","8b901e39":"code","46c335d9":"code","d0621cb9":"code","06282af8":"markdown","3cb37d64":"markdown","5784e5df":"markdown","f6031093":"markdown","b054abbf":"markdown","a3dfb97c":"markdown","3d692ef1":"markdown","c1059f53":"markdown","6bbeba02":"markdown","adebe861":"markdown","05950ea1":"markdown","a677236c":"markdown"},"source":{"6f589877":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns","fb81314c":"file_path='..\/input\/dsn-ai-oau-july-challenge\/train.csv'\ndf=pd.read_csv(file_path)\ndf.head()","b6851f2c":"path='..\/input\/dsn-ai-oau-july-challenge\/test.csv'\ndf2=pd.read_csv(path)\ndf2.head()\n# df2.isnull().sum()","5e692a34":"df.describe(include='all')","5e01d8d1":"df.isnull().sum()","91a8e8e0":"df2.isnull().sum()","f488b3ce":"#check the mode of the supermarket size values\ndf['Supermarket _Size'].value_counts().idxmax()","d762e164":"df2['Supermarket _Size'].value_counts().idxmax()","3131cfff":"#replace the missing 'Supermarket_Size' values by the most frequent \ndf[\"Supermarket _Size\"].replace(np.nan, \"Medium\", inplace=True)\ndf2[\"Supermarket _Size\"].replace(np.nan, \"Medium\", inplace=True)","5dce78d8":"df.isnull().sum()","892544f4":"df2.isnull().sum()","b4fdcbca":"df.Product_Weight=df.sort_values(['Product_Identifier','Product_Weight']).Product_Weight.ffill( )\n","ee109864":"df2.Product_Weight=df.sort_values(['Product_Identifier','Product_Weight']).Product_Weight.ffill( )","65c3e7b2":"df.isnull().sum()","6c4c76bc":"df.isnull().sum()","3763e99d":"# group 'Product_Identifier', 'Product_Weight' by 'Product_Identifier' so as to replace nan with the mean\n#of the corresponding 'Product_Identifier'\ndf_gptest = df[['Product_Identifier', 'Product_Weight']]\ngrouped_test1 = df_gptest.groupby(['Product_Identifier'],as_index=False).mean() ","1e12454c":"df.sort_values(['Product_Identifier','Supermarket_Identifier']).head()","9d0eb346":"df.dtypes","56629231":"grouped_1=df[['Product_Type','Supermarket_Identifier','Product_Supermarket_Sales']]\ngrpd_1=grouped_1.groupby(['Product_Type','Supermarket_Identifier'],as_index=False).mean()\ngrpd_1=grpd_1.sort_values(['Product_Type','Product_Supermarket_Sales'], ascending=False)\ngrpd_1.head()","0d6a6a6c":"grouped_pivot = grpd_1.pivot(index='Product_Type',columns='Supermarket_Identifier')\ngrouped_pivot","cab60dc0":"fig, ax = plt.subplots()\nim = ax.pcolor(grouped_pivot, cmap='RdBu')\n\n#label names\nrow_labels = grouped_pivot.columns.levels[1]\ncol_labels = grouped_pivot.index\n\n#move ticks and labels to the center\nax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\nax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n\n#insert labels\nax.set_xticklabels(row_labels, minor=False)\nax.set_yticklabels(col_labels, minor=False)\n\n#rotate label if too long\nplt.xticks(rotation=90)\n\nfig.colorbar(im)\nplt.show()","446d1541":"grouped_2=df[['Supermarket_Type', 'Product_Supermarket_Sales']]\ngrpd_2=grouped_2.groupby(['Supermarket_Type'],as_index=False).mean()\ngrpd_2","a0bb7e2d":"sns.boxplot(x=\"Supermarket_Type\", y=\"Product_Supermarket_Sales\", data=df)","1ee4ac98":"grpd_2=grouped_2.groupby(['Supermarket_Type'],as_index=False)\nf_val, p_val = stats.f_oneway(grpd_2.get_group('Supermarket Type1')['Product_Supermarket_Sales'], grpd_2.get_group('Supermarket Type2')['Product_Supermarket_Sales'], grpd_2.get_group('Supermarket Type3')['Product_Supermarket_Sales'], grpd_2.get_group('Grocery Store')['Product_Supermarket_Sales'])  \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val)   ","bbf214be":"df['Supermarket_Type'].value_counts()","789b2bf2":"grouped_3=df[['Supermarket_Location_Type', 'Product_Supermarket_Sales']]\ngrpd_3=grouped_3.groupby(['Supermarket_Location_Type'],as_index=False).mean()\ngrpd_3","a1838315":"df['Supermarket_Location_Type'].value_counts()","614dccec":"sns.boxplot(x=\"Supermarket_Location_Type\", y=\"Product_Supermarket_Sales\", data=df)","19779e36":"grpd_3=grouped_3.groupby(['Supermarket_Location_Type'],as_index=False)\nf_val, p_val = stats.f_oneway(grpd_3.get_group('Cluster 1')['Product_Supermarket_Sales'], grpd_3.get_group('Cluster 2')['Product_Supermarket_Sales'], grpd_3.get_group('Cluster 3')['Product_Supermarket_Sales'])  \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val)   ","a9337a10":"df['Product_Fat_Content'].value_counts()","950c5941":"grouped_4=df[['Product_Fat_Content', 'Product_Supermarket_Sales']]\ngrpd_4=grouped_4.groupby(['Product_Fat_Content'],as_index=False).mean()\ngrpd_4","4b2ec114":"sns.boxplot(x='Product_Fat_Content', y='Product_Supermarket_Sales', data=df)","dec9a325":"grpd_4=grouped_4.groupby(['Product_Fat_Content'],as_index=False)\nf_val, p_val = stats.f_oneway(grpd_4.get_group('Low Fat')['Product_Supermarket_Sales'], grpd_4.get_group('Normal Fat')['Product_Supermarket_Sales'], grpd_4.get_group('Ultra Low fat')['Product_Supermarket_Sales'])  \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val)   ","5fee27b7":"df['Supermarket _Size'].value_counts()","c955861f":"grouped_5=df[['Supermarket _Size', 'Product_Supermarket_Sales']]\ngrpd_5=grouped_5.groupby(['Supermarket _Size'],as_index=False).mean()\ngrpd_5","e045b2c8":"sns.boxplot(x='Supermarket _Size', y='Product_Supermarket_Sales', data=df)","79ad6289":"grpd_5=grouped_5.groupby(['Supermarket _Size'],as_index=False)\nf_val, p_val = stats.f_oneway(grpd_5.get_group('Medium')['Product_Supermarket_Sales'], grpd_5.get_group('Small')['Product_Supermarket_Sales'],grpd_5.get_group('High')['Product_Supermarket_Sales'])  \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val) ","b9911d39":"df['Product_Type'].value_counts()","553dae6f":"grouped_6=df[['Product_Type','Product_Supermarket_Sales']]\ngrpd_6=grouped_6.groupby(['Product_Type'],as_index=False).mean()\ngrpd_6","87102d54":"sns.boxplot(x='Product_Type', y='Product_Supermarket_Sales', data=grpd_1)\nsns.plt.xticks(rotation=90)","0352d8f3":"list(df['Product_Type'].unique())","77a03b5c":"# grpd_6=grouped_6.groupby(['Supermarket _Size'],as_index=False)\n# for \n# f_val, p_val = stats.f_oneway(grpd_6.get_group('Medium')['Product_Supermarket_Sales'], grpd_6.get_group('Small')['Product_Supermarket_Sales'],grpd_5.get_group('High')['Product_Supermarket_Sales'])  \n# print( \"ANOVA results: F=\", f_val, \", P =\", p_val) ","9d5dc1e8":"grouped_7=df[['Supermarket_Opening_Year','Supermarket_Identifier','Product_Supermarket_Sales']]\ngrpd_7=grouped_7.groupby(['Supermarket_Opening_Year','Supermarket_Identifier'],as_index=False).mean()\ngrpd_7.sort_values(['Product_Supermarket_Sales'], ascending=False)","e55fbe00":"sns.regplot(x=\"Supermarket_Opening_Year\", y=\"Product_Supermarket_Sales\", data=grpd_7)\nplt.ylim(0,)","cc9548a8":"grpd_7.corr()","9a8dadf7":"df.columns","c946620c":"# df.sort_values(['Product_Type','Product_Supermarket_Identifier','Product_Supermarket_Sales']).head(10)\ndf.head()","aef3e9e0":"# df['Product_Price']=df['Product_Price']\/df['Product_Price'].max()\n# df2['Product_Price']=df2['Product_Price']\/df2['Product_Price'].max()","ec23413e":"df['Product_Weight']=df['Product_Weight']\/df['Product_Weight'].max()\ndf2['Product_Weight']=df2['Product_Weight']\/df2['Product_Weight'].max()\ndf.head()","2987dd2c":"# dummy_variable_1 = pd.get_dummies(df[\"Supermarket_Type\"])\n# dummy_variable_1.rename(columns={'Grocery Store':'Supermarket Type Grocery Store'}, inplace=True)\n# dummy_variable_1.head()\nX=df.drop(['Product_Identifier','Supermarket_Identifier','Product_Supermarket_Identifier','Product_Fat_Content','Supermarket_Opening_Year','Product_Supermarket_Sales'], axis=1)\nX=pd.get_dummies(X)\nX.head()","3aba7691":"X.head()","8159a1b2":"y=df.Product_Supermarket_Sales\ny.head()","2b3e9ad7":"def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n    width = 12\n    height = 10\n    plt.figure(figsize=(width, height))\n\n    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n\n    plt.title(Title)\n    plt.xlabel('Price (in naira)')\n    plt.ylabel('Proportion of Products')\n\n    plt.show()\n    plt.close()","2697bd4f":"def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):\n    width = 12\n    height = 10\n    plt.figure(figsize=(width, height))\n    \n    \n    #training data \n    #testing data \n    # lr:  linear regression object \n    #poly_transform:  polynomial transformation object \n \n    xmax=max([xtrain.values.max(), xtest.values.max()])\n\n    xmin=min([xtrain.values.min(), xtest.values.min()])\n\n    x=np.arange(xmin, xmax, 0.1)\n\n\n    plt.plot(xtrain, y_train, 'ro', label='Training Data')\n    plt.plot(xtest, y_test, 'go', label='Test Data')\n    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Predicted Function')\n    plt.ylim([-10000, 60000])\n    plt.ylabel('Price')\n    plt.legend()","b00c435c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","d20203cf":"priii()","0ed5da8c":"# from sklearn.ensemble import GradientBoostingRegressor\n# from sklearn.metrics import mean_squared_error\n# from sklearn.model_selection import GridSearchCV","285ec378":"# params = {'n_estimators': 500,\n#           'max_depth': 4,\n#           'min_samples_split': 5,\n#           'learning_rate': 0.01,\n#           'loss': 'ls'}","a50d036c":"# params = {'n_estimators': 600,\n#           'max_depth': 4,\n#           'min_samples_split': 5,\n#           'learning_rate': 0.01,\n#           'loss': 'ls'}","04e18755":"# reg = GradientBoostingRegressor(**params)\n# reg.fit(X_train, y_train)\n\n# mse = mean_squared_error(y_train, reg.predict(X_train))\n# print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))","64034a97":"# mse = mean_squared_error(y_test, reg.predict(X_test))\n# print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))","9ad22dc5":"# print (\"R-squared for Train: %.2f\" %reg.score(X_train, y_train))\n# print (\"R-squared for Test: %.2f\"%reg.score(X_test, y_test))","0795bcab":"# !pip install xgboost","985c66c7":"# X2=df2.drop(['Product_Identifier','Supermarket_Identifier','Product_Supermarket_Identifier','Product_Fat_Content','Supermarket_Opening_Year'], axis=1)\n# X2=pd.get_dummies(X2)\n# X2.head()","82ea7cde":"# test_pred = reg.predict(X2) #predict on the test set for submission\n# df3= {'Product_Supermarket_Identifier': df2['Product_Supermarket_Identifier'], 'Product_Supermarket_Sales': test_pred}\n# sub = pd.DataFrame(data=df3)\n# sub = sub[['Product_Supermarket_Identifier', 'Product_Supermarket_Sales']]","5c28b2f0":"# sub.shape","f361e4e0":"# # sub.to_csv('submission.csv', index = False)","630a7eae":"# subxamp=pd.read_csv('sample_submission.csv')\n# subxamp.head()","e549c0f8":"from sklearn.linear_model import LinearRegression\nlre=LinearRegression()\n","a92f8502":"lre.fit(X_train,y_train)\nlre.score(X_train,y_train)","be8e1590":"lre.score(X_test,y_test)","c216b192":"from sklearn.metrics import mean_squared_error","17cd3cfd":"yhat_train=lre.predict(X_train)\nyhat_train[:5]","df90445d":"print('The mean square error of price and predicted value using multifit is: ', \\\n      mean_squared_error(y_train, yhat_train))","e64025e7":"print('The mean square error of price and predicted value using multifit is: ', \\\n      mean_squared_error(y_test, lre.predict(X_test)))","8b901e39":"Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\nDistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)","46c335d9":"yhat_test=lre.predict(X_test)\nyhat_test[:5]","d0621cb9":"Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\nDistributionPlot(y_test, yhat_test, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)","06282af8":"# **SORRY I DON'T KNOW HOW THINGS ARE DONE ON KAGGLE WELL YET.\n# THIS NOTEBOOK GIVES MY VERY FIRST APPROACH TO THE PROBLEM**","3cb37d64":"# supermarket_size analysis","5784e5df":"# product that gives a better margin at specific stores","f6031093":"# predicting the test data","b054abbf":"# Normalization","a3dfb97c":"# Product_Fat_Content analysis","3d692ef1":"# Product_Type analysis","c1059f53":"# Linear Regression Algo","6bbeba02":"# Supermarket Type analysis","adebe861":"Croos validation","05950ea1":"# Supermarket_Location_Type analysis","a677236c":"# GradientBoostingRegression Algo"}}