{"cell_type":{"2588686a":"code","3ef53a57":"code","71b78b8d":"code","08765898":"code","a6e29c65":"code","ebfd0fb6":"code","2a1bb21b":"code","33c8e777":"code","5948ed16":"code","0c74eb06":"code","f6a10402":"code","59606131":"code","2a28f326":"code","e212dd48":"code","8ddadf1f":"code","a1525c14":"code","9837441c":"code","3c226feb":"markdown","00737ab4":"markdown","1de51258":"markdown","c949d60f":"markdown","eca1a10e":"markdown","b032b41d":"markdown","85e32f1e":"markdown","179c46ae":"markdown","e884620d":"markdown","d873f3c7":"markdown","db4551e3":"markdown","681309f2":"markdown","9fb0107a":"markdown","91f8aad7":"markdown","f540bebb":"markdown"},"source":{"2588686a":"# install library that you needed\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3ef53a57":"data = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")\ndata.head()","71b78b8d":"data.drop(['Unnamed: 32','id'], inplace = True, axis = 1) # datada anlams\u0131z veri id siliyoruz.\ndata = data.rename(columns = {\"diagnosis\":\"target\"}) # do\u011frulama tespiti(accurately rate) i\u00e7in hedef veriyi belirliyoruz.\n\n","08765898":"sns.countplot(data[\"target\"]) \nprint(data.target.value_counts())\ndata[\"target\"] = [1 if i == \"M\" else 0 for i in data.target] # malignant ise 1 de\u011filse 0 \u015feklinde digit veriye d\u00f6n\u00fc\u015ftiriyoruz ","a6e29c65":"corr_matrix = data.corr()\nsns.clustermap(corr_matrix, annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features\")\nplt.show()\n","ebfd0fb6":"threshold = 0.7\nfiltre = np.abs(corr_matrix[\"target\"]) > threshold\ncorr_features = corr_matrix.columns[filtre].tolist()\nsns.clustermap(data[corr_features].corr(), annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features w Corr Threshold 0.75\")","2a1bb21b":"data_melted = pd.melt(data, id_vars = \"target\",\n                      var_name = \"features\",\n                      value_name = \"value\")\n\nplt.figure()\nsns.boxplot(x = \"features\", y = \"value\", hue = \"target\", data = data_melted)\nplt.xticks(rotation = 90)\nplt.show()","33c8e777":"\n# pair plot \nsns.pairplot(data[corr_features], diag_kind = \"kde\", markers = \"+\",hue = \"target\")\nplt.show()\n\n","5948ed16":"y = data.target\nx = data.drop([\"target\"],axis = 1)\ncolumns = x.columns.tolist()\n\nclf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x)\nX_score = clf.negative_outlier_factor_\n\noutlier_score = pd.DataFrame()\noutlier_score[\"score\"] = X_score\n\n# threshold\nthreshold = -2.5\nfiltre = outlier_score[\"score\"] < threshold\noutlier_index = outlier_score[filtre].index.tolist()\n\n\nplt.figure()\nplt.scatter(x.iloc[outlier_index,0], x.iloc[outlier_index,1],color = \"blue\", s = 50, label = \"Outliers\")\nplt.scatter(x.iloc[:,0], x.iloc[:,1], color = \"k\", s = 3, label = \"Data Points\")\n\nradius = (X_score.max() - X_score)\/(X_score.max() - X_score.min())\noutlier_score[\"radius\"] = radius\nplt.scatter(x.iloc[:,0], x.iloc[:,1], s = 1000*radius, edgecolors = \"r\",facecolors = \"none\", label = \"Outlier Scores\")\nplt.legend()\nplt.show()\n","0c74eb06":"\n# drop outliers\nx = x.drop(outlier_index)\ny = y.drop(outlier_index).values","f6a10402":"test_size = 0.3\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = test_size, random_state = 42)","59606131":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_train_df = pd.DataFrame(X_train, columns = columns)\nX_train_df_describe = X_train_df.describe()\nX_train_df[\"target\"] = Y_train\n# box plot \ndata_melted = pd.melt(X_train_df, id_vars = \"target\",\n                      var_name = \"features\",\n                      value_name = \"value\")\n\nplt.figure()\nsns.boxplot(x = \"features\", y = \"value\", hue = \"target\", data = data_melted)\nplt.xticks(rotation = 90)\nplt.show()\n\n\n# pair plot \nsns.pairplot(X_train_df[corr_features], diag_kind = \"kde\", markers = \"+\",hue = \"target\")\nplt.show()\n","2a28f326":"knn = KNeighborsClassifier(n_neighbors = 2)\nknn.fit(X_train, Y_train)\ny_pred = knn.predict(X_test)\ncm = confusion_matrix(Y_test, y_pred)\nacc = accuracy_score(Y_test, y_pred)\nscore = knn.score(X_test, Y_test)\nprint(\"Score: \",score)\nprint(\"CM: \",cm)\nprint(\"Basic KNN Acc: \",acc)","e212dd48":"def KNN_Best_Params(x_train, x_test, y_train, y_test):\n    \n    k_range = list(range(1,31))\n    weight_options = [\"uniform\",\"distance\"]\n    print()\n    param_grid = dict(n_neighbors = k_range, weights = weight_options)\n    \n    knn = KNeighborsClassifier()\n    grid = GridSearchCV(knn, param_grid, cv = 10, scoring = \"accuracy\")\n    grid.fit(x_train, y_train)\n    \n    print(\"Best training score: {} with parameters: {}\".format(grid.best_score_, grid.best_params_))\n    print()\n    \n    knn = KNeighborsClassifier(**grid.best_params_)\n    knn.fit(x_train, y_train)\n    \n    y_pred_test = knn.predict(x_test)\n    y_pred_train = knn.predict(x_train)\n    \n    cm_test = confusion_matrix(y_test, y_pred_test)\n    cm_train = confusion_matrix(y_train, y_pred_train)\n    \n    acc_test = accuracy_score(y_test, y_pred_test)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    print(\"Test Score: {}, Train Score: {}\".format(acc_test, acc_train))\n    print()\n    print(\"CM Test: \",cm_test)\n    print(\"CM Train: \",cm_train)\n    \n    return grid\n    \n    \ngrid = KNN_Best_Params(X_train, X_test, Y_train, Y_test)","8ddadf1f":"scaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)\n\npca = PCA(n_components = 2)\npca.fit(x_scaled)\nX_reduced_pca = pca.transform(x_scaled)\npca_data = pd.DataFrame(X_reduced_pca, columns = [\"p1\",\"p2\"])\npca_data[\"target\"] = y\nsns.scatterplot(x = \"p1\", y = \"p2\", hue = \"target\", data = pca_data)\nplt.title(\"PCA: p1 vs p2\")\n\n\nX_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X_reduced_pca, y, test_size = test_size, random_state = 42)\n\ngrid_pca = KNN_Best_Params(X_train_pca, X_test_pca, Y_train_pca, Y_test_pca)\n\n# visualize \ncmap_light = ListedColormap(['orange',  'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'darkblue'])\n\nh = .05 # step size in the mesh\nX = X_reduced_pca\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = grid_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = '%s')\"\n          % (len(np.unique(y)),grid_pca.best_estimator_.n_neighbors, grid_pca.best_estimator_.weights))\n","a1525c14":"nca = NeighborhoodComponentsAnalysis(n_components = 2, random_state = 42)\nnca.fit(x_scaled, y)\nX_reduced_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(X_reduced_nca, columns = [\"p1\",\"p2\"])\nnca_data[\"target\"] = y\nsns.scatterplot(x = \"p1\",  y = \"p2\", hue = \"target\", data = nca_data)\nplt.title(\"NCA: p1 vs p2\")\n\nX_train_nca, X_test_nca, Y_train_nca, Y_test_nca = train_test_split(X_reduced_nca, y, test_size = test_size, random_state = 42)\n\ngrid_nca = KNN_Best_Params(X_train_nca, X_test_nca, Y_train_nca, Y_test_nca)\n\n# visualize \ncmap_light = ListedColormap(['orange',  'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'darkblue'])\n\nh = .2 # step size in the mesh\nX = X_reduced_nca\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = grid_nca.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = '%s')\"\n          % (len(np.unique(y)),grid_nca.best_estimator_.n_neighbors, grid_nca.best_estimator_.weights))\n","9837441c":"knn = KNeighborsClassifier(**grid_nca.best_params_)\nknn.fit(X_train_nca,Y_train_nca)\ny_pred_nca = knn.predict(X_test_nca)\nacc_test_nca = accuracy_score(y_pred_nca,Y_test_nca)\nknn.score(X_test_nca,Y_test_nca)\n\ntest_data = pd.DataFrame()\ntest_data[\"X_test_nca_p1\"] = X_test_nca[:,0]\ntest_data[\"X_test_nca_p2\"] = X_test_nca[:,1]\ntest_data[\"y_pred_nca\"] = y_pred_nca\ntest_data[\"Y_test_nca\"] = Y_test_nca\n\nplt.figure()\nsns.scatterplot(x=\"X_test_nca_p1\", y=\"X_test_nca_p2\", hue=\"Y_test_nca\",data=test_data)\n\ndiff = np.where(y_pred_nca!=Y_test_nca)[0]\nplt.scatter(test_data.iloc[diff,0],test_data.iloc[diff,1],label = \"Wrong Classified\",alpha = 0.2,color = \"red\",s = 1000)\n","3c226feb":"![Roadmap](https:\/\/dugunslayti.net\/blog\/wp-content\/uploads\/2020\/04\/dugunslayti-backlink-olsun-bari-1.jpg)","00737ab4":"# Result","1de51258":"**there are outliers we can see on area worst !!! and on other **","c949d60f":"# NCA(Neighborhood component Analysis)","eca1a10e":"# KNN(unsupervised Learning clasifications method)","b032b41d":"**there is a lot of unnecessary information so I have to put a threshold**","85e32f1e":"# KNN BEST PARAMETERS","179c46ae":"**Write path that you obtain from above output**","e884620d":"# PCA(Principal component analysis)","d873f3c7":"# OUTLIER(Outlier detection data)","db4551e3":"# TRAIN TEST SPLIT","681309f2":"# STANDARDIZATION","9fb0107a":"**we neednt \"id\" and \"Unnamed: 32\" coloums**","91f8aad7":"# EDA (exploratory data analysis)","f540bebb":"**there are some skewness  is mean that there are outliers**"}}