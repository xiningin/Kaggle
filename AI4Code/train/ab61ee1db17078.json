{"cell_type":{"ff7f80e2":"code","38c1bc9f":"code","0e4204aa":"code","c69f3ffb":"code","9c6edfb9":"code","025f6d37":"code","33d4fb36":"code","6f7eee54":"code","d8039c77":"code","e23cf5e2":"code","741c3d5b":"code","518bf569":"code","d4bd7a2a":"code","f8360bcc":"code","8808b952":"code","e1fd6463":"code","77403f80":"code","62cbfa5c":"code","e60cd580":"code","80058902":"code","ba56927a":"markdown","e6d5efe8":"markdown","8cbd1e60":"markdown"},"source":{"ff7f80e2":"import pandas as pd\n\n# Read csv file into dataframe\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n\ndf.head()","38c1bc9f":"Y = df['DEATH_EVENT']\nX = df[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']]\n\nX.head(5)","0e4204aa":"import seaborn as sns\nimport matplotlib.pyplot as plt\n# Heatmap to Invertigate Correlation in Data\nsns.set()\nfig, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(df.corr(), linewidths=.5, ax=ax, cmap='Blues')\nplt.show()","c69f3ffb":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, test_size=0.2, random_state=52)\n\nprint('Shape of X_train:', X_train.shape)\nprint('Shape of X_test:', X_test.shape)\nprint('Shape of Y_train:', Y_train.shape)\nprint('Shape of Y_test:', Y_test.shape)\n","9c6edfb9":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, Y_train)\n\nDecisionTreeClassifier(class_weight=None, criterion=\"gini\", \n                       max_depth=None,max_features=None, max_leaf_nodes=None,\n                       min_impurity_split=1e-07, min_samples_leaf=1,\n                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n                       presort=False, random_state=None, splitter=\"best\")\n\nY_pred = dt.predict(X_test)\nY_pred","025f6d37":"from sklearn.metrics import roc_curve, auc\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test,Y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nroc_auc","33d4fb36":"from sklearn import decomposition, datasets\nfrom sklearn import tree\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler","6f7eee54":"std_slc = StandardScaler()\n\npca = decomposition.PCA()\n\ndec_tree = tree.DecisionTreeClassifier()","d8039c77":"pipe = Pipeline(steps=[('std_slc', std_slc),\n                           ('pca', pca),\n                           ('dec_tree', dec_tree)])","e23cf5e2":"n_components = list(range(1,X.shape[1]+1,1))","741c3d5b":"criterion = ['gini', 'entropy']\nmax_depth = [2,4,6,8,10,12]\nmax_features = [6,7,8,9,10,11,12]\n\nmin_samples_leaf = [0.10, 0.2, 0.3, 0.4, 0.5]\nmin_samples_split = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ]","518bf569":"parameters = dict(pca__n_components=n_components,\n                dec_tree__criterion=criterion,\n                dec_tree__max_depth=max_depth,\n                dec_tree__min_samples_leaf = min_samples_leaf,\n                dec_tree__min_samples_split = min_samples_split)","d4bd7a2a":"clf_GS = GridSearchCV(pipe, parameters)\nclf_GS.fit(X, Y)","f8360bcc":"print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\nprint('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\nprint('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n# print('Max_features:', clf_GS.best_estimator_.get_params()['dec_tree__max_features'])\nprint('min_samples_leaf:', clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf'])\nprint('min_samples_split:', clf_GS.best_estimator_.get_params()['dec_tree__min_samples_split'])\nprint()\nprint(clf_GS.best_estimator_.get_params()['dec_tree'])","8808b952":"import scikitplot as skplt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report \nfrom sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, Y_train)\n\nDecisionTreeClassifier(class_weight=None, criterion=\"gini\", \n                       max_depth=4, min_samples_leaf=0.1,\n                       min_samples_split=0.1)\n\nY_predict = dt.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: Decision Tree',\n                                    normalize=True,\n                                    cmap='Blues')\n\nplt.savefig(\"confusion grid des.png\")\nplt.show()\n\nprint(classification_report(Y_test, Y_predict))","e1fd6463":"text_representation = tree.export_text(dt, feature_names=['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time'])\nprint(text_representation)","77403f80":"# with open(\"decistion_tree_OPTIMISED.txt\", \"w\") as fout:\n#     fout.write(text_representation)","62cbfa5c":"import scikitplot as skplt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report \n\ndt = DecisionTreeClassifier()\nmodel = dt.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(8,8), \n                                    title='Confusion Matrix: Decision Tree',\n                                    normalize=True,\n                                    cmap='Blues')\nplt.savefig(\"confusion matrix usual des.png\")\nplt.show()\n\nprint(classification_report(Y_test, Y_predict))","e60cd580":"text_representation = tree.export_text(dt, feature_names=['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time'])\nprint(text_representation)","80058902":"# with open(\"decistion_tree_NORMAL.txt\", \"w\") as fout:\n#     fout.write(text_representation)","ba56927a":"## Heart Faliure Prediction using Descison Tree","e6d5efe8":"## Feature Selection","8cbd1e60":"Athul Mathew Konoor - 20016  M-Tech AI and DS 19AI613 Machine Learning Project- Hyper Parameter Tuning."}}