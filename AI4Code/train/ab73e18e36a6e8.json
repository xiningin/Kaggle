{"cell_type":{"f3f25974":"code","1b3e081d":"code","a7c5b792":"code","399f0631":"code","993b754b":"code","47a0a91c":"code","dc3aa72f":"code","79ac268b":"code","79e9e589":"code","e662d949":"code","bc703ad9":"markdown","c046ed22":"markdown","a32eb163":"markdown","9a1b85c0":"markdown"},"source":{"f3f25974":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, utils, callbacks\nimport tensorflow as tf\n\nimport os","1b3e081d":"nbr_of_clases = 10#10\u5206\u7c7b\nvalidation_percentage = 0.2#\u9a8c\u8bc1\u96c6\u6bd4\u4f8b\nresnet_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'#\u9884\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\n\ntraining_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')#\u8bfb\u53d6\u6570\u636e","a7c5b792":"def prepare_data_for_resnet50(data_to_transform):\n    data = data_to_transform.copy()\n    data = data.reshape(-1, 28, 28) \/ 255\n    data = np.stack([data, data, data], axis=-1)\n    return data","399f0631":"y = training_data['label'].values\nX = training_data.drop('label',axis = 1).values\n\ny = keras.utils.to_categorical(y, nbr_of_clases)#\u6807\u79f0\u578b\u7c7b\u522b\u8f6c\u72ec\u70ed\u7801\nX_rgb = prepare_data_for_resnet50(X)#\u53d8\u4e3a28*28\u76843\u901a\u9053\u56fe\u7247\uff0c\u6570\u503c\u8303\u56f40-1\n\nX_train, X_val, y_train, y_val = train_test_split(X_rgb, y, test_size=validation_percentage)","993b754b":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.applications.resnet50 import ResNet50\n\nmodel = Sequential()\nmodel.add(ResNet50(include_top=False, pooling='avg', weights=resnet_path))#ResNet50\u67b6\u6784\nmodel.add(Dropout(0.50))#dropout\nmodel.add(Dense(nbr_of_clases, activation='softmax'))#\u8f93\u51fa\u5c42\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])#adam\u8bad\u7ec3\u5668\u3001\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570","47a0a91c":"def get_fitted_data_generator(data):\n    data_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1,height_shift_range=0.1, zoom_range=0.1)\n    data_generator.fit(data)\n    return data_generator\n    \ndef fit_model_generator(model, X_train, y_train, epochs=1, batch=32, X_val=None, y_val=None):#batchsize\u4e3a32\n    image_nbr = np.size(X_train, 0)\n    training_data_generator = get_fitted_data_generator(X_train)\n    es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)#\u65e9\u505c\n    rlp = callbacks.ReduceLROnPlateau(    monitor='val_loss', factor=0.1, patience=2, min_lr=1e-10, mode='min', verbose=1)#\u5b66\u4e60\u7387\u8870\u51cf\n    return model.fit_generator(training_data_generator.flow(X_train, y_train, batch_size=batch), steps_per_epoch=(image_nbr\/\/batch),callbacks=[es, rlp],epochs=epochs, validation_data=(X_val, y_val), verbose=1)#fit_generator\u4f20\u9012\u7684\u662fsteps_per_epoch\u800c\u4e0d\u662fbatchsize","dc3aa72f":"full_data_model = fit_model_generator(model, X_train, y_train, epochs=150,X_val=X_val,y_val=y_val)","79ac268b":"testing_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv').values#\u8bfb\u53d6\u6d4b\u8bd5\u6570\u636e\ntesting_data = prepare_data_for_resnet50(testing_data)#\u53d8\u4e3a28*28\u76843\u901a\u9053\u56fe\u7247\uff0c\u6570\u503c\u8303\u56f40-1\n\ndef get_predictions(model, data):\n    return np.array([np.argmax(prediction) for prediction in model.predict(data)])\n\nfinal_predictions = get_predictions(model, testing_data)#\u9884\u6d4b","79e9e589":"submission_filename = 'submission.csv'\nanswers = pd.DataFrame({'ImageId':range(1, final_predictions.size + 1),'Label':final_predictions})\nanswers.to_csv(submission_filename, index=False)","e662d949":"submission_filename = '\/kaggle\/working\/submission.csv'\nanswers.to_csv(submission_filename, index=False)","bc703ad9":"# \u8bad\u7ec3","c046ed22":"# \u521b\u5efa\u6a21\u578b","a32eb163":"# \u6570\u636e\u9884\u5904\u7406","9a1b85c0":"# \u9884\u6d4b\u5e76\u8f93\u51fa\u7ed3\u679c"}}