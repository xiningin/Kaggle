{"cell_type":{"8ebeb3da":"code","4d624ce2":"code","fe3a4587":"code","133b32ad":"code","4033ecf5":"code","3e1bc7d7":"code","61bd831e":"code","7d927efd":"code","607c1e96":"code","580ea359":"code","10986f6a":"code","0e4daca9":"code","e4cd7c97":"markdown","bfb16132":"markdown","2cfe15e0":"markdown","1b711c20":"markdown","b16de48d":"markdown"},"source":{"8ebeb3da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4d624ce2":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import preprocessing","fe3a4587":"data_frame = pd.read_csv('..\/input\/bike_share.csv')\ndata_frame.head()","133b32ad":"holidays_1 = data_frame['holiday'].values\nworking_days_1 = data_frame['workingday'].values\n\nweekend_1 = []\nfor i in range(len(holidays_1)):\n    if working_days_1[i] == 0 and holidays_1[i] == 0:\n        weekend_1.append(1)\n    else:\n        weekend_1.append(0)\ndata_frame['weekend'] = weekend_1\ndata_frame.head()","4033ecf5":"x_casual_o = data_frame[['season', 'holiday', 'workingday', 'weather', 'atemp', 'humidity', 'windspeed', 'weekend']].values\ny_casual = data_frame['casual'].values\n\nx_registered_o = data_frame[['season', 'holiday', 'workingday', 'weather', 'atemp', 'humidity', 'windspeed', 'weekend']].values\ny_registered = data_frame['registered'].values","3e1bc7d7":"min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 10))\nx_casual_s = min_max_scaler.fit_transform(x_casual_o)\nx_registered_s = min_max_scaler.fit_transform(x_registered_o)\ntrain_x1, test_x1, train_y1, test_y1 = train_test_split(x_casual_s, y_casual, test_size=0.2, random_state=4)\ntrain_x2, test_x2, train_y2, test_y2 = train_test_split(x_registered_s, y_registered, test_size=0.2, random_state=4)\n\ny_true_1 = np.add(test_y1, test_y2)\n","61bd831e":"k_min_casual = 5\nk_min_registered = 5\ntest_MAE_casual_array = []\ntest_MAE_registered_array = []\nk_values = []\nmae_casual = 10000\nmae_registered = 10000\nfor k in range(5, 50):\n    model_casual = KNeighborsRegressor(n_neighbors=k).fit(train_x1, train_y1)\n    model_registered = KNeighborsRegressor(n_neighbors=k).fit(train_x2, train_y2)\n\n    predict_casual = model_casual.predict(test_x1)\n    predict_registered = model_registered.predict(test_x2)\n\n    test_MAE_casual = mean_absolute_error(test_y1, predict_casual)\n    test_MAE_registered = mean_absolute_error(test_y2, predict_registered)\n    if test_MAE_casual < mae_casual:\n        mae_casual = test_MAE_casual\n        k_min_casual = k\n\n    if test_MAE_registered < mae_registered:\n        mae_registered = test_MAE_registered\n        k_min_registered = k\n    print(\"k_value\",k , \"MAE casual\", int(test_MAE_casual),\"    \", \"MAE registered\", int(test_MAE_registered))\n    test_MAE_casual_array.append(test_MAE_casual)\n    test_MAE_registered_array.append(test_MAE_registered)\n    k_values.append(k)","7d927efd":"plt.plot(k_values, test_MAE_casual_array)\nplt.xlabel(\"k_values\")\nplt.ylabel(\"mean absolute error for number of casual bikes\")\nplt.show()","607c1e96":"plt.plot(k_values, test_MAE_registered_array, 'r')\nplt.xlabel(\"k_value\")\nplt.ylabel(\"mean absolute error for number of registered bikes\")\nplt.show()","580ea359":"print(\"Best k value for the prediction of casual bikes number\", k_min_casual)\nprint(\"Best k value for the prediction of registered bikes number\", k_min_registered)","10986f6a":"model_casual_final = KNeighborsRegressor(n_neighbors=k_min_casual).fit(train_x1, train_y1)\nmodel_registered_final = KNeighborsRegressor(n_neighbors=k_min_registered).fit(train_x2, train_y2)\n\nprediction_casual_f = model_casual_final.predict(test_x1)\nprediction_registered_f = model_registered_final.predict(test_x2)\n\nprediction_count_f = np.add(prediction_casual_f, prediction_registered_f)\n\nprint(\"Final Prediction\")\nprint(prediction_count_f)","0e4daca9":"MAE = mean_absolute_error(y_true_1, prediction_count_f)\nMSE = mean_squared_error(y_true_1, prediction_count_f)\n\nprint(\"Mean Absolute error\", MAE)\nprint(\"Mean Squared Error\", MSE)","e4cd7c97":"The features present in the data-set predicts the number of casual bikes very accurately, with MAE in the range of 15 to 20, but struggles to achieve same level of accuracy for the prediction of number of registered bikes, with MAE being in the range on 90 to 100.\n\nThis suggests that the features in the data-set are good to go for casual bikes number but for registered bikes we kind of need more features in the data-set.\n\nSince we don't have any other features presently available, we move on with our process with the same data-set.","bfb16132":"x_dataset is scaled, so as to avoid the domination of objective function by one of the features in the data-set having larger values.","2cfe15e0":"In the above data-set, we notice a column for week-end is missing. Apart from holidays and working-days, a third parameter for week-end is added to the data-frame. ","1b711c20":"Total number of bikes (count) is the sum of number of registered and casual bikes. On any random day, the registered bikes used and casual bikes used would be independent of each other. Also, it can be intutively concluded that number of registered bikes and number of casual bikes used on a random day would depend differently on the features listed in the data-set. \n\nOne such example,it maybe possible that on a working-day the number of casual bikes used would be less while number of registered bikes used would be greater. This example on an intutive level seems plausible, since people on working day are less likely to casually use bikes for some work. \n\nSo we model this using k-nearest neigbour regressor. First on any random day, we calculate number of casual bikes used based on the features in the data-set. And then we calculate the number of registered bikes used. The summation of these two predict the values of total number of bikes used.","b16de48d":"Find best k value for kNN regressor."}}