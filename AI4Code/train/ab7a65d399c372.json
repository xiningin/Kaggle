{"cell_type":{"f396461f":"code","bd42c9bd":"code","5c09a02b":"code","664bd10a":"code","148c7ff6":"code","80a9ef0f":"code","075fe6a2":"code","c695e942":"code","2f8ae9e6":"code","c5a94bdf":"code","33f67fee":"code","29d8d46a":"code","3d0fb5c0":"code","2c5aadc6":"code","98615e03":"code","ca166ace":"code","1323c1b2":"code","cf475a64":"code","83440e8a":"code","29417f6a":"code","2ecf2d2f":"code","780b0caf":"code","86f8e6bf":"code","83636659":"code","ec0dd969":"code","d6046020":"code","13ffce6f":"code","9bdcfda5":"code","d231e063":"code","698782fd":"code","32af346d":"code","3008dc92":"code","c5270ec8":"code","e43aff99":"code","cc9aa85e":"code","3a1b71a8":"code","8b560d14":"code","f1b92489":"code","6e4139f0":"code","18a56a51":"code","4fb92db8":"code","706483d6":"code","71f33e8a":"code","bb1091f8":"code","5952a727":"code","b865e3f2":"code","9f7ed7d8":"code","048afe69":"code","8ced1083":"code","61e17d4d":"code","6ad16982":"code","49aab0d7":"code","2523c941":"code","2fa1d5f2":"code","f1b81890":"code","acbb9b21":"code","411fd93f":"code","8df1bee1":"code","71c9eacf":"code","8056d56b":"code","36d6c0fe":"code","b75a356e":"code","1d068bf1":"code","bec294d9":"code","cca8b615":"code","837610c1":"code","49a738f9":"code","2966e835":"code","6f82ff91":"code","fb474cc1":"code","1baf4213":"code","5888142c":"code","7988582e":"code","1bdc44cf":"code","d734d1d7":"code","0c733047":"code","f3a43f49":"code","c1955324":"code","ad075a71":"code","a8a2d380":"code","6cba5c77":"code","0efb9544":"code","ef52dcdb":"code","6ae02385":"markdown","efa5a4b7":"markdown","140a132a":"markdown","f6307ce8":"markdown","11392333":"markdown","cc8c8dc6":"markdown","a662a8cd":"markdown","aaabe88e":"markdown","cf82f8a8":"markdown","bc92e06b":"markdown","9ed40b4c":"markdown","983c1be5":"markdown","7b4d2c0f":"markdown","e1e607b3":"markdown","e9b17c1d":"markdown","515b6c45":"markdown","bdaf7824":"markdown"},"source":{"f396461f":"import sqlite3\nimport numpy as np\nimport pandas as pd \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.feature_selection import RFE, f_regression\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso,LogisticRegression)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.feature_selection import RFE, f_regression\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso,LogisticRegression)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom math import sqrt","bd42c9bd":"train = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/train.csv.zip\")\ntest = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv.zip\")","5c09a02b":"train.head()","664bd10a":"train.tail()","148c7ff6":"train.shape","80a9ef0f":"train.columns","075fe6a2":"train.info()","c695e942":"train.describe()","2f8ae9e6":"train.columns","c5a94bdf":"# V\u00e9rifier les features ayant les valeurs nulles.\ntrain.isnull().any()","33f67fee":"# V\u00e9rifier les features ayant les valeurs nulles.\ntest.isnull().any()","29d8d46a":"### affichez les percentages des valleurs nulles ","3d0fb5c0":"train.isnull().sum()*100\/train.shape[0]","2c5aadc6":"test.isnull().sum()*100\/test.shape[0]","98615e03":"# Afficher un plot pr\u00e9sentant ces pourcentages\nimport matplotlib.pyplot as plt\n%matplotlib inline\npercent = (train.isnull().sum()*100\/train.shape[0]).sort_values(ascending=False)\npercent.plot(kind=\"bar\", figsize = (20,10), fontsize = 20)\nplt.xlabel(\"Columns\", fontsize = 20)\nplt.ylabel(\"Value Percent(%)\", fontsize = 20)\nplt.title(\"Total Missing Value \", fontsize = 20)","ca166ace":"### on n a pas de valleurs nulles ","1323c1b2":"train.dtypes==object","cf475a64":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(train['Open Date'])\ntrain['Open Date']=le.fit_transform(train['Open Date'])","83440e8a":"le.fit(train['City'])\ntrain['City']=le.fit_transform(train['City'])","29417f6a":"le.fit(train['City Group'])\ntrain['City Group']=le.fit_transform(train['City Group'])","2ecf2d2f":"le.fit(train['Type'])\ntrain['Type']=le.fit_transform(train['Type'])","780b0caf":"train.dtypes==object","86f8e6bf":"train.info()","83636659":"test.info()","ec0dd969":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(test['Open Date'])\ntest['Open Date']=le.fit_transform(test['Open Date'])\nle.fit(test['City'])\ntest['City']=le.fit_transform(test['City'])\nle.fit(train['City Group'])\ntest['City Group']=le.fit_transform(test['City Group'])\nle.fit(test['Type'])\ntest['Type']=le.fit_transform(test['Type']) ","d6046020":"test.info()","13ffce6f":"train.head()","9bdcfda5":"test.head()","d231e063":"# Display pandas histogram\ntrain['City'].plot.hist()\nplt.show()","698782fd":"#  \nId = train['Id'].values\n#  \nCity = train['City'].values\n\n\nplt.bar(City,Id)\nplt.show()","32af346d":"Id = train['Id'].values\n#  \nCity = train['City'].values\n\n\nplt.bar(Id,City)\nplt.show()","3008dc92":"# Display a Seaborn distplot\nsns.distplot(train['City'])\nplt.show()","c5270ec8":"sns.regplot(data=train,\n         x=\"revenue\",\n         y=\"City\")\n\n# Display the plot\nplt.show()","e43aff99":"sns.regplot(data=train,\n         x=\"Id\",\n         y=\"Type\")\n\n# Display the plot\nplt.show()","cc9aa85e":"#  \nId = train['Id'].values\n#  \nCity = train['Type'].values\n\n\nplt.bar(City,Id)\nplt.show()","3a1b71a8":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans","8b560d14":"X = StandardScaler().fit_transform(train)\nX","f1b92489":"kmeans = KMeans(n_clusters=5)\nmodel = kmeans.fit(X)\nprint(\"model\\n\", model)","6e4139f0":"centers = model.cluster_centers_\ncenters","18a56a51":"def pd_centers(featuresUsed, centers):\n\tcolNames = list(train.columns)\n\tcolNames.append('revenu')\n\n\t# Zip with a column called 'prediction' (index)\n\tZ = [np.append(A, index) for index, A in enumerate(centers)]\n\n\t# Convert to pandas data frame for plotting\n\tP = pd.DataFrame(Z, columns=colNames)\n\tP['revenu'] = P['revenu'].astype(int)\n\treturn P","4fb92db8":"A=pd_centers(train.columns,centers)","706483d6":"def parallel_plot(train):\n\tmy_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(train)))\n\tplt.figure(figsize=(15,8)).gca().axes.set_ylim([-3,+3])\n\tparallel_coordinates(train,'revenu', color = my_colors, marker='o')","71f33e8a":"# train[train['City'] ].Id.value_counts()","bb1091f8":"### la ville avec le plus grand nbr de restauration c istanbul","5952a727":"from sklearn.neighbors import NearestNeighbors\nnbrs = NearestNeighbors(n_neighbors=3).fit(X)\ndistances, indices = nbrs.kneighbors(X)","b865e3f2":"distanceDec = sorted(distances[:,3-1], reverse=False)\nplt.plot(indices[:,0], distanceDec)\nplt.xlabel('Points sorted according to distance of 3th nearest neighbor')\nplt.ylabel('3th Nearest Neighbor Distance')\nplt.show()","9f7ed7d8":"plt.axhline(3)\nplt.plot(indices[:,0], distanceDec)\nplt.xlabel('Points sorted according to distance of 3th nearest neighbor')\nplt.ylabel('3th Nearest Neighbor Distance')\nplt.show()","048afe69":"from sklearn.cluster import DBSCAN\ndbscan=DBSCAN(eps=3, min_samples=20)\ndbscan.fit(X)","8ced1083":"labels=dbscan.labels_","61e17d4d":"#les valeurs extr\u00eames dont labels == -1\ntrain[labels==-1]","6ad16982":"#Shape des donn\u00e9es repr\u00e9sentant des valeurs extremes\ntrain[labels==-1].shape","49aab0d7":"# La cible\ny= train['revenue']","2523c941":"# Import TSNE\nfrom sklearn.manifold import TSNE\nmodel = TSNE(learning_rate=10)\ntsne_features = model.fit_transform(X)\nxs = tsne_features[:,0]\nys = tsne_features[:,1]\nplt.scatter(xs,ys, c=y)\nplt.show()\nplt.clf()","2fa1d5f2":"corr_with_target = train.corr()['revenue'].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_target.drop('revenue').plot.bar()\nplt.show()","f1b81890":"coor_pos= corr_with_target[corr_with_target>0]\ncoor_neg= corr_with_target[corr_with_target<0]","acbb9b21":"coor_pos","411fd93f":"coor_neg","8df1bee1":"import seaborn as sns\n#Corr\u00e9lation\nstr_list = [] # liste vide pour contenir les colonnes avec les mots \nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n            \nnum_list = train.columns.difference(str_list) \n\ndf_num = train[num_list]\nf, ax = plt.subplots(figsize=(30, 20))\nplt.title(' Correlation ')\nsns.heatmap(df_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)","71c9eacf":"# d\u00e9finir un dictionnaire pour stocker nos rankings \nranks = {}\n# cr\u00e9er une fonction qui stocke le classement des caract\u00e9ristiques \ndef ranking(ranks, names, order=1):\n    minmax = MinMaxScaler()\n    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n    ranks = map(lambda x: round(x,2), ranks)\n    return dict(zip(names, ranks))","8056d56b":"# lingReg\nlr = LinearRegression(normalize=True)\nlr.fit(X,y)\nranks[\"LinReg\"] = ranking(np.abs(lr.coef_), train.columns)\n\n#  Ridge \nridge = Ridge(alpha = 7)\nridge.fit(X,y)\nranks['Ridge'] = ranking(np.abs(ridge.coef_),  train.columns)\n\n#  Lasso\nlasso = Lasso(alpha=.05)\nlasso.fit(X,y)\nranks[\"Lasso\"] = ranking(np.abs(lasso.coef_),  train.columns)\n\n# RF\nrf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=0)\nrf.fit(X,y)\nranks[\"RF\"] = ranking(rf.feature_importances_,  train.columns);","36d6c0fe":"# cr\u00e9er un dictionnaire vide pour contenir la valeur moyenne des scores calcul\u00e9s \nr = {}\nfor name in train.columns:\n    r[name] = round(np.mean([ranks[method][name] \n                             for method in ranks.keys()]), 2)\n \nmethods = sorted(ranks.keys())\nranks[\"Mean\"] = r\nmethods.append(\"Mean\")\n \nprint(\"\\t%s\" % \"\\t\".join(methods))\nfor name in train.columns:\n    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n                         [ranks[method][name] for method in methods]))))","b75a356e":"# mettre la moyenne dans un dataframe Pandas\nmeanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n\n# Trier le  dataframe\nmeanplot = meanplot.sort_values('Mean Ranking', ascending=False)","1d068bf1":"sns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", \n               size=14, aspect=1.9, palette='coolwarm')","bec294d9":"# les features selectionn\u00e9s\nfeatures_to_use=meanplot[meanplot[\"Mean Ranking\"]> 0].Feature","cca8b615":"features_to_use","837610c1":"X2= train[features_to_use].values","49a738f9":"#Divison des donn\u00e9es en train et test\nX_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.33, random_state=324)\n","2966e835":"#liste pour stocker les rmse\nrmse=[]","6f82ff91":"# R\u00e9gression lin\u00e9aire\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","fb474cc1":"y_prediction = regressor.predict(X_test)\nRMSE_lin_reg = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\nRMSE_lin_reg ","1baf4213":"rmse.append(RMSE_lin_reg)","5888142c":"randomforest = RandomForestRegressor()\nrandomforest.fit(X_train, y_train)\ny_pred = randomforest.predict(X_test)\nRMSE_RF = sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred))\nprint(RMSE_RF)\nrmse.append(RMSE_RF)","7988582e":"from sklearn.ensemble import AdaBoostRegressor","1bdc44cf":"ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=30), learning_rate=0.5, random_state=42)\nada_reg.fit(X_train, y_train)\ny_pred_ada = ada_reg.predict(X_test)","d734d1d7":"ada_reg","0c733047":"RMSE_ada = sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_ada))\nrmse.append(RMSE_ada)\nRMSE_ada","f3a43f49":"import xgboost","c1955324":"xgb_reg = xgboost.XGBRegressor()\nxgb_reg.fit(X_train, y_train)","ad075a71":"y_pred = xgb_reg.predict(X_test)","a8a2d380":"RMSE_XG=sqrt(mean_squared_error(y_test, y_pred))\nrmse.append(RMSE_XG)\nRMSE_XG","6cba5c77":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbrt = GradientBoostingRegressor(max_depth=5, learning_rate=1.0, random_state=42)\ngbrt.fit(X_train, y_train)","0efb9544":"y_pred_gra = gbrt.predict(X_test)\n\nRMSE_gra = sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred_gra))\nrmse.append(RMSE_gra)\nRMSE_gra","ef52dcdb":"table1 = {'RMSE':rmse,'Algorithmes':['linear regression','random forest','AdaBoost',\n                                               'XGBoost','Gradient Boosting']}\ndf = pd.DataFrame.from_dict(table1, orient='index')\ndf.transpose()","6ae02385":"## D\u00e9tection des valeurs manquantes","efa5a4b7":"## Transformation des donn\u00e9es\u00b6","140a132a":"## Application du k-means sur 5 clusters","f6307ce8":"## Feature engineering","11392333":"## T-SNE","cc8c8dc6":"## AdaBoost","a662a8cd":"### random forest est l'algorithme ayant la plus grande performance","aaabe88e":"les colonnes \"Open date\" \"City\" \"City groupe\" \"Type\" sont de types objets ","cf82f8a8":"## Random Forest","bc92e06b":"## Linear Regression","9ed40b4c":"## Application des algorithmes","983c1be5":"#### la date d'ouverture affecte la prediction finale ","7b4d2c0f":"## DBSCAN","e1e607b3":"## Tableau Comparatif","e9b17c1d":"## Visualisations","515b6c45":"## Gradient Boosting","bdaf7824":"## XGBoost"}}