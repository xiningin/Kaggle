{"cell_type":{"95ba8b10":"code","3ef22939":"code","d922c47d":"code","1954f10c":"code","fa2809af":"code","4873b32e":"code","409ee53f":"code","d34189f1":"code","6ae79c09":"code","ac017e09":"code","6b41b9a7":"code","6595b7c7":"code","4cc4b19b":"code","4c45965e":"code","a28c7835":"code","6bc6f1af":"code","9860c585":"code","092d95fd":"code","3a73af81":"markdown","7e02a641":"markdown","2a285d0f":"markdown","d2580d52":"markdown","e3557f70":"markdown","fe9bb194":"markdown","c9bb22f1":"markdown","416c7738":"markdown","9ae96e80":"markdown","c28b75ed":"markdown"},"source":{"95ba8b10":"from google.cloud import bigquery\nimport pandas as pd\nimport bq_helper \nimport numpy as np\n%matplotlib inline\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nimport spacy\nnlp = spacy.load('en')\n\n# create a helper object for our bigquery dataset\nbq_hacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n                                       dataset_name = \"hacker_news\")\n\nclient = bigquery.Client()\n%matplotlib inline","3ef22939":"query =\"\"\"\nSELECT score, author, time\nFROM `bigquery-public-data.hacker_news.stories`\nWHERE time > 1387536270 AND score >= 0\n\"\"\"\nbq_hacker_news.estimate_query_size(query)","d922c47d":"# df_hn = bq_hacker_news.query_to_pandas_safe(query, max_gb_scanned=0.1)","1954f10c":"# df_hn.to_csv(\"hn_scores.csv\") ","fa2809af":"import re\ndef add_datepart(df, fldname, drop=True, time=False, errors=\"raise\"):\t\n    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3\/11\/2000', '3\/12\/2000', '3\/13\/2000'], infer_datetime_format=False) })\n    >>> df\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n    >>> add_datepart(df, 'A')\n    >>> df\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    \"\"\"\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Hour']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr: df[n] = getattr(fld.dt, n.lower())\n    if drop: df.drop(fldname, axis=1, inplace=True)","4873b32e":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n","409ee53f":"df_hn = pd.read_csv('..\/input\/hacker-news\/hn_scores.csv', index_col=0)","d34189f1":"df_hn.head()","6ae79c09":"df_hn = df_hn.sort_values('time').reset_index(drop=True)\ndf_hn[\"delta_s\"]=df_hn.time.diff()\ndf_hn = df_hn.dropna()\ndf_hn.head()","ac017e09":"# plt.plot(df_hn.time)","6b41b9a7":"outlier_max=1000\nstory_rate = 1\/(df_hn.delta_s[df_hn.delta_s<outlier_max].mean()) # 1\/100 sec\nprint(f'one story every {1\/story_rate:.0f} seconds on average')","6595b7c7":"plt.hist(df_hn.delta_s[df_hn.delta_s<outlier_max],100, density=True)\nt = np.arange(1000)\ny = story_rate*np.exp(-story_rate*t)\nplt.plot(t,y, label=\"theoretical from mean rate\")\nplt.title('Interarrival time for Hacker News')\nplt.xlabel(\"seconds\");\nplt.ylabel(\"density\");\nplt.legend(loc='upper right')\n","4cc4b19b":"df_hn = pd.read_csv('..\/input\/hacker-news\/hn_scores.csv', index_col=0)\ndf_hn = df_hn.sort_values('time').reset_index()\ndf_hn[\"delta_s\"]=df_hn.time.diff()\ndf_hn = df_hn.dropna()\ndf_hn['datetime'] = pd.to_datetime(df_hn.time, unit='s').dt.tz_localize('GMT').dt.tz_convert('US\/Pacific') # in GMT\nadd_datepart(df_hn,'datetime')","4c45965e":"import calendar\ndow_dic =dict(enumerate(calendar.day_name))\nfig,ax=plt.subplots(figsize=(12,6))\nfor d in range(7):\n    df_hn[df_hn.Dayofweek == d].groupby(\"Hour\").mean().delta_s.plot()\nplt.legend(list(dow_dic.values()))\nplt.ylabel(\"stories intervals\");\nplt.xlabel(\"Time of day hour (Pacific)\")\nplt.axvline(x=6, c='0.6', linestyle=\"dashed\")\nplt.axvline(x=12,  c='0.6', linestyle=\"dashed\")\n","a28c7835":"index_wk_6_12= (df_hn.Dayofweek<5) & (df_hn.delta_s < 1000) & (df_hn.Hour<12) & (df_hn.Hour>6)\nplt.hist(df_hn.delta_s[index_wk_6_12],100, density=True)\nstory_rate = 1\/(df_hn.delta_s[index_wk_6_12].mean()) # 1\/100 sec\nt = np.arange(1000)\ny = story_rate*np.exp(-story_rate*t)\nplt.plot(t,y, label=\"theoretical from mean rate\")\nplt.xlabel(\"seconds\");\nplt.ylabel(\"density\");\nplt.title('Interarrival time for Hacker News, constant rate')\nplt.legend(loc='upper right')","6bc6f1af":"outlier_max=1000\ndf_hn_high = df_hn[index_wk_6_12]\nstory_rate = 1\/(df_hn_high.delta_s[df_hn_high.delta_s[index_wk_6_12]<outlier_max].mean()) # 1\/100 sec\nprint(f'one story every {1\/story_rate:.0f} seconds on average')","9860c585":"import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom scipy.stats import poisson\n\n\nflip_events = np.random.binomial(1,story_rate,1000000)\n\ndef events_to_intervals(x):\n    tmp = np.diff(x.cumsum())\n    idx_ev = np.where(tmp == 1)\n    return np.diff(idx_ev)[0]\n\ninterval_times = events_to_intervals(flip_events)\nplt.hist(df_hn.delta_s[index_wk_6_12],100,\n         label=\"HN data\", density=True)\nplt.hist(interval_times,bins=999,color=\"r\", \n         histtype=\"step\",alpha=0.5,\n         range=(1,1000),density=True, label=\"Bernoulli\")\nplt.ylabel(\"probability\")\nplt.title('Interarrival time for Hacker News, constant rate')\nplt.title(\"distribution of inter-arrival time\")\nplt.legend(loc='upper right')","092d95fd":"flip_events[:10]","3a73af81":"### Looking closer at the arrival rate patterns","7e02a641":"# Hacker News, interarrival time of stories posted\n\n","2a285d0f":"Theoretical interarrival rate\n$$\n\\frac{1}{101}e^{(-\\frac{1}{101}t)}\n$$\n","d2580d52":"## Data loading from BigQuery","e3557f70":"This kernel is a fork from from [this kernel](https:\/\/www.kaggle.com\/vksbhandary\/big-data-analysis-analyzing-hacker-news-stories)\n\nIt is the accompanying notebook for the Medium story [The Incredible Shrinking Bernoulli](https:\/\/medium.com\/@jfrederic.plante\/the-incredible-shrinking-bernoulli-de16aac524a)","fe9bb194":"### Back to coin flipping","c9bb22f1":"## Loading Hacker News dataframe","416c7738":"### Utils","9ae96e80":"This seems to indicate really 4 modes: week-end vs week and Day pattern. Weird spike on Monday?\nWeek-end are overall slower in terms of stories posted. Saturday and Sunday are equivalent","c28b75ed":"\n### A first look"}}