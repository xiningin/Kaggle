{"cell_type":{"c830d14a":"code","d11574e9":"code","d400eadd":"code","deba6a42":"code","b8248851":"code","851aad16":"code","6227d337":"code","2888700a":"code","1e1cfb7b":"code","f6dae6a0":"code","845f2aef":"code","24a6dfcb":"code","e53bc5f4":"code","b25fcbea":"code","dd1bbded":"code","c432b647":"code","dc028e50":"code","36a572fe":"code","8729a6d0":"code","e9320c8c":"code","062f1836":"code","fb086300":"code","7d7b7902":"code","215fc23c":"code","79ce62aa":"code","8eae344c":"code","bb5aeaaf":"code","dba161f8":"code","f65f78e1":"code","39d06635":"code","48b25c9e":"code","11317b94":"markdown","9b1e1608":"markdown","8a68607a":"markdown"},"source":{"c830d14a":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.python.keras.models import Sequential,model_from_json\nfrom tensorflow.python.keras.preprocessing import image\nfrom tensorflow.keras.callbacks            import ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.applications import VGG16\nfrom tensorflow.python.keras.optimizers import Adam\nimport numpy as np\nimport os \nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport os\nimport zipfile\nimport cv2\nimport shutil\nimport random\nimport pandas as pd\nfrom matplotlib.image import imread\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","d11574e9":"file = files.upload()\np = os.path.abspath('kaggle.json')\nprint(p)","d400eadd":"!pip install kaggle","deba6a42":"!mkdir ~\/.kaggle\np = os.path.abspath('.kaggle')\nprint(p)\n!ls","b8248851":"!mv \/content\/kaggle.json ~\/.kaggle\n!kaggle competitions download -c dogs-vs-cats","851aad16":"!unzip '\/content\/test1.zip'\n!unzip '\/content\/train.zip'","6227d337":"# \u041a\u0430\u0442\u0430\u043b\u043e\u0433 \u0441 \u043d\u0430\u0431\u043e\u0440\u043e\u043c \u0434\u0430\u043d\u043d\u044b\u0445\ndata_dir = '\/content\/train'\n# \u041a\u0430\u0442\u0430\u043b\u043e\u0433 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\ntrain_dir = 'train01'\ntest_sub = 'final-dataset'\n# \u041a\u0430\u0442\u0430\u043b\u043e\u0433 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438\nval_dir = 'val'\n# \u041a\u0430\u0442\u0430\u043b\u043e\u0433 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\ntest_dir = 'test01'\n# \u0427\u0430\u0441\u0442\u044c \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\ntest_data_portion = 0.15\n# \u0427\u0430\u0441\u0442\u044c \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438\nval_data_portion = 0.15\n# \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u043e\u0434\u043d\u043e\u043c \u043a\u043b\u0430\u0441\u0441\u0435\nnb_images = 12500","2888700a":"def create_directory(dir_name):\n    if os.path.exists(dir_name):\n        shutil.rmtree(dir_name)\n    os.makedirs(dir_name)\n    os.makedirs(os.path.join(dir_name, \"cats\"))\n    os.makedirs(os.path.join(dir_name, \"dogs\"))","1e1cfb7b":"create_directory(train_dir)\ncreate_directory(val_dir)\ncreate_directory(test_sub)\ncreate_directory(test_dir)","f6dae6a0":"def copy_images(start_index, end_index, source_dir, dest_dir):\n    for i in range(start_index, end_index):\n        shutil.copy2(os.path.join(source_dir, \"cat.\" + str(i) + \".jpg\"), \n                    os.path.join(dest_dir, \"cats\"))\n        shutil.copy2(os.path.join(source_dir, \"dog.\" + str(i) + \".jpg\"), \n                   os.path.join(dest_dir, \"dogs\"))","845f2aef":"final_data = int(nb_images * 0.5)\nstart_val_data_idx = int(nb_images * (1 - val_data_portion - test_data_portion))\nstart_test_data_idx = int(nb_images * (1 - test_data_portion))\nprint(start_val_data_idx)\nprint(final_data)\nprint(start_test_data_idx)","24a6dfcb":"test = '\/content\/test1'\ncopy_images(0, final_data, data_dir, test_sub)\ncopy_images(0, start_val_data_idx, data_dir, train_dir)\ncopy_images(start_val_data_idx, start_test_data_idx, data_dir, val_dir)\ncopy_images(start_test_data_idx, nb_images, data_dir, test_dir)","e53bc5f4":"img_width, img_height = 150, 150\ninput_shape = (img_width, img_height, 3)\nbatch_size = 10\nnb_train_samples = 17500\nnb_validation_samples = 3750\nnb_test_samples = 3750","b25fcbea":"# define location of dataset\nfolder = '\/content\/train\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + 'dog.' + str(i) + '.jpg'\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tplt.imshow(image)\n# show the figure\nplt.show()","dd1bbded":"vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))","c432b647":"datagen = ImageDataGenerator(rescale=1. \/ 255)","dc028e50":"train_dir = '\/content\/train01'\ntrain_generator = datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_width,img_height),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False)","36a572fe":"val_generator = datagen.flow_from_directory(\n    val_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False)","8729a6d0":"test_generator = datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False)","e9320c8c":"features_train = vgg16_net.predict_generator(\n        train_generator, \n        nb_train_samples \/\/ batch_size)\nnp.save(open('\/content\/features_train.npy', 'wb'), features_train)","062f1836":"features_val = vgg16_net.predict_generator(\n        val_generator, nb_validation_samples \/\/ batch_size)\nnp.save(open('\/content\/features_val.npy', 'wb'), features_val)","fb086300":"features_test = vgg16_net.predict_generator(\n        test_generator, nb_test_samples \/\/ batch_size)\nnp.save(open('\/content\/features_test.npy', 'wb'), features_test)","7d7b7902":"labels_train =  np.array(\n        [0] * (nb_train_samples \/\/ 2) + [1] * (nb_train_samples \/\/ 2))\nlabels_val =  np.array(\n        [0] * (nb_validation_samples \/\/ 2) + [1] * (nb_validation_samples \/\/ 2))\nlabels_test =  np.array(\n        [0] * (nb_test_samples \/\/ 2) + [1] * (nb_test_samples \/\/ 2))","215fc23c":"features_train = np.load(open('features_train.npy', 'rb'))\nfeatures_val = np.load(open('features_val.npy', 'rb'))\nfeatures_test = np.load(open('features_test.npy', 'rb'))","79ce62aa":"def model_init_():\n  model = Sequential()\n  model.add(Flatten(input_shape=features_train.shape[1:]))\n  model.add(Dense(512, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(1, activation='sigmoid'))\n  return model\nmodel = model_init_()","8eae344c":"model.compile(optimizer='Adam',\n              loss='binary_crossentropy', metrics=['accuracy'])","bb5aeaaf":"\u0441heckpoint = ModelCheckpoint('content\/mnist-cnn.h5', \n                              monitor='val_acc', \n                              save_best_only=True,\n                              verbose=1)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","dba161f8":"history = model.fit(features_train, labels_train,\n              epochs=30,\n              batch_size=64,\n              validation_data=(features_val, labels_val), \n              verbose=2,\n              callbacks=[\u0441heckpoint, learning_rate_reduction])","f65f78e1":"model.save('\/content\/model01.h5')","39d06635":"def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history[acc])+1),len(model_history.history[acc])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \nplot_model_history(history)","48b25c9e":"scores = model.evaluate(features_test, labels_test, verbose=1)\nprint(\"\u0410\u043a\u043a\u0443\u0440\u0430\u0442\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445: %.2f%%\" % (scores[1]*100))","11317b94":"## UPLOADING FILES\n\n---\n\n","9b1e1608":"## Data Preparation\n\n---\n\n","8a68607a":"## Creating model\n\n---\n\n\n\n---\n\n"}}