{"cell_type":{"aa3f47dd":"code","cb4c2fc4":"code","b4f8f81f":"code","5ba4a6e6":"code","67e421fe":"code","63564dec":"code","0acc88f7":"code","686e4073":"code","129c7aa0":"code","7ff82682":"code","f9c5e7ee":"code","bcddf4b5":"code","c968cdd8":"code","dd8603c6":"code","ca641476":"code","4dbd5e20":"code","e062507a":"code","0959f387":"code","c9b01ee4":"code","b0523dc4":"code","ea4e3600":"code","55a79516":"code","dee5bc89":"code","c62d2127":"code","19dae83d":"code","2468d19c":"code","c61d020d":"code","80077034":"code","ebb75697":"code","8a532b05":"code","aa89a3d8":"code","bfb4a01d":"code","dace8044":"code","1e639cc8":"code","d6e1e1ba":"code","42f1f8eb":"code","33fc5e7f":"code","27d80253":"code","e75d41ca":"code","1c4af69e":"code","905ee334":"code","5f8c231f":"code","ac5fa504":"code","06ab95ba":"code","d50a04bf":"code","2b545f7e":"code","e004e825":"code","aee7299d":"code","f8b32fe7":"code","3f43d312":"code","fd998b94":"code","44c1508a":"code","6fed1b85":"code","e718aa96":"code","b5cedea2":"code","a337a52f":"code","7fe40f45":"code","a44a611b":"code","33b63410":"code","2062bed1":"code","95466fa9":"code","a0427801":"code","7148e7c8":"code","741d5ec7":"code","d182e386":"code","db2da186":"code","2af6c512":"code","d6229a07":"code","429eee73":"code","a5adbf31":"code","e0e478d4":"code","3708c45f":"code","0025e617":"code","d3ebb94d":"code","dcfbd393":"code","436e09f6":"code","de7b4bab":"code","15f2c06e":"code","73a9b2fc":"code","7cd32fa2":"code","0b2bf657":"code","f7fd1b49":"code","51ed9668":"code","00cdd82f":"markdown","57085aa1":"markdown","cc352fc7":"markdown","32df16ff":"markdown","693df90d":"markdown","f25c016b":"markdown","31987761":"markdown","b01cb9b0":"markdown","ea8805a2":"markdown","042c89b9":"markdown","dec5dc64":"markdown","00c24ce6":"markdown","db756679":"markdown","f06889c6":"markdown","7d24a4e1":"markdown","71bc877d":"markdown","6196177b":"markdown","50e72ac3":"markdown","23a58cbf":"markdown","124a4617":"markdown"},"source":{"aa3f47dd":"# TensorFlow\/keras\u306e\u6700\u65b0version\u3067\u758e\u884c\u5217\u5468\u308a\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\u30d0\u30fc\u30b8\u30e7\u30f3\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n# \u73fe\u72b6\u3067\u306f\u672a\u89e3\u6c7a\u306e\u3088\u3046\u3067\u3001PyTorch\u4f7f\u3063\u305f\u307b\u3046\u304c\u3044\u3044\u304b\u3082\u3002\n!pip uninstall tensorflow -y\n!pip install tensorflow==1.11.0\n\n!pip uninstall keras -y\n!pip install keras==2.2.4","cb4c2fc4":"import gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, mean_squared_log_error, log_loss\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom category_encoders import OrdinalEncoder\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","b4f8f81f":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.tot_cur_bal\nX_train = df_train.drop(['tot_cur_bal'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)","5ba4a6e6":"X_train = X_train[y_train.isnull()==False]\ny_train = y_train[y_train.isnull()==False]","67e421fe":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","63564dec":"from category_encoders import OrdinalEncoder\n\ncats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","0acc88f7":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","686e4073":"X_train.head()","129c7aa0":"X_test.head()","7ff82682":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n# \u6b21\u56deBuild Model\u306e\u5185\u5bb9\u3067\u3059\u304c\u3001\u662f\u975e\u5404\u81ea\u691c\u8a0e\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\nscores = []\n\nskf = KFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf = GradientBoostingRegressor() \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict(X_val)\n    score = mean_squared_error(y_val, y_pred)**0.5\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","f9c5e7ee":"# Fold_4\u306eactual vs pred\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u307f\u3088\u3046\nplt.figure(figsize=[7,7])\nplt.scatter(y_val, y_pred, s=5)\nplt.xlabel('actual')\nplt.ylabel('pred')\nplt.show()","bcddf4b5":"%%time\n# \u91d1\u984d\u7cfb\u306a\u306e\u3067\u3001RMSLE\u3067\u6700\u9069\u5316\u3057\u3066\u307f\u308b\u3002\n# \u4f55\u3082\u6307\u5b9a\u3057\u306a\u3044\u3068\u5927\u62b5\u306fRMSE\u3067\u6700\u9069\u5316\u3055\u308c\u308b\u3002\u3053\u3053\u3067\u306f\u5bfe\u6570\u3092\u53d6\u3063\u3066\u304a\u304f\u3068\u3061\u3087\u3046\u3069RMSLE\u306e\u6700\u9069\u5316\u306b\u76f8\u5f53\u3059\u308b\u3002\nscores = []\n\nskf = KFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf = GradientBoostingRegressor() \n    \n    clf.fit(X_train_, np.log1p(y_train_))\n    y_pred = np.expm1(clf.predict(X_val))\n    score = mean_squared_log_error(y_val, y_pred)**0.5\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","c968cdd8":"# Fold_4\u306eactual vs pred\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u307f\u3088\u3046\nplt.figure(figsize=[7,7])\nplt.scatter(y_val, y_pred, s=5)\nplt.xlabel('actual')\nplt.ylabel('pred')\nplt.show()","dd8603c6":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.purpose\nX_train = df_train.drop(['purpose'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)","ca641476":"y_train ","4dbd5e20":"le = LabelEncoder()\ny_train = le.fit_transform(y_train)","e062507a":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","0959f387":"y_train","c9b01ee4":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","b0523dc4":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","ea4e3600":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train[test_ix]\n    \n    clf = GradientBoostingClassifier() \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)\n    score = log_loss(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","55a79516":"y_pred","dee5bc89":"labels = np.argmax(y_pred, axis=1)\nlabels","c62d2127":"# \u4e88\u6e2c\u5024\u3092\u5143\u306e\u30e9\u30d9\u30eb\u306b\u623b\u3057\u3066\u307f\u308b\u3002\nle.inverse_transform(labels)","19dae83d":"le.inverse_transform(y_val)","2468d19c":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)","c61d020d":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","80077034":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","ebb75697":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","8a532b05":"# \u3042\u3068\u3067\u307e\u305f\u4f7f\u3046\u306e\u3067\u4fdd\u5b58\u3057\u3066\u304a\u304f\nX_train.to_csv('..\/X_train_tree.csv')\nX_test.to_csv('..\/X_test_tree.csv')","aa89a3d8":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf = GradientBoostingClassifier() \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","bfb4a01d":"scores = np.array(scores)","dace8044":"scores.mean(), scores.std()","1e639cc8":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\n\ndel df_train\ngc.collect()","d6e1e1ba":"X_train.issue_d.head()","42f1f8eb":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        if col != 'issue_d':\n            cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","33fc5e7f":"year = X_train.issue_d.dt.year\n\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","27d80253":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","e75d41ca":"X_train_, y_train_ = X_train[year < 2015], y_train[year < 2015]\nX_val, y_val = X_train[year >= 2015], y_train[year >= 2015]","1c4af69e":"clf = GradientBoostingClassifier() \n\nclf.fit(X_train_, y_train_)\ny_pred = clf.predict_proba(X_val)[:,1]\nscore = roc_auc_score(y_val, y_pred)\n\nprint('Time Split Score is %f' % (score))","905ee334":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ndel df_train\ngc.collect()","5f8c231f":"# \u4f4f\u6240\uff08\u5dde\uff09\u3092\u30b0\u30eb\u30fc\u30d7\u8b58\u5225\u5b50\u3068\u3057\u3066\u5206\u96e2\u3057\u3066\u304a\u304f\u3002\u65e5\u4ed8\u3068\u30c6\u30ad\u30b9\u30c8\u3082\u9664\u3044\u3066\u304a\u304f\u3002\ngroups = X_train.addr_state.values\n\nX_train.drop(['issue_d', 'emp_title', 'addr_state'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title', 'addr_state'], axis=1, inplace=True)","ac5fa504":"groups","06ab95ba":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","d50a04bf":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","2b545f7e":"score","e004e825":"gkf = GroupKFold(n_splits=5)\nscores = []\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(gkf.split(X_train, y_train, groups))):\n    \n    X_train_, y_train_, groups_train_ = X_train.iloc[train_ix], y_train.iloc[train_ix], groups[train_ix]\n    X_val, y_val, groups_val = X_train.iloc[test_ix], y_train.iloc[test_ix], groups[test_ix]\n    \n    print('Train Groups', np.unique(groups_train_))\n    print('Val Groups', np.unique(groups_val))\n    \n    clf = GradientBoostingClassifier(n_estimators=1) \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))\n    print('\\n')","aee7299d":"clf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n                                importance_type='split', learning_rate=0.05, max_depth=-1,\n                                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n                                n_estimators=9999, n_jobs=-1, num_leaves=15, objective=None,\n                                random_state=71, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n                                subsample=1.0, subsample_for_bin=200000, subsample_freq=0)","f8b32fe7":"%%time\nclf.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='auc', eval_set=[(X_val, y_val)])","3f43d312":"imp = DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance']).sort_values(['importance'], ascending=False)\nimp","fd998b94":"imp.shape","44c1508a":"use_col = imp.index[:10]","6fed1b85":"X_train_[use_col]","e718aa96":"fig, ax = plt.subplots(figsize=(5, 8))\nlgb.plot_importance(clf, max_num_features=50, ax=ax, importance_type='gain')","b5cedea2":"y_pred = clf.predict_proba(X_val)[:,1]\ny_pred","a337a52f":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\n#df_train = pd.read_csv('..\/input\/train.csv', index_col=0)\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\n\ndel df_train\ngc.collect()","7fe40f45":"cat = []\nnum = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        if col != 'emp_title':\n            cat.append(col)\n    else:\n        if col != 'issue_d':\n            num.append(col)","a44a611b":"# train\/test\n# \u7279\u5fb4\u91cf\u30bf\u30a4\u30d7\u3054\u3068\u306b\u5206\u5272\u3059\u308b\ncat_train = X_train[cat]\ntxt_train = X_train.emp_title\nX_train = X_train[num]\n\ncat_test = X_test[cat]\ntxt_test = X_test.emp_title\nX_test = X_test[num]","33b63410":"from sklearn.preprocessing import StandardScaler","2062bed1":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train.fillna(X_train.median()))\nX_test = scaler.transform(X_test.fillna(X_test.median()))","95466fa9":"from sklearn.preprocessing import OneHotEncoder\nfrom category_encoders import OrdinalEncoder\nfrom tqdm import tqdm_notebook as tqdm","a0427801":"for col in tqdm(cat):\n    ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n    oe = OrdinalEncoder(return_df=False)\n    \n    cat_train[col] = oe.fit_transform(cat_train[[col]])\n    cat_test[col] = oe.transform(cat_test[[col]])    \n    \n    train = ohe.fit_transform(cat_train[[col]])\n    test = ohe.transform(cat_test[[col]])\n    \n    X_train = sp.sparse.hstack([X_train, train])\n    X_test = sp.sparse.hstack([X_test, test])","7148e7c8":"X_train.shape, X_test.shape","741d5ec7":"from sklearn.feature_extraction.text import TfidfVectorizer","d182e386":"tfidf = TfidfVectorizer(max_features=100000, analyzer='word', ngram_range=(1, 2))","db2da186":"train = tfidf.fit_transform(txt_train.fillna('#'))\ntest = tfidf.transform(txt_test.fillna('#'))\n\nX_train = sp.sparse.hstack([X_train, train])\nX_test = sp.sparse.hstack([X_test, test])\n\nX_train = X_train.tocsr()# \u884c\u65b9\u5411\u306e\u30b9\u30e9\u30a4\u30b9\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u5909\u63db\u3059\u308b\nX_test = X_test.tocsr()","2af6c512":"del cat_train, cat_test, txt_train, txt_test\ngc.collect()","d6229a07":"num_train = int(X_train.shape[0]*0.7)\n\nX_train_ = X_train[:num_train, :]\ny_train_ = y_train[:num_train]\n\nX_val = X_train[num_train:, :]\ny_val = y_train[num_train:]","429eee73":"from keras.layers import Input, Dense ,Dropout, BatchNormalization\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping","a5adbf31":"# \u30b7\u30f3\u30d7\u30eb\u306aMLP\n\ndef create_model(input_dim):\n    inp = Input(shape=(input_dim,), sparse=True) # \u758e\u884c\u5217\u3092\u5165\u308c\u308b\n    x = Dense(194, activation='relu')(inp)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    outp = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n    \n    return model","e0e478d4":"X_train_.shape","3708c45f":"model = create_model(X_train_.shape[1])\n\nes = EarlyStopping(monitor='val_loss', patience=0)\n\nmodel.fit(X_train_, y_train_, batch_size=32, epochs=999, validation_data=(X_val, y_val), callbacks=[es])","0025e617":"roc_auc_score(y_val, model.predict(X_val))","d3ebb94d":"X_train = pd.read_csv('..\/X_train_tree.csv', index_col=0)\nX_test = pd.read_csv('..\/X_test_tree.csv', index_col=0)","dcfbd393":"from sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nskf = StratifiedKFold(n_splits=3, random_state=71, shuffle=True)\ngkf = GroupKFold(n_splits=3, )\n\nparam_grid = {'learning_rate': [0.05],\n                    'max_depth':  np.linspace(5,12,4,dtype = int),\n                    'colsample_bytree': np.linspace(0.5, 1.0, 3),\n                    'random_state': [71]}\n\nfit_params = {\"early_stopping_rounds\": 20,\n                    \"eval_metric\": 'auc',\n                    \"eval_set\": [(X_val, y_val)]}\n\nclf  = LGBMClassifier(n_estimators=9999, n_jobs=1)\n\ngs = GridSearchCV(clf, param_grid, scoring='roc_auc',  \n                              n_jobs=-1, cv=skf, verbose=True)\n\ngs.fit(X_train_, y_train_, **fit_params,)","436e09f6":"gs.best_score_","de7b4bab":"gs.best_estimator_","15f2c06e":"from hyperopt import fmin, tpe, hp, rand, Trials\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom lightgbm import LGBMClassifier","73a9b2fc":"def objective(space):\n    scores = []\n\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n    for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n        clf = LGBMClassifier(n_estimators=9999, **space) \n\n        clf.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='auc', eval_set=[(X_val, y_val)])\n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n    scores = np.array(scores)\n    print(scores.mean())\n    \n    return -scores.mean()","7cd32fa2":"space ={\n        'max_depth': hp.choice('max_depth', np.arange(10, 30, dtype=int)),\n        'subsample': hp.uniform ('subsample', 0.8, 1),\n        'learning_rate' : hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n        'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05)\n    }","0b2bf657":"trials = Trials()\n\nbest = fmin(fn=objective,\n              space=space, \n              algo=tpe.suggest,\n              max_evals=20, \n              trials=trials, \n              rstate=np.random.RandomState(71) \n             )","f7fd1b49":"LGBMClassifier(**best)","51ed9668":"trials.best_trial['result']","00cdd82f":"## LightGBM","57085aa1":"## \u6b21\u306f\u591a\u5024\u5206\u985e","cc352fc7":"## \u5c64\u5316\u62bd\u51fa","32df16ff":"## \u5206\u985e\u5668\u306b\u5165\u308c\u3089\u308c\u308b\u3088\u3046\u306b\u6700\u4f4e\u9650\u306e\u30a8\u30f3\u30b3\u30fc\u30c9\u3092\u3057\u3066\u304a\u304f\u3002  \n\u305f\u3060\u3057\u3001\u3053\u306e\u72b6\u614b\u3067\u306f\u30d9\u30b9\u30c8\u306a\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304b\u3089\u306f\u7a0b\u9060\u3044\u306e\u306f\u3053\u306e\u4e00\u9031\u9593\u3067\u4f53\u9a13\u3057\u305f\u3068\u304a\u308a\u3067\u3059\u3002\n\u5f15\u304d\u7d9a\u304d\u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0\u3082\u9811\u5f35\u308a\u307e\u3057\u3087\u3046","693df90d":"# \u30cf\u30a4\u30d1\u30e9\u6700\u9069\u5316\u30fb\u30e2\u30c7\u30eb\u9078\u629e","f25c016b":"## \u6700\u5f8c\u306b\u30c6\u30ad\u30b9\u30c8\u306e\u51e6\u7406","31987761":"# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u3068\u78ba\u8a8d","b01cb9b0":"## \u307e\u305aNumeric\u3092StandardScaler","ea8805a2":"## Neural Network","042c89b9":"## \u4e8c\u5024\u5206\u985e\u306f\u3084\u3063\u305f\u306e\u3067\u3001\u305d\u308c\u4ee5\u5916\u3092\u3084\u3063\u3066\u307f\u3088\u3046\u3002\u307e\u305a\u306f\u56de\u5e30\u304b\u3089\u3002\u53e3\u5ea7\u6b8b\u9ad8\u3092\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u8a66\u3057\u3066\u307f\u3088\u3046\u3002","dec5dc64":"# Validation Scheme\u306e\u69cb\u7bc9\u306b\u30c1\u30e3\u30ec\u30f3\u30b8","00c24ce6":"## \u4eca\u5ea6\u306ftime split","db756679":"## \u5909\u6570\u91cd\u8981\u5ea6\u3092\u898b\u3066\u307f\u3088\u3046","f06889c6":"## \u5909\u6570\u91cd\u8981\u5ea6\u3092\u5143\u306b\u7279\u5fb4\u91cf\u9078\u629e\u3092\u3057\u3066\u307f\u3088\u3046","7d24a4e1":"## hyperopt\u3082\u3084\u3063\u3066\u307f\u308b","71bc877d":"\u3053\u3053\u3067\u306f\u4f4f\u6240\uff08\u5dde\uff09\u3067\u30b0\u30eb\u30fc\u30d7\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30cb\u30f3\u30b0\u3092\u884c\u3046\u3002","6196177b":"# \u5404\u4e88\u6e2c\u30bf\u30b9\u30af\u306e\u578b\u3092\u30cf\u30f3\u30ba\u30aa\u30f3\u3067\u3084\u3063\u3066\u307f\u3088\u3046","50e72ac3":"## \u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3057\u3066\u307f\u3088\u3046","23a58cbf":"## \u6b21\u306bcategorical\u3092One-hot","124a4617":"## GroupKfold"}}