{"cell_type":{"cb6c2fa6":"code","9cff5295":"code","f33aa45b":"code","39f65262":"code","1b5aef25":"code","4ab0a0e2":"code","e468da57":"code","6494da11":"code","38f61d01":"code","f2809e88":"code","ba970e27":"code","41d817e4":"code","53bc3d63":"code","ae982096":"code","010d2a45":"code","355a22a8":"code","4a41b893":"code","6f8d709a":"code","1ff4f759":"code","350caf98":"code","d2c89e26":"markdown","abc49d66":"markdown","332e2ab5":"markdown","7d49c55e":"markdown","ae4935cf":"markdown","9fe6c34a":"markdown","c59f899b":"markdown","e24dc6c3":"markdown","af21434f":"markdown","ed644e3f":"markdown","a4905534":"markdown","75bd0c82":"markdown","e49c61ca":"markdown","d2387443":"markdown","1d35b87e":"markdown","8c0c778e":"markdown","6f9b9a13":"markdown","c335876c":"markdown"},"source":{"cb6c2fa6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #data science plot\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import ShuffleSplit\n\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.\n\n#Ref - https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python","9cff5295":"dataFrame_train = pd.read_csv('..\/input\/train.csv')\ndataFrame_test = pd.read_csv('..\/input\/test.csv')\ndataFrame = pd.concat([dataFrame_train, dataFrame_test])","f33aa45b":"dataFrame.head(5)","39f65262":"y = dataFrame_train['SalePrice']\ndataFrame = dataFrame.drop(['SalePrice', 'Utilities', 'Id'], axis=1)","1b5aef25":"dataFrame.info()","4ab0a0e2":"dataFrame.columns[dataFrame.isna().any()].tolist()","e468da57":"dataFrame.Alley.fillna('NA', inplace=True)\ndataFrame.BsmtCond.fillna('NA', inplace=True)\ndataFrame.BsmtExposure.fillna('NA', inplace=True)\ndataFrame.BsmtFinSF1.fillna(0, inplace=True)\ndataFrame.BsmtFinSF2.fillna(0, inplace=True)\ndataFrame.BsmtFinType1.fillna('NA', inplace=True)\ndataFrame.BsmtFinType2.fillna('NA', inplace=True)\ndataFrame.BsmtFullBath.fillna(0, inplace=True)\ndataFrame.BsmtHalfBath.fillna(0, inplace=True)\ndataFrame.BsmtQual.fillna(\"NA\", inplace=True)\ndataFrame.BsmtUnfSF.fillna(0, inplace=True)\ndataFrame.Electrical.fillna('SBrkr', inplace=True)\ndataFrame.Exterior1st.fillna('VinylSd', inplace=True)\ndataFrame.Exterior2nd.fillna('VinylSd', inplace=True)\ndataFrame.Fence.fillna('NA', inplace=True)\ndataFrame.FireplaceQu.fillna('NA', inplace=True)\ndataFrame.Functional.fillna('Typ', inplace=True)\ndataFrame.GarageArea.fillna(0, inplace=True)\ndataFrame.GarageCond.fillna('NA', inplace=True)\ndataFrame.GarageCars.fillna(0, inplace=True)\ndataFrame.GarageYrBlt.fillna(0, inplace=True)\ndataFrame.GarageQual.fillna(\"NA\", inplace=True)\ndataFrame.GarageFinish.fillna(\"NA\", inplace=True)\ndataFrame.GarageType.fillna(\"NA\", inplace=True)\ndataFrame.KitchenQual.fillna(\"TA\", inplace=True)\ndataFrame.LotFrontage.fillna(dataFrame.LotFrontage.mean(), inplace=True)\ndataFrame.MSZoning.fillna(\"RL\", inplace=True)\ndataFrame.MasVnrType.fillna(\"None\", inplace=True)\ndataFrame.MasVnrArea.fillna(0, inplace=True)\ndataFrame.MiscFeature.fillna('NA', inplace=True)\ndataFrame.PoolQC.fillna('NA', inplace=True)\ndataFrame.SaleType.fillna(\"WD\", inplace=True)\ndataFrame.TotalBsmtSF.fillna(0, inplace=True)\n#dataFrame.Utilities.fillna('AllPub', inplace=True)","6494da11":"#dataFrame['houseAge'] = dataFrame['YrSold'] -( dataFrame['YearRemodAdd'] + dataFrame['YearBuilt'])\/2.0","38f61d01":"#Columns which have integer values but are actually categorical\nint_to_cat_columns = ['MSSubClass']","f2809e88":"cat_columns = dataFrame.select_dtypes(include='object').columns.values.tolist()\ndataFrame = pd.get_dummies(dataFrame, columns=cat_columns+int_to_cat_columns)","ba970e27":"dataFrame.columns.tolist()","41d817e4":"#Rebuild train and test data frames\ndataFrame_trainval = dataFrame.iloc[:y.shape[0], :]\nX_trainval = dataFrame_trainval.values\ndataFrame_trainval['SalePrice'] = y\ndataFrame_test = dataFrame.iloc[y.shape[0]:, :]\nX_test = dataFrame_test.values","53bc3d63":"splitter = ShuffleSplit(n_splits=1, test_size=0.2)\nsplits = list(splitter.split(X_trainval, y))[0]\ntrain_ind, test_ind = splits","ae982096":"X_train = X_trainval[train_ind]\nX_val  = X_trainval[test_ind]\n\ny_train = y[train_ind]\ny_val  = y[test_ind]","010d2a45":"xgb = XGBRegressor(n_estimators=300, max_depth=3, learning_rate=0.12,subsample=0.5)","355a22a8":"y_log_train = np.log(y_train)\ny_log_val = np.log(y_val)","4a41b893":"xgb.fit(X_train, y_log_train, eval_set=[(X_val, y_log_val)], verbose=True)","6f8d709a":"y_pred = np.exp(xgb.predict(X_test))","1ff4f759":"res = pd.DataFrame()\nres['Id'] = dataFrame_test['Id']\nres['SalePrice'] = y_pred\nres.to_csv('rf.csv', index=False)","350caf98":"#https:\/\/towardsdatascience.com\/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96","d2c89e26":"Load train and test data frames and combine them to a single data frame.","abc49d66":"Load sale price into y vector, and drop it from the dataFrame","332e2ab5":"Replace missing values with NA values when NA means something, esle replace it with mean\/most frequent values.","7d49c55e":"Calculate a new feature `houseAge` which determines an average age of the house since its been built\/remodeled.","ae4935cf":"threshold_versions = [0.5, 0.4, 0.3, 0.2, 0.1]\nsalePrice_correlations = corr['SalePrice'] \nfeature_versions = []\nfor threshold in threshold_versions:\n    features = dataFrame_train.columns[(salePrice_correlations > threshold) & (salePrice_correlations < 1)]\n    feature_versions.append(features)","9fe6c34a":"Build different model versions with different features, chosen based on correlation greater than a specific value.****","c59f899b":"for idx, features in enumerate(feature_versions):\n    lr = LinearRegression()\n    X_train = dataFrame_train.loc[:, features]\n    y_train = dataFrame_train['SalePrice']\n    X_test = dataFrame_test.loc[:, features]\n    lr.fit(X_train, y_train)\n    y_pred = lr.predict(X_test)\n    res = pd.DataFrame()\n    res['Id'] = dataFrame_test['Id']\n    res['SalePrice'] = y_pred\n    res.to_csv('lr_{}.csv'.format(idx), index=False)","e24dc6c3":"Create a correlation matrix and generate a heatmap","af21434f":"Convert all categorical variables to dummy variables.","ed644e3f":"Look at how much data we got, and Identify columns with missing data.","a4905534":"**Predict Housing Prices (so you can get a better  house)**","75bd0c82":"For each set of features, build training and test matrices X and y, run the models, create a new data Frame with the predictions and save it to a csv.","e49c61ca":"corr = dataFrame_train.corr()\n\n# Set up the matplotlib figure\n#f, ax = plt.subplots(figsize=(30, 20))\n\n# Generate a custom diverging colormap\n#cmap = sns.diverging_palette(359, -359, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\n#sns.heatmap(corr, cmap=cmap, vmax=1, vmin=-1, center=0,\n#            square=True, linewidths=1)","d2387443":"for idx, features in enumerate(feature_versions):\n    xgb = XGBRegressor()\n    X_train = dataFrame_train.loc[:, features]\n    y_train = dataFrame_train['SalePrice']\n    X_test = dataFrame_test.loc[:, features]\n    xgb.fit(X_train, y_train)\n    y_pred = xgb.predict(X_test)\n    res = pd.DataFrame()\n    res['Id'] = dataFrame_test['Id']\n    res['SalePrice'] = y_pred\n    res.to_csv('xgb_{}.csv'.format(idx), index=False)","1d35b87e":"rfr = RandomForestRegressor(n_jobs=-1)","8c0c778e":"rfr.fit(dataFrame_train.drop('SalePrice', axis=1), y)","6f9b9a13":"Run Linear Regression and Gradient Boosting models on each of the feature versions","c335876c":"y_pred = rfr.predict(dataFrame_test)"}}