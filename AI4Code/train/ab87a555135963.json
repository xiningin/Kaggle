{"cell_type":{"b02b95f7":"code","5791f25f":"code","1e12d50e":"code","219ea622":"code","6f5606a8":"code","42d85778":"code","b3945c07":"code","47c59cfa":"code","e400da0d":"code","25d7961d":"code","cb702e9d":"code","14ca6fcc":"code","805b8bb7":"code","e59de7f6":"code","cf59aad6":"code","fd48c38e":"code","2534e7fa":"code","3e6396eb":"code","0942bc11":"code","e4e2fb9e":"code","50a2cd41":"code","1e9a0918":"code","beaeff00":"code","c092c8cd":"code","c4eefec4":"code","aeba2372":"code","bbad9c06":"code","f1f9ff9f":"code","36d4cd15":"code","937eae2e":"code","3e44716c":"code","a88da971":"code","186a83c4":"code","f043e29b":"code","2ac21bf0":"code","37dd0de1":"code","cd7e1598":"code","ac8f3c3b":"code","fba64978":"code","6c18d417":"code","baeed122":"code","d8369b45":"code","ab12a3e3":"code","1fb46e50":"code","054f9d92":"code","100153d2":"code","67ebdf29":"code","5cf1ba20":"code","b7b99654":"code","2ca8d1ca":"code","9c3719c9":"code","6135b699":"code","e3429395":"code","49ee1af6":"code","6baba6ac":"code","6f5ec8dd":"code","87cdb124":"code","75ce40ce":"code","4e1b39a8":"code","3c0ec7f1":"code","03d5fbfb":"code","b8c08cb3":"code","10121da5":"code","014583cf":"code","d4e03923":"code","0b7e2abf":"code","f1b5afd1":"code","f8775da4":"code","f64d6f2f":"code","0aa445be":"code","a5063a2a":"markdown","10c12dce":"markdown","ab866b3e":"markdown","98bc59bd":"markdown","0140c92c":"markdown","7eb72732":"markdown","0bbaa798":"markdown","b47330ee":"markdown","737b81d7":"markdown","7c5c1cac":"markdown","336cbbb7":"markdown","e6ea12b9":"markdown","abfa2830":"markdown","8ad8c23e":"markdown","d9cade40":"markdown","ecbfe5a9":"markdown","6ac8eb4e":"markdown","117aba8a":"markdown","7dad4c69":"markdown","47e560f3":"markdown","e19ac9ac":"markdown","b9602bf6":"markdown","318021a7":"markdown","42de4ab5":"markdown","47b3eb9a":"markdown","ebab9cb1":"markdown","608c901b":"markdown","d70ab7f5":"markdown","342caebd":"markdown","bfcb4dcc":"markdown","78746c59":"markdown","8294d9a9":"markdown","af6e5d38":"markdown","79fd827e":"markdown","4b7a76a6":"markdown","66d0d7ff":"markdown","5bc4040a":"markdown","ae075f46":"markdown","55a577e2":"markdown","af723f70":"markdown","ed3d398c":"markdown","676e0bb4":"markdown","67129ab0":"markdown","8cf50dbd":"markdown","92c8d5cd":"markdown","64eb2dab":"markdown","787458c8":"markdown","13be1a6c":"markdown","4b8f4408":"markdown","e0e8280c":"markdown","e38acb86":"markdown","1b0c95af":"markdown","b022e719":"markdown","3f084c0c":"markdown","e0c606bf":"markdown","c6b1ddd6":"markdown","a10f1787":"markdown","3e5fae8d":"markdown","9022a321":"markdown","9a654dcd":"markdown","d11bad74":"markdown","33164f04":"markdown","7398722b":"markdown","1c7c379d":"markdown","4c33ad1a":"markdown","4c3d9c80":"markdown","5090c858":"markdown","389e8711":"markdown","0f8b4bb7":"markdown"},"source":{"b02b95f7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","5791f25f":"data = pd.read_csv('..\/input\/gtd\/globalterrorismdb_0718dist.csv' ,encoding= 'ISO-8859-1')  \nprint(f'Data Shape is {data.shape}')\ndata.head()","1e12d50e":"def drop(feature) :\n    global data\n    data.drop([feature],axis=1, inplace=True)\n    data.head()\n\ndef unique(feature) : \n    global data\n    print(f'Number of unique vaure are {len(list(data[feature].unique()))} which are : \\n {list(data[feature].unique())}')\n\ndef unique_all(show_value = True) : \n    global data\n    for col in data.columns : \n        print(f'Length of unique data for   {col}   is    {len(data[col].unique())} ')\n        if show_value == True  : \n            print(f'unique values ae {data[col].unique()}' )\n            print('-----------------------------')\n\ndef drop_nulls(percentage = 0.3) : \n    global data\n    for col in data.columns : \n        ratio =  data[col].isna().sum()\/data.shape[0]\n        if ratio >= percentage : \n            data.drop([col],axis=1, inplace=True)\n            print(f'Column {col} has been dropped since nulls percentage is {round(ratio *100)} %')\n\ndef count_nulls() : \n    global data\n    for col in data.columns : \n        if not data[col].isna().sum() == 0 : \n            print(f'Column {col} has been number of nulls {data[col].isna().sum()}')\n\n\ndef fillna(feature , val = 'none') : \n    global data\n    data[feature].fillna(val, inplace=True)\n\ndef cplot(feature) : \n    global data\n    sns.countplot(x=feature, data=data,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))\n\ndef spie(series) : \n    global data\n    plt.pie(series.values,labels=list(series.index),autopct ='%1.2f%%',labeldistance = 1.1,explode = [0.05 for i in range(len(series.values))])\n    plt.show()\n\ndef pie(feature) : \n    global data\n    plt.pie(data[feature].value_counts(),labels=list(data[feature].value_counts().index),\n        autopct ='%1.2f%%' , labeldistance = 1.1,explode = [0.05 for i in range(len(data[feature].value_counts()))] )\n    plt.show()\n\ndef make_xy(feature) : \n    global data\n    X = data.drop([feature], axis=1, inplace=False)\n    y = data[feature]\n    return X , y\n   \ndef encoder(feature , new_feature, drop = True) : \n    global data\n    enc  = LabelEncoder()\n    enc.fit(data[feature])\n    data[new_feature] = enc.transform(data[feature])\n    if drop == True : \n        data.drop([feature],axis=1, inplace=True)\n    \ndef max_counts(feature, number, return_rest = False) : \n    global data\n    counts = data[feature].value_counts()\n    values_list = list(counts[:number].values)\n    rest_value =  sum(counts.values) - sum (values_list)\n    index_list = list(counts[:number].index)\n\n    if return_rest : \n        values_list.append(rest_value )\n        index_list.append('rest items')\n\n    result = pd.Series(values_list, index=index_list)\n\n    if len(data[feature]) <= number : \n        result = None\n    return result\n\ndef remove_zero(feature , val = 0) :\n    global data\n    data = data[data[feature] != val]\n    \ndef show_details() : \n    global data\n    for col in data.columns : \n        print(f'for feature : {col}')\n        print(f'Number of Nulls is   {data[col].isna().sum()}')\n        print(f'Number of Unique values is   {len(data[col].unique())}')\n        print(f'random Value {data[col][0]}')\n        print(f'random Value {data[col][10]}')\n        print(f'random Value {data[col][20]}')\n        print('--------------------------')\n","219ea622":"data.shape","6f5606a8":"drop_nulls()","42d85778":"data.shape","b3945c07":"drop('eventid')\ndrop('country')\ndrop('region')\ndrop('attacktype1')\ndrop('targtype1')\ndrop('targsubtype1')\ndrop('natlty1')\ndrop('weaptype1')\ndrop('weapsubtype1')","47c59cfa":"data.head()","e400da0d":"unique_all(False)","25d7961d":"count_nulls()","cb702e9d":"show_details()","14ca6fcc":"unique('iyear')","805b8bb7":"cplot('iyear')","e59de7f6":"unique('imonth')","cf59aad6":"data.shape[0]","fd48c38e":"remove_zero('imonth')","2534e7fa":"data.shape[0]","3e6396eb":"unique('imonth')","0942bc11":"cplot('imonth')","e4e2fb9e":"unique('iday')","50a2cd41":"remove_zero('iday')","1e9a0918":"unique('iday')","beaeff00":"data.shape[0]","c092c8cd":"unique('extended')","c4eefec4":"data['latitude'].isna().sum()","aeba2372":"fillna('latitude',0)\nremove_zero('latitude')","bbad9c06":"data['latitude'].isna().sum()","f1f9ff9f":"data.shape[0]","36d4cd15":"fillna('longitude',0)\nremove_zero('longitude')\ndata['longitude'].isna().sum()","937eae2e":"data.shape[0]","3e44716c":"data['specificity'].isna().sum()","a88da971":"data['vicinity'].isna().sum()","186a83c4":"data['doubtterr'].isna().sum()","f043e29b":"unique('doubtterr')","2ac21bf0":"fillna('doubtterr',33)\nremove_zero('doubtterr',33)\ndata['doubtterr'].isna().sum()","37dd0de1":"data['multiple'].isna().sum()","cd7e1598":"unique('multiple')","ac8f3c3b":"fillna('multiple',33)\nremove_zero('multiple',33)\ndata['multiple'].isna().sum()","fba64978":"data['guncertain1'].isna().sum()","6c18d417":"unique('guncertain1')","baeed122":"fillna('guncertain1',33)\nremove_zero('guncertain1',33)\ndata['guncertain1'].isna().sum()","d8369b45":"pie('guncertain1')","ab12a3e3":"unique('nkill')","1fb46e50":"fillna('nkill',999999)\nremove_zero('nkill',999999)\ndata['nkill'].isna().sum()","054f9d92":"victims = max_counts('nkill',10, True)\nvictims","100153d2":"spie(victims)","67ebdf29":"data['nwound'].isna().sum()","5cf1ba20":"unique('nwound')","b7b99654":"fillna('nwound',999999)\nremove_zero('nwound',999999)\ndata['nwound'].isna().sum()","2ca8d1ca":"wounded = max_counts('nwound',10, True)\nwounded","9c3719c9":"spie(wounded)","6135b699":"data['ishostkid'].isna().sum()","e3429395":"unique('ishostkid')","49ee1af6":"fillna('ishostkid',33)\nremove_zero('ishostkid',33)\ndata['ishostkid'].isna().sum()","6baba6ac":"data.shape","6f5ec8dd":"count_nulls()","87cdb124":"fillna('provstate','other')\nfillna('city','other')\nfillna('targsubtype1_txt','other')\nfillna('corp1','other')\nfillna('target1','other')\nfillna('natlty1_txt','other')\nfillna('weapsubtype1_txt','other')","75ce40ce":"count_nulls()","4e1b39a8":"encoder('provstate','provstate_code',True)\nencoder('city','city_code',True)\nencoder('targsubtype1_txt','targsubtype_code',True)\nencoder('corp1','corp_code',True)\nencoder('target1','target_code',True)\nencoder('natlty1_txt','natlty_code',True)\nencoder('weapsubtype1_txt','weapsubtype_code',True)\n\nencoder('country_txt','country_code',True)    \nencoder('region_txt','region_code',True)    \nencoder('attacktype1_txt','attacktype_code',True)    \nencoder('targtype1_txt','targtype_code',True)    \nencoder('gname','gname_code',True)    \nencoder('weaptype1_txt','weaptype_code',True)    \nencoder('dbsource','dbsource_code',True)    ","3c0ec7f1":"show_details()","03d5fbfb":"data.head()","b8c08cb3":"data.info()","10121da5":"X , y = make_xy('success')","014583cf":"X.shape","d4e03923":"y.shape","0b7e2abf":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=44, shuffle =True)\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","f1b5afd1":"cplot('success')","f8775da4":"from sklearn.ensemble import GradientBoostingClassifier\n\nGBCModel = GradientBoostingClassifier(n_estimators=100,max_depth=3,random_state=33) \nGBCModel.fit(X_train, y_train)","f64d6f2f":"print('GBCModel Train Score is : ' , GBCModel.score(X_train, y_train))\nprint('GBCModel Test Score is : ' , GBCModel.score(X_test, y_test))","0aa445be":"y_pred = GBCModel.predict(X_test)\ny_pred_prob = GBCModel.predict_proba(X_test)\nprint('Predicted Value for GBCModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for GBCModel is : ' , y_pred_prob[:10])","a5063a2a":"____\n\nnow data is ready to split & build the model \n\n# Data Splitting\n\n\n","10c12dce":"and we can see the count plot of the output","ab866b3e":"snce we have hundreds of nulls in these 7 features , let's fill them with 'other' to make them ready for label encoder","98bc59bd":"almost 100 feature are dropped . \n\nnow we'll drop ventid feature since it is not helpful , & also several numerical features which got exact values as text like country & region \n\n","0140c92c":"now check number of rows ","7eb72732":"ok , 135 features ,  but since several features got so much nulls , so it will mislead us in the training . \n\nso let's drop all features with null value covers more than 30% of all rows ","0bbaa798":"also we can have a look to their ratios","b47330ee":"how about the shape","737b81d7":"is there specific month which got more terroristic operation rate ? ","7c5c1cac":"now how data looks like","336cbbb7":"great , let's repeat it with longitude","e6ea12b9":"again we'll fill nulls with 33 to drop it","abfa2830":"_____\n\nnow let's move to gun certain","8ad8c23e":"we'll repeat the 33 value again ","d9cade40":"unique values ? ","ecbfe5a9":"looks that the rate increased so much in the last fea years , how about the month","6ac8eb4e":"then split it ","117aba8a":"______\n\nlet's move to specificity ","7dad4c69":"and doubtterr","47e560f3":"almost equally distributed \n\nnow how about the days ? ","e19ac9ac":"nothing wrong with it , how about latitude , how many nulls at it  ?","b9602bf6":"now it should got no nulls","318021a7":"again it contain several numbers & we cannot use 0 since it's exist indeed , let's pick 999999","42de4ab5":"what are the values ? ","47b3eb9a":"great , now how multiple looks  ? ","ebab9cb1":"ok , now to the last numerical feature ","608c901b":"so we can have a look to umber of victims distribution ","d70ab7f5":"we have 14 numerical features to handle here which are : iyear , imonth , iday , extended , latitude , longitude , specificity , vicinity , doubtterr , multiple , guncertain1, nkill , nwound & ishostkid\n\nlet's be sure that it got no nulls & all values are suitable\n\nlet's start with iyear","342caebd":"now hw many rows left","bfcb4dcc":"let's have a look to number of wounded people statistics","78746c59":"also we need to have a detailed look so all data ","8294d9a9":"great ,  94% accuracy ,  lets predict the X_test","af6e5d38":"great , how many rows dropped ? ","79fd827e":"what are unique values for it ? ","4b7a76a6":"then we'll read the data","66d0d7ff":"so since it got an original values for 0 , so we'll fill nulls with another number 33 to drop it","5bc4040a":"now how the scores looks like","ae075f46":"now how it looks ","55a577e2":"almost 10% of operations failed & 90% succeeded\n\n______\n\n# Building the Model\n\nlet's use the Gradient Boosting Classifier , with 100 classifier & max_depth 3","af723f70":"now it should show 0 nulls in all features  ","ed3d398c":"and it should show no nulls","676e0bb4":"____\n\n# Data Cleaning\n\nnow let's know the data shape","67129ab0":"about 20 rows dropped , let's be sure that 0 value is vanished","8cf50dbd":"how it looks","92c8d5cd":"_____\n\nnow what is the shape  ? ","64eb2dab":"____\n\nnow it's time to define needed functions\n","787458c8":"almost half of operations with no victims & fifth with only 1 victim , now how about the wounds","13be1a6c":"so much nulls , so let's fill nulls with 0 then drop all rows with zero value ","4b8f4408":"great , now we read to move to categorical features \n\n______\n\n# Categorical Features\n\nhow the data looks now ? ","e0e8280c":"so let's use 33 value","e38acb86":"_____\n\nso we'll need to handle Numerical features & categorical features , step by step\n\n_____\n\n# Numerical Features\n","1b0c95af":"also we can draw a pie chart for it","b022e719":"great now we can label encode all categorical features , & drop original features ","3f084c0c":"how many nulls ? ","e0c606bf":"again we have to drop all values of 0 ","c6b1ddd6":"what are values at it ? ","a10f1787":"_____\n\nnow let's have a look to unique values for each feature ","3e5fae8d":"again we'll use 999999to drop null rows","9022a321":"now how it looks ","9a654dcd":"cool , how about vicinity","d11bad74":"how about unique values ? ","33164f04":"since value of 0 is not accepted in month , we have to drop all rows contain 0 in month value , how many are rows right now ? \n","7398722b":"& how many nulls are there  ? ","1c7c379d":"# IMPORTING NEEDED LIBRARIES","4c33ad1a":"almost 1 thousand rows dropped\n\n______\n\nok , let's moce to extended","4c3d9c80":"ok looks fine , let's draw a graphical representaion for year distribution ","5090c858":"____\n\nnow the number of victims","389e8711":"& how many rows left","0f8b4bb7":"now let's drop 0 value at month"}}