{"cell_type":{"12bfe555":"code","f6c4e1e1":"code","74932774":"code","d0ee3eb8":"code","3027377f":"code","e23c20b3":"code","c070504d":"code","abe52b72":"code","c218b61e":"markdown","31650779":"markdown","cba97897":"markdown","44576383":"markdown"},"source":{"12bfe555":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6c4e1e1":"x_data=pd.read_csv('..\/input\/melbourne-housing-snapshot\/melb_data.csv')\nx_data.columns","74932774":"# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n# We'll learn to handle missing values in a later tutorial.  \n# Your Iowa data doesn't have missing values in the columns you use. \n# So we will take the simplest option for now, and drop houses from our data. \n# Don't worry about this much for now, though the code is:\n\n# dropna drops missing values (think of na as \"not available\")\n\nx_data=x_data.dropna(axis=0)\nx_data.tail()","d0ee3eb8":"#Dot Notation\ny=x_data.Price","3027377f":"#features\nfeatures=['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\nx1_data=x_data[features]\nx1_data.describe().T","e23c20b3":"x1_data.head()","c070504d":"from sklearn.tree import DecisionTreeRegressor\n\n# Define model. Specify a number for random_state to ensure same results each run\nmelbourne_model = DecisionTreeRegressor(random_state=1)\n\n# Fit model\nmelbourne_model.fit(x1_data, y)","abe52b72":"print(\"Making predictions for the following 5 houses:\")\nprint(x1_data.head())\nprint(\"The predictions are\")\nprint(melbourne_model.predict(x1_data.head()))","c218b61e":"There are many ways to select a subset of your data but we will focus on two approaches for now.\n\nDot notation, which we use to select the \"prediction target\"\nSelecting with a column list, which we use to select the \"features\"\n","31650779":"Your dataset had too many variables to wrap your head around, or even to print out nicely. How can you pare down this overwhelming amount of data to something you can understand?\n\nWe'll start by picking a few variables using our intuition. Later courses will show you statistical techniques to automatically prioritize variables.\n\nTo choose variables\/columns, we'll need to see a list of all columns in the dataset. That is done with the columns property of the DataFrame (the bottom line of code below)","cba97897":"Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. This is considered a good practice. You use any number, and model quality won't depend meaningfully on exactly what value you choose.\n\nWe now have a fitted model that we can use to make predictions.\n\nIn practice, you'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But we'll make predictions for the first few rows of the training data to see how the predict function works.","44576383":"You will use the **scikit-learn** library to create your models. When coding, this library is written as sklearn, as you will see in the sample code. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n\nThe steps to building and using a model are:\n\n**Define**: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n**Fit**: Capture patterns from provided data. This is the heart of modeling.\n**Predict**: Just what it sounds like\n**Evaluate**: Determine how accurate the model's predictions are."}}