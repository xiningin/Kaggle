{"cell_type":{"a663a8b9":"code","9b9bff62":"code","2756aba9":"code","0ac6326a":"code","21e080f1":"code","90766af4":"code","c8823646":"code","280f6a44":"code","06de9fcb":"code","9569751c":"code","c5926049":"code","1da1f5d8":"code","b6b7630e":"code","856dee57":"code","c69a62f9":"code","88c7c168":"code","7ce367b2":"code","1511634a":"code","1d2a5ecf":"code","1133d919":"code","d9ad55e4":"code","77081840":"code","365610df":"code","68bb6a58":"markdown","c04b5186":"markdown","16e06f9a":"markdown","325d2a2b":"markdown","486699eb":"markdown","b9677808":"markdown","c883a979":"markdown","23b03aee":"markdown","650263a3":"markdown","8343fd52":"markdown","5004d5f3":"markdown","41ad7853":"markdown","e032b51a":"markdown","ac99cec9":"markdown"},"source":{"a663a8b9":"! pip install -q pip install git+https:\/\/github.com\/ildoonet\/pytorch-gradual-warmup-lr.git","9b9bff62":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport gc\nimport torch\nprint(torch.__version__)\nfrom torch.optim.optimizer import Optimizer","2756aba9":"train = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntest = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/train\/{}\/{}.npy\".format(image_id[0], image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/test\/{}\/{}.npy\".format(image_id[0], image_id)\n\ntrain['file_path'] = train['id'].apply(get_train_file_path)\ntest['file_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","0ac6326a":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","21e080f1":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    print_freq=100\n    num_workers=4\n    model_name='nfnet_l0'  #'efficientnet_b0', 'vit_base_patch16_224', 'tf_efficientnet_b4_ns'\n    input_size=512   #512, 768, 1028, 'original'\n    output_size=368\n    scheduler='CosineAnnealingLR' #'ReduceLROnPlateau', 'CosineAnnealingLR'\n    epochs=10\n    factor=0.2 # ReduceLROnPlateau\n    patience=4 # ReduceLROnPlateau\n    eps=1e-6 # ReduceLROnPlateau\n    T_max=15 # CosineAnnealingLR\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=24\n    optimizer='adamw'   #adamw', 'adam' \n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=42\n    target_size=1\n    target_col='target'\n    n_fold=5\n    trn_folds=[0]\n    train=True\n    mode='spatial_3'   #'channel_3', 'channel_6', 'spatial_3', spatial_6'\n    aug_mode='mixup'   #'mixup', 'fmix'\n    warmup_epochs=2\n    multiplier=10\n    epoch_no_aug=0\n    \nif CFG.debug:\n    CFG.epochs=3\n    train=train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)   ","90766af4":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/image-fmix\/FMix-master')\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nfrom fmix import sample_mask\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, AdamW\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","c8823646":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","280f6a44":"Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col])):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby(['fold', 'target']).size())","06de9fcb":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, mode=CFG.mode, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        label = self.labels[idx]\n        image = np.load(file_path)\n        \n        if self.mode in ['spatial_3', 'channel_3']:\n            image = image[::2]\n            image = image.astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n        if self.mode in ['spatial_3', 'spatial_6']: \n            image = np.vstack(image).transpose((1, 0))\n        elif self.mode in ['channel_3', 'channel_6']:\n            image = np.transpose(image, (1,2,0))\n            \n        if self.transform:\n            image = self.transform(image=image)['image']\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n            \n        label = torch.tensor(label).float()\n        return image, label\n    \nclass TestDataset(Dataset):\n    def __init__(self, df, mode=CFG.mode, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        image = np.load(file_path)\n        if self.mode in ['spatial_3', 'channel_3']:\n            image = image[::2].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n        if self.mode in ['spatial_3', 'spatial_6']:\n            image = np.vstack(image).transpose((1, 0))\n        elif self.mode in ['channel_3', 'channel_6']:\n            image = np.transpose(image, (1,2,0))\n        if self.transform:\n            image = self.transform(image=image)['image']\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n        return image\n    \ndef worker_init_fn(worker_id):                                                          \n    np.random.seed(np.random.get_state()[1][0] + worker_id)","9569751c":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'train':\n        if type(CFG.input_size) == int:\n            return A.Compose([\n                   A.Resize(CFG.input_size, CFG.input_size),\n#                    A.HorizontalFlip(p=.5),\n#                    A.VerticalFlip(p=.5),\n                   A.ShiftScaleRotate(rotate_limit=0, scale_limit=0.15, shift_limit=0, p=0.5),\n#                    A.MotionBlur(p=.2),\n#                    A.IAASharpen(p=.25),\n                   ToTensorV2(),\n            ])\n        else:\n            return A.Compose([\n#                    A.HorizontalFlip(p=.5),\n#                    A.VerticalFlip(p=.5),\n                   A.ShiftScaleRotate(rotate_limit=0, scale_limit=0.15, shift_limit=0, p=0.5),\n#                    A.MotionBlur(p=.2),\n#                    A.IAASharpen(p=.25),\n                   ToTensorV2(),\n            ])\n            \n    elif data == 'valid':\n        if type(CFG.input_size) == int:\n            return A.Compose([\n#                    A.Resize(CFG.input_size, CFG.input_size),\n                   A.Resize(512, 512),\n                   ToTensorV2(),\n            ])\n        else:\n            return A.Compose([\n                   ToTensorV2(),\n            ])","c5926049":"# https:\/\/github.com\/facebookresearch\/mixup-cifar10\/blob\/master\/train.py\ndef mixup_data(x, y, alpha=1, use_cuda=True):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n    mixed_x = (lam**.5) * x + ((1 - lam)**.5) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef fmix_data(data, targets, alpha=1.0, \n              decay_power=3.0,\n              max_soft=0.0,\n              shape=(CFG.input_size, CFG.input_size),):\n    lam, mask = sample_mask(alpha, decay_power, shape, max_soft)\n    indices = torch.randperm(data.size(0)).cuda()\n    shuffled_data = data[indices]\n    \n    targets_a = targets\n    targets_b = targets[indices]\n    x1 = torch.from_numpy(mask).float()*data\n    x2 = torch.from_numpy(1-mask).float()*shuffled_data\n    return (x1+x2), targets_a, targets_b, lam\n\ndef aug_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","1da1f5d8":"#credit : https:\/\/github.com\/tyunist\/memory_efficient_mish_swish\/blob\/master\/mish.py\n\n''' I just wanted to understand and implement custom backward activation in PyTorch so I choose this.\n    You can also simply use this function below too.\n\nclass Mish(nn.Module):\n    def __init__(self):\n        super(Mish, self).__init__()\n\n    def forward(self, input):\n        return input * (torch.tanh(F.softplus(input)))\n'''\n\nclass Mish_func(torch.autograd.Function):\n    \n    @staticmethod\n    def forward(ctx, i):\n        result = i * torch.tanh(F.softplus(i))\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_tensors[0]\n  \n        v = 1. + i.exp()\n        h = v.log() \n        grad_gh = 1.\/h.cosh().pow_(2) \n\n        # Note that grad_hv * grad_vx = sigmoid(x)\n        #grad_hv = 1.\/v  \n        #grad_vx = i.exp()\n        \n        grad_hx = i.sigmoid()\n\n        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n        \n        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n        \n        return grad_output * grad_f ","b6b7630e":"class Mish(nn.Module):\n    def __init__(self, **kwargs):\n        super().__init__()\n        print(\"Mish initialized\")\n        pass\n    def forward(self, input_tensor):\n        return Mish_func.apply(input_tensor)","856dee57":"def replace_activations(model, existing_layer, new_layer):\n    for name, module in reversed(model._modules.items()):\n        if len(list(module.children())) > 0:\n            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n\n        if type(module) == existing_layer:\n            layer_old = module\n            layer_new = new_layer\n            model._modules[name] = layer_new\n    return model","c69a62f9":"#credit : https:\/\/github.com\/Yonghongwei\/Gradient-Centralization\n\ndef centralized_gradient(x, use_gc=True, gc_conv_only=False):\n    if use_gc:\n        if gc_conv_only:\n            if len(list(x.size())) > 3:\n                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n        else:\n            if len(list(x.size())) > 1:\n                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n    return x\n\n\nclass Ranger(Optimizer):\n\n    def __init__(self, params, lr=1e-3,                       # lr\n                 alpha=0.5, k=5, N_sma_threshhold=5,           # Ranger options\n                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n                 use_gc=True, gc_conv_only=False, gc_loc=True\n                 ):\n\n        # parameter checks\n        if not 0.0 <= alpha <= 1.0:\n            raise ValueError(f'Invalid slow update rate: {alpha}')\n        if not 1 <= k:\n            raise ValueError(f'Invalid lookahead steps: {k}')\n        if not lr > 0:\n            raise ValueError(f'Invalid Learning Rate: {lr}')\n        if not eps > 0:\n            raise ValueError(f'Invalid eps: {eps}')\n\n        # parameter comments:\n        # beta1 (momentum) of .95 seems to work better than .90...\n        # N_sma_threshold of 5 seems better in testing than 4.\n        # In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.\n\n        # prep defaults and init torch.optim base\n        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas,\n                        N_sma_threshhold=N_sma_threshhold, eps=eps, weight_decay=weight_decay)\n        super().__init__(params, defaults)\n\n        # adjustable threshold\n        self.N_sma_threshhold = N_sma_threshhold\n\n        # look ahead params\n\n        self.alpha = alpha\n        self.k = k\n\n        # radam buffer for state\n        self.radam_buffer = [[None, None, None] for ind in range(10)]\n\n        # gc on or off\n        self.gc_loc = gc_loc\n        self.use_gc = use_gc\n        self.gc_conv_only = gc_conv_only\n        # level of gradient centralization\n        #self.gc_gradient_threshold = 3 if gc_conv_only else 1\n\n        print(\n            f\"Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}\")\n        if (self.use_gc and self.gc_conv_only == False):\n            print(f\"GC applied to both conv and fc layers\")\n        elif (self.use_gc and self.gc_conv_only == True):\n            print(f\"GC applied to conv layers only\")\n\n    def __setstate__(self, state):\n        print(\"set state called\")\n        super(Ranger, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        # note - below is commented out b\/c I have other work that passes back the loss as a float, and thus not a callable closure.\n        # Uncomment if you need to use the actual closure...\n\n        # if closure is not None:\n        #loss = closure()\n\n        # Evaluate averages and grad, update param tensors\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n\n                if grad.is_sparse:\n                    raise RuntimeError(\n                        'Ranger optimizer does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]  # get state dict for this param\n\n                if len(state) == 0:  # if first time to run...init dictionary with our desired entries\n                    # if self.first_run_check==0:\n                    # self.first_run_check=1\n                    #print(\"Initializing slow buffer...should not see this at load from saved model!\")\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n\n                    # look ahead weight storage now in state dict\n                    state['slow_buffer'] = torch.empty_like(p.data)\n                    state['slow_buffer'].copy_(p.data)\n\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(\n                        p_data_fp32)\n\n                # begin computations\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                # GC operation for Conv layers and FC layers\n                # if grad.dim() > self.gc_gradient_threshold:\n                #    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n                if self.gc_loc:\n                    grad = centralized_gradient(grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n\n                state['step'] += 1\n\n                # compute variance mov avg\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n                # compute mean moving avg\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n\n                buffered = self.radam_buffer[int(state['step'] % 10)]\n\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 \/ (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * \\\n                        state['step'] * beta2_t \/ (1 - beta2_t)\n                    buffered[1] = N_sma\n                    if N_sma > self.N_sma_threshhold:\n                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) \/ (N_sma_max - 4) * (\n                            N_sma - 2) \/ N_sma * N_sma_max \/ (N_sma_max - 2)) \/ (1 - beta1 ** state['step'])\n                    else:\n                        step_size = 1.0 \/ (1 - beta1 ** state['step'])\n                    buffered[2] = step_size\n\n                # if group['weight_decay'] != 0:\n                #    p_data_fp32.add_(-group['weight_decay']\n                #                     * group['lr'], p_data_fp32)\n\n                # apply lr\n                if N_sma > self.N_sma_threshhold:\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    G_grad = exp_avg \/ denom\n                else:\n                    G_grad = exp_avg\n\n                if group['weight_decay'] != 0:\n                    G_grad.add_(p_data_fp32, alpha=group['weight_decay'])\n                # GC operation\n                if self.gc_loc == False:\n                    G_grad = centralized_gradient(G_grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n\n                p_data_fp32.add_(G_grad, alpha=-step_size * group['lr'])\n                p.data.copy_(p_data_fp32)\n\n                # integrated look ahead...\n                # we do it at the param level instead of group level\n                if state['step'] % group['k'] == 0:\n                    # get access to slow param tensor\n                    slow_p = state['slow_buffer']\n                    # (fast weights - slow weights) * alpha\n                    slow_p.add_(p.data - slow_p, alpha=self.alpha)\n                    # copy interpolated weights to RAdam param tensor\n                    p.data.copy_(slow_p)\n\n        return loss","88c7c168":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.n = 16\n        self.slope = .1\n        self.r = 1\n        \n        if self.cfg.mode in ['spatial_3', 'spatial_6']: \n            self.cnn = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=1)\n        elif self.cfg.mode == 'channel_3':\n            self.cnn = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=3)\n        elif self.cfg.mode == 'channel_6':\n            self.cnn = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=6)\n        if hasattr(self.cnn, \"fc\"):\n            nb_ft = self.cnn.fc.in_features\n            self.cnn.fc = nn.Identity()\n        elif hasattr(self.cnn, \"_fc\"):\n            nb_ft = self.cnn._fc.in_features\n            self.cnn._fc = nn.Identity()\n        elif hasattr(self.cnn, \"classifier\"):\n            nb_ft = self.cnn.classifier.in_features\n            self.cnn.classifier = nn.Identity()\n        elif hasattr(self.cnn, \"last_linear\"):\n            nb_ft = self.cnn.last_linear.in_features\n            self.cnn.last_linear = nn.Identity()\n        elif hasattr(self.cnn, \"head\"):\n            nb_ft = self.cnn.head.fc.in_features\n            self.cnn.head.fc = nn.Identity()\n        \n        self.block1 = nn.Sequential(\n                nn.Conv2d(1, self.n, kernel_size=(7, 7), stride=(1,1), padding=(1, 1), bias=False),\n                nn.LeakyReLU(negative_slope=self.slope),\n                nn.Conv2d(self.n, self.n, kernel_size=(1, 1), stride=(1,1), padding=(1, 1), bias=False),\n                nn.LeakyReLU(negative_slope=self.slope),\n                nn.BatchNorm2d(self.n))\n        self.block2 = nn.Sequential(\n                nn.Conv2d(self.n, self.n, kernel_size=(3, 3), stride=(1,1), padding=(1, 1), bias=False),\n                nn.BatchNorm2d(self.n),\n                nn.LeakyReLU(negative_slope=self.slope),\n                nn.Conv2d(self.n, self.n, kernel_size=(3, 3), stride=(1,1), padding=(1, 1), bias=False),\n                nn.BatchNorm2d(self.n))\n        self.block3 = nn.Sequential(\n                nn.Conv2d(self.n, self.n, kernel_size=(3, 3), stride=(1,1), padding=(1, 1), bias=False),\n                nn.BatchNorm2d(self.n))\n        self.block4 = nn.Sequential(\n                nn.Conv2d(self.n, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False))\n        self.fc = nn.Linear(nb_ft, self.cfg.target_size)\n\n    def forward(self, x):\n        res1 = F.interpolate(x, size=(self.cfg.output_size, self.cfg.output_size), mode='bilinear')\n        x = self.block1(x)\n        res2 = F.interpolate(x, size=(self.cfg.output_size, self.cfg.output_size), mode='bilinear')\n\n        x = self.block2(res2)\n        x += res2\n        if self.r > 1:\n            for _ in range(self.r):\n                res2 = x\n                x = self.block2(x)\n                x += res2\n \n        x = self.block3(x)\n        x += res2\n        \n        x = self.block4(x)\n        x += res1\n        \n        x = self.cnn(x)\n        x = self.fc(x)\n        return x","7ce367b2":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) \/ self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch \/ self.total_epoch + 1.) for base_lr in self.base_lrs]","1511634a":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, mode):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        if mode == 'mixup':\n            images, targets_a, targets_b, lam = mixup_data(images, labels.view(-1, 1), use_cuda=True)\n            images = images.to(device)\n            targets_a = targets_a.to(device)\n            targets_b = targets_b.to(device)\n            y_preds = model(images)\n            loss = aug_criterion(criterion, y_preds, targets_a, targets_b, lam)\n            \n        elif mode == 'fmix':\n            images, targets_a, targets_b, lam = fmix_data(images, labels.view(-1, 1))\n            images = images.to(device)\n            targets_a = targets_a.to(device)\n            targets_b = targets_b.to(device)\n            y_preds = model(images)\n            loss = aug_criterion(criterion, y_preds, targets_a, targets_b, lam)\n\n        else:\n            images = images.to(device)\n            labels = labels.to(device)\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n            \n        batch_size = labels.size(0)\n        \n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}\/{2}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  #'LR: {lr:.6f}  '\n                  .format(\n                   epoch+1, step, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(train_loader)),\n                   grad_norm=grad_norm,\n                   #lr=scheduler.get_lr()[0],\n                   ))\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        \n        loss = criterion(y_preds.view(-1), labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}\/{1}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(valid_loader)),\n                   ))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions\n\ndef flip_inference(models, test_loader, device):\n    preds = []\n    for i, fold in enumerate(CFG.trn_folds):\n        model = models[i]\n        probs = []\n        for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            images = images.to(device)\n            with torch.no_grad():\n                y_preds1 = model(images)\n                y_preds2 = model(images.flip(-1))\n                y_preds3 = model(images.flip(-2))\n                y_preds4 = model(images.flip(-1).flip(-2))\n            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy() + y_preds3.sigmoid().to('cpu').numpy() + y_preds4.sigmoid().to('cpu').numpy()) \/ 4\n            probs.append(y_preds[:, 0])\n        preds.append(np.concatenate(probs))\n    return preds\n\ndef get_models(CFG, mode='loss'):\n    models = []\n    for fold in CFG.trn_folds:\n        model = CustomModel(cfg=CFG, pretrained=False)\n        path = OUTPUT_DIR + f'{CFG.model_name}_fold{fold}_best_{mode}.pth'\n        path = f'..\/input\/setinfnet-l0368\/{CFG.model_name}_fold{fold}_best_{mode}.pth'\n#         model.load_state_dict(torch.load(path)['model'])\n        model.eval()\n        model.to(device)\n        models.append(model)\n    return models","1d2a5ecf":"def train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True,\n                              drop_last=True, worker_init_fn=worker_init_fn)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    # ====================================================\n    # optimizer\n    # ====================================================\n    def get_optimizer(lr=CFG.lr):\n        if CFG.optimizer == 'adam':\n            optimizer = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay, amsgrad=False)\n        elif CFG.optimizer == 'adamw':\n            optimizer = AdamW(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n        return optimizer\n    \n    # ====================================================\n    # criterion\n    # ====================================================\n    def get_criterion():\n        criterion = nn.BCEWithLogitsLoss()\n        return criterion\n    \n    # ====================================================\n    # scheduler\n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        if CFG.warmup_epochs > 0:\n            scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=CFG.multiplier,\n                                                 total_epoch=CFG.warmup_epochs, \n                                                 after_scheduler=scheduler)\n        return scheduler \n    \n    # ====================================================\n    # training loop\n    # ====================================================\n    model = CustomModel(CFG, pretrained=True)\n    model.to(device)\n    \n    existing_layer = torch.nn.SiLU\n    new_layer = Mish()\n    model = replace_activations(model, existing_layer, new_layer) # in eca_nfnet_l0 SiLU() is used, but it will be replace by Mish()\n    \n#     optimizer = get_optimizer()\n    optimizer = Ranger(model.parameters(), lr = CFG.min_lr)\n    scheduler = get_scheduler(optimizer)\n    criterion = get_criterion()\n\n    best_score = 0.\n    best_loss = np.inf\n\n    for epoch in range(CFG.epochs + CFG.epoch_no_aug):\n        start_time = time.time()\n        \n        # train\n        if epoch < CFG.epochs:\n            avg_loss = train_fn(train_loader, model, criterion, optimizer,\n                                 epoch, scheduler,\n                                 device,\n                                 mode=CFG.aug_mode)\n        else:\n            optimizer = get_optimizer(lr=1e-6)\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n            avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, mode='none')\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n    \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, GradualWarmupSchedulerV2):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n    \n    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth', \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","1133d919":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train \n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_folds:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","d9ad55e4":"# if __name__ == '__main__':\n#     main()","77081840":"models = get_models(CFG, mode='loss')\nmodels_ = get_models(CFG, mode='score')\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n# test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size*2, shuffle=False, \n#                          num_workers=CFG.num_workers, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=142, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\nfold_preds = flip_inference(models, test_loader, device)\nfold_preds_ = flip_inference(models_, test_loader, device)\npreds = np.mean(fold_preds, axis=0)\npreds_ = np.mean(fold_preds_, axis=0)","365610df":"test = test[['id', 'target']]\ntest[CFG.target_col] = (preds + preds_) \/ 2\ntest.to_csv(OUTPUT_DIR+'submission.csv', index=False)\ndisplay(test)","68bb6a58":"# Train Loop","c04b5186":"# Learning Rate","16e06f9a":"# Transforms","325d2a2b":"# CFG","486699eb":"# Utils","b9677808":"# Model","c883a979":"# About \n\nWhen training CNNs, we typically resize our input images to some standard size before passing them to the model. For example, if the original images are `600 x 400` we might resize them to a resolution like `248 x 248` or `512 x 512` as a preprocessing step.\n\nBut this resizing results in information loss, and every time we resize images with `opencv`, we rely on some interpolation algorithm to decrease this resize-loss as much as possible. Instead of using `cv2.INTER_LINEAR` or `cv2.INTER_AREA`, why not train our own 'algorithm' to resize the images? The simplest example would be to take a `1024 x 1024` image and convolve it to size `512 x 512` before giving it to the CNN backbone. This way, the model learns how to best resize the images alongside the main training task. \n\nThis was done succesfully [here](https:\/\/www.kaggle.com\/c\/ranzcr-clip-catheter-line-classification\/discussion\/226557) and [here](https:\/\/www.kaggle.com\/c\/understanding_cloud_organization\/discussion\/118255) - two competitions in which the native image resolutions where > `1400 x 1400`. Seeing as we have fairly large 'images' for this competition, let's try it here. Instead of using either of the two above approaches, I want to try to implement the approach from [this paper](https:\/\/arxiv.org\/abs\/2103.09950) in which the proposed 'learned image resizer' looks like:\n\n![Capture.PNG](attachment:ccf6a3fd-9ee4-4cff-b6a6-4fd3d1588735.PNG)\n\nIn this commit, we will feed the learned image resizer original resolution images for it to resize to `256 x 256`. Note that I am not 100% sure I coded all this correctly, so if you see anything suspicious, please let me know. While I opted for the approach taken in the paper, the previously linked approaches seem fruitful as well and require less training time. \n\nCode template is taken from the one and only [yasufuminakama](https:\/\/www.kaggle.com\/yasufuminakama).","23b03aee":"# Library","650263a3":"# Inference","8343fd52":"# Helper functions","5004d5f3":"# Directory settings","41ad7853":"# Data Loading","e032b51a":"# Dataset","ac99cec9":"# CV split"}}