{"cell_type":{"1e0a3988":"code","f031146c":"code","d35413fa":"code","6a9ba89c":"code","0dfbfbaa":"code","e71a25e4":"code","8ad88019":"code","6057c0a6":"code","0e23fb5c":"code","53000787":"code","770134b8":"code","445e8a34":"code","a7ff4336":"code","98a1cd77":"code","cc54127e":"code","36485168":"code","774b30c0":"code","a81381ad":"code","8d4d3fd3":"code","55549df5":"code","753eb09a":"code","372d4a39":"code","7dde7a04":"code","e266b12b":"code","598dcab9":"code","cb8fffee":"code","c3220121":"code","29b82d9f":"code","784eeb6d":"code","e8458902":"code","7e49923b":"code","3d6982b8":"code","d886721e":"code","0663db8a":"code","c43f2c3b":"code","5fbf2b3f":"code","64a8ddd1":"code","24207027":"code","641127a5":"code","16189345":"code","02d6efd5":"markdown"},"source":{"1e0a3988":"# 1.1 Call libraries\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport re\n%reset -f\n# 1.2 For data manipulations\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# 1.3 For plotting\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport matplotlib.pyplot\nimport plotly.express as px\n# 1.4 For data processing\nfrom sklearn.preprocessing import StandardScaler\n# 1.5 OS related\nimport os\n# 1.3 Modeling librray\n# 1.3.1 Scale data\nfrom sklearn.preprocessing import StandardScaler\n# 1.3.2 Split dataset\nfrom sklearn.model_selection import train_test_split\n# 1.3.3 Class to develop kmeans model\nfrom sklearn.cluster import KMeans\n# 1.4 Plotting library\nimport seaborn as sns\n# 1.5 How good is clustering?\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster import SilhouetteVisualizer\n# 1.6 Set numpy options to display wide array\nnp.set_printoptions(precision = 3,          # Display upto 3 decimal places\n                    threshold=np.inf        # Display full array\n                    )\n","f031146c":"#Load the data frame\nstock_df1=pd.read_csv(\"..\/input\/nyse\/fundamentals.csv\")","d35413fa":"stock_df1.head()","6a9ba89c":"stock_df1.drop('Unnamed: 0',axis=1,inplace=True)","0dfbfbaa":"#Replace space in column names with underscore\nstock_df1.columns=stock_df1.columns.str.replace(' ','_')","e71a25e4":"#Replace special characters\nstock_df1.columns=stock_df1.columns.str.replace(',','')\nstock_df1.columns=stock_df1.columns.str.replace('.','')\nstock_df1.columns=stock_df1.columns.str.replace('\/','')\nstock_df1.columns=stock_df1.columns.str.replace('-','_')","8ad88019":"#Remove the NaN with zero\nstock_df1.dropna(inplace=True)","6057c0a6":"stock_df1.head()","0e23fb5c":"stock_df1.For_Year = stock_df1.For_Year.astype('int64')\nstock_df1.drop(stock_df1[stock_df1.Ticker_Symbol == 'nan'].index , inplace=True)","53000787":"#correlation between Total_Current_Assets and Total_Current_Liabilities\nax=sns.scatterplot(x='Total_Current_Assets',y='Total_Current_Liabilities',data=stock_df1)","770134b8":"#Relationship between accounts payable and accounts receivable\nsns.jointplot(stock_df1.Accounts_Payable,stock_df1.Accounts_Receivable, kind = 'reg')","445e8a34":"plt.plot(stock_df1['Current_Ratio'])","a7ff4336":"stock_df11 = stock_df1[[\"Ticker_Symbol\", \"For_Year\", \"Earnings_Per_Share\"]]\nstock_df11.For_Year = stock_df11.For_Year.astype('int64')\nstock_df11.drop(stock_df11[stock_df11.For_Year == 1215].index , inplace=True)\nsymbols = stock_df11[\"Ticker_Symbol\"].unique().tolist()\nstock_df11.For_Year.unique()\nfor u in symbols[:10]:\n    dates = stock_df11[(stock_df11[\"Ticker_Symbol\"] == u)][\"For_Year\"]\n    values = stock_df11[(stock_df11[\"Ticker_Symbol\"] == u)][\"Earnings_Per_Share\"]\n    plt.plot(dates.tolist(), values.tolist())\nplt.legend(symbols, loc='upper left')","98a1cd77":"#Group data by mean of ticker symbol\nstock_df2 = stock_df1.groupby('Ticker_Symbol').mean().reset_index()","cc54127e":"stock_df2.head()","36485168":"#Using Heat map to analyse ticker symbol wise earnings per share\n#drop rows where year 1510\n\nstock_df2.Earnings_Per_Share = stock_df2.Earnings_Per_Share.astype('float')\nstock_df2.drop(stock_df2[stock_df2.For_Year == 1510].index , inplace=True)\nticker1=stock_df2[['Ticker_Symbol','For_Year','Earnings_Per_Share']]\n#ax=sns.heatmap(ticker1)\n#symbol=((np.asarray(ticker1['Ticker_Symbol'])))\n#EPS=((np.asarray(ticker1['Earnings_Per_Share'])))\nticker1.For_Year=ticker1.For_Year.astype('int')\n","774b30c0":"\n#result=ticker1.pivot(index='Ticker_Symbol',columns='For_Year',values='Earnings_Per_Share')\n#result=result.fillna(0)\n#sns.heatmap(result,fmt=\"\",cmap='CMRmap_r')","a81381ad":"ticker1.drop(ticker1[ticker1.For_Year == 1813].index , inplace=True)\nstock_df2.For_Year=stock_df2.For_Year.astype('int')\nstock_df2.drop(stock_df2[stock_df2.For_Year == 1813].index , inplace=True)\npx.density_heatmap(data_frame =ticker1,\n                   x = 'For_Year',\n                   y = 'Ticker_Symbol',\n                   z = 'Earnings_Per_Share', # histfunc() of this is intensity of colour\n                   histfunc = 'sum' # Diverging color scale\n                   )","8d4d3fd3":"sns.distplot(stock_df2.After_Tax_ROE) ","55549df5":"stock_df2.For_Year=stock_df2.For_Year.astype('int')\nstock_df2.drop(stock_df2[stock_df2.For_Year == 1813].index , inplace=True)\npx.density_heatmap(data_frame =stock_df2,\n                   x = 'For_Year',\n                   y = 'Ticker_Symbol',\n                   z = 'Estimated_Shares_Outstanding',  # histfunc() of this is intensity of colour\n                   histfunc = 'sum' # Diverging color scale\n                   )\n#stock_df2.For_Year.unique()","753eb09a":"#sns.barplot('Ticker_Symbol', 'After_Tax_ROE',   estimator = np.mean, data = stock_df2)\n\nsns.jointplot(stock_df2.After_Tax_ROE, stock_df2.Pre_Tax_ROE, kind = 'reg') ","372d4a39":"px.histogram(data_frame =stock_df2,\n                   x = 'Ticker_Symbol',\n                   y = 'Total_Revenue',\n                   histfunc = \"sum\",\n                    template=\"plotly_dark\"\n                   )","7dde7a04":"# Relationship between Capital expenditures and capital surplus\n\npx.density_contour(\n                   data_frame =stock_df2,\n                   x = 'Total_Liabilities',\n                   y = 'Total_Liabilities_&_Equity'\n                   )","e266b12b":"#Clustering\n\nstock_df2.info()","598dcab9":"clust_df=stock_df2[['Accounts_Payable','Accounts_Receivable','Capital_Expenditures','Cash_Ratio','Current_Ratio','Investments','Liabilities',\n                    'Total_Assets','Total_Equity','Total_Liabilities','Total_Liabilities_&_Equity','Total_Revenue','Treasury_Stock','Earnings_Per_Share','Estimated_Shares_Outstanding']]","cb8fffee":"clust_df.head()","c3220121":"#Create a new variable\nclust_df.loc[(clust_df['Earnings_Per_Share'] > 0),'share_profit'] = 1\nclust_df.loc[(clust_df['Earnings_Per_Share'] <= 0),'share_profit'] = 0\n\nx = clust_df['share_profit'].values\n\nclust_df.drop(columns = ['share_profit'], inplace = True)\n\n","29b82d9f":"ss = StandardScaler()                 # Create an instance of class\nss.fit(clust_df)                # Train object on the data\nX = ss.transform(clust_df)      # Transform data\nX[:5, :]                              # See first 5 rows","784eeb6d":"X_train, X_test, _, y_test = train_test_split( X,               # np array without target\n                                               x,               # Target\n                                               test_size = 0.25 # test_size proportion\n                                               )\n# 4.1 Examine the results\n\nX_train.shape    \n\n","e8458902":"X_test.shape  ","7e49923b":"clf = KMeans(n_clusters = 2)\n# 5.2 Train the object over data\nclf.fit(X_train)","3d6982b8":"\n# 5.3 So what are our clusters?\nclf.cluster_centers_\nclf.cluster_centers_.shape         # (2, 7)\nclf.labels_                        # Cluster labels for every observation\nclf.labels_.size                   # 375\nclf.inertia_                       # Sum of squared distance to respective centriods, SSE\n","d886721e":"# 5.4 For importance and interpretaion of silhoutte score, see:\n# See Stackoverflow:  https:\/\/stats.stackexchange.com\/q\/10540\nsilhouette_score(X_train,clf.labels_)    # 0.20532663345078295","0663db8a":"# 6 Make prediction over our test data and check accuracy\ny_pred = clf.predict(X_test)\ny_pred\n","c43f2c3b":"# 6.1 How good is prediction\nnp.sum(y_pred == y_test)\/y_test.size","5fbf2b3f":"# 7.0 Are clusters distiguisable?\n#     We plot 1st and 2nd columns of X\n#     Each point is coloured as per the\n#     cluster to which it is assigned (y_pred)\ndx = pd.Series(X_test[:, 0])\ndy = pd.Series(X_test[:,1])\nsns.scatterplot(dx,dy, hue = y_pred)","64a8ddd1":"# 7.1 Scree plot:\nsse = []\nfor i,j in enumerate(range(10)):\n    # 7.1.1 How many clusters?\n    n_clusters = i+1\n    # 7.1.2 Create an instance of class\n    clf1 = KMeans(n_clusters = n_clusters)\n    # 7.1.3 Train the kmeans object over data\n    clf1.fit(X_train)\n    # 7.1.4 Store the value of inertia in sse\n    sse.append(clf1.inertia_ )","24207027":"# 7.2 Plot the line now\nsns.lineplot(range(1, 11), sse)","641127a5":"#Silhoutte plot\n\nvisualizer = SilhouetteVisualizer(clf, colors='yellowbrick')\nvisualizer.fit(X_train)        # Fit the data to the visualizer\nvisualizer.show()              # Finalize and render the figure\n","16189345":"#Thank You","02d6efd5":"<img src=\"https:\/\/ei.marketwatch.com\/Multimedia\/2019\/03\/28\/Photos\/ZQ\/MW-HG534_nyse_0_20190328062318_ZQ.jpg?uuid=818c9ed8-5143-11e9-96bd-9c8e992d421e\" width=500px>"}}