{"cell_type":{"64036696":"code","ab52b25c":"code","b4658f8e":"code","c696f693":"code","43bad0b4":"code","198970b4":"code","4cead7d7":"code","bd625d5f":"code","db1ad5fb":"code","dc220833":"code","147db1ee":"code","dc34fe15":"code","70715d44":"code","a303ddf8":"code","f7559359":"code","5df804c8":"code","a5bf8d73":"code","9ba28f42":"code","e21c8b5b":"code","1a6c744e":"code","598682a8":"code","06776bdc":"code","39d4be82":"code","d66fe83a":"code","aa41f2e1":"code","14679e51":"code","31cfd509":"code","3a0551a0":"code","1d3337ed":"code","5afa1deb":"code","cbe7e92e":"code","9072781c":"code","ea169a93":"code","058e518b":"markdown","a2e5645c":"markdown","cd3429e5":"markdown","5079d328":"markdown","375907f1":"markdown","e950f5ec":"markdown","26549eba":"markdown","e17abe64":"markdown","e84e1879":"markdown","5f6c7a27":"markdown"},"source":{"64036696":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ab52b25c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b4658f8e":"dataset = pd.read_csv(\"..\/input\/spam.csv\",encoding='latin-1')","c696f693":"##Checking the head\ndataset.head()","43bad0b4":"dataset.describe()","198970b4":"dataset.groupby('v1').describe()","4cead7d7":"dataset['length'] = dataset['v2'].apply(len)","bd625d5f":"dataset['length'].plot(bins=50, kind='hist') ","db1ad5fb":"dataset.length.describe()","dc220833":"dataset[dataset['length'] == 910]['v2'].iloc[0]","147db1ee":"dataset.hist(column='length', by='v1', bins=50,figsize=(12,4))","dc34fe15":"dataset.drop(labels = ['Unnamed: 2','Unnamed: 3','Unnamed: 4','length'],axis = 1,inplace = True)","70715d44":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","a303ddf8":"portstemmer = PorterStemmer()\ncorpus = []\nfor i in range (0,len(dataset)):\n    mess = re.sub('[^a-zA-Z]',repl = ' ',string = dataset['v2'][i])\n    mess.lower()\n    mess = mess.split()\n    mess = [portstemmer.stem(word) for word in mess if word not in set(stopwords.words('english'))]\n    mess = ' '.join(mess)\n    corpus.append(mess)","f7559359":"corpus[1]","5df804c8":"len(corpus)","a5bf8d73":"from sklearn.feature_extraction.text import CountVectorizer","9ba28f42":"countvectorizer = CountVectorizer()","e21c8b5b":"x = countvectorizer.fit_transform(corpus).toarray() #Independent Variable","1a6c744e":"y = dataset['v1'].values #Dependent Variable","598682a8":"x.shape","06776bdc":"from sklearn.model_selection import train_test_split ","39d4be82":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)","d66fe83a":"from sklearn.naive_bayes import MultinomialNB","aa41f2e1":"multinomialnb = MultinomialNB()","14679e51":"multinomialnb.fit(x_train,y_train)","31cfd509":"y_pred = multinomialnb.predict(x_test)","3a0551a0":"y_pred","1d3337ed":"from sklearn.metrics import classification_report,confusion_matrix","5afa1deb":"print(classification_report(y_test,y_pred))","cbe7e92e":"confusion_matrix(y_test,y_pred)","9072781c":"from sklearn.metrics import accuracy_score","ea169a93":"accuracy_score(y_test,y_pred)","058e518b":"## Accuracy Score","a2e5645c":"1.  **Here we  are creating corpus,we are using re package to remove punctuation and special characters. **\n\n2. **We are converting all characters in the corpus into lower case**\n\n3. **Then we are splitting a message into words to remove stop words and to perform stemming**\n\n4.  **And then we are removing stopwords and we are performing stemming while removing stopwords,the word which is not a stop word will be converted to its root form.For example loved will be converted to love.This process is called stemming**\n\n5. **After this we are joining the words in the list again  to form a message without any stopwords and all words will be present in its root form**\n\n6. **After all this step we are appending refined message into  corpus**","cd3429e5":"## Using MultinomialNB to classify the message","5079d328":"#### In this step we are vectorizing the words,We are creating sparse matrix here","375907f1":"# Data Visualization","e950f5ec":"## Classification Report","26549eba":"#### Creating training and test set","e17abe64":"**Dropping the last four columns,because that three columns don't have any values and length column doesn't have any values useful to build to a model**","e84e1879":"## Importing Dataset","5f6c7a27":"## Confusion Matrix"}}