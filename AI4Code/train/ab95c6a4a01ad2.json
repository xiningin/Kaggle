{"cell_type":{"98acf99f":"code","d91b08ff":"code","409fca28":"code","7787b3ef":"code","16245c17":"code","a626cb9e":"code","a6bceecd":"code","c3bdd7a2":"code","41ef00c6":"code","eb151d5a":"code","3c2379e5":"code","d9bfe0f9":"code","4a4c1462":"code","855247d1":"code","d8d98702":"code","c495f3d2":"code","6b64fba7":"code","555de442":"code","e266ae5e":"code","13d66b74":"code","e2493d0c":"code","0e098cd9":"code","c76a8ed7":"code","f7f76b73":"code","1bae2b7c":"code","db577439":"code","3b03adb3":"code","63d2401d":"code","12cbe437":"code","b3ca9e9f":"code","e6f8c6c9":"code","875acbbc":"markdown","0d844a79":"markdown","008a95d4":"markdown","649c229e":"markdown","41b363ee":"markdown","1b4751c6":"markdown","bbb654ca":"markdown","7fa47788":"markdown","210e55cc":"markdown","34108932":"markdown","37f222e3":"markdown","ea3759ec":"markdown","bd411733":"markdown","502abe63":"markdown","9f134487":"markdown","0b3d2736":"markdown","cf70f79e":"markdown","eda8b58b":"markdown","403ec4b4":"markdown","1b74702c":"markdown","c7094e79":"markdown","02695721":"markdown","6fd2a913":"markdown","641f64cb":"markdown","e6d0336f":"markdown","988ae1ab":"markdown","42db56ec":"markdown","c8dcb223":"markdown","09742b63":"markdown"},"source":{"98acf99f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d91b08ff":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nvalidation_df = test_df['PassengerId']\n\ntrain_data = train_df.copy()\ntest_data = test_df.copy()","409fca28":"train_data.info()","7787b3ef":"test_data.info()","16245c17":"train_data.isnull().sum()","a626cb9e":"test_data.isnull().sum()","a6bceecd":"train_data.describe()","c3bdd7a2":"test_data.describe()","41ef00c6":"train_data[\"Survived\"].value_counts()\ntrain_data[\"Sex\"].value_counts()","eb151d5a":"train_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Parch'], axis=1, inplace=True)\ntest_data.drop(columns= ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Parch'], axis=1, inplace= True)","3c2379e5":"train_data['Age'].fillna(train_data['Age'].median(), inplace = True)\ntrain_data['Fare'].fillna(train_data['Fare'].median(), inplace = True)\ntrain_data['Embarked'].fillna(\"?\", inplace = True)","d9bfe0f9":"test_data['Age'].fillna(train_data['Age'].median(), inplace = True)\ntest_data['Fare'].fillna(train_data['Fare'].median(), inplace = True)\ntest_data['Embarked'].fillna(\"?\", inplace = True)","4a4c1462":"print(\"Training data head:\\n\", train_data.head())\nprint(\"Testing data head:\\n\", test_data.head())\n\nprint(\"Train shape:\", train_data.shape)\nprint(\"Testing data shape:\", test_data.shape)","855247d1":"_ = sns.countplot(x = train_data['Survived'])\n_ = plt.xticks(ticks = [0, 1], labels = ['Not survived', 'Survived'])","d8d98702":"_ = sns.countplot(x = train_data['Sex'], hue = train_data['Survived'])\n_ = plt.xticks(ticks = [0, 1], labels = ['Male', 'Female'])\n_ = plt.legend(['Not survived', 'Survived'])","c495f3d2":"_ = sns.countplot(data=train_data, x='Pclass',hue='Survived')\n_ = plt.legend(['Not survived', 'Survived'])\n_ = plt.xticks(ticks = [0, 1, 2], labels = ['Class 1', 'Class 2', 'Class 3'])","6b64fba7":"_ = sns.countplot(x=train_data['Survived'], hue = pd.cut(train_data['Age'], 4))\n_ = plt.xticks(ticks = [0, 1], labels = ['Not survived', 'Survived'])\n_ = plt.legend(title = 'Age', labels = ['0-20', '20-40', '40-60', '60-80'])","555de442":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ncolumns = ['Sex', 'Embarked']\nfor col in columns:\n    train_data[col] = le.fit_transform(train_data[col])\n    test_data[col] = le.transform(test_data[col])\n\nprint(train_data.head())","e266ae5e":"X = train_data.drop(\"Survived\", axis = 1)\ny = train_data['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 99)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y _train shape:\", y_train.shape)\n\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_test shape:\", y_test.shape)","13d66b74":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score\n\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)\n\nlinreg_pred = linreg.predict(test_data)","e2493d0c":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train, y_train)\n\nknn_pred = knn.predict(test_data)\nknn_acc_pred = knn.predict(X_test)\n\nknnscore = accuracy_score(y_test, knn_acc_pred)","0e098cd9":"from sklearn import tree\n\ndct = tree.DecisionTreeClassifier(max_depth = 5)\ndct.fit(X_train, y_train)\n\ndct_pred = dct.predict(test_data)\ndct_acc_pred = dct.predict(X_test)\n\ndctscore = accuracy_score(y_test, dct_acc_pred)","c76a8ed7":"from sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\n\nsgd_pred = sgd.predict(test_data)\nsgd_acc_pred = sgd.predict(X_test)\n\nsgdscore = accuracy_score(y_test, sgd_acc_pred)","f7f76b73":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\nlogreg_pred = logreg.predict(test_data)\nlogreg_acc_pred = logreg.predict(X_test)\n\nlogregscore = accuracy_score(y_test, logreg_acc_pred)","1bae2b7c":"linreg_score = linreg.score(X_train, y_train)\nprint(\"Linear Regression Training accuracy:\", linreg.score(X_train, y_train))","db577439":"knn_score = knn.score(X_train, y_train)\nprint(\"KNN Training accuracy:\", knn.score(X_train, y_train))\nprint(\"KNN Testing accuracy:\", accuracy_score(y_test, knn_acc_pred))","3b03adb3":"dct_score = dct.score(X_train, y_train)\nprint(\"DCT Training accuracy:\", dct.score(X_train, y_train))\nprint(\"DCT Testing accuracy:\", accuracy_score(y_test, dct_acc_pred))","63d2401d":"sgd_score = sgd.score(X_train, y_train)\nprint(\"SGDClassifier Training accuracy:\", sgd.score(X_train, y_train))\nprint(\"SGDClassifier Testing accuracy:\", accuracy_score(y_test, sgd_acc_pred))","12cbe437":"logreg_score = logreg.score(X_train, y_train)\nprint(\"Logistic Regression Training accuracy:\", logreg.score(X_train, y_train))\nprint(\"Logistic Regression Testing accuracy:\", accuracy_score(y_test, logreg_acc_pred))","b3ca9e9f":"names =  ['LINREG', 'KNN', 'DCT', 'SGD', 'LOGREG']\nresults = [linreg_score, knn_score, dct_score, sgd_score, logreg_score]\n_ = plt.bar(names, results, color = 'c')","e6f8c6c9":"submission = pd.DataFrame({'PassengerId' : validation_df.values, 'Survived': dct_pred})\nsubmission.to_csv(\"submission.csv\", index = False)","875acbbc":"## 2.4 Pclass feature","0d844a79":"## 4.4 SGDClassifier","008a95d4":"## 2.3 Sex feature","649c229e":"# 4. Evaluating the models","41b363ee":"## 3.4 SGDClassifier model","1b4751c6":"# 3. Building the models","bbb654ca":"## 3.5 [Just for fun] Logistic Regression model","7fa47788":"### For the test set we have 86 Age and 327 cabin data slots that are null.","210e55cc":"### Set up label encoder to turn feature values into numerics so we can use them for analysis. Print the head so we can verify the changes.","34108932":"### Fill in the missing data entries for the training data. I will use the mean of the columns to fill in the empty spots for Age and Fare. For embarked I opt to just use a missing data symbol. In this case '?'","37f222e3":"### We do the same as above on the test data.","ea3759ec":"## 4.6 Plot comparing the models training accuracies versus each other","bd411733":"# 2. Exploratory Data Analysis\n## 2.1 Checking the data in of both train_data and test_data.\n### We can see that Age and Cabin seem to have a much lower count than the others in both sets of data by quite a bit. Given this information, we should check the null counts to see how much of the data is missing.","502abe63":"## 4.3 Decision Tree\n### Definitely some overfitting happening here","9f134487":"# 5. Submission Data using best model\n### Looking at the data above from our model evaluations, the best model seems to be the Decision Tree model. So we will use the Decision Tree model for our submission.","0b3d2736":"## 3.3 Decision Tree model","cf70f79e":"### Let's check the statiscal information of the data using describe()","eda8b58b":"### As expected, we can see we have quite a bit of invalid data in our training set, which won't be good for our model. 177 Age, 687 cabin, and 2 embarked data slots are null.","403ec4b4":"## 2.5 Age feature","1b74702c":"### Let's drop columns that probably don't have much of an impact. In this case, I do not think the following columns impact whether we can tell if someone survives or not:\n### PassengerID, Name, Ticket, Cabin, and Parch \n### It is possible these columns could indeed provide us with better information, but for now let's drop them.","c7094e79":"### Check head of both sets and the shape to make sure they match","02695721":"# 1. Loading the data\n### Loading the training data into train_df and test_df. The copying those into train_data and test_data so we can alter them later while keeping the original df if we need it.","6fd2a913":"### Create X and y inputs. \n### Plug them into train_test_split model.\n### Verify the shapes of both the train and test data are as expected, so we don't get errors when training the models.","641f64cb":"## 4.5 [Just for fun] Logistic Regression","e6d0336f":"## 2.2 Survived feature","988ae1ab":"## 4.2 K Nearest Neighbors","42db56ec":"## 3.2 K Nearest Neighbors model","c8dcb223":"## 3.1 Linear regression model","09742b63":"## 4.1 Linear Regression"}}