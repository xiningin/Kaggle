{"cell_type":{"aa8edf04":"code","44e7fc32":"code","37610d6e":"code","54f7f0bf":"code","bf3d3be5":"code","dff0d33a":"code","e8764882":"code","5698019f":"code","59609fc7":"code","634a91fc":"code","f75d04fe":"code","22271e2e":"code","353016c3":"code","529ad61a":"code","f1d50c89":"code","6c96b0b5":"code","1097501f":"code","13808dff":"markdown","f610ff66":"markdown","625e970a":"markdown","4486474a":"markdown","2af24955":"markdown","697f9aae":"markdown","2975435a":"markdown"},"source":{"aa8edf04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44e7fc32":"country_data = pd.read_csv('\/kaggle\/input\/unsupervised-learning-on-country-data\/Country-data.csv')\ndata_dictionary = pd.read_csv('\/kaggle\/input\/unsupervised-learning-on-country-data\/data-dictionary.csv')\ncountry_data.head()","37610d6e":"country_data.shape","54f7f0bf":"country_data.isnull().sum()","bf3d3be5":"country_data.info()","dff0d33a":"dataset = country_data.iloc[:,1:]\ndataset.head()","e8764882":"# Importing necessary libraries for Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","5698019f":"plt.figure(figsize=(8,8))\ncorr = dataset.corr()\nsns.heatmap(dataset.corr(),annot=True)\nplt.show()","59609fc7":"pos_ =  corr[corr >= 0.80]\nneg_ = corr[corr <= -0.80]\nprint(pos_)\nprint(neg_)","634a91fc":"sns.color_palette()\n","f75d04fe":"sns.set_theme(style=\"ticks\")\nsns.pairplot(dataset,palette='red')","22271e2e":"X = dataset","353016c3":"#elbow method\nfrom sklearn.cluster import KMeans\nwcss=[]\nK = range(1,11)\nfor i in K:\n    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(K,wcss,marker='o')\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","529ad61a":"from sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\n\n\nrange_n_clusters = [2,3,4,5,6]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 1 column\n    fig, (ax1) = plt.subplots(1)\n    fig.set_size_inches(10, 5)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","f1d50c89":"# Fitting K-Means to the dataset\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)\nprint(y_kmeans)","6c96b0b5":"# Count of records in each cluster\npd.Series(kmeans.labels_).value_counts()","1097501f":"pd.options.display.max_rows = None\nClusterNumber = pd.DataFrame(kmeans.labels_)\nCountry = country_data['country']\ndf1 = pd.concat([ClusterNumber,Country],axis=1)\ndf1\n","13808dff":"As per Elbow graph, \"3\" should be the Number of Cluster.\nLets validate using Silhoute Score","f610ff66":"Now Apply K-Means clustering with number of cluster = 3","625e970a":"# **Data Visualization**","4486474a":"1. Choose Number of Clusters i.e. k.\n2. Valtidate the chosen k using Clustering Validation : Sillhoute","2af24955":"KMeans, HSCAN, DBSCAN","697f9aae":"**As observed, more that 80 % data are correlated for below features:**\n1. Negatively Correlated : \"child_mort\" <=> \"life_expec\"\n2. Positively Correlated : \"income\" <=> \"gdpp\" and \"child_mort\" <=> \"total_fer\"","2975435a":"**As observed For cluster 2, we've highest Silhouette Score but it do have negative values so, it can't be consider.\nHence, 3 is the optimal value of K.**"}}