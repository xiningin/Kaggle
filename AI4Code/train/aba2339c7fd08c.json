{"cell_type":{"ecb6b827":"code","be809e6d":"code","1bb1e35d":"code","c137941f":"code","1bb05505":"code","0e08372c":"code","60a1a91c":"code","d4003d72":"code","f8c6740f":"code","3e739bca":"code","603136fd":"code","6786cc25":"code","2ba2e589":"code","ebce55f4":"code","cdbf6b73":"code","e334de50":"code","b08d2385":"code","74b79da6":"code","0d604a7d":"code","10fa289f":"markdown","68d42e3e":"markdown","329d6aae":"markdown","e14c9417":"markdown","26df7e3a":"markdown","3c80b0a3":"markdown","cf9be644":"markdown","6bca7de3":"markdown","54a96bb4":"markdown","9ee97172":"markdown"},"source":{"ecb6b827":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be809e6d":"import cv2\nimport matplotlib.pyplot as plt","1bb1e35d":"img = plt.imread(\"..\/input\/images\/infographic.jpg\")\nplt.imshow(img)","c137941f":"from mpl_toolkits.mplot3d import Axes3D\nimport cv2\nimg = plt.imread(\"..\/input\/images\/infographic.jpg\")\n#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nr, g, b = cv2.split(img)\nr = r.flatten()\ng = g.flatten()\nb = b.flatten()#plotting \nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(r, g, b)\nplt.show()\n#From the plot one can easily see that the data points are forming groups \u2014 \n#some places in a graph are more dense, which we can think as different colors\u2019 dominance on the image.","1bb05505":"img = cv2.imread(\"..\/input\/mixima\/miximage.jpg\")\nimg=cv2.cvtColor(img ,cv2.COLOR_BGR2RGB)\nplt.figure(figsize=(13,10))\nplt.imshow(img)","0e08372c":"img.shape #the first is height, the second is width and the third is the color channel of the image","60a1a91c":"#Next, converts the HxWx3 image into a Kx3 matrix where K=HxW and each row is now a vector in the 3-D space of RGB.\nvectorized_img = img.reshape((-1,3))\nvectorized_img.shape","d4003d72":"#We convert the unit8 values to float as it is a requirement of the k-means method of OpenCV.\nvectorized_img= np.float32(vectorized_img)\nvectorized_img","f8c6740f":"criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)","3e739bca":"K = 3\nattempts=10\nret,label,center=cv2.kmeans(vectorized_img,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)","603136fd":"center = np.uint8(center)\ncenter","6786cc25":"#Next, we have to access the labels to regenerate the clustered image\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))","2ba2e589":"plt.figure(figsize=(15,10))\nplt.imshow(result_image)","ebce55f4":"plt.figure(figsize=(15,12))\nplt.subplot(1,2,1)\nplt.imshow(img)\nplt.title('Original Image')\nplt.subplot(1,2,2)\nplt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K)\nplt.show()","cdbf6b73":"K = 5\nattempts=10\nret,label,center=cv2.kmeans(vectorized_img,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)","e334de50":"center = np.uint8(center)\ncenter","b08d2385":"res = center[label.flatten()]\nresult_image = res.reshape((img.shape))","74b79da6":"plt.figure(figsize=(15,12))\nplt.subplot(1,2,1)\nplt.imshow(img)\nplt.title('Original Image')\nplt.subplot(1,2,2)\nplt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K)\nplt.show()","0d604a7d":"K = 20\nattempts=10\nret,label,center=cv2.kmeans(vectorized_img,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))\nplt.figure(figsize=(15,12))\nplt.subplot(1,2,1)\nplt.imshow(img)\nplt.title('Original Image')\nplt.subplot(1,2,2)\nplt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K)\nplt.show()","10fa289f":"## 2.Where Can We Use Image Segmentation:","68d42e3e":"<font color=\"purple\">\nWe are going to cluster with k = 3 because if you look at the image above it has 3 colors, green-colored grass and forest, blue sea and the greenish-blue seashore.","329d6aae":"## 1. Definition and Explanation of Image Segmentation:","e14c9417":"<font color=\"purple\">\nLet's see what happens when we change the value of K=5:","26df7e3a":"<font color=\"purple\">\nAs you can see with an increase in the value of K, the image becomes clearer because the K-means algorithm can classify more classes\/cluster of colors.","3c80b0a3":"## 3. K Means Algorithm for Image Segmentation:","cf9be644":"<font color=\"purple\">\nK Means clustering algorithm is an unsupervised algorithm and it is used to segment the interest area from the background. It clusters, or partitions the given data into K-clusters or parts based on the K-centroids.\n    \n\nThe algorithm is used when you have unlabeled data(i.e. data without defined categories or groups). The goal is to find certain groups based on some kind of similarity in the data with the number of groups represented by K.","6bca7de3":"<font color=\"purple\">\nOpenCV provides cv2.kmeans(samples, nclusters(K), criteria, attempts, flags) function for color clustering.\n\n1. samples: It should be of np.float32 data type, and each feature should be put in a single column.\n\n2. nclusters(K): Number of clusters required at the end\n\n3. criteria: It is the iteration termination criteria. When this criterion is satisfied, the algorithm iteration stops. Actually, it should be a tuple of 3 parameters. They are `( type, max_iter, epsilon )`:\n\nType of termination criteria. It has 3 flags as below:\n\ncv.TERM_CRITERIA_EPS \u2014 stop the algorithm iteration if specified accuracy, epsilon, is reached.\ncv.TERM_CRITERIA_MAX_ITER \u2014 stop the algorithm after the specified number of iterations, max_iter.\ncv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER \u2014 stop the iteration when any of the above condition is met.\n4. attempts: Flag to specify the number of times the algorithm is executed using different initial labelings. The algorithm returns the labels that yield the best compactness. This compactness is returned as output.\n\n5. flags: This flag is used to specify how initial centers are taken. Normally two flags are used for this: cv.KMEANS_PP_CENTERS and cv.KMEANS_RANDOM_CENTERS.\n\n","54a96bb4":"<font color=\"green\">\nImage segmentation is the classification of an image into different groups. \n    \nImage segmentation is the task of partitioning an image into multiple segments. In semantic segmentation, all pixels that are part of the same object type get assigned to the same segment. For example, in a selfdriving car\u2019s vision system, all pixels that are part of a pedestrian\u2019s image might be assigned to the \u201cpedestrian\u201d segment (there would be one segment containing all the pedestrians).In some applications, this may be sufficient. For example, if you want to analyze satellite images to measure how much total forest area there is in a region, color segmentation may be just fine.\n    \n    \n    \nImage segmentation is the process of partitioning a digital image into multiple distinct regions containing each pixel(sets of pixels, also known as superpixels) with similar attributes.\n    \n    \nThe goal of Image segmentation is to change the representation of an image into something that is more meaningful and easier to analyze.\n    \n    \nImage segmentation is typically used to locate objects and boundaries(lines, curves, etc.) in images. More precisely, Image Segmentation is the process of assigning a label to every pixel in an image such that pixels with the same label share certain characteristics.","9ee97172":"<font color=\"purple\">\n1. In  Autonomous Vehicles: they need sensory input devices like cameras, radar, and lasers to allow the car to perceive the world around it, creating a digital map. Autonomous driving is not even possible without object detection which itself involves image classification\/segmentation.\n    \n    \n    \n2. Healthcare Industry:if we talk about Cancer, even in today\u2019s age of technological advancements, cancer can be fatal if we don\u2019t identify it at an early stage. Detecting cancerous cell(s) as quickly as possible can potentially save millions of lives. The shape of the cancerous cells plays a vital role in determining the severity of cancer which can be identified using image classification algorithms.\n\n"}}