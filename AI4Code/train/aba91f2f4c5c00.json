{"cell_type":{"224d74d2":"code","682af179":"code","2dd6adbe":"code","0973fd97":"code","cb4991fc":"code","00581db0":"code","993c5a15":"code","bce69900":"code","94ef0265":"code","12dad7d1":"code","21077076":"code","4f9d5885":"markdown","dbb22f4e":"markdown","1698c2d9":"markdown"},"source":{"224d74d2":"!pip install -q pycbc\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport numpy, pylab, glob, os\nimport pycbc.types\nfrom scipy import signal\nfrom matplotlib import pyplot as plt","682af179":"FOLDS = 16\nSEED = 2809","2dd6adbe":"train_df = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\ntrain_df['path'] = train_df['id'].apply(lambda x: f'..\/input\/g2net-gravitational-wave-detection\/train\/{x[0]}\/{x[1]}\/{x[2]}\/{x}.npy')","0973fd97":"train_df.head()","cb4991fc":"def get_data(path):\n    return np.load(path)\n\n#https:\/\/www.kaggle.com\/alexnitz\/pycbc-making-images\ndef get_qtransform(path):\n    q_vec = []\n    data = get_data(path)\n    for i in range(3):\n        vec = data[i]\n        ts = pycbc.types.TimeSeries(vec, epoch=0, delta_t=1.0\/2048) \n        \n        # whiten the data (i.e. normalize the noise power at different frequencies)\n        ts = ts.whiten(0.125, 0.125)\n        \n        # calculate the qtransform\n        time, freq, power = ts.qtransform(15.0\/2048, logfsteps=256, qrange=(10, 10), frange=(20, 512))\n        power -= power.min()\n        power \/= power.max()\n        q_vec.append(power)\n    return np.dstack(q_vec)\n\ndef get_img_qtransform(path):\n    q_vec = get_qtransform(path)*255\n    return q_vec.astype(np.uint8)","00581db0":"data = get_data(train_df.path.values[0])\n\nfig, ax = plt.subplots(3, 1, figsize=(21, 21))\n\nfor i in range(3):\n    ax[i].plot(data[i])\nplt.show();","993c5a15":"power = get_img_qtransform(train_df.path.values[1])\n\nfig, ax = plt.subplots(1, 3, figsize=(24, 8))\n\n\nfor i in range(3):\n    ax[i].imshow(power[..., i].astype(np.float32).T)","bce69900":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n    train_df.loc[val_idx,'fold'] = fold\ntrain_df.groupby(['fold', 'target'])['id'].count()","94ef0265":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","12dad7d1":"def train_serialize_example(feature0, feature1, feature2):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),   \n      'target'        : _int64_feature(feature2),\n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","21077076":"show=True\nfolds = sorted(train_df.fold.unique().tolist())\nfor fold in tqdm(folds):\n    if fold not in list(range(0, 2)):\n        continue\n    fold_df = train_df[train_df.fold==fold]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it:\n            row = fold_df.iloc[k,:]\n            image      = get_img_qtransform(row['path'])[...,::-1]\n            image_id   = row['id']\n            target     = np.array(row['target'], dtype=np.uint8)\n            example  = train_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                target,\n                )\n            writer.write(example)\n        if show:\n            filepath = 'train%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('\/')[-1]\n            filesize = os.path.getsize(filepath)\/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","4f9d5885":"<a id=\"1\"><\/a>\n## 2. Save in TFRecords","dbb22f4e":"<a id=\"0\"><\/a>\n## 0. EDA","1698c2d9":"<a id=\"1\"><\/a>\n## 1. Grouped by Target"}}