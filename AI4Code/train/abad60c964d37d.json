{"cell_type":{"d632c7e1":"code","7b35d024":"code","ad15224f":"code","47f888e4":"code","65c1815f":"code","dc3c6b57":"code","5690353b":"code","7ecdf3a6":"markdown","2192e9f8":"markdown","805e528d":"markdown","5a127705":"markdown","936471a4":"markdown","2d903189":"markdown","c71fe000":"markdown","14b952c0":"markdown"},"source":{"d632c7e1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, log_loss\n\n\nd = pd.read_csv('..\/input\/inspections_train.csv')\nx_train0, x_test0 = train_test_split(d, test_size=0.25)","7b35d024":"violations = pd.read_csv('..\/input\/violations.csv')\nviolations.head()","ad15224f":"violation_counts = violations.groupby(['camis', 'inspection_date']).size()\nviolation_counts = violation_counts.reset_index().set_index(['camis', 'inspection_date'])\nviolation_counts.columns = ['n_violations']\n\nx_train1 = x_train0.merge(violation_counts, 'left', left_on=['camis', 'inspection_date'], right_index=True)\nx_test1 = x_test0.merge(violation_counts, 'left', left_on=['camis', 'inspection_date'], right_index=True)","47f888e4":"x_train1.n_violations.hist()\nplt.show()","65c1815f":"test_solution1 = ((x_test1.n_violations < 3).map(int) * 0.5) + 0.4\nloss1 = log_loss(x_test1.passed.values, test_solution1)\nprint(f'log loss: {loss1:.3f}')","dc3c6b57":"# edit these 3 variables\ncut_off = 3\nlower_prob = 0.95\nupper_prob = 0.45\n\n\n# don't change anything down here\ndef decision_rule(val):\n    if val < cut_off: return lower_prob\n    else: return upper_prob\n\ncustom_solution = x_test1.n_violations.map(decision_rule)\ncustom_loss = log_loss(x_test1.passed.values, custom_solution)\nprint(f'Custom loss: {custom_loss:.3f}')\n\nloss_delta = loss1 - custom_loss\nif loss_delta > 0: print(f'Loss improved {loss_delta*100 \/ loss1:.2f}% Good stuff!')\nelif loss_delta < 0: print('Loss did not improve')","5690353b":"# load the test data and add the `n_violations` feature\ntest_data = pd.read_csv('..\/input\/inspections_test.csv')\ntest_data = test_data.merge(violation_counts, 'left', left_on=['camis', 'inspection_date'], right_index=True)\n\n\n\n# take just the `id` and `n_violations` columns (since that's all we need)\nsubmission = test_data[['id', 'n_violations']].copy()\n\n# create a `Predicted` column\n# for this example, we're using the custom decision rule defined by you above\nsubmission['Predicted'] = submission.n_violations.map(decision_rule)\n\n# drop the n_violations columns\nsubmission = submission.drop('n_violations', axis=1)\n\n# IMPORTANT: Kaggle expects you to name the columns `Id` and `Predicted`, so let's make sure here\nsubmission.columns = ['ID', 'Predicted']\n\n# write the submission to a csv file so that we can submit it after running the kernel\nsubmission.to_csv('submission1.csv', index=False)\n\n# let's take a look at our submission to make sure it's what we want\nsubmission.head()","7ecdf3a6":"### Submitting our solution\nIn this kernel we've developed a new way to generate solutions. Now we need to generate solutions for each row in the test data, which we find in inspections_test.csv. The steps are:","2192e9f8":"## kernel 1: rule-based solution\n#### Can we identify a prediction rule based on a first look at the data?\nWe're going to import some useful tools and load the data. If this step is unfamiliar to you, try going back to [**kernel_0**](https:\/\/www.kaggle.com\/nicknormandin\/cuny-data-challenge-kernel0).","805e528d":"Let's see what this `n_violations` feature looks like by creating a histogram. This is really easy in **pandas**.","5a127705":"With just one rule, we've made a nearly 50% reduction in our score metric (log loss)- that's awesome. This particular rule was intuitive and easy for us to understand, but what about the more subtle things? How do we create many sets of interconnected rules when the data is big and complex? Some important features of our data may not be quite so obvious to us. The next step would be to build models automatically, using **machine learning \/ statistical learning**.","936471a4":"## customize this solution!\nWant to try other values for our decision rule? Try defining your own violation cut-off value and probabilities to see what the log loss would be.\n\n**Hint:** what about raising the `lower_prob` value above 0.9?","2d903189":"Now our first step will be to create a feature that we think is important. In fact, creating and manipulating our features (widely referred to as **feature engineering** in data science) is one of the most important aspects of this profession, and one where creativity and subject matter expertise can deliver an enormous amount of value. \n\nIn the previous kernel, we only loaded the `inspections_train.csv` file, but we saw that there was other data available. Let's load `violations.csv`.","c71fe000":"We have a dataframe containing details of violations that occurred in each inspection, and it seems like it would make sense that the number of violations contributes to the probability of a failure. We'll create a dataframe that just counts the number of violations that occured and then merge it with our training \/ testing data!","14b952c0":"Based on our intution and an examination of the data, let's create a rule where we assign a pass probability of 0.9 if there were fewer than three violation records and 0.5 otherwise."}}