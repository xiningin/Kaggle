{"cell_type":{"06a3702f":"code","89a09c85":"code","39185dae":"code","6c844a1e":"code","075cea54":"code","034eca55":"code","2f642cea":"code","e5e2d807":"code","54c12848":"code","495329b9":"markdown","fee0c00d":"markdown","b121d32e":"markdown","cc143090":"markdown","1972e3b1":"markdown","db16278c":"markdown"},"source":{"06a3702f":"import pandas as pd\nimport numpy as np\nimport datetime\nimport random\nimport glob\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold,GroupKFold,RepeatedKFold\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Activation,Dropout,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n# \u4e71\u6570\u30b7\u30fc\u30c9\u56fa\u5b9a\nseed = 2020\nseed_everything(seed)","89a09c85":"inputPath = '..\/input\/5th-datarobot-ai-academy-deep-learning\/'\ntrain = pd.read_csv(inputPath+'train.csv')\ntrain['price_bin'] = pd.cut(train['price'], [2000, 20000, 200000,500000,1000000,2000000], labels=[1,2,3,4,5])\ntrain['price_bin'] = train['price_bin'].astype('int')\ntest = pd.read_csv(inputPath+'test.csv')\ndisplay(train.shape)\ndisplay(train.head())\ndisplay(test.shape)\ndisplay(test.head())","39185dae":"def load_images(df,inputPath,size):\n    images = []\n    for i in df['id']:\n        basePath = os.path.sep.join([inputPath, \"{}_*\".format(i)])\n        housePaths = sorted(list(glob.glob(basePath)))\n        inputImages = []\n        outputImage = np.zeros((size*2, size*2, 3))\n        for housePath in housePaths:\n            image = cv2.imread(housePath)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (size, size))\n            inputImages.append(image)\n        \n        outputImage[0:size, 0:size] = inputImages[0]\n        outputImage[0:size, size:size*2] = inputImages[1]\n        outputImage[size:size*2, size:size*2] = inputImages[2]\n        outputImage[size:size*2, 0:size] = inputImages[3]\n        \n        images.append(outputImage)\n    \n    return np.array(images) \/ 255.0\n\nsize = 64\n# load train images\ninputPath = '..\/input\/5th-datarobot-ai-academy-deep-learning\/images\/train_images\/'\ntrain_images = load_images(train,inputPath,size)\ndisplay(train_images.shape)\ndisplay(train_images[0][0][0])\n# load test images\ninputPath = '..\/input\/5th-datarobot-ai-academy-deep-learning\/images\/test_images\/'\ntest_images = load_images(test,inputPath,size)\ndisplay(test_images.shape)\ndisplay(test_images[0][0][0])","6c844a1e":"def vgg16_finetuning(inputShape):\n    backbone = VGG16(weights='imagenet',\n                    include_top=False,\n                    input_shape=inputShape)\n    \n    for layer in backbone.layers[:15]:\n        layer.trainable = False\n        \n    model = Sequential(layers=backbone.layers)     \n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(units=512, activation='relu',kernel_initializer='he_normal'))  \n    model.add(Dense(units=256, activation='relu',kernel_initializer='he_normal'))    \n    model.add(Dense(units=32, activation='relu',kernel_initializer='he_normal'))    \n    model.add(Dense(units=1, activation='linear'))\n    \n    model.compile(loss='mape', optimizer='adam', metrics=['mape']) \n    return model","075cea54":"datagen = ImageDataGenerator(rotation_range=45,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,         \n                             )","034eca55":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\ndef nn_kfold(train_df,test_df,train_images,test_images,imageShape,target,seed,network):\n    n_splits= 5\n    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    oof_preds = np.zeros((train_df.shape[0],1))\n    sub_preds = np.zeros((test_df.shape[0],1))\n    cv_list = []\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, train_df['price_bin'])):\n\n        train_x, train_y = train_images[train_idx], train_df[target].iloc[train_idx].values.reshape(-1,1)\n\n        valid_x, valid_y = train_images[valid_idx], train_df[target].iloc[valid_idx].values.reshape(-1,1)\n        \n        test_x = test_images\n        \n        model = network(imageShape)\n    \n        filepath = str(n_fold) + \"_nn_best_model.hdf5\" \n        es = EarlyStopping(patience=8, mode='min', verbose=1) \n        checkpoint = ModelCheckpoint(monitor='val_loss', filepath=filepath, save_best_only=True,mode='auto') \n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1)\n\n        batch_size = 16\n        datagen.fit(train_x,augment=True)\n        train_datagen = datagen.flow(train_x, train_y, batch_size=batch_size, shuffle=True)\n        history = model.fit(train_datagen, validation_data=(valid_x, valid_y),\n                            steps_per_epoch=(len(train_x) \/ batch_size) , epochs=100,\n                            callbacks=[es, checkpoint, reduce_lr_loss])\n        \n        model.load_weights(filepath)\n        _oof_preds = model.predict(valid_x, batch_size=32,verbose=1)\n        oof_preds[valid_idx] = _oof_preds.reshape(-1,1)\n\n        oof_cv = mean_absolute_percentage_error(valid_y,  oof_preds[valid_idx])\n        cv_list.append(oof_cv)\n        print (cv_list)\n        sub_preds += model.predict(test_x, batch_size=32).reshape(-1,1) \/ folds.n_splits \n        \n    cv = mean_absolute_percentage_error(train_df[target].values.reshape(-1,1),  oof_preds)\n    print('Full OOF MAPE %.6f' % cv)  \n\n    return oof_preds,sub_preds\n","2f642cea":"imageShape = (128, 128, 3) \ntarget = 'price'\nnetwork = vgg16_finetuning\n\n# \u8907\u6570\u4e71\u6570\u30b7\u30fc\u30c9merge\nfor seed in [9,42,228,817,999]:\n    train['prediction_' + str(seed)],test['prediction_' + str(seed)] = nn_kfold(train,test,train_images,test_images,imageShape,target,seed,network)\n    \n    ","e5e2d807":"train['prediction'] = (train['prediction_9'] + train['prediction_42'] + train['prediction_228'] + train['prediction_817'] + train['prediction_999'])\/5\ncv = mean_absolute_percentage_error(train['price'],  train['prediction'])\nprint('Full OOF MAPE %.6f' % cv)  ","54c12848":"test['price'] = (test['prediction_9'] + test['prediction_42'] + test['prediction_228'] + test['prediction_817'] + test['prediction_999'])\/5\ntest[['id','price']].to_csv('submission.csv',index=False)","495329b9":"# CNN\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3059\u308b","fee0c00d":"# Cross Validation \u30e2\u30c7\u30eb\u8a13\u7df4","b121d32e":"# \u30c7\u30fc\u30bf\u6c34\u5897\u3084\u3057","cc143090":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","1972e3b1":"# CSV\u8aad\u307f\u8fbc\u307f","db16278c":"# \u753b\u50cf\u3092\u8aad\u307f\u8fbc\u307f"}}