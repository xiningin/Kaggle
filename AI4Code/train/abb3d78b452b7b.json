{"cell_type":{"2614bf2c":"code","400a1554":"code","d7248d2c":"code","897386fb":"code","d2306658":"code","3334833b":"code","aaa831cd":"code","f1dea668":"code","3ceaaabd":"code","099c4c51":"code","d8da6875":"code","40d75cb5":"code","de6c6e52":"code","d8374725":"code","c042ed8e":"code","15d10cf2":"code","d5622d57":"code","97935bd2":"code","f71d3d99":"code","01580a58":"code","82f27b25":"code","fe6b267d":"code","7dc6311c":"code","06368016":"code","9256dc15":"code","a2d81c4a":"code","66d99904":"code","6d2f3360":"code","03d39171":"code","725415ca":"code","e19cf92a":"code","df84f29b":"code","4e39db6c":"code","5b7f9539":"code","456ab6ec":"code","56e211b7":"code","fb43a126":"code","0281f61b":"markdown","0e0a2b7a":"markdown","852dd325":"markdown","288330b8":"markdown","d7768f55":"markdown","70d7fc57":"markdown","5914bb3f":"markdown","efd287f5":"markdown","59acf3d8":"markdown","bbc037f9":"markdown","67a3ff0b":"markdown","57282b65":"markdown","bb4a538f":"markdown","bf72ab06":"markdown","51e18bbf":"markdown","57f35d34":"markdown","5cdcd60f":"markdown","a999628a":"markdown"},"source":{"2614bf2c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom datetime import datetime","400a1554":"# Import the Data\ndata = pd.read_csv('..\/input\/data.csv')","d7248d2c":"# Explore the Data\ndata.head(8)","897386fb":"data.describe()","d2306658":"# Check for missing values\nsns.heatmap(data.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')","3334833b":"# Delete the empty column\ndata.drop('Unnamed: 32', axis = 1, inplace = True)","aaa831cd":"# Visualize the data\nsns.set(style = 'darkgrid')\ng = sns.countplot(x = \"diagnosis\", data = data, palette = \"Set3\")\nplt.ylabel(\"Number of Occurences\")\nplt.xlabel(\"Diagnosis\")\nplt.title(\"Diagnosis Distribution\")","f1dea668":"# drop ID column from our dataset\ndata.drop('id', axis = 1, inplace = True)","3ceaaabd":"data.columns","099c4c51":"# Create groups of some variables we want to visualize\nmeans = data[['diagnosis', 'radius_mean', 'texture_mean', 'radius_worst', 'texture_worst']]\n\nmeans2 = data[['diagnosis', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean']]\n\nmeans3 = data[['diagnosis', 'concave points_mean', 'fractal_dimension_mean']]","d8da6875":"# Use pd.melt to be able to visualize multiple variables at once\nmelt_means = pd.melt(means, id_vars = 'diagnosis', var_name = \"Variables\", value_name = \"Value\")\nmelt_means2 = pd.melt(means2, id_vars = 'diagnosis', var_name = \"Variables\", value_name = \"Value\")\nmelt_means3 = pd.melt(means3, id_vars = 'diagnosis', var_name = \"Variables\", value_name = \"Value\")","40d75cb5":"# Boxplots\nsns.boxplot(x = \"Variables\", y = \"Value\", data = melt_means, hue = 'diagnosis', palette = 'pastel')","de6c6e52":"sns.boxplot(x = \"Variables\", y = \"Value\", \n            data = melt_means2, hue = 'diagnosis', \n            palette = 'pastel')\n\nplt.xticks(rotation=25)","d8374725":"sns.boxplot(x = \"Variables\", y = \"Value\", data = melt_means3, hue = 'diagnosis', palette = 'pastel')","c042ed8e":"# We can also see the relationship between multiple variables at once\nf = sns.PairGrid(means)\nf = f.map_upper(plt.scatter)\nf = f.map_lower(sns.kdeplot, cmap = \"Purples_d\")\nf = f.map_diag(sns.kdeplot, lw = 3, legend = False)","15d10cf2":"c = sns.swarmplot(x = \"Variables\", y = \"Value\", data = melt_means2, hue = 'diagnosis', palette = 'pastel')\nplt.xticks(rotation=25)","d5622d57":"# Violin plots\ncv = sns.violinplot(x = \"Variables\", y = \"Value\", data = melt_means2, hue = 'diagnosis', palette = 'spring')\nplt.xticks(rotation=25)","97935bd2":"cv = sns.violinplot(x = \"Variables\", y = \"Value\", data = melt_means2, hue = 'diagnosis', palette = 'seismic', split = True)\nplt.xticks(rotation=25)","f71d3d99":"# If we want to see any specific relationships, we can use this:\nsns.jointplot(x = 'texture_mean', y = 'radius_mean', data = means, kind = 'hex', color = \"#4CB391\")","01580a58":"corrmat = data.corr()\nfig, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrmat, square = True, cmap = \"YlGnBu\", annot = True, fmt = '.1f', linewidths = .25, linecolor = 'r')","82f27b25":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier","fe6b267d":"# Prepare the data\nX = data.drop('diagnosis', axis = 1)\ny = data['diagnosis']","7dc6311c":"# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","06368016":"# Feature Selection\nsel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\nsel.fit(X_train, y_train)","9256dc15":"# Check which features were selected to be the best to use\nsel.get_support()","a2d81c4a":"selected_feat = X_train.columns[(sel.get_support())]\nprint(selected_feat)","66d99904":"X = data[['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean',\n       'radius_worst', 'perimeter_worst', 'area_worst',\n       'concave points_worst']]\n\ny = data['diagnosis']","6d2f3360":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","03d39171":"dtree = DecisionTreeClassifier()","725415ca":"dtree.fit(X_train, y_train)","e19cf92a":"# Predict values based on selected model\npredictions = dtree.predict(X_test)","df84f29b":"# Check how the well the model did\nfrom sklearn.metrics import classification_report, confusion_matrix","4e39db6c":"print(confusion_matrix(y_test, predictions))\nprint('\\n')\nprint(classification_report(y_test, predictions))","5b7f9539":"rfc = RandomForestClassifier(n_estimators = 100)","456ab6ec":"# Fit the model\nrfc.fit(X_train, y_train)","56e211b7":"# Predict values\nrfc_pred = rfc.predict(X_test)","fb43a126":"# Check accuracy\nprint(confusion_matrix(y_test, rfc_pred))\nprint('\\n')\nprint(classification_report(y_test, rfc_pred))","0281f61b":"### Feature Selection\n\nFirst, let's see which variables are going to be included in our model","0e0a2b7a":"Let's try to fit a model using random forests","852dd325":"We are going to be using Machine Learning (Decision Trees and Random Forests) to diagnose patients based on the data","288330b8":"### Refit the model with new features","d7768f55":"We have 30 variables\n\nIt is going to be easier to visualize them in smaller groups","70d7fc57":"## Thanks for checking this out","5914bb3f":"Lastly, let's see how all variable scorrelate to one another","efd287f5":"### Data Visualization","59acf3d8":"### Data: Breast Cancer Wisconsin Diagnostic","bbc037f9":"92% acuuracy - Not too great but not too bad","67a3ff0b":"There are definitely some significant differences in values between M and B groups\n\nLet's try different kinds of plots to explore the data a little more","57282b65":"There are now no missing values in the data","bb4a538f":"The dataset is fairly big, we can assume that Random Forests is going to do a better job here","bf72ab06":"That's enough visualization\n\n## Model Building","51e18bbf":"## Machine Learning Using Decision Trees and Random Forests","57f35d34":"## Random Forests","5cdcd60f":"You can see the B values being smaller than the M values very clearly here","a999628a":"Sure enough!\n\nWe get 96% accuracy.\n\nAs expected, random forests did a better job."}}