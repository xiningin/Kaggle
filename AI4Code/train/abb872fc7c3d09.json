{"cell_type":{"9c2694ae":"code","eb79bb05":"code","bab90ccd":"code","265a0b76":"code","dd25141a":"code","8476cf3e":"code","049b6803":"code","fec62682":"code","e37962be":"code","3ff1bcb1":"code","0022a3c1":"code","877f2cb1":"code","81a709c3":"code","2f1b3b91":"code","3208ce9c":"code","dcb48c2d":"code","b64942bc":"code","eaa8e36a":"code","2834e2d6":"code","32e23444":"code","c63e5458":"code","b2056081":"code","b6418a5c":"code","b8176cab":"code","38d9c84d":"code","a67678d6":"code","b9665580":"code","caeb7865":"code","19eb7244":"code","ae5a3967":"code","b1f3e28b":"code","d7c32915":"code","bb15d005":"code","9d59dff5":"code","972ad9d5":"code","fd21cda5":"code","0a68f44b":"code","670ff122":"markdown","243e55a3":"markdown","a5077801":"markdown","f11131b1":"markdown","cdac03f0":"markdown","ca5d319b":"markdown","70ed6e9d":"markdown","931b89ce":"markdown","81fc1375":"markdown","defa1589":"markdown","ca037cc2":"markdown","fa2cc396":"markdown","54399183":"markdown","8bd56db8":"markdown","54f7b678":"markdown","8a9beff8":"markdown"},"source":{"9c2694ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os, sys\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eb79bb05":"!pwd","bab90ccd":"!ls ..\/","265a0b76":"!ls ..\/input\/amazon-fine-food-reviews\/","dd25141a":"!pip install jupyterthemes","8476cf3e":"import pandas as pd\nimport numpy as np\nimport sqlite3\nimport re\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom jupyterthemes import jtplot\nfrom tqdm import tqdm","049b6803":"# from sklearn.preprocessing import StandardScaler\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.dummy import DummyClassifier\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom xgboost import XGBClassifier\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import ngrams\n\nfrom string import punctuation\nfrom itertools import chain\n\n# from imblearn.over_sampling import SMOTE\n# from imblearn.under_sampling import RandomUnderSampler","fec62682":"import warnings\nwarnings.filterwarnings('ignore')","e37962be":"# set plot rc parameters\n\n# jtplot.style(grid=False)\nplt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = '#464646'\n#plt.rcParams['axes.edgecolor'] = '#FFFFFF'\nplt.rcParams['figure.figsize'] = 10, 7\nplt.rcParams['text.color'] = '#666666'\nplt.rcParams['axes.labelcolor'] = '#333333'\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['xtick.color'] = '#666666'\nplt.rcParams['xtick.labelsize'] = 14\nplt.rcParams['ytick.color'] = '#666666'\nplt.rcParams['ytick.labelsize'] = 14\n\n# plt.rcParams['font.size'] = 16\n\nsns.color_palette('dark')\n%matplotlib inline\n\ntqdm.pandas()","3ff1bcb1":"# establish connection with database\n\nconn = sqlite3.connect('..\/input\/amazon-fine-food-reviews\/database.sqlite')","0022a3c1":"# sneak peek of data\n\npd.read_sql_query('''SELECT * FROM Reviews LIMIT 10''', conn)","877f2cb1":"# read data into data frame\n# drop data points where score is 3 neutral\n# score > 3 are positive reviews and score < 3 are negative\n\ndata_df = pd.read_sql_query('''\nSELECT\n    HelpfulnessNumerator as helpful,\n    HelpfulnessDenominator,\n    Score,\n    Text\nFROM\n    Reviews\nWHERE\n    Score != 3''', conn)","81a709c3":"data_df.shape","2f1b3b91":"# drop duplicate data points\n\ndata_df.drop_duplicates(inplace=True)\ndata_df.shape","3208ce9c":"data_df.head()","dcb48c2d":"data_df['Sentiment'] = data_df['Score'].apply(lambda x: 1 if x>3 else 0)","b64942bc":"# remove non alphabetic characters\n\ndef remove_non_alphabet(sentence):\n    pattern = re.compile(r'[^a-z]+')\n    sentence = sentence.lower()\n    sentence = pattern.sub(' ', sentence).strip()\n    \n    return sentence\n\ndata_df['Clean_text'] = data_df['Text'].apply(lambda x: remove_non_alphabet(x))","eaa8e36a":"# remove stopwords and stemming\n\ndef remove_stop_words(sentence):\n    # Tokenize\n    word_list = word_tokenize(sentence)\n    # stop words\n    stopwords_list = set(stopwords.words('english'))\n    # remove stop words\n    word_list = [word for word in word_list if word not in stopwords_list]\n    # stemming\n    ps  = PorterStemmer()\n    word_list = [ps.stem(word) for word in word_list]\n    # list to sentence\n    sentence = ' '.join(word_list)\n    \n    return sentence\n\ndata_df['Clean_text'] = data_df['Clean_text'].progress_apply(lambda x: remove_stop_words(x))","2834e2d6":"data_df.head()","32e23444":"# vectorize data \n\n# bag of words\nbow = CountVectorizer()\nX_bow = bow.fit_transform(data_df['Clean_text'])\n# Xtest_bow = bow.fit_transform(test_df['Clean_text'])\n\n# tfidf \ntfidf = TfidfVectorizer()\nX_tfidf = tfidf.fit_transform(data_df['Clean_text'])\n# Xtest_tfidf = tfidf.fit_transform(test_df['Clean_text'])\n\n# ytrain and ytest\n# Ytrain = train_df['Sentiment']\n# Ytest = test_df['Sentiment']","c63e5458":"Xtrain_bow, Xtest_bow, Ytrain, Ytest = train_test_split(X_bow, data_df['Sentiment'], test_size=0.25, random_state=12)\nXtrain_tfidf, Xtest_tfidf, Ytrain, Ytest = train_test_split(X_tfidf, data_df['Sentiment'], test_size=0.25, random_state=12)","b2056081":"# plot word cloud function\n\ndef plot_wordcloud(sentences, title):\n    # create word cloud\n    wordcloud = WordCloud(background_color='black',\n                          max_words=200).generate(str(sentences))\n    # plt params\n    fig = plt.figure(figsize=[15,15])\n    plt.axis('off')\n    plt.suptitle(title, fontsize=18)\n    plt.subplots_adjust(top=1.4)\n    plt.imshow(wordcloud)\n    plt.show()\n    \n    return","b6418a5c":"# plot word cloud for training data with positive examples\nplot_wordcloud(data_df[data_df['Sentiment'] == 1]['Clean_text'], 'data points with positive sentiment')","b8176cab":"# plot word cloud for training data with negative examples\nplot_wordcloud(data_df[data_df['Sentiment'] == 0]['Clean_text'], 'data points with negative sentiment')","38d9c84d":"fig = plt.figure(figsize=[6,8])\nplt.suptitle('Sentiment Distribution', fontsize=18)\nax = sns.countplot(data=data_df,x='Sentiment')\nax.set_xticklabels(['negative', 'positive'])\nplt.show()","a67678d6":"# Function to print model performance summary statistics\n\ndef performance_summary(model, Xtrain, Xtest, Ytrain, Ytest):\n    \n    Ytrain_pred = model.predict(Xtrain)\n    Ytest_pred = model.predict(Xtest)\n\n    # model performance\n    # accuracy score\n    print('Training Accuracy:\\n', accuracy_score(Ytrain, Ytrain_pred))\n    print('\\n')\n    print('Test Accuracy:\\n', accuracy_score(Ytest, Ytest_pred))\n    print('\\n')\n    # classification report\n    print('Classification Report training:\\n', classification_report(Ytrain,Ytrain_pred))\n    print('\\n')\n    print('Classification Report test:\\n', classification_report(Ytest,Ytest_pred))\n    \n    return","b9665580":"# Function to plot Confusion matrix\n\ndef plot_confusion_matrix(model, Xtrain, Xtest, Ytrain, Ytest):\n    \n    Ytrain_pred = model.predict(Xtrain)\n    Ytest_pred = model.predict(Xtest)\n\n    # confusion matrix\n    fig, axs = plt.subplots(1,2,\n                            figsize=[15,5])\n    axs = axs.flatten()\n    \n    axs[0].title.set_text('Training data')\n    # axs[0].set_xlabel('Predicted label')\n    # axs[0].set_ylabel('True label')\n    axs[1].title.set_text('Test data')\n    # axs[1].set_xlabel('Predicted label')\n    # axs[1].set_ylabel('True label')\n    \n    fig.text(0.26, 0.01, 'Predicted label', ha='center', size=14)\n    fig.text(0.69, 0.01, 'Predicted label', ha='center', size=14)\n    fig.text(0.08, 0.5, 'True label', va='center', rotation='vertical', size=14)\n    fig.text(0.5, 0.5, 'True label', va='center', rotation='vertical', size=14)\n    \n    sns.heatmap(confusion_matrix(Ytrain,Ytrain_pred),\n                    annot=True,\n                    xticklabels=['negative', 'positive'],\n                    yticklabels=['negative', 'positive'],\n                    fmt=\"d\",\n                    ax=axs[0])\n    \n    sns.heatmap(confusion_matrix(Ytest,Ytest_pred),\n                    annot=True,\n                    xticklabels=['negative', 'positive'],\n                    yticklabels=['negative', 'positive'],\n                    fmt=\"d\",\n                    ax=axs[1])\n    plt.show()\n    \n    return","caeb7865":"# Function to plot ROC\n\ndef plot_roc(model, Xtrain, Xtest, Ytrain, Ytest):\n    # ROC curve and area under ROC curve\n\n    # get FPR and TPR for training and test data\n    Ytrain_pred_proba = model.predict_proba(Xtrain)\n    fpr_train, tpr_train, thresholds_train = roc_curve(Ytrain, Ytrain_pred_proba[:,1])\n    # tpr fpr are swapped \n    roc_auc_train = auc(fpr_train, tpr_train)\n    Ytest_pred_proba = model.predict_proba(Xtest)\n    fpr_test, tpr_test, thresholds_test = roc_curve(Ytest, Ytest_pred_proba[:,1])\n    # tpr fpr are swapped\n    roc_auc_test = auc(fpr_test, tpr_test)\n\n    # print area under roc curve\n    print ('AUC_ROC train:\\t', roc_auc_train)\n    print ('AUC_ROC test:\\t', roc_auc_test)\n\n    # plot auc roc\n    fig, axs = plt.subplots(1,2,\n                            figsize=[15,5],\n                            sharex=False,\n                            sharey=False)\n    \n    # training data\n    axs[0].set_title('Receiver Operating Characteristic trainning')\n    axs[0].plot(fpr_train,\n                tpr_train,\n                sns.xkcd_rgb['greenish cyan'],\n                label='AUC = %0.2f'% roc_auc_train)\n    axs[0].legend(loc='lower right', facecolor='#232323')\n    \n    axs[0].plot([0,1],[0,1],\n                ls='--',\n                c=sns.xkcd_rgb['red pink'])\n    \n    axs[0].set_xlim([-0.01,1.01])\n    axs[0].set_ylim([-0.01,1.01])\n    axs[0].set_ylabel('True Positive Rate')\n    axs[0].set_xlabel('False Positive Rate')\n    \n    # test data\n    axs[1].set_title('Receiver Operating Characteristic testing')\n    axs[1].plot(fpr_test,\n                tpr_test,\n                sns.xkcd_rgb['greenish cyan'],\n                label='AUC = %0.2f'% roc_auc_test)\n    axs[1].legend(loc='lower right', facecolor='#232323')\n    \n    axs[1].plot([0,1],[0,1],\n                ls='--',\n                c=sns.xkcd_rgb['red pink'])\n    \n    axs[1].set_xlim([0.0,1.0])\n    axs[1].set_ylim([0.0,1.0])\n    axs[1].set_ylabel('True Positive Rate')\n    axs[1].set_xlabel('False Positive Rate')\n\n    plt.show()\n    \n    return","19eb7244":"lr_clf = GridSearchCV(LogisticRegression(),\n                     cv=5,\n                     param_grid={'C':[1e-2,1e-1,1,10,100]},\n                     scoring='accuracy')","ae5a3967":"# lr_clf.fit(Xtrain_bow, Ytrain)","b1f3e28b":"# lr_clf.best_params_, lr_clf.best_score_","d7c32915":"# train logistic regression model for bag of words\nlogreg_bow = LogisticRegression(C=1)\nlogreg_bow.fit(Xtrain_bow, Ytrain)\n\n# train logistic regression model for tfidf\nlogreg_tfidf = LogisticRegression(C=10)\nlogreg_tfidf.fit(Xtrain_tfidf, Ytrain)","bb15d005":"# model performance\nprint('*'*25+'Bag of Words'+'*'*25)\nperformance_summary(logreg_bow, Xtrain_bow, Xtest_bow, Ytrain, Ytest)\nprint('\\n\\n\\n')\nprint('*'*28+'TF-IDF'+'*'*28)\nperformance_summary(logreg_tfidf, Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest)","9d59dff5":"# pot confusion matrix and roc curve\n# Bag of words\nprint('*'*25+'Bag of words'+'*'*25)\nplot_confusion_matrix(logreg_bow, Xtrain_bow, Xtest_bow, Ytrain, Ytest)\nplot_roc(logreg_bow, Xtrain_bow, Xtest_bow, Ytrain, Ytest)\n\n# Tf idf\nprint('*'*28+'TF-IDF'+'*'*28)\nplot_confusion_matrix(logreg_tfidf, Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest)\nplot_roc(logreg_tfidf, Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest)","972ad9d5":"# train logistic regression model for bag of words\nrf_bow = RandomForestClassifier(n_jobs=-1)\nrf_bow.fit(Xtrain_bow, Ytrain)\n\n# train logistic regression model for tfidf\nrf_tfidf = RandomForestClassifier(n_jobs=-1)\nrf_tfidf.fit(Xtrain_tfidf, Ytrain)","fd21cda5":"# model performance\nprint('*'*25+'Bag of Words'+'*'*25)\nperformance_summary(rf_bow, Xtrain_bow, Xtest_bow, Ytrain, Ytest)\nprint('\\n\\n\\n')\nprint('*'*28+'TF-IDF'+'*'*28)\nperformance_summary(rf_tfidf, Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest)","0a68f44b":"# pot confusion matrix and roc curve\n# Bag of words\nprint('*'*25+'Bag of words'+'*'*25)\nplot_confusion_matrix(rf_bow, Xtrain_bow, Xtest_bow, Ytrain, Ytest)\nplot_roc(rf_bow, Xtrain_bow, Xtest_bow, Ytrain, Ytest)\n\n# Tf idf\nprint('*'*28+'TF-IDF'+'*'*28)\nplot_confusion_matrix(rf_tfidf, Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest)\nplot_roc(rf_tfidf, Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest)","670ff122":"## Text Pre-processing","243e55a3":"## Set Plotting parameters","a5077801":"### Logistic Regression","f11131b1":"## Data Visualization","cdac03f0":"## Import modules","ca5d319b":"### Training data","70ed6e9d":"\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.","931b89ce":"### Helper functions","81fc1375":"### Install jupyter-themes","defa1589":"# Amazon Fine Food Reviews","ca037cc2":"### Hyper parameter tuning","fa2cc396":"*  Can't find any negative words for negative sentiment data\n*  Its better to try modelling data with stop words","54399183":"### Random Forest","8bd56db8":"## Load data","54f7b678":"## Train Models","8a9beff8":"*  for tfidf best c is 10\n*  for bag of words best c is 1"}}