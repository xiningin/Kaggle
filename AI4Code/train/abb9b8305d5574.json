{"cell_type":{"0534a183":"code","27ee34e9":"code","b9747626":"code","343e9926":"code","42a8ef4d":"code","8e01fad6":"code","5a6cfd95":"code","678d155c":"code","bb52be16":"code","7ec9db49":"code","11b15460":"code","94ad065c":"code","4a24ee3c":"code","16340111":"code","7dddc1f0":"code","9a6dd1ba":"code","2e530b4c":"code","caa23b3c":"code","cd49345d":"code","dfe9aa66":"code","97e60bc1":"code","4011c0ea":"code","d7dc6afb":"code","e61a5160":"code","ee436225":"code","febf1ee9":"code","64129c13":"code","8cf0be34":"code","105a8a12":"markdown","15050a0c":"markdown","06d677d3":"markdown"},"source":{"0534a183":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.metrics import roc_curve, auc\n\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27ee34e9":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","b9747626":"train_data.loc[train_data['Name'].str.contains(\"Jack\", case=False)]","343e9926":"train_data.head(20)","42a8ef4d":"train_data.describe()","8e01fad6":"train_data.info()","5a6cfd95":"features_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']","678d155c":"train_data = pd.get_dummies(train_data, columns=['Pclass'], prefix='P')\ntrain_data = pd.get_dummies(train_data, columns=['Sex'], prefix='S')\ntrain_data = pd.get_dummies(train_data, columns=['Embarked'], prefix='E')","bb52be16":"imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\ntrain_data['Age'] = imputer.fit_transform(train_data[['Age']])","7ec9db49":"scaler = StandardScaler()\ntrain_data[['Age']] = scaler.fit_transform(train_data[['Age']])\ntrain_data[['Fare']] = scaler.fit_transform(train_data[['Fare']])","11b15460":"X = train_data.drop(columns = features_to_drop)\nX","94ad065c":"y = X.pop(\"Survived\")","4a24ee3c":"train_data_corr = train_data.select_dtypes(include=['uint8', 'int64', 'float64']).corr()\nnp.round(train_data_corr, 2)","16340111":"X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)","7dddc1f0":"#from sklearn.ensemble import RandomForestClassifier\n#model = RandomForestClassifier(max_depth=2, random_state=0)\n#model.fit(X_train, y_train)","9a6dd1ba":"model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=5000, learning_rate=0.001, subsample=0.8, colsample_bytree=0.5)\nmodel.fit(X_train, y_train, verbose=False, early_stopping_rounds=10, eval_metric='logloss', eval_set=[(X_train, y_train),(X_test, y_test)])\n#model = LogisticRegression(max_iter=2000)\n#model.fit(X_train, y_train)","2e530b4c":"score_train = model.score(X_train, y_train)\nscore_test = model.score(X_test, y_test)\nprint(score_train, score_test)","caa23b3c":"plot_confusion_matrix(model, X_train, y_train)","cd49345d":"results = model.evals_result()\n#print(results)\nplt.plot(results['validation_0']['logloss'], label='train')\nplt.plot(results['validation_1']['logloss'], label='test')\nplt.legend()\nplt.show()","dfe9aa66":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","97e60bc1":"test_data.head()","4011c0ea":"test_data.info()","d7dc6afb":"test_data = pd.get_dummies(test_data, columns=['Pclass'], prefix='P')\ntest_data = pd.get_dummies(test_data, columns=['Sex'], prefix='S')\ntest_data = pd.get_dummies(test_data, columns=['Embarked'], prefix='E')","e61a5160":"test_data['Age'] = imputer.fit_transform(test_data[['Age']])","ee436225":"test_data[['Age']] = scaler.fit_transform(test_data[['Age']])\ntest_data[['Fare']] = scaler.fit_transform(test_data[['Fare']])","febf1ee9":"X_test = test_data.drop(columns = features_to_drop)","64129c13":"X_test","8cf0be34":"predictions = model.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('xg_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\noutput.head()","105a8a12":"## Feature Engineering","15050a0c":"# Train Data Cleaning","06d677d3":"## Train the Model"}}