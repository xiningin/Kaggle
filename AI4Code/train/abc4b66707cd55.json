{"cell_type":{"efeb898c":"code","7f3ff454":"code","203ba1fd":"code","3476f27b":"code","a986dad3":"code","0d5e9f81":"code","698775aa":"code","df126159":"code","19ff9776":"code","9d9f025b":"code","221f9a9b":"markdown","2c2a2af0":"markdown"},"source":{"efeb898c":"# SOURCE: https:\/\/www.kaggle.com\/rabaman\/0-64-in-100-lines","7f3ff454":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom kaggle.competitions import twosigmanews\nimport datetime\nimport time\n\nenv = twosigmanews.make_env()","203ba1fd":"def prepare_market_data(market_df):\n    market_df['ratio'] = market_df['close'] \/ market_df['open']\n    market_df['average'] = (market_df['close'] + market_df['open'])\/2\n    market_df['pricevolume'] = market_df['volume'] * market_df['close']\n\n    market_df.drop(['assetName', 'volume'], axis=1, inplace=True)\n\n    return market_df","3476f27b":"def prepare_news_data(news_df):\n    news_df['position'] = news_df['firstMentionSentence'] \/ news_df['sentenceCount']\n    news_df['coverage'] = news_df['sentimentWordCount'] \/ news_df['wordCount']\n\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence',\n                'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass',\n                'assetName', 'urgency','wordCount','sentimentWordCount']\n    news_df.drop(droplist, axis=1, inplace=True)\n\n    # create a mapping between 'assetCode' to 'news_index'\n    assets = []\n    indices = []\n    for i, values in news_df['assetCodes'].iteritems():\n        assetCodes = eval(values)\n        assets.extend(assetCodes)\n        indices.extend([i]*len(assetCodes))\n    mapping_df = pd.DataFrame({'news_index': indices, 'assetCode': assets})\n    del assets, indices\n    \n    # join 'news_train_df' and 'mapping_df' (effectivly duplicating news entries)\n    news_df['news_index'] = news_df.index.copy()\n    expanded_news_df = mapping_df.merge(news_df, how='left', on='news_index')\n    del mapping_df, news_df\n    \n    expanded_news_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return expanded_news_df.groupby(['time', 'assetCode']).mean().reset_index()","a986dad3":"def prepare_data(market_df, news_df, start=None):\n    market_df['time'] = market_df['time'].dt.date\n    news_df['time'] = news_df['time'].dt.date\n    if start is not None:\n        market_df = market_df[market_df['time'] >= start].reset_index(drop=True)\n        news_df = news_df[news_df['time'] >= start].reset_index(drop=True)\n\n    market_df = prepare_market_data(market_df)\n    news_df = prepare_news_data(news_df)\n\n    # join news_df to market_df using ['assetCode', 'time']\n    return market_df.merge(news_df, how='left', on=['assetCode', 'time']).fillna(0)","0d5e9f81":"(market_df, news_df) = env.get_training_data()\n\n# # TODO: remove this\n# market_df = market_df.tail(1_000_000)\n# news_df = news_df.tail(3_000_000)\n\nprint('preparing data...')\nstart = datetime.date(2009,1,1)\nmerged_df = prepare_data(market_df, news_df, start)\nprint('Ready!')","698775aa":"train_columns = [x for x in merged_df.columns if x not in ['assetCode', 'time', 'returnsOpenNextMktres10']]\nX = merged_df[train_columns].values\ny = (merged_df.returnsOpenNextMktres10 >= 0).astype(int).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=99)","df126159":"import lightgbm as lgb\nimport random\nfrom sklearn.metrics import mean_squared_error\n\nt = time.time()\nprint ('Tune hyperparameters for lightgbm')\n\ntrain_set, val_set = lgb.Dataset(X_train, y_train), lgb.Dataset(X_test, y_test)\n\n# best_params = None\n# best_loss = 100\n# for _ in range(25):\n#     # generate params\n#     params = {\"objective\" : \"binary\",\n#           \"metric\" : \"binary_logloss\",\n#           \"num_leaves\" : random.choice([10, 25, 60, 75, 100]),\n#           \"max_depth\": -1,\n#           \"learning_rate\" : random.choice([0.1, 0.01, 0.08, 0.05, 0.001, 0.003]),\n#           \"bagging_fraction\" : random.choice([0.7, 0.8, 0.9, 0.95]),  # subsample\n#           \"feature_fraction\" : random.choice([0.7, 0.8, 0.9, 0.95]),  # colsample_bytree\n#           \"bagging_freq\" : 5,        # subsample_freq\n#           \"bagging_seed\" : 2018,\n#           \"verbosity\" : -1 }\n    \n#     lgbm_model = lgb.train(params, train_set, 2000, valid_sets=[train_set, val_set], early_stopping_rounds=100, verbose_eval=False)\n#     loss = mean_squared_error(lgbm_model.predict(X_test, num_iteration=lgbm_model.best_iteration), y_test.astype(float))\n\n#     if loss < best_loss:\n#         best_params = params\n#         best_loss = loss\n\nbest_params = {\n    'objective': 'binary', \n    'metric': 'binary_logloss', \n    'num_leaves': 75, \n    'max_depth': -1, \n    'learning_rate': 0.05, \n    'bagging_fraction': 0.9, \n    'feature_fraction': 0.9, \n    'bagging_freq': 5, \n    'bagging_seed': 2018, \n    'verbosity': -1\n}\n\nprint(f'Train again with the best params: {best_params}s')\nlgbm_model = lgb.train(best_params, train_set, 2000, valid_sets=[train_set, val_set], early_stopping_rounds=100, verbose_eval=2000)\n\nprint(f'Done, time = {time.time() - t}s')","19ff9776":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfeat_importance = pd.DataFrame()\nfeat_importance[\"feature\"] = train_columns\nfeat_importance[\"gain\"] = lgbm_model.feature_importance(importance_type='gain')\nfeat_importance.sort_values(by='gain', ascending=False, inplace=True)\nplt.figure(figsize=(8,10))\nax = sns.barplot(y=\"feature\", x=\"gain\", data=feat_importance)","9d9f025b":"print(\"generating predictions...\")\n\nfor market_df, news_df, pred_template_df in env.get_prediction_days():\n    test_df = prepare_data(market_df, news_df, start)\n    test_columns = [x for x in test_df.columns if x not in ['assetCode', 'time', 'returnsOpenNextMktres10']]\n    X_test = test_df[test_columns].values\n    preds = lgbm_model.predict(X_test, num_iteration=lgbm_model.best_iteration) * 2 - 1\n    preds_df = pd.DataFrame({'assetCode':test_df['assetCode'],'confidenceValue':preds})\n    env.predict(preds_df)\nenv.write_submission_file()","221f9a9b":"## Predict","2c2a2af0":"## LightGBM"}}