{"cell_type":{"4ae89217":"code","67d3b4aa":"code","e4ef9969":"code","0dbc7bbb":"code","554cca85":"code","a3fe1828":"code","850e547d":"code","ff131d41":"code","4810235d":"code","9892d6ad":"code","5e100a4d":"code","3a54fc00":"code","e69f27e0":"code","885305be":"code","f31a6325":"code","c69069de":"code","74cffc1f":"code","09a16413":"code","f39bfe4f":"code","dfda8006":"markdown","e53982c6":"markdown"},"source":{"4ae89217":"import os\nimport scipy.io\nimport scipy.misc\nimport numpy as np\nfrom numpy import expand_dims\nimport pandas as pd\nimport PIL\nimport struct\nimport cv2\nfrom numpy import expand_dims\nimport ast\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom matplotlib.patches import Rectangle\nfrom skimage.transform import resize \nimport matplotlib\n","67d3b4aa":"path = '\/kaggle\/input\/siim-covid19-detection\/'\nos.listdir(path)","e4ef9969":"train_image = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_image_level.csv\")\ntrain_study = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_study_level.csv\")\nsamp_submi = pd.read_csv(path+'sample_submission.csv')","0dbc7bbb":"train_image.head(10)","554cca85":"train_image.tail(10)","a3fe1828":"train_study.head(10)","850e547d":"train_study.tail(10)","ff131d41":"print('Number train images samples:', len(train_image))\nprint('Number train study samples:', len(train_study))","4810235d":"import pydicom as dicom\n# Define image path of the example\npath_train = path+'train\/'+train_image.loc[0, 'StudyInstanceUID']+'\/'+'81456c9c5423'+'\/'\n# Extract image name of the example\nimg_id = train_image.loc[0, 'id'].replace('_image', '.dcm')\n# Load dicom file\ndata_file = dicom.dcmread(path_train+img_id)\n# Extract image data of the dicom file\nimg = data_file.pixel_array","9892d6ad":"print(data_file)","5e100a4d":"print('Image shape:', img.shape)","3a54fc00":"boxes = ast.literal_eval(train_image.loc[0, 'boxes'])\nboxes","e69f27e0":"fig, ax = plt.subplots(1, 1, figsize=(30, 4))\n\nfor box in boxes:\n    p = matplotlib.patches.Rectangle((box['x'], box['y']), box['width'], box['height'],\n                                     ec='r', fc='none', lw=2.)\n    ax.add_patch(p)\nax.imshow(img, cmap='gray')\nplt.show()","885305be":"fig, axs = plt.subplots(3, 3, figsize=(40, 40))\nfig.subplots_adjust(hspace = .1, wspace=.1)\naxs = axs.ravel()\n\nfor row in range(9):\n    study = train_image.loc[row, 'StudyInstanceUID']\n    path_in = path+'train\/'+study+'\/'\n    folder = os.listdir(path_in)\n    path_file = path_in+folder[0]\n    filename = os.listdir(path_file)[0]\n    file_id = filename.split('.')[0]\n    \n    data_file = dicom.dcmread(path_file+'\/'+file_id+'.dcm')\n    img = data_file.pixel_array\n    if (train_image.loc[row, 'boxes']!=train_image.loc[row, 'boxes']) == False:\n        boxes = ast.literal_eval(train_image.loc[row, 'boxes'])\n    \n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']), box['width'], box['height'],\n                                     ec='r', fc='none', lw=2.)\n            axs[row].add_patch(p)\n    axs[row].imshow(img, cmap='gray')\n    axs[row].set_title(train_image.loc[row, 'label'].split(' ')[0])\n    axs[row].set_xticklabels([])\n    axs[row].set_yticklabels([])","f31a6325":"label_dict = {0: 'none', 1: 'simple_opacity', 2: 'double_opacity'}","c69069de":"def split_label(s):\n    split_string = s.split(' ')\n    if len(split_string)==6 and 'none' in split_string:\n        return 0\n    elif len(split_string)==6 and 'opacity' in split_string:\n        return 1\n    else:\n        return 2","74cffc1f":"train_image['category'] = train_image['label'].apply(split_label)","09a16413":"train_image.head(20)","f39bfe4f":"train_image.tail(20)","dfda8006":"load data ","e53982c6":"add to path"}}