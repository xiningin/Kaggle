{"cell_type":{"059ee3d6":"code","d6b66da9":"code","ceed3d56":"code","7a0a18af":"code","b19e0831":"code","b42e6d22":"code","87cc36c8":"code","4c019da6":"code","9260819f":"code","0249bb81":"code","8fc3bc7a":"code","0dd1c525":"code","6cacb70b":"code","41fdc05f":"code","539c83c4":"markdown","65c35a85":"markdown","3bf1b2f4":"markdown","3f06e65d":"markdown","914ca039":"markdown"},"source":{"059ee3d6":"!pip install pennylane","d6b66da9":"import pandas as pd\nimport numpy as np\nimport copy\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\n#Torch for Classical NN\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n#PennyLane for QNN\nimport pennylane as qml\nfrom pennylane.optimize import AdamOptimizer","ceed3d56":"# load IRIS dataset\ndataset = pd.read_csv('..\/input\/iris\/Iris.csv')\n\n\n# transform species to numerics\ndataset.loc[dataset.Species=='Iris-setosa', 'Species'] = 0\ndataset.loc[dataset.Species=='Iris-versicolor', 'Species'] = 1\ndataset.loc[dataset.Species=='Iris-virginica', 'Species'] = 2\ndataset = dataset.query('Species==0 or Species==1')\n\n\n#scale the data to be between -1 and 1 - scaling to between 0 and pi will yield better results, but sticking to the PoQNN paper here\nx = dataset[dataset.columns[1:5]].values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\nx_scaled = min_max_scaler.fit_transform(x)\nx_dataframe_scaled = pd.DataFrame(x_scaled,columns=dataset.columns[1:5])\n\n\n\n#train_X, validation_X, train_Y, validation_Y = train_test_split(x_dataframe_scaled.values,\n#                                                    dataset.Species.values, test_size=0.5)\n\ntrain_X = x_dataframe_scaled.values\ntrain_Y = dataset.Species.values","7a0a18af":"#Define pre-parameters\nnum_epochs = 100\nloss_curve_x = np.array(range(num_epochs))","b19e0831":"def classical_iris_train(train_X,train_Y,validation_X=None,validation_Y=None): \n    \n    from torch.autograd import Variable\n    \n    class Net(nn.Module):\n        # define nn\n        def __init__(self):\n            super(Net, self).__init__()\n            self.fc1 = nn.Linear(4,2,bias=False)\n            nn.init.uniform_(self.fc1.weight,-1.,1)\n            \n        def forward(self, X):\n            X = self.fc1(X)\n            return X\n        \n   \n\n        \n    # wrap up with Variable in pytorch\n    train_X = Variable(torch.Tensor(train_X).float())\n    validation_X = Variable(torch.Tensor(validation_X).float())\n    train_Y = Variable(torch.Tensor(np.float64(train_Y)).long())\n    validation_Y = Variable(torch.Tensor(np.float64(validation_Y)).long())\n    \n    \n    \n    net = Net()\n    \n    criterion = nn.CrossEntropyLoss()# cross entropy loss\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n    \n    cnn_training_loss = np.array([])\n    cnn_validation_loss = np.array([])\n    \n    for epoch in range(num_epochs):\n        optimizer.zero_grad()\n        \n        out = net(train_X)\n        loss = criterion(out,train_Y)\n        loss.backward()\n        optimizer.step()\n        cnn_training_loss = np.append(cnn_training_loss,loss.item())\n        \n        #validation loss\n        with torch.no_grad():\n            validation_out = net(validation_X)\n            validation_loss = criterion(validation_out,validation_Y)\n            cnn_validation_loss = np.append(cnn_validation_loss,validation_loss.item())\n        \n    \n    \n    return cnn_training_loss,cnn_validation_loss","b42e6d22":"\n#----------------------------------------QUANTUM NN-------------------------------------------------\n\ndef quantum_models_iris_train(train_X,train_Y,validation_X=None,validation_Y=None,depth=2,variation=\"RYRY\"):\n    from pennylane import numpy as  np\n    \n    train_X = np.array(train_X,requires_grad=False)\n    train_Y = np.array(train_Y,requires_grad=False)\n\n    train_data = list(zip(train_X,train_Y))\n    dev = qml.device(\"default.qubit\", wires=5) \n\n    \n    #QUANTUM NEURAL NETWORK\n    @qml.qnode(dev, diff_method='backprop')\n    def quantum_neural_network(x, w,depth=depth):\n        \n        #encoding circuit============================================================\n\n        #Hadamards\n        for i in range(4):\n            qml.Hadamard(wires=i)\n\n        #Accounting for depth=0\n        if(depth==0):\n            for i in range(4):\n                qml.RZ(x[i],wires=i)\n\n        #Multiple encoding layers:\n        for k in range(depth):\n            #RZ gates\n            for i in range(4):\n                qml.RZ(x[i],wires=i)\n            #RZZ gates\n            for i in range(4):\n                for j in range(i):\n                    qml.CNOT(wires=[j,i])\n                    qml.RZ(((x[i])*(x[j])),wires=[i])\n                    qml.CNOT(wires=[j,i])\n                \n        \n        #variational circuit =======================================================\n        for i in range(4):\n            qml.RY(w[0][i],wires=i)\n            \n        qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\n        \n        for i in range(4):\n            if variation==\"RYRY\":qml.RY(w[1][i],wires=i)\n            elif variation==\"RYRX\":qml.RX(w[1][i],wires=i)\n                \n                \n        dev.shots = 10000\n        \n        for i in range(4):\n          qml.CNOT(wires=[i,4])\n\n        return qml.expval(qml.PauliZ(wires=4))\n    \n    def get_parity_prediction(x,w):\n        \n        np_measurements = (quantum_neural_network(x,w)+1.)\/2.\n        \n        return np.array([1.-np_measurements,np_measurements])\n    \n    def average_loss(w, data):\n        cost_value = 0\n        for i,(x, y) in enumerate(data):\n           \n            cost_value += single_loss(w,x,y)\n\n        return cost_value\/len(data)\n\n    def single_loss(w,x,y):\n        prediction = get_parity_prediction(x,w)\n        #print(prediction[int(y)])\n        return rel_ent(prediction, y)\n    \n    def rel_ent(pred,y):\n        return -1.*np.log(pred)[int(y)]\n    \n\n    \n    #initialise weights\n    w = np.array(np.split(np.random.uniform(size=(8,),low=-1,high=1),2),requires_grad=True)\n    learning_rate=0.1\n    train_losses = np.array([])\n     #Optimiser\n    optimiser = AdamOptimizer(learning_rate)\n    for i in range(num_epochs):\n      w, train_loss_value = optimiser.step_and_cost(lambda v: average_loss(v, train_data), w)        \n      if i%5==0:\n          print(\"Epoch = \",i, \" Training Loss = \",train_loss_value)\n      train_losses = np.append(train_losses,train_loss_value)\n      \n    \n    return train_losses","87cc36c8":"def quantum_models_iris_train(train_X,train_Y,validation_X=None,validation_Y=None,depth=2,variation=\"RYRY\"):\n    from pennylane import numpy as  np\n    \n    train_X = np.array(train_X,requires_grad=False)\n    train_Y = np.array(train_Y,requires_grad=False)\n    \n\n    train_data = list(zip(train_X,train_Y))\n    dev = qml.device(\"default.qubit\", wires=3) \n\n    \n    #QUANTUM NEURAL NETWORK\n    @qml.qnode(dev, diff_method='backprop')\n    def quantum_neural_network(x, w,depth=depth):\n        \n        qml.Hadamard(wires=0)\n        qml.Hadamard(wires=1)\n        \n        \n        #  FIRST LAYER\n        qml.RZ(w[0][0],wires=0)\n        qml.RZ(w[0][1],wires=1)\n            \n        qml.RX(w[1][0],wires=0)\n        qml.RX(w[1][1],wires=1) \n        \n        qml.RZ(x[0],wires=0)\n        qml.RZ(x[1],wires=1)\n            \n        qml.RX(x[2],wires=0)\n        qml.RX(x[3],wires=1)\n        \n        #  SECOND LAYER\n        qml.RZ(w[2][0],wires=0)\n        qml.RZ(w[2][1],wires=1)\n            \n        qml.RX(w[3][0],wires=0)\n        qml.RX(w[3][1],wires=1) \n        \n                \n        dev.shots = 10000\n        \n        for i in range(2):\n          qml.CNOT(wires=[i,2])\n\n        return qml.expval(qml.PauliZ(wires=2))\n    \n    def get_parity_prediction(x,w):\n        \n        np_measurements = (quantum_neural_network(x,w)+1.)\/2.\n        \n        return np.array([1.-np_measurements,np_measurements])\n    \n    def average_loss(w, data):\n        cost_value = 0\n        for i,(x, y) in enumerate(data):\n           \n            cost_value += single_loss(w,x,y)\n\n        return cost_value\/len(data)\n\n    def single_loss(w,x,y):\n        prediction = get_parity_prediction(x,w)\n        #print(prediction[int(y)])\n        return rel_ent(prediction, y)\n    \n    def rel_ent(pred,y):\n        return -1.*np.log(pred)[int(y)]\n    \n\n    \n    #initialise weights\n    w = np.array(np.split(np.arccos(np.random.uniform(size=(8,),low=-1,high=1)),4),requires_grad=True)\n    learning_rate=0.1\n    train_losses = np.array([])\n     #Optimiser\n    optimiser = AdamOptimizer(learning_rate)\n    for i in range(num_epochs):\n      \n      w, train_loss_value = optimiser.step_and_cost(lambda v: average_loss(v, train_data), w)        \n      if i%5==0:\n          print(\"Epoch = \",i, \" Training Loss = \",train_loss_value)\n      train_losses = np.append(train_losses,train_loss_value)\n      \n    \n    return train_losses","4c019da6":"#Run the results here: \nn_iteration = 5\ndepths = [0]\nvariations = ['RYRX']\nqnn_loss= np.zeros((len(depths),2,n_iteration,2,num_epochs))\n\nfor depth in depths:\n    for i in range(n_iteration):\n        for j,variation in enumerate(variations):\n            print(\"depth= \",depth, \" iteration= \", i, \" variation=\",variation)\n            qnn_loss[depth][j][i] = quantum_models_iris_train(train_X,train_Y,depth=depth,variation=variation)\n            #depending on which quantum nn cell was run most recently, this could give results for the 2 qubit and 4 qubit setting","9260819f":"from pennylane import numpy as  np\n\ntrain_X = np.array(train_X,requires_grad=False)\ntrain_Y = np.array(train_Y,requires_grad=False)\n\ntrain_data = list(zip(train_X,train_Y))\ndev = qml.device(\"default.qubit\", wires=5) \n\n\n#QUANTUM NEURAL NETWORK\n@qml.qnode(dev, diff_method='backprop')\ndef quantum_neural_network(x, w,depth=0):\n\n    #encoding circuit============================================================\n\n    #Hadamards\n    for i in range(4):\n        qml.Hadamard(wires=i)\n\n    #Accounting for depth=0\n    if(depth==0):\n        for i in range(4):\n            qml.RZ(x[i],wires=i)\n\n    #Multiple encoding layers:\n    for k in range(depth):\n        #RZ gates\n        for i in range(4):\n            qml.RZ(x[i],wires=i)\n        #RZZ gates\n        for i in range(4):\n            for j in range(i):\n                qml.CNOT(wires=[j,i])\n                qml.RZ(((x[i])*(x[j])),wires=[i])\n                qml.CNOT(wires=[j,i])\n\n\n    #variational circuit =======================================================\n    for i in range(4):\n        qml.RY(w[0][i],wires=i)\n\n    qml.broadcast(qml.CNOT, wires=[0,1,2,3], pattern=\"all_to_all\", parameters=None, kwargs=None)\n\n    for i in range(4):\n        qml.RX(w[1][i],wires=i)\n\n\n    dev.shots = 10000\n\n    for i in range(4):\n      qml.CNOT(wires=[i,4])\n\n    return qml.expval(qml.PauliZ(wires=4))\n\ndef get_parity_prediction(x,w):\n\n    np_measurements = (quantum_neural_network(x,w)+1.)\/2.\n\n    return np.array([1.-np_measurements,np_measurements])\n\ndef average_loss(w, data):\n    cost_value = 0\n    for i,(x, y) in enumerate(data):\n\n        cost_value += single_loss(w,x,y)\n\n    return cost_value\/len(data)\n\ndef single_loss(w,x,y):\n    prediction = get_parity_prediction(x,w)\n    #print(prediction[int(y)])\n    return rel_ent(prediction, y)\n\ndef rel_ent(pred,y):\n    return -1.*np.log(pred)[int(y)]\n\n#initialise weights\nw = np.array(np.split(np.random.uniform(size=(8,),low=-1,high=1),2),requires_grad=True)\nlearning_rate=0.1\ntrain_losses = np.array([])\n#Optimiser\nn = 100\noptimiser = AdamOptimizer(learning_rate)     \nmetric = qml.metric_tensor(quantum_neural_network)\nmatrix = np.zeros((n,8,8))q\nfisher = np.zeros((n,8,8))\nEVs_mat = np.zeros((8))\nEVs_fish = np.zeros((8))\nlosses = np.zeros((n,1))\nfor j in range(n):\n    print(j)\n    w = np.array(np.split(np.random.uniform(size=(8,),low=-1,high=1),2),requires_grad=True)\n    for i,(x,y) in enumerate(list(zip(train_X,train_Y))):\n        matrix[j] += metric(x,w)\n        grad_fn = qml.grad(single_loss,argnum=0)\n        gradient = grad_fn(w,x,y).flatten()\n        fisher[j] += np.outer(gradient,gradient)\n        losses[j] += single_loss(w,x,y)\n    \n    losses[j] = losses[j]\/len(train_X)\n    fisher[j] = fisher[j]\/len(train_X)\n    matrix[j] = matrix[j]\/len(train_X)\n    EVs_mat = np.append(np.linalg.eig(matrix)[0],EVs_mat)\n    EVs_fish = np.append(np.linalg.eig(fisher)[0],EVs_fish)\n\n\n#for i in range(num_epochs):\n#  w, train_loss_value = optimiser.step_and_cost(lambda v: average_loss(v, train_data), w)        \n#  if i%5==0:\n#      print(\"Epoch = \",i, \" Training Loss = \",train_loss_value)\n#  train_losses = np.append(train_losses,train_loss_value)","0249bb81":"EVs = EVs_mat\nx, bins, p=plt.hist(EVs, bins=10,rwidth=0.6,color='black')\nfor item in p:\n  item.set_height(item.get_height()\/len(EVs)) # normalise it\nplt.ylim(0,1)\nplt.show()","8fc3bc7a":"EVs = EVs_fish\nx, bins, p=plt.hist(EVs, bins=10,rwidth=0.6,color='black')\nfor item in p:\n  item.set_height(item.get_height()\/len(EVs)) # normalise it\nplt.ylim(0,1)\nplt.show()","0dd1c525":"norms = np.zeros(n)\nfor i in range(n):\n  norms[i] = np.linalg.norm(fisher[i]-matrix[i],ord='fro').item()\nplt.plot(losses,norms,'ro')\nplt.title(\"Fubini-Study metric & our Fisher - Frobenius Norm\")\nplt.xlabel('loss value')\nplt.ylabel('Norm of F-C')\nplt.yscale(\"log\")\nplt.xscale(\"log\")\nplt.show()","6cacb70b":"#Trace ratios\ntrace_ratios = np.zeros((n))\n\nfor i in range(n):\n  trace_ratios[i]= (np.trace(fisher[i])\/np.trace(matrix[i]))\n\nplt.plot(losses,trace_ratios,'ro')\nplt.title(\"Fubini-Study metric & our Fisher - Trace Ratios\")\nplt.xlabel('loss value')\nplt.ylabel('Tr(ours)\/Tr(FS)')\n\nplt.show()","41fdc05f":"def natural_gradient(params):\n    \n    # QHACK #\n    dev = qml.device(\"default.qubit\", wires=3)\n    qml.enable_tape()\n    #|psi>\n    @qml.qnode(dev)\n    def quantum_circuit(params):\n        variational_circuit(params)\n        return qml.state()\n    \n    #<psi|pauliX|psi> (1)\n    @qml.qnode(dev)\n    def quantum_circuit_val(params):\n        variational_circuit(params)\n        return qml.expval(qml.PauliZ(1))\n    \n    \n    @qml.qnode(dev)\n    def quantum_circuit_shifted(target_state,params_shifted):\n      variational_circuit(params_shifted)\n      return qml.expval(qml.Hermitian(np.outer(target_state, target_state.conj()), wires=[0, 1,2]))\n    \n    target_state = quantum_circuit(params)\n    \n    def F_ij(i,j,params,target_state):\n      sum = 0\n      for m in [-1,1]:\n          for n in [-1,1]:\n              params_shifted = params.copy()\n              params_shifted[i] += m*np.pi\/2\n              params_shifted[j] += n*np.pi\/2\n              sum = sum - 1\/8*((m*n)*((quantum_circuit_shifted(target_state,params_shifted))))\n      return sum\n    \n    def get_grad(circ,w,s,i):\n      shifted = w.copy()\n      shifted[i] += s\n      plus_s = circ(shifted)\n      shifted[i] -= 2*s\n      minus_s = circ(shifted)\n      return (plus_s - minus_s)\/2.\n              \n    F = np.zeros((6,6))\n    grad = np.zeros((6,))\n    for i in range(6):\n      grad[i] = get_grad(quantum_circuit_val,params,np.pi\/2,i)\n      for j in range(i,6):\n        F[i][j] = F_ij(i,j,params,target_state)\n        F[j][i] = F[i][j]\n\n    return F","539c83c4":"# IRIS\nNeed to import the Iris dataset and scale it accordingly","65c35a85":"# The Fubini-Study Metric","3bf1b2f4":"# Linear Classical Network ","3f06e65d":"# Quantum Neural Network (IQP enabled with 4 encoding qubits + 1 Ancilla + 8 trainable parameters)","914ca039":"# Quantum Neural Network (2 encoding qubits + 1 Ancilla + 8 trainable parameters)"}}