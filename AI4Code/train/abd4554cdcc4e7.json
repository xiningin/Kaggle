{"cell_type":{"80970884":"code","bbee38a6":"code","4e4b3a72":"code","7ab93051":"code","076e1b0a":"code","6334be36":"code","bdcfb41e":"code","794aab3d":"code","dd7dd144":"code","1876541c":"code","9fc5ee20":"code","74d7c1b2":"code","814a8d4f":"code","85c7886b":"code","40f25573":"code","90db6653":"code","00ff73bc":"markdown","b8807a55":"markdown","c20e5472":"markdown","1825786f":"markdown","88f38f97":"markdown","a8e50bd4":"markdown","0cdd0d95":"markdown","886ff9f6":"markdown","731b3fff":"markdown","28563835":"markdown","da256f70":"markdown"},"source":{"80970884":"!pip install vaderSentiment\nfrom pprint import pprint\nimport os\nimport sys\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom matplotlib.pyplot import figure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport os\nfrom IPython.core.display import display, HTML\nimport matplotlib.pyplot as plt\nimport numpy as np","bbee38a6":"# configuration\n!wget https:\/\/dl.fbaipublicfiles.com\/fasttext\/supervised-models\/lid.176.ftz\ndatadir = '\/kaggle\/input\/CORD-19-research-challenge'\n# datadir = 'kaggle\/input\/CORD-19-research-challenge' # for local test\nmetadata = 'metadata.csv'\nsubsetdata = ['biorxiv_medrxiv', 'comm_use_subset', 'noncomm_use_subset', 'custom_license']\ncovid19_dataset_path = 'covid19_datasets'","4e4b3a72":"# Useful functions and constants from\n# https:\/\/www.kaggle.com\/ajrwhite\/covid-19-thematic-tagging-with-regular-expressions\/notebook\n# Fix DOI links\ndef doi_url(d):\n    if d.startswith('http'):\n        return d\n    elif d.startswith('doi.org'):\n        return f'http:\/\/{d}'\n    else:\n        return f'http:\/\/doi.org\/{d}'\n    \n# Turn authors list into '<surname>' or '<surname> et al'\ndef shorten_authors(authors):\n    if isinstance(authors, str):\n        authors = authors.split(';')\n        if len(authors) == 1:\n            return authors[0].split(',')[0]\n        else:\n            return f'{authors[0].split(\",\")[0]} et al'\n    else:\n        return authors\n\ndef load_metadata(metadata_file):\n    df = pd.read_csv(metadata_file,\n                 dtype={'Microsoft Academic Paper ID': str,\n                        'pubmed_id': str},\n                 low_memory=False)\n    df.doi = df.doi.fillna('').apply(doi_url)\n    df['authors_short'] = df.authors.apply(shorten_authors)\n    df['sorting_date'] = pd.to_datetime(df.publish_time)\n    print(f'loaded DataFrame with {len(df)} records')\n    return df.sort_values('sorting_date', ascending=False)\n\ndef abstract_title_filter(df, search_string):\n    return (df.abstract.str.lower().str.replace('-', ' ')\n            .str.contains(search_string, na=False) |\n            df.title.str.lower().str.replace('-', ' ')\n            .str.contains(search_string, na=False))\n\n# Helper function which counts synonyms and adds tag column to DF\ndef count_and_tag(df: pd.DataFrame,\n                  synonym_list: list,\n                  tag_suffix: str) -> (pd.DataFrame, pd.Series):\n    counts = {}\n    df[f'tag_{tag_suffix}'] = False\n    for s in synonym_list:\n        synonym_filter = abstract_title_filter(df, s)\n        counts[s] = sum(synonym_filter)\n        df.loc[synonym_filter, f'tag_{tag_suffix}'] = True\n    print(f'Added tag_{tag_suffix} to DataFrame')\n    return df, pd.Series(counts)\n\n# Function for printing out key passage of abstract based on key terms\ndef print_key_phrases(df, key_terms, n=5, chars=300):\n    for ind, item in enumerate(df[:n].itertuples()):\n        print(f'{ind+1} of {len(df)}')\n        print(item.title)\n        print('[ ' + item.doi + ' ]')\n        try:\n            i = len(item.abstract)\n            for kt in key_terms:\n                kt = kt.replace(r'\\b', '')\n                term_loc = item.abstract.lower().find(kt)\n                if term_loc != -1:\n                    i = min(i, term_loc)\n            if i < len(item.abstract):\n                print('    \"' + item.abstract[i-30:i+chars-30] + '\"')\n            else:\n                print('    \"' + item.abstract[:chars] + '\"')\n        except:\n            print('NO ABSTRACT')\n        print('---')\n        \ndef add_tag_covid19(df):\n    # Customised approach to include more complicated logic\n    df, covid19_counts = count_and_tag(df, COVID19_SYNONYMS, 'disease_covid19')\n    novel_corona_filter = (abstract_title_filter(df, 'novel corona') &\n                           df.publish_time.str.startswith('2020', na=False))\n    df.loc[novel_corona_filter, 'tag_disease_covid19'] = True\n    covid19_counts = covid19_counts.append(pd.Series(index=['novel corona'],\n                                                     data=[novel_corona_filter.sum()]))\n    return df, covid19_counts\n\n\ndef load_full_text(df, data_folder):\n    json_list = []\n    # Adding code to handle PDF vs. XML parse\n    for row in df[df.has_pdf_parse].itertuples():\n        filename = f'{row.sha}.json'\n        sources = ['biorxiv_medrxiv', 'comm_use_subset',\n                   'custom_license', 'noncomm_use_subset']\n        for source in sources:\n            if filename in os.listdir(os.path.join(data_folder, source, source, 'pdf_json')):\n                with open(os.path.join(data_folder, source, source, 'pdf_json', filename), 'rb') as f:\n                    json_list.append(json.load(f))\n    for row in df[df.has_pmc_xml_parse].itertuples():\n        filename = f'{row.sha}.json'\n        sources = ['comm_use_subset',\n                   'custom_license', 'noncomm_use_subset']\n        for source in sources:\n            if filename in os.listdir(os.path.join(data_folder, source, source, 'pmc_json')):\n                with open(os.path.join(data_folder, source, source, 'pmc_json', filename), 'rb') as f:\n                    json_list.append(json.load(f))\n    print(f'Found {len(json_list)} full texts for {len(df)} records')\n    return json_list\n\n\ndef display_dataframe(df, title):\n    text = f'<h2>{title}<\/h2><table><tr>'\n    text += ''.join([f'<td><b>{col}<\/b><\/td>' for col in df.columns.values]) + '<\/tr>'\n    for row in df.itertuples():\n        text +=  '<tr>' + ''.join([f'<td valign=\"top\">{v}<\/td>' for v in row[1:]]) + '<\/tr>'\n    text += '<\/table>'\n    display(HTML(text))\n    \n\n# CONSTANTS\n\nCOVID19_SYNONYMS = [\n                    'covid',\n                    'coronavirus disease 19',\n                    'sars cov 2', # Note that search function replaces '-' with ' '\n                    '2019 ncov',\n                    '2019ncov',\n                    r'2019 n cov\\b',\n                    r'2019n cov\\b',\n                    'ncov 2019',\n                    r'\\bn cov 2019',\n                    'coronavirus 2019',\n                    'wuhan pneumonia',\n                    'wuhan virus',\n                    'wuhan coronavirus',\n                    r'coronavirus 2\\b'\n]\n\nAGE_SYNONYMS = ['median age',\n                'mean age',\n                'average age',\n                'elderly',\n                r'\\baged\\b',\n                r'\\bold',\n                'young',\n                'teenager',\n                'adult',\n                'child'\n               ]\n\nSEX_SYNONYMS = ['sex',\n                'gender',\n                r'\\bmale\\b',\n                r'\\bfemale\\b',\n                r'\\bmales\\b',\n                r'\\bfemales\\b',\n                r'\\bmen\\b',\n                r'\\bwomen\\b'\n               ]\n\nBODYWEIGHT_SYNONYMS = [\n    'overweight',\n    'over weight',\n    'obese',\n    'obesity',\n    'bodyweight',\n    'body weight',\n    r'\\bbmi\\b',\n    'body mass',\n    'body fat',\n    'bodyfat',\n    'kilograms',\n    r'\\bkg\\b', # e.g. 70 kg\n    r'\\dkg\\b'  # e.g. 70kg\n]\n\nSMOKING_SYNONYMS = ['smoking',\n                    'smoke',\n                    'cigar', # this picks up cigar, cigarette, e-cigarette, etc.\n                    'nicotine',\n                    'cannabis',\n                    'marijuana']\n\nDIABETES_SYNONYMS = [\n    'diabet', # picks up diabetes, diabetic, etc.\n    'insulin', # any paper mentioning insulin likely to be relevant\n    'blood sugar',\n    'blood glucose',\n    'ketoacidosis',\n    'hyperglycemi', # picks up hyperglycemia and hyperglycemic\n]\n\nHYPERTENSION_SYNONYMS = [\n    'hypertension',\n    'blood pressure',\n    r'\\bhbp\\b', # HBP = high blood pressure\n    r'\\bhtn\\b' # HTN = hypertension\n]\n\nIMMUNODEFICIENCY_SYNONYMS = [\n    'immune deficiency',\n    'immunodeficiency',\n    r'\\bhiv\\b',\n    r'\\baids\\b'\n    'granulocyte deficiency',\n    'hypogammaglobulinemia',\n    'asplenia',\n    'dysfunction of the spleen',\n    'spleen dysfunction',\n    'complement deficiency',\n    'neutropenia',\n    'neutropaenia', # alternate spelling\n    'cell deficiency' # e.g. T cell deficiency, B cell deficiency\n]\n\nCANCER_SYNONYMS = [\n    'cancer',\n    'malignant tumour',\n    'malignant tumor',\n    'melanoma',\n    'leukemia',\n    'leukaemia',\n    'chemotherapy',\n    'radiotherapy',\n    'radiation therapy',\n    'lymphoma',\n    'sarcoma',\n    'carcinoma',\n    'blastoma',\n    'oncolog'\n]\n\nCHRONICRESP_SYNONYMS = [\n    'chronic respiratory disease',\n    'asthma',\n    'chronic obstructive pulmonary disease',\n    r'\\bcopd',\n    'chronic bronchitis',\n    'emphysema'\n]\n\nIMMUNITY_SYNONYMS = [\n    'immunity',\n    r'\\bvaccin',\n    'innoculat'\n]\n\nCLIMATE_SYNONYMS = [\n    'climate',\n    'weather',\n    'humid',\n    'sunlight',\n    'air temperature',\n    'meteorolog', # picks up meteorology, meteorological, meteorologist\n    'climatolog', # as above\n    'dry environment',\n    'damp environment',\n    'moist environment',\n    'wet environment',\n    'hot environment',\n    'cold environment',\n    'cool environment'\n]\n\nTRANSMISSION_SYNONYMS = [\n    'transmiss', # Picks up 'transmission' and 'transmissibility'\n    'transmitted',\n    'incubation',\n    'environmental stability',\n    'airborne',\n    'via contact',\n    'human to human',\n    'through droplets',\n    'through secretions',\n    r'\\broute',\n    'exportation'\n]\n\nREPR_SYNONYMS = [\n    r'reproduction \\(r\\)',\n    'reproduction rate',\n    'reproductive rate',\n    '{r}_0',\n    r'\\br0\\b',\n    r'\\br_0',\n    '{r_0}',\n    r'\\b{r}',\n    r'\\br naught',\n    r'\\br zero'\n]\n\nINCUBATION_SYNONYMS = [\n    'incubation period',\n    'period of incubation',\n    'latent period',\n    'latency period',\n    'period of latency',\n    'window period'\n]\n\nPERSISTENCE_SYNONYMS = ['persistence',\n                        # r'(?<!viral )surface[s]?\\b', # THIS DOESN'T WORK\n                        'survival surface',\n                        'persistence surface',\n                        'survival on a surface',\n                        'persistence on a surface',\n                        'carrier test',\n                        'suspension test',\n                        'fomite',\n                        # 'survival time',\n                        'environmental surface',\n                        'environmental stability',\n                        'environmental reservoirs',\n                        'environmental survival',\n                        'pathogens in the environment',\n                        'environmental pathogen',\n                        'contaminated',\n                        'contamination',\n                        'surface stability',\n                        'surface swab',\n                        'inanimate surface',\n                        'surface disinfection'\n                       ]","7ab93051":"# df = pd.read_csv(\"data\/metadata.csv\")\ndf = pd.read_csv(f'{datadir}\/{metadata}', na_filter= False)\ncorona, covid19_counts = count_and_tag(df, COVID19_SYNONYMS, 'disease_covid19')\ndf","076e1b0a":"corona_filtered = corona[corona.loc[:,\"tag_disease_covid19\"] == True]\ncorona_filtered","6334be36":"covid19_counts.sort_values(ascending=False)","bdcfb41e":"treatment_names = [\n'remdesivir',\n'kaletra',\n'actemra',\n'kevzara',\n'convalescent plasma',\n'avigan',\n'favilavir',\n'tjm2',\n'medicago',\n'at-100',\n'tzls-501',\n'oya1',\n'bpi-002',\n'ino-4800',\n'np-120',\n'ifenprodil',\n'mrna-1273',\n'brilacidin',\n'bcx4430',\n'regn3048',\n'regn3051',\n'interferon-\u03b2',\n'oseltamivir phosphate',\n'tamiflu',\n'zanamivir',\n'relenza',\n'peramivir',\n'rapivab',\n'baloxavir marboxil',\n'xofluza']","794aab3d":"treatments, treatments_counts = count_and_tag(corona_filtered, treatment_names, 'treatments_covid19')","dd7dd144":"treatments_filtered = treatments[treatments.loc[:,\"tag_treatments_covid19\"] == True]\ntreatments_filtered2 = treatments_filtered[treatments_filtered['abstract'].notna()]\n# titles = treatments_filtered.loc[:,\"title\"]\ntitles = treatments_filtered2.loc[:,\"abstract\"]","1876541c":"sid = SentimentIntensityAnalyzer()","9fc5ee20":"treatments_filtered2[\"scores\"] = treatments_filtered2[\"abstract\"].apply(lambda review: sid.polarity_scores(review))\ntreatments_filtered2[\"compound\"] = treatments_filtered2[\"scores\"].apply(lambda d:d[\"compound\"])\ntreatments_filtered2[\"comp_score\"] = treatments_filtered2[\"compound\"].apply(lambda score: 'pos' if  score >=0 else 'neg')","74d7c1b2":"treatments_filtered2","814a8d4f":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","85c7886b":"abstracts = treatments_filtered2.sort_values(\"compound\", ascending = False).loc[:,\"abstract\"]\nfor ab in abstracts:\n    found_words = []\n    for word in treatment_names:\n        if word in ab:\n            found_words.append(word)\n    print(found_words)","40f25573":"bars = treatments_filtered2.loc[:,\"comp_score\"]\npos_height = len(treatments_filtered2[treatments_filtered2.loc[:,\"comp_score\"] == \"pos\"])\nneg_height = len(treatments_filtered2[treatments_filtered2.loc[:,\"comp_score\"] == \"neg\"])\nplt.bar([\"positive\", \"negative\"], [pos_height, neg_height])\n# Add some text for labels, title and custom x-axis tick labels, etc.\nplt.ylabel('Number of papers')\nplt.yticks(np.arange(0,22, 2))\nplt.xlabel('Sentiment')\nplt.title('Sentiment of papers related to COVID-19')","90db6653":"paper_numbers = treatments_filtered2.index\nx = np.array(paper_numbers)\npaper_numbers_string = []\nfor i in x:\n    paper_numbers_string.append(str(i))\nscores = treatments_filtered2.loc[:,\"compound\"]\nfigure(figsize=(40,10))\nplt.bar(paper_numbers_string, scores)\nplt.ylabel('Compound Sentiment Score')\nplt.xlabel('Paper number')\nplt.title('compound score of papers')","00ff73bc":"![word_cloud.png](attachment:word_cloud.png)","b8807a55":"# Conclusion:\n\nThe goal of our project was to scan through research papers on potential treatments for the COVID-19 outbreak and check the viability of the treatments via sentiment analysis on the tone of the paper to conclude whether it succeeded or failed. We had a wide range of outputs across the abstracts of the research papers, going from about -0.95 to 0.95 (-1 to 0 being a negative sentiment and 0-1 being a positive sentiment). The treatments we found to have a positive sentiment were remdesivir, convalescent plasma, interferon-\u03b2, and zanamivir. In action, our program can be utilized in the process of scanning future documents in a large scale for potential treatments for this crisis. \n\n\n# Extensions: \n\nOur document-search for treatment terms and sentiment analysis was only based upon the abstracts of the lab-reports. Incorporating the full-body text as further research could uncover slightly different results and a deeper classification of whether the treatment discussed was effective or not. Another factor for further experimentation is a greater concentration of documents discussing treatments for more results. We also only used the metadata.csv in order to accomplish our task and perhaps could have included some other datasets (non_comm_use, etc.) to get more data.  ","c20e5472":"# adding popular COVID-19 treatments","1825786f":"# initializing VADER sentiment model, adding sentiment scores based on title and abstract","88f38f97":"# Motivation for the project\n\nOne of the most pressing challenges related to COVID-19 is finding effective treatments. Since the virus has began spreading, numerous papers have been published regarding different treatment options.  \n\nIn this project, we have created a sentiment model that takes in the names of popular COVID-19 treatments and returns the sentiment of different papers that are about these treatments. \n\nWe used the VADER sentiment model to test the polarity of each paper. Each paper\u2019s sentiment is scored from -1 to +1. ","a8e50bd4":"### compound score of papers","0cdd0d95":"# filtering papers specific to COVID-19","886ff9f6":"# filtering papers that mention the COVID-19 treatments","731b3fff":"# scanning the abstracts and displaying the treatments that were in the papers with the highest compound polarity score","28563835":"# covid_19 tools","da256f70":"### Number of positive\/negative papers"}}