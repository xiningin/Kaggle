{"cell_type":{"130b5a10":"code","e136c60c":"code","7a202ddf":"code","f0e5e03d":"code","7f8ea777":"code","cc0f3f6a":"code","e66d498b":"code","65e904a8":"code","9d064886":"code","8ef3132f":"code","f1005ecb":"code","9397d989":"code","7e2791ce":"code","3bb76c68":"code","a1d2e7fb":"code","9d6658c6":"code","eec37107":"code","e98644cb":"code","88b7cbb6":"code","4cbdb0d3":"code","8e075ca2":"code","03183310":"markdown","8b6d1669":"markdown","a9023d57":"markdown","e2e5a3e3":"markdown","3a55f579":"markdown","fb8e36a1":"markdown","dd107d43":"markdown","8d45567f":"markdown","57bb887a":"markdown","6e10f4dd":"markdown","5f5f1964":"markdown","349d16be":"markdown","62e30c82":"markdown"},"source":{"130b5a10":"pip install sagemaker==1.0.0","e136c60c":"%matplotlib inline\n\nimport os\nimport tarfile\nimport urllib\nimport shutil\nimport json\nimport random\nimport numpy as np\nimport tensorflow as tf\nimport sagemaker\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\nurls = ['http:\/\/www.robots.ox.ac.uk\/~vgg\/data\/pets\/data\/images.tar.gz',\n        'http:\/\/www.robots.ox.ac.uk\/~vgg\/data\/pets\/data\/annotations.tar.gz']\n\nprint('Libraries imported')","7a202ddf":"def download_and_extract(data_dir, download_dir):\n    for url in urls:\n        target_file = url.split('\/')[-1]\n        if target_file not in os.listdir(download_dir):\n            print('Downloading', url)\n            urllib.request.urlretrieve(url, os.path.join(download_dir, target_file))\n            tf = tarfile.open(url.split('\/')[-1])\n            tf.extractall(data_dir)\n        else:\n            print('Already downloaded', url)\n\ndef get_annotations(file_path, annotations={}):\n    \n    with open(file_path, 'r') as f:\n        rows = f.read().splitlines()\n\n    for i, row in enumerate(rows):\n        image_name, _, _, _ = row.split(' ')\n        class_name = image_name.split('_')[:-1]\n        class_name = '_'.join(class_name)\n        image_name = image_name + '.jpg'\n        \n        annotations[image_name] = 'cat' if class_name[0] != class_name[0].lower() else 'dog'\n    \n    return annotations","f0e5e03d":"if not os.path.isdir('data'):\n    os.mkdir('data')\n\ndownload_and_extract('data', '.')","7f8ea777":"annotations = get_annotations('data\/annotations\/trainval.txt')\nannotations = get_annotations('data\/annotations\/test.txt', annotations)\n\ntotal_count = len(annotations.keys())\nprint('Total examples', total_count)","cc0f3f6a":"next(iter(annotations.items()))","e66d498b":"classes = ['cat', 'dog']\nsets = ['train', 'validation']\nroot_dir = 'custom_data'\n\nif not os.path.isdir(root_dir):\n    os.mkdir(root_dir)\n    \nfor set_name in sets:\n    if not os.path.isdir(os.path.join(root_dir, set_name)):\n        os.mkdir(os.path.join(root_dir, set_name))\n    for class_name in classes:\n        folder = os.path.join(root_dir, set_name, class_name)\n        if not os.path.isdir(folder):\n            os.mkdir(folder)","65e904a8":"for image, class_name in annotations.items():\n    target_set = 'validation' if random.randint(0, 99) < 20 else 'train'\n    target_path = os.path.join(root_dir, target_set, class_name, image)\n    shutil.copy(os.path.join('data\/images\/', image), target_path)","9d064886":"sets_counts = {\n    'train': 0,\n    'validation': 0\n}\n\nfor set_name in sets:\n    for class_name in classes:\n        path = os.path.join(root_dir, set_name, class_name)\n        count = len(os.listdir(path))\n        print(path, 'has', count, 'images')\n        sets_counts[set_name] += count\n\nprint(sets_counts)","8ef3132f":"%%writefile train.py\n\nimport tensorflow as tf\nimport argparse\nimport os\nimport json\n\ndef create_model():\n    model = tf.keras.models.Sequential([\n        tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet',\n                                                       pooling='avg', input_shape=(128, 128, 3)),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    model.layers[0].trainable = False\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n","f1005ecb":"%%writefile -a train.py\n\ndef create_data_generators(root_dir, batch_size):\n    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n        horizontal_flip=True,\n        zoom_range=[0.8, 1.2],\n        rotation_range=20\n    ).flow_from_directory(\n        os.path.join(root_dir, 'train'),\n        target_size=(128, 128),\n        batch_size=batch_size,\n        class_mode='binary'\n    )\n    \n    val_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n    ).flow_from_directory(\n        os.path.join(root_dir, 'validation'),\n        target_size=(128, 128),\n        batch_size=batch_size,\n        class_mode='binary'\n    )\n    \n    return train_data_generator, val_data_generator\n","9397d989":"%%writefile -a train.py\n\nif __name__ =='__main__':\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--epochs', type=int, default=3)\n    parser.add_argument('--batch_size', type=int, default=16)\n    parser.add_argument('--steps', type=int, default=int(5873\/16))\n    parser.add_argument('--val_steps', type=int, default=(1476\/16))\n\n    # input data and model directories\n    parser.add_argument('--model_dir', type=str)\n    parser.add_argument('--sm-model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAINING'))\n\n    args, _ = parser.parse_known_args()\n\n    local_output_dir = args.sm_model_dir\n    local_root_dir = args.train\n    batch_size = args.batch_size\n    \n    model = create_model()\n    train_gen, val_gen = create_data_generators(local_root_dir, batch_size)\n    \n    _ = model.fit(\n        train_gen,\n        epochs=args.epochs,\n        steps_per_epoch=args.steps,\n        validation_data=val_gen,\n        validation_steps=args.val_steps\n    )\n    \n    model.save(os.path.join(local_output_dir, 'model', '1'))\n    ","7e2791ce":"sagemaker_session = sagemaker.Session()\nrole = sagemaker.get_execution_role()\nbucket_name = 'petscustom'\n\nprint('Uploading to S3..')\ns3_data_path = sagemaker_session.upload_data(path=root_dir, bucket=bucket_name, key_prefix='data')\n\nprint('Uploaded to', s3_data_path)","3bb76c68":"from sagemaker.tensorflow import TensorFlow\n\npets_estimator = TensorFlow(\n    entry_point='train.py',\n    role=role,\n    train_instance_count=1,\n    train_instance_type='ml.p2.xlarge',\n    framework_version='2.1.0',\n    py_version='py3',\n    output_path='s3:\/\/petscustom\/'\n)","a1d2e7fb":"pets_estimator.fit(s3_data_path)","9d6658c6":"pets_predictor = pets_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\nprint('\\nModel Deployed!')","eec37107":"cat_dir = 'custom_data\/validation\/cat\/'\ncat_images = [os.path.join(cat_dir, x) for x in os.listdir(cat_dir)]\nprint(cat_images[0])\n\ndog_dir = 'custom_data\/validation\/dog\/'\ndog_images = [os.path.join(dog_dir, x) for x in os.listdir(dog_dir)]\nprint(dog_images[0])","e98644cb":"def get_pred(image_path):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n    img = np.expand_dims(img, axis=0)\n\n    results = pets_predictor.predict(img)\n    return results","88b7cbb6":"image_path = cat_images[0]\nresults = get_pred(image_path)\n\nprint(results)","4cbdb0d3":"class_id = int(np.squeeze(results['predictions']) > 0.5)\nprint('Predicted class_id:', class_id, 'with class_name:', classes[class_id])","8e075ca2":"sagemaker_session.delete_endpoint(pets_predictor.endpoint)","03183310":"# Custom Training with TensorFlow in Sagemaker","8b6d1669":"# Training Script - Putting it Together","a9023d57":"# Training Script - Create Model","e2e5a3e3":"# Final Predictions","3a55f579":"# Train with TensorFlow Estimator","fb8e36a1":"# Dataset for Training","dd107d43":"** Now setup a bucket in 'S3' (for example='petcustom') and upload your dataset in cloud.** and excute the rest of the code.","8d45567f":"# Training Script - Data Generators","57bb887a":"Copy the files to correct set\/ class folders","6e10f4dd":"# Deploy TensorFlow Model","5f5f1964":"# Delete Model Endpoint","349d16be":"# Upload Dataset to S3","62e30c82":"We will be using Tensorflow in Sagemaker to build custom training model, I learn this project from \"Guided project\" in Coursera. \n\nFirst create an AWS account and go to Sagemaker, create a notebook instance and upload this notebook."}}