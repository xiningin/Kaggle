{"cell_type":{"a55f5797":"code","2cab0cf4":"code","9a57df63":"code","0ba06c87":"code","9e834fac":"code","3546b22a":"code","970c42b9":"code","aefacfd2":"code","91ddd3e9":"code","0d8f2398":"code","61cbe4fc":"code","eee9b3ec":"code","949d00b6":"code","798bfce1":"code","253bb20e":"code","4442b8be":"code","d1c2f7d4":"code","35abb2d0":"code","ca24c0fb":"code","7afd9c23":"code","bfb906e2":"code","30e2b89e":"markdown","9b26cbfa":"markdown","3af92c29":"markdown","499493a6":"markdown","0738a23b":"markdown","e4bd4827":"markdown","e9aca9da":"markdown","4d92b120":"markdown","46e2bb92":"markdown","fd31a241":"markdown","cda34759":"markdown","ed3f83da":"markdown"},"source":{"a55f5797":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport glob\n\nimport gc\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport imgaug.augmenters as iaa\nimport tensorflow as tf\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model,load_model\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom skimage.segmentation import slic\nfrom keras import backend as K\n\ncolor = sns.color_palette()\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nprint(os.listdir(\"..\/input\/chest_xray\/\"))\n\n","2cab0cf4":"# Set the seed for hash based operations in python\nos.environ['PYTHONHASHSEED'] = '0'\n\n# Set the numpy seed\nnp.random.seed(111)\n\n# Disable multi-threading in tensorflow ops\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n\n# Set the random seed in tensorflow at graph level\ntf.set_random_seed(111)\n\n# Define a tensorflow session with above session configs\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n\n# Set the session in keras\nK.set_session(sess)\n\n# Make the augmentation sequence deterministic\naug.seed(111)","9a57df63":"data_dir = Path(\"..\/input\/chest_xray\/chest_xray\")\ntrain_dir= data_dir\/'train'\nval_dir=data_dir\/'val'\ntest_dir = data_dir \/ 'test'\n","0ba06c87":"def load_train():\n    normal_cases_dir = train_dir \/ 'NORMAL'\n    pneumonia_cases_dir = train_dir \/ 'PNEUMONIA'\n\n    # Get the list of all the images\n    normal_cases = normal_cases_dir.glob('*.jpeg')\n    pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n    train_data=[]\n    train_label=[]\n    for img in normal_cases:\n            train_data.append(img)\n            train_label.append(0)\n    for img in pneumonia_cases:\n        train_data.append(img)\n        train_label.append(1)\n    df=pd.DataFrame(train_data)\n    df.columns=['images']\n    df['labels']=train_label\n    df=df.sample(frac=1).reset_index(drop=True)\n    return df","9e834fac":"train_data=load_train()\nlen(train_data)","3546b22a":"def prepare_and_load(isval=True):\n    if isval==True:\n        normal_dir=val_dir\/'NORMAL'\n        pneumonia_dir=val_dir\/'PNEUMONIA'\n    else:\n        normal_dir=test_dir\/'NORMAL'\n        pneumonia_dir=test_dir\/'PNEUMONIA'\n    normal_cases = normal_dir.glob('*.jpeg')\n    pneumonia_cases = pneumonia_dir.glob('*.jpeg')\n    data,labels=([] for x in range(2))\n    def prepare(case):\n        for img in case:\n            img = cv2.imread(str(img))\n            img = cv2.resize(img, (224,224))\n            if img.shape[2] ==1:\n                 img = np.dstack([img, img, img])\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = img.astype(np.float32)\/255.\n            if case==normal_cases:\n                label = to_categorical(0, num_classes=2)\n            else:\n                label = to_categorical(1, num_classes=2)\n            data.append(img)\n            labels.append(label)\n        return data,labels\n    prepare(normal_cases)\n    d,l=prepare(pneumonia_cases)\n    d=np.array(d)\n    l=np.array(l)\n    return d,l\n        ","970c42b9":"val_data,val_labels=prepare_and_load(isval=True)\ntest_data,test_labels=prepare_and_load(isval=False)","aefacfd2":"def data_gen(data, batch_size):\n    # Get total number of samples in the data\n    n = len(data)\n    steps = n\/\/batch_size\n    \n    # Define two numpy arrays for containing batch data and labels\n    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n\n    # Get a numpy array of all the indices of the input data\n    indices = np.arange(n)\n    \n    # Initialize a counter\n    i =0\n    while True:\n        np.random.shuffle(indices)\n        # Get the next batch \n        count = 0\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n        for j, idx in enumerate(next_batch):\n            img_name = data.iloc[idx]['images']\n            label = data.iloc[idx]['labels']\n            \n            # one hot encoding\n            encoded_label = to_categorical(label, num_classes=2)\n            # read the image and resize\n            img = cv2.imread(str(img_name))\n            img = cv2.resize(img, (224,224))\n            \n            # check if it's grayscale\n            if img.shape[2]==1:\n                img = np.dstack([img, img, img])\n            \n            # cv2 reads in BGR mode by default\n            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            # normalize the image pixels\n            orig_img = img.astype(np.float32)\/255.\n            \n            #segmentation\n            oig_img=slic(orig_img) \n            \n            batch_data[count] = orig_img\n            batch_labels[count] = encoded_label\n            #augmentation\n            seq = iaa.OneOf([\n                 iaa.Fliplr(), # horizontal flips\n                 iaa.Affine(rotate=20), # roatation\n                 iaa.Multiply((1.2, 1.5))]) #random brightness\n            # generating more samples of the undersampled class\n            if label==0 and count < batch_size-2:\n                aug_img1 = seq.augment_image(img)\n                aug_img2 = seq.augment_image(img)\n                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n                aug_img1 = aug_img1.astype(np.float32)\/255.\n                aug_img2 = aug_img2.astype(np.float32)\/255.\n\n                batch_data[count+1] = aug_img1\n                batch_labels[count+1] = encoded_label\n                batch_data[count+2] = aug_img2\n                batch_labels[count+2] = encoded_label\n                count +=2\n            \n            else:\n                count+=1\n            \n            if count==batch_size-1:\n                break\n            \n        i+=1\n        yield batch_data, batch_labels\n            \n        if i>=steps:\n            i=0","91ddd3e9":"def vgg16_model( num_classes=None):\n\n    model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n\n    x=Dense(1024, activation='relu')(model.layers[-4].output)# add my own dense layer after the last conv block\n    x=Dropout(0.7)(x)\n    x=Dense(512,activation='relu')(x)\n    x=Dropout(0.5)(x)\n    x=Dense(2,activation='softmax')(x)\n    model=Model(model.input,x)\n    \n    return model\n","0d8f2398":"vgg_conv=vgg16_model(2)\nfor layer in vgg_conv.layers[:-10]:#freeze all layers except the last ten\n    layer.trainable = False\n \n# Check the trainable status of the individual layers\nfor layer in vgg_conv.layers:\n    print(layer, layer.trainable)\n","61cbe4fc":"vgg_conv.summary()","eee9b3ec":"opt = Adam(lr=0.0001, decay=1e-5)\nearly_stop = EarlyStopping(monitor='loss',patience=3,verbose=1)\nvgg_conv.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)","949d00b6":"batch_size = 16\nnb_epochs = 5\n\n# Get a train data generator\ntrain_data_gen = data_gen(data=train_data, batch_size=batch_size)\n\n# Define the number of training steps\nnb_train_steps = train_data.shape[0]\/\/batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(val_data)))","798bfce1":"# # Fit the model\nhistory = vgg_conv.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                              validation_data=(val_data,val_labels),callbacks=[early_stop],\n                               class_weight={0:1.0, 1:0.4})","253bb20e":"loss,acc=vgg_conv.evaluate(test_data,test_labels,batch_size=16)\nprint('Loss and accuracy',loss,'&',acc)","4442b8be":"# Get predictions\npred = vgg_conv.predict(test_data, batch_size=16)\npred = np.argmax(pred, axis=-1)\n\n# Original labels\nlabels = np.argmax(test_labels, axis=-1)\nfrom sklearn.metrics import classification_report\nprint(classification_report(labels, pred))","d1c2f7d4":"# Get the confusion matrix\ncm  = confusion_matrix(labels, pred)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()","35abb2d0":"# Calculate Precision and Recall\ntn, fp, fn, tp = cm.ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall\/Sensitivity of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))\n","ca24c0fb":"import sklearn.metrics as metrics\nfpr, tpr, threshold = metrics.roc_curve(labels, pred)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","7afd9c23":"\nfrom skimage import data, color, io, img_as_float\ndef get_heatmap(processed_image, class_idx):\n    # we want the activations for the predicted label\n    class_output = vgg_conv.output[:, class_idx]\n    \n    # choose the last conv layer in your model\n    last_conv_layer = vgg_conv.get_layer('block5_conv3')\n    \n    # get the gradients wrt to the last conv layer\n    grads = K.gradients(class_output, last_conv_layer.output)[0]\n    \n   # we pool the gradients over all the axes leaving out the channel dimension\n    pooled_grads = K.mean(grads, axis=(0,1,2))\n    \n    # Define a function that generates the values for the output and gradients\n    iterate = K.function([vgg_conv.input], [pooled_grads, last_conv_layer.output[0]])\n    \n    # get the values\n    grads_values, conv_ouput_values = iterate([processed_image])\n    \n    # iterate over each feature map in your conv output and multiply\n    # the gradient values with the conv output values. This gives an \n    # indication of \"how important a feature is\"\n    for i in range(512): # we have 512 features in our last conv layer\n        conv_ouput_values[:,:,i] *= grads_values[i]\n    \n    # create a heatmap\n    heatmap = np.mean(conv_ouput_values, axis=-1)\n    \n    # remove negative values\n    heatmap = np.maximum(heatmap, 0)\n    \n    # normalize\n    heatmap \/= heatmap.max()\n    \n    return heatmap","bfb906e2":"\n# select the sample and read the corresponding image and label\nsample_image = cv2.imread('..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA\/person1947_bacteria_4876.jpeg')\n# pre-process the image\nsample_image = cv2.resize(sample_image, (224,224))\nif sample_image.shape[2] ==1:\n            sample_image = np.dstack([sample_image, sample_image, sample_image])\nsample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\nsample_image = sample_image.astype(np.float32)\/255.\nsample_label = 1\n    \n    \nsample_image_processed = np.expand_dims(sample_image, axis=0)#since we pass only one image,we expand dim to include\n                                                             #batch size 1\n    \n# get the label predicted by our original model\npred_label = np.argmax(vgg_conv.predict(sample_image_processed), axis=-1)[0]\n    \n    \n# get the heatmap for class activation map(CAM)\nheatmap = get_heatmap(sample_image_processed, pred_label)\nheatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\nheatmap = heatmap *255\nheatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n#superimpose the heatmap on the image    \n\nsample_image_hsv = color.rgb2hsv(sample_image)\nheatmap = color.rgb2hsv(heatmap)\n\nalpha=0.7\nsample_image_hsv[..., 0] = heatmap[..., 0]\nsample_image_hsv[..., 1] = heatmap[..., 1] * alpha\n\nimg_masked = color.hsv2rgb(sample_image_hsv)\n\nf,ax = plt.subplots(1,2, figsize=(16,6))\nax[0].imshow(sample_image)\nax[0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label}\")\nax[0].axis('off')\n    \nax[1].imshow(img_masked)\nax[1].set_title(\"Class Activation Map\")\nax[1].axis('off')\n\nplt.show()","30e2b89e":"Since we are working on Imbalanced data, accuracy is not really a trustworthy measure.Let's view the classification report first.","9b26cbfa":"CAM proves to be useful in interpreting the model, to know whether the CNN percieves x-ray images as radiologists do, or whether it learns unuseful features to make predictions.\n\nThank you for reading, you can show your appreciation by upvoting this kernel.And I intend to make the model better in the future.\n","3af92c29":"The basic aim of this kernel is to introduce the topics of Fine-Tuning and Class Activation Maps on the Pneumonia X-ray images dataset.Thanks to [Aakash Nain](https:\/\/www.kaggle.com\/aakashnain) for all the amazing preprocessing stuff I've borrowed from his [kernel](https:\/\/www.kaggle.com\/aakashnain\/beating-everything-with-depthwise-convolution).\n\nThe reason why I find this problem particularly useful is more than 1 million adults are hospitalized with pneumonia\nand around 50,000 die from the disease every\nyear in the US alone. Chest X-rays\nare currently the best available method for diagnosing\npneumonia , playing a crucial role in clinical\ncare  and epidemiological studies\n. However, detecting pneumonia\nin chest X-rays is a challenging task that relies on\nthe availability of expert radiologists(as reported by WHO).\n\n![](https:\/\/img.webmd.com\/dtmcms\/live\/webmd\/consumer_assets\/site_images\/article_thumbnails\/video\/nucleus_pneumonia_video\/650x350_nucleus_pneumonia_video.jpg?resize=650px:*)\n\nThis dataset contains train,val and test folders of chest x ray images.One thing to keep in mind is that the dataset is imbalanced and has three times pneumonia cases than normal ones.\n\nLet's just import all the stuff and get started.","499493a6":"## Class Activation Maps\nHere, I have used Gradient-weighted Class Activation Maps.It uses the gradients of any target concept (say logits for \u2018cat\u2019), flowing into the\nfinal convolutional layer to produce a coarse localization\nmap highlighting the important regions in the image for predicting the concept.\n\nSo, to explain in simple terms, we simply take the final convolutional feature map and then we weigh every channel in that feature with the gradient of the class with respect to the channel. It\u2019s just nothing but how intensely the input image activates different channels by how important each channel is with regard to the class. The best part is it doesn\u2019t require any re-training or change in the existing architecture unlike CAM where a Global Average Pooling layer is needed to generate activations.\n![](https:\/\/pbs.twimg.com\/media\/DTRSmgHXcAEYask.jpg)","0738a23b":"Let's see how it does on the test data.","e4bd4827":"### AUC-ROC Curve\n It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. For our case, Higher the AUC, better the model is at distinguishing between patients with disease and no disease. For an ideal model, the AUC is close to 1 and for a model as good as random guessing it's 0.5","e9aca9da":"### Loading and preprocessing validation and test data\nSteps:-\n* Load the image using imread()\n* Since the images are of different length and widths, resize them to 224,224.\n* Some images in our data are greyscale (1 channel) , therefore convert them to 3 channel\n* Images using cv2 are read in BGR format(by default) , convert it to RGB.\n* Normalize the image pixels by dividing by 255.","4d92b120":"According to me in medical diagnosis, having False Negatives can prove to be far more fatal than having False Positives. Since there is a trade-off between precision and recall , which  means one increases at the cost of other , our main motive will be to have a high recall for our model and a relatively low but good precision as well.\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*7J08ekAwupLBegeUI8muHA.png)","46e2bb92":"A basic function to load train images from the directory and save it in a dataframe with labels.","fd31a241":"**Precision** is a fraction of people actually having pneumonia to all those predicted by the model as having pneumonia. **Recall\/Sensitivity** on the other hand refers to the fraction of people actually having pneumonia and are predicted positive by the model to the total number of people having pneumonia. Hence, it relates to the potential of a test to recognise subjects with the disease.\n\nThe definitions may seem quite overwhelming, but there meaning will be clear in a while.Quite evidently, our model isn't doing well on the normal class.","cda34759":"# Fine Tuned Model\nTo train a neural network from scratch,we need a lot of data also lot of processing power and time , which is obviously unavailble and impractical. Therefore, we fine-tune pretrained neural networks. There are a lot of neural networks pretrained on billions of images, that can be used by changing the top layer as per our data.But we use a better technique than that called fine-tuning in which we tweak the parameters of an already trained network so that it adapts to the new task at hand. \n\nThe initial layers learn very general features and as we go higher up the network, the layers tend to learn patterns more specific to the task it is being trained on. Thus, for fine-tuning, we want to keep the initial layers intact ( or freeze them ) and retrain the later layers for our task.\n\nI have used the VGG16 model and added my own dense layers at the bottom, then I freeze the network upto the second last convolutional block, after which I retrain.\n\n![](https:\/\/i.imgur.com\/Jjh8f0z.png)","ed3f83da":"### Generating batches of images for training\n* It involves the same preprocessing steps as above, except that images are processed and returned in batches,defined by the batch size.\n* We also use Image segmentation ( the slic function of skimage).Image segmentation is the process of partitioning a  image into multiple segments (sets of pixels, also known as super-pixels). The goal of segmentation is to simplify and\/or change the representation of an image into something that is more meaningful and easier to analyze.\n* The dataset we have is Imbalanced and has pneumonia cases three times the normal cases.The goal of our model is to optimize accuracy while training , which it can easily do by classifying most of the cases as infected(since the majority cases are infected, the model will have high accuracy), but it is biased aginst the underrepresented class.Thus we try to augment images of the normal class , by adding flipped , rotated and changing brightness of the original images."}}