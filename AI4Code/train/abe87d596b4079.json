{"cell_type":{"b3007812":"code","11c9f501":"code","6a3acc27":"code","8efe3e02":"code","75e38470":"code","8175de95":"code","35ec6533":"code","0fd8e995":"code","5b061a35":"code","c636d864":"code","aa7270f4":"code","ce36871c":"code","b3ba7b01":"code","d1aba43e":"code","31f90112":"code","35d832b7":"code","a29b7666":"code","4b987421":"code","da7df038":"code","7bcd2b2b":"markdown","3ef1edd9":"markdown","dca616a5":"markdown","949ed6c2":"markdown","9cbf2fc1":"markdown","b0a19d82":"markdown","01931d95":"markdown","2fe41123":"markdown","b879183b":"markdown"},"source":{"b3007812":"import numpy as np \nimport pandas as pd \nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import minmax_scale\nimport random\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation\nfrom tensorflow.keras.optimizers import Adam","11c9f501":"training_folder = '..\/input\/cassava-leaf-disease-classification\/train_images\/' #\ud6c8\ub828\ud560 \uc774\ubbf8\uc9c0\ub4e4\uc774 \uc788\ub294 \ud3f4\ub354\nsamples_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv') #\ud6c8\ub828\ud560 \uc774\ubbf8\uc9c0\uc758 \uc774\ub984 \ubc0f \uac01 label \ub370\uc774\ud130 \ub85c\ub4dc\nsamples_df[\"filepath\"] = training_folder+samples_df[\"image_id\"] #\uc0ac\uc9c4\uc744 \ubd88\ub7ec\uc624\uae30 \uc27d\ub3c4\ub85d \ud3f4\ub354\uc640 \uc774\ubbf8\uc9c0\uc758 \uc774\ub984\uc744 \ud569\uccd0 \uacbd\ub85c\ub97c \uc0dd\uc131\nsamples_df = samples_df.drop(['image_id'],axis=1) #\ud544\uc694\uc5c6\ub294 \uc774\ubbf8\uc9c0 \uc774\ub984\uc744 \ubaa8\ub450 \ubc84\ub9bc","6a3acc27":"samples_df = shuffle(samples_df, random_state=42) #\ub370\uc774\ud130\ub97c \ubb34\uc791\uc704\ub85c \uc11e\uc74c\ntrain_size = int(len(samples_df)*0.8) # \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ud560 \ub370\uc774\ud130\uc758 \ud06c\uae30\ub97c \uc9c0\uc815\ntraining_df = samples_df[:train_size] # \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4e4\uc5b4\uc90c\nvalidation_df = samples_df[train_size:] # validation \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4e4\uc5b4\uc90c","8efe3e02":"batch_size = 8 # \ubc30\uce58 \uc0ac\uc774\uc988\ub97c \uc124\uc815\nimage_size = 512 # \uc774\ubbf8\uc9c0\uc758 \ud06c\uae30\ub97c \uc124\uc815\ninput_shape = (image_size, image_size, 3) #\uc774\ubbf8\uc9c0\uc758 \uc0ac\uc774\uc988 \uc815\uc758 (\uceec\ub7ec \uc774\ubbf8\uc9c0\uc774\uae30 \ub54c\ubb38\uc5d0 \ud55c \ud654\uc18c\ub2f9 3\uac1c\uc758 \ub370\uc774\ud130\uac00 \ud544\uc694)\ndropout_rate = 0.4 #\ub4dc\ub86d\uc544\uc6c3 \ube44\uc728 \uc815\uc758\nclasses_to_predict = sorted(training_df.label.unique()) #\uc608\uce21\ud574\uc57c \ud558\ub294 \ud074\ub798\uc2a4 \uc218 \uc815\uc758, \uc5ec\uae30\uc11c\ub294 5\uac1c","75e38470":"\"\"\"\ntrain \ub370\uc774\ud130\uc640 validation \ub370\uc774\ud130\ub97c \ud150\uc11c\ud50c\ub85c\uc6b0 Dataset\uc73c\ub85c \uc815\uc758\ud569\ub2c8\ub2e4.\n\ud150\uc11c\ud50c\ub85c\uc6b0 Dataset\ub294 \ub3d9\uc801\uc73c\ub85c \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc640, \ub108\ubb34 \ub9ce\uc740 \ub370\uc774\ud130\uac00 \uba54\ubaa8\ub9ac\uc5d0 \uc4f0\uc5ec\uc9c0\ub294 \uc77c\uc744 \ubc29\uc9c0\ud558\uc5ec \ud37c\ud3ec\uba3c\uc2a4\uac00 \ud5a5\uc0c1\ub429\ub2c8\ub2e4.\n\ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc544\ub798\uc758 \ub9c1\ud06c\ub97c \ucc38\uc870\ud558\uc138\uc694.\nhttps:\/\/www.tensorflow.org\/guide\/data_performance?hl=ko\n\"\"\"\ntraining_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\nvalidation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))","8175de95":"def load_image_and_label_from_path(image_path, label): #\uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc640 \ud150\uc11c (array\uc640 \ube44\uc2b7\ud55c \ud615\ud0dc)\ub85c \ubcc0\ud658\ud558\ub294 \ud568\uc218\n    img = tf.io.read_file(image_path) #\uc774\ubbf8\uc9c0 \uacbd\ub85c\uc758 \ud30c\uc77c\uc744 \uc77d\uc74c\n    img = tf.image.decode_jpeg(img, channels=3) #\uc774\ubbf8\uc9c0\ub97c array \ub370\uc774\ud130\ub85c \ubcc0\ud658\ud558\uc5ec \uc800\uc7a5\n    img = tf.image.random_crop(img, size=[image_size,image_size,3]) # \uc774\ubbf8\uc9c0\ub97c \ub79c\ub364\uc73c\ub85c \uc6d0\ud558\ub294 \uc0ac\uc774\uc988\ub85c \uc798\ub77c\uc90c. \uc911\uc559\ub9cc \uc790\ub974\uace0 \uc2f6\ub2e4\uba74 central_crop \uc0ac\uc6a9.\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE #\uba54\ubaa8\ub9ac \ub3d9\uc801 \ud560\ub2f9\uc744 \uc704\ud55c AUTOTUNE\ntraining_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE) #train \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc634\nvalidation_data = validation_data.map(load_image_and_label_from_path,num_parallel_calls=AUTOTUNE) #validation \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc634","35ec6533":"#train \ubc0f validation \ub370\uc774\ud130\ub97c \ud6c8\ub828\ud558\uae30 \uc88b\uac8c batch\ub85c \uc790\ub984\ntraining_data_batches = training_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\nvalidation_data_batches = validation_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","0fd8e995":"\"\"\"\n\uc774\ubbf8\uc9c0\ub97c Augmentation \ud574\uc8fc\ub294 \ub808\uc774\uc5b4\ub97c \ub9cc\ub4e4\uc5b4\uc90d\ub2c8\ub2e4. \ubaa8\ub378\uc744 \ub9cc\ub4e4 \ub54c augmentation layer\uc744 \ub123\uc73c\uba74 \uc790\ub3d9\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \ub2e4\uc591\ud558\uac8c \ubcc0\ud658\ud558\uc5ec \uc90d\ub2c8\ub2e4.\n\ub354 \ub9ce\uc740 augmentation\uc744 \uc801\uc6a9\ud574\ubcf4\uace0 \uc2f6\uc73c\uba74 https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/experimental\/preprocessing \uc774 \ub9c1\ud06c\ub97c \ucc38\uc870\ud558\uc138\uc694.\n\ub610\ud55c, imgaug, albumentation\uacfc \uac19\uc740 \uac15\ub825\ud55c augmentation \ub77c\uc774\ube0c\ub7ec\ub9ac\ub3c4 \uc0b4\ud3b4\ubcf4\uc138\uc694. \n\"\"\"\ndata_augmentation_layers = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"), #\ub79c\ub364\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \uc88c\uc6b0\ub85c \ub4a4\uc9d1\uc5b4\uc90c.\n        layers.experimental.preprocessing.RandomRotation(0.25), #\uc774\ubbf8\uc9c0\ub97c \uc88c\uc6b0\ub85c 25% \uc774\ub0b4\ub85c \ub79c\ub364\uc73c\ub85c \ub3cc\ub9bd\ub2c8\ub2e4. \n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)), #\uc774\ubbf8\uc9c0\ub97c 0~20%\ub9cc\ud07c \ub79c\ub364\uc73c\ub85c \ucd95\uc18c\ud569\ub2c8\ub2e4.\n        \n    ]\n)\n","5b061a35":"\"\"\"\n\uc774 \ubca0\uc774\uc2a4\ub77c\uc778\uc5d0\uc11c\ub294 transfer learning\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ubbf8\ub9ac \ud6c8\ub828\ub418\uc5b4 \uc788\ub294 \uc774\ubbf8\uc9c0\uc6a9 \ubaa8\ub378\uc744 \ubd88\ub7ec\uc640\uc11c \uadf8 \ubaa8\ub378\uc758 \ub4a4\ucabd\uc5d0 \ub098\ub9cc\uc758 \ubaa8\ub378\uc744 \ucd94\uac00\ud55c \ub4a4 \ud559\uc2b5\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4.\n\uc9c1\uc811 \uc218\ub9ce\uc740 \ub808\uc774\uc5b4\uc758 \ubaa8\ub378\uc744 \ub514\uc790\uc778\ud558\ub294 \uac83\uc740 \uc5b4\ub835\uae30 \ub54c\ubb38\uc5d0 \uc774\ub7ec\ud55c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 \uad6c\uae00\uc758 EfficientNetB0\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 https:\/\/arxiv.org\/pdf\/1905.11946.pdf \uc774 \ub17c\ubb38\uc744 \ucc38\uace0\ud558\uc138\uc694.\n\n\uc8fc\uc758!! imagenet \uac00\uc911\uce58 \uac12\uc744 \ub2e4\uc6b4\ubc1b\uae30 \uc704\ud558\uc5ec \uc6b0\uce21 \uc0c1\ub2e8 |< \ud45c\uc2dc\ub97c \ub204\ub974\uace0 setting\uc5d0\uc11c Internet\uc744 \ucf1c\uc918\uc57c\ud569\ub2c8\ub2e4.\n\"\"\"\nefficientnet = EfficientNetB0(weights=\"imagenet\", #\uc774\ubbf8\uc9c0\ub137 \uac00\uc911\uce58 \uac12\uc744 \ubd88\ub7ec\uc640 \uc801\uc6a9\n                              include_top=False, \n                              input_shape=input_shape, \n                              drop_connect_rate=dropout_rate) #efficientnetB0 \ubaa8\ub378\uc744 \ub85c\ub4dc\nefficientnet.trainable=True # efficientnetb0\uc758 \ud559\uc2b5\uc744 \ud5c8\uc6a9. \ub9cc\uc57d False\ub85c \uc9c0\uc815\ud560 \uc2dc\uc5d0 \uc815\ud655\ub3c4\ub294 \ub5a8\uc5b4\uc9c0\uc9c0\ub9cc \ud559\uc2b5 \uc18d\ub3c4\uac00 \ub9e4\uc6b0 \ube68\ub77c\uc9d0.","c636d864":"\"\"\"\n\uc790\uc2e0\ub9cc\uc758 CNN \ubaa8\ub378\uc744 \uc9c1\uc811 \ub9cc\ub4e4\uc5b4 \ubcf4\uc544\ub3c4 \uad1c\ucc2e\uc2b5\ub2c8\ub2e4.\n\"\"\"\nmodel = Sequential() #\uc0c8 Sequential \ubaa8\ub378\uc744 \ub9cc\ub4ec \nmodel.add(Input(shape=input_shape)) #\uc778\ud48b\uc744 \uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988\ub85c \uc124\uc815\nmodel.add(data_augmentation_layers) #\uc774\ubbf8\uc9c0 augumentation \ub808\uc774\uc5b4 \ucd94\uac00\nmodel.add(efficientnet) # efficientnetb0 \ucd94\uac00\nmodel.add(layers.GlobalAveragePooling2D()) # \ud480\ub9c1 \ub808\uc774\uc5b4\ub97c \ucd94\uac00\nmodel.add(layers.Dropout(dropout_rate)) # \ub4dc\ub86d\uc544\uc6c3 \ub808\uc774\uc5b4\ub97c \ucd94\uac00\nmodel.add(Dense(len(classes_to_predict), activation=\"softmax\")) #\ub9c8\uc9c0\ub9c9 \ub374\uc2a4 \ub808\uc774\uc5b4\ub97c \ucd94\uac00. \uc608\uce21\ud560 \ud074\ub798\uc2a4\uc758 \uac1c\uc218\ub9cc\ud07c\uc774 \uc544\uc6c3\ud48b\uc774 \ub41c\ub2e4. \nmodel.summary() #\ubaa8\ub378 \ud655\uc778","aa7270f4":"epochs = 30 #\uc5d0\ud3ed \uc218\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\ndecay_steps = int(round(len(training_df)\/batch_size))*epochs\ncosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3) #learning rate\ub97c \uc5d0\ud3ed\uc774 \uc9c0\ub0a0\uc218\ub85d \uc810\uc810 \uc904\uc5ec\ub098\uac00\ub294 cosine decay \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ncallbacks = [ModelCheckpoint(filepath='mymodel.h5', monitor='val_loss', save_best_only=True), #\uac00\uc7a5 validation loss\uac00 \ub0ae\uc740 \uc5d0\ud3ed\uc758 \ubaa8\ub378\uc744 .h5 \ud30c\uc77c\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4. \n            EarlyStopping(monitor='val_loss', patience = 5, verbose=1)] #\uc815\ud574\uc9c4 \uc5d0\ud3ed\uc774 \ub418\uae30 \uc804\uc5d0 5\ubc88\uc758 \uc5d0\ud3ed\ub3d9\ud55c validation loss\uac00 \ud5a5\uc0c1\ub418\uc9c0 \uc54a\uc73c\uba74 \ud559\uc2b5\uc744 \uc885\ub8cc\ud569\ub2c8\ub2e4. \n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(cosine_decay), metrics=[\"accuracy\"]) #loss\ub294 sparse_categorical_crossentropy, optimizer\ub294 Adam\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uac01 \uc5d0\ud3ed\ub2f9 \uc815\ud655\ub3c4\ub97c \ud1b5\ud574 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud569\ub2c8\ub2e4, ","ce36871c":"history = model.fit(training_data_batches, #\ubaa8\ub378\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4. \n                  epochs = epochs, \n                  validation_data=validation_data_batches,\n                  callbacks=callbacks)","b3ba7b01":"\"\"\"\nmodel = tf.keras.models.load_model('\ud30c\uc77c\uacbd\ub85c')\n\"\"\"","d1aba43e":"#\uc704\uc758 train \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud55c \ubc29\ubc95\uacfc \ube44\uc2b7\ud558\uac8c test \ub370\uc774\ud130\ub3c4 \ub85c\ub4dc\ud574\uc90d\ub2c8\ub2e4.\ntest_folder = '..\/input\/cassava-leaf-disease-classification\/test_images\/' \nsubmission_df = pd.DataFrame(columns={\"image_id\",\"label\",\"filepath\"})\nsubmission_df[\"image_id\"] =  os.listdir(test_folder) #\uc790\ub3d9\uc73c\ub85c \ud14c\uc2a4\ud2b8 \ud3f4\ub354 \uc548\uc758 \uc774\ubbf8\uc9c0 \uc774\ub984\ub4e4\uc744 image_id\uc5d0 \uc785\ub825\ud568\nsubmission_df[\"label\"] = 0\nsubmission_df[\"filepath\"] = test_folder+submission_df['image_id']\nsubmission_df = submission_df.drop(['image_id'],axis=1)","31f90112":"def load_image(image_path): #\uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc640 \ud150\uc11c (array\uc640 \ube44\uc2b7\ud55c \ud615\ud0dc)\ub85c \ubcc0\ud658\ud558\ub294 \ud568\uc218\n    img = tf.io.read_file(image_path) #\uc774\ubbf8\uc9c0 \uacbd\ub85c\uc758 \ud30c\uc77c\uc744 \uc77d\uc74c\n    img = tf.image.decode_jpeg(img, channels=3) #\uc774\ubbf8\uc9c0\ub97c array \ub370\uc774\ud130\ub85c \ubcc0\ud658\ud558\uc5ec \uc800\uc7a5\n    img = tf.image.random_crop(img, size=[image_size,image_size,3]) # \uc774\ubbf8\uc9c0\ub97c \ub79c\ub364\uc73c\ub85c \uc6d0\ud558\ub294 \uc0ac\uc774\uc988\ub85c \uc798\ub77c\uc90c. \uc911\uc559\ub9cc \uc790\ub974\uace0 \uc2f6\ub2e4\uba74 central_crop \uc0ac\uc6a9.\n    img = np.reshape(img, [-1,512,512,3]) #\uc774\ubbf8\uc9c0\ub97c 3\ucc28\uc6d0\uc5d0\uc11c 4\ucc28\uc6d0 \ud150\uc11c\ub85c \ubcc0\ud658\n    return img","35d832b7":"def test_predict(filepath):\n    local_image = load_image(filepath) #\ud568\uc218\ub97c \ud1b5\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \ubd88\ub7ec\uc634\n    predictions = model.predict(local_image) #\uac01 \ud074\ub798\uc2a4\uc758 \ud655\ub960\uc744 \ud6c8\ub828\ud55c \ubaa8\ub378\uc73c\ub85c \uc608\uce21\n    final_prediction = np.argmax(predictions) #\uac00\uc7a5 \ud655\ub960\uc774 \ub192\uc740 \ud074\ub798\uc2a4\ub97c \ucd5c\uc885 \uc608\uce21 \uacb0\uacfc\ub85c \ub3c4\ucd9c\n    return final_prediction #\uc608\uce21\uacb0\uacfc \ubc18\ud658","a29b7666":"def predictions_over_image(filepath):\n    predictions = [] #\uc5d0\uce21\uac12\uc744 \uc800\uc7a5\ud558\ub294 \ub9ac\uc2a4\ud2b8\n    for path in filepath:   \n        predictions.append(test_predict(path)) # \uac01 \uc0ac\uc9c4\ub9c8\ub2e4 \uc608\uce21\uac12\uc744 \uc800\uc7a5\ud55c\ub2e4\n    return predictions #\uc608\uce21\uac12 \ubcc0\ud658","4b987421":"submission_df[\"label\"] = predictions_over_image(submission_df[\"filepath\"]) # \ubaa8\ub378\ub85c \uc608\uce21\ud55c \uac12\uc744 submission DataFrame\uc5d0 \uc785\ub825","da7df038":"submission_df.to_csv(\"submission.csv\", index=False) # submission csv \ud30c\uc77c \uc0dd\uc131","7bcd2b2b":"# \ub370\uc774\ud130 \uc804\ucc98\ub9ac (\uc774\ubbf8\uc9c0 \ub85c\ub4dc)","3ef1edd9":"# \uc810\uc218 \ud5a5\uc0c1\uc744 \uc704\ud574 \uc2dc\ub3c4\ud574\ubcfc \uc218 \uc788\ub294 \uac83\ub4e4\n\n1. \ub354 \ud070 \ubaa8\ub378 \uc0ac\uc6a9 (EfflicientNetB4 \ub4f1)\n2. \ub354 \ub2e4\uc591\ud55c augmentation \uc0ac\uc6a9 (Dropout, Cutmix, Mixup \ub4f1)\n3. TTA (Test Time Augmentation) \uc0ac\uc6a9    https:\/\/inspaceai.github.io\/2019\/12\/20\/Test_Time_Augmentation_Review\/\n4. Stratified Kfold \uc0ac\uc6a9 : \ub370\uc774\ud130\uac00 \ud55c \ud074\ub798\uc2a4\ub85c \uce58\uc6b0\uccd0\uc838 \uc788\uae30 \ub54c\ubb38\uc5d0 \uac1c\uc218\uc5d0 \ub9de\ucdb0\uc11c train \ub370\uc774\ud130\uc640 validation \ub370\uc774\ud130\ub97c \ub098\ub204\uba74 \uc88b\ub2e4.\n5. \uc0c8\ub85c\uc6b4 Callbacks \uc804\ub7b5 \uc0ac\uc6a9\n6. Symmetric Cross Entropy\uc640 \uac19\uc740 \ub2e4\ub978 loss fuction \uc0ac\uc6a9    https:\/\/arxiv.org\/abs\/1908.06112\n7. Lookahead\ub098 RAdam \ub4f1 \ub2e4\ub978 optimizer \uc0ac\uc6a9\n8. \uc678\ubd80 \ub370\uc774\ud130 \uc14b \ud65c\uc6a9    https:\/\/www.kaggle.com\/tahsin\/cassava-leaf-disease-merged\n9. \ub2e4\uc591\ud55c Ensemble \uae30\ubc95 \ud65c\uc6a9 : Bagging, voting, stacking \ub4f1\n10. \uc0c8\ub85c\uc6b4 model \ub514\uc790\uc778","dca616a5":"# **Cassava Competition Baseline**\n\n\uc774 competition\uc740 \uc5f4\ub300\uc5d0 \uc11c\uc2dd\ud558\ub294 \uce74\uc0ac\ubc14 \ub098\ubb34\uc5d0 \ubc1c\ubcd1\ud558\ub294 \uc9c8\ubcd1 4\uac1c\uc640 \uac74\uac15\ud55c \uc0c1\ud0dc, \uc989 5\uac00\uc9c0\uc758 class\ub4e4\uc744 \ubd84\ub958\ud558\ub294 classification \ubb38\uc81c\uc785\ub2c8\ub2e4. \uc8fc\uc5b4\uc9c0\ub294 \uc774\ubbf8\uc9c0\ub294 \ubaa8\ub450 600x800 \uc0ac\uc774\uc988\uc774\uace0, test set\uc740 \uacf5\uac1c\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \n\uac01 \uc9c8\ubcd1\ub4e4\uc758 \ud2b9\uc9d5 \ub4f1\uc740 \uc544\ub798\uc758 EDA\ub97c \ucc38\uace0\ud569\ub2c8\ub2e4.\nhttps:\/\/www.kaggle.com\/ihelon\/cassava-leaf-disease-exploratory-data-analysis\n\n\uc774 \ubca0\uc774\uc2a4\ub77c\uc778 \ucf54\ub4dc\ub294 \ub2e4\uc74c \ucee4\ub110\uc744 \ucc38\uace0\ud558\uc5ec \uc7ac\uad6c\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4.\nhttps:\/\/www.kaggle.com\/frlemarchand\/efficientnet-aug-tf-keras-for-cassava-diseases\n\n\uc8fc\uc11d\uc5d0 \uc790\uc138\ud55c \uc124\uba85\uc744 \uae30\uc7ac\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n\uc9c8\ubb38\uc740 \uc5b8\uc81c\ub4e0\uc9c0 \uc790\uc720\ub86d\uac8c \ud574\uc8fc\uc2dc\uba74 \ub429\ub2c8\ub2e4. tensorflow, numpy, pandas, scikit-learn\uc740 \uacf5\uc2dd \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uba74 \ub354\uc6b1 \uc815\ud655\ud55c \uc815\ubcf4\ub97c \ube60\ub974\uac8c \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n* Tensorflow - https:\/\/www.tensorflow.org\/api_docs\/python\/tf\n* numpy - https:\/\/numpy.org\/doc\/1.19\/\n* pandas - https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/index.html\n* scikit-learn - https:\/\/scikit-learn.org\/stable\/modules\/classes.html","949ed6c2":"# \uc2e4\uc81c Test \ub370\uc774\ud130 \uc608\uce21","9cbf2fc1":"**\uc774 \ub178\ud2b8\ubd81\uc774 \ub3c4\uc6c0\uc774 \ub418\uc5c8\ub2e4\uba74 \uc5c5\ubcf4\ud2b8 \ud55c \ubc88 \uc529 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4. \uac10\uc0ac\ud569\ub2c8\ub2e4!**","b0a19d82":"If you are not Korean, please check out this notebook. https:\/\/www.kaggle.com\/vkehfdl1\/cassava-baseline-with-detailed-explanation","01931d95":"# \ubaa8\ub378 \ub9cc\ub4e4\uae30 \ubc0f \ud559\uc2b5","2fe41123":"\uc774 \uc544\ub798\ubd80\ud130\uc758 \ub0b4\uc6a9\uc740 \uc2e4\uc81c submission \ud560 \ub54c \ud544\uc694\ud55c \ub0b4\uc6a9\uc785\ub2c8\ub2e4. kaggle\uc5d0\uc11c submission\uc744 \ud560 \ub54c \ubaa8\ub4e0 \ub178\ud2b8\ubd81\uc774 \ub2e4\uc2dc \ub3cc\uc544\uac00\uc11c \ud6c8\ub828\uc744 \ub2e4\uc2dc \ud558\uac8c \ub418\ubbc0\ub85c, .h5\ub85c \uc800\uc7a5\ub41c \ud30c\uc77c\uc744 \ubd88\ub7ec\uc640\uc11c \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uac04\uc744 \ud06c\uac8c \uc808\uc57d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \uc704\ud55c \ub0b4\uc6a9\uc740 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4. \n\n1. \uc800\uc7a5\ub41c .h5 \ud30c\uc77c\uc744 output -> \/kaggle\/working \uc5d0\uc11c \ucc3e\uc544 \uc624\ub978\ucabd\uc758 \uc810 \uc138\uac1c\ub97c \ub20c\ub7ec download\ub97c \ud074\ub9ad\ud558\uc5ec \ub2e4\uc6b4\ub85c\ub4dc \ud569\ub2c8\ub2e4.\n2. kaggle Data \ud0ed\uc5d0 \ub4e4\uc5b4\uac00 New Dataset\uc744 \ud074\ub9ad\ud569\ub2c8\ub2e4.\n3. Dataset \uc774\ub984\uc744 \uc785\ub825\ud558\uace0 .h5 \ud30c\uc77c\uc744 \ucc3e\uc544 \uc5c5\ub85c\ub4dc\ud55c \ud6c4, Create \ubc84\ud2bc\uc744 \ub20c\ub7ec \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n4. submission\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 notebook\uc744 \ub9cc\ub4e4\uace0, \uc6b0\uce21 \uc0c1\ub2e8\uc758 Add data\ub97c \ub204\ub978 \ud6c4 Your Dataset\uc73c\ub85c \uac04 \ud6c4, \ubc29\uae08 \ub9cc\ub4e0 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud30c\ub780\uc0c9 Add \ubc84\ud2bc\uc744 \ub20c\ub7ec notebook\uc5d0 \ucd94\uac00\ud574\uc90d\ub2c8\ub2e4.\n5. model = tf.keras.models.load_model('\ud30c\uc77c\uacbd\ub85c') \ucf54\ub4dc\ub97c \uc774\uc6a9\ud558\uc5ec \ubaa8\ub378\uc744 \uac00\uc838\uc635\ub2c8\ub2e4. \n\ucc38\uace0 : \uc6b0\uce21\uc758 Data \ud0ed\uc5d0\uc11c Copy File path\ub77c\uace0 \ub098\uc624\ub294 \uc791\uc740 \ubc84\ud2bc\uc744 \ub204\ub974\uba74 \ud30c\uc77c \uacbd\ub85c\ub97c \uc27d\uac8c \ubcf5\uc0ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. ","b879183b":"# \ub77c\uc774\ube0c\ub7ec\ub9ac import"}}