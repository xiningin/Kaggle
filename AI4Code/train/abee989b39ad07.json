{"cell_type":{"92ede6f7":"code","0da2c3bb":"code","e8e80e72":"code","0222d8e1":"code","cf45f922":"code","ed653e9b":"code","3482a032":"code","73d42fde":"code","effdd22a":"code","f55276ae":"code","8f1048da":"code","90f3ef4a":"code","31946c2f":"code","2337b37e":"code","91c6ff61":"code","58370eea":"code","4a71bc37":"code","dfab6477":"markdown","785141b8":"markdown","d51d51dd":"markdown","eebaa80b":"markdown","fdc2f167":"markdown","2872a540":"markdown","60ec3b0f":"markdown","ab8e1cea":"markdown","05ae06ec":"markdown","0dfbd2df":"markdown","0d51ba7b":"markdown"},"source":{"92ede6f7":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport datetime","0da2c3bb":"BATCH_SIZE = 32\nSHUFFLE = True","e8e80e72":"train_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntrain_numpy_df = np.asarray(train_df)\n\ntest_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ntest_numpy_df = np.asarray(test_df)","0222d8e1":"train_df.sample(5)","cf45f922":"test_df.sample(5)","ed653e9b":"train_labels, train_data = (\n    train_numpy_df[:, 0],\n    train_numpy_df[:, 1:].reshape(-1, 28, 28, 1) # 28, 28, 1 - one 28x28 image with 1 color channel\n)\n\ntest_labels, test_data = (\n    test_numpy_df[:, 0],\n    test_numpy_df[:, 1:].reshape(-1, 28, 28, 1)\n)\n\nprint(f'''\nData Shapes:\nTrain data - {train_data.shape}\nTrain labels - {train_labels.shape}\n\nTest data - {test_data.shape}\nTest labels - {test_labels.shape}\n''')","3482a032":"class FashionMnistDataset(torch.utils.data.Dataset):\n    def __init__(self, data, labels, transform=torchvision.transforms.ToTensor()):\n        self.data = np.asarray(data, dtype=np.float32)\n        self.labels = np.asarray(labels, dtype=np.int64)\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        sample_data = self.data[index]\n        sample_label = self.labels[index]\n        \n        sample_data = self.transform(sample_data)\n        \n        return sample_data, sample_label\n    \n    def __len__(self):\n        return len(self.data)","73d42fde":"transform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(0.5, 0.5)\n])","effdd22a":"train_set = FashionMnistDataset(\n    data=train_data,\n    labels=train_labels,\n    transform=transform,\n)\n\ntest_set = FashionMnistDataset(\n    data=test_data,\n    labels=test_labels,\n    transform=transform,\n)\n\n\n\ntrain_loader = DataLoader(\n    train_set,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    drop_last=True,\n)\n\ntest_loader = DataLoader(\n    test_set,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    drop_last=True,\n)\n\nprint(f'Train loader - {len(train_loader)}\\nTest loader - {len(test_loader)}')","f55276ae":"plt.figure(figsize=(20, 20), facecolor='0.7')\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\n\nfor i in range(BATCH_SIZE):\n    plt.subplot(BATCH_SIZE\/\/8, 8, i+1)\n    plt.imshow(images[i].permute(1, 2, 0), cmap='Greys')\n    plt.axis('off')\n    plt.title(f'Class - {int(labels[i])}')\nplt.show()","8f1048da":"# BS := BATCH_SIZE\n# I will use 3 models forming an ensemble\n\nclass MiddleHeadCNN(nn.Module):\n    def __init__(self):\n        super(MiddleHeadCNN, self).__init__()\n        self.cnn_block_1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2), # BS, 16, 28, 28\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(16, 32, kernel_size=5, padding=2), # BS, 32, 14, 14\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(32*7*7, 256),\n            nn.ReLU(),\n            nn.Linear(256, 10)\n        )\n\n\n    def forward(self, x):\n        x = self.cnn_block_1(x)\n        x = self.classifier(x)\n        x = F.log_softmax(x, dim=1)\n        return x\n\nclass RightHeadCNN(nn.Module):\n    def __init__(self):\n        super(RightHeadCNN, self).__init__()\n        self.cnn_block_1 = nn.Sequential(\n            nn.Conv2d(1, 12, kernel_size=5, padding=2), # BS, 12, 28, 28\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(12, 24, kernel_size=5, padding=2), # BS, 24, 14, 14\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(24*7*7, 164),\n            nn.ReLU(),\n            nn.Linear(164, 10)\n        )\n\n\n    def forward(self, x):\n        x = self.cnn_block_1(x)\n        x = self.classifier(x)\n        x = F.log_softmax(x, dim=1)\n        return x\n\nclass LeftHeadCNN(nn.Module):\n    def __init__(self):\n        super(LeftHeadCNN, self).__init__()\n        self.cnn_block_1 = nn.Sequential(\n            nn.Conv2d(1, 20, kernel_size=5, padding=2), # BS, 20, 28, 28\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(20, 40, kernel_size=5, padding=2), # BS, 40, 14, 14\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(40*7*7, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n\n    def forward(self, x):\n        x = self.cnn_block_1(x)\n        x = self.classifier(x)\n        x = F.log_softmax(x, dim=1)\n        return x","90f3ef4a":"class Ensemble:\n    def __init__(self, models: list, verbose=0):\n        self.models = models\n        self.verbose = verbose\n        self.history = None\n        self.device = torch.device('cpu')\n\n    def load_models(self, names=None):\n        modls = []\n        if names is None:\n            for i in range(len(self.models)):\n                modls.append(torch.load(f'Best_Model_{i}'))\n        else:\n            for i in range(len(self.models)):\n                modls.append(torch.load(names[i]))\n        if self.verbose:\n            print('All models loaded!')\n\n    def train_all(self, train_loader, test_loader, lr: tuple, epochs: tuple, make_plot=True, save_model=False, save_best=True, device=torch.device('cpu'), smartmode=True):\n        assert(len(lr)==len(self.models)==len(epochs))\n        \n        if self.verbose:\n            print(f'Using {device} device... {len(self.models)} models found')\n            \n        print(f\"---------------------------<START - {datetime.datetime.now()}>---------------------------\")\n        \n        loss_history = []\n        acc_test_history = []\n        acc_train_history = []\n\n        for i, model in enumerate(self.models):\n            optimizer = torch.optim.Adam(model.parameters(), lr=lr[i])\n            criterion = nn.CrossEntropyLoss()\n            model.to(device)\n            model_losses = []\n            model_test_acc = []\n            model_train_acc = []\n\n            model.train()\n\n            poor_results = 0\n\n            for epoch in range(epochs[i]):\n                #TRAIN\n                train_loss = 0\n                train_correct = 0\n                test_correct = 0\n                if smartmode:\n                    if poor_results > 10:\n                        model_losses.append(model_losses[-1])\n                        model_train_acc.append(model_train_acc[-1])\n                        model_test_acc.append(model_test_acc[-1])\n                        continue\n\n                for j, (image, label) in enumerate(train_loader):\n                    image, label = image.to(device), label.to(device)\n                    optimizer.zero_grad()\n                    output = model(image)\n                    loss = criterion(output, label)\n                    loss.backward()\n                    optimizer.step()\n                    train_loss += loss.item()\n\n                    pred = output.argmax(dim=1, keepdim=True)\n                    train_correct += pred.eq(label.view_as(pred)).sum().item()\n                    print(f'<{j}\/{len(train_loader)}><{i}>', end='\\r')\n                #TEST\n\n                model.eval()\n                for image, label in test_loader:\n                    image, label = image.to(device), label.to(device)\n                    output = model(image)\n                    pred = output.argmax(dim=1, keepdim=True)\n                    test_correct += pred.eq(label.view_as(pred)).sum().item()\n\n                train_acc = train_correct*100\/len(train_loader.dataset)\n                test_acc = test_correct*100\/len(test_loader.dataset)\n                print(f\"Model-[{i}] [{epoch}\/{epochs[i]}] - Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}% | Test Acc: {test_acc:.4f}%\")\n\n                model_losses.append(train_loss)\n                model_train_acc.append(train_acc)\n                model_test_acc.append(test_acc)\n\n\n                if save_model:\n                    if save_best:\n                        if (model_test_acc[-1]) >= max(model_test_acc):\n                            torch.save(model, f=f'Best_Model_{i}')\n                            if self.verbose:\n                                print('Save best!')\n                                poor_results = 0\n                        else:\n                            poor_results += 1\n                            if poor_results > 10:\n                                print('Overfitting... skip!')\n\n            loss_history.append(model_losses)\n            acc_train_history.append(model_train_acc)\n            acc_test_history.append(model_test_acc)\n            if save_model:\n                torch.save(model, f=f'Model_{i}')\n                if self.verbose:\n                    print('Save!')\n        print(f'{i+1} model successful train...')\n\n        if make_plot:\n            #Train loss\n            plt.figure(figsize=(30, 10), facecolor='0.3')\n            for i in range(len(self.models)):\n                plt.subplot(1, len(self.models), i+1)\n                plt.plot(range(len(loss_history[i])), loss_history[i])\n                plt.title(f'Train Loss {i} Model')\n\n            #Train acc\n            plt.figure(figsize=(30, 10), facecolor='0.3')\n            for i in range(len(self.models)):\n                plt.subplot(1, len(self.models), i+1)\n                plt.plot(range(len(acc_train_history[i])), acc_train_history[i])\n                plt.title(f'Train Acc {i} Model')\n\n            #Test acc\n            plt.figure(figsize=(30, 10), facecolor='0.3')\n            for i in range(len(self.models)):\n                plt.subplot(1, len(self.models), i+1)\n                plt.plot(range(len(acc_test_history[i])), acc_test_history[i])\n                plt.title(f'Test Acc {i} Model')\n        self.history = (loss_history, acc_train_history, acc_test_history)\n        self.device = device\n        print('Complete!')\n        print(f\"---------------------------<END - {datetime.datetime.now()}>---------------------------\")\n\n    def eval_all(self, test_loader, shape = [32, 10]):\n\n        correct = 0\n\n        for image, labels in test_loader:\n            output = torch.zeros(shape)\n            image, labels, output = image.to(self.device), labels.to(self.device), output.to(self.device)\n            for model in self.models:\n                model.to(self.device)\n                output += model(image)\n            predict = output.argmax(dim=1)\n            correct += predict.eq(labels.view_as(predict)).sum().item()\n        acc = correct*100\/len(test_loader.dataset)\n        if self.verbose:\n            print(f'Ensemble Accuracy: {acc:.4f}%')\n        return acc","31946c2f":"model1 = MiddleHeadCNN()\nmodel2 = RightHeadCNN()\nmodel3 = LeftHeadCNN()\n\n\nMODELS = (model1, model2, model3)\nEPOCHS = (150, 150, 150)\nLR = (1e-3, 1e-3, 1e-3)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","2337b37e":"ensemble = Ensemble(MODELS, verbose=True)","91c6ff61":"ensemble.train_all(train_loader=train_loader,\n                   test_loader=test_loader,\n                   epochs=EPOCHS,\n                   lr=LR,\n                   device=device,\n                   make_plot=True,\n                   save_model=True,\n                   save_best=True)","58370eea":"ensemble.load_models() # Upload the best weights for each model\n\nensemble.eval_all(test_loader=test_loader)","4a71bc37":"# Result - ","dfab6477":"### Models","785141b8":"# **Define Train and Test Loaders**","d51d51dd":"# **Read data**","eebaa80b":"### Preparation","fdc2f167":"# **Hyperparameters**","2872a540":"# **Define Models and Ensemble**","60ec3b0f":"# **Calculate accuracy**","ab8e1cea":"# **Libraries**","05ae06ec":"# **View Data**","0dfbd2df":"### Ensemble","0d51ba7b":"# **Train**"}}