{"cell_type":{"b2a10fd8":"code","2e95e21f":"code","2f3c3e94":"code","d5d47a1b":"code","1a53e244":"code","2a59f498":"code","88569a58":"code","b444c9f2":"code","a277acb8":"code","ccabbe99":"code","a24711e1":"code","fc48d8b5":"code","e31840ea":"code","4ca2e6bb":"code","00f459cc":"code","be0c8be1":"code","6e22c683":"code","0d18a28d":"code","7a372fc9":"code","6a0e3e33":"code","80a8d515":"code","cf9c755a":"code","191bab0b":"code","dde70678":"markdown","80a96ddf":"markdown","719ceeb1":"markdown","a3ec2e98":"markdown","1e16ca8c":"markdown"},"source":{"b2a10fd8":"!pip install efficientnet_pytorch","2e95e21f":"import numpy as np \nimport pandas as pd \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torchvision\nimport torchvision.models as models # resnet18 pretrained model\nimport librosa # for feature extraction\nimport scipy # to load wav files\nfrom efficientnet_pytorch import EfficientNet","2f3c3e94":"import warnings\nwarnings.filterwarnings('ignore')","d5d47a1b":"input_path = '\/kaggle\/input\/'","1a53e244":"train_df = pd.read_csv('\/kaggle\/input\/birdsong-recognition\/train.csv')","2a59f498":"train_df = train_df[(train_df.filename != 'XC395021.mp3') & (train_df.filename != 'XC504005.mp3') & (train_df.filename != 'XC504006.mp3') & (train_df.filename != 'XC505006.mp3')]","88569a58":"import os\nwav_folders = [\n    'birdsong-wav-1',\n    'birdsong-wav-2',\n    'birdsong-wav-3',\n    'birdsong-wav-4',\n    'birdsong-wav-5',\n]\nbird_folder = {\n    bird: folder for folder in wav_folders for bird in os.listdir(os.path.join(input_path, folder)) \n}","b444c9f2":"row = train_df.iloc[0]\nebird_code = row.ebird_code\nfile_name = row.filename\nfile_path = f'{input_path}\/{bird_folder[ebird_code]}\/{ebird_code}\/{file_name.replace(\"mp3\", \"wav\")}'\nsr, audio = scipy.io.wavfile.read(file_path)\nif len(audio.shape) == 2:\n    audio = audio[:, 0]","a277acb8":"import IPython.display as ipd\nipd.Audio(file_path)","ccabbe99":"bird_codes = sorted(list(set(train_df['ebird_code'])))\nbird_to_idx = { bird: idx for idx, bird in enumerate(bird_codes) }","a24711e1":"class Dataset(data.Dataset):\n\n    def __init__(self, df):\n        self.df = df\n\n    def __getitem__(self, index):\n\n        row = self.df.iloc[index]\n        ebird_code = row.ebird_code\n        file_name = row.filename\n        file_path = f'{input_path}\/{bird_folder[ebird_code]}\/{ebird_code}\/{file_name.replace(\"mp3\", \"wav\")}'\n        sr, audio = scipy.io.wavfile.read(file_path)\n        if len(audio.shape) == 2:\n            audio = audio[:, 0]\n        i = np.random.randint(len(audio) - 480000) if len(audio) > 480000 else 0\n        audio = audio[i:i+480000].astype('float')\n        audio = np.pad(audio, (0, 480000 - len(audio)))\n        # Generate a melspectrogram with 256 mels.\n        mel = librosa.feature.melspectrogram(audio, sr=sr, n_mels=256)\n        mel = (mel - mel.mean()) \/ (mel.std() + 1e-12)\n        mel = mel[None, ...]\n        return mel, bird_to_idx[row['ebird_code']]\n\n    def __len__(self):\n        return len(self.df)","fc48d8b5":"import sklearn.utils as utils \ntrain_df = utils.shuffle(train_df, random_state=42)","e31840ea":"train_df.shape","4ca2e6bb":"train_dataset = Dataset(df=train_df.iloc[:20000].reset_index(drop=True))\nval_dataset = Dataset(df=train_df.iloc[20000:].reset_index(drop=True))","00f459cc":"train_dataloader = data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=12, num_workers=2, pin_memory=True)\nval_dataloader = data.DataLoader(dataset=val_dataset, shuffle=True, batch_size=6, num_workers=2, pin_memory=True)","be0c8be1":"class MyModel(nn.Module):\n\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # Convert 1 channel to 3 channel to be able to send to resnet18\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, padding=1)\n        self.base_model = EfficientNet.from_pretrained('efficientnet-b2')\n        self.fc2 = nn.Linear(1000, 264) # 264 different birds\n\n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.base_model(x)\n        x = self.fc2(x)\n        \n        return x\n        \n","6e22c683":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel = MyModel().to(device)","0d18a28d":"def get_accuracy(y_pred, y_actual):\n    y_pred_ = y_pred.argmax(1).detach().cpu().numpy()\n    y_actual_ = y_actual.numpy()\n    \n    return np.mean(y_pred_ == y_actual_) * 100.0","7a372fc9":"criterion = nn.CrossEntropyLoss()","6a0e3e33":"opt = torch.optim.Adam(model.parameters(), lr=0.0001)","80a8d515":"EPOCHS = 5","cf9c755a":"running_acc = 0\nfor epoch in range(0, EPOCHS):\n    print('\\nTraining: \\n')\n    model.train()\n    for b, (x, y) in enumerate(train_dataloader):\n\n        opt.zero_grad()\n\n        y_pred = model(x.to(device))\n        loss = criterion(y_pred, y.to(device))\n        loss.backward()\n\n        opt.step()\n        \n        acc = get_accuracy(y_pred, y.cpu())\n        \n        running_acc = running_acc * 0.9 + acc * 0.1\n\n        print('\\rEpoch: {}\/{}, \\\n        batch: {}\/{}, \\\n        loss: {:4f}, \\\n        running_acc: {:.4f}'.format(epoch+1, EPOCHS, b+1, len(train_dataloader), loss.item(), running_acc),  end=' ')\n    \n    print('\\nValidation: \\n')\n    running_acc = 0\n    mean_acc = 0\n    model.eval()\n    for b, (x, y) in enumerate(val_dataloader):\n\n\n        y_pred = model(x.to(device))\n\n        loss = criterion(y_pred, y.to(device))\n        acc = get_accuracy(y_pred, y)\n\n        running_acc = running_acc * 0.9 + acc * 0.1\n        mean_acc = mean_acc + acc\n\n        print('\\rbatch: {}\/{}, \\\n        loss: {:4f}, \\\n        acc: {:.4f}'.format(b+1, len(val_dataloader), loss.item(), running_acc),  end=' ')\n    mean_acc \/= len(val_dataloader)\n    print('Mean accuracy: ', mean_acc)","191bab0b":"torch.save(model.state_dict(), 'birdsong_model.pth')","dde70678":"Unfortunately for some reason the following file names are not present in the converted dataset (maybe some conversion error).","80a96ddf":"Save model after training","719ceeb1":"Keep 20000 for train, and 1371 for validation","a3ec2e98":"I have converted the mp3 files to wav files using the mpg123 command and and uploaded as 5 different datasets (it was too large to fit in a single dataset). Have used melspectrogram features to train a resnet18 model. You can try other features\/model to get good results.","1e16ca8c":"I was not able to put all the wav files inside a single dataset, so I have used 5 datasets of about 30GB each. The following code will map each bird folder to one of the five datasets."}}