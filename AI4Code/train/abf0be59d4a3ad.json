{"cell_type":{"c0c3da39":"code","3aeb9024":"code","0a9b8bd7":"code","c578a333":"code","78eb46bb":"code","39526f0a":"code","572ac519":"code","520cb009":"code","b72e8094":"code","d20c42f6":"code","1bd25b4f":"code","0b309ff1":"code","04b8edff":"code","7790c3b9":"code","6aa64779":"code","5ba503f8":"code","6fa8c9a9":"code","14478f37":"code","334050bc":"code","9973296c":"code","c5ea997f":"code","17889e6b":"code","ba9e111d":"code","4054c9ac":"code","7a9fa248":"code","335d61f1":"code","519ac122":"code","3871d9ad":"code","1d27f5c3":"code","6df1f910":"markdown","73480f04":"markdown","222a2f86":"markdown","43758858":"markdown","b7c5b5ee":"markdown","b3d3b0d8":"markdown","2b5ff0b4":"markdown","88b726d6":"markdown","b3f0f795":"markdown","24a5fced":"markdown","171702b7":"markdown","c9eaa90a":"markdown","e3a36798":"markdown","aab56771":"markdown"},"source":{"c0c3da39":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Dense, Dropout\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nimport keras","3aeb9024":"train_data = pd.read_csv(\"..\/input\/train.csv\")","0a9b8bd7":"train_data.head()","c578a333":"train_data.shape","78eb46bb":"images = train_data.iloc[:,1:].values\nlabels = train_data.iloc[:,0].values","39526f0a":"def show_image(number):\n    image = images[number]\n    plt.axis('off')\n    plt.imshow(image.reshape(28,28))\n    plt.title(labels[number])","572ac519":"show_image(24)","520cb009":"show_image(890)","b72e8094":"show_image(32190)","d20c42f6":"X_train, X_val, Y_train, Y_val = train_test_split(images, labels, test_size=0.2, random_state=0)\nprint(\"Length of X_train:\", len(X_train))\nprint(\"Length of Y_train:\", len(Y_train))\nprint(\"Length of X_val:\", len(X_val))\nprint(\"Length of Y_train:\", len(Y_val))","1bd25b4f":"X_train = X_train.reshape(-1,28,28,1)\nX_val = X_val.reshape(-1,28,28,1)","0b309ff1":"Y_train_one_hot = np_utils.to_categorical(Y_train, 10)\nY_validation_one_hot = np_utils.to_categorical(Y_val, 10)","04b8edff":"classifier = Sequential()\n\nclassifier.add(Convolution2D(16,3,3, input_shape=(28,28,1), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Convolution2D(32,3,3, input_shape=(28,28,1), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Flatten())\n\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(output_dim = 64, activation='relu'))\nclassifier.add(Dense(output_dim = 10, activation='softmax'))\n\nclassifier.summary()\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=False)\ntrain_set = train_datagen.flow(X_train, Y_train_one_hot, batch_size=32)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_set = validation_datagen.flow(X_val, Y_validation_one_hot, batch_size=32)\n\n\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nclassifier.fit_generator(train_set,\n                    steps_per_epoch=33600,epochs=5,\n                    validation_data=(validation_set), validation_steps=8400, shuffle=True)","7790c3b9":"X_test = pd.read_csv(\"..\/input\/test.csv\")\nX_test.head()","6aa64779":"X_test = X_test.iloc[:,:].values","5ba503f8":"X_test = (X_test)*1.\/255","6fa8c9a9":"X_test = X_test.reshape(-1,28,28,1)","14478f37":"predictions = classifier.predict(X_test)","334050bc":"predictions = np.argmax(predictions,axis = 1)","9973296c":"ImageId = np.arange(1,28001)","c5ea997f":"test_images = X_test\ntest_labels = predictions","17889e6b":"def show_test_image(number):\n    test_image = test_images[number]\n    plt.axis('off')\n    plt.imshow(test_image.reshape(28,28))\n    plt.title(\"Predicted:{}\".format(test_labels[number]))","ba9e111d":"show_test_image(54)","4054c9ac":"show_test_image(3439)","7a9fa248":"show_test_image(15439)","335d61f1":"Label = predictions","519ac122":"submission = pd.DataFrame()","3871d9ad":"submission['ImageId'] = ImageId\nsubmission['Label'] = Label","1d27f5c3":"submission.to_csv(\"MNIST2.csv\",index=False)","6df1f910":"We check the first few rows of our pandas dataframe containing the training data.","73480f04":"I predict the test images using predict.","222a2f86":"In the below images, the values are mentioned on top of the images.","43758858":"Keras has the functionality to one-hot encode the labels using to_categorical.","b7c5b5ee":"I load the values of the pandas dataframe into a variable. \nimages contain only the images and leaving out the first column which are the labels.\nlabels contain only the labels hence we select only the first column and all the rows.","b3d3b0d8":"We try to plot an image so as to get a visual representation of the data.","2b5ff0b4":"We start by importing the required libraries into our notebook.","88b726d6":"I make our model here. Since the images will be fed in sequentially, we use a Sequential classifier. \nI add the first Convolution2D layer which gives 16 feature maps using a filter of size 3x3. \nA MaxPooling2D layer is used next with the pool size of 2x2.\n\nSimilarly another Convolution2D and MaxPooling2D layers are added.\nNext a dense layer or a hidden layer is added with 64 neurons.\nWe use the next dense layer with 10 neurons at the output as we expect 10 probabilistic values.\nI rescale the training and validation pixel values by 1.\/255 in order to obtain normalization.\nThen we fit our model. I use the standard adam optimizer.","b3f0f795":"The shape shows the number of rows and number of columns that is 42000 rows and 785 columns.","24a5fced":"Convolution2D accepts a 4D input. As the image is of size 28x28, we add dimensions.","171702b7":"MNIST is a dataset of handwritten digits between 0 and 9. The images are in train.csv with each row containing an image. There are 784 columns with each column indicating a pixel. As a result each image is of size 28x28 (widthxheight). The first column of train.csv are the image labels.","c9eaa90a":"Now I load the test file.","e3a36798":"We load the training data ie. train.csv into a pandas dataframe.","aab56771":"We now split the training and validation data. We choose a 8:2 ratio for training and validation."}}