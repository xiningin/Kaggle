{"cell_type":{"3d97c21d":"code","e3cb1494":"code","2e3a493a":"code","e8015271":"code","7aae2458":"code","a5d7b3ba":"code","e4b6cd82":"code","ed81bdb9":"code","5927c01b":"code","50a03f33":"markdown","5812711d":"markdown","50030951":"markdown"},"source":{"3d97c21d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3cb1494":"!wget http:\/\/setup.johnsnowlabs.com\/colab.sh -O - | bash\n# !bash colab.sh\n# -p is for pyspark\n# -s is for spark-nlp\n# !bash colab.sh -p 3.1.1 -s 3.0.1\n# by default they are set to the latest\n\n# Install Spark NLP Display for visualization\n!pip install --ignore-installed spark-nlp-display","2e3a493a":"import json\nimport pandas as pd\nimport numpy as np\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nfrom sparknlp.annotator import *\nfrom sparknlp.base import *\nimport sparknlp\nfrom sparknlp.pretrained import PretrainedPipeline\n\nspark = sparknlp.start()","e8015271":"# If you change the model, re-run all the cells below\n# Other applicable models: ner_dl, ner_dl_bert\nMODEL_NAME = \"onto_100\"","7aae2458":"text_list = [\n    \"\"\"Bob Dylan (born Robert Allen Zimmerman; May 24, 1941) is an American singer-songwriter, author and visual artist.\n    Often regarded as one of the greatest songwriters of all time,\n    Dylan has been a major figure in popular culture during a career spanning nearly 60 years.\n    Much of his most celebrated work dates from the 1960s, when songs such as \"Blowin' in the Wind\" (1963)\n    and \"The Times They Are a-Changin'\" (1964) became anthems for the civil rights and anti-war movements.\"\"\"\n]","a5d7b3ba":"documentAssembler = DocumentAssembler() \\\n    .setInputCol('text') \\\n    .setOutputCol('document')\n\ntokenizer = Tokenizer() \\\n    .setInputCols(['document']) \\\n    .setOutputCol('token')\n\n# ner_dl and onto_100 model are trained with glove_100d, so the embeddings in\n# the pipeline should match\nif (MODEL_NAME == \"ner_dl\") or (MODEL_NAME == \"onto_100\"):\n    embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n        .setInputCols([\"document\", 'token']) \\\n        .setOutputCol(\"embeddings\")\n\n# Bert model uses Bert embeddings\nelif MODEL_NAME == \"ner_dl_bert\":\n    embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n        .setInputCols(['document', 'token']) \\\n        .setOutputCol('embeddings')\n\nner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n    .setInputCols(['document', 'token', 'embeddings']) \\\n    .setOutputCol('ner')\n\nner_converter = NerConverter() \\\n    .setInputCols(['document', 'token', 'ner']) \\\n    .setOutputCol('ner_chunk')\n\nnlp_pipeline = Pipeline(stages=[\n    documentAssembler, \n    tokenizer,\n    embeddings,\n    ner_model,\n    ner_converter\n])","e4b6cd82":"def run_pipeline():\n    empty_df = spark.createDataFrame([['']]).toDF('text')\n    pipeline_model = nlp_pipeline.fit(empty_df)\n    df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n    return pipeline_model.transform(df)","ed81bdb9":"result = run_pipeline()","5927c01b":"from sparknlp_display import NerVisualizer\n\nNerVisualizer().display(\n    result = result.collect()[0],\n    label_col = 'ner_chunk',\n    document_col = 'document'\n)","50a03f33":"# Define the SparkNLP pipeline","5812711d":"# Run the pipeline","50030951":"# DL model selection"}}