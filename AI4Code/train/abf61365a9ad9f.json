{"cell_type":{"2b63240f":"code","7de7e54b":"code","482a917f":"code","d8b4d6aa":"code","d4d7f86d":"code","03c68a20":"code","76f87fae":"code","ad930525":"code","36e22860":"code","abf4bd31":"code","b1f58104":"code","3a1b84ac":"code","b80d1326":"code","615cc9b5":"code","339ddda1":"code","67aea1b4":"code","19d1e240":"code","ed957b8e":"code","7eaa908f":"code","5add591d":"code","e21e8d1f":"markdown","9337cec3":"markdown","4651bb22":"markdown","2e8feac5":"markdown","ff54137c":"markdown","eb90c3ad":"markdown","49f4adbd":"markdown","0d82e978":"markdown","ea324e0d":"markdown","ae47cf8c":"markdown","9f526716":"markdown","161c7ec9":"markdown","dc3bb620":"markdown","aab7ee83":"markdown","63279c2c":"markdown","6320a2a1":"markdown","5acebd51":"markdown","5720c7b1":"markdown","bae75483":"markdown","bcf5470a":"markdown","e97ba76c":"markdown","5fb89a3f":"markdown","4e4c1e5b":"markdown"},"source":{"2b63240f":"# import the necessary libray\nimport numpy as np  # for scientific Calculation\nimport pandas as pd # perform dataframe Operation\nimport matplotlib.pyplot as plt #plot visualization\nimport tensorflow as tf\nimport zipfile\nimport os\nimport datetime\nimport seaborn as sns\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nimport tensorflow_addons as tfa","7de7e54b":"flower_dataset = '..\/input\/flowers-recognition'\n#In this flower_dataset we have a subfolder flowers inside the flowers subfolder have flower Images and the class Label\nflower_path = os.path.join(flower_dataset,os.listdir(flower_dataset)[0])\n#list how many class label present in the dataset \nprint(\"Class Labels in the dataset : {0}\".format(os.listdir(flower_path)))","482a917f":"#we have Five Class in the dataset, Let's see how many flowers in each Class\ndef flower_count(base_path):\n    \"\"\"\n    basepath - flower Folder path\n    return - dict {class_label :count(image)}\n\n  \"\"\"\n    flower_classes = os.listdir(base_path)\n\n    class_count = dict()\n    for class_label in flower_classes:\n    #Join the Current Flower path and counting length of class label\n        class_count[class_label] = len(os.listdir(os.path.join(base_path , class_label)))\n    return class_count \n\nclass_count = flower_count(flower_path)  \n","d8b4d6aa":"class_count","d4d7f86d":"#Reference\/Credits: https:\/\/towardsdatascience.com\/mastering-the-bar-plot-in-python-4c987b459053\n#Let's see Howmany classes in each label\n#Each Class Values \nclass_count_values = list(class_count.values())\nclass_label = list(class_count.keys())\nplt.figure(figsize = (10,10))\n# Passing the parameters to the bar function, this is the main function which creates the bar plot\nplt.barh(class_label, class_count_values, align='center')\n\n# Creating the legend of the bars in the plot\nplt.legend(labels = ['count'])\n# Giving the tilte for the plot\nplt.title(\"Class Distribution\")\n# Namimg the x and y axis\nplt.xlabel('Classes')\nplt.ylabel('Count')\n# Saving the plot as a 'png'\nplt.savefig('1BarPlot.png')\n# Displaying the bar plot\nplt.show()","03c68a20":"#lets's see the percentage of Each class label\nclass_count_values = np.array(class_count_values)\nclass_label = np.array(class_label)\ntotal_flower = np.sum(class_count_values)\nprint(\"...Total No of Flowers :{0}.....\".format(np.sum(class_count_values)))\n\nfor i in range(len(class_label)):\n    print(\"{0} Flower  is distributed as percentage : {1}\".format(class_label[i],(class_count_values[i]\/total_flower) * 100))\n","76f87fae":"#initialize x and y to add the image as numpy\n#x = np.zeros_like((len(class_count_values)))\n#y = np.zeros_like(len(class_count_values))\nimport tqdm\nimport cv2\n\n\ndef data_preparation(base_dir,flower_type,target_image_size):\n  \n    \"\"\"\n    base_dir - Image Base directory \n    flower_type - class label Eg: tulip\n    target_image_size - resize of the image \n    return -  converted image array and class label\n      \"\"\"\n  #initalize x and y to st\n    x,y = [],[]\n    class_path = os.path.join(base_dir,flower_type)\n  \n    for image in tqdm.tqdm(os.listdir(class_path)):\n    \n        image_path = os.path.join(class_path,image)\n        #read the image #cv2.IMREAD_color for RGB image\n        img = cv2.imread(image_path,cv2.IMREAD_COLOR)\n        #resize the image\n        img = cv2.resize(img, (target_image_size,target_image_size))\n\n        x.append(np.array(img))\n\n        y.append(str(flower_type))\n\n    return(x,y)","ad930525":"X_data,y_data = [],[]\n#base_path is a flower dataset\nprint(\"Flower Path : {0}\".format(flower_path))\nfor label in class_label:\n    print(\"Flower Label :{0}\".format(label))\n    x,y = data_preparation(flower_path,label,256)\n    X_data.extend(x)\n    y_data.extend(y)  \nX_data = np.array(X_data)\ny_data = np.array(y_data)","36e22860":"print(\"Total No of Data : {0}\".format(len(X_data)))\nprint(\"Shape of the image : {0}\",format(X_data[0].shape))","abf4bd31":"import random as rn\n\n#plot the image Randomly\n\ndef plot_image(row,column,inches,x_data,y_data):\n  \n    fig,ax=plt.subplots(row,column)\n    fig.set_size_inches(inches,inches)\n\n    for i in range(row):\n        for j in range (column):\n            l=rn.randint(0,len(y_data))\n            ax[i,j].imshow(x_data[l])\n            ax[i,j].set_title('Flower: '+y_data[l])\n    \n    plt.tight_layout()\nrow,column = 5,2\ninches = 20\nplot_image(row,column,inches,X_data,y_data)","b1f58104":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n#normalize the data all data lies in the 0 to 1\n\ny_data = LabelEncoder().fit_transform(y_data)\ny_data = tf.keras.utils.to_categorical(y_data ,5)\n","3a1b84ac":"seed = 100\nnp.random.seed(seed)\nnp.random.shuffle(X_data)\nnp.random.seed(seed)\nnp.random.shuffle(y_data)","b80d1326":"from sklearn.model_selection import train_test_split\n# split the Data into train and test \nx_train,x_test,y_train,y_test = train_test_split(X_data,y_data,random_state = 42, test_size = 0.1)\nprint(\"Training Shape Of the Dataset : {0}\".format(x_train.shape))\nprint(\"Test Shape Of the Dataset: {0}\".format(x_test.shape))bb","615cc9b5":"batch_size = 32\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.4,\n    height_shift_range=0.4,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True\n)\n\n# Note that the validation data should not be augmented!\nval_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n)\n\n# Flow training images in batches of 32 using train_datagen generator\ntrain_generator = train_datagen.flow(\n    x_train,\n    y_train,\n    batch_size=batch_size\n)\n\nval_generator = val_datagen.flow(\n    x_test,\n    y_test,\n    batch_size=batch_size\n)","339ddda1":"tf.keras.backend.clear_session()\n#we create a model using sequential api\nmodel = Sequential([Conv2D(16 , (3,3),activation = \"relu\" ,input_shape = (256,256,3),kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    MaxPooling2D(2,2),\n                    Conv2D(32 ,(3,3), activation = \"relu\" ,padding = \"same\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    MaxPooling2D(2,2),\n                    Conv2D(64 ,(3,3),activation = \"relu\" ,padding = \"same\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    MaxPooling2D(2,2),\n                    Conv2D(128 ,(3,3),activation = \"relu\" ,padding = \"same\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    MaxPooling2D(2,2),\n                    Conv2D(256 ,(3,3),activation = \"relu\" ,padding = \"same\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    MaxPooling2D(2,2),\n                    Flatten(),\n                    Dense(1024 , activation = \"relu\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    Dense(512 ,activation=\"relu\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    Dense(256 , activation = \"relu\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    Dense(128 , activation = \"relu\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3)),\n                    Dropout(0.2),\n                    Dense(5,activation = \"softmax\",kernel_initializer=tf.keras.initializers.glorot_normal(seed=3))\n])","67aea1b4":"model.summary()","19d1e240":"tf.keras.utils.plot_model(model,show_shapes = True)","ed957b8e":"epochs = 75\n#using Adam Optimizer and Loss a Categorial loss\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',tfa.metrics.F1Score(num_classes = 5)]) \nmodel_history = model.fit_generator(\n    generator=train_generator, \n    steps_per_epoch=len(x_train)\/batch_size,   \n    epochs=epochs, \n    validation_steps=len(x_test)\/batch_size, \n    validation_data=val_generator\n)\n","7eaa908f":"#After training the custom model see the accuracy and loss performance\nacc = model_history.history['acc']\nval_acc = model_history.history['val_acc']\nepochs = range(len(acc))\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","5add591d":"loss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\nepochs = range(len(acc))\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validating Loss')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","e21e8d1f":"# 3.4 Convert the Categorical Input","9337cec3":"At End of the Training Stage we  Get Validation Accuracy - 83% and F1 Score - 82.15%","4651bb22":"### 2.2.1. Type of Machine Learning Problem","2e8feac5":"## 3.2 Percentage of the Each Class Label","ff54137c":"# 5 Conclusion","eb90c3ad":"# Plot the Model History ","49f4adbd":"# 3.1 Checking Imbalaceness in the Data","0d82e978":"# Image Augmentation and Normalization","ea324e0d":"All the Classes is distributed as same There is no imbalance in the Data","ae47cf8c":"### 2.3 Machine Learning Objective and Constraint\n\nObjective : Our Objective is to classify the images which belongs to the five classes\n","9f526716":"### 2.2.2 Performance Metric \n\n    1. Accuracy\n    2.F1 Score","161c7ec9":"# 3. Import Library and Simple Exploratory Data Analysis","dc3bb620":"There are Five different classes of Flower images we need to classifify a given image - this problem state as Multi classs Classification Problem ","aab7ee83":"# 2.Mapping the Real world Problem","63279c2c":"# Train a model","6320a2a1":"### Custom Model","5acebd51":"# 2.3 Train and Test Dataset\n\nsplit the dataset Randomly into 2 parts train and test with 90% and 10% ","5720c7b1":"# Flower Classification","bae75483":"# Train Test Split","bcf5470a":"\n# 4. Construct Model ","e97ba76c":"Classify Images With Different Types of Flowers this dataset contains 4242 images of flowers.\n","5fb89a3f":"### 1.1 Problem Statement  ","4e4c1e5b":"# 3.3 Data Preparation"}}