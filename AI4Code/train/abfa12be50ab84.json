{"cell_type":{"79b12c19":"code","f9909225":"code","df19e2a4":"code","e7b19932":"code","d07915c7":"code","c9aad56e":"code","a0ec137e":"code","96400b9c":"code","c1085348":"code","dd5813c3":"code","83f906af":"code","77714aaf":"code","0cbfaa79":"code","a64f209c":"code","421b0920":"code","120eb054":"code","6cd86b46":"code","dd59e927":"code","50508d47":"code","364a37bc":"code","84c0aa6a":"code","753167ac":"code","fd8a4dbe":"code","535074f0":"code","482c8d7e":"code","eb1012be":"code","a3001136":"code","9e8186f0":"code","6927b2a0":"code","75186b76":"code","473ea9f5":"code","fdecc856":"markdown","a8f020a4":"markdown","4cb24338":"markdown","9642a1cd":"markdown","15fef379":"markdown","1c64b460":"markdown","7faaab41":"markdown","7aed705e":"markdown","db53a2e1":"markdown","3f0437e9":"markdown","5060710b":"markdown","0fd2dfef":"markdown","b7916fae":"markdown","e769da25":"markdown","0ddd5772":"markdown","4940e915":"markdown","11b2d6ae":"markdown","e719b9e0":"markdown"},"source":{"79b12c19":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\nfrom tensorflow.keras.layers import SpatialDropout2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img","f9909225":"dir_ = Path('..\/input\/fire-dataset\/fire_dataset')\npng_filepaths = list(dir_.glob(r'**\/*.png'))","df19e2a4":"labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], png_filepaths))","e7b19932":"# Caminhos & labels...\nfilepaths = pd.Series(png_filepaths, name = 'File').astype(str)\nlabels = pd.Series(labels, name = 'Label')\n\n# Concatenando...\ndf = pd.concat([filepaths, labels], axis=1)\n\n# Mudando os nomes...\ndf['Label'].replace({\"non_fire_images\":\"nofire\",\"fire_images\":\"fire\"}, inplace=True)","d07915c7":"# Visualizando os dados do dataset em um barplot\nvc = df['Label'].value_counts()\nplt.figure(figsize = (9, 5))\nsns.barplot(x = vc.index, y = vc, palette = \"icefire\")\nplt.title(\"N\u00famero de imagens de cada categoria no Dataset de treino\", fontsize = 11)\nplt.show()","c9aad56e":"# Misturando o dataframe e resetando o index\ndf = df.sample(frac = 1, random_state = 83).reset_index(drop = True)\n\n# Resultado\ndf.head()","a0ec137e":"png_error = '..\/input\/fire-dataset\/fire_dataset\/non_fire_images\/non_fire.189.png'\ndf = df.loc[~(df.loc[:, 'Label'] == png_error), :]","96400b9c":"train_df, test_df = train_test_split(df, train_size = 0.9, random_state = 86)\n\ndisplay(train_df.head())\n\ntest_df.head()","c1085348":"# Visualizando os dados em ambos datasets\nprint('Dataset de treinamento:')\n\nprint(f'N\u00famero de imagens: {train_df.shape[0]}')\n\nprint(f'N\u00famero de imagens com fogo: {train_df[\"Label\"].value_counts()[0]}')\nprint(f'N\u00famero de imagens sem fogo: {train_df[\"Label\"].value_counts()[1]}\\n')\n      \nprint('Dataset de teste:')\n      \nprint(f'N\u00famero de imagens no dataset de teste: {test_df.shape[0]}')\nprint(f'N\u00famero de imagens com fogo: {test_df[\"Label\"].value_counts()[0]}')\nprint(f'N\u00famero de imagens sem fogo: {test_df[\"Label\"].value_counts()[1]}')","dd5813c3":"# convertendo a Label para formato n\u00famerico para teste posteriormente\nLE = LabelEncoder()\n\ny_test = LE.fit_transform(test_df[\"Label\"])","83f906af":"plt.style.use(\"dark_background\")","77714aaf":"# Observando as imagens do dataset de treino (fire)\nfigure = plt.figure(figsize=(10, 10))\nx = cv2.imread(train_df[\"File\"][986])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(train_df[\"Label\"][986])","0cbfaa79":"# Observando as imagens do dataset de treino (nofire)\nfigure = plt.figure(figsize=(10,10))\nx = cv2.imread(train_df[\"File\"][910])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(train_df[\"Label\"][910])","a64f209c":"# Observando as imagens do dataset de teste (fire)\nfigure = plt.figure(figsize = (10,10))\nx = cv2.imread(test_df[\"File\"][686])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(test_df[\"Label\"][686])","421b0920":"# Observando as imagens do dataset de teste (nofire)\nfigure = plt.figure(figsize=(10,10))\nx = cv2.imread(test_df[\"File\"][978])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(test_df[\"Label\"][978])","120eb054":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                    shear_range = 0.2,\n                                    zoom_range = 0.1,\n                                    rotation_range = 20,\n                                    width_shift_range = 0.1,\n                                    height_shift_range = 0.1,\n                                    horizontal_flip = True,\n                                    vertical_flip = True,\n                                    validation_split = 0.1)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","6cd86b46":"print(\"Preparando o dataset de treino...\")\ntraining_set = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = \"File\",\n    y_col = \"Label\",\n    target_size = (250, 250),\n    color_mode = \"rgb\",\n    class_mode = \"binary\",\n    batch_size = 32,\n    shuffle = True,\n    seed = 1,\n    subset = \"training\")\n\nprint(\"Preparando o dataset de valida\u00e7\u00e3o...\")\nvalidation_set = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = \"File\",\n    y_col = \"Label\",\n    target_size = (250, 250),\n    color_mode =\"rgb\",\n    class_mode = \"binary\",\n    batch_size = 32,\n    shuffle = True,\n    seed = 1,\n    subset = \"validation\")\n\nprint(\"Preparando o dataset de teste...\")\ntest_set = test_datagen.flow_from_dataframe(\n    dataframe = test_df,\n    x_col = \"File\",\n    y_col = \"Label\",\n    target_size = (250, 250),\n    color_mode =\"rgb\",\n    class_mode = \"binary\",\n    shuffle = False,\n    batch_size = 32)\n\nprint('Geradores de dados prontos!')","dd59e927":"CNN = Sequential()\n\nCNN.add(Conv2D(32, (3, 3), input_shape = (250, 250, 3), activation = 'relu'))","50508d47":"CNN.add(MaxPooling2D(pool_size = (2, 2)))","364a37bc":"CNN.add(Conv2D(32, (3, 3), activation = 'relu'))\nCNN.add(MaxPooling2D(pool_size = (2, 2)))","84c0aa6a":"CNN.add(Conv2D(64, (3, 3), activation = 'relu'))\nCNN.add(SpatialDropout2D(0.2))\nCNN.add(MaxPooling2D(pool_size = (2, 2)))","753167ac":"CNN.add(Conv2D(128, (3, 3), activation = 'relu'))\nCNN.add(SpatialDropout2D(0.4))\nCNN.add(MaxPooling2D(pool_size = (2, 2)))","fd8a4dbe":"CNN.add(Flatten())","535074f0":"# Camada de entrada\nCNN.add(Dense(units = 256, activation = 'relu'))\nCNN.add(Dropout(0.4))\n# Camada de saida (classifica\u00e7\u00e3o bin\u00e1ria)\nCNN.add(Dense(units = 1, activation = 'sigmoid'))\n# Callbacks\ncallbacks = [EarlyStopping(monitor = 'loss', mode = 'min', patience = 20, restore_best_weights = True)]\n\nprint(CNN.summary())","482c8d7e":"plot_model(CNN, to_file='CNN_model.png', show_layer_names = True , show_shapes = True)","eb1012be":"# Compila\u00e7\u00e3o\nCNN.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Inicio da contagem do tempo\nstart = dt.datetime.now()\n\n# Treinamento\nCNN_model = CNN.fit(training_set, epochs = 100, validation_data = validation_set, callbacks = callbacks)\n\n# Fim da Contagem do tempo\nend = dt.datetime.now()\ntime_CNN = end - start\nprint ('\\nTempo de treinamento e valida\u00e7\u00e3o: ', time_CNN)","a3001136":"acc = CNN_model.history['accuracy']\nval_acc = CNN_model.history['val_accuracy']\nloss = CNN_model.history['loss']\nval_loss = CNN_model.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","9e8186f0":"score = CNN.evaluate(test_set)\nprint(\"Test Loss:\", score[0])\nprint(\"Test Accuracy:\", score[1])","6927b2a0":"y_pred = CNN.predict(test_set)\ny_pred = np.round(y_pred)","75186b76":"print(classification_report(y_test, y_pred))","473ea9f5":"plt.figure(figsize = (6, 4))\n\nsns.heatmap(confusion_matrix(y_test, y_pred),annot = True)\nplt.title(\"Matriz de confus\u00e3o\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.show()","fdecc856":"###### Etapa 5 - Redes Neurais Densas\n\nPar\u00e2metros da ``RNA``:\n\n    Dense - Todos os neur\u00f4nios conectados\n    units - Quantidade de neur\u00f4nios que fazem parte da camada oculta\n    activation - Fun\u00e7\u00e3o de ativa\u00e7\u00e3o que ser\u00e1 inserida\n    Dropout - \u00e9 usado para diminuir a chance de overfitting (40% dos neur\u00f4nios de entrada s\u00e3o zerados)\n\nPar\u00e2metros do ``EarlyStopping``:\n\n    monitor - M\u00e9trica que ir\u00e1 ser monitorada\n    patience - N\u00famero de \u00e9pocas sem melhoras no modelo, ap\u00f3s estas \u00e9pocas o treinamento \u00e9 interrompido\n    restore_best_weights - Restaura os melhores pesos caso o treinamento seja interrompido","a8f020a4":"## 1. Importa\u00e7\u00f5es das bibliotecas","4cb24338":"## 3. Dividindo em conjuntos de treinamento e teste\n\nAgora precisamos converter nossos dados em conjuntos de treinamento e teste. Usaremos 90% das imagens como nossos dados de treinamento e testaremos nosso modelo nos 10% restantes com a fun\u00e7\u00e3o ``train_test_split`` do Scikit-learn.","9642a1cd":"###### Etapa 6 - Compila\u00e7\u00e3o e treinamento do modelo\n\nAgora que especificamos a arquitetura do modelo, iremos compilar o modelo para treinamento. Para isso, precisamos especificar a fun\u00e7\u00e3o de perda (o que estamos tentando minimizar), o otimizador (como queremos fazer para minimizar a perda) e a m\u00e9trica (como julgaremos o desempenho do modelo). Em seguida, chamaremos .fit para iniciar o treinamento do processo.\n\nPar\u00e2metros do ``compile``:\n\n    optimizer - descida do gradiente e descida do gradiente estoc\u00e1stica\n    loss - Fun\u00e7\u00e3o de perda (binary_crossentropy pois s\u00f3 h\u00e1 uma sa\u00edda)\n    metrics - M\u00e9trica de avalia\u00e7\u00e3o (obs - pode ser colocado mais de um)\n\nParam\u00eatros do ``fit``:\n\n    train_data - base de dados de treinamento\n    epochs - n\u00famero de \u00e9pocas\n    validation_data - base de dados de teste\n    callbacks - Utiliza\u00e7\u00e3o do EarlyStopping\n    validation_steps - n\u00famero de imagens para teste","15fef379":"## Detec\u00e7\u00e3o de Inc\u00eandios Florestais utilizando Redes Neurais Convolucionais\n\n<img src=\"https:\/\/media2.giphy.com\/media\/RuhIAu5P0LO7u\/giphy.gif?cid=ecf05e47qr2jh7mh57dfnvvct3bdqwxj2y4cb5tat96kufvr&rid=giphy.gif&ct=g\" width=\"480\" align=\"center\">\n\n\n#### Informa\u00e7\u00f5es sobre o Dataset:\n\n- Os dados foram coletados para treinar um modelo para distinguir entre as imagens que cont\u00eam fogo (imagens de fogo) e imagens regulares (imagens que n\u00e3o s\u00e3o de fogo), ent\u00e3o todo o problema \u00e9 de classifica\u00e7\u00e3o bin\u00e1ria.\n\n\n- Os dados s\u00e3o divididos em 2 pastas, a pasta fireimages cont\u00e9m 755 imagens de fogo ao ar livre, algumas delas cont\u00eam fuma\u00e7a, a outra n\u00e3o s\u00e3o imagens de fogo que cont\u00e9m 244 imagens da natureza (por exemplo: florestas, \u00e1rvores, gramas, rios, pessoas, lagos, animais, estradas e cachoeiras).\n\n\n- Observa\u00e7\u00e3o: os dados est\u00e3o distorcidos, o que significa que as 2 classes (pastas) n\u00e3o t\u00eam um n\u00famero igual de amostras, ent\u00e3o certifique-se de ter um conjunto de valida\u00e7\u00e3o com um n\u00famero igual de imagens por classe (por exemplo: 40 imagens de ambas classes de fogo e n\u00e3o fogo).\n\nO dataset se encontra na plataforma ``Kaggle`` no link abaixo:\n\n- https:\/\/www.kaggle.com\/phylake1337\/fire-dataset","1c64b460":"## 4. Observando as imagens","7faaab41":"###### Etapa 2 - Max Pooling\nRedu\u00e7\u00e3o do tamanho da imagem focando nas caracteristicas mais importantes\n\n    Defini\u00e7\u00e3o da matriz com o total de 4 pixels (2, 2)","7aed705e":"## 2. Criando o Dataframe","db53a2e1":"N\u00f3s precisamos remover a imagem 'non_fire.189.png' pois ela est\u00e1 com formato incompat\u00edvel","3f0437e9":"###### Etapa 3 - Camadas ocultas","5060710b":"Podemos observar que o nosso dataset de imagens est\u00e1 desbalanceado, assim como estava na descri\u00e7\u00e3o do dataset no kaggle.","0fd2dfef":"## 5. Pr\u00e9-processamento das imagens\nNesta parte iremos fazer o pr\u00e9-processamento das imagens da base de dados de treinamento usando o [ImageDataGenerator](https:\/\/keras.io\/api\/preprocessing\/image\/#imagedatagenerator-class), para a base de dados de teste iremos apenas fazer a normaliza\u00e7\u00e3o dos dados\n\nParam\u00eatros do ``ImageDataGenerator``:\n\n    rescale - Transforma o tamanho da imagem (normaliza\u00e7\u00e3o dos dados)\n    shear_range - Transforma\u00e7\u00f5es geometricas aleat\u00f3rias\n    zoom_range - Imagens que ser\u00e3o aplicadas o zoom\n    brightness_range - Grau da mudan\u00e7a do brilho (tupla ou lista)\n    rotation_range - grau da rota\u00e7\u00e3o da imagem\n    width_shift_range - Faixa da mudan\u00e7a da altura da imagem\n    height_shift_range - Faixa da mudan\u00e7a da largura da imagem\n    horizontal_flip - Girar as imagens horizontalmente\n    vertical_flip - Girar as imagens verticalmente\n    validation_split - Imagens que ficaram reservadas para valida\u00e7\u00e3o (0-1)","b7916fae":"## 7. Constru\u00e7\u00e3o do modelo (ConvNet)\n\nCNNs s\u00e3o um tipo espec\u00edfico de rede neural artificial bastante eficaz para classifica\u00e7\u00e3o de imagens pois s\u00e3o capazes de levar em considera\u00e7\u00e3o a coer\u00eancia espacial da imagem, ou seja, que pixels pr\u00f3ximos uns dos outros est\u00e3o frequentemente relacionados.\n\nA constru\u00e7\u00e3o de uma CNN come\u00e7a com a especifica\u00e7\u00e3o do tipo de modelo. Em nosso caso, usaremos um modelo ``Sequential``.\n\n<p><img src = \"https:\/\/i.ibb.co\/0jWhFsW\/ConvNet.png\" alt><\/p>","e769da25":"## 8. Hist\u00f3rico do treinamento do modelo\n\nPodemos observar como a precis\u00e3o melhora com o tempo, eventualmente se estabilizando. Correspondentemente, a perda diminui com o tempo. Parcelas como essas podem ajudar a diagnosticar o sobreajuste. Se tiv\u00e9ssemos visto uma curva ascendente na perda de valida\u00e7\u00e3o com o passar do tempo (uma forma de U no gr\u00e1fico), suspeitar\u00edamos que o modelo estava come\u00e7ando a memorizar o conjunto de teste e n\u00e3o generalizaria bem para novos dados.","0ddd5772":"## 6. Diret\u00f3rio das imagens de treinamento, valida\u00e7\u00e3o e teste\n\nAqui fazemos a divis\u00e3o das bases de imagens para treinamento, valida\u00e7\u00e3o e teste do modelo, para isso usamos o [flow_from_dataframe](https:\/\/keras.io\/api\/preprocessing\/image\/#flowfromdataframe-method)\n\nParam\u00eatros do ``flow_from_directory``:\n\n    dataframe - Dataframe contendo o diret\u00f3rio da imagem\n    x_col - Nome da coluna contendo o diret\u00f3rio das imagens\n    y_col - Nome da coluna contendo oque queremos prever\n    target_size - tamanho das imagens (lembrando que deve ser do mesmo tamanho da camada de entrada)\n    color_mode - Padr\u00e3o de cores RGB\n    class_mode - modo da classe bin\u00e1rio (Fire\/No Fire)\n    batch_size - tamanho do batch\n    shuffle - Embaralhar os dados \n    seed - semente aleat\u00f3ria opcional para o shuffle\n    subset - Subset dos dados sendo training e validation (apenas usado caso use validation_split no ImageDataGenerator) ","4940e915":"###### Etapa 1 - Convolution\nDetector de Caracter\u00edsticas e Mapa de Caracter\u00edsticas\n\n    N\u00famero de filtros (32)\n    Dimens\u00f5es do detector de caracter\u00edsticas (3, 3)\n    Defini\u00e7\u00e3o da altura\/largura e canais RGB (250, 250, 3)\n    Fun\u00e7\u00e3o de ativa\u00e7\u00e3o para retirar os valores negativos da imagem - 'relu'\n    Acelera\u00e7\u00e3o do processamento - BatchNormalization","11b2d6ae":"## 9. Visualizando resultados e gerando previs\u00f5es","e719b9e0":"###### Etapa 4 - Flattening\n    \n    Transforma\u00e7\u00e3o da matriz para um vetor para entrar na camada da Rede Neural Artificial"}}