{"cell_type":{"1e222e55":"code","b785b80b":"code","ee59f304":"code","3c82131a":"code","dc389542":"code","e641e7e4":"code","c41a300f":"code","55bb915c":"code","cb610f0a":"code","3845611c":"code","0f77b38a":"code","1ca6505b":"code","53dbd0b6":"code","26d645ba":"code","875b30f7":"code","02c17ee3":"code","215f4404":"code","73873955":"code","7d5fa6f8":"code","4e9f700c":"code","d58ad18d":"code","ca664c37":"code","6c32c8bb":"code","a423ca81":"code","2dc50c18":"code","c42875a8":"code","445f6b03":"code","4017e2e5":"code","48bd2058":"code","d7228b36":"markdown","b9af96e6":"markdown","a8999d82":"markdown","13115e39":"markdown","fc3d0dc2":"markdown","6ae0152a":"markdown","30dd40ef":"markdown","c1bbdc5f":"markdown","b7bd48e9":"markdown","76fc3ffe":"markdown","c13a3f77":"markdown","2ec216ab":"markdown","e95edcf1":"markdown","b2e7795b":"markdown"},"source":{"1e222e55":"{'name':'\u00c1lvaro Riob\u00f3o de Larriva',\n'start_date':'2021\/03\/09'}","b785b80b":"#--< main modules >--#\nimport numpy as np \nimport pandas as pd \nimport scipy as sp\nimport statsmodels.api as sm\nimport sklearn\n\n#--< visualization >--#\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#--< others >--#\nfrom datetime import datetime\nimport time\nfrom IPython.display import display \nimport pickle\nimport gc\n\nfor i in locals().copy():\n    try:\n        print(\"%s:\"%eval(i).__name__, eval(i).__version__)\n    except:\n        continue","ee59f304":"###----------------< START of 'iris_nb.ipynb'>---------------###","3c82131a":"from sklearn import datasets\niris_dict = datasets.load_iris()\nspecies_coded_dict = {k:v for k,v in enumerate(iris_dict['target_names'])}\n\n# Load iris dataframe.\ndata = pd.DataFrame(iris_dict['data'], columns=['sepal_length','sepal_width','petal_length','petal_width'])\ntarget = pd.DataFrame(iris_dict['target'], columns=['species'])\niris = pd.DataFrame.join(data, target)\n\n# Display info\nprint(iris_dict.keys())\nprint(\"\\nFeature_names:\", iris_dict['feature_names'])\nprint(\"\\nSpecies are coded as:\", species_coded_dict)\nprint(\"\\nNAN values:\\n%a\" %iris.isna().sum())\ndisplay(iris)\n","dc389542":"# Display plain information, types and main stats.\ndescr = iris.describe()\n\niris.info()\ndisplay(descr)\n\nqlabels = ['min','25%','50%','75%','max']\nqvalues = descr.loc[qlabels] # we keep quartile values from df description ","e641e7e4":"# Pairplot\nsns.pairplot(iris)","c41a300f":"# BOXPLOT\nfig ,ax = plt.subplots(figsize=(20,10))\niris.boxplot(by='species', ax=ax)","55bb915c":"# HISTOGRAMS\nprint(plt.style.available)\nwith plt.style.context('classic'):\n    data.hist(bins=20, figsize=(10,5))","cb610f0a":"# HEATMAP (upper triangle)\narray = iris.iloc[:,:-1].corr()\nsns.heatmap(array, mask=np.tril(array), annot=True, fmt=\".2f\", cmap=plt.cm.inferno, square=True)","3845611c":"# SEPAL & PETAL graphics\nsns.lmplot(x=\"sepal_width\", y=\"sepal_length\", hue=\"species\",data=iris)\nsns.lmplot(x=\"petal_width\", y=\"petal_length\", hue=\"species\",data=iris)","0f77b38a":"# TEST T-STUDENT: H0-> true diff in means=0 (two-sided test)\/ rejectable if p-value<0.05 at 95% confidence.\nfrom scipy.stats import ttest_ind\nprint(species_coded_dict)\n\nsetosa = iris.loc[iris['species']==0]\nversicolor = iris.loc[iris['species']==1]\nvirginica = iris.loc[iris['species']==2]\n\npw_ttest = ttest_ind(versicolor['petal_width'], virginica['petal_width']) \npl_ttest = ttest_ind(versicolor['petal_length'], virginica['petal_length'])\nsw_ttest = ttest_ind(versicolor['sepal_width'], virginica['sepal_width']) \nsl_ttest = ttest_ind(versicolor['sepal_length'], virginica['sepal_length'])\n\nprint('\\nVersicolor vs. Virginica: Ttest')\nprint('petal_width--->{}\\npetal_length--->{}'.format(pw_ttest, pl_ttest))\nprint('sepal_width--->{}\\nsepal_length--->{}'.format(sw_ttest, sl_ttest))\n\n## alternative=greater for 'sepal_width' (versicolor < virginica ?)\nfrom scipy.stats import t\n\nt_crit_95 = t.ppf(df=len(virginica)+len(versicolor)-2, q=0.95) #df=degrees_freedom\nt_crit_99 = t.ppf(df=len(virginica)+len(versicolor)-2, q=0.99)\nprint('t critical at 95% conf:{}'.format(t_crit_95), \n     '\\n(idem for 99%):{}'.format(t_crit_99))","1ca6505b":"# TEST CHI-SQUARE FOR INDEPENDENCE BETWEEN CATEGORICALS: \n'''\nH0 -> sample dists are the same (table-samples)-> so that distinct categories of a variable doesn't affect the other variable \n -> variables are independent \/\/ rejectable if p-value<0.05 at 95% confidence. '''\nfrom scipy.stats import chisquare, chi2, chi2_contingency\nfrom scipy.stats import distributions\n\n# CATEGORICAL MAPPING: We map our dataset into a new one with categorical variables matching each interquartile range.\ndef map_quartile_ranges(x, col):\n    if x<qvalues.loc['25%',col]:\n        catv = 'low'\n    elif x<qvalues.loc['50%',col]:\n        catv = 'low-average'\n    elif x<qvalues.loc['75%',col]:\n        catv = 'high-average'\n    else:\n        catv = 'high'\n    return catv\n\ndata_cat = data.copy()\nfor c in data.columns:\n    data_cat[c] = data[c].map(lambda x: map_quartile_ranges(x, c))\n\ndef chi2contingency_by_LemmaOrCol(lemma, one_col):\n    if lemma:\n        features = data_cat.loc[:,data_cat.columns.str.contains(lemma)] \n        \n    else:\n        features = data_cat.loc[:,:] if not one_col else pd.DataFrame(data_cat.loc[:,one_col]) \n        \n    iris_cat = pd.DataFrame.join(features, iris['species'].astype('object'))\n\n    contable = iris_cat.value_counts().unstack('species').fillna(0)\n    display(contable)\n    res = chi2_contingency(contable)\n    gc.collect()\n    return res\n\nchi2contingency_by_LemmaOrCol(lemma = None, one_col=\"sepal_width\") \n# check lemma = 'sepal','petal','length','width', None\n# check all columns separately for lemma=None","53dbd0b6":"from scipy.stats import chi2_contingency\n\nfor f in data.columns:\n    fig = plt.figure()\n    ax = fig.add_subplot()\n    ctab = pd.crosstab(iris['species'],iris[f])\n    sns.heatmap(ctab, ax=ax)\n    c, p, dof, expected = chi2_contingency(ctab,)\n    print(f,'p_value for test is:%f'%p)","26d645ba":"import statsmodels.formula.api as smf\nimport patsy\n\n\nrhs = \"C(species)\"  # independent, categorical\nlhs = \"sepal_width\" # dependent, numeric\n\nformula = lambda lhs,rhs: lhs + \"~\" + rhs   # formulas are handled by \"patsy\" module (.dmatrices)\n#C(variable, method) wrapper that var as cathegory for patsy.dmatrices || default: method='Treatment'\n\n\n\n# OLS: cannot do \"species~(any)\" or \"(any) + 1 ~ species\". It compares same-shape arrays (ONE-WAY)\n[ print(\"{}:\\n{}\\n\".format(lhs, smf.ols( formula(lhs , rhs) ,data=iris).fit().summary())) for lhs in data.columns]\n","875b30f7":"#--< scikit-learn imports >--#\nfrom sklearn.metrics import make_scorer, roc_curve, RocCurveDisplay, auc\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, label_binarize\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n","02c17ee3":"# DATA\/TARGET definitions\ndata = iris.drop(\"species\", axis=1)\ntarget = iris[\"species\"].values\n\nlabels = pd.Series([0,1,2])\nn_classes = len(labels)\n\n# SCALERS\nsc = StandardScaler()\ndata_sc = sc.fit_transform(data)\n\n#labenc = LabelBinarizer()\n#target = labenc.fit_transform(target)\n\n# TRAIN\/TEST split\nX_train, X_test, y_train, y_test = train_test_split(data_sc, target, \n                                                    test_size=0.3, random_state=1994)\n\n\n","215f4404":"# We define a function to evaluate all models in a dictionary.\ndef train_all_models(models_dict, train_now=True):\n    if train_now:\n        for k,m in models_dict.items():\n            start_time = time.time()\n            print('MODEL:%s'%k)\n            m.fit(X_train, y_train)\n            print(\"(model_runtime= %.2f s)\\n\"%(time.time() - start_time))\n    else: \n        print(\"Not training for now\")\n    return models_dict\n\ndef plot_predict_all_models(models_dict, kw_dict={'average':'weighted'}):\n    \"\"\"N=1 example:\n    y_pred = label_binarize(XGBc.predict(X_test), classes=labels)\n    res = roc_auc_score(y_test, y_pred, average=\"macro\", multi_class=\"ovo\")\n    print(res)\"\"\"\n    #lb = lambda arr: label_binarize(arr, classes=labels)\n    for k,m in models_dict.items():\n        y_pred = m.predict(X_test)\n        y_pred_bin = m.predict_proba(X_test) #label_binarize(y_pred, classes=labels)\n        print('MODEL :%s\\n'%k,\n              'AUC = %.3f\\n'%roc_auc_score(y_test, y_pred_bin, \n                                           average=kw_dict['average'], \n                                           multi_class=\"ovo\"),\n              'Acc= %.3f\\n'%accuracy_score(y_test, y_pred ),\n              'Prec= %.3f\\n'%precision_score(y_test, y_pred, \n                                             average=kw_dict['average']), \n              'Rec= %.3f\\n'%recall_score(y_test, y_pred, \n                                         average=kw_dict['average']),\n              'F1= %.3f\\n'%f1_score(y_test,y_pred, \n                                    average=kw_dict['average'])\n             )\n        \n        \n        fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n        axs.set_title(r\"ROC curve || Model: {}\".format(m.__repr__()))\n        axs.set_xlabel(\"FPR\") ; axs.set_ylabel(\"TPR\")\n        \n        \n        for c in range(n_classes):\n            fpr, tpr, thresholds = roc_curve(y_test, y_pred_bin[:,c], pos_label=c) \n            roc_auc = auc(fpr, tpr)\n            axs.plot(fpr, tpr, label=f\"class:{c} || AUC={roc_auc:.3f}\")\n            axs.plot([0,1], [0,1], color=\"navy\", linestyle='--')\n        fig.legend()\n\n","73873955":"## VANILLA MODELS\nLc = LogisticRegression()\nKNc = KNeighborsClassifier()\nDTc = DecisionTreeClassifier()\nRFc = RandomForestClassifier()\nSVc = SVC(probability=True)\nXGBc = XGBClassifier(objective=\"reg:logistic\",\n                     eval_metric=\"rmse\",\n                     use_label_encoder=False)  #objective=\"multi:softmax\", \"reg:logistic\", \"multi:softprob\" \/\/ probabilities=Trues ->(W!)\n\nmodels_vanilla = {\"Lc\" : Lc,\n             \"KNc\" : KNc,\n             \"DTc\" : DTc,\n             \"RFc\" : RFc,\n             \"SVc\" : SVc,\n             \"XGBc\" : XGBc}\n\n# TRAIN\nmodels_vanilla = train_all_models(models_vanilla, train_now=True)","7d5fa6f8":"# EVALUATION: VANILLA MODELS\nplot_predict_all_models(models_vanilla, kw_dict={'average':'weighted'})","4e9f700c":"%timeit\n## SEARCH FOR PARAMETERS GRIDSEARCHCV: CV MODELS || NOTE: Time + + + ...\nLc_kw = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n        'fit_intercept' : [True, False],\n        'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n        'class_weight' : ['balanced', None],\n        'multi_class': ['multinomial', 'ovr'],}\nLc_cv = GridSearchCV(Lc, Lc_kw, cv=4, ) \n\nKNc_kw = {'n_neighbors' : np.arange(1,7),\n          'weights' : ['uniform', 'distance'],\n          'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n          'leaf_size' : np.arange(10,30),\n          'p' : np.arange(1,3)\n         }\nKNc_cv = GridSearchCV(KNc, KNc_kw, cv=4, ) \n\nDTc_kw = {\"criterion\" : ['gini', 'entropy'],\n          \"splitter\" : [\"best\", \"random\"], \n          \"max_depth\" : [2,3,4,None],\n          \"min_samples_leaf\" : np.arange(1,9), \n          \"min_samples_split\": np.arange(2,5),\n          \"max_features\" : [\"sqrt\", \"log2\", None],\n          \"max_leaf_nodes\":[20, 30, None],\n          \"class_weight\" : ['balanced', None],\n          \"ccp_alpha\" : [0, 1]\n          }\nDTc_cv = GridSearchCV(DTc, DTc_kw, cv=4, ) \n\nRFc_kw = {\"n_estimators\" : [20,40], \n          \"criterion\" : ['gini','entropy'],\n          \"min_samples_leaf\" : np.arange(1, 7, 2), \n          \"min_samples_split\": np.arange(2, 3),\n          \"max_features\" : [\"sqrt\", \"log2\"], \n          \"max_depth\" : [3, 4, None],\n          \"max_features\" : [\"sqrt\", \"log2\"],\n          \"max_leaf_nodes\":[10, None],\n          \"class_weight\" : ['balanced', None],\n         }\nRFc_cv = GridSearchCV(RFc, RFc_kw, cv=3, )  \n\nSVc_kw = {\"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n          \"degree\": [2, 3, 4, 5],\n          \"gamma\" : [\"scale\", \"auto\"],\n          \"shrinking\" : [True, False],\n          \"C\" : [0.5, 1, 1.5, 2],\n          \"class_weight\" : ['balanced', None],\n         }\nSVc_cv = GridSearchCV(SVc, SVc_kw, cv=3, ) \n\nXGBc_kw = {'n_estimators' : [50, 100],\n    'max_depth' : [2, 3, 4],\n    'learning_rate' : [0.02, 0.05, 0.1],\n    'booster' : ['gbtree','gblinear','dart'],\n    'base_score' : [0.25, 0.5, 0.75, 1]}\n\nXGBc_cv = GridSearchCV(XGBc, XGBc_kw, cv=5 ) \n\nmodels_CV = {\"Lc\" : Lc_cv,\n             \"KNc\" : KNc_cv,\n             \"DTc\" : DTc_cv,\n             \"RFc\" : RFc_cv,\n             \"SVc\" : SVc_cv,\n             \"XGBc\" : XGBc_cv}\n\n# TRAIN\nmodels_CV = train_all_models(models_CV)","d58ad18d":"## EVALUATION AND PLOTTING: CV MODELS\nplot_predict_all_models(models_CV, kw_dict={'average':'weighted'})","ca664c37":"%timeit\n### HYPERPARAMETER TUNING: IMPROVED MODELS\nLc_imp = LogisticRegression(**models_CV['Lc'].best_params_) \nKNc_imp = KNeighborsClassifier(**models_CV['KNc'].best_params_)\nDTc_imp = DecisionTreeClassifier(**models_CV['DTc'].best_params_)\nRFc_imp = RandomForestClassifier(**models_CV['RFc'].best_params_)\nSVc_imp = SVC(**models_CV['SVc'].best_params_, probability=True)\nXGBc_imp =XGBClassifier(**models_CV['XGBc'].best_params_,\n                        probability=True,\n                        use_label_encoder=False,\n                        objective=\"reg:logistic\",\n                        eval_metric=\"rmse\")\n\n\nmodels_improved = {\"Lc\" : Lc_imp,\n             \"KNc\" : KNc_imp,\n             \"DTc\" : DTc_imp,\n             \"RFc\" : RFc_imp,\n             \"SVc\" : SVc_imp,\n             \"XGBc\" : XGBc_imp}\n\n# TRAIN\nmodels_improved = train_all_models(models_improved, train_now=True)","6c32c8bb":"## EVALUATION AND PLOTTING: IMPROVED MODELS\nplot_predict_all_models(models_improved, kw_dict={'average':'weighted'})","a423ca81":"%timeit\n### BAGGING ENSEMBLE: BAG MODELS\nLc_bag = BaggingClassifier(LogisticRegression(**models_CV['Lc'].best_params_)) \nKNc_bag = BaggingClassifier(KNeighborsClassifier(**models_CV['KNc'].best_params_))\nDTc_bag = BaggingClassifier(DecisionTreeClassifier(**models_CV['DTc'].best_params_))\nRFc_bag = BaggingClassifier(RandomForestClassifier(**models_CV['RFc'].best_params_))\nSVc_bag = BaggingClassifier(SVC(**models_CV['SVc'].best_params_, probability=True))\nXGBc_bag = BaggingClassifier(XGBClassifier(**models_CV['XGBc'].best_params_,\n                                            probability=True,\n                                            use_label_encoder=False,\n                                            objective=\"reg:logistic\",\n                                            eval_metric=\"rmse\"))\n\n\nmodels_bag = {\"Lc\" : Lc_bag,\n             \"KNc\" : KNc_bag,\n             \"DTc\" : DTc_bag,\n             \"RFc\" : RFc_bag,\n             \"SVc\" : SVc_bag,\n             \"XGBc\" : XGBc_bag}\n\n# TRAIN\nmodels_bag = train_all_models(models_bag, train_now=True)","2dc50c18":"## EVALUATION AND PLOTTING: BAGGING MODELS\nplot_predict_all_models(models_bag)","c42875a8":"%timeit\n# MAIN RESULTS INTO DATAFRAMES\nalgorithms = ['Logistic Regression',\n            'K-Nearest Neighbour Classifier',\n            'Decision Tree Classifier', \n            'Random Forest Classifier',\n            'Support Vector Machine Classifier',\n            'XGBoost Classifier']\n\nvanilla_results = pd.DataFrame( {\"Algorithm\": algorithms,\n                          \"Train_score\":[m.score(X_train,y_train) for m in models_vanilla.values()],\n                          \"Test_score\":[m.score(X_test,y_test) for m in models_vanilla.values()]\n                                }).sort_values('Test_score', ascending=False)\n\nimproved_results = pd.DataFrame({\"Algorithm\": algorithms,\n                          \"Train_score\":[m.score(X_train,y_train) for m in models_improved.values()],\n                          \"Test_score\":[m.score(X_test,y_test) for m in models_improved.values()]\n                                }).sort_values('Test_score', ascending=False)\n\nbag_results = pd.DataFrame({\"Algorithm\": algorithms,\n                          \"Train_score\":[m.score(X_train,y_train) for m in models_bag.values()],\n                          \"Test_score\":[m.score(X_test,y_test) for m in models_bag.values()]\n                               }).sort_values('Test_score', ascending=False)\n\ndisplay(\"VANILLA:\", vanilla_results)\ndisplay(\"IMPROVED:\", improved_results)\ndisplay(\"BAGGING:\", bag_results)","445f6b03":"# EXPORT CLEANED AND IMPUTED DATASET TO CSV (for production)\niris.to_csv(\"iris.csv\", header=True, index=False)\n\n# EXPORTS TO CSV\nvanilla_results.to_csv(\"iris_vanilla_results.csv\")\nimproved_results.to_csv(\"iris_improved_results.csv\")\nbag_results.to_csv(\"iris_bagging_results.csv\")\n\n# EXPORT TO PICKLE\nimport pickle\n\nmodel_filename = 'iris_svm_bag.pkl'\nwith open(model_filename, \"wb\") as f:\n    pickle.dump(models_bag['SVc'], f)\nwith open(\"iris_lc_imp.pkl\", \"wb\") as f:\n    pickle.dump(models_improved['Lc'], f)\n    \n","4017e2e5":"# FEATURE IMPORTANCES\nfeatures = pd.Series(models_bag['RFc'].base_estimator_.fit(X_train,y_train).feature_importances_)\nfeatures.index = features.index.map({i:c for i,c in enumerate(data.columns)})\ndisplay(features)","48bd2058":"###----------------< END of 'iris_nb.ipynb'>---------------###","d7228b36":"## 3. EVALUATION AND IMPROVEMENTS FOR THOSE ALGORITHMS","b9af96e6":"## 0. LOAD DATASET AND PARAMETERS","a8999d82":"Podemos comprobar si las variables tienen dependencia con el target en una versi\u00f3n categ\u00f3rica del dataset, donde asignamos cuatro clases dependiendo del rango intercuartil en el que caigan [0->0.25,-> 0.5,->0.75,->1.00]. En todas las agrupaciones de columnas que se pueden comprobar con la funci\u00f3n 'chi2contingency_by_LemmaOrCol', podemos ver un p-value demasiado bajo ($t<e^{-12}$), por lo cual podemos descartar la hip\u00f3tesis nula que nos dice que las muestras son iguales y por tanto, nuestras variables categ\u00f3ricas son dependientes. \u00c9sto es as\u00ed porque hemos clasificado en categor\u00edas respecto a los rangos de cada variable, sin tener en cuenta las dem\u00e1s. Es decir, hemos comprobado algo tan obvio como que las tres especies de plantas son distintas entre s\u00ed atendiendo a la clasificaci\u00f3n relativa de algunas de sus propiedades (como 'sepal_width'). Si hubiese alguna combinaci\u00f3n de caracter\u00edsticas categ\u00f3ricas que contribuyese significativamente a separar las especies (dependencia), se ver\u00eda reflejada en este test al tener un p-value alto en torno a un intervalo de confianza aceptable.","13115e39":"# IRIS DATASET EXPLORATION","fc3d0dc2":"El valor 'statistic' es lo que se denomina t-value. El signo de t en el test indica si la primera muestra tiende a ser mayor (+) o viceversa(-), en este caso obtenemos lo que ya sab\u00edamos en los gr\u00e1ficos 'width'vs'length' anteriores. El hecho de que el t-value (de nuestros tests) sea mayor en valor absoluto que el t-value-cr\u00edtico de nuestras muestras para un intervalo de confianza dado, nos indica que podemos rechazar la hip\u00f3tesis nula y por tanto afirmar que las muestras poseen diferentes medias. Si tenemos que $t_{value} > t_{value-crit}$, podemos rechazar $H_0$, lo cual se dar\u00e1 en el caso de 'one-sided test, less-than' donde $H_0: \\mu_{versicolor} >= \\mu_{virginica} $, y podr\u00edamos afirmar la hip\u00f3tesis alternativa $H_1: \\mu_{versicolor} < \\mu_{virginica}$, esto ocurre para los dos intervalos de confianza definidos (95 y 99\\%) para todas las variables.\n\nComo hab\u00edamos observado en los gr\u00e1ficos, los valores de 'sepal_width' y 'sepal_length' eran m\u00e1s difusos. Hemos comprobado con los anteriores tests, que aunque en media 'sepal_width' para las clases virginica y versicolor se parezcan, a\u00fan son separables. A\u00fan as\u00ed, es una muestra difusa de ser un peor predictor.","6ae0152a":"## <ins>*CONCLUSIONES*:<\/ins>\n\n**Variables predictoras o features:** 'sepal_width','sepal_length','petal_width','petal_length' \\\n**Variable objetivo o target:** 'species'\n\n- 1. AN\u00c1LISIS EXPLORATORIO DE DATOS:\n\n    - Hay correlaci\u00f3n (bastante mayor en las caracter\u00edsticas del p\u00e9talo) entre las variables predictoras y la objetivo, salvo en el caso de 'sepal_width',en la que hay una m\u00ednima correlaci\u00f3n negativa.\n    \n    - La distribuci\u00f3n bimodal en algunos de nuestros histogramas y un scatterplot m\u00e1s detallado en las caracter\u00edsticas del p\u00e9talo diferenciando por especies, nos llevan a la conclusi\u00f3n de que la especie setosa posee unas propiedades del p\u00e9talo suficientemente caracter\u00edsticas para ser diferenciadas del resto de especies. Se podr\u00eda quitar el subgrupo setosa de nuestros datos y seguir investigando de manera visual y anal\u00edtica la separaci\u00f3n entre versicolor y virginica. \n    \n    - Las variables 'petal_length' y 'petal_width' (sobre todo la segunda) pueden parecer a simple vista que comparten rangos entre las especies virginica y versicolor, pero un an\u00e1lisis m\u00e1s detallado con el test T-student indica que son separables estad\u00edsticamente con una confianza significativa (95%). Tambi\u00e9n este test nos dice que ambas caracter\u00edsticas del p\u00e9talo son objetivamente mayores en el caso de la virginica.\n    \n    - Si convertimos a variables categ\u00f3ricas en funci\u00f3n de nuestros rangos intercuartiles, no hay una combinaci\u00f3n de caracter\u00edsticas que sea dependiente y por tanto predictora de nuestra variable target. \u00c9sto hemos podido comprobarlo con nuestro test $\\chi^2$ de independencia.\n        \n- 2. BUSCANDO ALGORITMOS CANDIDATOS:\n\nDefinimos nuestro target 'species', a continuaci\u00f3n hemos dividido en train\/test con una fracci\u00f3n del 70% y 30%, respectivamente.\n\nHemos realizado un StandardScaler() que nos redistribuye la muestra como $\\sim N(0,1)$, \u00e9sto es suficiente y recomendable puesto que no tenemos demasiados valores extremos en nuestros datos y nuestras variables predictoras poseen una distribuci\u00f3n normal.\n\nHemos usado los siguientes y famosos algoritmos de sklearn para problemas de clasificaci\u00f3n:\n\n    - LinearClassifier(): Modelo m\u00e1s simple, ajusta los coeficientes por medio de minimizar diferencias cuadr\u00e1ticas.\n    - KNeighborsClassifier(): Modelo sencillo que, una vez se establece k (el n\u00famero de predictores m\u00e1ximo), nos dar\u00e1 la importancia de predictores en torno a la variable de objetivo de la clasificaci\u00f3n.\n    - DecisionTreeClassifier(): Modelo sencillo que penaliza la distancia de nuestros datos en relaci\u00f3n a valores de prueba , construye un \u00e1rbol de decisi\u00f3n y permite realizar clasificaci\u00f3n. Permite ver la importancia de predictores.\n    - RandomForestClassifier(): Modelo mejorado basado en \u00e1rboles de decisi\u00f3n que permite promediar una muestra significativa de ellos, sus resultados, y ver la importancia de predictores.\n    - SVC(): Modelo de m\u00e1quinas de soporte vectorial ('Support Vector Machines'), que busca hacer la mejor divisi\u00f3n de nuestros datos mediante hiperplanos que los separen.\n    - XGBClassifier(): Modelo complejo y \u00f3ptimo ('eXtreme Gradient Boosting') basado en \u00e1rboles de decisi\u00f3n, optimizaci\u00f3n del descenso del gradiente y una randomizazi\u00f3n de par\u00e1metros optimizada, entre otros.\n    \nDado que nuestro dataset es relativamente peque\u00f1o, hemos usado GridSearchCV como algoritmo de b\u00fasqueda de hiperpar\u00e1metros. \u00c9ste es mas lento que otros (i.e. RandomizedSearchCV), pero \u00e9sto se traduce en una mejora general de los hiperpar\u00e1metros buscados, dado que prueba todas las combinaciones en los datos.\n\n**NOTA: Hemos evaluado la \u00e1rea debajo de la curva ROC (AUC), la precisi\u00f3n (accuracy) del modelo y otras m\u00e9tricas principales de la tabla de contingencia, tambi\u00e9n hemos dibujado la curva ROC de los modelos para cada posible clase. En las m\u00e9tricas, hemos optado por hacer una media pesada (\"weighted\") entre los 3 pares de evaluaci\u00f3n todos-contra-todos.**\n\n- 3. EVALUACI\u00d3N Y MEJORAS PARA \u00c9STOS ALGORITMOS:\n\nUna vez buscados los mejores par\u00e1metros para nuestros modelos, hemos evaluado nuestros modelos con \u00e9stos, lo que hemos llamado modelos \"improved\".\n\nLuego, hemos usado un m\u00e9todo de ensamblado ('BaggingClassifier') para mejorar nuestros modelos mediante el ensamblaje de clasificadores con los mejores par\u00e1metros encontrados, lo que hemos llamado modelos \"bagging\".\n\nHemos exportado nuestros modelos a DataFrames y hemos guardado los resultados principales, tambi\u00e9n, hemos guardado el dataset en formato .csv y el mejor modelo en formato 'pickle' para la fase de producci\u00f3n.\n\nEn nuestros algoritmos principales evaluados en test:\n\nPara modelos \"vanilla\" (default): Gana *Logistic Regression*, con un score de 0.978 en test. \n\nPara modelos \"improved\" (con hiperpar\u00e1metros mejorados), nos dan como favoritos:\n\n1. Logistic Regression \t0.980952 \t0.977778 \\\n2. K-Nearest Neighbour Classifier \t0.971429 \t0.933333 \\\n3. Support Vector Machine Classifier \t0.961905 \t0.933333 \\\n\nPara modelos \"bagging\" (mejorados con ensamblamiento):\n\n1. Support Vector Machine Classifier \t0.971429 \t0.977778 \\\n2. Logistic Regression \t0.990476 \t0.955556 \\\n3. Random Forest Classifier \t0.961905 \t0.955556 \\\n\nPor tanto, guardaremos el modelo SVM_bagging y el Lc_improved en formato 'pickle' para la fase de producci\u00f3n. Tambi\u00e9n guardamos el dataset original.\n\nSeg\u00fan nuestro mejor modelo que permite estimar la importancia de los predictores en la variable objetivo (RandomForestClassifier_bagging), ir\u00edan por orden:\n\n**'petal_width' > 'petal_length' > 'sepal_length' > 'sepal_width'**\n","30dd40ef":"Un simple OLS para cada variable nos dice c\u00f3mo de bien ajustar\u00eda esta variable, midiendo el $R^2$ del modelo resultante. Por el momento, vemos que \"sepal_width\" es el peor predictor, mientras que los mejores predictores ser\u00edan la anchura y longitud del p\u00e9talo.","c1bbdc5f":"## 2. FINDING CANDIDATE ALGORITHMS","b7bd48e9":"## 1. EXPLORATORY DATA ANALYSIS (EDA)","76fc3ffe":"Del anterior gr\u00e1fico de pares vemos en la diagonal principal que \"sepal_length\" y \"sepal_width\" siguen una distribuci\u00f3n t-student (si hubiese m\u00e1s datos ser\u00eda mas parecida a la distribuci\u00f3n normal). En cambio \"petal_length\" y \"petal_width\" parecen seguir una distribuci\u00f3n bimodal. Nuestro target \"species\" sigue distribuci\u00f3n uniforme, y de hecho vemos el mismo n\u00famero de valores en todas las categor\u00edas. \u00c9ste es un dataset muy preparado y con probabilidad se habr\u00e1n tocado datos a prop\u00f3sito desde el antiguo estudio del que es originario. \n\nTambi\u00e9n vemos un razonable n\u00famero de casos pertenecientes a cada categor\u00eda del target. En los gr\u00e1ficos no diagonales restantes, podemos ver una correlaci\u00f3n m\u00e1s o menos clara entre variables, incluso diversos grupos se\u00f1alados dentro de los datos. Investigaremos ahora esta correlaci\u00f3n.\n\nNOTA: No nos pararemos demasiado en verificar si las distribuciones mencionadas anteriormente son correctas en cada variable (diagonal principal). Pero de hacerlo, el procedimiento a seguir ser\u00eda hacer un test $\\chi^2$ para bondad del ajuste en cada variable.\n\n1. Se hace un histograma de nuestras variables continuas en un cierto n\u00famero de bins, normalizando al conteo total de valores ([0,1]). \n2. Se crea una variable con la distribuci\u00f3n modelo dada la funci\u00f3n de probabilidad de esa distribuci\u00f3n, y de longitud el n\u00famero de bines. N\u00f3tese que no es una random variable, sino una que sigue perfectamente la distribuci\u00f3n.\n3. Se realiza el $\\chi^2$-test para determinar con un cierto grado de confianza $\\alpha$ si las distribuciones son independientes. En este caso $H_0$: expected dist. = observed dist, por lo que el test s\u00f3lo puede determinar independencia entre las distribuciones, pero no asegura que la hip\u00f3tesis nula (dependencia) sea correcta. En todo caso, cuanto mayor sea el p-value, m\u00e1s seguros estaremos de que las distribuciones son id\u00e9nticas.","c13a3f77":"Del heatmap puede verse de manera visual como \"petal_length\" y \"petal_width\" est\u00e1n m\u00e1s correladas.\n\nTambi\u00e9n vemos una dependencia de 'sepal_length' con el target, y incluso vemos que 'sepal_width' est\u00e1 anticorrelada a los dem\u00e1s predictores.\n","2ec216ab":"La tabla de contingencia representada en heatmaps puede tener una interpretaci\u00f3n menos clara. Se puede decir, que representa qu\u00e9 valores de una variable determinada contribuyen m\u00e1s al valor esperado de esa variable diferenci\u00e1ndola por nuestro target 'species'.","e95edcf1":"Para la b\u00fasqueda de algoritmos candidatos, usaremos los siguientes para el problema de clasificaci\u00f3n:\n\n- LogisticRegression()\n- KNeighborsClassifier()\n- DecisionTreeClassifier()\n- RandomForestClassifier()\n- SVC()\n- XGBClassifier()\n\nPodemos buscar los hiperpar\u00e1metros m\u00e1s tarde por la clase **\"GridSearchCV\"**, recomendada para datasets con pocos datos y que comprueba todas las opciones disponibles.","b2e7795b":"- Gr\u00e1fico sepal length\/width: Las caracter\u00edsticas del s\u00e9palo diferencian a la setosa, pero no a la versicolor y virginica entre s\u00ed.\n- Gr\u00e1fico petal length\/width: La setosa se caracteriza por tener dimensiones menores tanto en longitud como en anchura del p\u00e9talo. La versicolor y virginica parecen m\u00e1s diferenciables que en el g\u0155\u00e1fico anterior, aunque hay una cierta regi\u00f3n de convivencia.\n\nVeremos si el test t-student y el chi-cuadrado nos pueden arrojar certidumbre sobre las poblaciones."}}