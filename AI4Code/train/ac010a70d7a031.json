{"cell_type":{"610bf5d1":"code","e32300f4":"code","4964cc4a":"code","936fcf31":"code","ca3e098b":"code","fe7e7111":"code","8d5fbd72":"code","08d6bb5f":"code","b05169cc":"code","04dbf7da":"code","37b399e0":"code","867d9634":"code","3e88e5a0":"code","4e38d7c4":"code","19d0f98d":"code","0de5d2da":"code","01d7736f":"code","be823573":"code","9bfee372":"code","011bdf9c":"code","7bb66213":"code","b9077905":"code","00c73e44":"code","31e4897b":"code","e2355a11":"code","d67b032c":"code","34b830f0":"code","1d0d0783":"code","f47dc717":"code","c6200b96":"code","77c349ff":"code","24f40ac6":"code","322ec895":"code","18b31adf":"code","93457ad9":"code","f6de7d96":"code","2aa0abe3":"code","ab62bb44":"code","c4db2549":"code","560cacf8":"code","a5a5cc3a":"code","53f5b245":"code","073c5071":"code","0f3e4001":"code","53e13520":"code","87d8e20d":"code","b3d7924d":"code","0014540c":"code","a9396d2a":"code","2cb22ca5":"code","7db5ebed":"code","a7adfd4c":"code","ef5fe632":"code","b8842e02":"code","aa7a54f3":"code","25b959e7":"code","1ecdf592":"code","7411524f":"code","c417cac5":"code","4a694262":"code","1ea0702c":"code","4385d0af":"code","e2a93168":"code","6d59280e":"code","46900019":"code","7048ae7c":"code","7f602eed":"code","8f5f679a":"code","31788ce1":"code","18b42a4a":"code","37cd41d7":"code","f4fd79aa":"code","69f7381a":"markdown","f3c17c63":"markdown","2069772e":"markdown","73e29d6b":"markdown","1a0421fe":"markdown","d3b3c6ce":"markdown","27228c5b":"markdown","a1016f2d":"markdown","dd66dfb3":"markdown","a42bcc47":"markdown","205907b9":"markdown","7a67396d":"markdown","fb163784":"markdown"},"source":{"610bf5d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e32300f4":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, mean_absolute_error, r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPool2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nimport datetime","4964cc4a":"# Let's import our data, with the common notation for the input data X and target data Y.\ndf_X = pd.read_csv(\"..\/input\/production-quality\/data_X.csv\", parse_dates=['date_time'])\ndf_Y = pd.read_csv(\"..\/input\/production-quality\/data_Y.csv\", parse_dates=['date_time'])\ndf_X.head()","936fcf31":"df_X.info(), df_Y.info()","ca3e098b":"df_X.describe()","fe7e7111":"# Check for quality of data. No data missing, nice and clean set.\nprint(df_X.isnull().sum()\/df_X.shape[0]*100)","8d5fbd72":"# We'll add the initial hour of the process so that we can join the data to the hourl-based quality measurements.\ndf_X[\"date_hour\"] = df_X[\"date_time\"].apply(lambda x: x.strftime(\"%d-%m-%Y-%H\"))","08d6bb5f":"# We can now see the adjusted datetime feature appended to the dataframe.\ndf_X.head()","b05169cc":"# Transform data into flattened batches based on the initial run time of the batch.\n# Target shape 1x1020 for 17x60 measurements per batch, append dh = 1x1021 per batch.\nL = list(df_X.groupby(\"date_hour\"))\nl = len(L)\nList = []\nfor i in range(l):\n    dh = L[i][1][\"date_hour\"].iloc[0]\n    row = L[i][1].drop([\"date_time\", \"date_hour\"], axis=1).to_numpy().flatten().tolist()\n    row.append(dh)\n    List.append(row)\n    if (i+1)%2000 == 0:\n        print(\"Processing: %.4f%%\"%(100*(i+1)\/l))\n\ndf = pd.DataFrame(List)\ndf[\"date_hour\"] = df[1020]\ndf.drop([1020], axis=1, inplace=True)","04dbf7da":"# New process measurement dataframe has our flattened, aggregated batch data.\ndf.shape","37b399e0":"# Off-set quality measurement data to match the beginning of the run.\ndf_Y[\"date_shifted\"] = pd.to_datetime(df_Y[\"date_time\"]) - datetime.timedelta(hours=1)\ndf_Y[\"date_shifted\"] = pd.to_datetime(df_Y[\"date_shifted\"])\ndf_Y[\"date_shifted\"] = df_Y[\"date_shifted\"].apply(lambda x: x.strftime(\"%d-%m-%Y-%H\"))","867d9634":"# On the appended date_hour field, we can join the end-product quality feature to the process measurement dataframe.\ntransformed_data = pd.merge(df,df_Y[[\"date_shifted\", \"quality\"]],left_on=\"date_hour\", right_on=\"date_shifted\", how=\"inner\")","3e88e5a0":"transformed_data.shape","4e38d7c4":"transformed_data.head","19d0f98d":"# Let's split our data for training, testing, and validation with a 60-30-10 split.\ndf_X = transformed_data.drop(columns=['date_hour', 'date_shifted', 'quality'])\ndf_Y = transformed_data.quality\n\nX_train, X_test, Y_train, Y_test = train_test_split(df_X, df_Y, test_size=0.4, random_state=0)\nX_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.75, random_state=0)","0de5d2da":"print(f'training set: {X_train.shape} | {Y_train.shape}\\n\\\ntesting set:  {X_test.shape} | {Y_test.shape}\\n\\\nvalidation set: {X_val.shape} | {Y_val.shape}')","01d7736f":"# Let's scale our data using StandardScaler.\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_val_sc = sc.fit_transform(X_val)\nX_test_sc = sc.fit_transform(X_test)","be823573":"# Here are a few helper functions that are used throughout the notebook to visualize the model's performance.\n\n# Helper function to visualize model effectiveness.\ndef show_scatter(y_p, y_true, nested_pred=False):\n    if nested_pred:\n        y_p = y_p.transpose()[0].transpose()\n    plt.scatter(y_p, y_true, color='k', alpha=0.25)\n    min_val = np.concatenate((y_p, np.array(y_true))).min()\n    max_val = np.concatenate((y_p, np.array(y_true))).max()\n    plt.plot([min_val, max_val], [min_val, max_val], linestyle='--', color = 'r')\n    plt.xlim(min_val,max_val)\n    plt.ylim(min_val,max_val)\n    plt.title('Scatter Plot')\n    plt.xlabel('Predicted Quality')\n    plt.ylabel('Actual Quality')\n\n# Helper function to view model effectiveness.\ndef show_confusion_matrix(y_p, y_true, nested_pred=False):\n    if nested_pred:\n        y_pred_rd = np.round(y_p, decimals=-1).transpose()[0].transpose()\n    else:\n        y_pred_rd = np.round(y_p, decimals=-1)\n    y_true_rd = np.round(y_true, decimals=-1)\n    cm = confusion_matrix(y_true_rd, y_pred_rd)\n    f, ax = plt.subplots(figsize=(20,20))\n    sns.heatmap(cm, annot=True, linewidths=0.01, cmap='RdBu', linecolor='gray', fmt='.0f', ax=ax)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title('Confusion Matrix')\n    plt.show()","9bfee372":"# Here's our first model, which uses only dense layers to handle the flattened data.\ndef Dense_NN():\n  model = Sequential()  \n  model.add(Dense(100, activation='relu', input_shape=(1020,)))\n  model.add(Dense(100, activation='relu'))\n  model.add(Dense(100, activation='relu'))\n  model.add(Dense(10, activation=\"linear\"))\n  model.compile(optimizer='adam', loss = \"mean_absolute_error\", metrics = [\"mae\"])\n  return model\n\nmodel = Dense_NN()\nmodel.summary()","011bdf9c":"# While there are over one thousand features in the flattened data set, the model still only needs about a minute to train against the 17,510 batches.\nmodel.fit(X_train_sc, Y_train, batch_size=50, epochs=20, validation_data=(X_val_sc, Y_val))","7bb66213":"# The score on the test set is similar to the losses in the training, which is about MAE=9.4.\nscore = model.evaluate(X_test_sc, Y_test, verbose=0)\nscore[0]","b9077905":"y_pred_dnn = model.predict(X_test_sc)","00c73e44":"# The matrix shows that the model has a very tight fit along the centerline after being binned by values of 10. \nshow_confusion_matrix(y_pred_dnn, Y_test, nested_pred=True)","31e4897b":"# We can also see that the residual is very straight, which means that it is good at predicting qualities\n# across the entire observed range of end-product qualities.\nshow_scatter(y_pred_dnn, Y_test, nested_pred=True)","e2355a11":"# We'll start by instantiating our linear regression object and applying our data.\nlim_0 = LinearRegression()\nlim_0.fit(X_train_sc, Y_train)\ny_pred_0 = lim_0.predict(X_train_sc)\ny_pred_0","d67b032c":"# Measuring the prediction on the test set, we can see an MAE of around 12.8, which is surprising good but not as effective as the DNN.\nMAE_0 = mean_absolute_error(Y_train, y_pred_0)\nr2_score_lim_0 = r2_score(Y_train, y_pred_0)\nprint(f'r-squared coef: {r2_score_lim_0:.3f}\\nMAE: {MAE_0:.3f}')","34b830f0":"# Compared to the dense neural network, we can see that the residuals spread further from our centerline--a sign of a weaker fit.\nshow_scatter(y_pred_0, Y_train)","1d0d0783":"# Additionally, we can see a curvature in our heatmap, which is a sign that it performs worse at the extremes of the data set.\nshow_confusion_matrix(y_pred_0, Y_train)","f47dc717":"# Let's set up our PCA object and look at the explained variance on our training set.\npca = PCA()\npca.fit(X_train_sc)\nnp.cumsum(pca.explained_variance_ratio_)[:50]","c6200b96":"# Reaching 99.7% with 50 features is pretty good. We'll create a new dataframe with these 50 most significant PCA features.\npca = PCA(n_components=50)\ntdf = pd.DataFrame(pca.fit_transform(X_train_sc), columns=['PC' + str(x) for x in range(1, 51)])\ntdf.head","77c349ff":"# Let's create a new linear regression object and train it to the transformed data set.\nlim = LinearRegression()\nlim.fit(tdf, Y_train)\ny_pred = lim.predict(tdf)","24f40ac6":"# As expected, it slightly worsened the performance of the linear regression model.\nMAE = mean_absolute_error(Y_train, y_pred)\nr2_score_lim = r2_score(Y_train, y_pred)\nprint(f'r-squared coef: {r2_score_lim:.3f}\\nMAE: {MAE:.3f}')","322ec895":"# Now let's create a new dense neural network with an adjusted input_shape to receive the transformed data set.\ndef Dense_NN_PCA():\n  model = Sequential()  \n  model.add(Dense(100, activation='relu', input_shape=(50,)))\n  model.add(Dense(100, activation='relu'))\n  model.add(Dense(100, activation='relu'))\n  model.add(Dense(10, activation=\"linear\"))\n  model.compile(optimizer='adam', loss = \"mean_absolute_error\", metrics = [\"mae\"])\n  return model\n\nmodel_pca = Dense_NN_PCA()\nmodel_pca.summary()","18b31adf":"# Let's train the new model. This took a fraction of the time and reaches about the same MAE between the test and validation sets.\ntdf_val = pd.DataFrame(pca.transform(X_val_sc), columns=['PC' + str(x) for x in range(1, 51)])\nmodel_pca.fit(tdf, Y_train, batch_size=50, epochs=20, validation_data=(tdf_val, Y_val))\n","93457ad9":"tdf_test = pd.DataFrame(pca.transform(X_test_sc), columns=['PC' + str(x) for x in range(1, 51)])","f6de7d96":"# With the test set, we get an MAE of about 9.8. For reducing the feature count by 95%, it's pretty good!\ny_pred_dnn_pca = model_pca.predict(tdf_test)\nmodel_pca.evaluate(tdf_test, Y_test)","2aa0abe3":"# While we lost some accuracy, the difference is pretty minor. We can see very similar residual plots to the model with which used the 1,020 features to train.\nshow_confusion_matrix(y_pred_dnn_pca, Y_test, nested_pred=True)","ab62bb44":"show_scatter(y_pred_dnn_pca, Y_test, nested_pred=True)","c4db2549":"# First, we'll reshape data into time series, 1x1020 -> 60x17.\nX_train_rsi = X_train_sc.reshape(-1, 60, 17, 1)\nX_test_rsi = X_test_sc.reshape(-1, 60, 17, 1)\nX_val_rsi = X_val_sc.reshape(-1, 60, 17, 1)\nX_train_rsi.shape\nt = X_train_rsi[0]","560cacf8":"# Display new data shape. Looks like we'll need to transpose the data.\nplt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(t)","a5a5cc3a":"# Transpose data 60x17 -> 17x60.\nX_train_rs = np.transpose(X_train_rsi, axes=[0, 2, 1, 3])\nX_test_rs = np.transpose(X_test_rsi, axes=[0, 2, 1, 3])\nX_val_rs = np.transpose(X_val_rsi, axes=[0, 2, 1, 3])\nt2 = X_train_rs[0]","53f5b245":"# Now it looks right.\nplt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(t2)","073c5071":"# We're going to create a generator object to feed our CNN.\ndatagen = ImageDataGenerator(featurewise_center=False,\n                             samplewise_center=False,\n                             featurewise_std_normalization=False,\n                             samplewise_std_normalization=False,\n                             zca_whitening=False,\n                             rotation_range=0,\n                             zoom_range=0,\n                             width_shift_range=0,\n                             height_shift_range=0,\n                             horizontal_flip=False,\n                             vertical_flip=False)\n\ndatagen.fit(X_train_rs)","0f3e4001":"# Here's the reshaped data set.\nX_train_rs.shape","53e13520":"# Before we use our CNN, let's double-check that the reshaped data returns similar results with a DNN model.\n# The difference here is that we'll be using a flattening layer to undo our reshaping.\ndef Reshaped_Dense_NN():\n    model = Sequential()\n    model.add(Flatten(input_shape=(17,60,1)))\n    model.add(Dense(100, activation='relu', input_shape=(1020,)))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(10, activation=\"linear\"))\n    model.compile(optimizer='adam', loss = \"mean_absolute_error\", metrics = [\"mae\"])\n    return model\n\ndnn_rs = Reshaped_Dense_NN()\ndnn_rs.summary()","87d8e20d":"# Let's train our reshaped dnn model. Still reaching <10 MAE, looks good!\ndnn_rs.fit(datagen.flow(X_train_rs, Y_train, batch_size=50), epochs=20, validation_data=(X_val_sc, Y_val))","b3d7924d":"# Here's our CNN, which uses convolutional and pooling layers to try to emphasize shape trends within the set.\n# The intent in the design is that convolutional layer will look to adjascent rows while the pooling layer will only pool measurements from the same sensor.\ndef Convolutional_NN():\n  model = Sequential()  \n  model.add(Conv2D(8,(3,5), input_shape=(17,60,1), padding=\"same\", activation=\"relu\"))\n  model.add(BatchNormalization(axis = -1))\n  model.add(MaxPool2D(pool_size=(1,3)))\n  model.add(Flatten())\n  model.add(Dense(100, activation=\"relu\"))\n  model.add(Dropout(rate=0.2))\n  model.add(Dense(100, activation=\"relu\"))\n  model.add(Dropout(rate=0.2))\n  model.add(Dense(10, activation=\"relu\"))\n  model.compile(optimizer='adam', loss=\"mean_absolute_error\", metrics = [\"mae\"])\n  return model\n\ncnn = Convolutional_NN()\ncnn.summary()","0014540c":"# Let's train our cnn model.\ncnn.fit(datagen.flow(X_train_rs, Y_train, batch_size=50), epochs=20, validation_data=(X_val_rs, Y_val))","a9396d2a":"# Surprisingly, it's performing the worst! This may be from very little dependency or relation between features.\ny_pred_cnn = cnn.predict(X_test_rs)\ncnn.evaluate(X_test_rs, Y_test)","2cb22ca5":"# While the MAE is worse, it still has a relatively straight residual, so one may be able to argue that\n# this performs better at extremes than the linear regression model.\nshow_confusion_matrix(y_pred_cnn, Y_test, nested_pred=True)","7db5ebed":"show_scatter(y_pred_cnn, Y_test, nested_pred=True)","a7adfd4c":"# Get the median values for the 17x60 shaped data.\nX_train_med_rsi = pd.DataFrame(X_train_sc).median().to_numpy().reshape(60, 17)\nX_train_med_rs = np.transpose(X_train_med_rsi, axes=[1, 0])\nX_train_med_rs.shape","ef5fe632":"# Helper function to return a DataFrame with a percentage of the data\n# filled with median values.\ndef partial_dataset_median(arr, frac, feat_ct=17):\n    section = frac * feat_ct\n    \n    arr_empty = np.empty(arr.shape)\n    arr_empty[:, :] = np.NaN\n    arr_frac = arr_empty\n    arr_frac[:,:section] = arr[:,:section]\n    arr_frac = pd.DataFrame(arr_frac)\n    #X_train_10 = X_train_10.append(pd.DataFrame(X_train_sc).median(), ignore_index=True)\n    arr_frac = arr_frac.fillna(pd.DataFrame(arr).median())\n    #X_train_10 = X_train_10.drop()\n    return arr_frac\n    ","b8842e02":"# Here's an example data set with on the first 10 minutes of data (the remaining 50 minutes has been replaced with median values).\nX_train_10 = partial_dataset_median(X_train_sc, 10, feat_ct=17)\nX_train_10.head","aa7a54f3":"# Reshape data into time series, 1x1020 -> 17x60. We can see that there is a drastic change between the last reading and the median-fill data.\nX_train_10_inv = X_train_10.to_numpy().reshape(-1, 60, 17, 1)\nX_train_10_rs = np.transpose(X_train_10_inv, axes=[0, 2, 1, 3])\nplt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(X_train_10_rs[0])","25b959e7":"# Let's see how the error changes in the DNN model. Not great, and getting MAE above 20.\ndnn_rs.evaluate(X_train_10_rs, Y_train)\ny_pred_10 = dnn_rs.predict(X_train_10_rs)\nshow_scatter(y_pred_10, Y_train, nested_pred=True)","1ecdf592":"# Helper function to get error by fraction of data.\ndef evaluate_prediction_rs(X, Y, steps, model, method='median'):\n    scores = []\n    preds = []\n    for i in steps:\n        if method == 'median':\n            X_frac = partial_dataset_median(X, i, feat_ct=17)\n        elif method == 'recent':\n            X_frac = partial_dataset_recent(X, i, feat_ct=17)\n        else:\n            raise TypeError(f\"Method {method} not recognized. Please use 'median' or 'recent'.\")\n        X_inv = X_frac.to_numpy().reshape(-1, 60, 17, 1)\n        X_rs = np.transpose(X_inv, axes=[0, 2, 1, 3])\n        scores.append(model.evaluate(X_rs, Y))\n        preds.append(model.predict(X_rs))\n    return scores, preds\n        ","7411524f":"# Now let's iterate across processing time and see how prediction changes.\nsteps = range(1,61)\nscores_dnn, preds_dnn = evaluate_prediction_rs(X_test_sc, Y_test, steps, dnn_rs, method='median')","c417cac5":"# We can see that the initial error is around 35 and it gradually reduces as more of the filled data is replaced, finally reaching the end MAE seen before.\nplt.plot(range(1,61), scores_dnn)\nplt.title('MAE by Minute, DNN, Median Fill')\nplt.xlabel('Process Time (minutes)')\nplt.ylabel('MAE')\nplt.show()","4a694262":"# Now compare it to the CNN with predicting quality with partial batch sensor data.\nsteps = range(1,61)\nscores_cnn, preds_cnn = evaluate_prediction_rs(X_test_sc, Y_test, steps, cnn)","1ea0702c":"# Interestingly, the CNN's error grows as it nears the end and reaches mean errors exceeding the initial error at time 0!\n# It seems that the DNN is more useful for this application.\nplt.plot(range(1,61), scores_cnn)\nplt.title('MAE by Minute, CNN')\nplt.xlabel('Process Time (minutes)')\nplt.ylabel('MAE')\nplt.show()","4385d0af":"# Helper function to return a DataFrame with a percentage of the data\n# filled with median values.\ndef partial_dataset_recent(arr, frac, feat_ct=17):\n    section = frac * feat_ct\n    arr_empty = np.empty(arr.shape)\n    arr_empty[:, :] = np.NaN\n    arr_frac = arr_empty\n    arr_frac[:,:section] = arr[:,:section]\n    arr_rec = arr[:, ((frac-1)*feat_ct):section]\n    ct_zones = arr.shape[1]\/feat_ct - frac\n    for i in range(int(ct_zones)):\n        arr_frac[:, (frac+i)*feat_ct:(frac+i+1)*feat_ct] = arr_rec[:, :]\n    return pd.DataFrame(arr_frac)","e2a93168":"# Test the fill using the most recent sensor data.\nX_train_10_rc = partial_dataset_recent(X_train_sc, 10, feat_ct=17)\nX_train_10_rc.head","6d59280e":"# Reshape data into time series, 1x1020 -> 17x60. This data looks much closer to the actual data set!\nX_train_10_rc_inv = X_train_10_rc.to_numpy().reshape(-1, 60, 17, 1)\nX_train_10_rc_rs = np.transpose(X_train_10_rc_inv, axes=[0, 2, 1, 3])\nplt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(X_train_10_rc_rs[0])","46900019":"# Now let's try iterating across processing time using the most recent sensor data and see how prediction changes.\nsteps = range(1,61)\nscores_dnn_rc, preds_dnn_rc = evaluate_prediction_rs(X_test_sc, Y_test, steps, dnn_rs, method='recent')","7048ae7c":"# Let's look at the change in MAE as more process data replaces the filled data.\n# Not only is the gradient more smooth, but it also reaching MAE of around 12 at time = 0!\n# This means that this model can more accurately predict the end-product quality from the initial recipe than the linear regression or cnn models when given\n# the data for the entire run.\nplt.plot(range(1,61), scores_dnn_rc)\nplt.title('MAE by Minute, DNN, Most Recent Fill')\nplt.xlabel('Process Time (minutes)')\nplt.ylabel('MAE')\nplt.show()","7f602eed":"# Helper function to plot batch quality data and prediction.\ndef plot_predictions(X, Y_p, Y_t, i):\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,10))\n    pred_q = [x[i].mean() for x in Y_p]\n    t = np.array(Y_t)[i]\n    ax1.set_title(f'Normalized Sensor Data, Batch {i}')\n    ax1.axis('off')\n    ax1.imshow(X[i])\n    ax2.set_title(f'Predicted Quality Across Batch Process')\n    ax2.set_xlabel('Process Time (minutes)')\n    ax2.set_ylabel('Product Quality')\n    ax2.plot(range(1,61), pred_q, label='predicted')\n    ax2.axhline(y=t, color='r', linestyle='--', label='end quality')\n    ax2.legend(loc=\"upper right\")\n    ax2.set_xlim(1,61)\n    ax2.set_ylim(min(min(pred_q), t)-20, max(max(pred_q), t)+20)","8f5f679a":"# Since it performs so well, let's look at how the prediction changes over time compared to the changes in the process data.\n# For the most part, it looks like it is highly reactive, but also that there typically is very little variation in the process.\n# The low variation explains why the initial estimate for quality is so good and also that this fill method works well for this application.\nplot_predictions(X_test_rs, preds_dnn_rc, Y_test, 4)","31788ce1":"plot_predictions(X_test_rs, preds_dnn_rc, Y_test, 7)","18b42a4a":"plot_predictions(X_test_rs, preds_dnn_rc, Y_test, 1000)","37cd41d7":"# Let's look at the batch with the highest actual quality.\nplot_predictions(X_test_rs, preds_dnn_rc, Y_test, np.array(Y_test).argmax())","f4fd79aa":"# ... and the batch with the lowest actual quality.\nplot_predictions(X_test_rs, preds_dnn_rc, Y_test, np.array(Y_test).argmin())","69f7381a":"## Convolution Neural Network Model and Reshaping into Time-Series\n* To gain the benefits of a convolutional neural network, we'll reshape the data for each batch into a 2D matrix of the time-series data of each sensor.\n* We'll reshape each batch and then use convolutional and pooling layers to try to take advantage of relationships between the features.","f3c17c63":"## Median Fill Method\n* The first method that we'll try is to replace the missing values with the median value for each feature.\n* The use of filling NaN values with the median is a widely popular technique in data science when values are missing.","2069772e":"## Linear Regression Model","73e29d6b":"Since our data set is manageable to train without the use of PCA and the perfomance is better using the full data set in this application, we'll proceed with the full data set.","1a0421fe":"## Most Recent Fill Method\n* In hopes of removing that harsh break as seen before between the last measurement and the beginning of the median-fill data, let's try copying the remainder of the run with the most recent measurements for each sensor.\n* This is effectively assuming that the process with remain constant for the rest of the batch run.","d3b3c6ce":"# 4. Data Pre-Processing\n* High data quality -- no nulls. However, about 6,000 batches don't have quality measurements, which will be dropped at the join.\n* All numeric aside from datetime columns, which are used to join the tables.\n* Need to combine data for each batch and join to the end-product quality value.","27228c5b":"# 6. Prediction With Incomplete Time-Series Data\n* We're pretty confident that our DNN can provide relatively good predictions for end-product quality, given the entire batch run's data.\n* This could mean that product quality testing could be significantly reduced (a potential cost reduction).\n* However, there is also value in predicting end-quality prior to batch completion since intervention in the process could lead to better quality (avoiding scrap and rework costs!)\n* For this reason, let's create an emulator for removing the tail end of the data and then reprocessing our data and testing our models.\n","a1016f2d":"# 1. About the Data Set\n![image.png](attachment:c92ff26e-fe7c-4a1d-8f52-c161f0613668.png)\n* Process data for the production quality of a roasting process (https:\/\/www.kaggle.com\/podsyp\/production-quality).\n* Roasts material in a 5-chamber kiln for 1 hour, collecting process data every minute.\n* Goal: Predict the quality of the batch.\n* Quality is empirically measured at the end of each batch.\n* 17 Measurements per minute (1020 measurements per batch).\n* 29 Thousand quality measurements and 2.1 million process measurements.\n\n# 2. Questions to be Answered\n* What sort of accuracies can we obtain through predicting the process batch quality, given the full run data?\n* What sort of methods could be applied to predict the quality of the batch prior to finishing the process?\n* What limitations are there to this being applied to other processes when evaluating time-series data?\n\n# 3. Disclaimer\n* I have no industry knowledge outside of the given information from the data set, so I don't know the potential scenarios that would affect the batch quality.\n* Conversely, approaching the dataset without bias may result in more insightful findings.","dd66dfb3":"Given that the median quality is about 400 and the model is achieving an MAE of about 9.4, this is a fantastic model for this purpose.","a42bcc47":"## Reprocess After Feature Reduction using PCA\n* There are advantages to applying PCA in situations like this since there are over 1,000 features.\n* By reducing the features, it can improve training for deep neural networks and also reduce computation time.\n* We'll apply it to both linear regression and dense neural network models from above.","205907b9":"## Dense Neural Network Model","7a67396d":"# 5. Model Training with Full Batch Process Data.\n* We'll train a linear regression model along with two deep neural networks: one with a dense architecture and one with a convolutional architecture.\n* Each model will evaluate the test set, using MAE as the indicator for goodness of fit.","fb163784":"# 7. Discussion\nWe can notice distinct features within the time series of the sensor data for a batch in which there is a significant change in the predicted product quality, most often times moving the predicted quality towards the end quality value of the batch. This gives us reason to believe that the model is able to identify events that could significantly affect the product quality during the process!<br> Additionally, even though the predicted quality often converges with the end quality, the initial quality prediction at t=0 is remarkably close to the end quality. This suggests that initial process parameters have a significant role in the end product quality, and may support the argument that using a good initial state is more important than adding any gradients within the process parameters during the batch process. For batch process applications with low variation in the process, we've proven that the most-recent fill method out-performs the median fill method. However, it may be worth looking into the use of RNN models to fill larger time series data sets when there is a large amount of variation. This application was best suited for deep neural networks, with dense network architecture performing the best, reaching MAE as low as 9.4. There is reason to believe that the executed prediction methods could be applied to other batch processes for quality prediction."}}