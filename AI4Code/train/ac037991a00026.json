{"cell_type":{"06b9c7c6":"code","3cb04836":"code","c9add753":"code","0f02e394":"code","e4850cfc":"code","e94cccb8":"markdown","43c4c547":"markdown"},"source":{"06b9c7c6":"from optiver_features import generate_test_df\nfrom fastai.tabular.all import *","3cb04836":"test_df = generate_test_df()\ntrain_df = pd.read_csv('..\/input\/optiver-train-features\/train_with_features.csv')","c9add753":"def pred_tabular_nn(train_df, test_df):\n    train_df = train_df.drop(['time_id', 'row_id'], axis=1).fillna(0)\n    train_df.stock_id = train_df.stock_id.astype('category')\n    cont_nn,cat_nn = cont_cat_split(train_df,  dep_var='target')\n    dls = TabularPandas(train_df, [Categorify, Normalize], cat_nn, cont_nn, y_names='target').dataloaders(2048)\n    test_dl = dls.test_dl(test_df.fillna(0))\n    learn = tabular_learner(dls, y_range=(0,.1), layers=[1000,500,200], n_out=1, path = '..\/input\/optiver-models\/')\n    res = torch.zeros(len(test_df))\n    for idx in range(5):\n        learn.load(f'nn_fold{idx}')\n        preds, _ = learn.get_preds(dl=test_dl)\n        res += preds.squeeze() \/ 5\n    return res.numpy()","0f02e394":"def pred_lgb(test_df):\n    test_df = test_df.drop(['row_id', 'time_id'], axis=1)\n    res = np.zeros(len(test_df))\n#     for idx in range(9):\n#         filename = f'..\/input\/optiver-models\/models\/lgb_fold{idx}.pickle'\n#         model = pickle.load(open(filename, 'rb'))\n#         preds = model.predict(test_df)\n#         res += preds \/ 9\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold0.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds0 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold1.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds1 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold2.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds2 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold3.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds3 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold4.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds4 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold5.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds5 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold6.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds6 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold7.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds7 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold8.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds8 = model.predict(test_df)\n    filename = f'..\/input\/optiver-models\/models\/lgb_fold9.pickle'\n    model = pickle.load(open(filename, 'rb'))\n    preds9 = model.predict(test_df)\n    res = (preds0*1+preds1*1+preds2*1+preds3*6+preds4*8+preds5*0+preds6*0+preds7*1+preds8*0+preds9*0)\/18\n    return res","e4850cfc":"nn_preds = pred_tabular_nn(train_df, test_df)\nlgb_preds = pred_lgb(test_df)\n\ntest_df['target']=(nn_preds*0.575+lgb_preds*0.425)\ntest_df[['row_id', 'target']].to_csv('submission.csv', index =False)\npd.read_csv('submission.csv').head()","e94cccb8":"This notebook doesn't do anything novel in terms of features, nor architecture. Instead I want to show how you can structure your code and data to run experiments in a fast and concise manner. \n\nThe preprocessing code and LGB models were taken from [here](https:\/\/www.kaggle.com\/tatudoug\/stock-embedding-ffnn-features-of-the-best-lgbm) and based on [this](https:\/\/www.kaggle.com\/ragnar123\/optiver-realized-volatility-lgbm-baseline)\n\nThis is how it works:\n- The training set with features is cached and loaded from https:\/\/www.kaggle.com\/slawekbiel\/optiver-train-features\n- The code to generate those features is saved in an Utility Script: https:\/\/www.kaggle.com\/slawekbiel\/optiver-features and used to process the test data.\n- fast.ai library handles defining the NN model and preparing the data for it (normalization, embeddings, batching etc)\n- Both fastai nad LGB models are trained locally, serialized and then pushed to the dataset: https:\/\/www.kaggle.com\/slawekbiel\/optiver-models","43c4c547":"thanks for: https:\/\/www.kaggle.com\/slawekbiel\/short-fast-nn-lgb\nThis note is just a parameter optimization."}}