{"cell_type":{"8f9f998b":"code","dab59434":"code","a3755b38":"code","6ecefac9":"markdown","6030946e":"markdown"},"source":{"8f9f998b":"# From https:\/\/github.com\/graykode\/gpt-2-Pytorch\nimport os\n!git clone https:\/\/github.com\/graykode\/gpt-2-Pytorch.git\nos.chdir('.\/gpt-2-Pytorch')\n!curl --output gpt2-pytorch_model.bin https:\/\/s3.amazonaws.com\/models.huggingface.co\/bert\/gpt2-pytorch_model.bin\n!pip install -r requirements.txt","dab59434":"!python main.py --text \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. According to Dr. \"","a3755b38":"os.chdir('..\/')\n!rm -rf gpt-2-Pytorch","6ecefac9":"# Generating conditional samples","6030946e":"# Generate Text with OpenAI's GPT-2 Language Model (117M version)\n\n## For more information, refer to OpenAI's original blog post:\nhttps:\/\/blog.openai.com\/better-language-models\n\n## Details:\nOpenAI only released their smaller 117M parameter model but even this small model performs suprisingly well. You can generate conditional samples from a given sentence or generate unconditional samples. \n\n### Tuning parameters for optimal predictions\nThe model starts repeating itself more often when given short prompts, but changing the temperature from the default of 0.7 can give you better results. Increasing the temperature forces the model to make more novel predictions, but often causes the model to go off topic. Decreasing the temperature keeps the model from going off topic, but causes the model to repeat itself more often. \n\n## Options:\n```\n--text : sentence to begin with.\n--quiet : not print all of the extraneous stuff like the \"================\"\n--nsamples : number of sample sampled in batch when multinomial function use\n--unconditional : If true, unconditional generation.\n--batch_size : number of batch size\n--length : sentence length (< number of context)\n--temperature: the thermodynamic temperature in distribution (default 0.7)\n--top_k : Returns the top k largest elements of the given input tensor along a given dimension. (default 40)\n```\n\n## Code:\n https:\/\/github.com\/graykode\/gpt-2-Pytorch"}}