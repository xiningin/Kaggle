{"cell_type":{"e5e51ea2":"code","dfd8cb7a":"code","e52862f9":"code","2b8f3f68":"code","23736063":"code","7c832049":"code","5d64b6cd":"code","7141918f":"code","bd1bba53":"code","1dae2939":"code","45a5add3":"code","45e21390":"code","d1797371":"code","02a3dfb4":"code","3c5fc39a":"code","352f83ba":"code","a9d3028e":"code","bf34ce18":"code","ceae7581":"code","d6757c68":"code","336f845b":"code","bccbb7cb":"code","086cad4d":"code","b4b1402d":"code","126c6840":"code","3d802d01":"code","48fcd1b5":"code","b4332b92":"code","4342d72c":"code","9bfc16a5":"code","ebb04c3c":"code","d61ec788":"code","de87c82b":"code","98064b32":"code","a5455aa3":"code","de003793":"code","560f9a9b":"code","2df00b16":"code","cdad992a":"code","a60bd947":"code","9f02633d":"code","f06f8caa":"code","c39dd24b":"code","e636dc76":"code","dd5ba42e":"code","53b7ed6f":"code","4ed7358d":"markdown","b3ae90a3":"markdown","d9563d23":"markdown","f1749b47":"markdown","bfc1af8b":"markdown","0b2c521e":"markdown","55b61e61":"markdown","ba4fe41d":"markdown","c5ef3481":"markdown","cc70a278":"markdown","f9032dff":"markdown","b2c2cee8":"markdown","78d3a506":"markdown","4f9d2e31":"markdown","cab65726":"markdown","4f0a91c3":"markdown","cf0b0e8e":"markdown","1d55b2e4":"markdown","8ffd3c1c":"markdown","19d3c894":"markdown","aa8b230d":"markdown","a375e8eb":"markdown","e31c260c":"markdown","0321e4c6":"markdown","53eb9b49":"markdown","8be7735d":"markdown","58b07b57":"markdown","22f5d7b1":"markdown","02f79343":"markdown","5789cecb":"markdown","f0a0a43d":"markdown","1acda768":"markdown","76536f51":"markdown","89cf0778":"markdown","dc62a223":"markdown","0a21b077":"markdown","27109490":"markdown","f16e685a":"markdown","4cf1bcf5":"markdown","141d6047":"markdown","e102d27d":"markdown","0606baad":"markdown","306e3218":"markdown","8c716c0b":"markdown","9a836c76":"markdown","a6f997cf":"markdown","75a982e1":"markdown","4c823cd5":"markdown","b0094f7c":"markdown"},"source":{"e5e51ea2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# import os\n# os.chdir(\"C:\\\\Users\\\\DILIP\\\\Downloads\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport statsmodels.api as sm\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dfd8cb7a":"df=pd.read_csv('\/kaggle\/input\/lower-back-pain-symptoms-dataset\/Dataset_spine.csv')\ndf.head()","e52862f9":"df.drop('Unnamed: 13',axis=1,inplace=True)","2b8f3f68":"df.columns = ['pelvic_incidence','pelvic tilt','lumbar_lordosis_angle','sacral_slope','pelvic_radius','degree_spondylolisthesis','pelvic_slope','Direct_tilt','thoracic_slope','cervical_tilt','sacrum_angle','scoliosis_slope','Status']","23736063":"df.head()","7c832049":"df.info()","5d64b6cd":"columns=df.columns\nfor i in columns:\n    print(i,'has : ',df[i].nunique(),'Unique Values')","7141918f":"print(df.Status.value_counts())\nprint(df.Status.describe())","bd1bba53":"df.isnull().sum()","1dae2939":"df.describe().T","45a5add3":"sns.set(style=\"ticks\", color_codes=True)\nsns.pairplot(df)\nplt.show()","45e21390":"df.groupby('Status').mean()","d1797371":"df.groupby('Status').median()","02a3dfb4":"plt.figure(figsize=(10,7))\nsns.distplot(df['degree_spondylolisthesis'],bins=100, kde=True, color=\"blue\")","3c5fc39a":"df.skew()","352f83ba":"df.kurt()","a9d3028e":"df[\"deg1\"]=(df[\"degree_spondylolisthesis\"])**2","bf34ce18":"sns.set(style=\"darkgrid\")\nfig,ax=plt.subplots(1,2,figsize=(15,8))\nsns.kdeplot(df['degree_spondylolisthesis'],shade=True, color=\"black\",ax=ax[0])\nax[0].set_title('degree_spondylolisthesis')\nsns.kdeplot(df['deg1'],shade=True, color=\"black\",ax=ax[1])\nax[1].set_title('degree_spondylolisthesis after applying Square transformation')\nplt.show()\n","ceae7581":"df.drop('deg1',axis=1,inplace=True)","d6757c68":"correlation=df.corr()\ncorrelation","336f845b":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True,cmap='seismic_r')","bccbb7cb":"plt.figure(figsize=(12,10))\nmask = np.zeros_like(correlation, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(correlation, mask=mask, center=0, square=True, linewidths=.5,cmap='gist_ncar')\n\nplt.show()","086cad4d":"sns.set(style=\"darkgrid\")\nfig,ax=plt.subplots(2,3,figsize=(15,8))\nsns.swarmplot(\"Status\",\"pelvic_incidence\",data=df,ax=ax[0,0])\nsns.swarmplot(\"Status\",\"pelvic tilt\",data=df,ax=ax[0,1])\nsns.swarmplot(\"Status\",\"sacral_slope\",data=df,ax=ax[0,2])\nsns.swarmplot(\"Status\",\"degree_spondylolisthesis\",data=df,ax=ax[1,0])\nsns.swarmplot(\"Status\",\"lumbar_lordosis_angle\",data=df,ax=ax[1,1])\nsns.swarmplot(\"Status\",\"pelvic_radius\",data=df,ax=ax[1,2])\nplt.show()","b4b1402d":"def draw_histograms(dataframe, features, rows, cols):\n    fig=plt.figure(figsize=(20,20))\n    for i, feature in enumerate(features):\n        ax=fig.add_subplot(rows,cols,i+1)\n        dataframe[feature].hist(bins=20,ax=ax,facecolor='k')\n        ax.set_title(feature+\" Distribution\",color='DarkRed')\n        \n    fig.tight_layout()  \n    plt.show()\ndraw_histograms(df,df.columns,6,3)","126c6840":"fig, axes = plt.subplots(3, 4, figsize = (15,20))\naxes = axes.flatten()\nfor i in range(0,len(df.columns)-1):\n   \n    sns.kdeplot(df.iloc[:,i], ax=axes[i],shade=True, color=\"r\")\n\nplt.tight_layout()\nplt.show()","3d802d01":"fig, axes = plt.subplots(3, 4, figsize = (15,20))\naxes = axes.flatten()\n\nfor i in range(0,len(df.columns)-1):\n    sns.boxenplot(x=\"Status\", y=df.iloc[:,i], data=df, orient='v', ax=axes[i],palette=\"magma_r\")\n\nplt.tight_layout()\nplt.show()","48fcd1b5":"plt.figure(figsize=(8,5))\nsns.countplot('Status',data=df,palette=\"viridis_r\")\nplt.show()\ndf['Status'].value_counts()","b4332b92":"fig, ax = plt.subplots(figsize=(8,5))\n\nsns.swarmplot(x ='Status', y='degree_spondylolisthesis',ax=ax,size=4,data=df, palette=\"PuRd\") \nsns.boxplot(x ='Status', y='degree_spondylolisthesis',ax=ax,data=df)","4342d72c":"import plotly\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\ncol = \"Status\"\ngrouped = df[col].value_counts().reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ncolors = ['magenta', 'purplr']\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0],marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nlayout = {'title': 'Status of Spine(Normal, Abnormal)'}\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","9bfc16a5":"df[\"Status\"]=pd.get_dummies(df[\"Status\"],drop_first=True)","ebb04c3c":"from statsmodels.tools import add_constant as add_constant\ndf_constant = add_constant(df)\ndf_constant.head()","d61ec788":"cols=df_constant.columns[:-1]\nmodel=sm.Logit(df.Status,df_constant[cols])\nresult=model.fit()\nresult.summary()","de87c82b":"def back_feature_elem (data_frame,dep_var,col_list):\n\n\n    while len(col_list)>0 :\n        model=sm.Logit(dep_var,data_frame[col_list])\n        result=model.fit(disp=0)\n        largest_pvalue=round(result.pvalues,3).nlargest(1)\n        if largest_pvalue[0]<(0.05):\n            return result\n            break\n        else:\n            col_list=col_list.drop(largest_pvalue.index)\n\nresult=back_feature_elem(df_constant,df.Status,cols)","98064b32":"result.summary()","a5455aa3":"params = np.exp(result.params)\nconf = np.exp(result.conf_int())\nconf['OR'] = params\npvalue=round(result.pvalues,3)\nconf['pvalue']=pvalue\nconf.columns = ['CI 95%(2.5%)', 'CI 95%(97.5%)', 'Odds Ratio','pvalue']\nprint ((conf))\n","de003793":"import sklearn\nnew_features=df[['pelvic tilt','sacral_slope','pelvic_radius','degree_spondylolisthesis',\"Status\"]]\nx=new_features.iloc[:,:-1]\ny=new_features.iloc[:,-1]\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)","560f9a9b":"from sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred=logreg.predict(x_test)","2df00b16":"sklearn.metrics.accuracy_score(y_test,y_pred)","cdad992a":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nplt.figure(figsize = (8,5))\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap='gist_ncar')","a60bd947":"TN=cm[0,0]\nTP=cm[1,1]\nFN=cm[1,0]\nFP=cm[0,1]\nsensitivity=TP\/float(TP+FN)\nspecificity=TN\/float(TN+FP)","9f02633d":"print('The acuuracy of the model = TP+TN \/ (TP+TN+FP+FN) = ',(TP+TN)\/float(TP+TN+FP+FN),'\\n\\n',\n\n'The Miss-classification = 1-Accuracy = ',1-((TP+TN)\/float(TP+TN+FP+FN)),'\\n\\n',\n\n'Sensitivity or True Positive Rate = TP \/ (TP+FN) = ',TP\/float(TP+FN),'\\n\\n',\n\n'Specificity or True Negative Rate = TN \/ (TN+FP) = ',TN\/float(TN+FP),'\\n\\n',\n\n'Positive Predictive value = TP \/ (TP+FP) = ',TP\/float(TP+FP),'\\n\\n',\n\n'Negative predictive Value = TN \/ (TN+FN) = ',TN\/float(TN+FN),'\\n\\n',\n\n'Positive Likelihood Ratio = Sensitivity \/ (1-Specificity) = ',sensitivity\/(1-specificity),'\\n\\n',\n\n'Negative likelihood Ratio = (1-Sensitivity) \/ Specificity = ',(1-sensitivity)\/specificity)\n","f06f8caa":"y_pred_prob=logreg.predict_proba(x_test)[:,:]\ny_pred_prob_df=pd.DataFrame(data=y_pred_prob, columns=['Prob of abnormal spine (0)','Prb of normal spine (1)'])\ny_pred_prob_df.head()","c39dd24b":"from sklearn.preprocessing import binarize\nfor i in range(1,5):\n    cm2=0\n    y_pred_prob_yes=logreg.predict_proba(x_test)\n    y_pred2=binarize(y_pred_prob_yes,i\/10)[:,1]\n    cm2=confusion_matrix(y_test,y_pred2)\n    print ('With',i\/10,'threshold the Confusion Matrix is ','\\n',cm2,'\\n',\n            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n          'Sensitivity: ',cm2[1,1]\/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]\/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')\n    ","e636dc76":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_yes[:,1])\nplt.plot(fpr,tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.title('ROC curve for Heart disease classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\nplt.grid(True)","dd5ba42e":"sklearn.metrics.roc_auc_score(y_test,y_pred_prob_yes[:,1])","53b7ed6f":"print('Abnormal', round(df['Status'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Normal', round(df['Status'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","4ed7358d":"pelvic_incidence is highly correlated with pelvic tilt, sacral slope, degree spondylolisthesis and lumbar lordosis angle.","b3ae90a3":"We were completely right about the right skewness of the degree_spondylolisthesis.You can see that as above.","d9563d23":"# Interpreting the results: Odds Ratio, Confidence Intervals and Pvalues:","f1749b47":"# Model Evaluation:","bfc1af8b":"In most cases the mean is higher than median signifying that the data is positively skewed.However,this can also be due to outliers as the mean is affected by outliers in the data.","0b2c521e":"Accuracy of our model is 88.7%","55b61e61":"# Lower Backpain\n![image.png](attachment:image.png)","ba4fe41d":"CONFUSION MATRIX: \n\n\n\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \u201cclassifier\u201d) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.","c5ef3481":"Great! We have received an amazing score. Model is build well.","cc70a278":"# Logistic Regression:","f9032dff":"Lets plot the kernel density to know if there is any use of the transformation or not and compare:","b2c2cee8":"Let us see how all the variables are related with the target column.","78d3a506":"A common way to visualize the trade-offs of different thresholds is by using an ROC curve, a plot of the true positive rate ( true positives\/ total positives) versus the false positive rate ( false positives \/total negatives) for all possible choices of thresholds.\n\n\n\nA model with good classification accuracy should have significantly more true positives than false positives at all thresholds.\n\n\n\nThe optimum position for roc curve is towards the top left corner where the specificity and sensitivity are at optimum levels","4f9d2e31":"Here the columns are not named,so now we name the columns.\n\n\n\nAlso Unnamed is not of any significance so we drop it.","cab65726":"67% of the variables correspond to the Abnormal Status. 32.3% contribute to the Normal Status.","4f0a91c3":"degree_spondylolisthesis is having a positive skew.","cf0b0e8e":"We were sucessful in increasing sensitivity.","1d55b2e4":" Anything closer to +- 1 indicates high correlation between those two predictor variables.\n ","8ffd3c1c":"np.triu_indices_from:Returns the indices for the upper-triangle of an array.","19d3c894":"Lets see the relationship with the multicolinear variables with the target as below:","aa8b230d":"Here the power transformation has made it worst and given us no positive result.log transformation can often increase \u2013 not reduce \u2013 the variability of data whether or not there are outliers.Z score transform too, in this case will have no effect and hence we will se if we need to transform data or not after model building.","a375e8eb":"# The AUC\/ROC Curve:","e31c260c":"Logistic regression is a type of regression analysis in statistics used for prediction of outcome of a categorical dependent variable from a set of predictor or independent variables. In logistic regression the dependent variable is always binary. Logistic regression is mainly used to for prediction and also calculating the probability of success.","0321e4c6":"When all features plugged in:\n\n$$logit(p) = log(p\/(1-p))=\\beta_0 +\\beta_1\\hspace{.1cm} *\\hspace{.2cm} Pelvic tilt\\hspace{.2cm}+\\beta_2\\hspace{.1cm} * \\hspace{.1cm}\\hspace{.2cm}Sacral slope+\\hspace{.2cm}\\beta_3\\hspace{.1cm} *\\hspace{.1cm} Pelvic radius\\hspace{.2cm}+\\hspace{.2cm}\\beta_4 \\hspace{.1cm}*\\hspace{.1cm} degree spondylolisthesis\\hspace{.2cm}$$\n","53eb9b49":"Area Under The Curve (AUC)\n\n\nThe area under the ROC curve quantifies model classification accuracy ; the higher the area, the greater the disparity between true and false positives, and the stronger the model in classifying members of the training dataset.\n\n\nAn area of 0.5 corresponds to a model that performs no better than random classification and a good classifier stays as far away from that as possible. An area of 1 is ideal.\nThe closer the AUC to 1 the better.","8be7735d":"Great!  No Null Values.","58b07b57":"We need to lower our threshold in order to increase our Sensitivity.Because,a  False Negative ( ignoring the probability of abnormal spine when there actualy is one) is more dangerous than a False Positive in this case","22f5d7b1":"We can Clearly see the presence of outliers in the degree_spondylolisthesis. But since its a Data used for medical purposes, we cannot drop anything as it will lead to information loss.","02f79343":"Most of the individuals have an Abnormal Spine.But it is also evident here that more than 20% of individuals also have a normal spine.So, no imbalance data treatment required here.","5789cecb":"# Class Imbalance:","f0a0a43d":"Here we can see that almost all the features's skew are close to 0, except degree_spondylolisthesis, which has a right skew or a positive skew as seen above.\n\nAlso,kurtosis of all features is close to 0,which means most features are meso kurtic.Mesokurtic distributions are similar to normal distributions, in which extreme or outlier events are very unlikely.Great, so we know that majority of the events have no or little outliers.\n\nHowever in case of sacral_slope and degree_spondylolisthesis the kurtosis is >0, which means they are Leptokurtic.Leptokurtic means the distributions are more peaked than usual.sharply peaked with heavy tails.\n\n\nso we will just be transforming the degree_spondylolisthesis feature.","1acda768":"From the above statistics it is clear that the model is slightly specific than sensitive. The negative values are predicted comparately accurately than the positives.","76536f51":"Most Variables are roughly Normal except the degree_spondylolisthesis.","89cf0778":"The confusion matrix shows 37+18 = 55 correct predictions and 7 incorrect ones.\n\n**<font color=DarkBlue>True Positives:**  18<font>\n\n**<font color=DarkBlue>True Negatives:**  37<font>\n\n**<font color=DarkBlue>False Positives:** 3(*Type I error*)<font>\n\n**<font color=DarkBlue>False Negatives:** 4 ( *Type II error*)<font>","dc62a223":"The results above show some of the attributes with P value higher than the preferred alpha(5%) and thereby showing low statistically significant relationship with the probability of Abnormal Spine. Backward elemination approach is used here to remove those attributes with highest Pvalue one at a time follwed by running the regression repeatedly until all attributes have P Values less than 0.05.","0a21b077":"As we can see from above, there is multicolinearity in the data.","27109490":"So easy! Now, even a pleb can tell you which features are correlated:pelvic_incidence is highly correlated with pelvic tilt, sacral slope, degree spondylolisthesis and lumbar lordosis angle.","f16e685a":"To get a clearer view of correlation visually we use masking.\nMasks are an array of boolean values for which a condition is met.","4cf1bcf5":"Now we know that this is a classification problem.\n\nStatus of the Spine is the target variable.","141d6047":"Boxenplots are used when we need to draw an enhanced box plot for larger datasets","e102d27d":" Lets see the pearsons correlation plot for it:","0606baad":"Our Analysis from the above plots:\n\n1.Pelvic_incidence >= 100 will lead to an Abnormal Lower Back for sure, Less than that can be either normal or abnormal.\n\n\n2.Pelvic_tilt till 30 the Status can be normal or abnormal but if the pelvictitlt is somewhere greater than 30, then the spine is abnormal\n\n\n3.Sacral_slope does not have much of a relationship with the Spinal Status.However if its >70  it can lead to an Abnormal Spine for sure, there are outliears here.\n\n\n4.Normal Spine has a lower degree of Spondylolisthesis.\n\n\n5.lumbar_lordosis_angle:The Abnormal and Normal spine both have outliers.lumbar_lordosis_angle till 100 or less than 100 can either lead to a Normal or an Abnormal Spine.\n\n\n6.Pelvic_radius: A normal or Abnormal spines pelvic radius  can range in  between : 100 - 150. Any thing above or below will Definely lead to an Abnormal Spine .","306e3218":"pelvic_radius has a negative co-efficient indicating that for every unit increase in the values of this variable, the log of odds of the Status being Abnormal decreases.\ndegree_spondylolisthesis has a positive relationship with Abnormal status i.e for every unit increase in the value of degree_spondylolisthesis the log of odds of the Status being Abnormal increases.","8c716c0b":"I  cannot think of anyone who has not encountered a backpain once in a while.\n\nUrban Lifestyle,Corporate job, Constantly sitting in the same  position lead me into this uncomfortable and undesirable condition.\n\nHowever, it can be hard to differentiate on your own if the intensity is Normal or Abnormal.\n\nLower back pain is caused by injury to a muscle (strain) or ligament (sprain). Common causes include improper lifting, poor posture, lack of regular exercise, a fracture, a ruptured disc or arthritis.\n\nWhile lower back pain is extremely common, the symptoms and severity of lower back pain vary greatly.\n\nOften, the only symptom is pain in the lower back.\n\nMost low back pain goes away on its own in two to four weeks.\n\nA simple lower back muscle strain might be excruciating enough to necessitate an emergency room visit, while a degenerating disc might cause only mild, intermittent discomfort.Physiotherapy and pain relievers can help. A few cases may require surgery.\n\nThis data set is about to identify a person is abnormal or normal using collected physical spine details\/data.\n\nKindly Upvote if you learned anything new !Motivates me to post further.","9a836c76":"# Model Evaluation Statistics:","a6f997cf":"# Lets Explore:","75a982e1":"The mean corresponding to Abnormal for degree_spondylolisthesis is quite higher than the corresponding median,this is mainly because the degree_spondylolisthesis might be positively skewed or right skewed.Could be also due to outliers.","4c823cd5":"As we can see that most people have an anomaly in the lower back, lets see what factors are contributing to it in our further course of study.The dataset has 210 abnormal values and 100 normal.The dataset has no class imbalance.","b0094f7c":"### <font color= Blue>Predicted probabilities of  0 (Abnormal) and 1 ( Normal)  for the test data with a default classification threshold of 0.5 <font>\n"}}