{"cell_type":{"1bb731d3":"code","e26fb2c1":"code","b1621ae1":"code","ebef9933":"code","ef090bbc":"code","32dd4473":"code","b5ed40a9":"code","4e8758cb":"code","6dbc0517":"code","ca6c1cc0":"code","3113789c":"code","3be49821":"code","3c769c66":"code","cc420f71":"code","5f4c8245":"code","8ff69b7e":"code","1a063477":"code","33704c76":"markdown","77f069a3":"markdown","173d7140":"markdown","0dc01604":"markdown","87d334fa":"markdown","086ad210":"markdown","9d0b63ad":"markdown"},"source":{"1bb731d3":"import os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nfrom tensorflow.contrib.keras import models\nfrom tensorflow.contrib.keras import layers ","e26fb2c1":"# Set some parameters\nim_width = 128\nim_height = 128\nim_chan = 1\npath_train = '..\/input\/train\/'\npath_test = '..\/input\/test\/'","b1621ae1":"ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\nplt.figure(figsize=(20,10))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    img = load_img('..\/input\/train\/images\/' + img_name + '.png')\n    img_mask = load_img('..\/input\/train\/masks\/' + img_name + '.png')\n    \n    plt.subplot(1,2*(1+len(ids)),q*2-1)\n    plt.imshow(img)\n    plt.subplot(1,2*(1+len(ids)),q*2)\n    plt.imshow(img_mask)\nplt.show()","ebef9933":"train_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]","ef090bbc":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    img = load_img(path + '\/images\/' + id_)\n    x = img_to_array(img)[:,:,1]\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_train[n] = x\n    mask = img_to_array(load_img(path + '\/masks\/' + id_))[:,:,1]\n    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\nprint('Done!')","32dd4473":"# Check if training data looks all right\nix = random.randint(0, len(train_ids))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","b5ed40a9":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","4e8758cb":"im_height","6dbc0517":"# Build U-Net model\nstart_neurons=16\ninputs = Input((im_height, im_width, im_chan))\ns = Lambda(lambda x: x \/ 255) (inputs)\n\n# standard size 128 -> 64   custome size 101 -> 50\nconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(s)\nconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\npool1 = MaxPooling2D((2, 2))(conv1)\n#pool1 = Dropout(0.25)(pool1)\n\n# standard size 64 -> 32       custome size 50 -> 25\nconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\nconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\npool2 = MaxPooling2D((2, 2))(conv2)\n#pool2 = Dropout(0.25)(pool2)\n\n# standard size 32 -> 16       custome size 25 -> 12\nconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\nconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n\n\n\n\n# standard size 32 -> 64   custome size 25 -> 50\ndeconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(conv3)\nuconv2 = concatenate([deconv2, conv2])\n#uconv2 = Dropout(0.25)(uconv2)\nuconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\nuconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n# standard size 64 -> 128   custome size 50 -> 101\n# Changed padding from \"same\" to \"valid\" to round up image to next size\n#deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\ndeconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\nuconv1 = concatenate([deconv1, conv1])\n#uconv1 = Dropout(0.25)(uconv1)\nuconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\nuconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n\n#uconv1 = Dropout(0.25)(uconv1)\noutput_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\nmodel = Model(inputs=[inputs], outputs=[output_layer])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","ca6c1cc0":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=35, \n                    )","3113789c":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    img = load_img(path + '\/images\/' + id_)\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')","3be49821":"# Predict on train, val and test\nmodel = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","3c769c66":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","cc420f71":"preds_test_upsampled[0].shape","5f4c8245":"# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train_t))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()\ntmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","8ff69b7e":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}","1a063477":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","33704c76":"# Prepare Submission\nWe need to prepare the submission. A nice CSV with predictions. All of this is one to one from Ketil and does not differ from any of the other segmentation tasks. Check them out to improve on this.","77f069a3":"Reference: All credit goes to her and her nice code https:\/\/www.kaggle.com\/jesperdramsch\/intro-to-seismic-salt-and-how-to-geophysics  \n\ni just make network deep\n\n\n","173d7140":"# Train Model\nOur task, just like the segmentation task for nuclei, is evaluated on the mean IoU metric. This one isn't in keras, but obviously, we're stealing this one too from Ketil.","0dc01604":"We'll look at it again, just to be sure.","87d334fa":"# Test Data\nFirst we'll get the test data. This takes a while, it's 18000 samples.","086ad210":"# Data Exploration\nLet's look at some data. We can see that TGS chose to use very varied data by inspecting. That is great and adresses a problem in deep learning geoscience at the moment. We build models on one type of seismic and have no idea whether it generalizes.","9d0b63ad":"This is the fun part. Building the sequential Model. The U-Net is basically looking like an Auto-Encoder with shortcuts. \n\nWe're also sprinkling in some earlystopping to prevent overfitting. If you're running this on kaggle, this is the point, you want to have GPU support."}}