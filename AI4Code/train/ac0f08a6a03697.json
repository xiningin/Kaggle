{"cell_type":{"a50a422f":"code","1f6e8867":"code","0b0c80cc":"code","b3b4ca7d":"code","c7482f5a":"code","36e15b25":"code","f2dc3e4e":"code","3d392491":"code","6075f3bb":"code","156d6c0c":"code","caeb68f7":"code","6f117c88":"code","90654e23":"code","63d39fb7":"code","71af1cfa":"code","e6931a48":"code","f0986ec1":"code","69ef42df":"code","b4ca30a2":"code","1a2325fe":"code","464f130d":"code","a4e25e8c":"code","6326900b":"code","57ce31d4":"code","3d184f56":"code","1339cd49":"code","7bf4c2cd":"code","52662f68":"code","bc74b78e":"code","a3d6836d":"code","17053664":"code","22db6c9e":"code","3030c185":"code","354dfb61":"code","987e46a0":"code","b68aff93":"code","2882c935":"code","24bbb825":"code","250d8cdc":"code","a9cfe58e":"code","7442d770":"code","08d426fd":"code","5ad022c2":"code","7bbcdeb3":"code","81384fc8":"markdown","653e5649":"markdown","c66c0fd1":"markdown","e6e34a10":"markdown","bcf40d0a":"markdown","977fcd12":"markdown","e13217d6":"markdown","03bf9f99":"markdown","e9269bac":"markdown","d1c4b392":"markdown","f628bd6d":"markdown","d06cf830":"markdown","1ad1716d":"markdown","0a7dd568":"markdown"},"source":{"a50a422f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f6e8867":"import tensorflow as tf\nimport random as rn\nimport os\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(6)\ntf.random.set_seed(6)","0b0c80cc":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nX_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","b3b4ca7d":"sub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","c7482f5a":"train.head()","36e15b25":"train.shape","f2dc3e4e":"X_train = train.copy()\ny_train = X_train.pop('label')","3d392491":"y_train.value_counts()","6075f3bb":"from sklearn.preprocessing import StandardScaler","156d6c0c":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","caeb68f7":"y_train = pd.get_dummies(y_train)   ","6f117c88":"from keras.models import Model\nfrom keras.layers import Input, Dense, Flatten\nfrom sklearn.model_selection import train_test_split","90654e23":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=6)","63d39fb7":"inp = Input(shape=(784,))\nout = Dense(10, activation='softmax')(inp)\nmodel = Model(inputs=inp, outputs=out)","71af1cfa":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","e6931a48":"# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)","f0986ec1":"def get_sub(x):\n    pred = model.predict(X_test)\n    pred_classes = pred.argmax(axis=-1)\n    sub['Label'] = pred_classes\n    return sub\nsub = get_sub(X_test)\nsub.to_csv('submission.csv', index=False)","69ef42df":"# Leaderboard : 0.91246","b4ca30a2":"inp = Input(shape=(784,))\nhidden = Dense(256, activation='relu')(inp)\nout = Dense(10, activation='softmax')(hidden)\nmodel = Model(inputs=inp, outputs=out)","1a2325fe":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","464f130d":"# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)","a4e25e8c":"sub = get_sub(X_test)\nsub.to_csv('submission.csv', index=False)","6326900b":"# Leaderboard : 0.95932","57ce31d4":"from keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping","3d184f56":"early_stop = EarlyStopping(patience=5, restore_best_weights=True)","1339cd49":"X_train = np.array(X_train).reshape((31500, 28, 28, 1))\nX_val = np.array(X_val).reshape((10500, 28, 28, 1))\nX_test = np.array(X_test).reshape((28000, 28, 28, 1))","7bf4c2cd":"inp = Input(shape=(28, 28, 1))\nconv = Conv2D(16, kernel_size=(3,3), padding='same')(inp)\npool = MaxPooling2D()(conv)\nhidden = Dense(256, activation='relu')(pool)\nflatten = Flatten()(hidden)\nout = Dense(10, activation='softmax')(flatten)\nmodel = Model(inputs=inp, outputs=out)","52662f68":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","bc74b78e":"# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[early_stop])","a3d6836d":"sub = get_sub(X_test)\nsub.to_csv('submission.csv', index=False) ","17053664":"# Leaderboard : 0.97875","22db6c9e":"import matplotlib.pyplot as plt","3030c185":"fig, ax = plt.subplots(1,5, figsize=(15,5))\nfor i in np.arange(1,6,1):\n    ax[i-1] = plt.subplot(1, 5, i)\n    plt.imshow(X_train[i])\n    plt.tight_layout()","354dfb61":"from keras.layers import Resizing, RandomZoom, RandomRotation","987e46a0":"inp = Input(shape=(28, 28, 1))\n\nresized = Resizing(38,38)(inp)\nzoom = RandomZoom(0.07)(resized)   \nrot = RandomRotation(0.07)(zoom)\n\nconv = Conv2D(16, kernel_size=(3,3), padding='same')(inp)\npool = MaxPooling2D()(conv)\n\nhidden = Dense(256, activation='relu')(pool)\nflatten = Flatten()(hidden)\nout = Dense(10, activation='softmax')(flatten)\nmodel = Model(inputs=inp, outputs=out)","b68aff93":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","2882c935":"model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[early_stop])","24bbb825":"sub = get_sub(X_test)\nsub.to_csv('submission.csv', index=False) ","250d8cdc":"# Leaderboard : 0.97760","a9cfe58e":"from keras.layers import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau","7442d770":"lr_plat = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.3, min_lr=0.00001)","08d426fd":"inp = Input(shape=(28, 28, 1))      \n\n# Data augmentation\nresized = Resizing(38,38)(inp)\nzoom = RandomZoom(0.07)(resized)   \nrot = RandomRotation(0.07)(zoom)\n\nconv = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(rot)                             \npool = MaxPooling2D()(conv)          \nnorm = BatchNormalization()(pool)\n\nconv_2 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(norm)\npool_2 = MaxPooling2D()(conv_2)\nnorm_2 = BatchNormalization()(pool_2)\n\nconv_3 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(norm_2)        \npool_3 = MaxPooling2D()(conv_3)\nnorm_3 = BatchNormalization()(pool_3)\n\nconv_4 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(norm_3)        \npool_4 = MaxPooling2D()(conv_4)\nnorm_4 = BatchNormalization()(pool_4)\n\nconv_5 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(norm_4)        \npool_5 = MaxPooling2D()(conv_5)\nnorm_5 = BatchNormalization()(pool_5)\n\nhidden = Dense(256, activation='relu')(norm_5)\nflatten = Flatten()(hidden)\nout = Dense(10, activation='softmax')(flatten)\n\nmodel = Model(inputs=inp, outputs=out)\n\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","5ad022c2":"model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=40, callbacks=[early_stop, lr_plat], batch_size=64)                                                         ","7bbcdeb3":"sub = get_sub(X_test)            \nsub.to_csv('submission.csv', index=False)                     ","81384fc8":"# **Baseline Model**","653e5649":"Scale the data","c66c0fd1":"One hot encode target","e6e34a10":"# **Data augmentation**","bcf40d0a":"We have to reshape the data to feed the convolution layer","977fcd12":"# **Optimizations**","e13217d6":"Some observations : \n\nTask : multi class classification\n\nClasses are pretty balanced","03bf9f99":"I'll add several things to increase the accuracy : \n* 4 more convolution \/ pooling layers\n* Batch Normalization layers\n* a new callback which will reduce the learning rate by steps","e9269bac":"Taking a look at the images makes me think there's not a big need for data augmentation\n\nEvery transformation i want to apply can be process directly in the network using keras layers (https:\/\/www.tensorflow.org\/guide\/keras\/preprocessing_layers)","d1c4b392":"# **Hidden layer**","f628bd6d":"Final model : ","d06cf830":"# **Convolution and pooling**","1ad1716d":"From now on i'll use an early stopping which stop the training of the model when it hits the best score (the lowest loss function value by default) ","0a7dd568":"The model seems to need more complexity to treat those new layers"}}