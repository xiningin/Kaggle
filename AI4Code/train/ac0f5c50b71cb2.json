{"cell_type":{"99392159":"code","89d00813":"code","02db21c6":"code","79a82ee4":"code","334b9d33":"code","c92c356e":"code","5aa2ec73":"code","4f98637f":"code","f6a2faa1":"code","0e16678e":"code","a9316092":"code","da3537fd":"code","a72d3ea5":"code","9b925545":"code","4f017881":"code","89485485":"code","c42af071":"code","7d3111fe":"code","10ca8fc7":"code","13fd2be0":"code","d91abf2a":"code","a8583dfb":"code","35156f8b":"code","705b6b72":"code","ee7f08f1":"markdown","abe5a9db":"markdown","264b2035":"markdown"},"source":{"99392159":"import numpy as np\nimport pandas as pd\n\nimport os\nprint(os.listdir('..\/input\/digit-recognizer'))\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\nfrom sklearn.model_selection import train_test_split\n\n# OpenCV Image Library\nimport cv2 # Image provessing library\n\n# Import PyTorch\nimport torchvision.transforms as transforms # Useful to make transformation on images easily\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch\nimport torch.nn as nn # To build neural network on PyTorch\nimport torch.nn.functional as F # Useful to get specific layers for the nn\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset # To create torch datasets\nimport torchvision # Very large package that contains datasets, models etc...\nimport torch.optim as optim # To get the optimizer of our model","89d00813":"# Data paths\ntrain_path = '..\/input\/digit-recognizer\/train.csv'\ntest_path = '..\/input\/digit-recognizer\/test.csv'\nsample_sub_path = '..\/input\/digit-recognizer\/sample_submission.csv'","02db21c6":"df_train = pd.read_csv(train_path, dtype=np.float32)\ndf_test = pd.read_csv(test_path, dtype=np.float32)\ndf_sample_sub = pd.read_csv(sample_sub_path)","79a82ee4":"print(df_train.shape)\nprint(df_test.shape)\nprint(df_sample_sub.shape)","334b9d33":"y_train_full = df_train['label'].to_numpy() # We need to convert pd.DataFrame to numpy array to then, convert it to PyTorch tensor\nX_train_full = df_train.loc[:,df_train.columns != 'label']","c92c356e":"X_train_full = X_train_full.values.reshape(-1,1,28,28) # (nbr of samples, height, width, channel) Since these are not colored images, there's only one channel\ndf_test = df_test.values.reshape(-1,1,28,28)\n\nX_train_full \/= 255.0\ndf_test \/= 255.0\n\n# Split into training and test set\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)","5aa2ec73":"# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\nX_train_pyt = torch.from_numpy(X_train)\ny_train_pyt = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for validation set.\nX_val_pyt = torch.from_numpy(X_val)\ny_val_pyt = torch.from_numpy(y_val).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for the final set that will be used to train the final model.\nX_train_full_pyt = torch.from_numpy(X_train_full)\ny_train_full_pyt = torch.from_numpy(y_train_full).type(torch.LongTensor) # data type is long\n\n# Data for submission\nX_test_pyt = torch.from_numpy(df_test)\n#y_test_pyt = torch.from_numpy(y_test).type(torch.LongTensor)","4f98637f":"print(X_train_pyt.shape)\nprint(X_val_pyt.shape)\nprint(X_train_full_pyt.shape)\nprint(X_test_pyt.shape)","f6a2faa1":"# Set batch size\nbatch_size = 64\n\n# Pytorch train and test sets\ndf_train_pyt = torch.utils.data.TensorDataset(X_train_pyt,y_train_pyt)\ndf_val_pyt = torch.utils.data.TensorDataset(X_val_pyt,y_val_pyt)\ndf_train_full_pyt = torch.utils.data.TensorDataset(X_train_full_pyt,y_train_full_pyt)\ndf_test_pyt = torch.utils.data.TensorDataset(X_test_pyt)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(df_train_pyt, batch_size = batch_size, shuffle = True)\nvalid_loader = torch.utils.data.DataLoader(df_val_pyt, batch_size = batch_size, shuffle = True)\nsubmission_loader = torch.utils.data.DataLoader(df_train_full_pyt, batch_size = batch_size, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(df_test_pyt, batch_size = batch_size, shuffle = False)","0e16678e":"one_batch_images, one_batch_labels = next(iter(train_loader))\n\none_image = one_batch_images[0,0,:,:]\none_label = one_batch_labels[0]\n\nplt.imshow(one_image)\nplt.title(one_label)\nplt.axis('off')\nplt.show()","a9316092":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(in_features = 320,  out_features = 50)\n        self.fc2 = nn.Linear(in_features = 50, out_features = 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)","da3537fd":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","a72d3ea5":"# create a complete CNN\nmodel = Net()\nprint(model)\n\n# Move model to GPU if available\nif train_on_gpu: model.cuda()","9b925545":"criterion = nn.NLLLoss()\n\n# Define the optimier\noptimizer = optim.Adam(model.parameters(), lr=0.0015)","4f017881":"# number of epochs to train the model\nn_epochs = 30\n\nvalid_loss_min = np.Inf # track change in validation loss\n\n# keeping track of losses as it happen\ntrain_losses = []\nvalid_losses = []\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'best_model.pt')\n        valid_loss_min = valid_loss","89485485":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(valid_losses, label='Validation loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend(frameon=False)","c42af071":"# Load Best parameters learned from training into our model to make predictions later\n#best_model = model.load_state_dict(torch.load('best_model.pt'))\n#model.load_state_dict(torch.load('best_model.pt'))\n\n#model.load_state_dict(torch.load('best_model.pt'))\ncheckpoint = torch.load('best_model.pt')\nmodel.load_state_dict(torch.load('best_model.pt'))","7d3111fe":"for keys in checkpoint:\n    print(keys)","10ca8fc7":"#final_test_np = final_test.values\/255\ntest_tn = torch.from_numpy(df_test)","13fd2be0":"# Creating fake labels for convenience of passing into DataLoader\n## CAUTION: There are other ways of doing this, I just did it this way\nfake_labels = np.zeros(df_test.shape)\nfake_labels = torch.from_numpy(fake_labels)","d91abf2a":"submission_tn_data = torch.utils.data.TensorDataset(test_tn, fake_labels)\n\nsubmission_loader = torch.utils.data.DataLoader(submission_tn_data, batch_size = batch_size, shuffle = False)","a8583dfb":"# Making it submission ready\nsubmission = [['ImageId', 'Label']]\n\n        \n\n# Turn off gradients for validation\nwith torch.no_grad():\n    #best_model.eval()\n    model.eval()\n    image_id = 1\n    for images, _ in submission_loader:\n        if train_on_gpu:\n            images = images.cuda()\n        log_ps = model(images)\n        ps = torch.exp(log_ps)\n        top_p, top_class = ps.topk(1, dim=1)\n        \n        for prediction in top_class:\n            submission.append([image_id, prediction.item()])\n            image_id += 1","35156f8b":"submission_df = pd.DataFrame(submission)\nsubmission_df.columns = submission_df.iloc[0]\nsubmission_df = submission_df.drop(0, axis=0)","705b6b72":"submission_df.to_csv(\"submission.csv\", index=False)","ee7f08f1":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # Convolutional Layer (sees 28*28*1 image tensor) \n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 16x16x16 image tensor)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 8x8x32 image tensor)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 4*4*64 image tensor)\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        # Maxpooling Layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # Linear Fully-Connected Layer 1 (sees 2*2*128 image tensor)\n        self.fc1 = nn.Linear(128*2*2, 512)\n        # Linear FC Layer 2\n        self.fc2 = nn.Linear(512, 10)\n        # Set Dropout\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x):\n        # add sequence of convolutional and max pooling layers\n        x = self.pool(F.relu(self.conv1(x))) # 14*14\n        x = self.pool(F.relu(self.conv2(x))) # 7*7\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        # flatten image input\n        x = x.view(-1, 128 * 2 * 2)\n        # add dropout layer\n        x = self.dropout(x)\n        # add 1st hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        # add dropout layer\n        x = self.dropout(x)\n        # add 2nd hidden layer, with relu activation function\n        x = self.fc2(x)\n        return x","abe5a9db":"## Load the training data","264b2035":"## Import the relevant libraries"}}