{"cell_type":{"ca92c072":"code","a1ed33ae":"code","83b63904":"code","aa834f62":"code","3c744d60":"code","042994e9":"code","2e9b2c99":"code","3579afd9":"code","aca2b0eb":"code","99cea806":"code","9056566b":"code","9ef4313d":"markdown","c9377249":"markdown","87d8d8e6":"markdown","44404b84":"markdown","6b05b2f5":"markdown","160d68a6":"markdown","9939c586":"markdown","0f38417c":"markdown","e91c6f9a":"markdown","eecd6ff5":"markdown","e5fdcafb":"markdown","932963f6":"markdown"},"source":{"ca92c072":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.getcwd())\nprint('number {:d}'.format(4))\n\n# os.walk('\/kaggle\/input\/Fashion MNIST') \u6709\u7a7a\u683c \u9519\u8bef\u7684\u6587\u4ef6\u8def\u5f84\u5199\u6cd5\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/fashionmnist'):\n# for dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a1ed33ae":"#!\/usr\/bin\/env python\nimport multiprocessing\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom typing import Any, Optional, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.backends.cudnn as cudnn\n\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nfrom tqdm import tqdm","83b63904":"IN_KERNEL = os.environ.get('KAGGLE_WORKING_DIR') is not None\n# \u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684\u6837\u672c\u6570\u76ee\u81f3\u5c11\u662f50\nMIN_SAMPLES_PER_CLASS = 50\nBATCH_SIZE = 512\nLEARNING_RATE = 1e-3\nLR_STEP = 1          # epoch\nLR_FACTOR = 0.5\nNUM_WORKERS = multiprocessing.cpu_count()\n# \u9700\u8981\u5927\u5bb6\u6539\n# MAX_STEPS_PER_EPOCH = 15000\nMAX_STEPS_PER_EPOCH = 15 \nNUM_EPOCHS = 2\n# \u6bcf\u51e0\u4e2aiteration\u663e\u793aloss\nLOG_FREQ = 5\n# \u8fd9\u662f\u4ec0\u4e48\u610f\u601d\uff1f\uff1f\uff1f\uff1f\nNUM_TOP_PREDICTS = 20","aa834f62":"class LandmarkDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, mode):\n        print(f'creating data loader - {mode}')\n        assert mode in ['train', 'val', 'test']\n        \n        self.df = dataframe   # \u4ece \u2018train.csv\u2019\u6587\u4ef6 \u8bfb\u597d\u7684\u6570\u636e\n        self.mode = mode\n        transforms_list = []\n\n        if self.mode == 'train':\n            transforms_list = [\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomChoice([\n                    transforms.RandomResizedCrop(64),\n                    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n                    transforms.RandomAffine(degrees=15, translate=(0.2, 0.2),\n                                            scale=(0.8, 1.2), shear=15,\n                                            resample=Image.BILINEAR)\n                ])\n            ]\n\n        transforms_list.extend([\n            transforms.ToTensor(),\n            # \u8fd9\u4e9b\u6570\u503c \u53ef\u80fd\u662flandmark_Recognition \u4e0a\u6839\u636eimage \u7b97\u51fa\u6765\u7684 \/ \u4e5f\u53ef\u80fd\u662fiamgenet\u6570\u636e\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225]),\n        ])\n        self.transforms = transforms.Compose(transforms_list)\n    \n    def __getitem__(self, index):\n        ''' Returns: tuple (sample, target) '''\n        # df \u662fdataframe, csv\u6587\u4ef6\uff0c train.csv, \u662f\u7531\u6570\u636e\u5e93\u672c\u8eab\u63d0\u4f9b\u7684\u3002\n        filename = self.df.id.values[index]   # 45465656.jpg\n\n        part = 1 if self.mode == 'test' or filename[0] in '01234567' else 2\n        directory = 'test' if self.mode == 'test' else 'train_' + filename[0]\n        sample = Image.open(f'..\/input\/google-landmarks-2019-64x64-part{part}\/{directory}\/{self.mode}_64\/{filename}.jpg')\n        assert sample.mode == 'RGB'\n\n        image = self.transforms(sample)\n\n        if self.mode == 'test':\n            return image\n        elif self.mode == 'train':\n            # image and target\n            return image, self.df.landmark_id.values[index]\n\n    def __len__(self):\n        return self.df.shape[0]","3c744d60":"def load_data():\n    # \u8fd9\u4e2a\u6211\u4e5f\u4e0d\u77e5\u9053 \u5c31\u6284\u8fc7\u6765\u5427\u3002\n    torch.multiprocessing.set_sharing_strategy('file_system')\n    cudnn.benchmark = True\n\n    # only use classes which have at least MIN_SAMPLES_PER_CLASS samples\n    print('loading data...')\n    df = pd.read_csv('..\/input\/google-landmarks-2019-64x64-part1\/train.csv')\n    df.drop(columns='url', inplace=True)\n\n    counts = df.landmark_id.value_counts()\n    selected_classes = counts[counts >= MIN_SAMPLES_PER_CLASS].index\n    num_classes = selected_classes.shape[0]\n    print('# of classes with at least {:d} samples: {:d}'.format(MIN_SAMPLES_PER_CLASS, num_classes))\n\n    train_df = df.loc[df.landmark_id.isin(selected_classes)].copy()\n    print('train_df', train_df.shape)\n\n    test_df = pd.read_csv('..\/input\/google-landmarks-2019-64x64-part1\/test.csv', dtype=str)\n    test_df.drop(columns='url', inplace=True)\n    print('test_df', test_df.shape)\n\n    # filter non-existing test images\n    exists = lambda img: os.path.exists(f'..\/input\/google-landmarks-2019-64x64-part1\/test\/test_64\/{img}.jpg')\n    test_df = test_df.loc[test_df.id.apply(exists)].copy()\n    print('test_df after filtering', test_df.shape)\n    assert test_df.shape[0] > 112000\n\n    label_encoder = LabelEncoder()\n    label_encoder.fit(train_df.landmark_id.values)\n    print('found classes', len(label_encoder.classes_))\n    assert len(label_encoder.classes_) == num_classes\n\n    train_df.landmark_id = label_encoder.transform(train_df.landmark_id)\n\n    # \u4e0b\u9762\u8fd9\u4e9b\u90fd\u662f\u6807\u51c6pytorch\u8bed\u6cd5\n    train_dataset = LandmarkDataset(train_df, mode='train')\n    test_dataset = LandmarkDataset(test_df, mode='test')\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                             shuffle=False, num_workers=NUM_WORKERS)\n\n    return train_loader, test_loader, label_encoder, num_classes","042994e9":"class AverageMeter:\n    ''' Computes and stores the average and current value '''\n    def __init__(self) -> None:\n        self.reset()\n\n    def reset(self) -> None:\n        self.val = 0.0\n        self.avg = 0.0\n        self.sum = 0.0\n        self.count = 0\n\n    def update(self, val: float, n: int = 1) -> None:\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","2e9b2c99":"def GAP(predicts: torch.Tensor, confs: torch.Tensor, targets: torch.Tensor) -> float:\n    ''' Simplified GAP@1 metric: only one prediction per sample is supported '''\n    assert len(predicts.shape) == 1\n    assert len(confs.shape) == 1\n    assert len(targets.shape) == 1\n    assert predicts.shape == confs.shape and confs.shape == targets.shape\n\n    _, indices = torch.sort(confs, descending=True)\n\n    confs = confs.cpu().numpy()\n    predicts = predicts[indices].cpu().numpy()\n    targets = targets[indices].cpu().numpy()\n\n    res, true_pos = 0.0, 0\n\n    for i, (c, p, t) in enumerate(zip(confs, predicts, targets)):\n        rel = int(p == t)\n        true_pos += rel\n\n        res += true_pos \/ (i + 1) * rel\n\n    res \/= targets.shape[0] \n    return res\n","3579afd9":"def train(train_loader, model, criterion, optimizer,\n          epoch, lr_scheduler):\n    print(f'epoch {epoch}')\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    avg_score = AverageMeter()\n\n    model.train()\n    num_steps = min(len(train_loader), MAX_STEPS_PER_EPOCH)  # \u662f 20\n    print(f'total batches: {num_steps}')\n\n    end = time.time()\n    lr_str = ''\n\n    for i, (input_, target) in enumerate(train_loader):\n        if i >= num_steps:\n            break\n\n        output = model(input_.cuda())\n        loss = criterion(output, target.cuda())\n\n        confs, predicts = torch.max(output.detach(), dim=1)\n        avg_score.update(GAP(predicts, confs, target))\n\n        losses.update(loss.data.item(), input_.size(0))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % LOG_FREQ == 0:\n            print(f'{epoch} [{i}\/{num_steps}]\\t'\n                        f'time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                        f'loss {losses.val:.4f} ({losses.avg:.4f})\\t'\n                        f'GAP {avg_score.val:.4f} ({avg_score.avg:.4f})'\n                        + lr_str)\n            \n    print(f' * average GAP(accuray\/error) on train {avg_score.avg:.4f}')","aca2b0eb":"def inference(data_loader: Any, model: Any) -> Tuple[torch.Tensor, torch.Tensor,\n                                                     Optional[torch.Tensor]]:\n    ''' Returns predictions and targets, if any. '''\n    model.eval()\n    activation = nn.Softmax(dim=1)\n    all_predicts, all_confs, all_targets = [], [], []\n\n    with torch.no_grad():\n        for i, data in enumerate(tqdm(data_loader, disable=IN_KERNEL)):\n            if data_loader.dataset.mode != 'test':\n                input_, target = data\n            else:\n                input_, target = data, None\n\n            output = model(input_.cuda())\n            output = activation(output)\n\n            confs, predicts = torch.topk(output, NUM_TOP_PREDICTS)\n            all_confs.append(confs)\n            all_predicts.append(predicts)\n\n            if target is not None:\n                all_targets.append(target)\n\n    predicts = torch.cat(all_predicts)\n    confs = torch.cat(all_confs)\n    targets = torch.cat(all_targets) if len(all_targets) else None\n\n    return predicts, confs, targets","99cea806":"def generate_submission(test_loader: Any, model: Any, label_encoder: Any) -> np.ndarray:\n    \n    # \u5751\uff1a\"-\" \u4e2d\u95f4\u6a2a\u7ebf\uff0c\u4e0d\u662f\u4e0b\u5212\u7ebf\uff01\uff01\uff01\n    sample_sub = pd.read_csv('..\/input\/julyonline-landmark\/haha_sample_submission.csv')\n\n    predicts_gpu, confs_gpu, _ = inference(test_loader, model)\n    predicts, confs = predicts_gpu.cpu().numpy(), confs_gpu.cpu().numpy()\n\n    labels = [label_encoder.inverse_transform(pred) for pred in predicts]\n    print('labels')\n    print(np.array(labels))\n    print('confs')\n    print(np.array(confs))\n\n    sub = test_loader.dataset.df\n    def concat(label: np.ndarray, conf: np.ndarray) -> str:\n        return ' '.join([f'{L} {c}' for L, c in zip(label, conf)])\n    sub['landmarks'] = [concat(label, conf) for label, conf in zip(labels, confs)]\n\n    sample_sub = sample_sub.set_index('id')\n    sub = sub.set_index('id')\n    sample_sub.update(sub)\n\n    sample_sub.to_csv('july_today_Dec_3_NEW.csv')","9056566b":"# \u6570\u636e\ntrain_loader, test_loader, label_encoder, num_classes = load_data()\n\nmodel = torchvision.models.resnet50(pretrained=False)\n# \u8981\u4e8b\u5148\u6d4f\u89c8resnet-50 \u6bcf\u4e00\u5c42\u7684\u540d\u5b57\uff0c\u624d\u77e5\u9053 \u6709 \"avg_pool\"\nmodel.avg_pool = nn.AdaptiveAvgPool2d(1)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)  # 1.8w \u7c7b\u7684\u4e2a\u6570\nmodel.cuda()   # \u9001\u5230GPU\u4e2d\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP,\n                                               gamma=LR_FACTOR)\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    print('-' * 50)\n    train(train_loader, model, criterion, optimizer, epoch, lr_scheduler)\n    lr_scheduler.step()\n\nprint('inference mode')\ngenerate_submission(test_loader, model, label_encoder)\nprint('done')","9ef4313d":"## \u4e3b\u51fd\u6570","c9377249":"### \u751f\u6210\u7ed3\u679c","87d8d8e6":"### \u5177\u4f53define dataset","44404b84":"## \u5b50\u51fd\u6570\uff1atest","6b05b2f5":"### define dataloader","160d68a6":"### \u8bc4\u4ef7\u51fd\u6570","9939c586":"\u5404\u4f4d\u540c\u5b66\u5927\u5bb6\u597d\uff0c\u73b0\u5c06kernel\u91cd\u5199\u3002\n\n2019\u5e7412\u67083\u65e5","0f38417c":"### \u5b50\u51fd\u6570\uff1atrain","e91c6f9a":"Step 1: \u51c6\u5907\u6570\u636e\u3002\n    \u6dfb\u52a0\u53f3\u4e0a\u89d2 \u201c+ Add data\u201d\n    \u5c06google landmark recognition dataset\u52a0\u8fdb\u53bb\u3002\u5206\u522b\u662f\uff1a\n        \uff08a\uff09google_landmarks_2019_64x64_part1\n         (b) google_landmarks_2019_64x64_part2","eecd6ff5":"Step 3: \u4f9d\u8d56\u9879\u548c\u8d85\u53c2\u8bbe\u7f6e","e5fdcafb":"# \u6574\u4f53\u8bbe\u8ba1\u601d\u8def\u4ecb\u7ecd\n    \n### define dataset\nlandmark_recog:\n    __init__(root, path, transform)\n    __get_item():\n    \ntrain_dataloader = Dataloader(dataset, 'train')\n\n### define model, loss, optimizer\nuse resenet-50\n\n### train_epoch \nfor i, (input, target) in enumerate(train_dataloader):\n\n    output = model(input)\n    loss = criterion(output, target)\n    loss.zero()\n    optimizer.backward()\n    loss.update()\n    \n    ## show progress\n    # \u4e0d\u9700\u8981\u5927\u5bb6\u5199\u8fd9\u91cc\n    \n### test_epoch\n    torch.with_no_grad():\n        for i, (input, target) in enumerate(test_dataloader):\n            xxxx\n            \n        # compute accuracy here\n        xxxx\n\n### main function\nif __file__ == 'main':\n\n    xxxx\n    dataloader = xx\n    model = xx\n    for i in range(MAX_EPOCH):\n        train_epoch\n        test_epoch\n        \n    save_result_to_csv('result_my_own.csv')\n    print('done')\n            ","932963f6":"Step 2: \u89c2\u5bdf\u6dfb\u52a0\u7684\u6570\u636e\uff08\u901a\u8fc7Kernel\u4e0b\u9762\u7684console\uff09\u3002"}}