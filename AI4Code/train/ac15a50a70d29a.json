{"cell_type":{"a08711ba":"code","60b90ed6":"code","c7caa9c2":"code","5eebcf3d":"code","d5206b90":"code","5ea64e4c":"code","d9cadca5":"code","6067f8bb":"code","06e87cc1":"code","b7b7eacf":"code","1555f488":"code","c89133c5":"code","e4675e7e":"code","47edd408":"code","03d0e492":"code","d761fe3e":"code","b1008e37":"code","8ee56974":"code","5cd9ca6c":"code","5bffe100":"code","aa9a3bd3":"code","88228a45":"code","fd33eb66":"code","dd59b5e2":"code","35bbb959":"code","22b0f176":"code","89bd81f3":"code","c34d74b5":"code","56dc1619":"code","4336d48c":"code","ddae5edc":"markdown","5d5ce926":"markdown","3837e91e":"markdown","80d8d5cd":"markdown","345892bc":"markdown"},"source":{"a08711ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60b90ed6":"import plotly.io as pio\npio.renderers.default = 'iframe' # or 'notebook' or 'colab' or 'jupyterlab'","c7caa9c2":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nfrom sklearn.impute import KNNImputer\n\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy import stats","5eebcf3d":"train_data = pd.read_csv('\/kaggle\/input\/song-popularity-prediction\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/song-popularity-prediction\/test.csv')","d5206b90":"correlation_matrix = train_data.corr()\ncorrelation_matrix = correlation_matrix*(correlation_matrix.abs()>0.3)","5ea64e4c":"fig = px.imshow(correlation_matrix, range_color=[-1,1], title=\"Correlation plot between all variables\") \n\nfig.update_layout(\n    yaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0,\n        dtick = 1\n    ),\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0,\n        dtick = 1\n    ), height = 700, width = 700\n)\nfig.show()","d9cadca5":"def create_distribution_plot(variable, bin_size=None):\n    not_pop_song = train_data.loc[train_data['song_popularity']==0][variable].dropna()\n    pop_song = train_data.loc[train_data['song_popularity']==1][variable].dropna()\n    \n    params = {}\n    if bin_size:\n        params['bin_size'] = bin_size\n    \n    fig = ff.create_distplot([not_pop_song, pop_song], ['not_pop_song', 'pop_song'],\n                       curve_type='normal',\n                       show_hist=False,\n                       show_rug=False, \n                       **params)\n    fig.update_layout(title_text=f'Distplot with Normal Distribution of - {variable}')\n#     fig.write_html(f'plots\/distplot_{variable}.html')\n    fig.show()","6067f8bb":"create_distribution_plot('acousticness', bin_size=0.2)","06e87cc1":"create_distribution_plot('song_duration_ms')","b7b7eacf":"create_distribution_plot('danceability')","1555f488":"create_distribution_plot('energy')","c89133c5":"create_distribution_plot('instrumentalness')","e4675e7e":"create_distribution_plot('liveness')","47edd408":"create_distribution_plot('loudness')","03d0e492":"create_distribution_plot('speechiness')","d761fe3e":"create_distribution_plot('tempo')","b1008e37":"create_distribution_plot('audio_valence')","8ee56974":"%%time\nnacols = [\n    \"song_duration_ms\",\n    \"acousticness\",\n    \"danceability\",\n    \"energy\",\n    \"instrumentalness\",\n    \"key\",\n    \"liveness\",\n    \"loudness\",\n]\n\nknn_imptr = KNNImputer(n_neighbors=1)\ntrain_knnimp = knn_imptr.fit_transform(train_data[nacols])\ntest_knnimp = knn_imptr.transform(test_data[nacols])","5cd9ca6c":"def get_cv_preds(clf, x_test):\n    preds = clf.predict(x_test)\n    return preds\n\ndef get_oof_preds(clf, skf, X, y):\n    oof_val_preds = []\n    oof_scores = []\n    y_val = []\n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        clf.fit(X_train, y_train)\n        val_preds = get_cv_preds(clf, X_test)\n        oof_val_preds.append(val_preds)\n        oof_scores.append(roc_auc_score(y_test, val_preds))\n        \n    oof_val_preds = [pred for oof_pred in oof_val_preds for pred in oof_pred.tolist()]\n    return y_val, oof_val_preds, oof_scores","5bffe100":"params_lgb = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 3,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':5000,\n    'colsample_bytree':0.1107,\n    'is_unbalance':True\n    }\n\nparams_xgb = {\n    'max_depth': 15,\n    'n_estimators': 11500,\n    'learning_rate': 0.01700342969369311,\n    'subsample': 0.30000000000000004,\n    'colsample_bytree': 0.9,\n    'colsample_bylevel': 0.2,\n    'min_child_weight': 2.7454477004662747,\n    'reg_lambda': 127.50463543261313,\n    'reg_alpha': 0.000742660058158055,\n    'gamma': 0.48066399265944365,\n    'tree_method':'gpu_hist'\n}","aa9a3bd3":"skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\nskf.get_n_splits(train_data.drop('song_popularity', axis=1), train_data['song_popularity'])","88228a45":"rgr1 = lgb.LGBMRegressor(**params_lgb)\nrgr2 = XGBRegressor(**params_xgb)","fd33eb66":"val_set, oof_preds, oof_scores = get_oof_preds(rgr1, skf,\n                                                       train_data.drop('song_popularity', axis=1),\n                                                       train_data['song_popularity'])","dd59b5e2":"oof_scores","35bbb959":"%%time\nval_set, oof_preds, oof_scores = get_oof_preds(rgr2, skf,\n                                                       train_data.drop('song_popularity', axis=1),\n                                                       train_data['song_popularity'])","22b0f176":"oof_scores","89bd81f3":"predicitons = rgr2.predict(test_data)","c34d74b5":"sample_submission_df = test_data.reset_index()[['id']].copy()\nsample_submission_df[\"song_popularity\"] = predicitons","56dc1619":"sample_submission_df.head()","4336d48c":"sample_submission_df.to_csv('submission.csv', index=False)","ddae5edc":"#### Definition of audio features according to [Spotify](https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/#\/operations\/get-audio-features)\n\n\n\n- **Danceability**: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n- **Valence**: Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n- **Energy**: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n- **Tempo**: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n- **Loudness**: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n- **Speechiness**: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\n- **Instrumentalness**: Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d.\n- **Liveness**: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n- **Acousticness**: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n- **Key**: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n- **Mode**: Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n- **Duration**: The duration of the track in milliseconds.\n- **Time Signature**: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).","5d5ce926":"## Classifier","3837e91e":"## Data Imputation","80d8d5cd":"## Correlation plot","345892bc":"acousticness and (loudness, energy) are <span style='color:red '> negatively correlated <\/span>\n\nenergy and loudness are <span style='color:#235C07 '> positively correlated <\/span>\n\naudio valence is <span style='color:#6AD638 '> slightly positive correlated <\/span> to dancebility, instrumentalness, loudness "}}