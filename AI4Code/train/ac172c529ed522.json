{"cell_type":{"2a7a2433":"code","cd1603cd":"code","53a80a53":"code","d48bd876":"code","61d57a8e":"code","4438c347":"code","7aec1e50":"code","8ed22115":"code","eea7baa8":"code","2f1499ab":"code","4748fc73":"code","569fe8c6":"code","b27e2c87":"markdown","71179488":"markdown","dd0d7667":"markdown","98c73492":"markdown","d62c2027":"markdown"},"source":{"2a7a2433":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import manifold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import decomposition","cd1603cd":"data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndata.head()","53a80a53":"df_labels = data.label\ndf_data = data.drop('label', axis = 1)\n","d48bd876":"#Count plot for the labels \nsns.countplot(df_labels)","61d57a8e":"#extracting top 10000 data points \ndf_data = df_data.head(10000)\ndf_labels = df_labels.head(10000)\npixel_df = StandardScaler().fit_transform(df_data)\npixel_df.shape","4438c347":"sample_data = pixel_df","7aec1e50":"pca = decomposition.PCA(n_components = 2, random_state = 42)","8ed22115":"pca_data = pca.fit_transform(sample_data)\nprint(\"shape of pca_reduced.shape = \", pca_data.shape)","eea7baa8":"# attaching the label for each 2-d data point \npca_data = np.column_stack((pca_data, df_labels))\n\n# creating a new data frame for plotting of data points\npca_df = pd.DataFrame(data=pca_data, columns=(\"X\", \"Y\", \"labels\"))\nprint(pca_df.head(10))\nsns.FacetGrid(pca_df, hue=\"labels\", size=6).map(plt.scatter, 'X', 'Y').add_legend()\nplt.show()","2f1499ab":"tsne = manifold.TSNE(n_components = 2, random_state = 42, verbose = 2, n_iter = 2000)\ntransformed_data = tsne.fit_transform(sample_data)","4748fc73":"#Creation of new dataframe for plotting of data points\ntsne_df = pd.DataFrame(\n    np.column_stack((transformed_data, df_labels)),\n    columns = ['x', 'y', 'labels'])\ntsne_df.loc[:, 'labels']= tsne_df.labels.astype(int)\nprint(tsne_df.head(10))\n","569fe8c6":"grid = sns.FacetGrid(tsne_df, hue='labels', size = 8)\ngrid.map(plt.scatter, 'x', 'y').add_legend()","b27e2c87":"**Implementation of t-SNE**","71179488":"# Introduction\n\n**Dimension Reduction:**\nThere are many ways to achieve dimensionality reduction, but most of these techniques fall into one of two classes \n* Feature Elimination\n* Feature Extraction\n\n**Principal Component Analysis (PCA):** \nPCA is a dimension reduction technique extensionally used for visualization of high dimensional data. It is a feature extraction technique \u2014 it combines all input variable in a specific way, drop the least important variables while retaining the most valuable ones. In this method we calculate eigenvectors and eigenvalues of the covariance matrix. Once eigenvectors are found from the covariance matrix, the nextstep is to order them by eigenvalue, highest to lowest. This gives you the components in order of significance.The eigenvector with the highest eigenvalue is the principal component of the data set.\n\n**t-Distributed Stochastic Neighbor Embedding (t-SNE):**\nt-SNE is a non-linear, unsupervised technique primarily used for data exploration and visualization of high-dimensional data. It provides you an intuition of how the data is arranged in a high-dimensional space. The t-SNE algorithm calculates a similarity measure between points in high dimensional space using Gaussian distribution then in the low dimensional space using Cauchy distribution. Finally it measures the probability distribution of the two dimensional spaces by Kullback-Liebler divergence and optimize the KL cost function using gradient descent.\n\n**PCA vs t-SNE:**\nt-SNE differs from PCA by preserving only small pairwise distances or local similarities whereas PCA is concerned with preserving large pairwise distances to maximize variance. PCA is a linear dimension reduction technique that seeks to maximize variance and preserves large pairwise distances. In other words, things that are different end up far apart. This can lead to poor visualization especially when dealing with non-linear manifold structures. \n\n> *In this notebook we will see the comparision between PCA and t-SNE on MNIST digits dataset*\n\n\n","dd0d7667":"Standardizing the data into a 2D array of shape 10000x784 as 10000 images have been extracted of shape 28x28 pixels. Flattening 28x28 pixels give 784 data points.","98c73492":"> Import data as Input\n\n* MNIST digits dataset is used for the purpose which consist of 784 pixel values and 42000 entries in train data","d62c2027":"**Implementation of PCA**"}}